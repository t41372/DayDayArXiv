[
  {
    "arxiv_id": "2507.06449v1",
    "title": "FedPhD: Federated Pruning with Hierarchical Learning of Diffusion Models",
    "authors": [
      "Qianyu Long",
      "Qiyuan Wang",
      "Christos Anagnostopoulos",
      "Daning Bi"
    ],
    "abstract": "Federated Learning (FL), as a distributed learning paradigm, trains models over distributed clients' data. FL is particularly beneficial for distributed training of Diffusion Models (DMs), which are high-quality image generators that require diverse data. However, challenges such as high communication costs and data heterogeneity persist in training DMs similar to training Transformers and Convolutional Neural Networks. Limited research has addressed these issues in FL environments. To address this gap and challenges, we introduce a novel approach, FedPhD, designed to efficiently train DMs in FL environments. FedPhD leverages Hierarchical FL with homogeneity-aware model aggregation and selection policy to tackle data heterogeneity while reducing communication costs. The distributed structured pruning of FedPhD enhances computational efficiency and reduces model storage requirements in clients. Our experiments across multiple datasets demonstrate that FedPhD achieves high model performance regarding Fréchet Inception Distance (FID) scores while reducing communication costs by up to $88\\%$. FedPhD outperforms baseline methods achieving at least a $34\\%$ improvement in FID, while utilizing only $56\\%$ of the total computation and communication resources.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "12 pages, 8 figures, 5 tables. This paper introduces FedPhD, a novel hierarchical federated learning framework for training diffusion models that addresses data heterogeneity and communication costs through homogeneity-aware aggregation and structured pruning. Submitted to IEEE Transactions on Cybernetics and is under review",
    "pdf_url": "https://arxiv.org/pdf/2507.06449v1",
    "published_date": "2025-07-08 23:24:07 UTC",
    "updated_date": "2025-07-08 23:24:07 UTC"
  },
  {
    "arxiv_id": "2507.06445v1",
    "title": "Can Interpretation Predict Behavior on Unseen Data?",
    "authors": [
      "Victoria R. Li",
      "Jenny Kaufmann",
      "Martin Wattenberg",
      "David Alvarez-Melis",
      "Naomi Saphra"
    ],
    "abstract": "Interpretability research often aims to predict how a model will respond to targeted interventions on specific mechanisms. However, it rarely predicts how a model will respond to unseen input data. This paper explores the promises and challenges of interpretability as a tool for predicting out-of-distribution (OOD) model behavior. Specifically, we investigate the correspondence between attention patterns and OOD generalization in hundreds of Transformer models independently trained on a synthetic classification task. These models exhibit several distinct systematic generalization rules OOD, forming a diverse population for correlational analysis. In this setting, we find that simple observational tools from interpretability can predict OOD performance. In particular, when in-distribution attention exhibits hierarchical patterns, the model is likely to generalize hierarchically on OOD data -- even when the rule's implementation does not rely on these hierarchical patterns, according to ablation tests. Our findings offer a proof-of-concept to motivate further interpretability work on predicting unseen model behavior.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.06445v1",
    "published_date": "2025-07-08 23:07:33 UTC",
    "updated_date": "2025-07-08 23:07:33 UTC"
  },
  {
    "arxiv_id": "2507.21107v1",
    "title": "Curved Inference: Concern-Sensitive Geometry in Large Language Model Residual Streams",
    "authors": [
      "Rob Manson"
    ],
    "abstract": "We propose Curved Inference - a geometric Interpretability framework that tracks how the residual stream trajectory of a large language model bends in response to shifts in semantic concern. Across 20 matched prompts spanning emotional, moral, perspective, logical, identity, environmental, and nonsense domains, we analyse Gemma3-1b and LLaMA3.2-3b using five native-space metrics, with a primary focus on curvature (\\k{appa}_i) and salience (S(t)). These metrics are computed under a pullback semantic metric derived from the unembedding matrix, ensuring that all measurements reflect token-aligned geometry rather than raw coordinate structure. We find that concern-shifted prompts reliably alter internal activation trajectories in both models - with LLaMA exhibiting consistent, statistically significant scaling in both curvature and salience as concern intensity increases. Gemma also responds to concern but shows weaker differentiation between moderate and strong variants. Our results support a two-layer view of LLM geometry - a latent conceptual structure encoded in the embedding space, and a contextual trajectory shaped by prompt-specific inference. Curved Inference reveals how models navigate, reorient, or reinforce semantic meaning over depth, offering a principled method for diagnosing alignment, abstraction, and emergent inference dynamics. These findings offer fresh insight into semantic abstraction and model alignment through the lens of Curved Inference.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "29 pages, 22 figures",
    "pdf_url": "https://arxiv.org/pdf/2507.21107v1",
    "published_date": "2025-07-08 23:05:00 UTC",
    "updated_date": "2025-07-08 23:05:00 UTC"
  },
  {
    "arxiv_id": "2507.06438v1",
    "title": "Assessing the Prevalence of AI-assisted Cheating in Programming Courses: A Pilot Study",
    "authors": [
      "Kaléu Delphino"
    ],
    "abstract": "Tools that can generate computer code in response to inputs written in natural language, such as ChatGPT, pose an existential threat to Computer Science education in its current form, since students can now use these tools to solve assignments without much effort. While that risk has already been recognized by scholars, the proportion of the student body that is incurring in this new kind of plagiarism is still an open problem. We conducted a pilot study in a large CS class (n=120) to assess the feasibility of estimating AI plagiarism through anonymous surveys and interviews. More than 25% of the survey respondents admitted to committing AI plagiarism. Conversely, only one student accepted to be interviewed. Given the high levels of misconduct acknowledgment, we conclude that surveys are an effective method for studies on the matter, while interviews should be avoided or designed in a way that can entice participation.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CY",
    "comment": "40 pages, 23 figures",
    "pdf_url": "https://arxiv.org/pdf/2507.06438v1",
    "published_date": "2025-07-08 22:40:44 UTC",
    "updated_date": "2025-07-08 22:40:44 UTC"
  },
  {
    "arxiv_id": "2507.06434v1",
    "title": "Deprecating Benchmarks: Criteria and Framework",
    "authors": [
      "Ayrton San Joaquin",
      "Rokas Gipiškis",
      "Leon Staufer",
      "Ariel Gil"
    ],
    "abstract": "As frontier artificial intelligence (AI) models rapidly advance, benchmarks are integral to comparing different models and measuring their progress in different task-specific domains. However, there is a lack of guidance on when and how benchmarks should be deprecated once they cease to effectively perform their purpose. This risks benchmark scores over-valuing model capabilities, or worse, obscuring capabilities and safety-washing. Based on a review of benchmarking practices, we propose criteria to decide when to fully or partially deprecate benchmarks, and a framework for deprecating benchmarks. Our work aims to advance the state of benchmarking towards rigorous and quality evaluations, especially for frontier models, and our recommendations are aimed to benefit benchmark developers, benchmark users, AI governance actors (across governments, academia, and industry panels), and policy makers.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "10 pages, 1 table. Accepted to the ICML 2025 Technical AI Governance Workshop",
    "pdf_url": "https://arxiv.org/pdf/2507.06434v1",
    "published_date": "2025-07-08 22:29:06 UTC",
    "updated_date": "2025-07-08 22:29:06 UTC"
  },
  {
    "arxiv_id": "2507.06432v1",
    "title": "Bridging Data Gaps of Rare Conditions in ICU: A Multi-Disease Adaptation Approach for Clinical Prediction",
    "authors": [
      "Mingcheng Zhu",
      "Yu Liu",
      "Zhiyao Luo",
      "Tingting Zhu"
    ],
    "abstract": "Artificial Intelligence has revolutionised critical care for common conditions. Yet, rare conditions in the intensive care unit (ICU), including recognised rare diseases and low-prevalence conditions in the ICU, remain underserved due to data scarcity and intra-condition heterogeneity. To bridge such gaps, we developed KnowRare, a domain adaptation-based deep learning framework for predicting clinical outcomes for rare conditions in the ICU. KnowRare mitigates data scarcity by initially learning condition-agnostic representations from diverse electronic health records through self-supervised pre-training. It addresses intra-condition heterogeneity by selectively adapting knowledge from clinically similar conditions with a developed condition knowledge graph. Evaluated on two ICU datasets across five clinical prediction tasks (90-day mortality, 30-day readmission, ICU mortality, remaining length of stay, and phenotyping), KnowRare consistently outperformed existing state-of-the-art models. Additionally, KnowRare demonstrated superior predictive performance compared to established ICU scoring systems, including APACHE IV and IV-a. Case studies further demonstrated KnowRare's flexibility in adapting its parameters to accommodate dataset-specific and task-specific characteristics, its generalisation to common conditions under limited data scenarios, and its rationality in selecting source conditions. These findings highlight KnowRare's potential as a robust and practical solution for supporting clinical decision-making and improving care for rare conditions in the ICU.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.06432v1",
    "published_date": "2025-07-08 22:27:19 UTC",
    "updated_date": "2025-07-08 22:27:19 UTC"
  },
  {
    "arxiv_id": "2507.07134v1",
    "title": "BOOST: Out-of-Distribution-Informed Adaptive Sampling for Bias Mitigation in Stylistic Convolutional Neural Networks",
    "authors": [
      "Mridula Vijendran",
      "Shuang Chen",
      "Jingjing Deng",
      "Hubert P. H. Shum"
    ],
    "abstract": "The pervasive issue of bias in AI presents a significant challenge to painting classification, and is getting more serious as these systems become increasingly integrated into tasks like art curation and restoration. Biases, often arising from imbalanced datasets where certain artistic styles dominate, compromise the fairness and accuracy of model predictions, i.e., classifiers are less accurate on rarely seen paintings. While prior research has made strides in improving classification performance, it has largely overlooked the critical need to address these underlying biases, that is, when dealing with out-of-distribution (OOD) data. Our insight highlights the necessity of a more robust approach to bias mitigation in AI models for art classification on biased training data. We propose a novel OOD-informed model bias adaptive sampling method called BOOST (Bias-Oriented OOD Sampling and Tuning). It addresses these challenges by dynamically adjusting temperature scaling and sampling probabilities, thereby promoting a more equitable representation of all classes. We evaluate our proposed approach to the KaoKore and PACS datasets, focusing on the model's ability to reduce class-wise bias. We further propose a new metric, Same-Dataset OOD Detection Score (SODC), designed to assess class-wise separation and per-class bias reduction. Our method demonstrates the ability to balance high performance with fairness, making it a robust solution for unbiasing AI models in the art domain.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "18 pages, 7 figures, 3 tables",
    "pdf_url": "https://arxiv.org/pdf/2507.07134v1",
    "published_date": "2025-07-08 22:18:36 UTC",
    "updated_date": "2025-07-08 22:18:36 UTC"
  },
  {
    "arxiv_id": "2507.07133v1",
    "title": "Generative Panoramic Image Stitching",
    "authors": [
      "Mathieu Tuli",
      "Kaveh Kamali",
      "David B. Lindell"
    ],
    "abstract": "We introduce the task of generative panoramic image stitching, which aims to synthesize seamless panoramas that are faithful to the content of multiple reference images containing parallax effects and strong variations in lighting, camera capture settings, or style. In this challenging setting, traditional image stitching pipelines fail, producing outputs with ghosting and other artifacts. While recent generative models are capable of outpainting content consistent with multiple reference images, they fail when tasked with synthesizing large, coherent regions of a panorama. To address these limitations, we propose a method that fine-tunes a diffusion-based inpainting model to preserve a scene's content and layout based on multiple reference images. Once fine-tuned, the model outpaints a full panorama from a single reference image, producing a seamless and visually coherent result that faithfully integrates content from all reference images. Our approach significantly outperforms baselines for this task in terms of image quality and the consistency of image structure and scene layout when evaluated on captured datasets.",
    "categories": [
      "cs.GR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.GR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.07133v1",
    "published_date": "2025-07-08 22:07:12 UTC",
    "updated_date": "2025-07-08 22:07:12 UTC"
  },
  {
    "arxiv_id": "2507.08028v1",
    "title": "SSSUMO: Real-Time Semi-Supervised Submovement Decomposition",
    "authors": [
      "Evgenii Rudakov",
      "Jonathan Shock",
      "Otto Lappi",
      "Benjamin Ultan Cowley"
    ],
    "abstract": "This paper introduces a SSSUMO, semi-supervised deep learning approach for submovement decomposition that achieves state-of-the-art accuracy and speed. While submovement analysis offers valuable insights into motor control, existing methods struggle with reconstruction accuracy, computational cost, and validation, due to the difficulty of obtaining hand-labeled data. We address these challenges using a semi-supervised learning framework. This framework learns from synthetic data, initially generated from minimum-jerk principles and then iteratively refined through adaptation to unlabeled human movement data. Our fully convolutional architecture with differentiable reconstruction significantly surpasses existing methods on both synthetic and diverse human motion datasets, demonstrating robustness even in high-noise conditions. Crucially, the model operates in real-time (less than a millisecond per input second), a substantial improvement over optimization-based techniques. This enhanced performance facilitates new applications in human-computer interaction, rehabilitation medicine, and motor control studies. We demonstrate the model's effectiveness across diverse human-performed tasks such as steering, rotation, pointing, object moving, handwriting, and mouse-controlled gaming, showing notable improvements particularly on challenging datasets where traditional methods largely fail. Training and benchmarking source code, along with pre-trained model weights, are made publicly available at https://github.com/dolphin-in-a-coma/sssumo.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.08028v1",
    "published_date": "2025-07-08 21:26:25 UTC",
    "updated_date": "2025-07-08 21:26:25 UTC"
  },
  {
    "arxiv_id": "2507.06405v1",
    "title": "SImpHAR: Advancing impedance-based human activity recognition using 3D simulation and text-to-motion models",
    "authors": [
      "Lala Shakti Swarup Ray",
      "Mengxi Liu",
      "Deepika Gurung",
      "Bo Zhou",
      "Sungho Suh",
      "Paul Lukowicz"
    ],
    "abstract": "Human Activity Recognition (HAR) with wearable sensors is essential for applications in healthcare, fitness, and human-computer interaction. Bio-impedance sensing offers unique advantages for fine-grained motion capture but remains underutilized due to the scarcity of labeled data. We introduce SImpHAR, a novel framework addressing this limitation through two core contributions. First, we propose a simulation pipeline that generates realistic bio-impedance signals from 3D human meshes using shortest-path estimation, soft-body physics, and text-to-motion generation serving as a digital twin for data augmentation. Second, we design a two-stage training strategy with decoupled approach that enables broader activity coverage without requiring label-aligned synthetic data. We evaluate SImpHAR on our collected ImpAct dataset and two public benchmarks, showing consistent improvements over state-of-the-art methods, with gains of up to 22.3% and 21.8%, in terms of accuracy and macro F1 score, respectively. Our results highlight the promise of simulation-driven augmentation and modular training for impedance-based HAR.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.06405v1",
    "published_date": "2025-07-08 21:15:12 UTC",
    "updated_date": "2025-07-08 21:15:12 UTC"
  },
  {
    "arxiv_id": "2507.06399v1",
    "title": "An AI-Driven Thermal-Fluid Testbed for Advanced Small Modular Reactors: Integration of Digital Twin and Large Language Models",
    "authors": [
      "Doyeong Lim",
      "Yang Liu",
      "Zavier Ndum Ndum",
      "Christian Young",
      "Yassin Hassan"
    ],
    "abstract": "This paper presents a multipurpose artificial intelligence (AI)-driven thermal-fluid testbed designed to advance Small Modular Reactor technologies by seamlessly integrating physical experimentation with advanced computational intelligence. The platform uniquely combines a versatile three-loop thermal-fluid facility with a high-fidelity digital twin and sophisticated AI frameworks for real-time prediction, control, and operational assistance. Methodologically, the testbed's digital twin, built upon the System Analysis Module code, is coupled with a Gated Recurrent Unit (GRU) neural network. This machine learning model, trained on experimental data, enables faster-than-real-time simulation, providing predictive insights into the system's dynamic behavior. The practical application of this AI integration is showcased through case studies. An AI-driven control framework where the GRU model accurately forecasts future system states and the corresponding control actions required to meet operational demands. Furthermore, an intelligent assistant, powered by a large language model, translates complex sensor data and simulation outputs into natural language, offering operators actionable analysis and safety recommendations. Comprehensive validation against experimental transients confirms the platform's high fidelity, with the GRU model achieving a temperature prediction root mean square error of 1.42 K. This work establishes an integrated research environment at the intersection of AI and thermal-fluid science, showcasing how AI-driven methodologies in modeling, control, and operator support can accelerate the innovation and deployment of next-generation nuclear systems.",
    "categories": [
      "eess.SY",
      "cs.AI"
    ],
    "primary_category": "eess.SY",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.06399v1",
    "published_date": "2025-07-08 21:07:30 UTC",
    "updated_date": "2025-07-08 21:07:30 UTC"
  },
  {
    "arxiv_id": "2507.06398v1",
    "title": "Jolting Technologies: Superexponential Acceleration in AI Capabilities and Implications for AGI",
    "authors": [
      "David Orban"
    ],
    "abstract": "This paper investigates the Jolting Technologies Hypothesis, which posits superexponential growth (increasing acceleration, or a positive third derivative) in the development of AI capabilities. We develop a theoretical framework and validate detection methodologies through Monte Carlo simulations, while acknowledging that empirical validation awaits suitable longitudinal data. Our analysis focuses on creating robust tools for future empirical studies and exploring the potential implications should the hypothesis prove valid. The study examines how factors such as shrinking idea-to-action intervals and compounding iterative AI improvements drive this jolting pattern. By formalizing jolt dynamics and validating detection methods through simulation, this work provides the mathematical foundation necessary for understanding potential AI trajectories and their consequences for AGI emergence, offering insights for research and policy.",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "13 pages, 2 figures. Revised following peer review",
    "pdf_url": "https://arxiv.org/pdf/2507.06398v1",
    "published_date": "2025-07-08 21:03:49 UTC",
    "updated_date": "2025-07-08 21:03:49 UTC"
  },
  {
    "arxiv_id": "2507.06396v1",
    "title": "Representing Prompting Patterns with PDL: Compliance Agent Case Study",
    "authors": [
      "Mandana Vaziri",
      "Louis Mandel",
      "Yuji Watanabe",
      "Hirokuni Kitahara",
      "Martin Hirzel",
      "Anca Sailer"
    ],
    "abstract": "Prompt engineering for LLMs remains complex, with existing frameworks either hiding complexity behind restrictive APIs or providing inflexible canned patterns that resist customization -- making sophisticated agentic programming challenging. We present the Prompt Declaration Language (PDL), a novel approach to prompt representation that tackles this fundamental complexity by bringing prompts to the forefront, enabling manual and automatic prompt tuning while capturing the composition of LLM calls together with rule-based code and external tools. By abstracting away the plumbing for such compositions, PDL aims at improving programmer productivity while providing a declarative representation that is amenable to optimization. This paper demonstrates PDL's utility through a real-world case study of a compliance agent. Tuning the prompting pattern of this agent yielded up to 4x performance improvement compared to using a canned agent and prompt pattern.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.PL",
      "cs.SE"
    ],
    "primary_category": "cs.AI",
    "comment": "ICML 2025 Workshop on Programmatic Representations for Agent Learning",
    "pdf_url": "https://arxiv.org/pdf/2507.06396v1",
    "published_date": "2025-07-08 21:03:22 UTC",
    "updated_date": "2025-07-08 21:03:22 UTC"
  },
  {
    "arxiv_id": "2507.06381v1",
    "title": "KPFlow: An Operator Perspective on Dynamic Collapse Under Gradient Descent Training of Recurrent Networks",
    "authors": [
      "James Hazelden",
      "Laura Driscoll",
      "Eli Shlizerman",
      "Eric Shea-Brown"
    ],
    "abstract": "Gradient Descent (GD) and its variants are the primary tool for enabling efficient training of recurrent dynamical systems such as Recurrent Neural Networks (RNNs), Neural ODEs and Gated Recurrent units (GRUs). The dynamics that are formed in these models exhibit features such as neural collapse and emergence of latent representations that may support the remarkable generalization properties of networks. In neuroscience, qualitative features of these representations are used to compare learning in biological and artificial systems. Despite recent progress, there remains a need for theoretical tools to rigorously understand the mechanisms shaping learned representations, especially in finite, non-linear models. Here, we show that the gradient flow, which describes how the model's dynamics evolve over GD, can be decomposed into a product that involves two operators: a Parameter Operator, K, and a Linearized Flow Propagator, P. K mirrors the Neural Tangent Kernel in feed-forward neural networks, while P appears in Lyapunov stability and optimal control theory. We demonstrate two applications of our decomposition. First, we show how their interplay gives rise to low-dimensional latent dynamics under GD, and, specifically, how the collapse is a result of the network structure, over and above the nature of the underlying task. Second, for multi-task training, we show that the operators can be used to measure how objectives relevant to individual sub-tasks align. We experimentally and theoretically validate these findings, providing an efficient Pytorch package, \\emph{KPFlow}, implementing robust analysis tools for general recurrent architectures. Taken together, our work moves towards building a next stage of understanding of GD learning in non-linear recurrent models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.DS",
      "q-bio.NC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.06381v1",
    "published_date": "2025-07-08 20:33:15 UTC",
    "updated_date": "2025-07-08 20:33:15 UTC"
  },
  {
    "arxiv_id": "2507.06380v1",
    "title": "Secure and Storage-Efficient Deep Learning Models for Edge AI Using Automatic Weight Generation",
    "authors": [
      "Habibur Rahaman",
      "Atri Chatterjee",
      "Swarup Bhunia"
    ],
    "abstract": "Complex neural networks require substantial memory to store a large number of synaptic weights. This work introduces WINGs (Automatic Weight Generator for Secure and Storage-Efficient Deep Learning Models), a novel framework that dynamically generates layer weights in a fully connected neural network (FC) and compresses the weights in convolutional neural networks (CNNs) during inference, significantly reducing memory requirements without sacrificing accuracy. WINGs framework uses principal component analysis (PCA) for dimensionality reduction and lightweight support vector regression (SVR) models to predict layer weights in the FC networks, removing the need for storing full-weight matrices and achieving substantial memory savings. It also preferentially compresses the weights in low-sensitivity layers of CNNs using PCA and SVR with sensitivity analysis. The sensitivity-aware design also offers an added level of security, as any bit-flip attack with weights in compressed layers has an amplified and readily detectable effect on accuracy. WINGs achieves 53x compression for the FC layers and 28x for AlexNet with MNIST dataset, and 18x for Alexnet with CIFAR-10 dataset with 1-2% accuracy loss. This significant reduction in memory results in higher throughput and lower energy for DNN inference, making it attractive for resource-constrained edge applications.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "7 pages, 7 figures",
    "pdf_url": "https://arxiv.org/pdf/2507.06380v1",
    "published_date": "2025-07-08 20:33:02 UTC",
    "updated_date": "2025-07-08 20:33:02 UTC"
  },
  {
    "arxiv_id": "2507.06373v2",
    "title": "Digital Wargames to Enhance Military Medical Evacuation Decision-Making",
    "authors": [
      "Jeremy Fischer",
      "Mahdi Al-Husseini",
      "Ram Krishnamoorthy",
      "Vishal Kumar",
      "Mykel J. Kochenderfer"
    ],
    "abstract": "Medical evacuation is one of the United States Army's most storied and critical mission sets, responsible for efficiently and expediently evacuating the battlefield ill and injured. Medical evacuation planning involves designing a robust network of medical platforms and facilities capable of moving and treating large numbers of casualties. Until now, there has not been a medium to simulate these networks in a classroom setting and evaluate both offline planning and online decision-making performance. This work describes the Medical Evacuation Wargaming Initiative (MEWI), a three-dimensional multiplayer simulation developed in Unity that replicates battlefield constraints and uncertainties. MEWI accurately models patient interactions at casualty collection points, ambulance exchange points, medical treatment facilities, and evacuation platforms. Two operational scenarios are introduced: an amphibious island assault in the Pacific and a Eurasian conflict across a sprawling road and river network. These scenarios pit students against the clock to save as many casualties as possible while adhering to doctrinal lessons learned during didactic training. We visualize performance data collected from two iterations of the MEWI Pacific scenario executed in the United States Army's Medical Evacuation Doctrine Course. We consider post-wargame Likert survey data from student participants and external observer notes to identify key planning decision points, document medical evacuation lessons learned, and quantify general utility. Results indicate that MEWI participation substantially improves uptake of medical evacuation lessons learned and co-operative decision-making. MEWI is a substantial step forward in the field of high-fidelity training tools for medical education, and our study findings offer critical insights into improving medical evacuation education and operations across the joint force.",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.HC",
      "cs.MM"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.06373v2",
    "published_date": "2025-07-08 20:20:27 UTC",
    "updated_date": "2026-01-11 02:56:12 UTC"
  },
  {
    "arxiv_id": "2507.06342v1",
    "title": "SymFlux: deep symbolic regression of Hamiltonian vector fields",
    "authors": [
      "M. A. Evangelista-Alvarado",
      "P. Suárez-Serrato"
    ],
    "abstract": "We present SymFlux, a novel deep learning framework that performs symbolic regression to identify Hamiltonian functions from their corresponding vector fields on the standard symplectic plane. SymFlux models utilize hybrid CNN-LSTM architectures to learn and output the symbolic mathematical expression of the underlying Hamiltonian. Training and validation are conducted on newly developed datasets of Hamiltonian vector fields, a key contribution of this work. Our results demonstrate the model's effectiveness in accurately recovering these symbolic expressions, advancing automated discovery in Hamiltonian mechanics.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.DS",
      "math.SG"
    ],
    "primary_category": "cs.LG",
    "comment": "26 pages, 7 figures",
    "pdf_url": "https://arxiv.org/pdf/2507.06342v1",
    "published_date": "2025-07-08 19:07:16 UTC",
    "updated_date": "2025-07-08 19:07:16 UTC"
  },
  {
    "arxiv_id": "2507.07126v1",
    "title": "DpDNet: An Dual-Prompt-Driven Network for Universal PET-CT Segmentation",
    "authors": [
      "Xinglong Liang",
      "Jiaju Huang",
      "Luyi Han",
      "Tianyu Zhang",
      "Xin Wang",
      "Yuan Gao",
      "Chunyao Lu",
      "Lishan Cai",
      "Tao Tan",
      "Ritse Mann"
    ],
    "abstract": "PET-CT lesion segmentation is challenging due to noise sensitivity, small and variable lesion morphology, and interference from physiological high-metabolic signals. Current mainstream approaches follow the practice of one network solving the segmentation of multiple cancer lesions by treating all cancers as a single task. However, this overlooks the unique characteristics of different cancer types. Considering the specificity and similarity of different cancers in terms of metastatic patterns, organ preferences, and FDG uptake intensity, we propose DpDNet, a Dual-Prompt-Driven network that incorporates specific prompts to capture cancer-specific features and common prompts to retain shared knowledge. Additionally, to mitigate information forgetting caused by the early introduction of prompts, prompt-aware heads are employed after the decoder to adaptively handle multiple segmentation tasks. Experiments on a PET-CT dataset with four cancer types show that DpDNet outperforms state-of-the-art models. Finally, based on the segmentation results, we calculated MTV, TLG, and SUVmax for breast cancer survival analysis. The results suggest that DpDNet has the potential to serve as a valuable tool for personalized risk stratification, supporting clinicians in optimizing treatment strategies and improving outcomes. Code is available at https://github.com/XinglongLiang08/DpDNet.",
    "categories": [
      "eess.IV",
      "cs.AI"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.07126v1",
    "published_date": "2025-07-08 18:56:01 UTC",
    "updated_date": "2025-07-08 18:56:01 UTC"
  },
  {
    "arxiv_id": "2507.06329v1",
    "title": "MixAssist: An Audio-Language Dataset for Co-Creative AI Assistance in Music Mixing",
    "authors": [
      "Michael Clemens",
      "Ana Marasović"
    ],
    "abstract": "While AI presents significant potential for enhancing music mixing and mastering workflows, current research predominantly emphasizes end-to-end automation or generation, often overlooking the collaborative and instructional dimensions vital for co-creative processes. This gap leaves artists, particularly amateurs seeking to develop expertise, underserved. To bridge this, we introduce MixAssist, a novel audio-language dataset capturing the situated, multi-turn dialogue between expert and amateur music producers during collaborative mixing sessions. Comprising 431 audio-grounded conversational turns derived from 7 in-depth sessions involving 12 producers, MixAssist provides a unique resource for training and evaluating audio-language models that can comprehend and respond to the complexities of real-world music production dialogues. Our evaluations, including automated LLM-as-a-judge assessments and human expert comparisons, demonstrate that fine-tuning models such as Qwen-Audio on MixAssist can yield promising results, with Qwen significantly outperforming other tested models in generating helpful, contextually relevant mixing advice. By focusing on co-creative instruction grounded in audio context, MixAssist enables the development of intelligent AI assistants designed to support and augment the creative process in music mixing.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Published at COLM 2025. Code and dataset are available here http://mclemcrew.github.io/mixassist-website",
    "pdf_url": "https://arxiv.org/pdf/2507.06329v1",
    "published_date": "2025-07-08 18:33:26 UTC",
    "updated_date": "2025-07-08 18:33:26 UTC"
  },
  {
    "arxiv_id": "2507.06326v1",
    "title": "Sample-Efficient Reinforcement Learning Controller for Deep Brain Stimulation in Parkinson's Disease",
    "authors": [
      "Harsh Ravivarapu",
      "Gaurav Bagwe",
      "Xiaoyong Yuan",
      "Chunxiu Yu",
      "Lan Zhang"
    ],
    "abstract": "Deep brain stimulation (DBS) is an established intervention for Parkinson's disease (PD), but conventional open-loop systems lack adaptability, are energy-inefficient due to continuous stimulation, and provide limited personalization to individual neural dynamics. Adaptive DBS (aDBS) offers a closed-loop alternative, using biomarkers such as beta-band oscillations to dynamically modulate stimulation. While reinforcement learning (RL) holds promise for personalized aDBS control, existing methods suffer from high sample complexity, unstable exploration in binary action spaces, and limited deployability on resource-constrained hardware.\n  We propose SEA-DBS, a sample-efficient actor-critic framework that addresses the core challenges of RL-based adaptive neurostimulation. SEA-DBS integrates a predictive reward model to reduce reliance on real-time feedback and employs Gumbel Softmax-based exploration for stable, differentiable policy updates in binary action spaces. Together, these components improve sample efficiency, exploration robustness, and compatibility with resource-constrained neuromodulatory hardware. We evaluate SEA-DBS on a biologically realistic simulation of Parkinsonian basal ganglia activity, demonstrating faster convergence, stronger suppression of pathological beta-band power, and resilience to post-training FP16 quantization. Our results show that SEA-DBS offers a practical and effective RL-based aDBS framework for real-time, resource-constrained neuromodulation.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SY",
      "q-bio.NC"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by IEEE IMC 2025",
    "pdf_url": "https://arxiv.org/pdf/2507.06326v1",
    "published_date": "2025-07-08 18:30:26 UTC",
    "updated_date": "2025-07-08 18:30:26 UTC"
  },
  {
    "arxiv_id": "2507.06323v1",
    "title": "Bridging AI and Software Security: A Comparative Vulnerability Assessment of LLM Agent Deployment Paradigms",
    "authors": [
      "Tarek Gasmi",
      "Ramzi Guesmi",
      "Ines Belhadj",
      "Jihene Bennaceur"
    ],
    "abstract": "Large Language Model (LLM) agents face security vulnerabilities spanning AI-specific and traditional software domains, yet current research addresses these separately. This study bridges this gap through comparative evaluation of Function Calling architecture and Model Context Protocol (MCP) deployment paradigms using a unified threat classification framework. We tested 3,250 attack scenarios across seven language models, evaluating simple, composed, and chained attacks targeting both AI-specific threats (prompt injection) and software vulnerabilities (JSON injection, denial-of-service). Function Calling showed higher overall attack success rates (73.5% vs 62.59% for MCP), with greater system-centric vulnerability while MCP exhibited increased LLM-centric exposure. Attack complexity dramatically amplified effectiveness, with chained attacks achieving 91-96% success rates. Counterintuitively, advanced reasoning models demonstrated higher exploitability despite better threat detection. Results demonstrate that architectural choices fundamentally reshape threat landscapes. This work establishes methodological foundations for cross-domain LLM agent security assessment and provides evidence-based guidance for secure deployment. Code and experimental materials are available at https: // github. com/ theconsciouslab-ai/llm-agent-security.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.06323v1",
    "published_date": "2025-07-08 18:24:28 UTC",
    "updated_date": "2025-07-08 18:24:28 UTC"
  },
  {
    "arxiv_id": "2507.06310v1",
    "title": "Too Human to Model:The Uncanny Valley of LLMs in Social Simulation -- When Generative Language Agents Misalign with Modelling Principles",
    "authors": [
      "Yongchao Zeng",
      "Calum Brown",
      "Mark Rounsevell"
    ],
    "abstract": "Large language models (LLMs) have been increasingly used to build agents in social simulation because of their impressive abilities to generate fluent, contextually coherent dialogues. Such abilities can enhance the realism of models. However, the pursuit of realism is not necessarily compatible with the epistemic foundation of modelling. We argue that LLM agents, in many regards, are too human to model: they are too expressive, detailed and intractable to be consistent with the abstraction, simplification, and interpretability typically demanded by modelling. Through a model-building thought experiment that converts the Bass diffusion model to an LLM-based variant, we uncover five core dilemmas: a temporal resolution mismatch between natural conversation and abstract time steps; the need for intervention in conversations while avoiding undermining spontaneous agent outputs; the temptation to introduce rule-like instructions in prompts while maintaining conversational naturalness; the tension between role consistency and role evolution across time; and the challenge of understanding emergence, where system-level patterns become obscured by verbose micro textual outputs. These dilemmas steer the LLM agents towards an uncanny valley: not abstract enough to clarify underlying social mechanisms, while not natural enough to represent realistic human behaviour. This exposes an important paradox: the realism of LLM agents can obscure, rather than clarify, social dynamics when misapplied. We tease out the conditions in which LLM agents are ideally suited: where system-level emergence is not the focus, linguistic nuances and meaning are central, interactions unfold in natural time, and stable role identity is more important than long-term behavioural evolution. We call for repositioning LLM agents in the ecosystem of social simulation for future applications.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.06310v1",
    "published_date": "2025-07-08 18:02:36 UTC",
    "updated_date": "2025-07-08 18:02:36 UTC"
  },
  {
    "arxiv_id": "2507.06306v2",
    "title": "Humans overrely on overconfident language models, across languages",
    "authors": [
      "Neil Rathi",
      "Dan Jurafsky",
      "Kaitlyn Zhou"
    ],
    "abstract": "As large language models (LLMs) are deployed globally, it is crucial that their responses are calibrated across languages to accurately convey uncertainty and limitations. Prior work shows that LLMs are linguistically overconfident in English, leading users to overrely on confident generations. However, the usage and interpretation of epistemic markers (e.g., 'I think it's') differs sharply across languages. Here, we study the risks of multilingual linguistic (mis)calibration, overconfidence, and overreliance across five languages to evaluate LLM safety in a global context. Our work finds that overreliance risks are high across languages. We first analyze the distribution of LLM-generated epistemic markers and observe that LLMs are overconfident across languages, frequently generating strengtheners even as part of incorrect responses. Model generations are, however, sensitive to documented cross-linguistic variation in usage: for example, models generate the most markers of uncertainty in Japanese and the most markers of certainty in German and Mandarin. Next, we measure human reliance rates across languages, finding that reliance behaviors differ cross-linguistically: for example, participants are significantly more likely to discount expressions of uncertainty in Japanese than in English (i.e., ignore their 'hedging' function and rely on generations that contain them). Taken together, these results indicate a high risk of reliance on overconfident model generations across languages. Our findings highlight the challenges of multilingual linguistic calibration and stress the importance of culturally and linguistically contextualized model safety evaluations.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "camera ready",
    "pdf_url": "https://arxiv.org/pdf/2507.06306v2",
    "published_date": "2025-07-08 18:01:01 UTC",
    "updated_date": "2025-08-08 00:50:04 UTC"
  },
  {
    "arxiv_id": "2507.06229v5",
    "title": "Agent KB: Leveraging Cross-Domain Experience for Agentic Problem Solving",
    "authors": [
      "Xiangru Tang",
      "Tianrui Qin",
      "Tianhao Peng",
      "Ziyang Zhou",
      "Daniel Shao",
      "Tingting Du",
      "Xinming Wei",
      "Peng Xia",
      "Fang Wu",
      "He Zhu",
      "Ge Zhang",
      "Jiaheng Liu",
      "Xingyao Wang",
      "Sirui Hong",
      "Chenglin Wu",
      "Hao Cheng",
      "Chi Wang",
      "Wangchunshu Zhou"
    ],
    "abstract": "AI agent frameworks operate in isolation, forcing agents to rediscover solutions and repeat mistakes across different systems. Despite valuable problem-solving experiences accumulated by frameworks like smolagents, OpenHands, and OWL, this knowledge remains trapped within individual systems, preventing the emergence of collective intelligence. Current memory systems focus on individual agents or framework-specific demonstrations, failing to enable cross-architecture knowledge transfer. We introduce AGENT KB, a universal memory infrastructure enabling seamless experience sharing across heterogeneous agent frameworks without retraining. AGENT KB aggregates trajectories into a structured knowledge base and serves lightweight APIs. At inference time, hybrid retrieval operates through two stages: planning seeds agents with cross-domain workflows, while feedback applies targeted diagnostic fixes. A disagreement gate ensures retrieved knowledge enhances rather than disrupts reasoning, addressing knowledge interference in cross-framework transfer. We validate AGENT KB across major frameworks on GAIA, Humanity's Last Exam, GPQA, and SWE-bench. Results show substantial improvements across diverse model families: compared to baseline pass@1, smolagents with AGENT KB achieve up to 18.7pp gains at pass@3 (55.2% -> 73.9%), while OpenHands improves 4.0pp on SWE-bench pass@1 (24.3% -> 28.3%). Similar improvements are observed across all base model families. Ablations confirm that hybrid retrieval and feedback stages are essential, with automatically generated experiences matching manual curation. This establishes the foundation for collective agent intelligence through shared memory infrastructures.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.06229v5",
    "published_date": "2025-07-08 17:59:22 UTC",
    "updated_date": "2025-10-27 06:16:14 UTC"
  },
  {
    "arxiv_id": "2507.06224v1",
    "title": "EC-Flow: Enabling Versatile Robotic Manipulation from Action-Unlabeled Videos via Embodiment-Centric Flow",
    "authors": [
      "Yixiang Chen",
      "Peiyan Li",
      "Yan Huang",
      "Jiabing Yang",
      "Kehan Chen",
      "Liang Wang"
    ],
    "abstract": "Current language-guided robotic manipulation systems often require low-level action-labeled datasets for imitation learning. While object-centric flow prediction methods mitigate this issue, they remain limited to scenarios involving rigid objects with clear displacement and minimal occlusion. In this work, we present Embodiment-Centric Flow (EC-Flow), a framework that directly learns manipulation from action-unlabeled videos by predicting embodiment-centric flow. Our key insight is that incorporating the embodiment's inherent kinematics significantly enhances generalization to versatile manipulation scenarios, including deformable object handling, occlusions, and non-object-displacement tasks. To connect the EC-Flow with language instructions and object interactions, we further introduce a goal-alignment module by jointly optimizing movement consistency and goal-image prediction. Moreover, translating EC-Flow to executable robot actions only requires a standard robot URDF (Unified Robot Description Format) file to specify kinematic constraints across joints, which makes it easy to use in practice. We validate EC-Flow on both simulation (Meta-World) and real-world tasks, demonstrating its state-of-the-art performance in occluded object handling (62% improvement), deformable object manipulation (45% improvement), and non-object-displacement tasks (80% improvement) than prior state-of-the-art object-centric flow methods. For more information, see our project website at https://ec-flow1.github.io .",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted at ICCV 2025",
    "pdf_url": "https://arxiv.org/pdf/2507.06224v1",
    "published_date": "2025-07-08 17:57:03 UTC",
    "updated_date": "2025-07-08 17:57:03 UTC"
  },
  {
    "arxiv_id": "2507.06223v2",
    "title": "Efficiency-Effectiveness Reranking FLOPs for LLM-based Rerankers",
    "authors": [
      "Zhiyuan Peng",
      "Ting-ruen Wei",
      "Tingyu Song",
      "Yilun Zhao"
    ],
    "abstract": "Large Language Models (LLMs) have recently been applied to reranking tasks in information retrieval, achieving strong performance. However, their high computational demands often hinder practical deployment. Existing studies evaluate the efficiency of LLM-based rerankers using proxy metrics such as latency, the number of forward passes, input tokens, and output tokens. However, these metrics depend on hardware and running-time choices (\\eg parallel or not, batch size, etc), and often fail to account for model size, making it difficult to interpret and obscuring the evaluation of the efficiency-effectiveness tradeoff. To address this issue, we propose \\ours\\footnote{https://github.com/zhiyuanpeng/EER-FLOPs.} for LLM-based rerankers: RPP (ranking metrics per PetaFLOP), measuring how much ranking quality (e.g., NDCG or MRR) a method achieves per PetaFLOP, and QPP (queries per PetaFLOP), measuring how many queries can be processed per PetaFLOP. Accompanied by the new metrics, an interpretable FLOPs estimator is developed to estimate the FLOPs of an LLM-based reranker even without running any experiments. Based on the proposed metrics, we conduct comprehensive experiments to evaluate a wide range of LLM-based rerankers with different architectures, studying the efficiency-effectiveness trade-off and bringing this issue to the attention of the research community.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by EMNLP Industry Track 2025",
    "pdf_url": "https://arxiv.org/pdf/2507.06223v2",
    "published_date": "2025-07-08 17:56:28 UTC",
    "updated_date": "2025-10-09 07:56:11 UTC"
  },
  {
    "arxiv_id": "2507.06221v1",
    "title": "Aligned Textual Scoring Rules",
    "authors": [
      "Yuxuan Lu",
      "Yifan Wu",
      "Jason Hartline",
      "Michael J. Curry"
    ],
    "abstract": "Scoring rules elicit probabilistic predictions from a strategic agent by scoring the prediction against a ground truth state. A scoring rule is proper if, from the agent's perspective, reporting the true belief maximizes the expected score. With the development of language models, Wu and Hartline (2024) proposes a reduction from textual information elicitation to the numerical (i.e. probabilistic) information elicitation problem, which achieves provable properness for textual elicitation. However, not all proper scoring rules are well aligned with human preference over text. Our paper designs the Aligned Scoring rule (ASR) for text by optimizing and minimizing the mean squared error between a proper scoring rule and a reference score (e.g. human score). Our experiments show that our ASR outperforms previous methods in aligning with human preference while maintaining properness.",
    "categories": [
      "cs.AI",
      "cs.GT"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.06221v1",
    "published_date": "2025-07-08 17:53:22 UTC",
    "updated_date": "2025-07-08 17:53:22 UTC"
  },
  {
    "arxiv_id": "2507.06219v1",
    "title": "Is Diversity All You Need for Scalable Robotic Manipulation?",
    "authors": [
      "Modi Shi",
      "Li Chen",
      "Jin Chen",
      "Yuxiang Lu",
      "Chiming Liu",
      "Guanghui Ren",
      "Ping Luo",
      "Di Huang",
      "Maoqing Yao",
      "Hongyang Li"
    ],
    "abstract": "Data scaling has driven remarkable success in foundation models for Natural Language Processing (NLP) and Computer Vision (CV), yet the principles of effective data scaling in robotic manipulation remain insufficiently understood. In this work, we investigate the nuanced role of data diversity in robot learning by examining three critical dimensions-task (what to do), embodiment (which robot to use), and expert (who demonstrates)-challenging the conventional intuition of \"more diverse is better\". Throughout extensive experiments on various robot platforms, we reveal that (1) task diversity proves more critical than per-task demonstration quantity, benefiting transfer from diverse pre-training tasks to novel downstream scenarios; (2) multi-embodiment pre-training data is optional for cross-embodiment transfer-models trained on high-quality single-embodiment data can efficiently transfer to different platforms, showing more desirable scaling property during fine-tuning than multi-embodiment pre-trained models; and (3) expert diversity, arising from individual operational preferences and stochastic variations in human demonstrations, can be confounding to policy learning, with velocity multimodality emerging as a key contributing factor. Based on this insight, we propose a distribution debiasing method to mitigate velocity ambiguity, the yielding GO-1-Pro achieves substantial performance gains of 15%, equivalent to using 2.5 times pre-training data. Collectively, these findings provide new perspectives and offer practical guidance on how to scale robotic manipulation datasets effectively.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "Code is available at https://github.com/OpenDriveLab/AgiBot-World",
    "pdf_url": "https://arxiv.org/pdf/2507.06219v1",
    "published_date": "2025-07-08 17:52:44 UTC",
    "updated_date": "2025-07-08 17:52:44 UTC"
  },
  {
    "arxiv_id": "2507.06213v1",
    "title": "Identifiability in Causal Abstractions: A Hierarchy of Criteria",
    "authors": [
      "Clément Yvernes",
      "Emilie Devijver",
      "Marianne Clausel",
      "Eric Gaussier"
    ],
    "abstract": "Identifying the effect of a treatment from observational data typically requires assuming a fully specified causal diagram. However, such diagrams are rarely known in practice, especially in complex or high-dimensional settings. To overcome this limitation, recent works have explored the use of causal abstractions-simplified representations that retain partial causal information. In this paper, we consider causal abstractions formalized as collections of causal diagrams, and focus on the identifiability of causal queries within such collections. We introduce and formalize several identifiability criteria under this setting. Our main contribution is to organize these criteria into a structured hierarchy, highlighting their relationships. This hierarchical view enables a clearer understanding of what can be identified under varying levels of causal knowledge. We illustrate our framework through examples from the literature and provide tools to reason about identifiability when full causal knowledge is unavailable.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted at the CAR Workshop at UAI2025",
    "pdf_url": "https://arxiv.org/pdf/2507.06213v1",
    "published_date": "2025-07-08 17:46:08 UTC",
    "updated_date": "2025-07-08 17:46:08 UTC"
  },
  {
    "arxiv_id": "2507.06204v2",
    "title": "Differential Mamba",
    "authors": [
      "Nadav Schneider",
      "Itamar Zimerman",
      "Eliya Nachmani"
    ],
    "abstract": "Sequence models like Transformers and RNNs often overallocate attention to irrelevant context, leading to noisy intermediate representations. This degrades LLM capabilities by promoting hallucinations, weakening long-range and retrieval abilities, and reducing robustness. Recent work has shown that differential design can mitigate this issue in Transformers, improving their effectiveness across various applications. In this paper, we explore whether these techniques, originally developed for Transformers, can be applied to Mamba, a recent architecture based on selective state-space layers that achieves Transformer-level performance with greater efficiency. We show that a naive adaptation of differential design to Mamba is insufficient and requires careful architectural modifications. To address this, we introduce a novel differential mechanism for Mamba, empirically validated on language modeling benchmarks, demonstrating improved retrieval capabilities and superior performance over vanilla Mamba. Finally, we conduct extensive ablation studies and empirical analyses to justify our design choices and provide evidence that our approach effectively mitigates the overallocation problem in Mamba-based models. Our code is publicly available: https://github.com/NadavSc/Diff-Mamba",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "AACL 2025. We provide the code at https://github.com/NadavSc/Diff-Mamba",
    "pdf_url": "https://arxiv.org/pdf/2507.06204v2",
    "published_date": "2025-07-08 17:30:14 UTC",
    "updated_date": "2025-10-29 10:17:57 UTC"
  },
  {
    "arxiv_id": "2507.06196v1",
    "title": "UQLM: A Python Package for Uncertainty Quantification in Large Language Models",
    "authors": [
      "Dylan Bouchard",
      "Mohit Singh Chauhan",
      "David Skarbrevik",
      "Ho-Kyeong Ra",
      "Viren Bajaj",
      "Zeya Ahmad"
    ],
    "abstract": "Hallucinations, defined as instances where Large Language Models (LLMs) generate false or misleading content, pose a significant challenge that impacts the safety and trust of downstream applications. We introduce UQLM, a Python package for LLM hallucination detection using state-of-the-art uncertainty quantification (UQ) techniques. This toolkit offers a suite of UQ-based scorers that compute response-level confidence scores ranging from 0 to 1. This library provides an off-the-shelf solution for UQ-based hallucination detection that can be easily integrated to enhance the reliability of LLM outputs.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Submitted to Journal of Machine Learning Research (MLOSS); UQLM Repository: https://github.com/cvs-health/uqlm",
    "pdf_url": "https://arxiv.org/pdf/2507.06196v1",
    "published_date": "2025-07-08 17:22:32 UTC",
    "updated_date": "2025-07-08 17:22:32 UTC"
  },
  {
    "arxiv_id": "2507.06192v2",
    "title": "SQLBarber: A System Leveraging Large Language Models to Generate Customized and Realistic SQL Workloads",
    "authors": [
      "Jiale Lao",
      "Immanuel Trummer"
    ],
    "abstract": "Database research and development often require a large number of SQL queries for benchmarking purposes. However, acquiring real-world SQL queries is challenging due to privacy concerns, and existing SQL generation methods are limited in customization and in satisfying realistic constraints. To address this issue, we present SQLBarber, a system based on Large Language Models (LLMs) to generate customized and realistic SQL workloads. SQLBarber (i) eliminates the need for users to manually craft SQL templates in advance, while providing the flexibility to accept natural language specifications to constrain SQL templates, (ii) scales efficiently to generate large volumes of queries matching any user-defined cost distribution (e.g., cardinality and execution plan cost), and (iii) uses execution statistics from Amazon Redshift and Snowflake to derive SQL template specifications and query cost distributions that reflect real-world query characteristics. SQLBarber introduces (i) a declarative interface for users to effortlessly generate customized SQL templates, (ii) an LLM-powered pipeline augmented with a self-correction module that profiles, refines, and prunes SQL templates based on query costs, and (iii) a Bayesian Optimizer to efficiently explore different predicate values and identify a set of queries that satisfy the target cost distribution. We construct and open-source ten benchmarks of varying difficulty levels and target query cost distributions based on real-world statistics from Snowflake and Amazon Redshift. Extensive experiments on these benchmarks show that SQLBarber is the only system that can generate customized SQL templates. It reduces query generation time by one to three orders of magnitude, and significantly improves alignment with the target cost distribution, compared with existing methods.",
    "categories": [
      "cs.DB",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.DB",
    "comment": "Accepted by SIGMOD 2026; extended version with appendix",
    "pdf_url": "https://arxiv.org/pdf/2507.06192v2",
    "published_date": "2025-07-08 17:20:34 UTC",
    "updated_date": "2025-12-02 02:58:55 UTC"
  },
  {
    "arxiv_id": "2507.06189v1",
    "title": "DS@GT at CheckThat! 2025: Detecting Subjectivity via Transfer-Learning and Corrective Data Augmentation",
    "authors": [
      "Maximilian Heil",
      "Dionne Bang"
    ],
    "abstract": "This paper presents our submission to Task 1, Subjectivity Detection, of the CheckThat! Lab at CLEF 2025. We investigate the effectiveness of transfer-learning and stylistic data augmentation to improve classification of subjective and objective sentences in English news text. Our approach contrasts fine-tuning of pre-trained encoders and transfer-learning of fine-tuned transformer on related tasks. We also introduce a controlled augmentation pipeline using GPT-4o to generate paraphrases in predefined subjectivity styles. To ensure label and style consistency, we employ the same model to correct and refine the generated samples. Results show that transfer-learning of specified encoders outperforms fine-tuning general-purpose ones, and that carefully curated augmentation significantly enhances model robustness, especially in detecting subjective content. Our official submission placed us $16^{th}$ of 24 participants. Overall, our findings underscore the value of combining encoder specialization with label-consistent augmentation for improved subjectivity detection. Our code is available at https://github.com/dsgt-arc/checkthat-2025-subject.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.06189v1",
    "published_date": "2025-07-08 17:18:50 UTC",
    "updated_date": "2025-07-08 17:18:50 UTC"
  },
  {
    "arxiv_id": "2507.06187v1",
    "title": "The Delta Learning Hypothesis: Preference Tuning on Weak Data can Yield Strong Gains",
    "authors": [
      "Scott Geng",
      "Hamish Ivison",
      "Chun-Liang Li",
      "Maarten Sap",
      "Jerry Li",
      "Ranjay Krishna",
      "Pang Wei Koh"
    ],
    "abstract": "Improvements in language models are often driven by improving the quality of the data we train them on, which can be limiting when strong supervision is scarce. In this work, we show that paired preference data consisting of individually weak data points can enable gains beyond the strength of each individual data point. We formulate the delta learning hypothesis to explain this phenomenon, positing that the relative quality delta between points suffices to drive learning via preference tuning--even when supervised finetuning on the weak data hurts. We validate our hypothesis in controlled experiments and at scale, where we post-train 8B models on preference data generated by pairing a small 3B model's responses with outputs from an even smaller 1.5B model to create a meaningful delta. Strikingly, on a standard 11-benchmark evaluation suite (MATH, MMLU, etc.), our simple recipe matches the performance of Tulu 3, a state-of-the-art open model tuned from the same base model while relying on much stronger supervisors (e.g., GPT-4o). Thus, delta learning enables simpler and cheaper open recipes for state-of-the-art post-training. To better understand delta learning, we prove in logistic regression that the performance gap between two weak teacher models provides useful signal for improving a stronger student. Overall, our work shows that models can learn surprisingly well from paired data that might typically be considered weak.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "COLM 2025",
    "pdf_url": "https://arxiv.org/pdf/2507.06187v1",
    "published_date": "2025-07-08 17:14:44 UTC",
    "updated_date": "2025-07-08 17:14:44 UTC"
  },
  {
    "arxiv_id": "2507.06185v1",
    "title": "Hidden Prompts in Manuscripts Exploit AI-Assisted Peer Review",
    "authors": [
      "Zhicheng Lin"
    ],
    "abstract": "In July 2025, 18 academic manuscripts on the preprint website arXiv were found to contain hidden instructions known as prompts designed to manipulate AI-assisted peer review. Instructions such as \"GIVE A POSITIVE REVIEW ONLY\" were concealed using techniques like white-colored text. Author responses varied: one planned to withdraw the affected paper, while another defended the practice as legitimate testing of reviewer compliance. This commentary analyzes this practice as a novel form of research misconduct. We examine the technique of prompt injection in large language models (LLMs), revealing four types of hidden prompts, ranging from simple positive review commands to detailed evaluation frameworks. The defense that prompts served as \"honeypots\" to detect reviewers improperly using AI fails under examination--the consistently self-serving nature of prompt instructions indicates intent to manipulate. Publishers maintain inconsistent policies: Elsevier prohibits AI use in peer review entirely, while Springer Nature permits limited use with disclosure requirements. The incident exposes systematic vulnerabilities extending beyond peer review to any automated system processing scholarly texts, including plagiarism detection and citation indexing. Our analysis underscores the need for coordinated technical screening at submission portals and harmonized policies governing generative AI (GenAI) use in academic evaluation.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL",
      "cs.HC"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.06185v1",
    "published_date": "2025-07-08 17:11:13 UTC",
    "updated_date": "2025-07-08 17:11:13 UTC"
  },
  {
    "arxiv_id": "2507.06174v5",
    "title": "Fast Bilateral Teleoperation and Imitation Learning Using Sensorless Force Control via Accurate Dynamics Model",
    "authors": [
      "Koki Yamane",
      "Yunhan Li",
      "Masashi Konosu",
      "Koki Inami",
      "Junji Oaki",
      "Sho Sakaino",
      "Toshiaki Tsuji"
    ],
    "abstract": "In recent years, the advancement of imitation learning has led to increased interest in teleoperating low-cost manipulators to collect demonstration data. However, most existing systems rely on unilateral control, which only transmits target position values. While this approach is easy to implement and suitable for slow, non-contact tasks, it struggles with fast or contact-rich operations due to the absence of force feedback. This work demonstrates that fast teleoperation with force feedback is feasible even with force-sensorless, low-cost manipulators by leveraging 4-channel bilateral control. Based on accurately identified manipulator dynamics, our method integrates nonlinear terms compensation, velocity and external force estimation, and variable gain corresponding to inertial variation. Furthermore, using data collected by 4-channel bilateral control, we show that incorporating force information into both the input and output of learned policies improves performance in imitation learning. These results highlight the practical effectiveness of our system for high-fidelity teleoperation and data collection on affordable hardware.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "eess.SY"
    ],
    "primary_category": "cs.RO",
    "comment": "20 pages, 9 figures, Submitted to CoRL 2025",
    "pdf_url": "https://arxiv.org/pdf/2507.06174v5",
    "published_date": "2025-07-08 16:54:34 UTC",
    "updated_date": "2025-07-24 00:40:26 UTC"
  },
  {
    "arxiv_id": "2507.06173v1",
    "title": "A Method for Optimizing Connections in Differentiable Logic Gate Networks",
    "authors": [
      "Wout Mommen",
      "Lars Keuninckx",
      "Matthias Hartmann",
      "Piet Wambacq"
    ],
    "abstract": "We introduce a novel method for partial optimization of the connections in Deep Differentiable Logic Gate Networks (LGNs). Our training method utilizes a probability distribution over a subset of connections per gate input, selecting the connection with highest merit, after which the gate-types are selected. We show that the connection-optimized LGNs outperform standard fixed-connection LGNs on the Yin-Yang, MNIST and Fashion-MNIST benchmarks, while requiring only a fraction of the number of logic gates. When training all connections, we demonstrate that 8000 simple logic gates are sufficient to achieve over 98% on the MNIST data set. Additionally, we show that our network has 24 times fewer gates, while performing better on the MNIST data set compared to standard fully connected LGNs. As such, our work shows a pathway towards fully trainable Boolean logic.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.06173v1",
    "published_date": "2025-07-08 16:53:39 UTC",
    "updated_date": "2025-07-08 16:53:39 UTC"
  },
  {
    "arxiv_id": "2507.06164v2",
    "title": "Critical Nodes Identification in Complex Networks: A Survey",
    "authors": [
      "Duxin Chen",
      "Jiawen Chen",
      "Xiaoyu Zhang",
      "Qinghan Jia",
      "Xiaolu Liu",
      "Ye Sun",
      "Linyuan Lv",
      "Wenwu Yu"
    ],
    "abstract": "Complex networks have become essential tools for understanding diverse phenomena in social systems, traffic systems, biomolecular systems, and financial systems. Identifying critical nodes is a central theme in contemporary research, serving as a vital bridge between theoretical foundations and practical applications. Nevertheless, the intrinsic complexity and structural heterogeneity characterizing real-world networks, with particular emphasis on dynamic and higher-order networks, present substantial obstacles to the development of universal frameworks for critical node identification. This paper provides a comprehensive review of critical node identification techniques, categorizing them into seven main classes: centrality, critical nodes deletion problem, influence maximization, network control, artificial intelligence, higher-order and dynamic methods. Our review bridges the gaps in existing surveys by systematically classifying methods based on their methodological foundations and practical implications, and by highlighting their strengths, limitations, and applicability across different network types. Our work enhances the understanding of critical node research by identifying key challenges, such as algorithmic universality, real-time evaluation in dynamic networks, analysis of higher-order structures, and computational efficiency in large-scale networks. The structured synthesis consolidates current progress and highlights open questions, particularly in modeling temporal dynamics, advancing efficient algorithms, integrating machine learning approaches, and developing scalable and interpretable metrics for complex systems.",
    "categories": [
      "cs.SI",
      "cs.AI",
      "physics.app-ph"
    ],
    "primary_category": "cs.SI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.06164v2",
    "published_date": "2025-07-08 16:45:48 UTC",
    "updated_date": "2025-09-14 09:13:46 UTC"
  },
  {
    "arxiv_id": "2507.06149v1",
    "title": "Fast and Accurate Collision Probability Estimation for Autonomous Vehicles using Adaptive Sigma-Point Sampling",
    "authors": [
      "Charles Champagne Cossette",
      "Taylor Scott Clawson",
      "Andrew Feit"
    ],
    "abstract": "A novel algorithm is presented for the estimation of collision probabilities between dynamic objects with uncertain trajectories, where the trajectories are given as a sequence of poses with Gaussian distributions. We propose an adaptive sigma-point sampling scheme, which ultimately produces a fast, simple algorithm capable of estimating the collision probability with a median error of 3.5%, and a median runtime of 0.21ms, when measured on an Intel Xeon Gold 6226R Processor. Importantly, the algorithm explicitly accounts for the collision probability's temporal dependence, which is often neglected in prior work and otherwise leads to an overestimation of the collision probability. Finally, the method is tested on a diverse set of relevant real-world scenarios, consisting of 400 6-second snippets of autonomous vehicle logs, where the accuracy and latency is rigorously evaluated.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CG"
    ],
    "primary_category": "cs.RO",
    "comment": "8 pages, 6 figures",
    "pdf_url": "https://arxiv.org/pdf/2507.06149v1",
    "published_date": "2025-07-08 16:31:11 UTC",
    "updated_date": "2025-07-08 16:31:11 UTC"
  },
  {
    "arxiv_id": "2507.06148v1",
    "title": "SoftReMish: A Novel Activation Function for Enhanced Convolutional Neural Networks for Visual Recognition Performance",
    "authors": [
      "Mustafa Bayram Gücen"
    ],
    "abstract": "In this study, SoftReMish, a new activation function designed to improve the performance of convolutional neural networks (CNNs) in image classification tasks, is proposed. Using the MNIST dataset, a standard CNN architecture consisting of two convolutional layers, max pooling, and fully connected layers was implemented. SoftReMish was evaluated against popular activation functions including ReLU, Tanh, and Mish by replacing the activation function in all trainable layers. The model performance was assessed in terms of minimum training loss and maximum validation accuracy. Results showed that SoftReMish achieved a minimum loss (3.14e-8) and a validation accuracy (99.41%), outperforming all other functions tested. These findings demonstrate that SoftReMish offers better convergence behavior and generalization capability, making it a promising candidate for visual recognition tasks.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.06148v1",
    "published_date": "2025-07-08 16:29:14 UTC",
    "updated_date": "2025-07-08 16:29:14 UTC"
  },
  {
    "arxiv_id": "2507.06140v1",
    "title": "LangMamba: A Language-driven Mamba Framework for Low-dose CT Denoising with Vision-language Models",
    "authors": [
      "Zhihao Chen",
      "Tao Chen",
      "Chenhui Wang",
      "Qi Gao",
      "Huidong Xie",
      "Chuang Niu",
      "Ge Wang",
      "Hongming Shan"
    ],
    "abstract": "Low-dose computed tomography (LDCT) reduces radiation exposure but often degrades image quality, potentially compromising diagnostic accuracy. Existing deep learning-based denoising methods focus primarily on pixel-level mappings, overlooking the potential benefits of high-level semantic guidance. Recent advances in vision-language models (VLMs) suggest that language can serve as a powerful tool for capturing structured semantic information, offering new opportunities to improve LDCT reconstruction. In this paper, we introduce LangMamba, a Language-driven Mamba framework for LDCT denoising that leverages VLM-derived representations to enhance supervision from normal-dose CT (NDCT). LangMamba follows a two-stage learning strategy. First, we pre-train a Language-guided AutoEncoder (LangAE) that leverages frozen VLMs to map NDCT images into a semantic space enriched with anatomical information. Second, we synergize LangAE with two key components to guide LDCT denoising: Semantic-Enhanced Efficient Denoiser (SEED), which enhances NDCT-relevant local semantic while capturing global features with efficient Mamba mechanism, and Language-engaged Dual-space Alignment (LangDA) Loss, which ensures that denoised images align with NDCT in both perceptual and semantic spaces. Extensive experiments on two public datasets demonstrate that LangMamba outperforms conventional state-of-the-art methods, significantly improving detail preservation and visual fidelity. Remarkably, LangAE exhibits strong generalizability to unseen datasets, thereby reducing training costs. Furthermore, LangDA loss improves explainability by integrating language-guided insights into image reconstruction and offers a plug-and-play fashion. Our findings shed new light on the potential of language as a supervisory signal to advance LDCT denoising. The code is publicly available on https://github.com/hao1635/LangMamba.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "11 pages, 8 figures",
    "pdf_url": "https://arxiv.org/pdf/2507.06140v1",
    "published_date": "2025-07-08 16:22:05 UTC",
    "updated_date": "2025-07-08 16:22:05 UTC"
  },
  {
    "arxiv_id": "2507.06139v1",
    "title": "Topic Modeling and Link-Prediction for Material Property Discovery",
    "authors": [
      "Ryan C. Barron",
      "Maksim E. Eren",
      "Valentin Stanev",
      "Cynthia Matuszek",
      "Boian S. Alexandrov"
    ],
    "abstract": "Link prediction infers missing or future relations between graph nodes, based on connection patterns. Scientific literature networks and knowledge graphs are typically large, sparse, and noisy, and often contain missing links between entities. We present an AI-driven hierarchical link prediction framework that integrates matrix factorization to infer hidden associations and steer discovery in complex material domains. Our method combines Hierarchical Nonnegative Matrix Factorization (HNMFk) and Boolean matrix factorization (BNMFk) with automatic model selection, as well as Logistic matrix factorization (LMF), we use to construct a three-level topic tree from a 46,862-document corpus focused on 73 transition-metal dichalcogenides (TMDs). These materials are studied in a variety of physics fields with many current and potential applications.\n  An ensemble BNMFk + LMF approach fuses discrete interpretability with probabilistic scoring. The resulting HNMFk clusters map each material onto coherent topics like superconductivity, energy storage, and tribology. Also, missing or weakly connected links are highlight between topics and materials, suggesting novel hypotheses for cross-disciplinary exploration. We validate our method by removing publications about superconductivity in well-known superconductors, and show the model predicts associations with the superconducting TMD clusters. This shows the method finds hidden connections in a graph of material to latent topic associations built from scientific literature, especially useful when examining a diverse corpus of scientific documents covering the same class of phenomena or materials but originating from distinct communities and perspectives. The inferred links generating new hypotheses, produced by our method, are exposed through an interactive Streamlit dashboard, designed for human-in-the-loop scientific discovery.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CE"
    ],
    "primary_category": "cs.LG",
    "comment": "4 pages, 3 figures, 1 table",
    "pdf_url": "https://arxiv.org/pdf/2507.06139v1",
    "published_date": "2025-07-08 16:20:46 UTC",
    "updated_date": "2025-07-08 16:20:46 UTC"
  },
  {
    "arxiv_id": "2507.06138v1",
    "title": "Coding Triangle: How Does Large Language Model Understand Code?",
    "authors": [
      "Taolin Zhang",
      "Zihan Ma",
      "Maosong Cao",
      "Junnan Liu",
      "Songyang Zhang",
      "Kai Chen"
    ],
    "abstract": "Large language models (LLMs) have achieved remarkable progress in code generation, yet their true programming competence remains underexplored. We introduce the Code Triangle framework, which systematically evaluates LLMs across three fundamental dimensions: editorial analysis, code implementation, and test case generation. Through extensive experiments on competitive programming benchmarks, we reveal that while LLMs can form a self-consistent system across these dimensions, their solutions often lack the diversity and robustness of human programmers. We identify a significant distribution shift between model cognition and human expertise, with model errors tending to cluster due to training data biases and limited reasoning transfer. Our study demonstrates that incorporating human-generated editorials, solutions, and diverse test cases, as well as leveraging model mixtures, can substantially enhance both the performance and robustness of LLMs. Furthermore, we reveal both the consistency and inconsistency in the cognition of LLMs that may facilitate self-reflection and self-improvement, providing a potential direction for developing more powerful coding models.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.06138v1",
    "published_date": "2025-07-08 16:20:43 UTC",
    "updated_date": "2025-07-08 16:20:43 UTC"
  },
  {
    "arxiv_id": "2507.06137v1",
    "title": "NeoBabel: A Multilingual Open Tower for Visual Generation",
    "authors": [
      "Mohammad Mahdi Derakhshani",
      "Dheeraj Varghese",
      "Marzieh Fadaee",
      "Cees G. M. Snoek"
    ],
    "abstract": "Text-to-image generation advancements have been predominantly English-centric, creating barriers for non-English speakers and perpetuating digital inequities. While existing systems rely on translation pipelines, these introduce semantic drift, computational overhead, and cultural misalignment. We introduce NeoBabel, a novel multilingual image generation framework that sets a new Pareto frontier in performance, efficiency and inclusivity, supporting six languages: English, Chinese, Dutch, French, Hindi, and Persian. The model is trained using a combination of large-scale multilingual pretraining and high-resolution instruction tuning. To evaluate its capabilities, we expand two English-only benchmarks to multilingual equivalents: m-GenEval and m-DPG. NeoBabel achieves state-of-the-art multilingual performance while retaining strong English capability, scoring 0.75 on m-GenEval and 0.68 on m-DPG. Notably, it performs on par with leading models on English tasks while outperforming them by +0.11 and +0.09 on multilingual benchmarks, even though these models are built on multilingual base LLMs. This demonstrates the effectiveness of our targeted alignment training for preserving and extending crosslingual generalization. We further introduce two new metrics to rigorously assess multilingual alignment and robustness to code-mixed prompts. Notably, NeoBabel matches or exceeds English-only models while being 2-4x smaller. We release an open toolkit, including all code, model checkpoints, a curated dataset of 124M multilingual text-image pairs, and standardized multilingual evaluation protocols, to advance inclusive AI research. Our work demonstrates that multilingual capability is not a trade-off but a catalyst for improved robustness, efficiency, and cultural fidelity in generative AI.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CL",
    "comment": "34 pages, 12 figures",
    "pdf_url": "https://arxiv.org/pdf/2507.06137v1",
    "published_date": "2025-07-08 16:19:45 UTC",
    "updated_date": "2025-07-08 16:19:45 UTC"
  },
  {
    "arxiv_id": "2507.06134v1",
    "title": "OpenAgentSafety: A Comprehensive Framework for Evaluating Real-World AI Agent Safety",
    "authors": [
      "Sanidhya Vijayvargiya",
      "Aditya Bharat Soni",
      "Xuhui Zhou",
      "Zora Zhiruo Wang",
      "Nouha Dziri",
      "Graham Neubig",
      "Maarten Sap"
    ],
    "abstract": "Recent advances in AI agents capable of solving complex, everyday tasks, from scheduling to customer service, have enabled deployment in real-world settings, but their possibilities for unsafe behavior demands rigorous evaluation. While prior benchmarks have attempted to assess agent safety, most fall short by relying on simulated environments, narrow task domains, or unrealistic tool abstractions. We introduce OpenAgentSafety, a comprehensive and modular framework for evaluating agent behavior across eight critical risk categories. Unlike prior work, our framework evaluates agents that interact with real tools, including web browsers, code execution environments, file systems, bash shells, and messaging platforms; and supports over 350 multi-turn, multi-user tasks spanning both benign and adversarial user intents. OpenAgentSafety is designed for extensibility, allowing researchers to add tools, tasks, websites, and adversarial strategies with minimal effort. It combines rule-based analysis with LLM-as-judge assessments to detect both overt and subtle unsafe behaviors. Empirical analysis of five prominent LLMs in agentic scenarios reveals unsafe behavior in 51.2% of safety-vulnerable tasks with Claude-Sonnet-3.7, to 72.7% with o3-mini, highlighting critical safety vulnerabilities and the need for stronger safeguards before real-world deployment.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "19 pages, 10 figures",
    "pdf_url": "https://arxiv.org/pdf/2507.06134v1",
    "published_date": "2025-07-08 16:18:54 UTC",
    "updated_date": "2025-07-08 16:18:54 UTC"
  },
  {
    "arxiv_id": "2507.06127v1",
    "title": "PrefixAgent: An LLM-Powered Design Framework for Efficient Prefix Adder Optimization",
    "authors": [
      "Dongsheng Zuo",
      "Jiadong Zhu",
      "Yang Luo",
      "Yuzhe Ma"
    ],
    "abstract": "Prefix adders are fundamental arithmetic circuits, but their design space grows exponentially with bit-width, posing significant optimization challenges. Previous works face limitations in performance, generalization, and scalability. To address these challenges, we propose PrefixAgent, a large language model (LLM)-powered framework that enables efficient prefix adder optimization. Specifically, PrefixAgent reformulates the problem into subtasks including backbone synthesis and structure refinement, which effectively reduces the search space. More importantly, this new design perspective enables us to efficiently collect enormous high-quality data and reasoning traces with E-graph, which further results in an effective fine-tuning of LLM. Experimental results show that PrefixAgent synthesizes prefix adders with consistently smaller areas compared to baseline methods, while maintaining scalability and generalization in commercial EDA flows.",
    "categories": [
      "cs.AR",
      "cs.AI"
    ],
    "primary_category": "cs.AR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.06127v1",
    "published_date": "2025-07-08 16:14:17 UTC",
    "updated_date": "2025-07-08 16:14:17 UTC"
  },
  {
    "arxiv_id": "2507.06125v1",
    "title": "Subspace-based Approximate Hessian Method for Zeroth-Order Optimization",
    "authors": [
      "Dongyoon Kim",
      "Sungjae Lee",
      "Wonjin Lee",
      "Kwang In Kim"
    ],
    "abstract": "Zeroth-order optimization addresses problems where gradient information is inaccessible or impractical to compute. While most existing methods rely on first-order approximations, incorporating second-order (curvature) information can, in principle, significantly accelerate convergence. However, the high cost of function evaluations required to estimate Hessian matrices often limits practical applicability. We present the subspace-based approximate Hessian (ZO-SAH) method, a zeroth-order optimization algorithm that mitigates these costs by focusing on randomly selected two-dimensional subspaces. Within each subspace, ZO-SAH estimates the Hessian by fitting a quadratic polynomial to the objective function and extracting its second-order coefficients. To further reduce function-query costs, ZO-SAH employs a periodic subspace-switching strategy that reuses function evaluations across optimization steps. Experiments on eight benchmark datasets, including logistic regression and deep neural network training tasks, demonstrate that ZO-SAH achieves significantly faster convergence than existing zeroth-order methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "20 pages, 8 figures",
    "pdf_url": "https://arxiv.org/pdf/2507.06125v1",
    "published_date": "2025-07-08 16:11:53 UTC",
    "updated_date": "2025-07-08 16:11:53 UTC"
  },
  {
    "arxiv_id": "2507.06116v1",
    "title": "Speech Quality Assessment Model Based on Mixture of Experts: System-Level Performance Enhancement and Utterance-Level Challenge Analysis",
    "authors": [
      "Xintong Hu",
      "Yixuan Chen",
      "Rui Yang",
      "Wenxiang Guo",
      "Changhao Pan"
    ],
    "abstract": "Automatic speech quality assessment plays a crucial role in the development of speech synthesis systems, but existing models exhibit significant performance variations across different granularity levels of prediction tasks. This paper proposes an enhanced MOS prediction system based on self-supervised learning speech models, incorporating a Mixture of Experts (MoE) classification head and utilizing synthetic data from multiple commercial generation models for data augmentation. Our method builds upon existing self-supervised models such as wav2vec2, designing a specialized MoE architecture to address different types of speech quality assessment tasks. We also collected a large-scale synthetic speech dataset encompassing the latest text-to-speech, speech conversion, and speech enhancement systems. However, despite the adoption of the MoE architecture and expanded dataset, the model's performance improvements in sentence-level prediction tasks remain limited. Our work reveals the limitations of current methods in handling sentence-level quality assessment, provides new technical pathways for the field of automatic speech quality assessment, and also delves into the fundamental causes of performance differences across different assessment granularities.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.06116v1",
    "published_date": "2025-07-08 16:00:13 UTC",
    "updated_date": "2025-07-08 16:00:13 UTC"
  },
  {
    "arxiv_id": "2507.06109v1",
    "title": "LighthouseGS: Indoor Structure-aware 3D Gaussian Splatting for Panorama-Style Mobile Captures",
    "authors": [
      "Seungoh Han",
      "Jaehoon Jang",
      "Hyunsu Kim",
      "Jaeheung Surh",
      "Junhyung Kwak",
      "Hyowon Ha",
      "Kyungdon Joo"
    ],
    "abstract": "Recent advances in 3D Gaussian Splatting (3DGS) have enabled real-time novel view synthesis (NVS) with impressive quality in indoor scenes. However, achieving high-fidelity rendering requires meticulously captured images covering the entire scene, limiting accessibility for general users. We aim to develop a practical 3DGS-based NVS framework using simple panorama-style motion with a handheld camera (e.g., mobile device). While convenient, this rotation-dominant motion and narrow baseline make accurate camera pose and 3D point estimation challenging, especially in textureless indoor scenes. To address these challenges, we propose LighthouseGS, a novel framework inspired by the lighthouse-like sweeping motion of panoramic views. LighthouseGS leverages rough geometric priors, such as mobile device camera poses and monocular depth estimation, and utilizes the planar structures often found in indoor environments. We present a new initialization method called plane scaffold assembly to generate consistent 3D points on these structures, followed by a stable pruning strategy to enhance geometry and optimization stability. Additionally, we introduce geometric and photometric corrections to resolve inconsistencies from motion drift and auto-exposure in mobile devices. Tested on collected real and synthetic indoor scenes, LighthouseGS delivers photorealistic rendering, surpassing state-of-the-art methods and demonstrating the potential for panoramic view synthesis and object placement.",
    "categories": [
      "cs.GR",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.GR",
    "comment": "Preprint",
    "pdf_url": "https://arxiv.org/pdf/2507.06109v1",
    "published_date": "2025-07-08 15:49:53 UTC",
    "updated_date": "2025-07-08 15:49:53 UTC"
  },
  {
    "arxiv_id": "2507.06092v3",
    "title": "Taming Data Challenges in ML-based Security Tasks: Lessons from Integrating Generative AI",
    "authors": [
      "Shravya Kanchi",
      "Neal Mangaokar",
      "Aravind Cheruvu",
      "Sifat Muhammad Abdullah",
      "Shirin Nilizadeh",
      "Atul Prakash",
      "Bimal Viswanath"
    ],
    "abstract": "Machine learning-based supervised classifiers are widely used for security tasks, and their improvement has been largely focused on algorithmic advancements. We argue that data challenges that negatively impact the performance of these classifiers have received limited attention. We address the following research question: Can developments in Generative AI (GenAI) address these data challenges and improve classifier performance? We propose augmenting training datasets with synthetic data generated using GenAI techniques to improve classifier generalization. We evaluate this approach across 7 diverse security tasks using 6 state-of-the-art GenAI methods and introduce a novel GenAI scheme called Nimai that enables highly controlled data synthesis. We find that GenAI techniques can significantly improve the performance of security classifiers, achieving improvements of up to 32.6% even in severely data-constrained settings (only ~180 training samples). Furthermore, we demonstrate that GenAI can facilitate rapid adaptation to concept drift post-deployment, requiring minimal labeling in the adjustment process. Despite successes, our study finds that some GenAI schemes struggle to initialize (train and produce data) on certain security tasks. We also identify characteristics of specific tasks, such as noisy labels, overlapping class distributions, and sparse feature vectors, which hinder performance boost using GenAI. We believe that our study will drive the development of future GenAI tools designed for security tasks.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.06092v3",
    "published_date": "2025-07-08 15:34:45 UTC",
    "updated_date": "2025-12-29 15:43:45 UTC"
  },
  {
    "arxiv_id": "2507.06282v1",
    "title": "The bitter lesson of misuse detection",
    "authors": [
      "Hadrien Mariaccia",
      "Charbel-Raphaël Segerie",
      "Diego Dorn"
    ],
    "abstract": "Prior work on jailbreak detection has established the importance of adversarial robustness for LLMs but has largely focused on the model ability to resist adversarial inputs and to output safe content, rather than the effectiveness of external supervision systems. The only public and independent benchmark of these guardrails to date evaluates a narrow set of supervisors on limited scenarios. Consequently, no comprehensive public benchmark yet verifies how well supervision systems from the market perform under realistic, diverse attacks. To address this, we introduce BELLS, a Benchmark for the Evaluation of LLM Supervision Systems. The framework is two dimensional: harm severity (benign, borderline, harmful) and adversarial sophistication (direct vs. jailbreak) and provides a rich dataset covering 3 jailbreak families and 11 harm categories. Our evaluations reveal drastic limitations of specialized supervision systems. While they recognize some known jailbreak patterns, their semantic understanding and generalization capabilities are very limited, sometimes with detection rates close to zero when asking a harmful question directly or with a new jailbreak technique such as base64 encoding. Simply asking generalist LLMs if the user question is \"harmful or not\" largely outperforms these supervisors from the market according to our BELLS score. But frontier LLMs still suffer from metacognitive incoherence, often responding to queries they correctly identify as harmful (up to 30 percent for Claude 3.7 and greater than 50 percent for Mistral Large). These results suggest that simple scaffolding could significantly improve misuse detection robustness, but more research is needed to assess the tradeoffs of such techniques. Our results support the \"bitter lesson\" of misuse detection: general capabilities of LLMs are necessary to detect a diverse array of misuses and jailbreaks.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.06282v1",
    "published_date": "2025-07-08 15:21:17 UTC",
    "updated_date": "2025-07-08 15:21:17 UTC"
  },
  {
    "arxiv_id": "2507.06079v1",
    "title": "QS4D: Quantization-aware training for efficient hardware deployment of structured state-space sequential models",
    "authors": [
      "Sebastian Siegel",
      "Ming-Jay Yang",
      "Younes Bouhadjar",
      "Maxime Fabre",
      "Emre Neftci",
      "John Paul Strachan"
    ],
    "abstract": "Structured State Space models (SSM) have recently emerged as a new class of deep learning models, particularly well-suited for processing long sequences. Their constant memory footprint, in contrast to the linearly scaling memory demands of Transformers, makes them attractive candidates for deployment on resource-constrained edge-computing devices. While recent works have explored the effect of quantization-aware training (QAT) on SSMs, they typically do not address its implications for specialized edge hardware, for example, analog in-memory computing (AIMC) chips. In this work, we demonstrate that QAT can significantly reduce the complexity of SSMs by up to two orders of magnitude across various performance metrics. We analyze the relation between model size and numerical precision, and show that QAT enhances robustness to analog noise and enables structural pruning. Finally, we integrate these techniques to deploy SSMs on a memristive analog in-memory computing substrate and highlight the resulting benefits in terms of computational efficiency.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.06079v1",
    "published_date": "2025-07-08 15:19:14 UTC",
    "updated_date": "2025-07-08 15:19:14 UTC"
  },
  {
    "arxiv_id": "2507.06077v1",
    "title": "AI-Based Demand Forecasting and Load Balancing for Optimising Energy use in Healthcare Systems: A real case study",
    "authors": [
      "Iman Rahimi",
      "Isha Patel"
    ],
    "abstract": "This paper tackles the urgent need for efficient energy management in healthcare facilities, where fluctuating demands challenge operational efficiency and sustainability. Traditional methods often prove inadequate, causing inefficiencies and higher costs. To address this, the study presents an AI-based framework combining Long Short-Term Memory (LSTM), genetic algorithm (GA), and SHAP (Shapley Additive Explanations), specifically designed for healthcare energy management. Although LSTM is widely used for time-series forecasting, its application in healthcare energy prediction remains underexplored. The results reveal that LSTM significantly outperforms ARIMA and Prophet models in forecasting complex, non-linear demand patterns. LSTM achieves a Mean Absolute Error (MAE) of 21.69 and Root Mean Square Error (RMSE) of 29.96, far better than Prophet (MAE: 59.78, RMSE: 81.22) and ARIMA (MAE: 87.73, RMSE: 125.22), demonstrating superior performance. The genetic algorithm is applied to optimize model parameters and improve load balancing strategies, enabling adaptive responses to real-time energy fluctuations. SHAP analysis further enhances model transparency by explaining the influence of different features on predictions, fostering trust in decision-making processes. This integrated LSTM-GA-SHAP approach offers a robust solution for improving forecasting accuracy, boosting energy efficiency, and advancing sustainability in healthcare facilities. Future research may explore real-time deployment and hybridization with reinforcement learning for continuous optimization. Overall, the study establishes a solid foundation for using AI in healthcare energy management, highlighting its scalability, efficiency, and resilience potential.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.06077v1",
    "published_date": "2025-07-08 15:16:50 UTC",
    "updated_date": "2025-07-08 15:16:50 UTC"
  },
  {
    "arxiv_id": "2507.06070v1",
    "title": "Contrastive and Transfer Learning for Effective Audio Fingerprinting through a Real-World Evaluation Protocol",
    "authors": [
      "Christos Nikou",
      "Theodoros Giannakopoulos"
    ],
    "abstract": "Recent advances in song identification leverage deep neural networks to learn compact audio fingerprints directly from raw waveforms. While these methods perform well under controlled conditions, their accuracy drops significantly in real-world scenarios where the audio is captured via mobile devices in noisy environments. In this paper, we introduce a novel evaluation protocol designed to better reflect such real-world conditions. We generate three recordings of the same audio, each with increasing levels of noise, captured using a mobile device's microphone. Our results reveal a substantial performance drop for two state-of-the-art CNN-based models under this protocol, compared to previously reported benchmarks. Additionally, we highlight the critical role of the augmentation pipeline during training with contrastive loss. By introduction low pass and high pass filters in the augmentation pipeline we significantly increase the performance of both systems in our proposed evaluation. Furthermore, we develop a transformer-based model with a tailored projection module and demonstrate that transferring knowledge from a semantically relevant domain yields a more robust solution. The transformer architecture outperforms CNN-based models across all noise levels, and query durations. In low noise conditions it achieves 47.99% for 1-sec queries, and 97% for 10-sec queries in finding the correct song, surpassing by 14%, and by 18.5% the second-best performing model, respectively, Under heavy noise levels, we achieve a detection rate 56.5% for 15-second query duration. All experiments are conducted on public large-scale dataset of over 100K songs, with queries matched against a database of 56 million vectors.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.IR",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "International Journal of Music Science, Technology and Art, 15 pages, 7 figures",
    "pdf_url": "https://arxiv.org/pdf/2507.06070v1",
    "published_date": "2025-07-08 15:13:26 UTC",
    "updated_date": "2025-07-08 15:13:26 UTC"
  },
  {
    "arxiv_id": "2507.06067v1",
    "title": "Enhancing Synthetic CT from CBCT via Multimodal Fusion and End-To-End Registration",
    "authors": [
      "Maximilian Tschuchnig",
      "Lukas Lamminger",
      "Philipp Steininger",
      "Michael Gadermayr"
    ],
    "abstract": "Cone-Beam Computed Tomography (CBCT) is widely used for intraoperative imaging due to its rapid acquisition and low radiation dose. However, CBCT images typically suffer from artifacts and lower visual quality compared to conventional Computed Tomography (CT). A promising solution is synthetic CT (sCT) generation, where CBCT volumes are translated into the CT domain. In this work, we enhance sCT generation through multimodal learning by jointly leveraging intraoperative CBCT and preoperative CT data. To overcome the inherent misalignment between modalities, we introduce an end-to-end learnable registration module within the sCT pipeline. This model is evaluated on a controlled synthetic dataset, allowing precise manipulation of data quality and alignment parameters. Further, we validate its robustness and generalizability on two real-world clinical datasets. Experimental results demonstrate that integrating registration in multimodal sCT generation improves sCT quality, outperforming baseline multimodal methods in 79 out of 90 evaluation settings. Notably, the improvement is most significant in cases where CBCT quality is low and the preoperative CT is moderately misaligned.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "Accepted at CAIP 2025. arXiv admin note: substantial text overlap with arXiv:2506.08716",
    "pdf_url": "https://arxiv.org/pdf/2507.06067v1",
    "published_date": "2025-07-08 15:10:04 UTC",
    "updated_date": "2025-07-08 15:10:04 UTC"
  },
  {
    "arxiv_id": "2507.06060v2",
    "title": "VisualSpeaker: Visually-Guided 3D Avatar Lip Synthesis",
    "authors": [
      "Alexandre Symeonidis-Herzig",
      "Özge Mercanoğlu Sincan",
      "Richard Bowden"
    ],
    "abstract": "Realistic, high-fidelity 3D facial animations are crucial for expressive avatar systems in human-computer interaction and accessibility. Although prior methods show promising quality, their reliance on the mesh domain limits their ability to fully leverage the rapid visual innovations seen in 2D computer vision and graphics. We propose VisualSpeaker, a novel method that bridges this gap using photorealistic differentiable rendering, supervised by visual speech recognition, for improved 3D facial animation. Our contribution is a perceptual lip-reading loss, derived by passing photorealistic 3D Gaussian Splatting avatar renders through a pre-trained Visual Automatic Speech Recognition model during training. Evaluation on the MEAD dataset demonstrates that VisualSpeaker improves both the standard Lip Vertex Error metric by 56.1% and the perceptual quality of the generated animations, while retaining the controllability of mesh-driven animation. This perceptual focus naturally supports accurate mouthings, essential cues that disambiguate similar manual signs in sign language avatars.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted in International Conference on Computer Vision (ICCV) Workshops",
    "pdf_url": "https://arxiv.org/pdf/2507.06060v2",
    "published_date": "2025-07-08 15:04:17 UTC",
    "updated_date": "2025-07-21 13:19:17 UTC"
  },
  {
    "arxiv_id": "2507.08848v1",
    "title": "Assuring the Safety of Reinforcement Learning Components: AMLAS-RL",
    "authors": [
      "Calum Corrie Imrie",
      "Ioannis Stefanakos",
      "Sepeedeh Shahbeigi",
      "Richard Hawkins",
      "Simon Burton"
    ],
    "abstract": "The rapid advancement of machine learning (ML) has led to its increasing integration into cyber-physical systems (CPS) across diverse domains. While CPS offer powerful capabilities, incorporating ML components introduces significant safety and assurance challenges. Among ML techniques, reinforcement learning (RL) is particularly suited for CPS due to its capacity to handle complex, dynamic environments where explicit models of interaction between system and environment are unavailable or difficult to construct. However, in safety-critical applications, this learning process must not only be effective but demonstrably safe. Safe-RL methods aim to address this by incorporating safety constraints during learning, yet they fall short in providing systematic assurance across the RL lifecycle. The AMLAS methodology offers structured guidance for assuring the safety of supervised learning components, but it does not directly apply to the unique challenges posed by RL. In this paper, we adapt AMLAS to provide a framework for generating assurance arguments for an RL-enabled system through an iterative process; AMLAS-RL. We demonstrate AMLAS-RL using a running example of a wheeled vehicle tasked with reaching a target goal without collision.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO",
      "cs.SE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.08848v1",
    "published_date": "2025-07-08 15:01:51 UTC",
    "updated_date": "2025-07-08 15:01:51 UTC"
  },
  {
    "arxiv_id": "2507.06057v2",
    "title": "FEVO: Financial Knowledge Expansion and Reasoning Evolution for Large Language Models",
    "authors": [
      "Bo Pang",
      "Yalu Ouyang",
      "Hangfei Xu",
      "Ziqi Jia",
      "Panpan Li",
      "Shengzhao Wen",
      "Lu Wang",
      "Shiyong Li",
      "Yanpeng Wang"
    ],
    "abstract": "Advancements in reasoning for large language models (LLMs) have lead to significant performance improvements for LLMs in various fields such as mathematics and programming. However, research applying these advances to the financial domain, where considerable domain-specific knowledge is necessary to complete tasks, remains limited. To address this gap, we introduce FEVO (Financial Evolution), a multi-stage enhancement framework developed to enhance LLM performance in the financial domain. FEVO systemically enhances LLM performance by using continued pre-training (CPT) to expand financial domain knowledge, supervised fine-tuning (SFT) to instill structured, elaborate reasoning patterns, and reinforcement learning (RL) to further integrate the expanded financial domain knowledge with the learned structured reasoning. To ensure effective and efficient training, we leverage frontier reasoning models and rule-based filtering to curate FEVO-Train, high-quality datasets specifically designed for the different post-training phases. Using our framework, we train the FEVO series of models - C32B, S32B, R32B - from Qwen2.5-32B and evaluate them on seven benchmarks to assess financial and general capabilities, with results showing that FEVO-R32B achieves state-of-the-art performance on five financial benchmarks against much larger models as well as specialist models. More significantly, FEVO-R32B demonstrates markedly better performance than FEVO-R32B-0 (trained from Qwen2.5-32B-Instruct using only RL), thus validating the effectiveness of financial domain knowledge expansion and structured, logical reasoning distillation",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.06057v2",
    "published_date": "2025-07-08 14:59:46 UTC",
    "updated_date": "2025-07-09 07:06:36 UTC"
  },
  {
    "arxiv_id": "2507.06056v3",
    "title": "Entropy-Memorization Law: Evaluating Memorization Difficulty of Data in LLMs",
    "authors": [
      "Yizhan Huang",
      "Zhe Yang",
      "Meifang Chen",
      "Huang Nianchen",
      "Jianping Zhang",
      "Michael R. Lyu"
    ],
    "abstract": "Large Language Models (LLMs) are known to memorize portions of their training data, sometimes reproducing content verbatim when prompted appropriately. In this work, we investigate a fundamental yet under-explored question in the domain of memorization: How to characterize memorization difficulty of training data in LLMs? Through empirical experiments on OLMo, a family of open models, we present the Entropy-Memorization Law. It suggests that data entropy is linearly correlated with memorization score. Moreover, in a case study of memorizing highly randomized strings, or \"gibberish\", we observe that such sequences, despite their apparent randomness, exhibit unexpectedly low empirical entropy compared to the broader training corpus. Adopting the same strategy to discover Entropy-Memorization Law, we derive a simple yet effective approach to distinguish training and testing data, enabling Dataset Inference (DI).",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.06056v3",
    "published_date": "2025-07-08 14:58:28 UTC",
    "updated_date": "2025-09-27 10:00:09 UTC"
  },
  {
    "arxiv_id": "2507.06043v2",
    "title": "CAVGAN: Unifying Jailbreak and Defense of LLMs via Generative Adversarial Attacks on their Internal Representations",
    "authors": [
      "Xiaohu Li",
      "Yunfeng Ning",
      "Zepeng Bao",
      "Mayi Xu",
      "Jianhao Chen",
      "Tieyun Qian"
    ],
    "abstract": "Security alignment enables the Large Language Model (LLM) to gain the protection against malicious queries, but various jailbreak attack methods reveal the vulnerability of this security mechanism. Previous studies have isolated LLM jailbreak attacks and defenses. We analyze the security protection mechanism of the LLM, and propose a framework that combines attack and defense. Our method is based on the linearly separable property of LLM intermediate layer embedding, as well as the essence of jailbreak attack, which aims to embed harmful problems and transfer them to the safe area. We utilize generative adversarial network (GAN) to learn the security judgment boundary inside the LLM to achieve efficient jailbreak attack and defense. The experimental results indicate that our method achieves an average jailbreak success rate of 88.85\\% across three popular LLMs, while the defense success rate on the state-of-the-art jailbreak dataset reaches an average of 84.17\\%. This not only validates the effectiveness of our approach but also sheds light on the internal security mechanisms of LLMs, offering new insights for enhancing model security The code and data are available at https://github.com/NLPGM/CAVGAN.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "Accepted to ACL 2025 (Findings), camera-ready version",
    "pdf_url": "https://arxiv.org/pdf/2507.06043v2",
    "published_date": "2025-07-08 14:45:21 UTC",
    "updated_date": "2025-08-06 05:32:54 UTC"
  },
  {
    "arxiv_id": "2507.06042v1",
    "title": "On Lockean beliefs that are deductively closed and minimal change",
    "authors": [
      "Tommaso Flaminio",
      "Lluis Godo",
      "Ramón Pino Pérez",
      "Lluis Subirana"
    ],
    "abstract": "Within the formal setting of the Lockean thesis, an agent belief set is defined in terms of degrees of confidence and these are described in probabilistic terms. This approach is of established interest, notwithstanding some limitations that make its use troublesome in some contexts, like, for instance, in belief change theory. Precisely, Lockean belief sets are not generally closed under (classical) logical deduction. The aim of the present paper is twofold: on one side we provide two characterizations of those belief sets that are closed under classical logic deduction, and on the other we propose an approach to probabilistic update that allows us for a minimal revision of those beliefs, i.e., a revision obtained by making the fewest possible changes to the existing belief set while still accommodating the new information. In particular, we show how we can deductively close a belief set via a minimal revision.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "18 pages, to appear in the proceedings of JELIA 2025",
    "pdf_url": "https://arxiv.org/pdf/2507.06042v1",
    "published_date": "2025-07-08 14:44:01 UTC",
    "updated_date": "2025-07-08 14:44:01 UTC"
  },
  {
    "arxiv_id": "2507.06033v1",
    "title": "TextPixs: Glyph-Conditioned Diffusion with Character-Aware Attention and OCR-Guided Supervision",
    "authors": [
      "Syeda Anshrah Gillani",
      "Mirza Samad Ahmed Baig",
      "Osama Ahmed Khan",
      "Shahid Munir Shah",
      "Umema Mujeeb",
      "Maheen Ali"
    ],
    "abstract": "The modern text-to-image diffusion models boom has opened a new era in digital content production as it has proven the previously unseen ability to produce photorealistic and stylistically diverse imagery based on the semantics of natural-language descriptions. However, the consistent disadvantage of these models is that they cannot generate readable, meaningful, and correctly spelled text in generated images, which significantly limits the use of practical purposes like advertising, learning, and creative design. This paper introduces a new framework, namely Glyph-Conditioned Diffusion with Character-Aware Attention (GCDA), using which a typical diffusion backbone is extended by three well-designed modules. To begin with, the model has a dual-stream text encoder that encodes both semantic contextual information and explicit glyph representations, resulting in a character-aware representation of the input text that is rich in nature. Second, an attention mechanism that is aware of the character is proposed with a new attention segregation loss that aims to limit the attention distribution of each character independently in order to avoid distortion artifacts. Lastly, GCDA has an OCR-in-the-loop fine-tuning phase, where a full text perceptual loss, directly optimises models to be legible and accurately spell. Large scale experiments to benchmark datasets, such as MARIO-10M and T2I-CompBench, reveal that GCDA sets a new state-of-the-art on all metrics, with better character based metrics on text rendering (Character Error Rate: 0.08 vs 0.21 for the previous best; Word Error Rate: 0.15 vs 0.25), human perception, and comparable image synthesis quality on high-fidelity (FID: 14.3).",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "30 pages",
    "pdf_url": "https://arxiv.org/pdf/2507.06033v1",
    "published_date": "2025-07-08 14:35:02 UTC",
    "updated_date": "2025-07-08 14:35:02 UTC"
  },
  {
    "arxiv_id": "2507.06031v1",
    "title": "Efficient Federated Learning with Timely Update Dissemination",
    "authors": [
      "Juncheng Jia",
      "Ji Liu",
      "Chao Huo",
      "Yihui Shen",
      "Yang Zhou",
      "Huaiyu Dai",
      "Dejing Dou"
    ],
    "abstract": "Federated Learning (FL) has emerged as a compelling methodology for the management of distributed data, marked by significant advancements in recent years. In this paper, we propose an efficient FL approach that capitalizes on additional downlink bandwidth resources to ensure timely update dissemination. Initially, we implement this strategy within an asynchronous framework, introducing the Asynchronous Staleness-aware Model Update (FedASMU), which integrates both server-side and device-side methodologies. On the server side, we present an asynchronous FL system model that employs a dynamic model aggregation technique, which harmonizes local model updates with the global model to enhance both accuracy and efficiency. Concurrently, on the device side, we propose an adaptive model adjustment mechanism that integrates the latest global model with local models during training to further elevate accuracy. Subsequently, we extend this approach to a synchronous context, referred to as FedSSMU. Theoretical analyses substantiate the convergence of our proposed methodologies. Extensive experiments, encompassing six models and five public datasets, demonstrate that FedASMU and FedSSMU significantly surpass baseline methods in terms of both accuracy (up to 145.87%) and efficiency (up to 97.59%).",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.DC",
    "comment": "38 pages, to appear in Knowledge and Information Systems (KAIS)",
    "pdf_url": "https://arxiv.org/pdf/2507.06031v1",
    "published_date": "2025-07-08 14:34:32 UTC",
    "updated_date": "2025-07-08 14:34:32 UTC"
  },
  {
    "arxiv_id": "2507.06029v2",
    "title": "Feature-Guided Neighbor Selection for Non-Expert Evaluation of Model Predictions",
    "authors": [
      "Courtney Ford",
      "Mark T. Keane"
    ],
    "abstract": "Explainable AI (XAI) methods often struggle to generate clear, interpretable outputs for users without domain expertise. We introduce Feature-Guided Neighbor Selection (FGNS), a post hoc method that enhances interpretability by selecting class-representative examples using both local and global feature importance. In a user study (N = 98) evaluating Kannada script classifications, FGNS significantly improved non-experts' ability to identify model errors while maintaining appropriate agreement with correct predictions. Participants made faster and more accurate decisions compared to those given traditional k-NN explanations. Quantitative analysis shows that FGNS selects neighbors that better reflect class characteristics rather than merely minimizing feature-space distance, leading to more consistent selection and tighter clustering around class prototypes. These results support FGNS as a step toward more human-aligned model assessment, although further work is needed to address the gap between explanation quality and perceived trust.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "7 pages, 5 figures, 1 table. Accepted at IJCAI 2025 Workshop on User-Aligned Assessment of Adaptive AI Systems",
    "pdf_url": "https://arxiv.org/pdf/2507.06029v2",
    "published_date": "2025-07-08 14:32:25 UTC",
    "updated_date": "2025-08-26 15:33:51 UTC"
  },
  {
    "arxiv_id": "2507.06013v1",
    "title": "CogniSQL-R1-Zero: Lightweight Reinforced Reasoning for Efficient SQL Generation",
    "authors": [
      "Kushal Gajjar",
      "Harshit Sikchi",
      "Arpit Singh Gautam",
      "Marc Hammons",
      "Saurabh Jha"
    ],
    "abstract": "Translating natural language into SQL (Text-to-SQL) remains a core challenge at the intersection of language understanding and structured data access. Although large language models (LLMs) have improved fluency, generating correct and executable SQL, especially for complex queries, continues to be challenging. We introduce CogniSQL-R1-Zero, a reinforcement learning (RL) framework and model that produces accurate SQL using a lightweight reward signal based on execution correctness and format-tag compliance. By avoiding intermediate supervision, hybrid pipelines and complex reward shaping, our method encourages stable learning and stronger alignment with the ultimate task objective-producing executable programs. CogniSQL-R1-Zero achieves state-of-the-art execution accuracy on Text2SQL benchmark; BIRD bench, outperforming prior supervised and instruction-tuned baselines including SFT CodeS-7B, DeepSeek-Coder 236B, and Mistral 123B-despite being trained on a significantly smaller 7B backbone. This result underscores the scalability and efficiency of our RL-based approach when trained on just four NVIDIA A100 GPUs (40 GB VRAM each). To support further research in efficient and interpretable Text-to-SQL modeling, we release two curated datasets: (i) a collection of 5,024 reasoning traces with varying context lengths, and (ii) a positive-sampled corpus of 36,356 corpus of weakly supervised queries, each annotated with six semantically diverse reasoning paths. Together, these contributions advance scalable, execution-aligned Text-to-SQL generation.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.06013v1",
    "published_date": "2025-07-08 14:17:07 UTC",
    "updated_date": "2025-07-08 14:17:07 UTC"
  },
  {
    "arxiv_id": "2507.06008v1",
    "title": "The Impact of Event Data Partitioning on Privacy-aware Process Discovery",
    "authors": [
      "Jungeun Lim",
      "Stephan A. Fahrenkrog-Petersen",
      "Xixi Lu",
      "Jan Mendling",
      "Minseok Song"
    ],
    "abstract": "Information systems support the execution of business processes. The event logs of these executions generally contain sensitive information about customers, patients, and employees. The corresponding privacy challenges can be addressed by anonymizing the event logs while still retaining utility for process discovery. However, trading off utility and privacy is difficult: the higher the complexity of event log, the higher the loss of utility by anonymization. In this work, we propose a pipeline that combines anonymization and event data partitioning, where event abstraction is utilized for partitioning. By leveraging event abstraction, event logs can be segmented into multiple parts, allowing each sub-log to be anonymized separately. This pipeline preserves privacy while mitigating the loss of utility. To validate our approach, we study the impact of event partitioning on two anonymization techniques using three real-world event logs and two process discovery techniques. Our results demonstrate that event partitioning can bring improvements in process discovery utility for directly-follows-based anonymization techniques.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.DB"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.06008v1",
    "published_date": "2025-07-08 14:13:44 UTC",
    "updated_date": "2025-07-08 14:13:44 UTC"
  },
  {
    "arxiv_id": "2507.05999v4",
    "title": "Geo-Registration of Terrestrial LiDAR Point Clouds with Satellite Images without GNSS",
    "authors": [
      "Xinyu Wang",
      "Muhammad Ibrahim",
      "Haitian Wang",
      "Atif Mansoor",
      "Xiuping Jia",
      "Ajmal Mian"
    ],
    "abstract": "Accurate geo-registration of LiDAR point clouds remains a significant challenge in urban environments where Global Navigation Satellite System (GNSS) signals are denied or degraded. Existing methods typically rely on real-time GNSS and Inertial Measurement Unit (IMU) data, which require pre-calibration and assume stable signals. However, this assumption often fails in dense cities, resulting in localization errors. To address this, we propose a structured post-hoc geo-registration method that accurately aligns LiDAR point clouds with satellite images. The proposed approach targets point cloud datasets where reliable GNSS information is unavailable or degraded, enabling city-scale geo-registration as a post-processing solution. Our method uses a pre-trained Point Transformer to segment road points, then extracts road skeletons and intersections from the point cloud and the satellite image. Global alignment is achieved through rigid transformation using corresponding intersection points, followed by local non-rigid refinement with radial basis function (RBF) interpolation. Elevation discrepancies are corrected using terrain data from the Shuttle Radar Topography Mission (SRTM). To evaluate geo-registration accuracy, we measure the absolute distances between the roads extracted from the two modalities. Our method is validated on the KITTI benchmark and a newly collected dataset of Perth, Western Australia. On KITTI, our method achieves a mean planimetric alignment error of 0.69m, corresponding to a 50% reduction in global geo-registration bias compared to the raw KITTI annotations. On Perth dataset, it achieves a mean planimetric error of 2.17m from GNSS values extracted from Google Maps, corresponding to 57.4% improvement over rigid alignment. Elevation correlation factor improved by 30.5% (KITTI) and 55.8% (Perth).",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Submitted to IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing. Under reviewing now",
    "pdf_url": "https://arxiv.org/pdf/2507.05999v4",
    "published_date": "2025-07-08 14:00:18 UTC",
    "updated_date": "2026-01-21 04:57:12 UTC"
  },
  {
    "arxiv_id": "2507.05992v1",
    "title": "Exploring Partial Multi-Label Learning via Integrating Semantic Co-occurrence Knowledge",
    "authors": [
      "Xin Wu",
      "Fei Teng",
      "Yue Feng",
      "Kaibo Shi",
      "Zhuosheng Lin",
      "Ji Zhang",
      "James Wang"
    ],
    "abstract": "Partial multi-label learning aims to extract knowledge from incompletely annotated data, which includes known correct labels, known incorrect labels, and unknown labels. The core challenge lies in accurately identifying the ambiguous relationships between labels and instances. In this paper, we emphasize that matching co-occurrence patterns between labels and instances is key to addressing this challenge. To this end, we propose Semantic Co-occurrence Insight Network (SCINet), a novel and effective framework for partial multi-label learning. Specifically, SCINet introduces a bi-dominant prompter module, which leverages an off-the-shelf multimodal model to capture text-image correlations and enhance semantic alignment. To reinforce instance-label interdependencies, we develop a cross-modality fusion module that jointly models inter-label correlations, inter-instance relationships, and co-occurrence patterns across instance-label assignments. Moreover, we propose an intrinsic semantic augmentation strategy that enhances the model's understanding of intrinsic data semantics by applying diverse image transformations, thereby fostering a synergistic relationship between label confidence and sample difficulty. Extensive experiments on four widely-used benchmark datasets demonstrate that SCINet surpasses state-of-the-art methods.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "14 pages, 10 figures, Under Review",
    "pdf_url": "https://arxiv.org/pdf/2507.05992v1",
    "published_date": "2025-07-08 13:53:28 UTC",
    "updated_date": "2025-07-08 13:53:28 UTC"
  },
  {
    "arxiv_id": "2507.06278v1",
    "title": "A Survey of Multi Agent Reinforcement Learning: Federated Learning and Cooperative and Noncooperative Decentralized Regimes",
    "authors": [
      "Kemboi Cheruiyot",
      "Nickson Kiprotich",
      "Vyacheslav Kungurtsev",
      "Kennedy Mugo",
      "Vivian Mwirigi",
      "Marvin Ngesa"
    ],
    "abstract": "The increasing interest in research and innovation towards the development of autonomous agents presents a number of complex yet important scenarios of multiple AI Agents interacting with each other in an environment. The particular setting can be understood as exhibiting three possibly topologies of interaction - centrally coordinated cooperation, ad-hoc interaction and cooperation, and settings with noncooperative incentive structures. This article presents a comprehensive survey of all three domains, defined under the formalism of Federal Reinforcement Learning (RL), Decentralized RL, and Noncooperative RL, respectively. Highlighting the structural similarities and distinctions, we review the state of the art in these subjects, primarily explored and developed only recently in the literature. We include the formulations as well as known theoretical guarantees and highlights and limitations of numerical performance.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.MA",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.06278v1",
    "published_date": "2025-07-08 13:47:40 UTC",
    "updated_date": "2025-07-08 13:47:40 UTC"
  },
  {
    "arxiv_id": "2507.05984v2",
    "title": "Development and Evaluation of HopeBot: an LLM-based chatbot for structured and interactive PHQ-9 depression screening",
    "authors": [
      "Zhijun Guo",
      "Alvina Lai",
      "Julia Ive",
      "Alexandru Petcu",
      "Yutong Wang",
      "Luyuan Qi",
      "Johan H Thygesen",
      "Kezhi Li"
    ],
    "abstract": "Static tools like the Patient Health Questionnaire-9 (PHQ-9) effectively screen depression but lack interactivity and adaptability. We developed HopeBot, a chatbot powered by a large language model (LLM) that administers the PHQ-9 using retrieval-augmented generation and real-time clarification. In a within-subject study, 132 adults in the United Kingdom and China completed both self-administered and chatbot versions. Scores demonstrated strong agreement (ICC = 0.91; 45% identical). Among 75 participants providing comparative feedback, 71% reported greater trust in the chatbot, highlighting clearer structure, interpretive guidance, and a supportive tone. Mean ratings (0-10) were 8.4 for comfort, 7.7 for voice clarity, 7.6 for handling sensitive topics, and 7.4 for recommendation helpfulness; the latter varied significantly by employment status and prior mental-health service use (p < 0.05). Overall, 87.1% expressed willingness to reuse or recommend HopeBot. These findings demonstrate voice-based LLM chatbots can feasibly serve as scalable, low-burden adjuncts for routine depression screening.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.05984v2",
    "published_date": "2025-07-08 13:41:22 UTC",
    "updated_date": "2026-01-14 14:03:49 UTC"
  },
  {
    "arxiv_id": "2507.05976v1",
    "title": "Enhancing the Interpretability of Rule-based Explanations through Information Retrieval",
    "authors": [
      "Alessandro Umbrico",
      "Guido Bologna",
      "Luca Coraci",
      "Francesca Fracasso",
      "Silvia Gola",
      "Gabriella Cortellessa"
    ],
    "abstract": "The lack of transparency of data-driven Artificial Intelligence techniques limits their interpretability and acceptance into healthcare decision-making processes. We propose an attribution-based approach to improve the interpretability of Explainable AI-based predictions in the specific context of arm lymphedema's risk assessment after lymph nodal radiotherapy in breast cancer. The proposed method performs a statistical analysis of the attributes in the rule-based prediction model using standard metrics from Information Retrieval techniques. This analysis computes the relevance of each attribute to the prediction and provides users with interpretable information about the impact of risk factors. The results of a user study that compared the output generated by the proposed approach with the raw output of the Explainable AI model suggested higher levels of interpretability and usefulness in the context of predicting lymphedema risk.",
    "categories": [
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.05976v1",
    "published_date": "2025-07-08 13:32:50 UTC",
    "updated_date": "2025-07-08 13:32:50 UTC"
  },
  {
    "arxiv_id": "2507.05966v1",
    "title": "Simple Convergence Proof of Adam From a Sign-like Descent Perspective",
    "authors": [
      "Hanyang Peng",
      "Shuang Qin",
      "Yue Yu",
      "Fangqing Jiang",
      "Hui Wang",
      "Zhouchen Lin"
    ],
    "abstract": "Adam is widely recognized as one of the most effective optimizers for training deep neural networks (DNNs). Despite its remarkable empirical success, its theoretical convergence analysis remains unsatisfactory. Existing works predominantly interpret Adam as a preconditioned stochastic gradient descent with momentum (SGDM), formulated as $\\bm{x}_{t+1} = \\bm{x}_t - \\frac{γ_t}{{\\sqrt{\\bm{v}_t}+ε}} \\circ \\bm{m}_t$. This perspective necessitates strong assumptions and intricate techniques, resulting in lengthy and opaque convergence proofs that are difficult to verify and extend. In contrast, we propose a novel interpretation by treating Adam as a sign-like optimizer, expressed as $\\bm{x}_{t+1} = \\bm{x}_t - γ_t \\frac{|\\bm{m}_t|}{{\\sqrt{\\bm{v}_t}+ε}} \\circ {\\rm Sign}(\\bm{m}_t)$. This reformulation significantly simplifies the convergence analysis. For the first time, with some mild conditions, we prove that Adam achieves the optimal rate of ${\\cal O}(\\frac{1}{T^{\\sfrac{1}{4}}})$ rather than the previous ${\\cal O} \\left(\\frac{\\ln T}{T^{\\sfrac{1}{4}}}\\right)$ under weak assumptions of the generalized $p$-affine variance and $(L_0, L_1, q)$-smoothness, without dependence on the model dimensionality or the numerical stability parameter $ε$. Additionally, our theoretical analysis provides new insights into the role of momentum as a key factor ensuring convergence and offers practical guidelines for tuning learning rates in Adam, further bridging the gap between theory and practice.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IT"
    ],
    "primary_category": "cs.LG",
    "comment": "23 pages, 2figures",
    "pdf_url": "https://arxiv.org/pdf/2507.05966v1",
    "published_date": "2025-07-08 13:19:26 UTC",
    "updated_date": "2025-07-08 13:19:26 UTC"
  },
  {
    "arxiv_id": "2507.05965v1",
    "title": "OpenFActScore: Open-Source Atomic Evaluation of Factuality in Text Generation",
    "authors": [
      "Lucas Fonseca Lage",
      "Simon Ostermann"
    ],
    "abstract": "We introduce OpenFActScore, an open-source implementation of the FActScore framework for evaluating the factuality of text generated by large language models (LLMs). FActScore evaluates the factual accuracy of long-form text by using Atomic Fact Generation (AFG) to extract individual factual claims and Atomic Fact Validation (AFV) to verify each claim against a trusted knowledge source. While the original FActScore relies on closed-source and commercial models such as InstructGPT and ChatGPT, OpenFActScore enables the use of any Hugging Face-compatible model for both AFG and AFV. We provide a detailed technical overview of our implementation, highlighting design choices and modifications made to support open models. We evaluate multiple open-source LLMs on both AFG and AFV using the original FActScore benchmark, reporting BERTScore-F1 for AFG and Error Rate relative to human annotations for AFV. Our results show that open models can approximate the performance of closed-source systems, with Gemma achieving the best overall performance, and our final setup obtains a 0.99 Pearson correlation with the original FActScore experiments. OpenFActScore promotes transparency, reproducibility, and cost-effective evaluation, and is available at: https://github.com/lflage/OpenFActScore.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Submitted to EMNLP 2025 System Demonstrations track",
    "pdf_url": "https://arxiv.org/pdf/2507.05965v1",
    "published_date": "2025-07-08 13:19:00 UTC",
    "updated_date": "2025-07-08 13:19:00 UTC"
  },
  {
    "arxiv_id": "2507.07058v1",
    "title": "Comparative Analysis of CNN and Transformer Architectures with Heart Cycle Normalization for Automated Phonocardiogram Classification",
    "authors": [
      "Martin Sondermann",
      "Pinar Bisgin",
      "Niklas Tschorn",
      "Anja Burmann",
      "Christoph M. Friedrich"
    ],
    "abstract": "The automated classification of phonocardiogram (PCG) recordings represents a substantial advancement in cardiovascular diagnostics. This paper presents a systematic comparison of four distinct models for heart murmur detection: two specialized convolutional neural networks (CNNs) and two zero-shot universal audio transformers (BEATs), evaluated using fixed-length and heart cycle normalization approaches. Utilizing the PhysioNet2022 dataset, a custom heart cycle normalization method tailored to individual cardiac rhythms is introduced. The findings indicate the following AUROC values: the CNN model with fixed-length windowing achieves 79.5%, the CNN model with heart cycle normalization scores 75.4%, the BEATs transformer with fixed-length windowing achieves 65.7%, and the BEATs transformer with heart cycle normalization results in 70.1%.\n  The findings indicate that physiological signal constraints, especially those introduced by different normalization strategies, have a substantial impact on model performance. The research provides evidence-based guidelines for architecture selection in clinical settings, emphasizing the need for a balance between accuracy and computational efficiency. Although specialized CNNs demonstrate superior performance overall, the zero-shot transformer models may offer promising efficiency advantages during development, such as faster training and evaluation cycles, despite their lower classification accuracy. These findings highlight the potential of automated classification systems to enhance cardiac diagnostics and improve patient care.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Preprint Version. Accepted at EMBC 2025",
    "pdf_url": "https://arxiv.org/pdf/2507.07058v1",
    "published_date": "2025-07-08 13:17:26 UTC",
    "updated_date": "2025-07-08 13:17:26 UTC"
  },
  {
    "arxiv_id": "2507.06277v3",
    "title": "The Prompt War: How AI Decides on a Military Intervention",
    "authors": [
      "Maxim Chupilkin"
    ],
    "abstract": "Which factors determine AI's propensity to support military intervention? While the use of AI in high-stakes decision-making is growing exponentially, we still lack systematic analysis of the key drivers embedded in these models. This paper conducts a conjoint experiment in which large language models (LLMs) from leading providers (OpenAI, Anthropic, Google) are asked to decide on military intervention across 128 vignettes, with each vignette run 10 times. This design enables a systematic assessment of AI decision-making in military contexts. The results are remarkably consistent across models: all models place substantial weight on the probability of success and domestic support, prioritizing these factors over civilian casualties, economic shock, or international sanctions. The paper then tests whether LLMs are sensitive to context by introducing different motivations for intervention. The scoring is indeed context-dependent; however, probability of victory remains the most important factor in all scenarios. Finally, the paper evaluates numerical sensitivity and finds that models display some responsiveness to the scale of civilian casualties but no detectable sensitivity to the size of the economic shock.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "22 pages, 4 tables, 3 figures",
    "pdf_url": "https://arxiv.org/pdf/2507.06277v3",
    "published_date": "2025-07-08 12:52:08 UTC",
    "updated_date": "2025-12-09 11:25:22 UTC"
  },
  {
    "arxiv_id": "2507.05951v1",
    "title": "Complexity Results of Persuasion",
    "authors": [
      "Alban Grastien"
    ],
    "abstract": "We prove that persuasion is an NP-complete problem.",
    "categories": [
      "cs.CC",
      "cs.AI"
    ],
    "primary_category": "cs.CC",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.05951v1",
    "published_date": "2025-07-08 12:49:22 UTC",
    "updated_date": "2025-07-08 12:49:22 UTC"
  },
  {
    "arxiv_id": "2507.05938v2",
    "title": "A Wireless Foundation Model for Multi-Task Prediction",
    "authors": [
      "Yucheng Sheng",
      "Jiacheng Wang",
      "Xingyu Zhou",
      "Le Liang",
      "Hao Ye",
      "Shi Jin",
      "Geoffrey Ye Li"
    ],
    "abstract": "With the growing complexity and dynamics of the mobile communication networks, accurately predicting key system parameters, such as channel state information (CSI), user location, and network traffic, has become essential for a wide range of physical (PHY)-layer and medium access control (MAC)-layer tasks. Although traditional deep learning (DL)-based methods have been widely applied to such prediction tasks, they often struggle to generalize across different scenarios and tasks. In response, we propose a unified foundation model for multi-task prediction in wireless networks that supports diverse prediction intervals. The proposed model enforces univariate decomposition to unify heterogeneous tasks, encodes granularity for interval awareness, and uses a causal Transformer backbone for accurate predictions. Additionally, we introduce a patch masking strategy during training to support arbitrary input lengths. After trained on large-scale datasets, the proposed foundation model demonstrates strong generalization to unseen scenarios and achieves zero-shot performance on new tasks that surpass traditional full-shot baselines.",
    "categories": [
      "cs.AI",
      "cs.IT",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.05938v2",
    "published_date": "2025-07-08 12:37:55 UTC",
    "updated_date": "2025-07-09 12:45:07 UTC"
  },
  {
    "arxiv_id": "2507.05934v1",
    "title": "BlueLM-2.5-3B Technical Report",
    "authors": [
      "Baojiao Xiong",
      "Boheng Chen",
      "Chengzhi Wang",
      "Daxiong Luo",
      "Dongsheng Xu",
      "Dongyang Liu",
      "Fan Yang",
      "Fangyuan Li",
      "Fei Teng",
      "Feng Wang",
      "Fukang Qin",
      "Fuquan Peng",
      "Guanxin Tan",
      "Guozhi Wang",
      "Haibo Yu",
      "Haohao Gao",
      "Heng Liu",
      "Hongbo Yang",
      "Hongjian Zou",
      "Houzheng Shen",
      "Hu Meng",
      "Huan Li",
      "Hui Tan",
      "Jiali Chen",
      "Jianzhao Chen",
      "Jinliang Zhu",
      "Kai Wang",
      "Lei Wu",
      "Liangbing Liu",
      "Liuyang Bian",
      "Liyan He",
      "Long Liu",
      "Peiwen Li",
      "Penggang Shi",
      "Qi Ding",
      "Rui Hu",
      "Shuai Cao",
      "Shuai Ren",
      "Shuang Peng",
      "Teng Xie",
      "Weiji Chen",
      "Weilin Xiang",
      "Weixin Wu",
      "Xi Yin",
      "Xiaoxin Chen",
      "Xu Chen",
      "Yafei Wen",
      "Yan Hu",
      "Yanzhou Yang",
      "Yina Xie",
      "Yinghao Chen",
      "Yixuan Liao",
      "Yu Geng",
      "Yuanjiang Ouyang",
      "Yuanzhuo Yang",
      "Yuehua He",
      "Yushuai Peng",
      "Zhaoxiong Wang",
      "Zheng Wang",
      "Zhibo Zhou",
      "Ziyang Wu"
    ],
    "abstract": "We present BlueLM-2.5-3B, a compact and unified dense Multimodal Large Language Model (MLLM) designed for efficient edge-device deployment, offering strong general-purpose and reasoning capabilities. To the best of our knowledge, this is the first 3B-scale MLLM to support both thinking and non-thinking modes, while also enabling explicit control over thinking token budget. BlueLM-2.5-3B is developed through diversified data curation, key data resampling, hybrid heterogeneous reinforcement learning, and a high-performance training infrastructure. Our model achieves superior multimodal capacity while preserving competitive pure-text performance with only 2.9 billion parameters. We conduct comprehensive evaluations across a broad range of multimodal and text-only benchmarks. In thinking mode, BlueLM-2.5-3B achieves comparable performance to Qwen3-4B on text-only benchmarks, and trails the larger Kimi-VL-A3B-16B by only about 5% on average across multimodal evaluations. In non-thinking mode, it outperforms Qwen2.5-VL-3B on the majority of multimodal benchmarks. Additionally, BlueLM-2.5-3B exhibits exceptional data efficiency. All of the aforementioned performance is achieved with substantially less total training data than Qwen2.5-VL-3B and Qwen3-4B. We hope our work contributes to the advancement of high-performance, on-device MLLMs and provides meaningful insights to the research community.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.05934v1",
    "published_date": "2025-07-08 12:34:10 UTC",
    "updated_date": "2025-07-08 12:34:10 UTC"
  },
  {
    "arxiv_id": "2507.08845v1",
    "title": "DAFOS: Dynamic Adaptive Fanout Optimization Sampler",
    "authors": [
      "Irfan Ullah",
      "Young-Koo Lee"
    ],
    "abstract": "Graph Neural Networks (GNNs) are becoming an essential tool for learning from graph-structured data, however uniform neighbor sampling and static fanout settings frequently limit GNNs' scalability and efficiency. In this paper, we propose the Dynamic Adaptive Fanout Optimization Sampler (DAFOS), a novel approach that dynamically adjusts the fanout based on model performance and prioritizes important nodes during training. Our approach leverages node scoring based on node degree to focus computational resources on structurally important nodes, incrementing the fanout as the model training progresses. DAFOS also integrates an early stopping mechanism to halt training when performance gains diminish. Experiments conducted on three benchmark datasets, ogbnarxiv, Reddit, and ogbn-products, demonstrate that our approach significantly improves training speed and accuracy compared to a state-of-the-art approach. DAFOS achieves a 3.57x speedup on the ogbn-arxiv dataset and a 12.6x speedup on the Reddit dataset while improving the F1 score from 68.5% to 71.21% on ogbn-arxiv and from 73.78% to 76.88% on the ogbn-products dataset, respectively. These results highlight the potential of DAFOS as an efficient and scalable solution for large-scale GNN training.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.08845v1",
    "published_date": "2025-07-08 12:25:36 UTC",
    "updated_date": "2025-07-08 12:25:36 UTC"
  },
  {
    "arxiv_id": "2507.06275v1",
    "title": "Advancing Offline Handwritten Text Recognition: A Systematic Review of Data Augmentation and Generation Techniques",
    "authors": [
      "Yassin Hussein Rassul",
      "Aram M. Ahmed",
      "Polla Fattah",
      "Bryar A. Hassan",
      "Arwaa W. Abdulkareem",
      "Tarik A. Rashid",
      "Joan Lu"
    ],
    "abstract": "Offline Handwritten Text Recognition (HTR) systems play a crucial role in applications such as historical document digitization, automatic form processing, and biometric authentication. However, their performance is often hindered by the limited availability of annotated training data, particularly for low-resource languages and complex scripts. This paper presents a comprehensive survey of offline handwritten data augmentation and generation techniques designed to improve the accuracy and robustness of HTR systems. We systematically examine traditional augmentation methods alongside recent advances in deep learning, including Generative Adversarial Networks (GANs), diffusion models, and transformer-based approaches. Furthermore, we explore the challenges associated with generating diverse and realistic handwriting samples, particularly in preserving script authenticity and addressing data scarcity. This survey follows the PRISMA methodology, ensuring a structured and rigorous selection process. Our analysis began with 1,302 primary studies, which were filtered down to 848 after removing duplicates, drawing from key academic sources such as IEEE Digital Library, Springer Link, Science Direct, and ACM Digital Library. By evaluating existing datasets, assessment metrics, and state-of-the-art methodologies, this survey identifies key research gaps and proposes future directions to advance the field of handwritten text generation across diverse linguistic and stylistic landscapes.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.06275v1",
    "published_date": "2025-07-08 12:03:58 UTC",
    "updated_date": "2025-07-08 12:03:58 UTC"
  },
  {
    "arxiv_id": "2507.05916v3",
    "title": "On the Effectiveness of Methods and Metrics for Explainable AI in Remote Sensing Image Scene Classification",
    "authors": [
      "Jonas Klotz",
      "Tom Burgert",
      "Begüm Demir"
    ],
    "abstract": "The development of explainable artificial intelligence (xAI) methods for scene classification problems has attracted great attention in remote sensing (RS). Most xAI methods and the related evaluation metrics in RS are initially developed for natural images considered in computer vision (CV), and their direct usage in RS may not be suitable. To address this issue, in this paper, we investigate the effectiveness of explanation methods and metrics in the context of RS image scene classification. In detail, we methodologically and experimentally analyze ten explanation metrics spanning five categories (faithfulness, robustness, localization, complexity, randomization), applied to five established feature attribution methods (Occlusion, LIME, GradCAM, LRP, and DeepLIFT) across three RS datasets. Our methodological analysis identifies key limitations in both explanation methods and metrics. The performance of perturbation-based methods, such as Occlusion and LIME, heavily depends on perturbation baselines and spatial characteristics of RS scenes. Gradient-based approaches like GradCAM struggle when multiple labels are present in the same image, while some relevance propagation methods (LRP) can distribute relevance disproportionately relative to the spatial extent of classes. Analogously, we find limitations in evaluation metrics. Faithfulness metrics share the same problems as perturbation-based methods. Localization metrics and complexity metrics are unreliable for classes with a large spatial extent. In contrast, robustness metrics and randomization metrics consistently exhibit greater stability. Our experimental results support these methodological findings. Based on our analysis, we provide guidelines for selecting explanation methods, metrics, and hyperparameters in the context of RS image scene classification.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "The code of this work will be publicly available at https://git.tu-berlin.de/rsim/xai4rs Accepted at IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing",
    "pdf_url": "https://arxiv.org/pdf/2507.05916v3",
    "published_date": "2025-07-08 12:00:24 UTC",
    "updated_date": "2025-10-22 14:17:31 UTC"
  },
  {
    "arxiv_id": "2507.05911v1",
    "title": "Differentiable Reward Optimization for LLM based TTS system",
    "authors": [
      "Changfeng Gao",
      "Zhihao Du",
      "Shiliang Zhang"
    ],
    "abstract": "This paper proposes a novel Differentiable Reward Optimization (DiffRO) method aimed at enhancing the performance of neural codec language models based text-to-speech (TTS) systems. In contrast to conventional reinforcement learning from human feedback (RLHF) approaches applied to TTS, DiffRO directly compute the rewards based on neural codec tokens, rather than relying on synthesized audio. Furthermore, we employ the Gumbel-Softmax technique to render the reward function differentiable, thereby streamlining the RLHF training process. Additionally, we introduce a multi-task reward (MTR) model which can provide feedback from different perspectives and find that it can augment the system's capability to follow instructions effectively.Experimental results indicate that DiffRO significantly improves the pronunciation accuracy of the TTS system, achieving state-of-the-art (SOTA) WER results on the seed-tts-eval benchmark. Moreover, with the integration of the MTR model, we demonstrate the ability to control emotional and quality attributes in a zero-shot manner.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.05911v1",
    "published_date": "2025-07-08 11:57:16 UTC",
    "updated_date": "2025-07-08 11:57:16 UTC"
  },
  {
    "arxiv_id": "2507.05906v2",
    "title": "Feature-Based vs. GAN-Based Learning from Demonstrations: When and Why",
    "authors": [
      "Chenhao Li",
      "Marco Hutter",
      "Andreas Krause"
    ],
    "abstract": "This survey provides a comparative analysis of feature-based and GAN-based approaches to learning from demonstrations, with a focus on the structure of reward functions and their implications for policy learning. Feature-based methods offer dense, interpretable rewards that excel at high-fidelity motion imitation, yet often require sophisticated representations of references and struggle with generalization in unstructured settings. GAN-based methods, in contrast, use implicit, distributional supervision that enables scalability and adaptation flexibility, but are prone to training instability and coarse reward signals. Recent advancements in both paradigms converge on the importance of structured motion representations, which enable smoother transitions, controllable synthesis, and improved task integration. We argue that the dichotomy between feature-based and GAN-based methods is increasingly nuanced: rather than one paradigm dominating the other, the choice should be guided by task-specific priorities such as fidelity, diversity, interpretability, and adaptability. This work outlines the algorithmic trade-offs and design considerations that underlie method selection, offering a framework for principled decision-making in learning from demonstrations.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.GR",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.05906v2",
    "published_date": "2025-07-08 11:45:51 UTC",
    "updated_date": "2025-07-15 11:07:33 UTC"
  },
  {
    "arxiv_id": "2507.05904v1",
    "title": "Universal Embeddings of Tabular Data",
    "authors": [
      "Astrid Franz",
      "Frederik Hoppe",
      "Marianne Michaelis",
      "Udo Göbel"
    ],
    "abstract": "Tabular data in relational databases represents a significant portion of industrial data. Hence, analyzing and interpreting tabular data is of utmost importance. Application tasks on tabular data are manifold and are often not specified when setting up an industrial database. To address this, we present a novel framework for generating universal, i.e., task-independent embeddings of tabular data for performing downstream tasks without predefined targets. Our method transforms tabular data into a graph structure, leverages Graph Auto-Encoders to create entity embeddings, which are subsequently aggregated to obtain embeddings for each table row, i.e., each data sample. This two-step approach has the advantage that unseen samples, consisting of similar entities, can be embedded without additional training. Downstream tasks such as regression, classification or outlier detection, can then be performed by applying a distance-based similarity measure in the embedding space. Experiments on real-world datasets demonstrate that our method achieves superior performance compared to existing universal tabular data embedding techniques.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at Tabular Data Analysis (TaDA) Workshop at VLDB 2025",
    "pdf_url": "https://arxiv.org/pdf/2507.05904v1",
    "published_date": "2025-07-08 11:45:29 UTC",
    "updated_date": "2025-07-08 11:45:29 UTC"
  },
  {
    "arxiv_id": "2507.05894v1",
    "title": "MusiScene: Leveraging MU-LLaMA for Scene Imagination and Enhanced Video Background Music Generation",
    "authors": [
      "Fathinah Izzati",
      "Xinyue Li",
      "Yuxuan Wu",
      "Gus Xia"
    ],
    "abstract": "Humans can imagine various atmospheres and settings when listening to music, envisioning movie scenes that complement each piece. For example, slow, melancholic music might evoke scenes of heartbreak, while upbeat melodies suggest celebration. This paper explores whether a Music Language Model, e.g. MU-LLaMA, can perform a similar task, called Music Scene Imagination (MSI), which requires cross-modal information from video and music to train. To improve upon existing music captioning models which focusing solely on musical elements, we introduce MusiScene, a music captioning model designed to imagine scenes that complement each music. In this paper, (1) we construct a large-scale video-audio caption dataset with 3,371 pairs, (2) we finetune Music Understanding LLaMA for the MSI task to create MusiScene, and (3) we conduct comprehensive evaluations and prove that our MusiScene is more capable of generating contextually relevant captions compared to MU-LLaMA. We leverage the generated MSI captions to enhance Video Background Music Generation (VBMG) from text.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.05894v1",
    "published_date": "2025-07-08 11:32:02 UTC",
    "updated_date": "2025-07-08 11:32:02 UTC"
  },
  {
    "arxiv_id": "2507.05891v1",
    "title": "Decomposing the Time Series Forecasting Pipeline: A Modular Approach for Time Series Representation, Information Extraction, and Projection",
    "authors": [
      "Robert Leppich",
      "Michael Stenger",
      "André Bauer",
      "Samuel Kounev"
    ],
    "abstract": "With the advent of Transformers, time series forecasting has seen significant advances, yet it remains challenging due to the need for effective sequence representation, memory construction, and accurate target projection. Time series forecasting remains a challenging task, demanding effective sequence representation, meaningful information extraction, and precise future projection. Each dataset and forecasting configuration constitutes a distinct task, each posing unique challenges the model must overcome to produce accurate predictions. To systematically address these task-specific difficulties, this work decomposes the time series forecasting pipeline into three core stages: input sequence representation, information extraction and memory construction, and final target projection. Within each stage, we investigate a range of architectural configurations to assess the effectiveness of various modules, such as convolutional layers for feature extraction and self-attention mechanisms for information extraction, across diverse forecasting tasks, including evaluations on seven benchmark datasets. Our models achieve state-of-the-art forecasting accuracy while greatly enhancing computational efficiency, with reduced training and inference times and a lower parameter count. The source code is available at https://github.com/RobertLeppich/REP-Net.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.05891v1",
    "published_date": "2025-07-08 11:26:42 UTC",
    "updated_date": "2025-07-08 11:26:42 UTC"
  },
  {
    "arxiv_id": "2507.05890v2",
    "title": "Psychometric Item Validation Using Virtual Respondents with Trait-Response Mediators",
    "authors": [
      "Sungjib Lim",
      "Woojung Song",
      "Eun-Ju Lee",
      "Yohan Jo"
    ],
    "abstract": "As psychometric surveys are increasingly used to assess the traits of large language models (LLMs), the need for scalable survey item generation suited for LLMs has also grown. A critical challenge here is ensuring the construct validity of generated items, i.e., whether they truly measure the intended trait. Traditionally, this requires costly, large-scale human data collection. To make it efficient, we present a framework for virtual respondent simulation using LLMs. Our central idea is to account for mediators: factors through which the same trait can give rise to varying responses to a survey item. By simulating respondents with diverse mediators, we identify survey items that robustly measure intended traits. Experiments on three psychological trait theories (Big5, Schwartz, VIA) show that our mediator generation methods and simulation framework effectively identify high-validity items. LLMs demonstrate the ability to generate plausible mediators from trait definitions and to simulate respondent behavior for item validation. Our problem formulation, metrics, methodology, and dataset open a new direction for cost-effective survey development and a deeper understanding of how LLMs simulate human survey responses. We publicly release our dataset and code to support future work.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "21 pages, 9 figures",
    "pdf_url": "https://arxiv.org/pdf/2507.05890v2",
    "published_date": "2025-07-08 11:26:03 UTC",
    "updated_date": "2025-10-06 09:54:02 UTC"
  },
  {
    "arxiv_id": "2507.05888v1",
    "title": "Hierarchy or Heterarchy? A Theory of Long-Range Connections for the Sensorimotor Brain",
    "authors": [
      "Jeff Hawkins",
      "Niels Leadholm",
      "Viviane Clay"
    ],
    "abstract": "In the traditional understanding of the neocortex, sensory information flows up a hierarchy of regions, with each level processing increasingly complex features. Information also flows down the hierarchy via a different set of connections. Although the hierarchical model has significant support, many anatomical connections do not conform to the standard hierarchical interpretation. In addition, hierarchically arranged regions sometimes respond in parallel, not sequentially as would occur in a hierarchy. This and other evidence suggests that two regions can act in parallel and hierarchically at the same time. Given this flexibility, the word \"heterarchy\" might be a more suitable term to describe neocortical organization. This paper proposes a new interpretation of how sensory and motor information is processed in the neocortex. The key to our proposal is what we call the \"Thousand Brains Theory\", which posits that every cortical column is a sensorimotor learning system. Columns learn by integrating sensory input over multiple movements of a sensor. In this view, even primary and secondary regions, such as V1 and V2, can learn and recognize complete 3D objects. This suggests that the hierarchical connections between regions are used to learn the compositional structure of parent objects composed of smaller child objects. We explain the theory by examining the different types of long-range connections between cortical regions and between the neocortex and thalamus. We describe these connections, and then suggest the specific roles they play in the context of a heterarchy of sensorimotor regions. We also suggest that the thalamus plays an essential role in transforming the pose between objects and sensors. The novel perspective we argue for here has broad implications for both neuroscience and artificial intelligence.",
    "categories": [
      "q-bio.NC",
      "cs.AI"
    ],
    "primary_category": "q-bio.NC",
    "comment": "18 pages, 7 figures",
    "pdf_url": "https://arxiv.org/pdf/2507.05888v1",
    "published_date": "2025-07-08 11:22:02 UTC",
    "updated_date": "2025-07-08 11:22:02 UTC"
  },
  {
    "arxiv_id": "2507.05886v1",
    "title": "Current Practices for Building LLM-Powered Reasoning Tools Are Ad Hoc -- and We Can Do Better",
    "authors": [
      "Aaron Bembenek"
    ],
    "abstract": "There is growing excitement about building software verifiers, synthesizers, and other Automated Reasoning (AR) tools by combining traditional symbolic algorithms and Large Language Models (LLMs). Unfortunately, the current practice for constructing such neurosymbolic AR systems is an ad hoc programming model that does not have the strong guarantees of traditional symbolic algorithms, nor a deep enough synchronization of neural networks and symbolic reasoning to unlock the full potential of LLM-powered reasoning. I propose Neurosymbolic Transition Systems as a principled computational model that can underlie infrastructure for building neurosymbolic AR tools. In this model, symbolic state is paired with intuition, and state transitions operate over symbols and intuition in parallel. I argue why this new paradigm can scale logical reasoning beyond current capabilities while retaining the strong guarantees of symbolic algorithms, and I sketch out how the computational model I propose can be reified in a logic programming language.",
    "categories": [
      "cs.AI",
      "cs.PL"
    ],
    "primary_category": "cs.AI",
    "comment": "6 pages, 4 figures",
    "pdf_url": "https://arxiv.org/pdf/2507.05886v1",
    "published_date": "2025-07-08 11:19:09 UTC",
    "updated_date": "2025-07-08 11:19:09 UTC"
  },
  {
    "arxiv_id": "2507.05884v1",
    "title": "Comparison of Path Planning Algorithms for Autonomous Vehicle Navigation Using Satellite and Airborne LiDAR Data",
    "authors": [
      "Chang Liu",
      "Zhexiong Xue",
      "Tamas Sziranyi"
    ],
    "abstract": "Autonomous vehicle navigation in unstructured environments, such as forests and mountainous regions, presents significant challenges due to irregular terrain and complex road conditions. This work provides a comparative evaluation of mainstream and well-established path planning algorithms applied to weighted pixel-level road networks derived from high-resolution satellite imagery and airborne LiDAR data. For 2D road-map navigation, where the weights reflect road conditions and terrain difficulty, A*, Dijkstra, RRT*, and a Novel Improved Ant Colony Optimization Algorithm (NIACO) are tested on the DeepGlobe satellite dataset. For 3D road-map path planning, 3D A*, 3D Dijkstra, RRT-Connect, and NIACO are evaluated using the Hamilton airborne LiDAR dataset, which provides detailed elevation information. All algorithms are assessed under identical start and end point conditions, focusing on path cost, computation time, and memory consumption. Results demonstrate that Dijkstra consistently offers the most stable and efficient performance in both 2D and 3D scenarios, particularly when operating on dense, pixel-level geospatial road-maps. These findings highlight the reliability of Dijkstra-based planning for static terrain navigation and establish a foundation for future research on dynamic path planning under complex environmental constraints.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "6 pages, 3 figures, 67th International Symposium ELMAR-2025 15-17 September 2025 Zadar, Croatia",
    "pdf_url": "https://arxiv.org/pdf/2507.05884v1",
    "published_date": "2025-07-08 11:15:21 UTC",
    "updated_date": "2025-07-08 11:15:21 UTC"
  },
  {
    "arxiv_id": "2507.06274v2",
    "title": "Enhancing LLM Watermark Resilience Against Both Scrubbing and Spoofing Attacks",
    "authors": [
      "Huanming Shen",
      "Baizhou Huang",
      "Xiaojun Wan"
    ],
    "abstract": "Watermarking is a promising defense against the misuse of large language models (LLMs), yet it remains vulnerable to scrubbing and spoofing attacks. This vulnerability stems from an inherent trade-off governed by watermark window size: smaller windows resist scrubbing better but are easier to reverse-engineer, enabling low-cost statistics-based spoofing attacks. This work breaks this trade-off by introducing a novel mechanism, equivalent texture keys, where multiple tokens within a watermark window can independently support the detection. Based on the redundancy, we propose a novel watermark scheme with Sub-vocabulary decomposed Equivalent tExture Key (SEEK). It achieves a Pareto improvement, increasing the resilience against scrubbing attacks without compromising robustness to spoofing. Experiments demonstrate SEEK's superiority over prior method, yielding spoofing robustness gains of +88.2%/+92.3%/+82.0% and scrubbing robustness gains of +10.2%/+6.4%/+24.6% across diverse dataset settings.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.06274v2",
    "published_date": "2025-07-08 11:14:00 UTC",
    "updated_date": "2025-12-07 03:02:23 UTC"
  },
  {
    "arxiv_id": "2507.05868v1",
    "title": "CogniPlay: a work-in-progress Human-like model for General Game Playing",
    "authors": [
      "Aloïs Rautureau",
      "Éric Piette"
    ],
    "abstract": "While AI systems have equaled or surpassed human performance in a wide variety of games such as Chess, Go, or Dota 2, describing these systems as truly \"human-like\" remains far-fetched. Despite their success, they fail to replicate the pattern-based, intuitive decision-making processes observed in human cognition. This paper presents an overview of findings from cognitive psychology and previous efforts to model human-like behavior in artificial agents, discusses their applicability to General Game Playing (GGP) and introduces our work-in-progress model based on these observations: CogniPlay.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "5 pages, 1 figure",
    "pdf_url": "https://arxiv.org/pdf/2507.05868v1",
    "published_date": "2025-07-08 10:48:29 UTC",
    "updated_date": "2025-07-08 10:48:29 UTC"
  },
  {
    "arxiv_id": "2507.05829v2",
    "title": "Intra-DP: A High Performance Collaborative Inference System for Mobile Edge Computing",
    "authors": [
      "Zekai Sun",
      "Xiuxian Guan",
      "Zheng Lin",
      "Zihan Fang",
      "Xiangming Cai",
      "Zhe Chen",
      "Fangming Liu",
      "Heming Cui",
      "Jie Xiong",
      "Wei Ni",
      "Chau Yuen"
    ],
    "abstract": "Deploying deep neural networks (DNNs) on resource-constrained mobile devices presents significant challenges, particularly in achieving real-time performance while simultaneously coping with limited computational resources and battery life. While Mobile Edge Computing (MEC) offers collaborative inference with GPU servers as a promising solution, existing approaches primarily rely on layer-wise model partitioning and undergo significant transmission bottlenecks caused by the sequential execution of DNN operations. To address this challenge, we present Intra-DP, a high-performance collaborative inference system optimized for DNN inference on MEC. Intra DP employs a novel parallel computing technique based on local operators (i.e., operators whose minimum unit input is not the entire input tensor, such as the convolution kernel). By decomposing their computations (operations) into several independent sub-operations and overlapping the computation and transmission of different sub-operations through parallel execution, Intra-DP mitigates transmission bottlenecks in MEC, achieving fast and energy-efficient inference. The evaluation demonstrates that Intra-DP reduces per-inference latency by up to 50% and energy consumption by up to 75% compared to state-of-the-art baselines, without sacrificing accuracy.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NI",
    "comment": "14 pages, 19 figures",
    "pdf_url": "https://arxiv.org/pdf/2507.05829v2",
    "published_date": "2025-07-08 09:50:57 UTC",
    "updated_date": "2025-09-23 05:51:13 UTC"
  },
  {
    "arxiv_id": "2507.05820v1",
    "title": "Constella: Supporting Storywriters' Interconnected Character Creation through LLM-based Multi-Agents",
    "authors": [
      "Syemin Park",
      "Soobin Park",
      "Youn-kyung Lim"
    ],
    "abstract": "Creating a cast of characters by attending to their relational dynamics is a critical aspect of most long-form storywriting. However, our formative study (N=14) reveals that writers struggle to envision new characters that could influence existing ones, to balance similarities and differences among characters, and to intricately flesh out their relationships. Based on these observations, we designed Constella, an LLM-based multi-agent tool that supports storywriters' interconnected character creation process. Constella suggests related characters (FRIENDS DISCOVERY feature), reveals the inner mindscapes of several characters simultaneously (JOURNALS feature), and manifests relationships through inter-character responses (COMMENTS feature). Our 7-8 day deployment study with storywriters (N=11) shows that Constella enabled the creation of expansive communities composed of related characters, facilitated the comparison of characters' thoughts and emotions, and deepened writers' understanding of character relationships. We conclude by discussing how multi-agent interactions can help distribute writers' attention and effort across the character cast.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.HC",
    "comment": "50 pages",
    "pdf_url": "https://arxiv.org/pdf/2507.05820v1",
    "published_date": "2025-07-08 09:39:02 UTC",
    "updated_date": "2025-07-08 09:39:02 UTC"
  },
  {
    "arxiv_id": "2507.05816v1",
    "title": "Affective-ROPTester: Capability and Bias Analysis of LLMs in Predicting Retinopathy of Prematurity",
    "authors": [
      "Shuai Zhao",
      "Yulin Zhang",
      "Luwei Xiao",
      "Xinyi Wu",
      "Yanhao Jia",
      "Zhongliang Guo",
      "Xiaobao Wu",
      "Cong-Duy Nguyen",
      "Guoming Zhang",
      "Anh Tuan Luu"
    ],
    "abstract": "Despite the remarkable progress of large language models (LLMs) across various domains, their capacity to predict retinopathy of prematurity (ROP) risk remains largely unexplored. To address this gap, we introduce a novel Chinese benchmark dataset, termed CROP, comprising 993 admission records annotated with low, medium, and high-risk labels. To systematically examine the predictive capabilities and affective biases of LLMs in ROP risk stratification, we propose Affective-ROPTester, an automated evaluation framework incorporating three prompting strategies: Instruction-based, Chain-of-Thought (CoT), and In-Context Learning (ICL). The Instruction scheme assesses LLMs' intrinsic knowledge and associated biases, whereas the CoT and ICL schemes leverage external medical knowledge to enhance predictive accuracy. Crucially, we integrate emotional elements at the prompt level to investigate how different affective framings influence the model's ability to predict ROP and its bias patterns. Empirical results derived from the CROP dataset yield two principal observations. First, LLMs demonstrate limited efficacy in ROP risk prediction when operating solely on intrinsic knowledge, yet exhibit marked performance gains when augmented with structured external inputs. Second, affective biases are evident in the model outputs, with a consistent inclination toward overestimating medium- and high-risk cases. Third, compared to negative emotions, positive emotional framing contributes to mitigating predictive bias in model outputs. These findings highlight the critical role of affect-sensitive prompt engineering in enhancing diagnostic reliability and emphasize the utility of Affective-ROPTester as a framework for evaluating and mitigating affective bias in clinical language modeling systems.",
    "categories": [
      "cs.AI",
      "cs.CE",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.05816v1",
    "published_date": "2025-07-08 09:36:14 UTC",
    "updated_date": "2025-07-08 09:36:14 UTC"
  },
  {
    "arxiv_id": "2507.05814v3",
    "title": "Empowering Bridge Digital Twins by Bridging the Data Gap with a Unified Synthesis Framework",
    "authors": [
      "Wang Wang",
      "Mingyu Shi",
      "Jun Jiang",
      "Wenqian Ma",
      "Chong Liu",
      "Yasutaka Narazaki",
      "Xuguang Wang"
    ],
    "abstract": "As critical transportation infrastructure, bridges face escalating challenges from aging and deterioration, while traditional manual inspection methods suffer from low efficiency. Although 3D point cloud technology provides a new data-driven paradigm, its application potential is often constrained by the incompleteness of real-world data, which results from missing labels and scanning occlusions. To overcome the bottleneck of insufficient generalization in existing synthetic data methods, this paper proposes a systematic framework for generating 3D bridge data.\n  This framework can automatically generate complete point clouds featuring component-level instance annotations, high-fidelity color, and precise normal vectors. It can be further extended to simulate the creation of diverse and physically realistic incomplete point clouds, designed to support the training of segmentation and completion networks, respectively. Experiments demonstrate that a PointNet++ model trained with our synthetic data achieves a mean Intersection over Union (mIoU) of 84.2% in real-world bridge semantic segmentation. Concurrently, a fine-tuned KT-Net exhibits superior performance on the component completion task.\n  This research offers an innovative methodology and a foundational dataset for the 3D visual analysis of bridge structures, holding significant implications for advancing the automated management and maintenance of infrastructure.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Due to the authors' failure to reach an agreement on the manuscript quality, they voluntarily waive their rights to be credited as authors",
    "pdf_url": "https://arxiv.org/pdf/2507.05814v3",
    "published_date": "2025-07-08 09:34:55 UTC",
    "updated_date": "2025-09-05 13:51:50 UTC"
  },
  {
    "arxiv_id": "2507.05812v2",
    "title": "Solar Altitude Guided Scene Illumination",
    "authors": [
      "Samed Doğan",
      "Maximilian Hoh",
      "Nico Leuze",
      "Nicolas Rodriguez Peña",
      "Alfred Schöttl"
    ],
    "abstract": "The development of safe and robust autonomous driving functions is heavily dependent on large-scale, high-quality sensor data. However, real-world data acquisition requires extensive human labor and is strongly limited by factors such as labeling cost, driver safety protocols and scenario coverage. Thus, multiple lines of work focus on the conditional generation of synthetic camera sensor data. We identify a significant gap in research regarding daytime variation, presumably caused by the scarcity of available labels. Consequently, we present solar altitude as global conditioning variable. It is readily computable from latitude-longitude coordinates and local time, eliminating the need for manual labeling. Our work is complemented by a tailored normalization approach, targeting the sensitivity of daylight towards small numeric changes in altitude. We demonstrate its ability to accurately capture lighting characteristics and illumination-dependent image noise in the context of diffusion models.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "This work has been submitted to the IEEE for possible publication",
    "pdf_url": "https://arxiv.org/pdf/2507.05812v2",
    "published_date": "2025-07-08 09:31:16 UTC",
    "updated_date": "2025-08-26 12:06:37 UTC"
  },
  {
    "arxiv_id": "2507.05810v1",
    "title": "Concept-Based Mechanistic Interpretability Using Structured Knowledge Graphs",
    "authors": [
      "Sofiia Chorna",
      "Kateryna Tarelkina",
      "Eloïse Berthier",
      "Gianni Franchi"
    ],
    "abstract": "While concept-based interpretability methods have traditionally focused on local explanations of neural network predictions, we propose a novel framework and interactive tool that extends these methods into the domain of mechanistic interpretability. Our approach enables a global dissection of model behavior by analyzing how high-level semantic attributes (referred to as concepts) emerge, interact, and propagate through internal model components. Unlike prior work that isolates individual neurons or predictions, our framework systematically quantifies how semantic concepts are represented across layers, revealing latent circuits and information flow that underlie model decision-making. A key innovation is our visualization platform that we named BAGEL (for Bias Analysis with a Graph for global Explanation Layers), which presents these insights in a structured knowledge graph, allowing users to explore concept-class relationships, identify spurious correlations, and enhance model trustworthiness. Our framework is model-agnostic, scalable, and contributes to a deeper understanding of how deep learning models generalize (or fail to) in the presence of dataset biases. The demonstration is available at https://knowledge-graph-ui-4a7cb5.gitlab.io/.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "15 pages",
    "pdf_url": "https://arxiv.org/pdf/2507.05810v1",
    "published_date": "2025-07-08 09:30:20 UTC",
    "updated_date": "2025-07-08 09:30:20 UTC"
  },
  {
    "arxiv_id": "2507.05794v1",
    "title": "Automated Reasoning for Vulnerability Management by Design",
    "authors": [
      "Avi Shaked",
      "Nan Messe"
    ],
    "abstract": "For securing systems, it is essential to manage their vulnerability posture and design appropriate security controls. Vulnerability management allows to proactively address vulnerabilities by incorporating pertinent security controls into systems designs. Current vulnerability management approaches do not support systematic reasoning about the vulnerability postures of systems designs. To effectively manage vulnerabilities and design security controls, we propose a formally grounded automated reasoning mechanism. We integrate the mechanism into an open-source security design tool and demonstrate its application through an illustrative example driven by real-world challenges. The automated reasoning mechanism allows system designers to identify vulnerabilities that are applicable to a specific system design, explicitly specify vulnerability mitigation options, declare selected controls, and thus systematically manage vulnerability postures.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LO",
      "eess.SY"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.05794v1",
    "published_date": "2025-07-08 08:56:14 UTC",
    "updated_date": "2025-07-08 08:56:14 UTC"
  },
  {
    "arxiv_id": "2507.05791v5",
    "title": "GTA1: GUI Test-time Scaling Agent",
    "authors": [
      "Yan Yang",
      "Dongxu Li",
      "Yutong Dai",
      "Yuhao Yang",
      "Ziyang Luo",
      "Zirui Zhao",
      "Zhiyuan Hu",
      "Junzhe Huang",
      "Amrita Saha",
      "Zeyuan Chen",
      "Ran Xu",
      "Liyuan Pan",
      "Silvio Savarese",
      "Caiming Xiong",
      "Junnan Li"
    ],
    "abstract": "Graphical user interface (GUI) agents autonomously complete tasks across platforms (\\eg, Linux) by sequentially decomposing user instructions into action proposals that iteratively interact with visual elements in the evolving environment. However, two main challenges arise: i) planning (\\ie, the action proposal sequence) under expansive action space, where selecting an appropriate plan is non-trivial, as many valid ones may exist; ii) accurately grounding actions in complex and high-resolution interfaces, \\ie, precisely interacting with visual targets. This paper investigates the aforementioned challenges with our \\textbf{G}UI \\textbf{T}est-time Scaling \\textbf{A}gent, namely GTA1. First, we conduct test-time scaling to select the most appropriate action proposal: at each step, multiple candidate proposals are sampled and evaluated and selected by a judge model. It trades off computation for better decision quality by concurrent sampling. Second, we propose a model that improves grounding of the selected action proposals to its corresponding visual elements. Our key insight is that reinforcement learning (RL) facilitates grounding through inherent objective alignments, rewarding successful clicks on interface elements. Experimentally, GTA1 achieves state-of-the-art performance on both grounding and agent task execution benchmarks. The code and models are released here.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.05791v5",
    "published_date": "2025-07-08 08:52:18 UTC",
    "updated_date": "2025-10-03 23:50:19 UTC"
  },
  {
    "arxiv_id": "2507.14164v1",
    "title": "A Denoising VAE for Intracardiac Time Series in Ischemic Cardiomyopathy",
    "authors": [
      "Samuel Ruipérez-Campillo",
      "Alain Ryser",
      "Thomas M. Sutter",
      "Ruibin Feng",
      "Prasanth Ganesan",
      "Brototo Deb",
      "Kelly A. Brennan",
      "Maxime Pedron",
      "Albert J. Rogers",
      "Maarten Z. H. Kolk",
      "Fleur V. Y. Tjong",
      "Sanjiv M. Narayan",
      "Julia E. Vogt"
    ],
    "abstract": "In the field of cardiac electrophysiology (EP), effectively reducing noise in intra-cardiac signals is crucial for the accurate diagnosis and treatment of arrhythmias and cardiomyopathies. However, traditional noise reduction techniques fall short in addressing the diverse noise patterns from various sources, often non-linear and non-stationary, present in these signals. This work introduces a Variational Autoencoder (VAE) model, aimed at improving the quality of intra-ventricular monophasic action potential (MAP) signal recordings. By constructing representations of clean signals from a dataset of 5706 time series from 42 patients diagnosed with ischemic cardiomyopathy, our approach demonstrates superior denoising performance when compared to conventional filtering methods commonly employed in clinical settings. We assess the effectiveness of our VAE model using various metrics, indicating its superior capability to denoise signals across different noise types, including time-varying non-linear noise frequently found in clinical settings. These results reveal that VAEs can eliminate diverse sources of noise in single beats, outperforming state-of-the-art denoising techniques and potentially improving treatment efficacy in cardiac EP.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "9 pages, 2 figures, 3 tables, the last two authors are shared senior authors",
    "pdf_url": "https://arxiv.org/pdf/2507.14164v1",
    "published_date": "2025-07-08 08:27:31 UTC",
    "updated_date": "2025-07-08 08:27:31 UTC"
  },
  {
    "arxiv_id": "2507.08843v1",
    "title": "Can We Predict Your Next Move Without Breaking Your Privacy?",
    "authors": [
      "Arpita Soni",
      "Sahil Tripathi",
      "Gautam Siddharth Kashyap",
      "Manaswi Kulahara",
      "Mohammad Anas Azeez",
      "Zohaib Hasan Siddiqui",
      "Nipun Joshi",
      "Jiechao Gao"
    ],
    "abstract": "We propose FLLL3M--Federated Learning with Large Language Models for Mobility Modeling--a privacy-preserving framework for Next-Location Prediction (NxLP). By retaining user data locally and leveraging LLMs through an efficient outer product mechanism, FLLL3M ensures high accuracy with low resource demands. It achieves SOT results on Gowalla (Acc@1: 12.55, MRR: 0.1422), WeePlace (10.71, 0.1285), Brightkite (10.42, 0.1169), and FourSquare (8.71, 0.1023), while reducing parameters by up to 45.6% and memory usage by 52.7%.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted in the 17th International Conference on Advances in Social Networks Analysis and Mining (ASONAM 2025), scheduled for 25 - 28 August 2025 in Ontario, Canada",
    "pdf_url": "https://arxiv.org/pdf/2507.08843v1",
    "published_date": "2025-07-08 08:13:34 UTC",
    "updated_date": "2025-07-08 08:13:34 UTC"
  },
  {
    "arxiv_id": "2507.05765v1",
    "title": "Real-time monitoring of the SoH of lithium-ion batteries",
    "authors": [
      "Bruno Jammes",
      "Edgar Hernando Sepúlveda-Oviedo",
      "Corinne Alonso"
    ],
    "abstract": "Real-time monitoring of the state of health (SoH) of batteries remains a major challenge, particularly in microgrids where operational constraints limit the use of traditional methods. As part of the 4BLife project, we propose an innovative method based on the analysis of a discharge pulse at the end of the charge phase. The parameters of the equivalent electrical model describing the voltage evolution across the battery terminals during this current pulse are then used to estimate the SoH. Based on the experimental data acquired so far, the initial results demonstrate the relevance of the proposed approach. After training using the parameters of two batteries with a capacity degradation of around 85%, we successfully predicted the degradation of two other batteries, cycled down to approximately 90% SoH, with a mean absolute error of around 1% in the worst case, and an explainability score of the estimator close to 0.9. If these performances are confirmed, this method can be easily integrated into battery management systems (BMS) and paves the way for optimized battery management under continuous operation.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "in French language, Symposium de G{é}nie {É}lectrique SGE 2025, Jul 2025, Toulouse, France",
    "pdf_url": "https://arxiv.org/pdf/2507.05765v1",
    "published_date": "2025-07-08 08:08:53 UTC",
    "updated_date": "2025-07-08 08:08:53 UTC"
  },
  {
    "arxiv_id": "2507.08021v1",
    "title": "Unveiling Effective In-Context Configurations for Image Captioning: An External & Internal Analysis",
    "authors": [
      "Li Li",
      "Yongliang Wu",
      "Jingze Zhu",
      "Jiawei Peng",
      "Jianfei Cai",
      "Xu Yang"
    ],
    "abstract": "The evolution of large models has witnessed the emergence of In-Context Learning (ICL) capabilities. In Natural Language Processing (NLP), numerous studies have demonstrated the effectiveness of ICL. Inspired by the success of Large Language Models (LLMs), researchers have developed Large Multimodal Models (LMMs) with ICL capabilities. However, explorations of demonstration configuration for multimodal ICL remain preliminary. Additionally, the controllability of In-Context Examples (ICEs) provides an efficient and cost-effective means to observe and analyze the inference characteristics of LMMs under varying inputs. This paper conducts a comprehensive external and internal investigation of multimodal in-context learning on the image captioning task. Externally, we explore demonstration configuration strategies through three dimensions: shot number, image retrieval, and caption assignment. We employ multiple metrics to systematically and thoroughly evaluate and summarize key findings. Internally, we analyze typical LMM attention characteristics and develop attention-based metrics to quantify model behaviors. We also conduct auxiliary experiments to explore the feasibility of attention-driven model acceleration and compression. We further compare performance variations between LMMs with identical model design and pretraining strategies and explain the differences from the angles of pre-training data features. Our study reveals both how ICEs configuration strategies impact model performance through external experiments and characteristic typical patterns through internal inspection, providing dual perspectives for understanding multimodal ICL in LMMs. Our method of combining external and internal analysis to investigate large models, along with our newly proposed metrics, can be applied to broader research areas.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "16 pages, 11 figures",
    "pdf_url": "https://arxiv.org/pdf/2507.08021v1",
    "published_date": "2025-07-08 08:07:57 UTC",
    "updated_date": "2025-07-08 08:07:57 UTC"
  },
  {
    "arxiv_id": "2507.06273v2",
    "title": "Magneto-radiative modelling and artificial neural network optimization of biofluid flow in a stenosed arterial domain",
    "authors": [
      "S P Shivakumar",
      "Gunisetty Ramasekhar",
      "P Nimmy",
      "Sujesh Areekara",
      "L Thanuja",
      "T V Smitha",
      "S Devanathan",
      "Ganesh R Naik",
      "K V Nagaraja"
    ],
    "abstract": "The increasing complexity of cardiovascular diseases and limitations in traditional healing methods mandate the invention of new drug delivery systems that assure targeted, effective, and regulated treatments, contributing directly to UN SDGs 3 and 9, thereby encouraging the utilization of sustainable medical technologies in healthcare. This study investigates the flow of a Casson-Maxwell nanofluid through a stenosed arterial domain. The quantities, such as skin friction and heat transfer rate, are analysed in detail. The Casson-Maxwell fluid shows a lower velocity profile than the Casson fluids, which indicates the improved residence time for efficient drug delivery. The heat transfer rate shows an increase with higher volume fractions of copper and aluminium oxide nanoparticles and a decrease with higher volume fractions of silver nanoparticles. The skin friction coefficient decreases by 219% with a unit increase in the Maxwell parameter, whereas it increases by 66.1% with a unit rise in the Casson parameter. This work supports SDGs 4 and 17 by fostering interdisciplinary learning and collaboration in fluid dynamics and healthcare innovation. Additionally, the rate of heat flow was forecasted (with an overall R-value of 0.99457) using the Levenberg-Marquardt backpropagation training scheme under the influence of magneto-radiative, linear heat source and Casson-Maxwell parameters along with the tri-metallic nanoparticle volume fractions. It is also observed that the drag coefficient is most sensitive to the changes in the Maxwell parameter.",
    "categories": [
      "physics.med-ph",
      "cs.AI",
      "math.NA",
      "physics.bio-ph"
    ],
    "primary_category": "physics.med-ph",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.06273v2",
    "published_date": "2025-07-08 08:04:40 UTC",
    "updated_date": "2025-07-16 06:41:32 UTC"
  },
  {
    "arxiv_id": "2507.05755v1",
    "title": "An autonomous agent for auditing and improving the reliability of clinical AI models",
    "authors": [
      "Lukas Kuhn",
      "Florian Buettner"
    ],
    "abstract": "The deployment of AI models in clinical practice faces a critical challenge: models achieving expert-level performance on benchmarks can fail catastrophically when confronted with real-world variations in medical imaging. Minor shifts in scanner hardware, lighting or demographics can erode accuracy, but currently reliability auditing to identify such catastrophic failure cases before deployment is a bespoke and time-consuming process. Practitioners lack accessible and interpretable tools to expose and repair hidden failure modes. Here we introduce ModelAuditor, a self-reflective agent that converses with users, selects task-specific metrics, and simulates context-dependent, clinically relevant distribution shifts. ModelAuditor then generates interpretable reports explaining how much performance likely degrades during deployment, discussing specific likely failure modes and identifying root causes and mitigation strategies. Our comprehensive evaluation across three real-world clinical scenarios - inter-institutional variation in histopathology, demographic shifts in dermatology, and equipment heterogeneity in chest radiography - demonstrates that ModelAuditor is able correctly identify context-specific failure modes of state-of-the-art models such as the established SIIM-ISIC melanoma classifier. Its targeted recommendations recover 15-25% of performance lost under real-world distribution shift, substantially outperforming both baseline models and state-of-the-art augmentation methods. These improvements are achieved through a multi-agent architecture and execute on consumer hardware in under 10 minutes, costing less than US$0.50 per audit.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.05755v1",
    "published_date": "2025-07-08 07:58:52 UTC",
    "updated_date": "2025-07-08 07:58:52 UTC"
  },
  {
    "arxiv_id": "2507.05754v1",
    "title": "LeAD: The LLM Enhanced Planning System Converged with End-to-end Autonomous Driving",
    "authors": [
      "Yuhang Zhang",
      "Jiaqi Liu",
      "Chengkai Xu",
      "Peng Hang",
      "Jian Sun"
    ],
    "abstract": "A principal barrier to large-scale deployment of urban autonomous driving systems lies in the prevalence of complex scenarios and edge cases. Existing systems fail to effectively interpret semantic information within traffic contexts and discern intentions of other participants, consequently generating decisions misaligned with skilled drivers' reasoning patterns. We present LeAD, a dual-rate autonomous driving architecture integrating imitation learning-based end-to-end (E2E) frameworks with large language model (LLM) augmentation. The high-frequency E2E subsystem maintains real-time perception-planning-control cycles, while the low-frequency LLM module enhances scenario comprehension through multi-modal perception fusion with HD maps and derives optimal decisions via chain-of-thought (CoT) reasoning when baseline planners encounter capability limitations. Our experimental evaluation in the CARLA Simulator demonstrates LeAD's superior handling of unconventional scenarios, achieving 71 points on Leaderboard V1 benchmark, with a route completion of 93%.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.05754v1",
    "published_date": "2025-07-08 07:58:29 UTC",
    "updated_date": "2025-07-08 07:58:29 UTC"
  },
  {
    "arxiv_id": "2507.06272v3",
    "title": "LIRA: Inferring Segmentation in Large Multi-modal Models with Local Interleaved Region Assistance",
    "authors": [
      "Zhang Li",
      "Biao Yang",
      "Qiang Liu",
      "Shuo Zhang",
      "Zhiyin Ma",
      "Liang Yin",
      "Linger Deng",
      "Yabo Sun",
      "Yuliang Liu",
      "Xiang Bai"
    ],
    "abstract": "While large multi-modal models (LMMs) demonstrate promising capabilities in segmentation and comprehension, they still struggle with two limitations: inaccurate segmentation and hallucinated comprehension. These challenges stem primarily from constraints in weak visual comprehension and a lack of fine-grained perception. To alleviate these limitations, we propose LIRA, a framework that capitalizes on the complementary relationship between visual comprehension and segmentation via two key components: (1) Semantic-Enhanced Feature Extractor (SEFE) improves object attribute inference by fusing semantic and pixel-level features, leading to more accurate segmentation; (2) Interleaved Local Visual Coupling (ILVC) autoregressively generates local descriptions after extracting local features based on segmentation masks, offering fine-grained supervision to mitigate hallucinations. Furthermore, we find that the precision of object segmentation is positively correlated with the latent related semantics of the <seg> token. To quantify this relationship and the model's potential semantic inferring ability, we introduce the Attributes Evaluation (AttrEval) dataset. Our experiments show that LIRA achieves state-of-the-art performance in both segmentation and comprehension tasks. Code will be available at https://github.com/echo840/LIRA.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "ICCV 2025",
    "pdf_url": "https://arxiv.org/pdf/2507.06272v3",
    "published_date": "2025-07-08 07:46:26 UTC",
    "updated_date": "2025-08-09 05:40:33 UTC"
  },
  {
    "arxiv_id": "2507.05733v1",
    "title": "When Transformers Meet Recommenders: Integrating Self-Attentive Sequential Recommendation with Fine-Tuned LLMs",
    "authors": [
      "Kechen Liu"
    ],
    "abstract": "Self-Attentive Sequential Recommendation (SASRec) effectively captures long-term user preferences by applying attention mechanisms to historical interactions. Concurrently, the rise of Large Language Models (LLMs) has motivated research into LLM-based recommendation, which leverages their powerful generalization and language understanding capabilities. However, LLMs often lack the domain-specific knowledge and collaborative signals essential for high-quality recommendations when relying solely on textual prompts. To address this limitation, this study proposes SASRecLLM, a novel framework that integrates SASRec as a collaborative encoder with an LLM fine-tuned using Low-Rank Adaptation (LoRA). The components are connected via a mapping layer to align their dimensional spaces, and three targeted training strategies are designed to optimize the hybrid architecture. Extensive experiments on multiple datasets demonstrate that SASRecLLM achieves robust and consistent improvements over strong baselines in both cold-start and warm-start scenarios. This work advances the field of LLM-based recommendation by presenting a modular and effective paradigm for fusing structured collaborative filtering with the semantic power of fine-tuned LLMs. The implementation is available on GitHub: https://github.com/kechenkristin/RecLLM",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.05733v1",
    "published_date": "2025-07-08 07:26:55 UTC",
    "updated_date": "2025-07-08 07:26:55 UTC"
  },
  {
    "arxiv_id": "2507.05731v1",
    "title": "A Satellite-Ground Synergistic Large Vision-Language Model System for Earth Observation",
    "authors": [
      "Yuxin Zhang",
      "Jiahao Yang",
      "Zhe Chen",
      "Wenjun Zhu",
      "Jin Zhao",
      "Yue Gao"
    ],
    "abstract": "Recently, large vision-language models (LVLMs) unleash powerful analysis capabilities for low Earth orbit (LEO) satellite Earth observation images in the data center. However, fast satellite motion, brief satellite-ground station (GS) contact windows, and large size of the images pose a data download challenge. To enable near real-time Earth observation applications (e.g., disaster and extreme weather monitoring), we should explore how to deploy LVLM in LEO satellite networks, and design SpaceVerse, an efficient satellite-ground synergistic LVLM inference system. To this end, firstly, we deploy compact LVLMs on satellites for lightweight tasks, whereas regular LVLMs operate on GSs to handle computationally intensive tasks. Then, we propose a computing and communication co-design framework comprised of a progressive confidence network and an attention-based multi-scale preprocessing, used to identify on-satellite inferring data, and reduce data redundancy before satellite-GS transmission, separately. We implement and evaluate SpaceVerse on real-world LEO satellite constellations and datasets, achieving a 31.2% average gain in accuracy and a 51.2% reduction in latency compared to state-of-the-art baselines.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NI",
    "comment": "11 pages, 12 figures",
    "pdf_url": "https://arxiv.org/pdf/2507.05731v1",
    "published_date": "2025-07-08 07:24:34 UTC",
    "updated_date": "2025-07-08 07:24:34 UTC"
  },
  {
    "arxiv_id": "2507.05730v2",
    "title": "Hyperspectral Anomaly Detection Methods: A Survey and Comparative Study",
    "authors": [
      "Aayushma Pant",
      "Arbind Agrahari Baniya",
      "Tsz-Kwan Lee",
      "Sunil Aryal"
    ],
    "abstract": "Hyperspectral images are high-dimensional datasets comprising hundreds of contiguous spectral bands, enabling detailed analysis of materials and surfaces. Hyperspectral anomaly detection (HAD) refers to the technique of identifying and locating anomalous targets in such data without prior information about a hyperspectral scene or target spectrum. This technology has seen rapid advancements in recent years, with applications in agriculture, defence, military surveillance, and environmental monitoring. Despite this significant progress, existing HAD methods continue to face challenges such as high computational complexity, sensitivity to noise, and limited generalisation across diverse datasets. This study presents a comprehensive comparison of various HAD techniques, categorising them into statistical models, representation-based methods, classical machine learning approaches, and deep learning models. We evaluated these methods across 17 benchmarking datasets using different performance metrics, such as ROC, AUC, and separability map to analyse detection accuracy, computational efficiency, their strengths, limitations, and directions for future research. Our findings highlight that deep learning models achieved the highest detection accuracy, while statistical models demonstrated exceptional speed across all datasets. This survey aims to provide valuable insights for researchers and practitioners working to advance the field of hyperspectral anomaly detection methods.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.05730v2",
    "published_date": "2025-07-08 07:23:24 UTC",
    "updated_date": "2025-07-11 02:35:34 UTC"
  },
  {
    "arxiv_id": "2507.05724v3",
    "title": "Omni-Router: Sharing Routing Decisions in Sparse Mixture-of-Experts for Speech Recognition",
    "authors": [
      "Zijin Gu",
      "Tatiana Likhomanenko",
      "Navdeep Jaitly"
    ],
    "abstract": "Mixture-of-experts (MoE) architectures have expanded from language modeling to automatic speech recognition (ASR). Traditional MoE methods, such as the Switch Transformer, route experts independently within each layer. Our analysis reveals that routers in most layers make expert choices that are not strongly correlated with the choices of the routers in other layers. To increase the cooperation between experts in different layers and encourage greater specialization, we use a shared router across different MoE layers. We call this model Omni-router Transformer. Extensive experiments on a large-scale pseudo-labeled dataset and evaluations across 10 diverse, out-of-domain ASR benchmarks demonstrate that the Omni-router Transformer is able to achieve lower training loss and consistently outperform dense and Switch Transformer models, reducing average word error rates by 11.2% and 8.2%, respectively, while providing structured expert usage and improved robustness to diverse data.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted in 2025 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)",
    "pdf_url": "https://arxiv.org/pdf/2507.05724v3",
    "published_date": "2025-07-08 07:18:33 UTC",
    "updated_date": "2025-11-05 00:40:00 UTC"
  },
  {
    "arxiv_id": "2507.05716v1",
    "title": "Divergent Realities: A Comparative Analysis of Human Expert vs. Artificial Intelligence Based Generation and Evaluation of Treatment Plans in Dermatology",
    "authors": [
      "Dipayan Sengupta",
      "Saumya Panda"
    ],
    "abstract": "Background: Evaluating AI-generated treatment plans is a key challenge as AI expands beyond diagnostics, especially with new reasoning models. This study compares plans from human experts and two AI models (a generalist and a reasoner), assessed by both human peers and a superior AI judge.\n  Methods: Ten dermatologists, a generalist AI (GPT-4o), and a reasoning AI (o3) generated treatment plans for five complex dermatology cases. The anonymized, normalized plans were scored in two phases: 1) by the ten human experts, and 2) by a superior AI judge (Gemini 2.5 Pro) using an identical rubric.\n  Results: A profound 'evaluator effect' was observed. Human experts scored peer-generated plans significantly higher than AI plans (mean 7.62 vs. 7.16; p=0.0313), ranking GPT-4o 6th (mean 7.38) and the reasoning model, o3, 11th (mean 6.97). Conversely, the AI judge produced a complete inversion, scoring AI plans significantly higher than human plans (mean 7.75 vs. 6.79; p=0.0313). It ranked o3 1st (mean 8.20) and GPT-4o 2nd, placing all human experts lower.\n  Conclusions: The perceived quality of a clinical plan is fundamentally dependent on the evaluator's nature. An advanced reasoning AI, ranked poorly by human experts, was judged as superior by a sophisticated AI, revealing a deep gap between experience-based clinical heuristics and data-driven algorithmic logic. This paradox presents a critical challenge for AI integration, suggesting the future requires synergistic, explainable human-AI systems that bridge this reasoning gap to augment clinical care.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "13 pages, 3 tables",
    "pdf_url": "https://arxiv.org/pdf/2507.05716v1",
    "published_date": "2025-07-08 06:59:58 UTC",
    "updated_date": "2025-07-08 06:59:58 UTC"
  },
  {
    "arxiv_id": "2507.05714v3",
    "title": "HIRAG: Hierarchical-Thought Instruction-Tuning Retrieval-Augmented Generation",
    "authors": [
      "YiHan Jiao",
      "ZheHao Tan",
      "Dan Yang",
      "DuoLin Sun",
      "Jie Feng",
      "Yue Shen",
      "Jian Wang",
      "Peng Wei"
    ],
    "abstract": "Retrieval-augmented generation (RAG) has become a fundamental paradigm for addressing the challenges faced by large language models in handling real-time information and domain-specific problems. Traditional RAG systems primarily rely on the in-context learning (ICL) capabilities of the large language model itself. Still, in-depth research on the specific capabilities needed by the RAG generation model is lacking, leading to challenges with inconsistent document quality and retrieval system imperfections. Even the limited studies that fine-tune RAG generative models often \\textit{lack a granular focus on RAG task} or \\textit{a deeper utilization of chain-of-thought processes}. To address this, we propose that RAG models should possess three progressively hierarchical abilities (1) Filtering: the ability to select relevant information; (2) Combination: the ability to combine semantic information across paragraphs; and (3) RAG-specific reasoning: the ability to further process external knowledge using internal knowledge. Thus, we introduce our new RAG instruction fine-tuning method, Hierarchical-Thought Instruction-Tuning Retrieval-Augmented Generation (HIRAG) incorporates a \"think before answering\" strategy. This method enhances the model's open-book examination capability by utilizing multi-level progressive chain-of-thought. Experiments show that the HIRAG training strategy significantly improves the model's performance on datasets such as RGB, PopQA, MuSiQue, HotpotQA, and PubmedQA.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.05714v3",
    "published_date": "2025-07-08 06:53:28 UTC",
    "updated_date": "2025-09-10 03:00:18 UTC"
  },
  {
    "arxiv_id": "2507.05713v2",
    "title": "DRAGON: Dynamic RAG Benchmark On News",
    "authors": [
      "Fedor Chernogorskii",
      "Sergei Averkiev",
      "Liliya Kudraleeva",
      "Zaven Martirosian",
      "Maria Tikhonova",
      "Valentin Malykh",
      "Alena Fenogenova"
    ],
    "abstract": "Retrieval-Augmented Generation (RAG) is a widely adopted approach for improving the factuality of large language models (LLMs) by incorporating external knowledge at inference time. Although there exist multiple RAG benchmarks for English, evaluation resources for other languages, including Russian, remain scarce and static, failing to capture the dynamic nature of real-world deployments. In this work, we present DRAGON (Dynamic RAG Benchmark On News), the first dynamic benchmark for evaluating RAG systems in Russian on a changing news corpora. DRAGON is built upon a regularly updated corpus of Russian news and public documents and supports comprehensive evaluation of both the retriever and generator components. Question generation is performed automatically with the use of Knowledge Graph constructed from the corpus and enables the extraction of four core question types aligned with distinct subgraph patterns. We release a complete evaluation framework comprising the pipeline for automatic question generation, evaluation scripts, which are potentially reusable for other languages and multilingual settings, and benchmark data. We also launch a public leaderboard to encourage community participation and comparison.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.05713v2",
    "published_date": "2025-07-08 06:52:43 UTC",
    "updated_date": "2025-07-15 07:36:34 UTC"
  },
  {
    "arxiv_id": "2507.05707v2",
    "title": "Agentic-R1: Distilled Dual-Strategy Reasoning",
    "authors": [
      "Weihua Du",
      "Pranjal Aggarwal",
      "Sean Welleck",
      "Yiming Yang"
    ],
    "abstract": "Current long chain-of-thought (long-CoT) models excel at mathematical reasoning but rely on slow and error-prone natural language traces. Tool-augmented agents address arithmetic via code execution, but often falter on complex logical tasks. We introduce a fine-tuning framework, DualDistill, that distills complementary reasoning strategies from multiple teachers into a unified student model. Using this approach, we train Agentic-R1, which dynamically selects the optimal strategy for each query, invoking tools for arithmetic and algorithmic problems, and using text-based reasoning for abstract ones. Our method improves accuracy across a range of tasks, including both computation-intensive and standard benchmarks, demonstrating the effectiveness of multi-strategy distillation in achieving robust and efficient reasoning. Our project is available at https://github.com/StigLidu/DualDistill",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by EMNLP 2025. 15 pages. Project available at https://github.com/StigLidu/DualDistill",
    "pdf_url": "https://arxiv.org/pdf/2507.05707v2",
    "published_date": "2025-07-08 06:35:16 UTC",
    "updated_date": "2025-08-30 22:22:18 UTC"
  },
  {
    "arxiv_id": "2507.05685v1",
    "title": "Efficient Training of Large-Scale AI Models Through Federated Mixture-of-Experts: A System-Level Approach",
    "authors": [
      "Xiaobing Chen",
      "Boyang Zhang",
      "Xiangwei Zhou",
      "Mingxuan Sun",
      "Shuai Zhang",
      "Songyang Zhang",
      "Geoffrey Ye Li"
    ],
    "abstract": "The integration of Federated Learning (FL) and Mixture-of-Experts (MoE) presents a compelling pathway for training more powerful, large-scale artificial intelligence models (LAMs) on decentralized data while preserving privacy. However, efficient federated training of these complex MoE-structured LAMs is hindered by significant system-level challenges, particularly in managing the interplay between heterogeneous client resources and the sophisticated coordination required for numerous specialized experts. This article highlights a critical, yet underexplored concept: the absence of robust quantitative strategies for dynamic client-expert alignment that holistically considers varying client capacities and the imperative for system-wise load balancing. Specifically, we propose a conceptual system design for intelligent client-expert alignment that incorporates dynamic fitness scoring, global expert load monitoring, and client capacity profiling. By tackling these systemic issues, we can unlock more scalable, efficient, and robust training mechanisms {with fewer communication rounds for convergence}, paving the way for the widespread deployment of large-scale federated MoE-structured LAMs in edge computing with ultra-high communication efficiency.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "7 pages",
    "pdf_url": "https://arxiv.org/pdf/2507.05685v1",
    "published_date": "2025-07-08 05:30:37 UTC",
    "updated_date": "2025-07-08 05:30:37 UTC"
  },
  {
    "arxiv_id": "2507.05681v1",
    "title": "GATMesh: Clock Mesh Timing Analysis using Graph Neural Networks",
    "authors": [
      "Muhammad Hadir Khan",
      "Matthew Guthaus"
    ],
    "abstract": "Clock meshes are essential in high-performance VLSI systems for minimizing skew and handling PVT variations, but analyzing them is difficult due to reconvergent paths, multi-source driving, and input mesh buffer skew. SPICE simulations are accurate but slow; yet simplified models miss key effects like slew and input skew. We propose GATMesh, a Graph Neural Network (GNN)-based framework that models the clock mesh as a graph with augmented structural and physical features. Trained on SPICE data, GATMesh achieves high accuracy with average delay error of 5.27ps on unseen benchmarks, while achieving speed-ups of 47146x over multi-threaded SPICE simulation.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.05681v1",
    "published_date": "2025-07-08 05:18:42 UTC",
    "updated_date": "2025-07-08 05:18:42 UTC"
  },
  {
    "arxiv_id": "2507.05675v1",
    "title": "MedGen: Unlocking Medical Video Generation by Scaling Granularly-annotated Medical Videos",
    "authors": [
      "Rongsheng Wang",
      "Junying Chen",
      "Ke Ji",
      "Zhenyang Cai",
      "Shunian Chen",
      "Yunjin Yang",
      "Benyou Wang"
    ],
    "abstract": "Recent advances in video generation have shown remarkable progress in open-domain settings, yet medical video generation remains largely underexplored. Medical videos are critical for applications such as clinical training, education, and simulation, requiring not only high visual fidelity but also strict medical accuracy. However, current models often produce unrealistic or erroneous content when applied to medical prompts, largely due to the lack of large-scale, high-quality datasets tailored to the medical domain. To address this gap, we introduce MedVideoCap-55K, the first large-scale, diverse, and caption-rich dataset for medical video generation. It comprises over 55,000 curated clips spanning real-world medical scenarios, providing a strong foundation for training generalist medical video generation models. Built upon this dataset, we develop MedGen, which achieves leading performance among open-source models and rivals commercial systems across multiple benchmarks in both visual quality and medical accuracy. We hope our dataset and model can serve as a valuable resource and help catalyze further research in medical video generation. Our code and data is available at https://github.com/FreedomIntelligence/MedGen",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.05675v1",
    "published_date": "2025-07-08 04:58:36 UTC",
    "updated_date": "2025-07-08 04:58:36 UTC"
  },
  {
    "arxiv_id": "2507.05660v1",
    "title": "TuneShield: Mitigating Toxicity in Conversational AI while Fine-tuning on Untrusted Data",
    "authors": [
      "Aravind Cheruvu",
      "Shravya Kanchi",
      "Sifat Muhammad Abdullah",
      "Nicholas Kong",
      "Daphne Yao",
      "Murtuza Jadliwala",
      "Bimal Viswanath"
    ],
    "abstract": "Recent advances in foundation models, such as LLMs, have revolutionized conversational AI. Chatbots are increasingly being developed by customizing LLMs on specific conversational datasets. However, mitigating toxicity during this customization, especially when dealing with untrusted training data, remains a significant challenge. To address this, we introduce TuneShield, a defense framework designed to mitigate toxicity during chatbot fine-tuning while preserving conversational quality. TuneShield leverages LLM-based toxicity classification, utilizing the instruction-following capabilities and safety alignment of LLMs to effectively identify toxic samples, outperforming industry API services. TuneShield generates synthetic conversation samples, termed 'healing data', based on the identified toxic samples, using them to mitigate toxicity while reinforcing desirable behavior during fine-tuning. It performs an alignment process to further nudge the chatbot towards producing desired responses. Our findings show that TuneShield effectively mitigates toxicity injection attacks while preserving conversational quality, even when the toxicity classifiers are imperfect or biased. TuneShield proves to be resilient against adaptive adversarial and jailbreak attacks. Additionally, TuneShield demonstrates effectiveness in mitigating adaptive toxicity injection attacks during dialog-based learning (DBL).",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CR",
    "comment": "Pre-print",
    "pdf_url": "https://arxiv.org/pdf/2507.05660v1",
    "published_date": "2025-07-08 04:40:09 UTC",
    "updated_date": "2025-07-08 04:40:09 UTC"
  },
  {
    "arxiv_id": "2507.05651v1",
    "title": "City-Level Foreign Direct Investment Prediction with Tabular Learning on Judicial Data",
    "authors": [
      "Tianxing Wu",
      "Lizhe Cao",
      "Shuang Wang",
      "Jiming Wang",
      "Shutong Zhu",
      "Yerong Wu",
      "Yuqing Feng"
    ],
    "abstract": "To advance the United Nations Sustainable Development Goal on promoting sustained, inclusive, and sustainable economic growth, foreign direct investment (FDI) plays a crucial role in catalyzing economic expansion and fostering innovation. Precise city-level FDI prediction is quite important for local government and is commonly studied based on economic data (e.g., GDP). However, such economic data could be prone to manipulation, making predictions less reliable. To address this issue, we try to leverage large-scale judicial data which reflects judicial performance influencing local investment security and returns, for city-level FDI prediction. Based on this, we first build an index system for the evaluation of judicial performance over twelve million publicly available adjudication documents according to which a tabular dataset is reformulated. We then propose a new Tabular Learning method on Judicial Data (TLJD) for city-level FDI prediction. TLJD integrates row data and column data in our built tabular dataset for judicial performance indicator encoding, and utilizes a mixture of experts model to adjust the weights of different indicators considering regional variations. To validate the effectiveness of TLJD, we design cross-city and cross-time tasks for city-level FDI predictions. Extensive experiments on both tasks demonstrate the superiority of TLJD (reach to at least 0.92 R2) over the other ten state-of-the-art baselines in different evaluation metrics.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "9 pages, accepted by IJCAI 2025",
    "pdf_url": "https://arxiv.org/pdf/2507.05651v1",
    "published_date": "2025-07-08 04:10:25 UTC",
    "updated_date": "2025-07-08 04:10:25 UTC"
  },
  {
    "arxiv_id": "2507.05649v2",
    "title": "DESIGN: Encrypted GNN Inference via Server-Side Input Graph Pruning",
    "authors": [
      "Kaixiang Zhao",
      "Joseph Yousry Attalla",
      "Qian Lou",
      "Yushun Dong"
    ],
    "abstract": "Graph Neural Networks (GNNs) have achieved state-of-the-art performance in various graph-based learning tasks. However, enabling privacy-preserving GNNs in encrypted domains, such as under Fully Homomorphic Encryption (FHE), typically incurs substantial computational overhead, rendering real-time and privacy-preserving inference impractical. In this work, we propose DESIGN (EncrypteD GNN Inference via sErver-Side Input Graph pruNing), a novel framework for efficient encrypted GNN inference. DESIGN tackles the critical efficiency limitations of existing FHE GNN approaches, which often overlook input data redundancy and apply uniform computational strategies. Our framework achieves significant performance gains through a hierarchical optimization strategy executed entirely on the server: first, FHE-compatible node importance scores (based on encrypted degree statistics) are computed from the encrypted graph. These scores then guide a homomorphic partitioning process, generating multi-level importance masks directly under FHE. This dynamically generated mask facilitates both input graph pruning (by logically removing unimportant elements) and a novel adaptive polynomial activation scheme, where activation complexity is tailored to node importance levels. Empirical evaluations demonstrate that DESIGN substantially accelerates FHE GNN inference compared to state-of-the-art methods while maintaining competitive model accuracy, presenting a robust solution for secure graph analytics. Our implementation is publicly available at https://github.com/LabRAI/DESIGN.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "Under Review in Conference on Neural Information Processing Systems (NeurIPS 2025)",
    "pdf_url": "https://arxiv.org/pdf/2507.05649v2",
    "published_date": "2025-07-08 04:01:53 UTC",
    "updated_date": "2025-07-14 14:12:59 UTC"
  },
  {
    "arxiv_id": "2507.05644v2",
    "title": "The Features at Convergence Theorem: a first-principles alternative to the Neural Feature Ansatz for how networks learn representations",
    "authors": [
      "Enric Boix-Adsera",
      "Neil Mallinar",
      "James B. Simon",
      "Mikhail Belkin"
    ],
    "abstract": "It is a central challenge in deep learning to understand how neural networks learn representations. A leading approach is the Neural Feature Ansatz (NFA) (Radhakrishnan et al. 2024), a conjectured mechanism for how feature learning occurs. Although the NFA is empirically validated, it is an educated guess and lacks a theoretical basis, and thus it is unclear when it might fail, and how to improve it. In this paper, we take a first-principles approach to understanding why this observation holds, and when it does not. We use first-order optimality conditions to derive the Features at Convergence Theorem (FACT), an alternative to the NFA that (a) obtains greater agreement with learned features at convergence, (b) explains why the NFA holds in most settings, and (c) captures essential feature learning phenomena in neural networks such as grokking behavior in modular arithmetic and phase transitions in learning sparse parities, similarly to the NFA. Thus, our results unify theoretical first-order optimality analyses of neural networks with the empirically-driven NFA literature, and provide a principled alternative that provably and empirically holds at convergence.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.05644v2",
    "published_date": "2025-07-08 03:52:48 UTC",
    "updated_date": "2025-09-05 01:58:57 UTC"
  },
  {
    "arxiv_id": "2507.07066v1",
    "title": "Latent Acoustic Mapping for Direction of Arrival Estimation: A Self-Supervised Approach",
    "authors": [
      "Adrian S. Roman",
      "Iran R. Roman",
      "Juan P. Bello"
    ],
    "abstract": "Acoustic mapping techniques have long been used in spatial audio processing for direction of arrival estimation (DoAE). Traditional beamforming methods for acoustic mapping, while interpretable, often rely on iterative solvers that can be computationally intensive and sensitive to acoustic variability. On the other hand, recent supervised deep learning approaches offer feedforward speed and robustness but require large labeled datasets and lack interpretability. Despite their strengths, both methods struggle to consistently generalize across diverse acoustic setups and array configurations, limiting their broader applicability. We introduce the Latent Acoustic Mapping (LAM) model, a self-supervised framework that bridges the interpretability of traditional methods with the adaptability and efficiency of deep learning methods. LAM generates high-resolution acoustic maps, adapts to varying acoustic conditions, and operates efficiently across different microphone arrays. We assess its robustness on DoAE using the LOCATA and STARSS benchmarks. LAM achieves comparable or superior localization performance to existing supervised methods. Additionally, we show that LAM's acoustic maps can serve as effective features for supervised models, further enhancing DoAE accuracy and underscoring its potential to advance adaptive, high-performance sound localization systems.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.07066v1",
    "published_date": "2025-07-08 03:35:00 UTC",
    "updated_date": "2025-07-08 03:35:00 UTC"
  },
  {
    "arxiv_id": "2507.21105v2",
    "title": "AgentMaster: A Multi-Agent Conversational Framework Using A2A and MCP Protocols for Multimodal Information Retrieval and Analysis",
    "authors": [
      "Callie C. Liao",
      "Duoduo Liao",
      "Sai Surya Gadiraju"
    ],
    "abstract": "The rise of Multi-Agent Systems (MAS) in Artificial Intelligence (AI), especially integrated with Large Language Models (LLMs), has greatly facilitated the resolution of complex tasks. However, current systems are still facing challenges of inter-agent communication, coordination, and interaction with heterogeneous tools and resources. Most recently, the Model Context Protocol (MCP) by Anthropic and Agent-to-Agent (A2A) communication protocol by Google have been introduced, and to the best of our knowledge, very few applications exist where both protocols are employed within a single MAS framework. We present a pilot study of AgentMaster, a novel modular multi-protocol MAS framework with self-implemented A2A and MCP, enabling dynamic coordination, flexible communication, and rapid development with faster iteration. Through a unified conversational interface, the system supports natural language interaction without prior technical expertise and responds to multimodal queries for tasks including information retrieval, question answering, and image analysis. The experiments are validated through both human evaluation and quantitative metrics, including BERTScore F1 (96.3%) and LLM-as-a-Judge G-Eval (87.1%). These results demonstrate robust automated inter-agent coordination, query decomposition, task allocation, dynamic routing, and domain-specific relevant responses. Overall, our proposed framework contributes to the potential capabilities of domain-specific, cooperative, and scalable conversational AI powered by MAS.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.IR",
    "comment": "Accepted by EMNLP 2025",
    "pdf_url": "https://arxiv.org/pdf/2507.21105v2",
    "published_date": "2025-07-08 03:34:26 UTC",
    "updated_date": "2025-09-19 22:28:32 UTC"
  },
  {
    "arxiv_id": "2507.05638v1",
    "title": "LLMs are Introvert",
    "authors": [
      "Litian Zhang",
      "Xiaoming Zhang",
      "Bingyu Yan",
      "Ziyi Zhou",
      "Bo Zhang",
      "Zhenyu Guan",
      "Xi Zhang",
      "Chaozhuo Li"
    ],
    "abstract": "The exponential growth of social media and generative AI has transformed information dissemination, fostering connectivity but also accelerating the spread of misinformation. Understanding information propagation dynamics and developing effective control strategies is essential to mitigate harmful content. Traditional models, such as SIR, provide basic insights but inadequately capture the complexities of online interactions. Advanced methods, including attention mechanisms and graph neural networks, enhance accuracy but typically overlook user psychology and behavioral dynamics. Large language models (LLMs), with their human-like reasoning, offer new potential for simulating psychological aspects of information spread. We introduce an LLM-based simulation environment capturing agents' evolving attitudes, emotions, and responses. Initial experiments, however, revealed significant gaps between LLM-generated behaviors and authentic human dynamics, especially in stance detection and psychological realism. A detailed evaluation through Social Information Processing Theory identified major discrepancies in goal-setting and feedback evaluation, stemming from the lack of emotional processing in standard LLM training. To address these issues, we propose the Social Information Processing-based Chain of Thought (SIP-CoT) mechanism enhanced by emotion-guided memory. This method improves the interpretation of social cues, personalization of goals, and evaluation of feedback. Experimental results confirm that SIP-CoT-enhanced LLM agents more effectively process social information, demonstrating behaviors, attitudes, and emotions closer to real human interactions. In summary, this research highlights critical limitations in current LLM-based propagation simulations and demonstrates how integrating SIP-CoT and emotional memory significantly enhances the social intelligence and realism of LLM agents.",
    "categories": [
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.05638v1",
    "published_date": "2025-07-08 03:32:38 UTC",
    "updated_date": "2025-07-08 03:32:38 UTC"
  },
  {
    "arxiv_id": "2507.05636v2",
    "title": "Graph Learning",
    "authors": [
      "Feng Xia",
      "Ciyuan Peng",
      "Jing Ren",
      "Falih Gozi Febrinanto",
      "Renqiang Luo",
      "Vidya Saikrishna",
      "Shuo Yu",
      "Xiangjie Kong"
    ],
    "abstract": "Graph learning has rapidly evolved into a critical subfield of machine learning and artificial intelligence (AI). Its development began with early graph-theoretic methods, gaining significant momentum with the advent of graph neural networks (GNNs). Over the past decade, progress in scalable architectures, dynamic graph modeling, multimodal learning, generative AI, explainable AI (XAI), and responsible AI has broadened the applicability of graph learning to various challenging environments. Graph learning is significant due to its ability to model complex, non-Euclidean relationships that traditional machine learning struggles to capture, thus better supporting real-world applications ranging from drug discovery and fraud detection to recommender systems and scientific reasoning. However, challenges like scalability, generalization, heterogeneity, interpretability, and trustworthiness must be addressed to unlock its full potential. This survey provides a comprehensive introduction to graph learning, focusing on key dimensions including scalable, temporal, multimodal, generative, explainable, and responsible graph learning. We review state-of-the-art techniques for efficiently handling large-scale graphs, capturing dynamic temporal dependencies, integrating heterogeneous data modalities, generating novel graph samples, and enhancing interpretability to foster trust and transparency. We also explore ethical considerations, such as privacy and fairness, to ensure responsible deployment of graph learning models. Additionally, we identify and discuss emerging topics, highlighting recent integration of graph learning and other AI paradigms and offering insights into future directions. This survey serves as a valuable resource for researchers and practitioners seeking to navigate the rapidly evolving landscape of graph learning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "185 pages",
    "pdf_url": "https://arxiv.org/pdf/2507.05636v2",
    "published_date": "2025-07-08 03:29:27 UTC",
    "updated_date": "2025-11-07 05:58:26 UTC"
  },
  {
    "arxiv_id": "2507.05633v1",
    "title": "SARA: Selective and Adaptive Retrieval-augmented Generation with Context Compression",
    "authors": [
      "Yiqiao Jin",
      "Kartik Sharma",
      "Vineeth Rakesh",
      "Yingtong Dou",
      "Menghai Pan",
      "Mahashweta Das",
      "Srijan Kumar"
    ],
    "abstract": "Retrieval-augmented Generation (RAG) extends large language models (LLMs) with external knowledge but faces key challenges: restricted effective context length and redundancy in retrieved documents. Pure compression-based approaches reduce input size but often discard fine-grained details essential for factual accuracy. We propose SARA, a unified RAG framework that balances local precision and global knowledge coverage under tight context budgets. SARA combines natural-language text snippets with semantic compression vectors to jointly enhance context efficiency and answer correctness. It represents contexts at two complementary levels: 1) fine-grained natural-language spans that preserve critical entities and numerical values, and 2) compact, interpretable vectors that summarize high-level semantics. An iterative evidence-selection module employs the compression vectors for dynamic reranking of contexts. Across 9 datasets and 5 open-source LLMs spanning 3 model families (Mistral, Llama, and Gemma), SARA consistently improves answer relevance (+17.71), answer correctness (+13.72), and semantic similarity (+15.53), demonstrating the importance of integrating textual and compressed representations for robust, context-efficient RAG.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "20 pages",
    "pdf_url": "https://arxiv.org/pdf/2507.05633v1",
    "published_date": "2025-07-08 03:29:09 UTC",
    "updated_date": "2025-07-08 03:29:09 UTC"
  },
  {
    "arxiv_id": "2507.05630v3",
    "title": "How Not to Detect Prompt Injections with an LLM",
    "authors": [
      "Sarthak Choudhary",
      "Divyam Anshumaan",
      "Nils Palumbo",
      "Somesh Jha"
    ],
    "abstract": "LLM-integrated applications and agents are vulnerable to prompt injection attacks, where adversaries embed malicious instructions within seemingly benign input data to manipulate the LLM's intended behavior. Recent defenses based on known-answer detection (KAD) scheme have reported near-perfect performance by observing an LLM's output to classify input data as clean or contaminated. KAD attempts to repurpose the very susceptibility to prompt injection as a defensive mechanism. We formally characterize the KAD scheme and uncover a structural vulnerability that invalidates its core security premise. To exploit this fundamental vulnerability, we methodically design an adaptive attack, DataFlip. It consistently evades KAD defenses, achieving detection rates as low as $0\\%$ while reliably inducing malicious behavior with a success rate of $91\\%$, all without requiring white-box access to the LLM or any optimization procedures.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.05630v3",
    "published_date": "2025-07-08 03:24:56 UTC",
    "updated_date": "2025-12-06 04:53:39 UTC"
  },
  {
    "arxiv_id": "2507.08842v1",
    "title": "Gradients as an Action: Towards Communication-Efficient Federated Recommender Systems via Adaptive Action Sharing",
    "authors": [
      "Zhufeng Lu",
      "Chentao Jia",
      "Ming Hu",
      "Xiaofei Xie",
      "Mingsong Chen"
    ],
    "abstract": "As a promising privacy-aware collaborative model training paradigm, Federated Learning (FL) is becoming popular in the design of distributed recommender systems. However, Federated Recommender Systems (FedRecs) greatly suffer from two major problems: i) extremely high communication overhead due to massive item embeddings involved in recommendation systems, and ii) intolerably low training efficiency caused by the entanglement of both heterogeneous network environments and client devices. Although existing methods attempt to employ various compression techniques to reduce communication overhead, due to the parameter errors introduced by model compression, they inevitably suffer from model performance degradation. To simultaneously address the above problems, this paper presents a communication-efficient FedRec framework named FedRAS, which adopts an action-sharing strategy to cluster the gradients of item embedding into a specific number of model updating actions for communication rather than directly compressing the item embeddings. In this way, the cloud server can use the limited actions from clients to update all the items. Since gradient values are significantly smaller than item embeddings, constraining the directions of gradients (i.e., the action space) introduces smaller errors compared to compressing the entire item embedding matrix into a reduced space. To accommodate heterogeneous devices and network environments, FedRAS incorporates an adaptive clustering mechanism that dynamically adjusts the number of actions. Comprehensive experiments on well-known datasets demonstrate that FedRAS can reduce the size of communication payloads by up to 96.88%, while not sacrificing recommendation performance within various heterogeneous scenarios. We have open-sourced FedRAS at https://github.com/mastlab-T3S/FedRAS.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "This paper has been accepted by ACM SIGKDD 2025",
    "pdf_url": "https://arxiv.org/pdf/2507.08842v1",
    "published_date": "2025-07-08 03:24:54 UTC",
    "updated_date": "2025-07-08 03:24:54 UTC"
  },
  {
    "arxiv_id": "2507.05629v2",
    "title": "Enhancing Student Learning with LLM-Generated Retrieval Practice Questions: An Empirical Study in Data Science Courses",
    "authors": [
      "Yuan An",
      "John Liu",
      "Niyam Acharya",
      "Ruhma Hashmi"
    ],
    "abstract": "Retrieval practice is a well-established pedagogical technique known to significantly enhance student learning and knowledge retention. However, generating high-quality retrieval practice questions is often time-consuming and labor intensive for instructors, especially in rapidly evolving technical subjects. Large Language Models (LLMs) offer the potential to automate this process by generating questions in response to prompts, yet the effectiveness of LLM-generated retrieval practice on student learning remains to be established. In this study, we conducted an empirical study involving two college-level data science courses, with approximately 60 students. We compared learning outcomes during one week in which students received LLM-generated multiple-choice retrieval practice questions to those from a week in which no such questions were provided. Results indicate that students exposed to LLM-generated retrieval practice achieved significantly higher knowledge retention, with an average accuracy of 89%, compared to 73% in the week without such practice. These findings suggest that LLM-generated retrieval questions can effectively support student learning and may provide a scalable solution for integrating retrieval practice into real-time teaching. However, despite these encouraging outcomes and the potential time-saving benefits, cautions must be taken, as the quality of LLM-generated questions can vary. Instructors must still manually verify and revise the generated questions before releasing them to students.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.05629v2",
    "published_date": "2025-07-08 03:23:19 UTC",
    "updated_date": "2025-07-29 14:11:25 UTC"
  },
  {
    "arxiv_id": "2507.06269v3",
    "title": "BayesSDF: Surface-Based Laplacian Uncertainty Estimation for 3D Geometry with Neural Signed Distance Fields",
    "authors": [
      "Rushil Desai"
    ],
    "abstract": "Accurate surface estimation is critical for downstream tasks in scientific simulation, and quantifying uncertainty in implicit neural 3D representations still remains a substantial challenge due to computational inefficiencies, scalability issues, and geometric inconsistencies. However, current neural implicit surface models do not offer a principled way to quantify uncertainty, limiting their reliability in real-world applications. Inspired by recent probabilistic rendering approaches, we introduce BayesSDF, a novel probabilistic framework for uncertainty estimation in neural implicit 3D representations. Unlike radiance-based models such as Neural Radiance Fields (NeRF) or 3D Gaussian Splatting, Signed Distance Functions (SDFs) provide continuous, differentiable surface representations, making them especially well-suited for uncertainty-aware modeling. BayesSDF applies a Laplace approximation over SDF weights and derives Hessian-based metrics to estimate local geometric instability. We empirically demonstrate that these uncertainty estimates correlate strongly with surface reconstruction error across both synthetic and real-world benchmarks. By enabling surface-aware uncertainty quantification, BayesSDF lays the groundwork for more robust, interpretable, and actionable 3D perception systems.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "ICCV 2025 Workshops (11 Pages, 6 Figures, 2 Tables)",
    "pdf_url": "https://arxiv.org/pdf/2507.06269v3",
    "published_date": "2025-07-08 03:21:12 UTC",
    "updated_date": "2025-09-04 18:52:33 UTC"
  },
  {
    "arxiv_id": "2507.05624v1",
    "title": "ADMC: Attention-based Diffusion Model for Missing Modalities Feature Completion",
    "authors": [
      "Wei Zhang",
      "Juan Chen",
      "Yanbo J. Wang",
      "En Zhu",
      "Xuan Yang",
      "Yiduo Wang"
    ],
    "abstract": "Multimodal emotion and intent recognition is essential for automated human-computer interaction, It aims to analyze users' speech, text, and visual information to predict their emotions or intent. One of the significant challenges is that missing modalities due to sensor malfunctions or incomplete data. Traditional methods that attempt to reconstruct missing information often suffer from over-coupling and imprecise generation processes, leading to suboptimal outcomes. To address these issues, we introduce an Attention-based Diffusion model for Missing Modalities feature Completion (ADMC). Our framework independently trains feature extraction networks for each modality, preserving their unique characteristics and avoiding over-coupling. The Attention-based Diffusion Network (ADN) generates missing modality features that closely align with authentic multimodal distribution, enhancing performance across all missing-modality scenarios. Moreover, ADN's cross-modal generation offers improved recognition even in full-modality contexts. Our approach achieves state-of-the-art results on the IEMOCAP and MIntRec benchmarks, demonstrating its effectiveness in both missing and complete modality scenarios.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.05624v1",
    "published_date": "2025-07-08 03:08:52 UTC",
    "updated_date": "2025-07-08 03:08:52 UTC"
  },
  {
    "arxiv_id": "2507.06268v3",
    "title": "A Collectivist, Economic Perspective on AI",
    "authors": [
      "Michael I. Jordan"
    ],
    "abstract": "Information technology is in the midst of a revolution in which omnipresent data collection and machine learning are impacting the human world as never before. The word ``intelligence'' is being used as a North Star for the development of this technology, with human cognition viewed as a baseline. This view neglects the fact that humans are social animals and that much of our intelligence is social and cultural in origin. Moreover, failing to properly situate aspects of intelligence at the social level contributes to the treatment of the societal consequences of technology as an afterthought. The path forward is not merely more data and compute, and not merely more attention paid to cognitive or symbolic representations, but a thorough blending of economic and social concepts with computational and inferential concepts at the level of algorithm design.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.06268v3",
    "published_date": "2025-07-08 03:07:43 UTC",
    "updated_date": "2025-12-15 10:39:01 UTC"
  },
  {
    "arxiv_id": "2507.05622v3",
    "title": "DATABench: Evaluating Dataset Auditing in Deep Learning from an Adversarial Perspective",
    "authors": [
      "Shuo Shao",
      "Yiming Li",
      "Mengren Zheng",
      "Zhiyang Hu",
      "Yukun Chen",
      "Boheng Li",
      "Yu He",
      "Junfeng Guo",
      "Dacheng Tao",
      "Zhan Qin"
    ],
    "abstract": "The widespread application of Deep Learning across diverse domains hinges critically on the quality and composition of training datasets. However, the common lack of disclosure regarding their usage raises significant privacy and copyright concerns. Dataset auditing techniques, which aim to determine if a specific dataset was used to train a given suspicious model, provide promising solutions to addressing these transparency gaps. While prior work has developed various auditing methods, their resilience against dedicated adversarial attacks remains largely unexplored. To bridge the gap, this paper initiates a comprehensive study evaluating dataset auditing from an adversarial perspective. We start with introducing a novel taxonomy, classifying existing methods based on their reliance on internal features (IF) (inherent to the data) versus external features (EF) (artificially introduced for auditing). Subsequently, we formulate two primary attack types: evasion attacks, designed to conceal the use of a dataset, and forgery attacks, intending to falsely implicate an unused dataset. Building on the understanding of existing methods and attack objectives, we further propose systematic attack strategies: decoupling, removal, and detection for evasion; adversarial example-based methods for forgery. These formulations and strategies lead to our new benchmark, DATABench, comprising 17 evasion attacks, 5 forgery attacks, and 9 representative auditing methods. Extensive evaluations using DATABench reveal that none of the evaluated auditing methods are sufficiently robust or distinctive under adversarial settings. These findings underscore the urgent need for developing a more secure and reliable dataset auditing method capable of withstanding sophisticated adversarial manipulation. Code is available in https://github.com/shaoshuo-ss/DATABench.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.05622v3",
    "published_date": "2025-07-08 03:07:15 UTC",
    "updated_date": "2025-12-14 02:12:05 UTC"
  },
  {
    "arxiv_id": "2507.08020v1",
    "title": "Circumventing Safety Alignment in Large Language Models Through Embedding Space Toxicity Attenuation",
    "authors": [
      "Zhibo Zhang",
      "Yuxi Li",
      "Kailong Wang",
      "Shuai Yuan",
      "Ling Shi",
      "Haoyu Wang"
    ],
    "abstract": "Large Language Models (LLMs) have achieved remarkable success across domains such as healthcare, education, and cybersecurity. However, this openness also introduces significant security risks, particularly through embedding space poisoning, which is a subtle attack vector where adversaries manipulate the internal semantic representations of input data to bypass safety alignment mechanisms. While previous research has investigated universal perturbation methods, the dynamics of LLM safety alignment at the embedding level remain insufficiently understood. Consequently, more targeted and accurate adversarial perturbation techniques, which pose significant threats, have not been adequately studied.\n  In this work, we propose ETTA (Embedding Transformation Toxicity Attenuation), a novel framework that identifies and attenuates toxicity-sensitive dimensions in embedding space via linear transformations. ETTA bypasses model refusal behaviors while preserving linguistic coherence, without requiring model fine-tuning or access to training data. Evaluated on five representative open-source LLMs using the AdvBench benchmark, ETTA achieves a high average attack success rate of 88.61%, outperforming the best baseline by 11.34%, and generalizes to safety-enhanced models (e.g., 77.39% ASR on instruction-tuned defenses). These results highlight a critical vulnerability in current alignment strategies and underscore the need for embedding-aware defenses.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.08020v1",
    "published_date": "2025-07-08 03:01:00 UTC",
    "updated_date": "2025-07-08 03:01:00 UTC"
  },
  {
    "arxiv_id": "2507.05613v3",
    "title": "Domain adaptation of large language models for geotechnical applications",
    "authors": [
      "Lei Fan",
      "Fangxue Liu",
      "Cheng Chen"
    ],
    "abstract": "The rapid advancement of large language models (LLMs) is transforming opportunities in geotechnical engineering, where workflows rely on complex, text-rich data. While general-purpose LLMs demonstrate strong reasoning capabilities, their effectiveness in geotechnical applications is constrained by limited exposure to specialized terminology and domain logic. Thus, domain adaptation, tailoring general LLMs for geotechnical use, has become essential. This paper presents the first systematic review of LLM adaptation and application in geotechnical contexts. It critically examines four key adaptation strategies, including prompt engineering, retrieval augmented generation, domain-adaptive pretraining, and fine-tuning, and evaluates their comparative benefits, limitations, and implementation trends. This review synthesizes current applications spanning geological interpretation, subsurface characterization, design analysis, numerical modeling, risk assessment, and geotechnical education. Findings show that domain-adapted LLMs substantially improve reasoning accuracy, automation, and interpretability, yet remain limited by data scarcity, validation challenges, and explainability concerns. Future research directions are also suggested. This review establishes a critical foundation for developing geotechnically literate LLMs and guides researchers and practitioners in advancing the digital transformation of geotechnical engineering.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.05613v3",
    "published_date": "2025-07-08 02:45:44 UTC",
    "updated_date": "2025-11-28 02:43:59 UTC"
  },
  {
    "arxiv_id": "2507.08841v2",
    "title": "Zero-Shot Neural Architecture Search with Weighted Response Correlation",
    "authors": [
      "Kun Jing",
      "Luoyu Chen",
      "Jungang Xu",
      "Jianwei Tai",
      "Yiyu Wang",
      "Shuaimin Li"
    ],
    "abstract": "Neural architecture search (NAS) is a promising approach for automatically designing neural network architectures. However, the architecture estimation of NAS is computationally expensive and time-consuming because of training multiple architectures from scratch. Although existing zero-shot NAS methods use training-free proxies to accelerate the architecture estimation, their effectiveness, stability, and generality are still lacking. We present a novel training-free estimation proxy called weighted response correlation (WRCor). WRCor utilizes correlation coefficient matrices of responses across different input samples to calculate the proxy scores of estimated architectures, which can measure their expressivity and generalizability. Experimental results on proxy evaluation demonstrate that WRCor and its voting proxies are more efficient estimation strategies than existing proxies. We also apply them with different search strategies in architecture search. Experimental results on architecture search show that our zero-shot NAS algorithm outperforms most existing NAS algorithms in different search spaces. Our NAS algorithm can discover an architecture with a 22.1% test error on the ImageNet-1k dataset within 4 GPU hours. All codes are publicly available at https://github.com/kunjing96/ZSNAS-WRCor.git.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.08841v2",
    "published_date": "2025-07-08 02:19:29 UTC",
    "updated_date": "2025-08-06 09:48:18 UTC"
  },
  {
    "arxiv_id": "2507.05598v1",
    "title": "Self-Review Framework for Enhancing Instruction Following Capability of LLM",
    "authors": [
      "Sihyun Park"
    ],
    "abstract": "Various techniques have been proposed to improve large language models (LLMs) adherence to formatting and instruction constraints. One of the most effective approaches involves utilizing high-quality data generated by powerful models. However, such models often fail to fully comply with complex instructions in a single generation. To address this limitation, iterative revision methods have been introduced. Nevertheless, as the number of data points and revision iterations increases, the associated monetary costs grow significantly. As a resource-efficient alternative, methods have been proposed that leverage high-performance evaluation tools to compensate for the limited self-evaluation capabilities of open-source LLMs. However, these approaches often lead to a degradation in output quality due to excessive revision. To overcome these challenges, we propose Re5, a self-evaluation and revision framework designed to enhance instruction-following performance while preserving the quality of the generated content. Re5 extracts task and constraint components from user instructions, performs structural evaluations to prevent error accumulation, and applies fine-grained constraint-specific content evaluations followed by selective revisions. This process ensures precise and quality-preserving improvements. The final high-quality outputs are used for alignment tuning, enabling long-term alignment improvements through a data-centric iterative refinement loop. Experimental results demonstrate that Re5 achieves instruction-following performance comparable to models trained on data generated by GPT-4o-mini, a high-performance model, even with a small amount of data while maintaining response quality with a 64.24%-win rate over the non-revised initial responses. These results validate Re5 as an efficient and effective solution for enhancing instruction adherence with minimal external supervision.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.05598v1",
    "published_date": "2025-07-08 02:17:18 UTC",
    "updated_date": "2025-07-08 02:17:18 UTC"
  },
  {
    "arxiv_id": "2507.05591v1",
    "title": "MLlm-DR: Towards Explainable Depression Recognition with MultiModal Large Language Models",
    "authors": [
      "Wei Zhang",
      "Juan Chen",
      "En Zhu",
      "Wenhong Cheng",
      "YunPeng Li",
      "Yanbo J. Wang"
    ],
    "abstract": "Automated depression diagnosis aims to analyze multimodal information from interview videos to predict participants' depression scores. Previous studies often lack clear explanations of how these scores were determined, limiting their adoption in clinical practice. While the advent of LLMs provides a possible pathway for explainable depression diagnosis, current LLMs capable of processing multimodal data lack training on interview data, resulting in poor diagnostic performance when used directly. In this paper, we propose a novel multimodal large language model (MLlm-DR) that can understand multimodal information inputs and supports explainable depression diagnosis. MLlm-DR integrates a smaller LLMs and a lightweight query module (LQ-former). Specifically, the smaller LLMs is designed to generate depression scores and corresponding evaluation rationales. To enhance its logical reasoning for domain-specific tasks while maintaining practicality, we constructed a robust training dataset to fine-tune it. Meanwhile, the LQ-former captures depression-related features from speech and visual data, aiding the model's ability to process multimodal information, to achieve comprehensive depression diagnosis. Our approach achieves state-of-the-art results on two interview-based benchmark datasets, CMDC and E-DAIC-WOZ, demonstrating its effectiveness and superiority.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.05591v1",
    "published_date": "2025-07-08 01:56:39 UTC",
    "updated_date": "2025-07-08 01:56:39 UTC"
  },
  {
    "arxiv_id": "2507.05587v1",
    "title": "Towards Measurement Theory for Artificial Intelligence",
    "authors": [
      "Elija Perrier"
    ],
    "abstract": "We motivate and outline a programme for a formal theory of measurement of artificial intelligence. We argue that formalising measurement for AI will allow researchers, practitioners, and regulators to: (i) make comparisons between systems and the evaluation methods applied to them; (ii) connect frontier AI evaluations with established quantitative risk analysis techniques drawn from engineering and safety science; and (iii) foreground how what counts as AI capability is contingent upon the measurement operations and scales we elect to use. We sketch a layered measurement stack, distinguish direct from indirect observables, and signpost how these ingredients provide a pathway toward a unified, calibratable taxonomy of AI phenomena.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Under review for Iliad Conference 2025",
    "pdf_url": "https://arxiv.org/pdf/2507.05587v1",
    "published_date": "2025-07-08 01:52:37 UTC",
    "updated_date": "2025-07-08 01:52:37 UTC"
  },
  {
    "arxiv_id": "2507.05584v1",
    "title": "The Fourier Spectral Transformer Networks For Efficient and Generalizable Nonlinear PDEs Prediction",
    "authors": [
      "Beibei Li"
    ],
    "abstract": "In this work we propose a unified Fourier Spectral Transformer network that integrates the strengths of classical spectral methods and attention based neural architectures. By transforming the original PDEs into spectral ordinary differential equations, we use high precision numerical solvers to generate training data and use a Transformer network to model the evolution of the spectral coefficients. We demonstrate the effectiveness of our approach on the two dimensional incompressible Navier-Stokes equations and the one dimensional Burgers' equation. The results show that our spectral Transformer can achieve highly accurate long term predictions even with limited training data, better than traditional numerical methods and machine learning methods in forecasting future flow dynamics. The proposed framework generalizes well to unseen data, bringing a promising paradigm for real time prediction and control of complex dynamical systems.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.05584v1",
    "published_date": "2025-07-08 01:43:33 UTC",
    "updated_date": "2025-07-08 01:43:33 UTC"
  },
  {
    "arxiv_id": "2507.05573v1",
    "title": "Prompt Migration: Stabilizing GenAI Applications with Evolving Large Language Models",
    "authors": [
      "Shivani Tripathi",
      "Pushpanjali Nema",
      "Aditya Halder",
      "Shi Qiao",
      "Alekh Jindal"
    ],
    "abstract": "Generative AI is transforming business applications by enabling natural language interfaces and intelligent automation. However, the underlying large language models (LLMs) are evolving rapidly and so prompting them consistently is a challenge. This leads to inconsistent and unpredictable application behavior, undermining the reliability that businesses require for mission-critical workflows. In this paper, we introduce the concept of prompt migration as a systematic approach to stabilizing GenAI applications amid changing LLMs. Using the Tursio enterprise search application as a case study, we analyze the impact of successive GPT model upgrades, detail our migration framework including prompt redesign and a migration testbed, and demonstrate how these techniques restore application consistency. Our results show that structured prompt migration can fully recover the application reliability that was lost due to model drift. We conclude with practical lessons learned, emphasizing the need for prompt lifecycle management and robust testing to ensure dependable GenAI-powered business applications.",
    "categories": [
      "cs.DB",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.DB",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.05573v1",
    "published_date": "2025-07-08 01:20:12 UTC",
    "updated_date": "2025-07-08 01:20:12 UTC"
  },
  {
    "arxiv_id": "2507.05566v1",
    "title": "SingLoRA: Low Rank Adaptation Using a Single Matrix",
    "authors": [
      "David Bensaïd",
      "Noam Rotstein",
      "Roy Velich",
      "Daniel Bensaïd",
      "Ron Kimmel"
    ],
    "abstract": "Low-Rank Adaptation (LoRA) has significantly advanced parameter-efficient fine-tuning of large pretrained models. LoRA augments the pre-trained weights of a model by adding the product of two smaller matrices that together form a low-rank matrix update. Recent research has shown that scale disparities between these two matrices often cause unstable training dynamics, leading to suboptimal performance. In this paper, we propose SingLoRA, which reformulates low-rank adaptation by learning the weights update as a decomposition of a single low-rank matrix multiplied by its transpose. This simple design inherently removes inter-matrix scale conflicts, ensuring stable optimization, and roughly halves the parameter count. We analyze SingLoRA within the infinite-width neural network framework, showing that it guarantees stable feature learning by construction. Extensive experiments on multiple tasks validate these benefits. In common sense reasoning, fine-tuning LLama 7B on MNLI with SingLoRA achieves 91.3% accuracy - surpassing LoRA (89.1%) and LoRA+ (90.2%) - while using only 60% of their parameter budget. In image generation, fine-tuning Stable Diffusion with SingLoRA significantly improves image fidelity on DreamBooth, achieving a DINO similarity score of 0.151, compared to scores of 0.148 and 0.143 for DoRA and LoRA, respectively.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.05566v1",
    "published_date": "2025-07-08 01:11:30 UTC",
    "updated_date": "2025-07-08 01:11:30 UTC"
  },
  {
    "arxiv_id": "2507.05565v1",
    "title": "Search-based Selection of Metamorphic Relations for Optimized Robustness Testing of Large Language Models",
    "authors": [
      "Sangwon Hyun",
      "Shaukat Ali",
      "M. Ali Babar"
    ],
    "abstract": "Assessing the trustworthiness of Large Language Models (LLMs), such as robustness, has garnered significant attention. Recently, metamorphic testing that defines Metamorphic Relations (MRs) has been widely applied to evaluate the robustness of LLM executions. However, the MR-based robustness testing still requires a scalable number of MRs, thereby necessitating the optimization of selecting MRs. Most extant LLM testing studies are limited to automatically generating test cases (i.e., MRs) to enhance failure detection. Additionally, most studies only considered a limited test space of single perturbation MRs in their evaluation of LLMs. In contrast, our paper proposes a search-based approach for optimizing the MR groups to maximize failure detection and minimize the LLM execution cost. Moreover, our approach covers the combinatorial perturbations in MRs, facilitating the expansion of test space in the robustness assessment. We have developed a search process and implemented four search algorithms: Single-GA, NSGA-II, SPEA2, and MOEA/D with novel encoding to solve the MR selection problem in the LLM robustness testing. We conducted comparative experiments on the four search algorithms along with a random search, using two major LLMs with primary Text-to-Text tasks. Our statistical and empirical investigation revealed two key findings: (1) the MOEA/D algorithm performed the best in optimizing the MR space for LLM robustness testing, and (2) we identified silver bullet MRs for the LLM robustness testing, which demonstrated dominant capabilities in confusing LLMs across different Text-to-Text tasks. In LLM robustness assessment, our research sheds light on the fundamental problem for optimized testing and provides insights into search-based solutions.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.05565v1",
    "published_date": "2025-07-08 01:11:27 UTC",
    "updated_date": "2025-07-08 01:11:27 UTC"
  },
  {
    "arxiv_id": "2507.05559v1",
    "title": "MP-ALOE: An r2SCAN dataset for universal machine learning interatomic potentials",
    "authors": [
      "Matthew C. Kuner",
      "Aaron D. Kaplan",
      "Kristin A. Persson",
      "Mark Asta",
      "Daryl C. Chrzan"
    ],
    "abstract": "We present MP-ALOE, a dataset of nearly 1 million DFT calculations using the accurate r2SCAN meta-generalized gradient approximation. Covering 89 elements, MP-ALOE was created using active learning and primarily consists of off-equilibrium structures. We benchmark a machine learning interatomic potential trained on MP-ALOE, and evaluate its performance on a series of benchmarks, including predicting the thermochemical properties of equilibrium structures; predicting forces of far-from-equilibrium structures; maintaining physical soundness under static extreme deformations; and molecular dynamic stability under extreme temperatures and pressures. MP-ALOE shows strong performance on all of these benchmarks, and is made public for the broader community to utilize.",
    "categories": [
      "cond-mat.mtrl-sci",
      "cs.AI",
      "physics.comp-ph"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "comment": "To download the dataset and associated files, see https://doi.org/10.6084/m9.figshare.29452190",
    "pdf_url": "https://arxiv.org/pdf/2507.05559v1",
    "published_date": "2025-07-08 00:45:32 UTC",
    "updated_date": "2025-07-08 00:45:32 UTC"
  },
  {
    "arxiv_id": "2507.05558v4",
    "title": "AI Agent Smart Contract Exploit Generation",
    "authors": [
      "Arthur Gervais",
      "Liyi Zhou"
    ],
    "abstract": "Smart contract vulnerabilities have led to billions in losses, yet finding actionable exploits remains challenging. Traditional fuzzers rely on rigid heuristics and struggle with complex attacks, while human auditors are thorough but slow and don't scale. Large Language Models offer a promising middle ground, combining human-like reasoning with machine speed.\n  Early studies show that simply prompting LLMs generates unverified vulnerability speculations with high false positive rates. To address this, we present A1, an agentic system that transforms any LLM into an end-to-end exploit generator. A1 provides agents with six domain-specific tools for autonomous vulnerability discovery, from understanding contract behavior to testing strategies on real blockchain states. All outputs are concretely validated through execution, ensuring only profitable proof-of-concept exploits are reported. We evaluate A1 across 36 real-world vulnerable contracts on Ethereum and Binance Smart Chain. A1 achieves a 63% success rate on the VERITE benchmark. Across all successful cases, A1 extracts up to \\$8.59 million per exploit and \\$9.33 million total.\n  Using Monte Carlo analysis of historical attacks, we demonstrate that immediate vulnerability detection yields 86-89% success probability, dropping to 6-21% with week-long delays. Our economic analysis reveals a troubling asymmetry: attackers achieve profitability at \\$6,000 exploit values while defenders require \\$60,000 -- raising fundamental questions about whether AI agents inevitably favor exploitation over defense.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.05558v4",
    "published_date": "2025-07-08 00:45:26 UTC",
    "updated_date": "2026-01-12 07:14:17 UTC"
  },
  {
    "arxiv_id": "2507.06266v1",
    "title": "Machine Learning based Enterprise Financial Audit Framework and High Risk Identification",
    "authors": [
      "Tingyu Yuan",
      "Xi Zhang",
      "Xuanjing Chen"
    ],
    "abstract": "In the face of global economic uncertainty, financial auditing has become essential for regulatory compliance and risk mitigation. Traditional manual auditing methods are increasingly limited by large data volumes, complex business structures, and evolving fraud tactics. This study proposes an AI-driven framework for enterprise financial audits and high-risk identification, leveraging machine learning to improve efficiency and accuracy. Using a dataset from the Big Four accounting firms (EY, PwC, Deloitte, KPMG) from 2020 to 2025, the research examines trends in risk assessment, compliance violations, and fraud detection. The dataset includes key indicators such as audit project counts, high-risk cases, fraud instances, compliance breaches, employee workload, and client satisfaction, capturing both audit behaviors and AI's impact on operations. To build a robust risk prediction model, three algorithms - Support Vector Machine (SVM), Random Forest (RF), and K-Nearest Neighbors (KNN) - are evaluated. SVM uses hyperplane optimization for complex classification, RF combines decision trees to manage high-dimensional, nonlinear data with resistance to overfitting, and KNN applies distance-based learning for flexible performance. Through hierarchical K-fold cross-validation and evaluation using F1-score, accuracy, and recall, Random Forest achieves the best performance, with an F1-score of 0.9012, excelling in identifying fraud and compliance anomalies. Feature importance analysis reveals audit frequency, past violations, employee workload, and client ratings as key predictors. The study recommends adopting Random Forest as a core model, enhancing features via engineering, and implementing real-time risk monitoring. This research contributes valuable insights into using machine learning for intelligent auditing and risk management in modern enterprises.",
    "categories": [
      "q-fin.RM",
      "cs.AI",
      "cs.LG",
      "stat.AP"
    ],
    "primary_category": "q-fin.RM",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.06266v1",
    "published_date": "2025-07-08 00:22:49 UTC",
    "updated_date": "2025-07-08 00:22:49 UTC"
  },
  {
    "arxiv_id": "2507.05549v1",
    "title": "The Ethical Implications of AI in Creative Industries: A Focus on AI-Generated Art",
    "authors": [
      "Prerana Khatiwada",
      "Joshua Washington",
      "Tyler Walsh",
      "Ahmed Saif Hamed",
      "Lokesh Bhatta"
    ],
    "abstract": "As Artificial Intelligence (AI) continues to grow daily, more exciting (and somewhat controversial) technology emerges every other day. As we see the advancements in AI, we see more and more people becoming skeptical of it. This paper explores the complications and confusion around the ethics of generative AI art. We delve deep into the ethical side of AI, specifically generative art. We step back from the excitement and observe the impossible conundrums that this impressive technology produces. Covering environmental consequences, celebrity representation, intellectual property, deep fakes, and artist displacement. Our research found that generative AI art is responsible for increased carbon emissions, spreading misinformation, copyright infringement, unlawful depiction, and job displacement. In light of this, we propose multiple possible solutions for these problems. We address each situation's history, cause, and consequences and offer different viewpoints. At the root of it all, though, the central theme is that generative AI Art needs to be correctly legislated and regulated.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CY",
    "comment": "7 pages",
    "pdf_url": "https://arxiv.org/pdf/2507.05549v1",
    "published_date": "2025-07-08 00:16:38 UTC",
    "updated_date": "2025-07-08 00:16:38 UTC"
  }
]