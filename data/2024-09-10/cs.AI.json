{
  "date": "2024-09-10",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-09-10 的 arXiv 中文 TLDR 快报！今天 arXiv 更新了 87 篇论文，主要聚焦 AI 模型优化、多模态学习和医疗应用等领域，其中 LLMs 在科学知识合成和数学问题解决上的超人表现（如 Samuel G. Rodriques 等学者的作品）最为令人印象深刻，同时强调了 AI 在实际部署中的鲁棒性和安全性。\n\n下面，我将挑选几篇重要的、话题度高的论文优先讨论，包括那些涉及著名学者或创新基准的（如 LLMs 和多模态模型），并将相关论文归类讨论。对于其他较常规或非核心论文，我会快速掠过，只简要列出标题和关键点，以控制篇幅。\n\n### 重点论文讨论\n\n**1. Language agents achieve superhuman synthesis of scientific knowledge（语言代理实现超人科学知识合成）**  \n这篇论文由 Samuel G. Rodriques 等著名学者主导，探讨了大型语言模型（LLMs）在科学文献分析中的潜力。主要贡献是通过 PaperQA2 框架，使用 LLMs 匹配或超越人类专家在信息检索和总结任务上的表现，发现模型能生成更准确的科学摘要，并识别文献矛盾（70% 验证准确）。这为 AI 在科研中的应用提供了新洞见，强调了 LLMs 的超人能力，但也暴露了潜在局限。\n\n**2. MathGLM-Vision: Solving Mathematical Problems with Multi-Modal Large Language Model（MathGLM-Vision: 使用多模态大型语言模型解决数学问题）**  \n这篇工作构建了 MathGLM-Vision 模型，针对多模态 AI 在数学领域的应用。关键发现是通过 Supervised Fine-Tuning（SFT）在多样化数据集上训练，模型显著提升了数学问题解决的准确性，尤其在几何和代数任务上，超越了现有开源模型。该论文与另一篇 \"VisScience: An Extensive Benchmark for Evaluating K12 Educational Multi-modal Scientific Reasoning\"（VisScience: 评估 K12 教育多模态科学推理的广泛基准）相关，后者提供了全面基准，评估了 25 个 MLLMs 在数学、物理和化学上的表现，揭示了模型在科学推理中的优势和不足。两者共同推动了教育 AI 的发展。\n\n**3. ProteinBench: A Holistic Evaluation of Protein Foundation Models（ProteinBench: 蛋白质基础模型的整体评估）**  \n作者包括 Quanquan Gu 等，该论文提出了 ProteinBench 框架，用于全面评估蛋白质基础模型。贡献在于分类任务、引入多指标（如质量、新颖性和鲁棒性），实验显示模型在蛋白结构预测和生成任务上表现出色，为 AI 在生物医学中的应用提供了标准化基准。该工作与医疗 AI 主题相关，突出了模型在复杂科学任务中的潜力。\n\n**4. HexaCoder: Secure Code Generation via Oracle-Guided Synthetic Training Data（HexaCoder: 通过 Oracle 引导的合成训练数据实现安全代码生成）**  \n这篇论文聚焦 AI 安全，作者 Hossein Hajipour 等开发了 HexaCoder 方法，使用合成数据和集成学习减少代码漏洞。关键发现是，该方法在代码生成任务中降低了漏洞率（比基线高 85%），并在实际数据集上验证了鲁棒性。这与 AI 安全话题高度相关，强调了在软件开发中防范恶意生成的必要性。\n\n### 相关论文快速掠过\n以下是其他论文的简要总结，我优先选择了与上述主题相关的（如 AI 生成和医疗），并快速掠过较无聊或次要的（如音乐或物理建模）。对于每篇，我只列出标题（中文 + 英文）和核心贡献。\n\n- **AI 和 LLMs 相关（续）**  \n  - \"DiPT: Enhancing LLM reasoning through diversified perspective-taking（DiPT: 通过多样化视角提升 LLM 推理）\"：引入视角多样化机制，提升 LLM 在复杂任务中的推理稳定性和准确性。  \n  - \"RNR: Teaching Large Language Models to Follow Roles and Rules（RNR: 教大型语言模型遵循角色和规则）\"：提出数据生成框架，让 LLMs 更好地遵守系统提示，提高部署安全性。  \n  - \"LAMP: Learnable Meta-Path Guided Adversarial Contrastive Learning for Heterogeneous Graphs（LAMP: 学习型元路径引导的对抗对比学习用于异构图）\"：开发 LAMP 模型，提升异构图上的无监督学习性能，F1 分数较基线提升 19.6%。  \n\n- **医疗和生物应用**  \n  - \"CerviXpert: A Multi-Structural Convolutional Neural Network for Predicting Cervix Type and Cervical Cell Abnormalities（CerviXpert: 用于预测子宫颈类型和细胞异常的多结构卷积神经网络）\"：构建高效 CNN 模型，子宫颈癌检测准确率达 98%，优于 ResNet50 等基准。  \n  - \"Texture-AD: An Anomaly Detection Dataset and Benchmark for Real Algorithm Development（Texture-AD: 用于真实算法开发的异常检测数据集和基准）\"：发布新数据集，提升工业缺陷检测的鲁棒性，适用于 AI 在制造中的应用。  \n\n- **其他领域快速总结**  \n  其余论文如 \"Sines, Transient, Noise Neural Modeling of Piano Notes（钢琴音符的正弦、瞬态和噪声神经建模）\" 和 \"Modeling Image Tone Dichotomy with the Power Function（使用幂函数建模图像色调二分法）\" 等，聚焦音乐和图像处理，仅贡献了新模型或方法，但话题度较低，故快速掠过；它们在特定领域（如音频建模）有小幅改进，但对主流 AI 研究影响有限。\n\n今天的 arXiv 更新突显了 AI 在科学和医疗中的潜力，但也提醒我们关注模型的鲁棒性和伦理问题。感兴趣的读者可查阅具体论文深入探索！",
  "papers": [
    {
      "arxiv_id": "2409.06916v1",
      "title": "Interactive Counterfactual Exploration of Algorithmic Harms in Recommender Systems",
      "title_zh": "交互式反事实探索推荐系统中的算法危害",
      "authors": [
        "Yongsu Ahn",
        "Quinn K Wolter",
        "Jonilyn Dick",
        "Janet Dick",
        "Yu-Ru Lin"
      ],
      "abstract": "Recommender systems have become integral to digital experiences, shaping user\ninteractions and preferences across various platforms. Despite their widespread\nuse, these systems often suffer from algorithmic biases that can lead to unfair\nand unsatisfactory user experiences. This study introduces an interactive tool\ndesigned to help users comprehend and explore the impacts of algorithmic harms\nin recommender systems. By leveraging visualizations, counterfactual\nexplanations, and interactive modules, the tool allows users to investigate how\nbiases such as miscalibration, stereotypes, and filter bubbles affect their\nrecommendations. Informed by in-depth user interviews, this tool benefits both\ngeneral users and researchers by increasing transparency and offering\npersonalized impact assessments, ultimately fostering a better understanding of\nalgorithmic biases and contributing to more equitable recommendation outcomes.\nThis work provides valuable insights for future research and practical\napplications in mitigating bias and enhancing fairness in machine learning\nalgorithms.",
      "tldr_zh": "本研究探讨了推荐系统中的算法偏见（algorithmic biases），如 miscalibration、stereotypes 和 filter bubbles，这些偏见可能导致不公平的用户体验。研究团队开发了一个交互式工具，利用 visualizations、counterfactual explanations 和交互模块，让用户探索这些偏见对推荐的影响。基于用户访谈，该工具提升了透明度，提供个性化影响评估，帮助一般用户和研究人员更好地理解算法偏见，并为缓解偏见和提升推荐公平性提供实用见解。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.06916v1",
      "published_date": "2024-09-10 23:58:27 UTC",
      "updated_date": "2024-09-10 23:58:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:41:04.204978"
    },
    {
      "arxiv_id": "2409.06912v3",
      "title": "A Bayesian Framework for Active Tactile Object Recognition, Pose Estimation and Shape Transfer Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Haodong Zheng",
        "Andrei Jalba",
        "Raymond H. Cuijpers",
        "Wijnand IJsselsteijn",
        "Sanne Schoenmakers"
      ],
      "abstract": "As humans can explore and understand the world through active touch, similar\ncapability is desired for robots. In this paper, we address the problem of\nactive tactile object recognition, pose estimation and shape transfer learning,\nwhere a customized particle filter (PF) and Gaussian process implicit surface\n(GPIS) is combined in a unified Bayesian framework. Upon new tactile input, the\ncustomized PF updates the joint distribution of the object class and object\npose while tracking the novelty of the object. Once a novel object is\nidentified, its shape will be reconstructed using GPIS. By grounding the prior\nof the GPIS with the maximum-a-posteriori (MAP) estimation from the PF, the\nknowledge about known shapes can be transferred to learn novel shapes. An\nexploration procedure based on global shape estimation is proposed to guide\nactive data acquisition and terminate the exploration upon sufficient\ninformation. Through experiments in simulation, the proposed framework\ndemonstrated its effectiveness and efficiency in estimating object class and\npose for known objects and learning novel shapes. Furthermore, it can recognize\npreviously learned shapes reliably.",
      "tldr_zh": "本研究提出了一种统一的贝叶斯框架，用于主动触觉物体识别、位姿估计和形状转移学习，结合了定制的粒子滤波器 (PF) 和高斯过程隐式表面 (GPIS)。框架通过 PF 更新新触觉输入下的物体类别、位姿联合分布，并跟踪物体新奇性；一旦识别出新物体，便使用 GPIS 重建其形状，并通过 PF 的最大后验估计 (MAP) 转移已知形状的知识。基于全局形状估计的探索过程被设计来指导主动数据采集，并在信息足够时终止探索。模拟实验证明，该框架在处理已知物体类别和位姿估计方面高效有效，并能可靠地学习和识别新形状。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.06912v3",
      "published_date": "2024-09-10 23:35:30 UTC",
      "updated_date": "2024-10-11 09:49:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:41:17.039167"
    },
    {
      "arxiv_id": "2409.16307v1",
      "title": "DeepScore: A Comprehensive Approach to Measuring Quality in AI-Generated Clinical Documentation",
      "title_zh": "DeepScore",
      "authors": [
        "Jon Oleson"
      ],
      "abstract": "Medical practitioners are rapidly adopting generative AI solutions for\nclinical documentation, leading to significant time savings and reduced stress.\nHowever, evaluating the quality of AI-generated documentation is a complex and\nongoing challenge. This paper presents an overview of DeepScribe's\nmethodologies for assessing and managing note quality, focusing on various\nmetrics and the composite \"DeepScore\", an overall index of quality and\naccuracy. These methodologies aim to enhance the quality of patient care\ndocumentation through accountability and continuous improvement.",
      "tldr_zh": "该研究探讨了生成式AI在临床文档生成中的应用，虽然能节省时间并减轻医疗从业者的压力，但评估文档质量仍面临复杂挑战。论文概述了DeepScribe的评估方法，包括多种指标和综合指数“DeepScore”，用于衡量AI生成文档的质量与准确性。这些方法通过引入问责机制和持续改进，帮助提升患者护理文档的整体质量。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "stat.AP"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages, 5 figures, 6 tables",
      "pdf_url": "http://arxiv.org/pdf/2409.16307v1",
      "published_date": "2024-09-10 23:06:48 UTC",
      "updated_date": "2024-09-10 23:06:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:41:27.562817"
    },
    {
      "arxiv_id": "2409.06904v1",
      "title": "Applied Federated Model Personalisation in the Industrial Domain: A Comparative Study",
      "title_zh": "工业领域中",
      "authors": [
        "Ilias Siniosoglou",
        "Vasileios Argyriou",
        "George Fragulis",
        "Panagiotis Fouliras",
        "Georgios Th. Papadopoulos",
        "Anastasios Lytos",
        "Panagiotis Sarigiannidis"
      ],
      "abstract": "The time-consuming nature of training and deploying complicated Machine and\nDeep Learning (DL) models for a variety of applications continues to pose\nsignificant challenges in the field of Machine Learning (ML). These challenges\nare particularly pronounced in the federated domain, where optimizing models\nfor individual nodes poses significant difficulty. Many methods have been\ndeveloped to tackle this problem, aiming to reduce training expenses and time\nwhile maintaining efficient optimisation. Three suggested strategies to tackle\nthis challenge include Active Learning, Knowledge Distillation, and Local\nMemorization. These methods enable the adoption of smaller models that require\nfewer computational resources and allow for model personalization with local\ninsights, thereby improving the effectiveness of current models. The present\nstudy delves into the fundamental principles of these three approaches and\nproposes an advanced Federated Learning System that utilises different\nPersonalisation methods towards improving the accuracy of AI models and\nenhancing user experience in real-time NG-IoT applications, investigating the\nefficacy of these techniques in the local and federated domain. The results of\nthe original and optimised models are then compared in both local and federated\ncontexts using a comparison analysis. The post-analysis shows encouraging\noutcomes when it comes to optimising and personalising the models with the\nsuggested techniques.",
      "tldr_zh": "这篇论文探讨了在工业领域应用联邦学习(Federated Learning)模型个性化的挑战，针对复杂机器学习(ML)和深度学习(DL)模型的训练和部署问题，比较了三种策略：Active Learning、Knowledge Distillation 和 Local Memorization，以减少计算资源消耗并实现模型个性化。研究提出一个先进的Federated Learning System，利用这些方法来提升AI模型的准确性和实时NG-IoT应用的用户体验。实验结果显示，在本地和联邦环境中优化后的模型表现出色，显著改善了模型性能和个性化效果。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.PF"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.06904v1",
      "published_date": "2024-09-10 23:00:19 UTC",
      "updated_date": "2024-09-10 23:00:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:41:41.091229"
    },
    {
      "arxiv_id": "2409.06892v1",
      "title": "Formative Study for AI-assisted Data Visualization",
      "title_zh": "AI辅助数据可视化的形成性研究",
      "authors": [
        "Rania Saber",
        "Anna Fariha"
      ],
      "abstract": "This formative study investigates the impact of data quality on AI-assisted\ndata visualizations, focusing on how uncleaned datasets influence the outcomes\nof these tools. By generating visualizations from datasets with inherent\nquality issues, the research aims to identify and categorize the specific\nvisualization problems that arise. The study further explores potential methods\nand tools to address these visualization challenges efficiently and\neffectively. Although tool development has not yet been undertaken, the\nfindings emphasize enhancing AI visualization tools to handle flawed data\nbetter. This research underscores the critical need for more robust,\nuser-friendly solutions that facilitate quicker and easier correction of data\nand visualization errors, thereby improving the overall reliability and\nusability of AI-assisted data visualization processes.",
      "tldr_zh": "这篇论文通过形式化研究，探讨了数据质量对 AI-assisted Data Visualization 的影响，重点分析未清理数据集如何导致可视化问题。研究方法包括使用有缺陷的数据生成可视化，并识别及分类这些问题，同时探索潜在的解决方法和工具。结果强调了开发更 robust 和用户友好的解决方案的必要性，以更快地修正数据和可视化错误，从而提升 AI 辅助数据可视化的可靠性和可用性。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.06892v1",
      "published_date": "2024-09-10 22:20:28 UTC",
      "updated_date": "2024-09-10 22:20:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:41:52.271034"
    },
    {
      "arxiv_id": "2409.06883v1",
      "title": "A Dataset for Evaluating LLM-based Evaluation Functions for Research Question Extraction Task",
      "title_zh": "翻译失败",
      "authors": [
        "Yuya Fujisaki",
        "Shiro Takagi",
        "Hideki Asoh",
        "Wataru Kumagai"
      ],
      "abstract": "The progress in text summarization techniques has been remarkable. However\nthe task of accurately extracting and summarizing necessary information from\nhighly specialized documents such as research papers has not been sufficiently\ninvestigated. We are focusing on the task of extracting research questions (RQ)\nfrom research papers and construct a new dataset consisting of machine learning\npapers, RQ extracted from these papers by GPT-4, and human evaluations of the\nextracted RQ from multiple perspectives. Using this dataset, we systematically\ncompared recently proposed LLM-based evaluation functions for summarizations,\nand found that none of the functions showed sufficiently high correlations with\nhuman evaluations. We expect our dataset provides a foundation for further\nresearch on developing better evaluation functions tailored to the RQ\nextraction task, and contribute to enhance the performance of the task. The\ndataset is available at https://github.com/auto-res/PaperRQ-HumanAnno-Dataset.",
      "tldr_zh": "本研究构建了一个新数据集，用于评估基于LLM的评价函数在研究问题(RQ)提取任务中的表现。该数据集包含机器学习论文、由GPT-4提取的RQ，以及从多个角度的人类评估。通过系统比较最近提出的LLM-based评价函数，发现这些函数与人类评估的相关性均不足。该数据集可作为基础，促进开发更有效的评价函数，并提升RQ提取任务的整体性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.06883v1",
      "published_date": "2024-09-10 21:54:46 UTC",
      "updated_date": "2024-09-10 21:54:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:42:04.748826"
    },
    {
      "arxiv_id": "2409.06859v2",
      "title": "NSP: A Neuro-Symbolic Natural Language Navigational Planner",
      "title_zh": "翻译失败",
      "authors": [
        "William English",
        "Dominic Simon",
        "Sumit Jha",
        "Rickard Ewetz"
      ],
      "abstract": "Path planners that can interpret free-form natural language instructions hold\npromise to automate a wide range of robotics applications. These planners\nsimplify user interactions and enable intuitive control over complex\nsemi-autonomous systems. While existing symbolic approaches offer guarantees on\nthe correctness and efficiency, they struggle to parse free-form natural\nlanguage inputs. Conversely, neural approaches based on pre-trained Large\nLanguage Models (LLMs) can manage natural language inputs but lack performance\nguarantees. In this paper, we propose a neuro-symbolic framework for path\nplanning from natural language inputs called NSP. The framework leverages the\nneural reasoning abilities of LLMs to i) craft symbolic representations of the\nenvironment and ii) a symbolic path planning algorithm. Next, a solution to the\npath planning problem is obtained by executing the algorithm on the environment\nrepresentation. The framework uses a feedback loop from the symbolic execution\nenvironment to the neural generation process to self-correct syntax errors and\nsatisfy execution time constraints. We evaluate our neuro-symbolic approach\nusing a benchmark suite with 1500 path-planning problems. The experimental\nevaluation shows that our neuro-symbolic approach produces 90.1% valid paths\nthat are on average 19-77% shorter than state-of-the-art neural approaches.",
      "tldr_zh": "该论文提出NSP，一种Neuro-Symbolic框架，用于从自然语言输入实现路径规划，旨在结合符号方法（symbolic approaches）的正确性和效率与神经方法（基于LLMs）的语言处理能力。框架利用LLMs生成环境的符号表示和路径规划算法，并通过反馈循环从符号执行环境中修正语法错误和优化执行时间。实验评估在1500个路径规划问题基准上显示，NSP生成90.1%的有效路径，比最先进神经方法平均短19-77%。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages, Preprint of paper accepted at 23rd International Conference\n  on Machine Learning and Applications (ICMLA) 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.06859v2",
      "published_date": "2024-09-10 20:49:05 UTC",
      "updated_date": "2024-09-13 22:13:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:42:17.115720"
    },
    {
      "arxiv_id": "2409.17158v1",
      "title": "Cross Dataset Analysis and Network Architecture Repair for Autonomous Car Lane Detection",
      "title_zh": "跨数据集分析和网络架构修复用于自动驾驶汽车车道检测",
      "authors": [
        "Parth Ganeriwala",
        "Siddhartha Bhattacharyya",
        "Raja Muthalagu"
      ],
      "abstract": "Transfer Learning has become one of the standard methods to solve problems to\novercome the isolated learning paradigm by utilizing knowledge acquired for one\ntask to solve another related one. However, research needs to be done, to\nidentify the initial steps before inducing transfer learning to applications\nfor further verification and explainablity. In this research, we have performed\ncross dataset analysis and network architecture repair for the lane detection\napplication in autonomous vehicles. Lane detection is an important aspect of\nautonomous vehicles driving assistance system. In most circumstances, modern\ndeep-learning-based lane recognition systems are successful, but they struggle\nwith lanes with complex topologies. The proposed architecture, ERFCondLaneNet\nis an enhancement to the CondlaneNet used for lane identification framework to\nsolve the difficulty of detecting lane lines with complex topologies like\ndense, curved and fork lines. The newly proposed technique was tested on two\ncommon lane detecting benchmarks, CULane and CurveLanes respectively, and two\ndifferent backbones, ResNet and ERFNet. The researched technique with\nERFCondLaneNet, exhibited similar performance in comparison to\nResnetCondLaneNet, while using 33% less features, resulting in a reduction of\nmodel size by 46%.",
      "tldr_zh": "该研究探讨了迁移学习(Transfer Learning)在自动驾驶汽车车道检测中的应用，通过进行跨数据集分析和网络架构修复来提升模型的鲁棒性。针对复杂拓扑的车道线（如密集、弯曲和分叉线），研究提出ERFCondLaneNet作为CondLaneNet的增强版本，使用ResNet和ERFNet作为backbone。实验在CULane和CurveLanes数据集上进行，结果显示ERFCondLaneNet的性能与ResNetCondLaneNet相当，但仅使用33%的特征，模型大小减少46%，从而提高了效率和可解释性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.17158v1",
      "published_date": "2024-09-10 20:27:49 UTC",
      "updated_date": "2024-09-10 20:27:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:42:28.910713"
    },
    {
      "arxiv_id": "2409.06851v3",
      "title": "LIME: Less Is More for MLLM Evaluation",
      "title_zh": "翻译失败",
      "authors": [
        "King Zhu",
        "Qianbo Zang",
        "Shian Jia",
        "Siwei Wu",
        "Feiteng Fang",
        "Yizhi Li",
        "Shawn Gavin",
        "Tuney Zheng",
        "Jiawei Guo",
        "Bo Li",
        "Haoning Wu",
        "Xingwei Qu",
        "Jian Yang",
        "Zachary Liu",
        "Xiang Yue",
        "J. H. Liu",
        "Chenghua Lin",
        "Min Yang",
        "Shiwen Ni",
        "Wenhao Huang",
        "Ge Zhang"
      ],
      "abstract": "Multimodal Large Language Models (MLLMs) are evaluated on various benchmarks,\nsuch as image captioning, visual question answering, and reasoning. However,\nmany of these benchmarks include overly simple or uninformative samples,\ncomplicating the effective distinction of different MLLMs' performance.\nFurthermore, evaluating models across numerous benchmarks incurs a significant\ncomputational burden. To address these issues, we propose LIME (Less Is More\nfor MLLM Evaluation), a refined and efficient benchmark curated through a\nsemi-automated pipeline. This pipeline filters out uninformative samples and\neliminates answer leakage by focusing on tasks that necessitate image-based\nunderstanding. Our experiments indicate that LIME reduces the number of samples\nby 76% and evaluation time by 77%, while also providing a more effective means\nof distinguishing the capabilities of different models. Notably, we find that\ntraditional automatic metrics, such as CIDEr, are inadequate for assessing\nMLLMs' captioning performance; excluding the caption task score yields a more\naccurate reflection of overall model performance. All code and data are\navailable at https://github.com/kangreen0210/LIME.",
      "tldr_zh": "该论文提出LIME（Less Is More for MLLM Evaluation），一种精炼的基准，用于评估多模态大语言模型(MLLM)，旨在解决现有基准中简单样本过多和计算资源消耗大的问题。\nLIME采用半自动化管道过滤不信息性样本，专注于需要图像理解的任务，以消除答案泄露。\n实验结果显示，LIME将样本数量减少76%和评估时间减少77%，并更有效地区分不同模型的能力。\n此外，研究发现传统指标如CIDEr不适合评估MLLM的图像标题生成性能，排除该任务分数能更准确反映模型整体表现。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.06851v3",
      "published_date": "2024-09-10 20:19:14 UTC",
      "updated_date": "2024-10-13 18:11:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:42:41.319334"
    },
    {
      "arxiv_id": "2409.06817v1",
      "title": "Bifurcation Identification for Ultrasound-driven Robotic Cannulation",
      "title_zh": "翻译失败",
      "authors": [
        "Cecilia G. Morales",
        "Dhruv Srikanth",
        "Jack H. Good",
        "Keith A. Dufendach",
        "Artur Dubrawski"
      ],
      "abstract": "In trauma and critical care settings, rapid and precise intravascular access\nis key to patients' survival. Our research aims at ensuring this access, even\nwhen skilled medical personnel are not readily available. Vessel bifurcations\nare anatomical landmarks that can guide the safe placement of catheters or\nneedles during medical procedures. Although ultrasound is advantageous in\nnavigating anatomical landmarks in emergency scenarios due to its portability\nand safety, to our knowledge no existing algorithm can autonomously extract\nvessel bifurcations using ultrasound images. This is primarily due to the\nlimited availability of ground truth data, in particular, data from live\nsubjects, needed for training and validating reliable models. Researchers often\nresort to using data from anatomical phantoms or simulations. We introduce\nBIFURC, Bifurcation Identification for Ultrasound-driven Robot Cannulation, a\nnovel algorithm that identifies vessel bifurcations and provides optimal needle\ninsertion sites for an autonomous robotic cannulation system. BIFURC integrates\nexpert knowledge with deep learning techniques to efficiently detect vessel\nbifurcations within the femoral region and can be trained on a limited amount\nof in-vivo data. We evaluated our algorithm using a medical phantom as well as\nreal-world experiments involving live pigs. In all cases, BIFURC consistently\nidentified bifurcation points and needle insertion locations in alignment with\nthose identified by expert clinicians.",
      "tldr_zh": "本研究针对创伤和急救环境中快速血管通路的需求，开发了BIFURC算法，用于从ultrasound图像中自主识别血管分叉并确定最佳针插入位置，以支持机器人辅助插管系统。BIFURC整合了专家知识和深度学习技术，能够在有限的in-vivo数据上进行训练，专注于股骨区的检测。实验结果显示，该算法在医学假体和活体猪模型中准确识别分叉点和插入位置，与专家临床评估一致。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.06817v1",
      "published_date": "2024-09-10 18:53:52 UTC",
      "updated_date": "2024-09-10 18:53:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:42:52.847040"
    },
    {
      "arxiv_id": "2409.09082v1",
      "title": "Shadowed AHP for multi-criteria supplier selection",
      "title_zh": "翻译失败",
      "authors": [
        "Mohamed Abdel Hameed El-Hawy"
      ],
      "abstract": "Numerous techniques of multi-criteria decision-making (MCDM) have been\nproposed in a variety of business domains. One of the well-known methods is the\nAnalytical Hierarchical Process (AHP). Various uncertain numbers are commonly\nused to represent preference values in AHP problems. In the case of\nmulti-granularity linguistic information, several methods have been proposed to\naddress this type of AHP problem. This paper introduces a novel method to solve\nthis problem using shadowed fuzzy numbers (SFNs). These numbers are\ncharacterized by approximating different types of fuzzy numbers and preserving\ntheir uncertainty properties. The new Shadowed AHP method is proposed to handle\npreference values which are represented by multi-types of uncertain numbers.\nThe new approach converts multi-granular preference values into unified model\nof shadowed fuzzy numbers and utilizes their properties. A new ranking approach\nis introduced to order the results of aggregation preferences. The new approach\nis applied to solve a supplier selection problem in which multi-granular\ninformation are used. The features of the new approach are significant for\ndecision-making applications.",
      "tldr_zh": "该论文针对多标准决策（MCDM）中的Analytical Hierarchical Process (AHP)问题，引入了一种新方法，使用shadowed fuzzy numbers (SFNs)来处理多粒度语言信息和不确定偏好值。Shadowed AHP方法将多粒度偏好值转换为统一的SFNs模型，并提出新的排名方法来聚合和排序结果，从而提升决策准确性。在供应商选择问题中的应用表明，该方法显著提高了处理不确定性的能力，为实际决策应用提供了重要优势。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "14 pages",
      "pdf_url": "http://arxiv.org/pdf/2409.09082v1",
      "published_date": "2024-09-10 18:44:54 UTC",
      "updated_date": "2024-09-10 18:44:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:43:03.511091"
    },
    {
      "arxiv_id": "2409.06805v1",
      "title": "Personalized Federated Learning Techniques: Empirical Analysis",
      "title_zh": "个性化联邦学习技术：实证分析",
      "authors": [
        "Azal Ahmad Khan",
        "Ahmad Faraz Khan",
        "Haider Ali",
        "Ali Anwar"
      ],
      "abstract": "Personalized Federated Learning (pFL) holds immense promise for tailoring\nmachine learning models to individual users while preserving data privacy.\nHowever, achieving optimal performance in pFL often requires a careful\nbalancing act between memory overhead costs and model accuracy. This paper\ndelves into the trade-offs inherent in pFL, offering valuable insights for\nselecting the right algorithms for diverse real-world scenarios. We empirically\nevaluate ten prominent pFL techniques across various datasets and data splits,\nuncovering significant differences in their performance. Our study reveals\ninteresting insights into how pFL methods that utilize personalized (local)\naggregation exhibit the fastest convergence due to their efficiency in\ncommunication and computation. Conversely, fine-tuning methods face limitations\nin handling data heterogeneity and potential adversarial attacks while\nmulti-objective learning methods achieve higher accuracy at the cost of\nadditional training and resource consumption. Our study emphasizes the critical\nrole of communication efficiency in scaling pFL, demonstrating how it can\nsignificantly affect resource usage in real-world deployments.",
      "tldr_zh": "本研究通过实证分析探讨了Personalized Federated Learning (pFL)技术在个性化机器学习模型与数据隐私保护之间的权衡，重点评估了内存开销和模型准确性的平衡。研究者评估了十种主要pFL方法在不同数据集和数据分割上的性能，发现利用个性化（本地）聚合的方法因通信和计算效率高而收敛最快，而微调方法在处理数据异质性和潜在对抗攻击方面存在局限。另一方面，多目标学习方法虽能实现更高准确性，但需额外训练资源；总体上，该研究强调了通信效率在扩展pFL到实际部署中的关键作用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.06805v1",
      "published_date": "2024-09-10 18:16:28 UTC",
      "updated_date": "2024-09-10 18:16:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:43:16.922885"
    },
    {
      "arxiv_id": "2409.06800v1",
      "title": "Adaptive Meta-Domain Transfer Learning (AMDTL): A Novel Approach for Knowledge Transfer in AI",
      "title_zh": "自适应元域迁移学习 (AMDTL)：一种用于人工智能中知识转移的新颖方法",
      "authors": [
        "Michele Laurelli"
      ],
      "abstract": "This paper presents Adaptive Meta-Domain Transfer Learning (AMDTL), a novel\nmethodology that combines principles of meta-learning with domain-specific\nadaptations to enhance the transferability of artificial intelligence models\nacross diverse and unknown domains. AMDTL aims to address the main challenges\nof transfer learning, such as domain misalignment, negative transfer, and\ncatastrophic forgetting, through a hybrid framework that emphasizes both\ngeneralization and contextual specialization. The framework integrates a\nmeta-learner trained on a diverse distribution of tasks, adversarial training\ntechniques for aligning domain feature distributions, and dynamic feature\nregulation mechanisms based on contextual domain embeddings. Experimental\nresults on benchmark datasets demonstrate that AMDTL outperforms existing\ntransfer learning methodologies in terms of accuracy, adaptation efficiency,\nand robustness. This research provides a solid theoretical and practical\nfoundation for the application of AMDTL in various fields, opening new\nperspectives for the development of more adaptable and inclusive AI systems.",
      "tldr_zh": "本研究提出了一种新颖的方法——Adaptive Meta-Domain Transfer Learning (AMDTL)，它将meta-learning原理与领域特定适应相结合，提升AI模型在多样未知领域的知识转移能力。AMDTL通过一个混合框架解决关键挑战，包括domain misalignment、negative transfer和catastrophic forgetting，具体整合了在多样任务上训练的meta-learner、adversarial training用于对齐领域特征分布，以及基于contextual domain embeddings的动态特征调节机制。实验结果显示，AMDTL在基准数据集上超越现有转移学习方法，在准确率、适应效率和鲁棒性方面表现出色。该方法为AI系统的适应性和包容性提供了坚实的理论与实践基础，适用于多个领域的发展。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.06800v1",
      "published_date": "2024-09-10 18:11:48 UTC",
      "updated_date": "2024-09-10 18:11:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:43:28.431230"
    },
    {
      "arxiv_id": "2409.06702v1",
      "title": "Hint-AD: Holistically Aligned Interpretability in End-to-End Autonomous Driving",
      "title_zh": "翻译失败",
      "authors": [
        "Kairui Ding",
        "Boyuan Chen",
        "Yuchen Su",
        "Huan-ang Gao",
        "Bu Jin",
        "Chonghao Sima",
        "Wuqiang Zhang",
        "Xiaohui Li",
        "Paul Barsch",
        "Hongyang Li",
        "Hao Zhao"
      ],
      "abstract": "End-to-end architectures in autonomous driving (AD) face a significant\nchallenge in interpretability, impeding human-AI trust. Human-friendly natural\nlanguage has been explored for tasks such as driving explanation and 3D\ncaptioning. However, previous works primarily focused on the paradigm of\ndeclarative interpretability, where the natural language interpretations are\nnot grounded in the intermediate outputs of AD systems, making the\ninterpretations only declarative. In contrast, aligned interpretability\nestablishes a connection between language and the intermediate outputs of AD\nsystems. Here we introduce Hint-AD, an integrated AD-language system that\ngenerates language aligned with the holistic perception-prediction-planning\noutputs of the AD model. By incorporating the intermediate outputs and a\nholistic token mixer sub-network for effective feature adaptation, Hint-AD\nachieves desirable accuracy, achieving state-of-the-art results in driving\nlanguage tasks including driving explanation, 3D dense captioning, and command\nprediction. To facilitate further study on driving explanation task on\nnuScenes, we also introduce a human-labeled dataset, Nu-X. Codes, dataset, and\nmodels will be publicly available.",
      "tldr_zh": "本文提出Hint-AD，一种在端到端自动驾驶（End-to-End Autonomous Driving）中实现整体对齐可解释性（Holistically Aligned Interpretability）的集成系统，以解决传统声明式可解释性（declarative interpretability）缺乏与中间输出挂钩的问题。Hint-AD通过整合感知-预测-规划的中间输出和整体令牌混合器子网络（holistic token mixer sub-network）进行特征适应，从而生成与AD模型输出对齐的自然语言解释。实验结果显示，该系统在驾驶解释、3D密集描述和命令预测等任务上达到了最先进水平（state-of-the-art）。此外，作者引入了人类标注数据集Nu-X，并计划公开代码、数据集和模型。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "CoRL 2024, Project Page: https://air-discover.github.io/Hint-AD/",
      "pdf_url": "http://arxiv.org/pdf/2409.06702v1",
      "published_date": "2024-09-10 17:59:40 UTC",
      "updated_date": "2024-09-10 17:59:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:43:43.707762"
    },
    {
      "arxiv_id": "2409.06764v1",
      "title": "Modeling Image Tone Dichotomy with the Power Function",
      "title_zh": "基于幂函数的图像色调二分法建模",
      "authors": [
        "Axel Martinez",
        "Gustavo Olague",
        "Emilio Hernandez"
      ],
      "abstract": "The primary purpose of this paper is to present the concept of dichotomy in\nimage illumination modeling based on the power function. In particular, we\nreview several mathematical properties of the power function to identify the\nlimitations and propose a new mathematical model capable of abstracting\nillumination dichotomy. The simplicity of the equation opens new avenues for\nclassical and modern image analysis and processing. The article provides\npractical and illustrative image examples to explain how the new model manages\ndichotomy in image perception. The article shows dichotomy image space as a\nviable way to extract rich information from images despite poor contrast linked\nto tone, lightness, and color perception. Moreover, a comparison with\nstate-of-the-art methods in image enhancement provides evidence of the method's\nvalue.",
      "tldr_zh": "本论文探讨了基于 power function 的图像照明建模中的 dichotomy 概念，通过回顾 power function 的数学属性，识别其局限性，并提出一个新的数学模型来抽象照明 dichotomy。该模型方程简单，为传统和现代图像分析与处理开辟新途径，并通过实际图像示例展示了其在处理图像感知中的 dichotomy 能力。该方法能够从对比度差的图像中提取丰富信息，并在与 state-of-the-art 图像增强方法的比较中证明了其价值。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "49 pages, 11 figures and 36 references",
      "pdf_url": "http://arxiv.org/pdf/2409.06764v1",
      "published_date": "2024-09-10 17:55:09 UTC",
      "updated_date": "2024-09-10 17:55:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:43:52.258048"
    },
    {
      "arxiv_id": "2409.06692v1",
      "title": "HybridFC: A Hybrid Fact-Checking Approach for Knowledge Graphs",
      "title_zh": "HybridFC：一种针对知识图谱的混合事实检查方法",
      "authors": [
        "Umair Qudus",
        "Michael Roeder",
        "Muhammad Saleem",
        "Axel-Cyrille Ngonga Ngomo"
      ],
      "abstract": "We consider fact-checking approaches that aim to predict the veracity of\nassertions in knowledge graphs. Five main categories of fact-checking\napproaches for knowledge graphs have been proposed in the recent literature, of\nwhich each is subject to partially overlapping limitations. In particular,\ncurrent text-based approaches are limited by manual feature engineering.\nPath-based and rule-based approaches are limited by their exclusive use of\nknowledge graphs as background knowledge, and embedding-based approaches suffer\nfrom low accuracy scores on current fact-checking tasks. We propose a hybrid\napproach -- dubbed HybridFC -- that exploits the diversity of existing\ncategories of fact-checking approaches within an ensemble learning setting to\nachieve a significantly better prediction performance. In particular, our\napproach outperforms the state of the art by 0.14 to 0.27 in terms of Area\nUnder the Receiver Operating Characteristic curve on the FactBench dataset. Our\ncode is open-source and can be found at https://github.com/dice-group/HybridFC.",
      "tldr_zh": "该研究针对知识图谱（knowledge graphs）中的事实检查（fact-checking）问题，分析了现有五类方法的局限性，包括文本方法依赖手动特征工程（manual feature engineering）、路径和规则方法仅使用知识图谱作为背景知识，以及嵌入方法（embedding-based approaches）的准确性较低。作者提出了一种混合方法 HybridFC，通过集成学习（ensemble learning）结合多种现有方法的优势，实现更优的预测性能。在 FactBench 数据集上，HybridFC 的 Area Under the Receiver Operating Characteristic curve (AUC) 得分比最先进方法提高了 0.14 到 0.27，并提供了开源代码以便进一步应用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.06692v1",
      "published_date": "2024-09-10 17:55:00 UTC",
      "updated_date": "2024-09-10 17:55:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:44:05.404174"
    },
    {
      "arxiv_id": "2409.06691v3",
      "title": "Geometric-Averaged Preference Optimization for Soft Preference Labels",
      "title_zh": "翻译失败",
      "authors": [
        "Hiroki Furuta",
        "Kuang-Huei Lee",
        "Shixiang Shane Gu",
        "Yutaka Matsuo",
        "Aleksandra Faust",
        "Heiga Zen",
        "Izzeddin Gur"
      ],
      "abstract": "Many algorithms for aligning LLMs with human preferences assume that human\npreferences are binary and deterministic. However, human preferences can vary\nacross individuals, and therefore should be represented distributionally. In\nthis work, we introduce the distributional soft preference labels and improve\nDirect Preference Optimization (DPO) with a weighted geometric average of the\nLLM output likelihood in the loss function. This approach adjusts the scale of\nlearning loss based on the soft labels such that the loss would approach zero\nwhen the responses are closer to equally preferred. This simple modification\ncan be easily applied to any DPO-based methods and mitigate over-optimization\nand objective mismatch, which prior works suffer from. Our experiments simulate\nthe soft preference labels with AI feedback from LLMs and demonstrate that\ngeometric averaging consistently improves performance on standard benchmarks\nfor alignment research. In particular, we observe more preferable responses\nthan binary labels and significant improvements where modestly-confident labels\nare in the majority.",
      "tldr_zh": "这篇论文指出，现有的LLM对齐算法假设人类偏好是二元确定的，但实际偏好是分布式的，因此引入了distributional soft preference labels。作者改进了Direct Preference Optimization (DPO)方法，通过在损失函数中使用加权geometric averaging来调整学习损失规模，使其在响应等同偏好时趋近于零，从而缓解过度优化和目标不匹配问题。这种简单修改适用于任何DPO-based方法，实验通过模拟AI反馈显示，在标准基准上性能一致提升，尤其在中等置信度标签占多数时，生成更可取的响应。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.06691v3",
      "published_date": "2024-09-10 17:54:28 UTC",
      "updated_date": "2024-12-30 11:05:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:44:17.251009"
    },
    {
      "arxiv_id": "2409.06690v1",
      "title": "Benchmarking Sub-Genre Classification For Mainstage Dance Music",
      "title_zh": "翻译失败",
      "authors": [
        "Hongzhi Shu",
        "Xinglin Li",
        "Hongyu Jiang",
        "Minghao Fu",
        "Xinyu Li"
      ],
      "abstract": "Music classification, with a wide range of applications, is one of the most\nprominent tasks in music information retrieval. To address the absence of\ncomprehensive datasets and high-performing methods in the classification of\nmainstage dance music, this work introduces a novel benchmark comprising a new\ndataset and a baseline. Our dataset extends the number of sub-genres to cover\nmost recent mainstage live sets by top DJs worldwide in music festivals. A\ncontinuous soft labeling approach is employed to account for tracks that span\nmultiple sub-genres, preserving the inherent sophistication. For the baseline,\nwe developed deep learning models that outperform current state-of-the-art\nmultimodel language models, which struggle to identify house music sub-genres,\nemphasizing the need for specialized models trained on fine-grained datasets.\nOur benchmark is applicable to serve for application scenarios such as music\nrecommendation, DJ set curation, and interactive multimedia, where we also\nprovide video demos. Our code is on\n\\url{https://anonymous.4open.science/r/Mainstage-EDM-Benchmark/}.",
      "tldr_zh": "这篇论文针对主流舞曲音乐（mainstage dance music）的子流派（sub-genre）分类问题，引入了一个新的基准数据集和基线模型，以填补现有数据集和方法的不足。数据集扩展了子流派的覆盖范围，包含全球顶尖DJ的现场表演，并采用continuous soft labeling方法来处理跨越多个子流派的曲目，从而保留音乐的复杂性。研究开发的深度学习模型在识别house music子流派方面优于现有多模态语言模型，性能提升显著，强调了针对细粒度数据集的专用模型必要性。该基准可应用于音乐推荐、DJ集整理和交互式多媒体场景，并提供了代码和视频演示。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.MM",
        "I.2.1"
      ],
      "primary_category": "cs.SD",
      "comment": "Submitted to ICASSP 2025",
      "pdf_url": "http://arxiv.org/pdf/2409.06690v1",
      "published_date": "2024-09-10 17:54:00 UTC",
      "updated_date": "2024-09-10 17:54:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:44:30.993019"
    },
    {
      "arxiv_id": "2409.06762v1",
      "title": "Generative Hierarchical Materials Search",
      "title_zh": "生成式层次材料搜索",
      "authors": [
        "Sherry Yang",
        "Simon Batzner",
        "Ruiqi Gao",
        "Muratahan Aykol",
        "Alexander L. Gaunt",
        "Brendan McMorrow",
        "Danilo J. Rezende",
        "Dale Schuurmans",
        "Igor Mordatch",
        "Ekin D. Cubuk"
      ],
      "abstract": "Generative models trained at scale can now produce text, video, and more\nrecently, scientific data such as crystal structures. In applications of\ngenerative approaches to materials science, and in particular to crystal\nstructures, the guidance from the domain expert in the form of high-level\ninstructions can be essential for an automated system to output candidate\ncrystals that are viable for downstream research. In this work, we formulate\nend-to-end language-to-structure generation as a multi-objective optimization\nproblem, and propose Generative Hierarchical Materials Search (GenMS) for\ncontrollable generation of crystal structures. GenMS consists of (1) a language\nmodel that takes high-level natural language as input and generates\nintermediate textual information about a crystal (e.g., chemical formulae), and\n(2) a diffusion model that takes intermediate information as input and\ngenerates low-level continuous value crystal structures. GenMS additionally\nuses a graph neural network to predict properties (e.g., formation energy) from\nthe generated crystal structures. During inference, GenMS leverages all three\ncomponents to conduct a forward tree search over the space of possible\nstructures. Experiments show that GenMS outperforms other alternatives of\ndirectly using language models to generate structures both in satisfying user\nrequest and in generating low-energy structures. We confirm that GenMS is able\nto generate common crystal structures such as double perovskites, or spinels,\nsolely from natural language input, and hence can form the foundation for more\ncomplex structure generation in near future.",
      "tldr_zh": "本文提出 Generative Hierarchical Materials Search (GenMS)，一个端到端的框架，用于通过自然语言指令实现可控生成晶体结构，将多目标优化问题转化为层次化生成过程。GenMS 包括一个 language model 生成中间文本信息（如化学公式）、一个 diffusion model 生成晶体结构，以及一个 graph neural network 预测属性（如形成能量），并在推理时使用 forward tree search 优化搜索空间。实验结果表明，GenMS 优于直接使用 language model 的方法，能更有效地满足用户请求并生成低能量结构，例如双 perovskites 或 spinels，从而为未来复杂材料生成奠定基础。",
      "categories": [
        "cond-mat.mtrl-sci",
        "cs.AI"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "comment": "https://generative-materials.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2409.06762v1",
      "published_date": "2024-09-10 17:51:28 UTC",
      "updated_date": "2024-09-10 17:51:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:44:41.275857"
    },
    {
      "arxiv_id": "2409.06673v1",
      "title": "Liability and Insurance for Catastrophic Losses: the Nuclear Power Precedent and Lessons for AI",
      "title_zh": "翻译失败",
      "authors": [
        "Cristian Trout"
      ],
      "abstract": "As AI systems become more autonomous and capable, experts warn of them\npotentially causing catastrophic losses. Drawing on the successful precedent\nset by the nuclear power industry, this paper argues that developers of\nfrontier AI models should be assigned limited, strict, and exclusive third\nparty liability for harms resulting from Critical AI Occurrences (CAIOs) -\nevents that cause or easily could have caused catastrophic losses. Mandatory\ninsurance for CAIO liability is recommended to overcome developers'\njudgment-proofness, mitigate winner's curse dynamics, and leverage insurers'\nquasi-regulatory abilities. Based on theoretical arguments and observations\nfrom the analogous nuclear power context, insurers are expected to engage in a\nmix of causal risk-modeling, monitoring, lobbying for stricter regulation, and\nproviding loss prevention guidance in the context of insuring against\nheavy-tail risks from AI. While not a substitute for regulation, clear\nliability assignment and mandatory insurance can help efficiently allocate\nresources to risk-modeling and safe design, facilitating future regulatory\nefforts.",
      "tldr_zh": "这篇论文借鉴核电行业的先例，讨论了应对AI系统可能导致灾难性损失的策略，主张为前沿AI模型开发商设定有限、严格且独家的第三方责任（third party liability），以应对Critical AI Occurrences (CAIOs)——即可能造成或几乎造成灾难性损失的事件。论文推荐实施强制保险（mandatory insurance），以解决开发商的“判断证明”问题（judgment-proofness）、缓解赢家诅咒动态（winner's curse dynamics），并利用保险公司的准监管能力，包括因果风险建模、监控、游说更严格监管以及提供损失预防指导。总体而言，这种责任分配和保险机制能有效分配资源到风险建模和安全设计上，支持未来的监管努力，尽管不能替代直接监管。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "Accepted to Generative AI and Law Workshop at the International\n  Conference on Machine Learning (ICML 2024)",
      "pdf_url": "http://arxiv.org/pdf/2409.06673v1",
      "published_date": "2024-09-10 17:41:31 UTC",
      "updated_date": "2024-09-10 17:41:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:44:54.570093"
    },
    {
      "arxiv_id": "2409.06672v1",
      "title": "Insuring Uninsurable Risks from AI: The State as Insurer of Last Resort",
      "title_zh": "翻译失败",
      "authors": [
        "Cristian Trout"
      ],
      "abstract": "Many experts believe that AI systems will sooner or later pose uninsurable\nrisks, including existential risks. This creates an extreme judgment-proof\nproblem: few if any parties can be held accountable ex post in the event of\nsuch a catastrophe. This paper proposes a novel solution: a\ngovernment-provided, mandatory indemnification program for AI developers. The\nprogram uses risk-priced indemnity fees to induce socially optimal levels of\ncare. Risk-estimates are determined by surveying experts, including indemnified\ndevelopers. The Bayesian Truth Serum mechanism is employed to incent honest and\neffortful responses. Compared to alternatives, this approach arguably better\nleverages all private information, and provides a clearer signal to indemnified\ndevelopers regarding what risks they must mitigate to lower their fees. It's\nrecommended that collected fees be used to help fund the safety research\ndevelopers need, employing a fund matching mechanism (Quadratic Financing) to\ninduce an optimal supply of this public good. Under Quadratic Financing, safety\nresearch projects would compete for private contributions from developers,\nsignaling how much each is to be supplemented with public funds.",
      "tldr_zh": "该论文探讨了 AI 系统可能带来的不可保险风险（如存在性风险），导致责任归属困难的问题，并提出政府作为最终保险人，提供强制性赔偿计划给 AI 开发者。方案通过风险定价的赔偿费来激励开发者采取社会最优水平的预防措施，并采用 Bayesian Truth Serum 机制对专家（包括开发者）的风险评估进行诚实激励。相比其他方法，该方案更有效地利用私人信息，并为开发者提供清晰信号以降低费用；此外，建议用收取的费用通过 Quadratic Financing 机制资助安全研究，促进开发者贡献和公共资金的匹配。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG",
        "q-fin.RM"
      ],
      "primary_category": "cs.CY",
      "comment": "Accepted to Generative AI and Law Workshop at the International\n  Conference on Machine Learning (ICML 2024)",
      "pdf_url": "http://arxiv.org/pdf/2409.06672v1",
      "published_date": "2024-09-10 17:41:24 UTC",
      "updated_date": "2024-09-10 17:41:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:45:05.960053"
    },
    {
      "arxiv_id": "2409.06666v2",
      "title": "LLaMA-Omni: Seamless Speech Interaction with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Qingkai Fang",
        "Shoutao Guo",
        "Yan Zhou",
        "Zhengrui Ma",
        "Shaolei Zhang",
        "Yang Feng"
      ],
      "abstract": "Models like GPT-4o enable real-time interaction with large language models\n(LLMs) through speech, significantly enhancing user experience compared to\ntraditional text-based interaction. However, there is still a lack of\nexploration on how to build speech interaction models based on open-source\nLLMs. To address this, we propose LLaMA-Omni, a novel model architecture\ndesigned for low-latency and high-quality speech interaction with LLMs.\nLLaMA-Omni integrates a pretrained speech encoder, a speech adaptor, an LLM,\nand a streaming speech decoder. It eliminates the need for speech\ntranscription, and can simultaneously generate text and speech responses\ndirectly from speech instructions with extremely low latency. We build our\nmodel based on the latest Llama-3.1-8B-Instruct model. To align the model with\nspeech interaction scenarios, we construct a dataset named InstructS2S-200K,\nwhich includes 200K speech instructions and corresponding speech responses.\nExperimental results show that compared to previous speech-language models,\nLLaMA-Omni provides better responses in both content and style, with a response\nlatency as low as 226ms. Additionally, training LLaMA-Omni takes less than 3\ndays on just 4 GPUs, paving the way for the efficient development of\nspeech-language models in the future.",
      "tldr_zh": "本研究提出 LLaMA-Omni，一种新型模型架构，旨在实现基于开源 LLM 的无缝语音交互，提升用户体验。\n该模型整合预训练语音编码器、语音适配器、LLM（如 Llama-3.1-8B-Instruct）和流式语音解码器，无需语音转录即可直接从语音指令生成文本和语音响应，延迟低至 226ms。\n为了适应语音场景，研究者构建了 InstructS2S-200K 数据集进行训练，实验结果显示 LLaMA-Omni 在内容和风格上优于现有语音语言模型，且训练仅需 4 个 GPU 不到 3 天，为高效开发语音交互技术铺平道路。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SD",
        "eess.AS",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2409.06666v2",
      "published_date": "2024-09-10 17:34:34 UTC",
      "updated_date": "2025-03-01 12:59:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:45:19.364224"
    },
    {
      "arxiv_id": "2409.06662v1",
      "title": "World-Grounded Human Motion Recovery via Gravity-View Coordinates",
      "title_zh": "翻译失败",
      "authors": [
        "Zehong Shen",
        "Huaijin Pi",
        "Yan Xia",
        "Zhi Cen",
        "Sida Peng",
        "Zechen Hu",
        "Hujun Bao",
        "Ruizhen Hu",
        "Xiaowei Zhou"
      ],
      "abstract": "We present a novel method for recovering world-grounded human motion from\nmonocular video. The main challenge lies in the ambiguity of defining the world\ncoordinate system, which varies between sequences. Previous approaches attempt\nto alleviate this issue by predicting relative motion in an autoregressive\nmanner, but are prone to accumulating errors. Instead, we propose estimating\nhuman poses in a novel Gravity-View (GV) coordinate system, which is defined by\nthe world gravity and the camera view direction. The proposed GV system is\nnaturally gravity-aligned and uniquely defined for each video frame, largely\nreducing the ambiguity of learning image-pose mapping. The estimated poses can\nbe transformed back to the world coordinate system using camera rotations,\nforming a global motion sequence. Additionally, the per-frame estimation avoids\nerror accumulation in the autoregressive methods. Experiments on in-the-wild\nbenchmarks demonstrate that our method recovers more realistic motion in both\nthe camera space and world-grounded settings, outperforming state-of-the-art\nmethods in both accuracy and speed. The code is available at\nhttps://zju3dv.github.io/gvhmr/.",
      "tldr_zh": "本研究提出了一种从单目视频中恢复世界坐标系下人类运动的新方法，使用 Gravity-View (GV) 坐标系统，该系统基于世界重力和相机视角方向定义，以减少图像-姿势映射的模糊性。不同于传统的 autoregressive 方法，该方法通过每帧独立估计姿势并转换回世界坐标系，避免了错误积累。实验结果显示，在野外基准测试中，该方法在准确性和速度上均优于现有最先进技术，恢复了更真实的运动序列。代码已在 https://zju3dv.github.io/gvhmr/ 公开。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at SIGGRAPH Asia 2024 (Conference Track). Project page:\n  https://zju3dv.github.io/gvhmr/",
      "pdf_url": "http://arxiv.org/pdf/2409.06662v1",
      "published_date": "2024-09-10 17:25:47 UTC",
      "updated_date": "2024-09-10 17:25:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:45:30.268651"
    },
    {
      "arxiv_id": "2409.06644v2",
      "title": "EyeCLIP: A visual-language foundation model for multi-modal ophthalmic image analysis",
      "title_zh": "EyeCLIP：一种视觉-语言基础模型，用于多模态眼科图像分析",
      "authors": [
        "Danli Shi",
        "Weiyi Zhang",
        "Jiancheng Yang",
        "Siyu Huang",
        "Xiaolan Chen",
        "Mayinuer Yusufu",
        "Kai Jin",
        "Shan Lin",
        "Shunming Liu",
        "Qing Zhang",
        "Mingguang He"
      ],
      "abstract": "Early detection of eye diseases like glaucoma, macular degeneration, and\ndiabetic retinopathy is crucial for preventing vision loss. While artificial\nintelligence (AI) foundation models hold significant promise for addressing\nthese challenges, existing ophthalmic foundation models primarily focus on a\nsingle modality, whereas diagnosing eye diseases requires multiple modalities.\nA critical yet often overlooked aspect is harnessing the multi-view information\nacross various modalities for the same patient. Additionally, due to the\nlong-tail nature of ophthalmic diseases, standard fully supervised or\nunsupervised learning approaches often struggle. Therefore, it is essential to\nintegrate clinical text to capture a broader spectrum of diseases. We propose\nEyeCLIP, a visual-language foundation model developed using over 2.77 million\nmulti-modal ophthalmology images with partial text data. To fully leverage the\nlarge multi-modal unlabeled and labeled data, we introduced a pretraining\nstrategy that combines self-supervised reconstructions, multi-modal image\ncontrastive learning, and image-text contrastive learning to learn a shared\nrepresentation of multiple modalities. Through evaluation using 14 benchmark\ndatasets, EyeCLIP can be transferred to a wide range of downstream tasks\ninvolving ocular and systemic diseases, achieving state-of-the-art performance\nin disease classification, visual question answering, and cross-modal\nretrieval. EyeCLIP represents a significant advancement over previous methods,\nespecially showcasing few-shot, even zero-shot capabilities in real-world\nlong-tail scenarios.",
      "tldr_zh": "本研究提出 EyeCLIP，一种视觉-语言 foundation model，用于多模态眼科图像分析，以解决早期检测眼部疾病（如青光眼、黄斑变性和糖尿病视网膜病变）的挑战。EyeCLIP 利用超过 2.77 百万多模态眼科图像和部分文本数据，通过结合自监督 reconstructions、多模态图像 contrastive learning 和图像-文本 contrastive learning 的预训练策略，学习多模态共享表示。实验结果显示，EyeCLIP 在 14 个基准数据集上实现 state-of-the-art 性能，尤其在疾病分类、视觉问答和跨模态检索任务中表现出色，并具备 few-shot 和 zero-shot 能力，适用于真实世界的长尾分布场景。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.06644v2",
      "published_date": "2024-09-10 17:00:19 UTC",
      "updated_date": "2024-09-11 17:00:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:45:42.571834"
    },
    {
      "arxiv_id": "2409.06635v4",
      "title": "MoWE-Audio: Multitask AudioLLMs with Mixture of Weak Encoders",
      "title_zh": "翻译失败",
      "authors": [
        "Wenyu Zhang",
        "Shuo Sun",
        "Bin Wang",
        "Xunlong Zou",
        "Zhuohan Liu",
        "Yingxu He",
        "Geyu Lin",
        "Nancy F. Chen",
        "Ai Ti Aw"
      ],
      "abstract": "The rapid advancements in large language models (LLMs) have significantly\nenhanced natural language processing capabilities, facilitating the development\nof AudioLLMs that process and understand speech and audio inputs alongside\ntext. Existing AudioLLMs typically combine a pre-trained audio encoder with a\npre-trained LLM, which are subsequently finetuned on specific audio tasks.\nHowever, the pre-trained audio encoder has constrained capacity to capture\nfeatures for new tasks and datasets. To address this, we propose to incorporate\nmixtures of `weak' encoders (MoWE) into the AudioLLM framework. MoWE\nsupplements a base encoder with a pool of relatively light weight encoders,\nselectively activated based on the audio input to enhance feature extraction\nwithout significantly increasing model size. Our empirical results demonstrate\nthat MoWE effectively improves multi-task performance, broadening the\napplicability of AudioLLMs to more diverse audio tasks.",
      "tldr_zh": "该论文探讨了大型语言模型（LLMs）的快速发展如何推动 AudioLLMs 在处理语音和音频输入方面的能力，但现有 AudioLLMs 的预训练音频编码器在捕捉新任务特征时存在容量限制问题。为解决此问题，作者提出 MoWE（Mixture of Weak Encoders）框架，该方法在 AudioLLM 中添加一组轻量级编码器，根据音频输入选择性激活，以增强特征提取而不显著增加模型规模。实验结果显示，MoWE 有效提升了多任务性能，使 AudioLLMs 能够更好地适应多样化的音频任务。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CL",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "ICASSP 2025",
      "pdf_url": "http://arxiv.org/pdf/2409.06635v4",
      "published_date": "2024-09-10 16:46:18 UTC",
      "updated_date": "2025-04-21 09:48:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:45:54.041958"
    },
    {
      "arxiv_id": "2409.13740v2",
      "title": "Language agents achieve superhuman synthesis of scientific knowledge",
      "title_zh": "翻译失败",
      "authors": [
        "Michael D. Skarlinski",
        "Sam Cox",
        "Jon M. Laurent",
        "James D. Braza",
        "Michaela Hinks",
        "Michael J. Hammerling",
        "Manvitha Ponnapati",
        "Samuel G. Rodriques",
        "Andrew D. White"
      ],
      "abstract": "Language models are known to hallucinate incorrect information, and it is\nunclear if they are sufficiently accurate and reliable for use in scientific\nresearch. We developed a rigorous human-AI comparison methodology to evaluate\nlanguage model agents on real-world literature search tasks covering\ninformation retrieval, summarization, and contradiction detection tasks. We\nshow that PaperQA2, a frontier language model agent optimized for improved\nfactuality, matches or exceeds subject matter expert performance on three\nrealistic literature research tasks without any restrictions on humans (i.e.,\nfull access to internet, search tools, and time). PaperQA2 writes cited,\nWikipedia-style summaries of scientific topics that are significantly more\naccurate than existing, human-written Wikipedia articles. We also introduce a\nhard benchmark for scientific literature research called LitQA2 that guided\ndesign of PaperQA2, leading to it exceeding human performance. Finally, we\napply PaperQA2 to identify contradictions within the scientific literature, an\nimportant scientific task that is challenging for humans. PaperQA2 identifies\n2.34 +/- 1.99 contradictions per paper in a random subset of biology papers, of\nwhich 70% are validated by human experts. These results demonstrate that\nlanguage model agents are now capable of exceeding domain experts across\nmeaningful tasks on scientific literature.",
      "tldr_zh": "这篇论文展示了语言模型代理在科学知识合成中的超人类能力，开发了 PaperQA2，这是一个优化事实性的前沿代理，能够在信息检索、总结和矛盾检测任务上匹配或超过领域专家的表现。研究者引入了 LitQA2 基准来指导 PaperQA2 的设计，使其生成的引用准确的 Wikipedia 风格科学总结显著优于现有人类编写的文章。最终，PaperQA2 在随机生物学论文中识别出约 2.34 ± 1.99 个矛盾，其中 70% 经专家验证，这些结果证明语言模型代理已能在真实科学任务中超越人类。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "physics.soc-ph"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.13740v2",
      "published_date": "2024-09-10 16:37:58 UTC",
      "updated_date": "2024-09-26 15:27:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:46:07.045088"
    },
    {
      "arxiv_id": "2409.06756v1",
      "title": "Beyond designer's knowledge: Generating materials design hypotheses via large language models",
      "title_zh": "超越设计者的知识：通过大型语言模型生成材料设计假设",
      "authors": [
        "Quanliang Liu",
        "Maciej P. Polak",
        "So Yeon Kim",
        "MD Al Amin Shuvo",
        "Hrishikesh Shridhar Deodhar",
        "Jeongsoo Han",
        "Dane Morgan",
        "Hyunseok Oh"
      ],
      "abstract": "Materials design often relies on human-generated hypotheses, a process\ninherently limited by cognitive constraints such as knowledge gaps and limited\nability to integrate and extract knowledge implications, particularly when\nmultidisciplinary expertise is required. This work demonstrates that large\nlanguage models (LLMs), coupled with prompt engineering, can effectively\ngenerate non-trivial materials hypotheses by integrating scientific principles\nfrom diverse sources without explicit design guidance by human experts. These\ninclude design ideas for high-entropy alloys with superior cryogenic properties\nand halide solid electrolytes with enhanced ionic conductivity and formability.\nThese design ideas have been experimentally validated in high-impact\npublications in 2023 not available in the LLM training data, demonstrating the\nLLM's ability to generate highly valuable and realizable innovative ideas not\nestablished in the literature. Our approach primarily leverages materials\nsystem charts encoding processing-structure-property relationships, enabling\nmore effective data integration by condensing key information from numerous\npapers, and evaluation and categorization of numerous hypotheses for human\ncognition, both through the LLM. This LLM-driven approach opens the door to new\navenues of artificial intelligence-driven materials discovery by accelerating\ndesign, democratizing innovation, and expanding capabilities beyond the\ndesigner's direct knowledge.",
      "tldr_zh": "本文提出了一种利用大型语言模型 (LLMs) 和提示工程的方法，来生成材料设计假设，从而超越设计师的认知限制，如知识缺口和多学科整合难题。LLMs 通过整合来自多样来源的科学原理，成功生成了创新设计想法，例如高熵 alloys 具有优越的低温性能，以及 halide solid electrolytes 的增强离子导电性和可成形性，这些已在 2023 年的实验验证中得到证实。相比传统方法，该框架依赖材料系统图表进行数据整合和假设评估，加速了 AI 驱动的材料发现、促进了创新民主化和扩展了设计能力。",
      "categories": [
        "cs.LG",
        "cond-mat.mtrl-sci",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.06756v1",
      "published_date": "2024-09-10 16:28:50 UTC",
      "updated_date": "2024-09-10 16:28:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:46:19.013220"
    },
    {
      "arxiv_id": "2409.06624v1",
      "title": "A Practice of Post-Training on Llama-3 70B with Optimal Selection of Additional Language Mixture Ratio",
      "title_zh": "翻译失败",
      "authors": [
        "Ningyuan Xi",
        "Yetao Wu",
        "Kun Fan",
        "Teng Chen",
        "Qingqing Gu",
        "Peng Yu",
        "Jinxian Qu",
        "Chenxi Liu",
        "Zhonglin Jiang",
        "Yong Chen",
        "Luo Ji"
      ],
      "abstract": "Large Language Models (LLM) often needs to be Continual Pre-Trained (CPT) to\nobtain the unfamiliar language skill or adapt into new domains. The huge\ntraining cost of CPT often asks for cautious choice of key hyper-parameters\nsuch as the mixture ratio of extra language or domain corpus. However, there is\nno systematic study which bridge the gap between the optimal mixture ratio and\nthe actual model performance, and the gap between experimental scaling law and\nthe actual deployment in the full model size. In this paper, we perform CPT on\nLlama-3 8B and 70B to enhance its Chinese ability. We study the optimal\ncorrelation between the Additional Language Mixture Ratio (ALMR) and the\nLearning Rate (LR) on the 8B size which directly indicate the optimal\nexperimental set up. By thorough choice of hyper-parameter, and subsequent\nfine-tuning, the model capability is improved not only on the Chinese-related\nbenchmark, but also some specific domains including math, coding and emotional\nintelligence. We deploy the final 70B version of LLM on an real-life chat\nsystem which obtain satisfying performance.",
      "tldr_zh": "本论文探讨了对 Llama-3 模型进行持续预训练 (CPT)，以提升其中文能力并适应新领域，通过优化额外语言混合比率 (ALMR) 和学习率 (LR) 来降低训练成本。研究者首先在 Llama-3 8B 模型上实验，分析 ALMR 与 LR 的最优相关性，并将其应用于 70B 模型的后续微调，从而显著提升了模型在中文基准测试、数学、编码和情感智能等领域的表现。最终，该优化后的 70B 模型部署在实际聊天系统中，展现出满意的性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "11 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.06624v1",
      "published_date": "2024-09-10 16:26:43 UTC",
      "updated_date": "2024-09-10 16:26:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:46:30.638816"
    },
    {
      "arxiv_id": "2409.06615v6",
      "title": "One-Shot Imitation under Mismatched Execution",
      "title_zh": "翻译失败",
      "authors": [
        "Kushal Kedia",
        "Prithwish Dan",
        "Angela Chao",
        "Maximus Adrian Pace",
        "Sanjiban Choudhury"
      ],
      "abstract": "Human demonstrations as prompts are a powerful way to program robots to do\nlong-horizon manipulation tasks. However, translating these demonstrations into\nrobot-executable actions presents significant challenges due to execution\nmismatches in movement styles and physical capabilities. Existing methods for\nhuman-robot translation either depend on paired data, which is infeasible to\nscale, or rely heavily on frame-level visual similarities that often break down\nin practice. To address these challenges, we propose RHyME, a novel framework\nthat automatically pairs human and robot trajectories using sequence-level\noptimal transport cost functions. Given long-horizon robot demonstrations,\nRHyME synthesizes semantically equivalent human videos by retrieving and\ncomposing short-horizon human clips. This approach facilitates effective policy\ntraining without the need for paired data. RHyME successfully imitates a range\nof cross-embodiment demonstrators, both in simulation and with a real human\nhand, achieving over 50% increase in task success compared to previous methods.\nWe release our code and datasets at https://portal-cornell.github.io/rhyme/.",
      "tldr_zh": "本论文探讨了在执行不匹配条件下使用人类演示进行机器人 one-shot imitation 的挑战，针对现有方法的依赖于配对数据或帧级视觉相似性的局限性，提出 RHyME 框架。\nRHyME 通过序列级 optimal transport cost functions 自动配对人类和机器人轨迹，并通过检索和组合短时序人类片段合成语义等价视频，从而实现有效的策略训练，而无需配对数据。\n实验结果表明，该框架在模拟和真实环境中成功模仿跨实体演示者，任务成功率比先前方法提高了 50% 以上，并开源了代码和数据集。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.06615v6",
      "published_date": "2024-09-10 16:11:57 UTC",
      "updated_date": "2025-03-28 22:16:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:46:43.482767"
    },
    {
      "arxiv_id": "2409.06754v4",
      "title": "Scaling Law Hypothesis for Multimodal Model",
      "title_zh": "多模态模型的缩放定律假设",
      "authors": [
        "Qingyun Sun",
        "Zhen Guo",
        "PIN AI Team"
      ],
      "abstract": "We propose a scaling law hypothesis for multimodal models processing text,\naudio, images, and video within a shared token and embedding space. Our\nframework predicts model performance based on modality-specific compression and\ntokenization efficiency, extending established scaling laws from text-based\ndecoder models to mixed-modality systems. We explore whether leveraging more\ntraining data in multiple modalities can reduce the size of the multimodal\nmodel, enabling efficient deployment on resource-constrained devices.",
      "tldr_zh": "该论文提出了一种针对处理文本、音频、图像和视频的多模态模型的scaling law假设，框架基于模态特定的压缩和tokenization效率，以扩展文本解码器模型的现有scaling laws并预测模型性能。研究探讨了通过增加多模态训练数据是否能减小模型规模，从而在资源受限设备上实现高效部署。该假设为混合模态系统的优化提供了新见解，有助于提升模型的实用性和效率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.06754v4",
      "published_date": "2024-09-10 16:05:02 UTC",
      "updated_date": "2024-11-11 18:32:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:46:54.388727"
    },
    {
      "arxiv_id": "2409.06612v1",
      "title": "Label-free Monitoring of Self-Supervised Learning Progress",
      "title_zh": "自监督学习进度的无标签监测",
      "authors": [
        "Isaac Xu",
        "Scott Lowe",
        "Thomas Trappenberg"
      ],
      "abstract": "Self-supervised learning (SSL) is an effective method for exploiting\nunlabelled data to learn a high-level embedding space that can be used for\nvarious downstream tasks. However, existing methods to monitor the quality of\nthe encoder -- either during training for one model or to compare several\ntrained models -- still rely on access to annotated data. When SSL\nmethodologies are applied to new data domains, a sufficiently large labelled\ndataset may not always be available. In this study, we propose several\nevaluation metrics which can be applied on the embeddings of unlabelled data\nand investigate their viability by comparing them to linear probe accuracy (a\ncommon metric which utilizes an annotated dataset). In particular, we apply\n$k$-means clustering and measure the clustering quality with the silhouette\nscore and clustering agreement. We also measure the entropy of the embedding\ndistribution. We find that while the clusters did correspond better to the\nground truth annotations as training of the network progressed, label-free\nclustering metrics correlated with the linear probe accuracy only when training\nwith SSL methods SimCLR and MoCo-v2, but not with SimSiam. Additionally,\nalthough entropy did not always have strong correlations with LP accuracy, this\nappears to be due to instability arising from early training, with the metric\nstabilizing and becoming more reliable at later stages of learning.\nFurthermore, while entropy generally decreases as learning progresses, this\ntrend reverses for SimSiam. More research is required to establish the cause\nfor this unexpected behaviour. Lastly, we find that while clustering based\napproaches are likely only viable for same-architecture comparisons, entropy\nmay be architecture-independent.",
      "tldr_zh": "这篇论文针对自监督学习 (SSL) 的问题，提出无需标签数据的评估指标，以监控模型在未标注数据集上的训练进展。方法包括使用 k-means 聚类计算轮廓分数 (silhouette score) 和聚类一致性 (clustering agreement)，以及测量嵌入分布的熵 (entropy)，并与线性探针准确率 (linear probe accuracy) 进行比较。实验发现，这些指标在 SimCLR 和 MoCo-v2 上与线性探针准确率相关，但在 SimSiam 上不一致；此外，熵在训练后期趋于稳定，但 SimSiam 显示熵增加的异常行为，可能需进一步研究。总体而言，聚类方法适合相同架构的比较，而熵指标可能独立于模型架构，提供了一种更灵活的监控方式。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.06612v1",
      "published_date": "2024-09-10 16:04:10 UTC",
      "updated_date": "2024-09-10 16:04:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:47:07.258831"
    },
    {
      "arxiv_id": "2409.06608v1",
      "title": "Simulation-based Scenario Generation for Robust Hybrid AI for Autonomy",
      "title_zh": "基于模拟的场景生成，用于稳健混合AI的自治",
      "authors": [
        "Hambisa Keno",
        "Nicholas J. Pioch",
        "Christopher Guagliano",
        "Timothy H. Chung"
      ],
      "abstract": "Application of Unmanned Aerial Vehicles (UAVs) in search and rescue,\nemergency management, and law enforcement has gained traction with the advent\nof low-cost platforms and sensor payloads. The emergence of hybrid neural and\nsymbolic AI approaches for complex reasoning is expected to further push the\nboundaries of these applications with decreasing levels of human intervention.\nHowever, current UAV simulation environments lack semantic context suited to\nthis hybrid approach. To address this gap, HAMERITT (Hybrid Ai Mission\nEnvironment for RapId Training and Testing) provides a simulation-based\nautonomy software framework that supports the training, testing and assurance\nof neuro-symbolic algorithms for autonomous maneuver and perception reasoning.\nHAMERITT includes scenario generation capabilities that offer mission-relevant\ncontextual symbolic information in addition to raw sensor data. Scenarios\ninclude symbolic descriptions for entities of interest and their relations to\nscene elements, as well as spatial-temporal constraints in the form of\ntime-bounded areas of interest with prior probabilities and restricted zones\nwithin those areas. HAMERITT also features support for training distinct\nalgorithm threads for maneuver vs. perception within an end-to-end mission run.\nFuture work includes improving scenario realism and scaling symbolic context\ngeneration through automated workflow.",
      "tldr_zh": "该论文针对无人机（UAVs）在搜索和救援、紧急管理和执法中的应用，提出了一种基于模拟的场景生成方法，以增强混合神经和符号 AI 的鲁棒性。HAMERITT 框架作为核心工具，提供模拟环境支持神经符号算法的训练、测试和验证，包括任务相关的符号信息、实体关系以及空间-时间约束。实验和功能设计展示了 HAMERITT 在处理机动和感知算法方面的优势，有助于减少人为干预，并计划通过自动化工作流程进一步提升场景真实性和符号上下文生成。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "68T20, 68T45, 68T40",
        "J.7; C.3"
      ],
      "primary_category": "cs.RO",
      "comment": "6 pages, 5 figures, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2409.06608v1",
      "published_date": "2024-09-10 16:00:26 UTC",
      "updated_date": "2024-09-10 16:00:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:47:17.677068"
    },
    {
      "arxiv_id": "2409.06607v3",
      "title": "An Ontology-based Approach Towards Traceable Behavior Specifications in Automated Driving",
      "title_zh": "翻译失败",
      "authors": [
        "Nayel Fabian Salem",
        "Marcus Nolte",
        "Veronica Haber",
        "Till Menzel",
        "Hans Steege",
        "Robert Graubohm",
        "Markus Maurer"
      ],
      "abstract": "Vehicles in public traffic that are equipped with Automated Driving Systems\nare subject to a number of expectations: Among other aspects, their behavior\nshould be safe, conforming to the rules of the road and provide mobility to\ntheir users. This poses challenges for the developers of such systems:\nDevelopers are responsible for specifying this behavior, for example, in terms\nof requirements at system design time. As we will discuss in the article, this\nspecification always involves the need for assumptions and trade-offs. As a\nresult, insufficiencies in such a behavior specification can occur that can\npotentially lead to unsafe system behavior. In order to support the\nidentification of specification insufficiencies, requirements and respective\nassumptions need to be made explicit. In this article, we propose the Semantic\nNorm Behavior Analysis as an ontology-based approach to specify the behavior\nfor an Automated Driving System equipped vehicle. We use ontologies to formally\nrepresent specified behavior for a targeted operational environment, and to\nestablish traceability between specified behavior and the addressed stakeholder\nneeds. Furthermore, we illustrate the application of the Semantic Norm Behavior\nAnalysis in a German legal context with two example scenarios and evaluate our\nresults. Our evaluation shows that the explicit documentation of assumptions in\nthe behavior specification supports both the identification of specification\ninsufficiencies and their treatment. Therefore, this article provides\nrequirements, terminology and an according methodology to facilitate\nontology-based behavior specifications in automated driving.",
      "tldr_zh": "本研究针对自动驾驶车辆的行为规范问题，提出了一种基于本体论（ontology-based）的Semantic Norm Behavior Analysis方法，以确保行为符合安全、交通规则和用户需求。该方法通过本体论正式表示指定行为，并建立行为规范与利益相关者需求的追溯性（traceability），从而明确记录假设和权衡，避免潜在的不安全风险。在德国法律背景下的两个示例场景中进行评估，结果显示此方法有助于识别和处理规范不足，为自动驾驶系统的开发提供了一个可追溯且可靠的规范框架。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.SE",
      "comment": "24 pages, 12 figures, submitted for publication",
      "pdf_url": "http://arxiv.org/pdf/2409.06607v3",
      "published_date": "2024-09-10 16:00:22 UTC",
      "updated_date": "2024-11-15 14:09:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:47:29.766222"
    },
    {
      "arxiv_id": "2409.06585v1",
      "title": "Developing the Temporal Graph Convolutional Neural Network Model to Predict Hip Replacement using Electronic Health Records",
      "title_zh": "翻译失败",
      "authors": [
        "Zoe Hancox",
        "Sarah R. Kingsbury",
        "Andrew Clegg",
        "Philip G. Conaghan",
        "Samuel D. Relton"
      ],
      "abstract": "Background: Hip replacement procedures improve patient lives by relieving\npain and restoring mobility. Predicting hip replacement in advance could reduce\npain by enabling timely interventions, prioritising individuals for surgery or\nrehabilitation, and utilising physiotherapy to potentially delay the need for\njoint replacement. This study predicts hip replacement a year in advance to\nenhance quality of life and health service efficiency. Methods: Adapting\nprevious work using Temporal Graph Convolutional Neural Network (TG-CNN)\nmodels, we construct temporal graphs from primary care medical event codes,\nsourced from ResearchOne EHRs of 40-75-year-old patients, to predict hip\nreplacement risk. We match hip replacement cases to controls by age, sex, and\nIndex of Multiple Deprivation. The model, trained on 9,187 cases and 9,187\ncontrols, predicts hip replacement one year in advance. We validate the model\non two unseen datasets, recalibrating for class imbalance. Additionally, we\nconduct an ablation study and compare against four baseline models. Results:\nOur best model predicts hip replacement risk one year in advance with an AUROC\nof 0.724 (95% CI: 0.715-0.733) and an AUPRC of 0.185 (95% CI: 0.160-0.209),\nachieving a calibration slope of 1.107 (95% CI: 1.074-1.139) after\nrecalibration. Conclusions: The TG-CNN model effectively predicts hip\nreplacement risk by identifying patterns in patient trajectories, potentially\nimproving understanding and management of hip-related conditions.",
      "tldr_zh": "本研究开发了Temporal Graph Convolutional Neural Network (TG-CNN)模型，利用Electronic Health Records (EHRs)从40-75岁患者的医疗事件代码构建时间图，来预测一年前的髋关节置换风险，从而实现及时干预和改善医疗效率。方法包括将髋关节置换病例与年龄、性别和多重剥夺指数匹配的对照组进行训练，并在两个未见数据集上验证，同时与四个基线模型比较。结果显示，最佳模型的预测性能为AUROC 0.724（95% CI: 0.715-0.733）和AUPRC 0.185（95% CI: 0.160-0.209），经重新校准后校准斜率为1.107（95% CI: 1.074-1.139）。该模型通过识别患者轨迹模式，有望提升对髋关节相关疾病的理解和管理。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to the 2024 International Conference on Machine Learning and\n  Applications (ICMLA). 8 pages, 3 figures, 7 tables",
      "pdf_url": "http://arxiv.org/pdf/2409.06585v1",
      "published_date": "2024-09-10 15:26:58 UTC",
      "updated_date": "2024-09-10 15:26:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:47:45.428015"
    },
    {
      "arxiv_id": "2409.06579v1",
      "title": "Quantifying and Enabling the Interpretability of CLIP-like Models",
      "title_zh": "翻译失败",
      "authors": [
        "Avinash Madasu",
        "Yossi Gandelsman",
        "Vasudev Lal",
        "Phillip Howard"
      ],
      "abstract": "CLIP is one of the most popular foundational models and is heavily used for\nmany vision-language tasks. However, little is known about the inner workings\nof CLIP. To bridge this gap we propose a study to quantify the interpretability\nin CLIP like models. We conduct this study on six different CLIP models from\nOpenAI and OpenCLIP which vary by size, type of pre-training data and patch\nsize. Our approach begins with using the TEXTSPAN algorithm and in-context\nlearning to break down individual attention heads into specific properties. We\nthen evaluate how easily these heads can be interpreted using new metrics which\nmeasure property consistency within heads and property disentanglement across\nheads. Our findings reveal that larger CLIP models are generally more\ninterpretable than their smaller counterparts. To further assist users in\nunderstanding the inner workings of CLIP models, we introduce CLIP-InterpreT, a\ntool designed for interpretability analysis. CLIP-InterpreT offers five types\nof analyses: property-based nearest neighbor search, per-head topic\nsegmentation, contrastive segmentation, per-head nearest neighbors of an image,\nand per-head nearest neighbors of text.",
      "tldr_zh": "本文研究量化了 CLIP-like 模型的可解释性，针对六个不同 CLIP 模型（包括大小、预训练数据和 patch size 的变体）使用 TEXTSPAN 算法和 in-context learning 来分解注意力头（attention heads）成特定属性，并引入新指标评估属性在头内的一致性和在不同头间的解耦（disentanglement）。研究发现，较大的 CLIP 模型比小型模型更易解释。作者还开发了 CLIP-InterpreT 工具，提供五种分析功能，包括基于属性的最近邻搜索、每个头的主题分割、对比分割以及图像和文本的每个头最近邻分析，以帮助用户更好地理解模型内部机制。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.06579v1",
      "published_date": "2024-09-10 15:19:40 UTC",
      "updated_date": "2024-09-10 15:19:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:47:54.192338"
    },
    {
      "arxiv_id": "2409.06566v1",
      "title": "Indirect Dynamic Negotiation in the Nash Demand Game",
      "title_zh": "Nash Demand Game 中的间接动态谈判",
      "authors": [
        "Tatiana V. Guy",
        "Jitka Homolová",
        "Aleksej Gaj"
      ],
      "abstract": "The paper addresses a problem of sequential bilateral bargaining with\nincomplete information. We proposed a decision model that helps agents to\nsuccessfully bargain by performing indirect negotiation and learning the\nopponent's model. Methodologically the paper casts heuristically-motivated\nbargaining of a self-interested independent player into a framework of Bayesian\nlearning and Markov decision processes. The special form of the reward\nimplicitly motivates the players to negotiate indirectly, via closed-loop\ninteraction. We illustrate the approach by applying our model to the Nash\ndemand game, which is an abstract model of bargaining. The results indicate\nthat the established negotiation: i) leads to coordinating players' actions;\nii) results in maximising success rate of the game and iii) brings more\nindividual profit to the players.",
      "tldr_zh": "本文探讨了不完全信息下的顺序双边讨价还价问题，提出了一种决策模型，通过间接谈判和学习对手模型来帮助代理实现成功讨价还价。该模型将启发式讨价还价框架化为Bayesian learning和Markov decision processes，利用闭环交互的奖励机制来激励间接谈判。在Nash demand game的实际应用中，结果显示该方法能协调玩家行动、最大化游戏成功率，并为玩家带来更多个人收益。",
      "categories": [
        "cs.GT",
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.GT",
      "comment": "Appears in IEEE Access",
      "pdf_url": "http://arxiv.org/pdf/2409.06566v1",
      "published_date": "2024-09-10 14:58:00 UTC",
      "updated_date": "2024-09-10 14:58:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:48:05.813805"
    },
    {
      "arxiv_id": "2409.06561v1",
      "title": "ChatGPT's Potential in Cryptography Misuse Detection: A Comparative Analysis with Static Analysis Tools",
      "title_zh": "翻译失败",
      "authors": [
        "Ehsan Firouzi",
        "Mohammad Ghafari",
        "Mike Ebrahimi"
      ],
      "abstract": "The correct adoption of cryptography APIs is challenging for mainstream\ndevelopers, often resulting in widespread API misuse. Meanwhile, cryptography\nmisuse detectors have demonstrated inconsistent performance and remain largely\ninaccessible to most developers. We investigated the extent to which ChatGPT\ncan detect cryptography misuses and compared its performance with that of the\nstate-of-the-art static analysis tools. Our investigation, mainly based on the\nCryptoAPI-Bench benchmark, demonstrated that ChatGPT is effective in\nidentifying cryptography API misuses, and with the use of prompt engineering,\nit can even outperform leading static cryptography misuse detectors.",
      "tldr_zh": "这篇论文探讨了 ChatGPT 在检测加密 API 误用方面的潜力，针对主流开发者在使用 cryptography APIs 时常见的问题进行了分析，并将其性能与最先进的 static analysis tools 进行比较。研究基于 CryptoAPI-Bench 基准测试，结果显示 ChatGPT 能够有效识别加密 API 误用，且通过 prompt engineering 优化后，甚至超过了领先的静态检测工具。该发现为开发者提供了一种更易访问的加密误用检测方法，扩展了 AI 在安全领域的应用。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "ESEM 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.06561v1",
      "published_date": "2024-09-10 14:50:12 UTC",
      "updated_date": "2024-09-10 14:50:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:48:18.743911"
    },
    {
      "arxiv_id": "2409.06518v1",
      "title": "Questioning Internal Knowledge Structure of Large Language Models Through the Lens of the Olympic Games",
      "title_zh": "翻译失败",
      "authors": [
        "Juhwan Choi",
        "YoungBin Kim"
      ],
      "abstract": "Large language models (LLMs) have become a dominant approach in natural\nlanguage processing, yet their internal knowledge structures remain largely\nunexplored. In this paper, we analyze the internal knowledge structures of LLMs\nusing historical medal tallies from the Olympic Games. We task the models with\nproviding the medal counts for each team and identifying which teams achieved\nspecific rankings. Our results reveal that while state-of-the-art LLMs perform\nremarkably well in reporting medal counts for individual teams, they struggle\nsignificantly with questions about specific rankings. This suggests that the\ninternal knowledge structures of LLMs are fundamentally different from those of\nhumans, who can easily infer rankings from known medal counts. To support\nfurther research, we publicly release our code, dataset, and model outputs.",
      "tldr_zh": "本研究通过奥林匹克运动会的历史奖牌数据，探讨大型语言模型（LLMs）的内部知识结构。研究者让模型报告各团队的奖牌数和特定排名，结果显示LLMs在提供单个团队奖牌数方面表现优秀，但对排名问题处理困难，这反映出其知识结构与人类（能轻松从奖牌数推断排名）存在根本差异。为促进进一步研究，该论文公开了代码、数据集和模型输出。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.06518v1",
      "published_date": "2024-09-10 13:54:04 UTC",
      "updated_date": "2024-09-10 13:54:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:48:29.464014"
    },
    {
      "arxiv_id": "2409.06513v3",
      "title": "Sines, Transient, Noise Neural Modeling of Piano Notes",
      "title_zh": "翻译失败",
      "authors": [
        "Riccardo Simionato",
        "Stefano Fasciani"
      ],
      "abstract": "This paper introduces a novel method for emulating piano sounds. We propose\nto exploit the sines, transient, and noise decomposition to design a\ndifferentiable spectral modeling synthesizer replicating piano notes. Three\nsub-modules learn these components from piano recordings and generate the\ncorresponding harmonic, transient, and noise signals. Splitting the emulation\ninto three independently trainable models reduces the modeling tasks'\ncomplexity. The quasi-harmonic content is produced using a differentiable\nsinusoidal model guided by physics-derived formulas, whose parameters are\nautomatically estimated from audio recordings. The noise sub-module uses a\nlearnable time-varying filter, and the transients are generated using a deep\nconvolutional network. From singular notes, we emulate the coupling between\ndifferent keys in trichords with a convolutional-based network. Results show\nthe model matches the partial distribution of the target while predicting the\nenergy in the higher part of the spectrum presents more challenges. The energy\ndistribution in the spectra of the transient and noise components is accurate\noverall. While the model is more computationally and memory efficient,\nperceptual tests reveal limitations in accurately modeling the attack phase of\nnotes. Despite this, it generally achieves perceptual accuracy in emulating\nsingle notes and trichords.",
      "tldr_zh": "这篇论文提出了一种新型钢琴声音模拟方法，通过 sines, transient, and noise 分解设计一个可微分的光谱建模合成器，分为三个子模块分别处理谐波信号（使用基于物理公式的正弦模型）、噪声信号（采用可学习时变滤波器）和瞬态信号（利用深度卷积网络）。该方法还扩展到模拟单个音符和三和弦（trichords）的耦合，提高了建模效率。实验结果显示，模型准确匹配了目标声音的部分分布和能量分布，但预测高频谱能量及音符攻击阶段存在挑战，尽管整体在感知准确性和计算效率上表现出色。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.06513v3",
      "published_date": "2024-09-10 13:48:18 UTC",
      "updated_date": "2025-02-01 13:18:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:48:43.069333"
    },
    {
      "arxiv_id": "2409.06509v3",
      "title": "Aligning Machine and Human Visual Representations across Abstraction Levels",
      "title_zh": "在不同抽象级别上对齐机器和人类视觉表示",
      "authors": [
        "Lukas Muttenthaler",
        "Klaus Greff",
        "Frieda Born",
        "Bernhard Spitzer",
        "Simon Kornblith",
        "Michael C. Mozer",
        "Klaus-Robert Müller",
        "Thomas Unterthiner",
        "Andrew K. Lampinen"
      ],
      "abstract": "Deep neural networks have achieved success across a wide range of\napplications, including as models of human behavior in vision tasks. However,\nneural network training and human learning differ in fundamental ways, and\nneural networks often fail to generalize as robustly as humans do, raising\nquestions regarding the similarity of their underlying representations. What is\nmissing for modern learning systems to exhibit more human-like behavior? We\nhighlight a key misalignment between vision models and humans: whereas human\nconceptual knowledge is hierarchically organized from fine- to coarse-scale\ndistinctions, model representations do not accurately capture all these levels\nof abstraction. To address this misalignment, we first train a teacher model to\nimitate human judgments, then transfer human-like structure from its\nrepresentations into pretrained state-of-the-art vision foundation models.\nThese human-aligned models more accurately approximate human behavior and\nuncertainty across a wide range of similarity tasks, including a new dataset of\nhuman judgments spanning multiple levels of semantic abstractions. They also\nperform better on a diverse set of machine learning tasks, increasing\ngeneralization and out-of-distribution robustness. Thus, infusing neural\nnetworks with additional human knowledge yields a best-of-both-worlds\nrepresentation that is both more consistent with human cognition and more\npractically useful, thus paving the way toward more robust, interpretable, and\nhuman-like artificial intelligence systems.",
      "tldr_zh": "本研究探讨了机器视觉表示与人类视觉表示在不同抽象级别(abstraction levels)上的不匹配问题，指出deep neural networks虽然在视觉任务中模仿人类行为取得成功，但其泛化能力和人类相比存在差距。作者提出了一种方法，先训练一个teacher model来模仿人类判断，然后将人类-like结构转移到预训练的state-of-the-art vision foundation models中。这些人类-aligned模型在各种相似性任务上更准确地模拟人类行为和不确定性，同时在机器学习任务中提升了泛化能力和out-of-distribution robustness。通过注入人类知识，该方法为构建更鲁棒、可解释的人类-like人工智能系统提供了新途径。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "54 pages",
      "pdf_url": "http://arxiv.org/pdf/2409.06509v3",
      "published_date": "2024-09-10 13:41:08 UTC",
      "updated_date": "2024-10-29 09:30:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:48:54.981904"
    },
    {
      "arxiv_id": "2409.06750v2",
      "title": "Can Agents Spontaneously Form a Society? Introducing a Novel Architecture for Generative Multi-Agents to Elicit Social Emergence",
      "title_zh": "翻译失败",
      "authors": [
        "H. Zhang",
        "J. Yin",
        "M. Jiang",
        "C. Su"
      ],
      "abstract": "Generative agents have demonstrated impressive capabilities in specific\ntasks, but most of these frameworks focus on independent tasks and lack\nattention to social interactions. We introduce a generative agent architecture\ncalled ITCMA-S, which includes a basic framework for individual agents and a\nframework called LTRHA that supports social interactions among multi-agents.\nThis architecture enables agents to identify and filter out behaviors that are\ndetrimental to social interactions, guiding them to choose more favorable\nactions. We designed a sandbox environment to simulate the natural evolution of\nsocial relationships among multiple identity-less agents for experimental\nevaluation. The results showed that ITCMA-S performed well on multiple\nevaluation indicators, demonstrating its ability to actively explore the\nenvironment, recognize new agents, and acquire new information through\ncontinuous actions and dialogue. Observations show that as agents establish\nconnections with each other, they spontaneously form cliques with internal\nhierarchies around a selected leader and organize collective activities.",
      "tldr_zh": "这篇论文探讨了生成代理是否能自发形成社会结构，引入了名为 ITCMA-S 的新型架构，以促进多代理系统的社会涌现。ITCMA-S 包括个体代理基本框架和 LTRHA 框架，用于识别并过滤有害社会行为的行动，从而引导代理选择更有利的互动方式。在沙盒环境中实验表明，该架构在多个评估指标上表现出色，代理能够主动探索环境、识别新代理并通过行动和对话获取信息，最终自发形成带有内部等级的派系，并围绕领导者组织集体活动。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.HC",
        "cs.LG",
        "68T42",
        "I.2.7; J.4"
      ],
      "primary_category": "cs.MA",
      "comment": "13 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.06750v2",
      "published_date": "2024-09-10 13:39:29 UTC",
      "updated_date": "2024-11-19 15:44:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:49:06.429629"
    },
    {
      "arxiv_id": "2409.06477v1",
      "title": "Superior Computer Chess with Model Predictive Control, Reinforcement Learning, and Rollout",
      "title_zh": "翻译失败",
      "authors": [
        "Atharva Gundawar",
        "Yuchao Li",
        "Dimitri Bertsekas"
      ],
      "abstract": "In this paper we apply model predictive control (MPC), rollout, and\nreinforcement learning (RL) methodologies to computer chess. We introduce a new\narchitecture for move selection, within which available chess engines are used\nas components. One engine is used to provide position evaluations in an\napproximation in value space MPC/RL scheme, while a second engine is used as\nnominal opponent, to emulate or approximate the moves of the true opponent\nplayer.\n  We show that our architecture improves substantially the performance of the\nposition evaluation engine. In other words our architecture provides an\nadditional layer of intelligence, on top of the intelligence of the engines on\nwhich it is based. This is true for any engine, regardless of its strength: top\nengines such as Stockfish and Komodo Dragon (of varying strengths), as well as\nweaker engines.\n  Structurally, our basic architecture selects moves by a one-move lookahead\nsearch, with an intermediate move generated by a nominal opponent engine, and\nfollowed by a position evaluation by another chess engine. Simpler schemes that\nforego the use of the nominal opponent, also perform better than the position\nevaluator, but not quite by as much. More complex schemes, involving multistep\nlookahead, may also be used and generally tend to perform better as the length\nof the lookahead increases.\n  Theoretically, our methodology relies on generic cost improvement properties\nand the superlinear convergence framework of Newton's method, which\nfundamentally underlies approximation in value space, and related MPC/RL and\nrollout/policy iteration schemes. A critical requirement of this framework is\nthat the first lookahead step should be executed exactly. This fact has guided\nour architectural choices, and is apparently an important factor in improving\nthe performance of even the best available chess engines.",
      "tldr_zh": "这篇论文将Model Predictive Control (MPC)、Reinforcement Learning (RL)和Rollout应用于国际象棋AI，引入一个新架构，使用两个棋引擎作为组件：一个引擎评估位置以实现价值空间近似，另一个引擎模拟对手的走法。实验结果显示，该架构显著提升了任何引擎的表现，包括顶级引擎如Stockfish和Komodo Dragon，通过一步前瞻搜索或更复杂的多步前瞻方案，提供额外的智能层。理论上，该方法依赖于成本改进属性和牛顿方法的超线性收敛框架，要求第一步前瞻精确执行，以优化整体性能。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.06477v1",
      "published_date": "2024-09-10 13:05:45 UTC",
      "updated_date": "2024-09-10 13:05:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:49:19.432514"
    },
    {
      "arxiv_id": "2409.17157v1",
      "title": "Confident Teacher, Confident Student? A Novel User Study Design for Investigating the Didactic Potential of Explanations and their Impact on Uncertainty",
      "title_zh": "翻译失败",
      "authors": [
        "Teodor Chiaburu",
        "Frank Haußer",
        "Felix Bießmann"
      ],
      "abstract": "Evaluating the quality of explanations in Explainable Artificial Intelligence\n(XAI) is to this day a challenging problem, with ongoing debate in the research\ncommunity. While some advocate for establishing standardized offline metrics,\nothers emphasize the importance of human-in-the-loop (HIL) evaluation. Here we\npropose an experimental design to evaluate the potential of XAI in human-AI\ncollaborative settings as well as the potential of XAI for didactics. In a user\nstudy with 1200 participants we investigate the impact of explanations on human\nperformance on a challenging visual task - annotation of biological species in\ncomplex taxonomies. Our results demonstrate the potential of XAI in complex\nvisual annotation tasks: users become more accurate in their annotations and\ndemonstrate less uncertainty with AI assistance. The increase in accuracy was,\nhowever, not significantly different when users were shown the mere prediction\nof the model compared to when also providing an explanation. We also find\nnegative effects of explanations: users tend to replicate the model's\npredictions more often when shown explanations, even when those predictions are\nwrong. When evaluating the didactic effects of explanations in collaborative\nhuman-AI settings, we find that users' annotations are not significantly better\nafter performing annotation with AI assistance. This suggests that explanations\nin visual human-AI collaboration do not appear to induce lasting learning\neffects. All code and experimental data can be found in our GitHub repository:\nhttps://github.com/TeodorChiaburu/beexplainable.",
      "tldr_zh": "这篇论文提出了一种新型用户研究设计，用于评估可解释人工智能(XAI)解释的教育潜力和对不确定性的影响，通过一个涉及1200名参与者的实验，考察了解释在复杂视觉任务（如生物物种注释）中的作用。研究发现，AI辅助显著提高了用户的准确性和减少了不确定性，但提供解释与仅显示模型预测的准确性提升无显著差异；此外，解释可能导致用户更频繁地复制模型的错误预测。总体而言，XAI解释在人类-AI协作中未显示出持久的学习效果，这为XAI的实际应用提供了重要启示。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "15 pages, 5 figures, 1 table, presented at ECML 2024, AIMLAI\n  Workshop, Vilnius",
      "pdf_url": "http://arxiv.org/pdf/2409.17157v1",
      "published_date": "2024-09-10 12:59:50 UTC",
      "updated_date": "2024-09-10 12:59:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:49:31.552242"
    },
    {
      "arxiv_id": "2409.06468v1",
      "title": "An Effective Context-Balanced Adaptation Approach for Long-Tailed Speech Recognition",
      "title_zh": "一种有效的上下文平衡适应方法，用于长尾语音识别",
      "authors": [
        "Yi-Cheng Wang",
        "Li-Ting Pai",
        "Bi-Cheng Yan",
        "Hsin-Wei Wang",
        "Chi-Han Lin",
        "Berlin Chen"
      ],
      "abstract": "End-to-end (E2E) automatic speech recognition (ASR) models have become\nstandard practice for various commercial applications. However, in real-world\nscenarios, the long-tailed nature of word distribution often leads E2E ASR\nmodels to perform well on common words but fall short in recognizing uncommon\nones. Recently, the notion of a contextual adapter (CA) was proposed to infuse\nexternal knowledge represented by a context word list into E2E ASR models.\nAlthough CA can improve recognition performance on rare words, two crucial data\nimbalance problems remain. First, when using low-frequency words as context\nwords during training, since these words rarely occur in the utterance, CA\nbecomes prone to overfit on attending to the <no-context> token due to\nhigher-frequency words not being present in the context list. Second, the\nlong-tailed distribution within the context list itself still causes the model\nto perform poorly on low-frequency context words. In light of this, we explore\nin-depth the impact of altering the context list to have words with different\nfrequency distributions on model performance, and meanwhile extend CA with a\nsimple yet effective context-balanced learning objective. A series of\nexperiments conducted on the AISHELL-1 benchmark dataset suggests that using\nall vocabulary words from the training corpus as the context list and pairing\nthem with our balanced objective yields the best performance, demonstrating a\nsignificant reduction in character error rate (CER) by up to 1.21% and a more\npronounced 9.44% reduction in the error rate of zero-shot words.",
      "tldr_zh": "这篇论文针对端到端自动语音识别 (E2E ASR) 模型在长尾词分布下的问题，提出了一种有效的上下文平衡适应方法，以改善对罕见词的识别性能。作者扩展了上下文适配器 (CA)，通过调整上下文列表的频率分布（如使用所有训练语料词汇作为列表）和引入上下文平衡学习目标，缓解模型对低频词的过拟合和数据不平衡问题。在 AISHELL-1 数据集上的实验表明，该方法将字符错误率 (CER) 降低了最多1.21%，并对零-shot 词的错误率降低了9.44%。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by SLT 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.06468v1",
      "published_date": "2024-09-10 12:52:36 UTC",
      "updated_date": "2024-09-10 12:52:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:49:43.218934"
    },
    {
      "arxiv_id": "2409.06450v1",
      "title": "Multimodal Large Language Model Driven Scenario Testing for Autonomous Vehicles",
      "title_zh": "多模态大语言模型驱动的自动驾驶车辆场景测试",
      "authors": [
        "Qiujing Lu",
        "Xuanhan Wang",
        "Yiwei Jiang",
        "Guangming Zhao",
        "Mingyue Ma",
        "Shuo Feng"
      ],
      "abstract": "The generation of corner cases has become increasingly crucial for\nefficiently testing autonomous vehicles prior to road deployment. However,\nexisting methods struggle to accommodate diverse testing requirements and often\nlack the ability to generalize to unseen situations, thereby reducing the\nconvenience and usability of the generated scenarios. A method that facilitates\neasily controllable scenario generation for efficient autonomous vehicles (AV)\ntesting with realistic and challenging situations is greatly needed. To address\nthis, we proposed OmniTester: a multimodal Large Language Model (LLM) based\nframework that fully leverages the extensive world knowledge and reasoning\ncapabilities of LLMs. OmniTester is designed to generate realistic and diverse\nscenarios within a simulation environment, offering a robust solution for\ntesting and evaluating AVs. In addition to prompt engineering, we employ tools\nfrom Simulation of Urban Mobility to simplify the complexity of codes generated\nby LLMs. Furthermore, we incorporate Retrieval-Augmented Generation and a\nself-improvement mechanism to enhance the LLM's understanding of scenarios,\nthereby increasing its ability to produce more realistic scenes. In the\nexperiments, we demonstrated the controllability and realism of our approaches\nin generating three types of challenging and complex scenarios. Additionally,\nwe showcased its effectiveness in reconstructing new scenarios described in\ncrash report, driven by the generalization capability of LLMs.",
      "tldr_zh": "该论文提出 OmniTester，一种基于 Multimodal Large Language Model (LLM) 的框架，用于生成真实、多样化的自动驾驶车辆测试场景，以解决现有方法在处理多样需求和泛化能力方面的不足。框架利用 LLM 的广泛世界知识和推理能力，结合提示工程、Retrieval-Augmented Generation 和自提升机制，以及 Simulation of Urban Mobility 工具，简化代码并提升场景的真实性与可控性。实验结果显示，OmniTester 在生成三种挑战性复杂场景以及重建崩溃报告描述的新场景中表现出色，显著提高了测试效率和效果。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.06450v1",
      "published_date": "2024-09-10 12:12:09 UTC",
      "updated_date": "2024-09-10 12:12:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:49:55.382031"
    },
    {
      "arxiv_id": "2409.06446v1",
      "title": "HexaCoder: Secure Code Generation via Oracle-Guided Synthetic Training Data",
      "title_zh": "翻译失败",
      "authors": [
        "Hossein Hajipour",
        "Lea Schönherr",
        "Thorsten Holz",
        "Mario Fritz"
      ],
      "abstract": "Large language models (LLMs) have shown great potential for automatic code\ngeneration and form the basis for various tools such as GitHub Copilot.\nHowever, recent studies highlight that many LLM-generated code contains serious\nsecurity vulnerabilities. While previous work tries to address this by training\nmodels that generate secure code, these attempts remain constrained by limited\naccess to training data and labor-intensive data preparation.\n  In this paper, we introduce HexaCoder, a novel approach to enhance the\nability of LLMs to generate secure codes by automatically synthesizing secure\ncodes, which reduces the effort of finding suitable training data. HexaCoder\ncomprises two key components: an oracle-guided data synthesis pipeline and a\ntwo-step process for secure code generation. The data synthesis pipeline\ngenerates pairs of vulnerable and fixed codes for specific Common Weakness\nEnumeration (CWE) types by utilizing a state-of-the-art LLM for repairing\nvulnerable code. A security oracle identifies vulnerabilities, and a\nstate-of-the-art LLM repairs them by extending and/or editing the codes,\ncreating data pairs for fine-tuning using the Low-Rank Adaptation (LoRA)\nmethod. Each example of our fine-tuning dataset includes the necessary\nsecurity-related libraries and code that form the basis of our novel two-step\ngeneration approach. This allows the model to integrate security-relevant\nlibraries before generating the main code, significantly reducing the number of\ngenerated vulnerable codes by up to 85% compared to the baseline methods. We\nperform extensive evaluations on three different benchmarks for four LLMs,\ndemonstrating that HexaCoder not only improves the security of the generated\ncode but also maintains a high level of functional correctness.",
      "tldr_zh": "本文提出 HexaCoder，一种通过 oracle 指导的合成训练数据方法，提升 LLMs 在代码生成中的安全性，以解决现有模型常产生漏洞的问题。该方法包括一个数据合成管道，利用安全 oracle 识别 Common Weakness Enumeration (CWE) 漏洞，并使用 LLM 修复代码生成漏洞-修复数据对，然后通过 Low-Rank Adaptation (LoRA) 进行微调。HexaCoder 的两步生成过程先集成安全相关库再生成主代码，相比基线方法减少漏洞代码高达 85%。实验在三个基准上评估四个 LLMs，证明该框架显著提高了代码的安全性，同时维持了高功能正确性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.SE"
      ],
      "primary_category": "cs.CR",
      "comment": "24 pages, 16 tables, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.06446v1",
      "published_date": "2024-09-10 12:01:43 UTC",
      "updated_date": "2024-09-10 12:01:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:50:07.104484"
    },
    {
      "arxiv_id": "2409.06445v2",
      "title": "Learning Generative Interactive Environments By Trained Agent Exploration",
      "title_zh": "翻译失败",
      "authors": [
        "Naser Kazemi",
        "Nedko Savov",
        "Danda Paudel",
        "Luc Van Gool"
      ],
      "abstract": "World models are increasingly pivotal in interpreting and simulating the\nrules and actions of complex environments. Genie, a recent model, excels at\nlearning from visually diverse environments but relies on costly\nhuman-collected data. We observe that their alternative method of using random\nagents is too limited to explore the environment. We propose to improve the\nmodel by employing reinforcement learning based agents for data generation.\nThis approach produces diverse datasets that enhance the model's ability to\nadapt and perform well across various scenarios and realistic actions within\nthe environment. In this paper, we first release the model GenieRedux - an\nimplementation based on Genie. Additionally, we introduce GenieRedux-G, a\nvariant that uses the agent's readily available actions to factor out action\nprediction uncertainty during validation. Our evaluation, including a\nreplication of the Coinrun case study, shows that GenieRedux-G achieves\nsuperior visual fidelity and controllability using the trained agent\nexploration. The proposed approach is reproducable, scalable and adaptable to\nnew types of environments. Our codebase is available at\nhttps://github.com/insait-institute/GenieRedux .",
      "tldr_zh": "这篇论文提出了一种改进生成式交互环境学习的方法，通过使用强化学习（reinforcement learning）训练的代理来探索环境，从而生成多样化的数据集，解决现有模型如 Genie 依赖昂贵人类数据的局限性。相比随机代理，该方法提升了模型在各种场景中的适应性和性能。作者发布了 GenieRedux 模型及其变体 GenieRedux-G，后者通过利用代理的可用动作减少验证中的动作预测不确定性。在评估中，包括 Coinrun 案例研究，GenieRedux-G 展示了优越的视觉保真度（visual fidelity）和可控性，且该方法是可重现、可扩展的，并提供了开源代码库。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.06445v2",
      "published_date": "2024-09-10 12:00:40 UTC",
      "updated_date": "2024-10-18 17:37:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:50:19.518187"
    },
    {
      "arxiv_id": "2409.06748v1",
      "title": "EasyST: A Simple Framework for Spatio-Temporal Prediction",
      "title_zh": "EasyST：一种用于时空预测的简单框架",
      "authors": [
        "Jiabin Tang",
        "Wei Wei",
        "Lianghao Xia",
        "Chao Huang"
      ],
      "abstract": "Spatio-temporal prediction is a crucial research area in data-driven urban\ncomputing, with implications for transportation, public safety, and\nenvironmental monitoring. However, scalability and generalization challenges\nremain significant obstacles. Advanced models often rely on Graph Neural\nNetworks to encode spatial and temporal correlations, but struggle with the\nincreased complexity of large-scale datasets. The recursive GNN-based message\npassing schemes used in these models hinder their training and deployment in\nreal-life urban sensing scenarios. Moreover, long-spanning large-scale\nspatio-temporal data introduce distribution shifts, necessitating improved\ngeneralization performance. To address these challenges, we propose a simple\nframework for spatio-temporal prediction - EasyST paradigm. It learns\nlightweight and robust Multi-Layer Perceptrons (MLPs) by effectively distilling\nknowledge from complex spatio-temporal GNNs. We ensure robust knowledge\ndistillation by integrating the spatio-temporal information bottleneck with\nteacher-bounded regression loss, filtering out task-irrelevant noise and\navoiding erroneous guidance. We further enhance the generalization ability of\nthe student model by incorporating spatial and temporal prompts to provide\ndownstream task contexts. Evaluation on three spatio-temporal datasets for\nurban computing tasks demonstrates that EasyST surpasses state-of-the-art\napproaches in terms of efficiency and accuracy. The implementation code is\navailable at: https://github.com/HKUDS/EasyST.",
      "tldr_zh": "该研究针对时空预测（Spatio-Temporal Prediction）在城市计算中的挑战，如模型的可扩展性和泛化问题，提出了一种简单框架EasyST。EasyST通过知识蒸馏（knowledge distillation）从复杂的时空GNNs（Graph Neural Networks）中学习轻量级的MLPs（Multi-Layer Perceptrons），并整合时空信息瓶颈（spatio-temporal information bottleneck）和教师边界回归损失（teacher-bounded regression loss）来过滤无关噪声，同时使用空间和时间提示（spatial and temporal prompts）提升模型的泛化能力。在三个城市计算数据集上的实验表明，EasyST在效率和准确性上超越了最先进的方法，代码已在GitHub开源。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by CIKM'2024, full paper",
      "pdf_url": "http://arxiv.org/pdf/2409.06748v1",
      "published_date": "2024-09-10 11:40:01 UTC",
      "updated_date": "2024-09-10 11:40:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:50:31.853907"
    },
    {
      "arxiv_id": "2409.06427v1",
      "title": "GeMuCo: Generalized Multisensory Correlational Model for Body Schema Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Kento Kawaharazuka",
        "Kei Okada",
        "Masayuki Inaba"
      ],
      "abstract": "Humans can autonomously learn the relationship between sensation and motion\nin their own bodies, estimate and control their own body states, and move while\ncontinuously adapting to the current environment. On the other hand, current\nrobots control their bodies by learning the network structure described by\nhumans from their experiences, making certain assumptions on the relationship\nbetween sensors and actuators. In addition, the network model does not adapt to\nchanges in the robot's body, the tools that are grasped, or the environment,\nand there is no unified theory, not only for control but also for state\nestimation, anomaly detection, simulation, and so on. In this study, we propose\na Generalized Multisensory Correlational Model (GeMuCo), in which the robot\nitself acquires a body schema describing the correlation between sensors and\nactuators from its own experience, including model structures such as network\ninput/output. The robot adapts to the current environment by updating this body\nschema model online, estimates and controls its body state, and even performs\nanomaly detection and simulation. We demonstrate the effectiveness of this\nmethod by applying it to tool-use considering changes in grasping state for an\naxis-driven robot, to joint-muscle mapping learning for a musculoskeletal\nrobot, and to full-body tool manipulation for a low-rigidity plastic-made\nhumanoid.",
      "tldr_zh": "论文提出 Generalized Multisensory Correlational Model (GeMuCo)，一种让机器人从自身经验中自主学习身体模式 (body schema) 的模型，以描述传感器和执行器之间的相关性，从而解决现有机器人控制系统无法适应身体、工具或环境变化的问题。GeMuCo 通过在线更新模型结构，实现状态估计、控制、异常检测和模拟等功能。实验结果显示，该方法在轴驱动机器人工具使用、肌肉骨骼机器人关节-肌肉映射学习，以及塑料人形机器人全身工具操作中均表现出有效性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted at IEEE Robotics and Automation Magazine",
      "pdf_url": "http://arxiv.org/pdf/2409.06427v1",
      "published_date": "2024-09-10 11:19:13 UTC",
      "updated_date": "2024-09-10 11:19:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:50:42.446570"
    },
    {
      "arxiv_id": "2409.09079v1",
      "title": "D3-GNN: Dynamic Distributed Dataflow for Streaming Graph Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Rustam Guliyev",
        "Aparajita Haldar",
        "Hakan Ferhatosmanoglu"
      ],
      "abstract": "Graph Neural Network (GNN) models on streaming graphs entail algorithmic\nchallenges to continuously capture its dynamic state, as well as systems\nchallenges to optimize latency, memory, and throughput during both inference\nand training. We present D3-GNN, the first distributed, hybrid-parallel,\nstreaming GNN system designed to handle real-time graph updates under online\nquery setting. Our system addresses data management, algorithmic, and systems\nchallenges, enabling continuous capturing of the dynamic state of the graph and\nupdating node representations with fault-tolerance and optimal latency,\nload-balance, and throughput. D3-GNN utilizes streaming GNN aggregators and an\nunrolled, distributed computation graph architecture to handle cascading graph\nupdates. To counteract data skew and neighborhood explosion issues, we\nintroduce inter-layer and intra-layer windowed forward pass solutions.\nExperiments on large-scale graph streams demonstrate that D3-GNN achieves high\nefficiency and scalability. Compared to DGL, D3-GNN achieves a significant\nthroughput improvement of about 76x for streaming workloads. The windowed\nenhancement further reduces running times by around 10x and message volumes by\nup to 15x at higher parallelism.",
      "tldr_zh": "本论文提出D3-GNN，一种动态分布式数据流系统，旨在处理流式Graph Neural Networks (GNN)中的实时图更新挑战，包括算法和系统方面的优化，如延迟、内存和吞吐量。D3-GNN采用流式GNN聚合器、展开的分布式计算图架构，以及层间和层内窗口化前向传播来解决数据倾斜和邻居爆炸问题，确保图状态的连续捕获、容错和负载平衡。实验结果显示，在大规模图流上，D3-GNN相较于DGL提高了约76倍的吞吐量，并通过窗口化增强减少了运行时间约10倍和消息量最多15倍。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.DC",
      "comment": "14 pages, 7 figures, published at VLDB'24",
      "pdf_url": "http://arxiv.org/pdf/2409.09079v1",
      "published_date": "2024-09-10 11:00:43 UTC",
      "updated_date": "2024-09-10 11:00:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:50:55.214911"
    },
    {
      "arxiv_id": "2409.06416v1",
      "title": "Exploring the Integration of Large Language Models in Industrial Test Maintenance Processes",
      "title_zh": "探索大型语言模型在工业测试维护流程中的整合",
      "authors": [
        "Ludvig Lemner",
        "Linnea Wahlgren",
        "Gregory Gay",
        "Nasser Mohammadiha",
        "Jingxiong Liu",
        "Joakim Wennerberg"
      ],
      "abstract": "Much of the cost and effort required during the software testing process is\ninvested in performing test maintenance - the addition, removal, or\nmodification of test cases to keep the test suite in sync with the\nsystem-under-test or to otherwise improve its quality. Tool support could\nreduce the cost - and improve the quality - of test maintenance by automating\naspects of the process or by providing guidance and support to developers.\n  In this study, we explore the capabilities and applications of large language\nmodels (LLMs) - complex machine learning models adapted to textual analysis -\nto support test maintenance. We conducted a case study at Ericsson AB where we\nexplored the triggers that indicate the need for test maintenance, the actions\nthat LLMs can take, and the considerations that must be made when deploying\nLLMs in an industrial setting. We also proposed and demonstrated\nimplementations of two multi-agent architectures that can predict which test\ncases require maintenance following a change to the source code. Collectively,\nthese contributions advance our theoretical and practical understanding of how\nLLMs can be deployed to benefit industrial test maintenance processes.",
      "tldr_zh": "该研究探讨了大型语言模型 (LLMs) 在工业测试维护过程中的整合，以降低测试用例的添加、移除或修改成本，并提升测试质量。通过在 Ericsson AB 进行案例研究，分析了触发测试维护的因素、LLMs 可能采取的行动，以及工业部署的考虑因素。论文提出了两种 multi-agent architectures 的实现，用于预测源代码变化后哪些测试用例需要维护。这些贡献增强了对 LLMs 在工业测试维护中的理论和实践理解。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "Under submission to ACM TOSEM",
      "pdf_url": "http://arxiv.org/pdf/2409.06416v1",
      "published_date": "2024-09-10 10:55:48 UTC",
      "updated_date": "2024-09-10 10:55:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:51:09.095891"
    },
    {
      "arxiv_id": "2409.06402v2",
      "title": "Symmetry Breaking in Neural Network Optimization: Insights from Input Dimension Expansion",
      "title_zh": "神经网络优化中的对称性破缺：从输入维度扩展的洞见",
      "authors": [
        "Jun-Jie Zhang",
        "Nan Cheng",
        "Fu-Peng Li",
        "Xiu-Cheng Wang",
        "Jian-Nan Chen",
        "Long-Gang Pang",
        "Deyu Meng"
      ],
      "abstract": "Understanding the mechanisms behind neural network optimization is crucial\nfor improving network design and performance. While various optimization\ntechniques have been developed, a comprehensive understanding of the underlying\nprinciples that govern these techniques remains elusive. Specifically, the role\nof symmetry breaking, a fundamental concept in physics, has not been fully\nexplored in neural network optimization. This gap in knowledge limits our\nability to design networks that are both efficient and effective. Here, we\npropose the symmetry breaking hypothesis to elucidate the significance of\nsymmetry breaking in enhancing neural network optimization. We demonstrate that\na simple input expansion can significantly improve network performance across\nvarious tasks, and we show that this improvement can be attributed to the\nunderlying symmetry breaking mechanism. We further develop a metric to quantify\nthe degree of symmetry breaking in neural networks, providing a practical\napproach to evaluate and guide network design. Our findings confirm that\nsymmetry breaking is a fundamental principle that underpins various\noptimization techniques, including dropout, batch normalization, and\nequivariance. By quantifying the degree of symmetry breaking, our work offers a\npractical technique for performance enhancement and a metric to guide network\ndesign without the need for complete datasets and extensive training processes.",
      "tldr_zh": "这篇论文探讨了神经网络优化中对称性破坏（symmetry breaking）的机制，提出对称性破坏假设（symmetry breaking hypothesis）以解释其在提升性能中的关键作用。研究者通过简单的输入维度扩展（input dimension expansion）方法，展示了网络在各种任务上的显著性能改善，并将其归因于底层对称性破坏机制。他们开发了一个量化对称性破坏程度的指标，提供了一种实用工具来指导网络设计，而无需完整数据集和大量训练过程。最终，研究证实对称性破坏是多种优化技术（如dropout、batch normalization和equivariance）的根本原则，为高效网络设计提供了新见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math-ph",
        "math.MP"
      ],
      "primary_category": "cs.LG",
      "comment": "29 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.06402v2",
      "published_date": "2024-09-10 10:36:40 UTC",
      "updated_date": "2024-09-12 10:47:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:51:18.590466"
    },
    {
      "arxiv_id": "2409.06371v1",
      "title": "Distilling Generative-Discriminative Representations for Very Low-Resolution Face Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Junzheng Zhang",
        "Weijia Guo",
        "Bochao Liu",
        "Ruixin Shi",
        "Yong Li",
        "Shiming Ge"
      ],
      "abstract": "Very low-resolution face recognition is challenging due to the serious loss\nof informative facial details in resolution degradation. In this paper, we\npropose a generative-discriminative representation distillation approach that\ncombines generative representation with cross-resolution aligned knowledge\ndistillation. This approach facilitates very low-resolution face recognition by\njointly distilling generative and discriminative models via two distillation\nmodules. Firstly, the generative representation distillation takes the encoder\nof a diffusion model pretrained for face super-resolution as the generative\nteacher to supervise the learning of the student backbone via feature\nregression, and then freezes the student backbone. After that, the\ndiscriminative representation distillation further considers a pretrained face\nrecognizer as the discriminative teacher to supervise the learning of the\nstudent head via cross-resolution relational contrastive distillation. In this\nway, the general backbone representation can be transformed into discriminative\nhead representation, leading to a robust and discriminative student model for\nvery low-resolution face recognition. Our approach improves the recovery of the\nmissing details in very low-resolution faces and achieves better knowledge\ntransfer. Extensive experiments on face datasets demonstrate that our approach\nenhances the recognition accuracy of very low-resolution faces, showcasing its\neffectiveness and adaptability.",
      "tldr_zh": "这篇论文提出了一种生成-判别表示蒸馏方法，用于解决非常低分辨率人脸识别中信息丢失的挑战，通过结合生成表示和跨分辨率对齐知识蒸馏来提升模型性能。该方法首先利用预训练的扩散模型编码器作为生成教师，通过特征回归监督学生主干网络的学习，然后冻结主干网络；随后，使用预训练人脸识别器作为判别教师，通过跨分辨率关系对比蒸馏来优化学生头的判别表示，从而生成更鲁棒的模型。实验结果显示，该方法显著改善了低分辨率人脸中缺失细节的恢复，并在多个面部数据集上提升了识别准确性，证明了其有效性和适应性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.06371v1",
      "published_date": "2024-09-10 09:53:06 UTC",
      "updated_date": "2024-09-10 09:53:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:51:31.297738"
    },
    {
      "arxiv_id": "2409.06367v1",
      "title": "Texture-AD: An Anomaly Detection Dataset and Benchmark for Real Algorithm Development",
      "title_zh": "Texture-AD：异常检测数据集和基准，用于真实算法开发",
      "authors": [
        "Tianwu Lei",
        "Bohan Wang",
        "Silin Chen",
        "Shurong Cao",
        "Ningmu Zou"
      ],
      "abstract": "Anomaly detection is a crucial process in industrial manufacturing and has\nmade significant advancements recently. However, there is a large variance\nbetween the data used in the development and the data collected by the\nproduction environment. Therefore, we present the Texture-AD benchmark based on\nrepresentative texture-based anomaly detection to evaluate the effectiveness of\nunsupervised anomaly detection algorithms in real-world applications. This\ndataset includes images of 15 different cloth, 14 semiconductor wafers and 10\nmetal plates acquired under different optical schemes. In addition, it includes\nmore than 10 different types of defects produced during real manufacturing\nprocesses, such as scratches, wrinkles, color variations and point defects,\nwhich are often more difficult to detect than existing datasets. All anomalous\nareas are provided with pixel-level annotations to facilitate comprehensive\nevaluation using anomaly detection models. Specifically, to adapt to diverse\nproducts in automated pipelines, we present a new evaluation method and results\nof baseline algorithms. The experimental results show that Texture-AD is a\ndifficult challenge for state-of-the-art algorithms. To our knowledge,\nTexture-AD is the first dataset to be devoted to evaluating industrial defect\ndetection algorithms in the real world. The dataset is available at\nhttps://XXX.",
      "tldr_zh": "这篇论文引入了 Texture-AD，这是一个针对真实算法开发的设计异常检测（Anomaly Detection）数据集和基准，用于评估无监督异常检测算法在实际工业环境中的有效性。该数据集包括 15 种布料、14 种半导体晶圆和 10 种金属板的图像，涵盖超过 10 种真实制造缺陷，如 scratches、wrinkles、color variations 和 point defects，这些缺陷比现有数据集更难检测，并提供像素级标注以便全面评估。为适应自动化流水线中的多样产品，论文提出了一种新的评估方法，并展示了基线算法的结果，实验表明 Texture-AD 对最先进算法构成了重大挑战。作为首个专注于真实世界工业缺陷检测的数据集，Texture-AD 填补了现有数据与生产环境之间差距的空白。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.06367v1",
      "published_date": "2024-09-10 09:44:38 UTC",
      "updated_date": "2024-09-10 09:44:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:51:43.369982"
    },
    {
      "arxiv_id": "2409.06362v1",
      "title": "Connecting Concept Convexity and Human-Machine Alignment in Deep Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Teresa Dorszewski",
        "Lenka Tětková",
        "Lorenz Linhardt",
        "Lars Kai Hansen"
      ],
      "abstract": "Understanding how neural networks align with human cognitive processes is a\ncrucial step toward developing more interpretable and reliable AI systems.\nMotivated by theories of human cognition, this study examines the relationship\nbetween \\emph{convexity} in neural network representations and\n\\emph{human-machine alignment} based on behavioral data. We identify a\ncorrelation between these two dimensions in pretrained and fine-tuned vision\ntransformer models. Our findings suggest that the convex regions formed in\nlatent spaces of neural networks to some extent align with human-defined\ncategories and reflect the similarity relations humans use in cognitive tasks.\nWhile optimizing for alignment generally enhances convexity, increasing\nconvexity through fine-tuning yields inconsistent effects on alignment, which\nsuggests a complex relationship between the two. This study presents a first\nstep toward understanding the relationship between the convexity of latent\nrepresentations and human-machine alignment.",
      "tldr_zh": "本研究探讨了深度神经网络中概念凸性（convexity）和人类-机器对齐（human-machine alignment）之间的关系，以提升AI系统的可解释性和可靠性。研究基于人类认知理论，使用行为数据分析预训练和微调的vision transformer模型，发现神经网络潜空间中的凸区域部分与人类定义的类别和相似性关系对齐。结果显示，优化对齐通常会增强凸性，但通过微调增加凸性对对齐的影响并不一致。该工作为理解潜表示的凸性与人类-机器对齐提供了初步见解。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "First two authors contributed equally",
      "pdf_url": "http://arxiv.org/pdf/2409.06362v1",
      "published_date": "2024-09-10 09:32:16 UTC",
      "updated_date": "2024-09-10 09:32:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:51:54.801541"
    },
    {
      "arxiv_id": "2409.06356v2",
      "title": "Double Successive Over-Relaxation Q-Learning with an Extension to Deep Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Shreyas S R"
      ],
      "abstract": "Q-learning is a widely used algorithm in reinforcement learning (RL), but its\nconvergence can be slow, especially when the discount factor is close to one.\nSuccessive Over-Relaxation (SOR) Q-learning, which introduces a relaxation\nfactor to speed up convergence, addresses this issue but has two major\nlimitations: In the tabular setting, the relaxation parameter depends on\ntransition probability, making it not entirely model-free, and it suffers from\noverestimation bias. To overcome these limitations, we propose a sample-based,\nmodel-free double SOR Q-learning algorithm. Theoretically and empirically, this\nalgorithm is shown to be less biased than SOR Q-learning. Further, in the\ntabular setting, the convergence analysis under boundedness assumptions on\niterates is discussed. The proposed algorithm is extended to large-scale\nproblems using deep RL. Finally, the tabular version of the proposed algorithm\nis compared using roulette and grid world environments, while the deep RL\nversion is tested on a maximization bias example and OpenAI Gym environments.",
      "tldr_zh": "本文提出了一种双重 Successive Over-Relaxation (SOR) Q-learning 算法，以解决传统 Q-learning 在强化学习中收敛缓慢的问题，同时克服 SOR Q-learning 的依赖转移概率和过估计偏差的局限性。该算法采用样本-based 和完全无模型的方法，在理论上和经验上显示出更低的偏差，并在表格设置下进行了收敛分析。作者进一步扩展了该算法到深度强化学习领域，并通过轮盘、网格世界和 OpenAI Gym 环境进行实验验证，证明了其在大型问题中的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.06356v2",
      "published_date": "2024-09-10 09:23:03 UTC",
      "updated_date": "2025-05-15 15:16:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:52:07.098761"
    },
    {
      "arxiv_id": "2409.06351v1",
      "title": "MAGDA: Multi-agent guideline-driven diagnostic assistance",
      "title_zh": "翻译失败",
      "authors": [
        "David Bani-Harouni",
        "Nassir Navab",
        "Matthias Keicher"
      ],
      "abstract": "In emergency departments, rural hospitals, or clinics in less developed\nregions, clinicians often lack fast image analysis by trained radiologists,\nwhich can have a detrimental effect on patients' healthcare. Large Language\nModels (LLMs) have the potential to alleviate some pressure from these\nclinicians by providing insights that can help them in their decision-making.\nWhile these LLMs achieve high test results on medical exams showcasing their\ngreat theoretical medical knowledge, they tend not to follow medical\nguidelines. In this work, we introduce a new approach for zero-shot\nguideline-driven decision support. We model a system of multiple LLM agents\naugmented with a contrastive vision-language model that collaborate to reach a\npatient diagnosis. After providing the agents with simple diagnostic\nguidelines, they will synthesize prompts and screen the image for findings\nfollowing these guidelines. Finally, they provide understandable\nchain-of-thought reasoning for their diagnosis, which is then self-refined to\nconsider inter-dependencies between diseases. As our method is zero-shot, it is\nadaptable to settings with rare diseases, where training data is limited, but\nexpert-crafted disease descriptions are available. We evaluate our method on\ntwo chest X-ray datasets, CheXpert and ChestX-ray 14 Longtail, showcasing\nperformance improvement over existing zero-shot methods and generalizability to\nrare diseases.",
      "tldr_zh": "该论文提出了 MAGDA，一种多代理系统，利用大型语言模型 (LLMs) 和对比视觉语言模型，针对紧急部门或资源有限地区提供基于指南的零样本诊断辅助，以缓解临床医生缺乏放射科支持的问题。系统让多个代理根据简单诊断指南合成提示、筛选图像并生成 chain-of-thought 推理的诊断结果，同时通过自我优化考虑疾病间依赖，提升诊断准确性。作为零样本方法，它适应性强，仅需专家描述即可应用于稀有疾病场景。在 CheXpert 和 ChestX-ray 14 Longtail 数据集上，MAGDA 性能优于现有零样本方法，并展示了良好的泛化能力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.06351v1",
      "published_date": "2024-09-10 09:10:30 UTC",
      "updated_date": "2024-09-10 09:10:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:52:19.286905"
    },
    {
      "arxiv_id": "2409.06348v1",
      "title": "VoiceWukong: Benchmarking Deepfake Voice Detection",
      "title_zh": "VoiceWukong: 深度伪造语音检测的基准测试",
      "authors": [
        "Ziwei Yan",
        "Yanjie Zhao",
        "Haoyu Wang"
      ],
      "abstract": "With the rapid advancement of technologies like text-to-speech (TTS) and\nvoice conversion (VC), detecting deepfake voices has become increasingly\ncrucial. However, both academia and industry lack a comprehensive and intuitive\nbenchmark for evaluating detectors. Existing datasets are limited in language\ndiversity and lack many manipulations encountered in real-world production\nenvironments.\n  To fill this gap, we propose VoiceWukong, a benchmark designed to evaluate\nthe performance of deepfake voice detectors. To build the dataset, we first\ncollected deepfake voices generated by 19 advanced and widely recognized\ncommercial tools and 15 open-source tools. We then created 38 data variants\ncovering six types of manipulations, constructing the evaluation dataset for\ndeepfake voice detection. VoiceWukong thus includes 265,200 English and 148,200\nChinese deepfake voice samples. Using VoiceWukong, we evaluated 12\nstate-of-the-art detectors. AASIST2 achieved the best equal error rate (EER) of\n13.50%, while all others exceeded 20%. Our findings reveal that these detectors\nface significant challenges in real-world applications, with dramatically\ndeclining performance. In addition, we conducted a user study with more than\n300 participants. The results are compared with the performance of the 12\ndetectors and a multimodel large language model (MLLM), i.e., Qwen2-Audio,\nwhere different detectors and humans exhibit varying identification\ncapabilities for deepfake voices at different deception levels, while the LALM\ndemonstrates no detection ability at all. Furthermore, we provide a leaderboard\nfor deepfake voice detection, publicly available at\n{https://voicewukong.github.io}.",
      "tldr_zh": "该研究提出VoiceWukong基准，用于全面评估深度伪造声音检测器，以应对TTS和VC技术的快速发展。研究构建了一个数据集，包括19个商业工具和15个开源工具生成的深度伪造声音样本，共38个数据变体覆盖六种真实世界操纵类型，包含265,200个英语和148,200个中文样本。实验评估了12个最先进检测器，其中AASIST2的EER最低为13.50%，但其他检测器均超过20%，并通过用户研究发现人类和检测器在不同欺骗水平下的识别能力差异，同时提供公开排行榜以促进进一步研究。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CR",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.06348v1",
      "published_date": "2024-09-10 09:07:12 UTC",
      "updated_date": "2024-09-10 09:07:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:52:31.378992"
    },
    {
      "arxiv_id": "2409.06343v2",
      "title": "Compute-Update Federated Learning: A Lattice Coding Approach Over-the-Air",
      "title_zh": "翻译失败",
      "authors": [
        "Seyed Mohammad Azimi-Abarghouyi",
        "Lav R. Varshney"
      ],
      "abstract": "This paper introduces a federated learning framework that enables\nover-the-air computation via digital communications, using a new joint\nsource-channel coding scheme. Without relying on channel state information at\ndevices, this scheme employs lattice codes to both quantize model parameters\nand exploit interference from the devices. We propose a novel receiver\nstructure at the server, designed to reliably decode an integer combination of\nthe quantized model parameters as a lattice point for the purpose of\naggregation. We present a mathematical approach to derive a convergence bound\nfor the proposed scheme and offer design remarks. In this context, we suggest\nan aggregation metric and a corresponding algorithm to determine effective\ninteger coefficients for the aggregation in each communication round. Our\nresults illustrate that, regardless of channel dynamics and data heterogeneity,\nour scheme consistently delivers superior learning accuracy across various\nparameters and markedly surpasses other over-the-air methodologies.",
      "tldr_zh": "这篇论文提出了一种名为Compute-Update Federated Learning的框架，利用格编码(lattice codes)实现基于数字通信的空中计算(over-the-air computation)，无需依赖设备的信道状态信息(channel state information)。该框架采用联合源-信道编码方案来量化模型参数并利用设备间的干扰，设计了一个新颖的服务器接收器结构，以可靠地解码量化参数的整数组合作为格点进行聚合。作者还提供了收敛界(convergence bound)的数学推导、聚合指标和相应算法，结果表明该方案在各种信道动态和数据异质性条件下，显著优于其他空中计算方法，提供更高的学习准确率。",
      "categories": [
        "cs.IT",
        "cs.AI",
        "cs.LG",
        "math.IT"
      ],
      "primary_category": "cs.IT",
      "comment": "Extended version of the preprint available at arXiv:2403.01023",
      "pdf_url": "http://arxiv.org/pdf/2409.06343v2",
      "published_date": "2024-09-10 08:52:24 UTC",
      "updated_date": "2024-11-05 21:17:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:52:53.718955"
    },
    {
      "arxiv_id": "2409.06336v3",
      "title": "Towards Agentic AI on Particle Accelerators",
      "title_zh": "翻译失败",
      "authors": [
        "Antonin Sulc",
        "Thorsten Hellert",
        "Raimund Kammering",
        "Hayden Hoschouer",
        "Jason St. John"
      ],
      "abstract": "As particle accelerators grow in complexity, traditional control methods face\nincreasing challenges in achieving optimal performance. This paper envisions a\nparadigm shift: a decentralized multi-agent framework for accelerator control,\npowered by Large Language Models (LLMs) and distributed among autonomous\nagents. We present a proposition of a self-improving decentralized system where\nintelligent agents handle high-level tasks and communication and each agent is\nspecialized to control individual accelerator components.\n  This approach raises some questions: What are the future applications of AI\nin particle accelerators? How can we implement an autonomous complex system\nsuch as a particle accelerator where agents gradually improve through\nexperience and human feedback? What are the implications of integrating a\nhuman-in-the-loop component for labeling operational data and providing expert\nguidance? We show three examples, where we demonstrate the viability of such\narchitecture.",
      "tldr_zh": "这篇论文针对粒子加速器日益复杂的控制挑战，提出了一种基于 Large Language Models (LLMs) 的去中心化多智能体框架，作为传统方法的范式转变。该框架由自主智能体组成，每个智能体负责特定加速器组件的高层任务、通信，并通过经验和人类反馈实现自改进。作者探讨了 AI 在粒子加速器中的未来应用、系统实现的可行性，以及整合人类在循环的含义，并通过三个例子证明了该架构的有效性。",
      "categories": [
        "physics.acc-ph",
        "cs.AI"
      ],
      "primary_category": "physics.acc-ph",
      "comment": "5 pages, 3 figures, Machine Learning and the Physical Sciences at\n  Workshop at the 38th conference on Neural Information Processing Systems\n  (NeurIPS)",
      "pdf_url": "http://arxiv.org/pdf/2409.06336v3",
      "published_date": "2024-09-10 08:47:23 UTC",
      "updated_date": "2024-12-22 09:30:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:52:54.052981"
    },
    {
      "arxiv_id": "2409.06323v1",
      "title": "LAMP: Learnable Meta-Path Guided Adversarial Contrastive Learning for Heterogeneous Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Siqing Li",
        "Jin-Duk Park",
        "Wei Huang",
        "Xin Cao",
        "Won-Yong Shin",
        "Zhiqiang Xu"
      ],
      "abstract": "Heterogeneous graph neural networks (HGNNs) have significantly propelled the\ninformation retrieval (IR) field. Still, the effectiveness of HGNNs heavily\nrelies on high-quality labels, which are often expensive to acquire. This\nchallenge has shifted attention towards Heterogeneous Graph Contrastive\nLearning (HGCL), which usually requires pre-defined meta-paths. However, our\nfindings reveal that meta-path combinations significantly affect performance in\nunsupervised settings, an aspect often overlooked in current literature.\nExisting HGCL methods have considerable variability in outcomes across\ndifferent meta-path combinations, thereby challenging the optimization process\nto achieve consistent and high performance. In response, we introduce\n\\textsf{LAMP} (\\underline{\\textbf{L}}earn\\underline{\\textbf{A}}ble\n\\underline{\\textbf{M}}eta-\\underline{\\textbf{P}}ath), a novel adversarial\ncontrastive learning approach that integrates various meta-path sub-graphs into\na unified and stable structure, leveraging the overlap among these sub-graphs.\nTo address the denseness of this integrated sub-graph, we propose an\nadversarial training strategy for edge pruning, maintaining sparsity to enhance\nmodel performance and robustness. \\textsf{LAMP} aims to maximize the difference\nbetween meta-path and network schema views for guiding contrastive learning to\ncapture the most meaningful information. Our extensive experimental study\nconducted on four diverse datasets from the Heterogeneous Graph Benchmark (HGB)\ndemonstrates that \\textsf{LAMP} significantly outperforms existing\nstate-of-the-art unsupervised models in terms of accuracy and robustness.",
      "tldr_zh": "该论文提出LAMP（Learnable Meta-Path），一种可学习meta-path引导的对抗对比学习方法，用于处理Heterogeneous Graphs中的无监督学习问题。LAMP通过整合各种meta-path子图，利用子图重叠形成统一的结构，并采用对抗训练策略进行边pruning，以缓解整合后的图稠密性问题，从而提升模型的性能和鲁棒性。该方法旨在最大化meta-path视图与网络schema视图之间的差异，引导对比学习捕获最有意义的信息。在四个Heterogeneous Graph Benchmark (HGB)数据集上的实验表明，LAMP在准确性和鲁棒性方面显著优于现有无监督模型。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "19 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.06323v1",
      "published_date": "2024-09-10 08:27:39 UTC",
      "updated_date": "2024-09-10 08:27:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:53:17.599827"
    },
    {
      "arxiv_id": "2409.06316v2",
      "title": "PharmacoMatch: Efficient 3D Pharmacophore Screening via Neural Subgraph Matching",
      "title_zh": "PharmacoMatch",
      "authors": [
        "Daniel Rose",
        "Oliver Wieder",
        "Thomas Seidel",
        "Thierry Langer"
      ],
      "abstract": "The increasing size of screening libraries poses a significant challenge for\nthe development of virtual screening methods for drug discovery, necessitating\na re-evaluation of traditional approaches in the era of big data. Although 3D\npharmacophore screening remains a prevalent technique, its application to very\nlarge datasets is limited by the computational cost associated with matching\nquery pharmacophores to database molecules. In this study, we introduce\nPharmacoMatch, a novel contrastive learning approach based on neural subgraph\nmatching. Our method reinterprets pharmacophore screening as an approximate\nsubgraph matching problem and enables efficient querying of conformational\ndatabases by encoding query-target relationships in the embedding space. We\nconduct comprehensive investigations of the learned representations and\nevaluate PharmacoMatch as pre-screening tool in a zero-shot setting. We\ndemonstrate significantly shorter runtimes and comparable performance metrics\nto existing solutions, providing a promising speed-up for screening very large\ndatasets.",
      "tldr_zh": "本研究针对药物发现中虚拟筛选的计算挑战，提出PharmacoMatch，一种基于neural subgraph matching的对比学习方法，以高效处理3D Pharmacophore Screening。PharmacoMatch将构效团筛选重新定义为近似子图匹配问题，通过在嵌入空间编码查询-目标关系，实现对大型构象数据库的快速查询。实验结果显示，该方法在零样本预筛选场景下显著缩短运行时间，同时保持与现有解决方案相当的性能指标，为处理大数据集的药物筛选提供重要加速。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.QM"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.06316v2",
      "published_date": "2024-09-10 08:17:06 UTC",
      "updated_date": "2025-03-14 09:51:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:53:18.549950"
    },
    {
      "arxiv_id": "2409.06307v1",
      "title": "An End-to-End Approach for Chord-Conditioned Song Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Shuochen Gao",
        "Shun Lei",
        "Fan Zhuo",
        "Hangyu Liu",
        "Feng Liu",
        "Boshi Tang",
        "Qiaochu Huang",
        "Shiyin Kang",
        "Zhiyong Wu"
      ],
      "abstract": "The Song Generation task aims to synthesize music composed of vocals and\naccompaniment from given lyrics. While the existing method, Jukebox, has\nexplored this task, its constrained control over the generations often leads to\ndeficiency in music performance. To mitigate the issue, we introduce an\nimportant concept from music composition, namely chords, to song generation\nnetworks. Chords form the foundation of accompaniment and provide vocal melody\nwith associated harmony. Given the inaccuracy of automatic chord extractors, we\ndevise a robust cross-attention mechanism augmented with dynamic weight\nsequence to integrate extracted chord information into song generations and\nreduce frame-level flaws, and propose a novel model termed Chord-Conditioned\nSong Generator (CSG) based on it. Experimental evidence demonstrates our\nproposed method outperforms other approaches in terms of musical performance\nand control precision of generated songs.",
      "tldr_zh": "该研究提出了一种端到端方法，用于基于和弦（chords）的歌曲生成任务，旨在从给定歌词合成包含人声和伴奏的音乐，以解决现有方法如 Jukebox 在生成控制方面的不足。论文引入和弦作为伴奏基础和人声和声的条件，并设计了一个增强动态权重序列（dynamic weight sequence）的鲁棒跨注意力机制（cross-attention mechanism），以整合提取的和弦信息并减少帧级错误。基于此，作者开发了新的 Chord-Conditioned Song Generator (CSG) 模型，实验结果显示，该方法在音乐表现和生成的歌曲控制精度上优于其他方法。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.06307v1",
      "published_date": "2024-09-10 08:07:43 UTC",
      "updated_date": "2024-09-10 08:07:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:53:30.122864"
    },
    {
      "arxiv_id": "2409.06299v1",
      "title": "Enhancing Long Video Understanding via Hierarchical Event-Based Memory",
      "title_zh": "翻译失败",
      "authors": [
        "Dingxin Cheng",
        "Mingda Li",
        "Jingyu Liu",
        "Yongxin Guo",
        "Bin Jiang",
        "Qingbin Liu",
        "Xi Chen",
        "Bo Zhao"
      ],
      "abstract": "Recently, integrating visual foundation models into large language models\n(LLMs) to form video understanding systems has attracted widespread attention.\nMost of the existing models compress diverse semantic information within the\nwhole video and feed it into LLMs for content comprehension. While this method\nexcels in short video understanding, it may result in a blend of multiple event\ninformation in long videos due to coarse compression, which causes information\nredundancy. Consequently, the semantics of key events might be obscured within\nthe vast information that hinders the model's understanding capabilities. To\naddress this issue, we propose a Hierarchical Event-based Memory-enhanced LLM\n(HEM-LLM) for better understanding of long videos. Firstly, we design a novel\nadaptive sequence segmentation scheme to divide multiple events within long\nvideos. In this way, we can perform individual memory modeling for each event\nto establish intra-event contextual connections, thereby reducing information\nredundancy. Secondly, while modeling current event, we compress and inject the\ninformation of the previous event to enhance the long-term inter-event\ndependencies in videos. Finally, we perform extensive experiments on various\nvideo understanding tasks and the results show that our model achieves\nstate-of-the-art performances.",
      "tldr_zh": "该研究针对长视频理解中的信息冗余问题，提出了一种基于分层事件记忆的增强LLM模型（HEM-LLM），以改善视觉基础模型与LLMs的整合。HEM-LLM 包括自适应序列分割方案将视频分成多个事件，并为每个事件进行独立内存建模以建立内部上下文连接，同时注入前一事件的信息来增强事件间长期依赖，从而减少冗余并突出关键语义。实验结果表明，该模型在各种视频理解任务上实现了最先进性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.06299v1",
      "published_date": "2024-09-10 07:53:10 UTC",
      "updated_date": "2024-09-10 07:53:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:53:43.022797"
    },
    {
      "arxiv_id": "2409.06280v2",
      "title": "Catch Me if You Can: Detecting Unauthorized Data Use in Deep Learning Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zitao Chen",
        "Karthik Pattabiraman"
      ],
      "abstract": "The rise of deep learning (DL) has led to a surging demand for training data,\nwhich incentivizes the creators of DL models to trawl through the Internet for\ntraining materials. Meanwhile, users often have limited control over whether\ntheir data (e.g., facial images) are used to train DL models without their\nconsent, which has engendered pressing concerns.\n  This work proposes MembershipTracker, a practical data auditing tool that can\nempower ordinary users to reliably detect the unauthorized use of their data in\ntraining DL models. We view data auditing through the lens of membership\ninference (MI). MembershipTracker consists of a lightweight data marking\ncomponent to mark the target data with small and targeted changes, which can be\nstrongly memorized by the model trained on them; and a specialized MI-based\nverification process to audit whether the model exhibits strong memorization on\nthe target samples.\n  MembershipTracker only requires the users to mark a small fraction of data\n(0.005% to 0.1% in proportion to the training set), and it enables the users to\nreliably detect the unauthorized use of their data (average 0% FPR@100% TPR).\nWe show that MembershipTracker is highly effective across various settings,\nincluding industry-scale training on the full-size ImageNet-1k dataset. We\nfinally evaluate MembershipTracker under multiple classes of countermeasures.",
      "tldr_zh": "本研究针对深度学习（DL）模型可能未经用户同意使用其数据（如面部图像）的问题，提出了一种实用的数据审计工具 MembershipTracker。 该工具通过一个轻量级的数据标记组件，在目标数据上添加小而针对性的变化，使这些数据被模型强烈记忆；随后利用基于 Membership Inference (MI) 的验证过程，检查模型是否对这些样本表现出强烈记忆，从而检测未授权数据使用。 用户只需标记训练集的极小比例（0.005% 到 0.1%），即可实现可靠检测（平均 0% FPR@100% TPR），并在各种场景中表现出色，包括全尺寸 ImageNet-1k 数据集的工业规模训练。 此外，该工具经评估，在多种反措施下仍保持有效性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.06280v2",
      "published_date": "2024-09-10 07:31:56 UTC",
      "updated_date": "2024-12-23 02:44:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:54:04.897953"
    },
    {
      "arxiv_id": "2409.06277v2",
      "title": "Ferret: Federated Full-Parameter Tuning at Scale for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yao Shu",
        "Wenyang Hu",
        "See-Kiong Ng",
        "Bryan Kian Hsiang Low",
        "Fei Richard Yu"
      ],
      "abstract": "Large Language Models (LLMs) have become indispensable in numerous real-world\napplications. Unfortunately, fine-tuning these models at scale, especially in\nfederated settings where data privacy and communication efficiency are\ncritical, presents significant challenges. Existing methods often resort to\nparameter-efficient fine-tuning (PEFT) to mitigate communication overhead, but\nthis typically comes at the cost of model accuracy. To address these\nlimitations, we propose federated full-parameter tuning at scale for LLMs\n(Ferret), the first first-order method with shared randomness to enable\nscalable full-parameter tuning of LLMs across decentralized data sources while\nmaintaining competitive model accuracy. Ferret accomplishes this through three\naspects: (1) it employs widely applied first-order methods for efficient local\nupdates; (2) it projects these updates into a low-dimensional space to\nconsiderably reduce communication overhead; and (3) it reconstructs local\nupdates from this low-dimensional space with shared randomness to facilitate\neffective full-parameter global aggregation, ensuring fast convergence and\ncompetitive final performance. Our rigorous theoretical analyses and insights\nalong with extensive experiments, show that Ferret significantly enhances the\nscalability of existing federated full-parameter tuning approaches by achieving\nhigh computational efficiency, reduced communication overhead, and fast\nconvergence, all while maintaining competitive model accuracy. Our\nimplementation is available at https://github.com/allen4747/Ferret.",
      "tldr_zh": "该论文提出Ferret，一种用于大语言模型(LLMs)的联邦全参数微调方法，旨在解决传统参数高效微调(PEFT)方法在数据隐私和通信效率方面的挑战，同时保持高模型准确性。Ferret采用一阶方法进行高效本地更新，将更新投影到低维空间以减少通信开销，并通过共享随机性重建更新，实现有效的全局聚合和快速收敛。实验和理论分析表明，Ferret显著提升了计算效率、降低了通信开销，并确保了竞争性的性能表现。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.06277v2",
      "published_date": "2024-09-10 07:28:13 UTC",
      "updated_date": "2024-09-11 01:47:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:54:07.077927"
    },
    {
      "arxiv_id": "2409.06270v1",
      "title": "Towards Robust Uncertainty-Aware Incomplete Multi-View Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Mulin Chen",
        "Haojian Huang",
        "Qiang Li"
      ],
      "abstract": "Handling incomplete data in multi-view classification is challenging,\nespecially when traditional imputation methods introduce biases that compromise\nuncertainty estimation. Existing Evidential Deep Learning (EDL) based\napproaches attempt to address these issues, but they often struggle with\nconflicting evidence due to the limitations of the Dempster-Shafer combination\nrule, leading to unreliable decisions. To address these challenges, we propose\nthe Alternating Progressive Learning Network (APLN), specifically designed to\nenhance EDL-based methods in incomplete MVC scenarios. Our approach mitigates\nbias from corrupted observed data by first applying coarse imputation, followed\nby mapping the data to a latent space. In this latent space, we progressively\nlearn an evidence distribution aligned with the target domain, incorporating\nuncertainty considerations through EDL. Additionally, we introduce a\nconflict-aware Dempster-Shafer combination rule (DSCR) to better handle\nconflicting evidence. By sampling from the learned distribution, we optimize\nthe latent representations of missing views, reducing bias and enhancing\ndecision-making robustness. Extensive experiments demonstrate that APLN,\ncombined with DSCR, significantly outperforms traditional methods, particularly\nin environments characterized by high uncertainty and conflicting evidence,\nestablishing it as a promising solution for incomplete multi-view\nclassification.",
      "tldr_zh": "本文针对多视图分类(multi-view classification)中不完整数据的偏差和不确定性估计问题，提出Alternating Progressive Learning Network (APLN)，以增强Evidential Deep Learning (EDL)方法的性能。APLN通过粗略填充数据、映射到潜在空间并逐步学习与目标域对齐的证据分布，同时引入conflict-aware Dempster-Shafer combination rule (DSCR)来有效处理冲突证据，从而优化缺失视图的潜在表示并减少偏差。实验结果显示，APLN结合DSCR在高不确定性和冲突证据环境中显著优于传统方法，提高了分类决策的鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Ongoing work: 9 pages, 6 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2409.06270v1",
      "published_date": "2024-09-10 07:18:57 UTC",
      "updated_date": "2024-09-10 07:18:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:54:19.478986"
    },
    {
      "arxiv_id": "2409.06263v1",
      "title": "Keyword-Aware ASR Error Augmentation for Robust Dialogue State Tracking",
      "title_zh": "翻译失败",
      "authors": [
        "Jihyun Lee",
        "Solee Im",
        "Wonjun Lee",
        "Gary Geunbae Lee"
      ],
      "abstract": "Dialogue State Tracking (DST) is a key part of task-oriented dialogue\nsystems, identifying important information in conversations. However, its\naccuracy drops significantly in spoken dialogue environments due to named\nentity errors from Automatic Speech Recognition (ASR) systems. We introduce a\nsimple yet effective data augmentation method that targets those entities to\nimprove the robustness of DST model. Our novel method can control the placement\nof errors using keyword-highlighted prompts while introducing phonetically\nsimilar errors. As a result, our method generated sufficient error patterns on\nkeywords, leading to improved accuracy in noised and low-accuracy ASR\nenvironments.",
      "tldr_zh": "论文针对 Automatic Speech Recognition (ASR) 系统中的命名实体错误导致 Dialogue State Tracking (DST) 准确性下降的问题，提出了一种简单有效的 Keyword-Aware ASR Error Augmentation 数据增强方法，以提升 DST 模型的鲁棒性。该方法利用关键字突出提示控制错误位置，同时引入语音上相似的错误，生成丰富的错误模式。实验结果表明，这种方法在噪声和低准确率 ASR 环境中显著提高了 DST 的准确性，为任务导向对话系统在口语环境中的应用提供了更可靠的支持。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.06263v1",
      "published_date": "2024-09-10 07:06:40 UTC",
      "updated_date": "2024-09-10 07:06:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:54:31.021816"
    },
    {
      "arxiv_id": "2409.06745v1",
      "title": "Personalized Knowledge Tracing through Student Representation Reconstruction and Class Imbalance Mitigation",
      "title_zh": "翻译失败",
      "authors": [
        "Zhiyu Chen",
        "Wei Ji",
        "Jing Xiao",
        "Zitao Liu"
      ],
      "abstract": "Knowledge tracing is a technique that predicts students' future performance\nby analyzing their learning process through historical interactions with\nintelligent educational platforms, enabling a precise evaluation of their\nknowledge mastery. Recent studies have achieved significant progress by\nleveraging powerful deep neural networks. These models construct complex input\nrepresentations using questions, skills, and other auxiliary information but\noverlook individual student characteristics, which limits the capability for\npersonalized assessment. Additionally, the available datasets in the field\nexhibit class imbalance issues. The models that simply predict all responses as\ncorrect without substantial effort can yield impressive accuracy. In this\npaper, we propose PKT, a novel approach for personalized knowledge tracing. PKT\nreconstructs representations from sequences of interactions with a tutoring\nplatform to capture latent information about the students. Moreover, PKT\nincorporates focal loss to improve prioritize minority classes, thereby\nachieving more balanced predictions. Extensive experimental results on four\npublicly available educational datasets demonstrate the advanced predictive\nperformance of PKT in comparison with 16 state-of-the-art models. To ensure the\nreproducibility of our research, the code is publicly available at\nhttps://anonymous.4open.science/r/PKT.",
      "tldr_zh": "该研究针对知识追踪（knowledge tracing）中的问题，提出了一种名为 PKT 的新方法，通过重建学生互动序列的表示（student representation reconstruction）来捕捉个体学生的潜在特征，从而实现个性化评估。同时，PKT 采用 focal loss 来缓解数据集中的类别不平衡（class imbalance）问题，提高预测的平衡性。在四个公开教育数据集上的实验表明，PKT 比 16 个最先进模型表现出更好的预测性能，并提供了可复现的公开代码。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.06745v1",
      "published_date": "2024-09-10 07:02:46 UTC",
      "updated_date": "2024-09-10 07:02:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:54:42.706688"
    },
    {
      "arxiv_id": "2409.06744v2",
      "title": "ProteinBench: A Holistic Evaluation of Protein Foundation Models",
      "title_zh": "ProteinBench：蛋白质基础模型的整体评估",
      "authors": [
        "Fei Ye",
        "Zaixiang Zheng",
        "Dongyu Xue",
        "Yuning Shen",
        "Lihao Wang",
        "Yiming Ma",
        "Yan Wang",
        "Xinyou Wang",
        "Xiangxin Zhou",
        "Quanquan Gu"
      ],
      "abstract": "Recent years have witnessed a surge in the development of protein foundation\nmodels, significantly improving performance in protein prediction and\ngenerative tasks ranging from 3D structure prediction and protein design to\nconformational dynamics. However, the capabilities and limitations associated\nwith these models remain poorly understood due to the absence of a unified\nevaluation framework. To fill this gap, we introduce ProteinBench, a holistic\nevaluation framework designed to enhance the transparency of protein foundation\nmodels. Our approach consists of three key components: (i) A taxonomic\nclassification of tasks that broadly encompass the main challenges in the\nprotein domain, based on the relationships between different protein\nmodalities; (ii) A multi-metric evaluation approach that assesses performance\nacross four key dimensions: quality, novelty, diversity, and robustness; and\n(iii) In-depth analyses from various user objectives, providing a holistic view\nof model performance. Our comprehensive evaluation of protein foundation models\nreveals several key findings that shed light on their current capabilities and\nlimitations. To promote transparency and facilitate further research, we\nrelease the evaluation dataset, code, and a public leaderboard publicly for\nfurther analysis and a general modular toolkit. We intend for ProteinBench to\nbe a living benchmark for establishing a standardized, in-depth evaluation\nframework for protein foundation models, driving their development and\napplication while fostering collaboration within the field.",
      "tldr_zh": "该论文引入了ProteinBench，一种全面评估蛋白质基础模型的统一框架，以解决这些模型能力与局限性的认知空白。框架包括基于蛋白质模态关系的任务分类、多指标评估（涵盖质量、新颖性、多样性和鲁棒性）以及从用户目标角度的深入分析。通过对蛋白质基础模型的全面评估，论文揭示了其关键优势和不足，并公开了评估数据集、代码及排行榜，以推动该领域的标准化研究和协作。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.LG",
        "q-bio.BM"
      ],
      "primary_category": "q-bio.QM",
      "comment": "30 pages, 2 figures and 15 tables",
      "pdf_url": "http://arxiv.org/pdf/2409.06744v2",
      "published_date": "2024-09-10 06:52:33 UTC",
      "updated_date": "2024-10-07 08:20:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:54:54.392673"
    },
    {
      "arxiv_id": "2409.06241v1",
      "title": "DiPT: Enhancing LLM reasoning through diversified perspective-taking",
      "title_zh": "翻译失败",
      "authors": [
        "Hoang Anh Just",
        "Mahavir Dabas",
        "Lifu Huang",
        "Ming Jin",
        "Ruoxi Jia"
      ],
      "abstract": "Existing work on improving language model reasoning typically explores a\nsingle solution path, which can be prone to errors. Inspired by\nperspective-taking in social studies, this paper introduces DiPT, a novel\napproach that complements current reasoning methods by explicitly incorporating\ndiversified viewpoints. This approach allows the model to gain a deeper\nunderstanding of the problem's context and identify the most effective solution\npath during the inference stage. Additionally, it provides a general\ndata-centric AI recipe for augmenting existing data to improve their quality\nfor fine-tuning.\n  Our empirical results demonstrate that DiPT can be flexibly integrated into\nexisting methods that focus on a single reasoning approach, enhancing their\nreasoning performance and stability when presented with paraphrased problems.\nFurthermore, we illustrate improved context understanding by maintaining the\nmodel's safe outputs against \"jailbreaking\" prompts intentionally designed to\nbypass safeguards built into deployed models. Lastly, we show that fine-tuning\nwith data enriched with diverse perspectives can boost the reasoning\ncapabilities of the model compared to fine-tuning with raw data alone.",
      "tldr_zh": "该论文提出 DiPT 方法，通过受社会学视角转换（perspective-taking）启发，显式整合多样化观点来增强大型语言模型（LLM）的推理能力，从而帮助模型更深入理解问题上下文并在推理阶段选择最有效的解决方案路径。DiPT 还提供了一个通用的数据中心 AI 策略，用于增强现有数据以提高微调质量。实验结果表明，DiPT 可以灵活整合到单一推理方法中，提升性能和稳定性，尤其在处理改述问题时，并改善模型对“越狱”提示的抵抗力。最后，通过使用多样化视角增强的数据进行微调，模型的推理能力比仅用原始数据更显著提升。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "LLM Reasoning with Perspectives, Preprint",
      "pdf_url": "http://arxiv.org/pdf/2409.06241v1",
      "published_date": "2024-09-10 06:17:27 UTC",
      "updated_date": "2024-09-10 06:17:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:55:07.398971"
    },
    {
      "arxiv_id": "2409.13733v1",
      "title": "RNR: Teaching Large Language Models to Follow Roles and Rules",
      "title_zh": "翻译失败",
      "authors": [
        "Kuan Wang",
        "Alexander Bukharin",
        "Haoming Jiang",
        "Qingyu Yin",
        "Zhengyang Wang",
        "Tuo Zhao",
        "Jingbo Shang",
        "Chao Zhang",
        "Bing Yin",
        "Xian Li",
        "Jianshu Chen",
        "Shiyang Li"
      ],
      "abstract": "Instruction fine-tuning (IFT) elicits instruction following capabilities and\nsteers the behavior of large language models (LLMs) via supervised learning.\nHowever, existing models trained on open-source IFT datasets only have the\nability to follow instructions from users, and often fail to follow complex\nrole and rules specified by developers, a.k.a. system prompts. The ability to\nfollow these roles and rules is essential for deployment, as it ensures that\nthe model safely interacts with users within developer defined guidelines. To\nimprove such role and rule following ability, we propose \\model, an automated\ndata generation pipeline that generates diverse roles and rules from existing\nIFT instructions, along with corresponding responses. This data can then be\nused to train models that follow complex system prompts. The models are\nevaluated on our newly created benchmarks for role and rule following ability,\nas well as standard instruction-following benchmarks and general NLP tasks. Our\nframework significantly improves role and rule following capability in LLMs, as\nevidenced by over 25% increase in pass-rate on rule adherence, i.e. following\nall requirements, in our experiments with the Alpaca and Ultrachat datasets.\nMoreover, our models achieves this increase without any regression on popular\ninstruction following benchmarks.",
      "tldr_zh": "这篇论文提出了 RNR 框架，用于提升大型语言模型 (LLMs) 遵循复杂角色和规则的能力，以解决现有指令微调 (IFT) 模型仅能处理用户指令而忽略开发者定义的 system prompts 的问题。RNR 通过一个自动数据生成管道，从开源 IFT 指令中创建多样化的角色、规则和响应数据，并使用这些数据训练模型。实验结果显示，训练后的模型在角色和规则遵循基准上取得了超过 25% 的规则遵守通过率提升，同时在标准指令遵循基准和一般 NLP 任务上保持了原有性能，无任何退化。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.13733v1",
      "published_date": "2024-09-10 06:07:32 UTC",
      "updated_date": "2024-09-10 06:07:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:55:19.125893"
    },
    {
      "arxiv_id": "2409.06220v2",
      "title": "CerviXpert: A Multi-Structural Convolutional Neural Network for Predicting Cervix Type and Cervical Cell Abnormalities",
      "title_zh": "翻译失败",
      "authors": [
        "Rashik Shahriar Akash",
        "Radiful Islam",
        "S. M. Saiful Islam Badhon",
        "K. S. M. Tozammel Hossain"
      ],
      "abstract": "Cervical cancer is a major cause of cancer-related mortality among women\nworldwide, and its survival rate improves significantly with early detection.\nTraditional diagnostic methods such as Pap smears and cervical biopsies rely\nheavily on cytologist expertise, making the process prone to human error. This\nstudy introduces CerviXpert, a multi-structural convolutional neural network\nmodel designed to efficiently classify cervix types and detect cervical cell\nabnormalities. CerviXpert is built as a computationally efficient model that\nclassifies cervical cancer using images from the publicly available SiPaKMeD\ndataset. The model architecture emphasizes simplicity, using a limited number\nof convolutional layers followed by max pooling and dense layers, trained from\nscratch.\n  We assessed the performance of CerviXpert against other state of the art\nconvolutional neural network models including ResNet50, VGG16, MobileNetV2, and\nInceptionV3, evaluating them on accuracy, computational efficiency, and\nrobustness using five fold cross validation. CerviXpert achieved an accuracy of\n98.04 percent in classifying cervical cell abnormalities into three classes and\n98.60 percent for five class cervix type classification, outperforming\nMobileNetV2 and InceptionV3 in both accuracy and computational requirements. It\nshowed comparable results to ResNet50 and VGG16 while reducing computational\ncomplexity and resource needs.\n  CerviXpert provides an effective solution for cervical cancer screening and\ndiagnosis, balancing accuracy with computational efficiency. Its streamlined\ndesign enables deployment in resource constrained environments, potentially\nenhancing early detection and management of cervical cancer.",
      "tldr_zh": "该研究针对宫颈癌早期检测的挑战，提出 CerviXpert，一种多结构 Convolutional Neural Network 模型，用于分类宫颈类型和检测细胞异常，以减少传统方法的错误依赖。模型采用简单架构，包括有限的卷积层、max pooling 和 dense layers，从零开始在 SiPaKMeD 数据集上训练。实验结果显示，CerviXpert 在三类细胞异常分类中达到 98.04% 准确率，在五类宫颈类型分类中达到 98.60%，优于 MobileNetV2 和 InceptionV3，并在准确率上与 ResNet50 和 VGG16 相当，同时显著降低计算复杂度和资源需求。该模型为资源受限环境提供高效的宫颈癌筛查解决方案，促进早期诊断和管理。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "11 figures, 9 tables",
      "pdf_url": "http://arxiv.org/pdf/2409.06220v2",
      "published_date": "2024-09-10 05:08:26 UTC",
      "updated_date": "2024-11-18 05:00:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:55:32.631587"
    },
    {
      "arxiv_id": "2409.06214v4",
      "title": "Towards Generalizable Scene Change Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Jaewoo Kim",
        "Uehwan Kim"
      ],
      "abstract": "While current state-of-the-art Scene Change Detection (SCD) approaches\nachieve impressive results in well-trained research data, they become\nunreliable under unseen environments and different temporal conditions;\nin-domain performance drops from 77.6% to 8.0% in a previously unseen\nenvironment and to 4.6% under a different temporal condition -- calling for\ngeneralizable SCD and benchmark. In this work, we propose the Generalizable\nScene Change Detection Framework (GeSCF), which addresses unseen domain\nperformance and temporal consistency -- to meet the growing demand for anything\nSCD. Our method leverages the pre-trained Segment Anything Model (SAM) in a\nzero-shot manner. For this, we design Initial Pseudo-mask Generation and\nGeometric-Semantic Mask Matching -- seamlessly turning user-guided prompt and\nsingle-image based segmentation into scene change detection for a pair of\ninputs without guidance. Furthermore, we define the Generalizable Scene Change\nDetection (GeSCD) benchmark along with novel metrics and an evaluation protocol\nto facilitate SCD research in generalizability. In the process, we introduce\nthe ChangeVPR dataset, a collection of challenging image pairs with diverse\nenvironmental scenarios -- including urban, suburban, and rural settings.\nExtensive experiments across various datasets demonstrate that GeSCF achieves\nan average performance gain of 19.2% on existing SCD datasets and 30.0% on the\nChangeVPR dataset, nearly doubling the prior art performance. We believe our\nwork can lay a solid foundation for robust and generalizable SCD research.",
      "tldr_zh": "本研究针对当前场景变化检测(SCD)方法在未见环境或不同时间条件下性能急剧下降的问题（如从77.6%降至8.0%或4.6%），提出Generalizable Scene Change Detection Framework (GeSCF)，利用预训练的Segment Anything Model (SAM)以零-shot方式，通过Initial Pseudo-mask Generation和Geometric-Semantic Mask Matching模块，将用户引导提示和单图像分割转化为对图像对的无指导变化检测。论文定义了Generalizable Scene Change Detection (GeSCD)基准，包括新指标和评估协议，并引入ChangeVPR数据集，涵盖城市、郊区和农村等多样场景。实验结果显示，GeSCF在现有SCD数据集上平均提升19.2%，在ChangeVPR上提升30.0%，几乎翻倍了现有性能，为鲁棒的通用化SCD研究奠定基础。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Camera-ready version. Accepted to CVPR 2025",
      "pdf_url": "http://arxiv.org/pdf/2409.06214v4",
      "published_date": "2024-09-10 04:45:25 UTC",
      "updated_date": "2025-03-13 13:55:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:55:44.083469"
    },
    {
      "arxiv_id": "2409.06209v1",
      "title": "Adaptive Transformer Modelling of Density Function for Nonparametric Survival Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Xin Zhang",
        "Deval Mehta",
        "Yanan Hu",
        "Chao Zhu",
        "David Darby",
        "Zhen Yu",
        "Daniel Merlo",
        "Melissa Gresle",
        "Anneke Van Der Walt",
        "Helmut Butzkueven",
        "Zongyuan Ge"
      ],
      "abstract": "Survival analysis holds a crucial role across diverse disciplines, such as\neconomics, engineering and healthcare. It empowers researchers to analyze both\ntime-invariant and time-varying data, encompassing phenomena like customer\nchurn, material degradation and various medical outcomes. Given the complexity\nand heterogeneity of such data, recent endeavors have demonstrated successful\nintegration of deep learning methodologies to address limitations in\nconventional statistical approaches. However, current methods typically involve\ncluttered probability distribution function (PDF), have lower sensitivity in\ncensoring prediction, only model static datasets, or only rely on recurrent\nneural networks for dynamic modelling. In this paper, we propose a novel\nsurvival regression method capable of producing high-quality unimodal PDFs\nwithout any prior distribution assumption, by optimizing novel\nMargin-Mean-Variance loss and leveraging the flexibility of Transformer to\nhandle both temporal and non-temporal data, coined UniSurv. Extensive\nexperiments on several datasets demonstrate that UniSurv places a significantly\nhigher emphasis on censoring compared to other methods.",
      "tldr_zh": "本研究针对生存分析(Survival Analysis)领域的挑战，提出了一种新型非参数回归方法UniSurv，以解决现有方法在概率分布函数(PDF)建模、审查预测(censoring)敏感性和动态数据处理上的局限性。UniSurv通过优化Margin-Mean-Variance loss并利用Transformer的灵活性，实现了高质量单峰PDF(unimodal PDFs)的生成，而无需任何先验分布假设，能够处理时间和非时间数据。在多个数据集上的广泛实验表明，UniSurv在审查预测方面显著优于其他方法，为跨学科应用如医疗和经济学提供了更可靠的分析工具。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.06209v1",
      "published_date": "2024-09-10 04:29:59 UTC",
      "updated_date": "2024-09-10 04:29:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:55:54.304742"
    },
    {
      "arxiv_id": "2409.06192v1",
      "title": "NOVI : Chatbot System for University Novice with BERT and LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Yoonji Nam",
        "TaeWoong Seo",
        "Gyeongcheol Shin",
        "Sangji Lee",
        "JaeEun Im"
      ],
      "abstract": "To mitigate the difficulties of university freshmen in adapting to university\nlife, we developed NOVI, a chatbot system based on GPT-4o. This system utilizes\npost and comment data from SKKU 'Everytime', a university community site.\nDeveloped using LangChain, NOVI's performance has been evaluated with a BLEU\nscore, Perplexity score, ROUGE-1 score, ROUGE-2 score, ROUGE-L score and METEOR\nscore. This approach is not only limited to help university freshmen but is\nalso expected to help various people adapting to new environments with\ndifferent data. This research explores the development and potential\napplication of new educational technology tools, contributing to easier social\nadaptation for beginners and settling a foundation for future advancement in\nLLM studies.",
      "tldr_zh": "本文开发了 NOVI 聊天机器人系统，利用 BERT 和 LLMs（如 GPT-4o）结合 LangChain 框架，基于 SKKU 'Everytime' 社区的帖子和评论数据，帮助大学新生适应大学生活。系统通过 BLEU、Perplexity、ROUGE-1、ROUGE-2、ROUGE-L 和 METEOR 等指标评估性能，展示了良好的响应质量。NOVI 的应用不仅限于大学新生，还可扩展到其他适应新环境的情景，并为 LLM 研究奠定基础。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.06192v1",
      "published_date": "2024-09-10 03:43:26 UTC",
      "updated_date": "2024-09-10 03:43:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:56:07.543737"
    },
    {
      "arxiv_id": "2409.06185v1",
      "title": "Can Large Language Models Unlock Novel Scientific Research Ideas?",
      "title_zh": "大型语言模型能否解锁新颖的科学研究想法？",
      "authors": [
        "Sandeep Kumar",
        "Tirthankar Ghosal",
        "Vinayak Goyal",
        "Asif Ekbal"
      ],
      "abstract": "\"An idea is nothing more nor less than a new combination of old elements\"\n(Young, J.W.). The widespread adoption of Large Language Models (LLMs) and\npublicly available ChatGPT have marked a significant turning point in the\nintegration of Artificial Intelligence (AI) into people's everyday lives. This\nstudy explores the capability of LLMs in generating novel research ideas based\non information from research papers. We conduct a thorough examination of 4\nLLMs in five domains (e.g., Chemistry, Computer, Economics, Medical, and\nPhysics). We found that the future research ideas generated by Claude-2 and\nGPT-4 are more aligned with the author's perspective than GPT-3.5 and Gemini.\nWe also found that Claude-2 generates more diverse future research ideas than\nGPT-4, GPT-3.5, and Gemini 1.0. We further performed a human evaluation of the\nnovelty, relevancy, and feasibility of the generated future research ideas.\nThis investigation offers insights into the evolving role of LLMs in idea\ngeneration, highlighting both its capability and limitations. Our work\ncontributes to the ongoing efforts in evaluating and utilizing language models\nfor generating future research ideas. We make our datasets and codes publicly\navailable.",
      "tldr_zh": "这篇论文探讨了大型语言模型(LLMs)是否能基于研究论文生成新颖的科学研究想法，评估了Claude-2、GPT-4、GPT-3.5和Gemini在化学、计算机、经济、医学和物理五个领域的表现。结果显示，Claude-2和GPT-4生成的想法更符合作者视角，且Claude-2产生的研究想法更具多样性；人类评估进一步确认了这些想法在新颖性、相关性和可行性方面的表现。总体而言，该研究揭示了LLMs在想法生成中的潜力与局限性，并公开了数据集和代码以推动后续工作。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "24 pages, 12 figures, 6 tables",
      "pdf_url": "http://arxiv.org/pdf/2409.06185v1",
      "published_date": "2024-09-10 03:26:42 UTC",
      "updated_date": "2024-09-10 03:26:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:56:19.558858"
    },
    {
      "arxiv_id": "2409.06173v3",
      "title": "Larger Language Models Don't Care How You Think: Why Chain-of-Thought Prompting Fails in Subjective Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Georgios Chochlakis",
        "Niyantha Maruthu Pandiyan",
        "Kristina Lerman",
        "Shrikanth Narayanan"
      ],
      "abstract": "In-Context Learning (ICL) in Large Language Models (LLM) has emerged as the\ndominant technique for performing natural language tasks, as it does not\nrequire updating the model parameters with gradient-based methods. ICL promises\nto \"adapt\" the LLM to perform the present task at a competitive or\nstate-of-the-art level at a fraction of the computational cost. ICL can be\naugmented by incorporating the reasoning process to arrive at the final label\nexplicitly in the prompt, a technique called Chain-of-Thought (CoT) prompting.\nHowever, recent work has found that ICL relies mostly on the retrieval of task\npriors and less so on \"learning\" to perform tasks, especially for complex\nsubjective domains like emotion and morality, where priors ossify posterior\npredictions. In this work, we examine whether \"enabling\" reasoning also creates\nthe same behavior in LLMs, wherein the format of CoT retrieves reasoning priors\nthat remain relatively unchanged despite the evidence in the prompt. We find\nthat, surprisingly, CoT indeed suffers from the same posterior collapse as ICL\nfor larger language models. Code is avalaible at\nhttps://github.com/gchochla/cot-priors.",
      "tldr_zh": "本文研究了Chain-of-Thought (CoT)提示在主观任务（如情感和道德领域）中的失效问题，指出Large Language Models (LLM)中的In-Context Learning (ICL)主要依赖任务先验，而非真正学习。作者通过实验考察CoT是否也会出现类似后验坍缩（posterior collapse），结果显示CoT在较大LLM中同样无法改变推理先验，导致预测结果僵化。总体而言，该工作揭示了CoT提示的局限性，并提供了代码以供进一步验证。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "5 pages, 2 figures, 1 table. arXiv admin note: text overlap with\n  arXiv:2403.17125",
      "pdf_url": "http://arxiv.org/pdf/2409.06173v3",
      "published_date": "2024-09-10 03:06:17 UTC",
      "updated_date": "2024-10-17 17:02:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:56:31.196151"
    },
    {
      "arxiv_id": "2409.06741v2",
      "title": "Generative AI for Requirements Engineering: A Systematic Literature Review",
      "title_zh": "生成式 AI 用于需求工程：系统文献综述",
      "authors": [
        "Haowei Cheng",
        "Jati H. Husen",
        "Yijun Lu",
        "Teeradaj Racharak",
        "Nobukazu Yoshioka",
        "Naoyasu Ubayashi",
        "Hironori Washizaki"
      ],
      "abstract": "Context: Requirements engineering (RE) faces mounting challenges in handling\nincreasingly complex software systems. The emergence of generative AI (GenAI)\noffers new opportunities and challenges in RE. Objective: This systematic\nliterature review aims to analyze and synthesize current research on GenAI\napplications in RE, focusing on identifying research trends, methodologies,\nchallenges, and future directions. Method: We conducted a comprehensive review\nof 105 articles published between 2019 and 2024 obtained from major academic\ndatabases, using a systematic methodology for paper selection, data extraction,\nand feature analysis. Results: Analysis revealed the following. (1) While GPT\nseries models dominate current applications by 67.3% of studies, the existing\narchitectures face technical challenges-interpretability (61.9%),\nreproducibility (52.4%), and controllability (47.6%), which demonstrate strong\ncorrelations (>35% co-occurrence). (2) Reproducibility is identified as a major\nconcern by 52.4% of studies, which highlights challenges in achieving\nconsistent results due to the stochastic nature and parameter sensitivity of\nGenAI. (3) Governance-related issues (e.g., ethics and security) form a\ndistinct cluster of challenges that requires coordinated solutions, yet they\nare addressed by less than 20% of studies. Conclusions: While GenAI exhibits\npotential in RE, our findings reveal critical issues: (1) the high correlations\namong interpretability, reproducibility, and controllability imply the\nrequirement for more specialized architectures that target interdependencies of\nthese attributes. (2) The widespread concern about result consistency and\nreproducibility demands standardized evaluation frameworks. (3) The emergence\nof challenges related to interconnected governance demands comprehensive\ngovernance structures.",
      "tldr_zh": "本研究通过系统文献回顾，分析了2019-2024年间105篇关于Generative AI (GenAI)在Requirements Engineering (RE)中的应用，聚焦研究趋势、方法、挑战和未来方向。结果显示，GPT系列模型在67.3%的研究中占主导，但面临显著挑战，包括可解释性(61.9%)、可重复性(52.4%)和可控性(47.6%)，这些问题存在强相关性，且可重复性因GenAI的随机性和参数敏感性而备受关注。治理相关问题如伦理和安全虽形成独立挑战群，但仅在不到20%的研究中被讨论，结论强调需要开发针对这些属性的专用架构、标准化评估框架，以及全面治理结构。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.06741v2",
      "published_date": "2024-09-10 02:44:39 UTC",
      "updated_date": "2025-01-23 11:12:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:56:44.611497"
    },
    {
      "arxiv_id": "2409.06163v1",
      "title": "MCDGLN: Masked Connection-based Dynamic Graph Learning Network for Autism Spectrum Disorder",
      "title_zh": "翻译失败",
      "authors": [
        "Peng Wang",
        "Xin Wen",
        "Ruochen Cao",
        "Chengxin Gao",
        "Yanrong Hao",
        "Rui Cao"
      ],
      "abstract": "Autism Spectrum Disorder (ASD) is a neurodevelopmental disorder characterized\nby complex physiological processes. Previous research has predominantly focused\non static cerebral interactions, often neglecting the brain's dynamic nature\nand the challenges posed by network noise. To address these gaps, we introduce\nthe Masked Connection-based Dynamic Graph Learning Network (MCDGLN). Our\napproach first segments BOLD signals using sliding temporal windows to capture\ndynamic brain characteristics. We then employ a specialized weighted edge\naggregation (WEA) module, which uses the cross convolution with channel-wise\nelement-wise convolutional kernel, to integrate dynamic functional connectivity\nand to isolating task-relevant connections. This is followed by topological\nfeature extraction via a hierarchical graph convolutional network (HGCN), with\nkey attributes highlighted by a self-attention module. Crucially, we refine\nstatic functional connections using a customized task-specific mask, reducing\nnoise and pruning irrelevant links. The attention-based connection encoder\n(ACE) then enhances critical connections and compresses static features. The\ncombined features are subsequently used for classification. Applied to the\nAutism Brain Imaging Data Exchange I (ABIDE I) dataset, our framework achieves\na 73.3\\% classification accuracy between ASD and Typical Control (TC) groups\namong 1,035 subjects. The pivotal roles of WEA and ACE in refining connectivity\nand enhancing classification accuracy underscore their importance in capturing\nASD-specific features, offering new insights into the disorder.",
      "tldr_zh": "本研究针对Autism Spectrum Disorder (ASD)的复杂神经发育特征，提出Masked Connection-based Dynamic Graph Learning Network (MCDGLN)，以克服传统静态脑交互分析忽略大脑动态性和网络噪声的局限。MCDGLN首先通过滑动时间窗口分割BOLD signals捕获动态脑特征，然后利用weighted edge aggregation (WEA)模块整合动态功能连接，并结合hierarchical graph convolutional network (HGCN)和自注意力模块提取拓扑特征，同时通过任务特定掩码和attention-based connection encoder (ACE)精炼连接、减少噪声。实验在ABIDE I数据集上对1035个受试者进行ASD与Typical Control (TC)组分类，准确率达73.3%，突显WEA和ACE在提升ASD特征捕获和分类性能的关键作用，为ASD诊断提供新见解。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.06163v1",
      "published_date": "2024-09-10 02:21:29 UTC",
      "updated_date": "2024-09-10 02:21:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:56:55.680741"
    },
    {
      "arxiv_id": "2409.13731v3",
      "title": "KAG: Boosting LLMs in Professional Domains via Knowledge Augmented Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Lei Liang",
        "Mengshu Sun",
        "Zhengke Gui",
        "Zhongshu Zhu",
        "Zhouyu Jiang",
        "Ling Zhong",
        "Yuan Qu",
        "Peilong Zhao",
        "Zhongpu Bo",
        "Jin Yang",
        "Huaidong Xiong",
        "Lin Yuan",
        "Jun Xu",
        "Zaoyang Wang",
        "Zhiqiang Zhang",
        "Wen Zhang",
        "Huajun Chen",
        "Wenguang Chen",
        "Jun Zhou"
      ],
      "abstract": "The recently developed retrieval-augmented generation (RAG) technology has\nenabled the efficient construction of domain-specific applications. However, it\nalso has limitations, including the gap between vector similarity and the\nrelevance of knowledge reasoning, as well as insensitivity to knowledge logic,\nsuch as numerical values, temporal relations, expert rules, and others, which\nhinder the effectiveness of professional knowledge services. In this work, we\nintroduce a professional domain knowledge service framework called Knowledge\nAugmented Generation (KAG). KAG is designed to address the aforementioned\nchallenges with the motivation of making full use of the advantages of\nknowledge graph(KG) and vector retrieval, and to improve generation and\nreasoning performance by bidirectionally enhancing large language models (LLMs)\nand KGs through five key aspects: (1) LLM-friendly knowledge representation,\n(2) mutual-indexing between knowledge graphs and original chunks, (3)\nlogical-form-guided hybrid reasoning engine, (4) knowledge alignment with\nsemantic reasoning, and (5) model capability enhancement for KAG. We compared\nKAG with existing RAG methods in multihop question answering and found that it\nsignificantly outperforms state-of-theart methods, achieving a relative\nimprovement of 19.6% on 2wiki and 33.5% on hotpotQA in terms of F1 score. We\nhave successfully applied KAG to two professional knowledge Q&A tasks of Ant\nGroup, including E-Government Q&A and E-Health Q&A, achieving significant\nimprovement in professionalism compared to RAG methods.",
      "tldr_zh": "本研究提出 KAG 框架，通过知识增强生成（Knowledge Augmented Generation）来提升大型语言模型（LLMs）在专业领域的性能，解决 RAG（Retrieval-Augmented Generation）存在的向量相似度与知识推理差距，以及对知识逻辑（如数字、时间关系和专家规则）的敏感性不足问题。\nKAG 通过五个关键方面双向增强 LLMs 和知识图谱（KGs），包括 LLM-friendly knowledge representation、知识图谱与原始块的相互索引、逻辑形式引导的混合推理引擎、知识与语义推理的对齐，以及针对 KAG 的模型能力增强。\n实验结果显示，KAG 在多跳问答任务上显著优于现有 RAG 方法，F1 score 分别在 2wiki 和 HotpotQA 上提升 19.6% 和 33.5%；实际应用在 Ant Group 的 E-Government Q&A 和 E-Health Q&A 中，专业性得到显著改善。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "33 pages",
      "pdf_url": "http://arxiv.org/pdf/2409.13731v3",
      "published_date": "2024-09-10 02:00:28 UTC",
      "updated_date": "2024-09-26 16:34:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:57:09.649628"
    },
    {
      "arxiv_id": "2409.06147v1",
      "title": "Multiclass Arrhythmia Classification using Smartwatch Photoplethysmography Signals Collected in Real-life Settings",
      "title_zh": "翻译失败",
      "authors": [
        "Dong Han",
        "Jihye Moon",
        "Luís Roberto Mercado Díaz",
        "Darren Chen",
        "Devan Williams",
        "Eric Y. Ding",
        "Khanh-Van Tran",
        "David D. McManus",
        "Ki H. Chon"
      ],
      "abstract": "Most deep learning models of multiclass arrhythmia classification are tested\non fingertip photoplethysmographic (PPG) data, which has higher signal-to-noise\nratios compared to smartwatch-derived PPG, and the best reported sensitivity\nvalue for premature atrial/ventricular contraction (PAC/PVC) detection is only\n75%. To improve upon PAC/PVC detection sensitivity while maintaining high AF\ndetection, we use multi-modal data which incorporates 1D PPG, accelerometers,\nand heart rate data as the inputs to a computationally efficient 1D\nbi-directional Gated Recurrent Unit (1D-Bi-GRU) model to detect three\narrhythmia classes. We used motion-artifact prone smartwatch PPG data from the\nNIH-funded Pulsewatch clinical trial. Our multimodal model tested on 72\nsubjects achieved an unprecedented 83% sensitivity for PAC/PVC detection while\nmaintaining a high accuracy of 97.31% for AF detection. These results\noutperformed the best state-of-the-art model by 20.81% for PAC/PVC and 2.55%\nfor AF detection even while our model was computationally more efficient (14\ntimes lighter and 2.7 faster).",
      "tldr_zh": "这篇论文提出了一种使用多模态数据（包括 1D PPG、加速度计和心率数据）输入到 1D-Bi-GRU 模型的方法，用于在真实生活环境中基于智能手表 PPG 信号进行多类心律失常分类，旨在提升 PAC/PVC 检测的敏感性，同时保持高 AF 检测准确率。模型基于 NIH 资助的 Pulsewatch 临床试验数据，在 72 名受试者上测试，实现了 83% 的 PAC/PVC 检测敏感性和 97.31% 的 AF 检测准确率。相比现有最佳模型，该方法提高了 20.81% 的 PAC/PVC 检测和 2.55% 的 AF 检测，同时计算效率更高（模型轻 14 倍、快 2.7 倍）。",
      "categories": [
        "eess.SP",
        "cs.AI"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.06147v1",
      "published_date": "2024-09-10 01:44:56 UTC",
      "updated_date": "2024-09-10 01:44:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:57:22.393825"
    },
    {
      "arxiv_id": "2409.13730v2",
      "title": "VisScience: An Extensive Benchmark for Evaluating K12 Educational Multi-modal Scientific Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Zhihuan Jiang",
        "Zhen Yang",
        "Jinhao Chen",
        "Zhengxiao Du",
        "Weihan Wang",
        "Bin Xu",
        "Jie Tang"
      ],
      "abstract": "Multi-modal large language models (MLLMs) have demonstrated promising\ncapabilities across various tasks by integrating textual and visual information\nto achieve visual understanding in complex scenarios. Despite the availability\nof several benchmarks aims to evaluating MLLMs in tasks from visual question\nanswering to complex problem-solving, most focus predominantly on mathematics\nor general visual understanding tasks. This reveals a critical gap in current\nbenchmarks, which often overlook the inclusion of other key scientific\ndisciplines such as physics and chemistry. To address this gap, we meticulously\nconstruct a comprehensive benchmark, named VisScience, which is utilized to\nassess the multi-modal scientific reasoning across the three disciplines of\nmathematics, physics, and chemistry. This benchmark comprises 3,000 questions\ndrawn from K12 education - spanning elementary school through high school -\nequally distributed across three disciplines, with 1,000 questions per\ndiscipline. The questions within VisScience span 21 distinct subjects and are\ncategorized into five difficulty levels, offering a broad spectrum of topics\nwithin each discipline. With VisScience, we present a detailed evaluation of\nthe performance of 25 representative MLLMs in scientific reasoning.\nExperimental results demonstrate that closed-source MLLMs generally outperform\nopen-source models. The best performance observed include a 53.4\\% accuracy in\nmathematics by Claude3.5-Sonnet, 38.2\\% in physics by GPT-4o, and 47.0\\% in\nchemistry by Gemini-1.5-Pro. These results underscore the strengths and\nlimitations of MLLMs, suggesting areas for future improvement and highlighting\nthe importance of developing models that can effectively handle the diverse\ndemands of multi-modal scientific reasoning.",
      "tldr_zh": "本研究构建了VisScience基准，用于评估多模态大语言模型(MLLMs)在K12教育中多模态科学推理的表现，该基准填补了现有基准忽略物理和化学等学科的空白。VisScience包含3000个问题，平均分布于数学、物理和化学各1000个，覆盖21个主题和五个难度级别。研究评估了25个代表性MLLMs的性能，结果显示闭源模型整体优于开源模型，其中Claude3.5-Sonnet在数学的准确率达53.4%，GPT-4o在物理为38.2%，Gemini-1.5-Pro在化学为47.0%。这些发现突出了MLLMs的优势和局限性，强调了未来模型在处理多样化科学推理方面的改进需求。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "89 pages, 70 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.13730v2",
      "published_date": "2024-09-10 01:20:26 UTC",
      "updated_date": "2024-12-02 15:11:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:57:31.909110"
    },
    {
      "arxiv_id": "2409.13729v2",
      "title": "MathGLM-Vision: Solving Mathematical Problems with Multi-Modal Large Language Model",
      "title_zh": "MathGLM-Vision：使用多模态大语言模型解决数学问题",
      "authors": [
        "Zhen Yang",
        "Jinhao Chen",
        "Zhengxiao Du",
        "Wenmeng Yu",
        "Weihan Wang",
        "Wenyi Hong",
        "Zhihuan Jiang",
        "Bin Xu",
        "Jie Tang"
      ],
      "abstract": "Large language models (LLMs) have demonstrated significant capabilities in\nmathematical reasoning, particularly with text-based mathematical problems.\nHowever, current multi-modal large language models (MLLMs), especially those\nspecialized in mathematics, tend to focus predominantly on solving geometric\nproblems but ignore the diversity of visual information available in other\nareas of mathematics. Moreover, the geometric information for these specialized\nmathematical MLLMs is derived from several public datasets, which are typically\nlimited in diversity and complexity. To address these limitations, we aim to\nconstruct a fine-tuning dataset named MathVL, and develop a series of\nspecialized mathematical MLLMs termed MathGLM-Vision by conducting Supervised\nFine-Tuning (SFT) on MathVL with various parameter-scale backbones. To\nextensively evaluate the effectiveness of MathGLM-Vision, we conduct\nexperiments on several public benchmarks and our curated MathVL-test consisting\nof 2,000 problems. Experimental results demonstrate that MathGLM-Vision\nachieves significant improvements compared with some existing models, including\nbackbone models and open-source mathematical MLLMs. These findings indicate the\nimportance of diversity dataset in enhancing the mathematical reasoning\nabilities of MLLMs.",
      "tldr_zh": "这篇论文针对多模态大型语言模型（MLLMs）在数学问题解决中的局限性，构建了名为 MathVL 的微调数据集，以覆盖更多数学领域的视觉信息多样性。研究团队开发了 MathGLM-Vision 系列模型，通过 Supervised Fine-Tuning (SFT) 在不同规模的骨干模型上进行训练，提升了模型对非几何数学问题的处理能力。实验结果显示，MathGLM-Vision 在多个公共基准和自制的 2,000 问题测试集上，比现有模型和开源 MLLMs 取得了显著改进，突显了多样性数据集对增强 MLLMs 数学推理能力的关键作用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "30 pages,19 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.13729v2",
      "published_date": "2024-09-10 01:20:22 UTC",
      "updated_date": "2024-12-02 14:59:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:57:44.106270"
    },
    {
      "arxiv_id": "2409.06131v2",
      "title": "Accelerating Large Language Model Pretraining via LFR Pedagogy: Learn, Focus, and Review",
      "title_zh": "翻译失败",
      "authors": [
        "Neha Prakriya",
        "Jui-Nan Yen",
        "Cho-Jui Hsieh",
        "Jason Cong"
      ],
      "abstract": "Traditional Large Language Model (LLM) pretraining relies on autoregressive\nlanguage modeling with randomly sampled data from web-scale datasets. Inspired\nby human learning techniques like spaced repetition, we hypothesize that random\nsampling leads to high training costs, lower-quality models, and significant\ndata forgetting. To address these inefficiencies, we propose the\nLearn-Focus-Review (LFR) paradigm -- a dynamic training approach that adapts to\nthe model's learning progress. LFR tracks the model's learning performance\nacross data blocks (sequences of tokens) and prioritizes revisiting challenging\nregions of the dataset that are more prone to being forgotten, enabling better\nretention and more efficient learning. Using the LFR paradigm, we pretrained\nLlama and GPT models on the SlimPajama and OpenWebText datasets, respectively.\nThese models were evaluated on downstream tasks across various domains,\nincluding question answering, problem-solving, commonsense reasoning, language\nmodeling, and translation. Compared to baseline models trained on the full\ndatasets, LFR consistently achieved lower perplexity and higher accuracy, while\nusing only 5%--19% of the training tokens. Furthermore, LFR matched the\nperformance of industry-standard Pythia models with up to 2$\\times$ the\nparameter count, using just 3.2% of the training tokens, demonstrating its\neffectiveness and efficiency.",
      "tldr_zh": "本研究批评传统LLM预训练方法依赖随机采样数据，导致高成本、模型质量低下和数据遗忘问题，并提出LFR范式（Learn-Focus-Review），一种受人类学习启发的动态训练方法。LFR通过跟踪模型在数据块上的学习表现，优先复习容易遗忘的区域，从而提升数据保留和训练效率。在SlimPajama和OpenWebText数据集上预训练Llama和GPT模型后，实验显示LFR仅使用5%–19%的训练标记，就实现了比基线模型更低的perplexity和更高准确率，并在问答、问题解决等下游任务上表现突出。此外，LFR甚至能匹配参数量达2倍的Pythia模型，仅需3.2%的训练标记，证明其高效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.06131v2",
      "published_date": "2024-09-10 00:59:18 UTC",
      "updated_date": "2025-01-28 19:18:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:57:55.423714"
    },
    {
      "arxiv_id": "2409.06130v1",
      "title": "On the Weaknesses of Backdoor-based Model Watermarking: An Information-theoretic Perspective",
      "title_zh": "翻译失败",
      "authors": [
        "Aoting Hu",
        "Yanzhi Chen",
        "Renjie Xie",
        "Adrian Weller"
      ],
      "abstract": "Safeguarding the intellectual property of machine learning models has emerged\nas a pressing concern in AI security. Model watermarking is a powerful\ntechnique for protecting ownership of machine learning models, yet its\nreliability has been recently challenged by recent watermark removal attacks.\nIn this work, we investigate why existing watermark embedding techniques\nparticularly those based on backdooring are vulnerable. Through an\ninformation-theoretic analysis, we show that the resilience of watermarking\nagainst erasure attacks hinges on the choice of trigger-set samples, where\ncurrent uses of out-distribution trigger-set are inherently vulnerable to\nwhite-box adversaries. Based on this discovery, we propose a novel model\nwatermarking scheme, In-distribution Watermark Embedding (IWE), to overcome the\nlimitations of existing method. To further minimise the gap to clean models, we\nanalyze the role of logits as watermark information carriers and propose a new\napproach to better conceal watermark information within the logits. Experiments\non real-world datasets including CIFAR-100 and Caltech-101 demonstrate that our\nmethod robustly defends against various adversaries with negligible accuracy\nloss (< 0.1%).",
      "tldr_zh": "本研究从信息理论视角分析了基于后门（backdoor-based）的模型水印技术（model watermarking）的弱点，指出现有方法依赖外部分布触发集（trigger-set），使其易受白盒攻击和擦除攻击。作者提出了一种新方案In-distribution Watermark Embedding (IWE)，通过优化触发集选择和logits作为水印信息载体来提升鲁棒性，同时最小化对模型准确率的影响。实验在CIFAR-100和Caltech-101数据集上显示，该方法对各种攻击具有强大防御力，准确率损失小于0.1%。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.06130v1",
      "published_date": "2024-09-10 00:55:21 UTC",
      "updated_date": "2024-09-10 00:55:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:58:07.384244"
    },
    {
      "arxiv_id": "2409.06122v1",
      "title": "Case Study: Leveraging GenAI to Build AI-based Surrogates and Regressors for Modeling Radio Frequency Heating in Fusion Energy Science",
      "title_zh": "翻译失败",
      "authors": [
        "E. Wes Bethel",
        "Vianna Cramer",
        "Alexander del Rio",
        "Lothar Narins",
        "Chris Pestano",
        "Satvik Verma",
        "Erick Arias",
        "Nicola Bertelli",
        "Talita Perciano",
        "Syun'ichi Shiraiwa",
        "Álvaro Sánchez Villar",
        "Greg Wallace",
        "John C. Wright"
      ],
      "abstract": "This work presents a detailed case study on using Generative AI (GenAI) to\ndevelop AI surrogates for simulation models in fusion energy research. The\nscope includes the methodology, implementation, and results of using GenAI to\nassist in model development and optimization, comparing these results with\nprevious manually developed models.",
      "tldr_zh": "本研究通过一个案例研究，探讨了利用 Generative AI (GenAI) 构建 AI-based surrogates 和 regressors，用于模拟融合能源科学中的 Radio Frequency Heating。研究涵盖了方法论、实施过程以及模型开发和优化的具体步骤，并将 GenAI 辅助的结果与之前的手动开发模型进行比较。结果表明，这种 AI 驱动方法可能提升了模拟效率和准确性，为融合能源研究提供了新的优化途径。",
      "categories": [
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.06122v1",
      "published_date": "2024-09-10 00:22:19 UTC",
      "updated_date": "2024-09-10 00:22:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:58:20.944076"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 87,
  "processed_papers_count": 87,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-19T22:58:40.683543"
}