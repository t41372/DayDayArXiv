{
  "date": "2024-02-24",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-02-24 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 更新了 56 篇论文，主要聚焦于 AI 模型优化（如 LLM 的越狱防御和数学推理）、多模态处理（如医疗图像和视觉任务）、以及机器学习应用等领域。其中，令人印象深刻的文章包括使用 GPT-4 改进 LLM 数学推理的框架，以及多模态模型在医疗中的创新应用；有名学者如 Patrick Lewis 在第 4 篇论文中参与讨论，强调了 LLM 表示的分析。\n\n下面，我将挑选并讨论部分重要、话题度高或有突破性的论文，先聊 LLM 相关和医疗 AI 等关键主题，将相关论文归类讨论。对于其他较常规或学术性较弱的论文，我会快速掠过。\n\n### LLM 和 AI 模型优化主题\n- **Generalization or Memorization: Data Contamination and Trustworthy Evaluation for Large Language Models**（泛化还是记忆：LLM 数据污染与可信评估）  \n  作者包括 Zhi Jin 和 Bin Gu，这篇 ACL 接受论文提出 CDD 和 TED 方法，通过输出分布检测和修正 LLM 数据污染，提升模型评估的准确性和鲁棒性。发现 ChatGPT 在 HumanEval 基准上易受污染，强调了 LLM 可靠性的实际挑战。\n\n- **Certifying Knowledge Comprehension in LLMs**（认证 LLM 的知识理解能力）  \n  作者 Gagandeep Singh 等人开发了一个概率框架，使用知识图谱生成规范，提供 LLM 知识提取和推理的正式保证。在精确医学和问答任务上，揭示了 LLM 对噪声提示的脆弱性，并建立了模型性能层级。\n\n- **MultiContrievers: Analysis of Dense Retrieval Representations**（MultiContrievers：密集检索表示分析）  \n  作者包括著名学者 Patrick Lewis，这篇论文分析了 Contriever 模型的表示提取性，与 BERT 相比，Contriever 提高了信息提取，但与基准性能相关性低，并讨论了性别偏差和随机初始化敏感性。\n\n- **Abdelhak at SemEval-2024 Task 9: Decoding Brainteasers, The Efficacy of Dedicated Models Versus ChatGPT**（Abdelhak 在 SemEval-2024 任务 9：解谜题，专用模型 vs. ChatGPT 的效能）  \n  这篇论文的专用模型在句子谜题上排名第一，得分 0.98，远超 ChatGPT，突出了专用模型在侧向思考任务中的优势。\n\n- **Stepwise Self-Consistent Mathematical Reasoning with Large Language Models**（逐步自一致的 LLM 数学推理）  \n  作者使用 GPT-4 开发 SSC-CoT 算法，通过迭代策略优化数学推理，在 TriMaster100 和 MATH 数据集上提升了准确率，显著减少了错误步骤。\n\n- **Empowering Large Language Model Agents through Action Learning**（通过动作学习增强 LLM 代理）  \n  这篇论文提出 LearnAct 框架，让 LLM 代理从经验中学习新动作，在机器人规划任务上提升性能，实现了更智能的决策迭代。\n\n- **Look Before You Leap: Problem Elaboration Prompting Improves Mathematical Reasoning in Large Language Models**（先看再跳：问题阐述提示提升 LLM 数学推理）  \n  PEP 方法通过分解问题上下文提升 LLM 数学任务的准确性，在 GSM8k 上提高了 9.93% 的准确率，特别适用于模糊查询。\n\n- **LLMs Can Defend Themselves Against Jailbreaking in a Practical Manner: A Vision Paper**（LLM 可以实际防御越狱攻击：一个愿景论文）  \n  作者提出 SELFDEFEND 框架，利用影子堆栈检测有害提示，防御各种越狱攻击，在 GPT-3.5/4 上有效，强调了 LLM 自我保护的潜力。\n\n### 医疗和多模态 AI 应用主题\n- **Bridging the Gap between 2D and 3D Visual Question Answering: A Fusion Approach for 3D VQA**（桥接 2D 和 3D 视觉问答：3D VQA 的融合方法）  \n  这篇 AAAI 24 论文提出 BridgeQA 框架，通过问题条件 2D 视图选择和双分支 Transformer 融合 2D/3D 信息，在 3D VQA 数据集上达到最先进性能。\n\n- **Explainable Contrastive and Cost-Sensitive Learning for Cervical Cancer Classification**（可解释的对比和成本敏感学习用于宫颈癌分类）  \n  作者使用预训练 CNN 和对比学习，在 SIPaKMeD 数据集上达到 97.29% 准确率，并通过可解释 AI 技术展示决策过程。\n\n- **Multiple Instance Learning for Glioma Diagnosis using Hematoxylin and Eosin Whole Slide Images: An Indian Cohort Study**（使用多实例学习诊断胶质瘤：基于印度队列的苏木精-伊红全滑显微图像）  \n  这篇论文在 IPD-Brain 数据集上使用 ResNet-50 和 DTFD 聚合器，实现了 88.08% AUC，在胶质瘤亚型分类和生物标记检测上设定了新基准。\n\n- **Hal-Eval: A Universal and Fine-grained Hallucination Evaluation Framework for Large Vision Language Models**（Hal-Eval：一个通用的细粒度幻觉评估框架，用于大型视觉语言模型）  \n  作者扩展了幻觉分类，包括事件幻觉，并开发了评估框架，帮助 LVLMs 识别多模态幻觉，提高了模型可靠性。\n\n- **TV-SAM: Increasing Zero-Shot Segmentation Performance on Multimodal Medical Images Using GPT-4 Generated Descriptive Prompts Without Human Annotation**（TV-SAM：使用 GPT-4 生成描述提示提升多模态医疗图像零样本分割性能，无需人工标注）  \n  这篇论文整合 GPT-4 和 SAM，实现无标注的多模态医疗图像分割，在多个数据集上超越了基线，展示了基础模型的潜力。\n\n### 其他创新或快速掠过主题\n- **PhyPlan: Compositional and Adaptive Physical Task Reasoning with Physics-Informed Skill Networks for Robot Manipulators**（PhyPlan：使用物理信息技能网络的机器人机械臂组合自适应物理任务推理）  \n  作者提出 PhyPlan 框架，结合 PINNs 和 MCTS 优化机器人任务，在模拟环境中显著提升了规划效率和准确性。\n  \n- **GenCode: A Generic Data Augmentation Framework for Boosting Deep Learning-Based Code Understanding**（GenCode：一个通用的数据增强框架，提升基于深度学习的代码理解）  \n  这个框架通过生成和选择策略增强代码数据，在代码理解任务上比 SOTA 方法提高了 2.92% 准确率。\n\n其他论文如第5（使用 LSTM 预测游戏结果）、第8（ESFL 算法优化联邦学习）、第11（遗传算法用于任务卸载）、第20（高精度地图构建）等，涉及游戏、优化和应用领域，但相对常规，我仅快速提及：这些工作在资源约束和实用优化上提供了新方法，却未有重大突破，可作为参考但非重点。\n\n总之，今天的 arXiv 论文展示了 AI 领域的活跃创新，特别是 LLM 的可靠性和多模态应用，读者可关注 LLM 防御和医疗 AI 方向以寻找潜在兴趣点。更多细节请查阅 arXiv！",
  "papers": [
    {
      "arxiv_id": "2402.15938v3",
      "title": "Generalization or Memorization: Data Contamination and Trustworthy Evaluation for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yihong Dong",
        "Xue Jiang",
        "Huanyu Liu",
        "Zhi Jin",
        "Bin Gu",
        "Mengfei Yang",
        "Ge Li"
      ],
      "abstract": "Recent statements about the impressive capabilities of large language models\n(LLMs) are usually supported by evaluating on open-access benchmarks.\nConsidering the vast size and wide-ranging sources of LLMs' training data, it\ncould explicitly or implicitly include test data, leading to LLMs being more\nsusceptible to data contamination. However, due to the opacity of training\ndata, the black-box access of models, and the rapid growth of synthetic\ntraining data, detecting and mitigating data contamination for LLMs faces\nsignificant challenges. In this paper, we propose CDD, which stands for\nContamination Detection via output Distribution for LLMs. CDD necessitates only\nthe sampled texts to detect data contamination, by identifying the peakedness\nof LLM's output distribution. To mitigate the impact of data contamination in\nevaluation, we also present TED: Trustworthy Evaluation via output\nDistribution, based on the correction of LLM's output distribution. To\nfacilitate this study, we introduce two benchmarks, i.e., DetCon and ComiEval,\nfor data contamination detection and contamination mitigation evaluation tasks.\nExtensive experimental results show that CDD achieves the average relative\nimprovements of 21.8\\%-30.2\\% over other contamination detection approaches in\nterms of Accuracy, F1 Score, and AUC metrics, and can effectively detect\nimplicit contamination. TED substantially mitigates performance improvements up\nto 66.9\\% attributed to data contamination across various contamination setups.\nIn real-world applications, we reveal that ChatGPT exhibits a high potential to\nsuffer from data contamination on HumanEval benchmark.",
      "tldr_zh": "这篇论文探讨了大型语言模型 (LLMs) 在基准测试中可能的数据污染问题，导致模型表现可能是记忆而非泛化。作者提出了 CDD（Contamination Detection via output Distribution）方法，通过分析模型输出分布的峰度，仅需采样文本即可检测显式和隐式污染。针对缓解影响，他们引入了 TED（Trustworthy Evaluation via output Distribution）方法，用于修正输出分布以进行可信评估。同时，论文构建了两个基准：DetCon 用于污染检测评估，以及 ComiEval 用于缓解效果测试。实验结果显示，CDD 在准确率、F1 分数和 AUC 指标上比其他方法提高了 21.8%-30.2%，而 TED 能减少高达 66.9% 的性能提升，且 ChatGPT 在 HumanEval 基准上显示出高污染风险。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR",
        "cs.LG",
        "cs.SE"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to ACL",
      "pdf_url": "http://arxiv.org/pdf/2402.15938v3",
      "published_date": "2024-02-24 23:54:41 UTC",
      "updated_date": "2024-05-31 17:49:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:39:41.438859"
    },
    {
      "arxiv_id": "2402.15933v1",
      "title": "Bridging the Gap between 2D and 3D Visual Question Answering: A Fusion Approach for 3D VQA",
      "title_zh": "翻译失败",
      "authors": [
        "Wentao Mo",
        "Yang Liu"
      ],
      "abstract": "In 3D Visual Question Answering (3D VQA), the scarcity of fully annotated\ndata and limited visual content diversity hampers the generalization to novel\nscenes and 3D concepts (e.g., only around 800 scenes are utilized in ScanQA and\nSQA dataset). Current approaches resort supplement 3D reasoning with 2D\ninformation. However, these methods face challenges: either they use top-down\n2D views that introduce overly complex and sometimes question-irrelevant visual\nclues, or they rely on globally aggregated scene/image-level representations\nfrom 2D VLMs, losing the fine-grained vision-language correlations. To overcome\nthese limitations, our approach utilizes question-conditional 2D view selection\nprocedure, pinpointing semantically relevant 2D inputs for crucial visual\nclues. We then integrate this 2D knowledge into the 3D-VQA system via a\ntwo-branch Transformer structure. This structure, featuring a Twin-Transformer\ndesign, compactly combines 2D and 3D modalities and captures fine-grained\ncorrelations between modalities, allowing them mutually augmenting each other.\nIntegrating proposed mechanisms above, we present BridgeQA, that offers a fresh\nperspective on multi-modal transformer-based architectures for 3D-VQA.\nExperiments validate that BridgeQA achieves state-of-the-art on 3D-VQA datasets\nand significantly outperforms existing solutions. Code is available at\n$\\href{https://github.com/matthewdm0816/BridgeQA}{\\text{this URL}}$.",
      "tldr_zh": "该论文针对3D Visual Question Answering (3D VQA) 的数据稀缺和视觉多样性不足问题，提出一种融合2D和3D信息的方法，以提升模型的泛化能力。核心方法包括question-conditional 2D view selection，用于选择语义相关的2D输入，以及Twin-Transformer结构的双分支设计，来捕捉细粒度的2D和3D模态相关性，实现模态间互补。最终开发的BridgeQA模型在3D-VQA数据集上达到state-of-the-art性能，显著超越现有方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "To be published in AAAI 24",
      "pdf_url": "http://arxiv.org/pdf/2402.15933v1",
      "published_date": "2024-02-24 23:31:34 UTC",
      "updated_date": "2024-02-24 23:31:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:39:52.917981"
    },
    {
      "arxiv_id": "2402.15929v3",
      "title": "Certifying Knowledge Comprehension in LLMs",
      "title_zh": "大型语言模型中知识理解的认证",
      "authors": [
        "Isha Chaudhary",
        "Vedaant V. Jain",
        "Gagandeep Singh"
      ],
      "abstract": "Large Language Models (LLMs) are increasingly deployed in safety-critical\nsystems where they provide answers based on in-context information derived from\nknowledge bases. As LLMs are increasingly envisioned as superhuman agents,\ntheir proficiency in knowledge comprehension-extracting relevant information\nand reasoning over it to answer questions, a key facet of human\nintelligence-becomes crucial. However, existing evaluations of LLMs on\nknowledge comprehension are typically conducted on small test sets, but these\ndatasets represent only a tiny fraction of the vast number of possible queries.\nSimple empirical evaluations on these limited test sets raises concerns about\nthe reliability and generalizability of the results. In this work, we introduce\nthe first specification and certification framework for knowledge comprehension\nin LLMs, providing formal probabilistic guarantees for reliability. Instead of\na fixed dataset, we design novel specifications that mathematically represent\nprohibitively large probability distributions of knowledge comprehension\nprompts with natural noise, using knowledge graphs. From these specifications,\nwe generate quantitative certificates that offer high-confidence, tight bounds\non the probability that a given LLM correctly answers any question drawn from\nthe specification distribution. We apply our framework to certify SOTA LLMs in\ntwo domains: precision medicine and general question-answering. Our results\nreveal previously unrecognized vulnerabilities in SOTA LLMs due to natural\nnoise in the prompts. Additionally, we establish performance hierarchies with\nformal guarantees among the SOTA LLMs, particularly in the context of precision\nmedicine question-answering.",
      "tldr_zh": "本研究针对大型语言模型（LLMs）在安全关键系统中的知识理解能力，提出首个规范和认证框架，以提供正式的概率保证。该框架利用知识图谱设计大规模提示分布，模拟自然噪声并生成定量证书，从而给出高置信度边界，确保LLMs正确回答问题。实验在精确医学和一般问答领域应用后，揭示了SOTA LLMs在噪声提示下的脆弱性，并建立了正式的性能层次结构，突出不同模型的可靠性差异。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.15929v3",
      "published_date": "2024-02-24 23:16:57 UTC",
      "updated_date": "2025-04-21 23:10:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:40:03.686886"
    },
    {
      "arxiv_id": "2402.15925v2",
      "title": "MultiContrievers: Analysis of Dense Retrieval Representations",
      "title_zh": "翻译失败",
      "authors": [
        "Seraphina Goldfarb-Tarrant",
        "Pedro Rodriguez",
        "Jane Dwivedi-Yu",
        "Patrick Lewis"
      ],
      "abstract": "Dense retrievers compress source documents into (possibly lossy) vector\nrepresentations, yet there is little analysis of what information is lost\nversus preserved, and how it affects downstream tasks. We conduct the first\nanalysis of the information captured by dense retrievers compared to the\nlanguage models they are based on (e.g., BERT versus Contriever). We use 25\nMultiBert checkpoints as randomized initialisations to train MultiContrievers,\na set of 25 contriever models. We test whether specific pieces of information\n-- such as gender and occupation -- can be extracted from contriever vectors of\nwikipedia-like documents. We measure this extractability via information\ntheoretic probing. We then examine the relationship of extractability to\nperformance and gender bias, as well as the sensitivity of these results to\nmany random initialisations and data shuffles. We find that (1) contriever\nmodels have significantly increased extractability, but extractability usually\ncorrelates poorly with benchmark performance 2) gender bias is present, but is\nnot caused by the contriever representations 3) there is high sensitivity to\nboth random initialisation and to data shuffle, suggesting that future\nretrieval research should test across a wider spread of both.",
      "tldr_zh": "本文分析了密集检索器(Dense retrievers)对文档向量的信息保留和丢失情况，比较了基于语言模型（如BERT和Contriever）的性能差异。研究者通过训练25个MultiContriever模型，使用信息理论探测(information theoretic probing)评估特定信息的提取性（如性别和职业），并考察其与下游任务性能、性别偏差的关系。结果表明，Contriever模型显著提高了信息提取性，但提取性与基准性能相关性差，且模型对随机初始化和数据洗牌高度敏感，建议未来检索研究进行更广泛的测试。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.15925v2",
      "published_date": "2024-02-24 23:01:21 UTC",
      "updated_date": "2024-10-04 13:37:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:40:16.956698"
    },
    {
      "arxiv_id": "2402.15923v1",
      "title": "Predicting Outcomes in Video Games with Long Short Term Memory Networks",
      "title_zh": "使用长短时记忆网络预测视频游戏中的结果",
      "authors": [
        "Kittimate Chulajata",
        "Sean Wu",
        "Fabien Scalzo",
        "Eun Sang Cha"
      ],
      "abstract": "Forecasting winners in E-sports with real-time analytics has the potential to\nfurther engage audiences watching major tournament events. However, making such\nreal-time predictions is challenging due to unpredictable variables within the\ngame involving diverse player strategies and decision-making. Our work attempts\nto enhance audience engagement within video game tournaments by introducing a\nreal-time method of predicting wins. Our Long Short Term Memory Network (LSTMs)\nbased approach enables efficient predictions of win-lose outcomes by only using\nthe health indicator of each player as a time series. As a proof of concept, we\nevaluate our model's performance within a classic, two-player arcade game,\nSuper Street Fighter II Turbo. We also benchmark our method against state of\nthe art methods for time series forecasting; i.e. Transformer models found in\nlarge language models (LLMs). Finally, we open-source our data set and code in\nhopes of furthering work in predictive analysis for arcade games.",
      "tldr_zh": "本文提出了一种基于Long Short Term Memory Networks (LSTMs)的实时方法，用于预测电子竞技比赛中的胜负结果，从而提升观众参与度。该方法仅利用玩家的健康指标作为时间序列数据进行预测，并在经典游戏Super Street Fighter II Turbo上进行验证，与Transformer模型进行基准对比。实验结果显示，该方法在准确性上优于现有基准，并开源了数据集和代码，以推动视频游戏预测分析的进一步发展。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.LG",
      "comment": "7 pages, 2 Figures, 2 Tables. Kittimate Chulajata and Sean Wu are\n  considered co-first authors",
      "pdf_url": "http://arxiv.org/pdf/2402.15923v1",
      "published_date": "2024-02-24 22:36:23 UTC",
      "updated_date": "2024-02-24 22:36:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:40:27.375095"
    },
    {
      "arxiv_id": "2402.16905v2",
      "title": "Procedural Adherence and Interpretability Through Neuro-Symbolic Generative Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Raven Rothkopf",
        "Hannah Tongxin Zeng",
        "Mark Santolucito"
      ],
      "abstract": "The surge in popularity of large language models (LLMs) has opened doors for\nnew approaches to the creation of interactive agents. However, managing and\ninterpreting the temporal behavior of such agents over the course of a\npotentially infinite interaction remain challenging. The stateful, long-term\nhorizon reasoning required for coherent agent behavior does not fit well into\nthe LLM paradigm. We propose a combination of formal logic-based program\nsynthesis and LLM content generation to bring guarantees of procedural\nadherence and interpretability to generative agent behavior. To illustrate the\nbenefit of procedural adherence and interpretability, we use Temporal Stream\nLogic (TSL) to generate an automaton that enforces an interpretable, high-level\ntemporal structure on an agent. With the automaton tracking the context of the\ninteraction and making decisions to guide the conversation accordingly, we can\ndrive content generation in a way that allows the LLM to focus on a shorter\ncontext window. We evaluated our approach on different tasks involved in\ncreating an interactive agent specialized for generating\nchoose-your-own-adventure games. We found that over all of the tasks, an\nautomaton-enhanced agent with procedural guarantees achieves at least 96%\nadherence to its temporal constraints, whereas a purely LLM-based agent\ndemonstrates as low as 14.67% adherence.",
      "tldr_zh": "这篇论文提出了一种神经符号生成代理方法，将形式逻辑-based 程序合成与大型语言模型 (LLMs) 内容生成相结合，以确保代理行为的程序遵守性和可解释性。作者使用 Temporal Stream Logic (TSL) 生成自动机 (automaton)，该自动机跟踪交互上下文并强制代理遵守高级时间结构，从而让 LLMs 专注于更短的上下文窗口。在评估生成“选择你的冒险”游戏的任务时，实验结果显示，增强代理的遵守率至少达到96%，而纯 LLMs 代理的遵守率低至14.67%。这为创建可靠的交互代理提供了重要贡献。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "11 pages",
      "pdf_url": "http://arxiv.org/pdf/2402.16905v2",
      "published_date": "2024-02-24 21:36:26 UTC",
      "updated_date": "2024-08-28 02:37:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:40:40.620091"
    },
    {
      "arxiv_id": "2402.15905v1",
      "title": "Explainable Contrastive and Cost-Sensitive Learning for Cervical Cancer Classification",
      "title_zh": "可解释的对比学习和成本敏感学习用于子宫颈癌分类",
      "authors": [
        "Ashfiqun Mustari",
        "Rushmia Ahmed",
        "Afsara Tasnim",
        "Jakia Sultana Juthi",
        "G M Shahariar"
      ],
      "abstract": "This paper proposes an efficient system for classifying cervical cancer cells\nusing pre-trained convolutional neural networks (CNNs). We first fine-tune five\npre-trained CNNs and minimize the overall cost of misclassification by\nprioritizing accuracy for certain classes that have higher associated costs or\nimportance. To further enhance the performance of the models, supervised\ncontrastive learning is included to make the models more adept at capturing\nimportant features and patterns. Extensive experimentation are conducted to\nevaluate the proposed system on the SIPaKMeD dataset. The experimental results\ndemonstrate the effectiveness of the developed system, achieving an accuracy of\n97.29%. To make our system more trustworthy, we have employed several\nexplainable AI techniques to interpret how the models reached a specific\ndecision. The implementation of the system can be found at -\nhttps://github.com/isha-67/CervicalCancerStudy.",
      "tldr_zh": "本文提出了一种用于宫颈癌细胞分类的系统，基于预训练的 CNNs 进行微调，并通过成本敏感学习优先提升高成本或重要类别的准确性，以最小化误分类风险。系统还整合 supervised contrastive learning，帮助模型更好地捕捉关键特征和模式。在 SIPaKMeD 数据集上的实验显示，该系统达到了 97.29% 的准确率，并采用 explainable AI 技术提升模型的可解释性和可信度。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted and presented in 26th International Conference on Computer\n  and Information Technology (ICCIT 2023)",
      "pdf_url": "http://arxiv.org/pdf/2402.15905v1",
      "published_date": "2024-02-24 21:03:30 UTC",
      "updated_date": "2024-02-24 21:03:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:40:52.326191"
    },
    {
      "arxiv_id": "2402.15903v2",
      "title": "ESFL: Efficient Split Federated Learning over Resource-Constrained Heterogeneous Wireless Devices",
      "title_zh": "ESFL",
      "authors": [
        "Guangyu Zhu",
        "Yiqin Deng",
        "Xianhao Chen",
        "Haixia Zhang",
        "Yuguang Fang",
        "Tan F. Wong"
      ],
      "abstract": "Federated learning (FL) allows multiple parties (distributed devices) to\ntrain a machine learning model without sharing raw data. How to effectively and\nefficiently utilize the resources on devices and the central server is a highly\ninteresting yet challenging problem. In this paper, we propose an efficient\nsplit federated learning algorithm (ESFL) to take full advantage of the\npowerful computing capabilities at a central server under a split federated\nlearning framework with heterogeneous end devices (EDs). By splitting the model\ninto different submodels between the server and EDs, our approach jointly\noptimizes user-side workload and server-side computing resource allocation by\nconsidering users' heterogeneity. We formulate the whole optimization problem\nas a mixed-integer non-linear program, which is an NP-hard problem, and develop\nan iterative approach to obtain an approximate solution efficiently. Extensive\nsimulations have been conducted to validate the significantly increased\nefficiency of our ESFL approach compared with standard federated learning,\nsplit learning, and splitfed learning.",
      "tldr_zh": "该论文提出了一种高效的分割联邦学习算法（ESFL），旨在在资源受限的异构无线设备上优化联邦学习（Federated Learning）过程，通过将模型分割到服务器和设备之间充分利用计算资源。ESFL 算法考虑设备异质性，联合优化用户端工作负载和服务器端资源分配，并将问题表述为混合整数非线性规划（mixed-integer non-linear program），采用迭代方法高效求解。实验结果显示，ESFL 与标准 Federated Learning、Split Learning 和 SplitFed Learning 相比，显著提高了效率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.15903v2",
      "published_date": "2024-02-24 20:50:29 UTC",
      "updated_date": "2024-04-17 02:59:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:41:03.364377"
    },
    {
      "arxiv_id": "2403.00809v1",
      "title": "Abdelhak at SemEval-2024 Task 9 : Decoding Brainteasers, The Efficacy of Dedicated Models Versus ChatGPT",
      "title_zh": "翻译失败",
      "authors": [
        "Abdelhak Kelious",
        "Mounir Okirim"
      ],
      "abstract": "This study introduces a dedicated model aimed at solving the BRAINTEASER task\n9 , a novel challenge designed to assess models lateral thinking capabilities\nthrough sentence and word puzzles. Our model demonstrates remarkable efficacy,\nsecuring Rank 1 in sentence puzzle solving during the test phase with an\noverall score of 0.98. Additionally, we explore the comparative performance of\nChatGPT, specifically analyzing how variations in temperature settings affect\nits ability to engage in lateral thinking and problem-solving. Our findings\nindicate a notable performance disparity between the dedicated model and\nChatGPT, underscoring the potential of specialized approaches in enhancing\ncreative reasoning in AI.",
      "tldr_zh": "本研究开发了一个专有模型，用于解决 SemEval-2024 Task 9 中的 BRAINTEASER 挑战，该任务通过句子和单词谜题评估模型的横向思考能力。模型在测试阶段的句子谜题解决中获得第一名，总分达0.98，展示了其卓越效能。研究同时比较了 ChatGPT 的性能，分析了温度 settings 对其横向思考和问题解决的影响，发现 ChatGPT 与专有模型之间存在显著性能差距。总体而言，这强调了专有方法在提升 AI 创意推理方面的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.00809v1",
      "published_date": "2024-02-24 20:00:03 UTC",
      "updated_date": "2024-02-24 20:00:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:41:16.009519"
    },
    {
      "arxiv_id": "2402.15892v1",
      "title": "Statistical Games",
      "title_zh": "统计游戏",
      "authors": [
        "Jozsef Konczer"
      ],
      "abstract": "This work contains the mathematical exploration of a few prototypical games\nin which central concepts from statistics and probability theory naturally\nemerge. The first two kinds of games are termed Fisher and Bayesian games,\nwhich are connected to Frequentist and Bayesian statistics, respectively.\nLater, a more general type of game is introduced, termed Statistical game, in\nwhich a further parameter, the players' relative risk aversion, can be set. In\nthis work, we show that Fisher and Bayesian games can be viewed as limiting\ncases of Statistical games. Therefore, Statistical games can be viewed as a\nunified framework, incorporating both Frequentist and Bayesian statistics.\nFurthermore, a philosophical framework is (re-)presented -- often referred to\nas minimax regret criterion -- as a general approach to decision making.\n  The main motivation for this work was to embed Bayesian statistics into a\nbroader decision-making framework, where, based on collected data, actions with\nconsequences have to be made, which can be translated to utilities (or\nrewards/losses) of the decision-maker. The work starts with the simplest\npossible toy model, related to hypothesis testing and statistical inference.\nThis choice has two main benefits: i.) it allows us to determine (conjecture)\nthe behaviour of the equilibrium strategies in various limiting cases ii.) this\nway, we can introduce Statistical games without requiring additional stochastic\nparameters. The work contains game theoretical methods related to two-player,\nnon-cooperative games to determine and prove equilibrium strategies of Fisher,\nBayesian and Statistical games. It also relies on analytical tools for\nderivations concerning various limiting cases.",
      "tldr_zh": "这篇论文探讨了“Statistical games”，一种将统计和概率理论核心概念融入游戏模型的框架。具体来说，它引入了Fisher games和Bayesian games，分别对应于Frequentist和Bayesian统计学，并进一步提出Statistical games作为更一般形式，允许设置玩家的相对风险厌恶参数。论文证明，Fisher和Bayesian games可以视为Statistical games的极限特例，从而构建了一个统一Frequentist和Bayesian统计的决策框架。作者还重新呈现了minimax regret criterion作为一种哲学决策方法，并通过简单玩具模型（如假设检验）分析两玩家非合作游戏的平衡策略，展示了在各种极限情况下的行为预测。整体上，这为将Bayesian统计嵌入更广泛的基于数据决策体系提供了新视角。",
      "categories": [
        "math.ST",
        "cs.AI",
        "cs.GT",
        "cs.LG",
        "econ.TH",
        "stat.ML",
        "stat.TH",
        "62C05, 62C20, 91A35, 68T37, 68T05"
      ],
      "primary_category": "math.ST",
      "comment": "129 pages, 51 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.15892v1",
      "published_date": "2024-02-24 19:59:15 UTC",
      "updated_date": "2024-02-24 19:59:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:41:27.910591"
    },
    {
      "arxiv_id": "2402.16904v1",
      "title": "Selective Task offloading for Maximum Inference Accuracy and Energy efficient Real-Time IoT Sensing Systems",
      "title_zh": "选择性任务卸载以实现最大推理准确性和能量高效",
      "authors": [
        "Abdelkarim Ben Sada",
        "Amar Khelloufi",
        "Abdenacer Naouri",
        "Huansheng Ning",
        "Sahraoui Dhelim"
      ],
      "abstract": "The recent advancements in small-size inference models facilitated AI\ndeployment on the edge. However, the limited resource nature of edge devices\nposes new challenges especially for real-time applications. Deploying multiple\ninference models (or a single tunable model) varying in size and therefore\naccuracy and power consumption, in addition to an edge server inference model,\ncan offer a dynamic system in which the allocation of inference models to\ninference jobs is performed according to the current resource conditions.\nTherefore, in this work, we tackle the problem of selectively allocating\ninference models to jobs or offloading them to the edge server to maximize\ninference accuracy under time and energy constraints. This problem is shown to\nbe an instance of the unbounded multidimensional knapsack problem which is\nconsidered a strongly NP-hard problem. We propose a lightweight hybrid genetic\nalgorithm (LGSTO) to solve this problem. We introduce a termination condition\nand neighborhood exploration techniques for faster evolution of populations. We\ncompare LGSTO with the Naive and Dynamic programming solutions. In addition to\nclassic genetic algorithms using different reproduction methods including\nNSGA-II, and finally we compare to other evolutionary methods such as Particle\nswarm optimization (PSO) and Ant colony optimization (ACO). Experiment results\nshow that LGSTO performed 3 times faster than the fastest comparable schemes\nwhile producing schedules with higher average accuracy.",
      "tldr_zh": "这篇论文针对资源有限的边缘设备在实时 IoT 感知系统中，提出了一种选择性任务卸载策略，以最大化推理准确率并优化能源效率。作者将问题建模为 unbounded multidimensional knapsack problem（一个强 NP-hard 问题），并开发了轻量级混合遗传算法（LGSTO），包括终止条件和邻域探索技术来加速演化过程。与 Naive、动态规划、NSGA-II、PSO 和 ACO 等方法比较，实验结果显示 LGSTO 的速度比最快方案快 3 倍，同时产生更高平均准确率的调度方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.16904v1",
      "published_date": "2024-02-24 18:46:06 UTC",
      "updated_date": "2024-02-24 18:46:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:41:41.904701"
    },
    {
      "arxiv_id": "2402.15832v2",
      "title": "Multiple Instance Learning for Glioma Diagnosis using Hematoxylin and Eosin Whole Slide Images: An Indian Cohort Study",
      "title_zh": "翻译失败",
      "authors": [
        "Ekansh Chauhan",
        "Amit Sharma",
        "Megha S Uppin",
        "C. V. Jawahar",
        "P. K. Vinod"
      ],
      "abstract": "The effective management of brain tumors relies on precise typing, subtyping,\nand grading. This study advances patient care with findings from rigorous\nmultiple instance learning experimentations across various feature extractors\nand aggregators in brain tumor histopathology. It establishes new performance\nbenchmarks in glioma subtype classification across multiple datasets, including\na novel dataset focused on the Indian demographic (IPD- Brain), providing a\nvaluable resource for existing research. Using a ResNet-50, pretrained on\nhistopathology datasets for feature extraction, combined with the Double-Tier\nFeature Distillation (DTFD) feature aggregator, our approach achieves\nstate-of-the-art AUCs of 88.08 on IPD-Brain and 95.81 on the TCGA-Brain\ndataset, respectively, for three-way glioma subtype classification. Moreover,\nit establishes new benchmarks in grading and detecting IHC molecular biomarkers\n(IDH1R132H, TP53, ATRX, Ki-67) through H&E stained whole slide images for the\nIPD-Brain dataset. The work also highlights a significant correlation between\nthe model decision-making processes and the diagnostic reasoning of\npathologists, underscoring its capability to mimic professional diagnostic\nprocedures.",
      "tldr_zh": "这篇论文使用 Multiple Instance Learning 技术，对 Hematoxylin and Eosin 染色的全滑微镜图像进行脑肿瘤诊断，聚焦于胶质瘤的亚型分类、分级和分子生物标记物检测，基于一个新的印度人群数据集（IPD-Brain）和其他数据集。研究采用 ResNet-50 作为特征提取器，并结合 Double-Tier Feature Distillation (DTFD) 作为特征聚合器，在 IPD-Brain 上实现了 88.08% AUC，在 TCGA-Brain 上达到了 95.81% 的三分类性能基准。结果不仅建立了新的诊断基准，还突显了模型决策过程与病理学家诊断推理的高度相关性，为脑肿瘤管理尤其是印度人群提供了宝贵资源。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.15832v2",
      "published_date": "2024-02-24 14:59:19 UTC",
      "updated_date": "2024-03-08 11:31:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:41:55.354789"
    },
    {
      "arxiv_id": "2402.15826v1",
      "title": "Reward Design for Justifiable Sequential Decision-Making",
      "title_zh": "可辩护序列决策的奖励设计",
      "authors": [
        "Aleksa Sukovic",
        "Goran Radanovic"
      ],
      "abstract": "Equipping agents with the capacity to justify made decisions using supporting\nevidence represents a cornerstone of accountable decision-making. Furthermore,\nensuring that justifications are in line with human expectations and societal\nnorms is vital, especially in high-stakes situations such as healthcare. In\nthis work, we propose the use of a debate-based reward model for reinforcement\nlearning agents, where the outcome of a zero-sum debate game quantifies the\njustifiability of a decision in a particular state. This reward model is then\nused to train a justifiable policy, whose decisions can be more easily\ncorroborated with supporting evidence. In the debate game, two argumentative\nagents take turns providing supporting evidence for two competing decisions.\nGiven the proposed evidence, a proxy of a human judge evaluates which decision\nis better justified. We demonstrate the potential of our approach in learning\npolicies for prescribing and justifying treatment decisions of septic patients.\nWe show that augmenting the reward with the feedback signal generated by the\ndebate-based reward model yields policies highly favored by the judge when\ncompared to the policy obtained solely from the environment rewards, while\nhardly sacrificing any performance. Moreover, in terms of the overall\nperformance and justifiability of trained policies, the debate-based feedback\nis comparable to the feedback obtained from an ideal judge proxy that evaluates\ndecisions using the full information encoded in the state. This suggests that\nthe debate game outputs key information contained in states that is most\nrelevant for evaluating decisions, which in turn substantiates the practicality\nof combining our approach with human-in-the-loop evaluations. Lastly, we\nshowcase that agents trained via multi-agent debate learn to propose evidence\nthat is resilient to refutations and closely aligns with human preferences.",
      "tldr_zh": "本研究提出了一种基于辩论的奖励模型（reward model），用于强化学习（reinforcement learning）代理在顺序决策（sequential decision-making）中实现可证实的决策，确保决策符合人类期望和社会规范。方法涉及一个零和辩论游戏（zero-sum debate game），其中两个代理轮流为竞争决策提供支持证据，由一个代理充当人类法官评估哪个决策更合理。实验结果显示，在败血症患者治疗决策中，该模型增强的奖励反馈使训练出的策略比仅使用环境奖励的策略更受法官青睐，同时几乎不牺牲性能，且生成的证据与人类偏好高度一致，证明了其在高风险场景中的实用性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.15826v1",
      "published_date": "2024-02-24 14:29:30 UTC",
      "updated_date": "2024-02-24 14:29:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:42:05.525956"
    },
    {
      "arxiv_id": "2403.00808v1",
      "title": "IPED: An Implicit Perspective for Relational Triple Extraction based on Diffusion Model",
      "title_zh": "IPED：基于扩散模型的关系三元组抽取",
      "authors": [
        "Jianli Zhao",
        "Changhao Xu",
        "Bin Jiang"
      ],
      "abstract": "Relational triple extraction is a fundamental task in the field of\ninformation extraction, and a promising framework based on table filling has\nrecently gained attention as a potential baseline for entity relation\nextraction. However, inherent shortcomings such as redundant information and\nincomplete triple recognition remain problematic. To address these challenges,\nwe propose an Implicit Perspective for relational triple Extraction based on\nDiffusion model (IPED), an innovative approach for extracting relational\ntriples. Our classifier-free solution adopts an implicit strategy using block\ncoverage to complete the tables, avoiding the limitations of explicit tagging\nmethods. Additionally, we introduce a generative model structure, the\nblock-denoising diffusion model, to collaborate with our implicit perspective\nand effectively circumvent redundant information disruptions. Experimental\nresults on two popular datasets demonstrate that IPED achieves state-of-the-art\nperformance while gaining superior inference speed and low computational\ncomplexity. To support future research, we have made our source code publicly\navailable online.",
      "tldr_zh": "该研究针对关系三元组提取(Relational Triple Extraction)中的冗余信息和不完整识别问题，提出了一种基于扩散模型(Diffusion Model)的创新框架IPED。IPED采用隐式策略和块覆盖(block coverage)来完成表格填充，避免了显式标记方法的局限，同时引入块去噪扩散模型(block-denoising diffusion model)来有效处理冗余干扰。该方法在两个流行数据集上实现了最先进(State-of-the-art)性能，同时具备更快的推理速度和低计算复杂度，并公开了源码以支持后续研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "12 pages, 4 figures, committed to NAACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.00808v1",
      "published_date": "2024-02-24 14:18:11 UTC",
      "updated_date": "2024-02-24 14:18:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:42:16.488742"
    },
    {
      "arxiv_id": "2402.15821v2",
      "title": "Cooperation and Control in Delegation Games",
      "title_zh": "委托博弈中的合作与控制",
      "authors": [
        "Oliver Sourbut",
        "Lewis Hammond",
        "Harriet Wood"
      ],
      "abstract": "Many settings of interest involving humans and machines -- from virtual\npersonal assistants to autonomous vehicles -- can naturally be modelled as\nprincipals (humans) delegating to agents (machines), which then interact with\neach other on their principals' behalf. We refer to these multi-principal,\nmulti-agent scenarios as delegation games. In such games, there are two\nimportant failure modes: problems of control (where an agent fails to act in\nline their principal's preferences) and problems of cooperation (where the\nagents fail to work well together). In this paper we formalise and analyse\nthese problems, further breaking them down into issues of alignment (do the\nplayers have similar preferences?) and capabilities (how competent are the\nplayers at satisfying those preferences?). We show -- theoretically and\nempirically -- how these measures determine the principals' welfare, how they\ncan be estimated using limited observations, and thus how they might be used to\nhelp us design more aligned and cooperative AI systems.",
      "tldr_zh": "这篇论文引入了委托游戏（delegation games）模型，用于描述人类（principals）委托机器（agents）互动的场景，如虚拟助手或自动驾驶车辆。论文分析了两种主要失败模式：控制问题（agents 未遵守 principals 偏好）和合作问题（agents 间协作不足），并将这些问题细分为对齐（alignment，玩家偏好是否相似）和能力（capabilities，玩家满足偏好能力）问题。通过理论和实证分析，论文展示了这些因素如何影响 principals 的福利，并提出使用有限观察来估计它们，从而指导设计更对齐和合作的 AI 系统。",
      "categories": [
        "cs.GT",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.GT",
      "comment": "Published at IJCAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.15821v2",
      "published_date": "2024-02-24 14:17:41 UTC",
      "updated_date": "2024-08-05 22:54:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:42:28.310713"
    },
    {
      "arxiv_id": "2402.15820v1",
      "title": "DART: Depth-Enhanced Accurate and Real-Time Background Matting",
      "title_zh": "DART: 深度增强的准确实时背景抠图",
      "authors": [
        "Hanxi Li",
        "Guofeng Li",
        "Bo Li",
        "Lin Wu",
        "Yan Cheng"
      ],
      "abstract": "Matting with a static background, often referred to as ``Background Matting\"\n(BGM), has garnered significant attention within the computer vision community\ndue to its pivotal role in various practical applications like webcasting and\nphoto editing. Nevertheless, achieving highly accurate background matting\nremains a formidable challenge, primarily owing to the limitations inherent in\nconventional RGB images. These limitations manifest in the form of\nsusceptibility to varying lighting conditions and unforeseen shadows.\n  In this paper, we leverage the rich depth information provided by the\nRGB-Depth (RGB-D) cameras to enhance background matting performance in\nreal-time, dubbed DART. Firstly, we adapt the original RGB-based BGM algorithm\nto incorporate depth information. The resulting model's output undergoes\nrefinement through Bayesian inference, incorporating a background depth prior.\nThe posterior prediction is then translated into a \"trimap,\" which is\nsubsequently fed into a state-of-the-art matting algorithm to generate more\nprecise alpha mattes. To ensure real-time matting capabilities, a critical\nrequirement for many real-world applications, we distill the backbone of our\nmodel from a larger and more versatile BGM network. Our experiments demonstrate\nthe superior performance of the proposed method. Moreover, thanks to the\ndistillation operation, our method achieves a remarkable processing speed of 33\nframes per second (fps) on a mid-range edge-computing device. This high\nefficiency underscores DART's immense potential for deployment in mobile\napplications}",
      "tldr_zh": "本论文提出DART方法，通过整合RGB-Depth (RGB-D) 相机提供的深度信息，提升背景抠图（Background Matting, BGM）的准确性和实时性能，以应对RGB图像受照明和阴影影响的挑战。DART首先将原始RGB-based BGM算法适应深度数据，并通过Bayesian inference结合背景深度先验生成精炼的trimap，然后输入先进抠图算法以产生精确的alpha matte；同时，通过模型蒸馏（distillation）从更大网络中提炼骨干，确保实时处理。实验结果显示，DART在性能上优于基线模型，并在中档边缘计算设备上实现33 fps的处理速度，适用于移动应用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.15820v1",
      "published_date": "2024-02-24 14:10:17 UTC",
      "updated_date": "2024-02-24 14:10:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:42:40.032375"
    },
    {
      "arxiv_id": "2402.16901v2",
      "title": "FGBERT: Function-Driven Pre-trained Gene Language Model for Metagenomics",
      "title_zh": "翻译失败",
      "authors": [
        "ChenRui Duan",
        "Zelin Zang",
        "Yongjie Xu",
        "Hang He",
        "Zihan Liu",
        "Siyuan Li",
        "Zijia Song",
        "Ju-Sheng Zheng",
        "Stan Z. Li"
      ],
      "abstract": "Metagenomic data, comprising mixed multi-species genomes, are prevalent in\ndiverse environments like oceans and soils, significantly impacting human\nhealth and ecological functions. However, current research relies on K-mer,\nwhich limits the capture of structurally and functionally relevant gene\ncontexts. Moreover, these approaches struggle with encoding biologically\nmeaningful genes and fail to address the One-to-Many and Many-to-One\nrelationships inherent in metagenomic data. To overcome these challenges, we\nintroduce FGBERT, a novel metagenomic pre-trained model that employs a\nprotein-based gene representation as a context-aware and structure-relevant\ntokenizer. FGBERT incorporates Masked Gene Modeling (MGM) to enhance the\nunderstanding of inter-gene contextual relationships and Triplet Enhanced\nMetagenomic Contrastive Learning (TMC) to elucidate gene sequence-function\nrelationships. Pre-trained on over 100 million metagenomic sequences, FGBERT\ndemonstrates superior performance on metagenomic datasets at four levels,\nspanning gene, functional, bacterial, and environmental levels and ranging from\n1k to 213k input sequences. Case studies of ATP Synthase and Gene Operons\nhighlight FGBERT's capability for functional recognition and its biological\nrelevance in metagenomic research.",
      "tldr_zh": "本研究针对 metagenomic 数据中 K-mer 方法的局限性（如无法捕获结构和功能相关基因上下文，以及处理 One-to-Many 和 Many-to-One 关系的不足），提出了一种功能驱动的预训练模型 FGBERT。FGBERT 采用 protein-based gene representation 作为 context-aware 和 structure-relevant tokenizer，并结合 Masked Gene Modeling (MGM) 来增强基因间上下文关系，以及 Triplet Enhanced Metagenomic Contrastive Learning (TMC) 来阐明基因序列-功能关系。在超过1亿 metagenomic 序列上预训练后，FGBERT 在基因、功能、细菌和环境四个层面上表现出优越性能，适用于从1k到213k输入序列的数据集。通过 ATP Synthase 和 Gene Operons 的案例研究，证明了其在功能识别和生物学相关性方面的强大能力。",
      "categories": [
        "q-bio.GN",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.GN",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.16901v2",
      "published_date": "2024-02-24 13:13:17 UTC",
      "updated_date": "2024-12-27 06:40:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:42:54.860499"
    },
    {
      "arxiv_id": "2402.15809v2",
      "title": "Empowering Large Language Model Agents through Action Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Haiteng Zhao",
        "Chang Ma",
        "Guoyin Wang",
        "Jing Su",
        "Lingpeng Kong",
        "Jingjing Xu",
        "Zhi-Hong Deng",
        "Hongxia Yang"
      ],
      "abstract": "Large Language Model (LLM) Agents have recently garnered increasing interest\nyet they are limited in their ability to learn from trial and error, a key\nelement of intelligent behavior. In this work, we argue that the capacity to\nlearn new actions from experience is fundamental to the advancement of learning\nin LLM agents. While humans naturally expand their action spaces and develop\nskills through experiential learning, LLM agents typically operate within fixed\naction spaces, limiting their potential for growth. To address these\nchallenges, our study explores open-action learning for language agents. We\nintroduce a framework LearnAct with an iterative learning strategy to create\nand improve actions in the form of Python functions. In each iteration, LLM\nrevises and updates the currently available actions based on the errors\nidentified in unsuccessful training tasks, thereby enhancing action\neffectiveness. Our experimental evaluations across Robotic Planning and\nAlfworld environments reveal that after learning on a few training task\ninstances, our approach to open-action learning markedly improves agent\nperformance for the type of task (by 32 percent in AlfWorld compared to\nReAct+Reflexion, for instance) highlighting the importance of experiential\naction learning in the development of more intelligent LLM agents.",
      "tldr_zh": "该研究指出，大型语言模型(LLM)代理在从试错中学习新动作方面存在局限性，因此提出LearnAct框架，支持开放动作学习以提升代理智能。LearnAct采用迭代学习策略，LLM通过分析失败任务的错误来修订和更新动作，这些动作以Python functions形式呈现，从而逐步优化代理行为。在Robotic Planning和Alfworld环境中，实验结果显示，该方法在少量训练任务后显著提升性能，例如在Alfworld中比ReAct+Reflexion提高了32%。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "9 pages",
      "pdf_url": "http://arxiv.org/pdf/2402.15809v2",
      "published_date": "2024-02-24 13:13:04 UTC",
      "updated_date": "2024-08-08 07:05:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:43:04.378062"
    },
    {
      "arxiv_id": "2402.15808v2",
      "title": "Optimal Zero-Shot Detector for Multi-Armed Attacks",
      "title_zh": "翻译失败",
      "authors": [
        "Federica Granese",
        "Marco Romanelli",
        "Pablo Piantanida"
      ],
      "abstract": "This paper explores a scenario in which a malicious actor employs a\nmulti-armed attack strategy to manipulate data samples, offering them various\navenues to introduce noise into the dataset. Our central objective is to\nprotect the data by detecting any alterations to the input. We approach this\ndefensive strategy with utmost caution, operating in an environment where the\ndefender possesses significantly less information compared to the attacker.\nSpecifically, the defender is unable to utilize any data samples for training a\ndefense model or verifying the integrity of the channel. Instead, the defender\nrelies exclusively on a set of pre-existing detectors readily available \"off\nthe shelf\". To tackle this challenge, we derive an innovative\ninformation-theoretic defense approach that optimally aggregates the decisions\nmade by these detectors, eliminating the need for any training data. We further\nexplore a practical use-case scenario for empirical evaluation, where the\nattacker possesses a pre-trained classifier and launches well-known adversarial\nattacks against it. Our experiments highlight the effectiveness of our proposed\nsolution, even in scenarios that deviate from the optimal setup.",
      "tldr_zh": "这篇论文探讨了恶意攻击者使用 multi-armed attack 策略操纵数据样本的问题，目标是开发一种零样本(zero-shot)检测器来保护数据免受篡改。论文提出了一种创新的信息-theoretic 防御方法，通过最佳聚合现成“off-the-shelf”检测器的决策，而无需任何训练数据或样本验证。实验结果显示，该方法在攻击者使用预训练分类器发起 adversarial attacks 的实际场景中表现出色，即使在非最优条件下也能有效提升防御性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to appear in the 27th International Conference on Artificial\n  Intelligence and Statistics (AISTATS), May 2nd - May 4th, 2024 This article\n  supersedes arXiv:2302.02216",
      "pdf_url": "http://arxiv.org/pdf/2402.15808v2",
      "published_date": "2024-02-24 13:08:39 UTC",
      "updated_date": "2024-02-27 20:08:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:43:15.790177"
    },
    {
      "arxiv_id": "2402.15796v1",
      "title": "Construction and application of artificial intelligence crowdsourcing map based on multi-track GPS data",
      "title_zh": "基于多轨迹 GPS 数据的人工智能众包地图构建与应用",
      "authors": [
        "Yong Wang",
        "Yanlin Zhou",
        "Huan Ji",
        "Zheng He",
        "Xinyu Shen"
      ],
      "abstract": "In recent years, the rapid development of high-precision map technology\ncombined with artificial intelligence has ushered in a new development\nopportunity in the field of intelligent vehicles. High-precision map technology\nis an important guarantee for intelligent vehicles to achieve autonomous\ndriving. However, due to the lack of research on high-precision map technology,\nit is difficult to rationally use this technology in the field of intelligent\nvehicles. Therefore, relevant researchers studied a fast and effective\nalgorithm to generate high-precision GPS data from a large number of\nlow-precision GPS trajectory data fusion, and generated several key data points\nto simplify the description of GPS trajectory, and realized the \"crowdsourced\nupdate\" model based on a large number of social vehicles for map data\ncollection came into being. This kind of algorithm has the important\nsignificance to improve the data accuracy, reduce the measurement cost and\nreduce the data storage space. On this basis, this paper analyzes the\nimplementation form of crowdsourcing map, so as to improve the various\ninformation data in the high-precision map according to the actual situation,\nand promote the high-precision map can be reasonably applied to the intelligent\ncar.",
      "tldr_zh": "本研究探讨了基于多轨迹 GPS data 的 artificial intelligence crowdsourcing map 的构建和应用，旨在解决高-precision map 在智能车辆领域的数据准确性和成本问题。研究提出了一种快速有效的算法，通过融合大量低-precision GPS 轨迹数据生成高精度 GPS data 的关键点，并简化轨迹描述，同时实现了基于社会车辆的“crowdsourced update”模型来收集地图数据。该方法显著提高了数据准确性、降低了测量成本和数据存储空间，最终促进高-precision map 在智能车辆自主驾驶中的合理应用。",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.15796v1",
      "published_date": "2024-02-24 11:54:32 UTC",
      "updated_date": "2024-02-24 11:54:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:43:28.694692"
    },
    {
      "arxiv_id": "2403.00805v1",
      "title": "A New Dynamic Distributed Planning Approach: Application to DPDP Problems",
      "title_zh": "翻译失败",
      "authors": [
        "Zakaria Tolba"
      ],
      "abstract": "In this work, we proposed a new dynamic distributed planning approach that is\nable to take into account the changes that the agent introduces on his set of\nactions to be planned in order to take into account the changes that occur in\nhis environment. Our approach fits into the context of distributed planning for\ndistributed plans where each agent can produce its own plans. According to our\napproach the generation of the plans is based on the satisfaction of the\nconstraints by the use of the genetic algorithms. Our approach is to generate,\na new plan by each agent, whenever there is a change in its set of actions to\nplan. This in order to take into account the new actions introduced in its new\nplan. In this new plan, the agent takes, each time, as a new action set to plan\nall the old un-executed actions of the old plan and the new actions engendered\nby the changes and as a new initial state; the state in which the set of\nactions of the agent undergoes a change. In our work, we used a concrete case\nto illustrate and demonstrate the utility of our approach.",
      "tldr_zh": "这篇论文提出了一种新的动态分布式规划方法，应用于DPDP（Distributed Planning for Distributed Plans）问题，以帮助代理在环境变化时动态调整其行动集。方法的核心是利用遗传算法基于约束生成计划，每当代理的行动集发生变化时，它会创建新计划，将旧未执行行动和新行动结合，并以变化后的状态作为初始状态。该方法通过一个具体案例演示了其实用性和有效性，在分布式规划中提升了代理的适应性。",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "Master's thesis, in French language",
      "pdf_url": "http://arxiv.org/pdf/2403.00805v1",
      "published_date": "2024-02-24 10:06:04 UTC",
      "updated_date": "2024-02-24 10:06:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:43:41.009567"
    },
    {
      "arxiv_id": "2402.15779v1",
      "title": "Cryptanalysis and improvement of multimodal data encryption by machine-learning-based system",
      "title_zh": "翻译失败",
      "authors": [
        "Zakaria Tolba"
      ],
      "abstract": "With the rising popularity of the internet and the widespread use of networks\nand information systems via the cloud and data centers, the privacy and\nsecurity of individuals and organizations have become extremely crucial. In\nthis perspective, encryption consolidates effective technologies that can\neffectively fulfill these requirements by protecting public information\nexchanges. To achieve these aims, the researchers used a wide assortment of\nencryption algorithms to accommodate the varied requirements of this field, as\nwell as focusing on complex mathematical issues during their work to\nsubstantially complicate the encrypted communication mechanism. as much as\npossible to preserve personal information while significantly reducing the\npossibility of attacks. Depending on how complex and distinct the requirements\nestablished by these various applications are, the potential of trying to break\nthem continues to occur, and systems for evaluating and verifying the\ncryptographic algorithms implemented continue to be necessary. The best\napproach to analyzing an encryption algorithm is to identify a practical and\nefficient technique to break it or to learn ways to detect and repair weak\naspects in algorithms, which is known as cryptanalysis. Experts in\ncryptanalysis have discovered several methods for breaking the cipher, such as\ndiscovering a critical vulnerability in mathematical equations to derive the\nsecret key or determining the plaintext from the ciphertext. There are various\nattacks against secure cryptographic algorithms in the literature, and the\nstrategies and mathematical solutions widely employed empower cryptanalysts to\ndemonstrate their findings, identify weaknesses, and diagnose maintenance\nfailures in algorithms.",
      "tldr_zh": "本研究针对多模态数据加密的安全性问题，进行了密码分析（cryptanalysis），重点分析现有加密算法的弱点，如数学方程中的关键漏洞，以推导出密钥或从密文恢复明文。论文提出了一种基于机器学习的系统，用于检测和修复这些算法的缺陷，从而显著降低攻击风险。实验结果表明，这种方法能有效提升加密机制的鲁棒性，为保护个人信息和网络安全提供改进策略。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CR",
      "comment": "Doctoral thesis. Keywords: Cryptanalysis, Black-box, Deep learning,\n  Machine learning, Ciphertext, Plaintext, Genetic algorithm, Permutation box,\n  Substitution Box",
      "pdf_url": "http://arxiv.org/pdf/2402.15779v1",
      "published_date": "2024-02-24 10:02:21 UTC",
      "updated_date": "2024-02-24 10:02:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:43:53.258851"
    },
    {
      "arxiv_id": "2402.15770v1",
      "title": "From COBIT to ISO 42001: Evaluating Cybersecurity Frameworks for Opportunities, Risks, and Regulatory Compliance in Commercializing Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Timothy R. McIntosh",
        "Teo Susnjak",
        "Tong Liu",
        "Paul Watters",
        "Raza Nowrozy",
        "Malka N. Halgamuge"
      ],
      "abstract": "This study investigated the integration readiness of four predominant\ncybersecurity Governance, Risk and Compliance (GRC) frameworks - NIST CSF 2.0,\nCOBIT 2019, ISO 27001:2022, and the latest ISO 42001:2023 - for the\nopportunities, risks, and regulatory compliance when adopting Large Language\nModels (LLMs), using qualitative content analysis and expert validation. Our\nanalysis, with both LLMs and human experts in the loop, uncovered potential for\nLLM integration together with inadequacies in LLM risk oversight of those\nframeworks. Comparative gap analysis has highlighted that the new ISO\n42001:2023, specifically designed for Artificial Intelligence (AI) management\nsystems, provided most comprehensive facilitation for LLM opportunities,\nwhereas COBIT 2019 aligned most closely with the impending European Union AI\nAct. Nonetheless, our findings suggested that all evaluated frameworks would\nbenefit from enhancements to more effectively and more comprehensively address\nthe multifaceted risks associated with LLMs, indicating a critical and\ntime-sensitive need for their continuous evolution. We propose integrating\nhuman-expert-in-the-loop validation processes as crucial for enhancing\ncybersecurity frameworks to support secure and compliant LLM integration, and\ndiscuss implications for the continuous evolution of cybersecurity GRC\nframeworks to support the secure integration of LLMs.",
      "tldr_zh": "本研究评估了四个主要网络安全治理、风险和合规 (GRC) 框架——NIST CSF 2.0、COBIT 2019、ISO 27001:2022 和 ISO 42001:2023——在采用 Large Language Models (LLMs) 时所提供的机会、风险和监管合规支持，使用定性内容分析和专家验证方法。分析发现，ISO 42001:2023 最全面地促进了 LLMs 的机会，而 COBIT 2019 最符合即将到来的欧盟 AI Act (EU AI Act)，但所有框架在监督 LLMs 的多方面风险方面均存在不足。研究建议通过整合人类专家参与的验证过程来增强这些框架，以支持 LLMs 的安全整合，并强调网络安全 GRC 框架的持续演变迫在眉睫。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.15770v1",
      "published_date": "2024-02-24 09:06:25 UTC",
      "updated_date": "2024-02-24 09:06:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:44:08.989677"
    },
    {
      "arxiv_id": "2402.15769v2",
      "title": "GenCode: A Generic Data Augmentation Framework for Boosting Deep Learning-Based Code Understanding",
      "title_zh": "GenCode：一种通用的数据增强框架，用于提升基于深度学习的代码理解",
      "authors": [
        "Zeming Dong",
        "Qiang Hu",
        "Xiaofei Xie",
        "Maxime Cordy",
        "Mike Papadakis",
        "Jianjun Zhao"
      ],
      "abstract": "Pre-trained code models lead the era of code intelligence with multiple\nmodels have been designed with impressive performance. However, one important\nproblem, data augmentation for code data that automatically helps developers\nprepare training data lacks study in this field. In this paper, we introduce a\ngeneric data augmentation framework, GenCode, to enhance the training of code\nunderstanding models. Simply speaking, GenCode follows a\ngeneration-and-selection paradigm to prepare useful training code data.\nSpecifically, it employs code transformation techniques to generate new code\ncandidates first and then selects important ones as the training data by\nimportance metrics. To evaluate the effectiveness of GenCode, we conduct\nexperiments on four code understanding tasks (e.g., code clone detection) and\nthree pre-trained code models (e.g., CodeT5). Compared to the state-of-the-art\n(SOTA) code augmentation method, MixCode, GenCode produces code models with\n2.92% higher accuracy and 4.90% robustness on average.",
      "tldr_zh": "本论文提出了一种通用的数据增强框架 GenCode，用于提升基于深度学习的代码理解模型的训练效果，旨在解决代码数据增强缺乏自动化的问题。GenCode 采用生成-选择范式，首先通过代码转换技术生成新代码候选，然后利用重要性指标筛选出有用的训练数据。实验在四个代码理解任务（如代码克隆检测）和三个预训练模型（如 CodeT5）上进行，结果显示 GenCode 相较于最先进方法 MixCode，平均提高了 2.92% 的准确率和 4.90% 的鲁棒性。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.15769v2",
      "published_date": "2024-02-24 08:57:12 UTC",
      "updated_date": "2024-11-11 09:38:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:44:18.133064"
    },
    {
      "arxiv_id": "2402.15767v1",
      "title": "PhyPlan: Compositional and Adaptive Physical Task Reasoning with Physics-Informed Skill Networks for Robot Manipulators",
      "title_zh": "翻译失败",
      "authors": [
        "Harshil Vagadia",
        "Mudit Chopra",
        "Abhinav Barnawal",
        "Tamajit Banerjee",
        "Shreshth Tuli",
        "Souvik Chakraborty",
        "Rohan Paul"
      ],
      "abstract": "Given the task of positioning a ball-like object to a goal region beyond\ndirect reach, humans can often throw, slide, or rebound objects against the\nwall to attain the goal. However, enabling robots to reason similarly is\nnon-trivial. Existing methods for physical reasoning are data-hungry and\nstruggle with complexity and uncertainty inherent in the real world. This paper\npresents PhyPlan, a novel physics-informed planning framework that combines\nphysics-informed neural networks (PINNs) with modified Monte Carlo Tree Search\n(MCTS) to enable embodied agents to perform dynamic physical tasks. PhyPlan\nleverages PINNs to simulate and predict outcomes of actions in a fast and\naccurate manner and uses MCTS for planning. It dynamically determines whether\nto consult a PINN-based simulator (coarse but fast) or engage directly with the\nactual environment (fine but slow) to determine optimal policy. Evaluation with\nrobots in simulated 3D environments demonstrates the ability of our approach to\nsolve 3D-physical reasoning tasks involving the composition of dynamic skills.\nQuantitatively, PhyPlan excels in several aspects: (i) it achieves lower regret\nwhen learning novel tasks compared to state-of-the-art, (ii) it expedites skill\nlearning and enhances the speed of physical reasoning, (iii) it demonstrates\nhigher data efficiency compared to a physics un-informed approach.",
      "tldr_zh": "本论文提出 PhyPlan，一种基于 Physics-Informed Neural Networks (PINNs) 和修改的 Monte Carlo Tree Search (MCTS) 的框架，用于机器人机械臂的物理任务推理，帮助机器人处理动态任务，如投掷或反弹物体以达到目标。PhyPlan 通过 PINNs 快速模拟动作结果，并结合 MCTS 进行规划，同时动态决定是使用粗略但快速的模拟器还是精确但缓慢的真实环境交互，以优化决策。在模拟 3D 环境中评估结果表明，PhyPlan 比现有方法降低 regret、加速技能学习，并显著提高数据效率。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.15767v1",
      "published_date": "2024-02-24 08:51:03 UTC",
      "updated_date": "2024-02-24 08:51:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:44:30.375936"
    },
    {
      "arxiv_id": "2402.15764v2",
      "title": "Look Before You Leap: Problem Elaboration Prompting Improves Mathematical Reasoning in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Haoran Liao",
        "Jidong Tian",
        "Shaohua Hu",
        "Hao He",
        "Yaohui Jin"
      ],
      "abstract": "Large language models (LLMs) still grapple with complex tasks like\nmathematical reasoning. Despite significant efforts invested in improving\nprefix prompts or reasoning process, the crucial role of problem context might\nhave been neglected. Accurate recognition of inputs is fundamental for solving\nmathematical tasks, as ill-formed problems could potentially mislead LLM's\nreasoning. In this study, we propose a new approach named Problem Elaboration\nPrompting (PEP) to enhance the mathematical capacities of LLMs. Specifically,\nPEP decomposes and elucidates the problem context before reasoning, therefore\nenhancing the context modeling and parsing efficiency. Experiments across\ndatasets and models demonstrate promising performances: (1) PEP demonstrates an\noverall enhancement in various mathematical tasks. For instance, with the\nGPT-3.5 model, PEP exhibits improvements of 9.93% and 8.80% on GSM8k through\ngreedy decoding and self-consistency, respectively. (2) PEP can be easily\nimplemented and integrated with other prompting methods. (3) PEP shows\nparticular strength in handling distraction problems.",
      "tldr_zh": "本论文探讨了大型语言模型（LLMs）在数学推理任务中的挑战，强调问题上下文识别的重要性，并提出了一种新方法：Problem Elaboration Prompting (PEP)。PEP 通过在推理前分解和阐述问题上下文，提升了上下文建模和解析效率，从而改善了模型的数学能力。实验结果显示，在 GSM8k 数据集上，使用 GPT-3.5 模型时，PEP 通过贪婪解码和自一致性方法分别提高了 9.93% 和 8.80% 的准确率，且该方法易于与其他提示技术结合，并特别擅长处理 distraction problems。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.15764v2",
      "published_date": "2024-02-24 08:40:30 UTC",
      "updated_date": "2024-03-27 01:23:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:44:42.268893"
    },
    {
      "arxiv_id": "2402.17786v1",
      "title": "Stepwise Self-Consistent Mathematical Reasoning with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zilong Zhao",
        "Yao Rong",
        "Dongyang Guo",
        "Emek Gözlüklü",
        "Emir Gülboy",
        "Enkelejda Kasneci"
      ],
      "abstract": "Using Large Language Models for complex mathematical reasoning is difficult,\nprimarily due to the complexity of multi-step reasoning. The main challenges of\nthis process include (1) selecting critical intermediate results to advance the\nprocedure, and (2) limited exploration of potential solutions. To address these\nissues, we introduce a novel algorithm, namely Stepwise Self-Consistent\nChain-of-Thought (SSC-CoT). SSC-CoT employs a strategy of selecting\nintermediate steps based on the intersection of various reasoning chains.\nAdditionally, SSC-CoT enables the model to discover critical intermediate steps\nby querying a knowledge graph comprising relevant domain knowledge. To validate\nSSC-CoT, we present a new dataset, TriMaster100, tailored for complex\ntrigonometry problems. This dataset contains 100 questions, with each solution\nbroken down into scored intermediate steps, facilitating a comprehensive\nevaluation of the mathematical reasoning process. On TriMaster100, SSC-CoT\ntriples the effectiveness of the state-of-the-art methods. Furthermore, we\nbenchmark SSC-CoT on the widely recognized complex mathematical question\ndataset, MATH level 5, and it surpasses the second-best method by 7.2% in\naccuracy. Code and the TriMaster100 dataset can be found at:\nhttps://github.com/zhao-zilong/ssc-cot.",
      "tldr_zh": "这篇论文针对大型语言模型（Large Language Models）在复杂数学推理中的挑战，提出了一种新算法Stepwise Self-Consistent Chain-of-Thought (SSC-CoT)，以解决选择关键中间结果和探索潜在解决方案的难题。SSC-CoT 通过基于各种推理链的交集选择中间步骤，并利用包含相关领域知识的knowledge graph进行查询，从而提升多步推理的准确性和探索能力。研究者创建了新数据集TriMaster100，专注于复杂三角学问题，每个解决方案分解为评分中间步骤，用于全面评估推理过程。在实验中，SSC-CoT 在TriMaster100上使最先进方法的有效性提高三倍，并在MATH level 5数据集上准确率比第二好方法高7.2%。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.17786v1",
      "published_date": "2024-02-24 08:22:39 UTC",
      "updated_date": "2024-02-24 08:22:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:44:54.786478"
    },
    {
      "arxiv_id": "2402.15761v3",
      "title": "Res-VMamba: Fine-Grained Food Category Visual Classification Using Selective State Space Models with Deep Residual Learning",
      "title_zh": "Res-VMamba：利用选择性状态空间模型与深度残差学习的细",
      "authors": [
        "Chi-Sheng Chen",
        "Guan-Ying Chen",
        "Dong Zhou",
        "Di Jiang",
        "Dai-Shi Chen"
      ],
      "abstract": "Food classification is the foundation for developing food vision tasks and\nplays a key role in the burgeoning field of computational nutrition. Due to the\ncomplexity of food requiring fine-grained classification, recent academic\nresearch mainly modifies Convolutional Neural Networks (CNNs) and/or Vision\nTransformers (ViTs) to perform food category classification. However, to learn\nfine-grained features, the CNN backbone needs additional structural design,\nwhereas ViT, containing the self-attention module, has increased computational\ncomplexity. In recent months, a new Sequence State Space (S4) model, through a\nSelection mechanism and computation with a Scan (S6), colloquially termed\nMamba, has demonstrated superior performance and computation efficiency\ncompared to the Transformer architecture. The VMamba model, which incorporates\nthe Mamba mechanism into image tasks (such as classification), currently\nestablishes the state-of-the-art (SOTA) on the ImageNet dataset. In this\nresearch, we introduce an academically underestimated food dataset CNFOOD-241,\nand pioneer the integration of a residual learning framework within the VMamba\nmodel to concurrently harness both global and local state features inherent in\nthe original VMamba architectural design. The research results show that VMamba\nsurpasses current SOTA models in fine-grained and food classification. The\nproposed Res-VMamba further improves the classification accuracy to 79.54\\%\nwithout pretrained weight. Our findings elucidate that our proposed methodology\nestablishes a new benchmark for SOTA performance in food recognition on the\nCNFOOD-241 dataset. The code can be obtained on GitHub:\nhttps://github.com/ChiShengChen/ResVMamba.",
      "tldr_zh": "本研究针对食物分类的细粒度挑战，引入Selective State Space Models的Mamba机制，以克服CNN和ViTs模型的结构复杂性和计算效率问题。作者提出Res-VMamba模型，将深层残差学习框架整合到VMamba中，结合全局和局部特征，实现高效的食物类别视觉分类，并在新数据集CNFOOD-241上进行评估。实验结果显示，Res-VMamba在无预训练权重的情况下达到79.54%的准确率，超越现有SOTA模型，并为计算营养领域的食物识别任务设立新基准。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "14 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.15761v3",
      "published_date": "2024-02-24 08:20:39 UTC",
      "updated_date": "2024-09-06 16:23:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:45:05.718067"
    },
    {
      "arxiv_id": "2402.15759v2",
      "title": "TV-SAM: Increasing Zero-Shot Segmentation Performance on Multimodal Medical Images Using GPT-4 Generated Descriptive Prompts Without Human Annotation",
      "title_zh": "TV-SAM：使用 GPT-4 生成的描述性提示提高多模态医学图像零样本分割性能，而无需人工标注",
      "authors": [
        "Zekun Jiang",
        "Dongjie Cheng",
        "Ziyuan Qin",
        "Jun Gao",
        "Qicheng Lao",
        "Abdullaev Bakhrom Ismoilovich",
        "Urazboev Gayrat",
        "Yuldashov Elyorbek",
        "Bekchanov Habibullo",
        "Defu Tang",
        "LinJing Wei",
        "Kang Li",
        "Le Zhang"
      ],
      "abstract": "This study presents a novel multimodal medical image zero-shot segmentation\nalgorithm named the text-visual-prompt segment anything model (TV-SAM) without\nany manual annotations. The TV-SAM incorporates and integrates the large\nlanguage model GPT-4, the vision language model GLIP, and the SAM to\nautonomously generate descriptive text prompts and visual bounding box prompts\nfrom medical images, thereby enhancing the SAM's capability for zero-shot\nsegmentation. Comprehensive evaluations are implemented on seven public\ndatasets encompassing eight imaging modalities to demonstrate that TV-SAM can\neffectively segment unseen targets across various modalities without additional\ntraining. TV-SAM significantly outperforms SAM AUTO and GSAM, closely matching\nthe performance of SAM BBOX with gold standard bounding box prompts and\nsurpasses the state-of-the-art methods on specific datasets such as ISIC and\nWBC. The study indicates that TV-SAM serves as an effective multimodal medical\nimage zero-shot segmentation algorithm, highlighting the significant\ncontribution of GPT-4 to zero-shot segmentation. By integrating foundational\nmodels such as GPT-4, GLIP, and SAM, the ability to address complex problems in\nspecialized domains can be enhanced.",
      "tldr_zh": "该研究提出了一种名为 TV-SAM 的多模态医疗图像零-shot segmentation 算法，利用 GPT-4 生成描述性文本提示和视觉边界框提示，而无需任何手动标注。通过整合 GPT-4、GLIP 和 SAM，TV-SAM 实现了对未见目标的自主分割，并在七个公共数据集（涵盖八种成像模态）上进行评估。实验结果显示，TV-SAM 显著优于 SAM AUTO 和 GSAM，性能接近 SAM BBOX，并在 ISIC 和 WBC 等特定数据集上超越最先进方法，证明了 GPT-4 在增强零-shot segmentation 方面的关键贡献。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "13 pages, 5 figures, 4 tables, accepted by BDMA Journal",
      "pdf_url": "http://arxiv.org/pdf/2402.15759v2",
      "published_date": "2024-02-24 08:10:54 UTC",
      "updated_date": "2024-10-14 14:41:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:45:17.558997"
    },
    {
      "arxiv_id": "2402.15758v2",
      "title": "Chimera: A Lossless Decoding Method for Accelerating Large Language Models Inference by Fusing all Tokens",
      "title_zh": "翻译失败",
      "authors": [
        "Ziqian Zeng",
        "Jiahong Yu",
        "Qianshi Pang",
        "Zihao Wang",
        "Huiping Zhuang",
        "Hongen Shao",
        "Xiaofeng Zou"
      ],
      "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities across\nvarious tasks. However, their widespread application is hindered by the\nresource-intensive decoding process. To address this challenge, current\napproaches have incorporated additional decoding heads to enable parallel\nprediction of multiple subsequent tokens, thereby achieving inference\nacceleration. Nevertheless, the accuracy of these decoding heads falls short of\nthe auto-regressive decoding approach.\n  In light of these limitations, we propose Chimera, a novel framework\nspecifically designed for speculative sampling. Within this framework, we\nintroduce a lightweight draft model that effectively utilizes previously\ngenerated tokens to predict subsequent words. To ensure both accuracy and\nefficiency, we present two strategies within the lightweight draft model.\nFirstly, we focus on capturing short-range dependencies at the bottom layer.\nSecondly, we leverage the readily available representations from the original\nLLM.Through empirical evaluation on the Vicuna and LlaMA-2 series, Chimera\ndemonstrates impressive results, achieving an average latency speedup ratio of\n2.7x compared to the vanilla auto-regressive decoding approach. This highlights\nthe potential of our proposed framework in significantly improving the\nefficiency of large language models during the decoding process.",
      "tldr_zh": "本论文提出 Chimera，一种无损解码框架，用于加速大型语言模型 (LLMs) 的推理过程，通过融合所有标记实现并行预测。Chimera 引入一个轻量级草稿模型，利用先前生成的标记预测后续词，并采用两种策略：捕捉底层短距离依赖和利用原始 LLM 的可用表示，从而平衡准确性和效率。在 Vicuna 和 LlaMA-2 系列的实证评估中，Chimera 相对于传统的自回归解码方法实现了平均延迟加速比 2.7 倍，显著提升了 LLM 的推理性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.15758v2",
      "published_date": "2024-02-24 08:10:39 UTC",
      "updated_date": "2024-04-18 16:23:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:45:28.911239"
    },
    {
      "arxiv_id": "2402.15757v1",
      "title": "Batch Active Learning of Reward Functions from Human Preferences",
      "title_zh": "从人类偏好中批量主动学习奖励函数",
      "authors": [
        "Erdem Bıyık",
        "Nima Anari",
        "Dorsa Sadigh"
      ],
      "abstract": "Data generation and labeling are often expensive in robot learning.\nPreference-based learning is a concept that enables reliable labeling by\nquerying users with preference questions. Active querying methods are commonly\nemployed in preference-based learning to generate more informative data at the\nexpense of parallelization and computation time. In this paper, we develop a\nset of novel algorithms, batch active preference-based learning methods, that\nenable efficient learning of reward functions using as few data samples as\npossible while still having short query generation times and also retaining\nparallelizability. We introduce a method based on determinantal point processes\n(DPP) for active batch generation and several heuristic-based alternatives.\nFinally, we present our experimental results for a variety of robotics tasks in\nsimulation. Our results suggest that our batch active learning algorithm\nrequires only a few queries that are computed in a short amount of time. We\nshowcase one of our algorithms in a study to learn human users' preferences.",
      "tldr_zh": "这篇论文提出了批量主动偏好学习方法，用于从人类偏好中高效学习奖励函数(reward functions)，以减少机器人学习中的数据生成和标注成本。算法包括基于Determinantal Point Processes (DPP)的主动批量生成方法，以及几个启发式备选方法，这些方法确保查询生成时间短并保持并行性。实验结果显示，该算法在多种模拟机器人任务中只需少量查询即可实现高效学习，并在实际研究中成功应用于学习人类用户的偏好。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "To appear in ACM Transactions on Human-Robot Interaction (THRI). 27\n  pages, 12 figures, 2 tables. arXiv admin note: text overlap with\n  arXiv:1810.04303",
      "pdf_url": "http://arxiv.org/pdf/2402.15757v1",
      "published_date": "2024-02-24 08:07:48 UTC",
      "updated_date": "2024-02-24 08:07:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:45:41.234379"
    },
    {
      "arxiv_id": "2402.15751v1",
      "title": "Sparse MeZO: Less Parameters for Better Performance in Zeroth-Order LLM Fine-Tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Yong Liu",
        "Zirui Zhu",
        "Chaoyu Gong",
        "Minhao Cheng",
        "Cho-Jui Hsieh",
        "Yang You"
      ],
      "abstract": "While fine-tuning large language models (LLMs) for specific tasks often\nyields impressive results, it comes at the cost of memory inefficiency due to\nback-propagation in gradient-based training. Memory-efficient Zeroth-order\n(MeZO) optimizers, recently proposed to address this issue, only require\nforward passes during training, making them more memory-friendly. However, the\nquality of gradient estimates in zeroth order optimization often depends on the\ndata dimensionality, potentially explaining why MeZO still exhibits significant\nperformance drops compared to standard fine-tuning across various tasks.\nInspired by the success of Parameter-Efficient Fine-Tuning (PEFT), this paper\nintroduces Sparse MeZO, a novel memory-efficient zeroth-order optimization\napproach that applies ZO only to a carefully chosen subset of parameters. We\npropose a simple yet effective parameter selection scheme that yields\nsignificant performance gains with Sparse-MeZO. Additionally, we develop a\nmemory-optimized implementation for sparse masking, ensuring the algorithm\nrequires only inference-level memory consumption, allowing Sparse-MeZO to\nfine-tune LLaMA-30b on a single A100 GPU. Experimental results illustrate that\nSparse-MeZO consistently improves both performance and convergence speed over\nMeZO without any overhead. For example, it achieves a 9\\% absolute accuracy\nimprovement and 3.5x speedup over MeZO on the RTE task.",
      "tldr_zh": "这篇论文引入了 Sparse MeZO，一种基于 Zeroth-Order 优化的方法，用于大型语言模型 (LLMs) 的微调，通过仅对选定的参数子集应用 ZO 来提高性能和内存效率。相比传统 MeZO，Sparse MeZO 采用一个简单有效的参数选择方案，同时开发了内存优化的稀疏掩码实现，使其只需推理级别的内存消耗，便于在单 A100 GPU 上微调 LLaMA-30b 模型。实验结果显示，Sparse MeZO 在各种任务上显著提升了准确率和收敛速度，例如在 RTE 任务上比 MeZO 提高了 9% 的绝对准确率并实现了 3.5 倍的加速。总体而言，该方法解决了 ZO 优化在高维数据中的性能问题，为 Parameter-Efficient Fine-Tuning (PEFT) 提供了更高效的替代方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.15751v1",
      "published_date": "2024-02-24 07:22:04 UTC",
      "updated_date": "2024-02-24 07:22:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:45:54.238765"
    },
    {
      "arxiv_id": "2402.15746v1",
      "title": "Intelligent Director: An Automatic Framework for Dynamic Visual Composition using ChatGPT",
      "title_zh": "翻译失败",
      "authors": [
        "Sixiao Zheng",
        "Jingyang Huo",
        "Yu Wang",
        "Yanwei Fu"
      ],
      "abstract": "With the rise of short video platforms represented by TikTok, the trend of\nusers expressing their creativity through photos and videos has increased\ndramatically. However, ordinary users lack the professional skills to produce\nhigh-quality videos using professional creation software. To meet the demand\nfor intelligent and user-friendly video creation tools, we propose the Dynamic\nVisual Composition (DVC) task, an interesting and challenging task that aims to\nautomatically integrate various media elements based on user requirements and\ncreate storytelling videos. We propose an Intelligent Director framework,\nutilizing LENS to generate descriptions for images and video frames and\ncombining ChatGPT to generate coherent captions while recommending appropriate\nmusic names. Then, the best-matched music is obtained through music retrieval.\nThen, materials such as captions, images, videos, and music are integrated to\nseamlessly synthesize the video. Finally, we apply AnimeGANv2 for style\ntransfer. We construct UCF101-DVC and Personal Album datasets and verified the\neffectiveness of our framework in solving DVC through qualitative and\nquantitative comparisons, along with user studies, demonstrating its\nsubstantial potential.",
      "tldr_zh": "该论文提出Intelligent Director框架，用于Dynamic Visual Composition (DVC)任务，该任务旨在根据用户需求自动整合图像、视频、音乐等媒体元素，创建高质量的故事性视频，以解决普通用户缺乏专业技能的问题。框架利用LENS生成图像和视频帧的描述，结合ChatGPT生成连贯字幕并推荐音乐名称，随后通过音乐检索获取最佳匹配，并应用AnimeGANv2进行风格转移，最终合成无缝视频。实验在UCF101-DVC和Personal Album数据集上通过定性和定量比较以及用户研究，证明了框架的有效性，并展示了其在智能视频创作中的巨大潜力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "Project Page: https://sixiaozheng.github.io/IntelligentDirector/",
      "pdf_url": "http://arxiv.org/pdf/2402.15746v1",
      "published_date": "2024-02-24 06:58:15 UTC",
      "updated_date": "2024-02-24 06:58:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:46:06.064180"
    },
    {
      "arxiv_id": "2402.15745v2",
      "title": "GAOKAO-MM: A Chinese Human-Level Benchmark for Multimodal Models Evaluation",
      "title_zh": "GAOKAO-MM：一个用于多模态模型评估的中国人类水平基准",
      "authors": [
        "Yi Zong",
        "Xipeng Qiu"
      ],
      "abstract": "The Large Vision-Language Models (LVLMs) have demonstrated great abilities in\nimage perception and language understanding. However, existing multimodal\nbenchmarks focus on primary perception abilities and commonsense knowledge\nwhich are insufficient to reflect the comprehensive capabilities of LVLMs. We\npropose GAOKAO-MM, a multimodal benchmark based on the Chinese College Entrance\nExamination (GAOKAO), comprising of 8 subjects and 12 types of images, such as\ndiagrams, function graphs, maps and photos. GAOKAO-MM derives from native\nChinese context and sets human-level requirements for the model's abilities,\nincluding perception, understanding, knowledge and reasoning. We evaluate 10\nLVLMs and find that the accuracies of all of them are lower than 50%, with\nGPT-4-Vison (48.1%), Qwen-VL-Plus (41.2%) and Gemini-Pro-Vision (35.1%) ranking\nin the top three positions. The results of our multi-dimension analysis\nindicate that LVLMs have moderate distance towards Artificial General\nIntelligence (AGI) and provide insights facilitating the development of\nmultilingual LVLMs.",
      "tldr_zh": "本研究提出GAOKAO-MM，一种基于中国高考的中文多模态基准，用于评估Large Vision-Language Models (LVLMs)的全面能力，弥补现有基准仅关注基本感知和常识知识的不足。GAOKAO-MM涵盖8个科目和12种图像类型（如图表、函数图、地图和照片），要求模型具备感知、理解、知识和推理能力，并源于本土中文语境以设定人类水平标准。实验评估了10个LVLMs，结果显示所有模型准确率低于50%，其中GPT-4-Vision (48.1%)、Qwen-VL-Plus (41.2%)和Gemini-Pro-Vision (35.1%)排名前三；多维度分析揭示LVLMs距离Artificial General Intelligence (AGI)仍有差距，并为多语言LVLMs的发展提供宝贵见解。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.15745v2",
      "published_date": "2024-02-24 06:57:15 UTC",
      "updated_date": "2024-08-06 15:28:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:46:17.908934"
    },
    {
      "arxiv_id": "2402.16899v3",
      "title": "A priori Estimates for Deep Residual Network in Continuous-time Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Shuyu Yin",
        "Qixuan Zhou",
        "Fei Wen",
        "Tao Luo"
      ],
      "abstract": "Deep reinforcement learning excels in numerous large-scale practical\napplications. However, existing performance analyses ignores the unique\ncharacteristics of continuous-time control problems, is unable to directly\nestimate the generalization error of the Bellman optimal loss and require a\nboundedness assumption. Our work focuses on continuous-time control problems\nand proposes a method that is applicable to all such problems where the\ntransition function satisfies semi-group and Lipschitz properties. Under this\nmethod, we can directly analyze the \\emph{a priori} generalization error of the\nBellman optimal loss. The core of this method lies in two transformations of\nthe loss function. To complete the transformation, we propose a decomposition\nmethod for the maximum operator. Additionally, this analysis method does not\nrequire a boundedness assumption. Finally, we obtain an \\emph{a priori}\ngeneralization error without the curse of dimensionality.",
      "tldr_zh": "本论文针对深度强化学习在连续时间控制问题中的性能分析，指出现有方法忽略了问题特性、无法直接估计 Bellman 最优损失的 a priori 泛化误差，并依赖有界性假设。论文提出一种适用于过渡函数满足 semi-group 和 Lipschitz 性质的通用方法，通过损失函数的两个变换和最大运算符的分解，直接分析 a priori 泛化误差的核心。结果显示，该方法无需有界性假设，并成功避免了维度诅咒，提供更精确的泛化误差估计。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.16899v3",
      "published_date": "2024-02-24 06:31:43 UTC",
      "updated_date": "2024-03-07 05:33:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:46:31.534576"
    },
    {
      "arxiv_id": "2403.14652v1",
      "title": "MemeCraft: Contextual and Stance-Driven Multimodal Meme Generation",
      "title_zh": "MemeCraft: 情境与立场驱动的多模态",
      "authors": [
        "Han Wang",
        "Roy Ka-Wei Lee"
      ],
      "abstract": "Online memes have emerged as powerful digital cultural artifacts in the age\nof social media, offering not only humor but also platforms for political\ndiscourse, social critique, and information dissemination. Their extensive\nreach and influence in shaping online communities' sentiments make them\ninvaluable tools for campaigning and promoting ideologies. Despite the\ndevelopment of several meme-generation tools, there remains a gap in their\nsystematic evaluation and their ability to effectively communicate ideologies.\nAddressing this, we introduce MemeCraft, an innovative meme generator that\nleverages large language models (LLMs) and visual language models (VLMs) to\nproduce memes advocating specific social movements. MemeCraft presents an\nend-to-end pipeline, transforming user prompts into compelling multimodal memes\nwithout manual intervention. Conscious of the misuse potential in creating\ndivisive content, an intrinsic safety mechanism is embedded to curb hateful\nmeme production.",
      "tldr_zh": "本研究探讨了在线 memes 作为数字文化工具的作用，包括幽默、政治话语和社会批判等方面，并指出现有 meme 生成工具在系统评估和意识形态传播上存在不足。作者引入 MemeCraft，一种创新的多模态 meme 生成系统，利用大型语言模型 (LLMs) 和视觉语言模型 (VLMs) 构建端到端管道，从用户提示自动生成支持特定社会运动的上下文和立场驱动 memes。为了防止滥用，该系统内置安全机制，抑制仇恨内容的产生。MemeCraft 的设计旨在提升 memes 在推广意识形态方面的有效性，同时促进更负责任的在线内容创作。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL",
        "cs.MM",
        "I.2.7; I.2.10"
      ],
      "primary_category": "cs.CY",
      "comment": "8 pages, 7 figures, ACM MM 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.14652v1",
      "published_date": "2024-02-24 06:14:34 UTC",
      "updated_date": "2024-02-24 06:14:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:46:41.071822"
    },
    {
      "arxiv_id": "2402.15729v3",
      "title": "How Do Humans Write Code? Large Models Do It the Same Way Too",
      "title_zh": "人类如何编写代码？大型模型也以同样的方式进行",
      "authors": [
        "Long Li",
        "Xuzheng He",
        "Haozhe Wang",
        "Linlin Wang",
        "Liang He"
      ],
      "abstract": "Program-of-Thought (PoT) replaces natural language-based Chain-of-Thought\n(CoT) as the most popular method in Large Language Models (LLMs) mathematical\nreasoning tasks by utilizing external tool calls to circumvent computational\nerrors. However, our evaluation of the GPT-4 and Llama series reveals that\nusing PoT introduces more reasoning errors, such as incorrect formulas or\nflawed logic, compared to CoT. To address this issue, we propose Human-Think\nLanguage (HTL), which leverages a suite of strategies that help integrate PoT\nand CoT, encompassing: (1) a new generation paradigm that uses full CoT\nreasoning to control code generation. (2) Focus Attention, that directs model\nattention to the CoT reasoning during PoT to generate more logical code. (3)\nreinforcement learning that utilizes the accuracy of both CoT and PoT responses\nas rewards to prevent repetitive reasoning steps in LLMs when solving difficult\nmath problems. Our method achieves an average improvement of 6.5% on the\nLlama-Base model and 4.3% on the Mistral-Base model across 8 mathematical\ncalculation datasets. It also shows significant effectiveness on five\nout-of-domain datasets by controlling the model's information flow, exhibiting\nstrong transferability. Additionally, HTL shows the most significant\nimprovement in non-mathematical natural language inference task, contributing\nto a unified reasoning task framework",
      "tldr_zh": "本研究发现，虽然 Program-of-Thought (PoT) 通过外部工具调用在 Large Language Models (LLMs) 的数学推理任务中取代了 Chain-of-Thought (CoT)，但 PoT 导致更多推理错误，如不正确公式或逻辑缺陷。为解决此问题，提出 Human-Think Language (HTL)，它整合 PoT 和 CoT 的策略，包括使用完整 CoT 推理控制代码生成、Focus Attention 引导模型关注推理逻辑，以及强化学习以奖励准确响应并避免重复步骤。实验结果显示，HTL 在 8 个数学计算数据集上使 Llama-Base 模型平均提升 6.5%、Mistral-Base 提升 4.3%，并在外域数据集和非数学自然语言推理任务中表现出强转移性和显著改善，构建了一个统一的推理框架。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.PL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.15729v3",
      "published_date": "2024-02-24 05:40:01 UTC",
      "updated_date": "2024-10-16 08:04:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:46:56.043970"
    },
    {
      "arxiv_id": "2402.15727v2",
      "title": "LLMs Can Defend Themselves Against Jailbreaking in a Practical Manner: A Vision Paper",
      "title_zh": "大语言模型可以以实用方式防御越狱攻击",
      "authors": [
        "Daoyuan Wu",
        "Shuai Wang",
        "Yang Liu",
        "Ning Liu"
      ],
      "abstract": "Jailbreaking is an emerging adversarial attack that bypasses the safety\nalignment deployed in off-the-shelf large language models (LLMs). A\nconsiderable amount of research exists proposing more effective jailbreak\nattacks, including the recent Greedy Coordinate Gradient (GCG) attack,\njailbreak template-based attacks such as using \"Do-Anything-Now\" (DAN), and\nmultilingual jailbreak. In contrast, the defensive side has been relatively\nless explored. This paper proposes a lightweight yet practical defense called\nSELFDEFEND, which can defend against all existing jailbreak attacks with\nminimal delay for jailbreak prompts and negligible delay for normal user\nprompts. Our key insight is that regardless of the kind of jailbreak strategies\nemployed, they eventually need to include a harmful prompt (e.g., \"how to make\na bomb\") in the prompt sent to LLMs, and we found that existing LLMs can\neffectively recognize such harmful prompts that violate their safety policies.\nBased on this insight, we design a shadow stack that concurrently checks\nwhether a harmful prompt exists in the user prompt and triggers a checkpoint in\nthe normal stack once a token of \"No\" or a harmful prompt is output. The latter\ncould also generate an explainable LLM response to adversarial prompts. We\ndemonstrate our idea of SELFDEFEND works in various jailbreak scenarios through\nmanual analysis in GPT-3.5/4. We also list three future directions to further\nenhance SELFDEFEND.",
      "tldr_zh": "这篇论文探讨了大型语言模型（LLMs）如何以实用方式防御越狱攻击（Jailbreaking），提出了一种轻量级防御机制SELFDEFEND。核心方法利用LLMs的内在能力识别有害提示（如“how to make a bomb”），通过shadow stack并发检查用户输入，并在检测到违规时触发检查点，以最小延迟处理正常提示并生成解释性响应。实验在GPT-3.5/4上验证了SELFDEFEND对现有攻击（如Greedy Coordinate Gradient (GCG)和Do-Anything-Now (DAN)）的有效性，并提出了三个未来方向来进一步提升其性能。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "Fixed the bibliography reference issue in our LLM jailbreak defense\n  vision paper submitted on 24 Feb 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.15727v2",
      "published_date": "2024-02-24 05:34:43 UTC",
      "updated_date": "2024-03-04 05:37:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:47:06.149712"
    },
    {
      "arxiv_id": "2402.15721v2",
      "title": "Hal-Eval: A Universal and Fine-grained Hallucination Evaluation Framework for Large Vision Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Chaoya Jiang",
        "Hongrui Jia",
        "Wei Ye",
        "Mengfan Dong",
        "Haiyang Xu",
        "Ming Yan",
        "Ji Zhang",
        "Shikun Zhang"
      ],
      "abstract": "Large Vision Language Models exhibit remarkable capabilities but struggle\nwith hallucinations inconsistencies between images and their descriptions.\nPrevious hallucination evaluation studies on LVLMs have identified\nhallucinations in terms of objects, attributes, and relations but overlooked\ncomplex hallucinations that create an entire narrative around a fictional\nentity. In this paper, we introduce a refined taxonomy of hallucinations,\nfeaturing a new category: Event Hallucination. We then utilize advanced LLMs to\ngenerate and filter fine grained hallucinatory data consisting of various types\nof hallucinations, with a particular focus on event hallucinations, laying the\ngroundwork for integrating discriminative and generative evaluation methods\nwithin our universal evaluation framework. The proposed benchmark distinctively\nassesses LVLMs ability to tackle a broad spectrum of hallucinations, making it\na reliable and comprehensive tool for gauging LVLMs efficacy in handling\nhallucinations. We will release our code and data.",
      "tldr_zh": "这篇论文针对Large Vision Language Models (LVLMs)的hallucinations问题，引入了一个细化的分类体系，包括新的Event Hallucination类别，以覆盖复杂叙事型幻觉。研究者利用高级LLMs生成和过滤细粒度的幻觉数据，并提出一个通用评估框架，整合判别和生成方法来全面评估LVLMs处理对象、属性、关系和事件等各种hallucinations的能力。实验结果表明，该框架是可靠且全面的工具，将发布代码和数据以促进进一步研究。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by ACM MM 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.15721v2",
      "published_date": "2024-02-24 05:14:52 UTC",
      "updated_date": "2024-11-08 05:08:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:47:18.866594"
    },
    {
      "arxiv_id": "2402.17785v2",
      "title": "ByteComposer: a Human-like Melody Composition Method based on Language Model Agent",
      "title_zh": "翻译失败",
      "authors": [
        "Xia Liang",
        "Xingjian Du",
        "Jiaju Lin",
        "Pei Zou",
        "Yuan Wan",
        "Bilei Zhu"
      ],
      "abstract": "Large Language Models (LLM) have shown encouraging progress in multimodal\nunderstanding and generation tasks. However, how to design a human-aligned and\ninterpretable melody composition system is still under-explored. To solve this\nproblem, we propose ByteComposer, an agent framework emulating a human's\ncreative pipeline in four separate steps : \"Conception Analysis - Draft\nComposition - Self-Evaluation and Modification - Aesthetic Selection\". This\nframework seamlessly blends the interactive and knowledge-understanding\nfeatures of LLMs with existing symbolic music generation models, thereby\nachieving a melody composition agent comparable to human creators. We conduct\nextensive experiments on GPT4 and several open-source large language models,\nwhich substantiate our framework's effectiveness. Furthermore, professional\nmusic composers were engaged in multi-dimensional evaluations, the final\nresults demonstrated that across various facets of music composition,\nByteComposer agent attains the level of a novice melody composer.",
      "tldr_zh": "该研究提出ByteComposer，一种基于语言模型代理的旋律作曲方法，模拟人类的创造流程，通过四个步骤——Conception Analysis（构思分析）、Draft Composition（草稿创作）、Self-Evaluation and Modification（自我评估和修改）以及Aesthetic Selection（审美选择）——来整合LLM的交互和知识理解特性与现有符号音乐生成模型。实验在GPT4和多个开源LLM上进行，证明了框架的有效性。最终，通过专业音乐作曲家的多维度评估，ByteComposer达到了新手作曲家的水平，在音乐创作的可解释性和人类相似性方面表现出色。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.17785v2",
      "published_date": "2024-02-24 04:35:07 UTC",
      "updated_date": "2024-03-07 00:32:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:47:28.897030"
    },
    {
      "arxiv_id": "2402.15713v1",
      "title": "Making Pre-trained Language Models Better Continual Few-Shot Relation Extractors",
      "title_zh": "使预训练语言模型成为更好的持续少样本关系抽取器",
      "authors": [
        "Shengkun Ma",
        "Jiale Han",
        "Yi Liang",
        "Bo Cheng"
      ],
      "abstract": "Continual Few-shot Relation Extraction (CFRE) is a practical problem that\nrequires the model to continuously learn novel relations while avoiding\nforgetting old ones with few labeled training data. The primary challenges are\ncatastrophic forgetting and overfitting. This paper harnesses prompt learning\nto explore the implicit capabilities of pre-trained language models to address\nthe above two challenges, thereby making language models better continual\nfew-shot relation extractors. Specifically, we propose a Contrastive Prompt\nLearning framework, which designs prompt representation to acquire more\ngeneralized knowledge that can be easily adapted to old and new categories, and\nmargin-based contrastive learning to focus more on hard samples, therefore\nalleviating catastrophic forgetting and overfitting issues. To further remedy\noverfitting in low-resource scenarios, we introduce an effective memory\naugmentation strategy that employs well-crafted prompts to guide ChatGPT in\ngenerating diverse samples. Extensive experiments demonstrate that our method\noutperforms state-of-the-art methods by a large margin and significantly\nmitigates catastrophic forgetting and overfitting in low-resource scenarios.",
      "tldr_zh": "这篇论文针对 Continual Few-shot Relation Extraction (CFRE) 的灾难性遗忘（catastrophic forgetting）和过拟合（overfitting）问题，提出了一种 Contrastive Prompt Learning 框架，利用预训练语言模型的隐式能力来提升模型的持续学习性能。具体而言，该框架通过设计提示表示获取更泛化的知识，并采用 margin-based contrastive learning 关注难样本，从而便于适应旧和新类别。论文还引入 memory augmentation 策略，使用精心设计的提示引导 ChatGPT 生成多样样本，以缓解低资源场景下的过拟合。实验结果显示，该方法大幅度优于现有最先进方法，并在低资源环境中显著缓解关键挑战。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted as COLING2024",
      "pdf_url": "http://arxiv.org/pdf/2402.15713v1",
      "published_date": "2024-02-24 04:32:44 UTC",
      "updated_date": "2024-02-24 04:32:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:47:42.187729"
    },
    {
      "arxiv_id": "2402.17783v1",
      "title": "BagStacking: An Integrated Ensemble Learning Approach for Freezing of Gait Detection in Parkinson's Disease",
      "title_zh": "翻译失败",
      "authors": [
        "Seffi Cohen",
        "Lior Rokach"
      ],
      "abstract": "This paper introduces BagStacking, a novel ensemble learning method designed\nto enhance the detection of Freezing of Gait (FOG) in Parkinson's Disease (PD)\nby using a lower-back sensor to track acceleration. Building on the principles\nof bagging and stacking, BagStacking aims to achieve the variance reduction\nbenefit of bagging's bootstrap sampling while also learning sophisticated\nblending through stacking. The method involves training a set of base models on\nbootstrap samples from the training data, followed by a meta-learner trained on\nthe base model outputs and true labels to find an optimal aggregation scheme.\nThe experimental evaluation demonstrates significant improvements over other\nstate-of-the-art machine learning methods on the validation set. Specifically,\nBagStacking achieved a MAP score of 0.306, outperforming LightGBM (0.234) and\nclassic Stacking (0.286). Additionally, the run-time of BagStacking was\nmeasured at 3828 seconds, illustrating an efficient approach compared to\nRegular Stacking's 8350 seconds. BagStacking presents a promising direction for\nhandling the inherent variability in FOG detection data, offering a robust and\nscalable solution to improve patient care in PD.",
      "tldr_zh": "本文提出 BagStacking，一种新型集成 ensemble learning 方法，旨在通过下背部传感器跟踪加速度来提升帕金森病（PD）患者 Freezing of Gait (FOG) 检测的准确性。该方法结合 bagging 的引导采样（bootstrap sampling）减少方差，以及 stacking 的复杂混合学习，通过训练基础模型并使用元学习器优化输出聚合，实现高效的检测框架。实验结果显示，BagStacking 在验证集上取得 MAP 得分为 0.306，显著优于 LightGBM (0.234) 和经典 Stacking (0.286)，且运行时间仅为 3828 秒，比 Regular Stacking 的 8350 秒更高效。作为一个鲁棒且可扩展的解决方案，BagStacking 为处理 FOG 检测数据的固有变异性提供了新方向，从而改善 PD 患者护理。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.17783v1",
      "published_date": "2024-02-24 04:13:48 UTC",
      "updated_date": "2024-02-24 04:13:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:47:55.240590"
    },
    {
      "arxiv_id": "2402.15708v2",
      "title": "Query Augmentation by Decoding Semantics from Brain Signals",
      "title_zh": "翻译失败",
      "authors": [
        "Ziyi Ye",
        "Jingtao Zhan",
        "Qingyao Ai",
        "Yiqun Liu",
        "Maarten de Rijke",
        "Christina Lioma",
        "Tuukka Ruotsalo"
      ],
      "abstract": "Query augmentation is a crucial technique for refining semantically imprecise\nqueries. Traditionally, query augmentation relies on extracting information\nfrom initially retrieved, potentially relevant documents. If the quality of the\ninitially retrieved documents is low, then the effectiveness of query\naugmentation would be limited as well. We propose Brain-Aug, which enhances a\nquery by incorporating semantic information decoded from brain signals.\nBrainAug generates the continuation of the original query with a prompt\nconstructed with brain signal information and a ranking-oriented inference\napproach. Experimental results on fMRI (functional magnetic resonance imaging)\ndatasets show that Brain-Aug produces semantically more accurate queries,\nleading to improved document ranking performance. Such improvement brought by\nbrain signals is particularly notable for ambiguous queries.",
      "tldr_zh": "这篇论文提出了一种名为 Brain-Aug 的查询增强方法，通过从脑信号中解码语义信息来改进传统查询增强的局限性，该方法避免了对初始检索文档的依赖。Brain-Aug 使用脑信号构建提示，并采用排名导向的推理方式生成查询的延续，从而提升查询的语义准确性。在 fMRI 数据集上的实验结果显示，该方法显著提高了文档排名性能，尤其对模糊查询的改进最为突出。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.15708v2",
      "published_date": "2024-02-24 04:08:51 UTC",
      "updated_date": "2024-03-03 09:18:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:48:06.245620"
    },
    {
      "arxiv_id": "2402.16898v2",
      "title": "MIM-Reasoner: Learning with Theoretical Guarantees for Multiplex Influence Maximization",
      "title_zh": "翻译失败",
      "authors": [
        "Nguyen Do",
        "Tanmoy Chowdhury",
        "Chen Ling",
        "Liang Zhao",
        "My T. Thai"
      ],
      "abstract": "Multiplex influence maximization (MIM) asks us to identify a set of seed\nusers such as to maximize the expected number of influenced users in a\nmultiplex network. MIM has been one of central research topics, especially in\nnowadays social networking landscape where users participate in multiple online\nsocial networks (OSNs) and their influences can propagate among several OSNs\nsimultaneously. Although there exist a couple combinatorial algorithms to MIM,\nlearning-based solutions have been desired due to its generalization ability to\nheterogeneous networks and their diversified propagation characteristics. In\nthis paper, we introduce MIM-Reasoner, coupling reinforcement learning with\nprobabilistic graphical model, which effectively captures the complex\npropagation process within and between layers of a given multiplex network,\nthereby tackling the most challenging problem in MIM. We establish a\ntheoretical guarantee for MIM-Reasoner as well as conduct extensive analyses on\nboth synthetic and real-world datasets to validate our MIM-Reasoner's\nperformance.",
      "tldr_zh": "本论文提出 MIM-Reasoner，一种结合 reinforcement learning 和 probabilistic graphical model 的学习方法，用于解决 Multiplex Influence Maximization (MIM) 问题，即在多层网络中选择种子用户以最大化影响传播。MIM-Reasoner 能够有效捕捉网络层内及层间的复杂传播过程，并提供理论保证以确保其泛化能力。实验结果显示，该方法在合成和真实数据集上表现出色，优于传统组合算法。",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.LG",
        "math.PR",
        "stat.ML"
      ],
      "primary_category": "cs.SI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.16898v2",
      "published_date": "2024-02-24 03:48:22 UTC",
      "updated_date": "2024-03-10 07:35:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:48:18.242725"
    },
    {
      "arxiv_id": "2402.16897v2",
      "title": "Reliable Conflictive Multi-View Learning",
      "title_zh": "可靠的冲突多视图学习",
      "authors": [
        "Cai Xu",
        "Jiajun Si",
        "Ziyu Guan",
        "Wei Zhao",
        "Yue Wu",
        "Xiyue Gao"
      ],
      "abstract": "Multi-view learning aims to combine multiple features to achieve more\ncomprehensive descriptions of data. Most previous works assume that multiple\nviews are strictly aligned. However, real-world multi-view data may contain\nlow-quality conflictive instances, which show conflictive information in\ndifferent views. Previous methods for this problem mainly focus on eliminating\nthe conflictive data instances by removing them or replacing conflictive views.\nNevertheless, real-world applications usually require making decisions for\nconflictive instances rather than only eliminating them. To solve this, we\npoint out a new Reliable Conflictive Multi-view Learning (RCML) problem, which\nrequires the model to provide decision results and attached reliabilities for\nconflictive multi-view data. We develop an Evidential Conflictive Multi-view\nLearning (ECML) method for this problem. ECML first learns view-specific\nevidence, which could be termed as the amount of support to each category\ncollected from data. Then, we can construct view-specific opinions consisting\nof decision results and reliability. In the multi-view fusion stage, we propose\na conflictive opinion aggregation strategy and theoretically prove this\nstrategy can exactly model the relation of multi-view common and view-specific\nreliabilities. Experiments performed on 6 datasets verify the effectiveness of\nECML.",
      "tldr_zh": "该论文提出 Reliable Conflictive Multi-View Learning (RCML) 问题，旨在处理多视图学习中存在冲突性实例（conflictive instances）的挑战，这些实例在不同视图中显示冲突信息，而非简单删除或替换。作者开发了 Evidential Conflictive Multi-View Learning (ECML) 方法，该方法首先学习视图特定的证据（view-specific evidence），并构建包含决策结果和可靠性的视图特定意见（opinions）。在多视图融合阶段，ECML 采用冲突意见聚合策略（conflictive opinion aggregation strategy），并理论证明其能精确建模多视图的共同和特定可靠性；实验在 6 个数据集上验证了该方法的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages and to be appeared in AAAI2024",
      "pdf_url": "http://arxiv.org/pdf/2402.16897v2",
      "published_date": "2024-02-24 03:47:06 UTC",
      "updated_date": "2024-02-28 09:58:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:48:30.126554"
    },
    {
      "arxiv_id": "2402.15703v1",
      "title": "Is Offline Decision Making Possible with Only Few Samples? Reliable Decisions in Data-Starved Bandits via Trust Region Enhancement",
      "title_zh": "翻译失败",
      "authors": [
        "Ruiqi Zhang",
        "Yuexiang Zhai",
        "Andrea Zanette"
      ],
      "abstract": "What can an agent learn in a stochastic Multi-Armed Bandit (MAB) problem from\na dataset that contains just a single sample for each arm? Surprisingly, in\nthis work, we demonstrate that even in such a data-starved setting it may still\nbe possible to find a policy competitive with the optimal one. This paves the\nway to reliable decision-making in settings where critical decisions must be\nmade by relying only on a handful of samples.\n  Our analysis reveals that \\emph{stochastic policies can be substantially\nbetter} than deterministic ones for offline decision-making. Focusing on\noffline multi-armed bandits, we design an algorithm called Trust Region of\nUncertainty for Stochastic policy enhancemenT (TRUST) which is quite different\nfrom the predominant value-based lower confidence bound approach. Its design is\nenabled by localization laws, critical radii, and relative pessimism. We prove\nthat its sample complexity is comparable to that of LCB on minimax problems\nwhile being substantially lower on problems with very few samples.\n  Finally, we consider an application to offline reinforcement learning in the\nspecial case where the logging policies are known.",
      "tldr_zh": "本研究探讨了在数据匮乏的多臂赌博机（Multi-Armed Bandit, MAB）环境中，仅使用每个臂少数样本（如单个样本）是否能实现可靠的离线决策，发现随机策略（stochastic policies）比确定性策略更具优势。论文提出了一种名为 TRUST（Trust Region of Uncertainty for Stochastic policy enhancemenT）的算法，利用信任区域、本地化定律和相对悲观主义来优化策略设计，使其样本复杂度与传统下界置信区间（LCB）方法相当，但在极少样本问题上显著降低。实验结果表明，TRUST 算法为数据匮乏场景下的离线决策铺平了道路，并扩展到已知日志策略的离线强化学习（offline reinforcement learning）应用中。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "22 pages",
      "pdf_url": "http://arxiv.org/pdf/2402.15703v1",
      "published_date": "2024-02-24 03:41:09 UTC",
      "updated_date": "2024-02-24 03:41:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:48:42.095079"
    },
    {
      "arxiv_id": "2402.15700v1",
      "title": "CoRelation: Boosting Automatic ICD Coding Through Contextualized Code Relation Learning",
      "title_zh": "CoRelation：通过语境化代码关系学习提升自动 ICD 编码",
      "authors": [
        "Junyu Luo",
        "Xiaochen Wang",
        "Jiaqi Wang",
        "Aofei Chang",
        "Yaqing Wang",
        "Fenglong Ma"
      ],
      "abstract": "Automatic International Classification of Diseases (ICD) coding plays a\ncrucial role in the extraction of relevant information from clinical notes for\nproper recording and billing. One of the most important directions for boosting\nthe performance of automatic ICD coding is modeling ICD code relations.\nHowever, current methods insufficiently model the intricate relationships among\nICD codes and often overlook the importance of context in clinical notes. In\nthis paper, we propose a novel approach, a contextualized and flexible\nframework, to enhance the learning of ICD code representations. Our approach,\nunlike existing methods, employs a dependent learning paradigm that considers\nthe context of clinical notes in modeling all possible code relations. We\nevaluate our approach on six public ICD coding datasets and the experimental\nresults demonstrate the effectiveness of our approach compared to\nstate-of-the-art baselines.",
      "tldr_zh": "本研究针对自动 ICD 编码的挑战，提出了一种名为 CoRelation 的上下文化框架，通过学习 ICD 代码间的复杂关系来提升编码性能。不同于现有方法，该框架采用依赖学习范式，充分利用临床笔记的上下文来建模所有可能的代码关系，从而更好地表示和关联 ICD 代码。在六个公开数据集上的实验结果显示，CoRelation 比最先进基线方法表现出色，证明了其在提高自动 ICD 编码准确性和效率方面的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "LREC-Coling 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.15700v1",
      "published_date": "2024-02-24 03:25:28 UTC",
      "updated_date": "2024-02-24 03:25:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:48:52.493845"
    },
    {
      "arxiv_id": "2402.15690v1",
      "title": "Foot In The Door: Understanding Large Language Model Jailbreaking via Cognitive Psychology",
      "title_zh": "Foot In The Door：通过认知心理学理解",
      "authors": [
        "Zhenhua Wang",
        "Wei Xie",
        "Baosheng Wang",
        "Enze Wang",
        "Zhiwen Gui",
        "Shuoyoucheng Ma",
        "Kai Chen"
      ],
      "abstract": "Large Language Models (LLMs) have gradually become the gateway for people to\nacquire new knowledge. However, attackers can break the model's security\nprotection (\"jail\") to access restricted information, which is called\n\"jailbreaking.\" Previous studies have shown the weakness of current LLMs when\nconfronted with such jailbreaking attacks. Nevertheless, comprehension of the\nintrinsic decision-making mechanism within the LLMs upon receipt of jailbreak\nprompts is noticeably lacking. Our research provides a psychological\nexplanation of the jailbreak prompts. Drawing on cognitive consistency theory,\nwe argue that the key to jailbreak is guiding the LLM to achieve cognitive\ncoordination in an erroneous direction. Further, we propose an automatic\nblack-box jailbreaking method based on the Foot-in-the-Door (FITD) technique.\nThis method progressively induces the model to answer harmful questions via\nmulti-step incremental prompts. We instantiated a prototype system to evaluate\nthe jailbreaking effectiveness on 8 advanced LLMs, yielding an average success\nrate of 83.9%. This study builds a psychological perspective on the explanatory\ninsights into the intrinsic decision-making logic of LLMs.",
      "tldr_zh": "本文从认知心理学角度分析大型语言模型(LLMs)的jailbreaking机制，基于认知一致性理论指出，jailbreaking的关键在于引导模型在错误方向上实现认知协调。研究提出了一种自动黑盒攻击方法，利用Foot-in-the-Door(FITD)技术，通过多步渐进提示逐步诱导模型回答有害问题。在8个高级LLMs上进行评估，该方法平均成功率达83.9%，为揭示LLMs内在决策逻辑提供了新的解释性洞见。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.15690v1",
      "published_date": "2024-02-24 02:27:55 UTC",
      "updated_date": "2024-02-24 02:27:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:49:05.850981"
    },
    {
      "arxiv_id": "2402.15687v1",
      "title": "General Purpose Image Encoder DINOv2 for Medical Image Registration",
      "title_zh": "翻译失败",
      "authors": [
        "Xinrui Song",
        "Xuanang Xu",
        "Pingkun Yan"
      ],
      "abstract": "Existing medical image registration algorithms rely on either dataset\nspecific training or local texture-based features to align images. The former\ncannot be reliably implemented without large modality-specific training\ndatasets, while the latter lacks global semantics thus could be easily trapped\nat local minima. In this paper, we present a training-free deformable image\nregistration method, DINO-Reg, leveraging a general purpose image encoder\nDINOv2 for image feature extraction. The DINOv2 encoder was trained using the\nImageNet data containing natural images. We used the pretrained DINOv2 without\nany finetuning. Our method feeds the DINOv2 encoded features into a discrete\noptimizer to find the optimal deformable registration field. We conducted a\nseries of experiments to understand the behavior and role of such a general\npurpose image encoder in the application of image registration. Combined with\nhandcrafted features, our method won the first place in the recent OncoReg\nChallenge. To our knowledge, this is the first application of general vision\nfoundation models in medical image registration.",
      "tldr_zh": "本研究针对现有医疗图像配准算法的局限性——依赖特定数据集训练或局部纹理特征容易陷入局部最小值——提出了一种无训练的变形图像配准方法DINO-Reg。方法利用通用图像编码器DINOv2（基于ImageNet数据预训练，无需微调）提取图像特征，然后通过离散优化器求解最优变形配准场。实验结果显示，该方法在图像配准任务中表现出色，结合手工特征后在OncoReg挑战赛中获得第一名，这是首次将通用视觉基础模型应用于医疗图像配准领域。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.15687v1",
      "published_date": "2024-02-24 02:15:30 UTC",
      "updated_date": "2024-02-24 02:15:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:49:18.129004"
    },
    {
      "arxiv_id": "2402.15670v1",
      "title": "A mathematical model for simultaneous personnel shift planning and unrelated parallel machine scheduling",
      "title_zh": "翻译失败",
      "authors": [
        "Maziyar Khadivi",
        "Mostafa Abbasi",
        "Todd Charter",
        "Homayoun Najjaran"
      ],
      "abstract": "This paper addresses a production scheduling problem derived from an\nindustrial use case, focusing on unrelated parallel machine scheduling with the\npersonnel availability constraint. The proposed model optimizes the production\nplan over a multi-period scheduling horizon, accommodating variations in\npersonnel shift hours within each time period. It assumes shared personnel\namong machines, with one personnel required per machine for setup and\nsupervision during job processing. Available personnel are fewer than the\nmachines, thus limiting the number of machines that can operate in parallel.\nThe model aims to minimize the total production time considering\nmachine-dependent processing times and sequence-dependent setup times. The\nmodel handles practical scenarios like machine eligibility constraints and\nproduction time windows. A Mixed Integer Linear Programming (MILP) model is\nintroduced to formulate the problem, taking into account both continuous and\ndistrict variables. A two-step solution approach enhances computational speed,\nfirst maximizing accepted jobs and then minimizing production time. Validation\nwith synthetic problem instances and a real industrial case study of a food\nprocessing plant demonstrates the performance of the model and its usefulness\nin personnel shift planning. The findings offer valuable insights for practical\nmanagerial decision-making in the context of production scheduling.",
      "tldr_zh": "这篇论文提出一个数学模型，用于同时优化人员班次规划和非相关平行机器调度问题，旨在处理生产环境中人员可用性约束的影响。模型采用混合整数线性规划 (MILP) 框架，考虑机器相关的处理时间、序列相关的设置时间以及实际场景如机器资格约束和生产时间窗口，以最小化总生产时间。针对可用人员少于机器的情况，该模型通过两步解决方案先最大化接受的任务，然后最小化生产时间，从而提升调度效率。在合成实例和真实食品加工厂案例中验证后，证明了该模型在实际管理决策中的实用性和性能提升。",
      "categories": [
        "cs.AI",
        "cs.DM"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.15670v1",
      "published_date": "2024-02-24 01:04:04 UTC",
      "updated_date": "2024-02-24 01:04:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:49:30.305099"
    },
    {
      "arxiv_id": "2402.15666v1",
      "title": "Universal Model in Online Customer Service",
      "title_zh": "在线客户服务中的通用模型",
      "authors": [
        "Shu-Ting Pi",
        "Cheng-Ping Hsieh",
        "Qun Liu",
        "Yuying Zhu"
      ],
      "abstract": "Building machine learning models can be a time-consuming process that often\ntakes several months to implement in typical business scenarios. To ensure\nconsistent model performance and account for variations in data distribution,\nregular retraining is necessary. This paper introduces a solution for improving\nonline customer service in e-commerce by presenting a universal model for\npredict-ing labels based on customer questions, without requiring training. Our\nnovel approach involves using machine learning techniques to tag customer\nquestions in transcripts and create a repository of questions and corresponding\nlabels. When a customer requests assistance, an information retrieval model\nsearches the repository for similar questions, and statistical analysis is used\nto predict the corresponding label. By eliminating the need for individual\nmodel training and maintenance, our approach reduces both the model development\ncycle and costs. The repository only requires periodic updating to maintain\naccuracy.",
      "tldr_zh": "本论文针对机器学习模型的构建耗时和定期训练需求，提出了一种无需训练的通用模型，用于在线客服中基于客户问题预测标签。该方法通过机器学习技术标记客户问题并构建一个问题标签仓库，当新问题出现时，使用信息检索模型搜索相似问题并通过统计分析预测相应标签。这种创新方式显著减少了模型开发周期和成本，仅需定期更新仓库即可维持准确性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.15666v1",
      "published_date": "2024-02-24 00:41:16 UTC",
      "updated_date": "2024-02-24 00:41:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:49:42.424663"
    },
    {
      "arxiv_id": "2402.15665v1",
      "title": "Teacher-Student Learning on Complexity in Intelligent Routing",
      "title_zh": "翻译失败",
      "authors": [
        "Shu-Ting Pi",
        "Michael Yang",
        "Yuying Zhu",
        "Qun Liu"
      ],
      "abstract": "Customer service is often the most time-consuming aspect for e-commerce\nwebsites, with each contact typically taking 10-15 minutes. Effectively routing\ncustomers to appropriate agents without transfers is therefore crucial for\ne-commerce success. To this end, we have developed a machine learning framework\nthat predicts the complexity of customer contacts and routes them to\nappropriate agents accordingly. The framework consists of two parts. First, we\ntrain a teacher model to score the complexity of a contact based on the\npost-contact transcripts. Then, we use the teacher model as a data annotator to\nprovide labels to train a student model that predicts the complexity based on\npre-contact data only. Our experiments show that such a framework is successful\nand can significantly improve customer experience. We also propose a useful\nmetric called complexity AUC that evaluates the effectiveness of customer\nservice at a statistical level.",
      "tldr_zh": "本研究针对电商客户服务中的路由问题，提出了一种基于 Teacher-Student Learning 的机器学习框架，用于预测客户联系的复杂性并智能路由。该框架首先训练一个教师模型，通过分析联系后的 transcripts 来评分复杂性；随后，使用教师模型标注数据来训练学生模型，使其基于联系前的预置数据（pre-contact data）进行预测。实验结果显示，该框架显著提升了客户体验，减少了路由转移；此外，研究还引入了 complexity AUC 指标，用于统计评估客户服务有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "KDD 2023 Workshop on End-End Customer Journey Optimization",
      "pdf_url": "http://arxiv.org/pdf/2402.15665v1",
      "published_date": "2024-02-24 00:40:40 UTC",
      "updated_date": "2024-02-24 00:40:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:49:53.239229"
    },
    {
      "arxiv_id": "2402.15662v1",
      "title": "GiMeFive: Towards Interpretable Facial Emotion Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Jiawen Wang",
        "Leah Kawka"
      ],
      "abstract": "Deep convolutional neural networks have been shown to successfully recognize\nfacial emotions for the past years in the realm of computer vision. However,\nthe existing detection approaches are not always reliable or explainable, we\nhere propose our model GiMeFive with interpretations, i.e., via layer\nactivations and gradient-weighted class activation mapping. We compare against\nthe state-of-the-art methods to classify the six facial emotions. Empirical\nresults show that our model outperforms the previous methods in terms of\naccuracy on two Facial Emotion Recognition (FER) benchmarks and our aggregated\nFER GiMeFive. Furthermore, we explain our work in real-world image and video\nexamples, as well as real-time live camera streams. Our code and supplementary\nmaterial are available at https: //github.com/werywjw/SEP-CVDL.",
      "tldr_zh": "本研究针对面部情绪分类中的不可靠性和解释性不足问题，提出GiMeFive模型，通过层激活和gradient-weighted class activation mapping来提供可解释性。该模型在分类六种面部情绪时，与最先进方法相比，在两个Facial Emotion Recognition (FER)基准和聚合FER GiMeFive上实现了更高的准确率。实验结果显示，GiMeFive在真实世界图像、视频以及实时摄像头流中表现出色，并提供了开源代码以支持进一步应用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "9 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.15662v1",
      "published_date": "2024-02-24 00:37:37 UTC",
      "updated_date": "2024-02-24 00:37:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:50:06.254603"
    },
    {
      "arxiv_id": "2403.00804v1",
      "title": "Uncovering Customer Issues through Topological Natural Language Analysis",
      "title_zh": "通过拓扑自然语言分析揭示客户问题",
      "authors": [
        "Shu-Ting Pi",
        "Sidarth Srinivasan",
        "Yuying Zhu",
        "Michael Yang",
        "Qun Liu"
      ],
      "abstract": "E-commerce companies deal with a high volume of customer service requests\ndaily. While a simple annotation system is often used to summarize the topics\nof customer contacts, thoroughly exploring each specific issue can be\nchallenging. This presents a critical concern, especially during an emerging\noutbreak where companies must quickly identify and address specific issues. To\ntackle this challenge, we propose a novel machine learning algorithm that\nleverages natural language techniques and topological data analysis to monitor\nemerging and trending customer issues. Our approach involves an end-to-end deep\nlearning framework that simultaneously tags the primary question sentence of\neach customer's transcript and generates sentence embedding vectors. We then\nwhiten the embedding vectors and use them to construct an undirected graph.\nFrom there, we define trending and emerging issues based on the topological\nproperties of each transcript. We have validated our results through various\nmethods and found that they are highly consistent with news sources.",
      "tldr_zh": "本研究针对电子商务公司处理海量客户服务请求的挑战，提出了一种新型机器学习算法，利用 natural language techniques 和 topological data analysis 来识别新兴和趋势客户问题。算法采用端到端的 deep learning framework，对客户记录的主要问题句子进行标记并生成 sentence embedding vectors，然后白化这些向量并构建 undirected graph，通过图的拓扑属性定义问题趋势。实验验证显示，该方法的结果与新闻来源高度一致，有效提升了问题监控的准确性和实时性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted in KDD 2023 Workshop on Decision Intelligence and Analytics\n  for Online Marketplaces",
      "pdf_url": "http://arxiv.org/pdf/2403.00804v1",
      "published_date": "2024-02-24 00:15:09 UTC",
      "updated_date": "2024-02-24 00:15:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:50:19.024136"
    },
    {
      "arxiv_id": "2402.15656v2",
      "title": "Learning Semilinear Neural Operators : A Unified Recursive Framework For Prediction And Data Assimilation",
      "title_zh": "学习半线性神经算子：一个用于预测和数据同化的",
      "authors": [
        "Ashutosh Singh",
        "Ricardo Augusto Borsoi",
        "Deniz Erdogmus",
        "Tales Imbiriba"
      ],
      "abstract": "Recent advances in the theory of Neural Operators (NOs) have enabled fast and\naccurate computation of the solutions to complex systems described by partial\ndifferential equations (PDEs). Despite their great success, current NO-based\nsolutions face important challenges when dealing with spatio-temporal PDEs over\nlong time scales. Specifically, the current theory of NOs does not present a\nsystematic framework to perform data assimilation and efficiently correct the\nevolution of PDE solutions over time based on sparsely sampled noisy\nmeasurements. In this paper, we propose a learning-based state-space approach\nto compute the solution operators to infinite-dimensional semilinear PDEs.\nExploiting the structure of semilinear PDEs and the theory of nonlinear\nobservers in function spaces, we develop a flexible recursive method that\nallows for both prediction and data assimilation by combining prediction and\ncorrection operations. The proposed framework is capable of producing fast and\naccurate predictions over long time horizons, dealing with irregularly sampled\nnoisy measurements to correct the solution, and benefits from the decoupling\nbetween the spatial and temporal dynamics of this class of PDEs. We show\nthrough experiments on the Kuramoto-Sivashinsky, Navier-Stokes and Korteweg-de\nVries equations that the proposed model is robust to noise and can leverage\narbitrary amounts of measurements to correct its prediction over a long time\nhorizon with little computational overhead.",
      "tldr_zh": "本论文提出了一种基于学习的state-space框架，用于计算无限维半线性PDEs（偏微分方程）的解算子，该框架统一支持预测和data assimilation，通过结合预测和修正操作来处理长期时空动态。利用半线性PDEs的结构以及非线性观察者理论，该方法实现了空间和时间动态的解耦，并能处理不规则采样噪声测量，提供快速准确的长期预测。实验结果显示，在Kuramoto-Sivashinsky、Navier-Stokes和Korteweg-de Vries方程上，该模型对噪声具有鲁棒性，并能利用任意量的测量以低计算开销修正预测。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NA",
        "math.NA"
      ],
      "primary_category": "cs.LG",
      "comment": "ICLR 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.15656v2",
      "published_date": "2024-02-24 00:10:51 UTC",
      "updated_date": "2024-03-15 06:47:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:50:31.516035"
    },
    {
      "arxiv_id": "2402.15655v1",
      "title": "Contact Complexity in Customer Service",
      "title_zh": "客户服务中的联系复杂性",
      "authors": [
        "Shu-Ting Pi",
        "Michael Yang",
        "Qun Liu"
      ],
      "abstract": "Customers who reach out for customer service support may face a range of\nissues that vary in complexity. Routing high-complexity contacts to junior\nagents can lead to multiple transfers or repeated contacts, while directing\nlow-complexity contacts to senior agents can strain their capacity to assist\ncustomers who need professional help. To tackle this, a machine learning model\nthat accurately predicts the complexity of customer issues is highly desirable.\nHowever, defining the complexity of a contact is a difficult task as it is a\nhighly abstract concept. While consensus-based data annotation by experienced\nagents is a possible solution, it is time-consuming and costly. To overcome\nthese challenges, we have developed a novel machine learning approach to define\ncontact complexity. Instead of relying on human annotation, we trained an AI\nexpert model to mimic the behavior of agents and evaluate each contact's\ncomplexity based on how the AI expert responds. If the AI expert is uncertain\nor lacks the skills to comprehend the contact transcript, it is considered a\nhigh-complexity contact. Our method has proven to be reliable, scalable, and\ncost-effective based on the collected data.",
      "tldr_zh": "本研究探讨了客户服务中联系复杂度的挑战，高复杂度联系分配给初级代理可能导致多次转移或重复联系，而低复杂度联系分配给高级代理则会浪费资源，因此需要一个准确预测复杂度的机器学习模型。研究提出了一种新颖方法，通过训练一个AI expert model来模仿代理行为，根据模型对联系转录的响应评估复杂度——如果模型不确定或无法理解，则视为高复杂度联系，从而避免了耗时且昂贵的共识-based数据标注过程。该方法基于收集的数据证明了其可靠性、可扩展性和成本效益，为优化客户服务路由提供了可行的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted in KDD 2023 Workshop on Decision Intelligence and Analytics\n  for Online Marketplaces",
      "pdf_url": "http://arxiv.org/pdf/2402.15655v1",
      "published_date": "2024-02-24 00:09:27 UTC",
      "updated_date": "2024-02-24 00:09:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:50:42.190720"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 56,
  "processed_papers_count": 56,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-17T09:51:10.158124"
}