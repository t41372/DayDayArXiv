{
  "date": "2024-11-03",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-11-03 的 arXiv 中文 TLDR 快报！今天 arXiv 的论文主要聚焦于 AI 和机器学习的创新应用，包括大型语言模型（LLM）的优化、安全防护和强化学习策略，以及机器人路径规划和医疗图像处理等领域的进展。重点包括 UniGuard 在多模态 LLM 安全方面的突破，以及 SkyServe 在 AI 服务效率上的提升；令人印象深刻的文章有著名学者如 Hang Ma 和 Yunhao Yang 参与的机器人和多代理系统研究，而 LLM 相关论文则探讨了实际部署中的挑战和改进。\n\n下面，我将挑选并简要讨论今天更重要的论文，先优先聊 AI、LLM 和机器人领域的高影响力文章，再快速掠过医疗和其它主题的相关论文。每个条目会列出论文标题（中文 + 英文），并用简洁语言描述核心贡献和发现。\n\n### AI 和 LLM 优化\n- **UniGuard: Towards Universal Safety Guardrails for Jailbreak Attacks on Multimodal Large Language Models**（中文：UniGuard：针对多模态大型语言模型越狱攻击的通用安全防护）  \n  这篇论文提出 UniGuard，一种多模态安全框架，能检测并减少 LLM 在图像-文本任务中的有害响应。通过联合考虑单模态和跨模态信号，UniGuard 在 LLaVA 和 GPT-4o 等模型上提升了鲁棒性，同时保持视觉-语言理解能力，是 LLM 安全领域的重要进展。\n\n- **Graph-based Confidence Calibration for Large Language Models**（中文：基于图形的置信度校准用于大型语言模型）  \n  作者包括 Lifu Huang，该论文引入图神经网络来校准 LLM 的响应正确性概率，使用自一致性和标记数据训练辅助模型，在多个基准数据集上显著超越现有方法，提高了 LLM 在不确定环境下的可靠性。\n\n- **SkyServe: Serving AI Models across Regions and Clouds with Spot Instances**（中文：SkyServe：使用 Spot 实例跨区域和云端服务 AI 模型）  \n  这篇论文开发了 SkyServe 系统，利用 Spot 实例优化 AI 模型服务，实现了成本降低 43% 和延迟改善。通过智能资源分配和容错机制，它在实际工作负载中表现出色，是 AI 部署效率的创新范例。\n\n- **EcoAct: Economic Agent Determines When to Register What Action**（中文：EcoAct：经济代理决定何时注册何种动作）  \n  作者包括 Chi Wang，该研究提出 EcoAct 算法，让 LLM 代理动态选择工具注册，减少上下文冗余并降低计算成本 50%，适用于多步骤推理任务，提升了 LLM 代理的实用性。\n\n- **Rate, Explain and Cite (REC): Enhanced Explanation and Attribution in Automatic Evaluation by Large Language Models**（中文：Rate, Explain and Cite (REC)：提升大型语言模型自动评估的解释和归因）  \n  这篇论文细调了 LLM 评估模型（如 REC-70B），使其能提供评分、解释和可验证引用，在 faithfulness 和 coherence 等指标上超越基准，强调了 LLM 评估的透明度和可信度。\n\n- **A Deep Dive Into Large Language Model Code Generation Mistakes: What and Why?**（中文：深入探讨大型语言模型代码生成错误：是什么和为什么）  \n  该论文分析了 LLM 在代码生成中的非语法错误，识别出七类问题（如函数签名误导），并探讨了原因，还评估了 LLM 在检测这些错误时的表现，提供改进代码生成可靠性的实用洞见。\n\n### 机器人和多代理系统\n- **Large-Scale Multi-Robot Coverage Path Planning on Grids with Path Deconfliction**（中文：网格上大规模多机器人覆盖路径规划及其路径去冲突）  \n  作者包括 Hang Ma，这篇论文引入 Extended-STC 和 LS-MCPP 框架，直接在网格上优化多机器人路径，支持部分阻塞环境，并整合 Multi-Agent Path Finding 技术。在 256x256 网格上处理 100 个机器人，显著提升效率和实际可行性，是机器人协调领域的关键贡献。\n\n- **Guiding Genetic Programming with Graph Neural Networks**（中文：使用图神经网络指导遗传编程）  \n  该研究提出 EvoNUDGE 方法，利用图神经网络从符号回归问题中提取子程序，优化遗传编程的初始种群和操作器，在多个基准上超越传统方法，提高了进化计算的探索效率。\n\n- **Know Where You're Uncertain When Planning with Multimodal Foundation Models: A Formal Framework**（中文：多模态基础模型规划中的不确定性定位：一个形式框架）  \n  作者包括 Yunhao Yang，这篇论文框架化处理多模态模型中的感知和决策不确定性，使用 Conformal Prediction 和 Formal-Methods-Driven Prediction 量化不确定性，并在机器人任务中提升成功率 5%，为鲁棒规划提供理论保障。\n\n### 医疗和生物应用\n- **A Multi-Modal Unsupervised Machine Learning Approach for Biomedical Signal Processing in CPR**（中文：用于 CPR 生物医学信号处理的多种模态无监督机器学习方法）  \n  这篇论文提出一种无监督框架处理 CPR 信号噪声，提高信号保真度和相关性（相关系数 0.9993），在 SNR 和 PSNR 上优于现有方法，支持实时医疗决策。\n\n- **Machine Learning Innovations in CPR: A Comprehensive Survey on Enhanced Resuscitation Techniques**（中文：CPR 中的机器学习创新：增强复苏技术的全面调查）  \n  该调查综述了 ML 在 CPR 中的应用，从预测建模到实时分析，分类了挑战和未来方向，是医疗 AI 领域的系统性回顾。\n\n其他论文，如一些特定工具或小规模应用的（如 Ontology Population using LLMs 或 FilterNet），虽然涉及机器学习创新，但相对次要，我这里快速掠过：它们主要贡献于特定子领域，如时间序列预测或知识图构建，但未有重大突破，故不展开讨论。\n\n总之，今天的 arXiv 论文突显了 AI 领域的快速迭代，尤其在 LLM 安全和效率优化上，值得跟踪。明天的快报将继续关注这些动态！",
  "papers": [
    {
      "arxiv_id": "2411.01707v1",
      "title": "Large-Scale Multi-Robot Coverage Path Planning on Grids with Path Deconfliction",
      "title_zh": "翻译失败",
      "authors": [
        "Jingtao Tang",
        "Zining Mao",
        "Hang Ma"
      ],
      "abstract": "We study Multi-Robot Coverage Path Planning (MCPP) on a 4-neighbor 2D grid G,\nwhich aims to compute paths for multiple robots to cover all cells of G.\nTraditional approaches are limited as they first compute coverage trees on a\nquadrant coarsened grid H and then employ the Spanning Tree Coverage (STC)\nparadigm to generate paths on G, making them inapplicable to grids with\npartially obstructed 2x2 blocks. To address this limitation, we reformulate the\nproblem directly on G, revolutionizing grid-based MCPP solving and establishing\nnew NP-hardness results. We introduce Extended-STC (ESTC), a novel paradigm\nthat extends STC to ensure complete coverage with bounded suboptimality, even\nwhen H includes partially obstructed blocks. Furthermore, we present LS-MCPP, a\nnew algorithmic framework that integrates ESTC with three novel types of\nneighborhood operators within a local search strategy to optimize coverage\npaths directly on G. Unlike prior grid-based MCPP work, our approach also\nincorporates a versatile post-processing procedure that applies Multi-Agent\nPath Finding (MAPF) techniques to MCPP for the first time, enabling a fusion of\nthese two important fields in multi-robot coordination. This procedure\neffectively resolves inter-robot conflicts and accommodates turning costs by\nsolving a MAPF variant, making our MCPP solutions more practical for real-world\napplications. Extensive experiments demonstrate that our approach significantly\nimproves solution quality and efficiency, managing up to 100 robots on grids as\nlarge as 256x256 within minutes of runtime. Validation with physical robots\nconfirms the feasibility of our solutions under real-world conditions.",
      "tldr_zh": "本文研究大规模多机器人覆盖路径规划 (MCPP) 在 4-邻居 2D 网格上的问题，解决了传统方法的局限性，如无法处理部分阻塞的 2x2 块，并证明了该问题的 NP-hardness。作者提出 Extended-STC (ESTC) 范式和 LS-MCPP 算法框架，结合新型邻域操作符和局部搜索策略来优化覆盖路径，并首次将 Multi-Agent Path Finding (MAPF) 技术应用于后处理，以解决机器人间冲突并考虑转向成本。实验结果显示，该方法在高达 256x256 的网格上支持多达 100 个机器人，显著提升了解决方案的质量和效率，并在物理机器人验证中证明了其实际可行性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Submitted to T-RO",
      "pdf_url": "http://arxiv.org/pdf/2411.01707v1",
      "published_date": "2024-11-03 22:37:56 UTC",
      "updated_date": "2024-11-03 22:37:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:36:09.747039"
    },
    {
      "arxiv_id": "2411.01703v2",
      "title": "UniGuard: Towards Universal Safety Guardrails for Jailbreak Attacks on Multimodal Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Sejoon Oh",
        "Yiqiao Jin",
        "Megha Sharma",
        "Donghyun Kim",
        "Eric Ma",
        "Gaurav Verma",
        "Srijan Kumar"
      ],
      "abstract": "Multimodal large language models (MLLMs) have revolutionized vision-language\nunderstanding but remain vulnerable to multimodal jailbreak attacks, where\nadversarial inputs are meticulously crafted to elicit harmful or inappropriate\nresponses. We propose UniGuard, a novel multimodal safety guardrail that\njointly considers the unimodal and cross-modal harmful signals. UniGuard trains\na multimodal guardrail to minimize the likelihood of generating harmful\nresponses in a toxic corpus. The guardrail can be seamlessly applied to any\ninput prompt during inference with minimal computational costs. Extensive\nexperiments demonstrate the generalizability of UniGuard across multiple\nmodalities, attack strategies, and multiple state-of-the-art MLLMs, including\nLLaVA, Gemini Pro, GPT-4o, MiniGPT-4, and InstructBLIP. Notably, this robust\ndefense mechanism maintains the models' overall vision-language understanding\ncapabilities.",
      "tldr_zh": "这篇论文针对多模态大语言模型(MLLMs)易受越狱攻击(jailbreak attacks)的问题，提出了UniGuard，一种新型的多模态安全防护机制。UniGuard通过联合考虑单模态(unimodal)和跨模态(cross-modal)有害信号，在有毒语料上训练防护模型，以最小化生成有害响应的可能性，并能在推理过程中无缝应用且计算成本低。实验证明，UniGuard在多种模态、攻击策略和最先进MLLMs（如LLaVA、Gemini Pro、GPT-4o等）上表现出色，同时保持了模型的整体视觉-语言理解能力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "14 pages",
      "pdf_url": "http://arxiv.org/pdf/2411.01703v2",
      "published_date": "2024-11-03 22:19:20 UTC",
      "updated_date": "2025-01-31 16:47:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:34:29.418189"
    },
    {
      "arxiv_id": "2411.01702v1",
      "title": "Symmetry Adapted Residual Neural Network Diabatization: Conical Intersections in Aniline Photodissociation",
      "title_zh": "翻译失败",
      "authors": [
        "Yifan Shen",
        "David Yarkony"
      ],
      "abstract": "We present a symmetry adapted residual neural network (SAResNet)\ndiabatization method to construct quasi-diabatic Hamiltonians that accurately\nrepresent ab initio adiabatic energies, energy gradients, and nonadiabatic\ncouplings for moderate sized systems. Our symmetry adapted neural network\ninherits from the pioneering symmetry adapted polynomial and fundamental\ninvariant neural network diabatization methods to exploit the power of neural\nnetwork along with the transparent symmetry adaptation of polynomial for both\nsymmetric and asymmetric irreducible representations. In addition, our symmetry\nadaptation provides a unified framework for symmetry adapted polynomial and\nsymmetry adapted neural network, enabling the adoption of the residual neural\nnetwork architecture, which is a powerful descendant of the pioneering\nfeedforward neural network. Our SAResNet is applied to construct the full\n36-dimensional coupled diabatic potential energy surfaces for aniline N-H bond\nphotodissociation, with 2,269 data points and 32,640 trainable parameters and\n190 cm-1 root mean square deviation in energy. In addition to the\nexperimentally observed {\\pi}{\\pi}* and {\\pi}Rydberg/{\\pi}{\\sigma}* states, a\nhigher state (HOMO - 1 {\\pi} to Rydberg/{\\sigma}* excitation) is found to\nintroduce an induced geometric phase effect thus indirectly participate in the\nphotodissociation process.",
      "tldr_zh": "我们提出了一种 symmetry adapted residual neural network (SAResNet) 方法，用于构建准-diabatic Hamiltonians，以准确表示 ab initio adiabatic energies、energy gradients 和 nonadiabatic couplings，在中等规模系统中实现对称适应。SAResNet 继承了 symmetry adapted polynomial 和 fundamental invariant neural network 的优势，结合 residual neural network 架构，提供一个统一框架来处理对称和不对称不可约表示。应用于 aniline N-H bond photodissociation，该方法构建了 36-dimensional coupled diabatic potential energy surfaces，使用 2,269 数据点和 32,640 可训练参数，能量 root mean square deviation 为 190 cm-1，并发现一个更高状态引入 induced geometric phase effect，从而间接参与光解离过程。",
      "categories": [
        "physics.chem-ph",
        "cs.AI"
      ],
      "primary_category": "physics.chem-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.01702v1",
      "published_date": "2024-11-03 21:56:25 UTC",
      "updated_date": "2024-11-03 21:56:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:34:41.537854"
    },
    {
      "arxiv_id": "2411.02455v1",
      "title": "An Exploration of Higher Education Course Evaluation by Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Bo Yuan",
        "Jiazi Hu"
      ],
      "abstract": "Course evaluation is a critical component in higher education pedagogy. It\nnot only serves to identify limitations in existing course designs and provide\na basis for curricular innovation, but also to offer quantitative insights for\nuniversity administrative decision-making. Traditional evaluation methods,\nprimarily comprising student surveys, instructor self-assessments, and expert\nreviews, often encounter challenges, including inherent subjectivity, feedback\ndelays, inefficiencies, and limitations in addressing innovative teaching\napproaches. Recent advancements in large language models (LLMs) within\nartificial intelligence (AI) present promising new avenues for enhancing course\nevaluation processes. This study explores the application of LLMs in automated\ncourse evaluation from multiple perspectives and conducts rigorous experiments\nacross 100 courses at a major university in China. The findings indicate that:\n(1) LLMs can be an effective tool for course evaluation; (2) their\neffectiveness is contingent upon appropriate fine-tuning and prompt\nengineering; and (3) LLM-generated evaluation results demonstrate a notable\nlevel of rationality and interpretability.",
      "tldr_zh": "这篇论文探讨了大型语言模型 (LLMs) 在高等教育课程评估中的应用，以解决传统方法（如学生调查和专家审查）的局限性，包括主观性、反馈延迟和效率问题。研究通过在中国一所主要大学的100门课程上进行实验，验证了LLMs的有效性，并强调了适当的微调和提示工程对提升评估质量的关键作用。主要发现是，LLMs生成的评估结果表现出较高的合理性和可解释性，为课程改进和行政决策提供了新工具。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.02455v1",
      "published_date": "2024-11-03 20:43:52 UTC",
      "updated_date": "2024-11-03 20:43:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:34:52.765000"
    },
    {
      "arxiv_id": "2411.05820v1",
      "title": "Guiding Genetic Programming with Graph Neural Networks",
      "title_zh": "通过图神经网络指导遗传编程",
      "authors": [
        "Piotr Wyrwiński",
        "Krzysztof Krawiec"
      ],
      "abstract": "In evolutionary computation, it is commonly assumed that a search algorithm\nacquires knowledge about a problem instance by sampling solutions from the\nsearch space and evaluating them with a fitness function. This is necessarily\ninefficient because fitness reveals very little about solutions -- yet they\ncontain more information that can be potentially exploited. To address this\nobservation in genetic programming, we propose EvoNUDGE, which uses a graph\nneural network to elicit additional knowledge from symbolic regression\nproblems. The network is queried on the problem before an evolutionary run to\nproduce a library of subprograms, which is subsequently used to seed the\ninitial population and bias the actions of search operators. In an extensive\nexperiment on a large number of problem instances, EvoNUDGE is shown to\nsignificantly outperform multiple baselines, including the conventional\ntree-based genetic programming and the purely neural variant of the method.",
      "tldr_zh": "该研究针对遗传编程（Genetic Programming）中依赖适应度评估的低效问题，提出EvoNUDGE框架，使用Graph Neural Networks从符号回归问题中提取额外知识。EvoNUDGE通过查询网络生成子程序库，并将其用于初始化种群和偏置搜索操作符，以提升搜索效率。在大量实验中，该方法显著优于传统树-based Genetic Programming和纯神经变体基线，展示了其在进化计算中的潜力。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG",
        "cs.SC",
        "stat.ML"
      ],
      "primary_category": "cs.NE",
      "comment": "Full version of the same-titled paper accepted at GECCO 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.05820v1",
      "published_date": "2024-11-03 20:43:31 UTC",
      "updated_date": "2024-11-03 20:43:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:35:04.453886"
    },
    {
      "arxiv_id": "2411.02454v1",
      "title": "Graph-based Confidence Calibration for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yukun Li",
        "Sijia Wang",
        "Lifu Huang",
        "Li-Ping Liu"
      ],
      "abstract": "One important approach to improving the reliability of large language models\n(LLMs) is to provide accurate confidence estimations regarding the correctness\nof their answers. However, developing a well-calibrated confidence estimation\nmodel is challenging, as mistakes made by LLMs can be difficult to detect. We\npropose a novel method combining the LLM's self-consistency with labeled data\nand training an auxiliary model to estimate the correctness of its responses to\nquestions. This auxiliary model predicts the correctness of responses based\nsolely on their consistent information. To set up the learning problem, we use\na weighted graph to represent the consistency among the LLM's multiple\nresponses to a question. Correctness labels are assigned to these responses\nbased on their similarity to the correct answer. We then train a graph neural\nnetwork to estimate the probability of correct responses. Experiments\ndemonstrate that the proposed approach substantially outperforms several of the\nmost recent methods in confidence calibration across multiple widely adopted\nbenchmark datasets. Furthermore, the proposed approach significantly improves\nthe generalization capability of confidence calibration on out-of-domain (OOD)\ndata.",
      "tldr_zh": "本论文针对Large Language Models (LLMs) 的置信度校准问题，提出了一种新方法，通过结合LLMs的自一致性(self-consistency)和标记数据，训练辅助模型来估计响应正确性。方法使用加权图(weighted graph)表示LLMs对问题多个响应的一致性，并基于响应与正确答案的相似度分配标签，然后训练图神经网络(Graph Neural Network)预测正确概率。实验结果表明，该方法在多个基准数据集上显著优于最新方法，并在out-of-domain (OOD)数据上提升了泛化能力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.02454v1",
      "published_date": "2024-11-03 20:36:44 UTC",
      "updated_date": "2024-11-03 20:36:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:35:17.338164"
    },
    {
      "arxiv_id": "2411.01663v1",
      "title": "Unlocking the Theory Behind Scaling 1-Bit Neural Networks",
      "title_zh": "揭示缩放1比特神经网络背后的理论",
      "authors": [
        "Majid Daliri",
        "Zhao Song",
        "Chiwun Yang"
      ],
      "abstract": "Recently, 1-bit Large Language Models (LLMs) have emerged, showcasing an\nimpressive combination of efficiency and performance that rivals traditional\nLLMs. Research by Wang et al. (2023); Ma et al. (2024) indicates that the\nperformance of these 1-bit LLMs progressively improves as the number of\nparameters increases, hinting at the potential existence of a Scaling Law for\n1-bit Neural Networks. In this paper, we present the first theoretical result\nthat rigorously establishes this scaling law for 1-bit models. We prove that,\ndespite the constraint of weights restricted to $\\{-1, +1\\}$, the dynamics of\nmodel training inevitably align with kernel behavior as the network width\ngrows. This theoretical breakthrough guarantees convergence of the 1-bit model\nto an arbitrarily small loss as width increases. Furthermore, we introduce the\nconcept of the generalization difference, defined as the gap between the\noutputs of 1-bit networks and their full-precision counterparts, and\ndemonstrate that this difference maintains a negligible level as network width\nscales. Building on the work of Kaplan et al. (2020), we conclude by examining\nhow the training loss scales as a power-law function of the model size, dataset\nsize, and computational resources utilized for training. Our findings\nunderscore the promising potential of scaling 1-bit neural networks, suggesting\nthat int1 could become the standard in future neural network precision.",
      "tldr_zh": "本论文首次理论证明了 1-bit 神经网络的 Scaling Law，尽管权重限制在 {-1, +1}，模型训练动态会随着网络宽度增加而趋向 kernel behavior，并保证损失收敛到任意小值。作者引入了 generalization difference 概念，来量化 1-bit 网络输出与全精度网络输出的差距，并证明此差距在网络宽度扩展时保持可忽略水平。基于 Kaplan et al. (2020) 的工作，论文进一步分析了训练损失如何作为模型大小、数据集大小和计算资源的幂律函数缩放，强调扩展 1-bit 神经网络的潜力，可能使 int1 成为未来神经网络的标准精度。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CC",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.01663v1",
      "published_date": "2024-11-03 19:18:57 UTC",
      "updated_date": "2024-11-03 19:18:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:35:29.787035"
    },
    {
      "arxiv_id": "2411.01661v2",
      "title": "Sing-On-Your-Beat: Simple Text-Controllable Accompaniment Generations",
      "title_zh": "翻译失败",
      "authors": [
        "Quoc-Huy Trinh",
        "Minh-Van Nguyen",
        "Trong-Hieu Nguyen Mau",
        "Khoa Tran",
        "Thanh Do"
      ],
      "abstract": "Singing is one of the most cherished forms of human entertainment. However,\ncreating a beautiful song requires an accompaniment that complements the vocals\nand aligns well with the song instruments and genre. With advancements in deep\nlearning, previous research has focused on generating suitable accompaniments\nbut often lacks precise alignment with the desired instrumentation and genre.\nTo address this, we propose a straightforward method that enables control over\nthe accompaniment through text prompts, allowing the generation of music that\ncomplements the vocals and aligns with the song instrumental and genre\nrequirements. Through extensive experiments, we successfully generate 10-second\naccompaniments using vocal input and text control.",
      "tldr_zh": "本论文提出了一种名为Sing-On-Your-Beat的简单方法，通过text prompts实现对伴奏的文本控制，从而生成与人声、乐器和流派精确对齐的音乐。相比以往研究，该方法解决了伴奏生成中缺乏精确对齐的问题，使音乐创作更灵活高效。通过实验，研究团队成功生成了10秒长度的伴奏，证明了该方法的实用性。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.01661v2",
      "published_date": "2024-11-03 19:17:20 UTC",
      "updated_date": "2024-11-12 22:10:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:35:40.262925"
    },
    {
      "arxiv_id": "2411.03348v2",
      "title": "Undermining Image and Text Classification Algorithms Using Adversarial Attacks",
      "title_zh": "利用对抗攻击破坏图像和文本分类算法",
      "authors": [
        "Langalibalele Lunga",
        "Suhas Sreehari"
      ],
      "abstract": "Machine learning models are prone to adversarial attacks, where inputs can be\nmanipulated in order to cause misclassifications. While previous research has\nfocused on techniques like Generative Adversarial Networks (GANs), there's\nlimited exploration of GANs and Synthetic Minority Oversampling Technique\n(SMOTE) in text and image classification models to perform adversarial attacks.\nOur study addresses this gap by training various machine learning models and\nusing GANs and SMOTE to generate additional data points aimed at attacking text\nclassification models. Furthermore, we extend our investigation to face\nrecognition models, training a Convolutional Neural Network(CNN) and subjecting\nit to adversarial attacks with fast gradient sign perturbations on key features\nidentified by GradCAM, a technique used to highlight key image characteristics\nCNNs use in classification. Our experiments reveal a significant vulnerability\nin classification models. Specifically, we observe a 20 % decrease in accuracy\nfor the top-performing text classification models post-attack, along with a 30\n% decrease in facial recognition accuracy. This highlights the susceptibility\nof these models to manipulation of input data. Adversarial attacks not only\ncompromise the security but also undermine the reliability of machine learning\nsystems. By showcasing the impact of adversarial attacks on both text\nclassification and face recognition models, our study underscores the urgent\nneed for develop robust defenses against such vulnerabilities.",
      "tldr_zh": "本研究探讨了使用对抗攻击（adversarial attacks）破坏图像和文本分类算法的易感性，特别聚焦于 Generative Adversarial Networks (GANs) 和 Synthetic Minority Oversampling Technique (SMOTE) 在生成攻击数据方面的应用。研究者训练了多种机器学习模型，包括文本分类模型和 Convolutional Neural Network (CNN) 面部识别模型，并利用 GradCAM 识别关键特征后施加快速梯度符号扰动（fast gradient sign perturbations），以模拟攻击场景。实验结果显示，顶级文本分类模型的准确率下降了20%，面部识别准确率下降了30%，突显了这些模型在安全性和可靠性方面的脆弱性。该研究强调了开发 robust defenses 的迫切需求，以提升机器学习系统的抗攻击能力。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted for presentation at Electronic Imaging Conference 2025",
      "pdf_url": "http://arxiv.org/pdf/2411.03348v2",
      "published_date": "2024-11-03 18:44:28 UTC",
      "updated_date": "2024-11-07 04:05:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:35:53.605546"
    },
    {
      "arxiv_id": "2411.11869v1",
      "title": "A Multi-Modal Unsupervised Machine Learning Approach for Biomedical Signal Processing in CPR",
      "title_zh": "一种多模态无监督机器学习方法，用于心肺复苏中的生物医学信号处理",
      "authors": [
        "Saidul Islam",
        "Jamal Bentahar",
        "Robin Cohen",
        "Gaith Rjoub"
      ],
      "abstract": "Cardiopulmonary resuscitation (CPR) is a critical, life-saving intervention\naimed at restoring blood circulation and breathing in individuals experiencing\ncardiac arrest or respiratory failure. Accurate and real-time analysis of\nbiomedical signals during CPR is essential for monitoring and decision-making,\nfrom the pre-hospital stage to the intensive care unit (ICU). However, CPR\nsignals are often corrupted by noise and artifacts, making precise\ninterpretation challenging. Traditional denoising methods, such as filters,\nstruggle to adapt to the varying and complex noise patterns present in CPR\nsignals. Given the high-stakes nature of CPR, where rapid and accurate\nresponses can determine survival, there is a pressing need for more robust and\nadaptive denoising techniques. In this context, an unsupervised machine\nlearning (ML) methodology is particularly valuable, as it removes the\ndependence on labeled data, which can be scarce or impractical in emergency\nscenarios. This paper introduces a novel unsupervised ML approach for denoising\nCPR signals using a multi-modality framework, which leverages multiple signal\nsources to enhance the denoising process. The proposed approach not only\nimproves noise reduction and signal fidelity but also preserves critical\ninter-signal correlations (0.9993) which is crucial for downstream tasks.\nFurthermore, it outperforms existing methods in an unsupervised context in\nterms of signal-to-noise ratio (SNR) and peak signal-to-noise ratio (PSNR),\nmaking it highly effective for real-time applications. The integration of\nmulti-modality further enhances the system's adaptability to various biomedical\nsignals beyond CPR, improving both automated CPR systems and clinical\ndecision-making.",
      "tldr_zh": "本研究提出了一种多模态无监督机器学习方法，用于处理心肺复苏（CPR）中的生物医学信号，旨在应对信号噪声和伪影的挑战。 该方法通过整合多个信号来源进行去噪，提高了信号保真度和关键的信号间相关性（correlation: 0.9993），并在信号噪声比（SNR）和峰值信号噪声比（PSNR）上优于现有技术。 这种框架不仅适用于实时CPR决策，还可扩展到其他生物医学信号处理场景，提升自动化系统和临床决策的可靠性。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.11869v1",
      "published_date": "2024-11-03 18:40:25 UTC",
      "updated_date": "2024-11-03 18:40:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:38:04.990945"
    },
    {
      "arxiv_id": "2411.01653v1",
      "title": "Diagnosing Medical Datasets with Training Dynamics",
      "title_zh": "通过训练动态诊断医疗数据集",
      "authors": [
        "Laura Wenderoth"
      ],
      "abstract": "This study explores the potential of using training dynamics as an automated\nalternative to human annotation for evaluating the quality of training data.\nThe framework used is Data Maps, which classifies data points into categories\nsuch as easy-to-learn, hard-to-learn, and ambiguous (Swayamdipta et al., 2020).\nSwayamdipta et al. (2020) highlight that difficult-to-learn examples often\ncontain errors, and ambiguous cases significantly impact model training. To\nconfirm the reliability of these findings, we replicated the experiments using\na challenging dataset, with a focus on medical question answering. In addition\nto text comprehension, this field requires the acquisition of detailed medical\nknowledge, which further complicates the task. A comprehensive evaluation was\nconducted to assess the feasibility and transferability of the Data Maps\nframework to the medical domain. The evaluation indicates that the framework is\nunsuitable for addressing datasets' unique challenges in answering medical\nquestions.",
      "tldr_zh": "本研究探讨了使用 training dynamics 作为自动替代方案来评估训练数据的质量，特别针对医疗数据集。研究采用 Data Maps 框架，将数据点分类为 easy-to-learn、hard-to-learn 和 ambiguous 类型，并基于 Swayamdipta et al. (2020) 的发现，在医疗问答数据集上复制实验。结果显示，该框架无法有效应对医疗领域的独特挑战，如文本理解和详细医疗知识的结合，从而证明其在该领域的适用性有限。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "https://github.com/LauraWenderoth/training-dynamics",
      "pdf_url": "http://arxiv.org/pdf/2411.01653v1",
      "published_date": "2024-11-03 18:37:35 UTC",
      "updated_date": "2024-11-03 18:37:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:38:15.847809"
    },
    {
      "arxiv_id": "2411.01652v1",
      "title": "Optimizing Gastrointestinal Diagnostics: A CNN-Based Model for VCE Image Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Vaneeta Ahlawat",
        "Rohit Sharma",
        "Urush"
      ],
      "abstract": "In recent years, the diagnosis of gastrointestinal (GI) diseases has advanced\ngreatly with the advent of high-tech video capsule endoscopy (VCE) technology,\nwhich allows for non-invasive observation of the digestive system. The MisaHub\nCapsule Vision Challenge encourages the development of vendor-independent\nartificial intelligence models that can autonomously classify GI anomalies from\nVCE images. This paper presents CNN architecture designed specifically for\nmulticlass classification of ten gut pathologies, including angioectasia,\nbleeding, erosion, erythema, foreign bodies, lymphangiectasia, polyps, ulcers,\nand worms as well as their normal state.",
      "tldr_zh": "本研究针对胃肠（GI）疾病诊断，利用视频胶囊内镜（VCE）技术，提出了一种基于CNN的模型，用于多类分类VCE图像。该模型专门设计来识别十种肠道病变，包括angioectasia、bleeding、erosion、erythema、foreign bodies、lymphangiectasia、polyps、ulcers、worms，以及正常状态。作为MisaHub Capsule Vision Challenge的一部分，该工作旨在开发独立于供应商的AI模型，提高非侵入式诊断的准确性和效率。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "11 pages, 7 figuers",
      "pdf_url": "http://arxiv.org/pdf/2411.01652v1",
      "published_date": "2024-11-03 18:30:37 UTC",
      "updated_date": "2024-11-03 18:30:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:38:29.640629"
    },
    {
      "arxiv_id": "2411.03131v1",
      "title": "Machine Learning Innovations in CPR: A Comprehensive Survey on Enhanced Resuscitation Techniques",
      "title_zh": "翻译失败",
      "authors": [
        "Saidul Islam",
        "Gaith Rjoub",
        "Hanae Elmekki",
        "Jamal Bentahar",
        "Witold Pedrycz",
        "Robin Cohen"
      ],
      "abstract": "This survey paper explores the transformative role of Machine Learning (ML)\nand Artificial Intelligence (AI) in Cardiopulmonary Resuscitation (CPR). It\nexamines the evolution from traditional CPR methods to innovative ML-driven\napproaches, highlighting the impact of predictive modeling, AI-enhanced\ndevices, and real-time data analysis in improving resuscitation outcomes. The\npaper provides a comprehensive overview, classification, and critical analysis\nof current applications, challenges, and future directions in this emerging\nfield.",
      "tldr_zh": "这篇调查论文探讨了 Machine Learning (ML) 和 Artificial Intelligence (AI) 在 Cardiopulmonary Resuscitation (CPR) 中的变革作用，审视了从传统方法到创新 ML 驱动技术的演变。论文强调了预测建模、AI 增强设备和实时数据分析如何显著改善复苏结果，并提供了当前应用的全面概述和分类。最终，它对关键挑战进行了分析，并指出了该领域的未来发展方向。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.03131v1",
      "published_date": "2024-11-03 18:01:50 UTC",
      "updated_date": "2024-11-03 18:01:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:38:41.011994"
    },
    {
      "arxiv_id": "2411.01647v1",
      "title": "Optical Flow Representation Alignment Mamba Diffusion Model for Medical Video Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Zhenbin Wang",
        "Lei Zhang",
        "Lituan Wang",
        "Minjuan Zhu",
        "Zhenwei Zhang"
      ],
      "abstract": "Medical video generation models are expected to have a profound impact on the\nhealthcare industry, including but not limited to medical education and\ntraining, surgical planning, and simulation. Current video diffusion models\ntypically build on image diffusion architecture by incorporating temporal\noperations (such as 3D convolution and temporal attention). Although this\napproach is effective, its oversimplification limits spatio-temporal\nperformance and consumes substantial computational resources. To counter this,\nwe propose Medical Simulation Video Generator (MedSora), which incorporates\nthree key elements: i) a video diffusion framework integrates the advantages of\nattention and Mamba, balancing low computational load with high-quality video\ngeneration, ii) an optical flow representation alignment method that implicitly\nenhances attention to inter-frame pixels, and iii) a video variational\nautoencoder (VAE) with frequency compensation addresses the information loss of\nmedical features that occurs when transforming pixel space into latent features\nand then back to pixel frames. Extensive experiments and applications\ndemonstrate that MedSora exhibits superior visual quality in generating medical\nvideos, outperforming the most advanced baseline methods. Further results and\ncode are available at https://wongzbb.github.io/MedSora",
      "tldr_zh": "这篇论文提出了 Optical Flow Representation Alignment Mamba Diffusion Model for Medical Video Generation，具体通过 Medical Simulation Video Generator (MedSora) 模型来生成高质量医疗视频，以支持医疗教育、手术规划和模拟。MedSora 整合了 attention 和 Mamba 的视频扩散框架，以平衡计算负载和生成质量；引入 optical flow representation alignment 方法来隐式增强帧间像素的注意力；并采用视频 variational autoencoder (VAE) with frequency compensation 来解决像素空间到潜在特征转换中的信息损失。实验结果显示，MedSora 在视觉质量上优于最先进的基线方法，并在医疗视频生成应用中表现出显著优势。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.01647v1",
      "published_date": "2024-11-03 17:57:00 UTC",
      "updated_date": "2024-11-03 17:57:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:38:52.808763"
    },
    {
      "arxiv_id": "2411.01645v2",
      "title": "Enriching Tabular Data with Contextual LLM Embeddings: A Comprehensive Ablation Study for Ensemble Classifiers",
      "title_zh": "翻译失败",
      "authors": [
        "Gjergji Kasneci",
        "Enkelejda Kasneci"
      ],
      "abstract": "Feature engineering is crucial for optimizing machine learning model\nperformance, particularly in tabular data classification tasks. Leveraging\nadvancements in natural language processing, this study presents a systematic\napproach to enrich tabular datasets with features derived from large language\nmodel embeddings. Through a comprehensive ablation study on diverse datasets,\nwe assess the impact of RoBERTa and GPT-2 embeddings on ensemble classifiers,\nincluding Random Forest, XGBoost, and CatBoost. Results indicate that\nintegrating embeddings with traditional numerical and categorical features\noften enhances predictive performance, especially on datasets with class\nimbalance or limited features and samples, such as UCI Adult, Heart Disease,\nTitanic, and Pima Indian Diabetes, with improvements particularly notable in\nXGBoost and CatBoost classifiers. Additionally, feature importance analysis\nreveals that LLM-derived features frequently rank among the most impactful for\nthe predictions. This study provides a structured approach to embedding-based\nfeature enrichment and illustrates its benefits in ensemble learning for\ntabular data.",
      "tldr_zh": "该研究提出了一种系统方法，通过利用大型语言模型（LLM）嵌入（如 RoBERTa 和 GPT-2）来丰富表格数据特征，从而优化机器学习模型在分类任务中的性能。研究通过全面的 ablation study，在多样数据集（如 UCI Adult、Heart Disease、Titanic 和 Pima Indian Diabetes）上评估了这些嵌入对集成分类器（包括 Random Forest、XGBoost 和 CatBoost）的提升效果。结果显示，将 LLM 嵌入与传统特征结合显著提高了预测性能，尤其在类别不平衡或特征/样本有限的场景下，XGBoost 和 CatBoost 表现出色，且 LLM 派生特征在特征重要性分析中排名靠前。该方法为基于嵌入的特征工程提供了结构化框架，并证明了其在集成学习中的实际益处。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.01645v2",
      "published_date": "2024-11-03 17:45:00 UTC",
      "updated_date": "2024-11-05 21:02:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:39:05.064886"
    },
    {
      "arxiv_id": "2411.01643v1",
      "title": "EcoAct: Economic Agent Determines When to Register What Action",
      "title_zh": "翻译失败",
      "authors": [
        "Shaokun Zhang",
        "Jieyu Zhang",
        "Dujian Ding",
        "Mirian Hipolito Garcia",
        "Ankur Mallick",
        "Daniel Madrigal",
        "Menglin Xia",
        "Victor Rühle",
        "Qingyun Wu",
        "Chi Wang"
      ],
      "abstract": "Recent advancements have enabled Large Language Models (LLMs) to function as\nagents that can perform actions using external tools. This requires\nregistering, i.e., integrating tool information into the LLM context prior to\ntaking actions. Current methods indiscriminately incorporate all candidate\ntools into the agent's context and retain them across multiple reasoning steps.\nThis process remains opaque to LLM agents and is not integrated into their\nreasoning procedures, leading to inefficiencies due to increased context length\nfrom irrelevant tools. To address this, we introduce EcoAct, a tool using\nalgorithm that allows LLMs to selectively register tools as needed, optimizing\ncontext use. By integrating the tool registration process into the reasoning\nprocedure, EcoAct reduces computational costs by over 50% in multiple steps\nreasoning tasks while maintaining performance, as demonstrated through\nextensive experiments. Moreover, it can be plugged into any reasoning pipeline\nwith only minor modifications to the prompt, making it applicable to LLM agents\nnow and future.",
      "tldr_zh": "该研究针对大型语言模型（LLMs）作为代理使用外部工具时的问题，指出现有方法会无差别地将所有候选工具整合进上下文，导致上下文长度增加和计算效率低下。EcoAct 是一种创新算法，允许 LLMs 在推理过程中选择性地注册所需工具，优化上下文使用并将其融入推理流程。通过广泛实验证明，EcoAct 在多步骤推理任务中将计算成本降低超过 50%，同时保持性能水平，且只需对提示进行微调即可轻松整合到任何推理管道中。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "16 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.01643v1",
      "published_date": "2024-11-03 17:37:06 UTC",
      "updated_date": "2024-11-03 17:37:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:39:15.639841"
    },
    {
      "arxiv_id": "2411.01639v3",
      "title": "Know Where You're Uncertain When Planning with Multimodal Foundation Models: A Formal Framework",
      "title_zh": "翻译失败",
      "authors": [
        "Neel P. Bhatt",
        "Yunhao Yang",
        "Rohan Siva",
        "Daniel Milan",
        "Ufuk Topcu",
        "Zhangyang Wang"
      ],
      "abstract": "Multimodal foundation models offer a promising framework for robotic\nperception and planning by processing sensory inputs to generate actionable\nplans. However, addressing uncertainty in both perception (sensory\ninterpretation) and decision-making (plan generation) remains a critical\nchallenge for ensuring task reliability. We present a comprehensive framework\nto disentangle, quantify, and mitigate these two forms of uncertainty. We first\nintroduce a framework for uncertainty disentanglement, isolating perception\nuncertainty arising from limitations in visual understanding and decision\nuncertainty relating to the robustness of generated plans.\n  To quantify each type of uncertainty, we propose methods tailored to the\nunique properties of perception and decision-making: we use conformal\nprediction to calibrate perception uncertainty and introduce\nFormal-Methods-Driven Prediction (FMDP) to quantify decision uncertainty,\nleveraging formal verification techniques for theoretical guarantees. Building\non this quantification, we implement two targeted intervention mechanisms: an\nactive sensing process that dynamically re-observes high-uncertainty scenes to\nenhance visual input quality and an automated refinement procedure that\nfine-tunes the model on high-certainty data, improving its capability to meet\ntask specifications. Empirical validation in real-world and simulated robotic\ntasks demonstrates that our uncertainty disentanglement framework reduces\nvariability by up to 40% and enhances task success rates by 5% compared to\nbaselines. These improvements are attributed to the combined effect of both\ninterventions and highlight the importance of uncertainty disentanglement,\nwhich facilitates targeted interventions that enhance the robustness and\nreliability of autonomous systems. Fine-tuned models, code, and datasets are\navailable at https://uncertainty-in-planning.github.io/.",
      "tldr_zh": "该论文提出一个正式框架，用于处理多模态基础模型（Multimodal Foundation Models）在机器人感知和规划中的不确定性问题，通过分离感知不确定性（视觉理解限制）和决策不确定性（计划生成鲁棒性）。框架采用 Conformal Prediction 来量化感知不确定性，并引入 Formal-Methods-Driven Prediction (FMDP) 方法，利用形式验证技术为决策不确定性提供理论保证。针对这些不确定性，论文实现了主动感知过程（动态重新观察高不确定性场景）和自动精炼过程（在高确定性数据上微调模型），以提升任务可靠性。实验结果显示，该框架在真实和模拟机器人任务中减少不确定性高达 40%，并提高任务成功率 5%，强调了不确定性分离对增强自主系统鲁棒性的重要性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Fine-tuned models, code, and datasets are available at\n  https://uncertainty-in-planning.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2411.01639v3",
      "published_date": "2024-11-03 17:32:00 UTC",
      "updated_date": "2025-04-17 02:45:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:39:29.749842"
    },
    {
      "arxiv_id": "2411.01625v1",
      "title": "Counterfactual explainability of black-box prediction models",
      "title_zh": "黑箱预测模型的反事实可解释性",
      "authors": [
        "Zijun Gao",
        "Qingyuan Zhao"
      ],
      "abstract": "It is crucial to be able to explain black-box prediction models to use them\neffectively and safely in practice. Most existing tools for model explanations\nare associational rather than causal, and we use two paradoxical examples to\nshow that such explanations are generally inadequate. Motivated by the concept\nof genetic heritability in twin studies, we propose a new notion called\ncounterfactual explainability for black-box prediction models. Counterfactual\nexplainability has three key advantages: (1) it leverages counterfactual\noutcomes and extends methods for global sensitivity analysis (such as\nfunctional analysis of variance and Sobol's indices) to a causal setting; (2)\nit is defined not only for the totality of a set of input factors but also for\ntheir interactions (indeed, it is a probability measure on a whole\n``explanation algebra''); (3) it also applies to dependent input factors whose\ncausal relationship can be modeled by a directed acyclic graph, thus\nincorporating causal mechanisms into the explanation.",
      "tldr_zh": "该论文强调了解释黑盒预测模型（black-box prediction models）的必要性，因为现有的关联性解释工具往往不足，并通过两个悖论例子进行了说明。作者提出了一种新概念counterfactual explainability，借鉴遗传学中双胞胎研究的启发，将全局敏感性分析方法（如functional analysis of variance和Sobol's indices）扩展到因果设置中。counterfactual explainability的优势在于，它不仅适用于输入因素的整体和交互作用（作为“explanation algebra”上的概率测度），还能够处理依赖输入因素，通过directed acyclic graph建模因果机制，从而提供更可靠的模型解释。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "19 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.01625v1",
      "published_date": "2024-11-03 16:29:09 UTC",
      "updated_date": "2024-11-03 16:29:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:39:39.983627"
    },
    {
      "arxiv_id": "2411.01623v2",
      "title": "FilterNet: Harnessing Frequency Filters for Time Series Forecasting",
      "title_zh": "FilterNet: 利用频率滤波器进行时间序列预测",
      "authors": [
        "Kun Yi",
        "Jingru Fei",
        "Qi Zhang",
        "Hui He",
        "Shufeng Hao",
        "Defu Lian",
        "Wei Fan"
      ],
      "abstract": "While numerous forecasters have been proposed using different network\narchitectures, the Transformer-based models have state-of-the-art performance\nin time series forecasting. However, forecasters based on Transformers are\nstill suffering from vulnerability to high-frequency signals, efficiency in\ncomputation, and bottleneck in full-spectrum utilization, which essentially are\nthe cornerstones for accurately predicting time series with thousands of\npoints. In this paper, we explore a novel perspective of enlightening signal\nprocessing for deep time series forecasting. Inspired by the filtering process,\nwe introduce one simple yet effective network, namely FilterNet, built upon our\nproposed learnable frequency filters to extract key informative temporal\npatterns by selectively passing or attenuating certain components of time\nseries signals. Concretely, we propose two kinds of learnable filters in the\nFilterNet: (i) Plain shaping filter, that adopts a universal frequency kernel\nfor signal filtering and temporal modeling; (ii) Contextual shaping filter,\nthat utilizes filtered frequencies examined in terms of its compatibility with\ninput signals for dependency learning. Equipped with the two filters, FilterNet\ncan approximately surrogate the linear and attention mappings widely adopted in\ntime series literature, while enjoying superb abilities in handling\nhigh-frequency noises and utilizing the whole frequency spectrum that is\nbeneficial for forecasting. Finally, we conduct extensive experiments on eight\ntime series forecasting benchmarks, and experimental results have demonstrated\nour superior performance in terms of both effectiveness and efficiency compared\nwith state-of-the-art methods. Code is available at this repository:\nhttps://github.com/aikunyi/FilterNet",
      "tldr_zh": "这篇论文提出了 FilterNet，一种基于可学习频率滤波器的网络，用于提升时间序列预测的性能，针对 Transformer-based 模型在高频信号脆弱性、计算效率和全谱利用方面的不足。FilterNet 包括两种关键组件：Plain shaping filter 用于通用信号过滤和时间建模，以及 Contextual shaping filter 通过评估输入信号兼容性来学习依赖关系，从而更好地处理高频噪声并替代传统线性或注意力映射。在八个时间序列预测基准上的实验结果显示，FilterNet 在有效性和效率上均优于现有最先进方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.01623v2",
      "published_date": "2024-11-03 16:20:41 UTC",
      "updated_date": "2024-11-05 04:07:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:41:52.383388"
    },
    {
      "arxiv_id": "2411.01618v1",
      "title": "VQ-Map: Bird's-Eye-View Map Layout Estimation in Tokenized Discrete Space via Vector Quantization",
      "title_zh": "翻译失败",
      "authors": [
        "Yiwei Zhang",
        "Jin Gao",
        "Fudong Ge",
        "Guan Luo",
        "Bing Li",
        "Zhaoxiang Zhang",
        "Haibin Ling",
        "Weiming Hu"
      ],
      "abstract": "Bird's-eye-view (BEV) map layout estimation requires an accurate and full\nunderstanding of the semantics for the environmental elements around the ego\ncar to make the results coherent and realistic. Due to the challenges posed by\nocclusion, unfavourable imaging conditions and low resolution,\n\\emph{generating} the BEV semantic maps corresponding to corrupted or invalid\nareas in the perspective view (PV) is appealing very recently. \\emph{The\nquestion is how to align the PV features with the generative models to\nfacilitate the map estimation}. In this paper, we propose to utilize a\ngenerative model similar to the Vector Quantized-Variational AutoEncoder\n(VQ-VAE) to acquire prior knowledge for the high-level BEV semantics in the\ntokenized discrete space. Thanks to the obtained BEV tokens accompanied with a\ncodebook embedding encapsulating the semantics for different BEV elements in\nthe groundtruth maps, we are able to directly align the sparse backbone image\nfeatures with the obtained BEV tokens from the discrete representation learning\nbased on a specialized token decoder module, and finally generate high-quality\nBEV maps with the BEV codebook embedding serving as a bridge between PV and\nBEV. We evaluate the BEV map layout estimation performance of our model, termed\nVQ-Map, on both the nuScenes and Argoverse benchmarks, achieving 62.2/47.6 mean\nIoU for surround-view/monocular evaluation on nuScenes, as well as 73.4 IoU for\nmonocular evaluation on Argoverse, which all set a new record for this map\nlayout estimation task. The code and models are available on\n\\url{https://github.com/Z1zyw/VQ-Map}.",
      "tldr_zh": "本研究提出 VQ-Map 模型，用于 Bird's-Eye-View (BEV) 地图布局估计，旨在通过 Vector Quantization (VQ) 在 token 化的离散空间中处理视角视图 (PV) 中的遮挡、不利成像条件和低分辨率问题。模型借鉴 Vector Quantized-Variational AutoEncoder (VQ-VAE) 的生成框架，获取 BEV 语义的先验知识，并利用 BEV tokens 和 codebook embedding 将 PV 特征与 BEV tokens 对齐，最终生成高质量的 BEV 地图。实验结果显示，VQ-Map 在 nuScenes 数据集上达到 62.2/47.6 mIoU（surround-view/monocular）和 Argoverse 数据集上达到 73.4 IoU，创下了该任务的新记录。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.01618v1",
      "published_date": "2024-11-03 16:09:47 UTC",
      "updated_date": "2024-11-03 16:09:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:40:05.028167"
    },
    {
      "arxiv_id": "2411.01612v1",
      "title": "Ontology Population using LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Sanaz Saki Norouzi",
        "Adrita Barua",
        "Antrea Christou",
        "Nikita Gautam",
        "Andrew Eells",
        "Pascal Hitzler",
        "Cogan Shimizu"
      ],
      "abstract": "Knowledge graphs (KGs) are increasingly utilized for data integration,\nrepresentation, and visualization. While KG population is critical, it is often\ncostly, especially when data must be extracted from unstructured text in\nnatural language, which presents challenges, such as ambiguity and complex\ninterpretations. Large Language Models (LLMs) offer promising capabilities for\nsuch tasks, excelling in natural language understanding and content generation.\nHowever, their tendency to ``hallucinate'' can produce inaccurate outputs.\nDespite these limitations, LLMs offer rapid and scalable processing of natural\nlanguage data, and with prompt engineering and fine-tuning, they can\napproximate human-level performance in extracting and structuring data for KGs.\nThis study investigates LLM effectiveness for the KG population, focusing on\nthe Enslaved.org Hub Ontology. In this paper, we report that compared to the\nground truth, LLM's can extract ~90% of triples, when provided a modular\nontology as guidance in the prompts.",
      "tldr_zh": "本研究探讨了使用大型语言模型 (LLMs) 来填充知识图谱 (KGs)，以解决从非结构化文本中提取数据面临的挑战，如歧义和复杂解释问题。研究通过提示工程和微调技术，增强 LLMs 的自然语言理解能力，使其在数据提取和结构化方面接近人类水平。聚焦于 Enslaved.org Hub Ontology 的实验显示，当在提示中提供模块化本体指导时，LLMs 能提取约 90% 的三元组 (triples)。这项工作突显了 LLMs 在 KG 填充中的可扩展潜力，尽管仍需应对其“幻觉”输出问题。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.01612v1",
      "published_date": "2024-11-03 15:39:20 UTC",
      "updated_date": "2024-11-03 15:39:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:42:04.794346"
    },
    {
      "arxiv_id": "2411.01611v1",
      "title": "Stochastic Communication Avoidance for Recommendation Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Lutfi Eren Erdogan",
        "Vijay Anand Raghava Kanakagiri",
        "Kurt Keutzer",
        "Zhen Dong"
      ],
      "abstract": "One of the major bottlenecks for efficient deployment of neural network based\nrecommendation systems is the memory footprint of their embedding tables.\nAlthough many neural network based recommendation systems could benefit from\nthe faster on-chip memory access and increased computational power of hardware\naccelerators, the large embedding tables in these models often cannot fit on\nthe constrained memory of accelerators. Despite the pervasiveness of these\nmodels, prior methods in memory optimization and parallelism fail to address\nthe memory and communication costs of large embedding tables on accelerators.\nAs a result, the majority of models are trained on CPUs, while current\nimplementations of accelerators are hindered by issues such as bottlenecks in\ninter-device communication and main memory lookups. In this paper, we propose a\ntheoretical framework that analyses the communication costs of arbitrary\ndistributed systems that use lookup tables. We use this framework to propose\nalgorithms that maximize throughput subject to memory, computation, and\ncommunication constraints. Furthermore, we demonstrate that our method achieves\nstrong theoretical performance across dataset distributions and memory\nconstraints, applicable to a wide range of use cases from mobile federated\nlearning to warehouse-scale computation. We implement our framework and\nalgorithms in PyTorch and achieve up to 6x increases in training throughput on\nGPU systems over baselines, on the Criteo Terabytes dataset.",
      "tldr_zh": "该论文针对神经网络推荐系统的嵌入 tables（embedding tables）内存占用问题，提出了一种随机通信避免（Stochastic Communication Avoidance）框架，以优化分布式系统中的通信成本。研究者开发了一个理论框架来分析任意分布式系统使用查找表的通信开销，并设计算法最大化训练吞吐量，同时满足内存、计算和通信约束。实验结果显示，在 PyTorch 实现下，该方法在 Criteo Terabytes 数据集上实现了高达 6 倍的 GPU 训练吞吐量提升，适用于从移动联邦学习到仓库级计算的多种场景。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.CV",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.01611v1",
      "published_date": "2024-11-03 15:37:37 UTC",
      "updated_date": "2024-11-03 15:37:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:42:21.210159"
    },
    {
      "arxiv_id": "2411.01608v1",
      "title": "GITSR: Graph Interaction Transformer-based Scene Representation for Multi Vehicle Collaborative Decision-making",
      "title_zh": "翻译失败",
      "authors": [
        "Xingyu Hu",
        "Lijun Zhang",
        "Dejian Meng",
        "Ye Han",
        "Lisha Yuan"
      ],
      "abstract": "In this study, we propose GITSR, an effective framework for Graph Interaction\nTransformer-based Scene Representation for multi-vehicle collaborative\ndecision-making in intelligent transportation system. In the context of mixed\ntraffic where Connected Automated Vehicles (CAVs) and Human Driving Vehicles\n(HDVs) coexist, in order to enhance the understanding of the environment by\nCAVs to improve decision-making capabilities, this framework focuses on\nefficient scene representation and the modeling of spatial interaction\nbehaviors of traffic states. We first extract features of the driving\nenvironment based on the background of intelligent networking. Subsequently,\nthe local scene representation, which is based on the agent-centric and dynamic\noccupation grid, is calculated by the Transformer module. Besides, feasible\nregion of the map is captured through the multi-head attention mechanism to\nreduce the collision of vehicles. Notably, spatial interaction behaviors, based\non motion information, are modeled as graph structures and extracted via Graph\nNeural Network (GNN). Ultimately, the collaborative decision-making among\nmultiple vehicles is formulated as a Markov Decision Process (MDP), with\ndriving actions output by Reinforcement Learning (RL) algorithms. Our\nalgorithmic validation is executed within the extremely challenging scenario of\nhighway off-ramp task, thereby substantiating the superiority of agent-centric\napproach to scene representation. Simulation results demonstrate that the GITSR\nmethod can not only effectively capture scene representation but also extract\nspatial interaction data, outperforming the baseline method across various\ncomparative metrics.",
      "tldr_zh": "本研究提出GITSR框架，即基于Graph Interaction Transformer的场景表示方法，用于智能交通系统中多车辆协作决策，尤其在Connected Automated Vehicles (CAVs)和Human Driving Vehicles (HDVs)混合环境中。框架首先提取驾驶环境特征，并通过Transformer模块计算代理中心的动态占用网格局部场景表示，同时利用多头注意力机制捕获地图可行区域以减少碰撞。接着，将空间交互行为建模为图结构并使用Graph Neural Network (GNN)提取信息，最终将协作决策表述为Markov Decision Process (MDP)，并通过Reinforcement Learning (RL)算法输出驾驶动作。模拟结果显示，GITSR在高速公路出口任务中优于基线方法，能更有效地捕获场景表示和空间交互数据，提升决策性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.MA",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.01608v1",
      "published_date": "2024-11-03 15:27:26 UTC",
      "updated_date": "2024-11-03 15:27:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:42:28.479933"
    },
    {
      "arxiv_id": "2411.01604v1",
      "title": "Large Language Model Supply Chain: Open Problems From the Security Perspective",
      "title_zh": "大型语言模型供应链：从安全视角的开放问题",
      "authors": [
        "Qiang Hu",
        "Xiaofei Xie",
        "Sen Chen",
        "Lei Ma"
      ],
      "abstract": "Large Language Model (LLM) is changing the software development paradigm and\nhas gained huge attention from both academia and industry. Researchers and\ndevelopers collaboratively explore how to leverage the powerful problem-solving\nability of LLMs for specific domain tasks. Due to the wide usage of LLM-based\napplications, e.g., ChatGPT, multiple works have been proposed to ensure the\nsecurity of LLM systems. However, a comprehensive understanding of the entire\nprocesses of LLM system construction (the LLM supply chain) is crucial but\nrelevant works are limited. More importantly, the security issues hidden in the\nLLM SC which could highly impact the reliable usage of LLMs are lack of\nexploration. Existing works mainly focus on assuring the quality of LLM from\nthe model level, security assurance for the entire LLM SC is ignored. In this\nwork, we take the first step to discuss the potential security risks in each\ncomponent as well as the integration between components of LLM SC. We summarize\n12 security-related risks and provide promising guidance to help build safer\nLLM systems. We hope our work can facilitate the evolution of artificial\ngeneral intelligence with secure LLM ecosystems.",
      "tldr_zh": "该论文探讨了从安全视角看大型语言模型（Large Language Model, LLM）供应链（LLM supply chain）的开放问题，强调现有研究主要关注模型层面的安全，而忽略了整个供应链的全面风险评估。作者分析了LLM供应链中各组件（如数据处理、模型训练和部署）以及组件之间集成的潜在安全风险，并总结了12个与安全相关的风险。论文提供了指导建议，以帮助构建更安全的LLM系统，并促进安全LLM生态系统的演变，从而支持人工智能的可靠发展。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.01604v1",
      "published_date": "2024-11-03 15:20:21 UTC",
      "updated_date": "2024-11-03 15:20:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:44:39.738084"
    },
    {
      "arxiv_id": "2411.01602v1",
      "title": "DreamPolish: Domain Score Distillation With Progressive Geometry Generation",
      "title_zh": "DreamPolish：域分数蒸馏与渐进式几何生成",
      "authors": [
        "Yean Cheng",
        "Ziqi Cai",
        "Ming Ding",
        "Wendi Zheng",
        "Shiyu Huang",
        "Yuxiao Dong",
        "Jie Tang",
        "Boxin Shi"
      ],
      "abstract": "We introduce DreamPolish, a text-to-3D generation model that excels in\nproducing refined geometry and high-quality textures. In the geometry\nconstruction phase, our approach leverages multiple neural representations to\nenhance the stability of the synthesis process. Instead of relying solely on a\nview-conditioned diffusion prior in the novel sampled views, which often leads\nto undesired artifacts in the geometric surface, we incorporate an additional\nnormal estimator to polish the geometry details, conditioned on viewpoints with\nvarying field-of-views. We propose to add a surface polishing stage with only a\nfew training steps, which can effectively refine the artifacts attributed to\nlimited guidance from previous stages and produce 3D objects with more\ndesirable geometry. The key topic of texture generation using pretrained\ntext-to-image models is to find a suitable domain in the vast latent\ndistribution of these models that contains photorealistic and consistent\nrenderings. In the texture generation phase, we introduce a novel score\ndistillation objective, namely domain score distillation (DSD), to guide neural\nrepresentations toward such a domain. We draw inspiration from the\nclassifier-free guidance (CFG) in textconditioned image generation tasks and\nshow that CFG and variational distribution guidance represent distinct aspects\nin gradient guidance and are both imperative domains for the enhancement of\ntexture quality. Extensive experiments show our proposed model can produce 3D\nassets with polished surfaces and photorealistic textures, outperforming\nexisting state-of-the-art methods.",
      "tldr_zh": "我们介绍了 DreamPolish，一种文本到 3D 生成模型，通过多神经表示和视点条件下的正常估计器来提升几何构建的稳定性和细节，并在后续表面抛光阶段仅需少量训练步骤即可修复缺陷，产生更精致的几何形状。在纹理生成方面，我们提出 Domain Score Distillation (DSD) 目标，结合 classifier-free guidance (CFG) 和变分分布引导，引导神经表示朝向逼真一致的潜在域，从而提升纹理质量。实验结果显示，DreamPolish 生成的 3D 资产在表面抛光和纹理逼真度上优于现有最先进方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.01602v1",
      "published_date": "2024-11-03 15:15:01 UTC",
      "updated_date": "2024-11-03 15:15:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:42:52.658272"
    },
    {
      "arxiv_id": "2411.01597v1",
      "title": "OSAD: Open-Set Aircraft Detection in SAR Images",
      "title_zh": "翻译失败",
      "authors": [
        "Xiayang Xiao",
        "Zhuoxuan Li",
        "Haipeng Wang"
      ],
      "abstract": "Current mainstream SAR image object detection methods still lack robustness\nwhen dealing with unknown objects in open environments. Open-set detection aims\nto enable detectors trained on a closed set to detect all known objects and\nidentify unknown objects in open-set environments. The key challenges are how\nto improve the generalization to potential unknown objects and reduce the\nempirical classification risk of known categories under strong supervision. To\naddress these challenges, a novel open-set aircraft detector for SAR images is\nproposed, named Open-Set Aircraft Detection (OSAD), which is equipped with\nthree dedicated components: global context modeling (GCM), location\nquality-driven pseudo labeling generation (LPG), and prototype contrastive\nlearning (PCL). GCM effectively enhances the network's representation of\nobjects by attention maps which is formed through the capture of long\nsequential positional relationships. LPG leverages clues about object positions\nand shapes to optimize localization quality, avoiding overfitting to known\ncategory information and enhancing generalization to potential unknown objects.\nPCL employs prototype-based contrastive encoding loss to promote instance-level\nintra-class compactness and inter-class variance, aiming to minimize the\noverlap between known and unknown distributions and reduce the empirical\nclassification risk of known categories. Extensive experiments have\ndemonstrated that the proposed method can effectively detect unknown objects\nand exhibit competitive performance without compromising closed-set\nperformance. The highest absolute gain which ranges from 0 to 18.36% can be\nachieved on the average precision of unknown objects.",
      "tldr_zh": "该研究针对 SAR 图像中开放集飞机检测的问题，提出了一种新型方法 OSAD，以提升对未知物体的检测鲁棒性，同时减少已知类别的经验分类风险。OSAD 包括三个关键组件：全局上下文建模 (GCM) 用于通过注意力图捕获长序列关系增强物体表示、位置质量驱动的伪标签生成 (LPG) 优化定位以避免过拟合并提高泛化能力，以及原型对比学习 (PCL) 通过对比编码损失促进类内紧凑性和类间差异。实验结果表明，OSAD 能有效识别未知物体，并在未知物体的平均精度上实现高达 18.36% 的绝对增益，同时不影响封闭集性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "15 pages,11 figures. This work has been submitted to the IEEE for\n  possible publication on March 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.01597v1",
      "published_date": "2024-11-03 15:06:14 UTC",
      "updated_date": "2024-11-03 15:06:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:43:05.232987"
    },
    {
      "arxiv_id": "2411.01595v2",
      "title": "RS-MoE: A Vision-Language Model with Mixture of Experts for Remote Sensing Image Captioning and Visual Question Answering",
      "title_zh": "RS-MoE：一种基于混合专家的视觉-语言模型，用于遥感图像描述和视觉问答",
      "authors": [
        "Hui Lin",
        "Danfeng Hong",
        "Shuhang Ge",
        "Chuyao Luo",
        "Kai Jiang",
        "Hao Jin",
        "Congcong Wen"
      ],
      "abstract": "Remote Sensing Image Captioning (RSIC) presents unique challenges and plays a\ncritical role in applications. Traditional RSIC methods often struggle to\nproduce rich and diverse descriptions. Recently, with advancements in VLMs,\nefforts have emerged to integrate these models into the remote sensing domain\nand to introduce descriptive datasets specifically designed to enhance VLM\ntraining. This paper proposes RS-MoE, a first Mixture of Expert based VLM\nspecifically customized for remote sensing domain. Unlike traditional MoE\nmodels, the core of RS-MoE is the MoE Block, which incorporates a novel\nInstruction Router and multiple lightweight Large Language Models (LLMs) as\nexpert models. The Instruction Router is designed to generate specific prompts\ntailored for each corresponding LLM, guiding them to focus on distinct aspects\nof the RSIC task. This design not only allows each expert LLM to concentrate on\na specific subset of the task, thereby enhancing the specificity and accuracy\nof the generated captions, but also improves the scalability of the model by\nfacilitating parallel processing of sub-tasks. Additionally, we present a\ntwo-stage training strategy for tuning our RS-MoE model to prevent performance\ndegradation due to sparsity. We fine-tuned our model on the RSICap dataset\nusing our proposed training strategy. Experimental results on the RSICap\ndataset, along with evaluations on other traditional datasets where no\nadditional fine-tuning was applied, demonstrate that our model achieves\nstate-of-the-art performance in generating precise and contextually relevant\ncaptions. Notably, our RS-MoE-1B variant achieves performance comparable to 13B\nVLMs, demonstrating the efficiency of our model design. Moreover, our model\ndemonstrates promising generalization capabilities by consistently achieving\nstate-of-the-art performance on the Remote Sensing Visual Question Answering\n(RSVQA) task.",
      "tldr_zh": "本论文提出 RS-MoE，一种基于 Mixture of Experts 的视觉语言模型，专门针对遥感图像描述 (RSIC) 和视觉问答 (RSVQA) 任务，旨在解决传统方法在生成丰富描述方面的不足。RS-MoE 核心包括 Instruction Router 和多个轻量级 Large Language Models (LLMs) 作为专家模型，该路由器生成特定提示引导每个 LLM 专注于任务的不同子方面，从而提升生成标题的精确性、准确性和模型可扩展性。论文采用两阶段训练策略在 RSICap 数据集上微调模型，实验结果显示 RS-MoE-1B 模型性能可比 13B VLMs，并在 RSVQA 任务上实现最先进性能，展示了其高效性和泛化能力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.01595v2",
      "published_date": "2024-11-03 15:05:49 UTC",
      "updated_date": "2025-02-10 19:14:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:43:17.411312"
    },
    {
      "arxiv_id": "2411.01583v1",
      "title": "Trustworthy Federated Learning: Privacy, Security, and Beyond",
      "title_zh": "可信的联邦学习：隐私、安全，以及更进一步",
      "authors": [
        "Chunlu Chen",
        "Ji Liu",
        "Haowen Tan",
        "Xingjian Li",
        "Kevin I-Kai Wang",
        "Peng Li",
        "Kouichi Sakurai",
        "Dejing Dou"
      ],
      "abstract": "While recent years have witnessed the advancement in big data and Artificial\nIntelligence (AI), it is of much importance to safeguard data privacy and\nsecurity. As an innovative approach, Federated Learning (FL) addresses these\nconcerns by facilitating collaborative model training across distributed data\nsources without transferring raw data. However, the challenges of robust\nsecurity and privacy across decentralized networks catch significant attention\nin dealing with the distributed data in FL. In this paper, we conduct an\nextensive survey of the security and privacy issues prevalent in FL,\nunderscoring the vulnerability of communication links and the potential for\ncyber threats. We delve into various defensive strategies to mitigate these\nrisks, explore the applications of FL across different sectors, and propose\nresearch directions. We identify the intricate security challenges that arise\nwithin the FL frameworks, aiming to contribute to the development of secure and\nefficient FL systems.",
      "tldr_zh": "该论文对可信联邦学习（Federated Learning, FL）进行了广泛调查，强调了在分布式数据环境中保护隐私和安全的重要性。论文分析了FL面临的挑战，如通信链路的脆弱性和潜在网络威胁，并探讨了各种防御策略来缓解这些风险。同时，它考察了FL在不同行业的应用，并提出了未来研究方向，以推动开发安全、高效的FL系统。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.CR",
      "comment": "32 pages, to appear in KAIS",
      "pdf_url": "http://arxiv.org/pdf/2411.01583v1",
      "published_date": "2024-11-03 14:18:01 UTC",
      "updated_date": "2024-11-03 14:18:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:43:26.696973"
    },
    {
      "arxiv_id": "2411.01579v1",
      "title": "Flexible Coded Distributed Convolution Computing for Enhanced Fault Tolerance and Numerical Stability in Distributed CNNs",
      "title_zh": "灵活编码分布式卷积计算，用于增强分布式卷积神经网络中的容错性和数值稳定性",
      "authors": [
        "Shuo Tan",
        "Rui Liu",
        "XianLei Long",
        "Kai Wan",
        "Linqi Song",
        "Yong Li"
      ],
      "abstract": "Deploying Convolutional Neural Networks (CNNs) on resource-constrained\ndevices necessitates efficient management of computational resources, often via\ndistributed systems susceptible to latency from straggler nodes. This paper\nintroduces the Flexible Coded Distributed Convolution Computing (FCDCC)\nframework to enhance fault tolerance and numerical stability in distributed\nCNNs. We extend Coded Distributed Computing (CDC) with Circulant and Rotation\nMatrix Embedding (CRME) which was originally proposed for matrix multiplication\nto high-dimensional tensor convolution. For the proposed scheme, referred to as\nNumerically Stable Coded Tensor Convolution (NSCTC) scheme, we also propose two\nnew coded partitioning schemes: Adaptive-Padding Coded Partitioning (APCP) for\ninput tensor and Kernel-Channel Coded Partitioning (KCCP) for filter tensor.\nThese strategies enable linear decomposition of tensor convolutions and\nencoding them into CDC sub-tasks, combining model parallelism with coded\nredundancy for robust and efficient execution. Theoretical analysis identifies\nan optimal trade-off between communication and storage costs. Empirical results\nvalidate the framework's effectiveness in computational efficiency, fault\ntolerance, and scalability across various CNN architectures.",
      "tldr_zh": "这篇论文介绍了 Flexible Coded Distributed Convolution Computing (FCDCC) 框架，用于提升分布式 CNNs 的容错性和数值稳定性，以应对资源受限设备上的计算挑战。该框架扩展 Coded Distributed Computing (CDC) 通过 Circulant and Rotation Matrix Embedding (CRME) 处理高维张量卷积，并提出 Adaptive-Padding Coded Partitioning (APCP) 和 Kernel-Channel Coded Partitioning (KCCP) 等新方案，实现张量卷积的线性分解和编码，从而结合模型并行与编码冗余。理论分析优化了通信和存储成本，实证结果验证了框架在计算效率、容错性和可扩展性方面的显著优势。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.CV",
        "cs.IT",
        "cs.LG",
        "math.IT"
      ],
      "primary_category": "cs.DC",
      "comment": "14 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.01579v1",
      "published_date": "2024-11-03 14:05:29 UTC",
      "updated_date": "2024-11-03 14:05:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:43:41.850986"
    },
    {
      "arxiv_id": "2411.01574v1",
      "title": "DELE: Deductive $\\mathcal{EL}^{++} \\thinspace $ Embeddings for Knowledge Base Completion",
      "title_zh": "翻译失败",
      "authors": [
        "Olga Mashkova",
        "Fernando Zhapa-Camacho",
        "Robert Hoehndorf"
      ],
      "abstract": "Ontology embeddings map classes, relations, and individuals in ontologies\ninto $\\mathbb{R}^n$, and within $\\mathbb{R}^n$ similarity between entities can\nbe computed or new axioms inferred. For ontologies in the Description Logic\n$\\mathcal{EL}^{++}$, several embedding methods have been developed that\nexplicitly generate models of an ontology. However, these methods suffer from\nsome limitations; they do not distinguish between statements that are\nunprovable and provably false, and therefore they may use entailed statements\nas negatives. Furthermore, they do not utilize the deductive closure of an\nontology to identify statements that are inferred but not asserted. We\nevaluated a set of embedding methods for $\\mathcal{EL}^{++}$ ontologies,\nincorporating several modifications that aim to make use of the ontology\ndeductive closure. In particular, we designed novel negative losses that\naccount both for the deductive closure and different types of negatives and\nformulated evaluation methods for knowledge base completion. We demonstrate\nthat our embedding methods improve over the baseline ontology embedding in the\ntask of knowledge base or ontology completion.",
      "tldr_zh": "本研究提出 DELE，一种基于演绎闭包（deductive closure）的 $\\mathcal{EL}^{++}$ 嵌入方法，用于提升知识库完成（knowledge base completion）任务。现有 $\\mathcal{EL}^{++}$ 嵌入方法存在局限性，无法区分不可证明的语句和可证明为假的语句，且未充分利用本体的演绎闭包来处理推断出的非断言语句。论文设计了新型负损失函数（negative losses），考虑不同类型负例，并改进评估方法。实验结果显示，DELE 方法在知识库或本体完成任务中显著优于基线嵌入方法。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Extended version of the paper \"Enhancing Geometric Ontology\n  Embeddings for $\\mathcal{EL}^{++}$ with Negative Sampling and Deductive\n  Closure Filtering\" presented at NeSy 2024 conference",
      "pdf_url": "http://arxiv.org/pdf/2411.01574v1",
      "published_date": "2024-11-03 14:00:04 UTC",
      "updated_date": "2024-11-03 14:00:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:43:51.983725"
    },
    {
      "arxiv_id": "2411.01562v1",
      "title": "Are LLMs good pragmatic speakers?",
      "title_zh": "翻译失败",
      "authors": [
        "Mingyue Jian",
        "N. Siddharth"
      ],
      "abstract": "Large language models (LLMs) are trained on data assumed to include natural\nlanguage pragmatics, but do they actually behave like pragmatic speakers? We\nattempt to answer this question using the Rational Speech Act (RSA) framework,\nwhich models pragmatic reasoning in human communication. Using the paradigm of\na reference game constructed from the TUNA corpus, we score candidate\nreferential utterances in both a state-of-the-art LLM (Llama3-8B-Instruct) and\nin the RSA model, comparing and contrasting these scores. Given that RSA\nrequires defining alternative utterances and a truth-conditional meaning\nfunction, we explore such comparison for different choices of each of these\nrequirements. We find that while scores from the LLM have some positive\ncorrelation with those from RSA, there isn't sufficient evidence to claim that\nit behaves like a pragmatic speaker. This initial study paves way for further\ntargeted efforts exploring different models and settings, including\nhuman-subject evaluation, to see if LLMs truly can, or be made to, behave like\npragmatic speakers.",
      "tldr_zh": "本研究探讨大型语言模型 (LLMs) 是否能像人类一样进行语用推理，使用 Rational Speech Act (RSA) 框架和基于 TUNA 语料库的参考游戏来评估 Llama3-8B-Instruct 模型的分数，并与 RSA 模型进行比较。\n实验涉及定义备选 utterances 和 truth-conditional meaning function，结果显示 LLM 的分数与 RSA 有一些正相关，但证据不足以证明 LLMs 真正行为如语用说话者。\n这项初步研究为进一步探索不同模型、设置和人类主体评估提供了基础，以检验 LLMs 是否能或被训练成语用说话者。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.01562v1",
      "published_date": "2024-11-03 13:23:18 UTC",
      "updated_date": "2024-11-03 13:23:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:44:52.224204"
    },
    {
      "arxiv_id": "2411.01553v2",
      "title": "Learning to Communicate Through Implicit Communication Channels",
      "title_zh": "通过隐式通信通道的学习沟通",
      "authors": [
        "Han Wang",
        "Binbin Chen",
        "Tieying Zhang",
        "Baoxiang Wang"
      ],
      "abstract": "Effective communication is an essential component in collaborative\nmulti-agent systems. Situations where explicit messaging is not feasible have\nbeen common in human society throughout history, which motivate the study of\nimplicit communication. Previous works on learning implicit communication\nmostly rely on theory of mind (ToM), where agents infer the mental states and\nintentions of others by interpreting their actions. However, ToM-based methods\nbecome less effective in making accurate inferences in complex tasks. In this\nwork, we propose the Implicit Channel Protocol (ICP) framework, which allows\nagents to communicate through implicit communication channels similar to the\nexplicit ones. ICP leverages a subset of actions, denoted as the scouting\nactions, and a mapping between information and these scouting actions that\nencodes and decodes the messages. We propose training algorithms for agents to\nmessage and act, including learning with a randomly initialized information map\nand with a delayed information map. The efficacy of ICP has been tested on the\ntasks of Guessing Numbers, Revealing Goals, and Hanabi, where ICP significantly\noutperforms baseline methods through more efficient information transmission.",
      "tldr_zh": "本研究探讨了在协作多智能体系统中，通过隐式通信渠道实现有效沟通的问题，因为传统的theory of mind (ToM)方法在复杂任务中难以准确推断代理意图。论文提出Implicit Channel Protocol (ICP)框架，让代理利用一组scouting actions和信息映射来编码、解码消息，从而模拟显式通信。训练算法包括随机初始化信息映射和延迟信息映射，以优化代理的通信和行动策略。在Guessing Numbers、Revealing Goals和Hanabi任务上，ICP显著优于基线方法，通过更高效的信息传输提升了整体性能。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.MA",
      "comment": "17 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.01553v2",
      "published_date": "2024-11-03 12:58:22 UTC",
      "updated_date": "2025-02-10 09:32:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:45:02.764185"
    },
    {
      "arxiv_id": "2411.08919v1",
      "title": "A Machine Learning based Hybrid Receiver for 5G NR PRACH",
      "title_zh": "翻译失败",
      "authors": [
        "Rohit Singh",
        "Anil Kumar Yerrapragada",
        "Radha Krishna Ganti"
      ],
      "abstract": "Random Access is a critical procedure using which a User Equipment (UE)\nidentifies itself to a Base Station (BS). Random Access starts with the UE\ntransmitting a random preamble on the Physical Random Access Channel (PRACH).\nIn a conventional BS receiver, the UE's specific preamble is identified by\ncorrelation with all the possible preambles. The PRACH signal is also used to\nestimate the timing advance which is induced by propagation delay.\nCorrelation-based receivers suffer from false peaks and missed detection in\nscenarios dominated by high fading and low signal-to-noise ratio. This paper\ndescribes the design of a hybrid receiver that consists of an AI/ML model for\npreamble detection followed by conventional peak detection for the Timing\nAdvance estimation. The proposed receiver combines the Power Delay Profiles of\ncorrelation windows across multiple antennas and uses the combination as input\nto a Neural Network model. The model predicts the presence or absence of a user\nin a particular preamble window, after which the timing advance is estimated by\npeak detection. Results show superior performance of the hybrid receiver\ncompared to conventional receivers both for simulated and real\nhardware-captured datasets.",
      "tldr_zh": "本文提出了一种基于机器学习的混合接收器，用于5G NR PRACH的随机接入过程，以解决传统相关性接收器在高衰落和低信噪比场景下存在的假峰和漏检问题。该接收器将多个天线的Power Delay Profiles组合作为输入，采用Neural Network模型预测特定前导码窗口中用户的存在，随后通过传统峰值检测估计Timing Advance。实验结果表明，该混合接收器在模拟和真实硬件捕获的数据集上比常规接收器表现出色，显著提高了检测准确性。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.IT",
        "cs.LG",
        "math.IT"
      ],
      "primary_category": "eess.SP",
      "comment": "6 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.08919v1",
      "published_date": "2024-11-03 11:49:12 UTC",
      "updated_date": "2024-11-03 11:49:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:45:15.849289"
    },
    {
      "arxiv_id": "2411.01535v1",
      "title": "Customized Subgraph Selection and Encoding for Drug-drug Interaction Prediction",
      "title_zh": "药物-药物",
      "authors": [
        "Haotong Du",
        "Quanming Yao",
        "Juzheng Zhang",
        "Yang Liu",
        "Zhen Wang"
      ],
      "abstract": "Subgraph-based methods have proven to be effective and interpretable in\npredicting drug-drug interactions (DDIs), which are essential for medical\npractice and drug development. Subgraph selection and encoding are critical\nstages in these methods, yet customizing these components remains underexplored\ndue to the high cost of manual adjustments. In this study, inspired by the\nsuccess of neural architecture search (NAS), we propose a method to search for\ndata-specific components within subgraph-based frameworks. Specifically, we\nintroduce extensive subgraph selection and encoding spaces that account for the\ndiverse contexts of drug interactions in DDI prediction. To address the\nchallenge of large search spaces and high sampling costs, we design a\nrelaxation mechanism that uses an approximation strategy to efficiently explore\noptimal subgraph configurations. This approach allows for robust exploration of\nthe search space. Extensive experiments demonstrate the effectiveness and\nsuperiority of the proposed method, with the discovered subgraphs and encoding\nfunctions highlighting the model's adaptability.",
      "tldr_zh": "这篇论文针对药物-药物相互作用 (DDIs) 预测中的子图选择和编码问题，提出了一种受神经架构搜索 (NAS) 启发的自定义方法，以适应数据特定的子图框架。方法引入了广泛的子图选择和编码空间，考虑药物相互作用的多样上下文，并设计了一个松弛机制，使用近似策略来高效探索最优配置，从而降低手动调整成本。实验结果显示，该方法在 DDI 预测任务上表现出优越性，所发现的子图和编码函数显著提升了模型的适应性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.BM"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.01535v1",
      "published_date": "2024-11-03 11:41:35 UTC",
      "updated_date": "2024-11-03 11:41:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:47:27.786089"
    },
    {
      "arxiv_id": "2411.01533v3",
      "title": "Enhancing LLM Evaluations: The Garbling Trick",
      "title_zh": "翻译失败",
      "authors": [
        "William F. Bradley"
      ],
      "abstract": "As large language models (LLMs) become increasingly powerful, traditional\nevaluation metrics tend to saturate, making it challenging to distinguish\nbetween models. We propose a general method to transform existing LLM\nevaluations into a series of progressively more difficult tasks. These enhanced\nevaluations emphasize reasoning capabilities and can reveal relative\nperformance differences that are not apparent in the original assessments.\n  To demonstrate the effectiveness of our approach, we create a new\nmultiple-choice test corpus, extend it into a family of evaluations, and assess\na collection of LLMs. Our results offer insights into the comparative abilities\nof these models, particularly highlighting the differences between base LLMs\nand more recent \"reasoning\" models.",
      "tldr_zh": "这篇论文提出“The Garbling Trick”方法，用于增强大型语言模型（LLMs）的评估，通过将现有任务转化为一系列渐进更难的版本，以突出模型的推理能力，并揭示原评估中不明显的性能差异。研究者创建了一个新的多项选择测试语料库，并扩展为评估系列，对多种LLMs进行测试。结果显示，该方法有效比较了基础LLMs和更先进的“推理”模型，帮助识别模型间的相对优势。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "15 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.01533v3",
      "published_date": "2024-11-03 11:39:50 UTC",
      "updated_date": "2025-05-18 04:56:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:45:38.831283"
    },
    {
      "arxiv_id": "2411.01523v1",
      "title": "SinaTools: Open Source Toolkit for Arabic Natural Language Processing",
      "title_zh": "SinaTools：阿拉伯自然语言处理的开源工具包",
      "authors": [
        "Tymaa Hammouda",
        "Mustafa Jarrar",
        "Mohammed Khalilia"
      ],
      "abstract": "We introduce SinaTools, an open-source Python package for Arabic natural\nlanguage processing and understanding. SinaTools is a unified package allowing\npeople to integrate it into their system workflow, offering solutions for\nvarious tasks such as flat and nested Named Entity Recognition (NER),\nfully-flagged Word Sense Disambiguation (WSD), Semantic Relatedness, Synonymy\nExtractions and Evaluation, Lemmatization, Part-of-speech Tagging, Root\nTagging, and additional helper utilities such as corpus processing, text\nstripping methods, and diacritic-aware word matching. This paper presents\nSinaTools and its benchmarking results, demonstrating that SinaTools\noutperforms all similar tools on the aforementioned tasks, such as Flat NER\n(87.33%), Nested NER (89.42%), WSD (82.63%), Semantic Relatedness (0.49\nSpearman rank), Lemmatization (90.5%), POS tagging (97.5%), among others.\nSinaTools can be downloaded from (https://sina.birzeit.edu/sinatools).",
      "tldr_zh": "我们介绍了 SinaTools，这是一个开源 Python 包，旨在为阿拉伯自然语言处理和理解提供统一解决方案，支持任务如 Flat and Nested Named Entity Recognition (NER)、Word Sense Disambiguation (WSD)、Semantic Relatedness、Synonymy Extractions、Lemmatization、Part-of-speech Tagging 和 Root Tagging，以及辅助工具如语料处理和文本 stripping。SinaTools 通过基准测试证明了其优越性能，在 Flat NER 上达到 87.33%、Nested NER 89.42%、WSD 82.63%、Semantic Relatedness 的 Spearman rank 为 0.49、Lemmatization 90.5% 和 POS tagging 97.5%，均超过了类似工具。该工具包易于集成系统工作流，并可从 https://sina.birzeit.edu/sinatools 下载。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.01523v1",
      "published_date": "2024-11-03 11:03:52 UTC",
      "updated_date": "2024-11-03 11:03:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:45:51.623890"
    },
    {
      "arxiv_id": "2411.01521v2",
      "title": "Diversity Progress for Goal Selection in Discriminability-Motivated RL",
      "title_zh": "翻译失败",
      "authors": [
        "Erik M. Lintunen",
        "Nadia M. Ady",
        "Christian Guckelsberger"
      ],
      "abstract": "Non-uniform goal selection has the potential to improve the reinforcement\nlearning (RL) of skills over uniform-random selection. In this paper, we\nintroduce a method for learning a goal-selection policy in\nintrinsically-motivated goal-conditioned RL: \"Diversity Progress\" (DP). The\nlearner forms a curriculum based on observed improvement in discriminability\nover its set of goals. Our proposed method is applicable to the class of\ndiscriminability-motivated agents, where the intrinsic reward is computed as a\nfunction of the agent's certainty of following the true goal being pursued.\nThis reward can motivate the agent to learn a set of diverse skills without\nextrinsic rewards. We demonstrate empirically that a DP-motivated agent can\nlearn a set of distinguishable skills faster than previous approaches, and do\nso without suffering from a collapse of the goal distribution -- a known issue\nwith some prior approaches. We end with plans to take this proof-of-concept\nforward.",
      "tldr_zh": "该论文提出了一种名为“Diversity Progress”（DP）的目标选择策略，用于提升discriminability-motivated agents在强化学习（RL）中的表现。DP方法通过基于目标可区分性改进来形成课程（curriculum），帮助代理在goal-conditioned RL中学习多样化技能，而无需外部奖励。实验结果显示，DP使代理比先前方法更快地习得一组可区分技能，并避免了目标分布崩溃的问题。该研究为内在动机导向的RL提供了新思路，并计划进一步扩展这一概念。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "11 pages including appendices, full-track paper at the Intrinsically\n  Motivated Open-ended Learning workshop at NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.01521v2",
      "published_date": "2024-11-03 10:47:39 UTC",
      "updated_date": "2024-11-06 14:52:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:46:02.228737"
    },
    {
      "arxiv_id": "2411.01508v1",
      "title": "FaceDig: Automated tool for placing landmarks on facial portraits for geometric morphometrics users",
      "title_zh": "翻译失败",
      "authors": [
        "Karel Kleisner",
        "Jaroslav Trnka",
        "Petr Turecek"
      ],
      "abstract": "Landmark digitization is essential in geometric morphometrics, enabling the\nquantification of biological shapes, such as facial structures, for in-depth\nmorphological analysis. Traditional landmarking, which identifies specific\nanatomical points, can be complemented by semilandmarks when precise locations\nare challenging to define. However, manual placement of numerous landmarks is\ntime-consuming and prone to human error, leading to inconsistencies across\nstudies. To address this, we introduce FaceDig, an AI-powered tool designed to\nautomate landmark placement with human-level precision, focusing on\nanatomically sound facial points. FaceDig is open-source and integrates\nseamlessly with analytical platforms like R and Python. It was trained using\none of the largest and most ethnically diverse face datasets, applying a\nlandmark configuration optimized for 2D enface photographs. Our results\ndemonstrate that FaceDig provides reliable landmark coordinates, comparable to\nthose placed manually by experts. The tool's output is compatible with the\nwidely-used TpsDig2 software, facilitating adoption and ensuring consistency\nacross studies. Users are advised to work with standardized facial images and\nvisually inspect the results for potential corrections. Despite the growing\npreference for 3D morphometrics, 2D facial photographs remain valuable due to\ntheir cultural and practical significance. Future enhancements to FaceDig will\ninclude support for profile views, further expanding its utility. By offering a\nstandardized approach to landmark placement, FaceDig promotes reproducibility\nin facial morphology research and provides a robust alternative to existing 2D\ntools.",
      "tldr_zh": "本文介绍了 FaceDig，一款开源 AI 工具，旨在自动化放置 landmarks 和 semilandmarks 于面部肖像中，以提升 geometric morphometrics 研究中的形态分析效率和准确性。FaceDig 基于大规模、多民族脸部数据集训练，专注于 2D 正面照片，并与 R 和 Python 平台无缝集成，其输出兼容 TpsDig2 软件。实验结果显示，该工具的 landmarks 放置精度可媲美专家手动操作，并促进研究的可重复性和标准化。未来，FaceDig 将扩展支持 profile views，进一步增强其实用性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "q-bio.QM"
      ],
      "primary_category": "cs.CV",
      "comment": "13 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.01508v1",
      "published_date": "2024-11-03 10:03:52 UTC",
      "updated_date": "2024-11-03 10:03:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:47:28.089297"
    },
    {
      "arxiv_id": "2411.01493v2",
      "title": "Sample-Efficient Alignment for LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Zichen Liu",
        "Changyu Chen",
        "Chao Du",
        "Wee Sun Lee",
        "Min Lin"
      ],
      "abstract": "We study methods for efficiently aligning large language models (LLMs) with\nhuman preferences given budgeted online feedback. We first formulate the LLM\nalignment problem in the frame of contextual dueling bandits. This formulation,\nsubsuming recent paradigms such as online RLHF and online DPO, inherently\nquests for sample-efficient algorithms that incorporate online active\nexploration. Leveraging insights from bandit theory, we introduce a unified\nalgorithm based on Thompson sampling and highlight its applications in two\ndistinct LLM alignment scenarios. The practical agent that efficiently\nimplements this algorithm, named SEA (Sample-Efficient Alignment), is\nempirically validated through extensive experiments across three model scales\n(1B, 2.8B, 6.9B) and three preference learning algorithms (DPO, IPO, SLiC). The\nresults demonstrate that SEA achieves highly sample-efficient alignment with\noracle's preferences, outperforming recent active exploration methods for LLMs.\nAdditionally, we release the implementation of SEA together with an efficient\ncodebase designed for online alignment of LLMs, aiming to accelerate future\nresearch in this field.",
      "tldr_zh": "本研究探讨了在预算有限的在线反馈下，对大型语言模型 (LLMs) 进行样本高效对齐的方法，将问题表述为上下文决斗 bandits 框架，从而整合在线 RLHF 和在线 DPO 等范式。研究引入基于 Thompson sampling 的统一算法，并开发了名为 SEA (Sample-Efficient Alignment) 的实际代理，应用于两种 LLM 对齐场景。实验结果显示，SEA 在三个模型规模 (1B、2.8B、6.9B) 和三种偏好学习算法 (DPO、IPO、SLiC) 上显著优于现有方法，实现了更高的样本效率；此外，作者发布了 SEA 的开源代码，以推动该领域的未来研究。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.01493v2",
      "published_date": "2024-11-03 09:18:28 UTC",
      "updated_date": "2024-11-09 12:22:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:46:27.610876"
    },
    {
      "arxiv_id": "2411.01479v1",
      "title": "Capsule Vision Challenge 2024: Multi-Class Abnormality Classification for Video Capsule Endoscopy",
      "title_zh": "Capsule Vision Challenge 2024：视频胶囊内镜的多类异常分类",
      "authors": [
        "Aakarsh Bansal",
        "Bhuvanesh Singla",
        "Raajan Rajesh Wankhade",
        "Nagamma Patil"
      ],
      "abstract": "This study presents an approach to developing a model for classifying\nabnormalities in video capsule endoscopy (VCE) frames. Given the challenges of\ndata imbalance, we implemented a tiered augmentation strategy using the\nalbumentations library to enhance minority class representation. Additionally,\nwe addressed learning complexities by progressively structuring training tasks,\nallowing the model to differentiate between normal and abnormal cases and then\ngradually adding more specific classes based on data availability. Our\npipeline, developed in PyTorch, employs a flexible architecture enabling\nseamless adjustments to classification complexity. We tested our approach using\nResNet50 and a custom ViT-CNN hybrid model, with training conducted on the\nKaggle platform. This work demonstrates a scalable approach to abnormality\nclassification in VCE.",
      "tldr_zh": "本文提出了一种针对视频胶囊内镜(VCE)帧的多类异常分类方法，以解决数据不平衡和学习复杂性问题。研究团队采用层级增强策略(albumentations库)来提升少数类别的表示，并通过渐进式训练任务，让模型先区分正常与异常，然后逐步添加更多具体类别。使用PyTorch开发了一个灵活的管道，并测试了ResNet50和自定义ViT-CNN混合模型，在Kaggle平台上进行训练。该方法展示了VCE异常分类的可扩展性和实用性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.01479v1",
      "published_date": "2024-11-03 08:34:04 UTC",
      "updated_date": "2024-11-03 08:34:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:47:46.165288"
    },
    {
      "arxiv_id": "2411.01472v1",
      "title": "Adaptive Domain Learning for Cross-domain Image Denoising",
      "title_zh": "自适应域学习用于跨域图像去噪",
      "authors": [
        "Zian Qian",
        "Chenyang Qi",
        "Ka Lung Law",
        "Hao Fu",
        "Chenyang Lei",
        "Qifeng Chen"
      ],
      "abstract": "Different camera sensors have different noise patterns, and thus an image\ndenoising model trained on one sensor often does not generalize well to a\ndifferent sensor. One plausible solution is to collect a large dataset for each\nsensor for training or fine-tuning, which is inevitably time-consuming. To\naddress this cross-domain challenge, we present a novel adaptive domain\nlearning (ADL) scheme for cross-domain RAW image denoising by utilizing\nexisting data from different sensors (source domain) plus a small amount of\ndata from the new sensor (target domain). The ADL training scheme automatically\nremoves the data in the source domain that are harmful to fine-tuning a model\nfor the target domain (some data are harmful as adding them during training\nlowers the performance due to domain gaps). Also, we introduce a modulation\nmodule to adopt sensor-specific information (sensor type and ISO) to understand\ninput data for image denoising. We conduct extensive experiments on public\ndatasets with various smartphone and DSLR cameras, which show our proposed\nmodel outperforms prior work on cross-domain image denoising, given a small\namount of image data from the target domain sensor.",
      "tldr_zh": "这篇论文针对不同相机传感器间噪声模式差异导致的跨域图像去噪问题，提出了Adaptive Domain Learning (ADL)方案，利用现有源域数据加上少量目标域数据进行训练。ADL训练机制自动移除源域中可能因域差距而有害的数据，同时引入一个modulation module来整合传感器特定信息（如传感器类型和ISO），从而提升模型对输入数据的理解和去噪效果。在公共数据集上的实验表明，该方法在各种智能手机和DSLR相机上显著优于现有工作，仅需少量目标域数据即可实现更好的跨域去噪性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "13 pages, 3 figures, accepted by neurips 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.01472v1",
      "published_date": "2024-11-03 08:08:26 UTC",
      "updated_date": "2024-11-03 08:08:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:47:57.797739"
    },
    {
      "arxiv_id": "2411.01458v1",
      "title": "Two-Timescale Model Caching and Resource Allocation for Edge-Enabled AI-Generated Content Services",
      "title_zh": "双时间尺度模型缓存和资源分配，用于边缘启用的人工智能生成内容服务",
      "authors": [
        "Zhang Liu",
        "Hongyang Du",
        "Xiangwang Hou",
        "Lianfen Huang",
        "Seyyedali Hosseinalipour",
        "Dusit Niyato",
        "Khaled Ben Letaief"
      ],
      "abstract": "Generative AI (GenAI) has emerged as a transformative technology, enabling\ncustomized and personalized AI-generated content (AIGC) services. In this\npaper, we address challenges of edge-enabled AIGC service provisioning, which\nremain underexplored in the literature. These services require executing GenAI\nmodels with billions of parameters, posing significant obstacles to\nresource-limited wireless edge. We subsequently introduce the formulation of\njoint model caching and resource allocation for AIGC services to balance a\ntrade-off between AIGC quality and latency metrics. We obtain mathematical\nrelationships of these metrics with the computational resources required by\nGenAI models via experimentation. Afterward, we decompose the formulation into\na model caching subproblem on a long-timescale and a resource allocation\nsubproblem on a short-timescale. Since the variables to be solved are discrete\nand continuous, respectively, we leverage a double deep Q-network (DDQN)\nalgorithm to solve the former subproblem and propose a diffusion-based deep\ndeterministic policy gradient (D3PG) algorithm to solve the latter. The\nproposed D3PG algorithm makes an innovative use of diffusion models as the\nactor network to determine optimal resource allocation decisions. Consequently,\nwe integrate these two learning methods within the overarching two-timescale\ndeep reinforcement learning (T2DRL) algorithm, the performance of which is\nstudied through comparative numerical simulations.",
      "tldr_zh": "本论文探讨了在资源有限的无线边缘环境中提供 AI 生成内容 (AIGC) 服务的挑战，针对 Generative AI (GenAI) 模型的执行问题，提出了一种联合模型缓存和资源分配框架，以平衡 AIGC 质量和延迟指标。研究通过实验建立这些指标与计算资源需求的数学关系，并将问题分解为长期尺度的模型缓存子问题（使用 Double Deep Q-Network, DDQN 算法解决）和短期尺度的资源分配子问题（采用创新的 Diffusion-based Deep Deterministic Policy Gradient, D3PG 算法）。最终，论文整合这些方法形成 Two-Timescale Deep Reinforcement Learning (T2DRL) 算法，并通过数值模拟验证其性能，展示了显著的优化效果。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "14 pages, 8 figures, 39 references",
      "pdf_url": "http://arxiv.org/pdf/2411.01458v1",
      "published_date": "2024-11-03 07:01:13 UTC",
      "updated_date": "2024-11-03 07:01:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:48:10.777968"
    },
    {
      "arxiv_id": "2411.01453v1",
      "title": "Denoising Fisher Training For Neural Implicit Samplers",
      "title_zh": "翻译失败",
      "authors": [
        "Weijian Luo",
        "Wei Deng"
      ],
      "abstract": "Efficient sampling from un-normalized target distributions is pivotal in\nscientific computing and machine learning. While neural samplers have\ndemonstrated potential with a special emphasis on sampling efficiency, existing\nneural implicit samplers still have issues such as poor mode covering behavior,\nunstable training dynamics, and sub-optimal performances. To tackle these\nissues, in this paper, we introduce Denoising Fisher Training (DFT), a novel\ntraining approach for neural implicit samplers with theoretical guarantees. We\nframe the training problem as an objective of minimizing the Fisher divergence\nby deriving a tractable yet equivalent loss function, which marks a unique\ntheoretical contribution to assessing the intractable Fisher divergences. DFT\nis empirically validated across diverse sampling benchmarks, including\ntwo-dimensional synthetic distribution, Bayesian logistic regression, and\nhigh-dimensional energy-based models (EBMs). Notably, in experiments with\nhigh-dimensional EBMs, our best one-step DFT neural sampler achieves results on\npar with MCMC methods with up to 200 sampling steps, leading to a substantially\ngreater efficiency over 100 times higher. This result not only demonstrates the\nsuperior performance of DFT in handling complex high-dimensional sampling but\nalso sheds light on efficient sampling methodologies across broader\napplications.",
      "tldr_zh": "该论文提出Denoising Fisher Training (DFT)，一种新型训练方法，用于提升神经隐式采样器的性能，解决其模式覆盖差、不稳定训练和性能不佳等问题。DFT通过将训练目标框架为最小化Fisher divergence，并推导一个可计算的等价损失函数，从而提供理论保证。在实验中，DFT在二维合成分布、Bayesian logistic regression和高维energy-based models (EBMs)基准上验证有效，其中最佳一步DFT采样器性能媲美MCMC方法的200步，效率提高100倍以上，展示了其在复杂高维采样任务中的优越性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "stat.CO"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.01453v1",
      "published_date": "2024-11-03 06:21:59 UTC",
      "updated_date": "2024-11-03 06:21:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:48:22.122346"
    },
    {
      "arxiv_id": "2411.01442v2",
      "title": "Online Relational Inference for Evolving Multi-agent Interacting Systems",
      "title_zh": "演化多智能体互动系统的在线关系推断",
      "authors": [
        "Beomseok Kang",
        "Priyabrata Saha",
        "Sudarshan Sharma",
        "Biswadeep Chakraborty",
        "Saibal Mukhopadhyay"
      ],
      "abstract": "We introduce a novel framework, Online Relational Inference (ORI), designed\nto efficiently identify hidden interaction graphs in evolving multi-agent\ninteracting systems using streaming data. Unlike traditional offline methods\nthat rely on a fixed training set, ORI employs online backpropagation, updating\nthe model with each new data point, thereby allowing it to adapt to changing\nenvironments in real-time. A key innovation is the use of an adjacency matrix\nas a trainable parameter, optimized through a new adaptive learning rate\ntechnique called AdaRelation, which adjusts based on the historical sensitivity\nof the decoder to changes in the interaction graph. Additionally, a data\naugmentation method named Trajectory Mirror (TM) is introduced to improve\ngeneralization by exposing the model to varied trajectory patterns.\nExperimental results on both synthetic datasets and real-world data (CMU MoCap\nfor human motion) demonstrate that ORI significantly improves the accuracy and\nadaptability of relational inference in dynamic settings compared to existing\nmethods. This approach is model-agnostic, enabling seamless integration with\nvarious neural relational inference (NRI) architectures, and offers a robust\nsolution for real-time applications in complex, evolving systems.",
      "tldr_zh": "这篇论文提出了 Online Relational Inference (ORI) 框架，用于利用流式数据高效识别演化多智能体交互系统中的隐藏交互图。不同于传统离线方法，ORI 通过在线反向传播实时更新模型，以适应动态环境；它创新性地使用邻接矩阵作为可训练参数，并引入 AdaRelation 自适应学习率技术和 Trajectory Mirror (TM) 数据增强方法来优化模型并提升泛化能力。实验结果显示，在合成数据集和真实世界数据（如 CMU MoCap 人类运动数据）上，ORI 显著提高了关系推理的准确性和适应性，且作为模型无关的方法，可无缝集成到各种 neural relational inference (NRI) 架构中，适用于复杂实时应用。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.01442v2",
      "published_date": "2024-11-03 05:43:55 UTC",
      "updated_date": "2024-11-07 05:54:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:48:34.408586"
    },
    {
      "arxiv_id": "2411.01438v2",
      "title": "SkyServe: Serving AI Models across Regions and Clouds with Spot Instances",
      "title_zh": "翻译失败",
      "authors": [
        "Ziming Mao",
        "Tian Xia",
        "Zhanghao Wu",
        "Wei-Lin Chiang",
        "Tyler Griggs",
        "Romil Bhardwaj",
        "Zongheng Yang",
        "Scott Shenker",
        "Ion Stoica"
      ],
      "abstract": "Recent years have witnessed an explosive growth of AI models. The high cost\nof hosting AI services on GPUs and their demanding service requirements, make\nit timely and challenging to lower service costs and guarantee service quality.\nWhile spot instances have long been offered with a large discount, spot\npreemptions have discouraged users from using them to host model replicas when\nserving AI models.\n  To address this, we propose a simple yet efficient policy, SpotHedge, that\nleverages spot replicas across different failure domains (e.g., regions and\nclouds) to ensure availability, lower costs, and high service quality.\nSpotHedge intelligently spreads spot replicas across different regions and\nclouds to improve availability and reduce correlated preemptions,\noverprovisions cheap spot replicas than required as a safeguard against\npossible preemptions, and dynamically falls back to on-demand replicas when\nspot replicas become unavailable. We built SkyServe, a system leveraging\nSpotHedge to efficiently serve AI models over a mixture of spot and on-demand\nreplicas across regions and clouds. We compared SkyServe with both research and\nproduction systems on real AI workloads: SkyServe reduces cost by 43% on\naverage while achieving high resource availability compared to using on-demand\nreplicas. Additionally, SkyServe improves P50, P90, and P99 latency by\n2.3$\\times$, 2.1$\\times$, 2.1$\\times$ on average compared to other research and\nproduction systems.",
      "tldr_zh": "该研究针对AI模型托管的高成本和服务需求，提出了一种名为SpotHedge的策略，利用spot instances跨不同故障域（如regions和clouds）来提升可用性并降低成本。SpotHedge通过智能分布spot replicas、过度提供副本作为抢占保障，以及动态切换到on-demand replicas，确保高服务质量。基于此，构建了SkyServe系统，能够在spot和on-demand replicas混合环境中高效服务AI模型。实验结果显示，SkyServe相较于使用on-demand replicas，平均降低成本43%，并将P50、P90和P99延迟分别提高2.3倍、2.1倍和2.1倍。",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "EuroSys 25'",
      "pdf_url": "http://arxiv.org/pdf/2411.01438v2",
      "published_date": "2024-11-03 05:00:53 UTC",
      "updated_date": "2025-03-03 22:39:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:48:45.874712"
    },
    {
      "arxiv_id": "2411.05819v1",
      "title": "Hierarchical Sentiment Analysis Framework for Hate Speech Detection: Implementing Binary and Multiclass Classification Strategy",
      "title_zh": "仇恨言论检测的分层情感分析框架：实现二元和多类分类策略",
      "authors": [
        "Faria Naznin",
        "Md Touhidur Rahman",
        "Shahran Rahman Alve"
      ],
      "abstract": "A significant challenge in automating hate speech detection on social media\nis distinguishing hate speech from regular and offensive language. These\nidentify an essential category of content that web filters seek to remove. Only\nautomated methods can manage this volume of daily data. To solve this problem,\nthe community of Natural Language Processing is currently investigating\ndifferent ways of hate speech detection. In addition to those, previous\napproaches (e.g., Convolutional Neural Networks, multi-channel BERT models, and\nlexical detection) have always achieved low precision without carefully\ntreating other related tasks like sentiment analysis and emotion\nclassification. They still like to group all messages with specific words in\nthem as hate speech simply because those terms often appear alongside hateful\nrhetoric. In this research, our paper presented the hate speech text\nclassification system model drawn upon deep learning and machine learning. In\nthis paper, we propose a new multitask model integrated with shared emotional\nrepresentations to detect hate speech across the English language. The\nTransformer-based model we used from Hugging Face and sentiment analysis helped\nus prevent false positives. Conclusion. We conclude that utilizing sentiment\nanalysis and a Transformer-based trained model considerably improves hate\nspeech detection across multiple datasets.",
      "tldr_zh": "本研究提出了一种分层情感分析框架（Hierarchical Sentiment Analysis Framework），旨在通过二元和多类分类策略改善社交媒体上的仇恨言论检测。该框架整合多任务模型、共享情感表示以及基于 Hugging Face 的 Transformer-based 模型，与情感分析相结合，以减少假阳性并更好地区分仇恨言论与常规或冒犯性语言。实验结果显示，这种方法在多个数据集上显著提升了检测精度，解决了传统方法如 Convolutional Neural Networks 和 BERT 模型的低精度问题。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "20 Pages",
      "pdf_url": "http://arxiv.org/pdf/2411.05819v1",
      "published_date": "2024-11-03 04:11:33 UTC",
      "updated_date": "2024-11-03 04:11:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:48:56.474385"
    },
    {
      "arxiv_id": "2411.01431v1",
      "title": "Efficient Deep Learning Infrastructures for Embedded Computing Systems: A Comprehensive Survey and Future Envision",
      "title_zh": "翻译失败",
      "authors": [
        "Xiangzhong Luo",
        "Di Liu",
        "Hao Kong",
        "Shuo Huai",
        "Hui Chen",
        "Guochu Xiong",
        "Weichen Liu"
      ],
      "abstract": "Deep neural networks (DNNs) have recently achieved impressive success across\na wide range of real-world vision and language processing tasks, spanning from\nimage classification to many other downstream vision tasks, such as object\ndetection, tracking, and segmentation. However, previous well-established DNNs,\ndespite being able to maintain superior accuracy, have also been evolving to be\ndeeper and wider and thus inevitably necessitate prohibitive computational\nresources for both training and inference. This trend further enlarges the\ncomputational gap between computation-intensive DNNs and resource-constrained\nembedded computing systems, making it challenging to deploy powerful DNNs upon\nreal-world embedded computing systems towards ubiquitous embedded intelligence.\nTo alleviate the above computational gap and enable ubiquitous embedded\nintelligence, we, in this survey, focus on discussing recent efficient deep\nlearning infrastructures for embedded computing systems, spanning from training\nto inference, from manual to automated, from convolutional neural networks to\ntransformers, from transformers to vision transformers, from vision models to\nlarge language models, from software to hardware, and from algorithms to\napplications. Specifically, we discuss recent efficient deep learning\ninfrastructures for embedded computing systems from the lens of (1) efficient\nmanual network design for embedded computing systems, (2) efficient automated\nnetwork design for embedded computing systems, (3) efficient network\ncompression for embedded computing systems, (4) efficient on-device learning\nfor embedded computing systems, (5) efficient large language models for\nembedded computing systems, (6) efficient deep learning software and hardware\nfor embedded computing systems, and (7) efficient intelligent applications for\nembedded computing systems.",
      "tldr_zh": "这篇论文对高效深度学习基础设施进行了全面调查，旨在解决深度神经网络 (DNNs) 在资源受限的嵌入式计算系统中的计算资源挑战，从而实现无处不在的嵌入式智能。论文从多个角度讨论了高效策略，包括高效手动网络设计、自动网络设计、网络压缩、设备端学习，以及针对大型语言模型 (LLMs) 和视觉变压器 (Vision Transformers) 的优化。论文还涵盖了深度学习软件、硬件支持以及智能应用的具体实现，并展望了未来发展方向，以缩小 DNNs 与嵌入式系统的计算差距。实验和分析为部署高效 DNNs 提供了宝贵指导。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ACM Transactions on Embedded Computing Systems (TECS) 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.01431v1",
      "published_date": "2024-11-03 03:55:04 UTC",
      "updated_date": "2024-11-03 03:55:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:49:09.571628"
    },
    {
      "arxiv_id": "2411.01425v1",
      "title": "Learning Hidden Subgoals under Temporal Ordering Constraints in Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Duo Xu",
        "Faramarz Fekri"
      ],
      "abstract": "In real-world applications, the success of completing a task is often\ndetermined by multiple key steps which are distant in time steps and have to be\nachieved in a fixed time order. For example, the key steps listed on the\ncooking recipe should be achieved one-by-one in the right time order. These key\nsteps can be regarded as subgoals of the task and their time orderings are\ndescribed as temporal ordering constraints. However, in many real-world\nproblems, subgoals or key states are often hidden in the state space and their\ntemporal ordering constraints are also unknown, which make it challenging for\nprevious RL algorithms to solve this kind of tasks. In order to address this\nissue, in this work we propose a novel RL algorithm for {\\bf l}earning hidden\n{\\bf s}ubgoals under {\\bf t}emporal {\\bf o}rdering {\\bf c}onstraints (LSTOC).\nWe propose a new contrastive learning objective which can effectively learn\nhidden subgoals (key states) and their temporal orderings at the same time,\nbased on first-occupancy representation and temporal geometric sampling. In\naddition, we propose a sample-efficient learning strategy to discover subgoals\none-by-one following their temporal order constraints by building a subgoal\ntree to represent discovered subgoals and their temporal ordering\nrelationships. Specifically, this tree can be used to improve the sample\nefficiency of trajectory collection, fasten the task solving and generalize to\nunseen tasks. The LSTOC framework is evaluated on several environments with\nimage-based observations, showing its significant improvement over baseline\nmethods.",
      "tldr_zh": "这篇论文针对强化学习(Reinforcement Learning)中隐藏子目标(subgoals)和时间顺序约束(temporal ordering constraints)的挑战，提出了一种新算法LSTOC。LSTOC通过一个新的对比学习目标，利用first-occupancy representation和temporal geometric sampling，同时学习隐藏子目标及其时间顺序，并构建子目标树(subgoal tree)来逐步发现子目标，提高样本效率和任务解决速度。实验在基于图像观察的环境中显示，LSTOC框架显著优于基线方法，在泛化到新任务方面也表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.01425v1",
      "published_date": "2024-11-03 03:22:39 UTC",
      "updated_date": "2024-11-03 03:22:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:49:21.762879"
    },
    {
      "arxiv_id": "2411.01423v1",
      "title": "Conditional Latent Space Molecular Scaffold Optimization for Accelerated Molecular Design",
      "title_zh": "翻译失败",
      "authors": [
        "Onur Boyar",
        "Hiroyuki Hanada",
        "Ichiro Takeuchi"
      ],
      "abstract": "The rapid discovery of new chemical compounds is essential for advancing\nglobal health and developing treatments. While generative models show promise\nin creating novel molecules, challenges remain in ensuring the real-world\napplicability of these molecules and finding such molecules efficiently. To\naddress this, we introduce Conditional Latent Space Molecular Scaffold\nOptimization (CLaSMO), which combines a Conditional Variational Autoencoder\n(CVAE) with Latent Space Bayesian Optimization (LSBO) to modify molecules\nstrategically while maintaining similarity to the original input. Our LSBO\nsetting improves the sample-efficiency of our optimization, and our\nmodification approach helps us to obtain molecules with higher chances of\nreal-world applicability. CLaSMO explores substructures of molecules in a\nsample-efficient manner by performing BO in the latent space of a CVAE\nconditioned on the atomic environment of the molecule to be optimized. Our\nexperiments demonstrate that CLaSMO efficiently enhances target properties with\nminimal substructure modifications, achieving state-of-the-art results with a\nsmaller model and dataset compared to existing methods. We also provide an\nopen-source web application that enables chemical experts to apply CLaSMO in a\nHuman-in-the-Loop setting.",
      "tldr_zh": "本研究提出了一种名为 Conditional Latent Space Molecular Scaffold Optimization (CLaSMO) 的方法，用于加速分子设计，以应对生成模型在分子实际应用性和效率方面的挑战。CLaSMO 结合了 Conditional Variational Autoencoder (CVAE) 和 Latent Space Bayesian Optimization (LSBO)，通过在 CVAE 的潜在空间中进行优化，实现对分子子结构的样本高效探索，同时保持与原分子的相似性。实验结果显示，该方法只需最小子结构修改即可高效提升目标属性，并在更小模型和数据集上达到最先进性能。此外，研究提供了一个开源网络应用，支持 Human-in-the-Loop 设置，便于化学专家应用。",
      "categories": [
        "q-bio.BM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.BM",
      "comment": "22 pages, 10 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2411.01423v1",
      "published_date": "2024-11-03 03:17:38 UTC",
      "updated_date": "2024-11-03 03:17:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:49:33.345925"
    },
    {
      "arxiv_id": "2411.01419v2",
      "title": "PSformer: Parameter-efficient Transformer with Segment Attention for Time Series Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Yanlong Wang",
        "Jian Xu",
        "Fei Ma",
        "Shao-Lun Huang",
        "Danny Dongning Sun",
        "Xiao-Ping Zhang"
      ],
      "abstract": "Time series forecasting remains a critical challenge across various domains,\noften complicated by high-dimensional data and long-term dependencies. This\npaper presents a novel transformer architecture for time series forecasting,\nincorporating two key innovations: parameter sharing (PS) and Spatial-Temporal\nSegment Attention (SegAtt). We also define the time series segment as the\nconcatenation of sequence patches from the same positions across different\nvariables. The proposed model, PSformer, reduces the number of training\nparameters through the parameter sharing mechanism, thereby improving model\nefficiency and scalability. The introduction of SegAtt could enhance the\ncapability of capturing local spatio-temporal dependencies by computing\nattention over the segments, and improve global representation by integrating\ninformation across segments. The combination of parameter sharing and SegAtt\nsignificantly improves the forecasting performance. Extensive experiments on\nbenchmark datasets demonstrate that PSformer outperforms popular baselines and\nother transformer-based approaches in terms of accuracy and scalability,\nestablishing itself as an accurate and scalable tool for time series\nforecasting.",
      "tldr_zh": "这篇论文针对时间序列预测中的高维数据和长期依赖性挑战，提出了一种新型Transformer架构PSformer。PSformer通过参数共享（Parameter Sharing）机制减少训练参数，从而提升模型效率和可扩展性；同时引入时空段注意（Spatial-Temporal Segment Attention, SegAtt），以捕捉局部时空依赖并整合全局信息。实验结果显示，PSformer在基准数据集上优于流行基线和其它Transformer模型，在准确性和可扩展性方面表现出显著优势。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "30 pages",
      "pdf_url": "http://arxiv.org/pdf/2411.01419v2",
      "published_date": "2024-11-03 03:04:00 UTC",
      "updated_date": "2025-02-11 09:50:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:49:44.748613"
    },
    {
      "arxiv_id": "2411.01417v1",
      "title": "BF-IMNA: A Bit Fluid In-Memory Neural Architecture for Neural Network Acceleration",
      "title_zh": "翻译失败",
      "authors": [
        "Mariam Rakka",
        "Rachid Karami",
        "Ahmed M. Eltawil",
        "Mohammed E. Fouda",
        "Fadi Kurdahi"
      ],
      "abstract": "Mixed-precision quantization works Neural Networks (NNs) are gaining traction\nfor their efficient realization on the hardware leading to higher throughput\nand lower energy. In-Memory Computing (IMC) accelerator architectures are\noffered as alternatives to traditional architectures relying on a data-centric\ncomputational paradigm, diminishing the memory wall problem, and scoring high\nthroughput and energy efficiency. These accelerators can support static\nfixed-precision but are not flexible to support mixed-precision NNs. In this\npaper, we present BF-IMNA, a bit fluid IMC accelerator for end-to-end\nConvolutional NN (CNN) inference that is capable of static and dynamic\nmixed-precision without any hardware reconfiguration overhead at run-time. At\nthe heart of BF-IMNA are Associative Processors (APs), which are bit-serial\nword-parallel Single Instruction, Multiple Data (SIMD)-like engines. We report\nthe performance of end-to-end inference of ImageNet on AlexNet, VGG16, and\nResNet50 on BF-IMNA for different technologies (eNVM and NVM), mixed-precision\nconfigurations, and supply voltages. To demonstrate bit fluidity, we implement\nHAWQ-V3's per-layer mixed-precision configurations for ResNet18 on BF-IMNA\nusing different latency budgets, and results reveal a trade-off between\naccuracy and Energy-Delay Product (EDP): On one hand, mixed-precision with a\nhigh latency constraint achieves the closest accuracy to fixed-precision INT8\nand reports a high (worse) EDP compared to fixed-precision INT4. On the other\nhand, with a low latency constraint, BF-IMNA reports the closest EDP to\nfixed-precision INT4, with a higher degradation in accuracy compared to\nfixed-precision INT8. We also show that BF-IMNA with fixed-precision\nconfiguration still delivers performance that is comparable to current\nstate-of-the-art accelerators: BF-IMNA achieves $20\\%$ higher energy efficiency\nand $2\\%$ higher throughput.",
      "tldr_zh": "本文提出 BF-IMNA，一种灵活的 In-Memory Computing (IMC) 架构，用于加速神经网络推理，支持静态和动态混合精度量化，而无需运行时硬件重新配置。核心组件为 Associative Processors (APs)，这些位串行、字并行的 SIMD-like 引擎实现了端到端 Convolutional NN (CNN) 推理，如在 ImageNet 上对 AlexNet、VGG16 和 ResNet50 的测试。实验结果显示，BF-IMNA 在不同技术（如 eNVM 和 NVM）和精度配置下，实现了精度与 Energy-Delay Product (EDP) 的权衡，并比现有加速器提高了 20% 的能量效率和 2% 的吞吐量。",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "primary_category": "cs.AR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.01417v1",
      "published_date": "2024-11-03 03:02:23 UTC",
      "updated_date": "2024-11-03 03:02:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:49:58.801544"
    },
    {
      "arxiv_id": "2411.01414v2",
      "title": "A Deep Dive Into Large Language Model Code Generation Mistakes: What and Why?",
      "title_zh": "翻译失败",
      "authors": [
        "QiHong Chen",
        "Jiachen Yu",
        "Jiawei Li",
        "Jiecheng Deng",
        "Justin Tian Jin Chen",
        "Iftekhar Ahmed"
      ],
      "abstract": "Recent advancements in Large Language Models (LLMs) have led to their\nwidespread application in automated code generation. However, these models can\nstill generate defective code that deviates from the specification. Previous\nresearch has mainly focused on the mistakes in LLM-generated standalone\nfunctions, overlooking real-world software development situations where the\nsuccessful generation of the code requires software contexts such as external\ndependencies. In this paper, we considered both of these code generation\nsituations and identified a range of \\textit{non-syntactic mistakes} arising\nfrom LLMs' misunderstandings of coding question specifications. Seven\ncategories of non-syntactic mistakes were identified through extensive manual\nanalyses, four of which were missed by previous works. To better understand\nthese mistakes, we proposed six reasons behind these mistakes from various\nperspectives. Moreover, we explored the effectiveness of LLMs in detecting\nmistakes and their reasons. Our evaluation demonstrated that GPT-4 with the\nReAct prompting technique can achieve an F1 score of up to 0.65 when\nidentifying reasons for LLM's mistakes, such as misleading function signatures.\nWe believe that these findings offer valuable insights into enhancing the\nquality of LLM-generated code.",
      "tldr_zh": "该研究深入探讨了Large Language Models (LLMs)在代码生成中的非语法错误，包括独立函数和软件上下文（如外部依赖）场景，识别了七类LLMs对编码规范误解导致的错误，其中四类为先前研究忽略。研究者通过手动分析提出了六种错误原因，从多个角度解释这些问题，并评估了LLMs检测错误及其原因的有效性。实验结果显示，使用GPT-4和ReAct提示技术，错误原因识别的F1 score可达0.65，这为提升LLM生成代码质量提供了重要启示。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.01414v2",
      "published_date": "2024-11-03 02:47:03 UTC",
      "updated_date": "2025-03-20 11:21:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:50:10.075385"
    },
    {
      "arxiv_id": "2411.01410v1",
      "title": "PageRank Bandits for Link Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Yikun Ban",
        "Jiaru Zou",
        "Zihao Li",
        "Yunzhe Qi",
        "Dongqi Fu",
        "Jian Kang",
        "Hanghang Tong",
        "Jingrui He"
      ],
      "abstract": "Link prediction is a critical problem in graph learning with broad\napplications such as recommender systems and knowledge graph completion.\nNumerous research efforts have been directed at solving this problem, including\napproaches based on similarity metrics and Graph Neural Networks (GNN).\nHowever, most existing solutions are still rooted in conventional supervised\nlearning, which makes it challenging to adapt over time to changing customer\ninterests and to address the inherent dilemma of exploitation versus\nexploration in link prediction. To tackle these challenges, this paper\nreformulates link prediction as a sequential decision-making process, where\neach link prediction interaction occurs sequentially. We propose a novel fusion\nalgorithm, PRB (PageRank Bandits), which is the first to combine contextual\nbandits with PageRank for collaborative exploitation and exploration. We also\nintroduce a new reward formulation and provide a theoretical performance\nguarantee for PRB. Finally, we extensively evaluate PRB in both online and\noffline settings, comparing it with bandit-based and graph-based methods. The\nempirical success of PRB demonstrates the value of the proposed fusion\napproach. Our code is released at https://github.com/jiaruzouu/PRB.",
      "tldr_zh": "本文将链接预测(Link Prediction)重新表述为顺序决策过程，以解决传统监督学习方法在适应变化和探索-利用困境方面的挑战。提出 PRB (PageRank Bandits) 算法，这是首次将上下文 Bandits 与 PageRank 结合，用于协作式探索和利用。算法引入新奖励公式，并提供理论性能保证。实验结果显示，PRB 在在线和离线设置中优于 Bandits 和图-based 方法，证明了这种融合方法的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.01410v1",
      "published_date": "2024-11-03 02:39:28 UTC",
      "updated_date": "2024-11-03 02:39:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:50:21.572781"
    },
    {
      "arxiv_id": "2411.02448v2",
      "title": "Rate, Explain and Cite (REC): Enhanced Explanation and Attribution in Automatic Evaluation by Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Aliyah R. Hsu",
        "James Zhu",
        "Zhichao Wang",
        "Bin Bi",
        "Shubham Mehrotra",
        "Shiva K. Pentyala",
        "Katherine Tan",
        "Xiang-Bo Mao",
        "Roshanak Omrani",
        "Sougata Chaudhuri",
        "Regunathan Radhakrishnan",
        "Sitaram Asur",
        "Claire Na Cheng",
        "Bin Yu"
      ],
      "abstract": "LLMs have demonstrated impressive proficiency in generating coherent and\nhigh-quality text, making them valuable across a range of text-generation\ntasks. However, rigorous evaluation of this generated content is crucial, as\nensuring its quality remains a significant challenge due to persistent issues\nsuch as factual inaccuracies and hallucination. This paper introduces three\nfine-tuned general-purpose LLM autoevaluators, REC-8B, REC-12B and REC-70B,\nspecifically designed to evaluate generated text across several dimensions:\nfaithfulness, instruction following, coherence, and completeness. These models\nnot only provide ratings for these metrics but also offer detailed explanation\nand verifiable citation, thereby enhancing trust in the content. Moreover, the\nmodels support various citation modes, accommodating different requirements for\nlatency and granularity. Extensive evaluations on diverse benchmarks\ndemonstrate that our general-purpose LLM auto-evaluator, REC-70B, outperforms\nstate-of-the-art LLMs, excelling in content evaluation by delivering better\nquality explanation and citation with minimal bias. It achieves Rank #1 as of\nFeb 15th, 2025 as a generative model on the RewardBench leaderboard under the\nmodel name TextEval-Llama3.1-70B. Our REC dataset and models are available at\nhttps://github.com/adelaidehsu/REC.",
      "tldr_zh": "这篇论文介绍了REC（Rate, Explain and Cite）系列微调LLM自动评估器，包括REC-8B、REC-12B和REC-70B，用于评估生成的文本在faithful（忠实度）、instruction following（指令遵循）、coherence（连贯性）和completeness（完整性）等维度上的质量。这些模型不仅提供评分，还生成详细解释和可验证引用，并支持多种引用模式以平衡延迟和粒度需求。在多基准评估中，REC-70B超越了最先进的LLM，提供更高质量的解释和引用，同时最小化偏差，并在RewardBench排行榜上排名第一（模型名为TextEval-Llama3.1-70B，截至2025年2月15日）。论文还开源了REC数据集和模型，供进一步研究使用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.02448v2",
      "published_date": "2024-11-03 02:36:33 UTC",
      "updated_date": "2025-02-19 00:50:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:50:34.181016"
    },
    {
      "arxiv_id": "2411.01408v1",
      "title": "HeightMapNet: Explicit Height Modeling for End-to-End HD Map Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Wenzhao Qiu",
        "Shanmin Pang",
        "Hao zhang",
        "Jianwu Fang",
        "Jianru Xue"
      ],
      "abstract": "Recent advances in high-definition (HD) map construction from surround-view\nimages have highlighted their cost-effectiveness in deployment. However,\nprevailing techniques often fall short in accurately extracting and utilizing\nroad features, as well as in the implementation of view transformation. In\nresponse, we introduce HeightMapNet, a novel framework that establishes a\ndynamic relationship between image features and road surface height\ndistributions. By integrating height priors, our approach refines the accuracy\nof Bird's-Eye-View (BEV) features beyond conventional methods. HeightMapNet\nalso introduces a foreground-background separation network that sharply\ndistinguishes between critical road elements and extraneous background\ncomponents, enabling precise focus on detailed road micro-features.\nAdditionally, our method leverages multi-scale features within the BEV space,\noptimally utilizing spatial geometric information to boost model performance.\nHeightMapNet has shown exceptional results on the challenging nuScenes and\nArgoverse 2 datasets, outperforming several widely recognized approaches. The\ncode will be available at \\url{https://github.com/adasfag/HeightMapNet/}.",
      "tldr_zh": "该论文提出 HeightMapNet，一种端到端的 HD Map 学习框架，通过显式高度建模建立图像特征与道路表面高度分布的动态关系，并整合高度先验来提升 Bird's-Eye-View (BEV) 特征的准确性。该框架还引入前景-背景分离网络，以精确区分关键道路元素和无关背景，并利用 BEV 空间的多尺度特征优化空间几何信息，从而改善道路特征提取和视图转换。实验结果显示，HeightMapNet 在 nuScenes 和 Argoverse 2 数据集上超越多项知名方法，展示了其在高精度地图构建中的优越性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "This paper has been accepted to WACV 2025",
      "pdf_url": "http://arxiv.org/pdf/2411.01408v1",
      "published_date": "2024-11-03 02:35:17 UTC",
      "updated_date": "2024-11-03 02:35:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:50:45.359100"
    },
    {
      "arxiv_id": "2411.01401v1",
      "title": "Pre-trained Molecular Language Models with Random Functional Group Masking",
      "title_zh": "预训练分子语言模型采用随机官能团掩码",
      "authors": [
        "Tianhao Peng",
        "Yuchen Li",
        "Xuhong Li",
        "Jiang Bian",
        "Zeke Xie",
        "Ning Sui",
        "Shahid Mumtaz",
        "Yanwu Xu",
        "Linghe Kong",
        "Haoyi Xiong"
      ],
      "abstract": "Recent advancements in computational chemistry have leveraged the power of\ntrans-former-based language models, such as MoLFormer, pre-trained using a vast\namount of simplified molecular-input line-entry system (SMILES) sequences, to\nunderstand and predict molecular properties and activities, a critical step in\nfields like drug discovery and materials science. To further improve\nperformance, researchers have introduced graph neural networks with graph-based\nmolecular representations, such as GEM, incorporating the topology, geometry,\n2D or even 3D structures of molecules into pre-training. While most of\nmolecular graphs in existing studies were automatically converted from SMILES\nsequences, it is to assume that transformer-based language models might be able\nto implicitly learn structure-aware representations from SMILES sequences. In\nthis paper, we propose \\ours{} -- a SMILES-based \\underline{\\em M}olecular\n\\underline{\\em L}anguage \\underline{\\em M}odel, which randomly masking SMILES\nsubsequences corresponding to specific molecular \\underline{\\em F}unctional\n\\underline{\\em G}roups to incorporate structure information of atoms during the\npre-training phase. This technique aims to compel the model to better infer\nmolecular structures and properties, thus enhancing its predictive\ncapabilities. Extensive experimental evaluations across 11 benchmark\nclassification and regression tasks in the chemical domain demonstrate the\nrobustness and superiority of \\ours{}. Our findings reveal that \\ours{}\noutperforms existing pre-training models, either based on SMILES or graphs, in\n9 out of the 11 downstream tasks, ranking as a close second in the remaining\nones.",
      "tldr_zh": "本论文提出了一种新的预训练分子语言模型 \\ours{}，通过随机 masking SMILES 序列中对应特定分子 Functional Groups 的子序列，旨在帮助模型更好地融入原子结构信息，从而提升对分子属性和结构的预测能力。与现有基于 SMILES 或图神经网络（如 MoLFormer 和 GEM）的模型相比，\\ours{} 在 11 个化学领域基准任务中表现出色，在 9 个任务上取得优异性能，仅在剩余 2 个任务中排名第二。实验结果证明了该方法的鲁棒性和有效性，为药物发现和材料科学等领域提供了更强大的工具。",
      "categories": [
        "q-bio.BM",
        "cs.AI",
        "cs.LG",
        "physics.chem-ph"
      ],
      "primary_category": "q-bio.BM",
      "comment": "Under review",
      "pdf_url": "http://arxiv.org/pdf/2411.01401v1",
      "published_date": "2024-11-03 01:56:15 UTC",
      "updated_date": "2024-11-03 01:56:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:50:58.172894"
    },
    {
      "arxiv_id": "2411.02446v1",
      "title": "Learning World Models for Unconstrained Goal Navigation",
      "title_zh": "翻译失败",
      "authors": [
        "Yuanlin Duan",
        "Wensen Mao",
        "He Zhu"
      ],
      "abstract": "Learning world models offers a promising avenue for goal-conditioned\nreinforcement learning with sparse rewards. By allowing agents to plan actions\nor exploratory goals without direct interaction with the environment, world\nmodels enhance exploration efficiency. The quality of a world model hinges on\nthe richness of data stored in the agent's replay buffer, with expectations of\nreasonable generalization across the state space surrounding recorded\ntrajectories. However, challenges arise in generalizing learned world models to\nstate transitions backward along recorded trajectories or between states across\ndifferent trajectories, hindering their ability to accurately model real-world\ndynamics. To address these challenges, we introduce a novel goal-directed\nexploration algorithm, MUN (short for \"World Models for Unconstrained Goal\nNavigation\"). This algorithm is capable of modeling state transitions between\narbitrary subgoal states in the replay buffer, thereby facilitating the\nlearning of policies to navigate between any \"key\" states. Experimental results\ndemonstrate that MUN strengthens the reliability of world models and\nsignificantly improves the policy's capacity to generalize across new goal\nsettings.",
      "tldr_zh": "该论文探讨了在稀疏奖励条件下，通过学习世界模型（world models）来提升目标条件强化学习（reinforcement learning）的效率，但强调了世界模型在泛化方面面临的挑战，如处理录制轨迹的逆向转换或不同轨迹间状态。作者引入了 MUN（World Models for Unconstrained Goal Navigation）算法，这是一种新型目标导向探索方法，能建模重放缓冲区中任意子目标状态间的转换，从而增强世界模型的可靠性。实验结果显示，MUN 显著提高了策略在新目标设置下的泛化能力，为无约束目标导航提供了更有效的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS2024 Poster. arXiv admin note: substantial text overlap with\n  arXiv:2411.01396",
      "pdf_url": "http://arxiv.org/pdf/2411.02446v1",
      "published_date": "2024-11-03 01:35:06 UTC",
      "updated_date": "2024-11-03 01:35:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:51:08.679685"
    },
    {
      "arxiv_id": "2411.10463v3",
      "title": "Unexploited Information Value in Human-AI Collaboration",
      "title_zh": "翻译失败",
      "authors": [
        "Ziyang Guo",
        "Yifan Wu",
        "Jason Hartline",
        "Jessica Hullman"
      ],
      "abstract": "Humans and AIs are often paired on decision tasks with the expectation of\nachieving complementary performance -- where the combination of human and AI\noutperforms either one alone. However, how to improve performance of a human-AI\nteam is often not clear without knowing more about what particular information\nand strategies each agent employs. In this paper, we propose a model based in\nstatistical decision theory to analyze human-AI collaboration from the\nperspective of what information could be used to improve a human or AI\ndecision. We demonstrate our model on a deepfake detection task to investigate\nseven video-level features by their unexploited value of information. We\ncompare the human alone, AI alone and human-AI team and offer insights on how\nthe AI assistance impacts people's usage of the information and what\ninformation that the AI exploits well might be useful for improving human\ndecisions.",
      "tldr_zh": "该论文探讨了人类和 AI 在决策任务中的协作问题，提出一个基于 statistical decision theory 的模型，来分析未被充分利用的信息价值。该模型应用于 deepfake detection 任务，调查七个视频级特征，并比较人类单独、AI 单独以及人类-AI 团队的表现。通过实验，论文揭示了 AI 辅助如何影响人类的信息使用，并指出 AI 擅长的信息可用于改善人类决策，从而提升整体协作效率。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "We withdraw this version and direct readers to the updated version\n  available on arXiv. See the new version at arXiv:2502.06152",
      "pdf_url": "http://arxiv.org/pdf/2411.10463v3",
      "published_date": "2024-11-03 01:34:45 UTC",
      "updated_date": "2025-02-24 20:06:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:51:21.033697"
    },
    {
      "arxiv_id": "2411.01396v1",
      "title": "Exploring the Edges of Latent State Clusters for Goal-Conditioned Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Yuanlin Duan",
        "Guofeng Cui",
        "He Zhu"
      ],
      "abstract": "Exploring unknown environments efficiently is a fundamental challenge in\nunsupervised goal-conditioned reinforcement learning. While selecting\nexploratory goals at the frontier of previously explored states is an effective\nstrategy, the policy during training may still have limited capability of\nreaching rare goals on the frontier, resulting in reduced exploratory behavior.\nWe propose \"Cluster Edge Exploration\" ($CE^2$), a new goal-directed exploration\nalgorithm that when choosing goals in sparsely explored areas of the state\nspace gives priority to goal states that remain accessible to the agent. The\nkey idea is clustering to group states that are easily reachable from one\nanother by the current policy under training in a latent space and traversing\nto states holding significant exploration potential on the boundary of these\nclusters before doing exploratory behavior. In challenging robotics\nenvironments including navigating a maze with a multi-legged ant robot,\nmanipulating objects with a robot arm on a cluttered tabletop, and rotating\nobjects in the palm of an anthropomorphic robotic hand, $CE^2$ demonstrates\nsuperior efficiency in exploration compared to baseline methods and ablations.",
      "tldr_zh": "该论文探讨了在无监督的目标条件强化学习(Goal-Conditioned Reinforcement Learning)中，如何高效探索未知环境的问题，特别是当前政策可能无法到达前沿稀有目标导致探索效率降低。作者提出了一种新算法Cluster Edge Exploration ($CE^2$)，通过在潜在空间(latent space)中聚类状态，将容易相互到达的状态分组，并优先选择这些聚类边界上的可达目标，以提升探索潜力。实验结果显示，在包括蚂蚁机器人导航迷宫、机器人臂操作杂乱物体以及人形机器人手旋转物体的挑战性环境中，$CE^2$ 比基线方法表现出更高的探索效率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS2024 Poster",
      "pdf_url": "http://arxiv.org/pdf/2411.01396v1",
      "published_date": "2024-11-03 01:21:43 UTC",
      "updated_date": "2024-11-03 01:21:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T20:53:33.909143"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 59,
  "processed_papers_count": 59,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-20T20:53:51.805506"
}