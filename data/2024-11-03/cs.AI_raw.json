[
  {
    "arxiv_id": "2411.01707v1",
    "title": "Large-Scale Multi-Robot Coverage Path Planning on Grids with Path Deconfliction",
    "authors": [
      "Jingtao Tang",
      "Zining Mao",
      "Hang Ma"
    ],
    "abstract": "We study Multi-Robot Coverage Path Planning (MCPP) on a 4-neighbor 2D grid G,\nwhich aims to compute paths for multiple robots to cover all cells of G.\nTraditional approaches are limited as they first compute coverage trees on a\nquadrant coarsened grid H and then employ the Spanning Tree Coverage (STC)\nparadigm to generate paths on G, making them inapplicable to grids with\npartially obstructed 2x2 blocks. To address this limitation, we reformulate the\nproblem directly on G, revolutionizing grid-based MCPP solving and establishing\nnew NP-hardness results. We introduce Extended-STC (ESTC), a novel paradigm\nthat extends STC to ensure complete coverage with bounded suboptimality, even\nwhen H includes partially obstructed blocks. Furthermore, we present LS-MCPP, a\nnew algorithmic framework that integrates ESTC with three novel types of\nneighborhood operators within a local search strategy to optimize coverage\npaths directly on G. Unlike prior grid-based MCPP work, our approach also\nincorporates a versatile post-processing procedure that applies Multi-Agent\nPath Finding (MAPF) techniques to MCPP for the first time, enabling a fusion of\nthese two important fields in multi-robot coordination. This procedure\neffectively resolves inter-robot conflicts and accommodates turning costs by\nsolving a MAPF variant, making our MCPP solutions more practical for real-world\napplications. Extensive experiments demonstrate that our approach significantly\nimproves solution quality and efficiency, managing up to 100 robots on grids as\nlarge as 256x256 within minutes of runtime. Validation with physical robots\nconfirms the feasibility of our solutions under real-world conditions.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Submitted to T-RO",
    "pdf_url": "http://arxiv.org/pdf/2411.01707v1",
    "published_date": "2024-11-03 22:37:56 UTC",
    "updated_date": "2024-11-03 22:37:56 UTC"
  },
  {
    "arxiv_id": "2411.01703v2",
    "title": "UniGuard: Towards Universal Safety Guardrails for Jailbreak Attacks on Multimodal Large Language Models",
    "authors": [
      "Sejoon Oh",
      "Yiqiao Jin",
      "Megha Sharma",
      "Donghyun Kim",
      "Eric Ma",
      "Gaurav Verma",
      "Srijan Kumar"
    ],
    "abstract": "Multimodal large language models (MLLMs) have revolutionized vision-language\nunderstanding but remain vulnerable to multimodal jailbreak attacks, where\nadversarial inputs are meticulously crafted to elicit harmful or inappropriate\nresponses. We propose UniGuard, a novel multimodal safety guardrail that\njointly considers the unimodal and cross-modal harmful signals. UniGuard trains\na multimodal guardrail to minimize the likelihood of generating harmful\nresponses in a toxic corpus. The guardrail can be seamlessly applied to any\ninput prompt during inference with minimal computational costs. Extensive\nexperiments demonstrate the generalizability of UniGuard across multiple\nmodalities, attack strategies, and multiple state-of-the-art MLLMs, including\nLLaVA, Gemini Pro, GPT-4o, MiniGPT-4, and InstructBLIP. Notably, this robust\ndefense mechanism maintains the models' overall vision-language understanding\ncapabilities.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "14 pages",
    "pdf_url": "http://arxiv.org/pdf/2411.01703v2",
    "published_date": "2024-11-03 22:19:20 UTC",
    "updated_date": "2025-01-31 16:47:16 UTC"
  },
  {
    "arxiv_id": "2411.01702v1",
    "title": "Symmetry Adapted Residual Neural Network Diabatization: Conical Intersections in Aniline Photodissociation",
    "authors": [
      "Yifan Shen",
      "David Yarkony"
    ],
    "abstract": "We present a symmetry adapted residual neural network (SAResNet)\ndiabatization method to construct quasi-diabatic Hamiltonians that accurately\nrepresent ab initio adiabatic energies, energy gradients, and nonadiabatic\ncouplings for moderate sized systems. Our symmetry adapted neural network\ninherits from the pioneering symmetry adapted polynomial and fundamental\ninvariant neural network diabatization methods to exploit the power of neural\nnetwork along with the transparent symmetry adaptation of polynomial for both\nsymmetric and asymmetric irreducible representations. In addition, our symmetry\nadaptation provides a unified framework for symmetry adapted polynomial and\nsymmetry adapted neural network, enabling the adoption of the residual neural\nnetwork architecture, which is a powerful descendant of the pioneering\nfeedforward neural network. Our SAResNet is applied to construct the full\n36-dimensional coupled diabatic potential energy surfaces for aniline N-H bond\nphotodissociation, with 2,269 data points and 32,640 trainable parameters and\n190 cm-1 root mean square deviation in energy. In addition to the\nexperimentally observed {\\pi}{\\pi}* and {\\pi}Rydberg/{\\pi}{\\sigma}* states, a\nhigher state (HOMO - 1 {\\pi} to Rydberg/{\\sigma}* excitation) is found to\nintroduce an induced geometric phase effect thus indirectly participate in the\nphotodissociation process.",
    "categories": [
      "physics.chem-ph",
      "cs.AI"
    ],
    "primary_category": "physics.chem-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.01702v1",
    "published_date": "2024-11-03 21:56:25 UTC",
    "updated_date": "2024-11-03 21:56:25 UTC"
  },
  {
    "arxiv_id": "2411.02455v1",
    "title": "An Exploration of Higher Education Course Evaluation by Large Language Models",
    "authors": [
      "Bo Yuan",
      "Jiazi Hu"
    ],
    "abstract": "Course evaluation is a critical component in higher education pedagogy. It\nnot only serves to identify limitations in existing course designs and provide\na basis for curricular innovation, but also to offer quantitative insights for\nuniversity administrative decision-making. Traditional evaluation methods,\nprimarily comprising student surveys, instructor self-assessments, and expert\nreviews, often encounter challenges, including inherent subjectivity, feedback\ndelays, inefficiencies, and limitations in addressing innovative teaching\napproaches. Recent advancements in large language models (LLMs) within\nartificial intelligence (AI) present promising new avenues for enhancing course\nevaluation processes. This study explores the application of LLMs in automated\ncourse evaluation from multiple perspectives and conducts rigorous experiments\nacross 100 courses at a major university in China. The findings indicate that:\n(1) LLMs can be an effective tool for course evaluation; (2) their\neffectiveness is contingent upon appropriate fine-tuning and prompt\nengineering; and (3) LLM-generated evaluation results demonstrate a notable\nlevel of rationality and interpretability.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.02455v1",
    "published_date": "2024-11-03 20:43:52 UTC",
    "updated_date": "2024-11-03 20:43:52 UTC"
  },
  {
    "arxiv_id": "2411.05820v1",
    "title": "Guiding Genetic Programming with Graph Neural Networks",
    "authors": [
      "Piotr Wyrwi≈Ñski",
      "Krzysztof Krawiec"
    ],
    "abstract": "In evolutionary computation, it is commonly assumed that a search algorithm\nacquires knowledge about a problem instance by sampling solutions from the\nsearch space and evaluating them with a fitness function. This is necessarily\ninefficient because fitness reveals very little about solutions -- yet they\ncontain more information that can be potentially exploited. To address this\nobservation in genetic programming, we propose EvoNUDGE, which uses a graph\nneural network to elicit additional knowledge from symbolic regression\nproblems. The network is queried on the problem before an evolutionary run to\nproduce a library of subprograms, which is subsequently used to seed the\ninitial population and bias the actions of search operators. In an extensive\nexperiment on a large number of problem instances, EvoNUDGE is shown to\nsignificantly outperform multiple baselines, including the conventional\ntree-based genetic programming and the purely neural variant of the method.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG",
      "cs.SC",
      "stat.ML"
    ],
    "primary_category": "cs.NE",
    "comment": "Full version of the same-titled paper accepted at GECCO 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.05820v1",
    "published_date": "2024-11-03 20:43:31 UTC",
    "updated_date": "2024-11-03 20:43:31 UTC"
  },
  {
    "arxiv_id": "2411.02454v1",
    "title": "Graph-based Confidence Calibration for Large Language Models",
    "authors": [
      "Yukun Li",
      "Sijia Wang",
      "Lifu Huang",
      "Li-Ping Liu"
    ],
    "abstract": "One important approach to improving the reliability of large language models\n(LLMs) is to provide accurate confidence estimations regarding the correctness\nof their answers. However, developing a well-calibrated confidence estimation\nmodel is challenging, as mistakes made by LLMs can be difficult to detect. We\npropose a novel method combining the LLM's self-consistency with labeled data\nand training an auxiliary model to estimate the correctness of its responses to\nquestions. This auxiliary model predicts the correctness of responses based\nsolely on their consistent information. To set up the learning problem, we use\na weighted graph to represent the consistency among the LLM's multiple\nresponses to a question. Correctness labels are assigned to these responses\nbased on their similarity to the correct answer. We then train a graph neural\nnetwork to estimate the probability of correct responses. Experiments\ndemonstrate that the proposed approach substantially outperforms several of the\nmost recent methods in confidence calibration across multiple widely adopted\nbenchmark datasets. Furthermore, the proposed approach significantly improves\nthe generalization capability of confidence calibration on out-of-domain (OOD)\ndata.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.02454v1",
    "published_date": "2024-11-03 20:36:44 UTC",
    "updated_date": "2024-11-03 20:36:44 UTC"
  },
  {
    "arxiv_id": "2411.01663v1",
    "title": "Unlocking the Theory Behind Scaling 1-Bit Neural Networks",
    "authors": [
      "Majid Daliri",
      "Zhao Song",
      "Chiwun Yang"
    ],
    "abstract": "Recently, 1-bit Large Language Models (LLMs) have emerged, showcasing an\nimpressive combination of efficiency and performance that rivals traditional\nLLMs. Research by Wang et al. (2023); Ma et al. (2024) indicates that the\nperformance of these 1-bit LLMs progressively improves as the number of\nparameters increases, hinting at the potential existence of a Scaling Law for\n1-bit Neural Networks. In this paper, we present the first theoretical result\nthat rigorously establishes this scaling law for 1-bit models. We prove that,\ndespite the constraint of weights restricted to $\\{-1, +1\\}$, the dynamics of\nmodel training inevitably align with kernel behavior as the network width\ngrows. This theoretical breakthrough guarantees convergence of the 1-bit model\nto an arbitrarily small loss as width increases. Furthermore, we introduce the\nconcept of the generalization difference, defined as the gap between the\noutputs of 1-bit networks and their full-precision counterparts, and\ndemonstrate that this difference maintains a negligible level as network width\nscales. Building on the work of Kaplan et al. (2020), we conclude by examining\nhow the training loss scales as a power-law function of the model size, dataset\nsize, and computational resources utilized for training. Our findings\nunderscore the promising potential of scaling 1-bit neural networks, suggesting\nthat int1 could become the standard in future neural network precision.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CC",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.01663v1",
    "published_date": "2024-11-03 19:18:57 UTC",
    "updated_date": "2024-11-03 19:18:57 UTC"
  },
  {
    "arxiv_id": "2411.01661v2",
    "title": "Sing-On-Your-Beat: Simple Text-Controllable Accompaniment Generations",
    "authors": [
      "Quoc-Huy Trinh",
      "Minh-Van Nguyen",
      "Trong-Hieu Nguyen Mau",
      "Khoa Tran",
      "Thanh Do"
    ],
    "abstract": "Singing is one of the most cherished forms of human entertainment. However,\ncreating a beautiful song requires an accompaniment that complements the vocals\nand aligns well with the song instruments and genre. With advancements in deep\nlearning, previous research has focused on generating suitable accompaniments\nbut often lacks precise alignment with the desired instrumentation and genre.\nTo address this, we propose a straightforward method that enables control over\nthe accompaniment through text prompts, allowing the generation of music that\ncomplements the vocals and aligns with the song instrumental and genre\nrequirements. Through extensive experiments, we successfully generate 10-second\naccompaniments using vocal input and text control.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.01661v2",
    "published_date": "2024-11-03 19:17:20 UTC",
    "updated_date": "2024-11-12 22:10:55 UTC"
  },
  {
    "arxiv_id": "2411.03348v2",
    "title": "Undermining Image and Text Classification Algorithms Using Adversarial Attacks",
    "authors": [
      "Langalibalele Lunga",
      "Suhas Sreehari"
    ],
    "abstract": "Machine learning models are prone to adversarial attacks, where inputs can be\nmanipulated in order to cause misclassifications. While previous research has\nfocused on techniques like Generative Adversarial Networks (GANs), there's\nlimited exploration of GANs and Synthetic Minority Oversampling Technique\n(SMOTE) in text and image classification models to perform adversarial attacks.\nOur study addresses this gap by training various machine learning models and\nusing GANs and SMOTE to generate additional data points aimed at attacking text\nclassification models. Furthermore, we extend our investigation to face\nrecognition models, training a Convolutional Neural Network(CNN) and subjecting\nit to adversarial attacks with fast gradient sign perturbations on key features\nidentified by GradCAM, a technique used to highlight key image characteristics\nCNNs use in classification. Our experiments reveal a significant vulnerability\nin classification models. Specifically, we observe a 20 % decrease in accuracy\nfor the top-performing text classification models post-attack, along with a 30\n% decrease in facial recognition accuracy. This highlights the susceptibility\nof these models to manipulation of input data. Adversarial attacks not only\ncompromise the security but also undermine the reliability of machine learning\nsystems. By showcasing the impact of adversarial attacks on both text\nclassification and face recognition models, our study underscores the urgent\nneed for develop robust defenses against such vulnerabilities.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "Accepted for presentation at Electronic Imaging Conference 2025",
    "pdf_url": "http://arxiv.org/pdf/2411.03348v2",
    "published_date": "2024-11-03 18:44:28 UTC",
    "updated_date": "2024-11-07 04:05:58 UTC"
  },
  {
    "arxiv_id": "2411.11869v1",
    "title": "A Multi-Modal Unsupervised Machine Learning Approach for Biomedical Signal Processing in CPR",
    "authors": [
      "Saidul Islam",
      "Jamal Bentahar",
      "Robin Cohen",
      "Gaith Rjoub"
    ],
    "abstract": "Cardiopulmonary resuscitation (CPR) is a critical, life-saving intervention\naimed at restoring blood circulation and breathing in individuals experiencing\ncardiac arrest or respiratory failure. Accurate and real-time analysis of\nbiomedical signals during CPR is essential for monitoring and decision-making,\nfrom the pre-hospital stage to the intensive care unit (ICU). However, CPR\nsignals are often corrupted by noise and artifacts, making precise\ninterpretation challenging. Traditional denoising methods, such as filters,\nstruggle to adapt to the varying and complex noise patterns present in CPR\nsignals. Given the high-stakes nature of CPR, where rapid and accurate\nresponses can determine survival, there is a pressing need for more robust and\nadaptive denoising techniques. In this context, an unsupervised machine\nlearning (ML) methodology is particularly valuable, as it removes the\ndependence on labeled data, which can be scarce or impractical in emergency\nscenarios. This paper introduces a novel unsupervised ML approach for denoising\nCPR signals using a multi-modality framework, which leverages multiple signal\nsources to enhance the denoising process. The proposed approach not only\nimproves noise reduction and signal fidelity but also preserves critical\ninter-signal correlations (0.9993) which is crucial for downstream tasks.\nFurthermore, it outperforms existing methods in an unsupervised context in\nterms of signal-to-noise ratio (SNR) and peak signal-to-noise ratio (PSNR),\nmaking it highly effective for real-time applications. The integration of\nmulti-modality further enhances the system's adaptability to various biomedical\nsignals beyond CPR, improving both automated CPR systems and clinical\ndecision-making.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.11869v1",
    "published_date": "2024-11-03 18:40:25 UTC",
    "updated_date": "2024-11-03 18:40:25 UTC"
  },
  {
    "arxiv_id": "2411.01653v1",
    "title": "Diagnosing Medical Datasets with Training Dynamics",
    "authors": [
      "Laura Wenderoth"
    ],
    "abstract": "This study explores the potential of using training dynamics as an automated\nalternative to human annotation for evaluating the quality of training data.\nThe framework used is Data Maps, which classifies data points into categories\nsuch as easy-to-learn, hard-to-learn, and ambiguous (Swayamdipta et al., 2020).\nSwayamdipta et al. (2020) highlight that difficult-to-learn examples often\ncontain errors, and ambiguous cases significantly impact model training. To\nconfirm the reliability of these findings, we replicated the experiments using\na challenging dataset, with a focus on medical question answering. In addition\nto text comprehension, this field requires the acquisition of detailed medical\nknowledge, which further complicates the task. A comprehensive evaluation was\nconducted to assess the feasibility and transferability of the Data Maps\nframework to the medical domain. The evaluation indicates that the framework is\nunsuitable for addressing datasets' unique challenges in answering medical\nquestions.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "https://github.com/LauraWenderoth/training-dynamics",
    "pdf_url": "http://arxiv.org/pdf/2411.01653v1",
    "published_date": "2024-11-03 18:37:35 UTC",
    "updated_date": "2024-11-03 18:37:35 UTC"
  },
  {
    "arxiv_id": "2411.01652v1",
    "title": "Optimizing Gastrointestinal Diagnostics: A CNN-Based Model for VCE Image Classification",
    "authors": [
      "Vaneeta Ahlawat",
      "Rohit Sharma",
      "Urush"
    ],
    "abstract": "In recent years, the diagnosis of gastrointestinal (GI) diseases has advanced\ngreatly with the advent of high-tech video capsule endoscopy (VCE) technology,\nwhich allows for non-invasive observation of the digestive system. The MisaHub\nCapsule Vision Challenge encourages the development of vendor-independent\nartificial intelligence models that can autonomously classify GI anomalies from\nVCE images. This paper presents CNN architecture designed specifically for\nmulticlass classification of ten gut pathologies, including angioectasia,\nbleeding, erosion, erythema, foreign bodies, lymphangiectasia, polyps, ulcers,\nand worms as well as their normal state.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "11 pages, 7 figuers",
    "pdf_url": "http://arxiv.org/pdf/2411.01652v1",
    "published_date": "2024-11-03 18:30:37 UTC",
    "updated_date": "2024-11-03 18:30:37 UTC"
  },
  {
    "arxiv_id": "2411.03131v1",
    "title": "Machine Learning Innovations in CPR: A Comprehensive Survey on Enhanced Resuscitation Techniques",
    "authors": [
      "Saidul Islam",
      "Gaith Rjoub",
      "Hanae Elmekki",
      "Jamal Bentahar",
      "Witold Pedrycz",
      "Robin Cohen"
    ],
    "abstract": "This survey paper explores the transformative role of Machine Learning (ML)\nand Artificial Intelligence (AI) in Cardiopulmonary Resuscitation (CPR). It\nexamines the evolution from traditional CPR methods to innovative ML-driven\napproaches, highlighting the impact of predictive modeling, AI-enhanced\ndevices, and real-time data analysis in improving resuscitation outcomes. The\npaper provides a comprehensive overview, classification, and critical analysis\nof current applications, challenges, and future directions in this emerging\nfield.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.03131v1",
    "published_date": "2024-11-03 18:01:50 UTC",
    "updated_date": "2024-11-03 18:01:50 UTC"
  },
  {
    "arxiv_id": "2411.01647v1",
    "title": "Optical Flow Representation Alignment Mamba Diffusion Model for Medical Video Generation",
    "authors": [
      "Zhenbin Wang",
      "Lei Zhang",
      "Lituan Wang",
      "Minjuan Zhu",
      "Zhenwei Zhang"
    ],
    "abstract": "Medical video generation models are expected to have a profound impact on the\nhealthcare industry, including but not limited to medical education and\ntraining, surgical planning, and simulation. Current video diffusion models\ntypically build on image diffusion architecture by incorporating temporal\noperations (such as 3D convolution and temporal attention). Although this\napproach is effective, its oversimplification limits spatio-temporal\nperformance and consumes substantial computational resources. To counter this,\nwe propose Medical Simulation Video Generator (MedSora), which incorporates\nthree key elements: i) a video diffusion framework integrates the advantages of\nattention and Mamba, balancing low computational load with high-quality video\ngeneration, ii) an optical flow representation alignment method that implicitly\nenhances attention to inter-frame pixels, and iii) a video variational\nautoencoder (VAE) with frequency compensation addresses the information loss of\nmedical features that occurs when transforming pixel space into latent features\nand then back to pixel frames. Extensive experiments and applications\ndemonstrate that MedSora exhibits superior visual quality in generating medical\nvideos, outperforming the most advanced baseline methods. Further results and\ncode are available at https://wongzbb.github.io/MedSora",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.01647v1",
    "published_date": "2024-11-03 17:57:00 UTC",
    "updated_date": "2024-11-03 17:57:00 UTC"
  },
  {
    "arxiv_id": "2411.01645v2",
    "title": "Enriching Tabular Data with Contextual LLM Embeddings: A Comprehensive Ablation Study for Ensemble Classifiers",
    "authors": [
      "Gjergji Kasneci",
      "Enkelejda Kasneci"
    ],
    "abstract": "Feature engineering is crucial for optimizing machine learning model\nperformance, particularly in tabular data classification tasks. Leveraging\nadvancements in natural language processing, this study presents a systematic\napproach to enrich tabular datasets with features derived from large language\nmodel embeddings. Through a comprehensive ablation study on diverse datasets,\nwe assess the impact of RoBERTa and GPT-2 embeddings on ensemble classifiers,\nincluding Random Forest, XGBoost, and CatBoost. Results indicate that\nintegrating embeddings with traditional numerical and categorical features\noften enhances predictive performance, especially on datasets with class\nimbalance or limited features and samples, such as UCI Adult, Heart Disease,\nTitanic, and Pima Indian Diabetes, with improvements particularly notable in\nXGBoost and CatBoost classifiers. Additionally, feature importance analysis\nreveals that LLM-derived features frequently rank among the most impactful for\nthe predictions. This study provides a structured approach to embedding-based\nfeature enrichment and illustrates its benefits in ensemble learning for\ntabular data.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.01645v2",
    "published_date": "2024-11-03 17:45:00 UTC",
    "updated_date": "2024-11-05 21:02:11 UTC"
  },
  {
    "arxiv_id": "2411.01643v1",
    "title": "EcoAct: Economic Agent Determines When to Register What Action",
    "authors": [
      "Shaokun Zhang",
      "Jieyu Zhang",
      "Dujian Ding",
      "Mirian Hipolito Garcia",
      "Ankur Mallick",
      "Daniel Madrigal",
      "Menglin Xia",
      "Victor R√ºhle",
      "Qingyun Wu",
      "Chi Wang"
    ],
    "abstract": "Recent advancements have enabled Large Language Models (LLMs) to function as\nagents that can perform actions using external tools. This requires\nregistering, i.e., integrating tool information into the LLM context prior to\ntaking actions. Current methods indiscriminately incorporate all candidate\ntools into the agent's context and retain them across multiple reasoning steps.\nThis process remains opaque to LLM agents and is not integrated into their\nreasoning procedures, leading to inefficiencies due to increased context length\nfrom irrelevant tools. To address this, we introduce EcoAct, a tool using\nalgorithm that allows LLMs to selectively register tools as needed, optimizing\ncontext use. By integrating the tool registration process into the reasoning\nprocedure, EcoAct reduces computational costs by over 50% in multiple steps\nreasoning tasks while maintaining performance, as demonstrated through\nextensive experiments. Moreover, it can be plugged into any reasoning pipeline\nwith only minor modifications to the prompt, making it applicable to LLM agents\nnow and future.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "16 pages, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.01643v1",
    "published_date": "2024-11-03 17:37:06 UTC",
    "updated_date": "2024-11-03 17:37:06 UTC"
  },
  {
    "arxiv_id": "2411.01639v3",
    "title": "Know Where You're Uncertain When Planning with Multimodal Foundation Models: A Formal Framework",
    "authors": [
      "Neel P. Bhatt",
      "Yunhao Yang",
      "Rohan Siva",
      "Daniel Milan",
      "Ufuk Topcu",
      "Zhangyang Wang"
    ],
    "abstract": "Multimodal foundation models offer a promising framework for robotic\nperception and planning by processing sensory inputs to generate actionable\nplans. However, addressing uncertainty in both perception (sensory\ninterpretation) and decision-making (plan generation) remains a critical\nchallenge for ensuring task reliability. We present a comprehensive framework\nto disentangle, quantify, and mitigate these two forms of uncertainty. We first\nintroduce a framework for uncertainty disentanglement, isolating perception\nuncertainty arising from limitations in visual understanding and decision\nuncertainty relating to the robustness of generated plans.\n  To quantify each type of uncertainty, we propose methods tailored to the\nunique properties of perception and decision-making: we use conformal\nprediction to calibrate perception uncertainty and introduce\nFormal-Methods-Driven Prediction (FMDP) to quantify decision uncertainty,\nleveraging formal verification techniques for theoretical guarantees. Building\non this quantification, we implement two targeted intervention mechanisms: an\nactive sensing process that dynamically re-observes high-uncertainty scenes to\nenhance visual input quality and an automated refinement procedure that\nfine-tunes the model on high-certainty data, improving its capability to meet\ntask specifications. Empirical validation in real-world and simulated robotic\ntasks demonstrates that our uncertainty disentanglement framework reduces\nvariability by up to 40% and enhances task success rates by 5% compared to\nbaselines. These improvements are attributed to the combined effect of both\ninterventions and highlight the importance of uncertainty disentanglement,\nwhich facilitates targeted interventions that enhance the robustness and\nreliability of autonomous systems. Fine-tuned models, code, and datasets are\navailable at https://uncertainty-in-planning.github.io/.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "Fine-tuned models, code, and datasets are available at\n  https://uncertainty-in-planning.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2411.01639v3",
    "published_date": "2024-11-03 17:32:00 UTC",
    "updated_date": "2025-04-17 02:45:08 UTC"
  },
  {
    "arxiv_id": "2411.01625v1",
    "title": "Counterfactual explainability of black-box prediction models",
    "authors": [
      "Zijun Gao",
      "Qingyuan Zhao"
    ],
    "abstract": "It is crucial to be able to explain black-box prediction models to use them\neffectively and safely in practice. Most existing tools for model explanations\nare associational rather than causal, and we use two paradoxical examples to\nshow that such explanations are generally inadequate. Motivated by the concept\nof genetic heritability in twin studies, we propose a new notion called\ncounterfactual explainability for black-box prediction models. Counterfactual\nexplainability has three key advantages: (1) it leverages counterfactual\noutcomes and extends methods for global sensitivity analysis (such as\nfunctional analysis of variance and Sobol's indices) to a causal setting; (2)\nit is defined not only for the totality of a set of input factors but also for\ntheir interactions (indeed, it is a probability measure on a whole\n``explanation algebra''); (3) it also applies to dependent input factors whose\ncausal relationship can be modeled by a directed acyclic graph, thus\nincorporating causal mechanisms into the explanation.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "stat.ML",
    "comment": "19 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.01625v1",
    "published_date": "2024-11-03 16:29:09 UTC",
    "updated_date": "2024-11-03 16:29:09 UTC"
  },
  {
    "arxiv_id": "2411.01623v2",
    "title": "FilterNet: Harnessing Frequency Filters for Time Series Forecasting",
    "authors": [
      "Kun Yi",
      "Jingru Fei",
      "Qi Zhang",
      "Hui He",
      "Shufeng Hao",
      "Defu Lian",
      "Wei Fan"
    ],
    "abstract": "While numerous forecasters have been proposed using different network\narchitectures, the Transformer-based models have state-of-the-art performance\nin time series forecasting. However, forecasters based on Transformers are\nstill suffering from vulnerability to high-frequency signals, efficiency in\ncomputation, and bottleneck in full-spectrum utilization, which essentially are\nthe cornerstones for accurately predicting time series with thousands of\npoints. In this paper, we explore a novel perspective of enlightening signal\nprocessing for deep time series forecasting. Inspired by the filtering process,\nwe introduce one simple yet effective network, namely FilterNet, built upon our\nproposed learnable frequency filters to extract key informative temporal\npatterns by selectively passing or attenuating certain components of time\nseries signals. Concretely, we propose two kinds of learnable filters in the\nFilterNet: (i) Plain shaping filter, that adopts a universal frequency kernel\nfor signal filtering and temporal modeling; (ii) Contextual shaping filter,\nthat utilizes filtered frequencies examined in terms of its compatibility with\ninput signals for dependency learning. Equipped with the two filters, FilterNet\ncan approximately surrogate the linear and attention mappings widely adopted in\ntime series literature, while enjoying superb abilities in handling\nhigh-frequency noises and utilizing the whole frequency spectrum that is\nbeneficial for forecasting. Finally, we conduct extensive experiments on eight\ntime series forecasting benchmarks, and experimental results have demonstrated\nour superior performance in terms of both effectiveness and efficiency compared\nwith state-of-the-art methods. Code is available at this repository:\nhttps://github.com/aikunyi/FilterNet",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.01623v2",
    "published_date": "2024-11-03 16:20:41 UTC",
    "updated_date": "2024-11-05 04:07:39 UTC"
  },
  {
    "arxiv_id": "2411.01618v1",
    "title": "VQ-Map: Bird's-Eye-View Map Layout Estimation in Tokenized Discrete Space via Vector Quantization",
    "authors": [
      "Yiwei Zhang",
      "Jin Gao",
      "Fudong Ge",
      "Guan Luo",
      "Bing Li",
      "Zhaoxiang Zhang",
      "Haibin Ling",
      "Weiming Hu"
    ],
    "abstract": "Bird's-eye-view (BEV) map layout estimation requires an accurate and full\nunderstanding of the semantics for the environmental elements around the ego\ncar to make the results coherent and realistic. Due to the challenges posed by\nocclusion, unfavourable imaging conditions and low resolution,\n\\emph{generating} the BEV semantic maps corresponding to corrupted or invalid\nareas in the perspective view (PV) is appealing very recently. \\emph{The\nquestion is how to align the PV features with the generative models to\nfacilitate the map estimation}. In this paper, we propose to utilize a\ngenerative model similar to the Vector Quantized-Variational AutoEncoder\n(VQ-VAE) to acquire prior knowledge for the high-level BEV semantics in the\ntokenized discrete space. Thanks to the obtained BEV tokens accompanied with a\ncodebook embedding encapsulating the semantics for different BEV elements in\nthe groundtruth maps, we are able to directly align the sparse backbone image\nfeatures with the obtained BEV tokens from the discrete representation learning\nbased on a specialized token decoder module, and finally generate high-quality\nBEV maps with the BEV codebook embedding serving as a bridge between PV and\nBEV. We evaluate the BEV map layout estimation performance of our model, termed\nVQ-Map, on both the nuScenes and Argoverse benchmarks, achieving 62.2/47.6 mean\nIoU for surround-view/monocular evaluation on nuScenes, as well as 73.4 IoU for\nmonocular evaluation on Argoverse, which all set a new record for this map\nlayout estimation task. The code and models are available on\n\\url{https://github.com/Z1zyw/VQ-Map}.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.01618v1",
    "published_date": "2024-11-03 16:09:47 UTC",
    "updated_date": "2024-11-03 16:09:47 UTC"
  },
  {
    "arxiv_id": "2411.01612v1",
    "title": "Ontology Population using LLMs",
    "authors": [
      "Sanaz Saki Norouzi",
      "Adrita Barua",
      "Antrea Christou",
      "Nikita Gautam",
      "Andrew Eells",
      "Pascal Hitzler",
      "Cogan Shimizu"
    ],
    "abstract": "Knowledge graphs (KGs) are increasingly utilized for data integration,\nrepresentation, and visualization. While KG population is critical, it is often\ncostly, especially when data must be extracted from unstructured text in\nnatural language, which presents challenges, such as ambiguity and complex\ninterpretations. Large Language Models (LLMs) offer promising capabilities for\nsuch tasks, excelling in natural language understanding and content generation.\nHowever, their tendency to ``hallucinate'' can produce inaccurate outputs.\nDespite these limitations, LLMs offer rapid and scalable processing of natural\nlanguage data, and with prompt engineering and fine-tuning, they can\napproximate human-level performance in extracting and structuring data for KGs.\nThis study investigates LLM effectiveness for the KG population, focusing on\nthe Enslaved.org Hub Ontology. In this paper, we report that compared to the\nground truth, LLM's can extract ~90% of triples, when provided a modular\nontology as guidance in the prompts.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.01612v1",
    "published_date": "2024-11-03 15:39:20 UTC",
    "updated_date": "2024-11-03 15:39:20 UTC"
  },
  {
    "arxiv_id": "2411.01611v1",
    "title": "Stochastic Communication Avoidance for Recommendation Systems",
    "authors": [
      "Lutfi Eren Erdogan",
      "Vijay Anand Raghava Kanakagiri",
      "Kurt Keutzer",
      "Zhen Dong"
    ],
    "abstract": "One of the major bottlenecks for efficient deployment of neural network based\nrecommendation systems is the memory footprint of their embedding tables.\nAlthough many neural network based recommendation systems could benefit from\nthe faster on-chip memory access and increased computational power of hardware\naccelerators, the large embedding tables in these models often cannot fit on\nthe constrained memory of accelerators. Despite the pervasiveness of these\nmodels, prior methods in memory optimization and parallelism fail to address\nthe memory and communication costs of large embedding tables on accelerators.\nAs a result, the majority of models are trained on CPUs, while current\nimplementations of accelerators are hindered by issues such as bottlenecks in\ninter-device communication and main memory lookups. In this paper, we propose a\ntheoretical framework that analyses the communication costs of arbitrary\ndistributed systems that use lookup tables. We use this framework to propose\nalgorithms that maximize throughput subject to memory, computation, and\ncommunication constraints. Furthermore, we demonstrate that our method achieves\nstrong theoretical performance across dataset distributions and memory\nconstraints, applicable to a wide range of use cases from mobile federated\nlearning to warehouse-scale computation. We implement our framework and\nalgorithms in PyTorch and achieve up to 6x increases in training throughput on\nGPU systems over baselines, on the Criteo Terabytes dataset.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.CV",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.01611v1",
    "published_date": "2024-11-03 15:37:37 UTC",
    "updated_date": "2024-11-03 15:37:37 UTC"
  },
  {
    "arxiv_id": "2411.01608v1",
    "title": "GITSR: Graph Interaction Transformer-based Scene Representation for Multi Vehicle Collaborative Decision-making",
    "authors": [
      "Xingyu Hu",
      "Lijun Zhang",
      "Dejian Meng",
      "Ye Han",
      "Lisha Yuan"
    ],
    "abstract": "In this study, we propose GITSR, an effective framework for Graph Interaction\nTransformer-based Scene Representation for multi-vehicle collaborative\ndecision-making in intelligent transportation system. In the context of mixed\ntraffic where Connected Automated Vehicles (CAVs) and Human Driving Vehicles\n(HDVs) coexist, in order to enhance the understanding of the environment by\nCAVs to improve decision-making capabilities, this framework focuses on\nefficient scene representation and the modeling of spatial interaction\nbehaviors of traffic states. We first extract features of the driving\nenvironment based on the background of intelligent networking. Subsequently,\nthe local scene representation, which is based on the agent-centric and dynamic\noccupation grid, is calculated by the Transformer module. Besides, feasible\nregion of the map is captured through the multi-head attention mechanism to\nreduce the collision of vehicles. Notably, spatial interaction behaviors, based\non motion information, are modeled as graph structures and extracted via Graph\nNeural Network (GNN). Ultimately, the collaborative decision-making among\nmultiple vehicles is formulated as a Markov Decision Process (MDP), with\ndriving actions output by Reinforcement Learning (RL) algorithms. Our\nalgorithmic validation is executed within the extremely challenging scenario of\nhighway off-ramp task, thereby substantiating the superiority of agent-centric\napproach to scene representation. Simulation results demonstrate that the GITSR\nmethod can not only effectively capture scene representation but also extract\nspatial interaction data, outperforming the baseline method across various\ncomparative metrics.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.MA",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.01608v1",
    "published_date": "2024-11-03 15:27:26 UTC",
    "updated_date": "2024-11-03 15:27:26 UTC"
  },
  {
    "arxiv_id": "2411.01604v1",
    "title": "Large Language Model Supply Chain: Open Problems From the Security Perspective",
    "authors": [
      "Qiang Hu",
      "Xiaofei Xie",
      "Sen Chen",
      "Lei Ma"
    ],
    "abstract": "Large Language Model (LLM) is changing the software development paradigm and\nhas gained huge attention from both academia and industry. Researchers and\ndevelopers collaboratively explore how to leverage the powerful problem-solving\nability of LLMs for specific domain tasks. Due to the wide usage of LLM-based\napplications, e.g., ChatGPT, multiple works have been proposed to ensure the\nsecurity of LLM systems. However, a comprehensive understanding of the entire\nprocesses of LLM system construction (the LLM supply chain) is crucial but\nrelevant works are limited. More importantly, the security issues hidden in the\nLLM SC which could highly impact the reliable usage of LLMs are lack of\nexploration. Existing works mainly focus on assuring the quality of LLM from\nthe model level, security assurance for the entire LLM SC is ignored. In this\nwork, we take the first step to discuss the potential security risks in each\ncomponent as well as the integration between components of LLM SC. We summarize\n12 security-related risks and provide promising guidance to help build safer\nLLM systems. We hope our work can facilitate the evolution of artificial\ngeneral intelligence with secure LLM ecosystems.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.01604v1",
    "published_date": "2024-11-03 15:20:21 UTC",
    "updated_date": "2024-11-03 15:20:21 UTC"
  },
  {
    "arxiv_id": "2411.01602v1",
    "title": "DreamPolish: Domain Score Distillation With Progressive Geometry Generation",
    "authors": [
      "Yean Cheng",
      "Ziqi Cai",
      "Ming Ding",
      "Wendi Zheng",
      "Shiyu Huang",
      "Yuxiao Dong",
      "Jie Tang",
      "Boxin Shi"
    ],
    "abstract": "We introduce DreamPolish, a text-to-3D generation model that excels in\nproducing refined geometry and high-quality textures. In the geometry\nconstruction phase, our approach leverages multiple neural representations to\nenhance the stability of the synthesis process. Instead of relying solely on a\nview-conditioned diffusion prior in the novel sampled views, which often leads\nto undesired artifacts in the geometric surface, we incorporate an additional\nnormal estimator to polish the geometry details, conditioned on viewpoints with\nvarying field-of-views. We propose to add a surface polishing stage with only a\nfew training steps, which can effectively refine the artifacts attributed to\nlimited guidance from previous stages and produce 3D objects with more\ndesirable geometry. The key topic of texture generation using pretrained\ntext-to-image models is to find a suitable domain in the vast latent\ndistribution of these models that contains photorealistic and consistent\nrenderings. In the texture generation phase, we introduce a novel score\ndistillation objective, namely domain score distillation (DSD), to guide neural\nrepresentations toward such a domain. We draw inspiration from the\nclassifier-free guidance (CFG) in textconditioned image generation tasks and\nshow that CFG and variational distribution guidance represent distinct aspects\nin gradient guidance and are both imperative domains for the enhancement of\ntexture quality. Extensive experiments show our proposed model can produce 3D\nassets with polished surfaces and photorealistic textures, outperforming\nexisting state-of-the-art methods.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.01602v1",
    "published_date": "2024-11-03 15:15:01 UTC",
    "updated_date": "2024-11-03 15:15:01 UTC"
  },
  {
    "arxiv_id": "2411.01597v1",
    "title": "OSAD: Open-Set Aircraft Detection in SAR Images",
    "authors": [
      "Xiayang Xiao",
      "Zhuoxuan Li",
      "Haipeng Wang"
    ],
    "abstract": "Current mainstream SAR image object detection methods still lack robustness\nwhen dealing with unknown objects in open environments. Open-set detection aims\nto enable detectors trained on a closed set to detect all known objects and\nidentify unknown objects in open-set environments. The key challenges are how\nto improve the generalization to potential unknown objects and reduce the\nempirical classification risk of known categories under strong supervision. To\naddress these challenges, a novel open-set aircraft detector for SAR images is\nproposed, named Open-Set Aircraft Detection (OSAD), which is equipped with\nthree dedicated components: global context modeling (GCM), location\nquality-driven pseudo labeling generation (LPG), and prototype contrastive\nlearning (PCL). GCM effectively enhances the network's representation of\nobjects by attention maps which is formed through the capture of long\nsequential positional relationships. LPG leverages clues about object positions\nand shapes to optimize localization quality, avoiding overfitting to known\ncategory information and enhancing generalization to potential unknown objects.\nPCL employs prototype-based contrastive encoding loss to promote instance-level\nintra-class compactness and inter-class variance, aiming to minimize the\noverlap between known and unknown distributions and reduce the empirical\nclassification risk of known categories. Extensive experiments have\ndemonstrated that the proposed method can effectively detect unknown objects\nand exhibit competitive performance without compromising closed-set\nperformance. The highest absolute gain which ranges from 0 to 18.36% can be\nachieved on the average precision of unknown objects.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "15 pages,11 figures. This work has been submitted to the IEEE for\n  possible publication on March 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.01597v1",
    "published_date": "2024-11-03 15:06:14 UTC",
    "updated_date": "2024-11-03 15:06:14 UTC"
  },
  {
    "arxiv_id": "2411.01595v2",
    "title": "RS-MoE: A Vision-Language Model with Mixture of Experts for Remote Sensing Image Captioning and Visual Question Answering",
    "authors": [
      "Hui Lin",
      "Danfeng Hong",
      "Shuhang Ge",
      "Chuyao Luo",
      "Kai Jiang",
      "Hao Jin",
      "Congcong Wen"
    ],
    "abstract": "Remote Sensing Image Captioning (RSIC) presents unique challenges and plays a\ncritical role in applications. Traditional RSIC methods often struggle to\nproduce rich and diverse descriptions. Recently, with advancements in VLMs,\nefforts have emerged to integrate these models into the remote sensing domain\nand to introduce descriptive datasets specifically designed to enhance VLM\ntraining. This paper proposes RS-MoE, a first Mixture of Expert based VLM\nspecifically customized for remote sensing domain. Unlike traditional MoE\nmodels, the core of RS-MoE is the MoE Block, which incorporates a novel\nInstruction Router and multiple lightweight Large Language Models (LLMs) as\nexpert models. The Instruction Router is designed to generate specific prompts\ntailored for each corresponding LLM, guiding them to focus on distinct aspects\nof the RSIC task. This design not only allows each expert LLM to concentrate on\na specific subset of the task, thereby enhancing the specificity and accuracy\nof the generated captions, but also improves the scalability of the model by\nfacilitating parallel processing of sub-tasks. Additionally, we present a\ntwo-stage training strategy for tuning our RS-MoE model to prevent performance\ndegradation due to sparsity. We fine-tuned our model on the RSICap dataset\nusing our proposed training strategy. Experimental results on the RSICap\ndataset, along with evaluations on other traditional datasets where no\nadditional fine-tuning was applied, demonstrate that our model achieves\nstate-of-the-art performance in generating precise and contextually relevant\ncaptions. Notably, our RS-MoE-1B variant achieves performance comparable to 13B\nVLMs, demonstrating the efficiency of our model design. Moreover, our model\ndemonstrates promising generalization capabilities by consistently achieving\nstate-of-the-art performance on the Remote Sensing Visual Question Answering\n(RSVQA) task.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.01595v2",
    "published_date": "2024-11-03 15:05:49 UTC",
    "updated_date": "2025-02-10 19:14:09 UTC"
  },
  {
    "arxiv_id": "2411.01583v1",
    "title": "Trustworthy Federated Learning: Privacy, Security, and Beyond",
    "authors": [
      "Chunlu Chen",
      "Ji Liu",
      "Haowen Tan",
      "Xingjian Li",
      "Kevin I-Kai Wang",
      "Peng Li",
      "Kouichi Sakurai",
      "Dejing Dou"
    ],
    "abstract": "While recent years have witnessed the advancement in big data and Artificial\nIntelligence (AI), it is of much importance to safeguard data privacy and\nsecurity. As an innovative approach, Federated Learning (FL) addresses these\nconcerns by facilitating collaborative model training across distributed data\nsources without transferring raw data. However, the challenges of robust\nsecurity and privacy across decentralized networks catch significant attention\nin dealing with the distributed data in FL. In this paper, we conduct an\nextensive survey of the security and privacy issues prevalent in FL,\nunderscoring the vulnerability of communication links and the potential for\ncyber threats. We delve into various defensive strategies to mitigate these\nrisks, explore the applications of FL across different sectors, and propose\nresearch directions. We identify the intricate security challenges that arise\nwithin the FL frameworks, aiming to contribute to the development of secure and\nefficient FL systems.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.CR",
    "comment": "32 pages, to appear in KAIS",
    "pdf_url": "http://arxiv.org/pdf/2411.01583v1",
    "published_date": "2024-11-03 14:18:01 UTC",
    "updated_date": "2024-11-03 14:18:01 UTC"
  },
  {
    "arxiv_id": "2411.01579v1",
    "title": "Flexible Coded Distributed Convolution Computing for Enhanced Fault Tolerance and Numerical Stability in Distributed CNNs",
    "authors": [
      "Shuo Tan",
      "Rui Liu",
      "XianLei Long",
      "Kai Wan",
      "Linqi Song",
      "Yong Li"
    ],
    "abstract": "Deploying Convolutional Neural Networks (CNNs) on resource-constrained\ndevices necessitates efficient management of computational resources, often via\ndistributed systems susceptible to latency from straggler nodes. This paper\nintroduces the Flexible Coded Distributed Convolution Computing (FCDCC)\nframework to enhance fault tolerance and numerical stability in distributed\nCNNs. We extend Coded Distributed Computing (CDC) with Circulant and Rotation\nMatrix Embedding (CRME) which was originally proposed for matrix multiplication\nto high-dimensional tensor convolution. For the proposed scheme, referred to as\nNumerically Stable Coded Tensor Convolution (NSCTC) scheme, we also propose two\nnew coded partitioning schemes: Adaptive-Padding Coded Partitioning (APCP) for\ninput tensor and Kernel-Channel Coded Partitioning (KCCP) for filter tensor.\nThese strategies enable linear decomposition of tensor convolutions and\nencoding them into CDC sub-tasks, combining model parallelism with coded\nredundancy for robust and efficient execution. Theoretical analysis identifies\nan optimal trade-off between communication and storage costs. Empirical results\nvalidate the framework's effectiveness in computational efficiency, fault\ntolerance, and scalability across various CNN architectures.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.CV",
      "cs.IT",
      "cs.LG",
      "math.IT"
    ],
    "primary_category": "cs.DC",
    "comment": "14 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.01579v1",
    "published_date": "2024-11-03 14:05:29 UTC",
    "updated_date": "2024-11-03 14:05:29 UTC"
  },
  {
    "arxiv_id": "2411.01574v1",
    "title": "DELE: Deductive $\\mathcal{EL}^{++} \\thinspace $ Embeddings for Knowledge Base Completion",
    "authors": [
      "Olga Mashkova",
      "Fernando Zhapa-Camacho",
      "Robert Hoehndorf"
    ],
    "abstract": "Ontology embeddings map classes, relations, and individuals in ontologies\ninto $\\mathbb{R}^n$, and within $\\mathbb{R}^n$ similarity between entities can\nbe computed or new axioms inferred. For ontologies in the Description Logic\n$\\mathcal{EL}^{++}$, several embedding methods have been developed that\nexplicitly generate models of an ontology. However, these methods suffer from\nsome limitations; they do not distinguish between statements that are\nunprovable and provably false, and therefore they may use entailed statements\nas negatives. Furthermore, they do not utilize the deductive closure of an\nontology to identify statements that are inferred but not asserted. We\nevaluated a set of embedding methods for $\\mathcal{EL}^{++}$ ontologies,\nincorporating several modifications that aim to make use of the ontology\ndeductive closure. In particular, we designed novel negative losses that\naccount both for the deductive closure and different types of negatives and\nformulated evaluation methods for knowledge base completion. We demonstrate\nthat our embedding methods improve over the baseline ontology embedding in the\ntask of knowledge base or ontology completion.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Extended version of the paper \"Enhancing Geometric Ontology\n  Embeddings for $\\mathcal{EL}^{++}$ with Negative Sampling and Deductive\n  Closure Filtering\" presented at NeSy 2024 conference",
    "pdf_url": "http://arxiv.org/pdf/2411.01574v1",
    "published_date": "2024-11-03 14:00:04 UTC",
    "updated_date": "2024-11-03 14:00:04 UTC"
  },
  {
    "arxiv_id": "2411.01562v1",
    "title": "Are LLMs good pragmatic speakers?",
    "authors": [
      "Mingyue Jian",
      "N. Siddharth"
    ],
    "abstract": "Large language models (LLMs) are trained on data assumed to include natural\nlanguage pragmatics, but do they actually behave like pragmatic speakers? We\nattempt to answer this question using the Rational Speech Act (RSA) framework,\nwhich models pragmatic reasoning in human communication. Using the paradigm of\na reference game constructed from the TUNA corpus, we score candidate\nreferential utterances in both a state-of-the-art LLM (Llama3-8B-Instruct) and\nin the RSA model, comparing and contrasting these scores. Given that RSA\nrequires defining alternative utterances and a truth-conditional meaning\nfunction, we explore such comparison for different choices of each of these\nrequirements. We find that while scores from the LLM have some positive\ncorrelation with those from RSA, there isn't sufficient evidence to claim that\nit behaves like a pragmatic speaker. This initial study paves way for further\ntargeted efforts exploring different models and settings, including\nhuman-subject evaluation, to see if LLMs truly can, or be made to, behave like\npragmatic speakers.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.01562v1",
    "published_date": "2024-11-03 13:23:18 UTC",
    "updated_date": "2024-11-03 13:23:18 UTC"
  },
  {
    "arxiv_id": "2411.01553v2",
    "title": "Learning to Communicate Through Implicit Communication Channels",
    "authors": [
      "Han Wang",
      "Binbin Chen",
      "Tieying Zhang",
      "Baoxiang Wang"
    ],
    "abstract": "Effective communication is an essential component in collaborative\nmulti-agent systems. Situations where explicit messaging is not feasible have\nbeen common in human society throughout history, which motivate the study of\nimplicit communication. Previous works on learning implicit communication\nmostly rely on theory of mind (ToM), where agents infer the mental states and\nintentions of others by interpreting their actions. However, ToM-based methods\nbecome less effective in making accurate inferences in complex tasks. In this\nwork, we propose the Implicit Channel Protocol (ICP) framework, which allows\nagents to communicate through implicit communication channels similar to the\nexplicit ones. ICP leverages a subset of actions, denoted as the scouting\nactions, and a mapping between information and these scouting actions that\nencodes and decodes the messages. We propose training algorithms for agents to\nmessage and act, including learning with a randomly initialized information map\nand with a delayed information map. The efficacy of ICP has been tested on the\ntasks of Guessing Numbers, Revealing Goals, and Hanabi, where ICP significantly\noutperforms baseline methods through more efficient information transmission.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.MA",
    "comment": "17 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.01553v2",
    "published_date": "2024-11-03 12:58:22 UTC",
    "updated_date": "2025-02-10 09:32:30 UTC"
  },
  {
    "arxiv_id": "2411.08919v1",
    "title": "A Machine Learning based Hybrid Receiver for 5G NR PRACH",
    "authors": [
      "Rohit Singh",
      "Anil Kumar Yerrapragada",
      "Radha Krishna Ganti"
    ],
    "abstract": "Random Access is a critical procedure using which a User Equipment (UE)\nidentifies itself to a Base Station (BS). Random Access starts with the UE\ntransmitting a random preamble on the Physical Random Access Channel (PRACH).\nIn a conventional BS receiver, the UE's specific preamble is identified by\ncorrelation with all the possible preambles. The PRACH signal is also used to\nestimate the timing advance which is induced by propagation delay.\nCorrelation-based receivers suffer from false peaks and missed detection in\nscenarios dominated by high fading and low signal-to-noise ratio. This paper\ndescribes the design of a hybrid receiver that consists of an AI/ML model for\npreamble detection followed by conventional peak detection for the Timing\nAdvance estimation. The proposed receiver combines the Power Delay Profiles of\ncorrelation windows across multiple antennas and uses the combination as input\nto a Neural Network model. The model predicts the presence or absence of a user\nin a particular preamble window, after which the timing advance is estimated by\npeak detection. Results show superior performance of the hybrid receiver\ncompared to conventional receivers both for simulated and real\nhardware-captured datasets.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.IT",
      "cs.LG",
      "math.IT"
    ],
    "primary_category": "eess.SP",
    "comment": "6 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.08919v1",
    "published_date": "2024-11-03 11:49:12 UTC",
    "updated_date": "2024-11-03 11:49:12 UTC"
  },
  {
    "arxiv_id": "2411.01535v1",
    "title": "Customized Subgraph Selection and Encoding for Drug-drug Interaction Prediction",
    "authors": [
      "Haotong Du",
      "Quanming Yao",
      "Juzheng Zhang",
      "Yang Liu",
      "Zhen Wang"
    ],
    "abstract": "Subgraph-based methods have proven to be effective and interpretable in\npredicting drug-drug interactions (DDIs), which are essential for medical\npractice and drug development. Subgraph selection and encoding are critical\nstages in these methods, yet customizing these components remains underexplored\ndue to the high cost of manual adjustments. In this study, inspired by the\nsuccess of neural architecture search (NAS), we propose a method to search for\ndata-specific components within subgraph-based frameworks. Specifically, we\nintroduce extensive subgraph selection and encoding spaces that account for the\ndiverse contexts of drug interactions in DDI prediction. To address the\nchallenge of large search spaces and high sampling costs, we design a\nrelaxation mechanism that uses an approximation strategy to efficiently explore\noptimal subgraph configurations. This approach allows for robust exploration of\nthe search space. Extensive experiments demonstrate the effectiveness and\nsuperiority of the proposed method, with the discovered subgraphs and encoding\nfunctions highlighting the model's adaptability.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.BM"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.01535v1",
    "published_date": "2024-11-03 11:41:35 UTC",
    "updated_date": "2024-11-03 11:41:35 UTC"
  },
  {
    "arxiv_id": "2411.01533v3",
    "title": "Enhancing LLM Evaluations: The Garbling Trick",
    "authors": [
      "William F. Bradley"
    ],
    "abstract": "As large language models (LLMs) become increasingly powerful, traditional\nevaluation metrics tend to saturate, making it challenging to distinguish\nbetween models. We propose a general method to transform existing LLM\nevaluations into a series of progressively more difficult tasks. These enhanced\nevaluations emphasize reasoning capabilities and can reveal relative\nperformance differences that are not apparent in the original assessments.\n  To demonstrate the effectiveness of our approach, we create a new\nmultiple-choice test corpus, extend it into a family of evaluations, and assess\na collection of LLMs. Our results offer insights into the comparative abilities\nof these models, particularly highlighting the differences between base LLMs\nand more recent \"reasoning\" models.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "15 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.01533v3",
    "published_date": "2024-11-03 11:39:50 UTC",
    "updated_date": "2025-05-18 04:56:06 UTC"
  },
  {
    "arxiv_id": "2411.01523v1",
    "title": "SinaTools: Open Source Toolkit for Arabic Natural Language Processing",
    "authors": [
      "Tymaa Hammouda",
      "Mustafa Jarrar",
      "Mohammed Khalilia"
    ],
    "abstract": "We introduce SinaTools, an open-source Python package for Arabic natural\nlanguage processing and understanding. SinaTools is a unified package allowing\npeople to integrate it into their system workflow, offering solutions for\nvarious tasks such as flat and nested Named Entity Recognition (NER),\nfully-flagged Word Sense Disambiguation (WSD), Semantic Relatedness, Synonymy\nExtractions and Evaluation, Lemmatization, Part-of-speech Tagging, Root\nTagging, and additional helper utilities such as corpus processing, text\nstripping methods, and diacritic-aware word matching. This paper presents\nSinaTools and its benchmarking results, demonstrating that SinaTools\noutperforms all similar tools on the aforementioned tasks, such as Flat NER\n(87.33%), Nested NER (89.42%), WSD (82.63%), Semantic Relatedness (0.49\nSpearman rank), Lemmatization (90.5%), POS tagging (97.5%), among others.\nSinaTools can be downloaded from (https://sina.birzeit.edu/sinatools).",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "10 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.01523v1",
    "published_date": "2024-11-03 11:03:52 UTC",
    "updated_date": "2024-11-03 11:03:52 UTC"
  },
  {
    "arxiv_id": "2411.01521v2",
    "title": "Diversity Progress for Goal Selection in Discriminability-Motivated RL",
    "authors": [
      "Erik M. Lintunen",
      "Nadia M. Ady",
      "Christian Guckelsberger"
    ],
    "abstract": "Non-uniform goal selection has the potential to improve the reinforcement\nlearning (RL) of skills over uniform-random selection. In this paper, we\nintroduce a method for learning a goal-selection policy in\nintrinsically-motivated goal-conditioned RL: \"Diversity Progress\" (DP). The\nlearner forms a curriculum based on observed improvement in discriminability\nover its set of goals. Our proposed method is applicable to the class of\ndiscriminability-motivated agents, where the intrinsic reward is computed as a\nfunction of the agent's certainty of following the true goal being pursued.\nThis reward can motivate the agent to learn a set of diverse skills without\nextrinsic rewards. We demonstrate empirically that a DP-motivated agent can\nlearn a set of distinguishable skills faster than previous approaches, and do\nso without suffering from a collapse of the goal distribution -- a known issue\nwith some prior approaches. We end with plans to take this proof-of-concept\nforward.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "11 pages including appendices, full-track paper at the Intrinsically\n  Motivated Open-ended Learning workshop at NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.01521v2",
    "published_date": "2024-11-03 10:47:39 UTC",
    "updated_date": "2024-11-06 14:52:28 UTC"
  },
  {
    "arxiv_id": "2411.01508v1",
    "title": "FaceDig: Automated tool for placing landmarks on facial portraits for geometric morphometrics users",
    "authors": [
      "Karel Kleisner",
      "Jaroslav Trnka",
      "Petr Turecek"
    ],
    "abstract": "Landmark digitization is essential in geometric morphometrics, enabling the\nquantification of biological shapes, such as facial structures, for in-depth\nmorphological analysis. Traditional landmarking, which identifies specific\nanatomical points, can be complemented by semilandmarks when precise locations\nare challenging to define. However, manual placement of numerous landmarks is\ntime-consuming and prone to human error, leading to inconsistencies across\nstudies. To address this, we introduce FaceDig, an AI-powered tool designed to\nautomate landmark placement with human-level precision, focusing on\nanatomically sound facial points. FaceDig is open-source and integrates\nseamlessly with analytical platforms like R and Python. It was trained using\none of the largest and most ethnically diverse face datasets, applying a\nlandmark configuration optimized for 2D enface photographs. Our results\ndemonstrate that FaceDig provides reliable landmark coordinates, comparable to\nthose placed manually by experts. The tool's output is compatible with the\nwidely-used TpsDig2 software, facilitating adoption and ensuring consistency\nacross studies. Users are advised to work with standardized facial images and\nvisually inspect the results for potential corrections. Despite the growing\npreference for 3D morphometrics, 2D facial photographs remain valuable due to\ntheir cultural and practical significance. Future enhancements to FaceDig will\ninclude support for profile views, further expanding its utility. By offering a\nstandardized approach to landmark placement, FaceDig promotes reproducibility\nin facial morphology research and provides a robust alternative to existing 2D\ntools.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "q-bio.QM"
    ],
    "primary_category": "cs.CV",
    "comment": "13 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.01508v1",
    "published_date": "2024-11-03 10:03:52 UTC",
    "updated_date": "2024-11-03 10:03:52 UTC"
  },
  {
    "arxiv_id": "2411.01493v2",
    "title": "Sample-Efficient Alignment for LLMs",
    "authors": [
      "Zichen Liu",
      "Changyu Chen",
      "Chao Du",
      "Wee Sun Lee",
      "Min Lin"
    ],
    "abstract": "We study methods for efficiently aligning large language models (LLMs) with\nhuman preferences given budgeted online feedback. We first formulate the LLM\nalignment problem in the frame of contextual dueling bandits. This formulation,\nsubsuming recent paradigms such as online RLHF and online DPO, inherently\nquests for sample-efficient algorithms that incorporate online active\nexploration. Leveraging insights from bandit theory, we introduce a unified\nalgorithm based on Thompson sampling and highlight its applications in two\ndistinct LLM alignment scenarios. The practical agent that efficiently\nimplements this algorithm, named SEA (Sample-Efficient Alignment), is\nempirically validated through extensive experiments across three model scales\n(1B, 2.8B, 6.9B) and three preference learning algorithms (DPO, IPO, SLiC). The\nresults demonstrate that SEA achieves highly sample-efficient alignment with\noracle's preferences, outperforming recent active exploration methods for LLMs.\nAdditionally, we release the implementation of SEA together with an efficient\ncodebase designed for online alignment of LLMs, aiming to accelerate future\nresearch in this field.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.01493v2",
    "published_date": "2024-11-03 09:18:28 UTC",
    "updated_date": "2024-11-09 12:22:19 UTC"
  },
  {
    "arxiv_id": "2411.01479v1",
    "title": "Capsule Vision Challenge 2024: Multi-Class Abnormality Classification for Video Capsule Endoscopy",
    "authors": [
      "Aakarsh Bansal",
      "Bhuvanesh Singla",
      "Raajan Rajesh Wankhade",
      "Nagamma Patil"
    ],
    "abstract": "This study presents an approach to developing a model for classifying\nabnormalities in video capsule endoscopy (VCE) frames. Given the challenges of\ndata imbalance, we implemented a tiered augmentation strategy using the\nalbumentations library to enhance minority class representation. Additionally,\nwe addressed learning complexities by progressively structuring training tasks,\nallowing the model to differentiate between normal and abnormal cases and then\ngradually adding more specific classes based on data availability. Our\npipeline, developed in PyTorch, employs a flexible architecture enabling\nseamless adjustments to classification complexity. We tested our approach using\nResNet50 and a custom ViT-CNN hybrid model, with training conducted on the\nKaggle platform. This work demonstrates a scalable approach to abnormality\nclassification in VCE.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.01479v1",
    "published_date": "2024-11-03 08:34:04 UTC",
    "updated_date": "2024-11-03 08:34:04 UTC"
  },
  {
    "arxiv_id": "2411.01472v1",
    "title": "Adaptive Domain Learning for Cross-domain Image Denoising",
    "authors": [
      "Zian Qian",
      "Chenyang Qi",
      "Ka Lung Law",
      "Hao Fu",
      "Chenyang Lei",
      "Qifeng Chen"
    ],
    "abstract": "Different camera sensors have different noise patterns, and thus an image\ndenoising model trained on one sensor often does not generalize well to a\ndifferent sensor. One plausible solution is to collect a large dataset for each\nsensor for training or fine-tuning, which is inevitably time-consuming. To\naddress this cross-domain challenge, we present a novel adaptive domain\nlearning (ADL) scheme for cross-domain RAW image denoising by utilizing\nexisting data from different sensors (source domain) plus a small amount of\ndata from the new sensor (target domain). The ADL training scheme automatically\nremoves the data in the source domain that are harmful to fine-tuning a model\nfor the target domain (some data are harmful as adding them during training\nlowers the performance due to domain gaps). Also, we introduce a modulation\nmodule to adopt sensor-specific information (sensor type and ISO) to understand\ninput data for image denoising. We conduct extensive experiments on public\ndatasets with various smartphone and DSLR cameras, which show our proposed\nmodel outperforms prior work on cross-domain image denoising, given a small\namount of image data from the target domain sensor.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "13 pages, 3 figures, accepted by neurips 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.01472v1",
    "published_date": "2024-11-03 08:08:26 UTC",
    "updated_date": "2024-11-03 08:08:26 UTC"
  },
  {
    "arxiv_id": "2411.01458v1",
    "title": "Two-Timescale Model Caching and Resource Allocation for Edge-Enabled AI-Generated Content Services",
    "authors": [
      "Zhang Liu",
      "Hongyang Du",
      "Xiangwang Hou",
      "Lianfen Huang",
      "Seyyedali Hosseinalipour",
      "Dusit Niyato",
      "Khaled Ben Letaief"
    ],
    "abstract": "Generative AI (GenAI) has emerged as a transformative technology, enabling\ncustomized and personalized AI-generated content (AIGC) services. In this\npaper, we address challenges of edge-enabled AIGC service provisioning, which\nremain underexplored in the literature. These services require executing GenAI\nmodels with billions of parameters, posing significant obstacles to\nresource-limited wireless edge. We subsequently introduce the formulation of\njoint model caching and resource allocation for AIGC services to balance a\ntrade-off between AIGC quality and latency metrics. We obtain mathematical\nrelationships of these metrics with the computational resources required by\nGenAI models via experimentation. Afterward, we decompose the formulation into\na model caching subproblem on a long-timescale and a resource allocation\nsubproblem on a short-timescale. Since the variables to be solved are discrete\nand continuous, respectively, we leverage a double deep Q-network (DDQN)\nalgorithm to solve the former subproblem and propose a diffusion-based deep\ndeterministic policy gradient (D3PG) algorithm to solve the latter. The\nproposed D3PG algorithm makes an innovative use of diffusion models as the\nactor network to determine optimal resource allocation decisions. Consequently,\nwe integrate these two learning methods within the overarching two-timescale\ndeep reinforcement learning (T2DRL) algorithm, the performance of which is\nstudied through comparative numerical simulations.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "14 pages, 8 figures, 39 references",
    "pdf_url": "http://arxiv.org/pdf/2411.01458v1",
    "published_date": "2024-11-03 07:01:13 UTC",
    "updated_date": "2024-11-03 07:01:13 UTC"
  },
  {
    "arxiv_id": "2411.01453v1",
    "title": "Denoising Fisher Training For Neural Implicit Samplers",
    "authors": [
      "Weijian Luo",
      "Wei Deng"
    ],
    "abstract": "Efficient sampling from un-normalized target distributions is pivotal in\nscientific computing and machine learning. While neural samplers have\ndemonstrated potential with a special emphasis on sampling efficiency, existing\nneural implicit samplers still have issues such as poor mode covering behavior,\nunstable training dynamics, and sub-optimal performances. To tackle these\nissues, in this paper, we introduce Denoising Fisher Training (DFT), a novel\ntraining approach for neural implicit samplers with theoretical guarantees. We\nframe the training problem as an objective of minimizing the Fisher divergence\nby deriving a tractable yet equivalent loss function, which marks a unique\ntheoretical contribution to assessing the intractable Fisher divergences. DFT\nis empirically validated across diverse sampling benchmarks, including\ntwo-dimensional synthetic distribution, Bayesian logistic regression, and\nhigh-dimensional energy-based models (EBMs). Notably, in experiments with\nhigh-dimensional EBMs, our best one-step DFT neural sampler achieves results on\npar with MCMC methods with up to 200 sampling steps, leading to a substantially\ngreater efficiency over 100 times higher. This result not only demonstrates the\nsuperior performance of DFT in handling complex high-dimensional sampling but\nalso sheds light on efficient sampling methodologies across broader\napplications.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "stat.CO"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.01453v1",
    "published_date": "2024-11-03 06:21:59 UTC",
    "updated_date": "2024-11-03 06:21:59 UTC"
  },
  {
    "arxiv_id": "2411.01442v2",
    "title": "Online Relational Inference for Evolving Multi-agent Interacting Systems",
    "authors": [
      "Beomseok Kang",
      "Priyabrata Saha",
      "Sudarshan Sharma",
      "Biswadeep Chakraborty",
      "Saibal Mukhopadhyay"
    ],
    "abstract": "We introduce a novel framework, Online Relational Inference (ORI), designed\nto efficiently identify hidden interaction graphs in evolving multi-agent\ninteracting systems using streaming data. Unlike traditional offline methods\nthat rely on a fixed training set, ORI employs online backpropagation, updating\nthe model with each new data point, thereby allowing it to adapt to changing\nenvironments in real-time. A key innovation is the use of an adjacency matrix\nas a trainable parameter, optimized through a new adaptive learning rate\ntechnique called AdaRelation, which adjusts based on the historical sensitivity\nof the decoder to changes in the interaction graph. Additionally, a data\naugmentation method named Trajectory Mirror (TM) is introduced to improve\ngeneralization by exposing the model to varied trajectory patterns.\nExperimental results on both synthetic datasets and real-world data (CMU MoCap\nfor human motion) demonstrate that ORI significantly improves the accuracy and\nadaptability of relational inference in dynamic settings compared to existing\nmethods. This approach is model-agnostic, enabling seamless integration with\nvarious neural relational inference (NRI) architectures, and offers a robust\nsolution for real-time applications in complex, evolving systems.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted at NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.01442v2",
    "published_date": "2024-11-03 05:43:55 UTC",
    "updated_date": "2024-11-07 05:54:07 UTC"
  },
  {
    "arxiv_id": "2411.01438v2",
    "title": "SkyServe: Serving AI Models across Regions and Clouds with Spot Instances",
    "authors": [
      "Ziming Mao",
      "Tian Xia",
      "Zhanghao Wu",
      "Wei-Lin Chiang",
      "Tyler Griggs",
      "Romil Bhardwaj",
      "Zongheng Yang",
      "Scott Shenker",
      "Ion Stoica"
    ],
    "abstract": "Recent years have witnessed an explosive growth of AI models. The high cost\nof hosting AI services on GPUs and their demanding service requirements, make\nit timely and challenging to lower service costs and guarantee service quality.\nWhile spot instances have long been offered with a large discount, spot\npreemptions have discouraged users from using them to host model replicas when\nserving AI models.\n  To address this, we propose a simple yet efficient policy, SpotHedge, that\nleverages spot replicas across different failure domains (e.g., regions and\nclouds) to ensure availability, lower costs, and high service quality.\nSpotHedge intelligently spreads spot replicas across different regions and\nclouds to improve availability and reduce correlated preemptions,\noverprovisions cheap spot replicas than required as a safeguard against\npossible preemptions, and dynamically falls back to on-demand replicas when\nspot replicas become unavailable. We built SkyServe, a system leveraging\nSpotHedge to efficiently serve AI models over a mixture of spot and on-demand\nreplicas across regions and clouds. We compared SkyServe with both research and\nproduction systems on real AI workloads: SkyServe reduces cost by 43% on\naverage while achieving high resource availability compared to using on-demand\nreplicas. Additionally, SkyServe improves P50, P90, and P99 latency by\n2.3$\\times$, 2.1$\\times$, 2.1$\\times$ on average compared to other research and\nproduction systems.",
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "primary_category": "cs.DC",
    "comment": "EuroSys 25'",
    "pdf_url": "http://arxiv.org/pdf/2411.01438v2",
    "published_date": "2024-11-03 05:00:53 UTC",
    "updated_date": "2025-03-03 22:39:13 UTC"
  },
  {
    "arxiv_id": "2411.05819v1",
    "title": "Hierarchical Sentiment Analysis Framework for Hate Speech Detection: Implementing Binary and Multiclass Classification Strategy",
    "authors": [
      "Faria Naznin",
      "Md Touhidur Rahman",
      "Shahran Rahman Alve"
    ],
    "abstract": "A significant challenge in automating hate speech detection on social media\nis distinguishing hate speech from regular and offensive language. These\nidentify an essential category of content that web filters seek to remove. Only\nautomated methods can manage this volume of daily data. To solve this problem,\nthe community of Natural Language Processing is currently investigating\ndifferent ways of hate speech detection. In addition to those, previous\napproaches (e.g., Convolutional Neural Networks, multi-channel BERT models, and\nlexical detection) have always achieved low precision without carefully\ntreating other related tasks like sentiment analysis and emotion\nclassification. They still like to group all messages with specific words in\nthem as hate speech simply because those terms often appear alongside hateful\nrhetoric. In this research, our paper presented the hate speech text\nclassification system model drawn upon deep learning and machine learning. In\nthis paper, we propose a new multitask model integrated with shared emotional\nrepresentations to detect hate speech across the English language. The\nTransformer-based model we used from Hugging Face and sentiment analysis helped\nus prevent false positives. Conclusion. We conclude that utilizing sentiment\nanalysis and a Transformer-based trained model considerably improves hate\nspeech detection across multiple datasets.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "20 Pages",
    "pdf_url": "http://arxiv.org/pdf/2411.05819v1",
    "published_date": "2024-11-03 04:11:33 UTC",
    "updated_date": "2024-11-03 04:11:33 UTC"
  },
  {
    "arxiv_id": "2411.01431v1",
    "title": "Efficient Deep Learning Infrastructures for Embedded Computing Systems: A Comprehensive Survey and Future Envision",
    "authors": [
      "Xiangzhong Luo",
      "Di Liu",
      "Hao Kong",
      "Shuo Huai",
      "Hui Chen",
      "Guochu Xiong",
      "Weichen Liu"
    ],
    "abstract": "Deep neural networks (DNNs) have recently achieved impressive success across\na wide range of real-world vision and language processing tasks, spanning from\nimage classification to many other downstream vision tasks, such as object\ndetection, tracking, and segmentation. However, previous well-established DNNs,\ndespite being able to maintain superior accuracy, have also been evolving to be\ndeeper and wider and thus inevitably necessitate prohibitive computational\nresources for both training and inference. This trend further enlarges the\ncomputational gap between computation-intensive DNNs and resource-constrained\nembedded computing systems, making it challenging to deploy powerful DNNs upon\nreal-world embedded computing systems towards ubiquitous embedded intelligence.\nTo alleviate the above computational gap and enable ubiquitous embedded\nintelligence, we, in this survey, focus on discussing recent efficient deep\nlearning infrastructures for embedded computing systems, spanning from training\nto inference, from manual to automated, from convolutional neural networks to\ntransformers, from transformers to vision transformers, from vision models to\nlarge language models, from software to hardware, and from algorithms to\napplications. Specifically, we discuss recent efficient deep learning\ninfrastructures for embedded computing systems from the lens of (1) efficient\nmanual network design for embedded computing systems, (2) efficient automated\nnetwork design for embedded computing systems, (3) efficient network\ncompression for embedded computing systems, (4) efficient on-device learning\nfor embedded computing systems, (5) efficient large language models for\nembedded computing systems, (6) efficient deep learning software and hardware\nfor embedded computing systems, and (7) efficient intelligent applications for\nembedded computing systems.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "ACM Transactions on Embedded Computing Systems (TECS) 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.01431v1",
    "published_date": "2024-11-03 03:55:04 UTC",
    "updated_date": "2024-11-03 03:55:04 UTC"
  },
  {
    "arxiv_id": "2411.01425v1",
    "title": "Learning Hidden Subgoals under Temporal Ordering Constraints in Reinforcement Learning",
    "authors": [
      "Duo Xu",
      "Faramarz Fekri"
    ],
    "abstract": "In real-world applications, the success of completing a task is often\ndetermined by multiple key steps which are distant in time steps and have to be\nachieved in a fixed time order. For example, the key steps listed on the\ncooking recipe should be achieved one-by-one in the right time order. These key\nsteps can be regarded as subgoals of the task and their time orderings are\ndescribed as temporal ordering constraints. However, in many real-world\nproblems, subgoals or key states are often hidden in the state space and their\ntemporal ordering constraints are also unknown, which make it challenging for\nprevious RL algorithms to solve this kind of tasks. In order to address this\nissue, in this work we propose a novel RL algorithm for {\\bf l}earning hidden\n{\\bf s}ubgoals under {\\bf t}emporal {\\bf o}rdering {\\bf c}onstraints (LSTOC).\nWe propose a new contrastive learning objective which can effectively learn\nhidden subgoals (key states) and their temporal orderings at the same time,\nbased on first-occupancy representation and temporal geometric sampling. In\naddition, we propose a sample-efficient learning strategy to discover subgoals\none-by-one following their temporal order constraints by building a subgoal\ntree to represent discovered subgoals and their temporal ordering\nrelationships. Specifically, this tree can be used to improve the sample\nefficiency of trajectory collection, fasten the task solving and generalize to\nunseen tasks. The LSTOC framework is evaluated on several environments with\nimage-based observations, showing its significant improvement over baseline\nmethods.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.01425v1",
    "published_date": "2024-11-03 03:22:39 UTC",
    "updated_date": "2024-11-03 03:22:39 UTC"
  },
  {
    "arxiv_id": "2411.01423v1",
    "title": "Conditional Latent Space Molecular Scaffold Optimization for Accelerated Molecular Design",
    "authors": [
      "Onur Boyar",
      "Hiroyuki Hanada",
      "Ichiro Takeuchi"
    ],
    "abstract": "The rapid discovery of new chemical compounds is essential for advancing\nglobal health and developing treatments. While generative models show promise\nin creating novel molecules, challenges remain in ensuring the real-world\napplicability of these molecules and finding such molecules efficiently. To\naddress this, we introduce Conditional Latent Space Molecular Scaffold\nOptimization (CLaSMO), which combines a Conditional Variational Autoencoder\n(CVAE) with Latent Space Bayesian Optimization (LSBO) to modify molecules\nstrategically while maintaining similarity to the original input. Our LSBO\nsetting improves the sample-efficiency of our optimization, and our\nmodification approach helps us to obtain molecules with higher chances of\nreal-world applicability. CLaSMO explores substructures of molecules in a\nsample-efficient manner by performing BO in the latent space of a CVAE\nconditioned on the atomic environment of the molecule to be optimized. Our\nexperiments demonstrate that CLaSMO efficiently enhances target properties with\nminimal substructure modifications, achieving state-of-the-art results with a\nsmaller model and dataset compared to existing methods. We also provide an\nopen-source web application that enables chemical experts to apply CLaSMO in a\nHuman-in-the-Loop setting.",
    "categories": [
      "q-bio.BM",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.BM",
    "comment": "22 pages, 10 figures, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2411.01423v1",
    "published_date": "2024-11-03 03:17:38 UTC",
    "updated_date": "2024-11-03 03:17:38 UTC"
  },
  {
    "arxiv_id": "2411.01419v2",
    "title": "PSformer: Parameter-efficient Transformer with Segment Attention for Time Series Forecasting",
    "authors": [
      "Yanlong Wang",
      "Jian Xu",
      "Fei Ma",
      "Shao-Lun Huang",
      "Danny Dongning Sun",
      "Xiao-Ping Zhang"
    ],
    "abstract": "Time series forecasting remains a critical challenge across various domains,\noften complicated by high-dimensional data and long-term dependencies. This\npaper presents a novel transformer architecture for time series forecasting,\nincorporating two key innovations: parameter sharing (PS) and Spatial-Temporal\nSegment Attention (SegAtt). We also define the time series segment as the\nconcatenation of sequence patches from the same positions across different\nvariables. The proposed model, PSformer, reduces the number of training\nparameters through the parameter sharing mechanism, thereby improving model\nefficiency and scalability. The introduction of SegAtt could enhance the\ncapability of capturing local spatio-temporal dependencies by computing\nattention over the segments, and improve global representation by integrating\ninformation across segments. The combination of parameter sharing and SegAtt\nsignificantly improves the forecasting performance. Extensive experiments on\nbenchmark datasets demonstrate that PSformer outperforms popular baselines and\nother transformer-based approaches in terms of accuracy and scalability,\nestablishing itself as an accurate and scalable tool for time series\nforecasting.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "30 pages",
    "pdf_url": "http://arxiv.org/pdf/2411.01419v2",
    "published_date": "2024-11-03 03:04:00 UTC",
    "updated_date": "2025-02-11 09:50:04 UTC"
  },
  {
    "arxiv_id": "2411.01417v1",
    "title": "BF-IMNA: A Bit Fluid In-Memory Neural Architecture for Neural Network Acceleration",
    "authors": [
      "Mariam Rakka",
      "Rachid Karami",
      "Ahmed M. Eltawil",
      "Mohammed E. Fouda",
      "Fadi Kurdahi"
    ],
    "abstract": "Mixed-precision quantization works Neural Networks (NNs) are gaining traction\nfor their efficient realization on the hardware leading to higher throughput\nand lower energy. In-Memory Computing (IMC) accelerator architectures are\noffered as alternatives to traditional architectures relying on a data-centric\ncomputational paradigm, diminishing the memory wall problem, and scoring high\nthroughput and energy efficiency. These accelerators can support static\nfixed-precision but are not flexible to support mixed-precision NNs. In this\npaper, we present BF-IMNA, a bit fluid IMC accelerator for end-to-end\nConvolutional NN (CNN) inference that is capable of static and dynamic\nmixed-precision without any hardware reconfiguration overhead at run-time. At\nthe heart of BF-IMNA are Associative Processors (APs), which are bit-serial\nword-parallel Single Instruction, Multiple Data (SIMD)-like engines. We report\nthe performance of end-to-end inference of ImageNet on AlexNet, VGG16, and\nResNet50 on BF-IMNA for different technologies (eNVM and NVM), mixed-precision\nconfigurations, and supply voltages. To demonstrate bit fluidity, we implement\nHAWQ-V3's per-layer mixed-precision configurations for ResNet18 on BF-IMNA\nusing different latency budgets, and results reveal a trade-off between\naccuracy and Energy-Delay Product (EDP): On one hand, mixed-precision with a\nhigh latency constraint achieves the closest accuracy to fixed-precision INT8\nand reports a high (worse) EDP compared to fixed-precision INT4. On the other\nhand, with a low latency constraint, BF-IMNA reports the closest EDP to\nfixed-precision INT4, with a higher degradation in accuracy compared to\nfixed-precision INT8. We also show that BF-IMNA with fixed-precision\nconfiguration still delivers performance that is comparable to current\nstate-of-the-art accelerators: BF-IMNA achieves $20\\%$ higher energy efficiency\nand $2\\%$ higher throughput.",
    "categories": [
      "cs.AR",
      "cs.AI"
    ],
    "primary_category": "cs.AR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.01417v1",
    "published_date": "2024-11-03 03:02:23 UTC",
    "updated_date": "2024-11-03 03:02:23 UTC"
  },
  {
    "arxiv_id": "2411.01414v2",
    "title": "A Deep Dive Into Large Language Model Code Generation Mistakes: What and Why?",
    "authors": [
      "QiHong Chen",
      "Jiachen Yu",
      "Jiawei Li",
      "Jiecheng Deng",
      "Justin Tian Jin Chen",
      "Iftekhar Ahmed"
    ],
    "abstract": "Recent advancements in Large Language Models (LLMs) have led to their\nwidespread application in automated code generation. However, these models can\nstill generate defective code that deviates from the specification. Previous\nresearch has mainly focused on the mistakes in LLM-generated standalone\nfunctions, overlooking real-world software development situations where the\nsuccessful generation of the code requires software contexts such as external\ndependencies. In this paper, we considered both of these code generation\nsituations and identified a range of \\textit{non-syntactic mistakes} arising\nfrom LLMs' misunderstandings of coding question specifications. Seven\ncategories of non-syntactic mistakes were identified through extensive manual\nanalyses, four of which were missed by previous works. To better understand\nthese mistakes, we proposed six reasons behind these mistakes from various\nperspectives. Moreover, we explored the effectiveness of LLMs in detecting\nmistakes and their reasons. Our evaluation demonstrated that GPT-4 with the\nReAct prompting technique can achieve an F1 score of up to 0.65 when\nidentifying reasons for LLM's mistakes, such as misleading function signatures.\nWe believe that these findings offer valuable insights into enhancing the\nquality of LLM-generated code.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.01414v2",
    "published_date": "2024-11-03 02:47:03 UTC",
    "updated_date": "2025-03-20 11:21:07 UTC"
  },
  {
    "arxiv_id": "2411.01410v1",
    "title": "PageRank Bandits for Link Prediction",
    "authors": [
      "Yikun Ban",
      "Jiaru Zou",
      "Zihao Li",
      "Yunzhe Qi",
      "Dongqi Fu",
      "Jian Kang",
      "Hanghang Tong",
      "Jingrui He"
    ],
    "abstract": "Link prediction is a critical problem in graph learning with broad\napplications such as recommender systems and knowledge graph completion.\nNumerous research efforts have been directed at solving this problem, including\napproaches based on similarity metrics and Graph Neural Networks (GNN).\nHowever, most existing solutions are still rooted in conventional supervised\nlearning, which makes it challenging to adapt over time to changing customer\ninterests and to address the inherent dilemma of exploitation versus\nexploration in link prediction. To tackle these challenges, this paper\nreformulates link prediction as a sequential decision-making process, where\neach link prediction interaction occurs sequentially. We propose a novel fusion\nalgorithm, PRB (PageRank Bandits), which is the first to combine contextual\nbandits with PageRank for collaborative exploitation and exploration. We also\nintroduce a new reward formulation and provide a theoretical performance\nguarantee for PRB. Finally, we extensively evaluate PRB in both online and\noffline settings, comparing it with bandit-based and graph-based methods. The\nempirical success of PRB demonstrates the value of the proposed fusion\napproach. Our code is released at https://github.com/jiaruzouu/PRB.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.01410v1",
    "published_date": "2024-11-03 02:39:28 UTC",
    "updated_date": "2024-11-03 02:39:28 UTC"
  },
  {
    "arxiv_id": "2411.02448v2",
    "title": "Rate, Explain and Cite (REC): Enhanced Explanation and Attribution in Automatic Evaluation by Large Language Models",
    "authors": [
      "Aliyah R. Hsu",
      "James Zhu",
      "Zhichao Wang",
      "Bin Bi",
      "Shubham Mehrotra",
      "Shiva K. Pentyala",
      "Katherine Tan",
      "Xiang-Bo Mao",
      "Roshanak Omrani",
      "Sougata Chaudhuri",
      "Regunathan Radhakrishnan",
      "Sitaram Asur",
      "Claire Na Cheng",
      "Bin Yu"
    ],
    "abstract": "LLMs have demonstrated impressive proficiency in generating coherent and\nhigh-quality text, making them valuable across a range of text-generation\ntasks. However, rigorous evaluation of this generated content is crucial, as\nensuring its quality remains a significant challenge due to persistent issues\nsuch as factual inaccuracies and hallucination. This paper introduces three\nfine-tuned general-purpose LLM autoevaluators, REC-8B, REC-12B and REC-70B,\nspecifically designed to evaluate generated text across several dimensions:\nfaithfulness, instruction following, coherence, and completeness. These models\nnot only provide ratings for these metrics but also offer detailed explanation\nand verifiable citation, thereby enhancing trust in the content. Moreover, the\nmodels support various citation modes, accommodating different requirements for\nlatency and granularity. Extensive evaluations on diverse benchmarks\ndemonstrate that our general-purpose LLM auto-evaluator, REC-70B, outperforms\nstate-of-the-art LLMs, excelling in content evaluation by delivering better\nquality explanation and citation with minimal bias. It achieves Rank #1 as of\nFeb 15th, 2025 as a generative model on the RewardBench leaderboard under the\nmodel name TextEval-Llama3.1-70B. Our REC dataset and models are available at\nhttps://github.com/adelaidehsu/REC.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.02448v2",
    "published_date": "2024-11-03 02:36:33 UTC",
    "updated_date": "2025-02-19 00:50:10 UTC"
  },
  {
    "arxiv_id": "2411.01408v1",
    "title": "HeightMapNet: Explicit Height Modeling for End-to-End HD Map Learning",
    "authors": [
      "Wenzhao Qiu",
      "Shanmin Pang",
      "Hao zhang",
      "Jianwu Fang",
      "Jianru Xue"
    ],
    "abstract": "Recent advances in high-definition (HD) map construction from surround-view\nimages have highlighted their cost-effectiveness in deployment. However,\nprevailing techniques often fall short in accurately extracting and utilizing\nroad features, as well as in the implementation of view transformation. In\nresponse, we introduce HeightMapNet, a novel framework that establishes a\ndynamic relationship between image features and road surface height\ndistributions. By integrating height priors, our approach refines the accuracy\nof Bird's-Eye-View (BEV) features beyond conventional methods. HeightMapNet\nalso introduces a foreground-background separation network that sharply\ndistinguishes between critical road elements and extraneous background\ncomponents, enabling precise focus on detailed road micro-features.\nAdditionally, our method leverages multi-scale features within the BEV space,\noptimally utilizing spatial geometric information to boost model performance.\nHeightMapNet has shown exceptional results on the challenging nuScenes and\nArgoverse 2 datasets, outperforming several widely recognized approaches. The\ncode will be available at \\url{https://github.com/adasfag/HeightMapNet/}.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "This paper has been accepted to WACV 2025",
    "pdf_url": "http://arxiv.org/pdf/2411.01408v1",
    "published_date": "2024-11-03 02:35:17 UTC",
    "updated_date": "2024-11-03 02:35:17 UTC"
  },
  {
    "arxiv_id": "2411.01401v1",
    "title": "Pre-trained Molecular Language Models with Random Functional Group Masking",
    "authors": [
      "Tianhao Peng",
      "Yuchen Li",
      "Xuhong Li",
      "Jiang Bian",
      "Zeke Xie",
      "Ning Sui",
      "Shahid Mumtaz",
      "Yanwu Xu",
      "Linghe Kong",
      "Haoyi Xiong"
    ],
    "abstract": "Recent advancements in computational chemistry have leveraged the power of\ntrans-former-based language models, such as MoLFormer, pre-trained using a vast\namount of simplified molecular-input line-entry system (SMILES) sequences, to\nunderstand and predict molecular properties and activities, a critical step in\nfields like drug discovery and materials science. To further improve\nperformance, researchers have introduced graph neural networks with graph-based\nmolecular representations, such as GEM, incorporating the topology, geometry,\n2D or even 3D structures of molecules into pre-training. While most of\nmolecular graphs in existing studies were automatically converted from SMILES\nsequences, it is to assume that transformer-based language models might be able\nto implicitly learn structure-aware representations from SMILES sequences. In\nthis paper, we propose \\ours{} -- a SMILES-based \\underline{\\em M}olecular\n\\underline{\\em L}anguage \\underline{\\em M}odel, which randomly masking SMILES\nsubsequences corresponding to specific molecular \\underline{\\em F}unctional\n\\underline{\\em G}roups to incorporate structure information of atoms during the\npre-training phase. This technique aims to compel the model to better infer\nmolecular structures and properties, thus enhancing its predictive\ncapabilities. Extensive experimental evaluations across 11 benchmark\nclassification and regression tasks in the chemical domain demonstrate the\nrobustness and superiority of \\ours{}. Our findings reveal that \\ours{}\noutperforms existing pre-training models, either based on SMILES or graphs, in\n9 out of the 11 downstream tasks, ranking as a close second in the remaining\nones.",
    "categories": [
      "q-bio.BM",
      "cs.AI",
      "cs.LG",
      "physics.chem-ph"
    ],
    "primary_category": "q-bio.BM",
    "comment": "Under review",
    "pdf_url": "http://arxiv.org/pdf/2411.01401v1",
    "published_date": "2024-11-03 01:56:15 UTC",
    "updated_date": "2024-11-03 01:56:15 UTC"
  },
  {
    "arxiv_id": "2411.02446v1",
    "title": "Learning World Models for Unconstrained Goal Navigation",
    "authors": [
      "Yuanlin Duan",
      "Wensen Mao",
      "He Zhu"
    ],
    "abstract": "Learning world models offers a promising avenue for goal-conditioned\nreinforcement learning with sparse rewards. By allowing agents to plan actions\nor exploratory goals without direct interaction with the environment, world\nmodels enhance exploration efficiency. The quality of a world model hinges on\nthe richness of data stored in the agent's replay buffer, with expectations of\nreasonable generalization across the state space surrounding recorded\ntrajectories. However, challenges arise in generalizing learned world models to\nstate transitions backward along recorded trajectories or between states across\ndifferent trajectories, hindering their ability to accurately model real-world\ndynamics. To address these challenges, we introduce a novel goal-directed\nexploration algorithm, MUN (short for \"World Models for Unconstrained Goal\nNavigation\"). This algorithm is capable of modeling state transitions between\narbitrary subgoal states in the replay buffer, thereby facilitating the\nlearning of policies to navigate between any \"key\" states. Experimental results\ndemonstrate that MUN strengthens the reliability of world models and\nsignificantly improves the policy's capacity to generalize across new goal\nsettings.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "NeurIPS2024 Poster. arXiv admin note: substantial text overlap with\n  arXiv:2411.01396",
    "pdf_url": "http://arxiv.org/pdf/2411.02446v1",
    "published_date": "2024-11-03 01:35:06 UTC",
    "updated_date": "2024-11-03 01:35:06 UTC"
  },
  {
    "arxiv_id": "2411.10463v3",
    "title": "Unexploited Information Value in Human-AI Collaboration",
    "authors": [
      "Ziyang Guo",
      "Yifan Wu",
      "Jason Hartline",
      "Jessica Hullman"
    ],
    "abstract": "Humans and AIs are often paired on decision tasks with the expectation of\nachieving complementary performance -- where the combination of human and AI\noutperforms either one alone. However, how to improve performance of a human-AI\nteam is often not clear without knowing more about what particular information\nand strategies each agent employs. In this paper, we propose a model based in\nstatistical decision theory to analyze human-AI collaboration from the\nperspective of what information could be used to improve a human or AI\ndecision. We demonstrate our model on a deepfake detection task to investigate\nseven video-level features by their unexploited value of information. We\ncompare the human alone, AI alone and human-AI team and offer insights on how\nthe AI assistance impacts people's usage of the information and what\ninformation that the AI exploits well might be useful for improving human\ndecisions.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "We withdraw this version and direct readers to the updated version\n  available on arXiv. See the new version at arXiv:2502.06152",
    "pdf_url": "http://arxiv.org/pdf/2411.10463v3",
    "published_date": "2024-11-03 01:34:45 UTC",
    "updated_date": "2025-02-24 20:06:26 UTC"
  },
  {
    "arxiv_id": "2411.01396v1",
    "title": "Exploring the Edges of Latent State Clusters for Goal-Conditioned Reinforcement Learning",
    "authors": [
      "Yuanlin Duan",
      "Guofeng Cui",
      "He Zhu"
    ],
    "abstract": "Exploring unknown environments efficiently is a fundamental challenge in\nunsupervised goal-conditioned reinforcement learning. While selecting\nexploratory goals at the frontier of previously explored states is an effective\nstrategy, the policy during training may still have limited capability of\nreaching rare goals on the frontier, resulting in reduced exploratory behavior.\nWe propose \"Cluster Edge Exploration\" ($CE^2$), a new goal-directed exploration\nalgorithm that when choosing goals in sparsely explored areas of the state\nspace gives priority to goal states that remain accessible to the agent. The\nkey idea is clustering to group states that are easily reachable from one\nanother by the current policy under training in a latent space and traversing\nto states holding significant exploration potential on the boundary of these\nclusters before doing exploratory behavior. In challenging robotics\nenvironments including navigating a maze with a multi-legged ant robot,\nmanipulating objects with a robot arm on a cluttered tabletop, and rotating\nobjects in the palm of an anthropomorphic robotic hand, $CE^2$ demonstrates\nsuperior efficiency in exploration compared to baseline methods and ablations.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "NeurIPS2024 Poster",
    "pdf_url": "http://arxiv.org/pdf/2411.01396v1",
    "published_date": "2024-11-03 01:21:43 UTC",
    "updated_date": "2024-11-03 01:21:43 UTC"
  }
]