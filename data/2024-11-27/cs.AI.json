{
  "date": "2024-11-27",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-11-27 的 arXiv 中文 TLDR 快报！今天 arXiv 更新了 108 篇论文，主要聚焦 AI 模型优化（如 LLM 和多模态学习）、计算机视觉、机器人交互以及实际应用（如医疗和强化学习），亮点包括 LLM 在机器人和生成任务中的创新应用，以及多篇涉及知名学者如 James M. Rehg 的作品；其中，RelCon 和 UOE 等论文因其在自监督学习和模型鲁棒性上的突破，值得关注。\n\n下面，我将按主题归类并优先讨论重要、话题性强的论文（如 LLM、视觉生成和机器人），快速掠过较基础或特定领域的文章。每篇论文会列出标题（中文 + 英文），并简要描述其主要贡献和发现。\n\n### LLM 和多模态模型优化\n- **RelCon: 相对对比学习用于可穿戴数据运动基础模型（RelCon: Relative Contrastive Learning for a Motion Foundation Model for Wearable Data）**：这篇论文提出了一种自监督相对对比学习方法，用于训练可穿戴加速度计数据的运动模型，显著提升了人类活动识别和步态度量任务的性能，首次展示了基础模型在跨任务泛化上的潜力。\n- **UOE: 仅需卸载一个专家即可用于混合专家 LLM（UOE: Unlearning One Expert Is Enough For Mixture-of-experts LLMS）**：作者 Haomin Zhuang 等开发了 UOE 框架，通过专家归因和锚定损失专注于特定知识的卸载，提高了混合专家 LLM 的遗忘质量和实用性，实验显示在各种基准上提升了 35% 的模型效用。\n- **Differential learning kinetics govern the transition from memorization to generalization during in-context learning（微分学习动力学在 in-context 学习中从记忆到泛化的过渡）**：论文揭示了 Transformer 在任务多样性下的学习机制，使用理论和实验证明子电路的相对学习速率决定了泛化过渡，提供了解释 in-context 学习行为的洞见。\n- **Immune: Improving Safety Against Jailbreaks in Multi-modal LLMs via Inference-Time Alignment（Immune: 通过推理时对齐改善多模态 LLM 的越狱安全性）**：这篇论文（被 CVPR 2025 接受）提出 Inference-Time Alignment 框架，使用安全奖励模型防御多模态 LLM 的越狱攻击，显著降低了攻击成功率，同时保持模型性能。\n- 其他如 **Unifying Generative and Dense Retrieval for Sequential Recommendation（统一生成式和密集检索用于序列推荐）** 和 **NewsEdits 2.0: Learning the Intentions Behind Updating News（NewsEdits 2.0: 学习新闻更新的意图）** 等，分别探讨了推荐系统和新闻更新的优化，但影响力稍逊，快速提及：前者通过混合模型 LIGER 提升了冷启动推荐效率，后者使用 LLM 预测新闻事实更新以提高准确性。\n\n### 计算机视觉和图像生成\n- **MLLM-Search: A Zero-Shot Approach to Finding People using Multimodal Large Language Models（MLLM-Search: 使用多模态 LLM 的零样本人查找方法）**：论文引入 MLLM-Search 框架，利用视觉提示和语义规划实现机器人零样本人搜索，实验证明在真实环境中提升了搜索效率。\n- **MatchDiffusion: Training-free Generation of Match-cuts（MatchDiffusion: 无需训练的匹配剪辑生成）**：作者提出无训练的 MatchDiffusion 方法，使用扩散模型生成视频匹配剪辑，显著改善了视频编辑的连贯性和效率。\n- **Diffusion Self-Distillation for Zero-Shot Customized Image Generation（扩散自蒸馏用于零样本自定义图像生成）**：这篇论文开发了扩散自蒸馏框架，实现零样本图像生成，实验显示在身份保持生成任务上超越了现有方法。\n- 其他视觉相关如 **CoVis: A Collaborative Framework for Fine-grained Graphic Visual Understanding（CoVis: 细粒度图形视觉理解的协作框架）** 和 **Enhancing Document AI Data Generation Through Graph-Based Synthetic Layouts（通过基于图的合成布局增强文档 AI 数据生成）** 等，贡献包括细粒度图像分析和文档布局生成，但不为核心热点，故简要：CoVis 通过级联网络提升了视觉描述的全面性。\n\n### 机器人和交互应用\n- **Embodied Red Teaming for Auditing Robotic Foundation Models（用于审计机器人基础模型的实体红队测试）**：论文提出实体红队框架，使用视觉语言模型生成多样指令测试机器人模型，揭示了现有模型在真实场景下的失败点。\n- **GaussianSpeech: Audio-Driven Gaussian Avatars（GaussianSpeech: 音频驱动的高斯头像）**：作者使用 3D 高斯点云和音频建模生成逼真的头像动画，实验在真实数据上实现了高保真度序列生成。\n- **Explainable deep learning improves human mental models of self-driving cars（可解释深度学习改善人类对自动驾驶汽车的心理模型）**：这篇论文（涉及知名学者 Julie A. Shah）开发了 CW-Net 方法，通过可解释概念提升人类对自动驾驶行为的预测，首次在真实车辆上验证了其效果。\n\n### 其他领域快速掠过\n- 强化学习和时间序列如 **Robust Offline Reinforcement Learning with Linearly Structured f-Divergence Regularization（鲁棒离线强化学习使用线性结构 f-散度正则化）** 和 **The Performance of the LSTM-based Code Generated by Large Language Models（LLM 生成的 LSTM 代码在时间序列预测中的性能）** 等，贡献包括鲁棒策略学习和 LLM 生成代码的评估，但不为主流，故简述：前者提升了离线 RL 的鲁棒性，后者显示 ChatGPT 在预测任务中表现最佳。\n- 医疗和生成模型如 **PDZSeg: Adapting the Foundation Model for Dissection Zone Segmentation（PDZSeg: 适应基础模型用于切割区分割）** 和 **SALMONN-omni: A Codec-free LLM for Full-duplex Speech Understanding and Generation（SALMONN-omni: 无编解码器 LLM 用于全双工语音理解和生成）**，快速提及：PDZSeg 通过视觉提示改善了内镜手术分割，SALMONN-omni 实现了高效的多模态对话。\n- 其余论文，如金融或数据生成主题（e.g., **Automated Literature Review Using NLP Techniques and LLM-Based Retrieval-Augmented Generation**），虽有实用价值，但非核心，均简要掠过不详述。\n\n总之，今天的论文突出了 AI 模型在实际应用中的潜力，特别是 LLM 的优化和多模态融合。感兴趣的读者可关注 RelCon 和 UOE 等创新工作，以探索 AI 的前沿进展。更多细节请查阅 arXiv！",
  "papers": [
    {
      "arxiv_id": "2411.18822v5",
      "title": "RelCon: Relative Contrastive Learning for a Motion Foundation Model for Wearable Data",
      "title_zh": "翻译失败",
      "authors": [
        "Maxwell A. Xu",
        "Jaya Narain",
        "Gregory Darnell",
        "Haraldur Hallgrimsson",
        "Hyewon Jeong",
        "Darren Forde",
        "Richard Fineman",
        "Karthik J. Raghuram",
        "James M. Rehg",
        "Shirley Ren"
      ],
      "abstract": "We present RelCon, a novel self-supervised Relative Contrastive learning\napproach for training a motion foundation model from wearable accelerometry\nsensors. First, a learnable distance measure is trained to capture motif\nsimilarity and domain-specific semantic information such as rotation\ninvariance. Then, the learned distance provides a measurement of semantic\nsimilarity between a pair of accelerometry time-series, which we use to train\nour foundation model to model relative relationships across time and across\nsubjects. The foundation model is trained on 1 billion segments from 87,376\nparticipants, and achieves state-of-the-art performance across multiple\ndownstream tasks, including human activity recognition and gait metric\nregression. To our knowledge, we are the first to show the generalizability of\na foundation model with motion data from wearables across distinct evaluation\ntasks.",
      "tldr_zh": "本研究提出RelCon，一种自监督的Relative Contrastive Learning方法，用于从可穿戴加速度计传感器训练一个运动基础模型。首先，该方法训练一个可学习的距离度量来捕捉图案相似性以及领域特定语义信息，如旋转不变性，然后利用该距离度量训练模型，以建模时间和跨主体的相对关系。基础模型使用来自87,376名参与者的10亿段数据进行训练，在多个下游任务中（如人类活动识别和步态指标回归）实现了最先进性能。RelCon首次证明了基础模型在可穿戴运动数据上的泛化能力，适用于不同评估任务。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "Accepted to ICLR 2025. Code here: https://github.com/maxxu05/relcon",
      "pdf_url": "http://arxiv.org/pdf/2411.18822v5",
      "published_date": "2024-11-27 23:51:53 UTC",
      "updated_date": "2025-04-10 22:16:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:52:28.132779"
    },
    {
      "arxiv_id": "2411.18814v2",
      "title": "Unifying Generative and Dense Retrieval for Sequential Recommendation",
      "title_zh": "统一生成式和稠密检索用于序列推荐",
      "authors": [
        "Liu Yang",
        "Fabian Paischer",
        "Kaveh Hassani",
        "Jiacheng Li",
        "Shuai Shao",
        "Zhang Gabriel Li",
        "Yun He",
        "Xue Feng",
        "Nima Noorshams",
        "Sem Park",
        "Bo Long",
        "Robert D Nowak",
        "Xiaoli Gao",
        "Hamid Eghbalzadeh"
      ],
      "abstract": "Sequential dense retrieval models utilize advanced sequence learning\ntechniques to compute item and user representations, which are then used to\nrank relevant items for a user through inner product computation between the\nuser and all item representations. However, this approach requires storing a\nunique representation for each item, resulting in significant memory\nrequirements as the number of items grow. In contrast, the recently proposed\ngenerative retrieval paradigm offers a promising alternative by directly\npredicting item indices using a generative model trained on semantic IDs that\nencapsulate items' semantic information. Despite its potential for large-scale\napplications, a comprehensive comparison between generative retrieval and\nsequential dense retrieval under fair conditions is still lacking, leaving open\nquestions regarding performance, and computation trade-offs. To address this,\nwe compare these two approaches under controlled conditions on academic\nbenchmarks and propose LIGER (LeveragIng dense retrieval for GEnerative\nRetrieval), a hybrid model that combines the strengths of these two widely used\nmethods. LIGER integrates sequential dense retrieval into generative retrieval,\nmitigating performance differences and enhancing cold-start item recommendation\nin the datasets evaluated. This hybrid approach provides insights into the\ntrade-offs between these approaches and demonstrates improvements in efficiency\nand effectiveness for recommendation systems in small-scale benchmarks.",
      "tldr_zh": "本论文探讨了顺序密集检索（sequential dense retrieval）和生成式检索（generative retrieval）在序列推荐系统中的优缺点，前者因需存储大量物品表示而面临内存挑战，后者通过生成模型预测物品索引更适合大规模应用，但两者缺乏公平比较。作者在学术基准上进行了对照实验，并提出LIGER（LeveragIng dense retrieval for GEnerative Retrieval）混合模型，将顺序密集检索整合到生成式检索中，以缓解性能差异并提升冷启动物品推荐。实验结果显示，LIGER在小规模基准上提高了推荐系统的效率和有效性，提供宝贵的权衡洞见。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.18814v2",
      "published_date": "2024-11-27 23:36:59 UTC",
      "updated_date": "2024-12-06 23:09:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:52:40.339996"
    },
    {
      "arxiv_id": "2411.18811v1",
      "title": "NewsEdits 2.0: Learning the Intentions Behind Updating News",
      "title_zh": "NewsEdits 2.0：学习更新新闻背后的意图",
      "authors": [
        "Alexander Spangher",
        "Kung-Hsiang Huang",
        "Hyundong Cho",
        "Jonathan May"
      ],
      "abstract": "As events progress, news articles often update with new information: if we\nare not cautious, we risk propagating outdated facts. In this work, we\nhypothesize that linguistic features indicate factual fluidity, and that we can\npredict which facts in a news article will update using solely the text of a\nnews article (i.e. not external resources like search engines). We test this\nhypothesis, first, by isolating fact-updates in large news revisions corpora.\nNews articles may update for many reasons (e.g. factual, stylistic, narrative).\nWe introduce the NewsEdits 2.0 taxonomy, an edit-intentions schema that\nseparates fact updates from stylistic and narrative updates in news writing. We\nannotate over 9,200 pairs of sentence revisions and train high-scoring ensemble\nmodels to apply this schema. Then, taking a large dataset of silver-labeled\npairs, we show that we can predict when facts will update in older article\ndrafts with high precision. Finally, to demonstrate the usefulness of these\nfindings, we construct a language model question asking (LLM-QA) abstention\ntask. We wish the LLM to abstain from answering questions when information is\nlikely to become outdated. Using our predictions, we show, LLM absention\nreaches near oracle levels of accuracy.",
      "tldr_zh": "本研究假设新闻文章的语言特征可用于预测事实更新，从而避免传播过时信息，仅依赖文章文本（不需外部资源）。他们引入了 NewsEdits 2.0 taxonomy，这是一个编辑意图分类系统，用于区分新闻修订中的事实更新、风格更新和叙述更新，并标注了超过9,200对句子修订对来训练高分集成模型。利用大型银标签数据集，该模型实现了高精度预测旧文章草稿中哪些事实将更新。最后，通过构建语言模型问答 (LLM-QA) 弃权任务，使用这些预测使LLM在信息可能过时时选择不回答，达到了接近预言家水平的准确性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DL"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages main body, 11 pages appendix",
      "pdf_url": "http://arxiv.org/pdf/2411.18811v1",
      "published_date": "2024-11-27 23:35:23 UTC",
      "updated_date": "2024-11-27 23:35:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:52:52.418548"
    },
    {
      "arxiv_id": "2411.18797v1",
      "title": "UOE: Unlearning One Expert Is Enough For Mixture-of-experts LLMS",
      "title_zh": "翻译失败",
      "authors": [
        "Haomin Zhuang",
        "Yihua Zhang",
        "Kehan Guo",
        "Jinghan Jia",
        "Gaowen Liu",
        "Sijia Liu",
        "Xiangliang Zhang"
      ],
      "abstract": "Recent advancements in large language model (LLM) unlearning have shown\nremarkable success in removing unwanted data-model influences while preserving\nthe model's utility for legitimate knowledge. However, despite these strides,\nsparse Mixture-of-Experts (MoE) LLMs--a key subset of the LLM family--have\nreceived little attention and remain largely unexplored in the context of\nunlearning. As MoE LLMs are celebrated for their exceptional performance and\nhighly efficient inference processes, we ask: How can unlearning be performed\neffectively and efficiently on MoE LLMs? And will traditional unlearning\nmethods be applicable to MoE architectures? Our pilot study shows that the\ndynamic routing nature of MoE LLMs introduces unique challenges, leading to\nsubstantial utility drops when existing unlearning methods are applied.\nSpecifically, unlearning disrupts the router's expert selection, causing\nsignificant selection shift from the most unlearning target-related experts to\nirrelevant ones. As a result, more experts than necessary are affected, leading\nto excessive forgetting and loss of control over which knowledge is erased. To\naddress this, we propose a novel single-expert unlearning framework, referred\nto as UOE, for MoE LLMs. Through expert attribution, unlearning is concentrated\non the most actively engaged expert for the specified knowledge. Concurrently,\nan anchor loss is applied to the router to stabilize the active state of this\ntargeted expert, ensuring focused and controlled unlearning that preserves\nmodel utility. The proposed UOE framework is also compatible with various\nunlearning algorithms. Extensive experiments demonstrate that UOE enhances both\nforget quality up to 5% and model utility by 35% on MoE LLMs across various\nbenchmarks, LLM architectures, while only unlearning 0.06% of the model\nparameters.",
      "tldr_zh": "本研究探讨了在Mixture-of-Experts (MoE) LLMs上进行unlearning的挑战，指出现有方法会导致路由器专家选择偏移，造成过度遗忘和模型性能下降。针对此问题，作者提出UOE框架，通过expert attribution识别与目标知识最相关的单个专家，并集中unlearning于该专家，同时使用anchor loss稳定路由器以保持模型整体效用。实验结果显示，UOE在各种基准和架构上将forget quality提升高达5%，模型utility提高35%，且仅需unlearning 0.06%的参数，实现了高效且可控的知识擦除。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.18797v1",
      "published_date": "2024-11-27 22:46:08 UTC",
      "updated_date": "2024-11-27 22:46:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:53:03.833820"
    },
    {
      "arxiv_id": "2412.00104v2",
      "title": "Differential learning kinetics govern the transition from memorization to generalization during in-context learning",
      "title_zh": "翻译失败",
      "authors": [
        "Alex Nguyen",
        "Gautam Reddy"
      ],
      "abstract": "Transformers exhibit in-context learning (ICL): the ability to use novel\ninformation presented in the context without additional weight updates. Recent\nwork shows that ICL emerges when models are trained on a sufficiently diverse\nset of tasks and the transition from memorization to generalization is sharp\nwith increasing task diversity. One interpretation is that a network's limited\ncapacity to memorize favors generalization. Here, we examine the mechanistic\nunderpinnings of this transition using a small transformer applied to a\nsynthetic ICL task. Using theory and experiment, we show that the sub-circuits\nthat memorize and generalize can be viewed as largely independent. The relative\nrates at which these sub-circuits learn explains the transition from\nmemorization to generalization, rather than capacity constraints. We uncover a\nmemorization scaling law, which determines the task diversity threshold at\nwhich the network generalizes. The theory quantitatively explains a variety of\nother ICL-related phenomena, including the long-tailed distribution of when ICL\nis acquired, the bimodal behavior of solutions close to the task diversity\nthreshold, the influence of contextual and data distributional statistics on\nICL, and the transient nature of ICL.",
      "tldr_zh": "本研究探讨了 Transformers 模型在 in-context learning (ICL) 中的机制，揭示从 memorization 到 generalization 的转变是由 differential learning kinetics（差异学习动力学）驱动的，而不是容量限制。作者通过小型 transformer 和合成任务的理论与实验分析，证明 memorization 和 generalization 的 sub-circuits 是 largely independent，且它们的相对学习速率决定了任务多样性阈值。论文还引入 memorization scaling law，并解释了 ICL 的 long-tailed distribution、bimodal behavior、数据分布影响以及 transient nature 等现象，为理解 ICL 提供了量化框架。",
      "categories": [
        "cs.LG",
        "cond-mat.dis-nn",
        "cs.AI",
        "cs.NE",
        "q-bio.NC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.00104v2",
      "published_date": "2024-11-27 22:12:29 UTC",
      "updated_date": "2024-12-12 16:10:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:53:16.715770"
    },
    {
      "arxiv_id": "2412.00103v1",
      "title": "MLLM-Search: A Zero-Shot Approach to Finding People using Multimodal Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Angus Fung",
        "Aaron Hao Tan",
        "Haitong Wang",
        "Beno Benhabib",
        "Goldie Nejat"
      ],
      "abstract": "Robotic search of people in human-centered environments, including healthcare\nsettings, is challenging as autonomous robots need to locate people without\ncomplete or any prior knowledge of their schedules, plans or locations.\nFurthermore, robots need to be able to adapt to real-time events that can\ninfluence a person's plan in an environment. In this paper, we present\nMLLM-Search, a novel zero-shot person search architecture that leverages\nmultimodal large language models (MLLM) to address the mobile robot problem of\nsearching for a person under event-driven scenarios with varying user\nschedules. Our approach introduces a novel visual prompting method to provide\nrobots with spatial understanding of the environment by generating a spatially\ngrounded waypoint map, representing navigable waypoints by a topological graph\nand regions by semantic labels. This is incorporated into a MLLM with a region\nplanner that selects the next search region based on the semantic relevance to\nthe search scenario, and a waypoint planner which generates a search path by\nconsidering the semantically relevant objects and the local spatial context\nthrough our unique spatial chain-of-thought prompting approach. Extensive 3D\nphotorealistic experiments were conducted to validate the performance of\nMLLM-Search in searching for a person with a changing schedule in different\nenvironments. An ablation study was also conducted to validate the main design\nchoices of MLLM-Search. Furthermore, a comparison study with state-of-the art\nsearch methods demonstrated that MLLM-Search outperforms existing methods with\nrespect to search efficiency. Real-world experiments with a mobile robot in a\nmulti-room floor of a building showed that MLLM-Search was able to generalize\nto finding a person in a new unseen environment.",
      "tldr_zh": "这篇论文提出了MLLM-Search，一种零样本（zero-shot）方法，利用多模态大语言模型（Multimodal Large Language Models）来帮助机器人搜索人，特别是在事件驱动的动态环境中，如医疗设置。核心创新包括视觉提示生成的空间定位航点地图（waypoint map），结合区域规划器（基于语义相关性选择搜索区域）和航点规划器（通过空间链式思维提示考虑语义对象和本地上下文）。实验结果显示，MLLM-Search在3D光照真实环境和真实世界测试中，比现有方法在搜索效率上提升显著，并能泛化到未见环境。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.00103v1",
      "published_date": "2024-11-27 21:59:29 UTC",
      "updated_date": "2024-11-27 21:59:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:53:28.724806"
    },
    {
      "arxiv_id": "2411.18764v1",
      "title": "CoVis: A Collaborative Framework for Fine-grained Graphic Visual Understanding",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaoyu Deng",
        "Zhengjian Kang",
        "Xintao Li",
        "Yongzhe Zhang",
        "Tianmin Guo"
      ],
      "abstract": "Graphic visual content helps in promoting information communication and\ninspiration divergence. However, the interpretation of visual content currently\nrelies mainly on humans' personal knowledge background, thereby affecting the\nquality and efficiency of information acquisition and understanding. To improve\nthe quality and efficiency of visual information transmission and avoid the\nlimitation of the observer due to the information cocoon, we propose CoVis, a\ncollaborative framework for fine-grained visual understanding. By designing and\nimplementing a cascaded dual-layer segmentation network coupled with a\nlarge-language-model (LLM) based content generator, the framework extracts as\nmuch knowledge as possible from an image. Then, it generates visual analytics\nfor images, assisting observers in comprehending imagery from a more holistic\nperspective. Quantitative experiments and qualitative experiments based on 32\nhuman participants indicate that the CoVis has better performance than current\nmethods in feature extraction and can generate more comprehensive and detailed\nvisual descriptions than current general-purpose large models.",
      "tldr_zh": "论文提出 CoVis 框架，这是一个协作式系统，旨在提升图形视觉内容的细粒度理解，避免受限于观察者的个人知识背景和信息茧房。框架通过设计级联双层分割网络（cascaded dual-layer segmentation network）结合大型语言模型（LLM）基于的内容生成器，从图像中提取最大化知识，并生成全面的视觉分析以辅助观察者。实验结果显示，CoVis 在特征提取方面优于当前方法，并在定量和定性评估（包括32名参与者）中产生更详细的视觉描述。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.18764v1",
      "published_date": "2024-11-27 21:38:04 UTC",
      "updated_date": "2024-11-27 21:38:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:53:40.061532"
    },
    {
      "arxiv_id": "2412.03590v1",
      "title": "Enhancing Document AI Data Generation Through Graph-Based Synthetic Layouts",
      "title_zh": "通过基于图的合成布局增强文档 AI 数据生成",
      "authors": [
        "Amit Agarwal",
        "Hitesh Patel",
        "Priyaranjan Pattnayak",
        "Srikant Panda",
        "Bhargava Kumar",
        "Tejaswini Kumar"
      ],
      "abstract": "The development of robust Document AI models has been constrained by limited\naccess to high-quality, labeled datasets, primarily due to data privacy\nconcerns, scarcity, and the high cost of manual annotation. Traditional methods\nof synthetic data generation, such as text and image augmentation, have proven\neffective for increasing data diversity but often fail to capture the complex\nlayout structures present in real world documents. This paper proposes a novel\napproach to synthetic document layout generation using Graph Neural Networks\n(GNNs). By representing document elements (e.g., text blocks, images, tables)\nas nodes in a graph and their spatial relationships as edges, GNNs are trained\nto generate realistic and diverse document layouts. This method leverages\ngraph-based learning to ensure structural coherence and semantic consistency,\naddressing the limitations of traditional augmentation techniques. The proposed\nframework is evaluated on tasks such as document classification, named entity\nrecognition (NER), and information extraction, demonstrating significant\nperformance improvements. Furthermore, we address the computational challenges\nof GNN based synthetic data generation and propose solutions to mitigate domain\nadaptation issues between synthetic and real-world datasets. Our experimental\nresults show that graph-augmented document layouts outperform existing\naugmentation techniques, offering a scalable and flexible solution for training\nDocument AI models.",
      "tldr_zh": "这篇论文针对Document AI模型的数据生成问题，提出了一种基于Graph Neural Networks (GNNs)的合成文档布局生成方法，以解决传统增强技术无法捕捉真实文档复杂结构的问题。通过将文档元素（如文本块、图像、表格）表示为图中的节点，并利用其空间关系作为边，GNNs确保生成的布局具备结构连贯性和语义一致性。实验结果显示，该框架在文档分类、Named Entity Recognition (NER)和信息提取任务上显著提升了性能，并通过优化计算挑战和领域适配策略，提供了一个可扩展的解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.6; I.2.7; I.5.4; H.3.3; H.2.8; G.2.2"
      ],
      "primary_category": "cs.CL",
      "comment": "Published in IJERT, Volume 13, Issue 10 (October 2024)",
      "pdf_url": "http://arxiv.org/pdf/2412.03590v1",
      "published_date": "2024-11-27 21:15:02 UTC",
      "updated_date": "2024-11-27 21:15:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:53:52.466175"
    },
    {
      "arxiv_id": "2411.18731v1",
      "title": "The Performance of the LSTM-based Code Generated by Large Language Models (LLMs) in Forecasting Time Series Data",
      "title_zh": "翻译失败",
      "authors": [
        "Saroj Gopali",
        "Sima Siami-Namini",
        "Faranak Abri",
        "Akbar Siami Namin"
      ],
      "abstract": "As an intriguing case is the goodness of the machine and deep learning models\ngenerated by these LLMs in conducting automated scientific data analysis, where\na data analyst may not have enough expertise in manually coding and optimizing\ncomplex deep learning models and codes and thus may opt to leverage LLMs to\ngenerate the required models. This paper investigates and compares the\nperformance of the mainstream LLMs, such as ChatGPT, PaLM, LLama, and Falcon,\nin generating deep learning models for analyzing time series data, an important\nand popular data type with its prevalent applications in many application\ndomains including financial and stock market. This research conducts a set of\ncontrolled experiments where the prompts for generating deep learning-based\nmodels are controlled with respect to sensitivity levels of four criteria\nincluding 1) Clarify and Specificity, 2) Objective and Intent, 3) Contextual\nInformation, and 4) Format and Style. While the results are relatively mix, we\nobserve some distinct patterns. We notice that using LLMs, we are able to\ngenerate deep learning-based models with executable codes for each dataset\nseperatly whose performance are comparable with the manually crafted and\noptimized LSTM models for predicting the whole time series dataset. We also\nnoticed that ChatGPT outperforms the other LLMs in generating more accurate\nmodels. Furthermore, we observed that the goodness of the generated models vary\nwith respect to the ``temperature'' parameter used in configuring LLMS. The\nresults can be beneficial for data analysts and practitioners who would like to\nleverage generative AIs to produce good prediction models with acceptable\ngoodness.",
      "tldr_zh": "这篇论文评估了大型语言模型（LLMs）如 ChatGPT、PaLM、Llama 和 Falcon 在生成基于 LSTM 的代码用于时间序列数据预测方面的性能，通过控制提示的四个标准（Clarify and Specificity、Objective and Intent、Contextual Information、Format and Style）进行了一系列实验。结果显示，LLMs 生成的模型代码能够产生与手动优化的 LSTM 模型相当的预测性能，且 ChatGPT 在准确性上表现出色。研究还发现，LLMs 的 \"temperature\" 参数会影响生成模型的质量，这些发现为数据分析师利用生成式 AI 构建高效预测模型提供了实用指导。",
      "categories": [
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.18731v1",
      "published_date": "2024-11-27 20:18:36 UTC",
      "updated_date": "2024-11-27 20:18:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:54:05.783970"
    },
    {
      "arxiv_id": "2411.18727v1",
      "title": "Generative Visual Communication in the Era of Vision-Language Models",
      "title_zh": "生成式视觉传达在视觉语言模型时代",
      "authors": [
        "Yael Vinker"
      ],
      "abstract": "Visual communication, dating back to prehistoric cave paintings, is the use\nof visual elements to convey ideas and information. In today's visually\nsaturated world, effective design demands an understanding of graphic design\nprinciples, visual storytelling, human psychology, and the ability to distill\ncomplex information into clear visuals. This dissertation explores how recent\nadvancements in vision-language models (VLMs) can be leveraged to automate the\ncreation of effective visual communication designs. Although generative models\nhave made great progress in generating images from text, they still struggle to\nsimplify complex ideas into clear, abstract visuals and are constrained by\npixel-based outputs, which lack flexibility for many design tasks. To address\nthese challenges, we constrain the models' operational space and introduce\ntask-specific regularizations. We explore various aspects of visual\ncommunication, namely, sketches and visual abstraction, typography, animation,\nand visual inspiration.",
      "tldr_zh": "这篇论文探讨了如何利用视觉语言模型（VLMs）自动化视觉沟通设计，以应对生成模型在简化复杂想法和灵活性上的挑战，如难以创建抽象视觉和受限于像素输出。论文提出通过约束模型的操作空间并引入任务特定正则化，来提升设计的有效性。研究重点探索了草图、视觉抽象、排版、动画和视觉灵感等关键方面，为视觉沟通领域提供了创新方法和潜在改进路径。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "PhD Thesis",
      "pdf_url": "http://arxiv.org/pdf/2411.18727v1",
      "published_date": "2024-11-27 20:04:31 UTC",
      "updated_date": "2024-11-27 20:04:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:54:16.493754"
    },
    {
      "arxiv_id": "2412.09632v2",
      "title": "Methods to Assess the UK Government's Current Role as a Data Provider for AI",
      "title_zh": "评估 UK 政府作为 AI 数据提供者当前角色的方法",
      "authors": [
        "Neil Majithia",
        "Elena Simperl"
      ],
      "abstract": "Governments typically collect and steward a vast amount of high-quality data\non their citizens and institutions, and the UK government is exploring how it\ncan better publish and provision this data to the benefit of the AI landscape.\nHowever, the compositions of generative AI training corpora remain closely\nguarded secrets, making the planning of data sharing initiatives difficult. To\naddress this, we devise two methods to assess UK government data usage for the\ntraining of Large Language Models (LLMs) and 'peek behind the curtain' in order\nto observe the UK government's current contributions as a data provider for AI.\nThe first method, an ablation study that utilises LLM 'unlearning', seeks to\nexamine the importance of the information held on UK government websites for\nLLMs and their performance in citizen query tasks. The second method, an\ninformation leakage study, seeks to ascertain whether LLMs are aware of the\ninformation held in the datasets published on the UK government's open data\ninitiative data$.$gov$.$uk. Our findings indicate that UK government websites\nare important data sources for AI (heterogenously across subject matters) while\ndata$.$gov$.$uk is not. This paper serves as a technical report, explaining\nin-depth the designs, mechanics, and limitations of the above experiments. It\nis accompanied by a complementary non-technical report on the ODI website in\nwhich we summarise the experiments and key findings, interpret them, and build\na set of actionable recommendations for the UK government to take forward as it\nseeks to design AI policy. While we focus on UK open government data, we\nbelieve that the methods introduced in this paper present a reproducible\napproach to tackle the opaqueness of AI training corpora and provide\norganisations a framework to evaluate and maximize their contributions to AI\ndevelopment.",
      "tldr_zh": "本研究探讨了英国政府作为AI数据提供者的角色，提出两种方法评估其数据在Large Language Models (LLMs) 训练中的使用，以应对AI训练语料库不透明的问题。第一种方法是基于LLM 'unlearning'的消融研究（ablation study），用于检验英国政府网站信息对LLMs处理公民查询任务的影响；第二种方法是信息泄漏研究（information leakage study），评估LLMs是否了解data.gov.uk上发布的开放数据集。结果表明，英国政府网站在不同主题上对AI至关重要，而data.gov.uk的影响有限。该文作为技术报告，提供实验设计、机制和限制的详细说明，并附带行动建议，帮助政府和组织优化对AI发展的贡献。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CY",
      "comment": "17 pages, 5 figures; v2 - incorporated editor feedback; for the\n  accompanying, non-technical ODI report see\n  https://theodi.org/insights/reports/the-uk-government-as-a-data-provider-for-ai",
      "pdf_url": "http://arxiv.org/pdf/2412.09632v2",
      "published_date": "2024-11-27 19:53:05 UTC",
      "updated_date": "2024-12-18 15:55:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:54:29.226053"
    },
    {
      "arxiv_id": "2411.18719v1",
      "title": "Timing Matters: Enhancing User Experience through Temporal Prediction in Smart Homes",
      "title_zh": "时机至关重要：通过时间预测提升智能家居用户体验",
      "authors": [
        "Shrey Ganatra",
        "Spandan Anaokar",
        "Pushpak Bhattacharyya"
      ],
      "abstract": "Have you ever considered the sheer volume of actions we perform using IoT\n(Internet of Things) devices within our homes, offices, and daily environments?\nFrom the mundane act of flicking a light switch to the precise adjustment of\nroom temperatures, we are surrounded by a wealth of data, each representing a\nglimpse into user behaviour. While existing research has sought to decipher\nuser behaviours from these interactions and their timestamps, a critical\ndimension still needs to be explored: the timing of these actions. Despite\nextensive efforts to understand and forecast user behaviours, the temporal\ndimension of these interactions has received scant attention. However, the\ntiming of actions holds profound implications for user experience, efficiency,\nand overall satisfaction with intelligent systems. In our paper, we venture\ninto the less-explored realm of human-centric AI by endeavoring to predict user\nactions and their timing. To achieve this, we contribute a meticulously\nsynthesized dataset comprising 11k sequences of actions paired with their\nrespective date and time stamps. Building upon this dataset, we propose our\nmodel, which employs advanced machine learning techniques for k-class\nclassification over time intervals within a day. To the best of our knowledge,\nthis is the first attempt at time prediction for smart homes. We achieve a 40%\n(96-class) accuracy across all datasets and an 80% (8-class) accuracy on the\ndataset containing exact timestamps, showcasing the efficacy of our approach in\npredicting the temporal dynamics of user actions within smart environments.",
      "tldr_zh": "这篇论文强调了在智能家居中，用户动作的时机（timing）对提升用户体验的重要性，并指出现有研究忽略了这一关键维度。研究者贡献了一个包含11k行动序列的合成数据集，每个序列配有日期和时间戳，并提出一个基于机器学习的k-class分类模型，用于预测用户动作在一天内的具体时间间隔。该模型在实验中实现了40%（96类）和80%（8类）的准确率，这是智能家居领域首次针对时间预测的尝试。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "7 pages + 1 reference, 5 figures, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2411.18719v1",
      "published_date": "2024-11-27 19:49:11 UTC",
      "updated_date": "2024-11-27 19:49:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:54:40.366213"
    },
    {
      "arxiv_id": "2411.18714v1",
      "title": "Explainable deep learning improves human mental models of self-driving cars",
      "title_zh": "翻译失败",
      "authors": [
        "Eoin M. Kenny",
        "Akshay Dharmavaram",
        "Sang Uk Lee",
        "Tung Phan-Minh",
        "Shreyas Rajesh",
        "Yunqing Hu",
        "Laura Major",
        "Momchil S. Tomov",
        "Julie A. Shah"
      ],
      "abstract": "Self-driving cars increasingly rely on deep neural networks to achieve\nhuman-like driving. However, the opacity of such black-box motion planners\nmakes it challenging for the human behind the wheel to accurately anticipate\nwhen they will fail, with potentially catastrophic consequences. Here, we\nintroduce concept-wrapper network (i.e., CW-Net), a method for explaining the\nbehavior of black-box motion planners by grounding their reasoning in\nhuman-interpretable concepts. We deploy CW-Net on a real self-driving car and\nshow that the resulting explanations refine the human driver's mental model of\nthe car, allowing them to better predict its behavior and adjust their own\nbehavior accordingly. Unlike previous work using toy domains or simulations,\nour study presents the first real-world demonstration of how to build authentic\nautonomous vehicles (AVs) that give interpretable, causally faithful\nexplanations for their decisions, without sacrificing performance. We\nanticipate our method could be applied to other safety-critical systems with a\nhuman in the loop, such as autonomous drones and robotic surgeons. Overall, our\nstudy suggests a pathway to explainability for autonomous agents as a whole,\nwhich can help make them more transparent, their deployment safer, and their\nusage more ethical.",
      "tldr_zh": "本研究针对自驾车的黑-box motion planners 问题，提出 concept-wrapper network (CW-Net) 方法，通过人类可解释的概念来解释深度神经网络的行为，从而帮助驾驶员更好地理解和预测车辆决策。  \n实验在真实自驾车上进行，结果显示 CW-Net 显著改善了人类驾驶员的 mental model，使他们能更准确地预判车辆行为并相应调整自身操作，而不影响系统性能。  \n这项工作首次在真实世界中证明了构建可解释、因果忠实的自主车辆的可行性，并有望扩展到其他安全关键系统，如自主无人机和机器人外科，促进自主代理的透明性、安全性和道德性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "* - equal contribution",
      "pdf_url": "http://arxiv.org/pdf/2411.18714v1",
      "published_date": "2024-11-27 19:38:43 UTC",
      "updated_date": "2024-11-27 19:38:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:54:52.167626"
    },
    {
      "arxiv_id": "2411.18708v1",
      "title": "Embracing AI in Education: Understanding the Surge in Large Language Model Use by Secondary Students",
      "title_zh": "在教育中拥抱 AI：理解中学学生使用大型语言模型的激增",
      "authors": [
        "Tiffany Zhu",
        "Kexun Zhang",
        "William Yang Wang"
      ],
      "abstract": "The impressive essay writing and problem-solving capabilities of large\nlanguage models (LLMs) like OpenAI's ChatGPT have opened up new avenues in\neducation. Our goal is to gain insights into the widespread use of LLMs among\nsecondary students to inform their future development. Despite school\nrestrictions, our survey of over 300 middle and high school students revealed\nthat a remarkable 70% of students have utilized LLMs, higher than the usage\npercentage among young adults, and this percentage remains consistent across\n7th to 12th grade. Students also reported using LLMs for multiple subjects,\nincluding language arts, history, and math assignments, but expressed mixed\nthoughts on their effectiveness due to occasional hallucinations in historical\ncontexts and incorrect answers for lack of rigorous reasoning. The survey\nfeedback called for LLMs better adapted for students, and also raised questions\nto developers and educators on how to help students from underserved\ncommunities leverage LLMs' capabilities for equal access to advanced education\nresources. We propose a few ideas to address such issues, including\nsubject-specific models, personalized learning, and AI classrooms.",
      "tldr_zh": "本研究调查了中学学生使用大型语言模型（LLMs）如ChatGPT的情况，以了解其在教育中的应用并指导未来发展。调查超过300名7至12年级学生发现，70%的学生使用过LLMs，使用率高于年轻成人，且适用于语言艺术、历史和数学等科目。学生对LLMs的评价褒贬不一，指出其在历史上下文中可能出现hallucinations和缺乏严格推理导致的错误答案，并呼吁开发更适合学生的模型。研究提出几点建议，包括主题特定模型（subject-specific models）、个性化学习（personalized learning）和AI教室，以帮助弱势社区学生平等获取先进教育资源。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "6 main pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.18708v1",
      "published_date": "2024-11-27 19:19:34 UTC",
      "updated_date": "2024-11-27 19:19:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:55:04.530782"
    },
    {
      "arxiv_id": "2411.18702v1",
      "title": "Random Walks with Tweedie: A Unified Framework for Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Chicago Y. Park",
        "Michael T. McCann",
        "Cristina Garcia-Cardona",
        "Brendt Wohlberg",
        "Ulugbek S. Kamilov"
      ],
      "abstract": "We present a simple template for designing generative diffusion model\nalgorithms based on an interpretation of diffusion sampling as a sequence of\nrandom walks. Score-based diffusion models are widely used to generate\nhigh-quality images. Diffusion models have also been shown to yield\nstate-of-the-art performance in many inverse problems. While these algorithms\nare often surprisingly simple, the theory behind them is not, and multiple\ncomplex theoretical justifications exist in the literature. Here, we provide a\nsimple and largely self-contained theoretical justification for\nscore-based-diffusion models that avoids using the theory of Markov chains or\nreverse diffusion, instead centering the theory of random walks and Tweedie's\nformula. This approach leads to unified algorithmic templates for network\ntraining and sampling. In particular, these templates cleanly separate training\nfrom sampling, e.g., the noise schedule used during training need not match the\none used during sampling. We show that several existing diffusion models\ncorrespond to particular choices within this template and demonstrate that\nother, more straightforward algorithmic choices lead to effective diffusion\nmodels. The proposed framework has the added benefit of enabling conditional\nsampling without any likelihood approximation.",
      "tldr_zh": "本研究提出了一种基于随机游走(random walks)和Tweedie's公式的统一框架，用于设计生成扩散模型(diffusion models)的算法模板。该框架将扩散采样解释为随机游走序列，避免了Markov链或反向扩散的复杂理论，提供简化的训练和采样过程，支持灵活的噪声调度和条件采样。实验结果表明，该模板能生成高质量图像，并在逆问题中实现最先进性能，同时兼容现有扩散模型的设计选择。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.18702v1",
      "published_date": "2024-11-27 19:13:20 UTC",
      "updated_date": "2024-11-27 19:13:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:55:16.657243"
    },
    {
      "arxiv_id": "2411.18700v1",
      "title": "On the Effectiveness of Incremental Training of Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Miles Q. Li",
        "Benjamin C. M. Fung",
        "Shih-Chia Huang"
      ],
      "abstract": "Training large language models is a computationally intensive process that\noften requires substantial resources to achieve state-of-the-art results.\nIncremental layer-wise training has been proposed as a potential strategy to\noptimize the training process by progressively introducing layers, with the\nexpectation that this approach would lead to faster convergence and more\nefficient use of computational resources. In this paper, we investigate the\neffectiveness of incremental training for LLMs, dividing the training process\ninto multiple stages where layers are added progressively. Our experimental\nresults indicate that while the incremental approach initially demonstrates\nsome computational efficiency, it ultimately requires greater overall\ncomputational costs to reach comparable performance to traditional full-scale\ntraining. Although the incremental training process can eventually close the\nperformance gap with the baseline, it does so only after significantly extended\ncontinual training. These findings suggest that incremental layer-wise training\nmay not be a viable alternative for training large language models,\nhighlighting its limitations and providing valuable insights into the\ninefficiencies of this approach.",
      "tldr_zh": "这篇论文探讨了增量层式训练（incremental layer-wise training）在大型语言模型（LLMs）中的有效性，该方法通过将训练过程分为多个阶段逐步添加层，以期望实现更快收敛和更高效的计算资源利用。实验结果表明，虽然增量训练初期显示出一些计算效率优势，但总体上需要更多计算成本才能达到与传统全规模训练相当的性能水平，且需显著延长持续训练才能缩小差距。这些发现突出了增量层式训练的局限性，表明它并非训练LLMs的可行替代方案，并为优化LLMs训练策略提供了宝贵洞见。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.18700v1",
      "published_date": "2024-11-27 19:11:49 UTC",
      "updated_date": "2024-11-27 19:11:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:55:27.987990"
    },
    {
      "arxiv_id": "2411.18688v3",
      "title": "Immune: Improving Safety Against Jailbreaks in Multi-modal LLMs via Inference-Time Alignment",
      "title_zh": "Immune：通过推理时对齐改善多模态LLMs中针对越狱攻击的安全性",
      "authors": [
        "Soumya Suvra Ghosal",
        "Souradip Chakraborty",
        "Vaibhav Singh",
        "Tianrui Guan",
        "Mengdi Wang",
        "Ahmad Beirami",
        "Furong Huang",
        "Alvaro Velasquez",
        "Dinesh Manocha",
        "Amrit Singh Bedi"
      ],
      "abstract": "With the widespread deployment of Multimodal Large Language Models (MLLMs)\nfor visual-reasoning tasks, improving their safety has become crucial. Recent\nresearch indicates that despite training-time safety alignment, these models\nremain vulnerable to jailbreak attacks. In this work, we first highlight an\nimportant safety gap to describe that alignment achieved solely through safety\ntraining may be insufficient against jailbreak attacks. To address this\nvulnerability, we propose Immune, an inference-time defense framework that\nleverages a safe reward model through controlled decoding to defend against\njailbreak attacks. Additionally, we provide a mathematical characterization of\nImmune, offering insights on why it improves safety against jailbreaks.\nExtensive evaluations on diverse jailbreak benchmarks using recent MLLMs reveal\nthat Immune effectively enhances model safety while preserving the model's\noriginal capabilities. For instance, against text-based jailbreak attacks on\nLLaVA-1.6, Immune reduces the attack success rate by 57.82% and 16.78% compared\nto the base MLLM and state-of-the-art defense strategy, respectively.",
      "tldr_zh": "该研究针对多模态大语言模型(MLLMs)在视觉推理任务中的安全漏洞，提出 Immune 框架，通过推理时对齐(inference-time alignment)来防御 jailbreak 攻击。Immune 利用安全奖励模型(safe reward model)和控制解码技术，确保模型在面对攻击时保持鲁棒性，同时提供数学表征来解释其有效性。实验结果显示，Immune 在各种基准测试中显著提升了模型安全性，例如在 LLaVA-1.6 上，对文本-based jailbreak 攻击的成功率较基线模型降低了 57.82%，并优于现有防御策略。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted to CVPR 2025",
      "pdf_url": "http://arxiv.org/pdf/2411.18688v3",
      "published_date": "2024-11-27 19:00:10 UTC",
      "updated_date": "2025-03-20 16:07:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:55:39.636774"
    },
    {
      "arxiv_id": "2411.18677v1",
      "title": "MatchDiffusion: Training-free Generation of Match-cuts",
      "title_zh": "翻译失败",
      "authors": [
        "Alejandro Pardo",
        "Fabio Pizzati",
        "Tong Zhang",
        "Alexander Pondaven",
        "Philip Torr",
        "Juan Camilo Perez",
        "Bernard Ghanem"
      ],
      "abstract": "Match-cuts are powerful cinematic tools that create seamless transitions\nbetween scenes, delivering strong visual and metaphorical connections. However,\ncrafting match-cuts is a challenging, resource-intensive process requiring\ndeliberate artistic planning. In MatchDiffusion, we present the first\ntraining-free method for match-cut generation using text-to-video diffusion\nmodels. MatchDiffusion leverages a key property of diffusion models: early\ndenoising steps define the scene's broad structure, while later steps add\ndetails. Guided by this insight, MatchDiffusion employs \"Joint Diffusion\" to\ninitialize generation for two prompts from shared noise, aligning structure and\nmotion. It then applies \"Disjoint Diffusion\", allowing the videos to diverge\nand introduce unique details. This approach produces visually coherent videos\nsuited for match-cuts. User studies and metrics demonstrate MatchDiffusion's\neffectiveness and potential to democratize match-cut creation.",
      "tldr_zh": "这篇论文介绍了 MatchDiffusion，一种无需训练的方法，用于生成 match-cuts，以实现电影场景间的无缝过渡和视觉连接。MatchDiffusion 利用文本到视频扩散模型的特性：在早期去噪步骤中通过 Joint Diffusion 从共享噪声初始化两个提示的结构和动作，确保一致性；随后应用 Disjoint Diffusion，让视频分叉添加独特细节，从而创建视觉连贯的视频。用户研究和评估指标证明，该方法有效提升了 match-cut 生成的质量，并有望使这一技术更易于普及。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "https://matchdiffusion.github.io",
      "pdf_url": "http://arxiv.org/pdf/2411.18677v1",
      "published_date": "2024-11-27 18:59:59 UTC",
      "updated_date": "2024-11-27 18:59:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:55:51.896002"
    },
    {
      "arxiv_id": "2412.00099v1",
      "title": "Mixture of Cache-Conditional Experts for Efficient Mobile Device Inference",
      "title_zh": "翻译失败",
      "authors": [
        "Andrii Skliar",
        "Ties van Rozendaal",
        "Romain Lepert",
        "Todor Boinovski",
        "Mart van Baalen",
        "Markus Nagel",
        "Paul Whatmough",
        "Babak Ehteshami Bejnordi"
      ],
      "abstract": "Mixture of Experts (MoE) LLMs have recently gained attention for their\nability to enhance performance by selectively engaging specialized subnetworks\nor \"experts\" for each input. However, deploying MoEs on memory-constrained\ndevices remains challenging, particularly when generating tokens sequentially\nwith a batch size of one, as opposed to typical high-throughput settings\ninvolving long sequences or large batches. In this work, we optimize MoE on\nmemory-constrained devices where only a subset of expert weights fit in DRAM.\nWe introduce a novel cache-aware routing strategy that leverages expert reuse\nduring token generation to improve cache locality. We evaluate our approach on\nlanguage modeling, MMLU, and GSM8K benchmarks and present on-device results\ndemonstrating 2$\\times$ speedups on mobile devices, offering a flexible,\ntraining-free solution to extend MoE's applicability across real-world\napplications.",
      "tldr_zh": "该研究针对内存受限设备上的 Mixture of Experts (MoE) LLMs 优化问题，提出了一种 cache-aware routing 策略，以提升在批量大小为1的顺序生成任务中的效率。该策略利用专家重用改善缓存局部性，确保仅部分专家权重驻留在 DRAM 中，从而实现灵活的部署。实验在语言建模、MMLU 和 GSM8K 基准上评估，结果显示在移动设备上实现了 2 倍的速度提升，提供了一个无需训练的解决方案，扩展了 MoE 在实际应用的适用性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.AR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.00099v1",
      "published_date": "2024-11-27 18:59:48 UTC",
      "updated_date": "2024-11-27 18:59:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:56:03.764928"
    },
    {
      "arxiv_id": "2411.18620v2",
      "title": "Cross-modal Information Flow in Multimodal Large Language Models",
      "title_zh": "多模态大型语言模型中的跨模态信息流",
      "authors": [
        "Zhi Zhang",
        "Srishti Yadav",
        "Fengze Han",
        "Ekaterina Shutova"
      ],
      "abstract": "The recent advancements in auto-regressive multimodal large language models\n(MLLMs) have demonstrated promising progress for vision-language tasks. While\nthere exists a variety of studies investigating the processing of linguistic\ninformation within large language models, little is currently known about the\ninner working mechanism of MLLMs and how linguistic and visual information\ninteract within these models. In this study, we aim to fill this gap by\nexamining the information flow between different modalities -- language and\nvision -- in MLLMs, focusing on visual question answering. Specifically, given\nan image-question pair as input, we investigate where in the model and how the\nvisual and linguistic information are combined to generate the final\nprediction. Conducting experiments with a series of models from the LLaVA\nseries, we find that there are two distinct stages in the process of\nintegration of the two modalities. In the lower layers, the model first\ntransfers the more general visual features of the whole image into the\nrepresentations of (linguistic) question tokens. In the middle layers, it once\nagain transfers visual information about specific objects relevant to the\nquestion to the respective token positions of the question. Finally, in the\nhigher layers, the resulting multimodal representation is propagated to the\nlast position of the input sequence for the final prediction. Overall, our\nfindings provide a new and comprehensive perspective on the spatial and\nfunctional aspects of image and language processing in the MLLMs, thereby\nfacilitating future research into multimodal information localization and\nediting. Our code and collected dataset are released here:\nhttps://github.com/FightingFighting/cross-modal-information-flow-in-MLLM.git.",
      "tldr_zh": "这篇论文研究了多模态大语言模型(MLLMs)中语言和视觉信息之间的交互，焦点在于视觉问答任务，通过实验分析LLaVA系列模型揭示了信息流动的机制。作者发现，信息整合过程分为三个阶段：在较低层，将图像的整体视觉特征转移到问题令牌的表示中；在中间层，将与问题相关的特定对象视觉信息转移到相应令牌位置；在较高层，将多模态表示传播到输入序列末端以生成最终预测。这些发现为MLLMs中图像和语言处理的空间及功能方面提供了新的全面视角，并促进了未来多模态信息定位和编辑的研究。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.18620v2",
      "published_date": "2024-11-27 18:59:26 UTC",
      "updated_date": "2025-03-25 18:59:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:56:16.819584"
    },
    {
      "arxiv_id": "2411.18616v1",
      "title": "Diffusion Self-Distillation for Zero-Shot Customized Image Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Shengqu Cai",
        "Eric Chan",
        "Yunzhi Zhang",
        "Leonidas Guibas",
        "Jiajun Wu",
        "Gordon Wetzstein"
      ],
      "abstract": "Text-to-image diffusion models produce impressive results but are frustrating\ntools for artists who desire fine-grained control. For example, a common use\ncase is to create images of a specific instance in novel contexts, i.e.,\n\"identity-preserving generation\". This setting, along with many other tasks\n(e.g., relighting), is a natural fit for image+text-conditional generative\nmodels. However, there is insufficient high-quality paired data to train such a\nmodel directly. We propose Diffusion Self-Distillation, a method for using a\npre-trained text-to-image model to generate its own dataset for\ntext-conditioned image-to-image tasks. We first leverage a text-to-image\ndiffusion model's in-context generation ability to create grids of images and\ncurate a large paired dataset with the help of a Visual-Language Model. We then\nfine-tune the text-to-image model into a text+image-to-image model using the\ncurated paired dataset. We demonstrate that Diffusion Self-Distillation\noutperforms existing zero-shot methods and is competitive with per-instance\ntuning techniques on a wide range of identity-preservation generation tasks,\nwithout requiring test-time optimization.",
      "tldr_zh": "本论文针对文本到图像扩散模型（text-to-image diffusion models）在细粒度控制方面的不足，例如身份保持生成（identity-preserving generation），提出了一种Diffusion Self-Distillation方法。该方法利用预训练模型的上下文生成能力创建图像网格，并借助视觉语言模型（Visual-Language Model）整理出高质量配对数据集，然后对模型进行微调，使其支持文本+图像条件生成。实验结果显示，该方法在零样本（zero-shot）任务上优于现有方法，并在各种身份保持生成任务中与实例级调优（per-instance tuning）技术竞争，同时无需测试时优化。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Project page: https://primecai.github.io/dsd/",
      "pdf_url": "http://arxiv.org/pdf/2411.18616v1",
      "published_date": "2024-11-27 18:58:52 UTC",
      "updated_date": "2024-11-27 18:58:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:56:28.625592"
    },
    {
      "arxiv_id": "2411.18615v1",
      "title": "Proactive Gradient Conflict Mitigation in Multi-Task Learning: A Sparse Training Perspective",
      "title_zh": "翻译失败",
      "authors": [
        "Zhi Zhang",
        "Jiayi Shen",
        "Congfeng Cao",
        "Gaole Dai",
        "Shiji Zhou",
        "Qizhe Zhang",
        "Shanghang Zhang",
        "Ekaterina Shutova"
      ],
      "abstract": "Advancing towards generalist agents necessitates the concurrent processing of\nmultiple tasks using a unified model, thereby underscoring the growing\nsignificance of simultaneous model training on multiple downstream tasks. A\ncommon issue in multi-task learning is the occurrence of gradient conflict,\nwhich leads to potential competition among different tasks during joint\ntraining. This competition often results in improvements in one task at the\nexpense of deterioration in another. Although several optimization methods have\nbeen developed to address this issue by manipulating task gradients for better\ntask balancing, they cannot decrease the incidence of gradient conflict. In\nthis paper, we systematically investigate the occurrence of gradient conflict\nacross different methods and propose a strategy to reduce such conflicts\nthrough sparse training (ST), wherein only a portion of the model's parameters\nare updated during training while keeping the rest unchanged. Our extensive\nexperiments demonstrate that ST effectively mitigates conflicting gradients and\nleads to superior performance. Furthermore, ST can be easily integrated with\ngradient manipulation techniques, thus enhancing their effectiveness.",
      "tldr_zh": "本论文探讨了多任务学习（multi-task learning）中的梯度冲突（gradient conflict）问题，该问题会导致任务之间竞争，优化一个任务可能损害另一个。作者通过系统调查不同方法后，提出使用稀疏训练（sparse training, ST）策略，仅更新模型部分参数来主动减少冲突。实验结果显示，ST 不仅有效缓解了冲突梯度，还提升了整体性能，且能轻松与梯度操纵技术结合，进一步增强效果。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.18615v1",
      "published_date": "2024-11-27 18:58:22 UTC",
      "updated_date": "2024-11-27 18:58:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:56:39.443542"
    },
    {
      "arxiv_id": "2411.18676v2",
      "title": "Embodied Red Teaming for Auditing Robotic Foundation Models",
      "title_zh": "翻译失败",
      "authors": [
        "Sathwik Karnik",
        "Zhang-Wei Hong",
        "Nishant Abhangi",
        "Yen-Chen Lin",
        "Tsun-Hsuan Wang",
        "Christophe Dupuy",
        "Rahul Gupta",
        "Pulkit Agrawal"
      ],
      "abstract": "Language-conditioned robot models have the potential to enable robots to\nperform a wide range of tasks based on natural language instructions. However,\nassessing their safety and effectiveness remains challenging because it is\ndifficult to test all the different ways a single task can be phrased. Current\nbenchmarks have two key limitations: they rely on a limited set of\nhuman-generated instructions, missing many challenging cases, and focus only on\ntask performance without assessing safety, such as avoiding damage. To address\nthese gaps, we introduce Embodied Red Teaming (ERT), a new evaluation method\nthat generates diverse and challenging instructions to test these models. ERT\nuses automated red teaming techniques with Vision Language Models (VLMs) to\ncreate contextually grounded, difficult instructions. Experimental results show\nthat state-of-the-art language-conditioned robot models fail or behave unsafely\non ERT-generated instructions, underscoring the shortcomings of current\nbenchmarks in evaluating real-world performance and safety. Code and videos are\navailable at: https://s-karnik.github.io/embodied-red-team-project-page.",
      "tldr_zh": "该研究针对语言条件机器人模型的安全性和有效性评估问题，指出现有基准依赖有限指令且忽略安全因素，难以覆盖所有挑战性场景。为解决此问题，研究提出Embodied Red Teaming (ERT)，一种利用Vision Language Models (VLMs)的自动化红队技术，生成多样且上下文相关的困难指令，以全面测试模型性能。实验结果显示，最先进的机器人模型在ERT生成的指令上频繁失败或表现出不安全行为，突显当前基准在评估真实世界应用方面的不足，从而为改进机器人基础模型的安全审计提供新路径。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.18676v2",
      "published_date": "2024-11-27 18:57:26 UTC",
      "updated_date": "2025-02-10 16:32:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:56:52.115571"
    },
    {
      "arxiv_id": "2411.18612v1",
      "title": "Robust Offline Reinforcement Learning with Linearly Structured $f$-Divergence Regularization",
      "title_zh": "线性结构化的 $f$ 散度正则化的稳健离线强化学习",
      "authors": [
        "Cheng Tang",
        "Zhishuai Liu",
        "Pan Xu"
      ],
      "abstract": "The Distributionally Robust Markov Decision Process (DRMDP) is a popular\nframework for addressing dynamics shift in reinforcement learning by learning\npolicies robust to the worst-case transition dynamics within a constrained set.\nHowever, solving its dual optimization oracle poses significant challenges,\nlimiting theoretical analysis and computational efficiency. The recently\nproposed Robust Regularized Markov Decision Process (RRMDP) replaces the\nuncertainty set constraint with a regularization term on the value function,\noffering improved scalability and theoretical insights. Yet, existing RRMDP\nmethods rely on unstructured regularization, often leading to overly\nconservative policies by considering transitions that are unrealistic. To\naddress these issues, we propose a novel framework, the $d$-rectangular linear\nrobust regularized Markov decision process ($d$-RRMDP), which introduces a\nlinear latent structure into both transition kernels and regularization. For\nthe offline RL setting, where an agent learns robust policies from a\npre-collected dataset in the nominal environment, we develop a family of\nalgorithms, Robust Regularized Pessimistic Value Iteration (R2PVI), employing\nlinear function approximation and $f$-divergence based regularization terms on\ntransition kernels. We provide instance-dependent upper bounds on the\nsuboptimality gap of R2PVI policies, showing these bounds depend on how well\nthe dataset covers state-action spaces visited by the optimal robust policy\nunder robustly admissible transitions. This term is further shown to be\nfundamental to $d$-RRMDPs via information-theoretic lower bounds. Finally,\nnumerical experiments validate that R2PVI learns robust policies and is\ncomputationally more efficient than methods for constrained DRMDPs.",
      "tldr_zh": "本研究针对强化学习中动态偏移问题，提出了一种新的框架$d$-RRMDP（$d$-rectangular linear robust regularized Markov decision process），通过在转移核和正则化中引入线性潜在结构，避免了传统RRMDP（Robust Regularized Markov Decision Process）方法的过度保守策略。作者开发了R2PVI（Robust Regularized Pessimistic Value Iteration）算法，结合线性函数逼近和基于$f$-divergence的正则化，用于离线RL场景，帮助从预收集的数据集中学习鲁棒策略。理论分析提供了R2PVI策略的次优性上界，这些上界取决于数据集对最优鲁棒策略的覆盖，并通过信息论下界证明其根本性；实验结果显示，该算法比约束DRMDP（Distributionally Robust Markov Decision Process）方法更高效且鲁棒性更强。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "52 pages, 3 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2411.18612v1",
      "published_date": "2024-11-27 18:57:03 UTC",
      "updated_date": "2024-11-27 18:57:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:57:04.797845"
    },
    {
      "arxiv_id": "2411.18675v1",
      "title": "GaussianSpeech: Audio-Driven Gaussian Avatars",
      "title_zh": "翻译失败",
      "authors": [
        "Shivangi Aneja",
        "Artem Sevastopolsky",
        "Tobias Kirschstein",
        "Justus Thies",
        "Angela Dai",
        "Matthias Nießner"
      ],
      "abstract": "We introduce GaussianSpeech, a novel approach that synthesizes high-fidelity\nanimation sequences of photo-realistic, personalized 3D human head avatars from\nspoken audio. To capture the expressive, detailed nature of human heads,\nincluding skin furrowing and finer-scale facial movements, we propose to couple\nspeech signal with 3D Gaussian splatting to create realistic, temporally\ncoherent motion sequences. We propose a compact and efficient 3DGS-based avatar\nrepresentation that generates expression-dependent color and leverages wrinkle-\nand perceptually-based losses to synthesize facial details, including wrinkles\nthat occur with different expressions. To enable sequence modeling of 3D\nGaussian splats with audio, we devise an audio-conditioned transformer model\ncapable of extracting lip and expression features directly from audio input.\nDue to the absence of high-quality datasets of talking humans in correspondence\nwith audio, we captured a new large-scale multi-view dataset of audio-visual\nsequences of talking humans with native English accents and diverse facial\ngeometry. GaussianSpeech consistently achieves state-of-the-art performance\nwith visually natural motion at real time rendering rates, while encompassing\ndiverse facial expressions and styles.",
      "tldr_zh": "本研究提出GaussianSpeech，一种基于音频驱动的创新方法，用于合成高保真、个性化的3D人体头部头像动画，通过将语音信号与3D Gaussian splatting结合，捕捉面部细微表情和细节如皮肤皱纹。研究设计了一个紧凑的3DGS-based头像表示，利用音频条件transformer模型从音频中提取唇部和表情特征，并引入基于皱纹和感知的损失函数来提升合成质量。为解决数据集缺失问题，团队捕获了一个新的大规模多视图音频-视觉数据集。结果显示，GaussianSpeech在实时渲染中实现了最先进的性能，提供自然流畅的运动序列，并支持多样化的面部表情和风格。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CV",
      "comment": "Paper Video: https://youtu.be/2VqYoFlYcwQ Project Page:\n  https://shivangi-aneja.github.io/projects/gaussianspeech",
      "pdf_url": "http://arxiv.org/pdf/2411.18675v1",
      "published_date": "2024-11-27 18:54:08 UTC",
      "updated_date": "2024-11-27 18:54:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:57:16.289008"
    },
    {
      "arxiv_id": "2411.18583v1",
      "title": "Automated Literature Review Using NLP Techniques and LLM-Based Retrieval-Augmented Generation",
      "title_zh": "利用自然语言处理技术和基于大型语言模型的检索增强生成的自动文献综述",
      "authors": [
        "Nurshat Fateh Ali",
        "Md. Mahdi Mohtasim",
        "Shakil Mosharrof",
        "T. Gopi Krishna"
      ],
      "abstract": "This research presents and compares multiple approaches to automate the\ngeneration of literature reviews using several Natural Language Processing\n(NLP) techniques and retrieval-augmented generation (RAG) with a Large Language\nModel (LLM). The ever-increasing number of research articles provides a huge\nchallenge for manual literature review. It has resulted in an increased demand\nfor automation. Developing a system capable of automatically generating the\nliterature reviews from only the PDF files as input is the primary objective of\nthis research work. The effectiveness of several Natural Language Processing\n(NLP) strategies, such as the frequency-based method (spaCy), the transformer\nmodel (Simple T5), and retrieval-augmented generation (RAG) with Large Language\nModel (GPT-3.5-turbo), is evaluated to meet the primary objective. The SciTLDR\ndataset is chosen for this research experiment and three distinct techniques\nare utilized to implement three different systems for auto-generating the\nliterature reviews. The ROUGE scores are used for the evaluation of all three\nsystems. Based on the evaluation, the Large Language Model GPT-3.5-turbo\nachieved the highest ROUGE-1 score, 0.364. The transformer model comes in\nsecond place and spaCy is at the last position. Finally, a graphical user\ninterface is created for the best system based on the large language model.",
      "tldr_zh": "这篇论文介绍了使用 NLP 技术和 LLM-Based Retrieval-Augmented Generation 自动生成文献综述的方法，以应对研究文章数量激增带来的挑战。研究比较了三种策略：基于频率的方法（spaCy）、Transformer 模型（Simple T5）和 RAG 与 GPT-3.5-turbo，在 SciTLDR 数据集上进行评估。结果显示，GPT-3.5-turbo 取得了最高的 ROUGE-1 分数（0.364），并基于此系统开发了图形用户界面，以实现从 PDF 文件自动生成文献综述的目标。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Key Words : T5, SpaCy, Large Language Model, GPT, ROUGE, Literature\n  Review, Natural Language Processing, Retrieval-augmented generation",
      "pdf_url": "http://arxiv.org/pdf/2411.18583v1",
      "published_date": "2024-11-27 18:27:07 UTC",
      "updated_date": "2024-11-27 18:27:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:57:28.909315"
    },
    {
      "arxiv_id": "2411.18575v1",
      "title": "Functional relevance based on the continuous Shapley value",
      "title_zh": "翻译失败",
      "authors": [
        "Pedro Delicado",
        "Cristian Pachón-García"
      ],
      "abstract": "The presence of Artificial Intelligence (AI) in our society is increasing,\nwhich brings with it the need to understand the behaviour of AI mechanisms,\nincluding machine learning predictive algorithms fed with tabular data, text,\nor images, among other types of data. This work focuses on interpretability of\npredictive models based on functional data. Designing interpretability methods\nfor functional data models implies working with a set of features whose size is\ninfinite. In the context of scalar on function regression, we propose an\ninterpretability method based on the Shapley value for continuous games, a\nmathematical formulation that allows to fairly distribute a global payoff among\na continuous set players. The method is illustrated through a set of\nexperiments with simulated and real data sets. The open source Python package\nShapleyFDA is also presented.",
      "tldr_zh": "这篇论文针对功能数据的预测模型可解释性问题，提出了一种基于连续 Shapley value 的方法，以公平分配全局回报并处理无限特征集的挑战。在标量到函数回归的背景下，该方法借鉴连续游戏的数学公式，评估功能数据模型中各特征的相关性。通过模拟和真实数据集的实验验证，该方法证明了其有效性，并发布了开源 Python 包 ShapleyFDA，以支持进一步应用。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG",
        "stat.AP"
      ],
      "primary_category": "stat.ML",
      "comment": "36 pages, 13 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.18575v1",
      "published_date": "2024-11-27 18:20:00 UTC",
      "updated_date": "2024-11-27 18:20:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:57:39.379958"
    },
    {
      "arxiv_id": "2411.18564v2",
      "title": "Dspy-based Neural-Symbolic Pipeline to Enhance Spatial Reasoning in LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Rong Wang",
        "Kun Sun",
        "Jonas Kuhn"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities across\nvarious tasks, yet they often struggle with spatial reasoning. This paper\npresents a novel neural-symbolic framework that enhances LLMs' spatial\nreasoning abilities through iterative feedback between LLMs and Answer Set\nProgramming (ASP). We evaluate our approach on two benchmark datasets: StepGame\nand SparQA, implementing three distinct strategies: (1) direct prompting\nbaseline, (2) Facts+Rules prompting, and (3) DSPy-based LLM+ASP pipeline with\niterative refinement. Our experimental results demonstrate that the LLM+ASP\npipeline significantly outperforms baseline methods, achieving an average 82%\naccuracy on StepGame and 69% on SparQA, marking improvements of 40-50% and\n8-15% respectively over direct prompting. The success stems from three key\ninnovations: (1) effective separation of semantic parsing and logical reasoning\nthrough a modular pipeline, (2) iterative feedback mechanism between LLMs and\nASP solvers that improves program rate, and (3) robust error handling that\naddresses parsing, grounding, and solving failures. Additionally, we propose\nFacts+Rules as a lightweight alternative that achieves comparable performance\non complex SparQA dataset, while reducing computational overhead.Our analysis\nacross different LLM architectures (Deepseek, Llama3-70B, GPT-4.0 mini)\ndemonstrates the framework's generalizability and provides insights into the\ntrade-offs between implementation complexity and reasoning capability,\ncontributing to the development of more interpretable and reliable AI systems.",
      "tldr_zh": "这篇论文提出了一种基于DSPy的神经符号框架，通过LLMs和Answer Set Programming (ASP)的迭代反馈机制，提升LLMs在空间推理任务中的性能。框架在StepGame和SparQA数据集上评估了三种策略，包括直接提示基线、Facts+Rules提示以及LLM+ASP管道，结果显示LLM+ASP管道的准确率分别达到82%和69%，比基线方法提高了40-50%和8-15%。关键创新包括模块化管道的语义解析与逻辑推理分离、迭代反馈机制的程序率优化，以及鲁棒的错误处理策略；此外，Facts+Rules作为轻量级替代方案，在SparQA上表现出色，同时降低了计算开销。该框架在Deepseek、Llama3-70B和GPT-4.0 mini等不同LLM架构上展现出良好的泛化性，为构建更可解释和可靠的AI系统提供了重要见解。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.18564v2",
      "published_date": "2024-11-27 18:04:05 UTC",
      "updated_date": "2024-12-12 16:03:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:57:54.876012"
    },
    {
      "arxiv_id": "2411.18526v2",
      "title": "NeuroAI for AI Safety",
      "title_zh": "翻译失败",
      "authors": [
        "Patrick Mineault",
        "Niccolò Zanichelli",
        "Joanne Zichen Peng",
        "Anton Arkhipov",
        "Eli Bingham",
        "Julian Jara-Ettinger",
        "Emily Mackevicius",
        "Adam Marblestone",
        "Marcelo Mattar",
        "Andrew Payne",
        "Sophia Sanborn",
        "Karen Schroeder",
        "Zenna Tavares",
        "Andreas Tolias",
        "Anthony Zador"
      ],
      "abstract": "As AI systems become increasingly powerful, the need for safe AI has become\nmore pressing. Humans are an attractive model for AI safety: as the only known\nagents capable of general intelligence, they perform robustly even under\nconditions that deviate significantly from prior experiences, explore the world\nsafely, understand pragmatics, and can cooperate to meet their intrinsic goals.\nIntelligence, when coupled with cooperation and safety mechanisms, can drive\nsustained progress and well-being. These properties are a function of the\narchitecture of the brain and the learning algorithms it implements.\nNeuroscience may thus hold important keys to technical AI safety that are\ncurrently underexplored and underutilized. In this roadmap, we highlight and\ncritically evaluate several paths toward AI safety inspired by neuroscience:\nemulating the brain's representations, information processing, and\narchitecture; building robust sensory and motor systems from imitating brain\ndata and bodies; fine-tuning AI systems on brain data; advancing\ninterpretability using neuroscience methods; and scaling up\ncognitively-inspired architectures. We make several concrete recommendations\nfor how neuroscience can positively impact AI safety.",
      "tldr_zh": "本论文提出利用神经科学（Neuroscience）来增强AI安全（AI Safety），认为人类大脑的架构和学习算法可作为AI系统安全设计的灵感来源。作者评估了几条路径，包括模拟大脑的表示、信息处理和架构；构建稳健的感官和运动系统；用大脑数据微调AI系统；以及使用神经科学方法提升AI的可解释性。最终，论文提供具体推荐，强调通过这些认知启发方法（如scaling up cognitively-inspired architectures）可推动AI安全进展，实现更可靠的智能系统。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "152 pages, 22 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.18526v2",
      "published_date": "2024-11-27 17:18:51 UTC",
      "updated_date": "2025-04-03 02:40:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:58:04.222017"
    },
    {
      "arxiv_id": "2411.18506v3",
      "title": "LLM-ABBA: Understanding time series via symbolic approximation",
      "title_zh": "LLM-ABBA：通过符号近似理解时间序列",
      "authors": [
        "Erin Carson",
        "Xinye Chen",
        "Cheng Kang"
      ],
      "abstract": "The success of large language models (LLMs) for time series has been\ndemonstrated in previous work. Utilizing a symbolic time series representation,\none can efficiently bridge the gap between LLMs and time series. However, the\nremaining challenge is to exploit the semantic information hidden in time\nseries by using symbols or existing tokens of LLMs, while aligning the\nembedding space of LLMs according to the hidden information of time series. The\nsymbolic time series approximation (STSA) method called adaptive Brownian\nbridge-based symbolic aggregation (ABBA) shows outstanding efficacy in\npreserving salient time series features by modeling time series patterns in\nterms of amplitude and period while using existing tokens of LLMs.\n  In this paper, we introduce a method, called LLM-ABBA, that integrates ABBA\ninto large language models for various downstream time series tasks. By\nsymbolizing time series, LLM-ABBA compares favorably to the recent\nstate-of-the-art (SOTA) in UCR and three medical time series classification\ntasks. Meanwhile, a fixed-polygonal chain trick in ABBA is introduced to\n\\kc{avoid obvious drifting} during prediction tasks by significantly mitigating\nthe effects of cumulative error arising from misused symbols during the\ntransition from symbols to numerical values. In time series regression tasks,\nLLM-ABBA achieves the new SOTA on Time Series Extrinsic Regression (TSER)\nbenchmarks. LLM-ABBA also shows competitive prediction capability compared to\nrecent SOTA time series prediction results. We believe this framework can also\nseamlessly extend to other time series tasks.",
      "tldr_zh": "这篇论文提出了 LLM-ABBA 方法，将 adaptive Brownian bridge-based symbolic aggregation (ABBA) 整合到大型语言模型 (LLMs) 中，通过符号化时间序列表示 (STSA) 来保留幅度和周期等关键特征，从而桥接 LLMs 与时间序列的语义信息。LLM-ABBA 在时间序列分类任务中（如 UCR 和医疗数据集）优于现有最先进 (SOTA) 方法，并在回归任务上在 Time Series Extrinsic Regression (TSER) 基准中达到新 SOTA，同时引入固定多边形链技巧来减少符号转换时的累积错误。实验结果显示，该框架在预测任务中表现出色，并可无缝扩展到其他时间序列任务。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.18506v3",
      "published_date": "2024-11-27 16:48:24 UTC",
      "updated_date": "2024-12-06 13:35:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:58:16.988273"
    },
    {
      "arxiv_id": "2411.18502v1",
      "title": "Isometry pursuit",
      "title_zh": "翻译失败",
      "authors": [
        "Samson Koelle",
        "Marina Meila"
      ],
      "abstract": "Isometry pursuit is a convex algorithm for identifying orthonormal\ncolumn-submatrices of wide matrices. It consists of a novel normalization\nmethod followed by multitask basis pursuit. Applied to Jacobians of putative\ncoordinate functions, it helps identity isometric embeddings from within\ninterpretable dictionaries. We provide theoretical and experimental results\njustifying this method. For problems involving coordinate selection and\ndiversification, it offers a synergistic alternative to greedy and brute force\nsearch.",
      "tldr_zh": "该研究提出了Isometry pursuit，一种凸算法，用于识别宽矩阵中的orthonormal column-submatrices，通过新颖的normalization method和multitask basis pursuit相结合实现。该方法应用于坐标函数的Jacobians，有助于从interpretable dictionaries中识别isometric embeddings。研究提供了理论和实验结果来验证其有效性，并将其作为greedy search和brute force search的协同替代方案，特别适用于坐标选择和多样化问题。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.IR",
        "cs.LG",
        "stat.ME"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.18502v1",
      "published_date": "2024-11-27 16:43:13 UTC",
      "updated_date": "2024-11-27 16:43:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:58:27.787878"
    },
    {
      "arxiv_id": "2411.18479v2",
      "title": "SoK: Watermarking for AI-Generated Content",
      "title_zh": "翻译失败",
      "authors": [
        "Xuandong Zhao",
        "Sam Gunn",
        "Miranda Christ",
        "Jaiden Fairoze",
        "Andres Fabrega",
        "Nicholas Carlini",
        "Sanjam Garg",
        "Sanghyun Hong",
        "Milad Nasr",
        "Florian Tramer",
        "Somesh Jha",
        "Lei Li",
        "Yu-Xiang Wang",
        "Dawn Song"
      ],
      "abstract": "As the outputs of generative AI (GenAI) techniques improve in quality, it\nbecomes increasingly challenging to distinguish them from human-created\ncontent. Watermarking schemes are a promising approach to address the problem\nof distinguishing between AI and human-generated content. These schemes embed\nhidden signals within AI-generated content to enable reliable detection. While\nwatermarking is not a silver bullet for addressing all risks associated with\nGenAI, it can play a crucial role in enhancing AI safety and trustworthiness by\ncombating misinformation and deception. This paper presents a comprehensive\noverview of watermarking techniques for GenAI, beginning with the need for\nwatermarking from historical and regulatory perspectives. We formalize the\ndefinitions and desired properties of watermarking schemes and examine the key\nobjectives and threat models for existing approaches. Practical evaluation\nstrategies are also explored, providing insights into the development of robust\nwatermarking techniques capable of resisting various attacks. Additionally, we\nreview recent representative works, highlight open challenges, and discuss\npotential directions for this emerging field. By offering a thorough\nunderstanding of watermarking in GenAI, this work aims to guide researchers in\nadvancing watermarking methods and applications, and support policymakers in\naddressing the broader implications of GenAI.",
      "tldr_zh": "这篇论文（SoK: Watermarking for AI-Generated Content）系统化了水印技术（Watermarking）在生成式 AI（GenAI）中的应用，以解决区分 AI 生成内容与人类内容的核心挑战。作者形式化了水印方案的定义、期望属性、威胁模型，并探讨了实用评估策略，以提升水印的鲁棒性并抵抗各种攻击。论文回顾了代表性工作，突出了开放挑战和未来方向，并为研究者推进水印方法以及政策制定者应对 GenAI 风险提供指导。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.18479v2",
      "published_date": "2024-11-27 16:22:33 UTC",
      "updated_date": "2024-12-19 18:49:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:58:40.891603"
    },
    {
      "arxiv_id": "2411.18475v1",
      "title": "Weakly Supervised Framework Considering Multi-temporal Information for Large-scale Cropland Mapping with Satellite Imagery",
      "title_zh": "翻译失败",
      "authors": [
        "Yuze Wang",
        "Aoran Hu",
        "Ji Qi",
        "Yang Liu",
        "Chao Tao"
      ],
      "abstract": "Accurately mapping large-scale cropland is crucial for agricultural\nproduction management and planning. Currently, the combination of remote\nsensing data and deep learning techniques has shown outstanding performance in\ncropland mapping. However, those approaches require massive precise labels,\nwhich are labor-intensive. To reduce the label cost, this study presented a\nweakly supervised framework considering multi-temporal information for\nlarge-scale cropland mapping. Specifically, we extract high-quality labels\naccording to their consistency among global land cover (GLC) products to\nconstruct the supervised learning signal. On the one hand, to alleviate the\noverfitting problem caused by the model's over-trust of remaining errors in\nhigh-quality labels, we encode the similarity/aggregation of cropland in the\nvisual/spatial domain to construct the unsupervised learning signal, and take\nit as the regularization term to constrain the supervised part. On the other\nhand, to sufficiently leverage the plentiful information in the samples without\nhigh-quality labels, we also incorporate the unsupervised learning signal in\nthese samples, enriching the diversity of the feature space. After that, to\ncapture the phenological features of croplands, we introduce dense satellite\nimage time series (SITS) to extend the proposed framework in the temporal\ndimension. We also visualized the high dimensional phenological features to\nuncover how multi-temporal information benefits cropland extraction, and\nassessed the method's robustness under conditions of data scarcity. The\nproposed framework has been experimentally validated for strong adaptability\nacross three study areas (Hunan Province, Southeast France, and Kansas) in\nlarge-scale cropland mapping, and the internal mechanism and temporal\ngeneralizability are also investigated.",
      "tldr_zh": "该研究提出了一种弱监督框架，用于利用卫星图像进行大规模农田映射，旨在减少标签成本并考虑多时态信息。具体方法包括从全球土地覆盖产品提取高品质标签作为监督信号，结合视觉/空间域的无监督学习信号（如相似性/聚合）来缓解过拟合，并通过密集卫星图像时间序列 (SITS) 捕捉农田的表型特征。实验在湖南省、法国东南部和堪萨斯州等区域验证了框架的适应性和鲁棒性，展示了多时态信息如何提升农田提取准确性，并在数据稀缺条件下保持了较强泛化能力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.18475v1",
      "published_date": "2024-11-27 16:11:52 UTC",
      "updated_date": "2024-11-27 16:11:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:58:53.485121"
    },
    {
      "arxiv_id": "2411.18462v1",
      "title": "Draft Model Knows When to Stop: A Self-Verification Length Policy for Speculative Decoding",
      "title_zh": "翻译失败",
      "authors": [
        "Ziyin Zhang",
        "Jiahao Xu",
        "Tian Liang",
        "Xingyu Chen",
        "Zhiwei He",
        "Rui Wang",
        "Zhaopeng Tu"
      ],
      "abstract": "Speculative Decoding (SD) has become an important technique in accelerating\nthe inference speed of large language models. Conventional SD methods employ a\nfixed draft length, which ignores the token generation difficulty across tasks.\nConsequently, in this paper, we address such an issue and introduce SVIP - a\ndifficulty-aware dynamic draft length policy for speculative decoding systems.\nBased on a theoretical lower bound of draft token acceptance rate and its\ninference-time approximation, SVIP adaptively determines the lengths of draft\nsequences based on the entropy of each draft token distribution. Experimental\nresults on mainstream SD benchmarks and frameworks demonstrate the superior\nperformance of SVIP, achieving up to 20\\% walltime speedup on SpecBench over\nbaseline SD methods and 60\\% speedup on MT-Bench for long-form generation of up\nto 8K tokens. Moreover, SVIP is totally training-free and compatible with any\nexisting SD methods that generate draft tokens autoregressively. Experimental\nresults also show that SVIP yields consistent walltime improvement on top of\nGliDe & CaPE and EAGLE-2.",
      "tldr_zh": "这篇论文针对 Speculative Decoding (SD) 的固定草稿长度问题，提出了一种基于难度的动态策略 SVIP，通过每个草稿 token 分布的 entropy 及其推理时近似值，适应性地调整草稿序列长度。SVIP 基于理论下界实现训练-free 设计，并与任何自回归生成草稿的 SD 方法兼容。实验结果显示，SVIP 在 SpecBench 上比基线方法加速 20%，在 MT-Bench 的长序列生成（高达 8K tokens）上加速 60%，并在 GliDe & CaPE 和 EAGLE-2 上表现出一致的性能提升。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Code at https://github.com/Geralt-Targaryen/SVIP",
      "pdf_url": "http://arxiv.org/pdf/2411.18462v1",
      "published_date": "2024-11-27 15:53:17 UTC",
      "updated_date": "2024-11-27 15:53:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:59:04.573922"
    },
    {
      "arxiv_id": "2411.18456v1",
      "title": "Synthetic ECG Generation for Data Augmentation and Transfer Learning in Arrhythmia Classification",
      "title_zh": "翻译失败",
      "authors": [
        "José Fernando Núñez",
        "Jamie Arjona",
        "Javier Béjar"
      ],
      "abstract": "Deep learning models need a sufficient amount of data in order to be able to\nfind the hidden patterns in it. It is the purpose of generative modeling to\nlearn the data distribution, thus allowing us to sample more data and augment\nthe original dataset. In the context of physiological data, and more\nspecifically electrocardiogram (ECG) data, given its sensitive nature and\nexpensive data collection, we can exploit the benefits of generative models in\norder to enlarge existing datasets and improve downstream tasks, in our case,\nclassification of heart rhythm.\n  In this work, we explore the usefulness of synthetic data generated with\ndifferent generative models from Deep Learning namely Diffweave, Time-Diffusion\nand Time-VQVAE in order to obtain better classification results for two open\nsource multivariate ECG datasets. Moreover, we also investigate the effects of\ntransfer learning, by fine-tuning a synthetically pre-trained model and then\nprogressively adding increasing proportions of real data. We conclude that\nalthough the synthetic samples resemble the real ones, the classification\nimprovement when simply augmenting the real dataset is barely noticeable on\nindividual datasets, but when both datasets are merged the results show an\nincrease across all metrics for the classifiers when using synthetic samples as\naugmented data. From the fine-tuning results the Time-VQVAE generative model\nhas shown to be superior to the others but not powerful enough to achieve\nresults close to a classifier trained with real data only. In addition, methods\nand metrics for measuring closeness between synthetic data and the real one\nhave been explored as a side effect of the main research questions of this\nstudy.",
      "tldr_zh": "本文研究了使用生成模型（如Diffweave、Time-Diffusion和Time-VQVAE）生成合成ECG数据，以扩充数据集并提升心律分类任务的性能。实验结果显示，单纯扩充单个数据集的分类改善有限，但当合并多个数据集时，合成数据能显著提高分类指标；在迁移学习中，Time-VQVAE模型表现最佳，但仍无法达到仅用真实数据训练的水平，同时探讨了衡量合成数据与真实数据相似度的方法和指标。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.18456v1",
      "published_date": "2024-11-27 15:46:34 UTC",
      "updated_date": "2024-11-27 15:46:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:59:16.457876"
    },
    {
      "arxiv_id": "2411.18447v1",
      "title": "Continuous Autoregressive Models with Noise Augmentation Avoid Error Accumulation",
      "title_zh": "带噪声增强的连续自回归模型避免错误积累",
      "authors": [
        "Marco Pasini",
        "Javier Nistal",
        "Stefan Lattner",
        "George Fazekas"
      ],
      "abstract": "Autoregressive models are typically applied to sequences of discrete tokens,\nbut recent research indicates that generating sequences of continuous\nembeddings in an autoregressive manner is also feasible. However, such\nContinuous Autoregressive Models (CAMs) can suffer from a decline in generation\nquality over extended sequences due to error accumulation during inference. We\nintroduce a novel method to address this issue by injecting random noise into\nthe input embeddings during training. This procedure makes the model robust\nagainst varying error levels at inference. We further reduce error accumulation\nthrough an inference procedure that introduces low-level noise. Experiments on\nmusical audio generation show that CAM substantially outperforms existing\nautoregressive and non-autoregressive approaches while preserving audio quality\nover extended sequences. This work paves the way for generating continuous\nembeddings in a purely autoregressive setting, opening new possibilities for\nreal-time and interactive generative applications.",
      "tldr_zh": "这篇论文解决了 Continuous Autoregressive Models (CAMs) 在生成长序列时因错误积累导致质量下降的问题，通过引入噪声增强方法在训练时向输入嵌入注入随机噪声，从而提升模型对推理误差的鲁棒性。作者还设计了在推理过程中添加低水平噪声的策略，进一步减少错误积累。在音乐音频生成实验中，CAM 显著优于现有自动回归和非自动回归方法，并在长序列中保持音频质量。该工作为纯自动回归设置下的连续嵌入生成开辟了新路径，支持实时和交互式应用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to NeurIPS 2024 - Audio Imagination Workshop",
      "pdf_url": "http://arxiv.org/pdf/2411.18447v1",
      "published_date": "2024-11-27 15:38:20 UTC",
      "updated_date": "2024-11-27 15:38:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:59:28.716679"
    },
    {
      "arxiv_id": "2411.18444v1",
      "title": "Is my Meeting Summary Good? Estimating Quality with a Multi-LLM Evaluator",
      "title_zh": "翻译失败",
      "authors": [
        "Frederic Kirstein",
        "Terry Ruas",
        "Bela Gipp"
      ],
      "abstract": "The quality of meeting summaries generated by natural language generation\n(NLG) systems is hard to measure automatically. Established metrics such as\nROUGE and BERTScore have a relatively low correlation with human judgments and\nfail to capture nuanced errors. Recent studies suggest using large language\nmodels (LLMs), which have the benefit of better context understanding and\nadaption of error definitions without training on a large number of human\npreference judgments. However, current LLM-based evaluators risk masking errors\nand can only serve as a weak proxy, leaving human evaluation the gold standard\ndespite being costly and hard to compare across studies. In this work, we\npresent MESA, an LLM-based framework employing a three-step assessment of\nindividual error types, multi-agent discussion for decision refinement, and\nfeedback-based self-training to refine error definition understanding and\nalignment with human judgment. We show that MESA's components enable thorough\nerror detection, consistent rating, and adaptability to custom error\nguidelines. Using GPT-4o as its backbone, MESA achieves mid to high\nPoint-Biserial correlation with human judgment in error detection and mid\nSpearman and Kendall correlation in reflecting error impact on summary quality,\non average 0.25 higher than previous methods. The framework's flexibility in\nadapting to custom error guidelines makes it suitable for various tasks with\nlimited human-labeled data.",
      "tldr_zh": "这篇论文探讨了会议摘要质量自动评估的挑战，指出传统指标如 ROUGE 和 BERTScore 与人类判断的相关性较低，无法有效捕捉细微错误。作者提出 MESA 框架，一个基于 LLMs 的多智能体评估系统，包括个体错误类型评估、多代理讨论决策精炼以及反馈自训练，以提升错误检测准确性和与人类判断的对齐。实验结果显示，使用 GPT-4o 作为骨干的 MESA 在错误检测中达到中到高 Point-Biserial 相关性，在反映错误影响的 Spearman 和 Kendall 相关性上平均比之前方法高 0.25。该框架还具备灵活适应自定义错误指南的能力，适合数据有限的各种任务。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.18444v1",
      "published_date": "2024-11-27 15:35:32 UTC",
      "updated_date": "2024-11-27 15:35:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:59:41.738683"
    },
    {
      "arxiv_id": "2411.18442v2",
      "title": "Metric-DST: Mitigating Selection Bias Through Diversity-Guided Semi-Supervised Metric Learning",
      "title_zh": "Metric-DST：通过多样性引导的半监督度量学习缓解选择偏差",
      "authors": [
        "Yasin I. Tepeli",
        "Mathijs de Wolf",
        "Joana P. Gonçalves"
      ],
      "abstract": "Selection bias poses a critical challenge for fairness in machine learning,\nas models trained on data that is less representative of the population might\nexhibit undesirable behavior for underrepresented profiles. Semi-supervised\nlearning strategies like self-training can mitigate selection bias by\nincorporating unlabeled data into model training to gain further insight into\nthe distribution of the population. However, conventional self-training seeks\nto include high-confidence data samples, which may reinforce existing model\nbias and compromise effectiveness. We propose Metric-DST, a diversity-guided\nself-training strategy that leverages metric learning and its implicit\nembedding space to counter confidence-based bias through the inclusion of more\ndiverse samples. Metric-DST learned more robust models in the presence of\nselection bias for generated and real-world datasets with induced bias, as well\nas a molecular biology prediction task with intrinsic bias. The Metric-DST\nlearning strategy offers a flexible and widely applicable solution to mitigate\nselection bias and enhance fairness of machine learning models.",
      "tldr_zh": "该论文针对机器学习中的选择偏差（selection bias）问题，提出了一种名为 Metric-DST 的多样性引导的自训练策略（diversity-guided self-training），通过结合度量学习（metric learning）的嵌入空间，选择更多样化的样本来避免传统自训练方法依赖高置信度样本而强化偏差。相比于常规方法，Metric-DST 在生成数据集、真实世界数据集以及一个分子生物学预测任务中，显著提升了模型的鲁棒性和公平性。总体而言，该策略提供了一个灵活且通用的解决方案，帮助缓解选择偏差并改进机器学习模型的公平表现。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "18 pages main manuscript (4 main figures), 7 pages of supplementary",
      "pdf_url": "http://arxiv.org/pdf/2411.18442v2",
      "published_date": "2024-11-27 15:29:42 UTC",
      "updated_date": "2024-11-28 08:34:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:59:52.193823"
    },
    {
      "arxiv_id": "2411.18428v4",
      "title": "MM-Path: Multi-modal, Multi-granularity Path Representation Learning -- Extended Version",
      "title_zh": "MM-Path: 多模态、多粒度路径表示学习——扩展版本",
      "authors": [
        "Ronghui Xu",
        "Hanyin Cheng",
        "Chenjuan Guo",
        "Hongfan Gao",
        "Jilin Hu",
        "Sean Bin Yang",
        "Bin Yang"
      ],
      "abstract": "Developing effective path representations has become increasingly essential\nacross various fields within intelligent transportation. Although pre-trained\npath representation learning models have shown improved performance, they\npredominantly focus on the topological structures from single modality data,\ni.e., road networks, overlooking the geometric and contextual features\nassociated with path-related images, e.g., remote sensing images. Similar to\nhuman understanding, integrating information from multiple modalities can\nprovide a more comprehensive view, enhancing both representation accuracy and\ngeneralization. However, variations in information granularity impede the\nsemantic alignment of road network-based paths (road paths) and image-based\npaths (image paths), while the heterogeneity of multi-modal data poses\nsubstantial challenges for effective fusion and utilization. In this paper, we\npropose a novel Multi-modal, Multi-granularity Path Representation Learning\nFramework (MM-Path), which can learn a generic path representation by\nintegrating modalities from both road paths and image paths. To enhance the\nalignment of multi-modal data, we develop a multi-granularity alignment\nstrategy that systematically associates nodes, road sub-paths, and road paths\nwith their corresponding image patches, ensuring the synchronization of both\ndetailed local information and broader global contexts. To address the\nheterogeneity of multi-modal data effectively, we introduce a graph-based\ncross-modal residual fusion component designed to comprehensively fuse\ninformation across different modalities and granularities. Finally, we conduct\nextensive experiments on two large-scale real-world datasets under two\ndownstream tasks, validating the effectiveness of the proposed MM-Path. The\ncode is available at: https://github.com/decisionintelligence/MM-Path.",
      "tldr_zh": "该研究提出了一种新型框架 MM-Path，用于多模态、多粒度路径表示学习，旨在解决现有模型仅关注道路网络拓扑结构而忽略图像（如遥感图像）的几何和上下文特征问题。通过整合道路路径和图像路径的信息，MM-Path 采用多粒度对齐策略（multi-granularity alignment strategy）来关联节点、子路径与图像补丁，确保多模态数据的语义同步，并引入图-based 跨模态残差融合组件（graph-based cross-modal residual fusion component）来有效融合异构数据。实验在两个大规模真实数据集上验证了该框架在下游任务中的优越性能，提高了路径表示的准确性和泛化能力。代码已在 GitHub 上公开。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "This is an extended version of the paper accepted by KDD 2025",
      "pdf_url": "http://arxiv.org/pdf/2411.18428v4",
      "published_date": "2024-11-27 15:10:22 UTC",
      "updated_date": "2025-01-02 07:52:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T05:00:04.409065"
    },
    {
      "arxiv_id": "2411.18384v2",
      "title": "Optimal In-Network Distribution of Learning Functions for a Secure-by-Design Programmable Data Plane of Next-Generation Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Mattia Giovanni Spina",
        "Edoardo Scalzo",
        "Floriano De Rango",
        "Francesca Guerriero",
        "Antonio Iera"
      ],
      "abstract": "The rise of programmable data plane (PDP) and in-network computing (INC)\nparadigms paves the way for the development of network devices (switches,\nnetwork interface cards, etc.) capable of performing advanced processing tasks.\nThis allows running various types of algorithms, including machine learning,\nwithin the network itself to support user and network services. In particular,\nthis paper delves into the deployment of in-network learning models with the\naim of implementing fully distributed intrusion detection systems (IDS) or\nintrusion prevention systems (IPS). Specifically, a model is proposed for the\noptimal distribution of the IDS/IPS workload among data plane devices with the\naim of ensuring complete network security without excessively burdening the\nnormal operations of the devices. Furthermore, a meta-heuristic approach is\nproposed to reduce the long computation time required by the exact solution\nprovided by the mathematical model and its performance is evaluated. The\nanalysis conducted and the results obtained demonstrate the enormous potential\nof the proposed new approach for the creation of intelligent data planes that\nact effectively and autonomously as the first line of defense against cyber\nattacks, with minimal additional workload on the network devices involved.",
      "tldr_zh": "该论文探讨了可编程数据平面 (PDP) 和网络内计算 (INC) 的兴起，如何使网络设备（如交换机和网卡）执行高级任务，包括机器学习，以支持分布式入侵检测系统 (IDS) 或入侵预防系统 (IPS)。作者提出一个优化模型，用于在数据平面设备之间最佳分配 IDS/IPS 工作负载，确保网络安全同时避免过度负担设备。针对该模型的计算时间问题，他们引入了一种元启发式方法，并通过实验验证其有效性，结果显示该方法能创建智能、自主的数据平面，作为网络攻击的第一道防线，同时最小化设备负载。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.18384v2",
      "published_date": "2024-11-27 14:29:53 UTC",
      "updated_date": "2025-04-29 16:33:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T05:00:17.314529"
    },
    {
      "arxiv_id": "2411.18382v1",
      "title": "ChatGPT as speechwriter for the French presidents",
      "title_zh": "ChatGPT 作为法国总统的演讲撰写者",
      "authors": [
        "Dominique Labbé",
        "Cyril Labbé",
        "Jacques Savoy"
      ],
      "abstract": "Generative AI proposes several large language models (LLMs) to automatically\ngenerate a message in response to users' requests. Such scientific\nbreakthroughs promote new writing assistants but with some fears. The main\nfocus of this study is to analyze the written style of one LLM called ChatGPT\nby comparing its generated messages with those of the recent French presidents.\nTo achieve this, we compare end-of-the-year addresses written by Chirac,\nSarkozy, Hollande, and Macron with those automatically produced by ChatGPT. We\nfound that ChatGPT tends to overuse nouns, possessive determiners, and numbers.\nOn the other hand, the generated speeches employ less verbs, pronouns, and\nadverbs and include, in mean, too standardized sentences. Considering some\nwords, one can observe that ChatGPT tends to overuse \"to must\" (devoir), \"to\ncontinue\" or the lemma \"we\" (nous). Moreover, GPT underuses the auxiliary verb\n\"to be\" (^etre), or the modal verbs \"to will\" (vouloir) or \"to have to\"\n(falloir). In addition, when a short text is provided as example to ChatGPT,\nthe machine can generate a short message with a style closed to the original\nwording. Finally, we reveal that ChatGPT style exposes distinct features\ncompared to real presidential speeches.",
      "tldr_zh": "这篇论文探讨了 ChatGPT 作为写作助手的角色，通过比较其生成的法国总统年终演讲与 Chirac、Sarkozy、Hollande 和 Macron 的真实演讲，分析 LLM 的写作风格。研究发现，ChatGPT 倾向于过度使用名词、所有格限定词和数字，同时减少动词、代词和副词的使用，导致句子过于标准化，并频繁出现如“devoir”（to must）和“nous”（we）等词汇，而少用“être”（to be）、“vouloir”（to will）或“falloir”（to have to）。此外，提供短文本示例时，ChatGPT 可以生成风格相似的短消息，但整体上其风格与真实总统演讲存在显著差异，突显了 LLM 在生成个性化文本时的局限性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.18382v1",
      "published_date": "2024-11-27 14:29:10 UTC",
      "updated_date": "2024-11-27 14:29:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T05:00:29.557818"
    },
    {
      "arxiv_id": "2411.18369v2",
      "title": "G3Flow: Generative 3D Semantic Flow for Pose-aware and Generalizable Object Manipulation",
      "title_zh": "翻译失败",
      "authors": [
        "Tianxing Chen",
        "Yao Mu",
        "Zhixuan Liang",
        "Zanxin Chen",
        "Shijia Peng",
        "Qiangyu Chen",
        "Mingkun Xu",
        "Ruizhen Hu",
        "Hongyuan Zhang",
        "Xuelong Li",
        "Ping Luo"
      ],
      "abstract": "Recent advances in imitation learning for 3D robotic manipulation have shown\npromising results with diffusion-based policies. However, achieving human-level\ndexterity requires seamless integration of geometric precision and semantic\nunderstanding. We present G3Flow, a novel framework that constructs real-time\nsemantic flow, a dynamic, object-centric 3D semantic representation by\nleveraging foundation models. Our approach uniquely combines 3D generative\nmodels for digital twin creation, vision foundation models for semantic feature\nextraction, and robust pose tracking for continuous semantic flow updates. This\nintegration enables complete semantic understanding even under occlusions while\neliminating manual annotation requirements. By incorporating semantic flow into\ndiffusion policies, we demonstrate significant improvements in both\nterminal-constrained manipulation and cross-object generalization. Extensive\nexperiments across five simulation tasks show that G3Flow consistently\noutperforms existing approaches, achieving up to 68.3% and 50.1% average\nsuccess rates on terminal-constrained manipulation and cross-object\ngeneralization tasks respectively. Our results demonstrate the effectiveness of\nG3Flow in enhancing real-time dynamic semantic feature understanding for\nrobotic manipulation policies.",
      "tldr_zh": "本文提出G3Flow框架，一种生成式3D语义流（Generative 3D Semantic Flow）方法，旨在通过整合3D生成模型（用于digital twin creation）、视觉基础模型（用于semantic feature extraction）和鲁棒姿态跟踪（pose tracking），构建动态的、以物体为中心的实时语义表示，实现对遮挡场景的完整语义理解，而无需手动标注。G3Flow将语义流融入diffusion policies中，显著提升了终端约束操作（terminal-constrained manipulation）和跨物体泛化（cross-object generalization）的性能。在五个模拟任务的实验中，该框架分别实现了68.3%和50.1%的平均成功率，优于现有方法，并证明了其在机器人操作策略中的实时动态语义特征理解的有效性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "Webpage: https://tianxingchen.github.io/G3Flow/, accepted to CVPR\n  2025",
      "pdf_url": "http://arxiv.org/pdf/2411.18369v2",
      "published_date": "2024-11-27 14:17:43 UTC",
      "updated_date": "2025-02-27 17:59:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T05:00:42.078945"
    },
    {
      "arxiv_id": "2411.18368v2",
      "title": "AMPS: ASR with Multimodal Paraphrase Supervision",
      "title_zh": "翻译失败",
      "authors": [
        "Abhishek Gupta",
        "Amruta Parulekar",
        "Sameep Chattopadhyay",
        "Preethi Jyothi"
      ],
      "abstract": "Spontaneous or conversational multilingual speech presents many challenges\nfor state-of-the-art automatic speech recognition (ASR) systems. In this work,\nwe present a new technique AMPS that augments a multilingual multimodal ASR\nsystem with paraphrase-based supervision for improved conversational ASR in\nmultiple languages, including Hindi, Marathi, Malayalam, Kannada, and Nyanja.\nWe use paraphrases of the reference transcriptions as additional supervision\nwhile training the multimodal ASR model and selectively invoke this paraphrase\nobjective for utterances with poor ASR performance. Using AMPS with a\nstate-of-the-art multimodal model SeamlessM4T, we obtain significant relative\nreductions in word error rates (WERs) of up to 5%. We present detailed analyses\nof our system using both objective and human evaluation metrics.",
      "tldr_zh": "本论文提出 AMPS 技术，用于提升多语言对话式 ASR（Automatic Speech Recognition）系统的性能，针对 Hindi、Marathi、Malayalam、Kannada 和 Nyanja 等语言。AMPS 通过在多模态 ASR 模型中加入参考转录的改写（paraphrases）作为额外监督，并选择性地应用于 ASR 表现不佳的 utterances，从而改善模型的准确性。实验结果显示，与 SeamlessM4T 模型结合后，WER（Word Error Rates）相对减少高达 5%，并通过客观和人类评估指标进行了详细分析。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.18368v2",
      "published_date": "2024-11-27 14:16:51 UTC",
      "updated_date": "2025-04-16 18:54:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T05:00:52.746682"
    },
    {
      "arxiv_id": "2411.18365v1",
      "title": "GPT as ghostwriter at the White House",
      "title_zh": "翻译失败",
      "authors": [
        "Jacques Savoy"
      ],
      "abstract": "Recently several large language models (LLMs) have demonstrated their\ncapability to generate a message in response to a user request. Such scientific\nbreakthroughs promote new perspectives but also some fears. The main focus of\nthis study is to analyze the written style of one LLM called ChatGPT 3.5 by\ncomparing its generated messages with those of the recent US presidents. To\nachieve this objective, we compare the State of the Union addresses written by\nReagan to Obama with those automatically produced by ChatGPT. We found that\nChatGPT tends to overuse the lemma \"we\" as well as nouns and commas. On the\nother hand, the generated speeches employ less verbs and include, in mean,\nlonger sentences. Even when imposing a given style to ChatGPT, the resulting\nspeech remains distinct from messages written by the target author. Moreover,\nChatGPT opts for a neutral tone with mainly positive emotional expressions and\nsymbolic terms (e.g., freedom, nation). Finally, we show that the GPT's style\nexposes distinct features compared to real presidential addresses.",
      "tldr_zh": "本研究分析了大型语言模型(LLMs)如 ChatGPT 3.5 的写作风格，通过将它生成的 State of the Union 演讲与 Reagan 到 Obama 的真实演讲进行比较。结果显示，ChatGPT 过度使用 \"we\" 词汇、名词和逗号，同时减少动词使用并产生较长句子，即使指定特定风格，其输出仍与目标作者明显不同。ChatGPT 倾向于采用中性、积极的语气，并频繁使用象征性术语（如 freedom 和 nation），最终揭示了其风格与真实总统演讲的独特差异。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.18365v1",
      "published_date": "2024-11-27 14:12:36 UTC",
      "updated_date": "2024-11-27 14:12:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T05:01:04.088638"
    },
    {
      "arxiv_id": "2411.18350v1",
      "title": "TryOffDiff: Virtual-Try-Off via High-Fidelity Garment Reconstruction using Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Riza Velioglu",
        "Petra Bevandic",
        "Robin Chan",
        "Barbara Hammer"
      ],
      "abstract": "This paper introduces Virtual Try-Off (VTOFF), a novel task focused on\ngenerating standardized garment images from single photos of clothed\nindividuals. Unlike traditional Virtual Try-On (VTON), which digitally dresses\nmodels, VTOFF aims to extract a canonical garment image, posing unique\nchallenges in capturing garment shape, texture, and intricate patterns. This\nwell-defined target makes VTOFF particularly effective for evaluating\nreconstruction fidelity in generative models. We present TryOffDiff, a model\nthat adapts Stable Diffusion with SigLIP-based visual conditioning to ensure\nhigh fidelity and detail retention. Experiments on a modified VITON-HD dataset\nshow that our approach outperforms baseline methods based on pose transfer and\nvirtual try-on with fewer pre- and post-processing steps. Our analysis reveals\nthat traditional image generation metrics inadequately assess reconstruction\nquality, prompting us to rely on DISTS for more accurate evaluation. Our\nresults highlight the potential of VTOFF to enhance product imagery in\ne-commerce applications, advance generative model evaluation, and inspire\nfuture work on high-fidelity reconstruction. Demo, code, and models are\navailable at: https://rizavelioglu.github.io/tryoffdiff/",
      "tldr_zh": "本论文引入Virtual Try-Off (VTOFF)任务，该任务从单个穿衣照片中生成标准化服装图像，专注于捕捉服装的形状、纹理和复杂图案，与传统Virtual Try-On (VTON)不同，更适合评估生成模型的重建保真度。作者提出TryOffDiff模型，通过适应Stable Diffusion并结合SigLIP-based视觉条件，实现高保真和细节保留的服装重建。实验在修改后的VITON-HD数据集上显示，该模型优于基线方法，减少了预处理和后处理步骤，并使用DISTS指标进行更准确评估，最终证明VTOFF可提升电商产品图像生成和生成模型评估。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.18350v1",
      "published_date": "2024-11-27 13:53:09 UTC",
      "updated_date": "2024-11-27 13:53:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T05:01:17.167246"
    },
    {
      "arxiv_id": "2411.18343v2",
      "title": "FreqX: Analyze the Attribution Methods in Another Domain",
      "title_zh": "翻译失败",
      "authors": [
        "Zechen Liu",
        "Feiyang Zhang",
        "Wei Song",
        "Xiang Li",
        "Wei Wei"
      ],
      "abstract": "Personalized Federal learning(PFL) allows clients to cooperatively train a\npersonalized model without disclosing their private dataset. However, PFL\nsuffers from Non-IID, heterogeneous devices, lack of fairness, and unclear\ncontribution which urgently need the interpretability of deep learning model to\novercome these challenges. These challenges proposed new demands for\ninterpretability. Low cost, privacy, and detailed information. There is no\ncurrent interpretability method satisfying them. In this paper, we propose a\nnovel interpretability method \\emph{FreqX} by introducing Signal Processing and\nInformation Theory. Our experiments show that the explanation results of FreqX\ncontain both attribution information and concept information. FreqX runs at\nleast 10 times faster than the baselines which contain concept information.",
      "tldr_zh": "该论文针对个性化联邦学习(PFL)面临的Non-IID、异构设备、公平性缺失和贡献不清晰等问题，强调了深度学习模型可解释性的重要性，并提出了新需求：低成本、隐私保护和详细信息。作者引入Signal Processing和Information Theory，开发了新型可解释性方法FreqX，以满足这些需求。实验结果显示，FreqX不仅提供归因信息和概念信息，还比基线方法快至少10倍，为PFL的可解释性挑战提供了有效解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "16pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.18343v2",
      "published_date": "2024-11-27 13:41:24 UTC",
      "updated_date": "2025-03-31 06:28:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T05:01:28.448683"
    },
    {
      "arxiv_id": "2411.18335v2",
      "title": "Helvipad: A Real-World Dataset for Omnidirectional Stereo Depth Estimation",
      "title_zh": "Helvipad：一个真实世界的全向立体深度估计数据集",
      "authors": [
        "Mehdi Zayene",
        "Jannik Endres",
        "Albias Havolli",
        "Charles Corbière",
        "Salim Cherkaoui",
        "Alexandre Kontouli",
        "Alexandre Alahi"
      ],
      "abstract": "Despite progress in stereo depth estimation, omnidirectional imaging remains\nunderexplored, mainly due to the lack of appropriate data. We introduce\nHelvipad, a real-world dataset for omnidirectional stereo depth estimation,\nfeaturing 40K video frames from video sequences across diverse environments,\nincluding crowded indoor and outdoor scenes with various lighting conditions.\nCollected using two 360{\\deg} cameras in a top-bottom setup and a LiDAR sensor,\nthe dataset includes accurate depth and disparity labels by projecting 3D point\nclouds onto equirectangular images. Additionally, we provide an augmented\ntraining set with an increased label density by using depth completion. We\nbenchmark leading stereo depth estimation models for both standard and\nomnidirectional images. The results show that while recent stereo methods\nperform decently, a challenge persists in accurately estimating depth in\nomnidirectional imaging. To address this, we introduce necessary adaptations to\nstereo models, leading to improved performance.",
      "tldr_zh": "这篇论文引入了 Helvipad，这是一个真实世界的全向立体深度估计数据集，包含 40K 视频帧来自多样环境，包括拥挤的室内和室外场景以及各种照明条件。数据集使用两个 360° 相机（顶部和底部设置）和 LiDAR 传感器收集，通过将 3D 点云投影到等矩形图像上提供准确的深度和视差标签，并通过 depth completion 增强训练集以增加标签密度。作者对领先的立体深度估计模型进行了基准测试，结果显示这些模型在 omnidirectional 图像上表现尚可但存在挑战，通过对模型的必要适应，显著提高了深度估计性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to CVPR 2025. Project page:\n  https://vita-epfl.github.io/Helvipad",
      "pdf_url": "http://arxiv.org/pdf/2411.18335v2",
      "published_date": "2024-11-27 13:34:41 UTC",
      "updated_date": "2025-03-25 13:57:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T05:01:41.419801"
    },
    {
      "arxiv_id": "2411.18324v1",
      "title": "RITA: Automatic Framework for Designing of Resilient IoT Applications",
      "title_zh": "RITA：弹性 IoT 应用设计自动框架",
      "authors": [
        "Luis Eduardo Pessoa",
        "Cristovao Freitas Iglesias Jr",
        "Claudio Miceli"
      ],
      "abstract": "Designing resilient Internet of Things (IoT) systems requires i)\nidentification of IoT Critical Objects (ICOs) such as services, devices, and\nresources, ii) threat analysis, and iii) mitigation strategy selection.\nHowever, the traditional process for designing resilient IoT systems is still\nmanual, leading to inefficiencies and increased risks. In addition, while tools\nsuch as ChatGPT could support this manual and highly error-prone process, their\nuse raises concerns over data privacy, inconsistent outputs, and internet\ndependence. Therefore, we propose RITA, an automated, open-source framework\nthat uses a fine-tuned RoBERTa-based Named Entity Recognition (NER) model to\nidentify ICOs from IoT requirement documents, correlate threats, and recommend\ncountermeasures. RITA operates entirely offline and can be deployed on-site,\nsafeguarding sensitive information and delivering consistent outputs that\nenhance standardization. In our empirical evaluation, RITA outperformed ChatGPT\nin four of seven ICO categories, particularly in actuator, sensor, network\nresource, and service identification, using both human-annotated and\nChatGPT-generated test data. These findings indicate that RITA can improve\nresilient IoT design by effectively supporting key security operations,\noffering a practical solution for developing robust IoT architectures.",
      "tldr_zh": "本研究提出 RITA，一个自动化开源框架，用于设计弹性 IoT 应用，通过识别 IoT Critical Objects (ICOs) 如服务、设备和资源，进行威胁分析并推荐缓解策略，以解决传统手动过程的低效和风险问题。RITA 采用 fine-tuned RoBERTa-based Named Entity Recognition (NER) 模型，从 IoT 需求文档中提取 ICOs，并确保离线运行以保护数据隐私和输出一致性。在实证评估中，RITA 在七个 ICO 类别中的四个（包括 actuator, sensor, network resource 和 service）上超过了 ChatGPT，使用人类标注和 ChatGPT 生成的数据，从而为构建稳健 IoT 架构提供实用支持。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.18324v1",
      "published_date": "2024-11-27 13:24:52 UTC",
      "updated_date": "2024-11-27 13:24:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T05:01:53.335753"
    },
    {
      "arxiv_id": "2411.18321v1",
      "title": "Learning optimal objective values for MILP",
      "title_zh": "翻译失败",
      "authors": [
        "Lara Scavuzzo",
        "Karen Aardal",
        "Neil Yorke-Smith"
      ],
      "abstract": "Modern Mixed Integer Linear Programming (MILP) solvers use the\nBranch-and-Bound algorithm together with a plethora of auxiliary components\nthat speed up the search. In recent years, there has been an explosive\ndevelopment in the use of machine learning for enhancing and supporting these\nalgorithmic components. Within this line, we propose a methodology for\npredicting the optimal objective value, or, equivalently, predicting if the\ncurrent incumbent is optimal. For this task, we introduce a predictor based on\na graph neural network (GNN) architecture, together with a set of dynamic\nfeatures. Experimental results on diverse benchmarks demonstrate the efficacy\nof our approach, achieving high accuracy in the prediction task and\noutperforming existing methods. These findings suggest new opportunities for\nintegrating ML-driven predictions into MILP solvers, enabling smarter\ndecision-making and improved performance.",
      "tldr_zh": "本文提出一种方法，用于在混合整数线性规划 (MILP) 中预测最优目标值，或判断当前最优解是否最优，旨在提升求解器的性能。研究者开发了基于图神经网络 (GNN) 架构的预测器，并结合一组动态特征来处理这一任务。在各种基准实验中，该方法显示出高准确率，并优于现有方法，为将机器学习驱动的预测整合到 MILP 求解器中提供了新机会，从而实现更智能的决策和整体性能提升。",
      "categories": [
        "math.OC",
        "cs.AI",
        "cs.LG",
        "cs.MS"
      ],
      "primary_category": "math.OC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.18321v1",
      "published_date": "2024-11-27 13:22:31 UTC",
      "updated_date": "2024-11-27 13:22:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T05:02:04.839153"
    },
    {
      "arxiv_id": "2411.18320v1",
      "title": "Continual Learning in Machine Speech Chain Using Gradient Episodic Memory",
      "title_zh": "翻译失败",
      "authors": [
        "Geoffrey Tyndall",
        "Kurniawati Azizah",
        "Dipta Tanaya",
        "Ayu Purwarianti",
        "Dessi Puji Lestari",
        "Sakriani Sakti"
      ],
      "abstract": "Continual learning for automatic speech recognition (ASR) systems poses a\nchallenge, especially with the need to avoid catastrophic forgetting while\nmaintaining performance on previously learned tasks. This paper introduces a\nnovel approach leveraging the machine speech chain framework to enable\ncontinual learning in ASR using gradient episodic memory (GEM). By\nincorporating a text-to-speech (TTS) component within the machine speech chain,\nwe support the replay mechanism essential for GEM, allowing the ASR model to\nlearn new tasks sequentially without significant performance degradation on\nearlier tasks. Our experiments, conducted on the LJ Speech dataset, demonstrate\nthat our method outperforms traditional fine-tuning and multitask learning\napproaches, achieving a substantial error rate reduction while maintaining high\nperformance across varying noise conditions. We showed the potential of our\nsemi-supervised machine speech chain approach for effective and efficient\ncontinual learning in speech recognition.",
      "tldr_zh": "这篇论文针对自动语音识别 (ASR) 系统的持续学习问题，提出了一种新方法，利用机器语音链框架结合梯度记忆回放 (Gradient Episodic Memory, GEM)，以避免灾难性遗忘并保持先前任务的性能。通过在机器语音链中整合文本到语音 (TTS) 组件，支持回放机制，使 ASR 模型能够顺序学习新任务。实验在 LJ Speech 数据集上表明，该方法优于传统微调和多任务学习，显著降低了错误率，并在不同噪声条件下维持高性能。该方法展示了半监督机器语音链在语音识别持续学习中的高效潜力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "Published as a conference paper at O-COCOSDA 2024. 6 pages; 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.18320v1",
      "published_date": "2024-11-27 13:19:20 UTC",
      "updated_date": "2024-11-27 13:19:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T05:02:17.249358"
    },
    {
      "arxiv_id": "2411.18309v2",
      "title": "MvKeTR: Chest CT Report Generation with Multi-View Perception and Knowledge Enhancement",
      "title_zh": "翻译失败",
      "authors": [
        "Xiwei Deng",
        "Xianchun He",
        "Jiangfeng Bao",
        "Yudan Zhou",
        "Shuhui Cai",
        "Congbo Cai",
        "Zhong Chen"
      ],
      "abstract": "CT report generation (CTRG) aims to automatically generate diagnostic reports\nfor 3D volumes, relieving clinicians' workload and improving patient care.\nDespite clinical value, existing works fail to effectively incorporate\ndiagnostic information from multiple anatomical views and lack related clinical\nexpertise essential for accurate and reliable diagnosis. To resolve these\nlimitations, we propose a novel Multi-view perception Knowledge-enhanced\nTransformer (MvKeTR) to mimic the diagnostic workflow of clinicians. Just as\nradiologists first examine CT scans from multiple planes, a Multi-View\nPerception Aggregator (MVPA) with view-aware attention effectively synthesizes\ndiagnostic information from multiple anatomical views. Then, inspired by how\nradiologists further refer to relevant clinical records to guide diagnostic\ndecision-making, a Cross-Modal Knowledge Enhancer (CMKE) retrieves the most\nsimilar reports based on the query volume to incorporate domain knowledge into\nthe diagnosis procedure. Furthermore, instead of traditional MLPs, we employ\nKolmogorov-Arnold Networks (KANs) with learnable nonlinear activation functions\nas the fundamental building blocks of both modules to better capture intricate\ndiagnostic patterns in CT interpretation. Extensive experiments on the public\nCTRG-Chest-548K dataset demonstrate that our method outpaces prior\nstate-of-the-art (SOTA) models across almost all metrics. The code will be made\npublicly available.",
      "tldr_zh": "该研究提出了一种新型模型 MvKeTR，用于胸部 CT 报告生成（CTRG），旨在通过多视图感知和知识增强来模拟临床医生的诊断流程。模型包括 Multi-View Perception Aggregator (MVPA)，它利用视图感知注意力从多个解剖视图合成诊断信息，以及 Cross-Modal Knowledge Enhancer (CMKE)，通过检索相似报告将领域知识融入诊断决策中。此外，MvKeTR 采用 Kolmogorov-Arnold Networks (KANs) 作为基本构建块，以更好地捕捉 CT 解释中的复杂模式。在公开数据集 CTRG-Chest-548K 上，实验结果显示该方法在几乎所有指标上超过了现有 SOTA 模型。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "11 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.18309v2",
      "published_date": "2024-11-27 12:58:23 UTC",
      "updated_date": "2025-01-06 10:34:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T05:02:28.898518"
    },
    {
      "arxiv_id": "2411.18305v1",
      "title": "Application of Soft Actor-Critic Algorithms in Optimizing Wastewater Treatment with Time Delays Integration",
      "title_zh": "Soft Actor-Critic 算法在废水处理优化中的应用：整合时间延迟",
      "authors": [
        "Esmaeel Mohammadi",
        "Daniel Ortiz-Arroyo",
        "Aviaja Anna Hansen",
        "Mikkel Stokholm-Bjerregaard",
        "Sebastien Gros",
        "Akhil S Anand",
        "Petar Durdevic"
      ],
      "abstract": "Wastewater treatment plants face unique challenges for process control due to\ntheir complex dynamics, slow time constants, and stochastic delays in\nobservations and actions. These characteristics make conventional control\nmethods, such as Proportional-Integral-Derivative controllers, suboptimal for\nachieving efficient phosphorus removal, a critical component of wastewater\ntreatment to ensure environmental sustainability. This study addresses these\nchallenges using a novel deep reinforcement learning approach based on the Soft\nActor-Critic algorithm, integrated with a custom simulator designed to model\nthe delayed feedback inherent in wastewater treatment plants. The simulator\nincorporates Long Short-Term Memory networks for accurate multi-step state\npredictions, enabling realistic training scenarios. To account for the\nstochastic nature of delays, agents were trained under three delay scenarios:\nno delay, constant delay, and random delay. The results demonstrate that\nincorporating random delays into the reinforcement learning framework\nsignificantly improves phosphorus removal efficiency while reducing operational\ncosts. Specifically, the delay-aware agent achieved 36% reduction in phosphorus\nemissions, 55% higher reward, 77% lower target deviation from the regulatory\nlimit, and 9% lower total costs than traditional control methods in the\nsimulated environment. These findings underscore the potential of reinforcement\nlearning to overcome the limitations of conventional control strategies in\nwastewater treatment, providing an adaptive and cost-effective solution for\nphosphorus removal.",
      "tldr_zh": "本研究探讨了Soft Actor-Critic算法在污水处理优化中的应用，针对污水处理厂的复杂动态、慢时间常量和随机延迟问题，提出了一种整合延迟反馈的深度强化学习方法。研究使用自定义模拟器结合LSTM网络进行多步状态预测，并在无延迟、常量延迟和随机延迟三种场景下训练代理。结果表明，处理随机延迟的代理相比传统控制方法（如PID控制器），实现了磷排放减少36%、奖励提高55%、目标偏差降低77%和总成本减少9%，为污水处理提供了一种适应性强且成本有效的解决方案。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.LG",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.18305v1",
      "published_date": "2024-11-27 12:52:48 UTC",
      "updated_date": "2024-11-27 12:52:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T05:02:40.795756"
    },
    {
      "arxiv_id": "2412.00091v2",
      "title": "Graph Canvas for Controllable 3D Scene Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Libin Liu",
        "Shen Chen",
        "Sen Jia",
        "Jingzhe Shi",
        "Zhongyu Jiang",
        "Can Jin",
        "Wu Zongkai",
        "Jenq-Neng Hwang",
        "Lei Li"
      ],
      "abstract": "Spatial intelligence is foundational to AI systems that interact with the\nphysical world, particularly in 3D scene generation and spatial comprehension.\nCurrent methodologies for 3D scene generation often rely heavily on predefined\ndatasets, and struggle to adapt dynamically to changing spatial relationships.\nIn this paper, we introduce GraphCanvas3D, a programmable, extensible, and\nadaptable framework for controllable 3D scene generation. Leveraging in-context\nlearning, GraphCanvas3D enables dynamic adaptability without the need for\nretraining, supporting flexible and customizable scene creation. Our framework\nemploys hierarchical, graph-driven scene descriptions, representing spatial\nelements as graph nodes and establishing coherent relationships among objects\nin 3D environments. Unlike conventional approaches, which are constrained in\nadaptability and often require predefined input masks or retraining for\nmodifications, GraphCanvas3D allows for seamless object manipulation and scene\nadjustments on the fly. Additionally, GraphCanvas3D supports 4D scene\ngeneration, incorporating temporal dynamics to model changes over time.\nExperimental results and user studies demonstrate that GraphCanvas3D enhances\nusability, flexibility, and adaptability for scene generation. Our code and\nmodels are available on the project website:\nhttps://github.com/ILGLJ/Graph-Canvas.",
      "tldr_zh": "本论文引入GraphCanvas3D，一种可编程、可扩展的框架，用于实现可控的3D场景生成，旨在解决现有方法依赖预定义数据集且无法动态适应空间关系的问题。该框架利用in-context learning进行动态适应，无需重新训练，并采用分层图驱动的场景描述，将空间元素作为图节点来建立3D环境中的对象关系。与传统方法相比，GraphCanvas3D支持即时对象操作、场景调整以及4D场景生成，包括时间动态。实验结果和用户研究证明，该框架显著提升了场景生成的可用性、灵活性和适应性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.00091v2",
      "published_date": "2024-11-27 12:41:23 UTC",
      "updated_date": "2024-12-06 02:26:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T05:02:52.451151"
    },
    {
      "arxiv_id": "2411.18294v1",
      "title": "Aligning Pre-trained Models for Spoken Language Translation",
      "title_zh": "翻译失败",
      "authors": [
        "Šimon Sedláček",
        "Santosh Kesiraju",
        "Alexander Polok",
        "Jan Černocký"
      ],
      "abstract": "This paper investigates a novel approach to end-to-end speech translation\n(ST) based on aligning frozen pre-trained automatic speech recognition (ASR)\nand machine translation (MT) models via a small connector module (Q-Former, our\nSubsampler-Transformer Encoder). This connector bridges the gap between the\nspeech and text modalities, transforming ASR encoder embeddings into the latent\nrepresentation space of the MT encoder while being the only part of the system\noptimized during training. Experiments are conducted on the How2\nEnglish-Portuguese dataset as we investigate the alignment approach in a\nsmall-scale scenario focusing on ST. While keeping the size of the connector\nmodule constant and small in comparison ( < 5% of the size of the larger\naligned models), increasing the size and capability of the foundation ASR and\nMT models universally improves translation results. We also find that the\nconnectors can serve as domain adapters for the foundation MT models,\nsignificantly improving translation performance in the aligned ST setting. We\nconclude that this approach represents a viable and scalable approach to\ntraining end-to-end ST systems.",
      "tldr_zh": "本论文提出了一种新方法，用于端到端的语音翻译 (ST)，通过一个小型连接器模块 (Q-Former 或 Subsampler-Transformer Encoder) 对齐冻结的预训练 ASR (自动语音识别) 和 MT (机器翻译) 模型，使 ASR 编码器的嵌入转化为 MT 编码器的潜在表示空间，而仅优化连接器模块。实验在 How2 英语-葡萄牙语数据集上进行，结果显示，保持连接器模块较小 (小于对齐模型的 5%) 时，增加 ASR 和 MT 模型的大小和能力可普遍提升翻译性能，且连接器可作为领域适配器，显著改善 ST 设置中的翻译效果。该方法被证明是一种可行且可扩展的端到端 ST 系统训练策略。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.18294v1",
      "published_date": "2024-11-27 12:32:41 UTC",
      "updated_date": "2024-11-27 12:32:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T05:03:04.639871"
    },
    {
      "arxiv_id": "2411.18286v1",
      "title": "DualCast: Disentangling Aperiodic Events from Traffic Series with a Dual-Branch Model",
      "title_zh": "DualCast：使用双分支模型从交通序列中分离非周期事件",
      "authors": [
        "Xinyu Su",
        "Feng Liu",
        "Yanchuan Chang",
        "Egemen Tanin",
        "Majid Sarvi",
        "Jianzhong Qi"
      ],
      "abstract": "Traffic forecasting is an important problem in the operation and optimisation\nof transportation systems. State-of-the-art solutions train machine learning\nmodels by minimising the mean forecasting errors on the training data. The\ntrained models often favour periodic events instead of aperiodic ones in their\nprediction results, as periodic events often prevail in the training data.\nWhile offering critical optimisation opportunities, aperiodic events such as\ntraffic incidents may be missed by the existing models. To address this issue,\nwe propose DualCast -- a model framework to enhance the learning capability of\ntraffic forecasting models, especially for aperiodic events. DualCast takes a\ndual-branch architecture, to disentangle traffic signals into two types, one\nreflecting intrinsic {spatial-temporal} patterns and the other reflecting\nexternal environment contexts including aperiodic events. We further propose a\ncross-time attention mechanism, to capture high-order spatial-temporal\nrelationships from both periodic and aperiodic patterns. DualCast is versatile.\nWe integrate it with recent traffic forecasting models, consistently reducing\ntheir forecasting errors by up to 9.6% on multiple real datasets.",
      "tldr_zh": "该论文针对交通预测中现有模型偏向周期性事件而忽略aperiodic events（如交通事故）的问题，提出DualCast框架，以提升模型对非周期性事件的预测能力。DualCast采用dual-branch architecture，将交通信号分解为内在的spatial-temporal模式和外部环境上下文两部分，并引入cross-time attention机制来捕捉周期性和非周期性模式的高阶时空关系。该框架可与现有模型无缝集成，在多个真实数据集上，将预测错误降低高达9.6%。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.18286v1",
      "published_date": "2024-11-27 12:17:50 UTC",
      "updated_date": "2024-11-27 12:17:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T05:03:16.500220"
    },
    {
      "arxiv_id": "2411.18279v12",
      "title": "Large Language Model-Brained GUI Agents: A Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Chaoyun Zhang",
        "Shilin He",
        "Jiaxu Qian",
        "Bowen Li",
        "Liqun Li",
        "Si Qin",
        "Yu Kang",
        "Minghua Ma",
        "Guyue Liu",
        "Qingwei Lin",
        "Saravan Rajmohan",
        "Dongmei Zhang",
        "Qi Zhang"
      ],
      "abstract": "GUIs have long been central to human-computer interaction, providing an\nintuitive and visually-driven way to access and interact with digital systems.\nThe advent of LLMs, particularly multimodal models, has ushered in a new era of\nGUI automation. They have demonstrated exceptional capabilities in natural\nlanguage understanding, code generation, and visual processing. This has paved\nthe way for a new generation of LLM-brained GUI agents capable of interpreting\ncomplex GUI elements and autonomously executing actions based on natural\nlanguage instructions. These agents represent a paradigm shift, enabling users\nto perform intricate, multi-step tasks through simple conversational commands.\nTheir applications span across web navigation, mobile app interactions, and\ndesktop automation, offering a transformative user experience that\nrevolutionizes how individuals interact with software. This emerging field is\nrapidly advancing, with significant progress in both research and industry.\n  To provide a structured understanding of this trend, this paper presents a\ncomprehensive survey of LLM-brained GUI agents, exploring their historical\nevolution, core components, and advanced techniques. We address research\nquestions such as existing GUI agent frameworks, the collection and utilization\nof data for training specialized GUI agents, the development of large action\nmodels tailored for GUI tasks, and the evaluation metrics and benchmarks\nnecessary to assess their effectiveness. Additionally, we examine emerging\napplications powered by these agents. Through a detailed analysis, this survey\nidentifies key research gaps and outlines a roadmap for future advancements in\nthe field. By consolidating foundational knowledge and state-of-the-art\ndevelopments, this work aims to guide both researchers and practitioners in\novercoming challenges and unlocking the full potential of LLM-brained GUI\nagents.",
      "tldr_zh": "这篇调查论文探讨了Large Language Models (LLMs)驱动的GUI Agents的发展，这些代理利用LLMs的多模态能力（如自然语言理解、代码生成和视觉处理），能够解释复杂GUI元素并基于自然语言指令自主执行多步任务。论文回顾了该领域的历史演变、核心组件（如框架设计和数据利用）、高级技术（如大型动作模型的开发），并讨论了评估指标、基准测试以及新兴应用，如网络导航和移动App交互。最终，该研究识别了关键研究空白，并为未来LLM-brained GUI Agents的优化和应用提供路线图，以提升用户交互体验和软件自动化潜力。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "The collection of papers reviewed in this survey will be hosted and\n  regularly updated on the GitHub repository:\n  https://github.com/vyokky/LLM-Brained-GUI-Agents-Survey Additionally, a\n  searchable webpage is available at https://aka.ms/gui-agent for easier access\n  and exploration",
      "pdf_url": "http://arxiv.org/pdf/2411.18279v12",
      "published_date": "2024-11-27 12:13:39 UTC",
      "updated_date": "2025-05-06 15:08:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T05:03:28.666161"
    },
    {
      "arxiv_id": "2411.18276v2",
      "title": "GAPartManip: A Large-scale Part-centric Dataset for Material-Agnostic Articulated Object Manipulation",
      "title_zh": "翻译失败",
      "authors": [
        "Wenbo Cui",
        "Chengyang Zhao",
        "Songlin Wei",
        "Jiazhao Zhang",
        "Haoran Geng",
        "Yaran Chen",
        "Haoran Li",
        "He Wang"
      ],
      "abstract": "Effectively manipulating articulated objects in household scenarios is a\ncrucial step toward achieving general embodied artificial intelligence.\nMainstream research in 3D vision has primarily focused on manipulation through\ndepth perception and pose detection. However, in real-world environments, these\nmethods often face challenges due to imperfect depth perception, such as with\ntransparent lids and reflective handles. Moreover, they generally lack the\ndiversity in part-based interactions required for flexible and adaptable\nmanipulation. To address these challenges, we introduced a large-scale\npart-centric dataset for articulated object manipulation that features both\nphoto-realistic material randomization and detailed annotations of\npart-oriented, scene-level actionable interaction poses. We evaluated the\neffectiveness of our dataset by integrating it with several state-of-the-art\nmethods for depth estimation and interaction pose prediction. Additionally, we\nproposed a novel modular framework that delivers superior and robust\nperformance for generalizable articulated object manipulation. Our extensive\nexperiments demonstrate that our dataset significantly improves the performance\nof depth perception and actionable interaction pose prediction in both\nsimulation and real-world scenarios. More information and demos can be found\nat: https://pku-epic.github.io/GAPartManip/.",
      "tldr_zh": "本论文引入了GAPartManip，一个大规模、以零件为中心的数据集，旨在解决3D vision中深度感知和姿态检测的局限性，例如处理透明盖子和反光把手等真实环境挑战。数据集包含真实照片级别的材料随机化和详细的零件导向、场景级可操作互动姿态注释，支持灵活的铰接物体操作。该数据集与现有深度估计和互动姿态预测方法整合后，显著提升了性能；此外，论文提出一个新型模块化框架，在模拟和真实场景中实现了更鲁棒的通用铰接物体操作。实验结果显示，性能改善明显，为家用场景的embodied artificial intelligence提供了关键支持。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted by ICRA 2025. Project page:\n  https://pku-epic.github.io/GAPartManip/",
      "pdf_url": "http://arxiv.org/pdf/2411.18276v2",
      "published_date": "2024-11-27 12:11:23 UTC",
      "updated_date": "2025-03-21 07:52:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T05:03:40.495883"
    },
    {
      "arxiv_id": "2411.18266v3",
      "title": "Wearable intelligent throat enables natural speech in stroke patients with dysarthria",
      "title_zh": "翻译失败",
      "authors": [
        "Chenyu Tang",
        "Shuo Gao",
        "Cong Li",
        "Wentian Yi",
        "Yuxuan Jin",
        "Xiaoxue Zhai",
        "Sixuan Lei",
        "Hongbei Meng",
        "Zibo Zhang",
        "Muzi Xu",
        "Shengbo Wang",
        "Xuhang Chen",
        "Chenxi Wang",
        "Hongyun Yang",
        "Ningli Wang",
        "Wenyu Wang",
        "Jin Cao",
        "Xiaodong Feng",
        "Peter Smielewski",
        "Yu Pan",
        "Wenhui Song",
        "Martin Birchall",
        "Luigi G. Occhipinti"
      ],
      "abstract": "Wearable silent speech systems hold significant potential for restoring\ncommunication in patients with speech impairments. However, seamless, coherent\nspeech remains elusive, and clinical efficacy is still unproven. Here, we\npresent an AI-driven intelligent throat (IT) system that integrates throat\nmuscle vibrations and carotid pulse signal sensors with large language model\n(LLM) processing to enable fluent, emotionally expressive communication. The\nsystem utilizes ultrasensitive textile strain sensors to capture high-quality\nsignals from the neck area and supports token-level processing for real-time,\ncontinuous speech decoding, enabling seamless, delay-free communication. In\ntests with five stroke patients with dysarthria, IT's LLM agents intelligently\ncorrected token errors and enriched sentence-level emotional and logical\ncoherence, achieving low error rates (4.2% word error rate, 2.9% sentence error\nrate) and a 55% increase in user satisfaction. This work establishes a\nportable, intuitive communication platform for patients with dysarthria with\nthe potential to be applied broadly across different neurological conditions\nand in multi-language support systems.",
      "tldr_zh": "本研究开发了一种AI驱动的智能喉(IT)系统，结合喉部肌肉振动和颈动脉脉冲信号传感器与大型语言模型(LLM)，帮助中风患者实现流畅、情感丰富的自然语音沟通。该系统使用超敏感纺织应变传感器捕获实时信号，支持令牌级处理，以纠正错误并提升句子逻辑和情感连贯性。在五名中风患者测试中，IT系统实现了低错误率（4.2% word error rate，2.9% sentence error rate），并使用户满意度提高55%。这项便携式平台具有广阔应用潜力，可扩展到其他神经病变患者和多语言支持系统。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.SD",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "eess.AS",
      "comment": "5 figures, 45 references",
      "pdf_url": "http://arxiv.org/pdf/2411.18266v3",
      "published_date": "2024-11-27 12:03:52 UTC",
      "updated_date": "2025-03-14 09:14:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T05:03:54.046956"
    },
    {
      "arxiv_id": "2411.18253v1",
      "title": "Multimodal Integration of Longitudinal Noninvasive Diagnostics for Survival Prediction in Immunotherapy Using Deep Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Melda Yeghaian",
        "Zuhir Bodalal",
        "Daan van den Broek",
        "John B A G Haanen",
        "Regina G H Beets-Tan",
        "Stefano Trebeschi",
        "Marcel A J van Gerven"
      ],
      "abstract": "Purpose: Analyzing noninvasive longitudinal and multimodal data using\nartificial intelligence could potentially transform immunotherapy for cancer\npatients, paving the way towards precision medicine. Methods: In this study, we\nintegrated pre- and on-treatment blood measurements, prescribed medications and\nCT-based volumes of organs from a large pan-cancer cohort of 694 patients\ntreated with immunotherapy to predict short and long-term overall survival. By\nleveraging a combination of recent developments, different variants of our\nextended multimodal transformer-based simple temporal attention (MMTSimTA)\nnetwork were trained end-to-end to predict mortality at three, six, nine and\ntwelve months. These models were also compared to baseline methods\nincorporating intermediate and late fusion based integration methods. Results:\nThe strongest prognostic performance was demonstrated using the extended\ntransformer-based multimodal model with area under the curves (AUCs) of $0.84\n\\pm $0.04, $0.83 \\pm $0.02, $0.82 \\pm $0.02, $0.81 \\pm $0.03 for 3-, 6-, 9-,\nand 12-month survival prediction, respectively. Conclusion: Our findings\nsuggest that analyzing integrated early treatment data has potential for\npredicting survival of immunotherapy patients. Integrating complementary\nnoninvasive modalities into a jointly trained model, using our extended\ntransformer-based architecture, demonstrated an improved multimodal prognostic\nperformance, especially in short term survival prediction.",
      "tldr_zh": "这篇论文提出了一种深度学习方法，通过整合纵向非侵入性诊断数据（如治疗前后的血液测量、处方药物和 CT 图像器官体积），来预测免疫治疗癌症患者的整体生存率。研究使用扩展的多模态 Transformer-based Simple Temporal Attention (MMTSimTA) 网络变体，对 694 名患者的资料进行端到端训练，预测 3、6、9 和 12 个月的死亡率，并与基线融合方法进行比较。结果显示，该模型在生存预测中表现出色，AUC 值分别为 0.84 ± 0.04、0.83 ± 0.02、0.82 ± 0.02 和 0.81 ± 0.03，尤其在短期预测中优于基线方法。该方法证明了整合多模态数据有助于提升免疫治疗的精准医学潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.QM"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.18253v1",
      "published_date": "2024-11-27 11:44:06 UTC",
      "updated_date": "2024-11-27 11:44:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T05:04:06.233209"
    },
    {
      "arxiv_id": "2411.18250v1",
      "title": "IKUN: Initialization to Keep snn training and generalization great with sUrrogate-stable variaNce",
      "title_zh": "翻译失败",
      "authors": [
        "Da Chang",
        "Deliang Wang",
        "Xiao Yang"
      ],
      "abstract": "Weight initialization significantly impacts the convergence and performance\nof neural networks. While traditional methods like Xavier and Kaiming\ninitialization are widely used, they often fall short for spiking neural\nnetworks (SNNs), which have distinct requirements compared to artificial neural\nnetworks (ANNs).\n  To address this, we introduce \\textbf{IKUN}, a variance-stabilizing\ninitialization method integrated with surrogate gradient functions,\nspecifically designed for SNNs. \\textbf{IKUN} stabilizes signal propagation,\naccelerates convergence, and enhances generalization. Experiments show\n\\textbf{IKUN} improves training efficiency by up to \\textbf{50\\%}, achieving\n\\textbf{95\\%} training accuracy and \\textbf{91\\%} generalization accuracy.\n  Hessian analysis reveals that \\textbf{IKUN}-trained models converge to\nflatter minima, characterized by Hessian eigenvalues near zero on the positive\nside, promoting better generalization. The method is open-sourced for further\nexploration:\n\\href{https://github.com/MaeChd/SurrogateVarStabe}{https://github.com/MaeChd/SurrogateVarStabe}.",
      "tldr_zh": "本研究提出了一种名为 IKUN 的权重初始化方法，旨在解决传统初始化如 Xavier 和 Kaiming 在脉冲神经网络 (SNNs) 中的不足，通过整合代理梯度函数 (surrogate gradient functions) 稳定方差、加速收敛并提升泛化性能。IKUN 通过稳定信号传播，帮助 SNNs 模型在实验中提高训练效率达 50%，实现 95% 的训练准确率和 91% 的泛化准确率。Hessian 分析进一步显示，IKUN 训练的模型收敛到更平坦的极小值（特征值为正侧接近零），从而促进更好的泛化能力，该方法已开源以供进一步探索。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.18250v1",
      "published_date": "2024-11-27 11:41:11 UTC",
      "updated_date": "2024-11-27 11:41:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T05:04:16.348115"
    },
    {
      "arxiv_id": "2411.18242v1",
      "title": "Thai Financial Domain Adaptation of THaLLE -- Technical Report",
      "title_zh": "翻译失败",
      "authors": [
        "KBTG Labs",
        "Atthakorn Petchsod",
        "Pornchanan Balee",
        "Danupat Khamnuansin",
        "Anuruth Lertpiya",
        "Chanatip Saetia",
        "Tawunrat Chalothorn",
        "Thadpong Pongthawornkamol",
        "Monchai Lertsutthiwong"
      ],
      "abstract": "Large Language Models (LLMs) excel in general tasks but struggle with\ndomain-specific challenges, such as specialized terminology and localized\nregulations. Existing financial LLMs, like FinGPT and BloombergGPT, lack\nsupport for the Thai financial domain. We developed a Thai Financial LLM using\nthe Investment Consultant (IC) exam dataset from the Stock Exchange of\nThailand. To address dataset limitations, we applied data augmentation, ReLoRA\nfor efficient training, Continued Pretraining (CPT) for domain knowledge, and\nRank-Stabilized LoRA (rsLoRA) for fine-tuning. Supervised Fine-Tuning (SFT)\nsimulated exam scenarios, while Direct Preference Optimization (DPO) refined\nthe model using feedback. The model achieved scores of 72%, 72%, and 84% on IC\nexam levels P1, P2, and P3, respectively, demonstrating its effectiveness in\nThai financial advisory tasks and its potential for specialized applications.",
      "tldr_zh": "本研究针对大型语言模型（LLMs）在泰国金融领域的适应挑战，开发了THaLLE的金融版本，使用泰国证券交易所的Investment Consultant (IC) exam数据集作为基础。研究团队应用数据增强、ReLoRA、Continued Pretraining (CPT)、Rank-Stabilized LoRA (rsLoRA)、Supervised Fine-Tuning (SFT) 和Direct Preference Optimization (DPO) 等技术进行高效训练和优化，以提升模型对专业术语和本地法规的处理能力。最终，模型在IC考试P1、P2和P3上分别获得72%、72%和84%的分数，展示了其在泰国金融咨询任务中的显著有效性和潜在应用价值。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.18242v1",
      "published_date": "2024-11-27 11:30:00 UTC",
      "updated_date": "2024-11-27 11:30:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T05:04:29.420738"
    },
    {
      "arxiv_id": "2411.18241v1",
      "title": "Exploration of LLM Multi-Agent Application Implementation Based on LangGraph+CrewAI",
      "title_zh": "基于 LangGraph+CrewAI 的 LLM 多智能体应用实现探索",
      "authors": [
        "Zhihua Duan",
        "Jialin Wang"
      ],
      "abstract": "With the rapid development of large model technology, the application of\nagent technology in various fields is becoming increasingly widespread,\nprofoundly changing people's work and lifestyles. In complex and dynamic\nsystems, multi-agents achieve complex tasks that are difficult for a single\nagent to complete through division of labor and collaboration among agents.\nThis paper discusses the integrated application of LangGraph and CrewAI.\nLangGraph improves the efficiency of information transmission through graph\narchitecture, while CrewAI enhances team collaboration capabilities and system\nperformance through intelligent task allocation and resource management. The\nmain research contents of this paper are: (1) designing the architecture of\nagents based on LangGraph for precise control; (2) enhancing the capabilities\nof agents based on CrewAI to complete a variety of tasks. This study aims to\ndelve into the application of LangGraph and CrewAI in multi-agent systems,\nproviding new perspectives for the future development of agent technology, and\npromoting technological progress and application innovation in the field of\nlarge model intelligent agents.",
      "tldr_zh": "这篇论文探讨了基于 LangGraph 和 CrewAI 的 LLM 多智能体应用实现，旨在通过代理间的分工协作处理复杂任务。研究重点包括利用 LangGraph 的图结构设计代理架构，以提升信息传输效率和精确控制；以及借助 CrewAI 的智能任务分配和资源管理，增强代理的协作能力和系统性能。该工作为多智能体系统提供了新视角，推动 LLM 智能代理领域的技术创新和应用发展。",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.18241v1",
      "published_date": "2024-11-27 11:29:17 UTC",
      "updated_date": "2024-11-27 11:29:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T05:04:39.843288"
    },
    {
      "arxiv_id": "2411.18235v1",
      "title": "Certified Training with Branch-and-Bound: A Case Study on Lyapunov-stable Neural Control",
      "title_zh": "基于分支定界的认证训练：李亚普诺夫稳定神经控制的一个案例研究",
      "authors": [
        "Zhouxing Shi",
        "Cho-Jui Hsieh",
        "Huan Zhang"
      ],
      "abstract": "We study the problem of learning Lyapunov-stable neural controllers which\nprovably satisfy the Lyapunov asymptotic stability condition within a\nregion-of-attraction. Compared to previous works which commonly used\ncounterexample guided training on this task, we develop a new and generally\nformulated certified training framework named CT-BaB, and we optimize for\ndifferentiable verified bounds, to produce verification-friendly models. In\norder to handle the relatively large region-of-interest, we propose a novel\nframework of training-time branch-and-bound to dynamically maintain a training\ndataset of subregions throughout training, such that the hardest subregions are\niteratively split into smaller ones whose verified bounds can be computed more\ntightly to ease the training. We demonstrate that our new training framework\ncan produce models which can be more efficiently verified at test time. On the\nlargest 2D quadrotor dynamical system, verification for our model is more than\n5X faster compared to the baseline, while our size of region-of-attraction is\n16X larger than the baseline.",
      "tldr_zh": "本研究针对学习 Lyapunov-stable 神经控制器的问题，提出了一种新的认证训练框架 CT-BaB，通过优化可微验证边界来生成易于验证的模型。\n该框架引入训练时的 branch-and-bound 方法，动态维护训练数据集的子区域，迭代地将最难子区域分割为更小部分，以更精确地计算验证边界。\n实验结果表明，在最大的 2D 四旋翼动态系统中，该方法使模型验证速度比基线提高 5 倍以上，同时吸引区域大小扩大 16 倍。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "Preprint",
      "pdf_url": "http://arxiv.org/pdf/2411.18235v1",
      "published_date": "2024-11-27 11:12:46 UTC",
      "updated_date": "2024-11-27 11:12:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T05:04:52.986735"
    },
    {
      "arxiv_id": "2411.18234v1",
      "title": "Randomized-Grid Search for Hyperparameter Tuning in Decision Tree Model to Improve Performance of Cardiovascular Disease Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Abhay Kumar Pathak",
        "Mrityunjay Chaubey",
        "Manjari Gupta"
      ],
      "abstract": "Cardiovascular disease refers to any critical condition that impacts the\nheart. Because heart diseases can be life-threatening. Researchers are focusing\non designing smart systems to accurately diagnose them based on electronic\nhealth data, with the aid of machine learning algorithms. Heart disease\nclassification using machine learning (ML) algorithms such as Support Vector\nMachine(SVM), Na\\\"ive Bayes(NB), Decision Trees (DTs) and Random Forests (RFs)\nare often hindered by overfitting. These ML algorithms need extensive\nhyperparameter tuning. Random Search offers a faster, and, more efficient\nexploration of hyperparameter space, but, it may overlook optimal regions. Grid\nSearch, though exhaustive, but, it is computationally expensive and\ninefficient, particularly with high-dimensional data. To address these\nlimitations, Randomized-Grid Search, a novel hybrid optimization method is\nproposed that combines the global exploration strengths of Random Search with\nthe focused, and, exhaustive search of Grid Search in the most promising\nregions. This hybrid approach efficiently balances exploration and\nexploitation. The proposed model optimizes the hyperparameter for Decision Tree\nmodel. The proposed model is applied to UCI heart disease dataset for\nclassification. It enhances model performance, provides improved accuracy,\ngeneralization, and computational efficiency. Experimental results demonstrate\nthat Randomized-Grid Search outperforms traditional methods by significant\nmargins. The proposed model provides a more effective solution for machine\nlearning applications in healthcare diagnosis.",
      "tldr_zh": "该研究针对心血管疾病分类问题，提出了一种新型混合优化方法——Randomized-Grid Search，将Random Search的全局探索优势与Grid Search的详尽搜索相结合，以高效调优Decision Tree模型的超参数，解决传统算法的过拟合和计算效率问题。方法应用于UCI心血管疾病数据集，通过平衡探索与利用，提升了模型的准确性、泛化能力和计算效率。实验结果显示，该方法显著优于传统方法，为医疗诊断中的机器学习应用提供了更有效的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.PF",
        "stat.CO"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.18234v1",
      "published_date": "2024-11-27 11:10:28 UTC",
      "updated_date": "2024-11-27 11:10:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T05:05:04.903768"
    },
    {
      "arxiv_id": "2411.18230v1",
      "title": "Dependency-Aware CAV Task Scheduling via Diffusion-Based Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Xiang Cheng",
        "Zhi Mao",
        "Ying Wang",
        "Wen Wu"
      ],
      "abstract": "In this paper, we propose a novel dependency-aware task scheduling strategy\nfor dynamic unmanned aerial vehicle-assisted connected autonomous vehicles\n(CAVs). Specifically, different computation tasks of CAVs consisting of\nmultiple dependency subtasks are judiciously assigned to nearby CAVs or the\nbase station for promptly completing tasks. Therefore, we formulate a joint\nscheduling priority and subtask assignment optimization problem with the\nobjective of minimizing the average task completion time. The problem aims at\nimproving the long-term system performance, which is reformulated as a Markov\ndecision process. To solve the problem, we further propose a diffusion-based\nreinforcement learning algorithm, named Synthetic DDQN based Subtasks\nScheduling, which can make adaptive task scheduling decision in real time. A\ndiffusion model-based synthetic experience replay is integrated into the\nreinforcement learning framework, which can generate sufficient synthetic data\nin experience replay buffer, thereby significantly accelerating convergence and\nimproving sample efficiency. Simulation results demonstrate the effectiveness\nof the proposed algorithm on reducing task completion time, comparing to\nbenchmark schemes.",
      "tldr_zh": "本文提出了一种依赖感知任务调度策略，用于动态无人机辅助的连接自主车辆(CAVs)，通过优化子任务分配和优先级来最小化平均任务完成时间，并将问题转化为Markov决策过程(MDP)。该策略采用Synthetic DDQN based Subtasks Scheduling算法，这是一种基于扩散的强化学习方法，整合扩散模型-based synthetic experience replay生成合成数据，以加速收敛和提升样本效率。模拟结果表明，该算法相较于基准方案显著降低了任务完成时间，提高了系统整体性能。",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "6 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.18230v1",
      "published_date": "2024-11-27 11:07:31 UTC",
      "updated_date": "2024-11-27 11:07:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T05:05:17.047124"
    },
    {
      "arxiv_id": "2411.18226v1",
      "title": "Feature-Factory: Automating Software Feature Integration Using Generative AI",
      "title_zh": "翻译失败",
      "authors": [
        "Ruslan Idelfonso Magana Vsevolodovna"
      ],
      "abstract": "Integrating new features into existing software projects can be a complex and\ntime-consuming process. Feature-Factory leverages Generative AI with WatsonX.ai\nto automate the analysis, planning, and implementation of feature requests. By\ncombining advanced project parsing, dependency resolution, and AI-generated\ncode, the program ensures seamless integration of features into software\nsystems while maintaining structural integrity. This paper presents the\nmethodology, mathematical model, and results of the Feature-Factory framework.",
      "tldr_zh": "该论文提出了一种名为 Feature-Factory 的框架，利用 Generative AI 和 WatsonX.ai 自动化软件特征集成的过程，包括特征请求的分析、规划和实现。框架结合高级项目解析、依赖 resolution 和 AI 生成代码，确保新特征无缝集成到现有软件系统中，同时维护结构完整性。研究呈现了 Feature-Factory 的方法论、数理模型，并展示了其在简化软件开发流程方面的有效性。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG",
        "cs.MA",
        "68T05, 68N01, 68N30, 68Q25",
        "D.2.3; I.2.2; D.2.7; D.2.9; I.2.7"
      ],
      "primary_category": "cs.SE",
      "comment": "14 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2411.18226v1",
      "published_date": "2024-11-27 11:03:47 UTC",
      "updated_date": "2024-11-27 11:03:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T05:05:26.830807"
    },
    {
      "arxiv_id": "2411.18225v1",
      "title": "PATHS: A Hierarchical Transformer for Efficient Whole Slide Image Analysis",
      "title_zh": "PATHS：一种用于高效全滑片图像分析的分层Transformer",
      "authors": [
        "Zak Buzzard",
        "Konstantin Hemker",
        "Nikola Simidjievski",
        "Mateja Jamnik"
      ],
      "abstract": "Computational analysis of whole slide images (WSIs) has seen significant\nresearch progress in recent years, with applications ranging across important\ndiagnostic and prognostic tasks such as survival or cancer subtype prediction.\nMany state-of-the-art models process the entire slide - which may be as large\nas $150,000 \\times 150,000$ pixels - as a bag of many patches, the size of\nwhich necessitates computationally cheap feature aggregation methods. However,\na large proportion of these patches are uninformative, such as those containing\nonly healthy or adipose tissue, adding significant noise and size to the bag.\nWe propose Pathology Transformer with Hierarchical Selection (PATHS), a novel\ntop-down method for hierarchical weakly supervised representation learning on\nslide-level tasks in computational pathology. PATHS is inspired by the\ncross-magnification manner in which a human pathologist examines a slide,\nrecursively filtering patches at each magnification level to a small subset\nrelevant to the diagnosis. Our method overcomes the complications of processing\nthe entire slide, enabling quadratic self-attention and providing a simple\ninterpretable measure of region importance. We apply PATHS to five datasets of\nThe Cancer Genome Atlas (TCGA), and achieve superior performance on slide-level\nprediction tasks when compared to previous methods, despite processing only a\nsmall proportion of the slide.",
      "tldr_zh": "该论文提出 PATHS（Pathology Transformer with Hierarchical Selection），一种高效的分层 Transformer 模型，用于处理 Whole Slide Image (WSI) 的计算分析。该方法模仿病理学家在不同放大倍率下的检查方式，通过自上而下的递归过滤，选取与诊断相关的补丁子集，从而克服处理大型幻灯片（如150,000 × 150,000 像素）的复杂性和噪声问题。PATHS 支持二次自注意力机制，并提供简单的区域重要性可解释性；在 The Cancer Genome Atlas (TCGA) 的五个数据集上，PATHS 在幻灯片级预测任务中比现有方法表现出色，尽管仅处理幻灯片的一小部分。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.18225v1",
      "published_date": "2024-11-27 11:03:38 UTC",
      "updated_date": "2024-11-27 11:03:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T05:05:41.382897"
    },
    {
      "arxiv_id": "2411.18220v3",
      "title": "R-MTLLMF: Resilient Multi-Task Large Language Model Fusion at the Wireless Edge",
      "title_zh": "翻译失败",
      "authors": [
        "Aladin Djuhera",
        "Vlad C. Andrei",
        "Mohsen Pourghasemian",
        "Haris Gacanin",
        "Holger Boche",
        "Walid Saad"
      ],
      "abstract": "Multi-task large language models (MTLLMs) are important for many applications\nat the wireless edge, where users demand specialized models to handle multiple\ntasks efficiently. However, training MTLLMs is complex and exhaustive,\nparticularly when tasks are subject to change. Recently, the concept of model\nfusion via task vectors has emerged as an efficient approach for combining\nfine-tuning parameters to produce an MTLLM. In this paper, the problem of\nenabling edge users to collaboratively craft such MTLMs via tasks vectors is\nstudied, under the assumption of worst-case adversarial attacks. To this end,\nfirst the influence of adversarial noise to multi-task model fusion is\ninvestigated and a relationship between the so-called weight disentanglement\nerror and the mean squared error (MSE) is derived. Using hypothesis testing, it\nis directly shown that the MSE increases interference between task vectors,\nthereby rendering model fusion ineffective. Then, a novel resilient MTLLM\nfusion (R-MTLLMF) is proposed, which leverages insights about the LLM\narchitecture and fine-tuning process to safeguard task vector aggregation under\nadversarial noise by realigning the MTLLM. The proposed R-MTLLMF is then\ncompared for both worst-case and ideal transmission scenarios to study the\nimpact of the wireless channel. Extensive model fusion experiments with vision\nLLMs demonstrate R-MTLLMF's effectiveness, achieving close-to-baseline\nperformance across eight different tasks in ideal noise scenarios and\nsignificantly outperforming unprotected model fusion in worst-case scenarios.\nThe results further advocate for additional physical layer protection for a\nholistic approach to resilience, from both a wireless and LLM perspective.",
      "tldr_zh": "该论文研究了在无线边缘环境中构建弹性多任务大型语言模型（MTLLMs）的挑战，特别是在面对最坏情况下的对抗性攻击时。作者分析了对抗性噪声对任务向量融合的影响，推导出权重解耦错误与均方误差（MSE）之间的关系，并证明MSE会增加任务向量间的干扰，导致模型融合失效。为解决此问题，提出了一种新型R-MTLLMF框架，利用LLM架构和微调过程的洞见来保护任务向量聚合和重新对齐模型。实验结果显示，R-MTLLMF在理想噪声场景下接近基线性能，在对抗性场景下显著优于无保护融合，并在八个视觉任务上验证了其有效性，最终强调需要结合物理层保护以实现整体弹性。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.18220v3",
      "published_date": "2024-11-27 10:57:06 UTC",
      "updated_date": "2025-02-21 12:44:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T05:05:53.824763"
    },
    {
      "arxiv_id": "2411.18212v1",
      "title": "SCoTT: Wireless-Aware Path Planning with Vision Language Models and Strategic Chains-of-Thought",
      "title_zh": "翻译失败",
      "authors": [
        "Aladin Djuhera",
        "Vlad C. Andrei",
        "Amin Seffo",
        "Holger Boche",
        "Walid Saad"
      ],
      "abstract": "Path planning is a complex problem for many practical applications,\nparticularly in robotics. Existing algorithms, however, are exhaustive in\nnature and become increasingly complex when additional side constraints are\nincorporated alongside distance minimization. In this paper, a novel approach\nusing vision language models (VLMs) is proposed for enabling path planning in\ncomplex wireless-aware environments. To this end, insights from a digital twin\n(DT) with real-world wireless ray tracing data are explored in order to\nguarantee an average path gain threshold while minimizing the trajectory\nlength. First, traditional approaches such as A* are compared to several\nwireless-aware extensions, and an optimal iterative dynamic programming\napproach (DP-WA*) is derived, which fully takes into account all path gains and\ndistance metrics within the DT. On the basis of these baselines, the role of\nVLMs as an alternative assistant for path planning is investigated, and a\nstrategic chain-of-thought tasking (SCoTT) approach is proposed. SCoTT divides\nthe complex planning task into several subproblems and solves each with\nadvanced CoT prompting. Results show that SCoTT achieves very close average\npath gains compared to DP-WA* while at the same time yielding consistently\nshorter path lengths. The results also show that VLMs can be used to accelerate\nDP-WA* by efficiently reducing the algorithm's search space and thus saving up\nto 62\\% in execution time. This work underscores the potential of VLMs in\nfuture digital systems as capable assistants for solving complex tasks, while\nenhancing user interaction and accelerating rapid prototyping under diverse\nwireless constraints.",
      "tldr_zh": "该论文提出了一种名为 SCoTT 的新方法，利用 Vision Language Models (VLMs) 和 Strategic Chains-of-Thought 来优化无线感知路径规划问题，尤其在复杂环境中兼顾路径增益和长度最小化。SCoTT 通过将任务分解成子问题，并结合数字孪生 (DT) 和无线射线追踪数据进行高级 CoT 提示，相比传统方法如 A* 和 DP-WA*，实现了更短的路径长度同时保持相似的平均路径增益。实验结果显示，SCoTT 能加速 DP-WA* 算法，减少搜索空间并节省高达 62% 的执行时间，突显了 VLMs 在增强用户交互和快速原型设计中的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.18212v1",
      "published_date": "2024-11-27 10:45:49 UTC",
      "updated_date": "2024-11-27 10:45:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T05:06:06.973112"
    },
    {
      "arxiv_id": "2411.18211v1",
      "title": "TimeMarker: A Versatile Video-LLM for Long and Short Video Understanding with Superior Temporal Localization Ability",
      "title_zh": "翻译失败",
      "authors": [
        "Shimin Chen",
        "Xiaohan Lan",
        "Yitian Yuan",
        "Zequn Jie",
        "Lin Ma"
      ],
      "abstract": "Rapid development of large language models (LLMs) has significantly advanced\nmultimodal large language models (LMMs), particularly in vision-language tasks.\nHowever, existing video-language models often overlook precise temporal\nlocalization and struggle with videos of varying lengths. We introduce\nTimeMarker, a versatile Video-LLM designed for high-quality dialogue based on\nvideo content, emphasizing temporal localization. TimeMarker integrates\nTemporal Separator Tokens to enhance temporal awareness, accurately marking\nspecific moments within videos. It employs the AnyLength mechanism for dynamic\nframe sampling and adaptive token merging, enabling effective handling of both\nshort and long videos. Additionally, TimeMarker utilizes diverse datasets,\nincluding further transformed temporal-related video QA datasets, to bolster\nits temporal understanding capabilities. Image and interleaved data are also\nemployed to further enhance the model's semantic perception ability.\nEvaluations demonstrate that TimeMarker achieves state-of-the-art performance\nacross multiple benchmarks, excelling in both short and long video categories.\nOur project page is at \\url{https://github.com/TimeMarker-LLM/TimeMarker/}.",
      "tldr_zh": "该研究针对现有视频语言模型在精确时间定位和处理不同长度视频方面的不足，提出 TimeMarker，一种多功能的 Video-LLM，用于基于视频内容的对话并强调时间定位能力。TimeMarker 整合了 Temporal Separator Tokens 来准确标记视频中的特定时刻，并采用 AnyLength 机制进行动态帧采样和自适应 token 合并，从而有效处理短视频和长视频。模型通过利用多样数据集，包括转换后的时间相关视频 QA 数据集，以及图像和交错数据，进一步提升了时间理解和语义感知能力。评估结果显示，TimeMarker 在多个基准测试中取得最先进性能，尤其在短视频和长视频类别中表现出色。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.18211v1",
      "published_date": "2024-11-27 10:45:40 UTC",
      "updated_date": "2024-11-27 10:45:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T05:06:17.720001"
    },
    {
      "arxiv_id": "2412.03589v1",
      "title": "Human Evaluation of Procedural Knowledge Graph Extraction from Text with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Valentina Anita Carriero",
        "Antonia Azzini",
        "Ilaria Baroni",
        "Mario Scrocca",
        "Irene Celino"
      ],
      "abstract": "Procedural Knowledge is the know-how expressed in the form of sequences of\nsteps needed to perform some tasks. Procedures are usually described by means\nof natural language texts, such as recipes or maintenance manuals, possibly\nspread across different documents and systems, and their interpretation and\nsubsequent execution is often left to the reader. Representing such procedures\nin a Knowledge Graph (KG) can be the basis to build digital tools to support\nthose users who need to apply or execute them. In this paper, we leverage Large\nLanguage Model (LLM) capabilities and propose a prompt engineering approach to\nextract steps, actions, objects, equipment and temporal information from a\ntextual procedure, in order to populate a Procedural KG according to a\npre-defined ontology. We evaluate the KG extraction results by means of a user\nstudy, in order to qualitatively and quantitatively assess the perceived\nquality and usefulness of the LLM-extracted procedural knowledge. We show that\nLLMs can produce outputs of acceptable quality and we assess the subjective\nperception of AI by human evaluators.",
      "tldr_zh": "这篇论文探讨了使用大型语言模型（Large Language Models, LLMs）从文本中提取程序性知识（Procedural Knowledge），以构建知识图谱（Knowledge Graph），帮助用户更好地理解和执行任务序列，如食谱或维护手册。研究采用提示工程（prompt engineering）方法，从文本中提取步骤、动作、对象、设备和时间信息，并根据预定义的本体（ontology）填充程序性知识图谱。最终，通过用户研究（user study）进行定性和定量评估，结果表明LLMs能生成可接受质量的输出，并揭示了人类评估者对AI的主观感知。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.03589v1",
      "published_date": "2024-11-27 10:36:28 UTC",
      "updated_date": "2024-11-27 10:36:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T05:06:29.380090"
    },
    {
      "arxiv_id": "2411.18207v3",
      "title": "From Open Vocabulary to Open World: Teaching Vision Language Models to Detect Novel Objects",
      "title_zh": "从开放词汇到开放世界：教视觉语言模型检测新颖对象",
      "authors": [
        "Zizhao Li",
        "Zhengkang Xiang",
        "Joseph West",
        "Kourosh Khoshelham"
      ],
      "abstract": "Traditional object detection methods operate under the closed-set assumption,\nwhere models can only detect a fixed number of objects predefined in the\ntraining set. Recent works on open vocabulary object detection (OVD) enable the\ndetection of objects defined by an in-principle unbounded vocabulary, which\nreduces the cost of training models for specific tasks. However, OVD heavily\nrelies on accurate prompts provided by an ``oracle'', which limits their use in\ncritical applications such as driving scene perception. OVD models tend to\nmisclassify near-out-of-distribution (NOOD) objects that have similar features\nto known classes, and ignore far-out-of-distribution (FOOD) objects. To address\nthese limitations, we propose a framework that enables OVD models to operate in\nopen world settings, by identifying and incrementally learning previously\nunseen objects. To detect FOOD objects, we propose Open World Embedding\nLearning (OWEL) and introduce the concept of Pseudo Unknown Embedding which\ninfers the location of unknown classes in a continuous semantic space based on\nthe information of known classes. We also propose Multi-Scale Contrastive\nAnchor Learning (MSCAL), which enables the identification of misclassified\nunknown objects by promoting the intra-class consistency of object embeddings\nat different scales. The proposed method achieves state-of-the-art performance\non standard open world object detection and autonomous driving benchmarks while\nmaintaining its open vocabulary object detection capability.",
      "tldr_zh": "这篇论文解决了开放词汇物体检测 (OVD) 的局限性，即模型依赖准确的 prompts、易误分类近分布外 (NOOD) 物体和忽略远分布外 (FOOD) 物体的问题。作者提出一个框架，使 OVD 模型能够在开放世界环境中识别和逐步学习未见物体，包括 Open World Embedding Learning (OWEL) 方法，该方法通过 Pseudo Unknown Embedding 在连续语义空间中基于已知类推断未知类位置，以及 Multi-Scale Contrastive Anchor Learning (MSCAL) 来提升不同尺度下物体嵌入的类内一致性，从而识别误分类的未知物体。该框架在标准开放世界物体检测和自动驾驶基准上实现了最先进性能，同时保持了 OVD 的检测能力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.18207v3",
      "published_date": "2024-11-27 10:33:51 UTC",
      "updated_date": "2025-03-21 03:09:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T05:06:42.332846"
    },
    {
      "arxiv_id": "2411.18201v1",
      "title": "Learning for Long-Horizon Planning via Neuro-Symbolic Abductive Imitation",
      "title_zh": "通过神经符号溯因模仿进行长时域规划的学习",
      "authors": [
        "Jie-Jing Shao",
        "Hao-Ran Hao",
        "Xiao-Wen Yang",
        "Yu-Feng Li"
      ],
      "abstract": "Recent learning-to-imitation methods have shown promising results in planning\nvia imitating within the observation-action space. However, their ability in\nopen environments remains constrained, particularly in long-horizon tasks. In\ncontrast, traditional symbolic planning excels in long-horizon tasks through\nlogical reasoning over human-defined symbolic spaces but struggles to handle\nobservations beyond symbolic states, such as high-dimensional visual inputs\nencountered in real-world scenarios. In this work, we draw inspiration from\nabductive learning and introduce a novel framework \\textbf{AB}ductive\n\\textbf{I}mitation \\textbf{L}earning (ABIL) that integrates the benefits of\ndata-driven learning and symbolic-based reasoning, enabling long-horizon\nplanning. Specifically, we employ abductive reasoning to understand the\ndemonstrations in symbolic space and design the principles of sequential\nconsistency to resolve the conflicts between perception and reasoning. ABIL\ngenerates predicate candidates to facilitate the perception from raw\nobservations to symbolic space without laborious predicate annotations,\nproviding a groundwork for symbolic planning. With the symbolic understanding,\nwe further develop a policy ensemble whose base policies are built with\ndifferent logical objectives and managed through symbolic reasoning.\nExperiments show that our proposal successfully understands the observations\nwith the task-relevant symbolics to assist the imitation learning. Importantly,\nABIL demonstrates significantly improved data efficiency and generalization\nacross various long-horizon tasks, highlighting it as a promising solution for\nlong-horizon planning. Project website:\n\\url{https://www.lamda.nju.edu.cn/shaojj/KDD25_ABIL/}.",
      "tldr_zh": "本研究提出了一种名为 ABIL 的新框架，结合神经符号（Neuro-Symbolic）和溯因推理（Abductive Imitation），以提升长时域（long-horizon）规划中的模仿学习能力。该框架通过溯因推理理解演示数据，并引入顺序一致性原则（sequential consistency）来解决感知与推理之间的冲突，同时自动生成谓词候选（predicate candidates）以从原始观察转化为符号空间，支持符号规划。实验结果显示，ABIL 显著提高了数据效率和泛化性能，在各种长时域任务中表现出色，为开放环境下的规划提供了高效解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by KDD2025. The KDD version is titled ''Abductive Learning\n  for Neuro-Symbolic Grounded Imitation''",
      "pdf_url": "http://arxiv.org/pdf/2411.18201v1",
      "published_date": "2024-11-27 10:26:14 UTC",
      "updated_date": "2024-11-27 10:26:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T05:06:52.359312"
    },
    {
      "arxiv_id": "2411.18179v1",
      "title": "Prediction with Action: Visual Policy Learning via Joint Denoising Process",
      "title_zh": "翻译失败",
      "authors": [
        "Yanjiang Guo",
        "Yucheng Hu",
        "Jianke Zhang",
        "Yen-Jen Wang",
        "Xiaoyu Chen",
        "Chaochao Lu",
        "Jianyu Chen"
      ],
      "abstract": "Diffusion models have demonstrated remarkable capabilities in image\ngeneration tasks, including image editing and video creation, representing a\ngood understanding of the physical world. On the other line, diffusion models\nhave also shown promise in robotic control tasks by denoising actions, known as\ndiffusion policy. Although the diffusion generative model and diffusion policy\nexhibit distinct capabilities--image prediction and robotic action,\nrespectively--they technically follow a similar denoising process. In robotic\ntasks, the ability to predict future images and generate actions is highly\ncorrelated since they share the same underlying dynamics of the physical world.\nBuilding on this insight, we introduce PAD, a novel visual policy learning\nframework that unifies image Prediction and robot Action within a joint\nDenoising process. Specifically, PAD utilizes Diffusion Transformers (DiT) to\nseamlessly integrate images and robot states, enabling the simultaneous\nprediction of future images and robot actions. Additionally, PAD supports\nco-training on both robotic demonstrations and large-scale video datasets and\ncan be easily extended to other robotic modalities, such as depth images. PAD\noutperforms previous methods, achieving a significant 26.3% relative\nimprovement on the full Metaworld benchmark, by utilizing a single\ntext-conditioned visual policy within a data-efficient imitation learning\nsetting. Furthermore, PAD demonstrates superior generalization to unseen tasks\nin real-world robot manipulation settings with 28.0% success rate increase\ncompared to the strongest baseline. Project page at\nhttps://sites.google.com/view/pad-paper",
      "tldr_zh": "本论文提出 PAD 框架，通过联合去噪过程统一图像预测和机器人动作学习，利用 Diffusion Transformers (DiT) 整合图像和机器人状态，实现同时预测未来图像和生成机器人动作。PAD 支持在机器人演示和大规模视频数据集上进行联合训练，并可扩展到其他模态，如深度图像，从而在数据高效的模仿学习设置中提升性能。实验结果显示，PAD 在 Metaworld 基准上比前人方法提高 26.3%，并在真实机器人操作中对未见任务的成功率提升 28.0%。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.18179v1",
      "published_date": "2024-11-27 09:54:58 UTC",
      "updated_date": "2024-11-27 09:54:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T05:07:05.423963"
    },
    {
      "arxiv_id": "2412.06809v1",
      "title": "Generating Diverse Synthetic Datasets for Evaluation of Real-life Recommender Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Miha Malenšek",
        "Blaž Škrlj",
        "Blaž Mramor",
        "Jure Demšar"
      ],
      "abstract": "Synthetic datasets are important for evaluating and testing machine learning\nmodels. When evaluating real-life recommender systems, high-dimensional\ncategorical (and sparse) datasets are often considered. Unfortunately, there\nare not many solutions that would allow generation of artificial datasets with\nsuch characteristics. For that purpose, we developed a novel framework for\ngenerating synthetic datasets that are diverse and statistically coherent. Our\nframework allows for creation of datasets with controlled attributes, enabling\niterative modifications to fit specific experimental needs, such as introducing\ncomplex feature interactions, feature cardinality, or specific distributions.\nWe demonstrate the framework's utility through use cases such as benchmarking\nprobabilistic counting algorithms, detecting algorithmic bias, and simulating\nAutoML searches. Unlike existing methods that either focus narrowly on specific\ndataset structures, or prioritize (private) data synthesis through real data,\nour approach provides a modular means to quickly generating completely\nsynthetic datasets we can tailor to diverse experimental requirements. Our\nresults show that the framework effectively isolates model behavior in unique\nsituations and highlights its potential for significant advancements in the\nevaluation and development of recommender systems. The readily-available\nframework is available as a free open Python package to facilitate research\nwith minimal friction.",
      "tldr_zh": "该研究提出了一种新型框架，用于生成多样化和统计连贯的合成数据集，专门针对高维分类（稀疏）数据以评估真实推荐系统（recommender systems）。框架通过模块化设计允许用户控制数据集属性、迭代修改以及引入复杂特征交互、特征基数和特定分布，支持各种实验需求，如基准测试probabilistic counting algorithms、检测算法偏差和模拟AutoML搜索。与现有方法不同，该框架完全基于合成数据而非真实数据生成，并证明其能有效隔离模型行为，促进推荐系统的发展。该框架作为免费开源Python包提供，便于研究应用。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "RecSys 2024'",
      "pdf_url": "http://arxiv.org/pdf/2412.06809v1",
      "published_date": "2024-11-27 09:53:14 UTC",
      "updated_date": "2024-11-27 09:53:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T05:07:16.934623"
    },
    {
      "arxiv_id": "2411.18659v1",
      "title": "DHCP: Detecting Hallucinations by Cross-modal Attention Pattern in Large Vision-Language Models",
      "title_zh": "DHCP：通过跨模态注意力模式检测大型视觉语言模型中的幻觉",
      "authors": [
        "Yudong Zhang",
        "Ruobing Xie",
        "Jiansheng Chen",
        "Xingwu Sun",
        "Zhanhui kang",
        "Yu Wang"
      ],
      "abstract": "Large vision-language models (LVLMs) have demonstrated exceptional\nperformance on complex multimodal tasks. However, they continue to suffer from\nsignificant hallucination issues, including object, attribute, and relational\nhallucinations. To accurately detect these hallucinations, we investigated the\nvariations in cross-modal attention patterns between hallucination and\nnon-hallucination states. Leveraging these distinctions, we developed a\nlightweight detector capable of identifying hallucinations. Our proposed\nmethod, Detecting Hallucinations by Cross-modal Attention Patterns (DHCP), is\nstraightforward and does not require additional LVLM training or extra LVLM\ninference steps. Experimental results show that DHCP achieves remarkable\nperformance in hallucination detection. By offering novel insights into the\nidentification and analysis of hallucinations in LVLMs, DHCP contributes to\nadvancing the reliability and trustworthiness of these models.",
      "tldr_zh": "本研究针对大型视觉语言模型(LVLMs)中的幻觉问题，包括对象(attribute)、属性和关系幻堂(hallucinations)，通过分析幻觉和非幻觉状态下的跨模态注意力模式(cross-modal attention patterns)差异，开发了一种轻量级检测方法。提出的DHCP(Detecting Hallucinations by Cross-modal Attention Patterns)方法简单高效，无需额外LVLM训练或推理步骤。实验结果显示，DHCP在幻觉检测上表现出色，为提升LVLMs的可靠性和可信度提供了新见解。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "18 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.18659v1",
      "published_date": "2024-11-27 09:43:09 UTC",
      "updated_date": "2024-11-27 09:43:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T05:07:29.176181"
    },
    {
      "arxiv_id": "2411.18169v1",
      "title": "PDZSeg: Adapting the Foundation Model for Dissection Zone Segmentation with Visual Prompts in Robot-assisted Endoscopic Submucosal Dissection",
      "title_zh": "翻译失败",
      "authors": [
        "Mengya Xu",
        "Wenjin Mo",
        "Guankun Wang",
        "Huxin Gao",
        "An Wang",
        "Zhen Li",
        "Xiaoxiao Yang",
        "Hongliang Ren"
      ],
      "abstract": "Purpose: Endoscopic surgical environments present challenges for dissection\nzone segmentation due to unclear boundaries between tissue types, leading to\nsegmentation errors where models misidentify or overlook edges. This study aims\nto provide precise dissection zone suggestions during endoscopic submucosal\ndissection (ESD) procedures, enhancing ESD safety.\n  Methods: We propose the Prompted-based Dissection Zone Segmentation (PDZSeg)\nmodel, designed to leverage diverse visual prompts such as scribbles and\nbounding boxes. By overlaying these prompts onto images and fine-tuning a\nfoundational model on a specialized dataset, our approach improves segmentation\nperformance and user experience through flexible input methods.\n  Results: The PDZSeg model was validated using three experimental setups:\nin-domain evaluation, variability in visual prompt availability, and robustness\nassessment. Using the ESD-DZSeg dataset, results show that our method\noutperforms state-of-the-art segmentation approaches. This is the first study\nto integrate visual prompt design into dissection zone segmentation.\n  Conclusion: The PDZSeg model effectively utilizes visual prompts to enhance\nsegmentation performance and user experience, supported by the novel ESD-DZSeg\ndataset as a benchmark for dissection zone segmentation in ESD. Our work\nestablishes a foundation for future research.",
      "tldr_zh": "本研究针对内镜手术中切割区域边界模糊导致的分割错误，提出PDZSeg模型，以提升机器人辅助内镜黏膜下剥离术(ESD)的安全性。PDZSeg通过利用视觉提示（如scribbles和bounding boxes）叠加图像，并在专用ESD-DZSeg数据集上微调Foundation Model，实现更精确的切割区域分割和灵活的用户输入方式。实验结果显示，PDZSeg在同域评估、提示可用性变异和鲁棒性测试中均优于现有方法，这是首个将视觉提示整合到切割区域分割的研究，为未来ESD相关研究奠定基础。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.18169v1",
      "published_date": "2024-11-27 09:28:50 UTC",
      "updated_date": "2024-11-27 09:28:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T05:07:40.196188"
    },
    {
      "arxiv_id": "2411.18158v1",
      "title": "Abductive Symbolic Solver on Abstraction and Reasoning Corpus",
      "title_zh": "翻译失败",
      "authors": [
        "Mintaek Lim",
        "Seokki Lee",
        "Liyew Woletemaryam Abitew",
        "Sundong Kim"
      ],
      "abstract": "This paper addresses the challenge of enhancing artificial intelligence\nreasoning capabilities, focusing on logicality within the Abstraction and\nReasoning Corpus (ARC). Humans solve such visual reasoning tasks based on their\nobservations and hypotheses, and they can explain their solutions with a proper\nreason. However, many previous approaches focused only on the grid transition\nand it is not enough for AI to provide reasonable and human-like solutions. By\nconsidering the human process of solving visual reasoning tasks, we have\nconcluded that the thinking process is likely the abductive reasoning process.\nThus, we propose a novel framework that symbolically represents the observed\ndata into a knowledge graph and extracts core knowledge that can be used for\nsolution generation. This information limits the solution search space and\nhelps provide a reasonable mid-process. Our approach holds promise for\nimproving AI performance on ARC tasks by effectively narrowing the solution\nspace and providing logical solutions grounded in core knowledge extraction.",
      "tldr_zh": "本论文针对增强人工智能在 Abstraction and Reasoning Corpus (ARC) 中的推理能力，特别强调逻辑性和人类-like 解决方案的问题。现有方法仅关注网格转换，未能提供合理的解释，因此作者提出一个新框架，通过符号表示将观察数据转换为知识图谱，并提取核心知识来生成解决方案。该框架基于 abductive reasoning 过程，有效缩小解决方案搜索空间，提供逻辑清晰的中间过程，从而显著提升 AI 在 ARC 任务上的性能。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Presented at IJCAI 2024 LNSAI Workshop",
      "pdf_url": "http://arxiv.org/pdf/2411.18158v1",
      "published_date": "2024-11-27 09:09:00 UTC",
      "updated_date": "2024-11-27 09:09:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T05:07:52.122926"
    },
    {
      "arxiv_id": "2411.18157v1",
      "title": "A survey on cutting-edge relation extraction techniques based on language models",
      "title_zh": "基于语言模型的前沿关系抽取技术综述",
      "authors": [
        "Jose A. Diaz-Garcia",
        "Julio Amador Diaz Lopez"
      ],
      "abstract": "This comprehensive survey delves into the latest advancements in Relation\nExtraction (RE), a pivotal task in natural language processing essential for\napplications across biomedical, financial, and legal sectors. This study\nhighlights the evolution and current state of RE techniques by analyzing 137\npapers presented at the Association for Computational Linguistics (ACL)\nconferences over the past four years, focusing on models that leverage language\nmodels. Our findings underscore the dominance of BERT-based methods in\nachieving state-of-the-art results for RE while also noting the promising\ncapabilities of emerging large language models (LLMs) like T5, especially in\nfew-shot relation extraction scenarios where they excel in identifying\npreviously unseen relations.",
      "tldr_zh": "这篇调查综述了基于语言模型的关系抽取（Relation Extraction, RE）技术的最新进展，RE 是自然语言处理中的核心任务，广泛应用于生物医学、金融和法律等领域。通过分析过去四年 Association for Computational Linguistics (ACL) 会议的 137 篇论文，该研究强调了 BERT-based 方法在 RE 中占据主导地位，并实现了最先进的结果。研究还突出了新兴大型语言模型（LLMs）如 T5 的潜力，尤其在少样本关系抽取（few-shot relation extraction）场景中，它们在识别新关系方面表现出色。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "50 pages, under review in Artificial Intelligence Review",
      "pdf_url": "http://arxiv.org/pdf/2411.18157v1",
      "published_date": "2024-11-27 09:04:47 UTC",
      "updated_date": "2024-11-27 09:04:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T05:08:04.500873"
    },
    {
      "arxiv_id": "2411.18141v1",
      "title": "Predicting Water Quality using Quantum Machine Learning: The Case of the Umgeni Catchment (U20A) Study Region",
      "title_zh": "使用量子机器学习预测水质：Umgeni Catchment (U20A) 研究区域的案例",
      "authors": [
        "Muhammad Al-Zafar Khan",
        "Jamal Al-Karaki",
        "Marwan Omar"
      ],
      "abstract": "In this study, we consider a real-world application of QML techniques to\nstudy water quality in the U20A region in Durban, South Africa. Specifically,\nwe applied the quantum support vector classifier (QSVC) and quantum neural\nnetwork (QNN), and we showed that the QSVC is easier to implement and yields a\nhigher accuracy. The QSVC models were applied for three kernels: Linear,\npolynomial, and radial basis function (RBF), and it was shown that the\npolynomial and RBF kernels had exactly the same performance. The QNN model was\napplied using different optimizers, learning rates, noise on the circuit\ncomponents, and weight initializations were considered, but the QNN\npersistently ran into the dead neuron problem. Thus, the QNN was compared only\nby accraucy and loss, and it was shown that with the Adam optimizer, the model\nhas the best performance, however, still less than the QSVC.",
      "tldr_zh": "本研究探讨了使用量子机器学习（QML）预测南非乌姆吉尼流域（U20A）地区水质，具体应用了量子支持向量分类器（QSVC）和量子神经网络（QNN）。结果显示，QSVC 比 QNN 更容易实现且准确率更高，其中 QSVC 在线性、多项式和径向基函数（RBF）内核下表现最佳，且多项式与 RBF 内核的性能相同。QNN 在不同优化器（如 Adam）、学习率、噪声和权重初始化下均遇到了死神经元问题，导致其整体表现逊于 QSVC，为水质预测提供了更可靠的量子方法。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "quant-ph",
      "comment": "13 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.18141v1",
      "published_date": "2024-11-27 08:43:07 UTC",
      "updated_date": "2024-11-27 08:43:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T05:08:17.760196"
    },
    {
      "arxiv_id": "2411.18657v1",
      "title": "ScaleViz: Scaling Visualization Recommendation Models on Large Data",
      "title_zh": "翻译失败",
      "authors": [
        "Ghazi Shazan Ahmad",
        "Shubham Agarwal",
        "Subrata Mitra",
        "Ryan Rossi",
        "Manav Doshi",
        "Vibhor Porwal",
        "Syam Manoj Kumar Paila"
      ],
      "abstract": "Automated visualization recommendations (vis-rec) help users to derive\ncrucial insights from new datasets. Typically, such automated vis-rec models\nfirst calculate a large number of statistics from the datasets and then use\nmachine-learning models to score or classify multiple visualizations choices to\nrecommend the most effective ones, as per the statistics. However, state-of-the\nart models rely on very large number of expensive statistics and therefore\nusing such models on large datasets become infeasible due to prohibitively\nlarge computational time, limiting the effectiveness of such techniques to most\nreal world complex and large datasets. In this paper, we propose a novel\nreinforcement-learning (RL) based framework that takes a given vis-rec model\nand a time-budget from the user and identifies the best set of input statistics\nthat would be most effective while generating the visual insights within a\ngiven time budget, using the given model. Using two state-of-the-art vis-rec\nmodels applied on three large real-world datasets, we show the effectiveness of\nour technique in significantly reducing time-to visualize with very small\namount of introduced error. Our approach is about 10X times faster compared to\nthe baseline approaches that introduce similar amounts of error.",
      "tldr_zh": "该论文提出ScaleViz，一种基于强化学习(RL)的框架，用于优化可视化推荐(vis-rec)模型在大数据集上的性能，通过选择最有效的输入统计集来在用户指定时间预算内生成高质量视觉洞见。现有vis-rec模型依赖大量昂贵统计计算，导致处理大型数据集时计算时间过长，该框架有效解决了这一问题。实验在两个state-of-the-art vis-rec模型和三个真实大型数据集上验证，显示ScaleViz比基线方法快约10倍，同时引入的错误量非常小。",
      "categories": [
        "cs.AI",
        "cs.HC",
        "stat.ML"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at PAKDD 2024 (Oral)",
      "pdf_url": "http://arxiv.org/pdf/2411.18657v1",
      "published_date": "2024-11-27 08:43:06 UTC",
      "updated_date": "2024-11-27 08:43:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T05:08:28.737944"
    },
    {
      "arxiv_id": "2411.18138v1",
      "title": "SALMONN-omni: A Codec-free LLM for Full-duplex Speech Understanding and Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Wenyi Yu",
        "Siyin Wang",
        "Xiaoyu Yang",
        "Xianzhao Chen",
        "Xiaohai Tian",
        "Jun Zhang",
        "Guangzhi Sun",
        "Lu Lu",
        "Yuxuan Wang",
        "Chao Zhang"
      ],
      "abstract": "Full-duplex multimodal large language models (LLMs) provide a unified\nframework for addressing diverse speech understanding and generation tasks,\nenabling more natural and seamless human-machine conversations. Unlike\ntraditional modularised conversational AI systems, which separate speech\nrecognition, understanding, and text-to-speech generation into distinct\ncomponents, multimodal LLMs operate as single end-to-end models. This\nstreamlined design eliminates error propagation across components and fully\nleverages the rich non-verbal information embedded in input speech signals. We\nintroduce SALMONN-omni, a codec-free, full-duplex speech understanding and\ngeneration model capable of simultaneously listening to its own generated\nspeech and background sounds while speaking. To support this capability, we\npropose a novel duplex spoken dialogue framework incorporating a ``thinking''\nmechanism that facilitates asynchronous text and speech generation relying on\nembeddings instead of codecs (quantized speech and audio tokens). Experimental\nresults demonstrate SALMONN-omni's versatility across a broad range of\nstreaming speech tasks, including speech recognition, speech enhancement, and\nspoken question answering. Additionally, SALMONN-omni excels at managing\nturn-taking, barge-in, and echo cancellation scenarios, establishing its\npotential as a robust prototype for full-duplex conversational AI systems. To\nthe best of our knowledge, SALMONN-omni is the first codec-free model of its\nkind. A full technical report along with model checkpoints will be released\nsoon.",
      "tldr_zh": "该研究提出了 SALMONN-omni，一种 codec-free 的全双工多模态 LLM，用于整合语音理解和生成任务，实现更自然的语音对话。不同于传统模块化系统，该模型采用端到端设计，通过一个新型双向对话框架和“thinking”机制，利用 embeddings 进行异步文本和语音生成，从而避免错误传播并利用语音中的非语言信息。实验结果显示，SALMONN-omni 在语音识别、语音增强和口语问答等流式任务上表现出色，并有效处理转接、插话和回声消除场景。作为首个 codec-free 全双工模型，它为稳健的对话 AI 系统奠定了基础。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CL",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "Technical report",
      "pdf_url": "http://arxiv.org/pdf/2411.18138v1",
      "published_date": "2024-11-27 08:38:57 UTC",
      "updated_date": "2024-11-27 08:38:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T05:08:40.857819"
    },
    {
      "arxiv_id": "2411.18656v1",
      "title": "The Return of Pseudosciences in Artificial Intelligence: Have Machine Learning and Deep Learning Forgotten Lessons from Statistics and History?",
      "title_zh": "翻译失败",
      "authors": [
        "Jérémie Sublime"
      ],
      "abstract": "In today's world, AI programs powered by Machine Learning are ubiquitous, and\nhave achieved seemingly exceptional performance across a broad range of tasks,\nfrom medical diagnosis and credit rating in banking, to theft detection via\nvideo analysis, and even predicting political or sexual orientation from facial\nimages. These predominantly deep learning methods excel due to their\nextraordinary capacity to process vast amounts of complex data to extract\ncomplex correlations and relationship from different levels of features.\n  In this paper, we contend that the designers and final users of these ML\nmethods have forgotten a fundamental lesson from statistics: correlation does\nnot imply causation. Not only do most state-of-the-art methods neglect this\ncrucial principle, but by doing so they often produce nonsensical or flawed\ncausal models, akin to social astrology or physiognomy. Consequently, we argue\nthat current efforts to make AI models more ethical by merely reducing biases\nin the training data are insufficient. Through examples, we will demonstrate\nthat the potential for harm posed by these methods can only be mitigated by a\ncomplete rethinking of their core models, improved quality assessment metrics\nand policies, and by maintaining humans oversight throughout the process.",
      "tldr_zh": "本论文质疑机器学习(Machine Learning)和深度学习(Deep Learning)是否忽略了统计学的基本原则，即相关性不等于因果性(correlation does not imply causation)，从而导致AI模型在实际应用中（如医疗诊断或面部分析）产生类似于伪科学（如社会占星术或相面术）的错误或无意义模型。作者通过示例说明，仅通过减少训练数据中的偏见(biases)来提升AI伦理是不够的，因为这些方法的核心缺陷可能造成潜在危害。论文建议通过重新设计AI核心模型、改进质量评估指标和政策，以及维持人类监督(human oversight)，才能有效缓解这些问题。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.18656v1",
      "published_date": "2024-11-27 08:23:23 UTC",
      "updated_date": "2024-11-27 08:23:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T05:08:52.967817"
    },
    {
      "arxiv_id": "2411.18104v3",
      "title": "Training and Evaluating Language Models with Template-based Data Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Yifan Zhang"
      ],
      "abstract": "The rapid advancement of large language models (LLMs) such as GPT-3, PaLM,\nand Llama has significantly transformed natural language processing, showcasing\nremarkable capabilities in understanding and generating language. However,\nthese models often struggle with tasks requiring complex reasoning,\nparticularly in mathematical problem-solving, due in part to the scarcity of\nlarge-scale, high-quality, domain-specific datasets necessary for training\nsophisticated reasoning abilities. To address this limitation, we introduce\nTemplate-based Data Generation (TDG), a novel approach that leverages LLMs\n(GPT-4) to automatically generate parameterized meta-templates, which are then\nused to synthesize a vast array of high-quality problems and solutions.\nLeveraging TDG, we create TemplateMath Part I: TemplateGSM, a dataset\ncomprising over 7 million synthetically generated grade school math\nproblems--each accompanied by code-based and natural language solutions--with\nthe potential to generate an effectively unlimited number more. This dataset\nalleviates the scarcity of large-scale mathematical datasets and serves as a\nvaluable resource for pre-training, fine-tuning, and evaluating LLMs in\nmathematical reasoning. Our method not only enables the generation of virtually\ninfinite data but also elevates data augmentation to a new level by using GPT-4\nfor meta-template generation, ensuring diverse and high-quality problem\nstructures. The TemplateMath Part I: TemplateGSM dataset is publicly available\nat https://huggingface.co/datasets/math-ai/TemplateGSM. The code is available\nat https://github.com/iiis-ai/TemplateMath.",
      "tldr_zh": "该论文针对大型语言模型 (LLMs) 在复杂推理任务（如数学问题）上的不足，提出了一种 Template-based Data Generation (TDG) 方法，利用 GPT-4 自动生成参数化元模板，从而合成大量高质量问题和解决方案。研究者基于 TDG 创建了 TemplateMath Part I: TemplateGSM 数据集，包含超过 700 万个小学数学问题，每题附带代码和自然语言解答，并可无限扩展以缓解领域特定数据集的稀缺问题。该数据集可用于 LLMs 的预训练、微调和评估，提高模型的数学推理能力，并已公开提供于 Hugging Face 和 GitHub。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.18104v3",
      "published_date": "2024-11-27 07:32:56 UTC",
      "updated_date": "2025-03-08 01:18:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T05:09:05.416058"
    },
    {
      "arxiv_id": "2411.18095v1",
      "title": "Derivation of Closed Form of Expected Improvement for Gaussian Process Trained on Log-Transformed Objective",
      "title_zh": "翻译失败",
      "authors": [
        "Shuhei Watanabe"
      ],
      "abstract": "Expected Improvement (EI) is arguably the most widely used acquisition\nfunction in Bayesian optimization. However, it is often challenging to enhance\nthe performance with EI due to its sensitivity to numerical precision.\nPreviously, Hutter et al. (2009) tackled this problem by using Gaussian process\ntrained on the log-transformed objective function and it was reported that this\ntrick improves the predictive accuracy of GP, leading to substantially better\nperformance. Although Hutter et al. (2009) offered the closed form of their EI,\nits intermediate derivation has not been provided so far. In this paper, we\ngive a friendly derivation of their proposition.",
      "tldr_zh": "本文研究了 Expected Improvement (EI) 在 Bayesian optimization 中的应用，该函数虽广泛使用，但对数值精度高度敏感。Hutter et al. (2009) 通过使用 Gaussian Process (GP) 训练在 log-transformed objective 上，改善了预测准确性和整体性能，但他们的 EI 闭合形式缺少中间推导过程。本文提供了一个清晰友好的中间推导，旨在增强 EI 的实用性和可靠性，为后续优化研究提供理论基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.18095v1",
      "published_date": "2024-11-27 07:13:41 UTC",
      "updated_date": "2024-11-27 07:13:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T05:09:15.964250"
    },
    {
      "arxiv_id": "2411.18085v1",
      "title": "MONOPOLY: Learning to Price Public Facilities for Revaluing Private Properties with Large-Scale Urban Data",
      "title_zh": "翻译失败",
      "authors": [
        "Miao Fan",
        "Jizhou Huang",
        "An Zhuo",
        "Ying Li",
        "Ping Li",
        "Haifeng Wang"
      ],
      "abstract": "The value assessment of private properties is an attractive but challenging\ntask which is widely concerned by a majority of people around the world. A\nprolonged topic among us is ``\\textit{how much is my house worth?}''. To answer\nthis question, most experienced agencies would like to price a property given\nthe factors of its attributes as well as the demographics and the public\nfacilities around it. However, no one knows the exact prices of these factors,\nespecially the values of public facilities which may help assess private\nproperties. In this paper, we introduce our newly launched project ``Monopoly''\n(named after a classic board game) in which we propose a distributed approach\nfor revaluing private properties by learning to price public facilities (such\nas hospitals etc.) with the large-scale urban data we have accumulated via\nBaidu Maps. To be specific, our method organizes many points of interest (POIs)\ninto an undirected weighted graph and formulates multiple factors including the\nvirtual prices of surrounding public facilities as adaptive variables to\nparallelly estimate the housing prices we know. Then the prices of both public\nfacilities and private properties can be iteratively updated according to the\nloss of prediction until convergence. We have conducted extensive experiments\nwith the large-scale urban data of several metropolises in China. Results show\nthat our approach outperforms several mainstream methods with significant\nmargins. Further insights from more in-depth discussions demonstrate that the\n``Monopoly'' is an innovative application in the interdisciplinary field of\nbusiness intelligence and urban computing, and it will be beneficial to tens of\nmillions of our users for investments and to the governments for urban planning\nas well as taxation.",
      "tldr_zh": "该论文提出“Monopoly”项目，使用大规模城市数据（如Baidu Maps数据）来学习定价公共设施（如医院等），从而重新评估私人房产价值。方法将兴趣点（POIs）组织成无向加权图，将公共设施的虚拟价格等因素作为自适应变量，并行估计已知房价，并通过迭代更新预测损失直到收敛。实验结果显示，该方法在多个中国大都市的数据上显著优于主流方法，并为用户投资决策和政府城市规划、税收提供创新应用价值。",
      "categories": [
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.AI",
      "comment": "CIKM'19",
      "pdf_url": "http://arxiv.org/pdf/2411.18085v1",
      "published_date": "2024-11-27 06:44:41 UTC",
      "updated_date": "2024-11-27 06:44:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T05:09:28.860348"
    },
    {
      "arxiv_id": "2411.18084v1",
      "title": "From Exploration to Revelation: Detecting Dark Patterns in Mobile Apps",
      "title_zh": "从探索到揭示：检测移动应用中的黑暗模式",
      "authors": [
        "Jieshan Chen",
        "Zhen Wang",
        "Jiamou Sun",
        "Wenbo Zou",
        "Zhenchang Xing",
        "Qinghua Lu",
        "Qing Huang",
        "Xiwei Xu"
      ],
      "abstract": "Mobile apps are essential in daily life, yet they often employ dark patterns,\nsuch as visual tricks to highlight certain options or linguistic tactics to nag\nusers into making purchases, to manipulate user behavior. Current research\nmainly uses manual methods to detect dark patterns, a process that is\ntime-consuming and struggles to keep pace with continually updating and\nemerging apps. While some studies targeted at automated detection, they are\nconstrained to static patterns and still necessitate manual app exploration. To\nbridge these gaps, we present AppRay, an innovative system that seamlessly\nblends task-oriented app exploration with automated dark pattern detection,\nreducing manual efforts. Our approach consists of two steps: First, we harness\nthe commonsense knowledge of large language models for targeted app\nexploration, supplemented by traditional random exploration to capture a\nbroader range of UI states. Second, we developed a static and dynamic dark\npattern detector powered by a contrastive learning-based multi-label classifier\nand a rule-based refiner to perform detection. We contributed two datasets,\nAppRay-Dark and AppRay-Light, with 2,185 unique deceptive patterns (including\n149 dynamic instances) across 18 types from 876 UIs and 871 benign UIs. These\ndatasets cover both static and dynamic dark patterns while preserving UI\nrelationships. Experimental results confirm that AppRay can efficiently explore\nthe app and identify a wide range of dark patterns with great performance.",
      "tldr_zh": "本研究探讨了移动应用中常见的暗模式（dark patterns），如视觉欺骗和语言诱导，这些模式操纵用户行为，但现有检测方法多依赖耗时的手动过程。论文提出AppRay系统，通过结合大语言模型（large language models）的常识知识进行任务导向的app探索，并辅以随机探索，以捕捉更广泛的UI状态。随后，使用基于对比学习（contrastive learning）的多标签分类器和规则-based精炼器，实现静态和动态暗模式的自动检测。研究贡献了AppRay-Dark和AppRay-Light两个数据集，涵盖2,185个独特欺骗模式（包括149个动态实例）来自876个UI和871个良性UI；实验结果显示，AppRay能高效探索应用并准确识别多种暗模式。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.HC",
        "D.2; I.2; H.5"
      ],
      "primary_category": "cs.SE",
      "comment": "12 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.18084v1",
      "published_date": "2024-11-27 06:39:35 UTC",
      "updated_date": "2024-11-27 06:39:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T05:09:40.988588"
    },
    {
      "arxiv_id": "2411.18073v1",
      "title": "DuMapper: Towards Automatic Verification of Large-Scale POIs with Street Views at Baidu Maps",
      "title_zh": "翻译失败",
      "authors": [
        "Miao Fan",
        "Jizhou Huang",
        "Haifeng Wang"
      ],
      "abstract": "With the increased popularity of mobile devices, Web mapping services have\nbecome an indispensable tool in our daily lives. To provide user-satisfied\nservices, such as location searches, the point of interest (POI) database is\nthe fundamental infrastructure, as it archives multimodal information on\nbillions of geographic locations closely related to people's lives, such as a\nshop or a bank. Therefore, verifying the correctness of a large-scale POI\ndatabase is vital. To achieve this goal, many industrial companies adopt\nvolunteered geographic information (VGI) platforms that enable thousands of\ncrowdworkers and expert mappers to verify POIs seamlessly; but to do so, they\nhave to spend millions of dollars every year. To save the tremendous labor\ncosts, we devised DuMapper, an automatic system for large-scale POI\nverification with the multimodal street-view data at Baidu Maps. DuMapper takes\nthe signboard image and the coordinates of a real-world place as input to\ngenerate a low-dimensional vector, which can be leveraged by ANN algorithms to\nconduct a more accurate search through billions of archived POIs in the\ndatabase for verification within milliseconds. It can significantly increase\nthe throughput of POI verification by $50$ times. DuMapper has already been\ndeployed in production since \\DuMPOnline, which dramatically improves the\nproductivity and efficiency of POI verification at Baidu Maps. As of December\n31, 2021, it has enacted over $405$ million iterations of POI verification\nwithin a 3.5-year period, representing an approximate workload of $800$\nhigh-performance expert mappers.",
      "tldr_zh": "该论文提出 DuMapper 系统，旨在自动验证大规模 POI（点 of interest）数据库，利用街景数据减少人工验证成本。DuMapper 以街景图像和坐标作为输入，生成低维向量，并结合 ANN（Approximate Nearest Neighbors）算法在数以亿计的 POI 数据库中进行快速搜索和验证，大幅提升效率。实验结果显示，该系统将 POI 验证吞吐量提高了 50 倍，已在 Baidu Maps 实际部署，自上线以来处理了超过 4.05 亿次验证，相当于 800 名专家的工作量。",
      "categories": [
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.18073v1",
      "published_date": "2024-11-27 05:54:33 UTC",
      "updated_date": "2024-11-27 05:54:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T05:09:53.141457"
    },
    {
      "arxiv_id": "2411.18071v1",
      "title": "Simulating Tabular Datasets through LLMs to Rapidly Explore Hypotheses about Real-World Entities",
      "title_zh": "通过大型语言模型模拟表格数据集，以快速探索真实世界实体的假设",
      "authors": [
        "Miguel Zabaleta",
        "Joel Lehman"
      ],
      "abstract": "Do horror writers have worse childhoods than other writers? Though\nbiographical details are known about many writers, quantitatively exploring\nsuch a qualitative hypothesis requires significant human effort, e.g. to sift\nthrough many biographies and interviews of writers and to iteratively search\nfor quantitative features that reflect what is qualitatively of interest. This\npaper explores the potential to quickly prototype these kinds of hypotheses\nthrough (1) applying LLMs to estimate properties of concrete entities like\nspecific people, companies, books, kinds of animals, and countries; (2)\nperforming off-the-shelf analysis methods to reveal possible relationships\namong such properties (e.g. linear regression); and towards further automation,\n(3) applying LLMs to suggest the quantitative properties themselves that could\nhelp ground a particular qualitative hypothesis (e.g. number of adverse\nchildhood events, in the context of the running example). The hope is to allow\nsifting through hypotheses more quickly through collaboration between human and\nmachine. Our experiments highlight that indeed, LLMs can serve as useful\nestimators of tabular data about specific entities across a range of domains,\nand that such estimations improve with model scale. Further, initial\nexperiments demonstrate the potential of LLMs to map a qualitative hypothesis\nof interest to relevant concrete variables that the LLM can then estimate. The\nconclusion is that LLMs offer intriguing potential to help illuminate\nscientifically interesting patterns latent within the internet-scale data they\nare trained upon.",
      "tldr_zh": "本论文提出了一种使用LLMs（Large Language Models）模拟表格数据集的方法，以快速探索真实世界实体的假设，例如评估恐怖作家是否比其他作家有更糟糕的童年。方法包括应用LLMs估计具体实体的属性（如人、公司或书籍）、使用现成分析工具（如线性回归）揭示属性关系，以及让LLMs自动建议相关量化变量来支撑定性假设。实验结果显示，LLMs在跨领域估计表格数据方面表现出色，随着模型规模增大而提升精度，且能有效将定性假设映射到具体变量，从而帮助人类更高效地发现互联网规模数据中的潜在科学模式。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.18071v1",
      "published_date": "2024-11-27 05:48:44 UTC",
      "updated_date": "2024-11-27 05:48:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T05:10:05.099832"
    },
    {
      "arxiv_id": "2411.18068v2",
      "title": "PersonaCraft: Personalized and Controllable Full-Body Multi-Human Scene Generation Using Occlusion-Aware 3D-Conditioned Diffusion",
      "title_zh": "翻译失败",
      "authors": [
        "Gwanghyun Kim",
        "Suh Yoon Jeon",
        "Seunggyu Lee",
        "Se Young Chun"
      ],
      "abstract": "We present PersonaCraft, a framework for controllable and occlusion-robust\nfull-body personalized image synthesis of multiple individuals in complex\nscenes. Current methods struggle with occlusion-heavy scenarios and complete\nbody personalization, as 2D pose conditioning lacks 3D geometry, often leading\nto ambiguous occlusions and anatomical distortions, and many approaches focus\nsolely on facial identity. In contrast, our PersonaCraft integrates diffusion\nmodels with 3D human modeling, employing SMPLx-ControlNet, to utilize 3D\ngeometry like depth and normal maps for robust 3D-aware pose conditioning and\nenhanced anatomical coherence. To handle fine-grained occlusions, we propose\nOcclusion Boundary Enhancer Network that exploits depth edge signals with\nocclusion-focused training, and Occlusion-Aware Classifier-Free Guidance\nstrategy that selectively reinforces conditioning in occluded regions without\naffecting unoccluded areas. PersonaCraft can seamlessly be combined with Face\nIdentity ControlNet, achieving full-body multi-human personalization and thus\nmarking a significant advancement beyond prior approaches that concentrate only\non facial identity. Our dual-pathway body shape representation with SMPLx-based\nshape parameters and textual refinement, enables precise full-body\npersonalization and flexible user-defined body shape adjustments. Extensive\nquantitative experiments and user studies demonstrate that PersonaCraft\nsignificantly outperforms existing methods in generating high-quality,\nmulti-person images with accurate personalization and robust occlusion\nhandling.",
      "tldr_zh": "我们提出了 PersonaCraft 框架，用于可控且对遮挡鲁棒的全身个性化多人类图像合成，解决了现有方法在遮挡场景和解剖一致性上的不足。 该框架整合扩散模型与 3D 人体建模（如 SMPLx-ControlNet），利用深度和法线图进行 3D 感知姿势条件，并引入 Occlusion Boundary Enhancer Network 和 Occlusion-Aware Classifier-Free Guidance 来处理细粒度遮挡。 此外，PersonaCraft 支持双路径身体形状表示（基于 SMPLx 参数和文本细化），实现精确的全身个性化并允许用户自定义调整。 实验结果表明，该框架在多人类图像生成中显著优于现有方法，提供更高质量的个性化结果和服务遮挡处理。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Project page: https://gwang-kim.github.io/persona_craft",
      "pdf_url": "http://arxiv.org/pdf/2411.18068v2",
      "published_date": "2024-11-27 05:41:15 UTC",
      "updated_date": "2025-03-14 02:05:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T05:10:18.876021"
    },
    {
      "arxiv_id": "2411.18653v1",
      "title": "PRSI: Privacy-Preserving Recommendation Model Based on Vector Splitting and Interactive Protocols",
      "title_zh": "PRSI: 基于向量分割和交互协议的隐私保护推荐模型",
      "authors": [
        "Xiaokai Cao",
        "Wenjin Mo",
        "Zhenyu He",
        "Changdong Wang"
      ],
      "abstract": "With the development of the internet, recommending interesting products to\nusers has become a highly valuable research topic for businesses.\nRecommendation systems play a crucial role in addressing this issue. To prevent\nthe leakage of each user's (client's) private data, Federated Recommendation\nSystems (FedRec) have been proposed and widely used. However, extensive\nresearch has shown that FedRec suffers from security issues such as data\nprivacy leakage, and it is challenging to train effective models with FedRec\nwhen each client only holds interaction information for a single user. To\naddress these two problems, this paper proposes a new privacy-preserving\nrecommendation system (PRSI), which includes a preprocessing module and two\nmain phases. The preprocessing module employs split vectors and fake\ninteraction items to protect clients' interaction information and\nrecommendation results. The two main phases are: (1) the collection of\ninteraction information and (2) the sending of recommendation results. In the\ninteraction information collection phase, each client uses the preprocessing\nmodule and random communication methods (according to the designed interactive\nprotocol) to protect their ID information and IP addresses. In the\nrecommendation results sending phase, the central server uses the preprocessing\nmodule and triplets to distribute recommendation results to each client under\nsecure conditions, following the designed interactive protocol. Finally, we\nconducted multiple sets of experiments to verify the security, accuracy, and\ncommunication cost of the proposed method.",
      "tldr_zh": "该论文提出了一种隐私保护推荐系统PRSI，旨在解决Federated Recommendation Systems (FedRec)中的数据隐私泄露问题，以及客户端仅持有单个用户交互信息时模型训练的挑战。PRSI包括一个预处理模块和两个主要阶段：预处理模块使用vector splitting和fake interaction items来保护交互信息和推荐结果；第一阶段通过交互协议的随机通信方法收集交互信息，保护客户端的ID和IP地址；第二阶段则由中央服务器利用预处理模块和triplets安全分发推荐结果。实验结果验证了PRSI在security、accuracy和communication cost方面的有效性，提高了推荐系统的隐私保护水平。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.18653v1",
      "published_date": "2024-11-27 05:14:15 UTC",
      "updated_date": "2024-11-27 05:14:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T05:10:29.942591"
    },
    {
      "arxiv_id": "2411.18050v1",
      "title": "RL for Mitigating Cascading Failures: Targeted Exploration via Sensitivity Factors",
      "title_zh": "用于缓解级联故障的强化学习：通过敏感性因素的针对性探索",
      "authors": [
        "Anmol Dwivedi",
        "Ali Tajer",
        "Santiago Paternain",
        "Nurali Virani"
      ],
      "abstract": "Electricity grid's resiliency and climate change strongly impact one another\ndue to an array of technical and policy-related decisions that impact both.\nThis paper introduces a physics-informed machine learning-based framework to\nenhance grid's resiliency. Specifically, when encountering disruptive events,\nthis paper designs remedial control actions to prevent blackouts. The proposed\nPhysics-Guided Reinforcement Learning (PG-RL) framework determines effective\nreal-time remedial line-switching actions, considering their impact on power\nbalance, system security, and grid reliability. To identify an effective\nblackout mitigation policy, PG-RL leverages power-flow sensitivity factors to\nguide the RL exploration during agent training. Comprehensive evaluations using\nthe Grid2Op platform demonstrate that incorporating physical signals into RL\nsignificantly improves resource utilization within electric grids and achieves\nbetter blackout mitigation policies - both of which are critical in addressing\nclimate change.",
      "tldr_zh": "本研究提出了一种基于物理指导的强化学习(Physics-Guided Reinforcement Learning, PG-RL)框架，用于缓解电力网格的级联故障，从而提升电网弹性并应对气候变化的影响。该框架通过利用power-flow sensitivity factors来指导RL代理的针对性探索，设计实时补救措施如线路切换，以维护电力平衡、系统安全和可靠性。在Grid2Op平台的全面评估中，PG-RL显著提高了资源利用率，并实现了更有效的blackout mitigation policies，为气候变化相关问题提供了关键解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.18050v1",
      "published_date": "2024-11-27 04:34:31 UTC",
      "updated_date": "2024-11-27 04:34:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T05:10:41.305783"
    },
    {
      "arxiv_id": "2411.18043v1",
      "title": "Heterogeneous Relationships of Subjects and Shapelets for Semi-supervised Multivariate Series Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Mingsen Du",
        "Meng Chen",
        "Yongjian Li",
        "Cun Ji",
        "Shoushui Wei"
      ],
      "abstract": "Multivariate time series (MTS) classification is widely applied in fields\nsuch as industry, healthcare, and finance, aiming to extract key features from\ncomplex time series data for accurate decision-making and prediction. However,\nexisting methods for MTS often struggle due to the challenges of effectively\nmodeling high-dimensional data and the lack of labeled data, resulting in poor\nclassification performance. To address this issue, we propose a heterogeneous\nrelationships of subjects and shapelets method for semi-supervised MTS\nclassification. This method offers a novel perspective by integrating various\ntypes of additional information while capturing the relationships between them.\nSpecifically, we first utilize a contrast temporal self-attention module to\nobtain sparse MTS representations, and then model the similarities between\nthese representations using soft dynamic time warping to construct a similarity\ngraph. Secondly, we learn the shapelets for different subject types,\nincorporating both the subject features and their shapelets as additional\ninformation to further refine the similarity graph, ultimately generating a\nheterogeneous graph. Finally, we use a dual level graph attention network to\nget prediction. Through this method, we successfully transform dataset into a\nheterogeneous graph, integrating multiple additional information and achieving\nprecise semi-supervised node classification. Experiments on the Human Activity\nRecognition, sleep stage classification and University of East Anglia datasets\ndemonstrate that our method outperforms current state-of-the-art methods in MTS\nclassification tasks, validating its superiority.",
      "tldr_zh": "本研究针对多变量时间序列 (Multivariate Time Series, MTS) 分类问题，提出了一种基于半监督学习的 \"heterogeneous relationships of subjects and shapelets\" 方法，以解决高维数据建模和标签数据不足的挑战。该方法首先通过 contrast temporal self-attention module 获取稀疏 MTS 表示，并使用 soft dynamic time warping 构建相似图，然后整合 subject features 和 shapelets 生成 heterogeneous graph，最后采用 dual level graph attention network 进行预测。实验结果显示，该方法在 Human Activity Recognition、睡眠阶段分类和 University of East Anglia 数据集上优于现有最先进方法，证明了其在精确半监督节点分类方面的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Submitted to IEEE International Conference on Data Engineering (ICDE)\n  2025",
      "pdf_url": "http://arxiv.org/pdf/2411.18043v1",
      "published_date": "2024-11-27 04:25:13 UTC",
      "updated_date": "2024-11-27 04:25:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T05:10:54.150909"
    },
    {
      "arxiv_id": "2411.18038v1",
      "title": "VLM-HOI: Vision Language Models for Interpretable Human-Object Interaction Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Donggoo Kang",
        "Dasol Jeong",
        "Hyunmin Lee",
        "Sangwoo Park",
        "Hasil Park",
        "Sunkyu Kwon",
        "Yeongjoon Kim",
        "Joonki Paik"
      ],
      "abstract": "The Large Vision Language Model (VLM) has recently addressed remarkable\nprogress in bridging two fundamental modalities. VLM, trained by a sufficiently\nlarge dataset, exhibits a comprehensive understanding of both visual and\nlinguistic to perform diverse tasks. To distill this knowledge accurately, in\nthis paper, we introduce a novel approach that explicitly utilizes VLM as an\nobjective function form for the Human-Object Interaction (HOI) detection task\n(\\textbf{VLM-HOI}). Specifically, we propose a method that quantifies the\nsimilarity of the predicted HOI triplet using the Image-Text matching\ntechnique. We represent HOI triplets linguistically to fully utilize the\nlanguage comprehension of VLMs, which are more suitable than CLIP models due to\ntheir localization and object-centric nature. This matching score is used as an\nobjective for contrastive optimization. To our knowledge, this is the first\nutilization of VLM language abilities for HOI detection. Experiments\ndemonstrate the effectiveness of our method, achieving state-of-the-art HOI\ndetection accuracy on benchmarks. We believe integrating VLMs into HOI\ndetection represents important progress towards more advanced and interpretable\nanalysis of human-object interactions.",
      "tldr_zh": "本研究提出了一种名为 VLM-HOI 的新方法，利用大型视觉语言模型 (VLM) 作为 Human-Object Interaction (HOI) 检测任务的目标函数，以提升分析的可解释性。具体而言，该方法通过图像-文本匹配技术量化预测 HOI 三元组的相似度，并将 HOI 三元组表示为语言形式，利用 VLM 的语言理解能力进行对比优化 (contrastive optimization)，从而更好地处理 HOI 检测。实验结果显示，该方法在基准测试中实现了最先进的 HOI 检测准确率，这是首次将 VLM 的语言能力应用于该领域。整体上，这代表了向更高级和可解释的人-物交互分析的重要进展。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "18 pages",
      "pdf_url": "http://arxiv.org/pdf/2411.18038v1",
      "published_date": "2024-11-27 04:13:23 UTC",
      "updated_date": "2024-11-27 04:13:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T05:11:05.993155"
    },
    {
      "arxiv_id": "2411.18015v1",
      "title": "AEGIS: An Agent-based Framework for General Bug Reproduction from Issue Descriptions",
      "title_zh": "AEGIS：一个基于代理的框架，用于从问题描述进行通用错误重现",
      "authors": [
        "Xinchen Wang",
        "Pengfei Gao",
        "Xiangxin Meng",
        "Chao Peng",
        "Ruida Hu",
        "Yun Lin",
        "Cuiyun Gao"
      ],
      "abstract": "In software maintenance, bug reproduction is essential for effective fault\nlocalization and repair. Manually writing reproduction scripts is a\ntime-consuming task with high requirements for developers. Hence, automation of\nbug reproduction has increasingly attracted attention from researchers and\npractitioners. However, the existing studies on bug reproduction are generally\nlimited to specific bug types such as program crashes, and hard to be applied\nto general bug reproduction. In this paper, considering the superior\nperformance of agent-based methods in code intelligence tasks, we focus on\ndesigning an agent-based framework for the task. Directly employing agents\nwould lead to limited bug reproduction performance, due to entangled subtasks,\nlengthy retrieved context, and unregulated actions. To mitigate the challenges,\nwe propose an Automated gEneral buG reproductIon Scripts generation framework,\nnamed AEGIS, which is the first agent-based framework for the task. AEGIS\nmainly contains two modules: (1) A concise context construction module, which\naims to guide the code agent in extracting structured information from issue\ndescriptions, identifying issue-related code with detailed explanations, and\nintegrating these elements to construct the concise context; (2) A FSM-based\nmulti-feedback optimization module to further regulate the behavior of the code\nagent within the finite state machine (FSM), ensuring a controlled and\nefficient script generation process based on multi-dimensional feedback.\nExtensive experiments on the public benchmark dataset show that AEGIS\noutperforms the state-of-the-art baseline by 23.0% in F->P metric. In addition,\nthe bug reproduction scripts generated by AEGIS can improve the relative\nresolved rate of Agentless by 12.5%.",
      "tldr_zh": "该论文提出 AEGIS，这是一个 agent-based 框架，用于从问题描述自动生成一般 bug 复现脚本，旨在解决现有方法局限于特定 bug 类型（如程序崩溃）的局限性。框架包括两个核心模块：简洁上下文构建模块，用于从问题描述提取结构化信息和相关代码以构建简明上下文；以及 FSM-based 多反馈优化模块，通过有限状态机（FSM）调节代理行为，确保脚本生成过程高效且可控。实验结果显示，AEGIS 在公共基准数据集上比最先进基线提高 23.0% 的 F->P metric，并将 Agentless 的相对解决率提升 12.5%。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.18015v1",
      "published_date": "2024-11-27 03:16:47 UTC",
      "updated_date": "2024-11-27 03:16:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T05:11:18.754702"
    },
    {
      "arxiv_id": "2411.18008v1",
      "title": "Causal and Local Correlations Based Network for Multivariate Time Series Classification",
      "title_zh": "基于因果和局部相关性的多变量时间序列分类网络",
      "authors": [
        "Mingsen Du",
        "Yanxuan Wei",
        "Xiangwei Zheng",
        "Cun Ji"
      ],
      "abstract": "Recently, time series classification has attracted the attention of a large\nnumber of researchers, and hundreds of methods have been proposed. However,\nthese methods often ignore the spatial correlations among dimensions and the\nlocal correlations among features. To address this issue, the causal and local\ncorrelations based network (CaLoNet) is proposed in this study for multivariate\ntime series classification. First, pairwise spatial correlations between\ndimensions are modeled using causality modeling to obtain the graph structure.\nThen, a relationship extraction network is used to fuse local correlations to\nobtain long-term dependency features. Finally, the graph structure and\nlong-term dependency features are integrated into the graph neural network.\nExperiments on the UEA datasets show that CaLoNet can obtain competitive\nperformance compared with state-of-the-art methods.",
      "tldr_zh": "本研究针对多变量时间序列分类(Multivariate Time Series Classification)问题，指出现有方法忽略了维度间的空间相关性和特征间的局部相关性，从而提出了一种基于因果和局部相关性的网络(CaLoNet)。该方法首先使用因果建模(causality modeling)来构建维度间的图结构，然后通过关系提取网络融合局部相关性以提取长期依赖特征，最后将这些元素整合到图神经网络(Graph Neural Network)中进行分类。实验结果显示，在UEA数据集上，CaLoNet与最先进方法相比取得了竞争性的性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ME",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Submitted on April 03, 2023; major revisions on March 25, 2024; minor\n  revisions on July 9, 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.18008v1",
      "published_date": "2024-11-27 02:54:26 UTC",
      "updated_date": "2024-11-27 02:54:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T05:11:30.036626"
    },
    {
      "arxiv_id": "2411.18003v3",
      "title": "HAAT: Hybrid Attention Aggregation Transformer for Image Super-Resolution",
      "title_zh": "HAAT：混合注意聚合 Transformer 用于图像超分辨率",
      "authors": [
        "Song-Jiang Lai",
        "Tsun-Hin Cheung",
        "Ka-Chun Fung",
        "Kai-wen Xue",
        "Kin-Man Lam"
      ],
      "abstract": "In the research area of image super-resolution, Swin-transformer-based models\nare favored for their global spatial modeling and shifting window attention\nmechanism. However, existing methods often limit self-attention to non\noverlapping windows to cut costs and ignore the useful information that exists\nacross channels. To address this issue, this paper introduces a novel model,\nthe Hybrid Attention Aggregation Transformer (HAAT), designed to better\nleverage feature information. HAAT is constructed by integrating\nSwin-Dense-Residual-Connected Blocks (SDRCB) with Hybrid Grid Attention Blocks\n(HGAB). SDRCB expands the receptive field while maintaining a streamlined\narchitecture, resulting in enhanced performance. HGAB incorporates channel\nattention, sparse attention, and window attention to improve nonlocal feature\nfusion and achieve more visually compelling results. Experimental evaluations\ndemonstrate that HAAT surpasses state-of-the-art methods on benchmark datasets.\nKeywords: Image super-resolution, Computer vision, Attention mechanism,\nTransformer",
      "tldr_zh": "本论文提出了一种新型模型Hybrid Attention Aggregation Transformer (HAAT)，用于图像超分辨率 (Image Super-Resolution)，旨在解决现有Swin-transformer-based方法仅限于非重叠窗口自注意力而忽略跨通道信息的局限性。HAAT通过整合Swin-Dense-Residual-Connected Blocks (SDRCB)来扩展感受野并保持架构简洁，以及Hybrid Grid Attention Blocks (HGAB)来结合channel attention、sparse attention和window attention，从而改善非局部特征融合并提升视觉效果。在基准数据集上的实验评估显示，HAAT超越了最先进的方法，证明了其在计算机视觉领域的显著性能提升。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "6 pages, 2 figures, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2411.18003v3",
      "published_date": "2024-11-27 02:47:17 UTC",
      "updated_date": "2024-12-10 06:39:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T05:11:41.872418"
    },
    {
      "arxiv_id": "2411.18002v1",
      "title": "An End-to-End Two-Stream Network Based on RGB Flow and Representation Flow for Human Action Recognition",
      "title_zh": "基于 RGB 流和表示流的端到端双流网络，用于人类",
      "authors": [
        "Song-Jiang Lai",
        "Tsun-Hin Cheung",
        "Ka-Chun Fung",
        "Tian-Shan Liu",
        "Kin-Man Lam"
      ],
      "abstract": "With the rapid advancements in deep learning, computer vision tasks have seen\nsignificant improvements, making two-stream neural networks a popular focus for\nvideo based action recognition. Traditional models using RGB and optical flow\nstreams achieve strong performance but at a high computational cost. To address\nthis, we introduce a representation flow algorithm to replace the optical flow\nbranch in the egocentric action recognition model, enabling end-to-end training\nwhile reducing computational cost and prediction time. Our model, designed for\negocentric action recognition, uses class activation maps (CAMs) to improve\naccuracy and ConvLSTM for spatio temporal encoding with spatial attention. When\nevaluated on the GTEA61, EGTEA GAZE+, and HMDB datasets, our model matches the\naccuracy of the original model on GTEA61 and exceeds it by 0.65% and 0.84% on\nEGTEA GAZE+ and HMDB, respectively. Prediction runtimes are significantly\nreduced to 0.1881s, 0.1503s, and 0.1459s, compared to the original model's\n101.6795s, 25.3799s, and 203.9958s. Ablation studies were also conducted to\nstudy the impact of different parameters on model performance.\n  Keywords: two-stream, egocentric, action recognition, CAM, representation\nflow, CAM, ConvLSTM",
      "tldr_zh": "本研究提出了一种端到-End Two-Stream Network，用于人类动作识别，通过使用 RGB Flow 和 Representation Flow 替换传统的光学流分支，实现了端到端训练并显著降低计算成本和预测时间。该模型针对第一人称（egocentric）动作识别，结合类激活映射（CAMs）提升准确性，并采用 ConvLSTM 进行时空编码和空间注意力机制。在 GTEA61、EGTEA GAZE+ 和 HMDB 数据集上，模型在 GTEA61 上与原模型准确率相当，在 EGTEA GAZE+ 和 HMDB 上分别提高了 0.65% 和 0.84%，同时预测时间从原模型的 101.6795s、25.3799s 和 203.9958s 降至 0.1881s、0.1503s 和 0.1459s。通过消融研究，验证了不同参数对性能的影响。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "6 pages, 3 figures, 9 tables",
      "pdf_url": "http://arxiv.org/pdf/2411.18002v1",
      "published_date": "2024-11-27 02:46:46 UTC",
      "updated_date": "2024-11-27 02:46:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T05:11:54.866710"
    },
    {
      "arxiv_id": "2411.17999v1",
      "title": "A Novel Pareto-optimal Ranking Method for Comparing Multi-objective Optimization Algorithms",
      "title_zh": "一种用于比较多目标优化算法的新颖Pareto最优排名方法",
      "authors": [
        "Amin Ibrahim",
        "Azam Asilian Bidgoli",
        "Shahryar Rahnamayan",
        "Kalyanmoy Deb"
      ],
      "abstract": "As the interest in multi- and many-objective optimization algorithms grows,\nthe performance comparison of these algorithms becomes increasingly important.\nA large number of performance indicators for multi-objective optimization\nalgorithms have been introduced, each of which evaluates these algorithms based\non a certain aspect. Therefore, assessing the quality of multi-objective\nresults using multiple indicators is essential to guarantee that the evaluation\nconsiders all quality perspectives. This paper proposes a novel multi-metric\ncomparison method to rank the performance of multi-/ many-objective\noptimization algorithms based on a set of performance indicators. We utilize\nthe Pareto optimality concept (i.e., non-dominated sorting algorithm) to create\nthe rank levels of algorithms by simultaneously considering multiple\nperformance indicators as criteria/objectives. As a result, four different\ntechniques are proposed to rank algorithms based on their contribution at each\nPareto level. This method allows researchers to utilize a set of existing/newly\ndeveloped performance metrics to adequately assess/rank multi-/many-objective\nalgorithms. The proposed methods are scalable and can accommodate in its\ncomprehensive scheme any newly introduced metric. The method was applied to\nrank 10 competing algorithms in the 2018 CEC competition solving 15\nmany-objective test problems. The Pareto-optimal ranking was conducted based on\n10 well-known multi-objective performance indicators and the results were\ncompared to the final ranks reported by the competition, which were based on\nthe inverted generational distance (IGD) and hypervolume indicator (HV)\nmeasures. The techniques suggested in this paper have broad applications in\nscience and engineering, particularly in areas where multiple metrics are used\nfor comparisons. Examples include machine learning and data mining.",
      "tldr_zh": "这篇论文提出了一种新型 Pareto-optimal 排名方法，用于比较多目标优化算法的性能。该方法利用非支配排序算法，同时考虑多个性能指标作为优化目标，创建算法的排名层次，并提供了四种技术基于算法在每个 Pareto 水平的贡献进行评估。这种方法可扩展且灵活，能够整合任何现有或新开发的性能指标。在实验中，该方法应用于 2018 CEC 比赛的 10 个算法和 15 个测试问题上，使用 10 个性能指标进行排名，结果显示比基于 IGD 和 hypervolume indicator 的传统排名更全面准确，具有广泛应用潜力，如机器学习和数据挖掘领域。",
      "categories": [
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.17999v1",
      "published_date": "2024-11-27 02:34:54 UTC",
      "updated_date": "2024-11-27 02:34:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T05:12:06.033746"
    },
    {
      "arxiv_id": "2411.17989v1",
      "title": "Regularized Multi-LLMs Collaboration for Enhanced Score-based Causal Discovery",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaoxuan Li",
        "Yao Liu",
        "Ruoyu Wang",
        "Lina Yao"
      ],
      "abstract": "As the significance of understanding the cause-and-effect relationships among\nvariables increases in the development of modern systems and algorithms,\nlearning causality from observational data has become a preferred and efficient\napproach over conducting randomized control trials. However, purely\nobservational data could be insufficient to reconstruct the true causal graph.\nConsequently, many researchers tried to utilise some form of prior knowledge to\nimprove causal discovery process. In this context, the impressive capabilities\nof large language models (LLMs) have emerged as a promising alternative to the\ncostly acquisition of prior expert knowledge. In this work, we further explore\nthe potential of using LLMs to enhance causal discovery approaches,\nparticularly focusing on score-based methods, and we propose a general\nframework to utilise the capacity of not only one but multiple LLMs to augment\nthe discovery process.",
      "tldr_zh": "该论文探讨了从观察数据中学习因果关系（causal discovery）的挑战，指出纯观察数据可能不足以重建真实因果图，因此需要整合先验知识来提升发现过程。作者提出一个通用框架，利用多个大型语言模型（LLMs）的协作，结合正则化技术来增强基于分数的因果发现方法（score-based methods）。这种多 LLMs 协作方法有望降低对专家知识的依赖，提供更高效和准确的因果图重建，为现代系统和算法的发展提供新途径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ME"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.17989v1",
      "published_date": "2024-11-27 01:56:21 UTC",
      "updated_date": "2024-11-27 01:56:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T05:12:17.221278"
    },
    {
      "arxiv_id": "2411.17983v1",
      "title": "Optimized Conformal Selection: Powerful Selective Inference After Conformity Score Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Tian Bai",
        "Ying Jin"
      ],
      "abstract": "Model selection/optimization in conformal inference is challenging, since it\nmay break the exchangeability between labeled and unlabeled data. We study this\nproblem in the context of conformal selection, which uses conformal p-values to\nselect ``interesting'' instances with large unobserved labels from a pool of\nunlabeled data, while controlling the FDR in finite sample. For validity,\nexisting solutions require the model choice to be independent of the data used\nto construct the p-values and calibrate the selection set. However, when\npresented with many model choices and limited labeled data, it is desirable to\n(i) select the best model in a data-driven manner, and (ii) mitigate power loss\ndue to sample splitting.\n  This paper presents OptCS, a general framework that allows valid statistical\ntesting (selection) after flexible data-driven model optimization. We introduce\ngeneral conditions under which OptCS constructs valid conformal p-values\ndespite substantial data reuse and handles complex p-value dependencies to\nmaintain finite-sample FDR control via a novel multiple testing procedure. We\ninstantiate this general recipe to propose three FDR-controlling procedures,\neach optimizing the models differently: (i) selecting the most powerful one\namong multiple pre-trained candidate models, (ii) using all data for model\nfitting without sample splitting, and (iii) combining full-sample model fitting\nand selection. We demonstrate the efficacy of our methods via simulation\nstudies and real applications in drug discovery and alignment of large language\nmodels in radiology report generation.",
      "tldr_zh": "本文提出OptCS框架，用于解决conformal inference中模型优化可能破坏数据可交换性的问题，允许在数据驱动方式下进行有效的统计测试和选择，同时维持有限样本中的FDR控制。OptCS引入一般条件和一个新颖的多重测试程序，以处理p-value依赖性和数据重用，支持三种优化过程：从多个预训练候选模型中选择最强大的一个、使用全样本数据拟合模型，或结合两者。实验结果通过模拟研究和实际应用（如药物发现和放射学报告生成的LLM对齐）证明了OptCS显著提升了方法的强大性和实用性。",
      "categories": [
        "stat.ME",
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "stat.ME",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.17983v1",
      "published_date": "2024-11-27 01:40:50 UTC",
      "updated_date": "2024-11-27 01:40:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T05:12:30.930795"
    },
    {
      "arxiv_id": "2412.00083v3",
      "title": "Visual Error Patterns in Multi-Modal AI: A Statistical Approach",
      "title_zh": "多模态人工智能中的视觉错误模式：一种统计学方法",
      "authors": [
        "Ching-Yi Wang"
      ],
      "abstract": "Multi-modal large language models (MLLMs), such as GPT-4o, excel at\nintegrating text and visual data but face systematic challenges when\ninterpreting ambiguous or incomplete visual stimuli. This study leverages\nstatistical modeling to analyze the factors driving these errors, using a\ndataset of geometric stimuli characterized by features like 3D, rotation, and\nmissing face/side. We applied parametric methods, non-parametric methods, and\nensemble techniques to predict classification errors, with the non-linear\ngradient boosting model achieving the highest performance (AUC=0.85) during\ncross-validation. Feature importance analysis highlighted difficulties in depth\nperception and reconstructing incomplete structures as key contributors to\nmisclassification. These findings demonstrate the effectiveness of statistical\napproaches for uncovering limitations in MLLMs and offer actionable insights\nfor enhancing model architectures by integrating contextual reasoning\nmechanisms.",
      "tldr_zh": "本研究分析了多模态大语言模型 (MLLMs) 如 GPT-4o 在处理模糊或不完整视觉刺激时的系统性错误，采用统计建模方法来识别错误驱动因素。研究基于一个包含3D、旋转和缺失面/侧等特征的几何刺激数据集，应用参数方法、非参数方法和集成技术进行分类错误预测，其中非线性梯度提升模型在交叉验证中表现最佳（AUC=0.85）。特征重要性分析揭示，深度感知困难和重建不完整结构是主要误分类原因。这些发现证明了统计方法在揭示MLLMs局限性的有效性，并为通过整合上下文推理机制来改进模型架构提供了实际见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "stat.AP"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.00083v3",
      "published_date": "2024-11-27 01:20:08 UTC",
      "updated_date": "2024-12-06 02:01:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T05:12:43.322750"
    },
    {
      "arxiv_id": "2411.17976v3",
      "title": "The importance of visual modelling languages in generative software engineering",
      "title_zh": "翻译失败",
      "authors": [
        "Roberto Rossi"
      ],
      "abstract": "Multimodal GPTs represent a watershed in the interplay between Software\nEngineering and Generative Artificial Intelligence. GPT-4 accepts image and\ntext inputs, rather than simply natural language. We investigate relevant use\ncases stemming from these enhanced capabilities of GPT-4. To the best of our\nknowledge, no other work has investigated similar use cases involving Software\nEngineering tasks carried out via multimodal GPTs prompted with a mix of\ndiagrams and natural language.",
      "tldr_zh": "本文讨论了视觉建模语言(visual modelling languages)在生成式软件工程中的重要性，特别是 Multimodal GPTs 在软件工程与生成式人工智能互动中的里程碑作用。研究调查了 GPT-4 处理图像和文本输入的增强能力，探索了相关的软件工程用例，包括通过混合图表和自然语言进行任务。作者指出，这是首次系统性研究此类多模态 GPTs 应用，填补了现有研究的空白。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "9 pages, working paper",
      "pdf_url": "http://arxiv.org/pdf/2411.17976v3",
      "published_date": "2024-11-27 01:15:36 UTC",
      "updated_date": "2025-01-13 17:42:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T05:12:54.417934"
    },
    {
      "arxiv_id": "2411.17973v2",
      "title": "Improved implicit diffusion model with knowledge distillation to estimate the spatial distribution density of carbon stock in remote sensing imagery",
      "title_zh": "改进的隐式扩散模型结合知识蒸馏，用于估计遥感图像中碳储量的空间分布密度",
      "authors": [
        "Zhenyu Yu",
        "Jinnian Wang",
        "Mohd Yamani Idna Idris"
      ],
      "abstract": "The forest serves as the most significant terrestrial carbon stock mechanism,\neffectively reducing atmospheric CO2 concentrations and mitigating climate\nchange. Remote sensing provides high data accuracy and enables large-scale\nobservations. Optical images facilitate long-term monitoring, which is crucial\nfor future carbon stock estimation studies. This study focuses on Huize County,\nQujing City, Yunnan Province, China, utilizing GF-1 WFV satellite imagery. The\nKD-VGG and KD-UNet modules were introduced for initial feature extraction, and\nthe improved implicit diffusion model (IIDM) was proposed. The results showed:\n(1) The VGG module improved initial feature extraction, improving accuracy, and\nreducing inference time with optimized model parameters. (2) The\nCross-attention + MLPs module enabled effective feature fusion, establishing\ncritical relationships between global and local features, achieving\nhigh-accuracy estimation. (3) The IIDM model, a novel contribution,\ndemonstrated the highest estimation accuracy with an RMSE of 12.17%,\nsignificantly improving by 41.69% to 42.33% compared to the regression model.\nIn carbon stock estimation, the generative model excelled in extracting deeper\nfeatures, significantly outperforming other models, demonstrating the\nfeasibility of AI-generated content in quantitative remote sensing. The\n16-meter resolution estimates provide a robust basis for tailoring forest\ncarbon sink regulations, enhancing regional carbon stock management.",
      "tldr_zh": "本研究针对森林碳储量空间分布密度的估算，利用遥感图像（如 GF-1 WFV 卫星图像）提出了一种改进的隐式扩散模型 (IIDM)，结合 knowledge distillation 技术（如 KD-VGG 和 KD-UNet 模块）进行初始特征提取。模型通过 Cross-attention + MLPs 模块实现全局和局部特征的有效融合，提升了估算的准确性和效率。结果显示，IIDM 在会泽县碳储量估计中达到最高精度，RMSE 为 12.17%，较回归模型改善 41.69% 至 42.33%，并证明生成模型在提取深层特征方面优于传统方法，为森林碳汇管理和区域碳储量调控提供了可靠依据。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.17973v2",
      "published_date": "2024-11-27 01:06:05 UTC",
      "updated_date": "2025-04-23 19:50:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T05:13:06.422017"
    },
    {
      "arxiv_id": "2411.17971v1",
      "title": "Graph Neural Network for Cerebral Blood Flow Prediction With Clinical Datasets",
      "title_zh": "翻译失败",
      "authors": [
        "Seungyeon Kim",
        "Wheesung Lee",
        "Sung-Ho Ahn",
        "Do-Eun Lee",
        "Tae-Rin Lee"
      ],
      "abstract": "Accurate prediction of cerebral blood flow is essential for the diagnosis and\ntreatment of cerebrovascular diseases. Traditional computational methods,\nhowever, often incur significant computational costs, limiting their\npracticality in real-time clinical applications. This paper proposes a graph\nneural network (GNN) to predict blood flow and pressure in previously unseen\ncerebral vascular network structures that were not included in training data.\nThe GNN was developed using clinical datasets from patients with stenosis,\nfeaturing complex and abnormal vascular geometries. Additionally, the GNN model\nwas trained on data incorporating a wide range of inflow conditions, vessel\ntopologies, and network connectivities to enhance its generalization\ncapability. The approach achieved Pearson's correlation coefficients of 0.727\nfor pressure and 0.824 for flow rate, with sufficient training data. These\nfindings demonstrate the potential of the GNN for real-time cerebrovascular\ndiagnostics, particularly in handling intricate and pathological vascular\nnetworks.",
      "tldr_zh": "本文提出了一种Graph Neural Network (GNN)模型，用于预测脑血管网络中血流和压力，从而解决传统计算方法在实时临床应用中的高计算成本问题。该模型基于临床数据集训练，包括有狭窄患者的复杂异常血管几何，并整合多种流入条件、血管拓扑和网络连接性，以提升泛化能力。实验结果显示，GNN在压力预测上达到Pearson's correlation coefficient of 0.727，在流量预测上达到0.824，证明其在处理病理血管网络的实时脑血管诊断中具有显著潜力。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CE",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "4 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.17971v1",
      "published_date": "2024-11-27 01:01:37 UTC",
      "updated_date": "2024-11-27 01:01:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T05:13:18.164865"
    },
    {
      "arxiv_id": "2412.00082v1",
      "title": "Dual Prototyping with Domain and Class Prototypes for Affective Brain-Computer Interface in Unseen Target Conditions",
      "title_zh": "翻译失败",
      "authors": [
        "Guangli Li",
        "Zhehao Zhou",
        "Tuo Sun",
        "Ping Tan",
        "Li Zhang",
        "Zhen Liang"
      ],
      "abstract": "EEG signals have emerged as a powerful tool in affective brain-computer\ninterfaces, playing a crucial role in emotion recognition. However, current\ndeep transfer learning-based methods for EEG recognition face challenges due to\nthe reliance of both source and target data in model learning, which\nsignificantly affect model performance and generalization. To overcome this\nlimitation, we propose a novel framework (PL-DCP) and introduce the concepts of\nfeature disentanglement and prototype inference. The dual prototyping mechanism\nincorporates both domain and class prototypes: domain prototypes capture\nindividual variations across subjects, while class prototypes represent the\nideal class distributions within their respective domains. Importantly, the\nproposed PL-DCP framework operates exclusively with source data during\ntraining, meaning that target data remains completely unseen throughout the\nentire process. To address label noise, we employ a pairwise learning strategy\nthat encodes proximity relationships between sample pairs, effectively reducing\nthe influence of mislabeled data. Experimental validation on the SEED and\nSEED-IV datasets demonstrates that PL-DCP, despite not utilizing target data\nduring training, achieves performance comparable to deep transfer learning\nmethods that require both source and target data. This highlights the potential\nof PL-DCP as an effective and robust approach for EEG-based emotion\nrecognition.",
      "tldr_zh": "本研究针对EEG信号在情感脑机接口(affective brain-computer interfaces)中的情感识别问题，提出了一种新框架PL-DCP，以解决现有深度迁移学习方法依赖源和目标数据的局限性。PL-DCP引入feature disentanglement和prototype inference机制，通过domain prototypes捕捉个体间差异，以及class prototypes表示领域内的理想类分布，并在训练时仅使用源数据，避免目标数据(unseen target conditions)的参与；同时采用pairwise learning策略处理标签噪声，编码样本对之间的接近关系以减少误标签影响。在SEED和SEED-IV数据集上的实验表明，PL-DCP不依赖目标数据即可实现与深度迁移学习方法相当的性能，证明其作为EEG-based emotion recognition的有效鲁棒方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.HC",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.00082v1",
      "published_date": "2024-11-27 00:56:43 UTC",
      "updated_date": "2024-11-27 00:56:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T05:13:30.411989"
    },
    {
      "arxiv_id": "2412.09628v2",
      "title": "Bridging AI and Science: Implications from a Large-Scale Literature Analysis of AI4Science",
      "title_zh": "翻译失败",
      "authors": [
        "Yutong Xie",
        "Yijun Pan",
        "Hua Xu",
        "Qiaozhu Mei"
      ],
      "abstract": "Artificial Intelligence has proven to be a transformative tool for advancing\nscientific research across a wide range of disciplines. However, a significant\ngap still exists between AI and scientific communities, limiting the full\npotential of AI methods in driving broad scientific discovery. Existing efforts\nin identifying and bridging this gap have often relied on qualitative\nexamination of small samples of literature, offering a limited perspective on\nthe broader AI4Science landscape. In this work, we present a large-scale\nanalysis of the AI4Science literature, starting by using large language models\nto identify scientific problems and AI methods in publications from top science\nand AI venues. Leveraging this new dataset, we quantitatively highlight key\ndisparities between AI methods and scientific problems, revealing substantial\nopportunities for deeper AI integration across scientific disciplines.\nFurthermore, we explore the potential and challenges of facilitating\ncollaboration between AI and scientific communities through the lens of link\nprediction. Our findings and tools aim to promote more impactful\ninterdisciplinary collaborations and accelerate scientific discovery through\ndeeper and broader AI integration. Our code and dataset are available at:\nhttps://github.com/charles-pyj/Bridging-AI-and-Science.",
      "tldr_zh": "本研究通过大规模文献分析探讨了 AI4Science 领域的现状与挑战，使用 Large Language Models (LLMs) 识别顶级科学和 AI 出版物中的科学问题与 AI 方法，构建了一个新数据集。分析量化揭示了 AI 方法与科学问题之间显著的差异，突显了在各科学学科中深化 AI 整合的机遇。论文进一步通过 link prediction 视角探讨促进 AI 和科学社区协作的潜力与障碍，最终旨在推动更具影响力的跨学科合作，加速科学发现。数据集和代码已在 GitHub 上公开。",
      "categories": [
        "cs.AI",
        "cs.DL",
        "cs.IR"
      ],
      "primary_category": "cs.AI",
      "comment": "22 pages",
      "pdf_url": "http://arxiv.org/pdf/2412.09628v2",
      "published_date": "2024-11-27 00:40:51 UTC",
      "updated_date": "2025-02-18 03:53:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T05:13:41.483741"
    },
    {
      "arxiv_id": "2411.18649v1",
      "title": "Dynamic Logistic Ensembles with Recursive Probability and Automatic Subset Splitting for Enhanced Binary Classification",
      "title_zh": "动态逻辑斯蒂集成模型，结合递归概率和自动子集分割，用于提升二元分类性能",
      "authors": [
        "Mohammad Zubair Khan",
        "David Li"
      ],
      "abstract": "This paper presents a novel approach to binary classification using dynamic\nlogistic ensemble models. The proposed method addresses the challenges posed by\ndatasets containing inherent internal clusters that lack explicit feature-based\nseparations. By extending traditional logistic regression, we develop an\nalgorithm that automatically partitions the dataset into multiple subsets,\nconstructing an ensemble of logistic models to enhance classification accuracy.\nA key innovation in this work is the recursive probability calculation, derived\nthrough algebraic manipulation and mathematical induction, which enables\nscalable and efficient model construction. Compared to traditional ensemble\nmethods such as Bagging and Boosting, our approach maintains interpretability\nwhile offering competitive performance. Furthermore, we systematically employ\nmaximum likelihood and cost functions to facilitate the analytical derivation\nof recursive gradients as functions of ensemble depth. The effectiveness of the\nproposed approach is validated on a custom dataset created by introducing noise\nand shifting data to simulate group structures, resulting in significant\nperformance improvements with layers. Implemented in Python, this work balances\ncomputational efficiency with theoretical rigor, providing a robust and\ninterpretable solution for complex classification tasks with broad implications\nfor machine learning applications. Code at\nhttps://github.com/ensemble-art/Dynamic-Logistic-Ensembles",
      "tldr_zh": "这篇论文提出了一种动态逻辑斯蒂克集成模型，用于提升二元分类性能，特别针对数据集中的内部集群问题，通过自动子集分割和递归概率计算来扩展传统 logistic regression。关键创新包括使用代数操作和数学归纳法推导递归概率，以及基于最大似然和成本函数的递归梯度分析，使模型在保持可解释性的同时实现高效扩展。与 Bagging 和 Boosting 等传统方法相比，该方法在自定义噪声数据集上实现了显著准确率提升。代码已在 GitHub 上开源，提供了一个平衡计算效率和理论严谨性的机器学习解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "8 Pages, 2024 IEEE 15th Annual Ubiquitous Computing, Electronics \\&\n  Mobile Communication Conference (UEMCON)}. Published in the Proceedings of\n  UEMCON 2024, \\c{opyright}2024 IEEE",
      "pdf_url": "http://arxiv.org/pdf/2411.18649v1",
      "published_date": "2024-11-27 00:22:55 UTC",
      "updated_date": "2024-11-27 00:22:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T05:13:54.272852"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 108,
  "processed_papers_count": 108,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-21T05:14:14.225939"
}