[
  {
    "arxiv_id": "2410.13909v1",
    "title": "Large Language Model-driven Multi-Agent Simulation for News Diffusion Under Different Network Structures",
    "authors": [
      "Xinyi Li",
      "Yu Xu",
      "Yongfeng Zhang",
      "Edward C. Malthouse"
    ],
    "abstract": "The proliferation of fake news in the digital age has raised critical\nconcerns, particularly regarding its impact on societal trust and democratic\nprocesses. Diverging from conventional agent-based simulation approaches, this\nwork introduces an innovative approach by employing a large language model\n(LLM)-driven multi-agent simulation to replicate complex interactions within\ninformation ecosystems. We investigate key factors that facilitate news\npropagation, such as agent personalities and network structures, while also\nevaluating strategies to combat misinformation. Through simulations across\nvarying network structures, we demonstrate the potential of LLM-based agents in\nmodeling the dynamics of misinformation spread, validating the influence of\nagent traits on the diffusion process. Our findings emphasize the advantages of\nLLM-based simulations over traditional techniques, as they uncover underlying\ncauses of information spread -- such as agents promoting discussions -- beyond\nthe predefined rules typically employed in existing agent-based models.\nAdditionally, we evaluate three countermeasure strategies, discovering that\nbrute-force blocking influential agents in the network or announcing news\naccuracy can effectively mitigate misinformation. However, their effectiveness\nis influenced by the network structure, highlighting the importance of\nconsidering network structure in the development of future misinformation\ncountermeasures.",
    "categories": [
      "cs.SI",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.SI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13909v1",
    "published_date": "2024-10-16 23:58:26 UTC",
    "updated_date": "2024-10-16 23:58:26 UTC"
  },
  {
    "arxiv_id": "2410.13094v1",
    "title": "Task Consistent Prototype Learning for Incremental Few-shot Semantic Segmentation",
    "authors": [
      "Wenbo Xu",
      "Yanan Wu",
      "Haoran Jiang",
      "Yang Wang",
      "Qiang Wu",
      "Jian Zhang"
    ],
    "abstract": "Incremental Few-Shot Semantic Segmentation (iFSS) tackles a task that\nrequires a model to continually expand its segmentation capability on novel\nclasses using only a few annotated examples. Typical incremental approaches\nencounter a challenge that the objective of the base training phase (fitting\nbase classes with sufficient instances) does not align with the incremental\nlearning phase (rapidly adapting to new classes with less forgetting). This\ndisconnect can result in suboptimal performance in the incremental setting.\nThis study introduces a meta-learning-based prototype approach that encourages\nthe model to learn how to adapt quickly while preserving previous knowledge.\nConcretely, we mimic the incremental evaluation protocol during the base\ntraining session by sampling a sequence of pseudo-incremental tasks. Each task\nin the simulated sequence is trained using a meta-objective to enable rapid\nadaptation without forgetting. To enhance discrimination among class\nprototypes, we introduce prototype space redistribution learning, which\ndynamically updates class prototypes to establish optimal inter-prototype\nboundaries within the prototype space. Extensive experiments on iFSS datasets\nbuilt upon PASCAL and COCO benchmarks show the advanced performance of the\nproposed approach, offering valuable insights for addressing iFSS challenges.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "conference",
    "pdf_url": "http://arxiv.org/pdf/2410.13094v1",
    "published_date": "2024-10-16 23:42:27 UTC",
    "updated_date": "2024-10-16 23:42:27 UTC"
  },
  {
    "arxiv_id": "2410.13086v1",
    "title": "Reverse-Engineering the Reader",
    "authors": [
      "Samuel Kiegeland",
      "Ethan Gotlieb Wilcox",
      "Afra Amini",
      "David Robert Reich",
      "Ryan Cotterell"
    ],
    "abstract": "Numerous previous studies have sought to determine to what extent language\nmodels, pretrained on natural language text, can serve as useful models of\nhuman cognition. In this paper, we are interested in the opposite question:\nwhether we can directly optimize a language model to be a useful cognitive\nmodel by aligning it to human psychometric data. To achieve this, we introduce\na novel alignment technique in which we fine-tune a language model to\nimplicitly optimize the parameters of a linear regressor that directly predicts\nhumans' reading times of in-context linguistic units, e.g., phonemes,\nmorphemes, or words, using surprisal estimates derived from the language model.\nUsing words as a test case, we evaluate our technique across multiple model\nsizes and datasets and find that it improves language models' psychometric\npredictive power. However, we find an inverse relationship between psychometric\npower and a model's performance on downstream NLP tasks as well as its\nperplexity on held-out test data. While this latter trend has been observed\nbefore (Oh et al., 2022; Shain et al., 2024), we are the first to induce it by\nmanipulating a model's alignment to psychometric data.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13086v1",
    "published_date": "2024-10-16 23:05:01 UTC",
    "updated_date": "2024-10-16 23:05:01 UTC"
  },
  {
    "arxiv_id": "2410.13083v1",
    "title": "FedCAP: Robust Federated Learning via Customized Aggregation and Personalization",
    "authors": [
      "Youpeng Li",
      "Xinda Wang",
      "Fuxun Yu",
      "Lichao Sun",
      "Wenbin Zhang",
      "Xuyu Wang"
    ],
    "abstract": "Federated learning (FL), an emerging distributed machine learning paradigm,\nhas been applied to various privacy-preserving scenarios. However, due to its\ndistributed nature, FL faces two key issues: the non-independent and identical\ndistribution (non-IID) of user data and vulnerability to Byzantine threats. To\naddress these challenges, in this paper, we propose FedCAP, a robust FL\nframework against both data heterogeneity and Byzantine attacks. The core of\nFedCAP is a model update calibration mechanism to help a server capture the\ndifferences in the direction and magnitude of model updates among clients.\nFurthermore, we design a customized model aggregation rule that facilitates\ncollaborative training among similar clients while accelerating the model\ndeterioration of malicious clients. With a Euclidean norm-based anomaly\ndetection mechanism, the server can quickly identify and permanently remove\nmalicious clients. Moreover, the impact of data heterogeneity and Byzantine\nattacks can be further mitigated through personalization on the client side. We\nconduct extensive experiments, comparing multiple state-of-the-art baselines,\nto demonstrate that FedCAP performs well in several non-IID settings and shows\nstrong robustness under a series of poisoning attacks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "14 pages, 12 figures, 5 tables, accepted by 2024 Annual Computer\n  Security Applications Conference (ACSAC 2024)",
    "pdf_url": "http://arxiv.org/pdf/2410.13083v1",
    "published_date": "2024-10-16 23:01:22 UTC",
    "updated_date": "2024-10-16 23:01:22 UTC"
  },
  {
    "arxiv_id": "2410.13077v1",
    "title": "Tuning Language Models by Mixture-of-Depths Ensemble",
    "authors": [
      "Haoyan Luo",
      "Lucia Specia"
    ],
    "abstract": "Transformer-based Large Language Models (LLMs) traditionally rely on\nfinal-layer loss for training and final-layer representations for predictions,\npotentially overlooking the predictive power embedded in intermediate layers.\nSurprisingly, we find that focusing training efforts on these intermediate\nlayers can yield training losses comparable to those of final layers, with\ncomplementary test-time performance. We introduce a novel tuning framework,\nMixture-of-Depths (MoD), which trains late layers as ensembles contributing to\nthe final logits through learned routing weights. With the auxiliary\ndistillation loss and additional normalization modules, we ensure that the\noutputs of the late layers adapt to language modeling. Our MoD framework, which\ncan be integrated with any existing tuning method, shows consistent improvement\non various language modelling tasks. Furthermore, by replacing traditional\ntrainable modules with MoD, our approach achieves similar performance with\nsignificantly fewer trainable parameters, demonstrating the potential of\nleveraging predictive power from intermediate representations during training.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13077v1",
    "published_date": "2024-10-16 22:51:45 UTC",
    "updated_date": "2024-10-16 22:51:45 UTC"
  },
  {
    "arxiv_id": "2410.13065v1",
    "title": "Language Models as Semiotic Machines: Reconceptualizing AI Language Systems through Structuralist and Post-Structuralist Theories of Language",
    "authors": [
      "Elad Vromen"
    ],
    "abstract": "This paper proposes a novel framework for understanding large language models\n(LLMs) by reconceptualizing them as semiotic machines rather than as imitations\nof human cognition. Drawing from structuralist and post-structuralist theories\nof language-specifically the works of Ferdinand de Saussure and Jacques\nDerrida-I argue that LLMs should be understood as models of language itself,\naligning with Derrida's concept of 'writing' (l'ecriture). The paper is\nstructured into three parts. First, I lay the theoretical groundwork by\nexplaining how the word2vec embedding algorithm operates within Saussure's\nframework of language as a relational system of signs. Second, I apply\nDerrida's critique of Saussure to position 'writing' as the object modeled by\nLLMs, offering a view of the machine's 'mind' as a statistical approximation of\nsign behavior. Finally, the third section addresses how modern LLMs reflect\npost-structuralist notions of unfixed meaning, arguing that the \"next token\ngeneration\" mechanism effectively captures the dynamic nature of meaning. By\nreconceptualizing LLMs as semiotic machines rather than cognitive models, this\nframework provides an alternative lens through which to assess the strengths\nand limitations of LLMs, offering new avenues for future research.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "18 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.13065v1",
    "published_date": "2024-10-16 21:45:54 UTC",
    "updated_date": "2024-10-16 21:45:54 UTC"
  },
  {
    "arxiv_id": "2410.13061v2",
    "title": "Optimal Transport for Probabilistic Circuits",
    "authors": [
      "Adrian Ciotinga",
      "YooJung Choi"
    ],
    "abstract": "We introduce a novel optimal transport framework for probabilistic circuits\n(PCs). While it has been shown recently that divergences between distributions\nrepresented as certain classes of PCs can be computed tractably, to the best of\nour knowledge, there is no existing approach to compute the Wasserstein\ndistance between probability distributions given by PCs. We propose a\nWasserstein-type distance that restricts the coupling measure of the associated\noptimal transport problem to be a probabilistic circuit. We then develop an\nalgorithm for computing this distance by solving a series of small linear\nprograms and derive the circuit conditions under which this is tractable.\nFurthermore, we show that we can easily retrieve the optimal transport plan\nbetween the PCs from the solutions to these linear programs. Lastly, we study\nthe empirical Wasserstein distance between a PC and a dataset, and show that we\ncan estimate the PC parameters to minimize this distance through an efficient\niterative algorithm.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "math.OC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13061v2",
    "published_date": "2024-10-16 21:42:16 UTC",
    "updated_date": "2025-03-07 20:03:13 UTC"
  },
  {
    "arxiv_id": "2410.13057v1",
    "title": "ERAS: Evaluating the Robustness of Chinese NLP Models to Morphological Garden Path Errors",
    "authors": [
      "Qinchan Li",
      "Sophie Hao"
    ],
    "abstract": "In languages without orthographic word boundaries, NLP models perform word\nsegmentation, either as an explicit preprocessing step or as an implicit step\nin an end-to-end computation. This paper shows that Chinese NLP models are\nvulnerable to morphological garden path errors: errors caused by a failure to\nresolve local word segmentation ambiguities using sentence-level\nmorphosyntactic context. We propose a benchmark, ERAS, that tests a model's\nvulnerability to morphological garden path errors by comparing its behavior on\nsentences with and without local segmentation ambiguities. Using ERAS, we show\nthat word segmentation models make garden path errors on locally ambiguous\nsentences, but do not make equivalent errors on unambiguous sentences. We\nfurther show that sentiment analysis models with character-level tokenization\nmake implicit garden path errors, even without an explicit word segmentation\nstep in the pipeline. Our results indicate that models' segmentation of Chinese\ntext often fails to account for morphosyntactic context.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Under review in ARR/NAACL",
    "pdf_url": "http://arxiv.org/pdf/2410.13057v1",
    "published_date": "2024-10-16 21:35:20 UTC",
    "updated_date": "2024-10-16 21:35:20 UTC"
  },
  {
    "arxiv_id": "2410.13056v3",
    "title": "Channel-Wise Mixed-Precision Quantization for Large Language Models",
    "authors": [
      "Zihan Chen",
      "Bike Xie",
      "Jundong Li",
      "Cong Shen"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable success across a\nwide range of language tasks, but their deployment on edge devices remains\nchallenging due to the substantial memory requirements imposed by their large\nparameter sizes. Weight-only quantization presents a promising solution to\nreduce the memory footprint of LLMs. However, existing approaches primarily\nfocus on integer-bit quantization, limiting their adaptability to\nfractional-bit quantization tasks and preventing the full utilization of\navailable storage space on devices. In this paper, we introduce Channel-Wise\nMixed-Precision Quantization (CMPQ), a novel mixed-precision quantization\nmethod that allocates quantization precision in a channel-wise pattern based on\nactivation distributions. By assigning different precision levels to different\nweight channels, CMPQ can adapt to any bit-width constraint. CMPQ employs a\nnon-uniform quantization strategy and incorporates two outlier extraction\ntechniques that collaboratively preserve the critical information, thereby\nminimizing the quantization loss. Experiments on different sizes of LLMs\ndemonstrate that CMPQ not only enhances performance in integer-bit quantization\ntasks but also achieves significant performance gains with a modest increase in\nmemory usage. CMPQ thus represents an adaptive and effective approach to LLM\nquantization, offering substantial benefits across diverse device capabilities.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13056v3",
    "published_date": "2024-10-16 21:34:41 UTC",
    "updated_date": "2025-02-03 21:48:18 UTC"
  },
  {
    "arxiv_id": "2410.13054v2",
    "title": "Systems with Switching Causal Relations: A Meta-Causal Perspective",
    "authors": [
      "Moritz Willig",
      "Tim Nelson Tobiasch",
      "Florian Peter Busch",
      "Jonas Seng",
      "Devendra Singh Dhami",
      "Kristian Kersting"
    ],
    "abstract": "Most work on causality in machine learning assumes that causal relationships\nare driven by a constant underlying process. However, the flexibility of\nagents' actions or tipping points in the environmental process can change the\nqualitative dynamics of the system. As a result, new causal relationships may\nemerge, while existing ones change or disappear, resulting in an altered causal\ngraph. To analyze these qualitative changes on the causal graph, we propose the\nconcept of meta-causal states, which groups classical causal models into\nclusters based on equivalent qualitative behavior and consolidates specific\nmechanism parameterizations. We demonstrate how meta-causal states can be\ninferred from observed agent behavior, and discuss potential methods for\ndisentangling these states from unlabeled data. Finally, we direct our analysis\ntowards the application of a dynamical system, showing that meta-causal states\ncan also emerge from inherent system dynamics, and thus constitute more than a\ncontext-dependent framework in which mechanisms emerge only as a result of\nexternal factors.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "21 pages, 3 figures, 4 tables, ICLR 2025 Camera Ready Version",
    "pdf_url": "http://arxiv.org/pdf/2410.13054v2",
    "published_date": "2024-10-16 21:32:31 UTC",
    "updated_date": "2025-04-17 07:48:47 UTC"
  },
  {
    "arxiv_id": "2410.13045v1",
    "title": "FedGTST: Boosting Global Transferability of Federated Models via Statistics Tuning",
    "authors": [
      "Evelyn Ma",
      "Chao Pan",
      "Rasoul Etesami",
      "Han Zhao",
      "Olgica Milenkovic"
    ],
    "abstract": "The performance of Transfer Learning (TL) heavily relies on effective\npretraining, which demands large datasets and substantial computational\nresources. As a result, executing TL is often challenging for individual model\ndevelopers. Federated Learning (FL) addresses these issues by facilitating\ncollaborations among clients, expanding the dataset indirectly, distributing\ncomputational costs, and preserving privacy. However, key challenges remain\nunresolved. First, existing FL methods tend to optimize transferability only\nwithin local domains, neglecting the global learning domain. Second, most\napproaches rely on indirect transferability metrics, which do not accurately\nreflect the final target loss or true degree of transferability. To address\nthese gaps, we propose two enhancements to FL. First, we introduce a\nclient-server exchange protocol that leverages cross-client Jacobian (gradient)\nnorms to boost transferability. Second, we increase the average Jacobian norm\nacross clients at the server, using this as a local regularizer to reduce\ncross-client Jacobian variance. Our transferable federated algorithm, termed\nFedGTST (Federated Global Transferability via Statistics Tuning), demonstrates\nthat increasing the average Jacobian and reducing its variance allows for\ntighter control of the target loss. This leads to an upper bound on the target\nloss in terms of the source loss and source-target domain discrepancy.\nExtensive experiments on datasets such as MNIST to MNIST-M and CIFAR10 to SVHN\nshow that FedGTST outperforms relevant baselines, including FedSR. On the\nsecond dataset pair, FedGTST improves accuracy by 9.8% over FedSR and 7.6% over\nFedIIR when LeNet is used as the backbone.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13045v1",
    "published_date": "2024-10-16 21:13:52 UTC",
    "updated_date": "2024-10-16 21:13:52 UTC"
  },
  {
    "arxiv_id": "2410.13037v1",
    "title": "LFOSum: Summarizing Long-form Opinions with Large Language Models",
    "authors": [
      "Mir Tafseer Nayeem",
      "Davood Rafiei"
    ],
    "abstract": "Online reviews play a pivotal role in influencing consumer decisions across\nvarious domains, from purchasing products to selecting hotels or restaurants.\nHowever, the sheer volume of reviews -- often containing repetitive or\nirrelevant content -- leads to information overload, making it challenging for\nusers to extract meaningful insights. Traditional opinion summarization models\nface challenges in handling long inputs and large volumes of reviews, while\nnewer Large Language Model (LLM) approaches often fail to generate accurate and\nfaithful summaries. To address those challenges, this paper introduces (1) a\nnew dataset of long-form user reviews, each entity comprising over a thousand\nreviews, (2) two training-free LLM-based summarization approaches that scale to\nlong inputs, and (3) automatic evaluation metrics. Our dataset of user reviews\nis paired with in-depth and unbiased critical summaries by domain experts,\nserving as a reference for evaluation. Additionally, our novel reference-free\nevaluation metrics provide a more granular, context-sensitive assessment of\nsummary faithfulness. We benchmark several open-source and closed-source LLMs\nusing our methods. Our evaluation reveals that LLMs still face challenges in\nbalancing sentiment and format adherence in long-form summaries, though\nopen-source models can narrow the gap when relevant information is retrieved in\na focused manner.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.ET",
      "cs.HC",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13037v1",
    "published_date": "2024-10-16 20:52:39 UTC",
    "updated_date": "2024-10-16 20:52:39 UTC"
  },
  {
    "arxiv_id": "2410.13032v1",
    "title": "Hypothesis Testing the Circuit Hypothesis in LLMs",
    "authors": [
      "Claudia Shi",
      "Nicolas Beltran-Velez",
      "Achille Nazaret",
      "Carolina Zheng",
      "Adrià Garriga-Alonso",
      "Andrew Jesson",
      "Maggie Makar",
      "David M. Blei"
    ],
    "abstract": "Large language models (LLMs) demonstrate surprising capabilities, but we do\nnot understand how they are implemented. One hypothesis suggests that these\ncapabilities are primarily executed by small subnetworks within the LLM, known\nas circuits. But how can we evaluate this hypothesis? In this paper, we\nformalize a set of criteria that a circuit is hypothesized to meet and develop\na suite of hypothesis tests to evaluate how well circuits satisfy them. The\ncriteria focus on the extent to which the LLM's behavior is preserved, the\ndegree of localization of this behavior, and whether the circuit is minimal. We\napply these tests to six circuits described in the research literature. We find\nthat synthetic circuits -- circuits that are hard-coded in the model -- align\nwith the idealized properties. Circuits discovered in Transformer models\nsatisfy the criteria to varying degrees. To facilitate future empirical studies\nof circuits, we created the \\textit{circuitry} package, a wrapper around the\n\\textit{TransformerLens} library, which abstracts away lower-level\nmanipulations of hooks and activations. The software is available at\n\\url{https://github.com/blei-lab/circuitry}.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.AI",
    "comment": "Code available here: https://github.com/blei-lab/circuitry",
    "pdf_url": "http://arxiv.org/pdf/2410.13032v1",
    "published_date": "2024-10-16 20:45:29 UTC",
    "updated_date": "2024-10-16 20:45:29 UTC"
  },
  {
    "arxiv_id": "2410.14735v4",
    "title": "Agent Skill Acquisition for Large Language Models via CycleQD",
    "authors": [
      "So Kuroki",
      "Taishi Nakamura",
      "Takuya Akiba",
      "Yujin Tang"
    ],
    "abstract": "Training large language models to acquire specific skills remains a\nchallenging endeavor. Conventional training approaches often struggle with data\ndistribution imbalances and inadequacies in objective functions that do not\nalign well with task-specific performance. To address these challenges, we\nintroduce CycleQD, a novel approach that leverages the Quality Diversity\nframework through a cyclic adaptation of the algorithm, along with a model\nmerging based crossover and an SVD-based mutation. In CycleQD, each task's\nperformance metric is alternated as the quality measure while the others serve\nas the behavioral characteristics. This cyclic focus on individual tasks allows\nfor concentrated effort on one task at a time, eliminating the need for data\nratio tuning and simplifying the design of the objective function. Empirical\nresults from AgentBench indicate that applying CycleQD to LLAMA3-8B-INSTRUCT\nbased models not only enables them to surpass traditional fine-tuning methods\nin coding, operating systems, and database tasks, but also achieves performance\non par with GPT-3.5-TURBO, which potentially contains much more parameters,\nacross these domains. Crucially, this enhanced performance is achieved while\nretaining robust language capabilities, as evidenced by its performance on\nwidely adopted language benchmark tasks. We highlight the key design choices in\nCycleQD, detailing how these contribute to its effectiveness. Furthermore, our\nmethod is general and can be applied to image segmentation models, highlighting\nits applicability across different domains.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.CL",
    "comment": "To appear at the 13th International Conference on Learning\n  Representations (ICLR 2025)",
    "pdf_url": "http://arxiv.org/pdf/2410.14735v4",
    "published_date": "2024-10-16 20:27:15 UTC",
    "updated_date": "2025-02-17 06:26:58 UTC"
  },
  {
    "arxiv_id": "2411.00782v2",
    "title": "TradExpert: Revolutionizing Trading with Mixture of Expert LLMs",
    "authors": [
      "Qianggang Ding",
      "Haochen Shi",
      "Jiadong Guo",
      "Bang Liu"
    ],
    "abstract": "The integration of Artificial Intelligence (AI) in the financial domain has\nopened new avenues for quantitative trading, particularly through the use of\nLarge Language Models (LLMs). However, the challenge of effectively\nsynthesizing insights from diverse data sources and integrating both structured\nand unstructured data persists. This paper presents TradeExpert, a novel\nframework that employs a mix of experts (MoE) approach, using four specialized\nLLMs, each analyzing distinct sources of financial data, including news\narticles, market data, alpha factors, and fundamental data. The insights of\nthese expert LLMs are further synthesized by a General Expert LLM to make a\nfinal prediction or decision. With specific prompts, TradeExpert can be\nswitched between the prediction mode and the ranking mode for stock movement\nprediction and quantitative stock trading, respectively. In addition to\nexisting benchmarks, we also release a large-scale financial dataset to\ncomprehensively evaluate TradeExpert's effectiveness. Our experimental results\ndemonstrate TradeExpert's superior performance across all trading scenarios.",
    "categories": [
      "cs.AI",
      "q-fin.ST"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.00782v2",
    "published_date": "2024-10-16 20:24:16 UTC",
    "updated_date": "2025-05-13 13:13:18 UTC"
  },
  {
    "arxiv_id": "2410.13018v1",
    "title": "Learning Representations for Reasoning: Generalizing Across Diverse Structures",
    "authors": [
      "Zhaocheng Zhu"
    ],
    "abstract": "Reasoning, the ability to logically draw conclusions from existing knowledge,\nis a hallmark of human. Together with perception, they constitute the two major\nthemes of artificial intelligence. While deep learning has pushed the limit of\nperception beyond human-level performance, the progress in reasoning domains is\nway behind. One fundamental reason is that reasoning problems usually have\nflexible structures for both knowledge and queries, and many existing models\nonly perform well on structures seen during training. Here we aim to push the\nboundary of reasoning models by devising algorithms that generalize across\nknowledge and query structures, as well as systems that accelerate development\non structured data. This thesis consists of three parts. In Part I, we study\nmodels that can inductively generalize to unseen knowledge graphs with new\nentity and relation vocabularies. For new entities, we propose a framework that\nlearns neural operators in a dynamic programming algorithm computing path\nrepresentations. For relations, we construct a relation graph to capture the\ninteractions between relations, thereby converting new relations into new\nentities. In Part II, we propose two solutions for generalizing across\nmulti-step queries on knowledge graphs and text respectively. For knowledge\ngraphs, we show that multi-step queries can be solved by multiple calls of\ngraph neural networks and fuzzy logic operations. For text, we devise an\nalgorithm to learn explicit knowledge as textual rules to improve large\nlanguage models on multi-step queries. In Part III, we propose two systems to\nfacilitate machine learning development on structured data. Our library treats\nstructured data as first-class citizens and removes the barrier for developing\nalgorithms on structured data. Our node embedding system solves the GPU memory\nbottleneck of embedding matrices and scales to graphs with billion nodes.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "PhD thesis",
    "pdf_url": "http://arxiv.org/pdf/2410.13018v1",
    "published_date": "2024-10-16 20:23:37 UTC",
    "updated_date": "2024-10-16 20:23:37 UTC"
  },
  {
    "arxiv_id": "2410.13013v1",
    "title": "LEGAL-UQA: A Low-Resource Urdu-English Dataset for Legal Question Answering",
    "authors": [
      "Faizan Faisal",
      "Umair Yousaf"
    ],
    "abstract": "We present LEGAL-UQA, the first Urdu legal question-answering dataset derived\nfrom Pakistan's constitution. This parallel English-Urdu dataset includes 619\nquestion-answer pairs, each with corresponding legal article contexts,\naddressing the need for domain-specific NLP resources in low-resource\nlanguages. We describe the dataset creation process, including OCR extraction,\nmanual refinement, and GPT-4-assisted translation and generation of QA pairs.\nOur experiments evaluate the latest generalist language and embedding models on\nLEGAL-UQA, with Claude-3.5-Sonnet achieving 99.19% human-evaluated accuracy. We\nfine-tune mt5-large-UQA-1.0, highlighting the challenges of adapting\nmultilingual models to specialized domains. Additionally, we assess retrieval\nperformance, finding OpenAI's text-embedding-3-large outperforms Mistral's\nmistral-embed. LEGAL-UQA bridges the gap between global NLP advancements and\nlocalized applications, particularly in constitutional law, and lays the\nfoundation for improved legal information access in Pakistan.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "68T50"
    ],
    "primary_category": "cs.CL",
    "comment": "8 pages",
    "pdf_url": "http://arxiv.org/pdf/2410.13013v1",
    "published_date": "2024-10-16 20:14:45 UTC",
    "updated_date": "2024-10-16 20:14:45 UTC"
  },
  {
    "arxiv_id": "2410.13010v1",
    "title": "Hiding-in-Plain-Sight (HiPS) Attack on CLIP for Targetted Object Removal from Images",
    "authors": [
      "Arka Daw",
      "Megan Hong-Thanh Chung",
      "Maria Mahbub",
      "Amir Sadovnik"
    ],
    "abstract": "Machine learning models are known to be vulnerable to adversarial attacks,\nbut traditional attacks have mostly focused on single-modalities. With the rise\nof large multi-modal models (LMMs) like CLIP, which combine vision and language\ncapabilities, new vulnerabilities have emerged. However, prior work in\nmultimodal targeted attacks aim to completely change the model's output to what\nthe adversary wants. In many realistic scenarios, an adversary might seek to\nmake only subtle modifications to the output, so that the changes go unnoticed\nby downstream models or even by humans. We introduce Hiding-in-Plain-Sight\n(HiPS) attacks, a novel class of adversarial attacks that subtly modifies model\npredictions by selectively concealing target object(s), as if the target object\nwas absent from the scene. We propose two HiPS attack variants, HiPS-cls and\nHiPS-cap, and demonstrate their effectiveness in transferring to downstream\nimage captioning models, such as CLIP-Cap, for targeted object removal from\nimage captions.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "Published in the 3rd Workshop on New Frontiers in Adversarial Machine\n  Learning at NeurIPS 2024. 10 pages, 7 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2410.13010v1",
    "published_date": "2024-10-16 20:11:32 UTC",
    "updated_date": "2024-10-16 20:11:32 UTC"
  },
  {
    "arxiv_id": "2410.13002v2",
    "title": "Flex: End-to-End Text-Instructed Visual Navigation from Foundation Model Features",
    "authors": [
      "Makram Chahine",
      "Alex Quach",
      "Alaa Maalouf",
      "Tsun-Hsuan Wang",
      "Daniela Rus"
    ],
    "abstract": "End-to-end learning directly maps sensory inputs to actions, creating highly\nintegrated and efficient policies for complex robotics tasks. However, such\nmodels often struggle to generalize beyond their training scenarios, limiting\nadaptability to new environments, tasks, and concepts. In this work, we\ninvestigate the minimal data requirements and architectural adaptations\nnecessary to achieve robust closed-loop performance with vision-based control\npolicies under unseen text instructions and visual distribution shifts. Our\nfindings are synthesized in Flex (Fly lexically), a framework that uses\npre-trained Vision Language Models (VLMs) as frozen patch-wise feature\nextractors, generating spatially aware embeddings that integrate semantic and\nvisual information. We demonstrate the effectiveness of this approach on a\nquadrotor fly-to-target task, where agents trained via behavior cloning on a\nsmall simulated dataset successfully generalize to real-world scenes with\ndiverse novel goals and command formulations.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "68T40, 68T05, 68T50",
      "I.2.6; I.2.9; I.2.10; I.4.8"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13002v2",
    "published_date": "2024-10-16 19:59:31 UTC",
    "updated_date": "2025-05-16 15:13:26 UTC"
  },
  {
    "arxiv_id": "2410.12996v1",
    "title": "SSET: Swapping-Sliding Explanation for Time Series Classifiers in Affect Detection",
    "authors": [
      "Nazanin Fouladgar",
      "Marjan Alirezaie",
      "Kary Främling"
    ],
    "abstract": "Local explanation of machine learning (ML) models has recently received\nsignificant attention due to its ability to reduce ambiguities about why the\nmodels make specific decisions. Extensive efforts have been invested to address\nexplainability for different data types, particularly images. However, the work\non multivariate time series data is limited. A possible reason is that the\nconflation of time and other variables in time series data can cause the\ngenerated explanations to be incomprehensible to humans. In addition, some\nefforts on time series fall short of providing accurate explanations as they\neither ignore a context in the time domain or impose differentiability\nrequirements on the ML models. Such restrictions impede their ability to\nprovide valid explanations in real-world applications and non-differentiable ML\nsettings. In this paper, we propose a swapping--sliding decision explanation\nfor multivariate time series classifiers, called SSET. The proposal consists of\nswapping and sliding stages, by which salient sub-sequences causing significant\ndrops in the prediction score are presented as explanations. In the former\nstage, the important variables are detected by swapping the series of interest\nwith close train data from target classes. In the latter stage, the salient\nobservations of these variables are explored by sliding a window over each time\nstep. Additionally, the model measures the importance of different variables\nover time in a novel way characterized by multiple factors. We leverage SSET on\naffect detection domain where evaluations are performed on two real-world\nphysiological time series datasets, WESAD and MAHNOB-HCI, and a deep\nconvolutional classifier, CN-Waterfall. This classifier has shown superior\nperformance to prior models to detect human affective states. Comparing SSET\nwith several benchmarks, including LIME, integrated gradients, and Dynamask, we\nfound..",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.12996v1",
    "published_date": "2024-10-16 19:47:08 UTC",
    "updated_date": "2024-10-16 19:47:08 UTC"
  },
  {
    "arxiv_id": "2410.12989v1",
    "title": "Qtok: A Comprehensive Framework for Evaluating Multilingual Tokenizer Quality in Large Language Models",
    "authors": [
      "Iaroslav Chelombitko",
      "Egor Safronov",
      "Aleksey Komissarov"
    ],
    "abstract": "In the development of Large Language Models (LLMs), considerable attention\nhas been given to the quality of training datasets. However, the role of\ntokenizers in the LLM training pipeline, particularly for multilingual models,\nhas received less focus. The quality of tokenization can significantly impact a\nmodel's ability to handle diverse languages effectively. We introduce Qtok, a\ntool designed to assess tokenizer quality with a specific emphasis on their\nperformance in multilingual contexts.\n  Our research proposes a set of metrics for evaluating tokenizer quality,\nincluding measures of language coverage, token completeness, and distribution\nacross languages and linguistic categories. Qtok applies these metrics to\nevaluate 13 distinct tokenizers from 58 publicly available models, analyzing\ntheir output across different linguistic contexts. Our analysis revealed\nsignificant variations in token distribution across languages and categories,\nhighlighting potential biases and areas for improvement in current tokenization\nstrategies.\n  This research contributes to the field of tokenizer evaluation within\nmultilingual LLM development by providing a systematic approach to assessing\ntokenizer quality. Our findings highlight the critical role of tokenization in\nmultilingual LLM capability. The Qtok tool and our analysis methodology offer\npractical means for researchers to evaluate and improve tokenization strategies\nfor multilingual applications. We offer a method to compare tokenizer quality\nacross these metrics, which may be useful when selecting or adjusting\ntokenizers for specific multilingual LLM applications.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.7; I.2.6; H.3.3"
    ],
    "primary_category": "cs.CL",
    "comment": "24 pages, 9 figures, 6 tables. Code and data available at\n  https://github.com/nup-csai/Qtok/",
    "pdf_url": "http://arxiv.org/pdf/2410.12989v1",
    "published_date": "2024-10-16 19:34:34 UTC",
    "updated_date": "2024-10-16 19:34:34 UTC"
  },
  {
    "arxiv_id": "2411.00781v1",
    "title": "Hazards in Daily Life? Enabling Robots to Proactively Detect and Resolve Anomalies",
    "authors": [
      "Zirui Song",
      "Guangxian Ouyang",
      "Meng Fang",
      "Hongbin Na",
      "Zijing Shi",
      "Zhenhao Chen",
      "Yujie Fu",
      "Zeyu Zhang",
      "Shiyu Jiang",
      "Miao Fang",
      "Ling Chen",
      "Xiuying Chen"
    ],
    "abstract": "Existing household robots have made significant progress in performing\nroutine tasks, such as cleaning floors or delivering objects. However, a key\nlimitation of these robots is their inability to recognize potential problems\nor dangers in home environments. For example, a child may pick up and ingest\nmedication that has fallen on the floor, posing a serious risk. We argue that\nhousehold robots should proactively detect such hazards or anomalies within the\nhome, and propose the task of anomaly scenario generation. We leverage\nfoundational models instead of relying on manually labeled data to build\nsimulated environments. Specifically, we introduce a multi-agent brainstorming\napproach, where agents collaborate and generate diverse scenarios covering\nhousehold hazards, hygiene management, and child safety. These textual task\ndescriptions are then integrated with designed 3D assets to simulate realistic\nenvironments. Within these constructed environments, the robotic agent learns\nthe necessary skills to proactively discover and handle the proposed anomalies\nthrough task decomposition, and optimal learning approach selection. We\ndemonstrate that our generated environment outperforms others in terms of task\ndescription and scene diversity, ultimately enabling robotic agents to better\naddress potential household hazards.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.RO",
    "comment": "In processing",
    "pdf_url": "http://arxiv.org/pdf/2411.00781v1",
    "published_date": "2024-10-16 19:29:14 UTC",
    "updated_date": "2024-10-16 19:29:14 UTC"
  },
  {
    "arxiv_id": "2410.12983v1",
    "title": "Reinforcement Learning with Euclidean Data Augmentation for State-Based Continuous Control",
    "authors": [
      "Jinzhu Luo",
      "Dingyang Chen",
      "Qi Zhang"
    ],
    "abstract": "Data augmentation creates new data points by transforming the original ones\nfor a reinforcement learning (RL) agent to learn from, which has been shown to\nbe effective for the objective of improving the data efficiency of RL for\ncontinuous control. Prior work towards this objective has been largely\nrestricted to perturbation-based data augmentation where new data points are\ncreated by perturbing the original ones, which has been impressively effective\nfor tasks where the RL agent observes control states as images with\nperturbations including random cropping, shifting, etc. This work focuses on\nstate-based control, where the RL agent can directly observe raw kinematic and\ntask features, and considers an alternative data augmentation applied to these\nfeatures based on Euclidean symmetries under transformations like rotations. We\nshow that the default state features used in exiting benchmark tasks that are\nbased on joint configurations are not amenable to Euclidean transformations. We\ntherefore advocate using state features based on configurations of the limbs\n(i.e., the rigid bodies connected by the joints) that instead provide rich\naugmented data under Euclidean transformations. With minimal hyperparameter\ntuning, we show this new Euclidean data augmentation strategy significantly\nimproves both data efficiency and asymptotic performance of RL on a wide range\nof continuous control tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.12983v1",
    "published_date": "2024-10-16 19:25:30 UTC",
    "updated_date": "2024-10-16 19:25:30 UTC"
  },
  {
    "arxiv_id": "2410.12982v1",
    "title": "Flash Inference: Near Linear Time Inference for Long Convolution Sequence Models and Beyond",
    "authors": [
      "Costin-Andrei Oncescu",
      "Sanket Purandare",
      "Stratos Idreos",
      "Sham Kakade"
    ],
    "abstract": "While transformers have been at the core of most recent advancements in\nsequence generative models, their computational cost remains quadratic in\nsequence length. Several subquadratic architectures have been proposed to\naddress this computational issue. Some of them, including long convolution\nsequence models (LCSMs), such as Hyena, address this issue at training time but\nremain quadratic during inference. We propose a method for speeding up LCSMs'\nexact inference to quasilinear $O(L\\log^2L)$ time, identify the key properties\nthat make this possible, and propose a general framework that exploits these.\nOur approach, inspired by previous work on relaxed polynomial interpolation, is\nbased on a tiling which helps decrease memory movement and share computation.\nIt has the added benefit of allowing for almost complete parallelization across\nlayers of the position-mixing part of the architecture. Empirically, we provide\na proof of concept implementation for Hyena, which gets up to $1.6\\times$\nend-to-end improvement over standard inference by improving $50\\times$ within\nthe position-mixing part.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "15 pages, 9 figures, 5 algorithms",
    "pdf_url": "http://arxiv.org/pdf/2410.12982v1",
    "published_date": "2024-10-16 19:23:46 UTC",
    "updated_date": "2024-10-16 19:23:46 UTC"
  },
  {
    "arxiv_id": "2410.12959v1",
    "title": "Large Language Models as a Tool for Mining Object Knowledge",
    "authors": [
      "Hannah YoungEun An",
      "Lenhart K. Schubert"
    ],
    "abstract": "Commonsense knowledge is essential for machines to reason about the world.\nLarge language models (LLMs) have demonstrated their ability to perform almost\nhuman-like text generation. Despite this success, they fall short as\ntrustworthy intelligent systems, due to the opacity of the basis for their\nanswers and a tendency to confabulate facts when questioned about obscure\nentities or technical domains. We hypothesize, however, that their general\nknowledge about objects in the everyday world is largely sound. Based on that\nhypothesis, this paper investigates LLMs' ability to formulate explicit\nknowledge about common physical artifacts, focusing on their parts and\nmaterials. Our work distinguishes between the substances that comprise an\nentire object and those that constitute its parts$\\unicode{x2014}$a previously\nunderexplored distinction in knowledge base construction. Using few-shot with\nfive in-context examples and zero-shot multi-step prompting, we produce a\nrepository of data on the parts and materials of about 2,300 objects and their\nsubtypes. Our evaluation demonstrates LLMs' coverage and soundness in\nextracting knowledge. This contribution to knowledge mining should prove useful\nto AI research on reasoning about object structure and composition and serve as\nan explicit knowledge source (analogous to knowledge graphs) for LLMs\nperforming multi-hop question answering.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.12959v1",
    "published_date": "2024-10-16 18:46:02 UTC",
    "updated_date": "2024-10-16 18:46:02 UTC"
  },
  {
    "arxiv_id": "2410.12955v1",
    "title": "Long-Tailed Backdoor Attack Using Dynamic Data Augmentation Operations",
    "authors": [
      "Lu Pang",
      "Tao Sun",
      "Weimin Lyu",
      "Haibin Ling",
      "Chao Chen"
    ],
    "abstract": "Recently, backdoor attack has become an increasing security threat to deep\nneural networks and drawn the attention of researchers. Backdoor attacks\nexploit vulnerabilities in third-party pretrained models during the training\nphase, enabling them to behave normally for clean samples and mispredict for\nsamples with specific triggers. Existing backdoor attacks mainly focus on\nbalanced datasets. However, real-world datasets often follow long-tailed\ndistributions. In this paper, for the first time, we explore backdoor attack on\nsuch datasets. Specifically, we first analyze the influence of data imbalance\non backdoor attack. Based on our analysis, we propose an effective backdoor\nattack named Dynamic Data Augmentation Operation (D$^2$AO). We design D$^2$AO\nselectors to select operations depending jointly on the class, sample type\n(clean vs. backdoored) and sample features. Meanwhile, we develop a trigger\ngenerator to generate sample-specific triggers. Through simultaneous\noptimization of the backdoored model and trigger generator, guided by dynamic\ndata augmentation operation selectors, we achieve significant advancements.\nExtensive experiments demonstrate that our method can achieve the\nstate-of-the-art attack performance while preserving the clean accuracy.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.12955v1",
    "published_date": "2024-10-16 18:44:22 UTC",
    "updated_date": "2024-10-16 18:44:22 UTC"
  },
  {
    "arxiv_id": "2410.12954v2",
    "title": "A Note on Shumailov et al. (2024): `AI Models Collapse When Trained on Recursively Generated Data'",
    "authors": [
      "Ali Borji"
    ],
    "abstract": "The study conducted by Shumailov et al. (2024) demonstrates that repeatedly\ntraining a generative model on synthetic data leads to model collapse. This\nfinding has generated considerable interest and debate, particularly given that\ncurrent models have nearly exhausted the available data. In this work, we\ninvestigate the effects of fitting a distribution (through Kernel Density\nEstimation, or KDE) or a model to the data, followed by repeated sampling from\nit. Our objective is to develop a theoretical understanding of the phenomenon\nobserved by Shumailov et al. (2024). Our results indicate that the outcomes\nreported are a statistical phenomenon and may be unavoidable.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Comment on https://doi.org/10.1038/s41586-024-07566-y",
    "pdf_url": "http://arxiv.org/pdf/2410.12954v2",
    "published_date": "2024-10-16 18:43:52 UTC",
    "updated_date": "2024-10-24 19:23:50 UTC"
  },
  {
    "arxiv_id": "2410.12941v1",
    "title": "Gradient Map-Assisted Head and Neck Tumor Segmentation: A Pre-RT to Mid-RT Approach in MRI-Guided Radiotherapy",
    "authors": [
      "Jintao Ren",
      "Kim Hochreuter",
      "Mathis Ersted Rasmussen",
      "Jesper Folsted Kallehauge",
      "Stine Sofia Korreman"
    ],
    "abstract": "Radiation therapy (RT) is a vital part of treatment for head and neck cancer,\nwhere accurate segmentation of gross tumor volume (GTV) is essential for\neffective treatment planning. This study investigates the use of pre-RT tumor\nregions and local gradient maps to enhance mid-RT tumor segmentation for head\nand neck cancer in MRI-guided adaptive radiotherapy. By leveraging pre-RT\nimages and their segmentations as prior knowledge, we address the challenge of\ntumor localization in mid-RT segmentation. A gradient map of the tumor region\nfrom the pre-RT image is computed and applied to mid-RT images to improve tumor\nboundary delineation. Our approach demonstrated improved segmentation accuracy\nfor both primary GTV (GTVp) and nodal GTV (GTVn), though performance was\nlimited by data constraints. The final DSCagg scores from the challenge's test\nset evaluation were 0.534 for GTVp, 0.867 for GTVn, and a mean score of 0.70.\nThis method shows potential for enhancing segmentation and treatment planning\nin adaptive radiotherapy. Team: DCPT-Stine's group.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "physics.med-ph"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.12941v1",
    "published_date": "2024-10-16 18:26:51 UTC",
    "updated_date": "2024-10-16 18:26:51 UTC"
  },
  {
    "arxiv_id": "2410.12940v1",
    "title": "UMambaAdj: Advancing GTV Segmentation for Head and Neck Cancer in MRI-Guided RT with UMamba and nnU-Net ResEnc Planner",
    "authors": [
      "Jintao Ren",
      "Kim Hochreuter",
      "Jesper Folsted Kallehauge",
      "Stine Sofia Korreman"
    ],
    "abstract": "Magnetic Resonance Imaging (MRI) plays a crucial role in MRI-guided adaptive\nradiotherapy for head and neck cancer (HNC) due to its superior soft-tissue\ncontrast. However, accurately segmenting the gross tumor volume (GTV), which\nincludes both the primary tumor (GTVp) and lymph nodes (GTVn), remains\nchallenging. Recently, two deep learning segmentation innovations have shown\ngreat promise: UMamba, which effectively captures long-range dependencies, and\nthe nnU-Net Residual Encoder (ResEnc), which enhances feature extraction\nthrough multistage residual blocks. In this study, we integrate these strengths\ninto a novel approach, termed 'UMambaAdj'. Our proposed method was evaluated on\nthe HNTS-MRG 2024 challenge test set using pre-RT T2-weighted MRI images,\nachieving an aggregated Dice Similarity Coefficient (DSCagg) of 0.751 for GTVp\nand 0.842 for GTVn, with a mean DSCagg of 0.796. This approach demonstrates\npotential for more precise tumor delineation in MRI-guided adaptive\nradiotherapy, ultimately improving treatment outcomes for HNC patients. Team:\nDCPT-Stine's group.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "physics.med-ph"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.12940v1",
    "published_date": "2024-10-16 18:26:27 UTC",
    "updated_date": "2024-10-16 18:26:27 UTC"
  },
  {
    "arxiv_id": "2410.12927v2",
    "title": "Deep Model Merging: The Sister of Neural Network Interpretability -- A Survey",
    "authors": [
      "Arham Khan",
      "Todd Nief",
      "Nathaniel Hudson",
      "Mansi Sakarvadia",
      "Daniel Grzenda",
      "Aswathy Ajith",
      "Jordan Pettyjohn",
      "Kyle Chard",
      "Ian Foster"
    ],
    "abstract": "We survey the model merging literature through the lens of loss landscape\ngeometry to connect observations from empirical studies on model merging and\nloss landscape analysis to phenomena that govern neural network training and\nthe emergence of their inner representations. We distill repeated empirical\nobservations from the literature in these fields into descriptions of four\nmajor characteristics of loss landscape geometry: mode convexity, determinism,\ndirectedness, and connectivity. We argue that insights into the structure of\nlearned representations from model merging have applications to model\ninterpretability and robustness, subsequently we propose promising new research\ndirections at the intersection of these fields.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.12927v2",
    "published_date": "2024-10-16 18:14:05 UTC",
    "updated_date": "2025-03-21 23:29:56 UTC"
  },
  {
    "arxiv_id": "2410.12918v2",
    "title": "Boosting Asynchronous Decentralized Learning with Model Fragmentation",
    "authors": [
      "Sayan Biswas",
      "Anne-Marie Kermarrec",
      "Alexis Marouani",
      "Rafael Pires",
      "Rishi Sharma",
      "Martijn de Vos"
    ],
    "abstract": "Decentralized learning (DL) is an emerging technique that allows nodes on the\nweb to collaboratively train machine learning models without sharing raw data.\nDealing with stragglers, i.e., nodes with slower compute or communication than\nothers, is a key challenge in DL. We present DivShare, a novel asynchronous DL\nalgorithm that achieves fast model convergence in the presence of communication\nstragglers. DivShare achieves this by having nodes fragment their models into\nparameter subsets and send, in parallel to computation, each subset to a random\nsample of other nodes instead of sequentially exchanging full models. The\ntransfer of smaller fragments allows more efficient usage of the collective\nbandwidth and enables nodes with slow network links to quickly contribute with\nat least some of their model parameters. By theoretically proving the\nconvergence of DivShare, we provide, to the best of our knowledge, the first\nformal proof of convergence for a DL algorithm that accounts for the effects of\nasynchronous communication with delays. We experimentally evaluate DivShare\nagainst two state-of-the-art DL baselines, AD-PSGD and Swift, and with two\nstandard datasets, CIFAR-10 and MovieLens. We find that DivShare with\ncommunication stragglers lowers time-to-accuracy by up to 3.9x compared to\nAD-PSGD on the CIFAR-10 dataset. Compared to baselines, DivShare also achieves\nup to 19.4% better accuracy and 9.5% lower test loss on the CIFAR-10 and\nMovieLens datasets, respectively.",
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "primary_category": "cs.DC",
    "comment": "Accepted to appear in the Proceedings of the ACM Web Conference 2025\n  (WWW '25)",
    "pdf_url": "http://arxiv.org/pdf/2410.12918v2",
    "published_date": "2024-10-16 18:03:52 UTC",
    "updated_date": "2025-02-03 18:24:33 UTC"
  },
  {
    "arxiv_id": "2410.12913v1",
    "title": "Fair Clustering for Data Summarization: Improved Approximation Algorithms and Complexity Insights",
    "authors": [
      "Ameet Gadekar",
      "Aristides Gionis",
      "Suhas Thejaswi"
    ],
    "abstract": "Data summarization tasks are often modeled as $k$-clustering problems, where\nthe goal is to choose $k$ data points, called cluster centers, that best\nrepresent the dataset by minimizing a clustering objective. A popular objective\nis to minimize the maximum distance between any data point and its nearest\ncenter, which is formalized as the $k$-center problem. While in some\napplications all data points can be chosen as centers, in the general setting,\ncenters must be chosen from a predefined subset of points, referred as\nfacilities or suppliers; this is known as the $k$-supplier problem. In this\nwork, we focus on fair data summarization modeled as the fair $k$-supplier\nproblem, where data consists of several groups, and a minimum number of centers\nmust be selected from each group while minimizing the $k$-supplier objective.\nThe groups can be disjoint or overlapping, leading to two distinct problem\nvariants each with different computational complexity.\n  We present $3$-approximation algorithms for both variants, improving the\npreviously known factor of $5$. For disjoint groups, our algorithm runs in\npolynomial time, while for overlapping groups, we present a fixed-parameter\ntractable algorithm, where the exponential runtime depends only on the number\nof groups and centers. We show that these approximation factors match the\ntheoretical lower bounds, assuming standard complexity theory conjectures.\nFinally, using an open-source implementation, we demonstrate the scalability of\nour algorithms on large synthetic datasets and assess the price of fairness on\nreal-world data, comparing solution quality with and without fairness\nconstraints.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY",
      "cs.DM"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.12913v1",
    "published_date": "2024-10-16 18:00:19 UTC",
    "updated_date": "2024-10-16 18:00:19 UTC"
  },
  {
    "arxiv_id": "2410.19803v2",
    "title": "First-Person Fairness in Chatbots",
    "authors": [
      "Tyna Eloundou",
      "Alex Beutel",
      "David G. Robinson",
      "Keren Gu-Lemberg",
      "Anna-Luisa Brakman",
      "Pamela Mishkin",
      "Meghan Shah",
      "Johannes Heidecke",
      "Lilian Weng",
      "Adam Tauman Kalai"
    ],
    "abstract": "Evaluating chatbot fairness is crucial given their rapid proliferation, yet\ntypical chatbot tasks (e.g., resume writing, entertainment) diverge from the\ninstitutional decision-making tasks (e.g., resume screening) which have\ntraditionally been central to discussion of algorithmic fairness. The\nopen-ended nature and diverse use-cases of chatbots necessitate novel methods\nfor bias assessment. This paper addresses these challenges by introducing a\nscalable counterfactual approach to evaluate \"first-person fairness,\" meaning\nfairness toward chatbot users based on demographic characteristics. Our method\nemploys a Language Model as a Research Assistant (LMRA) to yield quantitative\nmeasures of harmful stereotypes and qualitative analyses of demographic\ndifferences in chatbot responses. We apply this approach to assess biases in\nsix of our language models across millions of interactions, covering sixty-six\ntasks in nine domains and spanning two genders and four races. Independent\nhuman annotations corroborate the LMRA-generated bias evaluations. This study\nrepresents the first large-scale fairness evaluation based on real-world chat\ndata. We highlight that post-training reinforcement learning techniques\nsignificantly mitigate these biases. This evaluation provides a practical\nmethodology for ongoing bias monitoring and mitigation.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CY",
    "comment": "In ICLR 2025, 59 pages, 27 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.19803v2",
    "published_date": "2024-10-16 17:59:47 UTC",
    "updated_date": "2025-03-03 15:13:10 UTC"
  },
  {
    "arxiv_id": "2410.12784v2",
    "title": "JudgeBench: A Benchmark for Evaluating LLM-based Judges",
    "authors": [
      "Sijun Tan",
      "Siyuan Zhuang",
      "Kyle Montgomery",
      "William Y. Tang",
      "Alejandro Cuadron",
      "Chenguang Wang",
      "Raluca Ada Popa",
      "Ion Stoica"
    ],
    "abstract": "LLM-based judges have emerged as a scalable alternative to human evaluation\nand are increasingly used to assess, compare, and improve models. However, the\nreliability of LLM-based judges themselves is rarely scrutinized. As LLMs\nbecome more advanced, their responses grow more sophisticated, requiring\nstronger judges to evaluate them. Existing benchmarks primarily focus on a\njudge's alignment with human preferences, but often fail to account for more\nchallenging tasks where crowdsourced human preference is a poor indicator of\nfactual and logical correctness. To address this, we propose a novel evaluation\nframework to objectively evaluate LLM-based judges. Based on this framework, we\npropose JudgeBench, a benchmark for evaluating LLM-based judges on challenging\nresponse pairs spanning knowledge, reasoning, math, and coding. JudgeBench\nleverages a novel pipeline for converting existing difficult datasets into\nchallenging response pairs with preference labels reflecting objective\ncorrectness. Our comprehensive evaluation on a collection of prompted judges,\nfine-tuned judges, multi-agent judges, and reward models shows that JudgeBench\nposes a significantly greater challenge than previous benchmarks, with many\nstrong models (e.g., GPT-4o) performing just slightly better than random\nguessing. Overall, JudgeBench offers a reliable platform for assessing\nincreasingly advanced LLM-based judges. Data and code are available at\nhttps://github.com/ScalerLab/JudgeBench.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Published as a conference paper at ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.12784v2",
    "published_date": "2024-10-16 17:58:19 UTC",
    "updated_date": "2025-04-05 00:07:35 UTC"
  },
  {
    "arxiv_id": "2410.12774v1",
    "title": "Identifying Task Groupings for Multi-Task Learning Using Pointwise V-Usable Information",
    "authors": [
      "Yingya Li",
      "Timothy Miller",
      "Steven Bethard",
      "Guergana Savova"
    ],
    "abstract": "The success of multi-task learning can depend heavily on which tasks are\ngrouped together. Naively grouping all tasks or a random set of tasks can\nresult in negative transfer, with the multi-task models performing worse than\nsingle-task models. Though many efforts have been made to identify task\ngroupings and to measure the relatedness among different tasks, it remains a\nchallenging research topic to define a metric to identify the best task\ngrouping out of a pool of many potential task combinations. We propose a metric\nof task relatedness based on task difficulty measured by pointwise V-usable\ninformation (PVI). PVI is a recently proposed metric to estimate how much\nusable information a dataset contains given a model. We hypothesize that tasks\nwith not statistically different PVI estimates are similar enough to benefit\nfrom the joint learning process. We conduct comprehensive experiments to\nevaluate the feasibility of this metric for task grouping on 15 NLP datasets in\nthe general, biomedical, and clinical domains. We compare the results of the\njoint learners against single learners, existing baseline methods, and recent\nlarge language models, including Llama 2 and GPT-4. The results show that by\ngrouping tasks with similar PVI estimates, the joint learners yielded\ncompetitive results with fewer total parameters, with consistent performance\nacross domains.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "main paper 12 pages, Appendix 7 pages, 1 figure, 18 tables",
    "pdf_url": "http://arxiv.org/pdf/2410.12774v1",
    "published_date": "2024-10-16 17:49:45 UTC",
    "updated_date": "2024-10-16 17:49:45 UTC"
  },
  {
    "arxiv_id": "2410.12773v1",
    "title": "Harmon: Whole-Body Motion Generation of Humanoid Robots from Language Descriptions",
    "authors": [
      "Zhenyu Jiang",
      "Yuqi Xie",
      "Jinhan Li",
      "Ye Yuan",
      "Yifeng Zhu",
      "Yuke Zhu"
    ],
    "abstract": "Humanoid robots, with their human-like embodiment, have the potential to\nintegrate seamlessly into human environments. Critical to their coexistence and\ncooperation with humans is the ability to understand natural language\ncommunications and exhibit human-like behaviors. This work focuses on\ngenerating diverse whole-body motions for humanoid robots from language\ndescriptions. We leverage human motion priors from extensive human motion\ndatasets to initialize humanoid motions and employ the commonsense reasoning\ncapabilities of Vision Language Models (VLMs) to edit and refine these motions.\nOur approach demonstrates the capability to produce natural, expressive, and\ntext-aligned humanoid motions, validated through both simulated and real-world\nexperiments. More videos can be found at\nhttps://ut-austin-rpl.github.io/Harmon/.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted for oral presentation at 8th Annual Conference on Robot\n  Learning. Project website: https://ut-austin-rpl.github.io/Harmon/",
    "pdf_url": "http://arxiv.org/pdf/2410.12773v1",
    "published_date": "2024-10-16 17:48:50 UTC",
    "updated_date": "2024-10-16 17:48:50 UTC"
  },
  {
    "arxiv_id": "2410.12772v1",
    "title": "Vaccinating Federated Learning for Robust Modulation Classification in Distributed Wireless Networks",
    "authors": [
      "Hunmin Lee",
      "Hongju Seong",
      "Wonbin Kim",
      "Hyeokchan Kwon",
      "Daehee Seo"
    ],
    "abstract": "Automatic modulation classification (AMC) serves a vital role in ensuring\nefficient and reliable communication services within distributed wireless\nnetworks. Recent developments have seen a surge in interest in deep neural\nnetwork (DNN)-based AMC models, with Federated Learning (FL) emerging as a\npromising framework. Despite these advancements, the presence of various noises\nwithin the signal exerts significant challenges while optimizing models to\ncapture salient features. Furthermore, existing FL-based AMC models commonly\nrely on linear aggregation strategies, which face notable difficulties in\nintegrating locally fine-tuned parameters within practical non-IID (Independent\nand Identically Distributed) environments, thereby hindering optimal learning\nconvergence. To address these challenges, we propose FedVaccine, a novel FL\nmodel aimed at improving generalizability across signals with varying noise\nlevels by deliberately introducing a balanced level of noise. This is\naccomplished through our proposed harmonic noise resilience approach, which\nidentifies an optimal noise tolerance for DNN models, thereby regulating the\ntraining process and mitigating overfitting. Additionally, FedVaccine overcomes\nthe limitations of existing FL-based AMC models' linear aggregation by\nemploying a split-learning strategy using structural clustering topology and\nlocal queue data structure, enabling adaptive and cumulative updates to local\nmodels. Our experimental results, including IID and non-IID datasets as well as\nablation studies, confirm FedVaccine's robust performance and superiority over\nexisting FL-based AMC approaches across different noise levels. These findings\nhighlight FedVaccine's potential to enhance the reliability and performance of\nAMC systems in practical wireless network environments.",
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.12772v1",
    "published_date": "2024-10-16 17:48:47 UTC",
    "updated_date": "2024-10-16 17:48:47 UTC"
  },
  {
    "arxiv_id": "2410.12771v1",
    "title": "Open Materials 2024 (OMat24) Inorganic Materials Dataset and Models",
    "authors": [
      "Luis Barroso-Luque",
      "Muhammed Shuaibi",
      "Xiang Fu",
      "Brandon M. Wood",
      "Misko Dzamba",
      "Meng Gao",
      "Ammar Rizvi",
      "C. Lawrence Zitnick",
      "Zachary W. Ulissi"
    ],
    "abstract": "The ability to discover new materials with desirable properties is critical\nfor numerous applications from helping mitigate climate change to advances in\nnext generation computing hardware. AI has the potential to accelerate\nmaterials discovery and design by more effectively exploring the chemical space\ncompared to other computational methods or by trial-and-error. While\nsubstantial progress has been made on AI for materials data, benchmarks, and\nmodels, a barrier that has emerged is the lack of publicly available training\ndata and open pre-trained models. To address this, we present a Meta FAIR\nrelease of the Open Materials 2024 (OMat24) large-scale open dataset and an\naccompanying set of pre-trained models. OMat24 contains over 110 million\ndensity functional theory (DFT) calculations focused on structural and\ncompositional diversity. Our EquiformerV2 models achieve state-of-the-art\nperformance on the Matbench Discovery leaderboard and are capable of predicting\nground-state stability and formation energies to an F1 score above 0.9 and an\naccuracy of 20 meV/atom, respectively. We explore the impact of model size,\nauxiliary denoising objectives, and fine-tuning on performance across a range\nof datasets including OMat24, MPtraj, and Alexandria. The open release of the\nOMat24 dataset and models enables the research community to build upon our\nefforts and drive further advancements in AI-assisted materials science.",
    "categories": [
      "cond-mat.mtrl-sci",
      "cs.AI",
      "physics.comp-ph"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "comment": "19 pages",
    "pdf_url": "http://arxiv.org/pdf/2410.12771v1",
    "published_date": "2024-10-16 17:48:34 UTC",
    "updated_date": "2024-10-16 17:48:34 UTC"
  },
  {
    "arxiv_id": "2410.12761v2",
    "title": "SAFREE: Training-Free and Adaptive Guard for Safe Text-to-Image And Video Generation",
    "authors": [
      "Jaehong Yoon",
      "Shoubin Yu",
      "Vaidehi Patil",
      "Huaxiu Yao",
      "Mohit Bansal"
    ],
    "abstract": "Recent advances in diffusion models have significantly enhanced their ability\nto generate high-quality images and videos, but they have also increased the\nrisk of producing unsafe content. Existing unlearning/editing-based methods for\nsafe generation remove harmful concepts from models but face several\nchallenges: (1) They cannot instantly remove harmful concepts without training.\n(2) Their safe generation capabilities depend on collected training data. (3)\nThey alter model weights, risking degradation in quality for content unrelated\nto toxic concepts. To address these, we propose SAFREE, a novel, training-free\napproach for safe T2I and T2V, that does not alter the model's weights.\nSpecifically, we detect a subspace corresponding to a set of toxic concepts in\nthe text embedding space and steer prompt embeddings away from this subspace,\nthereby filtering out harmful content while preserving intended semantics. To\nbalance the trade-off between filtering toxicity and preserving safe concepts,\nSAFREE incorporates a novel self-validating filtering mechanism that\ndynamically adjusts the denoising steps when applying the filtered embeddings.\nAdditionally, we incorporate adaptive re-attention mechanisms within the\ndiffusion latent space to selectively diminish the influence of features\nrelated to toxic concepts at the pixel level. In the end, SAFREE ensures\ncoherent safety checking, preserving the fidelity, quality, and safety of the\noutput. SAFREE achieves SOTA performance in suppressing unsafe content in T2I\ngeneration compared to training-free baselines and effectively filters targeted\nconcepts while maintaining high-quality images. It also shows competitive\nresults against training-based methods. We extend SAFREE to various T2I\nbackbones and T2V tasks, showcasing its flexibility and generalization. SAFREE\nprovides a robust and adaptable safeguard for ensuring safe visual generation.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "ICLR 2025; The first two authors contributed equally; Project page:\n  https://safree-safe-t2i-t2v.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2410.12761v2",
    "published_date": "2024-10-16 17:32:23 UTC",
    "updated_date": "2025-03-14 04:47:39 UTC"
  },
  {
    "arxiv_id": "2410.12759v1",
    "title": "Unitary Multi-Margin BERT for Robust Natural Language Processing",
    "authors": [
      "Hao-Yuan Chang",
      "Kang L. Wang"
    ],
    "abstract": "Recent developments in adversarial attacks on deep learning leave many\nmission-critical natural language processing (NLP) systems at risk of\nexploitation. To address the lack of computationally efficient adversarial\ndefense methods, this paper reports a novel, universal technique that\ndrastically improves the robustness of Bidirectional Encoder Representations\nfrom Transformers (BERT) by combining the unitary weights with the multi-margin\nloss. We discover that the marriage of these two simple ideas amplifies the\nprotection against malicious interference. Our model, the unitary multi-margin\nBERT (UniBERT), boosts post-attack classification accuracies significantly by\n5.3% to 73.8% while maintaining competitive pre-attack accuracies. Furthermore,\nthe pre-attack and post-attack accuracy tradeoff can be adjusted via a single\nscalar parameter to best fit the design requirements for the target\napplications.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.12759v1",
    "published_date": "2024-10-16 17:30:58 UTC",
    "updated_date": "2024-10-16 17:30:58 UTC"
  },
  {
    "arxiv_id": "2410.12730v3",
    "title": "Counterfactual Generative Modeling with Variational Causal Inference",
    "authors": [
      "Yulun Wu",
      "Louie McConnell",
      "Claudia Iriondo"
    ],
    "abstract": "Estimating an individual's counterfactual outcomes under interventions is a\nchallenging task for traditional causal inference and supervised learning\napproaches when the outcome is high-dimensional (e.g. gene expressions, facial\nimages) and covariates are relatively limited. In this case, to predict one's\noutcomes under counterfactual treatments, it is crucial to leverage individual\ninformation contained in the observed outcome in addition to the covariates.\nPrior works using variational inference in counterfactual generative modeling\nhave been focusing on neural adaptations and model variants within the\nconditional variational autoencoder formulation, which we argue is\nfundamentally ill-suited to the notion of counterfactual in causal inference.\nIn this work, we present a novel variational Bayesian causal inference\nframework and its theoretical backings to properly handle counterfactual\ngenerative modeling tasks, through which we are able to conduct counterfactual\nsupervision end-to-end during training without any counterfactual samples, and\nencourage disentangled exogenous noise abduction that aids the correct\nidentification of causal effect in counterfactual generations. In experiments,\nwe demonstrate the advantage of our framework compared to state-of-the-art\nmodels in counterfactual generative modeling on multiple benchmarks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.ST",
      "stat.ML",
      "stat.TH"
    ],
    "primary_category": "cs.LG",
    "comment": "Published as a conference paper at ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.12730v3",
    "published_date": "2024-10-16 16:44:12 UTC",
    "updated_date": "2025-03-18 17:48:13 UTC"
  },
  {
    "arxiv_id": "2411.00006v1",
    "title": "Personality-Guided Code Generation Using Large Language Models",
    "authors": [
      "Yaoqi Guo",
      "Zhenpeng Chen",
      "Jie M. Zhang",
      "Yang Liu",
      "Yun Ma"
    ],
    "abstract": "Code generation, the automatic creation of source code from natural language\ndescriptions, has garnered significant attention due to its potential to\nstreamline software development. Inspired by research that links\ntask-personality alignment with improved development outcomes, we conduct an\nempirical study on personality-guided code generation using large language\nmodels (LLMs). Specifically, we investigate how emulating personality traits\nappropriate to the coding tasks affects LLM performance. We extensively\nevaluate this approach using seven widely adopted LLMs across four\nrepresentative datasets. Our results show that personality guidance\nsignificantly enhances code generation accuracy, with improved pass rates in 23\nout of 28 LLM-dataset combinations. Notably, in 11 cases, the improvement\nexceeds 5%, and in 5 instances, it surpasses 10%, with the highest gain\nreaching 12.9%. Additionally, personality guidance can be easily integrated\nwith other prompting strategies to further boost performance.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.00006v1",
    "published_date": "2024-10-16 16:42:55 UTC",
    "updated_date": "2024-10-16 16:42:55 UTC"
  },
  {
    "arxiv_id": "2410.12728v1",
    "title": "Transformer based super-resolution downscaling for regional reanalysis: Full domain vs tiling approaches",
    "authors": [
      "Antonio Pérez",
      "Mario Santa Cruz",
      "Daniel San Martín",
      "José Manuel Gutiérrez"
    ],
    "abstract": "Super-resolution (SR) is a promising cost-effective downscaling methodology\nfor producing high-resolution climate information from coarser counterparts. A\nparticular application is downscaling regional reanalysis outputs (predictand)\nfrom the driving global counterparts (predictor). This study conducts an\nintercomparison of various SR downscaling methods focusing on temperature and\nusing the CERRA reanalysis (5.5 km resolution, produced with a regional\natmospheric model driven by ERA5) as example. The method proposed in this work\nis the Swin transformer and two alternative methods are used as benchmark\n(fully convolutional U-Net and convolutional and dense DeepESD) as well as the\nsimple bicubic interpolation. We compare two approaches, the standard one using\nthe full domain as input and a more scalable tiling approach, dividing the full\ndomain into tiles that are used as input. The methods are trained to downscale\nCERRA surface temperature, based on temperature information from the driving\nERA5; in addition, the tiling approach includes static orographic information.\nWe show that the tiling approach, which requires spatial transferability, comes\nat the cost of a lower performance (although it outperforms some full-domain\nbenchmarks), but provides an efficient scalable solution that allows SR\nreduction on a pan-European scale and is valuable for real-time applications.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.12728v1",
    "published_date": "2024-10-16 16:42:20 UTC",
    "updated_date": "2024-10-16 16:42:20 UTC"
  },
  {
    "arxiv_id": "2410.12720v1",
    "title": "HEnRY: A Multi-Agent System Framework for Multi-Domain Contexts",
    "authors": [
      "Emmanuele Lacavalla",
      "Shuyi Yang",
      "Riccardo Crupi",
      "Joseph E. Gonzalez"
    ],
    "abstract": "This project, named HEnRY, aims to introduce a Multi-Agent System (MAS) into\nIntesa Sanpaolo. The name HEnRY summarizes the project's core principles: the\nHierarchical organization of agents in a layered structure for efficient\nresource management; Efficient optimization of resources and operations to\nenhance overall performance; Reactive ability of agents to quickly respond to\nenvironmental stimuli; and Yielding adaptability and flexibility of agents to\nhandle unexpected situations. The discussion covers two distinct research\npaths: the first focuses on the system architecture, and the second on the\ncollaboration between agents. This work is not limited to the specific\nstructure of the Intesa Sanpaolo context; instead, it leverages existing\nresearch in MAS to introduce a new solution. Since Intesa Sanpaolo is organized\naccording to a model that aligns with international corporate governance best\npractices, this approach could also be relevant to similar scenarios.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.MA",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.12720v1",
    "published_date": "2024-10-16 16:28:49 UTC",
    "updated_date": "2024-10-16 16:28:49 UTC"
  },
  {
    "arxiv_id": "2410.12707v1",
    "title": "FusionLLM: A Decentralized LLM Training System on Geo-distributed GPUs with Adaptive Compression",
    "authors": [
      "Zhenheng Tang",
      "Xueze Kang",
      "Yiming Yin",
      "Xinglin Pan",
      "Yuxin Wang",
      "Xin He",
      "Qiang Wang",
      "Rongfei Zeng",
      "Kaiyong Zhao",
      "Shaohuai Shi",
      "Amelie Chi Zhou",
      "Bo Li",
      "Bingsheng He",
      "Xiaowen Chu"
    ],
    "abstract": "To alleviate hardware scarcity in training large deep neural networks (DNNs),\nparticularly large language models (LLMs), we present FusionLLM, a\ndecentralized training system designed and implemented for training DNNs using\ngeo-distributed GPUs across different computing clusters or individual devices.\nDecentralized training faces significant challenges regarding system design and\nefficiency, including: 1) the need for remote automatic differentiation (RAD),\n2) support for flexible model definitions and heterogeneous software, 3)\nheterogeneous hardware leading to low resource utilization or the straggler\nproblem, and 4) slow network communication. To address these challenges, in the\nsystem design, we represent the model as a directed acyclic graph of operators\n(OP-DAG). Each node in the DAG represents the operator in the DNNs, while the\nedge represents the data dependency between operators. Based on this design, 1)\nusers are allowed to customize any DNN without caring low-level operator\nimplementation; 2) we enable the task scheduling with the more fine-grained\nsub-tasks, offering more optimization space; 3) a DAG runtime executor can\nimplement RAD withour requiring the consistent low-level ML framework versions.\n  To enhance system efficiency, we implement a workload estimator and design an\nOP-Fence scheduler to cluster devices with similar bandwidths together and\npartition the DAG to increase throughput. Additionally, we propose an AdaTopK\ncompressor to adaptively compress intermediate activations and gradients at the\nslowest communication links. To evaluate the convergence and efficiency of our\nsystem and algorithms, we train ResNet-101 and GPT-2 on three real-world\ntestbeds using 48 GPUs connected with 8 Mbps~10 Gbps networks. Experimental\nresults demonstrate that our system and method can achieve 1.45 - 9.39x speedup\ncompared to baseline methods while ensuring convergence.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.12707v1",
    "published_date": "2024-10-16 16:13:19 UTC",
    "updated_date": "2024-10-16 16:13:19 UTC"
  },
  {
    "arxiv_id": "2410.12705v5",
    "title": "WorldCuisines: A Massive-Scale Benchmark for Multilingual and Multicultural Visual Question Answering on Global Cuisines",
    "authors": [
      "Genta Indra Winata",
      "Frederikus Hudi",
      "Patrick Amadeus Irawan",
      "David Anugraha",
      "Rifki Afina Putri",
      "Yutong Wang",
      "Adam Nohejl",
      "Ubaidillah Ariq Prathama",
      "Nedjma Ousidhoum",
      "Afifa Amriani",
      "Anar Rzayev",
      "Anirban Das",
      "Ashmari Pramodya",
      "Aulia Adila",
      "Bryan Wilie",
      "Candy Olivia Mawalim",
      "Ching Lam Cheng",
      "Daud Abolade",
      "Emmanuele Chersoni",
      "Enrico Santus",
      "Fariz Ikhwantri",
      "Garry Kuwanto",
      "Hanyang Zhao",
      "Haryo Akbarianto Wibowo",
      "Holy Lovenia",
      "Jan Christian Blaise Cruz",
      "Jan Wira Gotama Putra",
      "Junho Myung",
      "Lucky Susanto",
      "Maria Angelica Riera Machin",
      "Marina Zhukova",
      "Michael Anugraha",
      "Muhammad Farid Adilazuarda",
      "Natasha Santosa",
      "Peerat Limkonchotiwat",
      "Raj Dabre",
      "Rio Alexander Audino",
      "Samuel Cahyawijaya",
      "Shi-Xiong Zhang",
      "Stephanie Yulia Salim",
      "Yi Zhou",
      "Yinxuan Gui",
      "David Ifeoluwa Adelani",
      "En-Shiun Annie Lee",
      "Shogo Okada",
      "Ayu Purwarianti",
      "Alham Fikri Aji",
      "Taro Watanabe",
      "Derry Tanti Wijaya",
      "Alice Oh",
      "Chong-Wah Ngo"
    ],
    "abstract": "Vision Language Models (VLMs) often struggle with culture-specific knowledge,\nparticularly in languages other than English and in underrepresented cultural\ncontexts. To evaluate their understanding of such knowledge, we introduce\nWorldCuisines, a massive-scale benchmark for multilingual and multicultural,\nvisually grounded language understanding. This benchmark includes a visual\nquestion answering (VQA) dataset with text-image pairs across 30 languages and\ndialects, spanning 9 language families and featuring over 1 million data\npoints, making it the largest multicultural VQA benchmark to date. It includes\ntasks for identifying dish names and their origins. We provide evaluation\ndatasets in two sizes (12k and 60k instances) alongside a training dataset (1\nmillion instances). Our findings show that while VLMs perform better with\ncorrect location context, they struggle with adversarial contexts and\npredicting specific regional cuisines and languages. To support future\nresearch, we release a knowledge base with annotated food entries and images\nalong with the VQA data.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CL",
    "comment": "Best Theme Paper at NAACL 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.12705v5",
    "published_date": "2024-10-16 16:11:49 UTC",
    "updated_date": "2025-05-08 08:46:59 UTC"
  },
  {
    "arxiv_id": "2410.12700v1",
    "title": "Embedding an Ethical Mind: Aligning Text-to-Image Synthesis via Lightweight Value Optimization",
    "authors": [
      "Xingqi Wang",
      "Xiaoyuan Yi",
      "Xing Xie",
      "Jia Jia"
    ],
    "abstract": "Recent advancements in diffusion models trained on large-scale data have\nenabled the generation of indistinguishable human-level images, yet they often\nproduce harmful content misaligned with human values, e.g., social bias, and\noffensive content. Despite extensive research on Large Language Models (LLMs),\nthe challenge of Text-to-Image (T2I) model alignment remains largely\nunexplored. Addressing this problem, we propose LiVO (Lightweight Value\nOptimization), a novel lightweight method for aligning T2I models with human\nvalues. LiVO only optimizes a plug-and-play value encoder to integrate a\nspecified value principle with the input prompt, allowing the control of\ngenerated images over both semantics and values. Specifically, we design a\ndiffusion model-tailored preference optimization loss, which theoretically\napproximates the Bradley-Terry model used in LLM alignment but provides a more\nflexible trade-off between image quality and value conformity. To optimize the\nvalue encoder, we also develop a framework to automatically construct a\ntext-image preference dataset of 86k (prompt, aligned image, violating image,\nvalue principle) samples. Without updating most model parameters and through\nadaptive value selection from the input prompt, LiVO significantly reduces\nharmful outputs and achieves faster convergence, surpassing several strong\nbaselines and taking an initial step towards ethically aligned T2I models.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CY",
      "cs.LG",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by ACM Multimedia 2024. The dataset and code can be found at\n  https://github.com/achernarwang/LiVO",
    "pdf_url": "http://arxiv.org/pdf/2410.12700v1",
    "published_date": "2024-10-16 16:03:42 UTC",
    "updated_date": "2024-10-16 16:03:42 UTC"
  },
  {
    "arxiv_id": "2410.12895v1",
    "title": "Large Language Models and the Rationalist Empiricist Debate",
    "authors": [
      "David King"
    ],
    "abstract": "To many Chomsky's debates with Quine and Skinner are an updated version of\nthe Rationalist Empiricist debates of the 17th century. The consensus being\nthat Chomsky's Rationalism was victorious. This dispute has reemerged with the\nadvent of Large Language Models. With some arguing that LLMs vindicate\nrationalism because of the necessity of building in innate biases to make them\nwork. The necessity of building in innate biases is taken to prove that\nempiricism hasn't got the conceptual resources to explain linguistic\ncompetence. Such claims depend on the nature of the empiricism one is\nendorsing. Externalized Empiricism has no difficulties with innate apparatus\nonce they are determined empirically (Quine 1969). Thus, externalized\nempiricism is not refuted because of the need to build in innate biases in\nLLMs. Furthermore, the relevance of LLMs to the rationalist empiricist debate\nin relation to humans is dubious. For any claim about whether LLMs learn in an\nempiricist manner to be relevant to humans it needs to be shown that LLMs and\nhumans learn in the same way. Two key features distinguish humans and LLMs.\nHumans learn despite a poverty of stimulus and LLMs learn because of an\nincredibly rich stimulus. Human linguistic outputs are grounded in sensory\nexperience and LLMs are not. These differences in how the two learn indicates\nthat they both use different underlying competencies to produce their output.\nTherefore, any claims about whether LLMs learn in an empiricist manner are not\nrelevant to whether humans learn in an empiricist manner.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.12895v1",
    "published_date": "2024-10-16 15:49:33 UTC",
    "updated_date": "2024-10-16 15:49:33 UTC"
  },
  {
    "arxiv_id": "2410.12686v2",
    "title": "Automatic Mapping of Anatomical Landmarks from Free-Text Using Large Language Models: Insights from Llama-2",
    "authors": [
      "Mohamad Abdi",
      "Gerardo Hermosillo Valadez",
      "Halid Ziya Yerebakan"
    ],
    "abstract": "Anatomical landmarks are vital in medical imaging for navigation and anomaly\ndetection. Modern large language models (LLMs), like Llama-2, offer promise for\nautomating the mapping of these landmarks in free-text radiology reports to\ncorresponding positions in image data. Recent studies propose LLMs may develop\ncoherent representations of generative processes. Motivated by these insights,\nwe investigated whether LLMs accurately represent the spatial positions of\nanatomical landmarks. Through experiments with Llama-2 models, we found that\nthey can linearly represent anatomical landmarks in space with considerable\nrobustness to different prompts. These results underscore the potential of LLMs\nto enhance the efficiency and accuracy of medical imaging workflows.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "6 pages, 2 figures, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2410.12686v2",
    "published_date": "2024-10-16 15:48:28 UTC",
    "updated_date": "2024-10-17 12:52:30 UTC"
  },
  {
    "arxiv_id": "2410.12683v1",
    "title": "Generative Neural Reparameterization for Differentiable PDE-constrained Optimization",
    "authors": [
      "Archis S. Joglekar"
    ],
    "abstract": "Partial-differential-equation (PDE)-constrained optimization is a well-worn\ntechnique for acquiring optimal parameters of systems governed by PDEs.\nHowever, this approach is limited to providing a single set of optimal\nparameters per optimization. Given a differentiable PDE solver, if the free\nparameters are reparameterized as the output of a neural network, that neural\nnetwork can be trained to learn a map from a probability distribution to the\ndistribution of optimal parameters. This proves useful in the case where there\nare many well performing local minima for the PDE. We apply this technique to\ntrain a neural network that generates optimal parameters that minimize\nlaser-plasma instabilities relevant to laser fusion and show that the neural\nnetwork generates many well performing and diverse minima.",
    "categories": [
      "physics.comp-ph",
      "cs.AI",
      "cs.LG",
      "cs.NA",
      "math.NA",
      "physics.plasm-ph"
    ],
    "primary_category": "physics.comp-ph",
    "comment": "Accepted to D3S3: Data-driven and Differentiable Simulations,\n  Surrogates, and Solvers - Workshop @ NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.12683v1",
    "published_date": "2024-10-16 15:46:48 UTC",
    "updated_date": "2024-10-16 15:46:48 UTC"
  },
  {
    "arxiv_id": "2410.12672v5",
    "title": "Context Matters: Leveraging Contextual Features for Time Series Forecasting",
    "authors": [
      "Sameep Chattopadhyay",
      "Pulkit Paliwal",
      "Sai Shankar Narasimhan",
      "Shubhankar Agarwal",
      "Sandeep P. Chinchali"
    ],
    "abstract": "Time series forecasts are often influenced by exogenous contextual features\nin addition to their corresponding history. For example, in financial settings,\nit is hard to accurately predict a stock price without considering public\nsentiments and policy decisions in the form of news articles, tweets, etc.\nThough this is common knowledge, the current state-of-the-art (SOTA)\nforecasting models fail to incorporate such contextual information, owing to\nits heterogeneity and multimodal nature. To address this, we introduce\nContextFormer, a novel plug-and-play method to surgically integrate multimodal\ncontextual information into existing pre-trained forecasting models.\nContextFormer effectively distills forecast-specific information from rich\nmultimodal contexts, including categorical, continuous, time-varying, and even\ntextual information, to significantly enhance the performance of existing base\nforecasters. ContextFormer outperforms SOTA forecasting models by up to 30% on\na range of real-world datasets spanning energy, traffic, environmental, and\nfinancial domains.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.12672v5",
    "published_date": "2024-10-16 15:36:13 UTC",
    "updated_date": "2025-01-13 20:42:06 UTC"
  },
  {
    "arxiv_id": "2410.12665v1",
    "title": "Hamiltonian bridge: A physics-driven generative framework for targeted pattern control",
    "authors": [
      "Vishaal Krishnan",
      "Sumit Sinha",
      "L. Mahadevan"
    ],
    "abstract": "Patterns arise spontaneously in a range of systems spanning the sciences, and\ntheir study typically focuses on mechanisms to understand their evolution in\nspace-time. Increasingly, there has been a transition towards controlling these\npatterns in various functional settings, with implications for engineering.\nHere, we combine our knowledge of a general class of dynamical laws for pattern\nformation in non-equilibrium systems, and the power of stochastic optimal\ncontrol approaches to present a framework that allows us to control patterns at\nmultiple scales, which we dub the \"Hamiltonian bridge\". We use a mapping\nbetween stochastic many-body Lagrangian physics and deterministic Eulerian\npattern forming PDEs to leverage our recent approach utilizing the\nFeynman-Kac-based adjoint path integral formulation for the control of\ninteracting particles and generalize this to the active control of patterning\nfields. We demonstrate the applicability of our computational framework via\nnumerical experiments on the control of phase separation with and without a\nconserved order parameter, self-assembly of fluid droplets, coupled\nreaction-diffusion equations and finally a phenomenological model for\nspatio-temporal tissue differentiation. We interpret our numerical experiments\nin terms of a theoretical understanding of how the underlying physics shapes\nthe geometry of the pattern manifold, altering the transport paths of patterns\nand the nature of pattern interpolation. We finally conclude by showing how\noptimal control can be utilized to generate complex patterns via an iterative\ncontrol protocol over pattern forming pdes which can be casted as gradient\nflows. All together, our study shows how we can systematically build in\nphysical priors into a generative framework for pattern control in\nnon-equilibrium systems across multiple length and time scales.",
    "categories": [
      "cond-mat.soft",
      "cond-mat.stat-mech",
      "cs.AI",
      "math.DS",
      "math.OC"
    ],
    "primary_category": "cond-mat.soft",
    "comment": "29 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.12665v1",
    "published_date": "2024-10-16 15:24:54 UTC",
    "updated_date": "2024-10-16 15:24:54 UTC"
  },
  {
    "arxiv_id": "2410.12662v2",
    "title": "Cross-Modal Safety Mechanism Transfer in Large Vision-Language Models",
    "authors": [
      "Shicheng Xu",
      "Liang Pang",
      "Yunchang Zhu",
      "Huawei Shen",
      "Xueqi Cheng"
    ],
    "abstract": "Vision-language alignment in Large Vision-Language Models (LVLMs)\nsuccessfully enables LLMs to understand visual input. However, we find that\nexisting vision-language alignment methods fail to transfer the existing safety\nmechanism for text in LLMs to vision, which leads to vulnerabilities in toxic\nimage. To explore the cause of this problem, we give the insightful explanation\nof where and how the safety mechanism of LVLMs operates and conduct comparative\nanalysis between text and vision. We find that the hidden states at the\nspecific transformer layers play a crucial role in the successful activation of\nsafety mechanism, while the vision-language alignment at hidden states level in\ncurrent methods is insufficient. This results in a semantic shift for input\nimages compared to text in hidden states, therefore misleads the safety\nmechanism. To address this, we propose a novel Text-Guided vision-language\nAlignment method (TGA) for LVLMs. TGA retrieves the texts related to input\nvision and uses them to guide the projection of vision into the hidden states\nspace in LLMs. Experiments show that TGA not only successfully transfers the\nsafety mechanism for text in basic LLMs to vision in vision-language alignment\nfor LVLMs without any safety fine-tuning on the visual modality but also\nmaintains the general performance on various vision tasks (Safe and Good).",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.12662v2",
    "published_date": "2024-10-16 15:20:08 UTC",
    "updated_date": "2025-02-28 06:17:41 UTC"
  },
  {
    "arxiv_id": "2410.12656v3",
    "title": "Evaluating Morphological Compositional Generalization in Large Language Models",
    "authors": [
      "Mete Ismayilzada",
      "Defne Circi",
      "Jonne Sälevä",
      "Hale Sirin",
      "Abdullatif Köksal",
      "Bhuwan Dhingra",
      "Antoine Bosselut",
      "Duygu Ataman",
      "Lonneke van der Plas"
    ],
    "abstract": "Large language models (LLMs) have demonstrated significant progress in\nvarious natural language generation and understanding tasks. However, their\nlinguistic generalization capabilities remain questionable, raising doubts\nabout whether these models learn language similarly to humans. While humans\nexhibit compositional generalization and linguistic creativity in language use,\nthe extent to which LLMs replicate these abilities, particularly in morphology,\nis under-explored. In this work, we systematically investigate the\nmorphological generalization abilities of LLMs through the lens of\ncompositionality. We define morphemes as compositional primitives and design a\nnovel suite of generative and discriminative tasks to assess morphological\nproductivity and systematicity. Focusing on agglutinative languages such as\nTurkish and Finnish, we evaluate several state-of-the-art instruction-finetuned\nmultilingual models, including GPT-4 and Gemini. Our analysis shows that LLMs\nstruggle with morphological compositional generalization particularly when\napplied to novel word roots, with performance declining sharply as\nmorphological complexity increases. While models can identify individual\nmorphological combinations better than chance, their performance lacks\nsystematicity, leading to significant accuracy gaps compared to humans.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to NAACL 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.12656v3",
    "published_date": "2024-10-16 15:17:20 UTC",
    "updated_date": "2025-02-09 22:08:16 UTC"
  },
  {
    "arxiv_id": "2410.12652v1",
    "title": "Constrained Posterior Sampling: Time Series Generation with Hard Constraints",
    "authors": [
      "Sai Shankar Narasimhan",
      "Shubhankar Agarwal",
      "Litu Rout",
      "Sanjay Shakkottai",
      "Sandeep P. Chinchali"
    ],
    "abstract": "Generating realistic time series samples is crucial for stress-testing models\nand protecting user privacy by using synthetic data. In engineering and\nsafety-critical applications, these samples must meet certain hard constraints\nthat are domain-specific or naturally imposed by physics or nature. Consider,\nfor example, generating electricity demand patterns with constraints on peak\ndemand times. This can be used to stress-test the functioning of power grids\nduring adverse weather conditions. Existing approaches for generating\nconstrained time series are either not scalable or degrade sample quality. To\naddress these challenges, we introduce Constrained Posterior Sampling (CPS), a\ndiffusion-based sampling algorithm that aims to project the posterior mean\nestimate into the constraint set after each denoising update. Notably, CPS\nscales to a large number of constraints (~100) without requiring additional\ntraining. We provide theoretical justifications highlighting the impact of our\nprojection step on sampling. Empirically, CPS outperforms state-of-the-art\nmethods in sample quality and similarity to real time series by around 10% and\n42%, respectively, on real-world stocks, traffic, and air quality datasets.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.12652v1",
    "published_date": "2024-10-16 15:16:04 UTC",
    "updated_date": "2024-10-16 15:16:04 UTC"
  },
  {
    "arxiv_id": "2410.12641v1",
    "title": "Cascade learning in multi-task encoder-decoder networks for concurrent bone segmentation and glenohumeral joint assessment in shoulder CT scans",
    "authors": [
      "Luca Marsilio",
      "Davide Marzorati",
      "Matteo Rossi",
      "Andrea Moglia",
      "Luca Mainardi",
      "Alfonso Manzotti",
      "Pietro Cerveri"
    ],
    "abstract": "Osteoarthritis is a degenerative condition affecting bones and cartilage,\noften leading to osteophyte formation, bone density loss, and joint space\nnarrowing. Treatment options to restore normal joint function vary depending on\nthe severity of the condition. This work introduces an innovative deep-learning\nframework processing shoulder CT scans. It features the semantic segmentation\nof the proximal humerus and scapula, the 3D reconstruction of bone surfaces,\nthe identification of the glenohumeral (GH) joint region, and the staging of\nthree common osteoarthritic-related pathologies: osteophyte formation (OS), GH\nspace reduction (JS), and humeroscapular alignment (HSA). The pipeline\ncomprises two cascaded CNN architectures: 3D CEL-UNet for segmentation and 3D\nArthro-Net for threefold classification. A retrospective dataset of 571 CT\nscans featuring patients with various degrees of GH osteoarthritic-related\npathologies was used to train, validate, and test the pipeline. Root mean\nsquared error and Hausdorff distance median values for 3D reconstruction were\n0.22mm and 1.48mm for the humerus and 0.24mm and 1.48mm for the scapula,\noutperforming state-of-the-art architectures and making it potentially suitable\nfor a PSI-based shoulder arthroplasty preoperative plan context. The\nclassification accuracy for OS, JS, and HSA consistently reached around 90%\nacross all three categories. The computational time for the inference pipeline\nwas less than 15s, showcasing the framework's efficiency and compatibility with\northopedic radiology practice. The outcomes represent a promising advancement\ntoward the medical translation of artificial intelligence tools. This progress\naims to streamline the preoperative planning pipeline delivering high-quality\nbone surfaces and supporting surgeons in selecting the most suitable surgical\napproach according to the unique patient joint conditions.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.12641v1",
    "published_date": "2024-10-16 15:00:31 UTC",
    "updated_date": "2024-10-16 15:00:31 UTC"
  },
  {
    "arxiv_id": "2410.12631v1",
    "title": "Explainable Moral Values: a neuro-symbolic approach to value classification",
    "authors": [
      "Nicolas Lazzari",
      "Stefano De Giorgis",
      "Aldo Gangemi",
      "Valentina Presutti"
    ],
    "abstract": "This work explores the integration of ontology-based reasoning and Machine\nLearning techniques for explainable value classification. By relying on an\nontological formalization of moral values as in the Moral Foundations Theory,\nrelying on the DnS Ontology Design Pattern, the \\textit{sandra} neuro-symbolic\nreasoner is used to infer values (fomalized as descriptions) that are\n\\emph{satisfied by} a certain sentence. Sentences, alongside their structured\nrepresentation, are automatically generated using an open-source Large Language\nModel. The inferred descriptions are used to automatically detect the value\nassociated with a sentence. We show that only relying on the reasoner's\ninference results in explainable classification comparable to other more\ncomplex approaches. We show that combining the reasoner's inferences with\ndistributional semantics methods largely outperforms all the baselines,\nincluding complex models based on neural network architectures. Finally, we\nbuild a visualization tool to explore the potential of theory-based values\nclassification, which is publicly available at http://xmv.geomeaning.com/.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Published at ESWC24 Satellite Event",
    "pdf_url": "http://arxiv.org/pdf/2410.12631v1",
    "published_date": "2024-10-16 14:53:13 UTC",
    "updated_date": "2024-10-16 14:53:13 UTC"
  },
  {
    "arxiv_id": "2410.13907v2",
    "title": "NSmark: Null Space Based Black-box Watermarking Defense Framework for Language Models",
    "authors": [
      "Haodong Zhao",
      "Jinming Hu",
      "Peixuan Li",
      "Fangqi Li",
      "Jinrui Sha",
      "Tianjie Ju",
      "Peixuan Chen",
      "Zhuosheng Zhang",
      "Gongshen Liu"
    ],
    "abstract": "Language models (LMs) have emerged as critical intellectual property (IP)\nassets that necessitate protection. Although various watermarking strategies\nhave been proposed, they remain vulnerable to Linear Functionality Equivalence\nAttack (LFEA), which can invalidate most existing white-box watermarks without\nprior knowledge of the watermarking scheme or training data. This paper\nanalyzes and extends the attack scenarios of LFEA to the commonly employed\nblack-box settings for LMs by considering Last-Layer outputs (dubbed LL-LFEA).\nWe discover that the null space of the output matrix remains invariant against\nLL-LFEA attacks. Based on this finding, we propose NSmark, a black-box\nwatermarking scheme that is task-agnostic and capable of resisting LL-LFEA\nattacks. NSmark consists of three phases: (i) watermark generation using the\ndigital signature of the owner, enhanced by spread spectrum modulation for\nincreased robustness; (ii) watermark embedding through an output mapping\nextractor that preserves the LM performance while maximizing watermark\ncapacity; (iii) watermark verification, assessed by extraction rate and null\nspace conformity. Extensive experiments on both pre-training and downstream\ntasks confirm the effectiveness, scalability, reliability, fidelity, and\nrobustness of our approach. Code is available at\nhttps://github.com/dongdongzhaoUP/NSmark.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CR",
    "comment": "In progress",
    "pdf_url": "http://arxiv.org/pdf/2410.13907v2",
    "published_date": "2024-10-16 14:45:27 UTC",
    "updated_date": "2025-02-03 03:15:34 UTC"
  },
  {
    "arxiv_id": "2410.12613v1",
    "title": "Exploring Model Kinship for Merging Large Language Models",
    "authors": [
      "Yedi Hu",
      "Yunzhi Yao",
      "Ningyu Zhang",
      "Shumin Deng",
      "Huajun Chen"
    ],
    "abstract": "Model merging has become one of the key technologies for enhancing the\ncapabilities and efficiency of Large Language Models (LLMs). However, our\nunderstanding of the expected performance gains and principles when merging any\ntwo models remains limited. In this work, we introduce model kinship, the\ndegree of similarity or relatedness between LLMs, analogous to biological\nevolution. With comprehensive empirical analysis, we find that there is a\ncertain relationship between model kinship and the performance gains after\nmodel merging, which can help guide our selection of candidate models. Inspired\nby this, we propose a new model merging strategy: Top-k Greedy Merging with\nModel Kinship, which can yield better performance on benchmark datasets.\nSpecifically, we discover that using model kinship as a criterion can assist us\nin continuously performing model merging, alleviating the degradation (local\noptima) in model evolution, whereas model kinship can serve as a guide to\nescape these traps. Code is available at\nhttps://github.com/zjunlp/ModelKinship.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.CL",
    "comment": "Ongoing work",
    "pdf_url": "http://arxiv.org/pdf/2410.12613v1",
    "published_date": "2024-10-16 14:29:29 UTC",
    "updated_date": "2024-10-16 14:29:29 UTC"
  },
  {
    "arxiv_id": "2410.12609v2",
    "title": "Towards Graph Foundation Models: Training on Knowledge Graphs Enables Transferability to General Graphs",
    "authors": [
      "Kai Wang",
      "Siqiang Luo",
      "Caihua Shan",
      "Yifei Shen"
    ],
    "abstract": "Inspired by the success of large language models, there is a trend toward\ndeveloping graph foundation models to conduct diverse downstream tasks in\nvarious domains. However, current models often require extra fine-tuning to\napply their learned structural and semantic representations to new graphs,\nwhich limits their versatility. Recent breakthroughs in zero-shot inductive\nreasoning on knowledge graphs (KGs), offer us a new perspective on extending KG\nreasoning to general graph applications. In this paper, we introduce SCR, a\nunified graph reasoning framework designed to train on knowledge graphs and\neffectively generalize across a wide range of graph tasks and domains. We begin\nby designing the task-specific KG structures to establish a unified topology\nfor different task formats. Then we propose semantic-conditioned message\npassing, a novel mechanism addressing the inherent semantic isolation in\ntraditional KG reasoning, by jointly modeling structural and semantic\ninvariance patterns in graph representations. To demonstrate the effectiveness,\nwe evaluate the inductive reasoning capability of SCR using 38 diverse graph\ndatasets, covering node-level, link-level, and graph-level tasks across\nmultiple domains. Our results show substantial performance gains over existing\nfoundation models and supervised baselines, highlighting the efficacy and\nadaptability of our approach.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "25 Pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.12609v2",
    "published_date": "2024-10-16 14:26:08 UTC",
    "updated_date": "2025-05-15 14:27:59 UTC"
  },
  {
    "arxiv_id": "2410.12607v1",
    "title": "Low-Rank Adversarial PGD Attack",
    "authors": [
      "Dayana Savostianova",
      "Emanuele Zangrando",
      "Francesco Tudisco"
    ],
    "abstract": "Adversarial attacks on deep neural network models have seen rapid development\nand are extensively used to study the stability of these networks. Among\nvarious adversarial strategies, Projected Gradient Descent (PGD) is a widely\nadopted method in computer vision due to its effectiveness and quick\nimplementation, making it suitable for adversarial training. In this work, we\nobserve that in many cases, the perturbations computed using PGD predominantly\naffect only a portion of the singular value spectrum of the original image,\nsuggesting that these perturbations are approximately low-rank. Motivated by\nthis observation, we propose a variation of PGD that efficiently computes a\nlow-rank attack. We extensively validate our method on a range of standard\nmodels as well as robust models that have undergone adversarial training. Our\nanalysis indicates that the proposed low-rank PGD can be effectively used in\nadversarial training due to its straightforward and fast implementation coupled\nwith competitive performance. Notably, we find that low-rank PGD often performs\ncomparably to, and sometimes even outperforms, the traditional full-rank PGD\nattack, while using significantly less memory.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NA",
      "math.NA",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.12607v1",
    "published_date": "2024-10-16 14:24:51 UTC",
    "updated_date": "2024-10-16 14:24:51 UTC"
  },
  {
    "arxiv_id": "2410.12606v2",
    "title": "Self-Supervised Learning of Disentangled Representations for Multivariate Time-Series",
    "authors": [
      "Ching Chang",
      "Chiao-Tung Chan",
      "Wei-Yao Wang",
      "Wen-Chih Peng",
      "Tien-Fu Chen"
    ],
    "abstract": "Multivariate time-series data in fields like healthcare and industry are\ninformative but challenging due to high dimensionality and lack of labels.\nRecent self-supervised learning methods excel in learning rich representations\nwithout labels but struggle with disentangled embeddings and inductive bias\nissues like transformation-invariance. To address these challenges, we\nintroduce TimeDRL, a framework for multivariate time-series representation\nlearning with dual-level disentangled embeddings. TimeDRL features: (i)\ndisentangled timestamp-level and instance-level embeddings using a [CLS] token\nstrategy; (ii) timestamp-predictive and instance-contrastive tasks for\nrepresentation learning; and (iii) avoidance of augmentation methods to\neliminate inductive biases. Experiments on forecasting and classification\ndatasets show TimeDRL outperforms existing methods, with further validation in\nsemi-supervised settings with limited labeled data.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "This submission has been withdrawn to avoid duplication with a full\n  version of the paper that is already available in another arXiv entry\n  (arXiv:2410.12606). The withdrawn version was a short format prepared for a\n  NeurIPS workshop and is no longer necessary as a separate arXiv submission",
    "pdf_url": "http://arxiv.org/pdf/2410.12606v2",
    "published_date": "2024-10-16 14:24:44 UTC",
    "updated_date": "2024-10-21 06:27:47 UTC"
  },
  {
    "arxiv_id": "2410.12593v1",
    "title": "Expand and Compress: Exploring Tuning Principles for Continual Spatio-Temporal Graph Forecasting",
    "authors": [
      "Wei Chen",
      "Yuxuan Liang"
    ],
    "abstract": "The widespread deployment of sensing devices leads to a surge in data for\nspatio-temporal forecasting applications such as traffic flow, air quality, and\nwind energy. Although spatio-temporal graph neural networks have achieved\nsuccess in modeling various static spatio-temporal forecasting scenarios,\nreal-world spatio-temporal data are typically received in a streaming manner,\nand the network continuously expands with the installation of new sensors.\nThus, spatio-temporal forecasting in streaming scenarios faces dual challenges:\nthe inefficiency of retraining models over newly arrived data and the\ndetrimental effects of catastrophic forgetting over long-term history. To\naddress these challenges, we propose a novel prompt tuning-based continuous\nforecasting method, following two fundamental tuning principles guided by\nempirical and theoretical analysis: expand and compress, which effectively\nresolve the aforementioned problems with lightweight tuning parameters.\nSpecifically, we integrate the base spatio-temporal graph neural network with a\ncontinuous prompt pool, utilizing stored prompts (i.e., few learnable\nparameters) in memory, and jointly optimize them with the base spatio-temporal\ngraph neural network. This method ensures that the model sequentially learns\nfrom the spatio-temporal data stream to accomplish tasks for corresponding\nperiods. Extensive experimental results on multiple real-world datasets\ndemonstrate the multi-faceted superiority of our method over the\nstate-of-the-art baselines, including effectiveness, efficiency, universality,\netc.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.12593v1",
    "published_date": "2024-10-16 14:12:11 UTC",
    "updated_date": "2024-10-16 14:12:11 UTC"
  },
  {
    "arxiv_id": "2410.12591v1",
    "title": "Rethinking Visual Counterfactual Explanations Through Region Constraint",
    "authors": [
      "Bartlomiej Sobieski",
      "Jakub Grzywaczewski",
      "Bartlomiej Sadlej",
      "Matthew Tivnan",
      "Przemyslaw Biecek"
    ],
    "abstract": "Visual counterfactual explanations (VCEs) have recently gained immense\npopularity as a tool for clarifying the decision-making process of image\nclassifiers. This trend is largely motivated by what these explanations promise\nto deliver -- indicate semantically meaningful factors that change the\nclassifier's decision. However, we argue that current state-of-the-art\napproaches lack a crucial component -- the region constraint -- whose absence\nprevents from drawing explicit conclusions, and may even lead to faulty\nreasoning due to phenomenons like confirmation bias. To address the issue of\nprevious methods, which modify images in a very entangled and widely dispersed\nmanner, we propose region-constrained VCEs (RVCEs), which assume that only a\npredefined image region can be modified to influence the model's prediction. To\neffectively sample from this subclass of VCEs, we propose Region-Constrained\nCounterfactual Schr\\\"odinger Bridges (RCSB), an adaptation of a tractable\nsubclass of Schr\\\"odinger Bridges to the problem of conditional inpainting,\nwhere the conditioning signal originates from the classifier of interest. In\naddition to setting a new state-of-the-art by a large margin, we extend RCSB to\nallow for exact counterfactual reasoning, where the predefined region contains\nonly the factor of interest, and incorporating the user to actively interact\nwith the RVCE by predefining the regions manually.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Preprint",
    "pdf_url": "http://arxiv.org/pdf/2410.12591v1",
    "published_date": "2024-10-16 14:10:48 UTC",
    "updated_date": "2024-10-16 14:10:48 UTC"
  },
  {
    "arxiv_id": "2410.12583v1",
    "title": "STRUX: An LLM for Decision-Making with Structured Explanations",
    "authors": [
      "Yiming Lu",
      "Yebowen Hu",
      "Hassan Foroosh",
      "Wei Jin",
      "Fei Liu"
    ],
    "abstract": "Countless decisions shape our daily lives, and it is paramount to understand\nthe how and why behind these choices. In this paper, we introduce a new LLM\ndecision-making framework called STRUX, which enhances LLM decision-making by\nproviding structured explanations. These include favorable and adverse facts\nrelated to the decision, along with their respective strengths. STRUX begins by\ndistilling lengthy information into a concise table of key facts. It then\nemploys a series of self-reflection steps to determine which of these facts are\npivotal, categorizing them as either favorable or adverse in relation to a\nspecific decision. Lastly, we fine-tune an LLM to identify and prioritize these\nkey facts to optimize decision-making. STRUX has been evaluated on the\nchallenging task of forecasting stock investment decisions based on earnings\ncall transcripts and demonstrated superior performance against strong\nbaselines. It enhances decision transparency by allowing users to understand\nthe impact of different factors, representing a meaningful step towards\npractical decision-making with LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "10 pages, 7 figures, submitted to NAACL 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.12583v1",
    "published_date": "2024-10-16 14:01:22 UTC",
    "updated_date": "2024-10-16 14:01:22 UTC"
  },
  {
    "arxiv_id": "2410.12577v1",
    "title": "On the Utility of Domain Modeling Assistance with Large Language Models",
    "authors": [
      "Meriem Ben Chaaben",
      "Lola Burgueño",
      "Istvan David",
      "Houari Sahraoui"
    ],
    "abstract": "Model-driven engineering (MDE) simplifies software development through\nabstraction, yet challenges such as time constraints, incomplete domain\nunderstanding, and adherence to syntactic constraints hinder the design\nprocess. This paper presents a study to evaluate the usefulness of a novel\napproach utilizing large language models (LLMs) and few-shot prompt learning to\nassist in domain modeling. The aim of this approach is to overcome the need for\nextensive training of AI-based completion models on scarce domain-specific\ndatasets and to offer versatile support for various modeling activities,\nproviding valuable recommendations to software modelers. To support this\napproach, we developed MAGDA, a user-friendly tool, through which we conduct a\nuser study and assess the real-world applicability of our approach in the\ncontext of domain modeling, offering valuable insights into its usability and\neffectiveness.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.12577v1",
    "published_date": "2024-10-16 13:55:34 UTC",
    "updated_date": "2024-10-16 13:55:34 UTC"
  },
  {
    "arxiv_id": "2410.12568v2",
    "title": "Robust RL with LLM-Driven Data Synthesis and Policy Adaptation for Autonomous Driving",
    "authors": [
      "Sihao Wu",
      "Jiaxu Liu",
      "Xiangyu Yin",
      "Guangliang Cheng",
      "Xingyu Zhao",
      "Meng Fang",
      "Xinping Yi",
      "Xiaowei Huang"
    ],
    "abstract": "The integration of Large Language Models (LLMs) into autonomous driving\nsystems demonstrates strong common sense and reasoning abilities, effectively\naddressing the pitfalls of purely data-driven methods. Current LLM-based agents\nrequire lengthy inference times and face challenges in interacting with\nreal-time autonomous driving environments. A key open question is whether we\ncan effectively leverage the knowledge from LLMs to train an efficient and\nrobust Reinforcement Learning (RL) agent. This paper introduces RAPID, a novel\n\\underline{\\textbf{R}}obust \\underline{\\textbf{A}}daptive\n\\underline{\\textbf{P}}olicy \\underline{\\textbf{I}}nfusion and\n\\underline{\\textbf{D}}istillation framework, which trains specialized\nmix-of-policy RL agents using data synthesized by an LLM-based driving agent\nand online adaptation. RAPID features three key designs: 1) utilization of\noffline data collected from an LLM agent to distil expert knowledge into RL\npolicies for faster real-time inference; 2) introduction of robust distillation\nin RL to inherit both performance and robustness from LLM-based teacher; and 3)\nemployment of a mix-of-policy approach for joint decision decoding with a\npolicy adapter. Through fine-tuning via online environment interaction, RAPID\nreduces the forgetting of LLM knowledge while maintaining adaptability to\ndifferent tasks. Extensive experiments demonstrate RAPID's capability to\neffectively integrate LLM knowledge into scaled-down RL policies in an\nefficient, adaptable, and robust way. Code and checkpoints will be made\npublicly available upon acceptance.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.12568v2",
    "published_date": "2024-10-16 13:43:00 UTC",
    "updated_date": "2024-10-20 04:35:34 UTC"
  },
  {
    "arxiv_id": "2410.12561v1",
    "title": "Development of Image Collection Method Using YOLO and Siamese Network",
    "authors": [
      "Chan Young Shin",
      "Ah Hyun Lee",
      "Jun Young Lee",
      "Ji Min Lee",
      "Soo Jin Park"
    ],
    "abstract": "As we enter the era of big data, collecting high-quality data is very\nimportant. However, collecting data by humans is not only very time-consuming\nbut also expensive. Therefore, many scientists have devised various methods to\ncollect data using computers. Among them, there is a method called web\ncrawling, but the authors found that the crawling method has a problem in that\nunintended data is collected along with the user. The authors found that this\ncan be filtered using the object recognition model YOLOv10. However, there are\ncases where data that is not properly filtered remains. Here, image\nreclassification was performed by additionally utilizing the distance output\nfrom the Siamese network, and higher performance was recorded than other\nclassification models. (average \\_f1 score YOLO+MobileNet\n0.678->YOLO+SiameseNet 0.772)) The user can specify a distance threshold to\nadjust the balance between data deficiency and noise-robustness. The authors\nalso found that the Siamese network can achieve higher performance with fewer\nresources because the cropped images are used for object recognition when\nprocessing images in the Siamese network. (Class 20 mean-based f1 score,\nnon-crop+Siamese(MobileNetV3-Small) 80.94 -> crop\npreprocessing+Siamese(MobileNetV3-Small) 82.31) In this way, the image\nretrieval system that utilizes two consecutive models to reduce errors can save\nusers' time and effort, and build better quality data faster and with fewer\nresources than before.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "15 pages, 13 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2410.12561v1",
    "published_date": "2024-10-16 13:36:47 UTC",
    "updated_date": "2024-10-16 13:36:47 UTC"
  },
  {
    "arxiv_id": "2410.12558v1",
    "title": "A Claim Decomposition Benchmark for Long-form Answer Verification",
    "authors": [
      "Zhihao Zhang",
      "Yixing Fan",
      "Ruqing Zhang",
      "Jiafeng Guo"
    ],
    "abstract": "The advancement of LLMs has significantly boosted the performance of complex\nlong-form question answering tasks. However, one prominent issue of LLMs is the\ngenerated \"hallucination\" responses that are not factual. Consequently,\nattribution for each claim in responses becomes a common solution to improve\nthe factuality and verifiability. Existing researches mainly focus on how to\nprovide accurate citations for the response, which largely overlook the\nimportance of identifying the claims or statements for each response. To bridge\nthis gap, we introduce a new claim decomposition benchmark, which requires\nbuilding system that can identify atomic and checkworthy claims for LLM\nresponses. Specifically, we present the Chinese Atomic Claim Decomposition\nDataset (CACDD), which builds on the WebCPM dataset with additional expert\nannotations to ensure high data quality. The CACDD encompasses a collection of\n500 human-annotated question-answer pairs, including a total of 4956 atomic\nclaims. We further propose a new pipeline for human annotation and describe the\nchallenges of this task. In addition, we provide experiment results on\nzero-shot, few-shot and fine-tuned LLMs as baselines. The results show that the\nclaim decomposition is highly challenging and requires further explorations.\nAll code and data are publicly available at\n\\url{https://github.com/FBzzh/CACDD}.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by CCIR 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.12558v1",
    "published_date": "2024-10-16 13:34:51 UTC",
    "updated_date": "2024-10-16 13:34:51 UTC"
  },
  {
    "arxiv_id": "2410.12543v3",
    "title": "LLM-based Translation Inference with Iterative Bilingual Understanding",
    "authors": [
      "Andong Chen",
      "Kehai Chen",
      "Yang Xiang",
      "Xuefeng Bai",
      "Muyun Yang",
      "Yang Feng",
      "Tiejun Zhao",
      "Min zhang"
    ],
    "abstract": "The remarkable understanding and generation capabilities of large language\nmodels (LLMs) have greatly improved translation performance. However, incorrect\nunderstanding of the sentence to be translated can degrade translation quality.\nTo address this issue, we proposed a novel Iterative Bilingual Understanding\nTranslation (IBUT) method based on the cross-lingual capabilities of LLMs and\nthe dual characteristics of translation tasks. The cross-lingual capability of\nLLMs enables the generation of contextual understanding for both the source and\ntarget languages separately. Furthermore, the dual characteristics allow IBUT\nto generate effective cross-lingual feedback, iteratively refining contextual\nunderstanding, thereby reducing errors and improving translation performance.\nExperimental results showed that the proposed IBUT outperforms several strong\ncomparison methods, especially being generalized to multiple domains (e.g.,\nnews, commonsense, and cultural translation benchmarks).",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Work in progress",
    "pdf_url": "http://arxiv.org/pdf/2410.12543v3",
    "published_date": "2024-10-16 13:21:46 UTC",
    "updated_date": "2024-12-30 07:57:10 UTC"
  },
  {
    "arxiv_id": "2410.12539v2",
    "title": "Counterfactual Effect Decomposition in Multi-Agent Sequential Decision Making",
    "authors": [
      "Stelios Triantafyllou",
      "Aleksa Sukovic",
      "Yasaman Zolfimoselo",
      "Goran Radanovic"
    ],
    "abstract": "We address the challenge of explaining counterfactual outcomes in multi-agent\nMarkov decision processes. In particular, we aim to explain the total\ncounterfactual effect of an agent's action on the outcome of a realized\nscenario through its influence on the environment dynamics and the agents'\nbehavior. To achieve this, we introduce a novel causal explanation formula that\ndecomposes the counterfactual effect by attributing to each agent and state\nvariable a score reflecting their respective contributions to the effect.\nFirst, we show that the total counterfactual effect of an agent's action can be\ndecomposed into two components: one measuring the effect that propagates\nthrough all subsequent agents' actions and another related to the effect that\npropagates through the state transitions. Building on recent advancements in\ncausal contribution analysis, we further decompose these two effects as\nfollows. For the former, we consider agent-specific effects -- a causal concept\nthat quantifies the counterfactual effect of an agent's action that propagates\nthrough a subset of agents. Based on this notion, we use Shapley value to\nattribute the effect to individual agents. For the latter, we consider the\nconcept of structure-preserving interventions and attribute the effect to state\nvariables based on their \"intrinsic\" contributions. Through extensive\nexperimentation, we demonstrate the interpretability of our approach in a\nGridworld environment with LLM-assisted agents and a sepsis management\nsimulator.",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.12539v2",
    "published_date": "2024-10-16 13:20:35 UTC",
    "updated_date": "2025-02-07 09:54:53 UTC"
  },
  {
    "arxiv_id": "2410.12538v2",
    "title": "Automated Vehicles at Unsignalized Intersections: Safety and Efficiency Implications of Mixed-Human-Automated Traffic",
    "authors": [
      "Saeed Rahmani",
      "Zhenlin Xu",
      "Simeon C. Calvert",
      "Bart van Arem"
    ],
    "abstract": "The integration of automated vehicles (AVs) into transportation systems\npresents an unprecedented opportunity to enhance road safety and efficiency.\nHowever, understanding the interactions between AVs and human-driven vehicles\n(HVs) at intersections remains an open research question. This study aims to\nbridge this gap by examining behavioral differences and adaptations of AVs and\nHVs at unsignalized intersections by utilizing two large-scale AV datasets from\nWaymo and Lyft. By using a systematic methodology, the research identifies and\nanalyzes merging and crossing conflicts by calculating key safety and\nefficiency metrics, including time to collision (TTC), post-encroachment time\n(PET), maximum required deceleration (MRD), time advantage (TA), and speed and\nacceleration profiles. The findings reveal a paradox in mixed traffic flow:\nwhile AVs maintain larger safety margins, their conservative behavior can lead\nto unexpected situations for human drivers, potentially causing unsafe\nconditions. From a performance point of view, human drivers exhibit more\nconsistent behavior when interacting with AVs versus other HVs, suggesting AVs\nmay contribute to harmonizing traffic flow patterns. Moreover, notable\ndifferences were observed between Waymo and Lyft vehicles, which highlights the\nimportance of considering manufacturer-specific AV behaviors in traffic\nmodeling and management strategies for the safe integration of AVs. The\nprocessed dataset utilized in this study is openly published to foster the\nresearch on AV-HV interactions.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "stat.AP"
    ],
    "primary_category": "cs.RO",
    "comment": "This work has been submitted to Transportation Research Record for\n  potential publication",
    "pdf_url": "http://arxiv.org/pdf/2410.12538v2",
    "published_date": "2024-10-16 13:19:32 UTC",
    "updated_date": "2025-02-04 01:23:31 UTC"
  },
  {
    "arxiv_id": "2410.12537v2",
    "title": "Is Complex Query Answering Really Complex?",
    "authors": [
      "Cosimo Gregucci",
      "Bo Xiong",
      "Daniel Hernandez",
      "Lorenzo Loconte",
      "Pasquale Minervini",
      "Steffen Staab",
      "Antonio Vergari"
    ],
    "abstract": "Complex query answering (CQA) on knowledge graphs (KGs) is gaining momentum\nas a challenging reasoning task. In this paper, we show that the current\nbenchmarks for CQA might not be as complex as we think, as the way they are\nbuilt distorts our perception of progress in this field. For example, we find\nthat in these benchmarks, most queries (up to 98% for some query types) can be\nreduced to simpler problems, e.g., link prediction, where only one link needs\nto be predicted. The performance of state-of-the-art CQA models decreases\nsignificantly when such models are evaluated on queries that cannot be reduced\nto easier types. Thus, we propose a set of more challenging benchmarks composed\nof queries that require models to reason over multiple hops and better reflect\nthe construction of real-world KGs. In a systematic empirical investigation,\nthe new benchmarks show that current methods leave much to be desired from\ncurrent CQA methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.12537v2",
    "published_date": "2024-10-16 13:19:03 UTC",
    "updated_date": "2025-02-18 12:40:13 UTC"
  },
  {
    "arxiv_id": "2410.12521v1",
    "title": "Spectrum Sharing using Deep Reinforcement Learning in Vehicular Networks",
    "authors": [
      "Riya Dinesh Deshpande",
      "Faheem A. Khan",
      "Qasim Zeeshan Ahmed"
    ],
    "abstract": "As the number of devices getting connected to the vehicular network grows\nexponentially, addressing the numerous challenges of effectively allocating\nspectrum in dynamic vehicular environment becomes increasingly difficult.\nTraditional methods may not suffice to tackle this issue. In vehicular networks\nsafety critical messages are involved and it is important to implement an\nefficient spectrum allocation paradigm for hassle free communication as well as\nmanage the congestion in the network. To tackle this, a Deep Q Network (DQN)\nmodel is proposed as a solution, leveraging its ability to learn optimal\nstrategies over time and make decisions. The paper presents a few results and\nanalyses, demonstrating the efficacy of the DQN model in enhancing spectrum\nsharing efficiency. Deep Reinforcement Learning methods for sharing spectrum in\nvehicular networks have shown promising outcomes, demonstrating the system's\nability to adjust to dynamic communication environments. Both SARL and MARL\nmodels have exhibited successful rates of V2V communication, with the\ncumulative reward of the RL model reaching its maximum as training progresses.",
    "categories": [
      "eess.SP",
      "cs.AI"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.12521v1",
    "published_date": "2024-10-16 12:59:59 UTC",
    "updated_date": "2024-10-16 12:59:59 UTC"
  },
  {
    "arxiv_id": "2410.12520v1",
    "title": "QueensCAMP: an RGB-D dataset for robust Visual SLAM",
    "authors": [
      "Hudson M. S. Bruno",
      "Esther L. Colombini",
      "Sidney N. Givigi Jr"
    ],
    "abstract": "Visual Simultaneous Localization and Mapping (VSLAM) is a fundamental\ntechnology for robotics applications. While VSLAM research has achieved\nsignificant advancements, its robustness under challenging situations, such as\npoor lighting, dynamic environments, motion blur, and sensor failures, remains\na challenging issue. To address these challenges, we introduce a novel RGB-D\ndataset designed for evaluating the robustness of VSLAM systems. The dataset\ncomprises real-world indoor scenes with dynamic objects, motion blur, and\nvarying illumination, as well as emulated camera failures, including lens dirt,\ncondensation, underexposure, and overexposure. Additionally, we offer\nopen-source scripts for injecting camera failures into any images, enabling\nfurther customization by the research community. Our experiments demonstrate\nthat ORB-SLAM2, a traditional VSLAM algorithm, and TartanVO, a Deep\nLearning-based VO algorithm, can experience performance degradation under these\nchallenging conditions. Therefore, this dataset and the camera failure\nopen-source tools provide a valuable resource for developing more robust VSLAM\nsystems capable of handling real-world challenges.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "6 pages",
    "pdf_url": "http://arxiv.org/pdf/2410.12520v1",
    "published_date": "2024-10-16 12:58:08 UTC",
    "updated_date": "2024-10-16 12:58:08 UTC"
  },
  {
    "arxiv_id": "2410.12509v1",
    "title": "Benchmarking Defeasible Reasoning with Large Language Models -- Initial Experiments and Future Directions",
    "authors": [
      "Ilias Tachmazidis",
      "Sotiris Batsakis",
      "Grigoris Antoniou"
    ],
    "abstract": "Large Language Models (LLMs) have gained prominence in the AI landscape due\nto their exceptional performance. Thus, it is essential to gain a better\nunderstanding of their capabilities and limitations, among others in terms of\nnonmonotonic reasoning. This paper proposes a benchmark that corresponds to\nvarious defeasible rule-based reasoning patterns. We modified an existing\nbenchmark for defeasible logic reasoners by translating defeasible rules into\ntext suitable for LLMs. We conducted preliminary experiments on nonmonotonic\nrule-based reasoning using ChatGPT and compared it with reasoning patterns\ndefined by defeasible logic.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Presented at NeLaMKRR@KR, 2024 (arXiv:2410.05339)",
    "pdf_url": "http://arxiv.org/pdf/2410.12509v1",
    "published_date": "2024-10-16 12:36:23 UTC",
    "updated_date": "2024-10-16 12:36:23 UTC"
  },
  {
    "arxiv_id": "2410.13905v3",
    "title": "P4GCN: Vertical Federated Social Recommendation with Privacy-Preserving Two-Party Graph Convolution Network",
    "authors": [
      "Zheng Wang",
      "Wanwan Wang",
      "Yimin Huang",
      "Zhaopeng Peng",
      "Ziqi Yang",
      "Ming Yao",
      "Cheng Wang",
      "Xiaoliang Fan"
    ],
    "abstract": "In recent years, graph neural networks (GNNs) have been commonly utilized for\nsocial recommendation systems. However, real-world scenarios often present\nchallenges related to user privacy and business constraints, inhibiting direct\naccess to valuable social information from other platforms. While many existing\nmethods have tackled matrix factorization-based social recommendations without\ndirect social data access, developing GNN-based federated social recommendation\nmodels under similar conditions remains largely unexplored. To address this\nissue, we propose a novel vertical federated social recommendation method\nleveraging privacy-preserving two-party graph convolution networks (P4GCN) to\nenhance recommendation accuracy without requiring direct access to sensitive\nsocial information. First, we introduce a Sandwich-Encryption module to ensure\ncomprehensive data privacy during the collaborative computing process. Second,\nwe provide a thorough theoretical analysis of the privacy guarantees,\nconsidering the participation of both curious and honest parties. Extensive\nexperiments on four real-world datasets demonstrate that P4GCN outperforms\nstate-of-the-art methods in terms of recommendation accuracy.",
    "categories": [
      "cs.SI",
      "cs.AI",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.SI",
    "comment": "Accepted by WWW25",
    "pdf_url": "http://arxiv.org/pdf/2410.13905v3",
    "published_date": "2024-10-16 12:29:22 UTC",
    "updated_date": "2025-02-04 03:46:27 UTC"
  },
  {
    "arxiv_id": "2410.12501v1",
    "title": "DH-VTON: Deep Text-Driven Virtual Try-On via Hybrid Attention Learning",
    "authors": [
      "Jiabao Wei",
      "Zhiyuan Ma"
    ],
    "abstract": "Virtual Try-ON (VTON) aims to synthesis specific person images dressed in\ngiven garments, which recently receives numerous attention in online shopping\nscenarios. Currently, the core challenges of the VTON task mainly lie in the\nfine-grained semantic extraction (i.e.,deep semantics) of the given reference\ngarments during depth estimation and effective texture preservation when the\ngarments are synthesized and warped onto human body. To cope with these issues,\nwe propose DH-VTON, a deep text-driven virtual try-on model featuring a special\nhybrid attention learning strategy and deep garment semantic preservation\nmodule. By standing on the shoulder of a well-built pre-trained\npaint-by-example (abbr. PBE) approach, we present our DH-VTON pipeline in this\nwork. Specifically, to extract the deep semantics of the garments, we first\nintroduce InternViT-6B as fine-grained feature learner, which can be trained to\nalign with the large-scale intrinsic knowledge with deep text semantics\n(e.g.,\"neckline\" or \"girdle\") to make up for the deficiency of the commonly\nadopted CLIP encoder. Based on this, to enhance the customized dressing\nabilities, we further introduce Garment-Feature ControlNet Plus (abbr. GFC+)\nmodule and propose to leverage a fresh hybrid attention strategy for training,\nwhich can adaptively integrate fine-grained characteristics of the garments\ninto the different layers of the VTON model, so as to achieve multi-scale\nfeatures preservation effects. Extensive experiments on several representative\ndatasets demonstrate that our method outperforms previous diffusion-based and\nGAN-based approaches, showing competitive performance in preserving garment\ndetails and generating authentic human images.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "5 pages, 6 figures, ICASSP2025",
    "pdf_url": "http://arxiv.org/pdf/2410.12501v1",
    "published_date": "2024-10-16 12:27:10 UTC",
    "updated_date": "2024-10-16 12:27:10 UTC"
  },
  {
    "arxiv_id": "2410.12893v3",
    "title": "MIRROR: A Novel Approach for the Automated Evaluation of Open-Ended Question Generation",
    "authors": [
      "Aniket Deroy",
      "Subhankar Maity",
      "Sudeshna Sarkar"
    ],
    "abstract": "Automatic question generation is a critical task that involves evaluating\nquestion quality by considering factors such as engagement, pedagogical value,\nand the ability to stimulate critical thinking. These aspects require\nhuman-like understanding and judgment, which automated systems currently lack.\nHowever, human evaluations are costly and impractical for large-scale samples\nof generated questions. Therefore, we propose a novel system, MIRROR (Multi-LLM\nIterative Review and Response for Optimized Rating), which leverages large\nlanguage models (LLMs) to automate the evaluation process for questions\ngenerated by automated question generation systems. We experimented with\nseveral state-of-the-art LLMs, such as GPT-4, Gemini, and Llama2-70b. We\nobserved that the scores of human evaluation metrics, namely relevance,\nappropriateness, novelty, complexity, and grammaticality, improved when using\nthe feedback-based approach called MIRROR, tending to be closer to the human\nbaseline scores. Furthermore, we observed that Pearson's correlation\ncoefficient between GPT-4 and human experts improved when using our proposed\nfeedback-based approach, MIRROR, compared to direct prompting for evaluation.\nError analysis shows that our proposed approach, MIRROR, significantly helps to\nimprove relevance and appropriateness.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Updated Version",
    "pdf_url": "http://arxiv.org/pdf/2410.12893v3",
    "published_date": "2024-10-16 12:24:42 UTC",
    "updated_date": "2025-03-25 15:02:17 UTC"
  },
  {
    "arxiv_id": "2410.12490v2",
    "title": "Stabilize the Latent Space for Image Autoregressive Modeling: A Unified Perspective",
    "authors": [
      "Yongxin Zhu",
      "Bocheng Li",
      "Hang Zhang",
      "Xin Li",
      "Linli Xu",
      "Lidong Bing"
    ],
    "abstract": "Latent-based image generative models, such as Latent Diffusion Models (LDMs)\nand Mask Image Models (MIMs), have achieved notable success in image generation\ntasks. These models typically leverage reconstructive autoencoders like VQGAN\nor VAE to encode pixels into a more compact latent space and learn the data\ndistribution in the latent space instead of directly from pixels. However, this\npractice raises a pertinent question: Is it truly the optimal choice? In\nresponse, we begin with an intriguing observation: despite sharing the same\nlatent space, autoregressive models significantly lag behind LDMs and MIMs in\nimage generation. This finding contrasts sharply with the field of NLP, where\nthe autoregressive model GPT has established a commanding presence. To address\nthis discrepancy, we introduce a unified perspective on the relationship\nbetween latent space and generative models, emphasizing the stability of latent\nspace in image generative modeling. Furthermore, we propose a simple but\neffective discrete image tokenizer to stabilize the latent space for image\ngenerative modeling by applying K-Means on the latent features of\nself-supervised learning models. Experimental results show that image\nautoregressive modeling with our tokenizer (DiGIT) benefits both image\nunderstanding and image generation with the next token prediction principle,\nwhich is inherently straightforward for GPT models but challenging for other\ngenerative models. Remarkably, for the first time, a GPT-style autoregressive\nmodel for images outperforms LDMs, which also exhibits substantial improvement\nakin to GPT when scaling up model size. Our findings underscore the potential\nof an optimized latent space and the integration of discrete tokenization in\nadvancing the capabilities of image generative models. The code is available at\n\\url{https://github.com/DAMO-NLP-SG/DiGIT}.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.12490v2",
    "published_date": "2024-10-16 12:13:17 UTC",
    "updated_date": "2024-10-31 11:42:07 UTC"
  },
  {
    "arxiv_id": "2410.12483v2",
    "title": "Stable Object Placement Planning From Contact Point Robustness",
    "authors": [
      "Philippe Nadeau",
      "Jonathan Kelly"
    ],
    "abstract": "We introduce a planner designed to guide robot manipulators in stably placing\nobjects within intricate scenes. Our proposed method reverses the traditional\napproach to object placement: our planner selects contact points first and then\ndetermines a placement pose that solicits the selected points. This is instead\nof sampling poses, identifying contact points, and evaluating pose quality. Our\nalgorithm facilitates stability-aware object placement planning, imposing no\nrestrictions on object shape, convexity, or mass density homogeneity, while\navoiding combinatorial computational complexity. Our proposed stability\nheuristic enables our planner to find a solution about 20 times faster when\ncompared to the same algorithm not making use of the heuristic and eight times\nfaster than a state-of-the-art method that uses the traditional\nsample-and-evaluate approach. Our proposed planner is also more successful in\nfinding stable placements than the five other benchmarked algorithms. Derived\nfrom first principles and validated in ten real robot experiments, our planner\noffers a general and scalable method to tackle the problem of object placement\nplanning with rigid objects.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Submitted to IEEE Transactions on Robotics. Contains 15 pages, 13\n  figures, and 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2410.12483v2",
    "published_date": "2024-10-16 12:02:15 UTC",
    "updated_date": "2024-12-06 22:52:06 UTC"
  },
  {
    "arxiv_id": "2410.12481v1",
    "title": "SAC-GLAM: Improving Online RL for LLM agents with Soft Actor-Critic and Hindsight Relabeling",
    "authors": [
      "Loris Gaven",
      "Clement Romac",
      "Thomas Carta",
      "Sylvain Lamprier",
      "Olivier Sigaud",
      "Pierre-Yves Oudeyer"
    ],
    "abstract": "The past years have seen Large Language Models (LLMs) strive not only as\ngenerative models but also as agents solving textual sequential decision-making\ntasks. When facing complex environments where their zero-shot abilities are\ninsufficient, recent work showed online Reinforcement Learning (RL) could be\nused for the LLM agent to discover and learn efficient strategies\ninteractively. However, most prior work sticks to on-policy algorithms, which\ngreatly reduces the scope of methods such agents could use for both exploration\nand exploitation, such as experience replay and hindsight relabeling. Yet, such\nmethods may be key for LLM learning agents, and in particular when designing\nautonomous intrinsically motivated agents sampling and pursuing their own goals\n(i.e. autotelic agents). This paper presents and studies an adaptation of Soft\nActor-Critic and hindsight relabeling to LLM agents. Our method not only paves\nthe path towards autotelic LLM agents that learn online but can also outperform\non-policy methods in more classic multi-goal RL environments.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.12481v1",
    "published_date": "2024-10-16 11:59:27 UTC",
    "updated_date": "2024-10-16 11:59:27 UTC"
  },
  {
    "arxiv_id": "2411.00005v3",
    "title": "Mastering the Craft of Data Synthesis for CodeLLMs",
    "authors": [
      "Meng Chen",
      "Philip Arthur",
      "Qianyu Feng",
      "Cong Duy Vu Hoang",
      "Yu-Heng Hong",
      "Mahdi Kazemi Moghaddam",
      "Omid Nezami",
      "Thien Nguyen",
      "Gioacchino Tangari",
      "Duy Vu",
      "Thanh Vu",
      "Mark Johnson",
      "Krishnaram Kenthapadi",
      "Don Dharmasiri",
      "Long Duong",
      "Yuan-Fang Li"
    ],
    "abstract": "Large language models (LLMs) have shown impressive performance in \\emph{code}\nunderstanding and generation, making coding tasks a key focus for researchers\ndue to their practical applications and value as a testbed for LLM evaluation.\nData synthesis and filtering techniques have been widely adopted and shown to\nbe highly effective in this context. In this paper, we present a focused survey\nand taxonomy of these techniques, emphasizing recent advancements. We highlight\nkey challenges, explore future research directions, and offer practical\nguidance for new researchers entering the field.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "Accepted at NAACL 2025",
    "pdf_url": "http://arxiv.org/pdf/2411.00005v3",
    "published_date": "2024-10-16 11:57:14 UTC",
    "updated_date": "2025-02-07 08:49:48 UTC"
  },
  {
    "arxiv_id": "2410.12480v2",
    "title": "KcMF: A Knowledge-compliant Framework for Schema and Entity Matching with Fine-tuning-free LLMs",
    "authors": [
      "Yongqin Xu",
      "Huan Li",
      "Ke Chen",
      "Lidan Shou"
    ],
    "abstract": "Schema matching (SM) and entity matching (EM) tasks are crucial for data\nintegration. While large language models (LLMs) have shown promising results in\nthese tasks, they suffer from hallucinations and confusion about task\ninstructions. This study presents the Knowledge-Compliant Matching Framework\n(KcMF), an LLM-based approach that addresses these issues without the need for\ndomain-specific fine-tuning. KcMF employs a once-and-for-all pseudo-code-based\ntask decomposition strategy to adopt natural language statements that guide LLM\nreasoning and reduce confusion across various task types. We also propose two\nmechanisms, Dataset as Knowledge (DaK) and Example as Knowledge (EaK), to build\ndomain knowledge sets when unstructured domain knowledge is lacking. Moreover,\nwe introduce a result-ensemble strategy to leverage multiple knowledge sources\nand suppress badly formatted outputs. Extensive evaluations confirm that KcMF\nclearly enhances five LLM backbones in both SM and EM tasks while outperforming\nthe non-LLM competitors by an average F1-score of 17.93%.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.DB",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "under reveiw; new results and analysis added, typos corrected",
    "pdf_url": "http://arxiv.org/pdf/2410.12480v2",
    "published_date": "2024-10-16 11:50:02 UTC",
    "updated_date": "2025-02-17 07:23:58 UTC"
  },
  {
    "arxiv_id": "2410.12473v1",
    "title": "Unifying Economic and Language Models for Enhanced Sentiment Analysis of the Oil Market",
    "authors": [
      "Himmet Kaplan",
      "Ralf-Peter Mundani",
      "Heiko Rölke",
      "Albert Weichselbraun",
      "Martin Tschudy"
    ],
    "abstract": "Crude oil, a critical component of the global economy, has its prices\ninfluenced by various factors such as economic trends, political events, and\nnatural disasters. Traditional prediction methods based on historical data have\ntheir limits in forecasting, but recent advancements in natural language\nprocessing bring new possibilities for event-based analysis. In particular,\nLanguage Models (LM) and their advancement, the Generative Pre-trained\nTransformer (GPT), have shown potential in classifying vast amounts of natural\nlanguage. However, these LMs often have difficulty with domain-specific\nterminology, limiting their effectiveness in the crude oil sector. Addressing\nthis gap, we introduce CrudeBERT, a fine-tuned LM specifically for the crude\noil market. The results indicate that CrudeBERT's sentiment scores align more\nclosely with the WTI Futures curve and significantly enhance price predictions,\nunderscoring the crucial role of integrating economic principles into LMs.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.12473v1",
    "published_date": "2024-10-16 11:41:24 UTC",
    "updated_date": "2024-10-16 11:41:24 UTC"
  },
  {
    "arxiv_id": "2410.12468v2",
    "title": "Evaluating Software Development Agents: Patch Patterns, Code Quality, and Issue Complexity in Real-World GitHub Scenarios",
    "authors": [
      "Zhi Chen",
      "Lingxiao Jiang"
    ],
    "abstract": "In recent years, AI-based software engineering has progressed from\npre-trained models to advanced agentic workflows, with Software Development\nAgents representing the next major leap. These agents, capable of reasoning,\nplanning, and interacting with external environments, offer promising solutions\nto complex software engineering tasks. However, while much research has\nevaluated code generated by large language models (LLMs), comprehensive studies\non agent-generated patches, particularly in real-world settings, are lacking.\nThis study addresses that gap by evaluating 4,892 patches from 10 top-ranked\nagents on 500 real-world GitHub issues from SWE-Bench Verified, focusing on\ntheir impact on code quality. Our analysis shows no single agent dominated,\nwith 170 issues unresolved, indicating room for improvement. Even for patches\nthat passed unit tests and resolved issues, agents made different file and\nfunction modifications compared to the gold patches from repository developers,\nrevealing limitations in the benchmark's test case coverage. Most agents\nmaintained code reliability and security, avoiding new bugs or vulnerabilities;\nwhile some agents increased code complexity, many reduced code duplication and\nminimized code smells. Finally, agents performed better on simpler codebases,\nsuggesting that breaking complex tasks into smaller sub-tasks could improve\neffectiveness. This study provides the first comprehensive evaluation of\nagent-generated patches on real-world GitHub issues, offering insights to\nadvance AI-driven software development.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "Paper accepted to the SANER 2025 Conference Research Track",
    "pdf_url": "http://arxiv.org/pdf/2410.12468v2",
    "published_date": "2024-10-16 11:33:57 UTC",
    "updated_date": "2024-12-27 13:52:05 UTC"
  },
  {
    "arxiv_id": "2410.12457v1",
    "title": "Sharpness-Aware Black-Box Optimization",
    "authors": [
      "Feiyang Ye",
      "Yueming Lyu",
      "Xuehao Wang",
      "Masashi Sugiyama",
      "Yu Zhang",
      "Ivor Tsang"
    ],
    "abstract": "Black-box optimization algorithms have been widely used in various machine\nlearning problems, including reinforcement learning and prompt fine-tuning.\nHowever, directly optimizing the training loss value, as commonly done in\nexisting black-box optimization methods, could lead to suboptimal model quality\nand generalization performance. To address those problems in black-box\noptimization, we propose a novel Sharpness-Aware Black-box Optimization (SABO)\nalgorithm, which applies a sharpness-aware minimization strategy to improve the\nmodel generalization. Specifically, the proposed SABO method first\nreparameterizes the objective function by its expectation over a Gaussian\ndistribution. Then it iteratively updates the parameterized distribution by\napproximated stochastic gradients of the maximum objective value within a small\nneighborhood around the current solution in the Gaussian distribution space.\nTheoretically, we prove the convergence rate and generalization bound of the\nproposed SABO algorithm. Empirically, extensive experiments on the black-box\nprompt fine-tuning tasks demonstrate the effectiveness of the proposed SABO\nmethod in improving model generalization performance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "27 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.12457v1",
    "published_date": "2024-10-16 11:08:06 UTC",
    "updated_date": "2024-10-16 11:08:06 UTC"
  },
  {
    "arxiv_id": "2410.12445v3",
    "title": "Open Ko-LLM Leaderboard2: Bridging Foundational and Practical Evaluation for Korean LLMs",
    "authors": [
      "Hyeonwoo Kim",
      "Dahyun Kim",
      "Jihoo Kim",
      "Sukyung Lee",
      "Yungi Kim",
      "Chanjun Park"
    ],
    "abstract": "The Open Ko-LLM Leaderboard has been instrumental in benchmarking Korean\nLarge Language Models (LLMs), yet it has certain limitations. Notably, the\ndisconnect between quantitative improvements on the overly academic leaderboard\nbenchmarks and the qualitative impact of the models should be addressed.\nFurthermore, the benchmark suite is largely composed of translated versions of\ntheir English counterparts, which may not fully capture the intricacies of the\nKorean language. To address these issues, we propose Open Ko-LLM Leaderboard2,\nan improved version of the earlier Open Ko-LLM Leaderboard. The original\nbenchmarks are entirely replaced with new tasks that are more closely aligned\nwith real-world capabilities. Additionally, four new native Korean benchmarks\nare introduced to better reflect the distinct characteristics of the Korean\nlanguage. Through these refinements, Open Ko-LLM Leaderboard2 seeks to provide\na more meaningful evaluation for advancing Korean LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to NAACL 2025 Industry",
    "pdf_url": "http://arxiv.org/pdf/2410.12445v3",
    "published_date": "2024-10-16 10:49:22 UTC",
    "updated_date": "2025-03-04 01:18:34 UTC"
  },
  {
    "arxiv_id": "2410.12443v2",
    "title": "Reconstruction of Differentially Private Text Sanitization via Large Language Models",
    "authors": [
      "Shuchao Pang",
      "Zhigang Lu",
      "Haichen Wang",
      "Peng Fu",
      "Yongbin Zhou",
      "Minhui Xue"
    ],
    "abstract": "Differential privacy (DP) is the de facto privacy standard against privacy\nleakage attacks, including many recently discovered ones against large language\nmodels (LLMs). However, we discovered that LLMs could reconstruct the\naltered/removed privacy from given DP-sanitized prompts. We propose two attacks\n(black-box and white-box) based on the accessibility to LLMs and show that LLMs\ncould connect the pair of DP-sanitized text and the corresponding private\ntraining data of LLMs by giving sample text pairs as instructions (in the\nblack-box attacks) or fine-tuning data (in the white-box attacks). To\nillustrate our findings, we conduct comprehensive experiments on modern LLMs\n(e.g., LLaMA-2, LLaMA-3, ChatGPT-3.5, ChatGPT-4, ChatGPT-4o, Claude-3,\nClaude-3.5, OPT, GPT-Neo, GPT-J, Gemma-2, and Pythia) using commonly used\ndatasets (such as WikiMIA, Pile-CC, and Pile-Wiki) against both word-level and\nsentence-level DP. The experimental results show promising recovery rates,\ne.g., the black-box attacks against the word-level DP over WikiMIA dataset gave\n72.18% on LLaMA-2 (70B), 82.39% on LLaMA-3 (70B), 75.35% on Gemma-2, 91.2% on\nChatGPT-4o, and 94.01% on Claude-3.5 (Sonnet). More urgently, this study\nindicates that these well-known LLMs have emerged as a new security risk for\nexisting DP text sanitization approaches in the current environment.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.12443v2",
    "published_date": "2024-10-16 10:41:17 UTC",
    "updated_date": "2025-04-20 03:22:57 UTC"
  },
  {
    "arxiv_id": "2410.12428v1",
    "title": "Conformity in Large Language Models",
    "authors": [
      "Xiaochen Zhu",
      "Caiqi Zhang",
      "Tom Stafford",
      "Nigel Collier",
      "Andreas Vlachos"
    ],
    "abstract": "The conformity effect describes the tendency of individuals to align their\nresponses with the majority. Studying this bias in large language models (LLMs)\nis crucial, as LLMs are increasingly used in various information-seeking and\ndecision-making tasks as conversation partners to improve productivity. Thus,\nconformity to incorrect responses can compromise their effectiveness. In this\npaper, we adapt psychological experiments to examine the extent of conformity\nin state-of-the-art LLMs. Our findings reveal that all models tested exhibit\nvarying levels of conformity toward the majority, regardless of their initial\nchoice or correctness, across different knowledge domains. Notably, we are the\nfirst to show that LLMs are more likely to conform when they are more uncertain\nin their own prediction. We further explore factors that influence conformity,\nsuch as training paradigms and input characteristics, finding that\ninstruction-tuned models are less susceptible to conformity, while increasing\nthe naturalness of majority tones amplifies conformity. Finally, we propose two\ninterventions--Devil's Advocate and Question Distillation--to mitigate\nconformity, providing insights into building more robust language models.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "16 pages (8 pages main body), 14 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.12428v1",
    "published_date": "2024-10-16 10:16:34 UTC",
    "updated_date": "2024-10-16 10:16:34 UTC"
  },
  {
    "arxiv_id": "2410.12418v1",
    "title": "Privacy-Preserving Synthetically Augmented Knowledge Graphs with Semantic Utility",
    "authors": [
      "Luigi Bellomarini",
      "Costanza Catalano",
      "Andrea Coletta",
      "Michela Iezzi",
      "Pierangela Samarati"
    ],
    "abstract": "Knowledge Graphs (KGs) have recently gained relevant attention in many\napplication domains, from healthcare to biotechnology, from logistics to\nfinance. Financial organisations, central banks, economic research entities,\nand national supervision authorities apply ontological reasoning on KGs to\naddress crucial business tasks, such as economic policymaking, banking\nsupervision, anti-money laundering, and economic research. Reasoning allows for\nthe generation of derived knowledge capturing complex business semantics and\nthe set up of effective business processes. A major obstacle in KGs sharing is\nrepresented by privacy considerations since the identity of the data subjects\nand their sensitive or company-confidential information may be improperly\nexposed.\n  In this paper, we propose a novel framework to enable KGs sharing while\nensuring that information that should remain private is not directly released\nnor indirectly exposed via derived knowledge, while maintaining the embedded\nknowledge of the KGs to support business downstream tasks. Our approach\nproduces a privacy-preserving synthetic KG as an augmentation of the input one\nvia the introduction of structural anonymisation. We introduce a novel privacy\nmeasure for KGs, which considers derived knowledge and a new utility metric\nthat captures the business semantics we want to preserve, and propose two novel\nanonymization algorithms. Our extensive experimental evaluation, with both\nsynthetic graphs and real-world datasets, confirms the effectiveness of our\napproach achieving up to a 70% improvement in the privacy of entities compared\nto existing methods not specifically designed for KGs.",
    "categories": [
      "cs.DB",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.DB",
    "comment": "32 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.12418v1",
    "published_date": "2024-10-16 10:04:02 UTC",
    "updated_date": "2024-10-16 10:04:02 UTC"
  },
  {
    "arxiv_id": "2410.12416v1",
    "title": "Enhancing Speech Emotion Recognition through Segmental Average Pooling of Self-Supervised Learning Features",
    "authors": [
      "Jonghwan Hyeon",
      "Yung-Hwan Oh",
      "Ho-Jin Choi"
    ],
    "abstract": "Speech Emotion Recognition (SER) analyzes human emotions expressed through\nspeech. Self-supervised learning (SSL) offers a promising approach to SER by\nlearning meaningful representations from a large amount of unlabeled audio\ndata. However, existing SSL-based methods rely on Global Average Pooling (GAP)\nto represent audio signals, treating speech and non-speech segments equally.\nThis can lead to dilution of informative speech features by irrelevant\nnon-speech information. To address this, the paper proposes Segmental Average\nPooling (SAP), which selectively focuses on informative speech segments while\nignoring non-speech segments. By applying both GAP and SAP to SSL features, our\napproach utilizes overall speech signal information from GAP and specific\ninformation from SAP, leading to improved SER performance. Experiments show\nstate-of-the-art results on the IEMOCAP for English and superior performance on\nKEMDy19 for Korean datasets in both unweighted and weighted accuracies.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.12416v1",
    "published_date": "2024-10-16 10:00:57 UTC",
    "updated_date": "2024-10-16 10:00:57 UTC"
  },
  {
    "arxiv_id": "2410.12409v1",
    "title": "Revealing the Barriers of Language Agents in Planning",
    "authors": [
      "Jian Xie",
      "Kexun Zhang",
      "Jiangjie Chen",
      "Siyu Yuan",
      "Kai Zhang",
      "Yikai Zhang",
      "Lei Li",
      "Yanghua Xiao"
    ],
    "abstract": "Autonomous planning has been an ongoing pursuit since the inception of\nartificial intelligence. Based on curated problem solvers, early planning\nagents could deliver precise solutions for specific tasks but lacked\ngeneralization. The emergence of large language models (LLMs) and their\npowerful reasoning capabilities has reignited interest in autonomous planning\nby automatically generating reasonable solutions for given tasks. However,\nprior research and our experiments show that current language agents still lack\nhuman-level planning abilities. Even the state-of-the-art reasoning model,\nOpenAI o1, achieves only 15.6% on one of the complex real-world planning\nbenchmarks. This highlights a critical question: What hinders language agents\nfrom achieving human-level planning? Although existing studies have highlighted\nweak performance in agent planning, the deeper underlying issues and the\nmechanisms and limitations of the strategies proposed to address them remain\ninsufficiently understood. In this work, we apply the feature attribution study\nand identify two key factors that hinder agent planning: the limited role of\nconstraints and the diminishing influence of questions. We also find that\nalthough current strategies help mitigate these challenges, they do not fully\nresolve them, indicating that agents still have a long way to go before\nreaching human-level intelligence.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "Work in Progress",
    "pdf_url": "http://arxiv.org/pdf/2410.12409v1",
    "published_date": "2024-10-16 09:44:38 UTC",
    "updated_date": "2024-10-16 09:44:38 UTC"
  },
  {
    "arxiv_id": "2410.12891v2",
    "title": "Multi-trait User Simulation with Adaptive Decoding for Conversational Task Assistants",
    "authors": [
      "Rafael Ferreira",
      "David Semedo",
      "João Magalhães"
    ],
    "abstract": "Conversational systems must be robust to user interactions that naturally\nexhibit diverse conversational traits. Capturing and simulating these diverse\ntraits coherently and efficiently presents a complex challenge. This paper\nintroduces Multi-Trait Adaptive Decoding (mTAD), a method that generates\ndiverse user profiles at decoding-time by sampling from various trait-specific\nLanguage Models (LMs). mTAD provides an adaptive and scalable approach to user\nsimulation, enabling the creation of multiple user profiles without the need\nfor additional fine-tuning. By analyzing real-world dialogues from the\nConversational Task Assistant (CTA) domain, we identify key conversational\ntraits and developed a framework to generate profile-aware dialogues that\nenhance conversational diversity. Experimental results validate the\neffectiveness of our approach in modeling single-traits using specialized LMs,\nwhich can capture less common patterns, even in out-of-domain tasks.\nFurthermore, the results demonstrate that mTAD is a robust and flexible\nframework for combining diverse user simulators.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "Preprint from EMNLP 2024 Findings",
    "pdf_url": "http://arxiv.org/pdf/2410.12891v2",
    "published_date": "2024-10-16 09:40:34 UTC",
    "updated_date": "2024-10-28 09:22:49 UTC"
  },
  {
    "arxiv_id": "2410.12389v1",
    "title": "A Fast Convoluted Story: Scaling Probabilistic Inference for Integer Arithmetic",
    "authors": [
      "Lennert De Smet",
      "Pedro Zuidberg Dos Martires"
    ],
    "abstract": "As illustrated by the success of integer linear programming, linear integer\narithmetic is a powerful tool for modelling combinatorial problems.\nFurthermore, the probabilistic extension of linear programming has been used to\nformulate problems in neurosymbolic AI. However, two key problems persist that\nprevent the adoption of neurosymbolic techniques beyond toy problems. First,\nprobabilistic inference is inherently hard, #P-hard to be precise. Second, the\ndiscrete nature of integers renders the construction of meaningful gradients\nchallenging, which is problematic for learning. In order to mitigate these\nissues, we formulate linear arithmetic over integer-valued random variables as\ntensor manipulations that can be implemented in a straightforward fashion using\nmodern deep learning libraries. At the core of our formulation lies the\nobservation that the addition of two integer-valued random variables can be\nperformed by adapting the fast Fourier transform to probabilities in the\nlog-domain. By relying on tensor operations we obtain a differentiable data\nstructure, which unlocks, virtually for free, gradient-based learning. In our\nexperimental validation we show that tensorising probabilistic linear integer\narithmetic and leveraging the fast Fourier transform allows us to push the\nstate of the art by several orders of magnitude in terms of inference and\nlearning times.",
    "categories": [
      "cs.AI",
      "68T37",
      "G.3; G.3; I.2.6"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.12389v1",
    "published_date": "2024-10-16 09:16:10 UTC",
    "updated_date": "2024-10-16 09:16:10 UTC"
  },
  {
    "arxiv_id": "2410.12381v3",
    "title": "HumanEval-V: Benchmarking High-Level Visual Reasoning with Complex Diagrams in Coding Tasks",
    "authors": [
      "Fengji Zhang",
      "Linquan Wu",
      "Huiyu Bai",
      "Guancheng Lin",
      "Xiao Li",
      "Xiao Yu",
      "Yue Wang",
      "Bei Chen",
      "Jacky Keung"
    ],
    "abstract": "Understanding and reasoning over diagrams is a fundamental aspect of human\nintelligence. While Large Multimodal Models (LMMs) have demonstrated impressive\ncapabilities across various tasks, existing benchmarks lack comprehensive\nevaluation of their diagram interpretation and reasoning abilities,\nparticularly in coding contexts. We present HumanEval-V, a rigorous benchmark\nof human-annotated coding tasks that spans six task types and evaluates diverse\nvisual reasoning capabilities. Each task features carefully crafted diagrams\npaired with function signatures and test cases, employing novel code generation\ntasks to thoroughly assess models' diagram comprehension. Through extensive\nexperiments with 22 LMMs, we find that even top-performing models achieve\nmodest success rates, with Claude 3.5 Sonnet reaching only 36.8% pass@1,\nhighlighting substantial room for improvement. Our analysis reveals that\ncurrent LMMs struggle with spatial transformations, topological relationships,\nand dynamic patterns that humans find intuitive. These findings provide\nvaluable insights for advancing LMMs' visual reasoning abilities. We have\nopen-sourced our code and benchmark at\nhttps://github.com/HumanEval-V/HumanEval-V-Benchmark.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "homepage https://humaneval-v.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2410.12381v3",
    "published_date": "2024-10-16 09:04:57 UTC",
    "updated_date": "2025-02-18 06:00:26 UTC"
  },
  {
    "arxiv_id": "2410.14733v2",
    "title": "Knowledge Graph Embeddings: A Comprehensive Survey on Capturing Relation Properties",
    "authors": [
      "Guanglin Niu"
    ],
    "abstract": "Knowledge Graph Embedding (KGE) techniques play a pivotal role in\ntransforming symbolic Knowledge Graphs (KGs) into numerical representations,\nthereby enhancing various deep learning models for knowledge-augmented\napplications. Unlike entities, relations in KGs are the carriers of semantic\nmeaning, and their accurate modeling is crucial for the performance of KGE\nmodels. Firstly, we address the complex mapping properties inherent in\nrelations, such as one-to-one, one-to-many, many-to-one, and many-to-many\nmappings. We provide a comprehensive summary of relation-aware mapping-based\nmodels, models that utilize specific representation spaces, tensor\ndecomposition-based models, and neural network-based models. Next, focusing on\ncapturing various relation patterns like symmetry, asymmetry, inversion, and\ncomposition, we review models that employ modified tensor decomposition, those\nbased on modified relation-aware mappings, and those that leverage rotation\noperations. Subsequently, considering the implicit hierarchical relations among\nentities, we introduce models that incorporate auxiliary information, models\nbased on hyperbolic spaces, and those that utilize the polar coordinate system.\nFinally, in response to more complex scenarios such as sparse and dynamic KGs,\nthis paper discusses potential future research directions. We explore\ninnovative ideas such as integrating multimodal information into KGE, enhancing\nrelation pattern modeling with rules, and developing models to capture relation\ncharacteristics in dynamic KGE settings.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "I.2.7"
    ],
    "primary_category": "cs.LG",
    "comment": "22 pages, 8 figures, 3 tables, this paper is a modified English\n  version of our article already published in Computer Science journal (in\n  Chinese), released to facilitate communication among international\n  researchers in the relevant fields",
    "pdf_url": "http://arxiv.org/pdf/2410.14733v2",
    "published_date": "2024-10-16 08:54:52 UTC",
    "updated_date": "2025-03-21 02:50:43 UTC"
  },
  {
    "arxiv_id": "2410.12376v2",
    "title": "ShapefileGPT: A Multi-Agent Large Language Model Framework for Automated Shapefile Processing",
    "authors": [
      "Qingming Lin",
      "Rui Hu",
      "Huaxia Li",
      "Sensen Wu",
      "Yadong Li",
      "Kai Fang",
      "Hailin Feng",
      "Zhenhong Du",
      "Liuchang Xu"
    ],
    "abstract": "Vector data is one of the two core data structures in geographic information\nscience (GIS), essential for accurately storing and representing geospatial\ninformation. Shapefile, the most widely used vector data format, has become the\nindustry standard supported by all major geographic information systems.\nHowever, processing this data typically requires specialized GIS knowledge and\nskills, creating a barrier for researchers from other fields and impeding\ninterdisciplinary research in spatial data analysis. Moreover, while large\nlanguage models (LLMs) have made significant advancements in natural language\nprocessing and task automation, they still face challenges in handling the\ncomplex spatial and topological relationships inherent in GIS vector data. To\naddress these challenges, we propose ShapefileGPT, an innovative framework\npowered by LLMs, specifically designed to automate Shapefile tasks.\nShapefileGPT utilizes a multi-agent architecture, in which the planner agent is\nresponsible for task decomposition and supervision, while the worker agent\nexecutes the tasks. We developed a specialized function library for handling\nShapefiles and provided comprehensive API documentation, enabling the worker\nagent to operate Shapefiles efficiently through function calling. For\nevaluation, we developed a benchmark dataset based on authoritative textbooks,\nencompassing tasks in categories such as geometric operations and spatial\nqueries. ShapefileGPT achieved a task success rate of 95.24%, outperforming the\nGPT series models. In comparison to traditional LLMs, ShapefileGPT effectively\nhandles complex vector data analysis tasks, overcoming the limitations of\ntraditional LLMs in spatial analysis. This breakthrough opens new pathways for\nadvancing automation and intelligence in the GIS field, with significant\npotential in interdisciplinary data analysis and application contexts.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.12376v2",
    "published_date": "2024-10-16 08:48:27 UTC",
    "updated_date": "2024-10-23 12:58:14 UTC"
  },
  {
    "arxiv_id": "2410.12375v1",
    "title": "PRefLexOR: Preference-based Recursive Language Modeling for Exploratory Optimization of Reasoning and Agentic Thinking",
    "authors": [
      "Markus J. Buehler"
    ],
    "abstract": "PRefLexOR (Preference-based Recursive Language Modeling for Exploratory\nOptimization of Reasoning) combines preference optimization with concepts from\nReinforcement Learning to enable models to self-teach through iterative\nreasoning improvements. We propose a recursive learning approach that engages\nthe model in multi-step reasoning, revisiting, and refining intermediate steps\nbefore producing a final output in training and inference phases. Through\nmultiple training stages, the model first learns to align its reasoning with\naccurate decision paths by optimizing the log odds between preferred and\nnon-preferred responses. During this process, PRefLexOR builds a dynamic\nknowledge graph by generating questions from random text chunks and\nretrieval-augmentation to contextualize relevant details from the entire\ntraining corpus. In the second stage, preference optimization enhances model\nperformance by using rejection sampling to fine-tune reasoning quality by\ncontinually producing in-situ training data while masking the reasoning steps.\nRecursive optimization within a thinking token framework introduces iterative\nfeedback loops, where the model refines reasoning, achieving deeper coherence,\nconsistency, and adaptability. Implemented in small language models with only 3\nbillion parameters, we should that even tiny models can iteratively teach\nthemselves to reason with greater depth and reflectivity. Our implementation is\nstraightforward and can be incorporated into any existing pretrained LLM. We\nfocus our examples on applications in biological materials science and\ndemonstrate the method in a variety of case studies that range from in-domain\nto cross-domain applications. Using reasoning strategies that include thinking\nand reflection modalities we build a multi-agent recursive self-improving\ninference approach to successively improve responses via repeated sampling in\ninference time.",
    "categories": [
      "cs.AI",
      "cond-mat.dis-nn",
      "cond-mat.mes-hall",
      "cond-mat.mtrl-sci",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.12375v1",
    "published_date": "2024-10-16 08:46:26 UTC",
    "updated_date": "2024-10-16 08:46:26 UTC"
  },
  {
    "arxiv_id": "2410.14731v2",
    "title": "MatryoshkaKV: Adaptive KV Compression via Trainable Orthogonal Projection",
    "authors": [
      "Bokai Lin",
      "Zihao Zeng",
      "Zipeng Xiao",
      "Siqi Kou",
      "Tianqi Hou",
      "Xiaofeng Gao",
      "Hao Zhang",
      "Zhijie Deng"
    ],
    "abstract": "KV cache has become a de facto technique for the inference of large language\nmodels (LLMs), where tensors of shape (layer number, head number, sequence\nlength, feature dimension) are introduced to cache historical information for\nself-attention. As the size of the model and data grows, the KV cache can\nquickly become a bottleneck within the system in both storage and memory\ntransfer. To address this, prior studies usually focus on the first three axes\nof the cache tensors for compression. This paper supplements them, focusing on\nthe feature dimension axis, by utilizing low-rank projection matrices to\ntransform the cache features into spaces with reduced dimensions. We begin by\ninvestigating the canonical orthogonal projection method for data compression\nthrough principal component analysis (PCA). We observe the issue with PCA\nprojection where significant performance degradation is observed at low\ncompression rates. To bridge the gap, we propose to directly tune the\northogonal projection matrices with a distillation objective using an elaborate\nMatryoshka training strategy. After training, we adaptively search for the\noptimal compression rates for various layers and heads given varying\ncompression budgets. Compared to previous works, our method can easily embrace\npre-trained LLMs and hold a smooth tradeoff between performance and compression\nrate. We empirically witness the high data efficiency of our training procedure\nand find that our method can sustain over 90% performance with an average KV\ncache compression rate of 60% (and up to 75% in certain extreme scenarios) for\npopular LLMs like LLaMA2-7B-base and Mistral-7B-v0.3-base.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.14731v2",
    "published_date": "2024-10-16 08:34:51 UTC",
    "updated_date": "2025-05-16 09:40:01 UTC"
  },
  {
    "arxiv_id": "2410.12361v3",
    "title": "Proactive Agent: Shifting LLM Agents from Reactive Responses to Active Assistance",
    "authors": [
      "Yaxi Lu",
      "Shenzhi Yang",
      "Cheng Qian",
      "Guirong Chen",
      "Qinyu Luo",
      "Yesai Wu",
      "Huadong Wang",
      "Xin Cong",
      "Zhong Zhang",
      "Yankai Lin",
      "Weiwen Liu",
      "Yasheng Wang",
      "Zhiyuan Liu",
      "Fangming Liu",
      "Maosong Sun"
    ],
    "abstract": "Agents powered by large language models have shown remarkable abilities in\nsolving complex tasks. However, most agent systems remain reactive, limiting\ntheir effectiveness in scenarios requiring foresight and autonomous\ndecision-making. In this paper, we tackle the challenge of developing proactive\nagents capable of anticipating and initiating tasks without explicit human\ninstructions. We propose a novel data-driven approach for this problem.\nFirstly, we collect real-world human activities to generate proactive task\npredictions. These predictions are then labeled by human annotators as either\naccepted or rejected. The labeled data is used to train a reward model that\nsimulates human judgment and serves as an automatic evaluator of the\nproactiveness of LLM agents. Building on this, we develop a comprehensive data\ngeneration pipeline to create a diverse dataset, ProactiveBench, containing\n6,790 events. Finally, we demonstrate that fine-tuning models with the proposed\nProactiveBench can significantly elicit the proactiveness of LLM agents.\nExperimental results show that our fine-tuned model achieves an F1-Score of\n66.47% in proactively offering assistance, outperforming all open-source and\nclose-source models. These results highlight the potential of our method in\ncreating more proactive and effective agent systems, paving the way for future\nadvancements in human-agent collaboration.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "I.2.7"
    ],
    "primary_category": "cs.AI",
    "comment": "9 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.12361v3",
    "published_date": "2024-10-16 08:24:09 UTC",
    "updated_date": "2024-12-03 04:34:09 UTC"
  },
  {
    "arxiv_id": "2410.12360v3",
    "title": "Towards Neural Scaling Laws for Time Series Foundation Models",
    "authors": [
      "Qingren Yao",
      "Chao-Han Huck Yang",
      "Renhe Jiang",
      "Yuxuan Liang",
      "Ming Jin",
      "Shirui Pan"
    ],
    "abstract": "Scaling laws offer valuable insights into the design of time series\nfoundation models (TSFMs). However, previous research has largely focused on\nthe scaling laws of TSFMs for in-distribution (ID) data, leaving their\nout-of-distribution (OOD) scaling behavior and the influence of model\narchitectures less explored. In this work, we examine two common TSFM\narchitectures, encoder-only and decoder-only Transformers, and investigate\ntheir scaling behavior on both ID and OOD data. These models are trained and\nevaluated across varying parameter counts, compute budgets, and dataset sizes.\nOur experiments reveal that the log-likelihood loss of TSFMs exhibits similar\nscaling behavior in both OOD and ID settings. We further compare the scaling\nproperties across different architectures, incorporating two state-of-the-art\nTSFMs as case studies, showing that model architecture plays a significant role\nin scaling. The encoder-only Transformers demonstrate better scalability than\nthe decoder-only Transformers, while the architectural enhancements in the two\nadvanced TSFMs primarily improve ID performance but reduce OOD scalability.\nWhile scaling up TSFMs is expected to drive performance breakthroughs, the lack\nof a comprehensive understanding of TSFM scaling laws has hindered the\ndevelopment of a robust framework to guide model scaling. We fill this gap in\nthis work by synthesizing our findings and providing practical guidelines for\ndesigning and scaling larger TSFMs with enhanced model capabilities.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by the 13th International Conference on Learning\n  Representations (ICLR 2025)",
    "pdf_url": "http://arxiv.org/pdf/2410.12360v3",
    "published_date": "2024-10-16 08:23:39 UTC",
    "updated_date": "2025-03-18 06:54:45 UTC"
  },
  {
    "arxiv_id": "2410.13903v1",
    "title": "CoreGuard: Safeguarding Foundational Capabilities of LLMs Against Model Stealing in Edge Deployment",
    "authors": [
      "Qinfeng Li",
      "Yangfan Xie",
      "Tianyu Du",
      "Zhiqiang Shen",
      "Zhenghan Qin",
      "Hao Peng",
      "Xinkui Zhao",
      "Xianwei Zhu",
      "Jianwei Yin",
      "Xuhong Zhang"
    ],
    "abstract": "Proprietary large language models (LLMs) demonstrate exceptional\ngeneralization ability across various tasks. Additionally, deploying LLMs on\nedge devices is trending for efficiency and privacy reasons. However, edge\ndeployment of proprietary LLMs introduces new security threats: attackers who\nobtain an edge-deployed LLM can easily use it as a base model for various tasks\ndue to its high generalization ability, which we call foundational capability\nstealing. Unfortunately, existing model protection mechanisms are often\ntask-specific and fail to protect general-purpose LLMs, as they mainly focus on\nprotecting task-related parameters using trusted execution environments (TEEs).\nAlthough some recent TEE-based methods are able to protect the overall model\nparameters in a computation-efficient way, they still suffer from prohibitive\ncommunication costs between TEE and CPU/GPU, making it impractical to deploy\nfor edge LLMs. To protect the foundational capabilities of edge LLMs, we\npropose CoreGuard, a computation- and communication-efficient model protection\napproach against model stealing on edge devices. The core component of\nCoreGuard is a lightweight and propagative authorization module residing in\nTEE. Extensive experiments show that CoreGuard achieves the same security\nprotection as the black-box security guarantees with negligible overhead.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13903v1",
    "published_date": "2024-10-16 08:14:24 UTC",
    "updated_date": "2024-10-16 08:14:24 UTC"
  },
  {
    "arxiv_id": "2410.12350v1",
    "title": "GECTurk WEB: An Explainable Online Platform for Turkish Grammatical Error Detection and Correction",
    "authors": [
      "Ali Gebeşçe",
      "Gözde Gül Şahin"
    ],
    "abstract": "Sophisticated grammatical error detection/correction tools are available for\na small set of languages such as English and Chinese. However, it is not\nstraightforward -- if not impossible -- to adapt them to morphologically rich\nlanguages with complex writing rules like Turkish which has more than 80\nmillion speakers. Even though several tools exist for Turkish, they primarily\nfocus on spelling errors rather than grammatical errors and lack features such\nas web interfaces, error explanations and feedback mechanisms. To fill this\ngap, we introduce GECTurk WEB, a light, open-source, and flexible web-based\nsystem that can detect and correct the most common forms of Turkish writing\nerrors, such as the misuse of diacritics, compound and foreign words, pronouns,\nlight verbs along with spelling mistakes. Our system provides native speakers\nand second language learners an easily accessible tool to detect/correct such\nmistakes and also to learn from their mistakes by showing the explanation for\nthe violated rule(s). The proposed system achieves 88,3 system usability score,\nand is shown to help learn/remember a grammatical rule (confirmed by 80% of the\nparticipants). The GECTurk WEB is available both as an offline tool at\nhttps://github.com/GGLAB-KU/gecturkweb or online at www.gecturk.net.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.12350v1",
    "published_date": "2024-10-16 08:13:54 UTC",
    "updated_date": "2024-10-16 08:13:54 UTC"
  },
  {
    "arxiv_id": "2410.12889v1",
    "title": "Using Protected Attributes to Consider Fairness in Multi-Agent Systems",
    "authors": [
      "Gabriele La Malfa",
      "Jie M. Zhang",
      "Michael Luck",
      "Elizabeth Black"
    ],
    "abstract": "Fairness in Multi-Agent Systems (MAS) has been extensively studied,\nparticularly in reward distribution among agents in scenarios such as goods\nallocation, resource division, lotteries, and bargaining systems. Fairness in\nMAS depends on various factors, including the system's governing rules, the\nbehaviour of the agents, and their characteristics. Yet, fairness in human\nsociety often involves evaluating disparities between disadvantaged and\nprivileged groups, guided by principles of Equality, Diversity, and Inclusion\n(EDI). Taking inspiration from the work on algorithmic fairness, which\naddresses bias in machine learning-based decision-making, we define protected\nattributes for MAS as characteristics that should not disadvantage an agent in\nterms of its expected rewards. We adapt fairness metrics from the algorithmic\nfairness literature -- namely, demographic parity, counterfactual fairness, and\nconditional statistical parity -- to the multi-agent setting, where\nself-interested agents interact within an environment. These metrics allow us\nto evaluate the fairness of MAS, with the ultimate aim of designing MAS that do\nnot disadvantage agents based on protected attributes.",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "primary_category": "cs.MA",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.12889v1",
    "published_date": "2024-10-16 08:12:01 UTC",
    "updated_date": "2024-10-16 08:12:01 UTC"
  },
  {
    "arxiv_id": "2410.12346v2",
    "title": "Efficient Diffusion as Low Light Enhancer",
    "authors": [
      "Guanzhou Lan",
      "Qianli Ma",
      "Yuqi Yang",
      "Zhigang Wang",
      "Dong Wang",
      "Xuelong Li",
      "Bin Zhao"
    ],
    "abstract": "The computational burden of the iterative sampling process remains a major\nchallenge in diffusion-based Low-Light Image Enhancement (LLIE). Current\nacceleration methods, whether training-based or training-free, often lead to\nsignificant performance degradation, highlighting the trade-off between\nperformance and efficiency. In this paper, we identify two primary factors\ncontributing to performance degradation: fitting errors and the inference gap.\nOur key insight is that fitting errors can be mitigated by linearly\nextrapolating the incorrect score functions, while the inference gap can be\nreduced by shifting the Gaussian flow to a reflectance-aware residual space.\nBased on the above insights, we design Reflectance-Aware Trajectory Refinement\n(RATR) module, a simple yet effective module to refine the teacher trajectory\nusing the reflectance component of images. Following this, we introduce\n\\textbf{Re}flectance-aware \\textbf{D}iffusion with \\textbf{Di}stilled\n\\textbf{T}rajectory (\\textbf{ReDDiT}), an efficient and flexible distillation\nframework tailored for LLIE. Our framework achieves comparable performance to\nprevious diffusion-based methods with redundant steps in just 2 steps while\nestablishing new state-of-the-art (SOTA) results with 8 or 4 steps.\nComprehensive experimental evaluations on 10 benchmark datasets validate the\neffectiveness of our method, consistently outperforming existing SOTA methods.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "8 pages",
    "pdf_url": "http://arxiv.org/pdf/2410.12346v2",
    "published_date": "2024-10-16 08:07:18 UTC",
    "updated_date": "2024-11-21 08:20:04 UTC"
  },
  {
    "arxiv_id": "2410.12342v1",
    "title": "TAS: Distilling Arbitrary Teacher and Student via a Hybrid Assistant",
    "authors": [
      "Guopeng Li",
      "Qiang Wang",
      "Ke Yan",
      "Shouhong Ding",
      "Yuan Gao",
      "Gui-Song Xia"
    ],
    "abstract": "Most knowledge distillation (KD) methodologies predominantly focus on\nteacher-student pairs with similar architectures, such as both being\nconvolutional neural networks (CNNs). However, the potential and flexibility of\nKD can be greatly improved by expanding it to novel Cross-Architecture KD\n(CAKD), where the knowledge of homogeneous and heterogeneous teachers can be\ntransferred flexibly to a given student. The primary challenge in CAKD lies in\nthe substantial feature gaps between heterogeneous models, originating from the\ndistinction of their inherent inductive biases and module functions. To this\nend, we introduce an assistant model as a bridge to facilitate smooth feature\nknowledge transfer between heterogeneous teachers and students. More\nimportantly, within our proposed design principle, the assistant model combines\nthe advantages of cross-architecture inductive biases and module functions by\nmerging convolution and attention modules derived from both student and teacher\nmodule functions. Furthermore, we observe that heterogeneous features exhibit\ndiverse spatial distributions in CAKD, hindering the effectiveness of\nconventional pixel-wise mean squared error (MSE) loss. Therefore, we leverage a\nspatial-agnostic InfoNCE loss to align features after spatial smoothing,\nthereby improving the feature alignments in CAKD. Our proposed method is\nevaluated across some homogeneous model pairs and arbitrary heterogeneous\ncombinations of CNNs, ViTs, and MLPs, achieving state-of-the-art performance\nfor distilled models with a maximum gain of 11.47% on CIFAR-100 and 3.67% on\nImageNet-1K. Our code and models will be released.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "18 pages, 6 figures, and 12 tables",
    "pdf_url": "http://arxiv.org/pdf/2410.12342v1",
    "published_date": "2024-10-16 08:02:49 UTC",
    "updated_date": "2024-10-16 08:02:49 UTC"
  },
  {
    "arxiv_id": "2410.12341v2",
    "title": "Characterizing Model Collapse in Large Language Models Using Semantic Networks and Next-Token Probability",
    "authors": [
      "Daniele Gambetta",
      "Gizem Gezici",
      "Fosca Giannotti",
      "Dino Pedreschi",
      "Alistair Knott",
      "Luca Pappalardo"
    ],
    "abstract": "As synthetic content increasingly infiltrates the web, generative AI models\nmay experience an autophagy process, where they are fine-tuned using their own\noutputs. This autophagy could lead to a phenomenon known as model collapse,\nwhich entails a degradation in the performance and diversity of generative AI\nmodels over successive generations. Recent studies have explored the emergence\nof model collapse across various generative AI models and types of data.\nHowever, the current characterizations of model collapse tend to be simplistic\nand lack comprehensive evaluation. In this article, we conduct a thorough\ninvestigation of model collapse across three text datasets, utilizing semantic\nnetworks to analyze text repetitiveness and diversity, while employing\nnext-token probabilities to quantify the loss of diversity. We also examine how\nthe proportions of synthetic tokens affect the severity of model collapse and\nperform cross-dataset evaluations to identify domain-specific variations. By\nproposing metrics and strategies for a more detailed assessment of model\ncollapse, our study provides new insights for the development of robust\ngenerative AI systems.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.12341v2",
    "published_date": "2024-10-16 08:02:48 UTC",
    "updated_date": "2025-02-02 22:40:09 UTC"
  },
  {
    "arxiv_id": "2410.12329v1",
    "title": "Understanding the Role of LLMs in Multimodal Evaluation Benchmarks",
    "authors": [
      "Botian Jiang",
      "Lei Li",
      "Xiaonan Li",
      "Zhaowei Li",
      "Xiachong Feng",
      "Lingpeng Kong",
      "Qi Liu",
      "Xipeng Qiu"
    ],
    "abstract": "The rapid advancement of Multimodal Large Language Models (MLLMs) has been\naccompanied by the development of various benchmarks to evaluate their\ncapabilities. However, the true nature of these evaluations and the extent to\nwhich they assess multimodal reasoning versus merely leveraging the underlying\nLarge Language Model (LLM) backbone remain unclear. This paper presents a\ncomprehensive investigation into the role of LLM backbones in MLLM evaluation,\nfocusing on two critical aspects: the degree to which current benchmarks truly\nassess multimodal reasoning and the influence of LLM prior knowledge on\nperformance. Specifically, we introduce a modified evaluation protocol to\ndisentangle the contributions of the LLM backbone from multimodal integration,\nand an automatic knowledge identification technique for diagnosing whether LLMs\nequip the necessary knowledge for corresponding multimodal questions. Our study\nencompasses four diverse MLLM benchmarks and eight state-of-the-art MLLMs. Key\nfindings reveal that some benchmarks allow high performance even without visual\ninputs and up to 50\\% of error rates can be attributed to insufficient world\nknowledge in the LLM backbone, indicating a heavy reliance on language\ncapabilities. To address knowledge deficiencies, we propose a knowledge\naugmentation pipeline that achieves significant performance gains, with\nimprovements of up to 60\\% on certain datasets, resulting in a approximately 4x\nincrease in performance. Our work provides crucial insights into the role of\nthe LLM backbone in MLLMs, and highlights the need for more nuanced\nbenchmarking approaches.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.12329v1",
    "published_date": "2024-10-16 07:49:13 UTC",
    "updated_date": "2024-10-16 07:49:13 UTC"
  },
  {
    "arxiv_id": "2410.18125v3",
    "title": "Towards Edge General Intelligence via Large Language Models: Opportunities and Challenges",
    "authors": [
      "Handi Chen",
      "Weipeng Deng",
      "Shuo Yang",
      "Jinfeng Xu",
      "Zhihan Jiang",
      "Edith C. H. Ngai",
      "Jiangchuan Liu",
      "Xue Liu"
    ],
    "abstract": "Edge Intelligence (EI) has been instrumental in delivering real-time,\nlocalized services by leveraging the computational capabilities of edge\nnetworks. The integration of Large Language Models (LLMs) empowers EI to evolve\ninto the next stage: Edge General Intelligence (EGI), enabling more adaptive\nand versatile applications that require advanced understanding and reasoning\ncapabilities. However, systematic exploration in this area remains\ninsufficient. This survey delineates the distinctions between EGI and\ntraditional EI, categorizing LLM-empowered EGI into three conceptual systems:\ncentralized, hybrid, and decentralized. For each system, we detail the\nframework designs and review existing implementations. Furthermore, we evaluate\nthe performance and throughput of various Small Language Models (SLMs) that are\nmore suitable for development on edge devices. This survey provides researchers\nwith a comprehensive vision of EGI, offering insights into its vast potential\nand establishing a foundation for future advancements in this rapidly evolving\nfield.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.NI"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.18125v3",
    "published_date": "2024-10-16 07:45:31 UTC",
    "updated_date": "2025-03-06 06:10:12 UTC"
  },
  {
    "arxiv_id": "2410.12323v2",
    "title": "Reversal of Thought: Enhancing Large Language Models with Preference-Guided Reverse Reasoning Warm-up",
    "authors": [
      "Jiahao Yuan",
      "Dehui Du",
      "Hao Zhang",
      "Zixiang Di",
      "Usman Naseem"
    ],
    "abstract": "Large language models (LLMs) have shown remarkable performance in reasoning\ntasks but face limitations in mathematical and complex logical reasoning.\nExisting methods to improve LLMs' logical capabilities either involve traceable\nor verifiable logical sequences that generate more reliable responses by\nconstructing logical structures yet increase computational costs, or introduces\nrigid logic template rules, reducing flexibility. In this paper, we propose\nReversal of Thought (RoT), a plug-and-play and cost-effective reasoning\nframework designed to enhance the logical reasoning abilities of LLMs during\nthe warm-up phase prior to batch inference. RoT utilizes a Preference-Guided\nReverse Reasoning warm-up strategy, which integrates logical symbols for\npseudocode planning through meta-cognitive mechanisms and pairwise preference\nself-evaluation to generate task-specific prompts solely through\ndemonstrations, aligning with LLMs' cognitive preferences shaped by RLHF.\nThrough reverse reasoning, we utilize a Cognitive Preference Manager to assess\nknowledge boundaries and further expand LLMs' reasoning capabilities by\naggregating solution logic for known tasks and stylistic templates for unknown\ntasks. Experiments across various tasks demonstrate that RoT surpasses existing\nbaselines in both reasoning accuracy and efficiency.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.12323v2",
    "published_date": "2024-10-16 07:44:28 UTC",
    "updated_date": "2025-02-16 12:11:13 UTC"
  },
  {
    "arxiv_id": "2410.12318v1",
    "title": "UTF:Undertrained Tokens as Fingerprints A Novel Approach to LLM Identification",
    "authors": [
      "Jiacheng Cai",
      "Jiahao Yu",
      "Yangguang Shao",
      "Yuhang Wu",
      "Xinyu Xing"
    ],
    "abstract": "Fingerprinting large language models (LLMs) is essential for verifying model\nownership, ensuring authenticity, and preventing misuse. Traditional\nfingerprinting methods often require significant computational overhead or\nwhite-box verification access. In this paper, we introduce UTF, a novel and\nefficient approach to fingerprinting LLMs by leveraging under-trained tokens.\nUnder-trained tokens are tokens that the model has not fully learned during its\ntraining phase. By utilizing these tokens, we perform supervised fine-tuning to\nembed specific input-output pairs into the model. This process allows the LLM\nto produce predetermined outputs when presented with certain inputs,\neffectively embedding a unique fingerprint. Our method has minimal overhead and\nimpact on model's performance, and does not require white-box access to target\nmodel's ownership identification. Compared to existing fingerprinting methods,\nUTF is also more effective and robust to fine-tuning and random guess.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.12318v1",
    "published_date": "2024-10-16 07:36:57 UTC",
    "updated_date": "2024-10-16 07:36:57 UTC"
  },
  {
    "arxiv_id": "2410.14730v1",
    "title": "On the Relation Between Linear Diffusion and Power Iteration",
    "authors": [
      "Dana Weitzner",
      "Mauricio Delbracio",
      "Peyman Milanfar",
      "Raja Giryes"
    ],
    "abstract": "Recently, diffusion models have gained popularity due to their impressive\ngenerative abilities. These models learn the implicit distribution given by the\ntraining dataset, and sample new data by transforming random noise through the\nreverse process, which can be thought of as gradual denoising. In this work, we\nexamine the generation process as a ``correlation machine'', where random noise\nis repeatedly enhanced in correlation with the implicit given distribution. To\nthis end, we explore the linear case, where the optimal denoiser in the MSE\nsense is known to be the PCA projection. This enables us to connect the theory\nof diffusion models to the spiked covariance model, where the dependence of the\ndenoiser on the noise level and the amount of training data can be expressed\nanalytically, in the rank-1 case. In a series of numerical experiments, we\nextend this result to general low rank data, and show that low frequencies\nemerge earlier in the generation process, where the denoising basis vectors are\nmore aligned to the true data with a rate depending on their eigenvalues. This\nmodel allows us to show that the linear diffusion model converges in mean to\nthe leading eigenvector of the underlying data, similarly to the prevalent\npower iteration method. Finally, we empirically demonstrate the applicability\nof our findings beyond the linear case, in the Jacobians of a deep, non-linear\ndenoiser, used in general image generation tasks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.14730v1",
    "published_date": "2024-10-16 07:33:12 UTC",
    "updated_date": "2024-10-16 07:33:12 UTC"
  },
  {
    "arxiv_id": "2410.12312v2",
    "title": "FaceChain-FACT: Face Adapter with Decoupled Training for Identity-preserved Personalization",
    "authors": [
      "Cheng Yu",
      "Haoyu Xie",
      "Lei Shang",
      "Yang Liu",
      "Jun Dan",
      "Liefeng Bo",
      "Baigui Sun"
    ],
    "abstract": "In the field of human-centric personalized image generation, the\nadapter-based method obtains the ability to customize and generate portraits by\ntext-to-image training on facial data. This allows for identity-preserved\npersonalization without additional fine-tuning in inference. Although there are\nimprovements in efficiency and fidelity, there is often a significant\nperformance decrease in test following ability, controllability, and diversity\nof generated faces compared to the base model. In this paper, we analyze that\nthe performance degradation is attributed to the failure to decouple identity\nfeatures from other attributes during extraction, as well as the failure to\ndecouple the portrait generation training from the overall generation task. To\naddress these issues, we propose the Face Adapter with deCoupled Training\n(FACT) framework, focusing on both model architecture and training strategy. To\ndecouple identity features from others, we leverage a transformer-based\nface-export encoder and harness fine-grained identity features. To decouple the\nportrait generation training, we propose Face Adapting Increment\nRegularization~(FAIR), which effectively constrains the effect of face adapters\non the facial region, preserving the generative ability of the base model.\nAdditionally, we incorporate a face condition drop and shuffle mechanism,\ncombined with curriculum learning, to enhance facial controllability and\ndiversity. As a result, FACT solely learns identity preservation from training\ndata, thereby minimizing the impact on the original text-to-image capabilities\nof the base model. Extensive experiments show that FACT has both\ncontrollability and fidelity in both text-to-image generation and inpainting\nsolutions for portrait generation.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "12 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.12312v2",
    "published_date": "2024-10-16 07:25:24 UTC",
    "updated_date": "2024-10-25 06:56:54 UTC"
  },
  {
    "arxiv_id": "2410.12311v4",
    "title": "Open Domain Question Answering with Conflicting Contexts",
    "authors": [
      "Siyi Liu",
      "Qiang Ning",
      "Kishaloy Halder",
      "Wei Xiao",
      "Zheng Qi",
      "Phu Mon Htut",
      "Yi Zhang",
      "Neha Anna John",
      "Bonan Min",
      "Yassine Benajiba",
      "Dan Roth"
    ],
    "abstract": "Open domain question answering systems frequently rely on information\nretrieved from large collections of text (such as the Web) to answer questions.\nHowever, such collections of text often contain conflicting information, and\nindiscriminately depending on this information may result in untruthful and\ninaccurate answers. To understand the gravity of this problem, we collect a\nhuman-annotated dataset, Question Answering with Conflicting Contexts (QACC),\nand find that as much as 25% of unambiguous, open domain questions can lead to\nconflicting contexts when retrieved using Google Search. We evaluate and\nbenchmark three powerful Large Language Models (LLMs) with our dataset QACC and\ndemonstrate their limitations in effectively addressing questions with\nconflicting information. To explore how humans reason through conflicting\ncontexts, we request our annotators to provide explanations for their\nselections of correct answers. We demonstrate that by finetuning LLMs to\nexplain their answers, we can introduce richer information into their training\nthat guide them through the process of reasoning with conflicting contexts.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.12311v4",
    "published_date": "2024-10-16 07:24:28 UTC",
    "updated_date": "2025-04-28 03:06:08 UTC"
  },
  {
    "arxiv_id": "2410.14729v3",
    "title": "Is Less More? Exploring Token Condensation as Training-free Test-time Adaptation",
    "authors": [
      "Zixin Wang",
      "Dong Gong",
      "Sen Wang",
      "Zi Huang",
      "Yadan Luo"
    ],
    "abstract": "Contrastive Language-Image Pretraining (CLIP) excels at learning\ngeneralizable image representations but often falls short in zero-shot\ninference on certain downstream datasets. Test-time adaptation (TTA) mitigates\nthis issue by adjusting components like normalization layers or context\nprompts, yet it typically requires large batch sizes and extensive\naugmentations, leading to high computational costs. This raises a key question:\nCan VLMs' performance drop in specific test cases be mitigated through\nefficient, training-free approaches? To explore the solution, we investigate\ntoken condensation (TC) techniques, originally designed to enhance vision\ntransformer efficiency by refining token usage during inference. We observe\nthat informative tokens improve visual-text alignment in VLMs like CLIP on\nunseen datasets. However, existing TC methods often fail to maintain\nin-distribution performance when reducing tokens, prompting us to ask: How can\nwe transform TC into an effective ``free-lunch'' adaptation strategy for VLMs?\nTo address this, we propose Token Condensation as Adaptation (TCA), a\ntraining-free adaptation method that takes a step beyond standard TC. Rather\nthan passively discarding tokens, TCA condenses token representation by\nintroducing reservoir-based domain anchor tokens for information-preserving\ntoken reduction and logits correction. TCA achieves up to a 21.4% performance\nimprovement over the strongest baseline on cross-dataset benchmark and the\nCIFAR-100-Corrupted dataset while reducing GFLOPs by 12.2% to 48.9%, with\nminimal hyperparameter dependency on both CLIP and SigLIP series.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "16 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.14729v3",
    "published_date": "2024-10-16 07:13:35 UTC",
    "updated_date": "2025-03-15 09:01:31 UTC"
  },
  {
    "arxiv_id": "2410.12302v1",
    "title": "Two Birds with One Stone: Multi-Task Semantic Communications Systems over Relay Channel",
    "authors": [
      "Yujie Cao",
      "Tong Wu",
      "Zhiyong Chen",
      "Yin Xu",
      "Meixia Tao",
      "Wenjun Zhang"
    ],
    "abstract": "In this paper, we propose a novel multi-task, multi-link relay semantic\ncommunications (MTML-RSC) scheme that enables the destination node to\nsimultaneously perform image reconstruction and classification with one\ntransmission from the source node. In the MTML-RSC scheme, the source node\nbroadcasts a signal using semantic communications, and the relay node forwards\nthe signal to the destination. We analyze the coupling relationship between the\ntwo tasks and the two links (source-to-relay and source-to-destination) and\ndesign a semantic-focused forward method for the relay node, where it\nselectively forwards only the semantics of the relevant class while ignoring\nothers. At the destination, the node combines signals from both the source node\nand the relay node to perform classification, and then uses the classification\nresult to assist in decoding the signal from the relay node for image\nreconstructing. Experimental results demonstrate that the proposed MTML-RSC\nscheme achieves significant performance gains, e.g., $1.73$ dB improvement in\npeak-signal-to-noise ratio (PSNR) for image reconstruction and increasing the\naccuracy from $64.89\\%$ to $70.31\\%$ for classification.",
    "categories": [
      "cs.IT",
      "cs.AI",
      "cs.LG",
      "math.IT"
    ],
    "primary_category": "cs.IT",
    "comment": "submitted to IEEE WCNC",
    "pdf_url": "http://arxiv.org/pdf/2410.12302v1",
    "published_date": "2024-10-16 07:02:51 UTC",
    "updated_date": "2024-10-16 07:02:51 UTC"
  },
  {
    "arxiv_id": "2410.12298v2",
    "title": "Pyramid-Driven Alignment: Pyramid Principle Guided Integration of Large Language Models and Knowledge Graphs",
    "authors": [
      "Lei Sun",
      "Xinchen Wang",
      "Youdi Li"
    ],
    "abstract": "Large Language Models (LLMs) possess impressive reasoning abilities but are\nprone to generating incorrect information, often referred to as hallucinations.\nWhile incorporating external Knowledge Graphs (KGs) can partially mitigate this\nissue, existing methods primarily treat KGs as static knowledge repositories,\noverlooking the critical disparity between KG and LLM knowledge, and failing to\nfully exploit the reasoning capabilities inherent in KGs. To address these\nlimitations, we propose Pyramid-Driven Alignment (PDA), a novel framework for\nseamlessly integrating LLMs with KGs. PDA utilizes Pyramid Principle analysis\nto construct a hierarchical pyramid structure. This structure is designed to\nreflect the input question and generate more validated deductive knowledge,\nthereby enhancing the alignment of LLMs and KGs and ensuring more cohesive\nintegration. Furthermore, PDA employs a recursive mechanism to harness the\nunderlying reasoning abilities of KGs, resulting in more accurate knowledge\nretrieval for question-answering tasks. Our experimental results reveal a\nsubstantial performance advantage of PDA over state-of-the-art baselines, with\nimprovements reaching 26.70% and 26.78%.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.12298v2",
    "published_date": "2024-10-16 06:57:18 UTC",
    "updated_date": "2024-10-17 11:00:37 UTC"
  },
  {
    "arxiv_id": "2410.12297v1",
    "title": "Conjunction Subspaces Test for Conformal and Selective Classification",
    "authors": [
      "Zengyou He",
      "Zerun Li",
      "Junjie Dong",
      "Xinying Liu",
      "Mudi Jiang",
      "Lianyu Hu"
    ],
    "abstract": "In this paper, we present a new classifier, which integrates significance\ntesting results over different random subspaces to yield consensus p-values for\nquantifying the uncertainty of classification decision. The null hypothesis is\nthat the test sample has no association with the target class on a randomly\nchosen subspace, and hence the classification problem can be formulated as a\nproblem of testing for the conjunction of hypotheses. The proposed classifier\ncan be easily deployed for the purpose of conformal prediction and selective\nclassification with reject and refine options by simply thresholding the\nconsensus p-values. The theoretical analysis on the generalization error bound\nof the proposed classifier is provided and empirical studies on real data sets\nare conducted as well to demonstrate its effectiveness.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "36 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.12297v1",
    "published_date": "2024-10-16 06:56:53 UTC",
    "updated_date": "2024-10-16 06:56:53 UTC"
  },
  {
    "arxiv_id": "2410.12295v1",
    "title": "Consistency Calibration: Improving Uncertainty Calibration via Consistency among Perturbed Neighbors",
    "authors": [
      "Linwei Tao",
      "Haolan Guo",
      "Minjing Dong",
      "Chang Xu"
    ],
    "abstract": "Calibration is crucial in deep learning applications, especially in fields\nlike healthcare and autonomous driving, where accurate confidence estimates are\nvital for decision-making. However, deep neural networks often suffer from\nmiscalibration, with reliability diagrams and Expected Calibration Error (ECE)\nbeing the only standard perspective for evaluating calibration performance. In\nthis paper, we introduce the concept of consistency as an alternative\nperspective on model calibration, inspired by uncertainty estimation literature\nin large language models (LLMs). We highlight its advantages over the\ntraditional reliability-based view. Building on this concept, we propose a\npost-hoc calibration method called Consistency Calibration (CC), which adjusts\nconfidence based on the model's consistency across perturbed inputs. CC is\nparticularly effective in locally uncertainty estimation, as it requires no\nadditional data samples or label information, instead generating input\nperturbations directly from the source data. Moreover, we show that performing\nperturbations at the logit level significantly improves computational\nefficiency. We validate the effectiveness of CC through extensive comparisons\nwith various post-hoc and training-time calibration methods, demonstrating\nstate-of-the-art performance on standard datasets such as CIFAR-10, CIFAR-100,\nand ImageNet, as well as on long-tailed datasets like ImageNet-LT.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.12295v1",
    "published_date": "2024-10-16 06:55:02 UTC",
    "updated_date": "2024-10-16 06:55:02 UTC"
  },
  {
    "arxiv_id": "2410.12288v1",
    "title": "A Prompt-Based Knowledge Graph Foundation Model for Universal In-Context Reasoning",
    "authors": [
      "Yuanning Cui",
      "Zequn Sun",
      "Wei Hu"
    ],
    "abstract": "Extensive knowledge graphs (KGs) have been constructed to facilitate\nknowledge-driven tasks across various scenarios. However, existing work usually\ndevelops separate reasoning models for different KGs, lacking the ability to\ngeneralize and transfer knowledge across diverse KGs and reasoning settings. In\nthis paper, we propose a prompt-based KG foundation model via in-context\nlearning, namely KG-ICL, to achieve a universal reasoning ability.\nSpecifically, we introduce a prompt graph centered with a query-related example\nfact as context to understand the query relation. To encode prompt graphs with\nthe generalization ability to unseen entities and relations in queries, we\nfirst propose a unified tokenizer that maps entities and relations in prompt\ngraphs to predefined tokens. Then, we propose two message passing neural\nnetworks to perform prompt encoding and KG reasoning, respectively. We conduct\nevaluation on 43 different KGs in both transductive and inductive settings.\nResults indicate that the proposed KG-ICL outperforms baselines on most\ndatasets, showcasing its outstanding generalization and universal reasoning\ncapabilities. The source code is accessible on GitHub:\nhttps://github.com/nju-websoft/KG-ICL.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted in the 38th Conference on Neural Information Processing\n  Systems (NeurIPS 2024)",
    "pdf_url": "http://arxiv.org/pdf/2410.12288v1",
    "published_date": "2024-10-16 06:47:18 UTC",
    "updated_date": "2024-10-16 06:47:18 UTC"
  },
  {
    "arxiv_id": "2410.14728v1",
    "title": "Security Threats in Agentic AI System",
    "authors": [
      "Raihan Khan",
      "Sayak Sarkar",
      "Sainik Kumar Mahata",
      "Edwin Jose"
    ],
    "abstract": "This research paper explores the privacy and security threats posed to an\nAgentic AI system with direct access to database systems. Such access\nintroduces significant risks, including unauthorized retrieval of sensitive\ninformation, potential exploitation of system vulnerabilities, and misuse of\npersonal or confidential data. The complexity of AI systems combined with their\nability to process and analyze large volumes of data increases the chances of\ndata leaks or breaches, which could occur unintentionally or through\nadversarial manipulation. Furthermore, as AI agents evolve with greater\nautonomy, their capacity to bypass or exploit security measures becomes a\ngrowing concern, heightening the need to address these critical vulnerabilities\nin agentic systems.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.CR",
    "comment": "8 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.14728v1",
    "published_date": "2024-10-16 06:40:02 UTC",
    "updated_date": "2024-10-16 06:40:02 UTC"
  },
  {
    "arxiv_id": "2410.12279v1",
    "title": "Beyond Oversmoothing: Evaluating DDPM and MSE for Scalable Speech Synthesis in ASR",
    "authors": [
      "Christoph Minixhofer",
      "Ondrej Klejch",
      "Peter Bell"
    ],
    "abstract": "Synthetically generated speech has rapidly approached human levels of\nnaturalness. However, the paradox remains that ASR systems, when trained on TTS\noutput that is judged as natural by humans, continue to perform badly on real\nspeech. In this work, we explore whether this phenomenon is due to the\noversmoothing behaviour of models commonly used in TTS, with a particular focus\non the behaviour of TTS-for-ASR as the amount of TTS training data is scaled\nup. We systematically compare Denoising Diffusion Probabilistic Models (DDPM)\nto Mean Squared Error (MSE) based models for TTS, when used for ASR model\ntraining. We test the scalability of the two approaches, varying both the\nnumber hours, and the number of different speakers. We find that for a given\nmodel size, DDPM can make better use of more data, and a more diverse set of\nspeakers, than MSE models. We achieve the best reported ratio between real and\nsynthetic speech WER to date (1.46), but also find that a large gap remains.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "eess.AS",
    "comment": "Under review at ICASSP 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.12279v1",
    "published_date": "2024-10-16 06:35:56 UTC",
    "updated_date": "2024-10-16 06:35:56 UTC"
  },
  {
    "arxiv_id": "2410.12278v1",
    "title": "Controlled Automatic Task-Specific Synthetic Data Generation for Hallucination Detection",
    "authors": [
      "Yong Xie",
      "Karan Aggarwal",
      "Aitzaz Ahmad",
      "Stephen Lau"
    ],
    "abstract": "We present a novel approach to automatically generate non-trivial\ntask-specific synthetic datasets for hallucination detection. Our approach\nfeatures a two-step generation-selection pipeline, using hallucination pattern\nguidance and a language style alignment during generation. Hallucination\npattern guidance leverages the most important task-specific hallucination\npatterns while language style alignment aligns the style of the synthetic\ndataset with benchmark text. To obtain robust supervised detectors from\nsynthetic datasets, we also adopt a data mixture strategy to improve\nperformance robustness and generalization. Our results on three datasets show\nthat our generated hallucination text is more closely aligned with\nnon-hallucinated text versus baselines, to train hallucination detectors with\nbetter generalization. Our hallucination detectors trained on synthetic\ndatasets outperform in-context-learning (ICL)-based detectors by a large margin\nof 32%. Our extensive experiments confirm the benefits of our approach with\ncross-task and cross-generator generalization. Our data-mixture-based training\nfurther improves the generalization and robustness of hallucination detection.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "68T50",
      "I.2.7"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.12278v1",
    "published_date": "2024-10-16 06:31:59 UTC",
    "updated_date": "2024-10-16 06:31:59 UTC"
  },
  {
    "arxiv_id": "2410.12271v1",
    "title": "Kallini et al. (2024) do not compare impossible languages with constituency-based ones",
    "authors": [
      "Tim Hunter"
    ],
    "abstract": "A central goal of linguistic theory is to find a precise characterization of\nthe notion \"possible human language\", in the form of a computational device\nthat is capable of describing all and only the languages that can be acquired\nby a typically developing human child. The success of recent large language\nmodels (LLMs) in NLP applications arguably raises the possibility that LLMs\nmight be computational devices that meet this goal. This would only be the case\nif, in addition to succeeding in learning human languages, LLMs struggle to\nlearn \"impossible\" human languages. Kallini et al. (2024; \"Mission: Impossible\nLanguage Models\", Proc. ACL) conducted experiments aiming to test this by\ntraining GPT-2 on a variety of synthetic languages, and found that it learns\nsome more successfully than others. They present these asymmetries as support\nfor the idea that LLMs' inductive biases align with what is regarded as\n\"possible\" for human languages, but the most significant comparison has a\nconfound that makes this conclusion unwarranted. In this paper I explain the\nconfound and suggest some ways forward towards constructing a comparison that\nappropriately tests the underlying issue.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.12271v1",
    "published_date": "2024-10-16 06:16:30 UTC",
    "updated_date": "2024-10-16 06:16:30 UTC"
  },
  {
    "arxiv_id": "2410.12261v4",
    "title": "CATCH: Channel-Aware multivariate Time Series Anomaly Detection via Frequency Patching",
    "authors": [
      "Xingjian Wu",
      "Xiangfei Qiu",
      "Zhengyu Li",
      "Yihang Wang",
      "Jilin Hu",
      "Chenjuan Guo",
      "Hui Xiong",
      "Bin Yang"
    ],
    "abstract": "Anomaly detection in multivariate time series is challenging as heterogeneous\nsubsequence anomalies may occur. Reconstruction-based methods, which focus on\nlearning normal patterns in the frequency domain to detect diverse abnormal\nsubsequences, achieve promising results, while still falling short on capturing\nfine-grained frequency characteristics and channel correlations. To contend\nwith the limitations, we introduce CATCH, a framework based on frequency\npatching. We propose to patchify the frequency domain into frequency bands,\nwhich enhances its ability to capture fine-grained frequency characteristics.\nTo perceive appropriate channel correlations, we propose a Channel Fusion\nModule (CFM), which features a patch-wise mask generator and a masked-attention\nmechanism. Driven by a bi-level multi-objective optimization algorithm, the CFM\nis encouraged to iteratively discover appropriate patch-wise channel\ncorrelations, and to cluster relevant channels while isolating adverse effects\nfrom irrelevant channels. Extensive experiments on 10 real-world datasets and\n12 synthetic datasets demonstrate that CATCH achieves state-of-the-art\nperformance. We make our code and datasets available at\nhttps://github.com/decisionintelligence/CATCH.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.12261v4",
    "published_date": "2024-10-16 05:58:55 UTC",
    "updated_date": "2025-05-08 05:13:20 UTC"
  },
  {
    "arxiv_id": "2410.12258v2",
    "title": "Understanding Expert Structures on Minimax Parameter Estimation in Contaminated Mixture of Experts",
    "authors": [
      "Fanqi Yan",
      "Huy Nguyen",
      "Dung Le",
      "Pedram Akbarian",
      "Nhat Ho"
    ],
    "abstract": "We conduct the convergence analysis of parameter estimation in the\ncontaminated mixture of experts. This model is motivated from the prompt\nlearning problem where ones utilize prompts, which can be formulated as\nexperts, to fine-tune a large-scale pre-trained model for learning downstream\ntasks. There are two fundamental challenges emerging from the analysis: (i) the\nproportion in the mixture of the pre-trained model and the prompt may converge\nto zero during the training, leading to the prompt vanishing issue; (ii) the\nalgebraic interaction among parameters of the pre-trained model and the prompt\ncan occur via some partial differential equations and decelerate the prompt\nlearning. In response, we introduce a distinguishability condition to control\nthe previous parameter interaction. Additionally, we also investigate various\ntypes of expert structure to understand their effects on the convergence\nbehavior of parameter estimation. In each scenario, we provide comprehensive\nconvergence rates of parameter estimation along with the corresponding minimax\nlower bounds. Finally, we run several numerical experiments to empirically\njustify our theoretical findings.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Fanqi Yan, Huy Nguyen, and Dung Le contributed equally to this work.\n  Accepted to AISTATS 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.12258v2",
    "published_date": "2024-10-16 05:52:51 UTC",
    "updated_date": "2025-03-06 02:46:29 UTC"
  },
  {
    "arxiv_id": "2410.12250v1",
    "title": "Dual Action Policy for Robust Sim-to-Real Reinforcement Learning",
    "authors": [
      "Ng Wen Zheng Terence",
      "Chen Jianda"
    ],
    "abstract": "This paper presents Dual Action Policy (DAP), a novel approach to address the\ndynamics mismatch inherent in the sim-to-real gap of reinforcement learning.\nDAP uses a single policy to predict two sets of actions: one for maximizing\ntask rewards in simulation and another specifically for domain adaptation via\nreward adjustments. This decoupling makes it easier to maximize the overall\nreward in the source domain during training. Additionally, DAP incorporates\nuncertainty-based exploration during training to enhance agent robustness.\nExperimental results demonstrate DAP's effectiveness in bridging the\nsim-to-real gap, outperforming baselines on challenging tasks in simulation,\nand further improvement is achieved by incorporating uncertainty estimation.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.12250v1",
    "published_date": "2024-10-16 05:22:06 UTC",
    "updated_date": "2024-10-16 05:22:06 UTC"
  },
  {
    "arxiv_id": "2410.12236v2",
    "title": "Enhancing LLM Agents for Code Generation with Possibility and Pass-rate Prioritized Experience Replay",
    "authors": [
      "Yuyang Chen",
      "Kaiyan Zhao",
      "Yiming Wang",
      "Ming Yang",
      "Jian Zhang",
      "Xiaoguang Niu"
    ],
    "abstract": "Nowadays transformer-based Large Language Models (LLM) for code generation\ntasks usually apply sampling and filtering pipelines. Due to the sparse reward\nproblem in code generation tasks caused by one-token incorrectness,\ntransformer-based models will sample redundant programs till they find a\ncorrect one, leading to low efficiency. To overcome the challenge, we\nincorporate Experience Replay (ER) in the fine-tuning phase, where codes and\nprograms produced are stored and will be replayed to give the LLM agent a\nchance to learn from past experiences. Based on the spirit of ER, we introduce\na novel approach called BTP pipeline which consists of three phases: beam\nsearch sampling, testing phase, and prioritized experience replay phase. The\napproach makes use of failed programs collected by code models and replays\nprograms with high Possibility and Pass-rate Prioritized value (P2Value) from\nthe replay buffer to improve efficiency. P2Value comprehensively considers the\npossibility of transformers' output and pass rate and can make use of the\nredundant resources caused by the problem that most programs collected by LLMs\nfail to pass any tests. We empirically apply our approach in several LLMs,\ndemonstrating that it enhances their performance in code generation tasks and\nsurpasses existing baselines.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.12236v2",
    "published_date": "2024-10-16 04:54:42 UTC",
    "updated_date": "2025-01-11 07:08:29 UTC"
  },
  {
    "arxiv_id": "2410.12232v1",
    "title": "Improving the Generalization of Unseen Crowd Behaviors for Reinforcement Learning based Local Motion Planners",
    "authors": [
      "Wen Zheng Terence Ng",
      "Jianda Chen",
      "Sinno Jialin Pan",
      "Tianwei Zhang"
    ],
    "abstract": "Deploying a safe mobile robot policy in scenarios with human pedestrians is\nchallenging due to their unpredictable movements. Current Reinforcement\nLearning-based motion planners rely on a single policy to simulate pedestrian\nmovements and could suffer from the over-fitting issue. Alternatively, framing\nthe collision avoidance problem as a multi-agent framework, where agents\ngenerate dynamic movements while learning to reach their goals, can lead to\nconflicts with human pedestrians due to their homogeneity.\n  To tackle this problem, we introduce an efficient method that enhances agent\ndiversity within a single policy by maximizing an information-theoretic\nobjective. This diversity enriches each agent's experiences, improving its\nadaptability to unseen crowd behaviors. In assessing an agent's robustness\nagainst unseen crowds, we propose diverse scenarios inspired by pedestrian\ncrowd behaviors. Our behavior-conditioned policies outperform existing works in\nthese challenging scenes, reducing potential collisions without additional time\nor travel.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.12232v1",
    "published_date": "2024-10-16 04:46:21 UTC",
    "updated_date": "2024-10-16 04:46:21 UTC"
  },
  {
    "arxiv_id": "2410.12229v3",
    "title": "Comprehending Knowledge Graphs with Large Language Models for Recommender Systems",
    "authors": [
      "Ziqiang Cui",
      "Yunpeng Weng",
      "Xing Tang",
      "Fuyuan Lyu",
      "Dugang Liu",
      "Xiuqiang He",
      "Chen Ma"
    ],
    "abstract": "In recent years, the introduction of knowledge graphs (KGs) has significantly\nadvanced recommender systems by facilitating the discovery of potential\nassociations between items. However, existing methods still face several\nlimitations. First, most KGs suffer from missing facts or limited scopes.\nSecond, existing methods convert textual information in KGs into IDs, resulting\nin the loss of natural semantic connections between different items. Third,\nexisting methods struggle to capture high-order connections in the global KG.\nTo address these limitations, we propose a novel method called CoLaKG, which\nleverages large language models (LLMs) to improve KG-based recommendations. The\nextensive knowledge and remarkable reasoning capabilities of LLMs enable our\nmethod to supplement missing facts in KGs, and their powerful text\nunderstanding abilities allow for better utilization of semantic information.\nSpecifically, CoLaKG extracts useful information from KGs at both local and\nglobal levels. By employing the item-centered subgraph extraction and prompt\nengineering, it can accurately understand the local information. In addition,\nthrough the semantic-based retrieval module, each item is enriched by related\nitems from the entire knowledge graph, effectively harnessing global\ninformation. Furthermore, the local and global information are effectively\nintegrated into the recommendation model through a representation fusion module\nand a retrieval-augmented representation learning module, respectively.\nExtensive experiments on four real-world datasets demonstrate the superiority\nof our method.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "Accepted as a full paper by SIGIR'25",
    "pdf_url": "http://arxiv.org/pdf/2410.12229v3",
    "published_date": "2024-10-16 04:44:34 UTC",
    "updated_date": "2025-04-17 11:50:59 UTC"
  },
  {
    "arxiv_id": "2410.12228v2",
    "title": "Triple Modality Fusion: Aligning Visual, Textual, and Graph Data with Large Language Models for Multi-Behavior Recommendations",
    "authors": [
      "Luyi Ma",
      "Xiaohan Li",
      "Zezhong Fan",
      "Kai Zhao",
      "Jianpeng Xu",
      "Jason Cho",
      "Praveen Kanumala",
      "Kaushiki Nag",
      "Sushant Kumar",
      "Kannan Achan"
    ],
    "abstract": "Integrating diverse data modalities is crucial for enhancing the performance\nof personalized recommendation systems. Traditional models, which often rely on\nsingular data sources, lack the depth needed to accurately capture the\nmultifaceted nature of item features and user behaviors. This paper introduces\na novel framework for multi-behavior recommendations, leveraging the fusion of\ntriple-modality, which is visual, textual, and graph data through alignment\nwith large language models (LLMs). By incorporating visual information, we\ncapture contextual and aesthetic item characteristics; textual data provides\ninsights into user interests and item features in detail; and graph data\nelucidates relationships within the item-behavior heterogeneous graphs. Our\nproposed model called Triple Modality Fusion (TMF) utilizes the power of LLMs\nto align and integrate these three modalities, achieving a comprehensive\nrepresentation of user behaviors. The LLM models the user's interactions\nincluding behaviors and item features in natural languages. Initially, the LLM\nis warmed up using only natural language-based prompts. We then devise the\nmodality fusion module based on cross-attention and self-attention mechanisms\nto integrate different modalities from other models into the same embedding\nspace and incorporate them into an LLM. Extensive experiments demonstrate the\neffectiveness of our approach in improving recommendation accuracy. Further\nablation studies validate the effectiveness of our model design and benefits of\nthe TMF.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.12228v2",
    "published_date": "2024-10-16 04:44:15 UTC",
    "updated_date": "2025-02-16 09:41:32 UTC"
  },
  {
    "arxiv_id": "2410.12222v3",
    "title": "On A Scale From 1 to 5: Quantifying Hallucination in Faithfulness Evaluation",
    "authors": [
      "Xiaonan Jing",
      "Srinivas Billa",
      "Danny Godbout"
    ],
    "abstract": "Hallucination has been a popular topic in natural language generation (NLG).\nIn real-world applications, unfaithful content can result in poor data quality\nor loss of trust from end users. Thus, it is crucial to fact-check before\nadopting NLG for production usage, which can be expensive if done manually. In\nthis paper, we investigate automated faithfulness evaluation in guided NLG. We\ndeveloped a rubric template and used large language models (LLMs) to score the\ngeneration on quantifiable scales. We compared popular LLMs as well as widely\nadopted natural language inference (NLI) models in scoring quality and\nsensitivity. In addition, we developed methods for the generation of synthetic\nunfaithful data, as well as heuristics to quantify the percentage of\nhallucination. Our results on 4 travel-domain industry dataset show that GPT-4\ncan provide accurate judgement and explanation of whether a source and a\ngeneration are factually consistent. Furthermore, we found that tuning NLI\nmodels on synthetic data can improve performance. Lastly, we present insights\non the latency and cost of deploying such a system.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to NAACL 2025 Findings. 16 pages, 10 tables, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.12222v3",
    "published_date": "2024-10-16 04:36:17 UTC",
    "updated_date": "2025-02-08 09:35:35 UTC"
  },
  {
    "arxiv_id": "2410.12221v1",
    "title": "EdgeRL: Reinforcement Learning-driven Deep Learning Model Inference Optimization at Edge",
    "authors": [
      "Motahare Mounesan",
      "Xiaojie Zhang",
      "Saptarshi Debroy"
    ],
    "abstract": "Balancing mutually diverging performance metrics, such as, processing\nlatency, outcome accuracy, and end device energy consumption is a challenging\nundertaking for deep learning model inference in ad-hoc edge environments. In\nthis paper, we propose EdgeRL framework that seeks to strike such balance by\nusing an Advantage Actor-Critic (A2C) Reinforcement Learning (RL) approach that\ncan choose optimal run-time DNN inference parameters and aligns the performance\nmetrics based on the application requirements. Using real world deep learning\nmodel and a hardware testbed, we evaluate the benefits of EdgeRL framework in\nterms of end device energy savings, inference accuracy improvement, and\nend-to-end inference latency reduction.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.12221v1",
    "published_date": "2024-10-16 04:31:39 UTC",
    "updated_date": "2024-10-16 04:31:39 UTC"
  },
  {
    "arxiv_id": "2410.12219v1",
    "title": "OmnixR: Evaluating Omni-modality Language Models on Reasoning across Modalities",
    "authors": [
      "Lichang Chen",
      "Hexiang Hu",
      "Mingda Zhang",
      "Yiwen Chen",
      "Zifeng Wang",
      "Yandong Li",
      "Pranav Shyam",
      "Tianyi Zhou",
      "Heng Huang",
      "Ming-Hsuan Yang",
      "Boqing Gong"
    ],
    "abstract": "We introduce OmnixR, an evaluation suite designed to benchmark SoTA\nOmni-modality Language Models, such as GPT-4o and Gemini. Evaluating OLMs,\nwhich integrate multiple modalities such as text, vision, and audio, presents\nunique challenges. Particularly, the user message might often consist of\nmultiple modalities, such that OLMs have to establish holistic understanding\nand reasoning across modalities to accomplish the task. Existing benchmarks are\nlimited to single modality or dual-modality tasks, overlooking comprehensive\nmulti-modal assessments of model reasoning. To address this, OmnixR offers two\nevaluation variants: (1)synthetic subset: a synthetic dataset generated\nautomatically by translating text into multiple modalities--audio, images,\nvideo, and hybrids (Omnify). (2)realistic subset: a real-world dataset,\nmanually curated and annotated by experts, for evaluating cross-modal reasoning\nin natural settings. OmnixR presents a unique evaluation towards assessing OLMs\nover a diverse mix of modalities, such as a question that involves video,\naudio, and text, providing a rigorous cross-modal reasoning testbed unlike any\nexisting benchmarks. Our experiments find that all state-of-the-art OLMs\nstruggle with OmnixR questions that require integrating information from\nmultiple modalities to answer. Further analysis highlights differences in\nreasoning behavior, underscoring the challenges of omni-modal AI alignment.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.MM"
    ],
    "primary_category": "cs.AI",
    "comment": "19 pages, 6 figures, 12 tables",
    "pdf_url": "http://arxiv.org/pdf/2410.12219v1",
    "published_date": "2024-10-16 04:29:46 UTC",
    "updated_date": "2024-10-16 04:29:46 UTC"
  },
  {
    "arxiv_id": "2410.12214v3",
    "title": "Order-aware Interactive Segmentation",
    "authors": [
      "Bin Wang",
      "Anwesa Choudhuri",
      "Meng Zheng",
      "Zhongpai Gao",
      "Benjamin Planche",
      "Andong Deng",
      "Qin Liu",
      "Terrence Chen",
      "Ulas Bagci",
      "Ziyan Wu"
    ],
    "abstract": "Interactive segmentation aims to accurately segment target objects with\nminimal user interactions. However, current methods often fail to accurately\nseparate target objects from the background, due to a limited understanding of\norder, the relative depth between objects in a scene. To address this issue, we\npropose OIS: order-aware interactive segmentation, where we explicitly encode\nthe relative depth between objects into order maps. We introduce a novel\norder-aware attention, where the order maps seamlessly guide the user\ninteractions (in the form of clicks) to attend to the image features. We\nfurther present an object-aware attention module to incorporate a strong\nobject-level understanding to better differentiate objects with similar order.\nOur approach allows both dense and sparse integration of user clicks, enhancing\nboth accuracy and efficiency as compared to prior works. Experimental results\ndemonstrate that OIS achieves state-of-the-art performance, improving mIoU\nafter one click by 7.61 on the HQSeg44K dataset and 1.32 on the DAVIS dataset\nas compared to the previous state-of-the-art SegNext, while also doubling\ninference speed compared to current leading methods. The project page is\nhttps://ukaukaaaa.github.io/projects/OIS/index.html",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by ICLR 2025 Interactive demo can be found in project page:\n  https://ukaukaaaa.github.io/projects/OIS/index.html",
    "pdf_url": "http://arxiv.org/pdf/2410.12214v3",
    "published_date": "2024-10-16 04:19:28 UTC",
    "updated_date": "2025-02-06 22:16:59 UTC"
  },
  {
    "arxiv_id": "2410.12207v2",
    "title": "Divide-Verify-Refine: Can LLMs Self-Align with Complex Instructions?",
    "authors": [
      "Xianren Zhang",
      "Xianfeng Tang",
      "Hui Liu",
      "Zongyu Wu",
      "Qi He",
      "Dongwon Lee",
      "Suhang Wang"
    ],
    "abstract": "Recent studies show LLMs struggle with complex instructions involving\nmultiple constraints (e.g., length, format, sentiment). Existing works address\nthis issue by fine-tuning, which heavily relies on fine-tuning data quality and\nis computational expensive. An alternative is leveraging LLMs' self-correction\nto refine responses for better constraint adherence. However, this is limited\nby the feedback quality, as LLMs cannot generate reliable feedback or detect\nerrors. Moreover, its effectiveness relies on few-shot examples illustrating\nresponse modifications. As constraints in complex instructions are diverse,\nmanually crafting such examples for each constraint type can be labor-intensive\nand sub-optimal. To address these two challenges, we propose the\nDivide-Verify-Refine (DVR) framework with three steps: (1) Divide complex\ninstructions into single constraints and prepare appropriate tools; (2) Verify\nresponses using tools that provide rigorous check and textual guidance (e.g.,\nPython toolkit for format checks or pre-trained classifiers for content\nanalysis); (3) Refine: To maximize refinement effectiveness, we propose dynamic\nfew-shot prompting, where a refinement repository collects successful\nrefinements, and these examples are selectively retrieved for future\nrefinements. Recognizing the lack of complexity in existing datasets, we create\na new dataset of complex instructions. DVR doubles Llama3.1-8B's constraint\nadherence and triples Mistral-7B's performance.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Under review",
    "pdf_url": "http://arxiv.org/pdf/2410.12207v2",
    "published_date": "2024-10-16 04:01:55 UTC",
    "updated_date": "2025-02-27 22:16:18 UTC"
  },
  {
    "arxiv_id": "2410.12206v1",
    "title": "Abnormality Forecasting: Time Series Anomaly Prediction via Future Context Modeling",
    "authors": [
      "Sinong Zhao",
      "Wenrui Wang",
      "Hongzuo Xu",
      "Zhaoyang Yu",
      "Qingsong Wen",
      "Gang Wang",
      "xiaoguang Liu",
      "Guansong Pang"
    ],
    "abstract": "Identifying anomalies from time series data plays an important role in\nvarious fields such as infrastructure security, intelligent operation and\nmaintenance, and space exploration. Current research focuses on detecting the\nanomalies after they occur, which can lead to significant financial/reputation\nloss or infrastructure damage. In this work we instead study a more practical\nyet very challenging problem, time series anomaly prediction, aiming at\nproviding early warnings for abnormal events before their occurrence. To tackle\nthis problem, we introduce a novel principled approach, namely future context\nmodeling (FCM). Its key insight is that the future abnormal events in a target\nwindow can be accurately predicted if their preceding observation window\nexhibits any subtle difference to normal data. To effectively capture such\ndifferences, FCM first leverages long-term forecasting models to generate a\ndiscriminative future context based on the observation data, aiming to amplify\nthose subtle but unusual difference. It then models a normality correlation of\nthe observation data with the forecasting future context to complement the\nnormality modeling of the observation data in foreseeing possible abnormality\nin the target window. A joint variate-time attention learning is also\nintroduced in FCM to leverage both temporal signals and features of the time\nseries data for more discriminative normality modeling in the aforementioned\ntwo views. Comprehensive experiments on five datasets demonstrate that FCM\ngains good recall rate (70\\%+) on multiple datasets and significantly\noutperforms all baselines in F1 score. Code is available at\nhttps://github.com/mala-lab/FCM.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "11 pages, 5 figures, submitted to KDD conference",
    "pdf_url": "http://arxiv.org/pdf/2410.12206v1",
    "published_date": "2024-10-16 04:00:00 UTC",
    "updated_date": "2024-10-16 04:00:00 UTC"
  },
  {
    "arxiv_id": "2410.12195v1",
    "title": "Sparse Prototype Network for Explainable Pedestrian Behavior Prediction",
    "authors": [
      "Yan Feng",
      "Alexander Carballo",
      "Kazuya Takeda"
    ],
    "abstract": "Predicting pedestrian behavior is challenging yet crucial for applications\nsuch as autonomous driving and smart city. Recent deep learning models have\nachieved remarkable performance in making accurate predictions, but they fail\nto provide explanations of their inner workings. One reason for this problem is\nthe multi-modal inputs. To bridge this gap, we present Sparse Prototype Network\n(SPN), an explainable method designed to simultaneously predict a pedestrian's\nfuture action, trajectory, and pose. SPN leverages an intermediate prototype\nbottleneck layer to provide sample-based explanations for its predictions. The\nprototypes are modality-independent, meaning that they can correspond to any\nmodality from the input. Therefore, SPN can extend to arbitrary combinations of\nmodalities. Regularized by mono-semanticity and clustering constraints, the\nprototypes learn consistent and human-understandable features and achieve\nstate-of-the-art performance on action, trajectory and pose prediction on TITAN\nand PIE. Finally, we propose a metric named Top-K Mono-semanticity Scale to\nquantitatively evaluate the explainability. Qualitative results show the\npositive correlation between sparsity and explainability. Code available at\nhttps://github.com/Equinoxxxxx/SPN.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.12195v1",
    "published_date": "2024-10-16 03:33:40 UTC",
    "updated_date": "2024-10-16 03:33:40 UTC"
  },
  {
    "arxiv_id": "2410.12193v1",
    "title": "Trajectory Manifold Optimization for Fast and Adaptive Kinodynamic Motion Planning",
    "authors": [
      "Yonghyeon Lee"
    ],
    "abstract": "Fast kinodynamic motion planning is crucial for systems to effectively adapt\nto dynamically changing environments. Despite some efforts, existing approaches\nstill struggle with rapid planning in high-dimensional, complex problems. Not\nsurprisingly, the primary challenge arises from the high-dimensionality of the\nsearch space, specifically the trajectory space. We address this issue with a\ntwo-step method: initially, we identify a lower-dimensional trajectory manifold\n{\\it offline}, comprising diverse trajectories specifically relevant to the\ntask at hand while meeting kinodynamic constraints. Subsequently, we search for\nsolutions within this manifold {\\it online}, significantly enhancing the\nplanning speed. To encode and generate a manifold of continuous-time,\ndifferentiable trajectories, we propose a novel neural network model, {\\it\nDifferentiable Motion Manifold Primitives (DMMP)}, along with a practical\ntraining strategy. Experiments with a 7-DoF robot arm tasked with dynamic\nthrowing to arbitrary target positions demonstrate that our method surpasses\nexisting approaches in planning speed, task success, and constraint\nsatisfaction.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "12 pages, 11 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.12193v1",
    "published_date": "2024-10-16 03:29:33 UTC",
    "updated_date": "2024-10-16 03:29:33 UTC"
  },
  {
    "arxiv_id": "2410.12189v3",
    "title": "DocETL: Agentic Query Rewriting and Evaluation for Complex Document Processing",
    "authors": [
      "Shreya Shankar",
      "Tristan Chambers",
      "Tarak Shah",
      "Aditya G. Parameswaran",
      "Eugene Wu"
    ],
    "abstract": "Analyzing unstructured data has been a persistent challenge in data\nprocessing. Large Language Models (LLMs) have shown promise in this regard,\nleading to recent proposals for declarative frameworks for LLM-powered\nprocessing of unstructured data. However, these frameworks focus on reducing\ncost when executing user-specified operations using LLMs, rather than improving\naccuracy, executing most operations as-is (in a single LLM call). This is\nproblematic for complex tasks and data, where LLM outputs for user-defined\noperations are often inaccurate, even with optimized prompts. For example, an\nLLM may struggle to identify {\\em all} instances of specific clauses, like\nforce majeure or indemnification, in lengthy legal documents, requiring\ndecomposition of the data, the task, or both.\n  We present DocETL, a system that optimizes complex document processing\npipelines, while accounting for LLM shortcomings. DocETL offers a declarative\ninterface for users to define such pipelines and uses an agent-based approach\nto automatically optimize them, leveraging novel agent-based rewrites (that we\ncall rewrite directives), as well as an optimization and evaluation framework.\nWe introduce (i) logical rewriting of pipelines, tailored for LLM-based tasks,\n(ii) an agent-guided plan evaluation mechanism that synthesizes and\norchestrates task-specific validation prompts, and (iii) an optimization\nalgorithm that efficiently finds promising plans, considering the latencies of\nagent-based plan generation and evaluation. Our evaluation on four different\nunstructured document analysis tasks demonstrates that DocETL finds plans with\noutputs that are 25 to 80% more accurate than well-engineered baselines,\naddressing a critical gap in unstructured data analysis. DocETL is open-source\nat docetl.org, and as of March 2025, has amassed over 1.7k GitHub Stars, with\nusers spanning a variety of domains.",
    "categories": [
      "cs.DB",
      "cs.AI"
    ],
    "primary_category": "cs.DB",
    "comment": "22 pages, 6 figures, 7 tables",
    "pdf_url": "http://arxiv.org/pdf/2410.12189v3",
    "published_date": "2024-10-16 03:22:35 UTC",
    "updated_date": "2025-04-01 19:47:19 UTC"
  },
  {
    "arxiv_id": "2410.12187v2",
    "title": "DAQ: Density-Aware Post-Training Weight-Only Quantization For LLMs",
    "authors": [
      "Yingsong Luo",
      "Ling Chen"
    ],
    "abstract": "Large language models (LLMs) excel in various tasks but face deployment\nchallenges due to hardware constraints. We propose density-aware post-training\nweight-only quantization (DAQ), which has two stages: 1) density-centric\nalignment, which identifies the center of high-density weights and centers the\ndynamic range on this point to align high-density weight regions with\nfloating-point high-precision regions; 2) learnable dynamic range adjustment,\nwhich adjusts the dynamic range by optimizing quantization parameters (i.e.,\nscale and zero-point) based on the impact of weights on the model output.\nExperiments on LLaMA and LLaMA-2 show that DAQ consistently outperforms the\nbest baseline method, reducing perplexity loss by an average of 22.8% on LLaMA\nand 19.6% on LLaMA-2. Our code is available at\nhttps://github.com/LuoYingSong/DAQ.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "9 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.12187v2",
    "published_date": "2024-10-16 03:13:51 UTC",
    "updated_date": "2024-10-17 06:10:52 UTC"
  },
  {
    "arxiv_id": "2410.12175v1",
    "title": "Reinforcement Learning with LTL and $ω$-Regular Objectives via Optimality-Preserving Translation to Average Rewards",
    "authors": [
      "Xuan-Bach Le",
      "Dominik Wagner",
      "Leon Witzman",
      "Alexander Rabinovich",
      "Luke Ong"
    ],
    "abstract": "Linear temporal logic (LTL) and, more generally, $\\omega$-regular objectives\nare alternatives to the traditional discount sum and average reward objectives\nin reinforcement learning (RL), offering the advantage of greater\ncomprehensibility and hence explainability. In this work, we study the\nrelationship between these objectives. Our main result is that each RL problem\nfor $\\omega$-regular objectives can be reduced to a limit-average reward\nproblem in an optimality-preserving fashion, via (finite-memory) reward\nmachines. Furthermore, we demonstrate the efficacy of this approach by showing\nthat optimal policies for limit-average problems can be found asymptotically by\nsolving a sequence of discount-sum problems approximately. Consequently, we\nresolve an open problem: optimal policies for LTL and $\\omega$-regular\nobjectives can be learned asymptotically.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.12175v1",
    "published_date": "2024-10-16 02:42:37 UTC",
    "updated_date": "2024-10-16 02:42:37 UTC"
  },
  {
    "arxiv_id": "2410.21298v1",
    "title": "Explainable Artificial Intelligent (XAI) for Predicting Asphalt Concrete Stiffness and Rutting Resistance: Integrating Bailey's Aggregate Gradation Method",
    "authors": [
      "Warat Kongkitkul",
      "Sompote Youwai",
      "Siwipa Khamsoy",
      "Manaswee Feungfung"
    ],
    "abstract": "This study employs explainable artificial intelligence (XAI) techniques to\nanalyze the behavior of asphalt concrete with varying aggregate gradations,\nfocusing on resilience modulus (MR) and dynamic stability (DS) as measured by\nwheel track tests. The research utilizes a deep learning model with a\nmulti-layer perceptron architecture to predict MR and DS based on aggregate\ngradation parameters derived from Bailey's Method, including coarse aggregate\nratio (CA), fine aggregate coarse ratio (FAc), and other mix design variables.\nThe model's performance was validated using k-fold cross-validation,\ndemonstrating superior accuracy compared to alternative machine learning\napproaches. SHAP (SHapley Additive exPlanations) values were applied to\ninterpret the model's predictions, providing insights into the relative\nimportance and impact of different gradation characteristics on asphalt\nconcrete performance. Key findings include the identification of critical\naggregate size thresholds, particularly the 0.6 mm sieve size, which\nsignificantly influences both MR and DS. The study revealed size-dependent\nperformance of aggregates, with coarse aggregates primarily affecting rutting\nresistance and medium-fine aggregates influencing stiffness. The research also\nhighlighted the importance of aggregate lithology in determining rutting\nresistance. To facilitate practical application, web-based interfaces were\ndeveloped for predicting MR and DS, incorporating explainable features to\nenhance transparency and interpretation of results. This research contributes a\ndata-driven approach to understanding the complex relationships between\naggregate gradation and asphalt concrete performance, potentially informing\nmore efficient and performance-oriented mix design processes in the future.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "The link to web app https://huggingface.co/spaces/Sompote/MRpredict\n  https://huggingface.co/spaces/Sompote/Dynamic.stability",
    "pdf_url": "http://arxiv.org/pdf/2410.21298v1",
    "published_date": "2024-10-16 02:39:55 UTC",
    "updated_date": "2024-10-16 02:39:55 UTC"
  },
  {
    "arxiv_id": "2410.12172v2",
    "title": "The State of Robot Motion Generation",
    "authors": [
      "Kostas E. Bekris",
      "Joe Doerr",
      "Patrick Meng",
      "Sumanth Tangirala"
    ],
    "abstract": "This paper reviews the large spectrum of methods for generating robot motion\nproposed over the 50 years of robotics research culminating in recent\ndevelopments. It crosses the boundaries of methodologies, typically not\nsurveyed together, from those that operate over explicit models to those that\nlearn implicit ones. The paper discusses the current state-of-the-art as well\nas properties of varying methodologies, highlighting opportunities for\nintegration.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG",
      "I.2.9; I.2.8; I.2.6"
    ],
    "primary_category": "cs.RO",
    "comment": "Presented at the International Symposium of Robotics Research (ISRR),\n  2024. Website:\n  https://pracsys.cs.rutgers.edu/papers/the-state-of-robot-motion-generation/",
    "pdf_url": "http://arxiv.org/pdf/2410.12172v2",
    "published_date": "2024-10-16 02:31:31 UTC",
    "updated_date": "2024-12-16 18:25:35 UTC"
  },
  {
    "arxiv_id": "2410.12166v1",
    "title": "Reclaiming the Source of Programmatic Policies: Programmatic versus Latent Spaces",
    "authors": [
      "Tales H. Carvalho",
      "Kenneth Tjhia",
      "Levi H. S. Lelis"
    ],
    "abstract": "Recent works have introduced LEAPS and HPRL, systems that learn latent spaces\nof domain-specific languages, which are used to define programmatic policies\nfor partially observable Markov decision processes (POMDPs). These systems\ninduce a latent space while optimizing losses such as the behavior loss, which\naim to achieve locality in program behavior, meaning that vectors close in the\nlatent space should correspond to similarly behaving programs. In this paper,\nwe show that the programmatic space, induced by the domain-specific language\nand requiring no training, presents values for the behavior loss similar to\nthose observed in latent spaces presented in previous work. Moreover,\nalgorithms searching in the programmatic space significantly outperform those\nin LEAPS and HPRL. To explain our results, we measured the \"friendliness\" of\nthe two spaces to local search algorithms. We discovered that algorithms are\nmore likely to stop at local maxima when searching in the latent space than\nwhen searching in the programmatic space. This implies that the optimization\ntopology of the programmatic space, induced by the reward function in\nconjunction with the neighborhood function, is more conducive to search than\nthat of the latent space. This result provides an explanation for the superior\nperformance in the programmatic space.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Published as a conference paper at ICLR 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.12166v1",
    "published_date": "2024-10-16 02:10:04 UTC",
    "updated_date": "2024-10-16 02:10:04 UTC"
  },
  {
    "arxiv_id": "2410.12165v2",
    "title": "Dual-Model Distillation for Efficient Action Classification with Hybrid Edge-Cloud Solution",
    "authors": [
      "Timothy Wei",
      "Hsien Xin Peng",
      "Elaine Xu",
      "Bryan Zhao",
      "Lei Ding",
      "Diji Yang"
    ],
    "abstract": "As Artificial Intelligence models, such as Large Video-Language models\n(VLMs), grow in size, their deployment in real-world applications becomes\nincreasingly challenging due to hardware limitations and computational costs.\nTo address this, we design a hybrid edge-cloud solution that leverages the\nefficiency of smaller models for local processing while deferring to larger,\nmore accurate cloud-based models when necessary. Specifically, we propose a\nnovel unsupervised data generation method, Dual-Model Distillation (DMD), to\ntrain a lightweight switcher model that can predict when the edge model's\noutput is uncertain and selectively offload inference to the large model in the\ncloud. Experimental results on the action classification task show that our\nframework not only requires less computational overhead, but also improves\naccuracy compared to using a large model alone. Our framework provides a\nscalable and adaptable solution for action classification in\nresource-constrained environments, with potential applications beyond\nhealthcare. Noteworthy, while DMD-generated data is used for optimizing\nperformance and resource usage in our pipeline, we expect the concept of DMD to\nfurther support future research on knowledge alignment across multiple models.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.12165v2",
    "published_date": "2024-10-16 02:06:27 UTC",
    "updated_date": "2024-10-20 17:59:09 UTC"
  },
  {
    "arxiv_id": "2410.12159v3",
    "title": "NSSI-Net: A Multi-Concept GAN for Non-Suicidal Self-Injury Detection Using High-Dimensional EEG in a Semi-Supervised Framework",
    "authors": [
      "Zhen Liang",
      "Weishan Ye",
      "Qile Liu",
      "Li Zhang",
      "Gan Huang",
      "Yongjie Zhou"
    ],
    "abstract": "Non-suicidal self-injury (NSSI) is a serious threat to the physical and\nmental health of adolescents, significantly increasing the risk of suicide and\nattracting widespread public concern. Electroencephalography (EEG), as an\nobjective tool for identifying brain disorders, holds great promise. However,\nextracting meaningful and reliable features from high-dimensional EEG data,\nespecially by integrating spatiotemporal brain dynamics into informative\nrepresentations, remains a major challenge. In this study, we introduce an\nadvanced semi-supervised adversarial network, NSSI-Net, to effectively model\nEEG features related to NSSI. NSSI-Net consists of two key modules: a\nspatial-temporal feature extraction module and a multi-concept discriminator.\nIn the spatial-temporal feature extraction module, an integrated 2D\nconvolutional neural network (2D-CNN) and a bi-directional Gated Recurrent Unit\n(BiGRU) are used to capture both spatial and temporal dynamics in EEG data. In\nthe multi-concept discriminator, signal, gender, domain, and disease levels are\nfully explored to extract meaningful EEG features, considering individual,\ndemographic, disease variations across a diverse population. Based on\nself-collected NSSI data (n=114), the model's effectiveness and reliability are\ndemonstrated, with a 5.44% improvement in performance compared to existing\nmachine learning and deep learning methods. This study advances the\nunderstanding and early diagnosis of NSSI in adolescents with depression,\nenabling timely intervention. The source code is available at\nhttps://github.com/Vesan-yws/NSSINet.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.12159v3",
    "published_date": "2024-10-16 01:39:04 UTC",
    "updated_date": "2025-04-03 07:50:48 UTC"
  },
  {
    "arxiv_id": "2410.12156v1",
    "title": "FragNet: A Graph Neural Network for Molecular Property Prediction with Four Layers of Interpretability",
    "authors": [
      "Gihan Panapitiya",
      "Peiyuan Gao",
      "C Mark Maupin",
      "Emily G Saldanha"
    ],
    "abstract": "Molecular property prediction is a crucial step in many modern-day scientific\napplications including drug discovery and energy storage material design.\nDespite the availability of numerous machine learning models for this task, we\nare lacking in models that provide both high accuracies and interpretability of\nthe predictions. We introduce the FragNet architecture, a graph neural network\nnot only capable of achieving prediction accuracies comparable to the current\nstate-of-the-art models, but also able to provide insight on four levels of\nmolecular substructures. This model enables understanding of which atoms,\nbonds, molecular fragments, and molecular fragment connections are critical in\nthe prediction of a given molecular property. The ability to interpret the\nimportance of connections between fragments is of particular interest for\nmolecules which have substructures that are not connected with regular covalent\nbonds. The interpretable capabilities of FragNet are key to gaining scientific\ninsights from the model's learned patterns between molecular structure and\nmolecular properties.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.chem-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.12156v1",
    "published_date": "2024-10-16 01:37:01 UTC",
    "updated_date": "2024-10-16 01:37:01 UTC"
  },
  {
    "arxiv_id": "2410.12154v1",
    "title": "Exploiting LLMs' Reasoning Capability to Infer Implicit Concepts in Legal Information Retrieval",
    "authors": [
      "Hai-Long Nguyen",
      "Tan-Minh Nguyen",
      "Duc-Minh Nguyen",
      "Thi-Hai-Yen Vuong",
      "Ha-Thanh Nguyen",
      "Xuan-Hieu Phan"
    ],
    "abstract": "Statutory law retrieval is a typical problem in legal language processing,\nthat has various practical applications in law engineering. Modern deep\nlearning-based retrieval methods have achieved significant results for this\nproblem. However, retrieval systems relying on semantic and lexical\ncorrelations often exhibit limitations, particularly when handling queries that\ninvolve real-life scenarios, or use the vocabulary that is not specific to the\nlegal domain. In this work, we focus on overcoming this weaknesses by utilizing\nthe logical reasoning capabilities of large language models (LLMs) to identify\nrelevant legal terms and facts related to the situation mentioned in the query.\nThe proposed retrieval system integrates additional information from the\nterm--based expansion and query reformulation to improve the retrieval\naccuracy. The experiments on COLIEE 2022 and COLIEE 2023 datasets show that\nextra knowledge from LLMs helps to improve the retrieval result of both lexical\nand semantic ranking models. The final ensemble retrieval system outperformed\nthe highest results among all participating teams in the COLIEE 2022 and 2023\ncompetitions.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Presented at NeLaMKRR@KR, 2024 (arXiv:2410.05339)",
    "pdf_url": "http://arxiv.org/pdf/2410.12154v1",
    "published_date": "2024-10-16 01:34:14 UTC",
    "updated_date": "2024-10-16 01:34:14 UTC"
  },
  {
    "arxiv_id": "2410.13901v1",
    "title": "SoK: Prompt Hacking of Large Language Models",
    "authors": [
      "Baha Rababah",
      "Shang",
      "Wu",
      "Matthew Kwiatkowski",
      "Carson Leung",
      "Cuneyt Gurcan Akcora"
    ],
    "abstract": "The safety and robustness of large language models (LLMs) based applications\nremain critical challenges in artificial intelligence. Among the key threats to\nthese applications are prompt hacking attacks, which can significantly\nundermine the security and reliability of LLM-based systems. In this work, we\noffer a comprehensive and systematic overview of three distinct types of prompt\nhacking: jailbreaking, leaking, and injection, addressing the nuances that\ndifferentiate them despite their overlapping characteristics. To enhance the\nevaluation of LLM-based applications, we propose a novel framework that\ncategorizes LLM responses into five distinct classes, moving beyond the\ntraditional binary classification. This approach provides more granular\ninsights into the AI's behavior, improving diagnostic precision and enabling\nmore targeted enhancements to the system's safety and robustness.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL",
      "cs.ET"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13901v1",
    "published_date": "2024-10-16 01:30:41 UTC",
    "updated_date": "2024-10-16 01:30:41 UTC"
  },
  {
    "arxiv_id": "2410.12153v1",
    "title": "Layer-of-Thoughts Prompting (LoT): Leveraging LLM-Based Retrieval with Constraint Hierarchies",
    "authors": [
      "Wachara Fungwacharakorn",
      "Nguyen Ha Thanh",
      "May Myo Zin",
      "Ken Satoh"
    ],
    "abstract": "This paper presents a novel approach termed Layer-of-Thoughts Prompting\n(LoT), which utilizes constraint hierarchies to filter and refine candidate\nresponses to a given query. By integrating these constraints, our method\nenables a structured retrieval process that enhances explainability and\nautomation. Existing methods have explored various prompting techniques but\noften present overly generalized frameworks without delving into the nuances of\nprompts in multi-turn interactions. Our work addresses this gap by focusing on\nthe hierarchical relationships among prompts. We demonstrate that the efficacy\nof thought hierarchy plays a critical role in developing efficient and\ninterpretable retrieval algorithms. Leveraging Large Language Models (LLMs),\nLoT significantly improves the accuracy and comprehensibility of information\nretrieval tasks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Presented at NeLaMKRR@KR, 2024 (arXiv:2410.05339)",
    "pdf_url": "http://arxiv.org/pdf/2410.12153v1",
    "published_date": "2024-10-16 01:20:44 UTC",
    "updated_date": "2024-10-16 01:20:44 UTC"
  },
  {
    "arxiv_id": "2410.12148v1",
    "title": "Facing Identity: The Formation and Performance of Identity via Face-Based Artificial Intelligence Technologies",
    "authors": [
      "Wells Lucas Santo"
    ],
    "abstract": "How is identity constructed and performed in the digital via face-based\nartificial intelligence technologies? While questions of identity on the\ntextual Internet have been thoroughly explored, the Internet has progressed to\na multimedia form that not only centers the visual, but specifically the face.\nAt the same time, a wealth of scholarship has and continues to center the\ntopics of surveillance and control through facial recognition technologies\n(FRTs), which have extended the logics of the racist pseudoscience of\nphysiognomy. Much less work has been devoted to understanding how such\nface-based artificial intelligence technologies have influenced the formation\nand performance of identity. This literature review considers how such\ntechnologies interact with faciality, which entails the construction of what a\nface may represent or signify, along axes of identity such as race, gender, and\nsexuality. In grappling with recent advances in AI such as image generation and\ndeepfakes, I propose that we are now in an era of \"post-facial\" technologies\nthat build off our existing culture of facility while eschewing the analog\nface, complicating our relationship with identity vis-a-vis the face. Drawing\nfrom previous frameworks of identity play in the digital, as well as trans\npractices that have historically played with or transgressed the boundaries of\nidentity classification, we can develop concepts adequate for analyzing digital\nfaciality and identity given the current landscape of post-facial artificial\nintelligence technologies that allow users to interface with the digital in an\nentirely novel manner. To ground this framework of transgression, I conclude by\nproposing an interview study with VTubers -- online streamers who perform using\nmotion-captured avatars instead of their real-life faces -- to gain qualitative\ninsight on how these sociotechnical experiences.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.12148v1",
    "published_date": "2024-10-16 01:14:04 UTC",
    "updated_date": "2024-10-16 01:14:04 UTC"
  },
  {
    "arxiv_id": "2410.12136v1",
    "title": "Sample-Efficient Reinforcement Learning with Temporal Logic Objectives: Leveraging the Task Specification to Guide Exploration",
    "authors": [
      "Yiannis Kantaros",
      "Jun Wang"
    ],
    "abstract": "This paper addresses the problem of learning optimal control policies for\nsystems with uncertain dynamics and high-level control objectives specified as\nLinear Temporal Logic (LTL) formulas. Uncertainty is considered in the\nworkspace structure and the outcomes of control decisions giving rise to an\nunknown Markov Decision Process (MDP). Existing reinforcement learning (RL)\nalgorithms for LTL tasks typically rely on exploring a product MDP state-space\nuniformly (using e.g., an $\\epsilon$-greedy policy) compromising\nsample-efficiency. This issue becomes more pronounced as the rewards get\nsparser and the MDP size or the task complexity increase. In this paper, we\npropose an accelerated RL algorithm that can learn control policies\nsignificantly faster than competitive approaches. Its sample-efficiency relies\non a novel task-driven exploration strategy that biases exploration towards\ndirections that may contribute to task satisfaction. We provide theoretical\nanalysis and extensive comparative experiments demonstrating the\nsample-efficiency of the proposed method. The benefit of our method becomes\nmore evident as the task complexity or the MDP size increases.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "arXiv admin note: text overlap with arXiv:2205.04424",
    "pdf_url": "http://arxiv.org/pdf/2410.12136v1",
    "published_date": "2024-10-16 00:53:41 UTC",
    "updated_date": "2024-10-16 00:53:41 UTC"
  },
  {
    "arxiv_id": "2410.12130v1",
    "title": "Iter-AHMCL: Alleviate Hallucination for Large Language Model via Iterative Model-level Contrastive Learning",
    "authors": [
      "Huiwen Wu",
      "Xiaohan Li",
      "Xiaogang Xu",
      "Jiafei Wu",
      "Deyi Zhang",
      "Zhe Liu"
    ],
    "abstract": "The development of Large Language Models (LLMs) has significantly advanced\nvarious AI applications in commercial and scientific research fields, such as\nscientific literature summarization, writing assistance, and knowledge graph\nconstruction. However, a significant challenge is the high risk of\nhallucination during LLM inference, which can lead to security concerns like\nfactual inaccuracies, inconsistent information, and fabricated content. To\ntackle this issue, it is essential to develop effective methods for reducing\nhallucination while maintaining the original capabilities of the LLM. This\npaper introduces a novel approach called Iterative Model-level Contrastive\nLearning (Iter-AHMCL) to address hallucination. This method modifies the\nrepresentation layers of pre-trained LLMs by using contrastive `positive' and\n`negative' models, trained on data with and without hallucinations. By\nleveraging the differences between these two models, we create a more\nstraightforward pathway to eliminate hallucinations, and the iterative nature\nof contrastive learning further enhances performance. Experimental validation\non four pre-trained foundation LLMs (LLaMA2, Alpaca, LLaMA3, and Qwen)\nfinetuning with a specially designed dataset shows that our approach achieves\nan average improvement of 10.1 points on the TruthfulQA benchmark.\nComprehensive experiments demonstrate the effectiveness of Iter-AHMCL in\nreducing hallucination while maintaining the general capabilities of LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.12130v1",
    "published_date": "2024-10-16 00:15:40 UTC",
    "updated_date": "2024-10-16 00:15:40 UTC"
  },
  {
    "arxiv_id": "2410.12126v2",
    "title": "What Do LLMs Need to Understand Graphs: A Survey of Parametric Representation of Graphs",
    "authors": [
      "Dongqi Fu",
      "Liri Fang",
      "Zihao Li",
      "Hanghang Tong",
      "Vetle I. Torvik",
      "Jingrui He"
    ],
    "abstract": "Graphs, as a relational data structure, have been widely used for various\napplication scenarios, like molecule design and recommender systems. Recently,\nlarge language models (LLMs) are reorganizing in the AI community for their\nexpected reasoning and inference abilities. Making LLMs understand graph-based\nrelational data has great potential, including but not limited to (1)\ndistillate external knowledge base for eliminating hallucination and breaking\nthe context window limit for LLMs' inference during the retrieval augmentation\ngeneration process; (2) taking graph data as the input and directly solve the\ngraph-based research tasks like protein design and drug discovery. However,\ninputting the entire graph data to LLMs is not practical due to its complex\ntopological structure, data size, and the lack of effective and efficient\nsemantic graph representations. A natural question arises: Is there a kind of\ngraph representation that can be described by natural language for LLM's\nunderstanding and is also easy to require to serve as the raw input for LLMs?\nBased on statistical computation, graph laws pre-define a set of parameters\n(e.g., degree, time, diameter) and identifie their relationships and values by\nobserving the topological distribution of plenty of real-world graph data. We\nbelieve this kind of parametric representation of graphs, graph laws, can be a\nsolution for making LLMs understand graph data as the input. In this survey, we\nfirst review the previous study of graph laws from multiple perspectives, i.e.,\nmacroscope and microscope of graphs, low-order and high-order graphs, static\nand dynamic graphs, different observation spaces, and newly proposed graph\nparameters. After we review various real-world applications benefiting from the\nguidance of graph laws, we conclude the paper with current challenges and\nfuture research directions.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.SI"
    ],
    "primary_category": "cs.AI",
    "comment": "Preprint, 9 pages",
    "pdf_url": "http://arxiv.org/pdf/2410.12126v2",
    "published_date": "2024-10-16 00:01:31 UTC",
    "updated_date": "2025-02-18 02:16:09 UTC"
  }
]