[
  {
    "arxiv_id": "2406.02600v1",
    "title": "Data Quality in Edge Machine Learning: A State-of-the-Art Survey",
    "authors": [
      "Mohammed Djameleddine Belgoumri",
      "Mohamed Reda Bouadjenek",
      "Sunil Aryal",
      "Hakim Hacid"
    ],
    "abstract": "Data-driven Artificial Intelligence (AI) systems trained using Machine\nLearning (ML) are shaping an ever-increasing (in size and importance) portion\nof our lives, including, but not limited to, recommendation systems, autonomous\ndriving technologies, healthcare diagnostics, financial services, and\npersonalized marketing. On the one hand, the outsized influence of these\nsystems imposes a high standard of quality, particularly in the data used to\ntrain them. On the other hand, establishing and maintaining standards of Data\nQuality (DQ) becomes more challenging due to the proliferation of Edge\nComputing and Internet of Things devices, along with their increasing adoption\nfor training and deploying ML models. The nature of the edge environment --\ncharacterized by limited resources, decentralized data storage, and processing\n-- exacerbates data-related issues, making them more frequent, severe, and\ndifficult to detect and mitigate. From these observations, it follows that DQ\nresearch for edge ML is a critical and urgent exploration track for the safety\nand robust usefulness of present and future AI systems. Despite this fact, DQ\nresearch for edge ML is still in its infancy. The literature on this subject\nremains fragmented and scattered across different research communities, with no\ncomprehensive survey to date. Hence, this paper aims to fill this gap by\nproviding a global view of the existing literature from multiple disciplines\nthat can be grouped under the umbrella of DQ for edge ML. Specifically, we\npresent a tentative definition of data quality in Edge computing, which we use\nto establish a set of DQ dimensions. We explore each dimension in detail,\nincluding existing solutions for mitigation.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "31 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.02600v1",
    "published_date": "2024-06-01 23:07:05 UTC",
    "updated_date": "2024-06-01 23:07:05 UTC"
  },
  {
    "arxiv_id": "2407.02499v1",
    "title": "Amortizing Pragmatic Program Synthesis with Rankings",
    "authors": [
      "Yewen Pu",
      "Saujas Vaduguru",
      "Priyan Vaithilingam",
      "Elena Glassman",
      "Daniel Fried"
    ],
    "abstract": "The usage of Rational Speech Acts (RSA) framework has been successful in\nbuilding \\emph{pragmatic} program synthesizers that return programs which, in\naddition to being logically consistent with user-generated examples, account\nfor the fact that a user chooses their examples informatively. We present a\ngeneral method of amortizing the slow, exact RSA synthesizer. Our method first\nquery the exact RSA synthesizer to compile a communication dataset. The dataset\ncontains a number of example-dependent rankings of subsets of programs. It then\ndistills a \\textit{single} global ranking of all programs as an approximation\nto every ranking in the dataset. This global ranking is then used at inference\ntime to rank multiple logically consistent candidate programs generated from a\nfast, non-pragmatic synthesizer. Experiments on two program synthesis domains\nusing our ranking method resulted in orders of magnitudes of speed ups compared\nto the exact RSA synthesizer, while being more accurate than a non-pragmatic\nsynthesizer when communicating with humans. Finally, we prove that in the\nspecial case of synthesis from a single example, this approximation is exact.",
    "categories": [
      "cs.PL",
      "cs.AI"
    ],
    "primary_category": "cs.PL",
    "comment": "icml 2024. This work supersedes and serves as a new version of\n  arXiv:2309.03225",
    "pdf_url": "http://arxiv.org/pdf/2407.02499v1",
    "published_date": "2024-06-01 22:55:33 UTC",
    "updated_date": "2024-06-01 22:55:33 UTC"
  },
  {
    "arxiv_id": "2406.00569v1",
    "title": "Redefining Contributions: Shapley-Driven Federated Learning",
    "authors": [
      "Nurbek Tastan",
      "Samar Fares",
      "Toluwani Aremu",
      "Samuel Horvath",
      "Karthik Nandakumar"
    ],
    "abstract": "Federated learning (FL) has emerged as a pivotal approach in machine\nlearning, enabling multiple participants to collaboratively train a global\nmodel without sharing raw data. While FL finds applications in various domains\nsuch as healthcare and finance, it is challenging to ensure global model\nconvergence when participants do not contribute equally and/or honestly. To\novercome this challenge, principled mechanisms are required to evaluate the\ncontributions made by individual participants in the FL setting. Existing\nsolutions for contribution assessment rely on general accuracy evaluation,\noften failing to capture nuanced dynamics and class-specific influences. This\npaper proposes a novel contribution assessment method called ShapFed for\nfine-grained evaluation of participant contributions in FL. Our approach uses\nShapley values from cooperative game theory to provide a granular understanding\nof class-specific influences. Based on ShapFed, we introduce a weighted\naggregation method called ShapFed-WA, which outperforms conventional federated\naveraging, especially in class-imbalanced scenarios. Personalizing participant\nupdates based on their contributions further enhances collaborative fairness by\ndelivering differentiated models commensurate with the participant\ncontributions. Experiments on CIFAR-10, Chest X-Ray, and Fed-ISIC2019 datasets\ndemonstrate the effectiveness of our approach in improving utility, efficiency,\nand fairness in FL systems. The code can be found at\nhttps://github.com/tnurbek/shapfed.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by IJCAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.00569v1",
    "published_date": "2024-06-01 22:40:31 UTC",
    "updated_date": "2024-06-01 22:40:31 UTC"
  },
  {
    "arxiv_id": "2406.00554v2",
    "title": "Guiding and Diversifying LLM-Based Story Generation via Answer Set Programming",
    "authors": [
      "Phoebe J. Wang",
      "Max Kreminski"
    ],
    "abstract": "Instruction-tuned large language models (LLMs) are capable of generating\nstories in response to open-ended user requests, but the resulting stories tend\nto be limited in their diversity. Older, symbolic approaches to story\ngeneration (such as planning) can generate substantially more diverse plot\noutlines, but are limited to producing stories that recombine a fixed set of\nhand-engineered character action templates. Can we combine the strengths of\nthese approaches while mitigating their weaknesses? We propose to do so by\nusing a higher-level and more abstract symbolic specification of high-level\nstory structure -- implemented via answer set programming (ASP) -- to guide and\ndiversify LLM-based story generation. Via semantic similarity analysis, we\ndemonstrate that our approach produces more diverse stories than an unguided\nLLM, and via code excerpts, we demonstrate the improved compactness and\nflexibility of ASP-based outline generation over full-fledged narrative\nplanning.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to Wordplay @ ACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.00554v2",
    "published_date": "2024-06-01 21:14:25 UTC",
    "updated_date": "2024-07-19 22:50:46 UTC"
  },
  {
    "arxiv_id": "2406.00549v2",
    "title": "Zero Inflation as a Missing Data Problem: a Proxy-based Approach",
    "authors": [
      "Trung Phung",
      "Jaron J. R. Lee",
      "Opeyemi Oladapo-Shittu",
      "Eili Y. Klein",
      "Ayse Pinar Gurses",
      "Susan M. Hannum",
      "Kimberly Weems",
      "Jill A. Marsteller",
      "Sara E. Cosgrove",
      "Sara C. Keller",
      "Ilya Shpitser"
    ],
    "abstract": "A common type of zero-inflated data has certain true values incorrectly\nreplaced by zeros due to data recording conventions (rare outcomes assumed to\nbe absent) or details of data recording equipment (e.g. artificial zeros in\ngene expression data).\n  Existing methods for zero-inflated data either fit the observed data\nlikelihood via parametric mixture models that explicitly represent excess\nzeros, or aim to replace excess zeros by imputed values. If the goal of the\nanalysis relies on knowing true data realizations, a particular challenge with\nzero-inflated data is identifiability, since it is difficult to correctly\ndetermine which observed zeros are real and which are inflated.\n  This paper views zero-inflated data as a general type of missing data\nproblem, where the observability indicator for a potentially censored variable\nis itself unobserved whenever a zero is recorded. We show that, without\nadditional assumptions, target parameters involving a zero-inflated variable\nare not identified. However, if a proxy of the missingness indicator is\nobserved, a modification of the effect restoration approach of Kuroki and Pearl\nallows identification and estimation, given the proxy-indicator relationship is\nknown.\n  If this relationship is unknown, our approach yields a partial identification\nstrategy for sensitivity analysis. Specifically, we show that only certain\nproxy-indicator relationships are compatible with the observed data\ndistribution. We give an analytic bound for this relationship in cases with a\ncategorical outcome, which is sharp in certain models. For more complex cases,\nsharp numerical bounds may be computed using methods in Duarte et al.[2023].\n  We illustrate our method via simulation studies and a data application on\ncentral line-associated bloodstream infections (CLABSIs).",
    "categories": [
      "stat.ME",
      "cs.AI"
    ],
    "primary_category": "stat.ME",
    "comment": "28 pages, 8 figues, accepted for the 40th Conference on Uncertainty\n  in Artificial Intelligence (UAI 2024)",
    "pdf_url": "http://arxiv.org/pdf/2406.00549v2",
    "published_date": "2024-06-01 20:21:35 UTC",
    "updated_date": "2024-07-02 12:59:47 UTC"
  },
  {
    "arxiv_id": "2406.00545v2",
    "title": "Memory-guided Network with Uncertainty-based Feature Augmentation for Few-shot Semantic Segmentation",
    "authors": [
      "Xinyue Chen",
      "Miaojing Shi"
    ],
    "abstract": "The performance of supervised semantic segmentation methods highly relies on\nthe availability of large-scale training data. To alleviate this dependence,\nfew-shot semantic segmentation (FSS) is introduced to leverage the model\ntrained on base classes with sufficient data into the segmentation of novel\nclasses with few data. FSS methods face the challenge of model generalization\non novel classes due to the distribution shift between base and novel classes.\nTo overcome this issue, we propose a class-shared memory (CSM) module\nconsisting of a set of learnable memory vectors. These memory vectors learn\nelemental object patterns from base classes during training whilst re-encoding\nquery features during both training and inference, thereby improving the\ndistribution alignment between base and novel classes. Furthermore, to cope\nwith the performance degradation resulting from the intra-class variance across\nimages, we introduce an uncertainty-based feature augmentation (UFA) module to\nproduce diverse query features during training for improving the model's\nrobustness. We integrate CSM and UFA into representative FSS works, with\nexperimental results on the widely-used PASCAL-5$^i$ and COCO-20$^i$ datasets\ndemonstrating the superior performance of ours over state of the art.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to IEEE International Conference on Multimedia and Expo\n  (ICME) 2024 as an oral presentation",
    "pdf_url": "http://arxiv.org/pdf/2406.00545v2",
    "published_date": "2024-06-01 19:53:25 UTC",
    "updated_date": "2024-06-09 22:50:22 UTC"
  },
  {
    "arxiv_id": "2406.00544v1",
    "title": "Leveraging Knowlegde Graphs for Interpretable Feature Generation",
    "authors": [
      "Mohamed Bouadi",
      "Arta Alavi",
      "Salima Benbernou",
      "Mourad Ouziri"
    ],
    "abstract": "The quality of Machine Learning (ML) models strongly depends on the input\ndata, as such Feature Engineering (FE) is often required in ML. In addition,\nwith the proliferation of ML-powered systems, especially in critical contexts,\nthe need for interpretability and explainability becomes increasingly\nimportant. Since manual FE is time-consuming and requires case specific\nknowledge, we propose KRAFT, an AutoFE framework that leverages a knowledge\ngraph to guide the generation of interpretable features. Our hybrid AI approach\ncombines a neural generator to transform raw features through a series of\ntransformations and a knowledge-based reasoner to evaluate features\ninterpretability using Description Logics (DL). The generator is trained\nthrough Deep Reinforcement Learning (DRL) to maximize the prediction accuracy\nand the interpretability of the generated features. Extensive experiments on\nreal datasets demonstrate that KRAFT significantly improves accuracy while\nensuring a high level of interpretability.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.00544v1",
    "published_date": "2024-06-01 19:51:29 UTC",
    "updated_date": "2024-06-01 19:51:29 UTC"
  },
  {
    "arxiv_id": "2406.00537v1",
    "title": "Towards an ontology of portions of matter to support multi-scale analysis and provenance tracking",
    "authors": [
      "Lucas Valadares Vieira",
      "Mara Abel",
      "Fabricio Henrique Rodrigues",
      "Tiago Prince Sales",
      "Claudenir M. Fonseca"
    ],
    "abstract": "This paper presents an ontology of portions of matter with practical\nimplications across scientific and industrial domains. The ontology is\ndeveloped under the Unified Foundational Ontology (UFO), which uses the concept\nof quantity to represent topologically maximally self-connected portions of\nmatter. The proposed ontology introduces the granuleOf parthood relation,\nholding between objects and portions of matter. It also discusses the\nconstitution of quantities by collections of granules, the representation of\nsub-portions of matter, and the tracking of matter provenance between\nquantities using historical relations. Lastly, a case study is presented to\ndemonstrate the use of the portion of matter ontology in the geology domain for\nan Oil & Gas industry application. In the case study, we model how to represent\nthe historical relation between an original portion of rock and the\nsub-portions created during the industrial process. Lastly, future research\ndirections are outlined, including investigating granularity levels and\ndefining a taxonomy of events.",
    "categories": [
      "cs.AI",
      "I.2.4"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.00537v1",
    "published_date": "2024-06-01 19:26:21 UTC",
    "updated_date": "2024-06-01 19:26:21 UTC"
  },
  {
    "arxiv_id": "2406.00532v1",
    "title": "Breast Cancer Diagnosis: A Comprehensive Exploration of Explainable Artificial Intelligence (XAI) Techniques",
    "authors": [
      "Samita Bai",
      "Sidra Nasir",
      "Rizwan Ahmed Khan",
      "Sheeraz Arif",
      "Alexandre Meyer",
      "Hubert Konik"
    ],
    "abstract": "Breast cancer (BC) stands as one of the most common malignancies affecting\nwomen worldwide, necessitating advancements in diagnostic methodologies for\nbetter clinical outcomes. This article provides a comprehensive exploration of\nthe application of Explainable Artificial Intelligence (XAI) techniques in the\ndetection and diagnosis of breast cancer. As Artificial Intelligence (AI)\ntechnologies continue to permeate the healthcare sector, particularly in\noncology, the need for transparent and interpretable models becomes imperative\nto enhance clinical decision-making and patient care. This review discusses the\nintegration of various XAI approaches, such as SHAP, LIME, Grad-CAM, and\nothers, with machine learning and deep learning models utilized in breast\ncancer detection and classification. By investigating the modalities of breast\ncancer datasets, including mammograms, ultrasounds and their processing with\nAI, the paper highlights how XAI can lead to more accurate diagnoses and\npersonalized treatment plans. It also examines the challenges in implementing\nthese techniques and the importance of developing standardized metrics for\nevaluating XAI's effectiveness in clinical settings. Through detailed analysis\nand discussion, this article aims to highlight the potential of XAI in bridging\nthe gap between complex AI models and practical healthcare applications,\nthereby fostering trust and understanding among medical professionals and\nimproving patient outcomes.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.00532v1",
    "published_date": "2024-06-01 18:50:03 UTC",
    "updated_date": "2024-06-01 18:50:03 UTC"
  },
  {
    "arxiv_id": "2406.02599v1",
    "title": "Privacy-Aware Randomized Quantization via Linear Programming",
    "authors": [
      "Zhongteng Cai",
      "Xueru Zhang",
      "Mohammad Mahdi Khalili"
    ],
    "abstract": "Differential privacy mechanisms such as the Gaussian or Laplace mechanism\nhave been widely used in data analytics for preserving individual privacy.\nHowever, they are mostly designed for continuous outputs and are unsuitable for\nscenarios where discrete values are necessary. Although various quantization\nmechanisms were proposed recently to generate discrete outputs under\ndifferential privacy, the outcomes are either biased or have an inferior\naccuracy-privacy trade-off. In this paper, we propose a family of quantization\nmechanisms that is unbiased and differentially private. It has a high degree of\nfreedom and we show that some existing mechanisms can be considered as special\ncases of ours. To find the optimal mechanism, we formulate a linear\noptimization that can be solved efficiently using linear programming tools.\nExperiments show that our proposed mechanism can attain a better\nprivacy-accuracy trade-off compared to baselines.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.02599v1",
    "published_date": "2024-06-01 18:40:08 UTC",
    "updated_date": "2024-06-01 18:40:08 UTC"
  },
  {
    "arxiv_id": "2406.00519v2",
    "title": "Learning Discrete Concepts in Latent Hierarchical Models",
    "authors": [
      "Lingjing Kong",
      "Guangyi Chen",
      "Biwei Huang",
      "Eric P. Xing",
      "Yuejie Chi",
      "Kun Zhang"
    ],
    "abstract": "Learning concepts from natural high-dimensional data (e.g., images) holds\npotential in building human-aligned and interpretable machine learning models.\nDespite its encouraging prospect, formalization and theoretical insights into\nthis crucial task are still lacking. In this work, we formalize concepts as\ndiscrete latent causal variables that are related via a hierarchical causal\nmodel that encodes different abstraction levels of concepts embedded in\nhigh-dimensional data (e.g., a dog breed and its eye shapes in natural images).\nWe formulate conditions to facilitate the identification of the proposed causal\nmodel, which reveals when learning such concepts from unsupervised data is\npossible. Our conditions permit complex causal hierarchical structures beyond\nlatent trees and multi-level directed acyclic graphs in prior work and can\nhandle high-dimensional, continuous observed variables, which is well-suited\nfor unstructured data modalities such as images. We substantiate our\ntheoretical claims with synthetic data experiments. Further, we discuss our\ntheory's implications for understanding the underlying mechanisms of latent\ndiffusion models and provide corresponding empirical evidence for our\ntheoretical insights.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.00519v2",
    "published_date": "2024-06-01 18:01:03 UTC",
    "updated_date": "2025-01-14 20:44:45 UTC"
  },
  {
    "arxiv_id": "2406.00518v1",
    "title": "Learning to Play Air Hockey with Model-Based Deep Reinforcement Learning",
    "authors": [
      "Andrej Orsula"
    ],
    "abstract": "In the context of addressing the Robot Air Hockey Challenge 2023, we\ninvestigate the applicability of model-based deep reinforcement learning to\nacquire a policy capable of autonomously playing air hockey. Our agents learn\nsolely from sparse rewards while incorporating self-play to iteratively refine\ntheir behaviour over time. The robotic manipulator is interfaced using\ncontinuous high-level actions for position-based control in the Cartesian plane\nwhile having partial observability of the environment with stochastic\ntransitions. We demonstrate that agents are prone to overfitting when trained\nsolely against a single playstyle, highlighting the importance of self-play for\ngeneralization to novel strategies of unseen opponents. Furthermore, the impact\nof the imagination horizon is explored in the competitive setting of the highly\ndynamic game of air hockey, with longer horizons resulting in more stable\nlearning and better overall performance.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "Robot Air Hockey Challenge 2023 | The source code is available at\n  https://github.com/AndrejOrsula/drl_air_hockey",
    "pdf_url": "http://arxiv.org/pdf/2406.00518v1",
    "published_date": "2024-06-01 18:00:01 UTC",
    "updated_date": "2024-06-01 18:00:01 UTC"
  },
  {
    "arxiv_id": "2406.00515v2",
    "title": "A Survey on Large Language Models for Code Generation",
    "authors": [
      "Juyong Jiang",
      "Fan Wang",
      "Jiasi Shen",
      "Sungju Kim",
      "Sunghun Kim"
    ],
    "abstract": "Large Language Models (LLMs) have garnered remarkable advancements across\ndiverse code-related tasks, known as Code LLMs, particularly in code generation\nthat generates source code with LLM from natural language descriptions. This\nburgeoning field has captured significant interest from both academic\nresearchers and industry professionals due to its practical significance in\nsoftware development, e.g., GitHub Copilot. Despite the active exploration of\nLLMs for a variety of code tasks, either from the perspective of natural\nlanguage processing (NLP) or software engineering (SE) or both, there is a\nnoticeable absence of a comprehensive and up-to-date literature review\ndedicated to LLM for code generation. In this survey, we aim to bridge this gap\nby providing a systematic literature review that serves as a valuable reference\nfor researchers investigating the cutting-edge progress in LLMs for code\ngeneration. We introduce a taxonomy to categorize and discuss the recent\ndevelopments in LLMs for code generation, covering aspects such as data\ncuration, latest advances, performance evaluation, ethical implications,\nenvironmental impact, and real-world applications. In addition, we present a\nhistorical overview of the evolution of LLMs for code generation and offer an\nempirical comparison using the HumanEval, MBPP, and BigCodeBench benchmarks\nacross various levels of difficulty and types of programming tasks to highlight\nthe progressive enhancements in LLM capabilities for code generation. We\nidentify critical challenges and promising opportunities regarding the gap\nbetween academia and practical development. Furthermore, we have established a\ndedicated resource GitHub page (https://github.com/juyongjiang/CodeLLMSurvey)\nto continuously document and disseminate the most recent advances in the field.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.00515v2",
    "published_date": "2024-06-01 17:48:15 UTC",
    "updated_date": "2024-11-10 22:02:27 UTC"
  },
  {
    "arxiv_id": "2406.00509v1",
    "title": "Empirical influence functions to understand the logic of fine-tuning",
    "authors": [
      "Jordan K. Matelsky",
      "Lyle Ungar",
      "Konrad P. Kording"
    ],
    "abstract": "Understanding the process of learning in neural networks is crucial for\nimproving their performance and interpreting their behavior. This can be\napproximately understood by asking how a model's output is influenced when we\nfine-tune on a new training sample. There are desiderata for such influences,\nsuch as decreasing influence with semantic distance, sparseness, noise\ninvariance, transitive causality, and logical consistency. Here we use the\nempirical influence measured using fine-tuning to demonstrate how individual\ntraining samples affect outputs. We show that these desiderata are violated for\nboth for simple convolutional networks and for a modern LLM. We also illustrate\nhow prompting can partially rescue this failure. Our paper presents an\nefficient and practical way of quantifying how well neural networks learn from\nfine-tuning stimuli. Our results suggest that popular models cannot generalize\nor perform logic in the way they appear to.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.00509v1",
    "published_date": "2024-06-01 17:31:06 UTC",
    "updated_date": "2024-06-01 17:31:06 UTC"
  },
  {
    "arxiv_id": "2406.00507v1",
    "title": "Prompt Chaining or Stepwise Prompt? Refinement in Text Summarization",
    "authors": [
      "Shichao Sun",
      "Ruifeng Yuan",
      "Ziqiang Cao",
      "Wenjie Li",
      "Pengfei Liu"
    ],
    "abstract": "Large language models (LLMs) have demonstrated the capacity to improve\nsummary quality by mirroring a human-like iterative process of critique and\nrefinement starting from the initial draft. Two strategies are designed to\nperform this iterative process: Prompt Chaining and Stepwise Prompt. Prompt\nchaining orchestrates the drafting, critiquing, and refining phases through a\nseries of three discrete prompts, while Stepwise prompt integrates these phases\nwithin a single prompt. However, the relative effectiveness of the two methods\nhas not been extensively studied. This paper is dedicated to examining and\ncomparing these two methods in the context of text summarization to ascertain\nwhich method stands out as the most effective. Experimental results show that\nthe prompt chaining method can produce a more favorable outcome. This might be\nbecause stepwise prompt might produce a simulated refinement process according\nto our various experiments. Since refinement is adaptable to diverse tasks, our\nconclusions have the potential to be extrapolated to other applications,\nthereby offering insights that may contribute to the broader development of\nLLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to Findings of ACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.00507v1",
    "published_date": "2024-06-01 17:28:38 UTC",
    "updated_date": "2024-06-01 17:28:38 UTC"
  },
  {
    "arxiv_id": "2406.00504v2",
    "title": "Research on an Autonomous UAV Search and Rescue System Based on the Improved",
    "authors": [
      "Haobin Chen",
      "Junyu Tao",
      "Bize Zhou",
      "Xiaoyan Liu"
    ],
    "abstract": "The demand is to solve the issue of UAV (unmanned aerial vehicle) operating\nautonomously and implementing practical functions such as search and rescue in\ncomplex unknown environments. This paper proposes an autonomous search and\nrescue UAV system based on an EGO-Planner algorithm, which is improved by\ninnovative UAV body application and takes the methods of inverse motor\nbackstepping to enhance the overall flight efficiency of the UAV and\nminiaturization of the whole machine. At the same time, the system introduced\nthe EGO-Planner planning tool, which is optimized by a bidirectional A*\nalgorithm along with an object detection algorithm. It solves the issue of\nintelligent obstacle avoidance and search and rescue. Through the simulation\nand field verification work, and compared with traditional algorithms, this\nmethod shows more efficiency and reliability in the task. In addition, due to\nthe existing algorithm's improved robustness, this application shows good\nprospection.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "2024 5th International Conference on Computer Engineering and\n  Application",
    "pdf_url": "http://arxiv.org/pdf/2406.00504v2",
    "published_date": "2024-06-01 17:25:29 UTC",
    "updated_date": "2024-06-07 07:00:52 UTC"
  },
  {
    "arxiv_id": "2406.00497v2",
    "title": "Recent Advances in End-to-End Simultaneous Speech Translation",
    "authors": [
      "Xiaoqian Liu",
      "Guoqiang Hu",
      "Yangfan Du",
      "Erfeng He",
      "Yingfeng Luo",
      "Chen Xu",
      "Tong Xiao",
      "Jingbo Zhu"
    ],
    "abstract": "Simultaneous speech translation (SimulST) is a demanding task that involves\ngenerating translations in real-time while continuously processing speech\ninput. This paper offers a comprehensive overview of the recent developments in\nSimulST research, focusing on four major challenges. Firstly, the complexities\nassociated with processing lengthy and continuous speech streams pose\nsignificant hurdles. Secondly, satisfying real-time requirements presents\ninherent difficulties due to the need for immediate translation output.\nThirdly, striking a balance between translation quality and latency constraints\nremains a critical challenge. Finally, the scarcity of annotated data adds\nanother layer of complexity to the task. Through our exploration of these\nchallenges and the proposed solutions, we aim to provide valuable insights into\nthe current landscape of SimulST research and suggest promising directions for\nfuture exploration.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CL",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Accepted by IJCAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.00497v2",
    "published_date": "2024-06-01 16:56:19 UTC",
    "updated_date": "2024-08-20 07:47:49 UTC"
  },
  {
    "arxiv_id": "2406.00494v1",
    "title": "Activation-Descent Regularization for Input Optimization of ReLU Networks",
    "authors": [
      "Hongzhan Yu",
      "Sicun Gao"
    ],
    "abstract": "We present a new approach for input optimization of ReLU networks that\nexplicitly takes into account the effect of changes in activation patterns. We\nanalyze local optimization steps in both the input space and the space of\nactivation patterns to propose methods with superior local descent properties.\nTo accomplish this, we convert the discrete space of activation patterns into\ndifferentiable representations and propose regularization terms that improve\neach descent step. Our experiments demonstrate the effectiveness of the\nproposed input-optimization methods for improving the state-of-the-art in\nvarious areas, such as adversarial learning, generative modeling, and\nreinforcement learning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "ICML'24 Proceedings",
    "pdf_url": "http://arxiv.org/pdf/2406.00494v1",
    "published_date": "2024-06-01 16:46:46 UTC",
    "updated_date": "2024-06-01 16:46:46 UTC"
  },
  {
    "arxiv_id": "2406.00490v2",
    "title": "Research on the Application of Computer Vision Based on Deep Learning in Autonomous Driving Technology",
    "authors": [
      "Jingyu Zhang",
      "Jin Cao",
      "Jinghao Chang",
      "Xinjin Li",
      "Houze Liu",
      "Zhenglin Li"
    ],
    "abstract": "This research aims to explore the application of deep learning in autonomous\ndriving computer vision technology and its impact on improving system\nperformance. By using advanced technologies such as convolutional neural\nnetworks (CNN), multi-task joint learning methods, and deep reinforcement\nlearning, this article analyzes in detail the application of deep learning in\nimage recognition, real-time target tracking and classification, environment\nperception and decision support, and path planning and navigation. Application\nprocess in key areas. Research results show that the proposed system has an\naccuracy of over 98% in image recognition, target tracking and classification,\nand also demonstrates efficient performance and practicality in environmental\nperception and decision support, path planning and navigation. The conclusion\npoints out that deep learning technology can significantly improve the accuracy\nand real-time response capabilities of autonomous driving systems. Although\nthere are still challenges in environmental perception and decision support,\nwith the advancement of technology, it is expected to achieve wider\napplications and greater capabilities in the future. potential.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.00490v2",
    "published_date": "2024-06-01 16:41:24 UTC",
    "updated_date": "2024-06-04 03:15:41 UTC"
  },
  {
    "arxiv_id": "2406.00487v1",
    "title": "Optimistic Rates for Learning from Label Proportions",
    "authors": [
      "Gene Li",
      "Lin Chen",
      "Adel Javanmard",
      "Vahab Mirrokni"
    ],
    "abstract": "We consider a weakly supervised learning problem called Learning from Label\nProportions (LLP), where examples are grouped into ``bags'' and only the\naverage label within each bag is revealed to the learner. We study various\nlearning rules for LLP that achieve PAC learning guarantees for classification\nloss. We establish that the classical Empirical Proportional Risk Minimization\n(EPRM) learning rule (Yu et al., 2014) achieves fast rates under realizability,\nbut EPRM and similar proportion matching learning rules can fail in the\nagnostic setting. We also show that (1) a debiased proportional square loss, as\nwell as (2) a recently proposed EasyLLP learning rule (Busa-Fekete et al.,\n2023) both achieve ``optimistic rates'' (Panchenko, 2002); in both the\nrealizable and agnostic settings, their sample complexity is optimal (up to log\nfactors) in terms of $\\epsilon, \\delta$, and VC dimension.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to COLT 2024. Comments welcome",
    "pdf_url": "http://arxiv.org/pdf/2406.00487v1",
    "published_date": "2024-06-01 16:36:40 UTC",
    "updated_date": "2024-06-01 16:36:40 UTC"
  },
  {
    "arxiv_id": "2406.02598v1",
    "title": "Towards Learning Foundation Models for Heuristic Functions to Solve Pathfinding Problems",
    "authors": [
      "Vedant Khandelwal",
      "Amit Sheth",
      "Forest Agostinelli"
    ],
    "abstract": "Pathfinding problems are found throughout robotics, computational science,\nand natural sciences. Traditional methods to solve these require training deep\nneural networks (DNNs) for each new problem domain, consuming substantial time\nand resources. This study introduces a novel foundation model, leveraging deep\nreinforcement learning to train heuristic functions that seamlessly adapt to\nnew domains without further fine-tuning. Building upon DeepCubeA, we enhance\nthe model by providing the heuristic function with the domain's state\ntransition information, improving its adaptability. Utilizing a puzzle\ngenerator for the 15-puzzle action space variation domains, we demonstrate our\nmodel's ability to generalize and solve unseen domains. We achieve a strong\ncorrelation between learned and ground truth heuristic values across various\ndomains, as evidenced by robust R-squared and Concordance Correlation\nCoefficient metrics. These results underscore the potential of foundation\nmodels to establish new standards in efficiency and adaptability for AI-driven\nsolutions in complex pathfinding problems.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.02598v1",
    "published_date": "2024-06-01 16:18:20 UTC",
    "updated_date": "2024-06-01 16:18:20 UTC"
  },
  {
    "arxiv_id": "2406.00473v1",
    "title": "Pedestrian intention prediction in Adverse Weather Conditions with Spiking Neural Networks and Dynamic Vision Sensors",
    "authors": [
      "Mustafa Sakhai",
      "Szymon Mazurek",
      "Jakub Caputa",
      "Jan K. Argasiński",
      "Maciej Wielgosz"
    ],
    "abstract": "This study examines the effectiveness of Spiking Neural Networks (SNNs)\npaired with Dynamic Vision Sensors (DVS) to improve pedestrian detection in\nadverse weather, a significant challenge for autonomous vehicles. Utilizing the\nhigh temporal resolution and low latency of DVS, which excels in dynamic,\nlow-light, and high-contrast environments, we assess the efficiency of SNNs\ncompared to traditional Convolutional Neural Networks (CNNs).\n  Our experiments involved testing across diverse weather scenarios using a\ncustom dataset from the CARLA simulator, mirroring real-world variability. SNN\nmodels, enhanced with Temporally Effective Batch Normalization, were trained\nand benchmarked against state-of-the-art CNNs to demonstrate superior accuracy\nand computational efficiency in complex conditions such as rain and fog.\n  The results indicate that SNNs, integrated with DVS, significantly reduce\ncomputational overhead and improve detection accuracy in challenging conditions\ncompared to CNNs. This highlights the potential of DVS combined with\nbio-inspired SNN processing to enhance autonomous vehicle perception and\ndecision-making systems, advancing intelligent transportation systems' safety\nfeatures in varying operational environments.\n  Additionally, our research indicates that SNNs perform more efficiently in\nhandling long perception windows and prediction tasks, rather than simple\npedestrian detection.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "68T01",
      "I.2.1"
    ],
    "primary_category": "cs.CV",
    "comment": "Submitted for peer review to IEEE Transactions on Intelligent\n  Transportation Systems",
    "pdf_url": "http://arxiv.org/pdf/2406.00473v1",
    "published_date": "2024-06-01 15:58:24 UTC",
    "updated_date": "2024-06-01 15:58:24 UTC"
  },
  {
    "arxiv_id": "2406.01633v1",
    "title": "On Overcoming Miscalibrated Conversational Priors in LLM-based Chatbots",
    "authors": [
      "Christine Herlihy",
      "Jennifer Neville",
      "Tobias Schnabel",
      "Adith Swaminathan"
    ],
    "abstract": "We explore the use of Large Language Model (LLM-based) chatbots to power\nrecommender systems. We observe that the chatbots respond poorly when they\nencounter under-specified requests (e.g., they make incorrect assumptions,\nhedge with a long response, or refuse to answer). We conjecture that such\nmiscalibrated response tendencies (i.e., conversational priors) can be\nattributed to LLM fine-tuning using annotators -- single-turn annotations may\nnot capture multi-turn conversation utility, and the annotators' preferences\nmay not even be representative of users interacting with a recommender system.\n  We first analyze public LLM chat logs to conclude that query\nunder-specification is common. Next, we study synthetic recommendation problems\nwith configurable latent item utilities and frame them as Partially Observed\nDecision Processes (PODP). We find that pre-trained LLMs can be sub-optimal for\nPODPs and derive better policies that clarify under-specified queries when\nappropriate. Then, we re-calibrate LLMs by prompting them with learned control\nmessages to approximate the improved policy. Finally, we show empirically that\nour lightweight learning approach effectively uses logged conversation data to\nre-calibrate the response strategies of LLM-based chatbots for recommendation\ntasks.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "Preprint of UAI'24 conference publication",
    "pdf_url": "http://arxiv.org/pdf/2406.01633v1",
    "published_date": "2024-06-01 15:54:45 UTC",
    "updated_date": "2024-06-01 15:54:45 UTC"
  },
  {
    "arxiv_id": "2406.18566v1",
    "title": "Memorized Images in Diffusion Models share a Subspace that can be Located and Deleted",
    "authors": [
      "Ruchika Chavhan",
      "Ondrej Bohdal",
      "Yongshuo Zong",
      "Da Li",
      "Timothy Hospedales"
    ],
    "abstract": "Large-scale text-to-image diffusion models excel in generating high-quality\nimages from textual inputs, yet concerns arise as research indicates their\ntendency to memorize and replicate training data, raising We also addressed the\nissue of memorization in diffusion models, where models tend to replicate exact\ntraining samples raising copyright infringement and privacy issues. Efforts\nwithin the text-to-image community to address memorization explore causes such\nas data duplication, replicated captions, or trigger tokens, proposing\nper-prompt inference-time or training-time mitigation strategies. In this\npaper, we focus on the feed-forward layers and begin by contrasting neuron\nactivations of a set of memorized and non-memorized prompts. Experiments reveal\na surprising finding: many different sets of memorized prompts significantly\nactivate a common subspace in the model, demonstrating, for the first time,\nthat memorization in the diffusion models lies in a special subspace.\nSubsequently, we introduce a novel post-hoc method for editing pre-trained\nmodels, whereby memorization is mitigated through the straightforward pruning\nof weights in specialized subspaces, avoiding the need to disrupt the training\nor inference process as seen in prior research. Finally, we demonstrate the\nrobustness of the pruned model against training data extraction attacks,\nthereby unveiling new avenues for a practical and one-for-all solution to\nmemorization.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.18566v1",
    "published_date": "2024-06-01 15:47:13 UTC",
    "updated_date": "2024-06-01 15:47:13 UTC"
  },
  {
    "arxiv_id": "2407.13934v1",
    "title": "Towards Trustworthy AI: A Review of Ethical and Robust Large Language Models",
    "authors": [
      "Md Meftahul Ferdaus",
      "Mahdi Abdelguerfi",
      "Elias Ioup",
      "Kendall N. Niles",
      "Ken Pathak",
      "Steven Sloan"
    ],
    "abstract": "The rapid progress in Large Language Models (LLMs) could transform many\nfields, but their fast development creates significant challenges for\noversight, ethical creation, and building user trust. This comprehensive review\nlooks at key trust issues in LLMs, such as unintended harms, lack of\ntransparency, vulnerability to attacks, alignment with human values, and\nenvironmental impact. Many obstacles can undermine user trust, including\nsocietal biases, opaque decision-making, potential for misuse, and the\nchallenges of rapidly evolving technology. Addressing these trust gaps is\ncritical as LLMs become more common in sensitive areas like finance,\nhealthcare, education, and policy. To tackle these issues, we suggest combining\nethical oversight, industry accountability, regulation, and public involvement.\nAI development norms should be reshaped, incentives aligned, and ethics\nintegrated throughout the machine learning process, which requires close\ncollaboration across technology, ethics, law, policy, and other fields. Our\nreview contributes a robust framework to assess trust in LLMs and analyzes the\ncomplex trust dynamics in depth. We provide contextualized guidelines and\nstandards for responsibly developing and deploying these powerful AI systems.\nThis review identifies key limitations and challenges in creating trustworthy\nAI. By addressing these issues, we aim to build a transparent, accountable AI\necosystem that benefits society while minimizing risks. Our findings provide\nvaluable guidance for researchers, policymakers, and industry leaders striving\nto establish trust in LLMs and ensure they are used responsibly across various\napplications for the good of society.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "Under review at Proceedings of the IEEE",
    "pdf_url": "http://arxiv.org/pdf/2407.13934v1",
    "published_date": "2024-06-01 14:47:58 UTC",
    "updated_date": "2024-06-01 14:47:58 UTC"
  },
  {
    "arxiv_id": "2406.00456v2",
    "title": "Mix-of-Granularity: Optimize the Chunking Granularity for Retrieval-Augmented Generation",
    "authors": [
      "Zijie Zhong",
      "Hanwen Liu",
      "Xiaoya Cui",
      "Xiaofan Zhang",
      "Zengchang Qin"
    ],
    "abstract": "Integrating information from various reference databases is a major challenge\nfor Retrieval-Augmented Generation (RAG) systems because each knowledge source\nadopts a unique data structure and follows different conventions. Retrieving\nfrom multiple knowledge sources with one fixed strategy usually leads to\nunder-exploitation of information. To mitigate this drawback, inspired by\nMix-of-Expert, we introduce Mix-of-Granularity (MoG), a method that dynamically\ndetermines the optimal granularity of a knowledge source based on input queries\nusing a router. The router is efficiently trained with a newly proposed loss\nfunction employing soft labels. We further extend MoG to MoG-Graph (MoGG),\nwhere reference documents are pre-processed as graphs, enabling the retrieval\nof distantly situated snippets. Experiments demonstrate that MoG and MoGG\neffectively predict optimal granularity levels, significantly enhancing the\nperformance of the RAG system in downstream tasks. The code of both MoG and\nMoGG are released in https://github.com/ZGChung/Mix-of-Granularity.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "COLING 2025 conference paper. 19 pages, 6 figures and 11 tables",
    "pdf_url": "http://arxiv.org/pdf/2406.00456v2",
    "published_date": "2024-06-01 14:45:03 UTC",
    "updated_date": "2025-01-26 06:52:41 UTC"
  },
  {
    "arxiv_id": "2406.02597v1",
    "title": "CoNO: Complex Neural Operator for Continous Dynamical Physical Systems",
    "authors": [
      "Karn Tiwari",
      "N M Anoop Krishnan",
      "A P Prathosh"
    ],
    "abstract": "Neural operators extend data-driven models to map between\ninfinite-dimensional functional spaces. While these operators perform\neffectively in either the time or frequency domain, their performance may be\nlimited when applied to non-stationary spatial or temporal signals whose\nfrequency characteristics change with time. Here, we introduce Complex Neural\nOperator (CoNO) that parameterizes the integral kernel using Fractional Fourier\nTransform (FrFT), better representing non-stationary signals in a\ncomplex-valued domain. Theoretically, we prove the universal approximation\ncapability of CoNO. We perform an extensive empirical evaluation of CoNO on\nseven challenging partial differential equations (PDEs), including regular\ngrids, structured meshes, and point clouds. Empirically, CoNO consistently\nattains state-of-the-art performance, showcasing an average relative gain of\n10.9%. Further, CoNO exhibits superior performance, outperforming all other\nmodels in additional tasks such as zero-shot super-resolution and robustness to\nnoise. CoNO also exhibits the ability to learn from small amounts of data --\ngiving the same performance as the next best model with just 60% of the\ntraining data. Altogether, CoNO presents a robust and superior model for\nmodeling continuous dynamical systems, providing a fillip to scientific machine\nlearning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "Under Review",
    "pdf_url": "http://arxiv.org/pdf/2406.02597v1",
    "published_date": "2024-06-01 14:32:19 UTC",
    "updated_date": "2024-06-01 14:32:19 UTC"
  },
  {
    "arxiv_id": "2406.00452v1",
    "title": "Towards a Unified Framework of Clustering-based Anomaly Detection",
    "authors": [
      "Zeyu Fang",
      "Ming Gu",
      "Sheng Zhou",
      "Jiawei Chen",
      "Qiaoyu Tan",
      "Haishuai Wang",
      "Jiajun Bu"
    ],
    "abstract": "Unsupervised Anomaly Detection (UAD) plays a crucial role in identifying\nabnormal patterns within data without labeled examples, holding significant\npractical implications across various domains. Although the individual\ncontributions of representation learning and clustering to anomaly detection\nare well-established, their interdependencies remain under-explored due to the\nabsence of a unified theoretical framework. Consequently, their collective\npotential to enhance anomaly detection performance remains largely untapped. To\nbridge this gap, in this paper, we propose a novel probabilistic mixture model\nfor anomaly detection to establish a theoretical connection among\nrepresentation learning, clustering, and anomaly detection. By maximizing a\nnovel anomaly-aware data likelihood, representation learning and clustering can\neffectively reduce the adverse impact of anomalous data and collaboratively\nbenefit anomaly detection. Meanwhile, a theoretically substantiated anomaly\nscore is naturally derived from this framework. Lastly, drawing inspiration\nfrom gravitational analysis in physics, we have devised an improved anomaly\nscore that more effectively harnesses the combined power of representation\nlearning and clustering. Extensive experiments, involving 17 baseline methods\nacross 30 diverse datasets, validate the effectiveness and generalization\ncapability of the proposed method, surpassing state-of-the-art methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.00452v1",
    "published_date": "2024-06-01 14:30:12 UTC",
    "updated_date": "2024-06-01 14:30:12 UTC"
  },
  {
    "arxiv_id": "2406.00447v1",
    "title": "DroneVis: Versatile Computer Vision Library for Drones",
    "authors": [
      "Ahmed Heakl",
      "Fatma Youssef",
      "Victor Parque",
      "Walid Gomaa"
    ],
    "abstract": "This paper introduces DroneVis, a novel library designed to automate computer\nvision algorithms on Parrot drones. DroneVis offers a versatile set of features\nand provides a diverse range of computer vision tasks along with a variety of\nmodels to choose from. Implemented in Python, the library adheres to\nhigh-quality code standards, facilitating effortless customization and feature\nexpansion according to user requirements. In addition, comprehensive\ndocumentation is provided, encompassing usage guidelines and illustrative use\ncases. Our documentation, code, and examples are available in\nhttps://github.com/ahmedheakl/drone-vis.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CY",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "23 pages, 15 figure, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2406.00447v1",
    "published_date": "2024-06-01 14:06:46 UTC",
    "updated_date": "2024-06-01 14:06:46 UTC"
  },
  {
    "arxiv_id": "2406.00446v3",
    "title": "Advancing Supervised Local Learning Beyond Classification with Long-term Feature Bank",
    "authors": [
      "Feiyu Zhu",
      "Yuming Zhang",
      "Changpeng Cai",
      "Chenghao He",
      "Xiuyuan Guo",
      "Jiao Li",
      "Peizhe Wang",
      "Junhao Su",
      "Jialin Gao"
    ],
    "abstract": "Local learning offers an alternative to traditional end-to-end\nback-propagation in deep neural networks, significantly reducing GPU memory\nusage. While local learning has shown promise in image classification tasks,\nits application to other visual tasks remains limited. This limitation arises\nprimarily from two factors: 1) architectures tailored for classification are\noften not transferable to other tasks, leading to a lack of reusability of\ntask-specific knowledge; 2) the absence of cross-scale feature communication\nresults in degraded performance in tasks such as object detection and\nsuper-resolution. To address these challenges, we propose the Memory-augmented\nAuxiliary Network (MAN), which introduces a simplified design principle and\nincorporates a feature bank to enhance cross-task adaptability and\ncommunication. This work represents the first successful application of local\nlearning methods beyond classification, demonstrating that MAN not only\nconserves GPU memory but also achieves performance on par with end-to-end\napproaches across multiple datasets for various visual tasks.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.00446v3",
    "published_date": "2024-06-01 14:02:11 UTC",
    "updated_date": "2024-10-15 07:33:47 UTC"
  },
  {
    "arxiv_id": "2406.00443v1",
    "title": "Generating 3D Terrain with 2D Cellular Automata",
    "authors": [
      "Nuno Fachada",
      "António R. Rodrigues",
      "Diogo de Andrade",
      "Phil Lopes"
    ],
    "abstract": "This paper presents an initial exploration on the use of 2D cellular automata\n(CA) for generating 3D terrains through a simple yet effective additive\napproach. By experimenting with multiple CA transition rules, this preliminary\ninvestigation yielded aesthetically interesting landscapes, hinting at the\ntechnique's potential applicability for real-time terrain generation in games.",
    "categories": [
      "nlin.CG",
      "cs.AI",
      "cs.GR",
      "I.3.5; I.3.7; I.6.8; I.2.10"
    ],
    "primary_category": "nlin.CG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.00443v1",
    "published_date": "2024-06-01 13:43:28 UTC",
    "updated_date": "2024-06-01 13:43:28 UTC"
  },
  {
    "arxiv_id": "2406.00441v1",
    "title": "Neural Polarization: Toward Electron Density for Molecules by Extending Equivariant Networks",
    "authors": [
      "Bumju Kwak",
      "Jeonghee Jo"
    ],
    "abstract": "Recent SO(3)-equivariant models embedded a molecule as a set of single atoms\nfixed in the three-dimensional space, which is analogous to a ball-and-stick\nview. This perspective provides a concise view of atom arrangements, however,\nthe surrounding electron density cannot be represented and its polarization\neffects may be underestimated. To overcome this limitation, we propose\n\\textit{Neural Polarization}, a novel method extending equivariant network by\nembedding each atom as a pair of fixed and moving points. Motivated by density\nfunctional theory, Neural Polarization represents molecules as a space-filling\nview which includes an electron density, in contrast with a ball-and-stick\nview. Neural Polarization can flexibly be applied to most type of existing\nequivariant models. We showed that Neural Polarization can improve prediction\nperformances of existing models over a wide range of targets. Finally, we\nverified that our method can improve the expressiveness and equivariance in\nterms of mathematical aspects.",
    "categories": [
      "physics.chem-ph",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "physics.chem-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.00441v1",
    "published_date": "2024-06-01 13:39:27 UTC",
    "updated_date": "2024-06-01 13:39:27 UTC"
  },
  {
    "arxiv_id": "2406.07572v1",
    "title": "Domain-specific ReAct for physics-integrated iterative modeling: A case study of LLM agents for gas path analysis of gas turbines",
    "authors": [
      "Tao Song",
      "Yuwei Fan",
      "Chenlong Feng",
      "Keyu Song",
      "Chao Liu",
      "Dongxiang Jiang"
    ],
    "abstract": "This study explores the application of large language models (LLMs) with\ncallable tools in energy and power engineering domain, focusing on gas path\nanalysis of gas turbines. We developed a dual-agent tool-calling process to\nintegrate expert knowledge, predefined tools, and LLM reasoning. We evaluated\nvarious LLMs, including LLama3, Qwen1.5 and GPT. Smaller models struggled with\ntool usage and parameter extraction, while larger models demonstrated favorable\ncapabilities. All models faced challenges with complex, multi-component\nproblems. Based on the test results, we infer that LLMs with nearly 100 billion\nparameters could meet professional scenario requirements with fine-tuning and\nadvanced prompt design. Continued development are likely to enhance their\naccuracy and effectiveness, paving the way for more robust AI-driven solutions.",
    "categories": [
      "cs.AI",
      "cs.CE",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.07572v1",
    "published_date": "2024-06-01 13:35:18 UTC",
    "updated_date": "2024-06-01 13:35:18 UTC"
  },
  {
    "arxiv_id": "2406.00431v2",
    "title": "SpaFL: Communication-Efficient Federated Learning with Sparse Models and Low computational Overhead",
    "authors": [
      "Minsu Kim",
      "Walid Saad",
      "Merouane Debbah",
      "Choong Seon Hong"
    ],
    "abstract": "The large communication and computation overhead of federated learning (FL)\nis one of the main challenges facing its practical deployment over\nresource-constrained clients and systems. In this work, SpaFL: a\ncommunication-efficient FL framework is proposed to optimize sparse model\nstructures with low computational overhead. In SpaFL, a trainable threshold is\ndefined for each filter/neuron to prune its all connected parameters, thereby\nleading to structured sparsity. To optimize the pruning process itself, only\nthresholds are communicated between a server and clients instead of parameters,\nthereby learning how to prune. Further, global thresholds are used to update\nmodel parameters by extracting aggregated parameter importance. The\ngeneralization bound of SpaFL is also derived, thereby proving key insights on\nthe relation between sparsity and performance. Experimental results show that\nSpaFL improves accuracy while requiring much less communication and computing\nresources compared to sparse baselines. The code is available at\nhttps://github.com/news-vt/SpaFL_NeruIPS_2024",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "Published in NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.00431v2",
    "published_date": "2024-06-01 13:10:35 UTC",
    "updated_date": "2024-12-10 15:43:05 UTC"
  },
  {
    "arxiv_id": "2407.13112v1",
    "title": "Improvement of Applicability in Student Performance Prediction Based on Transfer Learning",
    "authors": [
      "Yan Zhao"
    ],
    "abstract": "Predicting student performance under varying data distributions is a\nchallenging task. This study proposes a method to improve prediction accuracy\nby employing transfer learning techniques on the dataset with varying\ndistributions. Using datasets from mathematics and Portuguese language courses,\nthe model was trained and evaluated to enhance its generalization ability and\nprediction accuracy. The datasets used in this study were sourced from Kaggle,\ncomprising a variety of attributes such as demographic details, social factors,\nand academic performance. The methodology involves using an Artificial Neural\nNetwork (ANN) combined with transfer learning, where some layer weights were\nprogressively frozen, and the remaining layers were fine-tuned. Experimental\nresults demonstrated that this approach excels in reducing Root Mean Square\nError (RMSE) and Mean Absolute Error (MAE), while improving the coefficient of\ndetermination (R2). The model was initially trained on a subset with a larger\nsample size and subsequently fine-tuned on another subset. This method\neffectively facilitated knowledge transfer, enhancing model performance on\ntasks with limited data. The results demonstrate that freezing more layers\nimproves performance for complex and noisy data, whereas freezing fewer layers\nis more effective for simpler and larger datasets. This study highlights the\npotential of transfer learning in predicting student performance and suggests\nfuture research to explore domain adaptation techniques for unlabeled datasets.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.13112v1",
    "published_date": "2024-06-01 13:09:05 UTC",
    "updated_date": "2024-06-01 13:09:05 UTC"
  },
  {
    "arxiv_id": "2406.00430v2",
    "title": "Evaluating Uncertainty-based Failure Detection for Closed-Loop LLM Planners",
    "authors": [
      "Zhi Zheng",
      "Qian Feng",
      "Hang Li",
      "Alois Knoll",
      "Jianxiang Feng"
    ],
    "abstract": "Recently, Large Language Models (LLMs) have witnessed remarkable performance\nas zero-shot task planners for robotic manipulation tasks. However, the\nopen-loop nature of previous works makes LLM-based planning error-prone and\nfragile. On the other hand, failure detection approaches for closed-loop\nplanning are often limited by task-specific heuristics or following an\nunrealistic assumption that the prediction is trustworthy all the time. As a\ngeneral-purpose reasoning machine, LLMs or Multimodal Large Language Models\n(MLLMs) are promising for detecting failures. However, However, the\nappropriateness of the aforementioned assumption diminishes due to the\nnotorious hullucination problem. In this work, we attempt to mitigate these\nissues by introducing a framework for closed-loop LLM-based planning called\nKnowLoop, backed by an uncertainty-based MLLMs failure detector, which is\nagnostic to any used MLLMs or LLMs. Specifically, we evaluate three different\nways for quantifying the uncertainty of MLLMs, namely token probability,\nentropy, and self-explained confidence as primary metrics based on three\ncarefully designed representative prompting strategies. With a self-collected\ndataset including various manipulation tasks and an LLM-based robot system, our\nexperiments demonstrate that token probability and entropy are more reflective\ncompared to self-explained confidence. By setting an appropriate threshold to\nfilter out uncertain predictions and seek human help actively, the accuracy of\nfailure detection can be significantly enhanced. This improvement boosts the\neffectiveness of closed-loop planning and the overall success rate of tasks.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted at ICRA 2024 Workshop on Back to the Future: Robot Learning\n  Going Probabilistic. Website: https://sites.google.com/view/konwloop/home",
    "pdf_url": "http://arxiv.org/pdf/2406.00430v2",
    "published_date": "2024-06-01 12:52:06 UTC",
    "updated_date": "2025-03-16 17:21:09 UTC"
  },
  {
    "arxiv_id": "2406.00415v3",
    "title": "Neural Combinatorial Optimization Algorithms for Solving Vehicle Routing Problems: A Comprehensive Survey with Perspectives",
    "authors": [
      "Xuan Wu",
      "Di Wang",
      "Lijie Wen",
      "Yubin Xiao",
      "Chunguo Wu",
      "Yuesong Wu",
      "Chaoyu Yu",
      "Douglas L. Maskell",
      "You Zhou"
    ],
    "abstract": "Although several surveys on Neural Combinatorial Optimization (NCO) solvers\nspecifically designed to solve Vehicle Routing Problems (VRPs) have been\nconducted, they did not cover the state-of-the-art (SOTA) NCO solvers emerged\nrecently. More importantly, to establish a comprehensive and up-to-date\ntaxonomy of NCO solvers, we systematically review relevant publications and\npreprints, categorizing them into four distinct types, namely Learning to\nConstruct, Learning to Improve, Learning to Predict-Once, and Learning to\nPredict-Multiplicity solvers. Subsequently, we present the inadequacies of the\nSOTA solvers, including poor generalization, incapability to solve large-scale\nVRPs, inability to address most types of VRP variants simultaneously, and\ndifficulty in comparing these NCO solvers with the conventional Operations\nResearch algorithms. Simultaneously, we discuss on-going efforts, identify open\ninadequacies, as well as propose promising and viable directions to overcome\nthese inadequacies. Notably, existing efforts focus on only one or two of these\ninadequacies, with none attempting to address all of them concurrently. In\naddition, we compare the performance of representative NCO solvers from the\nReinforcement, Supervised, and Unsupervised Learning paradigms across VRPs of\nvarying scales. Finally, following the proposed taxonomy, we provide an\naccompanying web page as a live repository for NCO solvers. Through this survey\nand the live repository, we aim to foster further advancements in the NCO\ncommunity.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "submitted to TNNLS",
    "pdf_url": "http://arxiv.org/pdf/2406.00415v3",
    "published_date": "2024-06-01 12:18:39 UTC",
    "updated_date": "2025-04-25 06:52:44 UTC"
  },
  {
    "arxiv_id": "2406.00410v1",
    "title": "Posterior Label Smoothing for Node Classification",
    "authors": [
      "Jaeseung Heo",
      "Moonjeong Park",
      "Dongwoo Kim"
    ],
    "abstract": "Soft labels can improve the generalization of a neural network classifier in\nmany domains, such as image classification. Despite its success, the current\nliterature has overlooked the efficiency of label smoothing in node\nclassification with graph-structured data. In this work, we propose a simple\nyet effective label smoothing for the transductive node classification task. We\ndesign the soft label to encapsulate the local context of the target node\nthrough the neighborhood label distribution. We apply the smoothing method for\nseven baseline models to show its effectiveness. The label smoothing methods\nimprove the classification accuracy in 10 node classification datasets in most\ncases. In the following analysis, we find that incorporating global label\nstatistics in posterior computation is the key to the success of label\nsmoothing. Further investigation reveals that the soft labels mitigate\noverfitting during training, leading to better generalization performance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.00410v1",
    "published_date": "2024-06-01 11:59:49 UTC",
    "updated_date": "2024-06-01 11:59:49 UTC"
  },
  {
    "arxiv_id": "2406.00409v1",
    "title": "Arabic Handwritten Text for Person Biometric Identification: A Deep Learning Approach",
    "authors": [
      "Mazen Balat",
      "Youssef Mohamed",
      "Ahmed Heakl",
      "Ahmed Zaky"
    ],
    "abstract": "This study thoroughly investigates how well deep learning models can\nrecognize Arabic handwritten text for person biometric identification. It\ncompares three advanced architectures -- ResNet50, MobileNetV2, and\nEfficientNetB7 -- using three widely recognized datasets: AHAWP, Khatt, and\nLAMIS-MSHD. Results show that EfficientNetB7 outperforms the others, achieving\ntest accuracies of 98.57\\%, 99.15\\%, and 99.79\\% on AHAWP, Khatt, and\nLAMIS-MSHD datasets, respectively. EfficientNetB7's exceptional performance is\ncredited to its innovative techniques, including compound scaling, depth-wise\nseparable convolutions, and squeeze-and-excitation blocks. These features allow\nthe model to extract more abstract and distinctive features from handwritten\ntext images. The study's findings hold significant implications for enhancing\nidentity verification and authentication systems, highlighting the potential of\ndeep learning in Arabic handwritten text recognition for person biometric\nidentification.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.MM",
      "cs.NE"
    ],
    "primary_category": "cs.CV",
    "comment": "6 pages, 11 figures, 4 tables, International IEEE Conference on the\n  Intelligent Methods, Systems, and Applications (IMSA)",
    "pdf_url": "http://arxiv.org/pdf/2406.00409v1",
    "published_date": "2024-06-01 11:43:00 UTC",
    "updated_date": "2024-06-01 11:43:00 UTC"
  },
  {
    "arxiv_id": "2406.03409v1",
    "title": "Robust Knowledge Distillation Based on Feature Variance Against Backdoored Teacher Model",
    "authors": [
      "Jinyin Chen",
      "Xiaoming Zhao",
      "Haibin Zheng",
      "Xiao Li",
      "Sheng Xiang",
      "Haifeng Guo"
    ],
    "abstract": "Benefiting from well-trained deep neural networks (DNNs), model compression\nhave captured special attention for computing resource limited equipment,\nespecially edge devices. Knowledge distillation (KD) is one of the widely used\ncompression techniques for edge deployment, by obtaining a lightweight student\nmodel from a well-trained teacher model released on public platforms. However,\nit has been empirically noticed that the backdoor in the teacher model will be\ntransferred to the student model during the process of KD. Although numerous KD\nmethods have been proposed, most of them focus on the distillation of a\nhigh-performing student model without robustness consideration. Besides, some\nresearch adopts KD techniques as effective backdoor mitigation tools, but they\nfail to perform model compression at the same time. Consequently, it is still\nan open problem to well achieve two objectives of robust KD, i.e., student\nmodel's performance and backdoor mitigation. To address these issues, we\npropose RobustKD, a robust knowledge distillation that compresses the model\nwhile mitigating backdoor based on feature variance. Specifically, RobustKD\ndistinguishes the previous works in three key aspects: (1) effectiveness: by\ndistilling the feature map of the teacher model after detoxification, the main\ntask performance of the student model is comparable to that of the teacher\nmodel; (2) robustness: by reducing the characteristic variance between the\nteacher model and the student model, it mitigates the backdoor of the student\nmodel under backdoored teacher model scenario; (3) generic: RobustKD still has\ngood performance in the face of multiple data models (e.g., WRN 28-4,\nPyramid-200) and diverse DNNs (e.g., ResNet50, MobileNet).",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.03409v1",
    "published_date": "2024-06-01 11:25:03 UTC",
    "updated_date": "2024-06-01 11:25:03 UTC"
  },
  {
    "arxiv_id": "2406.00405v2",
    "title": "Autaptic Synaptic Circuit Enhances Spatio-temporal Predictive Learning of Spiking Neural Networks",
    "authors": [
      "Lihao Wang",
      "Zhaofei Yu"
    ],
    "abstract": "Spiking Neural Networks (SNNs) emulate the integrated-fire-leak mechanism\nfound in biological neurons, offering a compelling combination of biological\nrealism and energy efficiency. In recent years, they have gained considerable\nresearch interest. However, existing SNNs predominantly rely on the Leaky\nIntegrate-and-Fire (LIF) model and are primarily suited for simple, static\ntasks. They lack the ability to effectively model long-term temporal\ndependencies and facilitate spatial information interaction, which is crucial\nfor tackling complex, dynamic spatio-temporal prediction tasks. To tackle these\nchallenges, this paper draws inspiration from the concept of autaptic synapses\nin biology and proposes a novel Spatio-Temporal Circuit (STC) model. The STC\nmodel integrates two learnable adaptive pathways, enhancing the spiking\nneurons' temporal memory and spatial coordination. We conduct a theoretical\nanalysis of the dynamic parameters in the STC model, highlighting their\ncontribution in establishing long-term memory and mitigating the issue of\ngradient vanishing. Through extensive experiments on multiple spatio-temporal\nprediction datasets, we demonstrate that our model outperforms other adaptive\nmodels. Furthermore, our model is compatible with existing spiking neuron\nmodels, thereby augmenting their dynamic representations. In essence, our work\nenriches the specificity and topological complexity of SNNs.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "Accepted by ICML2024",
    "pdf_url": "http://arxiv.org/pdf/2406.00405v2",
    "published_date": "2024-06-01 11:17:27 UTC",
    "updated_date": "2024-06-05 03:45:18 UTC"
  },
  {
    "arxiv_id": "2406.00403v1",
    "title": "Dual-perspective Cross Contrastive Learning in Graph Transformers",
    "authors": [
      "Zelin Yao",
      "Chuang Liu",
      "Xueqi Ma",
      "Mukun Chen",
      "Jia Wu",
      "Xiantao Cai",
      "Bo Du",
      "Wenbin Hu"
    ],
    "abstract": "Graph contrastive learning (GCL) is a popular method for leaning graph\nrepresentations by maximizing the consistency of features across augmented\nviews. Traditional GCL methods utilize single-perspective i.e. data or\nmodel-perspective) augmentation to generate positive samples, restraining the\ndiversity of positive samples. In addition, these positive samples may be\nunreliable due to uncontrollable augmentation strategies that potentially alter\nthe semantic information. To address these challenges, this paper proposed a\ninnovative framework termed dual-perspective cross graph contrastive learning\n(DC-GCL), which incorporates three modifications designed to enhance positive\nsample diversity and reliability: 1) We propose dual-perspective augmentation\nstrategy that provide the model with more diverse training data, enabling the\nmodel effective learning of feature consistency across different views. 2) From\nthe data perspective, we slightly perturb the original graphs using\ncontrollable data augmentation, effectively preserving their semantic\ninformation. 3) From the model perspective, we enhance the encoder by utilizing\nmore powerful graph transformers instead of graph neural networks. Based on the\nmodel's architecture, we propose three pruning-based strategies to slightly\nperturb the encoder, providing more reliable positive samples. These\nmodifications collectively form the DC-GCL's foundation and provide more\ndiverse and reliable training inputs, offering significant improvements over\ntraditional GCL methods. Extensive experiments on various benchmarks\ndemonstrate that DC-GCL consistently outperforms different baselines on various\ndatasets and tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "12 pages, 5 figures, submitted to IEEE TKDE",
    "pdf_url": "http://arxiv.org/pdf/2406.00403v1",
    "published_date": "2024-06-01 11:11:49 UTC",
    "updated_date": "2024-06-01 11:11:49 UTC"
  },
  {
    "arxiv_id": "2406.00396v3",
    "title": "Stochastic Resetting Mitigates Latent Gradient Bias of SGD from Label Noise",
    "authors": [
      "Youngkyoung Bae",
      "Yeongwoo Song",
      "Hawoong Jeong"
    ],
    "abstract": "Giving up and starting over may seem wasteful in many situations such as\nsearching for a target or training deep neural networks (DNNs). Our study,\nthough, demonstrates that resetting from a checkpoint can significantly improve\ngeneralization performance when training DNNs with noisy labels. In the\npresence of noisy labels, DNNs initially learn the general patterns of the data\nbut then gradually memorize the corrupted data, leading to overfitting. By\ndeconstructing the dynamics of stochastic gradient descent (SGD), we identify\nthe behavior of a latent gradient bias induced by noisy labels, which harms\ngeneralization. To mitigate this negative effect, we apply the stochastic\nresetting method to SGD, inspired by recent developments in the field of\nstatistical physics achieving efficient target searches. We first theoretically\nidentify the conditions where resetting becomes beneficial, and then we\nempirically validate our theory, confirming the significant improvements\nachieved by resetting. We further demonstrate that our method is both easy to\nimplement and compatible with other methods for handling noisy labels.\nAdditionally, this work offers insights into the learning dynamics of DNNs from\nan interpretability perspective, expanding the potential to analyze training\nmethods through the lens of statistical physics.",
    "categories": [
      "cs.LG",
      "cond-mat.stat-mech",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "30 pages, 14 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.00396v3",
    "published_date": "2024-06-01 10:45:41 UTC",
    "updated_date": "2025-03-04 05:51:53 UTC"
  },
  {
    "arxiv_id": "2406.00394v1",
    "title": "Learning Causal Abstractions of Linear Structural Causal Models",
    "authors": [
      "Riccardo Massidda",
      "Sara Magliacane",
      "Davide Bacciu"
    ],
    "abstract": "The need for modelling causal knowledge at different levels of granularity\narises in several settings. Causal Abstraction provides a framework for\nformalizing this problem by relating two Structural Causal Models at different\nlevels of detail. Despite increasing interest in applying causal abstraction,\ne.g. in the interpretability of large machine learning models, the graphical\nand parametrical conditions under which a causal model can abstract another are\nnot known. Furthermore, learning causal abstractions from data is still an open\nproblem. In this work, we tackle both issues for linear causal models with\nlinear abstraction functions. First, we characterize how the low-level\ncoefficients and the abstraction function determine the high-level coefficients\nand how the high-level model constrains the causal ordering of low-level\nvariables. Then, we apply our theoretical results to learn high-level and\nlow-level causal models and their abstraction function from observational data.\nIn particular, we introduce Abs-LiNGAM, a method that leverages the constraints\ninduced by the learned high-level model and the abstraction function to speedup\nthe recovery of the larger low-level model, under the assumption of\nnon-Gaussian noise terms. In simulated settings, we show the effectiveness of\nlearning causal abstractions from data and the potential of our method in\nimproving scalability of causal discovery.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ME"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.00394v1",
    "published_date": "2024-06-01 10:42:52 UTC",
    "updated_date": "2024-06-01 10:42:52 UTC"
  },
  {
    "arxiv_id": "2406.00392v2",
    "title": "Artificial Generational Intelligence: Cultural Accumulation in Reinforcement Learning",
    "authors": [
      "Jonathan Cook",
      "Chris Lu",
      "Edward Hughes",
      "Joel Z. Leibo",
      "Jakob Foerster"
    ],
    "abstract": "Cultural accumulation drives the open-ended and diverse progress in\ncapabilities spanning human history. It builds an expanding body of knowledge\nand skills by combining individual exploration with inter-generational\ninformation transmission. Despite its widespread success among humans, the\ncapacity for artificial learning agents to accumulate culture remains\nunder-explored. In particular, approaches to reinforcement learning typically\nstrive for improvements over only a single lifetime. Generational algorithms\nthat do exist fail to capture the open-ended, emergent nature of cultural\naccumulation, which allows individuals to trade-off innovation and imitation.\nBuilding on the previously demonstrated ability for reinforcement learning\nagents to perform social learning, we find that training setups which balance\nthis with independent learning give rise to cultural accumulation. These\naccumulating agents outperform those trained for a single lifetime with the\nsame cumulative experience. We explore this accumulation by constructing two\nmodels under two distinct notions of a generation: episodic generations, in\nwhich accumulation occurs via in-context learning and train-time generations,\nin which accumulation occurs via in-weights learning. In-context and in-weights\ncultural accumulation can be interpreted as analogous to knowledge and skill\naccumulation, respectively. To the best of our knowledge, this work is the\nfirst to present general models that achieve emergent cultural accumulation in\nreinforcement learning, opening up new avenues towards more open-ended learning\nsystems, as well as presenting new opportunities for modelling human culture.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.00392v2",
    "published_date": "2024-06-01 10:33:32 UTC",
    "updated_date": "2024-10-28 16:33:31 UTC"
  },
  {
    "arxiv_id": "2406.06558v1",
    "title": "Enhancing Text Authenticity: A Novel Hybrid Approach for AI-Generated Text Detection",
    "authors": [
      "Ye Zhang",
      "Qian Leng",
      "Mengran Zhu",
      "Rui Ding",
      "Yue Wu",
      "Jintong Song",
      "Yulu Gong"
    ],
    "abstract": "The rapid advancement of Large Language Models (LLMs) has ushered in an era\nwhere AI-generated text is increasingly indistinguishable from human-generated\ncontent. Detecting AI-generated text has become imperative to combat\nmisinformation, ensure content authenticity, and safeguard against malicious\nuses of AI. In this paper, we propose a novel hybrid approach that combines\ntraditional TF-IDF techniques with advanced machine learning models, including\nBayesian classifiers, Stochastic Gradient Descent (SGD), Categorical Gradient\nBoosting (CatBoost), and 12 instances of Deberta-v3-large models. Our approach\naims to address the challenges associated with detecting AI-generated text by\nleveraging the strengths of both traditional feature extraction methods and\nstate-of-the-art deep learning models. Through extensive experiments on a\ncomprehensive dataset, we demonstrate the effectiveness of our proposed method\nin accurately distinguishing between human and AI-generated text. Our approach\nachieves superior performance compared to existing methods. This research\ncontributes to the advancement of AI-generated text detection techniques and\nlays the foundation for developing robust solutions to mitigate the challenges\nposed by AI-generated content.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.06558v1",
    "published_date": "2024-06-01 10:21:54 UTC",
    "updated_date": "2024-06-01 10:21:54 UTC"
  },
  {
    "arxiv_id": "2406.01629v1",
    "title": "RecDiff: Diffusion Model for Social Recommendation",
    "authors": [
      "Zongwei Li",
      "Lianghao Xia",
      "Chao Huang"
    ],
    "abstract": "Social recommendation has emerged as a powerful approach to enhance\npersonalized recommendations by leveraging the social connections among users,\nsuch as following and friend relations observed in online social platforms. The\nfundamental assumption of social recommendation is that socially-connected\nusers exhibit homophily in their preference patterns. This means that users\nconnected by social ties tend to have similar tastes in user-item activities,\nsuch as rating and purchasing. However, this assumption is not always valid due\nto the presence of irrelevant and false social ties, which can contaminate user\nembeddings and adversely affect recommendation accuracy. To address this\nchallenge, we propose a novel diffusion-based social denoising framework for\nrecommendation (RecDiff). Our approach utilizes a simple yet effective\nhidden-space diffusion paradigm to alleivate the noisy effect in the compressed\nand dense representation space. By performing multi-step noise diffusion and\nremoval, RecDiff possesses a robust ability to identify and eliminate noise\nfrom the encoded user representations, even when the noise levels vary. The\ndiffusion module is optimized in a downstream task-aware manner, thereby\nmaximizing its ability to enhance the recommendation process. We conducted\nextensive experiments to evaluate the efficacy of our framework, and the\nresults demonstrate its superiority in terms of recommendation accuracy,\ntraining efficiency, and denoising effectiveness. The source code for the model\nimplementation is publicly available at: https://github.com/HKUDS/RecDiff.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.01629v1",
    "published_date": "2024-06-01 10:20:52 UTC",
    "updated_date": "2024-06-01 10:20:52 UTC"
  },
  {
    "arxiv_id": "2406.00380v3",
    "title": "HonestLLM: Toward an Honest and Helpful Large Language Model",
    "authors": [
      "Chujie Gao",
      "Siyuan Wu",
      "Yue Huang",
      "Dongping Chen",
      "Qihui Zhang",
      "Zhengyan Fu",
      "Yao Wan",
      "Lichao Sun",
      "Xiangliang Zhang"
    ],
    "abstract": "Large Language Models (LLMs) have achieved remarkable success across various\nindustries due to their exceptional generative capabilities. However, for safe\nand effective real-world deployments, ensuring honesty and helpfulness is\ncritical. This paper addresses the question: Can we prioritize the helpfulness\nof LLMs while preserving their honesty? To begin with, we establish exhaustive\nprinciples aimed at guaranteeing the honesty of LLM. Additionally, we introduce\na novel dataset, referred to as HoneSet, comprising 930 queries spanning six\ncategories meticulously crafted to assess an LLM's capacity for maintaining\nhonesty. Subsequently, we present two approaches to augmenting honesty and\nhelpfulness in LLMs: a training-free enhancement and a fine-tuning-based\nimprovement. The training-free approach, which is based on curiosity-driven\nprompting, empowers LLMs to articulate internal confusion and uncertainty\nregarding queries, thereby optimizing their responses. Conversely, the\nfine-tuning-based method employs a two-stage process inspired by curriculum\nlearning: initially instructing LLMs to discern between honest and dishonest\nresponses, then refining their training to enhance helpfulness. Experiments\nconducted on nine prominent LLMs demonstrate a significant improvement in\nalignment with honesty across all models through the implementation of our\nproposed enhancements. Particularly noteworthy is the 65.3% enhancement\nobserved in Llama3-8b and the remarkable 124.7% improvement in Mistral-7b, as\nmeasured by the H$^{2}$ (honest and helpful) assessment. We believe that our\nwork can pave the way for developing more trustworthy LLMs for real-world\napplications.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.00380v3",
    "published_date": "2024-06-01 09:36:16 UTC",
    "updated_date": "2024-12-11 11:52:58 UTC"
  },
  {
    "arxiv_id": "2406.00367v2",
    "title": "RoBERTa-BiLSTM: A Context-Aware Hybrid Model for Sentiment Analysis",
    "authors": [
      "Md. Mostafizer Rahman",
      "Ariful Islam Shiplu",
      "Yutaka Watanobe",
      "Md. Ashad Alam"
    ],
    "abstract": "Effectively analyzing the comments to uncover latent intentions holds immense\nvalue in making strategic decisions across various domains. However, several\nchallenges hinder the process of sentiment analysis including the lexical\ndiversity exhibited in comments, the presence of long dependencies within the\ntext, encountering unknown symbols and words, and dealing with imbalanced\ndatasets. Moreover, existing sentiment analysis tasks mostly leveraged\nsequential models to encode the long dependent texts and it requires longer\nexecution time as it processes the text sequentially. In contrast, the\nTransformer requires less execution time due to its parallel processing nature.\nIn this work, we introduce a novel hybrid deep learning model, RoBERTa-BiLSTM,\nwhich combines the Robustly Optimized BERT Pretraining Approach (RoBERTa) with\nBidirectional Long Short-Term Memory (BiLSTM) networks. RoBERTa is utilized to\ngenerate meaningful word embedding vectors, while BiLSTM effectively captures\nthe contextual semantics of long-dependent texts. The RoBERTa-BiLSTM hybrid\nmodel leverages the strengths of both sequential and Transformer models to\nenhance performance in sentiment analysis. We conducted experiments using\ndatasets from IMDb, Twitter US Airline, and Sentiment140 to evaluate the\nproposed model against existing state-of-the-art methods. Our experimental\nfindings demonstrate that the RoBERTa-BiLSTM model surpasses baseline models\n(e.g., BERT, RoBERTa-base, RoBERTa-GRU, and RoBERTa-LSTM), achieving accuracies\nof 80.74%, 92.36%, and 82.25% on the Twitter US Airline, IMDb, and Sentiment140\ndatasets, respectively. Additionally, the model achieves F1-scores of 80.73%,\n92.35%, and 82.25% on the same datasets, respectively.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CE"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.00367v2",
    "published_date": "2024-06-01 08:59:46 UTC",
    "updated_date": "2025-05-15 01:38:21 UTC"
  },
  {
    "arxiv_id": "2406.00348v1",
    "title": "An Effective Weight Initialization Method for Deep Learning: Application to Satellite Image Classification",
    "authors": [
      "Wadii Boulila",
      "Eman Alshanqiti",
      "Ayyub Alzahem",
      "Anis Koubaa",
      "Nabil Mlaiki"
    ],
    "abstract": "The growing interest in satellite imagery has triggered the need for\nefficient mechanisms to extract valuable information from these vast data\nsources, providing deeper insights. Even though deep learning has shown\nsignificant progress in satellite image classification. Nevertheless, in the\nliterature, only a few results can be found on weight initialization\ntechniques. These techniques traditionally involve initializing the networks'\nweights before training on extensive datasets, distinct from fine-tuning the\nweights of pre-trained networks. In this study, a novel weight initialization\nmethod is proposed in the context of satellite image classification. The\nproposed weight initialization method is mathematically detailed during the\nforward and backward passes of the convolutional neural network (CNN) model.\nExtensive experiments are carried out using six real-world datasets.\nComparative analyses with existing weight initialization techniques made on\nvarious well-known CNN models reveal that the proposed weight initialization\ntechnique outperforms the previous competitive techniques in classification\naccuracy. The complete code of the proposed technique, along with the obtained\nresults, is available at https://github.com/WadiiBoulila/Weight-Initialization",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.00348v1",
    "published_date": "2024-06-01 07:56:02 UTC",
    "updated_date": "2024-06-01 07:56:02 UTC"
  },
  {
    "arxiv_id": "2406.06556v1",
    "title": "Enhancing Presentation Slide Generation by LLMs with a Multi-Staged End-to-End Approach",
    "authors": [
      "Sambaran Bandyopadhyay",
      "Himanshu Maheshwari",
      "Anandhavelu Natarajan",
      "Apoorv Saxena"
    ],
    "abstract": "Generating presentation slides from a long document with multimodal elements\nsuch as text and images is an important task. This is time consuming and needs\ndomain expertise if done manually. Existing approaches for generating a rich\npresentation from a document are often semi-automatic or only put a flat\nsummary into the slides ignoring the importance of a good narrative. In this\npaper, we address this research gap by proposing a multi-staged end-to-end\nmodel which uses a combination of LLM and VLM. We have experimentally shown\nthat compared to applying LLMs directly with state-of-the-art prompting, our\nproposed multi-staged solution is better in terms of automated metrics and\nhuman evaluation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.06556v1",
    "published_date": "2024-06-01 07:49:31 UTC",
    "updated_date": "2024-06-01 07:49:31 UTC"
  },
  {
    "arxiv_id": "2406.00332v1",
    "title": "A Structured Review of Literature on Uncertainty in Machine Learning & Deep Learning",
    "authors": [
      "Fahimeh Fakour",
      "Ali Mosleh",
      "Ramin Ramezani"
    ],
    "abstract": "The adaptation and use of Machine Learning (ML) in our daily lives has led to\nconcerns in lack of transparency, privacy, reliability, among others. As a\nresult, we are seeing research in niche areas such as interpretability,\ncausality, bias and fairness, and reliability. In this survey paper, we focus\non a critical concern for adaptation of ML in risk-sensitive applications,\nnamely understanding and quantifying uncertainty. Our paper approaches this\ntopic in a structured way, providing a review of the literature in the various\nfacets that uncertainty is enveloped in the ML process. We begin by defining\nuncertainty and its categories (e.g., aleatoric and epistemic), understanding\nsources of uncertainty (e.g., data and model), and how uncertainty can be\nassessed in terms of uncertainty quantification techniques (Ensembles, Bayesian\nNeural Networks, etc.). As part of our assessment and understanding of\nuncertainty in the ML realm, we cover metrics for uncertainty quantification\nfor a single sample, dataset, and metrics for accuracy of the uncertainty\nestimation itself. This is followed by discussions on calibration (model and\nuncertainty), and decision making under uncertainty. Thus, we provide a more\ncomplete treatment of uncertainty: from the sources of uncertainty to the\ndecision-making process. We have focused the review of uncertainty\nquantification methods on Deep Learning (DL), while providing the necessary\nbackground for uncertainty discussion within ML in general. Key contributions\nin this review are broadening the scope of uncertainty discussion, as well as\nan updated review of uncertainty quantification methods in DL.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.00332v1",
    "published_date": "2024-06-01 07:17:38 UTC",
    "updated_date": "2024-06-01 07:17:38 UTC"
  },
  {
    "arxiv_id": "2406.06555v1",
    "title": "An Evaluation Benchmark for Autoformalization in Lean4",
    "authors": [
      "Aryan Gulati",
      "Devanshu Ladsaria",
      "Shubhra Mishra",
      "Jasdeep Sidhu",
      "Brando Miranda"
    ],
    "abstract": "Large Language Models (LLMs) hold the potential to revolutionize\nautoformalization. The introduction of Lean4, a mathematical programming\nlanguage, presents an unprecedented opportunity to rigorously assess the\nautoformalization capabilities of LLMs. This paper introduces a novel\nevaluation benchmark designed for Lean4, applying it to test the abilities of\nstate-of-the-art LLMs, including GPT-3.5, GPT-4, and Gemini Pro. Our\ncomprehensive analysis reveals that, despite recent advancements, these LLMs\nstill exhibit limitations in autoformalization, particularly in more complex\nareas of mathematics. These findings underscore the need for further\ndevelopment in LLMs to fully harness their potential in scientific research and\ndevelopment. This study not only benchmarks current LLM capabilities but also\nsets the stage for future enhancements in autoformalization.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.PL"
    ],
    "primary_category": "cs.LG",
    "comment": "To appear at ICLR 2024 as part of the Tiny Papers track",
    "pdf_url": "http://arxiv.org/pdf/2406.06555v1",
    "published_date": "2024-06-01 07:06:57 UTC",
    "updated_date": "2024-06-01 07:06:57 UTC"
  },
  {
    "arxiv_id": "2406.00324v2",
    "title": "Do's and Don'ts: Learning Desirable Skills with Instruction Videos",
    "authors": [
      "Hyunseung Kim",
      "Byungkun Lee",
      "Hojoon Lee",
      "Dongyoon Hwang",
      "Donghu Kim",
      "Jaegul Choo"
    ],
    "abstract": "Unsupervised skill discovery is a learning paradigm that aims to acquire\ndiverse behaviors without explicit rewards. However, it faces challenges in\nlearning complex behaviors and often leads to learning unsafe or undesirable\nbehaviors. For instance, in various continuous control tasks, current\nunsupervised skill discovery methods succeed in learning basic locomotions like\nstanding but struggle with learning more complex movements such as walking and\nrunning. Moreover, they may acquire unsafe behaviors like tripping and rolling\nor navigate to undesirable locations such as pitfalls or hazardous areas. In\nresponse, we present DoDont (Do's and Don'ts), an instruction-based skill\ndiscovery algorithm composed of two stages. First, in an instruction learning\nstage, DoDont leverages action-free instruction videos to train an instruction\nnetwork to distinguish desirable transitions from undesirable ones. Then, in\nthe skill learning stage, the instruction network adjusts the reward function\nof the skill discovery algorithm to weight the desired behaviors. Specifically,\nwe integrate the instruction network into a distance-maximizing skill discovery\nalgorithm, where the instruction network serves as the distance function.\nEmpirically, with less than 8 instruction videos, DoDont effectively learns\ndesirable behaviors and avoids undesirable ones across complex continuous\ncontrol tasks. Code and videos are available at\nhttps://mynsng.github.io/dodont/",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "published at NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.00324v2",
    "published_date": "2024-06-01 06:56:27 UTC",
    "updated_date": "2025-01-23 01:55:45 UTC"
  },
  {
    "arxiv_id": "2406.00314v3",
    "title": "CASE: Efficient Curricular Data Pre-training for Building Assistive Psychology Expert Models",
    "authors": [
      "Sarthak Harne",
      "Monjoy Narayan Choudhury",
      "Madhav Rao",
      "TK Srikanth",
      "Seema Mehrotra",
      "Apoorva Vashisht",
      "Aarushi Basu",
      "Manjit Sodhi"
    ],
    "abstract": "The limited availability of psychologists necessitates efficient\nidentification of individuals requiring urgent mental healthcare. This study\nexplores the use of Natural Language Processing (NLP) pipelines to analyze text\ndata from online mental health forums used for consultations. By analyzing\nforum posts, these pipelines can flag users who may require immediate\nprofessional attention. A crucial challenge in this domain is data privacy and\nscarcity. To address this, we propose utilizing readily available curricular\ntexts used in institutes specializing in mental health for pre-training the NLP\npipelines. This helps us mimic the training process of a psychologist. Our work\npresents CASE-BERT that flags potential mental health disorders based on forum\ntext. CASE-BERT demonstrates superior performance compared to existing methods,\nachieving an f1 score of 0.91 for Depression and 0.88 for Anxiety, two of the\nmost commonly reported mental health disorders. Our code and data are publicly\navailable.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.00314v3",
    "published_date": "2024-06-01 06:17:32 UTC",
    "updated_date": "2024-10-02 17:44:46 UTC"
  },
  {
    "arxiv_id": "2406.02596v2",
    "title": "Slow and Steady Wins the Race: Maintaining Plasticity with Hare and Tortoise Networks",
    "authors": [
      "Hojoon Lee",
      "Hyeonseo Cho",
      "Hyunseung Kim",
      "Donghu Kim",
      "Dugki Min",
      "Jaegul Choo",
      "Clare Lyle"
    ],
    "abstract": "This study investigates the loss of generalization ability in neural\nnetworks, revisiting warm-starting experiments from Ash & Adams. Our empirical\nanalysis reveals that common methods designed to enhance plasticity by\nmaintaining trainability provide limited benefits to generalization. While\nreinitializing the network can be effective, it also risks losing valuable\nprior knowledge. To this end, we introduce the Hare & Tortoise, inspired by the\nbrain's complementary learning system. Hare & Tortoise consists of two\ncomponents: the Hare network, which rapidly adapts to new information\nanalogously to the hippocampus, and the Tortoise network, which gradually\nintegrates knowledge akin to the neocortex. By periodically reinitializing the\nHare network to the Tortoise's weights, our method preserves plasticity while\nretaining general knowledge. Hare & Tortoise can effectively maintain the\nnetwork's ability to generalize, which improves advanced reinforcement learning\nalgorithms on the Atari-100k benchmark. The code is available at\nhttps://github.com/dojeon-ai/hare-tortoise.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "accepted to ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.02596v2",
    "published_date": "2024-06-01 05:55:15 UTC",
    "updated_date": "2025-02-04 09:13:43 UTC"
  },
  {
    "arxiv_id": "2406.00303v1",
    "title": "Multi-Dimensional Optimization for Text Summarization via Reinforcement Learning",
    "authors": [
      "Sangwon Ryu",
      "Heejin Do",
      "Yunsu Kim",
      "Gary Geunbae Lee",
      "Jungseul Ok"
    ],
    "abstract": "The evaluation of summary quality encompasses diverse dimensions such as\nconsistency, coherence, relevance, and fluency. However, existing summarization\nmethods often target a specific dimension, facing challenges in generating\nwell-balanced summaries across multiple dimensions. In this paper, we propose\nmulti-objective reinforcement learning tailored to generate balanced summaries\nacross all four dimensions. We introduce two multi-dimensional optimization\n(MDO) strategies for adaptive learning: 1) MDO_min, rewarding the current\nlowest dimension score, and 2) MDO_pro, optimizing multiple dimensions similar\nto multi-task learning, resolves conflicting gradients across dimensions\nthrough gradient projection. Unlike prior ROUGE-based rewards relying on\nreference summaries, we use a QA-based reward model that aligns with human\npreferences. Further, we discover the capability to regulate the length of\nsummaries by adjusting the discount factor, seeking the generation of concise\nyet informative summaries that encapsulate crucial points. Our approach\nachieved substantial performance gains compared to baseline models on\nrepresentative summarization datasets, particularly in the overlooked\ndimensions.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "ACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.00303v1",
    "published_date": "2024-06-01 05:15:12 UTC",
    "updated_date": "2024-06-01 05:15:12 UTC"
  },
  {
    "arxiv_id": "2406.10236v1",
    "title": "Lightening Anything in Medical Images",
    "authors": [
      "Ben Fei",
      "Yixuan Li",
      "Weidong Yang",
      "Hengjun Gao",
      "Jingyi Xu",
      "Lipeng Ma",
      "Yatian Yang",
      "Pinghong Zhou"
    ],
    "abstract": "The development of medical imaging techniques has made a significant\ncontribution to clinical decision-making. However, the existence of suboptimal\nimaging quality, as indicated by irregular illumination or imbalanced\nintensity, presents significant obstacles in automating disease screening,\nanalysis, and diagnosis. Existing approaches for natural image enhancement are\nmostly trained with numerous paired images, presenting challenges in data\ncollection and training costs, all while lacking the ability to generalize\neffectively. Here, we introduce a pioneering training-free Diffusion Model for\nUniversal Medical Image Enhancement, named UniMIE. UniMIE demonstrates its\nunsupervised enhancement capabilities across various medical image modalities\nwithout the need for any fine-tuning. It accomplishes this by relying solely on\na single pre-trained model from ImageNet. We conduct a comprehensive evaluation\non 13 imaging modalities and over 15 medical types, demonstrating better\nqualities, robustness, and accuracy than other modality-specific and\ndata-inefficient models. By delivering high-quality enhancement and\ncorresponding accuracy downstream tasks across a wide range of tasks, UniMIE\nexhibits considerable potential to accelerate the advancement of diagnostic\ntools and customized treatment plans.",
    "categories": [
      "eess.IV",
      "cs.AI"
    ],
    "primary_category": "eess.IV",
    "comment": "23 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.10236v1",
    "published_date": "2024-06-01 05:07:50 UTC",
    "updated_date": "2024-06-01 05:07:50 UTC"
  },
  {
    "arxiv_id": "2406.04371v2",
    "title": "Phased Instruction Fine-Tuning for Large Language Models",
    "authors": [
      "Wei Pang",
      "Chuan Zhou",
      "Xiao-Hua Zhou",
      "Xiaojie Wang"
    ],
    "abstract": "Instruction Fine-Tuning enhances pre-trained language models from basic\nnext-word prediction to complex instruction-following. However, existing\nOne-off Instruction Fine-Tuning (One-off IFT) method, applied on a diverse\ninstruction, may not effectively boost models' adherence to instructions due to\nthe simultaneous handling of varying instruction complexities. To improve this,\nPhased Instruction Fine-Tuning (Phased IFT) is proposed, based on the idea that\nlearning to follow instructions is a gradual process. It assesses instruction\ndifficulty using GPT-4, divides the instruction data into subsets of increasing\ndifficulty, and uptrains the model sequentially on these subsets. Experiments\nwith Llama-2 7B/13B/70B, Llama3 8/70B and Mistral-7B models using Alpaca data\nshow that Phased IFT significantly outperforms One-off IFT, supporting the\nprogressive alignment hypothesis and providing a simple and efficient way to\nenhance large language models. Codes and datasets from our experiments are\nfreely available at https://github.com/xubuvd/PhasedSFT.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "The final version, to be appear at ACL 2024 Findings",
    "pdf_url": "http://arxiv.org/pdf/2406.04371v2",
    "published_date": "2024-06-01 04:25:26 UTC",
    "updated_date": "2024-06-16 21:20:29 UTC"
  },
  {
    "arxiv_id": "2406.18565v1",
    "title": "Pseudo-label Based Domain Adaptation for Zero-Shot Text Steganalysis",
    "authors": [
      "Yufei Luo",
      "Zhen Yang",
      "Ru Zhang",
      "Jianyi Liu"
    ],
    "abstract": "Currently, most methods for text steganalysis are based on deep neural\nnetworks (DNNs). However, in real-life scenarios, obtaining a sufficient amount\nof labeled stego-text for correctly training networks using a large number of\nparameters is often challenging and costly. Additionally, due to a phenomenon\nknown as dataset bias or domain shift, recognition models trained on a large\ndataset exhibit poor generalization performance on novel datasets and tasks.\nTherefore, to address the issues of missing labeled data and inadequate model\ngeneralization in text steganalysis, this paper proposes a cross-domain\nstego-text analysis method (PDTS) based on pseudo-labeling and domain\nadaptation (unsupervised learning). Specifically, we propose a model\narchitecture combining pre-trained BERT with a single-layer Bi-LSTM to learn\nand extract generic features across tasks and generate task-specific\nrepresentations. Considering the differential contributions of different\nfeatures to steganalysis, we further design a feature filtering mechanism to\nachieve selective feature propagation, thereby enhancing classification\nperformance. We train the model using labeled source domain data and adapt it\nto target domain data distribution using pseudo-labels for unlabeled target\ndomain data through self-training. In the label estimation step, instead of\nusing a static sampling strategy, we propose a progressive sampling strategy to\ngradually increase the number of selected pseudo-label candidates. Experimental\nresults demonstrate that our method performs well in zero-shot text\nsteganalysis tasks, achieving high detection accuracy even in the absence of\nlabeled data in the target domain, and outperforms current zero-shot text\nsteganalysis methods.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "The 30th International Conference on Computational & Experimental\n  Engineering and Sciences (ICCES2024)",
    "pdf_url": "http://arxiv.org/pdf/2406.18565v1",
    "published_date": "2024-06-01 04:19:07 UTC",
    "updated_date": "2024-06-01 04:19:07 UTC"
  },
  {
    "arxiv_id": "2406.00291v2",
    "title": "Multi-Objective Neural Architecture Search by Learning Search Space Partitions",
    "authors": [
      "Yiyang Zhao",
      "Linnan Wang",
      "Tian Guo"
    ],
    "abstract": "Deploying deep learning models requires taking into consideration neural\nnetwork metrics such as model size, inference latency, and #FLOPs, aside from\ninference accuracy. This results in deep learning model designers leveraging\nmulti-objective optimization to design effective deep neural networks in\nmultiple criteria. However, applying multi-objective optimizations to neural\narchitecture search (NAS) is nontrivial because NAS tasks usually have a huge\nsearch space, along with a non-negligible searching cost. This requires\neffective multi-objective search algorithms to alleviate the GPU costs. In this\nwork, we implement a novel multi-objectives optimizer based on a recently\nproposed meta-algorithm called LaMOO on NAS tasks. In a nutshell, LaMOO\nspeedups the search process by learning a model from observed samples to\npartition the search space and then focusing on promising regions likely to\ncontain a subset of the Pareto frontier. Using LaMOO, we observe an improvement\nof more than 200% sample efficiency compared to Bayesian optimization and\nevolutionary-based multi-objective optimizers on different NAS datasets. For\nexample, when combined with LaMOO, qEHVI achieves a 225% improvement in sample\nefficiency compared to using qEHVI alone in NasBench201. For real-world tasks,\nLaMOO achieves 97.36% accuracy with only 1.62M #Params on CIFAR10 in only 600\nsearch samples. On ImageNet, our large model reaches 80.4% top-1 accuracy with\nonly 522M #FLOPs.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.00291v2",
    "published_date": "2024-06-01 03:51:34 UTC",
    "updated_date": "2024-07-18 01:53:35 UTC"
  },
  {
    "arxiv_id": "2406.00287v1",
    "title": "GenPalm: Contactless Palmprint Generation with Diffusion Models",
    "authors": [
      "Steven A. Grosz",
      "Anil K. Jain"
    ],
    "abstract": "The scarcity of large-scale palmprint databases poses a significant\nbottleneck to advancements in contactless palmprint recognition. To address\nthis, researchers have turned to synthetic data generation. While Generative\nAdversarial Networks (GANs) have been widely used, they suffer from instability\nand mode collapse. Recently, diffusion probabilistic models have emerged as a\npromising alternative, offering stable training and better distribution\ncoverage. This paper introduces a novel palmprint generation method using\ndiffusion probabilistic models, develops an end-to-end framework for\nsynthesizing multiple palm identities, and validates the realism and utility of\nthe generated palmprints. Experimental results demonstrate the effectiveness of\nour approach in generating palmprint images which enhance contactless palmprint\nrecognition performance across several test databases utilizing challenging\ncross-database and time-separated evaluation protocols.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.00287v1",
    "published_date": "2024-06-01 03:33:25 UTC",
    "updated_date": "2024-06-01 03:33:25 UTC"
  },
  {
    "arxiv_id": "2406.00281v1",
    "title": "Cross-Table Pretraining towards a Universal Function Space for Heterogeneous Tabular Data",
    "authors": [
      "Jintai Chen",
      "Zhen Lin",
      "Qiyuan Chen",
      "Jimeng Sun"
    ],
    "abstract": "Tabular data from different tables exhibit significant diversity due to\nvaried definitions and types of features, as well as complex inter-feature and\nfeature-target relationships. Cross-dataset pretraining, which learns reusable\npatterns from upstream data to support downstream tasks, have shown notable\nsuccess in various fields. Yet, when applied to tabular data prediction, this\nparadigm faces challenges due to the limited reusable patterns among diverse\ntabular datasets (tables) and the general scarcity of tabular data available\nfor fine-tuning. In this study, we fill this gap by introducing a cross-table\npretrained Transformer, XTFormer, for versatile downstream tabular prediction\ntasks. Our methodology insight is pretraining XTFormer to establish a\n\"meta-function\" space that encompasses all potential feature-target mappings.\nIn pre-training, a variety of potential mappings are extracted from\npre-training tabular datasets and are embedded into the \"meta-function\" space,\nand suited mappings are extracted from the \"meta-function\" space for downstream\ntasks by a specified coordinate positioning approach. Experiments show that, in\n190 downstream tabular prediction tasks, our cross-table pretrained XTFormer\nwins both XGBoost and Catboost on 137 (72%) tasks, and surpasses representative\ndeep learning models FT-Transformer and the tabular pre-training approach XTab\non 144 (76%) and 162 (85%) tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.00281v1",
    "published_date": "2024-06-01 03:24:31 UTC",
    "updated_date": "2024-06-01 03:24:31 UTC"
  },
  {
    "arxiv_id": "2406.02594v1",
    "title": "Graph Neural Networks for Brain Graph Learning: A Survey",
    "authors": [
      "Xuexiong Luo",
      "Jia Wu",
      "Jian Yang",
      "Shan Xue",
      "Amin Beheshti",
      "Quan Z. Sheng",
      "David McAlpine",
      "Paul Sowman",
      "Alexis Giral",
      "Philip S. Yu"
    ],
    "abstract": "Exploring the complex structure of the human brain is crucial for\nunderstanding its functionality and diagnosing brain disorders. Thanks to\nadvancements in neuroimaging technology, a novel approach has emerged that\ninvolves modeling the human brain as a graph-structured pattern, with different\nbrain regions represented as nodes and the functional relationships among these\nregions as edges. Moreover, graph neural networks (GNNs) have demonstrated a\nsignificant advantage in mining graph-structured data. Developing GNNs to learn\nbrain graph representations for brain disorder analysis has recently gained\nincreasing attention. However, there is a lack of systematic survey work\nsummarizing current research methods in this domain. In this paper, we aim to\nbridge this gap by reviewing brain graph learning works that utilize GNNs. We\nfirst introduce the process of brain graph modeling based on common\nneuroimaging data. Subsequently, we systematically categorize current works\nbased on the type of brain graph generated and the targeted research problems.\nTo make this research accessible to a broader range of interested researchers,\nwe provide an overview of representative methods and commonly used datasets,\nalong with their implementation sources. Finally, we present our insights on\nfuture research directions. The repository of this survey is available at\n\\url{https://github.com/XuexiongLuoMQ/Awesome-Brain-Graph-Learning-with-GNNs}.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "68T07 (Primary) 68T30 (Secondary)"
    ],
    "primary_category": "cs.LG",
    "comment": "9 pages, 2 figures, IJCAI-2024",
    "pdf_url": "http://arxiv.org/pdf/2406.02594v1",
    "published_date": "2024-06-01 02:47:39 UTC",
    "updated_date": "2024-06-01 02:47:39 UTC"
  },
  {
    "arxiv_id": "2406.00276v1",
    "title": "Non-destructive Degradation Pattern Decoupling for Ultra-early Battery Prototype Verification Using Physics-informed Machine Learning",
    "authors": [
      "Shengyu Tao",
      "Mengtian Zhang",
      "Zixi Zhao",
      "Haoyang Li",
      "Ruifei Ma",
      "Yunhong Che",
      "Xin Sun",
      "Lin Su",
      "Xiangyu Chen",
      "Zihao Zhou",
      "Heng Chang",
      "Tingwei Cao",
      "Xiao Xiao",
      "Yaojun Liu",
      "Wenjun Yu",
      "Zhongling Xu",
      "Yang Li",
      "Han Hao",
      "Xuan Zhang",
      "Xiaosong Hu",
      "Guangmin ZHou"
    ],
    "abstract": "Manufacturing complexities and uncertainties have impeded the transition from\nmaterial prototypes to commercial batteries, making prototype verification\ncritical to quality assessment. A fundamental challenge involves deciphering\nintertwined chemical processes to characterize degradation patterns and their\nquantitative relationship with battery performance. Here we show that a\nphysics-informed machine learning approach can quantify and visualize\ntemporally resolved losses concerning thermodynamics and kinetics only using\nelectric signals. Our method enables non-destructive degradation pattern\ncharacterization, expediting temperature-adaptable predictions of entire\nlifetime trajectories, rather than end-of-life points. The verification speed\nis 25 times faster yet maintaining 95.1% accuracy across temperatures. Such\nadvances facilitate more sustainable management of defective prototypes before\nmassive production, establishing a 19.76 billion USD scrap material recycling\nmarket by 2060 in China. By incorporating stepwise charge acceptance as a\nmeasure of the initial manufacturing variability of normally identical\nbatteries, we can immediately identify long-term degradation variations. We\nattribute the predictive power to interpreting machine learning insights using\nmaterial-agnostic featurization taxonomy for degradation pattern decoupling.\nOur findings offer new possibilities for dynamic system analysis, such as\nbattery prototype degradation, demonstrating that complex pattern evolutions\ncan be accurately predicted in a non-destructive and data-driven fashion by\nintegrating physics-informed machine learning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CE",
      "physics.data-an",
      "J.2; G.3"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.00276v1",
    "published_date": "2024-06-01 02:43:41 UTC",
    "updated_date": "2024-06-01 02:43:41 UTC"
  },
  {
    "arxiv_id": "2406.04370v3",
    "title": "Large Language Model Confidence Estimation via Black-Box Access",
    "authors": [
      "Tejaswini Pedapati",
      "Amit Dhurandhar",
      "Soumya Ghosh",
      "Soham Dan",
      "Prasanna Sattigeri"
    ],
    "abstract": "Estimating uncertainty or confidence in the responses of a model can be\nsignificant in evaluating trust not only in the responses, but also in the\nmodel as a whole. In this paper, we explore the problem of estimating\nconfidence for responses of large language models (LLMs) with simply black-box\nor query access to them. We propose a simple and extensible framework where, we\nengineer novel features and train a (interpretable) model (viz. logistic\nregression) on these features to estimate the confidence. We empirically\ndemonstrate that our simple framework is effective in estimating confidence of\nFlan-ul2, Llama-13b, Mistral-7b and GPT-4 on four benchmark Q\\&A tasks as well\nas of Pegasus-large and BART-large on two benchmark summarization tasks with it\nsurpassing baselines by even over $10\\%$ (on AUROC) in some cases.\nAdditionally, our interpretable approach provides insight into features that\nare predictive of confidence, leading to the interesting and useful discovery\nthat our confidence models built for one LLM generalize zero-shot across others\non a given dataset.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.04370v3",
    "published_date": "2024-06-01 02:08:44 UTC",
    "updated_date": "2025-02-20 18:42:41 UTC"
  },
  {
    "arxiv_id": "2406.00262v2",
    "title": "Contrastive Learning Via Equivariant Representation",
    "authors": [
      "Sifan Song",
      "Jinfeng Wang",
      "Qiaochu Zhao",
      "Xiang Li",
      "Dufan Wu",
      "Angelos Stefanidis",
      "Jionglong Su",
      "S. Kevin Zhou",
      "Quanzheng Li"
    ],
    "abstract": "Invariant Contrastive Learning (ICL) methods have achieved impressive\nperformance across various domains. However, the absence of latent space\nrepresentation for distortion (augmentation)-related information in the latent\nspace makes ICL sub-optimal regarding training efficiency and robustness in\ndownstream tasks. Recent studies suggest that introducing equivariance into\nContrastive Learning (CL) can improve overall performance. In this paper, we\nrevisit the roles of augmentation strategies and equivariance in improving CL's\nefficacy. We propose CLeVER (Contrastive Learning Via Equivariant\nRepresentation), a novel equivariant contrastive learning framework compatible\nwith augmentation strategies of arbitrary complexity for various mainstream CL\nbackbone models. Experimental results demonstrate that CLeVER effectively\nextracts and incorporates equivariant information from practical natural\nimages, thereby improving the training efficiency and robustness of baseline\nmodels in downstream tasks and achieving state-of-the-art (SOTA) performance.\nMoreover, we find that leveraging equivariant information extracted by CLeVER\nsimultaneously enhances rotational invariance and sensitivity across\nexperimental tasks, and helps stabilize the framework when handling complex\naugmentations, particularly for models with small-scale backbones.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Preprint. Under review",
    "pdf_url": "http://arxiv.org/pdf/2406.00262v2",
    "published_date": "2024-06-01 01:53:51 UTC",
    "updated_date": "2024-10-10 15:49:44 UTC"
  },
  {
    "arxiv_id": "2406.00258v1",
    "title": "Artemis: Towards Referential Understanding in Complex Videos",
    "authors": [
      "Jihao Qiu",
      "Yuan Zhang",
      "Xi Tang",
      "Lingxi Xie",
      "Tianren Ma",
      "Pengyu Yan",
      "David Doermann",
      "Qixiang Ye",
      "Yunjie Tian"
    ],
    "abstract": "Videos carry rich visual information including object description, action,\ninteraction, etc., but the existing multimodal large language models (MLLMs)\nfell short in referential understanding scenarios such as video-based\nreferring. In this paper, we present Artemis, an MLLM that pushes video-based\nreferential understanding to a finer level. Given a video, Artemis receives a\nnatural-language question with a bounding box in any video frame and describes\nthe referred target in the entire video. The key to achieving this goal lies in\nextracting compact, target-specific video features, where we set a solid\nbaseline by tracking and selecting spatiotemporal features from the video. We\ntrain Artemis on the newly established VideoRef45K dataset with 45K video-QA\npairs and design a computationally efficient, three-stage training procedure.\nResults are promising both quantitatively and qualitatively. Additionally, we\nshow that \\model can be integrated with video grounding and text summarization\ntools to understand more complex scenarios. Code and data are available at\nhttps://github.com/qiujihao19/Artemis.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "19 pages, 14 figures. Code and data are available at\n  https://github.com/qiujihao19/Artemis",
    "pdf_url": "http://arxiv.org/pdf/2406.00258v1",
    "published_date": "2024-06-01 01:43:56 UTC",
    "updated_date": "2024-06-01 01:43:56 UTC"
  },
  {
    "arxiv_id": "2406.00252v6",
    "title": "Towards Rationality in Language and Multimodal Agents: A Survey",
    "authors": [
      "Bowen Jiang",
      "Yangxinyu Xie",
      "Xiaomeng Wang",
      "Yuan Yuan",
      "Zhuoqun Hao",
      "Xinyi Bai",
      "Weijie J. Su",
      "Camillo J. Taylor",
      "Tanwi Mallick"
    ],
    "abstract": "This work discusses how to build more rational language and multimodal agents\nand what criteria define rationality in intelligent systems. Rationality is the\nquality of being guided by reason, characterized by decision-making that aligns\nwith evidence and logical principles. It plays a crucial role in reliable\nproblem-solving by ensuring well-grounded and consistent solutions. Despite\ntheir progress, large language models (LLMs) often fall short of rationality\ndue to their bounded knowledge space and inconsistent outputs. In response,\nrecent efforts have shifted toward developing multimodal and multi-agent\nsystems, as well as integrating modules like external tools, programming codes,\nsymbolic reasoners, utility function, and conformal risk controls rather than\nrelying solely on a single LLM for decision-making. This paper surveys\nstate-of-the-art advancements in language and multimodal agents, assesses their\nrole in enhancing rationality, and outlines open challenges and future research\ndirections. We maintain an open repository at\nhttps://github.com/bowen-upenn/Agent_Rationality.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "This paper has been accepted to the NAACL 2025 Main",
    "pdf_url": "http://arxiv.org/pdf/2406.00252v6",
    "published_date": "2024-06-01 01:17:25 UTC",
    "updated_date": "2025-02-16 05:30:30 UTC"
  },
  {
    "arxiv_id": "2406.00247v2",
    "title": "Large Language Models for Relevance Judgment in Product Search",
    "authors": [
      "Navid Mehrdad",
      "Hrushikesh Mohapatra",
      "Mossaab Bagdouri",
      "Prijith Chandran",
      "Alessandro Magnani",
      "Xunfan Cai",
      "Ajit Puthenputhussery",
      "Sachin Yadav",
      "Tony Lee",
      "ChengXiang Zhai",
      "Ciya Liao"
    ],
    "abstract": "High relevance of retrieved and re-ranked items to the search query is the\ncornerstone of successful product search, yet measuring relevance of items to\nqueries is one of the most challenging tasks in product information retrieval,\nand quality of product search is highly influenced by the precision and scale\nof available relevance-labelled data. In this paper, we present an array of\ntechniques for leveraging Large Language Models (LLMs) for automating the\nrelevance judgment of query-item pairs (QIPs) at scale. Using a unique dataset\nof multi-million QIPs, annotated by human evaluators, we test and optimize\nhyper parameters for finetuning billion-parameter LLMs with and without Low\nRank Adaption (LoRA), as well as various modes of item attribute concatenation\nand prompting in LLM finetuning, and consider trade offs in item attribute\ninclusion for quality of relevance predictions. We demonstrate considerable\nimprovement over baselines of prior generations of LLMs, as well as\noff-the-shelf models, towards relevance annotations on par with the human\nrelevance evaluators. Our findings have immediate implications for the growing\nfield of relevance judgment automation in product search.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "H.3.3; I.2.7"
    ],
    "primary_category": "cs.IR",
    "comment": "10 pages, 1 figure, 11 tables - SIGIR 2024, LLM4Eval",
    "pdf_url": "http://arxiv.org/pdf/2406.00247v2",
    "published_date": "2024-06-01 00:52:41 UTC",
    "updated_date": "2024-07-16 18:01:55 UTC"
  },
  {
    "arxiv_id": "2406.01624v2",
    "title": "Unveiling Hidden Factors: Explainable AI for Feature Boosting in Speech Emotion Recognition",
    "authors": [
      "Alaa Nfissi",
      "Wassim Bouachir",
      "Nizar Bouguila",
      "Brian Mishara"
    ],
    "abstract": "Speech emotion recognition (SER) has gained significant attention due to its\nseveral application fields, such as mental health, education, and\nhuman-computer interaction. However, the accuracy of SER systems is hindered by\nhigh-dimensional feature sets that may contain irrelevant and redundant\ninformation. To overcome this challenge, this study proposes an iterative\nfeature boosting approach for SER that emphasizes feature relevance and\nexplainability to enhance machine learning model performance. Our approach\ninvolves meticulous feature selection and analysis to build efficient SER\nsystems. In addressing our main problem through model explainability, we employ\na feature evaluation loop with Shapley values to iteratively refine feature\nsets. This process strikes a balance between model performance and\ntransparency, which enables a comprehensive understanding of the model's\npredictions. The proposed approach offers several advantages, including the\nidentification and removal of irrelevant and redundant features, leading to a\nmore effective model. Additionally, it promotes explainability, facilitating\ncomprehension of the model's predictions and the identification of crucial\nfeatures for emotion determination. The effectiveness of the proposed method is\nvalidated on the SER benchmarks of the Toronto emotional speech set (TESS),\nBerlin Database of Emotional Speech (EMO-DB), Ryerson Audio-Visual Database of\nEmotional Speech and Song (RAVDESS), and Surrey Audio-Visual Expressed Emotion\n(SAVEE) datasets, outperforming state-of-the-art methods. To the best of our\nknowledge, this is the first work to incorporate model explainability into an\nSER framework. The source code of this paper is publicly available via this\nhttps://github.com/alaaNfissi/Unveiling-Hidden-Factors-Explainable-AI-for-Feature-Boosting-in-Speech-Emotion-Recognition.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.SD",
      "I.2.7; I.2.6; I.2.1; I.2.8"
    ],
    "primary_category": "eess.AS",
    "comment": "Published in: Springer Nature International Journal of Applied\n  Intelligence (2024)",
    "pdf_url": "http://arxiv.org/pdf/2406.01624v2",
    "published_date": "2024-06-01 00:39:55 UTC",
    "updated_date": "2024-06-05 22:21:55 UTC"
  },
  {
    "arxiv_id": "2406.01623v1",
    "title": "WebSuite: Systematically Evaluating Why Web Agents Fail",
    "authors": [
      "Eric Li",
      "Jim Waldo"
    ],
    "abstract": "We describe WebSuite, the first diagnostic benchmark for generalist web\nagents, designed to systematically evaluate why agents fail. Advances in AI\nhave led to the rise of numerous web agents that autonomously operate a browser\nto complete tasks. However, most existing benchmarks focus on strictly\nmeasuring whether an agent can or cannot complete a task, without giving\ninsight on why. In this paper, we 1) develop a taxonomy of web actions to\nfacilitate identifying common failure patterns, and 2) create an extensible\nbenchmark suite to assess agents' performance on our taxonomized actions. This\nbenchmark suite consists of both individual tasks, such as clicking a button,\nand end-to-end tasks, such as adding an item to a cart, and is designed such\nthat any failure of a task can be attributed directly to a failure of a\nspecific web action. We evaluate two popular generalist web agents, one\ntext-based and one multimodal, and identify unique weaknesses for each agent.\nBecause WebSuite can disaggregate task failures into specific action failures,\nthis enables granular identification of which UX flows an individual agent has\ntrouble with and immediately highlights promising avenues for improvement.\nThese findings highlight the need for more focused benchmarking on where web\nagents go wrong to effectively improve agents beyond their weaker performance\ntoday.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.01623v1",
    "published_date": "2024-06-01 00:32:26 UTC",
    "updated_date": "2024-06-01 00:32:26 UTC"
  }
]