{
  "date": "2024-03-24",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-03-24 的 arXiv 中文 TLDR 快报！今天 arXiv 更新了 50 篇论文，主要聚焦 AI、机器学习、计算机视觉和生物医学等领域，其中令人印象深刻的是关于大型语言模型（LLM）在生物医学应用的综述，以及创新的图神经网络和 Transformer 模型；重点包括跨领域知识整合、鲁棒性提升和实际应用潜力，如 LLMs 在医疗决策支持和视频理解中的表现。\n\n### 重点论文讨论\n我们先聊聊那些重要、话题度和影响大的论文，再快速掠过其他次要内容。相关论文按主题归类，先从 AI 和机器学习的核心创新入手，然后聊医疗应用，最后简要提及其他领域。\n\n**AI 和机器学习领域的创新（高话题度）**  \n- **Large Language Models in Biomedical and Health Informatics: A Review with Bibliometric Analysis**（大型语言模型在生物医学和健康信息学中的应用：综述与文献计量分析）  \n  这篇论文由多位作者（如 Huizi Yu 和 Yongfeng Zhang）合作撰写，对 1698 篇文献进行分析，强调 LLMs 在临床决策支持、患者互动和医疗文档分析中的潜力。主要贡献是揭示 LLMs 在个性化医学和公共健康策略中的作用，并讨论了伦理挑战和模型验证问题。该综述可能推动 AI 在医疗领域的应用，值得关注学者跟进。\n\n- **Empowering LLMs with Pseudo-Untrimmed Videos for Audio-Visual Temporal Understanding**（使用伪非剪辑视频增强 LLMs 的音频-视觉时间理解）  \n  作者如 Yunlong Tang 和 Chenliang Xu 提出 PU-VALOR 数据集和 AVicuna 模型，通过微调 LLMs 处理音频-视觉事件的时间定位。主要发现是模型在视频问答和事件密集定位任务上达到 state-of-the-art 性能，展示了 LLMs 在多模态领域的鲁棒性扩展潜力。\n\n- **Out-of-Distribution Detection via Deep Multi-Comprehension Ensemble**（基于深度多理解集成的方法检测分布外数据）  \n  这篇 ICML 2024 论文引入 Multi-Comprehension Ensemble 方法，通过多样化训练任务扩展特征表示空间。主要贡献是提升 OOD 检测性能，实验显示比传统集成方法准确率高，适用于鲁棒 AI 系统。\n\n- **Transformer-based Joint Modelling for Automatic Essay Scoring and Off-Topic Detection**（基于 Transformer 的联合模型用于自动作文评分和离题检测）  \n  作者 Sourya Dipta Das 等提出 AOES 模型，使用主题正则化模块和混合损失函数检测离题作文。主要发现是模型在作文评分和离题检测上超越基线，并对对抗性策略表现出鲁棒性，适用于教育 AI。\n\n这些论文共同突出了 Transformer 和集成模型在处理不确定性和多模态数据时的优势，相关工作（如 LLMs 的应用）可能激发更多跨领域研究。\n\n**医疗和生物相关应用（实际影响强）**  \n- **L-MAE: Longitudinal masked auto-encoder with time and severity-aware encoding for diabetic retinopathy progression prediction**（纵向掩码自编码器：用于糖尿病视网膜病变进展预测的时间和严重度感知编码）  \n  作者如 Rachid Zeghlache 开发了基于 Transformer 的 L-MAE 模型，引入时间感知位置嵌入和基于疾病进展的掩码策略。主要贡献是通过 OPHDIAT 数据集预测视网膜病变进展，显著提升分类模型的预测准确性，展示了自监督学习在医疗图像分析中的潜力。\n\n- **Interpretable Modeling of Deep Reinforcement Learning Driven Scheduling**（可解释的深度强化学习驱动调度建模）  \n  作者 Boyang Li 等提出 IRL 框架，使用模仿学习将 DNN 策略转化为决策树模型。主要发现是保持调度性能的同时提升可解释性，适用于高性能计算场景。\n\n其他医疗论文如 **Guessing human intentions to avoid dangerous situations in caregiving robots**（猜测人类意图以避免危险情况的护理机器人），快速提一下：它使用 Artificial Theory of Mind 算法实时检测风险，实验证明在模拟环境中鲁棒性强，但实际应用需进一步验证。\n\n**其他领域快速掠过**  \n对于剩余论文，我们只挑核心点简述，以节省篇幅。  \n- **An Analytic Solution to Covariance Propagation in Neural Networks**（神经网络中协方差传播的解析解）  \n  AISTATS 2024 论文，提供样本无关的矩传播技术，分析激活函数对不确定性的影响，提升了神经网络的鲁棒性。\n\n- **Engineering Safety Requirements for Autonomous Driving with Large Language Models**（使用大型语言模型工程化自动驾驶的安全需求）  \n  作者如 Christian Berger 构建 LLMs 管道自动优化安全需求，主要发现是提升了需求集的冗余检测和分解效率。\n\n其他如 **Image Captioning in news report scenario**（新闻报告场景中的图像字幕生成），贡献在于针对名人图像的字幕模型，但影响力有限；**Rumor Detection with a novel graph neural network approach**（使用新型图神经网络的谣言检测），提出用户相关性建模，但实验仅限于社交媒体。剩下的论文（如 Python 框架或图分类方法）基本是工具性或方法改进，细节较琐碎，不做深入讨论。\n\n总之，今天的 arXiv 更新强调了 AI 模型的鲁棒性和实际应用潜力，LLMs 在生物医学和多模态领域的进展尤其值得追踪。感兴趣的读者可查阅这些论文的摘要深入了解！",
  "papers": [
    {
      "arxiv_id": "2403.16327v1",
      "title": "Artificial Neural Microcircuits as Building Blocks: Concept and Challenges",
      "title_zh": "翻译失败",
      "authors": [
        "Andrew Walter",
        "Shimeng Wu",
        "Andy M. Tyrrell",
        "Liam McDaid",
        "Malachy McElholm",
        "Nidhin Thandassery Sumithran",
        "Jim Harkin",
        "Martin A. Trefzer"
      ],
      "abstract": "Artificial Neural Networks (ANNs) are one of the most widely employed forms\nof bio-inspired computation. However the current trend is for ANNs to be\nstructurally homogeneous. Furthermore, this structural homogeneity requires the\napplication of complex training and learning tools that produce application\nspecific ANNs, susceptible to pitfalls such as overfitting. In this paper, an\nnew approach is explored, inspired by the role played in biology by Neural\nMicrocircuits, the so called ``fundamental processing elements'' of organic\nnervous systems. How large neural networks, particularly Spiking Neural\nNetworks (SNNs) can be assembled using Artificial Neural Microcircuits (ANMs),\nintended as off-the-shelf components, is articulated; the results of initial\nwork to produce a catalogue of such Microcircuits though the use of Novelty\nSearch is shown; followed by efforts to expand upon this initial work,\nincluding a discussion of challenges uncovered during these efforts and\nexplorations of methods by which they might be overcome.",
      "tldr_zh": "该论文探讨了受生物神经微回路（Neural Microcircuits）启发的创新方法，将Artificial Neural Microcircuits (ANMs)视为现成组件，用于构建大型Artificial Neural Networks (ANNs)，特别是Spiking Neural Networks (SNNs)，以克服当前ANNs结构同质化和训练复杂性导致的问题如过拟合。作者通过Novelty Search技术创建了ANMs的初步目录，展示了如何组装这些微回路以实现更高效的网络构建。论文还讨论了这一方法面临的挑战，包括扩展性和优化策略，并探索了潜在的解决方案。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NE",
      "comment": "12 pages, 31 figures, 3 tables, submitted to A-Life Journal for\n  review",
      "pdf_url": "http://arxiv.org/pdf/2403.16327v1",
      "published_date": "2024-03-24 23:22:02 UTC",
      "updated_date": "2024-03-24 23:22:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:18:47.502708"
    },
    {
      "arxiv_id": "2404.08655v1",
      "title": "Transformer-based Joint Modelling for Automatic Essay Scoring and Off-Topic Detection",
      "title_zh": "基于 Transformer 的自动作文评分和离题检测联合建模",
      "authors": [
        "Sourya Dipta Das",
        "Yash Vadi",
        "Kuldeep Yadav"
      ],
      "abstract": "Automated Essay Scoring (AES) systems are widely popular in the market as\nthey constitute a cost-effective and time-effective option for grading systems.\nNevertheless, many studies have demonstrated that the AES system fails to\nassign lower grades to irrelevant responses. Thus, detecting the off-topic\nresponse in automated essay scoring is crucial in practical tasks where\ncandidates write unrelated text responses to the given task in the question. In\nthis paper, we are proposing an unsupervised technique that jointly scores\nessays and detects off-topic essays. The proposed Automated Open Essay Scoring\n(AOES) model uses a novel topic regularization module (TRM), which can be\nattached on top of a transformer model, and is trained using a proposed hybrid\nloss function. After training, the AOES model is further used to calculate the\nMahalanobis distance score for off-topic essay detection. Our proposed method\noutperforms the baseline we created and earlier conventional methods on two\nessay-scoring datasets in off-topic detection as well as on-topic scoring.\nExperimental evaluation results on different adversarial strategies also show\nhow the suggested method is robust for detecting possible human-level\nperturbations.",
      "tldr_zh": "这篇论文提出了一种基于 Transformer 的联合模型，用于 Automated Essay Scoring (AES) 和 off-topic 检测，以解决 AES 系统无法有效处理无关响应的难题。模型名为 Automated Open Essay Scoring (AOES)，它整合了一个 novel topic regularization module (TRM) 并使用 hybrid loss function 进行训练，随后通过 Mahalanobis distance score 计算来识别 off-topic 作文。实验结果显示，该方法在两个作文评分数据集上优于基线和传统方法，并在不同 adversarial strategies 下表现出对人类级扰动的鲁棒性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted in LREC-COLING 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.08655v1",
      "published_date": "2024-03-24 21:44:14 UTC",
      "updated_date": "2024-03-24 21:44:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:18:58.417247"
    },
    {
      "arxiv_id": "2403.16303v4",
      "title": "Large Language Models in Biomedical and Health Informatics: A Review with Bibliometric Analysis",
      "title_zh": "大语言模型在生物医学和健康信息学中的应用：一项计量分析综述",
      "authors": [
        "Huizi Yu",
        "Lizhou Fan",
        "Lingyao Li",
        "Jiayan Zhou",
        "Zihui Ma",
        "Lu Xian",
        "Wenyue Hua",
        "Sijia He",
        "Mingyu Jin",
        "Yongfeng Zhang",
        "Ashvin Gandhi",
        "Xin Ma"
      ],
      "abstract": "Large Language Models (LLMs) have rapidly become important tools in\nBiomedical and Health Informatics (BHI), enabling new ways to analyze data,\ntreat patients, and conduct research. This study aims to provide a\ncomprehensive overview of LLM applications in BHI, highlighting their\ntransformative potential and addressing the associated ethical and practical\nchallenges. We reviewed 1,698 research articles from January 2022 to December\n2023, categorizing them by research themes and diagnostic categories.\nAdditionally, we conducted network analysis to map scholarly collaborations and\nresearch dynamics. Our findings reveal a substantial increase in the potential\napplications of LLMs to a variety of BHI tasks, including clinical decision\nsupport, patient interaction, and medical document analysis. Notably, LLMs are\nexpected to be instrumental in enhancing the accuracy of diagnostic tools and\npatient care protocols. The network analysis highlights dense and dynamically\nevolving collaborations across institutions, underscoring the interdisciplinary\nnature of LLM research in BHI. A significant trend was the application of LLMs\nin managing specific disease categories such as mental health and neurological\ndisorders, demonstrating their potential to influence personalized medicine and\npublic health strategies. LLMs hold promising potential to further transform\nbiomedical research and healthcare delivery. While promising, the ethical\nimplications and challenges of model validation call for rigorous scrutiny to\noptimize their benefits in clinical settings. This survey serves as a resource\nfor stakeholders in healthcare, including researchers, clinicians, and\npolicymakers, to understand the current state and future potential of LLMs in\nBHI.",
      "tldr_zh": "这篇综述回顾了Large Language Models (LLMs) 在Biomedical and Health Informatics (BHI) 中的应用，通过分析2022年1月至2023年12月的1,698篇研究文章，并结合bibliometric analysis进行分类和网络分析。研究发现，LLMs 在临床决策支持、患者互动和医疗文档分析等领域表现出巨大潜力，能提升诊断工具的准确性和患者护理协议，尤其在精神健康和神经系统疾病的个性化医学中发挥关键作用。网络分析揭示了机构间的密集跨学科合作，但也强调了LLMs 的伦理挑战和模型验证问题，为研究人员、临床医生和政策制定者提供宝贵资源，以推动BHI 的未来发展。",
      "categories": [
        "cs.DL",
        "cs.AI",
        "cs.CL",
        "cs.SI"
      ],
      "primary_category": "cs.DL",
      "comment": "62 pages, 9 figures, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2403.16303v4",
      "published_date": "2024-03-24 21:29:39 UTC",
      "updated_date": "2024-07-28 03:24:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:19:11.912581"
    },
    {
      "arxiv_id": "2403.16293v1",
      "title": "Interpretable Modeling of Deep Reinforcement Learning Driven Scheduling",
      "title_zh": "可解释的深度强化学习驱动调度建模",
      "authors": [
        "Boyang Li",
        "Zhiling Lan",
        "Michael E. Papka"
      ],
      "abstract": "In the field of high-performance computing (HPC), there has been recent\nexploration into the use of deep reinforcement learning for cluster scheduling\n(DRL scheduling), which has demonstrated promising outcomes. However, a\nsignificant challenge arises from the lack of interpretability in deep neural\nnetworks (DNN), rendering them as black-box models to system managers. This\nlack of model interpretability hinders the practical deployment of DRL\nscheduling. In this work, we present a framework called IRL (Interpretable\nReinforcement Learning) to address the issue of interpretability of DRL\nscheduling. The core idea is to interpret DNN (i.e., the DRL policy) as a\ndecision tree by utilizing imitation learning. Unlike DNN, decision tree models\nare non-parametric and easily comprehensible to humans. To extract an effective\nand efficient decision tree, IRL incorporates the Dataset Aggregation (DAgger)\nalgorithm and introduces the notion of critical state to prune the derived\ndecision tree. Through trace-based experiments, we demonstrate that IRL is\ncapable of converting a black-box DNN policy into an interpretable rulebased\ndecision tree while maintaining comparable scheduling performance.\nAdditionally, IRL can contribute to the setting of rewards in DRL scheduling.",
      "tldr_zh": "本研究针对深度强化学习（DRL）驱动的高性能计算（HPC）集群调度问题，指出DRL的深度神经网络（DNN）作为黑盒模型缺乏可解释性，阻碍实际部署。作者提出IRL（Interpretable Reinforcement Learning）框架，通过模仿学习将DNN策略转换为易懂的决策树模型，并结合Dataset Aggregation (DAgger)算法和critical state概念来修剪决策树，以确保高效性和准确性。实验结果显示，IRL在保持与原DRL调度性能相当的同时，大大提升了模型的可解释性，并能辅助设置DRL的奖励函数。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.16293v1",
      "published_date": "2024-03-24 20:56:16 UTC",
      "updated_date": "2024-03-24 20:56:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:19:22.912294"
    },
    {
      "arxiv_id": "2403.16291v3",
      "title": "Guessing human intentions to avoid dangerous situations in caregiving robots",
      "title_zh": "翻译失败",
      "authors": [
        "Noé Zapata",
        "Gerardo Pérez",
        "Lucas Bonilla",
        "Pedro Núñez",
        "Pilar Bachiller",
        "Pablo Bustos"
      ],
      "abstract": "For robots to interact socially, they must interpret human intentions and\nanticipate their potential outcomes accurately. This is particularly important\nfor social robots designed for human care, which may face potentially dangerous\nsituations for people, such as unseen obstacles in their way, that should be\navoided. This paper explores the Artificial Theory of Mind (ATM) approach to\ninferring and interpreting human intentions. We propose an algorithm that\ndetects risky situations for humans, selecting a robot action that removes the\ndanger in real time. We use the simulation-based approach to ATM and adopt the\n'like-me' policy to assign intentions and actions to people. Using this\nstrategy, the robot can detect and act with a high rate of success under\ntime-constrained situations. The algorithm has been implemented as part of an\nexisting robotics cognitive architecture and tested in simulation scenarios.\nThree experiments have been conducted to test the implementation's robustness,\nprecision and real-time response, including a simulated scenario, a\nhuman-in-the-loop hybrid configuration and a real-world scenario.",
      "tldr_zh": "本论文探讨了护理机器人如何通过推断人类意图来避免潜在危险情况，特别关注如障碍物等风险。研究提出了一种基于 Artificial Theory of Mind (ATM) 的算法，利用 simulation-based 方法和 'like-me' 政策来检测风险并实时选择机器人行动，以实现高成功率响应。该算法已整合到机器人认知架构中，并在模拟、混合和真实场景的三个实验中验证，展示了其鲁棒性、精确性和实时性能。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Associated mpeg file see https://youtu.be/87UEB8P97KY",
      "pdf_url": "http://arxiv.org/pdf/2403.16291v3",
      "published_date": "2024-03-24 20:43:29 UTC",
      "updated_date": "2024-07-09 18:20:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:19:34.416589"
    },
    {
      "arxiv_id": "2403.16289v1",
      "title": "Engineering Safety Requirements for Autonomous Driving with Large Language Models",
      "title_zh": "使用大型语言模型的自动驾驶安全要求工程",
      "authors": [
        "Ali Nouri",
        "Beatriz Cabrero-Daniel",
        "Fredrik Törner",
        "Hȧkan Sivencrona",
        "Christian Berger"
      ],
      "abstract": "Changes and updates in the requirement artifacts, which can be frequent in\nthe automotive domain, are a challenge for SafetyOps. Large Language Models\n(LLMs), with their impressive natural language understanding and generating\ncapabilities, can play a key role in automatically refining and decomposing\nrequirements after each update. In this study, we propose a prototype of a\npipeline of prompts and LLMs that receives an item definition and outputs\nsolutions in the form of safety requirements. This pipeline also performs a\nreview of the requirement dataset and identifies redundant or contradictory\nrequirements. We first identified the necessary characteristics for performing\nHARA and then defined tests to assess an LLM's capability in meeting these\ncriteria. We used design science with multiple iterations and let experts from\ndifferent companies evaluate each cycle quantitatively and qualitatively.\nFinally, the prototype was implemented at a case company and the responsible\nteam evaluated its efficiency.",
      "tldr_zh": "本研究探讨了汽车领域中需求工件的频繁变更对 SafetyOps 的挑战，并提出利用 Large Language Models (LLMs) 自动精炼和分解安全需求的方法。研究构建了一个提示管道原型，该系统接收项目定义并输出安全需求形式，同时审查需求数据集以识别冗余或矛盾项，并评估 LLM 在 HARA (Hazard and Risk Assessment) 方面的能力。采用设计科学方法进行多次迭代，由不同公司专家定量和定性评估，最终在案例公司实施后，证明了该原型提高了需求工程的效率和准确性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted in 32nd IEEE International Requirements Engineering 2024\n  conference, Iceland",
      "pdf_url": "http://arxiv.org/pdf/2403.16289v1",
      "published_date": "2024-03-24 20:40:51 UTC",
      "updated_date": "2024-03-24 20:40:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:19:45.955726"
    },
    {
      "arxiv_id": "2403.16276v2",
      "title": "Empowering LLMs with Pseudo-Untrimmed Videos for Audio-Visual Temporal Understanding",
      "title_zh": "利用伪未修剪视频赋能 LLMs 以实现音频-视觉时间理解",
      "authors": [
        "Yunlong Tang",
        "Daiki Shimada",
        "Jing Bi",
        "Mingqian Feng",
        "Hang Hua",
        "Chenliang Xu"
      ],
      "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities in\nnatural language and multimodal domains. By fine-tuning multimodal LLMs with\ntemporal annotations from well-annotated datasets, e.g., dense video captioning\ndatasets, their temporal understanding capacity in video-language tasks can be\nobtained. However, there is a notable lack of untrimmed audio-visual video\ndatasets with precise temporal annotations for events. This deficiency hinders\nLLMs from learning the alignment between time, audio-visual events, and text\ntokens, thus impairing their ability to temporally localize audio-visual events\nin videos. To address this gap, we introduce PU-VALOR, a comprehensive\naudio-visual dataset comprising over 114,000 pseudo-untrimmed videos with\ndetailed temporal annotations. PU-VALOR is derived from the large-scale but\ncoarse-annotated audio-visual dataset VALOR, through a subtle method involving\nevent-based video clustering, random temporal scaling, and permutation. By\nfine-tuning a multimodal LLM on PU-VALOR, we developed AVicuna, a model capable\nof aligning audio-visual events with temporal intervals and corresponding text\ntokens. AVicuna excels in temporal localization and time-aware dialogue\ncapabilities. Our experiments demonstrate that AVicuna effectively handles\ntemporal understanding in audio-visual videos and achieves state-of-the-art\nperformance on open-ended video QA, audio-visual QA, and audio-visual event\ndense localization tasks.",
      "tldr_zh": "本研究针对大型语言模型（LLMs）在音频-视觉任务中缺乏时间理解能力的问题，创建了 PU-VALOR 数据集，该数据集包含超过 114,000 个伪未修剪视频，通过事件-based 视频聚类、随机时间缩放和排列等方法从粗略注解的 VALOR 数据集衍生而来，并添加精确的时间注解。  \n利用 PU-VALOR 微调多模态 LLM，研究团队开发了 AVicuna 模型，该模型能够有效对齐音频-视觉事件与时间间隔及文本标记，从而提升 temporal localization 和时间感知对话能力。  \n实验结果显示，AVicuna 在开放式视频 QA、音频-视觉 QA 和音频-视觉事件密集定位任务上达到了 state-of-the-art 性能，为 LLMs 的多模态时间理解提供了新途径。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.16276v2",
      "published_date": "2024-03-24 19:50:49 UTC",
      "updated_date": "2024-08-21 01:15:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:20:02.621314"
    },
    {
      "arxiv_id": "2403.16272v1",
      "title": "L-MAE: Longitudinal masked auto-encoder with time and severity-aware encoding for diabetic retinopathy progression prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Rachid Zeghlache",
        "Pierre-Henri Conze",
        "Mostafa El Habib Daho",
        "Yihao Li",
        "Alireza Rezaei",
        "Hugo Le Boité",
        "Ramin Tadayoni",
        "Pascal Massin",
        "Béatrice Cochener",
        "Ikram Brahim",
        "Gwenolé Quellec",
        "Mathieu Lamard"
      ],
      "abstract": "Pre-training strategies based on self-supervised learning (SSL) have proven\nto be effective pretext tasks for many downstream tasks in computer vision. Due\nto the significant disparity between medical and natural images, the\napplication of typical SSL is not straightforward in medical imaging.\nAdditionally, those pretext tasks often lack context, which is critical for\ncomputer-aided clinical decision support. In this paper, we developed a\nlongitudinal masked auto-encoder (MAE) based on the well-known\nTransformer-based MAE. In particular, we explored the importance of time-aware\nposition embedding as well as disease progression-aware masking. Taking into\naccount the time between examinations instead of just scheduling them offers\nthe benefit of capturing temporal changes and trends. The masking strategy, for\nits part, evolves during follow-up to better capture pathological changes,\nensuring a more accurate assessment of disease progression. Using OPHDIAT, a\nlarge follow-up screening dataset targeting diabetic retinopathy (DR), we\nevaluated the pre-trained weights on a longitudinal task, which is to predict\nthe severity label of the next visit within 3 years based on the past time\nseries examinations. Our results demonstrated the relevancy of both time-aware\nposition embedding and masking strategies based on disease progression\nknowledge. Compared to popular baseline models and standard longitudinal\nTransformers, these simple yet effective extensions significantly enhance the\npredictive ability of deep classification models.",
      "tldr_zh": "本研究提出了一种纵向 masked auto-encoder（L-MAE）框架，基于 Transformer 的自监督学习（SSL），通过引入时间感知位置嵌入（time-aware position embedding）和疾病进展感知掩码（disease progression-aware masking），以更好地捕捉医疗图像中的时间变化和病理趋势。L-MAE 针对糖尿病视网膜病变（diabetic retinopathy, DR）的纵向任务，使用 OPHDIAT 数据集预测未来 3 年内的严重程度标签。实验结果显示，该方法显著提升了深度分类模型的预测性能，比传统基线模型和标准纵向 Transformer 模型表现出色。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.16272v1",
      "published_date": "2024-03-24 19:34:33 UTC",
      "updated_date": "2024-03-24 19:34:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:20:09.452035"
    },
    {
      "arxiv_id": "2403.16260v2",
      "title": "Out-of-Distribution Detection via Deep Multi-Comprehension Ensemble",
      "title_zh": "翻译失败",
      "authors": [
        "Chenhui Xu",
        "Fuxun Yu",
        "Zirui Xu",
        "Nathan Inkawhich",
        "Xiang Chen"
      ],
      "abstract": "Recent research underscores the pivotal role of the Out-of-Distribution (OOD)\nfeature representation field scale in determining the efficacy of models in OOD\ndetection. Consequently, the adoption of model ensembles has emerged as a\nprominent strategy to augment this feature representation field, capitalizing\non anticipated model diversity.\n  However, our introduction of novel qualitative and quantitative model\nensemble evaluation methods, specifically Loss Basin/Barrier Visualization and\nthe Self-Coupling Index, reveals a critical drawback in existing ensemble\nmethods. We find that these methods incorporate weights that are\naffine-transformable, exhibiting limited variability and thus failing to\nachieve the desired diversity in feature representation.\n  To address this limitation, we elevate the dimensions of traditional model\nensembles, incorporating various factors such as different weight\ninitializations, data holdout, etc., into distinct supervision tasks. This\ninnovative approach, termed Multi-Comprehension (MC) Ensemble, leverages\ndiverse training tasks to generate distinct comprehensions of the data and\nlabels, thereby extending the feature representation field.\n  Our experimental results demonstrate the superior performance of the MC\nEnsemble strategy in OOD detection compared to both the naive Deep Ensemble\nmethod and a standalone model of comparable size. This underscores the\neffectiveness of our proposed approach in enhancing the model's capability to\ndetect instances outside its training distribution.",
      "tldr_zh": "该研究强调了 Out-of-Distribution (OOD) 检测中特征表示的重要性，并通过引入 Loss Basin/Barrier Visualization 和 Self-Coupling Index 等新方法，揭示现有模型集成策略的局限性，即权重缺乏多样性导致特征表示不足。为解决此问题，作者提出 Multi-Comprehension (MC) Ensemble 方法，将不同权重初始化和数据保留等因素融入多样化监督任务，从而扩展特征表示场。实验结果表明，MC Ensemble 在 OOD 检测中比传统的 Deep Ensemble 和单模型表现出色，显著提升了检测性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.16260v2",
      "published_date": "2024-03-24 18:43:04 UTC",
      "updated_date": "2024-08-15 21:30:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:20:22.363303"
    },
    {
      "arxiv_id": "2403.16230v1",
      "title": "On machine learning analysis of atomic force microscopy images for image classification, sample surface recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Igor Sokolov"
      ],
      "abstract": "Atomic force microscopy (AFM or SPM) imaging is one of the best matches with\nmachine learning (ML) analysis among microscopy techniques. The digital format\nof AFM images allows for direct utilization in ML algorithms without the need\nfor additional processing. Additionally, AFM enables the simultaneous imaging\nof distributions of over a dozen different physicochemical properties of sample\nsurfaces, a process known as multidimensional imaging. While this wealth of\ninformation can be challenging to analyze using traditional methods, ML\nprovides a seamless approach to this task. However, the relatively slow speed\nof AFM imaging poses a challenge in applying deep learning methods broadly used\nin image recognition. This Prospective is focused on ML\nrecognition/classification when using a relatively small number of AFM images,\nsmall database. We discuss ML methods other than popular deep-learning neural\nnetworks. The described approach has already been successfully used to analyze\nand classify the surfaces of biological cells. It can be applied to recognize\nmedical images, specific material processing, in forensic studies, even to\nidentify the authenticity of arts. A general template for ML analysis specific\nto AFM is suggested, with a specific example of the identification of cell\nphenotype. Special attention is given to the analysis of the statistical\nsignificance of the obtained results, an important feature that is often\noverlooked in papers dealing with machine learning. A simple method for finding\nstatistical significance is also described.",
      "tldr_zh": "这篇论文探讨了使用机器学习（ML）分析原子力显微镜（AFM）图像来进行图像分类和样本表面识别，强调了AFM的多维成像优势及其与ML的兼容性。论文聚焦于小数据集场景，讨论了除深度学习神经网络外的其他ML方法，如传统算法，并提出一个针对AFM的通用分析模板，以成功应用于生物细胞表面分类。实验结果显示，该方法已在医疗图像识别、材料处理、法医研究和艺术真实性鉴定等领域取得成效。论文特别强调了结果的统计显著性分析，并提供了一个简单方法来验证可靠性。",
      "categories": [
        "physics.bio-ph",
        "cs.AI",
        "physics.ins-det",
        "physics.med-ph",
        "92C05, 92C55, 92C10, 92C50",
        "J.2; J.3; I.2; I.5"
      ],
      "primary_category": "physics.bio-ph",
      "comment": "perspective; mini-review; method description; Physical Chemistry\n  Chemical Physics (PCCP) in press, 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.16230v1",
      "published_date": "2024-03-24 16:48:10 UTC",
      "updated_date": "2024-03-24 16:48:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:20:34.822726"
    },
    {
      "arxiv_id": "2403.16222v2",
      "title": "Cyber-Security Knowledge Graph Generation by Hierarchical Nonnegative Matrix Factorization",
      "title_zh": "通过层次非负矩阵分解生成网络安全知识图谱",
      "authors": [
        "Ryan Barron",
        "Maksim E. Eren",
        "Manish Bhattarai",
        "Selma Wanna",
        "Nicholas Solovyev",
        "Kim Rasmussen",
        "Boian S. Alexandrov",
        "Charles Nicholas",
        "Cynthia Matuszek"
      ],
      "abstract": "Much of human knowledge in cybersecurity is encapsulated within the\never-growing volume of scientific papers. As this textual data continues to\nexpand, the importance of document organization methods becomes increasingly\ncrucial for extracting actionable insights hidden within large text datasets.\nKnowledge Graphs (KGs) serve as a means to store factual information in a\nstructured manner, providing explicit, interpretable knowledge that includes\ndomain-specific information from the cybersecurity scientific literature. One\nof the challenges in constructing a KG from scientific literature is the\nextraction of ontology from unstructured text. In this paper, we address this\ntopic and introduce a method for building a multi-modal KG by extracting\nstructured ontology from scientific papers. We demonstrate this concept in the\ncybersecurity domain. One modality of the KG represents observable information\nfrom the papers, such as the categories in which they were published or the\nauthors. The second modality uncovers latent (hidden) patterns of text\nextracted through hierarchical and semantic non-negative matrix factorization\n(NMF), such as named entities, topics or clusters, and keywords. We illustrate\nthis concept by consolidating more than two million scientific papers uploaded\nto arXiv into the cyber-domain, using hierarchical and semantic NMF, and by\nbuilding a cyber-domain-specific KG.",
      "tldr_zh": "本文提出了一种基于分层非负矩阵分解（hierarchical NMF）的方法，用于从海量科学论文中生成网络安全知识图谱（KGs），以解决从非结构化文本中提取本体（ontology）的挑战。该方法构建多模态 KG，包括可观察信息（如论文类别和作者）以及潜在模式（如命名实体、主题和关键词），通过语义 NMF 揭示隐藏的文本模式。实验结果显示，该框架成功整合了超过 200 万篇 arXiv 论文，创建了一个结构化的网络安全领域特定知识图谱，提供更易解释和可操作的洞见。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at IEEE ISDFS",
      "pdf_url": "http://arxiv.org/pdf/2403.16222v2",
      "published_date": "2024-03-24 16:30:05 UTC",
      "updated_date": "2024-03-26 15:28:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:20:49.403084"
    },
    {
      "arxiv_id": "2403.16218v4",
      "title": "CoverUp: Effective High Coverage Test Generation for Python",
      "title_zh": "CoverUp：用于 Python 的有效高覆盖率测试生成",
      "authors": [
        "Juan Altmayer Pizzorno",
        "Emery D. Berger"
      ],
      "abstract": "Testing is an essential part of software development. Test generation tools\nattempt to automate the otherwise labor-intensive task of test creation, but\ngenerating high-coverage tests remains challenging. This paper proposes\nCoverUp, a novel approach to driving the generation of high-coverage Python\nregression tests. CoverUp combines coverage analysis, code context, and\nfeedback in prompts that iteratively guide the LLM to generate tests that\nimprove line and branch coverage. We evaluate our prototype CoverUp\nimplementation across a benchmark of challenging code derived from open-source\nPython projects and show that CoverUp substantially improves on the state of\nthe art. Compared to CodaMosa, a hybrid search/LLM-based test generator,\nCoverUp achieves a per-module median line+branch coverage of 80% (vs. 47%).\nCompared to MuTAP, a mutation- and LLM-based test generator, CoverUp achieves\nan overall line+branch coverage of 89% (vs. 77%). We also demonstrate that\nCoverUp's performance stems not only from the LLM used but from the combined\neffectiveness of its components.",
      "tldr_zh": "这篇论文提出了 CoverUp，一种创新方法，用于生成高覆盖率的 Python 回归测试，以自动化测试创建过程。CoverUp 通过结合覆盖分析、代码上下文和反馈机制，在提示中迭代指导 LLM 生成测试，从而显著提升行和分支覆盖率。在基准测试中，CoverUp 与 CodaMosa 相比，每模块中位线+分支覆盖率达到 80% (vs. 47%)，与 MuTAP 相比整体覆盖率达 89% (vs. 77%)，证明其组件的协同效果超过了现有技术。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG",
        "cs.PL",
        "I.2.0; D.2.5"
      ],
      "primary_category": "cs.SE",
      "comment": "21 pages; to appear at FSE'25",
      "pdf_url": "http://arxiv.org/pdf/2403.16218v4",
      "published_date": "2024-03-24 16:18:27 UTC",
      "updated_date": "2025-05-09 14:33:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:21:00.840475"
    },
    {
      "arxiv_id": "2403.16210v2",
      "title": "Frankenstein: Generating Semantic-Compositional 3D Scenes in One Tri-Plane",
      "title_zh": "翻译失败",
      "authors": [
        "Han Yan",
        "Yang Li",
        "Zhennan Wu",
        "Shenzhou Chen",
        "Weixuan Sun",
        "Taizhang Shang",
        "Weizhe Liu",
        "Tian Chen",
        "Xiaqiang Dai",
        "Chao Ma",
        "Hongdong Li",
        "Pan Ji"
      ],
      "abstract": "We present Frankenstein, a diffusion-based framework that can generate\nsemantic-compositional 3D scenes in a single pass. Unlike existing methods that\noutput a single, unified 3D shape, Frankenstein simultaneously generates\nmultiple separated shapes, each corresponding to a semantically meaningful\npart. The 3D scene information is encoded in one single tri-plane tensor, from\nwhich multiple Singed Distance Function (SDF) fields can be decoded to\nrepresent the compositional shapes. During training, an auto-encoder compresses\ntri-planes into a latent space, and then the denoising diffusion process is\nemployed to approximate the distribution of the compositional scenes.\nFrankenstein demonstrates promising results in generating room interiors as\nwell as human avatars with automatically separated parts. The generated scenes\nfacilitate many downstream applications, such as part-wise re-texturing, object\nrearrangement in the room or avatar cloth re-targeting. Our project page is\navailable at: https://wolfball.github.io/frankenstein/.",
      "tldr_zh": "我们提出了 Frankenstein，一种基于扩散的框架，能够在单个 tri-plane 张量中生成语义组合的 3D 场景，与现有方法不同，它同时输出多个分离的形状，每个对应一个语义有意义的部件。框架通过 auto-encoder 将 tri-plane 压缩到潜在空间，然后使用去噪扩散过程来逼近组合场景的分布，确保高效训练和生成。该方法在生成房间内部和人类头像时表现出色，自动分离部件，并支持下游应用如部分重新纹理、对象重新排列或头像衣服重新定位。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR"
      ],
      "primary_category": "cs.CV",
      "comment": "SIGGRAPH Asia 2024 Conference Paper",
      "pdf_url": "http://arxiv.org/pdf/2403.16210v2",
      "published_date": "2024-03-24 16:09:21 UTC",
      "updated_date": "2024-08-30 17:39:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:21:12.747959"
    },
    {
      "arxiv_id": "2403.16209v3",
      "title": "Image Captioning in news report scenario",
      "title_zh": "新闻报道场景中的图像字幕生成",
      "authors": [
        "Tianrui Liu",
        "Qi Cai",
        "Changxin Xu",
        "Bo Hong",
        "Jize Xiong",
        "Yuxin Qiao",
        "Tsungwei Yang"
      ],
      "abstract": "Image captioning strives to generate pertinent captions for specified images,\nsituating itself at the crossroads of Computer Vision (CV) and Natural Language\nProcessing (NLP). This endeavor is of paramount importance with far-reaching\napplications in recommendation systems, news outlets, social media, and beyond.\nParticularly within the realm of news reporting, captions are expected to\nencompass detailed information, such as the identities of celebrities captured\nin the images. However, much of the existing body of work primarily centers\naround understanding scenes and actions. In this paper, we explore the realm of\nimage captioning specifically tailored for celebrity photographs, illustrating\nits broad potential for enhancing news industry practices. This exploration\naims to augment automated news content generation, thereby facilitating a more\nnuanced dissemination of information. Our endeavor shows a broader horizon,\nenriching the narrative in news reporting through a more intuitive image\ncaptioning framework.",
      "tldr_zh": "图像字幕（Image Captioning）结合计算机视觉（CV）和自然语言处理（NLP），在新闻报道场景中需要生成包含名人身份等详细信息的描述，以支持推荐系统和媒体应用。现有研究主要聚焦于场景和动作理解，但本文专门探索针对名人照片的图像字幕框架，旨在增强新闻内容的自动生成。最终，这为新闻行业提供更直观的叙述方式，促进信息传播的细致性和多样性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.16209v3",
      "published_date": "2024-03-24 16:08:10 UTC",
      "updated_date": "2024-04-02 01:57:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:21:22.949444"
    },
    {
      "arxiv_id": "2404.05735v1",
      "title": "A Python Framework for Neutrosophic Sets and Mappings",
      "title_zh": "翻译失败",
      "authors": [
        "Giorgio Nordo",
        "Saeid Jafari",
        "Arif Mehmood",
        "Bhimraj Basumatary"
      ],
      "abstract": "In this paper we present an open source framework developed in Python and\nconsisting of three distinct classes designed to manipulate in a simple and\nintuitive way both symbolic representations of neutrosophic sets over universes\nof various types as well as mappings between them. The capabilities offered by\nthis framework extend and generalize previous attempts to provide software\nsolutions to the manipulation of neutrosophic sets such as those proposed by\nSalama et al., Saranya et al., El-Ghareeb, Topal et al. and Sleem. The code is\ndescribed in detail and many examples and use cases are also provided.",
      "tldr_zh": "该论文提出一个开源Python框架，用于处理neutrosophic sets和mappings。该框架包括三个类，支持简单直观地操作neutrosophic sets的符号表示以及它们之间的映射，扩展了Salama et al.等先前工作的功能。通过详细描述代码并提供多个例子和用例，该框架为neutrosophic sets的研究提供了一个通用且易用的工具。",
      "categories": [
        "cs.AI",
        "03E72, 08A72, 03B52"
      ],
      "primary_category": "cs.AI",
      "comment": "38 PAGES",
      "pdf_url": "http://arxiv.org/pdf/2404.05735v1",
      "published_date": "2024-03-24 16:00:16 UTC",
      "updated_date": "2024-03-24 16:00:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:21:35.180715"
    },
    {
      "arxiv_id": "2403.16206v3",
      "title": "Rumor Detection with a novel graph neural network approach",
      "title_zh": "基于新颖的图神经网络方法的谣言检测",
      "authors": [
        "Tianrui Liu",
        "Qi Cai",
        "Changxin Xu",
        "Bo Hong",
        "Fanghao Ni",
        "Yuxin Qiao",
        "Tsungwei Yang"
      ],
      "abstract": "The wide spread of rumors on social media has caused a negative impact on\npeople's daily life, leading to potential panic, fear, and mental health\nproblems for the public. How to debunk rumors as early as possible remains a\nchallenging problem. Existing studies mainly leverage information propagation\nstructure to detect rumors, while very few works focus on correlation among\nusers that they may coordinate to spread rumors in order to gain large\npopularity. In this paper, we propose a new detection model, that jointly\nlearns both the representations of user correlation and information propagation\nto detect rumors on social media. Specifically, we leverage graph neural\nnetworks to learn the representations of user correlation from a bipartite\ngraph that describes the correlations between users and source tweets, and the\nrepresentations of information propagation with a tree structure. Then we\ncombine the learned representations from these two modules to classify the\nrumors. Since malicious users intend to subvert our model after deployment, we\nfurther develop a greedy attack scheme to analyze the cost of three adversarial\nattacks: graph attack, comment attack, and joint attack. Evaluation results on\ntwo public datasets illustrate that the proposed MODEL outperforms the\nstate-of-the-art rumor detection models. We also demonstrate our method\nperforms well for early rumor detection. Moreover, the proposed detection\nmethod is more robust to adversarial attacks compared to the best existing\nmethod. Importantly, we show that it requires a high cost for attackers to\nsubvert user correlation pattern, demonstrating the importance of considering\nuser correlation for rumor detection.",
      "tldr_zh": "这篇论文提出了一种新型谣言检测模型，使用 Graph Neural Networks (GNNs) 联合学习用户相关性和信息传播表示，以解决社交媒体谣言的早期识别问题。具体方法包括从一个 bipartite graph 中提取用户与源推文的相关性表示，并从树结构中学习信息传播表示，然后将两者结合进行谣言分类。论文还开发了贪婪攻击方案来评估三种对抗攻击（graph attack、comment attack 和 joint attack）的成本。实验结果显示，该模型在两个公共数据集上优于现有方法，在早期检测和对抗攻击的鲁棒性方面表现更佳，并强调考虑用户相关性能显著提高检测的安全性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.16206v3",
      "published_date": "2024-03-24 15:59:47 UTC",
      "updated_date": "2024-04-02 01:52:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:21:49.200861"
    },
    {
      "arxiv_id": "2403.16190v1",
      "title": "Logic-based Explanations for Linear Support Vector Classifiers with Reject Option",
      "title_zh": "翻译失败",
      "authors": [
        "Francisco Mateus Rocha Filho",
        "Thiago Alves Rocha",
        "Reginaldo Pereira Fernandes Ribeiro",
        "Ajalmar Rêgo da Rocha Neto"
      ],
      "abstract": "Support Vector Classifier (SVC) is a well-known Machine Learning (ML) model\nfor linear classification problems. It can be used in conjunction with a reject\noption strategy to reject instances that are hard to correctly classify and\ndelegate them to a specialist. This further increases the confidence of the\nmodel. Given this, obtaining an explanation of the cause of rejection is\nimportant to not blindly trust the obtained results. While most of the related\nwork has developed means to give such explanations for machine learning models,\nto the best of our knowledge none have done so for when reject option is\npresent. We propose a logic-based approach with formal guarantees on the\ncorrectness and minimality of explanations for linear SVCs with reject option.\nWe evaluate our approach by comparing it to Anchors, which is a heuristic\nalgorithm for generating explanations. Obtained results show that our proposed\nmethod gives shorter explanations with reduced time cost.",
      "tldr_zh": "本文针对线性支持向量分类器 (SVC) 结合拒绝选项的场景，提出了一种基于逻辑的解释方法，以解释拒绝决策的原因，并确保解释的正确性和最小性。该方法填补了现有研究在SVC with reject option 上的空白，通过正式保证提升模型的可解释性。与启发式算法 Anchors 相比，实验结果显示本文方法生成更短的解释，并显著降低计算时间。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.LO",
        "I.2.4; I.2.6"
      ],
      "primary_category": "cs.AI",
      "comment": "16 pages, submitted to BRACIS 2023 (Brazilian Conference on\n  Intelligent Systems), accepted version published in Intelligent Systems,\n  LNCS, vol 14195",
      "pdf_url": "http://arxiv.org/pdf/2403.16190v1",
      "published_date": "2024-03-24 15:14:44 UTC",
      "updated_date": "2024-03-24 15:14:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:21:59.664880"
    },
    {
      "arxiv_id": "2404.00042v1",
      "title": "Stochastic Optimization with Constraints: A Non-asymptotic Instance-Dependent Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Koulik Khamaru"
      ],
      "abstract": "We consider the problem of stochastic convex optimization under convex\nconstraints. We analyze the behavior of a natural variance reduced proximal\ngradient (VRPG) algorithm for this problem. Our main result is a non-asymptotic\nguarantee for VRPG algorithm. Contrary to minimax worst case guarantees, our\nresult is instance-dependent in nature. This means that our guarantee captures\nthe complexity of the loss function, the variability of the noise, and the\ngeometry of the constraint set. We show that the non-asymptotic performance of\nthe VRPG algorithm is governed by the scaled distance (scaled by $\\sqrt{N}$)\nbetween the solutions of the given problem and that of a certain small\nperturbation of the given problem -- both solved under the given convex\nconstraints; here, $N$ denotes the number of samples. Leveraging a\nwell-established connection between local minimax lower bounds and solutions to\nperturbed problems, we show that as $N \\rightarrow \\infty$, the VRPG algorithm\nachieves the renowned local minimax lower bound by H\\`{a}jek and Le Cam up to\nuniversal constants and a logarithmic factor of the sample size.",
      "tldr_zh": "本研究探讨了带凸约束的随机凸优化问题，分析了variance reduced proximal gradient (VRPG)算法的性能。研究的主要贡献是提供了一个instance-dependent的非渐近保证（non-asymptotic guarantee），该保证考虑了损失函数的复杂度、噪声的可变性和约束集的几何特性。结果表明，VRPG算法的性能由给定问题与其小扰动问题解决方案之间的scaled distance（缩放因子为√N）主导，随着样本数N增加，该算法接近Hájek和Le Cam的local minimax下界，仅差常数和对数因子。",
      "categories": [
        "math.OC",
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "math.OC",
      "comment": "18 pages",
      "pdf_url": "http://arxiv.org/pdf/2404.00042v1",
      "published_date": "2024-03-24 14:45:11 UTC",
      "updated_date": "2024-03-24 14:45:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:22:11.447515"
    },
    {
      "arxiv_id": "2403.16178v1",
      "title": "Mixed-Initiative Human-Robot Teaming under Suboptimality with Online Bayesian Adaptation",
      "title_zh": "翻译失败",
      "authors": [
        "Manisha Natarajan",
        "Chunyue Xue",
        "Sanne van Waveren",
        "Karen Feigh",
        "Matthew Gombolay"
      ],
      "abstract": "For effective human-agent teaming, robots and other artificial intelligence\n(AI) agents must infer their human partner's abilities and behavioral response\npatterns and adapt accordingly. Most prior works make the unrealistic\nassumption that one or more teammates can act near-optimally. In real-world\ncollaboration, humans and autonomous agents can be suboptimal, especially when\neach only has partial domain knowledge. In this work, we develop computational\nmodeling and optimization techniques for enhancing the performance of\nsuboptimal human-agent teams, where the human and the agent have asymmetric\ncapabilities and act suboptimally due to incomplete environmental knowledge. We\nadopt an online Bayesian approach that enables a robot to infer people's\nwillingness to comply with its assistance in a sequential decision-making game.\nOur user studies show that user preferences and team performance indeed vary\nwith robot intervention styles, and our approach for mixed-initiative\ncollaborations enhances objective team performance ($p<.001$) and subjective\nmeasures, such as user's trust ($p<.001$) and perceived likeability of the\nrobot ($p<.001$).",
      "tldr_zh": "该论文探讨了人类-机器人团队在 suboptimal 条件下进行混合主动协作的问题，强调机器人需通过在线 Bayesian 适应来推断人类的能力和行为模式，以应对信息不对称和不完整环境知识。研究开发了计算建模和优化技术，使机器人能在顺序决策游戏中评估人类对协助的意愿，并据此调整干预策略。用户研究结果显示，这种方法显著提升了团队客观表现（p<0.001），以及主观指标如用户信任（p<0.001）和机器人可喜爱度（p<0.001）。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "8 pages, 4 pages for supplementary",
      "pdf_url": "http://arxiv.org/pdf/2403.16178v1",
      "published_date": "2024-03-24 14:38:18 UTC",
      "updated_date": "2024-03-24 14:38:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:22:24.759188"
    },
    {
      "arxiv_id": "2403.18864v1",
      "title": "Interpretable Machine Learning for Weather and Climate Prediction: A Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Ruyi Yang",
        "Jingyu Hu",
        "Zihao Li",
        "Jianli Mu",
        "Tingzhao Yu",
        "Jiangjiang Xia",
        "Xuhong Li",
        "Aritra Dasgupta",
        "Haoyi Xiong"
      ],
      "abstract": "Advanced machine learning models have recently achieved high predictive\naccuracy for weather and climate prediction. However, these complex models\noften lack inherent transparency and interpretability, acting as \"black boxes\"\nthat impede user trust and hinder further model improvements. As such,\ninterpretable machine learning techniques have become crucial in enhancing the\ncredibility and utility of weather and climate modeling. In this survey, we\nreview current interpretable machine learning approaches applied to\nmeteorological predictions. We categorize methods into two major paradigms: 1)\nPost-hoc interpretability techniques that explain pre-trained models, such as\nperturbation-based, game theory based, and gradient-based attribution methods.\n2) Designing inherently interpretable models from scratch using architectures\nlike tree ensembles and explainable neural networks. We summarize how each\ntechnique provides insights into the predictions, uncovering novel\nmeteorological relationships captured by machine learning. Lastly, we discuss\nresearch challenges around achieving deeper mechanistic interpretations aligned\nwith physical principles, developing standardized evaluation benchmarks,\nintegrating interpretability into iterative model development workflows, and\nproviding explainability for large foundation models.",
      "tldr_zh": "这篇调查回顾了可解释机器学习在天气和气候预测中的应用，旨在解决复杂模型的“黑箱”问题以提升用户信任和模型改进。研究将方法分为两大类：后验解释技术（Post-hoc interpretability techniques），如基于扰动、博弈论和梯度归因的方法；以及从零设计固有可解释模型，如树集成和可解释神经网络。论文总结了这些技术如何揭示机器学习捕获的新气象关系，并讨论了关键挑战，包括实现与物理原则对齐的机制解释、开发标准化评估基准，以及将解释性整合到模型开发流程中。",
      "categories": [
        "physics.ao-ph",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "physics.ao-ph",
      "comment": "26 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.18864v1",
      "published_date": "2024-03-24 14:23:35 UTC",
      "updated_date": "2024-03-24 14:23:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:22:35.574637"
    },
    {
      "arxiv_id": "2403.16163v1",
      "title": "An Analytic Solution to Covariance Propagation in Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Oren Wright",
        "Yorie Nakahira",
        "José M. F. Moura"
      ],
      "abstract": "Uncertainty quantification of neural networks is critical to measuring the\nreliability and robustness of deep learning systems. However, this often\ninvolves costly or inaccurate sampling methods and approximations. This paper\npresents a sample-free moment propagation technique that propagates mean\nvectors and covariance matrices across a network to accurately characterize the\ninput-output distributions of neural networks. A key enabler of our technique\nis an analytic solution for the covariance of random variables passed through\nnonlinear activation functions, such as Heaviside, ReLU, and GELU. The wide\napplicability and merits of the proposed technique are shown in experiments\nanalyzing the input-output distributions of trained neural networks and\ntraining Bayesian neural networks.",
      "tldr_zh": "这篇论文提出了一种无样本的时刻传播技术，用于精确量化神经网络的输入-输出分布，从而提升深度学习系统的可靠性和鲁棒性。该技术通过提供Heaviside、ReLU和GELU等非线性激活函数下随机变量协方差的分析解，实现均值向量和协方差矩阵的传播，避免了传统采样方法的成本和不准确性。实验验证了该方法的广泛适用性，包括分析训练后神经网络的分布和训练Bayesian neural networks的效果。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to AISTATS 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.16163v1",
      "published_date": "2024-03-24 14:08:24 UTC",
      "updated_date": "2024-03-24 14:08:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:22:48.647315"
    },
    {
      "arxiv_id": "2403.16162v1",
      "title": "Multi-Task Learning with Multi-Task Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Lu Bai",
        "Abhishek Gupta",
        "Yew-Soon Ong"
      ],
      "abstract": "Multi-task learning solves multiple correlated tasks. However, conflicts may\nexist between them. In such circumstances, a single solution can rarely\noptimize all the tasks, leading to performance trade-offs. To arrive at a set\nof optimized yet well-distributed models that collectively embody different\ntrade-offs in one algorithmic pass, this paper proposes to view Pareto\nmulti-task learning through the lens of multi-task optimization. Multi-task\nlearning is first cast as a multi-objective optimization problem, which is then\ndecomposed into a diverse set of unconstrained scalar-valued subproblems. These\nsubproblems are solved jointly using a novel multi-task gradient descent\nmethod, whose uniqueness lies in the iterative transfer of model parameters\namong the subproblems during the course of optimization. A theorem proving\nfaster convergence through the inclusion of such transfers is presented. We\ninvestigate the proposed multi-task learning with multi-task optimization for\nsolving various problem settings including image classification, scene\nunderstanding, and multi-target regression. Comprehensive experiments confirm\nthat the proposed method significantly advances the state-of-the-art in\ndiscovering sets of Pareto-optimized models. Notably, on the large image\ndataset we tested on, namely NYUv2, the hypervolume convergence achieved by our\nmethod was found to be nearly two times faster than the next-best among the\nstate-of-the-art.",
      "tldr_zh": "本论文提出了一种新的Multi-Task Learning方法，通过Multi-Task Optimization框架来处理多任务学习中的任务冲突和性能权衡问题。具体而言，它将多任务学习转化为多目标优化问题，并分解为一系列无约束子问题，然后使用一种创新的多任务梯度下降方法来共同解决这些子问题，该方法通过迭代转移模型参数来加速收敛，并提供了相关的理论证明。实验结果显示，该方法在图像分类、场景理解和多目标回归等场景中显著优于现有技术，尤其在NYUv2数据集上，其超体积收敛速度比最先进方法快近两倍，从而高效发现Pareto优化模型集。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.16162v1",
      "published_date": "2024-03-24 14:04:40 UTC",
      "updated_date": "2024-03-24 14:04:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:23:02.280632"
    },
    {
      "arxiv_id": "2403.16153v1",
      "title": "One Masked Model is All You Need for Sensor Fault Detection, Isolation and Accommodation",
      "title_zh": "一个掩码模型",
      "authors": [
        "Yiwei Fu",
        "Weizhong Yan"
      ],
      "abstract": "Accurate and reliable sensor measurements are critical for ensuring the\nsafety and longevity of complex engineering systems such as wind turbines. In\nthis paper, we propose a novel framework for sensor fault detection, isolation,\nand accommodation (FDIA) using masked models and self-supervised learning. Our\nproposed approach is a general time series modeling approach that can be\napplied to any neural network (NN) model capable of sequence modeling, and\ncaptures the complex spatio-temporal relationships among different sensors.\nDuring training, the proposed masked approach creates a random mask, which acts\nlike a fault, for one or more sensors, making the training and inference task\nunified: finding the faulty sensors and correcting them. We validate our\nproposed technique on both a public dataset and a real-world dataset from GE\noffshore wind turbines, and demonstrate its effectiveness in detecting,\ndiagnosing and correcting sensor faults. The masked model not only simplifies\nthe overall FDIA pipeline, but also outperforms existing approaches. Our\nproposed technique has the potential to significantly improve the accuracy and\nreliability of sensor measurements in complex engineering systems in real-time,\nand could be applied to other types of sensors and engineering systems in the\nfuture. We believe that our proposed framework can contribute to the\ndevelopment of more efficient and effective FDIA techniques for a wide range of\napplications.",
      "tldr_zh": "本文提出了一种基于 masked models 和 self-supervised learning 的框架，用于传感器故障检测、隔离和校正（FDIA），旨在提升复杂工程系统如风力涡轮机的安全性和可靠性。该方法通过在训练过程中创建随机 mask 来模拟故障，统一训练和推理任务，并捕捉传感器间的复杂时空关系，适用于任何序列建模的神经网络（NN）。实验在公共数据集和 GE 离岸风力涡轮机真实数据上验证，该框架简化了 FDIA 流程，并显著优于现有方法，提高了实时传感器测量的准确性和可靠性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by the 2024 International Joint Conference on Neural\n  Networks (IJCNN 2024)",
      "pdf_url": "http://arxiv.org/pdf/2403.16153v1",
      "published_date": "2024-03-24 13:44:57 UTC",
      "updated_date": "2024-03-24 13:44:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:23:12.631899"
    },
    {
      "arxiv_id": "2403.16149v6",
      "title": "Analyzing Consumer IoT Traffic from Security and Privacy Perspectives: a Comprehensive Survey",
      "title_zh": "从安全和隐私角度分析消费者 IoT 流量：全面综述",
      "authors": [
        "Yan Jia",
        "Yuxin Song",
        "Zihou Liu",
        "Qingyin Tan",
        "Yang Song",
        "Yu Zhang",
        "Zheli Liu"
      ],
      "abstract": "The Consumer Internet of Things (CIoT), a notable segment within the IoT\ndomain, involves the integration of IoT technology into consumer electronics\nand devices, such as smart homes and smart wearables. Compared to traditional\nIoT fields, CIoT differs notably in target users, product types, and design\napproaches. While offering convenience to users, it also raises new security\nand privacy concerns. Network traffic analysis, a widely used technique in the\nsecurity community, has been extensively applied to investigate these concerns\nabout CIoT. Compared to traditional network traffic analysis in fields like\nmobile apps and websites, CIoT introduces unique characteristics that pose new\nchallenges and research opportunities. Researchers have made significant\ncontributions in this area. To aid researchers in understanding the application\nof traffic analysis tools for assessing CIoT security and privacy risks, this\nsurvey reviews 310 publications on traffic analysis within the CIoT security\nand privacy domain from January 2018 to June 2024, focusing on three research\nquestions. Our work: 1) outlines the CIoT traffic analysis process and\nhighlights its differences from general network traffic analysis. 2) summarizes\nand classifies existing research into four categories according to its\napplication objectives: device fingerprinting, user activity inference,\nmalicious traffic detection, and measurement. 3) explores emerging challenges\nand potential future research directions based on each step of the CIoT traffic\nanalysis process. This will provide new insights to the community and guide the\nindustry towards safer product designs.",
      "tldr_zh": "这篇调查论文系统分析了 Consumer IoT (CIoT) 流量的安全和隐私问题，通过回顾 2018 年至 2024 年 310 篇相关文献，概述了 CIoT 流量分析过程及其与传统网络流量分析的差异。研究将现有工作分类为四个类别：device fingerprinting（设备指纹识别）、user activity inference（用户活动推断）、malicious traffic detection（恶意流量检测）和测量。论文还探讨了新兴挑战和未来研究方向，以提供新见解并指导行业开发更安全的 CIoT 产品设计。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.16149v6",
      "published_date": "2024-03-24 13:43:43 UTC",
      "updated_date": "2025-05-14 12:39:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:23:27.599796"
    },
    {
      "arxiv_id": "2403.16142v1",
      "title": "What Happens to a Dataset Transformed by a Projection-based Concept Removal Method?",
      "title_zh": "翻译失败",
      "authors": [
        "Richard Johansson"
      ],
      "abstract": "We investigate the behavior of methods that use linear projections to remove\ninformation about a concept from a language representation, and we consider the\nquestion of what happens to a dataset transformed by such a method. A\ntheoretical analysis and experiments on real-world and synthetic data show that\nthese methods inject strong statistical dependencies into the transformed\ndatasets. After applying such a method, the representation space is highly\nstructured: in the transformed space, an instance tends to be located near\ninstances of the opposite label. As a consequence, the original labeling can in\nsome cases be reconstructed by applying an anti-clustering method.",
      "tldr_zh": "本研究调查了使用线性投影移除概念信息(linear projections for concept removal)的方法对数据集的影响，通过理论分析和真实/合成数据的实验，揭示这些方法会注入强烈的统计依赖性(statistical dependencies)。在转换后的表示空间中，实例倾向于靠近相反标签的实例，导致空间高度结构化。作为结果，原始标签在某些情况下可以通过反聚类(anti-clustering)方法重建，这暴露了该方法的潜在局限性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.16142v1",
      "published_date": "2024-03-24 13:28:27 UTC",
      "updated_date": "2024-03-24 13:28:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:23:35.781911"
    },
    {
      "arxiv_id": "2403.16135v1",
      "title": "Complementary Recommendation in E-commerce: Definition, Approaches, and Future Directions",
      "title_zh": "电子商务中的互补推荐：定义、方法和未来方向",
      "authors": [
        "Linyue Li",
        "Zhijuan Du"
      ],
      "abstract": "In recent years, complementary recommendation has received extensive\nattention in the e-commerce domain. In this paper, we comprehensively summarize\nand compare 34 representative studies conducted between 2009 and 2024. Firstly,\nwe compare the data and methods used for modeling complementary relationships\nbetween products, including simple complementarity and more complex scenarios\nsuch as asymmetric complementarity, the coexistence of substitution and\ncomplementarity relationships between products, and varying degrees of\ncomplementarity between different pairs of products. Next, we classify and\ncompare the models based on the research problems of complementary\nrecommendation, such as diversity, personalization, and cold-start.\nFurthermore, we provide a comparative analysis of experimental results from\ndifferent studies conducted on the same dataset, which helps identify the\nstrengths and weaknesses of the research. Compared to previous surveys, this\npaper provides a more updated and comprehensive summary of the research,\ndiscusses future research directions, and contributes to the advancement of\nthis field.",
      "tldr_zh": "这篇论文对电子商务中的互补推荐（complementary recommendation）进行了全面综述，定义了关键概念，并总结了2009-2024年间34个代表性研究。作者比较了产品间互补关系的数据和方法，包括simple complementarity、非对称互补（asymmetric complementarity）、替代与互补共存，以及不同产品对的互补程度；同时，分类并对比了基于多样性（diversity）、个性化（personalization）和冷启动（cold-start）等问题的模型。论文通过实验结果比较，突出了各研究的优势和劣势，并提出未来研究方向，推动该领域的发展。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "20 pages,9 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.16135v1",
      "published_date": "2024-03-24 13:06:05 UTC",
      "updated_date": "2024-03-24 13:06:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:23:48.865213"
    },
    {
      "arxiv_id": "2403.16133v2",
      "title": "SSHPool: The Separated Subgraph-based Hierarchical Pooling",
      "title_zh": "翻译失败",
      "authors": [
        "Zhuo Xu",
        "Lixin Cui",
        "Ming Li",
        "Yue Wang",
        "Ziyu Lyu",
        "Hangyuan Du",
        "Lu Bai",
        "Philip S. Yu",
        "Edwin R. Hancock"
      ],
      "abstract": "In this paper, we develop a novel local graph pooling method, namely the\nSeparated Subgraph-based Hierarchical Pooling (SSHPool), for graph\nclassification. We commence by assigning the nodes of a sample graph into\ndifferent clusters, resulting in a family of separated subgraphs. We\nindividually employ the local graph convolution units as the local structure to\nfurther compress each subgraph into a coarsened node, transforming the original\ngraph into a coarsened graph. Since these subgraphs are separated by different\nclusters and the structural information cannot be propagated between them, the\nlocal convolution operation can significantly avoid the over-smoothing problem\ncaused by message passing through edges in most existing Graph Neural Networks\n(GNNs). By hierarchically performing the proposed procedures on the resulting\ncoarsened graph, the proposed SSHPool can effectively extract the hierarchical\nglobal features of the original graph structure, encapsulating rich intrinsic\nstructural characteristics. Furthermore, we develop an end-to-end GNN framework\nassociated with the SSHPool module for graph classification. Experimental\nresults demonstrate the superior performance of the proposed model on\nreal-world datasets.",
      "tldr_zh": "本研究提出了一种新型局部图池化方法SSHPool（Separated Subgraph-based Hierarchical Pooling），用于图分类任务。它通过将图节点分配到不同集群形成分离子图，然后使用局部图卷积单元对每个子图进行压缩，生成粗化图，从而避免了Graph Neural Networks (GNNs)中常见的过平滑问题。SSHPool通过分层应用这一过程，高效提取原图的层次全局特征，保留丰富的结构信息。实验结果表明，该方法结合端到端GNN框架，在真实数据集上表现出优越的性能。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.16133v2",
      "published_date": "2024-03-24 13:03:35 UTC",
      "updated_date": "2024-08-13 16:15:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:24:00.875245"
    },
    {
      "arxiv_id": "2403.16130v2",
      "title": "AKBR: Learning Adaptive Kernel-based Representations for Graph Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Feifei Qian",
        "Lixin Cui",
        "Ming Li",
        "Yue Wang",
        "Hangyuan Du",
        "Lixiang Xu",
        "Lu Bai",
        "Philip S. Yu",
        "Edwin R. Hancock"
      ],
      "abstract": "In this paper, we propose a new model to learn Adaptive Kernel-based\nRepresentations (AKBR) for graph classification. Unlike state-of-the-art\nR-convolution graph kernels that are defined by merely counting any pair of\nisomorphic substructures between graphs and cannot provide an end-to-end\nlearning mechanism for the classifier, the proposed AKBR approach aims to\ndefine an end-to-end representation learning model to construct an adaptive\nkernel matrix for graphs. To this end, we commence by leveraging a novel\nfeature-channel attention mechanism to capture the interdependencies between\ndifferent substructure invariants of original graphs. The proposed AKBR model\ncan thus effectively identify the structural importance of different\nsubstructures, and compute the R-convolution kernel between pairwise graphs\nassociated with the more significant substructures specified by their\nstructural attentions. Since each row of the resulting kernel matrix can be\ntheoretically seen as the embedding vector of a sample graph, the proposed AKBR\nmodel is able to directly employ the resulting kernel matrix as the graph\nfeature matrix and input it into the classifier for classification (i.e., the\nSoftMax layer), naturally providing an end-to-end learning architecture between\nthe kernel computation as well as the classifier. Experimental results show\nthat the proposed AKBR model outperforms existing state-of-the-art graph\nkernels and deep learning methods on standard graph benchmarks.",
      "tldr_zh": "本论文提出AKBR模型，用于图分类任务，通过学习自适应核基表示来解决传统R-convolution图核方法的局限性，这些方法仅计算图间同构子结构的配对，无法实现端到端学习。AKBR引入了特征通道注意力机制（feature-channel attention mechanism），以捕捉不同子结构不变性的相互依赖性，并根据结构重要性计算R-convolution核，从而生成自适应核矩阵作为图特征输入。实验结果显示，AKBR在标准图基准上优于现有图核和深度学习方法，提供了一个高效的端到端学习框架。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.16130v2",
      "published_date": "2024-03-24 13:01:05 UTC",
      "updated_date": "2024-08-13 16:01:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:24:13.057585"
    },
    {
      "arxiv_id": "2403.16127v2",
      "title": "WangchanLion and WangchanX MRC Eval",
      "title_zh": "WangchanLion 和 WangchanX 机器阅读理解评估",
      "authors": [
        "Wannaphong Phatthiyaphaibun",
        "Surapon Nonesung",
        "Patomporn Payoungkhamdee",
        "Peerat Limkonchotiwat",
        "Can Udomcharoenchaikit",
        "Jitkapat Sawatphol",
        "Chompakorn Chaksangchaichot",
        "Ekapol Chuangsuwanich",
        "Sarana Nutanong"
      ],
      "abstract": "This technical report describes the development of WangchanLion, an\ninstruction fine-tuned model focusing on Machine Reading Comprehension (MRC) in\nthe Thai language. Our model is based on SEA-LION and a collection of\ninstruction following datasets. To promote open research and reproducibility,\nwe publicly release all training data, code, and the final model weights under\nthe Apache-2 license. To assess the contextual understanding capability, we\nconducted extensive experimental studies using two Thai MRC datasets, XQuAD and\nIapp_wiki_qa_squad. Experimental results demonstrate the model's ability to\ncomprehend the context and produce an answer faithful to the reference one in\n0-shot and 1-shot settings. In addition, our evaluation goes beyond the\ntraditional MRC. We propose a new evaluation scheme assessing the answer's\ncorrectness, helpfulness, conciseness, and contextuality. Our code is available\npublicly at https://github.com/vistec-AI/WangchanLion.",
      "tldr_zh": "本研究介绍了WangchanLion，一种针对泰语Machine Reading Comprehension (MRC)的指令微调模型，基于SEA-LION和多种指令跟随数据集开发而成。为了促进开放研究，该团队公开了所有训练数据、代码和模型权重（Apache-2许可证）。实验使用XQuAD和Iapp_wiki_qa_squad数据集评估了模型在0-shot和1-shot设置下的上下文理解能力，结果显示模型能生成与参考答案一致的回应。 additionally, 他们提出了一种新评估方案，考察答案的正确性、帮助性、简洁性和上下文性，并将代码公开在GitHub上。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.16127v2",
      "published_date": "2024-03-24 12:49:30 UTC",
      "updated_date": "2024-04-23 12:31:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:24:24.575256"
    },
    {
      "arxiv_id": "2403.16116v1",
      "title": "Self-Supervised Multi-Frame Neural Scene Flow",
      "title_zh": "自监督多帧神经场景流",
      "authors": [
        "Dongrui Liu",
        "Daqi Liu",
        "Xueqian Li",
        "Sihao Lin",
        "Hongwei xie",
        "Bing Wang",
        "Xiaojun Chang",
        "Lei Chu"
      ],
      "abstract": "Neural Scene Flow Prior (NSFP) and Fast Neural Scene Flow (FNSF) have shown\nremarkable adaptability in the context of large out-of-distribution autonomous\ndriving. Despite their success, the underlying reasons for their astonishing\ngeneralization capabilities remain unclear. Our research addresses this gap by\nexamining the generalization capabilities of NSFP through the lens of uniform\nstability, revealing that its performance is inversely proportional to the\nnumber of input point clouds. This finding sheds light on NSFP's effectiveness\nin handling large-scale point cloud scene flow estimation tasks. Motivated by\nsuch theoretical insights, we further explore the improvement of scene flow\nestimation by leveraging historical point clouds across multiple frames, which\ninherently increases the number of point clouds. Consequently, we propose a\nsimple and effective method for multi-frame point cloud scene flow estimation,\nalong with a theoretical evaluation of its generalization abilities. Our\nanalysis confirms that the proposed method maintains a limited generalization\nerror, suggesting that adding multiple frames to the scene flow optimization\nprocess does not detract from its generalizability. Extensive experimental\nresults on large-scale autonomous driving Waymo Open and Argoverse lidar\ndatasets demonstrate that the proposed method achieves state-of-the-art\nperformance.",
      "tldr_zh": "该研究分析了 Neural Scene Flow Prior (NSFP) 和 Fast Neural Scene Flow (FNSF) 的泛化能力，通过 uniform stability 理论揭示了 NSFP 的性能与输入点云数量成反比，从而解释了其在大规模自主驾驶场景中的有效性。基于此洞见，作者提出了一种简单有效的多帧点云场景流估计方法，利用历史点云信息来提升估计精度，并理论证明了该方法保持有限的泛化错误。实验结果显示，该方法在 Waymo Open 和 Argoverse 数据集上实现了 state-of-the-art 性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.16116v1",
      "published_date": "2024-03-24 12:15:28 UTC",
      "updated_date": "2024-03-24 12:15:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:24:37.863314"
    },
    {
      "arxiv_id": "2403.16112v1",
      "title": "Opportunities and challenges in the application of large artificial intelligence models in radiology",
      "title_zh": "大型人工智能模型在放射学中的应用机遇与挑战",
      "authors": [
        "Liangrui Pan",
        "Zhenyu Zhao",
        "Ying Lu",
        "Kewei Tang",
        "Liyong Fu",
        "Qingchun Liang",
        "Shaoliang Peng"
      ],
      "abstract": "Influenced by ChatGPT, artificial intelligence (AI) large models have\nwitnessed a global upsurge in large model research and development. As people\nenjoy the convenience by this AI large model, more and more large models in\nsubdivided fields are gradually being proposed, especially large models in\nradiology imaging field. This article first introduces the development history\nof large models, technical details, workflow, working principles of multimodal\nlarge models and working principles of video generation large models. Secondly,\nwe summarize the latest research progress of AI large models in radiology\neducation, radiology report generation, applications of unimodal and multimodal\nradiology. Finally, this paper also summarizes some of the challenges of large\nAI models in radiology, with the aim of better promoting the rapid revolution\nin the field of radiography.",
      "tldr_zh": "本论文探讨了 AI 大模型（如 ChatGPT 影响下的大模型）在放射学领域的机会和挑战，介绍了大模型的发展历史、技术细节、工作流程，以及多模态 large models 和 video generation large models 的工作原理。论文总结了这些模型在放射学教育、放射学报告生成、单模态和多模态放射学应用中的最新研究进展。最终，它指出了 AI 大模型在放射学中面临的挑战，如潜在的局限性和伦理问题，以促进该领域的快速变革。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.16112v1",
      "published_date": "2024-03-24 12:05:23 UTC",
      "updated_date": "2024-03-24 12:05:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:24:52.119716"
    },
    {
      "arxiv_id": "2403.16108v2",
      "title": "A Transformer approach for Electricity Price Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Oscar Llorente",
        "Jose Portela"
      ],
      "abstract": "This paper presents a novel approach to electricity price forecasting (EPF)\nusing a pure Transformer model. As opposed to other alternatives, no other\nrecurrent network is used in combination to the attention mechanism. Hence,\nshowing that the attention layer is enough for capturing the temporal patterns.\nThe paper also provides fair comparison of the models using the open-source EPF\ntoolbox and provide the code to enhance reproducibility and transparency in EPF\nresearch. The results show that the Transformer model outperforms traditional\nmethods, offering a promising solution for reliable and sustainable power\nsystem operation.",
      "tldr_zh": "本文提出了一种纯 Transformer 模型用于电价预测（EPF），通过注意力机制捕捉时间模式，而不依赖其他循环网络，展示了其独立处理时间序列的能力。作者使用开源 EPF 工具箱进行了公平比较，并提供代码以提高研究的透明度和可重复性。实验结果表明，Transformer 模型的表现优于传统方法，为可靠和可持续的电力系统操作提供了有前景的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "7 pages",
      "pdf_url": "http://arxiv.org/pdf/2403.16108v2",
      "published_date": "2024-03-24 11:52:39 UTC",
      "updated_date": "2024-03-30 23:46:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:25:02.574230"
    },
    {
      "arxiv_id": "2403.16101v3",
      "title": "Public Perceptions of Fairness Metrics Across Borders",
      "title_zh": "公众对公平度指标的认知：跨越国界",
      "authors": [
        "Yuya Sasaki",
        "Sohei Tokuno",
        "Haruka Maeda",
        "Kazuki Nakajima",
        "Osamu Sakura",
        "George Fletcher",
        "Mykola Pechenizkiy",
        "Panagiotis Karras",
        "Irina Shklovski"
      ],
      "abstract": "Which fairness metrics are appropriately applicable in your contexts? There\nmay be instances of discordance regarding the perception of fairness, even when\nthe outcomes comply with established fairness metrics. Several\nquestionnaire-based surveys have been conducted to evaluate fairness metrics\nwith human perceptions of fairness. However, these surveys were limited in\nscope, including only a few hundred participants within a single country. In\nthis study, we conduct an international survey to evaluate public perceptions\nof various fairness metrics in decision-making scenarios. We collected\nresponses from 1,000 participants in each of China, France, Japan, and the\nUnited States, amassing a total of 4,000 participants, to analyze the\npreferences of fairness metrics. Our survey consists of three distinct\nscenarios paired with four fairness metrics. This investigation explores the\nrelationship between personal attributes and the choice of fairness metrics,\nuncovering a significant influence of national context on these preferences.",
      "tldr_zh": "这篇论文探讨了不同国家公众对公平度量标准的认知差异，通过国际调查评估哪些度量标准更适用于特定语境。研究方法包括针对中国、法国、日本和美国的各1000名参与者（共4000人）进行问卷调查，每个场景配以三种决策情境和四种fairness metrics。结果显示，个人属性和国家背景显著影响fairness metrics的偏好，突显了跨境认知的差异，为更具文化敏感性的决策系统设计提供了重要洞见。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.16101v3",
      "published_date": "2024-03-24 11:33:18 UTC",
      "updated_date": "2025-05-08 12:50:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:25:16.238917"
    },
    {
      "arxiv_id": "2403.16100v1",
      "title": "Specifying Agent Ethics (Blue Sky Ideas)",
      "title_zh": "翻译失败",
      "authors": [
        "Louise A. Dennis",
        "Michael Fisher"
      ],
      "abstract": "We consider the question of what properties a Machine Ethics system should\nhave. This question is complicated by the existence of ethical dilemmas with no\nagreed upon solution. We provide an example to motivate why we do not believe\nfalling back on the elicitation of values from stakeholders is sufficient to\nguarantee correctness of such systems. We go on to define two broad categories\nof ethical property that have arisen in our own work and present a challenge to\nthe community to approach this question in a more systematic way.",
      "tldr_zh": "该论文探讨了机器伦理系统应具备的属性，强调伦理困境（ethical dilemmas）缺乏统一解决方案。作者通过一个例子说明，仅依赖从利益相关者那里获取价值观（elicitation of values from stakeholders）不足以保证系统的正确性。他们定义了两种广泛的伦理属性类别（broad categories of ethical property），并向社区提出更系统地研究此问题的挑战，以推进机器伦理领域的进展。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "To appear in Coordination, Organizations, Institutions, Norms and\n  Ethics for Governance of Multi-Agent Systems 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.16100v1",
      "published_date": "2024-03-24 11:32:43 UTC",
      "updated_date": "2024-03-24 11:32:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:25:25.639701"
    },
    {
      "arxiv_id": "2403.16097v2",
      "title": "Can Language Models Pretend Solvers? Logic Code Simulation with LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Minyu Chen",
        "Guoqiang Li",
        "Ling-I Wu",
        "Ruibang Liu",
        "Yuxin Su",
        "Xi Chang",
        "Jianxin Xue"
      ],
      "abstract": "Transformer-based large language models (LLMs) have demonstrated significant\npotential in addressing logic problems. capitalizing on the great capabilities\nof LLMs for code-related activities, several frameworks leveraging logical\nsolvers for logic reasoning have been proposed recently. While existing\nresearch predominantly focuses on viewing LLMs as natural language logic\nsolvers or translators, their roles as logic code interpreters and executors\nhave received limited attention. This study delves into a novel aspect, namely\nlogic code simulation, which forces LLMs to emulate logical solvers in\npredicting the results of logical programs. To further investigate this novel\ntask, we formulate our three research questions: Can LLMs efficiently simulate\nthe outputs of logic codes? What strength arises along with logic code\nsimulation? And what pitfalls? To address these inquiries, we curate three\nnovel datasets tailored for the logic code simulation task and undertake\nthorough experiments to establish the baseline performance of LLMs in code\nsimulation. Subsequently, we introduce a pioneering LLM-based code simulation\ntechnique, Dual Chains of Logic (DCoL). This technique advocates a dual-path\nthinking approach for LLMs, which has demonstrated state-of-the-art performance\ncompared to other LLM prompt strategies, achieving a notable improvement in\naccuracy by 7.06% with GPT-4-Turbo.",
      "tldr_zh": "这篇论文探讨了大型语言模型 (LLMs) 是否能模拟逻辑求解器，专注于逻辑代码模拟任务，即让 LLMs 预测逻辑程序的输出，以填补现有研究对 LLMs 作为代码解释器角色的忽视。研究者提出了三个研究问题，构建了三个新数据集，并通过实验评估了 LLMs 的性能，同时引入了 Dual Chains of Logic (DCoL) 技术，该方法采用双路径思考策略。结果显示，DCoL 比其他提示策略取得了显著提升，使用 GPT-4-Turbo 时准确率提高了 7.06%，揭示了 LLMs 在逻辑推理中的优势和潜在缺陷。",
      "categories": [
        "cs.AI",
        "cs.LO",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "12 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.16097v2",
      "published_date": "2024-03-24 11:27:16 UTC",
      "updated_date": "2024-03-28 06:56:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:25:41.627330"
    },
    {
      "arxiv_id": "2403.16081v4",
      "title": "The Interplay of Learning, Analytics, and Artificial Intelligence in Education: A Vision for Hybrid Intelligence",
      "title_zh": "学习、分析和人工智能在教育中的相互作用：混合智能的愿景",
      "authors": [
        "Mutlu Cukurova"
      ],
      "abstract": "This paper presents a multi-dimensional view of AI's role in learning and\neducation, emphasizing the intricate interplay between AI, analytics, and the\nlearning processes. Here, I challenge the prevalent narrow conceptualisation of\nAI as tools, as exemplified in generative AI tools, and argue for the\nimportance of alternative conceptualisations of AI for achieving human-AI\nhybrid intelligence. I highlight the differences between human intelligence and\nartificial information processing, the importance of hybrid human-AI systems to\nextend human cognition, and posit that AI can also serve as an instrument for\nunderstanding human learning. Early learning sciences and AI in Education\nresearch (AIED), which saw AI as an analogy for human intelligence, have\ndiverged from this perspective, prompting a need to rekindle this connection.\nThe paper presents three unique conceptualisations of AI: the externalization\nof human cognition, the internalization of AI models to influence human mental\nmodels, and the extension of human cognition via tightly coupled human-AI\nhybrid intelligence systems. Examples from current research and practice are\nexamined as instances of the three conceptualisations in education,\nhighlighting the potential value and limitations of each conceptualisation for\neducation, as well as the perils of overemphasis on externalising human\ncognition. The paper concludes with advocacy for a broader approach to AIED\nthat goes beyond considerations on the design and development of AI, but also\nincludes educating people about AI and innovating educational systems to remain\nrelevant in an AI-ubiquitous world.",
      "tldr_zh": "这篇论文探讨了 AI 在教育中的多维作用，强调 AI、analytics 和学习过程的互动，挑战将 AI 仅视为工具（如生成式 AI）的狭隘概念，转而主张通过人类-AI 混合智能（Hybrid Intelligence）扩展人类认知。作者提出三种 AI 概念化：外部化人类认知、内部化 AI 模型以影响人类心理模型，以及通过紧密耦合的混合系统增强认知，并通过教育领域的实际例子分析了这些概念的价值和潜在风险。论文呼吁更广泛的 AI in Education (AIED) 方针，不仅关注 AI 的设计开发，还包括教育公众关于 AI 的知识并创新教育系统，以适应 AI 普及的时代。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "20 pages, 7 figures, this paper is based on the keynote talk given by\n  the author at the ACM International Conference on Learning Analytics &\n  Knowledge (LAK) 2024 in Kyoto, Japan.\n  https://www.solaresearch.org/events/lak/lak24/keynotes/",
      "pdf_url": "http://arxiv.org/pdf/2403.16081v4",
      "published_date": "2024-03-24 10:07:46 UTC",
      "updated_date": "2024-07-08 13:38:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:25:53.634793"
    },
    {
      "arxiv_id": "2403.16071v2",
      "title": "Landmark-Guided Cross-Speaker Lip Reading with Mutual Information Regularization",
      "title_zh": "翻译失败",
      "authors": [
        "Linzhi Wu",
        "Xingyu Zhang",
        "Yakun Zhang",
        "Changyan Zheng",
        "Tiejun Liu",
        "Liang Xie",
        "Ye Yan",
        "Erwei Yin"
      ],
      "abstract": "Lip reading, the process of interpreting silent speech from visual lip\nmovements, has gained rising attention for its wide range of realistic\napplications. Deep learning approaches greatly improve current lip reading\nsystems. However, lip reading in cross-speaker scenarios where the speaker\nidentity changes, poses a challenging problem due to inter-speaker variability.\nA well-trained lip reading system may perform poorly when handling a brand new\nspeaker. To learn a speaker-robust lip reading model, a key insight is to\nreduce visual variations across speakers, avoiding the model overfitting to\nspecific speakers. In this work, in view of both input visual clues and latent\nrepresentations based on a hybrid CTC/attention architecture, we propose to\nexploit the lip landmark-guided fine-grained visual clues instead of\nfrequently-used mouth-cropped images as input features, diminishing\nspeaker-specific appearance characteristics. Furthermore, a max-min mutual\ninformation regularization approach is proposed to capture speaker-insensitive\nlatent representations. Experimental evaluations on public lip reading datasets\ndemonstrate the effectiveness of the proposed approach under the intra-speaker\nand inter-speaker conditions.",
      "tldr_zh": "本研究针对跨说话者（cross-speaker）唇读（lip reading）问题，提出一种基于唇部 landmarks 引导的细粒度视觉线索方法，以减少说话者间的外貌差异，避免模型过拟合特定说话者。该方法结合混合 CTC/attention 架构，并引入 max-min mutual information regularization 技术，来捕获不敏感于说话者的潜在表示，从而提升唇读系统的鲁棒性。在公开数据集上的实验结果显示，该方法在同一说话者（intra-speaker）和不同说话者条件下均表现出色，有效提高了唇读性能。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.MM"
      ],
      "primary_category": "cs.AI",
      "comment": "To appear in LREC-COLING 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.16071v2",
      "published_date": "2024-03-24 09:18:21 UTC",
      "updated_date": "2024-05-02 08:53:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:26:02.307292"
    },
    {
      "arxiv_id": "2403.16067v5",
      "title": "Adversarial Guided Diffusion Models for Adversarial Purification",
      "title_zh": "翻译失败",
      "authors": [
        "Guang Lin",
        "Zerui Tao",
        "Jianhai Zhang",
        "Toshihisa Tanaka",
        "Qibin Zhao"
      ],
      "abstract": "Diffusion model (DM) based adversarial purification (AP) has proven to be a\npowerful defense method that can remove adversarial perturbations and generate\na purified example without threats. In principle, the pre-trained DMs can only\nensure that purified examples conform to the same distribution of the training\ndata, but it may inadvertently compromise the semantic information of input\nexamples, leading to misclassification of purified examples. Recent\nadvancements introduce guided diffusion techniques to preserve semantic\ninformation while removing the perturbations. However, these guidances often\nrely on distance measures between purified examples and diffused examples,\nwhich can also preserve perturbations in purified examples. To further unleash\nthe robustness power of DM-based AP, we propose an adversarial guided diffusion\nmodel (AGDM) by introducing a novel adversarial guidance that contains\nsufficient semantic information but does not explicitly involve adversarial\nperturbations. The guidance is modeled by an auxiliary neural network obtained\nwith adversarial training, considering the distance in the latent\nrepresentations rather than at the pixel-level values. Extensive experiments\nare conducted on CIFAR-10, CIFAR-100 and ImageNet to demonstrate that our\nmethod is effective for simultaneously maintaining semantic information and\nremoving the adversarial perturbations. In addition, comprehensive comparisons\nshow that our method significantly enhances the robustness of existing DM-based\nAP, with an average robust accuracy improved by up to 7.30% on CIFAR-10.",
      "tldr_zh": "该研究针对扩散模型(DM)基于的对抗净化(Adversarial Purification, AP)方法存在的语义信息丢失问题，提出了一种新型Adversarial Guided Diffusion Models (AGDM)。AGDM引入一个通过对抗训练得到的辅助神经网络作为引导，基于潜在表示的距离来移除对抗扰动，同时保留输入样本的语义信息，避免了传统引导方法可能保留扰动的缺点。在CIFAR-10、CIFAR-100和ImageNet数据集上的实验表明，该方法有效提升了鲁棒性，相比现有DM-based AP方法，在CIFAR-10上平均鲁棒准确率提高了7.30%。这项创新为对抗攻击防御提供了更可靠的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.16067v5",
      "published_date": "2024-03-24 08:34:08 UTC",
      "updated_date": "2025-03-11 08:43:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:26:15.274730"
    },
    {
      "arxiv_id": "2403.16066v2",
      "title": "A Temporal Graph Network Framework for Dynamic Recommendation",
      "title_zh": "翻译失败",
      "authors": [
        "Yejin Kim",
        "Youngbin Lee",
        "Vincent Yuan",
        "Annika Lee",
        "Yongjae Lee"
      ],
      "abstract": "Recommender systems, crucial for user engagement on platforms like e-commerce\nand streaming services, often lag behind users' evolving preferences due to\nstatic data reliance. After Temporal Graph Networks (TGNs) were proposed,\nvarious studies have shown that TGN can significantly improve situations where\nthe features of nodes and edges dynamically change over time. However, despite\nits promising capabilities, it has not been directly applied in recommender\nsystems to date. Our study bridges this gap by directly implementing Temporal\nGraph Networks (TGN) in recommender systems, a first in this field. Using\nreal-world datasets and a range of graph and history embedding methods, we show\nTGN's adaptability, confirming its effectiveness in dynamic recommendation\nscenarios.",
      "tldr_zh": "该研究针对推荐系统依赖静态数据而无法适应用户偏好动态变化的问题，首次将 Temporal Graph Networks (TGN) 直接应用于动态推荐框架中。研究利用真实世界数据集和多种图嵌入及历史嵌入方法，展示了 TGN 在处理节点和边动态变化时的适应性。通过实验验证，TGN 证明了其在动态推荐场景中的有效性，有望提升电商和流媒体平台的用户参与度。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Presented at the AAAI 2024 Workshop on Recommendation Ecosystems:\n  Modeling, Optimization and Incentive Design\n  (https://sites.google.com/view/recommender-ecosystems/home)",
      "pdf_url": "http://arxiv.org/pdf/2403.16066v2",
      "published_date": "2024-03-24 08:33:13 UTC",
      "updated_date": "2024-12-21 10:42:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:26:25.750887"
    },
    {
      "arxiv_id": "2403.16056v3",
      "title": "Qibo: A Large Language Model for Traditional Chinese Medicine",
      "title_zh": "Qibo: 用于传统中医的大语言模型",
      "authors": [
        "Heyi Zhang",
        "Xin Wang",
        "Zhaopeng Meng",
        "Zhe Chen",
        "Pengwei Zhuang",
        "Yongzhe Jia",
        "Dawei Xu",
        "Wenbin Guo"
      ],
      "abstract": "Large Language Models (LLMs) has made significant progress in a number of\nprofessional fields, including medicine, law, and finance. However, in\ntraditional Chinese medicine (TCM), there are challenges such as the essential\ndifferences between theory and modern medicine, the lack of specialized corpus\nresources, and the fact that relying only on supervised fine-tuning may lead to\noverconfident predictions. To address these challenges, we propose a two-stage\ntraining approach that combines continuous pre-training and supervised\nfine-tuning. A notable contribution of our study is the processing of a 2GB\ncorpus dedicated to TCM, constructing pre-training and instruction fine-tuning\ndatasets for TCM, respectively. In addition, we have developed Qibo-Benchmark,\na tool that evaluates the performance of LLM in the TCM on multiple dimensions,\nincluding subjective, objective, and three TCM NLP tasks. The medical LLM\ntrained with our pipeline, named $\\textbf{Qibo}$, exhibits significant\nperformance boosts. Compared to the baselines, the average subjective win rate\nis 63%, the average objective accuracy improved by 23% to 58%, and the Rouge-L\nscores for the three TCM NLP tasks are 0.72, 0.61, and 0.55. Finally, we\npropose a pipline to apply Qibo to TCM consultation and demonstrate the model\nperformance through the case study.",
      "tldr_zh": "这篇论文针对传统中医(TCM)领域的挑战，如理论差异、语料缺乏和监督微调导致的过度自信问题，提出了一种结合连续预训练和监督微调的两阶段训练方法。研究团队处理了2GB的TCM专用语料，构建了预训练和指令微调数据集，并开发了Qibo-Benchmark工具，用于多维度评估LLM在TCM的主观、客观指标和三个NLP任务。训练得到的Qibo模型表现出显著性能提升，与基线相比，主观胜率平均达63%，客观准确率从23%提高到58%，且三个TCM NLP任务的Rouge-L分数分别为0.72、0.61和0.55。最后，论文展示了将Qibo应用于TCM咨询的管道，并通过案例研究验证其有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.16056v3",
      "published_date": "2024-03-24 07:48:05 UTC",
      "updated_date": "2024-06-22 05:43:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:26:41.243803"
    },
    {
      "arxiv_id": "2403.16043v1",
      "title": "Semantic Is Enough: Only Semantic Information For NeRF Reconstruction",
      "title_zh": "翻译失败",
      "authors": [
        "Ruibo Wang",
        "Song Zhang",
        "Ping Huang",
        "Donghai Zhang",
        "Wei Yan"
      ],
      "abstract": "Recent research that combines implicit 3D representation with semantic\ninformation, like Semantic-NeRF, has proven that NeRF model could perform\nexcellently in rendering 3D structures with semantic labels. This research aims\nto extend the Semantic Neural Radiance Fields (Semantic-NeRF) model by focusing\nsolely on semantic output and removing the RGB output component. We reformulate\nthe model and its training procedure to leverage only the cross-entropy loss\nbetween the model semantic output and the ground truth semantic images,\nremoving the colour data traditionally used in the original Semantic-NeRF\napproach. We then conduct a series of identical experiments using the original\nand the modified Semantic-NeRF model. Our primary objective is to obverse the\nimpact of this modification on the model performance by Semantic-NeRF, focusing\non tasks such as scene understanding, object detection, and segmentation. The\nresults offer valuable insights into the new way of rendering the scenes and\nprovide an avenue for further research and development in semantic-focused 3D\nscene understanding.",
      "tldr_zh": "本研究扩展了 Semantic-NeRF 模型，专注于仅使用语义信息进行 NeRF 重建，移除传统的 RGB 输出组件。研究者改进了模型训练过程，仅通过模型语义输出与真实语义图像之间的 cross-entropy loss 来优化模型。实验比较了原模型和修改后模型在场景理解、object detection 和 segmentation 等任务上的性能，结果显示这种语义焦点方法提供了新的见解，有助于推进语义导向的 3D 场景理解研究。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.16043v1",
      "published_date": "2024-03-24 07:04:08 UTC",
      "updated_date": "2024-03-24 07:04:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:26:52.805607"
    },
    {
      "arxiv_id": "2403.16023v2",
      "title": "RPMArt: Towards Robust Perception and Manipulation for Articulated Objects",
      "title_zh": "翻译失败",
      "authors": [
        "Junbo Wang",
        "Wenhai Liu",
        "Qiaojun Yu",
        "Yang You",
        "Liu Liu",
        "Weiming Wang",
        "Cewu Lu"
      ],
      "abstract": "Articulated objects are commonly found in daily life. It is essential that\nrobots can exhibit robust perception and manipulation skills for articulated\nobjects in real-world robotic applications. However, existing methods for\narticulated objects insufficiently address noise in point clouds and struggle\nto bridge the gap between simulation and reality, thus limiting the practical\ndeployment in real-world scenarios. To tackle these challenges, we propose a\nframework towards Robust Perception and Manipulation for Articulated Objects\n(RPMArt), which learns to estimate the articulation parameters and manipulate\nthe articulation part from the noisy point cloud. Our primary contribution is a\nRobust Articulation Network (RoArtNet) that is able to predict both joint\nparameters and affordable points robustly by local feature learning and point\ntuple voting. Moreover, we introduce an articulation-aware classification\nscheme to enhance its ability for sim-to-real transfer. Finally, with the\nestimated affordable point and articulation joint constraint, the robot can\ngenerate robust actions to manipulate articulated objects. After learning only\nfrom synthetic data, RPMArt is able to transfer zero-shot to real-world\narticulated objects. Experimental results confirm our approach's effectiveness,\nwith our framework achieving state-of-the-art performance in both noise-added\nsimulation and real-world environments. Code, data and more results can be\nfound on the project website at https://r-pmart.github.io.",
      "tldr_zh": "这篇论文提出了 RPMArt 框架，旨在提升机器人对 Articulated Objects 的鲁棒感知和操作能力，解决点云噪声以及模拟到现实转移的挑战。框架的核心是 Robust Articulation Network (RoArtNet)，通过局部特征学习和点元组投票来准确预测关节参数和可操作点，并引入 articulation-aware classification 方案以增强 sim-to-real 转移效果。实验结果显示，RPMArt 仅从合成数据学习后即可实现零样本转移，并在添加噪声的模拟环境和真实世界中达到最先进性能。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "8 pages, 7 figures, accepted by 2024 IEEE/RSJ International\n  Conference on Intelligent Robots and Systems (IROS 2024), project website at\n  https://r-pmart.github.io",
      "pdf_url": "http://arxiv.org/pdf/2403.16023v2",
      "published_date": "2024-03-24 05:55:39 UTC",
      "updated_date": "2024-09-28 04:13:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:27:08.512940"
    },
    {
      "arxiv_id": "2403.16016v1",
      "title": "Fill in the ____ (a Diffusion-based Image Inpainting Pipeline)",
      "title_zh": "翻译失败",
      "authors": [
        "Eyoel Gebre",
        "Krishna Saxena",
        "Timothy Tran"
      ],
      "abstract": "Image inpainting is the process of taking an image and generating lost or\nintentionally occluded portions. Inpainting has countless applications\nincluding restoring previously damaged pictures, restoring the quality of\nimages that have been degraded due to compression, and removing unwanted\nobjects/text. Modern inpainting techniques have shown remarkable ability in\ngenerating sensible completions for images with mask occlusions. In our paper,\nan overview of the progress of inpainting techniques will be provided, along\nwith identifying current leading approaches, focusing on their strengths and\nweaknesses. A critical gap in these existing models will be addressed, focusing\non the ability to prompt and control what exactly is generated. We will\nadditionally justify why we think this is the natural next progressive step\nthat inpainting models must take, and provide multiple approaches to\nimplementing this functionality. Finally, we will evaluate the results of our\napproaches by qualitatively checking whether they generate high-quality images\nthat correctly inpaint regions with the objects that they are instructed to\nproduce.",
      "tldr_zh": "该论文回顾了图像修复（Image Inpainting）技术的进展及其应用，如修复损坏图片和移除 unwanted objects，并分析了现有模型在生成内容提示和控制（prompt and control）方面的关键缺陷。作者提出了一种基于扩散模型（Diffusion-based）的图像修复管道，旨在通过多种实现方法来增强用户对生成内容的精确控制，认为这是修复技术发展的自然下一步。最终，通过定性评估，证明了新方法能生成高质量图像，并准确修复指定区域。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.16016v1",
      "published_date": "2024-03-24 05:26:55 UTC",
      "updated_date": "2024-03-24 05:26:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:27:18.387057"
    },
    {
      "arxiv_id": "2403.16004v1",
      "title": "A Federated Parameter Aggregation Method for Node Classification Tasks with Different Graph Network Structures",
      "title_zh": "一种联邦参数聚合方法，用于不同图网络结构下的节点分类任务",
      "authors": [
        "Hao Song",
        "Jiacheng Yao",
        "Zhengxi Li",
        "Shaocong Xu",
        "Shibo Jin",
        "Jiajun Zhou",
        "Chenbo Fu",
        "Qi Xuan",
        "Shanqing Yu"
      ],
      "abstract": "Over the past few years, federated learning has become widely used in various\nclassical machine learning fields because of its collaborative ability to train\ndata from multiple sources without compromising privacy. However, in the area\nof graph neural networks, the nodes and network structures of graphs held by\nclients are different in many practical applications, and the aggregation\nmethod that directly shares model gradients cannot be directly applied to this\nscenario. Therefore, this work proposes a federated aggregation method FLGNN\napplied to various graph federation scenarios and investigates the aggregation\neffect of parameter sharing at each layer of the graph neural network model.\nThe effectiveness of the federated aggregation method FLGNN is verified by\nexperiments on real datasets. Additionally, for the privacy security of FLGNN,\nthis paper designs membership inference attack experiments and differential\nprivacy defense experiments. The results show that FLGNN performs good\nrobustness, and the success rate of privacy theft is further reduced by adding\ndifferential privacy defense methods.",
      "tldr_zh": "该论文针对图神经网络(Graph Neural Networks, GNNs)中的联邦学习场景，提出了一种联邦参数聚合方法FLGNN，以解决客户端持有不同图结构时无法直接共享模型梯度的难题。该方法研究了GNN模型各层参数共享的聚合效果，并通过真实数据集上的实验验证了其有效性。实验结果显示，FLGNN在节点分类任务中表现出色，同时在隐私安全方面，通过成员推理攻击实验和差分隐私(Differential Privacy)防御，证明了其良好的鲁棒性，并进一步降低了隐私泄露风险。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.16004v1",
      "published_date": "2024-03-24 04:23:43 UTC",
      "updated_date": "2024-03-24 04:23:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:27:31.540008"
    },
    {
      "arxiv_id": "2403.16003v2",
      "title": "Diverse Representation Embedding for Lifelong Person Re-Identification",
      "title_zh": "翻译失败",
      "authors": [
        "Shiben Liu",
        "Huijie Fan",
        "Qiang Wang",
        "Xiai Chen",
        "Zhi Han",
        "Yandong Tang"
      ],
      "abstract": "Lifelong Person Re-Identification (LReID) aims to continuously learn from\nsuccessive data streams, matching individuals across multiple cameras. The key\nchallenge for LReID is how to effectively preserve old knowledge while\nincrementally learning new information, which is caused by task-level domain\ngaps and limited old task datasets. Existing methods based on CNN backbone are\ninsufficient to explore the representation of each instance from different\nperspectives, limiting model performance on limited old task datasets and new\ntask datasets. Unlike these methods, we propose a Diverse Representations\nEmbedding (DRE) framework that first explores a pure transformer for LReID. The\nproposed DRE preserves old knowledge while adapting to new information based on\ninstance-level and task-level layout. Concretely, an Adaptive Constraint Module\n(ACM) is proposed to implement integration and push away operations between\nmultiple overlapping representations generated by transformer-based backbone,\nobtaining rich and discriminative representations for each instance to improve\nadaptive ability of LReID. Based on the processed diverse representations, we\npropose Knowledge Update (KU) and Knowledge Preservation (KP) strategies at the\ntask-level layout by introducing the adjustment model and the learner model. KU\nstrategy enhances the adaptive learning ability of learner models for new\ninformation under the adjustment model prior, and KP strategy preserves old\nknowledge operated by representation-level alignment and logit-level\nsupervision in limited old task datasets while guaranteeing the adaptive\nlearning information capacity of the LReID model. Compared to state-of-the-art\nmethods, our method achieves significantly improved performance in holistic,\nlarge-scale, and occluded datasets.",
      "tldr_zh": "该论文针对终身行人再识别(LReID)问题，提出了一种Diverse Representations Embedding (DRE)框架，利用纯Transformer架构来处理连续数据流中的知识保留和学习挑战。DRE框架包括Adaptive Constraint Module (ACM)，通过在Transformer-based backbone生成的多个重叠表示之间进行集成和推开操作，生成丰富且判别性的实例表示，以提升模型的适应能力。同时，框架引入Knowledge Update (KU)和Knowledge Preservation (KP)策略，分别通过adjustment model和learner model在任务级布局中增强新信息学习和旧知识保留。实验结果显示，该方法在整体、大规模和遮挡数据集上显著优于现有最先进方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "11 pages,7 Tables,3 Figures",
      "pdf_url": "http://arxiv.org/pdf/2403.16003v2",
      "published_date": "2024-03-24 04:22:37 UTC",
      "updated_date": "2024-04-02 13:31:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:27:43.310199"
    },
    {
      "arxiv_id": "2403.15994v1",
      "title": "Multi-Scale Spatio-Temporal Graph Convolutional Network for Facial Expression Spotting",
      "title_zh": "翻译失败",
      "authors": [
        "Yicheng Deng",
        "Hideaki Hayashi",
        "Hajime Nagahara"
      ],
      "abstract": "Facial expression spotting is a significant but challenging task in facial\nexpression analysis. The accuracy of expression spotting is affected not only\nby irrelevant facial movements but also by the difficulty of perceiving subtle\nmotions in micro-expressions. In this paper, we propose a Multi-Scale\nSpatio-Temporal Graph Convolutional Network (SpoT-GCN) for facial expression\nspotting. To extract more robust motion features, we track both short- and\nlong-term motion of facial muscles in compact sliding windows whose window\nlength adapts to the temporal receptive field of the network. This strategy,\ntermed the receptive field adaptive sliding window strategy, effectively\nmagnifies the motion features while alleviating the problem of severe head\nmovement. The subtle motion features are then converted to a facial graph\nrepresentation, whose spatio-temporal graph patterns are learned by a graph\nconvolutional network. This network learns both local and global features from\nmultiple scales of facial graph structures using our proposed facial local\ngraph pooling (FLGP). Furthermore, we introduce supervised contrastive learning\nto enhance the discriminative capability of our model for difficult-to-classify\nframes. The experimental results on the SAMM-LV and CAS(ME)^2 datasets\ndemonstrate that our method achieves state-of-the-art performance, particularly\nin micro-expression spotting. Ablation studies further verify the effectiveness\nof our proposed modules.",
      "tldr_zh": "本论文提出了一种多尺度时空图卷积网络（SpoT-GCN），用于解决面部表情识别中的挑战，包括无关面部动作干扰和微表情的微妙运动问题。该方法采用接收域自适应滑动窗口策略追踪短/长期面部肌肉运动，将其转换为面部图表示，并通过图卷积网络结合提出的面部局部图池化（FLGP）学习多尺度的局部和全局特征，同时引入监督对比学习提升对难分类帧的辨别能力。在SAMM-LV和CAS(ME)^2数据集上的实验表明，该方法在微表情识别方面达到最先进性能，消融研究进一步验证了各模块的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by FG2024",
      "pdf_url": "http://arxiv.org/pdf/2403.15994v1",
      "published_date": "2024-03-24 03:10:39 UTC",
      "updated_date": "2024-03-24 03:10:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:27:55.142227"
    },
    {
      "arxiv_id": "2403.15989v2",
      "title": "Knowledge-guided Machine Learning: Current Trends and Future Prospects",
      "title_zh": "翻译失败",
      "authors": [
        "Anuj Karpatne",
        "Xiaowei Jia",
        "Vipin Kumar"
      ],
      "abstract": "This paper presents an overview of scientific modeling and discusses the\ncomplementary strengths and weaknesses of ML methods for scientific modeling in\ncomparison to process-based models. It also provides an introduction to the\ncurrent state of research in the emerging field of scientific knowledge-guided\nmachine learning (KGML) that aims to use both scientific knowledge and data in\nML frameworks to achieve better generalizability, scientific consistency, and\nexplainability of results. We discuss different facets of KGML research in\nterms of the type of scientific knowledge used, the form of knowledge-ML\nintegration explored, and the method for incorporating scientific knowledge in\nML. We also discuss some of the common categories of use cases in environmental\nsciences where KGML methods are being developed, using illustrative examples in\neach category.",
      "tldr_zh": "这篇论文概述了科学建模中机器学习（ML）方法与基于过程模型的优缺点，并介绍了科学知识引导机器学习（KGML）这一新兴领域，该领域旨在通过整合科学知识和数据来提升 ML 的泛化性、科学一致性和可解释性。论文讨论了 KGML 的关键方面，包括使用的科学知识类型、知识与 ML 集成的形式，以及知识整合的方法。论文还通过环境科学中的示例，阐述了 KGML 在不同用例类别中的应用前景。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.15989v2",
      "published_date": "2024-03-24 02:54:46 UTC",
      "updated_date": "2024-05-01 20:57:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:28:06.192932"
    },
    {
      "arxiv_id": "2404.00039v1",
      "title": "MicroHD: An Accuracy-Driven Optimization of Hyperdimensional Computing Algorithms for TinyML systems",
      "title_zh": "翻译失败",
      "authors": [
        "Flavio Ponzina",
        "Tajana Rosing"
      ],
      "abstract": "Hyperdimensional computing (HDC) is emerging as a promising AI approach that\ncan effectively target TinyML applications thanks to its lightweight computing\nand memory requirements. Previous works on HDC showed that limiting the\nstandard 10k dimensions of the hyperdimensional space to much lower values is\npossible, reducing even more HDC resource requirements. Similarly, other\nstudies demonstrated that binary values can be used as elements of the\ngenerated hypervectors, leading to significant efficiency gains at the cost of\nsome degree of accuracy degradation. Nevertheless, current optimization\nattempts do not concurrently co-optimize HDC hyper-parameters, and accuracy\ndegradation is not directly controlled, resulting in sub-optimal HDC models\nproviding several applications with unacceptable output qualities. In this\nwork, we propose MicroHD, a novel accuracy-driven HDC optimization approach\nthat iteratively tunes HDC hyper-parameters, reducing memory and computing\nrequirements while ensuring user-defined accuracy levels. The proposed method\ncan be applied to HDC implementations using different encoding functions,\ndemonstrates good scalability for larger HDC workloads, and achieves\ncompression and efficiency gains up to 200x when compared to baseline\nimplementations for accuracy degradations lower than 1%.",
      "tldr_zh": "这篇论文针对 Hyperdimensional Computing (HDC) 在 TinyML 系统中的优化问题，提出了一种新型准确性驱动的方法 MicroHD。该方法通过迭代调整 HDC 的 hyper-parameters，同时减少内存和计算需求，确保输出准确性保持在用户定义的水平。MicroHD 适用于不同 encoding functions，并展示了良好的可扩展性，在准确性下降小于 1% 的情况下，与基线实现相比，实现高达 200x 的压缩和效率提升。",
      "categories": [
        "cs.PF",
        "cs.AI",
        "cs.LG",
        "cs.NE",
        "math.OC"
      ],
      "primary_category": "cs.PF",
      "comment": "Accepted as a full paper by the tinyML Research Symposium 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.00039v1",
      "published_date": "2024-03-24 02:45:34 UTC",
      "updated_date": "2024-03-24 02:45:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:28:18.749960"
    },
    {
      "arxiv_id": "2403.15977v3",
      "title": "Towards Two-Stream Foveation-based Active Vision Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Timur Ibrayev",
        "Amitangshu Mukherjee",
        "Sai Aparna Aketi",
        "Kaushik Roy"
      ],
      "abstract": "Deep neural network (DNN) based machine perception frameworks process the\nentire input in a one-shot manner to provide answers to both \"what object is\nbeing observed\" and \"where it is located\". In contrast, the \"two-stream\nhypothesis\" from neuroscience explains the neural processing in the human\nvisual cortex as an active vision system that utilizes two separate regions of\nthe brain to answer the what and the where questions. In this work, we propose\na machine learning framework inspired by the \"two-stream hypothesis\" and\nexplore the potential benefits that it offers. Specifically, the proposed\nframework models the following mechanisms: 1) ventral (what) stream focusing on\nthe input regions perceived by the fovea part of an eye (foveation), 2) dorsal\n(where) stream providing visual guidance, and 3) iterative processing of the\ntwo streams to calibrate visual focus and process the sequence of focused image\npatches. The training of the proposed framework is accomplished by label-based\nDNN training for the ventral stream model and reinforcement learning for the\ndorsal stream model. We show that the two-stream foveation-based learning is\napplicable to the challenging task of weakly-supervised object localization\n(WSOL), where the training data is limited to the object class or its\nattributes. The framework is capable of both predicting the properties of an\nobject and successfully localizing it by predicting its bounding box. We also\nshow that, due to the independent nature of the two streams, the dorsal model\ncan be applied on its own to unseen images to localize objects from different\ndatasets.",
      "tldr_zh": "本研究提出了一种受“two-stream hypothesis”启发的机器学习框架，用于实现基于foveation的主动视觉学习。该框架包括ventral stream（专注于物体识别，通过fovea感知的输入区域进行处理）和dorsal stream（提供视觉指导以定位物体），并通过两流的迭代处理来校准焦点和序列图像补丁。训练方法采用基于标签的DNN训练ventral stream，并使用reinforcement learning训练dorsal stream。在weakly-supervised object localization（WSOL）任务中，该框架能准确预测物体属性并定位其bounding box，且dorsal stream模型可独立应用于未见数据集，实现跨数据集的物体定位。实验结果证明了该框架在资源有限场景下的有效性和鲁棒性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted version of the article, 18 pages, 14 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.15977v3",
      "published_date": "2024-03-24 01:20:08 UTC",
      "updated_date": "2024-04-20 20:19:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:28:32.265706"
    },
    {
      "arxiv_id": "2403.15974v1",
      "title": "CBGT-Net: A Neuromimetic Architecture for Robust Classification of Streaming Data",
      "title_zh": "翻译失败",
      "authors": [
        "Shreya Sharma",
        "Dana Hughes",
        "Katia Sycara"
      ],
      "abstract": "This paper describes CBGT-Net, a neural network model inspired by the\ncortico-basal ganglia-thalamic (CBGT) circuits found in mammalian brains.\nUnlike traditional neural network models, which either generate an output for\neach provided input, or an output after a fixed sequence of inputs, the\nCBGT-Net learns to produce an output after a sufficient criteria for evidence\nis achieved from a stream of observed data. For each observation, the CBGT-Net\ngenerates a vector that explicitly represents the amount of evidence the\nobservation provides for each potential decision, accumulates the evidence over\ntime, and generates a decision when the accumulated evidence exceeds a\npre-defined threshold. We evaluate the proposed model on two image\nclassification tasks, where models need to predict image categories based on a\nstream of small patches extracted from the image. We show that the CBGT-Net\nprovides improved accuracy and robustness compared to models trained to\nclassify from a single patch, and models leveraging an LSTM layer to classify\nfrom a fixed sequence length of patches.",
      "tldr_zh": "本论文提出 CBGT-Net，一种受哺乳动物大脑 cortico-basal ganglia-thalamic (CBGT) 电路启发的神经网络架构，旨在处理流式数据的鲁棒分类。不同于传统模型，CBGT-Net 通过为每个观察生成证据向量、累积证据并在超过预定义阈值时才输出决策，从而实现更精确的响应。实验在两个图像分类任务上评估，结果显示 CBGT-Net 比基于单个补丁的模型和使用 LSTM 层的固定序列模型提供了更高的准确性和鲁棒性。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.15974v1",
      "published_date": "2024-03-24 00:46:40 UTC",
      "updated_date": "2024-03-24 00:46:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:28:44.821790"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 50,
  "processed_papers_count": 50,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-17T18:29:09.599507"
}