{
  "date": "2024-08-04",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-08-04 的 arXiv 中文 TLDR 快报！今天 arXiv 的论文主要聚焦于人工智能和机器学习领域，包括强化学习、LLM 在推荐和情感分析中的优化、计算机视觉的创新，以及软件安全和多模态模型的应用，其中 SelfBC 和 LeapRec 等 LLM 相关论文最为引人注目，展示了在复杂场景下的高效性能，同时涉及知名学者如 Julian McAuley 的工作。\n\n### 重点论文讨论\n我们先聊聊今天最重要和话题度高的论文，特别是那些涉及 LLM 和强化学习的创新，这些领域正推动 AI 应用边界。接下来，快速掠过其他较为专业的或次要论文。\n\n1. **SelfBC: Self Behavior Cloning for Offline Reinforcement Learning（SelfBC: 自我行为克隆用于离线强化学习）**  \n   作者包括 Yang Liu 等，这篇论文提出了一种动态策略约束方法，通过指数移动平均生成样本，避免了传统方法的过度保守性。主要贡献是理论证明了策略的单调改进，并在 D4RL MuJoCo 数据集上实现了最先进性能，提升了离线强化学习的鲁棒性。\n\n2. **Calibration-Disentangled Learning and Relevance-Prioritized Reranking for Calibrated Sequential Recommendation（校准解耦学习和相关性优先重排序用于校准序列推荐）**  \n   作者包括知名学者 Julian McAuley，这篇 CIKM '24 论文引入 LeapRec 框架，结合校准解耦损失和重排序策略，解决了序列推荐中相关性和校准的冲突。主要发现是通过实验验证了其在四个真实数据集上的优越性能，提升了用户兴趣多样性的推荐效果。\n\n3. **ARVO: Atlas of Reproducible Vulnerabilities for Open Source Software（ARVO: 开源软件可重现漏洞图集）**  \n   作者团队包括 Brendan Dolan-Gavitt 等知名专家，这篇论文构建了包含 5000+ 内存漏洞的数据集，支持自动重建和修复。主要贡献是通过案例研究展示了其在 LLM 修复和零日漏洞识别中的价值，远超 Google 的 OSV 方法。\n\n4. **Generative Retrieval with Few-shot Indexing（少样本索引的生成式检索）**  \n   这篇论文提出 Few-Shot GR 框架，使用 LLM 提示生成文档 ID，无需训练即可实现高效检索。主要发现是其在少样本场景下超越了传统生成式检索方法，利用预训练知识处理动态语料库。\n\n5. **Analyzing Cultural Representations of Emotions in LLMs through Mixed Emotion Survey（通过混合情绪调查分析 LLM 中的文化情感表征）**  \n   作者包括 Agata Lapedriza，这篇 ACII 2024 论文考察了 LLM 在多语言中的情感偏差，发现模型对东亚语言的情感响应更相似，但整体与人类文化偏差有限。主要贡献是强调了语言比用户背景更影响 LLM 输出，提供文化偏差评估的实用方法。\n\n6. **Value-Based Rationales Improve Social Experience: A Multiagent Simulation Study（基于价值的理性解释改善社交体验：多代理模拟研究）**  \n   这篇 ECAI 2024 论文提出 Exanna 框架，使用代理模拟显示，基于价值的决策和解释能提升冲突解决和隐私。主要发现是实验证明了其在多代理环境中的优势，适用于社会 dilemmma 建模。\n\n其他论文主题多样，但相对次要，我们快速掠过。以下是简要概述：\n\n- **VidModEx: Interpretable and Efficient Black Box Model Extraction for High-Dimensional Spaces（VidModEx: 用于高维空间的可解释高效黑盒模型提取）**  \n  改进了模型提取方法，使用 SHAP 提升 GAN 性能，在图像和视频分类中提高了 16-33% 的准确率。\n\n- **KAN-RCBEVDepth: A multi-modal fusion algorithm in object detection for autonomous driving（KAN-RCBEVDepth: 自动驾驶物体检测的多模态融合算法）**  \n  融合相机、LiDAR 和雷达数据，提升了自动驾驶检测准确性，ND Score 提升 17.1%。\n\n- **Mamba-Spike: Enhancing the Mamba Architecture with a Spiking Front-End for Efficient Temporal Data Processing（Mamba-Spike: 使用脉冲前端增强 Mamba 架构的时序数据处理）**  \n  结合脉冲神经网络和 Mamba 模型，提高了时序数据效率，在多个数据集上超越基线。\n\n- **ParkingE2E: Camera-based End-to-end Parking Network, from Images to Planning（ParkingE2E: 基于相机的端到端停车网络，从图像到规划）**  \n  使用模仿学习实现图像到路径规划，实车实验中停车成功率达 87.8%。\n\n其余论文如库存问题（模糊理论应用）、LLM 在交通事故分析中的使用，或软件安全数据集等，贡献在于特定领域优化，但不具广泛话题度，故从简不详述。如果您对某个领域感兴趣，可以进一步探索这些论文的核心术语和发现。明天见，继续追踪 arXiv 的最新动态！",
  "papers": [
    {
      "arxiv_id": "2408.02165v1",
      "title": "SelfBC: Self Behavior Cloning for Offline Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Shirong Liu",
        "Chenjia Bai",
        "Zixian Guo",
        "Hao Zhang",
        "Gaurav Sharma",
        "Yang Liu"
      ],
      "abstract": "Policy constraint methods in offline reinforcement learning employ additional\nregularization techniques to constrain the discrepancy between the learned\npolicy and the offline dataset. However, these methods tend to result in overly\nconservative policies that resemble the behavior policy, thus limiting their\nperformance. We investigate this limitation and attribute it to the static\nnature of traditional constraints. In this paper, we propose a novel dynamic\npolicy constraint that restricts the learned policy on the samples generated by\nthe exponential moving average of previously learned policies. By integrating\nthis self-constraint mechanism into off-policy methods, our method facilitates\nthe learning of non-conservative policies while avoiding policy collapse in the\noffline setting. Theoretical results show that our approach results in a nearly\nmonotonically improved reference policy. Extensive experiments on the D4RL\nMuJoCo domain demonstrate that our proposed method achieves state-of-the-art\nperformance among the policy constraint methods.",
      "tldr_zh": "本研究针对离线强化学习（Offline Reinforcement Learning）中，政策约束方法（Policy Constraint Methods）导致策略过于保守并限制性能的问题，提出了一种新型方法SelfBC（Self Behavior Cloning）。SelfBC 通过动态政策约束机制，将学习策略限制在之前策略的指数移动平均（Exponential Moving Average）生成样本上，从而实现非保守策略的学习，同时避免策略崩溃（Policy Collapse）。实验结果显示，在D4RL MuJoCo领域，该方法在政策约束方法中取得了最先进性能，且理论证明其参考策略几乎单调改进。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.02165v1",
      "published_date": "2024-08-04 23:23:48 UTC",
      "updated_date": "2024-08-04 23:23:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:44:38.017866"
    },
    {
      "arxiv_id": "2408.02156v1",
      "title": "Calibration-Disentangled Learning and Relevance-Prioritized Reranking for Calibrated Sequential Recommendation",
      "title_zh": "翻译失败",
      "authors": [
        "Hyunsik Jeon",
        "Se-eun Yoon",
        "Julian McAuley"
      ],
      "abstract": "Calibrated recommendation, which aims to maintain personalized proportions of\ncategories within recommendations, is crucial in practical scenarios since it\nenhances user satisfaction by reflecting diverse interests. However, achieving\ncalibration in a sequential setting (i.e., calibrated sequential\nrecommendation) is challenging due to the need to adapt to users' evolving\npreferences. Previous methods typically leverage reranking algorithms to\ncalibrate recommendations after training a model without considering the effect\nof calibration and do not effectively tackle the conflict between relevance and\ncalibration during the reranking process. In this work, we propose LeapRec\n(Calibration-Disentangled Learning and Relevance-Prioritized Reranking), a\nnovel approach for the calibrated sequential recommendation that addresses\nthese challenges. LeapRec consists of two phases, model training phase and\nreranking phase. In the training phase, a backbone model is trained using our\nproposed calibration-disentangled learning-to-rank loss, which optimizes\npersonalized rankings while integrating calibration considerations. In the\nreranking phase, relevant items are prioritized at the top of the list, with\nitems needed for calibration following later to address potential conflicts\nbetween relevance and calibration. Through extensive experiments on four\nreal-world datasets, we show that LeapRec consistently outperforms previous\nmethods in the calibrated sequential recommendation. Our code is available at\nhttps://github.com/jeon185/LeapRec.",
      "tldr_zh": "这篇论文针对校准顺序推荐（Calibrated Sequential Recommendation）问题，提出了一种新方法LeapRec，以平衡用户个性化类别比例和动态偏好适应。LeapRec分为两个阶段：模型训练阶段使用校准分离学习（Calibration-Disentangled Learning）损失函数来优化个性化排名，同时考虑校准因素；重新排序阶段则优先相关性（Relevance-Prioritized Reranking），将相关项目置顶并随后调整校准项目，以缓解两者冲突。在四个真实数据集上的广泛实验中，LeapRec consistently outperforms现有方法，证明了其有效性。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "Published at CIKM '24 as a full research paper",
      "pdf_url": "http://arxiv.org/pdf/2408.02156v1",
      "published_date": "2024-08-04 22:23:09 UTC",
      "updated_date": "2024-08-04 22:23:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:44:48.770433"
    },
    {
      "arxiv_id": "2408.02153v1",
      "title": "ARVO: Atlas of Reproducible Vulnerabilities for Open Source Software",
      "title_zh": "ARVO: 开源软件可重现漏洞图集",
      "authors": [
        "Xiang Mei",
        "Pulkit Singh Singaria",
        "Jordi Del Castillo",
        "Haoran Xi",
        "Abdelouahab",
        "Benchikh",
        "Tiffany Bao",
        "Ruoyu Wang",
        "Yan Shoshitaishvili",
        "Adam Doupé",
        "Hammond Pearce",
        "Brendan Dolan-Gavitt"
      ],
      "abstract": "High-quality datasets of real-world vulnerabilities are enormously valuable\nfor downstream research in software security, but existing datasets are\ntypically small, require extensive manual effort to update, and are missing\ncrucial features that such research needs. In this paper, we introduce ARVO: an\nAtlas of Reproducible Vulnerabilities in Open-source software. By sourcing\nvulnerabilities from C/C++ projects that Google's OSS-Fuzz discovered and\nimplementing a reliable re-compilation system, we successfully reproduce more\nthan 5,000 memory vulnerabilities across over 250 projects, each with a\ntriggering input, the canonical developer-written patch for fixing the\nvulnerability, and the ability to automatically rebuild the project from source\nand run it at its vulnerable and patched revisions. Moreover, our dataset can\nbe automatically updated as OSS-Fuzz finds new vulnerabilities, allowing it to\ngrow over time. We provide a thorough characterization of the ARVO dataset,\nshow that it can locate fixes more accurately than Google's own OSV\nreproduction effort, and demonstrate its value for future research through two\ncase studies: firstly evaluating real-world LLM-based vulnerability repair, and\nsecondly identifying over 300 falsely patched (still-active) zero-day\nvulnerabilities from projects improperly labeled by OSS-Fuzz.",
      "tldr_zh": "本研究引入了 ARVO，这是一个高质量的开源软件漏洞数据集，旨在解决现有数据集规模小、更新困难和功能缺失的问题。ARVO 通过从 Google's OSS-Fuzz 获取漏洞，并实现可靠的重新编译系统，成功再现了超过 5,000 个 C/C++ 项目中的内存漏洞，每个漏洞包括触发输入、开发人员修复补丁，以及自动从源代码重建和运行的能力；数据集还支持自动更新以适应新漏洞。实验结果显示，ARVO 比 Google's OSV 更准确地定位漏洞修复，并通过两个案例研究证明其价值：一是评估 LLM-based vulnerability repair 的效果，二是识别超过 300 个虚假修复的 zero-day vulnerabilities。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "14 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.02153v1",
      "published_date": "2024-08-04 22:13:14 UTC",
      "updated_date": "2024-08-04 22:13:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:45:00.783851"
    },
    {
      "arxiv_id": "2408.02152v1",
      "title": "Generative Retrieval with Few-shot Indexing",
      "title_zh": "基于少样本索引的生成式检索",
      "authors": [
        "Arian Askari",
        "Chuan Meng",
        "Mohammad Aliannejadi",
        "Zhaochun Ren",
        "Evangelos Kanoulas",
        "Suzan Verberne"
      ],
      "abstract": "Existing generative retrieval (GR) approaches rely on training-based\nindexing, i.e., fine-tuning a model to memorise the associations between a\nquery and the document identifier (docid) of a relevant document.\nTraining-based indexing has three limitations: high training overhead,\nunder-utilization of the pre-trained knowledge of large language models (LLMs),\nand challenges in adapting to a dynamic document corpus. To address the above\nissues, we propose a novel few-shot indexing-based GR framework (Few-Shot GR).\nIt has a novel few-shot indexing process, where we prompt an LLM to generate\ndocids for all documents in a corpus, ultimately creating a docid bank for the\nentire corpus. During retrieval, we feed a query to the same LLM and constrain\nit to generate a docid within the docid bank created during indexing, and then\nmap the generated docid back to its corresponding document. Few-Shot GR relies\nsolely on prompting an LLM without requiring any training, making it more\nefficient. Moreover, we devise few-shot indexing with one-to-many mapping to\nfurther enhance Few-Shot GR. Experiments show that Few-Shot GR achieves\nsuperior performance to state-of-the-art GR methods that require heavy\ntraining.",
      "tldr_zh": "该论文提出了一种名为Few-Shot GR的生成式检索(Generative Retrieval)框架，以解决现有方法依赖训练-based indexing的问题，包括高训练开销、未充分利用LLM的预训练知识以及适应动态语料库的挑战。框架采用少样本索引过程，通过提示LLM为语料库中的文档生成docid并创建docid bank，在检索时约束LLM为查询生成匹配的docid并映射回文档，从而实现无需训练的检索。实验结果显示，Few-Shot GR在性能上优于需要大量训练的现有GR方法，进一步通过one-to-many映射增强了其有效性。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "H.3.3"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.02152v1",
      "published_date": "2024-08-04 22:00:34 UTC",
      "updated_date": "2024-08-04 22:00:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:45:13.047171"
    },
    {
      "arxiv_id": "2408.02148v2",
      "title": "Environment Complexity and Nash Equilibria in a Sequential Social Dilemma",
      "title_zh": "环境复杂性与纳什均衡在顺序社会",
      "authors": [
        "Mustafa Yasir",
        "Andrew Howes",
        "Vasilios Mavroudis",
        "Chris Hicks"
      ],
      "abstract": "Multi-agent reinforcement learning (MARL) methods, while effective in\nzero-sum or positive-sum games, often yield suboptimal outcomes in general-sum\ngames where cooperation is essential for achieving globally optimal outcomes.\nMatrix game social dilemmas, which abstract key aspects of general-sum\ninteractions, such as cooperation, risk, and trust, fail to model the temporal\nand spatial dynamics characteristic of real-world scenarios. In response, our\nstudy extends matrix game social dilemmas into more complex, higher-dimensional\nMARL environments. We adapt a gridworld implementation of the Stag Hunt dilemma\nto more closely match the decision-space of a one-shot matrix game while also\nintroducing variable environment complexity. Our findings indicate that as\ncomplexity increases, MARL agents trained in these environments converge to\nsuboptimal strategies, consistent with the risk-dominant Nash equilibria\nstrategies found in matrix games. Our work highlights the impact of environment\ncomplexity on achieving optimal outcomes in higher-dimensional game-theoretic\nMARL environments.",
      "tldr_zh": "本研究探讨了环境复杂度对多智能体强化学习(MARL)代理在顺序社会困境中的Nash Equilibria影响，特别是在需要合作的一般和游戏中，MARL方法往往导致次优结果。研究者扩展了矩阵游戏社会困境，将其适应为更复杂的高维度环境，通过改编Stag Hunt困境的网格世界实现，并引入可变环境复杂度。实验发现，随着环境复杂度的增加，MARL代理趋向于收敛到风险主导的Nash Equilibria策略，而不是全局最优策略。该工作强调了环境复杂度在高维度游戏理论MARL环境中的关键作用，为改进合作决策提供了新见解。",
      "categories": [
        "cs.GT",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.GT",
      "comment": "Accepted to the 17th European Workshop on Reinforcement Learning\n  (EWRL)",
      "pdf_url": "http://arxiv.org/pdf/2408.02148v2",
      "published_date": "2024-08-04 21:27:36 UTC",
      "updated_date": "2024-08-08 16:16:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:45:25.736797"
    },
    {
      "arxiv_id": "2408.02143v1",
      "title": "Analyzing Cultural Representations of Emotions in LLMs through Mixed Emotion Survey",
      "title_zh": "通过混合情感调查分析 LLMs 中情感的文化表征",
      "authors": [
        "Shiran Dudy",
        "Ibrahim Said Ahmad",
        "Ryoko Kitajima",
        "Agata Lapedriza"
      ],
      "abstract": "Large Language Models (LLMs) have gained widespread global adoption,\nshowcasing advanced linguistic capabilities across multiple of languages. There\nis a growing interest in academia to use these models to simulate and study\nhuman behaviors. However, it is crucial to acknowledge that an LLM's\nproficiency in a specific language might not fully encapsulate the norms and\nvalues associated with its culture. Concerns have emerged regarding potential\nbiases towards Anglo-centric cultures and values due to the predominance of\nWestern and US-based training data. This study focuses on analyzing the\ncultural representations of emotions in LLMs, in the specific case of\nmixed-emotion situations. Our methodology is based on the studies of Miyamoto\net al. (2010), which identified distinctive emotional indicators in Japanese\nand American human responses. We first administer their mixed emotion survey to\nfive different LLMs and analyze their outputs. Second, we experiment with\ncontextual variables to explore variations in responses considering both\nlanguage and speaker origin. Thirdly, we expand our investigation to encompass\nadditional East Asian and Western European origin languages to gauge their\nalignment with their respective cultures, anticipating a closer fit. We find\nthat (1) models have limited alignment with the evidence in the literature; (2)\nwritten language has greater effect on LLMs' response than information on\nparticipants origin; and (3) LLMs responses were found more similar for East\nAsian languages than Western European languages.",
      "tldr_zh": "这篇论文通过混合情感调查分析了大型语言模型(LLMs)对不同文化情感表示的偏差，特别关注其可能偏向盎格鲁文化的倾向。研究方法基于Miyamoto et al. (2010)的研究，对五种LLMs进行调查，并探索语言和说话者来源等变量的影响，包括扩展到东亚和西欧语言。结果发现，LLMs与文献证据的契合度有限，书面语言对响应影响更大，且对东亚语言的响应更相似，而西欧语言表现出更大差异。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Was accepted to ACII 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.02143v1",
      "published_date": "2024-08-04 20:56:05 UTC",
      "updated_date": "2024-08-04 20:56:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:45:37.500024"
    },
    {
      "arxiv_id": "2408.02140v1",
      "title": "VidModEx: Interpretable and Efficient Black Box Model Extraction for High-Dimensional Spaces",
      "title_zh": "VidModEx：用于高维空间的可解释和高效黑盒模型提取",
      "authors": [
        "Somnath Sendhil Kumar",
        "Yuvaraj Govindarajulu",
        "Pavan Kulkarni",
        "Manojkumar Parmar"
      ],
      "abstract": "In the domain of black-box model extraction, conventional methods reliant on\nsoft labels or surrogate datasets struggle with scaling to high-dimensional\ninput spaces and managing the complexity of an extensive array of interrelated\nclasses. In this work, we present a novel approach that utilizes SHAP (SHapley\nAdditive exPlanations) to enhance synthetic data generation. SHAP quantifies\nthe individual contributions of each input feature towards the victim model's\noutput, facilitating the optimization of an energy-based GAN towards a\ndesirable output. This method significantly boosts performance, achieving a\n16.45% increase in the accuracy of image classification models and extending to\nvideo classification models with an average improvement of 26.11% and a maximum\nof 33.36% on challenging datasets such as UCF11, UCF101, Kinetics 400, Kinetics\n600, and Something-Something V2. We further demonstrate the effectiveness and\npractical utility of our method under various scenarios, including the\navailability of top-k prediction probabilities, top-k prediction labels, and\ntop-1 labels.",
      "tldr_zh": "本研究提出VidModEx，一种可解释且高效的黑盒模型提取方法，针对高维输入空间和复杂类别的挑战，使用SHAP（SHapley Additive exPlanations）量化输入特征对victim模型输出的贡献，并优化能量-based GAN来生成更有效的合成数据。该方法显著提升了模型提取性能，在图像分类模型上准确率提高16.45%，而在视频分类数据集（如UCF11、UCF101、Kinetics 400等）上，平均改善26.11%，最高达33.36%。实验结果证明，VidModEx在top-k预测概率、标签等各种场景下均表现出色，增强了黑盒模型提取的实用性和可扩展性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.02140v1",
      "published_date": "2024-08-04 20:38:45 UTC",
      "updated_date": "2024-08-04 20:38:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:45:50.480423"
    },
    {
      "arxiv_id": "2408.02117v2",
      "title": "Value-Based Rationales Improve Social Experience: A Multiagent Simulation Study",
      "title_zh": "翻译失败",
      "authors": [
        "Sz-Ting Tzeng",
        "Nirav Ajmeri",
        "Munindar P. Singh"
      ],
      "abstract": "We propose Exanna, a framework to realize agents that incorporate values in\ndecision making. An Exannaagent considers the values of itself and others when\nproviding rationales for its actions and evaluating the rationales provided by\nothers. Via multiagent simulation, we demonstrate that considering values in\ndecision making and producing rationales, especially for norm-deviating\nactions, leads to (1) higher conflict resolution, (2) better social experience,\n(3) higher privacy, and (4) higher flexibility.",
      "tldr_zh": "本研究提出Exanna框架，使代理在决策中融入自身和他人价值观，并为行动提供理由，尤其是针对违反规范的行为。通过多代理模拟实验，Exanna代理展示了更高的冲突解决能力、更优的社交体验、增强的隐私保护以及更大的灵活性。这些发现表明，基于价值观的理由生成可以显著提升多代理系统的社会互动效果。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.MA",
      "comment": "13 pages, 13 figures, 13 tables (and supplementary material with\n  reproducibility and additional results), accepted at ECAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.02117v2",
      "published_date": "2024-08-04 19:14:36 UTC",
      "updated_date": "2024-08-14 15:25:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:45:59.953733"
    },
    {
      "arxiv_id": "2408.02113v2",
      "title": "Diseño de sonido para producciones audiovisuales e historias sonoras en el aula. Hacia una docencia creativa mediante el uso de herramientas inteligentes",
      "title_zh": "翻译失败",
      "authors": [
        "Miguel Civit",
        "Francisco Cuadrado"
      ],
      "abstract": "This study aims to share a teaching experience teaching sound design for\naudiovisual productions and compares different projects tackled by students. It\nis not intended to be a comparative analysis of different types of teaching but\nrather an analysis of different problems observed in different profiles of\nstudents of the subject who study it in different grades. The world of audio\ncan be very interesting for a large part of the students, both those with\ncreative and technical inclinations. Musical creation and production,\nsynchronization with images, dubbing, etc. They are disciplines that are\ngenerally interesting but can have a very high barrier to entry due to their\ngreat technical complexity. Sometimes it can take weeks or even months for the\nuninitiated to begin to use audio editing programs with the necessary ease,\nwhich are not always particularly intuitive for students. Learning through the\nuse of PBL methodologies generates, in our experience, results much superior to\nthose that can be observed through the use of other teaching methods such as\nmaster classes. Students acquire technical skills while developing creative\nprojects in which they get personally involved. Despite everything mentioned\nabove, most interactions between teachers and students focus on aspects of\ntechnical correction. From different parameters in reverbs (such as pre-delay,\ndecay, modulation...) to how to correctly adjust compressors, noise gates,\netc.; The number of tools with which to work with audio is incredibly\nextensive, as well as many of its features that can present serious differences\ndepending on their manufacturers.",
      "tldr_zh": "这篇研究分享了在课堂上教授声音设计（Diseño de sonido）用于视听制作和声音故事的教学经验，通过比较不同年级学生的项目，分析了各种学生群体面临的问题。研究指出，声音设计领域虽对创意和技术型学生有吸引力，但其技术复杂性（如音频编辑程序的使用）往往造成高入门门槛，传统教学方法效率低下。采用基于项目的学习方法（PBL）显著提高了学生技术技能和创意参与度，尽管教学互动主要聚焦于技术修正，例如调整reverbs（混响）的参数（如pre-delay、decay）和compressors（压缩器）。整体而言，该研究为利用智能工具推动创意教学提供了实用见解。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.MM",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "11 pages, in Spanish language. 1 figure. Preprint from La nueva era\n  del podcast (2023)",
      "pdf_url": "http://arxiv.org/pdf/2408.02113v2",
      "published_date": "2024-08-04 18:54:59 UTC",
      "updated_date": "2024-08-12 11:44:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:46:13.534164"
    },
    {
      "arxiv_id": "2408.02111v3",
      "title": "Understanding Deep Learning via Notions of Rank",
      "title_zh": "通过秩的概念理解深度学习",
      "authors": [
        "Noam Razin"
      ],
      "abstract": "Despite the extreme popularity of deep learning in science and industry, its\nformal understanding is limited. This thesis puts forth notions of rank as key\nfor developing a theory of deep learning, focusing on the fundamental aspects\nof generalization and expressiveness. In particular, we establish that\ngradient-based training can induce an implicit regularization towards low rank\nfor several neural network architectures, and demonstrate empirically that this\nphenomenon may facilitate an explanation of generalization over natural data\n(e.g., audio, images, and text). Then, we characterize the ability of graph\nneural networks to model interactions via a notion of rank, which is commonly\nused for quantifying entanglement in quantum physics. A central tool underlying\nthese results is a connection between neural networks and tensor\nfactorizations. Practical implications of our theory for designing explicit\nregularization schemes and data preprocessing algorithms are presented.",
      "tldr_zh": "这篇论文通过“rank”的概念来发展深度学习的理论，重点探讨其泛化和表达能力。研究证明，基于梯度的训练可以诱导神经网络朝着低秩方向的implicit regularization，并在音频、图像和文本等自然数据上实验验证了这一现象有助于解释泛化性能。同时，论文使用rank量化图神经网络(Graph Neural Networks)建模交互的能力，并通过神经网络与tensor factorizations的联系作为核心工具。最后，研究为设计显式regularization方案和数据预处理算法提供了实际指导。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "PhD thesis",
      "pdf_url": "http://arxiv.org/pdf/2408.02111v3",
      "published_date": "2024-08-04 18:47:55 UTC",
      "updated_date": "2024-12-28 23:53:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:46:26.132701"
    },
    {
      "arxiv_id": "2408.02700v1",
      "title": "Inventory problems and the parametric measure $m_λ$",
      "title_zh": "翻译失败",
      "authors": [
        "Irina Georgescu"
      ],
      "abstract": "The credibility theory was introduced by B. Liu as a new way to describe the\nfuzzy uncertainty. The credibility measure is the fundamental notion of the\ncredibility theory. Recently, L.Yang and K. Iwamura extended the credibility\nmeasure by defining the parametric measure $m_{\\lambda}$ ($\\lambda$ is a real\nparameter in the interval $[0,1]$ and for $\\lambda= 1/2$ we obtain as a\nparticular case the notion of credibility measure). By using the\n$m_{\\lambda}$-measure, we studied in this paper a risk neutral multi-item\ninventory problem. Our construction generalizes the credibilistic inventory\nmodel developed by Y. Li and Y. Liu in 2019. In our model, the components of\ndemand vector are fuzzy variables and the maximization problem is formulated by\nusing the notion of $m_{\\lambda}$-expected value. We shall prove a general\nformula for the solution of optimization problem, from which we obtained\neffective formulas for computing the optimal solutions in the particular cases\nwhere the demands are trapezoidal and triangular fuzzy numbers. For\n$\\lambda=1/2$ we obtain as a particular case the computation formulas of the\noptimal solutions of the credibilistic inventory problem of Li and Liu. These\ncomputation formulas are applied for some $m_{\\lambda}$-models obtained from\nnumerical data.",
      "tldr_zh": "本研究扩展了可信度理论（credibility theory），通过引入参数化测度 \\( m_\\lambda \\)（其中 λ 位于 [0,1] 区间，且 λ=1/2 时特化为可信度测度），并将其应用于风险中性多项库存问题（risk neutral multi-item inventory problem）。论文将需求向量建模为模糊变量（fuzzy variables），并使用 \\( m_\\lambda \\) 期望值（expected value）制定优化问题，从而推广了 Li 和 Liu 在 2019 年的可信度库存模型。研究证明了一个通用优化问题的公式，并为梯形和三角形模糊数（trapezoidal and triangular fuzzy numbers）提供了计算最优解的有效方法。作为特例，当 λ=1/2 时，这些公式回归到原有可信度库存问题的计算方案，并通过数值数据验证了 \\( m_\\lambda \\) 模型的应用。",
      "categories": [
        "math.OC",
        "cs.AI",
        "econ.TH"
      ],
      "primary_category": "math.OC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.02700v1",
      "published_date": "2024-08-04 18:05:34 UTC",
      "updated_date": "2024-08-04 18:05:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:46:40.703591"
    },
    {
      "arxiv_id": "2408.04652v1",
      "title": "Leveraging Large Language Models with Chain-of-Thought and Prompt Engineering for Traffic Crash Severity Analysis and Inference",
      "title_zh": "翻译失败",
      "authors": [
        "Hao Zhen",
        "Yucheng Shi",
        "Yongcan Huang",
        "Jidong J. Yang",
        "Ninghao Liu"
      ],
      "abstract": "Harnessing the power of Large Language Models (LLMs), this study explores the\nuse of three state-of-the-art LLMs, specifically GPT-3.5-turbo, LLaMA3-8B, and\nLLaMA3-70B, for crash severity inference, framing it as a classification task.\nWe generate textual narratives from original traffic crash tabular data using a\npre-built template infused with domain knowledge. Additionally, we incorporated\nChain-of-Thought (CoT) reasoning to guide the LLMs in analyzing the crash\ncauses and then inferring the severity. This study also examine the impact of\nprompt engineering specifically designed for crash severity inference. The LLMs\nwere tasked with crash severity inference to: (1) evaluate the models'\ncapabilities in crash severity analysis, (2) assess the effectiveness of CoT\nand domain-informed prompt engineering, and (3) examine the reasoning abilities\nwith the CoT framework. Our results showed that LLaMA3-70B consistently\noutperformed the other models, particularly in zero-shot settings. The CoT and\nPrompt Engineering techniques significantly enhanced performance, improving\nlogical reasoning and addressing alignment issues. Notably, the CoT offers\nvaluable insights into LLMs' reasoning processes, unleashing their capacity to\nconsider diverse factors such as environmental conditions, driver behavior, and\nvehicle characteristics in severity analysis and inference.",
      "tldr_zh": "这篇论文利用 Large Language Models (LLMs) 如 GPT-3.5-turbo、LLaMA3-8B 和 LLaMA3-70B，通过生成文本叙述和 Chain-of-Thought (CoT) 推理，将交通事故严重程度分析转化为分类任务。研究融入 Prompt Engineering 技术，以优化模型对事故原因的分析和推断，并评估其在逻辑推理和性能提升方面的效果。结果表明，LLaMA3-70B 在零样本设置中表现出色，CoT 和提示工程显著提高了准确率，并提供了对环境条件、驾驶员行为和车辆特性的全面推理洞见。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "20 pages, 12 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2408.04652v1",
      "published_date": "2024-08-04 17:14:10 UTC",
      "updated_date": "2024-08-04 17:14:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:46:54.334669"
    },
    {
      "arxiv_id": "2408.02088v3",
      "title": "KAN-RCBEVDepth: A multi-modal fusion algorithm in object detection for autonomous driving",
      "title_zh": "翻译失败",
      "authors": [
        "Zhihao Lai",
        "Chuanhao Liu",
        "Shihui Sheng",
        "Zhiqiang Zhang"
      ],
      "abstract": "Accurate 3D object detection in autonomous driving is critical yet\nchallenging due to occlusions, varying object sizes, and complex urban\nenvironments. This paper introduces the KAN-RCBEVDepth method, an innovative\napproach aimed at enhancing 3D object detection by fusing multimodal sensor\ndata from cameras, LiDAR, and millimeter-wave radar. Our unique Bird's Eye\nView-based approach significantly improves detection accuracy and efficiency by\nseamlessly integrating diverse sensor inputs, refining spatial relationship\nunderstanding, and optimizing computational procedures. Experimental results\nshow that the proposed method outperforms existing techniques across multiple\ndetection metrics, achieving a higher Mean Distance AP (0.389, 23\\%\nimprovement), a better ND Score (0.485, 17.1\\% improvement), and a faster\nEvaluation Time (71.28s, 8\\% faster). Additionally, the KAN-RCBEVDepth method\nsignificantly reduces errors compared to BEVDepth, with lower Transformation\nError (0.6044, 13.8\\% improvement), Scale Error (0.2780, 2.6\\% improvement),\nOrientation Error (0.5830, 7.6\\% improvement), Velocity Error (0.4244, 28.3\\%\nimprovement), and Attribute Error (0.2129, 3.2\\% improvement). These findings\nsuggest that our method offers enhanced accuracy, reliability, and efficiency,\nmaking it well-suited for dynamic and demanding autonomous driving scenarios.\nThe code will be released in \\url{https://github.com/laitiamo/RCBEVDepth-KAN}.",
      "tldr_zh": "这篇论文提出了 KAN-RCBEVDepth 方法，一种用于自动驾驶的 3D 对象检测多模态融合算法，通过整合摄像头、LiDAR 和毫米波雷达的数据，采用基于 Bird's Eye View (BEV) 的创新策略来提升检测准确性和效率。方法通过优化空间关系理解和计算过程，显著减少了遮挡和复杂环境带来的挑战。实验结果显示，该方法在 Mean Distance AP 上提高了 23%、ND Score 上提高了 17.1%、Evaluation Time 快了 8%，并在 Transformation Error 等指标上比 BEVDepth 降低了 2.6% 至 28.3%。这些改进使 KAN-RCBEVDepth 更适用于动态的自动驾驶场景，提供更高的可靠性和性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.02088v3",
      "published_date": "2024-08-04 16:54:49 UTC",
      "updated_date": "2024-08-27 16:46:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:47:04.116815"
    },
    {
      "arxiv_id": "2408.02085v5",
      "title": "Unleashing the Power of Data Tsunami: A Comprehensive Survey on Data Assessment and Selection for Instruction Tuning of Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yulei Qin",
        "Yuncheng Yang",
        "Pengcheng Guo",
        "Gang Li",
        "Hang Shao",
        "Yuchen Shi",
        "Zihan Xu",
        "Yun Gu",
        "Ke Li",
        "Xing Sun"
      ],
      "abstract": "Instruction tuning plays a critical role in aligning large language models\n(LLMs) with human preference. Despite the vast amount of open instruction\ndatasets, naively training a LLM on all existing instructions may not be\noptimal and practical. To pinpoint the most beneficial datapoints, data\nassessment and selection methods have been proposed in the fields of natural\nlanguage processing (NLP) and deep learning. However, under the context of\ninstruction tuning, there still exists a gap in knowledge on what kind of data\nevaluation metrics can be employed and how they can be integrated into the\nselection mechanism. To bridge this gap, we present a comprehensive review on\nexisting literature of data assessment and selection especially for instruction\ntuning of LLMs. We systematically categorize all applicable methods into\nquality-based, diversity-based, and importance-based ones where a unified,\nfine-grained taxonomy is structured. For each category, representative methods\nare elaborated to describe the landscape of relevant research. In addition,\ncomparison between the latest methods is conducted on their officially reported\nresults to provide in-depth discussions on their limitations. Finally, we\nsummarize the open challenges and propose the promosing avenues for future\nstudies. All related contents are available at\nhttps://github.com/yuleiqin/fantastic-data-engineering.",
      "tldr_zh": "这篇论文对数据评估和选择在语言模型（LLMs）的指令微调（instruction tuning）中的应用进行了全面调查，旨在解决简单使用所有指令数据集可能带来的低效问题。作者将相关方法系统分类为基于质量的（quality-based）、基于多样性的（diversity-based）和基于重要性的（importance-based），并详细阐述了每类方法的代表性技术。论文通过比较这些方法的实验结果，讨论了它们的局限性，并总结了当前挑战以及未来研究的潜在方向，如进一步优化数据工程策略。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "eess.SP"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to TMLR with Survey Certificate, review, survey, 37 pages, 5\n  figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2408.02085v5",
      "published_date": "2024-08-04 16:50:07 UTC",
      "updated_date": "2024-12-29 04:41:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:47:14.403278"
    },
    {
      "arxiv_id": "2408.02061v1",
      "title": "ParkingE2E: Camera-based End-to-end Parking Network, from Images to Planning",
      "title_zh": "ParkingE2E：基于摄像头的端到端停车网络，从",
      "authors": [
        "Changze Li",
        "Ziheng Ji",
        "Zhe Chen",
        "Tong Qin",
        "Ming Yang"
      ],
      "abstract": "Autonomous parking is a crucial task in the intelligent driving field.\nTraditional parking algorithms are usually implemented using rule-based\nschemes. However, these methods are less effective in complex parking scenarios\ndue to the intricate design of the algorithms. In contrast,\nneural-network-based methods tend to be more intuitive and versatile than the\nrule-based methods. By collecting a large number of expert parking trajectory\ndata and emulating human strategy via learning-based methods, the parking task\ncan be effectively addressed. In this paper, we employ imitation learning to\nperform end-to-end planning from RGB images to path planning by imitating human\ndriving trajectories. The proposed end-to-end approach utilizes a target query\nencoder to fuse images and target features, and a transformer-based decoder to\nautoregressively predict future waypoints. We conducted extensive experiments\nin real-world scenarios, and the results demonstrate that the proposed method\nachieved an average parking success rate of 87.8% across four different\nreal-world garages. Real-vehicle experiments further validate the feasibility\nand effectiveness of the method proposed in this paper.",
      "tldr_zh": "这篇论文提出了一种基于摄像头的端到端停车网络ParkingE2E，通过imitation learning从RGB图像到路径规划，模仿人类驾驶轨迹，以解决传统规则-based方法的局限性。方法包括使用target query encoder融合图像和目标特征，以及transformer-based decoder自动回归预测未来waypoints。实验结果显示，该方法在四个真实车库的平均停车成功率达到87.8%，并通过真实车辆测试验证了其可行性和有效性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.02061v1",
      "published_date": "2024-08-04 15:20:39 UTC",
      "updated_date": "2024-08-04 15:20:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:47:30.708664"
    },
    {
      "arxiv_id": "2408.02698v2",
      "title": "Applications of Scientific Machine Learning for the Analysis of Functionally Graded Porous Beams",
      "title_zh": "科学机器学习在功能梯度多孔梁分析中的应用",
      "authors": [
        "Mohammad Sadegh Eshaghi",
        "Mostafa Bamdad",
        "Cosmin Anitescu",
        "Yizheng Wang",
        "Xiaoying Zhuang",
        "Timon Rabczuk"
      ],
      "abstract": "This study investigates different Scientific Machine Learning (SciML)\napproaches for the analysis of functionally graded (FG) porous beams and\ncompares them under a new framework. The beam material properties are assumed\nto vary as an arbitrary continuous function. The methods consider the output of\na neural network/operator as an approximation to the displacement fields and\nderive the equations governing beam behavior based on the continuum\nformulation. The methods are implemented in the framework and formulated by\nthree approaches: (a) the vector approach leads to a Physics-Informed Neural\nNetwork (PINN), (b) the energy approach brings about the Deep Energy Method\n(DEM), and (c) the data-driven approach, which results in a class of Neural\nOperator methods. Finally, a neural operator has been trained to predict the\nresponse of the porous beam with functionally graded material under any\nporosity distribution pattern and any arbitrary traction condition. The results\nare validated with analytical and numerical reference solutions. The data and\ncode accompanying this manuscript will be publicly available at\nhttps://github.com/eshaghi-ms/DeepNetBeam.",
      "tldr_zh": "本研究探讨了 Scientific Machine Learning (SciML) 在分析功能梯度 (FG) 多孔梁方面的应用，并通过一个新框架进行比较。研究假设材料属性为任意连续函数，并采用三种方法：(a) 向量方法实现 Physics-Informed Neural Network (PINN)，(b) 能量方法实现 Deep Energy Method (DEM)，(c) 数据驱动方法实现 Neural Operator 方法。这些方法使用神经网络/运算符近似位移场，并基于连续体公式推导梁的行为方程。最终，训练了一个 Neural Operator 来预测 FG 多孔梁在任意孔隙分布和牵引条件下的响应，结果与分析和数值参考解决方案验证一致，并公开了相关数据和代码。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.02698v2",
      "published_date": "2024-08-04 15:01:52 UTC",
      "updated_date": "2024-12-24 10:45:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:47:39.680823"
    },
    {
      "arxiv_id": "2408.02049v3",
      "title": "3D Single-object Tracking in Point Clouds with High Temporal Variation",
      "title_zh": "翻译失败",
      "authors": [
        "Qiao Wu",
        "Kun Sun",
        "Pei An",
        "Mathieu Salzmann",
        "Yanning Zhang",
        "Jiaqi Yang"
      ],
      "abstract": "The high temporal variation of the point clouds is the key challenge of 3D\nsingle-object tracking (3D SOT). Existing approaches rely on the assumption\nthat the shape variation of the point clouds and the motion of the objects\nacross neighboring frames are smooth, failing to cope with high temporal\nvariation data. In this paper, we present a novel framework for 3D SOT in point\nclouds with high temporal variation, called HVTrack. HVTrack proposes three\nnovel components to tackle the challenges in the high temporal variation\nscenario: 1) A Relative-Pose-Aware Memory module to handle temporal point cloud\nshape variations; 2) a Base-Expansion Feature Cross-Attention module to deal\nwith similar object distractions in expanded search areas; 3) a Contextual\nPoint Guided Self-Attention module for suppressing heavy background noise. We\nconstruct a dataset with high temporal variation (KITTI-HV) by setting\ndifferent frame intervals for sampling in the KITTI dataset. On the KITTI-HV\nwith 5 frame intervals, our HVTrack surpasses the state-of-the-art tracker\nCXTracker by 11.3%/15.7% in Success/Precision.",
      "tldr_zh": "这篇论文针对点云中高时间变化的挑战，提出了一种新的3D Single-object Tracking框架HVTrack，以解决现有方法在形状变化和物体运动不平滑场景下的局限性。HVTrack包括三个关键组件：Relative-Pose-Aware Memory模块处理时间点云形状变化、Base-Expansion Feature Cross-Attention模块应对扩展搜索区域中的类似物体干扰，以及Contextual Point Guided Self-Attention模块抑制背景噪声。研究者构建了KITTI-HV数据集，通过调整帧间隔进行测试，结果显示HVTrack在5帧间隔条件下，比最先进方法CXTracker在Success和Precision上分别提高了11.3%和15.7%。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ECCV24",
      "pdf_url": "http://arxiv.org/pdf/2408.02049v3",
      "published_date": "2024-08-04 14:57:28 UTC",
      "updated_date": "2024-09-06 07:48:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:48:02.277798"
    },
    {
      "arxiv_id": "2408.02047v2",
      "title": "Latency-Aware Resource Allocation for Mobile Edge Generation and Computing via Deep Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Yinyu Wu",
        "Xuhui Zhang",
        "Jinke Ren",
        "Huijun Xing",
        "Yanyan Shen",
        "Shuguang Cui"
      ],
      "abstract": "Recently, the integration of mobile edge computing (MEC) and generative\nartificial intelligence (GAI) technology has given rise to a new area called\nmobile edge generation and computing (MEGC), which offers mobile users\nheterogeneous services such as task computing and content generation. In this\nletter, we investigate the joint communication, computation, and the AIGC\nresource allocation problem in an MEGC system. A latency minimization problem\nis first formulated to enhance the quality of service for mobile users. Due to\nthe strong coupling of the optimization variables, we propose a new deep\nreinforcement learning-based algorithm to solve it efficiently. Numerical\nresults demonstrate that the proposed algorithm can achieve lower latency than\ntwo baseline algorithms.",
      "tldr_zh": "该论文探讨了移动边缘生成和计算(MEGC)系统中的通信、计算和AIGC资源分配问题，旨在通过延迟最小化来提升移动用户的服务质量。针对优化变量的强耦合，研究者提出了一种基于深度强化学习的新算法，以高效解决这一复杂问题。数值结果显示，该算法比两个基准算法实现了更低的延迟，从而为MEGC系统的性能优化提供了有效方法。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "5 pages, 6 figures. This paper has been accepted for publication by\n  IEEE Networking Letters",
      "pdf_url": "http://arxiv.org/pdf/2408.02047v2",
      "published_date": "2024-08-04 14:53:44 UTC",
      "updated_date": "2024-10-19 05:42:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:48:12.626824"
    },
    {
      "arxiv_id": "2408.02044v1",
      "title": "Fine-tuning multilingual language models in Twitter/X sentiment analysis: a study on Eastern-European V4 languages",
      "title_zh": "翻译失败",
      "authors": [
        "Tomáš Filip",
        "Martin Pavlíček",
        "Petr Sosík"
      ],
      "abstract": "The aspect-based sentiment analysis (ABSA) is a standard NLP task with\nnumerous approaches and benchmarks, where large language models (LLM) represent\nthe current state-of-the-art. We focus on ABSA subtasks based on Twitter/X data\nin underrepresented languages. On such narrow tasks, small tuned language\nmodels can often outperform universal large ones, providing available and cheap\nsolutions.\n  We fine-tune several LLMs (BERT, BERTweet, Llama2, Llama3, Mistral) for\nclassification of sentiment towards Russia and Ukraine in the context of the\nongoing military conflict. The training/testing dataset was obtained from the\nacademic API from Twitter/X during 2023, narrowed to the languages of the V4\ncountries (Czech Republic, Slovakia, Poland, Hungary). Then we measure their\nperformance under a variety of settings including translations, sentiment\ntargets, in-context learning and more, using GPT4 as a reference model. We\ndocument several interesting phenomena demonstrating, among others, that some\nmodels are much better fine-tunable on multilingual Twitter tasks than others,\nand that they can reach the SOTA level with a very small training set. Finally\nwe identify combinations of settings providing the best results.",
      "tldr_zh": "这篇论文探讨了在Twitter/X数据上fine-tune多语言模型进行方面-based sentiment analysis (ABSA)，特别针对V4国家语言（捷克语、斯洛伐克语、波兰语和匈牙利语）。研究团队fine-tuned多个LLMs（如BERT、BERTweet、Llama2、Llama3和Mistral），用于分类俄乌冲突相关的情感，并评估了各种设置，包括翻译、in-context learning和情感目标，使用GPT4作为参考。结果表明，一些模型在多语言Twitter任务上更易fine-tune，且仅需小规模训练集即可达到SOTA水平，最终识别出最佳设置组合，提供了一种高效且经济的解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "18 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.02044v1",
      "published_date": "2024-08-04 14:35:30 UTC",
      "updated_date": "2024-08-04 14:35:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:48:16.200807"
    },
    {
      "arxiv_id": "2408.11823v1",
      "title": "Mamba-Spike: Enhancing the Mamba Architecture with a Spiking Front-End for Efficient Temporal Data Processing",
      "title_zh": "翻译失败",
      "authors": [
        "Jiahao Qin",
        "Feng Liu"
      ],
      "abstract": "The field of neuromorphic computing has gained significant attention in\nrecent years, aiming to bridge the gap between the efficiency of biological\nneural networks and the performance of artificial intelligence systems. This\npaper introduces Mamba-Spike, a novel neuromorphic architecture that integrates\na spiking front-end with the Mamba backbone to achieve efficient and robust\ntemporal data processing. The proposed approach leverages the event-driven\nnature of spiking neural networks (SNNs) to capture and process asynchronous,\ntime-varying inputs, while harnessing the power of the Mamba backbone's\nselective state spaces and linear-time sequence modeling capabilities to model\ncomplex temporal dependencies effectively. The spiking front-end of Mamba-Spike\nemploys biologically inspired neuron models, along with adaptive threshold and\nsynaptic dynamics. These components enable efficient spatiotemporal feature\nextraction and encoding of the input data. The Mamba backbone, on the other\nhand, utilizes a hierarchical structure with gated recurrent units and\nattention mechanisms to capture long-term dependencies and selectively process\nrelevant information. To evaluate the efficacy of the proposed architecture, a\ncomprehensive empirical study is conducted on both neuromorphic datasets,\nincluding DVS Gesture and TIDIGITS, and standard datasets, such as Sequential\nMNIST and CIFAR10-DVS. The results demonstrate that Mamba-Spike consistently\noutperforms state-of-the-art baselines, achieving higher accuracy, lower\nlatency, and improved energy efficiency. Moreover, the model exhibits\nrobustness to various input perturbations and noise levels, highlighting its\npotential for real-world applications. The code will be available at\nhttps://github.com/ECNU-Cross-Innovation-Lab/Mamba-Spike.",
      "tldr_zh": "这篇论文提出了 Mamba-Spike，一种新型神经形态架构，将 spiking front-end 与 Mamba backbone 整合，以实现高效的时序数据处理。Mamba-Spike 利用 SNNs 的 event-driven 特性结合生物启发的神经元模型、adaptive threshold 和 synaptic dynamics 来提取时空特征，同时借助 Mamba backbone 的 selective state spaces、gated recurrent units 和 attention mechanisms 来捕捉复杂的时间依赖。实验结果显示，该架构在 DVS Gesture、TIDIGITS、Sequential MNIST 和 CIFAR10-DVS 等数据集上，相比现有基线模型实现了更高的准确率、更低的延迟和更好的能效，并对输入扰动和噪声表现出色。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "12 pages, 5 figures, accepted by CGI 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.11823v1",
      "published_date": "2024-08-04 14:10:33 UTC",
      "updated_date": "2024-08-04 14:10:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:48:30.871831"
    },
    {
      "arxiv_id": "2408.02032v3",
      "title": "Self-Introspective Decoding: Alleviating Hallucinations for Large Vision-Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Fushuo Huo",
        "Wenchao Xu",
        "Zhong Zhang",
        "Haozhao Wang",
        "Zhicheng Chen",
        "Peilin Zhao"
      ],
      "abstract": "While Large Vision-Language Models (LVLMs) have rapidly advanced in recent\nyears, the prevalent issue known as the `hallucination' problem has emerged as\na significant bottleneck, hindering their real-world deployments. Existing\nmethods mitigate this issue mainly from two perspectives: One approach\nleverages extra knowledge like robust instruction tuning LVLMs with curated\ndatasets or employing auxiliary analysis networks, which inevitable incur\nadditional costs. Another approach, known as contrastive decoding, induces\nhallucinations by manually disturbing the vision or instruction raw inputs and\nmitigates them by contrasting the outputs of the disturbed and original LVLMs.\nHowever, these approaches rely on empirical holistic input disturbances and\ndouble the inference cost. To avoid these issues, we propose a simple yet\neffective method named Self-Introspective Decoding (SID). Our empirical\ninvestigation reveals that pretrained LVLMs can introspectively assess the\nimportance of vision tokens based on preceding vision and text (both\ninstruction and generated) tokens. We develop the Context and Text-aware Token\nSelection (CT2S) strategy, which preserves only unimportant vision tokens after\nearly layers of LVLMs to adaptively amplify text-informed hallucination during\nthe auto-regressive decoding. This approach ensures that multimodal knowledge\nabsorbed in the early layers induces multimodal contextual rather than aimless\nhallucinations. Subsequently, the original token logits subtract the amplified\nvision-and-text association hallucinations, guiding LVLMs decoding faithfully.\nExtensive experiments illustrate SID generates less-hallucination and\nhigher-quality texts across various metrics, without extra knowledge and much\nadditional computation burdens.",
      "tldr_zh": "这篇论文提出 Self-Introspective Decoding (SID) 方法，以缓解 Large Vision-Language Models (LVLMs) 中的 hallucination 问题，而无需额外知识或显著增加计算成本。SID 通过 Context and Text-aware Token Selection (CT2S) 策略，让 LVLMs 基于前面的视觉和文本 token 自省地评估视觉 token 的重要性，并在早期层后保留不重要 token，以适应性地放大文本相关的幻觉。最终，通过减去放大的幻觉来指导解码，实验结果显示 SID 生成的文本质量更高，hallucination 显著减少，在各种指标上表现出色。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "ICLR2025",
      "pdf_url": "http://arxiv.org/pdf/2408.02032v3",
      "published_date": "2024-08-04 13:50:17 UTC",
      "updated_date": "2025-03-16 06:51:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:48:46.574987"
    },
    {
      "arxiv_id": "2408.02029v3",
      "title": "Mining Path Association Rules in Large Property Graphs (with Appendix)",
      "title_zh": "在大型属性图中挖掘路径关联规则（附录）",
      "authors": [
        "Yuya Sasaki",
        "Panagiotis Karras"
      ],
      "abstract": "How can we mine frequent path regularities from a graph with edge labels and\nvertex attributes? The task of association rule mining successfully discovers\nregular patterns in item sets and substructures. Still, to our best knowledge,\nthis concept has not yet been extended to path patterns in large property\ngraphs. In this paper, we introduce the problem of path association rule mining\n(PARM). Applied to any \\emph{reachability path} between two vertices within a\nlarge graph, PARM discovers regular ways in which path patterns, identified by\nvertex attributes and edge labels, co-occur with each other. We develop an\nefficient and scalable algorithm PIONEER that exploits an anti-monotonicity\nproperty to effectively prune the search space. Further, we devise\napproximation techniques and employ parallelization to achieve scalable path\nassociation rule mining. Our experimental study using real-world graph data\nverifies the significance of path association rules and the efficiency of our\nsolutions.",
      "tldr_zh": "本文引入了路径关联规则挖掘 (PARM) 的概念，用于从大型属性图中挖掘频繁路径模式之间的规律，这些模式由顶点属性和边标签定义。研究开发了高效算法 PIONEER，利用反单调性属性修剪搜索空间，并结合近似技术和并行化以提升可扩展性。实验在真实世界图数据上验证了路径关联规则的显著性和算法的高效性。",
      "categories": [
        "cs.DB",
        "cs.AI"
      ],
      "primary_category": "cs.DB",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.02029v3",
      "published_date": "2024-08-04 13:39:57 UTC",
      "updated_date": "2024-09-20 14:59:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:48:55.095700"
    },
    {
      "arxiv_id": "2408.02025v2",
      "title": "Contrastive Learning-based Chaining-Cluster for Multilingual Voice-Face Association",
      "title_zh": "翻译失败",
      "authors": [
        "Wuyang Chen",
        "Yanjie Sun",
        "Kele Xu",
        "Yong Dou"
      ],
      "abstract": "The innate correlation between a person's face and voice has recently emerged\nas a compelling area of study, especially within the context of multilingual\nenvironments. This paper introduces our novel solution to the Face-Voice\nAssociation in Multilingual Environments (FAME) 2024 challenge, focusing on a\ncontrastive learning-based chaining-cluster method to enhance face-voice\nassociation. This task involves the challenges of building biometric relations\nbetween auditory and visual modality cues and modelling the prosody\ninterdependence between different languages while addressing both intrinsic and\nextrinsic variability present in the data. To handle these non-trivial\nchallenges, our method employs supervised cross-contrastive (SCC) learning to\nestablish robust associations between voices and faces in multi-language\nscenarios. Following this, we have specifically designed a\nchaining-cluster-based post-processing step to mitigate the impact of outliers\noften found in unconstrained in the wild data. We conducted extensive\nexperiments to investigate the impact of language on face-voice association.\nThe overall results were evaluated on the FAME public evaluation platform,\nwhere we achieved 2nd place. The results demonstrate the superior performance\nof our method, and we validate the robustness and effectiveness of our proposed\napproach. Code is available at https://github.com/colaudiolab/FAME24_solution.",
      "tldr_zh": "本研究针对多语言环境中的人脸-语音关联问题，提出了一种基于对比学习的链式聚类（Chaining-Cluster）方法，以增强生物特征关系建模。方法采用监督跨对比学习（Supervised Cross-Contrastive, SCC）来建立稳健的语音-人脸关联，并设计了链式聚类后处理步骤，以减少野外数据中异常值的影响。实验结果显示，该方法在 FAME 2024 挑战中获得第 2 名，证明了其在处理语言韵律相互依赖和数据变异性方面的优越性能和鲁棒性。代码可在 https://github.com/colaudiolab/FAME24_solution 获取。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.02025v2",
      "published_date": "2024-08-04 13:24:36 UTC",
      "updated_date": "2024-08-19 05:14:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:49:07.401012"
    },
    {
      "arxiv_id": "2408.02022v1",
      "title": "Scenario-based Thermal Management Parametrization Through Deep Reinforcement Learning",
      "title_zh": "基于场景的热管理参数化通过深度强化学习",
      "authors": [
        "Thomas Rudolf",
        "Philip Muhl",
        "Sören Hohmann",
        "Lutz Eckstein"
      ],
      "abstract": "The thermal system of battery electric vehicles demands advanced control. Its\nthermal management needs to effectively control active components across\nvarying operating conditions. While robust control function parametrization is\nrequired, current methodologies show significant drawbacks. They consume\nconsiderable time, human effort, and extensive real-world testing.\nConsequently, there is a need for innovative and intelligent solutions that are\ncapable of autonomously parametrizing embedded controllers. Addressing this\nissue, our paper introduces a learning-based tuning approach. We propose a\nmethodology that benefits from automated scenario generation for increased\nrobustness across vehicle usage scenarios. Our deep reinforcement learning\nagent processes the tuning task context and incorporates an image-based\ninterpretation of embedded parameter sets. We demonstrate its applicability to\na valve controller parametrization task and verify it in real-world vehicle\ntesting. The results highlight the competitive performance to baseline methods.\nThis novel approach contributes to the shift towards virtual development of\nthermal management functions, with promising potential of large-scale parameter\ntuning in the automotive industry.",
      "tldr_zh": "该研究针对电池电动车热管理系统（thermal management）的参数化问题，提出了一种基于深度强化学习（Deep Reinforcement Learning）的智能调优方法，以应对传统方法耗时且依赖实地测试的缺点。该方法利用自动场景生成提升鲁棒性，并通过图像-based 参数集解释来处理调优任务上下文，在阀门控制器参数化任务上进行了实际车辆测试。结果显示，该方法在性能上优于基线方法，并为汽车行业的虚拟开发和大规模参数调优提供了创新潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 7 figures, 2 tables, 1 algorithm, 10 equations, conference",
      "pdf_url": "http://arxiv.org/pdf/2408.02022v1",
      "published_date": "2024-08-04 13:19:45 UTC",
      "updated_date": "2024-08-04 13:19:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:49:18.944711"
    },
    {
      "arxiv_id": "2408.02018v1",
      "title": "Individualized multi-horizon MRI trajectory prediction for Alzheimer's Disease",
      "title_zh": "翻译失败",
      "authors": [
        "Rosemary He",
        "Gabriella Ang",
        "Daniel Tward"
      ],
      "abstract": "Neurodegeneration as measured through magnetic resonance imaging (MRI) is\nrecognized as a potential biomarker for diagnosing Alzheimer's disease (AD),\nbut is generally considered less specific than amyloid or tau based biomarkers.\nDue to a large amount of variability in brain anatomy between different\nindividuals, we hypothesize that leveraging MRI time series can help improve\nspecificity, by treating each patient as their own baseline. Here we turn to\nconditional variational autoencoders to generate individualized MRI predictions\ngiven the subject's age, disease status and one previous scan. Using serial\nimaging data from the Alzheimer's Disease Neuroimaging Initiative, we train a\nnovel architecture to build a latent space distribution which can be sampled\nfrom to generate future predictions of changing anatomy. This enables us to\nextrapolate beyond the dataset and predict MRIs up to 10 years. We evaluated\nthe model on a held-out set from ADNI and an independent dataset (from Open\nAccess Series of Imaging Studies). By comparing to several alternatives, we\nshow that our model produces more individualized images with higher resolution.\nFurther, if an individual already has a follow-up MRI, we demonstrate a usage\nof our model to compute a likelihood ratio classifier for disease status. In\npractice, the model may be able to assist in early diagnosis of AD and provide\na counterfactual baseline trajectory for treatment effect estimation.\nFurthermore, it generates a synthetic dataset that can potentially be used for\ndownstream tasks such as anomaly detection and classification.",
      "tldr_zh": "这篇论文提出了一种个性化的多时段 MRI 轨迹预测方法，用于阿尔茨海默病（Alzheimer's Disease）诊断，通过利用每个患者作为自身基线来提高 MRI 生物标志物的特异性。研究采用条件变分自编码器（conditional variational autoencoders）结合患者的年龄、疾病状态和先前扫描数据，训练一个新架构来生成未来长达 10 年的解剖变化预测。实验在 Alzheimer's Disease Neuroimaging Initiative 数据集和独立数据集上验证，该模型产生更高分辨率的个性化图像，并可用于计算疾病状态的似然比分类器，支持早期诊断、治疗效果估计和下游任务如异常检测。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "MICCAI 2024 LDTM workshop",
      "pdf_url": "http://arxiv.org/pdf/2408.02018v1",
      "published_date": "2024-08-04 13:09:06 UTC",
      "updated_date": "2024-08-04 13:09:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:49:32.297106"
    },
    {
      "arxiv_id": "2408.02697v3",
      "title": "Why Rectified Power Unit Networks Fail and How to Improve It: An Effective Theory Perspective",
      "title_zh": "翻译失败",
      "authors": [
        "Taeyoung Kim",
        "Myungjoo Kang"
      ],
      "abstract": "The Rectified Power Unit (RePU) activation functions, unlike the Rectified\nLinear Unit (ReLU), have the advantage of being a differentiable function when\nconstructing neural networks. However, it can be experimentally observed when\ndeep layers are stacked, neural networks constructed with RePU encounter\ncritical issues. These issues include the values exploding or vanishing and\nfailure of training. And these happen regardless of the hyperparameter\ninitialization. From the perspective of effective theory, we aim to identify\nthe causes of this phenomenon and propose a new activation function that\nretains the advantages of RePU while overcoming its drawbacks.",
      "tldr_zh": "该研究分析了Rectified Power Unit (RePU)激活函数在神经网络中的问题，尽管RePU比Rectified Linear Unit (ReLU)更易微分，但在深度层堆叠时，会出现值爆炸、消失和训练失败等问题，且这些问题独立于超参数初始化。作者从effective theory的视角探讨了这些现象的根本原因，揭示了RePU的潜在缺陷。最终，他们提出了一种新激活函数，保留了RePU的可微性优势，同时有效克服其缺点，从而提升神经网络的稳定性和训练性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "41 pages, 17 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.02697v3",
      "published_date": "2024-08-04 13:05:05 UTC",
      "updated_date": "2024-11-20 20:00:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:49:43.091892"
    },
    {
      "arxiv_id": "2408.02009v2",
      "title": "Joint Learning of Emotions in Music and Generalized Sounds",
      "title_zh": "翻译失败",
      "authors": [
        "Federico Simonetta",
        "Francesca Certo",
        "Stavros Ntalampiras"
      ],
      "abstract": "In this study, we aim to determine if generalized sounds and music can share\na common emotional space, improving predictions of emotion in terms of arousal\nand valence. We propose the use of multiple datasets as a multi-domain learning\ntechnique. Our approach involves creating a common space encompassing features\nthat characterize both generalized sounds and music, as they can evoke emotions\nin a similar manner. To achieve this, we utilized two publicly available\ndatasets, namely IADS-E and PMEmo, following a standardized experimental\nprotocol. We employed a wide variety of features that capture diverse aspects\nof the audio structure including key parameters of spectrum, energy, and\nvoicing. Subsequently, we performed joint learning on the common feature space,\nleveraging heterogeneous model architectures. Interestingly, this synergistic\nscheme outperforms the state-of-the-art in both sound and music emotion\nprediction. The code enabling full replication of the presented experimental\npipeline is available at https://github.com/LIMUNIMI/MusicSoundEmotions.",
      "tldr_zh": "本研究旨在探讨泛化声音和音乐是否能共享一个共同的情感空间，从而提升情绪预测（包括 arousal 和 valence）。研究者采用多域学习技术，利用 IADS-E 和 PMEmo 数据集创建共同特征空间，并提取音频特征（如频谱、能量和发声参数），通过异构模型架构进行联合学习。结果显示，这种协同方法在声音和音乐情绪预测上超过了现有最先进技术，并提供了可复现代码（https://github.com/LIMUNIMI/MusicSoundEmotions）。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted at Audio Mostly 2024, Milan",
      "pdf_url": "http://arxiv.org/pdf/2408.02009v2",
      "published_date": "2024-08-04 12:19:03 UTC",
      "updated_date": "2024-08-14 09:28:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:49:55.443857"
    },
    {
      "arxiv_id": "2408.01999v2",
      "title": "Reinforcement Learning for an Efficient and Effective Malware Investigation during Cyber Incident Response",
      "title_zh": "强化学习用于网络事件响应期间高效且有效的恶意软件调查",
      "authors": [
        "Dipo Dunsin",
        "Mohamed Chahine Ghanem",
        "Karim Ouazzane",
        "Vassil Vassilev"
      ],
      "abstract": "This research focused on enhancing post-incident malware forensic\ninvestigation using reinforcement learning RL. We proposed an advanced MDP post\nincident malware forensics investigation model and framework to expedite post\nincident forensics. We then implement our RL Malware Investigation Model based\non structured MDP within the proposed framework. To identify malware artefacts,\nthe RL agent acquires and examines forensics evidence files, iteratively\nimproving its capabilities using Q Table and temporal difference learning. The\nQ learning algorithm significantly improved the agent ability to identify\nmalware. An epsilon greedy exploration strategy and Q learning updates enabled\nefficient learning and decision making. Our experimental testing revealed that\noptimal learning rates depend on the MDP environment complexity, with simpler\nenvironments benefiting from higher rates for quicker convergence and complex\nones requiring lower rates for stability. Our model performance in identifying\nand classifying malware reduced malware analysis time compared to human\nexperts, demonstrating robustness and adaptability. The study highlighted the\nsignificance of hyper parameter tuning and suggested adaptive strategies for\ncomplex environments. Our RL based approach produced promising results and is\nvalidated as an alternative to traditional methods notably by offering\ncontinuous learning and adaptation to new and evolving malware threats which\nultimately enhance the post incident forensics investigations.",
      "tldr_zh": "该研究利用 Reinforcement Learning (RL) 增强网络事件响应中的恶意软件调查，提出一个基于 MDP (Markov Decision Process) 的后事件取证模型和框架，以加速调查过程。\nRL 代理通过 Q learning 算法、epsilon-greedy 探索策略和时间差学习来获取并分析取证证据文件，从而迭代提升恶意软件识别能力。\n实验显示，最佳学习率取决于环境复杂性，简单环境需高学习率快速收敛，而复杂环境需低学习率确保稳定性；该模型比人类专家更快地识别和分类恶意软件，并展示出鲁棒性和适应性。\n这项 RL  方法提供持续学习和应对新威胁的优势，作为传统取证方法的有效替代。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.CR",
      "comment": "21 pages",
      "pdf_url": "http://arxiv.org/pdf/2408.01999v2",
      "published_date": "2024-08-04 11:55:24 UTC",
      "updated_date": "2025-01-07 10:04:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:50:08.562920"
    },
    {
      "arxiv_id": "2408.01988v1",
      "title": "MetaWearS: A Shortcut in Wearable Systems Lifecycle with Only a Few Shots",
      "title_zh": "翻译失败",
      "authors": [
        "Alireza Amirshahi",
        "Maedeh H. Toosi",
        "Siamak Mohammadi",
        "Stefano Albini",
        "Pasquale Davide Schiavone",
        "Giovanni Ansaloni",
        "Amir Aminifar",
        "David Atienza"
      ],
      "abstract": "Wearable systems provide continuous health monitoring and can lead to early\ndetection of potential health issues. However, the lifecycle of wearable\nsystems faces several challenges. First, effective model training for new\nwearable devices requires substantial labeled data from various subjects\ncollected directly by the wearable. Second, subsequent model updates require\nfurther extensive labeled data for retraining. Finally, frequent model updating\non the wearable device can decrease the battery life in long-term data\nmonitoring. Addressing these challenges, in this paper, we propose MetaWearS, a\nmeta-learning method to reduce the amount of initial data collection required.\nMoreover, our approach incorporates a prototypical updating mechanism,\nsimplifying the update process by modifying the class prototype rather than\nretraining the entire model. We explore the performance of MetaWearS in two\ncase studies, namely, the detection of epileptic seizures and the detection of\natrial fibrillation. We show that by fine-tuning with just a few samples, we\nachieve 70% and 82% AUC for the detection of epileptic seizures and the\ndetection of atrial fibrillation, respectively. Compared to a conventional\napproach, our proposed method performs better with up to 45% AUC. Furthermore,\nupdating the model with only 16 minutes of additional labeled data increases\nthe AUC by up to 5.3%. Finally, MetaWearS reduces the energy consumption for\nmodel updates by 456x and 418x for epileptic seizure and AF detection,\nrespectively.",
      "tldr_zh": "这篇论文提出了 MetaWearS，一种基于 meta-learning 的方法，旨在简化可穿戴系统的生命周期，减少初始数据收集和模型更新需求，以解决传统方法对大量标注数据和频繁重训的依赖。MetaWearS 引入 prototypical updating 机制，通过修改类原型来简化更新过程，从而降低计算资源消耗。在癫痫发作检测和房颤检测的两个案例研究中，该方法仅需少量样本微调，即可分别实现 70% 和 82% AUC，比传统方法高出 45%。此外，使用 16 分钟额外数据更新模型可提高 AUC 5.3%，并将能量消耗分别减少 456 倍和 418 倍，为高效的可穿戴健康监测提供可行方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.AR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.01988v1",
      "published_date": "2024-08-04 11:00:43 UTC",
      "updated_date": "2024-08-04 11:00:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:50:21.760034"
    },
    {
      "arxiv_id": "2408.01986v1",
      "title": "DeMansia: Mamba Never Forgets Any Tokens",
      "title_zh": "翻译失败",
      "authors": [
        "Ricky Fang"
      ],
      "abstract": "This paper examines the mathematical foundations of transformer\narchitectures, highlighting their limitations particularly in handling long\nsequences. We explore prerequisite models such as Mamba, Vision Mamba (ViM),\nand LV-ViT that pave the way for our proposed architecture, DeMansia. DeMansia\nintegrates state space models with token labeling techniques to enhance\nperformance in image classification tasks, efficiently addressing the\ncomputational challenges posed by traditional transformers. The architecture,\nbenchmark, and comparisons with contemporary models demonstrate DeMansia's\neffectiveness. The implementation of this paper is available on GitHub at\nhttps://github.com/catalpaaa/DeMansia",
      "tldr_zh": "本论文分析了Transformer架构在处理长序列时的数学局限性，并回顾了先决模型如Mamba、Vision Mamba (ViM)和LV-ViT作为基础。论文提出DeMansia架构，通过整合state space models和token labeling技术，提升图像分类任务的性能，同时高效解决传统Transformers的计算挑战。实验基准测试和与其他模型的比较证明了DeMansia的有效性，其实现代码已在GitHub上公开（https://github.com/catalpaaa/DeMansia）。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.01986v1",
      "published_date": "2024-08-04 10:54:36 UTC",
      "updated_date": "2024-08-04 10:54:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:50:31.305875"
    },
    {
      "arxiv_id": "2408.01970v1",
      "title": "SR-CIS: Self-Reflective Incremental System with Decoupled Memory and Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Biqing Qi",
        "Junqi Gao",
        "Xinquan Chen",
        "Dong Li",
        "Weinan Zhang",
        "Bowen Zhou"
      ],
      "abstract": "The ability of humans to rapidly learn new knowledge while retaining old\nmemories poses a significant challenge for current deep learning models. To\nhandle this challenge, we draw inspiration from human memory and learning\nmechanisms and propose the Self-Reflective Complementary Incremental System\n(SR-CIS). Comprising the deconstructed Complementary Inference Module (CIM) and\nComplementary Memory Module (CMM), SR-CIS features a small model for fast\ninference and a large model for slow deliberation in CIM, enabled by the\nConfidence-Aware Online Anomaly Detection (CA-OAD) mechanism for efficient\ncollaboration. CMM consists of task-specific Short-Term Memory (STM) region and\na universal Long-Term Memory (LTM) region. By setting task-specific Low-Rank\nAdaptive (LoRA) and corresponding prototype weights and biases, it instantiates\nexternal storage for parameter and representation memory, thus deconstructing\nthe memory module from the inference module. By storing textual descriptions of\nimages during training and combining them with the Scenario Replay Module (SRM)\npost-training for memory combination, along with periodic short-to-long-term\nmemory restructuring, SR-CIS achieves stable incremental memory with limited\nstorage requirements. Balancing model plasticity and memory stability under\nconstraints of limited storage and low data resources, SR-CIS surpasses\nexisting competitive baselines on multiple standard and few-shot incremental\nlearning benchmarks.",
      "tldr_zh": "该研究提出 SR-CIS（Self-Reflective Incremental System），一个受人类记忆和学习机制启发的系统，旨在解决深度学习模型在快速学习新知识的同时保留旧记忆的挑战。SR-CIS 包括 Complementary Inference Module (CIM)，它使用小模型进行快速推理、大模型进行缓慢审议，并通过 Confidence-Aware Online Anomaly Detection (CA-OAD) 机制实现高效协作；以及 Complementary Memory Module (CMM)，它包含任务特定的 Short-Term Memory (STM) 和通用 Long-Term Memory (LTM)，通过 Low-Rank Adaptive (LoRA) 和 Scenario Replay Module (SRM) 等技术分离内存与推理模块。系统通过存储图像文本描述、定期内存重组等方式，在有限存储和数据资源下实现稳定的增量学习。最后，SR-CIS 在多个标准和少样本增量学习基准上超越现有基线，平衡了模型的可塑性和记忆稳定性。",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.01970v1",
      "published_date": "2024-08-04 09:09:35 UTC",
      "updated_date": "2024-08-04 09:09:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:50:45.504127"
    },
    {
      "arxiv_id": "2408.01966v2",
      "title": "ML-EAT: A Multilevel Embedding Association Test for Interpretable and Transparent Social Science",
      "title_zh": "ML-EAT：用于可解释和透明社会科学的多级嵌入关联测试",
      "authors": [
        "Robert Wolfe",
        "Alexis Hiniker",
        "Bill Howe"
      ],
      "abstract": "This research introduces the Multilevel Embedding Association Test (ML-EAT),\na method designed for interpretable and transparent measurement of intrinsic\nbias in language technologies. The ML-EAT addresses issues of ambiguity and\ndifficulty in interpreting the traditional EAT measurement by quantifying bias\nat three levels of increasing granularity: the differential association between\ntwo target concepts with two attribute concepts; the individual effect size of\neach target concept with two attribute concepts; and the association between\neach individual target concept and each individual attribute concept. Using the\nML-EAT, this research defines a taxonomy of EAT patterns describing the nine\npossible outcomes of an embedding association test, each of which is associated\nwith a unique EAT-Map, a novel four-quadrant visualization for interpreting the\nML-EAT. Empirical analysis of static and diachronic word embeddings, GPT-2\nlanguage models, and a CLIP language-and-image model shows that EAT patterns\nadd otherwise unobservable information about the component biases that make up\nan EAT; reveal the effects of prompting in zero-shot models; and can also\nidentify situations when cosine similarity is an ineffective metric, rendering\nan EAT unreliable. Our work contributes a method for rendering bias more\nobservable and interpretable, improving the transparency of computational\ninvestigations into human minds and societies.",
      "tldr_zh": "这篇论文引入了 Multilevel Embedding Association Test (ML-EAT)，一种用于可解释和透明测量语言技术中内在偏差的方法，以解决传统 Embedding Association Test (EAT) 的模糊性和解释难题。ML-EAT 通过三个层级的量化分析——目标概念与属性概念的差异关联、个别效应大小以及个别概念间的关联——定义了九种可能的 EAT 模式，并引入了四象限可视化工具 EAT-Map 来辅助解读。研究通过实证分析静态词嵌入、历时词嵌入、GPT-2 语言模型和 CLIP 模型，揭示了这些模式如何提供额外偏差信息、展示零样本模型中的提示效果，并识别余弦 similarity 作为无效指标的情况。总体上，该方法提升了偏差的可观察性和透明度，为社会科学计算调查人类思维和社会提供了更可靠的工具。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at Artificial Intelligence, Ethics, and Society 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.01966v2",
      "published_date": "2024-08-04 09:04:44 UTC",
      "updated_date": "2024-08-27 20:05:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:50:58.036938"
    },
    {
      "arxiv_id": "2408.01964v1",
      "title": "Top K Enhanced Reinforcement Learning Attacks on Heterogeneous Graph Node Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Honglin Gao",
        "Gaoxi Xiao"
      ],
      "abstract": "Graph Neural Networks (GNNs) have attracted substantial interest due to their\nexceptional performance on graph-based data. However, their robustness,\nespecially on heterogeneous graphs, remains underexplored, particularly against\nadversarial attacks. This paper proposes HeteroKRLAttack, a targeted evasion\nblack-box attack method for heterogeneous graphs. By integrating reinforcement\nlearning with a Top-K algorithm to reduce the action space, our method\nefficiently identifies effective attack strategies to disrupt node\nclassification tasks. We validate the effectiveness of HeteroKRLAttack through\nexperiments on multiple heterogeneous graph datasets, showing significant\nreductions in classification accuracy compared to baseline methods. An ablation\nstudy underscores the critical role of the Top-K algorithm in enhancing attack\nperformance. Our findings highlight potential vulnerabilities in current models\nand provide guidance for future defense strategies against adversarial attacks\non heterogeneous graphs.",
      "tldr_zh": "本研究探讨了Graph Neural Networks (GNNs)在异构图上的鲁棒性问题，特别是针对对抗性攻击的漏洞。论文提出HeteroKRLAttack，一种针对异构图节点分类的目标性规避黑盒攻击方法，该方法通过整合Reinforcement Learning与Top-K算法来缩小行动空间，从而高效识别破坏分类任务的有效策略。在多个异构图数据集上的实验显示，HeteroKRLAttack显著降低了分类准确率，比基线方法更具优势，且消融研究证实Top-K算法在提升攻击性能中发挥关键作用。该工作揭示了当前模型的潜在风险，并为未来的防御策略提供重要指导。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.01964v1",
      "published_date": "2024-08-04 08:44:00 UTC",
      "updated_date": "2024-08-04 08:44:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:51:09.122817"
    },
    {
      "arxiv_id": "2408.01962v1",
      "title": "The Implications of Open Generative Models in Human-Centered Data Science Work: A Case Study with Fact-Checking Organizations",
      "title_zh": "开放生成模型在以人为中心的数据科学工作中的含义：与事实核查组织的案例研究",
      "authors": [
        "Robert Wolfe",
        "Tanushree Mitra"
      ],
      "abstract": "Calls to use open generative language models in academic research have\nhighlighted the need for reproducibility and transparency in scientific\nresearch. However, the impact of generative AI extends well beyond academia, as\ncorporations and public interest organizations have begun integrating these\nmodels into their data science pipelines. We expand this lens to include the\nimpact of open models on organizations, focusing specifically on fact-checking\norganizations, which use AI to observe and analyze large volumes of circulating\nmisinformation, yet must also ensure the reproducibility and impartiality of\ntheir work. We wanted to understand where fact-checking organizations use open\nmodels in their data science pipelines; what motivates their use of open models\nor proprietary models; and how their use of open or proprietary models can\ninform research on the societal impact of generative AI. To answer these\nquestions, we conducted an interview study with N=24 professionals at 20\nfact-checking organizations on six continents. Based on these interviews, we\noffer a five-component conceptual model of where fact-checking organizations\nemploy generative AI to support or automate parts of their data science\npipeline, including Data Ingestion, Data Analysis, Data Retrieval, Data\nDelivery, and Data Sharing. We then provide taxonomies of fact-checking\norganizations' motivations for using open models and the limitations that\nprevent them for further adopting open models, finding that they prefer open\nmodels for Organizational Autonomy, Data Privacy and Ownership, Application\nSpecificity, and Capability Transparency. However, they nonetheless use\nproprietary models due to perceived advantages in Performance, Usability, and\nSafety, as well as Opportunity Costs related to participation in emerging\ngenerative AI ecosystems. Our work provides novel perspective on open models in\ndata-driven organizations.",
      "tldr_zh": "这篇论文通过对 24 名事实核查组织专业人士的访谈研究，探讨了开放生成式模型（open generative models）在这些组织数据科学管道中的应用及其社会影响。研究提出了一个五组件概念模型，包括 Data Ingestion、Data Analysis、Data Retrieval、Data Delivery 和 Data Sharing，用于支持或自动化事实核查流程。事实核查组织偏好开放模型的动机包括 Organizational Autonomy、Data Privacy and Ownership、Application Specificity 和 Capability Transparency，但受限于 Performance、Usability 和 Safety 等因素，而选择专有模型。总体上，该工作为理解生成 AI 在数据驱动组织中的作用提供了新颖视角。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL",
        "cs.CY",
        "cs.ET"
      ],
      "primary_category": "cs.HC",
      "comment": "Accepted at Artificial Intelligence, Ethics, and Society 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.01962v1",
      "published_date": "2024-08-04 08:41:48 UTC",
      "updated_date": "2024-08-04 08:41:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:51:31.471057"
    },
    {
      "arxiv_id": "2408.01961v1",
      "title": "Representation Bias of Adolescents in AI: A Bilingual, Bicultural Study",
      "title_zh": "翻译失败",
      "authors": [
        "Robert Wolfe",
        "Aayushi Dangol",
        "Bill Howe",
        "Alexis Hiniker"
      ],
      "abstract": "Popular and news media often portray teenagers with sensationalism, as both a\nrisk to society and at risk from society. As AI begins to absorb some of the\nepistemic functions of traditional media, we study how teenagers in two\ncountries speaking two languages: 1) are depicted by AI, and 2) how they would\nprefer to be depicted. Specifically, we study the biases about teenagers\nlearned by static word embeddings (SWEs) and generative language models (GLMs),\ncomparing these with the perspectives of adolescents living in the U.S. and\nNepal. We find English-language SWEs associate teenagers with societal\nproblems, and more than 50% of the 1,000 words most associated with teenagers\nin the pretrained GloVe SWE reflect such problems. Given prompts about\nteenagers, 30% of outputs from GPT2-XL and 29% from LLaMA-2-7B GLMs discuss\nsocietal problems, most commonly violence, but also drug use, mental illness,\nand sexual taboo. Nepali models, while not free of such associations, are less\ndominated by social problems. Data from workshops with N=13 U.S. adolescents\nand N=18 Nepalese adolescents show that AI presentations are disconnected from\nteenage life, which revolves around activities like school and friendship.\nParticipant ratings of how well 20 trait words describe teens are decorrelated\nfrom SWE associations, with Pearson's r=.02, n.s. in English FastText and\nr=.06, n.s. in GloVe; and r=.06, n.s. in Nepali FastText and r=-.23, n.s. in\nGloVe. U.S. participants suggested AI could fairly present teens by\nhighlighting diversity, while Nepalese participants centered positivity.\nParticipants were optimistic that, if it learned from adolescents, rather than\nmedia sources, AI could help mitigate stereotypes. Our work offers an\nunderstanding of the ways SWEs and GLMs misrepresent a developmentally\nvulnerable group and provides a template for less sensationalized\ncharacterization.",
      "tldr_zh": "本研究探讨了AI中对青少年的表征偏见，通过双语（英语和尼泊尔语）和双文化（美国和尼泊尔）视角，分析静态词嵌入(SWEs)如GloVe和FastText，以及生成语言模型(GLMs)如GPT2-XL和LLaMA-2-7B。结果显示，英语SWEs和GLMs将青少年与社会问题（如暴力、毒品和精神疾病）高度关联，而尼泊尔模型的影响较小；与此对比，通过与N=13美国和N=18尼泊尔青少年的工作坊数据，发现AI描绘与青少年实际生活（如学校和友谊）脱节，参与者认为AI应强调多样性和积极性以减少刻板印象。该研究为理解AI误传弱势群体提供了模板，并建议AI从青少年来源学习以实现更公平的表征。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "Accepted at Artificial Intelligence, Ethics, and Society 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.01961v1",
      "published_date": "2024-08-04 08:35:02 UTC",
      "updated_date": "2024-08-04 08:35:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:51:33.807997"
    },
    {
      "arxiv_id": "2408.01960v1",
      "title": "AnomalySD: Few-Shot Multi-Class Anomaly Detection with Stable Diffusion Model",
      "title_zh": "AnomalySD：基于 Stable Diffusion 模型的少样本多类异常检测",
      "authors": [
        "Zhenyu Yan",
        "Qingqing Fang",
        "Wenxi Lv",
        "Qinliang Su"
      ],
      "abstract": "Anomaly detection is a critical task in industrial manufacturing, aiming to\nidentify defective parts of products. Most industrial anomaly detection methods\nassume the availability of sufficient normal data for training. This assumption\nmay not hold true due to the cost of labeling or data privacy policies.\nAdditionally, mainstream methods require training bespoke models for different\nobjects, which incurs heavy costs and lacks flexibility in practice. To address\nthese issues, we seek help from Stable Diffusion (SD) model due to its\ncapability of zero/few-shot inpainting, which can be leveraged to inpaint\nanomalous regions as normal. In this paper, a few-shot multi-class anomaly\ndetection framework that adopts Stable Diffusion model is proposed, named\nAnomalySD. To adapt SD to anomaly detection task, we design different\nhierarchical text descriptions and the foreground mask mechanism for\nfine-tuning SD. In the inference stage, to accurately mask anomalous regions\nfor inpainting, we propose multi-scale mask strategy and prototype-guided mask\nstrategy to handle diverse anomalous regions. Hierarchical text prompts are\nalso utilized to guide the process of inpainting in the inference stage. The\nanomaly score is estimated based on inpainting result of all masks. Extensive\nexperiments on the MVTec-AD and VisA datasets demonstrate the superiority of\nour approach. We achieved anomaly classification and segmentation results of\n93.6%/94.8% AUROC on the MVTec-AD dataset and 86.1%/96.5% AUROC on the VisA\ndataset under multi-class and one-shot settings.",
      "tldr_zh": "该论文提出AnomalySD框架，利用Stable Diffusion (SD)模型实现少样本(few-shot)多类(multi-class)异常检测，解决了传统方法依赖大量正常数据和针对特定对象的定制模型问题。通过SD的inpainting能力，框架在微调阶段设计分层文本描述和前景掩码机制；在推理阶段，采用多尺度掩码策略、原型引导掩码策略以及分层文本提示来精确处理异常区域，并基于inpainting结果计算异常分数。实验在MVTec-AD数据集上达到93.6%/94.8% AUROC（分类/分割），在VisA数据集上达到86.1%/96.5% AUROC，在多类一样本设置下表现出色，证明了框架的有效性和灵活性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "8 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.01960v1",
      "published_date": "2024-08-04 08:33:44 UTC",
      "updated_date": "2024-08-04 08:33:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:51:45.471738"
    },
    {
      "arxiv_id": "2408.01959v2",
      "title": "Dataset Scale and Societal Consistency Mediate Facial Impression Bias in Vision-Language AI",
      "title_zh": "数据集规模和社会一致性介导视觉语言AI中的面部印象偏差",
      "authors": [
        "Robert Wolfe",
        "Aayushi Dangol",
        "Alexis Hiniker",
        "Bill Howe"
      ],
      "abstract": "Multimodal AI models capable of associating images and text hold promise for\nnumerous domains, ranging from automated image captioning to accessibility\napplications for blind and low-vision users. However, uncertainty about bias\nhas in some cases limited their adoption and availability. In the present work,\nwe study 43 CLIP vision-language models to determine whether they learn\nhuman-like facial impression biases, and we find evidence that such biases are\nreflected across three distinct CLIP model families. We show for the first time\nthat the the degree to which a bias is shared across a society predicts the\ndegree to which it is reflected in a CLIP model. Human-like impressions of\nvisually unobservable attributes, like trustworthiness and sexuality, emerge\nonly in models trained on the largest dataset, indicating that a better fit to\nuncurated cultural data results in the reproduction of increasingly subtle\nsocial biases. Moreover, we use a hierarchical clustering approach to show that\ndataset size predicts the extent to which the underlying structure of facial\nimpression bias resembles that of facial impression bias in humans. Finally, we\nshow that Stable Diffusion models employing CLIP as a text encoder learn facial\nimpression biases, and that these biases intersect with racial biases in Stable\nDiffusion XL-Turbo. While pretrained CLIP models may prove useful for\nscientific studies of bias, they will also require significant dataset curation\nwhen intended for use as general-purpose models in a zero-shot setting.",
      "tldr_zh": "这篇论文研究了 CLIP 视觉语言模型是否会学习人类面部印象偏见，通过分析 43 个模型发现，这些偏见在三个模型家族中普遍存在，且其程度与社会中偏见的共享一致性相关。研究首次证明，只有在训练数据集规模最大的模型中，才会出现对 trustworthiness 和 sexuality 等不可视属性的偏见，这反映了更大数据集可能强化微妙的社会偏见。使用层次聚类方法，论文显示数据集大小决定了模型中面部印象偏见的结构是否类似于人类。此外，Stable Diffusion 模型继承了这些偏见，并与种族偏见相交，建议在零样本一般用途中需进行数据集整理以减少风险。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at Artificial Intelligence, Ethics, and Society 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.01959v2",
      "published_date": "2024-08-04 08:26:58 UTC",
      "updated_date": "2024-08-27 19:57:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:51:58.227944"
    },
    {
      "arxiv_id": "2408.02695v1",
      "title": "Distribution-Level Memory Recall for Continual Learning: Preserving Knowledge and Avoiding Confusion",
      "title_zh": "分布级别记忆召回用于持续学习：保留知识并避免混淆",
      "authors": [
        "Shaoxu Cheng",
        "Kanglei Geng",
        "Chiyuan He",
        "Zihuan Qiu",
        "Linfeng Xu",
        "Heqian Qiu",
        "Lanxiao Wang",
        "Qingbo Wu",
        "Fanman Meng",
        "Hongliang Li"
      ],
      "abstract": "Continual Learning (CL) aims to enable Deep Neural Networks (DNNs) to learn\nnew data without forgetting previously learned knowledge. The key to achieving\nthis goal is to avoid confusion at the feature level, i.e., avoiding confusion\nwithin old tasks and between new and old tasks. Previous prototype-based CL\nmethods generate pseudo features for old knowledge replay by adding Gaussian\nnoise to the centroids of old classes. However, the distribution in the feature\nspace exhibits anisotropy during the incremental process, which prevents the\npseudo features from faithfully reproducing the distribution of old knowledge\nin the feature space, leading to confusion in classification boundaries within\nold tasks. To address this issue, we propose the Distribution-Level Memory\nRecall (DMR) method, which uses a Gaussian mixture model to precisely fit the\nfeature distribution of old knowledge at the distribution level and generate\npseudo features in the next stage. Furthermore, resistance to confusion at the\ndistribution level is also crucial for multimodal learning, as the problem of\nmultimodal imbalance results in significant differences in feature responses\nbetween different modalities, exacerbating confusion within old tasks in\nprototype-based CL methods. Therefore, we mitigate the multi-modal imbalance\nproblem by using the Inter-modal Guidance and Intra-modal Mining (IGIM) method\nto guide weaker modalities with prior information from dominant modalities and\nfurther explore useful information within modalities. For the second key, We\npropose the Confusion Index to quantitatively describe a model's ability to\ndistinguish between new and old tasks, and we use the Incremental Mixup Feature\nEnhancement (IMFE) method to enhance pseudo features with new sample features,\nalleviating classification confusion between new and old knowledge.",
      "tldr_zh": "本研究针对持续学习(Continual Learning)中深度神经网络(DNNs)学习新数据时遗忘旧知识的问题，提出Distribution-Level Memory Recall (DMR)方法，使用Gaussian mixture model精确拟合旧知识特征分布，并生成更准确的伪特征，以避免特征空间内的分类边界混淆。针对多模态学习中的多模态不平衡问题，该方法引入Inter-modal Guidance and Intra-modal Mining (IGIM)技术，通过主导模态指导较弱模态并挖掘模态内信息，缓解旧任务内部的混淆。此外，研究定义了Confusion Index来量化模型区分新旧任务的能力，并采用Incremental Mixup Feature Enhancement (IMFE)方法，通过混合新样本特征增强伪特征，减少新旧知识间的分类混淆。这些创新显著提高了持续学习的性能和鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.02695v1",
      "published_date": "2024-08-04 07:37:12 UTC",
      "updated_date": "2024-08-04 07:37:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:52:10.241459"
    },
    {
      "arxiv_id": "2408.01942v1",
      "title": "Visual Grounding for Object-Level Generalization in Reinforcement Learning",
      "title_zh": "视觉 grounding 用于强化学习中的对象级泛化",
      "authors": [
        "Haobin Jiang",
        "Zongqing Lu"
      ],
      "abstract": "Generalization is a pivotal challenge for agents following natural language\ninstructions. To approach this goal, we leverage a vision-language model (VLM)\nfor visual grounding and transfer its vision-language knowledge into\nreinforcement learning (RL) for object-centric tasks, which makes the agent\ncapable of zero-shot generalization to unseen objects and instructions. By\nvisual grounding, we obtain an object-grounded confidence map for the target\nobject indicated in the instruction. Based on this map, we introduce two routes\nto transfer VLM knowledge into RL. Firstly, we propose an object-grounded\nintrinsic reward function derived from the confidence map to more effectively\nguide the agent towards the target object. Secondly, the confidence map offers\na more unified, accessible task representation for the agent's policy, compared\nto language embeddings. This enables the agent to process unseen objects and\ninstructions through comprehensible visual confidence maps, facilitating\nzero-shot object-level generalization. Single-task experiments prove that our\nintrinsic reward significantly improves performance on challenging skill\nlearning. In multi-task experiments, through testing on tasks beyond the\ntraining set, we show that the agent, when provided with the confidence map as\nthe task representation, possesses better generalization capabilities than\nlanguage-based conditioning. The code is available at\nhttps://github.com/PKU-RL/COPL.",
      "tldr_zh": "这篇论文提出了一种利用视觉语言模型(VLM)进行视觉 grounding 的方法，将其知识转移到强化学习(RL)中，以实现对象中心任务的零样本泛化。作者基于目标对象的置信度地图(confidence map)设计了内在奖励函数(intrinsic reward)来引导代理更有效地定位目标，并使用置信度地图作为统一的任务表示(task representation)，从而处理未见对象和指令。实验结果表明，该方法在单任务场景显著提升了技能学习表现，在多任务测试中，代理的泛化能力优于基于语言嵌入的基准模型。",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "35 pages, 14 figures, 17 tables",
      "pdf_url": "http://arxiv.org/pdf/2408.01942v1",
      "published_date": "2024-08-04 06:34:24 UTC",
      "updated_date": "2024-08-04 06:34:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:52:20.067548"
    },
    {
      "arxiv_id": "2408.03160v2",
      "title": "User-in-the-loop Evaluation of Multimodal LLMs for Activity Assistance",
      "title_zh": "翻译失败",
      "authors": [
        "Mrinal Verghese",
        "Brian Chen",
        "Hamid Eghbalzadeh",
        "Tushar Nagarajan",
        "Ruta Desai"
      ],
      "abstract": "Our research investigates the capability of modern multimodal reasoning\nmodels, powered by Large Language Models (LLMs), to facilitate vision-powered\nassistants for multi-step daily activities. Such assistants must be able to 1)\nencode relevant visual history from the assistant's sensors, e.g., camera, 2)\nforecast future actions for accomplishing the activity, and 3) replan based on\nthe user in the loop. To evaluate the first two capabilities, grounding visual\nhistory and forecasting in short and long horizons, we conduct benchmarking of\ntwo prominent classes of multimodal LLM approaches -- Socratic Models and\nVision Conditioned Language Models (VCLMs) on video-based action anticipation\ntasks using offline datasets. These offline benchmarks, however, do not allow\nus to close the loop with the user, which is essential to evaluate the\nreplanning capabilities and measure successful activity completion in assistive\nscenarios. To that end, we conduct a first-of-its-kind user study, with 18\nparticipants performing 3 different multi-step cooking activities while wearing\nan egocentric observation device called Aria and following assistance from\nmultimodal LLMs. We find that the Socratic approach outperforms VCLMs in both\noffline and online settings. We further highlight how grounding long visual\nhistory, common in activity assistance, remains challenging in current models,\nespecially for VCLMs, and demonstrate that offline metrics do not indicate\nonline performance.",
      "tldr_zh": "本文研究评估了多模态大型语言模型(Multimodal LLMs)在辅助多步日常活动中的能力，包括编码视觉历史、预测未来行动以及基于用户反馈(User-in-the-loop)进行重新规划。研究者通过离线基准测试在视频-based 行动预测任务上比较了Socratic Models和Vision Conditioned Language Models(VCLMs)，并进行了首创的用户研究，涉及18名参与者佩戴egocentric设备(Aria)进行烹饪活动。结果表明，Socratic Models在离线和在线设置中优于VCLMs，但当前模型在处理长视觉历史时仍面临挑战，且离线指标无法准确反映在线性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "9 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.03160v2",
      "published_date": "2024-08-04 06:12:42 UTC",
      "updated_date": "2024-08-12 01:59:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:52:34.187756"
    },
    {
      "arxiv_id": "2408.01935v1",
      "title": "Defining and Evaluating Decision and Composite Risk in Language Models Applied to Natural Language Inference",
      "title_zh": "在应用于自然语言推理的语言模型中定义和评估决策风险与复合风险",
      "authors": [
        "Ke Shen",
        "Mayank Kejriwal"
      ],
      "abstract": "Despite their impressive performance, large language models (LLMs) such as\nChatGPT are known to pose important risks. One such set of risks arises from\nmisplaced confidence, whether over-confidence or under-confidence, that the\nmodels have in their inference. While the former is well studied, the latter is\nnot, leading to an asymmetry in understanding the comprehensive risk of the\nmodel based on misplaced confidence. In this paper, we address this asymmetry\nby defining two types of risk (decision and composite risk), and proposing an\nexperimental framework consisting of a two-level inference architecture and\nappropriate metrics for measuring such risks in both discriminative and\ngenerative LLMs. The first level relies on a decision rule that determines\nwhether the underlying language model should abstain from inference. The second\nlevel (which applies if the model does not abstain) is the model's inference.\nDetailed experiments on four natural language commonsense reasoning datasets\nusing both an open-source ensemble-based RoBERTa model and ChatGPT, demonstrate\nthe practical utility of the evaluation framework. For example, our results\nshow that our framework can get an LLM to confidently respond to an extra 20.1%\nof low-risk inference tasks that other methods might misclassify as high-risk,\nand skip 19.8% of high-risk tasks, which would have been answered incorrectly.",
      "tldr_zh": "这篇论文定义了语言模型在自然语言推理（Natural Language Inference）中的两种风险：decision risk 和 composite risk，以解决模型 misplaced confidence（如 over-confidence 或 under-confidence）导致的不对称问题。作者提出一个实验框架，包括两级推理架构（第一级使用决策规则决定是否放弃推理，第二级进行模型推理）和相应指标，用于评估 discriminative 和 generative LLMs。实验结果显示，在四个自然语言常识推理数据集上，使用 RoBERTa 和 ChatGPT，该框架能让模型额外自信处理20.1%的低风险任务，同时跳过19.8%的高风险任务，从而提高整体推理准确性和可靠性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "arXiv admin note: text overlap with arXiv:2310.03283",
      "pdf_url": "http://arxiv.org/pdf/2408.01935v1",
      "published_date": "2024-08-04 05:24:32 UTC",
      "updated_date": "2024-08-04 05:24:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:52:47.223035"
    },
    {
      "arxiv_id": "2408.01933v4",
      "title": "DiReCT: Diagnostic Reasoning for Clinical Notes via Large Language Models",
      "title_zh": "DiReCT：通过大型语言模型对临床笔记进行诊断推理",
      "authors": [
        "Bowen Wang",
        "Jiuyang Chang",
        "Yiming Qian",
        "Guoxin Chen",
        "Junhao Chen",
        "Zhouqiang Jiang",
        "Jiahao Zhang",
        "Yuta Nakashima",
        "Hajime Nagahara"
      ],
      "abstract": "Large language models (LLMs) have recently showcased remarkable capabilities,\nspanning a wide range of tasks and applications, including those in the medical\ndomain. Models like GPT-4 excel in medical question answering but may face\nchallenges in the lack of interpretability when handling complex tasks in real\nclinical settings. We thus introduce the diagnostic reasoning dataset for\nclinical notes (DiReCT), aiming at evaluating the reasoning ability and\ninterpretability of LLMs compared to human doctors. It contains 511 clinical\nnotes, each meticulously annotated by physicians, detailing the diagnostic\nreasoning process from observations in a clinical note to the final diagnosis.\nAdditionally, a diagnostic knowledge graph is provided to offer essential\nknowledge for reasoning, which may not be covered in the training data of\nexisting LLMs. Evaluations of leading LLMs on DiReCT bring out a significant\ngap between their reasoning ability and that of human doctors, highlighting the\ncritical need for models that can reason effectively in real-world clinical\nscenarios.",
      "tldr_zh": "该研究引入了 DiReCT 数据集，用于评估大型语言模型 (LLMs) 在临床笔记上的诊断推理能力及其可解释性。数据集包含 511 个由医生标注的临床笔记，详细记录了从观察到最终诊断的推理过程，并提供了一个诊断知识图谱以补充可能缺失的知识。评估结果显示，领先的 LLMs 与人类医生相比存在显著推理差距，突出了在真实临床场景中开发更可靠推理模型的迫切需求。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages,6 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.01933v4",
      "published_date": "2024-08-04 05:15:02 UTC",
      "updated_date": "2025-01-13 07:13:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:52:58.225928"
    },
    {
      "arxiv_id": "2408.01928v1",
      "title": "A Semi-supervised Multi-channel Graph Convolutional Network for Query Classification in E-commerce",
      "title_zh": "一种半监督多通道图卷积网络用于电子商务查询分类",
      "authors": [
        "Chunyuan Yuan",
        "Ming Pang",
        "Zheng Fang",
        "Xue Jiang",
        "Changping Peng",
        "Zhangang Lin"
      ],
      "abstract": "Query intent classification is an essential module for customers to find\ndesired products on the e-commerce application quickly. Most existing query\nintent classification methods rely on the users' click behavior as a supervised\nsignal to construct training samples. However, these methods based entirely on\nposterior labels may lead to serious category imbalance problems because of the\nMatthew effect in click samples. Compared with popular categories, it is\ndifficult for products under long-tail categories to obtain traffic and user\nclicks, which makes the models unable to detect users' intent for products\nunder long-tail categories. This in turn aggravates the problem that long-tail\ncategories cannot obtain traffic, forming a vicious circle. In addition, due to\nthe randomness of the user's click, the posterior label is unstable for the\nquery with similar semantics, which makes the model very sensitive to the\ninput, leading to an unstable and incomplete recall of categories.\n  In this paper, we propose a novel Semi-supervised Multi-channel Graph\nConvolutional Network (SMGCN) to address the above problems from the\nperspective of label association and semi-supervised learning. SMGCN extends\ncategory information and enhances the posterior label by utilizing the\nsimilarity score between the query and categories. Furthermore, it leverages\nthe co-occurrence and semantic similarity graph of categories to strengthen the\nrelations among labels and weaken the influence of posterior label instability.\nWe conduct extensive offline and online A/B experiments, and the experimental\nresults show that SMGCN significantly outperforms the strong baselines, which\nshows its effectiveness and practicality.",
      "tldr_zh": "本研究针对电商查询意图分类中的类别不平衡和后验标签不稳定问题，提出了一种新型的 Semi-supervised Multi-channel Graph Convolutional Network (SMGCN)。SMGCN 通过利用查询与类别的相似性分数来扩展类别信息并增强后验标签，同时构建类别的共现和语义相似性图，以加强标签关系并减弱标签不稳定的影响。相比传统方法，该框架从标签关联和半监督学习的视角有效缓解长尾类别问题。实验结果表明，SMGCN 在离线和在线 A/B 测试中显著优于基线模型，证明了其在电商应用中的实用性和有效性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by WWW2024",
      "pdf_url": "http://arxiv.org/pdf/2408.01928v1",
      "published_date": "2024-08-04 04:52:21 UTC",
      "updated_date": "2024-08-04 04:52:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:53:14.086843"
    },
    {
      "arxiv_id": "2408.01916v2",
      "title": "MAO: A Framework for Process Model Generation with Multi-Agent Orchestration",
      "title_zh": "MAO：一种用于过程模型生成的多智能体编排框架",
      "authors": [
        "Leilei Lin",
        "Yumeng Jin",
        "Yingming Zhou",
        "Wenlong Chen",
        "Chen Qian"
      ],
      "abstract": "Process models are frequently used in software engineering to describe\nbusiness requirements, guide software testing and control system improvement.\nHowever, traditional process modeling methods often require the participation\nof numerous experts, which is expensive and time-consuming. Therefore, the\nexploration of a more efficient and cost-effective automated modeling method\nhas emerged as a focal point in current research. This article explores a\nframework for automatically generating process models with multi-agent\norchestration (MAO), aiming to enhance the efficiency of process modeling and\noffer valuable insights for domain experts. Our framework MAO leverages large\nlanguage models as the cornerstone for multi-agent, employing an innovative\nprompt strategy to ensure efficient collaboration among multi-agent.\nSpecifically, 1) generation. The first phase of MAO is to generate a slightly\nrough process model from the text description; 2) refinement. The agents would\ncontinuously refine the initial process model through multiple rounds of\ndialogue; 3) reviewing. Large language models are prone to hallucination\nphenomena among multi-turn dialogues, so the agents need to review and repair\nsemantic hallucinations in process models; 4) testing. The representation of\nprocess models is diverse. Consequently, the agents utilize external tools to\ntest whether the generated process model contains format errors, namely format\nhallucinations, and then adjust the process model to conform to the output\nparadigm. The experiments demonstrate that the process models generated by our\nframework outperform existing methods and surpass manual modeling by 89%, 61%,\n52%, and 75% on four different datasets, respectively.",
      "tldr_zh": "本文提出 MAO 框架，利用 multi-agent orchestration 和 large language models 作为核心，通过创新的提示策略实现过程模型的自动生成，以解决传统建模方法依赖专家参与的低效问题。框架包括四个阶段：从文本描述生成粗略模型、通过多轮对话进行 refinement、审查并修复 semantic hallucinations，以及使用外部工具测试和修正 format hallucinations。实验结果显示，MAO 生成的模型在四个数据集上分别比现有方法和手动建模高出 89%、61%、52% 和 75%，显著提升了建模效率和准确性。",
      "categories": [
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.01916v2",
      "published_date": "2024-08-04 03:32:17 UTC",
      "updated_date": "2024-08-07 10:37:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:53:23.187846"
    },
    {
      "arxiv_id": "2408.01904v2",
      "title": "The Artificial Intelligence Disclosure (AID) Framework: An Introduction",
      "title_zh": "人工智能披露 (AID) 框架：导论",
      "authors": [
        "Kari D. Weaver"
      ],
      "abstract": "As the use of Generative Artificial Intelligence tools have grown in higher\neducation and research, there have been increasing calls for transparency and\ngranularity around the use and attribution of the use of these tools. Thus far,\nthis need has been met via the recommended inclusion of a note, with little to\nno guidance on what the note itself should include. This has been identified as\na problem to the use of AI in academic and research contexts. This article\nintroduces The Artificial Intelligence Disclosure (AID) Framework, a standard,\ncomprehensive, and detailed framework meant to inform the development and\nwriting of GenAI disclosure for education and research.",
      "tldr_zh": "该研究针对生成式人工智能（Generative Artificial Intelligence）工具在高等教育和研究中的广泛应用，强调了透明度和详细归因的必要性，因为当前仅推荐添加简单说明而缺乏具体指导，导致学术使用面临问题。文章引入了人工智能披露框架（The Artificial Intelligence Disclosure (AID) Framework），这是一个标准、全面且详细的框架，旨在指导教育和研究人员开发及撰写GenAI披露内容。该框架有助于提升AI在学术环境中的可信度和规范性，从而解决现有挑战。",
      "categories": [
        "cs.DL",
        "cs.AI"
      ],
      "primary_category": "cs.DL",
      "comment": "5 pages",
      "pdf_url": "http://arxiv.org/pdf/2408.01904v2",
      "published_date": "2024-08-04 02:18:42 UTC",
      "updated_date": "2025-04-09 19:03:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:53:33.781884"
    },
    {
      "arxiv_id": "2408.02694v1",
      "title": "KAN based Autoencoders for Factor Models",
      "title_zh": "翻译失败",
      "authors": [
        "Tianqi Wang",
        "Shubham Singh"
      ],
      "abstract": "Inspired by recent advances in Kolmogorov-Arnold Networks (KANs), we\nintroduce a novel approach to latent factor conditional asset pricing models.\nWhile previous machine learning applications in asset pricing have\npredominantly used Multilayer Perceptrons with ReLU activation functions to\nmodel latent factor exposures, our method introduces a KAN-based autoencoder\nwhich surpasses MLP models in both accuracy and interpretability. Our model\noffers enhanced flexibility in approximating exposures as nonlinear functions\nof asset characteristics, while simultaneously providing users with an\nintuitive framework for interpreting latent factors. Empirical backtesting\ndemonstrates our model's superior ability to explain cross-sectional risk\nexposures. Moreover, long-short portfolios constructed using our model's\npredictions achieve higher Sharpe ratios, highlighting its practical value in\ninvestment management.",
      "tldr_zh": "本研究引入了一种基于 Kolmogorov-Arnold Networks (KANs) 的自编码器，用于潜在因子资产定价模型，以取代传统的 Multilayer Perceptrons (MLPs) 方法。KAN-based autoencoder 提供了更高的准确性和可解释性，能够更灵活地近似资产特征的非线性函数，并为用户提供直观的潜在因子解释框架。实证回测结果显示，该模型在解释横截面风险暴露方面表现出色，使用其预测构建的长短组合实现了更高的 Sharpe ratios，具有实际的投资管理价值。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-fin.CP"
      ],
      "primary_category": "cs.LG",
      "comment": "7 pages",
      "pdf_url": "http://arxiv.org/pdf/2408.02694v1",
      "published_date": "2024-08-04 02:02:09 UTC",
      "updated_date": "2024-08-04 02:02:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:53:47.628304"
    },
    {
      "arxiv_id": "2408.04651v1",
      "title": "Knowledge AI: Fine-tuning NLP Models for Facilitating Scientific Knowledge Extraction and Understanding",
      "title_zh": "翻译失败",
      "authors": [
        "Balaji Muralidharan",
        "Hayden Beadles",
        "Reza Marzban",
        "Kalyan Sashank Mupparaju"
      ],
      "abstract": "This project investigates the efficacy of Large Language Models (LLMs) in\nunderstanding and extracting scientific knowledge across specific domains and\nto create a deep learning framework: Knowledge AI. As a part of this framework,\nwe employ pre-trained models and fine-tune them on datasets in the scientific\ndomain. The models are adapted for four key Natural Language Processing (NLP)\ntasks: summarization, text generation, question answering, and named entity\nrecognition. Our results indicate that domain-specific fine-tuning\nsignificantly enhances model performance in each of these tasks, thereby\nimproving their applicability for scientific contexts. This adaptation enables\nnon-experts to efficiently query and extract information within targeted\nscientific fields, demonstrating the potential of fine-tuned LLMs as a tool for\nknowledge discovery in the sciences.",
      "tldr_zh": "这篇论文探讨了大型语言模型 (LLMs) 在科学知识提取和理解中的效能，并开发了 Knowledge AI 框架。该框架通过在科学领域数据集上微调预训练模型，针对四个关键 Natural Language Processing (NLP) 任务——summarization（总结）、text generation（文本生成）、question answering（问答）和named entity recognition（命名实体识别）——来提升模型性能。研究结果表明，领域特定的fine-tuning 显著提高了模型在科学语境中的适用性，使非专家能够高效查询和提取信息，从而促进科学知识的发现。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "11 pages",
      "pdf_url": "http://arxiv.org/pdf/2408.04651v1",
      "published_date": "2024-08-04 01:32:09 UTC",
      "updated_date": "2024-08-04 01:32:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:54:00.087713"
    },
    {
      "arxiv_id": "2408.01892v1",
      "title": "Re-ENACT: Reinforcement Learning for Emotional Speech Generation using Actor-Critic Strategy",
      "title_zh": "Re-ENACT：使用Actor-Critic策略的强化学习用于情感语音生成",
      "authors": [
        "Ravi Shankar",
        "Archana Venkataraman"
      ],
      "abstract": "In this paper, we propose the first method to modify the prosodic features of\na given speech signal using actor-critic reinforcement learning strategy. Our\napproach uses a Bayesian framework to identify contiguous segments of\nimportance that links segments of the given utterances to perception of\nemotions in humans. We train a neural network to produce the variational\nposterior of a collection of Bernoulli random variables; our model applies a\nMarkov prior on it to ensure continuity. A sample from this distribution is\nused for downstream emotion prediction. Further, we train the neural network to\npredict a soft assignment over emotion categories as the target variable. In\nthe next step, we modify the prosodic features (pitch, intensity, and rhythm)\nof the masked segment to increase the score of target emotion. We employ an\nactor-critic reinforcement learning to train the prosody modifier by\ndiscretizing the space of modifications. Further, it provides a simple solution\nto the problem of gradient computation through WSOLA operation for rhythm\nmanipulation. Our experiments demonstrate that this framework changes the\nperceived emotion of a given speech utterance to the target. Further, we show\nthat our unified technique is on par with state-of-the-art emotion conversion\nmodels from supervised and unsupervised domains that require pairwise training.",
      "tldr_zh": "本研究提出Re-ENACT，一种使用actor-critic强化学习策略的框架，用于修改给定语音信号的prosodic features（韵律特征），以生成目标情感的语音。首先，该方法采用Bayesian框架识别重要连续段落，并训练神经网络产生Bernoulli随机变量的变分后验，结合Markov先验确保连续性，并通过样本进行情感预测。随后，actor-critic强化学习用于优化pitch、intensity和rhythm的修改，并解决WSOLA操作的梯度计算问题。实验结果表明，该框架能有效改变语音的感知情感，与最先进的情感转换模型相当，且无需配对训练数据。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.AS",
      "comment": "7 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.01892v1",
      "published_date": "2024-08-04 00:47:29 UTC",
      "updated_date": "2024-08-04 00:47:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:54:11.040729"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 48,
  "processed_papers_count": 48,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-19T12:54:31.071530"
}