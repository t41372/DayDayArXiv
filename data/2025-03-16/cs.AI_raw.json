[
  {
    "arxiv_id": "2503.12688v1",
    "title": "Dynamic Angle Selection in X-Ray CT: A Reinforcement Learning Approach to Optimal Stopping",
    "authors": [
      "Tianyuan Wang"
    ],
    "abstract": "In industrial X-ray Computed Tomography (CT), the need for rapid in-line\ninspection is critical. Sparse-angle tomography plays a significant role in\nthis by reducing the required number of projections, thereby accelerating\nprocessing and conserving resources. Most existing methods aim to balance\nreconstruction quality and scanning time, typically relying on fixed scan\ndurations. Adaptive adjustment of the number of angles is essential; for\ninstance, more angles may be required for objects with complex geometries or\nnoisier projections. The concept of optimal stopping, which dynamically adjusts\nthis balance according to varying industrial needs, remains underutilized.\nBuilding on our previous work, we integrate optimal stopping into sequential\nOptimal Experimental Design (OED). We propose a novel method for computing the\npolicy gradient within the Actor-Critic framework, enabling the development of\nadaptive policies for informative angle selection and scan termination.\nAdditionally, we investigated the gap between simulation and real-world\napplications in the context of the developed learning-based method. Our trained\nmodel, developed using synthetic data, demonstrates reliable performance when\napplied to real-world data. This approach enhances the flexibility of CT\noperations and expands the applicability of sparse-angle tomography in\nindustrial settings.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.12688v1",
    "published_date": "2025-03-16 23:09:13 UTC",
    "updated_date": "2025-03-16 23:09:13 UTC"
  },
  {
    "arxiv_id": "2503.12687v1",
    "title": "AI Agents: Evolution, Architecture, and Real-World Applications",
    "authors": [
      "Naveen Krishnan"
    ],
    "abstract": "This paper examines the evolution, architecture, and practical applications\nof AI agents from their early, rule-based incarnations to modern sophisticated\nsystems that integrate large language models with dedicated modules for\nperception, planning, and tool use. Emphasizing both theoretical foundations\nand real-world deployments, the paper reviews key agent paradigms, discusses\nlimitations of current evaluation benchmarks, and proposes a holistic\nevaluation framework that balances task effectiveness, efficiency, robustness,\nand safety. Applications across enterprise, personal assistance, and\nspecialized domains are analyzed, with insights into future research directions\nfor more resilient and adaptive AI agent systems.",
    "categories": [
      "cs.AI",
      "68T05, 68T20",
      "I.2.6; I.2.8; I.2.11"
    ],
    "primary_category": "cs.AI",
    "comment": "52 pages, 4 figures, comprehensive survey and analysis of AI agent\n  evolution, architecture, evaluation frameworks, and applications",
    "pdf_url": "http://arxiv.org/pdf/2503.12687v1",
    "published_date": "2025-03-16 23:07:48 UTC",
    "updated_date": "2025-03-16 23:07:48 UTC"
  },
  {
    "arxiv_id": "2503.12667v1",
    "title": "Plausibility Vaccine: Injecting LLM Knowledge for Event Plausibility",
    "authors": [
      "Jacob Chmura",
      "Jonah Dauvet",
      "Sebastian Sabry"
    ],
    "abstract": "Despite advances in language modelling, distributional methods that build\nsemantic representations from co-occurrences fail to discriminate between\nplausible and implausible events. In this work, we investigate how plausibility\nprediction can be improved by injecting latent knowledge prompted from large\nlanguage models using parameter-efficient fine-tuning. We train 12 task\nadapters to learn various physical properties and association measures and\nperform adapter fusion to compose latent semantic knowledge from each task on\ntop of pre-trained AlBERT embeddings. We automate auxiliary task data\ngeneration, which enables us to scale our approach and fine-tune our learned\nrepresentations across two plausibility datasets. Our code is available at\nhttps://github.com/Jacob-Chmura/plausibility-vaccine.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.12667v1",
    "published_date": "2025-03-16 21:55:17 UTC",
    "updated_date": "2025-03-16 21:55:17 UTC"
  },
  {
    "arxiv_id": "2503.12651v1",
    "title": "VeriLA: A Human-Centered Evaluation Framework for Interpretable Verification of LLM Agent Failures",
    "authors": [
      "Yoo Yeon Sung",
      "Hannah Kim",
      "Dan Zhang"
    ],
    "abstract": "AI practitioners increasingly use large language model (LLM) agents in\ncompound AI systems to solve complex reasoning tasks, these agent executions\noften fail to meet human standards, leading to errors that compromise the\nsystem's overall performance. Addressing these failures through human\nintervention is challenging due to the agents' opaque reasoning processes,\nmisalignment with human expectations, the complexity of agent dependencies, and\nthe high cost of manual inspection. This paper thus introduces a human-centered\nevaluation framework for Verifying LLM Agent failures (VeriLA), which\nsystematically assesses agent failures to reduce human effort and make these\nagent failures interpretable to humans. The framework first defines clear\nexpectations of each agent by curating human-designed agent criteria. Then, it\ndevelops a human-aligned agent verifier module, trained with human gold\nstandards, to assess each agent's execution output. This approach enables\ngranular evaluation of each agent's performance by revealing failures from a\nhuman standard, offering clear guidelines for revision, and reducing human\ncognitive load. Our case study results show that VeriLA is both interpretable\nand efficient in helping practitioners interact more effectively with the\nsystem. By upholding accountability in human-agent collaboration, VeriLA paves\nthe way for more trustworthy and human-aligned compound AI systems.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.12651v1",
    "published_date": "2025-03-16 21:11:18 UTC",
    "updated_date": "2025-03-16 21:11:18 UTC"
  },
  {
    "arxiv_id": "2503.12649v2",
    "title": "FW-Merging: Scaling Model Merging with Frank-Wolfe Optimization",
    "authors": [
      "Hao Mark Chen",
      "Shell Xu Hu",
      "Wayne Luk",
      "Timothy Hospedales",
      "Hongxiang Fan"
    ],
    "abstract": "Model merging has emerged as a promising approach for multi-task learning\n(MTL), offering a data-efficient alternative to conventional fine-tuning.\nHowever, with the rapid development of the open-source AI ecosystem and the\nincreasing availability of fine-tuned foundation models, existing model merging\nmethods face two key limitations: (i) They are primarily designed for in-house\nfine-tuned models, making them less adaptable to diverse model sources with\npartially unknown model and task information, (ii) They struggle to scale\neffectively when merging numerous model checkpoints. To address these\nchallenges, we formulate model merging as a constrained optimization problem\nand introduce a novel approach: Frank-Wolfe Merging (FW-Merging). Inspired by\nFrank-Wolfe optimization, our approach iteratively selects the most relevant\nmodel in the pool to minimize a linear approximation of the objective function\nand then executes a local merging similar to the Frank-Wolfe update. The\nobjective function is designed to capture the desired behavior of the\ntarget-merged model, while the fine-tuned candidate models define the\nconstraint set. More importantly, FW-Merging serves as an orthogonal technique\nfor existing merging methods, seamlessly integrating with them to further\nenhance accuracy performance. Our experiments show that FW-Merging scales\nacross diverse model sources, remaining stable with 16 irrelevant models and\nimproving by 15.3% with 16 relevant models on 20 CV tasks, while maintaining\nconstant memory overhead, unlike the linear overhead of data-informed merging\nmethods. Compared with the state-of-the-art approaches, FW-Merging surpasses\nthe data-free merging method by 32.8% and outperforms the data-informed\nAdamerging by 8.39% when merging 20 ViT models. Our code is open-sourced at\ngithub.com/hmarkc/FW-Merging.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.12649v2",
    "published_date": "2025-03-16 21:07:05 UTC",
    "updated_date": "2025-03-25 15:31:07 UTC"
  },
  {
    "arxiv_id": "2503.12642v2",
    "title": "COVID 19 Diagnosis Analysis using Transfer Learning",
    "authors": [
      "Anjali Dharmik"
    ],
    "abstract": "Coronaviruses, including SARS-CoV-2, are responsible for COVID-19, a highly\ntransmissible disease that emerged in December 2019 in Wuhan, China. During the\npast five years, significant advancements have been made in understanding and\nmitigating the virus. Although the initial outbreak led to global health\ncrises, improved vaccination strategies, antiviral treatments, and AI-driven\ndiagnostic tools have contributed to better disease management. However,\nCOVID-19 continues to pose risks, particularly for immuno-compromised\nindividuals and those with pre-existing conditions. This study explores the use\nof deep learning for a rapid and accurate diagnosis of COVID-19, addressing\nongoing challenges in healthcare infrastructure and testing accessibility. We\npropose an enhanced automated detection system leveraging state-of-the-art\nconvolutional neural networks (CNNs), including updated versions of VGG16,\nVGG19, and ResNet50, to classify COVID-19 infections from chest radiographs and\ncomputerized tomography (CT) scans. Our results, based on an expanded dataset\nof over 6000 medical images, demonstrate that the optimized ResNet50 model\nachieves the highest classification performance, with 97.77% accuracy, 100%\nsensitivity, 93.33% specificity, and a 98.0% F1-score. These findings reinforce\nthe potential of AI-assisted diagnostic tools in improving early detection and\npandemic preparedness.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.12642v2",
    "published_date": "2025-03-16 20:33:39 UTC",
    "updated_date": "2025-03-23 17:38:40 UTC"
  },
  {
    "arxiv_id": "2503.13554v1",
    "title": "LLMs' Leaning in European Elections",
    "authors": [
      "Federico Ricciuti"
    ],
    "abstract": "Many studies suggest that LLMs have left wing leans. The article extends the\nUS presidential election analysis made in previous works, where multiple LLMs\nwere asked to vote between Joe Biden and Donald Trump in a virtual election,\nand the results showed a clear lean of LLMs toward Joe Biden. This article\nconsiders natural follow-up questions that could arise from that experiment,\nsuch as: what is the extent of this phenomenon? Is it generalizable to multiple\nvirtual elections in other countries? The article considers virtual elections\nin ten european countries: Germany, France, Italy, Spain, Poland, Romania,\nNetherlands, Belgium, Czech Republic, and Sweden, and with four different LLMs:\ngpt4o, claude 3.5 sonnet, mistral-large, and gemini-2.0-flash.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.13554v1",
    "published_date": "2025-03-16 20:17:11 UTC",
    "updated_date": "2025-03-16 20:17:11 UTC"
  },
  {
    "arxiv_id": "2503.13553v1",
    "title": "LLM-Mediated Guidance of MARL Systems",
    "authors": [
      "Philipp D. Siedler",
      "Ian Gemp"
    ],
    "abstract": "In complex multi-agent environments, achieving efficient learning and\ndesirable behaviours is a significant challenge for Multi-Agent Reinforcement\nLearning (MARL) systems. This work explores the potential of combining MARL\nwith Large Language Model (LLM)-mediated interventions to guide agents toward\nmore desirable behaviours. Specifically, we investigate how LLMs can be used to\ninterpret and facilitate interventions that shape the learning trajectories of\nmultiple agents. We experimented with two types of interventions, referred to\nas controllers: a Natural Language (NL) Controller and a Rule-Based (RB)\nController. The NL Controller, which uses an LLM to simulate human-like\ninterventions, showed a stronger impact than the RB Controller. Our findings\nindicate that agents particularly benefit from early interventions, leading to\nmore efficient training and higher performance. Both intervention types\noutperform the baseline without interventions, highlighting the potential of\nLLM-mediated guidance to accelerate training and enhance MARL performance in\nchallenging environments.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.MA",
    "comment": "31 pages, 50 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.13553v1",
    "published_date": "2025-03-16 20:16:13 UTC",
    "updated_date": "2025-03-16 20:16:13 UTC"
  },
  {
    "arxiv_id": "2503.12637v1",
    "title": "Understanding Driver Cognition and Decision-Making Behaviors in High-Risk Scenarios: A Drift Diffusion Perspective",
    "authors": [
      "Heye Huang",
      "Zheng Li",
      "Hao Cheng",
      "Haoran Wang",
      "Junkai Jiang",
      "Xiaopeng Li",
      "Arkady Zgonnikov"
    ],
    "abstract": "Ensuring safe interactions between autonomous vehicles (AVs) and human\ndrivers in mixed traffic systems remains a major challenge, particularly in\ncomplex, high-risk scenarios. This paper presents a cognition-decision\nframework that integrates individual variability and commonalities in driver\nbehavior to quantify risk cognition and model dynamic decision-making. First, a\nrisk sensitivity model based on a multivariate Gaussian distribution is\ndeveloped to characterize individual differences in risk cognition. Then, a\ncognitive decision-making model based on the drift diffusion model (DDM) is\nintroduced to capture common decision-making mechanisms in high-risk\nenvironments. The DDM dynamically adjusts decision thresholds by integrating\ninitial bias, drift rate, and boundary parameters, adapting to variations in\nspeed, relative distance, and risk sensitivity to reflect diverse driving\nstyles and risk preferences. By simulating high-risk scenarios with lateral,\nlongitudinal, and multidimensional risk sources in a driving simulator, the\nproposed model accurately predicts cognitive responses and decision behaviors\nduring emergency maneuvers. Specifically, by incorporating driver-specific risk\nsensitivity, the model enables dynamic adjustments of key DDM parameters,\nallowing for personalized decision-making representations in diverse scenarios.\nComparative analysis with IDM, Gipps, and MOBIL demonstrates that DDM more\nprecisely captures human cognitive processes and adaptive decision-making in\nhigh-risk scenarios. These findings provide a theoretical basis for modeling\nhuman driving behavior and offer critical insights for enhancing AV-human\ninteraction in real-world traffic environments.",
    "categories": [
      "cs.AI",
      "cs.HC",
      "cs.SI"
    ],
    "primary_category": "cs.AI",
    "comment": "23 pages, 11 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.12637v1",
    "published_date": "2025-03-16 20:11:22 UTC",
    "updated_date": "2025-03-16 20:11:22 UTC"
  },
  {
    "arxiv_id": "2503.12635v1",
    "title": "Hybrid Learners Do Not Forget: A Brain-Inspired Neuro-Symbolic Approach to Continual Learning",
    "authors": [
      "Amin Banayeeanzade",
      "Mohammad Rostami"
    ],
    "abstract": "Continual learning is crucial for creating AI agents that can learn and\nimprove themselves autonomously. A primary challenge in continual learning is\nto learn new tasks without losing previously learned knowledge. Current\ncontinual learning methods primarily focus on enabling a neural network with\nmechanisms that mitigate forgetting effects. Inspired by the two distinct\nsystems in the human brain, System 1 and System 2, we propose a Neuro-Symbolic\nBrain-Inspired Continual Learning (NeSyBiCL) framework that incorporates two\nsubsystems to solve continual learning: A neural network model responsible for\nquickly adapting to the most recent task, together with a symbolic reasoner\nresponsible for retaining previously acquired knowledge from previous tasks.\nMoreover, we design an integration mechanism between these components to\nfacilitate knowledge transfer from the symbolic reasoner to the neural network.\nWe also introduce two compositional continual learning benchmarks and\ndemonstrate that NeSyBiCL is effective and leads to superior performance\ncompared to continual learning methods that merely rely on neural architectures\nto address forgetting.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.12635v1",
    "published_date": "2025-03-16 20:09:19 UTC",
    "updated_date": "2025-03-16 20:09:19 UTC"
  },
  {
    "arxiv_id": "2503.12626v1",
    "title": "Automated Planning for Optimal Data Pipeline Instantiation",
    "authors": [
      "Leonardo Rosa Amado",
      "Adriano Vogel",
      "Dalvan Griebler",
      "Gabriel Paludo Licks",
      "Eric Simon",
      "Felipe Meneguzzi"
    ],
    "abstract": "Data pipeline frameworks provide abstractions for implementing sequences of\ndata-intensive transformation operators, automating the deployment and\nexecution of such transformations in a cluster. Deploying a data pipeline,\nhowever, requires computing resources to be allocated in a data center, ideally\nminimizing the overhead for communicating data and executing operators in the\npipeline while considering each operator's execution requirements. In this\npaper, we model the problem of optimal data pipeline deployment as planning\nwith action costs, where we propose heuristics aiming to minimize total\nexecution time. Experimental results indicate that the heuristics can\noutperform the baseline deployment and that a heuristic based on connections\noutperforms other strategies.",
    "categories": [
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.12626v1",
    "published_date": "2025-03-16 19:43:12 UTC",
    "updated_date": "2025-03-16 19:43:12 UTC"
  },
  {
    "arxiv_id": "2503.12623v2",
    "title": "MAVEN: Multi-modal Attention for Valence-Arousal Emotion Network",
    "authors": [
      "Vrushank Ahire",
      "Kunal Shah",
      "Mudasir Nazir Khan",
      "Nikhil Pakhale",
      "Lownish Rai Sookha",
      "M. A. Ganaie",
      "Abhinav Dhall"
    ],
    "abstract": "Dynamic emotion recognition in the wild remains challenging due to the\ntransient nature of emotional expressions and temporal misalignment of\nmulti-modal cues. Traditional approaches predict valence and arousal and often\noverlook the inherent correlation between these two dimensions. The proposed\nMulti-modal Attention for Valence-Arousal Emotion Network (MAVEN) integrates\nvisual, audio, and textual modalities through a bi-directional cross-modal\nattention mechanism. MAVEN uses modality-specific encoders to extract features\nfrom synchronized video frames, audio segments, and transcripts, predicting\nemotions in polar coordinates following Russell's circumplex model. The\nevaluation of the Aff-Wild2 dataset using MAVEN achieved a concordance\ncorrelation coefficient (CCC) of 0.3061, surpassing the ResNet-50 baseline\nmodel with a CCC of 0.22. The multistage architecture captures the subtle and\ntransient nature of emotional expressions in conversational videos and improves\nemotion recognition in real-world situations. The code is available at:\nhttps://github.com/Vrushank-Ahire/MAVEN_8th_ABAW",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.MM"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.12623v2",
    "published_date": "2025-03-16 19:32:32 UTC",
    "updated_date": "2025-05-02 07:17:44 UTC"
  },
  {
    "arxiv_id": "2503.16518v2",
    "title": "Advancing Human-Machine Teaming: Concepts, Challenges, and Applications",
    "authors": [
      "Dian Chen",
      "Han Jun Yoon",
      "Zelin Wan",
      "Nithin Alluru",
      "Sang Won Lee",
      "Richard He",
      "Terrence J. Moore",
      "Frederica F. Nelson",
      "Sunghyun Yoon",
      "Hyuk Lim",
      "Dan Dongseong Kim",
      "Jin-Hee Cho"
    ],
    "abstract": "Human-Machine Teaming (HMT) is revolutionizing collaboration across domains\nsuch as defense, healthcare, and autonomous systems by integrating AI-driven\ndecision-making, trust calibration, and adaptive teaming. This survey presents\na comprehensive taxonomy of HMT, analyzing theoretical models, including\nreinforcement learning, instance-based learning, and interdependence theory,\nalongside interdisciplinary methodologies. Unlike prior reviews, we examine\nteam cognition, ethical AI, multi-modal interactions, and real-world evaluation\nframeworks. Key challenges include explainability, role allocation, and\nscalable benchmarking. We propose future research in cross-domain adaptation,\ntrust-aware AI, and standardized testbeds. By bridging computational and social\nsciences, this work lays a foundation for resilient, ethical, and scalable HMT\nsystems.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.16518v2",
    "published_date": "2025-03-16 19:32:17 UTC",
    "updated_date": "2025-05-06 17:34:16 UTC"
  },
  {
    "arxiv_id": "2503.12617v1",
    "title": "Scaling Semantic Categories: Investigating the Impact on Vision Transformer Labeling Performance",
    "authors": [
      "Anthony Lamelas",
      "Harrison Muchnic"
    ],
    "abstract": "This study explores the impact of scaling semantic categories on the image\nclassification performance of vision transformers (ViTs). In this specific\ncase, the CLIP server provided by Jina AI is used for experimentation. The\nresearch hypothesizes that as the number of ground truth and artificially\nintroduced semantically equivalent categories increases, the labeling accuracy\nof ViTs improves until a theoretical maximum or limit is reached. A wide\nvariety of image datasets were chosen to test this hypothesis. These datasets\nwere processed through a custom function in Python designed to evaluate the\nmodel's accuracy, with adjustments being made to account for format differences\nbetween datasets. By exponentially introducing new redundant categories, the\nexperiment assessed accuracy trends until they plateaued, decreased, or\nfluctuated inconsistently. The findings show that while semantic scaling\ninitially increases model performance, the benefits diminish or reverse after\nsurpassing a critical threshold, providing insight into the limitations and\npossible optimization of category labeling strategies for ViTs.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "4 pages, 7 figures, submitted to CVPR (feedback pending)",
    "pdf_url": "http://arxiv.org/pdf/2503.12617v1",
    "published_date": "2025-03-16 19:14:21 UTC",
    "updated_date": "2025-03-16 19:14:21 UTC"
  },
  {
    "arxiv_id": "2504.05325v1",
    "title": "Unequal Opportunities: Examining the Bias in Geographical Recommendations by Large Language Models",
    "authors": [
      "Shiran Dudy",
      "Thulasi Tholeti",
      "Resmi Ramachandranpillai",
      "Muhammad Ali",
      "Toby Jia-Jun Li",
      "Ricardo Baeza-Yates"
    ],
    "abstract": "Recent advancements in Large Language Models (LLMs) have made them a popular\ninformation-seeking tool among end users. However, the statistical training\nmethods for LLMs have raised concerns about their representation of\nunder-represented topics, potentially leading to biases that could influence\nreal-world decisions and opportunities. These biases could have significant\neconomic, social, and cultural impacts as LLMs become more prevalent, whether\nthrough direct interactions--such as when users engage with chatbots or\nautomated assistants--or through their integration into third-party\napplications (as agents), where the models influence decision-making processes\nand functionalities behind the scenes. Our study examines the biases present in\nLLMs recommendations of U.S. cities and towns across three domains: relocation,\ntourism, and starting a business. We explore two key research questions: (i)\nHow similar LLMs responses are, and (ii) How this similarity might favor areas\nwith certain characteristics over others, introducing biases. We focus on the\nconsistency of LLMs responses and their tendency to over-represent or\nunder-represent specific locations. Our findings point to consistent\ndemographic biases in these recommendations, which could perpetuate a\n``rich-get-richer'' effect that widens existing economic disparities.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.HC",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.05325v1",
    "published_date": "2025-03-16 18:59:00 UTC",
    "updated_date": "2025-03-16 18:59:00 UTC"
  },
  {
    "arxiv_id": "2503.12613v2",
    "title": "Negotiative Alignment: Embracing Disagreement to Achieve Fairer Outcomes -- Insights from Urban Studies",
    "authors": [
      "Rashid Mushkani",
      "Hugo Berard",
      "Shin Koseki"
    ],
    "abstract": "Cities are not monolithic; they are arenas of negotiation among groups that\nhold varying needs, values, and experiences. Conventional methods of urban\nassessment -- from standardized surveys to AI-driven evaluations -- frequently\nrely on a single consensus metric (e.g., an average measure of inclusivity or\nsafety). Although such aggregations simplify design decisions, they risk\nobscuring the distinct perspectives of marginalized populations. In this paper,\nwe present findings from a community-centered study in Montreal involving 35\nresidents with diverse demographic and social identities, particularly\nwheelchair users, seniors, and LGBTQIA2+ individuals. Using rating and ranking\ntasks on 20 urban sites, we observe that disagreements are systematic rather\nthan random, reflecting structural inequalities, differing cultural values, and\npersonal experiences of safety and accessibility.\n  Based on these empirical insights, we propose negotiative alignment, an AI\nframework that treats disagreement as an essential input to be preserved,\nanalyzed, and addressed. Negotiative alignment builds on pluralistic models by\ndynamically updating stakeholder preferences through multi-agent negotiation\nmechanisms, ensuring no single perspective is marginalized. We outline how this\nframework can be integrated into urban analytics -- and other decision-making\ncontexts -- to retain minority viewpoints, adapt to changing stakeholder\nconcerns, and enhance fairness and accountability. The study demonstrates that\npreserving and engaging with disagreement, rather than striving for an\nartificial consensus, can produce more equitable and responsive AI-driven\noutcomes in urban design.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CY",
      "cs.MA"
    ],
    "primary_category": "cs.HC",
    "comment": "16 pages, 13 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.12613v2",
    "published_date": "2025-03-16 18:55:54 UTC",
    "updated_date": "2025-05-08 03:26:00 UTC"
  },
  {
    "arxiv_id": "2503.12595v1",
    "title": "Point Cloud Based Scene Segmentation: A Survey",
    "authors": [
      "Dan Halperin",
      "Niklas Eisl"
    ],
    "abstract": "Autonomous driving is a safety-critical application, and it is therefore a\ntop priority that the accompanying assistance systems are able to provide\nprecise information about the surrounding environment of the vehicle. Tasks\nsuch as 3D Object Detection deliver an insufficiently detailed understanding of\nthe surrounding scene because they only predict a bounding box for foreground\nobjects. In contrast, 3D Semantic Segmentation provides richer and denser\ninformation about the environment by assigning a label to each individual\npoint, which is of paramount importance for autonomous driving tasks, such as\nnavigation or lane changes. To inspire future research, in this review paper,\nwe provide a comprehensive overview of the current state-of-the-art methods in\nthe field of Point Cloud Semantic Segmentation for autonomous driving. We\ncategorize the approaches into projection-based, 3D-based and hybrid methods.\nMoreover, we discuss the most important and commonly used datasets for this\ntask and also emphasize the importance of synthetic data to support research\nwhen real-world data is limited. We further present the results of the\ndifferent methods and compare them with respect to their segmentation accuracy\nand efficiency.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.12595v1",
    "published_date": "2025-03-16 18:02:41 UTC",
    "updated_date": "2025-03-16 18:02:41 UTC"
  },
  {
    "arxiv_id": "2503.12593v1",
    "title": "Fourier-Based 3D Multistage Transformer for Aberration Correction in Multicellular Specimens",
    "authors": [
      "Thayer Alshaabi",
      "Daniel E. Milkie",
      "Gaoxiang Liu",
      "Cyna Shirazinejad",
      "Jason L. Hong",
      "Kemal Achour",
      "Frederik Görlitz",
      "Ana Milunovic-Jevtic",
      "Cat Simmons",
      "Ibrahim S. Abuzahriyeh",
      "Erin Hong",
      "Samara Erin Williams",
      "Nathanael Harrison",
      "Evan Huang",
      "Eun Seok Bae",
      "Alison N. Killilea",
      "David G. Drubin",
      "Ian A. Swinburne",
      "Srigokul Upadhyayula",
      "Eric Betzig"
    ],
    "abstract": "High-resolution tissue imaging is often compromised by sample-induced optical\naberrations that degrade resolution and contrast. While wavefront sensor-based\nadaptive optics (AO) can measure these aberrations, such hardware solutions are\ntypically complex, expensive to implement, and slow when serially mapping\nspatially varying aberrations across large fields of view. Here, we introduce\nAOViFT (Adaptive Optical Vision Fourier Transformer) -- a machine\nlearning-based aberration sensing framework built around a 3D multistage Vision\nTransformer that operates on Fourier domain embeddings. AOViFT infers\naberrations and restores diffraction-limited performance in puncta-labeled\nspecimens with substantially reduced computational cost, training time, and\nmemory footprint compared to conventional architectures or real-space networks.\nWe validated AOViFT on live gene-edited zebrafish embryos, demonstrating its\nability to correct spatially varying aberrations using either a deformable\nmirror or post-acquisition deconvolution. By eliminating the need for the guide\nstar and wavefront sensing hardware and simplifying the experimental workflow,\nAOViFT lowers technical barriers for high-resolution volumetric microscopy\nacross diverse biological samples.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.LG",
      "physics.bio-ph",
      "q-bio.QM"
    ],
    "primary_category": "eess.IV",
    "comment": "52 pages, 6 figures, 23 si figures, 8 si tables",
    "pdf_url": "http://arxiv.org/pdf/2503.12593v1",
    "published_date": "2025-03-16 17:59:20 UTC",
    "updated_date": "2025-03-16 17:59:20 UTC"
  },
  {
    "arxiv_id": "2503.12592v1",
    "title": "MoECollab: Democratizing LLM Development Through Collaborative Mixture of Experts",
    "authors": [
      "Harshit"
    ],
    "abstract": "Large Language Model (LLM) development has become increasingly centralized,\nlimiting participation to well-resourced organizations. This paper introduces\nMoECollab, a novel framework leveraging Mixture of Experts (MoE) architecture\nto enable distributed, collaborative LLM development. By decomposing monolithic\nmodels into specialized expert modules coordinated by a trainable gating\nnetwork, our framework allows diverse contributors to participate regardless of\ncomputational resources. We provide a complete technical implementation with\nmathematical foundations for expert dynamics, gating mechanisms, and\nintegration strategies. Experiments on multiple datasets demonstrate that our\napproach achieves accuracy improvements of 3-7% over baseline models while\nreducing computational requirements by 34%. Expert specialization yields\nsignificant domain-specific gains, with improvements from 51% to 88% F1 score\nin general classification and from 23% to 44% accuracy in news categorization.\nWe formalize the routing entropy optimization problem and demonstrate how\nproper regularization techniques lead to 14% higher expert utilization rates.\nThese results validate MoECollab as an effective approach for democratizing LLM\ndevelopment through architecturally-supported collaboration.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.12592v1",
    "published_date": "2025-03-16 17:52:40 UTC",
    "updated_date": "2025-03-16 17:52:40 UTC"
  },
  {
    "arxiv_id": "2503.14530v2",
    "title": "SAUCE: Selective Concept Unlearning in Vision-Language Models with Sparse Autoencoders",
    "authors": [
      "Qing Li",
      "Jiahui Geng",
      "Derui Zhu",
      "Fengyu Cai",
      "Chenyang Lyu",
      "Fakhri Karray"
    ],
    "abstract": "Unlearning methods for vision-language models (VLMs) have primarily adapted\ntechniques from large language models (LLMs), relying on weight updates that\ndemand extensive annotated forget sets. Moreover, these methods perform\nunlearning at a coarse granularity, often leading to excessive forgetting and\nreduced model utility. To address this issue, we introduce SAUCE, a novel\nmethod that leverages sparse autoencoders (SAEs) for fine-grained and selective\nconcept unlearning in VLMs. Briefly, SAUCE first trains SAEs to capture\nhigh-dimensional, semantically rich sparse features. It then identifies the\nfeatures most relevant to the target concept for unlearning. During inference,\nit selectively modifies these features to suppress specific concepts while\npreserving unrelated information. We evaluate SAUCE on two distinct VLMs,\nLLaVA-v1.5-7B and LLaMA-3.2-11B-Vision-Instruct, across two types of tasks:\nconcrete concept unlearning (objects and sports scenes) and abstract concept\nunlearning (emotions, colors, and materials), encompassing a total of 60\nconcepts. Extensive experiments demonstrate that SAUCE outperforms\nstate-of-the-art methods by 18.04% in unlearning quality while maintaining\ncomparable model utility. Furthermore, we investigate SAUCE's robustness\nagainst widely used adversarial attacks, its transferability across models, and\nits scalability in handling multiple simultaneous unlearning requests. Our\nfindings establish SAUCE as an effective and scalable solution for selective\nconcept unlearning in VLMs.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "More comparative experiments are needed",
    "pdf_url": "http://arxiv.org/pdf/2503.14530v2",
    "published_date": "2025-03-16 17:32:23 UTC",
    "updated_date": "2025-03-20 05:47:10 UTC"
  },
  {
    "arxiv_id": "2503.12575v1",
    "title": "BalancedDPO: Adaptive Multi-Metric Alignment",
    "authors": [
      "Dipesh Tamboli",
      "Souradip Chakraborty",
      "Aditya Malusare",
      "Biplab Banerjee",
      "Amrit Singh Bedi",
      "Vaneet Aggarwal"
    ],
    "abstract": "Text-to-image (T2I) diffusion models have made remarkable advancements, yet\naligning them with diverse preferences remains a persistent challenge. Current\nmethods often optimize single metrics or depend on narrowly curated datasets,\nleading to overfitting and limited generalization across key visual quality\nmetrics. We present BalancedDPO, a novel extension of Direct Preference\nOptimization (DPO) that addresses these limitations by simultaneously aligning\nT2I diffusion models with multiple metrics, including human preference, CLIP\nscore, and aesthetic quality. Our key novelty lies in aggregating consensus\nlabels from diverse metrics in the preference distribution space as compared to\nexisting reward mixing approaches, enabling robust and scalable multi-metric\nalignment while maintaining the simplicity of the standard DPO pipeline that we\nrefer to as BalancedDPO. Our evaluations on the Pick-a-Pic, PartiPrompt and HPD\ndatasets show that BalancedDPO achieves state-of-the-art results, outperforming\nexisting approaches across all major metrics. BalancedDPO improves the average\nwin rates by 15%, 7.1%, and 10.3% on Pick-a-pic, PartiPrompt and HPD,\nrespectively, from the DiffusionDPO.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.12575v1",
    "published_date": "2025-03-16 17:06:00 UTC",
    "updated_date": "2025-03-16 17:06:00 UTC"
  },
  {
    "arxiv_id": "2503.12572v1",
    "title": "Deblur Gaussian Splatting SLAM",
    "authors": [
      "Francesco Girlanda",
      "Denys Rozumnyi",
      "Marc Pollefeys",
      "Martin R. Oswald"
    ],
    "abstract": "We present Deblur-SLAM, a robust RGB SLAM pipeline designed to recover sharp\nreconstructions from motion-blurred inputs. The proposed method bridges the\nstrengths of both frame-to-frame and frame-to-model approaches to model\nsub-frame camera trajectories that lead to high-fidelity reconstructions in\nmotion-blurred settings. Moreover, our pipeline incorporates techniques such as\nonline loop closure and global bundle adjustment to achieve a dense and precise\nglobal trajectory. We model the physical image formation process of\nmotion-blurred images and minimize the error between the observed blurry images\nand rendered blurry images obtained by averaging sharp virtual sub-frame\nimages. Additionally, by utilizing a monocular depth estimator alongside the\nonline deformation of Gaussians, we ensure precise mapping and enhanced image\ndeblurring. The proposed SLAM pipeline integrates all these components to\nimprove the results. We achieve state-of-the-art results for sharp map\nestimation and sub-frame trajectory recovery both on synthetic and real-world\nblurry input data.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.12572v1",
    "published_date": "2025-03-16 16:59:51 UTC",
    "updated_date": "2025-03-16 16:59:51 UTC"
  },
  {
    "arxiv_id": "2503.12556v1",
    "title": "From Guessing to Asking: An Approach to Resolving the Persona Knowledge Gap in LLMs during Multi-Turn Conversations",
    "authors": [
      "Sarvesh Baskar",
      "Tanmay Tulsidas Verelakar",
      "Srinivasan Parthasarathy",
      "Manas Gaur"
    ],
    "abstract": "In multi-turn dialogues, large language models (LLM) face a critical\nchallenge of ensuring coherence while adapting to user-specific information.\nThis study introduces the persona knowledge gap, the discrepancy between a\nmodel's internal understanding and the knowledge required for coherent,\npersonalized conversations. While prior research has recognized these gaps,\ncomputational methods for their identification and resolution remain\nunderexplored. We propose Conversation Preference Elicitation and\nRecommendation (CPER), a novel framework that dynamically detects and resolves\npersona knowledge gaps using intrinsic uncertainty quantification and\nfeedback-driven refinement. CPER consists of three key modules: a Contextual\nUnderstanding Module for preference extraction, a Dynamic Feedback Module for\nmeasuring uncertainty and refining persona alignment, and a Persona-Driven\nResponse Generation module for adapting responses based on accumulated user\ncontext. We evaluate CPER on two real-world datasets: CCPE-M for preferential\nmovie recommendations and ESConv for mental health support. Using A/B testing,\nhuman evaluators preferred CPER's responses 42% more often than baseline models\nin CCPE-M and 27% more often in ESConv. A qualitative human evaluation confirms\nthat CPER's responses are preferred for maintaining contextual relevance and\ncoherence, particularly in longer (12+ turn) conversations.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2; I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "12 pages, 1 Figure, Oral Presentation at NAACL 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.12556v1",
    "published_date": "2025-03-16 15:55:29 UTC",
    "updated_date": "2025-03-16 15:55:29 UTC"
  },
  {
    "arxiv_id": "2503.12549v1",
    "title": "Grasping Partially Occluded Objects Using Autoencoder-Based Point Cloud Inpainting",
    "authors": [
      "Alexander Koebler",
      "Ralf Gross",
      "Florian Buettner",
      "Ingo Thon"
    ],
    "abstract": "Flexible industrial production systems will play a central role in the future\nof manufacturing due to higher product individualization and customization. A\nkey component in such systems is the robotic grasping of known or unknown\nobjects in random positions. Real-world applications often come with challenges\nthat might not be considered in grasping solutions tested in simulation or lab\nsettings. Partial occlusion of the target object is the most prominent.\nExamples of occlusion can be supporting structures in the camera's field of\nview, sensor imprecision, or parts occluding each other due to the production\nprocess. In all these cases, the resulting lack of information leads to\nshortcomings in calculating grasping points. In this paper, we present an\nalgorithm to reconstruct the missing information. Our inpainting solution\nfacilitates the real-world utilization of robust object matching approaches for\ngrasping point calculation. We demonstrate the benefit of our solution by\nenabling an existing grasping system embedded in a real-world industrial\napplication to handle occlusions in the input. With our solution, we\ndrastically decrease the number of objects discarded by the process.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.RO",
    "comment": "Published at ECML PKDD 2022",
    "pdf_url": "http://arxiv.org/pdf/2503.12549v1",
    "published_date": "2025-03-16 15:38:08 UTC",
    "updated_date": "2025-03-16 15:38:08 UTC"
  },
  {
    "arxiv_id": "2503.13551v3",
    "title": "Towards Hierarchical Multi-Step Reward Models for Enhanced Reasoning in Large Language Models",
    "authors": [
      "Teng Wang",
      "Zhangyi Jiang",
      "Zhenqi He",
      "Shenyang Tong",
      "Wenhan Yang",
      "Yanan Zheng",
      "Zeyu Li",
      "Zifan He",
      "Hailei Gong"
    ],
    "abstract": "Recent studies show that Large Language Models (LLMs) achieve strong\nreasoning capabilities through supervised fine-tuning or reinforcement\nlearning. However, a key approach, the Process Reward Model (PRM), suffers from\nreward hacking, making it unreliable in identifying the best intermediate step.\nIn addition, the cost of annotating reasoning processes for reward modeling is\nhigh, making large-scale collection of high-quality data challenging. To\naddress this, we propose a novel reward model approach called the Hierarchical\nReward Model (HRM), which evaluates both individual and consecutive reasoning\nsteps at both fine-grained and coarse-grained levels. HRM excels at assessing\nmulti-step reasoning coherence, especially when flawed steps are later\ncorrected through self-reflection. To further reduce the cost of generating\ntraining data, we introduce a lightweight and effective data augmentation\nstrategy called Hierarchical Node Compression (HNC), which merges two\nconsecutive reasoning steps into one within the tree structure. By applying HNC\nto MCTS-generated reasoning trajectories, we enhance the diversity and\nrobustness of HRM training data while introducing controlled noise with minimal\ncomputational overhead. Empirical results on the PRM800K dataset show that HRM,\ntogether with HNC, provides more stable and reliable evaluations than PRM.\nFurthermore, cross-domain evaluations on the MATH500 and GSM8K datasets\ndemonstrate HRM's strong generalization and robustness across a variety of\nreasoning tasks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.13551v3",
    "published_date": "2025-03-16 15:18:40 UTC",
    "updated_date": "2025-05-06 11:38:24 UTC"
  },
  {
    "arxiv_id": "2503.12532v2",
    "title": "STEVE: A Step Verification Pipeline for Computer-use Agent Training",
    "authors": [
      "Fanbin Lu",
      "Zhisheng Zhong",
      "Ziqin Wei",
      "Shu Liu",
      "Chi-Wing Fu",
      "Jiaya Jia"
    ],
    "abstract": "Developing AI agents to autonomously manipulate graphical user interfaces is\na long challenging task. Recent advances in data scaling law inspire us to\ntrain computer-use agents with a scaled instruction set, yet using behavior\ncloning to train agents still requires immense high-quality trajectories. To\nmeet the scalability need, we designed STEVE, a step verification pipeline for\ncomputer-use agent training. First, we establish a large instruction set for\ncomputer-use agents and collect trajectory data with some suboptimal agents.\nGPT-4o is used to verify the correctness of each step in the trajectories based\non the screens before and after the action execution, assigning each step with\na binary label. Last, we adopt the Kahneman and Tversky Optimization to\noptimize the agent from the binary stepwise labels. Extensive experiments\nmanifest that our agent outperforms supervised finetuning by leveraging both\npositive and negative actions within a trajectory. Also, STEVE enables us to\ntrain a 7B vision-language model as a computer-use agent, achieving leading\nperformance in the challenging live desktop environment WinAgentArena with\ngreat efficiency at a reduced cost. Code and data:\nhttps://github.com/FanbinLu/STEVE.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.12532v2",
    "published_date": "2025-03-16 14:53:43 UTC",
    "updated_date": "2025-03-24 16:33:28 UTC"
  },
  {
    "arxiv_id": "2503.16517v1",
    "title": "From G-Factor to A-Factor: Establishing a Psychometric Framework for AI Literacy",
    "authors": [
      "Ning Li",
      "Wenming Deng",
      "Jiatan Chen"
    ],
    "abstract": "This research addresses the growing need to measure and understand AI\nliteracy in the context of generative AI technologies. Through three sequential\nstudies involving a total of 517 participants, we establish AI literacy as a\ncoherent, measurable construct with significant implications for education,\nworkforce development, and social equity. Study 1 (N=85) revealed a dominant\nlatent factor - termed the \"A-factor\" - that accounts for 44.16% of variance\nacross diverse AI interaction tasks. Study 2 (N=286) refined the measurement\ntool by examining four key dimensions of AI literacy: communication\neffectiveness, creative idea generation, content evaluation, and step-by-step\ncollaboration, resulting in an 18-item assessment battery. Study 3 (N=146)\nvalidated this instrument in a controlled laboratory setting, demonstrating its\npredictive validity for real-world task performance. Results indicate that AI\nliteracy significantly predicts performance on complex, language-based creative\ntasks but shows domain specificity in its predictive power. Additionally,\nregression analyses identified several significant predictors of AI literacy,\nincluding cognitive abilities (IQ), educational background, prior AI\nexperience, and training history. The multidimensional nature of AI literacy\nand its distinct factor structure provide evidence that effective human-AI\ncollaboration requires a combination of general and specialized abilities.\nThese findings contribute to theoretical frameworks of human-AI collaboration\nwhile offering practical guidance for developing targeted educational\ninterventions to promote equitable access to the benefits of generative AI\ntechnologies.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "econ.GN",
      "q-fin.EC"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.16517v1",
    "published_date": "2025-03-16 14:51:48 UTC",
    "updated_date": "2025-03-16 14:51:48 UTC"
  },
  {
    "arxiv_id": "2503.12525v1",
    "title": "HyConEx: Hypernetwork classifier with counterfactual explanations",
    "authors": [
      "Patryk Marszałek",
      "Ulvi Movsum-zada",
      "Oleksii Furman",
      "Kamil Książek",
      "Przemysław Spurek",
      "Marek Śmieja"
    ],
    "abstract": "In recent years, there has been a growing interest in explainable AI methods.\nWe want not only to make accurate predictions using sophisticated neural\nnetworks but also to understand what the model's decision is based on. One of\nthe fundamental levels of interpretability is to provide counterfactual\nexamples explaining the rationale behind the decision and identifying which\nfeatures, and to what extent, must be modified to alter the model's outcome. To\naddress these requirements, we introduce HyConEx, a classification model based\non deep hypernetworks specifically designed for tabular data. Owing to its\nunique architecture, HyConEx not only provides class predictions but also\ndelivers local interpretations for individual data samples in the form of\ncounterfactual examples that steer a given sample toward an alternative class.\nWhile many explainable methods generated counterfactuals for external models,\nthere have been no interpretable classifiers simultaneously producing\ncounterfactual samples so far. HyConEx achieves competitive performance on\nseveral metrics assessing classification accuracy and fulfilling the criteria\nof a proper counterfactual attack. This makes HyConEx a distinctive deep\nlearning model, which combines predictions and explainers as an all-in-one\nneural network. The code is available at https://github.com/gmum/HyConEx.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.12525v1",
    "published_date": "2025-03-16 14:39:36 UTC",
    "updated_date": "2025-03-16 14:39:36 UTC"
  },
  {
    "arxiv_id": "2503.12524v2",
    "title": "EXAONE Deep: Reasoning Enhanced Language Models",
    "authors": [
      "LG AI Research",
      "Kyunghoon Bae",
      "Eunbi Choi",
      "Kibong Choi",
      "Stanley Jungkyu Choi",
      "Yemuk Choi",
      "Seokhee Hong",
      "Junwon Hwang",
      "Hyojin Jeon",
      "Kijeong Jeon",
      "Gerrard Jeongwon Jo",
      "Hyunjik Jo",
      "Jiyeon Jung",
      "Hyosang Kim",
      "Joonkee Kim",
      "Seonghwan Kim",
      "Soyeon Kim",
      "Sunkyoung Kim",
      "Yireun Kim",
      "Yongil Kim",
      "Youchul Kim",
      "Edward Hwayoung Lee",
      "Haeju Lee",
      "Honglak Lee",
      "Jinsik Lee",
      "Kyungmin Lee",
      "Sangha Park",
      "Yongmin Park",
      "Sihoon Yang",
      "Heuiyeen Yeen",
      "Sihyuk Yi",
      "Hyeongu Yun"
    ],
    "abstract": "We present EXAONE Deep series, which exhibits superior capabilities in\nvarious reasoning tasks, including math and coding benchmarks. We train our\nmodels mainly on the reasoning-specialized dataset that incorporates long\nstreams of thought processes. Evaluation results show that our smaller models,\nEXAONE Deep 2.4B and 7.8B, outperform other models of comparable size, while\nthe largest model, EXAONE Deep 32B, demonstrates competitive performance\nagainst leading open-weight models. All EXAONE Deep models are openly available\nfor research purposes and can be downloaded from\nhttps://huggingface.co/LGAI-EXAONE",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "arXiv admin note: substantial text overlap with arXiv:2412.04862,\n  arXiv:2408.03541",
    "pdf_url": "http://arxiv.org/pdf/2503.12524v2",
    "published_date": "2025-03-16 14:39:33 UTC",
    "updated_date": "2025-03-19 07:09:24 UTC"
  },
  {
    "arxiv_id": "2503.13550v1",
    "title": "Towards Privacy-Preserving Data-Driven Education: The Potential of Federated Learning",
    "authors": [
      "Mohammad Khalil",
      "Ronas Shakya",
      "Qinyi Liu"
    ],
    "abstract": "The increasing adoption of data-driven applications in education such as in\nlearning analytics and AI in education has raised significant privacy and data\nprotection concerns. While these challenges have been widely discussed in\nprevious works, there are still limited practical solutions. Federated learning\nhas recently been discoursed as a promising privacy-preserving technique, yet\nits application in education remains scarce. This paper presents an\nexperimental evaluation of federated learning for educational data prediction,\ncomparing its performance to traditional non-federated approaches. Our findings\nindicate that federated learning achieves comparable predictive accuracy.\nFurthermore, under adversarial attacks, federated learning demonstrates greater\nresilience compared to non-federated settings. We summarise that our results\nreinforce the value of federated learning as a potential approach for balancing\npredictive performance and privacy in educational contexts.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.13550v1",
    "published_date": "2025-03-16 14:37:32 UTC",
    "updated_date": "2025-03-16 14:37:32 UTC"
  },
  {
    "arxiv_id": "2503.13549v1",
    "title": "A Showdown of ChatGPT vs DeepSeek in Solving Programming Tasks",
    "authors": [
      "Ronas Shakya",
      "Farhad Vadiee",
      "Mohammad Khalil"
    ],
    "abstract": "The advancement of large language models (LLMs) has created a competitive\nlandscape for AI-assisted programming tools. This study evaluates two leading\nmodels: ChatGPT 03-mini and DeepSeek-R1 on their ability to solve competitive\nprogramming tasks from Codeforces. Using 29 programming tasks of three levels\nof easy, medium, and hard difficulty, we assessed the outcome of both models by\ntheir accepted solutions, memory efficiency, and runtime performance. Our\nresults indicate that while both models perform similarly on easy tasks,\nChatGPT outperforms DeepSeek-R1 on medium-difficulty tasks, achieving a 54.5%\nsuccess rate compared to DeepSeek 18.1%. Both models struggled with hard tasks,\nthus highlighting some ongoing challenges LLMs face in handling highly complex\nprogramming problems. These findings highlight key differences in both model\ncapabilities and their computational power, offering valuable insights for\ndevelopers and researchers working to advance AI-driven programming tools.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.13549v1",
    "published_date": "2025-03-16 14:35:36 UTC",
    "updated_date": "2025-03-16 14:35:36 UTC"
  },
  {
    "arxiv_id": "2503.12511v2",
    "title": "LLM-Driven Multi-step Translation from C to Rust using Static Analysis",
    "authors": [
      "Tianyang Zhou",
      "Haowen Lin",
      "Somesh Jha",
      "Mihai Christodorescu",
      "Kirill Levchenko",
      "Varun Chandrasekaran"
    ],
    "abstract": "Translating software written in legacy languages to modern languages, such as\nC to Rust, has significant benefits in improving memory safety while\nmaintaining high performance. However, manual translation is cumbersome,\nerror-prone, and produces unidiomatic code. Large language models (LLMs) have\ndemonstrated promise in producing idiomatic translations, but offer no\ncorrectness guarantees as they lack the ability to capture all the semantics\ndifferences between the source and target languages. To resolve this issue, we\npropose SACTOR, an LLM-driven C-to-Rust zero-shot translation tool using a\ntwo-step translation methodology: an \"unidiomatic\" step to translate C into\nRust while preserving semantics, and an \"idiomatic\" step to refine the code to\nfollow Rust's semantic standards. SACTOR utilizes information provided by\nstatic analysis of the source C program to address challenges such as pointer\nsemantics and dependency resolution. To validate the correctness of the\ntranslated result from each step, we use end-to-end testing via the foreign\nfunction interface to embed our translated code segment into the original code.\nWe evaluate the translation of 200 programs from two datasets and two case\nstudies, comparing the performance of GPT-4o, Claude 3.5 Sonnet, Gemini 2.0\nFlash, Llama 3.3 70B and DeepSeek-R1 in SACTOR. Our results demonstrate that\nSACTOR achieves high correctness and improved idiomaticity, with the\nbest-performing model (DeepSeek-R1) reaching 93% and (GPT-4o, Claude 3.5,\nDeepSeek-R1) reaching 84% correctness (on each dataset, respectively), while\nproducing more natural and Rust-compliant translations compared to existing\nmethods.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.PL"
    ],
    "primary_category": "cs.SE",
    "comment": "22 pages, 13 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.12511v2",
    "published_date": "2025-03-16 14:05:26 UTC",
    "updated_date": "2025-03-18 04:17:27 UTC"
  },
  {
    "arxiv_id": "2503.12509v1",
    "title": "A Reservoir-based Model for Human-like Perception of Complex Rhythm Pattern",
    "authors": [
      "Zhongju Yuan",
      "Geraint Wiggins",
      "Dick Botteldooren"
    ],
    "abstract": "Rhythm is a fundamental aspect of human behaviour, present from infancy and\ndeeply embedded in cultural practices. Rhythm anticipation is a spontaneous\ncognitive process that typically occurs before the onset of actual beats. While\nmost research in both neuroscience and artificial intelligence has focused on\nmetronome-based rhythm tasks, studies investigating the perception of complex\nmusical rhythm patterns remain limited. To address this gap, we propose a\nhierarchical oscillator-based model to better understand the perception of\ncomplex musical rhythms in biological systems. The model consists of two types\nof coupled neurons that generate oscillations, with different layers tuned to\nrespond to distinct perception levels. We evaluate the model using several\nrepresentative rhythm patterns spanning the upper, middle, and lower bounds of\nhuman musical perception. Our findings demonstrate that, while maintaining a\nhigh degree of synchronization accuracy, the model exhibits human-like rhythmic\nbehaviours. Additionally, the beta band neuronal activity in the model mirrors\npatterns observed in the human brain, further validating the biological\nplausibility of the approach.",
    "categories": [
      "q-bio.NC",
      "cs.AI"
    ],
    "primary_category": "q-bio.NC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.12509v1",
    "published_date": "2025-03-16 14:02:42 UTC",
    "updated_date": "2025-03-16 14:02:42 UTC"
  },
  {
    "arxiv_id": "2503.13548v1",
    "title": "Fuzzy Rule-based Differentiable Representation Learning",
    "authors": [
      "Wei Zhang",
      "Zhaohong Deng",
      "Guanjin Wang",
      "Kup-Sze Choi"
    ],
    "abstract": "Representation learning has emerged as a crucial focus in machine and deep\nlearning, involving the extraction of meaningful and useful features and\npatterns from the input data, thereby enhancing the performance of various\ndownstream tasks such as classification, clustering, and prediction. Current\nmainstream representation learning methods primarily rely on non-linear data\nmining techniques such as kernel methods and deep neural networks to extract\nabstract knowledge from complex datasets. However, most of these methods are\nblack-box, lacking transparency and interpretability in the learning process,\nwhich constrains their practical utility. To this end, this paper introduces a\nnovel representation learning method grounded in an interpretable fuzzy\nrule-based model. Specifically, it is built upon the Takagi-Sugeno-Kang fuzzy\nsystem (TSK-FS) to initially map input data to a high-dimensional fuzzy feature\nspace through the antecedent part of the TSK-FS. Subsequently, a novel\ndifferentiable optimization method is proposed for the consequence part\nlearning which can preserve the model's interpretability and transparency while\nfurther exploring the nonlinear relationships within the data. This\noptimization method retains the essence of traditional optimization, with\ncertain parts of the process parameterized corresponding differentiable modules\nconstructed, and a deep optimization process implemented. Consequently, this\nmethod not only enhances the model's performance but also ensures its\ninterpretability. Moreover, a second-order geometry preservation method is\nintroduced to further improve the robustness of the proposed method. Extensive\nexperiments conducted on various benchmark datasets validate the superiority of\nthe proposed method, highlighting its potential for advancing representation\nlearning methodologies.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.13548v1",
    "published_date": "2025-03-16 14:00:34 UTC",
    "updated_date": "2025-03-16 14:00:34 UTC"
  },
  {
    "arxiv_id": "2503.12506v1",
    "title": "A General Close-loop Predictive Coding Framework for Auditory Working Memory",
    "authors": [
      "Zhongju Yuan",
      "Geraint Wiggins",
      "Dick Botteldooren"
    ],
    "abstract": "Auditory working memory is essential for various daily activities, such as\nlanguage acquisition, conversation. It involves the temporary storage and\nmanipulation of information that is no longer present in the environment. While\nextensively studied in neuroscience and cognitive science, research on its\nmodeling within neural networks remains limited. To address this gap, we\npropose a general framework based on a close-loop predictive coding paradigm to\nperform short auditory signal memory tasks. The framework is evaluated on two\nwidely used benchmark datasets for environmental sound and speech,\ndemonstrating high semantic similarity across both datasets.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.12506v1",
    "published_date": "2025-03-16 13:57:37 UTC",
    "updated_date": "2025-03-16 13:57:37 UTC"
  },
  {
    "arxiv_id": "2503.12505v1",
    "title": "MPBench: A Comprehensive Multimodal Reasoning Benchmark for Process Errors Identification",
    "authors": [
      "Zhaopan Xu",
      "Pengfei Zhou",
      "Jiaxin Ai",
      "Wangbo Zhao",
      "Kai Wang",
      "Xiaojiang Peng",
      "Wenqi Shao",
      "Hongxun Yao",
      "Kaipeng Zhang"
    ],
    "abstract": "Reasoning is an essential capacity for large language models (LLMs) to\naddress complex tasks, where the identification of process errors is vital for\nimproving this ability. Recently, process-level reward models (PRMs) were\nproposed to provide step-wise rewards that facilitate reinforcement learning\nand data production during training and guide LLMs toward correct steps during\ninference, thereby improving reasoning accuracy. However, existing benchmarks\nof PRMs are text-based and focus on error detection, neglecting other scenarios\nlike reasoning search. To address this gap, we introduce MPBench, a\ncomprehensive, multi-task, multimodal benchmark designed to systematically\nassess the effectiveness of PRMs in diverse scenarios. MPBench employs three\nevaluation paradigms, each targeting a specific role of PRMs in the reasoning\nprocess: (1) Step Correctness, which assesses the correctness of each\nintermediate reasoning step; (2) Answer Aggregation, which aggregates multiple\nsolutions and selects the best one; and (3) Reasoning Process Search, which\nguides the search for optimal reasoning steps during inference. Through these\nparadigms, MPBench makes comprehensive evaluations and provides insights into\nthe development of multimodal PRMs.",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.12505v1",
    "published_date": "2025-03-16 13:50:38 UTC",
    "updated_date": "2025-03-16 13:50:38 UTC"
  },
  {
    "arxiv_id": "2503.12499v1",
    "title": "Facilitating Automated Online Consensus Building through Parallel Thinking",
    "authors": [
      "Wen Gu",
      "Zhaoxing Li",
      "Jan Buermann",
      "Jim Dilkes",
      "Dimitris Michailidis",
      "Shinobu Hasegawa",
      "Vahid Yazdanpanah",
      "Sebastian Stein"
    ],
    "abstract": "Consensus building is inherently challenging due to the diverse opinions held\nby stakeholders. Effective facilitation is crucial to support the consensus\nbuilding process and enable efficient group decision making. However, the\neffectiveness of facilitation is often constrained by human factors such as\nlimited experience and scalability. In this research, we propose a Parallel\nThinking-based Facilitation Agent (PTFA) that facilitates online, text-based\nconsensus building processes. The PTFA automatically collects textual posts and\nleverages large language models (LLMs) to perform all of the six distinct roles\nof the well-established Six Thinking Hats technique in parallel thinking. To\nillustrate the potential of PTFA, a pilot study was carried out and PTFA's\nability in idea generation, emotional probing, and deeper analysis of ideas was\ndemonstrated. Furthermore, a comprehensive dataset that contains not only the\nconversational content among the participants but also between the participants\nand the agent is constructed for future study.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.12499v1",
    "published_date": "2025-03-16 13:32:35 UTC",
    "updated_date": "2025-03-16 13:32:35 UTC"
  },
  {
    "arxiv_id": "2503.12497v1",
    "title": "Defense Against Model Stealing Based on Account-Aware Distribution Discrepancy",
    "authors": [
      "Jian-Ping Mei",
      "Weibin Zhang",
      "Jie Chen",
      "Xuyun Zhang",
      "Tiantian Zhu"
    ],
    "abstract": "Malicious users attempt to replicate commercial models functionally at low\ncost by training a clone model with query responses. It is challenging to\ntimely prevent such model-stealing attacks to achieve strong protection and\nmaintain utility. In this paper, we propose a novel non-parametric detector\ncalled Account-aware Distribution Discrepancy (ADD) to recognize queries from\nmalicious users by leveraging account-wise local dependency. We formulate each\nclass as a Multivariate Normal distribution (MVN) in the feature space and\nmeasure the malicious score as the sum of weighted class-wise distribution\ndiscrepancy. The ADD detector is combined with random-based prediction\npoisoning to yield a plug-and-play defense module named D-ADD for image\nclassification models. Results of extensive experimental studies show that\nD-ADD achieves strong defense against different types of attacks with little\ninterference in serving benign users for both soft and hard-label settings.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "11 pages, 7 figures, published in AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.12497v1",
    "published_date": "2025-03-16 13:22:53 UTC",
    "updated_date": "2025-03-16 13:22:53 UTC"
  },
  {
    "arxiv_id": "2503.13546v1",
    "title": "CNCast: Leveraging 3D Swin Transformer and DiT for Enhanced Regional Weather Forecasting",
    "authors": [
      "Hongli Liang",
      "Yuanting Zhang",
      "Qingye Meng",
      "Shuangshuang He",
      "Xingyuan Yuan"
    ],
    "abstract": "This study introduces a cutting-edge regional weather forecasting model based\non the SwinTransformer 3D architecture. This model is specifically designed to\ndeliver precise hourly weather predictions ranging from 1 hour to 5 days,\nsignificantly improving the reliability and practicality of short-term weather\nforecasts. Our model has demonstrated generally superior performance when\ncompared to Pangu, a well-established global model. The evaluation indicates\nthat our model excels in predicting most weather variables, highlighting its\npotential as a more effective alternative in the field of limited area\nmodeling. A noteworthy feature of this model is the integration of enhanced\nboundary conditions, inspired by traditional numerical weather prediction (NWP)\ntechniques. This integration has substantially improved the model's predictive\naccuracy. Additionally, the model includes an innovative approach for\ndiagnosing hourly total precipitation at a high spatial resolution of\napproximately 5 kilometers. This is achieved through a latent diffusion model,\noffering an alternative method for generating high-resolution precipitation\ndata.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.13546v1",
    "published_date": "2025-03-16 12:52:48 UTC",
    "updated_date": "2025-03-16 12:52:48 UTC"
  },
  {
    "arxiv_id": "2503.12490v1",
    "title": "GeoRSMLLM: A Multimodal Large Language Model for Vision-Language Tasks in Geoscience and Remote Sensing",
    "authors": [
      "Zilun Zhang",
      "Haozhan Shen",
      "Tiancheng Zhao",
      "Bin Chen",
      "Zian Guan",
      "Yuhao Wang",
      "Xu Jia",
      "Yuxiang Cai",
      "Yongheng Shang",
      "Jianwei Yin"
    ],
    "abstract": "The application of Vision-Language Models (VLMs) in remote sensing (RS) has\ndemonstrated significant potential in traditional tasks such as scene\nclassification, object detection, and image captioning. However, current\nmodels, which excel in Referring Expression Comprehension (REC), struggle with\ntasks involving complex instructions (e.g., exists multiple conditions) or\npixel-level operations like segmentation and change detection. In this white\npaper, we provide a comprehensive hierarchical summary of vision-language tasks\nin RS, categorized by the varying levels of cognitive capability required. We\nintroduce the Remote Sensing Vision-Language Task Set (RSVLTS), which includes\nOpen-Vocabulary Tasks (OVT), Referring Expression Tasks (RET), and Described\nObject Tasks (DOT) with increased difficulty, and Visual Question Answering\n(VQA) aloneside. Moreover, we propose a novel unified data representation using\na set-of-points approach for RSVLTS, along with a condition parser and a\nself-augmentation strategy based on cyclic referring. These features are\nintegrated into the GeoRSMLLM model, and this enhanced model is designed to\nhandle a broad range of tasks of RSVLTS, paving the way for a more generalized\nsolution for vision-language tasks in geoscience and remote sensing.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.12490v1",
    "published_date": "2025-03-16 12:48:17 UTC",
    "updated_date": "2025-03-16 12:48:17 UTC"
  },
  {
    "arxiv_id": "2503.12484v1",
    "title": "SING: Semantic Image Communications using Null-Space and INN-Guided Diffusion Models",
    "authors": [
      "Jiakang Chen",
      "Selim F. Yilmaz",
      "Di You",
      "Pier Luigi Dragotti",
      "Deniz Gündüz"
    ],
    "abstract": "Joint source-channel coding systems based on deep neural networks (DeepJSCC)\nhave recently demonstrated remarkable performance in wireless image\ntransmission. Existing methods primarily focus on minimizing distortion between\nthe transmitted image and the reconstructed version at the receiver, often\noverlooking perceptual quality. This can lead to severe perceptual degradation\nwhen transmitting images under extreme conditions, such as low bandwidth\ncompression ratios (BCRs) and low signal-to-noise ratios (SNRs). In this work,\nwe propose SING, a novel two-stage JSCC framework that formulates the recovery\nof high-quality source images from corrupted reconstructions as an inverse\nproblem. Depending on the availability of information about the DeepJSCC\nencoder/decoder and the channel at the receiver, SING can either approximate\nthe stochastic degradation as a linear transformation, or leverage invertible\nneural networks (INNs) for precise modeling. Both approaches enable the\nseamless integration of diffusion models into the reconstruction process,\nenhancing perceptual quality. Experimental results demonstrate that SING\noutperforms DeepJSCC and other approaches, delivering superior perceptual\nquality even under extremely challenging conditions, including scenarios with\nsignificant distribution mismatches between the training and test data.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.IT",
      "cs.LG",
      "eess.SP",
      "math.IT"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.12484v1",
    "published_date": "2025-03-16 12:32:11 UTC",
    "updated_date": "2025-03-16 12:32:11 UTC"
  },
  {
    "arxiv_id": "2503.12478v2",
    "title": "KDSelector: A Knowledge-Enhanced and Data-Efficient Model Selector Learning Framework for Time Series Anomaly Detection",
    "authors": [
      "Zhiyu Liang",
      "Dongrui Cai",
      "Chenyuan Zhang",
      "Zheng Liang",
      "Chen Liang",
      "Bo Zheng",
      "Shi Qiu",
      "Jin Wang",
      "Hongzhi Wang"
    ],
    "abstract": "Model selection has been raised as an essential problem in the area of time\nseries anomaly detection (TSAD), because there is no single best TSAD model for\nthe highly heterogeneous time series in real-world applications. However,\ndespite the success of existing model selection solutions that train a\nclassification model (especially neural network, NN) using historical data as a\nselector to predict the correct TSAD model for each series, the NN-based\nselector learning methods used by existing solutions do not make full use of\nthe knowledge in the historical data and require iterating over all training\nsamples, which limits the accuracy and training speed of the selector. To\naddress these limitations, we propose KDSelector, a novel knowledge-enhanced\nand data-efficient framework for learning the NN-based TSAD model selector, of\nwhich three key components are specifically designed to integrate available\nknowledge into the selector and dynamically prune less important and redundant\nsamples during the learning. We develop a TSAD model selection system with\nKDSelector as the internal, to demonstrate how users improve the accuracy and\ntraining speed of their selectors by using KDSelector as a plug-and-play\nmodule. Our demonstration video is hosted at https://youtu.be/2uqupDWvTF0.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DB"
    ],
    "primary_category": "cs.LG",
    "comment": "This paper has been accepted by SIGMOD 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.12478v2",
    "published_date": "2025-03-16 12:13:19 UTC",
    "updated_date": "2025-03-20 03:06:28 UTC"
  },
  {
    "arxiv_id": "2504.11460v2",
    "title": "Semantic Matters: Multimodal Features for Affective Analysis",
    "authors": [
      "Tobias Hallmen",
      "Robin-Nico Kampa",
      "Fabian Deuser",
      "Norbert Oswald",
      "Elisabeth André"
    ],
    "abstract": "In this study, we present our methodology for two tasks: the Emotional\nMimicry Intensity (EMI) Estimation Challenge and the Behavioural\nAmbivalence/Hesitancy (BAH) Recognition Challenge, both conducted as part of\nthe 8th Workshop and Competition on Affective & Behavior Analysis in-the-wild.\nWe utilize a Wav2Vec 2.0 model pre-trained on a large podcast dataset to\nextract various audio features, capturing both linguistic and paralinguistic\ninformation. Our approach incorporates a valence-arousal-dominance (VAD) module\nderived from Wav2Vec 2.0, a BERT text encoder, and a vision transformer (ViT)\nwith predictions subsequently processed through a long short-term memory (LSTM)\narchitecture or a convolution-like method for temporal modeling. We integrate\nthe textual and visual modality into our analysis, recognizing that semantic\ncontent provides valuable contextual cues and underscoring that the meaning of\nspeech often conveys more critical insights than its acoustic counterpart\nalone. Fusing in the vision modality helps in some cases to interpret the\ntextual modality more precisely. This combined approach results in significant\nperformance improvements, achieving in EMI $\\rho_{\\text{TEST}} = 0.706$ and in\nBAH $F1_{\\text{TEST}} = 0.702$, securing first place in the EMI challenge and\nsecond place in the BAH challenge.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.11460v2",
    "published_date": "2025-03-16 11:30:44 UTC",
    "updated_date": "2025-04-18 06:46:03 UTC"
  },
  {
    "arxiv_id": "2503.12451v1",
    "title": "ISLR101: an Iranian Word-Level Sign Language Recognition Dataset",
    "authors": [
      "Hossein Ranjbar",
      "Alireza Taheri"
    ],
    "abstract": "Sign language recognition involves modeling complex multichannel information,\nsuch as hand shapes and movements while relying on sufficient sign\nlanguage-specific data. However, sign languages are often under-resourced,\nposing a significant challenge for research and development in this field. To\naddress this gap, we introduce ISLR101, the first publicly available Iranian\nSign Language dataset for isolated sign language recognition. This\ncomprehensive dataset includes 4,614 videos covering 101 distinct signs,\nrecorded by 10 different signers (3 deaf individuals, 2 sign language\ninterpreters, and 5 L2 learners) against varied backgrounds, with a resolution\nof 800x600 pixels and a frame rate of 25 frames per second. It also includes\nskeleton pose information extracted using OpenPose. We establish both a visual\nappearance-based and a skeleton-based framework as baseline models, thoroughly\ntraining and evaluating them on ISLR101. These models achieve 97.01% and 94.02%\naccuracy on the test set, respectively. Additionally, we publish the train,\nvalidation, and test splits to facilitate fair comparisons.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.12451v1",
    "published_date": "2025-03-16 10:57:01 UTC",
    "updated_date": "2025-03-16 10:57:01 UTC"
  },
  {
    "arxiv_id": "2503.16516v1",
    "title": "Using LLMs for Automated Privacy Policy Analysis: Prompt Engineering, Fine-Tuning and Explainability",
    "authors": [
      "Yuxin Chen",
      "Peng Tang",
      "Weidong Qiu",
      "Shujun Li"
    ],
    "abstract": "Privacy policies are widely used by digital services and often required for\nlegal purposes. Many machine learning based classifiers have been developed to\nautomate detection of different concepts in a given privacy policy, which can\nhelp facilitate other automated tasks such as producing a more reader-friendly\nsummary and detecting legal compliance issues. Despite the successful\napplications of large language models (LLMs) to many NLP tasks in various\ndomains, there is very little work studying the use of LLMs for automated\nprivacy policy analysis, therefore, if and how LLMs can help automate privacy\npolicy analysis remains under-explored. To fill this research gap, we conducted\na comprehensive evaluation of LLM-based privacy policy concept classifiers,\nemploying both prompt engineering and LoRA (low-rank adaptation) fine-tuning,\non four state-of-the-art (SOTA) privacy policy corpora and taxonomies. Our\nexperimental results demonstrated that combining prompt engineering and\nfine-tuning can make LLM-based classifiers outperform other SOTA methods,\n\\emph{significantly} and \\emph{consistently} across privacy policy\ncorpora/taxonomies and concepts. Furthermore, we evaluated the explainability\nof the LLM-based classifiers using three metrics: completeness, logicality, and\ncomprehensibility. For all three metrics, a score exceeding 91.1\\% was observed\nin our evaluation, indicating that LLMs are not only useful to improve the\nclassification performance, but also to enhance the explainability of detection\nresults.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.16516v1",
    "published_date": "2025-03-16 10:50:31 UTC",
    "updated_date": "2025-03-16 10:50:31 UTC"
  },
  {
    "arxiv_id": "2503.12447v1",
    "title": "Causality Model for Semantic Understanding on Videos",
    "authors": [
      "Li Yicong"
    ],
    "abstract": "After a decade of prosperity, the development of video understanding has\nreached a critical juncture, where the sole reliance on massive data and\ncomplex architectures is no longer a one-size-fits-all solution to all\nsituations. The presence of ubiquitous data imbalance hampers DNNs from\neffectively learning the underlying causal mechanisms, leading to significant\nperformance drops when encountering distribution shifts, such as long-tail\nimbalances and perturbed imbalances. This realization has prompted researchers\nto seek alternative methodologies to capture causal patterns in video data. To\ntackle these challenges and increase the robustness of DNNs, causal modeling\nemerged as a principle to discover the true causal patterns behind the observed\ncorrelations. This thesis focuses on the domain of semantic video understanding\nand explores the potential of causal modeling to advance two fundamental tasks:\nVideo Relation Detection (VidVRD) and Video Question Answering (VideoQA).",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "PhD Thesis",
    "pdf_url": "http://arxiv.org/pdf/2503.12447v1",
    "published_date": "2025-03-16 10:44:11 UTC",
    "updated_date": "2025-03-16 10:44:11 UTC"
  },
  {
    "arxiv_id": "2503.12446v1",
    "title": "BREEN: Bridge Data-Efficient Encoder-Free Multimodal Learning with Learnable Queries",
    "authors": [
      "Tianle Li",
      "Yongming Rao",
      "Winston Hu",
      "Yu Cheng"
    ],
    "abstract": "Encoder-free multimodal large language models(MLLMs) eliminate the need for a\nwell-trained vision encoder by directly processing image tokens before the\nlanguage model. While this approach reduces computational overhead and model\ncomplexity, it often requires large amounts of training data to effectively\ncapture the visual knowledge typically encoded by vision models like CLIP. The\nabsence of a vision encoder implies that the model is likely to rely on\nsubstantial data to learn the necessary visual-semantic alignments. In this\nwork, we present BREEN, a data-efficient encoder-free multimodal architecture\nthat mitigates this issue. BREEN leverages a learnable query and image experts\nto achieve comparable performance with significantly less training data. The\nlearnable query, positioned between image and text tokens, is supervised by the\noutput of a pretrained CLIP model to distill visual knowledge, bridging the gap\nbetween visual and textual modalities. Additionally, the image expert processes\nimage tokens and learnable queries independently, improving efficiency and\nreducing interference with the LLM's textual capabilities. BREEN achieves\ncomparable performance to prior encoder-free state-of-the-art models like\nMono-InternVL, using only 13 million text-image pairs in training about one\npercent of the data required by existing methods. Our work highlights a\npromising direction for data-efficient encoder-free multimodal learning,\noffering an alternative to traditional encoder-based approaches.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.12446v1",
    "published_date": "2025-03-16 10:43:14 UTC",
    "updated_date": "2025-03-16 10:43:14 UTC"
  },
  {
    "arxiv_id": "2503.12434v1",
    "title": "A Survey on the Optimization of Large Language Model-based Agents",
    "authors": [
      "Shangheng Du",
      "Jiabao Zhao",
      "Jinxin Shi",
      "Zhentao Xie",
      "Xin Jiang",
      "Yanhong Bai",
      "Liang He"
    ],
    "abstract": "With the rapid development of Large Language Models (LLMs), LLM-based agents\nhave been widely adopted in various fields, becoming essential for autonomous\ndecision-making and interactive tasks. However, current work typically relies\non prompt design or fine-tuning strategies applied to vanilla LLMs, which often\nleads to limited effectiveness or suboptimal performance in complex\nagent-related environments. Although LLM optimization techniques can improve\nmodel performance across many general tasks, they lack specialized optimization\ntowards critical agent functionalities such as long-term planning, dynamic\nenvironmental interaction, and complex decision-making. Although numerous\nrecent studies have explored various strategies to optimize LLM-based agents\nfor complex agent tasks, a systematic review summarizing and comparing these\nmethods from a holistic perspective is still lacking. In this survey, we\nprovide a comprehensive review of LLM-based agent optimization approaches,\ncategorizing them into parameter-driven and parameter-free methods. We first\nfocus on parameter-driven optimization, covering fine-tuning-based\noptimization, reinforcement learning-based optimization, and hybrid strategies,\nanalyzing key aspects such as trajectory data construction, fine-tuning\ntechniques, reward function design, and optimization algorithms. Additionally,\nwe briefly discuss parameter-free strategies that optimize agent behavior\nthrough prompt engineering and external knowledge retrieval. Finally, we\nsummarize the datasets and benchmarks used for evaluation and tuning, review\nkey applications of LLM-based agents, and discuss major challenges and\npromising future directions. Our repository for related references is available\nat https://github.com/YoungDubbyDu/LLM-Agent-Optimization.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.12434v1",
    "published_date": "2025-03-16 10:09:10 UTC",
    "updated_date": "2025-03-16 10:09:10 UTC"
  },
  {
    "arxiv_id": "2503.12427v1",
    "title": "Towards Learnable Anchor for Deep Multi-View Clustering",
    "authors": [
      "Bocheng Wang",
      "Chusheng Zeng",
      "Mulin Chen",
      "Xuelong Li"
    ],
    "abstract": "Deep multi-view clustering incorporating graph learning has presented\ntremendous potential. Most methods encounter costly square time consumption\nw.r.t. data size. Theoretically, anchor-based graph learning can alleviate this\nlimitation, but related deep models mainly rely on manual discretization\napproaches to select anchors, which indicates that 1) the anchors are fixed\nduring model training and 2) they may deviate from the true cluster\ndistribution. Consequently, the unreliable anchors may corrupt clustering\nresults. In this paper, we propose the Deep Multi-view Anchor Clustering (DMAC)\nmodel that performs clustering in linear time. Concretely, the initial anchors\nare intervened by the positive-incentive noise sampled from Gaussian\ndistribution, such that they can be optimized with a newly designed anchor\nlearning loss, which promotes a clear relationship between samples and anchors.\nAfterwards, anchor graph convolution is devised to model the cluster structure\nformed by the anchors, and the mutual information maximization loss is built to\nprovide cross-view clustering guidance. In this way, the learned anchors can\nbetter represent clusters. With the optimal anchors, the full sample graph is\ncalculated to derive a discriminative embedding for clustering. Extensive\nexperiments on several datasets demonstrate the superior performance and\nefficiency of DMAC compared to state-of-the-art competitors.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by AAAI25",
    "pdf_url": "http://arxiv.org/pdf/2503.12427v1",
    "published_date": "2025-03-16 09:38:11 UTC",
    "updated_date": "2025-03-16 09:38:11 UTC"
  },
  {
    "arxiv_id": "2504.13853v1",
    "title": "GenShin:geometry-enhanced structural graph embodies binding pose can better predicting compound-protein interaction affinity",
    "authors": [
      "Pingfei Zhu",
      "Chenyang Zhao",
      "Haishi Zhao",
      "Bo Yang"
    ],
    "abstract": "AI-powered drug discovery typically relies on the successful prediction of\ncompound-protein interactions, which are pivotal for the evaluation of designed\ncompound molecules in structure-based drug design and represent a core\nchallenge in the field.\n  However, accurately predicting compound-protein affinity via regression\nmodels usually requires adequate-binding pose, which are derived from costly\nand complex experimental methods or time-consuming simulations with docking\nsoftware. In response, we have introduced the GenShin model, which constructs a\ngeometry-enhanced structural graph module that separately extracts additional\nfeatures from proteins and compounds. Consequently, it attains an accuracy on\npar with mainstream models in predicting compound-protein affinities, while\neliminating the need for adequate-binding pose as input. Our experimental\nfindings demonstrate that the GenShin model vastly outperforms other models\nthat rely on non-input docking conformations, achieving, or in some cases even\nexceeding, the performance of those requiring adequate-binding pose. Further\nexperiments indicate that our GenShin model is more robust to\ninadequate-binding pose, affirming its higher suitability for real-world drug\ndiscovery scenarios. We hope our work will inspire more endeavors to bridge the\ngap between AI models and practical drug discovery challenges.",
    "categories": [
      "q-bio.BM",
      "cs.AI"
    ],
    "primary_category": "q-bio.BM",
    "comment": "11 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.13853v1",
    "published_date": "2025-03-16 09:11:56 UTC",
    "updated_date": "2025-03-16 09:11:56 UTC"
  },
  {
    "arxiv_id": "2503.12406v1",
    "title": "Bio-Inspired Plastic Neural Networks for Zero-Shot Out-of-Distribution Generalization in Complex Animal-Inspired Robots",
    "authors": [
      "Binggwong Leung",
      "Worasuchad Haomachai",
      "Joachim Winther Pedersen",
      "Sebastian Risi",
      "Poramate Manoonpong"
    ],
    "abstract": "Artificial neural networks can be used to solve a variety of robotic tasks.\nHowever, they risk failing catastrophically when faced with out-of-distribution\n(OOD) situations. Several approaches have employed a type of synaptic\nplasticity known as Hebbian learning that can dynamically adjust weights based\non local neural activities. Research has shown that synaptic plasticity can\nmake policies more robust and help them adapt to unforeseen changes in the\nenvironment. However, networks augmented with Hebbian learning can lead to\nweight divergence, resulting in network instability. Furthermore, such Hebbian\nnetworks have not yet been applied to solve legged locomotion in complex real\nrobots with many degrees of freedom. In this work, we improve the Hebbian\nnetwork with a weight normalization mechanism for preventing weight divergence,\nanalyze the principal components of the Hebbian's weights, and perform a\nthorough evaluation of network performance in locomotion control for real\n18-DOF dung beetle-like and 16-DOF gecko-like robots. We find that the\nHebbian-based plastic network can execute zero-shot sim-to-real adaptation\nlocomotion and generalize to unseen conditions, such as uneven terrain and\nmorphological damage.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.12406v1",
    "published_date": "2025-03-16 08:13:53 UTC",
    "updated_date": "2025-03-16 08:13:53 UTC"
  },
  {
    "arxiv_id": "2503.12389v1",
    "title": "FedGAI: Federated Style Learning with Cloud-Edge Collaboration for Generative AI in Fashion Design",
    "authors": [
      "Mingzhu Wu",
      "Jianan Jiang",
      "Xinglin Li",
      "Hanhui Deng",
      "Di Wu"
    ],
    "abstract": "Collaboration can amalgamate diverse ideas, styles, and visual elements,\nfostering creativity and innovation among different designers. In collaborative\ndesign, sketches play a pivotal role as a means of expressing design\ncreativity. However, designers often tend to not openly share these\nmeticulously crafted sketches. This phenomenon of data island in the design\narea hinders its digital transformation under the third wave of AI. In this\npaper, we introduce a Federated Generative Artificial Intelligence Clothing\nsystem, namely FedGAI, employing federated learning to aid in sketch design.\nFedGAI is committed to establishing an ecosystem wherein designers can exchange\nsketch styles among themselves. Through FedGAI, designers can generate sketches\nthat incorporate various designers' styles from their peers, drawing\ninspiration from collaboration without the need for data disclosure or upload.\nExtensive performance evaluations indicate that our FedGAI system can produce\nmulti-styled sketches of comparable quality to human-designed ones while\nsignificantly enhancing efficiency compared to hand-drawn sketches.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.12389v1",
    "published_date": "2025-03-16 07:31:25 UTC",
    "updated_date": "2025-03-16 07:31:25 UTC"
  },
  {
    "arxiv_id": "2503.12374v2",
    "title": "Unveiling Pitfalls: Understanding Why AI-driven Code Agents Fail at GitHub Issue Resolution",
    "authors": [
      "Zhi Chen",
      "Wei Ma",
      "Lingxiao Jiang"
    ],
    "abstract": "AI-driven software development has rapidly advanced with the emergence of\nsoftware development agents that leverage large language models (LLMs) to\ntackle complex, repository-level software engineering tasks. These agents go\nbeyond just generation of final code; they engage in multi-step reasoning,\nutilize various tools for code modification and debugging, and interact with\nexecution environments to diagnose and iteratively resolve issues. However,\nmost existing evaluations focus primarily on static analyses of final code\noutputs, yielding limited insights into the agents' dynamic problem-solving\nprocesses. To fill this gap, we conduct an in-depth empirical study on 3,977\nsolving-phase trajectories and 3,931 testing-phase logs from 8 top-ranked\nagents evaluated on 500 GitHub issues in the SWE-Bench benchmark. Our\nexploratory analysis shows that Python execution errors during the issue\nresolution phase correlate with lower resolution rates and increased reasoning\noverheads. We have identified the most prevalent errors -- such as\nModuleNotFoundError and TypeError -- and highlighted particularly challenging\nerrors like OSError and database-related issues (e.g., IntegrityError) that\ndemand significantly more debugging effort. Furthermore, we have discovered 3\nbugs in the SWE-Bench platform that affect benchmark fairness and accuracy;\nthese issues have been reported to and confirmed by the maintainers. To promote\ntransparency and foster future research, we publicly share our datasets and\nanalysis scripts.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.12374v2",
    "published_date": "2025-03-16 06:24:51 UTC",
    "updated_date": "2025-03-19 10:08:16 UTC"
  },
  {
    "arxiv_id": "2503.16515v1",
    "title": "Highlighting Case Studies in LLM Literature Review of Interdisciplinary System Science",
    "authors": [
      "Lachlan McGinness",
      "Peter Baumgartner"
    ],
    "abstract": "Large Language Models (LLMs) were used to assist four Commonwealth Scientific\nand Industrial Research Organisation (CSIRO) researchers to perform systematic\nliterature reviews (SLR). We evaluate the performance of LLMs for SLR tasks in\nthese case studies. In each, we explore the impact of changing parameters on\nthe accuracy of LLM responses. The LLM was tasked with extracting evidence from\nchosen academic papers to answer specific research questions. We evaluate the\nmodels' performance in faithfully reproducing quotes from the literature and\nsubject experts were asked to assess the model performance in answering the\nresearch questions. We developed a semantic text highlighting tool to\nfacilitate expert review of LLM responses.\n  We found that state of the art LLMs were able to reproduce quotes from texts\nwith greater than 95% accuracy and answer research questions with an accuracy\nof approximately 83%. We use two methods to determine the correctness of LLM\nresponses; expert review and the cosine similarity of transformer embeddings of\nLLM and expert answers. The correlation between these methods ranged from 0.48\nto 0.77, providing evidence that the latter is a valid metric for measuring\nsemantic similarity.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.16515v1",
    "published_date": "2025-03-16 05:52:18 UTC",
    "updated_date": "2025-03-16 05:52:18 UTC"
  },
  {
    "arxiv_id": "2503.12358v3",
    "title": "IPCGRL: Language-Instructed Reinforcement Learning for Procedural Level Generation",
    "authors": [
      "In-Chang Baek",
      "Sung-Hyun Kim",
      "Seo-Young Lee",
      "Dong-Hyeon Kim",
      "Kyung-Joong Kim"
    ],
    "abstract": "Recent research has highlighted the significance of natural language in\nenhancing the controllability of generative models. While various efforts have\nbeen made to leverage natural language for content generation, research on deep\nreinforcement learning (DRL) agents utilizing text-based instructions for\nprocedural content generation remains limited. In this paper, we propose\nIPCGRL, an instruction-based procedural content generation method via\nreinforcement learning, which incorporates a sentence embedding model. IPCGRL\nfine-tunes task-specific embedding representations to effectively compress\ngame-level conditions. We evaluate IPCGRL in a two-dimensional level generation\ntask and compare its performance with a general-purpose embedding method. The\nresults indicate that IPCGRL achieves up to a 21.4% improvement in\ncontrollability and a 17.2% improvement in generalizability for unseen\ninstructions. Furthermore, the proposed method extends the modality of\nconditional input, enabling a more flexible and expressive interaction\nframework for procedural content generation.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "9 pages, 9 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2503.12358v3",
    "published_date": "2025-03-16 04:53:38 UTC",
    "updated_date": "2025-03-25 01:48:16 UTC"
  },
  {
    "arxiv_id": "2503.12356v2",
    "title": "Localized Concept Erasure for Text-to-Image Diffusion Models Using Training-Free Gated Low-Rank Adaptation",
    "authors": [
      "Byung Hyun Lee",
      "Sungjin Lim",
      "Se Young Chun"
    ],
    "abstract": "Fine-tuning based concept erasing has demonstrated promising results in\npreventing generation of harmful contents from text-to-image diffusion models\nby removing target concepts while preserving remaining concepts. To maintain\nthe generation capability of diffusion models after concept erasure, it is\nnecessary to remove only the image region containing the target concept when it\nlocally appears in an image, leaving other regions intact. However, prior arts\noften compromise fidelity of the other image regions in order to erase the\nlocalized target concept appearing in a specific area, thereby reducing the\noverall performance of image generation. To address these limitations, we first\nintroduce a framework called localized concept erasure, which allows for the\ndeletion of only the specific area containing the target concept in the image\nwhile preserving the other regions. As a solution for the localized concept\nerasure, we propose a training-free approach, dubbed Gated Low-rank adaptation\nfor Concept Erasure (GLoCE), that injects a lightweight module into the\ndiffusion model. GLoCE consists of low-rank matrices and a simple gate,\ndetermined only by several generation steps for concepts without training. By\ndirectly applying GLoCE to image embeddings and designing the gate to activate\nonly for target concepts, GLoCE can selectively remove only the region of the\ntarget concepts, even when target and remaining concepts coexist within an\nimage. Extensive experiments demonstrated GLoCE not only improves the image\nfidelity to text prompts after erasing the localized target concepts, but also\noutperforms prior arts in efficacy, specificity, and robustness by large margin\nand can be extended to mass concept erasure.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to CVPR 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.12356v2",
    "published_date": "2025-03-16 04:53:20 UTC",
    "updated_date": "2025-03-25 15:29:45 UTC"
  },
  {
    "arxiv_id": "2503.12353v1",
    "title": "Synthetic Data for Robust AI Model Development in Regulated Enterprises",
    "authors": [
      "Aditi Godbole"
    ],
    "abstract": "In today's business landscape, organizations need to find the right balance\nbetween using their customers' data ethically to power AI solutions and being\ncompliant regarding data privacy and data usage regulations. In this paper, we\ndiscuss synthetic data as a possible solution to this dilemma. Synthetic data\nis simulated data that mimics the real data. We explore how organizations in\nheavily regulated industries, such as financial institutions or healthcare\norganizations, can leverage synthetic data to build robust AI solutions while\nstaying compliant. We demonstrate that synthetic data offers two significant\nadvantages by allowing AI models to learn from more diverse data and by helping\norganizations stay compliant against data privacy laws with the use of\nsynthetic data instead of customer information. We discuss case studies to show\nhow synthetic data can be effectively used in the finance and healthcare sector\nwhile discussing the challenges of using synthetic data and some ethical\nquestions it raises. Our research finds that synthetic data could be a\ngame-changer for AI in regulated industries. The potential can be realized when\nindustry, academia, and regulators collaborate to build solutions. We aim to\ninitiate discussions on the use of synthetic data to build ethical,\nresponsible, and effective AI systems in regulated enterprise industries.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.12353v1",
    "published_date": "2025-03-16 04:46:41 UTC",
    "updated_date": "2025-03-16 04:46:41 UTC"
  },
  {
    "arxiv_id": "2503.13543v1",
    "title": "Enhancing Visual Representation with Textual Semantics: Textual Semantics-Powered Prototypes for Heterogeneous Federated Learning",
    "authors": [
      "Xinghao Wu",
      "Jianwei Niu",
      "Xuefeng Liu",
      "Guogang Zhu",
      "Jiayuan Zhang",
      "Shaojie Tang"
    ],
    "abstract": "Federated Prototype Learning (FedPL) has emerged as an effective strategy for\nhandling data heterogeneity in Federated Learning (FL). In FedPL, clients\ncollaboratively construct a set of global feature centers (prototypes), and let\nlocal features align with these prototypes to mitigate the effects of data\nheterogeneity. The performance of FedPL highly depends on the quality of\nprototypes. Existing methods assume that larger inter-class distances among\nprototypes yield better performance, and thus design different methods to\nincrease these distances. However, we observe that while these methods increase\nprototype distances to enhance class discrimination, they inevitably disrupt\nessential semantic relationships among classes, which are crucial for model\ngeneralization. This raises an important question: how to construct prototypes\nthat inherently preserve semantic relationships among classes? Directly\nlearning these relationships from limited and heterogeneous client data can be\nproblematic in FL. Recently, the success of pre-trained language models (PLMs)\ndemonstrates their ability to capture semantic relationships from vast textual\ncorpora. Motivated by this, we propose FedTSP, a novel method that leverages\nPLMs to construct semantically enriched prototypes from the textual modality,\nenabling more effective collaboration in heterogeneous data settings. We first\nuse a large language model (LLM) to generate fine-grained textual descriptions\nfor each class, which are then processed by a PLM on the server to form textual\nprototypes. To address the modality gap between client image models and the\nPLM, we introduce trainable prompts, allowing prototypes to adapt better to\nclient tasks. Extensive experiments demonstrate that FedTSP mitigates data\nheterogeneity while significantly accelerating convergence.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "13 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.13543v1",
    "published_date": "2025-03-16 04:35:06 UTC",
    "updated_date": "2025-03-16 04:35:06 UTC"
  },
  {
    "arxiv_id": "2503.13542v1",
    "title": "HAR-DoReMi: Optimizing Data Mixture for Self-Supervised Human Activity Recognition Across Heterogeneous IMU Datasets",
    "authors": [
      "Lulu Ban",
      "Tao Zhu",
      "Xiangqing Lu",
      "Qi Qiu",
      "Wenyong Han",
      "Shuangjian Li",
      "Liming Chen",
      "Kevin I-Kai Wang",
      "Mingxing Nie",
      "Yaping Wan"
    ],
    "abstract": "Cross-dataset Human Activity Recognition (HAR) suffers from limited model\ngeneralization, hindering its practical deployment. To address this critical\nchallenge, inspired by the success of DoReMi in Large Language Models (LLMs),\nwe introduce a data mixture optimization strategy for pre-training HAR models,\naiming to improve the recognition performance across heterogeneous datasets.\nHowever, directly applying DoReMi to the HAR field encounters new challenges\ndue to the continuous, multi-channel and intrinsic heterogeneous\ncharacteristics of IMU sensor data. To overcome these limitations, we propose a\nnovel framework HAR-DoReMi, which introduces a masked reconstruction task based\non Mean Squared Error (MSE) loss. By raplacing the discrete language sequence\nprediction task, which relies on the Negative Log-Likelihood (NLL) loss, in the\noriginal DoReMi framework, the proposed framework is inherently more\nappropriate for handling the continuous and multi-channel characteristics of\nIMU data. In addition, HAR-DoReMi integrates the Mahony fusion algorithm into\nthe self-supervised HAR pre-training, aiming to mitigate the heterogeneity of\nvarying sensor orientation. This is achieved by estimating the sensor\norientation within each dataset and facilitating alignment with a unified\ncoordinate system, thereby improving the cross-dataset generalization ability\nof the HAR model. Experimental evaluation on multiple cross-dataset HAR\ntransfer tasks demonstrates that HAR-DoReMi improves the accuracy by an average\nof 6.51%, compared to the current state-of-the-art method with only\napproximately 30% to 50% of the data usage. These results confirm the\neffectiveness of HAR-DoReMi in improving the generalization and data efficiency\nof pre-training HAR models, underscoring its significant potential to\nfacilitate the practical deployment of HAR technology.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.13542v1",
    "published_date": "2025-03-16 04:31:58 UTC",
    "updated_date": "2025-03-16 04:31:58 UTC"
  },
  {
    "arxiv_id": "2503.12349v3",
    "title": "SPIN-Bench: How Well Do LLMs Plan Strategically and Reason Socially?",
    "authors": [
      "Jianzhu Yao",
      "Kevin Wang",
      "Ryan Hsieh",
      "Haisu Zhou",
      "Tianqing Zou",
      "Zerui Cheng",
      "Zhangyang Wang",
      "Pramod Viswanath"
    ],
    "abstract": "Reasoning and strategic behavior in social interactions is a hallmark of\nintelligence. This form of reasoning is significantly more sophisticated than\nisolated planning or reasoning tasks in static settings (e.g., math problem\nsolving). In this paper, we present Strategic Planning, Interaction, and\nNegotiation (SPIN-Bench), a new multi-domain evaluation designed to measure the\nintelligence of strategic planning and social reasoning. While many existing\nbenchmarks focus on narrow planning or single-agent reasoning, SPIN-Bench\ncombines classical PDDL tasks, competitive board games, cooperative card games,\nand multi-agent negotiation scenarios in one unified framework. The framework\nincludes both a benchmark as well as an arena to simulate and evaluate the\nvariety of social settings to test reasoning and strategic behavior of AI\nagents. We formulate the benchmark SPIN-Bench by systematically varying action\nspaces, state complexity, and the number of interacting agents to simulate a\nvariety of social settings where success depends on not only methodical and\nstep-wise decision making, but also conceptual inference of other (adversarial\nor cooperative) participants. Our experiments reveal that while contemporary\nLLMs handle basic fact retrieval and short-range planning reasonably well, they\nencounter significant performance bottlenecks in tasks requiring deep multi-hop\nreasoning over large state spaces and socially adept coordination under\nuncertainty. We envision SPIN-Bench as a catalyst for future research on robust\nmulti-agent planning, social reasoning, and human--AI teaming. Project Website:\nhttps://spinbench.github.io/",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "42 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.12349v3",
    "published_date": "2025-03-16 04:10:53 UTC",
    "updated_date": "2025-04-10 15:18:36 UTC"
  },
  {
    "arxiv_id": "2503.12345v1",
    "title": "General Table Question Answering via Answer-Formula Joint Generation",
    "authors": [
      "Zhongyuan Wang",
      "Richong Zhang",
      "Zhijie Nie"
    ],
    "abstract": "Advanced table question answering (TableQA) methods prompt large language\nmodels (LLMs) to generate answer text, SQL query, Python code, or custom\noperations, which impressively improve the complex reasoning problems in the\nTableQA task. However, these methods lack the versatility to cope with specific\nquestion types or table structures. In contrast, the Spreadsheet Formula, the\nwidely-used and well-defined operation language for tabular data, has not been\nthoroughly explored to solve TableQA. In this paper, we first attempt to use\nFormula as the logical form for solving complex reasoning on the tables with\ndifferent structures. Specifically, we construct a large Formula-annotated\nTableQA dataset \\texttt{FromulaQA} from existing datasets. In addition, we\npropose \\texttt{TabAF}, a general table answering framework to solve multiple\ntypes of tasks over multiple types of tables simultaneously. Unlike existing\nmethods, \\texttt{TabAF} decodes answers and Formulas with a single LLM\nbackbone, demonstrating great versatility and generalization. \\texttt{TabAF}\nbased on Llama3.1-70B achieves new state-of-the-art performance on the\nWikiTableQuestion, HiTab and TabFact.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "work in progress",
    "pdf_url": "http://arxiv.org/pdf/2503.12345v1",
    "published_date": "2025-03-16 03:51:06 UTC",
    "updated_date": "2025-03-16 03:51:06 UTC"
  },
  {
    "arxiv_id": "2503.13540v1",
    "title": "MSCMHMST: A traffic flow prediction model based on Transformer",
    "authors": [
      "Weiyang Geng",
      "Yiming Pan",
      "Zhecong Xing",
      "Dongyu Liu",
      "Rui Liu",
      "Yuan Zhu"
    ],
    "abstract": "This study proposes a hybrid model based on Transformers, named MSCMHMST,\naimed at addressing key challenges in traffic flow prediction. Traditional\nsingle-method approaches show limitations in traffic prediction tasks, whereas\nhybrid methods, by integrating the strengths of different models, can provide\nmore accurate and robust predictions. The MSCMHMST model introduces a\nmulti-head, multi-scale attention mechanism, allowing the model to parallel\nprocess different parts of the data and learn its intrinsic representations\nfrom multiple perspectives, thereby enhancing the model's ability to handle\ncomplex situations. This mechanism enables the model to capture features at\nvarious scales effectively, understanding both short-term changes and long-term\ntrends. Verified through experiments on the PeMS04/08 dataset with specific\nexperimental settings, the MSCMHMST model demonstrated excellent robustness and\naccuracy in long, medium, and short-term traffic flow predictions. The results\nindicate that this model has significant potential, offering a new and\neffective solution for the field of traffic flow prediction.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.13540v1",
    "published_date": "2025-03-16 03:40:32 UTC",
    "updated_date": "2025-03-16 03:40:32 UTC"
  },
  {
    "arxiv_id": "2503.12339v1",
    "title": "Augmented Adversarial Trigger Learning",
    "authors": [
      "Zhe Wang",
      "Yanjun Qi"
    ],
    "abstract": "Gradient optimization-based adversarial attack methods automate the learning\nof adversarial triggers to generate jailbreak prompts or leak system prompts.\nIn this work, we take a closer look at the optimization objective of\nadversarial trigger learning and propose ATLA: Adversarial Trigger Learning\nwith Augmented objectives. ATLA improves the negative log-likelihood loss used\nby previous studies into a weighted loss formulation that encourages the\nlearned adversarial triggers to optimize more towards response format tokens.\nThis enables ATLA to learn an adversarial trigger from just one query-response\npair and the learned trigger generalizes well to other similar queries. We\nfurther design a variation to augment trigger optimization with an auxiliary\nloss that suppresses evasive responses. We showcase how to use ATLA to learn\nadversarial suffixes jailbreaking LLMs and to extract hidden system prompts.\nEmpirically we demonstrate that ATLA consistently outperforms current\nstate-of-the-art techniques, achieving nearly 100% success in attacking while\nrequiring 80% fewer queries. ATLA learned jailbreak suffixes demonstrate high\ngeneralization to unseen queries and transfer well to new LLMs.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.12339v1",
    "published_date": "2025-03-16 03:20:52 UTC",
    "updated_date": "2025-03-16 03:20:52 UTC"
  },
  {
    "arxiv_id": "2503.12334v2",
    "title": "When neural implant meets multimodal LLM: A dual-loop system for neuromodulation and naturalistic neuralbehavioral research",
    "authors": [
      "Edward Hong Wang",
      "Cynthia Xin Wen"
    ],
    "abstract": "We propose a novel dual-loop system that synergistically combines responsive\nneurostimulation (RNS) implants with artificial intelligence-driven wearable\ndevices for treating post-traumatic stress disorder (PTSD) and enabling\nnaturalistic brain research. In PTSD Therapy Mode, an implanted closed-loop\nneural device monitors amygdala activity and provides on-demand stimulation\nupon detecting pathological theta oscillations, while an ensemble of wearables\n(smart glasses, smartwatches, smartphones) uses multimodal large language model\n(LLM) analysis of sensory data to detect environmental or physiological PTSD\ntriggers and deliver timely audiovisual interventions. Logged events from both\nthe neural and wearable loops are analyzed to personalize trigger detection and\nprogressively transition patients to non-invasive interventions. In\nNeuroscience Research Mode, the same platform is adapted for real-world brain\nactivity capture. Wearable-LLM systems recognize naturalistic events (social\ninteractions, emotional situations, compulsive behaviors, decision making) and\nsignal implanted RNS devices (via wireless triggers) to record synchronized\nintracranial data during these moments. This approach builds on recent advances\nin mobile intracranial EEG recording and closed-loop neuromodulation in humans\n(BRAIN Initiative, 2023) (Mobbs et al., 2021). We discuss how our\ninterdisciplinary system could revolutionize PTSD therapy and cognitive\nneuroscience by enabling 24/7 monitoring, context-aware intervention, and rich\ndata collection outside traditional labs. The vision is a future where\nAI-enhanced devices continuously collaborate with the human brain, offering\ntherapeutic support and deep insights into neural function, with the resulting\nreal-world context rich neural data, in turn, accelerating the development of\nmore biologically-grounded and human-centric AI.",
    "categories": [
      "q-bio.NC",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "q-bio.NC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.12334v2",
    "published_date": "2025-03-16 03:07:59 UTC",
    "updated_date": "2025-03-23 19:27:26 UTC"
  },
  {
    "arxiv_id": "2503.12326v1",
    "title": "Leveraging Vision Capabilities of Multimodal LLMs for Automated Data Extraction from Plots",
    "authors": [
      "Maciej P. Polak",
      "Dane Morgan"
    ],
    "abstract": "Automated data extraction from research texts has been steadily improving,\nwith the emergence of large language models (LLMs) accelerating progress even\nfurther. Extracting data from plots in research papers, however, has been such\na complex task that it has predominantly been confined to manual data\nextraction. We show that current multimodal large language models, with proper\ninstructions and engineered workflows, are capable of accurately extracting\ndata from plots. This capability is inherent to the pretrained models and can\nbe achieved with a chain-of-thought sequence of zero-shot engineered prompts we\ncall PlotExtract, without the need to fine-tune. We demonstrate PlotExtract\nhere and assess its performance on synthetic and published plots. We consider\nonly plots with two axes in this analysis. For plots identified as extractable,\nPlotExtract finds points with over 90% precision (and around 90% recall) and\nerrors in x and y position of around 5% or lower. These results prove that\nmultimodal LLMs are a viable path for high-throughput data extraction for plots\nand in many circumstances can replace the current manual methods of data\nextraction.",
    "categories": [
      "cs.CV",
      "cond-mat.mtrl-sci",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "8 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.12326v1",
    "published_date": "2025-03-16 02:41:43 UTC",
    "updated_date": "2025-03-16 02:41:43 UTC"
  },
  {
    "arxiv_id": "2503.12317v1",
    "title": "A Transformer-based survival model for prediction of all-cause mortality in heart failure patients: a multi-cohort study",
    "authors": [
      "Shishir Rao",
      "Nouman Ahmed",
      "Gholamreza Salimi-Khorshidi",
      "Christopher Yau",
      "Huimin Su",
      "Nathalie Conrad",
      "Folkert W Asselbergs",
      "Mark Woodward",
      "Rod Jackson",
      "John GF Cleland",
      "Kazem Rahimi"
    ],
    "abstract": "We developed and validated TRisk, a Transformer-based AI model predicting\n36-month mortality in heart failure patients by analysing temporal patient\njourneys from UK electronic health records (EHR). Our study included 403,534\nheart failure patients (ages 40-90) from 1,418 English general practices, with\n1,063 practices for model derivation and 355 for external validation. TRisk was\ncompared against the MAGGIC-EHR model across various patient subgroups. With\nmedian follow-up of 9 months, TRisk achieved a concordance index of 0.845 (95%\nconfidence interval: [0.841, 0.849]), significantly outperforming MAGGIC-EHR's\n0.728 (0.723, 0.733) for predicting 36-month all-cause mortality. TRisk showed\nmore consistent performance across sex, age, and baseline characteristics,\nsuggesting less bias. We successfully adapted TRisk to US hospital data through\ntransfer learning, achieving a C-index of 0.802 (0.789, 0.816) with 21,767\npatients. Explainability analyses revealed TRisk captured established risk\nfactors while identifying underappreciated predictors like cancers and hepatic\nfailure that were important across both cohorts. Notably, cancers maintained\nstrong prognostic value even a decade after diagnosis. TRisk demonstrated\nwell-calibrated mortality prediction across both healthcare systems. Our\nfindings highlight the value of tracking longitudinal health profiles and\nrevealed risk factors not included in previous expert-driven models.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.12317v1",
    "published_date": "2025-03-16 01:53:50 UTC",
    "updated_date": "2025-03-16 01:53:50 UTC"
  },
  {
    "arxiv_id": "2503.12307v1",
    "title": "Swift4D:Adaptive divide-and-conquer Gaussian Splatting for compact and efficient reconstruction of dynamic scene",
    "authors": [
      "Jiahao Wu",
      "Rui Peng",
      "Zhiyan Wang",
      "Lu Xiao",
      "Luyang Tang",
      "Jinbo Yan",
      "Kaiqiang Xiong",
      "Ronggang Wang"
    ],
    "abstract": "Novel view synthesis has long been a practical but challenging task, although\nthe introduction of numerous methods to solve this problem, even combining\nadvanced representations like 3D Gaussian Splatting, they still struggle to\nrecover high-quality results and often consume too much storage memory and\ntraining time. In this paper we propose Swift4D, a divide-and-conquer 3D\nGaussian Splatting method that can handle static and dynamic primitives\nseparately, achieving a good trade-off between rendering quality and\nefficiency, motivated by the fact that most of the scene is the static\nprimitive and does not require additional dynamic properties. Concretely, we\nfocus on modeling dynamic transformations only for the dynamic primitives which\nbenefits both efficiency and quality. We first employ a learnable decomposition\nstrategy to separate the primitives, which relies on an additional parameter to\nclassify primitives as static or dynamic. For the dynamic primitives, we employ\na compact multi-resolution 4D Hash mapper to transform these primitives from\ncanonical space into deformation space at each timestamp, and then mix the\nstatic and dynamic primitives to produce the final output. This\ndivide-and-conquer method facilitates efficient training and reduces storage\nredundancy. Our method not only achieves state-of-the-art rendering quality\nwhile being 20X faster in training than previous SOTA methods with a minimum\nstorage requirement of only 30MB on real-world datasets. Code is available at\nhttps://github.com/WuJH2001/swift4d.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.12307v1",
    "published_date": "2025-03-16 01:13:11 UTC",
    "updated_date": "2025-03-16 01:13:11 UTC"
  }
]