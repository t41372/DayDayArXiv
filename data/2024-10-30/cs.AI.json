{
  "date": "2024-10-30",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-10-30 的 arXiv 中文 TLDR 快报！今天的论文主要聚焦于 AI 模型优化、多模态处理和强化学习应用，亮点包括 LLM 的动态策略选择和多代理协作框架，以及新型强化学习在机器人和自动驾驶领域的创新，涉及知名学者如 John Langford 等参与的 Belief State Transformer。\n\n今天共有 148 篇论文，我将挑选最具影响力和话题度的文章优先讨论，并将相关主题归类快速概述。重点关注 AI、机器学习和应用领域的创新，其他次要论文（如纯理论或小众主题）将简要掠过。\n\n### AI 和语言模型优化\n- **Dynamic Strategy Planning for Efficient Question Answering with Large Language Models**（动态策略规划用于高效问答的大型语言模型）：这篇论文提出 DyPlan 技术，通过初始决策步骤选择最适合的策略（如 Chain-of-Thought），在多跳问答任务中提升模型性能 7-13%，同时降低成本 11-32%。主要贡献在于动态策略选择，减少了固定策略的低效性。\n- **The Belief State Transformer**（信念状态 Transformer）：作者包括 John Langford，该模型创新性地预测前缀和后缀的令牌，改进了传统 Transformer 在序列生成中的表现，尤其在故事写作任务中超越 Fill-in-the-Middle 方法。关键发现是其高效的目标条件解码和紧凑的信念状态表示。\n- **ACC-Collab: An Actor-Critic Approach to Multi-Agent LLM Collaboration**（多代理 LLM 协作的 Actor-Critic 方法）：这篇论文引入 ACC-Collab 框架，使用 Actor-Critic 强化学习训练多代理 LLM，实现比现有方法高 7.69% 的基准性能。贡献在于将协作行为转化为可学习策略，提升了 LLM 在多任务场景中的协同能力。\n- 其他如 **Demo-Craft: Using In-Context Learning to Improve Code Generation in Large Language Models**（使用 In-Context Learning 提升 LLM 代码生成的 Demo-Craft），通过潜在概念学习提高代码生成准确性 2 倍；**MoLE: Enhancing Human-centric Text-to-image Diffusion via Mixture of Low-rank Experts**（通过低秩专家混合提升人类中心文本到图像扩散），在人脸和手部生成上优化了扩散模型。这些论文快速扩展了 LLM 的应用，但细节较常规。\n\n### 强化学习和机器人应用\n- **Efficient Adaptation of Pre-trained Vision Transformer via Householder Transformation**（通过 Householder 变换高效适应预训练视觉 Transformer）：论文提出一种参数高效微调方法，利用 Householder 变换生成层间自适应矩阵，提升了视觉任务的鲁棒性。贡献在于减少计算开销，同时保持高精度。\n- **EMMA: End-to-end Multimodal Model for Autonomous Driving**（端到端多模态自动驾驶模型）：这篇论文构建了 EMMA 模型，直接从摄像头数据映射到规划轨迹和感知对象，显著提高了自动驾驶的性能（FVD 得分 514）。主要发现是多模态融合的潜力，尽管存在计算开销大等问题。\n- **Incremental Learning of Retrievable Skills For Efficient Continual Task Adaptation**（用于高效连续任务适应的可检索技能增量学习）：引入 IsCiL 框架，通过原型记忆和增量技能学习，实现机器人多任务适应，提升样本效率 17%。这篇快速展示了强化学习在机器人领域的实用性。\n- 相关论文如 **NetworkGym: Reinforcement Learning Environments for Multi-Access Traffic Management**（用于多接入交通管理的强化学习环境），提出 PTD3 算法，优化交通决策；**CoGS: Model Agnostic Causality Constrained Counterfactual Explanations**（基于因果约束的模型无关反事实解释），这些在强化学习应用中表现出色，但实验细节较冗长。\n\n### 医疗图像和计算机视觉\n- **DiaMond: Dementia Diagnosis with Multi-Modal Vision Transformers Using MRI and PET**（使用 MRI 和 PET 的多模态视觉 Transformer 痴呆诊断）：论文开发了 DiaMond 模型，通过生物注意机制融合 MRI 和 PET 数据，提升痴呆诊断准确性（AD 诊断准确率 92.4%）。主要贡献是多模态融合的鲁棒性。\n- **eDOC: Explainable Decoding Out-of-domain Cell Types with Evidential Learning**（使用证据学习的可解释解码单细胞类型）：提出 eDOC 方法，利用 Transformer 和证据学习识别异常细胞类型，提高单细胞 RNA-seq 分析效率。发现在于证据驱动的可解释性。\n- 其他如 **STIED: A deep learning model for the SpatioTemporal detection of focal Interictal Epileptiform Discharges**（用于时空检测间期癫痫放电的深度学习模型），在 MEG 数据上实现高精度检测；**VisAidMath: Benchmarking Visual-Aided Mathematical Reasoning**（视觉辅助数学推理基准），这些论文在医疗 AI 中有创新，但整体影响力较前述主题小。\n\n### 其他领域快速概述\n- 交通和能源领域有几篇，如 **Extralonger: Toward a Unified Perspective of Spatial-Temporal Factors for Extra-Long-Term Traffic Forecasting**（针对超长期交通预测的空间-时间统一视角），提出统一框架扩展预测时长至一周；**FlowLLM: Flow Matching for Material Generation with Large Language Models**（用于材料生成的流匹配 LLM），这些在实际应用中表现出色，但实验细节较琐碎。\n- 一些纯理论论文，如 **Provably Optimal Memory Capacity for Modern Hopfield Models**（现代 Hopfield 模型的证明最优内存容量），探讨了密集关联记忆的理论极限；**Two pathways to resolve relational inconsistencies**（解决关系不一致的两种路径），这些贡献在于理论分析，但对实际应用影响有限，故从简。\n- 其余论文（如语音处理、量子计算等）主题分散，贡献如 **TPP-Gaze: Modelling Gaze Dynamics in Space and Time**（时空建模注视动态），在视觉任务中提升性能，但整体优先级较低，仅提及其方法创新。\n\n总之，今天的论文突出了 AI 模型的效率提升和实际应用潜力，建议关注 LLM 优化和强化学习方向，以推动更可靠的 AI 系统。更多细节可查阅 arXiv！",
  "papers": [
    {
      "arxiv_id": "2410.23511v2",
      "title": "Dynamic Strategy Planning for Efficient Question Answering with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Tanmay Parekh",
        "Pradyot Prakash",
        "Alexander Radovic",
        "Akshay Shekher",
        "Denis Savenkov"
      ],
      "abstract": "Research has shown the effectiveness of reasoning (e.g., Chain-of-Thought),\nplanning (e.g., SelfAsk), and retrieval augmented generation strategies to\nimprove the performance of Large Language Models (LLMs) on various tasks, such\nas question answering. However, using a single fixed strategy to answer\ndifferent kinds of questions is suboptimal in performance and inefficient in\nterms of generated output tokens and performed retrievals. In our work, we\npropose a novel technique DyPlan, to induce a dynamic strategy selection\nprocess in LLMs, to improve performance and reduce costs in question-answering.\nDyPlan incorporates an initial decision step to select the most suitable\nstrategy conditioned on the input question and guides the LLM's response\ngeneration accordingly. We extend DyPlan to DyPlan-verify, adding an internal\nverification and correction process to further enrich the generated answer.\nExperiments on three prominent multi-hop question answering (MHQA) datasets\nreveal how DyPlan can improve model performance by 7-13% while reducing the\ncost by 11-32% relative to the best baseline model.",
      "tldr_zh": "该研究指出，现有的推理策略（如 Chain-of-Thought）和规划策略（如 SelfAsk）虽能提升 Large Language Models (LLMs) 在问答任务上的性能，但使用单一固定策略会降低效率并增加输出和检索成本。为解决此问题，研究提出 DyPlan 技术，通过初始决策步骤动态选择最适合的策略并引导响应生成，并扩展为 DyPlan-verify 以添加内部验证和修正过程。在三个 Multi-hop Question Answering (MHQA) 数据集上的实验显示，DyPlan 相比最佳基线模型提高了 7-13% 的性能，同时降低了 11-32% 的成本。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at NAACL 2025 Findings",
      "pdf_url": "http://arxiv.org/pdf/2410.23511v2",
      "published_date": "2024-10-30 23:35:21 UTC",
      "updated_date": "2025-02-08 00:48:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:45:02.767118"
    },
    {
      "arxiv_id": "2410.23506v2",
      "title": "The Belief State Transformer",
      "title_zh": "翻译失败",
      "authors": [
        "Edward S. Hu",
        "Kwangjun Ahn",
        "Qinghua Liu",
        "Haoran Xu",
        "Manan Tomar",
        "Ada Langford",
        "Dinesh Jayaraman",
        "Alex Lamb",
        "John Langford"
      ],
      "abstract": "We introduce the \"Belief State Transformer\", a next-token predictor that\ntakes both a prefix and suffix as inputs, with a novel objective of predicting\nboth the next token for the prefix and the previous token for the suffix. The\nBelief State Transformer effectively learns to solve challenging problems that\nconventional forward-only transformers struggle with, in a domain-independent\nfashion. Key to this success is learning a compact belief state that captures\nall relevant information necessary for accurate predictions. Empirical\nablations show that each component of the model is essential in difficult\nscenarios where standard Transformers fall short. For the task of story writing\nwith known prefixes and suffixes, our approach outperforms the\nFill-in-the-Middle method for reaching known goals and demonstrates improved\nperformance even when the goals are unknown. Altogether, the Belief State\nTransformer enables more efficient goal-conditioned decoding, better test-time\ninference, and high-quality text representations on small scale problems.\nWebsite: https://sites.google.com/view/belief-state-transformer",
      "tldr_zh": "本研究引入了 Belief State Transformer，一种新型的 next-token predictor，它同时接受 prefix 和 suffix 作为输入，并通过预测 prefix 的下一个 token 和 suffix 的上一个 token 来学习一个紧凑的 belief state，从而捕捉所有必要的预测信息。该模型在领域无关的方式下，解决了传统 forward-only transformers 在挑战性问题上的局限性，实验消融证明其每个组件在困难场景中至关重要。在故事写作任务中，Belief State Transformer 优于 Fill-in-the-Middle 方法，尤其在达到已知目标时表现突出，并实现了更有效的 goal-conditioned decoding、更好的测试时推理以及高质量的文本表示。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "ICLR2025 publication",
      "pdf_url": "http://arxiv.org/pdf/2410.23506v2",
      "published_date": "2024-10-30 23:26:06 UTC",
      "updated_date": "2025-02-20 04:44:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:45:15.198917"
    },
    {
      "arxiv_id": "2410.23501v2",
      "title": "All or None: Identifiable Linear Properties of Next-token Predictors in Language Modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Emanuele Marconato",
        "Sébastien Lachapelle",
        "Sebastian Weichwald",
        "Luigi Gresele"
      ],
      "abstract": "We analyze identifiability as a possible explanation for the ubiquity of\nlinear properties across language models, such as the vector difference between\nthe representations of \"easy\" and \"easiest\" being parallel to that between\n\"lucky\" and \"luckiest\". For this, we ask whether finding a linear property in\none model implies that any model that induces the same distribution has that\nproperty, too. To answer that, we first prove an identifiability result to\ncharacterize distribution-equivalent next-token predictors, lifting a diversity\nrequirement of previous results. Second, based on a refinement of relational\nlinearity [Paccanaro and Hinton, 2001; Hernandez et al., 2024], we show how\nmany notions of linearity are amenable to our analysis. Finally, we show that\nunder suitable conditions, these linear properties either hold in all or none\ndistribution-equivalent next-token predictors.",
      "tldr_zh": "本研究探讨了语言模型中线性属性的可识别性（identifiability），例如单词表示间的向量差异（如“easy”和“easiest”与“lucky”和“luckiest”），并分析这些属性在不同模型间的普遍性。作者证明了分布等价的下一个标记预测器（next-token predictors）的特征，通过去除先前结果的多样性要求，扩展了相关理论。基于对关系线性（relational linearity）的改进，他们展示了多种线性概念适用于此分析，并得出结论：在合适条件下，这些线性属性要么在所有分布等价模型中都存在，要么一个都没有。总的来说，此工作为理解语言模型的内在结构提供了重要见解。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "28th International Conference on Artificial Intelligence and\n  Statistics (AISTATS)",
      "pdf_url": "http://arxiv.org/pdf/2410.23501v2",
      "published_date": "2024-10-30 23:19:29 UTC",
      "updated_date": "2025-03-15 10:30:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:45:26.958774"
    },
    {
      "arxiv_id": "2410.23498v1",
      "title": "Kernel-Based Function Approximation for Average Reward Reinforcement Learning: An Optimist No-Regret Algorithm",
      "title_zh": "基于核的函数逼近用于平均奖励强化",
      "authors": [
        "Sattar Vakili",
        "Julia Olkhovskaya"
      ],
      "abstract": "Reinforcement learning utilizing kernel ridge regression to predict the\nexpected value function represents a powerful method with great\nrepresentational capacity. This setting is a highly versatile framework\namenable to analytical results. We consider kernel-based function approximation\nfor RL in the infinite horizon average reward setting, also referred to as the\nundiscounted setting. We propose an optimistic algorithm, similar to\nacquisition function based algorithms in the special case of bandits. We\nestablish novel no-regret performance guarantees for our algorithm, under\nkernel-based modelling assumptions. Additionally, we derive a novel confidence\ninterval for the kernel-based prediction of the expected value function,\napplicable across various RL problems.",
      "tldr_zh": "这篇论文探讨了在平均奖励强化学习（Reinforcement Learning）中，使用基于核的函数逼近方法，特别是通过核岭回归（Kernel Ridge Regression）来预测期望价值函数。作者提出了一种乐观算法（Optimist Algorithm），类似于Bandits问题中的获取函数方法，并针对无限地平线无折扣设置建立了新的无遗憾性能保证（No-Regret Performance Guarantees）。此外，该研究还推导了适用于各种RL问题的期望价值函数置信区间（Confidence Interval），增强了算法的可靠性和适用性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "38th Conference on Neural Information Processing Systems (NeurIPS\n  2024)",
      "pdf_url": "http://arxiv.org/pdf/2410.23498v1",
      "published_date": "2024-10-30 23:04:10 UTC",
      "updated_date": "2024-10-30 23:04:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:45:38.550016"
    },
    {
      "arxiv_id": "2410.23495v2",
      "title": "DASH: Warm-Starting Neural Network Training in Stationary Settings without Loss of Plasticity",
      "title_zh": "DASH：平稳设置下无可",
      "authors": [
        "Baekrok Shin",
        "Junsoo Oh",
        "Hanseul Cho",
        "Chulhee Yun"
      ],
      "abstract": "Warm-starting neural network training by initializing networks with\npreviously learned weights is appealing, as practical neural networks are often\ndeployed under a continuous influx of new data. However, it often leads to loss\nof plasticity, where the network loses its ability to learn new information,\nresulting in worse generalization than training from scratch. This occurs even\nunder stationary data distributions, and its underlying mechanism is poorly\nunderstood. We develop a framework emulating real-world neural network training\nand identify noise memorization as the primary cause of plasticity loss when\nwarm-starting on stationary data. Motivated by this, we propose Direction-Aware\nSHrinking (DASH), a method aiming to mitigate plasticity loss by selectively\nforgetting memorized noise while preserving learned features. We validate our\napproach on vision tasks, demonstrating improvements in test accuracy and\ntraining efficiency.",
      "tldr_zh": "该研究探讨了在固定数据分布(stationary settings)下，使用预训练权重进行神经网络(neural network)热启动(warm-starting)训练的问题，这种方法虽吸引人，但常导致plasticity loss，即网络丧失学习新信息的能力。论文通过一个模拟框架识别出noise memorization（噪声记忆）是主要原因，并提出Direction-Aware SHrinking (DASH)方法，该方法通过选择性忘记memorized noise同时保留learned features来缓解这一问题。在视觉任务上的实验验证显示，DASH显著提高了测试准确率并提升了训练效率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Published at NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.23495v2",
      "published_date": "2024-10-30 22:57:54 UTC",
      "updated_date": "2024-11-01 09:49:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:45:50.655794"
    },
    {
      "arxiv_id": "2410.23494v1",
      "title": "Causality-Driven Audits of Model Robustness",
      "title_zh": "翻译失败",
      "authors": [
        "Nathan Drenkow",
        "Chris Ribaudo",
        "Mathias Unberath"
      ],
      "abstract": "Robustness audits of deep neural networks (DNN) provide a means to uncover\nmodel sensitivities to the challenging real-world imaging conditions that\nsignificantly degrade DNN performance in-the-wild. Such conditions are often\nthe result of the compounding of multiple factors inherent to the environment,\nsensor, or processing pipeline and may lead to complex image distortions that\nare not easily categorized. When robustness audits are limited to a set of\npre-determined imaging effects or distortions, the results cannot be (easily)\ntransferred to real-world conditions where image corruptions may be more\ncomplex or nuanced. To address this challenge, we present a new alternative\nrobustness auditing method that uses causal inference to measure DNN\nsensitivities to the factors of the imaging process that cause complex\ndistortions. Our approach uses causal models to explicitly encode assumptions\nabout the domain-relevant factors and their interactions. Then, through\nextensive experiments on natural and rendered images across multiple vision\ntasks, we show that our approach reliably estimates causal effects of each\nfactor on DNN performance using observational domain data. These causal effects\ndirectly tie DNN sensitivities to observable properties of the imaging pipeline\nin the domain of interest towards reducing the risk of unexpected DNN failures\nwhen deployed in that domain.",
      "tldr_zh": "该研究针对深度神经网络 (DNN) 的鲁棒性审计问题，提出了一种基于因果推理 (causal inference) 的新方法，以评估模型对真实世界成像条件（如环境、传感器或处理管道因素）的敏感性，从而解决传统审计无法处理复杂扭曲的局限。方法通过构建因果模型 (causal models) 来明确编码领域相关因素及其交互，并利用观察数据估计算因果效应。实验在多个视觉任务上验证了该方法的可靠性，将 DNN 敏感性与成像管道的可观察属性关联起来，显著降低了部署时的意外失败风险。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.23494v1",
      "published_date": "2024-10-30 22:57:50 UTC",
      "updated_date": "2024-10-30 22:57:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:46:03.045038"
    },
    {
      "arxiv_id": "2410.23483v1",
      "title": "Keep on Swimming: Real Attackers Only Need Partial Knowledge of a Multi-Model System",
      "title_zh": "Keep on Swimming：真实攻击者只需对多模型系统拥有部分知识",
      "authors": [
        "Julian Collado",
        "Kevin Stangl"
      ],
      "abstract": "Recent approaches in machine learning often solve a task using a composition\nof multiple models or agentic architectures. When targeting a composed system\nwith adversarial attacks, it might not be computationally or informationally\nfeasible to train an end-to-end proxy model or a proxy model for every\ncomponent of the system. We introduce a method to craft an adversarial attack\nagainst the overall multi-model system when we only have a proxy model for the\nfinal black-box model, and when the transformation applied by the initial\nmodels can make the adversarial perturbations ineffective. Current methods\nhandle this by applying many copies of the first model/transformation to an\ninput and then re-use a standard adversarial attack by averaging gradients, or\nlearning a proxy model for both stages. To our knowledge, this is the first\nattack specifically designed for this threat model and our method has a\nsubstantially higher attack success rate (80% vs 25%) and contains 9.4% smaller\nperturbations (MSE) compared to prior state-of-the-art methods. Our experiments\nfocus on a supervised image pipeline, but we are confident the attack will\ngeneralize to other multi-model settings [e.g. a mix of open/closed source\nfoundation models], or agentic systems",
      "tldr_zh": "本文提出了一种新的对抗攻击（adversarial attack）方法，针对多模型系统（multi-model system），仅需最终黑盒模型（black-box model）的代理模型（proxy model），即可在初始模型转换影响下生成有效扰动。该方法首次专门设计针对这种部分知识威胁模型，通过优化攻击策略避免了现有方法的平均梯度或双阶段代理学习。与现有方法相比，它将攻击成功率提升至80%（对比25%），并将扰动大小（MSE）减少9.4%。实验在监督图像管道上进行，并预计可推广到其他多模型设置，如混合开源/闭源基础模型或代理系统。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "cs.CV",
        "cs.MA"
      ],
      "primary_category": "cs.LG",
      "comment": "11 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.23483v1",
      "published_date": "2024-10-30 22:23:16 UTC",
      "updated_date": "2024-10-30 22:23:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:46:15.769104"
    },
    {
      "arxiv_id": "2410.23472v2",
      "title": "Risk Sources and Risk Management Measures in Support of Standards for General-Purpose AI Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Rokas Gipiškis",
        "Ayrton San Joaquin",
        "Ze Shen Chin",
        "Adrian Regenfuß",
        "Ariel Gil",
        "Koen Holtman"
      ],
      "abstract": "There is an urgent need to identify both short and long-term risks from newly\nemerging types of Artificial Intelligence (AI), as well as available risk\nmanagement measures. In response, and to support global efforts in regulating\nAI and writing safety standards, we compile an extensive catalog of risk\nsources and risk management measures for general-purpose AI (GPAI) systems,\ncomplete with descriptions and supporting examples where relevant. This work\ninvolves identifying technical, operational, and societal risks across model\ndevelopment, training, and deployment stages, as well as surveying established\nand experimental methods for managing these risks. To the best of our\nknowledge, this paper is the first of its kind to provide extensive\ndocumentation of both GPAI risk sources and risk management measures that are\ndescriptive, self-contained and neutral with respect to any existing regulatory\nframework. This work intends to help AI providers, standards experts,\nresearchers, policymakers, and regulators in identifying and mitigating\nsystemic risks from GPAI systems. For this reason, the catalog is released\nunder a public domain license for ease of direct use by stakeholders in AI\ngovernance and standards.",
      "tldr_zh": "本论文编译了一个全面的目录，涵盖通用AI (GPAI) 系统的风险来源和风险管理措施，并提供了详细描述和相关例子，以支持全球AI监管和标准制定。该目录识别了AI模型开发、训练和部署阶段的技术、操作和社会风险，并调查了现有和实验性的风险管理方法。作为首个独立于任何监管框架的自包含文档，这项工作旨在帮助AI提供者、标准专家、研究人员、政策制定者和监管者识别并缓解GPAI系统的系统性风险；目录以公共领域许可发布，便于直接应用。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "92 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.23472v2",
      "published_date": "2024-10-30 21:32:56 UTC",
      "updated_date": "2024-11-15 17:18:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:47:32.633086"
    },
    {
      "arxiv_id": "2411.00056v1",
      "title": "Generating Diverse Negations from Affirmative Sentences",
      "title_zh": "从肯定句生成多样化的否定形式",
      "authors": [
        "Darian Rodriguez Vasquez",
        "Afroditi Papadaki"
      ],
      "abstract": "Despite the impressive performance of large language models across various\ntasks, they often struggle with reasoning under negated statements. Negations\nare important in real-world applications as they encode negative polarity in\nverb phrases, clauses, or other expressions. Nevertheless, they are\nunderrepresented in current benchmarks, which mainly include basic negation\nforms and overlook more complex ones, resulting in insufficient data for\ntraining a language model. In this work, we propose NegVerse, a method that\ntackles the lack of negation datasets by producing a diverse range of negation\ntypes from affirmative sentences, including verbal, non-verbal, and affixal\nforms commonly found in English text. We provide new rules for masking parts of\nsentences where negations are most likely to occur, based on syntactic\nstructure and use a frozen baseline LLM and prompt tuning to generate negated\nsentences. We also propose a filtering mechanism to identify negation cues and\nremove degenerate examples, producing a diverse range of meaningful\nperturbations. Our results show that NegVerse outperforms existing methods and\ngenerates negations with higher lexical similarity to the original sentences,\nbetter syntactic preservation and negation diversity. The code is available in\nhttps://github.com/DarianRodriguez/NegVerse",
      "tldr_zh": "本文研究发现，大语言模型在处理否定语句时表现不佳，主要由于现有基准数据集缺乏多样化的否定形式，如 verbal、non-verbal 和 affixal 类型。论文提出 NegVerse 方法，通过基于句法结构的规则、冻结基线 LLM 的提示调优和过滤机制，从肯定句生成高质量、多样化的否定句。实验结果显示，NegVerse 优于现有方法，在词汇相似度、句法保留和否定多样性上表现出色，并提供了开源代码（https://github.com/DarianRodriguez/NegVerse）。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at \"Adaptive Foundation Models: Evolving AI for Personalized\n  and Efficient Learning\" workshop at NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.00056v1",
      "published_date": "2024-10-30 21:25:02 UTC",
      "updated_date": "2024-10-30 21:25:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:46:38.872029"
    },
    {
      "arxiv_id": "2410.23452v1",
      "title": "Graph-Augmented Relation Extraction Model with LLMs-Generated Support Document",
      "title_zh": "基于LLMs生成支持文档的图增强关系",
      "authors": [
        "Vicky Dong",
        "Hao Yu",
        "Yao Chen"
      ],
      "abstract": "This study introduces a novel approach to sentence-level relation extraction\n(RE) that integrates Graph Neural Networks (GNNs) with Large Language Models\n(LLMs) to generate contextually enriched support documents. By harnessing the\npower of LLMs to generate auxiliary information, our approach crafts an\nintricate graph representation of textual data. This graph is subsequently\nprocessed through a Graph Neural Network (GNN) to refine and enrich the\nembeddings associated with each entity ensuring a more nuanced and\ninterconnected understanding of the data. This methodology addresses the\nlimitations of traditional sentence-level RE models by incorporating broader\ncontexts and leveraging inter-entity interactions, thereby improving the\nmodel's ability to capture complex relationships across sentences. Our\nexperiments, conducted on the CrossRE dataset, demonstrate the effectiveness of\nour approach, with notable improvements in performance across various domains.\nThe results underscore the potential of combining GNNs with LLM-generated\ncontext to advance the field of relation extraction.",
      "tldr_zh": "本研究提出了一种新型句子级关系提取 (RE) 方法，将 Graph Neural Networks (GNNs) 与 Large Language Models (LLMs) 相结合，通过 LLMs 生成的辅助信息构建复杂的文本图表示。GNNs 随后处理该图，以提炼和丰富实体嵌入，从而整合更广泛的上下文和实体间交互，解决传统 RE 模型的局限性。在 CrossRE 数据集上的实验显示，该方法在多个领域实现了显著性能提升，证明了结合 GNNs 与 LLM 生成上下文的潜力，有望推进关系提取领域的发展。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.23452v1",
      "published_date": "2024-10-30 20:48:34 UTC",
      "updated_date": "2024-10-30 20:48:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:46:51.559007"
    },
    {
      "arxiv_id": "2411.00866v1",
      "title": "Emory Knee Radiograph (MRKR) Dataset",
      "title_zh": "Emory 膝关节X光片 (MRKR) 数据集",
      "authors": [
        "Brandon Price",
        "Jason Adleberg",
        "Kaesha Thomas",
        "Zach Zaiman",
        "Aawez Mansuri",
        "Beatrice Brown-Mulry",
        "Chima Okecheukwu",
        "Judy Gichoya",
        "Hari Trivedi"
      ],
      "abstract": "The Emory Knee Radiograph (MRKR) dataset is a large, demographically diverse\ncollection of 503,261 knee radiographs from 83,011 patients, 40% of which are\nAfrican American. This dataset provides imaging data in DICOM format along with\ndetailed clinical information, including patient-reported pain scores,\ndiagnostic codes, and procedural codes, which are not commonly available in\nsimilar datasets. The MRKR dataset also features imaging metadata such as image\nlaterality, view type, and presence of hardware, enhancing its value for\nresearch and model development. MRKR addresses significant gaps in existing\ndatasets by offering a more representative sample for studying osteoarthritis\nand related outcomes, particularly among minority populations, thereby\nproviding a valuable resource for clinicians and researchers.",
      "tldr_zh": "本研究介绍了Emory Knee Radiograph (MRKR)数据集，这是一个包含503,261张膝关节X光片的大型数据集，来自83,011名患者，其中40%为非洲裔美国人，提供更具人口学多样性的样本。数据集以DICOM格式提供图像数据，并附带详细临床信息，如患者报告的疼痛评分、诊断代码和程序代码，以及图像元数据（如图像侧别、视图类型和硬件存在情况）。MRKR填补了现有数据集的空白，特别是针对少数民族人群的研究骨关节炎和相关结果，提供宝贵资源支持临床和模型开发。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "16 pages",
      "pdf_url": "http://arxiv.org/pdf/2411.00866v1",
      "published_date": "2024-10-30 20:48:19 UTC",
      "updated_date": "2024-10-30 20:48:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:47:44.688607"
    },
    {
      "arxiv_id": "2410.23450v1",
      "title": "Return Augmented Decision Transformer for Off-Dynamics Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Ruhan Wang",
        "Yu Yang",
        "Zhishuai Liu",
        "Dongruo Zhou",
        "Pan Xu"
      ],
      "abstract": "We study offline off-dynamics reinforcement learning (RL) to utilize data\nfrom an easily accessible source domain to enhance policy learning in a target\ndomain with limited data. Our approach centers on return-conditioned supervised\nlearning (RCSL), particularly focusing on the decision transformer (DT), which\ncan predict actions conditioned on desired return guidance and complete\ntrajectory history. Previous works tackle the dynamics shift problem by\naugmenting the reward in the trajectory from the source domain to match the\noptimal trajectory in the target domain. However, this strategy can not be\ndirectly applicable in RCSL owing to (1) the unique form of the RCSL policy\nclass, which explicitly depends on the return, and (2) the absence of a\nstraightforward representation of the optimal trajectory distribution. We\npropose the Return Augmented Decision Transformer (RADT) method, where we\naugment the return in the source domain by aligning its distribution with that\nin the target domain. We provide the theoretical analysis demonstrating that\nthe RCSL policy learned from RADT achieves the same level of suboptimality as\nwould be obtained without a dynamics shift. We introduce two practical\nimplementations RADT-DARA and RADT-MV respectively. Extensive experiments\nconducted on D4RL datasets reveal that our methods generally outperform dynamic\nprogramming based methods in off-dynamics RL scenarios.",
      "tldr_zh": "本文研究离动态强化学习（off-dynamics RL），提出 Return Augmented Decision Transformer (RADT) 方法，通过调整源域回报分布以匹配目标域，从而提升基于回报条件监督学习（RCSL）的决策变换器（DT）在数据有限场景下的政策学习。RADT 解决了传统奖励增强策略的局限性，并通过理论分析证明其学习政策能达到无动态偏移时的次优水平。实验在 D4RL 数据集上显示，RADT 的两个变体（RADT-DARA 和 RADT-MV）普遍优于基于动态规划的基线方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "26 pages, 10 tables, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.23450v1",
      "published_date": "2024-10-30 20:46:26 UTC",
      "updated_date": "2024-10-30 20:46:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:47:56.666860"
    },
    {
      "arxiv_id": "2410.23448v1",
      "title": "Venire: A Machine Learning-Guided Panel Review System for Community Content Moderation",
      "title_zh": "翻译失败",
      "authors": [
        "Vinay Koshy",
        "Frederick Choi",
        "Yi-Shyuan Chiang",
        "Hari Sundaram",
        "Eshwar Chandrasekharan",
        "Karrie Karahalios"
      ],
      "abstract": "Research into community content moderation often assumes that moderation\nteams govern with a single, unified voice. However, recent work has found that\nmoderators disagree with one another at modest, but concerning rates. The\nproblem is not the root disagreements themselves. Subjectivity in moderation is\nunavoidable, and there are clear benefits to including diverse perspectives\nwithin a moderation team. Instead, the crux of the issue is that, due to\nresource constraints, moderation decisions end up being made by individual\ndecision-makers. The result is decision-making that is inconsistent, which is\nfrustrating for community members. To address this, we develop Venire, an\nML-backed system for panel review on Reddit. Venire uses a machine learning\nmodel trained on log data to identify the cases where moderators are most\nlikely to disagree. Venire fast-tracks these cases for multi-person review.\nIdeally, Venire allows moderators to surface and resolve disagreements that\nwould have otherwise gone unnoticed. We conduct three studies through which we\ndesign and evaluate Venire: a set of formative interviews with moderators,\ntechnical evaluations on two datasets, and a think-aloud study in which\nmoderators used Venire to make decisions on real moderation cases.\nQuantitatively, we demonstrate that Venire is able to improve decision\nconsistency and surface latent disagreements. Qualitatively, we find that\nVenire helps moderators resolve difficult moderation cases more confidently.\nVenire represents a novel paradigm for human-AI content moderation, and shifts\nthe conversation from replacing human decision-making to supporting it.",
      "tldr_zh": "该研究针对社区内容审核中审核者分歧导致决策不一致的问题，开发了Venire系统，这是一个基于Machine Learning (ML)的面板审查框架。Venire使用训练于日志数据的ML模型来识别审核者最可能分歧的案例，并加速这些案例的多人大众审查，从而提升决策一致性。实验包括形成性访谈、技术评估和思考 aloud 研究，结果显示Venire能有效表面潜在分歧，帮助审核者更自信地处理困难案例，并推动人机协作内容审核从取代人类决策转向支持决策。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.23448v1",
      "published_date": "2024-10-30 20:39:34 UTC",
      "updated_date": "2024-10-30 20:39:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:48:07.715956"
    },
    {
      "arxiv_id": "2411.00054v1",
      "title": "eDOC: Explainable Decoding Out-of-domain Cell Types with Evidential Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Chaochen Wu",
        "Meiyun Zuo",
        "Lei Xie"
      ],
      "abstract": "Single-cell RNA-seq (scRNA-seq) technology is a powerful tool for unraveling\nthe complexity of biological systems. One of essential and fundamental tasks in\nscRNA-seq data analysis is Cell Type Annotation (CTA). In spite of tremendous\nefforts in developing machine learning methods for this problem, several\nchallenges remains. They include identifying Out-of-Domain (OOD) cell types,\nquantifying the uncertainty of unseen cell type annotations, and determining\ninterpretable cell type-specific gene drivers for an OOD case. OOD cell types\nare often associated with therapeutic responses and disease origins, making\nthem critical for precision medicine and early disease diagnosis. Additionally,\nscRNA-seq data contains tens thousands of gene expressions. Pinpointing gene\ndrivers underlying CTA can provide deep insight into gene regulatory mechanisms\nand serve as disease biomarkers. In this study, we develop a new method, eDOC,\nto address aforementioned challenges. eDOC leverages a transformer architecture\nwith evidential learning to annotate In-Domain (IND) and OOD cell types as well\nas to highlight genes that contribute both IND cells and OOD cells in a single\ncell resolution. Rigorous experiments demonstrate that eDOC significantly\nimproves the efficiency and effectiveness of OOD cell type and gene driver\nidentification compared to other state-of-the-art methods. Our findings suggest\nthat eDOC may provide new insights into single-cell biology.",
      "tldr_zh": "本研究提出了一种名为 eDOC 的新方法，用于解决单细胞 RNA-seq (scRNA-seq) 数据分析中的 Cell Type Annotation (CTA) 挑战，特别是识别 Out-of-Domain (OOD) 细胞类型、量化不确定性以及确定可解释的基因驱动因素。eDOC 采用 Transformer 架构结合 Evidential Learning，实现了对 In-Domain (IND) 和 OOD 细胞类型的精确注解，并在单细胞分辨率下突出关键基因的贡献。实验结果显示，eDOC 相较于现有最先进方法显著提高了 OOD 细胞类型和基因驱动识别的效率与有效性，为单细胞生物学提供新的见解和潜在的疾病生物标记物。",
      "categories": [
        "q-bio.GN",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.GN",
      "comment": "under review",
      "pdf_url": "http://arxiv.org/pdf/2411.00054v1",
      "published_date": "2024-10-30 20:15:36 UTC",
      "updated_date": "2024-10-30 20:15:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:48:19.958084"
    },
    {
      "arxiv_id": "2411.00865v2",
      "title": "Demo-Craft: Using In-Context Learning to Improve Code Generation in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Nirmal Joshua Kapu",
        "Mihit Sreejith"
      ],
      "abstract": "Generating executable code from natural language instructions using Large\nLanguage Models (LLMs) poses challenges such as semantic ambiguity and\nunderstanding taskspecific contexts. To address these issues, we propose a\nsystem called DemoCraft, which enhances code generation by leveraging\nin-context learning and demonstration selection, combined with latent concept\nlearning. Latent concept learning introduces additional concept tokens, which\nare trainable embeddings that capture task-specific knowledge. We then test our\nsystem on two major datasets: MBPP and Humaneval. Our experimental results\ndemonstrate that the proposed system achieves an approximate 2x increase in the\npass@k metric compared to baseline models. Furthermore, we introduce two novel\nevaluation metrics: correctness@k and similarity@k. Our empirical studies\nindicate that our system attains nearly a 3x improvement in these metrics as\nwell.",
      "tldr_zh": "本研究针对大型语言模型(LLMs)从自然语言指令生成可执行代码的挑战，如语义模糊和任务特定上下文理解，提出了Demo-Craft系统，该系统结合in-context learning、demonstration selection和latent concept learning来提升生成性能。Latent concept learning通过引入可训练的concept tokens来捕捉任务特定知识，从而优化代码输出。在MBPP和Humaneval数据集上的实验表明，Demo-Craft使pass@k指标提高约2倍，并引入了correctness@k和similarity@k新指标，在这些指标上实现了近3倍的改善。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted at IEEE ICIITCEE 2025. Presented on 16th January 2025 in\n  Bengaluru, India",
      "pdf_url": "http://arxiv.org/pdf/2411.00865v2",
      "published_date": "2024-10-30 19:45:50 UTC",
      "updated_date": "2025-03-22 05:52:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:48:33.611126"
    },
    {
      "arxiv_id": "2410.23409v1",
      "title": "TPP-Gaze: Modelling Gaze Dynamics in Space and Time with Neural Temporal Point Processes",
      "title_zh": "翻译失败",
      "authors": [
        "Alessandro D'Amelio",
        "Giuseppe Cartella",
        "Vittorio Cuculo",
        "Manuele Lucchi",
        "Marcella Cornia",
        "Rita Cucchiara",
        "Giuseppe Boccignone"
      ],
      "abstract": "Attention guides our gaze to fixate the proper location of the scene and\nholds it in that location for the deserved amount of time given current\nprocessing demands, before shifting to the next one. As such, gaze deployment\ncrucially is a temporal process. Existing computational models have made\nsignificant strides in predicting spatial aspects of observer's visual\nscanpaths (where to look), while often putting on the background the temporal\nfacet of attention dynamics (when). In this paper we present TPP-Gaze, a novel\nand principled approach to model scanpath dynamics based on Neural Temporal\nPoint Process (TPP), that jointly learns the temporal dynamics of fixations\nposition and duration, integrating deep learning methodologies with point\nprocess theory. We conduct extensive experiments across five publicly available\ndatasets. Our results show the overall superior performance of the proposed\nmodel compared to state-of-the-art approaches. Source code and trained models\nare publicly available at: https://github.com/phuselab/tppgaze.",
      "tldr_zh": "该论文提出TPP-Gaze，一种基于Neural Temporal Point Processes (TPP)的新方法，用于同时建模目光动态的空间（位置）和时间（持续时间）方面，以解决现有模型忽略时间维度的局限性。该方法整合深度学习和点过程理论，联合学习注视点的动态特征，包括位置和持续时间，从而更准确地预测观察者的视觉扫描路径。在五个公开数据集上的广泛实验中，TPP-Gaze显示出比现有最先进方法整体优越的性能，并提供了源代码和训练模型以促进进一步研究。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at WACV 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.23409v1",
      "published_date": "2024-10-30 19:22:38 UTC",
      "updated_date": "2024-10-30 19:22:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:48:43.221972"
    },
    {
      "arxiv_id": "2410.23405v1",
      "title": "FlowLLM: Flow Matching for Material Generation with Large Language Models as Base Distributions",
      "title_zh": "FlowLLM",
      "authors": [
        "Anuroop Sriram",
        "Benjamin Kurt Miller",
        "Ricky T. Q. Chen",
        "Brandon M. Wood"
      ],
      "abstract": "Material discovery is a critical area of research with the potential to\nrevolutionize various fields, including carbon capture, renewable energy, and\nelectronics. However, the immense scale of the chemical space makes it\nchallenging to explore all possible materials experimentally. In this paper, we\nintroduce FlowLLM, a novel generative model that combines large language models\n(LLMs) and Riemannian flow matching (RFM) to design novel crystalline\nmaterials. FlowLLM first fine-tunes an LLM to learn an effective base\ndistribution of meta-stable crystals in a text representation. After converting\nto a graph representation, the RFM model takes samples from the LLM and\niteratively refines the coordinates and lattice parameters. Our approach\nsignificantly outperforms state-of-the-art methods, increasing the generation\nrate of stable materials by over three times and increasing the rate for\nstable, unique, and novel crystals by $\\sim50\\%$ - a huge improvement on a\ndifficult problem. Additionally, the crystals generated by FlowLLM are much\ncloser to their relaxed state when compared with another leading model,\nsignificantly reducing post-hoc computational cost.",
      "tldr_zh": "这篇论文介绍了 FlowLLM，一种结合 Large Language Models (LLMs) 和 Riemannian flow matching (RFM) 的生成模型，用于设计新型晶体材料，以应对化学空间庞大的探索挑战。方法包括先微调 LLM 以学习亚稳晶体的文本表示作为基础分布，然后将表示转换为图形式，并通过 RFM 迭代优化坐标和晶格参数。实验结果显示，FlowLLM 显著优于现有方法，将稳定材料生成率提高超过三倍，并将稳定、独特和新颖晶体的生成率提高约 50%，同时生成的晶体更接近松弛状态，降低了后续计算成本。",
      "categories": [
        "cs.LG",
        "cond-mat.mtrl-sci",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.23405v1",
      "published_date": "2024-10-30 19:15:43 UTC",
      "updated_date": "2024-10-30 19:15:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:48:56.764848"
    },
    {
      "arxiv_id": "2411.00053v3",
      "title": "ACC-Collab: An Actor-Critic Approach to Multi-Agent LLM Collaboration",
      "title_zh": "翻译失败",
      "authors": [
        "Andrew Estornell",
        "Jean-Francois Ton",
        "Yuanshun Yao",
        "Yang Liu"
      ],
      "abstract": "Large language models (LLMs) have demonstrated a remarkable ability to serve\nas general-purpose tools for various language-based tasks. Recent works have\ndemonstrated that the efficacy of such models can be improved through iterative\ndialog between multiple models. While these paradigms show promise in improving\nmodel efficacy, most works in this area treat collaboration as an emergent\nbehavior, rather than a learned behavior. In doing so, current multi-agent\nframeworks rely on collaborative behaviors to have been sufficiently trained\ninto off-the-shelf models. To address this limitation, we propose ACC-Collab,\nan Actor-Critic based learning framework to produce a two-agent team (an\nactor-agent and a critic-agent) specialized in collaboration. We demonstrate\nthat ACC-Collab outperforms SotA multi-agent techniques on a wide array of\nbenchmarks.",
      "tldr_zh": "本文提出 ACC-Collab，一种基于 Actor-Critic 的学习框架，旨在通过训练两个智能体（actor-agent 和 critic-agent）来实现多智能体 LLM 协作，从而解决现有框架依赖于现成模型的协作行为的局限性。该框架将协作作为可学习的行为，而不是新兴行为，通过迭代对话提升 LLM 在语言任务中的效能。实验结果表明，ACC-Collab 在广泛的 benchmarks 上超过了现有最先进的多智能体技术。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.00053v3",
      "published_date": "2024-10-30 19:09:02 UTC",
      "updated_date": "2025-03-06 16:28:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:49:07.887047"
    },
    {
      "arxiv_id": "2410.23396v1",
      "title": "Adaptive Network Intervention for Complex Systems: A Hierarchical Graph Reinforcement Learning Approach",
      "title_zh": "复杂系统的自适应网络干预：一种分层图强化学习方法",
      "authors": [
        "Qiliang Chen",
        "Babak Heydari"
      ],
      "abstract": "Effective governance and steering of behavior in complex multi-agent systems\n(MAS) are essential for managing system-wide outcomes, particularly in\nenvironments where interactions are structured by dynamic networks. In many\napplications, the goal is to promote pro-social behavior among agents, where\nnetwork structure plays a pivotal role in shaping these interactions. This\npaper introduces a Hierarchical Graph Reinforcement Learning (HGRL) framework\nthat governs such systems through targeted interventions in the network\nstructure. Operating within the constraints of limited managerial authority,\nthe HGRL framework demonstrates superior performance across a range of\nenvironmental conditions, outperforming established baseline methods. Our\nfindings highlight the critical influence of agent-to-agent learning (social\nlearning) on system behavior: under low social learning, the HGRL manager\npreserves cooperation, forming robust core-periphery networks dominated by\ncooperators. In contrast, high social learning accelerates defection, leading\nto sparser, chain-like networks. Additionally, the study underscores the\nimportance of the system manager's authority level in preventing system-wide\nfailures, such as agent rebellion or collapse, positioning HGRL as a powerful\ntool for dynamic network-based governance.",
      "tldr_zh": "本论文提出了一种 Hierarchical Graph Reinforcement Learning (HGRL) 框架，用于在复杂多智能体系统 (MAS) 中，通过针对网络结构的干预来促进亲社会行为。该框架在有限管理权限下表现出色，优于现有基线方法，尤其在不同环境条件下。研究发现，低社会学习环境下，HGRL 能维持合作并形成稳固的核心-外围网络，而高社会学习则加速背叛，导致稀疏链状网络。此外，系统管理者的权限水平对防止系统崩溃（如代理叛变）至关重要，将 HGRL 确立为动态网络治理的强大工具。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.GT",
        "cs.MA"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.23396v1",
      "published_date": "2024-10-30 18:59:02 UTC",
      "updated_date": "2024-10-30 18:59:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:49:21.107580"
    },
    {
      "arxiv_id": "2410.23393v1",
      "title": "Resource Governance in Networked Systems via Integrated Variational Autoencoders and Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Qiliang Chen",
        "Babak Heydari"
      ],
      "abstract": "We introduce a framework that integrates variational autoencoders (VAE) with\nreinforcement learning (RL) to balance system performance and resource usage in\nmulti-agent systems by dynamically adjusting network structures over time. A\nkey innovation of this method is its capability to handle the vast action space\nof the network structure. This is achieved by combining Variational\nAuto-Encoder and Deep Reinforcement Learning to control the latent space\nencoded from the network structures. The proposed method, evaluated on the\nmodified OpenAI particle environment under various scenarios, not only\ndemonstrates superior performance compared to baselines but also reveals\ninteresting strategies and insights through the learned behaviors.",
      "tldr_zh": "本研究提出了一种整合 Variational Autoencoders (VAE) 和 Reinforcement Learning (RL) 的框架，用于在多智能体系统中动态调整网络结构，以平衡系统性能和资源使用。该框架的关键创新是通过 VAE 编码网络结构的潜在空间，并结合深度 RL 处理庞大的动作空间，从而实现高效控制。实验在修改后的 OpenAI particle environment 中显示，该方法比基线模型表现出优越性能，并揭示了有趣的策略和洞见。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.23393v1",
      "published_date": "2024-10-30 18:57:02 UTC",
      "updated_date": "2024-10-30 18:57:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:49:32.236747"
    },
    {
      "arxiv_id": "2410.23391v2",
      "title": "Understanding Representation of Deep Equilibrium Models from Neural Collapse Perspective",
      "title_zh": "从神经崩溃视角理解深层平衡模型的表示",
      "authors": [
        "Haixiang Sun",
        "Ye Shi"
      ],
      "abstract": "Deep Equilibrium Model (DEQ), which serves as a typical implicit neural\nnetwork, emphasizes their memory efficiency and competitive performance\ncompared to explicit neural networks. However, there has been relatively\nlimited theoretical analysis on the representation of DEQ. In this paper, we\nutilize the Neural Collapse ($\\mathcal{NC}$) as a tool to systematically\nanalyze the representation of DEQ under both balanced and imbalanced\nconditions. $\\mathcal{NC}$ is an interesting phenomenon in the neural network\ntraining process that characterizes the geometry of class features and\nclassifier weights. While extensively studied in traditional explicit neural\nnetworks, the $\\mathcal{NC}$ phenomenon has not received substantial attention\nin the context of implicit neural networks. We theoretically show that\n$\\mathcal{NC}$ exists in DEQ under balanced conditions. Moreover, in imbalanced\nsettings, despite the presence of minority collapse, DEQ demonstrated\nadvantages over explicit neural networks. These advantages include the\nconvergence of extracted features to the vertices of a simplex equiangular\ntight frame and self-duality properties under mild conditions, highlighting\nDEQ's superiority in handling imbalanced datasets. Finally, we validate our\ntheoretical analyses through experiments in both balanced and imbalanced\nscenarios.",
      "tldr_zh": "本研究从 Neural Collapse (NC) 角度分析 Deep Equilibrium Model (DEQ) 的表示，DEQ 作为一种隐式神经网络，具有内存效率和与显式神经网络相当的表现，但缺乏系统理论探讨。论文利用 NC 现象（描述类特征和分类器权重的几何结构）证明了在平衡条件下 DEQ 中存在 NC，而在不平衡设置中，DEQ 展示了优势，如特征收敛到 simplex equiangular tight frame 的顶点以及 self-duality 属性，从而更好地处理不平衡数据集。通过实验在平衡和不平衡场景中验证了这些理论分析。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.23391v2",
      "published_date": "2024-10-30 18:50:16 UTC",
      "updated_date": "2024-12-03 22:43:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:49:43.995906"
    },
    {
      "arxiv_id": "2410.23386v1",
      "title": "STIED: A deep learning model for the SpatioTemporal detection of focal Interictal Epileptiform Discharges with MEG",
      "title_zh": "翻译失败",
      "authors": [
        "Raquel Fernández-Martín",
        "Alfonso Gijón",
        "Odile Feys",
        "Elodie Juvené",
        "Alec Aeby",
        "Charline Urbain",
        "Xavier De Tiège",
        "Vincent Wens"
      ],
      "abstract": "Magnetoencephalography (MEG) allows the non-invasive detection of interictal\nepileptiform discharges (IEDs). Clinical MEG analysis in epileptic patients\ntraditionally relies on the visual identification of IEDs, which is time\nconsuming and partially subjective. Automatic, data-driven detection methods\nexist but show limited performance. Still, the rise of deep learning (DL)-with\nits ability to reproduce human-like abilities-could revolutionize clinical MEG\npractice. Here, we developed and validated STIED, a simple yet powerful\nsupervised DL algorithm combining two convolutional neural networks with\ntemporal (1D time-course) and spatial (2D topography) features of MEG signals\ninspired from current clinical guidelines. Our DL model enabled both temporal\nand spatial localization of IEDs in patients suffering from focal epilepsy with\nfrequent and high amplitude spikes (FE group), with high-performance\nmetrics-accuracy, specificity, and sensitivity all exceeding 85%-when learning\nfrom spatiotemporal features of IEDs. This performance can be attributed to our\nhandling of input data, which mimics established clinical MEG practice. Reverse\nengineering further revealed that STIED encodes fine spatiotemporal features of\nIEDs rather than their mere amplitude. The model trained on the FE group also\nshowed promising results when applied to a separate group of presurgical\npatients with different types of refractory focal epilepsy, though further work\nis needed to distinguish IEDs from physiological transients. This study paves\nthe way of incorporating STIED and DL algorithms into the routine clinical MEG\nevaluation of epilepsy.",
      "tldr_zh": "本研究开发了 STIED，一种监督深度学习（DL）算法，用于通过磁encephalography（MEG）实现局灶性间发作性放电（IEDs）的时空检测，该算法结合了两个卷积神经网络（CNN），分别处理 MEG 信号的时间序列（1D）和空间地形（2D）特征，以模仿临床实践。STIED 在频繁高振幅尖峰的局灶性癫痫患者群上表现出色，准确率、特异性和敏感性均超过 85%，并通过逆向工程证实其捕捉了 IEDs 的精细时空特征而非仅振幅。实验结果显示，该模型可扩展到其他难治性局灶性癫痫患者，但需进一步优化以区分 IEDs 和生理暂态，从而为 DL 算法在临床 MEG 评估中的整合铺平道路。",
      "categories": [
        "physics.med-ph",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "physics.med-ph",
      "comment": "10 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.23386v1",
      "published_date": "2024-10-30 18:41:22 UTC",
      "updated_date": "2024-10-30 18:41:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:49:56.570871"
    },
    {
      "arxiv_id": "2410.23382v1",
      "title": "Estimating Neural Network Robustness via Lipschitz Constant and Architecture Sensitivity",
      "title_zh": "通过 Lipschitz 常数和架构敏感性估计神经网络鲁棒性",
      "authors": [
        "Abulikemu Abuduweili",
        "Changliu Liu"
      ],
      "abstract": "Ensuring neural network robustness is essential for the safe and reliable\noperation of robotic learning systems, especially in perception and\ndecision-making tasks within real-world environments. This paper investigates\nthe robustness of neural networks in perception systems, specifically examining\ntheir sensitivity to targeted, small-scale perturbations. We identify the\nLipschitz constant as a key metric for quantifying and enhancing network\nrobustness. We derive an analytical expression to compute the Lipschitz\nconstant based on neural network architecture, providing a theoretical basis\nfor estimating and improving robustness. Several experiments reveal the\nrelationship between network design, the Lipschitz constant, and robustness,\noffering practical insights for developing safer, more robust robot learning\nsystems.",
      "tldr_zh": "这篇论文探讨了神经网络在机器人学习系统中的鲁棒性，特别是对针对性小规模扰动的敏感性，以确保感知和决策任务的安全性。作者将Lipschitz constant 识别为量化网络鲁棒性的关键指标，并推导了一个基于神经网络架构的解析表达式，用于估计和提升鲁棒性。实验结果揭示了网络设计与Lipschitz constant 之间的关系，为开发更安全、更可靠的机器人学习系统提供了实用见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "SAFE-ROL at CoRL 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.23382v1",
      "published_date": "2024-10-30 18:38:42 UTC",
      "updated_date": "2024-10-30 18:38:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:50:07.931865"
    },
    {
      "arxiv_id": "2411.00864v1",
      "title": "Advancing Crime Linkage Analysis with Machine Learning: A Comprehensive Review and Framework for Data-Driven Approaches",
      "title_zh": "翻译失败",
      "authors": [
        "Vinicius Lima",
        "Umit Karabiyik"
      ],
      "abstract": "Crime linkage is the process of analyzing criminal behavior data to determine\nwhether a pair or group of crime cases are connected or belong to a series of\noffenses. This domain has been extensively studied by researchers in sociology,\npsychology, and statistics. More recently, it has drawn interest from computer\nscientists, especially with advances in artificial intelligence. Despite this,\nthe literature indicates that work in this latter discipline is still in its\nearly stages. This study aims to understand the challenges faced by machine\nlearning approaches in crime linkage and to support foundational knowledge for\nfuture data-driven methods. To achieve this goal, we conducted a comprehensive\nsurvey of the main literature on the topic and developed a general framework\nfor crime linkage processes, thoroughly describing each step. Our goal was to\nunify insights from diverse fields into a shared terminology to enhance the\nresearch landscape for those intrigued by this subject.",
      "tldr_zh": "这篇论文审视了crime linkage（犯罪关联分析）的概念，即通过分析犯罪行为数据来确定案件是否相关，并强调了machine learning在这一领域的发展现状。作者进行了全面文献调研，识别出machine learning方法面临的挑战，如数据处理和模型准确性问题，并为未来数据驱动方法提供了基础知识。论文还开发了一个通用framework for crime linkage processes，详细描述了每个步骤，以统一社会学、心理学和计算机科学等领域的术语和见解。该框架有助于提升犯罪关联研究的整体景观，促进更有效的跨学科合作。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.00864v1",
      "published_date": "2024-10-30 18:22:45 UTC",
      "updated_date": "2024-10-30 18:22:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:50:20.447717"
    },
    {
      "arxiv_id": "2410.23373v1",
      "title": "Non-binary artificial neuron with phase variation implemented on a quantum computer",
      "title_zh": "翻译失败",
      "authors": [
        "Jhordan Silveira de Borba",
        "Jonas Maziero"
      ],
      "abstract": "The first artificial quantum neuron models followed a similar path to classic\nmodels, as they work only with discrete values. Here we introduce an algorithm\nthat generalizes the binary model manipulating the phase of complex numbers. We\npropose, test, and implement a neuron model that works with continuous values\nin a quantum computer. Through simulations, we demonstrate that our model may\nwork in a hybrid training scheme utilizing gradient descent as a learning\nalgorithm. This work represents another step in the direction of evaluation of\nthe use of artificial neural networks efficiently implemented on near-term\nquantum devices.",
      "tldr_zh": "本研究引入了一种非二进制 artificial neuron 模型，通过操纵复杂数的 phase variation 来处理连续值，并在量子计算机上实现和测试。该模型扩展了传统二进制量子神经元，允许在混合训练方案中使用 gradient descent 作为学习算法。通过模拟实验，证明了其在 hybrid training 中的有效性，为在近端量子设备上高效实现 artificial neural networks 提供了重要进展。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.LG",
        "cs.NE"
      ],
      "primary_category": "quant-ph",
      "comment": "11 pages, 7 figures, to be published in Ci\\^encia e Natura (ISSN\n  2179-460X, DOI: 10.5902/2179460X)",
      "pdf_url": "http://arxiv.org/pdf/2410.23373v1",
      "published_date": "2024-10-30 18:18:53 UTC",
      "updated_date": "2024-10-30 18:18:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:50:32.092148"
    },
    {
      "arxiv_id": "2410.23356v1",
      "title": "Sequential Order-Robust Mamba for Time Series Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Seunghan Lee",
        "Juri Hong",
        "Kibok Lee",
        "Taeyoung Park"
      ],
      "abstract": "Mamba has recently emerged as a promising alternative to Transformers,\noffering near-linear complexity in processing sequential data. However, while\nchannels in time series (TS) data have no specific order in general, recent\nstudies have adopted Mamba to capture channel dependencies (CD) in TS,\nintroducing a sequential order bias. To address this issue, we propose\nSOR-Mamba, a TS forecasting method that 1) incorporates a regularization\nstrategy to minimize the discrepancy between two embedding vectors generated\nfrom data with reversed channel orders, thereby enhancing robustness to channel\norder, and 2) eliminates the 1D-convolution originally designed to capture\nlocal information in sequential data. Furthermore, we introduce channel\ncorrelation modeling (CCM), a pretraining task aimed at preserving correlations\nbetween channels from the data space to the latent space in order to enhance\nthe ability to capture CD. Extensive experiments demonstrate the efficacy of\nthe proposed method across standard and transfer learning scenarios. Code is\navailable at https://github.com/seunghan96/SOR-Mamba.",
      "tldr_zh": "本研究针对Mamba模型在时间序列(TS)预测中引入的通道顺序偏差问题，提出了一种鲁棒性增强方法SOR-Mamba。SOR-Mamba通过正则化策略最小化反转通道顺序数据生成的嵌入向量差异，并去除原始的1D-convolution，以提升对通道依赖(CD)的捕捉能力而不受顺序影响。此外，该方法引入通道相关性建模(CCM)作为预训练任务，在数据空间和潜在空间保留通道相关性。实验结果显示，SOR-Mamba在标准和迁移学习场景中表现出色，证明了其有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS Workshop on Time Series in the Age of Large Models, 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.23356v1",
      "published_date": "2024-10-30 18:05:22 UTC",
      "updated_date": "2024-10-30 18:05:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:51:06.686903"
    },
    {
      "arxiv_id": "2411.00863v1",
      "title": "Next-Token Prediction Task Assumes Optimal Data Ordering for LLM Training in Proof Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Chenyang An",
        "Shima Imani",
        "Feng Yao",
        "Chengyu Dong",
        "Ali Abbasi",
        "Harsh Shrivastava",
        "Samuel Buss",
        "Jingbo Shang",
        "Gayathri Mahalingam",
        "Pramod Sharma",
        "Maurice Diesendruck"
      ],
      "abstract": "In the field of large language model (LLM)-based proof generation, despite\nbeing trained on extensive corpora such as OpenWebMath and Arxiv, these models\nstill exhibit only modest performance on proving tasks of moderate difficulty.\nWe believe that this is partly due to the suboptimal order of each proof data\nused in training. Published proofs often follow a purely logical order, where\neach step logically proceeds from the previous steps based on the deductive\nrules. However, this order aims to facilitate the verification of the proof's\nsoundness, rather than to help people and models learn the discovery process of\nthe proof. In proof generation, we argue that the optimal order for one\ntraining data sample occurs when the relevant intermediate supervision for a\nparticular proof step in the proof is always positioned to the left of that\nproof step. We call such order the intuitively sequential order. We validate\nour claims using two tasks: intuitionistic propositional logic theorem-proving\nand digit multiplication. Our experiments verify the order effect and provide\nsupport for our explanations. We demonstrate that training is most effective\nwhen the proof is in the intuitively sequential order. Moreover, the order\neffect and the performance gap between models trained on different data orders\nare substantial -- with an 11 percent improvement in proof success rate\nobserved in the propositional logic theorem-proving task, between models\ntrained on the optimal order compared to the worst order.",
      "tldr_zh": "该论文指出，大语言模型 (LLM) 在证明生成任务中表现不佳，部分原因是训练数据顺序不优，因为传统的逻辑顺序更适合验证而非学习。作者提出“intuitively sequential order”概念，即将相关中间监督置于证明步骤左侧，以优化 next-token prediction 任务的训练效果。实验通过直觉命题逻辑定理证明和数字乘法任务验证了这一顺序影响，证明成功率最高可提高11%，强调了数据顺序对LLM训练的重要性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.00863v1",
      "published_date": "2024-10-30 18:00:04 UTC",
      "updated_date": "2024-10-30 18:00:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:50:56.368201"
    },
    {
      "arxiv_id": "2410.23346v2",
      "title": "ASURA-FDPS-ML: Star-by-star Galaxy Simulations Accelerated by Surrogate Modeling for Supernova Feedback",
      "title_zh": "翻译失败",
      "authors": [
        "Keiya Hirashima",
        "Kana Moriwaki",
        "Michiko S. Fujii",
        "Yutaka Hirai",
        "Takayuki R. Saitoh",
        "Junnichiro Makino",
        "Ulrich P. Steinwandel",
        "Shirley Ho"
      ],
      "abstract": "We introduce new high-resolution galaxy simulations accelerated by a\nsurrogate model that reduces the computation cost by approximately 75 percent.\nMassive stars with a Zero Age Main Sequence mass of more than about 10\n$\\mathrm{M_\\odot}$ explode as core-collapse supernovae (CCSNe), which play a\ncritical role in galaxy formation. The energy released by CCSNe is essential\nfor regulating star formation and driving feedback processes in the\ninterstellar medium (ISM). However, the short integration timesteps required\nfor SNe feedback have presented significant bottlenecks in astrophysical\nsimulations across various scales. Overcoming this challenge is crucial for\nenabling star-by-star galaxy simulations, which aim to capture the dynamics of\nindividual stars and the inhomogeneous shell's expansion within the turbulent\nISM. To address this, our new framework combines direct numerical simulations\nand surrogate modeling, including machine learning and Gibbs sampling. The star\nformation history and the time evolution of outflow rates in the galaxy match\nthose obtained from resolved direct numerical simulations. Our new approach\nachieves high-resolution fidelity while reducing computational costs,\neffectively bridging the physical scale gap and enabling multi-scale\nsimulations.",
      "tldr_zh": "本研究引入了ASURA-FDPS-ML框架，通过surrogate modeling将高分辨率星系模拟的计算成本降低约75%，以加速处理核心坍缩超新星(CCSNe)反馈。框架结合直接数值模拟、machine learning和Gibbs sampling，解决了CCSNe在星际介质(ISM)中所需短积分时间步长的计算瓶颈，实现star-by-star模拟。结果显示，该方法在星形成历史和流出率时间演化上与高分辨率直接模拟一致，有效桥接物理尺度差距，并支持多尺度模拟。",
      "categories": [
        "astro-ph.GA",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "astro-ph.GA",
      "comment": "22 pages, 15 figures, 3 tables, accepted for publication in ApJ",
      "pdf_url": "http://arxiv.org/pdf/2410.23346v2",
      "published_date": "2024-10-30 18:00:02 UTC",
      "updated_date": "2025-05-07 08:03:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:51:08.816044"
    },
    {
      "arxiv_id": "2410.23332v1",
      "title": "MoLE: Enhancing Human-centric Text-to-image Diffusion via Mixture of Low-rank Experts",
      "title_zh": "翻译失败",
      "authors": [
        "Jie Zhu",
        "Yixiong Chen",
        "Mingyu Ding",
        "Ping Luo",
        "Leye Wang",
        "Jingdong Wang"
      ],
      "abstract": "Text-to-image diffusion has attracted vast attention due to its impressive\nimage-generation capabilities. However, when it comes to human-centric\ntext-to-image generation, particularly in the context of faces and hands, the\nresults often fall short of naturalness due to insufficient training priors. We\nalleviate the issue in this work from two perspectives. 1) From the data\naspect, we carefully collect a human-centric dataset comprising over one\nmillion high-quality human-in-the-scene images and two specific sets of\nclose-up images of faces and hands. These datasets collectively provide a rich\nprior knowledge base to enhance the human-centric image generation capabilities\nof the diffusion model. 2) On the methodological front, we propose a simple yet\neffective method called Mixture of Low-rank Experts (MoLE) by considering\nlow-rank modules trained on close-up hand and face images respectively as\nexperts. This concept draws inspiration from our observation of low-rank\nrefinement, where a low-rank module trained by a customized close-up dataset\nhas the potential to enhance the corresponding image part when applied at an\nappropriate scale. To validate the superiority of MoLE in the context of\nhuman-centric image generation compared to state-of-the-art, we construct two\nbenchmarks and perform evaluations with diverse metrics and human studies.\nDatasets, model, and code are released at\nhttps://sites.google.com/view/mole4diffuser/.",
      "tldr_zh": "本研究针对文本到图像扩散模型（Text-to-image diffusion）在人类中心图像生成（如面部和手部）中的自然性不足问题，提出从数据和方法两方面进行优化。首先，作者收集了一个超过一百万张高质量人类场景图像的数据集，以及专门的面部和手部特写图像集，以增强模型的训练先验知识。其次，引入了Mixture of Low-rank Experts (MoLE)方法，通过在特写图像上训练的低秩模块作为专家，实现对特定图像部分的精确增强。实验结果显示，MoLE在两个构建的基准上优于现有技术，并在多种指标和人类评估中验证了其有效性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Published at NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.23332v1",
      "published_date": "2024-10-30 17:59:57 UTC",
      "updated_date": "2024-10-30 17:59:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:51:20.208021"
    },
    {
      "arxiv_id": "2410.23285v3",
      "title": "Provable Acceleration for Diffusion Models under Minimal Assumptions",
      "title_zh": "在",
      "authors": [
        "Gen Li",
        "Changxiao Cai"
      ],
      "abstract": "Score-based diffusion models, while achieving minimax optimality for\nsampling, are often hampered by slow sampling speeds due to the high\ncomputational burden of score function evaluations. Despite the recent\nremarkable empirical advances in speeding up the score-based samplers,\ntheoretical understanding of acceleration techniques remains largely limited.\nTo bridge this gap, we propose a novel training-free acceleration scheme for\nstochastic samplers. Under minimal assumptions -- namely, $L^2$-accurate score\nestimates and a finite second-moment condition on the target distribution --\nour accelerated sampler provably achieves $\\varepsilon$-accuracy in total\nvariation within $\\widetilde{O}(d^{5/4}/\\sqrt{\\varepsilon})$ iterations,\nthereby significantly improving upon the $\\widetilde{O}(d/\\varepsilon)$\niteration complexity of standard score-based samplers for $\\varepsilon\\leq\n1/\\sqrt{d}$. Notably, our convergence theory does not rely on restrictive\nassumptions on the target distribution or higher-order score estimation\nguarantees.",
      "tldr_zh": "该研究针对 score-based diffusion models 在采样过程中的计算负担和慢速问题，提出了一种新的训练-free 加速方案。方案仅依赖于 L^2-accurate score estimates 和 finite second-moment condition 的最小假设，即可证明加速采样器在 total variation 中实现 ε-accuracy，仅需 Õ(d^{5/4}/√ε) 迭代次数。相比标准采样器的 Õ(d/ε) 复杂度，这一改进在 ε ≤ 1/√d 时尤为显著，且理论不需额外限制性假设。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.23285v3",
      "published_date": "2024-10-30 17:59:06 UTC",
      "updated_date": "2025-02-26 17:35:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:51:32.333235"
    },
    {
      "arxiv_id": "2411.00052v1",
      "title": "Larger models yield better results? Streamlined severity classification of ADHD-related concerns using BERT-based knowledge distillation",
      "title_zh": "更大的模型会产生更好的结果？使用基于 BERT 的知识蒸馏简化 ADHD 相关问题的严重程度分类",
      "authors": [
        "Ahmed Akib Jawad Karim",
        "Kazi Hafiz Md. Asad",
        "Md. Golam Rabiul Alam"
      ],
      "abstract": "This work focuses on the efficiency of the knowledge distillation approach in\ngenerating a lightweight yet powerful BERT based model for natural language\nprocessing applications. After the model creation, we applied the resulting\nmodel, LastBERT, to a real-world task classifying severity levels of Attention\nDeficit Hyperactivity Disorder (ADHD)-related concerns from social media text\ndata. Referring to LastBERT, a customized student BERT model, we significantly\nlowered model parameters from 110 million BERT base to 29 million, resulting in\na model approximately 73.64% smaller. On the GLUE benchmark, comprising\nparaphrase identification, sentiment analysis, and text classification, the\nstudent model maintained strong performance across many tasks despite this\nreduction. The model was also used on a real-world ADHD dataset with an\naccuracy and F1 score of 85%. When compared to DistilBERT (66M) and\nClinicalBERT (110M), LastBERT demonstrated comparable performance, with\nDistilBERT slightly outperforming it at 87%, and ClinicalBERT achieving 86%\nacross the same metrics. These findings highlight the LastBERT model's capacity\nto classify degrees of ADHD severity properly, so it offers a useful tool for\nmental health professionals to assess and comprehend material produced by users\non social networking platforms. The study emphasizes the possibilities of\nknowledge distillation to produce effective models fit for use in\nresource-limited conditions, hence advancing NLP and mental health diagnosis.\nFurthermore underlined by the considerable decrease in model size without\nappreciable performance loss is the lower computational resources needed for\ntraining and deployment, hence facilitating greater applicability. Especially\nusing readily available computational tools like Google Colab. This study shows\nthe accessibility and usefulness of advanced NLP methods in pragmatic world\napplications.",
      "tldr_zh": "本研究质疑更大模型是否总是更好，通过知识蒸馏技术开发了轻量级 BERT 模型 LastBERT，将参数从 BERT base 的 110 百万减少到 29 百万，约小 73.64%。LastBERT 应用于社交媒体文本中 ADHD 相关担忧的严重程度分类任务，取得了 85% 的准确率和 F1 分数，并在 GLUE 基准上保持了强劲性能。相比 DistilBERT (66M) 和 ClinicalBERT (110M)，LastBERT 的表现相当，突显了知识蒸馏在资源有限环境（如 Google Colab）下的潜力，提升了 NLP 在心理健康诊断中的实用性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "20 figures, 31 pages, review 1 from plos one journal",
      "pdf_url": "http://arxiv.org/pdf/2411.00052v1",
      "published_date": "2024-10-30 17:57:44 UTC",
      "updated_date": "2024-10-30 17:57:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:51:44.958187"
    },
    {
      "arxiv_id": "2410.23279v3",
      "title": "A Transformer Model for Segmentation, Classification, and Caller Identification of Marmoset Vocalization",
      "title_zh": "翻译失败",
      "authors": [
        "Bin Wu",
        "Shinnosuke Takamichi",
        "Sakriani Sakti",
        "Satoshi Nakamura"
      ],
      "abstract": "Marmoset, a highly vocalized primate, has become a popular animal model for\nstudying social-communicative behavior and its underlying mechanism comparing\nwith human infant linguistic developments. In the study of vocal communication,\nit is vital to know the caller identities, call contents, and vocal exchanges.\nPrevious work of a CNN has achieved a joint model for call segmentation,\nclassification, and caller identification for marmoset vocalizations. However,\nthe CNN has limitations in modeling long-range acoustic patterns; the\nTransformer architecture that has been shown to outperform CNNs, utilizes the\nself-attention mechanism that efficiently segregates information parallelly\nover long distances and captures the global structure of marmoset vocalization.\nWe propose using the Transformer to jointly segment and classify the marmoset\ncalls and identify the callers for each vocalization.",
      "tldr_zh": "本研究针对狨猴（marmoset）作为社会沟通行为模型，提出了一种基于 Transformer 模型的框架，用于联合处理 marmoset vocalization 的分割（segmentation）、分类（classification）和调用者识别（caller identification）。与之前的 CNN 模型相比，Transformer 通过 self-attention 机制更有效地捕捉长距离声学模式和全局结构，从而提升了模型在处理复杂 vocalization 时的性能。该方法为研究 marmoset 的社会沟通机制提供了更先进的工具，有望改善对人类婴儿语言发展的比较分析。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.23279v3",
      "published_date": "2024-10-30 17:57:13 UTC",
      "updated_date": "2024-11-21 08:52:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:51:55.601875"
    },
    {
      "arxiv_id": "2410.23277v2",
      "title": "SlowFast-VGen: Slow-Fast Learning for Action-Driven Long Video Generation",
      "title_zh": "SlowFast-VGen：慢速-快速学习用于动作驱动的长视频生成",
      "authors": [
        "Yining Hong",
        "Beide Liu",
        "Maxine Wu",
        "Yuanhao Zhai",
        "Kai-Wei Chang",
        "Linjie Li",
        "Kevin Lin",
        "Chung-Ching Lin",
        "Jianfeng Wang",
        "Zhengyuan Yang",
        "Yingnian Wu",
        "Lijuan Wang"
      ],
      "abstract": "Human beings are endowed with a complementary learning system, which bridges\nthe slow learning of general world dynamics with fast storage of episodic\nmemory from a new experience. Previous video generation models, however,\nprimarily focus on slow learning by pre-training on vast amounts of data,\noverlooking the fast learning phase crucial for episodic memory storage. This\noversight leads to inconsistencies across temporally distant frames when\ngenerating longer videos, as these frames fall beyond the model's context\nwindow. To this end, we introduce SlowFast-VGen, a novel dual-speed learning\nsystem for action-driven long video generation. Our approach incorporates a\nmasked conditional video diffusion model for the slow learning of world\ndynamics, alongside an inference-time fast learning strategy based on a\ntemporal LoRA module. Specifically, the fast learning process updates its\ntemporal LoRA parameters based on local inputs and outputs, thereby efficiently\nstoring episodic memory in its parameters. We further propose a slow-fast\nlearning loop algorithm that seamlessly integrates the inner fast learning loop\ninto the outer slow learning loop, enabling the recall of prior multi-episode\nexperiences for context-aware skill learning. To facilitate the slow learning\nof an approximate world model, we collect a large-scale dataset of 200k videos\nwith language action annotations, covering a wide range of scenarios. Extensive\nexperiments show that SlowFast-VGen outperforms baselines across various\nmetrics for action-driven video generation, achieving an FVD score of 514\ncompared to 782, and maintaining consistency in longer videos, with an average\nof 0.37 scene cuts versus 0.89. The slow-fast learning loop algorithm\nsignificantly enhances performances on long-horizon planning tasks as well.\nProject Website: https://slowfast-vgen.github.io",
      "tldr_zh": "该论文提出SlowFast-VGen，一种双速学习系统，用于行动驱动的长视频生成，旨在结合人类式慢速学习世界动态和快速存储episodic memory，以解决现有模型在长视频中远帧不一致的问题。方法包括使用masked conditional video diffusion model进行慢速学习，以及基于temporal LoRA module的推理时快速学习策略，后者通过更新参数高效存储局部记忆。研究者还设计了slow-fast learning loop算法，将快速学习融入慢速学习中，并收集了20k视频数据集以支持世界模型训练。实验结果显示，SlowFast-VGen在各种指标上优于基线模型，FVD分数达到514（相比782），长视频一致性显著提升（平均scene cuts为0.37 vs 0.89），并在长horizon规划任务中表现出色。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.23277v2",
      "published_date": "2024-10-30 17:55:52 UTC",
      "updated_date": "2024-10-31 18:03:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:52:09.221473"
    },
    {
      "arxiv_id": "2410.23274v2",
      "title": "Multi-student Diffusion Distillation for Better One-step Generators",
      "title_zh": "翻译失败",
      "authors": [
        "Yanke Song",
        "Jonathan Lorraine",
        "Weili Nie",
        "Karsten Kreis",
        "James Lucas"
      ],
      "abstract": "Diffusion models achieve high-quality sample generation at the cost of a\nlengthy multistep inference procedure. To overcome this, diffusion distillation\ntechniques produce student generators capable of matching or surpassing the\nteacher in a single step. However, the student model's inference speed is\nlimited by the size of the teacher architecture, preventing real-time\ngeneration for computationally heavy applications. In this work, we introduce\nMulti-Student Distillation (MSD), a framework to distill a conditional teacher\ndiffusion model into multiple single-step generators. Each student generator is\nresponsible for a subset of the conditioning data, thereby obtaining higher\ngeneration quality for the same capacity. MSD trains multiple distilled\nstudents, allowing smaller sizes and, therefore, faster inference. Also, MSD\noffers a lightweight quality boost over single-student distillation with the\nsame architecture. We demonstrate MSD is effective by training multiple\nsame-sized or smaller students on single-step distillation using distribution\nmatching and adversarial distillation techniques. With smaller students, MSD\ngets competitive results with faster inference for single-step generation.\nUsing 4 same-sized students, MSD significantly outperforms single-student\nbaseline counterparts and achieves remarkable FID scores for one-step image\ngeneration: 1.20 on ImageNet-64x64 and 8.20 on zero-shot COCO2014.",
      "tldr_zh": "本研究针对扩散模型（Diffusion models）的高质量样本生成需多步推理的问题，提出 Multi-Student Distillation (MSD) 框架，将条件教师扩散模型蒸馏成多个单步生成器，每个生成器负责条件数据的子集，从而在相同容量下提升生成质量并实现更快推理。相比单学生蒸馏，MSD 允许训练更小尺寸的学生模型，提供轻量级质量提升，并通过分布匹配和对抗蒸馏技术优化训练过程。实验结果显示，使用更小学生时，MSD 在单步生成中获得竞争性性能和加速推理；使用 4 个相同大小的学生时，显著超越基线，在 ImageNet-64x64 上 FID 得分为 1.20，在零样本 COCO2014 上达 8.20。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Project page: https://research.nvidia.com/labs/toronto-ai/MSD/",
      "pdf_url": "http://arxiv.org/pdf/2410.23274v2",
      "published_date": "2024-10-30 17:54:56 UTC",
      "updated_date": "2024-12-03 00:28:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:52:22.011245"
    },
    {
      "arxiv_id": "2410.23273v1",
      "title": "Proportional Fairness in Non-Centroid Clustering",
      "title_zh": "非质心聚类中的比例公平",
      "authors": [
        "Ioannis Caragiannis",
        "Evi Micha",
        "Nisarg Shah"
      ],
      "abstract": "We revisit the recently developed framework of proportionally fair\nclustering, where the goal is to provide group fairness guarantees that become\nstronger for groups of data points (agents) that are large and cohesive. Prior\nwork applies this framework to centroid clustering, where the loss of an agent\nis its distance to the centroid assigned to its cluster. We expand the\nframework to non-centroid clustering, where the loss of an agent is a function\nof the other agents in its cluster, by adapting two proportional fairness\ncriteria -- the core and its relaxation, fully justified representation (FJR)\n-- to this setting.\n  We show that the core can be approximated only under structured loss\nfunctions, and even then, the best approximation we are able to establish,\nusing an adaptation of the GreedyCapture algorithm developed for centroid\nclustering [Chen et al., 2019; Micha and Shah, 2020], is unappealing for a\nnatural loss function. In contrast, we design a new (inefficient) algorithm,\nGreedyCohesiveClustering, which achieves the relaxation FJR exactly under\narbitrary loss functions, and show that the efficient GreedyCapture algorithm\nachieves a constant approximation of FJR. We also design an efficient auditing\nalgorithm, which estimates the FJR approximation of any given clustering\nsolution up to a constant factor. Our experiments on real data suggest that\ntraditional clustering algorithms are highly unfair, whereas GreedyCapture is\nconsiderably fairer and incurs only a modest loss in common clustering\nobjectives.",
      "tldr_zh": "该研究扩展了比例公平聚类框架（proportional fairness clustering），旨在为大型且连贯的数据点群组提供更强的公平性保证，并首次应用于非中心聚类（non-centroid clustering），其中代理的损失函数依赖于其簇中的其他代理。作者适应了两个标准：core 和其松弛版本 fully justified representation (FJR)，但发现 core 仅在结构化损失函数下可近似，且使用 GreedyCapture 算法的近似效果不理想。论文提出新算法 GreedyCohesiveClustering，能在任意损失函数下精确实现 FJR，同时 GreedyCapture 提供 FJR 的常数近似，并设计了一个高效审计算法来评估聚类解决方案的 FJR 近似值。实验结果显示，传统聚类算法高度不公平，而 GreedyCapture 显著提升了公平性，仅在常见聚类目标上造成适度损失。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.GT"
      ],
      "primary_category": "cs.LG",
      "comment": "A preliminary version appeared at NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.23273v1",
      "published_date": "2024-10-30 17:53:49 UTC",
      "updated_date": "2024-10-30 17:53:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:52:33.156643"
    },
    {
      "arxiv_id": "2410.23272v1",
      "title": "A Monte Carlo Framework for Calibrated Uncertainty Estimation in Sequence Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Qidong Yang",
        "Weicheng Zhu",
        "Joseph Keslin",
        "Laure Zanna",
        "Tim G. J. Rudner",
        "Carlos Fernandez-Granda"
      ],
      "abstract": "Probabilistic prediction of sequences from images and other high-dimensional\ndata is a key challenge, particularly in risk-sensitive applications. In these\nsettings, it is often desirable to quantify the uncertainty associated with the\nprediction (instead of just determining the most likely sequence, as in\nlanguage modeling). In this paper, we propose a Monte Carlo framework to\nestimate probabilities and confidence intervals associated with the\ndistribution of a discrete sequence. Our framework uses a Monte Carlo\nsimulator, implemented as an autoregressively trained neural network, to sample\nsequences conditioned on an image input. We then use these samples to estimate\nthe probabilities and confidence intervals. Experiments on synthetic and real\ndata show that the framework produces accurate discriminative predictions, but\ncan suffer from miscalibration. In order to address this shortcoming, we\npropose a time-dependent regularization method, which is shown to produce\ncalibrated predictions.",
      "tldr_zh": "该论文提出一个 Monte Carlo 框架，用于在序列预测中估计校准的不确定性，特别针对图像和其他高维数据的概率预测，以满足风险敏感应用的需求。该框架通过一个 autoregressively trained neural network 实现的 Monte Carlo 模拟器来采样序列，并基于样本计算序列的概率和置信区间。实验结果显示，该框架能产生准确的预测，但可能出现校准偏差；为此，论文引入了 time-dependent regularization 方法，有效提升了预测的校准性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.23272v1",
      "published_date": "2024-10-30 17:53:37 UTC",
      "updated_date": "2024-10-30 17:53:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:52:44.354819"
    },
    {
      "arxiv_id": "2410.23330v1",
      "title": "CLIPErase: Efficient Unlearning of Visual-Textual Associations in CLIP",
      "title_zh": "翻译失败",
      "authors": [
        "Tianyu Yang",
        "Lisen Dai",
        "Zheyuan Liu",
        "Xiangqi Wang",
        "Meng Jiang",
        "Yapeng Tian",
        "Xiangliang Zhang"
      ],
      "abstract": "Machine unlearning (MU) has gained significant attention as a means to remove\nspecific data from trained models without requiring a full retraining process.\nWhile progress has been made in unimodal domains like text and image\nclassification, unlearning in multimodal models remains relatively\nunderexplored. In this work, we address the unique challenges of unlearning in\nCLIP, a prominent multimodal model that aligns visual and textual\nrepresentations. We introduce CLIPErase, a novel approach that disentangles and\nselectively forgets both visual and textual associations, ensuring that\nunlearning does not compromise model performance. CLIPErase consists of three\nkey modules: a Forgetting Module that disrupts the associations in the forget\nset, a Retention Module that preserves performance on the retain set, and a\nConsistency Module that maintains consistency with the original model.\nExtensive experiments on the CIFAR-100 and Flickr30K datasets across four CLIP\ndownstream tasks demonstrate that CLIPErase effectively forgets designated\nassociations in zero-shot tasks for multimodal samples, while preserving the\nmodel's performance on the retain set after unlearning.",
      "tldr_zh": "本研究针对多模态模型 CLIP 中的视觉-文本关联问题，提出 CLIPEase，一种高效的 Machine Unlearning 方法，能够选择性忘记指定数据而不需完整重训。CLIPEase 包括三个关键模块：Forgetting Module 用于破坏忘记集中的关联、Retention Module 用于保留保留集的性能，以及 Consistency Module 用于维持模型的一致性。在 CIFAR-100 和 Flickr30K 数据集上的实验显示，CLIPEase 在零样本任务中有效忘记指定关联，同时保持模型在保留集上的性能。总的来说，该方法为多模态模型的隐私保护和数据管理提供了可行方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.23330v1",
      "published_date": "2024-10-30 17:51:31 UTC",
      "updated_date": "2024-10-30 17:51:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:52:56.103775"
    },
    {
      "arxiv_id": "2410.23266v1",
      "title": "TOMATO: Assessing Visual Temporal Reasoning Capabilities in Multimodal Foundation Models",
      "title_zh": "TOMATO：评估多模态基础模型中的视觉时间推理能力",
      "authors": [
        "Ziyao Shangguan",
        "Chuhan Li",
        "Yuxuan Ding",
        "Yanan Zheng",
        "Yilun Zhao",
        "Tesca Fitzgerald",
        "Arman Cohan"
      ],
      "abstract": "Existing benchmarks often highlight the remarkable performance achieved by\nstate-of-the-art Multimodal Foundation Models (MFMs) in leveraging temporal\ncontext for video understanding. However, how well do the models truly perform\nvisual temporal reasoning? Our study of existing benchmarks shows that this\ncapability of MFMs is likely overestimated as many questions can be solved by\nusing a single, few, or out-of-order frames. To systematically examine current\nvisual temporal reasoning tasks, we propose three principles with corresponding\nmetrics: (1) Multi-Frame Gain, (2) Frame Order Sensitivity, and (3) Frame\nInformation Disparity. Following these principles, we introduce TOMATO,\nTemporal Reasoning Multimodal Evaluation, a novel benchmark crafted to\nrigorously assess MFMs' temporal reasoning capabilities in video understanding.\nTOMATO comprises 1,484 carefully curated, human-annotated questions spanning\nsix tasks (i.e., action count, direction, rotation, shape & trend, velocity &\nfrequency, and visual cues), applied to 1,417 videos, including 805\nself-recorded and -generated videos, that encompass human-centric, real-world,\nand simulated scenarios. Our comprehensive evaluation reveals a human-model\nperformance gap of 57.3% with the best-performing model. Moreover, our in-depth\nanalysis uncovers more fundamental limitations beyond this gap in current MFMs.\nWhile they can accurately recognize events in isolated frames, they fail to\ninterpret these frames as a continuous sequence. We believe TOMATO will serve\nas a crucial testbed for evaluating the next-generation MFMs and as a call to\nthe community to develop AI systems capable of comprehending human world\ndynamics through the video modality.",
      "tldr_zh": "这篇论文指出，现有的基准高估了 Multimodal Foundation Models (MFMs) 在视频理解中的视觉时间推理能力，因为许多问题仅需使用单个帧、少数帧或无序帧即可解决。作者提出三个评估原则及其指标：Multi-Frame Gain、Frame Order Sensitivity 和 Frame Information Disparity，以系统地考察 MFMs 的时间推理性能。基于这些原则，他们引入了 TOMATO 基准，该基准包含 1,484 个人工标注问题和 1,417 个视频，覆盖六种任务（如行动计数、方向和旋转等）。实验结果显示，最佳模型与人类的性能差距达 57.3%，并揭示 MFMs 虽能准确识别孤立帧事件，但无法有效处理连续序列。TOMATO 将作为评估下一代 MFMs 的关键测试床，推动开发能理解视频动态的 AI 系统。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.23266v1",
      "published_date": "2024-10-30 17:50:23 UTC",
      "updated_date": "2024-10-30 17:50:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:53:09.276953"
    },
    {
      "arxiv_id": "2410.23262v2",
      "title": "EMMA: End-to-End Multimodal Model for Autonomous Driving",
      "title_zh": "翻译失败",
      "authors": [
        "Jyh-Jing Hwang",
        "Runsheng Xu",
        "Hubert Lin",
        "Wei-Chih Hung",
        "Jingwei Ji",
        "Kristy Choi",
        "Di Huang",
        "Tong He",
        "Paul Covington",
        "Benjamin Sapp",
        "Yin Zhou",
        "James Guo",
        "Dragomir Anguelov",
        "Mingxing Tan"
      ],
      "abstract": "We introduce EMMA, an End-to-end Multimodal Model for Autonomous driving.\nBuilt on a multi-modal large language model foundation, EMMA directly maps raw\ncamera sensor data into various driving-specific outputs, including planner\ntrajectories, perception objects, and road graph elements. EMMA maximizes the\nutility of world knowledge from the pre-trained large language models, by\nrepresenting all non-sensor inputs (e.g. navigation instructions and ego\nvehicle status) and outputs (e.g. trajectories and 3D locations) as natural\nlanguage text. This approach allows EMMA to jointly process various driving\ntasks in a unified language space, and generate the outputs for each task using\ntask-specific prompts. Empirically, we demonstrate EMMA's effectiveness by\nachieving state-of-the-art performance in motion planning on nuScenes as well\nas competitive results on the Waymo Open Motion Dataset (WOMD). EMMA also\nyields competitive results for camera-primary 3D object detection on the Waymo\nOpen Dataset (WOD). We show that co-training EMMA with planner trajectories,\nobject detection, and road graph tasks yields improvements across all three\ndomains, highlighting EMMA's potential as a generalist model for autonomous\ndriving applications. However, EMMA also exhibits certain limitations: it can\nprocess only a small amount of image frames, does not incorporate accurate 3D\nsensing modalities like LiDAR or radar and is computationally expensive. We\nhope that our results will inspire further research to mitigate these issues\nand to further evolve the state of the art in autonomous driving model\narchitectures.",
      "tldr_zh": "该研究提出 EMMA，一种基于多模态大型语言模型（multimodal large language models）的端到端模型，用于自动驾驶，直接将原始相机数据映射到驾驶输出，如规划轨迹、感知对象和道路图形元素，通过自然语言文本表示非传感器输入和输出，并在统一语言空间联合处理任务。实验结果显示，EMMA 在 nuScenes 数据集上实现最先进的状态的运动规划，在 Waymo Open Motion Dataset (WOMD) 和 Waymo Open Dataset (WOD) 上取得竞争性性能，且通过联合训练规划轨迹、对象检测和道路图形任务，提升了所有领域的表现。EMMA 的局限性包括仅处理少量图像帧、不包含精确的3D感知模态如 LiDAR 或 radar，以及计算开销较大，作者希望此研究能激发进一步优化自动驾驶模型的努力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "Blog post: https://waymo.com/blog/2024/10/introducing-emma/",
      "pdf_url": "http://arxiv.org/pdf/2410.23262v2",
      "published_date": "2024-10-30 17:46:31 UTC",
      "updated_date": "2024-11-04 18:44:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:53:22.303667"
    },
    {
      "arxiv_id": "2410.23254v1",
      "title": "Keypoint Abstraction using Large Models for Object-Relative Imitation Learning",
      "title_zh": "关键点抽象：使用大型模型进行对象相关的模仿学习",
      "authors": [
        "Xiaolin Fang",
        "Bo-Ruei Huang",
        "Jiayuan Mao",
        "Jasmine Shone",
        "Joshua B. Tenenbaum",
        "Tomás Lozano-Pérez",
        "Leslie Pack Kaelbling"
      ],
      "abstract": "Generalization to novel object configurations and instances across diverse\ntasks and environments is a critical challenge in robotics. Keypoint-based\nrepresentations have been proven effective as a succinct representation for\ncapturing essential object features, and for establishing a reference frame in\naction prediction, enabling data-efficient learning of robot skills. However,\ntheir manual design nature and reliance on additional human labels limit their\nscalability. In this paper, we propose KALM, a framework that leverages large\npre-trained vision-language models (LMs) to automatically generate\ntask-relevant and cross-instance consistent keypoints. KALM distills robust and\nconsistent keypoints across views and objects by generating proposals using LMs\nand verifies them against a small set of robot demonstration data. Based on the\ngenerated keypoints, we can train keypoint-conditioned policy models that\npredict actions in keypoint-centric frames, enabling robots to generalize\neffectively across varying object poses, camera views, and object instances\nwith similar functional shapes. Our method demonstrates strong performance in\nthe real world, adapting to different tasks and environments from only a\nhandful of demonstrations while requiring no additional labels. Website:\nhttps://kalm-il.github.io/",
      "tldr_zh": "本研究针对机器人泛化到新对象配置和环境的挑战，提出KALM框架，利用大型预训练视觉语言模型(LMs)自动生成任务相关且跨实例一致的关键点(keypoints)。KALM通过LM生成关键点提案，并使用少量机器人演示数据进行验证，从而训练关键点条件策略模型，使机器人能在关键点中心框架中预测动作，实现对不同对象姿势、相机视图和类似功能形状对象的有效泛化。实验结果显示，该方法在真实世界任务中表现出色，仅需少量演示即可适应多种场景，且无需额外标签。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "CoRL LangRob Workshop, 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.23254v1",
      "published_date": "2024-10-30 17:37:31 UTC",
      "updated_date": "2024-10-30 17:37:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:53:31.278984"
    },
    {
      "arxiv_id": "2410.23242v2",
      "title": "A little less conversation, a little more action, please: Investigating the physical common-sense of LLMs in a 3D embodied environment",
      "title_zh": "翻译失败",
      "authors": [
        "Matteo G. Mecattaf",
        "Ben Slater",
        "Marko Tešić",
        "Jonathan Prunty",
        "Konstantinos Voudouris",
        "Lucy G. Cheke"
      ],
      "abstract": "As general-purpose tools, Large Language Models (LLMs) must often reason\nabout everyday physical environments. In a question-and-answer capacity,\nunderstanding the interactions of physical objects may be necessary to give\nappropriate responses. Moreover, LLMs are increasingly used as reasoning\nengines in agentic systems, designing and controlling their action sequences.\nThe vast majority of research has tackled this issue using static benchmarks,\ncomprised of text or image-based questions about the physical world. However,\nthese benchmarks do not capture the complexity and nuance of real-life physical\nprocesses. Here we advocate for a second, relatively unexplored, approach:\n'embodying' the LLMs by granting them control of an agent within a 3D\nenvironment. We present the first embodied and cognitively meaningful\nevaluation of physical common-sense reasoning in LLMs. Our framework allows\ndirect comparison of LLMs with other embodied agents, such as those based on\nDeep Reinforcement Learning, and human and non-human animals. We employ the\nAnimal-AI (AAI) environment, a simulated 3D virtual laboratory, to study\nphysical common-sense reasoning in LLMs. For this, we use the AAI Testbed, a\nsuite of experiments that replicate laboratory studies with non-human animals,\nto study physical reasoning capabilities including distance estimation,\ntracking out-of-sight objects, and tool use. We demonstrate that\nstate-of-the-art multi-modal models with no finetuning can complete this style\nof task, allowing meaningful comparison to the entrants of the 2019 Animal-AI\nOlympics competition and to human children. Our results show that LLMs are\ncurrently outperformed by human children on these tasks. We argue that this\napproach allows the study of physical reasoning using ecologically valid\nexperiments drawn directly from cognitive science, improving the predictability\nand reliability of LLMs.",
      "tldr_zh": "本研究调查了大型语言模型（LLMs）在3D embodied环境中处理物理常识推理的能力，强调了传统静态基准的局限性，转而采用让LLMs控制代理进行互动的方法。研究者使用Animal-AI（AAI）环境和AAI Testbed测试LLMs在距离估计、跟踪视线外物体及工具使用等任务中的表现，这些实验借鉴了认知科学中的动物实验。结果显示，先进的未微调多模态模型能完成部分任务，但整体性能逊于人类儿童和Deep Reinforcement Learning代理。该方法通过生态有效的实验框架，促进了对LLMs可预测性和可靠性的提升。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "25 pages, 4 figures; v2: Added AFMR Acknowledgment",
      "pdf_url": "http://arxiv.org/pdf/2410.23242v2",
      "published_date": "2024-10-30 17:28:28 UTC",
      "updated_date": "2025-01-03 11:29:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:53:45.160228"
    },
    {
      "arxiv_id": "2411.00862v1",
      "title": "A Simple and Effective Temporal Grounding Pipeline for Basketball Broadcast Footage",
      "title_zh": "翻译失败",
      "authors": [
        "Levi Harris"
      ],
      "abstract": "We present a reliable temporal grounding pipeline for video-to-analytic\nalignment of basketball broadcast footage. Given a series of frames as input,\nour method quickly and accurately extracts time-remaining and quarter values\nfrom basketball broadcast scenes. Our work intends to expedite the development\nof large, multi-modal video datasets to train data-hungry video models in the\nsports action recognition domain. Our method aligns a pre-labeled corpus of\nplay-by-play annotations containing dense event annotations to video frames,\nenabling quick retrieval of labeled video segments. Unlike previous methods, we\nforgo the need to localize game clocks by fine-tuning an out-of-the-box object\ndetector to find semantic text regions directly. Our end-to-end approach\nimproves the generality of our work. Additionally, interpolation and\nparallelization techniques prepare our pipeline for deployment in a large\ncomputing cluster. All code is made publicly available.",
      "tldr_zh": "该论文提出了一种简单有效的临时定位（temporal grounding）管道，用于篮球广播视频的视频到分析对齐，快速准确地从视频帧中提取剩余时间和季度值，以加速大型多模态视频数据集的开发。不同于以往方法，该管道无需微调现成物体检测器，而是直接定位语义文本区域，实现端到端处理，并通过插值和并行化技术适配大型计算集群。实验结果显示，该方法提高了视频帧与预标记逐个播放注释的对齐效率，支持体育动作识别模型的训练，所有代码已公开可用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.00862v1",
      "published_date": "2024-10-30 17:27:44 UTC",
      "updated_date": "2024-10-30 17:27:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:53:55.999786"
    },
    {
      "arxiv_id": "2410.23234v1",
      "title": "EMOTION: Expressive Motion Sequence Generation for Humanoid Robots with In-Context Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Peide Huang",
        "Yuhan Hu",
        "Nataliya Nechyporenko",
        "Daehwa Kim",
        "Walter Talbott",
        "Jian Zhang"
      ],
      "abstract": "This paper introduces a framework, called EMOTION, for generating expressive\nmotion sequences in humanoid robots, enhancing their ability to engage in\nhumanlike non-verbal communication. Non-verbal cues such as facial expressions,\ngestures, and body movements play a crucial role in effective interpersonal\ninteractions. Despite the advancements in robotic behaviors, existing methods\noften fall short in mimicking the diversity and subtlety of human non-verbal\ncommunication. To address this gap, our approach leverages the in-context\nlearning capability of large language models (LLMs) to dynamically generate\nsocially appropriate gesture motion sequences for human-robot interaction. We\nuse this framework to generate 10 different expressive gestures and conduct\nonline user studies comparing the naturalness and understandability of the\nmotions generated by EMOTION and its human-feedback version, EMOTION++, against\nthose by human operators. The results demonstrate that our approach either\nmatches or surpasses human performance in generating understandable and natural\nrobot motions under certain scenarios. We also provide design implications for\nfuture research to consider a set of variables when generating expressive\nrobotic gestures.",
      "tldr_zh": "这篇论文介绍了 EMOTION 框架，利用大型语言模型 (LLMs) 的 in-context learning 能力，为人形机器人生成表达性动作序列，从而提升其在非语言沟通（如手势和身体动作）方面的表现。框架通过动态生成社交合适的动作序列，解决了现有方法在模仿人类多样性和细微性上的不足，并在用户研究中生成 10 种不同手势。结果显示，EMOTION 和其改进版 EMOTION++ 在某些场景下在自然性和可理解性上匹配或超过人类操作者，并为未来生成表达性机器人手势的研究提供了设计启示。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.23234v1",
      "published_date": "2024-10-30 17:22:45 UTC",
      "updated_date": "2024-10-30 17:22:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:54:10.349399"
    },
    {
      "arxiv_id": "2410.23230v2",
      "title": "Aligning Audio-Visual Joint Representations with an Agentic Workflow",
      "title_zh": "翻译失败",
      "authors": [
        "Shentong Mo",
        "Yibing Song"
      ],
      "abstract": "Visual content and accompanied audio signals naturally formulate a joint\nrepresentation to improve audio-visual (AV) related applications. While studies\ndevelop various AV representation learning frameworks, the importance of AV\ndata alignment is usually undermined for achieving high-quality representation.\nWe observe that an audio signal may contain background noise interference.\nAlso, non-synchronization may appear between audio and video streams. These\nnon-strict data alignment limits representation quality and downgrade\napplication performance. In this paper, we propose to improve AV joint\nrepresentations from a data-centric perspective by aligning audio signals to\nvisual data. Our alignment is conducted in an agentic workflow controlled by an\nLLM-based assistant named AVAgent. For each input AV data pair, our AVAgent\nuses a multi-modal LLM to convert audio and visual data into language\ndescriptions separately (i.e., tool use). Then, AVAgent reasons whether this\npaired data is aligned well and plans to edit the audio signal if needed (i.e.,\nplanning). The audio editing is executed by predefined actions that filter\nnoise or augment data. Moreover, we use a VLM to evaluate how modified audio\nsignals match the visual content and provide feedback to AVAgent (i.e.,\nreflection). The tool use, planning, and reflection steps operate cyclically to\nbecome an agentic workflow where audio signals are gradually aligned to visual\ncontent. To this end, existing methods can directly leverage the aligned AV\ndata via our agentic workflow to improve AV joint representations. The\nexperimental results comprehensively demonstrate the state-of-the-art\nperformance of the proposed approach against previous baselines in diverse\ndownstream tasks.",
      "tldr_zh": "该论文提出一种 agentic workflow，通过名为 AVAgent 的 LLM 基助手来对齐音频和视觉数据，从而提升 Audio-Visual (AV) 联合表示的质量。AVAgent 采用多模态 LLM 将音频和视觉数据转换为语言描述，进行对齐推理和规划（如过滤噪声或数据增强），并利用 VLM 评估修改后的音频匹配度，提供反馈，形成循环的 tool use、planning 和 reflection 过程。实验结果表明，该方法在多种下游任务中实现了 state-of-the-art 性能，显著优于现有基线。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.MM",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.23230v2",
      "published_date": "2024-10-30 17:18:53 UTC",
      "updated_date": "2024-10-31 04:20:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:54:20.790575"
    },
    {
      "arxiv_id": "2410.23223v1",
      "title": "COMAL: A Convergent Meta-Algorithm for Aligning LLMs with General Preferences",
      "title_zh": "COM",
      "authors": [
        "Yixin Liu",
        "Argyris Oikonomou",
        "Weiqiang Zheng",
        "Yang Cai",
        "Arman Cohan"
      ],
      "abstract": "Many alignment methods, including reinforcement learning from human feedback\n(RLHF), rely on the Bradley-Terry reward assumption, which is insufficient to\ncapture the full range of general human preferences. To achieve robust\nalignment with general preferences, we model the alignment problem as a\ntwo-player zero-sum game, where the Nash equilibrium policy guarantees a 50%\nwin rate against any competing policy. However, previous algorithms for finding\nthe Nash policy either diverge or converge to a Nash policy in a modified game,\neven in a simple synthetic setting, thereby failing to maintain the 50% win\nrate guarantee against all other policies. We propose a meta-algorithm,\nConvergent Meta Alignment Algorithm (COMAL), for language model alignment with\ngeneral preferences, inspired by convergent algorithms in game theory.\nTheoretically, we prove that our meta-algorithm converges to an exact Nash\npolicy in the last iterate. Additionally, our meta-algorithm is simple and can\nbe integrated with many existing methods designed for RLHF and preference\noptimization with minimal changes. Experimental results demonstrate the\neffectiveness of the proposed framework when combined with existing preference\npolicy optimization methods.",
      "tldr_zh": "该论文指出，现有的语言模型对齐方法如RLHF依赖Bradley-Terry奖励假设，无法充分捕捉一般人类偏好，因此提出将对齐问题建模为两玩家零和博弈，以Nash equilibrium策略确保模型对任何竞争策略的50%胜率。论文引入COMAL元算法，受游戏理论启发，能够在最后迭代收敛到精确的Nash策略，并易于与其他RLHF和偏好优化方法整合。实验结果证明，COMAL结合现有方法后显著提升了语言模型（LLMs）的对齐效果。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.GT"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.23223v1",
      "published_date": "2024-10-30 17:13:02 UTC",
      "updated_date": "2024-10-30 17:13:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:54:31.401767"
    },
    {
      "arxiv_id": "2410.23222v1",
      "title": "Partial Channel Dependence with Channel Masks for Time Series Foundation Models",
      "title_zh": "翻译失败",
      "authors": [
        "Seunghan Lee",
        "Taeyoung Park",
        "Kibok Lee"
      ],
      "abstract": "Recent advancements in foundation models have been successfully extended to\nthe time series (TS) domain, facilitated by the emergence of large-scale TS\ndatasets. However, previous efforts have primarily focused on designing model\narchitectures to address explicit heterogeneity among datasets such as various\nnumbers of channels, while often overlooking implicit heterogeneity such as\nvarying dependencies between channels. In this work, we introduce the concept\nof partial channel dependence (PCD), which enables a more sophisticated\nadjustment of channel dependencies based on dataset-specific information. To\nachieve PCD, we propose a channel mask that captures the relationships between\nchannels within a dataset using two key components: 1) a correlation matrix\nthat encodes relative dependencies between channels, and 2) domain parameters\nthat learn the absolute dependencies specific to each dataset, refining the\ncorrelation matrix. We validate the effectiveness of PCD across four tasks in\nTS including forecasting, classification, imputation, and anomaly detection,\nunder diverse settings, including few-shot and zero-shot scenarios with both TS\nfoundation models and single-task models. Code is available at\nhttps://github.com/seunghan96/CM.",
      "tldr_zh": "本研究针对时间序列（Time Series）基础模型，引入了部分通道依赖（Partial Channel Dependence, PCD）概念，以处理通道之间的隐性异质性，如不同依赖关系，而非仅关注显性异质性。作者提出了一种通道掩码（Channel Masks）机制，包括相关矩阵（Correlation Matrix）来编码通道的相对依赖，以及领域参数（Domain Parameters）来学习数据集特定的绝对依赖，从而细化通道关系。该方法在时间序列的预测、分类、插值和异常检测等四个任务上进行验证，尤其在少样本和零样本场景中，显著提升了基础模型和单任务模型的性能。该创新为时间序列建模提供了更精细的适应性，支持更有效的跨数据集应用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS Workshop on Time Series in the Age of Large Models, 2024.\n  Oral presentation",
      "pdf_url": "http://arxiv.org/pdf/2410.23222v1",
      "published_date": "2024-10-30 17:12:03 UTC",
      "updated_date": "2024-10-30 17:12:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:54:45.347908"
    },
    {
      "arxiv_id": "2411.09706v1",
      "title": "AI-Driven Feedback Loops in Digital Technologies: Psychological Impacts on User Behaviour and Well-Being",
      "title_zh": "翻译失败",
      "authors": [
        "Anthonette Adanyin"
      ],
      "abstract": "The rapid spread of digital technologies has produced data-driven feedback\nloops, wearable devices, social media networks, and mobile applications that\nshape user behavior, motivation, and mental well-being. While these systems\nencourage self-improvement and the development of healthier habits through\nreal-time feedback, they also create psychological risks such as technostress,\naddiction, and loss of autonomy. The present study also aims to investigate the\npositive and negative psychological consequences of feedback mechanisms on\nusers' behaviour and well-being. Employing a descriptive survey method, the\nstudy collected data from 200 purposely selected users to assess changes in\nbehaviour, motivation, and mental well-being related to health, social, and\nlifestyle applications. Results indicate that while feedback mechanisms\nfacilitate goal attainment and social interconnection through streaks and\nbadges, among other components, they also enhance anxiety, mental weariness,\nand loss of productivity due to actions that are considered feedback-seeking.\nFurthermore, test subjects reported that their actions are unconsciously shaped\nby app feedback, often at the expense of personal autonomy, while real-time\nfeedback minimally influences professional or social interactions. The study\nshows that data-driven feedback loops deliver not only motivational benefits\nbut also psychological challenges. To mitigate these risks, users should\nestablish boundaries regarding their use of technology to prevent burnout and\naddiction, while developers need to refine feedback mechanisms to reduce\ncognitive load and foster more inclusive participation. Future research should\nfocus on designing feedback mechanisms that promote well-being without\ncompromising individual freedom or increasing social comparison.",
      "tldr_zh": "这篇论文探讨了AI-Driven Feedback Loops在数字技术（如可穿戴设备和社交媒体）中对用户行为、动机和心理健康的双重影响，包括积极促进自我提升和健康习惯，以及负面风险如technostress、addiction和自主性丧失。研究采用描述性调查方法，收集了200名用户的资料，结果显示反馈机制有助于目标达成和社会连接，但也增加了焦虑、精神疲惫和生产力损失，并使用户行为无意识地受其影响。作者建议用户设定技术使用边界，开发者优化反馈机制以降低认知负荷，并呼吁未来研究设计更注重well-being的反馈系统，以平衡动机益处和心理挑战。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.09706v1",
      "published_date": "2024-10-30 17:11:30 UTC",
      "updated_date": "2024-10-30 17:11:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:54:57.125728"
    },
    {
      "arxiv_id": "2410.23219v1",
      "title": "DiaMond: Dementia Diagnosis with Multi-Modal Vision Transformers Using MRI and PET",
      "title_zh": "翻译失败",
      "authors": [
        "Yitong Li",
        "Morteza Ghahremani",
        "Youssef Wally",
        "Christian Wachinger"
      ],
      "abstract": "Diagnosing dementia, particularly for Alzheimer's Disease (AD) and\nfrontotemporal dementia (FTD), is complex due to overlapping symptoms. While\nmagnetic resonance imaging (MRI) and positron emission tomography (PET) data\nare critical for the diagnosis, integrating these modalities in deep learning\nfaces challenges, often resulting in suboptimal performance compared to using\nsingle modalities. Moreover, the potential of multi-modal approaches in\ndifferential diagnosis, which holds significant clinical importance, remains\nlargely unexplored. We propose a novel framework, DiaMond, to address these\nissues with vision Transformers to effectively integrate MRI and PET. DiaMond\nis equipped with self-attention and a novel bi-attention mechanism that\nsynergistically combine MRI and PET, alongside a multi-modal normalization to\nreduce redundant dependency, thereby boosting the performance. DiaMond\nsignificantly outperforms existing multi-modal methods across various datasets,\nachieving a balanced accuracy of 92.4% in AD diagnosis, 65.2% for AD-MCI-CN\nclassification, and 76.5% in differential diagnosis of AD and FTD. We also\nvalidated the robustness of DiaMond in a comprehensive ablation study. The code\nis available at https://github.com/ai-med/DiaMond.",
      "tldr_zh": "本文提出 DiaMond 框架，利用 Multi-Modal Vision Transformers 整合 MRI 和 PET 数据，以解决痴呆诊断（如 Alzheimer's Disease (AD) 和 frontotemporal dementia (FTD)）的复杂性问题，并克服现有多模态方法的性能不足。DiaMond 采用 self-attention 和创新的 bi-attention 机制，以及 multi-modal normalization 来减少冗余依赖，从而提升模态融合效果。在多个数据集上，该框架显著优于基线模型，实现 AD 诊断平衡准确率 92.4%、AD-MCI-CN 分类 65.2% 和 AD 与 FTD 鉴别诊断 76.5%。通过全面的消融研究，DiaMond 的鲁棒性得到验证，并已开源代码。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by IEEE/CVF Winter Conference on Applications of Computer\n  Vision (WACV) 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.23219v1",
      "published_date": "2024-10-30 17:11:00 UTC",
      "updated_date": "2024-10-30 17:11:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:55:09.606961"
    },
    {
      "arxiv_id": "2410.23214v2",
      "title": "Grounding by Trying: LLMs with Reinforcement Learning-Enhanced Retrieval",
      "title_zh": "翻译失败",
      "authors": [
        "Sheryl Hsu",
        "Omar Khattab",
        "Chelsea Finn",
        "Archit Sharma"
      ],
      "abstract": "The hallucinations of large language models (LLMs) are increasingly mitigated\nby allowing LLMs to search for information and to ground their answers in real\nsources. Unfortunately, LLMs often struggle with posing the right search\nqueries, especially when dealing with complex or otherwise indirect topics.\nObserving that LLMs can learn to search for relevant facts by $\\textit{trying}$\ndifferent queries and learning to up-weight queries that successfully produce\nrelevant results, we introduce $\\underline{Le}$arning to $\\underline{Re}$trieve\nby $\\underline{T}$rying (LeReT), a reinforcement learning framework that\nexplores search queries and uses preference-based optimization to improve their\nquality. LeReT can improve the absolute retrieval accuracy by up to 29% and the\ndownstream generator evaluations by 17%. The simplicity and flexibility of\nLeReT allows it to be applied to arbitrary off-the-shelf retrievers and makes\nit a promising technique for improving general LLM pipelines. Project website:\nhttp://sherylhsu.com/LeReT/.",
      "tldr_zh": "这篇论文针对大型语言模型 (LLMs) 在搜索查询上的不足，提出了一种名为 LeReT 的强化学习 (reinforcement learning) 框架，通过尝试不同查询并使用基于偏好的优化来提升检索质量。LeReT 允许 LLMs 学习优先选择能产生相关结果的查询，从而显著减少幻觉问题。实验结果显示，该框架将检索准确率提高高达 29%，并使下游生成器评估提升 17%。此外，LeReT 的简单性和灵活性使其适用于任意现成检索器，适用于改进一般 LLM 管道。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.23214v2",
      "published_date": "2024-10-30 17:02:54 UTC",
      "updated_date": "2024-10-31 01:34:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:55:20.625860"
    },
    {
      "arxiv_id": "2410.23208v2",
      "title": "Kinetix: Investigating the Training of General Agents through Open-Ended Physics-Based Control Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Michael Matthews",
        "Michael Beukman",
        "Chris Lu",
        "Jakob Foerster"
      ],
      "abstract": "While large models trained with self-supervised learning on offline datasets\nhave shown remarkable capabilities in text and image domains, achieving the\nsame generalisation for agents that act in sequential decision problems remains\nan open challenge. In this work, we take a step towards this goal by\nprocedurally generating tens of millions of 2D physics-based tasks and using\nthese to train a general reinforcement learning (RL) agent for physical\ncontrol. To this end, we introduce Kinetix: an open-ended space of\nphysics-based RL environments that can represent tasks ranging from robotic\nlocomotion and grasping to video games and classic RL environments, all within\na unified framework. Kinetix makes use of our novel hardware-accelerated\nphysics engine Jax2D that allows us to cheaply simulate billions of environment\nsteps during training. Our trained agent exhibits strong physical reasoning\ncapabilities in 2D space, being able to zero-shot solve unseen human-designed\nenvironments. Furthermore, fine-tuning this general agent on tasks of interest\nshows significantly stronger performance than training an RL agent *tabula\nrasa*. This includes solving some environments that standard RL training\ncompletely fails at. We believe this demonstrates the feasibility of large\nscale, mixed-quality pre-training for online RL and we hope that Kinetix will\nserve as a useful framework to investigate this further.",
      "tldr_zh": "该研究引入了Kinetix框架，通过程序生成数千万个开放式2D物理控制任务，来训练一个通用的强化学习（RL）代理。该框架利用新型硬件加速物理引擎Jax2D，支持大规模环境模拟，帮助代理在2D空间实现强大的物理推理能力，并能零样本（zero-shot）解决未见的人类设计环境。实验结果显示，微调这个预训练代理比从零开始（tabula rasa）训练的代理性能更强，甚至能处理标准RL训练失败的任务，证明了大规模混合质量预训练在在线RL中的可行性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ICLR 2025 Oral. The first two authors contributed equally. Project\n  page located at: https://kinetix-env.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2410.23208v2",
      "published_date": "2024-10-30 16:59:41 UTC",
      "updated_date": "2025-03-03 14:29:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:55:31.950792"
    },
    {
      "arxiv_id": "2410.23180v1",
      "title": "ReasoningRec: Bridging Personalized Recommendations and Human-Interpretable Explanations through LLM Reasoning",
      "title_zh": "ReasoningRec：通过LLM推理桥接个性化推荐与人类可解释解释",
      "authors": [
        "Millennium Bismay",
        "Xiangjue Dong",
        "James Caverlee"
      ],
      "abstract": "This paper presents ReasoningRec, a reasoning-based recommendation framework\nthat leverages Large Language Models (LLMs) to bridge the gap between\nrecommendations and human-interpretable explanations. In contrast to\nconventional recommendation systems that rely on implicit user-item\ninteractions, ReasoningRec employs LLMs to model users and items, focusing on\npreferences, aversions, and explanatory reasoning. The framework utilizes a\nlarger LLM to generate synthetic explanations for user preferences,\nsubsequently used to fine-tune a smaller LLM for enhanced recommendation\naccuracy and human-interpretable explanation. Our experimental study\ninvestigates the impact of reasoning and contextual information on personalized\nrecommendations, revealing that the quality of contextual and personalized data\nsignificantly influences the LLM's capacity to generate plausible explanations.\nEmpirical evaluations demonstrate that ReasoningRec surpasses state-of-the-art\nmethods by up to 12.5\\% in recommendation prediction while concurrently\nproviding human-intelligible explanations. The code is available here:\nhttps://github.com/millenniumbismay/reasoningrec.",
      "tldr_zh": "该论文提出了一种基于 Large Language Models (LLMs) 的推荐框架 ReasoningRec，用于桥接个性化推荐和人类可解释的解释。与传统依赖用户-物品隐式交互的系统不同，该框架利用 LLMs 建模用户偏好、厌恶及推理过程，通过一个较大 LLM 生成合成解释，并微调一个较小 LLM 以提升推荐准确性和解释质量。实验研究显示，上下文信息和个性化数据的质量对 LLM 生成可信解释的能力有显著影响。最终，ReasoningRec 在推荐预测上比最先进方法提升高达 12.5%，并提供人类易懂的解释。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "Large Language Model, Recommendation, Human-Interpretable Reasoning,\n  Personalization",
      "pdf_url": "http://arxiv.org/pdf/2410.23180v1",
      "published_date": "2024-10-30 16:37:04 UTC",
      "updated_date": "2024-10-30 16:37:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:55:43.539590"
    },
    {
      "arxiv_id": "2410.23329v1",
      "title": "Variable Resolution Sampling and Deep Learning Image Recovery for Accelerated Multi-Spectral MRI Near Metal Implants",
      "title_zh": "翻译失败",
      "authors": [
        "Azadeh Sharafi",
        "Nikolai J. Mickevicius",
        "Mehran Baboli",
        "Andrew S. Nencka",
        "Kevin M. Koch"
      ],
      "abstract": "Purpose: This study presents a variable resolution (VR) sampling and deep\nlearning reconstruction approach for multi-spectral MRI near metal implants,\naiming to reduce scan times while maintaining image quality. Background: The\nrising use of metal implants has increased MRI scans affected by metal\nartifacts. Multi-spectral imaging (MSI) reduces these artifacts but sacrifices\nacquisition efficiency. Methods: This retrospective study on 1.5T MSI knee and\nhip data from patients with metal hardware used a novel spectral undersampling\nscheme to improve acquisition efficiency by ~40%. U-Net-based deep learning\nmodels were trained for reconstruction. Image quality was evaluated using SSIM,\nPSNR, and RESI metrics. Results: Deep learning reconstructions of undersampled\nVR data (DL-VR) showed significantly higher SSIM and PSNR values (p<0.001)\ncompared to conventional reconstruction (CR-VR), with improved edge sharpness.\nEdge sharpness in DL-reconstructed images matched fully sampled references\n(p=0.5). Conclusion: This approach can potentially enhance MRI examinations\nnear metal implants by reducing scan times or enabling higher resolution.\nFurther prospective studies are needed to assess clinical value.",
      "tldr_zh": "这篇论文提出了一种可变分辨率（VR）采样和深度学习重建方法，用于加速多谱MRI扫描金属植入物附近，旨在减少扫描时间约40%同时保持图像质量。方法基于回顾性研究，使用1.5T MSI膝盖和髋关节数据，采用新型光谱欠采样方案并训练基于U-Net的深度学习模型进行图像重建。结果显示，深度学习重建的欠采样VR数据（DL-VR）在SSIM和PSNR指标上显著优于传统重建（CR-VR），且边缘清晰度与完全采样参考图像相当。该方法有望通过缩短扫描时间或提升分辨率来改善MRI检查，但需进一步的前瞻性研究验证临床价值。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "physics.med-ph"
      ],
      "primary_category": "eess.IV",
      "comment": "10 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.23329v1",
      "published_date": "2024-10-30 16:19:06 UTC",
      "updated_date": "2024-10-30 16:19:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:55:57.611638"
    },
    {
      "arxiv_id": "2410.23166v2",
      "title": "SciPIP: An LLM-based Scientific Paper Idea Proposer",
      "title_zh": "SciPIP：一种",
      "authors": [
        "Wenxiao Wang",
        "Lihui Gu",
        "Liye Zhang",
        "Yunxiang Luo",
        "Yi Dai",
        "Chen Shen",
        "Liang Xie",
        "Binbin Lin",
        "Xiaofei He",
        "Jieping Ye"
      ],
      "abstract": "The rapid advancement of large language models (LLMs) has opened new\npossibilities for automating the proposal of innovative scientific ideas. This\nprocess involves two key phases: literature retrieval and idea generation.\nHowever, existing approaches often fall short due to their reliance on\nkeyword-based search tools during the retrieval phase, which neglects crucial\nsemantic information and frequently results in incomplete retrieval outcomes.\nSimilarly, in the idea generation phase, current methodologies tend to depend\nsolely on the internal knowledge of LLMs or metadata from retrieved papers,\nthereby overlooking significant valuable insights contained within the full\ntexts. To address these limitations, we introduce SciPIP, an innovative\nframework designed to enhance the LLM-based proposal of scientific ideas\nthrough improvements in both literature retrieval and idea generation. Our\napproach begins with the construction of a comprehensive literature database\nthat supports advanced retrieval based not only on keywords but also on\nsemantics and citation relationships. This is complemented by the introduction\nof a multi-granularity retrieval algorithm aimed at ensuring more thorough and\nexhaustive retrieval results. For the idea generation phase, we propose a\ndual-path framework that effectively integrates both the content of retrieved\npapers and the extensive internal knowledge of LLMs. This integration\nsignificantly boosts the novelty, feasibility, and practical value of proposed\nideas. Our experiments, conducted across various domains such as natural\nlanguage processing and computer vision, demonstrate SciPIP's capability to\ngenerate a multitude of innovative and useful ideas. These findings underscore\nSciPIP's potential as a valuable tool for researchers seeking to advance their\nfields with groundbreaking concepts.",
      "tldr_zh": "这篇论文介绍了 SciPIP，一种基于 LLM 的框架，用于自动化提出创新科学论文想法，通过改进文献检索和想法生成过程来解决现有方法的局限性。SciPIP 构建了支持关键词、语义和引用关系的全面文献数据库，并引入多粒度检索算法，以确保更彻底的检索结果；在想法生成阶段，它采用双路径框架，结合检索论文全文内容和 LLM 的内部知识，提升想法的新颖性、可行性和实用价值。实验在自然语言处理和计算机视觉等领域验证了 SciPIP 的有效性，生成的创新想法数量和质量显著优于基线方法，为研究者提供了一个有价值的工具。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "20 pages, 5 figures, 12 tables. The code has been availabel:\n  https://github.com/cheerss/SciPIP",
      "pdf_url": "http://arxiv.org/pdf/2410.23166v2",
      "published_date": "2024-10-30 16:18:22 UTC",
      "updated_date": "2025-02-17 08:59:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:58:01.724104"
    },
    {
      "arxiv_id": "2410.23160v1",
      "title": "FlexTSF: A Universal Forecasting Model for Time Series with Variable Regularities",
      "title_zh": "翻译失败",
      "authors": [
        "Jingge Xiao",
        "Yile Chen",
        "Gao Cong",
        "Wolfgang Nejdl",
        "Simon Gottschalk"
      ],
      "abstract": "Developing a foundation model for time series forecasting across diverse\ndomains has attracted significant attention in recent years. Existing works\ntypically assume regularly sampled, well-structured data, limiting their\napplicability to more generalized scenarios where time series often contain\nmissing values, unequal sequence lengths, and irregular time intervals between\nmeasurements. To cover diverse domains and handle variable regularities, we\npropose FlexTSF, a universal time series forecasting model that possesses\nbetter generalization and natively support both regular and irregular time\nseries. FlexTSF produces forecasts in an autoregressive manner and incorporates\nthree novel designs: VT-Norm, a normalization strategy to ablate data domain\nbarriers, IVP Patcher, a patching module to learn representations from flexibly\nstructured time series, and LED attention, an attention mechanism to seamlessly\nintegrate these two and propagate forecasts with awareness of domain and time\ninformation. Experiments on 12 datasets show that FlexTSF outperforms\nstate-of-the-art forecasting models respectively designed for regular and\nirregular time series. Furthermore, after self-supervised pre-training, FlexTSF\nshows exceptional performance in both zero-shot and few-show settings for time\nseries forecasting.",
      "tldr_zh": "该研究提出FlexTSF，一种通用的时间序列预测模型，旨在处理多样域中的规则和不规则时间序列，包括缺失值、不等长序列和不规则间隔的问题。FlexTSF 通过自回归预测方式，引入VT-Norm归一化策略以消除数据域障碍、IVP Patcher模块以学习灵活结构表示，以及LED attention机制以整合域和时间信息进行高效预测。在12个数据集上的实验表明，FlexTSF 超越了现有针对规则和不规则序列的模型，并在自监督预训练后表现出色于零样本和少样本设置。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.23160v1",
      "published_date": "2024-10-30 16:14:09 UTC",
      "updated_date": "2024-10-30 16:14:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:56:20.462089"
    },
    {
      "arxiv_id": "2410.23159v1",
      "title": "Fourier Amplitude and Correlation Loss: Beyond Using L2 Loss for Skillful Precipitation Nowcasting",
      "title_zh": "翻译失败",
      "authors": [
        "Chiu-Wai Yan",
        "Shi Quan Foo",
        "Van Hoan Trinh",
        "Dit-Yan Yeung",
        "Ka-Hing Wong",
        "Wai-Kin Wong"
      ],
      "abstract": "Deep learning approaches have been widely adopted for precipitation\nnowcasting in recent years. Previous studies mainly focus on proposing new\nmodel architectures to improve pixel-wise metrics. However, they frequently\nresult in blurry predictions which provide limited utility to forecasting\noperations. In this work, we propose a new Fourier Amplitude and Correlation\nLoss (FACL) which consists of two novel loss terms: Fourier Amplitude Loss\n(FAL) and Fourier Correlation Loss (FCL). FAL regularizes the Fourier amplitude\nof the model prediction and FCL complements the missing phase information. The\ntwo loss terms work together to replace the traditional $L_2$ losses such as\nMSE and weighted MSE for the spatiotemporal prediction problem on signal-based\ndata. Our method is generic, parameter-free and efficient. Extensive\nexperiments using one synthetic dataset and three radar echo datasets\ndemonstrate that our method improves perceptual metrics and meteorology skill\nscores, with a small trade-off to pixel-wise accuracy and structural\nsimilarity. Moreover, to improve the error margin in meteorological skill\nscores such as Critical Success Index (CSI) and Fractions Skill Score (FSS), we\npropose and adopt the Regional Histogram Divergence (RHD), a distance metric\nthat considers the patch-wise similarity between signal-based imagery patterns\nwith tolerance to local transforms. Code is available at\nhttps://github.com/argenycw/FACL",
      "tldr_zh": "本文提出了一种新的损失函数Fourier Amplitude and Correlation Loss (FACL)，包括Fourier Amplitude Loss (FAL)和Fourier Correlation Loss (FCL)，旨在取代传统的L2损失（如MSE），以改善深度学习在降水预报中的模糊预测问题。FAL用于调节模型预测的傅立叶幅度，而FCL补充缺失的相位信息，使方法适用于时空信号数据，且具有通用性、无参数和高效性。实验在合成数据集和三个雷达回波数据集上显示，FACL显著提升了感知指标和气象技能分数（如Critical Success Index），尽管略微牺牲像素级准确性和结构相似性；此外，作者引入Regional Histogram Divergence (RHD)作为一种容忍局部变换的距离度量，以进一步优化技能分数评估。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by NeurIPS 2024. Camera-ready submission",
      "pdf_url": "http://arxiv.org/pdf/2410.23159v1",
      "published_date": "2024-10-30 16:12:56 UTC",
      "updated_date": "2024-10-30 16:12:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:56:33.202462"
    },
    {
      "arxiv_id": "2410.23156v2",
      "title": "VisualPredicator: Learning Abstract World Models with Neuro-Symbolic Predicates for Robot Planning",
      "title_zh": "翻译失败",
      "authors": [
        "Yichao Liang",
        "Nishanth Kumar",
        "Hao Tang",
        "Adrian Weller",
        "Joshua B. Tenenbaum",
        "Tom Silver",
        "João F. Henriques",
        "Kevin Ellis"
      ],
      "abstract": "Broadly intelligent agents should form task-specific abstractions that\nselectively expose the essential elements of a task, while abstracting away the\ncomplexity of the raw sensorimotor space. In this work, we present\nNeuro-Symbolic Predicates, a first-order abstraction language that combines the\nstrengths of symbolic and neural knowledge representations. We outline an\nonline algorithm for inventing such predicates and learning abstract world\nmodels. We compare our approach to hierarchical reinforcement learning,\nvision-language model planning, and symbolic predicate invention approaches, on\nboth in- and out-of-distribution tasks across five simulated robotic domains.\nResults show that our approach offers better sample complexity, stronger\nout-of-distribution generalization, and improved interpretability.",
      "tldr_zh": "本论文提出VisualPredicator框架，使用Neuro-Symbolic Predicates——一种结合符号和神经知识表示的第一阶抽象语言——来帮助智能代理形成任务特定的抽象，从而简化原始传感器空间的复杂性。该框架包括一个在线算法，用于发明这些谓词并学习抽象世界模型，以支持机器人规划。在五个模拟机器人领域中，与hierarchical reinforcement learning、vision-language model planning和symbolic predicate invention方法相比，VisualPredicator显示出更好的样本复杂度、更强的out-of-distribution generalization以及更高的interpretability。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "ICLR 2025 (Spotlight)",
      "pdf_url": "http://arxiv.org/pdf/2410.23156v2",
      "published_date": "2024-10-30 16:11:05 UTC",
      "updated_date": "2025-02-28 19:50:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:56:44.931559"
    },
    {
      "arxiv_id": "2411.00859v1",
      "title": "Profiling AI Models: Towards Efficient Computation Offloading in Heterogeneous Edge AI Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Juan Marcelo Parra-Ullauri",
        "Oscar Dilley",
        "Hari Madhukumar",
        "Dimitra Simeonidou"
      ],
      "abstract": "The rapid growth of end-user AI applications, such as computer vision and\ngenerative AI, has led to immense data and processing demands often exceeding\nuser devices' capabilities. Edge AI addresses this by offloading computation to\nthe network edge, crucial for future services in 6G networks. However, it faces\nchallenges such as limited resources during simultaneous offloads and the\nunrealistic assumption of homogeneous system architecture. To address these, we\npropose a research roadmap focused on profiling AI models, capturing data about\nmodel types, hyperparameters, and underlying hardware to predict resource\nutilisation and task completion time. Initial experiments with over 3,000 runs\nshow promise in optimising resource allocation and enhancing Edge AI\nperformance.",
      "tldr_zh": "本研究探讨了端用户 AI 应用（如计算机视觉和生成式 AI）的快速增长导致的数据处理需求超出设备能力的问题，Edge AI 通过 computation offloading 到网络边缘来缓解这一挑战，但面临资源限制和 heterogeneous systems 的复杂性。论文提出一个研究路线图，专注于 profiling AI models，包括模型类型、hyperparameters 和底层硬件信息，以预测资源利用和任务完成时间。初步实验超过 3000 次运行，显示出优化资源分配和提升 Edge AI 性能的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC",
        "cs.ET",
        "cs.NI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.00859v1",
      "published_date": "2024-10-30 16:07:14 UTC",
      "updated_date": "2024-10-30 16:07:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:56:56.367279"
    },
    {
      "arxiv_id": "2411.00858v1",
      "title": "DiabML: AI-assisted diabetes diagnosis method with meta-heuristic-based feature selection",
      "title_zh": "翻译失败",
      "authors": [
        "Vahideh Hayyolalam",
        "Öznur Özkasap"
      ],
      "abstract": "Diabetes is a chronic disorder identified by the high sugar level in the\nblood that can cause various different disorders such as kidney failure, heart\nattack, sightlessness, and stroke. Developments in the healthcare domain by\nfacilitating the early detection of diabetes risk can help not only caregivers\nbut also patients. AIoMT is a recent technology that integrates IoT and machine\nlearning methods to give services for medical purposes, which is a powerful\ntechnology for the early detection of diabetes. In this paper, we take\nadvantage of AIoMT and propose a hybrid diabetes risk detection method, DiabML,\nwhich uses the BWO algorithm and ML methods. BWO is utilized for feature\nselection and SMOTE for imbalance handling in the pre-processing procedure. The\nsimulation results prove the superiority of the proposed DiabML method compared\nto the existing works. DiabML achieves 86.1\\% classification accuracy by\nAdaBoost classifier outperforms the relevant existing methods.",
      "tldr_zh": "这篇论文提出了一种AI辅助的糖尿病诊断方法DiabML，利用AIoMT技术结合元启发式算法BWO进行特征选择，并采用SMOTE处理数据不平衡问题。DiabML整合机器学习方法，如AdaBoost分类器，来实现早期糖尿病风险检测。实验结果显示，该方法在分类准确率上达到86.1%，比现有方法表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "14J60 (Primary) 14F05, 14J26 (Secondary)"
      ],
      "primary_category": "cs.LG",
      "comment": "Proceedings of 14th Turkish Congress of Medical Informatics 16 (18),\n  19-30; https://turkmia.net/TurkMIA2023-Proceedings.pdf",
      "pdf_url": "http://arxiv.org/pdf/2411.00858v1",
      "published_date": "2024-10-30 16:06:58 UTC",
      "updated_date": "2024-10-30 16:06:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:57:07.736623"
    },
    {
      "arxiv_id": "2410.23144v1",
      "title": "Public Domain 12M: A Highly Aesthetic Image-Text Dataset with Novel Governance Mechanisms",
      "title_zh": "翻译失败",
      "authors": [
        "Jordan Meyer",
        "Nick Padgett",
        "Cullen Miller",
        "Laura Exline"
      ],
      "abstract": "We present Public Domain 12M (PD12M), a dataset of 12.4 million high-quality\npublic domain and CC0-licensed images with synthetic captions, designed for\ntraining text-to-image models. PD12M is the largest public domain image-text\ndataset to date, with sufficient size to train foundation models while\nminimizing copyright concerns. Through the Source.Plus platform, we also\nintroduce novel, community-driven dataset governance mechanisms that reduce\nharm and support reproducibility over time.",
      "tldr_zh": "我们介绍了 Public Domain 12M (PD12M)，一个包含 1240 万张高质量公共领域和 CC0 许可图像的数据集，这些图像配有合成标题，专为训练文本到图像模型而设计。该数据集是目前最大的公共领域图像文本数据集，其规模足以训练基础模型，同时最小化版权风险。通过 Source.Plus 平台，我们引入了创新的社区驱动治理机制，以减少潜在危害并支持数据集的长期可重复性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Project Page: https://source.plus/pd12m",
      "pdf_url": "http://arxiv.org/pdf/2410.23144v1",
      "published_date": "2024-10-30 15:59:05 UTC",
      "updated_date": "2024-10-30 15:59:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:58:45.763816"
    },
    {
      "arxiv_id": "2410.23143v2",
      "title": "The Good, the Bad, and the Ugly: The Role of AI Quality Disclosure in Lie Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Haimanti Bhattacharya",
        "Subhasish Dugar",
        "Sanchaita Hazra",
        "Bodhisattwa Prasad Majumder"
      ],
      "abstract": "We investigate how low-quality AI advisors, lacking quality disclosures, can\nhelp spread text-based lies while seeming to help people detect lies.\nParticipants in our experiment discern truth from lies by evaluating\ntranscripts from a game show that mimicked deceptive social media exchanges on\ntopics with objective truths. We find that when relying on low-quality advisors\nwithout disclosures, participants' truth-detection rates fall below their own\nabilities, which recovered once the AI's true effectiveness was revealed.\nConversely, high-quality advisor enhances truth detection, regardless of\ndisclosure. We discover that participants' expectations about AI capabilities\ncontribute to their undue reliance on opaque, low-quality advisors.",
      "tldr_zh": "本研究探讨了 AI 质量披露在谎言检测中的作用，特别关注低质量 AI 顾问如何在缺乏披露的情况下传播文本-based lies，同时误导人们以为其有助于检测谎言。实验中，参与者通过评估模拟欺骗性社交媒体交流的游戏节目记录来区分真假，结果显示依赖未披露低质量 AI 时，参与者的真相检测率低于自身能力，一旦揭示 AI 的真实有效性即恢复。相比之下，高质量 AI 顾问能提升真相检测表现，无论是否有披露。该研究揭示了参与者对 AI 能力的期望导致他们过度依赖不透明的低质量顾问，为 AI 透明性提供重要启示。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Corresponding author: Sanchaita Hazra. Order of the authors are in\n  alphabetical order of their last names. All authors contributed equally. The\n  manuscript is under review. 74 Pages, including appendices and references",
      "pdf_url": "http://arxiv.org/pdf/2410.23143v2",
      "published_date": "2024-10-30 15:58:05 UTC",
      "updated_date": "2025-02-01 19:14:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:57:32.994634"
    },
    {
      "arxiv_id": "2410.23137v1",
      "title": "Fair Division with Market Values",
      "title_zh": "翻译失败",
      "authors": [
        "Siddharth Barman",
        "Soroush Ebadian",
        "Mohamad Latifian",
        "Nisarg Shah"
      ],
      "abstract": "We introduce a model of fair division with market values, where indivisible\ngoods must be partitioned among agents with (additive) subjective valuations,\nand each good additionally has a market value. The market valuation can be\nviewed as a separate additive valuation that holds identically across all the\nagents. We seek allocations that are simultaneously fair with respect to the\nsubjective valuations and with respect to the market valuation.\n  We show that an allocation that satisfies stochastically-dominant\nenvy-freeness up to one good (SD-EF1) with respect to both the subjective\nvaluations and the market valuation does not always exist, but the weaker\nguarantee of EF1 with respect to the subjective valuations along with SD-EF1\nwith respect to the market valuation can be guaranteed. We also study a number\nof other guarantees such as Pareto optimality, EFX, and MMS. In addition, we\nexplore non-additive valuations and extend our model to cake-cutting. Along the\nway, we identify several tantalizing open questions.",
      "tldr_zh": "本论文引入了“公平分配”（fair division）模型，涉及将不可分割物品分配给代理人，每个代理人拥有主观（additive）估值，同时每个物品具有统一的“市场价值”（market value），目标是实现对主观估值和市场估值的双重公平。研究发现，虽然满足主观估值和市场估值的“随机主导性 envy-freeness up to one good”（SD-EF1）分配不总是存在，但可以保证主观估值的“envy-freeness up to one good”（EF1）结合市场估值的SD-EF1。论文还探讨了其他属性如“Pareto optimality”、EFX 和“MMS”，并扩展到非加和估值和“cake-cutting”场景，同时提出了几个开放问题。",
      "categories": [
        "cs.GT",
        "cs.AI"
      ],
      "primary_category": "cs.GT",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.23137v1",
      "published_date": "2024-10-30 15:52:15 UTC",
      "updated_date": "2024-10-30 15:52:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:58:58.215082"
    },
    {
      "arxiv_id": "2410.23132v3",
      "title": "Revisiting MAE pre-training for 3D medical image segmentation",
      "title_zh": "重新审视 MAE 预训练用于 3D 医学图像分割",
      "authors": [
        "Tassilo Wald",
        "Constantin Ulrich",
        "Stanislav Lukyanenko",
        "Andrei Goncharov",
        "Alberto Paderno",
        "Maximilian Miller",
        "Leander Maerkisch",
        "Paul F. Jäger",
        "Klaus Maier-Hein"
      ],
      "abstract": "Self-Supervised Learning (SSL) presents an exciting opportunity to unlock the\npotential of vast, untapped clinical datasets, for various downstream\napplications that suffer from the scarcity of labeled data. While SSL has\nrevolutionized fields like natural language processing and computer vision, its\nadoption in 3D medical image computing has been limited by three key pitfalls:\nSmall pre-training dataset sizes, architectures inadequate for 3D medical image\nanalysis, and insufficient evaluation practices. In this paper, we address\nthese issues by i) leveraging a large-scale dataset of 39k 3D brain MRI volumes\nand ii) using a Residual Encoder U-Net architecture within the state-of-the-art\nnnU-Net framework. iii) A robust development framework, incorporating 5\ndevelopment and 8 testing brain MRI segmentation datasets, allowed\nperformance-driven design decisions to optimize the simple concept of Masked\nAuto Encoders (MAEs) for 3D CNNs. The resulting model not only surpasses\nprevious SSL methods but also outperforms the strong nnU-Net baseline by an\naverage of approximately 3 Dice points setting a new state-of-the-art. Our code\nand models are made available here.",
      "tldr_zh": "这篇论文重新审视了Self-Supervised Learning (SSL) 在3D医疗图像分割中的应用，解决了数据集规模小、架构不适和评估不足的三大问题。研究团队使用了大规模的39k 3D脑MRI数据集，并采用Residual Encoder U-Net架构结合nnU-Net框架，对Masked Auto Encoders (MAEs) 进行了优化设计。实验结果显示，该模型不仅超越了之前的SSL方法，还比nnU-Net基线平均提高了约3个Dice points，设定了新标准，并公开了代码和模型。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2025. Update to Camera-Ready",
      "pdf_url": "http://arxiv.org/pdf/2410.23132v3",
      "published_date": "2024-10-30 15:42:59 UTC",
      "updated_date": "2025-04-04 15:51:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:59:09.501902"
    },
    {
      "arxiv_id": "2410.23126v2",
      "title": "Provably Optimal Memory Capacity for Modern Hopfield Models: Transformer-Compatible Dense Associative Memories as Spherical Codes",
      "title_zh": "现代 Hop",
      "authors": [
        "Jerry Yao-Chieh Hu",
        "Dennis Wu",
        "Han Liu"
      ],
      "abstract": "We study the optimal memorization capacity of modern Hopfield models and\nKernelized Hopfield Models (KHMs), a transformer-compatible class of Dense\nAssociative Memories. We present a tight analysis by establishing a connection\nbetween the memory configuration of KHMs and spherical codes from information\ntheory. Specifically, we treat the stored memory set as a specialized spherical\ncode. This enables us to cast the memorization problem in KHMs into a point\narrangement problem on a hypersphere. We show that the optimal capacity of KHMs\noccurs when the feature space allows memories to form an optimal spherical\ncode. This unique perspective leads to: (i) An analysis of how KHMs achieve\noptimal memory capacity, and identify corresponding necessary conditions.\nImportantly, we establish an upper capacity bound that matches the well-known\nexponential lower bound in the literature. This provides the first tight and\noptimal asymptotic memory capacity for modern Hopfield models. (ii) A\nsub-linear time algorithm $\\mathtt{U}\\text{-}\\mathtt{Hop}$+ to reach KHMs'\noptimal capacity. (iii) An analysis of the scaling behavior of the required\nfeature dimension relative to the number of stored memories. These efforts\nimprove both the retrieval capability of KHMs and the representation learning\nof corresponding transformers. Experimentally, we provide thorough numerical\nresults to back up theoretical findings.",
      "tldr_zh": "本论文研究了现代 Hopfield 模型和 Kernelized Hopfield Models (KHMs) 的最优记忆容量，将 KHMs 的记忆配置视为信息理论中的 spherical codes，从而将问题转化为高维球上的点排列优化。研究发现，KHMs 达到最优容量时需满足特定特征空间条件，并首次建立了匹配现有下界的上界，提供精确的渐进最优记忆容量。论文还提出一个亚线性时间算法 U-Hop+ 以实现该容量，并分析了特征维度与存储记忆数量的缩放行为，实验结果验证了这些理论发现并提升了 KHMs 的检索能力和 Transformer 的表示学习。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG",
        "cs.NE"
      ],
      "primary_category": "stat.ML",
      "comment": "Accepted at NeurIPS 2024. v2 fixed typos and expanded related work\n  discussion",
      "pdf_url": "http://arxiv.org/pdf/2410.23126v2",
      "published_date": "2024-10-30 15:35:51 UTC",
      "updated_date": "2024-10-31 16:02:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:59:21.787283"
    },
    {
      "arxiv_id": "2410.23118v1",
      "title": "Teaching a Language Model to Distinguish Between Similar Details using a Small Adversarial Training Set",
      "title_zh": "翻译失败",
      "authors": [
        "Chris Achard"
      ],
      "abstract": "Language models can achieve high accuracy on natural language tasks such as\nNLI, but performance suffers on manually created adversarial examples. We\ninvestigate the performance of a language model trained on the Stanford Natural\nLanguage Inference (SNLI) corpus on a manually created adversarial test set. We\nthen improve the model's performance by fine tuning the model on a small,\nmanually created adversarial training set, designed to help the language model\nto learn to differentiate between similar words and phrases in the data. We\nshow an increase in accuracy on the adversarial test set (+ 13%) while still\nmaintaining good performance on the original NLI task. We also show an increase\nin accuracy from 91.2% to 92.9% on the most similar contradictions in the SNLI\ntest set (as judged by cosine similarity).",
      "tldr_zh": "这篇论文探讨了语言模型在 NLI 任务上虽有高准确率，但对手动创建的对抗示例性能较差的问题，通过在小规模手动创建的对抗训练集上微调模型，帮助语言模型更好地区分相似单词和短语。实验结果显示，微调后模型在对抗测试集上的准确率提高了 13%，同时保持了原 NLI 任务的良好性能。此外，在 SNLI 测试集中最相似的矛盾示例上，准确率从 91.2% 提升到 92.9%，证明了这种方法能有效提升模型的鲁棒性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.23118v1",
      "published_date": "2024-10-30 15:27:55 UTC",
      "updated_date": "2024-10-30 15:27:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:59:35.265213"
    },
    {
      "arxiv_id": "2410.23114v2",
      "title": "Unified Triplet-Level Hallucination Evaluation for Large Vision-Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Junjie Wu",
        "Tsz Ting Chung",
        "Kai Chen",
        "Dit-Yan Yeung"
      ],
      "abstract": "Despite the outstanding performance in vision-language reasoning, Large\nVision-Language Models (LVLMs) might generate hallucinated contents that do not\nexist in the given image. Most existing LVLM hallucination benchmarks are\nconstrained to evaluate the object-related hallucinations. However, the\npotential hallucination on the relations between two objects, i.e., relation\nhallucination, still lacks investigation. To remedy that, in this paper we\ndesign a unified framework to measure object and relation hallucination in\nLVLMs simultaneously. The core idea of our framework is to conduct\nhallucination evaluation on (object, relation, object) triplets extracted from\nLVLMs' responses, and thus, could be easily generalized to different\nvision-language tasks. Based on our framework, we further introduce Tri-HE, a\nnovel Triplet-level Hallucination Evaluation benchmark which can be used to\nstudy both object and relation hallucination at the same time. We conduct\ncomprehensive evaluations on Tri-HE and observe that the relation hallucination\nissue is even more serious than object hallucination among existing LVLMs,\nhighlighting a previously neglected problem towards reliable LVLMs. Moreover,\nbased on our findings, we design a simple yet effective training-free approach\nto mitigate hallucinations for LVLMs, with which, we exceed all open-sourced\ncounterparts on Tri-HE, achieving comparable performance with the powerful\nGPT-4V. Our dataset and code for the reproduction of our experiments are\navailable publicly at https://github.com/wujunjie1998/Tri-HE.",
      "tldr_zh": "这项研究针对大型视觉语言模型 (LVLMs) 在视觉语言推理中产生的幻觉问题，提出一个统一的框架，用于同时评估对象 hallucination 和关系 hallucination，通过从模型响应中提取的 (object, relation, object) 三元组进行评估。基于此框架，他们引入了 Tri-HE 基准，这是一个新型的三元组级 hallucination 评估工具，能够同时研究对象和关系幻觉。实验结果显示，现有的 LVLMs 中关系 hallucination 问题比对象 hallucination 更严重，突显了这一被忽略的可靠性挑战。此外，研究团队设计了一个简单有效的无训练方法来缓解这些幻觉，在 Tri-HE 基准上超越所有开源模型，并与 GPT-4V 性能相当。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Project Page: https://kaichen1998.github.io/projects/tri-he/",
      "pdf_url": "http://arxiv.org/pdf/2410.23114v2",
      "published_date": "2024-10-30 15:25:06 UTC",
      "updated_date": "2024-11-03 09:35:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:59:45.956505"
    },
    {
      "arxiv_id": "2410.23111v6",
      "title": "Exploring Gradient Subspaces: Addressing and Overcoming LoRA's Limitations in Federated Fine-Tuning of Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Navyansh Mahla",
        "Kshitij Sharad Jadhav",
        "Ganesh Ramakrishnan"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities across\nvarious domains, particularly in task generalization for both text and vision\ndata. While fine-tuning these models can significantly enhance their\nperformance on specific downstream tasks, it often requires high-quality data\nthat cannot be shared due to privacy concerns. Federated Learning (FL) offers a\npromising solution for collaborative training without direct data sharing.\nHowever, many parameter-efficient fine-tuning strategies for LLMs in FL,\nparticularly those based on Low-Rank Adaptation (LoRA), face limitations. In\nthis paper, we critically analyze the convergence and performance guarantees of\npopular FL frameworks utilizing LoRA, highlighting its suboptimal nature due to\nconstrained subspace learning of low-rank matrices. This limitation hinders\neffective fine-tuning of LLMs in federated settings. Through rigorous\nanalytical and empirical evaluations, we demonstrate that direct weight\naveraging outperforms LoRA-based strategies, leading to superior performance\nfor fine-tuned models. Our comprehensive comparison unmasks inefficiencies in\nLoRA approaches and underscores the advantages of direct weight aggregation. We\nextend our analysis to low-rank gradient-based optimizers, such as GaLore, used\nduring local training steps. Our findings show that GaLore along with\ndirect-weight aggregation is a more effective approach, outperforming federated\nLoRA methods like FlexLoRA and FFA-LoRA across both text and image modalities.\nWhile privacy remains paramount in FL discourse, our focus is on assessing\nperformance outcomes of federated fine-tuned models and evaluating various FL\nframeworks from both theoretical and empirical perspectives. Our findings\nadvocate reassessing the reliance on LoRA within FL contexts, paving the way\nfor more efficient training methodologies.",
      "tldr_zh": "这篇论文探讨了在联邦学习 (FL) 中微调大型语言模型 (LLMs) 时，Low-Rank Adaptation (LoRA) 的局限性，特别是其在低秩矩阵子空间学习上导致的收敛和性能问题。作者通过理论分析和实证评估比较了直接权重平均与 LoRA 策略，发现前者能显著提升模型性能，并扩展到低秩梯度优化器如 GaLore，与直接权重聚合结合时更有效。实验结果显示，这种方法在文本和图像任务上优于 FlexLoRA 和 FFA-LoRA，主张重新评估 LoRA 在 FL 框架中的依赖，以推动更高效的训练方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.23111v6",
      "published_date": "2024-10-30 15:23:44 UTC",
      "updated_date": "2025-01-14 06:25:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:59:57.875828"
    },
    {
      "arxiv_id": "2410.23108v1",
      "title": "Controllable Game Level Generation: Assessing the Effect of Negative Examples in GAN Models",
      "title_zh": "可控游戏关卡生成：评估",
      "authors": [
        "Mahsa Bazzaz",
        "Seth Cooper"
      ],
      "abstract": "Generative Adversarial Networks (GANs) are unsupervised models designed to\nlearn and replicate a target distribution. The vanilla versions of these models\ncan be extended to more controllable models. Conditional Generative Adversarial\nNetworks (CGANs) extend vanilla GANs by conditioning both the generator and\ndiscriminator on some additional information (labels). Controllable models\nbased on complementary learning, such as Rumi-GAN, have been introduced.\nRumi-GANs leverage negative examples to enhance the generator's ability to\nlearn positive examples. We evaluate the performance of two controllable GAN\nvariants, CGAN and Rumi-GAN, in generating game levels targeting specific\nconstraints of interest: playability and controllability. This evaluation is\nconducted under two scenarios: with and without the inclusion of negative\nexamples. The goal is to determine whether incorporating negative examples\nhelps the GAN models avoid generating undesirable outputs. Our findings\nhighlight the strengths and weaknesses of each method in enforcing the\ngeneration of specific conditions when generating outputs based on given\npositive and negative examples.",
      "tldr_zh": "这篇论文评估了在可控游戏关卡生成中，负面例子对 GAN 模型的影响，焦点是比较 Conditional Generative Adversarial Networks (CGANs) 和 Rumi-GAN 的性能。研究通过实验测试了两种模型在生成满足可玩性和可控性约束的游戏关卡时，是否能从正面和负面例子中受益，特别是避免生成不理想的输出。结果表明，加入负面例子能提升模型的生成质量，但也暴露了每种方法的优势（如 Rumi-GAN 的互补学习）和弱点（如潜在的过度约束）。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.23108v1",
      "published_date": "2024-10-30 15:18:26 UTC",
      "updated_date": "2024-10-30 15:18:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:00:09.166300"
    },
    {
      "arxiv_id": "2410.23107v1",
      "title": "Decoupling Semantic Similarity from Spatial Alignment for Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Tassilo Wald",
        "Constantin Ulrich",
        "Gregor Köhler",
        "David Zimmerer",
        "Stefan Denner",
        "Michael Baumgartner",
        "Fabian Isensee",
        "Priyank Jaini",
        "Klaus H. Maier-Hein"
      ],
      "abstract": "What representation do deep neural networks learn? How similar are images to\neach other for neural networks? Despite the overwhelming success of deep\nlearning methods key questions about their internal workings still remain\nlargely unanswered, due to their internal high dimensionality and complexity.\nTo address this, one approach is to measure the similarity of activation\nresponses to various inputs. Representational Similarity Matrices (RSMs)\ndistill this similarity into scalar values for each input pair. These matrices\nencapsulate the entire similarity structure of a system, indicating which input\nleads to similar responses. While the similarity between images is ambiguous,\nwe argue that the spatial location of semantic objects does neither influence\nhuman perception nor deep learning classifiers. Thus this should be reflected\nin the definition of similarity between image responses for computer vision\nsystems. Revisiting the established similarity calculations for RSMs we expose\ntheir sensitivity to spatial alignment. In this paper, we propose to solve this\nthrough semantic RSMs, which are invariant to spatial permutation. We measure\nsemantic similarity between input responses by formulating it as a set-matching\nproblem. Further, we quantify the superiority of semantic RSMs over\nspatio-semantic RSMs through image retrieval and by comparing the similarity\nbetween representations to the similarity between predicted class\nprobabilities.",
      "tldr_zh": "这篇论文探讨了深度神经网络中图像表示的相似性问题，指出传统 Representational Similarity Matrices (RSMs) 对空间对齐过于敏感，这不利于准确捕捉语义信息。作者提出 semantic RSMs 作为一种新方法，将相似性表述为集合匹配问题，从而使它对空间排列保持不变。实验结果显示，semantic RSMs 在图像检索任务中优于传统 RSMs，并更好地反映了神经网络表示与预测类概率的相似性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at NeurIPS2024",
      "pdf_url": "http://arxiv.org/pdf/2410.23107v1",
      "published_date": "2024-10-30 15:17:58 UTC",
      "updated_date": "2024-10-30 15:17:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:00:21.368688"
    },
    {
      "arxiv_id": "2410.23101v2",
      "title": "Guided Game Level Repair via Explainable AI",
      "title_zh": "翻译失败",
      "authors": [
        "Mahsa Bazzaz",
        "Seth Cooper"
      ],
      "abstract": "Procedurally generated levels created by machine learning models can be\nunsolvable without further editing. Various methods have been developed to\nautomatically repair these levels by enforcing hard constraints during the\npost-processing step. However, as levels increase in size, these\nconstraint-based repairs become increasingly slow. This paper proposes using\nexplainability methods to identify specific regions of a level that contribute\nto its unsolvability. By assigning higher weights to these regions,\nconstraint-based solvers can prioritize these problematic areas, enabling more\nefficient repairs. Our results, tested across three games, demonstrate that\nthis approach can help to repair procedurally generated levels faster.",
      "tldr_zh": "本文提出了一种利用 Explainable AI 指导游戏关卡修复的方法，以解决机器学习生成的程序关卡可能不可解的问题。传统基于硬约束的修复方法在关卡规模增大时效率低下，而该方法通过解释性 AI 识别出导致不可解的具体区域，并为这些区域分配更高权重，使约束求解器优先处理问题部分。实验结果显示，在三个游戏上测试，这种方法显著加快了关卡修复过程。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.23101v2",
      "published_date": "2024-10-30 15:12:36 UTC",
      "updated_date": "2024-11-04 16:26:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:00:38.460047"
    },
    {
      "arxiv_id": "2410.23099v1",
      "title": "Comparative Analysis of Demonstration Selection Algorithms for LLM In-Context Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Dong Shu",
        "Mengnan Du"
      ],
      "abstract": "In-context learning can help Large Language Models (LLMs) to adapt new tasks\nwithout additional training. However, this performance heavily depends on the\nquality of the demonstrations, driving research into effective demonstration\nselection algorithms to optimize this process. These algorithms assist users in\nselecting the best $k$ input-label pairs (demonstration examples) based on a\ngiven test input, enabling LLMs to in-context learn the relationship between\nthe provided examples and the test inputs. Despite all the proposed\ndemonstration selection algorithms, their efficiency and effectiveness remain\nunclear. This lack of clarity make it difficult to apply these algorithms in\nreal-world scenarios and poses challenges for future research aimed at\ndeveloping improved methods. This paper revisits six proposed algorithms,\nevaluating them on five datasets from both efficiency and effectiveness\nperspectives. Our experiments reveal significant variations in algorithm\nperformance across different tasks, with some methods struggling to outperform\nrandom selection in certain scenarios. We also find that increasing the number\nof demonstrations does not always lead to better performance, and that there\nare often trade-offs between accuracy and computational efficiency. Our code is\navailable at https://github.com/Tizzzzy/Demonstration_Selection_Overview.",
      "tldr_zh": "这篇论文对用于 LLM In-Context Learning 的 demonstration selection algorithms 进行了比较分析，评估了六种算法在五个数据集上的效率和有效性。研究发现，这些算法的性能因任务而异，有些方法在特定场景下甚至不如随机选择。作者还观察到，增加演示示例数量并不总是提升表现，且算法之间存在准确性和计算效率的权衡。代码已在 GitHub 上提供，以支持进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "6 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.23099v1",
      "published_date": "2024-10-30 15:11:58 UTC",
      "updated_date": "2024-10-30 15:11:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:00:44.891855"
    },
    {
      "arxiv_id": "2411.00856v1",
      "title": "AI in Investment Analysis: LLMs for Equity Stock Ratings",
      "title_zh": "人工智能在",
      "authors": [
        "Kassiani Papasotiriou",
        "Srijan Sood",
        "Shayleen Reynolds",
        "Tucker Balch"
      ],
      "abstract": "Investment Analysis is a cornerstone of the Financial Services industry. The\nrapid integration of advanced machine learning techniques, particularly Large\nLanguage Models (LLMs), offers opportunities to enhance the equity rating\nprocess. This paper explores the application of LLMs to generate multi-horizon\nstock ratings by ingesting diverse datasets. Traditional stock rating methods\nrely heavily on the expertise of financial analysts, and face several\nchallenges such as data overload, inconsistencies in filings, and delayed\nreactions to market events. Our study addresses these issues by leveraging LLMs\nto improve the accuracy and consistency of stock ratings. Additionally, we\nassess the efficacy of using different data modalities with LLMs for the\nfinancial domain.\n  We utilize varied datasets comprising fundamental financial, market, and news\ndata from January 2022 to June 2024, along with GPT-4-32k (v0613) (with a\ntraining cutoff in Sep. 2021 to prevent information leakage). Our results show\nthat our benchmark method outperforms traditional stock rating methods when\nassessed by forward returns, specially when incorporating financial\nfundamentals. While integrating news data improves short-term performance,\nsubstituting detailed news summaries with sentiment scores reduces token use\nwithout loss of performance. In many cases, omitting news data entirely\nenhances performance by reducing bias.\n  Our research shows that LLMs can be leveraged to effectively utilize large\namounts of multimodal financial data, as showcased by their effectiveness at\nthe stock rating prediction task. Our work provides a reproducible and\nefficient framework for generating accurate stock ratings, serving as a\ncost-effective alternative to traditional methods. Future work will extend to\nlonger timeframes, incorporate diverse data, and utilize newer models for\nenhanced insights.",
      "tldr_zh": "本研究探讨了在投资分析中应用大型语言模型（LLMs）来生成多时间horizon的股票评级，旨在解决传统方法面临的挑战，如数据过载、一致性问题和市场事件延迟反应。研究利用从2022年1月到2024年6月的财务、市场和新闻数据，与GPT-4-32k模型结合，证明LLMs方法在基于未来回报的评估中比传统方法提升了准确性，尤其当整合财务基础数据时。结果显示，加入新闻数据可改善短期表现，但使用情感分数代替详细摘要能减少令牌使用而不影响性能，甚至在某些情况下省略新闻数据可降低偏差并提升整体效果。该框架提供了一个可重现且成本有效的股票评级替代方案，并为未来扩展到更长时段和更多数据奠定基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-fin.CP",
        "68T50, 91G60 (Primary) 68T07 (Secondary)",
        "I.2.7"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages, 5 figures, ICAIF24: 5th ACM International Conference on AI\n  in Finance",
      "pdf_url": "http://arxiv.org/pdf/2411.00856v1",
      "published_date": "2024-10-30 15:06:57 UTC",
      "updated_date": "2024-10-30 15:06:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:00:57.548164"
    },
    {
      "arxiv_id": "2410.23086v1",
      "title": "From Hype to Reality: The Road Ahead of Deploying DRL in 6G Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Haiyuan Li",
        "Hari Madhukumar",
        "Peizheng Li",
        "Yiran Teng",
        "Shuangyi Yan",
        "Dimitra Simeonidou"
      ],
      "abstract": "The industrial landscape is rapidly evolving with the advent of 6G\napplications, which demand massive connectivity, high computational capacity,\nand ultra-low latency. These requirements present new challenges, which can no\nlonger be efficiently addressed by conventional strategies. In response, this\narticle underscores the transformative potential of Deep Reinforcement Learning\n(DRL) for 6G, highlighting its advantages over classic machine learning\nsolutions in meeting the demands of 6G. The necessity of DRL is further\nvalidated through three DRL applications in an end-to-end communication\nprocedure, including wireless access control, baseband function placement, and\nnetwork slicing coordination. However, DRL-based network management initiatives\nare far from mature. We extend the discussion to identify the challenges of\napplying DRL in practical networks and explore potential solutions along with\ntheir respective limitations. In the end, these insights are validated through\na practical DRL deployment in managing network slices on the testbed.",
      "tldr_zh": "该研究探讨了深度强化学习(DRL)在6G网络中的实际部署前景，强调DRL如何比传统机器学习方案更有效地应对6G应用的需求，如海量连接、高计算能力和超低延迟。文章通过三个端到端通信应用案例——无线访问控制(baseband function placement)、基带功能放置和网络切片协调——验证了DRL的潜力。作者进一步分析了DRL在实际网络中面临的挑战，包括部署复杂性和局限性，并提出潜在解决方案，最后通过在测试床上的实际DRL部署进行验证，为6G网络管理提供了可行路径。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.DC",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.23086v1",
      "published_date": "2024-10-30 15:02:54 UTC",
      "updated_date": "2024-10-30 15:02:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:01:09.025809"
    },
    {
      "arxiv_id": "2410.23085v3",
      "title": "S3PT: Scene Semantics and Structure Guided Clustering to Boost Self-Supervised Pre-Training for Autonomous Driving",
      "title_zh": "S3PT：场景语义和结构引导聚类以提升自动驾驶的自监督预训练",
      "authors": [
        "Maciej K. Wozniak",
        "Hariprasath Govindarajan",
        "Marvin Klingner",
        "Camille Maurice",
        "B Ravi Kiran",
        "Senthil Yogamani"
      ],
      "abstract": "Recent self-supervised clustering-based pre-training techniques like DINO and\nCribo have shown impressive results for downstream detection and segmentation\ntasks. However, real-world applications such as autonomous driving face\nchallenges with imbalanced object class and size distributions and complex\nscene geometries. In this paper, we propose S3PT a novel scene semantics and\nstructure guided clustering to provide more scene-consistent objectives for\nself-supervised training. Specifically, our contributions are threefold: First,\nwe incorporate semantic distribution consistent clustering to encourage better\nrepresentation of rare classes such as motorcycles or animals. Second, we\nintroduce object diversity consistent spatial clustering, to handle imbalanced\nand diverse object sizes, ranging from large background areas to small objects\nsuch as pedestrians and traffic signs. Third, we propose a depth-guided spatial\nclustering to regularize learning based on geometric information of the scene,\nthus further refining region separation on the feature level. Our learned\nrepresentations significantly improve performance in downstream semantic\nsegmentation and 3D object detection tasks on the nuScenes, nuImages, and\nCityscapes datasets and show promising domain translation properties.",
      "tldr_zh": "该论文提出 S3PT，一种基于场景语义和结构引导的聚类方法，用于提升自监督预训练（self-supervised pre-training）在自动驾驶领域的性能，解决现有技术如 DINO 和 Cribo 在处理物体类别不平衡、物体大小多样性和复杂场景几何方面的挑战。S3PT 的主要贡献包括语义分布一致聚类以改善稀有类别的表示（如摩托车或动物）、对象多样性一致空间聚类处理不同物体大小，以及深度引导空间聚类利用场景几何信息优化特征级区域分离。在 nuScenes、nuImages 和 Cityscapes 数据集上，S3PT 显著提升了下游语义分割和 3D 物体检测任务的性能，并展示了出色的领域转换特性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted for WACV 2025 (Oral)",
      "pdf_url": "http://arxiv.org/pdf/2410.23085v3",
      "published_date": "2024-10-30 15:00:06 UTC",
      "updated_date": "2025-01-24 10:46:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:02:58.253727"
    },
    {
      "arxiv_id": "2410.23082v1",
      "title": "An Event-Based Digital Compute-In-Memory Accelerator with Flexible Operand Resolution and Layer-Wise Weight/Output Stationarity",
      "title_zh": "翻译失败",
      "authors": [
        "Nicolas Chauvaux",
        "Adrian Kneip",
        "Christoph Posch",
        "Kofi Makinwa",
        "Charlotte Frenkel"
      ],
      "abstract": "Compute-in-memory (CIM) accelerators for spiking neural networks (SNNs) are\npromising solutions to enable $\\mu$s-level inference latency and ultra-low\nenergy in edge vision applications. Yet, their current lack of flexibility at\nboth the circuit and system levels prevents their deployment in a wide range of\nreal-life scenarios. In this work, we propose a novel digital CIM macro that\nsupports arbitrary operand resolution and shape, with a unified CIM storage for\nweights and membrane potentials. These circuit-level techniques enable a hybrid\nweight- and output-stationary dataflow at the system level to maximize operand\nreuse, thereby minimizing costly on- and off-chip data movements during the SNN\nexecution. Measurement results of a fabricated FlexSpIM prototype in 40-nm CMOS\ndemonstrate a 2$\\times$ increase in bit-normalized energy efficiency compared\nto prior fixed-precision digital CIM-SNNs, while providing resolution\nreconfiguration with bitwise granularity. Our approach can save up to 90%\nenergy in large-scale systems, while reaching a state-of-the-art classification\naccuracy of 95.8% on the IBM DVS gesture dataset.",
      "tldr_zh": "该论文提出了一种基于事件的数字计算存储 (CIM) 加速器，用于脉冲神经网络 (SNNs)，支持任意操作数分辨率和形状，并采用统一的 CIM 存储以实现混合权重和输出静态数据流，从而最大化操作数重用并减少数据移动。创新点包括电路级灵活性设计和系统级混合数据流策略，适用于边缘视觉应用。实验结果显示，在 40-nm CMOS 制造的 FlexSpIM 原型中，位归一化能量效率比先前固定精度模型提高了 2 倍，可节省高达 90% 的系统能量，并在 IBM DVS 手势数据集上实现 95.8% 的分类准确率。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "B.2.0; B.3.0; B.6.0; B.7.0; C.3"
      ],
      "primary_category": "cs.AR",
      "comment": "5 pages, 7 figures, submitted to IEEE ISCAS 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.23082v1",
      "published_date": "2024-10-30 14:55:13 UTC",
      "updated_date": "2024-10-30 14:55:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:01:33.009845"
    },
    {
      "arxiv_id": "2410.23079v1",
      "title": "BUZZ: Beehive-structured Sparse KV Cache with Segmented Heavy Hitters for Efficient LLM Inference",
      "title_zh": "翻译失败",
      "authors": [
        "Junqi Zhao",
        "Zhijin Fang",
        "Shu Li",
        "Shaohui Yang",
        "Shichao He"
      ],
      "abstract": "Large language models (LLMs) are essential in natural language processing but\noften struggle with inference speed and computational efficiency, limiting\nreal-time deployment. The key-value (KV) cache mechanism reduces computational\noverhead in transformer models, but challenges in maintaining contextual\nunderstanding remain. In this paper, we propose BUZZ, a novel KV caching\nalgorithm that leverages structured contextual information to minimize cache\nmemory usage while enhancing inference speed. BUZZ employs a beehive-structured\nsparse cache, incorporating a sliding window to capture recent information and\ndynamically segmenting historical tokens into chunks to prioritize important\ntokens in local neighborhoods. We evaluate BUZZ on four real-world datasets:\nCNN/Daily Mail, XSUM, Wikitext, and 10-QA. Our results demonstrate that BUZZ\n(1) reduces cache memory usage by $\\textbf{2.5}\\times$ in LLM inference while\nmaintaining over 99% accuracy in long-text summarization, and (2) surpasses\nstate-of-the-art performance in multi-document question answering by\n$\\textbf{7.69%}$ under the same memory limit, where full cache methods\nencounter out-of-memory issues. Additionally, BUZZ achieves significant\ninference speedup with a $\\log{n}$ time complexity. The code is available at\nhttps://github.com/JunqiZhao888/buzz-llm.",
      "tldr_zh": "该论文提出 BUZZ，一种创新的 KV cache 算法，用于提升 LLM 在推理过程中的效率，旨在解决传统缓存机制在内存使用和上下文理解方面的挑战。BUZZ 采用 beehive-structured sparse cache 结构，结合滑动窗口捕获最近信息，并动态分段历史 token 以优先处理局部邻域的重磅 token，从而最小化缓存内存。实验结果显示，BUZZ 在 CNN/Daily Mail、XSUM、Wikitext 和 10-QA 数据集上减少缓存内存使用 2.5 倍，同时保持超过 99% 的准确率，并在多文档问答任务中比最先进方法提高 7.69%，实现 log(n) 时间复杂度的推理加速。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.23079v1",
      "published_date": "2024-10-30 14:53:37 UTC",
      "updated_date": "2024-10-30 14:53:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:01:45.401927"
    },
    {
      "arxiv_id": "2410.23072v1",
      "title": "CNN Explainability with Multivector Tucker Saliency Maps for Self-Supervised Models",
      "title_zh": "翻译失败",
      "authors": [
        "Aymene Mohammed Bouayed",
        "Samuel Deslauriers-Gauthier",
        "Adrian Iaccovelli",
        "David Naccache"
      ],
      "abstract": "Interpreting the decisions of Convolutional Neural Networks (CNNs) is\nessential for understanding their behavior, yet explainability remains a\nsignificant challenge, particularly for self-supervised models. Most existing\nmethods for generating saliency maps rely on ground truth labels, restricting\ntheir use to supervised tasks. EigenCAM is the only notable label-independent\nalternative, leveraging Singular Value Decomposition to generate saliency maps\napplicable across CNN models, but it does not fully exploit the tensorial\nstructure of feature maps. In this work, we introduce the Tucker Saliency Map\n(TSM) method, which applies Tucker tensor decomposition to better capture the\ninherent structure of feature maps, producing more accurate singular vectors\nand values. These are used to generate high-fidelity saliency maps, effectively\nhighlighting objects of interest in the input. We further extend EigenCAM and\nTSM into multivector variants -Multivec-EigenCAM and Multivector Tucker\nSaliency Maps (MTSM)- which utilize all singular vectors and values, further\nimproving saliency map quality. Quantitative evaluations on supervised\nclassification models demonstrate that TSM, Multivec-EigenCAM, and MTSM achieve\ncompetitive performance with label-dependent methods. Moreover, TSM enhances\nexplainability by approximately 50% over EigenCAM for both supervised and\nself-supervised models. Multivec-EigenCAM and MTSM further advance\nstate-of-the-art explainability performance on self-supervised models, with\nMTSM achieving the best results.",
      "tldr_zh": "这篇论文针对卷积神经网络（CNN）的解释性问题，特别是在自监督模型中，引入了Tucker Saliency Map (TSM)方法，通过Tucker张量分解更好地捕捉特征图的结构，生成更精确的显著性图。作者进一步扩展了EigenCAM为Multivec-EigenCAM，并开发了Multivector Tucker Saliency Maps (MTSM)，利用所有奇异向量和值来提升显著性图的质量。实验结果显示，TSM较EigenCAM提高了约50%的解释性性能，而MTSM在自监督模型上达到了最佳效果，与依赖标签的方法相当。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "29 pages, 20 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.23072v1",
      "published_date": "2024-10-30 14:46:34 UTC",
      "updated_date": "2024-10-30 14:46:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:01:57.946355"
    },
    {
      "arxiv_id": "2411.00855v1",
      "title": "Vision-Language Models Can Self-Improve Reasoning via Reflection",
      "title_zh": "视觉语言模型可以通过反思自我提升推理",
      "authors": [
        "Kanzhi Cheng",
        "Yantao Li",
        "Fangzhi Xu",
        "Jianbing Zhang",
        "Hao Zhou",
        "Yang Liu"
      ],
      "abstract": "Chain-of-thought (CoT) has proven to improve the reasoning capability of\nlarge language models (LLMs). However, due to the complexity of multimodal\nscenarios and the difficulty in collecting high-quality CoT data, CoT reasoning\nin multimodal LLMs has been largely overlooked. To this end, we propose a\nsimple yet effective self-training framework, R3V, which iteratively enhances\nthe model's Vision-language Reasoning by Reflecting on CoT Rationales. Our\nframework consists of two interleaved parts: (1) iteratively bootstrapping\npositive and negative solutions for reasoning datasets, and (2) reflection on\nrationale for learning from mistakes. Specifically, we introduce the\nself-refine and self-select losses, enabling the model to refine flawed\nrationale and derive the correct answer by comparing rationale candidates.\nExperiments on a wide range of vision-language tasks show that R3V consistently\nimproves multimodal LLM reasoning, achieving a relative improvement of 23 to 60\npercent over GPT-distilled baselines. Additionally, our approach supports\nself-reflection on generated solutions, further boosting performance through\ntest-time computation.",
      "tldr_zh": "该研究提出了一种简单有效的自训练框架 R3V，帮助视觉语言模型 (VLMs) 通过反思 Chain-of-Thought (CoT) 推理来提升推理能力。该框架包括迭代引导正负解决方案以及对推理理由进行反思，具体通过 self-refine 和 self-select losses 让模型改进有缺陷的推理并比较候选答案，以从错误中学习。在多种视觉语言任务上的实验显示，R3V 相较于 GPT-distilled 基线实现了 23% 到 60% 的相对性能提升，并支持测试时的自反思，进一步增强模型效果。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.00855v1",
      "published_date": "2024-10-30 14:45:00 UTC",
      "updated_date": "2024-10-30 14:45:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:02:56.002072"
    },
    {
      "arxiv_id": "2410.23069v1",
      "title": "LLMs Integration in Software Engineering Team Projects: Roles, Impact, and a Pedagogical Design Space for AI Tools in Computing Education",
      "title_zh": "翻译失败",
      "authors": [
        "Ahmed Kharrufa",
        "Sami Alghamdi",
        "Abeer Aziz",
        "Christopher Bull"
      ],
      "abstract": "This work takes a pedagogical lens to explore the implications of generative\nAI (GenAI) models and tools, such as ChatGPT and GitHub Copilot, in a\nsemester-long 2nd-year undergraduate Software Engineering Team Project.\nQualitative findings from survey (39 students) and interviews (eight students)\nprovide insights into the students' views on the impact of GenAI use on their\ncoding experience, learning, and self-efficacy. Our results address a\nparticular gap in understanding the role and implications of GenAI on teamwork,\nteam-efficacy, and team dynamics. The analysis of the learning aspects is\ndistinguished by the application of learning and pedagogy informed lenses to\ndiscuss the data. We propose a preliminary design space for GenAI-based\nprogramming learning tools highlighting the importance of considering the roles\nthat GenAI can play during the learning process, the varying support-ability\npatterns that can be applied to each role, and the importance of supporting\ntransparency in GenAI for team members and students in addition to educators.",
      "tldr_zh": "这篇论文探讨了生成式 AI（如 ChatGPT 和 GitHub Copilot）在第二年本科软件工程团队项目中的角色和影响，通过对39名学生的调查和8名学生的访谈，分析了GenAI对编码体验、学习、自我效能以及团队合作和动态的影响。研究结果填补了GenAI在团队效能方面的理解空白，并采用学习与教育学视角进行分析。论文提出一个初步的设计空间，用于GenAI-based编程学习工具，强调GenAI在学习过程中的角色、支持模式以及透明度的必要性，以提升教育效果。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.23069v1",
      "published_date": "2024-10-30 14:43:33 UTC",
      "updated_date": "2024-10-30 14:43:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:02:21.292017"
    },
    {
      "arxiv_id": "2410.23054v2",
      "title": "Controlling Language and Diffusion Models by Transporting Activations",
      "title_zh": "翻译失败",
      "authors": [
        "Pau Rodriguez",
        "Arno Blaas",
        "Michal Klein",
        "Luca Zappella",
        "Nicholas Apostoloff",
        "Marco Cuturi",
        "Xavier Suau"
      ],
      "abstract": "The increasing capabilities of large generative models and their ever more\nwidespread deployment have raised concerns about their reliability, safety, and\npotential misuse. To address these issues, recent works have proposed to\ncontrol model generation by steering model activations in order to effectively\ninduce or prevent the emergence of concepts or behaviors in the generated\noutput. In this paper we introduce Activation Transport (AcT), a general\nframework to steer activations guided by optimal transport theory that\ngeneralizes many previous activation-steering works. AcT is modality-agnostic\nand provides fine-grained control over the model behavior with negligible\ncomputational overhead, while minimally impacting model abilities. We\nexperimentally show the effectiveness and versatility of our approach by\naddressing key challenges in large language models (LLMs) and text-to-image\ndiffusion models (T2Is). For LLMs, we show that AcT can effectively mitigate\ntoxicity, induce arbitrary concepts, and increase their truthfulness. In T2Is,\nwe show how AcT enables fine-grained style control and concept negation.",
      "tldr_zh": "本研究提出Activation Transport (AcT)框架，利用optimal transport theory来操控模型激活，从而控制语言模型(LLMs)和扩散模型(T2Is)的生成输出，以解决其可靠性、安全性和潜在误用问题。AcT框架模态无关，提供细粒度行为控制，同时保持计算开销低且最小化对模型能力的影响。在实验中，该方法成功减轻了LLMs的毒性、诱导特定概念并提升真实性；在T2Is中实现了风格精细控制和概念否定，展示了其有效性和多功能性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "68T07, 49Q22",
        "I.2.6; I.2.7; I.4.8"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.23054v2",
      "published_date": "2024-10-30 14:21:33 UTC",
      "updated_date": "2024-11-22 16:04:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:02:33.028889"
    },
    {
      "arxiv_id": "2410.23041v1",
      "title": "Emotional RAG: Enhancing Role-Playing Agents through Emotional Retrieval",
      "title_zh": "情感 RAG：通过情感检索增强角色扮演代理",
      "authors": [
        "Le Huang",
        "Hengzhi Lan",
        "Zijun Sun",
        "Chuan Shi",
        "Ting Bai"
      ],
      "abstract": "As LLMs exhibit a high degree of human-like capability, increasing attention\nhas been paid to role-playing research areas in which responses generated by\nLLMs are expected to mimic human replies. This has promoted the exploration of\nrole-playing agents in various applications, such as chatbots that can engage\nin natural conversations with users and virtual assistants that can provide\npersonalized support and guidance. The crucial factor in the role-playing task\nis the effective utilization of character memory, which stores characters'\nprofiles, experiences, and historical dialogues. Retrieval Augmented Generation\n(RAG) technology is used to access the related memory to enhance the response\ngeneration of role-playing agents. Most existing studies retrieve related\ninformation based on the semantic similarity of memory to maintain characters'\npersonalized traits, and few attempts have been made to incorporate the\nemotional factor in the retrieval argument generation (RAG) of LLMs. Inspired\nby the Mood-Dependent Memory theory, which indicates that people recall an\nevent better if they somehow reinstate during recall the original emotion they\nexperienced during learning, we propose a novel emotion-aware memory retrieval\nframework, termed Emotional RAG, which recalls the related memory with\nconsideration of emotional state in role-playing agents. Specifically, we\ndesign two kinds of retrieval strategies, i.e., combination strategy and\nsequential strategy, to incorporate both memory semantic and emotional states\nduring the retrieval process. Extensive experiments on three representative\nrole-playing datasets demonstrate that our Emotional RAG framework outperforms\nthe method without considering the emotional factor in maintaining the\npersonalities of role-playing agents. This provides evidence to further\nreinforce the Mood-Dependent Memory theory in psychology.",
      "tldr_zh": "这篇论文提出 Emotional RAG 框架，用于提升角色扮演代理的响应生成，通过在 Retrieval Augmented Generation (RAG) 技术中融入情感因素，受 Mood-Dependent Memory 理论启发。框架设计了两种检索策略：combination strategy 和 sequential strategy，以同时考虑记忆语义和情感状态，从而更好地维护角色的个性。实验结果显示，在三个代表性角色扮演数据集上，Emotional RAG 比不考虑情感的baseline 方法在个性保持方面表现出色，并为 Mood-Dependent Memory 理论提供了进一步的心理学证据。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.23041v1",
      "published_date": "2024-10-30 14:08:50 UTC",
      "updated_date": "2024-10-30 14:08:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:02:45.065147"
    },
    {
      "arxiv_id": "2410.23031v2",
      "title": "Offline Reinforcement Learning and Sequence Modeling for Downlink Link Adaptation",
      "title_zh": "离线强化学习和序列建模",
      "authors": [
        "Samuele Peri",
        "Alessio Russo",
        "Gabor Fodor",
        "Pablo Soldati"
      ],
      "abstract": "Link adaptation (LA) is an essential function in modern wireless\ncommunication systems that dynamically adjusts the transmission rate of a\ncommunication link to match time- and frequency-varying radio link conditions.\nHowever, factors such as user mobility, fast fading, imperfect channel quality\ninformation, and aging of measurements make the modeling of LA challenging. To\nbypass the need for explicit modeling, recent research has introduced online\nreinforcement learning (RL) approaches as an alternative to the more commonly\nused rule-based algorithms. Yet, RL-based approaches face deployment\nchallenges, as training in live networks can potentially degrade real-time\nperformance. To address this challenge, this paper considers offline RL as a\ncandidate to learn LA policies with minimal effects on the network operation.\nWe propose three LA designs based on batch-constrained deep Q-learning,\nconservative Q-learning, and decision transformer. Our results show that\noffline RL algorithms can match the performance of state-of-the-art online RL\nmethods when data is collected with a proper behavioral policy.",
      "tldr_zh": "这篇论文探讨了无线通信系统中链路适配（Link Adaptation, LA）的挑战，包括用户移动、快速衰落和不完善的信道质量信息等因素，导致传统规则-based算法和在线强化学习（online RL）方法难以部署。作者提出使用离线强化学习（offline RL）来学习LA策略，设计了三种方法：基于batch-constrained deep Q-learning、conservative Q-learning和decision transformer。实验结果表明，这些离线RL算法在数据由适当的行为策略收集时，能与最先进在线RL方法匹敌，同时最小化了对网络操作的影响。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.23031v2",
      "published_date": "2024-10-30 14:01:31 UTC",
      "updated_date": "2024-11-28 23:00:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:03:10.013557"
    },
    {
      "arxiv_id": "2410.23022v2",
      "title": "Online Intrinsic Rewards for Decision Making Agents from Large Language Model Feedback",
      "title_zh": "翻译失败",
      "authors": [
        "Qinqing Zheng",
        "Mikael Henaff",
        "Amy Zhang",
        "Aditya Grover",
        "Brandon Amos"
      ],
      "abstract": "Automatically synthesizing dense rewards from natural language descriptions\nis a promising paradigm in reinforcement learning (RL), with applications to\nsparse reward problems, open-ended exploration, and hierarchical skill design.\nRecent works have made promising steps by exploiting the prior knowledge of\nlarge language models (LLMs). However, these approaches suffer from important\nlimitations: they are either not scalable to problems requiring billions of\nenvironment samples, due to requiring LLM annotations for each observation, or\nthey require a diverse offline dataset, which may not exist or be impossible to\ncollect. In this work, we address these limitations through a combination of\nalgorithmic and systems-level contributions. We propose \\oni, a distributed\narchitecture that simultaneously learns an RL policy and an intrinsic reward\nfunction using LLM feedback. Our approach annotates the agent's collected\nexperience via an asynchronous LLM server, which is then distilled into an\nintrinsic reward model. We explore a range of algorithmic choices for reward\nmodeling with varying complexity, including hashing, classification, and\nranking models. By studying their relative tradeoffs, we shed light on\nquestions regarding intrinsic reward design for sparse reward problems. Our\napproach achieves state-of-the-art performance across a range of challenging,\nsparse reward tasks from the NetHack Learning Environment in a simple unified\nprocess, solely using the agent's gathered experience, without requiring\nexternal datasets. We make our code available at\n\\url{https://github.com/facebookresearch/oni}.",
      "tldr_zh": "本论文提出了一种名为 \\oni 的分布式架构，利用大型语言模型 (LLMs) 反馈为决策代理生成在线内在奖励，以解决强化学习 (RL) 中稀疏奖励问题。该方法通过异步 LLM 服务器标注代理收集的经验，并将其蒸馏成内在奖励模型，同时探索了哈希、分类和排名等算法的权衡，实现高效的学习过程。在 NetHack 学习环境中，\\oni 在多种挑战性任务上取得了最先进性能，仅依赖代理的经验，而无需外部数据集。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.23022v2",
      "published_date": "2024-10-30 13:52:43 UTC",
      "updated_date": "2024-12-17 22:29:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:03:22.836941"
    },
    {
      "arxiv_id": "2410.22997v2",
      "title": "A Comparison of Prompt Engineering Techniques for Task Planning and Execution in Service Robotics",
      "title_zh": "翻译失败",
      "authors": [
        "Jonas Bode",
        "Bastian Pätzold",
        "Raphael Memmesheimer",
        "Sven Behnke"
      ],
      "abstract": "Recent advances in LLM have been instrumental in autonomous robot control and\nhuman-robot interaction by leveraging their vast general knowledge and\ncapabilities to understand and reason across a wide range of tasks and\nscenarios. Previous works have investigated various prompt engineering\ntechniques for improving the performance of LLM to accomplish tasks, while\nothers have proposed methods that utilize LLMs to plan and execute tasks based\non the available functionalities of a given robot platform. In this work, we\nconsider both lines of research by comparing prompt engineering techniques and\ncombinations thereof within the application of high-level task planning and\nexecution in service robotics. We define a diverse set of tasks and a simple\nset of functionalities in simulation, and measure task completion accuracy and\nexecution time for several state-of-the-art models.",
      "tldr_zh": "本研究比较了各种提示工程（Prompt Engineering）技术及其组合在服务机器人任务规划和执行中的应用，旨在利用大型语言模型（LLM）的广泛知识来提升机器人自主控制和人机交互性能。研究者定义了多样化的任务集和简单的功能集，在模拟环境中测试了几种最先进模型的表现，重点评估任务完成准确率和执行时间。通过这些比较，论文为优化LLM在高水平任务规划中的应用提供了实证见解。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "6 pages, 3 figures, 2 tables, to be published in the 2024 IEEE-RAS\n  International Conference on Humanoid Robots, We make our code, including all\n  prompts, available at https://github.com/AIS-Bonn/Prompt_Engineering",
      "pdf_url": "http://arxiv.org/pdf/2410.22997v2",
      "published_date": "2024-10-30 13:22:55 UTC",
      "updated_date": "2024-11-06 16:57:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:03:33.288803"
    },
    {
      "arxiv_id": "2410.22996v1",
      "title": "Semantic Enrichment of the Quantum Cascade Laser Properties in Text- A Knowledge Graph Generation Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Deperias Kerre",
        "Anne Laurent",
        "Kenneth Maussang",
        "Dickson Owuor"
      ],
      "abstract": "A well structured collection of the various Quantum Cascade Laser (QCL)\ndesign and working properties data provides a platform to analyze and\nunderstand the relationships between these properties. By analyzing these\nrelationships, we can gain insights into how different design features impact\nlaser performance properties such as the working temperature. Most of these QCL\nproperties are captured in scientific text. There is therefore need for\nefficient methodologies that can be utilized to extract QCL properties from\ntext and generate a semantically enriched and interlinked platform where the\nproperties can be analyzed to uncover hidden relations. There is also the need\nto maintain provenance and reference information on which these properties are\nbased. Semantic Web technologies such as Ontologies and Knowledge Graphs have\nproven capability in providing interlinked data platforms for knowledge\nrepresentation in various domains. In this paper, we propose an approach for\ngenerating a QCL properties Knowledge Graph (KG) from text for semantic\nenrichment of the properties. The approach is based on the QCL ontology and a\nRetrieval Augmented Generation (RAG) enabled information extraction pipeline\nbased on GPT 4-Turbo language model. The properties of interest include:\nworking temperature, laser design type, lasing frequency, laser optical power\nand the heterostructure. The experimental results demonstrate the feasibility\nand effectiveness of this approach for efficiently extracting QCL properties\nfrom unstructured text and generating a QCL properties Knowledge Graph, which\nhas potential applications in semantic enrichment and analysis of QCL data.",
      "tldr_zh": "本文提出了一种从科学文本中提取 Quantum Cascade Laser (QCL) 属性并生成知识图谱 (Knowledge Graph) 的方法，旨在实现属性的语义丰富和关系分析，以揭示设计特征对激光性能（如工作温度）的影响。方法基于 QCL Ontology 和 Retrieval Augmented Generation (RAG) 启用的信息提取管道，使用 GPT 4-Turbo 模型，针对关键属性包括工作温度、激光设计类型、激射频率、激光光学功率和异质结构进行高效提取，同时维护来源信息。实验结果验证了该方法的有效性，为 QCL 数据的语义分析和潜在应用提供了可靠平台。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.22996v1",
      "published_date": "2024-10-30 13:22:22 UTC",
      "updated_date": "2024-10-30 13:22:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:03:46.409478"
    },
    {
      "arxiv_id": "2410.22995v1",
      "title": "VisAidMath: Benchmarking Visual-Aided Mathematical Reasoning",
      "title_zh": "VisAidMath：视觉辅助数学推理的基准测试",
      "authors": [
        "Jingkun Ma",
        "Runzhe Zhan",
        "Derek F. Wong",
        "Yang Li",
        "Di Sun",
        "Hou Pong Chan",
        "Lidia S. Chao"
      ],
      "abstract": "Although previous research on large language models (LLMs) and large\nmulti-modal models (LMMs) has systematically explored mathematical\nproblem-solving (MPS) within visual contexts, the analysis of how these models\nprocess visual information during problem-solving remains insufficient. To\naddress this gap, we present VisAidMath, a benchmark for evaluating the MPS\nprocess related to visual information. We follow a rigorous data curation\npipeline involving both automated processes and manual annotations to ensure\ndata quality and reliability. Consequently, this benchmark includes 1,200\nchallenging problems from various mathematical branches, vision-aid\nformulations, and difficulty levels, collected from diverse sources such as\ntextbooks, examination papers, and Olympiad problems. Based on the proposed\nbenchmark, we conduct comprehensive evaluations on ten mainstream LLMs and\nLMMs, highlighting deficiencies in the visual-aided reasoning process. For\nexample, GPT-4V only achieves 45.33% accuracy in the visual-aided reasoning\ntask, even with a drop of 2 points when provided with golden visual aids.\nIn-depth analysis reveals that the main cause of deficiencies lies in\nhallucination regarding the implicit visual reasoning process, shedding light\non future research directions in the visual-aided MPS process.",
      "tldr_zh": "本研究提出VisAidMath基准，用于评估大型语言模型(LLMs)和大型多模态模型(LMMs)在视觉辅助数学问题解决(MPS)过程中的表现，填补了现有模型对视觉信息处理分析的不足。基准通过严格的数据整理流程，包括自动化和手动注解，汇集了1200个来自教科书、考试和奥林匹克问题的挑战性任务，覆盖多种数学分支、视觉辅助形式和难度水平。对十个主流LLMs和LMMs的全面评估显示，这些模型在视觉辅助推理中存在显著缺陷，例如GPT-4V的准确率仅为45.33%，即使提供黄金视觉辅助也进一步下降。分析发现，主要问题在于模型对隐式视觉推理过程的hallucination，这为未来视觉辅助MPS研究提供了重要方向。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "58 pages, 28 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.22995v1",
      "published_date": "2024-10-30 13:19:44 UTC",
      "updated_date": "2024-10-30 13:19:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:03:57.597208"
    },
    {
      "arxiv_id": "2410.23325v1",
      "title": "Transfer Learning in Vocal Education: Technical Evaluation of Limited Samples Describing Mezzo-soprano",
      "title_zh": "翻译失败",
      "authors": [
        "Zhenyi Hou",
        "Xu Zhao",
        "Kejie Ye",
        "Xinyu Sheng",
        "Shanggerile Jiang",
        "Jiajing Xia",
        "Yitao Zhang",
        "Chenxi Ban",
        "Daijun Luo",
        "Jiaxing Chen",
        "Yan Zou",
        "Yuchao Feng",
        "Guangyu Fan",
        "Xin Yuan"
      ],
      "abstract": "Vocal education in the music field is difficult to quantify due to the\nindividual differences in singers' voices and the different quantitative\ncriteria of singing techniques. Deep learning has great potential to be applied\nin music education due to its efficiency to handle complex data and perform\nquantitative analysis. However, accurate evaluations with limited samples over\nrare vocal types, such as Mezzo-soprano, requires extensive well-annotated data\nsupport using deep learning models. In order to attain the objective, we\nperform transfer learning by employing deep learning models pre-trained on the\nImageNet and Urbansound8k datasets for the improvement on the precision of\nvocal technique evaluation. Furthermore, we tackle the problem of the lack of\nsamples by constructing a dedicated dataset, the Mezzo-soprano Vocal Set (MVS),\nfor vocal technique assessment. Our experimental results indicate that transfer\nlearning increases the overall accuracy (OAcc) of all models by an average of\n8.3%, with the highest accuracy at 94.2%. We not only provide a novel approach\nto evaluating Mezzo-soprano vocal techniques but also introduce a new\nquantitative assessment method for music education.",
      "tldr_zh": "这篇论文探讨了使用 transfer learning 在声乐教育中评估 Mezzo-soprano 声部的技术，旨在解决歌手声音个体差异和样本有限的量化难题。作者采用预训练于 ImageNet 和 Urbansound8k 的深层学习模型，并构建了专用数据集 Mezzo-soprano Vocal Set (MVS) 来提升评估精度。实验结果显示，transfer learning 平均提高了所有模型的整体准确率 (OAcc) 8.3%，最高达到 94.2%。该方法不仅为 Mezzo-soprano 声乐技术评估提供了新途径，还引入了音乐教育的量化评估框架。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.MM",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.23325v1",
      "published_date": "2024-10-30 13:17:13 UTC",
      "updated_date": "2024-10-30 13:17:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:04:10.808190"
    },
    {
      "arxiv_id": "2410.22984v1",
      "title": "Higher-order Cross-structural Embedding Model for Time Series Analysis",
      "title_zh": "高阶跨结构嵌入模型用于时间序列分析",
      "authors": [
        "Guancen Lin",
        "Cong Shen",
        "Aijing Lin"
      ],
      "abstract": "Time series analysis has gained significant attention due to its critical\napplications in diverse fields such as healthcare, finance, and sensor\nnetworks. The complexity and non-stationarity of time series make it\nchallenging to capture the interaction patterns across different timestamps.\nCurrent approaches struggle to model higher-order interactions within time\nseries, and focus on learning temporal or spatial dependencies separately,\nwhich limits performance in downstream tasks. To address these gaps, we propose\nHigher-order Cross-structural Embedding Model for Time Series (High-TS), a\nnovel framework that jointly models both temporal and spatial perspectives by\ncombining multiscale Transformer with Topological Deep Learning (TDL).\nMeanwhile, High-TS utilizes contrastive learning to integrate these two\nstructures for generating robust and discriminative representations. Extensive\nexperiments show that High-TS outperforms state-of-the-art methods in various\ntime series tasks and demonstrate the importance of higher-order\ncross-structural information in improving model performance.",
      "tldr_zh": "该论文针对时间序列分析中捕捉不同时间戳交互模式的挑战，指出现有方法难以建模更高阶交互并仅分别处理时间或空间依赖，导致下游任务性能受限。作者提出 Higher-order Cross-structural Embedding Model for Time Series (High-TS)，一个新框架，通过结合 multiscale Transformer 和 Topological Deep Learning (TDL) 来联合建模时间和空间视角，并利用 contrastive learning 整合这些结构以生成鲁棒且有区分性的表示。实验结果显示，High-TS 在各种时间序列任务中优于最先进方法，并证明了更高阶跨结构信息对提升模型性能的重要性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.22984v1",
      "published_date": "2024-10-30 12:51:14 UTC",
      "updated_date": "2024-10-30 12:51:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:04:23.108014"
    },
    {
      "arxiv_id": "2411.00853v1",
      "title": "Accelerated AI Inference via Dynamic Execution Methods",
      "title_zh": "翻译失败",
      "authors": [
        "Haim Barad",
        "Jascha Achterberg",
        "Tien Pei Chou",
        "Jean Yu"
      ],
      "abstract": "In this paper, we focus on Dynamic Execution techniques that optimize the\ncomputation flow based on input. This aims to identify simpler problems that\ncan be solved using fewer resources, similar to human cognition. The techniques\ndiscussed include early exit from deep networks, speculative sampling for\nlanguage models, and adaptive steps for diffusion models. Experimental results\ndemonstrate that these dynamic approaches can significantly improve latency and\nthroughput without compromising quality. When combined with model-based\noptimizations, such as quantization, dynamic execution provides a powerful\nmulti-pronged strategy to optimize AI inference.\n  Generative AI requires a large amount of compute resources. This is expected\nto grow, and demand for resources in data centers through to the edge is\nexpected to continue to increase at high rates. We take advantage of existing\nresearch and provide additional innovations for some generative optimizations.\nIn the case of LLMs, we provide more efficient sampling methods that depend on\nthe complexity of the data. In the case of diffusion model generation, we\nprovide a new method that also leverages the difficulty of the input prompt to\npredict an optimal early stopping point.\n  Therefore, dynamic execution methods are relevant because they add another\ndimension of performance optimizations. Performance is critical from a\ncompetitive point of view, but increasing capacity can result in significant\npower savings and cost savings. We have provided several integrations of these\ntechniques into several Intel performance libraries and Huggingface Optimum.\nThese integrations will make them easier to use and increase the adoption of\nthese techniques.",
      "tldr_zh": "这篇论文探讨了 Dynamic Execution 技术，通过根据输入动态优化计算流程来加速 AI 推理，旨在识别更简单的子问题以减少资源使用，类似于人类认知。关键方法包括 deep networks 的 early exit、language models 的 speculative sampling 以及 diffusion models 的 adaptive steps；此外，论文创新了针对 LLMs 的高效采样方法和针对 diffusion models 的新早停点预测策略。实验结果表明，这些动态方法显著改善了延迟和吞吐量，同时保持质量不降；当与 quantization 等模型优化结合时，它们形成多重策略，帮助节省功率和成本，并已整合到 Intel 性能库和 Huggingface Optimum 中。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.00853v1",
      "published_date": "2024-10-30 12:49:23 UTC",
      "updated_date": "2024-10-30 12:49:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:04:34.969067"
    },
    {
      "arxiv_id": "2410.22982v1",
      "title": "PDSR: Efficient UAV Deployment for Swift and Accurate Post-Disaster Search and Rescue",
      "title_zh": "PDSR：高效 UAV 部署用于迅速且准确的灾后搜索",
      "authors": [
        "Alaa Awad Abdellatif",
        "Ali Elmancy",
        "Amr Mohamed",
        "Ahmed Massoud",
        "Wadha Lebda",
        "Khalid K. Naji"
      ],
      "abstract": "This paper introduces a comprehensive framework for Post-Disaster Search and\nRescue (PDSR), aiming to optimize search and rescue operations leveraging\nUnmanned Aerial Vehicles (UAVs). The primary goal is to improve the precision\nand availability of sensing capabilities, particularly in various catastrophic\nscenarios. Central to this concept is the rapid deployment of UAV swarms\nequipped with diverse sensing, communication, and intelligence capabilities,\nfunctioning as an integrated system that incorporates multiple technologies and\napproaches for efficient detection of individuals buried beneath rubble or\ndebris following a disaster. Within this framework, we propose architectural\nsolution and address associated challenges to ensure optimal performance in\nreal-world disaster scenarios. The proposed framework aims to achieve complete\ncoverage of damaged areas significantly faster than traditional methods using a\nmulti-tier swarm architecture. Furthermore, integrating multi-modal sensing\ndata with machine learning for data fusion could enhance detection accuracy,\nensuring precise identification of survivors.",
      "tldr_zh": "本论文提出PDSR框架，利用无人驾驶飞机(UAVs)优化灾后搜索和救援操作，旨在提升感知能力的精确性和可用性，尤其在灾难场景中。框架的核心是快速部署配备多样化感知、通信和智能能力的UAV群，形成一个集成系统，通过多层群架构实现对受损区域的更快全面覆盖。论文还解决相关挑战，包括整合多模态感知数据与机器学习进行数据融合，从而显著提高幸存者检测的准确性。总体而言，该方法比传统方式更高效，为真实灾后救援提供可靠解决方案。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "This paper is currently under review at IEEE IoT Magazine",
      "pdf_url": "http://arxiv.org/pdf/2410.22982v1",
      "published_date": "2024-10-30 12:46:15 UTC",
      "updated_date": "2024-10-30 12:46:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:04:45.290626"
    },
    {
      "arxiv_id": "2410.22952v1",
      "title": "Efficient Adaptation of Pre-trained Vision Transformer via Householder Transformation",
      "title_zh": "通过 Householder 变换实现预训练视觉 Transformer 的高效适应",
      "authors": [
        "Wei Dong",
        "Yuan Sun",
        "Yiting Yang",
        "Xing Zhang",
        "Zhijun Lin",
        "Qingsen Yan",
        "Haokui Zhang",
        "Peng Wang",
        "Yang Yang",
        "Hengtao Shen"
      ],
      "abstract": "A common strategy for Parameter-Efficient Fine-Tuning (PEFT) of pre-trained\nVision Transformers (ViTs) involves adapting the model to downstream tasks by\nlearning a low-rank adaptation matrix. This matrix is decomposed into a product\nof down-projection and up-projection matrices, with the bottleneck\ndimensionality being crucial for reducing the number of learnable parameters,\nas exemplified by prevalent methods like LoRA and Adapter. However, these\nlow-rank strategies typically employ a fixed bottleneck dimensionality, which\nlimits their flexibility in handling layer-wise variations. To address this\nlimitation, we propose a novel PEFT approach inspired by Singular Value\nDecomposition (SVD) for representing the adaptation matrix. SVD decomposes a\nmatrix into the product of a left unitary matrix, a diagonal matrix of scaling\nvalues, and a right unitary matrix. We utilize Householder transformations to\nconstruct orthogonal matrices that efficiently mimic the unitary matrices,\nrequiring only a vector. The diagonal values are learned in a layer-wise\nmanner, allowing them to flexibly capture the unique properties of each layer.\nThis approach enables the generation of adaptation matrices with varying ranks\nacross different layers, providing greater flexibility in adapting pre-trained\nmodels. Experiments on standard downstream vision tasks demonstrate that our\nmethod achieves promising fine-tuning performance.",
      "tldr_zh": "这篇论文针对预训练 Vision Transformers (ViTs) 的 Parameter-Efficient Fine-Tuning (PEFT)，提出了一种新方法来解决现有低秩策略（如 LoRA 和 Adapter）的瓶颈维度固定问题。作者借鉴 Singular Value Decomposition (SVD)，利用 Householder transformations 构建正交矩阵，仅需一个向量即可表示适应矩阵，并允许层间对角值灵活学习，以适应各层的独特特性。该方法实现了适应矩阵在不同层间的可变秩，提高了模型的灵活性和效率。在标准视觉任务的实验中，该方法展示了有前景的微调性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.22952v1",
      "published_date": "2024-10-30 12:08:30 UTC",
      "updated_date": "2024-10-30 12:08:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:04:58.258789"
    },
    {
      "arxiv_id": "2410.22950v1",
      "title": "SpiroActive: Active Learning for Efficient Data Acquisition for Spirometry",
      "title_zh": "翻译失败",
      "authors": [
        "Ankita Kumari Jain",
        "Nitish Sharma",
        "Madhav Kanda",
        "Nipun Batra"
      ],
      "abstract": "Respiratory illnesses are a significant global health burden. Respiratory\nillnesses, primarily Chronic obstructive pulmonary disease (COPD), is the\nseventh leading cause of poor health worldwide and the third leading cause of\ndeath worldwide, causing 3.23 million deaths in 2019, necessitating early\nidentification and diagnosis for effective mitigation. Among the diagnostic\ntools employed, spirometry plays a crucial role in detecting respiratory\nabnormalities. However, conventional clinical spirometry methods often entail\nconsiderable costs and practical limitations like the need for specialized\nequipment, trained personnel, and a dedicated clinical setting, making them\nless accessible. To address these challenges, wearable spirometry technologies\nhave emerged as promising alternatives, offering accurate, cost-effective, and\nconvenient solutions. The development of machine learning models for wearable\nspirometry heavily relies on the availability of high-quality ground truth\nspirometry data, which is a laborious and expensive endeavor. In this research,\nwe propose using active learning, a sub-field of machine learning, to mitigate\nthe challenges associated with data collection and labeling. By strategically\nselecting samples from the ground truth spirometer, we can mitigate the need\nfor resource-intensive data collection. We present evidence that models trained\non small subsets obtained through active learning achieve comparable/better\nresults than models trained on the complete dataset.",
      "tldr_zh": "本研究针对呼吸疾病（如 COPD）诊断的挑战，指出传统 spirometry 方法因需要专业设备和人员而成本高昂。论文提出 SpiroActive 框架，利用 active learning 策略从地面真实数据中战略性选择样本，减少数据采集的资源消耗。实验结果表明，使用小数据集训练的 machine learning 模型可实现与完整数据集相当或更好的性能，为可穿戴 spirometry 技术提供高效且经济实惠的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.22950v1",
      "published_date": "2024-10-30 12:07:30 UTC",
      "updated_date": "2024-10-30 12:07:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:05:09.830979"
    },
    {
      "arxiv_id": "2410.22944v3",
      "title": "Focus On This, Not That! Steering LLMs With Adaptive Feature Specification",
      "title_zh": "翻译失败",
      "authors": [
        "Tom A. Lamb",
        "Adam Davies",
        "Alasdair Paren",
        "Philip H. S. Torr",
        "Francesco Pinto"
      ],
      "abstract": "Despite the success of Instruction Tuning (IT) in training large language\nmodels (LLMs) to perform arbitrary user-specified tasks, these models often\nstill leverage spurious or biased features learned from their training data,\nleading to undesired behaviours when deploying them in new contexts. In this\nwork, we introduce Focus Instruction Tuning (FIT), which trains LLMs to\ncondition their responses by focusing on specific features whilst ignoring\nothers, leading to different behaviours based on what features are specified.\nAcross several experimental settings, we show that focus-tuned models can be\nadaptively steered by focusing on different features at inference-time: for\ninstance, robustness can be improved by focusing on task-causal features and\nignoring spurious features, and social bias can be mitigated by ignoring\ndemographic categories. Furthermore, FIT can steer behaviour in new contexts,\ngeneralising under distribution shift and to new unseen features at inference\ntime, and thereby facilitating more robust, fair, and controllable LLM\napplications in real-world environments.",
      "tldr_zh": "这篇论文介绍了 Focus Instruction Tuning (FIT)，一种训练大型语言模型 (LLMs) 的方法，旨在让模型通过关注特定特征（如任务因果特征）而忽略虚假或偏置特征，从而在推理时灵活调整行为。相比传统 Instruction Tuning (IT)，FIT 可以提升模型的鲁棒性、减少社会偏见，并在分布偏移下泛化到新特征。实验结果表明，这种方法有助于构建更可靠、公平和可控的 LLM 应用环境。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "32pages, 17 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.22944v3",
      "published_date": "2024-10-30 12:01:48 UTC",
      "updated_date": "2025-02-10 23:03:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:05:21.370742"
    },
    {
      "arxiv_id": "2410.22938v2",
      "title": "DiffLight: A Partial Rewards Conditioned Diffusion Model for Traffic Signal Control with Missing Data",
      "title_zh": "DiffLight：一种部分奖励条件化的扩散模型，用于处理缺失数据的交通信号控制",
      "authors": [
        "Hanyang Chen",
        "Yang Jiang",
        "Shengnan Guo",
        "Xiaowei Mao",
        "Youfang Lin",
        "Huaiyu Wan"
      ],
      "abstract": "The application of reinforcement learning in traffic signal control (TSC) has\nbeen extensively researched and yielded notable achievements. However, most\nexisting works for TSC assume that traffic data from all surrounding\nintersections is fully and continuously available through sensors. In\nreal-world applications, this assumption often fails due to sensor malfunctions\nor data loss, making TSC with missing data a critical challenge. To meet the\nneeds of practical applications, we introduce DiffLight, a novel conditional\ndiffusion model for TSC under data-missing scenarios in the offline setting.\nSpecifically, we integrate two essential sub-tasks, i.e., traffic data\nimputation and decision-making, by leveraging a Partial Rewards Conditioned\nDiffusion (PRCD) model to prevent missing rewards from interfering with the\nlearning process. Meanwhile, to effectively capture the spatial-temporal\ndependencies among intersections, we design a Spatial-Temporal transFormer\n(STFormer) architecture. In addition, we propose a Diffusion Communication\nMechanism (DCM) to promote better communication and control performance under\ndata-missing scenarios. Extensive experiments on five datasets with various\ndata-missing scenarios demonstrate that DiffLight is an effective controller to\naddress TSC with missing data. The code of DiffLight is released at\nhttps://github.com/lokol5579/DiffLight-release.",
      "tldr_zh": "该论文针对交通信号控制(TSC)中数据缺失的实际挑战，提出了一种新型条件扩散模型DiffLight，用于离线场景下的TSC优化。具体而言，DiffLight通过Partial Rewards Conditioned Diffusion (PRCD)模型整合交通数据补全和决策过程，避免缺失奖励干扰学习，同时采用Spatial-Temporal transFormer (STFormer)架构捕捉交叉口的空间-时间依赖性，并引入Diffusion Communication Mechanism (DCM)来提升数据缺失环境下的通信和控制性能。在五个数据集上的广泛实验证明，DiffLight在各种数据缺失场景中表现出色，有效提高了TSC的鲁棒性。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.LG",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "Accepted by NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.22938v2",
      "published_date": "2024-10-30 11:47:40 UTC",
      "updated_date": "2024-10-31 13:39:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:05:33.602970"
    },
    {
      "arxiv_id": "2410.22937v1",
      "title": "Thoughtful Adoption of NLP for Civic Participation: Understanding Differences Among Policymakers",
      "title_zh": "翻译失败",
      "authors": [
        "Jose A. Guridi",
        "Cristobal Cheyre",
        "Qian Yang"
      ],
      "abstract": "Natural language processing (NLP) tools have the potential to boost civic\nparticipation and enhance democratic processes because they can significantly\nincrease governments' capacity to gather and analyze citizen opinions. However,\ntheir adoption in government remains limited, and harnessing their benefits\nwhile preventing unintended consequences remains a challenge. While prior work\nhas focused on improving NLP performance, this work examines how different\ninternal government stakeholders influence NLP tools' thoughtful adoption. We\ninterviewed seven politicians (politically appointed officials as heads of\ngovernment institutions) and thirteen public servants (career government\nemployees who design and administrate policy interventions), inquiring how they\nchoose whether and how to use NLP tools to support civic participation\nprocesses. The interviews suggest that policymakers across both groups focused\non their needs for career advancement and the need to showcase the legitimacy\nand fairness of their work when considering NLP tool adoption and use. Because\nthese needs vary between politicians and public servants, their preferred NLP\nfeatures and tool designs also differ. Interestingly, despite their differing\nneeds and opinions, neither group clearly identifies who should advocate for\nNLP adoption to enhance civic participation or address the unintended\nconsequences of a poorly considered adoption. This lack of clarity in\nresponsibility might have caused the governments' low adoption of NLP tools. We\ndiscuss how these findings reveal new insights for future HCI research. They\ninform the design of NLP tools for increasing civic participation efficiency\nand capacity, the design of other tools and methods that ensure thoughtful\nadoption of AI tools in government, and the design of NLP tools for\ncollaborative use among users with different incentives and needs.",
      "tldr_zh": "本研究探讨了自然语言处理(NLP)工具在提升公民参与和民主进程中的采用问题，特别关注政府内部利益相关者（如政客和公职人员）的差异。通过对七位政客和十三位公职人员的访谈，发现他们主要考虑职业发展和工作合法性，导致对NLP工具的偏好不同，例如在工具设计和功能上存在显著分歧。研究揭示，双方均未明确谁应负责推动NLP采用，这可能导致政府采用率低下。该发现为HCI研究提供了新洞见，有助于设计更高效的NLP工具、确保AI工具的审慎采用，以及支持不同需求的协作使用。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "Forthcoming in the Proceedings of the 2025 Conference on Computer\n  Supported Cooperative Work and Social Computing (CSCW)",
      "pdf_url": "http://arxiv.org/pdf/2410.22937v1",
      "published_date": "2024-10-30 11:46:26 UTC",
      "updated_date": "2024-10-30 11:46:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:05:46.117872"
    },
    {
      "arxiv_id": "2410.22925v1",
      "title": "BIS: NL2SQL Service Evaluation Benchmark for Business Intelligence Scenarios",
      "title_zh": "翻译失败",
      "authors": [
        "Bora Caglayan",
        "Mingxue Wang",
        "John D. Kelleher",
        "Shen Fei",
        "Gui Tong",
        "Jiandong Ding",
        "Puchao Zhang"
      ],
      "abstract": "NL2SQL (Natural Language to Structured Query Language) transformation has\nseen wide adoption in Business Intelligence (BI) applications in recent years.\nHowever, existing NL2SQL benchmarks are not suitable for production BI\nscenarios, as they are not designed for common business intelligence questions.\nTo address this gap, we have developed a new benchmark focused on typical NL\nquestions in industrial BI scenarios. We discuss the challenges of constructing\na BI-focused benchmark and the shortcomings of existing benchmarks.\nAdditionally, we introduce question categories in our benchmark that reflect\ncommon BI inquiries. Lastly, we propose two novel semantic similarity\nevaluation metrics for assessing NL2SQL capabilities in BI applications and\nservices.",
      "tldr_zh": "这篇论文介绍了 BIS 基准（Benchmark），一个针对商业智能（Business Intelligence, BI）场景的 NL2SQL（Natural Language to Structured Query Language）服务评估工具，因为现有基准不适合处理常见 BI 问题。论文讨论了构建此类基准的挑战，包括现有基准的不足，并定义了反映典型 BI 询问的问题类别。最终，他们提出了两个新的语义相似性评估指标，以更准确地评估 NL2SQL 在工业 BI 应用中的性能。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "This paper has been accepted by ICSOC (International Conference on\n  Service-Oriented Computing) 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.22925v1",
      "published_date": "2024-10-30 11:33:03 UTC",
      "updated_date": "2024-10-30 11:33:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:05:57.891769"
    },
    {
      "arxiv_id": "2411.00852v2",
      "title": "EF-LLM: Energy Forecasting LLM with AI-assisted Automation, Enhanced Sparse Prediction, Hallucination Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Zihang Qiu",
        "Chaojie Li",
        "Zhongyang Wang",
        "Renyou Xie",
        "Borui Zhang",
        "Huadong Mo",
        "Guo Chen",
        "Zhaoyang Dong"
      ],
      "abstract": "Accurate prediction helps to achieve supply-demand balance in energy systems,\nsupporting decision-making and scheduling. Traditional models, lacking\nAI-assisted automation, rely on experts, incur high costs, and struggle with\nsparse data prediction. To address these challenges, we propose the Energy\nForecasting Large Language Model (EF-LLM), which integrates domain knowledge\nand temporal data for time-series forecasting, supporting both pre-forecast\noperations and post-forecast decision-support. EF-LLM's human-AI interaction\ncapabilities lower the entry barrier in forecasting tasks, reducing the need\nfor extra expert involvement. To achieve this, we propose a continual learning\napproach with updatable LoRA and a multi-channel architecture for aligning\nheterogeneous multimodal data, enabling EF-LLM to continually learn\nheterogeneous multimodal knowledge. In addition, EF-LLM enables accurate\npredictions under sparse data conditions through its ability to process\nmultimodal data. We propose Fusion Parameter-Efficient Fine-Tuning (F-PEFT)\nmethod to effectively leverage both time-series data and text for this purpose.\nEF-LLM is also the first energy-specific LLM to detect hallucinations and\nquantify their occurrence rate, achieved via multi-task learning, semantic\nsimilarity analysis, and ANOVA. We have achieved success in energy prediction\nscenarios for load, photovoltaic, and wind power forecast.",
      "tldr_zh": "本研究提出EF-LLM，一种专为能源预测设计的Large Language Model（LLM），通过AI辅助自动化、增强稀疏预测和幻觉检测功能，解决传统模型依赖专家、高成本和稀疏数据问题的挑战。EF-LLM整合领域知识和时间序列数据，支持时间序列预测的预后操作和决策支持，并采用持续学习方法（如updatable LoRA和多通道架构）来处理异构多模态数据，同时引入Fusion Parameter-Efficient Fine-Tuning (F-PEFT)方法来利用时间序列数据和文本，实现稀疏数据下的准确预测。此外，EF-LLM首次在能源特定LLM中通过多任务学习、语义相似性分析和ANOVA检测幻觉并量化其发生率，并在负载、光伏和风力预测场景中取得显著成功，提高了预测效率和可靠性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.00852v2",
      "published_date": "2024-10-30 11:22:37 UTC",
      "updated_date": "2024-12-24 03:24:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:06:10.477479"
    },
    {
      "arxiv_id": "2411.00850v3",
      "title": "GWQ: Gradient-Aware Weight Quantization for Large Language Models",
      "title_zh": "GWQ: 梯度感知",
      "authors": [
        "Yihua Shao",
        "Yan Gu",
        "Siyu Chen",
        "Haiyang Liu",
        "Zijian Ling",
        "Minxi Yan",
        "Ziyang Yan",
        "Chenyu Zhang",
        "Michele Magno",
        "Haotong Qin",
        "Yan Wang",
        "Jingcai Guo",
        "Ling Shao",
        "Hao Tang"
      ],
      "abstract": "Large language models (LLMs) show impressive performance in solving complex\nlanguage tasks. However, its large number of parameters presents significant\nchallenges for the deployment. So, compressing LLMs to low bits can enable to\ndeploy on resource-constrained devices. To address this problem, we propose\ngradient-aware weight quantization (GWQ), the first quantization approach for\nlow-bit weight quantization that leverages gradients to localize outliers,\nrequiring only a minimal amount of calibration data for outlier detection. GWQ\nretains the top 1\\% outliers preferentially at FP16 precision, while the\nremaining non-outlier weights are stored in a low-bit. We widely evaluate GWQ\non different task include language modeling, grounding detection, massive\nmultitask language understanding and vision-language question and answering.\nResults show that models quantified by GWQ performs better than other\nquantization method. During quantization process, GWQ only need one calibration\nset to realize effective quant. Also, GWQ achieves 1.2x inference speedup in\ncomparison to the original model and effectively reduces the inference memory.",
      "tldr_zh": "这篇论文提出了一种梯度感知权重量化（GWQ）方法，用于压缩大型语言模型（LLMs），以解决其参数过多导致的部署挑战。GWQ 通过利用梯度定位异常值，仅需少量校准数据，即可优先保留顶层1%的异常值在FP16精度，而其他权重量化到低位。实验在语言建模、地面检测、大规模多任务语言理解和视觉语言问答等任务上显示，GWQ 比其他量化方法性能更优，并实现了1.2倍的推理加速和显著的内存减少。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.00850v3",
      "published_date": "2024-10-30 11:16:04 UTC",
      "updated_date": "2025-04-09 09:09:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:06:21.677142"
    },
    {
      "arxiv_id": "2410.22912v1",
      "title": "Self-optimization in distributed manufacturing systems using Modular State-based Stackelberg Games",
      "title_zh": "翻译失败",
      "authors": [
        "Steve Yuwono",
        "Ahmar Kamal Hussain",
        "Dorothea Schwung",
        "Andreas Schwung"
      ],
      "abstract": "In this study, we introduce Modular State-based Stackelberg Games (Mod-SbSG),\na novel game structure developed for distributed self-learning in modular\nmanufacturing systems. Mod-SbSG enhances cooperative decision-making among\nself-learning agents within production systems by integrating State-based\nPotential Games (SbPG) with Stackelberg games. This hierarchical structure\nassigns more important modules of the manufacturing system a first-mover\nadvantage, while less important modules respond optimally to the leaders'\ndecisions. This decision-making process differs from typical multi-agent\nlearning algorithms in manufacturing systems, where decisions are made\nsimultaneously. We provide convergence guarantees for the novel game structure\nand design learning algorithms to account for the hierarchical game structure.\nWe further analyse the effects of single-leader/multiple-follower and\nmultiple-leader/multiple-follower scenarios within a Mod-SbSG. To assess its\neffectiveness, we implement and test Mod-SbSG in an industrial control setting\nusing two laboratory-scale testbeds featuring sequential and serial-parallel\nprocesses. The proposed approach delivers promising results compared to the\nvanilla SbPG, which reduces overflow by 97.1%, and in some cases, prevents\noverflow entirely. Additionally, it decreases power consumption by 5-13% while\nsatisfying the production demand, which significantly improves potential\n(global objective) values.",
      "tldr_zh": "本文提出了一种名为 Modular State-based Stackelberg Games (Mod-SbSG) 的新型游戏结构，用于分布式制造系统的自优化学习。该框架整合 State-based Potential Games (SbPG) 和 Stackelberg 游戏，采用层次化决策机制，让重要模块作为领导者优先决策，而其他模块作为跟随者进行优化响应，从而提升代理间的合作效率。实验在两个实验室规模的工业控制测试床中验证了其效果，与传统 SbPG 相比，Mod-SbSG 减少溢出 97.1%、在某些场景完全防止溢出，并降低功耗 5-13%，同时满足生产需求并提高全局目标值。",
      "categories": [
        "cs.AI",
        "cs.GT",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "This pre-print was submitted to Journal of Manufacturing Systems on\n  October 30, 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.22912v1",
      "published_date": "2024-10-30 11:09:31 UTC",
      "updated_date": "2024-10-30 11:09:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:08:27.143855"
    },
    {
      "arxiv_id": "2410.22898v1",
      "title": "YOLOv11 for Vehicle Detection: Advancements, Performance, and Applications in Intelligent Transportation Systems",
      "title_zh": "YOLOv11 用于车辆检测：进展、性能和在智能交通系统的应用",
      "authors": [
        "Mujadded Al Rabbani Alif"
      ],
      "abstract": "Accurate vehicle detection is essential for the development of intelligent\ntransportation systems, autonomous driving, and traffic monitoring. This paper\npresents a detailed analysis of YOLO11, the latest advancement in the YOLO\nseries of deep learning models, focusing exclusively on vehicle detection\ntasks. Building upon the success of its predecessors, YOLO11 introduces\narchitectural improvements designed to enhance detection speed, accuracy, and\nrobustness in complex environments. Using a comprehensive dataset comprising\nmultiple vehicle types-cars, trucks, buses, motorcycles, and bicycles we\nevaluate YOLO11's performance using metrics such as precision, recall, F1\nscore, and mean average precision (mAP). Our findings demonstrate that YOLO11\nsurpasses previous versions (YOLOv8 and YOLOv10) in detecting smaller and more\noccluded vehicles while maintaining a competitive inference time, making it\nwell-suited for real-time applications. Comparative analysis shows significant\nimprovements in the detection of complex vehicle geometries, further\ncontributing to the development of efficient and scalable vehicle detection\nsystems. This research highlights YOLO11's potential to enhance autonomous\nvehicle performance and traffic monitoring systems, offering insights for\nfuture developments in the field.",
      "tldr_zh": "本论文分析了 YOLOv11 在车辆检测领域的最新进展，该模型基于 YOLO 系列的架构改进，提升了检测速度、准确性和复杂环境下的鲁棒性。研究使用包含汽车、卡车、公共汽车、摩托车和自行车等多种车辆类型的数据集，通过精度、召回率、F1 分数和 mAP 等指标评估，结果显示 YOLOv11 在检测较小和被遮挡车辆方面超过了 YOLOv8 和 YOLOv10，同时保持了高效的推理时间。YOLOv11 的这些优势使其适用于实时智能交通系统、自动驾驶和交通监控，提供了未来发展的宝贵见解。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "16 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.22898v1",
      "published_date": "2024-10-30 10:57:46 UTC",
      "updated_date": "2024-10-30 10:57:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:06:46.931765"
    },
    {
      "arxiv_id": "2410.22891v1",
      "title": "VPO: Leveraging the Number of Votes in Preference Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Jae Hyeon Cho",
        "Minkyung Park",
        "Byung-Jun Lee"
      ],
      "abstract": "Direct Preference Optimization (DPO) trains a language model using human\npreference data, bypassing the explicit reward modeling phase of Reinforcement\nLearning from Human Feedback (RLHF). By iterating over sentence pairs in a\npreference dataset, DPO enhances generation quality by increasing the\nlikelihood of producing preferred sentences over less favored ones. Preference\ndatasets are typically created by selecting preferred sentences through a\nvoting process involving multiple individuals, as opinions can vary due to the\nsubjective nature of human preferences. While the number of votes offers\ninsight into whether a sentence pair is clearly preferable or controversial,\ncurrent methods do not fully leverage this information. In this paper, we\nintroduce a technique that leverages user voting data to better align with\ndiverse subjective preferences. We employ the Bayesian Minimum Mean Square\nError (Bayesian MMSE) estimator to model the probability that one generation is\npreferable to another. Using this estimated probability as a target, we develop\nthe Vote-based Preference Optimization (VPO) framework, which incorporates the\nnumber of votes on both sides to distinguish between controversial and obvious\ngeneration pairs. We show that previous algorithms, such as DPO and Identity\nPreference Optimization (IPO), can be extended using the proposed framework,\ntermed VDPO and VIPO. Our experiments demonstrate that these proposed\nalgorithms outperform various existing methods, including their base\nalgorithms.",
      "tldr_zh": "本文提出 VPO（Vote-based Preference Optimization）框架，通过利用偏好数据集中的投票数量来优化语言模型训练，解决 DPO（Direct Preference Optimization）等方法未充分利用主观偏好信息的问题。VPO 采用 Bayesian MMSE 估计器来建模一个生成是否优于另一个的概率，并据此区分争议性和明显的句子对，从而扩展 DPO 和 IPO（Identity Preference Optimization）为 VDPO 和 VIPO。实验结果表明，这些算法在性能上优于现有方法，提升了模型对多样化主观偏好的对齐能力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.22891v1",
      "published_date": "2024-10-30 10:39:34 UTC",
      "updated_date": "2024-10-30 10:39:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:06:58.156773"
    },
    {
      "arxiv_id": "2410.22886v2",
      "title": "Less is More: Pre-Training Cross-Lingual Small-Scale Language Models with Cognitively-Plausible Curriculum Learning Strategies",
      "title_zh": "翻译失败",
      "authors": [
        "Suchir Salhan",
        "Richard Diehl Martinez",
        "Zébulon Goriely",
        "Paula Buttery"
      ],
      "abstract": "Curriculum Learning has been a popular strategy to improve the cognitive\nplausibility of Small-Scale Language Models (SSLMs) in the BabyLM Challenge.\nHowever, it has not led to considerable improvements over non-curriculum\nmodels. We assess whether theoretical linguistic acquisition theories can be\nused to specify more fine-grained curriculum learning strategies, creating\nage-ordered corpora of Child-Directed Speech for four typologically distant\nlanguage families to implement SSLMs and acquisition-inspired curricula\ncross-lingually. Comparing the success of three objective curricula (Growing,\nInwards and MMM) that precisely replicate the predictions of acquisition\ntheories on a standard SSLM architecture, we find fine-grained\nacquisition-inspired curricula can outperform non-curriculum baselines and\nperformance benefits of curricula strategies in SSLMs can be derived by\nspecifying fine-grained language-specific curricula that precisely replicate\nlanguage acquisition theories.",
      "tldr_zh": "本研究评估了基于语言习得理论的精细课程学习策略，以提升 Small-Scale Language Models (SSLMs) 的性能，特别是针对 BabyLM Challenge。作者创建了针对四种类型学上不同的语言家族的年龄排序儿童导向语料库，并测试了三种目标课程（Growing, Inwards 和 MMM），这些课程精确复制了语言习得理论的预测。结果显示，这些精细的跨语言课程策略能够超越非课程基线，并在 SSLMs 中显著提升性能，尤其通过语言特定的设计来实现更佳效果。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "BabyLM Shared Task 2024 (Accepted, Poster), co-located in EMNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.22886v2",
      "published_date": "2024-10-30 10:31:54 UTC",
      "updated_date": "2025-02-21 11:11:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:08:38.471867"
    },
    {
      "arxiv_id": "2410.22884v1",
      "title": "Stealing User Prompts from Mixture of Experts",
      "title_zh": "翻译失败",
      "authors": [
        "Itay Yona",
        "Ilia Shumailov",
        "Jamie Hayes",
        "Nicholas Carlini"
      ],
      "abstract": "Mixture-of-Experts (MoE) models improve the efficiency and scalability of\ndense language models by routing each token to a small number of experts in\neach layer. In this paper, we show how an adversary that can arrange for their\nqueries to appear in the same batch of examples as a victim's queries can\nexploit Expert-Choice-Routing to fully disclose a victim's prompt. We\nsuccessfully demonstrate the effectiveness of this attack on a two-layer\nMixtral model, exploiting the tie-handling behavior of the torch.topk CUDA\nimplementation. Our results show that we can extract the entire prompt using\n$O({VM}^2)$ queries (with vocabulary size $V$ and prompt length $M$) or 100\nqueries on average per token in the setting we consider. This is the first\nattack to exploit architectural flaws for the purpose of extracting user\nprompts, introducing a new class of LLM vulnerabilities.",
      "tldr_zh": "该研究揭示了Mixture-of-Experts (MoE) 模型中的一个新安全漏洞，通过Expert-Choice-Routing机制，攻击者可以将自己的查询与受害者查询置于同一批次中，从而完全窃取受害者的用户提示。攻击利用torch.topk CUDA实现的tie-handling行为，在一个两层Mixtral模型上进行演示，平均每令牌只需约100查询即可提取整个提示，总查询量为O(VM^2)（V为词汇表大小，M为提示长度）。这项工作首次利用模型架构缺陷来提取用户提示，引入了LLM漏洞的新类别，并强调了MoE模型在隐私保护方面的潜在风险。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.22884v1",
      "published_date": "2024-10-30 10:25:35 UTC",
      "updated_date": "2024-10-30 10:25:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:08:49.844150"
    },
    {
      "arxiv_id": "2410.22883v2",
      "title": "Dataset Awareness is not Enough: Implementing Sample-level Tail Encouragement in Long-tailed Self-supervised Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Haowen Xiao",
        "Guanghui Liu",
        "Xinyi Gao",
        "Yang Li",
        "Fengmao Lv",
        "Jielei Chu"
      ],
      "abstract": "Self-supervised learning (SSL) has shown remarkable data representation\ncapabilities across a wide range of datasets. However, when applied to\nreal-world datasets with long-tailed distributions, performance on multiple\ndownstream tasks degrades significantly. Recently, the community has begun to\nfocus more on self-supervised long-tailed learning. Some works attempt to\ntransfer temperature mechanisms to self-supervised learning or use\ncategory-space uniformity constraints to balance the representation of\ndifferent categories in the embedding space to fight against long-tail\ndistributions. However, most of these approaches focus on the joint\noptimization of all samples in the dataset or on constraining the category\ndistribution, with little attention given to whether each individual sample is\noptimally guided during training. To address this issue, we propose Temperature\nAuxiliary Sample-level Encouragement (TASE). We introduce pseudo-labels into\nself-supervised long-tailed learning, utilizing pseudo-label information to\ndrive a dynamic temperature and re-weighting strategy. Specifically, We assign\nan optimal temperature parameter to each sample. Additionally, we analyze the\nlack of quantity awareness in the temperature parameter and use re-weighting to\ncompensate for this deficiency, thereby achieving optimal training patterns at\nthe sample level. Comprehensive experimental results on six benchmarks across\nthree datasets demonstrate that our method achieves outstanding performance in\nimproving long-tail recognition, while also exhibiting high robustness.",
      "tldr_zh": "这篇论文指出，现有的自监督学习（SSL）方法在长尾分布数据集上表现不佳，因为它们主要关注数据集整体优化或类别分布，而忽略了单个样本的训练引导。作者提出了一种新方法Temperature Auxiliary Sample-level Encouragement (TASE)，它利用伪标签驱动动态温度和重新加权策略，为每个样本分配最优温度参数，并通过重新加权补偿样本数量不足的问题，从而实现样本级别的优化训练。实验结果显示，TASE 在三个数据集的六个基准上显著提高了长尾识别性能，并展示了高鲁棒性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.22883v2",
      "published_date": "2024-10-30 10:25:22 UTC",
      "updated_date": "2024-11-15 04:16:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:09:02.541865"
    },
    {
      "arxiv_id": "2410.22881v2",
      "title": "SFA-UNet: More Attention to Multi-Scale Contrast and Contextual Information in Infrared Small Object Segmentation",
      "title_zh": "SFA-UNet：红外小目标分割中对多尺度对比和上下文信息的更多关注",
      "authors": [
        "Imad Ali Shah",
        "Fahad Mumtaz Malik",
        "Muhammad Waqas Ashraf"
      ],
      "abstract": "Computer vision researchers have extensively worked on fundamental infrared\nvisual recognition for the past few decades. Among various approaches, deep\nlearning has emerged as the most promising candidate. However, Infrared Small\nObject Segmentation (ISOS) remains a major focus due to several challenges\nincluding: 1) the lack of effective utilization of local contrast and global\ncontextual information; 2) the potential loss of small objects in deep models;\nand 3) the struggling to capture fine-grained details and ignore noise. To\naddress these challenges, we propose a modified U-Net architecture, named\nSFA-UNet, by combining Scharr Convolution (SC) and Fast Fourier Convolution\n(FFC) in addition to vertical and horizontal Attention gates (AG) into UNet.\nSFA-UNet utilizes double convolution layers with the addition of SC and FFC in\nits encoder and decoder layers. SC helps to learn the foreground-to-background\ncontrast information whereas FFC provide multi-scale contextual information\nwhile mitigating the small objects vanishing problem. Additionally, the\nintroduction of vertical AGs in encoder layers enhances the model's focus on\nthe targeted object by ignoring irrelevant regions. We evaluated the proposed\napproach on publicly available, SIRST and IRSTD datasets, and achieved superior\nperformance by an average 0.75% with variance of 0.025 of all combined metrics\nin multiple runs as compared to the existing state-of-the-art methods",
      "tldr_zh": "该论文针对红外小物体分割（Infrared Small Object Segmentation, ISOS）面临的挑战，如局部对比和全局上下文信息利用不足、小物体在深度模型中丢失以及捕捉细粒度细节的困难，提出了一种改进的 U-Net 架构，名为 SFA-UNet。SFA-UNet 在编码器和解码器中整合了 Scharr Convolution (SC) 和 Fast Fourier Convolution (FFC)，其中 SC 用于学习前景与背景的对比信息，FFC 提供多尺度上下文信息并缓解小物体消失问题；此外，还添加了垂直和水平 Attention gates (AG) 来增强模型对目标物体的关注并忽略无关区域。通过在 SIRST 和 IRSTD 等公开数据集上的实验，SFA-UNet 比现有最先进方法平均提高了 0.75% 的性能指标，方差为 0.025，展示了其有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted and Presented at PRIP 2023",
      "pdf_url": "http://arxiv.org/pdf/2410.22881v2",
      "published_date": "2024-10-30 10:21:23 UTC",
      "updated_date": "2024-11-16 14:10:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:09:15.029676"
    },
    {
      "arxiv_id": "2410.22874v1",
      "title": "Eliciting Critical Reasoning in Retrieval-Augmented Language Models via Contrastive Explanations",
      "title_zh": "通过对比解释在检索增强语言模型中激发批判性推理",
      "authors": [
        "Leonardo Ranaldi",
        "Marco Valentino",
        "Andrè Freitas"
      ],
      "abstract": "Retrieval-augmented generation (RAG) has emerged as a critical mechanism in\ncontemporary NLP to support Large Language Models(LLMs) in systematically\naccessing richer factual context. However, the integration of RAG mechanisms\nbrings its inherent challenges, as LLMs need to deal with potentially noisy\ncontexts. Recent studies have shown that LLMs still struggle to critically\nanalyse RAG-based in-context information, a limitation that may lead to\nincorrect inferences and hallucinations. In this paper, we investigate how to\nelicit critical reasoning in RAG via contrastive explanations. In particular,\nwe propose Contrastive-RAG (C-RAG), a framework that (i) retrieves relevant\ndocuments given a query, (ii) selects and exemplifies relevant passages, and\n(iii) generates explanations that explicitly contrast the relevance of the\npassages to (iv) support the final answer. We show the impact of C-RAG building\ncontrastive reasoning demonstrations from LLMs to instruct smaller models for\nretrieval-augmented tasks. Extensive experiments demonstrate that C-RAG\nimproves state-of-the-art RAG models while (a) requiring significantly fewer\nprompts and demonstrations and (b) being robust to perturbations in the\nretrieved documents.",
      "tldr_zh": "该研究探讨了如何通过对比性解释（contrastive explanations）在检索增强生成模型（RAG）中激发大型语言模型（LLMs）的批判性推理，以解决模型处理噪声上下文时可能出现的错误推理和幻觉问题。论文提出Contrastive-RAG（C-RAG）框架，该框架包括检索相关文档、选择并举例相关段落、生成显式对比解释以及支持最终答案，从而指导较小模型进行高效的检索增强任务。实验结果显示，C-RAG 显著提升了现有 RAG 模型的表现，同时减少了提示和演示的需求，并对检索文档的扰动表现出更强的鲁棒性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.22874v1",
      "published_date": "2024-10-30 10:11:53 UTC",
      "updated_date": "2024-10-30 10:11:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:09:26.634024"
    },
    {
      "arxiv_id": "2410.22870v5",
      "title": "Conditioned quantum-assisted deep generative surrogate for particle-calorimeter interactions",
      "title_zh": "用于粒子-热量计相互作用的条件化量子辅助深度生成代理模型",
      "authors": [
        "J. Quetzalcoatl Toledo-Marin",
        "Sebastian Gonzalez",
        "Hao Jia",
        "Ian Lu",
        "Deniz Sogutlu",
        "Abhishek Abhishek",
        "Colin Gay",
        "Eric Paquet",
        "Roger Melko",
        "Geoffrey C. Fox",
        "Maximilian Swiatlowski",
        "Wojciech Fedorko"
      ],
      "abstract": "Particle collisions at accelerators such as the Large Hadron Collider,\nrecorded and analyzed by experiments such as ATLAS and CMS, enable exquisite\nmeasurements of the Standard Model and searches for new phenomena. Simulations\nof collision events at these detectors have played a pivotal role in shaping\nthe design of future experiments and analyzing ongoing ones. However, the quest\nfor accuracy in Large Hadron Collider (LHC) collisions comes at an imposing\ncomputational cost, with projections estimating the need for millions of\nCPU-years annually during the High Luminosity LHC (HL-LHC) run\n\\cite{collaboration2022atlas}. Simulating a single LHC event with\n\\textsc{Geant4} currently devours around 1000 CPU seconds, with simulations of\nthe calorimeter subdetectors in particular imposing substantial computational\ndemands \\cite{rousseau2023experimental}. To address this challenge, we propose\na conditioned quantum-assisted deep generative model. Our model integrates a\nconditioned variational autoencoder (VAE) on the exterior with a conditioned\nRestricted Boltzmann Machine (RBM) in the latent space, providing enhanced\nexpressiveness compared to conventional VAEs. The RBM nodes and connections are\nmeticulously engineered to enable the use of qubits and couplers on D-Wave's\nPegasus-structured \\textit{Advantage} quantum annealer (QA) for sampling. We\nintroduce a novel method for conditioning the quantum-assisted RBM using\n\\textit{flux biases}. We further propose a novel adaptive mapping to estimate\nthe effective inverse temperature in quantum annealers. The effectiveness of\nour framework is illustrated using Dataset 2 of the CaloChallenge\n\\cite{calochallenge}.",
      "tldr_zh": "本研究针对粒子碰撞模拟（如Large Hadron Collider的ATLAS和CMS实验）的高计算成本问题，提出了一种条件化的量子辅助深度生成模型，作为粒子-热量计交互的替代方案。该模型结合了外部条件化变分自动编码器（VAE）和内部条件化Restricted Boltzmann Machine (RBM)，通过D-Wave's Advantage量子退火器（QA）的qubits和couplers进行采样，并引入flux biases进行条件化以及一种新颖的自适应映射来估计有效逆温度。实验在CaloChallenge的Dataset 2上验证了框架的有效性，展示了其在加速模拟方面的潜力，为High Luminosity LHC (HL-LHC)时代的高精度模拟提供高效解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "hep-ph",
        "physics.comp-ph",
        "physics.ins-det"
      ],
      "primary_category": "cs.LG",
      "comment": "27 pages, 10 figures, 8 appendices",
      "pdf_url": "http://arxiv.org/pdf/2410.22870v5",
      "published_date": "2024-10-30 10:08:03 UTC",
      "updated_date": "2024-12-18 21:25:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:09:39.080829"
    },
    {
      "arxiv_id": "2410.23323v1",
      "title": "Exploiting Phonological Similarities between African Languages to achieve Speech to Speech Translation",
      "title_zh": "翻译失败",
      "authors": [
        "Peter Ochieng",
        "Dennis Kaburu"
      ],
      "abstract": "This paper presents a pilot study on direct speech-to-speech translation\n(S2ST) by leveraging linguistic similarities among selected African languages\nwithin the same phylum, particularly in cases where traditional data annotation\nis expensive or impractical. We propose a segment-based model that maps speech\nsegments both within and across language phyla, effectively eliminating the\nneed for large paired datasets. By utilizing paired segments and guided\ndiffusion, our model enables translation between any two languages in the\ndataset. We evaluate the model on a proprietary dataset from the Kenya\nBroadcasting Corporation (KBC), which includes five languages: Swahili, Luo,\nKikuyu, Nandi, and English. The model demonstrates competitive performance in\nsegment pairing and translation quality, particularly for languages within the\nsame phylum. Our experiments reveal that segment length significantly\ninfluences translation accuracy, with average-length segments yielding the\nhighest pairing quality. Comparative analyses with traditional cascaded ASR-MT\ntechniques show that the proposed model delivers nearly comparable translation\nperformance. This study underscores the potential of exploiting linguistic\nsimilarities within language groups to perform efficient S2ST, especially in\nlow-resource language contexts.",
      "tldr_zh": "本研究探索了利用非洲语言之间语音学相似性（特别是同一语系语言）实现直接语音到语音翻译（S2ST），以应对传统数据标注成本高的问题。研究提出了一种基于段落的模型，通过配对段和 guided diffusion 技术映射语音段，从而无需大量配对数据集，并在数据集中的任何两种语言间实现翻译。在肯尼亚广播公司（KBC）的专有数据集上（包括 Swahili、Luo、Kikuyu、Nandi 和 English），模型在同一语系语言的段配对和翻译质量上表现出色，实验显示平均长度段的配对准确性最高，且性能与传统 ASR-MT 级联方法几乎相当。该方法突显了在低资源语言环境中利用语言组相似性的潜力，为高效 S2ST 提供新途径。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "eess.AS",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.23323v1",
      "published_date": "2024-10-30 09:44:52 UTC",
      "updated_date": "2024-10-30 09:44:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:09:51.791154"
    },
    {
      "arxiv_id": "2410.22839v2",
      "title": "Danoliteracy of Generative Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Søren Vejlgaard Holm",
        "Lars Kai Hansen",
        "Martin Carsten Nielsen"
      ],
      "abstract": "The language technology moonshot moment of Generative Large Language Models\n(GLLMs) was not limited to English: These models brought a surge of\ntechnological applications, investments, and hype to low-resource languages as\nwell. However, the capabilities of these models in languages such as Danish\nwere, until recently, difficult to verify beyond qualitative demonstrations due\nto a lack of applicable evaluation corpora. We present a GLLM benchmark to\nevaluate \\emph{Danoliteracy}, a measure of Danish language and cultural\ncompetency across eight diverse scenarios such as Danish citizenship tests and\nabstractive social media question answering. This limited-size benchmark was\nfound to produce a robust ranking that correlates to human feedback at $\\rho\n\\sim 0.8$ with GPT-4 and Claude Opus models achieving the highest rankings.\nAnalyzing these model results across scenarios, we find one strong underlying\nfactor explaining $95\\%$ of scenario performance variance for GLLMs in Danish,\nsuggesting a $g$ factor of model consistency in language adaptation.",
      "tldr_zh": "本研究评估了生成式大型语言模型（GLLMs）在丹麦语（Danoliteracy）的语言和文化能力，针对低资源语言的模型表现提出一个基准测试。基准测试涵盖八种多样场景，包括丹麦公民测试和抽象社交媒体问答，结果显示该测试与人类反馈的相关性高达 ρ ~ 0.8，且 GPT-4 和 Claude Opus 模型排名最高。分析发现，一个主要因素解释了95%的场景性能差异，揭示了 GLLMs 在语言适应中的一致性因子（g factor）。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "16 pages, 13 figures, Accepted to NoDaLiDa/Baltic-HLT 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.22839v2",
      "published_date": "2024-10-30 09:18:31 UTC",
      "updated_date": "2025-03-04 07:13:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:10:01.932835"
    },
    {
      "arxiv_id": "2410.22832v1",
      "title": "HijackRAG: Hijacking Attacks against Retrieval-Augmented Large Language Models",
      "title_zh": "HijackRAG：针对检索增强大型语言模型的劫持攻击",
      "authors": [
        "Yucheng Zhang",
        "Qinfeng Li",
        "Tianyu Du",
        "Xuhong Zhang",
        "Xinkui Zhao",
        "Zhengwen Feng",
        "Jianwei Yin"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) systems enhance large language models\n(LLMs) by integrating external knowledge, making them adaptable and\ncost-effective for various applications. However, the growing reliance on these\nsystems also introduces potential security risks. In this work, we reveal a\nnovel vulnerability, the retrieval prompt hijack attack (HijackRAG), which\nenables attackers to manipulate the retrieval mechanisms of RAG systems by\ninjecting malicious texts into the knowledge database. When the RAG system\nencounters target questions, it generates the attacker's pre-determined answers\ninstead of the correct ones, undermining the integrity and trustworthiness of\nthe system. We formalize HijackRAG as an optimization problem and propose both\nblack-box and white-box attack strategies tailored to different levels of the\nattacker's knowledge. Extensive experiments on multiple benchmark datasets show\nthat HijackRAG consistently achieves high attack success rates, outperforming\nexisting baseline attacks. Furthermore, we demonstrate that the attack is\ntransferable across different retriever models, underscoring the widespread\nrisk it poses to RAG systems. Lastly, our exploration of various defense\nmechanisms reveals that they are insufficient to counter HijackRAG, emphasizing\nthe urgent need for more robust security measures to protect RAG systems in\nreal-world deployments.",
      "tldr_zh": "该论文揭示了检索增强生成(RAG)系统的一种新型安全漏洞，名为HijackRAG攻击，通过向知识数据库注入恶意文本来操纵RAG系统的检索机制，导致它在遇到目标问题时输出攻击者预定的答案，从而破坏系统的完整性和可信度。研究者将HijackRAG形式化为优化问题，并提出黑盒和白盒攻击策略，针对不同攻击者知识水平进行优化。实验在多个基准数据集上证明，该攻击比现有基线方法具有更高的成功率，且可在不同检索器模型之间转移；此外，现有防御机制无法有效应对，强调了需要更强大的安全措施来保护RAG系统在实际部署中的可靠性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.22832v1",
      "published_date": "2024-10-30 09:15:51 UTC",
      "updated_date": "2024-10-30 09:15:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:10:15.322806"
    },
    {
      "arxiv_id": "2411.05809v2",
      "title": "Two pathways to resolve relational inconsistencies",
      "title_zh": "解决关系不一致性的两种途径",
      "authors": [
        "Tomer Barak",
        "Yonatan Loewenstein"
      ],
      "abstract": "When individuals encounter observations that violate their expectations, when\nwill they adjust their expectations and when will they maintain them despite\nthese observations? For example, when individuals expect objects of type A to\nbe smaller than objects B, but observe the opposite, when will they adjust\ntheir expectation about the relationship between the two objects (to A being\nlarger than B)? Naively, one would predict that the larger the violation, the\ngreater the adaptation. However, experiments reveal that when violations are\nextreme, individuals are more likely to hold on to their prior expectations\nrather than adjust them. To address this puzzle, we tested the adaptation of\nartificial neural networks (ANNs) capable of relational learning and found a\nsimilar phenomenon: Standard learning dynamics dictates that small violations\nwould lead to adjustments of expected relations while larger ones would be\nresolved using a different mechanism -- a change in object representation that\nbypasses the need for adaptation of the relational expectations. These results\nsuggest that the experimentally-observed stability of prior expectations when\nfacing large expectation violations is a natural consequence of learning\ndynamics and does not require any additional mechanisms. We conclude by\ndiscussing the effect of intermediate adaptation steps on this stability.",
      "tldr_zh": "这篇论文探讨了当观察违背预期时，个体（如人类）或系统（如 artificial neural networks, ANNs）如何处理关系不一致：小违反会导致关系预期的调整，而大违反则通过改变物体表示来绕过调整。研究通过实验测试了 ANNs 的适应性，发现这一现象是学习动态的自然结果，而非需额外机制。作者进一步讨论了中间适应步骤对预期稳定的影响，为理解认知和机器学习中的预期调整提供了新见解。",
      "categories": [
        "q-bio.NC",
        "cs.AI"
      ],
      "primary_category": "q-bio.NC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.05809v2",
      "published_date": "2024-10-30 08:52:50 UTC",
      "updated_date": "2025-03-26 10:06:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:10:26.628967"
    },
    {
      "arxiv_id": "2410.22815v1",
      "title": "Towards Robust and Efficient Federated Low-Rank Adaptation with Heterogeneous Clients",
      "title_zh": "翻译失败",
      "authors": [
        "Jabin Koo",
        "Minwoo Jang",
        "Jungseul Ok"
      ],
      "abstract": "Federated fine-tuning for Large Language Models (LLMs) has recently gained\nattention due to the heavy communication overhead of transmitting large model\nupdates. Low Rank Adaptation (LoRA) has been proposed as a solution, yet its\napplication in federated learning is complicated by discordance in aggregation.\nExisting methods addressing this discordance often suffer from performance\ndegradation at low ranks in heterogeneous data settings. In response, we\nintroduce LoRA-A2 (Low Rank Adaptation with Alternating freeze and Adaptive\nrank selection), which demonstrates robustness in challenging settings with low\nranks and high data heterogeneity. Our experimental findings reveal that\nLoRA-A2 maintains performance even under extreme heterogeneity and low rank\nconditions, achieving up to a 99.8% reduction in uploaded parameters compared\nto full fine-tuning without compromising performance. This adaptive mechanism\nboosts robustness and communication efficiency in federated fine-tuning,\nenabling the practical deployment of LLMs in resource-constrained environments.",
      "tldr_zh": "这篇论文针对联邦微调 Large Language Models (LLMs) 的通信开销问题，提出了一种鲁棒且高效的 Low Rank Adaptation (LoRA) 变体，即 LoRA-A2，以处理异构客户端的挑战。LoRA-A2 采用交替冻结和自适应秩选择机制，能够在低秩和高数据异构性条件下维持性能，避免现有方法的下降。实验结果显示，该方法在极端异构环境中实现高达 99.8% 的上传参数减少，同时不影响微调效果，从而提升了联邦微调的鲁棒性和通信效率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.22815v1",
      "published_date": "2024-10-30 08:48:21 UTC",
      "updated_date": "2024-10-30 08:48:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:10:39.288822"
    },
    {
      "arxiv_id": "2410.22812v1",
      "title": "Universality of the $π^2/6$ Pathway in Avoiding Model Collapse",
      "title_zh": "翻译失败",
      "authors": [
        "Apratim Dey",
        "David Donoho"
      ],
      "abstract": "Researchers in empirical machine learning recently spotlighted their fears of\nso-called Model Collapse. They imagined a discard workflow, where an initial\ngenerative model is trained with real data, after which the real data are\ndiscarded, and subsequently, the model generates synthetic data on which a new\nmodel is trained. They came to the conclusion that models degenerate as\nmodel-fitting generations proceed. However, other researchers considered an\naugment workflow, where the original real data continue to be used in each\ngeneration of training, augmented by synthetic data from models fit in all\nearlier generations. Empirical results on canonical datasets and learning\nprocedures confirmed the occurrence of model collapse under the discard\nworkflow and avoidance of model collapse under the augment workflow. Under the\naugment workflow, theoretical evidence also confirmed avoidance in particular\ninstances; specifically, Gerstgrasser et al. (2024) found that for classical\nLinear Regression, test risk at any later generation is bounded by a moderate\nmultiple, viz. pi-squared-over-6 of the test risk of training with the original\nreal data alone. Some commentators questioned the generality of theoretical\nconclusions based on the generative model assumed in Gerstgrasser et al.\n(2024): could similar conclusions be reached for other task/model pairings? In\nthis work, we demonstrate the universality of the pi-squared-over-6 augment\nrisk bound across a large family of canonical statistical models, offering key\ninsights into exactly why collapse happens under the discard workflow and is\navoided under the augment workflow. In the process, we provide a framework that\nis able to accommodate a large variety of workflows (beyond discard and\naugment), thereby enabling an experimenter to judge the comparative merits of\nmultiple different workflows by simulating a simple Gaussian process.",
      "tldr_zh": "本文研究了机器学习中的 Model Collapse 问题，证明了在 augment workflow（保留真实数据并增强合成数据）下，测试风险被 $π^2/6$ 倍界限，这在多种经典统计模型中具有普遍性。相比之下，discard workflow（丢弃真实数据）会导致模型退化。作者通过理论分析和一个通用框架（如模拟 Gaussian process），解释了崩溃的原因，并为评估不同工作流的优劣提供了新工具。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.ET",
        "math.ST",
        "stat.ML",
        "stat.TH"
      ],
      "primary_category": "cs.LG",
      "comment": "30 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.22812v1",
      "published_date": "2024-10-30 08:44:10 UTC",
      "updated_date": "2024-10-30 08:44:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:10:50.659899"
    },
    {
      "arxiv_id": "2410.22809v1",
      "title": "Causality-Enhanced Behavior Sequence Modeling in LLMs for Personalized Recommendation",
      "title_zh": "翻译失败",
      "authors": [
        "Yang Zhang",
        "Juntao You",
        "Yimeng Bai",
        "Jizhi Zhang",
        "Keqin Bao",
        "Wenjie Wang",
        "Tat-Seng Chua"
      ],
      "abstract": "Recent advancements in recommender systems have focused on leveraging Large\nLanguage Models (LLMs) to improve user preference modeling, yielding promising\noutcomes. However, current LLM-based approaches struggle to fully leverage user\nbehavior sequences, resulting in suboptimal preference modeling for\npersonalized recommendations. In this study, we propose a novel Counterfactual\nFine-Tuning (CFT) method to address this issue by explicitly emphasizing the\nrole of behavior sequences when generating recommendations. Specifically, we\nemploy counterfactual reasoning to identify the causal effects of behavior\nsequences on model output and introduce a task that directly fits the\nground-truth labels based on these effects, achieving the goal of explicit\nemphasis. Additionally, we develop a token-level weighting mechanism to adjust\nthe emphasis strength for different item tokens, reflecting the diminishing\ninfluence of behavior sequences from earlier to later tokens during predicting\nan item. Extensive experiments on real-world datasets demonstrate that CFT\neffectively improves behavior sequence modeling. Our codes are available at\nhttps://github.com/itsmeyjt/CFT.",
      "tldr_zh": "本研究针对Large Language Models (LLMs)在个性化推荐中的不足，提出了一种Counterfactual Fine-Tuning (CFT)方法，以显式强调用户行为序列对推荐生成的影响。CFT通过counterfactual reasoning识别行为序列的因果效应，并设计一个任务来直接拟合ground-truth标签，同时引入token-level weighting机制来调整不同item tokens的强调强度，反映行为序列影响的递减趋势。在真实数据集上的广泛实验表明，CFT显著提升了行为序列建模的性能，为LLMs-based推荐系统提供了有效改进路径。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.22809v1",
      "published_date": "2024-10-30 08:41:13 UTC",
      "updated_date": "2024-10-30 08:41:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:11:03.129012"
    },
    {
      "arxiv_id": "2410.22805v1",
      "title": "Run-Time Adaptation of Neural Beamforming for Robust Speech Dereverberation and Denoising",
      "title_zh": "翻译失败",
      "authors": [
        "Yoto Fujita",
        "Aditya Arie Nugraha",
        "Diego Di Carlo",
        "Yoshiaki Bando",
        "Mathieu Fontaine",
        "Kazuyoshi Yoshii"
      ],
      "abstract": "This paper describes speech enhancement for realtime automatic speech\nrecognition (ASR) in real environments. A standard approach to this task is to\nuse neural beamforming that can work efficiently in an online manner. It\nestimates the masks of clean dry speech from a noisy echoic mixture spectrogram\nwith a deep neural network (DNN) and then computes a enhancement filter used\nfor beamforming. The performance of such a supervised approach, however, is\ndrastically degraded under mismatched conditions. This calls for run-time\nadaptation of the DNN. Although the ground-truth speech spectrogram required\nfor adaptation is not available at run time, blind dereverberation and\nseparation methods such as weighted prediction error (WPE) and fast\nmultichannel nonnegative matrix factorization (FastMNMF) can be used for\ngenerating pseudo groundtruth data from a mixture. Based on this idea, a prior\nwork proposed a dual-process system based on a cascade of WPE and minimum\nvariance distortionless response (MVDR) beamforming asynchronously fine-tuned\nby block-online FastMNMF. To integrate the dereverberation capability into\nneural beamforming and make it fine-tunable at run time, we propose to use\nweighted power minimization distortionless response (WPD) beamforming, a\nunified version of WPE and minimum power distortionless response (MPDR), whose\njoint dereverberation and denoising filter is estimated using a DNN. We\nevaluated the impact of run-time adaptation under various conditions with\ndifferent numbers of speakers, reverberation times, and signal-to-noise ratios\n(SNRs).",
      "tldr_zh": "本研究针对实时自动语音识别（ASR）中的语音增强问题，提出了一种运行时适应（run-time adaptation）的神经波束形成（neural beamforming）方法，以提升对混响和噪声的鲁棒性。传统方法依赖深度神经网络（DNN）估计干净语音掩码并计算增强滤波器，但环境不匹配时性能急剧下降；为此，作者引入weighted power minimization distortionless response (WPD)波束形成，将weighted prediction error (WPE)和minimum power distortionless response (MPDR)统一起来，并使用DNN估计联合去混响和去噪滤波器，同时利用WPE和fast multichannel nonnegative matrix factorization (FastMNMF)生成伪真实数据进行在线微调。实验结果显示，该方法在不同说话者数量、混响时间和信噪比（SNR）条件下显著提高了语音增强效果，增强了系统的适应性和鲁棒性。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted to APSIPA2024",
      "pdf_url": "http://arxiv.org/pdf/2410.22805v1",
      "published_date": "2024-10-30 08:32:47 UTC",
      "updated_date": "2024-10-30 08:32:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:11:15.158316"
    },
    {
      "arxiv_id": "2410.22803v1",
      "title": "DOA-Aware Audio-Visual Self-Supervised Learning for Sound Event Localization and Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Yoto Fujita",
        "Yoshiaki Bando",
        "Keisuke Imoto",
        "Masaki Onishi",
        "Kazuyoshi Yoshii"
      ],
      "abstract": "This paper describes sound event localization and detection (SELD) for\nspatial audio recordings captured by firstorder ambisonics (FOA) microphones.\nIn this task, one may train a deep neural network (DNN) using FOA data\nannotated with the classes and directions of arrival (DOAs) of sound events.\nHowever, the performance of this approach is severely bounded by the amount of\nannotated data. To overcome this limitation, we propose a novel method of\npretraining the feature extraction part of the DNN in a self-supervised manner.\nWe use spatial audio-visual recordings abundantly available as virtual reality\ncontents. Assuming that sound objects are concurrently observed by the FOA\nmicrophones and the omni-directional camera, we jointly train audio and visual\nencoders with contrastive learning such that the audio and visual embeddings of\nthe same recording and DOA are made close. A key feature of our method is that\nthe DOA-wise audio embeddings are jointly extracted from the raw audio data,\nwhile the DOA-wise visual embeddings are separately extracted from the local\nvisual crops centered on the corresponding DOA. This encourages the latent\nfeatures of the audio encoder to represent both the classes and DOAs of sound\nevents. The experiment using the DCASE2022 Task 3 dataset of 20 hours shows\nnon-annotated audio-visual recordings of 100 hours reduced the error score of\nSELD from 36.4 pts to 34.9 pts.",
      "tldr_zh": "这篇论文提出了一种 DOA-Aware 的音频-视觉自监督学习方法，用于提升声音事件定位和检测 (SELD) 的性能，针对第一级 ambiophonics (FOA) 麦克风录制的空间音频数据。方法通过对比学习 (contrastive learning) 联合训练音频和视觉编码器，利用丰富的非标注音频-视觉记录（如虚拟现实内容）预训练 DNN 的特征提取部分，使同一 DOA 的音频和视觉嵌入更接近。关键创新在于从原始音频数据提取 DOA-wise 音频嵌入，并与对应 DOA 的局部视觉作物嵌入相结合，从而让音频编码器的潜在特征同时表示声音事件的类别和 DOA。实验在 DCASE2022 Task 3 数据集上显示，使用 100 小时非标注数据将 SELD 错误分数从 36.4 pts 降低到 34.9 pts，证明了该方法的有效性。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "cs.MM",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted to APSIPA2023",
      "pdf_url": "http://arxiv.org/pdf/2410.22803v1",
      "published_date": "2024-10-30 08:31:58 UTC",
      "updated_date": "2024-10-30 08:31:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:11:28.064263"
    },
    {
      "arxiv_id": "2410.22790v1",
      "title": "Dual Contrastive Transformer for Hierarchical Preference Modeling in Sequential Recommendation",
      "title_zh": "翻译失败",
      "authors": [
        "Chengkai Huang",
        "Shoujin Wang",
        "Xianzhi Wang",
        "Lina Yao"
      ],
      "abstract": "Sequential recommender systems (SRSs) aim to predict the subsequent items\nwhich may interest users via comprehensively modeling users' complex preference\nembedded in the sequence of user-item interactions. However, most of existing\nSRSs often model users' single low-level preference based on item ID\ninformation while ignoring the high-level preference revealed by item attribute\ninformation, such as item category. Furthermore, they often utilize limited\nsequence context information to predict the next item while overlooking richer\ninter-item semantic relations. To this end, in this paper, we proposed a novel\nhierarchical preference modeling framework to substantially model the complex\nlow- and high-level preference dynamics for accurate sequential recommendation.\nSpecifically, in the framework, a novel dual-transformer module and a novel\ndual contrastive learning scheme have been designed to discriminatively learn\nusers' low- and high-level preference and to effectively enhance both low- and\nhigh-level preference learning respectively. In addition, a novel\nsemantics-enhanced context embedding module has been devised to generate more\ninformative context embedding for further improving the recommendation\nperformance. Extensive experiments on six real-world datasets have demonstrated\nboth the superiority of our proposed method over the state-of-the-art ones and\nthe rationality of our design.",
      "tldr_zh": "该论文针对顺序推荐系统（Sequential Recommender Systems, SRSs）中存在的局限性，提出了一种分层偏好建模框架，以全面捕捉用户基于项目 ID 的低级偏好和基于项目属性（如类别）的高级偏好动态。具体而言，该框架引入了双 Transformer 模块和双对比学习方案，用于区分性学习和增强低级与高级偏好，同时设计了语义增强的上下文嵌入模块，以利用更丰富的项目间语义关系提升推荐性能。在六个真实数据集上的广泛实验证明，该方法优于现有最先进方法，并验证了其设计的合理性。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.22790v1",
      "published_date": "2024-10-30 08:09:33 UTC",
      "updated_date": "2024-10-30 08:09:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:11:38.493163"
    },
    {
      "arxiv_id": "2411.00848v1",
      "title": "Evaluating Evidential Reliability In Pattern Recognition Based On Intuitionistic Fuzzy Sets",
      "title_zh": "基于直觉模糊集的模式识别证据可靠性评估",
      "authors": [
        "Juntao Xu",
        "Tianxiang Zhan",
        "Yong Deng"
      ],
      "abstract": "Determining the reliability of evidence sources is a crucial topic in\nDempster-Shafer theory (DST). Previous approaches have addressed high conflicts\nbetween evidence sources using discounting methods, but these methods may not\nensure the high efficiency of classification models. In this paper, we consider\nthe combination of DS theory and Intuitionistic Fuzzy Sets (IFS) and propose an\nalgorithm for quantifying the reliability of evidence sources, called Fuzzy\nReliability Index (FRI). The FRI algorithm is based on decision quantification\nrules derived from IFS, defining the contribution of different BPAs to correct\ndecisions and deriving the evidential reliability from these contributions. The\nproposed method effectively enhances the rationality of reliability estimation\nfor evidence sources, making it particularly suitable for classification\ndecision problems in complex scenarios. Subsequent comparisons with DST-based\nalgorithms and classical machine learning algorithms demonstrate the\nsuperiority and generalizability of the FRI algorithm. The FRI algorithm\nprovides a new perspective for future decision probability conversion and\nreliability analysis of evidence sources.",
      "tldr_zh": "这篇论文针对Dempster-Shafer theory (DST)中证据来源可靠性的评估问题，提出了一种基于Intuitionistic Fuzzy Sets (IFS)的算法，称为Fuzzy Reliability Index (FRI)。FRI算法通过IFS派生的决策量化规则，定义基本概率分配 (BPAs) 对正确决策的贡献，从而量化证据来源的可靠性，提升了在复杂场景下分类决策的合理性。与传统DST算法和经典机器学习算法相比，实验结果证明FRI算法具有更高的优越性和泛化性，为未来的决策概率转换和证据可靠性分析提供了新视角。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "35 pages",
      "pdf_url": "http://arxiv.org/pdf/2411.00848v1",
      "published_date": "2024-10-30 08:05:26 UTC",
      "updated_date": "2024-10-30 08:05:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:11:50.954893"
    },
    {
      "arxiv_id": "2410.22784v2",
      "title": "Contrastive Learning and Adversarial Disentanglement for Task-Oriented Semantic Communications",
      "title_zh": "翻译失败",
      "authors": [
        "Omar Erak",
        "Omar Alhussein",
        "Wen Tong"
      ],
      "abstract": "Task-oriented semantic communication systems have emerged as a promising\napproach to achieving efficient and intelligent data transmission, where only\ninformation relevant to a specific task is communicated. However, existing\nmethods struggle to fully disentangle task-relevant and task-irrelevant\ninformation, leading to privacy concerns and subpar performance. To address\nthis, we propose an information-bottleneck method, named CLAD (contrastive\nlearning and adversarial disentanglement). CLAD utilizes contrastive learning\nto effectively capture task-relevant features while employing adversarial\ndisentanglement to discard task-irrelevant information. Additionally, due to\nthe lack of reliable and reproducible methods to gain insight into the\ninformativeness and minimality of the encoded feature vectors, we introduce a\nnew technique to compute the information retention index (IRI), a comparative\nmetric used as a proxy for the mutual information between the encoded features\nand the input, reflecting the minimality of the encoded features. The IRI\nquantifies the minimality and informativeness of the encoded feature vectors\nacross different task-oriented communication techniques. Our extensive\nexperiments demonstrate that CLAD outperforms state-of-the-art baselines in\nterms of semantic extraction, task performance, privacy preservation, and IRI.\nCLAD achieves a predictive performance improvement of around 2.5-3%, along with\na 77-90% reduction in IRI and a 57-76% decrease in adversarial attribute\ninference attack accuracy.",
      "tldr_zh": "该研究针对任务导向语义通信系统的问题，提出了一种名为 CLAD 的信息瓶颈方法，利用 contrastive learning 捕获任务相关特征，并通过 adversarial disentanglement 去除任务无关信息，从而提升数据传输效率并缓解隐私风险。CLAD 还引入了信息保留指数（IRI）作为一种新指标，用于量化编码特征向量的 informativeness 和 minimality，便于比较不同技术的性能。实验结果显示，CLAD 优于现有基线，在语义提取、任务性能和隐私保护方面表现突出，实现预测性能提升约 2.5-3%，IRI 降低 77-90%，并将对抗属性推断攻击准确率减少 57-76%。这项工作为高效、安全的语义通信提供了重要进展。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.IT",
        "eess.IV",
        "math.IT"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.22784v2",
      "published_date": "2024-10-30 07:59:52 UTC",
      "updated_date": "2025-04-25 11:17:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:13:24.352985"
    },
    {
      "arxiv_id": "2411.00049v1",
      "title": "Rule by Rule: Learning with Confidence through Vocabulary Expansion",
      "title_zh": "翻译失败",
      "authors": [
        "Albert Nössig",
        "Tobias Hell",
        "Georg Moser"
      ],
      "abstract": "In this paper, we present an innovative iterative approach to rule learning\nspecifically designed for (but not limited to) text-based data. Our method\nfocuses on progressively expanding the vocabulary utilized in each iteration\nresulting in a significant reduction of memory consumption. Moreover, we\nintroduce a Value of Confidence as an indicator of the reliability of the\ngenerated rules. By leveraging the Value of Confidence, our approach ensures\nthat only the most robust and trustworthy rules are retained, thereby improving\nthe overall quality of the rule learning process. We demonstrate the\neffectiveness of our method through extensive experiments on various textual as\nwell as non-textual datasets including a use case of significant interest to\ninsurance industries, showcasing its potential for real-world applications.",
      "tldr_zh": "本论文提出了一种创新的迭代规则学习方法，专注于文本数据（但不限于），通过逐步扩展词汇表来显著减少内存消耗。方法引入了 Value of Confidence 作为规则可靠性的指标，确保仅保留最稳健的规则，从而提升整体学习质量。在各种文本和非文本数据集上的广泛实验中，该方法展示了出色的效果，包括保险行业的实际应用潜力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "29 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.00049v1",
      "published_date": "2024-10-30 07:54:01 UTC",
      "updated_date": "2024-10-30 07:54:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:12:14.666816"
    },
    {
      "arxiv_id": "2410.22772v1",
      "title": "Reliability Assessment of Information Sources Based on Random Permutation Set",
      "title_zh": "基于随机置换集的信息来源可靠性评估",
      "authors": [
        "Juntao Xu",
        "Tianxiang Zhan",
        "Yong Deng"
      ],
      "abstract": "In pattern recognition, handling uncertainty is a critical challenge that\nsignificantly affects decision-making and classification accuracy.\nDempster-Shafer Theory (DST) is an effective reasoning framework for addressing\nuncertainty, and the Random Permutation Set (RPS) extends DST by additionally\nconsidering the internal order of elements, forming a more ordered extension of\nDST. However, there is a lack of a transformation method based on permutation\norder between RPS and DST, as well as a sequence-based probability\ntransformation method for RPS. Moreover, the reliability of RPS sources remains\nan issue that requires attention. To address these challenges, this paper\nproposes an RPS transformation approach and a probability transformation method\ntailored for RPS. On this basis, a reliability computation method for RPS\nsources, based on the RPS probability transformation, is introduced and applied\nto pattern recognition. Experimental results demonstrate that the proposed\napproach effectively bridges the gap between DST and RPS and achieves superior\nrecognition accuracy in classification problems.",
      "tldr_zh": "在模式识别领域，处理不确定性是关键挑战，Dempster-Shafer Theory (DST) 提供有效框架，而其扩展Random Permutation Set (RPS) 进一步考虑元素内部顺序，但缺乏相应的转换和可靠性评估方法。本文提出了一种基于置换顺序的RPS到DST转换方法，以及针对RPS的序列-based概率转换方法。在此基础上，开发了RPS来源的可靠性计算方法，并将其应用于模式识别。实验结果显示，该方法成功桥接DST和RPS，在分类问题中实现了更高的识别准确率。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.22772v1",
      "published_date": "2024-10-30 07:40:35 UTC",
      "updated_date": "2024-10-30 07:40:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:12:28.639729"
    },
    {
      "arxiv_id": "2410.22770v3",
      "title": "InjecGuard: Benchmarking and Mitigating Over-defense in Prompt Injection Guardrail Models",
      "title_zh": "翻译失败",
      "authors": [
        "Hao Li",
        "Xiaogeng Liu"
      ],
      "abstract": "Prompt injection attacks pose a critical threat to large language models\n(LLMs), enabling goal hijacking and data leakage. Prompt guard models, though\neffective in defense, suffer from over-defense -- falsely flagging benign\ninputs as malicious due to trigger word bias. To address this issue, we\nintroduce NotInject, an evaluation dataset that systematically measures\nover-defense across various prompt guard models. NotInject contains 339 benign\nsamples enriched with trigger words common in prompt injection attacks,\nenabling fine-grained evaluation. Our results show that state-of-the-art models\nsuffer from over-defense issues, with accuracy dropping close to random\nguessing levels (60%). To mitigate this, we propose InjecGuard, a novel prompt\nguard model that incorporates a new training strategy, Mitigating Over-defense\nfor Free (MOF), which significantly reduces the bias on trigger words.\nInjecGuard demonstrates state-of-the-art performance on diverse benchmarks\nincluding NotInject, surpassing the existing best model by 30.8%, offering a\nrobust and open-source solution for detecting prompt injection attacks. The\ncode and datasets are released at https://github.com/leolee99/InjecGuard.",
      "tldr_zh": "该论文探讨了prompt injection attacks对大型语言模型(LLMs)的威胁，特别是prompt guard models存在的over-defense问题，即错误地将无害输入标记为恶意，导致准确率降至随机猜测水平(约60%)。为了评估和缓解这一问题，研究者引入了NotInject数据集，包含339个带有常见trigger words的无害样本，用于细粒度评估over-defense。论文提出InjecGuard模型，采用Mitigating Over-defense for Free (MOF)训练策略来减少trigger word bias，并在多种基准测试中比现有最佳模型提升30.8%的性能，提供了一个开源的鲁棒解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.22770v3",
      "published_date": "2024-10-30 07:39:42 UTC",
      "updated_date": "2025-03-30 16:39:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:13:40.300030"
    },
    {
      "arxiv_id": "2410.22767v1",
      "title": "Beyond Ontology in Dialogue State Tracking for Goal-Oriented Chatbot",
      "title_zh": "翻译失败",
      "authors": [
        "Sejin Lee",
        "Dongha Kim",
        "Min Song"
      ],
      "abstract": "Goal-oriented chatbots are essential for automating user tasks, such as\nbooking flights or making restaurant reservations. A key component of these\nsystems is Dialogue State Tracking (DST), which interprets user intent and\nmaintains the dialogue state. However, existing DST methods often rely on fixed\nontologies and manually compiled slot values, limiting their adaptability to\nopen-domain dialogues. We propose a novel approach that leverages instruction\ntuning and advanced prompt strategies to enhance DST performance, without\nrelying on any predefined ontologies. Our method enables Large Language Model\n(LLM) to infer dialogue states through carefully designed prompts and includes\nan anti-hallucination mechanism to ensure accurate tracking in diverse\nconversation contexts. Additionally, we employ a Variational Graph Auto-Encoder\n(VGAE) to model and predict subsequent user intent. Our approach achieved\nstate-of-the-art with a JGA of 42.57% outperforming existing ontology-less DST\nmodels, and performed well in open-domain real-world conversations. This work\npresents a significant advancement in creating more adaptive and accurate\ngoal-oriented chatbots.",
      "tldr_zh": "本文提出了一种超越传统本体的对话状态跟踪 (DST) 方法，用于提升目标导向聊天机器人的适应性，避免依赖预定义本体。该方法通过指令微调和高级提示策略，让 Large Language Model (LLM) 推断对话状态，并引入反幻觉机制 (anti-hallucination mechanism) 确保准确性，同时利用 Variational Graph Auto-Encoder (VGAE) 建模和预测后续用户意图。实验结果显示，该方法在 JGA (Joint Goal Accuracy) 上达到 42.57%，优于现有无本体 DST 模型，并在开放域真实对话中表现出色，为创建更灵活准确的聊天机器人提供了重大进展。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "There are 10 chapters, including references, and 2 figures used. To\n  be presented at the 15th IEEE International Conference on Knowledge Graphs\n  (ICKG2024)",
      "pdf_url": "http://arxiv.org/pdf/2410.22767v1",
      "published_date": "2024-10-30 07:36:23 UTC",
      "updated_date": "2024-10-30 07:36:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:13:52.178057"
    },
    {
      "arxiv_id": "2410.22766v1",
      "title": "Self-Driving Car Racing: Application of Deep Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Florentiana Yuwono",
        "Gan Pang Yen",
        "Jason Christopher"
      ],
      "abstract": "This paper explores the application of deep reinforcement learning (RL)\ntechniques in the domain of autonomous self-driving car racing. Motivated by\nthe rise of AI-driven mobility and autonomous racing events, the project aims\nto develop an AI agent that efficiently drives a simulated car in the OpenAI\nGymnasium CarRacing environment. We investigate various RL algorithms,\nincluding Deep Q-Network (DQN), Proximal Policy Optimization (PPO), and novel\nadaptations that incorporate transfer learning and recurrent neural networks\n(RNNs) for enhanced performance. The project demonstrates that while DQN\nprovides a strong baseline for policy learning, integrating ResNet and LSTM\nmodels significantly improves the agent's ability to capture complex spatial\nand temporal dynamics. PPO, particularly in continuous action spaces, shows\npromising results for fine control, although challenges such as policy collapse\nremain. We compare the performance of these approaches and outline future\nresearch directions focused on improving computational efficiency and\naddressing model stability. Our findings contribute to the ongoing development\nof AI systems in autonomous driving and related control tasks.",
      "tldr_zh": "这篇论文探讨了深度强化学习（RL）在自动驾驶赛车中的应用，目标是开发一个 AI 代理，在 OpenAI Gymnasium CarRacing 环境中高效驾驶模拟赛车。研究调查了多种 RL 算法，包括 Deep Q-Network (DQN)、Proximal Policy Optimization (PPO)，以及结合转移学习和 Recurrent Neural Networks (RNNs) 的新适应，并通过整合 ResNet 和 LSTM 模型来提升代理捕捉复杂空间和时间动态的能力。结果表明，DQN 提供强有力的基线，而 PPO 在连续动作空间中表现出色，尽管面临政策崩溃等问题；论文比较了这些方法的性能，并为未来研究指出了提高计算效率和模型稳定性的方向。这些发现为自动驾驶和相关控制任务的 AI 系统发展提供了重要贡献。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.22766v1",
      "published_date": "2024-10-30 07:32:25 UTC",
      "updated_date": "2024-10-30 07:32:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:14:03.103526"
    },
    {
      "arxiv_id": "2410.22752v1",
      "title": "SoftCTRL: Soft conservative KL-control of Transformer Reinforcement Learning for Autonomous Driving",
      "title_zh": "翻译失败",
      "authors": [
        "Minh Tri Huynh",
        "Duc Dung Nguyen"
      ],
      "abstract": "In recent years, motion planning for urban self-driving cars (SDV) has become\na popular problem due to its complex interaction of road components. To tackle\nthis, many methods have relied on large-scale, human-sampled data processed\nthrough Imitation learning (IL). Although effective, IL alone cannot adequately\nhandle safety and reliability concerns. Combining IL with Reinforcement\nlearning (RL) by adding KL divergence between RL and IL policy to the RL loss\ncan alleviate IL's weakness but suffer from over-conservation caused by\ncovariate shift of IL. To address this limitation, we introduce a method that\ncombines IL with RL using an implicit entropy-KL control that offers a simple\nway to reduce the over-conservation characteristic. In particular, we validate\ndifferent challenging simulated urban scenarios from the unseen dataset,\nindicating that although IL can perform well in imitation tasks, our proposed\nmethod significantly improves robustness (over 17\\% reduction in failures) and\ngenerates human-like driving behavior.",
      "tldr_zh": "本研究提出SoftCTRL，一种结合Imitation Learning (IL) 和 Transformer Reinforcement Learning (RL) 的框架，用于提升自动驾驶中的运动规划。该方法通过Soft conservative KL-control和implicit entropy-KL control机制，减少了传统IL与RL结合时因covariate shift导致的over-conservation问题，从而提高安全性和可靠性。在模拟的复杂城市场景中，实验结果显示SoftCTRL比IL基准降低了17%以上的失败率，并生成更接近人类驾驶行为的策略。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "submitted to IEEE Open Journal of Intelligent Transportation Systems",
      "pdf_url": "http://arxiv.org/pdf/2410.22752v1",
      "published_date": "2024-10-30 07:18:00 UTC",
      "updated_date": "2024-10-30 07:18:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:14:13.375980"
    },
    {
      "arxiv_id": "2410.22744v1",
      "title": "Designing AI Personalities: Enhancing Human-Agent Interaction Through Thoughtful Persona Design",
      "title_zh": "翻译失败",
      "authors": [
        "Nima Zargham",
        "Mateusz Dubiel",
        "Smit Desai",
        "Thomas Mildner",
        "Hanz-Joachim Belz"
      ],
      "abstract": "In the rapidly evolving field of artificial intelligence (AI) agents,\ndesigning the agent's characteristics is crucial for shaping user experience.\nThis workshop aims to establish a research community focused on AI agent\npersona design for various contexts, such as in-car assistants, educational\ntools, and smart home environments. We will explore critical aspects of persona\ndesign, such as voice, embodiment, and demographics, and their impact on user\nsatisfaction and engagement. Through discussions and hands-on activities, we\naim to propose practices and standards that enhance the ecological validity of\nagent personas. Topics include the design of conversational interfaces, the\ninfluence of agent personas on user experience, and approaches for creating\ncontextually appropriate AI agents. This workshop will provide a platform for\nbuilding a community dedicated to developing AI agent personas that better fit\ndiverse, everyday interactions.",
      "tldr_zh": "该论文探讨了AI代理人格设计的重要性，以提升人类-代理互动的用户体验。研讨会旨在建立一个专注于不同情境（如车载助手、教育工具和智能家居）的AI agent persona设计研究社区，涵盖关键方面如voice、embodiment和demographics对用户满意度和参与度的影响。通过讨论和hands-on activities，提出增强生态有效性的实践和标准。最终，该工作为创建contextually appropriate AI agents提供平台，促进更适合多样化日常互动的代理设计。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "8 pages, the workshop accepted at the 23rd International Conference\n  on Mobile and Ubiquitous Multimedia (MUM 2024)",
      "pdf_url": "http://arxiv.org/pdf/2410.22744v1",
      "published_date": "2024-10-30 06:58:59 UTC",
      "updated_date": "2024-10-30 06:58:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:14:26.129616"
    },
    {
      "arxiv_id": "2410.22732v1",
      "title": "st-DTPM: Spatial-Temporal Guided Diffusion Transformer Probabilistic Model for Delayed Scan PET Image Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Ran Hong",
        "Yuxia Huang",
        "Lei Liu",
        "Zhonghui Wu",
        "Bingxuan Li",
        "Xuemei Wang",
        "Qiegen Liu"
      ],
      "abstract": "PET imaging is widely employed for observing biological metabolic activities\nwithin the human body. However, numerous benign conditions can cause increased\nuptake of radiopharmaceuticals, confounding differentiation from malignant\ntumors. Several studies have indicated that dual-time PET imaging holds promise\nin distinguishing between malignant and benign tumor processes. Nevertheless,\nthe hour-long distribution period of radiopharmaceuticals post-injection\ncomplicates the determination of optimal timing for the second scan, presenting\nchallenges in both practical applications and research. Notably, we have\nidentified that delay time PET imaging can be framed as an image-to-image\nconversion problem. Motivated by this insight, we propose a novel\nspatial-temporal guided diffusion transformer probabilistic model (st-DTPM) to\nsolve dual-time PET imaging prediction problem. Specifically, this architecture\nleverages the U-net framework that integrates patch-wise features of CNN and\npixel-wise relevance of Transformer to obtain local and global information. And\nthen employs a conditional DDPM model for image synthesis. Furthermore, on\nspatial condition, we concatenate early scan PET images and noisy PET images on\nevery denoising step to guide the spatial distribution of denoising sampling.\nOn temporal condition, we convert diffusion time steps and delay time to a\nuniversal time vector, then embed it to each layer of model architecture to\nfurther improve the accuracy of predictions. Experimental results demonstrated\nthe superiority of our method over alternative approaches in preserving image\nquality and structural information, thereby affirming its efficacy in\npredictive task.",
      "tldr_zh": "本文提出st-DTPM模型，用于解决延迟扫描PET图像预测问题，帮助区分恶性和良性肿瘤。该模型基于U-net框架，结合CNN的patch-wise特征和Transformer的pixel-wise相关性，获取局部和全局信息，并采用条件DDPM进行图像合成。同时，通过空间条件（如拼接早期PET图像和噪声图像于每个去噪步骤）和时间条件（如将扩散时间步骤和延迟时间转换为嵌入向量）来提升预测准确性。实验结果表明，st-DTPM在保持图像质量和结构信息方面优于其他方法。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.22732v1",
      "published_date": "2024-10-30 06:37:55 UTC",
      "updated_date": "2024-10-30 06:37:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:14:40.571656"
    },
    {
      "arxiv_id": "2410.22728v1",
      "title": "Offline Behavior Distillation",
      "title_zh": "离线行为蒸馏",
      "authors": [
        "Shiye Lei",
        "Sen Zhang",
        "Dacheng Tao"
      ],
      "abstract": "Massive reinforcement learning (RL) data are typically collected to train\npolicies offline without the need for interactions, but the large data volume\ncan cause training inefficiencies. To tackle this issue, we formulate offline\nbehavior distillation (OBD), which synthesizes limited expert behavioral data\nfrom sub-optimal RL data, enabling rapid policy learning. We propose two naive\nOBD objectives, DBC and PBC, which measure distillation performance via the\ndecision difference between policies trained on distilled data and either\noffline data or a near-expert policy. Due to intractable bi-level optimization,\nthe OBD objective is difficult to minimize to small values, which deteriorates\nPBC by its distillation performance guarantee with quadratic discount\ncomplexity $\\mathcal{O}(1/(1-\\gamma)^2)$. We theoretically establish the\nequivalence between the policy performance and action-value weighted decision\ndifference, and introduce action-value weighted PBC (Av-PBC) as a more\neffective OBD objective. By optimizing the weighted decision difference, Av-PBC\nachieves a superior distillation guarantee with linear discount complexity\n$\\mathcal{O}(1/(1-\\gamma))$. Extensive experiments on multiple D4RL datasets\nreveal that Av-PBC offers significant improvements in OBD performance, fast\ndistillation convergence speed, and robust cross-architecture/optimizer\ngeneralization.",
      "tldr_zh": "该论文提出Offline Behavior Distillation (OBD) 方法，从次优强化学习 (RL) 数据中合成有限的专家行为数据，以加速离线策略训练，解决海量数据导致的训练低效问题。作者定义了两个基本OBD目标DBC和PBC，通过比较策略决策差异评估性能，但这些目标因双层优化和二次折扣复杂度$\\mathcal{O}(1/(1-\\gamma)^2)$而难以优化。论文建立了策略性能与行动价值加权决策差异的等价性，引入了更有效的Av-PBC目标，实现线性折扣复杂度$\\mathcal{O}(1/(1-\\gamma))$的性能保证，并在D4RL数据集上的实验中展示了Av-PBC的显著性能提升、快速收敛和跨架构/优化器的鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.22728v1",
      "published_date": "2024-10-30 06:28:09 UTC",
      "updated_date": "2024-10-30 06:28:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:14:53.464989"
    },
    {
      "arxiv_id": "2411.00845v1",
      "title": "End-to-end Graph Learning Approach for Cognitive Diagnosis of Student Tutorial",
      "title_zh": "翻译失败",
      "authors": [
        "Fulai Yang",
        "Di Wu",
        "Yi He",
        "Li Tao",
        "Xin Luo"
      ],
      "abstract": "Cognitive diagnosis (CD) utilizes students' existing studying records to\nestimate their mastery of unknown knowledge concepts, which is vital for\nevaluating their learning abilities. Accurate CD is extremely challenging\nbecause CD is associated with complex relationships and mechanisms among\nstudents, knowledge concepts, studying records, etc. However, existing\napproaches loosely consider these relationships and mechanisms by a\nnon-end-to-end learning framework, resulting in sub-optimal feature extractions\nand fusions for CD. Different from them, this paper innovatively proposes an\nEnd-to-end Graph Neural Networks-based Cognitive Diagnosis (EGNN-CD) model.\nEGNN-CD consists of three main parts: knowledge concept network (KCN), graph\nneural networks-based feature extraction (GNNFE), and cognitive ability\nprediction (CAP). First, KCN constructs CD-related interaction by\ncomprehensively extracting physical information from students, exercises, and\nknowledge concepts. Second, a four-channel GNNFE is designed to extract\nhigh-order and individual features from the constructed KCN. Finally, CAP\nemploys a multi-layer perceptron to fuse the extracted features to predict\nstudents' learning abilities in an end-to-end learning way. With such designs,\nthe feature extractions and fusions are guaranteed to be comprehensive and\noptimal for CD. Extensive experiments on three real datasets demonstrate that\nour EGNN-CD achieves significantly higher accuracy than state-of-the-art models\nin CD.",
      "tldr_zh": "本文提出了一种端到端图学习方法，名为 End-to-end Graph Neural Networks-based Cognitive Diagnosis (EGNN-CD)，用于评估学生的认知诊断（CD），通过构建知识概念网络 (KCN) 来全面提取学生、练习和知识概念间的交互关系。模型包括四通道的图神经网络特征提取 (GNNFE) 来获取高阶和个体特征，以及认知能力预测 (CAP) 模块，利用多层感知器融合这些特征，实现端到端学习以优化诊断准确性。实验在三个真实数据集上显示，EGNN-CD 比现有最先进模型的准确率显著提升，证明了其在学生学习能力评估中的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.00845v1",
      "published_date": "2024-10-30 06:18:47 UTC",
      "updated_date": "2024-10-30 06:18:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:15:05.686945"
    },
    {
      "arxiv_id": "2410.22707v1",
      "title": "Robotic State Recognition with Image-to-Text Retrieval Task of Pre-Trained Vision-Language Model and Black-Box Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Kento Kawaharazuka",
        "Yoshiki Obinata",
        "Naoaki Kanazawa",
        "Kei Okada",
        "Masayuki Inaba"
      ],
      "abstract": "State recognition of the environment and objects, such as the open/closed\nstate of doors and the on/off of lights, is indispensable for robots that\nperform daily life support and security tasks. Until now, state recognition\nmethods have been based on training neural networks from manual annotations,\npreparing special sensors for the recognition, or manually programming to\nextract features from point clouds or raw images. In contrast, we propose a\nrobotic state recognition method using a pre-trained vision-language model,\nwhich is capable of Image-to-Text Retrieval (ITR) tasks. We prepare several\nkinds of language prompts in advance, calculate the similarity between these\nprompts and the current image by ITR, and perform state recognition. By\napplying the optimal weighting to each prompt using black-box optimization,\nstate recognition can be performed with higher accuracy. Experiments show that\nthis theory enables a variety of state recognitions by simply preparing\nmultiple prompts without retraining neural networks or manual programming. In\naddition, since only prompts and their weights need to be prepared for each\nrecognizer, there is no need to prepare multiple models, which facilitates\nresource management. It is possible to recognize the open/closed state of\ntransparent doors, the state of whether water is running or not from a faucet,\nand even the qualitative state of whether a kitchen is clean or not, which have\nbeen challenging so far, through language.",
      "tldr_zh": "该论文提出了一种机器人状态识别方法，利用预训练视觉语言模型（pre-trained vision-language model）的 Image-to-Text Retrieval (ITR) 任务，通过准备多种语言提示并计算其与当前图像的相似度来实现识别。方法进一步应用 black-box optimization 对提示权重进行优化，提升了识别准确率，避免了传统方法的神经网络重新训练或手动编程需求。实验结果显示，这种方法能有效识别透明门开/关状态、水龙头是否流水以及厨房清洁度等挑战性任务，并简化了资源管理。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted at Humanoids2024",
      "pdf_url": "http://arxiv.org/pdf/2410.22707v1",
      "published_date": "2024-10-30 05:34:52 UTC",
      "updated_date": "2024-10-30 05:34:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:15:15.599875"
    },
    {
      "arxiv_id": "2410.22695v1",
      "title": "Permutation Invariant Learning with High-Dimensional Particle Filters",
      "title_zh": "基于",
      "authors": [
        "Akhilan Boopathy",
        "Aneesh Muppidi",
        "Peggy Yang",
        "Abhiram Iyer",
        "William Yue",
        "Ila Fiete"
      ],
      "abstract": "Sequential learning in deep models often suffers from challenges such as\ncatastrophic forgetting and loss of plasticity, largely due to the permutation\ndependence of gradient-based algorithms, where the order of training data\nimpacts the learning outcome. In this work, we introduce a novel\npermutation-invariant learning framework based on high-dimensional particle\nfilters. We theoretically demonstrate that particle filters are invariant to\nthe sequential ordering of training minibatches or tasks, offering a principled\nsolution to mitigate catastrophic forgetting and loss-of-plasticity. We develop\nan efficient particle filter for optimizing high-dimensional models, combining\nthe strengths of Bayesian methods with gradient-based optimization. Through\nextensive experiments on continual supervised and reinforcement learning\nbenchmarks, including SplitMNIST, SplitCIFAR100, and ProcGen, we empirically\nshow that our method consistently improves performance, while reducing variance\ncompared to standard baselines.",
      "tldr_zh": "本研究针对深度模型在顺序学习中的灾难性遗忘（catastrophic forgetting）和损失可塑性（loss of plasticity）问题，提出了一种基于高维粒子滤波器（high-dimensional particle filters）的排列不变学习框架，以消除训练数据顺序对学习结果的影响。理论上，该框架证明了粒子滤波器对训练小批量或任务顺序的固有不变性，从而有效缓解上述挑战，并结合了贝叶斯方法与基于梯度的优化来高效处理高维模型。通过在持续监督学习和强化学习基准（如SplitMNIST、SplitCIFAR100和ProcGen）上的广泛实验，该方法显著提高了性能并降低了方差，优于标准基线。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Website: https://aneeshers.github.io/PermutationInvariantLearning/",
      "pdf_url": "http://arxiv.org/pdf/2410.22695v1",
      "published_date": "2024-10-30 05:06:55 UTC",
      "updated_date": "2024-10-30 05:06:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:15:28.246223"
    },
    {
      "arxiv_id": "2411.02530v1",
      "title": "A Comprehensive Study on Quantization Techniques for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jiedong Lang",
        "Zhehao Guo",
        "Shuyu Huang"
      ],
      "abstract": "Large Language Models (LLMs) have been extensively researched and used in\nboth academia and industry since the rise in popularity of the Transformer\nmodel, which demonstrates excellent performance in AI. However, the\ncomputational demands of LLMs are immense, and the energy resources required to\nrun them are often limited. For instance, popular models like GPT-3, with 175\nbillion parameters and a storage requirement of 350 GB, present significant\nchallenges for deployment on resource-constrained IoT devices and embedded\nsystems. These systems often lack the computational capacity to handle such\nlarge models. Quantization, a technique that reduces the precision of model\nvalues to a smaller set of discrete values, offers a promising solution by\nreducing the size of LLMs and accelerating inference. In this research, we\nprovide a comprehensive analysis of quantization techniques within the machine\nlearning field, with a particular focus on their application to LLMs. We begin\nby exploring the mathematical theory of quantization, followed by a review of\ncommon quantization methods and how they are implemented. Furthermore, we\nexamine several prominent quantization methods applied to LLMs, detailing their\nalgorithms and performance outcomes.",
      "tldr_zh": "本研究探讨了Large Language Models (LLMs) 的量化技术问题，强调这些基于Transformer模型的AI系统因参数量巨大（如GPT-3的175亿参数和350GB存储）而难以部署在资源受限的IoT设备和嵌入式系统中。Quantization作为一种降低模型值精度的技术，能有效减小模型规模并加速推理，从而缓解计算需求。论文通过分析Quantization的数学理论、常见方法及其实现，重点考察了应用于LLMs的突出量化算法及其性能结果，提供了一个全面的指南。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.02530v1",
      "published_date": "2024-10-30 04:55:26 UTC",
      "updated_date": "2024-10-30 04:55:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:16:36.859705"
    },
    {
      "arxiv_id": "2410.22690v3",
      "title": "Choice Between Partial Trajectories: Disentangling Goals from Beliefs",
      "title_zh": "部分轨迹之间的选择：从信念中分离目标",
      "authors": [
        "Henrik Marklund",
        "Benjamin Van Roy"
      ],
      "abstract": "As AI agents generate increasingly sophisticated behaviors, manually encoding\nhuman preferences to guide these agents becomes more challenging. To address\nthis, it has been suggested that agents instead learn preferences from human\nchoice data. This approach requires a model of choice behavior that the agent\ncan use to interpret the data. For choices between partial trajectories of\nstates and actions, previous models assume choice probabilities are determined\nby the partial return or the cumulative advantage.\n  We consider an alternative model based instead on the bootstrapped return,\nwhich adds to the partial return an estimate of the future return. Benefits of\nthe bootstrapped return model stem from its treatment of human beliefs. Unlike\npartial return, choices based on bootstrapped return reflect human beliefs\nabout the environment. Further, while recovering the reward function from\nchoices based on cumulative advantage requires that those beliefs are correct,\ndoing so from choices based on bootstrapped return does not.\n  To motivate the bootstrapped return model, we formulate axioms and prove an\nAlignment Theorem. This result formalizes how, for a general class of\npreferences, such models are able to disentangle goals from beliefs. This\nensures recovery of an aligned reward function when learning from choices based\non bootstrapped return.\n  The bootstrapped return model also affords greater robustness to choice\nbehavior. Even when choices are based on partial return, learning via a\nbootstrapped return model recovers an aligned reward function. The same holds\nwith choices based on the cumulative advantage if the human and the agent both\nadhere to correct and consistent beliefs about the environment. On the other\nhand, if choices are based on bootstrapped return, learning via partial return\nor cumulative advantage models does not generally produce an aligned reward\nfunction.",
      "tldr_zh": "该论文探讨了 AI 代理从人类选择数据中学习偏好的问题，提出了一种基于 bootstrapped return 的模型，作为对传统 partial return 或 cumulative advantage 模型的替代。该模型通过估计未来回报来反映人类对环境的信念，从而在从选择数据中恢复奖励函数时，能够有效分离 goals 和 beliefs，并通过 Alignment Theorem 证明其对齐性。相比其他模型，bootstrapped return 模型更具鲁棒性，即使人类选择基于 partial return 或 cumulative advantage，也能恢复对齐的奖励函数，从而提升 AI 代理的学习可靠性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.22690v3",
      "published_date": "2024-10-30 04:52:22 UTC",
      "updated_date": "2024-12-21 13:42:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:16:13.696705"
    },
    {
      "arxiv_id": "2410.23320v1",
      "title": "Lina-Speech: Gated Linear Attention is a Fast and Parameter-Efficient Learner for text-to-speech synthesis",
      "title_zh": "Lina-Speech：门控线性注意力是一种快速且参数高效的学习器，用于文本到语音合成",
      "authors": [
        "Théodor Lemerle",
        "Harrison Vanderbyl",
        "Vaibhav Srivastav",
        "Nicolas Obin",
        "Axel Roebel"
      ],
      "abstract": "Neural codec language models have achieved state-of-the-art performance in\ntext-to-speech (TTS) synthesis, leveraging scalable architectures like\nautoregressive transformers and large-scale speech datasets. By framing voice\ncloning as a prompt continuation task, these models excel at cloning voices\nfrom short audio samples. However, this approach is limited in its ability to\nhandle numerous or lengthy speech excerpts, since the concatenation of source\nand target speech must fall within the maximum context length which is\ndetermined during training. In this work, we introduce Lina-Speech, a model\nthat replaces traditional self-attention mechanisms with emerging recurrent\narchitectures like Gated Linear Attention (GLA). Building on the success of\ninitial-state tuning on RWKV, we extend this technique to voice cloning,\nenabling the use of multiple speech samples and full utilization of the context\nwindow in synthesis. This approach is fast, easy to deploy, and achieves\nperformance comparable to fine-tuned baselines when the dataset size ranges\nfrom 3 to 15 minutes. Notably, Lina-Speech matches or outperforms\nstate-of-the-art baseline models, including some with a parameter count up to\nfour times higher or trained in an end-to-end style. We release our code and\ncheckpoints. Audio samples are available at\nhttps://theodorblackbird.github.io/blog/demo_lina/.",
      "tldr_zh": "本文提出Lina-Speech模型，使用Gated Linear Attention (GLA)替换传统自注意力机制，旨在提升text-to-speech (TTS)合成的速度和参数效率。该模型通过扩展初始状态调整技术，支持处理多个语音样本并充分利用上下文窗口，从而解决现有方法在处理冗长语音时的限制。在3到15分钟的数据集上，Lina-Speech的性能与参数多达四倍的端到端基线模型相当或更优，并实现快速部署，代码和音频样本已公开。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "Preprint",
      "pdf_url": "http://arxiv.org/pdf/2410.23320v1",
      "published_date": "2024-10-30 04:50:40 UTC",
      "updated_date": "2024-10-30 04:50:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:16:06.983184"
    },
    {
      "arxiv_id": "2410.22689v1",
      "title": "Multi-Task Interactive Robot Fleet Learning with Visual World Models",
      "title_zh": "翻译失败",
      "authors": [
        "Huihan Liu",
        "Yu Zhang",
        "Vaarij Betala",
        "Evan Zhang",
        "James Liu",
        "Crystal Ding",
        "Yuke Zhu"
      ],
      "abstract": "Recent advancements in large-scale multi-task robot learning offer the\npotential for deploying robot fleets in household and industrial settings,\nenabling them to perform diverse tasks across various environments. However,\nAI-enabled robots often face challenges with generalization and robustness when\nexposed to real-world variability and uncertainty. We introduce Sirius-Fleet, a\nmulti-task interactive robot fleet learning framework to address these\nchallenges. Sirius-Fleet monitors robot performance during deployment and\ninvolves humans to correct the robot's actions when necessary. We employ a\nvisual world model to predict the outcomes of future actions and build anomaly\npredictors to predict whether they will likely result in anomalies. As the\nrobot autonomy improves, the anomaly predictors automatically adapt their\nprediction criteria, leading to fewer requests for human intervention and\ngradually reducing human workload over time. Evaluations on large-scale\nbenchmarks demonstrate Sirius-Fleet's effectiveness in improving multi-task\npolicy performance and monitoring accuracy. We demonstrate Sirius-Fleet's\nperformance in both RoboCasa in simulation and Mutex in the real world, two\ndiverse, large-scale multi-task benchmarks. More information is available on\nthe project website: https://ut-austin-rpl.github.io/sirius-fleet",
      "tldr_zh": "该研究引入了 Sirius-Fleet 框架，用于多任务交互式机器人群学习，旨在提升机器人面对真实世界变异性和不确定性的泛化和鲁棒性。框架利用 visual world models 预测未来行动结果，并构建 anomaly predictors 来识别潜在异常，同时通过人类干预纠正机器人行为，并随着机器人自主性提升自动调整预测标准，从而减少人类工作量。在 RoboCasa 模拟和 Mutex 真实世界基准测试中，Sirius-Fleet 显著提高了多任务策略性能和监控准确性，证明了其在家庭和工业环境中的有效性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "In Proceedings of CoRL 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.22689v1",
      "published_date": "2024-10-30 04:49:39 UTC",
      "updated_date": "2024-10-30 04:49:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:18:14.970848"
    },
    {
      "arxiv_id": "2410.22685v1",
      "title": "Improving Uncertainty Quantification in Large Language Models via Semantic Embeddings",
      "title_zh": "通过语义嵌入改进大型语言模型的不确定性量化",
      "authors": [
        "Yashvir S. Grewal",
        "Edwin V. Bonilla",
        "Thang D. Bui"
      ],
      "abstract": "Accurately quantifying uncertainty in large language models (LLMs) is crucial\nfor their reliable deployment, especially in high-stakes applications. Current\nstate-of-the-art methods for measuring semantic uncertainty in LLMs rely on\nstrict bidirectional entailment criteria between multiple generated responses\nand also depend on sequence likelihoods. While effective, these approaches\noften overestimate uncertainty due to their sensitivity to minor wording\ndifferences, additional correct information, and non-important words in the\nsequence. We propose a novel approach that leverages semantic embeddings to\nachieve smoother and more robust estimation of semantic uncertainty in LLMs. By\ncapturing semantic similarities without depending on sequence likelihoods, our\nmethod inherently reduces any biases introduced by irrelevant words in the\nanswers. Furthermore, we introduce an amortised version of our approach by\nexplicitly modelling semantics as latent variables in a joint probabilistic\nmodel. This allows for uncertainty estimation in the embedding space with a\nsingle forward pass, significantly reducing computational overhead compared to\nexisting multi-pass methods. Experiments across multiple question-answering\ndatasets and frontier LLMs demonstrate that our embedding-based methods provide\nmore accurate and nuanced uncertainty quantification than traditional\napproaches.",
      "tldr_zh": "这篇论文针对大型语言模型(LLMs)的不确定性量化问题，指出现有方法依赖严格的双向蕴含(bidirectional entailment)和序列似然(sequence likelihoods)，易因细微措辞差异或无关词而高估不确定性。作者提出了一种新方法，利用语义嵌入(semantic embeddings)来实现更平滑和鲁棒的语义不确定性估计，从而减少偏差。进一步，他们引入了摊销版本(amortised version)，通过将语义建模为潜变量(latent variables)在联合概率模型中，仅需单次前向传递即可降低计算开销。实验在多个问答数据集和前沿LLMs上证明，该方法提供比传统方法更准确和细致的不确定性量化。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.22685v1",
      "published_date": "2024-10-30 04:41:46 UTC",
      "updated_date": "2024-10-30 04:41:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:16:30.467706"
    },
    {
      "arxiv_id": "2411.00844v1",
      "title": "Extralonger: Toward a Unified Perspective of Spatial-Temporal Factors for Extra-Long-Term Traffic Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Zhiwei Zhang",
        "Shaojun E",
        "Fandong Meng",
        "Jie Zhou",
        "Wenjuan Han"
      ],
      "abstract": "Traffic forecasting plays a key role in Intelligent Transportation Systems,\nand significant strides have been made in this field. However, most existing\nmethods can only predict up to four hours in the future, which doesn't quite\nmeet real-world demands. we identify that the prediction horizon is limited to\na few hours mainly due to the separation of temporal and spatial factors, which\nresults in high complexity. Drawing inspiration from Albert Einstein's\nrelativity theory, which suggests space and time are unified and inseparable,\nwe introduce Extralonger, which unifies temporal and spatial factors.\nExtralonger notably extends the prediction horizon to a week on real-world\nbenchmarks, demonstrating superior efficiency in the training time, inference\ntime, and memory usage. It sets new standards in long-term and extra-long-term\nscenarios. The code is available at https://github.com/PlanckChang/Extralonger.",
      "tldr_zh": "该论文指出，现有的交通预测方法因将空间(spatial)和时间(temporal)因素分离，导致预测时限仅限于几小时，无法满足实际需求。受爱因斯坦相对论启发，作者提出 Extralonger 框架，将 spatial-temporal factors 统一起来，从而显著扩展预测时限至一周。实验结果显示，Extralonger 在真实世界基准上提升了训练时间、推理时间和内存使用效率，并在长期和 extra-long-term 交通预测场景中设定了新标准，代码已开源。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by NeurIPS2024 workshop",
      "pdf_url": "http://arxiv.org/pdf/2411.00844v1",
      "published_date": "2024-10-30 04:28:20 UTC",
      "updated_date": "2024-10-30 04:28:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:16:41.143664"
    },
    {
      "arxiv_id": "2411.05025v1",
      "title": "LLMs as Research Tools: A Large Scale Survey of Researchers' Usage and Perceptions",
      "title_zh": "翻译失败",
      "authors": [
        "Zhehui Liao",
        "Maria Antoniak",
        "Inyoung Cheong",
        "Evie Yu-Yen Cheng",
        "Ai-Heng Lee",
        "Kyle Lo",
        "Joseph Chee Chang",
        "Amy X. Zhang"
      ],
      "abstract": "The rise of large language models (LLMs) has led many researchers to consider\ntheir usage for scientific work. Some have found benefits using LLMs to augment\nor automate aspects of their research pipeline, while others have urged caution\ndue to risks and ethical concerns. Yet little work has sought to quantify and\ncharacterize how researchers use LLMs and why. We present the first large-scale\nsurvey of 816 verified research article authors to understand how the research\ncommunity leverages and perceives LLMs as research tools. We examine\nparticipants' self-reported LLM usage, finding that 81% of researchers have\nalready incorporated LLMs into different aspects of their research workflow. We\nalso find that traditionally disadvantaged groups in academia (non-White,\njunior, and non-native English speaking researchers) report higher LLM usage\nand perceived benefits, suggesting potential for improved research equity.\nHowever, women, non-binary, and senior researchers have greater ethical\nconcerns, potentially hindering adoption.",
      "tldr_zh": "这篇论文通过对816名验证研究人员的首次大规模调查，探讨了大语言模型(LLMs)作为科研工具的使用情况和认知。调查结果显示，81%的研究人员已将LLMs融入研究工作流程的不同环节中。传统上处于劣势的群体（如非白人、初级研究人员和非母语英语者）报告了更高的LLMs使用率和感知益处，这可能有助于改善学术公平性。然而，女性、非二元性别和资深研究人员表达了更大的伦理担忧，这可能阻碍LLMs的进一步采用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.DL",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "30 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.05025v1",
      "published_date": "2024-10-30 04:25:23 UTC",
      "updated_date": "2024-10-30 04:25:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:16:52.803471"
    },
    {
      "arxiv_id": "2411.00843v2",
      "title": "The Graph's Apprentice: Teaching an LLM Low Level Knowledge for Circuit Quality Estimation",
      "title_zh": "翻译失败",
      "authors": [
        "Reza Moravej",
        "Saurabh Bodhe",
        "Zhanguang Zhang",
        "Didier Chetelat",
        "Dimitrios Tsaras",
        "Yingxue Zhang",
        "Hui-Ling Zhen",
        "Jianye Hao",
        "Mingxuan Yuan"
      ],
      "abstract": "Logic synthesis is a crucial phase in the circuit design process, responsible\nfor transforming hardware description language (HDL) designs into optimized\nnetlists. However, traditional logic synthesis methods are computationally\nintensive, restricting their iterative use in refining chip designs. Recent\nadvancements in large language models (LLMs), particularly those fine-tuned on\nprogramming languages, present a promising alternative. This work proposes\naugmenting LLMs with predictor networks trained to estimate circuit quality\ndirectly from HDL code. To enhance performance, the model is regularized using\nembeddings from graph neural networks (GNNs) trained on Look-Up Table (LUT)\ngraphs, thereby incorporating lower-level circuit insights. The proposed method\ndemonstrates superior performance compared to existing graph-based RTL-level\nestimation techniques on the established benchmark OpenABCD, while providing\ninstant feedback on HDL code quality.",
      "tldr_zh": "该研究针对电路设计中的逻辑综合问题，提出了一种增强大型语言模型（LLMs）的方法，通过训练预测器网络从硬件描述语言（HDL）代码直接估计电路质量，以克服传统方法的计算密集性。该方法利用图神经网络（GNNs）从查找表（LUT）图中提取低级电路洞见，并通过嵌入正则化来提升模型性能。在OpenABCD基准测试中，该方法优于现有基于图的RTL级估计技术，并提供即时HDL代码质量反馈，从而加速芯片设计迭代过程。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.AR",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.00843v2",
      "published_date": "2024-10-30 04:20:10 UTC",
      "updated_date": "2025-02-14 18:35:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:17:03.865807"
    },
    {
      "arxiv_id": "2410.22678v1",
      "title": "Backdoor Attack Against Vision Transformers via Attention Gradient-Based Image Erosion",
      "title_zh": "针对视觉变压器的后门攻击：通过基于注意力梯度的图像侵蚀",
      "authors": [
        "Ji Guo",
        "Hongwei Li",
        "Wenbo Jiang",
        "Guoming Lu"
      ],
      "abstract": "Vision Transformers (ViTs) have outperformed traditional Convolutional Neural\nNetworks (CNN) across various computer vision tasks. However, akin to CNN, ViTs\nare vulnerable to backdoor attacks, where the adversary embeds the backdoor\ninto the victim model, causing it to make wrong predictions about testing\nsamples containing a specific trigger. Existing backdoor attacks against ViTs\nhave the limitation of failing to strike an optimal balance between attack\nstealthiness and attack effectiveness.\n  In this work, we propose an Attention Gradient-based Erosion Backdoor (AGEB)\ntargeted at ViTs. Considering the attention mechanism of ViTs, AGEB selectively\nerodes pixels in areas of maximal attention gradient, embedding a covert\nbackdoor trigger. Unlike previous backdoor attacks against ViTs, AGEB achieves\nan optimal balance between attack stealthiness and attack effectiveness,\nensuring the trigger remains invisible to human detection while preserving the\nmodel's accuracy on clean samples. Extensive experimental evaluations across\nvarious ViT architectures and datasets confirm the effectiveness of AGEB,\nachieving a remarkable Attack Success Rate (ASR) without diminishing Clean Data\nAccuracy (CDA). Furthermore, the stealthiness of AGEB is rigorously validated,\ndemonstrating minimal visual discrepancies between the clean and the triggered\nimages.",
      "tldr_zh": "这篇论文针对 Vision Transformers (ViTs) 提出了一种新的后门攻击方法，名为 Attention Gradient-based Erosion Backdoor (AGEB)，旨在解决现有攻击在隐蔽性和有效性之间平衡不足的问题。AGEB 通过分析 ViTs 的注意力机制，选择性地侵蚀图像中最大注意力梯度区域的像素，从而嵌入隐蔽的后门触发器，确保触发器对人类难以察觉同时保持模型在干净样本上的准确性。实验结果显示，在多种 ViT 架构和数据集上，AGEB 实现了高攻击成功率 (ASR) 而不降低干净数据准确率 (CDA)，并验证了其隐蔽性表现优异。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by IEEE GLOBECOM 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.22678v1",
      "published_date": "2024-10-30 04:06:12 UTC",
      "updated_date": "2024-10-30 04:06:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:17:16.386268"
    },
    {
      "arxiv_id": "2410.22669v1",
      "title": "A Walsh Hadamard Derived Linear Vector Symbolic Architecture",
      "title_zh": "翻译失败",
      "authors": [
        "Mohammad Mahmudul Alam",
        "Alexander Oberle",
        "Edward Raff",
        "Stella Biderman",
        "Tim Oates",
        "James Holt"
      ],
      "abstract": "Vector Symbolic Architectures (VSAs) are one approach to developing\nNeuro-symbolic AI, where two vectors in $\\mathbb{R}^d$ are `bound' together to\nproduce a new vector in the same space. VSAs support the commutativity and\nassociativity of this binding operation, along with an inverse operation,\nallowing one to construct symbolic-style manipulations over real-valued\nvectors. Most VSAs were developed before deep learning and automatic\ndifferentiation became popular and instead focused on efficacy in hand-designed\nsystems. In this work, we introduce the Hadamard-derived linear Binding (HLB),\nwhich is designed to have favorable computational efficiency, and efficacy in\nclassic VSA tasks, and perform well in differentiable systems. Code is\navailable at\nhttps://github.com/FutureComputing4AI/Hadamard-derived-Linear-Binding",
      "tldr_zh": "Vector Symbolic Architectures (VSAs) 是一种 Neuro-symbolic AI 方法，通过在 \\(\\mathbb{R}^d\\) 空间中绑定两个向量来生成新向量，并支持绑定的交换性、结合性和逆操作，从而在实值向量上进行符号式操作。本文提出 Hadamard-derived linear Binding (HLB)，这是一种基于 Walsh Hadamard 变换的线性绑定技术，旨在提高计算效率，同时在经典 VSA 任务和可微系统中表现出色。与传统 VSAs 不同，HLB 更适合深度学习环境，并提供了开源代码以供进一步验证。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "To appear in the 38th Conference on Neural Information Processing\n  Systems (NeurIPS 2024)",
      "pdf_url": "http://arxiv.org/pdf/2410.22669v1",
      "published_date": "2024-10-30 03:42:59 UTC",
      "updated_date": "2024-10-30 03:42:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:17:30.118844"
    },
    {
      "arxiv_id": "2410.22662v2",
      "title": "EMOS: Embodiment-aware Heterogeneous Multi-robot Operating System with LLM Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Junting Chen",
        "Checheng Yu",
        "Xunzhe Zhou",
        "Tianqi Xu",
        "Yao Mu",
        "Mengkang Hu",
        "Wenqi Shao",
        "Yikai Wang",
        "Guohao Li",
        "Lin Shao"
      ],
      "abstract": "Heterogeneous multi-robot systems (HMRS) have emerged as a powerful approach\nfor tackling complex tasks that single robots cannot manage alone. Current\nlarge-language-model-based multi-agent systems (LLM-based MAS) have shown\nsuccess in areas like software development and operating systems, but applying\nthese systems to robot control presents unique challenges. In particular, the\ncapabilities of each agent in a multi-robot system are inherently tied to the\nphysical composition of the robots, rather than predefined roles. To address\nthis issue, we introduce a novel multi-agent framework designed to enable\neffective collaboration among heterogeneous robots with varying embodiments and\ncapabilities, along with a new benchmark named Habitat-MAS. One of our key\ndesigns is $\\textit{Robot Resume}$: Instead of adopting human-designed role\nplay, we propose a self-prompted approach, where agents comprehend robot URDF\nfiles and call robot kinematics tools to generate descriptions of their physics\ncapabilities to guide their behavior in task planning and action execution. The\nHabitat-MAS benchmark is designed to assess how a multi-agent framework handles\ntasks that require embodiment-aware reasoning, which includes 1) manipulation,\n2) perception, 3) navigation, and 4) comprehensive multi-floor object\nrearrangement. The experimental results indicate that the robot's resume and\nthe hierarchical design of our multi-agent system are essential for the\neffective operation of the heterogeneous multi-robot system within this\nintricate problem context.",
      "tldr_zh": "该研究提出 EMOS，一种基于 LLM Agents 的异构多机器人操作系统 (Heterogeneous Multi-robot Systems, HMRS)，旨在处理单一机器人无法完成的复杂任务，通过 embodiment-aware reasoning 实现机器人间的有效协作。核心创新是 Robot Resume 方法，代理通过分析机器人 URDF 文件和调用运动学工具，自行生成物理能力描述，以指导任务规划和执行，而非依赖预定义角色。研究还引入了 Habitat-MAS 基准，用于评估多智能体框架在操纵、感知、导航和多层物体重新排列等任务中的性能。实验结果表明，Robot Resume 和系统的层次化设计显著提升了 HMRS 的运作效率和有效性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.MA",
        "I.2.7; I.2.8; I.2.9; I.2.10"
      ],
      "primary_category": "cs.RO",
      "comment": "10 pages of main content, 3 pages of references, 5 pages of appendix,\n  7 figures in total",
      "pdf_url": "http://arxiv.org/pdf/2410.22662v2",
      "published_date": "2024-10-30 03:20:01 UTC",
      "updated_date": "2025-02-17 08:33:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:18:26.903858"
    },
    {
      "arxiv_id": "2410.22658v2",
      "title": "Incremental Learning of Retrievable Skills For Efficient Continual Task Adaptation",
      "title_zh": "增量学习可检索技能以实现高效持续任务适应",
      "authors": [
        "Daehee Lee",
        "Minjong Yoo",
        "Woo Kyung Kim",
        "Wonje Choi",
        "Honguk Woo"
      ],
      "abstract": "Continual Imitation Learning (CiL) involves extracting and accumulating task\nknowledge from demonstrations across multiple stages and tasks to achieve a\nmulti-task policy. With recent advancements in foundation models, there has\nbeen a growing interest in adapter-based CiL approaches, where adapters are\nestablished parameter-efficiently for tasks newly demonstrated. While these\napproaches isolate parameters for specific tasks and tend to mitigate\ncatastrophic forgetting, they limit knowledge sharing among different\ndemonstrations. We introduce IsCiL, an adapter-based CiL framework that\naddresses this limitation of knowledge sharing by incrementally learning\nshareable skills from different demonstrations, thus enabling sample-efficient\ntask adaptation using the skills particularly in non-stationary CiL\nenvironments. In IsCiL, demonstrations are mapped into the state embedding\nspace, where proper skills can be retrieved upon input states through\nprototype-based memory. These retrievable skills are incrementally learned on\ntheir corresponding adapters. Our CiL experiments with complex tasks in\nFranka-Kitchen and Meta-World demonstrate robust performance of IsCiL in both\ntask adaptation and sample-efficiency. We also show a simple extension of IsCiL\nfor task unlearning scenarios.",
      "tldr_zh": "该论文提出 IsCiL，一种基于 adapter 的 Continual Imitation Learning (CiL) 框架，通过从不同演示中增量学习可共享的 retrievable skills，实现高效的任务适应并缓解知识共享的限制，尤其在非平稳环境中。IsCiL 将演示映射到状态嵌入空间，并使用 prototype-based 记忆检索适当技能，这些技能在对应适配器上进行增量学习。实验结果显示，在 Franka-Kitchen 和 Meta-World 的复杂任务中，IsCiL 表现出色，提高了任务适应和样本效率，并支持任务 unlearning 场景的扩展。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.22658v2",
      "published_date": "2024-10-30 02:57:35 UTC",
      "updated_date": "2025-01-21 01:37:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:18:39.969965"
    },
    {
      "arxiv_id": "2410.22642v1",
      "title": "Prove Your Point!: Bringing Proof-Enhancement Principles to Argumentative Essay Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Ruiyu Xiao",
        "Lei Wu",
        "Yuhang Gou",
        "Weinan Zhang",
        "Ting Liu"
      ],
      "abstract": "Argumentative essay generation (AEG) aims to generate complete texts on\nspecific controversial topics or debates. Although current AEG methods can\ngenerate individual opinions, they often overlook the high-level connections\nbetween these opinions. This often leads to the generated results being mired\nin logical confusion, unable to proof their own arguments effectively. The\ngenerated essay may present evidence that contradicts the claims or they may\nfail to assemble the claims into logical flow. In this paper, we present a\nunified two-stage framework: Proof-Enhancement and Self-Annotation (PESA) for\nAEG with a focus on logical enhancement. Specifically, we first construct\npseudo-labels for logical information,claims and grounds, using a large\nlanguage model. We then propose a tree planning approach that introduces proof\nprinciples and ensures logical consistency. Extensive experimental results show\nthat, benefiting from proof principle guidance, PESA generates argumentative\nessays with better logical validity and persuasiveness than strong baseline\nmodels.",
      "tldr_zh": "本文针对争论性论文生成 (AEG) 的问题，指出现有方法虽能生成个别观点，但常忽略观点间的高层连接，导致逻辑混乱和论点证明无效。论文提出一个统一的二阶段框架：Proof-Enhancement and Self-Annotation (PESA)，首先使用大语言模型构建伪标签（包括逻辑信息、论点和依据），然后采用树状规划方法引入证明原则，确保生成的论文逻辑一致性。实验结果显示，PESA 生成的争论性论文在逻辑有效性和说服力上明显优于强基线模型。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.22642v1",
      "published_date": "2024-10-30 02:13:39 UTC",
      "updated_date": "2024-10-30 02:13:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:18:51.112535"
    },
    {
      "arxiv_id": "2411.00841v1",
      "title": "A Theoretical Perspective for Speculative Decoding Algorithm",
      "title_zh": "翻译失败",
      "authors": [
        "Ming Yin",
        "Minshuo Chen",
        "Kaixuan Huang",
        "Mengdi Wang"
      ],
      "abstract": "Transformer-based autoregressive sampling has been the major bottleneck for\nslowing down large language model inferences. One effective way to accelerate\ninference is \\emph{Speculative Decoding}, which employs a small model to sample\na sequence of draft tokens and a large model to validate. Given its empirical\neffectiveness, the theoretical understanding of Speculative Decoding is falling\nbehind. This paper tackles this gap by conceptualizing the decoding problem via\nmarkov chain abstraction and studying the key properties, \\emph{output quality\nand inference acceleration}, from a theoretical perspective. Our analysis\ncovers the theoretical limits of speculative decoding, batch algorithms, and\noutput quality-inference acceleration tradeoffs. Our results reveal the\nfundamental connections between different components of LLMs via total\nvariation distances and show how they jointly affect the efficiency of decoding\nalgorithms.",
      "tldr_zh": "本研究从理论角度探讨了Speculative Decoding算法，该算法通过使用小型模型生成草稿序列并由大型模型验证，来加速Transformer-based autoregressive sampling在大型语言模型推理中的瓶颈问题。作者采用Markov chain抽象来概念化解码过程，分析了输出质量和推理加速的关键属性，包括算法的理论极限、批量算法以及二者间的权衡。结果揭示了LLM不同组件之间的基本联系，通过total variation distances阐明了这些组件如何共同影响解码算法的效率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.00841v1",
      "published_date": "2024-10-30 01:53:04 UTC",
      "updated_date": "2024-10-30 01:53:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:19:01.939096"
    },
    {
      "arxiv_id": "2410.22631v2",
      "title": "DECRL: A Deep Evolutionary Clustering Jointed Temporal Knowledge Graph Representation Learning Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Qian Chen",
        "Ling Chen"
      ],
      "abstract": "Temporal Knowledge Graph (TKG) representation learning aims to map temporal\nevolving entities and relations to embedded representations in a continuous\nlow-dimensional vector space. However, existing approaches cannot capture the\ntemporal evolution of high-order correlations in TKGs. To this end, we propose\na Deep Evolutionary Clustering jointed temporal knowledge graph Representation\nLearning approach (DECRL). Specifically, a deep evolutionary clustering module\nis proposed to capture the temporal evolution of high-order correlations among\nentities. Furthermore, a cluster-aware unsupervised alignment mechanism is\nintroduced to ensure the precise one-to-one alignment of soft overlapping\nclusters across timestamps, thereby maintaining the temporal smoothness of\nclusters. In addition, an implicit correlation encoder is introduced to capture\nlatent correlations between any pair of clusters under the guidance of a global\ngraph. Extensive experiments on seven real-world datasets demonstrate that\nDECRL achieves the state-of-the-art performances, outperforming the best\nbaseline by an average of 9.53%, 12.98%, 10.42%, and 14.68% in MRR, Hits@1,\nHits@3, and Hits@10, respectively.",
      "tldr_zh": "本研究提出 DECRL，一种结合深度进化聚类(Deep Evolutionary Clustering)和 Temporal Knowledge Graph (TKG) 表示学习的框架，旨在捕捉 TKG 中实体和关系的高阶相关性时间演变。DECRL 包括一个深度进化聚类模块来处理高阶相关性的动态变化、一个聚类感知的无监督对齐机制确保不同时间戳的软重叠聚类精确对齐以维持时间平滑性，以及一个隐式相关性编码器在全局图指导下捕捉成对聚类间的潜在相关性。在七个真实数据集上的实验中，DECRL 显著优于现有基线，平均提升 MRR 9.53%、Hits@1 12.98%、Hits@3 10.42% 和 Hits@10 14.68%。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by NeurIPS 2024, 17 pages, and 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.22631v2",
      "published_date": "2024-10-30 01:36:06 UTC",
      "updated_date": "2024-12-19 02:31:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:19:15.053249"
    },
    {
      "arxiv_id": "2411.04138v1",
      "title": "NetworkGym: Reinforcement Learning Environments for Multi-Access Traffic Management in Network Simulation",
      "title_zh": "NetworkGym：用于网络模拟中的多接入流量管理的强化学习环境",
      "authors": [
        "Momin Haider",
        "Ming Yin",
        "Menglei Zhang",
        "Arpit Gupta",
        "Jing Zhu",
        "Yu-Xiang Wang"
      ],
      "abstract": "Mobile devices such as smartphones, laptops, and tablets can often connect to\nmultiple access networks (e.g., Wi-Fi, LTE, and 5G) simultaneously. Recent\nadvancements facilitate seamless integration of these connections below the\ntransport layer, enhancing the experience for apps that lack inherent\nmulti-path support. This optimization hinges on dynamically determining the\ntraffic distribution across networks for each device, a process referred to as\n\\textit{multi-access traffic splitting}. This paper introduces\n\\textit{NetworkGym}, a high-fidelity network environment simulator that\nfacilitates generating multiple network traffic flows and multi-access traffic\nsplitting. This simulator facilitates training and evaluating different\nRL-based solutions for the multi-access traffic splitting problem. Our initial\nexplorations demonstrate that the majority of existing state-of-the-art offline\nRL algorithms (e.g. CQL) fail to outperform certain hand-crafted heuristic\npolicies on average. This illustrates the urgent need to evaluate offline RL\nalgorithms against a broader range of benchmarks, rather than relying solely on\npopular ones such as D4RL. We also propose an extension to the TD3+BC\nalgorithm, named Pessimistic TD3 (PTD3), and demonstrate that it outperforms\nmany state-of-the-art offline RL algorithms. PTD3's behavioral constraint\nmechanism, which relies on value-function pessimism, is theoretically motivated\nand relatively simple to implement.",
      "tldr_zh": "本研究引入了NetworkGym，一种高保真网络模拟环境，用于训练和评估强化学习（RL）算法在多访问流量管理（如Wi-Fi、LTE和5G）中的应用，焦点在于动态的multi-access traffic splitting问题。NetworkGym能生成多种网络流量场景，帮助测试RL解决方案的性能。初步实验显示，现有的离线RL算法（如CQL）平均不如手工启发式策略有效，突显了扩展基准测试（如D4RL以外）的必要性。该研究还提出PTD3算法的扩展，利用价值函数的悲观机制，表现出色，并在理论上易于实现。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NI",
      "comment": "NeurIPS (Datasets and Benchmarks)",
      "pdf_url": "http://arxiv.org/pdf/2411.04138v1",
      "published_date": "2024-10-30 01:14:33 UTC",
      "updated_date": "2024-10-30 01:14:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:19:26.853812"
    },
    {
      "arxiv_id": "2410.22619v2",
      "title": "Efficient Feature Extraction and Classification Architecture for MRI-Based Brain Tumor Detection and Localization",
      "title_zh": "基于 MRI 的脑肿瘤检测和定位的高效特征提取与分类架构",
      "authors": [
        "Plabon Paul",
        "Md. Nazmul Islam",
        "Fazle Rafsani",
        "Pegah Khorasani",
        "Shovito Barua Soumma"
      ],
      "abstract": "Uncontrolled cell division in the brain is what gives rise to brain tumors.\nIf the tumor size increases by more than half, there is little hope for the\npatient's recovery. This emphasizes the need of rapid and precise brain tumor\ndiagnosis. When it comes to analyzing, diagnosing, and planning therapy for\nbrain tumors, MRI imaging plays a crucial role. A brain tumor's development\nhistory is crucial information for doctors to have. When it comes to\ndistinguishing between human soft tissues, MRI scans are superior. In order to\nget reliable classification results from MRI scans quickly, deep learning is\none of the most practical methods. Early human illness diagnosis has been\ndemonstrated to be more accurate when deep learning methods are used. In the\ncase of diagnosing a brain tumor, when even a little misdiagnosis might have\nserious consequences, accuracy is especially important. Disclosure of brain\ntumors in medical images is still a difficult task. Brain MRIs are notoriously\nimprecise in revealing the presence or absence of tumors. Using MRI scans of\nthe brain, a CNN was trained to identify the presence of a tumor in this\nresearch. Results from the CNN model showed an accuracy of 99.17%. The CNN\nmodel's characteristics were also retrieved. The CNN model's characteristics\nwere also retrieved and we also localized the tumor regions from the\nunannotated images using GradCAM, a deep learning explainability tool. In order\nto evaluate the CNN model's capability for processing images, we applied the\nfeatures into different ML models. CNN and machine learning models were also\nevaluated using the standard metrics of Precision, Recall, Specificity, and F1\nscore. The significance of the doctor's diagnosis enhanced the accuracy of the\nCNN model's assistance in identifying the existence of tumor and treating the\npatient.",
      "tldr_zh": "本研究提出了一种高效的特征提取和分类架构，用于基于 MRI 的脑肿瘤检测和定位，旨在解决脑肿瘤早期诊断的准确性挑战。研究团队训练了一个 CNN 模型来分析 MRI 扫描图像，实现了 99.17% 的检测准确率，并利用 GradCAM 工具从无标注图像中定位肿瘤区域。特征提取后，还将这些特征应用于其他机器学习（ML）模型，并通过 Precision、Recall、Specificity 和 F1 score 等标准指标评估模型性能。该方法显著提升了医生诊断的辅助效果，促进了脑肿瘤的快速精准治疗。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.22619v2",
      "published_date": "2024-10-30 00:47:32 UTC",
      "updated_date": "2025-03-09 22:00:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:19:38.832963"
    },
    {
      "arxiv_id": "2410.22615v1",
      "title": "CoGS: Model Agnostic Causality Constrained Counterfactual Explanations using goal-directed ASP",
      "title_zh": "翻译失败",
      "authors": [
        "Sopam Dasgupta",
        "Joaquín Arias",
        "Elmer Salazar",
        "Gopal Gupta"
      ],
      "abstract": "Machine learning models are increasingly used in critical areas such as loan\napprovals and hiring, yet they often function as black boxes, obscuring their\ndecision-making processes. Transparency is crucial, as individuals need\nexplanations to understand decisions, primarily if the decisions result in an\nundesired outcome. Our work introduces CoGS (Counterfactual Generation with\ns(CASP)), a model-agnostic framework capable of generating counterfactual\nexplanations for classification models. CoGS leverages the goal-directed Answer\nSet Programming system s(CASP) to compute realistic and causally consistent\nmodifications to feature values, accounting for causal dependencies between\nthem. By using rule-based machine learning algorithms (RBML), notably the\nFOLD-SE algorithm, CoGS extracts the underlying logic of a statistical model to\ngenerate counterfactual solutions. By tracing a step-by-step path from an\nundesired outcome to a desired one, CoGS offers interpretable and actionable\nexplanations of the changes required to achieve the desired outcome. We present\ndetails of the CoGS framework along with its evaluation.",
      "tldr_zh": "该论文引入了 CoGS 框架，这是一个模型无关（Model Agnostic）的系统，用于为分类模型生成因果约束（Causality Constrained）的反事实解释（Counterfactual Explanations），以提升决策透明度，尤其在贷款审批和招聘等关键领域。CoGS 利用 goal-directed Answer Set Programming 系统 s(CASP) 和基于规则的机器学习算法（如 FOLD-SE）来提取模型逻辑，并计算现实的特征值修改，同时考虑特征间的因果依赖。最终，框架通过提供可解释的逐步路径，帮助用户理解从不良结果到良好结果所需的变更，并通过评估证明了其有效性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "arXiv admin note: substantial text overlap with arXiv:2407.08179",
      "pdf_url": "http://arxiv.org/pdf/2410.22615v1",
      "published_date": "2024-10-30 00:43:01 UTC",
      "updated_date": "2024-10-30 00:43:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:19:51.856832"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 148,
  "processed_papers_count": 148,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-20T19:20:13.943786"
}