{
  "date": "2024-06-25",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-06-25 的 arXiv 中文 TLDR 快报！今天 arXiv 的论文主要聚焦于 AI 模型的优化、鲁棒性及应用，特别是 Large Language Models (LLMs) 在知识编辑、提示工程和多模态任务中的创新进展，以及强化学习和量子计算领域的突破性工作。令人印象深刻的是，论文 25 展示了超导量子比特在多体 Bell 相关深度方面的实验进展，以及多篇 LLM 相关论文如论文 2 和 9，由知名学者（如 Yulan He 和 Jimeng Sun）推动，强调了 AI 在科学和实际应用中的潜力。\n\n下面，我将逐一简要概述今天的论文，先优先讨论重要的、具有话题度的论文（如 LLM 和强化学习领域），然后快速掠过其他较常规的文章。每篇论文标题以中文 + 英文形式列出，焦点放在核心贡献和发现上。\n\n**1. 改进部分顺序计划中的执行并发性 via 块替换 (Improving Execution Concurrency in Partial-Order Plans via Block-Substitution)**  \n   这篇论文提出了一种算法，通过优化资源利用和块级解序来提升部分顺序计划（Partial-Order Plans）的并发执行，实验在 IPC 基准问题上显示了 25% 的计划改进和 2.1% 的整体并发性提升。主要贡献在于形式化非并发约束并引入块替换机制，适用于 AI 规划任务。\n\n**2. 鼓励还是抑制单义性？从特征去相关视角重新审视单义性 (Encourage or Inhibit Monosemanticity? Revisit Monosemanticity from a Feature Decorrelation Perspective)**  \n   作者 Hanqi Yan 等研究了 LLMs 中神经元的单义性（Monosemanticity），发现它与模型性能正相关，并提出特征去相关正则化来提升表示多样性和激活稀疏性。实验证明，该方法改善了偏好对齐性能，是 LLM 解释性和鲁棒性研究中的亮点。\n\n**3. 高效文档排序与可学习延迟交互 (Efficient Document Ranking with Learnable Late Interactions)**  \n   这篇工作引入 LITE 模型，通过可学习延迟交互优化查询-文档相关性排序，理论上证明其对连续评分函数的通用逼近能力。实验在 MS MARCO 数据集上超越 ColBERT，实现了更好的泛化、较低延迟和存储开销。\n\n**5. MAGIC: 元能力引导交互式蒸馏链用于视觉-语言导航 (MAGIC: Meta-Ability Guided Interactive Chain-of-Distillation for Effective-and-Efficient Vision-and-Language Navigation)**  \n   作者 Chengju Liu 等提出 MAGIC 方法，通过元能力知识蒸馏和交互式链式学习优化视觉-语言导航（VLN），在 R2R 数据集上，模型大小仅为教师的 5% 却超越了现有方法。主要发现是多步教师-学生共进化提升了 VLN 的效率和性能。\n\n**9. Panacea: 临床试验搜索、摘要、设计和招募的基础模型 (Panacea: A foundation model for clinical trial search, summarization, design, and recruitment)**  \n   作者 Jimeng Sun 等开发了 Panacea 模型，用于多任务临床试验处理，包括搜索和患者匹配。基于 TrialAlign 数据集的预训练，该模型在 TrialPanorama 基准上超越了其他 LLM，在患者匹配和摘要任务中提升了 14-52%，展示了 AI 在医疗领域的应用潜力。\n\n**11. RAGBench: 检索增强生成系统的可解释基准 (RAGBench: Explainable Benchmark for Retrieval-Augmented Generation Systems)**  \n   这篇论文引入 RAGBench 数据集和 TRACe 评估框架，用于评估检索增强生成（RAG）系统的可解释性和性能。实验显示，微调 RoBERTa 模型优于 LLM-based 方法，强调了 RAG 评估的实际改进。\n\n**25. 使用超导量子比特探测多体 Bell 相关深度 (Probing many-body Bell correlation depth with superconducting qubits)**  \n   作者 H. Wang 和 Dong-Ling Deng 等通过超导量子处理器实验证明了多体 Bell 相关（Bell correlations）在量子多体系统中的应用，在 24 量子比特上实现了新基准。该工作是量子计算领域的重大进展，展示了量子优势的潜力。\n\n**26. 通过学习单调对齐改进 LLM 基于语音合成的鲁棒性 (Improving Robustness of LLM-based Speech Synthesis by Learning Monotonic Alignment)**  \n   作者 Paarth Neekhara 等提出了一种基于 CTC 损失和注意力先验的方法，提升 LLM 语音合成（TTS）的鲁棒性，减少幻觉错误。实验在 INTERSPEECH 2024 中验证了其有效性。\n\n**39. AI 风险分类解码：从政府法规到企业政策 (AI Risk Categorization Decoded (AIR 2024): From Government Regulations to Corporate Policies)**  \n   作者 Yi Zeng 等构建了一个 AI 风险分类系统，基于欧盟、美国和中国政策，识别 314 个风险类别。该工作促进了 AI 安全评估的统一框架。\n\n其他论文中，论文 4、6、7、8、12、13、14、16、17、18、19、20、21、22、23、24、27、28、29、30、31、32、33、34、35、36、37、38、40、41、42、43、44、45、46、47、48、49、50、51、52、53、54、55、56、57、58、59、60、61、62、63、64、65、66、67、68、69、70、71、72、73、74、75、76、77、78、79、80、81、82、83、84、85、86、87、88、89、90、91、92、93、94、95、96、97、98、99、100、101、102、103、104、105、106、107、108、109、110、111、112、113、114、115、116、117、118、119、120、121、122、123、124、125 涉及主题如图像生成、强化学习、医疗 AI 和量子模拟，但相对常规或具体，因此快速掠过。例如，论文 4 (NormTab) 通过表归一化提升 LLM 在表格数据上的符号推理；论文 12 (Semi-supervised classification) 使用 LLM 和实例分割改进牙科图像分类；论文 13 (Transforming Software Development) 评估 GitHub Copilot 在软件开发中的效率。这些论文的核心贡献在于方法优化和基准改进，但未有重大突破，故不展开讨论。\n\n总之，今天的论文突显了 AI 领域的多样性与深度，LLM 和量子计算等方向值得关注，期待后续应用！（全文约800字）",
  "papers": [
    {
      "arxiv_id": "2406.18615v1",
      "title": "Improving Execution Concurrency in Partial-Order Plans via Block-Substitution",
      "title_zh": "通过块替换改善部分顺序计划中的执行并发性",
      "authors": [
        "Sabah Binte Noor",
        "Fazlul Hasan Siddiqui"
      ],
      "abstract": "Partial-order plans in AI planning facilitate execution flexibility and\nseveral other tasks, such as plan reuse, modification, and decomposition, due\nto their less constrained nature. A Partial-Order Plan (POP) allows two actions\nwith no ordering between them, thus providing the flexibility of executing\nactions in different sequences. This flexibility can be further extended by\nenabling parallel execution of actions in a POP to reduce its overall execution\ntime. While extensive studies exist on improving the flexibility of a POP by\noptimizing its action orderings through plan deordering and reordering, there\nhas been limited focus on the flexibility of executing actions concurrently in\na plan. Execution concurrency in a POP can be achieved by incorporating action\nnon-concurrency constraints, specifying which actions can not be executed in\nparallel. This work formalizes the conditions for non-concurrency constraints\nto transform a POP into a parallel plan. We also introduce an algorithm to\nenhance the plan's concurrency by optimizing resource utilization through\nsubstitutions of its subplans with respect to the corresponding planning task.\nOur algorithm employs block deordering that eliminates orderings in a POP by\nencapsulating coherent actions in blocks, and then exploits blocks as candidate\nsubplans for substitutions. Experiments over the benchmark problems from\nInternational Planning Competitions (IPC) exhibit significant improvement in\nplan concurrency, specifically, with improvement in 25% of the plans, and an\noverall increase of 2.1% in concurrency.",
      "tldr_zh": "本文提出一种通过 Block-Substitution 方法来提升 AI 规划中 Partial-Order Plans (POPs) 的执行并发性，旨在通过优化动作顺序和资源利用来减少整体执行时间。研究首先形式化了非并发约束的条件，将 POPs 转化为并行计划，并引入一个算法利用块式去顺序（block deordering）将相干动作封装成块，然后进行子计划替换以最大化并发性。实验在 International Planning Competitions (IPC) 基准问题上显示，25% 的计划得到改善，总并发性平均增加 2.1%。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "arXiv admin note: text overlap with arXiv:2406.03091",
      "pdf_url": "http://arxiv.org/pdf/2406.18615v1",
      "published_date": "2024-06-25 23:36:13 UTC",
      "updated_date": "2024-06-25 23:36:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:20:15.828144"
    },
    {
      "arxiv_id": "2406.17969v2",
      "title": "Encourage or Inhibit Monosemanticity? Revisit Monosemanticity from a Feature Decorrelation Perspective",
      "title_zh": "翻译失败",
      "authors": [
        "Hanqi Yan",
        "Yanzheng Xiang",
        "Guangyi Chen",
        "Yifei Wang",
        "Lin Gui",
        "Yulan He"
      ],
      "abstract": "To better interpret the intrinsic mechanism of large language models (LLMs),\nrecent studies focus on monosemanticity on its basic units. A monosemantic\nneuron is dedicated to a single and specific concept, which forms a one-to-one\ncorrelation between neurons and concepts. Despite extensive research in\nmonosemanticity probing, it remains unclear whether monosemanticity is\nbeneficial or harmful to model capacity. To explore this question, we revisit\nmonosemanticity from the feature decorrelation perspective and advocate for its\nencouragement. We experimentally observe that the current conclusion by\nwang2024learning, which suggests that decreasing monosemanticity enhances model\nperformance, does not hold when the model changes. Instead, we demonstrate that\nmonosemanticity consistently exhibits a positive correlation with model\ncapacity, in the preference alignment process. Consequently, we apply feature\ncorrelation as a proxy for monosemanticity and incorporate a feature\ndecorrelation regularizer into the dynamic preference optimization process. The\nexperiments show that our method not only enhances representation diversity and\nactivation sparsity but also improves preference alignment performance.",
      "tldr_zh": "该论文重新审视大型语言模型（LLMs）中单义性（monosemanticity）的作用，从特征去相关（feature decorrelation）的角度出发，挑战了现有观点，即减少monosemanticity能提升模型性能。作者通过实验发现，monosemanticity与模型容量呈正相关，尤其在偏好对齐过程。论文提出使用特征相关（feature correlation）作为monosemanticity的代理，并在动态偏好优化中加入特征去相关正则化器，结果显示此方法提高了表示多样性和激活稀疏性，并改善了偏好对齐性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP24, Main, Long",
      "pdf_url": "http://arxiv.org/pdf/2406.17969v2",
      "published_date": "2024-06-25 22:51:08 UTC",
      "updated_date": "2024-10-15 22:37:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:20:27.803953"
    },
    {
      "arxiv_id": "2406.17968v1",
      "title": "Efficient Document Ranking with Learnable Late Interactions",
      "title_zh": "翻译失败",
      "authors": [
        "Ziwei Ji",
        "Himanshu Jain",
        "Andreas Veit",
        "Sashank J. Reddi",
        "Sadeep Jayasumana",
        "Ankit Singh Rawat",
        "Aditya Krishna Menon",
        "Felix Yu",
        "Sanjiv Kumar"
      ],
      "abstract": "Cross-Encoder (CE) and Dual-Encoder (DE) models are two fundamental\napproaches for query-document relevance in information retrieval. To predict\nrelevance, CE models use joint query-document embeddings, while DE models\nmaintain factorized query and document embeddings; usually, the former has\nhigher quality while the latter benefits from lower latency. Recently,\nlate-interaction models have been proposed to realize more favorable\nlatency-quality tradeoffs, by using a DE structure followed by a lightweight\nscorer based on query and document token embeddings. However, these lightweight\nscorers are often hand-crafted, and there is no understanding of their\napproximation power; further, such scorers require access to individual\ndocument token embeddings, which imposes an increased latency and storage\nburden. In this paper, we propose novel learnable late-interaction models\n(LITE) that resolve these issues. Theoretically, we prove that LITE is a\nuniversal approximator of continuous scoring functions, even for relatively\nsmall embedding dimension. Empirically, LITE outperforms previous\nlate-interaction models such as ColBERT on both in-domain and zero-shot\nre-ranking tasks. For instance, experiments on MS MARCO passage re-ranking show\nthat LITE not only yields a model with better generalization, but also lowers\nlatency and requires 0.25x storage compared to ColBERT.",
      "tldr_zh": "本研究针对信息检索中的查询-文档相关性问题，比较了 Cross-Encoder (CE) 和 Dual-Encoder (DE) 模型的优缺点，前者提供更高质量但延迟更大，后者则更高效。作者提出了一种新型可学习 late-interaction 模型（LITE），通过理论证明其作为连续评分函数的通用近似器，即使在较小嵌入维度下也能有效。实验结果显示，LITE 在 MS MARCO 段落重排等任务中优于 ColBERT，提高了泛化性能，同时降低了延迟和存储需求，仅需 ColBERT 的 0.25 倍存储。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.17968v1",
      "published_date": "2024-06-25 22:50:48 UTC",
      "updated_date": "2024-06-25 22:50:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:20:41.127274"
    },
    {
      "arxiv_id": "2406.17961v2",
      "title": "NormTab: Improving Symbolic Reasoning in LLMs Through Tabular Data Normalization",
      "title_zh": "NormTab：通过表格数据规范化改进 LLMs 中的符号推理",
      "authors": [
        "Md Mahadi Hasan Nahid",
        "Davood Rafiei"
      ],
      "abstract": "In recent years, Large Language Models (LLMs) have demonstrated remarkable\ncapabilities in parsing textual data and generating code. However, their\nperformance in tasks involving tabular data, especially those requiring\nsymbolic reasoning, faces challenges due to the structural variance and\ninconsistency in table cell values often found in web tables. In this paper, we\nintroduce NormTab, a novel framework aimed at enhancing the symbolic reasoning\nperformance of LLMs by normalizing web tables. We study table normalization as\na stand-alone, one-time preprocessing step using LLMs to support symbolic\nreasoning on tabular data. Our experimental evaluation, conducted on\nchallenging web table datasets such as WikiTableQuestion and TabFact,\ndemonstrates that leveraging NormTab significantly improves symbolic reasoning\nperformance, showcasing the importance and effectiveness of web table\nnormalization for enhancing LLM-based symbolic reasoning tasks.",
      "tldr_zh": "该论文探讨了大型语言模型(LLMs)在处理表格数据时面临的符号推理(Symbolic Reasoning)挑战，特别是由于web表格的结构差异和值不一致性。研究引入了NormTab框架，将表格数据规范化(Tabular Data Normalization)作为独立的预处理步骤，使用LLMs来提升符号推理性能。在WikiTableQuestion和TabFact等数据集上的实验证明，NormTab显著提高了符号推理任务的准确性和有效性，突显了预处理在LLMs应用中的重要作用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DB",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP 2024 (Findings)",
      "pdf_url": "http://arxiv.org/pdf/2406.17961v2",
      "published_date": "2024-06-25 22:40:03 UTC",
      "updated_date": "2025-04-02 20:52:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:20:51.315914"
    },
    {
      "arxiv_id": "2406.17960v1",
      "title": "MAGIC: Meta-Ability Guided Interactive Chain-of-Distillation for Effective-and-Efficient Vision-and-Language Navigation",
      "title_zh": "翻译失败",
      "authors": [
        "Liuyi Wang",
        "Zongtao He",
        "Mengjiao Shen",
        "Jingwei Yang",
        "Chengju Liu",
        "Qijun Chen"
      ],
      "abstract": "Despite the remarkable developments of recent large models in Embodied\nArtificial Intelligence (E-AI), their integration into robotics is hampered by\ntheir excessive parameter sizes and computational demands. Towards the\nVision-and-Language Navigation (VLN) task, a core task in E-AI, this paper\nreveals the great potential of using knowledge distillation for obtaining\nlightweight student models by proposing a Meta-Ability Guided Interactive\nChain-of-distillation (MAGIC) method. Specifically, a Meta-Ability Knowledge\nDistillation (MAKD) framework is proposed for decoupling and refining the\nnecessary meta-abilities of VLN agents. A Meta-Knowledge Randomization\nWeighting (MKRW) and a Meta-Knowledge Transferable Determination (MKTD) module\nare incorporated to dynamically adjust aggregation weights at the meta-ability\nand sample levels, respectively. Move beyond the traditional one-step\nunidirectional distillation, an Interactive Chain-of-Distillation (ICoD)\nlearning strategy is proposed to allow students to give feedback to teachers,\nforming a new multi-step teacher-student co-evolution pipeline. Remarkably, on\nthe R2R test unseen public leaderboard, our smallest model, MAGIC-S, with only\n5% (11M) of the teacher's size, outperforms all previous methods under the same\ntraining data. Additionally, our largest model, MAGIC-L, surpasses the previous\nstate-of-the-art by 5.84% in SPL and 3.18% in SR. Furthermore, a new dataset\nwas collected and annotated from our living environments, where MAGIC-S\ndemonstrated superior performance and real-time efficiency. Our code is\npublicly available on https://github.com/CrystalSixone/VLN-MAGIC.",
      "tldr_zh": "本论文针对Embodied Artificial Intelligence (E-AI)中大模型的参数和计算需求问题，提出Meta-Ability Guided Interactive Chain-of-Distillation (MAGIC)方法，用于Vision-and-Language Navigation (VLN)任务，通过知识蒸馏创建高效轻量级学生模型。MAGIC包括Meta-Ability Knowledge Distillation (MAKD)框架、Meta-Knowledge Randomization Weighting (MKRW)和Meta-Knowledge Transferable Determination (MKTD)模块，以及Interactive Chain-of-Distillation (ICoD)策略，实现多步教师-学生共同演化。实验结果显示，MAGIC-S模型仅占教师模型5%的参数（11M），却在R2R测试中超越所有先前方法；MAGIC-L模型在SPL和SR指标上分别提升5.84%和3.18%。此外，论文收集了新数据集，并验证了MAGIC-S在实际环境中的优越性能和实时效率。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.17960v1",
      "published_date": "2024-06-25 22:33:41 UTC",
      "updated_date": "2024-06-25 22:33:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:21:08.097094"
    },
    {
      "arxiv_id": "2406.17957v1",
      "title": "Improving Robustness of LLM-based Speech Synthesis by Learning Monotonic Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Paarth Neekhara",
        "Shehzeen Hussain",
        "Subhankar Ghosh",
        "Jason Li",
        "Rafael Valle",
        "Rohan Badlani",
        "Boris Ginsburg"
      ],
      "abstract": "Large Language Model (LLM) based text-to-speech (TTS) systems have\ndemonstrated remarkable capabilities in handling large speech datasets and\ngenerating natural speech for new speakers. However, LLM-based TTS models are\nnot robust as the generated output can contain repeating words, missing words\nand mis-aligned speech (referred to as hallucinations or attention errors),\nespecially when the text contains multiple occurrences of the same token. We\nexamine these challenges in an encoder-decoder transformer model and find that\ncertain cross-attention heads in such models implicitly learn the text and\nspeech alignment when trained for predicting speech tokens for a given text. To\nmake the alignment more robust, we propose techniques utilizing CTC loss and\nattention priors that encourage monotonic cross-attention over the text tokens.\nOur guided attention training technique does not introduce any new learnable\nparameters and significantly improves robustness of LLM-based TTS models.",
      "tldr_zh": "这篇论文针对 Large Language Model (LLM) 基于的文本到语音 (TTS) 系统存在的鲁棒性问题（如重复词、缺失词和对齐错误），提出了一种学习 Monotonic Alignment 的方法，以改善模型在处理重复标记文本时的性能。研究发现，编码器-解码器 Transformer 模型中的某些跨注意力头会隐式学习文本和语音对齐，因此作者利用 CTC loss 和 attention priors 技术，引导模型实现单调跨注意力，从而增强对齐的稳定性。该方法不引入任何新参数，并在实验中显著提高了 LLM-based TTS 系统的鲁棒性。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Published as a conference paper at INTERSPEECH 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.17957v1",
      "published_date": "2024-06-25 22:18:52 UTC",
      "updated_date": "2024-06-25 22:18:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:21:16.518863"
    },
    {
      "arxiv_id": "2406.17949v2",
      "title": "The Overcooked Generalisation Challenge",
      "title_zh": "Overcooked 泛化挑战",
      "authors": [
        "Constantin Ruhdorfer",
        "Matteo Bortoletto",
        "Anna Penzkofer",
        "Andreas Bulling"
      ],
      "abstract": "We introduce the Overcooked Generalisation Challenge (OGC) - the first\nbenchmark to study agents' zero-shot cooperation abilities when faced with\nnovel partners and levels in the Overcooked-AI environment. This perspective\nstarkly contrasts a large body of previous work that has trained and evaluated\ncooperating agents only on the same level, failing to capture generalisation\nabilities required for real-world human-AI cooperation. Our challenge\ninterfaces with state-of-the-art dual curriculum design (DCD) methods to\ngenerate auto-curricula for training general agents in Overcooked. It is the\nfirst cooperative multi-agent environment specially designed for DCD methods\nand, consequently, the first benchmarked with state-of-the-art methods. It is\nfully GPU-accelerated, built on the DCD benchmark suite minimax, and freely\navailable under an open-source license:\nhttps://git.hcics.simtech.uni-stuttgart.de/public-projects/OGC. We show that\ncurrent DCD algorithms struggle to produce useful policies in this novel\nchallenge, even if combined with recent network architectures that were\ndesigned for scalability and generalisability. The OGC pushes the boundaries of\nreal-world human-AI cooperation by enabling the research community to study the\nimpact of generalisation on cooperating agents.",
      "tldr_zh": "该论文引入了 Overcooked Generalisation Challenge (OGC)，一个新的基准，用于评估代理在 Overcooked-AI 环境中的零-shot cooperation 能力，特别是面对新伙伴和新关卡时的泛化表现，以弥补现有研究仅在相同关卡上训练和评估代理的局限性。OGC 通过接口与 dual curriculum design (DCD) 方法生成自动课程训练通用代理，是首个专为 DCD 设计的合作多代理环境，并提供完全 GPU 加速和开源支持。实验结果显示，当前 DCD 算法即使结合可伸缩性和泛化性强的网络架构，仍然难以产生有效策略，从而推动了研究社区探索泛化对人类-AI 合作的影响。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.LG",
      "comment": "26 pages",
      "pdf_url": "http://arxiv.org/pdf/2406.17949v2",
      "published_date": "2024-06-25 21:51:43 UTC",
      "updated_date": "2025-04-03 12:32:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:21:29.255905"
    },
    {
      "arxiv_id": "2407.11008v1",
      "title": "Figuring out Figures: Using Textual References to Caption Scientific Figures",
      "title_zh": "翻译失败",
      "authors": [
        "Stanley Cao",
        "Kevin Liu"
      ],
      "abstract": "Figures are essential channels for densely communicating complex ideas in\nscientific papers. Previous work in automatically generating figure captions\nhas been largely unsuccessful and has defaulted to using single-layer LSTMs,\nwhich no longer achieve state-of-the-art performance. In our work, we use the\nSciCap datasets curated by Hsu et al. and use a variant of a CLIP+GPT-2\nencoder-decoder model with cross-attention to generate captions conditioned on\nthe image. Furthermore, we augment our training pipeline by creating a new\ndataset MetaSciCap that incorporates textual metadata from the original paper\nrelevant to the figure, such as the title, abstract, and in-text references. We\nuse SciBERT to encode the textual metadata and use this encoding alongside the\nfigure embedding. In our experimentation with different models, we found that\nthe CLIP+GPT-2 model performs better when it receives all textual metadata from\nthe SciBERT encoder in addition to the figure, but employing a SciBERT+GPT2\nmodel that uses only the textual metadata achieved optimal performance.",
      "tldr_zh": "本文提出了一种改进科学论文图表自动标题生成的方法，针对传统单层 LSTM 模型的不足，使用 CLIP + GPT-2 的编码器-解码器架构结合交叉注意力机制，基于 SciCap 数据集生成图像条件标题。研究者创建了新数据集 MetaSciCap，将图表相关的文本元数据（如标题、摘要和文本引用）纳入训练，并使用 SciBERT 编码这些元数据与图表嵌入相结合。实验发现，CLIP + GPT-2 模型在整合所有文本元数据时性能提升，但 SciBERT + GPT-2 模型（仅使用文本元数据）取得了最佳效果，从而提高了科学图表标题的准确性和相关性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.11008v1",
      "published_date": "2024-06-25 21:49:21 UTC",
      "updated_date": "2024-06-25 21:49:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:21:50.401084"
    },
    {
      "arxiv_id": "2407.11007v1",
      "title": "Panacea: A foundation model for clinical trial search, summarization, design, and recruitment",
      "title_zh": "翻译失败",
      "authors": [
        "Jiacheng Lin",
        "Hanwen Xu",
        "Zifeng Wang",
        "Sheng Wang",
        "Jimeng Sun"
      ],
      "abstract": "Clinical trials are fundamental in developing new drugs, medical devices, and\ntreatments. However, they are often time-consuming and have low success rates.\nAlthough there have been initial attempts to create large language models\n(LLMs) for clinical trial design and patient-trial matching, these models\nremain task-specific and not adaptable to diverse clinical trial tasks. To\naddress this challenge, we propose a clinical trial foundation model named\nPanacea, designed to handle multiple tasks, including trial search, trial\nsummarization, trial design, and patient-trial matching. We also assemble a\nlarge-scale dataset, named TrialAlign, of 793,279 trial documents and 1,113,207\ntrial-related scientific papers, to infuse clinical knowledge into the model by\npre-training. We further curate TrialInstruct, which has 200,866 of instruction\ndata for fine-tuning. These resources enable Panacea to be widely applicable\nfor a range of clinical trial tasks based on user requirements.\n  We evaluated Panacea on a new benchmark, named TrialPanorama, which covers\neight clinical trial tasks. Our method performed the best on seven of the eight\ntasks compared to six cutting-edge generic or medicine-specific LLMs.\nSpecifically, Panacea showed great potential to collaborate with human experts\nin crafting the design of eligibility criteria, study arms, and outcome\nmeasures, in multi-round conversations. In addition, Panacea achieved 14.42%\nimprovement in patient-trial matching, 41.78% to 52.02% improvement in trial\nsearch, and consistently ranked at the top for five aspects of trial\nsummarization. Our approach demonstrates the effectiveness of Panacea in\nclinical trials and establishes a comprehensive resource, including training\ndata, model, and benchmark, for developing clinical trial foundation models,\npaving the path for AI-based clinical trial development.",
      "tldr_zh": "本研究提出Panacea，一种临床试验基础模型，用于处理多个任务，包括试验搜索、总结、设计和患者匹配，以解决现有LLMs模型任务特定性和适应性差的问题。研究构建了大规模数据集TrialAlign（包含793,279个试验文档和1,113,207个相关论文）用于预训练，以及TrialInstruct（200,866条指令数据）用于微调，使模型能够根据用户需求灵活应用。在TrialPanorama基准测试中，Panacea在八个任务中胜出七项，实现了患者匹配提高14.42%、试验搜索提升41.78%至52.02%，并在试验总结的五个方面排名第一，展示了其与人类专家协作的潜力，为AI驱动的临床试验发展提供了全面资源。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.11007v1",
      "published_date": "2024-06-25 21:29:25 UTC",
      "updated_date": "2024-06-25 21:29:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:21:53.916265"
    },
    {
      "arxiv_id": "2407.11006v2",
      "title": "Evaluating the Efficacy of Foundational Models: Advancing Benchmarking Practices to Enhance Fine-Tuning Decision-Making",
      "title_zh": "评估基础模型的功效：推进基准测试实践以提升微调决策",
      "authors": [
        "Oluyemi Enoch Amujo",
        "Shanchieh Jay Yang"
      ],
      "abstract": "Recently, large language models (LLMs) have expanded into various domains.\nHowever, there remains a need to evaluate how these models perform when\nprompted with commonplace queries compared to domain-specific queries, which\nmay be useful for benchmarking prior to fine-tuning for domain-specific\ndownstream tasks. This study evaluates LLMs, specifically Gemma-2B and\nGemma-7B, across diverse domains, including cybersecurity, medicine, and\nfinance, compared to common knowledge queries. This study utilizes a\ncomprehensive methodology to assess foundational models, which includes problem\nformulation, data analysis, and the development of ThroughCut, a novel outlier\ndetection technique that automatically identifies response throughput outliers\nbased on their conciseness. This methodological rigor enhances the credibility\nof the presented evaluation frameworks. This study focused on assessing\ninference time, response length, throughput, quality, and resource utilization\nand investigated the correlations between these factors. The results indicate\nthat model size and types of prompts used for inference significantly\ninfluenced response length and quality. In addition, common prompts, which\ninclude various types of queries, generate diverse and inconsistent responses\nat irregular intervals. In contrast, domain-specific prompts consistently\ngenerate concise responses within a reasonable time. Overall, this study\nunderscores the need for comprehensive evaluation frameworks to enhance the\nreliability of benchmarking procedures in multidomain AI research.",
      "tldr_zh": "这篇论文评估了大型语言模型 (LLMs) 如 Gemma-2B 和 Gemma-7B 在常见查询与领域特定查询（如 cybersecurity、medicine 和 finance）下的性能，以指导后续的微调决策。研究引入了 ThroughCut，一种新型异常检测技术，通过问题制定、数据分析和评估指标（如推理时间、响应长度、吞吐量、质量及资源利用率）来增强基准测试的可靠性。结果表明，模型大小和提示类型显著影响响应长度及质量，领域特定提示生成更一致且简洁的响应，而常见提示则导致多样且不稳定的输出。总体上，该研究强调了建立全面评估框架的必要性，以提升多领域 AI 研究的基准测试实践。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.PF"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages, 5 figures, 2 tables, and algorithms",
      "pdf_url": "http://arxiv.org/pdf/2407.11006v2",
      "published_date": "2024-06-25 20:52:31 UTC",
      "updated_date": "2024-08-20 19:17:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:22:04.027309"
    },
    {
      "arxiv_id": "2407.11005v2",
      "title": "RAGBench: Explainable Benchmark for Retrieval-Augmented Generation Systems",
      "title_zh": "RAGBench：检索增强生成系统的可解释基准测试",
      "authors": [
        "Robert Friel",
        "Masha Belyi",
        "Atindriyo Sanyal"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) has become a standard architectural\npattern for incorporating domain-specific knowledge into user-facing chat\napplications powered by Large Language Models (LLMs). RAG systems are\ncharacterized by (1) a document retriever that queries a domain-specific corpus\nfor context information relevant to an input query, and (2) an LLM that\ngenerates a response based on the provided query and context. However,\ncomprehensive evaluation of RAG systems remains a challenge due to the lack of\nunified evaluation criteria and annotated datasets. In response, we introduce\nRAGBench: the first comprehensive, large-scale RAG benchmark dataset of 100k\nexamples. It covers five unique industry-specific domains and various RAG task\ntypes. RAGBench examples are sourced from industry corpora such as user\nmanuals, making it particularly relevant for industry applications. Further, we\nformalize the TRACe evaluation framework: a set of explainable and actionable\nRAG evaluation metrics applicable across all RAG domains. We release the\nlabeled dataset at https://huggingface.co/datasets/rungalileo/ragbench.\nRAGBench explainable labels facilitate holistic evaluation of RAG systems,\nenabling actionable feedback for continuous improvement of production\napplications. Thorough extensive benchmarking, we find that LLM-based RAG\nevaluation methods struggle to compete with a finetuned RoBERTa model on the\nRAG evaluation task. We identify areas where existing approaches fall short and\npropose the adoption of RAGBench with TRACe towards advancing the state of RAG\nevaluation systems.",
      "tldr_zh": "本研究引入RAGBench，这是一个包含10万例子的全面基准数据集，用于评估Retrieval-Augmented Generation (RAG) 系统，涵盖五个行业特定领域和多种任务类型，数据来源于行业语料如用户手册。论文同时提出TRACe评估框架，一套可解释且可操作的指标，用于统一RAG系统的评估，提供行动性反馈以改进生产应用。通过广泛基准测试，发现基于Large Language Models (LLMs)的RAG评估方法不如微调的RoBERTa模型有效，并建议采用RAGBench和TRACe框架来推进RAG评估系统的状态。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.11005v2",
      "published_date": "2024-06-25 20:23:15 UTC",
      "updated_date": "2025-01-16 10:05:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:22:16.592121"
    },
    {
      "arxiv_id": "2406.17915v1",
      "title": "Semi-supervised classification of dental conditions in panoramic radiographs using large language model and instance segmentation: A real-world dataset evaluation",
      "title_zh": "翻译失败",
      "authors": [
        "Bernardo Silva",
        "Jefferson Fontinele",
        "Carolina Letícia Zilli Vieira",
        "João Manuel R. S. Tavares",
        "Patricia Ramos Cury",
        "Luciano Oliveira"
      ],
      "abstract": "Dental panoramic radiographs offer vast diagnostic opportunities, but\ntraining supervised deep learning networks for automatic analysis of those\nradiology images is hampered by a shortage of labeled data. Here, a different\nperspective on this problem is introduced. A semi-supervised learning framework\nis proposed to classify thirteen dental conditions on panoramic radiographs,\nwith a particular emphasis on teeth. Large language models were explored to\nannotate the most common dental conditions based on dental reports.\nAdditionally, a masked autoencoder was employed to pre-train the classification\nneural network, and a Vision Transformer was used to leverage the unlabeled\ndata. The analyses were validated using two of the most extensive datasets in\nthe literature, comprising 8,795 panoramic radiographs and 8,029 paired reports\nand images. Encouragingly, the results consistently met or surpassed the\nbaseline metrics for the Matthews correlation coefficient. A comparison of the\nproposed solution with human practitioners, supported by statistical analysis,\nhighlighted its effectiveness and performance limitations; based on the degree\nof agreement among specialists, the solution demonstrated an accuracy level\ncomparable to that of a junior specialist.",
      "tldr_zh": "本研究提出了一种半监督学习框架，用于分类牙科全景射线照片中的13种牙科条件，旨在解决标注数据短缺的问题。框架利用Large Language Models (LLMs)基于牙科报告自动标注常见条件，并结合Masked Autoencoder预训练分类神经网络和Vision Transformer处理未标注数据。实验在两个大型数据集（包括8795张全景射线照片和8029对报告与图像）上验证，结果在Matthews correlation coefficient上达到或超过了基线水平，且其准确性与初级牙科专家相当。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "43 pages, 12 figures, 9 tables",
      "pdf_url": "http://arxiv.org/pdf/2406.17915v1",
      "published_date": "2024-06-25 19:56:12 UTC",
      "updated_date": "2024-06-25 19:56:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:22:28.367114"
    },
    {
      "arxiv_id": "2406.17910v1",
      "title": "Transforming Software Development: Evaluating the Efficiency and Challenges of GitHub Copilot in Real-World Projects",
      "title_zh": "翻译失败",
      "authors": [
        "Ruchika Pandey",
        "Prabhat Singh",
        "Raymond Wei",
        "Shaila Shankar"
      ],
      "abstract": "Generative AI technologies promise to transform the product development\nlifecycle. This study evaluates the efficiency gains, areas for improvement,\nand emerging challenges of using GitHub Copilot, an AI-powered coding\nassistant. We identified 15 software development tasks and assessed Copilot's\nbenefits through real-world projects on large proprietary code bases. Our\nfindings indicate significant reductions in developer toil, with up to 50% time\nsaved in code documentation and autocompletion, and 30-40% in repetitive coding\ntasks, unit test generation, debugging, and pair programming. However, Copilot\nstruggles with complex tasks, large functions, multiple files, and proprietary\ncontexts, particularly with C/C++ code. We project a 33-36% time reduction for\ncoding-related tasks in a cloud-first software development lifecycle. This\nstudy aims to quantify productivity improvements, identify underperforming\nscenarios, examine practical benefits and challenges, investigate performance\nvariations across programming languages, and discuss emerging issues related to\ncode quality, security, and developer experience.",
      "tldr_zh": "本研究评估了 GitHub Copilot 在真实软件开发项目中的效率提升和挑战，通过分析 15 个任务在大型专有代码库上的表现。结果显示，Copilot 可节省高达 50% 的代码文档和自动完成时间，以及 30-40% 的重复编码、单元测试生成、调试和配对编程时间，并预测在云优先开发周期中编码任务可减少 33-36%。然而，它在处理复杂任务、大函数、多个文件和 C/C++ 等专有上下文中存在不足。研究还探讨了生产力改善、编程语言差异、代码质量、安全性和开发者体验等潜在问题。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "13 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.17910v1",
      "published_date": "2024-06-25 19:51:21 UTC",
      "updated_date": "2024-06-25 19:51:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:22:41.213996"
    },
    {
      "arxiv_id": "2406.17906v1",
      "title": "Unbiasing on the Fly: Explanation-Guided Human Oversight of Machine Learning System Decisions",
      "title_zh": "翻译失败",
      "authors": [
        "Hussaini Mamman",
        "Shuib Basri",
        "Abdullateef Balogun",
        "Abubakar Abdullahi Imam",
        "Ganesh Kumar",
        "Luiz Fernando Capretz"
      ],
      "abstract": "The widespread adoption of ML systems across critical domains like hiring,\nfinance, and healthcare raises growing concerns about their potential for\ndiscriminatory decision-making based on protected attributes. While efforts to\nensure fairness during development are crucial, they leave deployed ML systems\nvulnerable to potentially exhibiting discrimination during their operations. To\naddress this gap, we propose a novel framework for on-the-fly tracking and\ncorrection of discrimination in deployed ML systems. Leveraging counterfactual\nexplanations, the framework continuously monitors the predictions made by an ML\nsystem and flags discriminatory outcomes. When flagged, post-hoc explanations\nrelated to the original prediction and the counterfactual alternatives are\npresented to a human reviewer for real-time intervention. This\nhuman-in-the-loop approach empowers reviewers to accept or override the ML\nsystem decision, enabling fair and responsible ML operation under dynamic\nsettings. While further work is needed for validation and refinement, this\nframework offers a promising avenue for mitigating discrimination and building\ntrust in ML systems deployed in a wide range of domains.",
      "tldr_zh": "该研究针对机器学习（ML）系统在招聘、金融和医疗等领域可能产生的歧视问题，提出了一种实时监控和纠正框架。该框架利用反事实解释（counterfactual explanations）持续跟踪ML系统的预测，并标记潜在歧视结果；当检测到问题时，向人类审查者提供相关解释以供实时干预，实现human-in-the-loop机制，允许审查者接受或覆盖决策。通过这种方式，该框架在动态环境中提升了ML系统的公平性和可信度，尽管仍需进一步验证和完善。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "13 pages",
      "pdf_url": "http://arxiv.org/pdf/2406.17906v1",
      "published_date": "2024-06-25 19:40:55 UTC",
      "updated_date": "2024-06-25 19:40:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:22:51.623355"
    },
    {
      "arxiv_id": "2406.17904v1",
      "title": "Application of Liquid Rank Reputation System for Twitter Trend Analysis on Bitcoin",
      "title_zh": "Liquid Rank 声",
      "authors": [
        "Abhishek Saxena",
        "Anton Kolonin"
      ],
      "abstract": "Analyzing social media trends can create a win-win situation for both\ncreators and consumers. Creators can receive fair compensation, while consumers\ngain access to engaging, relevant, and personalized content. This paper\nproposes a new model for analyzing Bitcoin trends on Twitter by incorporating a\n'liquid democracy' approach based on user reputation. This system aims to\nidentify the most impactful trends and their influence on Bitcoin prices and\ntrading volume. It uses a Twitter sentiment analysis model based on a\nreputation rating system to determine the impact on Bitcoin price change and\ntraded volume. In addition, the reputation model considers the users'\nhigher-order friends on the social network (the initial Twitter input channels\nin our case study) to improve the accuracy and diversity of the reputation\nresults. We analyze Bitcoin-related news on Twitter to understand how trends\nand user sentiment, measured through our Liquid Rank Reputation System, affect\nBitcoin price fluctuations and trading activity within the studied time frame.\nThis reputation model can also be used as an additional layer in other trend\nand sentiment analysis models. The paper proposes the implementation,\nchallenges, and future scope of the liquid rank reputation model.",
      "tldr_zh": "这篇论文提出了一种基于 Liquid Rank Reputation System 的新模型，用于分析 Twitter 上比特币趋势的影响，采用 liquid democracy 理念通过用户声誉评级来识别关键趋势及其对比特币价格和交易量的作用。模型整合 Twitter 情绪分析，并考虑用户的高阶朋友网络，以提升分析的准确性和多样性。通过对比特币相关新闻的案例研究，该系统展示了如何量化用户情绪对价格波动和交易活动的影响，并探讨了其作为其他趋势分析模型附加层的潜力。该方法突出了实现挑战和未来应用前景。",
      "categories": [
        "cs.SI",
        "cs.AI"
      ],
      "primary_category": "cs.SI",
      "comment": "Under publication in 2024 Ural-Siberian Conference on Biomedical\n  Engineering, Radioelectronics and Information Technology, Yekaterinburg,\n  Russia",
      "pdf_url": "http://arxiv.org/pdf/2406.17904v1",
      "published_date": "2024-06-25 19:35:25 UTC",
      "updated_date": "2024-06-25 19:35:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:23:05.181829"
    },
    {
      "arxiv_id": "2406.17902v1",
      "title": "Domain Adaptation of Echocardiography Segmentation Via Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Arnaud Judge",
        "Thierry Judge",
        "Nicolas Duchateau",
        "Roman A. Sandler",
        "Joseph Z. Sokol",
        "Olivier Bernard",
        "Pierre-Marc Jodoin"
      ],
      "abstract": "Performance of deep learning segmentation models is significantly challenged\nin its transferability across different medical imaging domains, particularly\nwhen aiming to adapt these models to a target domain with insufficient\nannotated data for effective fine-tuning. While existing domain adaptation (DA)\nmethods propose strategies to alleviate this problem, these methods do not\nexplicitly incorporate human-verified segmentation priors, compromising the\npotential of a model to produce anatomically plausible segmentations. We\nintroduce RL4Seg, an innovative reinforcement learning framework that reduces\nthe need to otherwise incorporate large expertly annotated datasets in the\ntarget domain, and eliminates the need for lengthy manual human review. Using a\ntarget dataset of 10,000 unannotated 2D echocardiographic images, RL4Seg not\nonly outperforms existing state-of-the-art DA methods in accuracy but also\nachieves 99% anatomical validity on a subset of 220 expert-validated subjects\nfrom the target domain. Furthermore, our framework's reward network offers\nuncertainty estimates comparable with dedicated state-of-the-art uncertainty\nmethods, demonstrating the utility and effectiveness of RL4Seg in overcoming\ndomain adaptation challenges in medical image segmentation.",
      "tldr_zh": "该研究针对深度学习分割模型在不同医疗图像领域（如超声心动图）适应性差的问题，提出RL4Seg框架，该框架利用Reinforcement Learning减少对目标领域标注数据的依赖，并整合解剖学先验以生成更可靠的分割结果。RL4Seg在10,000张未标注的2D echocardiographic图像上进行测试，不仅在准确性上超越现有Domain Adaptation方法，还在220个专家验证样本中实现99%的anatomical validity。总之，该框架还提供与先进不确定性估计方法相当的reward network输出，提升了医疗图像分割的可信度和实用性。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "9 pages",
      "pdf_url": "http://arxiv.org/pdf/2406.17902v1",
      "published_date": "2024-06-25 19:26:39 UTC",
      "updated_date": "2024-06-25 19:26:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:23:16.515876"
    },
    {
      "arxiv_id": "2406.17898v1",
      "title": "Human-centered In-building Embodied Delivery Benchmark",
      "title_zh": "翻译失败",
      "authors": [
        "Zhuoqun Xu",
        "Yang Liu",
        "Xiaoqi Li",
        "Jiyao Zhang",
        "Hao Dong"
      ],
      "abstract": "Recently, the concept of embodied intelligence has been widely accepted and\npopularized, leading people to naturally consider the potential for\ncommercialization in this field. In this work, we propose a specific commercial\nscenario simulation, human-centered in-building embodied delivery. Furthermore,\nfor this scenario, we have developed a brand-new virtual environment system\nfrom scratch, constructing a multi-level connected building space modeled after\na polar research station. This environment also includes autonomous human\ncharacters and robots with grasping and mobility capabilities, as well as a\nlarge number of interactive items. Based on this environment, we have built a\ndelivery dataset containing 13k language instructions to guide robots in\nproviding services. We simulate human behavior through human characters and\nsample their various needs in daily life. Finally, we proposed a method\ncentered around a large multimodal model to serve as the baseline system for\nthis dataset. Compared to past embodied data work, our work focuses on a\nvirtual environment centered around human-robot interaction for commercial\nscenarios. We believe this will bring new perspectives and exploration angles\nto the embodied community.",
      "tldr_zh": "该论文提出一个以人为中心的人类-机器人交互商业场景——室内具身交付基准（Human-centered In-building Embodied Delivery Benchmark），旨在推动具身智能（Embodied Intelligence）的商业应用。研究者从零构建了一个虚拟环境，模拟极地研究站的多层建筑，包含自主人类角色、具备抓取和移动能力的机器人，以及大量互动物品，并基于此创建了包含13k语言指令的交付数据集。最终，他们提出了一种以大型多模态模型（Large Multimodal Model）为中心的方法作为基准系统，与以往工作相比，该方法更注重人类-机器人交互的商业场景，提供新的探索角度。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.17898v1",
      "published_date": "2024-06-25 19:19:10 UTC",
      "updated_date": "2024-06-25 19:19:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:23:29.914749"
    },
    {
      "arxiv_id": "2406.17888v1",
      "title": "CTBench: A Comprehensive Benchmark for Evaluating Language Model Capabilities in Clinical Trial Design",
      "title_zh": "翻译失败",
      "authors": [
        "Nafis Neehal",
        "Bowen Wang",
        "Shayom Debopadhaya",
        "Soham Dan",
        "Keerthiram Murugesan",
        "Vibha Anand",
        "Kristin P. Bennett"
      ],
      "abstract": "CTBench is introduced as a benchmark to assess language models (LMs) in\naiding clinical study design. Given study-specific metadata, CTBench evaluates\nAI models' ability to determine the baseline features of a clinical trial (CT),\nwhich include demographic and relevant features collected at the trial's start\nfrom all participants. These baseline features, typically presented in CT\npublications (often as Table 1), are crucial for characterizing study cohorts\nand validating results. Baseline features, including confounders and\ncovariates, are also necessary for accurate treatment effect estimation in\nstudies involving observational data. CTBench consists of two datasets:\n\"CT-Repo,\" containing baseline features from 1,690 clinical trials sourced from\nclinicaltrials.gov, and \"CT-Pub,\" a subset of 100 trials with more\ncomprehensive baseline features gathered from relevant publications. Two\nLM-based evaluation methods are developed to compare the actual baseline\nfeature lists against LM-generated responses. \"ListMatch-LM\" and\n\"ListMatch-BERT\" use GPT-4o and BERT scores (at various thresholds),\nrespectively, for evaluation. To establish baseline results, advanced prompt\nengineering techniques using LLaMa3-70B-Instruct and GPT-4o in zero-shot and\nthree-shot learning settings are applied to generate potential baseline\nfeatures. The performance of GPT-4o as an evaluator is validated through\nhuman-in-the-loop evaluations on the CT-Pub dataset, where clinical experts\nconfirm matches between actual and LM-generated features. The results highlight\na promising direction with significant potential for improvement, positioning\nCTBench as a useful tool for advancing research on AI in CT design and\npotentially enhancing the efficacy and robustness of CTs.",
      "tldr_zh": "该论文引入了 CTBench，这是一个全面基准，用于评估语言模型 (LMs) 在临床试验设计中的能力，特别是从研究元数据中生成基线特征，如人口统计学和相关变量，这些特征对表征研究队列和处理观察数据至关重要。CTBench 包含两个数据集：CT-Repo（来自 clinicaltrials.gov 的 1690 个试验的基线特征）和 CT-Pub（100 个试验的更详细特征，从出版物中提取）。研究开发了两种评估方法，ListMatch-LM（基于 GPT-4o）和 ListMatch-BERT（基于 BERT 分数），并通过 LLaMa3-70B-Instruct 和 GPT-4o 的提示工程在零-shot 和三-shot 设置中进行实验，结果显示模型表现有前景但需改进。总体而言，CTBench 为推进 AI 在临床试验设计中的应用提供了有价值的工具，有助于提升试验的功效和鲁棒性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.17888v1",
      "published_date": "2024-06-25 18:52:48 UTC",
      "updated_date": "2024-06-25 18:52:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:23:42.094819"
    },
    {
      "arxiv_id": "2406.17887v1",
      "title": "Federated Dynamical Low-Rank Training with Global Loss Convergence Guarantees",
      "title_zh": "翻译失败",
      "authors": [
        "Steffen Schotthöfer",
        "M. Paul Laiu"
      ],
      "abstract": "In this work, we propose a federated dynamical low-rank training (FeDLRT)\nscheme to reduce client compute and communication costs - two significant\nperformance bottlenecks in horizontal federated learning. Our method builds\nupon dynamical low-rank splitting schemes for manifold-constrained optimization\nto create a global low-rank basis of network weights, which enables client\ntraining on a small coefficient matrix. A consistent global low-rank basis\nallows us to incorporate a variance correction scheme and prove global loss\ndescent and convergence to a stationary point. Dynamic augmentation and\ntruncation of the low-rank bases automatically optimizes computing and\ncommunication resource utilization. We demonstrate the efficiency of FeDLRT in\nan array of computer vision benchmarks and show a reduction of client compute\nand communication costs by up to an order of magnitude with minimal impacts on\nglobal accuracy.",
      "tldr_zh": "本文提出了一种名为 FeDLRT 的联邦动态低秩训练方案，旨在减少水平 federated learning 中的客户端计算和通信成本。FeDLRT 基于 dynamical low-rank splitting schemes 构建全局低秩网络权重基础，允许客户端在小系数矩阵上训练，并通过方差修正方案证明全局损失下降和收敛到平稳点。实验在计算机视觉基准测试中显示，该方法将客户端计算和通信成本降低一个数量级，同时对全局准确性影响最小。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.17887v1",
      "published_date": "2024-06-25 18:51:08 UTC",
      "updated_date": "2024-06-25 18:51:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:23:52.468403"
    },
    {
      "arxiv_id": "2406.17885v3",
      "title": "Enabling Regional Explainability by Automatic and Model-agnostic Rule Extraction",
      "title_zh": "通过自动和模型无关的规则提取实现区域解释性",
      "authors": [
        "Yu Chen",
        "Tianyu Cui",
        "Alexander Capstick",
        "Nan Fletcher-Loyd",
        "Payam Barnaghi"
      ],
      "abstract": "In Explainable AI, rule extraction translates model knowledge into logical\nrules, such as IF-THEN statements, crucial for understanding patterns learned\nby black-box models. This could significantly aid in fields like disease\ndiagnosis, disease progression estimation, or drug discovery. However, such\napplication domains often contain imbalanced data, with the class of interest\nunderrepresented. Existing methods inevitably compromise the performance of\nrules for the minor class to maximise the overall performance. As the first\nattempt in this field, we propose a model-agnostic approach for extracting\nrules from specific subgroups of data, featuring automatic rule generation for\nnumerical features. This method enhances the regional explainability of machine\nlearning models and offers wider applicability compared to existing methods. We\nadditionally introduce a new method for selecting features to compose rules,\nreducing computational costs in high-dimensional spaces. Experiments across\nvarious datasets and models demonstrate the effectiveness of our methods.",
      "tldr_zh": "本研究针对Explainable AI中的规则提取问题，提出了一种模型无关（model-agnostic）的自动规则提取方法，专注于从特定子群数据中生成IF-THEN逻辑规则，以提升区域可解释性。该方法特别解决了不平衡数据场景下少数类性能的牺牲问题，并引入自动规则生成技术针对数值特征，同时采用新特征选择策略来降低高维空间的计算成本。与现有方法相比，该方法具有更广泛的适用性，如在疾病诊断等领域。实验结果在多种数据集和模型上验证了其有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.17885v3",
      "published_date": "2024-06-25 18:47:50 UTC",
      "updated_date": "2024-08-15 13:08:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:24:04.975285"
    },
    {
      "arxiv_id": "2406.17876v1",
      "title": "ET tu, CLIP? Addressing Common Object Errors for Unseen Environments",
      "title_zh": "翻译失败",
      "authors": [
        "Ye Won Byun",
        "Cathy Jiao",
        "Shahriar Noroozizadeh",
        "Jimin Sun",
        "Rosa Vitiello"
      ],
      "abstract": "We introduce a simple method that employs pre-trained CLIP encoders to\nenhance model generalization in the ALFRED task. In contrast to previous\nliterature where CLIP replaces the visual encoder, we suggest using CLIP as an\nadditional module through an auxiliary object detection objective. We validate\nour method on the recently proposed Episodic Transformer architecture and\ndemonstrate that incorporating CLIP improves task performance on the unseen\nvalidation set. Additionally, our analysis results support that CLIP especially\nhelps with leveraging object descriptions, detecting small objects, and\ninterpreting rare words.",
      "tldr_zh": "这篇论文提出了一种简单方法，使用预训练的CLIP编码器作为额外模块，通过辅助对象检测 objective，提升ALFRED任务中模型的泛化能力，以解决未见环境中的常见对象错误问题。不同于以往直接替换视觉编码器，该方法将CLIP整合到Episodic Transformer架构中，作为辅助组件。实验结果显示，该方法显著提高了未见验证集上的任务性能。进一步分析表明，CLIP特别有助于利用对象描述、检测小对象以及解释稀有词汇。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.17876v1",
      "published_date": "2024-06-25 18:35:13 UTC",
      "updated_date": "2024-06-25 18:35:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:24:27.256284"
    },
    {
      "arxiv_id": "2406.17873v1",
      "title": "Improving Arithmetic Reasoning Ability of Large Language Models through Relation Tuples, Verification and Dynamic Feedback",
      "title_zh": "翻译失败",
      "authors": [
        "Zhongtao Miao",
        "Kaiyan Zhao",
        "Yoshimasa Tsuruoka"
      ],
      "abstract": "Current representations used in reasoning steps of large language models can\nmostly be categorized into two main types: (1) natural language, which is\ndifficult to verify; and (2) non-natural language, usually programming code,\nwhich is difficult for people who are unfamiliar with coding to read. In this\npaper, we propose to use a semi-structured form to represent reasoning steps of\nlarge language models. Specifically, we use relation tuples, which are not only\nhuman-readable but also machine-friendly and easier to verify than natural\nlanguage. We implement a framework that includes three main components: (1)\nintroducing relation tuples into the reasoning steps of large language models;\n(2) implementing an automatic verification process of reasoning steps with a\nlocal code interpreter based on relation tuples; and (3) integrating a simple\nand effective dynamic feedback mechanism, which we found helpful for\nself-improvement of large language models. The experimental results on various\narithmetic datasets demonstrate the effectiveness of our method in improving\nthe arithmetic reasoning ability of large language models. The source code is\navailable at https://github.com/gpgg/art.",
      "tldr_zh": "该研究针对大型语言模型（Large Language Models, LLMs）在算术推理中的表示问题，提出使用半结构化的 relation tuples 作为推理步骤的表示形式，这种形式兼具可读性和易验证性。框架包括三个关键组件：将 relation tuples 融入 LLMs 的推理过程、使用本地代码解释器进行自动 verification，以及整合动态 feedback 机制以促进模型自我改进。在多个算术数据集上的实验结果表明，该方法显著提升了 LLMs 的算术推理能力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Under review, 25 figures, 8 tables, 29 pages",
      "pdf_url": "http://arxiv.org/pdf/2406.17873v1",
      "published_date": "2024-06-25 18:21:00 UTC",
      "updated_date": "2024-06-25 18:21:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:24:28.969874"
    },
    {
      "arxiv_id": "2406.17864v1",
      "title": "AI Risk Categorization Decoded (AIR 2024): From Government Regulations to Corporate Policies",
      "title_zh": "翻译失败",
      "authors": [
        "Yi Zeng",
        "Kevin Klyman",
        "Andy Zhou",
        "Yu Yang",
        "Minzhou Pan",
        "Ruoxi Jia",
        "Dawn Song",
        "Percy Liang",
        "Bo Li"
      ],
      "abstract": "We present a comprehensive AI risk taxonomy derived from eight government\npolicies from the European Union, United States, and China and 16 company\npolicies worldwide, making a significant step towards establishing a unified\nlanguage for generative AI safety evaluation. We identify 314 unique risk\ncategories organized into a four-tiered taxonomy. At the highest level, this\ntaxonomy encompasses System & Operational Risks, Content Safety Risks, Societal\nRisks, and Legal & Rights Risks. The taxonomy establishes connections between\nvarious descriptions and approaches to risk, highlighting the overlaps and\ndiscrepancies between public and private sector conceptions of risk. By\nproviding this unified framework, we aim to advance AI safety through\ninformation sharing across sectors and the promotion of best practices in risk\nmitigation for generative AI models and systems.",
      "tldr_zh": "本研究提出一个全面的 AI 风险分类系统（AI risk taxonomy），基于欧盟、美国和中国等八个政府政策以及全球十六家公司政策，旨在统一生成式 AI 安全评估的语言。研究识别出 314 个独特风险类别，并将其组织成四层结构，包括最高层的 System & Operational Risks、Content Safety Risks、Societal Risks 和 Legal & Rights Risks，同时揭示了公共和私营部门风险概念之间的重叠（overlaps）和差异（discrepancies）。通过这个统一框架，该研究推动 AI 安全的发展，促进跨部门信息共享和生成式 AI 模型的风险缓解最佳实践。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.17864v1",
      "published_date": "2024-06-25 18:13:05 UTC",
      "updated_date": "2024-06-25 18:13:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:24:41.350748"
    },
    {
      "arxiv_id": "2406.17863v4",
      "title": "What type of inference is planning?",
      "title_zh": "规划属于何种推理类型？",
      "authors": [
        "Miguel Lázaro-Gredilla",
        "Li Yang Ku",
        "Kevin P. Murphy",
        "Dileep George"
      ],
      "abstract": "Multiple types of inference are available for probabilistic graphical models,\ne.g., marginal, maximum-a-posteriori, and even marginal maximum-a-posteriori.\nWhich one do researchers mean when they talk about \"planning as inference\"?\nThere is no consistency in the literature, different types are used, and their\nability to do planning is further entangled with specific approximations or\nadditional constraints. In this work we use the variational framework to show\nthat, just like all commonly used types of inference correspond to different\nweightings of the entropy terms in the variational problem, planning\ncorresponds exactly to a different set of weights. This means that all the\ntricks of variational inference are readily applicable to planning. We develop\nan analogue of loopy belief propagation that allows us to perform approximate\nplanning in factored-state Markov decisions processes without incurring\nintractability due to the exponentially large state space. The variational\nperspective shows that the previous types of inference for planning are only\nadequate in environments with low stochasticity, and allows us to characterize\neach type by its own merits, disentangling the type of inference from the\nadditional approximations that its practical use requires. We validate these\nresults empirically on synthetic MDPs and tasks posed in the International\nPlanning Competition.",
      "tldr_zh": "该论文探讨了在概率图形模型中，“planning as inference” 指的是哪种推理类型，因为文献中缺乏一致性，且类型与近似或约束纠缠。该研究使用 variational framework 证明，planning 对应于变分问题中不同的熵项权重，从而使变分推理的技巧（如 loopy belief propagation 的模拟）可直接应用于规划。作者开发了一种新方法，用于在 factored-state Markov decision processes 中进行近似规划，避免了状态空间指数增长的计算问题。实验结果显示，这种框架在合成 MDPs 和 International Planning Competition 的任务上表现优越，并揭示了传统推理类型仅适用于低随机性环境。",
      "categories": [
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.AI",
      "comment": "Camera-ready version update",
      "pdf_url": "http://arxiv.org/pdf/2406.17863v4",
      "published_date": "2024-06-25 18:05:31 UTC",
      "updated_date": "2025-01-14 07:33:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:24:54.951927"
    },
    {
      "arxiv_id": "2406.17841v1",
      "title": "Probing many-body Bell correlation depth with superconducting qubits",
      "title_zh": "使用超导量子比特探测多体贝尔相关性深度",
      "authors": [
        "Ke Wang",
        "Weikang Li",
        "Shibo Xu",
        "Mengyao Hu",
        "Jiachen Chen",
        "Yaozu Wu",
        "Chuanyu Zhang",
        "Feitong Jin",
        "Xuhao Zhu",
        "Yu Gao",
        "Ziqi Tan",
        "Aosai Zhang",
        "Ning Wang",
        "Yiren Zou",
        "Tingting Li",
        "Fanhao Shen",
        "Jiarun Zhong",
        "Zehang Bao",
        "Zitian Zhu",
        "Zixuan Song",
        "Jinfeng Deng",
        "Hang Dong",
        "Xu Zhang",
        "Pengfei Zhang",
        "Wenjie Jiang",
        "Zhide Lu",
        "Zheng-Zhi Sun",
        "Hekang Li",
        "Qiujiang Guo",
        "Zhen Wang",
        "Patrick Emonts",
        "Jordi Tura",
        "Chao Song",
        "H. Wang",
        "Dong-Ling Deng"
      ],
      "abstract": "Quantum nonlocality describes a stronger form of quantum correlation than\nthat of entanglement. It refutes Einstein's belief of local realism and is\namong the most distinctive and enigmatic features of quantum mechanics. It is a\ncrucial resource for achieving quantum advantages in a variety of practical\napplications, ranging from cryptography and certified random number generation\nvia self-testing to machine learning. Nevertheless, the detection of\nnonlocality, especially in quantum many-body systems, is notoriously\nchallenging. Here, we report an experimental certification of genuine\nmultipartite Bell correlations, which signal nonlocality in quantum many-body\nsystems, up to 24 qubits with a fully programmable superconducting quantum\nprocessor. In particular, we employ energy as a Bell correlation witness and\nvariationally decrease the energy of a many-body system across a hierarchy of\nthresholds, below which an increasing Bell correlation depth can be certified\nfrom experimental data. As an illustrating example, we variationally prepare\nthe low-energy state of a two-dimensional honeycomb model with 73 qubits and\ncertify its Bell correlations by measuring an energy that surpasses the\ncorresponding classical bound with up to 48 standard deviations. In addition,\nwe variationally prepare a sequence of low-energy states and certify their\ngenuine multipartite Bell correlations up to 24 qubits via energies measured\nefficiently by parity oscillation and multiple quantum coherence techniques.\nOur results establish a viable approach for preparing and certifying\nmultipartite Bell correlations, which provide not only a finer benchmark beyond\nentanglement for quantum devices, but also a valuable guide towards exploiting\nmultipartite Bell correlation in a wide spectrum of practical applications.",
      "tldr_zh": "这篇论文使用超导量子比特探测多体 Bell correlations 的深度，挑战了爱因斯坦的局部实在论，并证明了量子非定域性在多达 24 个量子比特上的真正多部分相关性。研究者采用能量作为 Bell correlation 见证，通过变分方法降低系统能量，跨越阈值来认证相关性深度。实验中，他们在 73 个量子比特的二维蜂窝模型中准备低能量态，并通过测量能量超过经典界限达 48 个标准差，展示了显著的量子优势。此外，这一方法为量子设备提供比纠缠更精细的基准，并指导 Bell correlations 在加密、随机数生成和机器学习等实际应用中的利用。",
      "categories": [
        "quant-ph",
        "cs.AI"
      ],
      "primary_category": "quant-ph",
      "comment": "11 pages,6 figures + 14 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.17841v1",
      "published_date": "2024-06-25 18:00:00 UTC",
      "updated_date": "2024-06-25 18:00:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:25:07.064919"
    },
    {
      "arxiv_id": "2407.11004v2",
      "title": "The ALCHEmist: Automated Labeling 500x CHEaper Than LLM Data Annotators",
      "title_zh": "翻译失败",
      "authors": [
        "Tzu-Heng Huang",
        "Catherine Cao",
        "Vaishnavi Bhargava",
        "Frederic Sala"
      ],
      "abstract": "Large pretrained models can be used as annotators, helping replace or augment\ncrowdworkers and enabling distilling generalist models into smaller specialist\nmodels. Unfortunately, this comes at a cost: employing top-of-the-line models\noften requires paying thousands of dollars for API calls, while the resulting\ndatasets are static and challenging to audit. To address these challenges, we\npropose a simple alternative: rather than directly querying labels from\npretrained models, we task models to generate programs that can produce labels.\nThese programs can be stored and applied locally, re-used and extended, and\ncost orders of magnitude less. Our system, Alchemist, obtains comparable to or\nbetter performance than large language model-based annotation in a range of\ntasks for a fraction of the cost: on average, improvements amount to a 12.9%\nenhancement while the total labeling costs across all datasets are reduced by a\nfactor of approximately 500x.",
      "tldr_zh": "本论文提出ALCHEmist系统，一种自动化标注方法，让预训练模型生成可产生标签的程序，而不是直接查询模型，从而避免高额API calls成本，并使数据集更易存储、重复使用和审计。与大型语言模型(LLM)基于标注相比，ALCHEmist在多种任务上实现了相当或更好的性能，平均提升12.9%。总体而言，这种方法将标注成本降低了约500倍，为高效的数据标注和模型微调提供了经济可行的解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "NeurIPS 2024 Spotlight Paper",
      "pdf_url": "http://arxiv.org/pdf/2407.11004v2",
      "published_date": "2024-06-25 17:58:26 UTC",
      "updated_date": "2025-02-03 18:17:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:25:17.614408"
    },
    {
      "arxiv_id": "2407.09533v1",
      "title": "Video Occupancy Models",
      "title_zh": "翻译失败",
      "authors": [
        "Manan Tomar",
        "Philippe Hansen-Estruch",
        "Philip Bachman",
        "Alex Lamb",
        "John Langford",
        "Matthew E. Taylor",
        "Sergey Levine"
      ],
      "abstract": "We introduce a new family of video prediction models designed to support\ndownstream control tasks. We call these models Video Occupancy models (VOCs).\nVOCs operate in a compact latent space, thus avoiding the need to make\npredictions about individual pixels. Unlike prior latent-space world models,\nVOCs directly predict the discounted distribution of future states in a single\nstep, thus avoiding the need for multistep roll-outs. We show that both\nproperties are beneficial when building predictive models of video for use in\ndownstream control. Code is available at\n\\href{https://github.com/manantomar/video-occupancy-models}{\\texttt{github.com/manantomar/video-occupancy-models}}.",
      "tldr_zh": "本研究引入了 Video Occupancy Models (VOCs)，一种新型视频预测模型家族，旨在支持下游控制任务。VOCs 在紧凑的 latent space 中操作，避免了针对单个像素的预测，并直接在单步内预测未来状态的 discounted distribution of future states，从而绕过了多步 roll-outs 的复杂性。与现有潜在空间世界模型相比，这种设计显著提高了视频预测的效率和适用性。实验结果表明，VOCs 在构建用于控制任务的预测模型方面具有明显优势。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.09533v1",
      "published_date": "2024-06-25 17:57:38 UTC",
      "updated_date": "2024-06-25 17:57:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:25:29.042893"
    },
    {
      "arxiv_id": "2406.17768v3",
      "title": "EXTRACT: Efficient Policy Learning by Extracting Transferable Robot Skills from Offline Data",
      "title_zh": "翻译失败",
      "authors": [
        "Jesse Zhang",
        "Minho Heo",
        "Zuxin Liu",
        "Erdem Biyik",
        "Joseph J Lim",
        "Yao Liu",
        "Rasool Fakoor"
      ],
      "abstract": "Most reinforcement learning (RL) methods focus on learning optimal policies\nover low-level action spaces. While these methods can perform well in their\ntraining environments, they lack the flexibility to transfer to new tasks.\nInstead, RL agents that can act over useful, temporally extended skills rather\nthan low-level actions can learn new tasks more easily. Prior work in\nskill-based RL either requires expert supervision to define useful skills,\nwhich is hard to scale, or learns a skill-space from offline data with\nheuristics that limit the adaptability of the skills, making them difficult to\ntransfer during downstream RL. Our approach, EXTRACT, instead utilizes\npre-trained vision language models to extract a discrete set of semantically\nmeaningful skills from offline data, each of which is parameterized by\ncontinuous arguments, without human supervision. This skill parameterization\nallows robots to learn new tasks by only needing to learn when to select a\nspecific skill and how to modify its arguments for the specific task. We\ndemonstrate through experiments in sparse-reward, image-based, robot\nmanipulation environments that EXTRACT can more quickly learn new tasks than\nprior works, with major gains in sample efficiency and performance over prior\nskill-based RL. Website at https://www.jessezhang.net/projects/extract/.",
      "tldr_zh": "该研究提出了一种名为 EXTRACT 的方法，用于从离线数据中提取可转移的机器人技能，从而提高强化学习 (RL) 的政策学习效率。EXTRACT 利用预训练的视觉语言模型 (VLM) 无需人类监督地提取一组离散的语义技能，每个技能由连续参数参数化，这使得机器人只需学习何时选择技能及其参数调整即可适应新任务。在稀疏奖励、基于图像的机器人操作环境中，实验结果显示 EXTRACT 比现有基于技能的 RL 方法更快速学习新任务，并显著提升样本效率和整体性能。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "25 pages, 16 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.17768v3",
      "published_date": "2024-06-25 17:50:03 UTC",
      "updated_date": "2024-09-19 00:24:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:25:40.977849"
    },
    {
      "arxiv_id": "2406.17764v2",
      "title": "BMIKE-53: Investigating Cross-Lingual Knowledge Editing with In-Context Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Ercong Nie",
        "Bo Shao",
        "Zifeng Ding",
        "Mingyang Wang",
        "Helmut Schmid",
        "Hinrich Schütze"
      ],
      "abstract": "This paper introduces BMIKE-53, a comprehensive benchmark for cross-lingual\nin-context knowledge editing (IKE) across 53 languages, unifying three\nknowledge editing (KE) datasets: zsRE, CounterFact, and WikiFactDiff.\nCross-lingual KE, which requires knowledge edited in one language to generalize\nacross others while preserving unrelated knowledge, remains underexplored. To\naddress this gap, we systematically evaluate IKE under zero-shot, one-shot, and\nfew-shot setups, incorporating tailored metric-specific demonstrations. Our\nfindings reveal that model scale and demonstration alignment critically govern\ncross-lingual IKE efficacy, with larger models and tailored demonstrations\nsignificantly improving performance. Linguistic properties, particularly script\ntype, strongly influence performance variation across languages, with non-Latin\nlanguages underperforming due to issues like language confusion.",
      "tldr_zh": "这篇论文引入了 BMIKE-53，这是一个涵盖 53 种语言的综合基准，用于评估跨语言 In-Context Knowledge Editing (IKE)，并统一了 zsRE、CounterFact 和 WikiFactDiff 等数据集。研究系统地评估了 IKE 在 zero-shot、one-shot 和 few-shot 设置下的表现，通过定制的指标特定演示来优化效果。结果显示，模型规模和演示的匹配度对跨语言 IKE 的效能至关重要，而语言特性（如脚本类型）会显著影响性能，非拉丁脚本语言因语言混淆等问题表现较差。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "18 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.17764v2",
      "published_date": "2024-06-25 17:48:56 UTC",
      "updated_date": "2025-02-19 21:35:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:25:56.394955"
    },
    {
      "arxiv_id": "2406.17763v2",
      "title": "DiffusionPDE: Generative PDE-Solving Under Partial Observation",
      "title_zh": "翻译失败",
      "authors": [
        "Jiahe Huang",
        "Guandao Yang",
        "Zichen Wang",
        "Jeong Joon Park"
      ],
      "abstract": "We introduce a general framework for solving partial differential equations\n(PDEs) using generative diffusion models. In particular, we focus on the\nscenarios where we do not have the full knowledge of the scene necessary to\napply classical solvers. Most existing forward or inverse PDE approaches\nperform poorly when the observations on the data or the underlying coefficients\nare incomplete, which is a common assumption for real-world measurements. In\nthis work, we propose DiffusionPDE that can simultaneously fill in the missing\ninformation and solve a PDE by modeling the joint distribution of the solution\nand coefficient spaces. We show that the learned generative priors lead to a\nversatile framework for accurately solving a wide range of PDEs under partial\nobservation, significantly outperforming the state-of-the-art methods for both\nforward and inverse directions.",
      "tldr_zh": "该研究提出了一种名为 DiffusionPDE 的框架，利用生成扩散模型来解决偏微分方程 (PDEs)，特别针对部分观察场景下的问题。DiffusionPDE 通过建模解决方案和系数空间的联合分布，能够同时填充缺失信息并进行PDE求解，从而克服现有方法在数据或系数不完整时的不足。实验结果表明，该框架在正向和逆向PDE求解中显著优于最先进方法，提供了一种更准确的通用解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.NA",
        "math.NA"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2024. Project page:\n  https://jhhuangchloe.github.io/Diffusion-PDE/",
      "pdf_url": "http://arxiv.org/pdf/2406.17763v2",
      "published_date": "2024-06-25 17:48:24 UTC",
      "updated_date": "2024-11-01 00:08:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:26:05.122885"
    },
    {
      "arxiv_id": "2406.17762v1",
      "title": "Solving Hard Mizar Problems with Instantiation and Strategy Invention",
      "title_zh": "通过实例化和策略发明解决困难的 Mizar 问题",
      "authors": [
        "Jan Jakubův",
        "Mikoláš Janota",
        "Josef Urban"
      ],
      "abstract": "In this work, we prove over 3000 previously ATP-unproved Mizar/MPTP problems\nby using several ATP and AI methods, raising the number of ATP-solved Mizar\nproblems from 75\\% to above 80\\%. First, we start to experiment with the cvc5\nSMT solver which uses several instantiation-based heuristics that differ from\nthe superposition-based systems, that were previously applied to Mizar,and add\nmany new solutions. Then we use automated strategy invention to develop cvc5\nstrategies that largely improve cvc5's performance on the hard problems. In\nparticular, the best invented strategy solves over 14\\% more problems than the\nbest previously available cvc5 strategy. We also show that different\nclausification methods have a high impact on such instantiation-based methods,\nagain producing many new solutions. In total, the methods solve 3021 (21.3\\%)\nof the 14163 previously unsolved hard Mizar problems. This is a new milestone\nover the Mizar large-theory benchmark and a large strengthening of the hammer\nmethods for Mizar.",
      "tldr_zh": "本研究使用实例化(instantiation)和策略发明(strategy invention)方法，结合 cvc5 SMT 求解器和 AI 技术，成功证明了超过 3000 个之前无法用自动定理证明器(ATP)解决的 Mizar/MPTP 问题，将整体解决率从 75% 提高到超过 80%。具体而言，研究者实验了 cvc5 的基于实例化的启发式方法，并通过自动策略发明开发了新策略，使 cvc5 在困难问题上的性能提升了 14%以上；同时，探索了不同 clausification 方法的影响，进一步增加了解决方案。总体结果显示，这些方法解决了 14163 个未解决硬问题的 21.3%，标志着 Mizar large-theory benchmark 的新里程碑，并显著加强了 hammer methods 在 Mizar 领域的应用。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.LO",
        "cs.SC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.17762v1",
      "published_date": "2024-06-25 17:47:13 UTC",
      "updated_date": "2024-06-25 17:47:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:26:18.063734"
    },
    {
      "arxiv_id": "2406.17840v2",
      "title": "Human-Object Interaction from Human-Level Instructions",
      "title_zh": "翻译失败",
      "authors": [
        "Zhen Wu",
        "Jiaman Li",
        "Pei Xu",
        "C. Karen Liu"
      ],
      "abstract": "Intelligent agents must autonomously interact with the environments to\nperform daily tasks based on human-level instructions. They need a foundational\nunderstanding of the world to accurately interpret these instructions, along\nwith precise low-level movement and interaction skills to execute the derived\nactions. In this work, we propose the first complete system for synthesizing\nphysically plausible, long-horizon human-object interactions for object\nmanipulation in contextual environments, driven by human-level instructions. We\nleverage large language models (LLMs) to interpret the input instructions into\ndetailed execution plans. Unlike prior work, our system is capable of\ngenerating detailed finger-object interactions, in seamless coordination with\nfull-body movements. We also train a policy to track generated motions in\nphysics simulation via reinforcement learning (RL) to ensure physical\nplausibility of the motion. Our experiments demonstrate the effectiveness of\nour system in synthesizing realistic interactions with diverse objects in\ncomplex environments, highlighting its potential for real-world applications.",
      "tldr_zh": "该研究提出一个完整的系统，用于基于人类级指令合成物理上合理的长期人-物体互动，旨在帮助智能代理在复杂环境中执行日常任务。该系统利用大型语言模型(LLMs)将输入指令转化为详细的执行计划，并生成精细的手指-物体互动与全身体动的协调配合；同时，通过强化学习(RL)训练策略来确保动作在物理模拟中的可信度。实验结果表明，该系统在多样物体和复杂环境中的互动合成表现出色，具有在真实世界应用的潜力。",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "project page: https://hoifhli.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2406.17840v2",
      "published_date": "2024-06-25 17:46:28 UTC",
      "updated_date": "2024-12-11 04:37:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:26:28.701673"
    },
    {
      "arxiv_id": "2406.17761v2",
      "title": "CaLMQA: Exploring culturally specific long-form question answering across 23 languages",
      "title_zh": "翻译失败",
      "authors": [
        "Shane Arora",
        "Marzena Karpinska",
        "Hung-Ting Chen",
        "Ipsita Bhattacharjee",
        "Mohit Iyyer",
        "Eunsol Choi"
      ],
      "abstract": "Large language models (LLMs) are used for long-form question answering\n(LFQA), which requires them to generate paragraph-length answers to complex\nquestions. While LFQA has been well-studied in English, this research has not\nbeen extended to other languages. To bridge this gap, we introduce CaLMQA, a\ncollection of 1.5K complex culturally specific questions spanning 23 languages\nand 51 culturally agnostic questions translated from English into 22 other\nlanguages. We define culturally specific questions as those uniquely or more\nlikely to be asked by people from cultures associated with the question's\nlanguage. We collect naturally-occurring questions from community web forums\nand hire native speakers to write questions to cover under-resourced,\nrarely-studied languages such as Fijian and Kirundi. Our dataset contains\ndiverse, complex questions that reflect cultural topics (e.g. traditions, laws,\nnews) and the language usage of native speakers. We automatically evaluate a\nsuite of open- and closed-source models on CaLMQA by detecting incorrect\nlanguage and token repetitions in answers, and observe that the quality of\nLLM-generated answers degrades significantly for some low-resource languages.\nLastly, we perform human evaluation on a subset of models and languages. Manual\nevaluation reveals that model performance is significantly worse for culturally\nspecific questions than for culturally agnostic questions. Our findings\nhighlight the need for further research in non-English LFQA and provide an\nevaluation framework.",
      "tldr_zh": "这篇论文引入了 CaLMQA 数据集，包含 1.5K 个跨越 23 种语言的文化特定复杂问题，以及 51 个从英语翻译的文化无关问题，用于探索长形式问题回答 (LFQA)。数据集通过从社区网络论坛收集自然问题并雇佣母语者撰写，覆盖了如 Fijian 和 Kirundi 等低资源语言，并反映了文化主题（如传统、法律和新闻）的多样性。研究评估了多种开源和闭源大型语言模型 (LLMs)，发现这些模型在低资源语言中生成的答案质量显著下降，尤其在检测语言错误和 token 重复时。人工评估进一步显示，模型在文化特定问题上的表现远逊于文化无关问题，从而强调了非英语 LFQA 研究的紧迫性和提供的评估框架。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "39 pages, 17 figures. Code and data available at\n  https://github.com/2015aroras/CaLMQA. Revised argument in section 4, results\n  unchanged",
      "pdf_url": "http://arxiv.org/pdf/2406.17761v2",
      "published_date": "2024-06-25 17:45:26 UTC",
      "updated_date": "2024-07-03 16:33:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:26:42.898653"
    },
    {
      "arxiv_id": "2406.17753v3",
      "title": "Measuring and Benchmarking Large Language Models' Capabilities to Generate Persuasive Language",
      "title_zh": "测量与基准测试大语言模型生成说服性语言的能力",
      "authors": [
        "Amalie Brogaard Pauli",
        "Isabelle Augenstein",
        "Ira Assent"
      ],
      "abstract": "We are exposed to much information trying to influence us, such as teaser\nmessages, debates, politically framed news, and propaganda - all of which use\npersuasive language. With the recent interest in Large Language Models (LLMs),\nwe study the ability of LLMs to produce persuasive text. As opposed to prior\nwork which focuses on particular domains or types of persuasion, we conduct a\ngeneral study across various domains to measure and benchmark to what degree\nLLMs produce persuasive language - both when explicitly instructed to rewrite\ntext to be more or less persuasive and when only instructed to paraphrase. We\nconstruct the new dataset Persuasive-Pairs of pairs of a short text and its\nrewrite by an LLM to amplify or diminish persuasive language. We multi-annotate\nthe pairs on a relative scale for persuasive language: a valuable resource in\nitself, and for training a regression model to score and benchmark persuasive\nlanguage, including for new LLMs across domains. In our analysis, we find that\ndifferent 'personas' in LLaMA3's system prompt change persuasive language\nsubstantially, even when only instructed to paraphrase.",
      "tldr_zh": "本研究评估了大型语言模型（LLMs）的生成说服性语言的能力，通过跨领域的通用基准测试来衡量其表现。研究者构建了新数据集Persuasive-Pairs，其中包含短文本及其由LLMs重写的版本，用于放大或减少说服性语言，并通过多重标注在相对规模上评估这些对。基于此数据，他们训练了一个回归模型，用于评分和基准测试说服性语言，包括不同LLMs在各种领域的表现。分析结果显示，LLaMA3的系统提示中不同'personas'会显著改变说服性语言，即使仅指令进行改述，这突显了LLMs在说服力控制方面的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "NAACL 2025",
      "pdf_url": "http://arxiv.org/pdf/2406.17753v3",
      "published_date": "2024-06-25 17:40:47 UTC",
      "updated_date": "2025-02-20 19:54:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:26:53.090244"
    },
    {
      "arxiv_id": "2406.17746v2",
      "title": "Recite, Reconstruct, Recollect: Memorization in LMs as a Multifaceted Phenomenon",
      "title_zh": "翻译失败",
      "authors": [
        "USVSN Sai Prashanth",
        "Alvin Deng",
        "Kyle O'Brien",
        "Jyothir S V",
        "Mohammad Aflah Khan",
        "Jaydeep Borkar",
        "Christopher A. Choquette-Choo",
        "Jacob Ray Fuehne",
        "Stella Biderman",
        "Tracy Ke",
        "Katherine Lee",
        "Naomi Saphra"
      ],
      "abstract": "Memorization in language models is typically treated as a homogenous\nphenomenon, neglecting the specifics of the memorized data. We instead model\nmemorization as the effect of a set of complex factors that describe each\nsample and relate it to the model and corpus. To build intuition around these\nfactors, we break memorization down into a taxonomy: recitation of highly\nduplicated sequences, reconstruction of inherently predictable sequences, and\nrecollection of sequences that are neither. We demonstrate the usefulness of\nour taxonomy by using it to construct a predictive model for memorization. By\nanalyzing dependencies and inspecting the weights of the predictive model, we\nfind that different factors influence the likelihood of memorization\ndifferently depending on the taxonomic category.",
      "tldr_zh": "这篇论文将语言模型(LMs)中的memorization视为多面现象，受样本、模型和语料库等多种复杂因素影响，而不是单一过程。作者提出一个taxonomy，将memorization分为三类：recitation（高度重复序列的背诵）、reconstruction（固有可预测序列的重构）和recollection（既非重复也非可预测序列的回想）。通过构建基于此分类的预测模型，他们发现不同因素对各memorization类别的概率影响存在差异，从而为理解和预测LMs记忆化提供了新框架。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.17746v2",
      "published_date": "2024-06-25 17:32:16 UTC",
      "updated_date": "2025-05-07 18:36:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:27:05.572436"
    },
    {
      "arxiv_id": "2406.17741v2",
      "title": "Point-SAM: Promptable 3D Segmentation Model for Point Clouds",
      "title_zh": "翻译失败",
      "authors": [
        "Yuchen Zhou",
        "Jiayuan Gu",
        "Tung Yen Chiang",
        "Fanbo Xiang",
        "Hao Su"
      ],
      "abstract": "The development of 2D foundation models for image segmentation has been\nsignificantly advanced by the Segment Anything Model (SAM). However, achieving\nsimilar success in 3D models remains a challenge due to issues such as\nnon-unified data formats, poor model scalability, and the scarcity of labeled\ndata with diverse masks. To this end, we propose a 3D promptable segmentation\nmodel Point-SAM, focusing on point clouds. We employ an efficient\ntransformer-based architecture tailored for point clouds, extending SAM to the\n3D domain. We then distill the rich knowledge from 2D SAM for Point-SAM\ntraining by introducing a data engine to generate part-level and object-level\npseudo-labels at scale from 2D SAM. Our model outperforms state-of-the-art 3D\nsegmentation models on several indoor and outdoor benchmarks and demonstrates a\nvariety of applications, such as interactive 3D annotation and zero-shot 3D\ninstance proposal. Codes and demo can be found at\nhttps://github.com/zyc00/Point-SAM.",
      "tldr_zh": "该研究提出 Point-SAM，一种可提示的 3D 点云分割模型，以解决 3D 模型面临的挑战，如数据格式不统一、模型可扩展性差和标注数据稀缺问题。Point-SAM 采用基于 Transformer 的高效架构，将 2D Segment Anything Model (SAM) 扩展到 3D 领域，并通过数据引擎从 2D SAM 生成大规模的 part-level 和 object-level 伪标签来蒸馏知识进行训练。该模型在多个室内和室外基准上超越现有最先进 3D 分割模型，并展示实际应用，如交互式 3D 标注和零样本 3D 实例提案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.17741v2",
      "published_date": "2024-06-25 17:28:03 UTC",
      "updated_date": "2024-12-02 23:28:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:27:17.724036"
    },
    {
      "arxiv_id": "2406.17740v3",
      "title": "Structured Unrestricted-Rank Matrices for Parameter Efficient Fine-tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Arijit Sehanobish",
        "Avinava Dubey",
        "Krzysztof Choromanski",
        "Somnath Basu Roy Chowdhury",
        "Deepali Jain",
        "Vikas Sindhwani",
        "Snigdha Chaturvedi"
      ],
      "abstract": "Recent efforts to scale Transformer models have demonstrated rapid progress\nacross a wide range of tasks (Wei et al., 2022). However, fine-tuning these\nmodels for downstream tasks is expensive due to their large parameter counts.\nParameter-efficient fine-tuning (PEFT) approaches have emerged as a viable\nalternative by allowing us to fine-tune models by updating only a small number\nof parameters. In this work, we propose a general framework for parameter\nefficient fine-tuning (PEFT), based on structured unrestricted-rank matrices\n(SURM) which can serve as a drop-in replacement for popular approaches such as\nAdapters and LoRA. Unlike other methods like LoRA, SURMs provides more\nflexibility in finding the right balance between compactness and\nexpressiveness. This is achieved by using low displacement rank matrices\n(LDRMs), which hasn't been used in this context before. SURMs remain\ncompetitive with baselines, often providing significant quality improvements\nwhile using a smaller parameter budget. SURMs achieve 5-7% accuracy gains on\nvarious image classification tasks while replacing low-rank matrices in LoRA.\nIt also results in up to 12x reduction of the number of parameters in adapters\n(with virtually no loss in quality) on the GLUE benchmark.",
      "tldr_zh": "这篇论文提出了一种基于 Structured Unrestricted-Rank Matrices (SURM) 的通用框架，用于参数高效微调 (PEFT)，旨在通过更新少量参数来降低大规模 Transformer 模型的微调成本，同时作为 Adapters 和 LoRA 的直接替代方案。SURM 创新性地引入 Low Displacement Rank Matrices (LDRMs)，提供更大的灵活性，以在模型的紧凑性和表现力之间实现最佳平衡。实验结果显示，SURM 在图像分类任务上比 LoRA 提升了 5-7% 的准确率，并在 GLUE 基准上实现了高达 12 倍的参数减少，同时几乎不损失性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.17740v3",
      "published_date": "2024-06-25 17:26:05 UTC",
      "updated_date": "2024-12-17 21:11:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:27:29.871781"
    },
    {
      "arxiv_id": "2406.17739v1",
      "title": "Find Parent then Label Children: A Two-stage Taxonomy Completion Method with Pre-trained Language Model",
      "title_zh": "先找父节点再标记子节点：一种基于预训练语言模型的两阶段分类学补全方法",
      "authors": [
        "Fei Xia",
        "Yixuan Weng",
        "Shizhu He",
        "Kang Liu",
        "Jun Zhao"
      ],
      "abstract": "Taxonomies, which organize domain concepts into hierarchical structures, are\ncrucial for building knowledge systems and downstream applications. As domain\nknowledge evolves, taxonomies need to be continuously updated to include new\nconcepts. Previous approaches have mainly focused on adding concepts to the\nleaf nodes of the existing hierarchical tree, which does not fully utilize the\ntaxonomy's knowledge and is unable to update the original taxonomy structure\n(usually involving non-leaf nodes). In this paper, we propose a two-stage\nmethod called ATTEMPT for taxonomy completion. Our method inserts new concepts\ninto the correct position by finding a parent node and labeling child nodes.\nSpecifically, by combining local nodes with prompts to generate natural\nsentences, we take advantage of pre-trained language models for\nhypernym/hyponymy recognition. Experimental results on two public datasets\n(including six domains) show that ATTEMPT performs best on both taxonomy\ncompletion and extension tasks, surpassing existing methods.",
      "tldr_zh": "该研究针对税onomies（组织领域概念的层次结构）在知识系统中的更新问题，提出了一种两阶段方法ATTEMPT，以处理现有方法仅限于叶节点添加的局限性。方法首先通过结合本地节点和提示生成自然句子，利用Pre-trained Language Model进行hypernym/hyponymy识别，从而找到新概念的父节点并标记子节点。实验结果显示，ATTEMPT在两个公共数据集（涵盖六个领域）的税onomies完成和扩展任务上，超越了现有方法，展示了其优越性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.17739v1",
      "published_date": "2024-06-25 17:25:02 UTC",
      "updated_date": "2024-06-25 17:25:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:27:41.472959"
    },
    {
      "arxiv_id": "2406.17737v1",
      "title": "LLM Targeted Underperformance Disproportionately Impacts Vulnerable Users",
      "title_zh": "翻译失败",
      "authors": [
        "Elinor Poole-Dayan",
        "Deb Roy",
        "Jad Kabbara"
      ],
      "abstract": "While state-of-the-art Large Language Models (LLMs) have shown impressive\nperformance on many tasks, there has been extensive research on undesirable\nmodel behavior such as hallucinations and bias. In this work, we investigate\nhow the quality of LLM responses changes in terms of information accuracy,\ntruthfulness, and refusals depending on three user traits: English proficiency,\neducation level, and country of origin. We present extensive experimentation on\nthree state-of-the-art LLMs and two different datasets targeting truthfulness\nand factuality. Our findings suggest that undesirable behaviors in\nstate-of-the-art LLMs occur disproportionately more for users with lower\nEnglish proficiency, of lower education status, and originating from outside\nthe US, rendering these models unreliable sources of information towards their\nmost vulnerable users.",
      "tldr_zh": "本研究调查了大型语言模型（LLMs）在信息准确性、真诚性和拒绝响应等方面的表现如何受用户特征影响，包括英语熟练度（English proficiency）、教育水平（education level）和原籍国（country of origin）。通过对三个最先进LLMs和两个针对真实性和事实性的数据集进行广泛实验，研究发现这些模型的不当行为（如幻觉和偏见）更频繁地发生在英语熟练度较低、教育水平较低或非美国用户的群体中。结果表明，这种针对性的性能下降使LLMs成为不可靠的信息来源，尤其对最脆弱用户造成不成比例的负面影响。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.17737v1",
      "published_date": "2024-06-25 17:24:07 UTC",
      "updated_date": "2024-06-25 17:24:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:27:53.323701"
    },
    {
      "arxiv_id": "2406.17838v1",
      "title": "InFiConD: Interactive No-code Fine-tuning with Concept-based Knowledge Distillation",
      "title_zh": "翻译失败",
      "authors": [
        "Jinbin Huang",
        "Wenbin He",
        "Liang Gou",
        "Liu Ren",
        "Chris Bryan"
      ],
      "abstract": "The emergence of large-scale pre-trained models has heightened their\napplication in various downstream tasks, yet deployment is a challenge in\nenvironments with limited computational resources. Knowledge distillation has\nemerged as a solution in such scenarios, whereby knowledge from large teacher\nmodels is transferred into smaller student' models, but this is a non-trivial\nprocess that traditionally requires technical expertise in AI/ML. To address\nthese challenges, this paper presents InFiConD, a novel framework that\nleverages visual concepts to implement the knowledge distillation process and\nenable subsequent no-code fine-tuning of student models. We develop a novel\nknowledge distillation pipeline based on extracting text-aligned visual\nconcepts from a concept corpus using multimodal models, and construct highly\ninterpretable linear student models based on visual concepts that mimic a\nteacher model in a response-based manner. InFiConD's interface allows users to\ninteractively fine-tune the student model by manipulating concept influences\ndirectly in the user interface. We validate InFiConD via a robust usage\nscenario and user study. Our findings indicate that InFiConD's\nhuman-in-the-loop and visualization-driven approach enables users to\neffectively create and analyze student models, understand how knowledge is\ntransferred, and efficiently perform fine-tuning operations. We discuss how\nthis work highlights the potential of interactive and visual methods in making\nknowledge distillation and subsequent no-code fine-tuning more accessible and\nadaptable to a wider range of users with domain-specific demands.",
      "tldr_zh": "这篇论文介绍了 InFiConD 框架，一种基于概念的知识 distillation 方法，旨在简化大型预训练模型在计算资源有限环境中的部署，同时无需专业 AI/ML 技术。该框架通过提取文本对齐的视觉 concepts 和使用多模态模型构建可解释的线性学生模型，实现响应式模仿教师模型，并提供交互式界面让用户直接操作概念影响进行无代码 fine-tuning。实验和用户研究表明，InFiConD 的可视化和人类参与方法能有效帮助用户理解知识转移过程、分析模型并高效执行 fine-tuning 操作，从而使知识 distillation 更易访问并适应领域特定需求。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.17838v1",
      "published_date": "2024-06-25 16:56:45 UTC",
      "updated_date": "2024-06-25 16:56:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:28:06.419909"
    },
    {
      "arxiv_id": "2406.17714v3",
      "title": "Compositional Models for Estimating Causal Effects",
      "title_zh": "用于估计因果效应的组合模型",
      "authors": [
        "Purva Pruthi",
        "David Jensen"
      ],
      "abstract": "Many real-world systems can be usefully represented as sets of interacting\ncomponents. Examples include computational systems, such as query processors\nand compilers, natural systems, such as cells and ecosystems, and social\nsystems, such as families and organizations. However, current approaches to\nestimating potential outcomes and causal effects typically treat such systems\nas single units, represent them with a fixed set of variables, and assume a\nhomogeneous data-generating process. In this work, we study a compositional\napproach for estimating individual-level potential outcomes and causal effects\nin structured systems, where each unit is represented by an instance-specific\ncomposition of multiple heterogeneous components. The compositional approach\ndecomposes unit-level causal queries into more fine-grained queries, explicitly\nmodeling how unit-level interventions affect component-level outcomes to\ngenerate a unit's outcome. We demonstrate this approach using modular neural\nnetwork architectures and show that it provides benefits for causal effect\nestimation from observational data, such as accurate causal effect estimation\nfor structured units, increased sample efficiency, improved overlap between\ntreatment and control groups, and compositional generalization to units with\nunseen combinations of components. Remarkably, our results show that\ncompositional modeling can improve the accuracy of causal estimation even when\ncomponent-level outcomes are unobserved. We also create and use a set of\nreal-world evaluation environments for the empirical evaluation of\ncompositional approaches for causal effect estimation and demonstrate the role\nof composition structure, varying amounts of component-level data access, and\ncomponent heterogeneity in the performance of compositional models as compared\nto the non-compositional approaches.",
      "tldr_zh": "这篇论文提出了一种组合式(compositional)方法，用于估计结构化系统的个体水平潜在结果(potential outcomes)和因果效应(causal effects)，将系统视为相互交互的组件，而不是单一单位。方法通过将单位级查询分解为更细粒度的组件级查询，并使用模块化神经网络(modular neural network architectures)来明确建模干预对组件的影响，从而提升了因果估计的准确性。实验结果显示，该方法在观察数据上提高了样本效率、改善了治疗和控制组的重叠，并实现了对未见组件组合的组合泛化，即使组件级结果未被观察也能有效。此外，论文创建了真实世界的评估环境，证明了组合式模型在组件结构和异质性方面的优势。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "stat.ME"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at the Fourth Conference on Causal Learning and Reasoning\n  (CLeaR), 2025",
      "pdf_url": "http://arxiv.org/pdf/2406.17714v3",
      "published_date": "2024-06-25 16:56:17 UTC",
      "updated_date": "2025-03-17 05:36:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:28:20.105228"
    },
    {
      "arxiv_id": "2406.17711v1",
      "title": "Data curation via joint example selection further accelerates multimodal learning",
      "title_zh": "翻译失败",
      "authors": [
        "Talfan Evans",
        "Nikhil Parthasarathy",
        "Hamza Merzic",
        "Olivier J. Henaff"
      ],
      "abstract": "Data curation is an essential component of large-scale pretraining. In this\nwork, we demonstrate that jointly selecting batches of data is more effective\nfor learning than selecting examples independently. Multimodal contrastive\nobjectives expose the dependencies between data and thus naturally yield\ncriteria for measuring the joint learnability of a batch. We derive a simple\nand tractable algorithm for selecting such batches, which significantly\naccelerate training beyond individually-prioritized data points. As performance\nimproves by selecting from larger super-batches, we also leverage recent\nadvances in model approximation to reduce the associated computational\noverhead. As a result, our approach--multimodal contrastive learning with joint\nexample selection (JEST)--surpasses state-of-the-art models with up to\n13$\\times$ fewer iterations and 10$\\times$ less computation. Essential to the\nperformance of JEST is the ability to steer the data selection process towards\nthe distribution of smaller, well-curated datasets via pretrained reference\nmodels, exposing the level of data curation as a new dimension for neural\nscaling laws.",
      "tldr_zh": "该研究证明，通过联合选择数据批次而非独立选择示例，能够更有效地加速多模态学习，因为多模态对比目标揭示了数据间的依赖性。论文提出了一种简单可行的算法（JEST），结合多模态对比学习从更大超批次中选择高可学习性批次，并利用模型近似技术降低计算开销。结果显示，JEST 比最先进模型在迭代次数减少多达 13 倍、计算量减少 10 倍的情况下实现性能提升，并将数据整理水平作为神经缩放定律的新维度。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Main text: 9 pages, 5 figures, 3 tables, 1 algorithm. Appendix: 7\n  pages, 5 figures, 1 table, 2. algorithm",
      "pdf_url": "http://arxiv.org/pdf/2406.17711v1",
      "published_date": "2024-06-25 16:52:37 UTC",
      "updated_date": "2024-06-25 16:52:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:28:31.895022"
    },
    {
      "arxiv_id": "2406.17697v1",
      "title": "HGTDP-DTA: Hybrid Graph-Transformer with Dynamic Prompt for Drug-Target Binding Affinity Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Xi Xiao",
        "Wentao Wang",
        "Jiacheng Xie",
        "Lijing Zhu",
        "Gaofei Chen",
        "Zhengji Li",
        "Tianyang Wang",
        "Min Xu"
      ],
      "abstract": "Drug target binding affinity (DTA) is a key criterion for drug screening.\nExisting experimental methods are time-consuming and rely on limited structural\nand domain information. While learning-based methods can model sequence and\nstructural information, they struggle to integrate contextual data and often\nlack comprehensive modeling of drug-target interactions. In this study, we\npropose a novel DTA prediction method, termed HGTDP-DTA, which utilizes dynamic\nprompts within a hybrid Graph-Transformer framework. Our method generates\ncontext-specific prompts for each drug-target pair, enhancing the model's\nability to capture unique interactions. The introduction of prompt tuning\nfurther optimizes the prediction process by filtering out irrelevant noise and\nemphasizing task-relevant information, dynamically adjusting the input features\nof the molecular graph. The proposed hybrid Graph-Transformer architecture\ncombines structural information from Graph Convolutional Networks (GCNs) with\nsequence information captured by Transformers, facilitating the interaction\nbetween global and local information. Additionally, we adopted the multi-view\nfeature fusion method to project molecular graph views and affinity subgraph\nviews into a common feature space, effectively combining structural and\ncontextual information. Experiments on two widely used public datasets, Davis\nand KIBA, show that HGTDP-DTA outperforms state-of-the-art DTA prediction\nmethods in both prediction performance and generalization ability.",
      "tldr_zh": "本研究针对药物靶点结合亲和力(DTA)预测中的挑战，提出了一种新型方法HGTDP-DTA，该方法采用动态提示与混合Graph-Transformer框架，生成特定于每个药物-靶点对的上下文提示，以增强交互建模并过滤无关噪声。框架结合Graph Convolutional Networks (GCNs)处理结构信息、Transformers捕捉序列信息，并通过多视图特征融合整合全局和局部数据。实验结果显示，在Davis和KIBA数据集上，HGTDP-DTA在预测性能和泛化能力方面均优于现有最先进方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.17697v1",
      "published_date": "2024-06-25 16:33:33 UTC",
      "updated_date": "2024-06-25 16:33:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:28:43.756811"
    },
    {
      "arxiv_id": "2407.11003v1",
      "title": "Using Large Language Models in Public Transit Systems, San Antonio as a case study",
      "title_zh": "翻译失败",
      "authors": [
        "Ramya Jonnala",
        "Gongbo Liang",
        "Jeong Yang",
        "Izzat Alsmadi"
      ],
      "abstract": "The integration of large language models into public transit systems\nrepresents a significant advancement in urban transportation management and\npassenger experience. This study examines the impact of LLMs within San\nAntonio's public transit system, leveraging their capabilities in natural\nlanguage processing, data analysis, and real time communication. By utilizing\nGTFS and other public transportation information, the research highlights the\ntransformative potential of LLMs in enhancing route planning, reducing wait\ntimes, and providing personalized travel assistance. Our case study is the city\nof San Antonio as part of a project aiming to demonstrate how LLMs can optimize\nresource allocation, improve passenger satisfaction, and support decision\nmaking processes in transit management. We evaluated LLM responses to questions\nrelated to both information retrieval and also understanding. Ultimately, we\nbelieve that the adoption of LLMs in public transit systems can lead to more\nefficient, responsive, and user-friendly transportation networks, providing a\nmodel for other cities to follow.",
      "tldr_zh": "本研究探讨了将大型语言模型（LLMs）整合到公共交通系统中的潜力，以圣安东尼奥市为例，旨在提升城市交通管理和乘客体验。研究利用GTFS和其他公共交通数据，评估LLMs在自然语言处理、数据分析和实时通信方面的能力，包括优化路线规划、减少等待时间以及提供个性化旅行协助。结果显示，LLMs能显著改善资源分配、提升乘客满意度和支持决策过程，并为其他城市提供可借鉴的模式。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.11003v1",
      "published_date": "2024-06-25 16:32:56 UTC",
      "updated_date": "2024-06-25 16:32:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:28:54.112563"
    },
    {
      "arxiv_id": "2406.17688v1",
      "title": "Unified Auto-Encoding with Masked Diffusion",
      "title_zh": "统一",
      "authors": [
        "Philippe Hansen-Estruch",
        "Sriram Vishwanath",
        "Amy Zhang",
        "Manan Tomar"
      ],
      "abstract": "At the core of both successful generative and self-supervised representation\nlearning models there is a reconstruction objective that incorporates some form\nof image corruption. Diffusion models implement this approach through a\nscheduled Gaussian corruption process, while masked auto-encoder models do so\nby masking patches of the image. Despite their different approaches, the\nunderlying similarity in their methodologies suggests a promising avenue for an\nauto-encoder capable of both de-noising tasks. We propose a unified\nself-supervised objective, dubbed Unified Masked Diffusion (UMD), that combines\npatch-based and noise-based corruption techniques within a single auto-encoding\nframework. Specifically, UMD modifies the diffusion transformer (DiT) training\nprocess by introducing an additional noise-free, high masking representation\nstep in the diffusion noising schedule, and utilizes a mixed masked and noised\nimage for subsequent timesteps. By integrating features useful for diffusion\nmodeling and for predicting masked patch tokens, UMD achieves strong\nperformance in downstream generative and representation learning tasks,\nincluding linear probing and class-conditional generation. This is achieved\nwithout the need for heavy data augmentations, multiple views, or additional\nencoders. Furthermore, UMD improves over the computational efficiency of prior\ndiffusion based methods in total training time. We release our code at\nhttps://github.com/philippe-eecs/small-vision.",
      "tldr_zh": "该论文提出Unified Masked Diffusion (UMD)，一种统一的自我监督目标框架，将扩散模型的噪声腐败和masked auto-encoder的图像补丁掩码技术结合，实现高效的图像重建和生成任务。UMD通过修改Diffusion Transformer (DiT)的训练过程，添加一个无噪声的高掩码表示步骤，并使用混合掩码和噪声图像进行后续处理，从而在不需额外数据增强或编码器的情况下，提升下游任务性能。实验结果显示，UMD在线性探测和条件生成等任务上表现出色，并显著提高了计算效率，代码已开源。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "I.2.10"
      ],
      "primary_category": "cs.CV",
      "comment": "19 Pages, 8 Figures, 3Tables",
      "pdf_url": "http://arxiv.org/pdf/2406.17688v1",
      "published_date": "2024-06-25 16:24:34 UTC",
      "updated_date": "2024-06-25 16:24:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:29:05.716889"
    },
    {
      "arxiv_id": "2406.17837v1",
      "title": "Transformer Normalisation Layers and the Independence of Semantic Subspaces",
      "title_zh": "Transformer 归一化层与语义子空间的独立性",
      "authors": [
        "Stephen Menary",
        "Samuel Kaski",
        "Andre Freitas"
      ],
      "abstract": "Recent works have shown that transformers can solve contextual reasoning\ntasks by internally executing computational graphs called circuits. Circuits\noften use attention to logically match information from subspaces of the\nrepresentation, e.g. using position-in-sequence to identify the previous token.\nIn this work, we consider a semantic subspace to be any independent subspace of\nthe latent representation that can fully determine an attention distribution.\nWe show that Pre-Norm, the placement of normalisation layer used by\nstate-of-the-art transformers, violates this ability unless the model learns a\nstrict representation structure of orthogonal spheres. This is because it\ncauses linear subspaces to interfere through their common normalisation factor.\nTheoretically, we analyse circuit stability by modelling this interference as\nrandom noise on the $L_2$-norms of the query/key/value vectors, predicting a\nphenomenon of circuit collapse when sparse-attention shifts to a different\ntoken. Empirically, we investigate the sensitivity of real-world models trained\nfor mathematical addition, observing a 1% rate of circuit collapse when the\nnorms are artificially perturbed by $\\lesssim$10%. We contrast Pre-Norm with\nQKV-Norm, which places normalisation after the attention head's linear\noperators. Theoretically this relaxes the representational constraints.\nEmpirically we observe comparable in-distribution but worse out-of-distribution\nperformance.",
      "tldr_zh": "这篇论文探讨了Transformer模型中归一化层的放置（Pre-Norm）如何影响语义子空间（semantic subspace）的独立性，语义子空间被定义为表示中能完全决定attention分布的独立子空间。研究发现，Pre-Norm会导致线性子空间通过共同的归一化因子相互干扰，除非模型学习到严格的正交球体结构，从而可能引起circuits collapse的现象。作者通过理论分析，将这种干扰建模为query/key/value向量的L2-范数上的随机噪声，并通过实证实验在数学加法任务上验证，当范数扰动小于10%时，circuits collapse的发生率约为1%。与Pre-Norm相比，QKV-Norm（将归一化置于attention head的线性操作之后）放宽了表示约束，但在分布内性能相当而分布外性能更差。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.17837v1",
      "published_date": "2024-06-25 16:16:38 UTC",
      "updated_date": "2024-06-25 16:16:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:29:21.145985"
    },
    {
      "arxiv_id": "2406.17836v1",
      "title": "A Moonshot for AI Oracles in the Sciences",
      "title_zh": "翻译失败",
      "authors": [
        "Bryan Kaiser",
        "Tailin Wu",
        "Maike Sonnewald",
        "Colin Thackray",
        "Skylar Callis"
      ],
      "abstract": "Nobel laureate Philip Anderson and Elihu Abrahams once stated that, \"even if\nmachines did contribute to normal science, we see no mechanism by which they\ncould create a Kuhnian revolution and thereby establish a new physical law.\" In\nthis Perspective, we draw upon insights from the philosophies of science and\nartificial intelligence (AI) to propose necessary conditions of precisely such\na mechanism for generating revolutionary mathematical theories. Recent\nadvancements in AI suggest that satisfying the proposed necessary conditions by\nmachines may be plausible; thus, our proposed necessary conditions also define\na moonshot challenge. We also propose a heuristic definition of the\nintelligibility of mathematical theories to accelerate the development of\nmachine theorists.",
      "tldr_zh": "这篇论文挑战了 Philip Anderson 和 Elihu Abrahams 的观点，认为 AI 可能通过生成革命性数学理论来引发 Kuhnian revolution。作者借鉴科学和 AI 哲学，提出了 AI 实现此目标的必要条件，并将其定义为一个 moonshot challenge，以推动机器生成新物理定律或理论的可能性。论文还提出数学理论的 intelligibility 定义，作为一个启发式框架，来加速机器理论家的开发。这些贡献为 AI 在科学领域的革命性应用提供了潜在机制和方向。",
      "categories": [
        "cs.AI",
        "cs.CY",
        "math.HO",
        "physics.soc-ph"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.17836v1",
      "published_date": "2024-06-25 16:15:57 UTC",
      "updated_date": "2024-06-25 16:15:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:29:30.534144"
    },
    {
      "arxiv_id": "2407.12808v1",
      "title": "Towards Optimal Trade-offs in Knowledge Distillation for CNNs and Vision Transformers at the Edge",
      "title_zh": "翻译失败",
      "authors": [
        "John Violos",
        "Symeon Papadopoulos",
        "Ioannis Kompatsiaris"
      ],
      "abstract": "This paper discusses four facets of the Knowledge Distillation (KD) process\nfor Convolutional Neural Networks (CNNs) and Vision Transformer (ViT)\narchitectures, particularly when executed on edge devices with constrained\nprocessing capabilities. First, we conduct a comparative analysis of the KD\nprocess between CNNs and ViT architectures, aiming to elucidate the feasibility\nand efficacy of employing different architectural configurations for the\nteacher and student, while assessing their performance and efficiency. Second,\nwe explore the impact of varying the size of the student model on accuracy and\ninference speed, while maintaining a constant KD duration. Third, we examine\nthe effects of employing higher resolution images on the accuracy, memory\nfootprint and computational workload. Last, we examine the performance\nimprovements obtained by fine-tuning the student model after KD to specific\ndownstream tasks. Through empirical evaluations and analyses, this research\nprovides AI practitioners with insights into optimal strategies for maximizing\nthe effectiveness of the KD process on edge devices.",
      "tldr_zh": "这篇论文探讨了在边缘设备上针对 CNNs 和 Vision Transformers (ViT) 架构进行 Knowledge Distillation (KD) 的最优权衡，涵盖四个关键方面：比较教师和学生模型的架构配置以评估性能和效率；分析学生模型大小对准确性和推理速度的影响，同时保持 KD 持续时间不变；考察使用更高分辨率图像对准确性、内存占用和计算负载的影响；以及评估 KD 后对学生模型进行微调以提升下游任务性能。通过实证评估，该研究为 AI 从业者提供了优化 KD 过程的实用策略。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.12808v1",
      "published_date": "2024-06-25 16:15:02 UTC",
      "updated_date": "2024-06-25 16:15:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:29:43.246893"
    },
    {
      "arxiv_id": "2406.17663v2",
      "title": "LLM-ARC: Enhancing LLMs with an Automated Reasoning Critic",
      "title_zh": "翻译失败",
      "authors": [
        "Aditya Kalyanpur",
        "Kailash Karthik Saravanakumar",
        "Victor Barres",
        "Jennifer Chu-Carroll",
        "David Melville",
        "David Ferrucci"
      ],
      "abstract": "We introduce LLM-ARC, a neuro-symbolic framework designed to enhance the\nlogical reasoning capabilities of Large Language Models (LLMs), by combining\nthem with an Automated Reasoning Critic (ARC). LLM-ARC employs an Actor-Critic\nmethod where the LLM Actor generates declarative logic programs along with\ntests for semantic correctness, while the Automated Reasoning Critic evaluates\nthe code, runs the tests and provides feedback on test failures for iterative\nrefinement. Implemented using Answer Set Programming (ASP), LLM-ARC achieves a\nnew state-of-the-art accuracy of 88.32% on the FOLIO benchmark which tests\ncomplex logical reasoning capabilities. Our experiments demonstrate significant\nimprovements over LLM-only baselines, highlighting the importance of logic test\ngeneration and iterative self-refinement. We achieve our best result using a\nfully automated self-supervised training loop where the Actor is trained on\nend-to-end dialog traces with Critic feedback. We discuss potential\nenhancements and provide a detailed error analysis, showcasing the robustness\nand efficacy of LLM-ARC for complex natural language reasoning tasks.",
      "tldr_zh": "我们引入了 LLM-ARC，一种结合大型语言模型(LLMs)和 Automated Reasoning Critic(ARC)的神经符号框架，旨在提升 LLMs 的逻辑推理能力。该框架采用 Actor-Critic 方法，其中 LLM Actor 生成声明式逻辑程序和语义正确性测试，而 ARC 负责评估代码、运行测试并提供反馈以进行迭代自精炼。使用 Answer Set Programming(ASP) 实现的 LLM-ARC 在 FOLIO benchmark 上达到了 88.32% 的新 state-of-the-art 准确率，比仅使用 LLMs 的基线有显著改善。实验还展示了通过自动化自监督训练循环进行端到端对话训练的功效，并讨论了潜在增强和错误分析，以证明框架在复杂自然语言推理任务中的稳健性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.17663v2",
      "published_date": "2024-06-25 15:52:15 UTC",
      "updated_date": "2024-07-19 12:59:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:29:56.215752"
    },
    {
      "arxiv_id": "2406.17659v1",
      "title": "DKPROMPT: Domain Knowledge Prompting Vision-Language Models for Open-World Planning",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaohan Zhang",
        "Zainab Altaweel",
        "Yohei Hayamizu",
        "Yan Ding",
        "Saeid Amiri",
        "Hao Yang",
        "Andy Kaminski",
        "Chad Esselink",
        "Shiqi Zhang"
      ],
      "abstract": "Vision-language models (VLMs) have been applied to robot task planning\nproblems, where the robot receives a task in natural language and generates\nplans based on visual inputs. While current VLMs have demonstrated strong\nvision-language understanding capabilities, their performance is still far from\nbeing satisfactory in planning tasks. At the same time, although classical task\nplanners, such as PDDL-based, are strong in planning for long-horizon tasks,\nthey do not work well in open worlds where unforeseen situations are common. In\nthis paper, we propose a novel task planning and execution framework, called\nDKPROMPT, which automates VLM prompting using domain knowledge in PDDL for\nclassical planning in open worlds. Results from quantitative experiments show\nthat DKPROMPT outperforms classical planning, pure VLM-based and a few other\ncompetitive baselines in task completion rate.",
      "tldr_zh": "该研究探讨了视觉语言模型(VLMs)在机器人任务规划中的局限性，包括在开放世界环境下表现不佳的问题，同时指出了经典任务规划器（如PDDL-based）在处理长horizon任务时的优势但缺乏灵活性。为此，提出DKPROMPT框架，该框架利用PDDL中的领域知识自动提示VLMs，实现开放世界的任务规划和执行。实验结果显示，DKPROMPT在任务完成率上优于经典规划、纯VLM方法和其他基线模型。",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.17659v1",
      "published_date": "2024-06-25 15:49:47 UTC",
      "updated_date": "2024-06-25 15:49:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:30:05.731631"
    },
    {
      "arxiv_id": "2406.17654v2",
      "title": "MDHA: Multi-Scale Deformable Transformer with Hybrid Anchors for Multi-View 3D Object Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Michelle Adeline",
        "Junn Yong Loo",
        "Vishnu Monn Baskaran"
      ],
      "abstract": "Multi-view 3D object detection is a crucial component of autonomous driving\nsystems. Contemporary query-based methods primarily depend either on\ndataset-specific initialization of 3D anchors, introducing bias, or utilize\ndense attention mechanisms, which are computationally inefficient and\nunscalable. To overcome these issues, we present MDHA, a novel sparse\nquery-based framework, which constructs adaptive 3D output proposals using\nhybrid anchors from multi-view, multi-scale image input. Fixed 2D anchors are\ncombined with depth predictions to form 2.5D anchors, which are projected to\nobtain 3D proposals. To ensure high efficiency, our proposed Anchor Encoder\nperforms sparse refinement and selects the top-$k$ anchors and features.\nMoreover, while existing multi-view attention mechanisms rely on projecting\nreference points to multiple images, our novel Circular Deformable Attention\nmechanism only projects to a single image but allows reference points to\nseamlessly attend to adjacent images, improving efficiency without compromising\non performance. On the nuScenes val set, it achieves 46.4\\% mAP and 55.0\\% NDS\nwith a ResNet101 backbone. MDHA significantly outperforms the baseline where\nanchor proposals are modelled as learnable embeddings. Code is available at\nhttps://github.com/NaomiEX/MDHA.",
      "tldr_zh": "本研究提出 MDHA，一种基于 Multi-Scale Deformable Transformer 的稀疏查询框架，用于多视图 3D 对象检测，以解决现有方法依赖数据集特定初始化锚点导致的偏置和计算密集问题。MDHA 通过结合固定 2D 锚点与深度预测生成 2.5D 锚点，并投影得到自适应 3D 提案；同时，引入 Anchor Encoder 进行稀疏精炼和 top-k 选择，以及 Circular Deformable Attention 机制，仅投影到单个图像但允许参考点关注相邻图像，从而提升效率。实验结果显示，在 nuScenes val set 上，使用 ResNet101 骨干网，MDHA 达到 46.4% mAP 和 55.0% NDS，显著优于基线模型。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted at the IEEE/RSJ International Conference on Intelligent\n  Robots and Systems (IROS) 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.17654v2",
      "published_date": "2024-06-25 15:46:39 UTC",
      "updated_date": "2024-11-09 12:00:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:30:19.750796"
    },
    {
      "arxiv_id": "2406.17651v5",
      "title": "Software Model Evolution with Large Language Models: Experiments on Simulated, Public, and Industrial Datasets",
      "title_zh": "使用大语言模型的软件模型演化：在模拟、公共和工业数据集上的实验",
      "authors": [
        "Christof Tinnes",
        "Alisa Welter",
        "Sven Apel"
      ],
      "abstract": "Modeling structure and behavior of software systems plays a crucial role in\nthe industrial practice of software engineering. As with other software\nengineering artifacts, software models are subject to evolution. Supporting\nmodelers in evolving software models with recommendations for model completions\nis still an open problem, though. In this paper, we explore the potential of\nlarge language models for this task. In particular, we propose an approach,\nRAMC, leveraging large language models, model histories, and\nretrieval-augmented generation for model completion. Through experiments on\nthree datasets, including an industrial application, one public open-source\ncommunity dataset, and one controlled collection of simulated model\nrepositories, we evaluate the potential of large language models for model\ncompletion with RAMC. We found that large language models are indeed a\npromising technology for supporting software model evolution (62.30%\nsemantically correct completions on real-world industrial data and up to 86.19%\ntype-correct completions). The general inference capabilities of large language\nmodels are particularly useful when dealing with concepts for which there are\nfew, noisy, or no examples at all.",
      "tldr_zh": "本研究探讨了大型语言模型（Large Language Models）在软件模型演化中的潜力，提出了一种名为 RAMC 的方法，该方法结合模型历史和检索增强生成（Retrieval-Augmented Generation），用于提供软件模型完成的推荐。RAMC 通过利用 LLMs 的泛化能力，支持模型者在处理软件系统结构和行为演化时自动完成任务。实验在三个数据集上进行，包括工业应用、公开开源社区数据和模拟模型仓库，结果显示 LLMs 在真实工业数据上实现了 62.30% 的语义正确率和高达 86.19% 的类型正确率，尤其在示例稀缺或噪声数据场景下表现出色。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "94-04",
        "D.2.2"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.17651v5",
      "published_date": "2024-06-25 15:43:20 UTC",
      "updated_date": "2024-12-10 09:54:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:30:32.847602"
    },
    {
      "arxiv_id": "2406.17650v2",
      "title": "ELIZA Reinterpreted: The world's first chatbot was not intended as a chatbot at all",
      "title_zh": "翻译失败",
      "authors": [
        "Jeff Shrager"
      ],
      "abstract": "ELIZA, often considered the world's first chatbot, was written by Joseph\nWeizenbaum in the early 1960s. Weizenbaum did not intend to invent the chatbot,\nbut rather to build a platform for research into human-machine conversation and\nthe important cognitive processes of interpretation and misinterpretation. His\npurpose was obscured by ELIZA's fame, resulting in large part from the\nfortuitous timing of it's creation, and it's escape into the wild. In this\npaper I provide a rich historical context for ELIZA's creation, demonstrating\nthat ELIZA arose from the intersection of some of the central threads in the\ntechnical history of AI. I also briefly discuss how ELIZA escaped into the\nworld, and how its accidental escape, along with several coincidental turns of\nthe programming language screws, led both to the misapprehension that ELIZA was\nintended as a chatbot, and to the loss of the original ELIZA to history for\nover 50 years.",
      "tldr_zh": "该论文重新解读了ELIZA程序，指出它并非如世人所知的世界首个chatbot，而是Joseph Weizenbaum在1960年代早期创建的，用于研究人类-机器对话、解释和误解认知过程的平台。作者通过提供丰富的历史背景，展示了ELIZA如何源于AI技术历史的关键交汇点，包括其创作时机和意外传播。最终，论文揭示了ELIZA的意外流行和一些编程语言巧合导致了对其意图的误解，并解释了原版ELIZA丢失超过50年的原因，为AI历史研究提供了更准确的视角。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CY",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "In process of journal review",
      "pdf_url": "http://arxiv.org/pdf/2406.17650v2",
      "published_date": "2024-06-25 15:41:40 UTC",
      "updated_date": "2024-09-19 15:13:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:30:42.886014"
    },
    {
      "arxiv_id": "2406.17835v1",
      "title": "The Use of AI-Robotic Systems for Scientific Discovery",
      "title_zh": "翻译失败",
      "authors": [
        "Alexander H. Gower",
        "Konstantin Korovin",
        "Daniel Brunnsåker",
        "Filip Kronström",
        "Gabriel K. Reder",
        "Ievgeniia A. Tiukova",
        "Ronald S. Reiserer",
        "John P. Wikswo",
        "Ross D. King"
      ],
      "abstract": "The process of developing theories and models and testing them with\nexperiments is fundamental to the scientific method. Automating the entire\nscientific method then requires not only automation of the induction of\ntheories from data, but also experimentation from design to implementation.\nThis is the idea behind a robot scientist -- a coupled system of AI and\nlaboratory robotics that has agency to test hypotheses with real-world\nexperiments. In this chapter we explore some of the fundamentals of robot\nscientists in the philosophy of science. We also map the activities of a robot\nscientist to machine learning paradigms, and argue that the scientific method\nshares an analogy with active learning. We demonstrate these concepts using\nexamples from previous robot scientists, and also from Genesis: a next\ngeneration robot scientist designed for research in systems biology, comprising\na micro-fluidic system with 1000 computer-controlled micro-bioreactors and\ninterpretable models based in controlled vocabularies and logic.",
      "tldr_zh": "这篇论文探讨了 AI-机器人系统在科学发现中的应用，特别是通过机器人科学家（robot scientist）来自动化科学方法，包括从数据中归纳理论和实验设计实施。作者分析了机器人科学家的哲学基础，并将其活动映射到机器学习范式（machine learning paradigms），如主动学习（active learning），强调二者之间的类比。论文通过以往机器人科学家例子和 Genesis 系统（一个包含1000个微流控生物反应器的平台）示范了这一方法在系统生物学研究中的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "19 pages, book chapter",
      "pdf_url": "http://arxiv.org/pdf/2406.17835v1",
      "published_date": "2024-06-25 15:33:01 UTC",
      "updated_date": "2024-06-25 15:33:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:30:56.508919"
    },
    {
      "arxiv_id": "2406.17642v1",
      "title": "Banishing LLM Hallucinations Requires Rethinking Generalization",
      "title_zh": "翻译失败",
      "authors": [
        "Johnny Li",
        "Saksham Consul",
        "Eda Zhou",
        "James Wong",
        "Naila Farooqui",
        "Yuxin Ye",
        "Nithyashree Manohar",
        "Zhuxiaona Wei",
        "Tian Wu",
        "Ben Echols",
        "Sharon Zhou",
        "Gregory Diamos"
      ],
      "abstract": "Despite their powerful chat, coding, and reasoning abilities, Large Language\nModels (LLMs) frequently hallucinate. Conventional wisdom suggests that\nhallucinations are a consequence of a balance between creativity and\nfactuality, which can be mitigated, but not eliminated, by grounding the LLM in\nexternal knowledge sources. Through extensive systematic experiments, we show\nthat these traditional approaches fail to explain why LLMs hallucinate in\npractice. Specifically, we show that LLMs augmented with a massive Mixture of\nMemory Experts (MoME) can easily memorize large datasets of random numbers. We\ncorroborate these experimental findings with a theoretical construction showing\nthat simple neural networks trained to predict the next token hallucinate when\nthe training loss is above a threshold as it usually does in practice when\ntraining on internet scale data. We interpret our findings by comparing against\ntraditional retrieval methods for mitigating hallucinations. We use our\nfindings to design a first generation model for removing hallucinations --\nLamini-1 -- that stores facts in a massive mixture of millions of memory\nexperts that are retrieved dynamically.",
      "tldr_zh": "该研究质疑了传统观点，即大型语言模型（LLMs）的幻觉（hallucinations）可以通过外部知识来源缓解但无法消除。作者通过系统实验证明，添加海量 Mixture of Memory Experts (MoME) 的 LLMs 可以轻松记忆随机数字数据集，但幻觉仍与训练损失高于阈值相关。理论分析进一步显示，简单神经网络在实际互联网规模数据训练中通常会产生幻觉。相比传统检索方法，该研究提出首代模型 Lamini-1，使用数百万动态检索的记忆专家存储事实，从而有效消除幻觉。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.17642v1",
      "published_date": "2024-06-25 15:31:01 UTC",
      "updated_date": "2024-06-25 15:31:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:31:06.792039"
    },
    {
      "arxiv_id": "2406.17640v2",
      "title": "BayTTA: Uncertainty-aware medical image classification with optimized test-time augmentation using Bayesian model averaging",
      "title_zh": "BayTTA：利用贝叶斯模型平均优化测试时增强的、不确定性感知医学图像分类",
      "authors": [
        "Zeinab Sherkatghanad",
        "Moloud Abdar",
        "Mohammadreza Bakhtyari",
        "Pawel Plawiak",
        "Vladimir Makarenkov"
      ],
      "abstract": "Test-time augmentation (TTA) is a well-known technique employed during the\ntesting phase of computer vision tasks. It involves aggregating multiple\naugmented versions of input data. Combining predictions using a simple average\nformulation is a common and straightforward approach after performing TTA. This\npaper introduces a novel framework for optimizing TTA, called BayTTA\n(Bayesian-based TTA), which is based on Bayesian Model Averaging (BMA). First,\nwe generate a prediction list associated with different variations of the input\ndata created through TTA. Then, we use BMA to combine predictions weighted by\nthe respective posterior probabilities. Such an approach allows one to take\ninto account model uncertainty, and thus to enhance the predictive performance\nof the related machine learning or deep learning model. We evaluate the\nperformance of BayTTA on various public data, including three medical image\ndatasets comprising skin cancer, breast cancer, and chest X-ray images and two\nwell-known gene editing datasets, CRISPOR and GUIDE-seq. Our experimental\nresults indicate that BayTTA can be effectively integrated into\nstate-of-the-art deep learning models used in medical image analysis as well as\ninto some popular pre-trained CNN models such as VGG-16, MobileNetV2,\nDenseNet201, ResNet152V2, and InceptionRes-NetV2, leading to the enhancement in\ntheir accuracy and robustness performance. The source code of the proposed\nBayTTA method is freely available at: \\underline\n{https://github.com/Z-Sherkat/BayTTA}.",
      "tldr_zh": "本研究提出BayTTA，一种基于Bayesian Model Averaging (BMA)的优化框架，用于处理测试时增强(TTA)的不确定性问题，从而提升医疗图像分类的预测性能。BayTTA通过生成多种输入数据变体的预测列表，并使用BMA根据后验概率加权结合这些预测，以有效考虑模型不确定性。实验在多个公共数据集上进行，包括皮肤癌、乳腺癌、胸部X光图像以及基因编辑数据集CRISPOR和GUIDE-seq，结果显示BayTTA显著提高了流行深度学习模型（如VGG-16、MobileNetV2等）的准确性和鲁棒性。源代码已在GitHub上公开，提供进一步应用的可能性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.17640v2",
      "published_date": "2024-06-25 15:24:06 UTC",
      "updated_date": "2024-08-27 11:00:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:31:19.249820"
    },
    {
      "arxiv_id": "2406.17639v3",
      "title": "Mitigate the Gap: Investigating Approaches for Improving Cross-Modal Alignment in CLIP",
      "title_zh": "翻译失败",
      "authors": [
        "Sedigheh Eslami",
        "Gerard de Melo"
      ],
      "abstract": "Contrastive Language--Image Pre-training (CLIP) has manifested remarkable\nimprovements in zero-shot classification and cross-modal vision-language tasks.\nYet, from a geometrical point of view, the CLIP embedding space has been found\nto have a pronounced modality gap. This gap renders the embedding space overly\nsparse and disconnected, with different modalities being densely distributed in\ndistinct subregions of the hypersphere. In this work, we aim at answering three\nmain questions: 1. Does sharing the parameter space between the multi-modal\nencoders reduce the modality gap? 2. Can the gap be mitigated by pushing apart\nthe uni-modal embeddings via intra-modality separation? 3. How do these gap\nreduction approaches affect the downstream performance? We design AlignCLIP, in\norder to answer these questions and through extensive experiments, we show that\nAlignCLIP achieves noticeable enhancements in the cross-modal alignment of the\nembeddings, and thereby, reduces the modality gap, while improving the\nperformance across several zero-shot and fine-tuning downstream evaluations.",
      "tldr_zh": "这篇论文探讨了 CLIP 模型中存在的模态间隙（modality gap）问题，该间隙导致嵌入空间稀疏和模态分布不均，从而影响跨模态视觉语言任务的表现。研究者设计了 AlignCLIP 方法，通过共享多模态编码器参数空间和实施模态内分离（intra-modality separation）来减少这一间隙。实验结果表明，AlignCLIP 显著提升了嵌入空间的跨模态对齐，并在多种零样本（zero-shot）和微调下游任务中提高了性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.17639v3",
      "published_date": "2024-06-25 15:24:02 UTC",
      "updated_date": "2024-09-16 15:32:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:31:31.209863"
    },
    {
      "arxiv_id": "2406.17636v1",
      "title": "Aligning Diffusion Models with Noise-Conditioned Perception",
      "title_zh": "基于噪声条件感知的对齐扩散模型",
      "authors": [
        "Alexander Gambashidze",
        "Anton Kulikov",
        "Yuriy Sosnin",
        "Ilya Makarov"
      ],
      "abstract": "Recent advancements in human preference optimization, initially developed for\nLanguage Models (LMs), have shown promise for text-to-image Diffusion Models,\nenhancing prompt alignment, visual appeal, and user preference. Unlike LMs,\nDiffusion Models typically optimize in pixel or VAE space, which does not align\nwell with human perception, leading to slower and less efficient training\nduring the preference alignment stage. We propose using a perceptual objective\nin the U-Net embedding space of the diffusion model to address these issues.\nOur approach involves fine-tuning Stable Diffusion 1.5 and XL using Direct\nPreference Optimization (DPO), Contrastive Preference Optimization (CPO), and\nsupervised fine-tuning (SFT) within this embedding space. This method\nsignificantly outperforms standard latent-space implementations across various\nmetrics, including quality and computational cost. For SDXL, our approach\nprovides 60.8\\% general preference, 62.2\\% visual appeal, and 52.1\\% prompt\nfollowing against original open-sourced SDXL-DPO on the PartiPrompts dataset,\nwhile significantly reducing compute. Our approach not only improves the\nefficiency and quality of human preference alignment for diffusion models but\nis also easily integrable with other optimization techniques. The training code\nand LoRA weights will be available here:\nhttps://huggingface.co/alexgambashidze/SDXL\\_NCP-DPO\\_v0.1",
      "tldr_zh": "该研究提出了一种基于噪声条件感知（Noise-Conditioned Perception）的优化方法，用于改进文本到图像扩散模型（Diffusion Models）的人类偏好对齐问题。传统优化在像素或 VAE 空间进行，与人类感知不匹配，导致训练效率低下；该方法改用 U-Net embedding 空间的感知目标，并通过 Direct Preference Optimization (DPO)、Contrastive Preference Optimization (CPO) 和 supervised fine-tuning (SFT) 微调 Stable Diffusion 1.5 和 XL 模型。实验结果显示，该方法在 PartiPrompts 数据集上显著优于基线模型，例如对 SDXL 实现 60.8% 一般偏好、62.2% 视觉吸引力和 52.1% 提示遵循，同时大幅降低计算成本。该创新不仅提升了扩散模型的效率和质量，还易于与其他优化技术整合。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.17636v1",
      "published_date": "2024-06-25 15:21:50 UTC",
      "updated_date": "2024-06-25 15:21:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:31:43.299714"
    },
    {
      "arxiv_id": "2406.17630v3",
      "title": "KANQAS: Kolmogorov-Arnold Network for Quantum Architecture Search",
      "title_zh": "翻译失败",
      "authors": [
        "Akash Kundu",
        "Aritra Sarkar",
        "Abhishek Sadhu"
      ],
      "abstract": "Quantum architecture Search (QAS) is a promising direction for optimization\nand automated design of quantum circuits towards quantum advantage. Recent\ntechniques in QAS emphasize Multi-Layer Perceptron (MLP)-based deep Q-networks.\nHowever, their interpretability remains challenging due to the large number of\nlearnable parameters and the complexities involved in selecting appropriate\nactivation functions. In this work, to overcome these challenges, we utilize\nthe Kolmogorov-Arnold Network (KAN) in the QAS algorithm, analyzing their\nefficiency in the task of quantum state preparation and quantum chemistry. In\nquantum state preparation, our results show that in a noiseless scenario, the\nprobability of success is 2 to 5 times higher than MLPs. In noisy environments,\nKAN outperforms MLPs in fidelity when approximating these states, showcasing\nits robustness against noise. In tackling quantum chemistry problems, we\nenhance the recently proposed QAS algorithm by integrating curriculum\nreinforcement learning with a KAN structure. This facilitates a more efficient\ndesign of parameterized quantum circuits by reducing the number of required\n2-qubit gates and circuit depth. Further investigation reveals that KAN\nrequires a significantly smaller number of learnable parameters compared to\nMLPs; however, the average time of executing each episode for KAN is higher.",
      "tldr_zh": "该研究提出KANQAS框架，使用Kolmogorov-Arnold Network (KAN)改进Quantum Architecture Search (QAS)，以解决传统Multi-Layer Perceptron (MLP)模型在量子电路设计中参数过多和可解释性差的问题。实验结果显示，在量子态制备任务中，KAN在无噪声场景下成功概率比MLP高2-5倍，并在有噪声环境中表现出更高的保真度，证明了其鲁棒性。对于量子化学问题，KAN通过整合课程强化学习，减少了参数化量子电路所需的2-qubit gates和电路深度，尽管每个episode的执行时间较长。总之，KAN以更少的参数实现了更高效的设计，有望推动量子优势的实现。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.ET",
        "cs.LG"
      ],
      "primary_category": "quant-ph",
      "comment": "Code available at: https://github.com/Aqasch/KANQAS_code",
      "pdf_url": "http://arxiv.org/pdf/2406.17630v3",
      "published_date": "2024-06-25 15:17:01 UTC",
      "updated_date": "2024-12-11 22:52:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:31:55.757262"
    },
    {
      "arxiv_id": "2406.17626v1",
      "title": "CoSafe: Evaluating Large Language Model Safety in Multi-Turn Dialogue Coreference",
      "title_zh": "翻译失败",
      "authors": [
        "Erxin Yu",
        "Jing Li",
        "Ming Liao",
        "Siqi Wang",
        "Zuchen Gao",
        "Fei Mi",
        "Lanqing Hong"
      ],
      "abstract": "As large language models (LLMs) constantly evolve, ensuring their safety\nremains a critical research problem. Previous red-teaming approaches for LLM\nsafety have primarily focused on single prompt attacks or goal hijacking. To\nthe best of our knowledge, we are the first to study LLM safety in multi-turn\ndialogue coreference. We created a dataset of 1,400 questions across 14\ncategories, each featuring multi-turn coreference safety attacks. We then\nconducted detailed evaluations on five widely used open-source LLMs. The\nresults indicated that under multi-turn coreference safety attacks, the highest\nattack success rate was 56% with the LLaMA2-Chat-7b model, while the lowest was\n13.9% with the Mistral-7B-Instruct model. These findings highlight the safety\nvulnerabilities in LLMs during dialogue coreference interactions.",
      "tldr_zh": "这项研究首次评估了大型语言模型(LLMs)在多轮对话核心ference（coreference）中的安全问题，填补了先前红队测试（red-teaming）主要聚焦单提示攻击的空白。研究者构建了一个包含1400个问题的数据集，涵盖14个类别，每类均涉及多轮核心ference安全攻击，并对五个开源LLMs进行了详细评估。结果显示，LLaMA2-Chat-7b模型的攻击成功率最高达56%，而Mistral-7B-Instruct模型最低为13.9%。这些发现突出了LLMs在对话核心ference交互中的安全漏洞，呼吁进一步加强模型的安全性设计。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Submitted to EMNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.17626v1",
      "published_date": "2024-06-25 15:13:02 UTC",
      "updated_date": "2024-06-25 15:13:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:32:07.855762"
    },
    {
      "arxiv_id": "2406.17624v1",
      "title": "Self-assessment, Exhibition, and Recognition: a Review of Personality in Large Language Models",
      "title_zh": "自我评估、展示和识别：大语言模型中人格的综述",
      "authors": [
        "Zhiyuan Wen",
        "Yu Yang",
        "Jiannong Cao",
        "Haoming Sun",
        "Ruosong Yang",
        "Shuaiqi Liu"
      ],
      "abstract": "As large language models (LLMs) appear to behave increasingly human-like in\ntext-based interactions, more and more researchers become interested in\ninvestigating personality in LLMs. However, the diversity of psychological\npersonality research and the rapid development of LLMs have led to a broad yet\nfragmented landscape of studies in this interdisciplinary field. Extensive\nstudies across different research focuses, different personality psychometrics,\nand different LLMs make it challenging to have a holistic overview and further\npose difficulties in applying findings to real-world applications. In this\npaper, we present a comprehensive review by categorizing current studies into\nthree research problems: self-assessment, exhibition, and recognition, based on\nthe intrinsic characteristics and external manifestations of personality in\nLLMs. For each problem, we provide a thorough analysis and conduct in-depth\ncomparisons of their corresponding solutions. Besides, we summarize research\nfindings and open challenges from current studies and further discuss their\nunderlying causes. We also collect extensive publicly available resources to\nfacilitate interested researchers and developers. Lastly, we discuss the\npotential future research directions and application scenarios. Our paper is\nthe first comprehensive survey of up-to-date literature on personality in LLMs.\nBy presenting a clear taxonomy, in-depth analysis, promising future directions,\nand extensive resource collections, we aim to provide a better understanding\nand facilitate further advancements in this emerging field.",
      "tldr_zh": "这篇论文对大型语言模型（LLMs）中的个性研究进行了全面综述，首次将现有工作分类为三个核心问题：self-assessment（自评估）、exhibition（展示）和 recognition（识别），以解决研究领域的碎片化问题。作者通过深入分析每类问题的解决方案，进行比较，并总结了关键发现、开放挑战及其潜在原因，同时提供了丰富的公共资源以支持进一步研究。该综述不仅澄清了LLMs个性研究的现状，还探讨了未来研究方向和实际应用场景，促进了这一新兴领域的进展。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.17624v1",
      "published_date": "2024-06-25 15:08:44 UTC",
      "updated_date": "2024-06-25 15:08:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:32:19.867738"
    },
    {
      "arxiv_id": "2406.17834v1",
      "title": "Univariate Skeleton Prediction in Multivariate Systems Using Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Giorgio Morales",
        "John W. Sheppard"
      ],
      "abstract": "Symbolic regression (SR) methods attempt to learn mathematical expressions\nthat approximate the behavior of an observed system. However, when dealing with\nmultivariate systems, they often fail to identify the functional form that\nexplains the relationship between each variable and the system's response. To\nbegin to address this, we propose an explainable neural SR method that\ngenerates univariate symbolic skeletons that aim to explain how each variable\ninfluences the system's response. By analyzing multiple sets of data generated\nartificially, where one input variable varies while others are fixed,\nrelationships are modeled separately for each input variable. The response of\nsuch artificial data sets is estimated using a regression neural network (NN).\nFinally, the multiple sets of input-response pairs are processed by a\npre-trained Multi-Set Transformer that solves a problem we termed Multi-Set\nSkeleton Prediction and outputs a univariate symbolic skeleton. Thus, such\nskeletons represent explanations of the function approximated by the regression\nNN. Experimental results demonstrate that this method learns skeleton\nexpressions matching the underlying functions and outperforms two GP-based and\ntwo neural SR methods.",
      "tldr_zh": "本文提出了一种可解释的神经符号回归(SR)方法，用于在多变量系统中预测单变量符号骨架(univariate symbolic skeletons)，以解释每个输入变量对系统响应的影响。方法包括生成多组人工数据（其中一个变量变化，其他固定），使用回归神经网络(NN)估计响应，然后通过预训练的Multi-Set Transformer处理这些输入-响应对，解决Multi-Set Skeleton Prediction问题。实验结果表明，该方法能学习匹配底层函数的表达式，并在性能上优于两个基于GP的和两个神经SR方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Paper accepted at European Conference on Machine Learning and\n  Principles and Practice of Knowledge Discovery in Databases (ECML PKDD) 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.17834v1",
      "published_date": "2024-06-25 15:07:06 UTC",
      "updated_date": "2024-06-25 15:07:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:32:33.125783"
    },
    {
      "arxiv_id": "2406.17615v1",
      "title": "Aligning Programming Language and Natural Language: Exploring Design Choices in Multi-Modal Transformer-Based Embedding for Bug Localization",
      "title_zh": "翻译失败",
      "authors": [
        "Partha Chakraborty",
        "Venkatraman Arumugam",
        "Meiyappan Nagappan"
      ],
      "abstract": "Bug localization refers to the identification of source code files which is\nin a programming language and also responsible for the unexpected behavior of\nsoftware using the bug report, which is a natural language. As bug localization\nis labor-intensive, bug localization models are employed to assist software\ndevelopers. Due to the domain difference between source code files and bug\nreports, modern bug-localization systems, based on deep learning models, rely\nheavily on embedding techniques that project bug reports and source code files\ninto a shared vector space. The creation of an embedding involves several\ndesign choices, but the impact of these choices on the quality of embedding and\nthe performance of bug localization models remains unexplained in current\nresearch.\n  To address this gap, our study evaluated 14 distinct embedding models to gain\ninsights into the effects of various design choices. Subsequently, we developed\nbug localization models utilizing these embedding models to assess the\ninfluence of these choices on the performance of the localization models. Our\nfindings indicate that the pre-training strategies significantly affect the\nquality of the embedding. Moreover, we discovered that the familiarity of the\nembedding models with the data has a notable impact on the bug localization\nmodel's performance. Notably, when the training and testing data are collected\nfrom different projects, the performance of the bug localization models\nexhibits substantial fluctuations.",
      "tldr_zh": "这篇论文探讨了在 bug localization 中，通过多模态 Transformer-based embedding 技术将编程语言和自然语言对齐，以辅助软件开发者识别源代码中的错误。研究者评估了 14 个不同的 embedding models，分析了设计选择的影響，并基于这些模型开发了 bug localization 系统来测试其性能。结果表明，pre-training strategies 显著影响 embedding 质量，模型对数据的熟悉度会直接影响定位模型的准确性，尤其当训练和测试数据来自不同项目时，性能会大幅波动。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG",
        "D.2; I.2"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.17615v1",
      "published_date": "2024-06-25 15:01:39 UTC",
      "updated_date": "2024-06-25 15:01:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:32:44.184813"
    },
    {
      "arxiv_id": "2407.11002v2",
      "title": "MoESD: Mixture of Experts Stable Diffusion to Mitigate Gender Bias",
      "title_zh": "翻译失败",
      "authors": [
        "Guorun Wang",
        "Lucia Specia"
      ],
      "abstract": "Text-to-image models are known to propagate social biases. For example, when\nprompted to generate images of people in certain professions, these models tend\nto systematically generate specific genders or ethnicities. In this paper, we\nshow that this bias is already present in the text encoder of the model and\nintroduce a Mixture-of-Experts approach by identifying text-encoded bias in the\nlatent space and then creating a Bias-Identification Gate mechanism. More\nspecifically, we propose MoESD (Mixture of Experts Stable Diffusion) with BiAs\n(Bias Adapters) to mitigate gender bias in text-to-image models. We also\ndemonstrate that introducing an arbitrary special token to the prompt is\nessential during the mitigation process. With experiments focusing on gender\nbias, we show that our approach successfully mitigates gender bias while\nmaintaining image quality.",
      "tldr_zh": "这篇论文揭示了文本到图像模型（如Stable Diffusion）中存在的性别偏见问题，例如在生成职业图像时倾向特定性别。作者提出MoESD（Mixture of Experts Stable Diffusion）框架，通过Bias-Identification Gate机制和BiAs（Bias Adapters）来识别并缓解文本编码器中的偏见，并强调在提示中引入特殊token是关键步骤。实验结果显示，该方法在减轻性别偏见的同时，成功维持了图像质量。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.11002v2",
      "published_date": "2024-06-25 14:59:31 UTC",
      "updated_date": "2024-10-24 11:28:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:32:55.585809"
    },
    {
      "arxiv_id": "2406.17606v1",
      "title": "Diffusion-based Adversarial Purification for Intrusion Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Mohamed Amine Merzouk",
        "Erwan Beurier",
        "Reda Yaich",
        "Nora Boulahia-Cuppens",
        "Frédéric Cuppens"
      ],
      "abstract": "The escalating sophistication of cyberattacks has encouraged the integration\nof machine learning techniques in intrusion detection systems, but the rise of\nadversarial examples presents a significant challenge. These crafted\nperturbations mislead ML models, enabling attackers to evade detection or\ntrigger false alerts. As a reaction, adversarial purification has emerged as a\ncompelling solution, particularly with diffusion models showing promising\nresults. However, their purification potential remains unexplored in the\ncontext of intrusion detection. This paper demonstrates the effectiveness of\ndiffusion models in purifying adversarial examples in network intrusion\ndetection. Through a comprehensive analysis of the diffusion parameters, we\nidentify optimal configurations maximizing adversarial robustness with minimal\nimpact on normal performance. Importantly, this study reveals insights into the\nrelationship between diffusion noise and diffusion steps, representing a novel\ncontribution to the field. Our experiments are carried out on two datasets and\nagainst 5 adversarial attacks. The implementation code is publicly available.",
      "tldr_zh": "这篇论文探讨了使用diffusion models进行adversarial purification，以提升入侵检测(intrusion detection)系统对对抗样本的鲁棒性。研究通过全面分析diffusion parameters，确定了最佳配置，能够最大化对抗鲁棒性，同时最小化对正常性能的影响。论文揭示了diffusion noise和diffusion steps之间的关系作为新贡献，并在两个数据集上对抗5种攻击的实验中验证了方法的有效性。代码已公开可用。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.17606v1",
      "published_date": "2024-06-25 14:48:28 UTC",
      "updated_date": "2024-06-25 14:48:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:33:08.032287"
    },
    {
      "arxiv_id": "2407.12807v2",
      "title": "Vision Controlled Sensorized Prosthetic Hand",
      "title_zh": "翻译失败",
      "authors": [
        "Md Abdul Baset Sarker",
        "Juan Pablo S. Sola",
        "Aaron Jones",
        "Evan Laing",
        "Ernesto Sola-Thomas",
        "Masudul H. Imtiaz"
      ],
      "abstract": "This paper presents a sensorized vision-enabled prosthetic hand aimed at\nreplicating a natural hand's performance, functionality, appearance, and\ncomfort. The design goal was to create an accessible substitution with a\nuser-friendly interface requiring little to no training. Our mechanical hand\nuses a camera and embedded processors to perform most of these tasks. The\ninterfaced pressure sensor is used to get pressure feedback and ensure a safe\ngrasp of the object; an accelerometer is used to detect gestures and release\nthe object. Unlike current EMG-based designs, the prototyped hand does not\nrequire personalized training. The details of the design, trade-offs, results,\nand informing the next iteration are presented in this paper.",
      "tldr_zh": "这篇论文提出了一种视觉控制的传感器化假肢手（Vision Controlled Sensorized Prosthetic Hand），旨在复制自然手的性能、功能、外观和舒适度，同时提供易于使用的界面，几乎不需要训练。设计采用摄像头和嵌入式处理器来处理主要任务，辅以压力传感器提供抓取反馈确保安全，以及加速度计检测手势以释放物体。相较于传统的 EMG-based designs，该原型无需个性化训练，大大提升了可访问性。论文详细讨论了设计细节、权衡取舍、实验结果以及后续迭代的启示。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.12807v2",
      "published_date": "2024-06-25 14:44:04 UTC",
      "updated_date": "2024-07-19 19:52:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:33:20.137842"
    },
    {
      "arxiv_id": "2406.17583v1",
      "title": "Towards Compositional Interpretability for XAI",
      "title_zh": "翻译失败",
      "authors": [
        "Sean Tull",
        "Robin Lorenz",
        "Stephen Clark",
        "Ilyas Khan",
        "Bob Coecke"
      ],
      "abstract": "Artificial intelligence (AI) is currently based largely on black-box machine\nlearning models which lack interpretability. The field of eXplainable AI (XAI)\nstrives to address this major concern, being critical in high-stakes areas such\nas the finance, legal and health sectors.\n  We present an approach to defining AI models and their interpretability based\non category theory. For this we employ the notion of a compositional model,\nwhich sees a model in terms of formal string diagrams which capture its\nabstract structure together with its concrete implementation. This\ncomprehensive view incorporates deterministic, probabilistic and quantum\nmodels. We compare a wide range of AI models as compositional models, including\nlinear and rule-based models, (recurrent) neural networks, transformers, VAEs,\nand causal and DisCoCirc models.\n  Next we give a definition of interpretation of a model in terms of its\ncompositional structure, demonstrating how to analyse the interpretability of a\nmodel, and using this to clarify common themes in XAI. We find that what makes\nthe standard 'intrinsically interpretable' models so transparent is brought out\nmost clearly diagrammatically. This leads us to the more general notion of\ncompositionally-interpretable (CI) models, which additionally include, for\ninstance, causal, conceptual space, and DisCoCirc models.\n  We next demonstrate the explainability benefits of CI models. Firstly, their\ncompositional structure may allow the computation of other quantities of\ninterest, and may facilitate inference from the model to the modelled\nphenomenon by matching its structure. Secondly, they allow for diagrammatic\nexplanations for their behaviour, based on influence constraints, diagram\nsurgery and rewrite explanations. Finally, we discuss many future directions\nfor the approach, raising the question of how to learn such meaningfully\nstructured models in practice.",
      "tldr_zh": "本论文探讨了 eXplainable AI (XAI) 的可组合解释性问题，针对 AI 模型的黑箱性质提出基于 category theory 的方法。作者定义了 compositional model，使用 formal string diagrams 来捕捉模型的抽象结构和具体实现，包括线性模型、神经网络、Transformer、VAE、因果模型和 DisCoCirc 模型等。论文进一步引入 compositionally-interpretable (CI) 模型的概念，强调其通过图示分析提升模型透明度，并通过 influence constraints、diagram surgery 和 rewrite explanations 提供更有效的解释。最终，研究展示了 CI 模型在计算感兴趣量和促进推理方面的优势，并讨论了未来方向，如在实践中学习这些结构化模型。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.LO",
        "math.CT"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.17583v1",
      "published_date": "2024-06-25 14:27:03 UTC",
      "updated_date": "2024-06-25 14:27:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:33:33.099219"
    },
    {
      "arxiv_id": "2406.17576v1",
      "title": "Leveraging Reinforcement Learning in Red Teaming for Advanced Ransomware Attack Simulations",
      "title_zh": "翻译失败",
      "authors": [
        "Cheng Wang",
        "Christopher Redino",
        "Ryan Clark",
        "Abdul Rahman",
        "Sal Aguinaga",
        "Sathvik Murli",
        "Dhruv Nandakumar",
        "Roland Rao",
        "Lanxiao Huang",
        "Daniel Radke",
        "Edward Bowen"
      ],
      "abstract": "Ransomware presents a significant and increasing threat to individuals and\norganizations by encrypting their systems and not releasing them until a large\nfee has been extracted. To bolster preparedness against potential attacks,\norganizations commonly conduct red teaming exercises, which involve simulated\nattacks to assess existing security measures. This paper proposes a novel\napproach utilizing reinforcement learning (RL) to simulate ransomware attacks.\nBy training an RL agent in a simulated environment mirroring real-world\nnetworks, effective attack strategies can be learned quickly, significantly\nstreamlining traditional, manual penetration testing processes. The attack\npathways revealed by the RL agent can provide valuable insights to the defense\nteam, helping them identify network weak points and develop more resilient\ndefensive measures. Experimental results on a 152-host example network confirm\nthe effectiveness of the proposed approach, demonstrating the RL agent's\ncapability to discover and orchestrate attacks on high-value targets while\nevading honeyfiles (decoy files strategically placed to detect unauthorized\naccess).",
      "tldr_zh": "本论文探讨了利用强化学习（Reinforcement Learning, RL）增强红队演习（Red Teaming），以模拟先进的勒索软件（Ransomware）攻击。研究提出一种新方法，通过在模拟真实网络环境中训练RL代理，快速学习有效的攻击策略，从而简化传统手动渗透测试过程，并帮助防御团队识别网络弱点。实验结果显示，在一个152主机的示例网络中，RL代理成功发现并组织了对高价值目标的攻击，同时规避蜜罐文件（honeyfiles），证明了该方法在提升组织安全准备方面的有效性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.17576v1",
      "published_date": "2024-06-25 14:16:40 UTC",
      "updated_date": "2024-06-25 14:16:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:33:43.370976"
    },
    {
      "arxiv_id": "2406.17563v1",
      "title": "Multi-property Steering of Large Language Models with Dynamic Activation Composition",
      "title_zh": "翻译失败",
      "authors": [
        "Daniel Scalena",
        "Gabriele Sarti",
        "Malvina Nissim"
      ],
      "abstract": "Activation steering methods were shown to be effective in conditioning\nlanguage model generation by additively intervening over models' intermediate\nrepresentations. However, the evaluation of these techniques has so far been\nlimited to single conditioning properties and synthetic settings. In this work,\nwe conduct a comprehensive evaluation of various activation steering\nstrategies, highlighting the property-dependent nature of optimal parameters to\nensure a robust effect throughout generation. To address this issue, we propose\nDynamic Activation Composition, an information-theoretic approach to modulate\nthe steering intensity of one or more properties throughout generation. Our\nexperiments on multi-property steering show that our method successfully\nmaintains high conditioning while minimizing the impact of conditioning on\ngeneration fluency.",
      "tldr_zh": "该研究评估了激活转向（activation steering）方法在调节大型语言模型（Large Language Models）生成时的效果，发现现有方法仅限于单一属性和合成设置，且最佳参数依赖于特定属性。针对这一问题，作者提出Dynamic Activation Composition，一种基于信息理论的方法，能够动态调整一个或多个属性的转向强度，以在生成过程中保持高条件性。实验结果显示，该方法在多属性转向任务中成功维持生成质量，同时最小化了对生成流畅性的负面影响。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.17563v1",
      "published_date": "2024-06-25 14:00:42 UTC",
      "updated_date": "2024-06-25 14:00:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:33:55.115312"
    },
    {
      "arxiv_id": "2406.17828v1",
      "title": "Extreme Learning Machines for Fast Training of Click-Through Rate Prediction Models",
      "title_zh": "翻译失败",
      "authors": [
        "Ergun Biçici"
      ],
      "abstract": "Extreme Learning Machines (ELM) provide a fast alternative to traditional\ngradient-based learning in neural networks, offering rapid training and robust\ngeneralization capabilities. Its theoretical basis shows its universal\napproximation capability. We explore the application of ELMs for the task of\nClick-Through Rate (CTR) prediction, which is largely unexplored by ELMs due to\nthe high dimensionality of the problem. We introduce an ELM-based model\nenhanced with embedding layers to improve the performance on CTR tasks, which\nis a novel addition to the field. Experimental results on benchmark datasets,\nincluding Avazu and Criteo, demonstrate that our proposed ELM with embeddings\nachieves competitive F1 results while significantly reducing training time\ncompared to state-of-the-art models such as Masknet. Our findings show that\nELMs can be useful for CTR prediction, especially when fast training is needed.",
      "tldr_zh": "本文研究了 Extreme Learning Machines (ELM) 在 Click-Through Rate (CTR) 预测任务中的应用，利用 ELM 的快速训练和鲁棒泛化能力来应对高维度问题。作者提出了一种新型 ELM 模型，通过添加 embedding layers 来提升性能，这为该领域带来了创新。实验在 Avazu 和 Criteo 等基准数据集上显示，该模型在 F1 分数上与 Masknet 等 state-of-the-art 模型竞争，同时显著缩短训练时间。结果表明，ELM 特别适合需要快速训练的 CTR 预测场景。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "I.2; I.5.1"
      ],
      "primary_category": "cs.LG",
      "comment": "5 pages, 2 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2406.17828v1",
      "published_date": "2024-06-25 13:50:00 UTC",
      "updated_date": "2024-06-25 13:50:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:34:09.513206"
    },
    {
      "arxiv_id": "2406.17542v3",
      "title": "CDQuant: Greedy Coordinate Descent for Accurate LLM Quantization",
      "title_zh": "翻译失败",
      "authors": [
        "Pranav Ajit Nair",
        "Arun Sai Suggala"
      ],
      "abstract": "Large language models (LLMs) have recently demonstrated remarkable\nperformance across diverse language tasks. But their deployment is often\nconstrained by their substantial computational and storage requirements.\nQuantization has emerged as a key technique for addressing this challenge,\nenabling the compression of large models with minimal impact on performance.\nThe recent GPTQ algorithm, a post-training quantization (PTQ) method, has\nproven highly effective for compressing LLMs, sparking a wave of research that\nleverages GPTQ as a core component. Recognizing the pivotal role of GPTQ in the\nPTQ landscape, we introduce CDQuant, a simple and scalable alternative to GPTQ\nwith improved performance. CDQuant uses greedy coordinate descent to minimize\nthe layer-wise reconstruction loss to achieve high-quality quantized weights.\nOur algorithm is easy to implement and scales efficiently to models with\nhundreds of billions of parameters. We perform extensive evaluation on Gemma,\nand PaLM2 model families, and demonstrate that CDQuant consistently outperforms\nGPTQ in 2-4 bit weight quantization. Moreover, CDQuant improves the performance\nof state-of-the-art PTQ techniques such as QuIP and FrameQuant when used as a\nreplacement for their GPTQ component, resulting in further gains in quality.",
      "tldr_zh": "该论文提出 CDQuant，一种基于贪婪坐标下降（greedy coordinate descent）的后训练量化（PTQ）算法，用于精确量化大型语言模型（LLMs），以缓解其计算和存储需求问题。CDQuant 通过最小化层级重建损失来生成高质量量化权重，比现有 GPTQ 方法更简单、可扩展，并适用于数百亿参数的模型。在 Gemma 和 PaLM2 模型家族的广泛评估中，CDQuant 在 2-4 位权重量化中 consistently 优于 GPTQ，并进一步提升了 QuIP 和 FrameQuant 等技术的性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.17542v3",
      "published_date": "2024-06-25 13:29:14 UTC",
      "updated_date": "2024-10-22 18:51:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:34:22.573251"
    },
    {
      "arxiv_id": "2406.17826v1",
      "title": "European Space Agency Benchmark for Anomaly Detection in Satellite Telemetry",
      "title_zh": "欧洲航天局卫星遥测异常检测基准",
      "authors": [
        "Krzysztof Kotowski",
        "Christoph Haskamp",
        "Jacek Andrzejewski",
        "Bogdan Ruszczak",
        "Jakub Nalepa",
        "Daniel Lakey",
        "Peter Collins",
        "Aybike Kolmas",
        "Mauro Bartesaghi",
        "Jose Martinez-Heras",
        "Gabriele De Canio"
      ],
      "abstract": "Machine learning has vast potential to improve anomaly detection in satellite\ntelemetry which is a crucial task for spacecraft operations. This potential is\ncurrently hampered by a lack of comprehensible benchmarks for multivariate time\nseries anomaly detection, especially for the challenging case of satellite\ntelemetry. The European Space Agency Benchmark for Anomaly Detection in\nSatellite Telemetry (ESA-ADB) aims to address this challenge and establish a\nnew standard in the domain. It is a result of close cooperation between\nspacecraft operations engineers from the European Space Agency (ESA) and\nmachine learning experts. The newly introduced ESA Anomalies Dataset contains\nannotated real-life telemetry from three different ESA missions, out of which\ntwo are included in ESA-ADB. Results of typical anomaly detection algorithms\nassessed in our novel hierarchical evaluation pipeline show that new approaches\nare necessary to address operators' needs. All elements of ESA-ADB are publicly\navailable to ensure its full reproducibility.",
      "tldr_zh": "欧洲航天局（ESA）推出了 ESA-ADB 基准，用于卫星遥测中的异常检测，旨在解决多变量时间序列异常检测缺乏标准的问题，特别是针对航天器操作的挑战。 该基准基于ESA与机器学习专家的合作，引入了ESA Anomalies Dataset，其中包含来自三个真实ESA任务的注释遥测数据，并通过新型层次化评估管道评估典型算法。 结果显示，现有的异常检测方法无法充分满足操作员需求，强调了开发新方法的重要性。 ESA-ADB的所有元素均公开可用，以确保研究的可重复性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "87 pages, 24 figures, 19 tables",
      "pdf_url": "http://arxiv.org/pdf/2406.17826v1",
      "published_date": "2024-06-25 13:23:37 UTC",
      "updated_date": "2024-06-25 13:23:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:34:34.387836"
    },
    {
      "arxiv_id": "2406.17537v1",
      "title": "SincVAE: a New Approach to Improve Anomaly Detection on EEG Data Using SincNet and Variational Autoencoder",
      "title_zh": "翻译失败",
      "authors": [
        "Andrea Pollastro",
        "Francesco Isgrò",
        "Roberto Prevete"
      ],
      "abstract": "Over the past few decades, electroencephalography (EEG) monitoring has become\na pivotal tool for diagnosing neurological disorders, particularly for\ndetecting seizures. Epilepsy, one of the most prevalent neurological diseases\nworldwide, affects approximately the 1 \\% of the population. These patients\nface significant risks, underscoring the need for reliable, continuous seizure\nmonitoring in daily life. Most of the techniques discussed in the literature\nrely on supervised Machine Learning (ML) methods. However, the challenge of\naccurately labeling variations in epileptic EEG waveforms complicates the use\nof these approaches. Additionally, the rarity of ictal events introduces an\nhigh imbalancing within the data, which could lead to poor prediction\nperformance in supervised learning approaches. Instead, a semi-supervised\napproach allows to train the model only on data not containing seizures, thus\navoiding the issues related to the data imbalancing. This work proposes a\nsemi-supervised approach for detecting epileptic seizures from EEG data,\nutilizing a novel Deep Learning-based method called SincVAE. This proposal\nincorporates the learning of an ad-hoc array of bandpass filter as a first\nlayer of a Variational Autoencoder (VAE), potentially eliminating the\npreprocessing stage where informative band frequencies are identified and\nisolated. Results indicate that SincVAE improves seizure detection in EEG data\nand is capable of identifying early seizures during the preictal stage as well\nas monitoring patients throughout the postictal stage.",
      "tldr_zh": "该研究针对 EEG 数据中癫痫发作检测的挑战（如数据标注困难和不平衡问题），提出了一种半监督方法 SincVAE，将 SincNet 和 Variational Autoencoder (VAE) 相结合。\nSincVAE 在 VAE 的第一层学习自定义的带通滤波器阵列，从而省去传统的预处理阶段，提高了模型的效率和针对性。\n实验结果显示，该方法显著提升了癫痫发作的检测性能，能够在 preictal 阶段提前识别发作，并在 postictal 阶段持续监测患者。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.17537v1",
      "published_date": "2024-06-25 13:21:01 UTC",
      "updated_date": "2024-06-25 13:21:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:34:47.365722"
    },
    {
      "arxiv_id": "2406.17535v1",
      "title": "Disce aut Deficere: Evaluating LLMs Proficiency on the INVALSI Italian Benchmark",
      "title_zh": "Disce aut Deficere：评估 LLMs 在 INVALSI 意大利基准测试中的熟练度",
      "authors": [
        "Fabio Mercorio",
        "Mario Mezzanzanica",
        "Daniele Potertì",
        "Antonio Serino",
        "Andrea Seveso"
      ],
      "abstract": "Recent advancements in Large Language Models (LLMs) have significantly\nenhanced their ability to generate and manipulate human language, highlighting\ntheir potential across various applications. Evaluating LLMs in languages other\nthan English is crucial for ensuring their linguistic versatility, cultural\nrelevance, and applicability in diverse global contexts, thus broadening their\nusability and effectiveness. We tackle this challenge by introducing a\nstructured benchmark using the INVALSI tests, a set of well-established\nassessments designed to measure educational competencies across Italy. Our\nstudy makes three primary contributions: Firstly, we adapt the INVALSI\nbenchmark for automated LLM evaluation, which involves rigorous adaptation of\nthe test format to suit automated processing while retaining the essence of the\noriginal tests. Secondly, we provide a detailed assessment of current LLMs,\noffering a crucial reference point for the academic community. Finally, we\nvisually compare the performance of these models against human results.\nAdditionally, researchers are invited to submit their models for ongoing\nevaluation, ensuring the benchmark remains a current and valuable resource.",
      "tldr_zh": "本研究评估了大语言模型（LLMs）在非英语语言（如意大利语）上的表现，强调其在全球语境中的适用性，并引入INVALSI基准——一套意大利教育能力测试——作为结构化评估工具。主要贡献包括：适应INVALSI测试以支持自动化LLM评估，同时保留原测试本质；对当前LLMs进行详细评估，提供学术参考；以及通过视觉比较模型性能与人类结果，揭示其优缺点。该基准还开放给研究者提交模型进行持续更新，以保持其动态性和实用价值。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.17535v1",
      "published_date": "2024-06-25 13:20:08 UTC",
      "updated_date": "2024-06-25 13:20:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:35:01.068808"
    },
    {
      "arxiv_id": "2406.17532v2",
      "title": "Can Large Language Models Understand DL-Lite Ontologies? An Empirical Study",
      "title_zh": "大型语言模型能理解",
      "authors": [
        "Keyu Wang",
        "Guilin Qi",
        "Jiaqi Li",
        "Songlin Zhai"
      ],
      "abstract": "Large language models (LLMs) have shown significant achievements in solving a\nwide range of tasks. Recently, LLMs' capability to store, retrieve and infer\nwith symbolic knowledge has drawn a great deal of attention, showing their\npotential to understand structured information. However, it is not yet known\nwhether LLMs can understand Description Logic (DL) ontologies. In this work, we\nempirically analyze the LLMs' capability of understanding DL-Lite ontologies\ncovering 6 representative tasks from syntactic and semantic aspects. With\nextensive experiments, we demonstrate both the effectiveness and limitations of\nLLMs in understanding DL-Lite ontologies. We find that LLMs can understand\nformal syntax and model-theoretic semantics of concepts and roles. However,\nLLMs struggle with understanding TBox NI transitivity and handling ontologies\nwith large ABoxes. We hope that our experiments and analyses provide more\ninsights into LLMs and inspire to build more faithful knowledge engineering\nsolutions.",
      "tldr_zh": "本研究通过实证分析，探讨大型语言模型 (LLMs) 是否能理解描述逻辑 (DL) 中的 DL-Lite 本体，涵盖了从语法和语义角度的6个代表性任务。实验结果显示，LLMs 能够有效处理概念和角色的正式语法以及模型理论语义，但存在局限性，如难以理解 TBox 中的 NI 传递性和处理大型 ABoxes。总体而言，此工作揭示了 LLMs 在知识工程中的潜力与挑战，并为构建更可靠的知识工程解决方案提供宝贵见解。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.17532v2",
      "published_date": "2024-06-25 13:16:34 UTC",
      "updated_date": "2024-10-10 09:03:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:35:09.660959"
    },
    {
      "arxiv_id": "2406.17531v1",
      "title": "Enhancing LLM-Based Human-Robot Interaction with Nuances for Diversity Awareness",
      "title_zh": "翻译失败",
      "authors": [
        "Lucrezia Grassi",
        "Carmine Tommaso Recchiuto",
        "Antonio Sgorbissa"
      ],
      "abstract": "This paper presents a system for diversity-aware autonomous conversation\nleveraging the capabilities of large language models (LLMs). The system adapts\nto diverse populations and individuals, considering factors like background,\npersonality, age, gender, and culture. The conversation flow is guided by the\nstructure of the system's pre-established knowledge base, while LLMs are tasked\nwith various functions, including generating diversity-aware sentences.\nAchieving diversity-awareness involves providing carefully crafted prompts to\nthe models, incorporating comprehensive information about users, conversation\nhistory, contextual details, and specific guidelines. To assess the system's\nperformance, we conducted both controlled and real-world experiments, measuring\na wide range of performance indicators.",
      "tldr_zh": "这篇论文提出了一种基于LLMs（Large Language Models）的多样性感知自主对话系统，以增强人机交互的包容性。该系统通过适应用户的背景、个性、年龄、性别和文化等因素，并利用精心设计的提示（如用户信息、对话历史和上下文细节）来生成多样化句子，同时以预建立的知识库结构引导对话流程。为评估系统性能，论文开展了受控和真实世界实验，测量了多种性能指标，以验证其有效性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.RO",
      "comment": "8 pages, 6 figures, 7 tables. This paper has been accepted for\n  publication at IEEE ROMAN 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.17531v1",
      "published_date": "2024-06-25 13:15:36 UTC",
      "updated_date": "2024-06-25 13:15:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:35:21.532789"
    },
    {
      "arxiv_id": "2406.17523v3",
      "title": "On the consistency of hyper-parameter selection in value-based deep reinforcement learning",
      "title_zh": "在基于价值的深度强化学习中超参数选择的一致性研究",
      "authors": [
        "Johan Obando-Ceron",
        "João G. M. Araújo",
        "Aaron Courville",
        "Pablo Samuel Castro"
      ],
      "abstract": "Deep reinforcement learning (deep RL) has achieved tremendous success on\nvarious domains through a combination of algorithmic design and careful\nselection of hyper-parameters. Algorithmic improvements are often the result of\niterative enhancements built upon prior approaches, while hyper-parameter\nchoices are typically inherited from previous methods or fine-tuned\nspecifically for the proposed technique. Despite their crucial impact on\nperformance, hyper-parameter choices are frequently overshadowed by algorithmic\nadvancements. This paper conducts an extensive empirical study focusing on the\nreliability of hyper-parameter selection for value-based deep reinforcement\nlearning agents, including the introduction of a new score to quantify the\nconsistency and reliability of various hyper-parameters. Our findings not only\nhelp establish which hyper-parameters are most critical to tune, but also help\nclarify which tunings remain consistent across different training regimes.",
      "tldr_zh": "本论文探讨了基于价值的深度强化学习(value-based deep reinforcement learning)中超参数(hyper-parameter)选择的可靠性和一致性问题，尽管这些选择对算法性能至关重要，但往往被算法改进所忽略。研究通过广泛的实证分析，引入了一个新的分数来量化各种超参数的一致性和可靠性。结果表明，该方法有助于识别出哪些超参数最关键需要调整，以及哪些调整在不同训练方案中保持一致。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.17523v3",
      "published_date": "2024-06-25 13:06:09 UTC",
      "updated_date": "2024-11-29 18:51:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:35:33.882193"
    },
    {
      "arxiv_id": "2406.17518v2",
      "title": "Enhancing Explainability of Knowledge Learning Paths: Causal Knowledge Networks",
      "title_zh": "增强知识学习路径的可解释性：因果知识网络",
      "authors": [
        "Yuang Wei",
        "Yizhou Zhou",
        "Yuan-Hao Jiang",
        "Bo Jiang"
      ],
      "abstract": "A reliable knowledge structure is a prerequisite for building effective\nadaptive learning systems and intelligent tutoring systems. Pursuing an\nexplainable and trustworthy knowledge structure, we propose a method for\nconstructing causal knowledge networks. This approach leverages Bayesian\nnetworks as a foundation and incorporates causal relationship analysis to\nderive a causal network. Additionally, we introduce a dependable\nknowledge-learning path recommendation technique built upon this framework,\nimproving teaching and learning quality while maintaining transparency in the\ndecision-making process.",
      "tldr_zh": "本研究旨在提升知识学习路径的可解释性和可信度，提出了一种构建因果知识网络(Causal Knowledge Networks)的方法。 该方法以Bayesian networks为基础，并整合因果关系分析，构建可靠的知识结构，用于支持适应性学习系统和智能辅导系统。 此外，论文引入了一种基于此框架的知识学习路径推荐技术，能够提高教学和学习质量，同时确保决策过程的透明性。",
      "categories": [
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages, 3 figures, Educational Data Mining 2024, Human-Centric\n  eXplainable AI in Education",
      "pdf_url": "http://arxiv.org/pdf/2406.17518v2",
      "published_date": "2024-06-25 12:59:20 UTC",
      "updated_date": "2024-06-26 01:25:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:35:45.690929"
    },
    {
      "arxiv_id": "2406.17517v1",
      "title": "Preserving Node Distinctness in Graph Autoencoders via Similarity Distillation",
      "title_zh": "翻译失败",
      "authors": [
        "Ge Chen",
        "Yulan Hu",
        "Sheng Ouyang",
        "Yong Liu",
        "Cuicui Luo"
      ],
      "abstract": "Graph autoencoders (GAEs), as a kind of generative self-supervised learning\napproach, have shown great potential in recent years. GAEs typically rely on\ndistance-based criteria, such as mean-square-error (MSE), to reconstruct the\ninput graph. However, relying solely on a single reconstruction criterion may\nlead to a loss of distinctiveness in the reconstructed graph, causing nodes to\ncollapse into similar representations and resulting in sub-optimal performance.\nTo address this issue, we have developed a simple yet effective strategy to\npreserve the necessary distinctness in the reconstructed graph. Inspired by the\nknowledge distillation technique, we found that the dual encoder-decoder\narchitecture of GAEs can be viewed as a teacher-student relationship.\nTherefore, we propose transferring the knowledge of distinctness from the raw\ngraph to the reconstructed graph, achieved through a simple KL constraint.\nSpecifically, we compute pairwise node similarity scores in the raw graph and\nreconstructed graph. During the training process, the KL constraint is\noptimized alongside the reconstruction criterion. We conducted extensive\nexperiments across three types of graph tasks, demonstrating the effectiveness\nand generality of our strategy. This indicates that the proposed approach can\nbe employed as a plug-and-play method to avoid vague reconstructions and\nenhance overall performance.",
      "tldr_zh": "该论文针对Graph Autoencoders (GAEs) 在重建图时可能导致节点失去独特性的问题，提出了一种基于相似性蒸馏的简单策略，以保留重建图中节点的独特性。作者将GAEs的双编码器-解码器架构视为教师-学生关系，通过KL constraint将原始图的节点相似性知识转移到重建图中，具体方法包括计算节点对相似性分数并在训练过程中优化该约束。实验结果显示，该策略在三种图任务上均提升了整体性能，并可作为即插即用的方法，避免模糊重建并改善GAEs的表现。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.17517v1",
      "published_date": "2024-06-25 12:54:35 UTC",
      "updated_date": "2024-06-25 12:54:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:35:58.195888"
    },
    {
      "arxiv_id": "2406.17513v2",
      "title": "Benchmarking Mental State Representations in Language Models",
      "title_zh": "语言模型中心理状态表示的基准测试",
      "authors": [
        "Matteo Bortoletto",
        "Constantin Ruhdorfer",
        "Lei Shi",
        "Andreas Bulling"
      ],
      "abstract": "While numerous works have assessed the generative performance of language\nmodels (LMs) on tasks requiring Theory of Mind reasoning, research into the\nmodels' internal representation of mental states remains limited. Recent work\nhas used probing to demonstrate that LMs can represent beliefs of themselves\nand others. However, these claims are accompanied by limited evaluation, making\nit difficult to assess how mental state representations are affected by model\ndesign and training choices. We report an extensive benchmark with various LM\ntypes with different model sizes, fine-tuning approaches, and prompt designs to\nstudy the robustness of mental state representations and memorisation issues\nwithin the probes. Our results show that the quality of models' internal\nrepresentations of the beliefs of others increases with model size and, more\ncrucially, with fine-tuning. We are the first to study how prompt variations\nimpact probing performance on theory of mind tasks. We demonstrate that models'\nrepresentations are sensitive to prompt variations, even when such variations\nshould be beneficial. Finally, we complement previous activation editing\nexperiments on Theory of Mind tasks and show that it is possible to improve\nmodels' reasoning performance by steering their activations without the need to\ntrain any probe.",
      "tldr_zh": "本文通过基准测试评估了语言模型 (LMs) 对心理状态的内部表示，聚焦于理论思维 (Theory of Mind) 任务，涵盖不同模型大小、微调方法和提示设计，以检验表示的鲁棒性和记忆问题。研究发现，模型对他人信念的表示质量随模型规模和微调而显著提升，但对提示变化高度敏感，即使这些变化本应有益。最终，实验证明可以通过激活编辑直接改善模型的推理性能，而无需训练任何 probing 探针。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "ICML 2024 Workshop on Mechanistic Interpretability",
      "pdf_url": "http://arxiv.org/pdf/2406.17513v2",
      "published_date": "2024-06-25 12:51:06 UTC",
      "updated_date": "2024-07-01 06:48:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:36:10.536958"
    },
    {
      "arxiv_id": "2407.09531v1",
      "title": "UAV Networks Surveillance Implementing an Effective Load-Aware Multipath Routing Protocol (ELAMRP)",
      "title_zh": "翻译失败",
      "authors": [
        "Raja Vavekanand",
        "Kira Sam",
        "Vijay Singh"
      ],
      "abstract": "In this work uses innovative multi-channel load-sensing techniques to deploy\nunmanned aerial vehicles (UAVs) for surveillance. The research aims to improve\nthe quality of data transmission methods and improve the efficiency and\nreliability of surveillance systems by exploiting the mobility and adaptability\nof UAVs does the proposed protocol intelligently distribute network traffic\nacross multiple channels, considering the load of each channel, While\naddressing challenges such as load balancing, this study investigates the\neffectiveness of the protocol by simulations or practical tests on The expected\nresults have improved UAV-based surveillance systems, more flexible and\nefficient networks for applications such as security, emergency response and\nthe environment alignment of monitoring -Offering infrastructures, which\ncontribute to efficient and reliable monitoring solutions.",
      "tldr_zh": "本研究提出了一种有效的负载感知多路径路由协议（ELAMRP），用于无人机（UAVs）网络监控系统，以提升数据传输质量和系统效率。该协议通过多通道负载感知技术智能分配网络流量，实现负载平衡，并解决UAVs的移动性和适应性挑战。研究通过模拟或实际测试验证了协议的有效性，预期结果包括更灵活高效的监控网络，适用于安全、紧急响应和环境监测等领域。",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "06 pages, 07 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.09531v1",
      "published_date": "2024-06-25 12:12:54 UTC",
      "updated_date": "2024-06-25 12:12:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:36:22.249255"
    },
    {
      "arxiv_id": "2406.17474v1",
      "title": "Transformer-based Named Entity Recognition with Combined Data Representation",
      "title_zh": "翻译失败",
      "authors": [
        "Michał Marcińczuk"
      ],
      "abstract": "This study examines transformer-based models and their effectiveness in named\nentity recognition tasks. The study investigates data representation\nstrategies, including single, merged, and context, which respectively use one\nsentence, multiple sentences, and sentences joined with attention to context\nper vector. Analysis shows that training models with a single strategy may lead\nto poor performance on different data representations. To address this\nlimitation, the study proposes a combined training procedure that utilizes all\nthree strategies to improve model stability and adaptability. The results of\nthis approach are presented and discussed for four languages (English, Polish,\nCzech, and German) across various datasets, demonstrating the effectiveness of\nthe combined strategy.",
      "tldr_zh": "这篇论文探讨了基于 Transformer 的模型在命名实体识别（Named Entity Recognition, NER）任务中的有效性，并调查了三种数据表示策略：single（单个句子）、merged（多个句子）和context（结合上下文的句子）。研究发现，使用单一策略训练的模型在不同数据表示上表现不佳，因此提出了一种结合训练程序，将所有三种策略整合，以提高模型的稳定性和适应性。在英语、波兰语、捷克语和德语的多个数据集上进行的实验结果证明了这一方法的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "14 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.17474v1",
      "published_date": "2024-06-25 11:41:16 UTC",
      "updated_date": "2024-06-25 11:41:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:36:34.652464"
    },
    {
      "arxiv_id": "2406.17473v1",
      "title": "TSynD: Targeted Synthetic Data Generation for Enhanced Medical Image Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Joshua Niemeijer",
        "Jan Ehrhardt",
        "Hristina Uzunova",
        "Heinz Handels"
      ],
      "abstract": "The usage of medical image data for the training of large-scale machine\nlearning approaches is particularly challenging due to its scarce availability\nand the costly generation of data annotations, typically requiring the\nengagement of medical professionals. The rapid development of generative models\nallows towards tackling this problem by leveraging large amounts of realistic\nsynthetically generated data for the training process. However, randomly\nchoosing synthetic samples, might not be an optimal strategy.\n  In this work, we investigate the targeted generation of synthetic training\ndata, in order to improve the accuracy and robustness of image classification.\nTherefore, our approach aims to guide the generative model to synthesize data\nwith high epistemic uncertainty, since large measures of epistemic uncertainty\nindicate underrepresented data points in the training set. During the image\ngeneration we feed images reconstructed by an auto encoder into the classifier\nand compute the mutual information over the class-probability distribution as a\nmeasure for uncertainty.We alter the feature space of the autoencoder through\nan optimization process with the objective of maximizing the classifier\nuncertainty on the decoded image. By training on such data we improve the\nperformance and robustness against test time data augmentations and adversarial\nattacks on several classifications tasks.",
      "tldr_zh": "本论文提出TSynD框架，通过针对性生成合成数据来提升医疗图像分类的准确性和鲁棒性，以解决医疗图像数据稀缺和标注成本高的挑战。方法涉及引导生成模型合成高epistemic uncertainty的数据，这些数据代表训练集中的 underrepresented 点；具体过程包括使用autoencoder重建图像、输入分类器计算class-probability distribution的mutual information作为不确定性度量，并通过优化autoencoder的feature space来最大化不确定性。实验结果显示，在多个分类任务上，使用这些合成数据训练的模型显著提高了性能，并增强了对测试时数据增强和对抗攻击的抵抗力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.17473v1",
      "published_date": "2024-06-25 11:38:46 UTC",
      "updated_date": "2024-06-25 11:38:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:36:46.683307"
    },
    {
      "arxiv_id": "2406.17470v1",
      "title": "Dynamic Scheduling for Vehicle-to-Vehicle Communications Enhanced Federated Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Jintao Yan",
        "Tan Chen",
        "Yuxuan Sun",
        "Zhaojun Nan",
        "Sheng Zhou",
        "Zhisheng Niu"
      ],
      "abstract": "Leveraging the computing and sensing capabilities of vehicles, vehicular\nfederated learning (VFL) has been applied to edge training for connected\nvehicles. The dynamic and interconnected nature of vehicular networks presents\nunique opportunities to harness direct vehicle-to-vehicle (V2V) communications,\nenhancing VFL training efficiency. In this paper, we formulate a stochastic\noptimization problem to optimize the VFL training performance, considering the\nenergy constraints and mobility of vehicles, and propose a V2V-enhanced dynamic\nscheduling (VEDS) algorithm to solve it. The model aggregation requirements of\nVFL and the limited transmission time due to mobility result in a stepwise\nobjective function, which presents challenges in solving the problem. We thus\npropose a derivative-based drift-plus-penalty method to convert the long-term\nstochastic optimization problem to an online mixed integer nonlinear\nprogramming (MINLP) problem, and provide a theoretical analysis to bound the\nperformance gap between the online solution and the offline optimal solution.\nFurther analysis of the scheduling priority reduces the original problem into a\nset of convex optimization problems, which are efficiently solved using the\ninterior-point method. Experimental results demonstrate that compared with the\nstate-of-the-art benchmarks, the proposed algorithm enhances the image\nclassification accuracy on the CIFAR-10 dataset by 3.18% and reduces the\naverage displacement errors on the Argoverse trajectory prediction dataset by\n10.21%.",
      "tldr_zh": "该论文提出了一种基于车辆间直接通信 (V2V) 的动态调度算法 VEDS，以优化车辆联邦学习 (VFL) 的训练性能，考虑车辆的能量约束和移动性。算法通过制定随机优化问题，并采用 derivative-based drift-plus-penalty 方法，将长期随机优化转换为在线混合整数非线性规划 (MINLP) 问题，并通过凸优化求解来提高效率。实验结果显示，与现有基准相比，VEDS 在 CIFAR-10 数据集上提升了 3.18% 的图像分类准确率，并在 Argoverse 轨迹预测数据集上降低了 10.21% 的平均位移错误。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC",
        "cs.IT",
        "math.IT"
      ],
      "primary_category": "cs.LG",
      "comment": "Submitted to IEEE for possible publication",
      "pdf_url": "http://arxiv.org/pdf/2406.17470v1",
      "published_date": "2024-06-25 11:15:53 UTC",
      "updated_date": "2024-06-25 11:15:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:37:10.779220"
    },
    {
      "arxiv_id": "2406.17465v2",
      "title": "Enhancing Tool Retrieval with Iterative Feedback from Large Language Models",
      "title_zh": "利用大型语言模型的迭代反馈增强工具检索",
      "authors": [
        "Qiancheng Xu",
        "Yongqi Li",
        "Heming Xia",
        "Wenjie Li"
      ],
      "abstract": "Tool learning aims to enhance and expand large language models' (LLMs)\ncapabilities with external tools, which has gained significant attention\nrecently. Current methods have shown that LLMs can effectively handle a certain\namount of tools through in-context learning or fine-tuning. However, in\nreal-world scenarios, the number of tools is typically extensive and\nirregularly updated, emphasizing the necessity for a dedicated tool retrieval\ncomponent. Tool retrieval is nontrivial due to the following challenges: 1)\ncomplex user instructions and tool descriptions; 2) misalignment between tool\nretrieval and tool usage models. To address the above issues, we propose to\nenhance tool retrieval with iterative feedback from the large language model.\nSpecifically, we prompt the tool usage model, i.e., the LLM, to provide\nfeedback for the tool retriever model in multi-round, which could progressively\nimprove the tool retriever's understanding of instructions and tools and reduce\nthe gap between the two standalone components. We build a unified and\ncomprehensive benchmark to evaluate tool retrieval models. The extensive\nexperiments indicate that our proposed approach achieves advanced performance\nin both in-domain evaluation and out-of-domain evaluation.",
      "tldr_zh": "该研究针对工具学习中的挑战（如复杂用户指令、工具描述及工具检索与使用模型的不匹配），提出了一种利用大型语言模型 (LLMs) 的迭代反馈机制来提升工具检索性能。具体方法通过多轮提示，让 LLMs 为工具检索模型提供反馈，从而逐步改善其对指令和工具的理解，并缩小两个组件之间的差距。研究者构建了一个统一的综合基准，并通过广泛实验验证，该方法在领域内和领域外评估中均实现了显著性能提升。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.17465v2",
      "published_date": "2024-06-25 11:12:01 UTC",
      "updated_date": "2024-09-29 15:26:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:37:11.154898"
    },
    {
      "arxiv_id": "2406.17462v2",
      "title": "EvolvED: Evolutionary Embeddings to Understand the Generation Process of Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Vidya Prasad",
        "Hans van Gorp",
        "Christina Humer",
        "Ruud J. G. van Sloun",
        "Anna Vilanova",
        "Nicola Pezzotti"
      ],
      "abstract": "Diffusion models, widely used in image generation, rely on iterative\nrefinement to generate images from noise. Understanding this data evolution is\nimportant for model development and interpretability, yet challenging due to\nits high-dimensional, iterative nature. Prior works often focus on static or\ninstance-level analyses, missing the iterative and holistic aspects of the\ngenerative path. While dimensionality reduction can visualize image evolution\nfor few instances, it does preserve the iterative structure. To address these\ngaps, we introduce EvolvED, a method that presents a holistic view of the\niterative generative process in diffusion models. EvolvED goes beyond instance\nexploration by leveraging predefined research questions to streamline\ngenerative space exploration. Tailored prompts aligned with these questions are\nused to extract intermediate images, preserving iterative context. Targeted\nfeature extractors trace the evolution of key image attribute evolution,\naddressing the complexity of high-dimensional outputs. Central to EvolvED is a\nnovel evolutionary embedding algorithm that encodes iterative steps while\nmaintaining semantic relations. It enhances the visualization of data evolution\nby clustering semantically similar elements within each iteration with t-SNE,\ngrouping elements by iteration, and aligning an instance's elements across\niterations. We present rectilinear and radial layouts to represent iterations\nand support exploration. We apply EvolvED to diffusion models like GLIDE and\nStable Diffusion, demonstrating its ability to provide valuable insights into\nthe generative process.",
      "tldr_zh": "扩散模型在图像生成中依赖迭代精炼，但现有方法往往忽略其整体迭代过程，导致理解困难。本文提出 EvolvED 方法，通过预定义研究问题、定制提示提取中间图像，以及针对性特征提取器追踪关键属性演变，来提供扩散模型生成过程的整体视角。核心是新型进化嵌入算法（evolutionary embedding algorithm），结合 t-SNE 聚类和 rectilinear 或 radial 布局，实现语义关系的编码和可视化。在 GLIDE 和 Stable Diffusion 等模型上应用，EvolvED 展示了增强模型可解释性和洞见的能力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.17462v2",
      "published_date": "2024-06-25 11:05:26 UTC",
      "updated_date": "2024-12-11 09:23:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:37:26.367145"
    },
    {
      "arxiv_id": "2407.00875v1",
      "title": "MoE-CT: A Novel Approach For Large Language Models Training With Resistance To Catastrophic Forgetting",
      "title_zh": "MoE-CT：一种新颖的方法，用于大型语言模型训练，以抵抗灾难性遗忘",
      "authors": [
        "Tianhao Li",
        "Shangjie Li",
        "Binbin Xie",
        "Deyi Xiong",
        "Baosong Yang"
      ],
      "abstract": "The advent of large language models (LLMs) has predominantly catered to\nhigh-resource languages, leaving a disparity in performance for low-resource\nlanguages. Conventional Continual Training (CT) approaches to bridge this gap\noften undermine a model's original linguistic proficiency when expanding to\nmultilingual contexts. Addressing this issue, we introduce a novel MoE-CT\narchitecture, a paradigm that innovatively separates the base model's learning\nfrom the multilingual expansion process. Our design freezes the original LLM\nparameters, thus safeguarding its performance in high-resource languages, while\nan appended MoE module, trained on diverse language datasets, augments\nlow-resource language proficiency. Our approach significantly outperforms\nconventional CT methods, as evidenced by our experiments, which show marked\nimprovements in multilingual benchmarks without sacrificing the model's\noriginal language performance. Moreover, our MoE-CT framework demonstrates\nenhanced resistance to forgetting and superior transfer learning capabilities.\nBy preserving the base model's integrity and focusing on strategic parameter\nexpansion, our methodology advances multilingual language modeling and\nrepresents a significant step forward for low-resource language inclusion in\nLLMs, indicating a fruitful direction for future research in language\ntechnologies.",
      "tldr_zh": "这篇论文提出 MoE-CT 架构，一种创新方法，用于大型语言模型（LLMs）的训练，以抵抗灾难性遗忘（Catastrophic Forgetting）。该方法通过冻结原 LLM 参数来保护高资源语言性能，同时添加一个 Mixture of Experts (MoE) 模块，在多样语言数据集上训练，以提升低资源语言能力。实验结果显示，MoE-CT 在多语言基准上显著优于传统 Continual Training (CT) 方法，同时保持了原语言性能，并展示了增强的抗遗忘和转移学习能力。这种框架为低资源语言的包含提供了重要进展，推动了多语言建模的发展。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "13 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.00875v1",
      "published_date": "2024-06-25 11:03:45 UTC",
      "updated_date": "2024-06-25 11:03:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:37:35.769155"
    },
    {
      "arxiv_id": "2406.17456v1",
      "title": "Improving Grammatical Error Correction via Contextual Data Augmentation",
      "title_zh": "通过",
      "authors": [
        "Yixuan Wang",
        "Baoxin Wang",
        "Yijun Liu",
        "Qingfu Zhu",
        "Dayong Wu",
        "Wanxiang Che"
      ],
      "abstract": "Nowadays, data augmentation through synthetic data has been widely used in\nthe field of Grammatical Error Correction (GEC) to alleviate the problem of\ndata scarcity. However, these synthetic data are mainly used in the\npre-training phase rather than the data-limited fine-tuning phase due to\ninconsistent error distribution and noisy labels. In this paper, we propose a\nsynthetic data construction method based on contextual augmentation, which can\nensure an efficient augmentation of the original data with a more consistent\nerror distribution. Specifically, we combine rule-based substitution with\nmodel-based generation, using the generative model to generate a richer context\nfor the extracted error patterns. Besides, we also propose a relabeling-based\ndata cleaning method to mitigate the effects of noisy labels in synthetic data.\nExperiments on CoNLL14 and BEA19-Test show that our proposed augmentation\nmethod consistently and substantially outperforms strong baselines and achieves\nthe state-of-the-art level with only a few synthetic data.",
      "tldr_zh": "本研究针对Grammatical Error Correction (GEC)中的数据稀缺问题，提出一种基于上下文增强的合成数据构建方法，以解决现有合成数据在错误分布不一致和噪声标签方面的不足。方法结合规则-based substitution和模型-based generation，使用生成模型为提取的错误模式创建更丰富的上下文，同时引入relabeling-based数据清洗技术来减少噪声标签的影响。实验结果显示，在CoNLL14和BEA19-Test数据集上，该方法仅使用少量合成数据，便显著优于强基线模型，并达到state-of-the-art水平。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted as Findings of ACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.17456v1",
      "published_date": "2024-06-25 10:49:56 UTC",
      "updated_date": "2024-06-25 10:49:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:37:56.782068"
    },
    {
      "arxiv_id": "2406.17450v1",
      "title": "Pseudo Labelling for Enhanced Masked Autoencoders",
      "title_zh": "翻译失败",
      "authors": [
        "Srinivasa Rao Nandam",
        "Sara Atito",
        "Zhenhua Feng",
        "Josef Kittler",
        "Muhammad Awais"
      ],
      "abstract": "Masked Image Modeling (MIM)-based models, such as SdAE, CAE, GreenMIM, and\nMixAE, have explored different strategies to enhance the performance of Masked\nAutoencoders (MAE) by modifying prediction, loss functions, or incorporating\nadditional architectural components. In this paper, we propose an enhanced\napproach that boosts MAE performance by integrating pseudo labelling for both\nclass and data tokens, alongside replacing the traditional pixel-level\nreconstruction with token-level reconstruction. This strategy uses cluster\nassignments as pseudo labels to promote instance-level discrimination within\nthe network, while token reconstruction requires generation of discrete tokens\nencapturing local context. The targets for pseudo labelling and reconstruction\nneeds to be generated by a teacher network. To disentangle the generation of\ntarget pseudo labels and the reconstruction of the token features, we decouple\nthe teacher into two distinct models, where one serves as a labelling teacher\nand the other as a reconstruction teacher. This separation proves empirically\nsuperior to a single teacher, while having negligible impact on throughput and\nmemory consumption. Incorporating pseudo-labelling as an auxiliary task has\ndemonstrated notable improvements in ImageNet-1K and other downstream tasks,\nincluding classification, semantic segmentation, and detection.",
      "tldr_zh": "本文提出了一种增强 Masked Autoencoders (MAE) 的方法，通过整合 Pseudo Labelling 应用于类和数据标记，并将传统的像素级重建替换为标记级重建，以提升实例级区分和局部上下文捕捉。该方法使用聚类分配作为伪标签，并将教师网络分为独立的标签教师和重建教师，从而更好地分离任务生成过程，同时保持吞吐量和内存消耗影响微小。实验结果显示，这种辅助任务策略在 ImageNet-1K 以及下游任务如分类、语义分割和检测中，显著提高了模型性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.17450v1",
      "published_date": "2024-06-25 10:41:45 UTC",
      "updated_date": "2024-06-25 10:41:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:38:00.018124"
    },
    {
      "arxiv_id": "2407.11000v1",
      "title": "Autonomous Prompt Engineering in Large Language Models",
      "title_zh": "自主提示工程在大语言模型中的应用",
      "authors": [
        "Daan Kepel",
        "Konstantina Valogianni"
      ],
      "abstract": "Prompt engineering is a crucial yet challenging task for optimizing the\nperformance of large language models (LLMs) on customized tasks. This\npioneering research introduces the Automatic Prompt Engineering Toolbox (APET),\nwhich enables GPT-4 to autonomously apply prompt engineering techniques. By\nleveraging sophisticated strategies such as Expert Prompting, Chain of Thought,\nand Tree of Thoughts, APET empowers GPT-4 to dynamically optimize prompts,\nresulting in substantial improvements in tasks like Word Sorting (4.4%\nincrease) and Geometric Shapes (6.8% increase). Despite encountering challenges\nin complex tasks such as Checkmate in One (-14.8%), these findings demonstrate\nthe transformative potential of APET in automating complex prompt optimization\nprocesses without the use of external data. Overall, this research represents a\nsignificant leap in AI development, presenting a robust framework for future\ninnovations in autonomous AI systems and highlighting the ability of GPT-4 to\nbring prompt engineering theory to practice. It establishes a foundation for\nenhancing performance in complex task performance and broadening the practical\napplications of these techniques in real-world scenarios.",
      "tldr_zh": "本研究引入了 Automatic Prompt Engineering Toolbox (APET)，一个工具箱允许 Large Language Models 如 GPT-4 自主优化提示工程，通过 Expert Prompting、Chain of Thought 和 Tree of Thoughts 等策略动态改进提示设计。实验结果显示，APET 在任务如 Word Sorting 上提升了 4.4%、Geometric Shapes 上提升了 6.8%，但在复杂任务如 Checkmate in One 上下降了 14.8%。总体而言，该框架无需外部数据即可自动化提示优化，为 Large Language Models 的实际应用和未来 AI 系统创新奠定了重要基础。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.11000v1",
      "published_date": "2024-06-25 10:14:44 UTC",
      "updated_date": "2024-06-25 10:14:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:38:11.880786"
    },
    {
      "arxiv_id": "2407.10999v1",
      "title": "TALEC: Teach Your LLM to Evaluate in Specific Domain with In-house Criteria by Criteria Division and Zero-shot Plus Few-shot",
      "title_zh": "翻译失败",
      "authors": [
        "Kaiqi Zhang",
        "Shuai Yuan",
        "Honghan Zhao"
      ],
      "abstract": "With the rapid development of large language models (LLM), the evaluation of\nLLM becomes increasingly important. Measuring text generation tasks such as\nsummarization and article creation is very difficult. Especially in specific\napplication domains (e.g., to-business or to-customer service), in-house\nevaluation criteria have to meet not only general standards (correctness,\nhelpfulness and creativity, etc.) but also specific needs of customers and\nbusiness security requirements at the same time, making the evaluation more\ndifficult. So far, the evaluation of LLM in business scenarios has mainly\nrelied on manual, which is expensive and time-consuming. In this paper, we\npropose a model-based evaluation method: TALEC, which allows users to flexibly\nset their own evaluation criteria, and uses in-context learning (ICL) to teach\njudge model these in-house criteria. In addition, we try combining zero-shot\nand few-shot to make the judge model focus on more information. We also propose\na prompt paradigm and an engineering approach to adjust and iterate the shots\n,helping judge model to better understand the complex criteria. We then compare\nfine-tuning with ICL, finding that fine-tuning can be replaced by ICL. TALEC\ndemonstrates a strong capability to accurately reflect human preferences and\nachieves a correlation of over 80% with human judgments, outperforming even the\ninter-human correlation in some tasks. The code is released in\nhttps://github.com/zlkqz/auto_eval",
      "tldr_zh": "本文提出 TALEC 方法，用于教导大型语言模型 (LLM) 在特定领域（如商业服务）评估文本生成任务，通过标准划分和结合 zero-shot 与 few-shot 技术来适应内部评估标准 (in-house criteria)。TALEC 利用 in-context learning (ICL) 构建提示范式和工程方法，帮助判断模型更好地理解复杂标准，并发现 ICL 可以替代 fine-tuning。实验结果显示，TALEC 与人类判断的相关性超过 80%，在某些任务中甚至优于人际相关性，并开源了代码以促进进一步应用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.10999v1",
      "published_date": "2024-06-25 10:02:42 UTC",
      "updated_date": "2024-06-25 10:02:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:38:26.271701"
    },
    {
      "arxiv_id": "2406.17425v1",
      "title": "CuDA2: An approach for Incorporating Traitor Agents into Cooperative Multi-Agent Systems",
      "title_zh": "CuDA2：一种将叛徒代理整合到合作多代理系统中的方法",
      "authors": [
        "Zhen Chen",
        "Yong Liao",
        "Youpeng Zhao",
        "Zipeng Dai",
        "Jian Zhao"
      ],
      "abstract": "Cooperative Multi-Agent Reinforcement Learning (CMARL) strategies are well\nknown to be vulnerable to adversarial perturbations. Previous works on\nadversarial attacks have primarily focused on white-box attacks that directly\nperturb the states or actions of victim agents, often in scenarios with a\nlimited number of attacks. However, gaining complete access to victim agents in\nreal-world environments is exceedingly difficult. To create more realistic\nadversarial attacks, we introduce a novel method that involves injecting\ntraitor agents into the CMARL system. We model this problem as a Traitor Markov\nDecision Process (TMDP), where traitors cannot directly attack the victim\nagents but can influence their formation or positioning through collisions. In\nTMDP, traitors are trained using the same MARL algorithm as the victim agents,\nwith their reward function set as the negative of the victim agents' reward.\nDespite this, the training efficiency for traitors remains low because it is\nchallenging for them to directly associate their actions with the victim\nagents' rewards. To address this issue, we propose the Curiosity-Driven\nAdversarial Attack (CuDA2) framework. CuDA2 enhances the efficiency and\naggressiveness of attacks on the specified victim agents' policies while\nmaintaining the optimal policy invariance of the traitors. Specifically, we\nemploy a pre-trained Random Network Distillation (RND) module, where the extra\nreward generated by the RND module encourages traitors to explore states\nunencountered by the victim agents. Extensive experiments on various scenarios\nfrom SMAC demonstrate that our CuDA2 framework offers comparable or superior\nadversarial attack capabilities compared to other baselines.",
      "tldr_zh": "本文提出 CuDA2 框架，用于在合作多智能体强化学习 (CMARL) 系统注入叛徒智能体 (traitor agents)，以模拟更现实的对抗攻击，而非直接扰动受害者。框架将问题建模为 Traitor Markov Decision Process (TMDP)，并通过预训练的 Random Network Distillation (RND) 模块提供额外奖励，鼓励叛徒探索受害者未遇到的状态，从而提高训练效率和攻击 aggressiveness。实验结果显示，在 SMAC 场景中，CuDA2 与基线方法相比，提供更强的对抗攻击能力，同时保持叛徒的最优策略不变。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "cs.MA"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.17425v1",
      "published_date": "2024-06-25 09:59:31 UTC",
      "updated_date": "2024-06-25 09:59:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:38:49.078783"
    },
    {
      "arxiv_id": "2406.17419v2",
      "title": "Leave No Document Behind: Benchmarking Long-Context LLMs with Extended Multi-Doc QA",
      "title_zh": "翻译失败",
      "authors": [
        "Minzheng Wang",
        "Longze Chen",
        "Cheng Fu",
        "Shengyi Liao",
        "Xinghua Zhang",
        "Bingli Wu",
        "Haiyang Yu",
        "Nan Xu",
        "Lei Zhang",
        "Run Luo",
        "Yunshui Li",
        "Min Yang",
        "Fei Huang",
        "Yongbin Li"
      ],
      "abstract": "Long-context modeling capabilities have garnered widespread attention,\nleading to the emergence of Large Language Models (LLMs) with ultra-context\nwindows. Meanwhile, benchmarks for evaluating long-context LLMs are gradually\ncatching up. However, existing benchmarks employ irrelevant noise texts to\nartificially extend the length of test cases, diverging from the real-world\nscenarios of long-context applications. To bridge this gap, we propose a novel\nlong-context benchmark, Loong, aligning with realistic scenarios through\nextended multi-document question answering (QA). Unlike typical document QA, in\nLoong's test cases, each document is relevant to the final answer, ignoring any\ndocument will lead to the failure of the answer. Furthermore, Loong introduces\nfour types of tasks with a range of context lengths: Spotlight Locating,\nComparison, Clustering, and Chain of Reasoning, to facilitate a more realistic\nand comprehensive evaluation of long-context understanding. Extensive\nexperiments indicate that existing long-context language models still exhibit\nconsiderable potential for enhancement. Retrieval augmented generation (RAG)\nachieves poor performance, demonstrating that Loong can reliably assess the\nmodel's long-context modeling capabilities.",
      "tldr_zh": "本论文提出一个新基准 Loong，用于评估大型语言模型（LLMs）的长上下文建模能力，通过扩展的多文档问答（QA）模拟真实场景，避免了现有基准使用无关噪声文本的问题。\n在 Loong 中，每个文档都与最终答案相关，忽略任何文档会导致回答失败，并引入四种任务类型（Spotlight Locating、Comparison、Clustering 和 Chain of Reasoning），覆盖不同上下文长度以全面测试模型理解。\n实验结果表明，现有的长上下文模型仍有很大提升潜力，而检索增强生成（RAG）表现较差，证明 Loong 能可靠评估模型的长上下文能力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP 2024 Main. We release our code and data publicly at\n  https://github.com/MozerWang/Loong",
      "pdf_url": "http://arxiv.org/pdf/2406.17419v2",
      "published_date": "2024-06-25 09:42:56 UTC",
      "updated_date": "2024-10-03 06:03:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:38:48.388609"
    },
    {
      "arxiv_id": "2406.17418v1",
      "title": "SE-VGAE: Unsupervised Disentangled Representation Learning for Interpretable Architectural Layout Design Graph Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Jielin Chen",
        "Rudi Stouffs"
      ],
      "abstract": "Despite the suitability of graphs for capturing the relational structures\ninherent in architectural layout designs, there is a notable dearth of research\non interpreting architectural design space using graph-based representation\nlearning and exploring architectural design graph generation. Concurrently,\ndisentangled representation learning in graph generation faces challenges such\nas node permutation invariance and representation expressiveness. To address\nthese challenges, we introduce an unsupervised disentangled representation\nlearning framework, Style-based Edge-augmented Variational Graph Auto-Encoder\n(SE-VGAE), aiming to generate architectural layout in the form of attributed\nadjacency multi-graphs while prioritizing representation disentanglement. The\nframework is designed with three alternative pipelines, each integrating a\ntransformer-based edge-augmented encoder, a latent space disentanglement\nmodule, and a style-based decoder. These components collectively facilitate the\ndecomposition of latent factors influencing architectural layout graph\ngeneration, enhancing generation fidelity and diversity. We also provide\ninsights into optimizing the framework by systematically exploring graph\nfeature augmentation schemes and evaluating their effectiveness for\ndisentangling architectural layout representation through extensive\nexperiments. Additionally, we contribute a new benchmark large-scale\narchitectural layout graph dataset extracted from real-world floor plan images\nto facilitate the exploration of graph data-based architectural design\nrepresentation space interpretation. This study pioneered disentangled\nrepresentation learning for the architectural layout graph generation. The code\nand dataset of this study will be open-sourced.",
      "tldr_zh": "本研究引入了 SE-VGAE 框架，这是一种无监督的解缠代表学习方法，旨在解决图生成中节点置换不变性和表示表达性挑战，以生成可解释的建筑布局设计图。框架包括基于变压器的边增强编码器、潜空间解缠模块和风格-based 解码器，这些组件共同分解影响图生成的潜在因素，提升了生成保真度和多样性。通过系统探索图特征增强方案和广泛实验，SE-VGAE 在建筑布局表示解缠方面表现出色，并贡献了一个新的基准大规模建筑布局图数据集，从真实楼层平面图中提取。该研究开创了建筑布局图生成的解缠代表学习领域，并计划开源代码和数据集。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.17418v1",
      "published_date": "2024-06-25 09:40:47 UTC",
      "updated_date": "2024-06-25 09:40:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:39:00.720276"
    },
    {
      "arxiv_id": "2406.17415v3",
      "title": "Layer-Wise Quantization: A Pragmatic and Effective Method for Quantizing LLMs Beyond Integer Bit-Levels",
      "title_zh": "翻译失败",
      "authors": [
        "Razvan-Gabriel Dumitru",
        "Vikas Yadav",
        "Rishabh Maheshwary",
        "Paul-Ioan Clotan",
        "Sathwik Tejaswi Madhusudhan",
        "Mihai Surdeanu"
      ],
      "abstract": "We present a simple meta quantization approach that quantizes different\nlayers of a large language model (LLM) at different bit levels, and is\nindependent of the underlying quantization technique. Specifically, we quantize\nthe most important layers to higher bit precision and less important layers to\nlower bits. We propose two effective strategies to measure the importance of\nlayers within LLMs: the first measures the importance of a layer based on how\ndifferent its output embeddings are from the input embeddings (higher is\nbetter); the second estimates the importance of a layer using the number of\nlayer weights that are much larger than average (smaller is better). We show\nthat quantizing different layers at varying bits according to our importance\nscores results in minimal performance drop with a far more compressed model\nsize. Finally, we present several practical key takeaways from our variable\nlayer-wise quantization experiments: (a) LLM performance under variable\nquantization remains close to the original model until 25-50% of layers are\nmoved in lower quantization using our proposed ordering but only until 5-10% if\nmoved using no specific ordering; (b) Adding layer importance to inherently\ndynamic quantization techniques can further improve their performance, showing\nthat our approach is complementary to other dynamic quantization methods; (c)\nQuantizing LLMs to lower bits performs substantially better than pruning unless\nextreme quantization (2-bit) is used; and (d) Layer-wise quantization to lower\nbits works better in the case of larger LLMs with more layers compared to\nsmaller LLMs with fewer layers. Our code is publicly available at\nhttps://github.com/RazvanDu/LayerwiseQuant/.",
      "tldr_zh": "本研究提出了一种层级量化（Layer-Wise Quantization）方法，用于量化大型语言模型（LLMs），允许不同层以不同位级进行量化，从而在保持模型性能的同时显著压缩大小。研究引入两种层重要性评估策略：第一种基于输出嵌入与输入嵌入的差异（差异越大越重要）；第二种基于层权重中远大于平均值的权重数量（数量越小越重要）。实验结果显示，按照这些重要性分数量化层，能使LLMs在25-50%层降低位级时性能接近原模型，而无特定顺序时仅至5-10%；此外，该方法优于修剪技术，尤其在大规模LLMs上表现更佳，并可与动态量化技术互补。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "I.2.7; I.2.0"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.17415v3",
      "published_date": "2024-06-25 09:37:15 UTC",
      "updated_date": "2024-10-28 08:59:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:39:13.818938"
    },
    {
      "arxiv_id": "2407.01596v1",
      "title": "Maze Discovery using Multiple Robots via Federated Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Kalpana Ranasinghe",
        "H. P. Madushanka",
        "Rafaela Scaciota",
        "Sumudu Samarakoon",
        "Mehdi Bennis"
      ],
      "abstract": "This work presents a use case of federated learning (FL) applied to\ndiscovering a maze with LiDAR sensors-equipped robots. Goal here is to train\nclassification models to accurately identify the shapes of grid areas within\ntwo different square mazes made up with irregular shaped walls. Due to the use\nof different shapes for the walls, a classification model trained in one maze\nthat captures its structure does not generalize for the other. This issue is\nresolved by adopting FL framework between the robots that explore only one maze\nso that the collective knowledge allows them to operate accurately in the\nunseen maze. This illustrates the effectiveness of FL in real-world\napplications in terms of enhancing classification accuracy and robustness in\nmaze discovery tasks.",
      "tldr_zh": "这篇论文探讨了使用联邦学习 (Federated Learning, FL) 的多机器人系统来发现迷宫。机器人配备 LiDAR 传感器，目标是训练分类模型准确识别两个不同方形迷宫中网格区域的形状，但由于墙壁不规则形状导致模型无法泛化。研究通过 FL 框架让仅探索一个迷宫的机器人共享知识，从而在未见迷宫中实现精确操作。结果显示，FL 显著提高了分类准确性和鲁棒性，证明了其在真实世界迷宫发现任务中的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO",
        "eess.IV"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted in ISCC 2024 conference",
      "pdf_url": "http://arxiv.org/pdf/2407.01596v1",
      "published_date": "2024-06-25 09:34:11 UTC",
      "updated_date": "2024-06-25 09:34:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:39:24.389283"
    },
    {
      "arxiv_id": "2406.17822v1",
      "title": "AI for the prediction of early stages of Alzheimer's disease from neuroimaging biomarkers -- A narrative review of a growing field",
      "title_zh": "翻译失败",
      "authors": [
        "Thorsten Rudroff",
        "Oona Rainio",
        "Riku Klén"
      ],
      "abstract": "Objectives: The objectives of this narrative review are to summarize the\ncurrent state of AI applications in neuroimaging for early Alzheimer's disease\n(AD) prediction and to highlight the potential of AI techniques in improving\nearly AD diagnosis, prognosis, and management.\n  Methods: We conducted a narrative review of studies using AI techniques\napplied to neuroimaging data for early AD prediction. We examined\nsingle-modality studies using structural MRI and PET imaging, as well as\nmulti-modality studies integrating multiple neuroimaging techniques and\nbiomarkers. Furthermore, they reviewed longitudinal studies that model AD\nprogression and identify individuals at risk of rapid decline.\n  Results: Single-modality studies using structural MRI and PET imaging have\ndemonstrated high accuracy in classifying AD and predicting progression from\nmild cognitive impairment (MCI) to AD. Multi-modality studies, integrating\nmultiple neuroimaging techniques and biomarkers, have shown improved\nperformance and robustness compared to single-modality approaches. Longitudinal\nstudies have highlighted the value of AI in modeling AD progression and\nidentifying individuals at risk of rapid decline. However, challenges remain in\ndata standardization, model interpretability, generalizability, clinical\nintegration, and ethical considerations.\n  Conclusion: AI techniques applied to neuroimaging data have the potential to\nimprove early AD diagnosis, prognosis, and management. Addressing challenges\nrelated to data standardization, model interpretability, generalizability,\nclinical integration, and ethical considerations is crucial for realizing the\nfull potential of AI in AD research and clinical practice. Collaborative\nefforts among researchers, clinicians, and regulatory agencies are needed to\ndevelop reliable, robust, and ethical AI tools that can benefit AD patients and\nsociety.",
      "tldr_zh": "本综述探讨了 AI 技术在神经影像生物标记中预测阿尔茨海默病（AD）早期阶段的应用，旨在总结当前进展并强调 AI 在改善 AD 诊断、预后和管理方面的潜力。研究审查了单模态方法（如结构 MRI 和 PET 成像），这些方法在分类 AD 和预测从轻度认知障碍（MCI）向 AD 进展时显示出高准确率；多模态方法整合多种影像技术和生物标记，进一步提升了性能和鲁棒性。纵向研究则突出了 AI 在建模 AD 进展和识别高风险个体方面的价值，但仍面临数据标准化、模型可解释性、泛化性、临床整合及伦理考虑等挑战，需要多方合作来开发可靠的 AI 工具。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "15 pages, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2406.17822v1",
      "published_date": "2024-06-25 09:22:53 UTC",
      "updated_date": "2024-06-25 09:22:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:39:37.182213"
    },
    {
      "arxiv_id": "2406.17386v1",
      "title": "Double Momentum Method for Lower-Level Constrained Bilevel Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Wanli Shi",
        "Yi Chang",
        "Bin Gu"
      ],
      "abstract": "Bilevel optimization (BO) has recently gained prominence in many machine\nlearning applications due to its ability to capture the nested structure\ninherent in these problems. Recently, many hypergradient methods have been\nproposed as effective solutions for solving large-scale problems. However,\ncurrent hypergradient methods for the lower-level constrained bilevel\noptimization (LCBO) problems need very restrictive assumptions, namely, where\noptimality conditions satisfy the differentiability and invertibility\nconditions and lack a solid analysis of the convergence rate. What's worse,\nexisting methods require either double-loop updates, which are sometimes less\nefficient. To solve this problem, in this paper, we propose a new hypergradient\nof LCBO leveraging the theory of nonsmooth implicit function theorem instead of\nusing the restrive assumptions. In addition, we propose a \\textit{single-loop\nsingle-timescale} algorithm based on the double-momentum method and adaptive\nstep size method and prove it can return a $(\\delta, \\epsilon)$-stationary\npoint with $\\tilde{\\mathcal{O}}(d_2^2\\epsilon^{-4})$ iterations. Experiments on\ntwo applications demonstrate the effectiveness of our proposed method.",
      "tldr_zh": "本研究针对下层约束双层优化（Lower-Level Constrained Bilevel Optimization, LCBO）问题，指出现有hypergradient方法依赖严格假设（如可微性和可逆性条件）且缺乏收敛率分析，导致效率低下。作者提出一种新hypergradient，利用nonsmooth implicit function theorem避免这些限制，并设计了一个基于double-momentum method和adaptive step size的单循环单时间尺度算法。实验结果显示，该算法能以$\\tilde{\\mathcal{O}}(d_2^2\\epsilon^{-4})$迭代达到$(\\delta, \\epsilon)$-stationary point，并在两个机器学习应用中证明了其有效性。",
      "categories": [
        "math.OC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "math.OC",
      "comment": "27pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.17386v1",
      "published_date": "2024-06-25 09:05:22 UTC",
      "updated_date": "2024-06-25 09:05:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:39:48.221549"
    },
    {
      "arxiv_id": "2407.09530v1",
      "title": "Optimization of Autonomous Driving Image Detection Based on RFAConv and Triplet Attention",
      "title_zh": "翻译失败",
      "authors": [
        "Zhipeng Ling",
        "Qi Xin",
        "Yiyu Lin",
        "Guangze Su",
        "Zuwei Shui"
      ],
      "abstract": "YOLOv8 plays a crucial role in the realm of autonomous driving, owing to its\nhigh-speed target detection, precise identification and positioning, and\nversatile compatibility across multiple platforms. By processing video streams\nor images in real-time, YOLOv8 rapidly and accurately identifies obstacles such\nas vehicles and pedestrians on roadways, offering essential visual data for\nautonomous driving systems. Moreover, YOLOv8 supports various tasks including\ninstance segmentation, image classification, and attitude estimation, thereby\nproviding comprehensive visual perception for autonomous driving, ultimately\nenhancing driving safety and efficiency. Recognizing the significance of object\ndetection in autonomous driving scenarios and the challenges faced by existing\nmethods, this paper proposes a holistic approach to enhance the YOLOv8 model.\nThe study introduces two pivotal modifications: the C2f_RFAConv module and the\nTriplet Attention mechanism. Firstly, the proposed modifications are elaborated\nupon in the methodological section. The C2f_RFAConv module replaces the\noriginal module to enhance feature extraction efficiency, while the Triplet\nAttention mechanism enhances feature focus. Subsequently, the experimental\nprocedure delineates the training and evaluation process, encompassing training\nthe original YOLOv8, integrating modified modules, and assessing performance\nimprovements using metrics and PR curves. The results demonstrate the efficacy\nof the modifications, with the improved YOLOv8 model exhibiting significant\nperformance enhancements, including increased MAP values and improvements in PR\ncurves. Lastly, the analysis section elucidates the results and attributes the\nperformance improvements to the introduced modules. C2f_RFAConv enhances\nfeature extraction efficiency, while Triplet Attention improves feature focus\nfor enhanced target detection.",
      "tldr_zh": "这篇论文针对自动驾驶物体检测的挑战，优化了YOLOv8模型，以提升其在实时识别车辆和行人等方面的性能。研究引入了C2f_RFAConv模块来提高特征提取效率，以及Triplet Attention机制来增强特征焦点，从而实现更精确的目标检测。实验结果显示，改进后的YOLOv8在MAP值和PR curves上显著提升，平均准确率提高了29.32%，为自动驾驶的安全性和效率提供了更可靠的视觉感知支持。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "13 pages",
      "pdf_url": "http://arxiv.org/pdf/2407.09530v1",
      "published_date": "2024-06-25 08:59:33 UTC",
      "updated_date": "2024-06-25 08:59:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:40:00.270200"
    },
    {
      "arxiv_id": "2406.17376v1",
      "title": "Temporal-Channel Modeling in Multi-head Self-Attention for Synthetic Speech Detection",
      "title_zh": "多头自注意力中的时频通道建模用于合成语音检测",
      "authors": [
        "Duc-Tuan Truong",
        "Ruijie Tao",
        "Tuan Nguyen",
        "Hieu-Thi Luong",
        "Kong Aik Lee",
        "Eng Siong Chng"
      ],
      "abstract": "Recent synthetic speech detectors leveraging the Transformer model have\nsuperior performance compared to the convolutional neural network counterparts.\nThis improvement could be due to the powerful modeling ability of the\nmulti-head self-attention (MHSA) in the Transformer model, which learns the\ntemporal relationship of each input token. However, artifacts of synthetic\nspeech can be located in specific regions of both frequency channels and\ntemporal segments, while MHSA neglects this temporal-channel dependency of the\ninput sequence. In this work, we proposed a Temporal-Channel Modeling (TCM)\nmodule to enhance MHSA's capability for capturing temporal-channel\ndependencies. Experimental results on the ASVspoof 2021 show that with only\n0.03M additional parameters, the TCM module can outperform the state-of-the-art\nsystem by 9.25% in EER. Further ablation study reveals that utilizing both\ntemporal and channel information yields the most improvement for detecting\nsynthetic speech.",
      "tldr_zh": "本研究针对Transformer模型中的Multi-head Self-Attention (MHSA) 在合成语音检测中忽略时域-频域依赖的问题，提出了一种Temporal-Channel Modeling (TCM) 模块，以增强MHSA捕获输入序列的时域-频域相关性。该模块仅增加了0.03M参数，便能在ASVspoof 2021数据集上将EER降低9.25%，优于现有最先进系统。消融研究进一步显示，结合时域和频域信息能最大程度提升合成语音检测性能。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted by INTERSPEECH 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.17376v1",
      "published_date": "2024-06-25 08:50:43 UTC",
      "updated_date": "2024-06-25 08:50:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:40:12.007746"
    },
    {
      "arxiv_id": "2407.00088v2",
      "title": "T-MAC: CPU Renaissance via Table Lookup for Low-Bit LLM Deployment on Edge",
      "title_zh": "T-MAC：通过表查找实现 CPU 复兴，用于低位 LLM 在边缘设备的部署",
      "authors": [
        "Jianyu Wei",
        "Shijie Cao",
        "Ting Cao",
        "Lingxiao Ma",
        "Lei Wang",
        "Yanyong Zhang",
        "Mao Yang"
      ],
      "abstract": "The deployment of Large Language Models (LLMs) on edge devices is\nincreasingly important to enhance on-device intelligence. Weight quantization\nis crucial for reducing the memory footprint of LLMs on devices. However,\nlow-bit LLMs necessitate mixed precision matrix multiplication (mpGEMM) of low\nprecision weights and high precision activations during inference. Existing\nsystems, lacking native support for mpGEMM, resort to dequantize weights for\nhigh precision computation. Such an indirect way can lead to a significant\ninference overhead.\n  In this paper, we introduce T-MAC, an innovative lookup table(LUT)-based\nmethod designed for efficient low-bit LLM (i.e., weight-quantized LLM)\ninference on CPUs. T-MAC directly supports mpGEMM without dequantization, while\nsimultaneously eliminating multiplications and reducing additions required.\nSpecifically, T-MAC transforms the traditional data-type-centric multiplication\nto bit-wise table lookup, and enables a unified and scalable mpGEMM solution.\n  Our LUT-based kernels scale linearly to the weight bit-width. Evaluated on\nlow-bit Llama and BitNet models, T-MAC demonstrates up to 4x increase in\nthroughput and 70% reduction in energy consumption compared to llama.cpp. For\nBitNet-b1.58-3B, T-MAC delivers a token generation throughput of 30 tokens/s\nwith a single core and 71 tokens/s with eight cores on M2-Ultra, and 11\ntokens/s on lower-end devices like Raspberry Pi 5, which significantly exceeds\nthe adult average reading speed. T-MAC with LUT-based computing paradigm, paves\nthe way for the practical deployment of low-bit LLMs on resource-constrained\nedge devices without compromising computational efficiency. The system is\nopen-sourced at https://github.com/microsoft/T-MAC .",
      "tldr_zh": "本研究提出T-MAC，一种基于查找表（LUT）的创新方法，用于在CPU上高效部署低位量化的大型语言模型（LLMs），以解决边缘设备上混合精度矩阵乘法（mpGEMM）的计算开销问题。T-MAC通过将传统乘法转化为位-wise表查找，直接支持mpGEMM而无需反量化，从而消除乘法并减少加法操作，实现线性扩展到权重位宽。实验显示，在低位Llama和BitNet模型上，T-MAC相较于llama.cpp提升高达4倍吞吐量并减少70%能量消耗，例如在M2-Ultra上实现单核30 tokens/s和八核71 tokens/s的生成速度，为资源受限的边缘设备上部署低位LLMs提供了高效、可扩展的解决方案。",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "EuroSys 2025",
      "pdf_url": "http://arxiv.org/pdf/2407.00088v2",
      "published_date": "2024-06-25 08:38:38 UTC",
      "updated_date": "2025-03-25 09:27:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:40:25.153368"
    },
    {
      "arxiv_id": "2406.17819v4",
      "title": "Automatically Adaptive Conformal Risk Control",
      "title_zh": "自动自",
      "authors": [
        "Vincent Blot",
        "Anastasios N Angelopoulos",
        "Michael I Jordan",
        "Nicolas J-B Brunel"
      ],
      "abstract": "Science and technology have a growing need for effective mechanisms that\nensure reliable, controlled performance from black-box machine learning\nalgorithms. These performance guarantees should ideally hold conditionally on\nthe input-that is the performance guarantees should hold, at least\napproximately, no matter what the input. However, beyond stylized discrete\ngroupings such as ethnicity and gender, the right notion of conditioning can be\ndifficult to define. For example, in problems such as image segmentation, we\nwant the uncertainty to reflect the intrinsic difficulty of the test sample,\nbut this may be difficult to capture via a conditioning event. Building on the\nrecent work of Gibbs et al. [2023], we propose a methodology for achieving\napproximate conditional control of statistical risks-the expected value of loss\nfunctions-by adapting to the difficulty of test samples. Our framework goes\nbeyond traditional conditional risk control based on user-provided conditioning\nevents to the algorithmic, data-driven determination of appropriate function\nclasses for conditioning. We apply this framework to various regression and\nsegmentation tasks, enabling finer-grained control over model performance and\ndemonstrating that by continuously monitoring and adjusting these parameters,\nwe can achieve superior precision compared to conventional risk-control\nmethods.",
      "tldr_zh": "该论文提出了一种自动适应性保形风险控制（Automatically Adaptive Conformal Risk Control）框架，旨在为黑箱机器学习算法提供条件性的性能保证，通过数据驱动的方式适应测试样本的内在难度，而非依赖用户预定义的条件事件。该方法基于Gibbs et al. [2023]的工作，算法地确定合适的条件函数类，实现统计风险（如损失函数的期望值）的近似条件控制。实验应用于回归和图像分割任务，结果显示，通过持续监控和调整参数，该框架比传统风险控制方法实现了更精细和精确的性能管理。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.17819v4",
      "published_date": "2024-06-25 08:29:32 UTC",
      "updated_date": "2025-03-27 10:19:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:40:36.684215"
    },
    {
      "arxiv_id": "2406.17818v1",
      "title": "Temporal Prototype-Aware Learning for Active Voltage Control on Power Distribution Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Feiyang Xu",
        "Shunyu Liu",
        "Yunpeng Qing",
        "Yihe Zhou",
        "Yuwen Wang",
        "Mingli Song"
      ],
      "abstract": "Active Voltage Control (AVC) on the Power Distribution Networks (PDNs) aims\nto stabilize the voltage levels to ensure efficient and reliable operation of\npower systems. With the increasing integration of distributed energy resources,\nrecent efforts have explored employing multi-agent reinforcement learning\n(MARL) techniques to realize effective AVC. Existing methods mainly focus on\nthe acquisition of short-term AVC strategies, i.e., only learning AVC within\nthe short-term training trajectories of a singular diurnal cycle. However, due\nto the dynamic nature of load demands and renewable energy, the operation\nstates of real-world PDNs may exhibit significant distribution shifts across\nvarying timescales (e.g., daily and seasonal changes). This can render those\nshort-term strategies suboptimal or even obsolete when performing continuous\nAVC over extended periods. In this paper, we propose a novel temporal\nprototype-aware learning method, abbreviated as TPA, to learn time-adaptive AVC\nunder short-term training trajectories. At the heart of TPA are two\ncomplementary components, namely multi-scale dynamic encoder and temporal\nprototype-aware policy, that can be readily incorporated into various MARL\nmethods. The former component integrates a stacked transformer network to learn\nunderlying temporal dependencies at different timescales of the PDNs, while the\nlatter implements a learnable prototype matching mechanism to construct a\ndedicated AVC policy that can dynamically adapt to the evolving operation\nstates. Experimental results on the AVC benchmark with different PDN sizes\ndemonstrate that the proposed TPA surpasses the state-of-the-art counterparts\nnot only in terms of control performance but also by offering model\ntransferability. Our code is available at\nhttps://github.com/Canyizl/TPA-for-AVC.",
      "tldr_zh": "本文提出 Temporal Prototype-Aware Learning (TPA) 方法，用于在 Power Distribution Networks (PDNs) 上实现 Active Voltage Control (AVC)，以应对分布式能源整合带来的长期动态变化，如季节性负载波动。TPA 包括两个关键组件：多尺度动态编码器（利用堆叠 Transformer 网络学习不同时间尺度的 PDN 依赖）和时间原型感知策略（通过可学习原型匹配机制动态适应操作状态）。实验结果表明，TPA 在不同 PDN 大小的基准测试中，超过了现有 Multi-Agent Reinforcement Learning (MARL) 方法，在控制性能和模型可转移性上表现出显著优势。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.17818v1",
      "published_date": "2024-06-25 08:07:00 UTC",
      "updated_date": "2024-06-25 08:07:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:40:48.817598"
    },
    {
      "arxiv_id": "2406.17343v2",
      "title": "Q-DiT: Accurate Post-Training Quantization for Diffusion Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Lei Chen",
        "Yuan Meng",
        "Chen Tang",
        "Xinzhu Ma",
        "Jingyan Jiang",
        "Xin Wang",
        "Zhi Wang",
        "Wenwu Zhu"
      ],
      "abstract": "Recent advancements in diffusion models, particularly the architectural\ntransformation from UNet-based models to Diffusion Transformers (DiTs),\nsignificantly improve the quality and scalability of image and video\ngeneration. However, despite their impressive capabilities, the substantial\ncomputational costs of these large-scale models pose significant challenges for\nreal-world deployment. Post-Training Quantization (PTQ) emerges as a promising\nsolution, enabling model compression and accelerated inference for pretrained\nmodels, without the costly retraining. However, research on DiT quantization\nremains sparse, and existing PTQ frameworks, primarily designed for traditional\ndiffusion models, tend to suffer from biased quantization, leading to notable\nperformance degradation. In this work, we identify that DiTs typically exhibit\nsignificant spatial variance in both weights and activations, along with\ntemporal variance in activations. To address these issues, we propose Q-DiT, a\nnovel approach that seamlessly integrates two key techniques: automatic\nquantization granularity allocation to handle the significant variance of\nweights and activations across input channels, and sample-wise dynamic\nactivation quantization to adaptively capture activation changes across both\ntimesteps and samples. Extensive experiments conducted on ImageNet and VBench\ndemonstrate the effectiveness of the proposed Q-DiT. Specifically, when\nquantizing DiT-XL/2 to W6A8 on ImageNet ($256 \\times 256$), Q-DiT achieves a\nremarkable reduction in FID by 1.09 compared to the baseline. Under the more\nchallenging W4A8 setting, it maintains high fidelity in image and video\ngeneration, establishing a new benchmark for efficient, high-quality\nquantization in DiTs. Code is available at\n\\href{https://github.com/Juanerx/Q-DiT}{https://github.com/Juanerx/Q-DiT}.",
      "tldr_zh": "本研究针对扩散模型中 Diffusion Transformers (DiTs) 的高计算成本问题，提出了一种精确的 Post-Training Quantization (PTQ) 方法，即 Q-DiT，以实现模型压缩和加速推理，而无需重新训练。Q-DiT 通过自动量化粒度分配处理权重和激活的空间方差，以及样本-wise 动态激活量化适应时间方差，从而缓解现有 PTQ 方法的偏差问题。在 ImageNet 和 VBench 上的实验显示，Q-DiT 在量化 DiT-XL/2 到 W6A8 时，使 FID 降低了 1.09，并在更具挑战性的 W4A8 设置下维持图像和视频生成的高保真度，树立了 DiTs 量化的新基准。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.17343v2",
      "published_date": "2024-06-25 07:57:27 UTC",
      "updated_date": "2024-11-19 09:58:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:41:02.105758"
    },
    {
      "arxiv_id": "2406.17342v2",
      "title": "Masked Generative Extractor for Synergistic Representation and 3D Generation of Point Clouds",
      "title_zh": "翻译失败",
      "authors": [
        "Hongliang Zeng",
        "Ping Zhang",
        "Fang Li",
        "Jiahua Wang",
        "Tingyu Ye",
        "Pengteng Guo"
      ],
      "abstract": "Representation and generative learning, as reconstruction-based methods, have\ndemonstrated their potential for mutual reinforcement across various domains.\nIn the field of point cloud processing, although existing studies have adopted\ntraining strategies from generative models to enhance representational\ncapabilities, these methods are limited by their inability to genuinely\ngenerate 3D shapes. To explore the benefits of deeply integrating 3D\nrepresentation learning and generative learning, we propose an innovative\nframework called \\textit{Point-MGE}. Specifically, this framework first\nutilizes a vector quantized variational autoencoder to reconstruct a neural\nfield representation of 3D shapes, thereby learning discrete semantic features\nof point patches. Subsequently, we design a sliding masking ratios to smooth\nthe transition from representation learning to generative learning. Moreover,\nour method demonstrates strong generalization capability in learning\nhigh-capacity models, achieving new state-of-the-art performance across\nmultiple downstream tasks. In shape classification, Point-MGE achieved an\naccuracy of 94.2% (+1.0%) on the ModelNet40 dataset and 92.9% (+5.5%) on the\nScanObjectNN dataset. Experimental results also confirmed that Point-MGE can\ngenerate high-quality 3D shapes in both unconditional and conditional settings.",
      "tldr_zh": "该研究提出Point-MGE框架，旨在深度整合点云的表示学习和生成学习，以克服现有方法无法真正生成3D形状的局限性。具体方法包括使用vector quantized variational autoencoder重建3D形状的神经场表示，学习点云补丁的离散语义特征，并通过sliding masking ratios平滑过渡从表示学习到生成学习。实验结果显示，Point-MGE在下游任务中达到新的最先进性能，例如在ModelNet40数据集上形状分类准确率达94.2%（+1.0%），在ScanObjectNN数据集上达92.9%（+5.5%），并能生成高质量的3D形状，支持无条件和条件设置。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.17342v2",
      "published_date": "2024-06-25 07:57:03 UTC",
      "updated_date": "2024-08-15 09:59:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:41:13.597474"
    },
    {
      "arxiv_id": "2407.02521v1",
      "title": "Performance Comparison of Deep RL Algorithms for Mixed Traffic Cooperative Lane-Changing",
      "title_zh": "翻译失败",
      "authors": [
        "Xue Yao",
        "Shengren Hou",
        "Serge P. Hoogendoorn",
        "Simeon C. Calvert"
      ],
      "abstract": "Lane-changing (LC) is a challenging scenario for connected and automated\nvehicles (CAVs) because of the complex dynamics and high uncertainty of the\ntraffic environment. This challenge can be handled by deep reinforcement\nlearning (DRL) approaches, leveraging their data-driven and model-free nature.\nOur previous work proposed a cooperative lane-changing in mixed traffic (CLCMT)\nmechanism based on TD3 to facilitate an optimal lane-changing strategy. This\nstudy enhances the current CLCMT mechanism by considering both the uncertainty\nof the human-driven vehicles (HVs) and the microscopic interactions between HVs\nand CAVs. The state-of-the-art (SOTA) DRL algorithms including DDPG, TD3, SAC,\nand PPO are utilized to deal with the formulated MDP with continuous actions.\nPerformance comparison among the four DRL algorithms demonstrates that DDPG,\nTD3, and PPO algorithms can deal with uncertainty in traffic environments and\nlearn well-performed LC strategies in terms of safety, efficiency, comfort, and\necology. The PPO algorithm outperforms the other three algorithms, regarding a\nhigher reward, fewer exploration mistakes and crashes, and a more comfortable\nand ecology LC strategy. The improvements promise CLCMT mechanism greater\nadvantages in the LC motion planning of CAVs.",
      "tldr_zh": "本文比较了 DDPG、TD3、SAC 和 PPO 等深度强化学习 (DRL) 算法在混合交通合作车道变换 (CLCMT) 机制中的性能，旨在处理连接和自动驾驶车辆 (CAVs) 面对的人类驾驶车辆 (HVs) 不确定性和微观互动。研究通过制定马尔可夫决策过程 (MDP) 以连续动作形式，增强了 CLCMT 机制。结果表明，DDPG、TD3 和 PPO 算法能有效应对交通不确定性，并在安全、效率、舒适和生态方面学习出优秀的车道变换策略，其中 PPO 算法表现最佳，提供更高的奖励、更少的碰撞和更优的整体性能。该改进为 CAVs 的车道变换规划带来显著优势。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "6 pages, 5 figures, IEEE conference",
      "pdf_url": "http://arxiv.org/pdf/2407.02521v1",
      "published_date": "2024-06-25 07:49:25 UTC",
      "updated_date": "2024-06-25 07:49:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:41:25.623504"
    },
    {
      "arxiv_id": "2406.17334v1",
      "title": "Joint Admission Control and Resource Allocation of Virtual Network Embedding via Hierarchical Deep Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Tianfu Wang",
        "Li Shen",
        "Qilin Fan",
        "Tong Xu",
        "Tongliang Liu",
        "Hui Xiong"
      ],
      "abstract": "As an essential resource management problem in network virtualization,\nvirtual network embedding (VNE) aims to allocate the finite resources of\nphysical network to sequentially arriving virtual network requests (VNRs) with\ndifferent resource demands. Since this is an NP-hard combinatorial optimization\nproblem, many efforts have been made to provide viable solutions. However, most\nexisting approaches have either ignored the admission control of VNRs, which\nhas a potential impact on long-term performances, or not fully exploited the\ntemporal and topological features of the physical network and VNRs. In this\npaper, we propose a deep Hierarchical Reinforcement Learning approach to learn\na joint Admission Control and Resource Allocation policy for VNE, named\nHRL-ACRA. Specifically, the whole VNE process is decomposed into an upper-level\npolicy for deciding whether to admit the arriving VNR or not and a lower-level\npolicy for allocating resources of the physical network to meet the requirement\nof VNR through the HRL approach. Considering the proximal policy optimization\nas the basic training algorithm, we also adopt the average reward method to\naddress the infinite horizon problem of the upper-level agent and design a\ncustomized multi-objective intrinsic reward to alleviate the sparse reward\nissue of the lower-level agent. Moreover, we develop a deep feature-aware graph\nneural network to capture the features of VNR and physical network and exploit\na sequence-to-sequence model to generate embedding actions iteratively.\nFinally, extensive experiments are conducted in various settings, and show that\nHRL-ACRA outperforms state-of-the-art baselines in terms of both the acceptance\nratio and long-term average revenue. Our code is available at\n\\url{https://github.com/GeminiLight/hrl-acra}.",
      "tldr_zh": "本文提出了一种基于分层深度强化学习(Hierarchical Reinforcement Learning, HRL)的框架HRL-ACRA，用于解决虚拟网络嵌入(Virtual Network Embedding, VNE)的联合准入控制和资源分配问题，该方法将VNE过程分解为上层策略(决定是否准入虚拟网络请求, VNRs)和下层策略(资源分配)，并采用近端策略优化(Proximal Policy Optimization, PPO)、平均奖励方法和自定义多目标内在奖励来优化训练。论文还开发了深度特征感知图神经网络(deep feature-aware graph neural network)来捕获网络特征，以及序列到序列模型(sequence-to-sequence model)来生成嵌入动作。实验在各种设置下进行，结果显示HRL-ACRA在VNR接受率和长期平均收入方面优于现有基线方法。",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "Accepted by IEEE Transactions on Services Computing (TSC)",
      "pdf_url": "http://arxiv.org/pdf/2406.17334v1",
      "published_date": "2024-06-25 07:42:30 UTC",
      "updated_date": "2024-06-25 07:42:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:41:38.372841"
    },
    {
      "arxiv_id": "2407.09529v1",
      "title": "Towards LLM-Powered Ambient Sensor Based Multi-Person Human Activity Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Xi Chen",
        "Julien Cumin",
        "Fano Ramparany",
        "Dominique Vaufreydaz"
      ],
      "abstract": "Human Activity Recognition (HAR) is one of the central problems in fields\nsuch as healthcare, elderly care, and security at home. However, traditional\nHAR approaches face challenges including data scarcity, difficulties in model\ngeneralization, and the complexity of recognizing activities in multi-person\nscenarios. This paper proposes a system framework called LAHAR, based on large\nlanguage models. Utilizing prompt engineering techniques, LAHAR addresses HAR\nin multi-person scenarios by enabling subject separation and action-level\ndescriptions of events occurring in the environment. We validated our approach\non the ARAS dataset, and the results demonstrate that LAHAR achieves comparable\naccuracy to the state-of-the-art method at higher resolutions and maintains\nrobustness in multi-person scenarios.",
      "tldr_zh": "人类活动识别 (HAR) 是医疗保健、老年护理和家庭安全等领域的核心问题，但传统方法面临数据稀缺、模型泛化困难以及多人群场景复杂性的挑战。  \n本文提出 LAHAR 系统框架，基于大型语言模型 (LLM) 并利用提示工程技术，实现主体分离和动作级事件描述，以提升多人群 HAR 的性能。  \n在 ARAS 数据集上验证结果显示，LAHAR 在更高分辨率下达到与最先进方法相当的准确性，并在多人群场景中保持稳健性，为 HAR 应用提供了更可靠的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.09529v1",
      "published_date": "2024-06-25 07:41:34 UTC",
      "updated_date": "2024-06-25 07:41:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:41:49.069557"
    },
    {
      "arxiv_id": "2406.17328v3",
      "title": "Dual-Space Knowledge Distillation for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Songming Zhang",
        "Xue Zhang",
        "Zengkui Sun",
        "Yufeng Chen",
        "Jinan Xu"
      ],
      "abstract": "Knowledge distillation (KD) is known as a promising solution to compress\nlarge language models (LLMs) via transferring their knowledge to smaller\nmodels. During this process, white-box KD methods usually minimize the distance\nbetween the output distributions of the two models so that more knowledge can\nbe transferred. However, in the current white-box KD framework, the output\ndistributions are from the respective output spaces of the two models, using\ntheir own prediction heads. We argue that the space discrepancy will lead to\nlow similarity between the teacher model and the student model on both\nrepresentation and distribution levels. Furthermore, this discrepancy also\nhinders the KD process between models with different vocabularies, which is\ncommon for current LLMs. To address these issues, we propose a dual-space\nknowledge distillation (DSKD) framework that unifies the output spaces of the\ntwo models for KD. On the basis of DSKD, we further develop a cross-model\nattention mechanism, which can automatically align the representations of the\ntwo models with different vocabularies. Thus, our framework is not only\ncompatible with various distance functions for KD (e.g., KL divergence) like\nthe current framework, but also supports KD between any two LLMs regardless of\ntheir vocabularies. Experiments on task-agnostic instruction-following\nbenchmarks show that DSKD significantly outperforms the current white-box KD\nframework with various distance functions, and also surpasses existing KD\nmethods for LLMs with different vocabularies.",
      "tldr_zh": "该论文提出 Dual-Space Knowledge Distillation (DSKD) 框架，用于压缩 Large Language Models (LLMs)，通过统一教师模型和学生模型的输出空间，解决当前白盒 KD 方法中存在的表示和分布层面相似度低的问题。DSKD 还引入交叉模型注意力机制，能够自动对齐不同词汇表的模型表示，从而支持任意两个 LLMs 之间的知识转移，并兼容各种距离函数如 KL divergence。实验结果显示，在任务无关的指令遵循基准上，DSKD 显著优于现有白盒 KD 方法和其他跨词汇表 KD 技术。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "The camera-ready version for EMNLP 2024 main conference. 17 pages, 11\n  figures, code available at: https://github.com/songmzhang/DSKD",
      "pdf_url": "http://arxiv.org/pdf/2406.17328v3",
      "published_date": "2024-06-25 07:25:15 UTC",
      "updated_date": "2024-10-01 16:45:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:42:01.665780"
    },
    {
      "arxiv_id": "2406.17326v1",
      "title": "The State-Action-Reward-State-Action Algorithm in Spatial Prisoner's Dilemma Game",
      "title_zh": "翻译失败",
      "authors": [
        "Lanyu Yang",
        "Dongchun Jiang",
        "Fuqiang Guo",
        "Mingjian Fu"
      ],
      "abstract": "Cooperative behavior is prevalent in both human society and nature.\nUnderstanding the emergence and maintenance of cooperation among\nself-interested individuals remains a significant challenge in evolutionary\nbiology and social sciences. Reinforcement learning (RL) provides a suitable\nframework for studying evolutionary game theory as it can adapt to\nenvironmental changes and maximize expected benefits. In this study, we employ\nthe State-Action-Reward-State-Action (SARSA) algorithm as the decision-making\nmechanism for individuals in evolutionary game theory. Initially, we apply\nSARSA to imitation learning, where agents select neighbors to imitate based on\nrewards. This approach allows us to observe behavioral changes in agents\nwithout independent decision-making abilities. Subsequently, SARSA is utilized\nfor primary agents to independently choose cooperation or betrayal with their\nneighbors. We evaluate the impact of SARSA on cooperation rates by analyzing\nvariations in rewards and the distribution of cooperators and defectors within\nthe network.",
      "tldr_zh": "本研究探讨了自利个体在进化博弈理论中的合作行为，使用 State-Action-Reward-State-Action (SARSA) 算法作为决策机制，应用于 Spatial Prisoner's Dilemma Game。研究首先将 SARSA 用于模仿学习，让代理基于邻居的奖励选择模仿行为；随后扩展到代理独立决策，决定是否合作或背叛。结果显示，SARSA 算法通过分析奖励变化和网络中合作者与背叛者的分布，显著影响了合作率的发展和维持。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.17326v1",
      "published_date": "2024-06-25 07:21:35 UTC",
      "updated_date": "2024-06-25 07:21:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:42:11.876803"
    },
    {
      "arxiv_id": "2407.00087v2",
      "title": "ARES: Alternating Reinforcement Learning and Supervised Fine-Tuning for Enhanced Multi-Modal Chain-of-Thought Reasoning Through Diverse AI Feedback",
      "title_zh": "翻译失败",
      "authors": [
        "Ju-Seung Byun",
        "Jiyun Chun",
        "Jihyung Kil",
        "Andrew Perrault"
      ],
      "abstract": "Large Multimodal Models (LMMs) excel at comprehending human instructions and\ndemonstrate remarkable results across a broad spectrum of tasks. Reinforcement\nLearning from Human Feedback (RLHF) and AI Feedback (RLAIF) further refine LLMs\nby aligning them with specific preferences. These methods primarily use\nranking-based feedback for entire generations. With advanced AI models\n(Teacher), such as GPT-4 and Claude 3 Opus, we can request various types of\ndetailed feedback that are expensive for humans to provide. We propose a\ntwo-stage algorithm ARES that Alternates REinforcement Learning (RL) and\nSupervised Fine-Tuning (SFT). First, we request the Teacher to score how much\neach sentence contributes to solving the problem in a Chain-of-Thought (CoT).\nThis sentence-level feedback allows us to consider individual valuable\nsegments, providing more granular rewards for the RL procedure. Second, we ask\nthe Teacher to correct the wrong reasoning after the RL stage. The RL procedure\nrequires massive efforts for hyperparameter tuning and often generates errors\nlike repetitive words and incomplete sentences. With the correction feedback,\nwe stabilize the RL fine-tuned model through SFT. We conduct experiments on\nmulti-model dataset ScienceQA and A-OKVQA to demonstrate the effectiveness of\nour proposal. ARES rationale reasoning achieves around 70% win rate against\nbaseline models judged by GPT-4o. Additionally, we observe that the improved\nrationale reasoning leads to a 2.5% increase in inference answer accuracy on\naverage for the multi-modal datasets.",
      "tldr_zh": "本研究提出 ARES 算法，通过交替 Reinforcement Learning (RL) 和 Supervised Fine-Tuning (SFT) 来提升大型多模态模型 (LMMs) 在 Chain-of-Thought (CoT) 推理中的性能，利用高级 AI 模型（如 GPT-4）提供句级反馈。ARES 的第一阶段对 CoT 句子进行评分，以细粒度奖励优化 RL；第二阶段则通过 AI 纠正推理错误（如重复词和不完整句子），并用 SFT 稳定模型。在 ScienceQA 和 A-OKVQA 数据集的实验中，ARES 推理能力在 GPT-4o 判断下比基线模型胜率约 70%，并平均提升 2.5% 的答案准确率。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to EMNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.00087v2",
      "published_date": "2024-06-25 07:20:11 UTC",
      "updated_date": "2024-10-03 18:06:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:42:25.963093"
    },
    {
      "arxiv_id": "2406.17322v1",
      "title": "ALPBench: A Benchmark for Active Learning Pipelines on Tabular Data",
      "title_zh": "翻译失败",
      "authors": [
        "Valentin Margraf",
        "Marcel Wever",
        "Sandra Gilhuber",
        "Gabriel Marques Tavares",
        "Thomas Seidl",
        "Eyke Hüllermeier"
      ],
      "abstract": "In settings where only a budgeted amount of labeled data can be afforded,\nactive learning seeks to devise query strategies for selecting the most\ninformative data points to be labeled, aiming to enhance learning algorithms'\nefficiency and performance. Numerous such query strategies have been proposed\nand compared in the active learning literature. However, the community still\nlacks standardized benchmarks for comparing the performance of different query\nstrategies. This particularly holds for the combination of query strategies\nwith different learning algorithms into active learning pipelines and examining\nthe impact of the learning algorithm choice. To close this gap, we propose\nALPBench, which facilitates the specification, execution, and performance\nmonitoring of active learning pipelines. It has built-in measures to ensure\nevaluations are done reproducibly, saving exact dataset splits and\nhyperparameter settings of used algorithms. In total, ALPBench consists of 86\nreal-world tabular classification datasets and 5 active learning settings,\nyielding 430 active learning problems. To demonstrate its usefulness and broad\ncompatibility with various learning algorithms and query strategies, we conduct\nan exemplary study evaluating 9 query strategies paired with 8 learning\nalgorithms in 2 different settings. We provide ALPBench here:\nhttps://github.com/ValentinMargraf/ActiveLearningPipelines.",
      "tldr_zh": "这篇论文引入了ALPBench，这是一个用于评估主动学习(active learning)管道在表格数据(tabular data)上的基准工具。ALPBench包含86个真实世界分类数据集和5个主动学习设置，总共430个问题，支持可复现的实验设计，包括数据集分割和超参数设置。研究通过示例评估了9个查询策略(query strategies)与8个学习算法(learning algorithms)的组合，展示了基准的广泛兼容性和实用性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.17322v1",
      "published_date": "2024-06-25 07:14:14 UTC",
      "updated_date": "2024-06-25 07:14:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:42:36.378490"
    },
    {
      "arxiv_id": "2406.17816v1",
      "title": "Towards Hypermedia Environments for Adaptive Coordination in Industrial Automation",
      "title_zh": "翻译失败",
      "authors": [
        "Ganesh Ramanathan",
        "Simon Mayer",
        "Andrei Ciortea"
      ],
      "abstract": "Electromechanical systems manage physical processes through a network of\ninter-connected components. Today, programming the interactions required for\ncoordinating these components is largely a manual process. This process is\ntime-consuming and requires manual adaptation when system features change. To\novercome this issue, we use autonomous software agents that process semantic\ndescriptions of the system to determine coordination requirements and\nconstraints; on this basis, they then interact with one another to control the\nsystem in a decentralized and coordinated manner.Our core insight is that\ncoordination requirements between individual components are, ultimately,\nlargely due to underlying physical interdependencies between the components,\nwhich can be (and, in many cases, already are) semantically modeled in\nautomation projects. Agents then use hypermedia to discover, at run time, the\nplans and protocols required for enacting the coordination. A key novelty of\nour approach is the use of hypermedia-driven interaction: it reduces coupling\nin the system and enables its run-time adaptation as features change.",
      "tldr_zh": "本文针对工业自动化的机电系统协调问题，指出当前手动编程交互过程耗时且不易适应系统变化。研究提出使用自主软件 agents 处理语义描述，以确定协调需求和约束，并通过去中心化互动控制系统。核心见解是协调需求主要源于物理互依赖，这些可通过语义模型表示；agents 利用 hypermedia 在运行时发现计划和协议，实现系统耦合减少及运行时适应。",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.17816v1",
      "published_date": "2024-06-25 06:21:52 UTC",
      "updated_date": "2024-06-25 06:21:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:42:48.545000"
    },
    {
      "arxiv_id": "2406.17297v2",
      "title": "Towards Open-set Camera 3D Object Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Zhuolin He",
        "Xinrun Li",
        "Heng Gao",
        "Jiachen Tang",
        "Shoumeng Qiu",
        "Wenfu Wang",
        "Lvjian Lu",
        "Xuchong Qiu",
        "Xiangyang Xue",
        "Jian Pu"
      ],
      "abstract": "Traditional camera 3D object detectors are typically trained to recognize a\npredefined set of known object classes. In real-world scenarios, these\ndetectors may encounter unknown objects outside the training categories and\nfail to identify them correctly. To address this gap, we present OS-Det3D\n(Open-set Camera 3D Object Detection), a two-stage training framework enhancing\nthe ability of camera 3D detectors to identify both known and unknown objects.\nThe framework involves our proposed 3D Object Discovery Network (ODN3D), which\nis specifically trained using geometric cues such as the location and scale of\n3D boxes to discover general 3D objects. ODN3D is trained in a class-agnostic\nmanner, and the provided 3D object region proposals inherently come with data\nnoise. To boost accuracy in identifying unknown objects, we introduce a Joint\nObjectness Selection (JOS) module. JOS selects the pseudo ground truth for\nunknown objects from the 3D object region proposals of ODN3D by combining the\nODN3D objectness and camera feature attention objectness. Experiments on the\nnuScenes and KITTI datasets demonstrate the effectiveness of our framework in\nenabling camera 3D detectors to successfully identify unknown objects while\nalso improving their performance on known objects.",
      "tldr_zh": "本文提出 OS-Det3D 框架，用于解决传统相机 3D 对象检测器在遇到未知对象时识别失败的问题，该框架通过两阶段训练增强检测器对已知和未知对象的识别能力。核心组件包括 3D Object Discovery Network (ODN3D)，它采用几何线索（如位置和规模）进行类无关训练，以发现一般 3D 对象，并通过 Joint Objectness Selection (JOS) 模块结合 ODN3D objectness 和相机特征注意力来选择未知对象的伪 ground truth，从而提高准确性。在 nuScenes 和 KITTI 数据集上的实验显示，该框架不仅成功识别未知对象，还提升了已知对象的检测性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.17297v2",
      "published_date": "2024-06-25 05:58:34 UTC",
      "updated_date": "2024-06-27 02:19:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:43:03.760906"
    },
    {
      "arxiv_id": "2406.17815v2",
      "title": "SUM: Saliency Unification through Mamba for Visual Attention Modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Alireza Hosseini",
        "Amirhossein Kazerouni",
        "Saeed Akhavan",
        "Michael Brudno",
        "Babak Taati"
      ],
      "abstract": "Visual attention modeling, important for interpreting and prioritizing visual\nstimuli, plays a significant role in applications such as marketing,\nmultimedia, and robotics. Traditional saliency prediction models, especially\nthose based on Convolutional Neural Networks (CNNs) or Transformers, achieve\nnotable success by leveraging large-scale annotated datasets. However, the\ncurrent state-of-the-art (SOTA) models that use Transformers are\ncomputationally expensive. Additionally, separate models are often required for\neach image type, lacking a unified approach. In this paper, we propose Saliency\nUnification through Mamba (SUM), a novel approach that integrates the efficient\nlong-range dependency modeling of Mamba with U-Net to provide a unified model\nfor diverse image types. Using a novel Conditional Visual State Space (C-VSS)\nblock, SUM dynamically adapts to various image types, including natural scenes,\nweb pages, and commercial imagery, ensuring universal applicability across\ndifferent data types. Our comprehensive evaluations across five benchmarks\ndemonstrate that SUM seamlessly adapts to different visual characteristics and\nconsistently outperforms existing models. These results position SUM as a\nversatile and powerful tool for advancing visual attention modeling, offering a\nrobust solution universally applicable across different types of visual\ncontent.",
      "tldr_zh": "本研究提出SUM（Saliency Unification through Mamba），一种新型视觉注意力建模方法，通过整合Mamba的高效长距离依赖建模与U-Net架构，提供一个统一的模型，适用于多种图像类型，如自然场景、网页和商业图像。SUM引入Conditional Visual State Space (C-VSS)块，能够动态适应不同图像特征，从而解决传统基于CNN或Transformer模型的计算开销大和缺乏通用性问题。在五个基准测试中，SUM表现出色， consistently outperforms现有模型，展示了其在视觉刺激解释和优先处理方面的强大适应性。该方法为营销、多媒体和机器人等领域提供了一个通用且高效的工具。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at IEEE/CVF WACV 2025",
      "pdf_url": "http://arxiv.org/pdf/2406.17815v2",
      "published_date": "2024-06-25 05:54:07 UTC",
      "updated_date": "2024-09-09 11:51:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:43:11.954047"
    },
    {
      "arxiv_id": "2406.17289v2",
      "title": "Hyperbolic Knowledge Transfer in Cross-Domain Recommendation System",
      "title_zh": "跨域推荐系统中的双曲知识转移",
      "authors": [
        "Xin Yang",
        "Heng Chang",
        "Zhijian Lai",
        "Jinze Yang",
        "Xingrun Li",
        "Yu Lu",
        "Shuaiqiang Wang",
        "Dawei Yin",
        "Erxue Min"
      ],
      "abstract": "Cross-Domain Recommendation (CDR) seeks to utilize knowledge from different\ndomains to alleviate the problem of data sparsity in the target recommendation\ndomain, and it has been gaining more attention in recent years. Although there\nhave been notable advancements in this area, most current methods represent\nusers and items in Euclidean space, which is not ideal for handling long-tail\ndistributed data in recommendation systems. Additionally, adding data from\nother domains can worsen the long-tail characteristics of the entire dataset,\nmaking it harder to train CDR models effectively. Recent studies have shown\nthat hyperbolic methods are particularly suitable for modeling long-tail\ndistributions, which has led us to explore hyperbolic representations for users\nand items in CDR scenarios. However, due to the distinct characteristics of the\ndifferent domains, applying hyperbolic representation learning to CDR tasks is\nquite challenging. In this paper, we introduce a new framework called\nHyperbolic Contrastive Learning (HCTS), designed to capture the unique features\nof each domain while enabling efficient knowledge transfer between domains. We\nachieve this by embedding users and items from each domain separately and\nmapping them onto distinct hyperbolic manifolds with adjustable curvatures for\nprediction. To improve the representations of users and items in the target\ndomain, we develop a hyperbolic contrastive learning module for knowledge\ntransfer. Extensive experiments on real-world datasets demonstrate that\nhyperbolic manifolds are a promising alternative to Euclidean space for CDR\ntasks.",
      "tldr_zh": "该论文探讨了跨域推荐（Cross-Domain Recommendation, CDR）系统中的知识转移问题，指出现有方法使用欧氏空间表示用户和物品，无法有效处理推荐系统中常见的长尾分布，且添加其他域数据可能加剧这一问题。作者提出了一种新框架Hyperbolic Contrastive Learning (HCTS)，通过将用户和物品从每个域单独嵌入并映射到可调节曲率的超曲流形（hyperbolic manifolds）上，实现高效的知识转移，并引入超曲对比学习模块来提升目标域的表示质量。在真实数据集上的广泛实验表明，HCTS框架显著优于欧氏空间方法，为CDR任务提供了更具前景的超曲表示方案。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.17289v2",
      "published_date": "2024-06-25 05:35:02 UTC",
      "updated_date": "2024-07-04 14:54:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:43:24.814858"
    },
    {
      "arxiv_id": "2406.17287v1",
      "title": "Predicting the Big Five Personality Traits in Chinese Counselling Dialogues Using Large Language Models",
      "title_zh": "使用大语言模型预测中文咨询对话中的大五性格特质",
      "authors": [
        "Yang Yan",
        "Lizhi Ma",
        "Anqi Li",
        "Jingsong Ma",
        "Zhenzhong Lan"
      ],
      "abstract": "Accurate assessment of personality traits is crucial for effective\npsycho-counseling, yet traditional methods like self-report questionnaires are\ntime-consuming and biased. This study exams whether Large Language Models\n(LLMs) can predict the Big Five personality traits directly from counseling\ndialogues and introduces an innovative framework to perform the task. Our\nframework applies role-play and questionnaire-based prompting to condition LLMs\non counseling sessions, simulating client responses to the Big Five Inventory.\nWe evaluated our framework on 853 real-world counseling sessions, finding a\nsignificant correlation between LLM-predicted and actual Big Five traits,\nproving the validity of framework. Moreover, ablation studies highlight the\nimportance of role-play simulations and task simplification via questionnaires\nin enhancing prediction accuracy. Meanwhile, our fine-tuned Llama3-8B model,\nutilizing Direct Preference Optimization with Supervised Fine-Tuning, achieves\na 130.95\\% improvement, surpassing the state-of-the-art Qwen1.5-110B by 36.94\\%\nin personality prediction validity. In conclusion, LLMs can predict personality\nbased on counseling dialogues. Our code and model are publicly available at\n\\url{https://github.com/kuri-leo/BigFive-LLM-Predictor}, providing a valuable\ntool for future research in computational psychometrics.",
      "tldr_zh": "这篇论文探讨了使用Large Language Models (LLMs)从中文咨询对话中预测Big Five Personality Traits，以解决传统自报问卷方法耗时和偏差的问题。研究提出一个创新框架，通过角色扮演和问卷-based prompting模拟客户响应，并对853个真实咨询会话进行评估，证明了LLM预测与实际人格特质的显著相关性。消融研究强调了角色扮演模拟和任务简化的重要性，而微调的Llama3-8B模型通过Direct Preference Optimization和Supervised Fine-Tuning实现了130.95%的性能提升，超越了Qwen1.5-110B 36.94%。该工作提供了公开的代码和模型，推进了计算心理测量领域的应用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.17287v1",
      "published_date": "2024-06-25 05:30:55 UTC",
      "updated_date": "2024-06-25 05:30:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:43:48.055719"
    },
    {
      "arxiv_id": "2406.17285v1",
      "title": "EON-1: A Brain-Inspired Processor for Near-Sensor Extreme Edge Online Feature Extraction",
      "title_zh": "EON-1：一种受脑启发的处理器，用于近传感器极端边缘在线特征提取",
      "authors": [
        "Alexandra Dobrita",
        "Amirreza Yousefzadeh",
        "Simon Thorpe",
        "Kanishkan Vadivel",
        "Paul Detterer",
        "Guangzhi Tang",
        "Gert-Jan van Schaik",
        "Mario Konijnenburg",
        "Anteneh Gebregiorgis",
        "Said Hamdioui",
        "Manolis Sifalakis"
      ],
      "abstract": "For Edge AI applications, deploying online learning and adaptation on\nresource-constrained embedded devices can deal with fast sensor-generated\nstreams of data in changing environments. However, since maintaining\nlow-latency and power-efficient inference is paramount at the Edge, online\nlearning and adaptation on the device should impose minimal additional overhead\nfor inference. With this goal in mind, we explore energy-efficient learning and\nadaptation on-device for streaming-data Edge AI applications using Spiking\nNeural Networks (SNNs), which follow the principles of brain-inspired\ncomputing, such as high-parallelism, neuron co-located memory and compute, and\nevent-driven processing. We propose EON-1, a brain-inspired processor for\nnear-sensor extreme edge online feature extraction, that integrates a fast\nonline learning and adaptation algorithm. We report results of only 1% energy\noverhead for learning, by far the lowest overhead when compared to other SoTA\nsolutions, while attaining comparable inference accuracy. Furthermore, we\ndemonstrate that EON-1 is up for the challenge of low-latency processing of HD\nand UHD streaming video in real-time, with learning enabled.",
      "tldr_zh": "本研究提出 EON-1，一种脑启发处理器，针对边缘 AI 应用中的在线学习和适应问题，旨在处理快速传感器数据流，同时保持低延迟和低功耗。EON-1 利用 Spiking Neural Networks (SNNs) 的高并行性、事件驱动处理和神经元共存内存，集成快速在线学习算法，以最小化推理开销。结果显示，学习仅带来 1% 的能量开销，与其他 SoTA 解决方案相比显著降低，同时实现可比的推理准确性，并支持实时处理高清和超高清视频流。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.ET",
        "cs.LG"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.17285v1",
      "published_date": "2024-06-25 05:23:41 UTC",
      "updated_date": "2024-06-25 05:23:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:43:49.667295"
    },
    {
      "arxiv_id": "2406.17279v1",
      "title": "Learning Decentralized Multi-Biped Control for Payload Transport",
      "title_zh": "翻译失败",
      "authors": [
        "Bikram Pandit",
        "Ashutosh Gupta",
        "Mohitvishnu S. Gadde",
        "Addison Johnson",
        "Aayam Kumar Shrestha",
        "Helei Duan",
        "Jeremy Dao",
        "Alan Fern"
      ],
      "abstract": "Payload transport over flat terrain via multi-wheel robot carriers is\nwell-understood, highly effective, and configurable. In this paper, our goal is\nto provide similar effectiveness and configurability for transport over rough\nterrain that is more suitable for legs rather than wheels. For this purpose, we\nconsider multi-biped robot carriers, where wheels are replaced by multiple\nbipedal robots attached to the carrier. Our main contribution is to design a\ndecentralized controller for such systems that can be effectively applied to\nvarying numbers and configurations of rigidly attached bipedal robots without\nretraining. We present a reinforcement learning approach for training the\ncontroller in simulation that supports transfer to the real world. Our\nexperiments in simulation provide quantitative metrics showing the\neffectiveness of the approach over a wide variety of simulated transport\nscenarios. In addition, we demonstrate the controller in the real-world for\nsystems composed of two and three Cassie robots. To our knowledge, this is the\nfirst example of a scalable multi-biped payload transport system.",
      "tldr_zh": "这篇论文旨在为崎岖地形上的有效负载运输开发多双足机器人（multi-biped robot）载体，以实现类似于轮式机器人的有效性和可配置性。研究者设计了一个去中心化控制器（decentralized controller），通过强化学习（Reinforcement Learning）在模拟环境中训练，使其能适应不同数量和配置的刚性附着双足机器人，而无需重新训练。实验结果显示，该控制器在各种模拟场景中表现出色，并在真实世界中使用两个和三个Cassie机器人验证了其有效性，这是首个可扩展的多双足机器人运输系统。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Submitted to CoRL 2024, Project website: decmbc.github.io",
      "pdf_url": "http://arxiv.org/pdf/2406.17279v1",
      "published_date": "2024-06-25 05:08:44 UTC",
      "updated_date": "2024-06-25 05:08:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:44:03.896975"
    },
    {
      "arxiv_id": "2406.17266v1",
      "title": "AG-LSEC: Audio Grounded Lexical Speaker Error Correction",
      "title_zh": "翻译失败",
      "authors": [
        "Rohit Paturi",
        "Xiang Li",
        "Sundararajan Srinivasan"
      ],
      "abstract": "Speaker Diarization (SD) systems are typically audio-based and operate\nindependently of the ASR system in traditional speech transcription pipelines\nand can have speaker errors due to SD and/or ASR reconciliation, especially\naround speaker turns and regions of speech overlap. To reduce these errors, a\nLexical Speaker Error Correction (LSEC), in which an external language model\nprovides lexical information to correct the speaker errors, was recently\nproposed. Though the approach achieves good Word Diarization error rate (WDER)\nimprovements, it does not use any additional acoustic information and is prone\nto miscorrections. In this paper, we propose to enhance and acoustically ground\nthe LSEC system with speaker scores directly derived from the existing SD\npipeline. This approach achieves significant relative WDER reductions in the\nrange of 25-40% over the audio-based SD, ASR system and beats the LSEC system\nby 15-25% relative on RT03-CTS, Callhome American English and Fisher datasets.",
      "tldr_zh": "该论文针对语音转录管道中 Speaker Diarization (SD) 系统的说话者错误问题（如说话者切换和重叠区域），提出了一种 Audio Grounded Lexical Speaker Error Correction (AG-LSEC) 方法。AG-LSEC 通过将原有 Lexical Speaker Error Correction (LSEC) 系统与来自 SD 管道的说话者分数相结合，实现声学地化增强，从而减少错误纠正的误判。实验结果显示，在 RT03-CTS、Callhome American English 和 Fisher 数据集上，AG-LSEC 相对于音频-based SD 和 ASR 系统实现了 25-40% 的 Word Diarization Error Rate (WDER) 相对减少，并比 LSEC 系统进一步提升 15-25%。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "eess.AS",
      "comment": "Accepted at INTERSPEECH 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.17266v1",
      "published_date": "2024-06-25 04:20:49 UTC",
      "updated_date": "2024-06-25 04:20:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:44:16.159813"
    },
    {
      "arxiv_id": "2406.17265v1",
      "title": "Image-Guided Outdoor LiDAR Perception Quality Assessment for Autonomous Driving",
      "title_zh": "翻译失败",
      "authors": [
        "Ce Zhang",
        "Azim Eskandarian"
      ],
      "abstract": "LiDAR is one of the most crucial sensors for autonomous vehicle perception.\nHowever, current LiDAR-based point cloud perception algorithms lack\ncomprehensive and rigorous LiDAR quality assessment methods, leading to\nuncertainty in detection performance. Additionally, existing point cloud\nquality assessment algorithms are predominantly designed for indoor\nenvironments or single-object scenarios. In this paper, we introduce a novel\nimage-guided point cloud quality assessment algorithm for outdoor autonomous\ndriving environments, named the Image-Guided Outdoor Point Cloud Quality\nAssessment (IGO-PQA) algorithm. Our proposed algorithm comprises two main\ncomponents. The first component is the IGO-PQA generation algorithm, which\nleverages point cloud data, corresponding RGB surrounding view images, and\nagent objects' ground truth annotations to generate an overall quality score\nfor a single-frame LiDAR-based point cloud. The second component is a\ntransformer-based IGO-PQA regression algorithm for no-reference outdoor point\ncloud quality assessment. This regression algorithm allows for the direct\nprediction of IGO-PQA scores in an online manner, without requiring image data\nand object ground truth annotations. We evaluate our proposed algorithm using\nthe nuScenes and Waymo open datasets. The IGO-PQA generation algorithm provides\nconsistent and reasonable perception quality indices. Furthermore, our proposed\nIGO-PQA regression algorithm achieves a Pearson Linear Correlation Coefficient\n(PLCC) of 0.86 on the nuScenes dataset and 0.97 on the Waymo dataset.",
      "tldr_zh": "这篇论文针对自动驾驶中 LiDAR 感知质量评估的不足，提出了一种新型算法 Image-Guided Outdoor Point Cloud Quality Assessment (IGO-PQA)，以解决现有方法主要针对室内或单一物体的局限性。算法包括两个核心组件：第一个是 IGO-PQA 生成算法，利用点云数据、对应的 RGB 周围视图图像和代理物体的 ground truth 注释来计算单帧点云的整体质量分数；第二个是基于 Transformer 的 IGO-PQA 回归算法，实现无参考在线预测，无需图像数据和注释。实验在 nuScenes 和 Waymo 数据集上验证，该算法提供一致的感知质量指标，并分别达到 Pearson Linear Correlation Coefficient (PLCC) 为 0.86 和 0.97 的高性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "This work has been submitted to the IEEE for possible publication",
      "pdf_url": "http://arxiv.org/pdf/2406.17265v1",
      "published_date": "2024-06-25 04:16:14 UTC",
      "updated_date": "2024-06-25 04:16:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:44:30.515184"
    },
    {
      "arxiv_id": "2406.17251v1",
      "title": "TopoGCL: Topological Graph Contrastive Learning",
      "title_zh": "TopoGCL：拓扑图对比学习",
      "authors": [
        "Yuzhou Chen",
        "Jose Frias",
        "Yulia R. Gel"
      ],
      "abstract": "Graph contrastive learning (GCL) has recently emerged as a new concept which\nallows for capitalizing on the strengths of graph neural networks (GNNs) to\nlearn rich representations in a wide variety of applications which involve\nabundant unlabeled information. However, existing GCL approaches largely tend\nto overlook the important latent information on higher-order graph\nsubstructures. We address this limitation by introducing the concepts of\ntopological invariance and extended persistence on graphs to GCL. In\nparticular, we propose a new contrastive mode which targets topological\nrepresentations of the two augmented views from the same graph, yielded by\nextracting latent shape properties of the graph at multiple resolutions. Along\nwith the extended topological layer, we introduce a new extended persistence\nsummary, namely, extended persistence landscapes (EPL) and derive its\ntheoretical stability guarantees. Our extensive numerical results on\nbiological, chemical, and social interaction graphs show that the new\nTopological Graph Contrastive Learning (TopoGCL) model delivers significant\nperformance gains in unsupervised graph classification for 11 out of 12\nconsidered datasets and also exhibits robustness under noisy scenarios.",
      "tldr_zh": "该研究提出了一种新的拓扑图对比学习模型TopoGCL，以解决现有Graph Contrastive Learning (GCL)方法忽略图的高阶子结构信息的问题。通过引入拓扑不变性和extended persistence概念，该模型针对同一图的两个增强视图提取多分辨率的拓扑表示，并开发了新的extended persistence landscapes (EPL)及其理论稳定性保证。实验结果显示，TopoGCL在11个生物、化学和社会互动图数据集上的无监督图分类任务中实现了显著性能提升，并在噪声环境中表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.17251v1",
      "published_date": "2024-06-25 03:35:20 UTC",
      "updated_date": "2024-06-25 03:35:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:44:39.766011"
    },
    {
      "arxiv_id": "2406.17246v2",
      "title": "Beyond Silence: Bias Analysis through Loss and Asymmetric Approach in Audio Anti-Spoofing",
      "title_zh": "翻译失败",
      "authors": [
        "Hye-jin Shim",
        "Md Sahidullah",
        "Jee-weon Jung",
        "Shinji Watanabe",
        "Tomi Kinnunen"
      ],
      "abstract": "Current trends in audio anti-spoofing detection research strive to improve\nmodels' ability to generalize across unseen attacks by learning to identify a\nvariety of spoofing artifacts. This emphasis has primarily focused on the spoof\nclass. Recently, several studies have noted that the distribution of silence\ndiffers between the two classes, which can serve as a shortcut. In this paper,\nwe extend class-wise interpretations beyond silence. We employ loss analysis\nand asymmetric methodologies to move away from traditional attack-focused and\nresult-oriented evaluations towards a deeper examination of model behaviors.\nOur investigations highlight the significant differences in training dynamics\nbetween the two classes, emphasizing the need for future research to focus on\nrobust modeling of the bonafide class.",
      "tldr_zh": "这篇论文探讨了音频反欺骗检测中的偏见问题，通过损失分析(loss analysis)和不对称方法(asymmetric methodologies)，扩展了类别-wise 解释，超越了传统的沉默(silence)分布差异分析。研究发现，真实类(bonafide class)和欺骗类在训练动态上存在显著差异，这可能导致模型依赖捷径而非全面学习。作者强调，未来研究应优先关注真实类的鲁棒建模，以提升模型对未知攻击的泛化能力。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "5 pages, 1 figure, 5 tables, ISCA Interspeech 2024 SynData4GenAI\n  Workshop",
      "pdf_url": "http://arxiv.org/pdf/2406.17246v2",
      "published_date": "2024-06-25 03:24:12 UTC",
      "updated_date": "2024-08-26 14:56:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:45:02.955307"
    },
    {
      "arxiv_id": "2406.17245v2",
      "title": "Unlocking Continual Learning Abilities in Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Wenyu Du",
        "Shuang Cheng",
        "Tongxu Luo",
        "Zihan Qiu",
        "Zeyu Huang",
        "Ka Chun Cheung",
        "Reynold Cheng",
        "Jie Fu"
      ],
      "abstract": "Language models (LMs) exhibit impressive performance and generalization\ncapabilities. However, LMs struggle with the persistent challenge of\ncatastrophic forgetting, which undermines their long-term sustainability in\ncontinual learning (CL). Existing approaches usually address the issue by\nincorporating old task data or task-wise inductive bias into LMs. However, old\ndata and accurate task information are often unavailable or costly to collect,\nhindering the availability of current CL approaches for LMs. To address this\nlimitation, we introduce $\\textbf{MIGU}$ ($\\textbf{M}$agn$\\textbf{I}$tude-based\n$\\textbf{G}$radient $\\textbf{U}$pdating for continual learning), a\nrehearsal-free and task-label-free method that only updates the model\nparameters with large magnitudes of output in LMs' linear layers. MIGU is based\non our observation that the L1-normalized magnitude distribution of the output\nin LMs' linear layers is different when the LM models deal with different task\ndata. By imposing this simple constraint on the gradient update process, we can\nleverage the inherent behaviors of LMs, thereby unlocking their innate CL\nabilities. Our experiments demonstrate that MIGU is universally applicable to\nall three LM architectures (T5, RoBERTa, and Llama2), delivering\nstate-of-the-art or on-par performance across continual finetuning and\ncontinual pre-training settings on four CL benchmarks. For example, MIGU brings\na 15.2% average accuracy improvement over conventional parameter-efficient\nfinetuning baselines in a 15-task CL benchmark. MIGU can also seamlessly\nintegrate with all three existing CL types to further enhance performance. Code\nis available at https://github.com/wenyudu/MIGU.",
      "tldr_zh": "这篇论文探讨了语言模型（LMs）在持续学习（CL）中面临的灾难性遗忘问题，提出了一种无需重演数据（rehearsal-free）和无需任务标签（task-label-free）的创新方法MIGU（Magnitude-based Gradient Updating）。MIGU通过仅更新LMs线性层中输出幅度大的参数，利用输出幅度分布的差异来释放模型的内在CL能力。实验结果显示，该方法适用于T5、RoBERTa和Llama2等多种架构，在四个CL基准上实现了最先进或相当性能，例如在15任务CL基准上比传统参数高效微调基线提升15.2%的平均准确率。此外，MIGU可无缝整合现有CL类型，进一步增强整体表现。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "EMNLP 2024 Findings",
      "pdf_url": "http://arxiv.org/pdf/2406.17245v2",
      "published_date": "2024-06-25 03:24:06 UTC",
      "updated_date": "2024-10-06 10:07:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:45:05.836030"
    },
    {
      "arxiv_id": "2406.17235v2",
      "title": "Task-Agnostic Federated Learning",
      "title_zh": "任务无关联邦学习",
      "authors": [
        "Zhengtao Yao",
        "Hong Nguyen",
        "Ajitesh Srivastava",
        "Jose Luis Ambite"
      ],
      "abstract": "In the realm of medical imaging, leveraging large-scale datasets from various\ninstitutions is crucial for developing precise deep learning models, yet\nprivacy concerns frequently impede data sharing. federated learning (FL)\nemerges as a prominent solution for preserving privacy while facilitating\ncollaborative learning. However, its application in real-world scenarios faces\nseveral obstacles, such as task & data heterogeneity, label scarcity,\nnon-identically distributed (non-IID) data, computational vaiation, etc. In\nreal-world, medical institutions may not want to disclose their tasks to FL\nserver and generalization challenge of out-of-network institutions with un-seen\ntask want to join the on-going federated system. This study address\ntask-agnostic and generalization problem on un-seen tasks by adapting\nself-supervised FL framework. Utilizing Vision Transformer (ViT) as consensus\nfeature encoder for self-supervised pre-training, no initial labels required,\nthe framework enabling effective representation learning across diverse\ndatasets and tasks. Our extensive evaluations, using various real-world non-IID\nmedical imaging datasets, validate our approach's efficacy, retaining 90\\% of\nF1 accuracy with only 5\\% of the training data typically required for\ncentralized approaches and exhibiting superior adaptability to\nout-of-distribution task. The result indicate that federated learning\narchitecture can be a potential approach toward multi-task foundation modeling.",
      "tldr_zh": "这项研究针对医疗成像领域的联邦学习（FL）问题，提出了一种任务无关的自监督FL框架，以应对任务异质性、非IID数据和标签稀缺等挑战。框架使用Vision Transformer (ViT)作为共识特征编码器，进行无标签预训练，从而实现跨多样数据集的有效表示学习，而无需初始标签。实验结果显示，该方法在各种真实非IID医疗数据集上，仅需5%的训练数据即可保留90%的F1准确率，并表现出色于分布外任务的适应性。该框架证明了FL在多任务基础建模中的潜力，为隐私保护下的协作学习提供了新途径。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.CV",
      "comment": "arXiv admin note: text overlap with arXiv:2205.08576 by other authors",
      "pdf_url": "http://arxiv.org/pdf/2406.17235v2",
      "published_date": "2024-06-25 02:53:37 UTC",
      "updated_date": "2025-01-06 16:18:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:45:17.042232"
    },
    {
      "arxiv_id": "2406.17224v1",
      "title": "Large Language Models are Interpretable Learners",
      "title_zh": "翻译失败",
      "authors": [
        "Ruochen Wang",
        "Si Si",
        "Felix Yu",
        "Dorothea Wiesmann",
        "Cho-Jui Hsieh",
        "Inderjit Dhillon"
      ],
      "abstract": "The trade-off between expressiveness and interpretability remains a core\nchallenge when building human-centric predictive models for classification and\ndecision-making. While symbolic rules offer interpretability, they often lack\nexpressiveness, whereas neural networks excel in performance but are known for\nbeing black boxes. In this paper, we show a combination of Large Language\nModels (LLMs) and symbolic programs can bridge this gap. In the proposed\nLLM-based Symbolic Programs (LSPs), the pretrained LLM with natural language\nprompts provides a massive set of interpretable modules that can transform raw\ninput into natural language concepts. Symbolic programs then integrate these\nmodules into an interpretable decision rule. To train LSPs, we develop a\ndivide-and-conquer approach to incrementally build the program from scratch,\nwhere the learning process of each step is guided by LLMs. To evaluate the\neffectiveness of LSPs in extracting interpretable and accurate knowledge from\ndata, we introduce IL-Bench, a collection of diverse tasks, including both\nsynthetic and real-world scenarios across different modalities. Empirical\nresults demonstrate LSP's superior performance compared to traditional\nneurosymbolic programs and vanilla automatic prompt tuning methods. Moreover,\nas the knowledge learned by LSP is a combination of natural language\ndescriptions and symbolic rules, it is easily transferable to humans\n(interpretable), and other LLMs, and generalizes well to out-of-distribution\nsamples.",
      "tldr_zh": "本研究探讨了在分类和决策模型中表达性和可解释性之间的权衡问题，提出了一种结合 Large Language Models (LLMs) 和 symbolic programs 的框架，称为 LLM-based Symbolic Programs (LSPs)。LSPs 通过预训练的 LLMs 和自然语言提示生成可解释模块，将原始输入转化为自然语言概念，然后整合成符号决策规则。研究采用 divide-and-conquer 策略逐步训练 LSPs，每个步骤由 LLMs 指导，以从数据中提取准确知识。实验在 IL-Bench 基准上显示，LSPs 优于传统 neurosymbolic programs 和自动提示调整方法，且其知识易于人类理解、可转移到其他 LLMs，并对 out-of-distribution 样本具有良好泛化能力。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.LG",
        "cs.SC",
        "68T05"
      ],
      "primary_category": "cs.AI",
      "comment": "Preliminary Version, Code at [this\n  url](https://github.com/ruocwang/llm-symbolic-program)",
      "pdf_url": "http://arxiv.org/pdf/2406.17224v1",
      "published_date": "2024-06-25 02:18:15 UTC",
      "updated_date": "2024-06-25 02:18:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:45:30.763950"
    },
    {
      "arxiv_id": "2406.17216v2",
      "title": "Machine Unlearning Fails to Remove Data Poisoning Attacks",
      "title_zh": "翻译失败",
      "authors": [
        "Martin Pawelczyk",
        "Jimmy Z. Di",
        "Yiwei Lu",
        "Ayush Sekhari",
        "Gautam Kamath",
        "Seth Neel"
      ],
      "abstract": "We revisit the efficacy of several practical methods for approximate machine\nunlearning developed for large-scale deep learning. In addition to complying\nwith data deletion requests, one often-cited potential application for\nunlearning methods is to remove the effects of poisoned data. We experimentally\ndemonstrate that, while existing unlearning methods have been demonstrated to\nbe effective in a number of settings, they fail to remove the effects of data\npoisoning across a variety of types of poisoning attacks (indiscriminate,\ntargeted, and a newly-introduced Gaussian poisoning attack) and models (image\nclassifiers and LLMs); even when granted a relatively large compute budget. In\norder to precisely characterize unlearning efficacy, we introduce new\nevaluation metrics for unlearning based on data poisoning. Our results suggest\nthat a broader perspective, including a wider variety of evaluations, are\nrequired to avoid a false sense of confidence in machine unlearning procedures\nfor deep learning without provable guarantees. Moreover, while unlearning\nmethods show some signs of being useful to efficiently remove poisoned data\nwithout having to retrain, our work suggests that these methods are not yet\n``ready for prime time,'' and currently provide limited benefit over\nretraining.",
      "tldr_zh": "该研究审视了机器取消学习（machine unlearning）方法在移除数据中毒攻击（data poisoning attacks）方面的效能，发现这些方法无法有效消除中毒数据的影响。作者通过实验评估了多种攻击类型，包括indiscriminate、targeted和新的Gaussian poisoning attack，以及不同模型（如图像分类器和LLMs），即使在较大计算资源下也失败了。为此，他们引入了基于数据中毒的新评估指标，并强调需要更广泛的评估视角，以避免对深度学习取消学习程序的虚假信心；目前，这些方法提供有限益处，不如直接重新训练可靠。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "Published at ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2406.17216v2",
      "published_date": "2024-06-25 02:05:29 UTC",
      "updated_date": "2025-04-01 10:49:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:45:41.082900"
    },
    {
      "arxiv_id": "2406.17215v3",
      "title": "Enabling Large Language Models to Perform Power System Simulations with Previously Unseen Tools: A Case of Daline",
      "title_zh": "翻译失败",
      "authors": [
        "Mengshuo Jia",
        "Zeyu Cui",
        "Gabriela Hug"
      ],
      "abstract": "The integration of experiment technologies with large language models (LLMs)\nis transforming scientific research, offering AI capabilities beyond\nspecialized problem-solving to becoming research assistants for human\nscientists. In power systems, simulations are essential for research. However,\nLLMs face significant challenges in power system simulations due to limited\npre-existing knowledge and the complexity of power grids. To address this\nissue, this work proposes a modular framework that integrates expertise from\nboth the power system and LLM domains. This framework enhances LLMs' ability to\nperform power system simulations on previously unseen tools. Validated using 34\nsimulation tasks in Daline, a (optimal) power flow simulation and linearization\ntoolbox not yet exposed to LLMs, the proposed framework improved GPT-4o's\nsimulation coding accuracy from 0% to 96.07%, also outperforming the ChatGPT-4o\nweb interface's 33.8% accuracy (with the entire knowledge base uploaded). These\nresults highlight the potential of LLMs as research assistants in power\nsystems.",
      "tldr_zh": "本研究针对大型语言模型（LLMs）在电力系统模拟中的局限性（如缺乏预有知识和处理复杂电网的挑战），提出一个模块化框架，该框架整合电力系统和LLMs领域的专业知识，使LLMs能够使用之前未见过的工具进行模拟。框架以Daline（一个电力流模拟和线性化工具）为例，通过34个模拟任务进行验证，将GPT-4o的模拟编码准确率从0%提高到96.07%，显著优于ChatGPT-4o的33.8%。这些结果证明了LLMs作为电力系统研究助手的潜力，推动AI在科学领域的应用。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.17215v3",
      "published_date": "2024-06-25 02:05:26 UTC",
      "updated_date": "2024-11-19 20:16:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:45:54.642982"
    },
    {
      "arxiv_id": "2406.17188v2",
      "title": "Geometric Median (GM) Matching for Robust Data Pruning",
      "title_zh": "翻译失败",
      "authors": [
        "Anish Acharya",
        "Inderjit S Dhillon",
        "Sujay Sanghavi"
      ],
      "abstract": "Large-scale data collections in the wild, are invariably noisy. Thus\ndeveloping data pruning strategies that remain robust even in the presence of\ncorruption is critical in practice. In this work, we propose Geometric Median\n($\\gm$) Matching -- a herding style greedy algorithm that yields a $k$-subset\nsuch that the mean of the subset approximates the geometric median of the\n(potentially) noisy dataset. Theoretically, we show that $\\gm$ Matching enjoys\nan improved $\\gO(1/k)$ scaling over $\\gO(1/\\sqrt{k})$ scaling of uniform\nsampling; while achieving {\\bf optimal breakdown point} of {\\bf 1/2} even under\n{\\bf arbitrary} corruption. Extensive experiments across several popular deep\nlearning benchmarks indicate that $\\gm$ Matching consistently improves over\nprior state-of-the-art; the gains become more profound at high rates of\ncorruption and aggressive pruning rates; making $\\gm$ Matching a strong\nbaseline for future research in robust data pruning.",
      "tldr_zh": "本研究提出了一种名为 Geometric Median (GM) Matching 的贪婪算法，用于在噪声数据集中进行鲁棒数据修剪，该算法通过选择子集使其均值逼近数据集的几何中位数，从而改善数据选择效率。理论上，GM Matching 比均匀采样具有更好的 O(1/k) 收敛率，并实现最佳崩溃点（breakdown point）为 1/2，即使面对任意损坏也能保持鲁棒性。实验结果显示，在多个深度学习基准上，该方法显著优于现有最先进技术，尤其在高损坏率和高修剪率场景下，证明了其作为未来鲁棒数据修剪研究的强有力基准。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.17188v2",
      "published_date": "2024-06-25 00:02:01 UTC",
      "updated_date": "2025-01-17 08:38:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:46:05.430792"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 129,
  "processed_papers_count": 129,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-19T00:46:31.476042"
}