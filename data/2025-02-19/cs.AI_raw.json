[
  {
    "arxiv_id": "2502.14155v2",
    "title": "Giving AI Personalities Leads to More Human-Like Reasoning",
    "authors": [
      "Animesh Nighojkar",
      "Bekhzodbek Moydinboyev",
      "My Duong",
      "John Licato"
    ],
    "abstract": "In computational cognitive modeling, capturing the full spectrum of human\njudgment and decision-making processes, beyond just optimal behaviors, is a\nsignificant challenge. This study explores whether Large Language Models (LLMs)\ncan emulate the breadth of human reasoning by predicting both intuitive, fast\nSystem 1 and deliberate, slow System 2 processes. We investigate the potential\nof AI to mimic diverse reasoning behaviors across a human population,\naddressing what we call the \"full reasoning spectrum problem\". We designed\nreasoning tasks using a novel generalization of the Natural Language Inference\n(NLI) format to evaluate LLMs' ability to replicate human reasoning. The\nquestions were crafted to elicit both System 1 and System 2 responses. Human\nresponses were collected through crowd-sourcing and the entire distribution was\nmodeled, rather than just the majority of the answers. We used\npersonality-based prompting inspired by the Big Five personality model to\nelicit AI responses reflecting specific personality traits, capturing the\ndiversity of human reasoning, and exploring how personality traits influence\nLLM outputs. Combined with genetic algorithms to optimize the weighting of\nthese prompts, this method was tested alongside traditional machine learning\nmodels. The results show that LLMs can mimic human response distributions, with\nopen-source models like Llama and Mistral outperforming proprietary GPT models.\nPersonality-based prompting, especially when optimized with genetic algorithms,\nsignificantly enhanced LLMs' ability to predict human response distributions,\nsuggesting that capturing suboptimal, naturalistic reasoning may require\nmodeling techniques incorporating diverse reasoning styles and psychological\nprofiles. The study concludes that personality-based prompting combined with\ngenetic algorithms is promising for enhancing AI's 'human-ness' in reasoning.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.14155v2",
    "published_date": "2025-02-19 23:51:23 UTC",
    "updated_date": "2025-02-21 14:57:14 UTC"
  },
  {
    "arxiv_id": "2502.14149v1",
    "title": "PitVQA++: Vector Matrix-Low-Rank Adaptation for Open-Ended Visual Question Answering in Pituitary Surgery",
    "authors": [
      "Runlong He",
      "Danyal Z. Khan",
      "Evangelos B. Mazomenos",
      "Hani J. Marcus",
      "Danail Stoyanov",
      "Matthew J. Clarkson",
      "Mobarakol Islam"
    ],
    "abstract": "Vision-Language Models (VLMs) in visual question answering (VQA) offer a\nunique opportunity to enhance intra-operative decision-making, promote\nintuitive interactions, and significantly advancing surgical education.\nHowever, the development of VLMs for surgical VQA is challenging due to limited\ndatasets and the risk of overfitting and catastrophic forgetting during full\nfine-tuning of pretrained weights. While parameter-efficient techniques like\nLow-Rank Adaptation (LoRA) and Matrix of Rank Adaptation (MoRA) address\nadaptation challenges, their uniform parameter distribution overlooks the\nfeature hierarchy in deep networks, where earlier layers, that learn general\nfeatures, require more parameters than later ones. This work introduces\nPitVQA++ with an open-ended PitVQA dataset and vector matrix-low-rank\nadaptation (Vector-MoLoRA), an innovative VLM fine-tuning approach for adapting\nGPT-2 to pituitary surgery. Open-Ended PitVQA comprises around 101,803 frames\nfrom 25 procedural videos with 745,972 question-answer sentence pairs, covering\nkey surgical elements such as phase and step recognition, context\nunderstanding, tool detection, localization, and interactions recognition.\nVector-MoLoRA incorporates the principles of LoRA and MoRA to develop a\nmatrix-low-rank adaptation strategy that employs vector ranking to allocate\nmore parameters to earlier layers, gradually reducing them in the later layers.\nOur approach, validated on the Open-Ended PitVQA and EndoVis18-VQA datasets,\neffectively mitigates catastrophic forgetting while significantly enhancing\nperformance over recent baselines. Furthermore, our risk-coverage analysis\nhighlights its enhanced reliability and trustworthiness in handling uncertain\npredictions. Our source code and dataset is available\nat~\\url{https://github.com/HRL-Mike/PitVQA-Plus}.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "9 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.14149v1",
    "published_date": "2025-02-19 23:28:39 UTC",
    "updated_date": "2025-02-19 23:28:39 UTC"
  },
  {
    "arxiv_id": "2502.14143v1",
    "title": "Multi-Agent Risks from Advanced AI",
    "authors": [
      "Lewis Hammond",
      "Alan Chan",
      "Jesse Clifton",
      "Jason Hoelscher-Obermaier",
      "Akbir Khan",
      "Euan McLean",
      "Chandler Smith",
      "Wolfram Barfuss",
      "Jakob Foerster",
      "Tomáš Gavenčiak",
      "The Anh Han",
      "Edward Hughes",
      "Vojtěch Kovařík",
      "Jan Kulveit",
      "Joel Z. Leibo",
      "Caspar Oesterheld",
      "Christian Schroeder de Witt",
      "Nisarg Shah",
      "Michael Wellman",
      "Paolo Bova",
      "Theodor Cimpeanu",
      "Carson Ezell",
      "Quentin Feuillade-Montixi",
      "Matija Franklin",
      "Esben Kran",
      "Igor Krawczuk",
      "Max Lamparth",
      "Niklas Lauffer",
      "Alexander Meinke",
      "Sumeet Motwani",
      "Anka Reuel",
      "Vincent Conitzer",
      "Michael Dennis",
      "Iason Gabriel",
      "Adam Gleave",
      "Gillian Hadfield",
      "Nika Haghtalab",
      "Atoosa Kasirzadeh",
      "Sébastien Krier",
      "Kate Larson",
      "Joel Lehman",
      "David C. Parkes",
      "Georgios Piliouras",
      "Iyad Rahwan"
    ],
    "abstract": "The rapid development of advanced AI agents and the imminent deployment of\nmany instances of these agents will give rise to multi-agent systems of\nunprecedented complexity. These systems pose novel and under-explored risks. In\nthis report, we provide a structured taxonomy of these risks by identifying\nthree key failure modes (miscoordination, conflict, and collusion) based on\nagents' incentives, as well as seven key risk factors (information asymmetries,\nnetwork effects, selection pressures, destabilising dynamics, commitment\nproblems, emergent agency, and multi-agent security) that can underpin them. We\nhighlight several important instances of each risk, as well as promising\ndirections to help mitigate them. By anchoring our analysis in a range of\nreal-world examples and experimental evidence, we illustrate the distinct\nchallenges posed by multi-agent systems and their implications for the safety,\ngovernance, and ethics of advanced AI.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.CY",
      "cs.ET",
      "cs.LG"
    ],
    "primary_category": "cs.MA",
    "comment": "Cooperative AI Foundation, Technical Report #1",
    "pdf_url": "http://arxiv.org/pdf/2502.14143v1",
    "published_date": "2025-02-19 23:03:21 UTC",
    "updated_date": "2025-02-19 23:03:21 UTC"
  },
  {
    "arxiv_id": "2502.14132v1",
    "title": "Can Community Notes Replace Professional Fact-Checkers?",
    "authors": [
      "Nadav Borenstein",
      "Greta Warren",
      "Desmond Elliott",
      "Isabelle Augenstein"
    ],
    "abstract": "Two commonly-employed strategies to combat the rise of misinformation on\nsocial media are (i) fact-checking by professional organisations and (ii)\ncommunity moderation by platform users. Policy changes by Twitter/X and, more\nrecently, Meta, signal a shift away from partnerships with fact-checking\norganisations and towards an increased reliance on crowdsourced community\nnotes. However, the extent and nature of dependencies between fact-checking and\nhelpful community notes remain unclear. To address these questions, we use\nlanguage models to annotate a large corpus of Twitter/X community notes with\nattributes such as topic, cited sources, and whether they refute claims tied to\nbroader misinformation narratives. Our analysis reveals that community notes\ncite fact-checking sources up to five times more than previously reported.\nFact-checking is especially crucial for notes on posts linked to broader\nnarratives, which are twice as likely to reference fact-checking sources\ncompared to other sources. In conclusion, our results show that successful\ncommunity moderation heavily relies on professional fact-checking.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.14132v1",
    "published_date": "2025-02-19 22:26:39 UTC",
    "updated_date": "2025-02-19 22:26:39 UTC"
  },
  {
    "arxiv_id": "2502.14131v3",
    "title": "An Empirical Risk Minimization Approach for Offline Inverse RL and Dynamic Discrete Choice Model",
    "authors": [
      "Enoch H. Kang",
      "Hema Yoganarasimhan",
      "Lalit Jain"
    ],
    "abstract": "We study the problem of estimating Dynamic Discrete Choice (DDC) models, also\nknown as offline Maximum Entropy-Regularized Inverse Reinforcement Learning\n(offline MaxEnt-IRL) in machine learning. The objective is to recover reward or\n$Q^*$ functions that govern agent behavior from offline behavior data. In this\npaper, we propose a globally convergent gradient-based method for solving these\nproblems without the restrictive assumption of linearly parameterized rewards.\nThe novelty of our approach lies in introducing the Empirical Risk Minimization\n(ERM) based IRL/DDC framework, which circumvents the need for explicit state\ntransition probability estimation in the Bellman equation. Furthermore, our\nmethod is compatible with non-parametric estimation techniques such as neural\nnetworks. Therefore, the proposed method has the potential to be scaled to\nhigh-dimensional, infinite state spaces. A key theoretical insight underlying\nour approach is that the Bellman residual satisfies the Polyak-Lojasiewicz (PL)\ncondition -- a property that, while weaker than strong convexity, is sufficient\nto ensure fast global convergence guarantees. Through a series of synthetic\nexperiments, we demonstrate that our approach consistently outperforms\nbenchmark methods and state-of-the-art alternatives.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "econ.EM"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.14131v3",
    "published_date": "2025-02-19 22:22:20 UTC",
    "updated_date": "2025-05-06 17:12:37 UTC"
  },
  {
    "arxiv_id": "2502.14121v1",
    "title": "Multi-Objective Bayesian Optimization for Networked Black-Box Systems: A Path to Greener Profits and Smarter Designs",
    "authors": [
      "Akshay Kudva",
      "Wei-Ting Tang",
      "Joel A. Paulson"
    ],
    "abstract": "Designing modern industrial systems requires balancing several competing\nobjectives, such as profitability, resilience, and sustainability, while\naccounting for complex interactions between technological, economic, and\nenvironmental factors. Multi-objective optimization (MOO) methods are commonly\nused to navigate these tradeoffs, but selecting the appropriate algorithm to\ntackle these problems is often unclear, particularly when system\nrepresentations vary from fully equation-based (white-box) to entirely\ndata-driven (black-box) models. While grey-box MOO methods attempt to bridge\nthis gap, they typically impose rigid assumptions on system structure,\nrequiring models to conform to the underlying structural assumptions of the\nsolver rather than the solver adapting to the natural representation of the\nsystem of interest. In this chapter, we introduce a unifying approach to\ngrey-box MOO by leveraging network representations, which provide a general and\nflexible framework for modeling interconnected systems as a series of function\nnodes that share various inputs and outputs. Specifically, we propose MOBONS, a\nnovel Bayesian optimization-inspired algorithm that can efficiently optimize\ngeneral function networks, including those with cyclic dependencies, enabling\nthe modeling of feedback loops, recycle streams, and multi-scale simulations -\nfeatures that existing methods fail to capture. Furthermore, MOBONS\nincorporates constraints, supports parallel evaluations, and preserves the\nsample efficiency of Bayesian optimization while leveraging network structure\nfor improved scalability. We demonstrate the effectiveness of MOBONS through\ntwo case studies, including one related to sustainable process design. By\nenabling efficient MOO under general graph representations, MOBONS has the\npotential to significantly enhance the design of more profitable, resilient,\nand sustainable engineering systems.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "stat.ML",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.14121v1",
    "published_date": "2025-02-19 21:49:05 UTC",
    "updated_date": "2025-02-19 21:49:05 UTC"
  },
  {
    "arxiv_id": "2503.05740v1",
    "title": "ChatWise: AI-Powered Engaging Conversations for Enhancing Senior Cognitive Wellbeing",
    "authors": [
      "Zhengbang Yang",
      "Zhuangdi Zhu"
    ],
    "abstract": "Cognitive health in older adults presents a growing challenge. While\nconversational interventions show feasibility in improving cognitive wellness,\nhuman caregiver resources remain overburdened. AI-based methods have shown\npromise in providing conversational support, yet existing work is limited to\nimplicit strategy while lacking multi-turn support tailored to seniors. We\nimprove prior art with an LLM-driven chatbot named ChatWise for older adults.\nIt follows dual-level conversation reasoning at the inference phase to provide\nengaging companionship. ChatWise thrives in long-turn conversations, in\ncontrast to conventional LLMs that primarily excel in short-turn exchanges.\nGrounded experiments show that ChatWise significantly enhances simulated users'\ncognitive and emotional status, including those with Mild Cognitive Impairment.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.05740v1",
    "published_date": "2025-02-19 21:32:09 UTC",
    "updated_date": "2025-02-19 21:32:09 UTC"
  },
  {
    "arxiv_id": "2502.14114v1",
    "title": "Zero loss guarantees and explicit minimizers for generic overparametrized Deep Learning networks",
    "authors": [
      "Thomas Chen",
      "Andrew G. Moore"
    ],
    "abstract": "We determine sufficient conditions for overparametrized deep learning (DL)\nnetworks to guarantee the attainability of zero loss in the context of\nsupervised learning, for the $\\mathcal{L}^2$ cost and {\\em generic} training\ndata. We present an explicit construction of the zero loss minimizers without\ninvoking gradient descent. On the other hand, we point out that increase of\ndepth can deteriorate the efficiency of cost minimization using a gradient\ndescent algorithm by analyzing the conditions for rank loss of the training\nJacobian. Our results clarify key aspects on the dichotomy between zero loss\nreachability in underparametrized versus overparametrized DL.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.AP",
      "math.OC",
      "stat.ML",
      "57R70, 62M45"
    ],
    "primary_category": "cs.LG",
    "comment": "AMS Latex, 9 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.14114v1",
    "published_date": "2025-02-19 21:31:05 UTC",
    "updated_date": "2025-02-19 21:31:05 UTC"
  },
  {
    "arxiv_id": "2502.14113v1",
    "title": "Object-centric Binding in Contrastive Language-Image Pretraining",
    "authors": [
      "Rim Assouel",
      "Pietro Astolfi",
      "Florian Bordes",
      "Michal Drozdzal",
      "Adriana Romero-Soriano"
    ],
    "abstract": "Recent advances in vision language models (VLM) have been driven by\ncontrastive models such as CLIP, which learn to associate visual information\nwith their corresponding text descriptions. However, these models have\nlimitations in understanding complex compositional scenes involving multiple\nobjects and their spatial relationships. To address these challenges, we\npropose a novel approach that diverges from commonly used strategies, which\nrely on the design of hard-negative augmentations. Instead, our work focuses on\nintegrating inductive biases into pre-trained CLIP-like models to improve their\ncompositional understanding without using any additional hard-negatives. To\nthat end, we introduce a binding module that connects a scene graph, derived\nfrom a text description, with a slot-structured image representation,\nfacilitating a structured similarity assessment between the two modalities. We\nalso leverage relationships as text-conditioned visual constraints, thereby\ncapturing the intricate interactions between objects and their contextual\nrelationships more effectively. Our resulting model not only enhances the\nperformance of CLIP-based models in multi-object compositional understanding\nbut also paves the way towards more accurate and sample-efficient image-text\nmatching of complex scenes.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.14113v1",
    "published_date": "2025-02-19 21:30:51 UTC",
    "updated_date": "2025-02-19 21:30:51 UTC"
  },
  {
    "arxiv_id": "2502.14102v1",
    "title": "Explainable Distributed Constraint Optimization Problems",
    "authors": [
      "Ben Rachmut",
      "Stylianos Loukas Vasileiou",
      "Nimrod Meir Weinstein",
      "Roie Zivan",
      "William Yeoh"
    ],
    "abstract": "The Distributed Constraint Optimization Problem (DCOP) formulation is a\npowerful tool to model cooperative multi-agent problems that need to be solved\ndistributively. A core assumption of existing approaches is that DCOP solutions\ncan be easily understood, accepted, and adopted, which may not hold, as\nevidenced by the large body of literature on Explainable AI. In this paper, we\npropose the Explainable DCOP (X-DCOP) model, which extends a DCOP to include\nits solution and a contrastive query for that solution. We formally define some\nkey properties that contrastive explanations must satisfy for them to be\nconsidered as valid solutions to X-DCOPs as well as theoretical results on the\nexistence of such valid explanations. To solve X-DCOPs, we propose a\ndistributed framework as well as several optimizations and suboptimal variants\nto find valid explanations. We also include a human user study that showed that\nusers, not surprisingly, prefer shorter explanations over longer ones. Our\nempirical evaluations showed that our approach can scale to large problems, and\nthe different variants provide different options for trading off explanation\nlengths for smaller runtimes. Thus, our model and algorithmic contributions\nextend the state of the art by reducing the barrier for users to understand\nDCOP solutions, facilitating their adoption in more real-world applications.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.14102v1",
    "published_date": "2025-02-19 21:06:30 UTC",
    "updated_date": "2025-02-19 21:06:30 UTC"
  },
  {
    "arxiv_id": "2502.14086v1",
    "title": "Navigating Semantic Relations: Challenges for Language Models in Abstract Common-Sense Reasoning",
    "authors": [
      "Cole Gawin",
      "Yidan Sun",
      "Mayank Kejriwal"
    ],
    "abstract": "Large language models (LLMs) have achieved remarkable performance in\ngenerating human-like text and solving reasoning tasks of moderate complexity,\nsuch as question-answering and mathematical problem-solving. However, their\ncapabilities in tasks requiring deeper cognitive skills, such as common-sense\nunderstanding and abstract reasoning, remain under-explored. In this paper, we\nsystematically evaluate abstract common-sense reasoning in LLMs using the\nConceptNet knowledge graph. We propose two prompting approaches: instruct\nprompting, where models predict plausible semantic relationships based on\nprovided definitions, and few-shot prompting, where models identify relations\nusing examples as guidance. Our experiments with the gpt-4o-mini model show\nthat in instruct prompting, consistent performance is obtained when ranking\nmultiple relations but with substantial decline when the model is restricted to\npredicting only one relation. In few-shot prompting, the model's accuracy\nimproves significantly when selecting from five relations rather than the full\nset, although with notable bias toward certain relations. These results suggest\nsignificant gaps still, even in commercially used LLMs' abstract common-sense\nreasoning abilities, compared to human-level understanding. However, the\nfindings also highlight the promise of careful prompt engineering, based on\nselective retrieval, for obtaining better performance.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "5 pages, 3 figures, ACM Web Conference 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.14086v1",
    "published_date": "2025-02-19 20:20:24 UTC",
    "updated_date": "2025-02-19 20:20:24 UTC"
  },
  {
    "arxiv_id": "2502.17490v1",
    "title": "A generalized dual potential for inelastic Constitutive Artificial Neural Networks: A JAX implementation at finite strains",
    "authors": [
      "Hagen Holthusen",
      "Kevin Linka",
      "Ellen Kuhl",
      "Tim Brepols"
    ],
    "abstract": "We present a methodology for designing a generalized dual potential, or\npseudo potential, for inelastic Constitutive Artificial Neural Networks\n(iCANNs). This potential, expressed in terms of stress invariants, inherently\nsatisfies thermodynamic consistency for large deformations. In comparison to\nour previous work, the new potential captures a broader spectrum of material\nbehaviors, including pressure-sensitive inelasticity.\n  To this end, we revisit the underlying thermodynamic framework of iCANNs for\nfinite strain inelasticity and derive conditions for constructing a convex,\nzero-valued, and non-negative dual potential. To embed these principles in a\nneural network, we detail the architecture's design, ensuring a priori\ncompliance with thermodynamics.\n  To evaluate the proposed architecture, we study its performance and\nlimitations discovering visco-elastic material behavior, though the method is\nnot limited to visco-elasticity. In this context, we investigate different\naspects in the strategy of discovering inelastic materials. Our results\nindicate that the novel architecture robustly discovers interpretable models\nand parameters, while autonomously revealing the degree of inelasticity.\n  The iCANN framework, implemented in JAX, is publicly accessible at\nhttps://doi.org/10.5281/zenodo.14894687.",
    "categories": [
      "cs.LG",
      "cond-mat.mtrl-sci",
      "cs.AI",
      "cs.CE",
      "65, 74",
      "I.6; J.2"
    ],
    "primary_category": "cs.LG",
    "comment": "56 pages, 19 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2502.17490v1",
    "published_date": "2025-02-19 20:16:45 UTC",
    "updated_date": "2025-02-19 20:16:45 UTC"
  },
  {
    "arxiv_id": "2502.14080v1",
    "title": "Personalized Education with Generative AI and Digital Twins: VR, RAG, and Zero-Shot Sentiment Analysis for Industry 4.0 Workforce Development",
    "authors": [
      "Yu-Zheng Lin",
      "Karan Petal",
      "Ahmed H Alhamadah",
      "Sujan Ghimire",
      "Matthew William Redondo",
      "David Rafael Vidal Corona",
      "Jesus Pacheco",
      "Soheil Salehi",
      "Pratik Satam"
    ],
    "abstract": "The Fourth Industrial Revolution (4IR) technologies, such as cloud computing,\nmachine learning, and AI, have improved productivity but introduced challenges\nin workforce training and reskilling. This is critical given existing workforce\nshortages, especially in marginalized communities like Underrepresented\nMinorities (URM), who often lack access to quality education. Addressing these\nchallenges, this research presents gAI-PT4I4, a Generative AI-based\nPersonalized Tutor for Industrial 4.0, designed to personalize 4IR experiential\nlearning. gAI-PT4I4 employs sentiment analysis to assess student comprehension,\nleveraging generative AI and finite automaton to tailor learning experiences.\nThe framework integrates low-fidelity Digital Twins for VR-based training,\nfeaturing an Interactive Tutor - a generative AI assistant providing real-time\nguidance via audio and text. It uses zero-shot sentiment analysis with LLMs and\nprompt engineering, achieving 86\\% accuracy in classifying student-teacher\ninteractions as positive or negative. Additionally, retrieval-augmented\ngeneration (RAG) enables personalized learning content grounded in\ndomain-specific knowledge. To adapt training dynamically, finite automaton\nstructures exercises into states of increasing difficulty, requiring 80\\%\ntask-performance accuracy for progression. Experimental evaluation with 22\nvolunteers showed improved accuracy exceeding 80\\%, reducing training time.\nFinally, this paper introduces a Multi-Fidelity Digital Twin model, aligning\nDigital Twin complexity with Bloom's Taxonomy and Kirkpatrick's model,\nproviding a scalable educational framework.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.14080v1",
    "published_date": "2025-02-19 20:11:19 UTC",
    "updated_date": "2025-02-19 20:11:19 UTC"
  },
  {
    "arxiv_id": "2502.14074v2",
    "title": "Investigating Non-Transitivity in LLM-as-a-Judge",
    "authors": [
      "Yi Xu",
      "Laura Ruis",
      "Tim Rocktäschel",
      "Robert Kirk"
    ],
    "abstract": "Automatic evaluation methods based on large language models (LLMs) are\nemerging as the standard tool for assessing the instruction-following abilities\nof LLM-based agents. The most common method in this paradigm, pairwise\ncomparisons with a baseline model, critically depends on the assumption of\ntransitive preferences. However, the validity of this assumption remains\nlargely unexplored. In this study, we investigate the presence of\nnon-transitivity within the AlpacaEval framework and analyze its effects on\nmodel rankings. We find that LLM judges exhibit non-transitive preferences,\nleading to rankings that are sensitive to the choice of the baseline model. To\nmitigate this issue, we show that round-robin tournaments combined with\nBradley-Terry models of preference can produce more reliable rankings. Notably,\nour method increases both the Spearman correlation and the Kendall correlation\nwith Chatbot Arena (95.0% -> 96.4% and 82.1% -> 86.3% respectively). To address\nthe computational cost of round-robin tournaments, we propose Swiss-Wise\nIterative Matchmaking (Swim) tournaments, using a dynamic matching strategy to\ncapture the benefits of round-robin tournaments while maintaining computational\nefficiency.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "8 pages, 6 figures, 2 tables (30 pages, 11 figures, 8 tables\n  including references and appendices)",
    "pdf_url": "http://arxiv.org/pdf/2502.14074v2",
    "published_date": "2025-02-19 19:59:16 UTC",
    "updated_date": "2025-03-06 06:32:54 UTC"
  },
  {
    "arxiv_id": "2502.14070v1",
    "title": "DiffExp: Efficient Exploration in Reward Fine-tuning for Text-to-Image Diffusion Models",
    "authors": [
      "Daewon Chae",
      "June Suk Choi",
      "Jinkyu Kim",
      "Kimin Lee"
    ],
    "abstract": "Fine-tuning text-to-image diffusion models to maximize rewards has proven\neffective for enhancing model performance. However, reward fine-tuning methods\noften suffer from slow convergence due to online sample generation. Therefore,\nobtaining diverse samples with strong reward signals is crucial for improving\nsample efficiency and overall performance. In this work, we introduce DiffExp,\na simple yet effective exploration strategy for reward fine-tuning of\ntext-to-image models. Our approach employs two key strategies: (a) dynamically\nadjusting the scale of classifier-free guidance to enhance sample diversity,\nand (b) randomly weighting phrases of the text prompt to exploit high-quality\nreward signals. We demonstrate that these strategies significantly enhance\nexploration during online sample generation, improving the sample efficiency of\nrecent reward fine-tuning methods, such as DDPO and AlignProp.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.14070v1",
    "published_date": "2025-02-19 19:47:58 UTC",
    "updated_date": "2025-02-19 19:47:58 UTC"
  },
  {
    "arxiv_id": "2502.14068v1",
    "title": "A Racing Dataset and Baseline Model for Track Detection in Autonomous Racing",
    "authors": [
      "Shreya Ghosh",
      "Yi-Huan Chen",
      "Ching-Hsiang Huang",
      "Abu Shafin Mohammad Mahdee Jameel",
      "Chien Chou Ho",
      "Aly El Gamal",
      "Samuel Labi"
    ],
    "abstract": "A significant challenge in racing-related research is the lack of publicly\navailable datasets containing raw images with corresponding annotations for the\ndownstream task. In this paper, we introduce RoRaTrack, a novel dataset that\ncontains annotated multi-camera image data from racing scenarios for track\ndetection. The data is collected on a Dallara AV-21 at a racing circuit in\nIndiana, in collaboration with the Indy Autonomous Challenge (IAC). RoRaTrack\naddresses common problems such as blurriness due to high speed, color inversion\nfrom the camera, and absence of lane markings on the track. Consequently, we\npropose RaceGAN, a baseline model based on a Generative Adversarial Network\n(GAN) that effectively addresses these challenges. The proposed model\ndemonstrates superior performance compared to current state-of-the-art machine\nlearning models in track detection. The dataset and code for this work are\navailable at github.com/RaceGAN.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "Currently Under Review",
    "pdf_url": "http://arxiv.org/pdf/2502.14068v1",
    "published_date": "2025-02-19 19:43:31 UTC",
    "updated_date": "2025-02-19 19:43:31 UTC"
  },
  {
    "arxiv_id": "2502.14064v2",
    "title": "Triad: Vision Foundation Model for 3D Magnetic Resonance Imaging",
    "authors": [
      "Shansong Wang",
      "Mojtaba Safari",
      "Qiang Li",
      "Chih-Wei Chang",
      "Richard LJ Qiu",
      "Justin Roper",
      "David S. Yu",
      "Xiaofeng Yang"
    ],
    "abstract": "Vision foundation models (VFMs) are pre-trained on extensive image datasets\nto learn general representations for diverse types of data. These models can\nsubsequently be fine-tuned for specific downstream tasks, significantly\nboosting performance across a broad range of applications. However, existing\nvision foundation models that claim to be applicable to various clinical tasks\nare mostly pre-trained on 3D computed tomography (CT), which benefits from the\navailability of extensive 3D CT databases. Significant differences between CT\nand magnetic resonance imaging (MRI) in imaging principles, signal\ncharacteristics, and data distribution may hinder their practical performance\nand versatility in MRI-specific applications. Here, we propose Triad, a vision\nfoundation model for 3D MRI. Triad adopts a widely used autoencoder\narchitecture to learn robust representations from 131,170 3D MRI volumes and\nuses organ-independent imaging descriptions to constrain the semantic\ndistribution of the visual modality. The above pre-training dataset is called\nTriad-131K, which is currently the largest 3D MRI pre-training dataset. We\nevaluate Triad across three tasks, namely, organ/tumor segmentation,\norgan/cancer classification, and medical image registration, in two data\nmodalities (within-domain and out-of-domain) settings using 25 downstream\ndatasets. By initializing models with Triad's pre-trained weights, nnUNet-Triad\nimproves segmentation performance by 2.51% compared to nnUNet-Scratch across 17\ndatasets. Swin-B-Triad achieves a 3.97% improvement over Swin-B-Scratch in\nclassification tasks across five datasets. SwinUNETR-Triad improves by 4.00%\ncompared to SwinUNETR-Scratch in registration tasks across two datasets. Our\nstudy demonstrates that pre-training can improve performance when the data\nmodalities and organs of upstream and downstream tasks are consistent.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.14064v2",
    "published_date": "2025-02-19 19:31:52 UTC",
    "updated_date": "2025-02-23 03:13:01 UTC"
  },
  {
    "arxiv_id": "2502.14061v1",
    "title": "EfficientPose 6D: Scalable and Efficient 6D Object Pose Estimation",
    "authors": [
      "Zixuan Fang",
      "Thomas Pöllabauer",
      "Tristan Wirth",
      "Sarah Berkei",
      "Volker Knauthe",
      "Arjan Kuijper"
    ],
    "abstract": "In industrial applications requiring real-time feedback, such as quality\ncontrol and robotic manipulation, the demand for high-speed and accurate pose\nestimation remains critical. Despite advances improving speed and accuracy in\npose estimation, finding a balance between computational efficiency and\naccuracy poses significant challenges in dynamic environments. Most current\nalgorithms lack scalability in estimation time, especially for diverse\ndatasets, and the state-of-the-art (SOTA) methods are often too slow. This\nstudy focuses on developing a fast and scalable set of pose estimators based on\nGDRNPP to meet or exceed current benchmarks in accuracy and robustness,\nparticularly addressing the efficiency-accuracy trade-off essential in\nreal-time scenarios. We propose the AMIS algorithm to tailor the utilized model\naccording to an application-specific trade-off between inference time and\naccuracy. We further show the effectiveness of the AMIS-based model choice on\nfour prominent benchmark datasets (LM-O, YCB-V, T-LESS, and ITODD).",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.14061v1",
    "published_date": "2025-02-19 19:21:23 UTC",
    "updated_date": "2025-02-19 19:21:23 UTC"
  },
  {
    "arxiv_id": "2502.14050v2",
    "title": "Diversity-driven Data Selection for Language Model Tuning through Sparse Autoencoder",
    "authors": [
      "Xianjun Yang",
      "Shaoliang Nie",
      "Lijuan Liu",
      "Suchin Gururangan",
      "Ujjwal Karn",
      "Rui Hou",
      "Madian Khabsa",
      "Yuning Mao"
    ],
    "abstract": "Instruction tuning data are often quantity-saturated due to the large volume\nof data collection and fast model iteration, leaving data selection important\nbut underexplored. Existing quality-driven data selection methods, such as LIMA\n(NeurIPS 2023 \\citep{zhou2024lima}) and AlpaGasus (ICLR 2024\n\\citep{chenalpagasus}) generally ignore the equal importance of data diversity\nand complexity. In this work, we aim to design a diversity-aware data selection\nstrategy and creatively propose using sparse autoencoders (SAEs) to tackle the\nchallenge of data diversity measure. In addition, SAEs can also provide more\ninterpretability of model behavior and explain, e.g., the surprising\neffectiveness of selecting the longest response (ICML 2024 \\citep{zhaolong}).\nUsing effective data selection, we experimentally prove that models trained on\nour selected data can outperform other methods in terms of model capabilities,\nreduce training cost, and potentially gain more control over model behaviors.\nWe prove that SAEs can serve as a good alternative to diversity measure and\ndesign our method to be scalable for potential industrial large-scale pruning,\nand we will also release our trained SAEs for use by the broader community.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "fix typos",
    "pdf_url": "http://arxiv.org/pdf/2502.14050v2",
    "published_date": "2025-02-19 19:12:34 UTC",
    "updated_date": "2025-03-31 21:41:42 UTC"
  },
  {
    "arxiv_id": "2502.14048v1",
    "title": "Semantic Decomposition and Selective Context Filtering -- Text Processing Techniques for Context-Aware NLP-Based Systems",
    "authors": [
      "Karl John Villardar"
    ],
    "abstract": "In this paper, we present two techniques for use in context-aware systems:\nSemantic Decomposition, which sequentially decomposes input prompts into a\nstructured and hierarchal information schema in which systems can parse and\nprocess easily, and Selective Context Filtering, which enables systems to\nsystematically filter out specific irrelevant sections of contextual\ninformation that is fed through a system's NLP-based pipeline. We will explore\nhow context-aware systems and applications can utilize these two techniques in\norder to implement dynamic LLM-to-system interfaces, improve an LLM's ability\nto generate more contextually cohesive user-facing responses, and optimize\ncomplex automated workflows and pipelines.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC",
      "I.2.7; I.7.0"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.14048v1",
    "published_date": "2025-02-19 19:09:40 UTC",
    "updated_date": "2025-02-19 19:09:40 UTC"
  },
  {
    "arxiv_id": "2502.14047v1",
    "title": "Towards a Learning Theory of Representation Alignment",
    "authors": [
      "Francesco Insulla",
      "Shuo Huang",
      "Lorenzo Rosasco"
    ],
    "abstract": "It has recently been argued that AI models' representations are becoming\naligned as their scale and performance increase. Empirical analyses have been\ndesigned to support this idea and conjecture the possible alignment of\ndifferent representations toward a shared statistical model of reality. In this\npaper, we propose a learning-theoretic perspective to representation alignment.\nFirst, we review and connect different notions of alignment based on metric,\nprobabilistic, and spectral ideas. Then, we focus on stitching, a particular\napproach to understanding the interplay between different representations in\nthe context of a task. Our main contribution here is relating properties of\nstitching to the kernel alignment of the underlying representation. Our results\ncan be seen as a first step toward casting representation alignment as a\nlearning-theoretic problem.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.14047v1",
    "published_date": "2025-02-19 19:09:14 UTC",
    "updated_date": "2025-02-19 19:09:14 UTC"
  },
  {
    "arxiv_id": "2502.14045v1",
    "title": "Position: There are no Champions in Long-Term Time Series Forecasting",
    "authors": [
      "Lorenzo Brigato",
      "Rafael Morand",
      "Knut Strømmen",
      "Maria Panagiotou",
      "Markus Schmidt",
      "Stavroula Mougiakakou"
    ],
    "abstract": "Recent advances in long-term time series forecasting have introduced numerous\ncomplex prediction models that consistently outperform previously published\narchitectures. However, this rapid progression raises concerns regarding\ninconsistent benchmarking and reporting practices, which may undermine the\nreliability of these comparisons. Our position emphasizes the need to shift\nfocus away from pursuing ever-more complex models and towards enhancing\nbenchmarking practices through rigorous and standardized evaluation methods. To\nsupport our claim, we first perform a broad, thorough, and reproducible\nevaluation of the top-performing models on the most popular benchmark by\ntraining 3,500+ networks over 14 datasets. Then, through a comprehensive\nanalysis, we find that slight changes to experimental setups or current\nevaluation metrics drastically shift the common belief that newly published\nresults are advancing the state of the art. Our findings suggest the need for\nrigorous and standardized evaluation methods that enable more substantiated\nclaims, including reproducible hyperparameter setups and statistical testing.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Pre-print",
    "pdf_url": "http://arxiv.org/pdf/2502.14045v1",
    "published_date": "2025-02-19 19:08:37 UTC",
    "updated_date": "2025-02-19 19:08:37 UTC"
  },
  {
    "arxiv_id": "2502.14043v1",
    "title": "Asking for Help Enables Safety Guarantees Without Sacrificing Effectiveness",
    "authors": [
      "Benjamin Plaut",
      "Juan Liévano-Karim",
      "Stuart Russell"
    ],
    "abstract": "Most reinforcement learning algorithms with regret guarantees rely on a\ncritical assumption: that all errors are recoverable. Recent work by Plaut et\nal. discarded this assumption and presented algorithms that avoid \"catastrophe\"\n(i.e., irreparable errors) by asking for help. However, they provided only\nsafety guarantees and did not consider reward maximization. We prove that any\nalgorithm that avoids catastrophe in their setting also guarantees high reward\n(i.e., sublinear regret) in any Markov Decision Process (MDP), including MDPs\nwith irreversible costs. This constitutes the first no-regret guarantee for\ngeneral MDPs. More broadly, our result may be the first formal proof that it is\npossible for an agent to obtain high reward while becoming self-sufficient in\nan unknown, unbounded, and high-stakes environment without causing catastrophe\nor requiring resets.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.14043v1",
    "published_date": "2025-02-19 19:01:39 UTC",
    "updated_date": "2025-02-19 19:01:39 UTC"
  },
  {
    "arxiv_id": "2502.14037v2",
    "title": "DiffSampling: Enhancing Diversity and Accuracy in Neural Text Generation",
    "authors": [
      "Giorgio Franceschelli",
      "Mirco Musolesi"
    ],
    "abstract": "Despite their growing capabilities, language models still frequently\nreproduce content from their training data, generate repetitive text, and favor\ncommon grammatical patterns and vocabulary. A possible cause is the decoding\nstrategy: the most common strategies either consider only the most probable\ntokens, which reduces output diversity, or increase the likelihood of unlikely\ntokens, compromising output accuracy and correctness. In this paper, we propose\nthree new decoding methods that leverage a mathematical analysis of the token\nprobability distribution to ensure the generation of contextually appropriate\ntext. In particular, the difference between consecutive, sorted probabilities\ncan be used to truncate incorrect tokens. Experiments concerning math problem\nsolving, extreme summarization, and the divergent association task demonstrate\nthat our approach consistently performs at least as well as existing methods in\nterms of quality and diversity.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.14037v2",
    "published_date": "2025-02-19 19:00:02 UTC",
    "updated_date": "2025-05-20 06:00:08 UTC"
  },
  {
    "arxiv_id": "2502.15815v1",
    "title": "Theoretical Physics Benchmark (TPBench) -- a Dataset and Study of AI Reasoning Capabilities in Theoretical Physics",
    "authors": [
      "Daniel J. H. Chung",
      "Zhiqi Gao",
      "Yurii Kvasiuk",
      "Tianyi Li",
      "Moritz Münchmeyer",
      "Maja Rudolph",
      "Frederic Sala",
      "Sai Chaitanya Tadepalli"
    ],
    "abstract": "We introduce a benchmark to evaluate the capability of AI to solve problems\nin theoretical physics, focusing on high-energy theory and cosmology. The first\niteration of our benchmark consists of 57 problems of varying difficulty, from\nundergraduate to research level. These problems are novel in the sense that\nthey do not come from public problem collections. We evaluate our data set on\nvarious open and closed language models, including o3-mini, o1, DeepSeek-R1,\nGPT-4o and versions of Llama and Qwen. While we find impressive progress in\nmodel performance with the most recent models, our research-level difficulty\nproblems are mostly unsolved. We address challenges of auto-verifiability and\ngrading, and discuss common failure modes. While currently state-of-the art\nmodels are still of limited use for researchers, our results show that AI\nassisted theoretical physics research may become possible in the near future.\nWe discuss the main obstacles towards this goal and possible strategies to\novercome them. The public problems and solutions, results for various models,\nand updates to the data set and score distribution, are available on the\nwebsite of the dataset tpbench.org.",
    "categories": [
      "cs.LG",
      "astro-ph.CO",
      "cs.AI",
      "hep-ph",
      "hep-th"
    ],
    "primary_category": "cs.LG",
    "comment": "48 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.15815v1",
    "published_date": "2025-02-19 19:00:00 UTC",
    "updated_date": "2025-02-19 19:00:00 UTC"
  },
  {
    "arxiv_id": "2502.13965v1",
    "title": "Autellix: An Efficient Serving Engine for LLM Agents as General Programs",
    "authors": [
      "Michael Luo",
      "Xiaoxiang Shi",
      "Colin Cai",
      "Tianjun Zhang",
      "Justin Wong",
      "Yichuan Wang",
      "Chi Wang",
      "Yanping Huang",
      "Zhifeng Chen",
      "Joseph E. Gonzalez",
      "Ion Stoica"
    ],
    "abstract": "Large language model (LLM) applications are evolving beyond simple chatbots\ninto dynamic, general-purpose agentic programs, which scale LLM calls and\noutput tokens to help AI agents reason, explore, and solve complex tasks.\nHowever, existing LLM serving systems ignore dependencies between programs and\ncalls, missing significant opportunities for optimization. Our analysis reveals\nthat programs submitted to LLM serving engines experience long cumulative wait\ntimes, primarily due to head-of-line blocking at both the individual LLM\nrequest and the program. To address this, we introduce Autellix, an LLM serving\nsystem that treats programs as first-class citizens to minimize their\nend-to-end latencies. Autellix intercepts LLM calls submitted by programs,\nenriching schedulers with program-level context. We propose two scheduling\nalgorithms-for single-threaded and distributed programs-that preempt and\nprioritize LLM calls based on their programs' previously completed calls. Our\nevaluation demonstrates that across diverse LLMs and agentic workloads,\nAutellix improves throughput of programs by 4-15x at the same latency compared\nto state-of-the-art systems, such as vLLM.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.13965v1",
    "published_date": "2025-02-19 18:59:30 UTC",
    "updated_date": "2025-02-19 18:59:30 UTC"
  },
  {
    "arxiv_id": "2502.13964v1",
    "title": "A Training-Free Framework for Precise Mobile Manipulation of Small Everyday Objects",
    "authors": [
      "Arjun Gupta",
      "Rishik Sathua",
      "Saurabh Gupta"
    ],
    "abstract": "Many everyday mobile manipulation tasks require precise interaction with\nsmall objects, such as grasping a knob to open a cabinet or pressing a light\nswitch. In this paper, we develop Servoing with Vision Models (SVM), a\nclosed-loop training-free framework that enables a mobile manipulator to tackle\nsuch precise tasks involving the manipulation of small objects. SVM employs an\nRGB-D wrist camera and uses visual servoing for control. Our novelty lies in\nthe use of state-of-the-art vision models to reliably compute 3D targets from\nthe wrist image for diverse tasks and under occlusion due to the end-effector.\nTo mitigate occlusion artifacts, we employ vision models to out-paint the\nend-effector thereby significantly enhancing target localization. We\ndemonstrate that aided by out-painting methods, open-vocabulary object\ndetectors can serve as a drop-in module to identify semantic targets (e.g.\nknobs) and point tracking methods can reliably track interaction sites\nindicated by user clicks. This training-free method obtains an 85% zero-shot\nsuccess rate on manipulating unseen objects in novel environments in the real\nworld, outperforming an open-loop control method and an imitation learning\nbaseline trained on 1000+ demonstrations by an absolute success rate of 50%.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "Project webpage: https://arjung128.github.io/svm",
    "pdf_url": "http://arxiv.org/pdf/2502.13964v1",
    "published_date": "2025-02-19 18:59:17 UTC",
    "updated_date": "2025-02-19 18:59:17 UTC"
  },
  {
    "arxiv_id": "2502.13957v1",
    "title": "RAG-Gym: Optimizing Reasoning and Search Agents with Process Supervision",
    "authors": [
      "Guangzhi Xiong",
      "Qiao Jin",
      "Xiao Wang",
      "Yin Fang",
      "Haolin Liu",
      "Yifan Yang",
      "Fangyuan Chen",
      "Zhixing Song",
      "Dengyu Wang",
      "Minjia Zhang",
      "Zhiyong Lu",
      "Aidong Zhang"
    ],
    "abstract": "Retrieval-augmented generation (RAG) has shown great potential for\nknowledge-intensive tasks, but its traditional architectures rely on static\nretrieval, limiting their effectiveness for complex questions that require\nsequential information-seeking. While agentic reasoning and search offer a more\nadaptive approach, most existing methods depend heavily on prompt engineering.\nIn this work, we introduce RAG-Gym, a unified optimization framework that\nenhances information-seeking agents through fine-grained process supervision at\neach search step. We also propose ReSearch, a novel agent architecture that\nsynergizes answer reasoning and search query generation within the RAG-Gym\nframework. Experiments on four challenging datasets show that RAG-Gym improves\nperformance by up to 25.6\\% across various agent architectures, with ReSearch\nconsistently outperforming existing baselines. Further analysis highlights the\neffectiveness of advanced LLMs as process reward judges and the transferability\nof trained reward models as verifiers for different LLMs. Additionally, we\nexamine the scaling properties of training and inference in agentic RAG. The\nproject homepage is available at https://rag-gym.github.io/.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.13957v1",
    "published_date": "2025-02-19 18:56:03 UTC",
    "updated_date": "2025-02-19 18:56:03 UTC"
  },
  {
    "arxiv_id": "2502.13953v1",
    "title": "Neurosymbolic artificial intelligence via large language models and coherence-driven inference",
    "authors": [
      "Steve Huntsman",
      "Jewell Thomas"
    ],
    "abstract": "We devise an algorithm to generate sets of propositions that objectively\ninstantiate graphs that support coherence-driven inference. We then benchmark\nthe ability of large language models (LLMs) to reconstruct coherence graphs\nfrom (a straightforward transformation of) propositions expressed in natural\nlanguage, with promising results from a single prompt to models optimized for\nreasoning. Combining coherence-driven inference with consistency evaluations by\nneural models may advance the state of the art in machine cognition.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.13953v1",
    "published_date": "2025-02-19 18:53:16 UTC",
    "updated_date": "2025-02-19 18:53:16 UTC"
  },
  {
    "arxiv_id": "2502.14023v1",
    "title": "Dynamic Activation with Knowledge Distillation for Energy-Efficient Spiking NN Ensembles",
    "authors": [
      "Orestis Konstantaropoulos",
      "Theodoris Mallios",
      "Maria Papadopouli"
    ],
    "abstract": "While foundation AI models excel at tasks like classification and\ndecision-making, their high energy consumption makes them unsuitable for\nenergy-constrained applications. Inspired by the brain's efficiency, spiking\nneural networks (SNNs) have emerged as a viable alternative due to their\nevent-driven nature and compatibility with neuromorphic chips. This work\nintroduces a novel system that combines knowledge distillation and ensemble\nlearning to bridge the performance gap between artificial neural networks\n(ANNs) and SNNs. A foundation AI model acts as a teacher network, guiding\nsmaller student SNNs organized into an ensemble, called Spiking Neural Ensemble\n(SNE). SNE enables the disentanglement of the teacher's knowledge, allowing\neach student to specialize in predicting a distinct aspect of it, while\nprocessing the same input. The core innovation of SNE is the adaptive\nactivation of a subset of SNN models of an ensemble, leveraging\nknowledge-distillation, enhanced with an informed-partitioning\n(disentanglement) of the teacher's feature space. By dynamically activating\nonly a subset of these student SNNs, the system balances accuracy and energy\nefficiency, achieving substantial energy savings with minimal accuracy loss.\nMoreover, SNE is significantly more efficient than the teacher network,\nreducing computational requirements by up to 20x with only a 2% drop in\naccuracy on the CIFAR-10 dataset. This disentanglement procedure achieves an\naccuracy improvement of up to 2.4% on the CIFAR-10 dataset compared to other\npartitioning schemes. Finally, we comparatively analyze SNE performance under\nnoisy conditions, demonstrating enhanced robustness compared to its ANN\nteacher. In summary, SNE offers a promising new direction for\nenergy-constrained applications.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.14023v1",
    "published_date": "2025-02-19 18:50:08 UTC",
    "updated_date": "2025-02-19 18:50:08 UTC"
  },
  {
    "arxiv_id": "2502.13946v1",
    "title": "Why Safeguarded Ships Run Aground? Aligned Large Language Models' Safety Mechanisms Tend to Be Anchored in The Template Region",
    "authors": [
      "Chak Tou Leong",
      "Qingyu Yin",
      "Jian Wang",
      "Wenjie Li"
    ],
    "abstract": "The safety alignment of large language models (LLMs) remains vulnerable, as\ntheir initial behavior can be easily jailbroken by even relatively simple\nattacks. Since infilling a fixed template between the input instruction and\ninitial model output is a common practice for existing LLMs, we hypothesize\nthat this template is a key factor behind their vulnerabilities: LLMs'\nsafety-related decision-making overly relies on the aggregated information from\nthe template region, which largely influences these models' safety behavior. We\nrefer to this issue as template-anchored safety alignment. In this paper, we\nconduct extensive experiments and verify that template-anchored safety\nalignment is widespread across various aligned LLMs. Our mechanistic analyses\ndemonstrate how it leads to models' susceptibility when encountering\ninference-time jailbreak attacks. Furthermore, we show that detaching safety\nmechanisms from the template region is promising in mitigating vulnerabilities\nto jailbreak attacks. We encourage future research to develop more robust\nsafety alignment techniques that reduce reliance on the template region.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.13946v1",
    "published_date": "2025-02-19 18:42:45 UTC",
    "updated_date": "2025-02-19 18:42:45 UTC"
  },
  {
    "arxiv_id": "2502.13943v1",
    "title": "AdaptiveStep: Automatically Dividing Reasoning Step through Model Confidence",
    "authors": [
      "Yuliang Liu",
      "Junjie Lu",
      "Zhaoling Chen",
      "Chaofeng Qu",
      "Jason Klein Liu",
      "Chonghan Liu",
      "Zefan Cai",
      "Yunhui Xia",
      "Li Zhao",
      "Jiang Bian",
      "Chuheng Zhang",
      "Wei Shen",
      "Zhouhan Lin"
    ],
    "abstract": "Current approaches for training Process Reward Models (PRMs) often involve\nbreaking down responses into multiple reasoning steps using rule-based\ntechniques, such as using predefined placeholder tokens or setting the\nreasoning step's length into a fixed size. These approaches overlook the fact\nthat specific words do not typically mark true decision points in a text. To\naddress this, we propose AdaptiveStep, a method that divides reasoning steps\nbased on the model's confidence in predicting the next word. This division\nmethod provides more decision-making information at each step, enhancing\ndownstream tasks, such as reward model learning. Moreover, our method does not\nrequire manual annotation. We demonstrate its effectiveness through experiments\nwith AdaptiveStep-trained PRMs in mathematical reasoning and code generation\ntasks. Experimental results indicate that the outcome PRM achieves\nstate-of-the-art Best-of-N performance, surpassing greedy search strategy with\ntoken-level value-guided decoding, while also reducing construction costs by\nover 30% compared to existing open-source PRMs. In addition, we provide a\nthorough analysis and case study on the PRM's performance, transferability, and\ngeneralization capabilities.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "17 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.13943v1",
    "published_date": "2025-02-19 18:35:55 UTC",
    "updated_date": "2025-02-19 18:35:55 UTC"
  },
  {
    "arxiv_id": "2502.13935v1",
    "title": "Continually Learning Structured Visual Representations via Network Refinement with Rerelation",
    "authors": [
      "Zeki Doruk Erden",
      "Boi Faltings"
    ],
    "abstract": "Current machine learning paradigm relies on continuous representations like\nneural networks, which iteratively adjust parameters to approximate outcomes\nrather than directly learning the structure of problem. This spreads\ninformation across the network, causing issues like information loss and\nincomprehensibility Building on prior work in environment dynamics modeling, we\npropose a method that learns visual space in a structured, continual manner.\nOur approach refines networks to capture the core structure of objects while\nrepresenting significant subvariants in structure efficiently. We demonstrate\nthis with 2D shape detection, showing incremental learning on MNIST without\noverwriting knowledge and creating compact, comprehensible representations.\nThese results offer a promising step toward a transparent, continually learning\nalternative to traditional neural networks for visual processing.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.13935v1",
    "published_date": "2025-02-19 18:18:27 UTC",
    "updated_date": "2025-02-19 18:18:27 UTC"
  },
  {
    "arxiv_id": "2502.14924v1",
    "title": "A Tale of Two Structures: Do LLMs Capture the Fractal Complexity of Language?",
    "authors": [
      "Ibrahim Alabdulmohsin",
      "Andreas Steiner"
    ],
    "abstract": "Language exhibits a fractal structure in its information-theoretic complexity\n(i.e. bits per token), with self-similarity across scales and long-range\ndependence (LRD). In this work, we investigate whether large language models\n(LLMs) can replicate such fractal characteristics and identify conditions-such\nas temperature setting and prompting method-under which they may fail.\nMoreover, we find that the fractal parameters observed in natural language are\ncontained within a narrow range, whereas those of LLMs' output vary widely,\nsuggesting that fractal parameters might prove helpful in detecting a\nnon-trivial portion of LLM-generated texts. Notably, these findings, and many\nothers reported in this work, are robust to the choice of the architecture;\ne.g. Gemini 1.0 Pro, Mistral-7B and Gemma-2B. We also release a dataset\ncomprising of over 240,000 articles generated by various LLMs (both pretrained\nand instruction-tuned) with different decoding temperatures and prompting\nmethods, along with their corresponding human-generated texts. We hope that\nthis work highlights the complex interplay between fractal properties,\nprompting, and statistical mimicry in LLMs, offering insights for generating,\nevaluating and detecting synthetic texts.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.14924v1",
    "published_date": "2025-02-19 18:15:57 UTC",
    "updated_date": "2025-02-19 18:15:57 UTC"
  },
  {
    "arxiv_id": "2502.14923v1",
    "title": "AI Thinking as a Meaning-Centered Framework: Reimagining Language Technologies Through Community Agency",
    "authors": [
      "Jose F Quesada"
    ],
    "abstract": "While language technologies have advanced significantly, current approaches\nfail to address the complex sociocultural dimensions of linguistic\npreservation. AI Thinking proposes a meaning-centered framework that would\ntransform technological development from creating tools FOR communities to\nco-creating solutions WITH them. This approach recognizes that meaningful\nsolutions emerge through the interplay of cultural understanding, community\nagency, and technological innovation. The proposal articulates a holistic\nmethodology and a five-layer technological ecosystem where communities maintain\ncontrol over their linguistic and cultural knowledge representation. This\nsystematic integration of community needs, cultural preservation, and advanced\ncapabilities could revolutionize how we approach linguistic diversity\npreservation in the digital age.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "LT4All 2025. Language Technologies for All - 2025. Advancing Humanism\n  through Language Technologies. Paris (FR), UNESCO Headquarters, 24-26\n  February 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.14923v1",
    "published_date": "2025-02-19 18:09:24 UTC",
    "updated_date": "2025-02-19 18:09:24 UTC"
  },
  {
    "arxiv_id": "2502.14019v1",
    "title": "Dehumanizing Machines: Mitigating Anthropomorphic Behaviors in Text Generation Systems",
    "authors": [
      "Myra Cheng",
      "Su Lin Blodgett",
      "Alicia DeVrio",
      "Lisa Egede",
      "Alexandra Olteanu"
    ],
    "abstract": "As text generation systems' outputs are increasingly anthropomorphic --\nperceived as human-like -- scholars have also raised increasing concerns about\nhow such outputs can lead to harmful outcomes, such as users over-relying or\ndeveloping emotional dependence on these systems. How to intervene on such\nsystem outputs to mitigate anthropomorphic behaviors and their attendant\nharmful outcomes, however, remains understudied. With this work, we aim to\nprovide empirical and theoretical grounding for developing such interventions.\nTo do so, we compile an inventory of interventions grounded both in prior\nliterature and a crowdsourced study where participants edited system outputs to\nmake them less human-like. Drawing on this inventory, we also develop a\nconceptual framework to help characterize the landscape of possible\ninterventions, articulate distinctions between different types of\ninterventions, and provide a theoretical basis for evaluating the effectiveness\nof different interventions.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.14019v1",
    "published_date": "2025-02-19 18:06:37 UTC",
    "updated_date": "2025-02-19 18:06:37 UTC"
  },
  {
    "arxiv_id": "2502.17489v1",
    "title": "Using Graph Convolutional Networks to Address fMRI Small Data Problems",
    "authors": [
      "Thomas Screven",
      "Andras Necz",
      "Jason Smucny",
      "Ian Davidson"
    ],
    "abstract": "Although great advances in the analysis of neuroimaging data have been made,\na major challenge is a lack of training data. This is less problematic in tasks\nsuch as diagnosis, where much data exists, but particularly prevalent in harder\nproblems such as predicting treatment responses (prognosis), where data is\nfocused and hence limited. Here, we address the learning from small data\nproblems for medical imaging using graph neural networks. This is particularly\nchallenging as the information about the patients is themselves graphs (regions\nof interest connectivity graphs). We show how a spectral representation of the\nconnectivity data allows for efficient propagation that can yield approximately\n12\\% improvement over traditional deep learning methods using the exact same\ndata. We show that our method's superior performance is due to a data smoothing\nresult that can be measured by closing the number of triangle inequalities and\nthereby satisfying transitivity.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "8 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.17489v1",
    "published_date": "2025-02-19 18:05:46 UTC",
    "updated_date": "2025-02-19 18:05:46 UTC"
  },
  {
    "arxiv_id": "2502.13928v1",
    "title": "Symmetrical Visual Contrastive Optimization: Aligning Vision-Language Models with Minimal Contrastive Images",
    "authors": [
      "Shengguang Wu",
      "Fan-Yun Sun",
      "Kaiyue Wen",
      "Nick Haber"
    ],
    "abstract": "Recent studies have shown that Large Vision-Language Models (VLMs) tend to\nneglect image content and over-rely on language-model priors, resulting in\nerrors in visually grounded tasks and hallucinations. We hypothesize that this\nissue arises because existing VLMs are not explicitly trained to generate texts\nthat are accurately grounded in fine-grained image details. To enhance visual\nfeedback during VLM training, we propose S-VCO (Symmetrical Visual Contrastive\nOptimization), a novel finetuning objective that steers the model toward\ncapturing important visual details and aligning them with corresponding text\ntokens. To further facilitate this detailed alignment, we introduce MVC, a\npaired image-text dataset built by automatically filtering and augmenting\nvisual counterfactual data to challenge the model with hard contrastive cases\ninvolving Minimal Visual Contrasts. Experiments show that our method\nconsistently improves VLM performance across diverse benchmarks covering\nvarious abilities and domains, achieving up to a 22% reduction in\nhallucinations, and significant gains in vision-centric and general tasks.\nNotably, these improvements become increasingly pronounced in benchmarks with\nhigher visual dependency. In short, S-VCO offers a significant enhancement of\nVLM's visually-dependent task performance while retaining or even improving the\nmodel's general abilities. We opensource our code at https://s-vco.github.io/",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Project Website: https://s-vco.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2502.13928v1",
    "published_date": "2025-02-19 18:05:42 UTC",
    "updated_date": "2025-02-19 18:05:42 UTC"
  },
  {
    "arxiv_id": "2502.13913v1",
    "title": "How Do LLMs Perform Two-Hop Reasoning in Context?",
    "authors": [
      "Tianyu Guo",
      "Hanlin Zhu",
      "Ruiqi Zhang",
      "Jiantao Jiao",
      "Song Mei",
      "Michael I. Jordan",
      "Stuart Russell"
    ],
    "abstract": "\"Socrates is human. All humans are mortal. Therefore, Socrates is mortal.\"\nThis classical example demonstrates two-hop reasoning, where a conclusion\nlogically follows from two connected premises. While transformer-based Large\nLanguage Models (LLMs) can make two-hop reasoning, they tend to collapse to\nrandom guessing when faced with distracting premises. To understand the\nunderlying mechanism, we train a three-layer transformer on synthetic two-hop\nreasoning tasks. The training dynamics show two stages: a slow learning phase,\nwhere the 3-layer transformer performs random guessing like LLMs, followed by\nan abrupt phase transitions, where the 3-layer transformer suddenly reaches\n$100%$ accuracy. Through reverse engineering, we explain the inner mechanisms\nfor how models learn to randomly guess between distractions initially, and how\nthey learn to ignore distractions eventually. We further propose a\nthree-parameter model that supports the causal claims for the mechanisms to the\ntraining dynamics of the transformer. Finally, experiments on LLMs suggest that\nthe discovered mechanisms generalize across scales. Our methodologies provide\nnew perspectives for scientific understandings of LLMs and our findings provide\nnew insights into how reasoning emerges during training.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.13913v1",
    "published_date": "2025-02-19 17:46:30 UTC",
    "updated_date": "2025-02-19 17:46:30 UTC"
  },
  {
    "arxiv_id": "2502.13909v3",
    "title": "Lost in Sequence: Do Large Language Models Understand Sequential Recommendation?",
    "authors": [
      "Sein Kim",
      "Hongseok Kang",
      "Kibum Kim",
      "Jiwan Kim",
      "Donghyun Kim",
      "Minchul Yang",
      "Kwangjin Oh",
      "Julian McAuley",
      "Chanyoung Park"
    ],
    "abstract": "Large Language Models (LLMs) have recently emerged as promising tools for\nrecommendation thanks to their advanced textual understanding ability and\ncontext-awareness. Despite the current practice of training and evaluating\nLLM-based recommendation (LLM4Rec) models under a sequential recommendation\nscenario, we found that whether these models understand the sequential\ninformation inherent in users' item interaction sequences has been largely\noverlooked. In this paper, we first demonstrate through a series of experiments\nthat existing LLM4Rec models do not fully capture sequential information both\nduring training and inference. Then, we propose a simple yet effective\nLLM-based sequential recommender, called LLM-SRec, a method that enhances the\nintegration of sequential information into LLMs by distilling the user\nrepresentations extracted from a pre-trained CF-SRec model into LLMs. Our\nextensive experiments show that LLM-SRec enhances LLMs' ability to understand\nusers' item interaction sequences, ultimately leading to improved\nrecommendation performance. Furthermore, unlike existing LLM4Rec models that\nrequire fine-tuning of LLMs, LLM-SRec achieves state-of-the-art performance by\ntraining only a few lightweight MLPs, highlighting its practicality in\nreal-world applications. Our code is available at\nhttps://github.com/Sein-Kim/LLM-SRec.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.13909v3",
    "published_date": "2025-02-19 17:41:09 UTC",
    "updated_date": "2025-04-02 17:42:03 UTC"
  },
  {
    "arxiv_id": "2502.13905v1",
    "title": "Partially Observable Gaussian Process Network and Doubly Stochastic Variational Inference",
    "authors": [
      "Saksham Kiroriwal",
      "Julius Pfrommer",
      "Jürgen Beyerer"
    ],
    "abstract": "To reduce the curse of dimensionality for Gaussian processes (GP), they can\nbe decomposed into a Gaussian Process Network (GPN) of coupled subprocesses\nwith lower dimensionality. In some cases, intermediate observations are\navailable within the GPN. However, intermediate observations are often\nindirect, noisy, and incomplete in most real-world systems. This work\nintroduces the Partially Observable Gaussian Process Network (POGPN) to model\nreal-world process networks. We model a joint distribution of latent functions\nof subprocesses and make inferences using observations from all subprocesses.\nPOGPN incorporates observation lenses (observation likelihoods) into the\nwell-established inference method of deep Gaussian processes. We also introduce\ntwo training methods for POPGN to make inferences on the whole network using\nnode observations. The application to benchmark problems demonstrates how\nincorporating partial observations during training and inference can improve\nthe predictive performance of the overall network, offering a promising outlook\nfor its practical application.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "8 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.13905v1",
    "published_date": "2025-02-19 17:39:46 UTC",
    "updated_date": "2025-02-19 17:39:46 UTC"
  },
  {
    "arxiv_id": "2502.14922v1",
    "title": "SIFT: Grounding LLM Reasoning in Contexts via Stickers",
    "authors": [
      "Zihao Zeng",
      "Xuyao Huang",
      "Boxiu Li",
      "Zhijie Deng"
    ],
    "abstract": "This paper identifies the misinterpretation of the context can be a\nsignificant issue during the reasoning process of large language models,\nspanning from smaller models like Llama3.2-3B-Instruct to cutting-edge ones\nlike DeepSeek-R1. For example, in the phrase \"10 dollars per kilo,\" LLMs might\nnot recognize that \"per\" means \"for each,\" leading to calculation errors. We\nintroduce a novel, post-training approach called **Stick to the Facts (SIFT)**\nto tackle this. SIFT leverages increasing inference-time compute to ground LLM\nreasoning in contexts. At the core of SIFT lies the *Sticker*, which is\ngenerated by the model itself to explicitly emphasize the key information\nwithin the context. Given the curated Sticker, SIFT generates two predictions\n-- one from the original query and one from the query augmented with the\nSticker. If they differ, the Sticker is sequentially refined via *forward*\noptimization (to better align the extracted facts with the query) and *inverse*\ngeneration (to conform with the model's inherent tendencies) for more faithful\nreasoning outcomes. Studies across diverse models (from 3B to 100B+) and\nbenchmarks (e.g., GSM8K, MATH-500) reveal consistent performance improvements.\nNotably, SIFT improves the pass@1 accuracy of DeepSeek-R1 on AIME2024 from\n78.33% to **85.67**%, establishing a new state-of-the-art in the open-source\ncommunity. The code is available at https://github.com/zhijie-group/SIFT.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.14922v1",
    "published_date": "2025-02-19 17:38:46 UTC",
    "updated_date": "2025-02-19 17:38:46 UTC"
  },
  {
    "arxiv_id": "2502.13897v1",
    "title": "DataSciBench: An LLM Agent Benchmark for Data Science",
    "authors": [
      "Dan Zhang",
      "Sining Zhoubian",
      "Min Cai",
      "Fengzu Li",
      "Lekang Yang",
      "Wei Wang",
      "Tianjiao Dong",
      "Ziniu Hu",
      "Jie Tang",
      "Yisong Yue"
    ],
    "abstract": "This paper presents DataSciBench, a comprehensive benchmark for evaluating\nLarge Language Model (LLM) capabilities in data science. Recent related\nbenchmarks have primarily focused on single tasks, easily obtainable ground\ntruth, and straightforward evaluation metrics, which limits the scope of tasks\nthat can be evaluated. In contrast, DataSciBench is constructed based on a more\ncomprehensive and curated collection of natural and challenging prompts for\nuncertain ground truth and evaluation metrics. We develop a semi-automated\npipeline for generating ground truth (GT) and validating evaluation metrics.\nThis pipeline utilizes and implements an LLM-based self-consistency and human\nverification strategy to produce accurate GT by leveraging collected prompts,\npredefined task types, and aggregate functions (metrics). Furthermore, we\npropose an innovative Task - Function - Code (TFC) framework to assess each\ncode execution outcome based on precisely defined metrics and programmatic\nrules. Our experimental framework involves testing 6 API-based models, 8\nopen-source general models, and 9 open-source code generation models using the\ndiverse set of prompts we have gathered. This approach aims to provide a more\ncomprehensive and rigorous evaluation of LLMs in data science, revealing their\nstrengths and weaknesses. Experimental results demonstrate that API-based\nmodels outperform open-sourced models on all metrics and\nDeepseek-Coder-33B-Instruct achieves the highest score among open-sourced\nmodels. We release all code and data at https://github.com/THUDM/DataSciBench.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "40 pages, 7 figures, 6 tables",
    "pdf_url": "http://arxiv.org/pdf/2502.13897v1",
    "published_date": "2025-02-19 17:31:51 UTC",
    "updated_date": "2025-02-19 17:31:51 UTC"
  },
  {
    "arxiv_id": "2502.15814v2",
    "title": "Slamming: Training a Speech Language Model on One GPU in a Day",
    "authors": [
      "Gallil Maimon",
      "Avishai Elmakies",
      "Yossi Adi"
    ],
    "abstract": "We introduce Slam, a recipe for training high-quality Speech Language Models\n(SLMs) on a single academic GPU in 24 hours. We do so through empirical\nanalysis of model initialisation and architecture, synthetic training data,\npreference optimisation with synthetic data and tweaking all other components.\nWe empirically demonstrate that this training recipe also scales well with more\ncompute getting results on par with leading SLMs in a fraction of the compute\ncost. We hope these insights will make SLM training and research more\naccessible. In the context of SLM scaling laws, our results far outperform\npredicted compute optimal performance, giving an optimistic view to SLM\nfeasibility. See code, data, models, samples at -\nhttps://pages.cs.huji.ac.il/adiyoss-lab/slamming .",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.LG",
    "comment": "ACL 2025 (Findings)",
    "pdf_url": "http://arxiv.org/pdf/2502.15814v2",
    "published_date": "2025-02-19 17:21:15 UTC",
    "updated_date": "2025-05-22 16:55:59 UTC"
  },
  {
    "arxiv_id": "2502.13881v3",
    "title": "PSCon: Product Search Through Conversations",
    "authors": [
      "Jie Zou",
      "Mohammad Aliannejadi",
      "Evangelos Kanoulas",
      "Shuxi Han",
      "Heli Ma",
      "Zheng Wang",
      "Yang Yang",
      "Heng Tao Shen"
    ],
    "abstract": "Conversational Product Search ( CPS ) systems interact with users via natural\nlanguage to offer personalized and context-aware product lists. However, most\nexisting research on CPS is limited to simulated conversations, due to the lack\nof a real CPS dataset driven by human-like language. Moreover, existing\nconversational datasets for e-commerce are constructed for a particular market\nor a particular language and thus can not support cross-market and\nmulti-lingual usage. In this paper, we propose a CPS data collection protocol\nand create a new CPS dataset, called PSCon, which assists product search\nthrough conversations with human-like language. The dataset is collected by a\ncoached human-human data collection protocol and is available for dual markets\nand two languages. By formulating the task of CPS, the dataset allows for\ncomprehensive and in-depth research on six subtasks: user intent detection,\nkeyword extraction, system action prediction, question selection, item ranking,\nand response generation. Moreover, we present a concise analysis of the dataset\nand propose a benchmark model on the proposed CPS dataset. Our proposed dataset\nand model will be helpful for facilitating future research on CPS.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "11 pages. Accepted by SIGIR 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.13881v3",
    "published_date": "2025-02-19 17:05:42 UTC",
    "updated_date": "2025-04-27 11:19:39 UTC"
  },
  {
    "arxiv_id": "2502.13875v1",
    "title": "MEX: Memory-efficient Approach to Referring Multi-Object Tracking",
    "authors": [
      "Huu-Thien Tran",
      "Phuoc-Sang Pham",
      "Thai-Son Tran",
      "Khoa Luu"
    ],
    "abstract": "Referring Multi-Object Tracking (RMOT) is a relatively new concept that has\nrapidly gained traction as a promising research direction at the intersection\nof computer vision and natural language processing. Unlike traditional\nmulti-object tracking, RMOT identifies and tracks objects and incorporates\ntextual descriptions for object class names, making the approach more\nintuitive. Various techniques have been proposed to address this challenging\nproblem; however, most require the training of the entire network due to their\nend-to-end nature. Among these methods, iKUN has emerged as a particularly\npromising solution. Therefore, we further explore its pipeline and enhance its\nperformance. In this paper, we introduce a practical module dubbed\nMemory-Efficient Cross-modality -- MEX. This memory-efficient technique can be\ndirectly applied to off-the-shelf trackers like iKUN, resulting in significant\narchitectural improvements. Our method proves effective during inference on a\nsingle GPU with 4 GB of memory. Among the various benchmarks, the Refer-KITTI\ndataset, which offers diverse autonomous driving scenes with relevant language\nexpressions, is particularly useful for studying this problem. Empirically, our\nmethod demonstrates effectiveness and efficiency regarding HOTA tracking\nscores, substantially improving memory allocation and processing speed.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "6 pages, 6 figures, 2024 International Conference on Advanced\n  Technologies for Communications (ATC), Signal Processing Track",
    "pdf_url": "http://arxiv.org/pdf/2502.13875v1",
    "published_date": "2025-02-19 16:58:42 UTC",
    "updated_date": "2025-02-19 16:58:42 UTC"
  },
  {
    "arxiv_id": "2502.13873v2",
    "title": "NVR: Vector Runahead on NPUs for Sparse Memory Access",
    "authors": [
      "Hui Wang",
      "Zhengpeng Zhao",
      "Jing Wang",
      "Yushu Du",
      "Yuan Cheng",
      "Bing Guo",
      "He Xiao",
      "Chenhao Ma",
      "Xiaomeng Han",
      "Dean You",
      "Jiapeng Guan",
      "Ran Wei",
      "Dawei Yang",
      "Zhe Jiang"
    ],
    "abstract": "Deep Neural Networks are increasingly leveraging sparsity to reduce the\nscaling up of model parameter size. However, reducing wall-clock time through\nsparsity and pruning remains challenging due to irregular memory access\npatterns, leading to frequent cache misses. In this paper, we present NPU\nVector Runahead (NVR), a prefetching mechanism tailored for NPUs to address\ncache miss problems in sparse DNN workloads. Rather than optimising memory\npatterns with high overhead and poor portability, NVR adapts runahead execution\nto the unique architecture of NPUs. NVR provides a general micro-architectural\nsolution for sparse DNN workloads without requiring compiler or algorithmic\nsupport, operating as a decoupled, speculative, lightweight hardware sub-thread\nalongside the NPU, with minimal hardware overhead (under 5%). NVR achieves an\naverage 90% reduction in cache misses compared to SOTA prefetching in\ngeneral-purpose processors, delivering 4x average speedup on sparse workloads\nversus NPUs without prefetching. Moreover, we investigate the advantages of\nincorporating a small cache (16KB) into the NPU combined with NVR. Our\nevaluation shows that expanding this modest cache delivers 5x higher\nperformance benefits than increasing the L2 cache size by the same amount.",
    "categories": [
      "cs.AR",
      "cs.AI"
    ],
    "primary_category": "cs.AR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.13873v2",
    "published_date": "2025-02-19 16:54:58 UTC",
    "updated_date": "2025-03-17 20:31:46 UTC"
  },
  {
    "arxiv_id": "2502.13870v1",
    "title": "SPEX: Scaling Feature Interaction Explanations for LLMs",
    "authors": [
      "Justin Singh Kang",
      "Landon Butler",
      "Abhineet Agarwal",
      "Yigit Efe Erginbas",
      "Ramtin Pedarsani",
      "Kannan Ramchandran",
      "Bin Yu"
    ],
    "abstract": "Large language models (LLMs) have revolutionized machine learning due to\ntheir ability to capture complex interactions between input features. Popular\npost-hoc explanation methods like SHAP provide marginal feature attributions,\nwhile their extensions to interaction importances only scale to small input\nlengths ($\\approx 20$). We propose Spectral Explainer (SPEX), a model-agnostic\ninteraction attribution algorithm that efficiently scales to large input\nlengths ($\\approx 1000)$. SPEX exploits underlying natural sparsity among\ninteractions -- common in real-world data -- and applies a sparse Fourier\ntransform using a channel decoding algorithm to efficiently identify important\ninteractions. We perform experiments across three difficult long-context\ndatasets that require LLMs to utilize interactions between inputs to complete\nthe task. For large inputs, SPEX outperforms marginal attribution methods by up\nto 20% in terms of faithfully reconstructing LLM outputs. Further, SPEX\nsuccessfully identifies key features and interactions that strongly influence\nmodel output. For one of our datasets, HotpotQA, SPEX provides interactions\nthat align with human annotations. Finally, we use our model-agnostic approach\nto generate explanations to demonstrate abstract reasoning in closed-source\nLLMs (GPT-4o mini) and compositional reasoning in vision-language models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.13870v1",
    "published_date": "2025-02-19 16:49:55 UTC",
    "updated_date": "2025-02-19 16:49:55 UTC"
  },
  {
    "arxiv_id": "2502.13847v1",
    "title": "DH-RAG: A Dynamic Historical Context-Powered Retrieval-Augmented Generation Method for Multi-Turn Dialogue",
    "authors": [
      "Feiyuan Zhang",
      "Dezhi Zhu",
      "James Ming",
      "Yilun Jin",
      "Di Chai",
      "Liu Yang",
      "Han Tian",
      "Zhaoxin Fan",
      "Kai Chen"
    ],
    "abstract": "Retrieval-Augmented Generation (RAG) systems have shown substantial benefits\nin applications such as question answering and multi-turn dialogue\n\\citep{lewis2020retrieval}. However, traditional RAG methods, while leveraging\nstatic knowledge bases, often overlook the potential of dynamic historical\ninformation in ongoing conversations. To bridge this gap, we introduce DH-RAG,\na Dynamic Historical Context-Powered Retrieval-Augmented Generation Method for\nMulti-Turn Dialogue. DH-RAG is inspired by human cognitive processes that\nutilize both long-term memory and immediate historical context in\nconversational responses \\citep{stafford1987conversational}. DH-RAG is\nstructured around two principal components: a History-Learning based Query\nReconstruction Module, designed to generate effective queries by synthesizing\ncurrent and prior interactions, and a Dynamic History Information Updating\nModule, which continually refreshes historical context throughout the dialogue.\nThe center of DH-RAG is a Dynamic Historical Information database, which is\nfurther refined by three strategies within the Query Reconstruction Module:\nHistorical Query Clustering, Hierarchical Matching, and Chain of Thought\nTracking. Experimental evaluations show that DH-RAG significantly surpasses\nconventional models on several benchmarks, enhancing response relevance,\ncoherence, and dialogue quality.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.13847v1",
    "published_date": "2025-02-19 16:10:43 UTC",
    "updated_date": "2025-02-19 16:10:43 UTC"
  },
  {
    "arxiv_id": "2502.13845v2",
    "title": "Improving LLM-powered Recommendations with Personalized Information",
    "authors": [
      "Jiahao Liu",
      "Xueshuo Yan",
      "Dongsheng Li",
      "Guangping Zhang",
      "Hansu Gu",
      "Peng Zhang",
      "Tun Lu",
      "Li Shang",
      "Ning Gu"
    ],
    "abstract": "Due to the lack of explicit reasoning modeling, existing LLM-powered\nrecommendations fail to leverage LLMs' reasoning capabilities effectively. In\nthis paper, we propose a pipeline called CoT-Rec, which integrates two key\nChain-of-Thought (CoT) processes -- user preference analysis and item\nperception analysis -- into LLM-powered recommendations, thereby enhancing the\nutilization of LLMs' reasoning abilities. CoT-Rec consists of two stages: (1)\npersonalized information extraction, where user preferences and item perception\nare extracted, and (2) personalized information utilization, where this\ninformation is incorporated into the LLM-powered recommendation process.\nExperimental results demonstrate that CoT-Rec shows potential for improving\nLLM-powered recommendations. The implementation is publicly available at\nhttps://github.com/jhliu0807/CoT-Rec.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "Accepted by SIGIR 2025, 7 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.13845v2",
    "published_date": "2025-02-19 16:08:17 UTC",
    "updated_date": "2025-04-18 07:45:55 UTC"
  },
  {
    "arxiv_id": "2502.13843v2",
    "title": "AgentCF++: Memory-enhanced LLM-based Agents for Popularity-aware Cross-domain Recommendations",
    "authors": [
      "Jiahao Liu",
      "Shengkang Gu",
      "Dongsheng Li",
      "Guangping Zhang",
      "Mingzhe Han",
      "Hansu Gu",
      "Peng Zhang",
      "Tun Lu",
      "Li Shang",
      "Ning Gu"
    ],
    "abstract": "LLM-based user agents, which simulate user interaction behavior, are emerging\nas a promising approach to enhancing recommender systems. In real-world\nscenarios, users' interactions often exhibit cross-domain characteristics and\nare influenced by others. However, the memory design in current methods causes\nuser agents to introduce significant irrelevant information during\ndecision-making in cross-domain scenarios and makes them unable to recognize\nthe influence of other users' interactions, such as popularity factors. To\ntackle this issue, we propose a dual-layer memory architecture combined with a\ntwo-step fusion mechanism. This design avoids irrelevant information during\ndecision-making while ensuring effective integration of cross-domain\npreferences. We also introduce the concepts of interest groups and group-shared\nmemory to better capture the influence of popularity factors on users with\nsimilar interests. Comprehensive experiments validate the effectiveness of\nAgentCF++. Our code is available at https://github.com/jhliu0807/AgentCF-plus.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "Accepted by SIGIR 2025, 6 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.13843v2",
    "published_date": "2025-02-19 16:02:59 UTC",
    "updated_date": "2025-04-18 07:48:48 UTC"
  },
  {
    "arxiv_id": "2502.13840v2",
    "title": "Unbiased Collaborative Filtering with Fair Sampling",
    "authors": [
      "Jiahao Liu",
      "Dongsheng Li",
      "Hansu Gu",
      "Peng Zhang",
      "Tun Lu",
      "Li Shang",
      "Ning Gu"
    ],
    "abstract": "Recommender systems leverage extensive user interaction data to model\npreferences; however, directly modeling these data may introduce biases that\ndisproportionately favor popular items. In this paper, we demonstrate that\npopularity bias arises from the influence of propensity factors during\ntraining. Building on this insight, we propose a fair sampling (FS) method that\nensures each user and each item has an equal likelihood of being selected as\nboth positive and negative instances, thereby mitigating the influence of\npropensity factors. The proposed FS method does not require estimating\npropensity scores, thus avoiding the risk of failing to fully eliminate\npopularity bias caused by estimation inaccuracies. Comprehensive experiments\ndemonstrate that the proposed FS method achieves state-of-the-art performance\nin both point-wise and pair-wise recommendation tasks. The code implementation\nis available at https://github.com/jhliu0807/Fair-Sampling.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "Accept by SIGIR 2025, 5 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.13840v2",
    "published_date": "2025-02-19 15:59:49 UTC",
    "updated_date": "2025-04-18 07:42:28 UTC"
  },
  {
    "arxiv_id": "2503.05737v1",
    "title": "Local Differences, Global Lessons: Insights from Organisation Policies for International Legislation",
    "authors": [
      "Lucie-Aimée Kaffee",
      "Pepa Atanasova",
      "Anna Rogers"
    ],
    "abstract": "The rapid adoption of AI across diverse domains has led to the development of\norganisational guidelines that vary significantly, even within the same sector.\nThis paper examines AI policies in two domains, news organisations and\nuniversities, to understand how bottom-up governance approaches shape AI usage\nand oversight. By analysing these policies, we identify key areas of\nconvergence and divergence in how organisations address risks such as bias,\nprivacy, misinformation, and accountability. We then explore the implications\nof these findings for international AI legislation, particularly the EU AI Act,\nhighlighting gaps where practical policy insights could inform regulatory\nrefinements. Our analysis reveals that organisational policies often address\nissues such as AI literacy, disclosure practices, and environmental impact,\nareas that are underdeveloped in existing international frameworks. We argue\nthat lessons from domain-specific AI policies can contribute to more adaptive\nand effective AI governance at the global level. This study provides actionable\nrecommendations for policymakers seeking to bridge the gap between local AI\npractices and international regulations.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.05737v1",
    "published_date": "2025-02-19 15:59:09 UTC",
    "updated_date": "2025-02-19 15:59:09 UTC"
  },
  {
    "arxiv_id": "2502.13836v1",
    "title": "Quantifying Memorization and Retriever Performance in Retrieval-Augmented Vision-Language Models",
    "authors": [
      "Peter Carragher",
      "Abhinand Jha",
      "R Raghav",
      "Kathleen M. Carley"
    ],
    "abstract": "Large Language Models (LLMs) demonstrate remarkable capabilities in question\nanswering (QA), but metrics for assessing their reliance on memorization versus\nretrieval remain underdeveloped. Moreover, while finetuned models are\nstate-of-the-art on closed-domain tasks, general-purpose models like GPT-4o\nexhibit strong zero-shot performance. This raises questions about the\ntrade-offs between memorization, generalization, and retrieval. In this work,\nwe analyze the extent to which multimodal retrieval-augmented VLMs memorize\ntraining data compared to baseline VLMs. Using the WebQA benchmark, we contrast\nfinetuned models with baseline VLMs on multihop retrieval and question\nanswering, examining the impact of finetuning on data memorization. To quantify\nmemorization in end-to-end retrieval and QA systems, we propose several proxy\nmetrics by investigating instances where QA succeeds despite retrieval failing.\nOur results reveal the extent to which finetuned models rely on memorization.\nIn contrast, retrieval-augmented VLMs have lower memorization scores, at the\ncost of accuracy (72% vs 52% on WebQA test set). As such, our measures pose a\nchallenge for future work to reconcile memorization and generalization in both\nOpen-Domain QA and joint Retrieval-QA tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.13836v1",
    "published_date": "2025-02-19 15:58:09 UTC",
    "updated_date": "2025-02-19 15:58:09 UTC"
  },
  {
    "arxiv_id": "2502.13834v3",
    "title": "Proving Olympiad Inequalities by Synergizing LLMs and Symbolic Reasoning",
    "authors": [
      "Zenan Li",
      "Zhaoyu Li",
      "Wen Tang",
      "Xian Zhang",
      "Yuan Yao",
      "Xujie Si",
      "Fan Yang",
      "Kaiyu Yang",
      "Xiaoxing Ma"
    ],
    "abstract": "Large language models (LLMs) can prove mathematical theorems formally by\ngenerating proof steps (\\textit{a.k.a.} tactics) within a proof system.\nHowever, the space of possible tactics is vast and complex, while the available\ntraining data for formal proofs is limited, posing a significant challenge to\nLLM-based tactic generation. To address this, we introduce a neuro-symbolic\ntactic generator that synergizes the mathematical intuition learned by LLMs\nwith domain-specific insights encoded by symbolic methods. The key aspect of\nthis integration is identifying which parts of mathematical reasoning are best\nsuited to LLMs and which to symbolic methods. While the high-level idea of\nneuro-symbolic integration is broadly applicable to various mathematical\nproblems, in this paper, we focus specifically on Olympiad inequalities\n(Figure~1). We analyze how humans solve these problems and distill the\ntechniques into two types of tactics: (1) scaling, handled by symbolic methods,\nand (2) rewriting, handled by LLMs. In addition, we combine symbolic tools with\nLLMs to prune and rank the proof goals for efficient proof search. We evaluate\nour framework on 161 challenging inequalities from multiple mathematics\ncompetitions, achieving state-of-the-art performance and significantly\noutperforming existing LLM and symbolic approaches without requiring additional\ntraining data.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Published as a conference paper at ICLR 2025. Code is available at\n  https://github.com/Lizn-zn/NeqLIPS/",
    "pdf_url": "http://arxiv.org/pdf/2502.13834v3",
    "published_date": "2025-02-19 15:54:21 UTC",
    "updated_date": "2025-02-27 04:24:25 UTC"
  },
  {
    "arxiv_id": "2503.16452v1",
    "title": "Towards Biomarker Discovery for Early Cerebral Palsy Detection: Evaluating Explanations Through Kinematic Perturbations",
    "authors": [
      "Kimji N. Pellano",
      "Inga Strümke",
      "Daniel Groos",
      "Lars Adde",
      "Pål Haugen",
      "Espen Alexander F. Ihlen"
    ],
    "abstract": "Cerebral Palsy (CP) is a prevalent motor disability in children, for which\nearly detection can significantly improve treatment outcomes. While\nskeleton-based Graph Convolutional Network (GCN) models have shown promise in\nautomatically predicting CP risk from infant videos, their \"black-box\" nature\nraises concerns about clinical explainability. To address this, we introduce a\nperturbation framework tailored for infant movement features and use it to\ncompare two explainable AI (XAI) methods: Class Activation Mapping (CAM) and\nGradient-weighted Class Activation Mapping (Grad-CAM). First, we identify\nsignificant and non-significant body keypoints in very low- and very high-risk\ninfant video snippets based on the XAI attribution scores. We then conduct\ntargeted velocity and angular perturbations, both individually and in\ncombination, on these keypoints to assess how the GCN model's risk predictions\nchange. Our results indicate that velocity-driven features of the arms, hips,\nand legs have a dominant influence on CP risk predictions, while angular\nperturbations have a more modest impact. Furthermore, CAM and Grad-CAM show\npartial convergence in their explanations for both low- and high-risk CP\ngroups. Our findings demonstrate the use of XAI-driven movement analysis for\nearly CP prediction and offer insights into potential movement-based biomarker\ndiscovery that warrant further clinical validation.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "19 pages, 14 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.16452v1",
    "published_date": "2025-02-19 15:54:10 UTC",
    "updated_date": "2025-02-19 15:54:10 UTC"
  },
  {
    "arxiv_id": "2502.13820v2",
    "title": "Scoring Verifiers: Evaluating Synthetic Verification for Code and Reasoning",
    "authors": [
      "Aleksander Ficek",
      "Somshubra Majumdar",
      "Vahid Noroozi",
      "Boris Ginsburg"
    ],
    "abstract": "Synthetic verification techniques such as generating test cases and reward\nmodelling are common ways to enhance the coding capabilities of large language\nmodels (LLM) beyond predefined tests. Additionally, code verification has\nrecently found great success as a critical component in improving reasoning\ncapability of LLMs via reinforcement learning. In this paper, we propose a an\napproach which can transform existing coding benchmarks into scoring and\nranking datasets to evaluate the effectiveness of synthetic verifiers. We also\npropose multiple metrics to measure different aspects of the synthetic\nverifiers with the proposed benchmarks. By employing the proposed approach, we\nrelease four new benchmarks (HE-R, HE-R+, MBPP-R, and MBPP-R+), and analyzed\nsynthetic verification methods with standard, reasoning-based, and reward-based\nLLMs. Our experiments show that reasoning can significantly improve test case\ngeneration and that scaling the number of test cases enhances the verification\naccuracy.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.SE"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.13820v2",
    "published_date": "2025-02-19 15:32:11 UTC",
    "updated_date": "2025-04-01 18:19:14 UTC"
  },
  {
    "arxiv_id": "2502.14920v1",
    "title": "Display Field-Of-View Agnostic Robust CT Kernel Synthesis Using Model-Based Deep Learning",
    "authors": [
      "Hemant Kumar Aggarwal",
      "Antony Jerald",
      "Phaneendra K. Yalavarthy",
      "Rajesh Langoju",
      "Bipul Das"
    ],
    "abstract": "In X-ray computed tomography (CT) imaging, the choice of reconstruction\nkernel is crucial as it significantly impacts the quality of clinical images.\nDifferent kernels influence spatial resolution, image noise, and contrast in\nvarious ways. Clinical applications involving lung imaging often require images\nreconstructed with both soft and sharp kernels. The reconstruction of images\nwith different kernels requires raw sinogram data and storing images for all\nkernels increases processing time and storage requirements. The Display\nField-of-View (DFOV) adds complexity to kernel synthesis, as data acquired at\ndifferent DFOVs exhibit varying levels of sharpness and details. This work\nintroduces an efficient, DFOV-agnostic solution for image-based kernel\nsynthesis using model-based deep learning. The proposed method explicitly\nintegrates CT kernel and DFOV characteristics into the forward model.\nExperimental results on clinical data, along with quantitative analysis of the\nestimated modulation transfer function using wire phantom data, clearly\ndemonstrate the utility of the proposed method in real-time. Additionally, a\ncomparative study with a direct learning network, that lacks forward model\ninformation, shows that the proposed method is more robust to DFOV variations.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "Accepted at IEEE ISBI 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.14920v1",
    "published_date": "2025-02-19 15:29:47 UTC",
    "updated_date": "2025-02-19 15:29:47 UTC"
  },
  {
    "arxiv_id": "2502.13805v2",
    "title": "AnDB: Breaking Boundaries with an AI-Native Database for Universal Semantic Analysis",
    "authors": [
      "Tianqing Wang",
      "Xun Xue",
      "Guoliang Li",
      "Yong Wang"
    ],
    "abstract": "In this demonstration, we present AnDB, an AI-native database that supports\ntraditional OLTP workloads and innovative AI-driven tasks, enabling unified\nsemantic analysis across structured and unstructured data. While structured\ndata analytics is mature, challenges remain in bridging the semantic gap\nbetween user queries and unstructured data. AnDB addresses these issues by\nleveraging cutting-edge AI-native technologies, allowing users to perform\nsemantic queries using intuitive SQL-like statements without requiring AI\nexpertise. This approach eliminates the ambiguity of traditional text-to-SQL\nsystems and provides a seamless end-to-end optimization for analyzing all data\ntypes. AnDB automates query processing by generating multiple execution plans\nand selecting the optimal one through its optimizer, which balances accuracy,\nexecution time, and financial cost based on user policies and internal\noptimizing mechanisms. AnDB future-proofs data management infrastructure,\nempowering users to effectively and efficiently harness the full potential of\nall kinds of data without starting from scratch.",
    "categories": [
      "cs.DB",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.DB",
    "comment": "4 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.13805v2",
    "published_date": "2025-02-19 15:15:59 UTC",
    "updated_date": "2025-03-24 04:22:35 UTC"
  },
  {
    "arxiv_id": "2502.15813v1",
    "title": "Stock Price Prediction Using a Hybrid LSTM-GNN Model: Integrating Time-Series and Graph-Based Analysis",
    "authors": [
      "Meet Satishbhai Sonani",
      "Atta Badii",
      "Armin Moin"
    ],
    "abstract": "This paper presents a novel hybrid model that integrates long-short-term\nmemory (LSTM) networks and Graph Neural Networks (GNNs) to significantly\nenhance the accuracy of stock market predictions. The LSTM component adeptly\ncaptures temporal patterns in stock price data, effectively modeling the time\nseries dynamics of financial markets. Concurrently, the GNN component leverages\nPearson correlation and association analysis to model inter-stock relational\ndata, capturing complex nonlinear polyadic dependencies influencing stock\nprices. The model is trained and evaluated using an expanding window validation\napproach, enabling continuous learning from increasing amounts of data and\nadaptation to evolving market conditions. Extensive experiments conducted on\nhistorical stock data demonstrate that our hybrid LSTM-GNN model achieves a\nmean square error (MSE) of 0.00144, representing a substantial reduction of\n10.6% compared to the MSE of the standalone LSTM model of 0.00161. Furthermore,\nthe hybrid model outperforms traditional and advanced benchmarks, including\nlinear regression, convolutional neural networks (CNN), and dense networks.\nThese compelling results underscore the significant potential of combining\ntemporal and relational data through a hybrid approach, offering a powerful\ntool for real-time trading and financial analysis.",
    "categories": [
      "q-fin.ST",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-fin.ST",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15813v1",
    "published_date": "2025-02-19 15:09:13 UTC",
    "updated_date": "2025-02-19 15:09:13 UTC"
  },
  {
    "arxiv_id": "2502.13794v1",
    "title": "LESA: Learnable LLM Layer Scaling-Up",
    "authors": [
      "Yifei Yang",
      "Zouying Cao",
      "Xinbei Ma",
      "Yao Yao",
      "Libo Qin",
      "Zhi Chen",
      "Hai Zhao"
    ],
    "abstract": "Training Large Language Models (LLMs) from scratch requires immense\ncomputational resources, making it prohibitively expensive. Model scaling-up\noffers a promising solution by leveraging the parameters of smaller models to\ncreate larger ones. However, existing depth scaling-up methods rely on\nempirical heuristic rules for layer duplication, which result in poorer\ninitialization and slower convergence during continual pre-training. We propose\n\\textbf{LESA}, a novel learnable method for depth scaling-up. By concatenating\nparameters from each layer and applying Singular Value Decomposition, we\nuncover latent patterns between layers, suggesting that inter-layer parameters\ncan be learned. LESA uses a neural network to predict the parameters inserted\nbetween adjacent layers, enabling better initialization and faster training.\nExperiments show that LESA outperforms existing baselines, achieving superior\nperformance with less than half the computational cost during continual\npre-training. Extensive analyses demonstrate its effectiveness across different\nmodel sizes and tasks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.13794v1",
    "published_date": "2025-02-19 14:58:48 UTC",
    "updated_date": "2025-02-19 14:58:48 UTC"
  },
  {
    "arxiv_id": "2502.13785v2",
    "title": "Helix-mRNA: A Hybrid Foundation Model For Full Sequence mRNA Therapeutics",
    "authors": [
      "Matthew Wood",
      "Mathieu Klop",
      "Maxime Allard"
    ],
    "abstract": "mRNA-based vaccines have become a major focus in the pharmaceutical industry.\nThe coding sequence as well as the Untranslated Regions (UTRs) of an mRNA can\nstrongly influence translation efficiency, stability, degradation, and other\nfactors that collectively determine a vaccine's effectiveness. However,\noptimizing mRNA sequences for those properties remains a complex challenge.\nExisting deep learning models often focus solely on coding region optimization,\noverlooking the UTRs. We present Helix-mRNA, a structured state-space-based and\nattention hybrid model to address these challenges. In addition to a first\npre-training, a second pre-training stage allows us to specialise the model\nwith high-quality data. We employ single nucleotide tokenization of mRNA\nsequences with codon separation, ensuring prior biological and structural\ninformation from the original mRNA sequence is not lost. Our model, Helix-mRNA,\noutperforms existing methods in analysing both UTRs and coding region\nproperties. It can process sequences 6x longer than current approaches while\nusing only 10% of the parameters of existing foundation models. Its predictive\ncapabilities extend to all mRNA regions. We open-source the model\n(https://github.com/helicalAI/helical) and model weights\n(https://huggingface.co/helical-ai/helix-mRNA).",
    "categories": [
      "q-bio.GN",
      "cs.AI"
    ],
    "primary_category": "q-bio.GN",
    "comment": "8 pages, 3 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2502.13785v2",
    "published_date": "2025-02-19 14:51:41 UTC",
    "updated_date": "2025-03-11 14:21:27 UTC"
  },
  {
    "arxiv_id": "2502.13778v1",
    "title": "Poster: SpiderSim: Multi-Agent Driven Theoretical Cybersecurity Simulation for Industrial Digitalization",
    "authors": [
      "Jiaqi Li",
      "Xizhong Guo",
      "Yang Zhao",
      "Lvyang Zhang",
      "Lidong Zhai"
    ],
    "abstract": "Rapid industrial digitalization has created intricate cybersecurity demands\nthat necessitate effective validation methods. While cyber ranges and\nsimulation platforms are widely deployed, they frequently face limitations in\nscenario diversity and creation efficiency. In this paper, we present\nSpiderSim, a theoretical cybersecurity simulation platform enabling rapid and\nlightweight scenario generation for industrial digitalization security\nresearch. At its core, our platform introduces three key innovations: a\nstructured framework for unified scenario modeling, a multi-agent collaboration\nmechanism for automated generation, and modular atomic security capabilities\nfor flexible scenario composition. Extensive implementation trials across\nmultiple industrial digitalization contexts, including marine ranch monitoring\nsystems, validate our platform's capacity for broad scenario coverage with\nefficient generation processes. Built on solid theoretical foundations and\nreleased as open-source software, SpiderSim facilitates broader research and\ndevelopment in automated security testing for industrial digitalization.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "https://github.com/NRT2024/SpiderSim",
    "pdf_url": "http://arxiv.org/pdf/2502.13778v1",
    "published_date": "2025-02-19 14:42:32 UTC",
    "updated_date": "2025-02-19 14:42:32 UTC"
  },
  {
    "arxiv_id": "2502.13775v1",
    "title": "VITAL: A New Dataset for Benchmarking Pluralistic Alignment in Healthcare",
    "authors": [
      "Anudeex Shetty",
      "Amin Beheshti",
      "Mark Dras",
      "Usman Naseem"
    ],
    "abstract": "Alignment techniques have become central to ensuring that Large Language\nModels (LLMs) generate outputs consistent with human values. However, existing\nalignment paradigms often model an averaged or monolithic preference, failing\nto account for the diversity of perspectives across cultures, demographics, and\ncommunities. This limitation is particularly critical in health-related\nscenarios, where plurality is essential due to the influence of culture,\nreligion, personal values, and conflicting opinions. Despite progress in\npluralistic alignment, no prior work has focused on health, likely due to the\nunavailability of publicly available datasets. To address this gap, we\nintroduce VITAL, a new benchmark dataset comprising 13.1K value-laden\nsituations and 5.4K multiple-choice questions focused on health, designed to\nassess and benchmark pluralistic alignment methodologies. Through extensive\nevaluation of eight LLMs of varying sizes, we demonstrate that existing\npluralistic alignment techniques fall short in effectively accommodating\ndiverse healthcare beliefs, underscoring the need for tailored AI alignment in\nspecific domains. This work highlights the limitations of current approaches\nand lays the groundwork for developing health-specific alignment solutions.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Under review",
    "pdf_url": "http://arxiv.org/pdf/2502.13775v1",
    "published_date": "2025-02-19 14:38:57 UTC",
    "updated_date": "2025-02-19 14:38:57 UTC"
  },
  {
    "arxiv_id": "2502.13769v1",
    "title": "A consensus set for the aggregation of partial rankings: the case of the Optimal Set of Bucket Orders Problem",
    "authors": [
      "Juan A. Aledo",
      "José A. Gámez",
      "Alejandro Rosete"
    ],
    "abstract": "In rank aggregation problems (RAP), the solution is usually a consensus\nranking that generalizes a set of input orderings. There are different variants\nthat differ not only in terms of the type of rankings that are used as input\nand output, but also in terms of the objective function employed to evaluate\nthe quality of the desired output ranking. In contrast, in some machine\nlearning tasks (e.g. subgroup discovery) or multimodal optimization tasks,\nattention is devoted to obtaining several models/results to account for the\ndiversity in the input data or across the search landscape. Thus, in this paper\nwe propose to provide, as the solution to an RAP, a set of rankings to better\nexplain the preferences expressed in the input orderings. We exemplify our\nproposal through the Optimal Bucket Order Problem (OBOP), an RAP which consists\nin finding a single consensus ranking (with ties) that generalizes a set of\ninput rankings codified as a precedence matrix. To address this, we introduce\nthe Optimal Set of Bucket Orders Problem (OSBOP), a generalization of the OBOP\nthat aims to produce not a single ranking as output but a set of consensus\nrankings. Experimental results are presented to illustrate this proposal,\nshowing how, by providing a set of consensus rankings, the fitness of the\nsolution significantly improves with respect to the one of the original OBOP,\nwithout losing comprehensibility.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "26 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.13769v1",
    "published_date": "2025-02-19 14:32:16 UTC",
    "updated_date": "2025-02-19 14:32:16 UTC"
  },
  {
    "arxiv_id": "2502.13767v3",
    "title": "Agentic AI Software Engineers: Programming with Trust",
    "authors": [
      "Abhik Roychoudhury",
      "Corina Pasareanu",
      "Michael Pradel",
      "Baishakhi Ray"
    ],
    "abstract": "Large Language Models (LLMs) have shown surprising proficiency in generating\ncode snippets, promising to automate large parts of software engineering via\nartificial intelligence (AI). We argue that successfully deploying AI software\nengineers requires a level of trust equal to or even greater than the trust\nestablished by human-driven software engineering practices. The recent trend\ntoward LLM agents offers a path toward integrating the power of LLMs to create\nnew code with the power of analysis tools to increase trust in the code. This\nopinion piece comments on whether LLM agents could dominate software\nengineering workflows in the future and whether the focus of programming will\nshift from programming at scale to programming with trust.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "5 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.13767v3",
    "published_date": "2025-02-19 14:28:42 UTC",
    "updated_date": "2025-05-22 10:02:39 UTC"
  },
  {
    "arxiv_id": "2502.13764v2",
    "title": "An Overall Real-Time Mechanism for Classification and Quality Evaluation of Rice",
    "authors": [
      "Wanke Xia",
      "Ruoxin Peng",
      "Haoqi Chu",
      "Xinlei Zhu",
      "Zhiyu Yang",
      "Yaojun Wang"
    ],
    "abstract": "Rice is one of the most widely cultivated crops globally and has been\ndeveloped into numerous varieties. The quality of rice during cultivation is\nprimarily determined by its cultivar and characteristics. Traditionally, rice\nclassification and quality assessment rely on manual visual inspection, a\nprocess that is both time-consuming and prone to errors. However, with\nadvancements in machine vision technology, automating rice classification and\nquality evaluation based on its cultivar and characteristics has become\nincreasingly feasible, enhancing both accuracy and efficiency. This study\nproposes a real-time evaluation mechanism for comprehensive rice grain\nassessment, integrating a one-stage object detection approach, a deep\nconvolutional neural network, and traditional machine learning techniques. The\nproposed framework enables rice variety identification, grain completeness\ngrading, and grain chalkiness evaluation. The rice grain dataset used in this\nstudy comprises approximately 20,000 images from six widely cultivated rice\nvarieties in China. Experimental results demonstrate that the proposed\nmechanism achieves a mean average precision (mAP) of 99.14% in the object\ndetection task and an accuracy of 97.89% in the classification task.\nFurthermore, the framework attains an average accuracy of 97.56% in grain\ncompleteness grading within the same rice variety, contributing to an effective\nquality evaluation system.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.13764v2",
    "published_date": "2025-02-19 14:24:25 UTC",
    "updated_date": "2025-02-23 07:06:03 UTC"
  },
  {
    "arxiv_id": "2502.13755v1",
    "title": "GPA: Grover Policy Agent for Generating Optimal Quantum Sensor Circuits",
    "authors": [
      "Ahmad Alomari",
      "Sathish A. P. Kumar"
    ],
    "abstract": "This study proposes a GPA for designing optimal Quantum Sensor Circuits\n(QSCs) to address complex quantum physics problems. The GPA consists of two\nparts: the Quantum Policy Evaluation (QPE) and the Quantum Policy Improvement\n(QPI). The QPE performs phase estimation to generate the search space, while\nthe QPI utilizes Grover search and amplitude amplification techniques to\nefficiently identify an optimal policy that generates optimal QSCs. The GPA\ngenerates QSCs by selecting sequences of gates that maximize the Quantum Fisher\nInformation (QFI) while minimizing the number of gates. The QSCs generated by\nthe GPA are capable of producing entangled quantum states, specifically the\nsqueezed states. High QFI indicates increased sensitivity to parameter changes,\nmaking the circuit useful for quantum state estimation and control tasks.\nEvaluation of the GPA on a QSC that consists of two qubits and a sequence of\nR_x, R_y, and S gates demonstrates its efficiency in generating optimal QSCs\nwith a QFI of 1. Compared to existing quantum agents, the GPA achieves higher\nQFI with fewer gates, demonstrating a more efficient and scalable approach to\nthe design of QSCs. This work illustrates the potential computational power of\nquantum agents for solving quantum physics problems",
    "categories": [
      "quant-ph",
      "cs.AI"
    ],
    "primary_category": "quant-ph",
    "comment": "10 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.13755v1",
    "published_date": "2025-02-19 14:20:07 UTC",
    "updated_date": "2025-02-19 14:20:07 UTC"
  },
  {
    "arxiv_id": "2502.13751v1",
    "title": "RobustX: Robust Counterfactual Explanations Made Easy",
    "authors": [
      "Junqi Jiang",
      "Luca Marzari",
      "Aaryan Purohit",
      "Francesco Leofante"
    ],
    "abstract": "The increasing use of Machine Learning (ML) models to aid decision-making in\nhigh-stakes industries demands explainability to facilitate trust.\nCounterfactual Explanations (CEs) are ideally suited for this, as they can\noffer insights into the predictions of an ML model by illustrating how changes\nin its input data may lead to different outcomes. However, for CEs to realise\ntheir explanatory potential, significant challenges remain in ensuring their\nrobustness under slight changes in the scenario being explained. Despite the\nwidespread recognition of CEs' robustness as a fundamental requirement, a lack\nof standardised tools and benchmarks hinders a comprehensive and effective\ncomparison of robust CE generation methods. In this paper, we introduce\nRobustX, an open-source Python library implementing a collection of CE\ngeneration and evaluation methods, with a focus on the robustness property.\nRobustX provides interfaces to several existing methods from the literature,\nenabling streamlined access to state-of-the-art techniques. The library is also\neasily extensible, allowing fast prototyping of novel robust CE generation and\nevaluation methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.13751v1",
    "published_date": "2025-02-19 14:12:01 UTC",
    "updated_date": "2025-02-19 14:12:01 UTC"
  },
  {
    "arxiv_id": "2502.13743v1",
    "title": "Inference of Abstraction for Grounded Predicate Logic",
    "authors": [
      "Hiroyuki Kido"
    ],
    "abstract": "An important open question in AI is what simple and natural principle enables\na machine to reason logically for meaningful abstraction with grounded symbols.\nThis paper explores a conceptually new approach to combining probabilistic\nreasoning and predicative symbolic reasoning over data. We return to the era of\nreasoning with a full joint distribution before the advent of Bayesian\nnetworks. We then discuss that a full joint distribution over models of\nexponential size in propositional logic and of infinite size in predicate logic\nshould be simply derived from a full joint distribution over data of linear\nsize. We show that the same process is not only enough to generalise the\nlogical consequence relation of predicate logic but also to provide a new\nperspective to rethink well-known limitations such as the undecidability of\npredicate logic, the symbol grounding problem and the principle of explosion.\nThe reproducibility of this theoretical work is fully demonstrated by the\nincluded proofs.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.13743v1",
    "published_date": "2025-02-19 14:07:34 UTC",
    "updated_date": "2025-02-19 14:07:34 UTC"
  },
  {
    "arxiv_id": "2502.14918v2",
    "title": "RAPTOR: Refined Approach for Product Table Object Recognition",
    "authors": [
      "Eliott Thomas",
      "Mickael Coustaty",
      "Aurelie Joseph",
      "Gaspar Deloin",
      "Elodie Carel",
      "Vincent Poulain D'Andecy",
      "Jean-Marc Ogier"
    ],
    "abstract": "Extracting tables from documents is a critical task across various\nindustries, especially on business documents like invoices and reports.\nExisting systems based on DEtection TRansformer (DETR) such as TAble\nTRansformer (TATR), offer solutions for Table Detection (TD) and Table\nStructure Recognition (TSR) but face challenges with diverse table formats and\ncommon errors like incorrect area detection and overlapping columns. This\nresearch introduces RAPTOR, a modular post-processing system designed to\nenhance state-of-the-art models for improved table extraction, particularly for\nproduct tables. RAPTOR addresses recurrent TD and TSR issues, improving both\nprecision and structural predictions. For TD, we use DETR (trained on ICDAR\n2019) and TATR (trained on PubTables-1M and FinTabNet), while TSR only relies\non TATR. A Genetic Algorithm is incorporated to optimize RAPTOR's module\nparameters, using a private dataset of product tables to align with industrial\nneeds. We evaluate our method on two private datasets of product tables, the\npublic DOCILE dataset (which contains tables similar to our target product\ntables), and the ICDAR 2013 and ICDAR 2019 datasets. The results demonstrate\nthat while our approach excels at product tables, it also maintains reasonable\nperformance across diverse table formats. An ablation study further validates\nthe contribution of each module in our system.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted for WACVW 2025 (VisionDocs)",
    "pdf_url": "http://arxiv.org/pdf/2502.14918v2",
    "published_date": "2025-02-19 13:59:06 UTC",
    "updated_date": "2025-02-24 08:29:03 UTC"
  },
  {
    "arxiv_id": "2502.13731v2",
    "title": "Robust Counterfactual Inference in Markov Decision Processes",
    "authors": [
      "Jessica Lally",
      "Milad Kazemi",
      "Nicola Paoletti"
    ],
    "abstract": "This paper addresses a key limitation in existing counterfactual inference\nmethods for Markov Decision Processes (MDPs). Current approaches assume a\nspecific causal model to make counterfactuals identifiable. However, there are\nusually many causal models that align with the observational and interventional\ndistributions of an MDP, each yielding different counterfactual distributions,\nso fixing a particular causal model limits the validity (and usefulness) of\ncounterfactual inference. We propose a novel non-parametric approach that\ncomputes tight bounds on counterfactual transition probabilities across all\ncompatible causal models. Unlike previous methods that require solving\nprohibitively large optimisation problems (with variables that grow\nexponentially in the size of the MDP), our approach provides closed-form\nexpressions for these bounds, making computation highly efficient and scalable\nfor non-trivial MDPs. Once such an interval counterfactual MDP is constructed,\nour method identifies robust counterfactual policies that optimise the\nworst-case reward w.r.t. the uncertain interval MDP probabilities. We evaluate\nour method on various case studies, demonstrating improved robustness over\nexisting methods.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Fixed typo in Equation (5)",
    "pdf_url": "http://arxiv.org/pdf/2502.13731v2",
    "published_date": "2025-02-19 13:56:20 UTC",
    "updated_date": "2025-03-27 14:20:21 UTC"
  },
  {
    "arxiv_id": "2502.13728v2",
    "title": "Secure Federated Data Distillation",
    "authors": [
      "Marco Arazzi",
      "Mert Cihangiroglu",
      "Serena Nicolazzo",
      "Antonino Nocera"
    ],
    "abstract": "Dataset Distillation (DD) is a powerful technique for reducing large datasets\ninto compact, representative synthetic datasets, accelerating Machine Learning\ntraining. However, traditional DD methods operate in a centralized manner,\nwhich poses significant privacy threats and reduces its applicability. To\nmitigate these risks, we propose a Secure Federated Data Distillation (SFDD)\nframework to decentralize the distillation process while preserving privacy.\nUnlike existing Federated Distillation techniques that focus on training global\nmodels with distilled knowledge, our approach aims to produce a distilled\ndataset without exposing local contributions. We leverage the\ngradient-matching-based distillation method, adapting it for a distributed\nsetting where clients contribute to the distillation process without sharing\nraw data. The central aggregator iteratively refines a synthetic dataset by\nintegrating client-side updates while ensuring data confidentiality. To make\nour approach resilient to inference attacks perpetrated by the server that\ncould exploit gradient updates to reconstruct private data, we create an\noptimized Local Differential Privacy approach, called LDPO-RLD. Furthermore, we\nassess the framework's resilience against malicious clients executing backdoor\nattacks (such as Doorping) and demonstrate robustness under the assumption of a\nsufficient number of participating clients. Our experimental results\ndemonstrate the effectiveness of SFDD and that the proposed defense concretely\nmitigates the identified vulnerabilities, with minimal impact on the\nperformance of the distilled dataset. By addressing the interplay between\nprivacy and federation in dataset distillation, this work advances the field of\nprivacy-preserving Machine Learning making our SFDD framework a viable solution\nfor sensitive data-sharing applications.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.13728v2",
    "published_date": "2025-02-19 13:54:44 UTC",
    "updated_date": "2025-03-06 14:07:57 UTC"
  },
  {
    "arxiv_id": "2502.13723v1",
    "title": "Direct Value Optimization: Improving Chain-of-Thought Reasoning in LLMs with Refined Values",
    "authors": [
      "Hongbo Zhang",
      "Han Cui",
      "Guangsheng Bao",
      "Linyi Yang",
      "Jun Wang",
      "Yue Zhang"
    ],
    "abstract": "We introduce Direct Value Optimization (DVO), an innovative reinforcement\nlearning framework for enhancing large language models in complex reasoning\ntasks. Unlike traditional methods relying on preference labels, DVO utilizes\nvalue signals at individual reasoning steps, optimizing models via a mean\nsquared error loss. The key benefit of DVO lies in its fine-grained\nsupervision, circumventing the need for labor-intensive human annotations.\nTarget values within the DVO are estimated using either Monte Carlo Tree Search\nor an outcome value model. Our empirical analysis on both mathematical and\ncommonsense reasoning tasks shows that DVO consistently outperforms existing\noffline preference optimization techniques, even with fewer training steps.\nThese findings underscore the importance of value signals in advancing\nreasoning capabilities and highlight DVO as a superior methodology under\nscenarios lacking explicit human preference information.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "preprint",
    "pdf_url": "http://arxiv.org/pdf/2502.13723v1",
    "published_date": "2025-02-19 13:51:05 UTC",
    "updated_date": "2025-02-19 13:51:05 UTC"
  },
  {
    "arxiv_id": "2502.13719v1",
    "title": "TrustRAG: An Information Assistant with Retrieval Augmented Generation",
    "authors": [
      "Yixing Fan",
      "Qiang Yan",
      "Wenshan Wang",
      "Jiafeng Guo",
      "Ruqing Zhang",
      "Xueqi Cheng"
    ],
    "abstract": "\\Ac{RAG} has emerged as a crucial technique for enhancing large models with\nreal-time and domain-specific knowledge. While numerous improvements and\nopen-source tools have been proposed to refine the \\ac{RAG} framework for\naccuracy, relatively little attention has been given to improving the\ntrustworthiness of generated results. To address this gap, we introduce\nTrustRAG, a novel framework that enhances \\ac{RAG} from three perspectives:\nindexing, retrieval, and generation. Specifically, in the indexing stage, we\npropose a semantic-enhanced chunking strategy that incorporates hierarchical\nindexing to supplement each chunk with contextual information, ensuring\nsemantic completeness. In the retrieval stage, we introduce a utility-based\nfiltering mechanism to identify high-quality information, supporting answer\ngeneration while reducing input length. In the generation stage, we propose\nfine-grained citation enhancement, which detects opinion-bearing sentences in\nresponses and infers citation relationships at the sentence-level, thereby\nimproving citation accuracy. We open-source the TrustRAG framework and provide\na demonstration studio designed for excerpt-based question answering tasks\n\\footnote{https://huggingface.co/spaces/golaxy/TrustRAG}. Based on these, we\naim to help researchers: 1) systematically enhancing the trustworthiness of\n\\ac{RAG} systems and (2) developing their own \\ac{RAG} systems with more\nreliable outputs.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.13719v1",
    "published_date": "2025-02-19 13:45:27 UTC",
    "updated_date": "2025-02-19 13:45:27 UTC"
  },
  {
    "arxiv_id": "2502.14013v1",
    "title": "Appeal prediction for AI up-scaled Images",
    "authors": [
      "Steve Göring",
      "Rasmus Merten",
      "Alexander Raake"
    ],
    "abstract": "DNN- or AI-based up-scaling algorithms are gaining in popularity due to the\nimprovements in machine learning. Various up-scaling models using CNNs, GANs or\nmixed approaches have been published. The majority of models are evaluated\nusing PSRN and SSIM or only a few example images. However, a performance\nevaluation with a wide range of real-world images and subjective evaluation is\nmissing, which we tackle in the following paper. For this reason, we describe\nour developed dataset, which uses 136 base images and five different up-scaling\nmethods, namely Real-ESRGAN, BSRGAN, waifu2x, KXNet, and Lanczos. Overall the\ndataset consists of 1496 annotated images. The labeling of our dataset focused\non image appeal and has been performed using crowd-sourcing employing our\nopen-source tool AVRate Voyager. We evaluate the appeal of the different\nmethods, and the results indicate that Real-ESRGAN and BSRGAN are the best.\nFurthermore, we train a DNN to detect which up-scaling method has been used,\nthe trained models have a good overall performance in our evaluation. In\naddition to this, we evaluate state-of-the-art image appeal and quality models,\nhere none of the models showed a high prediction performance, therefore we also\ntrained two own approaches. The first uses transfer learning and has the best\nperformance, and the second model uses signal-based features and a random\nforest model with good overall performance. We share the data and\nimplementation to allow further research in the context of open science.",
    "categories": [
      "cs.GR",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "cs.GR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.14013v1",
    "published_date": "2025-02-19 13:45:24 UTC",
    "updated_date": "2025-02-19 13:45:24 UTC"
  },
  {
    "arxiv_id": "2502.15812v1",
    "title": "InsightVision: A Comprehensive, Multi-Level Chinese-based Benchmark for Evaluating Implicit Visual Semantics in Large Vision Language Models",
    "authors": [
      "Xiaofei Yin",
      "Yijie Hong",
      "Ya Guo",
      "Yi Tu",
      "Weiqiang Wang",
      "Gongshen Liu",
      "Huijia zhu"
    ],
    "abstract": "In the evolving landscape of multimodal language models, understanding the\nnuanced meanings conveyed through visual cues - such as satire, insult, or\ncritique - remains a significant challenge. Existing evaluation benchmarks\nprimarily focus on direct tasks like image captioning or are limited to a\nnarrow set of categories, such as humor or satire, for deep semantic\nunderstanding. To address this gap, we introduce, for the first time, a\ncomprehensive, multi-level Chinese-based benchmark designed specifically for\nevaluating the understanding of implicit meanings in images. This benchmark is\nsystematically categorized into four subtasks: surface-level content\nunderstanding, symbolic meaning interpretation, background knowledge\ncomprehension, and implicit meaning comprehension. We propose an innovative\nsemi-automatic method for constructing datasets, adhering to established\nconstruction protocols. Using this benchmark, we evaluate 15 open-source large\nvision language models (LVLMs) and GPT-4o, revealing that even the\nbest-performing model lags behind human performance by nearly 14% in\nunderstanding implicit meaning. Our findings underscore the intrinsic\nchallenges current LVLMs face in grasping nuanced visual semantics,\nhighlighting significant opportunities for future research and development in\nthis domain. We will publicly release our InsightVision dataset, code upon\nacceptance of the paper.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "19 pages, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.15812v1",
    "published_date": "2025-02-19 13:42:37 UTC",
    "updated_date": "2025-02-19 13:42:37 UTC"
  },
  {
    "arxiv_id": "2502.15811v1",
    "title": "Spiking Point Transformer for Point Cloud Classification",
    "authors": [
      "Peixi Wu",
      "Bosong Chai",
      "Hebei Li",
      "Menghua Zheng",
      "Yansong Peng",
      "Zeyu Wang",
      "Xuan Nie",
      "Yueyi Zhang",
      "Xiaoyan Sun"
    ],
    "abstract": "Spiking Neural Networks (SNNs) offer an attractive and energy-efficient\nalternative to conventional Artificial Neural Networks (ANNs) due to their\nsparse binary activation. When SNN meets Transformer, it shows great potential\nin 2D image processing. However, their application for 3D point cloud remains\nunderexplored. To this end, we present Spiking Point Transformer (SPT), the\nfirst transformer-based SNN framework for point cloud classification.\nSpecifically, we first design Queue-Driven Sampling Direct Encoding for point\ncloud to reduce computational costs while retaining the most effective support\npoints at each time step. We introduce the Hybrid Dynamics Integrate-and-Fire\nNeuron (HD-IF), designed to simulate selective neuron activation and reduce\nover-reliance on specific artificial neurons. SPT attains state-of-the-art\nresults on three benchmark datasets that span both real-world and synthetic\ndatasets in the SNN domain. Meanwhile, the theoretical energy consumption of\nSPT is at least 6.4$\\times$ less than its ANN counterpart.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.15811v1",
    "published_date": "2025-02-19 13:28:55 UTC",
    "updated_date": "2025-02-19 13:28:55 UTC"
  },
  {
    "arxiv_id": "2502.13701v1",
    "title": "Causes and Strategies in Multiagent Systems",
    "authors": [
      "Sylvia S. Kerkhove",
      "Natasha Alechina",
      "Mehdi Dastani"
    ],
    "abstract": "Causality plays an important role in daily processes, human reasoning, and\nartificial intelligence. There has however not been much research on causality\nin multi-agent strategic settings. In this work, we introduce a systematic way\nto build a multi-agent system model, represented as a concurrent game\nstructure, for a given structural causal model. In the obtained so-called\ncausal concurrent game structure, transitions correspond to interventions on\nagent variables of the given causal model. The Halpern and Pearl framework of\ncausality is used to determine the effects of a certain value for an agent\nvariable on other variables. The causal concurrent game structure allows us to\nanalyse and reason about causal effects of agents' strategic decisions. We\nformally investigate the relation between causal concurrent game structures and\nthe original structural causal models.",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted at AAMAS 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.13701v1",
    "published_date": "2025-02-19 13:18:42 UTC",
    "updated_date": "2025-02-19 13:18:42 UTC"
  },
  {
    "arxiv_id": "2502.13685v2",
    "title": "MoM: Linear Sequence Modeling with Mixture-of-Memories",
    "authors": [
      "Jusen Du",
      "Weigao Sun",
      "Disen Lan",
      "Jiaxi Hu",
      "Yu Cheng"
    ],
    "abstract": "Linear sequence modeling methods, such as linear attention, state space\nmodeling, and linear RNNs, offer significant efficiency improvements by\nreducing the complexity of training and inference. However, these methods\ntypically compress the entire input sequence into a single fixed-size memory\nstate, which leads to suboptimal performance on recall-intensive downstream\ntasks. Drawing inspiration from neuroscience, particularly the brain's ability\nto maintain robust long-term memory while mitigating \"memory interference\", we\nintroduce a novel architecture called Mixture-of-Memories (MoM). MoM utilizes\nmultiple independent memory states, with a router network directing input\ntokens to specific memory states. This approach greatly enhances the overall\nmemory capacity while minimizing memory interference. As a result, MoM performs\nexceptionally well on recall-intensive tasks, surpassing existing linear\nsequence modeling techniques. Despite incorporating multiple memory states, the\ncomputation of each memory state remains linear in complexity, allowing MoM to\nretain the linear-complexity advantage during training, while\nconstant-complexity during inference. Our experimental results show that MoM\nsignificantly outperforms current linear sequence models on downstream language\ntasks, particularly recall-intensive tasks, and even achieves performance\ncomparable to Transformer models. The code is released at\nhttps://github.com/OpenSparseLLMs/MoM and is also released as a part of\nhttps://github.com/OpenSparseLLMs/Linear-MoE.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Technical report, 16 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.13685v2",
    "published_date": "2025-02-19 12:53:55 UTC",
    "updated_date": "2025-05-06 13:11:19 UTC"
  },
  {
    "arxiv_id": "2502.13681v2",
    "title": "An LLM-based Agent for Reliable Docker Environment Configuration",
    "authors": [
      "Ruida Hu",
      "Chao Peng",
      "Xinchen Wang",
      "Cuiyun Gao"
    ],
    "abstract": "Environment configuration is a critical yet time-consuming step in software\ndevelopment, especially when dealing with unfamiliar code repositories. While\nLarge Language Models (LLMs) demonstrate the potential to accomplish software\nengineering tasks, existing methods for environment configuration often rely on\nmanual efforts or fragile scripts, leading to inefficiencies and unreliable\noutcomes. We introduce Repo2Run, the first LLM-based agent designed to fully\nautomate environment configuration and generate executable Dockerfiles for\narbitrary Python repositories. We address two major challenges: (1) enabling\nthe LLM agent to configure environments within isolated Docker containers, and\n(2) ensuring the successful configuration process is recorded and accurately\ntransferred to a Dockerfile without error. To achieve this, we propose atomic\nconfiguration synthesis, featuring a dual-environment architecture (internal\nand external environment) with a rollback mechanism to prevent environment\n\"pollution\" from failed commands, guaranteeing atomic execution (execute fully\nor not at all) and a Dockerfile generator to transfer successful configuration\nsteps into runnable Dockerfiles. We evaluate Repo2Run~on our proposed benchmark\nof 420 recent Python repositories with unit tests, where it achieves an 86.0%\nsuccess rate, outperforming the best baseline by 63.9%. Repo2Run is available\nat https://github.com/bytedance/Repo2Run.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.13681v2",
    "published_date": "2025-02-19 12:51:35 UTC",
    "updated_date": "2025-03-06 07:17:09 UTC"
  },
  {
    "arxiv_id": "2502.14011v1",
    "title": "DFDT: Dynamic Fast Decision Tree for IoT Data Stream Mining on Edge Devices",
    "authors": [
      "Afonso Lourenço",
      "João Rodrigo",
      "João Gama",
      "Goreti Marreiros"
    ],
    "abstract": "The Internet of Things generates massive data streams, with edge computing\nemerging as a key enabler for online IoT applications and 5G networks. Edge\nsolutions facilitate real-time machine learning inference, but also require\ncontinuous adaptation to concept drifts. Ensemble-based solutions improve\npredictive performance, but incur higher resource consumption, latency, and\nmemory demands. This paper presents DFDT: Dynamic Fast Decision Tree, a novel\nalgorithm designed for energy-efficient memory-constrained data stream mining.\nDFDT improves hoeffding tree growth efficiency by dynamically adjusting grace\nperiods, tie thresholds, and split evaluations based on incoming data. It\nincorporates stricter evaluation rules (based on entropy, information gain, and\nleaf instance count), adaptive expansion modes, and a leaf deactivation\nmechanism to manage memory, allowing more computation on frequently visited\nnodes while conserving energy on others. Experiments show that the proposed\nframework can achieve increased predictive performance (0.43 vs 0.29 ranking)\nwith constrained memory and a fraction of the runtime of VFDT or SVFDT.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.14011v1",
    "published_date": "2025-02-19 12:45:42 UTC",
    "updated_date": "2025-02-19 12:45:42 UTC"
  },
  {
    "arxiv_id": "2502.20411v1",
    "title": "Backpropagation-free Spiking Neural Networks with the Forward-Forward Algorithm",
    "authors": [
      "Mohammadnavid Ghader",
      "Saeed Reza Kheradpisheh",
      "Bahar Farahani",
      "Mahmood Fazlali"
    ],
    "abstract": "Spiking Neural Networks (SNNs) offer a biologically inspired computational\nparadigm that emulates neuronal activity through discrete spike-based\nprocessing. Despite their advantages, training SNNs with traditional\nbackpropagation (BP) remains challenging due to computational inefficiencies\nand a lack of biological plausibility. This study explores the Forward-Forward\n(FF) algorithm as an alternative learning framework for SNNs. Unlike\nbackpropagation, which relies on forward and backward passes, the FF algorithm\nemploys two forward passes, enabling localized learning, enhanced computational\nefficiency, and improved compatibility with neuromorphic hardware. We introduce\nan FF-based SNN training framework and evaluate its performance across both\nnon-spiking (MNIST, Fashion-MNIST, CIFAR-10) and spiking (Neuro-MNIST, SHD)\ndatasets. Experimental results demonstrate that our model surpasses existing\nFF-based SNNs by over 5% on MNIST and Fashion-MNIST while achieving accuracy\ncomparable to state-of-the-art backpropagation-trained SNNs. On more complex\ntasks such as CIFAR-10 and SHD, our approach outperforms other SNN models by up\nto 6% and remains competitive with leading backpropagation-trained SNNs. These\nfindings highlight the FF algorithm's potential to advance SNN training\nmethodologies and neuromorphic computing by addressing key limitations of\nbackpropagation.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20411v1",
    "published_date": "2025-02-19 12:44:26 UTC",
    "updated_date": "2025-02-19 12:44:26 UTC"
  },
  {
    "arxiv_id": "2502.15810v1",
    "title": "Zero-Shot Commonsense Validation and Reasoning with Large Language Models: An Evaluation on SemEval-2020 Task 4 Dataset",
    "authors": [
      "Rawand Alfugaha",
      "Mohammad AL-Smadi"
    ],
    "abstract": "This study evaluates the performance of Large Language Models (LLMs) on\nSemEval-2020 Task 4 dataset, focusing on commonsense validation and\nexplanation. Our methodology involves evaluating multiple LLMs, including\nLLaMA3-70B, Gemma2-9B, and Mixtral-8x7B, using zero-shot prompting techniques.\nThe models are tested on two tasks: Task A (Commonsense Validation), where\nmodels determine whether a statement aligns with commonsense knowledge, and\nTask B (Commonsense Explanation), where models identify the reasoning behind\nimplausible statements. Performance is assessed based on accuracy, and results\nare compared to fine-tuned transformer-based models. The results indicate that\nlarger models outperform previous models and perform closely to human\nevaluation for Task A, with LLaMA3-70B achieving the highest accuracy of 98.40%\nin Task A whereas, lagging behind previous models with 93.40% in Task B.\nHowever, while models effectively identify implausible statements, they face\nchallenges in selecting the most relevant explanation, highlighting limitations\nin causal and inferential reasoning.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15810v1",
    "published_date": "2025-02-19 12:40:49 UTC",
    "updated_date": "2025-02-19 12:40:49 UTC"
  },
  {
    "arxiv_id": "2502.14010v1",
    "title": "Which Attention Heads Matter for In-Context Learning?",
    "authors": [
      "Kayo Yin",
      "Jacob Steinhardt"
    ],
    "abstract": "Large language models (LLMs) exhibit impressive in-context learning (ICL)\ncapability, enabling them to perform new tasks using only a few demonstrations\nin the prompt. Two different mechanisms have been proposed to explain ICL:\ninduction heads that find and copy relevant tokens, and function vector (FV)\nheads whose activations compute a latent encoding of the ICL task. To better\nunderstand which of the two distinct mechanisms drives ICL, we study and\ncompare induction heads and FV heads in 12 language models.\n  Through detailed ablations, we discover that few-shot ICL performance depends\nprimarily on FV heads, especially in larger models. In addition, we uncover\nthat FV and induction heads are connected: many FV heads start as induction\nheads during training before transitioning to the FV mechanism. This leads us\nto speculate that induction facilitates learning the more complex FV mechanism\nthat ultimately drives ICL.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.14010v1",
    "published_date": "2025-02-19 12:25:02 UTC",
    "updated_date": "2025-02-19 12:25:02 UTC"
  },
  {
    "arxiv_id": "2502.13668v1",
    "title": "PeerQA: A Scientific Question Answering Dataset from Peer Reviews",
    "authors": [
      "Tim Baumgärtner",
      "Ted Briscoe",
      "Iryna Gurevych"
    ],
    "abstract": "We present PeerQA, a real-world, scientific, document-level Question\nAnswering (QA) dataset. PeerQA questions have been sourced from peer reviews,\nwhich contain questions that reviewers raised while thoroughly examining the\nscientific article. Answers have been annotated by the original authors of each\npaper. The dataset contains 579 QA pairs from 208 academic articles, with a\nmajority from ML and NLP, as well as a subset of other scientific communities\nlike Geoscience and Public Health. PeerQA supports three critical tasks for\ndeveloping practical QA systems: Evidence retrieval, unanswerable question\nclassification, and answer generation. We provide a detailed analysis of the\ncollected dataset and conduct experiments establishing baseline systems for all\nthree tasks. Our experiments and analyses reveal the need for\ndecontextualization in document-level retrieval, where we find that even simple\ndecontextualization approaches consistently improve retrieval performance\nacross architectures. On answer generation, PeerQA serves as a challenging\nbenchmark for long-context modeling, as the papers have an average size of 12k\ntokens. Our code and data is available at https://github.com/UKPLab/peerqa.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at NAACL 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.13668v1",
    "published_date": "2025-02-19 12:24:46 UTC",
    "updated_date": "2025-02-19 12:24:46 UTC"
  },
  {
    "arxiv_id": "2503.16451v1",
    "title": "Think-Then-React: Towards Unconstrained Human Action-to-Reaction Generation",
    "authors": [
      "Wenhui Tan",
      "Boyuan Li",
      "Chuhao Jin",
      "Wenbing Huang",
      "Xiting Wang",
      "Ruihua Song"
    ],
    "abstract": "Modeling human-like action-to-reaction generation has significant real-world\napplications, like human-robot interaction and games. Despite recent\nadvancements in single-person motion generation, it is still challenging to\nwell handle action-to-reaction generation, due to the difficulty of directly\npredicting reaction from action sequence without prompts, and the absence of a\nunified representation that effectively encodes multi-person motion. To address\nthese challenges, we introduce Think-Then-React (TTR), a large\nlanguage-model-based framework designed to generate human-like reactions.\nFirst, with our fine-grained multimodal training strategy, TTR is capable to\nunify two processes during inference: a thinking process that explicitly infers\naction intentions and reasons corresponding reaction description, which serve\nas semantic prompts, and a reacting process that predicts reactions based on\ninput action and the inferred semantic prompts. Second, to effectively\nrepresent multi-person motion in language models, we propose a unified motion\ntokenizer by decoupling egocentric pose and absolute space features, which\neffectively represents action and reaction motion with same encoding. Extensive\nexperiments demonstrate that TTR outperforms existing baselines, achieving\nsignificant improvements in evaluation metrics, such as reducing FID from 3.988\nto 1.942.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.HC",
    "comment": "Accepted by ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.16451v1",
    "published_date": "2025-02-19 12:14:38 UTC",
    "updated_date": "2025-02-19 12:14:38 UTC"
  },
  {
    "arxiv_id": "2502.14008v1",
    "title": "MaskPrune: Mask-based LLM Pruning for Layer-wise Uniform Structures",
    "authors": [
      "Jiayu Qin",
      "Jianchao Tan",
      "Kefeng Zhang",
      "Xunliang Cai",
      "Wei Wang"
    ],
    "abstract": "The remarkable performance of large language models (LLMs) in various\nlanguage tasks has attracted considerable attention. However, the\never-increasing size of these models presents growing challenges for deployment\nand inference. Structured pruning, an effective model compression technique, is\ngaining increasing attention due to its ability to enhance inference\nefficiency. Nevertheless, most previous optimization-based structured pruning\nmethods sacrifice the uniform structure across layers for greater flexibility\nto maintain performance. The heterogeneous structure hinders the effective\nutilization of off-the-shelf inference acceleration techniques and impedes\nefficient configuration for continued training. To address this issue, we\npropose a novel masking learning paradigm based on minimax optimization to\nobtain the uniform pruned structure by optimizing the masks under sparsity\nregularization. Extensive experimental results demonstrate that our method can\nmaintain high performance while ensuring the uniformity of the pruned model\nstructure, thereby outperforming existing SOTA methods.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.14008v1",
    "published_date": "2025-02-19 11:57:31 UTC",
    "updated_date": "2025-02-19 11:57:31 UTC"
  },
  {
    "arxiv_id": "2502.13652v1",
    "title": "C2T: A Classifier-Based Tree Construction Method in Speculative Decoding",
    "authors": [
      "Feiye Huo",
      "Jianchao Tan",
      "Kefeng Zhang",
      "Xunliang Cai",
      "Shengli Sun"
    ],
    "abstract": "The growing scale of Large Language Models (LLMs) has exacerbated inference\nlatency and computational costs. Speculative decoding methods, which aim to\nmitigate these issues, often face inefficiencies in the construction of token\ntrees and the verification of candidate tokens. Existing strategies, including\nchain mode, static tree, and dynamic tree approaches, have limitations in\naccurately preparing candidate token trees for verification. We propose a novel\nmethod named C2T that adopts a lightweight classifier to generate and prune\ntoken trees dynamically. Our classifier considers additional feature variables\nbeyond the commonly used joint probability to predict the confidence score for\neach draft token to determine whether it is the candidate token for\nverification. This method outperforms state-of-the-art (SOTA) methods such as\nEAGLE-2 on multiple benchmarks, by reducing the total number of candidate\ntokens by 25% while maintaining or even improving the acceptance length.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.13652v1",
    "published_date": "2025-02-19 11:57:02 UTC",
    "updated_date": "2025-02-19 11:57:02 UTC"
  },
  {
    "arxiv_id": "2502.14007v1",
    "title": "d-Sketch: Improving Visual Fidelity of Sketch-to-Image Translation with Pretrained Latent Diffusion Models without Retraining",
    "authors": [
      "Prasun Roy",
      "Saumik Bhattacharya",
      "Subhankar Ghosh",
      "Umapada Pal",
      "Michael Blumenstein"
    ],
    "abstract": "Structural guidance in an image-to-image translation allows intricate control\nover the shapes of synthesized images. Generating high-quality realistic images\nfrom user-specified rough hand-drawn sketches is one such task that aims to\nimpose a structural constraint on the conditional generation process. While the\npremise is intriguing for numerous use cases of content creation and academic\nresearch, the problem becomes fundamentally challenging due to substantial\nambiguities in freehand sketches. Furthermore, balancing the trade-off between\nshape consistency and realistic generation contributes to additional complexity\nin the process. Existing approaches based on Generative Adversarial Networks\n(GANs) generally utilize conditional GANs or GAN inversions, often requiring\napplication-specific data and optimization objectives. The recent introduction\nof Denoising Diffusion Probabilistic Models (DDPMs) achieves a generational\nleap for low-level visual attributes in general image synthesis. However,\ndirectly retraining a large-scale diffusion model on a domain-specific subtask\nis often extremely difficult due to demanding computation costs and\ninsufficient data. In this paper, we introduce a technique for sketch-to-image\ntranslation by exploiting the feature generalization capabilities of a\nlarge-scale diffusion model without retraining. In particular, we use a\nlearnable lightweight mapping network to achieve latent feature translation\nfrom source to target domain. Experimental results demonstrate that the\nproposed method outperforms the existing techniques in qualitative and\nquantitative benchmarks, allowing high-resolution realistic image synthesis\nfrom rough hand-drawn sketches.",
    "categories": [
      "cs.GR",
      "cs.AI",
      "cs.CV",
      "cs.MM",
      "eess.IV"
    ],
    "primary_category": "cs.GR",
    "comment": "Accepted in The International Conference on Pattern Recognition\n  (ICPR) 2024",
    "pdf_url": "http://arxiv.org/pdf/2502.14007v1",
    "published_date": "2025-02-19 11:54:45 UTC",
    "updated_date": "2025-02-19 11:54:45 UTC"
  },
  {
    "arxiv_id": "2502.13638v1",
    "title": "Integrating Inverse and Forward Modeling for Sparse Temporal Data from Sensor Networks",
    "authors": [
      "Julian Vexler",
      "Björn Vieten",
      "Martin Nelke",
      "Stefan Kramer"
    ],
    "abstract": "We present CavePerception, a framework for the analysis of sparse data from\nsensor networks that incorporates elements of inverse modeling and forward\nmodeling. By integrating machine learning with physical modeling in a\nhypotheses space, we aim to improve the interpretability of sparse, noisy, and\npotentially incomplete sensor data. The framework assumes data from a\ntwo-dimensional sensor network laid out in a graph structure that detects\ncertain objects, with certain motion patterns. Examples of such sensors are\nmagnetometers. Given knowledge about the objects and the way they act on the\nsensors, one can develop a data generator that produces data from simulated\nmotions of the objects across the sensor field. The framework uses the\nsimulated data to infer object behaviors across the sensor network. The\napproach is experimentally tested on real-world data, where magnetometers are\nused on an airport to detect and identify aircraft motions. Experiments\ndemonstrate the value of integrating inverse and forward modeling, enabling\nintelligent systems to better understand and predict complex, sensor-driven\nevents.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.13638v1",
    "published_date": "2025-02-19 11:24:51 UTC",
    "updated_date": "2025-02-19 11:24:51 UTC"
  },
  {
    "arxiv_id": "2503.05734v1",
    "title": "Modeling Behavior Change for Multi-model At-Risk Students Early Prediction (extended version)",
    "authors": [
      "Jiabei Cheng",
      "Zhen-Qun Yang",
      "Jiannong Cao",
      "Yu Yang",
      "Kai Cheung Franky Poon",
      "Daniel Lai"
    ],
    "abstract": "In the educational domain, identifying students at risk of dropping out is\nessential for allowing educators to intervene effectively, improving both\nacademic outcomes and overall student well-being. Data in educational settings\noften originate from diverse sources, such as assignments, grades, and\nattendance records. However, most existing research relies on online learning\ndata and just extracting the quantitative features. While quantification eases\nprocessing, it also leads to a significant loss of original information.\nMoreover, current models primarily identify students with consistently poor\nperformance through simple and discrete behavioural patterns, failing to\ncapture the complex continuity and non-linear changes in student behaviour. We\nhave developed an innovative prediction model, Multimodal- ChangePoint\nDetection (MCPD), utilizing the textual teacher remark data and numerical grade\ndata from middle schools. Our model achieves a highly integrated and\nintelligent analysis by using independent encoders to process two data types,\nfusing the encoded feature. The model further refines its analysis by\nleveraging a changepoint detection module to pinpoint crucial behavioral\nchanges, which are integrated as dynamic weights through a simple attention\nmechanism. Experimental validations indicate that our model achieves an\naccuracy range of 70- 75%, with an average outperforming baseline algorithms by\napproximately 5-10%. Additionally, our algorithm demonstrates a certain degree\nof transferability, maintaining high accuracy when adjusted and retrained with\ndifferent definitions of at-risk, proving its broad applicability.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.05734v1",
    "published_date": "2025-02-19 11:16:46 UTC",
    "updated_date": "2025-02-19 11:16:46 UTC"
  },
  {
    "arxiv_id": "2502.13632v1",
    "title": "Concept Layers: Enhancing Interpretability and Intervenability via LLM Conceptualization",
    "authors": [
      "Or Raphael Bidusa",
      "Shaul Markovitch"
    ],
    "abstract": "The opaque nature of Large Language Models (LLMs) has led to significant\nresearch efforts aimed at enhancing their interpretability, primarily through\npost-hoc methods. More recent in-hoc approaches, such as Concept Bottleneck\nModels (CBMs), offer both interpretability and intervenability by incorporating\nexplicit concept representations. However, these methods suffer from key\nlimitations, including reliance on labeled concept datasets and significant\narchitectural modifications that challenges re-integration into existing system\npipelines. In this work, we introduce a new methodology for incorporating\ninterpretability and intervenability into an existing model by integrating\nConcept Layers (CLs) into its architecture. Our approach projects the model's\ninternal vector representations into a conceptual, explainable vector space\nbefore reconstructing and feeding them back into the model. Furthermore, we\neliminate the need for a human-selected concept set by algorithmically\nsearching an ontology for a set of concepts that can be either task-specific or\ntask-agnostic. We evaluate CLs across multiple tasks, demonstrating that they\nmaintain the original model's performance and agreement while enabling\nmeaningful interventions. Additionally, we present a proof of concept\nshowcasing an intervenability interface, allowing users to adjust model\nbehavior dynamically, such as mitigating biases during inference.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.13632v1",
    "published_date": "2025-02-19 11:10:19 UTC",
    "updated_date": "2025-02-19 11:10:19 UTC"
  },
  {
    "arxiv_id": "2502.13622v2",
    "title": "REFIND at SemEval-2025 Task 3: Retrieval-Augmented Factuality Hallucination Detection in Large Language Models",
    "authors": [
      "DongGeon Lee",
      "Hwanjo Yu"
    ],
    "abstract": "Hallucinations in large language model (LLM) outputs severely limit their\nreliability in knowledge-intensive tasks such as question answering. To address\nthis challenge, we introduce REFIND (Retrieval-augmented Factuality\nhallucINation Detection), a novel framework that detects hallucinated spans\nwithin LLM outputs by directly leveraging retrieved documents. As part of the\nREFIND, we propose the Context Sensitivity Ratio (CSR), a novel metric that\nquantifies the sensitivity of LLM outputs to retrieved evidence. This\ninnovative approach enables REFIND to efficiently and accurately detect\nhallucinations, setting it apart from existing methods. In the evaluation,\nREFIND demonstrated robustness across nine languages, including low-resource\nsettings, and significantly outperformed baseline models, achieving superior\nIoU scores in identifying hallucinated spans. This work highlights the\neffectiveness of quantifying context sensitivity for hallucination detection,\nthereby paving the way for more reliable and trustworthy LLM applications\nacross diverse languages. Our code is available at\nhttps://github.com/oneonlee/REFIND.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to SemEval@ACL 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.13622v2",
    "published_date": "2025-02-19 10:59:05 UTC",
    "updated_date": "2025-04-08 08:17:49 UTC"
  },
  {
    "arxiv_id": "2502.13621v1",
    "title": "Decentralized Planning Using Probabilistic Hyperproperties",
    "authors": [
      "Francesco Pontiggia",
      "Filip Macák",
      "Roman Andriushchenko",
      "Michele Chiari",
      "Milan Češka"
    ],
    "abstract": "Multi-agent planning under stochastic dynamics is usually formalised using\ndecentralized (partially observable) Markov decision processes ( MDPs) and\nreachability or expected reward specifications. In this paper, we propose a\ndifferent approach: we use an MDP describing how a single agent operates in an\nenvironment and probabilistic hyperproperties to capture desired temporal\nobjectives for a set of decentralized agents operating in the environment. We\nextend existing approaches for model checking probabilistic hyperproperties to\nhandle temporal formulae relating paths of different agents, thus requiring the\nself-composition between multiple MDPs. Using several case studies, we\ndemonstrate that our approach provides a flexible and expressive framework to\nbroaden the specification capabilities with respect to existing planning\ntechniques. Additionally, we establish a close connection between a subclass of\nprobabilistic hyperproperties and planning for a particular type of Dec-MDPs,\nfor both of which we show undecidability. This lays the ground for the use of\nexisting decentralized planning tools in the field of probabilistic\nhyperproperty verification.",
    "categories": [
      "cs.LO",
      "cs.AI"
    ],
    "primary_category": "cs.LO",
    "comment": "11 pages, 1 figure, 2 tables. Accepted at AAMAS 2025: the 24th\n  International Conference on Autonomous Agents and Multiagent Systems",
    "pdf_url": "http://arxiv.org/pdf/2502.13621v1",
    "published_date": "2025-02-19 10:59:02 UTC",
    "updated_date": "2025-02-19 10:59:02 UTC"
  },
  {
    "arxiv_id": "2502.13619v1",
    "title": "Complex Ontology Matching with Large Language Model Embeddings",
    "authors": [
      "Guilherme Sousa",
      "Rinaldo Lima",
      "Cassia Trojahn"
    ],
    "abstract": "Ontology, and more broadly, Knowledge Graph Matching is a challenging task in\nwhich expressiveness has not been fully addressed. Despite the increasing use\nof embeddings and language models for this task, approaches for generating\nexpressive correspondences still do not take full advantage of these models, in\nparticular, large language models (LLMs). This paper proposes to integrate LLMs\ninto an approach for generating expressive correspondences based on alignment\nneed and ABox-based relation discovery. The generation of correspondences is\nperformed by matching similar surroundings of instance sub-graphs. The\nintegration of LLMs results in different architectural modifications, including\nlabel similarity, sub-graph matching, and entity matching. The performance word\nembeddings, sentence embeddings, and LLM-based embeddings, was compared. The\nresults demonstrate that integrating LLMs surpasses all other models, enhancing\nthe baseline version of the approach with a 45\\% increase in F-measure.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.13619v1",
    "published_date": "2025-02-19 10:56:27 UTC",
    "updated_date": "2025-02-19 10:56:27 UTC"
  },
  {
    "arxiv_id": "2502.13606v1",
    "title": "LaVCa: LLM-assisted Visual Cortex Captioning",
    "authors": [
      "Takuya Matsuyama",
      "Shinji Nishimoto",
      "Yu Takagi"
    ],
    "abstract": "Understanding the property of neural populations (or voxels) in the human\nbrain can advance our comprehension of human perceptual and cognitive\nprocessing capabilities and contribute to developing brain-inspired computer\nmodels. Recent encoding models using deep neural networks (DNNs) have\nsuccessfully predicted voxel-wise activity. However, interpreting the\nproperties that explain voxel responses remains challenging because of the\nblack-box nature of DNNs. As a solution, we propose LLM-assisted Visual Cortex\nCaptioning (LaVCa), a data-driven approach that uses large language models\n(LLMs) to generate natural-language captions for images to which voxels are\nselective. By applying LaVCa for image-evoked brain activity, we demonstrate\nthat LaVCa generates captions that describe voxel selectivity more accurately\nthan the previously proposed method. Furthermore, the captions generated by\nLaVCa quantitatively capture more detailed properties than the existing method\nat both the inter-voxel and intra-voxel levels. Furthermore, a more detailed\nanalysis of the voxel-specific properties generated by LaVCa reveals\nfine-grained functional differentiation within regions of interest (ROIs) in\nthe visual cortex and voxels that simultaneously represent multiple distinct\nconcepts. These findings offer profound insights into human visual\nrepresentations by assigning detailed captions throughout the visual cortex\nwhile highlighting the potential of LLM-based methods in understanding brain\nrepresentations. Please check out our webpage at\nhttps://sites.google.com/view/lavca-llm/",
    "categories": [
      "q-bio.NC",
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "q-bio.NC",
    "comment": "33 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.13606v1",
    "published_date": "2025-02-19 10:37:04 UTC",
    "updated_date": "2025-02-19 10:37:04 UTC"
  },
  {
    "arxiv_id": "2502.13603v2",
    "title": "Efficient Safety Retrofitting Against Jailbreaking for LLMs",
    "authors": [
      "Dario Garcia-Gasulla",
      "Adrian Tormos",
      "Anna Arias-Duart",
      "Daniel Hinjos",
      "Oscar Molina-Sedano",
      "Ashwin Kumar Gururajan",
      "Maria Eugenia Cardello"
    ],
    "abstract": "Direct Preference Optimization (DPO) is an efficient alignment technique that\nsteers LLMs towards preferable outputs by training on preference data,\nbypassing the need for explicit reward models. Its simplicity enables easy\nadaptation to various domains and safety requirements. This paper examines\nDPO's effectiveness in model safety against jailbreaking attacks while\nminimizing data requirements and training costs. We introduce Egida, a dataset\nexpanded from multiple sources, which includes 27 different safety topics and\n18 different attack styles, complemented with synthetic and human labels. This\ndata is used to boost the safety of state-of-the-art LLMs\n(Llama-3.1-8B/70B-Instruct, Qwen-2.5-7B/72B-Instruct) across topics and attack\nstyles. In addition to safety evaluations, we assess their post-alignment\nperformance degradation in general purpose tasks, and their tendency to over\nrefusal. Following the proposed methodology, trained models reduce their Attack\nSuccess Rate by 10%-30%, using small training efforts (2,000 samples) with low\ncomputational cost (3\\$ for 8B models, 20\\$ for 72B models). Safety aligned\nmodels generalize to unseen topics and attack styles, with the most successful\nattack style reaching a success rate around 5%. Size and family are found to\nstrongly influence model malleability towards safety, pointing at the\nimportance of pre-training choices. To validate our findings, a large\nindependent assessment of human preference agreement with Llama-Guard-3-8B is\nconducted by the authors and the associated dataset Egida-HSafe is released.\nOverall, this study illustrates how affordable and accessible it is to enhance\nLLM safety using DPO while outlining its current limitations. All datasets and\nmodels are released to enable reproducibility and further research.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.13603v2",
    "published_date": "2025-02-19 10:33:18 UTC",
    "updated_date": "2025-02-25 12:06:25 UTC"
  },
  {
    "arxiv_id": "2502.13595v2",
    "title": "MMTEB: Massive Multilingual Text Embedding Benchmark",
    "authors": [
      "Kenneth Enevoldsen",
      "Isaac Chung",
      "Imene Kerboua",
      "Márton Kardos",
      "Ashwin Mathur",
      "David Stap",
      "Jay Gala",
      "Wissam Siblini",
      "Dominik Krzemiński",
      "Genta Indra Winata",
      "Saba Sturua",
      "Saiteja Utpala",
      "Mathieu Ciancone",
      "Marion Schaeffer",
      "Gabriel Sequeira",
      "Diganta Misra",
      "Shreeya Dhakal",
      "Jonathan Rystrøm",
      "Roman Solomatin",
      "Ömer Çağatan",
      "Akash Kundu",
      "Martin Bernstorff",
      "Shitao Xiao",
      "Akshita Sukhlecha",
      "Bhavish Pahwa",
      "Rafał Poświata",
      "Kranthi Kiran GV",
      "Shawon Ashraf",
      "Daniel Auras",
      "Björn Plüster",
      "Jan Philipp Harries",
      "Loïc Magne",
      "Isabelle Mohr",
      "Mariya Hendriksen",
      "Dawei Zhu",
      "Hippolyte Gisserot-Boukhlef",
      "Tom Aarsen",
      "Jan Kostkan",
      "Konrad Wojtasik",
      "Taemin Lee",
      "Marek Šuppa",
      "Crystina Zhang",
      "Roberta Rocca",
      "Mohammed Hamdy",
      "Andrianos Michail",
      "John Yang",
      "Manuel Faysse",
      "Aleksei Vatolin",
      "Nandan Thakur",
      "Manan Dey",
      "Dipam Vasani",
      "Pranjal Chitale",
      "Simone Tedeschi",
      "Nguyen Tai",
      "Artem Snegirev",
      "Michael Günther",
      "Mengzhou Xia",
      "Weijia Shi",
      "Xing Han Lù",
      "Jordan Clive",
      "Gayatri Krishnakumar",
      "Anna Maksimova",
      "Silvan Wehrli",
      "Maria Tikhonova",
      "Henil Panchal",
      "Aleksandr Abramov",
      "Malte Ostendorff",
      "Zheng Liu",
      "Simon Clematide",
      "Lester James Miranda",
      "Alena Fenogenova",
      "Guangyu Song",
      "Ruqiya Bin Safi",
      "Wen-Ding Li",
      "Alessia Borghini",
      "Federico Cassano",
      "Hongjin Su",
      "Jimmy Lin",
      "Howard Yen",
      "Lasse Hansen",
      "Sara Hooker",
      "Chenghao Xiao",
      "Vaibhav Adlakha",
      "Orion Weller",
      "Siva Reddy",
      "Niklas Muennighoff"
    ],
    "abstract": "Text embeddings are typically evaluated on a limited set of tasks, which are\nconstrained by language, domain, and task diversity. To address these\nlimitations and provide a more comprehensive evaluation, we introduce the\nMassive Multilingual Text Embedding Benchmark (MMTEB) - a large-scale,\ncommunity-driven expansion of MTEB, covering over 500 quality-controlled\nevaluation tasks across 250+ languages. MMTEB includes a diverse set of\nchallenging, novel tasks such as instruction following, long-document\nretrieval, and code retrieval, representing the largest multilingual collection\nof evaluation tasks for embedding models to date. Using this collection, we\ndevelop several highly multilingual benchmarks, which we use to evaluate a\nrepresentative set of models. We find that while large language models (LLMs)\nwith billions of parameters can achieve state-of-the-art performance on certain\nlanguage subsets and task categories, the best-performing publicly available\nmodel is multilingual-e5-large-instruct with only 560 million parameters. To\nfacilitate accessibility and reduce computational cost, we introduce a novel\ndownsampling method based on inter-task correlation, ensuring a diverse\nselection while preserving relative model rankings. Furthermore, we optimize\ntasks such as retrieval by sampling hard negatives, creating smaller but\neffective splits. These optimizations allow us to introduce benchmarks that\ndrastically reduce computational demands. For instance, our newly introduced\nzero-shot English benchmark maintains a ranking order similar to the full-scale\nversion but at a fraction of the computational cost.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted for ICLR: https://openreview.net/forum?id=zl3pfz4VCV",
    "pdf_url": "http://arxiv.org/pdf/2502.13595v2",
    "published_date": "2025-02-19 10:13:43 UTC",
    "updated_date": "2025-04-08 08:57:22 UTC"
  },
  {
    "arxiv_id": "2502.14917v1",
    "title": "Sce2DriveX: A Generalized MLLM Framework for Scene-to-Drive Learning",
    "authors": [
      "Rui Zhao",
      "Qirui Yuan",
      "Jinyu Li",
      "Haofeng Hu",
      "Yun Li",
      "Chengyuan Zheng",
      "Fei Gao"
    ],
    "abstract": "End-to-end autonomous driving, which directly maps raw sensor inputs to\nlow-level vehicle controls, is an important part of Embodied AI. Despite\nsuccesses in applying Multimodal Large Language Models (MLLMs) for high-level\ntraffic scene semantic understanding, it remains challenging to effectively\ntranslate these conceptual semantics understandings into low-level motion\ncontrol commands and achieve generalization and consensus in cross-scene\ndriving. We introduce Sce2DriveX, a human-like driving chain-of-thought (CoT)\nreasoning MLLM framework. Sce2DriveX utilizes multimodal joint learning from\nlocal scene videos and global BEV maps to deeply understand long-range\nspatiotemporal relationships and road topology, enhancing its comprehensive\nperception and reasoning capabilities in 3D dynamic/static scenes and achieving\ndriving generalization across scenes. Building on this, it reconstructs the\nimplicit cognitive chain inherent in human driving, covering scene\nunderstanding, meta-action reasoning, behavior interpretation analysis, motion\nplanning and control, thereby further bridging the gap between autonomous\ndriving and human thought processes. To elevate model performance, we have\ndeveloped the first extensive Visual Question Answering (VQA) driving\ninstruction dataset tailored for 3D spatial understanding and long-axis task\nreasoning. Extensive experiments demonstrate that Sce2DriveX achieves\nstate-of-the-art performance from scene understanding to end-to-end driving, as\nwell as robust generalization on the CARLA Bench2Drive benchmark.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.14917v1",
    "published_date": "2025-02-19 09:50:44 UTC",
    "updated_date": "2025-02-19 09:50:44 UTC"
  },
  {
    "arxiv_id": "2502.14003v1",
    "title": "Rectified Lagrangian for Out-of-Distribution Detection in Modern Hopfield Networks",
    "authors": [
      "Ryo Moriai",
      "Nakamasa Inoue",
      "Masayuki Tanaka",
      "Rei Kawakami",
      "Satoshi Ikehata",
      "Ikuro Sato"
    ],
    "abstract": "Modern Hopfield networks (MHNs) have recently gained significant attention in\nthe field of artificial intelligence because they can store and retrieve a\nlarge set of patterns with an exponentially large memory capacity. A MHN is\ngenerally a dynamical system defined with Lagrangians of memory and feature\nneurons, where memories associated with in-distribution (ID) samples are\nrepresented by attractors in the feature space. One major problem in existing\nMHNs lies in managing out-of-distribution (OOD) samples because it was\noriginally assumed that all samples are ID samples. To address this, we propose\nthe rectified Lagrangian (RegLag), a new Lagrangian for memory neurons that\nexplicitly incorporates an attractor for OOD samples in the dynamical system of\nMHNs. RecLag creates a trivial point attractor for any interaction matrix,\nenabling OOD detection by identifying samples that fall into this attractor as\nOOD. The interaction matrix is optimized so that the probability densities can\nbe estimated to identify ID/OOD. We demonstrate the effectiveness of\nRecLag-based MHNs compared to energy-based OOD detection methods, including\nthose using state-of-the-art Hopfield energies, across nine image datasets.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.14003v1",
    "published_date": "2025-02-19 09:50:22 UTC",
    "updated_date": "2025-02-19 09:50:22 UTC"
  },
  {
    "arxiv_id": "2502.13576v1",
    "title": "Beyond One-Size-Fits-All: Tailored Benchmarks for Efficient Evaluation",
    "authors": [
      "Peiwen Yuan",
      "Yueqi Zhang",
      "Shaoxiong Feng",
      "Yiwei Li",
      "Xinglin Wang",
      "Jiayi Shi",
      "Chuyi Tan",
      "Boyuan Pan",
      "Yao Hu",
      "Kan Li"
    ],
    "abstract": "Evaluating models on large benchmarks is very resource-intensive, especially\nduring the period of rapid model evolution. Existing efficient evaluation\nmethods estimate the performance of target models by testing them only on a\nsmall and static coreset of the benchmark, which is derived from the publicly\navailable evaluation results of source models. These methods rely on the\nassumption that target models have high prediction consistency with source\nmodels. However, we demonstrate that it doesn't generalize well in practice. To\nalleviate the inconsistency issue, we present TailoredBench, a method that\nconducts customized evaluation tailored to each target model. Specifically, a\nGlobal-coreset is first constructed as a probe to identify the most consistent\nsource models for each target model with an adaptive source model selection\nstrategy. Afterwards, a scalable K-Medoids clustering algorithm is proposed to\nextend the Global-coreset to a tailored Native-coreset for each target model.\nAccording to the predictions on Native-coresets, we obtain the performance of\ntarget models on the whole benchmark with a calibrated estimation strategy.\nComprehensive experiments on 5 benchmarks across over 300 models demonstrate\nthat compared to best performing baselines, TailoredBench achieves an average\nreduction of 31.4% in MAE of accuracy estimates under the same inference\nbudgets, showcasing strong effectiveness and generalizability.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.13576v1",
    "published_date": "2025-02-19 09:31:50 UTC",
    "updated_date": "2025-02-19 09:31:50 UTC"
  },
  {
    "arxiv_id": "2502.13569v1",
    "title": "Model Evolution Framework with Genetic Algorithm for Multi-Task Reinforcement Learning",
    "authors": [
      "Yan Yu",
      "Wengang Zhou",
      "Yaodong Yang",
      "Wanxuan Lu",
      "Yingyan Hou",
      "Houqiang Li"
    ],
    "abstract": "Multi-task reinforcement learning employs a single policy to complete various\ntasks, aiming to develop an agent with generalizability across different\nscenarios. Given the shared characteristics of tasks, the agent's learning\nefficiency can be enhanced through parameter sharing. Existing approaches\ntypically use a routing network to generate specific routes for each task and\nreconstruct a set of modules into diverse models to complete multiple tasks\nsimultaneously. However, due to the inherent difference between tasks, it is\ncrucial to allocate resources based on task difficulty, which is constrained by\nthe model's structure. To this end, we propose a Model Evolution framework with\nGenetic Algorithm (MEGA), which enables the model to evolve during training\naccording to the difficulty of the tasks. When the current model is\ninsufficient for certain tasks, the framework will automatically incorporate\nadditional modules, enhancing the model's capabilities. Moreover, to adapt to\nour model evolution framework, we introduce a genotype module-level model,\nusing binary sequences as genotype policies for model reconstruction, while\nleveraging a non-gradient genetic algorithm to optimize these genotype\npolicies. Unlike routing networks with fixed output dimensions, our approach\nallows for the dynamic adjustment of the genotype policy length, enabling it to\naccommodate models with a varying number of modules. We conducted experiments\non various robotics manipulation tasks in the Meta-World benchmark. Our\nstate-of-the-art performance demonstrated the effectiveness of the MEGA\nframework. We will release our source code to the public.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.13569v1",
    "published_date": "2025-02-19 09:22:34 UTC",
    "updated_date": "2025-02-19 09:22:34 UTC"
  },
  {
    "arxiv_id": "2502.13562v1",
    "title": "Are Large Language Models In-Context Graph Learners?",
    "authors": [
      "Jintang Li",
      "Ruofan Wu",
      "Yuchang Zhu",
      "Huizhe Zhang",
      "Liang Chen",
      "Zibin Zheng"
    ],
    "abstract": "Large language models (LLMs) have demonstrated remarkable in-context\nreasoning capabilities across a wide range of tasks, particularly with\nunstructured inputs such as language or images. However, LLMs struggle to\nhandle structured data, such as graphs, due to their lack of understanding of\nnon-Euclidean structures. As a result, without additional fine-tuning, their\nperformance significantly lags behind that of graph neural networks (GNNs) in\ngraph learning tasks. In this paper, we show that learning on graph data can be\nconceptualized as a retrieval-augmented generation (RAG) process, where\nspecific instances (e.g., nodes or edges) act as queries, and the graph itself\nserves as the retrieved context. Building on this insight, we propose a series\nof RAG frameworks to enhance the in-context learning capabilities of LLMs for\ngraph learning tasks. Comprehensive evaluations demonstrate that our proposed\nRAG frameworks significantly improve LLM performance on graph-based tasks,\nparticularly in scenarios where a pretrained LLM must be used without\nmodification or accessed via an API.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Preprint, under review",
    "pdf_url": "http://arxiv.org/pdf/2502.13562v1",
    "published_date": "2025-02-19 09:14:19 UTC",
    "updated_date": "2025-02-19 09:14:19 UTC"
  },
  {
    "arxiv_id": "2502.13555v1",
    "title": "Democratizing Large Language Model-Based Graph Data Augmentation via Latent Knowledge Graphs",
    "authors": [
      "Yushi Feng",
      "Tsai Hor Chan",
      "Guosheng Yin",
      "Lequan Yu"
    ],
    "abstract": "Data augmentation is necessary for graph representation learning due to the\nscarcity and noise present in graph data. Most of the existing augmentation\nmethods overlook the context information inherited from the dataset as they\nrely solely on the graph structure for augmentation. Despite the success of\nsome large language model-based (LLM) graph learning methods, they are mostly\nwhite-box which require access to the weights or latent features from the\nopen-access LLMs, making them difficult to be democratized for everyone as\nexisting LLMs are mostly closed-source for commercial considerations. To\novercome these limitations, we propose a black-box context-driven graph data\naugmentation approach, with the guidance of LLMs -- DemoGraph. Leveraging the\ntext prompt as context-related information, we task the LLM with generating\nknowledge graphs (KGs), which allow us to capture the structural interactions\nfrom the text outputs. We then design a dynamic merging schema to\nstochastically integrate the LLM-generated KGs into the original graph during\ntraining. To control the sparsity of the augmented graph, we further devise a\ngranularity-aware prompting strategy and an instruction fine-tuning module,\nwhich seamlessly generates text prompts according to different granularity\nlevels of the dataset. Extensive experiments on various graph learning tasks\nvalidate the effectiveness of our method over existing graph data augmentation\nmethods. Notably, our approach excels in scenarios involving electronic health\nrecords (EHRs), which validates its maximal utilization of contextual\nknowledge, leading to enhanced predictive performance and interpretability.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.13555v1",
    "published_date": "2025-02-19 09:00:32 UTC",
    "updated_date": "2025-02-19 09:00:32 UTC"
  },
  {
    "arxiv_id": "2502.13544v2",
    "title": "From Sub-Ability Diagnosis to Human-Aligned Generation: Bridging the Gap for Text Length Control via MARKERGEN",
    "authors": [
      "Peiwen Yuan",
      "Chuyi Tan",
      "Shaoxiong Feng",
      "Yiwei Li",
      "Xinglin Wang",
      "Yueqi Zhang",
      "Jiayi Shi",
      "Boyuan Pan",
      "Yao Hu",
      "Kan Li"
    ],
    "abstract": "Despite the rapid progress of large language models (LLMs), their\nlength-controllable text generation (LCTG) ability remains below expectations,\nposing a major limitation for practical applications. Existing methods mainly\nfocus on end-to-end training to reinforce adherence to length constraints.\nHowever, the lack of decomposition and targeted enhancement of LCTG\nsub-abilities restricts further progress. To bridge this gap, we conduct a\nbottom-up decomposition of LCTG sub-abilities with human patterns as reference\nand perform a detailed error analysis. On this basis, we propose MarkerGen, a\nsimple-yet-effective plug-and-play approach that:(1) mitigates LLM fundamental\ndeficiencies via external tool integration;(2) conducts explicit length\nmodeling with dynamically inserted markers;(3) employs a three-stage generation\nscheme to better align length constraints while maintaining content quality.\nComprehensive experiments demonstrate that MarkerGen significantly improves\nLCTG across various settings, exhibiting outstanding effectiveness and\ngeneralizability.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.13544v2",
    "published_date": "2025-02-19 08:52:45 UTC",
    "updated_date": "2025-02-21 07:23:35 UTC"
  },
  {
    "arxiv_id": "2502.13542v1",
    "title": "Activation-aware Probe-Query: Effective Key-Value Retrieval for Long-Context LLMs Inference",
    "authors": [
      "Qingfa Xiao",
      "Jiachuan Wang",
      "Haoyang Li",
      "Cheng Deng",
      "Jiaqi Tang",
      "Shuangyin Li",
      "Yongqi Zhang",
      "Jun Wang",
      "Lei Chen"
    ],
    "abstract": "Recent advances in large language models (LLMs) have showcased exceptional\nperformance in long-context tasks, while facing significant inference\nefficiency challenges with limited GPU memory. Existing solutions first\nproposed the sliding-window approach to accumulate a set of historical\n\\textbf{key-value} (KV) pairs for reuse, then further improvements selectively\nretain its subsets at each step. However, due to the sparse attention\ndistribution across a long context, it is hard to identify and recall relevant\nKV pairs, as the attention is distracted by massive candidate pairs.\nAdditionally, we found it promising to select representative tokens as\nprobe-Query in each sliding window to effectively represent the entire context,\nwhich is an approach overlooked by existing methods. Thus, we propose\n\\textbf{ActQKV}, a training-free, \\textbf{Act}ivation-aware approach that\ndynamically determines probe-\\textbf{Q}uery and leverages it to retrieve the\nrelevant \\textbf{KV} pairs for inference. Specifically, ActQKV monitors a\ntoken-level indicator, Activation Bias, within each context window, enabling\nthe proper construction of probe-Query for retrieval at pre-filling stage. To\naccurately recall the relevant KV pairs and minimize the irrelevant ones, we\ndesign a dynamic KV cut-off mechanism guided by information density across\nlayers at the decoding stage. Experiments on the Long-Bench and $\\infty$\nBenchmarks demonstrate its state-of-the-art performance with competitive\ninference quality and resource efficiency.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.13542v1",
    "published_date": "2025-02-19 08:50:44 UTC",
    "updated_date": "2025-02-19 08:50:44 UTC"
  },
  {
    "arxiv_id": "2502.13534v2",
    "title": "Solving the encoding bottleneck: of the HHL algorithm, by the HHL algorithm",
    "authors": [
      "Guang Ping He"
    ],
    "abstract": "The Harrow-Hassidim-Lloyd (HHL) algorithm offers exponential speedup for\nsolving the quantum linear-system problem. But some caveats for the speedup\ncould be hard to met. One of the difficulties is the encoding bottleneck, i.e.,\nthe efficient preparation of the initial quantum state. To prepare an arbitrary\n$N$-dimensional state exactly, existing state-preparation approaches generally\nrequire a runtime of $O(N)$, which will ruin the speedup of the HHL algorithm.\nHere we show that the states can be prepared approximately with a runtime of\n$O(poly(\\log N))$ by employing a slightly modified version of the HHL algorithm\nitself. Thus, applying this approach to prepare the initial state of the\noriginal HHL algorithm can preserve the exponential speedup advantage. It can\nalso serve as a standalone solution for other applications demanding fast state\npreparation.",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "quant-ph",
    "comment": "Added a diagram of the quantum circuit of our algorithm",
    "pdf_url": "http://arxiv.org/pdf/2502.13534v2",
    "published_date": "2025-02-19 08:39:41 UTC",
    "updated_date": "2025-03-09 10:29:36 UTC"
  },
  {
    "arxiv_id": "2502.13533v2",
    "title": "Train Small, Infer Large: Memory-Efficient LoRA Training for Large Language Models",
    "authors": [
      "Jun Zhang",
      "Jue Wang",
      "Huan Li",
      "Lidan Shou",
      "Ke Chen",
      "Yang You",
      "Guiming Xie",
      "Xuejian Gong",
      "Kunlong Zhou"
    ],
    "abstract": "Large Language Models (LLMs) have significantly advanced natural language\nprocessing with exceptional task generalization capabilities. Low-Rank Adaption\n(LoRA) offers a cost-effective fine-tuning solution, freezing the original\nmodel parameters and training only lightweight, low-rank adapter matrices.\nHowever, the memory footprint of LoRA is largely dominated by the original\nmodel parameters. To mitigate this, we propose LoRAM, a memory-efficient LoRA\ntraining scheme founded on the intuition that many neurons in\nover-parameterized LLMs have low training utility but are essential for\ninference. LoRAM presents a unique twist: it trains on a pruned (small) model\nto obtain pruned low-rank matrices, which are then recovered and utilized with\nthe original (large) model for inference. Additionally, minimal-cost continual\npre-training, performed by the model publishers in advance, aligns the\nknowledge discrepancy between pruned and original models. Our extensive\nexperiments demonstrate the efficacy of LoRAM across various pruning strategies\nand downstream tasks. For a model with 70 billion parameters, LoRAM enables\ntraining on a GPU with only 20G HBM, replacing an A100-80G GPU for LoRA\ntraining and 15 GPUs for full fine-tuning. Specifically, QLoRAM implemented by\nstructured pruning combined with 4-bit quantization, for LLaMA-3.1-70B\n(LLaMA-2-70B), reduces the parameter storage cost that dominates the memory\nusage in low-rank matrix training by 15.81$\\times$ (16.95$\\times$), while\nachieving dominant performance gains over both the original LLaMA-3.1-70B\n(LLaMA-2-70B) and LoRA-trained LLaMA-3.1-8B (LLaMA-2-13B). Code is available at\nhttps://github.com/junzhang-zj/LoRAM.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.13533v2",
    "published_date": "2025-02-19 08:39:15 UTC",
    "updated_date": "2025-03-15 04:12:52 UTC"
  },
  {
    "arxiv_id": "2502.13527v1",
    "title": "Exploiting Prefix-Tree in Structured Output Interfaces for Enhancing Jailbreak Attacking",
    "authors": [
      "Yanzeng Li",
      "Yunfan Xiong",
      "Jialun Zhong",
      "Jinchao Zhang",
      "Jie Zhou",
      "Lei Zou"
    ],
    "abstract": "The rise of Large Language Models (LLMs) has led to significant applications\nbut also introduced serious security threats, particularly from jailbreak\nattacks that manipulate output generation. These attacks utilize prompt\nengineering and logit manipulation to steer models toward harmful content,\nprompting LLM providers to implement filtering and safety alignment strategies.\nWe investigate LLMs' safety mechanisms and their recent applications, revealing\na new threat model targeting structured output interfaces, which enable\nattackers to manipulate the inner logit during LLM generation, requiring only\nAPI access permissions. To demonstrate this threat model, we introduce a\nblack-box attack framework called AttackPrefixTree (APT). APT exploits\nstructured output interfaces to dynamically construct attack patterns. By\nleveraging prefixes of models' safety refusal response and latent harmful\noutputs, APT effectively bypasses safety measures. Experiments on benchmark\ndatasets indicate that this approach achieves higher attack success rate than\nexisting methods. This work highlights the urgent need for LLM providers to\nenhance security protocols to address vulnerabilities arising from the\ninteraction between safety patterns and structured outputs.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.13527v1",
    "published_date": "2025-02-19 08:29:36 UTC",
    "updated_date": "2025-02-19 08:29:36 UTC"
  },
  {
    "arxiv_id": "2503.05733v1",
    "title": "Design an Ontology for Cognitive Business Strategy Based on Customer Satisfaction",
    "authors": [
      "Neda Bagherzadeh",
      "Saeed Setayeshi",
      "Samaneh Yazdani"
    ],
    "abstract": "Ontology is a general term used by researchers who want to share information\nin a specific domain. One of the hallmarks of the greatest success of a\npowerful manager of an organization is his ability to interpret unplanned and\nunrelated events. Tools to solve this problem are vital to business growth.\nModern technology allows customers to be more informed and influential in their\nroles as patrons and critics. This can make or break a business. Research shows\nthat businesses that employ a customer-first strategy and prioritize their\ncustomers can generate more revenue. Even though there are many different\nOntologies offered to businesses, none of it is built from a cognitive\nperspective. The objective of this study is to address the concept of strategic\nbusiness plans with a cognitive ontology approach as a basis for a new\nmanagement tool. This research proposes to design a cognitive ontology model\nthat links customer measurement with traditional business models, define\nrelationships between components and verify the accuracy of the added financial\nvalue.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.05733v1",
    "published_date": "2025-02-19 08:29:23 UTC",
    "updated_date": "2025-02-19 08:29:23 UTC"
  },
  {
    "arxiv_id": "2502.13524v4",
    "title": "MobileViM: A Light-weight and Dimension-independent Vision Mamba for 3D Medical Image Analysis",
    "authors": [
      "Wei Dai",
      "Jun Liu"
    ],
    "abstract": "Efficient evaluation of three-dimensional (3D) medical images is crucial for\ndiagnostic and therapeutic practices in healthcare. Recent years have seen a\nsubstantial uptake in applying deep learning and computer vision to analyse and\ninterpret medical images. Traditional approaches, such as convolutional neural\nnetworks (CNNs) and vision transformers (ViTs), face significant computational\nchallenges, prompting the need for architectural advancements. Recent efforts\nhave led to the introduction of novel architectures like the ``Mamba'' model as\nalternative solutions to traditional CNNs or ViTs. The Mamba model excels in\nthe linear processing of one-dimensional data with low computational demands.\nHowever, Mamba's potential for 3D medical image analysis remains underexplored\nand could face significant computational challenges as the dimension increases.\nThis manuscript presents MobileViM, a streamlined architecture for efficient\nsegmentation of 3D medical images. In the MobileViM network, we invent a new\ndimension-independent mechanism and a dual-direction traversing approach to\nincorporate with a vision-Mamba-based framework. MobileViM also features a\ncross-scale bridging technique to improve efficiency and accuracy across\nvarious medical imaging modalities. With these enhancements, MobileViM achieves\nsegmentation speeds exceeding 90 frames per second (FPS) on a single graphics\nprocessing unit (i.e., NVIDIA RTX 4090). This performance is over 24 FPS faster\nthan the state-of-the-art deep learning models for processing 3D images with\nthe same computational resources. In addition, experimental evaluations\ndemonstrate that MobileViM delivers superior performance, with Dice similarity\nscores reaching 92.72%, 86.69%, 80.46%, and 77.43% for PENGWIN, BraTS2024,\nATLAS, and Toothfairy2 datasets, respectively, which significantly surpasses\nexisting models.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.NI"
    ],
    "primary_category": "cs.CV",
    "comment": "The corresponding author disagrees with the manuscript submitted to\n  arXiv",
    "pdf_url": "http://arxiv.org/pdf/2502.13524v4",
    "published_date": "2025-02-19 08:21:59 UTC",
    "updated_date": "2025-03-06 14:27:12 UTC"
  },
  {
    "arxiv_id": "2502.13519v1",
    "title": "MILE: Model-based Intervention Learning",
    "authors": [
      "Yigit Korkmaz",
      "Erdem Bıyık"
    ],
    "abstract": "Imitation learning techniques have been shown to be highly effective in\nreal-world control scenarios, such as robotics. However, these approaches not\nonly suffer from compounding error issues but also require human experts to\nprovide complete trajectories. Although there exist interactive methods where\nan expert oversees the robot and intervenes if needed, these extensions usually\nonly utilize the data collected during intervention periods and ignore the\nfeedback signal hidden in non-intervention timesteps. In this work, we create a\nmodel to formulate how the interventions occur in such cases, and show that it\nis possible to learn a policy with just a handful of expert interventions. Our\nkey insight is that it is possible to get crucial information about the quality\nof the current state and the optimality of the chosen action from expert\nfeedback, regardless of the presence or the absence of intervention. We\nevaluate our method on various discrete and continuous simulation environments,\na real-world robotic manipulation task, as well as a human subject study.\nVideos and the code can be found at https://liralab.usc.edu/mile .",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "International Conference on Robotics and Automation (ICRA)",
    "pdf_url": "http://arxiv.org/pdf/2502.13519v1",
    "published_date": "2025-02-19 08:15:16 UTC",
    "updated_date": "2025-02-19 08:15:16 UTC"
  },
  {
    "arxiv_id": "2502.13516v1",
    "title": "SPPD: Self-training with Process Preference Learning Using Dynamic Value Margin",
    "authors": [
      "Hao Yi",
      "Qingyang Li",
      "Yulan Hu",
      "Fuzheng Zhang",
      "Di Zhang",
      "Yong Liu"
    ],
    "abstract": "Recently, enhancing the numerical and logical reasoning capability of Large\nLanguage Models (LLMs) has emerged as a research hotspot. Existing methods face\nseveral limitations: inference-phase techniques (e.g., Chain of Thoughts) rely\non prompt selection and the pretrained knowledge; sentence-level Supervised\nFine-Tuning (SFT) and Direct Preference Optimization (DPO) struggle with\nstep-wise mathematical correctness and depend on stronger models distillation\nor human annotations; while Reinforcement Learning (RL) approaches incur high\nGPU memory costs and unstable training. To address these, we propose\n\\textbf{S}elf-training framework integrating \\textbf{P}rocess\n\\textbf{P}reference learning using \\textbf{D}ynamic value margin (SPPD). SPPD\nleverages a process-based Markov Decision Process (MDP) and Bellman optimality\nequation to derive \\textbf{dynamic value margin} on step-level preference\noptimization, which employs tree-based self-sampling on model responses\n\\textbf{without any distillation} from other models. Furthermore, we\ntheoretically prove that SPPD is \\textbf{equivalent to on-policy policy\ngradient methods} under reward constraints. Experiments on 7B-scale models\ndemonstrate superior performance across in-domain and out-domain mathematical\nbenchmarks. We open-source our code at\n\\href{https://anonymous.4open.science/r/SSDPO-D-DCDD}{https://anonymous.4open.science/r/SPPD-DCDD}.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.13516v1",
    "published_date": "2025-02-19 08:11:26 UTC",
    "updated_date": "2025-02-19 08:11:26 UTC"
  },
  {
    "arxiv_id": "2502.14916v2",
    "title": "MKE-Coder: Multi-Axial Knowledge with Evidence Verification in ICD Coding for Chinese EMRs",
    "authors": [
      "Xinxin You",
      "Xien Liu",
      "Xue Yang",
      "Ziyi Wang",
      "Ji Wu"
    ],
    "abstract": "The task of automatically coding the International Classification of Diseases\n(ICD) in the medical field has been well-established and has received much\nattention. Automatic coding of the ICD in the medical field has been successful\nin English but faces challenges when dealing with Chinese electronic medical\nrecords (EMRs). The first issue lies in the difficulty of extracting disease\ncode-related information from Chinese EMRs, primarily due to the concise\nwriting style and specific internal structure of the EMRs. The second problem\nis that previous methods have failed to leverage the disease-based multi-axial\nknowledge and lack of association with the corresponding clinical evidence.\nThis paper introduces a novel framework called MKE-Coder: Multi-axial Knowledge\nwith Evidence verification in ICD coding for Chinese EMRs. Initially, we\nidentify candidate codes for the diagnosis and categorize each of them into\nknowledge under four coding axes.Subsequently, we retrieve corresponding\nclinical evidence from the comprehensive content of EMRs and filter credible\nevidence through a scoring model. Finally, to ensure the validity of the\ncandidate code, we propose an inference module based on the masked language\nmodeling strategy. This module verifies that all the axis knowledge associated\nwith the candidate code is supported by evidence and provides recommendations\naccordingly. To evaluate the performance of our framework, we conduct\nexperiments using a large-scale Chinese EMR dataset collected from various\nhospitals. The experimental results demonstrate that MKE-Coder exhibits\nsignificant superiority in the task of automatic ICD coding based on Chinese\nEMRs. In the practical evaluation of our method within simulated real coding\nscenarios, it has been demonstrated that our approach significantly aids coders\nin enhancing both their coding accuracy and speed.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.14916v2",
    "published_date": "2025-02-19 08:08:53 UTC",
    "updated_date": "2025-02-26 04:35:15 UTC"
  },
  {
    "arxiv_id": "2502.13509v1",
    "title": "Unlocking Multimodal Integration in EHRs: A Prompt Learning Framework for Language and Time Series Fusion",
    "authors": [
      "Shuai Niu",
      "Jing Ma",
      "Hongzhan Lin",
      "Liang Bai",
      "Zhihua Wang",
      "Wei Bi",
      "Yida Xu",
      "Guo Li",
      "Xian Yang"
    ],
    "abstract": "Large language models (LLMs) have shown remarkable performance in\nvision-language tasks, but their application in the medical field remains\nunderexplored, particularly for integrating structured time series data with\nunstructured clinical notes. In clinical practice, dynamic time series data\nsuch as lab test results capture critical temporal patterns, while clinical\nnotes provide rich semantic context. Merging these modalities is challenging\ndue to the inherent differences between continuous signals and discrete text.\nTo bridge this gap, we introduce ProMedTS, a novel self-supervised multimodal\nframework that employs prompt-guided learning to unify these heterogeneous data\ntypes. Our approach leverages lightweight anomaly detection to generate anomaly\ncaptions that serve as prompts, guiding the encoding of raw time series data\ninto informative embeddings. These embeddings are aligned with textual\nrepresentations in a shared latent space, preserving fine-grained temporal\nnuances alongside semantic insights. Furthermore, our framework incorporates\ntailored self-supervised objectives to enhance both intra- and inter-modal\nalignment. We evaluate ProMedTS on disease diagnosis tasks using real-world\ndatasets, and the results demonstrate that our method consistently outperforms\nstate-of-the-art approaches.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "68T50",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "13 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.13509v1",
    "published_date": "2025-02-19 07:56:48 UTC",
    "updated_date": "2025-02-19 07:56:48 UTC"
  },
  {
    "arxiv_id": "2502.14001v1",
    "title": "Towards a perturbation-based explanation for medical AI as differentiable programs",
    "authors": [
      "Takeshi Abe",
      "Yoshiyuki Asai"
    ],
    "abstract": "Recent advancement in machine learning algorithms reaches a point where\nmedical devices can be equipped with artificial intelligence (AI) models for\ndiagnostic support and routine automation in clinical settings. In medicine and\nhealthcare, there is a particular demand for sufficient and objective\nexplainability of the outcome generated by AI models. However, AI models are\ngenerally considered as black boxes due to their complexity, and the\ncomputational process leading to their response is often opaque. Although\nseveral methods have been proposed to explain the behavior of models by\nevaluating the importance of each feature in discrimination and prediction,\nthey may suffer from biases and opacities arising from the scale and sampling\nprotocol of the dataset used for training or testing. To overcome the\nshortcomings of existing methods, we explore an alternative approach to provide\nan objective explanation of AI models that can be defined independently of the\nlearning process and does not require additional data. As a preliminary study\nfor this direction of research, this work examines a numerical availability of\nthe Jacobian matrix of deep learning models that measures how stably a model\nresponses against small perturbations added to the input. The indicator, if\navailable, are calculated from a trained AI model for a given target input.\nThis is a first step towards a perturbation-based explanation, which will\nassist medical practitioners in understanding and interpreting the response of\nthe AI model in its clinical application.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "stat.ML",
    "comment": "7 pages, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2502.14001v1",
    "published_date": "2025-02-19 07:56:23 UTC",
    "updated_date": "2025-02-19 07:56:23 UTC"
  },
  {
    "arxiv_id": "2502.14000v1",
    "title": "Human-Artificial Interaction in the Age of Agentic AI: A System-Theoretical Approach",
    "authors": [
      "Uwe M. Borghoff",
      "Paolo Bottoni",
      "Remo Pareschi"
    ],
    "abstract": "This paper presents a novel perspective on human-computer interaction (HCI),\nframing it as a dynamic interplay between human and computational agents within\na networked system. Going beyond traditional interface-based approaches, we\nemphasize the importance of coordination and communication among heterogeneous\nagents with different capabilities, roles, and goals. A key distinction is made\nbetween multi-agent systems (MAS) and Centaurian systems, which represent two\ndifferent paradigms of human-AI collaboration. MAS maintain agent autonomy,\nwith structured protocols enabling cooperation, while Centaurian systems deeply\nintegrate human and AI capabilities, creating unified decision-making entities.\n  To formalize these interactions, we introduce a framework for communication\nspaces, structured into surface, observation, and computation layers, ensuring\nseamless integration between MAS and Centaurian architectures, where colored\nPetri nets effectively represent structured Centaurian systems and high-level\nreconfigurable networks address the dynamic nature of MAS.\n  Our research has practical applications in autonomous robotics,\nhuman-in-the-loop decision making, and AI-driven cognitive architectures, and\nprovides a foundation for next-generation hybrid intelligence systems that\nbalance structured coordination with emergent behavior.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.MA",
    "comment": "27 pages, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.14000v1",
    "published_date": "2025-02-19 07:55:34 UTC",
    "updated_date": "2025-02-19 07:55:34 UTC"
  },
  {
    "arxiv_id": "2502.14913v1",
    "title": "OpenSearch-SQL: Enhancing Text-to-SQL with Dynamic Few-shot and Consistency Alignment",
    "authors": [
      "Xiangjin Xie",
      "Guangwei Xu",
      "Lingyan Zhao",
      "Ruijie Guo"
    ],
    "abstract": "Although multi-agent collaborative Large Language Models (LLMs) have achieved\nsignificant breakthroughs in the Text-to-SQL task, their performance is still\nconstrained by various factors. These factors include the incompleteness of the\nframework, failure to follow instructions, and model hallucination problems. To\naddress these problems, we propose OpenSearch-SQL, which divides the\nText-to-SQL task into four main modules: Preprocessing, Extraction, Generation,\nand Refinement, along with an Alignment module based on a consistency alignment\nmechanism. This architecture aligns the inputs and outputs of agents through\nthe Alignment module, reducing failures in instruction following and\nhallucination. Additionally, we designed an intermediate language called\nSQL-Like and optimized the structured CoT based on SQL-Like. Meanwhile, we\ndeveloped a dynamic few-shot strategy in the form of self-taught Query-CoT-SQL.\nThese methods have significantly improved the performance of LLMs in the\nText-to-SQL task.\n  In terms of model selection, we directly applied the base LLMs without any\npost-training, thereby simplifying the task chain and enhancing the framework's\nportability. Experimental results show that OpenSearch-SQL achieves an\nexecution accuracy(EX) of 69.3% on the BIRD development set, 72.28% on the test\nset, and a reward-based validity efficiency score (R-VES) of 69.36%, with all\nthree metrics ranking first at the time of submission. These results\ndemonstrate the comprehensive advantages of the proposed method in both\neffectiveness and efficiency.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "15 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.14913v1",
    "published_date": "2025-02-19 07:51:50 UTC",
    "updated_date": "2025-02-19 07:51:50 UTC"
  },
  {
    "arxiv_id": "2502.13502v2",
    "title": "PLDR-LLMs Learn A Generalizable Tensor Operator That Can Replace Its Own Deep Neural Net At Inference",
    "authors": [
      "Burc Gokden"
    ],
    "abstract": "We show that Large Language Model from Power Law Decoder Representations\n(PLDR-LLM) is a foundational model whose deductive outputs are invariant\ntensors up to a small perturbation. PLDR-LLM learns a singularity condition for\nthe deductive outputs that enable the once-inferred energy-curvature tensor\n$\\mathbf{G}_{LM}$ to replace the deep neural network of power law graph\nattention (PLGA) generating the deductive outputs at inference. We demonstrate\nthat a cache for $\\mathbf{G}_{LM}$ (G-cache) and KV-cache can be implemented in\na straightforward manner to improve the inference time. The invariance and\ngeneralizable nature of deductive outputs is at a very high fidelity where\ndeductive outputs have same RMSE and determinant values up to 15 decimal places\nafter caching, and zero-shot benchmark scores remain unchanged. Ablation\nstudies show that learned deductive outputs have distinct loss and accuracy\ncharacteristics from models pretrained with transferred, randomly initialized\nor identity tensors as a constant tensor operator and an LLM with scaled-dot\nproduct attention (SDPA) is a special case of PLDR-LLM where $\\mathbf{G}_{LM}$\nis predefined as identity. The observed invariance characteristic introduces a\nnovel asymmetry between training and inference phases with caching. We outline\nobserved common characteristics of the deductive outputs for the learned\nsingularity condition. We provide an implementation of a training and inference\nframework for PLDR-LLM with KV-cache and G-cache.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "15 pages, 1 figure, 12 tables, more ablation data included",
    "pdf_url": "http://arxiv.org/pdf/2502.13502v2",
    "published_date": "2025-02-19 07:43:36 UTC",
    "updated_date": "2025-02-22 22:32:08 UTC"
  },
  {
    "arxiv_id": "2502.13499v1",
    "title": "Hidden Darkness in LLM-Generated Designs: Exploring Dark Patterns in Ecommerce Web Components Generated by LLMs",
    "authors": [
      "Ziwei Chen",
      "Jiawen Shen",
      "Luna",
      "Kristen Vaccaro"
    ],
    "abstract": "Recent work has highlighted the risks of LLM-generated content for a wide\nrange of harmful behaviors, including incorrect and harmful code. In this work,\nwe extend this by studying whether LLM-generated web design contains dark\npatterns. This work evaluated designs of ecommerce web components generated by\nfour popular LLMs: Claude, GPT, Gemini, and Llama. We tested 13 commonly used\necommerce components (e.g., search, product reviews) and used them as prompts\nto generate a total of 312 components across all models. Over one-third of\ngenerated components contain at least one dark pattern. The majority of dark\npattern strategies involve hiding crucial information, limiting users' actions,\nand manipulating them into making decisions through a sense of urgency. Dark\npatterns are also more frequently produced in components that are related to\ncompany interests. These findings highlight the need for interventions to\nprevent dark patterns during front-end code generation with LLMs and emphasize\nthe importance of expanding ethical design education to a broader audience.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.HC",
    "comment": "15 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.13499v1",
    "published_date": "2025-02-19 07:35:07 UTC",
    "updated_date": "2025-02-19 07:35:07 UTC"
  },
  {
    "arxiv_id": "2502.13998v1",
    "title": "A Baseline Method for Removing Invisible Image Watermarks using Deep Image Prior",
    "authors": [
      "Hengyue Liang",
      "Taihui Li",
      "Ju Sun"
    ],
    "abstract": "Image watermarks have been considered a promising technique to help detect\nAI-generated content, which can be used to protect copyright or prevent fake\nimage abuse. In this work, we present a black-box method for removing invisible\nimage watermarks, without the need of any dataset of watermarked images or any\nknowledge about the watermark system. Our approach is simple to implement:\ngiven a single watermarked image, we regress it by deep image prior (DIP). We\nshow that from the intermediate steps of DIP one can reliably find an evasion\nimage that can remove invisible watermarks while preserving high image quality.\nDue to its unique working mechanism and practical effectiveness, we advocate\nincluding DIP as a baseline invasion method for benchmarking the robustness of\nwatermarking systems. Finally, by showing the limited ability of DIP and other\nexisting black-box methods in evading training-based visible watermarks, we\ndiscuss the positive implications on the practical use of training-based\nvisible watermarks to prevent misinformation abuse.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CR",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.13998v1",
    "published_date": "2025-02-19 07:30:19 UTC",
    "updated_date": "2025-02-19 07:30:19 UTC"
  },
  {
    "arxiv_id": "2502.13497v2",
    "title": "Towards Geo-Culturally Grounded LLM Generations",
    "authors": [
      "Piyawat Lertvittayakumjorn",
      "David Kinney",
      "Vinodkumar Prabhakaran",
      "Donald Martin Jr.",
      "Sunipa Dev"
    ],
    "abstract": "Generative large language models (LLMs) have been demonstrated to have gaps\nin diverse, cultural knowledge across the globe. We investigate the effect of\nretrieval augmented generation and search-grounding techniques on the ability\nof LLMs to display familiarity with a diverse range of national cultures.\nSpecifically, we compare the performance of standard LLMs, LLMs augmented with\nretrievals from a bespoke knowledge base (i.e., KB grounding), and LLMs\naugmented with retrievals from a web search (i.e., search grounding) on a\nseries of cultural familiarity benchmarks. We find that search grounding\nsignificantly improves the LLM performance on multiple-choice benchmarks that\ntest propositional knowledge (e.g., the norms, artifacts, and institutions of\nnational cultures), while KB grounding's effectiveness is limited by inadequate\nknowledge base coverage and a suboptimal retriever. However, search grounding\nalso increases the risk of stereotypical judgments by language models, while\nfailing to improve evaluators' judgments of cultural familiarity in a human\nevaluation with adequate statistical power. These results highlight the\ndistinction between propositional knowledge about a culture and open-ended\ncultural fluency when it comes to evaluating the cultural familiarity of\ngenerative LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.13497v2",
    "published_date": "2025-02-19 07:29:58 UTC",
    "updated_date": "2025-02-20 06:38:50 UTC"
  },
  {
    "arxiv_id": "2502.15806v1",
    "title": "A Mousetrap: Fooling Large Reasoning Models for Jailbreak with Chain of Iterative Chaos",
    "authors": [
      "Yang Yao",
      "Xuan Tong",
      "Ruofan Wang",
      "Yixu Wang",
      "Lujundong Li",
      "Liang Liu",
      "Yan Teng",
      "Yingchun Wang"
    ],
    "abstract": "Large Reasoning Models (LRMs) have significantly advanced beyond traditional\nLarge Language Models (LLMs) with their exceptional logical reasoning\ncapabilities, yet these improvements introduce heightened safety risks. When\nsubjected to jailbreak attacks, their ability to generate more targeted and\norganized content can lead to greater harm. Although some studies claim that\nreasoning enables safer LRMs against existing LLM attacks, they overlook the\ninherent flaws within the reasoning process itself. To address this gap, we\npropose the first jailbreak attack targeting LRMs, exploiting their unique\nvulnerabilities stemming from the advanced reasoning capabilities.\nSpecifically, we introduce a Chaos Machine, a novel component to transform\nattack prompts with diverse one-to-one mappings. The chaos mappings iteratively\ngenerated by the machine are embedded into the reasoning chain, which\nstrengthens the variability and complexity and also promotes a more robust\nattack. Based on this, we construct the Mousetrap framework, which makes\nattacks projected into nonlinear-like low sample spaces with mismatched\ngeneralization enhanced. Also, due to the more competing objectives, LRMs\ngradually maintain the inertia of unpredictable iterative reasoning and fall\ninto our trap. Success rates of the Mousetrap attacking o1-mini, claude-sonnet\nand gemini-thinking are as high as 96%, 86% and 98% respectively on our toxic\ndataset Trotter. On benchmarks such as AdvBench, StrongREJECT, and HarmBench,\nattacking claude-sonnet, well-known for its safety, Mousetrap can astonishingly\nachieve success rates of 87.5%, 86.58% and 93.13% respectively. Attention: This\npaper contains inappropriate, offensive and harmful content.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15806v1",
    "published_date": "2025-02-19 07:23:36 UTC",
    "updated_date": "2025-02-19 07:23:36 UTC"
  },
  {
    "arxiv_id": "2502.13490v1",
    "title": "What are Models Thinking about? Understanding Large Language Model Hallucinations \"Psychology\" through Model Inner State Analysis",
    "authors": [
      "Peiran Wang",
      "Yang Liu",
      "Yunfei Lu",
      "Jue Hong",
      "Ye Wu"
    ],
    "abstract": "Large language model (LLM) systems suffer from the models' unstable ability\nto generate valid and factual content, resulting in hallucination generation.\nCurrent hallucination detection methods heavily rely on out-of-model\ninformation sources, such as RAG to assist the detection, thus bringing heavy\nadditional latency. Recently, internal states of LLMs' inference have been\nwidely used in numerous research works, such as prompt injection detection,\netc. Considering the interpretability of LLM internal states and the fact that\nthey do not require external information sources, we introduce such states into\nLLM hallucination detection. In this paper, we systematically analyze different\ninternal states' revealing features during inference forward and\ncomprehensively evaluate their ability in hallucination detection.\nSpecifically, we cut the forward process of a large language model into three\nstages: understanding, query, generation, and extracting the internal state\nfrom these stages. By analyzing these states, we provide a deep understanding\nof why the hallucinated content is generated and what happened in the internal\nstate of the models. Then, we introduce these internal states into\nhallucination detection and conduct comprehensive experiments to discuss the\nadvantages and limitations.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.13490v1",
    "published_date": "2025-02-19 07:23:18 UTC",
    "updated_date": "2025-02-19 07:23:18 UTC"
  },
  {
    "arxiv_id": "2502.13487v2",
    "title": "Transferring Textual Preferences to Vision-Language Understanding through Model Merging",
    "authors": [
      "Chen-An Li",
      "Tzu-Han Lin",
      "Yun-Nung Chen",
      "Hung-yi Lee"
    ],
    "abstract": "Large vision-language models (LVLMs) perform outstandingly across various\nmultimodal tasks. However, their ability to evaluate generated content remains\nlimited, and training vision-language reward models (VLRMs) with preference\ndata is computationally expensive. This paper explores a training-free\nalternative by merging text-based reward models (RMs) with LVLMs to create\nVLRMs. Our approach shows that integrating these models leads to improved\nperformance over LVLMs' scoring and text-based RMs, offering an efficient\nmethod for incorporating textual preferences into LVLMs.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to ACL 2025 main",
    "pdf_url": "http://arxiv.org/pdf/2502.13487v2",
    "published_date": "2025-02-19 07:20:07 UTC",
    "updated_date": "2025-05-22 10:28:32 UTC"
  },
  {
    "arxiv_id": "2502.13480v1",
    "title": "Astra: Efficient and Money-saving Automatic Parallel Strategies Search on Heterogeneous GPUs",
    "authors": [
      "Peiran Wang",
      "Haibing Li",
      "Fu Haohan",
      "Shiyong Li",
      "Yanpeng Wang",
      "Dou Shen"
    ],
    "abstract": "In this paper, we introduce an efficient and money-saving automatic parallel\nstrategies search framework on heterogeneous GPUs: Astra. First, Astra searches\nfor the efficiency-optimal parallel strategy in both GPU configurations search\nspace (GPU types and GPU numbers) and parallel parameters search space. Then,\nAstra also provides the solution on heterogeneous GPUs by mathematically\nmodeling the time consumption of heterogeneous training. At last, Astra is the\nfirst to propose the automatic parallel strategy search on money-saving. The\nexperiment results demonstrate that Astra can achieve better throughput than\nexpert-designed strategies. The search time cost for Astra can also be limited\nto 1.27 seconds in a single-GPU setting and less than 1.35 minutes in a\nheterogeneous-GPU setting on average with an accuracy of over 95%.",
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.13480v1",
    "published_date": "2025-02-19 07:08:37 UTC",
    "updated_date": "2025-02-19 07:08:37 UTC"
  },
  {
    "arxiv_id": "2502.14911v1",
    "title": "Batayan: A Filipino NLP benchmark for evaluating Large Language Models",
    "authors": [
      "Jann Railey Montalan",
      "Jimson Paulo Layacan",
      "David Demitri Africa",
      "Richell Isaiah Flores",
      "Michael T. Lopez II",
      "Theresa Denise Magsajo",
      "Anjanette Cayabyab",
      "William Chandra Tjhi"
    ],
    "abstract": "Recent advances in large language models (LLMs) have demonstrated remarkable\ncapabilities on widely benchmarked high-resource languages; however, linguistic\nnuances of under-resourced languages remain unexplored. We introduce Batayan, a\nholistic Filipino benchmark designed to systematically evaluate LLMs across\nthree key natural language processing (NLP) competencies: understanding,\nreasoning, and generation. Batayan consolidates eight tasks, covering both\nTagalog and code-switched Taglish utterances. Our rigorous,\nnative-speaker-driven annotation process ensures fluency and authenticity to\nthe complex morphological and syntactic structures of Filipino, alleviating a\npervasive translationese bias in existing Filipino corpora. We report empirical\nresults on a variety of multilingual LLMs, highlighting significant performance\ngaps that signal the under-representation of Filipino in pretraining corpora,\nthe unique hurdles in modeling Filipino's rich morphology and construction, and\nthe importance of explicit Filipino language support and instruction tuning.\nMoreover, we discuss the practical challenges encountered in dataset\nconstruction and propose principled solutions for building culturally and\nlinguistically-faithful resources in under-represented languages. We also\nprovide a public benchmark and leaderboard as a clear foundation for iterative,\ncommunity-driven progress in Filipino NLP.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Submitted to ACL 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.14911v1",
    "published_date": "2025-02-19 07:03:15 UTC",
    "updated_date": "2025-02-19 07:03:15 UTC"
  },
  {
    "arxiv_id": "2502.15805v1",
    "title": "FragFM: Efficient Fragment-Based Molecular Generation via Discrete Flow Matching",
    "authors": [
      "Joongwon Lee",
      "Seonghwan Kim",
      "Wou Youn Kim"
    ],
    "abstract": "We introduce FragFM, a novel fragment-based discrete flow matching framework\nfor molecular graph generation.FragFM generates molecules at the fragment\nlevel, leveraging a coarse-to-fine autoencoding mechanism to reconstruct\natom-level details. This approach reduces computational complexity while\nmaintaining high chemical validity, enabling more efficient and scalable\nmolecular generation. We benchmark FragFM against state-of-the-art diffusion-\nand flow-based models on standard molecular generation benchmarks and natural\nproduct datasets, demonstrating superior performance in validity, property\ncontrol, and sampling efficiency. Notably, FragFM achieves over 99\\% validity\nwith significantly fewer sampling steps, improving scalability while preserving\nmolecular diversity. These results highlight the potential of fragment-based\ngenerative modeling for large-scale, property-aware molecular design, paving\nthe way for more efficient exploration of chemical space.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.chem-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "19 pages, 11 figures, under review",
    "pdf_url": "http://arxiv.org/pdf/2502.15805v1",
    "published_date": "2025-02-19 07:01:00 UTC",
    "updated_date": "2025-02-19 07:01:00 UTC"
  },
  {
    "arxiv_id": "2502.13476v1",
    "title": "Integration of Agentic AI with 6G Networks for Mission-Critical Applications: Use-case and Challenges",
    "authors": [
      "Sunder Ali Khowaja",
      "Kapal Dev",
      "Muhammad Salman Pathan",
      "Engin Zeydan",
      "Merouane Debbah"
    ],
    "abstract": "We are in a transformative era, and advances in Artificial Intelligence (AI),\nespecially the foundational models, are constantly in the news. AI has been an\nintegral part of many applications that rely on automation for service\ndelivery, and one of them is mission-critical public safety applications. The\nproblem with AI-oriented mission-critical applications is the humanin-the-loop\nsystem and the lack of adaptability to dynamic conditions while maintaining\nsituational awareness. Agentic AI (AAI) has gained a lot of attention recently\ndue to its ability to analyze textual data through a contextual lens while\nquickly adapting to conditions. In this context, this paper proposes an AAI\nframework for mission-critical applications. We propose a novel framework with\na multi-layer architecture to realize the AAI. We also present a detailed\nimplementation of AAI layer that bridges the gap between network infrastructure\nand missioncritical applications. Our preliminary analysis shows that the AAI\nreduces initial response time by 5.6 minutes on average, while alert generation\ntime is reduced by 15.6 seconds on average and resource allocation is improved\nby up to 13.4%. We also show that the AAI methods improve the number of\nconcurrent operations by 40, which reduces the recovery time by up to 5.2\nminutes. Finally, we highlight some of the issues and challenges that need to\nbe considered when implementing AAI frameworks.",
    "categories": [
      "cs.AI",
      "cs.NI"
    ],
    "primary_category": "cs.AI",
    "comment": "FEMA\n  [https://www.fema.gov/openfema-data-page/disaster-declarations-summaries-v2]\n  National Oceanic and Atmospheric Administration\n  [https://www.ncdc.noaa.gov/stormevents/details.jsp] packages Pytorch\n  [https://pytorch.org/] RLib [https://docs.ray.io/en/latest/rllib/index.html]\n  Neo4j [https://neo4j.com/] Apache Kafka [https://kafka.apache.org/]",
    "pdf_url": "http://arxiv.org/pdf/2502.13476v1",
    "published_date": "2025-02-19 07:00:53 UTC",
    "updated_date": "2025-02-19 07:00:53 UTC"
  },
  {
    "arxiv_id": "2502.13475v2",
    "title": "LLM should think and action as a human",
    "authors": [
      "Haun Leung",
      "ZiNan Wang"
    ],
    "abstract": "It is popular lately to train large language models to be used as chat\nassistants, but in the conversation between the user and the chat assistant,\nthere are prompts, require multi-turns between the chat assistant and the user.\nHowever, there are a number of issues with the multi-turns conversation: The\nresponse of the chat assistant is prone to errors and can't help users achieve\ntheir goals, and as the number of conversation turns increases, the probability\nof errors will also increase; It is difficult for chat assistant to generate\nresponses with different processes based on actual needs for the same prompt;\nChat assistant require the use of tools, but the current approach is not\nelegant and efficient, and the number of tool calls is limited. The main reason\nfor these issues is that large language models don't have the thinking ability\nas a human, lack the reasoning ability and planning ability, and lack the\nability to execute plans. To solve these issues, we propose a thinking method\nbased on a built-in chain of thought: In the multi-turns conversation, for each\nuser prompt, the large language model thinks based on elements such as chat\nhistory, thinking context, action calls, memory and knowledge, makes detailed\nreasoning and planning, and actions according to the plan. We also explored how\nthe large language model enhances thinking ability through this thinking\nmethod: Collect training datasets according to the thinking method and fine\ntune the large language model through supervised learning; Train a consistency\nreward model and use it as a reward function to fine tune the large language\nmodel using reinforcement learning, and the reinforced large language model\noutputs according to this way of thinking. Our experimental results show that\nthe reasoning ability and planning ability of the large language model are\nenhanced, and the issues in the multi-turns conversation are solved.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "12 pages, 4 figures, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2502.13475v2",
    "published_date": "2025-02-19 06:58:34 UTC",
    "updated_date": "2025-02-20 21:40:58 UTC"
  },
  {
    "arxiv_id": "2502.13471v1",
    "title": "Some Insights of Construction of Feature Graph to Learn Pairwise Feature Interactions with Graph Neural Networks",
    "authors": [
      "Phaphontee Yamchote",
      "Saw Nay Htet Win",
      "Chainarong Amornbunchornvej",
      "Thanapon Noraset"
    ],
    "abstract": "Feature interaction is crucial in predictive machine learning models, as it\ncaptures the relationships between features that influence model performance.\nIn this work, we focus on pairwise interactions and investigate their\nimportance in constructing feature graphs for Graph Neural Networks (GNNs).\nRather than proposing new methods, we leverage existing GNN models and tools to\nexplore the relationship between feature graph structures and their\neffectiveness in modeling interactions. Through experiments on synthesized\ndatasets, we uncover that edges between interacting features are important for\nenabling GNNs to model feature interactions effectively. We also observe that\nincluding non-interaction edges can act as noise, degrading model performance.\nFurthermore, we provide theoretical support for sparse feature graph selection\nusing the Minimum Description Length (MDL) principle. We prove that feature\ngraphs retaining only necessary interaction edges yield a more efficient and\ninterpretable representation than complete graphs, aligning with Occam's Razor.\n  Our findings offer both theoretical insights and practical guidelines for\ndesigning feature graphs that improve the performance and interpretability of\nGNN models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML",
      "68T07 68T07 68T07",
      "I.2.6"
    ],
    "primary_category": "cs.LG",
    "comment": "This is the draft before submitting to any journal",
    "pdf_url": "http://arxiv.org/pdf/2502.13471v1",
    "published_date": "2025-02-19 06:47:23 UTC",
    "updated_date": "2025-02-19 06:47:23 UTC"
  },
  {
    "arxiv_id": "2502.13994v2",
    "title": "Generative Detail Enhancement for Physically Based Materials",
    "authors": [
      "Saeed Hadadan",
      "Benedikt Bitterli",
      "Tizian Zeltner",
      "Jan Novák",
      "Fabrice Rousselle",
      "Jacob Munkberg",
      "Jon Hasselgren",
      "Bartlomiej Wronski",
      "Matthias Zwicker"
    ],
    "abstract": "We present a tool for enhancing the detail of physically based materials\nusing an off-the-shelf diffusion model and inverse rendering. Our goal is to\nenhance the visual fidelity of materials with detail that is often tedious to\nauthor, by adding signs of wear, aging, weathering, etc. As these appearance\ndetails are often rooted in real-world processes, we leverage a generative\nimage model trained on a large dataset of natural images with corresponding\nvisuals in context. Starting with a given geometry, UV mapping, and basic\nappearance, we render multiple views of the object. We use these views,\ntogether with an appearance-defining text prompt, to condition a diffusion\nmodel. The details it generates are then backpropagated from the enhanced\nimages to the material parameters via inverse differentiable rendering. For\ninverse rendering to be successful, the generated appearance has to be\nconsistent across all the images. We propose two priors to address the\nmulti-view consistency of the diffusion model. First, we ensure that the\ninitial noise that seeds the diffusion process is itself consistent across\nviews by integrating it from a view-independent UV space. Second, we enforce\ngeometric consistency by biasing the attention mechanism via a projective\nconstraint so that pixels attend strongly to their corresponding pixel\nlocations in other views. Our approach does not require any training or\nfinetuning of the diffusion model, is agnostic of the material model used, and\nthe enhanced material properties, i.e., 2D PBR textures, can be further edited\nby artists. This project is available at https://generative-detail.github.io.",
    "categories": [
      "cs.GR",
      "cs.AI"
    ],
    "primary_category": "cs.GR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.13994v2",
    "published_date": "2025-02-19 06:39:51 UTC",
    "updated_date": "2025-05-07 04:33:26 UTC"
  },
  {
    "arxiv_id": "2502.14910v1",
    "title": "EvoP: Robust LLM Inference via Evolutionary Pruning",
    "authors": [
      "Shangyu Wu",
      "Hongchao Du",
      "Ying Xiong",
      "Shuai Chen",
      "Tei-wei Kuo",
      "Nan Guan",
      "Chun Jason Xue"
    ],
    "abstract": "Large Language Models (LLMs) have achieved remarkable success in natural\nlanguage processing tasks, but their massive size and computational demands\nhinder their deployment in resource-constrained environments. Existing\nstructured pruning methods address this issue by removing redundant structures\n(e.g., elements, channels, layers) from the model. However, these methods\nemploy a heuristic pruning strategy, which leads to suboptimal performance.\nBesides, they also ignore the data characteristics when pruning the model.\n  To overcome these limitations, we propose EvoP, an evolutionary pruning\nframework for robust LLM inference. EvoP first presents a cluster-based\ncalibration dataset sampling (CCDS) strategy for creating a more diverse\ncalibration dataset. EvoP then introduces an evolutionary pruning pattern\nsearching (EPPS) method to find the optimal pruning pattern. Compared to\nexisting structured pruning techniques, EvoP achieves the best performance\nwhile maintaining the best efficiency. Experiments across different LLMs and\ndifferent downstream tasks validate the effectiveness of the proposed EvoP,\nmaking it a practical and scalable solution for deploying LLMs in real-world\napplications.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.14910v1",
    "published_date": "2025-02-19 06:33:59 UTC",
    "updated_date": "2025-02-19 06:33:59 UTC"
  },
  {
    "arxiv_id": "2502.13465v1",
    "title": "HawkBench: Investigating Resilience of RAG Methods on Stratified Information-Seeking Tasks",
    "authors": [
      "Hongjin Qian",
      "Zheng Liu",
      "Chao Gao",
      "Yankai Wang",
      "Defu Lian",
      "Zhicheng Dou"
    ],
    "abstract": "In real-world information-seeking scenarios, users have dynamic and diverse\nneeds, requiring RAG systems to demonstrate adaptable resilience. To\ncomprehensively evaluate the resilience of current RAG methods, we introduce\nHawkBench, a human-labeled, multi-domain benchmark designed to rigorously\nassess RAG performance across categorized task types. By stratifying tasks\nbased on information-seeking behaviors, HawkBench provides a systematic\nevaluation of how well RAG systems adapt to diverse user needs.\n  Unlike existing benchmarks, which focus primarily on specific task types\n(mostly factoid queries) and rely on varying knowledge bases, HawkBench offers:\n(1) systematic task stratification to cover a broad range of query types,\nincluding both factoid and rationale queries, (2) integration of multi-domain\ncorpora across all task types to mitigate corpus bias, and (3) rigorous\nannotation for high-quality evaluation.\n  HawkBench includes 1,600 high-quality test samples, evenly distributed across\ndomains and task types. Using this benchmark, we evaluate representative RAG\nmethods, analyzing their performance in terms of answer quality and response\nlatency. Our findings highlight the need for dynamic task strategies that\nintegrate decision-making, query interpretation, and global knowledge\nunderstanding to improve RAG generalizability. We believe HawkBench serves as a\npivotal benchmark for advancing the resilience of RAG methods and their ability\nto achieve general-purpose information seeking.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.IR",
    "comment": "13 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.13465v1",
    "published_date": "2025-02-19 06:33:39 UTC",
    "updated_date": "2025-02-19 06:33:39 UTC"
  },
  {
    "arxiv_id": "2502.13464v1",
    "title": "Estimating Commonsense Plausibility through Semantic Shifts",
    "authors": [
      "Wanqing Cui",
      "Keping Bi",
      "Jiafeng Guo",
      "Xueqi Cheng"
    ],
    "abstract": "Commonsense plausibility estimation is critical for evaluating language\nmodels (LMs), yet existing generative approaches--reliant on likelihoods or\nverbalized judgments--struggle with fine-grained discrimination. In this paper,\nwe propose ComPaSS, a novel discriminative framework that quantifies\ncommonsense plausibility by measuring semantic shifts when augmenting sentences\nwith commonsense-related information. Plausible augmentations induce minimal\nshifts in semantics, while implausible ones result in substantial deviations.\nEvaluations on two types of fine-grained commonsense plausibility estimation\ntasks across different backbones, including LLMs and vision-language models\n(VLMs), show that ComPaSS consistently outperforms baselines. It demonstrates\nthe advantage of discriminative approaches over generative methods in\nfine-grained commonsense plausibility evaluation. Experiments also show that\n(1) VLMs yield superior performance to LMs, when integrated with ComPaSS, on\nvision-grounded commonsense tasks. (2) contrastive pre-training sharpens\nbackbone models' ability to capture semantic nuances, thereby further enhancing\nComPaSS.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.13464v1",
    "published_date": "2025-02-19 06:31:06 UTC",
    "updated_date": "2025-02-19 06:31:06 UTC"
  },
  {
    "arxiv_id": "2502.15804v2",
    "title": "FairKV: Balancing Per-Head KV Cache for Fast Multi-GPU Inference",
    "authors": [
      "Bingzhe Zhao",
      "Ke Cheng",
      "Aomufei Yuan",
      "Yuxuan Tian",
      "Ruiguang Zhong",
      "Chengchen Hu",
      "Tong Yang",
      "Lian Yu"
    ],
    "abstract": "KV cache techniques in Transformer models aim to reduce redundant\ncomputations at the expense of substantially increased memory usage, making KV\ncache compression an important and popular research topic. Recently,\nstate-of-the-art KV cache compression methods implement imbalanced, per-head\nallocation algorithms that dynamically adjust the KV cache budget for each\nattention head, achieving excellent performance in single-GPU scenarios.\nHowever, we observe that such imbalanced compression leads to significant load\nimbalance when deploying multi-GPU inference, as some GPUs become overburdened\nwhile others remain underutilized. In this paper, we propose FairKV, a method\ndesigned to ensure fair memory usage among attention heads in systems employing\nimbalanced KV cache compression. The core technique of FairKV is Fair-Copying,\nwhich replicates a small subset of memory-intensive attention heads across GPUs\nusing data parallelism to mitigate load imbalance. Our experiments on popular\nmodels, including LLaMA 70b and Mistral 24b model, demonstrate that FairKV\nincreases throughput by 1.66x compared to standard tensor parallelism\ninference. Our code will be released as open source upon acceptance.",
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "primary_category": "cs.DC",
    "comment": "11 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.15804v2",
    "published_date": "2025-02-19 06:14:27 UTC",
    "updated_date": "2025-05-17 12:22:59 UTC"
  },
  {
    "arxiv_id": "2502.15802v1",
    "title": "A General Error-Theoretical Analysis Framework for Constructing Compression Strategies",
    "authors": [
      "Boyang Zhang",
      "Daning Cheng",
      "Yunquan Zhang",
      "Meiqi Tu",
      "Fangmin Liu",
      "Jiake Tian"
    ],
    "abstract": "The exponential growth in parameter size and computational complexity of deep\nmodels poses significant challenges for efficient deployment. The core problem\nof existing compression methods is that different layers of the model have\nsignificant differences in their tolerance to compression levels. For instance,\nthe first layer of a model can typically sustain a higher compression level\ncompared to the last layer without compromising performance. Thus, the key\nchallenge lies in how to allocate compression levels across layers in a way\nthat minimizes performance loss while maximizing parameter reduction. To\naddress this challenge, we propose a Compression Error Theory (CET) framework,\ndesigned to determine the optimal compression level for each layer. Taking\nquantization as an example, CET leverages differential expansion and algebraic\ngeometry to reconstruct the quadratic form of quantization error as ellipsoids\nand hyperbolic paraboloids, and utilizes their geometric structures to define\nan error subspace. To identify the error subspace with minimal performance\nloss, by performing orthogonal decomposition of the geometric space, CET\ntransforms the optimization process of the error subspace into a complementary\nproblem. The final theoretical analysis shows that constructing the\nquantization subspace along the major axis results in minimal performance\ndegradation. Through experimental verification of the theory, CET can greatly\nretain performance while compressing. Specifically, on the ResNet-34 model, CET\nachieves nearly 11$\\times$ parameter compression while even surpassing\nperformance comparable to the original model.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.LG",
    "comment": "Under Review",
    "pdf_url": "http://arxiv.org/pdf/2502.15802v1",
    "published_date": "2025-02-19 06:12:43 UTC",
    "updated_date": "2025-02-19 06:12:43 UTC"
  },
  {
    "arxiv_id": "2502.13458v1",
    "title": "ThinkGuard: Deliberative Slow Thinking Leads to Cautious Guardrails",
    "authors": [
      "Xiaofei Wen",
      "Wenxuan Zhou",
      "Wenjie Jacky Mo",
      "Muhao Chen"
    ],
    "abstract": "Ensuring the safety of large language models (LLMs) is critical as they are\ndeployed in real-world applications. Existing guardrails rely on rule-based\nfiltering or single-pass classification, limiting their ability to handle\nnuanced safety violations. To address this, we propose ThinkGuard, a\ncritique-augmented guardrail model that distills knowledge from high-capacity\nLLMs by generating structured critiques alongside safety labels. Fine-tuned on\ncritique-augmented data, the captured deliberative thinking ability drastically\nenhances the guardrail's cautiousness and interpretability. Evaluated on\nmultiple safety benchmarks, ThinkGuard achieves the highest average F1 and\nAUPRC, outperforming all baselines. Compared to LLaMA Guard 3, ThinkGuard\nimproves accuracy by 16.1% and macro F1 by 27.0%. Moreover, it surpasses\nlabel-only fine-tuned models, confirming that structured critiques enhance both\nclassification precision and nuanced safety reasoning while maintaining\ncomputational efficiency.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.13458v1",
    "published_date": "2025-02-19 06:09:58 UTC",
    "updated_date": "2025-02-19 06:09:58 UTC"
  },
  {
    "arxiv_id": "2503.05731v2",
    "title": "AILuminate: Introducing v1.0 of the AI Risk and Reliability Benchmark from MLCommons",
    "authors": [
      "Shaona Ghosh",
      "Heather Frase",
      "Adina Williams",
      "Sarah Luger",
      "Paul Röttger",
      "Fazl Barez",
      "Sean McGregor",
      "Kenneth Fricklas",
      "Mala Kumar",
      "Quentin Feuillade--Montixi",
      "Kurt Bollacker",
      "Felix Friedrich",
      "Ryan Tsang",
      "Bertie Vidgen",
      "Alicia Parrish",
      "Chris Knotz",
      "Eleonora Presani",
      "Jonathan Bennion",
      "Marisa Ferrara Boston",
      "Mike Kuniavsky",
      "Wiebke Hutiri",
      "James Ezick",
      "Malek Ben Salem",
      "Rajat Sahay",
      "Sujata Goswami",
      "Usman Gohar",
      "Ben Huang",
      "Supheakmungkol Sarin",
      "Elie Alhajjar",
      "Canyu Chen",
      "Roman Eng",
      "Kashyap Ramanandula Manjusha",
      "Virendra Mehta",
      "Eileen Long",
      "Murali Emani",
      "Natan Vidra",
      "Benjamin Rukundo",
      "Abolfazl Shahbazi",
      "Kongtao Chen",
      "Rajat Ghosh",
      "Vithursan Thangarasa",
      "Pierre Peigné",
      "Abhinav Singh",
      "Max Bartolo",
      "Satyapriya Krishna",
      "Mubashara Akhtar",
      "Rafael Gold",
      "Cody Coleman",
      "Luis Oala",
      "Vassil Tashev",
      "Joseph Marvin Imperial",
      "Amy Russ",
      "Sasidhar Kunapuli",
      "Nicolas Miailhe",
      "Julien Delaunay",
      "Bhaktipriya Radharapu",
      "Rajat Shinde",
      "Tuesday",
      "Debojyoti Dutta",
      "Declan Grabb",
      "Ananya Gangavarapu",
      "Saurav Sahay",
      "Agasthya Gangavarapu",
      "Patrick Schramowski",
      "Stephen Singam",
      "Tom David",
      "Xudong Han",
      "Priyanka Mary Mammen",
      "Tarunima Prabhakar",
      "Venelin Kovatchev",
      "Rebecca Weiss",
      "Ahmed Ahmed",
      "Kelvin N. Manyeki",
      "Sandeep Madireddy",
      "Foutse Khomh",
      "Fedor Zhdanov",
      "Joachim Baumann",
      "Nina Vasan",
      "Xianjun Yang",
      "Carlos Mougn",
      "Jibin Rajan Varghese",
      "Hussain Chinoy",
      "Seshakrishna Jitendar",
      "Manil Maskey",
      "Claire V. Hardgrove",
      "Tianhao Li",
      "Aakash Gupta",
      "Emil Joswin",
      "Yifan Mai",
      "Shachi H Kumar",
      "Cigdem Patlak",
      "Kevin Lu",
      "Vincent Alessi",
      "Sree Bhargavi Balija",
      "Chenhe Gu",
      "Robert Sullivan",
      "James Gealy",
      "Matt Lavrisa",
      "James Goel",
      "Peter Mattson",
      "Percy Liang",
      "Joaquin Vanschoren"
    ],
    "abstract": "The rapid advancement and deployment of AI systems have created an urgent\nneed for standard safety-evaluation frameworks. This paper introduces\nAILuminate v1.0, the first comprehensive industry-standard benchmark for\nassessing AI-product risk and reliability. Its development employed an open\nprocess that included participants from multiple fields. The benchmark\nevaluates an AI system's resistance to prompts designed to elicit dangerous,\nillegal, or undesirable behavior in 12 hazard categories, including violent\ncrimes, nonviolent crimes, sex-related crimes, child sexual exploitation,\nindiscriminate weapons, suicide and self-harm, intellectual property, privacy,\ndefamation, hate, sexual content, and specialized advice (election, financial,\nhealth, legal). Our method incorporates a complete assessment standard,\nextensive prompt datasets, a novel evaluation framework, a grading and\nreporting system, and the technical as well as organizational infrastructure\nfor long-term support and evolution. In particular, the benchmark employs an\nunderstandable five-tier grading scale (Poor to Excellent) and incorporates an\ninnovative entropy-based system-response evaluation.\n  In addition to unveiling the benchmark, this report also identifies\nlimitations of our method and of building safety benchmarks generally,\nincluding evaluator uncertainty and the constraints of single-turn\ninteractions. This work represents a crucial step toward establishing global\nstandards for AI risk and reliability evaluation while acknowledging the need\nfor continued development in areas such as multiturn interactions, multimodal\nunderstanding, coverage of additional languages, and emerging hazard\ncategories. Our findings provide valuable insights for model developers, system\nintegrators, and policymakers working to promote safer AI deployment.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "51 pages, 8 figures and an appendix",
    "pdf_url": "http://arxiv.org/pdf/2503.05731v2",
    "published_date": "2025-02-19 05:58:52 UTC",
    "updated_date": "2025-04-18 22:04:46 UTC"
  },
  {
    "arxiv_id": "2502.13450v1",
    "title": "Interleaved Gibbs Diffusion for Constrained Generation",
    "authors": [
      "Gautham Govind Anil",
      "Sachin Yadav",
      "Dheeraj Nagaraj",
      "Karthikeyan Shanmugam",
      "Prateek Jain"
    ],
    "abstract": "We introduce Interleaved Gibbs Diffusion (IGD), a novel generative modeling\nframework for mixed continuous-discrete data, focusing on constrained\ngeneration problems. Prior works on discrete and continuous-discrete diffusion\nmodels assume factorized denoising distribution for fast generation, which can\nhinder the modeling of strong dependencies between random variables encountered\nin constrained generation. IGD moves beyond this by interleaving continuous and\ndiscrete denoising algorithms via a discrete time Gibbs sampling type Markov\nchain. IGD provides flexibility in the choice of denoisers, allows conditional\ngeneration via state-space doubling and inference time scaling via the\nReDeNoise method. Empirical evaluations on three challenging tasks-solving\n3-SAT, generating molecule structures, and generating layouts-demonstrate\nstate-of-the-art performance. Notably, IGD achieves a 7% improvement on 3-SAT\nout of the box and achieves state-of-the-art results in molecule generation\nwithout relying on equivariant diffusion or domain-specific architectures. We\nexplore a wide range of modeling, and interleaving strategies along with\nhyperparameters in each of these problems.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.13450v1",
    "published_date": "2025-02-19 05:51:24 UTC",
    "updated_date": "2025-02-19 05:51:24 UTC"
  },
  {
    "arxiv_id": "2502.13442v2",
    "title": "TreeCut: A Synthetic Unanswerable Math Word Problem Dataset for LLM Hallucination Evaluation",
    "authors": [
      "Jialin Ouyang"
    ],
    "abstract": "Large language models (LLMs) now achieve near-human performance on standard\nmath word problem benchmarks (e.g., GSM8K), yet their true reasoning ability\nremains disputed. A key concern is that models often produce confident, yet\nunfounded, answers to unanswerable problems. We introduce TreeCut, a synthetic\ndataset that systematically generates infinite unanswerable math word problems\nand their answerable counterparts, by representing each question as a tree and\nremoving chosen necessary conditions. Experiments show TreeCut effectively\ninduce hallucinations in large language models, including GPT-4o and o3-mini,\nwith rates of 64% and 44% in their respective worst-case scenarios under\nzero-shot setting. Further analysis highlights that deeper or more complex\ntrees, composite item names, and removing necessary condition near the middle\nof a path all increase the likelihood of hallucinations, underscoring the\npersistent challenges LLMs face in identifying unanswerable math problems. The\ndataset generation code and sample data are available at\nhttps://github.com/j-bagel/treecut-math.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to ACL 2025 Main Conference",
    "pdf_url": "http://arxiv.org/pdf/2502.13442v2",
    "published_date": "2025-02-19 05:38:45 UTC",
    "updated_date": "2025-05-20 04:13:56 UTC"
  },
  {
    "arxiv_id": "2502.13441v1",
    "title": "The Self-Improvement Paradox: Can Language Models Bootstrap Reasoning Capabilities without External Scaffolding?",
    "authors": [
      "Yutao Sun",
      "Mingshuai Chen",
      "Tiancheng Zhao",
      "Ruochen Xu",
      "Zilun Zhang",
      "Jianwei Yin"
    ],
    "abstract": "Self-improving large language models (LLMs) -- i.e., to improve the\nperformance of an LLM by fine-tuning it with synthetic data generated by itself\n-- is a promising way to advance the capabilities of LLMs while avoiding\nextensive supervision. Existing approaches to self-improvement often rely on\nexternal supervision signals in the form of seed data and/or assistance from\nthird-party models. This paper presents Crescent -- a simple yet effective\nframework for generating high-quality synthetic question-answer data in a fully\nautonomous manner. Crescent first elicits the LLM to generate raw questions via\na bait prompt, then diversifies these questions leveraging a rejection\nsampling-based self-deduplication, and finally feeds the questions to the LLM\nand collects the corresponding answers by means of majority voting. We show\nthat Crescent sheds light on the potential of true self-improvement with zero\nexternal supervision signals for math reasoning; in particular,\nCrescent-generated question-answer pairs suffice to (i) improve the reasoning\ncapabilities of an LLM while preserving its general performance (especially in\nthe 0-shot setting); and (ii) distil LLM knowledge to weaker models more\neffectively than existing methods based on seed-dataset augmentation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.13441v1",
    "published_date": "2025-02-19 05:37:08 UTC",
    "updated_date": "2025-02-19 05:37:08 UTC"
  },
  {
    "arxiv_id": "2502.13440v1",
    "title": "Semi-supervised classification of bird vocalizations",
    "authors": [
      "Simen Hexeberg",
      "Mandar Chitre",
      "Matthias Hoffmann-Kuhnt",
      "Bing Wen Low"
    ],
    "abstract": "Changes in bird populations can indicate broader changes in ecosystems,\nmaking birds one of the most important animal groups to monitor. Combining\nmachine learning and passive acoustics enables continuous monitoring over\nextended periods without direct human involvement. However, most existing\ntechniques require extensive expert-labeled datasets for training and cannot\neasily detect time-overlapping calls in busy soundscapes. We propose a\nsemi-supervised acoustic bird detector designed to allow both the detection of\ntime-overlapping calls (when separated in frequency) and the use of few labeled\ntraining samples. The classifier is trained and evaluated on a combination of\ncommunity-recorded open-source data and long-duration soundscape recordings\nfrom Singapore. It achieves a mean F0.5 score of 0.701 across 315 classes from\n110 bird species on a hold-out test set, with an average of 11 labeled training\nsamples per class. It outperforms the state-of-the-art BirdNET classifier on a\ntest set of 103 bird species despite significantly fewer labeled training\nsamples. The detector is further tested on 144 microphone-hours of continuous\nsoundscape data. The rich soundscape in Singapore makes suppression of false\npositives a challenge on raw, continuous data streams. Nevertheless, we\ndemonstrate that achieving high precision in such environments with minimal\nlabeled training data is possible.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CV",
      "eess.AS",
      "q-bio.QM"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.13440v1",
    "published_date": "2025-02-19 05:31:13 UTC",
    "updated_date": "2025-02-19 05:31:13 UTC"
  },
  {
    "arxiv_id": "2503.05730v1",
    "title": "Robust Optimization with Diffusion Models for Green Security",
    "authors": [
      "Lingkai Kong",
      "Haichuan Wang",
      "Yuqi Pan",
      "Cheol Woo Kim",
      "Mingxiao Song",
      "Alayna Nguyen",
      "Tonghan Wang",
      "Haifeng Xu",
      "Milind Tambe"
    ],
    "abstract": "In green security, defenders must forecast adversarial behavior, such as\npoaching, illegal logging, and illegal fishing, to plan effective patrols.\nThese behavior are often highly uncertain and complex. Prior work has leveraged\ngame theory to design robust patrol strategies to handle uncertainty, but\nexisting adversarial behavior models primarily rely on Gaussian processes or\nlinear models, which lack the expressiveness needed to capture intricate\nbehavioral patterns. To address this limitation, we propose a conditional\ndiffusion model for adversary behavior modeling, leveraging its strong\ndistribution-fitting capabilities. To the best of our knowledge, this is the\nfirst application of diffusion models in the green security domain. Integrating\ndiffusion models into game-theoretic optimization, however, presents new\nchallenges, including a constrained mixed strategy space and the need to sample\nfrom an unnormalized distribution to estimate utilities. To tackle these\nchallenges, we introduce a mixed strategy of mixed strategies and employ a\ntwisted Sequential Monte Carlo (SMC) sampler for accurate sampling.\nTheoretically, our algorithm is guaranteed to converge to an epsilon\nequilibrium with high probability using a finite number of iterations and\nsamples. Empirically, we evaluate our approach on both synthetic and real-world\npoaching datasets, demonstrating its effectiveness.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.05730v1",
    "published_date": "2025-02-19 05:30:46 UTC",
    "updated_date": "2025-02-19 05:30:46 UTC"
  },
  {
    "arxiv_id": "2502.13430v1",
    "title": "Vision-Based Generic Potential Function for Policy Alignment in Multi-Agent Reinforcement Learning",
    "authors": [
      "Hao Ma",
      "Shijie Wang",
      "Zhiqiang Pu",
      "Siyao Zhao",
      "Xiaolin Ai"
    ],
    "abstract": "Guiding the policy of multi-agent reinforcement learning to align with human\ncommon sense is a difficult problem, largely due to the complexity of modeling\ncommon sense as a reward, especially in complex and long-horizon multi-agent\ntasks. Recent works have shown the effectiveness of reward shaping, such as\npotential-based rewards, to enhance policy alignment. The existing works,\nhowever, primarily rely on experts to design rule-based rewards, which are\noften labor-intensive and lack a high-level semantic understanding of common\nsense. To solve this problem, we propose a hierarchical vision-based reward\nshaping method. At the bottom layer, a visual-language model (VLM) serves as a\ngeneric potential function, guiding the policy to align with human common sense\nthrough its intrinsic semantic understanding. To help the policy adapts to\nuncertainty and changes in long-horizon tasks, the top layer features an\nadaptive skill selection module based on a visual large language model (vLLM).\nThe module uses instructions, video replays, and training records to\ndynamically select suitable potential function from a pre-designed pool.\nBesides, our method is theoretically proven to preserve the optimal policy.\nExtensive experiments conducted in the Google Research Football environment\ndemonstrate that our method not only achieves a higher win rate but also\neffectively aligns the policy with human common sense.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.13430v1",
    "published_date": "2025-02-19 05:04:10 UTC",
    "updated_date": "2025-02-19 05:04:10 UTC"
  },
  {
    "arxiv_id": "2502.13428v1",
    "title": "MCTS-KBQA: Monte Carlo Tree Search for Knowledge Base Question Answering",
    "authors": [
      "Guanming Xiong",
      "Haochen Li",
      "Wen Zhao"
    ],
    "abstract": "This study explores how to enhance the reasoning capabilities of large\nlanguage models (LLMs) in knowledge base question answering (KBQA) by\nleveraging Monte Carlo Tree Search (MCTS). Semantic parsing-based KBQA methods\nare particularly challenging as these approaches require locating elements from\nknowledge bases and generating logical forms, demanding not only extensive\nannotated data but also strong reasoning capabilities. Although recent\napproaches leveraging LLMs as agents have demonstrated considerable potential,\nthese studies are inherently constrained by their linear decision-making\nprocesses. To address this limitation, we propose a MCTS-based framework that\nenhances LLMs' reasoning capabilities through tree search methodology. We\ndesign a carefully designed step-wise reward mechanism that requires only\ndirect prompting of open-source instruction LLMs without additional\nfine-tuning. Experimental results demonstrate that our approach significantly\noutperforms linear decision-making methods, particularly in low-resource\nscenarios. Additionally, we contribute new data resources to the KBQA community\nby annotating intermediate reasoning processes for existing question-SPARQL\ndatasets using distant supervision. Experimental results on the extended\ndataset demonstrate that our method achieves comparable performance to fully\nsupervised models while using significantly less training data.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.13428v1",
    "published_date": "2025-02-19 04:58:39 UTC",
    "updated_date": "2025-02-19 04:58:39 UTC"
  },
  {
    "arxiv_id": "2502.13422v1",
    "title": "TabSD: Large Free-Form Table Question Answering with SQL-Based Table Decomposition",
    "authors": [
      "Yuxiang Wang",
      "Junhao Gan",
      "Jianzhong Qi"
    ],
    "abstract": "Question answering on free-form tables (TableQA) is challenging due to the\nabsence of predefined schemas and the presence of noise in large tables. While\nLarge Language Models (LLMs) have shown promise in TableQA, they struggle with\nlarge free-form tables and noise sensitivity. To address these challenges, we\npropose TabSD, a SQL-based decomposition model that enhances LLMs' ability to\nprocess large free-form tables. TabSD generates SQL queries to guide the table\ndecomposition, remove noise, and processes sub-tables for better answer\ngeneration. Additionally, SQL Verifier refines SQL outputs to enhance\ndecomposition accuracy. We introduce two TableQA datasets with large free-form\ntables, SLQA and SEQA, which consist solely of large free-form tables and will\nbe publicly available. Experimental results on four benchmark datasets\ndemonstrate that TABSD outperforms the best-existing baseline models by 23.07%,\n2.84%, 23.24% and 9.32% in accuracy, respectively, highlighting its\neffectiveness in handling large and noisy free-form tables.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.DB"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.13422v1",
    "published_date": "2025-02-19 04:45:05 UTC",
    "updated_date": "2025-02-19 04:45:05 UTC"
  },
  {
    "arxiv_id": "2502.13417v2",
    "title": "RLTHF: Targeted Human Feedback for LLM Alignment",
    "authors": [
      "Yifei Xu",
      "Tusher Chakraborty",
      "Emre Kıcıman",
      "Bibek Aryal",
      "Eduardo Rodrigues",
      "Srinagesh Sharma",
      "Roberto Estevao",
      "Maria Angels de Luis Balaguer",
      "Jessica Wolk",
      "Rafael Padilha",
      "Leonardo Nunes",
      "Shobana Balakrishnan",
      "Songwu Lu",
      "Ranveer Chandra"
    ],
    "abstract": "Fine-tuning large language models (LLMs) to align with user preferences is\nchallenging due to the high cost of quality human annotations in Reinforcement\nLearning from Human Feedback (RLHF) and the generalizability limitations of AI\nFeedback. To address these challenges, we propose RLTHF, a human-AI hybrid\nframework that combines LLM-based initial alignment with selective human\nannotations to achieve full-human annotation alignment with minimal effort.\nRLTHF identifies hard-to-annotate samples mislabeled by LLMs using a reward\nmodel's reward distribution and iteratively enhances alignment by integrating\nstrategic human corrections while leveraging LLM's correctly labeled samples.\nEvaluations on HH-RLHF and TL;DR datasets show that RLTHF reaches full-human\nannotation-level alignment with only 6-7% of the human annotation effort.\nFurthermore, models trained on RLTHF's curated datasets for downstream tasks\noutperform those trained on fully human-annotated datasets, underscoring the\neffectiveness of RLTHF's strategic data curation.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.13417v2",
    "published_date": "2025-02-19 04:25:11 UTC",
    "updated_date": "2025-02-21 02:51:18 UTC"
  },
  {
    "arxiv_id": "2504.05312v1",
    "title": "Towards Adaptive Memory-Based Optimization for Enhanced Retrieval-Augmented Generation",
    "authors": [
      "Qitao Qin",
      "Yucong Luo",
      "Yihang Lu",
      "Zhibo Chu",
      "Xianwei Meng"
    ],
    "abstract": "Retrieval-Augmented Generation (RAG), by integrating non-parametric knowledge\nfrom external knowledge bases into models, has emerged as a promising approach\nto enhancing response accuracy while mitigating factual errors and\nhallucinations. This method has been widely applied in tasks such as Question\nAnswering (QA). However, existing RAG methods struggle with open-domain QA\ntasks because they perform independent retrieval operations and directly\nincorporate the retrieved information into generation without maintaining a\nsummarizing memory or using adaptive retrieval strategies, leading to noise\nfrom redundant information and insufficient information integration. To address\nthese challenges, we propose Adaptive memory-based optimization for enhanced\nRAG (Amber) for open-domain QA tasks, which comprises an Agent-based Memory\nUpdater, an Adaptive Information Collector, and a Multi-granular Content\nFilter, working together within an iterative memory updating paradigm.\nSpecifically, Amber integrates and optimizes the language model's memory\nthrough a multi-agent collaborative approach, ensuring comprehensive knowledge\nintegration from previous retrieval steps. It dynamically adjusts retrieval\nqueries and decides when to stop retrieval based on the accumulated knowledge,\nenhancing retrieval efficiency and effectiveness. Additionally, it reduces\nnoise by filtering irrelevant content at multiple levels, retaining essential\ninformation to improve overall model performance. We conduct extensive\nexperiments on several open-domain QA datasets, and the results demonstrate the\nsuperiority and effectiveness of our method and its components. The source code\nis available \\footnote{https://anonymous.4open.science/r/Amber-B203/}.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "8pages",
    "pdf_url": "http://arxiv.org/pdf/2504.05312v1",
    "published_date": "2025-02-19 04:23:12 UTC",
    "updated_date": "2025-02-19 04:23:12 UTC"
  },
  {
    "arxiv_id": "2502.13412v1",
    "title": "Explore-Construct-Filter: An Automated Framework for Rich and Reliable API Knowledge Graph Construction",
    "authors": [
      "Yanbang Sun",
      "Qing Huang",
      "Xiaoxue Ren",
      "Zhenchang Xing",
      "Xiaohong Li",
      "Junjie Wang"
    ],
    "abstract": "The API Knowledge Graph (API KG) is a structured network that models API\nentities and their relations, providing essential semantic insights for tasks\nsuch as API recommendation, code generation, and API misuse detection. However,\nconstructing a knowledge-rich and reliable API KG presents several challenges.\nExisting schema-based methods rely heavily on manual annotations to design KG\nschemas, leading to excessive manual overhead. On the other hand, schema-free\nmethods, due to the lack of schema guidance, are prone to introducing noise,\nreducing the KG's reliability. To address these issues, we propose the\nExplore-Construct-Filter framework, an automated approach for API KG\nconstruction based on large language models (LLMs). This framework consists of\nthree key modules: 1) KG exploration: LLMs simulate the workflow of annotators\nto automatically design a schema with comprehensive type triples, minimizing\nhuman intervention; 2) KG construction: Guided by the schema, LLMs extract\ninstance triples to construct a rich yet unreliable API KG; 3) KG filtering:\nRemoving invalid type triples and suspicious instance triples to construct a\nrich and reliable API KG. Experimental results demonstrate that our method\nsurpasses the state-of-the-art method, achieving a 25.2% improvement in F1\nscore. Moreover, the Explore-Construct-Filter framework proves effective, with\nthe KG exploration module increasing KG richness by 133.6% and the KG filtering\nmodule improving reliability by 26.6%. Finally, cross-model experiments confirm\nthe generalizability of our framework.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.13412v1",
    "published_date": "2025-02-19 03:51:31 UTC",
    "updated_date": "2025-02-19 03:51:31 UTC"
  },
  {
    "arxiv_id": "2502.13410v1",
    "title": "Tell Me Why: Incentivizing Explanations",
    "authors": [
      "Siddarth Srinivasan",
      "Ezra Karger",
      "Michiel Bakker",
      "Yiling Chen"
    ],
    "abstract": "Common sense suggests that when individuals explain why they believe\nsomething, we can arrive at more accurate conclusions than when they simply\nstate what they believe. Yet, there is no known mechanism that provides\nincentives to elicit explanations for beliefs from agents. This likely stems\nfrom the fact that standard Bayesian models make assumptions (like conditional\nindependence of signals) that preempt the need for explanations, in order to\nshow efficient information aggregation. A natural justification for the value\nof explanations is that agents' beliefs tend to be drawn from overlapping\nsources of information, so agents' belief reports do not reveal all that needs\nto be known. Indeed, this work argues that rationales-explanations of an\nagent's private information-lead to more efficient aggregation by allowing\nagents to efficiently identify what information they share and what information\nis new. Building on this model of rationales, we present a novel 'deliberation\nmechanism' to elicit rationales from agents in which truthful reporting of\nbeliefs and rationales is a perfect Bayesian equilibrium.",
    "categories": [
      "cs.GT",
      "cs.AI",
      "econ.TH"
    ],
    "primary_category": "cs.GT",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.13410v1",
    "published_date": "2025-02-19 03:47:34 UTC",
    "updated_date": "2025-02-19 03:47:34 UTC"
  },
  {
    "arxiv_id": "2502.13407v3",
    "title": "JL1-CD: A New Benchmark for Remote Sensing Change Detection and a Robust Multi-Teacher Knowledge Distillation Framework",
    "authors": [
      "Ziyuan Liu",
      "Ruifei Zhu",
      "Long Gao",
      "Yuanxiu Zhou",
      "Jingyu Ma",
      "Yuantao Gu"
    ],
    "abstract": "Change detection (CD) in remote sensing images plays a vital role in Earth\nobservation. However, the scarcity of high-resolution, comprehensive\nopen-source datasets and the difficulty in achieving robust performance across\nvarying change types remain major challenges. To address these issues, we\nintroduce JL1-CD, a large-scale, sub-meter CD dataset consisting of 5,000 image\npairs. We further propose a novel Origin-Partition (O-P) strategy and integrate\nit into a Multi-Teacher Knowledge Distillation (MTKD) framework to enhance CD\nperformance. The O-P strategy partitions the training set by Change Area Ratio\n(CAR) and trains specialized teacher models on each subset. The MTKD framework\nthen distills complementary knowledge from these teachers into a single student\nmodel, enabling improved detection results across diverse CAR scenarios without\nadditional inference cost. Our MTKD approach demonstrated strong performance in\nthe 2024 \"Jilin-1'' Cup challenge, ranking first in the preliminary and second\nin the final rounds. Extensive experiments on the JL1-CD and SYSU-CD datasets\nshow that the MTKD framework consistently improves the performance of CD models\nwith various network architectures and parameter sizes, establishing new\nstate-of-the-art results. Code and dataset are available at\nhttps://anonymous.4open.science/r/MTKD-A-84B8.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "23 pages, 11 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.13407v3",
    "published_date": "2025-02-19 03:33:54 UTC",
    "updated_date": "2025-05-17 11:10:34 UTC"
  },
  {
    "arxiv_id": "2502.13406v2",
    "title": "Generative Predictive Control: Flow Matching Policies for Dynamic and Difficult-to-Demonstrate Tasks",
    "authors": [
      "Vince Kurtz",
      "Joel W. Burdick"
    ],
    "abstract": "Generative control policies have recently unlocked major progress in\nrobotics. These methods produce action sequences via diffusion or flow\nmatching, with training data provided by demonstrations. But existing methods\ncome with two key limitations: they require expert demonstrations, which can be\ndifficult to obtain, and they are limited to relatively slow, quasi-static\ntasks. In this paper, we leverage a tight connection between sampling-based\npredictive control and generative modeling to address each of these issues. In\nparticular, we introduce generative predictive control, a supervised learning\nframework for tasks with fast dynamics that are easy to simulate but difficult\nto demonstrate. We then show how trained flow-matching policies can be\nwarm-started at inference time, maintaining temporal consistency and enabling\nhigh-frequency feedback. We believe that generative predictive control offers a\ncomplementary approach to existing behavior cloning methods, and hope that it\npaves the way toward generalist policies that extend beyond quasi-static\ndemonstration-oriented tasks.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.13406v2",
    "published_date": "2025-02-19 03:33:01 UTC",
    "updated_date": "2025-05-01 17:23:06 UTC"
  },
  {
    "arxiv_id": "2502.13991v1",
    "title": "Learning to Discover Regulatory Elements for Gene Expression Prediction",
    "authors": [
      "Xingyu Su",
      "Haiyang Yu",
      "Degui Zhi",
      "Shuiwang Ji"
    ],
    "abstract": "We consider the problem of predicting gene expressions from DNA sequences. A\nkey challenge of this task is to find the regulatory elements that control gene\nexpressions. Here, we introduce Seq2Exp, a Sequence to Expression network\nexplicitly designed to discover and extract regulatory elements that drive\ntarget gene expression, enhancing the accuracy of the gene expression\nprediction. Our approach captures the causal relationship between epigenomic\nsignals, DNA sequences and their associated regulatory elements. Specifically,\nwe propose to decompose the epigenomic signals and the DNA sequence conditioned\non the causal active regulatory elements, and apply an information bottleneck\nwith the Beta distribution to combine their effects while filtering out\nnon-causal components. Our experiments demonstrate that Seq2Exp outperforms\nexisting baselines in gene expression prediction tasks and discovers\ninfluential regions compared to commonly used statistical methods for peak\ndetection such as MACS3. The source code is released as part of the AIRS\nlibrary (https://github.com/divelab/AIRS/).",
    "categories": [
      "q-bio.GN",
      "cs.AI"
    ],
    "primary_category": "q-bio.GN",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.13991v1",
    "published_date": "2025-02-19 03:25:49 UTC",
    "updated_date": "2025-02-19 03:25:49 UTC"
  },
  {
    "arxiv_id": "2502.13398v1",
    "title": "$\\mathtt{GeLLM^3O}$: Generalizing Large Language Models for Multi-property Molecule Optimization",
    "authors": [
      "Vishal Dey",
      "Xiao Hu",
      "Xia Ning"
    ],
    "abstract": "Despite recent advancements, most computational methods for molecule\noptimization are constrained to single- or double-property optimization tasks\nand suffer from poor scalability and generalizability to novel optimization\ntasks. Meanwhile, Large Language Models (LLMs) demonstrate remarkable\nout-of-domain generalizability to novel tasks. To demonstrate LLMs' potential\nfor molecule optimization, we introduce $\\mathtt{MoMUInstruct}$, the first\nhigh-quality instruction-tuning dataset specifically focused on complex\nmulti-property molecule optimization tasks. Leveraging $\\mathtt{MoMUInstruct}$,\nwe develop $\\mathtt{GeLLM^3O}$s, a series of instruction-tuned LLMs for\nmolecule optimization. Extensive evaluations across 5 in-domain and 5\nout-of-domain tasks demonstrate that $\\mathtt{GeLLM^3O}$s consistently\noutperform state-of-the-art baselines. $\\mathtt{GeLLM^3O}$s also exhibit\noutstanding zero-shot generalization to unseen tasks, significantly\noutperforming powerful closed-source LLMs. Such strong generalizability\ndemonstrates the tremendous potential of $\\mathtt{GeLLM^3O}$s as foundational\nmodels for molecule optimization, thereby tackling novel optimization tasks\nwithout resource-intensive retraining. $\\mathtt{MoMUInstruct}$, models, and\ncode are accessible through https://github.com/ninglab/GeLLMO.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "physics.chem-ph",
      "q-bio.QM"
    ],
    "primary_category": "cs.LG",
    "comment": "Vishal Dey and Xiao Hu contributed equally to this paper",
    "pdf_url": "http://arxiv.org/pdf/2502.13398v1",
    "published_date": "2025-02-19 03:14:11 UTC",
    "updated_date": "2025-02-19 03:14:11 UTC"
  },
  {
    "arxiv_id": "2502.13392v2",
    "title": "Atomic Proximal Policy Optimization for Electric Robo-Taxi Dispatch and Charger Allocation",
    "authors": [
      "Jim Dai",
      "Manxi Wu",
      "Zhanhao Zhang"
    ],
    "abstract": "Pioneering companies such as Waymo have deployed robo-taxi services in\nseveral U.S. cities. These robo-taxis are electric vehicles, and their\noperations require the joint optimization of ride matching, vehicle\nrepositioning, and charging scheduling in a stochastic environment. We model\nthe operations of the ride-hailing system with robo-taxis as a discrete-time,\naverage-reward Markov Decision Process with an infinite horizon. As the fleet\nsize grows, dispatching becomes challenging, as both the system state space and\nthe fleet dispatching action space grow exponentially with the number of\nvehicles. To address this, we introduce a scalable deep reinforcement learning\nalgorithm, called Atomic Proximal Policy Optimization (Atomic-PPO), that\nreduces the action space using atomic action decomposition. We evaluate our\nalgorithm using real-world NYC for-hire vehicle trip records and measure its\nperformance by the long-run average reward achieved by the dispatching policy,\nrelative to a fluid-based upper bound. Our experiments demonstrate the superior\nperformance of Atomic-PPO compared to benchmark methods. Furthermore, we\nconduct extensive numerical experiments to analyze the efficient allocation of\ncharging facilities and assess the impact of vehicle range and charger speed on\nsystem performance.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.13392v2",
    "published_date": "2025-02-19 03:05:23 UTC",
    "updated_date": "2025-04-27 17:05:51 UTC"
  },
  {
    "arxiv_id": "2502.13389v1",
    "title": "Reasoning with Reinforced Functional Token Tuning",
    "authors": [
      "Kongcheng Zhang",
      "Qi Yao",
      "Baisheng Lai",
      "Jiaxing Huang",
      "Wenkai Fang",
      "Dacheng Tao",
      "Mingli Song",
      "Shunyu Liu"
    ],
    "abstract": "In this work, we propose Reinforced Functional Token Tuning (RFTT), a novel\nreinforced fine-tuning framework that empowers Large Language Models (LLMs)\nwith self-play learn-to-reason capabilities. Unlike prior prompt-driven\nreasoning efforts, RFTT embeds a rich set of learnable functional tokens (e.g.,\n<analyze>, <verify>, <refine>) directly into the model vocabulary, enabling\nchain-of-thought construction with diverse human-like reasoning behaviors.\nSpecifically, RFTT comprises two phases: (1) supervised fine-tuning performs\nprompt-driven tree search to obtain self-generated training data annotated with\nfunctional tokens, which warms up the model to learn these tokens for\nreasoning; and (2) online reinforcement learning further allows the model to\nexplore different reasoning pathways through functional token sampling without\nrelying on prompts, thereby facilitating effective self-improvement for\nfunctional reasoning. Extensive experiments demonstrate the superiority of the\nproposed RFTT on mathematical benchmarks, significantly boosting\nQwen-2.5-7B-Instruct (70.6% to 79.8%) and LLaMA-3.1-8B-Instruct (32.2% to\n60.2%) on the MATH dataset. Moreover, the performance of RFTT consistently\nimproves with more search rollouts at inference time. Our code is available at\nhttps://github.com/sastpg/RFTT.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.13389v1",
    "published_date": "2025-02-19 02:59:42 UTC",
    "updated_date": "2025-02-19 02:59:42 UTC"
  },
  {
    "arxiv_id": "2502.14909v2",
    "title": "Comparing Deep Neural Network for Multi-Label ECG Diagnosis From Scanned ECG",
    "authors": [
      "Cuong V. Nguyen",
      "Hieu X. Nguyen",
      "Dung D. Pham Minh",
      "Cuong D. Do"
    ],
    "abstract": "Automated ECG diagnosis has seen significant advancements with deep learning\ntechniques, but real-world applications still face challenges when dealing with\nscanned paper ECGs. In this study, we explore multi-label classification of\nECGs extracted from scanned images, moving beyond traditional binary\nclassification (normal/abnormal). We evaluate the performance of multiple deep\nneural network architectures, including AlexNet, VGG, ResNet, and Vision\nTransformer, on scanned ECG datasets. Our comparative analysis examines model\naccuracy, robustness to image artifacts, and generalizability across different\nECG conditions. Additionally, we investigate whether ECG signals extracted from\nscanned images retain sufficient diagnostic information for reliable automated\nclassification. The findings highlight the strengths and limitations of each\narchitecture, providing insights into the feasibility of image-based ECG\ndiagnosis and its potential integration into clinical workflows.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.14909v2",
    "published_date": "2025-02-19 02:56:27 UTC",
    "updated_date": "2025-03-06 05:18:12 UTC"
  },
  {
    "arxiv_id": "2502.13388v1",
    "title": "Reflection of Episodes: Learning to Play Game from Expert and Self Experiences",
    "authors": [
      "Xiaojie Xu",
      "Zongyuan Li",
      "Chang Lu",
      "Runnan Qi",
      "Yanan Ni",
      "Lumin Jiang",
      "Xiangbei Liu",
      "Xuebo Zhang",
      "Yongchun Fang",
      "Kuihua Huang",
      "Xian Guo",
      "Zhanghua Wu",
      "Zhenya Li"
    ],
    "abstract": "StarCraft II is a complex and dynamic real-time strategy (RTS) game\nenvironment, which is very suitable for artificial intelligence and\nreinforcement learning research. To address the problem of Large Language\nModel(LLM) learning in complex environments through self-reflection, we propose\na Reflection of Episodes(ROE) framework based on expert experience and\nself-experience. This framework first obtains key information in the game\nthrough a keyframe selection method, then makes decisions based on expert\nexperience and self-experience. After a game is completed, it reflects on the\nprevious experience to obtain new self-experience. Finally, in the experiment,\nour method beat the robot under the Very Hard difficulty in TextStarCraft II.\nWe analyze the data of the LLM in the process of the game in detail, verified\nits effectiveness.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.13388v1",
    "published_date": "2025-02-19 02:53:43 UTC",
    "updated_date": "2025-02-19 02:53:43 UTC"
  },
  {
    "arxiv_id": "2502.15801v1",
    "title": "An explainable transformer circuit for compositional generalization",
    "authors": [
      "Cheng Tang",
      "Brenden Lake",
      "Mehrdad Jazayeri"
    ],
    "abstract": "Compositional generalization-the systematic combination of known components\ninto novel structures-remains a core challenge in cognitive science and machine\nlearning. Although transformer-based large language models can exhibit strong\nperformance on certain compositional tasks, the underlying mechanisms driving\nthese abilities remain opaque, calling into question their interpretability. In\nthis work, we identify and mechanistically interpret the circuit responsible\nfor compositional induction in a compact transformer. Using causal ablations,\nwe validate the circuit and formalize its operation using a program-like\ndescription. We further demonstrate that this mechanistic understanding enables\nprecise activation edits to steer the model's behavior predictably. Our\nfindings advance the understanding of complex behaviors in transformers and\nhighlight such insights can provide a direct pathway for model control.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15801v1",
    "published_date": "2025-02-19 02:30:41 UTC",
    "updated_date": "2025-02-19 02:30:41 UTC"
  },
  {
    "arxiv_id": "2502.13376v1",
    "title": "Learning Symbolic Task Decompositions for Multi-Agent Teams",
    "authors": [
      "Ameesh Shah",
      "Niklas Lauffer",
      "Thomas Chen",
      "Nikhil Pitta",
      "Sanjit A. Seshia"
    ],
    "abstract": "One approach for improving sample efficiency in cooperative multi-agent\nlearning is to decompose overall tasks into sub-tasks that can be assigned to\nindividual agents. We study this problem in the context of reward machines:\nsymbolic tasks that can be formally decomposed into sub-tasks. In order to\nhandle settings without a priori knowledge of the environment, we introduce a\nframework that can learn the optimal decomposition from model-free interactions\nwith the environment. Our method uses a task-conditioned architecture to\nsimultaneously learn an optimal decomposition and the corresponding agents'\npolicies for each sub-task. In doing so, we remove the need for a human to\nmanually design the optimal decomposition while maintaining the\nsample-efficiency benefits of improved credit assignment. We provide\nexperimental results in several deep reinforcement learning settings,\ndemonstrating the efficacy of our approach. Our results indicate that our\napproach succeeds even in environments with codependent agent dynamics,\nenabling synchronous multi-agent learning not achievable in previous works.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.LG",
      "F.2.2"
    ],
    "primary_category": "cs.MA",
    "comment": "8 pages, main track full paper at AAMAS 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.13376v1",
    "published_date": "2025-02-19 02:24:44 UTC",
    "updated_date": "2025-02-19 02:24:44 UTC"
  },
  {
    "arxiv_id": "2502.13989v1",
    "title": "Erasing with Precision: Evaluating Specific Concept Erasure from Text-to-Image Generative Models",
    "authors": [
      "Masane Fuchi",
      "Tomohiro Takagi"
    ],
    "abstract": "Studies have been conducted to prevent specific concepts from being generated\nfrom pretrained text-to-image generative models, achieving concept erasure in\nvarious ways. However, the performance evaluation of these studies is still\nlargely reliant on visualization, with the superiority of studies often\ndetermined by human subjectivity. The metrics of quantitative evaluation also\nvary, making comprehensive comparisons difficult. We propose EraseEval, an\nevaluation method that differs from previous evaluation methods in that it\ninvolves three fundamental evaluation criteria: (1) How well does the prompt\ncontaining the target concept be reflected, (2) To what extent the concepts\nrelated to the erased concept can reduce the impact of the erased concept, and\n(3) Whether other concepts are preserved. These criteria are evaluated and\nintegrated into a single metric, such that a lower score is given if any of the\nevaluations are low, leading to a more robust assessment. We experimentally\nevaluated baseline concept erasure methods, organized their characteristics,\nand identified challenges with them. Despite being fundamental evaluation\ncriteria, some concept erasure methods failed to achieve high scores, which\npoint toward future research directions for concept erasure methods. Our code\nis available at https://github.com/fmp453/erase-eval.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "21 pages, 8 figures, 15 tables",
    "pdf_url": "http://arxiv.org/pdf/2502.13989v1",
    "published_date": "2025-02-19 02:19:38 UTC",
    "updated_date": "2025-02-19 02:19:38 UTC"
  },
  {
    "arxiv_id": "2502.13373v1",
    "title": "Fighter Jet Navigation and Combat using Deep Reinforcement Learning with Explainable AI",
    "authors": [
      "Swati Kar",
      "Soumyabrata Dey",
      "Mahesh K Banavar",
      "Shahnewaz Karim Sakib"
    ],
    "abstract": "This paper presents the development of an Artificial Intelligence (AI) based\nfighter jet agent within a customized Pygame simulation environment, designed\nto solve multi-objective tasks via deep reinforcement learning (DRL). The jet's\nprimary objectives include efficiently navigating the environment, reaching a\ntarget, and selectively engaging or evading an enemy. A reward function\nbalances these goals while optimized hyperparameters enhance learning\nefficiency. Results show more than 80\\% task completion rate, demonstrating\neffective decision-making. To enhance transparency, the jet's action choices\nare analyzed by comparing the rewards of the actual chosen action (factual\naction) with those of alternate actions (counterfactual actions), providing\ninsights into the decision-making rationale. This study illustrates DRL's\npotential for multi-objective problem-solving with explainable AI. Project page\nis available at:\n\\href{https://github.com/swatikar95/Autonomous-Fighter-Jet-Navigation-and-Combat}{Project\nGitHub Link}.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.13373v1",
    "published_date": "2025-02-19 02:14:27 UTC",
    "updated_date": "2025-02-19 02:14:27 UTC"
  },
  {
    "arxiv_id": "2502.13361v1",
    "title": "RGAR: Recurrence Generation-augmented Retrieval for Factual-aware Medical Question Answering",
    "authors": [
      "Sichu Liang",
      "Linhai Zhang",
      "Hongyu Zhu",
      "Wenwen Wang",
      "Yulan He",
      "Deyu Zhou"
    ],
    "abstract": "Medical question answering requires extensive access to specialized\nconceptual knowledge. The current paradigm, Retrieval-Augmented Generation\n(RAG), acquires expertise medical knowledge through large-scale corpus\nretrieval and uses this knowledge to guide a general-purpose large language\nmodel (LLM) for generating answers. However, existing retrieval approaches\noften overlook the importance of factual knowledge, which limits the relevance\nof retrieved conceptual knowledge and restricts its applicability in real-world\nscenarios, such as clinical decision-making based on Electronic Health Records\n(EHRs). This paper introduces RGAR, a recurrence generation-augmented retrieval\nframework that retrieves both relevant factual and conceptual knowledge from\ndual sources (i.e., EHRs and the corpus), allowing them to interact and refine\neach another. Through extensive evaluation across three factual-aware medical\nquestion answering benchmarks, RGAR establishes a new state-of-the-art\nperformance among medical RAG systems. Notably, the Llama-3.1-8B-Instruct model\nwith RGAR surpasses the considerably larger, RAG-enhanced GPT-3.5. Our findings\ndemonstrate the benefit of extracting factual knowledge for retrieval, which\nconsistently yields improved generation quality.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.13361v1",
    "published_date": "2025-02-19 01:50:10 UTC",
    "updated_date": "2025-02-19 01:50:10 UTC"
  },
  {
    "arxiv_id": "2502.18495v2",
    "title": "A Comprehensive Survey on Composed Image Retrieval",
    "authors": [
      "Xuemeng Song",
      "Haoqiang Lin",
      "Haokun Wen",
      "Bohan Hou",
      "Mingzhu Xu",
      "Liqiang Nie"
    ],
    "abstract": "Composed Image Retrieval (CIR) is an emerging yet challenging task that\nallows users to search for target images using a multimodal query, comprising a\nreference image and a modification text specifying the user's desired changes\nto the reference image. Given its significant academic and practical value, CIR\nhas become a rapidly growing area of interest in the computer vision and\nmachine learning communities, particularly with the advances in deep learning.\nTo the best of our knowledge, there is currently no comprehensive review of CIR\nto provide a timely overview of this field. Therefore, we synthesize insights\nfrom over 120 publications in top conferences and journals, including ACM TOIS,\nSIGIR, and CVPR In particular, we systematically categorize existing supervised\nCIR and zero-shot CIR models using a fine-grained taxonomy. For a comprehensive\nreview, we also briefly discuss approaches for tasks closely related to CIR,\nsuch as attribute-based CIR and dialog-based CIR. Additionally, we summarize\nbenchmark datasets for evaluation and analyze existing supervised and zero-shot\nCIR methods by comparing experimental results across multiple datasets.\nFurthermore, we present promising future directions in this field, offering\npractical insights for researchers interested in further exploration. The\ncurated collection of related works is maintained and continuously updated in\nhttps://github.com/haokunwen/Awesome-Composed-Image-Retrieval.",
    "categories": [
      "cs.MM",
      "cs.AI",
      "cs.CV",
      "cs.IR"
    ],
    "primary_category": "cs.MM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.18495v2",
    "published_date": "2025-02-19 01:37:24 UTC",
    "updated_date": "2025-03-04 15:16:52 UTC"
  },
  {
    "arxiv_id": "2502.14908v2",
    "title": "SegSub: Evaluating Robustness to Knowledge Conflicts and Hallucinations in Vision-Language Models",
    "authors": [
      "Peter Carragher",
      "Nikitha Rao",
      "Abhinand Jha",
      "R Raghav",
      "Kathleen M. Carley"
    ],
    "abstract": "Vision language models (VLM) demonstrate sophisticated multimodal reasoning\nyet are prone to hallucination when confronted with knowledge conflicts,\nimpeding their deployment in information-sensitive contexts. While existing\nresearch addresses robustness in unimodal models, the multimodal domain lacks\nsystematic investigation of cross-modal knowledge conflicts. This research\nintroduces \\segsub, a framework for applying targeted image perturbations to\ninvestigate VLM resilience against knowledge conflicts. Our analysis reveals\ndistinct vulnerability patterns: while VLMs are robust to parametric conflicts\n(20% adherence rates), they exhibit significant weaknesses in identifying\ncounterfactual conditions (<30% accuracy) and resolving source conflicts (<1%\naccuracy). Correlations between contextual richness and hallucination rate (r =\n-0.368, p = 0.003) reveal the kinds of images that are likely to cause\nhallucinations. Through targeted fine-tuning on our benchmark dataset, we\ndemonstrate improvements in VLM knowledge conflict detection, establishing a\nfoundation for developing hallucination-resilient multimodal systems in\ninformation-sensitive environments.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.14908v2",
    "published_date": "2025-02-19 00:26:38 UTC",
    "updated_date": "2025-05-09 18:36:00 UTC"
  },
  {
    "arxiv_id": "2502.14907v1",
    "title": "GneissWeb: Preparing High Quality Data for LLMs at Scale",
    "authors": [
      "Hajar Emami Gohari",
      "Swanand Ravindra Kadhe",
      "Syed Yousaf Shah. Constantin Adam",
      "Abdulhamid Adebayo",
      "Praneet Adusumilli",
      "Farhan Ahmed",
      "Nathalie Baracaldo Angel",
      "Santosh Borse",
      "Yuan-Chi Chang",
      "Xuan-Hong Dang",
      "Nirmit Desai",
      "Ravital Eres",
      "Ran Iwamoto",
      "Alexei Karve",
      "Yan Koyfman",
      "Wei-Han Lee",
      "Changchang Liu",
      "Boris Lublinsky",
      "Takuyo Ohko",
      "Pablo Pesce",
      "Maroun Touma",
      "Shiqiang Wang",
      "Shalisha Witherspoon",
      "Herbert Woisetschlager",
      "David Wood",
      "Kun-Lung Wu",
      "Issei Yoshida",
      "Syed Zawad",
      "Petros Zerfos",
      "Yi Zhou",
      "Bishwaranjan Bhattacharjee"
    ],
    "abstract": "Data quantity and quality play a vital role in determining the performance of\nLarge Language Models (LLMs). High-quality data, in particular, can\nsignificantly boost the LLM's ability to generalize on a wide range of\ndownstream tasks. Large pre-training datasets for leading LLMs remain\ninaccessible to the public, whereas many open datasets are small in size (less\nthan 5 trillion tokens), limiting their suitability for training large models.\n  In this paper, we introduce GneissWeb, a large dataset yielding around 10\ntrillion tokens that caters to the data quality and quantity requirements of\ntraining LLMs. Our GneissWeb recipe that produced the dataset consists of\nsharded exact sub-string deduplication and a judiciously constructed ensemble\nof quality filters. GneissWeb achieves a favorable trade-off between data\nquality and quantity, producing models that outperform models trained on\nstate-of-the-art open large datasets (5+ trillion tokens).\n  We show that models trained using GneissWeb dataset outperform those trained\non FineWeb-V1.1.0 by 2.73 percentage points in terms of average score computed\non a set of 11 commonly used benchmarks (both zero-shot and few-shot) for\npre-training dataset evaluation. When the evaluation set is extended to 20\nbenchmarks (both zero-shot and few-shot), models trained using GneissWeb still\nachieve a 1.75 percentage points advantage over those trained on\nFineWeb-V1.1.0.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.14907v1",
    "published_date": "2025-02-19 00:14:29 UTC",
    "updated_date": "2025-02-19 00:14:29 UTC"
  }
]