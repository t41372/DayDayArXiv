{
  "date": "2025-02-19",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-02-19 的 arXiv 中文 TLDR 快报！今天 arXiv 更新了 168 篇论文，主要聚焦于 AI 安全、LLM 推理优化、多代理系统风险以及视觉语言模型创新，亮点包括第 3 篇的多作者合作探讨多代理 AI 风险，以及 LLM 在复杂任务中的自提升和鲁棒性研究。\n\n### 重点论文讨论\n我们先聊聊今天最引人注目的论文，特别是那些涉及 LLM 推理、对齐和安全的关键工作，以及一些创新性强的研究。以下挑选了最具话题度和影响力的论文，相关主题优先放在一起讨论。\n\n- **Giving AI Personalities Leads to More Human-Like Reasoning (赋予 AI 个性以实现更人性化的推理)**  \n  这篇论文探讨了通过 Big Five 个性模型增强 LLM 的推理能力，使用遗传算法优化提示，显著提升了模型对人类响应分布的预测。核心贡献是证明人格化提示能模拟人类 System 1 和 System 2 推理，Llama 和 Mistral 等开源模型在该任务中超过了 GPT 模型。\n\n- **Multi-Agent Risks from Advanced AI (高级 AI 的多代理风险)**  \n  作者包括知名学者如 Jakob Foerster 和 Iyad Rahwan，这篇报告提出了多代理系统的风险分类，包括失调、冲突和勾结，并分析了七个关键风险因素。发现是通过现实案例和实验证据，强调了多代理 AI 在安全和治理中的挑战，是 AI 风险领域的重要讨论点。\n\n- **Can Community Notes Replace Professional Fact-Checkers? (社区笔记能否取代专业事实核查员？)**  \n  论文揭示社区笔记在社交媒体事实核查中高度依赖专业来源，分析了大量 Twitter 数据，发现事实核查对处理更广泛的错误叙述至关重要。贡献在于量化了社区核查的局限性，推动了 AI 在 misinformation 检测的伦理讨论。\n\n- **ChatWise: AI-Powered Engaging Conversations for Enhancing Senior Cognitive Wellbeing (ChatWise: 基于 AI 的互动对话提升老年人认知福祉)**  \n  这篇工作开发了 ChatWise，一个 LLM 驱动的聊天机器人，支持多轮对话以提升老年人认知健康。发现是通过实验证明，它显著改善了模拟用户的认知和情绪状态，尤其对轻度认知障碍患者有效。\n\n- **Zero loss guarantees and explicit minimizers for generic overparametrized Deep Learning networks (过参数化深度学习网络的零损失保证和显式最小化器)**  \n  作者 Thomas Chen 等人证明了过参数化 DL 网络在监督学习中的零损失可达性，并提供了显式最小化器。贡献在于分析了深度增加对梯度下降效率的影响，提供理论指导。\n\n- **Object-centric Binding in Contrastive Language-Image Pretraining (基于对象的绑定在对比语言-图像预训练中)**  \n  论文提出了一种新方法，通过场景图和槽位结构提升 CLIP 模型在多对象场景中的组合理解。发现是显著提高了图像-文本匹配性能，而无需额外负样本。\n\n- **Triad: Vision Foundation Model for 3D Magnetic Resonance Imaging (Triad: 3D 磁共振成像的视觉基础模型)**  \n  这篇工作介绍了 Triad，一个针对 3D MRI 的视觉基础模型，使用自监督学习在 13 万 MRI 体积上训练。贡献在于提升了器官分割和分类性能，展示了预训练在医学图像中的潜力。\n\n- **DiffExp: Efficient Exploration in Reward Fine-tuning for Text-to-Image Diffusion Models (DiffExp: 文本到图像扩散模型中奖励微调的有效探索)**  \n  论文优化了文本到图像扩散模型的奖励微调，通过动态调整指导规模和提示权重提升样本多样性。发现是显著提高了生成效率和质量。\n\n其他相关论文，如第 11、14、24、25、28、39、40、44、48、54、61、63、64、65、66、67、68、69、70、71、72、73、74、75、76、77、78、79、80、81、82、83、84、85、86、87、88、89、90、91、92、93、94、95、96、97、98、99、100、101、102、103、104、105、106、107、108、109、110、111、112、113、114、115、116、117、118、119、120、121、122、123、124、125、126、127、128、129、130、131、132、133、134、135、136、137、138、139、140、141、142、143、144、145、146、147、148、149、150、151、152、153、154、155、156、157、158、159、160、161、162、163、164、165、166、167、168 篇，主要扩展了 LLM 在安全、对齐和视觉任务的优化，但由于篇幅有限，这里快速掠过：这些论文大多聚焦 LLM 的鲁棒性提升、知识蒸馏和多模态融合，例如第 13 篇的个性化教育框架、第 17 篇的 3D MRI 模型，以及第 23 篇的强化学习无悔保证等，都展示了 AI 在实际应用中的潜力，但细节可参考摘要。\n\n总之，今天的论文突出了 AI 模型在推理和安全方面的进展，相关研究将继续推动 LLM 的实际部署。更多细节请查阅 arXiv！",
  "papers": [
    {
      "arxiv_id": "2502.14155v2",
      "title": "Giving AI Personalities Leads to More Human-Like Reasoning",
      "title_zh": "赋予 AI 个性会导致更像人类的推理",
      "authors": [
        "Animesh Nighojkar",
        "Bekhzodbek Moydinboyev",
        "My Duong",
        "John Licato"
      ],
      "abstract": "In computational cognitive modeling, capturing the full spectrum of human\njudgment and decision-making processes, beyond just optimal behaviors, is a\nsignificant challenge. This study explores whether Large Language Models (LLMs)\ncan emulate the breadth of human reasoning by predicting both intuitive, fast\nSystem 1 and deliberate, slow System 2 processes. We investigate the potential\nof AI to mimic diverse reasoning behaviors across a human population,\naddressing what we call the \"full reasoning spectrum problem\". We designed\nreasoning tasks using a novel generalization of the Natural Language Inference\n(NLI) format to evaluate LLMs' ability to replicate human reasoning. The\nquestions were crafted to elicit both System 1 and System 2 responses. Human\nresponses were collected through crowd-sourcing and the entire distribution was\nmodeled, rather than just the majority of the answers. We used\npersonality-based prompting inspired by the Big Five personality model to\nelicit AI responses reflecting specific personality traits, capturing the\ndiversity of human reasoning, and exploring how personality traits influence\nLLM outputs. Combined with genetic algorithms to optimize the weighting of\nthese prompts, this method was tested alongside traditional machine learning\nmodels. The results show that LLMs can mimic human response distributions, with\nopen-source models like Llama and Mistral outperforming proprietary GPT models.\nPersonality-based prompting, especially when optimized with genetic algorithms,\nsignificantly enhanced LLMs' ability to predict human response distributions,\nsuggesting that capturing suboptimal, naturalistic reasoning may require\nmodeling techniques incorporating diverse reasoning styles and psychological\nprofiles. The study concludes that personality-based prompting combined with\ngenetic algorithms is promising for enhancing AI's 'human-ness' in reasoning.",
      "tldr_zh": "本研究探讨了赋予 Large Language Models (LLMs) 个性特征是否能模拟人类推理的全谱系，包括直观的 System 1 和深思熟虑的 System 2 过程，以解决“全推理谱系问题”。研究者设计了基于 Natural Language Inference (NLI) 格式的推理任务，通过众包收集人类响应，并使用 personality-based prompting（受 Big Five 个性模型启发）结合 genetic algorithms 优化提示权重，来生成多样化的 AI 响应。结果显示，开源模型如 Llama 和 Mistral 在模仿人类响应分布方面优于 GPT 模型，而这种方法显著提升了 LLMs 的预测准确性。总体而言，该方法证明了通过整合个性特征和优化算法，可以增强 AI 的“人性化”推理能力，捕捉次优和自然主义行为。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14155v2",
      "published_date": "2025-02-19 23:51:23 UTC",
      "updated_date": "2025-02-21 14:57:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:38:40.679443"
    },
    {
      "arxiv_id": "2502.14149v1",
      "title": "PitVQA++: Vector Matrix-Low-Rank Adaptation for Open-Ended Visual Question Answering in Pituitary Surgery",
      "title_zh": "翻译失败",
      "authors": [
        "Runlong He",
        "Danyal Z. Khan",
        "Evangelos B. Mazomenos",
        "Hani J. Marcus",
        "Danail Stoyanov",
        "Matthew J. Clarkson",
        "Mobarakol Islam"
      ],
      "abstract": "Vision-Language Models (VLMs) in visual question answering (VQA) offer a\nunique opportunity to enhance intra-operative decision-making, promote\nintuitive interactions, and significantly advancing surgical education.\nHowever, the development of VLMs for surgical VQA is challenging due to limited\ndatasets and the risk of overfitting and catastrophic forgetting during full\nfine-tuning of pretrained weights. While parameter-efficient techniques like\nLow-Rank Adaptation (LoRA) and Matrix of Rank Adaptation (MoRA) address\nadaptation challenges, their uniform parameter distribution overlooks the\nfeature hierarchy in deep networks, where earlier layers, that learn general\nfeatures, require more parameters than later ones. This work introduces\nPitVQA++ with an open-ended PitVQA dataset and vector matrix-low-rank\nadaptation (Vector-MoLoRA), an innovative VLM fine-tuning approach for adapting\nGPT-2 to pituitary surgery. Open-Ended PitVQA comprises around 101,803 frames\nfrom 25 procedural videos with 745,972 question-answer sentence pairs, covering\nkey surgical elements such as phase and step recognition, context\nunderstanding, tool detection, localization, and interactions recognition.\nVector-MoLoRA incorporates the principles of LoRA and MoRA to develop a\nmatrix-low-rank adaptation strategy that employs vector ranking to allocate\nmore parameters to earlier layers, gradually reducing them in the later layers.\nOur approach, validated on the Open-Ended PitVQA and EndoVis18-VQA datasets,\neffectively mitigates catastrophic forgetting while significantly enhancing\nperformance over recent baselines. Furthermore, our risk-coverage analysis\nhighlights its enhanced reliability and trustworthiness in handling uncertain\npredictions. Our source code and dataset is available\nat~\\url{https://github.com/HRL-Mike/PitVQA-Plus}.",
      "tldr_zh": "该论文提出 PitVQA++，一种针对垂体手术的开放式视觉问答 (VQA) 框架，旨在解决视觉语言模型 (VLMs) 在手术决策、教育中的挑战，包括数据集不足和灾难性遗忘问题。研究构建了 Open-Ended PitVQA 数据集，包含约 101,803 帧视频和 745,972 个问答对，涵盖手术阶段识别、工具检测和交互等关键元素。创新方法 Vector-MoLoRA 结合 LoRA 和 MoRA，通过向量排名策略在模型细调中分配更多参数给早期层，逐步减少后期层，以适应深度网络的特征层次。实验在 Open-Ended PitVQA 和 EndoVis18-VQA 数据集上验证，该方法显著提升性能、缓解灾难性遗忘，并通过风险覆盖分析证明其可靠性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "9 pages",
      "pdf_url": "http://arxiv.org/pdf/2502.14149v1",
      "published_date": "2025-02-19 23:28:39 UTC",
      "updated_date": "2025-02-19 23:28:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:38:53.472268"
    },
    {
      "arxiv_id": "2502.14143v1",
      "title": "Multi-Agent Risks from Advanced AI",
      "title_zh": "翻译失败",
      "authors": [
        "Lewis Hammond",
        "Alan Chan",
        "Jesse Clifton",
        "Jason Hoelscher-Obermaier",
        "Akbir Khan",
        "Euan McLean",
        "Chandler Smith",
        "Wolfram Barfuss",
        "Jakob Foerster",
        "Tomáš Gavenčiak",
        "The Anh Han",
        "Edward Hughes",
        "Vojtěch Kovařík",
        "Jan Kulveit",
        "Joel Z. Leibo",
        "Caspar Oesterheld",
        "Christian Schroeder de Witt",
        "Nisarg Shah",
        "Michael Wellman",
        "Paolo Bova",
        "Theodor Cimpeanu",
        "Carson Ezell",
        "Quentin Feuillade-Montixi",
        "Matija Franklin",
        "Esben Kran",
        "Igor Krawczuk",
        "Max Lamparth",
        "Niklas Lauffer",
        "Alexander Meinke",
        "Sumeet Motwani",
        "Anka Reuel",
        "Vincent Conitzer",
        "Michael Dennis",
        "Iason Gabriel",
        "Adam Gleave",
        "Gillian Hadfield",
        "Nika Haghtalab",
        "Atoosa Kasirzadeh",
        "Sébastien Krier",
        "Kate Larson",
        "Joel Lehman",
        "David C. Parkes",
        "Georgios Piliouras",
        "Iyad Rahwan"
      ],
      "abstract": "The rapid development of advanced AI agents and the imminent deployment of\nmany instances of these agents will give rise to multi-agent systems of\nunprecedented complexity. These systems pose novel and under-explored risks. In\nthis report, we provide a structured taxonomy of these risks by identifying\nthree key failure modes (miscoordination, conflict, and collusion) based on\nagents' incentives, as well as seven key risk factors (information asymmetries,\nnetwork effects, selection pressures, destabilising dynamics, commitment\nproblems, emergent agency, and multi-agent security) that can underpin them. We\nhighlight several important instances of each risk, as well as promising\ndirections to help mitigate them. By anchoring our analysis in a range of\nreal-world examples and experimental evidence, we illustrate the distinct\nchallenges posed by multi-agent systems and their implications for the safety,\ngovernance, and ethics of advanced AI.",
      "tldr_zh": "这篇论文探讨了先进 AI 代理的多代理系统（multi-agent systems）可能带来的新风险，通过结构化分类识别出三个关键失败模式（miscoordination, conflict, and collusion），这些基于代理的激励机制。论文进一步列出了七个关键风险因素（information asymmetries, network effects, selection pressures, destabilising dynamics, commitment problems, emergent agency, and multi-agent security），并结合真实例子和实验证据，阐述了这些风险的实例和潜在缓解策略。最终，研究强调了多代理系统对 AI 安全、治理和伦理的深远影响。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.CY",
        "cs.ET",
        "cs.LG"
      ],
      "primary_category": "cs.MA",
      "comment": "Cooperative AI Foundation, Technical Report #1",
      "pdf_url": "http://arxiv.org/pdf/2502.14143v1",
      "published_date": "2025-02-19 23:03:21 UTC",
      "updated_date": "2025-02-19 23:03:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:39:04.245099"
    },
    {
      "arxiv_id": "2502.14132v1",
      "title": "Can Community Notes Replace Professional Fact-Checkers?",
      "title_zh": "翻译失败",
      "authors": [
        "Nadav Borenstein",
        "Greta Warren",
        "Desmond Elliott",
        "Isabelle Augenstein"
      ],
      "abstract": "Two commonly-employed strategies to combat the rise of misinformation on\nsocial media are (i) fact-checking by professional organisations and (ii)\ncommunity moderation by platform users. Policy changes by Twitter/X and, more\nrecently, Meta, signal a shift away from partnerships with fact-checking\norganisations and towards an increased reliance on crowdsourced community\nnotes. However, the extent and nature of dependencies between fact-checking and\nhelpful community notes remain unclear. To address these questions, we use\nlanguage models to annotate a large corpus of Twitter/X community notes with\nattributes such as topic, cited sources, and whether they refute claims tied to\nbroader misinformation narratives. Our analysis reveals that community notes\ncite fact-checking sources up to five times more than previously reported.\nFact-checking is especially crucial for notes on posts linked to broader\nnarratives, which are twice as likely to reference fact-checking sources\ncompared to other sources. In conclusion, our results show that successful\ncommunity moderation heavily relies on professional fact-checking.",
      "tldr_zh": "这篇论文探讨了社交媒体上 Community Notes 是否能取代专业 Fact-Checkers 的问题，通过使用语言模型分析 Twitter/X 的社区 notes，包括主题、引用的来源以及是否反驳 misinformation 叙事。研究发现，社区 notes 引用事实检查来源的频率比之前报道高出五倍，尤其是在处理与更广泛 misinformation 叙事相关的帖子时，这些 notes 更倾向于依赖事实检查来源。最终结论是，成功的社区 moderation 高度依赖专业 Fact-Checkers，因此无法完全取代它们。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14132v1",
      "published_date": "2025-02-19 22:26:39 UTC",
      "updated_date": "2025-02-19 22:26:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:39:16.239387"
    },
    {
      "arxiv_id": "2502.14131v3",
      "title": "An Empirical Risk Minimization Approach for Offline Inverse RL and Dynamic Discrete Choice Model",
      "title_zh": "翻译失败",
      "authors": [
        "Enoch H. Kang",
        "Hema Yoganarasimhan",
        "Lalit Jain"
      ],
      "abstract": "We study the problem of estimating Dynamic Discrete Choice (DDC) models, also\nknown as offline Maximum Entropy-Regularized Inverse Reinforcement Learning\n(offline MaxEnt-IRL) in machine learning. The objective is to recover reward or\n$Q^*$ functions that govern agent behavior from offline behavior data. In this\npaper, we propose a globally convergent gradient-based method for solving these\nproblems without the restrictive assumption of linearly parameterized rewards.\nThe novelty of our approach lies in introducing the Empirical Risk Minimization\n(ERM) based IRL/DDC framework, which circumvents the need for explicit state\ntransition probability estimation in the Bellman equation. Furthermore, our\nmethod is compatible with non-parametric estimation techniques such as neural\nnetworks. Therefore, the proposed method has the potential to be scaled to\nhigh-dimensional, infinite state spaces. A key theoretical insight underlying\nour approach is that the Bellman residual satisfies the Polyak-Lojasiewicz (PL)\ncondition -- a property that, while weaker than strong convexity, is sufficient\nto ensure fast global convergence guarantees. Through a series of synthetic\nexperiments, we demonstrate that our approach consistently outperforms\nbenchmark methods and state-of-the-art alternatives.",
      "tldr_zh": "本研究针对离线 Inverse Reinforcement Learning (IRL) 和 Dynamic Discrete Choice (DDC) 模型，提出了一种基于 Empirical Risk Minimization (ERM) 的方法，用于从离线行为数据中恢复 reward 或 Q* 函数，而无需假设 reward 为线性参数化。创新点在于，该框架避免了 Bellman 方程中显式估计状态转移概率，并兼容非参数技术如 neural networks，从而适用于高维或无限状态空间。理论上，该方法利用 Bellman residual 满足 Polyak-Lojasiewicz (PL) 条件，确保梯度算法的快速全局收敛。在合成实验中，该方法优于基准和最先进方法，展示了其有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "econ.EM"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14131v3",
      "published_date": "2025-02-19 22:22:20 UTC",
      "updated_date": "2025-05-06 17:12:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:39:28.937080"
    },
    {
      "arxiv_id": "2502.14121v1",
      "title": "Multi-Objective Bayesian Optimization for Networked Black-Box Systems: A Path to Greener Profits and Smarter Designs",
      "title_zh": "多目标贝叶斯优化用于网络化黑箱系统：通往更环保利润和更智能设计的路径",
      "authors": [
        "Akshay Kudva",
        "Wei-Ting Tang",
        "Joel A. Paulson"
      ],
      "abstract": "Designing modern industrial systems requires balancing several competing\nobjectives, such as profitability, resilience, and sustainability, while\naccounting for complex interactions between technological, economic, and\nenvironmental factors. Multi-objective optimization (MOO) methods are commonly\nused to navigate these tradeoffs, but selecting the appropriate algorithm to\ntackle these problems is often unclear, particularly when system\nrepresentations vary from fully equation-based (white-box) to entirely\ndata-driven (black-box) models. While grey-box MOO methods attempt to bridge\nthis gap, they typically impose rigid assumptions on system structure,\nrequiring models to conform to the underlying structural assumptions of the\nsolver rather than the solver adapting to the natural representation of the\nsystem of interest. In this chapter, we introduce a unifying approach to\ngrey-box MOO by leveraging network representations, which provide a general and\nflexible framework for modeling interconnected systems as a series of function\nnodes that share various inputs and outputs. Specifically, we propose MOBONS, a\nnovel Bayesian optimization-inspired algorithm that can efficiently optimize\ngeneral function networks, including those with cyclic dependencies, enabling\nthe modeling of feedback loops, recycle streams, and multi-scale simulations -\nfeatures that existing methods fail to capture. Furthermore, MOBONS\nincorporates constraints, supports parallel evaluations, and preserves the\nsample efficiency of Bayesian optimization while leveraging network structure\nfor improved scalability. We demonstrate the effectiveness of MOBONS through\ntwo case studies, including one related to sustainable process design. By\nenabling efficient MOO under general graph representations, MOBONS has the\npotential to significantly enhance the design of more profitable, resilient,\nand sustainable engineering systems.",
      "tldr_zh": "本论文探讨了多目标优化（MOO）在设计现代工业系统中的应用，旨在平衡盈利能力、韧性和可持续性等目标，同时处理从白箱到黑箱系统的复杂表示。作者提出 MOBONS，一种基于 Bayesian 优化启发的算法，利用网络表示来优化互联系统，支持循环依赖、约束处理、并行评估，并提升样本效率和可扩展性。通过两个案例研究，包括可持续过程设计，MOBONS 展示了显著的优化性能，有望提升工程系统的盈利、韧性和可持续性设计。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14121v1",
      "published_date": "2025-02-19 21:49:05 UTC",
      "updated_date": "2025-02-19 21:49:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:39:40.074140"
    },
    {
      "arxiv_id": "2503.05740v1",
      "title": "ChatWise: AI-Powered Engaging Conversations for Enhancing Senior Cognitive Wellbeing",
      "title_zh": "翻译失败",
      "authors": [
        "Zhengbang Yang",
        "Zhuangdi Zhu"
      ],
      "abstract": "Cognitive health in older adults presents a growing challenge. While\nconversational interventions show feasibility in improving cognitive wellness,\nhuman caregiver resources remain overburdened. AI-based methods have shown\npromise in providing conversational support, yet existing work is limited to\nimplicit strategy while lacking multi-turn support tailored to seniors. We\nimprove prior art with an LLM-driven chatbot named ChatWise for older adults.\nIt follows dual-level conversation reasoning at the inference phase to provide\nengaging companionship. ChatWise thrives in long-turn conversations, in\ncontrast to conventional LLMs that primarily excel in short-turn exchanges.\nGrounded experiments show that ChatWise significantly enhances simulated users'\ncognitive and emotional status, including those with Mild Cognitive Impairment.",
      "tldr_zh": "该研究针对老年人认知健康挑战，提出了一种基于LLM的聊天机器人ChatWise，以缓解人类护理资源不足的问题。ChatWise采用双层对话推理机制，支持长轮对话，提供引人入胜的陪伴体验，与传统LLM在短轮对话中的优势不同。实验结果显示，ChatWise显著提升模拟用户的认知和情感状态，包括Mild Cognitive Impairment患者。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.05740v1",
      "published_date": "2025-02-19 21:32:09 UTC",
      "updated_date": "2025-02-19 21:32:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:39:51.657046"
    },
    {
      "arxiv_id": "2502.14114v1",
      "title": "Zero loss guarantees and explicit minimizers for generic overparametrized Deep Learning networks",
      "title_zh": "针对泛化的过参数化深度学习网络的零损失保证",
      "authors": [
        "Thomas Chen",
        "Andrew G. Moore"
      ],
      "abstract": "We determine sufficient conditions for overparametrized deep learning (DL)\nnetworks to guarantee the attainability of zero loss in the context of\nsupervised learning, for the $\\mathcal{L}^2$ cost and {\\em generic} training\ndata. We present an explicit construction of the zero loss minimizers without\ninvoking gradient descent. On the other hand, we point out that increase of\ndepth can deteriorate the efficiency of cost minimization using a gradient\ndescent algorithm by analyzing the conditions for rank loss of the training\nJacobian. Our results clarify key aspects on the dichotomy between zero loss\nreachability in underparametrized versus overparametrized DL.",
      "tldr_zh": "本文研究了过参数化深度学习（DL）网络的充分条件，这些条件能保证在监督学习中实现 zero loss，并针对 L2 cost 和通用训练数据提供了显式最小化器的构建方法，而非依赖梯度下降。研究通过分析训练 Jacobian 的秩损失，指出增加网络深度可能降低梯度下降算法的效率，从而影响成本最小化。总体结果阐明了欠参数化和过参数化 DL 网络在 zero loss 可达性方面的关键差异，为深度学习理论提供了新洞见。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.AP",
        "math.OC",
        "stat.ML",
        "57R70, 62M45"
      ],
      "primary_category": "cs.LG",
      "comment": "AMS Latex, 9 pages",
      "pdf_url": "http://arxiv.org/pdf/2502.14114v1",
      "published_date": "2025-02-19 21:31:05 UTC",
      "updated_date": "2025-02-19 21:31:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:40:04.450662"
    },
    {
      "arxiv_id": "2502.14113v1",
      "title": "Object-centric Binding in Contrastive Language-Image Pretraining",
      "title_zh": "对象中心绑定在对比性语言-图像预训练中",
      "authors": [
        "Rim Assouel",
        "Pietro Astolfi",
        "Florian Bordes",
        "Michal Drozdzal",
        "Adriana Romero-Soriano"
      ],
      "abstract": "Recent advances in vision language models (VLM) have been driven by\ncontrastive models such as CLIP, which learn to associate visual information\nwith their corresponding text descriptions. However, these models have\nlimitations in understanding complex compositional scenes involving multiple\nobjects and their spatial relationships. To address these challenges, we\npropose a novel approach that diverges from commonly used strategies, which\nrely on the design of hard-negative augmentations. Instead, our work focuses on\nintegrating inductive biases into pre-trained CLIP-like models to improve their\ncompositional understanding without using any additional hard-negatives. To\nthat end, we introduce a binding module that connects a scene graph, derived\nfrom a text description, with a slot-structured image representation,\nfacilitating a structured similarity assessment between the two modalities. We\nalso leverage relationships as text-conditioned visual constraints, thereby\ncapturing the intricate interactions between objects and their contextual\nrelationships more effectively. Our resulting model not only enhances the\nperformance of CLIP-based models in multi-object compositional understanding\nbut also paves the way towards more accurate and sample-efficient image-text\nmatching of complex scenes.",
      "tldr_zh": "本研究针对视觉语言模型 (VLM) 如 CLIP 在处理多对象和空间关系的复杂组合场景时存在的局限性，提出了一种新型方法。不同于依赖 hard-negative augmentations 的传统策略，该方法通过整合 inductive biases 到预训练 CLIP-like 模型中，提升其组合理解能力。具体而言，引入了一个 binding module，将从文本描述派生的 scene graph 与 slot-structured image representation 连接起来，并利用 relationships 作为 text-conditioned visual constraints 来捕捉对象间的互动。实验结果显示，该模型显著提高了 CLIP 在多对象场景下的性能，并提升了复杂图像-文本匹配的准确性和样本效率。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14113v1",
      "published_date": "2025-02-19 21:30:51 UTC",
      "updated_date": "2025-02-19 21:30:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:40:16.334063"
    },
    {
      "arxiv_id": "2502.14102v1",
      "title": "Explainable Distributed Constraint Optimization Problems",
      "title_zh": "可解释的分布式约束优化问题",
      "authors": [
        "Ben Rachmut",
        "Stylianos Loukas Vasileiou",
        "Nimrod Meir Weinstein",
        "Roie Zivan",
        "William Yeoh"
      ],
      "abstract": "The Distributed Constraint Optimization Problem (DCOP) formulation is a\npowerful tool to model cooperative multi-agent problems that need to be solved\ndistributively. A core assumption of existing approaches is that DCOP solutions\ncan be easily understood, accepted, and adopted, which may not hold, as\nevidenced by the large body of literature on Explainable AI. In this paper, we\npropose the Explainable DCOP (X-DCOP) model, which extends a DCOP to include\nits solution and a contrastive query for that solution. We formally define some\nkey properties that contrastive explanations must satisfy for them to be\nconsidered as valid solutions to X-DCOPs as well as theoretical results on the\nexistence of such valid explanations. To solve X-DCOPs, we propose a\ndistributed framework as well as several optimizations and suboptimal variants\nto find valid explanations. We also include a human user study that showed that\nusers, not surprisingly, prefer shorter explanations over longer ones. Our\nempirical evaluations showed that our approach can scale to large problems, and\nthe different variants provide different options for trading off explanation\nlengths for smaller runtimes. Thus, our model and algorithmic contributions\nextend the state of the art by reducing the barrier for users to understand\nDCOP solutions, facilitating their adoption in more real-world applications.",
      "tldr_zh": "本文提出 X-DCOP 模型，扩展传统的 Distributed Constraint Optimization Problem (DCOP) 以包含解决方案和对比查询，从而解决 DCOP 解决方案不易理解的问题，并定义了有效对比解释的关键属性及其存在性理论。研究开发了一个分布式框架及其优化和次优变体，用于生成这些解释，用户研究显示用户更倾向于较短的解释。实证评估表明，该方法能扩展到大型问题，并提供权衡解释长度与运行时间的选项，最终降低用户理解障碍，促进 DCOP 在实际应用的采用。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14102v1",
      "published_date": "2025-02-19 21:06:30 UTC",
      "updated_date": "2025-02-19 21:06:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:40:27.644644"
    },
    {
      "arxiv_id": "2502.14086v1",
      "title": "Navigating Semantic Relations: Challenges for Language Models in Abstract Common-Sense Reasoning",
      "title_zh": "导航语义关系：语言模型在抽象常识推理中的挑战",
      "authors": [
        "Cole Gawin",
        "Yidan Sun",
        "Mayank Kejriwal"
      ],
      "abstract": "Large language models (LLMs) have achieved remarkable performance in\ngenerating human-like text and solving reasoning tasks of moderate complexity,\nsuch as question-answering and mathematical problem-solving. However, their\ncapabilities in tasks requiring deeper cognitive skills, such as common-sense\nunderstanding and abstract reasoning, remain under-explored. In this paper, we\nsystematically evaluate abstract common-sense reasoning in LLMs using the\nConceptNet knowledge graph. We propose two prompting approaches: instruct\nprompting, where models predict plausible semantic relationships based on\nprovided definitions, and few-shot prompting, where models identify relations\nusing examples as guidance. Our experiments with the gpt-4o-mini model show\nthat in instruct prompting, consistent performance is obtained when ranking\nmultiple relations but with substantial decline when the model is restricted to\npredicting only one relation. In few-shot prompting, the model's accuracy\nimproves significantly when selecting from five relations rather than the full\nset, although with notable bias toward certain relations. These results suggest\nsignificant gaps still, even in commercially used LLMs' abstract common-sense\nreasoning abilities, compared to human-level understanding. However, the\nfindings also highlight the promise of careful prompt engineering, based on\nselective retrieval, for obtaining better performance.",
      "tldr_zh": "这篇论文探讨了大型语言模型(LLMs)在抽象常识推理中的挑战，特别是处理语义关系的能力，使用ConceptNet知识图谱进行系统评估。研究者提出了两种提示方法：instruct prompting（基于定义预测语义关系）和few-shot prompting（通过示例指导识别关系），并在gpt-4o-mini模型上进行实验。结果显示，instruct prompting在排名多个关系时表现一致，但预测单个关系时准确率显著下降；few-shot prompting在从五个关系中选择时准确率有所提升，但存在对某些关系的偏向。这些发现突显了LLMs在抽象常识推理上与人类水平的差距，同时强调了通过仔细的提示工程（如选择性检索）来改善性能的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "5 pages, 3 figures, ACM Web Conference 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.14086v1",
      "published_date": "2025-02-19 20:20:24 UTC",
      "updated_date": "2025-02-19 20:20:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:40:40.217509"
    },
    {
      "arxiv_id": "2502.17490v1",
      "title": "A generalized dual potential for inelastic Constitutive Artificial Neural Networks: A JAX implementation at finite strains",
      "title_zh": "翻译失败",
      "authors": [
        "Hagen Holthusen",
        "Kevin Linka",
        "Ellen Kuhl",
        "Tim Brepols"
      ],
      "abstract": "We present a methodology for designing a generalized dual potential, or\npseudo potential, for inelastic Constitutive Artificial Neural Networks\n(iCANNs). This potential, expressed in terms of stress invariants, inherently\nsatisfies thermodynamic consistency for large deformations. In comparison to\nour previous work, the new potential captures a broader spectrum of material\nbehaviors, including pressure-sensitive inelasticity.\n  To this end, we revisit the underlying thermodynamic framework of iCANNs for\nfinite strain inelasticity and derive conditions for constructing a convex,\nzero-valued, and non-negative dual potential. To embed these principles in a\nneural network, we detail the architecture's design, ensuring a priori\ncompliance with thermodynamics.\n  To evaluate the proposed architecture, we study its performance and\nlimitations discovering visco-elastic material behavior, though the method is\nnot limited to visco-elasticity. In this context, we investigate different\naspects in the strategy of discovering inelastic materials. Our results\nindicate that the novel architecture robustly discovers interpretable models\nand parameters, while autonomously revealing the degree of inelasticity.\n  The iCANN framework, implemented in JAX, is publicly accessible at\nhttps://doi.org/10.5281/zenodo.14894687.",
      "tldr_zh": "本研究提出了一种设计广义双重势（generalized dual potential，或 pseudo potential）的方法，用于非弹性本构人工神经网络（inelastic Constitutive Artificial Neural Networks, iCANNs），以捕捉更广泛的材料行为，包括压力敏感非弹性，并确保在有限应变（finite strains）下符合热力学一致性。作者重新审视了 iCANNs 的热力学框架，导出了构建凸性、零值和非负的双重势条件，并设计了相应的神经网络架构以先验嵌入这些原则。实验评估显示，该架构在模拟粘弹性材料行为时表现稳健，能够自动发现可解释的模型、参数和非弹性程度；框架使用 JAX 实现，并已公开可用。",
      "categories": [
        "cs.LG",
        "cond-mat.mtrl-sci",
        "cs.AI",
        "cs.CE",
        "65, 74",
        "I.6; J.2"
      ],
      "primary_category": "cs.LG",
      "comment": "56 pages, 19 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2502.17490v1",
      "published_date": "2025-02-19 20:16:45 UTC",
      "updated_date": "2025-02-19 20:16:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:40:52.598310"
    },
    {
      "arxiv_id": "2502.14080v1",
      "title": "Personalized Education with Generative AI and Digital Twins: VR, RAG, and Zero-Shot Sentiment Analysis for Industry 4.0 Workforce Development",
      "title_zh": "翻译失败",
      "authors": [
        "Yu-Zheng Lin",
        "Karan Petal",
        "Ahmed H Alhamadah",
        "Sujan Ghimire",
        "Matthew William Redondo",
        "David Rafael Vidal Corona",
        "Jesus Pacheco",
        "Soheil Salehi",
        "Pratik Satam"
      ],
      "abstract": "The Fourth Industrial Revolution (4IR) technologies, such as cloud computing,\nmachine learning, and AI, have improved productivity but introduced challenges\nin workforce training and reskilling. This is critical given existing workforce\nshortages, especially in marginalized communities like Underrepresented\nMinorities (URM), who often lack access to quality education. Addressing these\nchallenges, this research presents gAI-PT4I4, a Generative AI-based\nPersonalized Tutor for Industrial 4.0, designed to personalize 4IR experiential\nlearning. gAI-PT4I4 employs sentiment analysis to assess student comprehension,\nleveraging generative AI and finite automaton to tailor learning experiences.\nThe framework integrates low-fidelity Digital Twins for VR-based training,\nfeaturing an Interactive Tutor - a generative AI assistant providing real-time\nguidance via audio and text. It uses zero-shot sentiment analysis with LLMs and\nprompt engineering, achieving 86\\% accuracy in classifying student-teacher\ninteractions as positive or negative. Additionally, retrieval-augmented\ngeneration (RAG) enables personalized learning content grounded in\ndomain-specific knowledge. To adapt training dynamically, finite automaton\nstructures exercises into states of increasing difficulty, requiring 80\\%\ntask-performance accuracy for progression. Experimental evaluation with 22\nvolunteers showed improved accuracy exceeding 80\\%, reducing training time.\nFinally, this paper introduces a Multi-Fidelity Digital Twin model, aligning\nDigital Twin complexity with Bloom's Taxonomy and Kirkpatrick's model,\nproviding a scalable educational framework.",
      "tldr_zh": "这篇论文针对工业4.0（Industry 4.0）劳动力培训的挑战，提出了gAI-PT4I4框架，利用Generative AI和Digital Twins实现个性化教育，以解决边缘化群体如Underrepresented Minorities（URM）的培训障碍。框架整合了VR训练、Retrieval-Augmented Generation (RAG) 技术以及Zero-Shot Sentiment Analysis（准确率86%），通过LLMs和prompt engineering评估学生情绪并动态调整学习内容，使用有限自动机（finite automaton）根据任务表现（如80%准确率）控制难度。实验结果显示，在22名志愿者中，准确率超过80%、训练时间缩短，并引入Multi-Fidelity Digital Twin模型，与Bloom's Taxonomy和Kirkpatrick's model对齐，提供可扩展的教育框架。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14080v1",
      "published_date": "2025-02-19 20:11:19 UTC",
      "updated_date": "2025-02-19 20:11:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:41:06.299183"
    },
    {
      "arxiv_id": "2502.14074v2",
      "title": "Investigating Non-Transitivity in LLM-as-a-Judge",
      "title_zh": "调查 LLM-as-a-Judge 中的非传递性",
      "authors": [
        "Yi Xu",
        "Laura Ruis",
        "Tim Rocktäschel",
        "Robert Kirk"
      ],
      "abstract": "Automatic evaluation methods based on large language models (LLMs) are\nemerging as the standard tool for assessing the instruction-following abilities\nof LLM-based agents. The most common method in this paradigm, pairwise\ncomparisons with a baseline model, critically depends on the assumption of\ntransitive preferences. However, the validity of this assumption remains\nlargely unexplored. In this study, we investigate the presence of\nnon-transitivity within the AlpacaEval framework and analyze its effects on\nmodel rankings. We find that LLM judges exhibit non-transitive preferences,\nleading to rankings that are sensitive to the choice of the baseline model. To\nmitigate this issue, we show that round-robin tournaments combined with\nBradley-Terry models of preference can produce more reliable rankings. Notably,\nour method increases both the Spearman correlation and the Kendall correlation\nwith Chatbot Arena (95.0% -> 96.4% and 82.1% -> 86.3% respectively). To address\nthe computational cost of round-robin tournaments, we propose Swiss-Wise\nIterative Matchmaking (Swim) tournaments, using a dynamic matching strategy to\ncapture the benefits of round-robin tournaments while maintaining computational\nefficiency.",
      "tldr_zh": "本文研究了LLM-as-a-Judge中非传递性(non-transitivity)问题，调查了AlpacaEval框架，发现LLM评判者表现出非传递性偏好，导致模型排名对基准模型(pairwise comparisons)的选择高度敏感。作者提出使用round-robin tournaments结合Bradley-Terry models来生成更可靠的排名，提高了与Chatbot Arena的相关性（Spearman correlation从95.0%增至96.4%，Kendall correlation从82.1%增至86.3%）。为解决计算成本问题，他们引入了Swiss-Wise Iterative Matchmaking (Swim)锦标赛，通过动态匹配策略平衡了准确性和效率。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages, 6 figures, 2 tables (30 pages, 11 figures, 8 tables\n  including references and appendices)",
      "pdf_url": "http://arxiv.org/pdf/2502.14074v2",
      "published_date": "2025-02-19 19:59:16 UTC",
      "updated_date": "2025-03-06 06:32:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:41:18.714368"
    },
    {
      "arxiv_id": "2502.14070v1",
      "title": "DiffExp: Efficient Exploration in Reward Fine-tuning for Text-to-Image Diffusion Models",
      "title_zh": "DiffExp：文本到图像扩散模型奖励微调中的高效探索",
      "authors": [
        "Daewon Chae",
        "June Suk Choi",
        "Jinkyu Kim",
        "Kimin Lee"
      ],
      "abstract": "Fine-tuning text-to-image diffusion models to maximize rewards has proven\neffective for enhancing model performance. However, reward fine-tuning methods\noften suffer from slow convergence due to online sample generation. Therefore,\nobtaining diverse samples with strong reward signals is crucial for improving\nsample efficiency and overall performance. In this work, we introduce DiffExp,\na simple yet effective exploration strategy for reward fine-tuning of\ntext-to-image models. Our approach employs two key strategies: (a) dynamically\nadjusting the scale of classifier-free guidance to enhance sample diversity,\nand (b) randomly weighting phrases of the text prompt to exploit high-quality\nreward signals. We demonstrate that these strategies significantly enhance\nexploration during online sample generation, improving the sample efficiency of\nrecent reward fine-tuning methods, such as DDPO and AlignProp.",
      "tldr_zh": "该研究提出DiffExp，一种简单有效的探索策略，用于提升文本到图像扩散模型的奖励细调效率，以解决在线样本生成导致的收敛缓慢问题。DiffExp的核心方法包括动态调整classifier-free guidance的规模来增加样本多样性，以及随机加权文本提示的短语以利用高质量奖励信号。这些策略显著增强了在线样本生成的探索能力，从而提高了现有奖励细调方法如DDPO和AlignProp的样本效率。实验结果表明，DiffExp能有效改善模型性能，为文本到图像生成任务提供更高效的优化途径。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.14070v1",
      "published_date": "2025-02-19 19:47:58 UTC",
      "updated_date": "2025-02-19 19:47:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:41:27.005354"
    },
    {
      "arxiv_id": "2502.14068v1",
      "title": "A Racing Dataset and Baseline Model for Track Detection in Autonomous Racing",
      "title_zh": "翻译失败",
      "authors": [
        "Shreya Ghosh",
        "Yi-Huan Chen",
        "Ching-Hsiang Huang",
        "Abu Shafin Mohammad Mahdee Jameel",
        "Chien Chou Ho",
        "Aly El Gamal",
        "Samuel Labi"
      ],
      "abstract": "A significant challenge in racing-related research is the lack of publicly\navailable datasets containing raw images with corresponding annotations for the\ndownstream task. In this paper, we introduce RoRaTrack, a novel dataset that\ncontains annotated multi-camera image data from racing scenarios for track\ndetection. The data is collected on a Dallara AV-21 at a racing circuit in\nIndiana, in collaboration with the Indy Autonomous Challenge (IAC). RoRaTrack\naddresses common problems such as blurriness due to high speed, color inversion\nfrom the camera, and absence of lane markings on the track. Consequently, we\npropose RaceGAN, a baseline model based on a Generative Adversarial Network\n(GAN) that effectively addresses these challenges. The proposed model\ndemonstrates superior performance compared to current state-of-the-art machine\nlearning models in track detection. The dataset and code for this work are\navailable at github.com/RaceGAN.",
      "tldr_zh": "本论文介绍了 RoRaTrack 数据集，这是一个针对自动驾驶赛车中轨道检测的标注多相机图像数据集，由 Indy Autonomous Challenge (IAC) 合作在 Indiana 赛道使用 Dallara AV-21 车辆收集。数据集解决了高速导致的图像模糊、相机颜色反转以及轨道无车道标记等常见问题。作者提出 RaceGAN，这是一个基于 GAN 的基线模型，能够有效应对这些挑战，并在轨道检测任务上表现出色，比现有最先进机器学习模型性能更优。该数据集和相关代码已在 GitHub 上公开可用。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "Currently Under Review",
      "pdf_url": "http://arxiv.org/pdf/2502.14068v1",
      "published_date": "2025-02-19 19:43:31 UTC",
      "updated_date": "2025-02-19 19:43:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:41:41.463300"
    },
    {
      "arxiv_id": "2502.14064v2",
      "title": "Triad: Vision Foundation Model for 3D Magnetic Resonance Imaging",
      "title_zh": "Triad：3D 磁共振成像的视觉基础模型",
      "authors": [
        "Shansong Wang",
        "Mojtaba Safari",
        "Qiang Li",
        "Chih-Wei Chang",
        "Richard LJ Qiu",
        "Justin Roper",
        "David S. Yu",
        "Xiaofeng Yang"
      ],
      "abstract": "Vision foundation models (VFMs) are pre-trained on extensive image datasets\nto learn general representations for diverse types of data. These models can\nsubsequently be fine-tuned for specific downstream tasks, significantly\nboosting performance across a broad range of applications. However, existing\nvision foundation models that claim to be applicable to various clinical tasks\nare mostly pre-trained on 3D computed tomography (CT), which benefits from the\navailability of extensive 3D CT databases. Significant differences between CT\nand magnetic resonance imaging (MRI) in imaging principles, signal\ncharacteristics, and data distribution may hinder their practical performance\nand versatility in MRI-specific applications. Here, we propose Triad, a vision\nfoundation model for 3D MRI. Triad adopts a widely used autoencoder\narchitecture to learn robust representations from 131,170 3D MRI volumes and\nuses organ-independent imaging descriptions to constrain the semantic\ndistribution of the visual modality. The above pre-training dataset is called\nTriad-131K, which is currently the largest 3D MRI pre-training dataset. We\nevaluate Triad across three tasks, namely, organ/tumor segmentation,\norgan/cancer classification, and medical image registration, in two data\nmodalities (within-domain and out-of-domain) settings using 25 downstream\ndatasets. By initializing models with Triad's pre-trained weights, nnUNet-Triad\nimproves segmentation performance by 2.51% compared to nnUNet-Scratch across 17\ndatasets. Swin-B-Triad achieves a 3.97% improvement over Swin-B-Scratch in\nclassification tasks across five datasets. SwinUNETR-Triad improves by 4.00%\ncompared to SwinUNETR-Scratch in registration tasks across two datasets. Our\nstudy demonstrates that pre-training can improve performance when the data\nmodalities and organs of upstream and downstream tasks are consistent.",
      "tldr_zh": "该研究提出 Triad，一种专为 3D Magnetic Resonance Imaging (MRI) 设计的 Vision Foundation Model，以解决现有模型主要基于 3D Computed Tomography (CT) 数据预训练，导致在 MRI 任务上性能不足的问题。Triad 采用 autoencoder 架构，在包含 131,170 个 3D MRI 体积的 Triad-131K 数据集上进行预训练，并使用器官无关的成像描述来约束视觉语义分布。实验结果显示，通过 Triad 的预训练权重初始化，nnUNet-Triad 在 17 个数据集上的分割任务中提升 2.51%，Swin-B-Triad 在 5 个数据集上的分类任务中提升 3.97%，SwinUNETR-Triad 在 2 个数据集上的注册任务中提升 4.00%，证明预训练能显著改善数据模态和器官一致的下游任务性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14064v2",
      "published_date": "2025-02-19 19:31:52 UTC",
      "updated_date": "2025-02-23 03:13:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:41:55.031272"
    },
    {
      "arxiv_id": "2502.14061v1",
      "title": "EfficientPose 6D: Scalable and Efficient 6D Object Pose Estimation",
      "title_zh": "EfficientPose 6D：可扩展且高效的6D对象姿态估计",
      "authors": [
        "Zixuan Fang",
        "Thomas Pöllabauer",
        "Tristan Wirth",
        "Sarah Berkei",
        "Volker Knauthe",
        "Arjan Kuijper"
      ],
      "abstract": "In industrial applications requiring real-time feedback, such as quality\ncontrol and robotic manipulation, the demand for high-speed and accurate pose\nestimation remains critical. Despite advances improving speed and accuracy in\npose estimation, finding a balance between computational efficiency and\naccuracy poses significant challenges in dynamic environments. Most current\nalgorithms lack scalability in estimation time, especially for diverse\ndatasets, and the state-of-the-art (SOTA) methods are often too slow. This\nstudy focuses on developing a fast and scalable set of pose estimators based on\nGDRNPP to meet or exceed current benchmarks in accuracy and robustness,\nparticularly addressing the efficiency-accuracy trade-off essential in\nreal-time scenarios. We propose the AMIS algorithm to tailor the utilized model\naccording to an application-specific trade-off between inference time and\naccuracy. We further show the effectiveness of the AMIS-based model choice on\nfour prominent benchmark datasets (LM-O, YCB-V, T-LESS, and ITODD).",
      "tldr_zh": "这篇论文介绍了 EfficientPose 6D，一种可伸缩且高效的 6D Object Pose Estimation 方法，旨在解决工业应用中实时反馈（如质量控制和机器人操作）的速度和准确性挑战。论文基于 GDRNPP 框架开发了一系列快速姿态估计器，并提出 AMIS 算法，用于根据应用需求动态调整推理时间与准确性的权衡。实验结果显示，该方法在 LM-O、YCB-V、T-LESS 和 ITODD 等基准数据集上表现出色，实现了与现有 SOTA 方法相当或更高的准确性和鲁棒性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14061v1",
      "published_date": "2025-02-19 19:21:23 UTC",
      "updated_date": "2025-02-19 19:21:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:42:05.122855"
    },
    {
      "arxiv_id": "2502.14050v2",
      "title": "Diversity-driven Data Selection for Language Model Tuning through Sparse Autoencoder",
      "title_zh": "翻译失败",
      "authors": [
        "Xianjun Yang",
        "Shaoliang Nie",
        "Lijuan Liu",
        "Suchin Gururangan",
        "Ujjwal Karn",
        "Rui Hou",
        "Madian Khabsa",
        "Yuning Mao"
      ],
      "abstract": "Instruction tuning data are often quantity-saturated due to the large volume\nof data collection and fast model iteration, leaving data selection important\nbut underexplored. Existing quality-driven data selection methods, such as LIMA\n(NeurIPS 2023 \\citep{zhou2024lima}) and AlpaGasus (ICLR 2024\n\\citep{chenalpagasus}) generally ignore the equal importance of data diversity\nand complexity. In this work, we aim to design a diversity-aware data selection\nstrategy and creatively propose using sparse autoencoders (SAEs) to tackle the\nchallenge of data diversity measure. In addition, SAEs can also provide more\ninterpretability of model behavior and explain, e.g., the surprising\neffectiveness of selecting the longest response (ICML 2024 \\citep{zhaolong}).\nUsing effective data selection, we experimentally prove that models trained on\nour selected data can outperform other methods in terms of model capabilities,\nreduce training cost, and potentially gain more control over model behaviors.\nWe prove that SAEs can serve as a good alternative to diversity measure and\ndesign our method to be scalable for potential industrial large-scale pruning,\nand we will also release our trained SAEs for use by the broader community.",
      "tldr_zh": "本研究针对指令调优数据量的饱和问题，提出了一种多样性驱动的数据选择策略，使用 Sparse Autoencoders (SAEs) 来衡量数据多样性和复杂性，从而弥补现有方法如 LIMA 和 AlpaGasus 的不足。SAEs 不仅提升数据选择的准确性，还提供模型行为的解释性，例如解释选择最长响应（Longest Response）的有效性。通过实验验证，该方法训练的语言模型在能力上优于基线模型，显著减少训练成本，并增强对模型行为的控制。作者证明 SAEs 是多样性测量的可扩展替代方案，并计划开源训练好的 SAEs 以供社区使用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "fix typos",
      "pdf_url": "http://arxiv.org/pdf/2502.14050v2",
      "published_date": "2025-02-19 19:12:34 UTC",
      "updated_date": "2025-03-31 21:41:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:42:16.323091"
    },
    {
      "arxiv_id": "2502.14048v1",
      "title": "Semantic Decomposition and Selective Context Filtering -- Text Processing Techniques for Context-Aware NLP-Based Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Karl John Villardar"
      ],
      "abstract": "In this paper, we present two techniques for use in context-aware systems:\nSemantic Decomposition, which sequentially decomposes input prompts into a\nstructured and hierarchal information schema in which systems can parse and\nprocess easily, and Selective Context Filtering, which enables systems to\nsystematically filter out specific irrelevant sections of contextual\ninformation that is fed through a system's NLP-based pipeline. We will explore\nhow context-aware systems and applications can utilize these two techniques in\norder to implement dynamic LLM-to-system interfaces, improve an LLM's ability\nto generate more contextually cohesive user-facing responses, and optimize\ncomplex automated workflows and pipelines.",
      "tldr_zh": "这篇论文介绍了两种文本处理技术：Semantic Decomposition 和 Selective Context Filtering，用于提升上下文感知的NLP系统。Semantic Decomposition 通过将输入提示顺序分解成结构化和层次化的信息模式，便于系统解析和处理；Selective Context Filtering 则系统地过滤掉NLP管道中无关的部分上下文信息。这些技术可用于实现动态的LLM-to-system接口、改善LLM生成更连贯的用户响应，并优化复杂的自动化工作流和管道。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC",
        "I.2.7; I.7.0"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14048v1",
      "published_date": "2025-02-19 19:09:40 UTC",
      "updated_date": "2025-02-19 19:09:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:42:27.260271"
    },
    {
      "arxiv_id": "2502.14047v1",
      "title": "Towards a Learning Theory of Representation Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Francesco Insulla",
        "Shuo Huang",
        "Lorenzo Rosasco"
      ],
      "abstract": "It has recently been argued that AI models' representations are becoming\naligned as their scale and performance increase. Empirical analyses have been\ndesigned to support this idea and conjecture the possible alignment of\ndifferent representations toward a shared statistical model of reality. In this\npaper, we propose a learning-theoretic perspective to representation alignment.\nFirst, we review and connect different notions of alignment based on metric,\nprobabilistic, and spectral ideas. Then, we focus on stitching, a particular\napproach to understanding the interplay between different representations in\nthe context of a task. Our main contribution here is relating properties of\nstitching to the kernel alignment of the underlying representation. Our results\ncan be seen as a first step toward casting representation alignment as a\nlearning-theoretic problem.",
      "tldr_zh": "这篇论文从学习理论视角探讨了 AI 模型表示的 representation alignment，旨在理解模型规模和性能提升时表示之间的对齐现象。作者回顾了基于 metric、probabilistic 和 spectral 概念的 alignment 定义，并重点分析了 stitching 方法，将其属性与 kernel alignment 联系起来。研究结果为将 representation alignment 转化为一个学习理论问题提供了初步框架，推动了对模型表示互操作性的理论理解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14047v1",
      "published_date": "2025-02-19 19:09:14 UTC",
      "updated_date": "2025-02-19 19:09:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:42:39.648006"
    },
    {
      "arxiv_id": "2502.14045v1",
      "title": "Position: There are no Champions in Long-Term Time Series Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Lorenzo Brigato",
        "Rafael Morand",
        "Knut Strømmen",
        "Maria Panagiotou",
        "Markus Schmidt",
        "Stavroula Mougiakakou"
      ],
      "abstract": "Recent advances in long-term time series forecasting have introduced numerous\ncomplex prediction models that consistently outperform previously published\narchitectures. However, this rapid progression raises concerns regarding\ninconsistent benchmarking and reporting practices, which may undermine the\nreliability of these comparisons. Our position emphasizes the need to shift\nfocus away from pursuing ever-more complex models and towards enhancing\nbenchmarking practices through rigorous and standardized evaluation methods. To\nsupport our claim, we first perform a broad, thorough, and reproducible\nevaluation of the top-performing models on the most popular benchmark by\ntraining 3,500+ networks over 14 datasets. Then, through a comprehensive\nanalysis, we find that slight changes to experimental setups or current\nevaluation metrics drastically shift the common belief that newly published\nresults are advancing the state of the art. Our findings suggest the need for\nrigorous and standardized evaluation methods that enable more substantiated\nclaims, including reproducible hyperparameter setups and statistical testing.",
      "tldr_zh": "该论文主张，在长期时间序列预测(Long-term Time Series Forecasting)领域，并不存在真正的“冠军”模型，因为当前的基准测试(Benchmarking)实践不一致，导致模型比较不可靠。作者通过在14个数据集上训练3500+网络进行广泛、可重现的评估，发现实验设置或评估指标的微小变化就能大幅改变模型表现，从而质疑新模型声称的先进性。研究呼吁转向更严格、标准化的评估方法，包括可重现的超参数(Hyperparameter)设置和统计测试，以提升研究的可信度。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Pre-print",
      "pdf_url": "http://arxiv.org/pdf/2502.14045v1",
      "published_date": "2025-02-19 19:08:37 UTC",
      "updated_date": "2025-02-19 19:08:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:42:52.366713"
    },
    {
      "arxiv_id": "2502.14043v1",
      "title": "Asking for Help Enables Safety Guarantees Without Sacrificing Effectiveness",
      "title_zh": "翻译失败",
      "authors": [
        "Benjamin Plaut",
        "Juan Liévano-Karim",
        "Stuart Russell"
      ],
      "abstract": "Most reinforcement learning algorithms with regret guarantees rely on a\ncritical assumption: that all errors are recoverable. Recent work by Plaut et\nal. discarded this assumption and presented algorithms that avoid \"catastrophe\"\n(i.e., irreparable errors) by asking for help. However, they provided only\nsafety guarantees and did not consider reward maximization. We prove that any\nalgorithm that avoids catastrophe in their setting also guarantees high reward\n(i.e., sublinear regret) in any Markov Decision Process (MDP), including MDPs\nwith irreversible costs. This constitutes the first no-regret guarantee for\ngeneral MDPs. More broadly, our result may be the first formal proof that it is\npossible for an agent to obtain high reward while becoming self-sufficient in\nan unknown, unbounded, and high-stakes environment without causing catastrophe\nor requiring resets.",
      "tldr_zh": "本文研究了强化学习算法如何在不牺牲有效性的前提下确保安全性，特别针对那些错误不可恢复的环境。作者证明，Plaut et al.提出的通过“asking for help”来避免“catastrophe”（灾难）的算法，不仅提供安全保证，还能在任何Markov Decision Process (MDP)中实现次线性 regret（遗憾），从而最大化奖励。这标志着第一个针对一般MDP的无遗憾保证，并展示了代理在未知、无界和高风险环境中获得高奖励的同时实现自给自足，而无需重置。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14043v1",
      "published_date": "2025-02-19 19:01:39 UTC",
      "updated_date": "2025-02-19 19:01:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:43:05.735123"
    },
    {
      "arxiv_id": "2502.14037v2",
      "title": "DiffSampling: Enhancing Diversity and Accuracy in Neural Text Generation",
      "title_zh": "DiffSampling：提升神经文本生成的多样性和准确性",
      "authors": [
        "Giorgio Franceschelli",
        "Mirco Musolesi"
      ],
      "abstract": "Despite their growing capabilities, language models still frequently\nreproduce content from their training data, generate repetitive text, and favor\ncommon grammatical patterns and vocabulary. A possible cause is the decoding\nstrategy: the most common strategies either consider only the most probable\ntokens, which reduces output diversity, or increase the likelihood of unlikely\ntokens, compromising output accuracy and correctness. In this paper, we propose\nthree new decoding methods that leverage a mathematical analysis of the token\nprobability distribution to ensure the generation of contextually appropriate\ntext. In particular, the difference between consecutive, sorted probabilities\ncan be used to truncate incorrect tokens. Experiments concerning math problem\nsolving, extreme summarization, and the divergent association task demonstrate\nthat our approach consistently performs at least as well as existing methods in\nterms of quality and diversity.",
      "tldr_zh": "该论文探讨了神经文本生成模型在输出多样性和准确性方面的挑战，如模型常复制训练数据、生成重复文本并偏好常见语法模式。作者提出三种新解码方法，通过对 token 概率分布的数学分析——特别是连续排序概率的差异——来截断不正确 tokens，从而确保生成的文本在上下文中更合适。实验结果显示，在数学问题求解、极端总结和发散关联任务中，该方法在质量和多样性上至少与现有解码策略相当或更胜一筹。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14037v2",
      "published_date": "2025-02-19 19:00:02 UTC",
      "updated_date": "2025-05-20 06:00:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:43:17.221884"
    },
    {
      "arxiv_id": "2502.15815v1",
      "title": "Theoretical Physics Benchmark (TPBench) -- a Dataset and Study of AI Reasoning Capabilities in Theoretical Physics",
      "title_zh": "翻译失败",
      "authors": [
        "Daniel J. H. Chung",
        "Zhiqi Gao",
        "Yurii Kvasiuk",
        "Tianyi Li",
        "Moritz Münchmeyer",
        "Maja Rudolph",
        "Frederic Sala",
        "Sai Chaitanya Tadepalli"
      ],
      "abstract": "We introduce a benchmark to evaluate the capability of AI to solve problems\nin theoretical physics, focusing on high-energy theory and cosmology. The first\niteration of our benchmark consists of 57 problems of varying difficulty, from\nundergraduate to research level. These problems are novel in the sense that\nthey do not come from public problem collections. We evaluate our data set on\nvarious open and closed language models, including o3-mini, o1, DeepSeek-R1,\nGPT-4o and versions of Llama and Qwen. While we find impressive progress in\nmodel performance with the most recent models, our research-level difficulty\nproblems are mostly unsolved. We address challenges of auto-verifiability and\ngrading, and discuss common failure modes. While currently state-of-the art\nmodels are still of limited use for researchers, our results show that AI\nassisted theoretical physics research may become possible in the near future.\nWe discuss the main obstacles towards this goal and possible strategies to\novercome them. The public problems and solutions, results for various models,\nand updates to the data set and score distribution, are available on the\nwebsite of the dataset tpbench.org.",
      "tldr_zh": "本研究引入了Theoretical Physics Benchmark (TPBench)，一个用于评估AI在理论物理领域推理能力的基准数据集，聚焦于高能理论和宇宙学，共包含57个原创问题，从本科到研究级别。研究者测试了多种语言模型（如o3-mini、o1、DeepSeek-R1、GPT-4o、Llama和Qwen），发现最新模型表现出色进步，但研究级问题仍未得到有效解决。论文讨论了自动验证、评分挑战以及常见失败模式，并指出尽管当前AI对理论物理研究帮助有限，但通过克服障碍，AI辅助研究可能在不久的将来实现。数据集及其更新可通过tpbench.org获取。",
      "categories": [
        "cs.LG",
        "astro-ph.CO",
        "cs.AI",
        "hep-ph",
        "hep-th"
      ],
      "primary_category": "cs.LG",
      "comment": "48 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.15815v1",
      "published_date": "2025-02-19 19:00:00 UTC",
      "updated_date": "2025-02-19 19:00:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:43:28.567982"
    },
    {
      "arxiv_id": "2502.13965v1",
      "title": "Autellix: An Efficient Serving Engine for LLM Agents as General Programs",
      "title_zh": "翻译失败",
      "authors": [
        "Michael Luo",
        "Xiaoxiang Shi",
        "Colin Cai",
        "Tianjun Zhang",
        "Justin Wong",
        "Yichuan Wang",
        "Chi Wang",
        "Yanping Huang",
        "Zhifeng Chen",
        "Joseph E. Gonzalez",
        "Ion Stoica"
      ],
      "abstract": "Large language model (LLM) applications are evolving beyond simple chatbots\ninto dynamic, general-purpose agentic programs, which scale LLM calls and\noutput tokens to help AI agents reason, explore, and solve complex tasks.\nHowever, existing LLM serving systems ignore dependencies between programs and\ncalls, missing significant opportunities for optimization. Our analysis reveals\nthat programs submitted to LLM serving engines experience long cumulative wait\ntimes, primarily due to head-of-line blocking at both the individual LLM\nrequest and the program. To address this, we introduce Autellix, an LLM serving\nsystem that treats programs as first-class citizens to minimize their\nend-to-end latencies. Autellix intercepts LLM calls submitted by programs,\nenriching schedulers with program-level context. We propose two scheduling\nalgorithms-for single-threaded and distributed programs-that preempt and\nprioritize LLM calls based on their programs' previously completed calls. Our\nevaluation demonstrates that across diverse LLMs and agentic workloads,\nAutellix improves throughput of programs by 4-15x at the same latency compared\nto state-of-the-art systems, such as vLLM.",
      "tldr_zh": "该论文指出，大语言模型（LLM）应用已从简单聊天机器人演变为动态的通用代理程序，但现有LLM服务系统忽略了程序和调用间的依赖关系，导致程序等待时间过长。针对此问题，研究提出Autellix，一种高效的LLM服务引擎，将程序视为第一类公民，通过拦截LLM调用并引入基于程序级上下文的调度算法（如针对单线程和分布式程序的优先化机制）来最小化端到端延迟。实验评估显示，Autellix在各种LLM和代理工作负载下，相较于vLLM等系统，在相同延迟条件下将程序吞吐量提高了4-15倍。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.13965v1",
      "published_date": "2025-02-19 18:59:30 UTC",
      "updated_date": "2025-02-19 18:59:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:43:42.130560"
    },
    {
      "arxiv_id": "2502.13964v1",
      "title": "A Training-Free Framework for Precise Mobile Manipulation of Small Everyday Objects",
      "title_zh": "无需训练的框架：用于小型日常物体的精确移动操作",
      "authors": [
        "Arjun Gupta",
        "Rishik Sathua",
        "Saurabh Gupta"
      ],
      "abstract": "Many everyday mobile manipulation tasks require precise interaction with\nsmall objects, such as grasping a knob to open a cabinet or pressing a light\nswitch. In this paper, we develop Servoing with Vision Models (SVM), a\nclosed-loop training-free framework that enables a mobile manipulator to tackle\nsuch precise tasks involving the manipulation of small objects. SVM employs an\nRGB-D wrist camera and uses visual servoing for control. Our novelty lies in\nthe use of state-of-the-art vision models to reliably compute 3D targets from\nthe wrist image for diverse tasks and under occlusion due to the end-effector.\nTo mitigate occlusion artifacts, we employ vision models to out-paint the\nend-effector thereby significantly enhancing target localization. We\ndemonstrate that aided by out-painting methods, open-vocabulary object\ndetectors can serve as a drop-in module to identify semantic targets (e.g.\nknobs) and point tracking methods can reliably track interaction sites\nindicated by user clicks. This training-free method obtains an 85% zero-shot\nsuccess rate on manipulating unseen objects in novel environments in the real\nworld, outperforming an open-loop control method and an imitation learning\nbaseline trained on 1000+ demonstrations by an absolute success rate of 50%.",
      "tldr_zh": "本论文提出了一种无需训练的框架Servoing with Vision Models (SVM)，用于移动机械臂精确操作小日常物体，如转动旋钮或按压开关。该框架利用RGB-D腕部相机和visual servoing控制，通过先进视觉模型从图像中计算3D目标，并采用out-painting技术缓解末端执行器遮挡，从而提升目标定位准确性。实验显示，SVM在真实世界新环境下的零样本任务中成功率达85%，比开环控制和基于1000+演示的模仿学习基线高出50%。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Project webpage: https://arjung128.github.io/svm",
      "pdf_url": "http://arxiv.org/pdf/2502.13964v1",
      "published_date": "2025-02-19 18:59:17 UTC",
      "updated_date": "2025-02-19 18:59:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:43:53.385326"
    },
    {
      "arxiv_id": "2502.13957v1",
      "title": "RAG-Gym: Optimizing Reasoning and Search Agents with Process Supervision",
      "title_zh": "翻译失败",
      "authors": [
        "Guangzhi Xiong",
        "Qiao Jin",
        "Xiao Wang",
        "Yin Fang",
        "Haolin Liu",
        "Yifan Yang",
        "Fangyuan Chen",
        "Zhixing Song",
        "Dengyu Wang",
        "Minjia Zhang",
        "Zhiyong Lu",
        "Aidong Zhang"
      ],
      "abstract": "Retrieval-augmented generation (RAG) has shown great potential for\nknowledge-intensive tasks, but its traditional architectures rely on static\nretrieval, limiting their effectiveness for complex questions that require\nsequential information-seeking. While agentic reasoning and search offer a more\nadaptive approach, most existing methods depend heavily on prompt engineering.\nIn this work, we introduce RAG-Gym, a unified optimization framework that\nenhances information-seeking agents through fine-grained process supervision at\neach search step. We also propose ReSearch, a novel agent architecture that\nsynergizes answer reasoning and search query generation within the RAG-Gym\nframework. Experiments on four challenging datasets show that RAG-Gym improves\nperformance by up to 25.6\\% across various agent architectures, with ReSearch\nconsistently outperforming existing baselines. Further analysis highlights the\neffectiveness of advanced LLMs as process reward judges and the transferability\nof trained reward models as verifiers for different LLMs. Additionally, we\nexamine the scaling properties of training and inference in agentic RAG. The\nproject homepage is available at https://rag-gym.github.io/.",
      "tldr_zh": "这篇论文引入了 RAG-Gym，一种统一的优化框架，通过细粒度的过程监督（process supervision）来提升信息搜索代理的性能，解决传统 RAG 在处理需要顺序信息搜索的复杂问题时的局限性。论文还提出了一种新颖的代理架构 ReSearch，将答案推理和搜索查询生成相结合，在 RAG-Gym 框架下协同工作。在四个 challenging 数据集上的实验显示，RAG-Gym 使各种代理架构的性能提升高达 25.6%，ReSearch 显著优于现有基线；此外，研究分析了高级 LLMs 作为过程奖励评判者的有效性、训练奖励模型的可转移性和代理 RAG 的缩放特性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.13957v1",
      "published_date": "2025-02-19 18:56:03 UTC",
      "updated_date": "2025-02-19 18:56:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:44:05.545038"
    },
    {
      "arxiv_id": "2502.13953v1",
      "title": "Neurosymbolic artificial intelligence via large language models and coherence-driven inference",
      "title_zh": "翻译失败",
      "authors": [
        "Steve Huntsman",
        "Jewell Thomas"
      ],
      "abstract": "We devise an algorithm to generate sets of propositions that objectively\ninstantiate graphs that support coherence-driven inference. We then benchmark\nthe ability of large language models (LLMs) to reconstruct coherence graphs\nfrom (a straightforward transformation of) propositions expressed in natural\nlanguage, with promising results from a single prompt to models optimized for\nreasoning. Combining coherence-driven inference with consistency evaluations by\nneural models may advance the state of the art in machine cognition.",
      "tldr_zh": "该论文提出了一种算法，用于生成一组命题，这些命题能客观实例化支持 coherence-driven inference 的图。研究者随后评估了 large language models (LLMs) 从自然语言表达的命题（经过简单转换）重建 coherence graphs 的能力，结果显示使用单一提示的推理优化模型表现出色。通过将 coherence-driven inference 与神经模型的一致性评估相结合，该方法有望推进 neurosymbolic artificial intelligence 在机器认知领域的进展。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.13953v1",
      "published_date": "2025-02-19 18:53:16 UTC",
      "updated_date": "2025-02-19 18:53:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:44:15.495991"
    },
    {
      "arxiv_id": "2502.14023v1",
      "title": "Dynamic Activation with Knowledge Distillation for Energy-Efficient Spiking NN Ensembles",
      "title_zh": "翻译失败",
      "authors": [
        "Orestis Konstantaropoulos",
        "Theodoris Mallios",
        "Maria Papadopouli"
      ],
      "abstract": "While foundation AI models excel at tasks like classification and\ndecision-making, their high energy consumption makes them unsuitable for\nenergy-constrained applications. Inspired by the brain's efficiency, spiking\nneural networks (SNNs) have emerged as a viable alternative due to their\nevent-driven nature and compatibility with neuromorphic chips. This work\nintroduces a novel system that combines knowledge distillation and ensemble\nlearning to bridge the performance gap between artificial neural networks\n(ANNs) and SNNs. A foundation AI model acts as a teacher network, guiding\nsmaller student SNNs organized into an ensemble, called Spiking Neural Ensemble\n(SNE). SNE enables the disentanglement of the teacher's knowledge, allowing\neach student to specialize in predicting a distinct aspect of it, while\nprocessing the same input. The core innovation of SNE is the adaptive\nactivation of a subset of SNN models of an ensemble, leveraging\nknowledge-distillation, enhanced with an informed-partitioning\n(disentanglement) of the teacher's feature space. By dynamically activating\nonly a subset of these student SNNs, the system balances accuracy and energy\nefficiency, achieving substantial energy savings with minimal accuracy loss.\nMoreover, SNE is significantly more efficient than the teacher network,\nreducing computational requirements by up to 20x with only a 2% drop in\naccuracy on the CIFAR-10 dataset. This disentanglement procedure achieves an\naccuracy improvement of up to 2.4% on the CIFAR-10 dataset compared to other\npartitioning schemes. Finally, we comparatively analyze SNE performance under\nnoisy conditions, demonstrating enhanced robustness compared to its ANN\nteacher. In summary, SNE offers a promising new direction for\nenergy-constrained applications.",
      "tldr_zh": "本文提出了一种名为 Spiking Neural Ensemble (SNE) 的系统，通过知识蒸馏和集成学习桥接 Artificial Neural Networks (ANNs) 与 Spiking Neural Networks (SNNs) 的性能差距，实现能效优化。核心创新在于动态激活 SNNs 子集，并通过增强的特征空间分区，让每个学生 SNN 专注于教师知识的特定方面，从而平衡准确性和能效。在 CIFAR-10 数据集上，SNE 比教师网络减少计算需求达 20 倍，仅损失 2% 准确率，并显示出在噪声条件下的更高鲁棒性，提供了一种适用于能量受限应用的创新方向。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14023v1",
      "published_date": "2025-02-19 18:50:08 UTC",
      "updated_date": "2025-02-19 18:50:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:44:29.918534"
    },
    {
      "arxiv_id": "2502.13946v1",
      "title": "Why Safeguarded Ships Run Aground? Aligned Large Language Models' Safety Mechanisms Tend to Be Anchored in The Template Region",
      "title_zh": "翻译失败",
      "authors": [
        "Chak Tou Leong",
        "Qingyu Yin",
        "Jian Wang",
        "Wenjie Li"
      ],
      "abstract": "The safety alignment of large language models (LLMs) remains vulnerable, as\ntheir initial behavior can be easily jailbroken by even relatively simple\nattacks. Since infilling a fixed template between the input instruction and\ninitial model output is a common practice for existing LLMs, we hypothesize\nthat this template is a key factor behind their vulnerabilities: LLMs'\nsafety-related decision-making overly relies on the aggregated information from\nthe template region, which largely influences these models' safety behavior. We\nrefer to this issue as template-anchored safety alignment. In this paper, we\nconduct extensive experiments and verify that template-anchored safety\nalignment is widespread across various aligned LLMs. Our mechanistic analyses\ndemonstrate how it leads to models' susceptibility when encountering\ninference-time jailbreak attacks. Furthermore, we show that detaching safety\nmechanisms from the template region is promising in mitigating vulnerabilities\nto jailbreak attacks. We encourage future research to develop more robust\nsafety alignment techniques that reduce reliance on the template region.",
      "tldr_zh": "这篇论文探讨了大型语言模型（LLMs）的安全对齐问题，指出模型的安全机制过度依赖于模板区域（template-anchored safety alignment），导致其易受简单jailbreak攻击破坏。作者通过广泛实验和机制分析，验证了这一问题在各种对齐LLMs中普遍存在，并解释了它如何增加模型在推理时的易感性。研究发现，分离安全机制与模板区域可以有效缓解这些漏洞。最终，论文鼓励未来研究开发更稳健的安全对齐技术，以减少对模板的依赖。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.13946v1",
      "published_date": "2025-02-19 18:42:45 UTC",
      "updated_date": "2025-02-19 18:42:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:44:42.153976"
    },
    {
      "arxiv_id": "2502.13943v1",
      "title": "AdaptiveStep: Automatically Dividing Reasoning Step through Model Confidence",
      "title_zh": "AdaptiveStep：通过模型置信度自动划分推理步骤",
      "authors": [
        "Yuliang Liu",
        "Junjie Lu",
        "Zhaoling Chen",
        "Chaofeng Qu",
        "Jason Klein Liu",
        "Chonghan Liu",
        "Zefan Cai",
        "Yunhui Xia",
        "Li Zhao",
        "Jiang Bian",
        "Chuheng Zhang",
        "Wei Shen",
        "Zhouhan Lin"
      ],
      "abstract": "Current approaches for training Process Reward Models (PRMs) often involve\nbreaking down responses into multiple reasoning steps using rule-based\ntechniques, such as using predefined placeholder tokens or setting the\nreasoning step's length into a fixed size. These approaches overlook the fact\nthat specific words do not typically mark true decision points in a text. To\naddress this, we propose AdaptiveStep, a method that divides reasoning steps\nbased on the model's confidence in predicting the next word. This division\nmethod provides more decision-making information at each step, enhancing\ndownstream tasks, such as reward model learning. Moreover, our method does not\nrequire manual annotation. We demonstrate its effectiveness through experiments\nwith AdaptiveStep-trained PRMs in mathematical reasoning and code generation\ntasks. Experimental results indicate that the outcome PRM achieves\nstate-of-the-art Best-of-N performance, surpassing greedy search strategy with\ntoken-level value-guided decoding, while also reducing construction costs by\nover 30% compared to existing open-source PRMs. In addition, we provide a\nthorough analysis and case study on the PRM's performance, transferability, and\ngeneralization capabilities.",
      "tldr_zh": "该研究针对训练 Process Reward Models (PRMs) 的现有方法（如基于规则的推理步骤划分）存在的问题，提出 AdaptiveStep 框架，该框架通过模型对下一个词的置信度自动划分推理步骤，从而提供更多决策信息并提升下游任务性能，且无需手动标注。实验在数学推理和代码生成任务中验证了其有效性，AdaptiveStep 训练的 PRM 实现了 state-of-the-art 的 Best-of-N 性能，超过了贪婪搜索策略，同时将构建成本降低了 30% 以上。该方法还包括对 PRM 的性能、可转移性和泛化能力的详细分析和案例研究。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "17 pages",
      "pdf_url": "http://arxiv.org/pdf/2502.13943v1",
      "published_date": "2025-02-19 18:35:55 UTC",
      "updated_date": "2025-02-19 18:35:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:44:54.055220"
    },
    {
      "arxiv_id": "2502.13935v1",
      "title": "Continually Learning Structured Visual Representations via Network Refinement with Rerelation",
      "title_zh": "翻译失败",
      "authors": [
        "Zeki Doruk Erden",
        "Boi Faltings"
      ],
      "abstract": "Current machine learning paradigm relies on continuous representations like\nneural networks, which iteratively adjust parameters to approximate outcomes\nrather than directly learning the structure of problem. This spreads\ninformation across the network, causing issues like information loss and\nincomprehensibility Building on prior work in environment dynamics modeling, we\npropose a method that learns visual space in a structured, continual manner.\nOur approach refines networks to capture the core structure of objects while\nrepresenting significant subvariants in structure efficiently. We demonstrate\nthis with 2D shape detection, showing incremental learning on MNIST without\noverwriting knowledge and creating compact, comprehensible representations.\nThese results offer a promising step toward a transparent, continually learning\nalternative to traditional neural networks for visual processing.",
      "tldr_zh": "该论文指出，当前机器学习依赖于连续表示如神经网络，通过调整参数模拟结果而非直接学习问题结构，导致信息丢失和不透明问题。为解决此，作者提出一种通过network refinement with Rerelation的方法，实现结构化的持续学习视觉表示，能够捕捉对象的核心结构并高效表示子变体。在MNIST数据集的2D形状检测任务上，该方法实现了增量学习而不覆盖现有知识，生成紧凑且可理解的表示，为视觉处理的透明持续学习提供了一个有前景的替代方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.13935v1",
      "published_date": "2025-02-19 18:18:27 UTC",
      "updated_date": "2025-02-19 18:18:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:45:06.469696"
    },
    {
      "arxiv_id": "2502.14924v1",
      "title": "A Tale of Two Structures: Do LLMs Capture the Fractal Complexity of Language?",
      "title_zh": "翻译失败",
      "authors": [
        "Ibrahim Alabdulmohsin",
        "Andreas Steiner"
      ],
      "abstract": "Language exhibits a fractal structure in its information-theoretic complexity\n(i.e. bits per token), with self-similarity across scales and long-range\ndependence (LRD). In this work, we investigate whether large language models\n(LLMs) can replicate such fractal characteristics and identify conditions-such\nas temperature setting and prompting method-under which they may fail.\nMoreover, we find that the fractal parameters observed in natural language are\ncontained within a narrow range, whereas those of LLMs' output vary widely,\nsuggesting that fractal parameters might prove helpful in detecting a\nnon-trivial portion of LLM-generated texts. Notably, these findings, and many\nothers reported in this work, are robust to the choice of the architecture;\ne.g. Gemini 1.0 Pro, Mistral-7B and Gemma-2B. We also release a dataset\ncomprising of over 240,000 articles generated by various LLMs (both pretrained\nand instruction-tuned) with different decoding temperatures and prompting\nmethods, along with their corresponding human-generated texts. We hope that\nthis work highlights the complex interplay between fractal properties,\nprompting, and statistical mimicry in LLMs, offering insights for generating,\nevaluating and detecting synthetic texts.",
      "tldr_zh": "这篇论文探讨了大型语言模型（LLMs）是否能捕捉语言的分形结构，包括信息理论复杂度（如 bits per token）的自相似性和长程依赖（LRD）。研究发现，LLMs 的输出分形参数变化较大，而自然语言的参数保持在狭窄范围内，这可能有助于检测 LLM 生成的文本，且这些结果在不同架构（如 Gemini 1.0 Pro 和 Mistral-7B）中稳健。作者发布了一个数据集，包含超过24万篇由各种 LLMs 生成的文章及其人类对应文本，并强调了分形属性、提示方法和统计模拟在生成、评估和检测合成文本中的复杂互动。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14924v1",
      "published_date": "2025-02-19 18:15:57 UTC",
      "updated_date": "2025-02-19 18:15:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:45:20.334974"
    },
    {
      "arxiv_id": "2502.14923v1",
      "title": "AI Thinking as a Meaning-Centered Framework: Reimagining Language Technologies Through Community Agency",
      "title_zh": "翻译失败",
      "authors": [
        "Jose F Quesada"
      ],
      "abstract": "While language technologies have advanced significantly, current approaches\nfail to address the complex sociocultural dimensions of linguistic\npreservation. AI Thinking proposes a meaning-centered framework that would\ntransform technological development from creating tools FOR communities to\nco-creating solutions WITH them. This approach recognizes that meaningful\nsolutions emerge through the interplay of cultural understanding, community\nagency, and technological innovation. The proposal articulates a holistic\nmethodology and a five-layer technological ecosystem where communities maintain\ncontrol over their linguistic and cultural knowledge representation. This\nsystematic integration of community needs, cultural preservation, and advanced\ncapabilities could revolutionize how we approach linguistic diversity\npreservation in the digital age.",
      "tldr_zh": "该论文指出，现有的语言技术无法有效应对语言保存的复杂社会文化维度，提出AI Thinking作为一种以meaning-centered framework为核心的框架，重塑语言技术发展从为社区创建工具转向与社区共同创建解决方案。该框架强调通过文化理解、community agency和技术创新的互动来产生有意义的解决方案，并描述了一个整体方法论和五层技术生态系统，让社区掌控其语言和文化知识表示。这种方法整合社区需求、文化保存与先进技术，可能革新数字时代语言多样性保存的途径。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "LT4All 2025. Language Technologies for All - 2025. Advancing Humanism\n  through Language Technologies. Paris (FR), UNESCO Headquarters, 24-26\n  February 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.14923v1",
      "published_date": "2025-02-19 18:09:24 UTC",
      "updated_date": "2025-02-19 18:09:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:45:31.359542"
    },
    {
      "arxiv_id": "2502.14019v1",
      "title": "Dehumanizing Machines: Mitigating Anthropomorphic Behaviors in Text Generation Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Myra Cheng",
        "Su Lin Blodgett",
        "Alicia DeVrio",
        "Lisa Egede",
        "Alexandra Olteanu"
      ],
      "abstract": "As text generation systems' outputs are increasingly anthropomorphic --\nperceived as human-like -- scholars have also raised increasing concerns about\nhow such outputs can lead to harmful outcomes, such as users over-relying or\ndeveloping emotional dependence on these systems. How to intervene on such\nsystem outputs to mitigate anthropomorphic behaviors and their attendant\nharmful outcomes, however, remains understudied. With this work, we aim to\nprovide empirical and theoretical grounding for developing such interventions.\nTo do so, we compile an inventory of interventions grounded both in prior\nliterature and a crowdsourced study where participants edited system outputs to\nmake them less human-like. Drawing on this inventory, we also develop a\nconceptual framework to help characterize the landscape of possible\ninterventions, articulate distinctions between different types of\ninterventions, and provide a theoretical basis for evaluating the effectiveness\nof different interventions.",
      "tldr_zh": "这篇论文探讨了如何缓解文本生成系统的拟人化行为（anthropomorphic behaviors），以减少用户过度依赖或情感依赖等有害后果。研究者通过文献回顾和一个众包研究（crowdsourced study），编译了一个干预清单，让参与者编辑系统输出使其不那么像人类。论文还开发了一个概念框架，用于描述干预景观、区分干预类型，并提供理论基础来评估其有效性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14019v1",
      "published_date": "2025-02-19 18:06:37 UTC",
      "updated_date": "2025-02-19 18:06:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:45:42.520808"
    },
    {
      "arxiv_id": "2502.17489v1",
      "title": "Using Graph Convolutional Networks to Address fMRI Small Data Problems",
      "title_zh": "利用图卷积网络解决 fMRI 小数据问题",
      "authors": [
        "Thomas Screven",
        "Andras Necz",
        "Jason Smucny",
        "Ian Davidson"
      ],
      "abstract": "Although great advances in the analysis of neuroimaging data have been made,\na major challenge is a lack of training data. This is less problematic in tasks\nsuch as diagnosis, where much data exists, but particularly prevalent in harder\nproblems such as predicting treatment responses (prognosis), where data is\nfocused and hence limited. Here, we address the learning from small data\nproblems for medical imaging using graph neural networks. This is particularly\nchallenging as the information about the patients is themselves graphs (regions\nof interest connectivity graphs). We show how a spectral representation of the\nconnectivity data allows for efficient propagation that can yield approximately\n12\\% improvement over traditional deep learning methods using the exact same\ndata. We show that our method's superior performance is due to a data smoothing\nresult that can be measured by closing the number of triangle inequalities and\nthereby satisfying transitivity.",
      "tldr_zh": "该论文针对 fMRI 数据分析中的小样本问题（如预测治疗响应），提出使用 Graph Neural Networks 来提升模型性能。研究通过图的谱表示（spectral representation）对患者连接性图（regions of interest connectivity graphs）进行高效传播，实现比传统深度学习方法约12%的性能提升。主要发现是，这种方法通过数据平滑效果减少三角不等式数量，从而满足 transitivity，并证明其在小数据场景下的优越性。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "8 pages",
      "pdf_url": "http://arxiv.org/pdf/2502.17489v1",
      "published_date": "2025-02-19 18:05:46 UTC",
      "updated_date": "2025-02-19 18:05:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:45:53.486064"
    },
    {
      "arxiv_id": "2502.13928v1",
      "title": "Symmetrical Visual Contrastive Optimization: Aligning Vision-Language Models with Minimal Contrastive Images",
      "title_zh": "翻译失败",
      "authors": [
        "Shengguang Wu",
        "Fan-Yun Sun",
        "Kaiyue Wen",
        "Nick Haber"
      ],
      "abstract": "Recent studies have shown that Large Vision-Language Models (VLMs) tend to\nneglect image content and over-rely on language-model priors, resulting in\nerrors in visually grounded tasks and hallucinations. We hypothesize that this\nissue arises because existing VLMs are not explicitly trained to generate texts\nthat are accurately grounded in fine-grained image details. To enhance visual\nfeedback during VLM training, we propose S-VCO (Symmetrical Visual Contrastive\nOptimization), a novel finetuning objective that steers the model toward\ncapturing important visual details and aligning them with corresponding text\ntokens. To further facilitate this detailed alignment, we introduce MVC, a\npaired image-text dataset built by automatically filtering and augmenting\nvisual counterfactual data to challenge the model with hard contrastive cases\ninvolving Minimal Visual Contrasts. Experiments show that our method\nconsistently improves VLM performance across diverse benchmarks covering\nvarious abilities and domains, achieving up to a 22% reduction in\nhallucinations, and significant gains in vision-centric and general tasks.\nNotably, these improvements become increasingly pronounced in benchmarks with\nhigher visual dependency. In short, S-VCO offers a significant enhancement of\nVLM's visually-dependent task performance while retaining or even improving the\nmodel's general abilities. We opensource our code at https://s-vco.github.io/",
      "tldr_zh": "最近研究发现，Large Vision-Language Models (VLMs) 往往忽略图像内容而过度依赖语言模型先验，导致视觉任务错误和幻觉问题。针对此，本文提出 S-VCO (Symmetrical Visual Contrastive Optimization)，一种新型微调目标，通过对称视觉对比优化引导模型捕捉细粒度图像细节并与对应文本标记对齐，从而增强视觉反馈。同时，引入 MVC 数据集，该数据集通过自动过滤和增强视觉反事实数据，创建最小视觉对比的挑战案例。实验结果显示，S-VCO 在多种基准上显著改善 VLM 性能，减少高达 22% 的幻觉，并在视觉依赖度高的任务中取得更大提升，同时保留或提升模型的一般能力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Project Website: https://s-vco.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2502.13928v1",
      "published_date": "2025-02-19 18:05:42 UTC",
      "updated_date": "2025-02-19 18:05:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:46:07.351129"
    },
    {
      "arxiv_id": "2502.13913v1",
      "title": "How Do LLMs Perform Two-Hop Reasoning in Context?",
      "title_zh": "LLMs 如何在上下文中进行二跳推理？",
      "authors": [
        "Tianyu Guo",
        "Hanlin Zhu",
        "Ruiqi Zhang",
        "Jiantao Jiao",
        "Song Mei",
        "Michael I. Jordan",
        "Stuart Russell"
      ],
      "abstract": "\"Socrates is human. All humans are mortal. Therefore, Socrates is mortal.\"\nThis classical example demonstrates two-hop reasoning, where a conclusion\nlogically follows from two connected premises. While transformer-based Large\nLanguage Models (LLMs) can make two-hop reasoning, they tend to collapse to\nrandom guessing when faced with distracting premises. To understand the\nunderlying mechanism, we train a three-layer transformer on synthetic two-hop\nreasoning tasks. The training dynamics show two stages: a slow learning phase,\nwhere the 3-layer transformer performs random guessing like LLMs, followed by\nan abrupt phase transitions, where the 3-layer transformer suddenly reaches\n$100%$ accuracy. Through reverse engineering, we explain the inner mechanisms\nfor how models learn to randomly guess between distractions initially, and how\nthey learn to ignore distractions eventually. We further propose a\nthree-parameter model that supports the causal claims for the mechanisms to the\ntraining dynamics of the transformer. Finally, experiments on LLMs suggest that\nthe discovered mechanisms generalize across scales. Our methodologies provide\nnew perspectives for scientific understandings of LLMs and our findings provide\nnew insights into how reasoning emerges during training.",
      "tldr_zh": "这篇论文探讨了大型语言模型(LLMs)在处理两跳推理（two-hop reasoning）时的问题，特别是当存在干扰前提时，模型往往会随机猜测。研究者训练了一个三层transformer模型在合成任务上，观察到训练动态分为慢速学习阶段（初始随机猜测）和突变阶段（突然达到100%准确率）。通过逆向工程，他们解释了模型如何从随机猜测转向忽略干扰，并提出一个三参数模型来支持这些机制。实验结果显示，这些机制在不同规模的LLMs上通用，为理解LLMs的推理过程提供了新视角和洞见。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.13913v1",
      "published_date": "2025-02-19 17:46:30 UTC",
      "updated_date": "2025-02-19 17:46:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:46:18.997895"
    },
    {
      "arxiv_id": "2502.13909v3",
      "title": "Lost in Sequence: Do Large Language Models Understand Sequential Recommendation?",
      "title_zh": "翻译失败",
      "authors": [
        "Sein Kim",
        "Hongseok Kang",
        "Kibum Kim",
        "Jiwan Kim",
        "Donghyun Kim",
        "Minchul Yang",
        "Kwangjin Oh",
        "Julian McAuley",
        "Chanyoung Park"
      ],
      "abstract": "Large Language Models (LLMs) have recently emerged as promising tools for\nrecommendation thanks to their advanced textual understanding ability and\ncontext-awareness. Despite the current practice of training and evaluating\nLLM-based recommendation (LLM4Rec) models under a sequential recommendation\nscenario, we found that whether these models understand the sequential\ninformation inherent in users' item interaction sequences has been largely\noverlooked. In this paper, we first demonstrate through a series of experiments\nthat existing LLM4Rec models do not fully capture sequential information both\nduring training and inference. Then, we propose a simple yet effective\nLLM-based sequential recommender, called LLM-SRec, a method that enhances the\nintegration of sequential information into LLMs by distilling the user\nrepresentations extracted from a pre-trained CF-SRec model into LLMs. Our\nextensive experiments show that LLM-SRec enhances LLMs' ability to understand\nusers' item interaction sequences, ultimately leading to improved\nrecommendation performance. Furthermore, unlike existing LLM4Rec models that\nrequire fine-tuning of LLMs, LLM-SRec achieves state-of-the-art performance by\ntraining only a few lightweight MLPs, highlighting its practicality in\nreal-world applications. Our code is available at\nhttps://github.com/Sein-Kim/LLM-SRec.",
      "tldr_zh": "这项研究探讨了大型语言模型 (LLMs) 在顺序推荐 (sequential recommendation) 中的理解能力，通过实验发现，现有的 LLM-based recommendation (LLM4Rec) 模型未能充分捕捉用户交互序列的顺序信息。作者提出了一种简单有效的模型 LLM-SRec，通过从预训练的 CF-SRec 模型中提取用户表示并进行知识蒸馏，增强 LLMs 对顺序信息的整合。实验结果显示，LLM-SRec 显著提高了推荐性能，且仅需训练少量轻量级 MLP (MLPs)，而无需微调 LLMs，从而提升了其在实际应用中的实用性。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.13909v3",
      "published_date": "2025-02-19 17:41:09 UTC",
      "updated_date": "2025-04-02 17:42:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:46:29.806751"
    },
    {
      "arxiv_id": "2502.13905v1",
      "title": "Partially Observable Gaussian Process Network and Doubly Stochastic Variational Inference",
      "title_zh": "部分可观测高斯过程网络和双重随机变分推断",
      "authors": [
        "Saksham Kiroriwal",
        "Julius Pfrommer",
        "Jürgen Beyerer"
      ],
      "abstract": "To reduce the curse of dimensionality for Gaussian processes (GP), they can\nbe decomposed into a Gaussian Process Network (GPN) of coupled subprocesses\nwith lower dimensionality. In some cases, intermediate observations are\navailable within the GPN. However, intermediate observations are often\nindirect, noisy, and incomplete in most real-world systems. This work\nintroduces the Partially Observable Gaussian Process Network (POGPN) to model\nreal-world process networks. We model a joint distribution of latent functions\nof subprocesses and make inferences using observations from all subprocesses.\nPOGPN incorporates observation lenses (observation likelihoods) into the\nwell-established inference method of deep Gaussian processes. We also introduce\ntwo training methods for POPGN to make inferences on the whole network using\nnode observations. The application to benchmark problems demonstrates how\nincorporating partial observations during training and inference can improve\nthe predictive performance of the overall network, offering a promising outlook\nfor its practical application.",
      "tldr_zh": "本文提出Partially Observable Gaussian Process Network (POGPN)，旨在缓解Gaussian Process (GP)的维度诅咒问题，通过将GP分解为耦合子过程的Gaussian Process Network (GPN)并整合部分观察数据来建模真实世界的过程网络。POGPN 模型子过程的潜在函数联合分布，并将observation lenses (观察似然)融入深度高斯过程的推理方法中，同时引入两种训练方法，利用节点观察对整个网络进行推理。实验结果显示，在基准问题上，纳入部分观察显著提高了网络的预测性能，为实际应用提供了有前景的方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.13905v1",
      "published_date": "2025-02-19 17:39:46 UTC",
      "updated_date": "2025-02-19 17:39:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:46:42.655727"
    },
    {
      "arxiv_id": "2502.14922v1",
      "title": "SIFT: Grounding LLM Reasoning in Contexts via Stickers",
      "title_zh": "翻译失败",
      "authors": [
        "Zihao Zeng",
        "Xuyao Huang",
        "Boxiu Li",
        "Zhijie Deng"
      ],
      "abstract": "This paper identifies the misinterpretation of the context can be a\nsignificant issue during the reasoning process of large language models,\nspanning from smaller models like Llama3.2-3B-Instruct to cutting-edge ones\nlike DeepSeek-R1. For example, in the phrase \"10 dollars per kilo,\" LLMs might\nnot recognize that \"per\" means \"for each,\" leading to calculation errors. We\nintroduce a novel, post-training approach called **Stick to the Facts (SIFT)**\nto tackle this. SIFT leverages increasing inference-time compute to ground LLM\nreasoning in contexts. At the core of SIFT lies the *Sticker*, which is\ngenerated by the model itself to explicitly emphasize the key information\nwithin the context. Given the curated Sticker, SIFT generates two predictions\n-- one from the original query and one from the query augmented with the\nSticker. If they differ, the Sticker is sequentially refined via *forward*\noptimization (to better align the extracted facts with the query) and *inverse*\ngeneration (to conform with the model's inherent tendencies) for more faithful\nreasoning outcomes. Studies across diverse models (from 3B to 100B+) and\nbenchmarks (e.g., GSM8K, MATH-500) reveal consistent performance improvements.\nNotably, SIFT improves the pass@1 accuracy of DeepSeek-R1 on AIME2024 from\n78.33% to **85.67**%, establishing a new state-of-the-art in the open-source\ncommunity. The code is available at https://github.com/zhijie-group/SIFT.",
      "tldr_zh": "这篇论文指出了大型语言模型(LLMs)在推理过程中对上下文的误解问题，例如在“10 dollars per kilo”中未能正确理解“per”的含义，并引入了后训练方法 **Stick to the Facts (SIFT)** 来解决这一问题。SIFT 通过增加推理时的计算生成 *Sticker* 来显式强调上下文关键信息，然后通过 *forward* optimization（优化事实与查询的对齐）和 *inverse* generation（符合模型内在倾向）来逐步完善 Sticker，从而产生更可靠的预测。实验结果显示，SIFT 在多种模型（从 3B 到 100B+）和基准（如 GSM8K、MATH-500）上实现了性能一致提升，特别是将 DeepSeek-R1 在 AIME2024 上的 pass@1 准确率从 78.33% 提高到 85.67%，在开源社区树立了新标准。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14922v1",
      "published_date": "2025-02-19 17:38:46 UTC",
      "updated_date": "2025-02-19 17:38:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:46:57.029064"
    },
    {
      "arxiv_id": "2502.13897v1",
      "title": "DataSciBench: An LLM Agent Benchmark for Data Science",
      "title_zh": "翻译失败",
      "authors": [
        "Dan Zhang",
        "Sining Zhoubian",
        "Min Cai",
        "Fengzu Li",
        "Lekang Yang",
        "Wei Wang",
        "Tianjiao Dong",
        "Ziniu Hu",
        "Jie Tang",
        "Yisong Yue"
      ],
      "abstract": "This paper presents DataSciBench, a comprehensive benchmark for evaluating\nLarge Language Model (LLM) capabilities in data science. Recent related\nbenchmarks have primarily focused on single tasks, easily obtainable ground\ntruth, and straightforward evaluation metrics, which limits the scope of tasks\nthat can be evaluated. In contrast, DataSciBench is constructed based on a more\ncomprehensive and curated collection of natural and challenging prompts for\nuncertain ground truth and evaluation metrics. We develop a semi-automated\npipeline for generating ground truth (GT) and validating evaluation metrics.\nThis pipeline utilizes and implements an LLM-based self-consistency and human\nverification strategy to produce accurate GT by leveraging collected prompts,\npredefined task types, and aggregate functions (metrics). Furthermore, we\npropose an innovative Task - Function - Code (TFC) framework to assess each\ncode execution outcome based on precisely defined metrics and programmatic\nrules. Our experimental framework involves testing 6 API-based models, 8\nopen-source general models, and 9 open-source code generation models using the\ndiverse set of prompts we have gathered. This approach aims to provide a more\ncomprehensive and rigorous evaluation of LLMs in data science, revealing their\nstrengths and weaknesses. Experimental results demonstrate that API-based\nmodels outperform open-sourced models on all metrics and\nDeepseek-Coder-33B-Instruct achieves the highest score among open-sourced\nmodels. We release all code and data at https://github.com/THUDM/DataSciBench.",
      "tldr_zh": "这篇论文介绍了 DataSciBench，一个全面的基准，用于评估 Large Language Model (LLM) 在数据科学领域的能力，与现有基准相比，它采用更自然的挑战性提示、半自动管道生成真实数据 (GT) 并结合人工验证，以及 Task - Function - Code (TFC) 框架来精确评估代码执行结果。研究通过测试 6 个 API-based 模型、8 个开源通用模型和 9 个开源代码生成模型，揭示了这些模型的优缺点。实验结果显示，API-based 模型在所有指标上优于开源模型，而 Deepseek-Coder-33B-Instruct 在开源模型中取得最高分数。论文已发布所有代码和数据在 GitHub 上，以促进进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "40 pages, 7 figures, 6 tables",
      "pdf_url": "http://arxiv.org/pdf/2502.13897v1",
      "published_date": "2025-02-19 17:31:51 UTC",
      "updated_date": "2025-02-19 17:31:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:47:08.261997"
    },
    {
      "arxiv_id": "2502.15814v2",
      "title": "Slamming: Training a Speech Language Model on One GPU in a Day",
      "title_zh": "翻译失败",
      "authors": [
        "Gallil Maimon",
        "Avishai Elmakies",
        "Yossi Adi"
      ],
      "abstract": "We introduce Slam, a recipe for training high-quality Speech Language Models\n(SLMs) on a single academic GPU in 24 hours. We do so through empirical\nanalysis of model initialisation and architecture, synthetic training data,\npreference optimisation with synthetic data and tweaking all other components.\nWe empirically demonstrate that this training recipe also scales well with more\ncompute getting results on par with leading SLMs in a fraction of the compute\ncost. We hope these insights will make SLM training and research more\naccessible. In the context of SLM scaling laws, our results far outperform\npredicted compute optimal performance, giving an optimistic view to SLM\nfeasibility. See code, data, models, samples at -\nhttps://pages.cs.huji.ac.il/adiyoss-lab/slamming .",
      "tldr_zh": "我们介绍了Slam，这是一种高效的训练方案，能够在单个学术GPU上用24小时训练高质量的Speech Language Models (SLMs)，通过对模型初始化、架构、合成训练数据以及偏好优化的实证分析来优化所有组件。该方法不仅在有限资源下表现优秀，还能扩展到更多计算资源，达到与领先SLMs相当的性能，但计算成本大幅降低。实验结果远超SLM扩展定律的预测，提供了一个乐观的SLM可行性视角，并通过公开代码、数据和模型促进相关研究的可访问性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.LG",
      "comment": "ACL 2025 (Findings)",
      "pdf_url": "http://arxiv.org/pdf/2502.15814v2",
      "published_date": "2025-02-19 17:21:15 UTC",
      "updated_date": "2025-05-22 16:55:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:47:18.768703"
    },
    {
      "arxiv_id": "2502.13881v3",
      "title": "PSCon: Product Search Through Conversations",
      "title_zh": "PSCon: 通过对话的产品搜索",
      "authors": [
        "Jie Zou",
        "Mohammad Aliannejadi",
        "Evangelos Kanoulas",
        "Shuxi Han",
        "Heli Ma",
        "Zheng Wang",
        "Yang Yang",
        "Heng Tao Shen"
      ],
      "abstract": "Conversational Product Search ( CPS ) systems interact with users via natural\nlanguage to offer personalized and context-aware product lists. However, most\nexisting research on CPS is limited to simulated conversations, due to the lack\nof a real CPS dataset driven by human-like language. Moreover, existing\nconversational datasets for e-commerce are constructed for a particular market\nor a particular language and thus can not support cross-market and\nmulti-lingual usage. In this paper, we propose a CPS data collection protocol\nand create a new CPS dataset, called PSCon, which assists product search\nthrough conversations with human-like language. The dataset is collected by a\ncoached human-human data collection protocol and is available for dual markets\nand two languages. By formulating the task of CPS, the dataset allows for\ncomprehensive and in-depth research on six subtasks: user intent detection,\nkeyword extraction, system action prediction, question selection, item ranking,\nand response generation. Moreover, we present a concise analysis of the dataset\nand propose a benchmark model on the proposed CPS dataset. Our proposed dataset\nand model will be helpful for facilitating future research on CPS.",
      "tldr_zh": "本研究提出了一种对话式产品搜索（Conversational Product Search, CPS）系统，以解决现有研究依赖模拟对话和缺乏真实人类语言数据集的问题。作者设计了一个CPS数据收集协议，并创建了新的PSCon数据集，通过指导的人-人数据收集方式，支持双市场和两种语言，确保对话更接近真实场景。该数据集定义了CPS任务，包括六个子任务：用户意图检测、关键词提取、系统动作预测、问题选择、物品排名和响应生成，并提供了一个基准模型进行评估。通过这一工作，PSCon有望推动未来CPS研究的全面发展。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "11 pages. Accepted by SIGIR 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.13881v3",
      "published_date": "2025-02-19 17:05:42 UTC",
      "updated_date": "2025-04-27 11:19:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:47:30.273261"
    },
    {
      "arxiv_id": "2502.13875v1",
      "title": "MEX: Memory-efficient Approach to Referring Multi-Object Tracking",
      "title_zh": "MEX：内存高效的参照多对象跟踪方法",
      "authors": [
        "Huu-Thien Tran",
        "Phuoc-Sang Pham",
        "Thai-Son Tran",
        "Khoa Luu"
      ],
      "abstract": "Referring Multi-Object Tracking (RMOT) is a relatively new concept that has\nrapidly gained traction as a promising research direction at the intersection\nof computer vision and natural language processing. Unlike traditional\nmulti-object tracking, RMOT identifies and tracks objects and incorporates\ntextual descriptions for object class names, making the approach more\nintuitive. Various techniques have been proposed to address this challenging\nproblem; however, most require the training of the entire network due to their\nend-to-end nature. Among these methods, iKUN has emerged as a particularly\npromising solution. Therefore, we further explore its pipeline and enhance its\nperformance. In this paper, we introduce a practical module dubbed\nMemory-Efficient Cross-modality -- MEX. This memory-efficient technique can be\ndirectly applied to off-the-shelf trackers like iKUN, resulting in significant\narchitectural improvements. Our method proves effective during inference on a\nsingle GPU with 4 GB of memory. Among the various benchmarks, the Refer-KITTI\ndataset, which offers diverse autonomous driving scenes with relevant language\nexpressions, is particularly useful for studying this problem. Empirically, our\nmethod demonstrates effectiveness and efficiency regarding HOTA tracking\nscores, substantially improving memory allocation and processing speed.",
      "tldr_zh": "本研究针对 Referring Multi-Object Tracking (RMOT) 问题，提出了一种内存高效的模块 MEX，以提升现有跟踪器如 iKUN 的性能。MEX 通过内存-Efficient Cross-modality 技术，直接应用于现成模型，避免端到端训练，并在单 GPU（4 GB 内存）上实现高效推理。实验在 Refer-KITTI 数据集上显示，该方法显著提高了 HOTA 跟踪分数，同时优化了内存分配和处理速度，为 RMOT 在计算机视觉和自然语言处理交叉领域的应用提供了更实用的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "6 pages, 6 figures, 2024 International Conference on Advanced\n  Technologies for Communications (ATC), Signal Processing Track",
      "pdf_url": "http://arxiv.org/pdf/2502.13875v1",
      "published_date": "2025-02-19 16:58:42 UTC",
      "updated_date": "2025-02-19 16:58:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:47:41.744822"
    },
    {
      "arxiv_id": "2502.13873v2",
      "title": "NVR: Vector Runahead on NPUs for Sparse Memory Access",
      "title_zh": "翻译失败",
      "authors": [
        "Hui Wang",
        "Zhengpeng Zhao",
        "Jing Wang",
        "Yushu Du",
        "Yuan Cheng",
        "Bing Guo",
        "He Xiao",
        "Chenhao Ma",
        "Xiaomeng Han",
        "Dean You",
        "Jiapeng Guan",
        "Ran Wei",
        "Dawei Yang",
        "Zhe Jiang"
      ],
      "abstract": "Deep Neural Networks are increasingly leveraging sparsity to reduce the\nscaling up of model parameter size. However, reducing wall-clock time through\nsparsity and pruning remains challenging due to irregular memory access\npatterns, leading to frequent cache misses. In this paper, we present NPU\nVector Runahead (NVR), a prefetching mechanism tailored for NPUs to address\ncache miss problems in sparse DNN workloads. Rather than optimising memory\npatterns with high overhead and poor portability, NVR adapts runahead execution\nto the unique architecture of NPUs. NVR provides a general micro-architectural\nsolution for sparse DNN workloads without requiring compiler or algorithmic\nsupport, operating as a decoupled, speculative, lightweight hardware sub-thread\nalongside the NPU, with minimal hardware overhead (under 5%). NVR achieves an\naverage 90% reduction in cache misses compared to SOTA prefetching in\ngeneral-purpose processors, delivering 4x average speedup on sparse workloads\nversus NPUs without prefetching. Moreover, we investigate the advantages of\nincorporating a small cache (16KB) into the NPU combined with NVR. Our\nevaluation shows that expanding this modest cache delivers 5x higher\nperformance benefits than increasing the L2 cache size by the same amount.",
      "tldr_zh": "本论文针对稀疏深度神经网络(DNN)工作负载中不规则内存访问导致的频繁缓存缺失问题，提出 NVR（NPU Vector Runahead），一种专为 NPUs 设计的预取机制。\nNVR 通过适应 NPUs 的独特架构，实现解耦的、推测性的轻量级硬件子线程运行，无需编译器或算法支持，硬件开销低于 5%。\n实验结果显示，NVR 相较于现有最先进预取技术，平均减少 90% 的缓存缺失，并为稀疏工作负载带来 4 倍的速度提升。\n此外，论文评估了在 NPU 中结合 16KB 小缓存的益处，发现扩展该小缓存比同等规模增加 L2 缓存提供 5 倍的性能优势。",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "primary_category": "cs.AR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.13873v2",
      "published_date": "2025-02-19 16:54:58 UTC",
      "updated_date": "2025-03-17 20:31:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:47:56.047910"
    },
    {
      "arxiv_id": "2502.13870v1",
      "title": "SPEX: Scaling Feature Interaction Explanations for LLMs",
      "title_zh": "SPEX：针对LLMs的特征交互解释扩展",
      "authors": [
        "Justin Singh Kang",
        "Landon Butler",
        "Abhineet Agarwal",
        "Yigit Efe Erginbas",
        "Ramtin Pedarsani",
        "Kannan Ramchandran",
        "Bin Yu"
      ],
      "abstract": "Large language models (LLMs) have revolutionized machine learning due to\ntheir ability to capture complex interactions between input features. Popular\npost-hoc explanation methods like SHAP provide marginal feature attributions,\nwhile their extensions to interaction importances only scale to small input\nlengths ($\\approx 20$). We propose Spectral Explainer (SPEX), a model-agnostic\ninteraction attribution algorithm that efficiently scales to large input\nlengths ($\\approx 1000)$. SPEX exploits underlying natural sparsity among\ninteractions -- common in real-world data -- and applies a sparse Fourier\ntransform using a channel decoding algorithm to efficiently identify important\ninteractions. We perform experiments across three difficult long-context\ndatasets that require LLMs to utilize interactions between inputs to complete\nthe task. For large inputs, SPEX outperforms marginal attribution methods by up\nto 20% in terms of faithfully reconstructing LLM outputs. Further, SPEX\nsuccessfully identifies key features and interactions that strongly influence\nmodel output. For one of our datasets, HotpotQA, SPEX provides interactions\nthat align with human annotations. Finally, we use our model-agnostic approach\nto generate explanations to demonstrate abstract reasoning in closed-source\nLLMs (GPT-4o mini) and compositional reasoning in vision-language models.",
      "tldr_zh": "本研究提出 SPEX，一种模型无关的交互归因算法，用于扩展大型语言模型 (LLMs) 的特征交互解释，能够高效处理长输入长度（约1000），而现有方法如 SHAP 仅限于小输入（约20）。SPEX 通过利用特征交互的自然稀疏性，并应用稀疏傅立叶变换 (sparse Fourier transform) 和通道解码算法，来快速识别重要交互。实验在三个复杂长上下文数据集上显示，SPEX 比边缘归因方法提高高达20% 在重建 LLM 输出方面的忠实度，并成功识别关键特征和交互，与 HotpotQA 数据集的人类标注一致；此外，该方法还用于解释闭源 LLMs（如 GPT-4o mini）的抽象推理和视觉语言模型的组合推理。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.IT",
        "math.IT"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.13870v1",
      "published_date": "2025-02-19 16:49:55 UTC",
      "updated_date": "2025-02-19 16:49:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:48:06.953386"
    },
    {
      "arxiv_id": "2502.13847v1",
      "title": "DH-RAG: A Dynamic Historical Context-Powered Retrieval-Augmented Generation Method for Multi-Turn Dialogue",
      "title_zh": "DH-RAG：一种动态历史上下文驱动的检索增强生成方法，用于多轮对话",
      "authors": [
        "Feiyuan Zhang",
        "Dezhi Zhu",
        "James Ming",
        "Yilun Jin",
        "Di Chai",
        "Liu Yang",
        "Han Tian",
        "Zhaoxin Fan",
        "Kai Chen"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) systems have shown substantial benefits\nin applications such as question answering and multi-turn dialogue\n\\citep{lewis2020retrieval}. However, traditional RAG methods, while leveraging\nstatic knowledge bases, often overlook the potential of dynamic historical\ninformation in ongoing conversations. To bridge this gap, we introduce DH-RAG,\na Dynamic Historical Context-Powered Retrieval-Augmented Generation Method for\nMulti-Turn Dialogue. DH-RAG is inspired by human cognitive processes that\nutilize both long-term memory and immediate historical context in\nconversational responses \\citep{stafford1987conversational}. DH-RAG is\nstructured around two principal components: a History-Learning based Query\nReconstruction Module, designed to generate effective queries by synthesizing\ncurrent and prior interactions, and a Dynamic History Information Updating\nModule, which continually refreshes historical context throughout the dialogue.\nThe center of DH-RAG is a Dynamic Historical Information database, which is\nfurther refined by three strategies within the Query Reconstruction Module:\nHistorical Query Clustering, Hierarchical Matching, and Chain of Thought\nTracking. Experimental evaluations show that DH-RAG significantly surpasses\nconventional models on several benchmarks, enhancing response relevance,\ncoherence, and dialogue quality.",
      "tldr_zh": "本文提出 DH-RAG，一种动态历史上下文驱动的检索增强生成（RAG）方法，旨在解决传统 RAG 在多轮对话中忽略动态历史信息的局限，通过模拟人类认知过程整合长期记忆和即时上下文。DH-RAG 的核心组件包括 History-Learning based Query Reconstruction Module（用于合成当前和先前交互生成有效查询）和 Dynamic History Information Updating Module（持续刷新历史数据库），并采用 Historical Query Clustering、Hierarchical Matching 和 Chain of Thought Tracking 等策略进行优化。实验评估显示，DH-RAG 在多个基准上显著超越传统模型，提升了响应相关性、一致性和整体对话质量。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.13847v1",
      "published_date": "2025-02-19 16:10:43 UTC",
      "updated_date": "2025-02-19 16:10:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:48:18.357873"
    },
    {
      "arxiv_id": "2502.13845v2",
      "title": "Improving LLM-powered Recommendations with Personalized Information",
      "title_zh": "利用个性化信息提升 LLM 驱动的推荐系统",
      "authors": [
        "Jiahao Liu",
        "Xueshuo Yan",
        "Dongsheng Li",
        "Guangping Zhang",
        "Hansu Gu",
        "Peng Zhang",
        "Tun Lu",
        "Li Shang",
        "Ning Gu"
      ],
      "abstract": "Due to the lack of explicit reasoning modeling, existing LLM-powered\nrecommendations fail to leverage LLMs' reasoning capabilities effectively. In\nthis paper, we propose a pipeline called CoT-Rec, which integrates two key\nChain-of-Thought (CoT) processes -- user preference analysis and item\nperception analysis -- into LLM-powered recommendations, thereby enhancing the\nutilization of LLMs' reasoning abilities. CoT-Rec consists of two stages: (1)\npersonalized information extraction, where user preferences and item perception\nare extracted, and (2) personalized information utilization, where this\ninformation is incorporated into the LLM-powered recommendation process.\nExperimental results demonstrate that CoT-Rec shows potential for improving\nLLM-powered recommendations. The implementation is publicly available at\nhttps://github.com/jhliu0807/CoT-Rec.",
      "tldr_zh": "该论文指出，现有的LLM-powered推荐系统因缺乏显式推理建模而未能有效利用LLM的推理能力。为解决此问题，研究提出CoT-Rec框架，该框架整合了Chain-of-Thought (CoT)过程，包括用户偏好分析和物品感知分析两个阶段：首先提取个性化信息（如用户偏好和物品感知），然后将其融入推荐流程中。实验结果表明，CoT-Rec有潜力显著提升推荐系统的性能，且其实现代码已在GitHub上公开。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted by SIGIR 2025, 7 pages",
      "pdf_url": "http://arxiv.org/pdf/2502.13845v2",
      "published_date": "2025-02-19 16:08:17 UTC",
      "updated_date": "2025-04-18 07:45:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:48:29.241979"
    },
    {
      "arxiv_id": "2502.13843v2",
      "title": "AgentCF++: Memory-enhanced LLM-based Agents for Popularity-aware Cross-domain Recommendations",
      "title_zh": "AgentCF++",
      "authors": [
        "Jiahao Liu",
        "Shengkang Gu",
        "Dongsheng Li",
        "Guangping Zhang",
        "Mingzhe Han",
        "Hansu Gu",
        "Peng Zhang",
        "Tun Lu",
        "Li Shang",
        "Ning Gu"
      ],
      "abstract": "LLM-based user agents, which simulate user interaction behavior, are emerging\nas a promising approach to enhancing recommender systems. In real-world\nscenarios, users' interactions often exhibit cross-domain characteristics and\nare influenced by others. However, the memory design in current methods causes\nuser agents to introduce significant irrelevant information during\ndecision-making in cross-domain scenarios and makes them unable to recognize\nthe influence of other users' interactions, such as popularity factors. To\ntackle this issue, we propose a dual-layer memory architecture combined with a\ntwo-step fusion mechanism. This design avoids irrelevant information during\ndecision-making while ensuring effective integration of cross-domain\npreferences. We also introduce the concepts of interest groups and group-shared\nmemory to better capture the influence of popularity factors on users with\nsimilar interests. Comprehensive experiments validate the effectiveness of\nAgentCF++. Our code is available at https://github.com/jhliu0807/AgentCF-plus.",
      "tldr_zh": "该论文提出AgentCF++，一种基于LLM的增强内存代理系统，用于处理流行度感知的跨域推荐问题，以模拟用户交互行为。论文引入双层内存架构和两步融合机制，避免决策过程中引入无关信息，同时有效整合跨域偏好；此外，通过兴趣groups和group-shared memory的概念，捕捉类似兴趣用户间的流行度影响。实验结果验证了AgentCF++的有效性，并提供了开源代码。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted by SIGIR 2025, 6 pages",
      "pdf_url": "http://arxiv.org/pdf/2502.13843v2",
      "published_date": "2025-02-19 16:02:59 UTC",
      "updated_date": "2025-04-18 07:48:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:48:41.602843"
    },
    {
      "arxiv_id": "2502.13840v2",
      "title": "Unbiased Collaborative Filtering with Fair Sampling",
      "title_zh": "翻译失败",
      "authors": [
        "Jiahao Liu",
        "Dongsheng Li",
        "Hansu Gu",
        "Peng Zhang",
        "Tun Lu",
        "Li Shang",
        "Ning Gu"
      ],
      "abstract": "Recommender systems leverage extensive user interaction data to model\npreferences; however, directly modeling these data may introduce biases that\ndisproportionately favor popular items. In this paper, we demonstrate that\npopularity bias arises from the influence of propensity factors during\ntraining. Building on this insight, we propose a fair sampling (FS) method that\nensures each user and each item has an equal likelihood of being selected as\nboth positive and negative instances, thereby mitigating the influence of\npropensity factors. The proposed FS method does not require estimating\npropensity scores, thus avoiding the risk of failing to fully eliminate\npopularity bias caused by estimation inaccuracies. Comprehensive experiments\ndemonstrate that the proposed FS method achieves state-of-the-art performance\nin both point-wise and pair-wise recommendation tasks. The code implementation\nis available at https://github.com/jhliu0807/Fair-Sampling.",
      "tldr_zh": "该研究揭示了推荐系统中流行偏置（popularity bias）的成因，即训练过程中的倾向性因素（propensity factors）对用户交互数据的影响。论文提出了一种公平采样（Fair Sampling, FS）方法，通过确保每个用户和每个物品在正例和负例中被选择的概率相等，从而有效缓解这种偏置。FS 方法无需估计倾向性分数（propensity scores），避免了估计误差导致的偏置消除不彻底。在全面实验中，FS 在点式（point-wise）和配对（pair-wise）推荐任务中实现了最先进性能，并提供了开源代码实现。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "Accept by SIGIR 2025, 5 pages",
      "pdf_url": "http://arxiv.org/pdf/2502.13840v2",
      "published_date": "2025-02-19 15:59:49 UTC",
      "updated_date": "2025-04-18 07:42:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:48:54.451896"
    },
    {
      "arxiv_id": "2503.05737v1",
      "title": "Local Differences, Global Lessons: Insights from Organisation Policies for International Legislation",
      "title_zh": "翻译失败",
      "authors": [
        "Lucie-Aimée Kaffee",
        "Pepa Atanasova",
        "Anna Rogers"
      ],
      "abstract": "The rapid adoption of AI across diverse domains has led to the development of\norganisational guidelines that vary significantly, even within the same sector.\nThis paper examines AI policies in two domains, news organisations and\nuniversities, to understand how bottom-up governance approaches shape AI usage\nand oversight. By analysing these policies, we identify key areas of\nconvergence and divergence in how organisations address risks such as bias,\nprivacy, misinformation, and accountability. We then explore the implications\nof these findings for international AI legislation, particularly the EU AI Act,\nhighlighting gaps where practical policy insights could inform regulatory\nrefinements. Our analysis reveals that organisational policies often address\nissues such as AI literacy, disclosure practices, and environmental impact,\nareas that are underdeveloped in existing international frameworks. We argue\nthat lessons from domain-specific AI policies can contribute to more adaptive\nand effective AI governance at the global level. This study provides actionable\nrecommendations for policymakers seeking to bridge the gap between local AI\npractices and international regulations.",
      "tldr_zh": "这篇论文分析了新闻组织和大学等领域的 AI 政策，探讨自下而上的治理方式如何影响 AI 使用和风险监督，包括偏见、隐私、错误信息及责任等方面。研究发现，这些组织政策在关键领域如 AI 素养、披露实践和环境影响上存在显著收敛和分歧，且这些方面在国际框架中尚未充分发展。作者据此为国际 AI 立法（如 EU AI Act）提供启示，并提出可操作建议，以从本地实践吸取教训，实现更具适应性的全球 AI 治理。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.05737v1",
      "published_date": "2025-02-19 15:59:09 UTC",
      "updated_date": "2025-02-19 15:59:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:49:06.769458"
    },
    {
      "arxiv_id": "2502.13836v1",
      "title": "Quantifying Memorization and Retriever Performance in Retrieval-Augmented Vision-Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Peter Carragher",
        "Abhinand Jha",
        "R Raghav",
        "Kathleen M. Carley"
      ],
      "abstract": "Large Language Models (LLMs) demonstrate remarkable capabilities in question\nanswering (QA), but metrics for assessing their reliance on memorization versus\nretrieval remain underdeveloped. Moreover, while finetuned models are\nstate-of-the-art on closed-domain tasks, general-purpose models like GPT-4o\nexhibit strong zero-shot performance. This raises questions about the\ntrade-offs between memorization, generalization, and retrieval. In this work,\nwe analyze the extent to which multimodal retrieval-augmented VLMs memorize\ntraining data compared to baseline VLMs. Using the WebQA benchmark, we contrast\nfinetuned models with baseline VLMs on multihop retrieval and question\nanswering, examining the impact of finetuning on data memorization. To quantify\nmemorization in end-to-end retrieval and QA systems, we propose several proxy\nmetrics by investigating instances where QA succeeds despite retrieval failing.\nOur results reveal the extent to which finetuned models rely on memorization.\nIn contrast, retrieval-augmented VLMs have lower memorization scores, at the\ncost of accuracy (72% vs 52% on WebQA test set). As such, our measures pose a\nchallenge for future work to reconcile memorization and generalization in both\nOpen-Domain QA and joint Retrieval-QA tasks.",
      "tldr_zh": "本研究探讨了大语言模型（LLMs）在问答（QA）任务中记忆与检索的权衡问题，特别是针对多模态检索增强视觉语言模型（VLMs）。作者使用 WebQA 基准对比微调模型和基线 VLMs，在多跳检索和 QA 上分析微调对数据记忆的影响，并提出代理指标来量化端到端检索和 QA 系统中的记忆程度。结果显示，微调模型更依赖记忆，导致准确率较高（72% on WebQA 测试集），而检索增强 VLMs 的记忆得分较低，但准确率下降至52%。这项工作揭示了记忆与泛化的权衡，为未来在开放域 QA 和联合 Retrieval-QA 任务中协调这些因素提出挑战。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.13836v1",
      "published_date": "2025-02-19 15:58:09 UTC",
      "updated_date": "2025-02-19 15:58:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:49:19.773491"
    },
    {
      "arxiv_id": "2502.13834v3",
      "title": "Proving Olympiad Inequalities by Synergizing LLMs and Symbolic Reasoning",
      "title_zh": "通过协同 LLMs 和符号推理证明奥林匹克不等式",
      "authors": [
        "Zenan Li",
        "Zhaoyu Li",
        "Wen Tang",
        "Xian Zhang",
        "Yuan Yao",
        "Xujie Si",
        "Fan Yang",
        "Kaiyu Yang",
        "Xiaoxing Ma"
      ],
      "abstract": "Large language models (LLMs) can prove mathematical theorems formally by\ngenerating proof steps (\\textit{a.k.a.} tactics) within a proof system.\nHowever, the space of possible tactics is vast and complex, while the available\ntraining data for formal proofs is limited, posing a significant challenge to\nLLM-based tactic generation. To address this, we introduce a neuro-symbolic\ntactic generator that synergizes the mathematical intuition learned by LLMs\nwith domain-specific insights encoded by symbolic methods. The key aspect of\nthis integration is identifying which parts of mathematical reasoning are best\nsuited to LLMs and which to symbolic methods. While the high-level idea of\nneuro-symbolic integration is broadly applicable to various mathematical\nproblems, in this paper, we focus specifically on Olympiad inequalities\n(Figure~1). We analyze how humans solve these problems and distill the\ntechniques into two types of tactics: (1) scaling, handled by symbolic methods,\nand (2) rewriting, handled by LLMs. In addition, we combine symbolic tools with\nLLMs to prune and rank the proof goals for efficient proof search. We evaluate\nour framework on 161 challenging inequalities from multiple mathematics\ncompetitions, achieving state-of-the-art performance and significantly\noutperforming existing LLM and symbolic approaches without requiring additional\ntraining data.",
      "tldr_zh": "该论文提出了一种 neuro-symbolic tactic generator，通过整合 LLMs 的数学直觉和符号方法的领域洞见，解决 LLMs 在生成数学证明步骤（tactics）时面临的数据有限和复杂性挑战。针对 Olympiad inequalities，该框架将证明技巧分为 scaling（由符号方法处理）和 rewriting（由 LLMs 处理），并结合符号工具来修剪和排序证明目标，以提升证明搜索效率。实验结果显示，在 161 个数学竞赛不等式上，该方法实现了 state-of-the-art 性能，大幅超越现有 LLMs 和符号方法，且无需额外训练数据。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Published as a conference paper at ICLR 2025. Code is available at\n  https://github.com/Lizn-zn/NeqLIPS/",
      "pdf_url": "http://arxiv.org/pdf/2502.13834v3",
      "published_date": "2025-02-19 15:54:21 UTC",
      "updated_date": "2025-02-27 04:24:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:49:32.290146"
    },
    {
      "arxiv_id": "2503.16452v1",
      "title": "Towards Biomarker Discovery for Early Cerebral Palsy Detection: Evaluating Explanations Through Kinematic Perturbations",
      "title_zh": "翻译失败",
      "authors": [
        "Kimji N. Pellano",
        "Inga Strümke",
        "Daniel Groos",
        "Lars Adde",
        "Pål Haugen",
        "Espen Alexander F. Ihlen"
      ],
      "abstract": "Cerebral Palsy (CP) is a prevalent motor disability in children, for which\nearly detection can significantly improve treatment outcomes. While\nskeleton-based Graph Convolutional Network (GCN) models have shown promise in\nautomatically predicting CP risk from infant videos, their \"black-box\" nature\nraises concerns about clinical explainability. To address this, we introduce a\nperturbation framework tailored for infant movement features and use it to\ncompare two explainable AI (XAI) methods: Class Activation Mapping (CAM) and\nGradient-weighted Class Activation Mapping (Grad-CAM). First, we identify\nsignificant and non-significant body keypoints in very low- and very high-risk\ninfant video snippets based on the XAI attribution scores. We then conduct\ntargeted velocity and angular perturbations, both individually and in\ncombination, on these keypoints to assess how the GCN model's risk predictions\nchange. Our results indicate that velocity-driven features of the arms, hips,\nand legs have a dominant influence on CP risk predictions, while angular\nperturbations have a more modest impact. Furthermore, CAM and Grad-CAM show\npartial convergence in their explanations for both low- and high-risk CP\ngroups. Our findings demonstrate the use of XAI-driven movement analysis for\nearly CP prediction and offer insights into potential movement-based biomarker\ndiscovery that warrant further clinical validation.",
      "tldr_zh": "这篇论文针对大脑性麻痹 (Cerebral Palsy, CP) 的早期检测问题，利用基于骨架的 Graph Convolutional Network (GCN) 模型从婴儿视频预测风险，但强调了模型的可解释性不足。研究引入了一个针对婴儿运动特征的扰动框架，比较了 Class Activation Mapping (CAM) 和 Gradient-weighted Class Activation Mapping (Grad-CAM) 两种可解释 AI (XAI) 方法，通过对重要身体关键点进行速度和角度扰动，评估模型预测的变化。结果显示，手臂、髋部和腿部的速度驱动特征对 CP 风险预测有主导影响，而角度扰动的影响较小，且 CAM 与 Grad-CAM 在解释低风险和高风险组时表现出部分一致性。该工作展示了 XAI 驱动的运动分析在早期 CP 预测中的潜力，并为基于运动的生物标志物发现提供了见解，有待进一步临床验证。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "19 pages, 14 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.16452v1",
      "published_date": "2025-02-19 15:54:10 UTC",
      "updated_date": "2025-02-19 15:54:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:49:45.858297"
    },
    {
      "arxiv_id": "2502.13820v2",
      "title": "Scoring Verifiers: Evaluating Synthetic Verification for Code and Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Aleksander Ficek",
        "Somshubra Majumdar",
        "Vahid Noroozi",
        "Boris Ginsburg"
      ],
      "abstract": "Synthetic verification techniques such as generating test cases and reward\nmodelling are common ways to enhance the coding capabilities of large language\nmodels (LLM) beyond predefined tests. Additionally, code verification has\nrecently found great success as a critical component in improving reasoning\ncapability of LLMs via reinforcement learning. In this paper, we propose a an\napproach which can transform existing coding benchmarks into scoring and\nranking datasets to evaluate the effectiveness of synthetic verifiers. We also\npropose multiple metrics to measure different aspects of the synthetic\nverifiers with the proposed benchmarks. By employing the proposed approach, we\nrelease four new benchmarks (HE-R, HE-R+, MBPP-R, and MBPP-R+), and analyzed\nsynthetic verification methods with standard, reasoning-based, and reward-based\nLLMs. Our experiments show that reasoning can significantly improve test case\ngeneration and that scaling the number of test cases enhances the verification\naccuracy.",
      "tldr_zh": "这篇论文提出了一种方法，将现有的编码基准转化为评分和排名数据集，以评估合成验证器（synthetic verifiers）在提升大型语言模型（LLM）编码和推理能力方面的有效性。\n他们定义了多个指标来衡量合成验证器的不同方面，并发布了四个新基准（HE-R, HE-R+, MBPP-R, and MBPP-R+），用于分析标准、基于推理和基于奖励的LLM。\n实验结果显示，推理能显著改善测试用例（test cases）生成，而增加测试用例数量可提升验证准确性。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.13820v2",
      "published_date": "2025-02-19 15:32:11 UTC",
      "updated_date": "2025-04-01 18:19:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:49:54.765314"
    },
    {
      "arxiv_id": "2502.14920v1",
      "title": "Display Field-Of-View Agnostic Robust CT Kernel Synthesis Using Model-Based Deep Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Hemant Kumar Aggarwal",
        "Antony Jerald",
        "Phaneendra K. Yalavarthy",
        "Rajesh Langoju",
        "Bipul Das"
      ],
      "abstract": "In X-ray computed tomography (CT) imaging, the choice of reconstruction\nkernel is crucial as it significantly impacts the quality of clinical images.\nDifferent kernels influence spatial resolution, image noise, and contrast in\nvarious ways. Clinical applications involving lung imaging often require images\nreconstructed with both soft and sharp kernels. The reconstruction of images\nwith different kernels requires raw sinogram data and storing images for all\nkernels increases processing time and storage requirements. The Display\nField-of-View (DFOV) adds complexity to kernel synthesis, as data acquired at\ndifferent DFOVs exhibit varying levels of sharpness and details. This work\nintroduces an efficient, DFOV-agnostic solution for image-based kernel\nsynthesis using model-based deep learning. The proposed method explicitly\nintegrates CT kernel and DFOV characteristics into the forward model.\nExperimental results on clinical data, along with quantitative analysis of the\nestimated modulation transfer function using wire phantom data, clearly\ndemonstrate the utility of the proposed method in real-time. Additionally, a\ncomparative study with a direct learning network, that lacks forward model\ninformation, shows that the proposed method is more robust to DFOV variations.",
      "tldr_zh": "这篇论文提出了一种基于模型的深度学习方法，用于实现DFOV无关的鲁棒CT核合成，解决了X射线CT成像中不同重建核对图像质量（如空间分辨率、噪声和对比度）的影响问题。方法通过将CT核和DFOV特性显式整合到前向模型中，实现了高效的图像-based内核合成，避免了依赖原始正弦图数据和存储需求。实验结果显示，该方法在临床数据和定量分析（如使用线形幻影的调制传输函数）上表现出实时性能和优越性，与直接学习网络相比，更能适应DFOV变化。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "Accepted at IEEE ISBI 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.14920v1",
      "published_date": "2025-02-19 15:29:47 UTC",
      "updated_date": "2025-02-19 15:29:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:50:07.724274"
    },
    {
      "arxiv_id": "2502.13805v2",
      "title": "AnDB: Breaking Boundaries with an AI-Native Database for Universal Semantic Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Tianqing Wang",
        "Xun Xue",
        "Guoliang Li",
        "Yong Wang"
      ],
      "abstract": "In this demonstration, we present AnDB, an AI-native database that supports\ntraditional OLTP workloads and innovative AI-driven tasks, enabling unified\nsemantic analysis across structured and unstructured data. While structured\ndata analytics is mature, challenges remain in bridging the semantic gap\nbetween user queries and unstructured data. AnDB addresses these issues by\nleveraging cutting-edge AI-native technologies, allowing users to perform\nsemantic queries using intuitive SQL-like statements without requiring AI\nexpertise. This approach eliminates the ambiguity of traditional text-to-SQL\nsystems and provides a seamless end-to-end optimization for analyzing all data\ntypes. AnDB automates query processing by generating multiple execution plans\nand selecting the optimal one through its optimizer, which balances accuracy,\nexecution time, and financial cost based on user policies and internal\noptimizing mechanisms. AnDB future-proofs data management infrastructure,\nempowering users to effectively and efficiently harness the full potential of\nall kinds of data without starting from scratch.",
      "tldr_zh": "这篇论文展示了 AnDB，一种 AI-native database，它支持传统 OLTP workloads 和 AI 驱动任务，实现结构化和非结构化数据的统一语义分析，从而桥接用户查询与非结构化数据之间的语义鸿沟。AnDB 允许用户使用直观的 SQL-like statements 进行语义查询，无需 AI 专业知识，并通过生成多个执行计划并选择最优方案来优化查询处理，平衡准确性、执行时间和成本。根据用户策略和内部优化机制，该系统提供无缝端到端优化，未来化数据管理基础设施，让用户高效利用各种数据。",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.DB",
      "comment": "4 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.13805v2",
      "published_date": "2025-02-19 15:15:59 UTC",
      "updated_date": "2025-03-24 04:22:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:50:19.273486"
    },
    {
      "arxiv_id": "2502.15813v1",
      "title": "Stock Price Prediction Using a Hybrid LSTM-GNN Model: Integrating Time-Series and Graph-Based Analysis",
      "title_zh": "使用混合 LSTM-GNN 模型的股票价格预测：整合时间序列和基于图的分析",
      "authors": [
        "Meet Satishbhai Sonani",
        "Atta Badii",
        "Armin Moin"
      ],
      "abstract": "This paper presents a novel hybrid model that integrates long-short-term\nmemory (LSTM) networks and Graph Neural Networks (GNNs) to significantly\nenhance the accuracy of stock market predictions. The LSTM component adeptly\ncaptures temporal patterns in stock price data, effectively modeling the time\nseries dynamics of financial markets. Concurrently, the GNN component leverages\nPearson correlation and association analysis to model inter-stock relational\ndata, capturing complex nonlinear polyadic dependencies influencing stock\nprices. The model is trained and evaluated using an expanding window validation\napproach, enabling continuous learning from increasing amounts of data and\nadaptation to evolving market conditions. Extensive experiments conducted on\nhistorical stock data demonstrate that our hybrid LSTM-GNN model achieves a\nmean square error (MSE) of 0.00144, representing a substantial reduction of\n10.6% compared to the MSE of the standalone LSTM model of 0.00161. Furthermore,\nthe hybrid model outperforms traditional and advanced benchmarks, including\nlinear regression, convolutional neural networks (CNN), and dense networks.\nThese compelling results underscore the significant potential of combining\ntemporal and relational data through a hybrid approach, offering a powerful\ntool for real-time trading and financial analysis.",
      "tldr_zh": "本文提出了一种混合 LSTM-GNN 模型，用于提升股票价格预测的准确性，通过整合时间序列分析和图-based 分析。模型中，LSTM 捕捉股票价格的时间序列动态，而 GNN 利用 Pearson correlation 和关联分析建模股票间的复杂非线性依赖，并采用扩展窗口验证方法进行训练以适应市场变化。实验在历史股票数据上显示，该模型的 MSE 为 0.00144，比独立 LSTM 模型降低了 10.6%，并优于线性回归、CNN 和密集网络等基准。整体结果突显了结合时序和关系数据的潜力，为实时交易和金融分析提供有力工具。",
      "categories": [
        "q-fin.ST",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-fin.ST",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.15813v1",
      "published_date": "2025-02-19 15:09:13 UTC",
      "updated_date": "2025-02-19 15:09:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:50:31.082319"
    },
    {
      "arxiv_id": "2502.13794v1",
      "title": "LESA: Learnable LLM Layer Scaling-Up",
      "title_zh": "翻译失败",
      "authors": [
        "Yifei Yang",
        "Zouying Cao",
        "Xinbei Ma",
        "Yao Yao",
        "Libo Qin",
        "Zhi Chen",
        "Hai Zhao"
      ],
      "abstract": "Training Large Language Models (LLMs) from scratch requires immense\ncomputational resources, making it prohibitively expensive. Model scaling-up\noffers a promising solution by leveraging the parameters of smaller models to\ncreate larger ones. However, existing depth scaling-up methods rely on\nempirical heuristic rules for layer duplication, which result in poorer\ninitialization and slower convergence during continual pre-training. We propose\n\\textbf{LESA}, a novel learnable method for depth scaling-up. By concatenating\nparameters from each layer and applying Singular Value Decomposition, we\nuncover latent patterns between layers, suggesting that inter-layer parameters\ncan be learned. LESA uses a neural network to predict the parameters inserted\nbetween adjacent layers, enabling better initialization and faster training.\nExperiments show that LESA outperforms existing baselines, achieving superior\nperformance with less than half the computational cost during continual\npre-training. Extensive analyses demonstrate its effectiveness across different\nmodel sizes and tasks.",
      "tldr_zh": "该研究针对训练大型语言模型 (LLMs) 的高计算成本问题，提出了一种新型可学习深度扩展方法 LESA，以优化模型规模扩展。LESA 通过对层参数进行串联并应用 Singular Value Decomposition (SVD)，发现层间潜在模式，并使用神经网络预测插入相邻层之间的参数，从而实现更好的初始化和更快收敛。实验结果显示，LESA 在持续预训练中比现有基线方法性能更优，且计算成本不到一半，在不同模型大小和任务上均表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.13794v1",
      "published_date": "2025-02-19 14:58:48 UTC",
      "updated_date": "2025-02-19 14:58:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:50:43.134966"
    },
    {
      "arxiv_id": "2502.13785v2",
      "title": "Helix-mRNA: A Hybrid Foundation Model For Full Sequence mRNA Therapeutics",
      "title_zh": "Helix-mRNA：用于全序列 mRNA 治疗的混合基础模型",
      "authors": [
        "Matthew Wood",
        "Mathieu Klop",
        "Maxime Allard"
      ],
      "abstract": "mRNA-based vaccines have become a major focus in the pharmaceutical industry.\nThe coding sequence as well as the Untranslated Regions (UTRs) of an mRNA can\nstrongly influence translation efficiency, stability, degradation, and other\nfactors that collectively determine a vaccine's effectiveness. However,\noptimizing mRNA sequences for those properties remains a complex challenge.\nExisting deep learning models often focus solely on coding region optimization,\noverlooking the UTRs. We present Helix-mRNA, a structured state-space-based and\nattention hybrid model to address these challenges. In addition to a first\npre-training, a second pre-training stage allows us to specialise the model\nwith high-quality data. We employ single nucleotide tokenization of mRNA\nsequences with codon separation, ensuring prior biological and structural\ninformation from the original mRNA sequence is not lost. Our model, Helix-mRNA,\noutperforms existing methods in analysing both UTRs and coding region\nproperties. It can process sequences 6x longer than current approaches while\nusing only 10% of the parameters of existing foundation models. Its predictive\ncapabilities extend to all mRNA regions. We open-source the model\n(https://github.com/helicalAI/helical) and model weights\n(https://huggingface.co/helical-ai/helix-mRNA).",
      "tldr_zh": "本研究提出Helix-mRNA，一种基于结构化状态空间和注意力机制的混合基础模型，用于优化mRNA序列的完整疗法，包括编码区和非翻译区(UTRs)，以提升翻译效率、稳定性和疫苗效果。模型采用两个预训练阶段（首个为通用预训练，第二个使用高质量数据专门化）以及单核苷酸标记化技术，以保留mRNA的生物和结构信息。相比现有方法，Helix-mRNA在分析UTRs和编码区方面表现优越，能处理长6倍的序列且仅用10%的参数，并开源模型权重以促进进一步应用。",
      "categories": [
        "q-bio.GN",
        "cs.AI"
      ],
      "primary_category": "q-bio.GN",
      "comment": "8 pages, 3 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2502.13785v2",
      "published_date": "2025-02-19 14:51:41 UTC",
      "updated_date": "2025-03-11 14:21:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:50:55.451208"
    },
    {
      "arxiv_id": "2502.13778v1",
      "title": "Poster: SpiderSim: Multi-Agent Driven Theoretical Cybersecurity Simulation for Industrial Digitalization",
      "title_zh": "海报：SpiderSim：多智能体驱动的理论网络安全模拟，用于工业数字化",
      "authors": [
        "Jiaqi Li",
        "Xizhong Guo",
        "Yang Zhao",
        "Lvyang Zhang",
        "Lidong Zhai"
      ],
      "abstract": "Rapid industrial digitalization has created intricate cybersecurity demands\nthat necessitate effective validation methods. While cyber ranges and\nsimulation platforms are widely deployed, they frequently face limitations in\nscenario diversity and creation efficiency. In this paper, we present\nSpiderSim, a theoretical cybersecurity simulation platform enabling rapid and\nlightweight scenario generation for industrial digitalization security\nresearch. At its core, our platform introduces three key innovations: a\nstructured framework for unified scenario modeling, a multi-agent collaboration\nmechanism for automated generation, and modular atomic security capabilities\nfor flexible scenario composition. Extensive implementation trials across\nmultiple industrial digitalization contexts, including marine ranch monitoring\nsystems, validate our platform's capacity for broad scenario coverage with\nefficient generation processes. Built on solid theoretical foundations and\nreleased as open-source software, SpiderSim facilitates broader research and\ndevelopment in automated security testing for industrial digitalization.",
      "tldr_zh": "该论文介绍了 SpiderSim，一个基于多智能体驱动的理论网络安全模拟平台，旨在解决工业数字化中场景多样性和创建效率的局限问题。平台的核心创新包括结构化的场景建模框架、多智能体协作机制用于自动化生成，以及模块化的原子安全能力以实现灵活场景组合。通过在海洋牧场监控系统等多个工业情境的实验验证，SpiderSim 展示了高效的场景覆盖和生成过程。作为开源软件，该平台基于坚实的理论基础，促进了工业数字化自动化安全测试的研究和发展。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "https://github.com/NRT2024/SpiderSim",
      "pdf_url": "http://arxiv.org/pdf/2502.13778v1",
      "published_date": "2025-02-19 14:42:32 UTC",
      "updated_date": "2025-02-19 14:42:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:51:08.253027"
    },
    {
      "arxiv_id": "2502.13775v1",
      "title": "VITAL: A New Dataset for Benchmarking Pluralistic Alignment in Healthcare",
      "title_zh": "VITAL：用于基准测试医疗",
      "authors": [
        "Anudeex Shetty",
        "Amin Beheshti",
        "Mark Dras",
        "Usman Naseem"
      ],
      "abstract": "Alignment techniques have become central to ensuring that Large Language\nModels (LLMs) generate outputs consistent with human values. However, existing\nalignment paradigms often model an averaged or monolithic preference, failing\nto account for the diversity of perspectives across cultures, demographics, and\ncommunities. This limitation is particularly critical in health-related\nscenarios, where plurality is essential due to the influence of culture,\nreligion, personal values, and conflicting opinions. Despite progress in\npluralistic alignment, no prior work has focused on health, likely due to the\nunavailability of publicly available datasets. To address this gap, we\nintroduce VITAL, a new benchmark dataset comprising 13.1K value-laden\nsituations and 5.4K multiple-choice questions focused on health, designed to\nassess and benchmark pluralistic alignment methodologies. Through extensive\nevaluation of eight LLMs of varying sizes, we demonstrate that existing\npluralistic alignment techniques fall short in effectively accommodating\ndiverse healthcare beliefs, underscoring the need for tailored AI alignment in\nspecific domains. This work highlights the limitations of current approaches\nand lays the groundwork for developing health-specific alignment solutions.",
      "tldr_zh": "该研究强调了现有对齐技术（alignment techniques）在处理 Large Language Models (LLMs) 时忽略了文化、人口统计和社区视角的多样性，尤其在医疗领域，这种局限性可能导致输出不符合多元价值观。论文引入了 VITAL 数据集，一个包含 13.1K 个价值导向情境和 5.4K 个多项选择题的基准数据集，用于评估多元对齐（pluralistic alignment）方法。通过对八个不同规模的 LLMs 进行广泛评估，研究发现现有技术无法有效适应多样化医疗信念，并呼吁开发针对医疗领域的特定 AI 对齐解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Under review",
      "pdf_url": "http://arxiv.org/pdf/2502.13775v1",
      "published_date": "2025-02-19 14:38:57 UTC",
      "updated_date": "2025-02-19 14:38:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:51:20.745015"
    },
    {
      "arxiv_id": "2502.13769v1",
      "title": "A consensus set for the aggregation of partial rankings: the case of the Optimal Set of Bucket Orders Problem",
      "title_zh": "用于部分排序聚合的共识集合：Optimal Set of",
      "authors": [
        "Juan A. Aledo",
        "José A. Gámez",
        "Alejandro Rosete"
      ],
      "abstract": "In rank aggregation problems (RAP), the solution is usually a consensus\nranking that generalizes a set of input orderings. There are different variants\nthat differ not only in terms of the type of rankings that are used as input\nand output, but also in terms of the objective function employed to evaluate\nthe quality of the desired output ranking. In contrast, in some machine\nlearning tasks (e.g. subgroup discovery) or multimodal optimization tasks,\nattention is devoted to obtaining several models/results to account for the\ndiversity in the input data or across the search landscape. Thus, in this paper\nwe propose to provide, as the solution to an RAP, a set of rankings to better\nexplain the preferences expressed in the input orderings. We exemplify our\nproposal through the Optimal Bucket Order Problem (OBOP), an RAP which consists\nin finding a single consensus ranking (with ties) that generalizes a set of\ninput rankings codified as a precedence matrix. To address this, we introduce\nthe Optimal Set of Bucket Orders Problem (OSBOP), a generalization of the OBOP\nthat aims to produce not a single ranking as output but a set of consensus\nrankings. Experimental results are presented to illustrate this proposal,\nshowing how, by providing a set of consensus rankings, the fitness of the\nsolution significantly improves with respect to the one of the original OBOP,\nwithout losing comprehensibility.",
      "tldr_zh": "这篇论文针对排名聚合问题 (RAP)，提出提供一组共识排名作为解决方案，以更好地解释输入顺序中的偏好多样性，而不是传统的单一共识排名。作者以 Optimal Bucket Order Problem (OBOP) 为基础，引入了 Optimal Set of Bucket Orders Problem (OSBOP)，这是一个推广版本，旨在输出多个共识排名（允许平级）来优化适应性。实验结果表明，OSBOP 的性能在 fitness 上显著优于 OBOP，同时保持了 comprehensibility。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "26 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.13769v1",
      "published_date": "2025-02-19 14:32:16 UTC",
      "updated_date": "2025-02-19 14:32:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:51:31.929313"
    },
    {
      "arxiv_id": "2502.13767v3",
      "title": "Agentic AI Software Engineers: Programming with Trust",
      "title_zh": "翻译失败",
      "authors": [
        "Abhik Roychoudhury",
        "Corina Pasareanu",
        "Michael Pradel",
        "Baishakhi Ray"
      ],
      "abstract": "Large Language Models (LLMs) have shown surprising proficiency in generating\ncode snippets, promising to automate large parts of software engineering via\nartificial intelligence (AI). We argue that successfully deploying AI software\nengineers requires a level of trust equal to or even greater than the trust\nestablished by human-driven software engineering practices. The recent trend\ntoward LLM agents offers a path toward integrating the power of LLMs to create\nnew code with the power of analysis tools to increase trust in the code. This\nopinion piece comments on whether LLM agents could dominate software\nengineering workflows in the future and whether the focus of programming will\nshift from programming at scale to programming with trust.",
      "tldr_zh": "该论文讨论了大型语言模型（LLMs）在代码生成方面的潜力，以及将AI软件工程师部署到实际应用中所需的高水平信任。该作者认为，LLM代理（agents）可以通过整合LLMs的代码生成能力与分析工具，来提升代码的可信度，从而类似于人类驱动的软件工程实践。论文作为意见性文章，探讨了LLM代理是否会主导未来的软件工程工作流程，并提出编程焦点可能从规模化转向“programming with trust”。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "5 pages",
      "pdf_url": "http://arxiv.org/pdf/2502.13767v3",
      "published_date": "2025-02-19 14:28:42 UTC",
      "updated_date": "2025-05-22 10:02:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:51:42.437020"
    },
    {
      "arxiv_id": "2502.13764v2",
      "title": "An Overall Real-Time Mechanism for Classification and Quality Evaluation of Rice",
      "title_zh": "水稻分类和质量评估的整体实时机制",
      "authors": [
        "Wanke Xia",
        "Ruoxin Peng",
        "Haoqi Chu",
        "Xinlei Zhu",
        "Zhiyu Yang",
        "Yaojun Wang"
      ],
      "abstract": "Rice is one of the most widely cultivated crops globally and has been\ndeveloped into numerous varieties. The quality of rice during cultivation is\nprimarily determined by its cultivar and characteristics. Traditionally, rice\nclassification and quality assessment rely on manual visual inspection, a\nprocess that is both time-consuming and prone to errors. However, with\nadvancements in machine vision technology, automating rice classification and\nquality evaluation based on its cultivar and characteristics has become\nincreasingly feasible, enhancing both accuracy and efficiency. This study\nproposes a real-time evaluation mechanism for comprehensive rice grain\nassessment, integrating a one-stage object detection approach, a deep\nconvolutional neural network, and traditional machine learning techniques. The\nproposed framework enables rice variety identification, grain completeness\ngrading, and grain chalkiness evaluation. The rice grain dataset used in this\nstudy comprises approximately 20,000 images from six widely cultivated rice\nvarieties in China. Experimental results demonstrate that the proposed\nmechanism achieves a mean average precision (mAP) of 99.14% in the object\ndetection task and an accuracy of 97.89% in the classification task.\nFurthermore, the framework attains an average accuracy of 97.56% in grain\ncompleteness grading within the same rice variety, contributing to an effective\nquality evaluation system.",
      "tldr_zh": "该研究针对稻米分类和质量评估的传统手动方法耗时且易出错的问题，提出了一种整体实时评估机制。该机制整合一阶段物体检测方法、深度卷积神经网络和传统机器学习技术，实现稻米品种识别、谷粒完整性分级以及谷粒白度评估，使用了约20,000张中国六种稻米品种的图像数据集。实验结果显示，该框架在物体检测任务中达到99.14%的mean average precision (mAP)，分类任务准确率达97.89%，而在同一品种的谷粒完整性分级中平均准确率达97.56%。这一创新机制显著提升了稻米质量评估的效率和准确性，为农业自动化提供了有效工具。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.13764v2",
      "published_date": "2025-02-19 14:24:25 UTC",
      "updated_date": "2025-02-23 07:06:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:51:54.327551"
    },
    {
      "arxiv_id": "2502.13755v1",
      "title": "GPA: Grover Policy Agent for Generating Optimal Quantum Sensor Circuits",
      "title_zh": "GPA：Grover 策略代理用于生成最优量子传感器电路",
      "authors": [
        "Ahmad Alomari",
        "Sathish A. P. Kumar"
      ],
      "abstract": "This study proposes a GPA for designing optimal Quantum Sensor Circuits\n(QSCs) to address complex quantum physics problems. The GPA consists of two\nparts: the Quantum Policy Evaluation (QPE) and the Quantum Policy Improvement\n(QPI). The QPE performs phase estimation to generate the search space, while\nthe QPI utilizes Grover search and amplitude amplification techniques to\nefficiently identify an optimal policy that generates optimal QSCs. The GPA\ngenerates QSCs by selecting sequences of gates that maximize the Quantum Fisher\nInformation (QFI) while minimizing the number of gates. The QSCs generated by\nthe GPA are capable of producing entangled quantum states, specifically the\nsqueezed states. High QFI indicates increased sensitivity to parameter changes,\nmaking the circuit useful for quantum state estimation and control tasks.\nEvaluation of the GPA on a QSC that consists of two qubits and a sequence of\nR_x, R_y, and S gates demonstrates its efficiency in generating optimal QSCs\nwith a QFI of 1. Compared to existing quantum agents, the GPA achieves higher\nQFI with fewer gates, demonstrating a more efficient and scalable approach to\nthe design of QSCs. This work illustrates the potential computational power of\nquantum agents for solving quantum physics problems",
      "tldr_zh": "本研究提出GPA（Grover Policy Agent），一种用于生成最优量子传感器电路（QSCs）的框架，以解决复杂量子物理问题。GPA由Quantum Policy Evaluation (QPE) 和Quantum Policy Improvement (QPI) 两部分组成，其中QPE通过相位估计生成搜索空间，QPI则利用Grover search和振幅放大技术高效识别最优策略。生成的QSCs通过选择最大化Quantum Fisher Information (QFI)的门序列，同时最小化门数量，能够产生纠缠量子态如squeezed states，从而提升对参数变化的敏感度。在实验中，GPA在由两个量子比特和R_x、R_y、S门的QSC上实现了QFI为1的性能，并比现有量子代理提供更高的QFI和更少的门，展示了其高效性和可扩展性。",
      "categories": [
        "quant-ph",
        "cs.AI"
      ],
      "primary_category": "quant-ph",
      "comment": "10 pages",
      "pdf_url": "http://arxiv.org/pdf/2502.13755v1",
      "published_date": "2025-02-19 14:20:07 UTC",
      "updated_date": "2025-02-19 14:20:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:52:08.278863"
    },
    {
      "arxiv_id": "2502.13751v1",
      "title": "RobustX: Robust Counterfactual Explanations Made Easy",
      "title_zh": "翻译失败",
      "authors": [
        "Junqi Jiang",
        "Luca Marzari",
        "Aaryan Purohit",
        "Francesco Leofante"
      ],
      "abstract": "The increasing use of Machine Learning (ML) models to aid decision-making in\nhigh-stakes industries demands explainability to facilitate trust.\nCounterfactual Explanations (CEs) are ideally suited for this, as they can\noffer insights into the predictions of an ML model by illustrating how changes\nin its input data may lead to different outcomes. However, for CEs to realise\ntheir explanatory potential, significant challenges remain in ensuring their\nrobustness under slight changes in the scenario being explained. Despite the\nwidespread recognition of CEs' robustness as a fundamental requirement, a lack\nof standardised tools and benchmarks hinders a comprehensive and effective\ncomparison of robust CE generation methods. In this paper, we introduce\nRobustX, an open-source Python library implementing a collection of CE\ngeneration and evaluation methods, with a focus on the robustness property.\nRobustX provides interfaces to several existing methods from the literature,\nenabling streamlined access to state-of-the-art techniques. The library is also\neasily extensible, allowing fast prototyping of novel robust CE generation and\nevaluation methods.",
      "tldr_zh": "随着机器学习(ML)模型在高风险行业的决策中日益应用，Counterfactual Explanations (CEs) 成为解释模型预测的重要工具，但其鲁棒性在场景微小变化下仍面临挑战。本文引入 RobustX，这是一个开源 Python 库，专注于生成和评估鲁棒的 CEs，提供现有文献方法的接口以简化访问最先进技术。该库设计易于扩展，支持快速原型化新型鲁棒 CE 方法，从而填补了标准化工具和基准的空白。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.13751v1",
      "published_date": "2025-02-19 14:12:01 UTC",
      "updated_date": "2025-02-19 14:12:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:52:19.347811"
    },
    {
      "arxiv_id": "2502.13743v1",
      "title": "Inference of Abstraction for Grounded Predicate Logic",
      "title_zh": "翻译失败",
      "authors": [
        "Hiroyuki Kido"
      ],
      "abstract": "An important open question in AI is what simple and natural principle enables\na machine to reason logically for meaningful abstraction with grounded symbols.\nThis paper explores a conceptually new approach to combining probabilistic\nreasoning and predicative symbolic reasoning over data. We return to the era of\nreasoning with a full joint distribution before the advent of Bayesian\nnetworks. We then discuss that a full joint distribution over models of\nexponential size in propositional logic and of infinite size in predicate logic\nshould be simply derived from a full joint distribution over data of linear\nsize. We show that the same process is not only enough to generalise the\nlogical consequence relation of predicate logic but also to provide a new\nperspective to rethink well-known limitations such as the undecidability of\npredicate logic, the symbol grounding problem and the principle of explosion.\nThe reproducibility of this theoretical work is fully demonstrated by the\nincluded proofs.",
      "tldr_zh": "该论文探讨了AI中一个关键问题：什么简单自然的原则能让机器使用接地符号进行逻辑推理，并提出了一种结合概率推理和谓词符号推理的新方法。该方法回归到使用全联合分布的时代，从线性大小的数据全联合分布推导出指数大小的命题逻辑模型或无限大小的谓词逻辑模型，从而推广谓词逻辑的逻辑 consequence relation。同时，这为重新审视well-known limitations，如谓词逻辑的undecidability、symbol grounding problem和principle of explosion提供了新视角，并通过包括的证明确保了理论的可重复性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.13743v1",
      "published_date": "2025-02-19 14:07:34 UTC",
      "updated_date": "2025-02-19 14:07:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:52:32.104290"
    },
    {
      "arxiv_id": "2502.14918v2",
      "title": "RAPTOR: Refined Approach for Product Table Object Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Eliott Thomas",
        "Mickael Coustaty",
        "Aurelie Joseph",
        "Gaspar Deloin",
        "Elodie Carel",
        "Vincent Poulain D'Andecy",
        "Jean-Marc Ogier"
      ],
      "abstract": "Extracting tables from documents is a critical task across various\nindustries, especially on business documents like invoices and reports.\nExisting systems based on DEtection TRansformer (DETR) such as TAble\nTRansformer (TATR), offer solutions for Table Detection (TD) and Table\nStructure Recognition (TSR) but face challenges with diverse table formats and\ncommon errors like incorrect area detection and overlapping columns. This\nresearch introduces RAPTOR, a modular post-processing system designed to\nenhance state-of-the-art models for improved table extraction, particularly for\nproduct tables. RAPTOR addresses recurrent TD and TSR issues, improving both\nprecision and structural predictions. For TD, we use DETR (trained on ICDAR\n2019) and TATR (trained on PubTables-1M and FinTabNet), while TSR only relies\non TATR. A Genetic Algorithm is incorporated to optimize RAPTOR's module\nparameters, using a private dataset of product tables to align with industrial\nneeds. We evaluate our method on two private datasets of product tables, the\npublic DOCILE dataset (which contains tables similar to our target product\ntables), and the ICDAR 2013 and ICDAR 2019 datasets. The results demonstrate\nthat while our approach excels at product tables, it also maintains reasonable\nperformance across diverse table formats. An ablation study further validates\nthe contribution of each module in our system.",
      "tldr_zh": "本研究提出 RAPTOR，一种模块化的后处理系统，用于提升产品表格的提取精度，针对现有基于 DETR 和 TATR 模型的系统在 Table Detection (TD) 和 Table Structure Recognition (TSR) 中存在的错误，如区域检测不准和重叠列问题。RAPTOR 整合 Genetic Algorithm 来优化参数，并使用私有数据集进行训练和调整，以适应工业需求。实验结果显示，在私有数据集、DOCILE 数据集以及 ICDAR 2013 和 2019 数据集上，RAPTOR 显著提高了产品表格的精确性和结构预测性能，且消融研究验证了各模块的贡献。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted for WACVW 2025 (VisionDocs)",
      "pdf_url": "http://arxiv.org/pdf/2502.14918v2",
      "published_date": "2025-02-19 13:59:06 UTC",
      "updated_date": "2025-02-24 08:29:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:52:45.040309"
    },
    {
      "arxiv_id": "2502.13731v2",
      "title": "Robust Counterfactual Inference in Markov Decision Processes",
      "title_zh": "Markov 决策过程中的鲁棒反事实推理",
      "authors": [
        "Jessica Lally",
        "Milad Kazemi",
        "Nicola Paoletti"
      ],
      "abstract": "This paper addresses a key limitation in existing counterfactual inference\nmethods for Markov Decision Processes (MDPs). Current approaches assume a\nspecific causal model to make counterfactuals identifiable. However, there are\nusually many causal models that align with the observational and interventional\ndistributions of an MDP, each yielding different counterfactual distributions,\nso fixing a particular causal model limits the validity (and usefulness) of\ncounterfactual inference. We propose a novel non-parametric approach that\ncomputes tight bounds on counterfactual transition probabilities across all\ncompatible causal models. Unlike previous methods that require solving\nprohibitively large optimisation problems (with variables that grow\nexponentially in the size of the MDP), our approach provides closed-form\nexpressions for these bounds, making computation highly efficient and scalable\nfor non-trivial MDPs. Once such an interval counterfactual MDP is constructed,\nour method identifies robust counterfactual policies that optimise the\nworst-case reward w.r.t. the uncertain interval MDP probabilities. We evaluate\nour method on various case studies, demonstrating improved robustness over\nexisting methods.",
      "tldr_zh": "本文研究了Markov Decision Processes (MDPs)中的反事实推理问题，指出现有方法依赖特定因果模型，导致结果在不同兼容模型下不一致，从而限制了其有效性。论文提出了一种新颖的非参数方法，通过计算所有兼容因果模型的反事实转移概率的紧密边界，并提供封闭形式表达式，实现高效且可扩展的计算。基于此，该方法构建区间反事实MDP，并识别出针对最坏情况的稳健策略；在各种案例研究中，展示了比现有方法更强的稳健性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Fixed typo in Equation (5)",
      "pdf_url": "http://arxiv.org/pdf/2502.13731v2",
      "published_date": "2025-02-19 13:56:20 UTC",
      "updated_date": "2025-03-27 14:20:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:52:57.114080"
    },
    {
      "arxiv_id": "2502.13728v2",
      "title": "Secure Federated Data Distillation",
      "title_zh": "安全的联邦数据蒸馏",
      "authors": [
        "Marco Arazzi",
        "Mert Cihangiroglu",
        "Serena Nicolazzo",
        "Antonino Nocera"
      ],
      "abstract": "Dataset Distillation (DD) is a powerful technique for reducing large datasets\ninto compact, representative synthetic datasets, accelerating Machine Learning\ntraining. However, traditional DD methods operate in a centralized manner,\nwhich poses significant privacy threats and reduces its applicability. To\nmitigate these risks, we propose a Secure Federated Data Distillation (SFDD)\nframework to decentralize the distillation process while preserving privacy.\nUnlike existing Federated Distillation techniques that focus on training global\nmodels with distilled knowledge, our approach aims to produce a distilled\ndataset without exposing local contributions. We leverage the\ngradient-matching-based distillation method, adapting it for a distributed\nsetting where clients contribute to the distillation process without sharing\nraw data. The central aggregator iteratively refines a synthetic dataset by\nintegrating client-side updates while ensuring data confidentiality. To make\nour approach resilient to inference attacks perpetrated by the server that\ncould exploit gradient updates to reconstruct private data, we create an\noptimized Local Differential Privacy approach, called LDPO-RLD. Furthermore, we\nassess the framework's resilience against malicious clients executing backdoor\nattacks (such as Doorping) and demonstrate robustness under the assumption of a\nsufficient number of participating clients. Our experimental results\ndemonstrate the effectiveness of SFDD and that the proposed defense concretely\nmitigates the identified vulnerabilities, with minimal impact on the\nperformance of the distilled dataset. By addressing the interplay between\nprivacy and federation in dataset distillation, this work advances the field of\nprivacy-preserving Machine Learning making our SFDD framework a viable solution\nfor sensitive data-sharing applications.",
      "tldr_zh": "本研究提出Secure Federated Data Distillation (SFDD) 框架，将Dataset Distillation (DD) 过程从集中式转向联邦式设置，以解决隐私威胁问题。SFDD 通过基于梯度匹配的蒸馏方法，让客户端在不共享原始数据的情况下贡献更新，由中央聚合器迭代精炼合成数据集，并引入优化本地差分隐私机制 LDPO-RLD 来抵抗服务器的推断攻击和恶意客户端（如后门攻击）。实验结果显示，SFDD 有效提升了隐私保护，同时对蒸馏数据集的性能影响最小，为隐私保护机器学习应用提供了可行解决方案。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.13728v2",
      "published_date": "2025-02-19 13:54:44 UTC",
      "updated_date": "2025-03-06 14:07:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:53:08.823125"
    },
    {
      "arxiv_id": "2502.13723v1",
      "title": "Direct Value Optimization: Improving Chain-of-Thought Reasoning in LLMs with Refined Values",
      "title_zh": "翻译失败",
      "authors": [
        "Hongbo Zhang",
        "Han Cui",
        "Guangsheng Bao",
        "Linyi Yang",
        "Jun Wang",
        "Yue Zhang"
      ],
      "abstract": "We introduce Direct Value Optimization (DVO), an innovative reinforcement\nlearning framework for enhancing large language models in complex reasoning\ntasks. Unlike traditional methods relying on preference labels, DVO utilizes\nvalue signals at individual reasoning steps, optimizing models via a mean\nsquared error loss. The key benefit of DVO lies in its fine-grained\nsupervision, circumventing the need for labor-intensive human annotations.\nTarget values within the DVO are estimated using either Monte Carlo Tree Search\nor an outcome value model. Our empirical analysis on both mathematical and\ncommonsense reasoning tasks shows that DVO consistently outperforms existing\noffline preference optimization techniques, even with fewer training steps.\nThese findings underscore the importance of value signals in advancing\nreasoning capabilities and highlight DVO as a superior methodology under\nscenarios lacking explicit human preference information.",
      "tldr_zh": "本研究引入了Direct Value Optimization (DVO)，一种创新的强化学习框架，用于提升大型语言模型 (LLMs) 在复杂推理任务中的Chain-of-Thought Reasoning能力。DVO 通过利用单个推理步骤的value signals进行优化，并采用均方误差损失(mean squared error loss)，从而提供细粒度的监督，避免了依赖耗时的人工偏好标注。Target values 通过Monte Carlo Tree Search或outcome value model进行估计，实验结果显示DVO 在数学和常识推理任务上优于现有离线偏好优化技术，即使训练步骤更少。这些发现强调了value signals在提升模型推理能力的重要性，并将DVO 定位为缺乏人类偏好信息场景下的优越方法。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "preprint",
      "pdf_url": "http://arxiv.org/pdf/2502.13723v1",
      "published_date": "2025-02-19 13:51:05 UTC",
      "updated_date": "2025-02-19 13:51:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:53:20.551357"
    },
    {
      "arxiv_id": "2502.13719v1",
      "title": "TrustRAG: An Information Assistant with Retrieval Augmented Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Yixing Fan",
        "Qiang Yan",
        "Wenshan Wang",
        "Jiafeng Guo",
        "Ruqing Zhang",
        "Xueqi Cheng"
      ],
      "abstract": "\\Ac{RAG} has emerged as a crucial technique for enhancing large models with\nreal-time and domain-specific knowledge. While numerous improvements and\nopen-source tools have been proposed to refine the \\ac{RAG} framework for\naccuracy, relatively little attention has been given to improving the\ntrustworthiness of generated results. To address this gap, we introduce\nTrustRAG, a novel framework that enhances \\ac{RAG} from three perspectives:\nindexing, retrieval, and generation. Specifically, in the indexing stage, we\npropose a semantic-enhanced chunking strategy that incorporates hierarchical\nindexing to supplement each chunk with contextual information, ensuring\nsemantic completeness. In the retrieval stage, we introduce a utility-based\nfiltering mechanism to identify high-quality information, supporting answer\ngeneration while reducing input length. In the generation stage, we propose\nfine-grained citation enhancement, which detects opinion-bearing sentences in\nresponses and infers citation relationships at the sentence-level, thereby\nimproving citation accuracy. We open-source the TrustRAG framework and provide\na demonstration studio designed for excerpt-based question answering tasks\n\\footnote{https://huggingface.co/spaces/golaxy/TrustRAG}. Based on these, we\naim to help researchers: 1) systematically enhancing the trustworthiness of\n\\ac{RAG} systems and (2) developing their own \\ac{RAG} systems with more\nreliable outputs.",
      "tldr_zh": "该论文介绍了TrustRAG，一种增强RAG（Retrieval Augmented Generation）框架的系统，以提升生成结果的可信度。TrustRAG从三个方面进行优化：在索引阶段，通过语义增强分块和层次化索引确保语义完整性；在检索阶段，采用基于效用的过滤机制选择高质量信息并减少输入长度；在生成阶段，实现细粒度引用增强，检测响应中的意见句并进行句子级引用。作者开源了TrustRAG框架并提供演示工作室，旨在帮助研究者系统地提升RAG系统的可信度和开发更可靠的AI助手。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.13719v1",
      "published_date": "2025-02-19 13:45:27 UTC",
      "updated_date": "2025-02-19 13:45:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:53:32.357123"
    },
    {
      "arxiv_id": "2502.14013v1",
      "title": "Appeal prediction for AI up-scaled Images",
      "title_zh": "AI 增强分辨率图像的吸引力预测",
      "authors": [
        "Steve Göring",
        "Rasmus Merten",
        "Alexander Raake"
      ],
      "abstract": "DNN- or AI-based up-scaling algorithms are gaining in popularity due to the\nimprovements in machine learning. Various up-scaling models using CNNs, GANs or\nmixed approaches have been published. The majority of models are evaluated\nusing PSRN and SSIM or only a few example images. However, a performance\nevaluation with a wide range of real-world images and subjective evaluation is\nmissing, which we tackle in the following paper. For this reason, we describe\nour developed dataset, which uses 136 base images and five different up-scaling\nmethods, namely Real-ESRGAN, BSRGAN, waifu2x, KXNet, and Lanczos. Overall the\ndataset consists of 1496 annotated images. The labeling of our dataset focused\non image appeal and has been performed using crowd-sourcing employing our\nopen-source tool AVRate Voyager. We evaluate the appeal of the different\nmethods, and the results indicate that Real-ESRGAN and BSRGAN are the best.\nFurthermore, we train a DNN to detect which up-scaling method has been used,\nthe trained models have a good overall performance in our evaluation. In\naddition to this, we evaluate state-of-the-art image appeal and quality models,\nhere none of the models showed a high prediction performance, therefore we also\ntrained two own approaches. The first uses transfer learning and has the best\nperformance, and the second model uses signal-based features and a random\nforest model with good overall performance. We share the data and\nimplementation to allow further research in the context of open science.",
      "tldr_zh": "本研究评估了AI图像上采样算法的吸引力，解决现有方法（如使用PSNR和SSIM的评估）仅依赖少数示例图像的问题。研究者开发了一个数据集，包含136个基础图像和五种上采样方法（Real-ESRGAN、BSRGAN、waifu2x、KXNet和Lanczos），总计1496个通过众包工具AVRate Voyager标注的图像，结果显示Real-ESRGAN和BSRGAN在图像吸引力方面表现最佳。论文还训练了DNN模型来检测上采样方法，并开发了两个新模型（一个基于迁移学习，另一个使用信号特征和随机森林），这些模型的预测性能优于现有图像质量模型；最后，研究分享了数据和实现代码以推动开放科学。",
      "categories": [
        "cs.GR",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.GR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14013v1",
      "published_date": "2025-02-19 13:45:24 UTC",
      "updated_date": "2025-02-19 13:45:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:53:45.827140"
    },
    {
      "arxiv_id": "2502.15812v1",
      "title": "InsightVision: A Comprehensive, Multi-Level Chinese-based Benchmark for Evaluating Implicit Visual Semantics in Large Vision Language Models",
      "title_zh": "InsightVision：一个全面的、多",
      "authors": [
        "Xiaofei Yin",
        "Yijie Hong",
        "Ya Guo",
        "Yi Tu",
        "Weiqiang Wang",
        "Gongshen Liu",
        "Huijia zhu"
      ],
      "abstract": "In the evolving landscape of multimodal language models, understanding the\nnuanced meanings conveyed through visual cues - such as satire, insult, or\ncritique - remains a significant challenge. Existing evaluation benchmarks\nprimarily focus on direct tasks like image captioning or are limited to a\nnarrow set of categories, such as humor or satire, for deep semantic\nunderstanding. To address this gap, we introduce, for the first time, a\ncomprehensive, multi-level Chinese-based benchmark designed specifically for\nevaluating the understanding of implicit meanings in images. This benchmark is\nsystematically categorized into four subtasks: surface-level content\nunderstanding, symbolic meaning interpretation, background knowledge\ncomprehension, and implicit meaning comprehension. We propose an innovative\nsemi-automatic method for constructing datasets, adhering to established\nconstruction protocols. Using this benchmark, we evaluate 15 open-source large\nvision language models (LVLMs) and GPT-4o, revealing that even the\nbest-performing model lags behind human performance by nearly 14% in\nunderstanding implicit meaning. Our findings underscore the intrinsic\nchallenges current LVLMs face in grasping nuanced visual semantics,\nhighlighting significant opportunities for future research and development in\nthis domain. We will publicly release our InsightVision dataset, code upon\nacceptance of the paper.",
      "tldr_zh": "这篇论文引入了InsightVision，一个全面的多级中文基准，用于评估大型视觉语言模型(LVLMs)在理解图像隐含语义（如讽刺、侮辱或批评）方面的能力，以填补现有基准的局限性。基准分为四个子任务：表面级内容理解、象征意义解释、背景知识理解和隐含意义理解，并采用创新的半自动方法构建数据集。实验评估了15个开源LVLMs和GPT-4o，结果显示最佳模型在隐含意义理解上落后人类近14%，突显了当前模型在处理细微视觉语义时的固有挑战，并为未来研究提供了重要机遇。作者计划公开InsightVision数据集和代码。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "19 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.15812v1",
      "published_date": "2025-02-19 13:42:37 UTC",
      "updated_date": "2025-02-19 13:42:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:53:57.269313"
    },
    {
      "arxiv_id": "2502.15811v1",
      "title": "Spiking Point Transformer for Point Cloud Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Peixi Wu",
        "Bosong Chai",
        "Hebei Li",
        "Menghua Zheng",
        "Yansong Peng",
        "Zeyu Wang",
        "Xuan Nie",
        "Yueyi Zhang",
        "Xiaoyan Sun"
      ],
      "abstract": "Spiking Neural Networks (SNNs) offer an attractive and energy-efficient\nalternative to conventional Artificial Neural Networks (ANNs) due to their\nsparse binary activation. When SNN meets Transformer, it shows great potential\nin 2D image processing. However, their application for 3D point cloud remains\nunderexplored. To this end, we present Spiking Point Transformer (SPT), the\nfirst transformer-based SNN framework for point cloud classification.\nSpecifically, we first design Queue-Driven Sampling Direct Encoding for point\ncloud to reduce computational costs while retaining the most effective support\npoints at each time step. We introduce the Hybrid Dynamics Integrate-and-Fire\nNeuron (HD-IF), designed to simulate selective neuron activation and reduce\nover-reliance on specific artificial neurons. SPT attains state-of-the-art\nresults on three benchmark datasets that span both real-world and synthetic\ndatasets in the SNN domain. Meanwhile, the theoretical energy consumption of\nSPT is at least 6.4$\\times$ less than its ANN counterpart.",
      "tldr_zh": "该论文提出了 Spiking Point Transformer (SPT)，这是首个基于 Transformer 的 Spiking Neural Networks (SNNs) 框架，用于点云分类，以利用 SNNs 的稀疏二进制激活实现更高的能源效率。SPT 引入了 Queue-Driven Sampling Direct Encoding 方法来降低计算成本，同时保留每个时间步的最有效支持点，并设计了 Hybrid Dynamics Integrate-and-Fire Neuron (HD-IF) 来模拟选择性神经元激活，减少对特定神经元的过度依赖。在三个基准数据集上，SPT 达到了 SNN 领域的最先进结果，同时其理论能源消耗比 ANN 对应物低至少 6.4 倍。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.15811v1",
      "published_date": "2025-02-19 13:28:55 UTC",
      "updated_date": "2025-02-19 13:28:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:54:09.541098"
    },
    {
      "arxiv_id": "2502.13701v1",
      "title": "Causes and Strategies in Multiagent Systems",
      "title_zh": "多智能体系统中的原因和策略",
      "authors": [
        "Sylvia S. Kerkhove",
        "Natasha Alechina",
        "Mehdi Dastani"
      ],
      "abstract": "Causality plays an important role in daily processes, human reasoning, and\nartificial intelligence. There has however not been much research on causality\nin multi-agent strategic settings. In this work, we introduce a systematic way\nto build a multi-agent system model, represented as a concurrent game\nstructure, for a given structural causal model. In the obtained so-called\ncausal concurrent game structure, transitions correspond to interventions on\nagent variables of the given causal model. The Halpern and Pearl framework of\ncausality is used to determine the effects of a certain value for an agent\nvariable on other variables. The causal concurrent game structure allows us to\nanalyse and reason about causal effects of agents' strategic decisions. We\nformally investigate the relation between causal concurrent game structures and\nthe original structural causal models.",
      "tldr_zh": "本文探讨了因果关系（causality）在多智能体系统（multiagent systems）中的作用，指出现有研究在智能体战略环境中的不足。作者提出一种系统方法，将给定的结构因果模型（structural causal model）构建为因果并发游戏结构（causal concurrent game structure），其中转换对应于对智能体变量的干预（interventions），并利用 Halpern and Pearl framework 来评估变量值对其他变量的影响。该框架允许分析和推理智能体战略决策的因果效果，并正式调查因果并发游戏结构与原始结构因果模型之间的关系，为多智能体系统的因果推理提供新工具。",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at AAMAS 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.13701v1",
      "published_date": "2025-02-19 13:18:42 UTC",
      "updated_date": "2025-02-19 13:18:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:54:19.909760"
    },
    {
      "arxiv_id": "2502.13685v2",
      "title": "MoM: Linear Sequence Modeling with Mixture-of-Memories",
      "title_zh": "翻译失败",
      "authors": [
        "Jusen Du",
        "Weigao Sun",
        "Disen Lan",
        "Jiaxi Hu",
        "Yu Cheng"
      ],
      "abstract": "Linear sequence modeling methods, such as linear attention, state space\nmodeling, and linear RNNs, offer significant efficiency improvements by\nreducing the complexity of training and inference. However, these methods\ntypically compress the entire input sequence into a single fixed-size memory\nstate, which leads to suboptimal performance on recall-intensive downstream\ntasks. Drawing inspiration from neuroscience, particularly the brain's ability\nto maintain robust long-term memory while mitigating \"memory interference\", we\nintroduce a novel architecture called Mixture-of-Memories (MoM). MoM utilizes\nmultiple independent memory states, with a router network directing input\ntokens to specific memory states. This approach greatly enhances the overall\nmemory capacity while minimizing memory interference. As a result, MoM performs\nexceptionally well on recall-intensive tasks, surpassing existing linear\nsequence modeling techniques. Despite incorporating multiple memory states, the\ncomputation of each memory state remains linear in complexity, allowing MoM to\nretain the linear-complexity advantage during training, while\nconstant-complexity during inference. Our experimental results show that MoM\nsignificantly outperforms current linear sequence models on downstream language\ntasks, particularly recall-intensive tasks, and even achieves performance\ncomparable to Transformer models. The code is released at\nhttps://github.com/OpenSparseLLMs/MoM and is also released as a part of\nhttps://github.com/OpenSparseLLMs/Linear-MoE.",
      "tldr_zh": "该研究针对线性序列建模方法（如线性注意力、状态空间模型和线性RNNs）的效率优势，但其单一固定内存状态导致在回忆密集型任务上表现不佳的问题，提出了一种名为Mixture-of-Memories (MoM)的创新架构。MoM受神经科学启发，使用多个独立内存状态和一个路由网络来指导输入标记分配，从而增强整体内存容量并减少内存干扰，同时保持训练的线性复杂度和推理的常数复杂度。实验结果显示，MoM在下游语言任务中显著优于现有线性序列模型，尤其在回忆密集型任务上，甚至与Transformer模型的性能相当。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Technical report, 16 pages",
      "pdf_url": "http://arxiv.org/pdf/2502.13685v2",
      "published_date": "2025-02-19 12:53:55 UTC",
      "updated_date": "2025-05-06 13:11:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:54:32.100416"
    },
    {
      "arxiv_id": "2502.13681v2",
      "title": "An LLM-based Agent for Reliable Docker Environment Configuration",
      "title_zh": "翻译失败",
      "authors": [
        "Ruida Hu",
        "Chao Peng",
        "Xinchen Wang",
        "Cuiyun Gao"
      ],
      "abstract": "Environment configuration is a critical yet time-consuming step in software\ndevelopment, especially when dealing with unfamiliar code repositories. While\nLarge Language Models (LLMs) demonstrate the potential to accomplish software\nengineering tasks, existing methods for environment configuration often rely on\nmanual efforts or fragile scripts, leading to inefficiencies and unreliable\noutcomes. We introduce Repo2Run, the first LLM-based agent designed to fully\nautomate environment configuration and generate executable Dockerfiles for\narbitrary Python repositories. We address two major challenges: (1) enabling\nthe LLM agent to configure environments within isolated Docker containers, and\n(2) ensuring the successful configuration process is recorded and accurately\ntransferred to a Dockerfile without error. To achieve this, we propose atomic\nconfiguration synthesis, featuring a dual-environment architecture (internal\nand external environment) with a rollback mechanism to prevent environment\n\"pollution\" from failed commands, guaranteeing atomic execution (execute fully\nor not at all) and a Dockerfile generator to transfer successful configuration\nsteps into runnable Dockerfiles. We evaluate Repo2Run~on our proposed benchmark\nof 420 recent Python repositories with unit tests, where it achieves an 86.0%\nsuccess rate, outperforming the best baseline by 63.9%. Repo2Run is available\nat https://github.com/bytedance/Repo2Run.",
      "tldr_zh": "该研究针对软件开发中环境配置的低效问题，提出了一种基于LLM的代理Repo2Run，用于完全自动化任意Python仓库的环境配置并生成可执行Dockerfile。Repo2Run通过原子配置合成方法解决关键挑战，包括采用双环境架构（内部和外部环境）和回滚机制，以防止失败命令污染环境，并确保配置步骤准确转移到Dockerfile中。实验结果显示，在420个Python仓库基准测试中，Repo2Run的成功率达86.0%，比最佳基线高出63.9%，显著提升了配置的可靠性和效率。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.13681v2",
      "published_date": "2025-02-19 12:51:35 UTC",
      "updated_date": "2025-03-06 07:17:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:54:44.208982"
    },
    {
      "arxiv_id": "2502.14011v1",
      "title": "DFDT: Dynamic Fast Decision Tree for IoT Data Stream Mining on Edge Devices",
      "title_zh": "翻译失败",
      "authors": [
        "Afonso Lourenço",
        "João Rodrigo",
        "João Gama",
        "Goreti Marreiros"
      ],
      "abstract": "The Internet of Things generates massive data streams, with edge computing\nemerging as a key enabler for online IoT applications and 5G networks. Edge\nsolutions facilitate real-time machine learning inference, but also require\ncontinuous adaptation to concept drifts. Ensemble-based solutions improve\npredictive performance, but incur higher resource consumption, latency, and\nmemory demands. This paper presents DFDT: Dynamic Fast Decision Tree, a novel\nalgorithm designed for energy-efficient memory-constrained data stream mining.\nDFDT improves hoeffding tree growth efficiency by dynamically adjusting grace\nperiods, tie thresholds, and split evaluations based on incoming data. It\nincorporates stricter evaluation rules (based on entropy, information gain, and\nleaf instance count), adaptive expansion modes, and a leaf deactivation\nmechanism to manage memory, allowing more computation on frequently visited\nnodes while conserving energy on others. Experiments show that the proposed\nframework can achieve increased predictive performance (0.43 vs 0.29 ranking)\nwith constrained memory and a fraction of the runtime of VFDT or SVFDT.",
      "tldr_zh": "该论文提出 DFDT（Dynamic Fast Decision Tree），一种新型算法，用于在边缘设备上进行 IoT 数据流挖掘，旨在解决概念漂移带来的挑战，同时实现能量高效和内存受限优化。DFDT 通过动态调整宽限期（grace periods）、平局阈值（tie thresholds）和分裂评估，并结合基于熵（entropy）、信息增益（information gain）和叶子实例计数的严格规则、适应性扩展模式以及叶子停用机制，来提升 Hoeffding 树的增长效率和资源管理。实验结果显示，DFDT 在内存约束条件下，比 VFDT 或 SVFDT 实现了更高的预测性能（排名 0.43 vs 0.29），并显著减少运行时间，为边缘计算中的实时机器学习应用提供了高效解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14011v1",
      "published_date": "2025-02-19 12:45:42 UTC",
      "updated_date": "2025-02-19 12:45:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:54:56.870704"
    },
    {
      "arxiv_id": "2502.20411v1",
      "title": "Backpropagation-free Spiking Neural Networks with the Forward-Forward Algorithm",
      "title_zh": "翻译失败",
      "authors": [
        "Mohammadnavid Ghader",
        "Saeed Reza Kheradpisheh",
        "Bahar Farahani",
        "Mahmood Fazlali"
      ],
      "abstract": "Spiking Neural Networks (SNNs) offer a biologically inspired computational\nparadigm that emulates neuronal activity through discrete spike-based\nprocessing. Despite their advantages, training SNNs with traditional\nbackpropagation (BP) remains challenging due to computational inefficiencies\nand a lack of biological plausibility. This study explores the Forward-Forward\n(FF) algorithm as an alternative learning framework for SNNs. Unlike\nbackpropagation, which relies on forward and backward passes, the FF algorithm\nemploys two forward passes, enabling localized learning, enhanced computational\nefficiency, and improved compatibility with neuromorphic hardware. We introduce\nan FF-based SNN training framework and evaluate its performance across both\nnon-spiking (MNIST, Fashion-MNIST, CIFAR-10) and spiking (Neuro-MNIST, SHD)\ndatasets. Experimental results demonstrate that our model surpasses existing\nFF-based SNNs by over 5% on MNIST and Fashion-MNIST while achieving accuracy\ncomparable to state-of-the-art backpropagation-trained SNNs. On more complex\ntasks such as CIFAR-10 and SHD, our approach outperforms other SNN models by up\nto 6% and remains competitive with leading backpropagation-trained SNNs. These\nfindings highlight the FF algorithm's potential to advance SNN training\nmethodologies and neuromorphic computing by addressing key limitations of\nbackpropagation.",
      "tldr_zh": "本研究提出了一种基于 Forward-Forward Algorithm 的无 Backpropagation SNNs（Spiking Neural Networks）训练框架，以解决传统 Backpropagation 在计算效率和生物可行性方面的挑战。该框架利用两个前向传递实现本地化学习、提升计算效率，并增强与 neuromorphic hardware 的兼容性。在实验中，该方法在 MNIST 和 Fashion-MNIST 数据集上比现有 FF-based SNNs 提高超过 5% 的准确率，并在 CIFAR-10 和 SHD 数据集上比其他 SNN 模型高出高达 6%，与顶级 Backpropagation-trained SNNs 性能相当。这些结果证明了 Forward-Forward Algorithm 在推进 SNN 训练方法和神经形态计算方面的潜力。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.20411v1",
      "published_date": "2025-02-19 12:44:26 UTC",
      "updated_date": "2025-02-19 12:44:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:55:10.294049"
    },
    {
      "arxiv_id": "2502.15810v1",
      "title": "Zero-Shot Commonsense Validation and Reasoning with Large Language Models: An Evaluation on SemEval-2020 Task 4 Dataset",
      "title_zh": "翻译失败",
      "authors": [
        "Rawand Alfugaha",
        "Mohammad AL-Smadi"
      ],
      "abstract": "This study evaluates the performance of Large Language Models (LLMs) on\nSemEval-2020 Task 4 dataset, focusing on commonsense validation and\nexplanation. Our methodology involves evaluating multiple LLMs, including\nLLaMA3-70B, Gemma2-9B, and Mixtral-8x7B, using zero-shot prompting techniques.\nThe models are tested on two tasks: Task A (Commonsense Validation), where\nmodels determine whether a statement aligns with commonsense knowledge, and\nTask B (Commonsense Explanation), where models identify the reasoning behind\nimplausible statements. Performance is assessed based on accuracy, and results\nare compared to fine-tuned transformer-based models. The results indicate that\nlarger models outperform previous models and perform closely to human\nevaluation for Task A, with LLaMA3-70B achieving the highest accuracy of 98.40%\nin Task A whereas, lagging behind previous models with 93.40% in Task B.\nHowever, while models effectively identify implausible statements, they face\nchallenges in selecting the most relevant explanation, highlighting limitations\nin causal and inferential reasoning.",
      "tldr_zh": "这篇论文评估了大型语言模型 (LLMs) 在 SemEval-2020 Task 4 数据集上的零-shot 常识验证和解释性能，使用 LLaMA3-70B、Gemma2-9B 和 Mixtral-8x7B 等模型进行测试。研究聚焦于 Task A (Commonsense Validation)，模型需判断语句是否符合常识，以及 Task B (Commonsense Explanation)，模型需识别不合理语句的推理原因。结果显示，LLaMA3-70B 在 Task A 上达到 98.40% 的准确率，接近人类水平，但整体在 Task B 上表现落后于 fine-tuned 模型，仅为 93.40%。该研究突显了 LLMs 在因果和推理方面的局限性，尽管它们在识别 implausible 语句方面表现出色。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.15810v1",
      "published_date": "2025-02-19 12:40:49 UTC",
      "updated_date": "2025-02-19 12:40:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:55:22.889027"
    },
    {
      "arxiv_id": "2502.14010v1",
      "title": "Which Attention Heads Matter for In-Context Learning?",
      "title_zh": "翻译失败",
      "authors": [
        "Kayo Yin",
        "Jacob Steinhardt"
      ],
      "abstract": "Large language models (LLMs) exhibit impressive in-context learning (ICL)\ncapability, enabling them to perform new tasks using only a few demonstrations\nin the prompt. Two different mechanisms have been proposed to explain ICL:\ninduction heads that find and copy relevant tokens, and function vector (FV)\nheads whose activations compute a latent encoding of the ICL task. To better\nunderstand which of the two distinct mechanisms drives ICL, we study and\ncompare induction heads and FV heads in 12 language models.\n  Through detailed ablations, we discover that few-shot ICL performance depends\nprimarily on FV heads, especially in larger models. In addition, we uncover\nthat FV and induction heads are connected: many FV heads start as induction\nheads during training before transitioning to the FV mechanism. This leads us\nto speculate that induction facilitates learning the more complex FV mechanism\nthat ultimately drives ICL.",
      "tldr_zh": "这篇论文探讨了大语言模型 (LLMs) 中的 attention heads 如何影响 in-context learning (ICL)，通过比较 induction heads 和 function vector (FV) heads 来解释 ICL 机制。研究者在 12 个语言模型上进行详细的 ablations 实验，发现 few-shot ICL 性能主要依赖于 FV heads，尤其在更大模型中。进一步发现，FV heads 往往从 induction heads 演变而来，并推测 induction heads 可能促进学习更复杂的 FV 机制，从而驱动 ICL。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14010v1",
      "published_date": "2025-02-19 12:25:02 UTC",
      "updated_date": "2025-02-19 12:25:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:55:33.264835"
    },
    {
      "arxiv_id": "2502.13668v1",
      "title": "PeerQA: A Scientific Question Answering Dataset from Peer Reviews",
      "title_zh": "翻译失败",
      "authors": [
        "Tim Baumgärtner",
        "Ted Briscoe",
        "Iryna Gurevych"
      ],
      "abstract": "We present PeerQA, a real-world, scientific, document-level Question\nAnswering (QA) dataset. PeerQA questions have been sourced from peer reviews,\nwhich contain questions that reviewers raised while thoroughly examining the\nscientific article. Answers have been annotated by the original authors of each\npaper. The dataset contains 579 QA pairs from 208 academic articles, with a\nmajority from ML and NLP, as well as a subset of other scientific communities\nlike Geoscience and Public Health. PeerQA supports three critical tasks for\ndeveloping practical QA systems: Evidence retrieval, unanswerable question\nclassification, and answer generation. We provide a detailed analysis of the\ncollected dataset and conduct experiments establishing baseline systems for all\nthree tasks. Our experiments and analyses reveal the need for\ndecontextualization in document-level retrieval, where we find that even simple\ndecontextualization approaches consistently improve retrieval performance\nacross architectures. On answer generation, PeerQA serves as a challenging\nbenchmark for long-context modeling, as the papers have an average size of 12k\ntokens. Our code and data is available at https://github.com/UKPLab/peerqa.",
      "tldr_zh": "本文提出 PeerQA 数据集，这是一个基于真实同行评审的科学文档级 Question Answering (QA) 数据集，包含 579 个 QA 对，来源于 208 篇学术论文，主要覆盖 Machine Learning (ML) 和 Natural Language Processing (NLP) 等领域，以及地质科学和公共卫生等子集。数据集支持三个关键任务：证据检索、unanswerable question 分类和答案生成，通过实验建立基线系统并证明去上下文化(decontextualization)方法能显著提升检索性能。PeerQA 作为长上下文建模的挑战性基准，论文平均长度达 12k tokens，并提供开源代码以促进进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at NAACL 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.13668v1",
      "published_date": "2025-02-19 12:24:46 UTC",
      "updated_date": "2025-02-19 12:24:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:55:45.397756"
    },
    {
      "arxiv_id": "2503.16451v1",
      "title": "Think-Then-React: Towards Unconstrained Human Action-to-Reaction Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Wenhui Tan",
        "Boyuan Li",
        "Chuhao Jin",
        "Wenbing Huang",
        "Xiting Wang",
        "Ruihua Song"
      ],
      "abstract": "Modeling human-like action-to-reaction generation has significant real-world\napplications, like human-robot interaction and games. Despite recent\nadvancements in single-person motion generation, it is still challenging to\nwell handle action-to-reaction generation, due to the difficulty of directly\npredicting reaction from action sequence without prompts, and the absence of a\nunified representation that effectively encodes multi-person motion. To address\nthese challenges, we introduce Think-Then-React (TTR), a large\nlanguage-model-based framework designed to generate human-like reactions.\nFirst, with our fine-grained multimodal training strategy, TTR is capable to\nunify two processes during inference: a thinking process that explicitly infers\naction intentions and reasons corresponding reaction description, which serve\nas semantic prompts, and a reacting process that predicts reactions based on\ninput action and the inferred semantic prompts. Second, to effectively\nrepresent multi-person motion in language models, we propose a unified motion\ntokenizer by decoupling egocentric pose and absolute space features, which\neffectively represents action and reaction motion with same encoding. Extensive\nexperiments demonstrate that TTR outperforms existing baselines, achieving\nsignificant improvements in evaluation metrics, such as reducing FID from 3.988\nto 1.942.",
      "tldr_zh": "该研究提出Think-Then-React (TTR)框架，利用大型语言模型生成人类般的动作到反应序列，解决直接预测反应和多人物动作表示的挑战。TTR通过细粒度多模态训练策略，将推理过程分为“思考”阶段（推断动作意图并生成语义提示）和“反应”阶段（基于输入动作和提示预测反应），并引入统一动作标记器来分离自我中心姿势和绝对空间特征，从而有效编码多人物动作。实验结果显示，TTR显著优于现有基线模型，将FID指标从3.988降低至1.942，在人机交互和游戏应用中展现出更高的生成质量。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.HC",
      "comment": "Accepted by ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.16451v1",
      "published_date": "2025-02-19 12:14:38 UTC",
      "updated_date": "2025-02-19 12:14:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:55:56.685949"
    },
    {
      "arxiv_id": "2502.14008v1",
      "title": "MaskPrune: Mask-based LLM Pruning for Layer-wise Uniform Structures",
      "title_zh": "翻译失败",
      "authors": [
        "Jiayu Qin",
        "Jianchao Tan",
        "Kefeng Zhang",
        "Xunliang Cai",
        "Wei Wang"
      ],
      "abstract": "The remarkable performance of large language models (LLMs) in various\nlanguage tasks has attracted considerable attention. However, the\never-increasing size of these models presents growing challenges for deployment\nand inference. Structured pruning, an effective model compression technique, is\ngaining increasing attention due to its ability to enhance inference\nefficiency. Nevertheless, most previous optimization-based structured pruning\nmethods sacrifice the uniform structure across layers for greater flexibility\nto maintain performance. The heterogeneous structure hinders the effective\nutilization of off-the-shelf inference acceleration techniques and impedes\nefficient configuration for continued training. To address this issue, we\npropose a novel masking learning paradigm based on minimax optimization to\nobtain the uniform pruned structure by optimizing the masks under sparsity\nregularization. Extensive experimental results demonstrate that our method can\nmaintain high performance while ensuring the uniformity of the pruned model\nstructure, thereby outperforming existing SOTA methods.",
      "tldr_zh": "大型语言模型 (LLMs) 的大小导致部署和推理效率低下，而现有的结构化剪枝方法虽能压缩模型，但往往牺牲层间均匀结构，影响加速技术和后续训练。该论文提出 MaskPrune，一种基于掩码学习的 LLM 剪枝方法，通过最小最大优化 (minimax optimization) 和稀疏性正则化 (sparsity regularization) 来优化掩码，确保剪枝后模型的层间均匀结构。实验结果显示，MaskPrune 在保持高性能的同时，超过了现有最先进 (SOTA) 方法，为高效模型压缩提供了新途径。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14008v1",
      "published_date": "2025-02-19 11:57:31 UTC",
      "updated_date": "2025-02-19 11:57:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:56:09.381480"
    },
    {
      "arxiv_id": "2502.13652v1",
      "title": "C2T: A Classifier-Based Tree Construction Method in Speculative Decoding",
      "title_zh": "翻译失败",
      "authors": [
        "Feiye Huo",
        "Jianchao Tan",
        "Kefeng Zhang",
        "Xunliang Cai",
        "Shengli Sun"
      ],
      "abstract": "The growing scale of Large Language Models (LLMs) has exacerbated inference\nlatency and computational costs. Speculative decoding methods, which aim to\nmitigate these issues, often face inefficiencies in the construction of token\ntrees and the verification of candidate tokens. Existing strategies, including\nchain mode, static tree, and dynamic tree approaches, have limitations in\naccurately preparing candidate token trees for verification. We propose a novel\nmethod named C2T that adopts a lightweight classifier to generate and prune\ntoken trees dynamically. Our classifier considers additional feature variables\nbeyond the commonly used joint probability to predict the confidence score for\neach draft token to determine whether it is the candidate token for\nverification. This method outperforms state-of-the-art (SOTA) methods such as\nEAGLE-2 on multiple benchmarks, by reducing the total number of candidate\ntokens by 25% while maintaining or even improving the acceptance length.",
      "tldr_zh": "该研究针对Large Language Models (LLMs)的推理延迟和计算成本问题，提出了一种名为C2T的创新方法，用于优化推测解码中的令牌树构建。C2T采用一个轻量级分类器，基于超出传统联合概率的额外特征变量动态生成和修剪令牌树，从而更准确地预测草稿令牌的置信度分数并筛选候选令牌。在多个基准测试中，C2T优于SOTA方法如EAGLE-2，能将候选令牌总数减少25%，同时维持或提升接受长度。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.13652v1",
      "published_date": "2025-02-19 11:57:02 UTC",
      "updated_date": "2025-02-19 11:57:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:56:19.995463"
    },
    {
      "arxiv_id": "2502.14007v1",
      "title": "d-Sketch: Improving Visual Fidelity of Sketch-to-Image Translation with Pretrained Latent Diffusion Models without Retraining",
      "title_zh": "翻译失败",
      "authors": [
        "Prasun Roy",
        "Saumik Bhattacharya",
        "Subhankar Ghosh",
        "Umapada Pal",
        "Michael Blumenstein"
      ],
      "abstract": "Structural guidance in an image-to-image translation allows intricate control\nover the shapes of synthesized images. Generating high-quality realistic images\nfrom user-specified rough hand-drawn sketches is one such task that aims to\nimpose a structural constraint on the conditional generation process. While the\npremise is intriguing for numerous use cases of content creation and academic\nresearch, the problem becomes fundamentally challenging due to substantial\nambiguities in freehand sketches. Furthermore, balancing the trade-off between\nshape consistency and realistic generation contributes to additional complexity\nin the process. Existing approaches based on Generative Adversarial Networks\n(GANs) generally utilize conditional GANs or GAN inversions, often requiring\napplication-specific data and optimization objectives. The recent introduction\nof Denoising Diffusion Probabilistic Models (DDPMs) achieves a generational\nleap for low-level visual attributes in general image synthesis. However,\ndirectly retraining a large-scale diffusion model on a domain-specific subtask\nis often extremely difficult due to demanding computation costs and\ninsufficient data. In this paper, we introduce a technique for sketch-to-image\ntranslation by exploiting the feature generalization capabilities of a\nlarge-scale diffusion model without retraining. In particular, we use a\nlearnable lightweight mapping network to achieve latent feature translation\nfrom source to target domain. Experimental results demonstrate that the\nproposed method outperforms the existing techniques in qualitative and\nquantitative benchmarks, allowing high-resolution realistic image synthesis\nfrom rough hand-drawn sketches.",
      "tldr_zh": "该论文提出了 d-Sketch 方法，通过利用预训练的 Latent Diffusion Models 实现草图到图像翻译的视觉保真度提升，而无需重新训练模型。核心技术涉及一个可学习的轻量级映射网络，用于潜在特征从源域到目标域的翻译，以解决手绘草图的模糊性和形状一致性与真实生成之间的权衡问题。与基于 GANs 的现有方法相比，该方法避免了特定数据和计算成本的限制。实验结果显示，d-Sketch 在定性和定量基准上表现出色，能够从粗糙手绘草图生成高质量、高分辨率的真实图像。",
      "categories": [
        "cs.GR",
        "cs.AI",
        "cs.CV",
        "cs.MM",
        "eess.IV"
      ],
      "primary_category": "cs.GR",
      "comment": "Accepted in The International Conference on Pattern Recognition\n  (ICPR) 2024",
      "pdf_url": "http://arxiv.org/pdf/2502.14007v1",
      "published_date": "2025-02-19 11:54:45 UTC",
      "updated_date": "2025-02-19 11:54:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:56:32.965210"
    },
    {
      "arxiv_id": "2502.13638v1",
      "title": "Integrating Inverse and Forward Modeling for Sparse Temporal Data from Sensor Networks",
      "title_zh": "整合逆向和正向建模，用于传感器网络的稀疏时序数据",
      "authors": [
        "Julian Vexler",
        "Björn Vieten",
        "Martin Nelke",
        "Stefan Kramer"
      ],
      "abstract": "We present CavePerception, a framework for the analysis of sparse data from\nsensor networks that incorporates elements of inverse modeling and forward\nmodeling. By integrating machine learning with physical modeling in a\nhypotheses space, we aim to improve the interpretability of sparse, noisy, and\npotentially incomplete sensor data. The framework assumes data from a\ntwo-dimensional sensor network laid out in a graph structure that detects\ncertain objects, with certain motion patterns. Examples of such sensors are\nmagnetometers. Given knowledge about the objects and the way they act on the\nsensors, one can develop a data generator that produces data from simulated\nmotions of the objects across the sensor field. The framework uses the\nsimulated data to infer object behaviors across the sensor network. The\napproach is experimentally tested on real-world data, where magnetometers are\nused on an airport to detect and identify aircraft motions. Experiments\ndemonstrate the value of integrating inverse and forward modeling, enabling\nintelligent systems to better understand and predict complex, sensor-driven\nevents.",
      "tldr_zh": "该研究提出CavePerception框架，用于分析传感器网络的稀疏时间数据，通过整合inverse modeling和forward modeling来提升数据的可解释性。框架将机器学习与物理建模结合在一个假设空间中，利用模拟数据生成器基于物体运动模拟数据来推断物体行为，例如在二维图结构传感器网络中检测磁力计等设备捕获的运动模式。在真实世界实验中，该框架应用于机场磁力计数据，成功检测和识别飞机运动，并证明了这种整合方法能帮助智能系统更好地理解和预测复杂的传感器驱动事件。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.13638v1",
      "published_date": "2025-02-19 11:24:51 UTC",
      "updated_date": "2025-02-19 11:24:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:56:44.194307"
    },
    {
      "arxiv_id": "2503.05734v1",
      "title": "Modeling Behavior Change for Multi-model At-Risk Students Early Prediction (extended version)",
      "title_zh": "翻译失败",
      "authors": [
        "Jiabei Cheng",
        "Zhen-Qun Yang",
        "Jiannong Cao",
        "Yu Yang",
        "Kai Cheung Franky Poon",
        "Daniel Lai"
      ],
      "abstract": "In the educational domain, identifying students at risk of dropping out is\nessential for allowing educators to intervene effectively, improving both\nacademic outcomes and overall student well-being. Data in educational settings\noften originate from diverse sources, such as assignments, grades, and\nattendance records. However, most existing research relies on online learning\ndata and just extracting the quantitative features. While quantification eases\nprocessing, it also leads to a significant loss of original information.\nMoreover, current models primarily identify students with consistently poor\nperformance through simple and discrete behavioural patterns, failing to\ncapture the complex continuity and non-linear changes in student behaviour. We\nhave developed an innovative prediction model, Multimodal- ChangePoint\nDetection (MCPD), utilizing the textual teacher remark data and numerical grade\ndata from middle schools. Our model achieves a highly integrated and\nintelligent analysis by using independent encoders to process two data types,\nfusing the encoded feature. The model further refines its analysis by\nleveraging a changepoint detection module to pinpoint crucial behavioral\nchanges, which are integrated as dynamic weights through a simple attention\nmechanism. Experimental validations indicate that our model achieves an\naccuracy range of 70- 75%, with an average outperforming baseline algorithms by\napproximately 5-10%. Additionally, our algorithm demonstrates a certain degree\nof transferability, maintaining high accuracy when adjusted and retrained with\ndifferent definitions of at-risk, proving its broad applicability.",
      "tldr_zh": "这篇论文针对教育领域识别辍学风险学生的早期预测问题，提出了一种创新模型 Multimodal- ChangePoint Detection (MCPD)，它整合文本教师备注数据和数字成绩数据，通过独立编码器处理两种数据类型、融合特征，并利用 changepoint detection 模块检测关键行为变化，再通过注意力机制整合动态权重，以捕捉学生行为的复杂连续性和非线性变化。相比现有研究，该模型克服了量化特征信息损失的局限性，并在中学数据上实现了70-75%的准确率，比基线算法高出5-10%。此外，MCPD 展示了良好的可转移性，能够在不同辍学风险定义下调整和重新训练后保持高性能。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.05734v1",
      "published_date": "2025-02-19 11:16:46 UTC",
      "updated_date": "2025-02-19 11:16:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:56:57.411016"
    },
    {
      "arxiv_id": "2502.13632v1",
      "title": "Concept Layers: Enhancing Interpretability and Intervenability via LLM Conceptualization",
      "title_zh": "Concept",
      "authors": [
        "Or Raphael Bidusa",
        "Shaul Markovitch"
      ],
      "abstract": "The opaque nature of Large Language Models (LLMs) has led to significant\nresearch efforts aimed at enhancing their interpretability, primarily through\npost-hoc methods. More recent in-hoc approaches, such as Concept Bottleneck\nModels (CBMs), offer both interpretability and intervenability by incorporating\nexplicit concept representations. However, these methods suffer from key\nlimitations, including reliance on labeled concept datasets and significant\narchitectural modifications that challenges re-integration into existing system\npipelines. In this work, we introduce a new methodology for incorporating\ninterpretability and intervenability into an existing model by integrating\nConcept Layers (CLs) into its architecture. Our approach projects the model's\ninternal vector representations into a conceptual, explainable vector space\nbefore reconstructing and feeding them back into the model. Furthermore, we\neliminate the need for a human-selected concept set by algorithmically\nsearching an ontology for a set of concepts that can be either task-specific or\ntask-agnostic. We evaluate CLs across multiple tasks, demonstrating that they\nmaintain the original model's performance and agreement while enabling\nmeaningful interventions. Additionally, we present a proof of concept\nshowcasing an intervenability interface, allowing users to adjust model\nbehavior dynamically, such as mitigating biases during inference.",
      "tldr_zh": "本研究针对大型语言模型(LLMs)的不透明性问题，提出了一种新方法——Concept Layers (CLs)，通过将模型的内部向量表示投影到概念化的可解释向量空间，并重建反馈到模型中，从而增强LLMs的可解释性和可干预性。不同于依赖标记概念数据集和架构修改的Concept Bottleneck Models (CBMs)，该方法利用算法在本体(ontology)中搜索任务特定或任务无关的概念集，消除了对人类选择的依赖。在多个任务上的评估显示，CLs 保持了原模型的性能和一致性，同时支持动态干预，如通过用户界面缓解模型偏差，提供了一个可操作的证明概念。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.13632v1",
      "published_date": "2025-02-19 11:10:19 UTC",
      "updated_date": "2025-02-19 11:10:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:57:08.485430"
    },
    {
      "arxiv_id": "2502.13622v2",
      "title": "REFIND at SemEval-2025 Task 3: Retrieval-Augmented Factuality Hallucination Detection in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "DongGeon Lee",
        "Hwanjo Yu"
      ],
      "abstract": "Hallucinations in large language model (LLM) outputs severely limit their\nreliability in knowledge-intensive tasks such as question answering. To address\nthis challenge, we introduce REFIND (Retrieval-augmented Factuality\nhallucINation Detection), a novel framework that detects hallucinated spans\nwithin LLM outputs by directly leveraging retrieved documents. As part of the\nREFIND, we propose the Context Sensitivity Ratio (CSR), a novel metric that\nquantifies the sensitivity of LLM outputs to retrieved evidence. This\ninnovative approach enables REFIND to efficiently and accurately detect\nhallucinations, setting it apart from existing methods. In the evaluation,\nREFIND demonstrated robustness across nine languages, including low-resource\nsettings, and significantly outperformed baseline models, achieving superior\nIoU scores in identifying hallucinated spans. This work highlights the\neffectiveness of quantifying context sensitivity for hallucination detection,\nthereby paving the way for more reliable and trustworthy LLM applications\nacross diverse languages. Our code is available at\nhttps://github.com/oneonlee/REFIND.",
      "tldr_zh": "本研究引入了 REFIND 框架，用于检测大型语言模型 (LLM) 输出中的幻觉问题，通过检索增强 (Retrieval-augmented) 技术直接利用检索文档识别幻觉片段。REFIND 提出了一种新指标 Context Sensitivity Ratio (CSR)，用于量化 LLM 输出对检索证据的敏感性，从而提高检测的效率和准确性。在 SemEval-2025 Task 3 的评估中，REFIND 在九种语言（包括低资源设置）上表现出色，IoU 分数显著优于基线模型，为构建更可靠的跨语言 LLM 应用奠定了基础。代码已开源，可在 GitHub 上获取。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to SemEval@ACL 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.13622v2",
      "published_date": "2025-02-19 10:59:05 UTC",
      "updated_date": "2025-04-08 08:17:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:57:20.920242"
    },
    {
      "arxiv_id": "2502.13621v1",
      "title": "Decentralized Planning Using Probabilistic Hyperproperties",
      "title_zh": "翻译失败",
      "authors": [
        "Francesco Pontiggia",
        "Filip Macák",
        "Roman Andriushchenko",
        "Michele Chiari",
        "Milan Češka"
      ],
      "abstract": "Multi-agent planning under stochastic dynamics is usually formalised using\ndecentralized (partially observable) Markov decision processes ( MDPs) and\nreachability or expected reward specifications. In this paper, we propose a\ndifferent approach: we use an MDP describing how a single agent operates in an\nenvironment and probabilistic hyperproperties to capture desired temporal\nobjectives for a set of decentralized agents operating in the environment. We\nextend existing approaches for model checking probabilistic hyperproperties to\nhandle temporal formulae relating paths of different agents, thus requiring the\nself-composition between multiple MDPs. Using several case studies, we\ndemonstrate that our approach provides a flexible and expressive framework to\nbroaden the specification capabilities with respect to existing planning\ntechniques. Additionally, we establish a close connection between a subclass of\nprobabilistic hyperproperties and planning for a particular type of Dec-MDPs,\nfor both of which we show undecidability. This lays the ground for the use of\nexisting decentralized planning tools in the field of probabilistic\nhyperproperty verification.",
      "tldr_zh": "本论文提出了一种新方法，用于处理随机动态下的多智能体规划问题，通过使用单个代理的Markov决策过程(MDPs)和概率超属性(probabilistic hyperproperties)来定义分散式代理的临时目标，从而扩展了现有模型检查技术以处理涉及不同代理路径的临时公式。作者通过多个MDPs的自组合，实现了对这些公式的验证。实验案例研究表明，该框架比传统规划技术更灵活且更具表现力；此外，论文建立了概率超属性子类与特定类型分散式MDPs(Dec-MDPs)的紧密联系，并证明了其不可判定性，为将现有分散式规划工具应用于概率超属性验证奠定了基础。",
      "categories": [
        "cs.LO",
        "cs.AI"
      ],
      "primary_category": "cs.LO",
      "comment": "11 pages, 1 figure, 2 tables. Accepted at AAMAS 2025: the 24th\n  International Conference on Autonomous Agents and Multiagent Systems",
      "pdf_url": "http://arxiv.org/pdf/2502.13621v1",
      "published_date": "2025-02-19 10:59:02 UTC",
      "updated_date": "2025-02-19 10:59:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:57:31.675382"
    },
    {
      "arxiv_id": "2502.13619v1",
      "title": "Complex Ontology Matching with Large Language Model Embeddings",
      "title_zh": "翻译失败",
      "authors": [
        "Guilherme Sousa",
        "Rinaldo Lima",
        "Cassia Trojahn"
      ],
      "abstract": "Ontology, and more broadly, Knowledge Graph Matching is a challenging task in\nwhich expressiveness has not been fully addressed. Despite the increasing use\nof embeddings and language models for this task, approaches for generating\nexpressive correspondences still do not take full advantage of these models, in\nparticular, large language models (LLMs). This paper proposes to integrate LLMs\ninto an approach for generating expressive correspondences based on alignment\nneed and ABox-based relation discovery. The generation of correspondences is\nperformed by matching similar surroundings of instance sub-graphs. The\nintegration of LLMs results in different architectural modifications, including\nlabel similarity, sub-graph matching, and entity matching. The performance word\nembeddings, sentence embeddings, and LLM-based embeddings, was compared. The\nresults demonstrate that integrating LLMs surpasses all other models, enhancing\nthe baseline version of the approach with a 45\\% increase in F-measure.",
      "tldr_zh": "该论文针对本体（Ontology）和知识图谱匹配任务的表达性挑战，提出了一种整合大型语言模型（LLMs）的创新方法，以生成更精确的表达性对应关系。该方法基于对齐需求和ABox-based关系发现，通过匹配实例子图的相似环境，并对架构进行修改，包括标签相似性、子图匹配和实体匹配。实验结果显示，使用LLM-based嵌入的方案比基线模型提高了45%的F-measure，超越了词嵌入和句子嵌入的表现。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.13619v1",
      "published_date": "2025-02-19 10:56:27 UTC",
      "updated_date": "2025-02-19 10:56:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:57:43.194059"
    },
    {
      "arxiv_id": "2502.13606v1",
      "title": "LaVCa: LLM-assisted Visual Cortex Captioning",
      "title_zh": "翻译失败",
      "authors": [
        "Takuya Matsuyama",
        "Shinji Nishimoto",
        "Yu Takagi"
      ],
      "abstract": "Understanding the property of neural populations (or voxels) in the human\nbrain can advance our comprehension of human perceptual and cognitive\nprocessing capabilities and contribute to developing brain-inspired computer\nmodels. Recent encoding models using deep neural networks (DNNs) have\nsuccessfully predicted voxel-wise activity. However, interpreting the\nproperties that explain voxel responses remains challenging because of the\nblack-box nature of DNNs. As a solution, we propose LLM-assisted Visual Cortex\nCaptioning (LaVCa), a data-driven approach that uses large language models\n(LLMs) to generate natural-language captions for images to which voxels are\nselective. By applying LaVCa for image-evoked brain activity, we demonstrate\nthat LaVCa generates captions that describe voxel selectivity more accurately\nthan the previously proposed method. Furthermore, the captions generated by\nLaVCa quantitatively capture more detailed properties than the existing method\nat both the inter-voxel and intra-voxel levels. Furthermore, a more detailed\nanalysis of the voxel-specific properties generated by LaVCa reveals\nfine-grained functional differentiation within regions of interest (ROIs) in\nthe visual cortex and voxels that simultaneously represent multiple distinct\nconcepts. These findings offer profound insights into human visual\nrepresentations by assigning detailed captions throughout the visual cortex\nwhile highlighting the potential of LLM-based methods in understanding brain\nrepresentations. Please check out our webpage at\nhttps://sites.google.com/view/lavca-llm/",
      "tldr_zh": "该研究提出LaVCa，一种使用大型语言模型(LLMs)辅助的视觉皮层描述方法，旨在解决深度神经网络(DNNs)编码模型的黑箱问题，从而更好地解释大脑voxels的响应特性。LaVCa通过为voxels选择性的图像生成自然语言描述，比现有方法更准确地捕捉inter-voxel和intra-voxel层面的细节。实验结果显示，该方法揭示了视觉皮层中感兴趣区域(ROIs)的精细功能差异，以及voxels同时代表多个概念，为理解人类视觉表征和开发脑启发模型提供了深刻洞见。",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "q-bio.NC",
      "comment": "33 pages",
      "pdf_url": "http://arxiv.org/pdf/2502.13606v1",
      "published_date": "2025-02-19 10:37:04 UTC",
      "updated_date": "2025-02-19 10:37:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:57:56.396333"
    },
    {
      "arxiv_id": "2502.13603v2",
      "title": "Efficient Safety Retrofitting Against Jailbreaking for LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Dario Garcia-Gasulla",
        "Adrian Tormos",
        "Anna Arias-Duart",
        "Daniel Hinjos",
        "Oscar Molina-Sedano",
        "Ashwin Kumar Gururajan",
        "Maria Eugenia Cardello"
      ],
      "abstract": "Direct Preference Optimization (DPO) is an efficient alignment technique that\nsteers LLMs towards preferable outputs by training on preference data,\nbypassing the need for explicit reward models. Its simplicity enables easy\nadaptation to various domains and safety requirements. This paper examines\nDPO's effectiveness in model safety against jailbreaking attacks while\nminimizing data requirements and training costs. We introduce Egida, a dataset\nexpanded from multiple sources, which includes 27 different safety topics and\n18 different attack styles, complemented with synthetic and human labels. This\ndata is used to boost the safety of state-of-the-art LLMs\n(Llama-3.1-8B/70B-Instruct, Qwen-2.5-7B/72B-Instruct) across topics and attack\nstyles. In addition to safety evaluations, we assess their post-alignment\nperformance degradation in general purpose tasks, and their tendency to over\nrefusal. Following the proposed methodology, trained models reduce their Attack\nSuccess Rate by 10%-30%, using small training efforts (2,000 samples) with low\ncomputational cost (3\\$ for 8B models, 20\\$ for 72B models). Safety aligned\nmodels generalize to unseen topics and attack styles, with the most successful\nattack style reaching a success rate around 5%. Size and family are found to\nstrongly influence model malleability towards safety, pointing at the\nimportance of pre-training choices. To validate our findings, a large\nindependent assessment of human preference agreement with Llama-Guard-3-8B is\nconducted by the authors and the associated dataset Egida-HSafe is released.\nOverall, this study illustrates how affordable and accessible it is to enhance\nLLM safety using DPO while outlining its current limitations. All datasets and\nmodels are released to enable reproducibility and further research.",
      "tldr_zh": "本论文探讨了 Direct Preference Optimization (DPO) 作为一种高效的对齐技术，用于提升大型语言模型 (LLMs) 的安全性，以抵抗越狱攻击 (jailbreaking)，同时最小化数据和训练成本。研究引入了 Egida 数据集，该数据集涵盖27个安全主题和18种攻击风格，并通过合成和人类标签对模型如 Llama-3.1-8B/70B-Instruct 和 Qwen-2.5-7B/72B-Instruct 进行安全增强。实验结果显示，训练后模型的攻击成功率降低了10%-30%，使用仅2000个样本和低成本（8B模型约3美元，72B模型约20美元），并在未见主题和攻击风格上实现了泛化，成功率最低约5%；此外，模型大小和家族对安全可塑性有显著影响。作者发布了所有数据集和模型，以促进再现性和进一步研究，并突出了DPO的局限性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.13603v2",
      "published_date": "2025-02-19 10:33:18 UTC",
      "updated_date": "2025-02-25 12:06:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:58:10.227023"
    },
    {
      "arxiv_id": "2502.13595v2",
      "title": "MMTEB: Massive Multilingual Text Embedding Benchmark",
      "title_zh": "MMTEB：大规模多语言文本嵌入基准测试",
      "authors": [
        "Kenneth Enevoldsen",
        "Isaac Chung",
        "Imene Kerboua",
        "Márton Kardos",
        "Ashwin Mathur",
        "David Stap",
        "Jay Gala",
        "Wissam Siblini",
        "Dominik Krzemiński",
        "Genta Indra Winata",
        "Saba Sturua",
        "Saiteja Utpala",
        "Mathieu Ciancone",
        "Marion Schaeffer",
        "Gabriel Sequeira",
        "Diganta Misra",
        "Shreeya Dhakal",
        "Jonathan Rystrøm",
        "Roman Solomatin",
        "Ömer Çağatan",
        "Akash Kundu",
        "Martin Bernstorff",
        "Shitao Xiao",
        "Akshita Sukhlecha",
        "Bhavish Pahwa",
        "Rafał Poświata",
        "Kranthi Kiran GV",
        "Shawon Ashraf",
        "Daniel Auras",
        "Björn Plüster",
        "Jan Philipp Harries",
        "Loïc Magne",
        "Isabelle Mohr",
        "Mariya Hendriksen",
        "Dawei Zhu",
        "Hippolyte Gisserot-Boukhlef",
        "Tom Aarsen",
        "Jan Kostkan",
        "Konrad Wojtasik",
        "Taemin Lee",
        "Marek Šuppa",
        "Crystina Zhang",
        "Roberta Rocca",
        "Mohammed Hamdy",
        "Andrianos Michail",
        "John Yang",
        "Manuel Faysse",
        "Aleksei Vatolin",
        "Nandan Thakur",
        "Manan Dey",
        "Dipam Vasani",
        "Pranjal Chitale",
        "Simone Tedeschi",
        "Nguyen Tai",
        "Artem Snegirev",
        "Michael Günther",
        "Mengzhou Xia",
        "Weijia Shi",
        "Xing Han Lù",
        "Jordan Clive",
        "Gayatri Krishnakumar",
        "Anna Maksimova",
        "Silvan Wehrli",
        "Maria Tikhonova",
        "Henil Panchal",
        "Aleksandr Abramov",
        "Malte Ostendorff",
        "Zheng Liu",
        "Simon Clematide",
        "Lester James Miranda",
        "Alena Fenogenova",
        "Guangyu Song",
        "Ruqiya Bin Safi",
        "Wen-Ding Li",
        "Alessia Borghini",
        "Federico Cassano",
        "Hongjin Su",
        "Jimmy Lin",
        "Howard Yen",
        "Lasse Hansen",
        "Sara Hooker",
        "Chenghao Xiao",
        "Vaibhav Adlakha",
        "Orion Weller",
        "Siva Reddy",
        "Niklas Muennighoff"
      ],
      "abstract": "Text embeddings are typically evaluated on a limited set of tasks, which are\nconstrained by language, domain, and task diversity. To address these\nlimitations and provide a more comprehensive evaluation, we introduce the\nMassive Multilingual Text Embedding Benchmark (MMTEB) - a large-scale,\ncommunity-driven expansion of MTEB, covering over 500 quality-controlled\nevaluation tasks across 250+ languages. MMTEB includes a diverse set of\nchallenging, novel tasks such as instruction following, long-document\nretrieval, and code retrieval, representing the largest multilingual collection\nof evaluation tasks for embedding models to date. Using this collection, we\ndevelop several highly multilingual benchmarks, which we use to evaluate a\nrepresentative set of models. We find that while large language models (LLMs)\nwith billions of parameters can achieve state-of-the-art performance on certain\nlanguage subsets and task categories, the best-performing publicly available\nmodel is multilingual-e5-large-instruct with only 560 million parameters. To\nfacilitate accessibility and reduce computational cost, we introduce a novel\ndownsampling method based on inter-task correlation, ensuring a diverse\nselection while preserving relative model rankings. Furthermore, we optimize\ntasks such as retrieval by sampling hard negatives, creating smaller but\neffective splits. These optimizations allow us to introduce benchmarks that\ndrastically reduce computational demands. For instance, our newly introduced\nzero-shot English benchmark maintains a ranking order similar to the full-scale\nversion but at a fraction of the computational cost.",
      "tldr_zh": "本研究引入了MMTEB（Massive Multilingual Text Embedding Benchmark），这是一个大规模、多语言的文本嵌入评估基准，扩展了MTEB，涵盖超过500个高质量控制任务和250+语言，以解决现有评估的语言、领域和任务多样性限制。MMTEB包括多样化的新挑战任务，如instruction following、long-document retrieval和code retrieval，并使用这些任务评估了一系列模型，结果显示大型语言模型（LLMs）在某些子集和类别中达到state-of-the-art表现，但最佳公开模型是multilingual-e5-large-instruct，仅有560百万参数。为降低计算成本，研究提出了一种基于inter-task correlation的降采样方法，以及如采样hard negatives的优化，使基准（如zero-shot English benchmark）显著减少计算需求，同时保持模型排名一致。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted for ICLR: https://openreview.net/forum?id=zl3pfz4VCV",
      "pdf_url": "http://arxiv.org/pdf/2502.13595v2",
      "published_date": "2025-02-19 10:13:43 UTC",
      "updated_date": "2025-04-08 08:57:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:58:19.931543"
    },
    {
      "arxiv_id": "2502.14917v1",
      "title": "Sce2DriveX: A Generalized MLLM Framework for Scene-to-Drive Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Rui Zhao",
        "Qirui Yuan",
        "Jinyu Li",
        "Haofeng Hu",
        "Yun Li",
        "Chengyuan Zheng",
        "Fei Gao"
      ],
      "abstract": "End-to-end autonomous driving, which directly maps raw sensor inputs to\nlow-level vehicle controls, is an important part of Embodied AI. Despite\nsuccesses in applying Multimodal Large Language Models (MLLMs) for high-level\ntraffic scene semantic understanding, it remains challenging to effectively\ntranslate these conceptual semantics understandings into low-level motion\ncontrol commands and achieve generalization and consensus in cross-scene\ndriving. We introduce Sce2DriveX, a human-like driving chain-of-thought (CoT)\nreasoning MLLM framework. Sce2DriveX utilizes multimodal joint learning from\nlocal scene videos and global BEV maps to deeply understand long-range\nspatiotemporal relationships and road topology, enhancing its comprehensive\nperception and reasoning capabilities in 3D dynamic/static scenes and achieving\ndriving generalization across scenes. Building on this, it reconstructs the\nimplicit cognitive chain inherent in human driving, covering scene\nunderstanding, meta-action reasoning, behavior interpretation analysis, motion\nplanning and control, thereby further bridging the gap between autonomous\ndriving and human thought processes. To elevate model performance, we have\ndeveloped the first extensive Visual Question Answering (VQA) driving\ninstruction dataset tailored for 3D spatial understanding and long-axis task\nreasoning. Extensive experiments demonstrate that Sce2DriveX achieves\nstate-of-the-art performance from scene understanding to end-to-end driving, as\nwell as robust generalization on the CARLA Bench2Drive benchmark.",
      "tldr_zh": "该研究提出 Sce2DriveX，一种基于 Multimodal Large Language Models (MLLMs) 的泛化框架，用于端到端自动驾驶系统，将传感器输入直接映射为车辆控制命令，并解决跨场景泛化和语义理解转化的挑战。该框架通过多模态联合学习，利用本地场景视频和全局 BEV (Bird's Eye View) 地图，增强对3D动态/静态场景的长距离时空关系和道路拓扑的理解，并模仿人类驾驶的 Chain-of-Thought (CoT) 推理链，包括场景理解、元动作推理、行为解释分析、运动规划和控制。为提升性能，研究团队开发了首个针对3D空间理解和长轴任务推理的 Visual Question Answering (VQA) 驾驶指令数据集。实验结果显示，Sce2DriveX 在 CARLA Bench2Drive 基准上实现了从场景理解到端到端驾驶的最先进性能，并展示了强大的泛化能力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14917v1",
      "published_date": "2025-02-19 09:50:44 UTC",
      "updated_date": "2025-02-19 09:50:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:58:34.479108"
    },
    {
      "arxiv_id": "2502.14003v1",
      "title": "Rectified Lagrangian for Out-of-Distribution Detection in Modern Hopfield Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Ryo Moriai",
        "Nakamasa Inoue",
        "Masayuki Tanaka",
        "Rei Kawakami",
        "Satoshi Ikehata",
        "Ikuro Sato"
      ],
      "abstract": "Modern Hopfield networks (MHNs) have recently gained significant attention in\nthe field of artificial intelligence because they can store and retrieve a\nlarge set of patterns with an exponentially large memory capacity. A MHN is\ngenerally a dynamical system defined with Lagrangians of memory and feature\nneurons, where memories associated with in-distribution (ID) samples are\nrepresented by attractors in the feature space. One major problem in existing\nMHNs lies in managing out-of-distribution (OOD) samples because it was\noriginally assumed that all samples are ID samples. To address this, we propose\nthe rectified Lagrangian (RegLag), a new Lagrangian for memory neurons that\nexplicitly incorporates an attractor for OOD samples in the dynamical system of\nMHNs. RecLag creates a trivial point attractor for any interaction matrix,\nenabling OOD detection by identifying samples that fall into this attractor as\nOOD. The interaction matrix is optimized so that the probability densities can\nbe estimated to identify ID/OOD. We demonstrate the effectiveness of\nRecLag-based MHNs compared to energy-based OOD detection methods, including\nthose using state-of-the-art Hopfield energies, across nine image datasets.",
      "tldr_zh": "本研究针对现代 Hopfield Networks (MHNs) 在处理 Out-of-Distribution (OOD) 样本时的不足，提出了一种新的 Rectified Lagrangian (RegLag) 方法，以显式地在 MHNs 的动态系统中为 OOD 样本引入一个吸引子。\nRegLag 通过创建针对任何交互矩阵的平凡点吸引子，并优化交互矩阵来估计概率密度，从而实现对 ID/OOD 样本的准确识别。\n实验结果表明，基于 RegLag 的 MHNs 在九个图像数据集上，比现有的基于能量的 OOD 检测方法，包括最先进的 Hopfield 能量方法，表现出更高的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.14003v1",
      "published_date": "2025-02-19 09:50:22 UTC",
      "updated_date": "2025-02-19 09:50:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:58:46.853689"
    },
    {
      "arxiv_id": "2502.13576v1",
      "title": "Beyond One-Size-Fits-All: Tailored Benchmarks for Efficient Evaluation",
      "title_zh": "超越一刀切：用于高效评估的定制化基准",
      "authors": [
        "Peiwen Yuan",
        "Yueqi Zhang",
        "Shaoxiong Feng",
        "Yiwei Li",
        "Xinglin Wang",
        "Jiayi Shi",
        "Chuyi Tan",
        "Boyuan Pan",
        "Yao Hu",
        "Kan Li"
      ],
      "abstract": "Evaluating models on large benchmarks is very resource-intensive, especially\nduring the period of rapid model evolution. Existing efficient evaluation\nmethods estimate the performance of target models by testing them only on a\nsmall and static coreset of the benchmark, which is derived from the publicly\navailable evaluation results of source models. These methods rely on the\nassumption that target models have high prediction consistency with source\nmodels. However, we demonstrate that it doesn't generalize well in practice. To\nalleviate the inconsistency issue, we present TailoredBench, a method that\nconducts customized evaluation tailored to each target model. Specifically, a\nGlobal-coreset is first constructed as a probe to identify the most consistent\nsource models for each target model with an adaptive source model selection\nstrategy. Afterwards, a scalable K-Medoids clustering algorithm is proposed to\nextend the Global-coreset to a tailored Native-coreset for each target model.\nAccording to the predictions on Native-coresets, we obtain the performance of\ntarget models on the whole benchmark with a calibrated estimation strategy.\nComprehensive experiments on 5 benchmarks across over 300 models demonstrate\nthat compared to best performing baselines, TailoredBench achieves an average\nreduction of 31.4% in MAE of accuracy estimates under the same inference\nbudgets, showcasing strong effectiveness and generalizability.",
      "tldr_zh": "现有高效模型评估方法依赖于静态的 coreset，并假设目标模型与源模型预测一致性高，但实践证明这一假设不成立，导致评估不准确。研究提出 TailoredBench 方法，通过构建 Global-coreset 来自适应选择与目标模型最一致的源模型，并使用可扩展的 K-Medoids 聚类算法生成针对每个目标模型的 Native-coreset，然后通过校准的估计策略预测整体基准性能。在 5 个基准上测试超过 300 个模型后，TailoredBench 在相同推理预算下平均将 MAE 减少 31.4%，展示了其有效性和泛化能力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.13576v1",
      "published_date": "2025-02-19 09:31:50 UTC",
      "updated_date": "2025-02-19 09:31:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:58:57.458025"
    },
    {
      "arxiv_id": "2502.13569v1",
      "title": "Model Evolution Framework with Genetic Algorithm for Multi-Task Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Yan Yu",
        "Wengang Zhou",
        "Yaodong Yang",
        "Wanxuan Lu",
        "Yingyan Hou",
        "Houqiang Li"
      ],
      "abstract": "Multi-task reinforcement learning employs a single policy to complete various\ntasks, aiming to develop an agent with generalizability across different\nscenarios. Given the shared characteristics of tasks, the agent's learning\nefficiency can be enhanced through parameter sharing. Existing approaches\ntypically use a routing network to generate specific routes for each task and\nreconstruct a set of modules into diverse models to complete multiple tasks\nsimultaneously. However, due to the inherent difference between tasks, it is\ncrucial to allocate resources based on task difficulty, which is constrained by\nthe model's structure. To this end, we propose a Model Evolution framework with\nGenetic Algorithm (MEGA), which enables the model to evolve during training\naccording to the difficulty of the tasks. When the current model is\ninsufficient for certain tasks, the framework will automatically incorporate\nadditional modules, enhancing the model's capabilities. Moreover, to adapt to\nour model evolution framework, we introduce a genotype module-level model,\nusing binary sequences as genotype policies for model reconstruction, while\nleveraging a non-gradient genetic algorithm to optimize these genotype\npolicies. Unlike routing networks with fixed output dimensions, our approach\nallows for the dynamic adjustment of the genotype policy length, enabling it to\naccommodate models with a varying number of modules. We conducted experiments\non various robotics manipulation tasks in the Meta-World benchmark. Our\nstate-of-the-art performance demonstrated the effectiveness of the MEGA\nframework. We will release our source code to the public.",
      "tldr_zh": "这篇论文提出了一种名为 MEGA 的模型进化框架，用于多任务强化学习（Multi-Task Reinforcement Learning），它利用遗传算法（Genetic Algorithm）根据任务难度动态调整模型结构。框架允许在训练中自动添加模块以提升模型能力，并通过基因型策略（genotype policies）和非梯度优化来重构模型，从而更好地分配资源处理任务差异。实验结果显示，在 Meta-World 基准的各种机器人操作任务上，MEGA 框架实现了最先进的性能，证明了其在提高代理泛化性和学习效率方面的有效性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.13569v1",
      "published_date": "2025-02-19 09:22:34 UTC",
      "updated_date": "2025-02-19 09:22:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:59:09.332030"
    },
    {
      "arxiv_id": "2502.13562v1",
      "title": "Are Large Language Models In-Context Graph Learners?",
      "title_zh": "大型语言模型是基于上下文的图学习器吗？",
      "authors": [
        "Jintang Li",
        "Ruofan Wu",
        "Yuchang Zhu",
        "Huizhe Zhang",
        "Liang Chen",
        "Zibin Zheng"
      ],
      "abstract": "Large language models (LLMs) have demonstrated remarkable in-context\nreasoning capabilities across a wide range of tasks, particularly with\nunstructured inputs such as language or images. However, LLMs struggle to\nhandle structured data, such as graphs, due to their lack of understanding of\nnon-Euclidean structures. As a result, without additional fine-tuning, their\nperformance significantly lags behind that of graph neural networks (GNNs) in\ngraph learning tasks. In this paper, we show that learning on graph data can be\nconceptualized as a retrieval-augmented generation (RAG) process, where\nspecific instances (e.g., nodes or edges) act as queries, and the graph itself\nserves as the retrieved context. Building on this insight, we propose a series\nof RAG frameworks to enhance the in-context learning capabilities of LLMs for\ngraph learning tasks. Comprehensive evaluations demonstrate that our proposed\nRAG frameworks significantly improve LLM performance on graph-based tasks,\nparticularly in scenarios where a pretrained LLM must be used without\nmodification or accessed via an API.",
      "tldr_zh": "大型语言模型 (LLMs) 在处理非结构化数据如文本或图像时表现出色，但对结构化图数据缺乏理解，导致在图学习任务中落后于图神经网络 (GNNs)。本文将图学习视为一种检索增强生成 (RAG) 过程，其中节点或边作为查询，图结构充当检索上下文，并提出了一系列 RAG 框架来增强 LLMs 的 in-context 学习能力。实验评估表明，这些框架显著提高了 LLMs 在图任务上的性能，特别是当预训练模型无法修改或仅通过 API 访问时。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Preprint, under review",
      "pdf_url": "http://arxiv.org/pdf/2502.13562v1",
      "published_date": "2025-02-19 09:14:19 UTC",
      "updated_date": "2025-02-19 09:14:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:59:21.967110"
    },
    {
      "arxiv_id": "2502.13555v1",
      "title": "Democratizing Large Language Model-Based Graph Data Augmentation via Latent Knowledge Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Yushi Feng",
        "Tsai Hor Chan",
        "Guosheng Yin",
        "Lequan Yu"
      ],
      "abstract": "Data augmentation is necessary for graph representation learning due to the\nscarcity and noise present in graph data. Most of the existing augmentation\nmethods overlook the context information inherited from the dataset as they\nrely solely on the graph structure for augmentation. Despite the success of\nsome large language model-based (LLM) graph learning methods, they are mostly\nwhite-box which require access to the weights or latent features from the\nopen-access LLMs, making them difficult to be democratized for everyone as\nexisting LLMs are mostly closed-source for commercial considerations. To\novercome these limitations, we propose a black-box context-driven graph data\naugmentation approach, with the guidance of LLMs -- DemoGraph. Leveraging the\ntext prompt as context-related information, we task the LLM with generating\nknowledge graphs (KGs), which allow us to capture the structural interactions\nfrom the text outputs. We then design a dynamic merging schema to\nstochastically integrate the LLM-generated KGs into the original graph during\ntraining. To control the sparsity of the augmented graph, we further devise a\ngranularity-aware prompting strategy and an instruction fine-tuning module,\nwhich seamlessly generates text prompts according to different granularity\nlevels of the dataset. Extensive experiments on various graph learning tasks\nvalidate the effectiveness of our method over existing graph data augmentation\nmethods. Notably, our approach excels in scenarios involving electronic health\nrecords (EHRs), which validates its maximal utilization of contextual\nknowledge, leading to enhanced predictive performance and interpretability.",
      "tldr_zh": "该论文针对图表示学习中的数据稀缺和噪声问题，提出了一种民主化的Large Language Model-based (LLM) 图数据增强方法——DemoGraph，以克服现有方法忽略上下文信息和依赖白盒LLM的局限。该方法利用文本提示作为上下文指导，让LLM生成知识图 (KGs) 来捕捉结构交互，并通过动态合并方案在训练时随机整合这些KGs到原图中；同时，引入粒度感知提示策略和指令微调模块，以控制增强图的稀疏度并适应不同数据集粒度。实验结果显示，DemoGraph在多种图学习任务上优于现有方法，尤其在Electronic Health Records (EHRs) 场景中显著提升了预测性能和可解释性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.13555v1",
      "published_date": "2025-02-19 09:00:32 UTC",
      "updated_date": "2025-02-19 09:00:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:59:33.860948"
    },
    {
      "arxiv_id": "2502.13544v2",
      "title": "From Sub-Ability Diagnosis to Human-Aligned Generation: Bridging the Gap for Text Length Control via MARKERGEN",
      "title_zh": "翻译失败",
      "authors": [
        "Peiwen Yuan",
        "Chuyi Tan",
        "Shaoxiong Feng",
        "Yiwei Li",
        "Xinglin Wang",
        "Yueqi Zhang",
        "Jiayi Shi",
        "Boyuan Pan",
        "Yao Hu",
        "Kan Li"
      ],
      "abstract": "Despite the rapid progress of large language models (LLMs), their\nlength-controllable text generation (LCTG) ability remains below expectations,\nposing a major limitation for practical applications. Existing methods mainly\nfocus on end-to-end training to reinforce adherence to length constraints.\nHowever, the lack of decomposition and targeted enhancement of LCTG\nsub-abilities restricts further progress. To bridge this gap, we conduct a\nbottom-up decomposition of LCTG sub-abilities with human patterns as reference\nand perform a detailed error analysis. On this basis, we propose MarkerGen, a\nsimple-yet-effective plug-and-play approach that:(1) mitigates LLM fundamental\ndeficiencies via external tool integration;(2) conducts explicit length\nmodeling with dynamically inserted markers;(3) employs a three-stage generation\nscheme to better align length constraints while maintaining content quality.\nComprehensive experiments demonstrate that MarkerGen significantly improves\nLCTG across various settings, exhibiting outstanding effectiveness and\ngeneralizability.",
      "tldr_zh": "尽管大语言模型 (LLMs) 在长度可控文本生成 (LCTG) 方面表现不佳，现有的端到端训练方法未能针对 LCTG 子能力进行分解和优化。  \n本文通过对 LCTG 子能力进行底层分解和基于人类模式的错误分析，提出了一种简单有效的即插即用方法 MarkerGen。  \nMarkerGen 包括外部工具集成以缓解 LLM 基本缺陷、动态插入标记进行显式长度建模，以及三阶段生成方案，以更好地符合长度约束同时保持内容质量。  \n实验证明，MarkerGen 在各种设置下显著提升了 LCTG 的性能，并展示了出色的有效性和泛化性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.13544v2",
      "published_date": "2025-02-19 08:52:45 UTC",
      "updated_date": "2025-02-21 07:23:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:59:45.834191"
    },
    {
      "arxiv_id": "2502.13542v1",
      "title": "Activation-aware Probe-Query: Effective Key-Value Retrieval for Long-Context LLMs Inference",
      "title_zh": "激活感知探针查询：针对长上下文大语言模型推理的有效键值检索",
      "authors": [
        "Qingfa Xiao",
        "Jiachuan Wang",
        "Haoyang Li",
        "Cheng Deng",
        "Jiaqi Tang",
        "Shuangyin Li",
        "Yongqi Zhang",
        "Jun Wang",
        "Lei Chen"
      ],
      "abstract": "Recent advances in large language models (LLMs) have showcased exceptional\nperformance in long-context tasks, while facing significant inference\nefficiency challenges with limited GPU memory. Existing solutions first\nproposed the sliding-window approach to accumulate a set of historical\n\\textbf{key-value} (KV) pairs for reuse, then further improvements selectively\nretain its subsets at each step. However, due to the sparse attention\ndistribution across a long context, it is hard to identify and recall relevant\nKV pairs, as the attention is distracted by massive candidate pairs.\nAdditionally, we found it promising to select representative tokens as\nprobe-Query in each sliding window to effectively represent the entire context,\nwhich is an approach overlooked by existing methods. Thus, we propose\n\\textbf{ActQKV}, a training-free, \\textbf{Act}ivation-aware approach that\ndynamically determines probe-\\textbf{Q}uery and leverages it to retrieve the\nrelevant \\textbf{KV} pairs for inference. Specifically, ActQKV monitors a\ntoken-level indicator, Activation Bias, within each context window, enabling\nthe proper construction of probe-Query for retrieval at pre-filling stage. To\naccurately recall the relevant KV pairs and minimize the irrelevant ones, we\ndesign a dynamic KV cut-off mechanism guided by information density across\nlayers at the decoding stage. Experiments on the Long-Bench and $\\infty$\nBenchmarks demonstrate its state-of-the-art performance with competitive\ninference quality and resource efficiency.",
      "tldr_zh": "该论文针对大型语言模型 (LLMs) 在长上下文推理中面临的效率和 GPU 内存限制问题，提出了一种无需训练的激活感知方法 ActQKV，以有效改进 Key-Value (KV) 检索。ActQKV 通过监控每个上下文窗口的 token-level Activation Bias 来动态确定 probe-Query，从而在预填充阶段代表整个上下文进行检索，并在解码阶段采用信息密度引导的动态 KV cut-off 机制，确保准确召回相关 KV 对并减少无关信息。实验结果显示，该方法在 Long-Bench 和 ∞ Benchmarks 上实现了最先进的性能，同时在推理质量和资源效率方面表现出色。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.13542v1",
      "published_date": "2025-02-19 08:50:44 UTC",
      "updated_date": "2025-02-19 08:50:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T15:59:57.598053"
    },
    {
      "arxiv_id": "2502.13534v2",
      "title": "Solving the encoding bottleneck: of the HHL algorithm, by the HHL algorithm",
      "title_zh": "翻译失败",
      "authors": [
        "Guang Ping He"
      ],
      "abstract": "The Harrow-Hassidim-Lloyd (HHL) algorithm offers exponential speedup for\nsolving the quantum linear-system problem. But some caveats for the speedup\ncould be hard to met. One of the difficulties is the encoding bottleneck, i.e.,\nthe efficient preparation of the initial quantum state. To prepare an arbitrary\n$N$-dimensional state exactly, existing state-preparation approaches generally\nrequire a runtime of $O(N)$, which will ruin the speedup of the HHL algorithm.\nHere we show that the states can be prepared approximately with a runtime of\n$O(poly(\\log N))$ by employing a slightly modified version of the HHL algorithm\nitself. Thus, applying this approach to prepare the initial state of the\noriginal HHL algorithm can preserve the exponential speedup advantage. It can\nalso serve as a standalone solution for other applications demanding fast state\npreparation.",
      "tldr_zh": "HHL 算法为量子线性系统问题提供了指数级加速，但面临编码瓶颈，即高效准备初始量子状态的挑战，现有的方法通常需要 O(N) 的运行时间，从而破坏了加速优势。  \n本文提出使用一个稍作修改的 HHL 算法来近似准备初始状态，仅需 O(poly(log N)) 的运行时间，从而保留了原 HHL 算法的指数级加速。  \n这种方法不仅适用于 HHL 算法的初始状态准备，还可以作为其他应用中快速状态准备的独立解决方案。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "quant-ph",
      "comment": "Added a diagram of the quantum circuit of our algorithm",
      "pdf_url": "http://arxiv.org/pdf/2502.13534v2",
      "published_date": "2025-02-19 08:39:41 UTC",
      "updated_date": "2025-03-09 10:29:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:00:09.608338"
    },
    {
      "arxiv_id": "2502.13533v2",
      "title": "Train Small, Infer Large: Memory-Efficient LoRA Training for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jun Zhang",
        "Jue Wang",
        "Huan Li",
        "Lidan Shou",
        "Ke Chen",
        "Yang You",
        "Guiming Xie",
        "Xuejian Gong",
        "Kunlong Zhou"
      ],
      "abstract": "Large Language Models (LLMs) have significantly advanced natural language\nprocessing with exceptional task generalization capabilities. Low-Rank Adaption\n(LoRA) offers a cost-effective fine-tuning solution, freezing the original\nmodel parameters and training only lightweight, low-rank adapter matrices.\nHowever, the memory footprint of LoRA is largely dominated by the original\nmodel parameters. To mitigate this, we propose LoRAM, a memory-efficient LoRA\ntraining scheme founded on the intuition that many neurons in\nover-parameterized LLMs have low training utility but are essential for\ninference. LoRAM presents a unique twist: it trains on a pruned (small) model\nto obtain pruned low-rank matrices, which are then recovered and utilized with\nthe original (large) model for inference. Additionally, minimal-cost continual\npre-training, performed by the model publishers in advance, aligns the\nknowledge discrepancy between pruned and original models. Our extensive\nexperiments demonstrate the efficacy of LoRAM across various pruning strategies\nand downstream tasks. For a model with 70 billion parameters, LoRAM enables\ntraining on a GPU with only 20G HBM, replacing an A100-80G GPU for LoRA\ntraining and 15 GPUs for full fine-tuning. Specifically, QLoRAM implemented by\nstructured pruning combined with 4-bit quantization, for LLaMA-3.1-70B\n(LLaMA-2-70B), reduces the parameter storage cost that dominates the memory\nusage in low-rank matrix training by 15.81$\\times$ (16.95$\\times$), while\nachieving dominant performance gains over both the original LLaMA-3.1-70B\n(LLaMA-2-70B) and LoRA-trained LLaMA-3.1-8B (LLaMA-2-13B). Code is available at\nhttps://github.com/junzhang-zj/LoRAM.",
      "tldr_zh": "该论文提出 LoRAM，一种内存高效的 LoRA 训练方案，针对大型语言模型 (LLMs) 的过参数化问题，通过在修剪后的小模型上训练低秩矩阵，然后在原大模型上恢复使用，从而减少训练内存占用，同时通过最小成本的持续预训练对齐模型知识差异。LoRAM 支持各种修剪策略，并在下游任务中表现出色，例如使用 20G HBM GPU 即可训练 70 亿参数模型，替代原需 80G GPU 的 LoRA 训练或多 GPU 全量微调。实验显示，结合结构化修剪和 4 位量化的 QLoRAM 方案将参数存储成本减少了约 15.81× 到 16.95×，并在性能上超越了原始 LLaMA-3.1-70B 和 LoRA 训练的较小模型。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.13533v2",
      "published_date": "2025-02-19 08:39:15 UTC",
      "updated_date": "2025-03-15 04:12:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:00:23.032418"
    },
    {
      "arxiv_id": "2502.13527v1",
      "title": "Exploiting Prefix-Tree in Structured Output Interfaces for Enhancing Jailbreak Attacking",
      "title_zh": "翻译失败",
      "authors": [
        "Yanzeng Li",
        "Yunfan Xiong",
        "Jialun Zhong",
        "Jinchao Zhang",
        "Jie Zhou",
        "Lei Zou"
      ],
      "abstract": "The rise of Large Language Models (LLMs) has led to significant applications\nbut also introduced serious security threats, particularly from jailbreak\nattacks that manipulate output generation. These attacks utilize prompt\nengineering and logit manipulation to steer models toward harmful content,\nprompting LLM providers to implement filtering and safety alignment strategies.\nWe investigate LLMs' safety mechanisms and their recent applications, revealing\na new threat model targeting structured output interfaces, which enable\nattackers to manipulate the inner logit during LLM generation, requiring only\nAPI access permissions. To demonstrate this threat model, we introduce a\nblack-box attack framework called AttackPrefixTree (APT). APT exploits\nstructured output interfaces to dynamically construct attack patterns. By\nleveraging prefixes of models' safety refusal response and latent harmful\noutputs, APT effectively bypasses safety measures. Experiments on benchmark\ndatasets indicate that this approach achieves higher attack success rate than\nexisting methods. This work highlights the urgent need for LLM providers to\nenhance security protocols to address vulnerabilities arising from the\ninteraction between safety patterns and structured outputs.",
      "tldr_zh": "该研究探讨了大语言模型(LLMs)面临的安全威胁，特别是利用提示工程和logit操纵的越狱攻击(jailbreak attacks)，并揭示了针对结构化输出接口的新威胁模型，该模型允许攻击者仅通过API访问权限操纵模型生成。论文提出了一种黑盒攻击框架AttackPrefixTree (APT)，通过利用Prefix-Tree动态构建攻击模式，结合模型的安全拒绝响应前缀和潜在有害输出，有效绕过安全措施。实验结果显示，APT在基准数据集上比现有方法实现了更高的攻击成功率，并强调LLM提供商需加强安全协议以应对安全模式和结构化输出间的漏洞。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.13527v1",
      "published_date": "2025-02-19 08:29:36 UTC",
      "updated_date": "2025-02-19 08:29:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:00:34.654514"
    },
    {
      "arxiv_id": "2503.05733v1",
      "title": "Design an Ontology for Cognitive Business Strategy Based on Customer Satisfaction",
      "title_zh": "翻译失败",
      "authors": [
        "Neda Bagherzadeh",
        "Saeed Setayeshi",
        "Samaneh Yazdani"
      ],
      "abstract": "Ontology is a general term used by researchers who want to share information\nin a specific domain. One of the hallmarks of the greatest success of a\npowerful manager of an organization is his ability to interpret unplanned and\nunrelated events. Tools to solve this problem are vital to business growth.\nModern technology allows customers to be more informed and influential in their\nroles as patrons and critics. This can make or break a business. Research shows\nthat businesses that employ a customer-first strategy and prioritize their\ncustomers can generate more revenue. Even though there are many different\nOntologies offered to businesses, none of it is built from a cognitive\nperspective. The objective of this study is to address the concept of strategic\nbusiness plans with a cognitive ontology approach as a basis for a new\nmanagement tool. This research proposes to design a cognitive ontology model\nthat links customer measurement with traditional business models, define\nrelationships between components and verify the accuracy of the added financial\nvalue.",
      "tldr_zh": "这篇论文旨在设计一个基于认知的Ontology，用于业务战略，以解决管理者解读非计划事件和客户影响的挑战。研究强调，以客户为中心的策略能提升收入，并指出现有Ontology缺乏认知视角。论文提出一个认知ontology模型，将客户满意度测量与传统商业模型关联，定义组件关系，并验证其增加的财务价值，作为一种新型管理工具。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.05733v1",
      "published_date": "2025-02-19 08:29:23 UTC",
      "updated_date": "2025-02-19 08:29:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:00:45.584291"
    },
    {
      "arxiv_id": "2502.13524v4",
      "title": "MobileViM: A Light-weight and Dimension-independent Vision Mamba for 3D Medical Image Analysis",
      "title_zh": "MobileViM：一种轻量级且维度无关的视觉 Mamba 用于 3D 医学图像分析",
      "authors": [
        "Wei Dai",
        "Jun Liu"
      ],
      "abstract": "Efficient evaluation of three-dimensional (3D) medical images is crucial for\ndiagnostic and therapeutic practices in healthcare. Recent years have seen a\nsubstantial uptake in applying deep learning and computer vision to analyse and\ninterpret medical images. Traditional approaches, such as convolutional neural\nnetworks (CNNs) and vision transformers (ViTs), face significant computational\nchallenges, prompting the need for architectural advancements. Recent efforts\nhave led to the introduction of novel architectures like the ``Mamba'' model as\nalternative solutions to traditional CNNs or ViTs. The Mamba model excels in\nthe linear processing of one-dimensional data with low computational demands.\nHowever, Mamba's potential for 3D medical image analysis remains underexplored\nand could face significant computational challenges as the dimension increases.\nThis manuscript presents MobileViM, a streamlined architecture for efficient\nsegmentation of 3D medical images. In the MobileViM network, we invent a new\ndimension-independent mechanism and a dual-direction traversing approach to\nincorporate with a vision-Mamba-based framework. MobileViM also features a\ncross-scale bridging technique to improve efficiency and accuracy across\nvarious medical imaging modalities. With these enhancements, MobileViM achieves\nsegmentation speeds exceeding 90 frames per second (FPS) on a single graphics\nprocessing unit (i.e., NVIDIA RTX 4090). This performance is over 24 FPS faster\nthan the state-of-the-art deep learning models for processing 3D images with\nthe same computational resources. In addition, experimental evaluations\ndemonstrate that MobileViM delivers superior performance, with Dice similarity\nscores reaching 92.72%, 86.69%, 80.46%, and 77.43% for PENGWIN, BraTS2024,\nATLAS, and Toothfairy2 datasets, respectively, which significantly surpasses\nexisting models.",
      "tldr_zh": "本论文提出 MobileViM，一种轻量级且维度无关的 Vision Mamba 架构，旨在高效处理 3D 医疗图像分析，以克服传统 CNNs 和 ViTs 在计算资源上的挑战。MobileViM 创新性地整合了维度无关机制、双向遍历方法和跨尺度桥接技术，与 Mamba 框架结合，实现快速且准确的图像分割。实验结果显示，该模型在 NVIDIA RTX 4090 上达到超过 90 FPS 的处理速度，比现有模型快 24 FPS，并在 PENGWIN、BraTS2024、ATLAS 和 Toothfairy2 数据集上取得最高 92.72% 的 Dice similarity scores，显著提升了 3D 医疗图像分析的性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.NI"
      ],
      "primary_category": "cs.CV",
      "comment": "The corresponding author disagrees with the manuscript submitted to\n  arXiv",
      "pdf_url": "http://arxiv.org/pdf/2502.13524v4",
      "published_date": "2025-02-19 08:21:59 UTC",
      "updated_date": "2025-03-06 14:27:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:00:59.298401"
    },
    {
      "arxiv_id": "2502.13519v1",
      "title": "MILE: Model-based Intervention Learning",
      "title_zh": "MILE：基于模型的干预学习",
      "authors": [
        "Yigit Korkmaz",
        "Erdem Bıyık"
      ],
      "abstract": "Imitation learning techniques have been shown to be highly effective in\nreal-world control scenarios, such as robotics. However, these approaches not\nonly suffer from compounding error issues but also require human experts to\nprovide complete trajectories. Although there exist interactive methods where\nan expert oversees the robot and intervenes if needed, these extensions usually\nonly utilize the data collected during intervention periods and ignore the\nfeedback signal hidden in non-intervention timesteps. In this work, we create a\nmodel to formulate how the interventions occur in such cases, and show that it\nis possible to learn a policy with just a handful of expert interventions. Our\nkey insight is that it is possible to get crucial information about the quality\nof the current state and the optimality of the chosen action from expert\nfeedback, regardless of the presence or the absence of intervention. We\nevaluate our method on various discrete and continuous simulation environments,\na real-world robotic manipulation task, as well as a human subject study.\nVideos and the code can be found at https://liralab.usc.edu/mile .",
      "tldr_zh": "本研究提出了一种基于模型的干预学习框架MILE，以解决传统模仿学习(Imitation Learning)中的累积错误问题和对完整轨迹的依赖。MILE通过建模专家干预过程，利用干预和非干预时步的反馈信号，提取当前状态质量和动作最优性的信息，从而仅需少量专家干预即可学习有效的策略。实验在各种离散和连续模拟环境、真实机器人操作任务以及人类主题研究中验证了该方法的有效性，展示了其在实际控制场景中的潜力。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "International Conference on Robotics and Automation (ICRA)",
      "pdf_url": "http://arxiv.org/pdf/2502.13519v1",
      "published_date": "2025-02-19 08:15:16 UTC",
      "updated_date": "2025-02-19 08:15:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:01:09.766089"
    },
    {
      "arxiv_id": "2502.13516v1",
      "title": "SPPD: Self-training with Process Preference Learning Using Dynamic Value Margin",
      "title_zh": "翻译失败",
      "authors": [
        "Hao Yi",
        "Qingyang Li",
        "Yulan Hu",
        "Fuzheng Zhang",
        "Di Zhang",
        "Yong Liu"
      ],
      "abstract": "Recently, enhancing the numerical and logical reasoning capability of Large\nLanguage Models (LLMs) has emerged as a research hotspot. Existing methods face\nseveral limitations: inference-phase techniques (e.g., Chain of Thoughts) rely\non prompt selection and the pretrained knowledge; sentence-level Supervised\nFine-Tuning (SFT) and Direct Preference Optimization (DPO) struggle with\nstep-wise mathematical correctness and depend on stronger models distillation\nor human annotations; while Reinforcement Learning (RL) approaches incur high\nGPU memory costs and unstable training. To address these, we propose\n\\textbf{S}elf-training framework integrating \\textbf{P}rocess\n\\textbf{P}reference learning using \\textbf{D}ynamic value margin (SPPD). SPPD\nleverages a process-based Markov Decision Process (MDP) and Bellman optimality\nequation to derive \\textbf{dynamic value margin} on step-level preference\noptimization, which employs tree-based self-sampling on model responses\n\\textbf{without any distillation} from other models. Furthermore, we\ntheoretically prove that SPPD is \\textbf{equivalent to on-policy policy\ngradient methods} under reward constraints. Experiments on 7B-scale models\ndemonstrate superior performance across in-domain and out-domain mathematical\nbenchmarks. We open-source our code at\n\\href{https://anonymous.4open.science/r/SSDPO-D-DCDD}{https://anonymous.4open.science/r/SPPD-DCDD}.",
      "tldr_zh": "该研究提出SPPD框架，用于提升Large Language Models (LLMs)的数值和逻辑推理能力，以解决现有方法的局限性，如Chain of Thoughts依赖预训练知识、Supervised Fine-Tuning (SFT)和Direct Preference Optimization (DPO)难以确保步进正确性，以及Reinforcement Learning (RL)的高计算成本。SPPD通过Markov Decision Process (MDP)和Bellman optimality equation引入动态价值边际(dynamic value margin)进行步进级偏好优化，并采用树状自采样(tree-based self-sampling)，无需从其他模型蒸馏即可实现自训练。理论上，SPPD被证明等效于on-policy policy gradient methods under reward constraints；实验在7B-scale模型上显示，在in-domain和out-domain数学基准上表现出色。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.13516v1",
      "published_date": "2025-02-19 08:11:26 UTC",
      "updated_date": "2025-02-19 08:11:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:01:22.566156"
    },
    {
      "arxiv_id": "2502.14916v2",
      "title": "MKE-Coder: Multi-Axial Knowledge with Evidence Verification in ICD Coding for Chinese EMRs",
      "title_zh": "MKE-Coder：多轴知识与证据验证在针对中文电子病历的ICD编码中",
      "authors": [
        "Xinxin You",
        "Xien Liu",
        "Xue Yang",
        "Ziyi Wang",
        "Ji Wu"
      ],
      "abstract": "The task of automatically coding the International Classification of Diseases\n(ICD) in the medical field has been well-established and has received much\nattention. Automatic coding of the ICD in the medical field has been successful\nin English but faces challenges when dealing with Chinese electronic medical\nrecords (EMRs). The first issue lies in the difficulty of extracting disease\ncode-related information from Chinese EMRs, primarily due to the concise\nwriting style and specific internal structure of the EMRs. The second problem\nis that previous methods have failed to leverage the disease-based multi-axial\nknowledge and lack of association with the corresponding clinical evidence.\nThis paper introduces a novel framework called MKE-Coder: Multi-axial Knowledge\nwith Evidence verification in ICD coding for Chinese EMRs. Initially, we\nidentify candidate codes for the diagnosis and categorize each of them into\nknowledge under four coding axes.Subsequently, we retrieve corresponding\nclinical evidence from the comprehensive content of EMRs and filter credible\nevidence through a scoring model. Finally, to ensure the validity of the\ncandidate code, we propose an inference module based on the masked language\nmodeling strategy. This module verifies that all the axis knowledge associated\nwith the candidate code is supported by evidence and provides recommendations\naccordingly. To evaluate the performance of our framework, we conduct\nexperiments using a large-scale Chinese EMR dataset collected from various\nhospitals. The experimental results demonstrate that MKE-Coder exhibits\nsignificant superiority in the task of automatic ICD coding based on Chinese\nEMRs. In the practical evaluation of our method within simulated real coding\nscenarios, it has been demonstrated that our approach significantly aids coders\nin enhancing both their coding accuracy and speed.",
      "tldr_zh": "本研究针对中文电子病历 (EMRs) 中的国际疾病分类 (ICD) 自动编码问题，提出了一种名为 MKE-Coder 的新型框架，以解决信息提取困难和多轴知识关联不足的挑战。框架首先识别诊断候选代码并分类到四个编码轴下的知识，然后从 EMRs 中检索临床证据并通过评分模型过滤可信证据，最后利用基于掩码语言模型的推理模块验证候选代码的关联性并提供推荐。实验结果显示，在大型中文 EMR 数据集上，MKE-Coder 显著优于现有方法，并在模拟真实编码场景中帮助编码者提升准确性和速度。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14916v2",
      "published_date": "2025-02-19 08:08:53 UTC",
      "updated_date": "2025-02-26 04:35:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:01:34.187848"
    },
    {
      "arxiv_id": "2502.13509v1",
      "title": "Unlocking Multimodal Integration in EHRs: A Prompt Learning Framework for Language and Time Series Fusion",
      "title_zh": "解锁 EHRs 中的多模态集成：一个用于语言和时间序列融合的提示学习框架",
      "authors": [
        "Shuai Niu",
        "Jing Ma",
        "Hongzhan Lin",
        "Liang Bai",
        "Zhihua Wang",
        "Wei Bi",
        "Yida Xu",
        "Guo Li",
        "Xian Yang"
      ],
      "abstract": "Large language models (LLMs) have shown remarkable performance in\nvision-language tasks, but their application in the medical field remains\nunderexplored, particularly for integrating structured time series data with\nunstructured clinical notes. In clinical practice, dynamic time series data\nsuch as lab test results capture critical temporal patterns, while clinical\nnotes provide rich semantic context. Merging these modalities is challenging\ndue to the inherent differences between continuous signals and discrete text.\nTo bridge this gap, we introduce ProMedTS, a novel self-supervised multimodal\nframework that employs prompt-guided learning to unify these heterogeneous data\ntypes. Our approach leverages lightweight anomaly detection to generate anomaly\ncaptions that serve as prompts, guiding the encoding of raw time series data\ninto informative embeddings. These embeddings are aligned with textual\nrepresentations in a shared latent space, preserving fine-grained temporal\nnuances alongside semantic insights. Furthermore, our framework incorporates\ntailored self-supervised objectives to enhance both intra- and inter-modal\nalignment. We evaluate ProMedTS on disease diagnosis tasks using real-world\ndatasets, and the results demonstrate that our method consistently outperforms\nstate-of-the-art approaches.",
      "tldr_zh": "这篇论文提出了 ProMedTS，一种自监督的多模态框架，用于整合电子健康记录(EHRs)中的结构化时间序列数据（如实验室测试结果）和非结构化临床笔记，解决二者融合的挑战。框架采用提示引导学习，通过轻量级异常检测生成异常描述作为提示，将时间序列数据编码成信息丰富的嵌入，并与文本表示在共享潜在空间中对齐，同时使用定制的自监督目标增强模态内和模态间对齐。实验结果显示，在真实数据集的疾病诊断任务上，ProMedTS  consistently outperforms 现有最先进方法，证明了其在医疗领域 LLMs 应用的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "68T50",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "13 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.13509v1",
      "published_date": "2025-02-19 07:56:48 UTC",
      "updated_date": "2025-02-19 07:56:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:01:46.738829"
    },
    {
      "arxiv_id": "2502.14001v1",
      "title": "Towards a perturbation-based explanation for medical AI as differentiable programs",
      "title_zh": "翻译失败",
      "authors": [
        "Takeshi Abe",
        "Yoshiyuki Asai"
      ],
      "abstract": "Recent advancement in machine learning algorithms reaches a point where\nmedical devices can be equipped with artificial intelligence (AI) models for\ndiagnostic support and routine automation in clinical settings. In medicine and\nhealthcare, there is a particular demand for sufficient and objective\nexplainability of the outcome generated by AI models. However, AI models are\ngenerally considered as black boxes due to their complexity, and the\ncomputational process leading to their response is often opaque. Although\nseveral methods have been proposed to explain the behavior of models by\nevaluating the importance of each feature in discrimination and prediction,\nthey may suffer from biases and opacities arising from the scale and sampling\nprotocol of the dataset used for training or testing. To overcome the\nshortcomings of existing methods, we explore an alternative approach to provide\nan objective explanation of AI models that can be defined independently of the\nlearning process and does not require additional data. As a preliminary study\nfor this direction of research, this work examines a numerical availability of\nthe Jacobian matrix of deep learning models that measures how stably a model\nresponses against small perturbations added to the input. The indicator, if\navailable, are calculated from a trained AI model for a given target input.\nThis is a first step towards a perturbation-based explanation, which will\nassist medical practitioners in understanding and interpreting the response of\nthe AI model in its clinical application.",
      "tldr_zh": "这篇论文针对医疗AI模型的黑盒问题，提出了一种基于扰动的解释方法，将AI模型视为可微程序，以提供独立于学习过程的客观解释。该方法利用Jacobian matrix来量化模型对输入小扰动的稳定响应，从而评估模型行为的可靠性，而无需额外数据或训练数据集。作为初步研究，该方法有助于医疗从业者更好地理解和解释AI模型在临床应用中的输出，为可信赖的AI辅助诊断奠定基础。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "7 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2502.14001v1",
      "published_date": "2025-02-19 07:56:23 UTC",
      "updated_date": "2025-02-19 07:56:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:01:57.176041"
    },
    {
      "arxiv_id": "2502.14000v1",
      "title": "Human-Artificial Interaction in the Age of Agentic AI: A System-Theoretical Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Uwe M. Borghoff",
        "Paolo Bottoni",
        "Remo Pareschi"
      ],
      "abstract": "This paper presents a novel perspective on human-computer interaction (HCI),\nframing it as a dynamic interplay between human and computational agents within\na networked system. Going beyond traditional interface-based approaches, we\nemphasize the importance of coordination and communication among heterogeneous\nagents with different capabilities, roles, and goals. A key distinction is made\nbetween multi-agent systems (MAS) and Centaurian systems, which represent two\ndifferent paradigms of human-AI collaboration. MAS maintain agent autonomy,\nwith structured protocols enabling cooperation, while Centaurian systems deeply\nintegrate human and AI capabilities, creating unified decision-making entities.\n  To formalize these interactions, we introduce a framework for communication\nspaces, structured into surface, observation, and computation layers, ensuring\nseamless integration between MAS and Centaurian architectures, where colored\nPetri nets effectively represent structured Centaurian systems and high-level\nreconfigurable networks address the dynamic nature of MAS.\n  Our research has practical applications in autonomous robotics,\nhuman-in-the-loop decision making, and AI-driven cognitive architectures, and\nprovides a foundation for next-generation hybrid intelligence systems that\nbalance structured coordination with emergent behavior.",
      "tldr_zh": "本论文从系统理论角度探讨了 Agentic AI 时代的人类-人工智能交互 (HCI)，将其视为人类和计算代理在网络系统中的动态互动，强调了不同代理在能力、角色和目标上的协调与通信。论文区分了多代理系统 (MAS)，which maintains agent autonomy through structured protocols，与 Centaurian systems，which deeply integrate human and AI capabilities to form unified decision-making entities，并引入了通信空间框架，包括 surface, observation, and computation layers，使用 colored Petri nets 和 high-level reconfigurable networks 来形式化这些互动。最终，该框架为自主机器人、人类参与决策和 AI 驱动认知架构提供实际应用基础，推动了平衡结构化协调与新兴行为的混合智能系统发展。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.MA",
      "comment": "27 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.14000v1",
      "published_date": "2025-02-19 07:55:34 UTC",
      "updated_date": "2025-02-19 07:55:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:02:10.216288"
    },
    {
      "arxiv_id": "2502.14913v1",
      "title": "OpenSearch-SQL: Enhancing Text-to-SQL with Dynamic Few-shot and Consistency Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Xiangjin Xie",
        "Guangwei Xu",
        "Lingyan Zhao",
        "Ruijie Guo"
      ],
      "abstract": "Although multi-agent collaborative Large Language Models (LLMs) have achieved\nsignificant breakthroughs in the Text-to-SQL task, their performance is still\nconstrained by various factors. These factors include the incompleteness of the\nframework, failure to follow instructions, and model hallucination problems. To\naddress these problems, we propose OpenSearch-SQL, which divides the\nText-to-SQL task into four main modules: Preprocessing, Extraction, Generation,\nand Refinement, along with an Alignment module based on a consistency alignment\nmechanism. This architecture aligns the inputs and outputs of agents through\nthe Alignment module, reducing failures in instruction following and\nhallucination. Additionally, we designed an intermediate language called\nSQL-Like and optimized the structured CoT based on SQL-Like. Meanwhile, we\ndeveloped a dynamic few-shot strategy in the form of self-taught Query-CoT-SQL.\nThese methods have significantly improved the performance of LLMs in the\nText-to-SQL task.\n  In terms of model selection, we directly applied the base LLMs without any\npost-training, thereby simplifying the task chain and enhancing the framework's\nportability. Experimental results show that OpenSearch-SQL achieves an\nexecution accuracy(EX) of 69.3% on the BIRD development set, 72.28% on the test\nset, and a reward-based validity efficiency score (R-VES) of 69.36%, with all\nthree metrics ranking first at the time of submission. These results\ndemonstrate the comprehensive advantages of the proposed method in both\neffectiveness and efficiency.",
      "tldr_zh": "该论文提出OpenSearch-SQL框架，以动态few-shot策略和一致性对齐机制提升Text-to-SQL任务的性能，针对多智能体LLMs的框架不完整、指令不遵守和模型幻觉等问题。框架将任务分为Preprocessing、Extraction、Generation、Refinement和Alignment模块，引入SQL-Like中间语言并优化结构化CoT（Chain-of-Thought），同时采用self-taught Query-CoT-SQL动态few-shot方法，提高了模型的准确性和可移植性。实验结果显示，在BIRD开发集上执行准确率（EX）达69.3%，测试集为72.28%，奖励-based有效性效率分数（R-VES）为69.36%，在提交时排名第一，证明了该方法的全面优势。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "15 pages",
      "pdf_url": "http://arxiv.org/pdf/2502.14913v1",
      "published_date": "2025-02-19 07:51:50 UTC",
      "updated_date": "2025-02-19 07:51:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:02:22.806792"
    },
    {
      "arxiv_id": "2502.13502v2",
      "title": "PLDR-LLMs Learn A Generalizable Tensor Operator That Can Replace Its Own Deep Neural Net At Inference",
      "title_zh": "翻译失败",
      "authors": [
        "Burc Gokden"
      ],
      "abstract": "We show that Large Language Model from Power Law Decoder Representations\n(PLDR-LLM) is a foundational model whose deductive outputs are invariant\ntensors up to a small perturbation. PLDR-LLM learns a singularity condition for\nthe deductive outputs that enable the once-inferred energy-curvature tensor\n$\\mathbf{G}_{LM}$ to replace the deep neural network of power law graph\nattention (PLGA) generating the deductive outputs at inference. We demonstrate\nthat a cache for $\\mathbf{G}_{LM}$ (G-cache) and KV-cache can be implemented in\na straightforward manner to improve the inference time. The invariance and\ngeneralizable nature of deductive outputs is at a very high fidelity where\ndeductive outputs have same RMSE and determinant values up to 15 decimal places\nafter caching, and zero-shot benchmark scores remain unchanged. Ablation\nstudies show that learned deductive outputs have distinct loss and accuracy\ncharacteristics from models pretrained with transferred, randomly initialized\nor identity tensors as a constant tensor operator and an LLM with scaled-dot\nproduct attention (SDPA) is a special case of PLDR-LLM where $\\mathbf{G}_{LM}$\nis predefined as identity. The observed invariance characteristic introduces a\nnovel asymmetry between training and inference phases with caching. We outline\nobserved common characteristics of the deductive outputs for the learned\nsingularity condition. We provide an implementation of a training and inference\nframework for PLDR-LLM with KV-cache and G-cache.",
      "tldr_zh": "本研究展示了 PLDR-LLMs 是一种基础模型，其推导输出是近似不变的张量，能够通过学习一个奇异性条件，让推导出的能量-曲率张量 \\(\\mathbf{G}_{LM}\\) 在推理阶段替换原有的深度神经网络（PLGA），从而实现高效推理。\n通过引入 G-cache 和 KV-cache 机制，研究实现了直观的缓存策略，提高了推理速度，且推导输出保持高度不变性，RMSE 和行列式值精确到 15 位小数，零样本基准分数不变。\n消融研究表明，PLDR-LLMs 的推导输出具有独特损失和准确性特征，与使用转移初始化、随机初始化或恒定张量操作符的模型不同，并揭示了训练和推理阶段的非对称性。\n这项工作提供了 PLDR-LLMs 的完整训练和推理框架，强调了其在高效、可解释性方面的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "15 pages, 1 figure, 12 tables, more ablation data included",
      "pdf_url": "http://arxiv.org/pdf/2502.13502v2",
      "published_date": "2025-02-19 07:43:36 UTC",
      "updated_date": "2025-02-22 22:32:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:02:34.843995"
    },
    {
      "arxiv_id": "2502.13499v1",
      "title": "Hidden Darkness in LLM-Generated Designs: Exploring Dark Patterns in Ecommerce Web Components Generated by LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Ziwei Chen",
        "Jiawen Shen",
        "Luna",
        "Kristen Vaccaro"
      ],
      "abstract": "Recent work has highlighted the risks of LLM-generated content for a wide\nrange of harmful behaviors, including incorrect and harmful code. In this work,\nwe extend this by studying whether LLM-generated web design contains dark\npatterns. This work evaluated designs of ecommerce web components generated by\nfour popular LLMs: Claude, GPT, Gemini, and Llama. We tested 13 commonly used\necommerce components (e.g., search, product reviews) and used them as prompts\nto generate a total of 312 components across all models. Over one-third of\ngenerated components contain at least one dark pattern. The majority of dark\npattern strategies involve hiding crucial information, limiting users' actions,\nand manipulating them into making decisions through a sense of urgency. Dark\npatterns are also more frequently produced in components that are related to\ncompany interests. These findings highlight the need for interventions to\nprevent dark patterns during front-end code generation with LLMs and emphasize\nthe importance of expanding ethical design education to a broader audience.",
      "tldr_zh": "本研究探讨了大型语言模型(LLM)生成电商网页组件中暗模式(dark patterns)的风险，评估了Claude、GPT、Gemini和Llama四个流行LLM生成的312个组件（基于13种常用电商元素，如搜索和产品评论）。结果显示，超过三分之一的生成组件包含至少一种暗模式，主要策略包括隐藏关键信息、限制用户操作以及通过紧迫感操纵决策，且这些模式更常出现在与公司利益相关的组件中。该发现突出了在LLM前端代码生成中预防暗模式的必要性，并强调扩展道德设计教育的重要性，以促进更负责任的AI应用。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "comment": "15 pages",
      "pdf_url": "http://arxiv.org/pdf/2502.13499v1",
      "published_date": "2025-02-19 07:35:07 UTC",
      "updated_date": "2025-02-19 07:35:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:02:46.495982"
    },
    {
      "arxiv_id": "2502.13998v1",
      "title": "A Baseline Method for Removing Invisible Image Watermarks using Deep Image Prior",
      "title_zh": "翻译失败",
      "authors": [
        "Hengyue Liang",
        "Taihui Li",
        "Ju Sun"
      ],
      "abstract": "Image watermarks have been considered a promising technique to help detect\nAI-generated content, which can be used to protect copyright or prevent fake\nimage abuse. In this work, we present a black-box method for removing invisible\nimage watermarks, without the need of any dataset of watermarked images or any\nknowledge about the watermark system. Our approach is simple to implement:\ngiven a single watermarked image, we regress it by deep image prior (DIP). We\nshow that from the intermediate steps of DIP one can reliably find an evasion\nimage that can remove invisible watermarks while preserving high image quality.\nDue to its unique working mechanism and practical effectiveness, we advocate\nincluding DIP as a baseline invasion method for benchmarking the robustness of\nwatermarking systems. Finally, by showing the limited ability of DIP and other\nexisting black-box methods in evading training-based visible watermarks, we\ndiscuss the positive implications on the practical use of training-based\nvisible watermarks to prevent misinformation abuse.",
      "tldr_zh": "这篇论文提出了一种使用 Deep Image Prior (DIP) 的黑盒方法，用于移除不可见图像水印，而无需任何水印图像数据集或水印系统知识。方法通过对水印图像进行回归，并利用 DIP 的中间步骤生成一个 evasion 图像，从而有效去除水印同时保持高图像质量。作者建议将 DIP 作为基准入侵方法，用于评估水印系统的鲁棒性。论文还讨论了该方法在 evasion 训练-based 可见水印时的有限效果，并强调了训练-based 可见水印在防止假图像滥用方面的实际价值。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CR",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.13998v1",
      "published_date": "2025-02-19 07:30:19 UTC",
      "updated_date": "2025-02-19 07:30:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:02:58.032075"
    },
    {
      "arxiv_id": "2502.13497v2",
      "title": "Towards Geo-Culturally Grounded LLM Generations",
      "title_zh": "翻译失败",
      "authors": [
        "Piyawat Lertvittayakumjorn",
        "David Kinney",
        "Vinodkumar Prabhakaran",
        "Donald Martin Jr.",
        "Sunipa Dev"
      ],
      "abstract": "Generative large language models (LLMs) have been demonstrated to have gaps\nin diverse, cultural knowledge across the globe. We investigate the effect of\nretrieval augmented generation and search-grounding techniques on the ability\nof LLMs to display familiarity with a diverse range of national cultures.\nSpecifically, we compare the performance of standard LLMs, LLMs augmented with\nretrievals from a bespoke knowledge base (i.e., KB grounding), and LLMs\naugmented with retrievals from a web search (i.e., search grounding) on a\nseries of cultural familiarity benchmarks. We find that search grounding\nsignificantly improves the LLM performance on multiple-choice benchmarks that\ntest propositional knowledge (e.g., the norms, artifacts, and institutions of\nnational cultures), while KB grounding's effectiveness is limited by inadequate\nknowledge base coverage and a suboptimal retriever. However, search grounding\nalso increases the risk of stereotypical judgments by language models, while\nfailing to improve evaluators' judgments of cultural familiarity in a human\nevaluation with adequate statistical power. These results highlight the\ndistinction between propositional knowledge about a culture and open-ended\ncultural fluency when it comes to evaluating the cultural familiarity of\ngenerative LLMs.",
      "tldr_zh": "本研究探讨了生成式大型语言模型（LLMs）在全球多样文化知识上的不足，并评估了检索增强生成（retrieval augmented generation）和搜索基础（search grounding）技术对 LLMs 显示国家文化熟悉度的影响。研究比较了标准 LLMs、用自定义知识库增强的 KB grounding，以及用网络搜索增强的 search grounding，在多项选择文化熟悉度基准上的表现，结果显示 search grounding 显著提高了对命题知识（如文化规范、文物和机构）的测试性能，但 KB grounding 受限于知识库覆盖不足和检索器不佳。此外，search grounding 增加了语言模型做出刻板判断的风险，并在人类评估中未能提升整体文化熟悉度，这些发现突出了命题知识与开放式文化流畅性在评估 LLMs 文化熟悉度时的关键区别。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.13497v2",
      "published_date": "2025-02-19 07:29:58 UTC",
      "updated_date": "2025-02-20 06:38:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:03:10.353750"
    },
    {
      "arxiv_id": "2502.15806v1",
      "title": "A Mousetrap: Fooling Large Reasoning Models for Jailbreak with Chain of Iterative Chaos",
      "title_zh": "翻译失败",
      "authors": [
        "Yang Yao",
        "Xuan Tong",
        "Ruofan Wang",
        "Yixu Wang",
        "Lujundong Li",
        "Liang Liu",
        "Yan Teng",
        "Yingchun Wang"
      ],
      "abstract": "Large Reasoning Models (LRMs) have significantly advanced beyond traditional\nLarge Language Models (LLMs) with their exceptional logical reasoning\ncapabilities, yet these improvements introduce heightened safety risks. When\nsubjected to jailbreak attacks, their ability to generate more targeted and\norganized content can lead to greater harm. Although some studies claim that\nreasoning enables safer LRMs against existing LLM attacks, they overlook the\ninherent flaws within the reasoning process itself. To address this gap, we\npropose the first jailbreak attack targeting LRMs, exploiting their unique\nvulnerabilities stemming from the advanced reasoning capabilities.\nSpecifically, we introduce a Chaos Machine, a novel component to transform\nattack prompts with diverse one-to-one mappings. The chaos mappings iteratively\ngenerated by the machine are embedded into the reasoning chain, which\nstrengthens the variability and complexity and also promotes a more robust\nattack. Based on this, we construct the Mousetrap framework, which makes\nattacks projected into nonlinear-like low sample spaces with mismatched\ngeneralization enhanced. Also, due to the more competing objectives, LRMs\ngradually maintain the inertia of unpredictable iterative reasoning and fall\ninto our trap. Success rates of the Mousetrap attacking o1-mini, claude-sonnet\nand gemini-thinking are as high as 96%, 86% and 98% respectively on our toxic\ndataset Trotter. On benchmarks such as AdvBench, StrongREJECT, and HarmBench,\nattacking claude-sonnet, well-known for its safety, Mousetrap can astonishingly\nachieve success rates of 87.5%, 86.58% and 93.13% respectively. Attention: This\npaper contains inappropriate, offensive and harmful content.",
      "tldr_zh": "本文提出了一种针对 Large Reasoning Models (LRMs) 的首创越狱攻击框架 Mousetrap，利用 Chain of Iterative Chaos 来利用模型的推理能力漏洞。Mousetrap 引入 Chaos Machine 组件，通过迭代生成的多样单对一映射嵌入推理链，提高攻击的变异性和复杂性，导致 LRMs 在处理竞争目标时陷入不可预测的迭代惯性。实验结果显示，该框架在 Trotter 数据集上对 o1-mini、claude-sonnet 和 gemini-thinking 的成功率分别高达96%、86%和98%，而在 AdvBench、StrongREJECT 和 HarmBench 等基准上，对 claude-sonnet 的成功率超过86%，揭示了 LRMs 的潜在安全风险。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.15806v1",
      "published_date": "2025-02-19 07:23:36 UTC",
      "updated_date": "2025-02-19 07:23:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:03:23.620426"
    },
    {
      "arxiv_id": "2502.13490v1",
      "title": "What are Models Thinking about? Understanding Large Language Model Hallucinations \"Psychology\" through Model Inner State Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Peiran Wang",
        "Yang Liu",
        "Yunfei Lu",
        "Jue Hong",
        "Ye Wu"
      ],
      "abstract": "Large language model (LLM) systems suffer from the models' unstable ability\nto generate valid and factual content, resulting in hallucination generation.\nCurrent hallucination detection methods heavily rely on out-of-model\ninformation sources, such as RAG to assist the detection, thus bringing heavy\nadditional latency. Recently, internal states of LLMs' inference have been\nwidely used in numerous research works, such as prompt injection detection,\netc. Considering the interpretability of LLM internal states and the fact that\nthey do not require external information sources, we introduce such states into\nLLM hallucination detection. In this paper, we systematically analyze different\ninternal states' revealing features during inference forward and\ncomprehensively evaluate their ability in hallucination detection.\nSpecifically, we cut the forward process of a large language model into three\nstages: understanding, query, generation, and extracting the internal state\nfrom these stages. By analyzing these states, we provide a deep understanding\nof why the hallucinated content is generated and what happened in the internal\nstate of the models. Then, we introduce these internal states into\nhallucination detection and conduct comprehensive experiments to discuss the\nadvantages and limitations.",
      "tldr_zh": "这篇论文探讨了 Large Language Model (LLM) 幻觉问题的成因，通过分析模型内部状态来理解其“心理学”。作者将 LLM 的前向过程分为理解、查询和生成三个阶段，并提取这些阶段的内部状态，以揭示幻觉生成的原因，同时避免依赖外部信息源如 RAG，从而减少延迟。实验结果显示，这种基于内部状态的检测方法在幻觉识别上表现出优势，但也存在某些局限性，为更可解释的 LLM 应用提供了新insights。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.13490v1",
      "published_date": "2025-02-19 07:23:18 UTC",
      "updated_date": "2025-02-19 07:23:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:03:33.508562"
    },
    {
      "arxiv_id": "2502.13487v2",
      "title": "Transferring Textual Preferences to Vision-Language Understanding through Model Merging",
      "title_zh": "翻译失败",
      "authors": [
        "Chen-An Li",
        "Tzu-Han Lin",
        "Yun-Nung Chen",
        "Hung-yi Lee"
      ],
      "abstract": "Large vision-language models (LVLMs) perform outstandingly across various\nmultimodal tasks. However, their ability to evaluate generated content remains\nlimited, and training vision-language reward models (VLRMs) with preference\ndata is computationally expensive. This paper explores a training-free\nalternative by merging text-based reward models (RMs) with LVLMs to create\nVLRMs. Our approach shows that integrating these models leads to improved\nperformance over LVLMs' scoring and text-based RMs, offering an efficient\nmethod for incorporating textual preferences into LVLMs.",
      "tldr_zh": "本文提出了一种训练-free 方法，通过模型合并（Model Merging）将文本-based 奖励模型（RMs）与大型视觉语言模型（LVLMs）整合，创建视觉语言奖励模型（VLRMs），以提升 LVLMs 在评估生成内容方面的能力。该方法避免了使用偏好数据训练 VLRMs 的高计算开销，并展示了整合后模型的评分性能优于原 LVLMs 和文本-based RMs。总体而言，这为高效地将文本偏好转移到视觉语言理解中提供了新途径。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to ACL 2025 main",
      "pdf_url": "http://arxiv.org/pdf/2502.13487v2",
      "published_date": "2025-02-19 07:20:07 UTC",
      "updated_date": "2025-05-22 10:28:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:03:48.158824"
    },
    {
      "arxiv_id": "2502.13480v1",
      "title": "Astra: Efficient and Money-saving Automatic Parallel Strategies Search on Heterogeneous GPUs",
      "title_zh": "翻译失败",
      "authors": [
        "Peiran Wang",
        "Haibing Li",
        "Fu Haohan",
        "Shiyong Li",
        "Yanpeng Wang",
        "Dou Shen"
      ],
      "abstract": "In this paper, we introduce an efficient and money-saving automatic parallel\nstrategies search framework on heterogeneous GPUs: Astra. First, Astra searches\nfor the efficiency-optimal parallel strategy in both GPU configurations search\nspace (GPU types and GPU numbers) and parallel parameters search space. Then,\nAstra also provides the solution on heterogeneous GPUs by mathematically\nmodeling the time consumption of heterogeneous training. At last, Astra is the\nfirst to propose the automatic parallel strategy search on money-saving. The\nexperiment results demonstrate that Astra can achieve better throughput than\nexpert-designed strategies. The search time cost for Astra can also be limited\nto 1.27 seconds in a single-GPU setting and less than 1.35 minutes in a\nheterogeneous-GPU setting on average with an accuracy of over 95%.",
      "tldr_zh": "本研究引入了Astra框架，这是一个高效且节省成本的自动并行策略搜索系统，针对heterogeneous GPUs环境优化训练策略。Astra首先在GPU configurations（包括GPU类型和数量）和parallel parameters搜索空间中寻找效率最优策略，并通过数学建模计算heterogeneous training的时间消耗，同时首次提出基于money-saving的自动搜索方法。实验结果显示，Astra的吞吐量优于专家设计的策略，且搜索时间在单GPU设置下平均仅1.27秒，在heterogeneous-GPU设置下不到1.35分钟，准确率超过95%。",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.13480v1",
      "published_date": "2025-02-19 07:08:37 UTC",
      "updated_date": "2025-02-19 07:08:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:03:58.716147"
    },
    {
      "arxiv_id": "2502.14911v1",
      "title": "Batayan: A Filipino NLP benchmark for evaluating Large Language Models",
      "title_zh": "Batayan：用于评估大语言模型的菲律宾自然语言处理基准",
      "authors": [
        "Jann Railey Montalan",
        "Jimson Paulo Layacan",
        "David Demitri Africa",
        "Richell Isaiah Flores",
        "Michael T. Lopez II",
        "Theresa Denise Magsajo",
        "Anjanette Cayabyab",
        "William Chandra Tjhi"
      ],
      "abstract": "Recent advances in large language models (LLMs) have demonstrated remarkable\ncapabilities on widely benchmarked high-resource languages; however, linguistic\nnuances of under-resourced languages remain unexplored. We introduce Batayan, a\nholistic Filipino benchmark designed to systematically evaluate LLMs across\nthree key natural language processing (NLP) competencies: understanding,\nreasoning, and generation. Batayan consolidates eight tasks, covering both\nTagalog and code-switched Taglish utterances. Our rigorous,\nnative-speaker-driven annotation process ensures fluency and authenticity to\nthe complex morphological and syntactic structures of Filipino, alleviating a\npervasive translationese bias in existing Filipino corpora. We report empirical\nresults on a variety of multilingual LLMs, highlighting significant performance\ngaps that signal the under-representation of Filipino in pretraining corpora,\nthe unique hurdles in modeling Filipino's rich morphology and construction, and\nthe importance of explicit Filipino language support and instruction tuning.\nMoreover, we discuss the practical challenges encountered in dataset\nconstruction and propose principled solutions for building culturally and\nlinguistically-faithful resources in under-represented languages. We also\nprovide a public benchmark and leaderboard as a clear foundation for iterative,\ncommunity-driven progress in Filipino NLP.",
      "tldr_zh": "该研究引入了 Batayan，这是一个全面的菲律宾语 NLP 基准，用于系统评估 Large Language Models (LLMs) 在理解、推理和生成方面的能力。Batayan 整合了八个任务，涵盖 Tagalog 和代码切换的 Taglish 语言，并通过本土说话者驱动的注释过程确保语言的流畅性和真实性，避免了现有语料库的翻译偏差。实验结果显示，多语言 LLMs 在菲律宾语上存在显著性能差距，突出了该语言在预训练语料库中的 underrepresented 问题，以及建模其丰富形态和结构的独特挑战。论文还讨论了数据集构建的实际难题，并提出解决方案，同时提供公共基准和排行榜，以推动菲律宾 NLP 的社区驱动进步。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Submitted to ACL 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.14911v1",
      "published_date": "2025-02-19 07:03:15 UTC",
      "updated_date": "2025-02-19 07:03:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:04:13.506120"
    },
    {
      "arxiv_id": "2502.15805v1",
      "title": "FragFM: Efficient Fragment-Based Molecular Generation via Discrete Flow Matching",
      "title_zh": "翻译失败",
      "authors": [
        "Joongwon Lee",
        "Seonghwan Kim",
        "Wou Youn Kim"
      ],
      "abstract": "We introduce FragFM, a novel fragment-based discrete flow matching framework\nfor molecular graph generation.FragFM generates molecules at the fragment\nlevel, leveraging a coarse-to-fine autoencoding mechanism to reconstruct\natom-level details. This approach reduces computational complexity while\nmaintaining high chemical validity, enabling more efficient and scalable\nmolecular generation. We benchmark FragFM against state-of-the-art diffusion-\nand flow-based models on standard molecular generation benchmarks and natural\nproduct datasets, demonstrating superior performance in validity, property\ncontrol, and sampling efficiency. Notably, FragFM achieves over 99\\% validity\nwith significantly fewer sampling steps, improving scalability while preserving\nmolecular diversity. These results highlight the potential of fragment-based\ngenerative modeling for large-scale, property-aware molecular design, paving\nthe way for more efficient exploration of chemical space.",
      "tldr_zh": "本研究引入了 FragFM，一种基于片段的离散流匹配（Discrete Flow Matching）框架，用于高效的分子图生成。该框架在片段级别生成分子，并采用粗到细的自动编码机制来重建原子级细节，从而降低计算复杂性，同时保持高化学有效性。在标准分子生成基准和自然产物数据集上的实验中，FragFM 优于现有扩散和流模型，实现了超过 99% 的有效率、更好的属性控制以及显著减少的采样步骤。这些结果突显了基于片段的生成建模在大规模、属性感知分子设计中的潜力，推动化学空间的更高效探索。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.chem-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "19 pages, 11 figures, under review",
      "pdf_url": "http://arxiv.org/pdf/2502.15805v1",
      "published_date": "2025-02-19 07:01:00 UTC",
      "updated_date": "2025-02-19 07:01:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:04:22.777940"
    },
    {
      "arxiv_id": "2502.13476v1",
      "title": "Integration of Agentic AI with 6G Networks for Mission-Critical Applications: Use-case and Challenges",
      "title_zh": "翻译失败",
      "authors": [
        "Sunder Ali Khowaja",
        "Kapal Dev",
        "Muhammad Salman Pathan",
        "Engin Zeydan",
        "Merouane Debbah"
      ],
      "abstract": "We are in a transformative era, and advances in Artificial Intelligence (AI),\nespecially the foundational models, are constantly in the news. AI has been an\nintegral part of many applications that rely on automation for service\ndelivery, and one of them is mission-critical public safety applications. The\nproblem with AI-oriented mission-critical applications is the humanin-the-loop\nsystem and the lack of adaptability to dynamic conditions while maintaining\nsituational awareness. Agentic AI (AAI) has gained a lot of attention recently\ndue to its ability to analyze textual data through a contextual lens while\nquickly adapting to conditions. In this context, this paper proposes an AAI\nframework for mission-critical applications. We propose a novel framework with\na multi-layer architecture to realize the AAI. We also present a detailed\nimplementation of AAI layer that bridges the gap between network infrastructure\nand missioncritical applications. Our preliminary analysis shows that the AAI\nreduces initial response time by 5.6 minutes on average, while alert generation\ntime is reduced by 15.6 seconds on average and resource allocation is improved\nby up to 13.4%. We also show that the AAI methods improve the number of\nconcurrent operations by 40, which reduces the recovery time by up to 5.2\nminutes. Finally, we highlight some of the issues and challenges that need to\nbe considered when implementing AAI frameworks.",
      "tldr_zh": "该论文探讨了 Agentic AI (AAI) 与 6G 网络的整合，以提升任务关键型应用（如公共安全）的适应性和效率。作者提出一个多层架构框架，包括一个桥接网络基础设施与应用层的 AAI 层，能够快速分析文本数据并适应动态条件。初步分析显示，该框架平均减少初始响应时间 5.6 分钟、警报生成时间 15.6 秒，并提高资源分配 13.4% 及并发操作 40 次，从而缩短恢复时间 5.2 分钟；最后，论文指出了实施 AAI 框架时面临的挑战，如人类在循环系统的整合和动态适应问题。",
      "categories": [
        "cs.AI",
        "cs.NI"
      ],
      "primary_category": "cs.AI",
      "comment": "FEMA\n  [https://www.fema.gov/openfema-data-page/disaster-declarations-summaries-v2]\n  National Oceanic and Atmospheric Administration\n  [https://www.ncdc.noaa.gov/stormevents/details.jsp] packages Pytorch\n  [https://pytorch.org/] RLib [https://docs.ray.io/en/latest/rllib/index.html]\n  Neo4j [https://neo4j.com/] Apache Kafka [https://kafka.apache.org/]",
      "pdf_url": "http://arxiv.org/pdf/2502.13476v1",
      "published_date": "2025-02-19 07:00:53 UTC",
      "updated_date": "2025-02-19 07:00:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:04:34.989921"
    },
    {
      "arxiv_id": "2502.13475v2",
      "title": "LLM should think and action as a human",
      "title_zh": "翻译失败",
      "authors": [
        "Haun Leung",
        "ZiNan Wang"
      ],
      "abstract": "It is popular lately to train large language models to be used as chat\nassistants, but in the conversation between the user and the chat assistant,\nthere are prompts, require multi-turns between the chat assistant and the user.\nHowever, there are a number of issues with the multi-turns conversation: The\nresponse of the chat assistant is prone to errors and can't help users achieve\ntheir goals, and as the number of conversation turns increases, the probability\nof errors will also increase; It is difficult for chat assistant to generate\nresponses with different processes based on actual needs for the same prompt;\nChat assistant require the use of tools, but the current approach is not\nelegant and efficient, and the number of tool calls is limited. The main reason\nfor these issues is that large language models don't have the thinking ability\nas a human, lack the reasoning ability and planning ability, and lack the\nability to execute plans. To solve these issues, we propose a thinking method\nbased on a built-in chain of thought: In the multi-turns conversation, for each\nuser prompt, the large language model thinks based on elements such as chat\nhistory, thinking context, action calls, memory and knowledge, makes detailed\nreasoning and planning, and actions according to the plan. We also explored how\nthe large language model enhances thinking ability through this thinking\nmethod: Collect training datasets according to the thinking method and fine\ntune the large language model through supervised learning; Train a consistency\nreward model and use it as a reward function to fine tune the large language\nmodel using reinforcement learning, and the reinforced large language model\noutputs according to this way of thinking. Our experimental results show that\nthe reasoning ability and planning ability of the large language model are\nenhanced, and the issues in the multi-turns conversation are solved.",
      "tldr_zh": "该论文指出，现有的Large Language Models (LLMs) 在多轮对话中存在问题，如响应易出错、难以帮助用户实现目标、生成响应缺乏灵活性，以及工具调用不优雅，这些主要源于LLMs 缺乏人类的思考、推理、规划和执行能力。为解决这些问题，研究提出了一种基于内置Chain of Thought的思考方法，让LLMs 在每个用户提示时，通过聊天历史、思考上下文、行动调用、记忆和知识进行详细推理、规划并执行行动。论文通过收集训练数据集并采用监督学习和强化学习（如训练一致性奖励模型）来增强LLMs 的思考能力。实验结果显示，该方法显著提升了LLMs 的推理和规划能力，成功解决了多轮对话中的关键问题。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "12 pages, 4 figures, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2502.13475v2",
      "published_date": "2025-02-19 06:58:34 UTC",
      "updated_date": "2025-02-20 21:40:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:04:48.332123"
    },
    {
      "arxiv_id": "2502.13471v1",
      "title": "Some Insights of Construction of Feature Graph to Learn Pairwise Feature Interactions with Graph Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Phaphontee Yamchote",
        "Saw Nay Htet Win",
        "Chainarong Amornbunchornvej",
        "Thanapon Noraset"
      ],
      "abstract": "Feature interaction is crucial in predictive machine learning models, as it\ncaptures the relationships between features that influence model performance.\nIn this work, we focus on pairwise interactions and investigate their\nimportance in constructing feature graphs for Graph Neural Networks (GNNs).\nRather than proposing new methods, we leverage existing GNN models and tools to\nexplore the relationship between feature graph structures and their\neffectiveness in modeling interactions. Through experiments on synthesized\ndatasets, we uncover that edges between interacting features are important for\nenabling GNNs to model feature interactions effectively. We also observe that\nincluding non-interaction edges can act as noise, degrading model performance.\nFurthermore, we provide theoretical support for sparse feature graph selection\nusing the Minimum Description Length (MDL) principle. We prove that feature\ngraphs retaining only necessary interaction edges yield a more efficient and\ninterpretable representation than complete graphs, aligning with Occam's Razor.\n  Our findings offer both theoretical insights and practical guidelines for\ndesigning feature graphs that improve the performance and interpretability of\nGNN models.",
      "tldr_zh": "本研究探讨了在Graph Neural Networks (GNNs)中构建特征图以学习成对特征交互的重要性，通过现有模型和工具进行实验分析。实验结果显示，特征图中连接交互特征的边对有效建模交互至关重要，而非交互边的加入可能作为噪声，降低模型性能。作者利用Minimum Description Length (MDL)原则提供理论支持，证明保留必要交互边的稀疏特征图比完整图更高效且可解释，符合Occam's Razor。该工作为设计更具性能和可解释性的GNN模型提供了实用指导。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML",
        "68T07 68T07 68T07",
        "I.2.6"
      ],
      "primary_category": "cs.LG",
      "comment": "This is the draft before submitting to any journal",
      "pdf_url": "http://arxiv.org/pdf/2502.13471v1",
      "published_date": "2025-02-19 06:47:23 UTC",
      "updated_date": "2025-02-19 06:47:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:05:02.844394"
    },
    {
      "arxiv_id": "2502.13994v2",
      "title": "Generative Detail Enhancement for Physically Based Materials",
      "title_zh": "翻译失败",
      "authors": [
        "Saeed Hadadan",
        "Benedikt Bitterli",
        "Tizian Zeltner",
        "Jan Novák",
        "Fabrice Rousselle",
        "Jacob Munkberg",
        "Jon Hasselgren",
        "Bartlomiej Wronski",
        "Matthias Zwicker"
      ],
      "abstract": "We present a tool for enhancing the detail of physically based materials\nusing an off-the-shelf diffusion model and inverse rendering. Our goal is to\nenhance the visual fidelity of materials with detail that is often tedious to\nauthor, by adding signs of wear, aging, weathering, etc. As these appearance\ndetails are often rooted in real-world processes, we leverage a generative\nimage model trained on a large dataset of natural images with corresponding\nvisuals in context. Starting with a given geometry, UV mapping, and basic\nappearance, we render multiple views of the object. We use these views,\ntogether with an appearance-defining text prompt, to condition a diffusion\nmodel. The details it generates are then backpropagated from the enhanced\nimages to the material parameters via inverse differentiable rendering. For\ninverse rendering to be successful, the generated appearance has to be\nconsistent across all the images. We propose two priors to address the\nmulti-view consistency of the diffusion model. First, we ensure that the\ninitial noise that seeds the diffusion process is itself consistent across\nviews by integrating it from a view-independent UV space. Second, we enforce\ngeometric consistency by biasing the attention mechanism via a projective\nconstraint so that pixels attend strongly to their corresponding pixel\nlocations in other views. Our approach does not require any training or\nfinetuning of the diffusion model, is agnostic of the material model used, and\nthe enhanced material properties, i.e., 2D PBR textures, can be further edited\nby artists. This project is available at https://generative-detail.github.io.",
      "tldr_zh": "本研究提出了一种生成式细节增强工具，使用现成的diffusion model和inverse rendering来提升physically based materials的视觉保真度，专注于添加磨损、老化或风化等真实世界细节。方法包括从给定几何、UV映射和基本外观渲染多视图图像，然后通过文本提示调节diffusion model生成细节，并利用inverse differentiable rendering将这些细节回传到材料参数中。为确保多视图一致性，引入了两个priors：一是从视图无关的UV空间集成初始噪声，二是通过projective constraint偏置注意力机制以保持几何一致。该方法无需训练或微调diffusion model，与材料模型无关，且生成的2D PBR textures可供艺术家进一步编辑。",
      "categories": [
        "cs.GR",
        "cs.AI"
      ],
      "primary_category": "cs.GR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.13994v2",
      "published_date": "2025-02-19 06:39:51 UTC",
      "updated_date": "2025-05-07 04:33:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:05:13.263810"
    },
    {
      "arxiv_id": "2502.14910v1",
      "title": "EvoP: Robust LLM Inference via Evolutionary Pruning",
      "title_zh": "EvoP：通过进化剪枝实现鲁棒的大语言模型推理",
      "authors": [
        "Shangyu Wu",
        "Hongchao Du",
        "Ying Xiong",
        "Shuai Chen",
        "Tei-wei Kuo",
        "Nan Guan",
        "Chun Jason Xue"
      ],
      "abstract": "Large Language Models (LLMs) have achieved remarkable success in natural\nlanguage processing tasks, but their massive size and computational demands\nhinder their deployment in resource-constrained environments. Existing\nstructured pruning methods address this issue by removing redundant structures\n(e.g., elements, channels, layers) from the model. However, these methods\nemploy a heuristic pruning strategy, which leads to suboptimal performance.\nBesides, they also ignore the data characteristics when pruning the model.\n  To overcome these limitations, we propose EvoP, an evolutionary pruning\nframework for robust LLM inference. EvoP first presents a cluster-based\ncalibration dataset sampling (CCDS) strategy for creating a more diverse\ncalibration dataset. EvoP then introduces an evolutionary pruning pattern\nsearching (EPPS) method to find the optimal pruning pattern. Compared to\nexisting structured pruning techniques, EvoP achieves the best performance\nwhile maintaining the best efficiency. Experiments across different LLMs and\ndifferent downstream tasks validate the effectiveness of the proposed EvoP,\nmaking it a practical and scalable solution for deploying LLMs in real-world\napplications.",
      "tldr_zh": "本文提出 EvoP，一种基于进化的修剪框架，用于提升大型语言模型(LLMs)的鲁棒性推理性能，以解决模型规模大和计算需求高的部署问题。EvoP 包括基于聚类的校准数据集采样(CCDS)策略来创建更丰富的数据集，以及进化修剪模式搜索(EPPS)方法来寻找最佳修剪模式，从而克服现有结构化修剪方法的启发式局限和数据特性忽略。实验在不同 LLMs 和下游任务上验证了 EvoP 的有效性，实现最佳性能和效率，为资源受限环境中的 LLM 部署提供了实用、可扩展的解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14910v1",
      "published_date": "2025-02-19 06:33:59 UTC",
      "updated_date": "2025-02-19 06:33:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:05:24.608792"
    },
    {
      "arxiv_id": "2502.13465v1",
      "title": "HawkBench: Investigating Resilience of RAG Methods on Stratified Information-Seeking Tasks",
      "title_zh": "HawkBench：研究 RAG 方法在分层信息搜索任务中的弹性",
      "authors": [
        "Hongjin Qian",
        "Zheng Liu",
        "Chao Gao",
        "Yankai Wang",
        "Defu Lian",
        "Zhicheng Dou"
      ],
      "abstract": "In real-world information-seeking scenarios, users have dynamic and diverse\nneeds, requiring RAG systems to demonstrate adaptable resilience. To\ncomprehensively evaluate the resilience of current RAG methods, we introduce\nHawkBench, a human-labeled, multi-domain benchmark designed to rigorously\nassess RAG performance across categorized task types. By stratifying tasks\nbased on information-seeking behaviors, HawkBench provides a systematic\nevaluation of how well RAG systems adapt to diverse user needs.\n  Unlike existing benchmarks, which focus primarily on specific task types\n(mostly factoid queries) and rely on varying knowledge bases, HawkBench offers:\n(1) systematic task stratification to cover a broad range of query types,\nincluding both factoid and rationale queries, (2) integration of multi-domain\ncorpora across all task types to mitigate corpus bias, and (3) rigorous\nannotation for high-quality evaluation.\n  HawkBench includes 1,600 high-quality test samples, evenly distributed across\ndomains and task types. Using this benchmark, we evaluate representative RAG\nmethods, analyzing their performance in terms of answer quality and response\nlatency. Our findings highlight the need for dynamic task strategies that\nintegrate decision-making, query interpretation, and global knowledge\nunderstanding to improve RAG generalizability. We believe HawkBench serves as a\npivotal benchmark for advancing the resilience of RAG methods and their ability\nto achieve general-purpose information seeking.",
      "tldr_zh": "本文引入了 HawkBench，这是一个人类标注的多领域基准，用于系统评估 RAG 方法在分层信息搜索任务中的适应性和弹性。HawkBench 通过任务分层覆盖多种查询类型（如 factoid queries 和 rationale queries）、整合多领域语料以减少偏差，以及进行严格标注，确保高质量评估，共包含 1600 个均匀分布的测试样本。研究结果显示，现有 RAG 方法在答案质量和响应延迟方面表现不足，并强调需要动态任务策略，包括决策、查询解释和全局知识理解，以提升其泛化能力。HawkBench 作为关键基准，将推动 RAG 方法在真实信息搜索场景中的发展和优化。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "13 pages",
      "pdf_url": "http://arxiv.org/pdf/2502.13465v1",
      "published_date": "2025-02-19 06:33:39 UTC",
      "updated_date": "2025-02-19 06:33:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:05:36.994817"
    },
    {
      "arxiv_id": "2502.13464v1",
      "title": "Estimating Commonsense Plausibility through Semantic Shifts",
      "title_zh": "通过语义偏移估计常识合理性",
      "authors": [
        "Wanqing Cui",
        "Keping Bi",
        "Jiafeng Guo",
        "Xueqi Cheng"
      ],
      "abstract": "Commonsense plausibility estimation is critical for evaluating language\nmodels (LMs), yet existing generative approaches--reliant on likelihoods or\nverbalized judgments--struggle with fine-grained discrimination. In this paper,\nwe propose ComPaSS, a novel discriminative framework that quantifies\ncommonsense plausibility by measuring semantic shifts when augmenting sentences\nwith commonsense-related information. Plausible augmentations induce minimal\nshifts in semantics, while implausible ones result in substantial deviations.\nEvaluations on two types of fine-grained commonsense plausibility estimation\ntasks across different backbones, including LLMs and vision-language models\n(VLMs), show that ComPaSS consistently outperforms baselines. It demonstrates\nthe advantage of discriminative approaches over generative methods in\nfine-grained commonsense plausibility evaluation. Experiments also show that\n(1) VLMs yield superior performance to LMs, when integrated with ComPaSS, on\nvision-grounded commonsense tasks. (2) contrastive pre-training sharpens\nbackbone models' ability to capture semantic nuances, thereby further enhancing\nComPaSS.",
      "tldr_zh": "本论文提出 ComPaSS，一种新型区分式框架，通过测量语义偏移（semantic shifts）来评估常识合理性：即在句子中添加常识相关信息时，合理增补会引起最小语义变化，而不合理增补则导致显著偏差。相比现有基于似然或判断的生成式方法，ComPaSS 在两种细粒度常识合理性任务上表现出色，并在 LLMs 和 VLMs 等不同模型上均超越基线。实验结果显示，VLMs 在视觉基础常识任务中优于 LMs，且对比式预训练能增强模型捕捉语义细微差别的能力，从而进一步提升框架性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.13464v1",
      "published_date": "2025-02-19 06:31:06 UTC",
      "updated_date": "2025-02-19 06:31:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:05:48.470116"
    },
    {
      "arxiv_id": "2502.15804v2",
      "title": "FairKV: Balancing Per-Head KV Cache for Fast Multi-GPU Inference",
      "title_zh": "翻译失败",
      "authors": [
        "Bingzhe Zhao",
        "Ke Cheng",
        "Aomufei Yuan",
        "Yuxuan Tian",
        "Ruiguang Zhong",
        "Chengchen Hu",
        "Tong Yang",
        "Lian Yu"
      ],
      "abstract": "KV cache techniques in Transformer models aim to reduce redundant\ncomputations at the expense of substantially increased memory usage, making KV\ncache compression an important and popular research topic. Recently,\nstate-of-the-art KV cache compression methods implement imbalanced, per-head\nallocation algorithms that dynamically adjust the KV cache budget for each\nattention head, achieving excellent performance in single-GPU scenarios.\nHowever, we observe that such imbalanced compression leads to significant load\nimbalance when deploying multi-GPU inference, as some GPUs become overburdened\nwhile others remain underutilized. In this paper, we propose FairKV, a method\ndesigned to ensure fair memory usage among attention heads in systems employing\nimbalanced KV cache compression. The core technique of FairKV is Fair-Copying,\nwhich replicates a small subset of memory-intensive attention heads across GPUs\nusing data parallelism to mitigate load imbalance. Our experiments on popular\nmodels, including LLaMA 70b and Mistral 24b model, demonstrate that FairKV\nincreases throughput by 1.66x compared to standard tensor parallelism\ninference. Our code will be released as open source upon acceptance.",
      "tldr_zh": "该研究针对Transformer模型中的KV cache压缩问题，指出现有不平衡的per-head分配方法虽在单GPU场景下表现优异，但会导致多GPU推理时的负载不平衡。FairKV是一种新方法，通过核心技术Fair-Copying在GPU间复制少量内存密集型attention heads，实现内存使用的公平分配，从而缓解负载问题。实验结果显示，在LLaMA 70b和Mistral 24b模型上，FairKV相较于标准tensor parallelism推理，提高了1.66倍的吞吐量，为高效的多GPU推理提供了实用解决方案。",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "11 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.15804v2",
      "published_date": "2025-02-19 06:14:27 UTC",
      "updated_date": "2025-05-17 12:22:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:05:59.204907"
    },
    {
      "arxiv_id": "2502.15802v1",
      "title": "A General Error-Theoretical Analysis Framework for Constructing Compression Strategies",
      "title_zh": "翻译失败",
      "authors": [
        "Boyang Zhang",
        "Daning Cheng",
        "Yunquan Zhang",
        "Meiqi Tu",
        "Fangmin Liu",
        "Jiake Tian"
      ],
      "abstract": "The exponential growth in parameter size and computational complexity of deep\nmodels poses significant challenges for efficient deployment. The core problem\nof existing compression methods is that different layers of the model have\nsignificant differences in their tolerance to compression levels. For instance,\nthe first layer of a model can typically sustain a higher compression level\ncompared to the last layer without compromising performance. Thus, the key\nchallenge lies in how to allocate compression levels across layers in a way\nthat minimizes performance loss while maximizing parameter reduction. To\naddress this challenge, we propose a Compression Error Theory (CET) framework,\ndesigned to determine the optimal compression level for each layer. Taking\nquantization as an example, CET leverages differential expansion and algebraic\ngeometry to reconstruct the quadratic form of quantization error as ellipsoids\nand hyperbolic paraboloids, and utilizes their geometric structures to define\nan error subspace. To identify the error subspace with minimal performance\nloss, by performing orthogonal decomposition of the geometric space, CET\ntransforms the optimization process of the error subspace into a complementary\nproblem. The final theoretical analysis shows that constructing the\nquantization subspace along the major axis results in minimal performance\ndegradation. Through experimental verification of the theory, CET can greatly\nretain performance while compressing. Specifically, on the ResNet-34 model, CET\nachieves nearly 11$\\times$ parameter compression while even surpassing\nperformance comparable to the original model.",
      "tldr_zh": "该论文提出一个通用的 Compression Error Theory (CET) 框架，用于构建深度模型的压缩策略，以解决不同层对压缩容忍度差异的问题，例如早期层可承受更高压缩水平而不影响性能。CET 通过 differential expansion 和 algebraic geometry 分析量化错误，将其重构为椭球和双曲抛物面，并利用正交分解优化错误子空间，从而最小化性能损失。实验验证显示，在 ResNet-34 模型上，CET 实现了近 11 倍的参数压缩，同时性能甚至超过了原模型。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IT",
        "math.IT"
      ],
      "primary_category": "cs.LG",
      "comment": "Under Review",
      "pdf_url": "http://arxiv.org/pdf/2502.15802v1",
      "published_date": "2025-02-19 06:12:43 UTC",
      "updated_date": "2025-02-19 06:12:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:06:10.957337"
    },
    {
      "arxiv_id": "2502.13458v1",
      "title": "ThinkGuard: Deliberative Slow Thinking Leads to Cautious Guardrails",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaofei Wen",
        "Wenxuan Zhou",
        "Wenjie Jacky Mo",
        "Muhao Chen"
      ],
      "abstract": "Ensuring the safety of large language models (LLMs) is critical as they are\ndeployed in real-world applications. Existing guardrails rely on rule-based\nfiltering or single-pass classification, limiting their ability to handle\nnuanced safety violations. To address this, we propose ThinkGuard, a\ncritique-augmented guardrail model that distills knowledge from high-capacity\nLLMs by generating structured critiques alongside safety labels. Fine-tuned on\ncritique-augmented data, the captured deliberative thinking ability drastically\nenhances the guardrail's cautiousness and interpretability. Evaluated on\nmultiple safety benchmarks, ThinkGuard achieves the highest average F1 and\nAUPRC, outperforming all baselines. Compared to LLaMA Guard 3, ThinkGuard\nimproves accuracy by 16.1% and macro F1 by 27.0%. Moreover, it surpasses\nlabel-only fine-tuned models, confirming that structured critiques enhance both\nclassification precision and nuanced safety reasoning while maintaining\ncomputational efficiency.",
      "tldr_zh": "为了提升大语言模型(LLMs)的安全性，本文提出ThinkGuard，一种critique-augmented守卫模型，通过从高容量LLMs中提炼结构化的critiques和安全标签，捕获deliberative thinking能力，从而处理细微的安全违规问题。相比传统规则-based过滤或单次分类方法，ThinkGuard在critique-augmented数据上微调后，大大提高了守卫的谨慎性和可解释性，同时保持计算效率。实验结果显示，该模型在多个安全基准测试中达到最高的平均F1和AUPRC，比LLaMA Guard 3提升16.1%的准确率和27.0%的宏F1，证明了结构化critiques在提升分类精度和安全推理方面的显著优势。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.13458v1",
      "published_date": "2025-02-19 06:09:58 UTC",
      "updated_date": "2025-02-19 06:09:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:06:25.383004"
    },
    {
      "arxiv_id": "2503.05731v2",
      "title": "AILuminate: Introducing v1.0 of the AI Risk and Reliability Benchmark from MLCommons",
      "title_zh": "AILuminate：介绍 MLCommons 的 AI 风险和可靠性基准 v1.0",
      "authors": [
        "Shaona Ghosh",
        "Heather Frase",
        "Adina Williams",
        "Sarah Luger",
        "Paul Röttger",
        "Fazl Barez",
        "Sean McGregor",
        "Kenneth Fricklas",
        "Mala Kumar",
        "Quentin Feuillade--Montixi",
        "Kurt Bollacker",
        "Felix Friedrich",
        "Ryan Tsang",
        "Bertie Vidgen",
        "Alicia Parrish",
        "Chris Knotz",
        "Eleonora Presani",
        "Jonathan Bennion",
        "Marisa Ferrara Boston",
        "Mike Kuniavsky",
        "Wiebke Hutiri",
        "James Ezick",
        "Malek Ben Salem",
        "Rajat Sahay",
        "Sujata Goswami",
        "Usman Gohar",
        "Ben Huang",
        "Supheakmungkol Sarin",
        "Elie Alhajjar",
        "Canyu Chen",
        "Roman Eng",
        "Kashyap Ramanandula Manjusha",
        "Virendra Mehta",
        "Eileen Long",
        "Murali Emani",
        "Natan Vidra",
        "Benjamin Rukundo",
        "Abolfazl Shahbazi",
        "Kongtao Chen",
        "Rajat Ghosh",
        "Vithursan Thangarasa",
        "Pierre Peigné",
        "Abhinav Singh",
        "Max Bartolo",
        "Satyapriya Krishna",
        "Mubashara Akhtar",
        "Rafael Gold",
        "Cody Coleman",
        "Luis Oala",
        "Vassil Tashev",
        "Joseph Marvin Imperial",
        "Amy Russ",
        "Sasidhar Kunapuli",
        "Nicolas Miailhe",
        "Julien Delaunay",
        "Bhaktipriya Radharapu",
        "Rajat Shinde",
        "Tuesday",
        "Debojyoti Dutta",
        "Declan Grabb",
        "Ananya Gangavarapu",
        "Saurav Sahay",
        "Agasthya Gangavarapu",
        "Patrick Schramowski",
        "Stephen Singam",
        "Tom David",
        "Xudong Han",
        "Priyanka Mary Mammen",
        "Tarunima Prabhakar",
        "Venelin Kovatchev",
        "Rebecca Weiss",
        "Ahmed Ahmed",
        "Kelvin N. Manyeki",
        "Sandeep Madireddy",
        "Foutse Khomh",
        "Fedor Zhdanov",
        "Joachim Baumann",
        "Nina Vasan",
        "Xianjun Yang",
        "Carlos Mougn",
        "Jibin Rajan Varghese",
        "Hussain Chinoy",
        "Seshakrishna Jitendar",
        "Manil Maskey",
        "Claire V. Hardgrove",
        "Tianhao Li",
        "Aakash Gupta",
        "Emil Joswin",
        "Yifan Mai",
        "Shachi H Kumar",
        "Cigdem Patlak",
        "Kevin Lu",
        "Vincent Alessi",
        "Sree Bhargavi Balija",
        "Chenhe Gu",
        "Robert Sullivan",
        "James Gealy",
        "Matt Lavrisa",
        "James Goel",
        "Peter Mattson",
        "Percy Liang",
        "Joaquin Vanschoren"
      ],
      "abstract": "The rapid advancement and deployment of AI systems have created an urgent\nneed for standard safety-evaluation frameworks. This paper introduces\nAILuminate v1.0, the first comprehensive industry-standard benchmark for\nassessing AI-product risk and reliability. Its development employed an open\nprocess that included participants from multiple fields. The benchmark\nevaluates an AI system's resistance to prompts designed to elicit dangerous,\nillegal, or undesirable behavior in 12 hazard categories, including violent\ncrimes, nonviolent crimes, sex-related crimes, child sexual exploitation,\nindiscriminate weapons, suicide and self-harm, intellectual property, privacy,\ndefamation, hate, sexual content, and specialized advice (election, financial,\nhealth, legal). Our method incorporates a complete assessment standard,\nextensive prompt datasets, a novel evaluation framework, a grading and\nreporting system, and the technical as well as organizational infrastructure\nfor long-term support and evolution. In particular, the benchmark employs an\nunderstandable five-tier grading scale (Poor to Excellent) and incorporates an\ninnovative entropy-based system-response evaluation.\n  In addition to unveiling the benchmark, this report also identifies\nlimitations of our method and of building safety benchmarks generally,\nincluding evaluator uncertainty and the constraints of single-turn\ninteractions. This work represents a crucial step toward establishing global\nstandards for AI risk and reliability evaluation while acknowledging the need\nfor continued development in areas such as multiturn interactions, multimodal\nunderstanding, coverage of additional languages, and emerging hazard\ncategories. Our findings provide valuable insights for model developers, system\nintegrators, and policymakers working to promote safer AI deployment.",
      "tldr_zh": "本论文介绍了由 MLCommons 开发的 AILuminate v1.0，这是首个全面的行业标准基准，用于评估 AI 产品的风险和可靠性。基准通过开放式开发过程，评估 AI 系统对 12 个危险类别（如暴力犯罪、隐私侵犯和仇恨内容）的抵抗力，采用五级评分系统（从 Poor 到 Excellent）和基于熵的响应评估方法。论文还识别了方法的局限性，包括评估者不确定性和单轮交互的限制，并强调未来需扩展到多轮交互、多模态理解和其他语言，以推动全球 AI 风险评估标准的发展。该工作为 AI 模型开发者、系统集成者和政策制定者提供了宝贵见解，促进更安全的 AI 部署。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "51 pages, 8 figures and an appendix",
      "pdf_url": "http://arxiv.org/pdf/2503.05731v2",
      "published_date": "2025-02-19 05:58:52 UTC",
      "updated_date": "2025-04-18 22:04:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:06:37.717004"
    },
    {
      "arxiv_id": "2502.13450v1",
      "title": "Interleaved Gibbs Diffusion for Constrained Generation",
      "title_zh": "交错吉布斯扩散用于约束生成",
      "authors": [
        "Gautham Govind Anil",
        "Sachin Yadav",
        "Dheeraj Nagaraj",
        "Karthikeyan Shanmugam",
        "Prateek Jain"
      ],
      "abstract": "We introduce Interleaved Gibbs Diffusion (IGD), a novel generative modeling\nframework for mixed continuous-discrete data, focusing on constrained\ngeneration problems. Prior works on discrete and continuous-discrete diffusion\nmodels assume factorized denoising distribution for fast generation, which can\nhinder the modeling of strong dependencies between random variables encountered\nin constrained generation. IGD moves beyond this by interleaving continuous and\ndiscrete denoising algorithms via a discrete time Gibbs sampling type Markov\nchain. IGD provides flexibility in the choice of denoisers, allows conditional\ngeneration via state-space doubling and inference time scaling via the\nReDeNoise method. Empirical evaluations on three challenging tasks-solving\n3-SAT, generating molecule structures, and generating layouts-demonstrate\nstate-of-the-art performance. Notably, IGD achieves a 7% improvement on 3-SAT\nout of the box and achieves state-of-the-art results in molecule generation\nwithout relying on equivariant diffusion or domain-specific architectures. We\nexplore a wide range of modeling, and interleaving strategies along with\nhyperparameters in each of these problems.",
      "tldr_zh": "本研究引入了Interleaved Gibbs Diffusion (IGD)，一种新型生成建模框架，用于处理混合连续-离散数据，特别针对约束生成问题。IGD 通过交错连续和离散去噪算法以及类似Gibbs sampling的Markov链，克服了传统模型的因子化去噪分布假设，从而更好地处理变量间的强依赖关系，并提供灵活的去噪器选择、条件生成和ReDeNoise缩放方法。在实验中，IGD 在3-SAT解决、分子结构生成和布局生成任务上表现出色，实现7%的即时改进，并在分子生成中达到最先进水平，而无需依赖等变扩散或特定领域架构。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.13450v1",
      "published_date": "2025-02-19 05:51:24 UTC",
      "updated_date": "2025-02-19 05:51:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:06:50.720030"
    },
    {
      "arxiv_id": "2502.13442v2",
      "title": "TreeCut: A Synthetic Unanswerable Math Word Problem Dataset for LLM Hallucination Evaluation",
      "title_zh": "翻译失败",
      "authors": [
        "Jialin Ouyang"
      ],
      "abstract": "Large language models (LLMs) now achieve near-human performance on standard\nmath word problem benchmarks (e.g., GSM8K), yet their true reasoning ability\nremains disputed. A key concern is that models often produce confident, yet\nunfounded, answers to unanswerable problems. We introduce TreeCut, a synthetic\ndataset that systematically generates infinite unanswerable math word problems\nand their answerable counterparts, by representing each question as a tree and\nremoving chosen necessary conditions. Experiments show TreeCut effectively\ninduce hallucinations in large language models, including GPT-4o and o3-mini,\nwith rates of 64% and 44% in their respective worst-case scenarios under\nzero-shot setting. Further analysis highlights that deeper or more complex\ntrees, composite item names, and removing necessary condition near the middle\nof a path all increase the likelihood of hallucinations, underscoring the\npersistent challenges LLMs face in identifying unanswerable math problems. The\ndataset generation code and sample data are available at\nhttps://github.com/j-bagel/treecut-math.",
      "tldr_zh": "这篇论文介绍了 TreeCut 数据集，一种合成数据集，用于评估大型语言模型(LLMs)在数学文字问题中的幻觉问题，特别是模型对无法回答的问题给出自信错误答案的能力。TreeCut 通过将问题表示为树结构并移除必要的条件，系统生成无限的无法回答问题及其可回答对应版本。实验结果显示，在零样本设置下，LLMs 如 GPT-4o 和 o3-mini 的幻觉率分别达到 64% 和 44% 的最坏情况，进一步分析表明，树结构深度、复杂性及移除条件的位置（如路径中间）会显著增加幻觉风险，突显了 LLMs 在识别不可回答问题的挑战。数据集生成代码已在 GitHub 上公开。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to ACL 2025 Main Conference",
      "pdf_url": "http://arxiv.org/pdf/2502.13442v2",
      "published_date": "2025-02-19 05:38:45 UTC",
      "updated_date": "2025-05-20 04:13:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:07:04.041633"
    },
    {
      "arxiv_id": "2502.13441v1",
      "title": "The Self-Improvement Paradox: Can Language Models Bootstrap Reasoning Capabilities without External Scaffolding?",
      "title_zh": "翻译失败",
      "authors": [
        "Yutao Sun",
        "Mingshuai Chen",
        "Tiancheng Zhao",
        "Ruochen Xu",
        "Zilun Zhang",
        "Jianwei Yin"
      ],
      "abstract": "Self-improving large language models (LLMs) -- i.e., to improve the\nperformance of an LLM by fine-tuning it with synthetic data generated by itself\n-- is a promising way to advance the capabilities of LLMs while avoiding\nextensive supervision. Existing approaches to self-improvement often rely on\nexternal supervision signals in the form of seed data and/or assistance from\nthird-party models. This paper presents Crescent -- a simple yet effective\nframework for generating high-quality synthetic question-answer data in a fully\nautonomous manner. Crescent first elicits the LLM to generate raw questions via\na bait prompt, then diversifies these questions leveraging a rejection\nsampling-based self-deduplication, and finally feeds the questions to the LLM\nand collects the corresponding answers by means of majority voting. We show\nthat Crescent sheds light on the potential of true self-improvement with zero\nexternal supervision signals for math reasoning; in particular,\nCrescent-generated question-answer pairs suffice to (i) improve the reasoning\ncapabilities of an LLM while preserving its general performance (especially in\nthe 0-shot setting); and (ii) distil LLM knowledge to weaker models more\neffectively than existing methods based on seed-dataset augmentation.",
      "tldr_zh": "本文探讨大型语言模型 (LLMs) 是否能在无外部监督信号下提升推理能力，提出 Crescent 框架作为一种完全自主的合成数据生成方法。Crescent 通过诱饵提示生成原始问题、基于拒绝采样的自去重多样化问题，以及多数投票收集答案，从而生成高质量的问答数据。实验结果表明，使用 Crescent 生成的数据能提升 LLMs 的数学推理能力，同时保持其一般性能（尤其在零样本设置），并比现有方法更有效地将知识蒸馏到较弱模型。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.13441v1",
      "published_date": "2025-02-19 05:37:08 UTC",
      "updated_date": "2025-02-19 05:37:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:07:14.862018"
    },
    {
      "arxiv_id": "2502.13440v1",
      "title": "Semi-supervised classification of bird vocalizations",
      "title_zh": "半监督鸟类鸣声分类",
      "authors": [
        "Simen Hexeberg",
        "Mandar Chitre",
        "Matthias Hoffmann-Kuhnt",
        "Bing Wen Low"
      ],
      "abstract": "Changes in bird populations can indicate broader changes in ecosystems,\nmaking birds one of the most important animal groups to monitor. Combining\nmachine learning and passive acoustics enables continuous monitoring over\nextended periods without direct human involvement. However, most existing\ntechniques require extensive expert-labeled datasets for training and cannot\neasily detect time-overlapping calls in busy soundscapes. We propose a\nsemi-supervised acoustic bird detector designed to allow both the detection of\ntime-overlapping calls (when separated in frequency) and the use of few labeled\ntraining samples. The classifier is trained and evaluated on a combination of\ncommunity-recorded open-source data and long-duration soundscape recordings\nfrom Singapore. It achieves a mean F0.5 score of 0.701 across 315 classes from\n110 bird species on a hold-out test set, with an average of 11 labeled training\nsamples per class. It outperforms the state-of-the-art BirdNET classifier on a\ntest set of 103 bird species despite significantly fewer labeled training\nsamples. The detector is further tested on 144 microphone-hours of continuous\nsoundscape data. The rich soundscape in Singapore makes suppression of false\npositives a challenge on raw, continuous data streams. Nevertheless, we\ndemonstrate that achieving high precision in such environments with minimal\nlabeled training data is possible.",
      "tldr_zh": "本研究针对鸟类种群监测的挑战，提出了一种半监督分类器，用于检测鸟类 vocalizations，尤其能处理频率上分离的时间重叠叫声，同时仅需少量标记训练样本。该方法在新加坡的社区录音和长时声景数据上训练和评估，实现了在315个类别的110个鸟类种上平均F0.5 score为0.701的性能，且每个类仅使用11个标记样本。该分类器在103个鸟类种的测试集上优于现有BirdNET模型，并在144小时的连续声景数据中证明了高精度检测的可行性，尽管面临复杂环境中的假阳性抑制挑战。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CV",
        "eess.AS",
        "q-bio.QM"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.13440v1",
      "published_date": "2025-02-19 05:31:13 UTC",
      "updated_date": "2025-02-19 05:31:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:07:26.931389"
    },
    {
      "arxiv_id": "2503.05730v1",
      "title": "Robust Optimization with Diffusion Models for Green Security",
      "title_zh": "基于扩散模型的绿色安全鲁棒优化",
      "authors": [
        "Lingkai Kong",
        "Haichuan Wang",
        "Yuqi Pan",
        "Cheol Woo Kim",
        "Mingxiao Song",
        "Alayna Nguyen",
        "Tonghan Wang",
        "Haifeng Xu",
        "Milind Tambe"
      ],
      "abstract": "In green security, defenders must forecast adversarial behavior, such as\npoaching, illegal logging, and illegal fishing, to plan effective patrols.\nThese behavior are often highly uncertain and complex. Prior work has leveraged\ngame theory to design robust patrol strategies to handle uncertainty, but\nexisting adversarial behavior models primarily rely on Gaussian processes or\nlinear models, which lack the expressiveness needed to capture intricate\nbehavioral patterns. To address this limitation, we propose a conditional\ndiffusion model for adversary behavior modeling, leveraging its strong\ndistribution-fitting capabilities. To the best of our knowledge, this is the\nfirst application of diffusion models in the green security domain. Integrating\ndiffusion models into game-theoretic optimization, however, presents new\nchallenges, including a constrained mixed strategy space and the need to sample\nfrom an unnormalized distribution to estimate utilities. To tackle these\nchallenges, we introduce a mixed strategy of mixed strategies and employ a\ntwisted Sequential Monte Carlo (SMC) sampler for accurate sampling.\nTheoretically, our algorithm is guaranteed to converge to an epsilon\nequilibrium with high probability using a finite number of iterations and\nsamples. Empirically, we evaluate our approach on both synthetic and real-world\npoaching datasets, demonstrating its effectiveness.",
      "tldr_zh": "本研究针对绿色安全领域（如偷猎、非法伐木和非法捕鱼）的对手行为不确定性，提出使用条件diffusion models来建模复杂行为，这是该领域的首次应用，以克服传统高斯过程或线性模型的表达性不足。研究将diffusion models整合到博弈论优化中，通过引入混合策略的混合策略和twisted Sequential Monte Carlo (SMC)采样器，解决混合策略空间受限和从未归一化分布采样的挑战。理论上，该算法能以高概率收敛到epsilon平衡；实验在合成和真实世界偷猎数据集上验证了其有效性，展示了显著的鲁棒性提升。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.05730v1",
      "published_date": "2025-02-19 05:30:46 UTC",
      "updated_date": "2025-02-19 05:30:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:07:38.295908"
    },
    {
      "arxiv_id": "2502.13430v1",
      "title": "Vision-Based Generic Potential Function for Policy Alignment in Multi-Agent Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Hao Ma",
        "Shijie Wang",
        "Zhiqiang Pu",
        "Siyao Zhao",
        "Xiaolin Ai"
      ],
      "abstract": "Guiding the policy of multi-agent reinforcement learning to align with human\ncommon sense is a difficult problem, largely due to the complexity of modeling\ncommon sense as a reward, especially in complex and long-horizon multi-agent\ntasks. Recent works have shown the effectiveness of reward shaping, such as\npotential-based rewards, to enhance policy alignment. The existing works,\nhowever, primarily rely on experts to design rule-based rewards, which are\noften labor-intensive and lack a high-level semantic understanding of common\nsense. To solve this problem, we propose a hierarchical vision-based reward\nshaping method. At the bottom layer, a visual-language model (VLM) serves as a\ngeneric potential function, guiding the policy to align with human common sense\nthrough its intrinsic semantic understanding. To help the policy adapts to\nuncertainty and changes in long-horizon tasks, the top layer features an\nadaptive skill selection module based on a visual large language model (vLLM).\nThe module uses instructions, video replays, and training records to\ndynamically select suitable potential function from a pre-designed pool.\nBesides, our method is theoretically proven to preserve the optimal policy.\nExtensive experiments conducted in the Google Research Football environment\ndemonstrate that our method not only achieves a higher win rate but also\neffectively aligns the policy with human common sense.",
      "tldr_zh": "该论文针对多智能体强化学习（Multi-Agent Reinforcement Learning）中策略与人类常识对齐的难题，提出了一种分层视觉-based 奖励塑造方法，以解决复杂长期任务中的挑战。底层使用视觉语言模型 (VLM) 作为通用潜能函数 (Generic Potential Function)，通过其内在语义理解来引导策略与人类常识对齐；上层则引入基于视觉大语言模型 (vLLM) 的自适应技能选择模块，利用指令、视频重放和训练记录动态选择合适的潜能函数，以应对不确定性和变化。该方法被理论证明能保留最优策略，在 Google Research Football 环境中的实验显示，它不仅提高了获胜率，还有效提升了策略的常识对齐。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.13430v1",
      "published_date": "2025-02-19 05:04:10 UTC",
      "updated_date": "2025-02-19 05:04:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:07:50.203096"
    },
    {
      "arxiv_id": "2502.13428v1",
      "title": "MCTS-KBQA: Monte Carlo Tree Search for Knowledge Base Question Answering",
      "title_zh": "MCTS-KBQA：蒙特卡洛树搜索用于知识库问答",
      "authors": [
        "Guanming Xiong",
        "Haochen Li",
        "Wen Zhao"
      ],
      "abstract": "This study explores how to enhance the reasoning capabilities of large\nlanguage models (LLMs) in knowledge base question answering (KBQA) by\nleveraging Monte Carlo Tree Search (MCTS). Semantic parsing-based KBQA methods\nare particularly challenging as these approaches require locating elements from\nknowledge bases and generating logical forms, demanding not only extensive\nannotated data but also strong reasoning capabilities. Although recent\napproaches leveraging LLMs as agents have demonstrated considerable potential,\nthese studies are inherently constrained by their linear decision-making\nprocesses. To address this limitation, we propose a MCTS-based framework that\nenhances LLMs' reasoning capabilities through tree search methodology. We\ndesign a carefully designed step-wise reward mechanism that requires only\ndirect prompting of open-source instruction LLMs without additional\nfine-tuning. Experimental results demonstrate that our approach significantly\noutperforms linear decision-making methods, particularly in low-resource\nscenarios. Additionally, we contribute new data resources to the KBQA community\nby annotating intermediate reasoning processes for existing question-SPARQL\ndatasets using distant supervision. Experimental results on the extended\ndataset demonstrate that our method achieves comparable performance to fully\nsupervised models while using significantly less training data.",
      "tldr_zh": "这篇论文提出了一种名为 MCTS-KBQA 的框架，利用 Monte Carlo Tree Search (MCTS) 来增强大型语言模型 (LLMs) 在知识库问答 (KBQA) 中的推理能力，以解决语义解析方法依赖大量标注数据和线性决策局限的问题。框架通过树搜索机制和步进式奖励设计，仅需直接提示开源指令 LLMs 即可实现，而无需额外微调。实验结果表明，该方法在低资源场景下显著优于线性决策方法，并在扩展数据集上，使用少量训练数据就达到了与完全监督模型相当的性能，同时为 KBQA 社区贡献了通过远端监督标注的新数据资源。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.13428v1",
      "published_date": "2025-02-19 04:58:39 UTC",
      "updated_date": "2025-02-19 04:58:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:08:03.112226"
    },
    {
      "arxiv_id": "2502.13422v1",
      "title": "TabSD: Large Free-Form Table Question Answering with SQL-Based Table Decomposition",
      "title_zh": "TabSD：基于 SQL 的表格分解的大型自由形式表格问答",
      "authors": [
        "Yuxiang Wang",
        "Junhao Gan",
        "Jianzhong Qi"
      ],
      "abstract": "Question answering on free-form tables (TableQA) is challenging due to the\nabsence of predefined schemas and the presence of noise in large tables. While\nLarge Language Models (LLMs) have shown promise in TableQA, they struggle with\nlarge free-form tables and noise sensitivity. To address these challenges, we\npropose TabSD, a SQL-based decomposition model that enhances LLMs' ability to\nprocess large free-form tables. TabSD generates SQL queries to guide the table\ndecomposition, remove noise, and processes sub-tables for better answer\ngeneration. Additionally, SQL Verifier refines SQL outputs to enhance\ndecomposition accuracy. We introduce two TableQA datasets with large free-form\ntables, SLQA and SEQA, which consist solely of large free-form tables and will\nbe publicly available. Experimental results on four benchmark datasets\ndemonstrate that TABSD outperforms the best-existing baseline models by 23.07%,\n2.84%, 23.24% and 9.32% in accuracy, respectively, highlighting its\neffectiveness in handling large and noisy free-form tables.",
      "tldr_zh": "这篇论文针对自由形式表格问题回答(TableQA)的挑战，如缺乏预定义模式和大噪声问题，提出了一种SQL-based分解模型TabSD，以提升Large Language Models(LLMs)处理大型表格的能力。TabSD通过生成SQL查询来分解表格、去除噪声并处理子表格，同时引入SQL Verifier来优化SQL输出准确性。论文还创建了两个新数据集SLQA和SEQA，专注于大型自由形式表格，并公开可用。在四个基准数据集上的实验结果显示，TabSD分别比现有最佳基线模型提高了23.07%、2.84%、23.24%和9.32%的准确率，证明了其在处理噪声表格方面的显著有效性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.13422v1",
      "published_date": "2025-02-19 04:45:05 UTC",
      "updated_date": "2025-02-19 04:45:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:08:16.468376"
    },
    {
      "arxiv_id": "2502.13417v2",
      "title": "RLTHF: Targeted Human Feedback for LLM Alignment",
      "title_zh": "RLTHF：针对 LLM 对齐的目标导向人类反馈",
      "authors": [
        "Yifei Xu",
        "Tusher Chakraborty",
        "Emre Kıcıman",
        "Bibek Aryal",
        "Eduardo Rodrigues",
        "Srinagesh Sharma",
        "Roberto Estevao",
        "Maria Angels de Luis Balaguer",
        "Jessica Wolk",
        "Rafael Padilha",
        "Leonardo Nunes",
        "Shobana Balakrishnan",
        "Songwu Lu",
        "Ranveer Chandra"
      ],
      "abstract": "Fine-tuning large language models (LLMs) to align with user preferences is\nchallenging due to the high cost of quality human annotations in Reinforcement\nLearning from Human Feedback (RLHF) and the generalizability limitations of AI\nFeedback. To address these challenges, we propose RLTHF, a human-AI hybrid\nframework that combines LLM-based initial alignment with selective human\nannotations to achieve full-human annotation alignment with minimal effort.\nRLTHF identifies hard-to-annotate samples mislabeled by LLMs using a reward\nmodel's reward distribution and iteratively enhances alignment by integrating\nstrategic human corrections while leveraging LLM's correctly labeled samples.\nEvaluations on HH-RLHF and TL;DR datasets show that RLTHF reaches full-human\nannotation-level alignment with only 6-7% of the human annotation effort.\nFurthermore, models trained on RLTHF's curated datasets for downstream tasks\noutperform those trained on fully human-annotated datasets, underscoring the\neffectiveness of RLTHF's strategic data curation.",
      "tldr_zh": "该论文提出RLTHF，一种人类-AI混合框架，用于解决大型语言模型(LLMs)在Reinforcement Learning from Human Feedback (RLHF)中的高注释成本和AI Feedback泛化限制问题。RLTHF通过LLM的初始对齐和奖励模型的奖励分布，识别并针对难标记样本进行选择性人类注释，同时迭代整合人类修正并利用LLM的正确样本。实验在HH-RLHF和TL;DR数据集上显示，RLTHF只需6-7%的人类注释努力即可达到全人类注释水平，且在下游任务上训练的模型表现优于全人类注释数据集，证明了其战略数据策划的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.13417v2",
      "published_date": "2025-02-19 04:25:11 UTC",
      "updated_date": "2025-02-21 02:51:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:08:27.691321"
    },
    {
      "arxiv_id": "2504.05312v1",
      "title": "Towards Adaptive Memory-Based Optimization for Enhanced Retrieval-Augmented Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Qitao Qin",
        "Yucong Luo",
        "Yihang Lu",
        "Zhibo Chu",
        "Xianwei Meng"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG), by integrating non-parametric knowledge\nfrom external knowledge bases into models, has emerged as a promising approach\nto enhancing response accuracy while mitigating factual errors and\nhallucinations. This method has been widely applied in tasks such as Question\nAnswering (QA). However, existing RAG methods struggle with open-domain QA\ntasks because they perform independent retrieval operations and directly\nincorporate the retrieved information into generation without maintaining a\nsummarizing memory or using adaptive retrieval strategies, leading to noise\nfrom redundant information and insufficient information integration. To address\nthese challenges, we propose Adaptive memory-based optimization for enhanced\nRAG (Amber) for open-domain QA tasks, which comprises an Agent-based Memory\nUpdater, an Adaptive Information Collector, and a Multi-granular Content\nFilter, working together within an iterative memory updating paradigm.\nSpecifically, Amber integrates and optimizes the language model's memory\nthrough a multi-agent collaborative approach, ensuring comprehensive knowledge\nintegration from previous retrieval steps. It dynamically adjusts retrieval\nqueries and decides when to stop retrieval based on the accumulated knowledge,\nenhancing retrieval efficiency and effectiveness. Additionally, it reduces\nnoise by filtering irrelevant content at multiple levels, retaining essential\ninformation to improve overall model performance. We conduct extensive\nexperiments on several open-domain QA datasets, and the results demonstrate the\nsuperiority and effectiveness of our method and its components. The source code\nis available \\footnote{https://anonymous.4open.science/r/Amber-B203/}.",
      "tldr_zh": "该论文针对Retrieval-Augmented Generation (RAG) 在开放域问答任务中的问题，如独立检索导致的冗余噪声和信息整合不足，提出了一种改进框架Amber。Amber 包括Agent-based Memory Updater、Adaptive Information Collector 和 Multi-granular Content Filter 等组件，通过多智能体协作在迭代记忆更新范式中优化语言模型的记忆。系统动态调整检索查询、基于积累知识决定停止检索，并通过多级别过滤减少无关内容，从而提升检索效率和生成准确性。在多个开放域 QA 数据集上的实验结果显示，Amber 显著优于现有方法，证明了其组件的有效性。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "8pages",
      "pdf_url": "http://arxiv.org/pdf/2504.05312v1",
      "published_date": "2025-02-19 04:23:12 UTC",
      "updated_date": "2025-02-19 04:23:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:08:37.709087"
    },
    {
      "arxiv_id": "2502.13412v1",
      "title": "Explore-Construct-Filter: An Automated Framework for Rich and Reliable API Knowledge Graph Construction",
      "title_zh": "Explore-Construct-Filter：一种用于构建丰富且可靠的 API 知识图谱的自动化框架",
      "authors": [
        "Yanbang Sun",
        "Qing Huang",
        "Xiaoxue Ren",
        "Zhenchang Xing",
        "Xiaohong Li",
        "Junjie Wang"
      ],
      "abstract": "The API Knowledge Graph (API KG) is a structured network that models API\nentities and their relations, providing essential semantic insights for tasks\nsuch as API recommendation, code generation, and API misuse detection. However,\nconstructing a knowledge-rich and reliable API KG presents several challenges.\nExisting schema-based methods rely heavily on manual annotations to design KG\nschemas, leading to excessive manual overhead. On the other hand, schema-free\nmethods, due to the lack of schema guidance, are prone to introducing noise,\nreducing the KG's reliability. To address these issues, we propose the\nExplore-Construct-Filter framework, an automated approach for API KG\nconstruction based on large language models (LLMs). This framework consists of\nthree key modules: 1) KG exploration: LLMs simulate the workflow of annotators\nto automatically design a schema with comprehensive type triples, minimizing\nhuman intervention; 2) KG construction: Guided by the schema, LLMs extract\ninstance triples to construct a rich yet unreliable API KG; 3) KG filtering:\nRemoving invalid type triples and suspicious instance triples to construct a\nrich and reliable API KG. Experimental results demonstrate that our method\nsurpasses the state-of-the-art method, achieving a 25.2% improvement in F1\nscore. Moreover, the Explore-Construct-Filter framework proves effective, with\nthe KG exploration module increasing KG richness by 133.6% and the KG filtering\nmodule improving reliability by 26.6%. Finally, cross-model experiments confirm\nthe generalizability of our framework.",
      "tldr_zh": "该论文提出 Explore-Construct-Filter 框架，利用大型语言模型 (LLMs) 自动构建丰富且可靠的 API Knowledge Graph (API KG)，以解决现有 schema-based 方法依赖手动注解和 schema-free 方法易引入噪声的问题。框架由三个模块组成：KG exploration 模块模拟注解流程自动设计全面的 type triples schema；KG construction 模块基于 schema 提取 instance triples 构建初始 KG；KG filtering 模块移除无效或可疑 triples 以提升可靠性。实验结果显示，该框架比最先进方法 F1 score 提高 25.2%，KG 丰富度提升 133.6%，可靠性提升 26.6%，并证明了其跨模型通用性。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.13412v1",
      "published_date": "2025-02-19 03:51:31 UTC",
      "updated_date": "2025-02-19 03:51:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:08:52.442841"
    },
    {
      "arxiv_id": "2502.13410v1",
      "title": "Tell Me Why: Incentivizing Explanations",
      "title_zh": "翻译失败",
      "authors": [
        "Siddarth Srinivasan",
        "Ezra Karger",
        "Michiel Bakker",
        "Yiling Chen"
      ],
      "abstract": "Common sense suggests that when individuals explain why they believe\nsomething, we can arrive at more accurate conclusions than when they simply\nstate what they believe. Yet, there is no known mechanism that provides\nincentives to elicit explanations for beliefs from agents. This likely stems\nfrom the fact that standard Bayesian models make assumptions (like conditional\nindependence of signals) that preempt the need for explanations, in order to\nshow efficient information aggregation. A natural justification for the value\nof explanations is that agents' beliefs tend to be drawn from overlapping\nsources of information, so agents' belief reports do not reveal all that needs\nto be known. Indeed, this work argues that rationales-explanations of an\nagent's private information-lead to more efficient aggregation by allowing\nagents to efficiently identify what information they share and what information\nis new. Building on this model of rationales, we present a novel 'deliberation\nmechanism' to elicit rationales from agents in which truthful reporting of\nbeliefs and rationales is a perfect Bayesian equilibrium.",
      "tldr_zh": "这篇论文探讨了激励代理人提供信念解释（rationales）的必要性，因为解释能帮助更准确地聚合信息，而标准贝叶斯模型的假设（如信号条件独立性）忽略了这一价值。研究认为，代理人的信念通常来自重叠的信息源，因此rationales能让代理人有效识别共享信息和新信息，从而提升信息聚合效率。最终，该论文提出一个创新的deliberation mechanism，在该机制中，真诚报告信念和rationales构成perfect Bayesian equilibrium。",
      "categories": [
        "cs.GT",
        "cs.AI",
        "econ.TH"
      ],
      "primary_category": "cs.GT",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.13410v1",
      "published_date": "2025-02-19 03:47:34 UTC",
      "updated_date": "2025-02-19 03:47:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:09:03.534540"
    },
    {
      "arxiv_id": "2502.13407v3",
      "title": "JL1-CD: A New Benchmark for Remote Sensing Change Detection and a Robust Multi-Teacher Knowledge Distillation Framework",
      "title_zh": "翻译失败",
      "authors": [
        "Ziyuan Liu",
        "Ruifei Zhu",
        "Long Gao",
        "Yuanxiu Zhou",
        "Jingyu Ma",
        "Yuantao Gu"
      ],
      "abstract": "Change detection (CD) in remote sensing images plays a vital role in Earth\nobservation. However, the scarcity of high-resolution, comprehensive\nopen-source datasets and the difficulty in achieving robust performance across\nvarying change types remain major challenges. To address these issues, we\nintroduce JL1-CD, a large-scale, sub-meter CD dataset consisting of 5,000 image\npairs. We further propose a novel Origin-Partition (O-P) strategy and integrate\nit into a Multi-Teacher Knowledge Distillation (MTKD) framework to enhance CD\nperformance. The O-P strategy partitions the training set by Change Area Ratio\n(CAR) and trains specialized teacher models on each subset. The MTKD framework\nthen distills complementary knowledge from these teachers into a single student\nmodel, enabling improved detection results across diverse CAR scenarios without\nadditional inference cost. Our MTKD approach demonstrated strong performance in\nthe 2024 \"Jilin-1'' Cup challenge, ranking first in the preliminary and second\nin the final rounds. Extensive experiments on the JL1-CD and SYSU-CD datasets\nshow that the MTKD framework consistently improves the performance of CD models\nwith various network architectures and parameter sizes, establishing new\nstate-of-the-art results. Code and dataset are available at\nhttps://anonymous.4open.science/r/MTKD-A-84B8.",
      "tldr_zh": "本论文引入了JL1-CD，这是一个大规模的亚米级遥感图像变化检测基准数据集，包含5000对图像对，旨在解决现有数据集稀缺和高分辨率不足的问题。同时，提出Origin-Partition (O-P)策略和Multi-Teacher Knowledge Distillation (MTKD)框架，通过根据Change Area Ratio (CAR)分区训练集并训练专用教师模型，再将知识蒸馏到一个学生模型中，提升变化检测的鲁棒性和性能。在JL1-CD和SYSU-CD数据集上的实验显示，MTKD框架显著提高了各种网络架构的CD模型效果，并在2024 \"Jilin-1\" Cup挑战赛中排名初赛第一和决赛第二，建立了新的最先进结果。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "23 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.13407v3",
      "published_date": "2025-02-19 03:33:54 UTC",
      "updated_date": "2025-05-17 11:10:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:09:15.876065"
    },
    {
      "arxiv_id": "2502.13406v2",
      "title": "Generative Predictive Control: Flow Matching Policies for Dynamic and Difficult-to-Demonstrate Tasks",
      "title_zh": "生成式预测控制：流匹配策略用于动态和难以演示的任务",
      "authors": [
        "Vince Kurtz",
        "Joel W. Burdick"
      ],
      "abstract": "Generative control policies have recently unlocked major progress in\nrobotics. These methods produce action sequences via diffusion or flow\nmatching, with training data provided by demonstrations. But existing methods\ncome with two key limitations: they require expert demonstrations, which can be\ndifficult to obtain, and they are limited to relatively slow, quasi-static\ntasks. In this paper, we leverage a tight connection between sampling-based\npredictive control and generative modeling to address each of these issues. In\nparticular, we introduce generative predictive control, a supervised learning\nframework for tasks with fast dynamics that are easy to simulate but difficult\nto demonstrate. We then show how trained flow-matching policies can be\nwarm-started at inference time, maintaining temporal consistency and enabling\nhigh-frequency feedback. We believe that generative predictive control offers a\ncomplementary approach to existing behavior cloning methods, and hope that it\npaves the way toward generalist policies that extend beyond quasi-static\ndemonstration-oriented tasks.",
      "tldr_zh": "这篇论文提出了 generative predictive control，一种监督学习框架，旨在解决现有生成控制策略的局限性，即依赖专家演示并限于慢速任务。该框架利用 sampling-based predictive control 与生成建模的紧密联系，训练 flow matching policies 来处理模拟容易但演示困难的快速动态任务。同时，通过在推理时进行 warm-start，确保策略保持时间一致性和高频反馈。作者认为，这为 behavior cloning 方法提供补充路径，并有望推动通用的机器人策略扩展到更广泛的场景。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.13406v2",
      "published_date": "2025-02-19 03:33:01 UTC",
      "updated_date": "2025-05-01 17:23:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:09:25.718955"
    },
    {
      "arxiv_id": "2502.13991v1",
      "title": "Learning to Discover Regulatory Elements for Gene Expression Prediction",
      "title_zh": "学习发现调控元件用于基因表达预测",
      "authors": [
        "Xingyu Su",
        "Haiyang Yu",
        "Degui Zhi",
        "Shuiwang Ji"
      ],
      "abstract": "We consider the problem of predicting gene expressions from DNA sequences. A\nkey challenge of this task is to find the regulatory elements that control gene\nexpressions. Here, we introduce Seq2Exp, a Sequence to Expression network\nexplicitly designed to discover and extract regulatory elements that drive\ntarget gene expression, enhancing the accuracy of the gene expression\nprediction. Our approach captures the causal relationship between epigenomic\nsignals, DNA sequences and their associated regulatory elements. Specifically,\nwe propose to decompose the epigenomic signals and the DNA sequence conditioned\non the causal active regulatory elements, and apply an information bottleneck\nwith the Beta distribution to combine their effects while filtering out\nnon-causal components. Our experiments demonstrate that Seq2Exp outperforms\nexisting baselines in gene expression prediction tasks and discovers\ninfluential regions compared to commonly used statistical methods for peak\ndetection such as MACS3. The source code is released as part of the AIRS\nlibrary (https://github.com/divelab/AIRS/).",
      "tldr_zh": "本文提出 Seq2Exp 网络，用于从 DNA sequences 预测基因表达，并显式发现和提取调控 elements，以提升预测准确性。该方法捕捉 epigenomic signals、DNA sequences 与调控 elements 之间的因果关系，通过分解信号、应用 information bottleneck 和 Beta distribution 结合它们的效应，同时过滤非-causal 成分。实验结果表明，Seq2Exp 在基因表达预测任务中优于现有基线模型，并在发现影响区域方面超越常见的统计方法如 MACS3；源码已开源在 AIRS 库中。",
      "categories": [
        "q-bio.GN",
        "cs.AI"
      ],
      "primary_category": "q-bio.GN",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.13991v1",
      "published_date": "2025-02-19 03:25:49 UTC",
      "updated_date": "2025-02-19 03:25:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:09:38.752159"
    },
    {
      "arxiv_id": "2502.13398v1",
      "title": "$\\mathtt{GeLLM^3O}$: Generalizing Large Language Models for Multi-property Molecule Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Vishal Dey",
        "Xiao Hu",
        "Xia Ning"
      ],
      "abstract": "Despite recent advancements, most computational methods for molecule\noptimization are constrained to single- or double-property optimization tasks\nand suffer from poor scalability and generalizability to novel optimization\ntasks. Meanwhile, Large Language Models (LLMs) demonstrate remarkable\nout-of-domain generalizability to novel tasks. To demonstrate LLMs' potential\nfor molecule optimization, we introduce $\\mathtt{MoMUInstruct}$, the first\nhigh-quality instruction-tuning dataset specifically focused on complex\nmulti-property molecule optimization tasks. Leveraging $\\mathtt{MoMUInstruct}$,\nwe develop $\\mathtt{GeLLM^3O}$s, a series of instruction-tuned LLMs for\nmolecule optimization. Extensive evaluations across 5 in-domain and 5\nout-of-domain tasks demonstrate that $\\mathtt{GeLLM^3O}$s consistently\noutperform state-of-the-art baselines. $\\mathtt{GeLLM^3O}$s also exhibit\noutstanding zero-shot generalization to unseen tasks, significantly\noutperforming powerful closed-source LLMs. Such strong generalizability\ndemonstrates the tremendous potential of $\\mathtt{GeLLM^3O}$s as foundational\nmodels for molecule optimization, thereby tackling novel optimization tasks\nwithout resource-intensive retraining. $\\mathtt{MoMUInstruct}$, models, and\ncode are accessible through https://github.com/ninglab/GeLLMO.",
      "tldr_zh": "本研究针对分子优化的局限性，即大多数方法仅限于单属性或双属性任务，且扩展性和泛化性较差，提出$\\mathtt{GeLLM^3O}$，一种基于Large Language Models (LLMs)的泛化框架。作者首先构建了$\\mathtt{MoMUInstruct}$，首个专注于复杂多属性分子优化任务的高质量指令微调数据集。利用该数据集，开发了$\\mathtt{GeLLM^3O}$系列模型，通过指令微调提升LLMs在分子优化中的性能。实验结果显示，在5个领域内和5个领域外任务上，$\\mathtt{GeLLM^3O}$显著优于现有基线，并在零样本泛化方面超越强大闭源LLMs，无需资源密集型重训练即可处理新任务。该框架展示了LLMs作为分子优化基础模型的巨大潜力，并提供了相关资源以供访问。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "physics.chem-ph",
        "q-bio.QM"
      ],
      "primary_category": "cs.LG",
      "comment": "Vishal Dey and Xiao Hu contributed equally to this paper",
      "pdf_url": "http://arxiv.org/pdf/2502.13398v1",
      "published_date": "2025-02-19 03:14:11 UTC",
      "updated_date": "2025-02-19 03:14:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:09:51.755316"
    },
    {
      "arxiv_id": "2502.13392v2",
      "title": "Atomic Proximal Policy Optimization for Electric Robo-Taxi Dispatch and Charger Allocation",
      "title_zh": "翻译失败",
      "authors": [
        "Jim Dai",
        "Manxi Wu",
        "Zhanhao Zhang"
      ],
      "abstract": "Pioneering companies such as Waymo have deployed robo-taxi services in\nseveral U.S. cities. These robo-taxis are electric vehicles, and their\noperations require the joint optimization of ride matching, vehicle\nrepositioning, and charging scheduling in a stochastic environment. We model\nthe operations of the ride-hailing system with robo-taxis as a discrete-time,\naverage-reward Markov Decision Process with an infinite horizon. As the fleet\nsize grows, dispatching becomes challenging, as both the system state space and\nthe fleet dispatching action space grow exponentially with the number of\nvehicles. To address this, we introduce a scalable deep reinforcement learning\nalgorithm, called Atomic Proximal Policy Optimization (Atomic-PPO), that\nreduces the action space using atomic action decomposition. We evaluate our\nalgorithm using real-world NYC for-hire vehicle trip records and measure its\nperformance by the long-run average reward achieved by the dispatching policy,\nrelative to a fluid-based upper bound. Our experiments demonstrate the superior\nperformance of Atomic-PPO compared to benchmark methods. Furthermore, we\nconduct extensive numerical experiments to analyze the efficient allocation of\ncharging facilities and assess the impact of vehicle range and charger speed on\nsystem performance.",
      "tldr_zh": "这篇论文针对电动 robo-taxi 的调度问题，构建了一个离散时间、平均奖励的无限期 Markov Decision Process (MDP)，以优化乘车匹配、车辆重新定位和充电调度。\n作者提出 Atomic Proximal Policy Optimization (Atomic-PPO) 算法，通过原子动作分解来减少动作空间，从而实现对大规模车队的高效调度。\n实验基于真实纽约市出租车数据显示，Atomic-PPO 在长期平均奖励方面优于基准方法，并通过数值实验评估了充电设施分配、车辆续航力和充电器速度对系统性能的影响。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.13392v2",
      "published_date": "2025-02-19 03:05:23 UTC",
      "updated_date": "2025-04-27 17:05:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:10:03.129828"
    },
    {
      "arxiv_id": "2502.13389v1",
      "title": "Reasoning with Reinforced Functional Token Tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Kongcheng Zhang",
        "Qi Yao",
        "Baisheng Lai",
        "Jiaxing Huang",
        "Wenkai Fang",
        "Dacheng Tao",
        "Mingli Song",
        "Shunyu Liu"
      ],
      "abstract": "In this work, we propose Reinforced Functional Token Tuning (RFTT), a novel\nreinforced fine-tuning framework that empowers Large Language Models (LLMs)\nwith self-play learn-to-reason capabilities. Unlike prior prompt-driven\nreasoning efforts, RFTT embeds a rich set of learnable functional tokens (e.g.,\n<analyze>, <verify>, <refine>) directly into the model vocabulary, enabling\nchain-of-thought construction with diverse human-like reasoning behaviors.\nSpecifically, RFTT comprises two phases: (1) supervised fine-tuning performs\nprompt-driven tree search to obtain self-generated training data annotated with\nfunctional tokens, which warms up the model to learn these tokens for\nreasoning; and (2) online reinforcement learning further allows the model to\nexplore different reasoning pathways through functional token sampling without\nrelying on prompts, thereby facilitating effective self-improvement for\nfunctional reasoning. Extensive experiments demonstrate the superiority of the\nproposed RFTT on mathematical benchmarks, significantly boosting\nQwen-2.5-7B-Instruct (70.6% to 79.8%) and LLaMA-3.1-8B-Instruct (32.2% to\n60.2%) on the MATH dataset. Moreover, the performance of RFTT consistently\nimproves with more search rollouts at inference time. Our code is available at\nhttps://github.com/sastpg/RFTT.",
      "tldr_zh": "本研究提出了一种名为 Reinforced Functional Token Tuning (RFTT) 的新型强化微调框架，用于增强大型语言模型 (LLMs) 的自我游戏学习推理能力。RFTT 通过将可学习的函数令牌（如 <analyze>, <verify>, <refine>）嵌入模型词汇表，支持构建多样化的链式思维 (chain-of-thought) 推理行为，并分为两个阶段：首先进行监督微调以生成带函数令牌的训练数据，其次通过在线强化学习让模型无提示地探索推理路径，实现自提升。实验结果显示，RFTT 在数学基准测试如 MATH 数据集上显著提升模型性能，例如 Qwen-2.5-7B-Instruct 的准确率从 70.6% 提高到 79.8%，LLaMA-3.1-8B-Instruct 从 32.2% 提高到 60.2%，且性能随推理时的搜索回合增加而持续改善。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.13389v1",
      "published_date": "2025-02-19 02:59:42 UTC",
      "updated_date": "2025-02-19 02:59:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:10:14.919098"
    },
    {
      "arxiv_id": "2502.14909v2",
      "title": "Comparing Deep Neural Network for Multi-Label ECG Diagnosis From Scanned ECG",
      "title_zh": "翻译失败",
      "authors": [
        "Cuong V. Nguyen",
        "Hieu X. Nguyen",
        "Dung D. Pham Minh",
        "Cuong D. Do"
      ],
      "abstract": "Automated ECG diagnosis has seen significant advancements with deep learning\ntechniques, but real-world applications still face challenges when dealing with\nscanned paper ECGs. In this study, we explore multi-label classification of\nECGs extracted from scanned images, moving beyond traditional binary\nclassification (normal/abnormal). We evaluate the performance of multiple deep\nneural network architectures, including AlexNet, VGG, ResNet, and Vision\nTransformer, on scanned ECG datasets. Our comparative analysis examines model\naccuracy, robustness to image artifacts, and generalizability across different\nECG conditions. Additionally, we investigate whether ECG signals extracted from\nscanned images retain sufficient diagnostic information for reliable automated\nclassification. The findings highlight the strengths and limitations of each\narchitecture, providing insights into the feasibility of image-based ECG\ndiagnosis and its potential integration into clinical workflows.",
      "tldr_zh": "本文比较了多种深度神经网络架构（包括 AlexNet、VGG、ResNet 和 Vision Transformer）在从扫描 ECG 图像进行多标签分类诊断中的性能，超越了传统的二元分类（正常/异常）。研究评估了这些模型的准确性、对图像伪影的鲁棒性，以及在不同 ECG 条件下的泛化能力。结果表明，从扫描图像提取的 ECG 信号保留了足够的诊断信息，但每个架构都有其优缺点，为图像-based ECG 诊断的可行性和临床整合提供了重要见解。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14909v2",
      "published_date": "2025-02-19 02:56:27 UTC",
      "updated_date": "2025-03-06 05:18:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:10:25.543265"
    },
    {
      "arxiv_id": "2502.13388v1",
      "title": "Reflection of Episodes: Learning to Play Game from Expert and Self Experiences",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaojie Xu",
        "Zongyuan Li",
        "Chang Lu",
        "Runnan Qi",
        "Yanan Ni",
        "Lumin Jiang",
        "Xiangbei Liu",
        "Xuebo Zhang",
        "Yongchun Fang",
        "Kuihua Huang",
        "Xian Guo",
        "Zhanghua Wu",
        "Zhenya Li"
      ],
      "abstract": "StarCraft II is a complex and dynamic real-time strategy (RTS) game\nenvironment, which is very suitable for artificial intelligence and\nreinforcement learning research. To address the problem of Large Language\nModel(LLM) learning in complex environments through self-reflection, we propose\na Reflection of Episodes(ROE) framework based on expert experience and\nself-experience. This framework first obtains key information in the game\nthrough a keyframe selection method, then makes decisions based on expert\nexperience and self-experience. After a game is completed, it reflects on the\nprevious experience to obtain new self-experience. Finally, in the experiment,\nour method beat the robot under the Very Hard difficulty in TextStarCraft II.\nWe analyze the data of the LLM in the process of the game in detail, verified\nits effectiveness.",
      "tldr_zh": "该论文提出了一种Reflection of Episodes (ROE)框架，旨在帮助Large Language Model (LLM)在复杂实时策略游戏如StarCraft II中，通过专家经验和自我经验进行学习。框架首先使用关键帧选择方法提取游戏关键信息，然后结合专家和自我经验做出决策，并在游戏结束后通过自我反思生成新的自我经验。实验结果显示，该方法在TextStarCraft II中击败了Very Hard难度的机器人，并通过详细分析LLM的数据验证了其有效性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.13388v1",
      "published_date": "2025-02-19 02:53:43 UTC",
      "updated_date": "2025-02-19 02:53:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:10:37.262084"
    },
    {
      "arxiv_id": "2502.15801v1",
      "title": "An explainable transformer circuit for compositional generalization",
      "title_zh": "翻译失败",
      "authors": [
        "Cheng Tang",
        "Brenden Lake",
        "Mehrdad Jazayeri"
      ],
      "abstract": "Compositional generalization-the systematic combination of known components\ninto novel structures-remains a core challenge in cognitive science and machine\nlearning. Although transformer-based large language models can exhibit strong\nperformance on certain compositional tasks, the underlying mechanisms driving\nthese abilities remain opaque, calling into question their interpretability. In\nthis work, we identify and mechanistically interpret the circuit responsible\nfor compositional induction in a compact transformer. Using causal ablations,\nwe validate the circuit and formalize its operation using a program-like\ndescription. We further demonstrate that this mechanistic understanding enables\nprecise activation edits to steer the model's behavior predictably. Our\nfindings advance the understanding of complex behaviors in transformers and\nhighlight such insights can provide a direct pathway for model control.",
      "tldr_zh": "该研究针对组合泛化(compositional generalization)的挑战，探讨了Transformer模型如何系统地将已知组件组合成新结构，同时解决其机制不透明的问题。通过识别并机制解释一个紧凑Transformer中的电路，使用因果消融(causal ablations)进行验证，并以程序-like描述形式化其操作。研究进一步证明，这种理解允许精确的激活编辑来预测性地引导模型行为，从而提升了对Transformer复杂行为的认知，并为模型控制提供直接路径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.15801v1",
      "published_date": "2025-02-19 02:30:41 UTC",
      "updated_date": "2025-02-19 02:30:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:10:51.142615"
    },
    {
      "arxiv_id": "2502.13376v1",
      "title": "Learning Symbolic Task Decompositions for Multi-Agent Teams",
      "title_zh": "翻译失败",
      "authors": [
        "Ameesh Shah",
        "Niklas Lauffer",
        "Thomas Chen",
        "Nikhil Pitta",
        "Sanjit A. Seshia"
      ],
      "abstract": "One approach for improving sample efficiency in cooperative multi-agent\nlearning is to decompose overall tasks into sub-tasks that can be assigned to\nindividual agents. We study this problem in the context of reward machines:\nsymbolic tasks that can be formally decomposed into sub-tasks. In order to\nhandle settings without a priori knowledge of the environment, we introduce a\nframework that can learn the optimal decomposition from model-free interactions\nwith the environment. Our method uses a task-conditioned architecture to\nsimultaneously learn an optimal decomposition and the corresponding agents'\npolicies for each sub-task. In doing so, we remove the need for a human to\nmanually design the optimal decomposition while maintaining the\nsample-efficiency benefits of improved credit assignment. We provide\nexperimental results in several deep reinforcement learning settings,\ndemonstrating the efficacy of our approach. Our results indicate that our\napproach succeeds even in environments with codependent agent dynamics,\nenabling synchronous multi-agent learning not achievable in previous works.",
      "tldr_zh": "本文提出了一种框架，用于在多智能体团队中学习符号任务分解（symbolic task decompositions），以提高合作学习的样本效率。框架利用任务条件架构（task-conditioned architecture）从模型无关的环境交互中，同时学习最优任务分解和每个子任务的代理策略，从而避免了手动设计分解的需求。相比传统方法，该方法在 reward machines 的基础上改进了信用分配（credit assignment），适用于代理动态相互依赖的环境。实验结果在多个深度强化学习（deep reinforcement learning）设置中证明了其有效性，实现了之前工作无法达到的同步多智能体学习。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.LG",
        "F.2.2"
      ],
      "primary_category": "cs.MA",
      "comment": "8 pages, main track full paper at AAMAS 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.13376v1",
      "published_date": "2025-02-19 02:24:44 UTC",
      "updated_date": "2025-02-19 02:24:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:11:03.571198"
    },
    {
      "arxiv_id": "2502.13989v1",
      "title": "Erasing with Precision: Evaluating Specific Concept Erasure from Text-to-Image Generative Models",
      "title_zh": "翻译失败",
      "authors": [
        "Masane Fuchi",
        "Tomohiro Takagi"
      ],
      "abstract": "Studies have been conducted to prevent specific concepts from being generated\nfrom pretrained text-to-image generative models, achieving concept erasure in\nvarious ways. However, the performance evaluation of these studies is still\nlargely reliant on visualization, with the superiority of studies often\ndetermined by human subjectivity. The metrics of quantitative evaluation also\nvary, making comprehensive comparisons difficult. We propose EraseEval, an\nevaluation method that differs from previous evaluation methods in that it\ninvolves three fundamental evaluation criteria: (1) How well does the prompt\ncontaining the target concept be reflected, (2) To what extent the concepts\nrelated to the erased concept can reduce the impact of the erased concept, and\n(3) Whether other concepts are preserved. These criteria are evaluated and\nintegrated into a single metric, such that a lower score is given if any of the\nevaluations are low, leading to a more robust assessment. We experimentally\nevaluated baseline concept erasure methods, organized their characteristics,\nand identified challenges with them. Despite being fundamental evaluation\ncriteria, some concept erasure methods failed to achieve high scores, which\npoint toward future research directions for concept erasure methods. Our code\nis available at https://github.com/fmp453/erase-eval.",
      "tldr_zh": "这篇论文针对文本到图像生成模型（Text-to-Image Generative Models）中的特定概念删除（Concept Erasure）评估问题，指出现有方法依赖主观可视化和不统一的量化指标，导致比较困难。作者提出了EraseEval评估方法，该方法基于三个核心标准：目标概念在提示中的反映程度、相关概念的影响减少程度，以及其他概念的保留情况，并将这些标准整合成一个单一指标，以提供更稳健的评估。实验结果显示，基线概念删除方法存在不足，无法在所有标准上取得高分，从而揭示了潜在挑战，并为未来研究方向提供了指导。代码已在GitHub上开源。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "21 pages, 8 figures, 15 tables",
      "pdf_url": "http://arxiv.org/pdf/2502.13989v1",
      "published_date": "2025-02-19 02:19:38 UTC",
      "updated_date": "2025-02-19 02:19:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:11:15.775263"
    },
    {
      "arxiv_id": "2502.13373v1",
      "title": "Fighter Jet Navigation and Combat using Deep Reinforcement Learning with Explainable AI",
      "title_zh": "基于深度强化学习和可解释人工智能的战斗机导航与作战",
      "authors": [
        "Swati Kar",
        "Soumyabrata Dey",
        "Mahesh K Banavar",
        "Shahnewaz Karim Sakib"
      ],
      "abstract": "This paper presents the development of an Artificial Intelligence (AI) based\nfighter jet agent within a customized Pygame simulation environment, designed\nto solve multi-objective tasks via deep reinforcement learning (DRL). The jet's\nprimary objectives include efficiently navigating the environment, reaching a\ntarget, and selectively engaging or evading an enemy. A reward function\nbalances these goals while optimized hyperparameters enhance learning\nefficiency. Results show more than 80\\% task completion rate, demonstrating\neffective decision-making. To enhance transparency, the jet's action choices\nare analyzed by comparing the rewards of the actual chosen action (factual\naction) with those of alternate actions (counterfactual actions), providing\ninsights into the decision-making rationale. This study illustrates DRL's\npotential for multi-objective problem-solving with explainable AI. Project page\nis available at:\n\\href{https://github.com/swatikar95/Autonomous-Fighter-Jet-Navigation-and-Combat}{Project\nGitHub Link}.",
      "tldr_zh": "本论文开发了一个基于深度强化学习 (DRL) 的战斗机 AI 代理，在自定义 Pygame 环境中处理多目标任务，包括高效导航、到达目标以及选择性地交战或逃避。代理通过优化奖励函数和超参数来平衡这些目标，并采用可解释 AI 方法，比较实际行动 (factual action) 与备选行动 (counterfactual actions) 的奖励，提供决策过程的透明解释。实验结果显示任务完成率超过 80%，证明了 DRL 在多目标问题解决中的有效性，并为未来自主战斗系统奠定了基础。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.13373v1",
      "published_date": "2025-02-19 02:14:27 UTC",
      "updated_date": "2025-02-19 02:14:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:11:27.348995"
    },
    {
      "arxiv_id": "2502.13361v1",
      "title": "RGAR: Recurrence Generation-augmented Retrieval for Factual-aware Medical Question Answering",
      "title_zh": "翻译失败",
      "authors": [
        "Sichu Liang",
        "Linhai Zhang",
        "Hongyu Zhu",
        "Wenwen Wang",
        "Yulan He",
        "Deyu Zhou"
      ],
      "abstract": "Medical question answering requires extensive access to specialized\nconceptual knowledge. The current paradigm, Retrieval-Augmented Generation\n(RAG), acquires expertise medical knowledge through large-scale corpus\nretrieval and uses this knowledge to guide a general-purpose large language\nmodel (LLM) for generating answers. However, existing retrieval approaches\noften overlook the importance of factual knowledge, which limits the relevance\nof retrieved conceptual knowledge and restricts its applicability in real-world\nscenarios, such as clinical decision-making based on Electronic Health Records\n(EHRs). This paper introduces RGAR, a recurrence generation-augmented retrieval\nframework that retrieves both relevant factual and conceptual knowledge from\ndual sources (i.e., EHRs and the corpus), allowing them to interact and refine\neach another. Through extensive evaluation across three factual-aware medical\nquestion answering benchmarks, RGAR establishes a new state-of-the-art\nperformance among medical RAG systems. Notably, the Llama-3.1-8B-Instruct model\nwith RGAR surpasses the considerably larger, RAG-enhanced GPT-3.5. Our findings\ndemonstrate the benefit of extracting factual knowledge for retrieval, which\nconsistently yields improved generation quality.",
      "tldr_zh": "该论文提出了 RGAR，一种循环生成增强检索框架，用于事实感知的医疗问答系统，以解决现有 Retrieval-Augmented Generation (RAG) 方法忽略事实知识导致检索相关性不足的问题。RGAR 通过从 Electronic Health Records (EHRs) 和大型语料库中同时检索事实和概念知识，并让它们相互交互和精炼，从而提升知识的准确性和适用性。在三个医疗问答基准测试中，RGAR 建立了新的最先进性能，其中 Llama-3.1-8B-Instruct 模型与 RGAR 结合超过了更大的 RAG 增强 GPT-3.5。研究结果证明，提取事实知识能一致地改善生成质量，为临床决策等实际场景提供更可靠的支持。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.13361v1",
      "published_date": "2025-02-19 01:50:10 UTC",
      "updated_date": "2025-02-19 01:50:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:11:39.900113"
    },
    {
      "arxiv_id": "2502.18495v2",
      "title": "A Comprehensive Survey on Composed Image Retrieval",
      "title_zh": "组合图像检索的全面综述",
      "authors": [
        "Xuemeng Song",
        "Haoqiang Lin",
        "Haokun Wen",
        "Bohan Hou",
        "Mingzhu Xu",
        "Liqiang Nie"
      ],
      "abstract": "Composed Image Retrieval (CIR) is an emerging yet challenging task that\nallows users to search for target images using a multimodal query, comprising a\nreference image and a modification text specifying the user's desired changes\nto the reference image. Given its significant academic and practical value, CIR\nhas become a rapidly growing area of interest in the computer vision and\nmachine learning communities, particularly with the advances in deep learning.\nTo the best of our knowledge, there is currently no comprehensive review of CIR\nto provide a timely overview of this field. Therefore, we synthesize insights\nfrom over 120 publications in top conferences and journals, including ACM TOIS,\nSIGIR, and CVPR In particular, we systematically categorize existing supervised\nCIR and zero-shot CIR models using a fine-grained taxonomy. For a comprehensive\nreview, we also briefly discuss approaches for tasks closely related to CIR,\nsuch as attribute-based CIR and dialog-based CIR. Additionally, we summarize\nbenchmark datasets for evaluation and analyze existing supervised and zero-shot\nCIR methods by comparing experimental results across multiple datasets.\nFurthermore, we present promising future directions in this field, offering\npractical insights for researchers interested in further exploration. The\ncurated collection of related works is maintained and continuously updated in\nhttps://github.com/haokunwen/Awesome-Composed-Image-Retrieval.",
      "tldr_zh": "这是一篇关于 Composed Image Retrieval (CIR) 的全面调查，回顾了超过 120 篇顶级会议和期刊的出版物，系统分类了现有 supervised CIR 和 zero-shot CIR 模型，并使用细粒度分类法分析其方法。论文还讨论了相关任务，如 attribute-based CIR 和 dialog-based CIR，总结了基准数据集并比较了多数据集上的实验结果。最终，它提出了 CIR 领域的未来研究方向，并提供了一个持续更新的 GitHub 仓库（https://github.com/haokunwen/Awesome-Composed-Image-Retrieval）以供参考。",
      "categories": [
        "cs.MM",
        "cs.AI",
        "cs.CV",
        "cs.IR"
      ],
      "primary_category": "cs.MM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.18495v2",
      "published_date": "2025-02-19 01:37:24 UTC",
      "updated_date": "2025-03-04 15:16:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:11:51.260311"
    },
    {
      "arxiv_id": "2502.14908v2",
      "title": "SegSub: Evaluating Robustness to Knowledge Conflicts and Hallucinations in Vision-Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Peter Carragher",
        "Nikitha Rao",
        "Abhinand Jha",
        "R Raghav",
        "Kathleen M. Carley"
      ],
      "abstract": "Vision language models (VLM) demonstrate sophisticated multimodal reasoning\nyet are prone to hallucination when confronted with knowledge conflicts,\nimpeding their deployment in information-sensitive contexts. While existing\nresearch addresses robustness in unimodal models, the multimodal domain lacks\nsystematic investigation of cross-modal knowledge conflicts. This research\nintroduces \\segsub, a framework for applying targeted image perturbations to\ninvestigate VLM resilience against knowledge conflicts. Our analysis reveals\ndistinct vulnerability patterns: while VLMs are robust to parametric conflicts\n(20% adherence rates), they exhibit significant weaknesses in identifying\ncounterfactual conditions (<30% accuracy) and resolving source conflicts (<1%\naccuracy). Correlations between contextual richness and hallucination rate (r =\n-0.368, p = 0.003) reveal the kinds of images that are likely to cause\nhallucinations. Through targeted fine-tuning on our benchmark dataset, we\ndemonstrate improvements in VLM knowledge conflict detection, establishing a\nfoundation for developing hallucination-resilient multimodal systems in\ninformation-sensitive environments.",
      "tldr_zh": "本文评估了视觉语言模型 (VLMs) 在面对知识冲突和 hallucination 时的鲁棒性，引入了 SegSub 框架，通过针对性图像扰动 (image perturbations) 来系统调查跨模态知识冲突。研究发现，VLMs 对参数冲突 (parametric conflicts) 表现出较高鲁棒性 (20%  adherence rates)，但在识别反事实条件 (counterfactual conditions) 和解决来源冲突 (source conflicts) 上准确率极低 (<30% 和 <1%)。此外，图像的上下文丰富度与 hallucination 率呈负相关 (r = -0.368, p = 0.003)，有助于识别易引发幻觉的图像类型。通过在基准数据集上进行针对性 fine-tuning，论文显著提升了 VLM 的知识冲突检测能力，为构建抗 hallucination 的多模态系统提供了基础。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14908v2",
      "published_date": "2025-02-19 00:26:38 UTC",
      "updated_date": "2025-05-09 18:36:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:12:05.212095"
    },
    {
      "arxiv_id": "2502.14907v1",
      "title": "GneissWeb: Preparing High Quality Data for LLMs at Scale",
      "title_zh": "GneissWeb：",
      "authors": [
        "Hajar Emami Gohari",
        "Swanand Ravindra Kadhe",
        "Syed Yousaf Shah. Constantin Adam",
        "Abdulhamid Adebayo",
        "Praneet Adusumilli",
        "Farhan Ahmed",
        "Nathalie Baracaldo Angel",
        "Santosh Borse",
        "Yuan-Chi Chang",
        "Xuan-Hong Dang",
        "Nirmit Desai",
        "Ravital Eres",
        "Ran Iwamoto",
        "Alexei Karve",
        "Yan Koyfman",
        "Wei-Han Lee",
        "Changchang Liu",
        "Boris Lublinsky",
        "Takuyo Ohko",
        "Pablo Pesce",
        "Maroun Touma",
        "Shiqiang Wang",
        "Shalisha Witherspoon",
        "Herbert Woisetschlager",
        "David Wood",
        "Kun-Lung Wu",
        "Issei Yoshida",
        "Syed Zawad",
        "Petros Zerfos",
        "Yi Zhou",
        "Bishwaranjan Bhattacharjee"
      ],
      "abstract": "Data quantity and quality play a vital role in determining the performance of\nLarge Language Models (LLMs). High-quality data, in particular, can\nsignificantly boost the LLM's ability to generalize on a wide range of\ndownstream tasks. Large pre-training datasets for leading LLMs remain\ninaccessible to the public, whereas many open datasets are small in size (less\nthan 5 trillion tokens), limiting their suitability for training large models.\n  In this paper, we introduce GneissWeb, a large dataset yielding around 10\ntrillion tokens that caters to the data quality and quantity requirements of\ntraining LLMs. Our GneissWeb recipe that produced the dataset consists of\nsharded exact sub-string deduplication and a judiciously constructed ensemble\nof quality filters. GneissWeb achieves a favorable trade-off between data\nquality and quantity, producing models that outperform models trained on\nstate-of-the-art open large datasets (5+ trillion tokens).\n  We show that models trained using GneissWeb dataset outperform those trained\non FineWeb-V1.1.0 by 2.73 percentage points in terms of average score computed\non a set of 11 commonly used benchmarks (both zero-shot and few-shot) for\npre-training dataset evaluation. When the evaluation set is extended to 20\nbenchmarks (both zero-shot and few-shot), models trained using GneissWeb still\nachieve a 1.75 percentage points advantage over those trained on\nFineWeb-V1.1.0.",
      "tldr_zh": "这篇论文介绍了 GneissWeb，这是一个约 10 万亿 tokens 的数据集，旨在为大型语言模型 (LLMs) 提供高质量且大规模的数据，以提升模型在下游任务上的泛化能力。该数据集通过 sharded exact sub-string deduplication 和一个精心构建的质量过滤器 ensemble 来实现数据质量与数量的平衡。实验结果显示，使用 GneissWeb 训练的模型在 11 个常用基准测试中比 FineWeb-V1.1.0 高出 2.73 百分点，在扩展至 20 个基准测试时仍领先 1.75 百分点。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14907v1",
      "published_date": "2025-02-19 00:14:29 UTC",
      "updated_date": "2025-02-19 00:14:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:12:14.682099"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 168,
  "processed_papers_count": 168,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-23T16:12:40.183123"
}