{
  "date": "2025-05-18",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-05-18 的 arXiv 中文 TLDR 快报！今天的论文主要聚焦 AI 模型的安全性、强化学习、多模态处理和知识图谱等领域，亮点包括对 LLM 攻击的系统综述（如 Wenrui Xu 的论文）和数学基准数据集的提出（如 Jie Zhang 的 RealMath），以及知名学者如 Heng Ji 参与的化学语言模型研究，强调了模型鲁棒性、效率优化和实际应用潜力。\n\n### 重点论文亮点\n我们挑选了几篇重要、话题性和影响大的论文先聊，这些涉及 LLM 安全、基准构建和创新框架，具有广泛的学术和实际影响。其他论文则快速掠过，只提核心点。\n\n1. **A Survey of Attacks on Large Language Models（大型语言模型攻击综述）**  \n   作者：Wenrui Xu, Keshab K. Parhi  \n   这篇综述性论文系统分析了 LLM 和基于 LLM 的代理在训练、推理和可用性阶段面临的攻击，包括恶意利用、隐私泄露和服务中断。贡献在于组织攻击类型并讨论防御策略，为 LLM 安全研究提供全面指南，强调了实际部署中的风险管理。\n\n2. **RealMath: A Continuous Benchmark for Evaluating Language Models on Research-Level Mathematics（RealMath：用于评估语言模型研究级数学能力的连续基准）**  \n   作者：Jie Zhang, Cezara Petrui, Kristina Nikolić, Florian Tramèr  \n   这篇论文引入 RealMath 基准，使用真实研究论文和论坛数据评估 LLM 在数学任务上的性能。关键发现是 LLM 在真实场景下比竞赛问题更具潜力，但仍受限；数据集公开可用，促进了更可靠的数学推理评估。\n\n3. **mCLM: A Function-Infused and Synthesis-Friendly Modular Chemical Language Model（mCLM：功能注入的模块化化学语言模型，支持合成友好）**  \n   作者：Carl Edwards, Chi Han, Gawon Lee, Thao Nguyen, Bowen Jin, Chetan Kumar Prasad, Sara Szymkuć, Bartosz A. Grzybowski, Ying Diao, Jiawei Han, Ge Liu, Hao Peng, Martin D. Burke, Heng Ji  \n   知名学者 Heng Ji 和 Jiawei Han 参与，这篇论文提出 mCLM 模型，通过分解分子为功能模块，提升 LLM 在化学合成中的性能。发现是显著改善药物功能（如 FDA 药物优化），并确保合成可行性，展示了 LLM 在科学领域的实际应用潜力。\n\n4. **AdaDim: Dimensionality Adaptation for SSL Representational Dynamics（AdaDim：自监督学习表示动态的维度适应）**  \n   作者：Kiran Kokilepersaud, Mohit Prabhushankar, Ghassan AlRegib  \n   这篇论文分析自监督学习中的维度坍缩问题，提出 AdaDim 方法，通过自适应加权损失平衡特征 decorrelation 和样本分布。关键贡献是揭示最佳 SSL 模型并非追求最高维度或最低互信息，而是中间最优点，提高了下游任务性能。\n\n相关论文如 #14 \"ALAS: A Stateful Multi-LLM Agent Framework for Disruption-Aware Planning（ALAS：面向中断感知规划的状态化多 LLM 代理框架）\" 和 #25 \"RAGXplain: From Explainable Evaluation to Actionable Guidance of RAG Pipelines（RAGXplain：从可解释评估到 RAG 管道的可操作指导）\"，则聚焦多代理协作和检索增强生成，提供鲁棒规划和优化策略，进一步强化 LLM 在复杂任务中的可靠性。\n\n### 其他论文速览\n其余论文覆盖广泛领域，以 AI 和机器学习为主，我们只快速提提核心点：\n- **强化学习和优化**：如 #10 \"Scalable Strategies for Continual Learning with Replay（可扩展的连续学习策略使用重放）\" 提出重放样本优化，提升模型适应性；#13 \"CPGD: Toward Stable Rule-based Reinforcement Learning for Language Models（CPGD：面向语言模型的稳定规则强化学习）\" 使用 KL 散度约束稳定训练。\n- **多模态和视觉**：#7 \"FreqSelect: Frequency-Aware fMRI-to-Image Reconstruction（FreqSelect：频率感知的 fMRI 到图像重建）\" 通过频率选择提升脑成像重建；#19 \"Video-GPT via Next Clip Diffusion（Video-GPT 通过下一剪辑扩散）\" 创新视频生成框架。\n- **知识图谱和基准**：#21 \"Enhancing Large Language Models with Reward-guided Tree Search for Knowledge Graph Question and Answering（使用奖励引导树搜索增强 LLM 的知识图谱问答）\" 优化知识图谱推理；#48 \"FinMaster: A Holistic Benchmark for Mastering Full-Pipeline Financial Workflows with LLMs（FinMaster：用于 LLM 金融工作流的整体基准）\" 构建金融任务基准。\n- **其他领域**：如 #6 \"Beyond Accuracy: EcoL2 Metric for Sustainable Neural PDE Solvers（超越准确性：EcoL2 指标用于可持续神经 PDE 求解器）\" 引入环境影响指标；#8 \"ProMi: An Efficient Prototype-Mixture Baseline for Few-Shot Segmentation（ProMi：少样本分割的有效原型混合基准）\" 简化分割任务。这些论文虽有贡献，但影响力较小，就不展开了。\n\n今天的快报到此为止，arXiv 持续更新这些前沿话题，感兴趣的读者可以关注 AI 安全和 LLM 优化领域！",
  "papers": [
    {
      "arxiv_id": "2505.12576v1",
      "title": "AdaDim: Dimensionality Adaptation for SSL Representational Dynamics",
      "title_zh": "AdaDim：自监督学习表示动态的维度适应",
      "authors": [
        "Kiran Kokilepersaud",
        "Mohit Prabhushankar",
        "Ghassan AlRegib"
      ],
      "abstract": "A key factor in effective Self-Supervised learning (SSL) is preventing\ndimensional collapse, which is where higher-dimensional representation spaces\nspan a lower-dimensional subspace. Therefore, SSL optimization strategies\ninvolve guiding a model to produce representations ($R$) with a higher\ndimensionality. Dimensionality is either optimized through a\ndimension-contrastive approach that encourages feature decorrelation or through\na sample-contrastive method that promotes a uniform spread of sample\nrepresentations. Both families of SSL algorithms also utilize a projection head\nthat maps $R$ into a lower-dimensional embedding space $Z$. Recent work has\ncharacterized the projection head as a filter of irrelevant features from the\nSSL objective by reducing mutual information, $I(R;Z)$. Therefore, the current\nliterature's view is that a good SSL representation space should have a high\n$H(R)$ and a low $I(R;Z)$. However, this view of the problem is lacking in\nterms of an understanding of the underlying training dynamics that influences\nboth terms, as well as how the values of $H(R)$ and $I(R;Z)$ arrived at the end\nof training reflect the downstream performance of an SSL model. We address both\ngaps in the literature by demonstrating that increases in $H(R)$ due to feature\ndecorrelation at the start of training lead to a higher $I(R;Z)$, while\nincreases in $H(R)$ due to samples distributing uniformly in a high-dimensional\nspace at the end of training cause $I(R;Z)$ to plateau or decrease.\nFurthermore, our analysis shows that the best performing SSL models do not have\nthe highest $H(R)$ nor the lowest $I(R;Z)$, but arrive at an optimal\nintermediate point for both. We develop a method called AdaDim to exploit these\nobserved training dynamics by adaptively weighting between losses based on\nfeature decorrelation and uniform sample spread.",
      "tldr_zh": "这篇论文探讨了自监督学习(SSL)中表示空间的维度动态，强调防止维度坍缩的关键是通过特征去相关和样本均匀分布来优化表示熵 H(R) 和互信息 I(R;Z)。作者发现，训练早期特征去相关导致 H(R) 增加的同时会提高 I(R;Z)，而训练后期样本均匀分布则使 I(R;Z) 平稳或降低；此外，最佳性能的 SSL 模型并非 H(R) 最高或 I(R;Z) 最低，而是达到一个中间平衡点。他们提出了 AdaDim 方法，通过自适应加权特征去相关和样本均匀分布的损失，利用这些训练动态来提升 SSL 模型的整体表现。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Under Review",
      "pdf_url": "http://arxiv.org/pdf/2505.12576v1",
      "published_date": "2025-05-18 23:35:34 UTC",
      "updated_date": "2025-05-18 23:35:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:36:50.158025"
    },
    {
      "arxiv_id": "2505.12575v1",
      "title": "RealMath: A Continuous Benchmark for Evaluating Language Models on Research-Level Mathematics",
      "title_zh": "RealMath：用于评估语言模型在研究级数学上的持续基准",
      "authors": [
        "Jie Zhang",
        "Cezara Petrui",
        "Kristina Nikolić",
        "Florian Tramèr"
      ],
      "abstract": "Existing benchmarks for evaluating mathematical reasoning in large language\nmodels (LLMs) rely primarily on competition problems, formal proofs, or\nartificially challenging questions -- failing to capture the nature of\nmathematics encountered in actual research environments. We introduce RealMath,\na novel benchmark derived directly from research papers and mathematical forums\nthat assesses LLMs' abilities on authentic mathematical tasks. Our approach\naddresses three critical challenges: sourcing diverse research-level content,\nenabling reliable automated evaluation through verifiable statements, and\ndesigning a continually refreshable dataset to mitigate contamination risks.\nExperimental results across multiple LLMs reveal surprising capabilities in\nhandling research mathematics compared to competition problems, suggesting\ncurrent models may already serve as valuable assistants for working\nmathematicians despite limitations on highly challenging problems. The code and\ndataset for RealMath are publicly available.",
      "tldr_zh": "该论文引入了RealMath，一个从研究论文和数学论坛中衍生而来的连续基准，用于评估大型语言模型(LLMs)在研究级数学任务上的能力，以弥补现有基准（如竞赛问题或人工挑战）无法捕捉真实研究环境的不足。RealMath解决了三个关键挑战：获取多样化的研究级内容、通过可验证语句实现可靠的自动化评估，以及设计可持续刷新的数据集以降低污染风险。实验结果显示，多种LLMs在处理研究数学问题时表现出色，比在竞赛问题上更具优势，表明这些模型已可作为工作数学家的宝贵助手，尽管在高度挑战性问题上仍有局限。该基准的代码和数据集已公开可用。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12575v1",
      "published_date": "2025-05-18 23:32:46 UTC",
      "updated_date": "2025-05-18 23:32:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:37:00.825949"
    },
    {
      "arxiv_id": "2505.12572v1",
      "title": "Measuring Information Distortion in Hierarchical Ultra long Novel Generation:The Optimal Expansion Ratio",
      "title_zh": "翻译失败",
      "authors": [
        "Hanwen Shen",
        "Ting Ying"
      ],
      "abstract": "Writing novels with Large Language Models (LLMs) raises a critical question:\nhow much human-authored outline is necessary to generate high-quality\nmillion-word novels? While frameworks such as DOME, Plan&Write, and Long Writer\nhave improved stylistic coherence and logical consistency, they primarily\ntarget shorter novels (10k--100k words), leaving ultra-long generation largely\nunexplored. Drawing on insights from recent text compression methods like\nLLMZip and LLM2Vec, we conduct an information-theoretic analysis that\nquantifies distortion occurring when LLMs compress and reconstruct ultra-long\nnovels under varying compression-expansion ratios. We introduce a hierarchical\ntwo-stage generation pipeline (outline -> detailed outline -> manuscript) and\nfind an optimal outline length that balances information preservation with\nhuman effort. Through extensive experimentation with Chinese novels, we\nestablish that a two-stage hierarchical outline approach significantly reduces\nsemantic distortion compared to single-stage methods. Our findings provide\nempirically-grounded guidance for authors and researchers collaborating with\nLLMs to create million-word novels.",
      "tldr_zh": "本论文探讨了使用大型语言模型（LLMs）生成百万字长篇小说时，所需人类提纲的长度问题，并量化了信息失真。研究借鉴了LLMZip和LLM2Vec等文本压缩方法，引入了一个分层两阶段生成管道（outline -> detailed outline -> manuscript），通过信息理论分析确定了最佳扩展比率，以平衡信息保留和人类努力。实验结果显示，该方法在中文小说生成中显著降低了语义失真，并为作者和研究人员与LLMs合作创建超长小说提供了实证指导。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IT",
        "math.IT"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12572v1",
      "published_date": "2025-05-18 23:20:01 UTC",
      "updated_date": "2025-05-18 23:20:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:37:12.747722"
    },
    {
      "arxiv_id": "2505.12567v1",
      "title": "A Survey of Attacks on Large Language Models",
      "title_zh": "针对大语言模型的攻击综述",
      "authors": [
        "Wenrui Xu",
        "Keshab K. Parhi"
      ],
      "abstract": "Large language models (LLMs) and LLM-based agents have been widely deployed\nin a wide range of applications in the real world, including healthcare\ndiagnostics, financial analysis, customer support, robotics, and autonomous\ndriving, expanding their powerful capability of understanding, reasoning, and\ngenerating natural languages. However, the wide deployment of LLM-based\napplications exposes critical security and reliability risks, such as the\npotential for malicious misuse, privacy leakage, and service disruption that\nweaken user trust and undermine societal safety. This paper provides a\nsystematic overview of the details of adversarial attacks targeting both LLMs\nand LLM-based agents. These attacks are organized into three phases in LLMs:\nTraining-Phase Attacks, Inference-Phase Attacks, and Availability & Integrity\nAttacks. For each phase, we analyze the details of representative and recently\nintroduced attack methods along with their corresponding defenses. We hope our\nsurvey will provide a good tutorial and a comprehensive understanding of LLM\nsecurity, especially for attacks on LLMs. We desire to raise attention to the\nrisks inherent in widely deployed LLM-based applications and highlight the\nurgent need for robust mitigation strategies for evolving threats.",
      "tldr_zh": "这篇论文对大型语言模型（LLMs）和基于 LLMs 的代理所面临的攻击进行了系统调查，强调了这些模型在医疗诊断、金融分析等领域应用的潜在风险，如恶意滥用、隐私泄露和服务中断。论文将攻击分为三个阶段：Training-Phase Attacks、Inference-Phase Attacks 和 Availability & Integrity Attacks，并分析了每个阶段的代表性攻击方法及其对应防御策略。通过提供详细教程，该研究旨在提升对 LLM 安全的全面理解，并呼吁开发 robust 的缓解策略以应对不断演变的威胁。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12567v1",
      "published_date": "2025-05-18 22:55:16 UTC",
      "updated_date": "2025-05-18 22:55:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:37:23.771969"
    },
    {
      "arxiv_id": "2505.12565v1",
      "title": "mCLM: A Function-Infused and Synthesis-Friendly Modular Chemical Language Model",
      "title_zh": "翻译失败",
      "authors": [
        "Carl Edwards",
        "Chi Han",
        "Gawon Lee",
        "Thao Nguyen",
        "Bowen Jin",
        "Chetan Kumar Prasad",
        "Sara Szymkuć",
        "Bartosz A. Grzybowski",
        "Ying Diao",
        "Jiawei Han",
        "Ge Liu",
        "Hao Peng",
        "Martin D. Burke",
        "Heng Ji"
      ],
      "abstract": "Despite their ability to understand chemical knowledge and accurately\ngenerate sequential representations, large language models (LLMs) remain\nlimited in their capacity to propose novel molecules with drug-like properties.\nIn addition, the molecules that LLMs propose can often be challenging to make\nin the lab. To more effectively enable the discovery of functional small\nmolecules, LLMs need to learn a molecular language. However, LLMs are currently\nlimited by encoding molecules from atoms. In this paper, we argue that just\nlike tokenizing texts into (sub-)word tokens instead of characters, molecules\nshould be decomposed and reassembled at the level of functional building\nblocks, i.e., parts of molecules that bring unique functions and serve as\neffective building blocks for real-world automated laboratory synthesis. This\nmotivates us to propose mCLM, a modular Chemical-Language Model tokenizing\nmolecules into building blocks and learning a bilingual language model of both\nnatural language descriptions of functions and molecule building blocks. By\nreasoning on such functional building blocks, mCLM guarantees to generate\nefficiently synthesizable molecules thanks to recent progress in block-based\nchemistry, while also improving the functions of molecules in a principled\nmanner. In experiments on 430 FDA-approved drugs, we find mCLM capable of\nsignificantly improving 5 out of 6 chemical functions critical to determining\ndrug potentials. More importantly, mCLM can reason on multiple functions and\nimprove the FDA-rejected drugs (``fallen angels'') over multiple iterations to\ngreatly improve their shortcomings.",
      "tldr_zh": "该论文提出 mCLM，一种模块化化学语言模型（mCLM），通过将分子分解为 functional building blocks（功能构建块）而非原子级别，学习双语模型以整合自然语言功能描述和分子构建块，从而解决大型语言模型（LLMs）在生成药物分子时的局限性。mCLM 通过在这些构建块上进行推理，确保生成的分子易于合成并提升其功能，在实验中对 430 种 FDA 批准药物显著改善了 5 种关键化学功能。更为重要的是，mCLM 能处理多功能优化，并在多次迭代中改进 FDA 拒绝的药物（fallen angels），提升其潜在药效。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "q-bio.QM"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12565v1",
      "published_date": "2025-05-18 22:52:39 UTC",
      "updated_date": "2025-05-18 22:52:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:37:37.394333"
    },
    {
      "arxiv_id": "2505.12556v1",
      "title": "Beyond Accuracy: EcoL2 Metric for Sustainable Neural PDE Solvers",
      "title_zh": "翻译失败",
      "authors": [
        "Taniya Kapoor",
        "Abhishek Chandra",
        "Anastasios Stamou",
        "Stephen J Roberts"
      ],
      "abstract": "Real-world systems, from aerospace to railway engineering, are modeled with\npartial differential equations (PDEs) describing the physics of the system.\nEstimating robust solutions for such problems is essential. Deep learning-based\narchitectures, such as neural PDE solvers, have recently gained traction as a\nreliable solution method. The current state of development of these approaches,\nhowever, primarily focuses on improving accuracy. The environmental impact of\nexcessive computation, leading to increased carbon emissions, has largely been\noverlooked. This paper introduces a carbon emission measure for a range of PDE\nsolvers. Our proposed metric, EcoL2, balances model accuracy with emissions\nacross data collection, model training, and deployment. Experiments across both\nphysics-informed machine learning and operator learning architectures\ndemonstrate that the proposed metric presents a holistic assessment of model\nperformance and emission cost. As such solvers grow in scale and deployment,\nEcoL2 represents a step toward building performant scientific machine learning\nsystems with lower long-term environmental impact.",
      "tldr_zh": "本论文强调了神经偏微分方程 (PDEs) 求解器在追求准确性时忽略的环境影响，提出 EcoL2 指标作为一种平衡模型准确性和碳排放的可持续评估方法。EcoL2 考虑了数据收集、模型训练和部署阶段的排放成本，通过实验在物理信息机器学习和操作符学习架构上验证了其全面评估能力。结果显示，该指标有助于开发性能强劲且环境影响更低的科学机器学习系统。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12556v1",
      "published_date": "2025-05-18 22:05:11 UTC",
      "updated_date": "2025-05-18 22:05:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:37:48.319038"
    },
    {
      "arxiv_id": "2505.12552v1",
      "title": "FreqSelect: Frequency-Aware fMRI-to-Image Reconstruction",
      "title_zh": "FreqSelect：频率感知的 fMRI 到图像重建",
      "authors": [
        "Junliang Ye",
        "Lei Wang",
        "Md Zakir Hossain"
      ],
      "abstract": "Reconstructing natural images from functional magnetic resonance imaging\n(fMRI) data remains a core challenge in natural decoding due to the mismatch\nbetween the richness of visual stimuli and the noisy, low resolution nature of\nfMRI signals. While recent two-stage models, combining deep variational\nautoencoders (VAEs) with diffusion models, have advanced this task, they treat\nall spatial-frequency components of the input equally. This uniform treatment\nforces the model to extract meaning features and suppress irrelevant noise\nsimultaneously, limiting its effectiveness. We introduce FreqSelect, a\nlightweight, adaptive module that selectively filters spatial-frequency bands\nbefore encoding. By dynamically emphasizing frequencies that are most\npredictive of brain activity and suppressing those that are uninformative,\nFreqSelect acts as a content-aware gate between image features and natural\ndata. It integrates seamlessly into standard very deep VAE-diffusion pipelines\nand requires no additional supervision. Evaluated on the Natural Scenes\ndataset, FreqSelect consistently improves reconstruction quality across both\nlow- and high-level metrics. Beyond performance gains, the learned\nfrequency-selection patterns offer interpretable insights into how different\nvisual frequencies are represented in the brain. Our method generalizes across\nsubjects and scenes, and holds promise for extension to other neuroimaging\nmodalities, offering a principled approach to enhancing both decoding accuracy\nand neuroscientific interpretability.",
      "tldr_zh": "这篇论文针对从 fMRI 数据重建自然图像的挑战，引入了 FreqSelect，一个轻量级、适应性的模块，能够在编码前选择性地过滤空间频率带。FreqSelect 通过动态强调与脑活动相关的频率并抑制无关噪声，作为一种内容感知门控，无缝整合到标准 VAE 和扩散模型的管道中，而无需额外监督。在 Natural Scenes 数据集上的实验显示，该方法显著提高了重建质量，在低级和高水平指标上均有提升，并提供了可解释的频率选择模式，帮助理解大脑中视觉频率的表示，具有泛化性和扩展潜力。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "Research report",
      "pdf_url": "http://arxiv.org/pdf/2505.12552v1",
      "published_date": "2025-05-18 21:45:06 UTC",
      "updated_date": "2025-05-18 21:45:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:38:01.306278"
    },
    {
      "arxiv_id": "2505.12547v1",
      "title": "ProMi: An Efficient Prototype-Mixture Baseline for Few-Shot Segmentation with Bounding-Box Annotations",
      "title_zh": "翻译失败",
      "authors": [
        "Florent Chiaroni",
        "Ali Ayub",
        "Ola Ahmad"
      ],
      "abstract": "In robotics applications, few-shot segmentation is crucial because it allows\nrobots to perform complex tasks with minimal training data, facilitating their\nadaptation to diverse, real-world environments. However, pixel-level\nannotations of even small amount of images is highly time-consuming and costly.\nIn this paper, we present a novel few-shot binary segmentation method based on\nbounding-box annotations instead of pixel-level labels. We introduce, ProMi, an\nefficient prototype-mixture-based method that treats the background class as a\nmixture of distributions. Our approach is simple, training-free, and effective,\naccommodating coarse annotations with ease. Compared to existing baselines,\nProMi achieves the best results across different datasets with significant\ngains, demonstrating its effectiveness. Furthermore, we present qualitative\nexperiments tailored to real-world mobile robot tasks, demonstrating the\napplicability of our approach in such scenarios. Our code:\nhttps://github.com/ThalesGroup/promi.",
      "tldr_zh": "本论文提出ProMi，一种高效的原型混合(prototype-mixture)基线方法，用于基于bounding-box annotations的few-shot segmentation。这方法将背景类视为分布的混合，避免了像素级标注的耗时问题，并以简单、无需训练的方式处理粗糙标注。与现有基线相比，ProMi在不同数据集上实现了最佳性能，并取得了显著提升。此外，通过针对真实世界移动机器人任务的定性实验，证明了其在实际场景中的适用性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12547v1",
      "published_date": "2025-05-18 21:08:05 UTC",
      "updated_date": "2025-05-18 21:08:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:38:11.797225"
    },
    {
      "arxiv_id": "2505.12532v1",
      "title": "Exploring Sparsity for Parameter Efficient Fine Tuning Using Wavelets",
      "title_zh": "使用小波探索稀疏性以实现参数高效微调",
      "authors": [
        "Ahmet Bilican",
        "M. Akın Yılmaz",
        "A. Murat Tekalp",
        "R. Gökberk Cinbiş"
      ],
      "abstract": "Efficiently adapting large foundation models is critical, especially with\ntight compute and memory budgets. Parameter-Efficient Fine-Tuning (PEFT)\nmethods such as LoRA offer limited granularity and effectiveness in\nfew-parameter regimes. We propose Wavelet Fine-Tuning (WaveFT), a novel PEFT\nmethod that learns highly sparse updates in the wavelet domain of residual\nmatrices. WaveFT allows precise control of trainable parameters, offering\nfine-grained capacity adjustment and excelling with remarkably low parameter\ncount, potentially far fewer than LoRA's minimum -- ideal for extreme\nparameter-efficient scenarios. In order to demonstrate the effect of the\nwavelet transform, we compare WaveFT with a special case, called SHiRA, that\nentails applying sparse updates directly in the weight domain. Evaluated on\npersonalized text-to-image generation using Stable Diffusion XL as baseline,\nWaveFT significantly outperforms LoRA and other PEFT methods, especially at low\nparameter counts; achieving superior subject fidelity, prompt alignment, and\nimage diversity.",
      "tldr_zh": "本研究探讨了使用 Wavelets 实现参数高效微调（PEFT）的稀疏性，以适应计算和内存资源有限的大型基础模型。作者提出了一种新方法 Wavelet Fine-Tuning (WaveFT)，通过在残差矩阵的 Wavelet 域中学习高度稀疏的更新，实现对可训练参数的精确控制，并在极低参数计数场景下表现出色。相比于 LoRA 和其他 PEFT 方法，WaveFT 在基于 Stable Diffusion XL 的个性化文本到图像生成任务中显著提升了主体保真度、提示对齐和图像多样性，尤其在低参数设置下优于直接权重域稀疏更新的特例 SHiRA。实验结果表明，WaveFT 为极端参数高效场景提供了更细粒度的容量调整潜力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "eess.IV",
        "eess.SP"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12532v1",
      "published_date": "2025-05-18 20:20:32 UTC",
      "updated_date": "2025-05-18 20:20:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:38:25.239156"
    },
    {
      "arxiv_id": "2505.12512v1",
      "title": "Scalable Strategies for Continual Learning with Replay",
      "title_zh": "翻译失败",
      "authors": [
        "Truman Hickok"
      ],
      "abstract": "Future deep learning models will be distinguished by systems that perpetually\nlearn through interaction, imagination, and cooperation, blurring the line\nbetween training and inference. This makes continual learning a critical\nchallenge, as methods that efficiently maximize bidirectional transfer across\nlearning trajectories will be essential. Replay is on track to play a\nfoundational role in continual learning, allowing models to directly reconcile\nnew information with past knowledge. In practice, however, replay is quite\nunscalable, doubling the cost of continual learning when applied naively.\nMoreover, the continual learning literature has not fully synchronized with the\nmulti-task fine-tuning literature, having not fully integrated highly scalable\ntechniques like model merging and low rank adaptation into a replay-enabled\ntoolset that can produce a unified model in the face of many sequential tasks.\nIn this paper, we begin by applying and analyzing low rank adaptation in a\ncontinual learning setting. Next, we introduce consolidation, a phasic approach\nto replay which leads to up to 55\\% less replay samples being needed for a\ngiven performance target. Then, we propose sequential merging, an offshoot of\ntask arithmetic which is tailored to the continual learning setting and is\nshown to work well in combination with replay. Finally, we demonstrate that the\ndeveloped strategies can operate synergistically, resulting in a highly\nscalable toolset that outperforms standalone variants.",
      "tldr_zh": "本论文探讨了持续学习（continual learning）中的可扩展策略，特别针对 replay 方法的不高效问题，旨在通过整合模型合并和低秩适应（low rank adaptation）等技术来最大化跨任务的双向转移。论文首先分析了低秩适应在持续学习中的应用，然后引入 consolidation 一种阶段性方法，能减少高达55%的 replay 样本需求；同时提出 sequential merging，一种针对顺序任务的模型合并策略，与 replay 结合使用。实验结果表明，这些策略能协同工作，提供高度可扩展的工具集，并在性能上超越独立变体。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12512v1",
      "published_date": "2025-05-18 18:23:50 UTC",
      "updated_date": "2025-05-18 18:23:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:38:36.438962"
    },
    {
      "arxiv_id": "2505.12509v1",
      "title": "Towards Budget-Friendly Model-Agnostic Explanation Generation for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Junhao Liu",
        "Haonan Yu",
        "Xin Zhang"
      ],
      "abstract": "With Large language models (LLMs) becoming increasingly prevalent in various\napplications, the need for interpreting their predictions has become a critical\nchallenge. As LLMs vary in architecture and some are closed-sourced,\nmodel-agnostic techniques show great promise without requiring access to the\nmodel's internal parameters. However, existing model-agnostic techniques need\nto invoke LLMs many times to gain sufficient samples for generating faithful\nexplanations, which leads to high economic costs. In this paper, we show that\nit is practical to generate faithful explanations for large-scale LLMs by\nsampling from some budget-friendly models through a series of empirical\nstudies. Moreover, we show that such proxy explanations also perform well on\ndownstream tasks. Our analysis provides a new paradigm of model-agnostic\nexplanation methods for LLMs, by including information from budget-friendly\nmodels.",
      "tldr_zh": "这篇论文针对大型语言模型 (LLMs) 的解释生成问题，提出了一种预算友好的模型无关 (model-agnostic) 方法，以减少频繁调用 LLMs 导致的高经济成本。研究通过实证分析表明，从经济实惠的代理模型中采样可以生成忠实的解释，同时这些 proxy explanations 在下游任务中表现出色。主要贡献是建立了一个新范式，将预算友好的模型信息纳入模型无关解释框架中。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12509v1",
      "published_date": "2025-05-18 18:05:37 UTC",
      "updated_date": "2025-05-18 18:05:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:38:48.223872"
    },
    {
      "arxiv_id": "2505.12506v1",
      "title": "Unsupervised Invariant Risk Minimization",
      "title_zh": "无监督不变风险最小化",
      "authors": [
        "Yotam Norman",
        "Ron Meir"
      ],
      "abstract": "We propose a novel unsupervised framework for \\emph{Invariant Risk\nMinimization} (IRM), extending the concept of invariance to settings where\nlabels are unavailable. Traditional IRM methods rely on labeled data to learn\nrepresentations that are robust to distributional shifts across environments.\nIn contrast, our approach redefines invariance through feature distribution\nalignment, enabling robust representation learning from unlabeled data. We\nintroduce two methods within this framework: Principal Invariant Component\nAnalysis (PICA), a linear method that extracts invariant directions under\nGaussian assumptions, and Variational Invariant Autoencoder (VIAE), a deep\ngenerative model that disentangles environment-invariant and\nenvironment-dependent latent factors. Our approach is based on a novel\n``unsupervised'' structural causal model and supports environment-conditioned\nsample-generation and intervention. Empirical evaluations on synthetic dataset\nand modified versions of MNIST demonstrate the effectiveness of our methods in\ncapturing invariant structure, preserving relevant information, and\ngeneralizing across environments without access to labels.",
      "tldr_zh": "该论文提出了一种无监督的Invariant Risk Minimization (IRM)框架，通过特征分布对齐重新定义不变性，从而从无标签数据中学习对分布偏移鲁棒的表示。框架包括两个主要方法：Principal Invariant Component Analysis (PICA)，一个基于高斯假设的线性方法，用于提取不变方向；以及Variational Invariant Autoencoder (VIAE)，一个深度生成模型，用于分离环境不变和环境相关的潜在因素。基于一个新的“无监督”结构因果模型，该框架支持环境条件下的样本生成和干预，并在合成数据集以及修改的MNIST上进行实证评估，证明了其在捕捉不变结构、保留相关信息和跨环境泛化方面的有效性，而无需依赖标签。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12506v1",
      "published_date": "2025-05-18 17:54:23 UTC",
      "updated_date": "2025-05-18 17:54:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:39:01.481508"
    },
    {
      "arxiv_id": "2505.12504v1",
      "title": "CPGD: Toward Stable Rule-based Reinforcement Learning for Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zongkai Liu",
        "Fanqing Meng",
        "Lingxiao Du",
        "Zhixiang Zhou",
        "Chao Yu",
        "Wenqi Shao",
        "Qiaosheng Zhang"
      ],
      "abstract": "Recent advances in rule-based reinforcement learning (RL) have significantly\nimproved the reasoning capability of language models (LMs) with rule-based\nrewards. However, existing RL methods -- such as GRPO, REINFORCE++, and RLOO --\noften suffer from training instability, where large policy updates and improper\nclipping can lead to training collapse. To address this issue, we propose\nClipped Policy Gradient Optimization with Policy Drift (CPGD), a novel\nalgorithm designed to stabilize policy learning in LMs. CPGD introduces a\npolicy drift constraint based on KL divergence to dynamically regularize policy\nupdates, and leverages a clip mechanism on the logarithm of the ratio to\nprevent excessive policy updates. We provide theoretical justification for CPGD\nand demonstrate through empirical analysis that it mitigates the instability\nobserved in prior approaches. Furthermore, we show that CPGD significantly\nimproves performance while maintaining training stability. Our implementation\nbalances theoretical rigor with practical usability, offering a robust\nalternative for RL in the post-training of LMs. We release our code at\nhttps://github.com/ModalMinds/MM-EUREKA.",
      "tldr_zh": "该研究针对基于规则的强化学习（RL）在语言模型（LMs）中的训练不稳定性问题（如 GRPO 和 REINFORCE++ 等方法导致的大策略更新和训练崩溃），提出了一种新算法 CPGD（Clipped Policy Gradient Optimization with Policy Drift）。CPGD 通过引入基于 KL divergence 的策略漂移约束来动态调节策略更新，并使用对比率对数的裁剪机制防止过度更新，提供理论证明并证明其有效性。实验结果显示，CPGD 显著提升了性能，同时维持了训练稳定性，并开源代码以支持实际应用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12504v1",
      "published_date": "2025-05-18 17:44:53 UTC",
      "updated_date": "2025-05-18 17:44:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:39:13.387375"
    },
    {
      "arxiv_id": "2505.12501v1",
      "title": "ALAS: A Stateful Multi-LLM Agent Framework for Disruption-Aware Planning",
      "title_zh": "翻译失败",
      "authors": [
        "Edward Y. Chang",
        "Longling Geng"
      ],
      "abstract": "Large language models (LLMs) excel at rapid generation of text and multimodal\ncontent, yet they falter on transaction-style planning that demands ACID-like\nguarantees and real-time disruption recovery. We present Adaptive LLM Agent\nSystem (ALAS), a framework that tackles four fundamental LLM deficits: (i)\nabsence of self-verification, (ii) context erosion, (iii) next-token myopia,\nand (iv) lack of persistent state. ALAS decomposes each plan into\nrole-specialized agents, equips them with automatic state tracking, and\ncoordinates them through a lightweight protocol. When disruptions arise, agents\napply history-aware local compensation, avoiding costly global replanning and\ncontaining cascade effects. On real-world, large-scale job-shop scheduling\nbenchmarks, ALAS sets new best results for static sequential planning and\nexcels in dynamic reactive scenarios with unexpected disruptions. These gains\nshow that principled modularization plus targeted compensation can unlock\nscalable and resilient planning with LLMs.",
      "tldr_zh": "本文提出 ALAS 框架，这是一个状态化的多 LLM 代理系统，旨在解决 LLMs 在交易式规划中的缺陷，包括缺乏自我验证、上下文侵蚀、下一个标记近视和持久状态缺失。ALAS 通过将计划分解为角色专业化的代理、配备自动状态跟踪，并采用轻量级协议和历史感知本地补偿机制，来处理实时中断并避免全局重新规划。在真实世界的作业车间调度基准测试中，ALAS 在静态顺序规划中设置了新最佳结果，并在动态反应场景中表现出色，证明了有原则的模块化和针对性补偿能提升 LLMs 的可扩展性和弹性。",
      "categories": [
        "cs.AI",
        "I.2.7"
      ],
      "primary_category": "cs.AI",
      "comment": "36 pages, 10 figures, 19 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.12501v1",
      "published_date": "2025-05-18 17:27:08 UTC",
      "updated_date": "2025-05-18 17:27:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:39:26.110296"
    },
    {
      "arxiv_id": "2505.13538v1",
      "title": "RAGXplain: From Explainable Evaluation to Actionable Guidance of RAG Pipelines",
      "title_zh": "RAGXplain：从可解释评估到 RAG 管道的可行动指导",
      "authors": [
        "Dvir Cohen",
        "Lin Burg",
        "Gilad Barkan"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) systems show promise by coupling large\nlanguage models with external knowledge, yet traditional RAG evaluation methods\nprimarily report quantitative scores while offering limited actionable guidance\nfor refining these complex pipelines. In this paper, we introduce RAGXplain, an\nevaluation framework that quantifies RAG performance and translates these\nassessments into clear insights that clarify the workings of its complex,\nmulti-stage pipeline and offer actionable recommendations. Using LLM reasoning,\nRAGXplain converts raw scores into coherent narratives identifying performance\ngaps and suggesting targeted improvements. By providing transparent\nexplanations for AI decision-making, our framework fosters user trust-a key\nchallenge in AI adoption. Our LLM-based metric assessments show strong\nalignment with human judgments, and experiments on public question-answering\ndatasets confirm that applying RAGXplain's actionable recommendations\nmeasurably improves system performance. RAGXplain thus bridges quantitative\nevaluation and practical optimization, empowering users to understand, trust,\nand enhance their AI systems.",
      "tldr_zh": "本论文提出RAGXplain框架，用于评估和优化Retrieval-Augmented Generation (RAG) 系统，通过将量化性能评估转化为清晰见解和行动建议，解决传统方法缺乏实用指导的问题。RAGXplain利用LLM推理将原始分数转化为连贯叙述，识别性能差距并提供针对性改进推荐，从而提升系统透明度和用户信任。实验结果显示，该框架的评估指标与人类判断高度一致，并在公共问答数据集上应用其建议后显著提高了系统性能，最终桥接了量化评估与实际优化，帮助用户更好地理解、信任和增强AI系统。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13538v1",
      "published_date": "2025-05-18 17:25:34 UTC",
      "updated_date": "2025-05-18 17:25:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:39:35.936006"
    },
    {
      "arxiv_id": "2505.12500v1",
      "title": "MARGE: Improving Math Reasoning for LLMs with Guided Exploration",
      "title_zh": "MARGE：通过引导式探索改善大语言模型的数学推理",
      "authors": [
        "Jingyue Gao",
        "Runji Lin",
        "Keming Lu",
        "Bowen Yu",
        "Junyang Lin",
        "Jianyu Chen"
      ],
      "abstract": "Large Language Models (LLMs) exhibit strong potential in mathematical\nreasoning, yet their effectiveness is often limited by a shortage of\nhigh-quality queries. This limitation necessitates scaling up computational\nresponses through self-generated data, yet current methods struggle due to\nspurious correlated data caused by ineffective exploration across all reasoning\nstages. To address such challenge, we introduce \\textbf{MARGE}: Improving\n\\textbf{Ma}th \\textbf{R}easoning with \\textbf{G}uided \\textbf{E}xploration, a\nnovel method to address this issue and enhance mathematical reasoning through\nhit-guided exploration. MARGE systematically explores intermediate reasoning\nstates derived from self-generated solutions, enabling adequate exploration and\nimproved credit assignment throughout the reasoning process. Through extensive\nexperiments across multiple backbone models and benchmarks, we demonstrate that\nMARGE significantly improves reasoning capabilities without requiring external\nannotations or training additional value models. Notably, MARGE improves both\nsingle-shot accuracy and exploration diversity, mitigating a common trade-off\nin alignment methods. These results demonstrate MARGE's effectiveness in\nenhancing mathematical reasoning capabilities and unlocking the potential of\nscaling self-generated training data. Our code and models are available at\n\\href{https://github.com/georgao35/MARGE}{this link}.",
      "tldr_zh": "这篇论文介绍了 MARGE，一种通过引导探索(Guided Exploration)来提升大型语言模型(LLMs)数学推理能力的方法，以解决自生成数据中无效探索导致的虚假相关问题。MARGE 系统地探索自生成解决方案的中间推理状态，提高了探索效率和信用分配过程，从而无需外部标注或额外训练模型。实验结果显示，在多个骨干模型和基准测试中，MARGE 显著提高了单次准确性和探索多样性，缓解了传统对齐方法中的权衡问题，并证明了其在扩展自生成训练数据方面的潜力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "To appear at ICML 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.12500v1",
      "published_date": "2025-05-18 17:24:16 UTC",
      "updated_date": "2025-05-18 17:24:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:39:48.321026"
    },
    {
      "arxiv_id": "2505.12493v1",
      "title": "UIShift: Enhancing VLM-based GUI Agents through Self-supervised Reinforcement Learning",
      "title_zh": "UIShift：通过自监督强化学习增强基于视觉语言模型的 GUI 代理",
      "authors": [
        "Longxi Gao",
        "Li Zhang",
        "Mengwei Xu"
      ],
      "abstract": "Training effective Vision Language Models (VLMs) for GUI agents typically\nrelies on supervised fine-tuning (SFT) over large-scale annotated datasets,\nwhere the collection process is labor-intensive and error-prone. In this work,\nwe propose a self-supervised inverse dynamics task to enable VLMs to learn from\nGUI transition pairs by inferring the action that caused that transition. This\ntraining task offers two advantages: (1) It enables VLMs to ignore variations\nunrelated to user actions (e.g., background refreshes, ads) and to focus on\ntrue affordances such as buttons and input fields within complex GUIs. (2) The\ntraining data can be easily obtained from existing GUI trajectories without\nrequiring human annotation, and it can be easily scaled through automatic\noffline exploration. Using this training task, we propose UI-shift, a framework\nfor enhancing VLM-based GUI agents through self-supervised reinforcement\nlearning (RL). With only 2K training samples sourced from existing datasets,\ntwo VLMs -- Qwen2.5-VL-3B and Qwen2.5-VL-7B -- trained with UI-Shift achieve\ncompetitive or superior performance on grounding tasks (ScreenSpot-series\nbenchmarks) and GUI automation tasks (AndroidControl), compared to SFT\nbaselines and GUI-specific models that explicitly elicit reasoning abilities\nduring RL. Our findings suggest a potential direction for enhancing VLMs for\nGUI agents by leveraging more self-supervised training data in the future.",
      "tldr_zh": "该研究针对训练 VLM（Vision Language Models）用于 GUI 代理的传统依赖于监督微调（SFT）的局限性，提出了一种自监督的反向动态任务和 UI-Shift 框架，通过自监督强化学习（RL）让模型从 GUI 转换对中推断操作，从而忽略无关变异（如背景刷新）并专注于关键元素，如按钮和输入字段。\n这种方法的优势在于数据可从现有 GUI 轨迹轻松获取，无需人工标注，并支持自动扩展。\n实验结果显示，使用仅 2K 训练样本，Qwen2.5-VL-3B 和 Qwen2.5-VL-7B 模型在 grounding 任务（ScreenSpot-series benchmarks）和 GUI 自动化任务（AndroidControl）上，性能达到或超过 SFT 基线和专用模型。\n这些发现为未来通过更多自监督数据增强 VLM-based GUI 代理提供了潜在方向。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12493v1",
      "published_date": "2025-05-18 16:34:30 UTC",
      "updated_date": "2025-05-18 16:34:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:40:02.976385"
    },
    {
      "arxiv_id": "2505.12492v1",
      "title": "Unleashing Automated Congestion Control Customization in the Wild",
      "title_zh": "翻译失败",
      "authors": [
        "Amit Cohen",
        "Lev Gloukhenki",
        "Ravid Hadar",
        "Eden Itah",
        "Yehuda Shvut",
        "Michael Schapira"
      ],
      "abstract": "Congestion control (CC) crucially impacts user experience across Internet\nservices like streaming, gaming, AR/VR, and connected cars. Traditionally, CC\nalgorithm design seeks universal control rules that yield high performance\nacross diverse application domains and networks. However, varying service needs\nand network conditions challenge this approach. We share operational experience\nwith a system that automatically customizes congestion control logic to service\nneeds and network conditions. We discuss design, deployment challenges, and\nsolutions, highlighting performance benefits through case studies in streaming,\ngaming, connected cars, and more.\n  Our system leverages PCC Vivace, an online-learning based congestion control\nprotocol developed by researchers. Hence, along with insights from customizing\ncongestion control, we also discuss lessons learned and modifications made to\nadapt PCC Vivace for real-world deployment.",
      "tldr_zh": "该研究探讨了拥塞控制（Congestion Control, CC）在互联网服务（如流媒体、游戏、AR/VR 和联网汽车）中的关键作用，指出传统通用 CC 算法难以适应多样化的服务需求和网络条件。论文分享了一个基于在线学习协议 PCC Vivace 的系统，该系统自动自定义 CC 逻辑，以优化性能，并讨论了设计、部署挑战及其解决方案。通过流媒体、游戏和联网汽车等案例研究，系统展示了显著的性能提升，并总结了从实际部署中获得的经验教训。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.LG",
        "cs.PF",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12492v1",
      "published_date": "2025-05-18 16:29:19 UTC",
      "updated_date": "2025-05-18 16:29:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:40:12.508266"
    },
    {
      "arxiv_id": "2505.12489v2",
      "title": "Video-GPT via Next Clip Diffusion",
      "title_zh": "翻译失败",
      "authors": [
        "Shaobin Zhuang",
        "Zhipeng Huang",
        "Ying Zhang",
        "Fangyikang Wang",
        "Canmiao Fu",
        "Binxin Yang",
        "Chong Sun",
        "Chen Li",
        "Yali Wang"
      ],
      "abstract": "GPT has shown its remarkable success in natural language processing. However,\nthe language sequence is not sufficient to describe spatial-temporal details in\nthe visual world. Alternatively, the video sequence is good at capturing such\ndetails. Motivated by this fact, we propose a concise Video-GPT in this paper\nby treating video as new language for visual world modeling. By analogy to next\ntoken prediction in GPT, we introduce a novel next clip diffusion paradigm for\npretraining Video-GPT. Different from the previous works, this distinct\nparadigm allows Video-GPT to tackle both short-term generation and long-term\nprediction, by autoregressively denoising the noisy clip according to the clean\nclips in the history. Extensive experiments show our Video-GPT achieves the\nstate-of-the-art performance on video prediction, which is the key factor\ntowards world modeling (Physics-IQ Benchmark: Video-GPT 34.97 vs. Kling 23.64\nvs. Wan 20.89). Moreover, it can be well adapted on 6 mainstream video tasks in\nboth video generation and understanding, showing its great generalization\ncapacity in downstream. The project page is at\nhttps://zhuangshaobin.github.io/Video-GPT.github.io/.",
      "tldr_zh": "该论文提出 Video-GPT 模型，将视频序列视为新语言来建模视觉世界，以克服传统语言模型在捕捉空间-时间细节方面的不足。作者引入 next clip diffusion 范式进行预训练，该方法通过自回归地去噪历史干净片段来预测下一个片段，从而支持视频的短长期生成和预测。实验结果显示，Video-GPT 在视频预测任务上达到 state-of-the-art 性能（例如 Physics-IQ Benchmark 上显著优于其他模型），并能泛化到 6 个主流视频生成和理解任务，展示了其强大的泛化能力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "22 pages, 12 figures, 18 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.12489v2",
      "published_date": "2025-05-18 16:22:58 UTC",
      "updated_date": "2025-05-21 04:44:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:40:24.509817"
    },
    {
      "arxiv_id": "2505.12477v1",
      "title": "Joint Embedding vs Reconstruction: Provable Benefits of Latent Space Prediction for Self Supervised Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Hugues Van Assel",
        "Mark Ibrahim",
        "Tommaso Biancalani",
        "Aviv Regev",
        "Randall Balestriero"
      ],
      "abstract": "Reconstruction and joint embedding have emerged as two leading paradigms in\nSelf Supervised Learning (SSL). Reconstruction methods focus on recovering the\noriginal sample from a different view in input space. On the other hand, joint\nembedding methods align the representations of different views in latent space.\nBoth approaches offer compelling advantages, yet practitioners lack clear\nguidelines for choosing between them. In this work, we unveil the core\nmechanisms that distinguish each paradigm. By leveraging closed form solutions\nfor both approaches, we precisely characterize how the view generation process,\ne.g. data augmentation, impacts the learned representations. We then\ndemonstrate that, unlike supervised learning, both SSL paradigms require a\nminimal alignment between augmentations and irrelevant features to achieve\nasymptotic optimality with increasing sample size. Our findings indicate that\nin scenarios where these irrelevant features have a large magnitude, joint\nembedding methods are preferable because they impose a strictly weaker\nalignment condition compared to reconstruction based methods. These results not\nonly clarify the trade offs between the two paradigms but also substantiate the\nempirical success of joint embedding approaches on real world challenging\ndatasets.",
      "tldr_zh": "这篇论文比较了自监督学习（Self Supervised Learning, SSL）中的两种主要范式：Reconstruction（重建）和Joint Embedding（联合嵌入），前者专注于从不同视图在输入空间恢复原始样本，而后者则在latent space中对齐不同视图的表示。作者通过封闭形式解决方案分析了数据增强等视图生成过程对学习表示的影响，发现两者均需最小程度的增强与无关特征的对齐，以实现样本规模增加时的渐近最优性。在无关特征幅度较大的场景下，Joint Embedding方法更具优势，因为其对对齐条件的限制更弱。这些发现阐明了两种范式的权衡，并为Joint Embedding在实际挑战性数据集上的经验成功提供了理论支撑。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "33 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.12477v1",
      "published_date": "2025-05-18 15:54:55 UTC",
      "updated_date": "2025-05-18 15:54:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:40:37.430459"
    },
    {
      "arxiv_id": "2505.12476v1",
      "title": "Enhancing Large Language Models with Reward-guided Tree Search for Knowledge Graph Question and Answering",
      "title_zh": "翻译失败",
      "authors": [
        "Xiao Long",
        "Liansheng Zhuang",
        "Chen Shen",
        "Shaotian Yan",
        "Yifei Li",
        "Shafei Wang"
      ],
      "abstract": "Recently, large language models (LLMs) have demonstrated impressive\nperformance in Knowledge Graph Question Answering (KGQA) tasks, which aim to\nfind answers based on knowledge graphs (KGs) for natural language questions.\nExisting LLMs-based KGQA methods typically follow the Graph Retrieval-Augmented\nGeneration (GraphRAG) paradigm, which first retrieves reasoning paths from the\nlarge KGs, and then generates the answers based on them. However, these methods\nemphasize the exploration of new optimal reasoning paths in KGs while ignoring\nthe exploitation of historical reasoning paths, which may lead to sub-optimal\nreasoning paths. Additionally, the complex semantics contained in questions may\nlead to the retrieval of inaccurate reasoning paths. To address these issues,\nthis paper proposes a novel and training-free framework for KGQA tasks called\nReward-guided Tree Search on Graph (RTSoG). RTSoG decomposes an original\nquestion into a series of simpler and well-defined sub-questions to handle the\ncomplex semantics. Then, a Self-Critic Monte Carlo Tree Search (SC-MCTS) guided\nby a reward model is introduced to iteratively retrieve weighted reasoning\npaths as contextual knowledge. Finally, it stacks the weighted reasoning paths\naccording to their weights to generate the final answers. Extensive experiments\non four datasets demonstrate the effectiveness of RTSoG. Notably, it achieves\n8.7\\% and 7.0\\% performance improvement over the state-of-the-art method on the\nGrailQA and the WebQSP respectively.",
      "tldr_zh": "本研究旨在提升大语言模型 (LLMs) 在知识图谱问答 (KGQA) 任务中的性能，针对现有 GraphRAG 方法忽略历史推理路径和复杂语义导致检索不准确的问题，提出一个无需训练的框架 Reward-guided Tree Search on Graph (RTSoG)。RTSoG 通过将原始问题分解为简单子问题，并使用 Self-Critic Monte Carlo Tree Search (SC-MCTS) 由奖励模型引导，迭代检索加权的推理路径作为上下文知识，最后根据权重堆叠这些路径生成答案。实验在四个数据集上验证了框架的有效性，在 GrailQA 和 WebQSP 上分别比最先进方法提高了 8.7% 和 7.0% 的性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12476v1",
      "published_date": "2025-05-18 15:52:57 UTC",
      "updated_date": "2025-05-18 15:52:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:40:49.827841"
    },
    {
      "arxiv_id": "2505.13535v1",
      "title": "Information Extraction from Visually Rich Documents using LLM-based Organization of Documents into Independent Textual Segments",
      "title_zh": "翻译失败",
      "authors": [
        "Aniket Bhattacharyya",
        "Anurag Tripathi",
        "Ujjal Das",
        "Archan Karmakar",
        "Amit Pathak",
        "Maneesh Gupta"
      ],
      "abstract": "Information extraction (IE) from Visually Rich Documents (VRDs) containing\nlayout features along with text is a critical and well-studied task.\nSpecialized non-LLM NLP-based solutions typically involve training models using\nboth textual and geometric information to label sequences/tokens as named\nentities or answers to specific questions. However, these approaches lack\nreasoning, are not able to infer values not explicitly present in documents,\nand do not generalize well to new formats. Generative LLM-based approaches\nproposed recently are capable of reasoning, but struggle to comprehend clues\nfrom document layout especially in previously unseen document formats, and do\nnot show competitive performance in heterogeneous VRD benchmark datasets. In\nthis paper, we propose BLOCKIE, a novel LLM-based approach that organizes VRDs\ninto localized, reusable semantic textual segments called $\\textit{semantic\nblocks}$, which are processed independently. Through focused and more\ngeneralizable reasoning,our approach outperforms the state-of-the-art on public\nVRD benchmarks by 1-3% in F1 scores, is resilient to document formats\npreviously not encountered and shows abilities to correctly extract information\nnot explicitly present in documents.",
      "tldr_zh": "本文研究了从视觉丰富文档（Visually Rich Documents, VRDs）中进行信息提取（Information Extraction, IE）的挑战，传统非LLM方法因缺乏推理能力和对新格式的泛化性差而存在局限，而现有LLM方法则难以处理文档布局。作者提出BLOCKIE，一种基于LLM的创新方法，将VRDs组织成独立的语义文本段（semantic blocks），并独立处理这些段落，以实现更聚焦和可泛化的推理。实验结果显示，BLOCKIE在公共VRD基准数据集上以F1 scores提高了1-3%，并对未见过的文档格式表现出色，还能准确提取文档中未明确出现的信息。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted to ACL Main 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.13535v1",
      "published_date": "2025-05-18 15:49:17 UTC",
      "updated_date": "2025-05-18 15:49:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:41:01.501953"
    },
    {
      "arxiv_id": "2505.12470v1",
      "title": "NeuroGen: Neural Network Parameter Generation via Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jiaqi Wang",
        "Yusen Zhang",
        "Xi Li"
      ],
      "abstract": "Acquiring the parameters of neural networks (NNs) has been one of the most\nimportant problems in machine learning since the inception of NNs. Traditional\napproaches, such as backpropagation and forward-only optimization, acquire\nparameters via iterative data fitting to gradually optimize them. This paper\naims to explore the feasibility of a new direction: acquiring NN parameters via\nlarge language model generation. We propose NeuroGen, a generalized and\neasy-to-implement two-stage approach for NN parameter generation conditioned on\ndescriptions of the data, task, and network architecture. Stage one is\nParameter Reference Knowledge Injection, where LLMs are pretrained on NN\ncheckpoints to build foundational understanding of parameter space, whereas\nstage two is Context-Enhanced Instruction Tuning, enabling LLMs to adapt to\nspecific tasks through enriched, task-aware prompts. Experimental results\ndemonstrate that NeuroGen effectively generates usable NN parameters. Our\nfindings highlight the feasibility of LLM-based NN parameter generation and\nsuggest a promising new paradigm where LLMs and lightweight NNs can coexist\nsynergistically",
      "tldr_zh": "该论文探讨了一种新方法，使用大语言模型（LLMs）生成神经网络（NNs）参数，以替代传统如反向传播的迭代优化方式。NeuroGen 是一个两阶段框架：第一阶段为 Parameter Reference Knowledge Injection，通过在 NN 检查点上预训练 LLMs 以建立参数空间的理解；第二阶段为 Context-Enhanced Instruction Tuning，利用任务感知提示使 LLMs 适应特定数据、任务和架构。实验结果证明 NeuroGen 可以有效生成可用的 NN 参数，并揭示了 LLMs 与轻量级 NNs 协同共存的潜在新范式。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "The three authors contributed equally to this work. The codes will be\n  public after being accepted",
      "pdf_url": "http://arxiv.org/pdf/2505.12470v1",
      "published_date": "2025-05-18 15:48:10 UTC",
      "updated_date": "2025-05-18 15:48:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:41:12.647995"
    },
    {
      "arxiv_id": "2505.12467v1",
      "title": "Beyond Frameworks: Unpacking Collaboration Strategies in Multi-Agent Systems",
      "title_zh": "超越框架：剖析多智能体系统中的协作策略",
      "authors": [
        "Haochun Wang",
        "Sendong Zhao",
        "Jingbo Wang",
        "Zewen Qiang",
        "Bing Qin",
        "Ting Liu"
      ],
      "abstract": "Multi-agent collaboration has emerged as a pivotal paradigm for addressing\ncomplex, distributed tasks in large language model (LLM)-driven applications.\nWhile prior research has focused on high-level architectural frameworks, the\ngranular mechanisms governing agents, critical to performance and scalability,\nremain underexplored. This study systematically investigates four dimensions of\ncollaboration strategies: (1) agent governance, (2) participation control, (3)\ninteraction dynamics, and (4) dialogue history management. Through rigorous\nexperimentation under two context-dependent scenarios: Distributed Evidence\nIntegration (DEI) and Structured Evidence Synthesis (SES), we quantify the\nimpact of these strategies on both task accuracy and computational efficiency.\nOur findings reveal that centralized governance, instructor-led participation,\nordered interaction patterns, and instructor-curated context summarization\ncollectively optimize the trade-off between decision quality and resource\nutilization with the support of the proposed Token-Accuracy Ratio (TAR). This\nwork establishes a foundation for designing adaptive, scalable multi-agent\nsystems, shifting the focus from structural novelty to strategic interaction\nmechanics.",
      "tldr_zh": "本文研究超越了多智能体系统的架构框架，系统探讨了代理协作策略的四个关键维度：代理治理、参与控制、交互动态和对话历史管理，以提升大型语言模型(LLM)驱动应用的性能和可扩展性。通过在 Distributed Evidence Integration (DEI) 和 Structured Evidence Synthesis (SES) 场景下的严格实验，量化了这些策略对任务准确性和计算效率的影响。研究发现，采用集中式治理、指导者主导的参与、有序交互模式以及指导者策划的上下文总结，能够优化决策质量与资源利用的权衡，并引入 Token-Accuracy Ratio (TAR) 指标。该工作为设计适应性、可扩展的多智能体系统奠定了基础，强调了战略交互机制的重要性。",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "ACL 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.12467v1",
      "published_date": "2025-05-18 15:46:14 UTC",
      "updated_date": "2025-05-18 15:46:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:41:26.665896"
    },
    {
      "arxiv_id": "2505.12442v2",
      "title": "IP Leakage Attacks Targeting LLM-Based Multi-Agent Systems",
      "title_zh": "针对基于 LLM 的多",
      "authors": [
        "Liwen Wang",
        "Wenxuan Wang",
        "Shuai Wang",
        "Zongjie Li",
        "Zhenlan Ji",
        "Zongyi Lyu",
        "Daoyuan Wu",
        "Shing-Chi Cheung"
      ],
      "abstract": "The rapid advancement of Large Language Models (LLMs) has led to the\nemergence of Multi-Agent Systems (MAS) to perform complex tasks through\ncollaboration. However, the intricate nature of MAS, including their\narchitecture and agent interactions, raises significant concerns regarding\nintellectual property (IP) protection. In this paper, we introduce MASLEAK, a\nnovel attack framework designed to extract sensitive information from MAS\napplications. MASLEAK targets a practical, black-box setting, where the\nadversary has no prior knowledge of the MAS architecture or agent\nconfigurations. The adversary can only interact with the MAS through its public\nAPI, submitting attack query $q$ and observing outputs from the final agent.\nInspired by how computer worms propagate and infect vulnerable network hosts,\nMASLEAK carefully crafts adversarial query $q$ to elicit, propagate, and retain\nresponses from each MAS agent that reveal a full set of proprietary components,\nincluding the number of agents, system topology, system prompts, task\ninstructions, and tool usages. We construct the first synthetic dataset of MAS\napplications with 810 applications and also evaluate MASLEAK against real-world\nMAS applications, including Coze and CrewAI. MASLEAK achieves high accuracy in\nextracting MAS IP, with an average attack success rate of 87% for system\nprompts and task instructions, and 92% for system architecture in most cases.\nWe conclude by discussing the implications of our findings and the potential\ndefenses.",
      "tldr_zh": "该论文提出MASLEAK，一种针对基于LLM的多智能体系统(MAS)的黑盒IP泄露攻击框架，旨在从系统架构和代理互动中提取敏感信息，如代理数量、系统拓扑、系统提示、任务指令和工具使用。攻击方法通过精心设计的adversarial query模仿计算机蠕虫的传播机制，仅通过公共API交互来诱导和保留响应。实验在包含810个合成MAS应用的首个数据集上，以及真实世界应用如Coze和CrewAI中进行，显示MASLEAK的平均成功率达到87%（系统提示和任务指令）和92%（系统架构）。该研究讨论了这些发现对IP保护的潜在影响，并探索了可能的防御策略。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12442v2",
      "published_date": "2025-05-18 14:31:45 UTC",
      "updated_date": "2025-05-20 11:48:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:41:40.258990"
    },
    {
      "arxiv_id": "2505.12440v1",
      "title": "Model Discovery with Grammatical Evolution. An Experiment with Prime Numbers",
      "title_zh": "翻译失败",
      "authors": [
        "Jakub Skrzyński",
        "Dominik Sepioło",
        "Antoni Ligęza"
      ],
      "abstract": "Machine Learning produces efficient decision and prediction models based on\ninput-output data only. Such models have the form of decision trees or neural\nnets and are far from transparent analytical models, based on mathematical\nformulas. Analytical model discovery requires additional knowledge and may be\nperformed with Grammatical Evolution. Such models are transparent, concise, and\nhave readable components and structure. This paper reports on a non-trivial\nexperiment with generating such models.",
      "tldr_zh": "这篇论文探讨了使用 Grammatical Evolution 来发现透明的分析模型，以弥补 Machine Learning 基于输入输出数据生成决策树或神经网络等模型的非透明性问题。Grammatical Evolution 允许创建基于数学公式的简洁、可读模型，需要额外知识支持。论文通过一个与质数相关的非平凡实验，展示了如何生成此类模型，并验证了其有效性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Presented during 5th Polish Conference on Artificial Intelligence,\n  published in \"PROGRESS IN POLISH ARTIFICIAL INTELLIGENCE RESEARCH 5\" ISBN\n  978-83-8156-696-4",
      "pdf_url": "http://arxiv.org/pdf/2505.12440v1",
      "published_date": "2025-05-18 14:22:21 UTC",
      "updated_date": "2025-05-18 14:22:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:41:48.106318"
    },
    {
      "arxiv_id": "2505.12437v1",
      "title": "Addressing the Scarcity of Benchmarks for Graph XAI",
      "title_zh": "解决 Graph XAI 基准的稀缺问题",
      "authors": [
        "Michele Fontanesi",
        "Alessio Micheli",
        "Marco Podda",
        "Domenico Tortorella"
      ],
      "abstract": "While Graph Neural Networks (GNNs) have become the de facto model for\nlearning from structured data, their decisional process remains opaque to the\nend user, undermining their deployment in safety-critical applications. In the\ncase of graph classification, Explainable Artificial Intelligence (XAI)\ntechniques address this major issue by identifying sub-graph motifs that\nexplain predictions. However, advancements in this field are hindered by a\nchronic scarcity of benchmark datasets with known ground-truth motifs to assess\nthe explanations' quality. Current graph XAI benchmarks are limited to\nsynthetic data or a handful of real-world tasks hand-curated by domain experts.\nIn this paper, we propose a general method to automate the construction of XAI\nbenchmarks for graph classification from real-world datasets. We provide both\n15 ready-made benchmarks, as well as the code to generate more than 2000\nadditional XAI benchmarks with our method. As a use case, we employ our\nbenchmarks to assess the effectiveness of some popular graph explainers.",
      "tldr_zh": "图神经网络 (GNNs) 在处理结构化数据时决策过程不透明，这限制了其在安全关键应用中的部署，而 Graph XAI 技术通过识别子图 motifs 来解释预测，但目前缺乏带有 ground-truth motifs 的基准数据集。论文提出了一种通用方法，从真实数据集自动构建 Graph XAI 基准数据集，并提供了 15 个现成基准以及代码来生成超过 2000 个额外基准。该方法有助于评估流行图解释器的有效性，推动 Graph XAI 领域的进展。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12437v1",
      "published_date": "2025-05-18 14:19:52 UTC",
      "updated_date": "2025-05-18 14:19:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:42:01.316061"
    },
    {
      "arxiv_id": "2505.12435v1",
      "title": "SGDPO: Self-Guided Direct Preference Optimization for Language Model Alignment",
      "title_zh": "SGDPO：自引导直接偏好优化用于语言模型对齐",
      "authors": [
        "Wenqiao Zhu",
        "Ji Liu",
        "Lulu Wang",
        "Jun Wu",
        "Yulun Zhang"
      ],
      "abstract": "Direct Preference Optimization (DPO) is broadly utilized for aligning Large\nLanguage Models (LLMs) with human values because of its flexibility. Despite\nits effectiveness, it has been observed that the capability of DPO to generate\nhuman-preferred response is limited and the results of DPO are far from\nresilient. To address these limitations, in this paper we propose a novel\nSelf-Guided Direct Preference Optimization algorithm, i.e., SGDPO, which\nincorporates a pilot term to steer the gradient flow during the optimization\nprocess, allowing for fine-grained control over the updates of chosen and\nrejected rewards. We provide a detailed theoretical analysis of our proposed\nmethod and elucidate its operational mechanism. Furthermore, we conduct\ncomprehensive experiments on various models and benchmarks. The extensive\nexperimental results demonstrate the consistency between the empirical results\nand our theoretical analysis and confirm the effectiveness of our proposed\napproach (up to 9.19% higher score).",
      "tldr_zh": "本研究针对Direct Preference Optimization (DPO)算法在对齐Large Language Models (LLMs)时存在的生成人类偏好响应能力有限和结果不稳定问题，提出了一种新型Self-Guided Direct Preference Optimization (SGDPO)算法。SGDPO通过引入pilot term来引导梯度流，实现对chosen和rejected rewards的精细控制，从而提升优化过程的精确性。论文提供了详细的理论分析，并通过在多种模型和基准上的实验验证了该方法的有效性，与理论结果一致，性能提升高达9.19%。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "18 pages, to appear in ACL'25",
      "pdf_url": "http://arxiv.org/pdf/2505.12435v1",
      "published_date": "2025-05-18 14:19:23 UTC",
      "updated_date": "2025-05-18 14:19:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:42:12.673312"
    },
    {
      "arxiv_id": "2505.12433v1",
      "title": "SRLoRA: Subspace Recomposition in Low-Rank Adaptation via Importance-Based Fusion and Reinitialization",
      "title_zh": "翻译失败",
      "authors": [
        "Haodong Yang",
        "Lei Wang",
        "Md Zakir Hossain"
      ],
      "abstract": "Low-Rank Adaptation (LoRA) is a widely adopted parameter-efficient\nfine-tuning (PEFT) method that injects two trainable low-rank matrices (A and\nB) into frozen pretrained models. While efficient, LoRA constrains updates to a\nfixed low-rank subspace (Delta W = BA), which can limit representational\ncapacity and hinder downstream performance. We introduce Subspace Recomposition\nin Low-Rank Adaptation (SRLoRA) via importance-based fusion and\nreinitialization, a novel approach that enhances LoRA's expressiveness without\ncompromising its lightweight structure. SRLoRA assigns importance scores to\neach LoRA pair (a column of B and the corresponding row of A), and dynamically\nrecomposes the subspace during training. Less important pairs are fused into\nthe frozen backbone, freeing capacity to reinitialize new pairs along unused\nprincipal directions derived from the pretrained weight's singular value\ndecomposition. This mechanism enables continual subspace refreshment and richer\nadaptation over time, without increasing the number of trainable parameters. We\nevaluate SRLoRA on both language and vision tasks, including the GLUE benchmark\nand various image classification datasets. SRLoRA consistently achieves faster\nconvergence and improved accuracy over standard LoRA, demonstrating its\ngenerality, efficiency, and potential for broader PEFT applications.",
      "tldr_zh": "本文提出 SRLoRA，一种改进 Low-Rank Adaptation (LoRA) 的方法，通过基于重要性的融合和重新初始化动态重组子空间，提升模型的表达能力，同时保持轻量级结构，避免增加可训练参数。SRLoRA 为每个 LoRA 对分配重要性分数，将不太重要的对融合到冻结骨干网络中，并沿预训练权重奇异值分解的未使用主方向重新初始化新对，实现子空间的持续刷新和更丰富的适应。在 GLUE benchmark 和各种图像分类任务上，SRLoRA 比标准 LoRA 实现更快收敛和更高准确率，证明了其在参数高效微调 (PEFT) 领域的通用性和潜力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Research report",
      "pdf_url": "http://arxiv.org/pdf/2505.12433v1",
      "published_date": "2025-05-18 14:12:40 UTC",
      "updated_date": "2025-05-18 14:12:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:42:25.502233"
    },
    {
      "arxiv_id": "2505.12432v1",
      "title": "Observe-R1: Unlocking Reasoning Abilities of MLLMs with Dynamic Progressive Reinforcement Learning",
      "title_zh": "Observe-R1：通过动态渐进强化学习解锁多模态",
      "authors": [
        "Zirun Guo",
        "Minjie Hong",
        "Tao Jin"
      ],
      "abstract": "Reinforcement Learning (RL) has shown promise in improving the reasoning\nabilities of Large Language Models (LLMs). However, the specific challenges of\nadapting RL to multimodal data and formats remain relatively unexplored. In\nthis work, we present Observe-R1, a novel framework aimed at enhancing the\nreasoning capabilities of multimodal large language models (MLLMs). We draw\ninspirations from human learning progression--from simple to complex and easy\nto difficult, and propose a gradual learning paradigm for MLLMs. To this end,\nwe construct the NeuraLadder dataset, which is organized and sampled according\nto the difficulty and complexity of data samples for RL training. To tackle\nmultimodal tasks, we introduce a multimodal format constraint that encourages\ncareful observation of images, resulting in enhanced visual abilities and\nclearer and more structured responses. Additionally, we implement a bonus\nreward system that favors concise, correct answers within a length constraint,\nalongside a dynamic weighting mechanism that prioritizes uncertain and\nmedium-difficulty problems, ensuring that more informative samples have a\ngreater impact on training. Our experiments with the Qwen2.5-VL-3B and\nQwen2.5-VL-7B models on 20k samples from the NeuraLadder dataset show that\nObserve-R1 outperforms a series of larger reasoning models on both reasoning\nand general benchmarks, achieving superior clarity and conciseness in reasoning\nchains. Ablation studies validate the effectiveness of our strategies,\nhighlighting the robustness and generalization of our approach. The dataset and\ncode will be released at https://github.com/zrguo/Observe-R1.",
      "tldr_zh": "本研究提出 Observe-R1 框架，利用动态渐进式 Reinforcement Learning (RL) 来提升多模态大型语言模型 (MLLMs) 的推理能力，借鉴人类学习从简单到复杂的模式。框架包括构建 NeuraLadder 数据集（按难度和复杂度采样）、多模态格式约束（鼓励图像仔细观察以改善视觉能力和响应结构）、奖励系统（奖励简洁正确答案并设置长度限制），以及动态权重机制（优先处理不确定性和中等难度样本）。实验结果显示，在 Qwen2.5-VL-3B 和 Qwen2.5-VL-7B 模型上使用 20k 样本训练后，Observe-R1 优于其他更大模型，在推理和一般基准上表现出更高的清晰度和简洁性；消融研究进一步验证了这些策略的有效性和泛化性。数据集和代码将在 GitHub 上发布。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12432v1",
      "published_date": "2025-05-18 14:08:03 UTC",
      "updated_date": "2025-05-18 14:08:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:42:37.862105"
    },
    {
      "arxiv_id": "2505.12424v1",
      "title": "EvoGPT: Enhancing Test Suite Robustness via LLM-Based Generation and Genetic Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Lior Broide",
        "Roni Stern"
      ],
      "abstract": "Large Language Models (LLMs) have recently emerged as promising tools for\nautomated unit test generation. We introduce a hybrid framework called EvoGPT\nthat integrates LLM-based test generation with evolutionary search techniques\nto create diverse, fault-revealing unit tests. Unit tests are initially\ngenerated with diverse temperature sampling to maximize behavioral and test\nsuite diversity, followed by a generation-repair loop and coverage-guided\nassertion enhancement. The resulting test suites are evolved using genetic\nalgorithms, guided by a fitness function prioritizing mutation score over\ntraditional coverage metrics. This design emphasizes the primary objective of\nunit testing-fault detection. Evaluated on multiple open-source Java projects,\nEvoGPT achieves an average improvement of 10% in both code coverage and\nmutation score compared to LLMs and traditional search-based software testing\nbaselines. These results demonstrate that combining LLM-driven diversity,\ntargeted repair, and evolutionary optimization produces more effective and\nresilient test suites.",
      "tldr_zh": "该研究提出EvoGPT框架，通过整合LLM（Large Language Models）生成测试和遗传算法优化，来提升单元测试套件的稳健性。框架首先使用多样温度采样生成初始测试，然后通过生成-修复循环和覆盖指导的断言增强来改进测试多样性，并以突变分数为优先的适应度函数进行遗传算法进化。实验结果显示，在多个开源Java项目上，EvoGPT相较于LLM和传统搜索-based软件测试基线，平均提高了10%的代码覆盖率和突变分数，从而证明了结合LLM驱动多样性、针对修复和进化优化的有效性。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12424v1",
      "published_date": "2025-05-18 13:48:53 UTC",
      "updated_date": "2025-05-18 13:48:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:42:49.611281"
    },
    {
      "arxiv_id": "2505.12423v1",
      "title": "PSC: Extending Context Window of Large Language Models via Phase Shift Calibration",
      "title_zh": "PSC：通过相位偏移校准扩展大型语言模型的上下文窗口",
      "authors": [
        "Wenqiao Zhu",
        "Chao Xu",
        "Lulu Wang",
        "Jun Wu"
      ],
      "abstract": "Rotary Position Embedding (RoPE) is an efficient position encoding approach\nand is widely utilized in numerous large language models (LLMs). Recently, a\nlot of methods have been put forward to further expand the context window based\non RoPE. The core concept of those methods is to predefine or search for a set\nof factors to rescale the base frequencies of RoPE. Nevertheless, it is quite a\nchallenge for existing methods to predefine an optimal factor due to the\nexponential search space. In view of this, we introduce PSC (Phase Shift\nCalibration), a small module for calibrating the frequencies predefined by\nexisting methods. With the employment of PSC, we demonstrate that many existing\nmethods can be further enhanced, like PI, YaRN, and LongRoPE. We conducted\nextensive experiments across multiple models and tasks. The results demonstrate\nthat (1) when PSC is enabled, the comparative reductions in perplexity increase\nas the context window size is varied from 16k, to 32k, and up to 64k. (2) Our\napproach is broadly applicable and exhibits robustness across a variety of\nmodels and tasks. The code can be found at https://github.com/WNQzhu/PSC.",
      "tldr_zh": "该研究提出 PSC（Phase Shift Calibration），一种小型模块，用于校准 Rotary Position Embedding (RoPE) 的预定义频率，从而扩展大型语言模型 (LLMs) 的上下文窗口。PSC 通过优化频率校准来增强现有方法，如 PI、YaRN 和 LongRoPE，帮助解决指数级搜索空间的挑战。实验结果显示，启用 PSC 时，随着上下文窗口从 16k 增加到 64k，模型的 perplexity 显著降低，且该方法在多种模型和任务中表现出广泛适用性和鲁棒性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12423v1",
      "published_date": "2025-05-18 13:47:44 UTC",
      "updated_date": "2025-05-18 13:47:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:43:01.221133"
    },
    {
      "arxiv_id": "2505.12421v1",
      "title": "Fixed Point Explainability",
      "title_zh": "固定点可解释性",
      "authors": [
        "Emanuele La Malfa",
        "Jon Vadillo",
        "Marco Molinari",
        "Michael Wooldridge"
      ],
      "abstract": "This paper introduces a formal notion of fixed point explanations, inspired\nby the \"why regress\" principle, to assess, through recursive applications, the\nstability of the interplay between a model and its explainer. Fixed point\nexplanations satisfy properties like minimality, stability, and faithfulness,\nrevealing hidden model behaviours and explanatory weaknesses. We define\nconvergence conditions for several classes of explainers, from feature-based to\nmechanistic tools like Sparse AutoEncoders, and we report quantitative and\nqualitative results.",
      "tldr_zh": "这篇论文引入了 fixed point explanations 的正式概念，受“why regress”原则启发，通过递归应用评估模型和解释器之间的稳定性。固定点解释满足 minimality、stability 和 faithfulness 等属性，能够揭示模型的隐藏行为和解释弱点。论文定义了多种解释器类别的收敛条件，包括基于特征的工具和 Sparse AutoEncoders，并报告了定量和定性结果。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Code: https://github.com/EmanueleLM/fixed-point-explainability",
      "pdf_url": "http://arxiv.org/pdf/2505.12421v1",
      "published_date": "2025-05-18 13:43:25 UTC",
      "updated_date": "2025-05-18 13:43:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:43:12.744433"
    },
    {
      "arxiv_id": "2505.12418v1",
      "title": "Mutual Evidential Deep Learning for Medical Image Segmentation",
      "title_zh": "互证深度学习用于",
      "authors": [
        "Yuanpeng He",
        "Yali Bi",
        "Lijian Li",
        "Chi-Man Pun",
        "Wenpin Jiao",
        "Zhi Jin"
      ],
      "abstract": "Existing semi-supervised medical segmentation co-learning frameworks have\nrealized that model performance can be diminished by the biases in model\nrecognition caused by low-quality pseudo-labels. Due to the averaging nature of\ntheir pseudo-label integration strategy, they fail to explore the reliability\nof pseudo-labels from different sources. In this paper, we propose a mutual\nevidential deep learning (MEDL) framework that offers a potentially viable\nsolution for pseudo-label generation in semi-supervised learning from two\nperspectives. First, we introduce networks with different architectures to\ngenerate complementary evidence for unlabeled samples and adopt an improved\nclass-aware evidential fusion to guide the confident synthesis of evidential\npredictions sourced from diverse architectural networks. Second, utilizing the\nuncertainty in the fused evidence, we design an asymptotic Fisher\ninformation-based evidential learning strategy. This strategy enables the model\nto initially focus on unlabeled samples with more reliable pseudo-labels,\ngradually shifting attention to samples with lower-quality pseudo-labels while\navoiding over-penalization of mislabeled classes in high data uncertainty\nsamples. Additionally, for labeled data, we continue to adopt an\nuncertainty-driven asymptotic learning strategy, gradually guiding the model to\nfocus on challenging voxels. Extensive experiments on five mainstream datasets\nhave demonstrated that MEDL achieves state-of-the-art performance.",
      "tldr_zh": "本研究提出了一种Mutual Evidential Deep Learning (MEDL)框架，用于解决半监督医疗图像分割中伪标签质量低导致模型偏差的问题。MEDL通过使用不同架构的网络生成互补证据，并采用改进的class-aware evidential fusion策略，来可靠地合成伪标签证据；同时，引入基于asymptotic Fisher information的evidential learning策略，使模型先关注高可靠性样本，逐步转向低质量样本，同时避免过度惩罚高不确定性数据。对于标记数据，该框架还使用uncertainty-driven asymptotic learning策略，逐步聚焦挑战性像素。在五个主流数据集上的广泛实验表明，MEDL实现了最先进性能。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12418v1",
      "published_date": "2025-05-18 13:42:27 UTC",
      "updated_date": "2025-05-18 13:42:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:43:26.208193"
    },
    {
      "arxiv_id": "2505.12415v1",
      "title": "Table-R1: Region-based Reinforcement Learning for Table Understanding",
      "title_zh": "翻译失败",
      "authors": [
        "Zhenhe Wu",
        "Jian Yang",
        "Jiaheng Liu",
        "Xianjie Wu",
        "Changzai Pan",
        "Jie Zhang",
        "Yu Zhao",
        "Shuangyong Song",
        "Yongxiang Li",
        "Zhoujun Li"
      ],
      "abstract": "Tables present unique challenges for language models due to their structured\nrow-column interactions, necessitating specialized approaches for effective\ncomprehension. While large language models (LLMs) have demonstrated potential\nin table reasoning through prompting and techniques like chain-of-thought (CoT)\nand program-of-thought (PoT), optimizing their performance for table question\nanswering remains underexplored. In this paper, we introduce region-based\nTable-R1, a novel reinforcement learning approach that enhances LLM table\nunderstanding by integrating region evidence into reasoning steps. Our method\nemploys Region-Enhanced Supervised Fine-Tuning (RE-SFT) to guide models in\nidentifying relevant table regions before generating answers, incorporating\ntextual, symbolic, and program-based reasoning. Additionally, Table-Aware Group\nRelative Policy Optimization (TARPO) introduces a mixed reward system to\ndynamically balance region accuracy and answer correctness, with decaying\nregion rewards and consistency penalties to align reasoning steps. Experiments\nshow that Table-R1 achieves an average performance improvement of 14.36 points\nacross multiple base models on three benchmark datasets, even outperforming\nbaseline models with ten times the parameters, while TARPO reduces response\ntoken consumption by 67.5% compared to GRPO, significantly advancing LLM\ncapabilities in efficient tabular reasoning.",
      "tldr_zh": "该论文针对表格的结构化行-列交互挑战，提出Table-R1，一种基于强化学习的区域方法，以提升LLMs在表格理解和问答中的性能。Table-R1通过Region-Enhanced Supervised Fine-Tuning (RE-SFT)引导模型先识别相关表格区域，并整合文本、符号和程序-based推理；同时，Table-Aware Group Relative Policy Optimization (TARPO)引入混合奖励系统，包括衰减区域奖励和一致性惩罚，以平衡区域准确性和答案正确性。实验结果显示，Table-R1在三个基准数据集上使多个基线模型的平均性能提高14.36点，甚至优于参数多十倍的模型，同时TARPO将响应令牌消耗减少67.5%，显著提升了LLMs的表格推理效率。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12415v1",
      "published_date": "2025-05-18 13:40:18 UTC",
      "updated_date": "2025-05-18 13:40:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:43:37.514708"
    },
    {
      "arxiv_id": "2505.12408v1",
      "title": "ViEEG: Hierarchical Neural Coding with Cross-Modal Progressive Enhancement for EEG-Based Visual Decoding",
      "title_zh": "翻译失败",
      "authors": [
        "Minxu Liu",
        "Donghai Guan",
        "Chuhang Zheng",
        "Chunwei Tian",
        "Jie Wen",
        "Qi Zhu"
      ],
      "abstract": "Understanding and decoding brain activity into visual representations is a\nfundamental challenge at the intersection of neuroscience and artificial\nintelligence. While EEG-based visual decoding has shown promise due to its\nnon-invasive, low-cost nature and millisecond-level temporal resolution,\nexisting methods are limited by their reliance on flat neural representations\nthat overlook the brain's inherent visual hierarchy. In this paper, we\nintroduce ViEEG, a biologically inspired hierarchical EEG decoding framework\nthat aligns with the Hubel-Wiesel theory of visual processing. ViEEG decomposes\neach visual stimulus into three biologically aligned components-contour,\nforeground object, and contextual scene-serving as anchors for a three-stream\nEEG encoder. These EEG features are progressively integrated via\ncross-attention routing, simulating cortical information flow from V1 to IT to\nthe association cortex. We further adopt hierarchical contrastive learning to\nalign EEG representations with CLIP embeddings, enabling zero-shot object\nrecognition. Extensive experiments on the THINGS-EEG dataset demonstrate that\nViEEG achieves state-of-the-art performance, with 40.9% Top-1 accuracy in\nsubject-dependent and 22.9% Top-1 accuracy in cross-subject settings,\nsurpassing existing methods by over 45%. Our framework not only advances the\nperformance frontier but also sets a new paradigm for biologically grounded\nbrain decoding in AI.",
      "tldr_zh": "这篇论文提出了 ViEEG，一种受 Hubel-Wiesel 理论启发的分层 EEG 解码框架，旨在解决 EEG-based visual decoding 中忽略大脑视觉层次结构的问题。ViEEG 将视觉刺激分解为 contour、foreground object 和 contextual scene 等生物学相关组件，使用三流 EEG 编码器并通过 cross-attention routing 逐步整合特征，模拟从 V1 到 IT 到关联皮层的皮层信息流，同时采用 hierarchical contrastive learning 与 CLIP embeddings 对齐，实现 zero-shot object recognition。在 THINGS-EEG 数据集的实验中，ViEEG 实现了 40.9% 的 subject-dependent 和 22.9% 的 cross-subject Top-1 准确率，比现有方法提高了 45%，并为生物学基础的脑解码在 AI 中设定了新范式。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CV",
      "comment": "24 pages, 18 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.12408v1",
      "published_date": "2025-05-18 13:19:08 UTC",
      "updated_date": "2025-05-18 13:19:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:43:50.954257"
    },
    {
      "arxiv_id": "2505.12405v1",
      "title": "The power of text similarity in identifying AI-LLM paraphrased documents: The case of BBC news articles and ChatGPT",
      "title_zh": "翻译失败",
      "authors": [
        "Konstantinos Xylogiannopoulos",
        "Petros Xanthopoulos",
        "Panagiotis Karampelas",
        "Georgios Bakamitsos"
      ],
      "abstract": "Generative AI paraphrased text can be used for copyright infringement and the\nAI paraphrased content can deprive substantial revenue from original content\ncreators. Despite this recent surge of malicious use of generative AI, there\nare few academic publications that research this threat. In this article, we\ndemonstrate the ability of pattern-based similarity detection for AI\nparaphrased news recognition. We propose an algorithmic scheme, which is not\nlimited to detect whether an article is an AI paraphrase, but, more\nimportantly, to identify that the source of infringement is the ChatGPT. The\nproposed method is tested with a benchmark dataset specifically created for\nthis task that incorporates real articles from BBC, incorporating a total of\n2,224 articles across five different news categories, as well as 2,224\nparaphrased articles created with ChatGPT. Results show that our pattern\nsimilarity-based method, that makes no use of deep learning, can detect ChatGPT\nassisted paraphrased articles at percentages 96.23% for accuracy, 96.25% for\nprecision, 96.21% for sensitivity, 96.25% for specificity and 96.23% for F1\nscore.",
      "tldr_zh": "本研究探讨了基于文本相似性的方法，用于识别AI-LLM生成的改写文档，特别是ChatGPT对BBC新闻文章的改写，以应对版权侵权风险。研究提出了一种模式相似性检测算法，不仅能检测文章是否为AI改写，还能识别出ChatGPT作为侵权来源。该算法使用一个包含2224篇BBC真实文章和2224篇ChatGPT改写文章的基准数据集进行测试，覆盖五种新闻类别。结果显示，该方法在不依赖深度学习的情况下，实现了96.23%的准确率、96.25%的精确率和96.23%的F1分数，证明其在检测AI改写文本方面的强大效能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12405v1",
      "published_date": "2025-05-18 13:16:30 UTC",
      "updated_date": "2025-05-18 13:16:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:44:02.727334"
    },
    {
      "arxiv_id": "2505.12404v1",
      "title": "Hyperbolic Residual Quantization: Discrete Representations for Data with Latent Hierarchies",
      "title_zh": "双曲残差量化：用于具有潜在层次结构的数据的离散表示",
      "authors": [
        "Piotr Piękos",
        "Subhradeep Kayal",
        "Alexandros Karatzoglou"
      ],
      "abstract": "Hierarchical data arise in countless domains, from biological taxonomies and\norganizational charts to legal codes and knowledge graphs. Residual\nQuantization (RQ) is widely used to generate discrete, multitoken\nrepresentations for such data by iteratively quantizing residuals in a\nmultilevel codebook. However, its reliance on Euclidean geometry can introduce\nfundamental mismatches that hinder modeling of hierarchical branching,\nnecessary for faithful representation of hierarchical data. In this work, we\npropose Hyperbolic Residual Quantization (HRQ), which embeds data natively in a\nhyperbolic manifold and performs residual quantization using hyperbolic\noperations and distance metrics. By adapting the embedding network, residual\ncomputation, and distance metric to hyperbolic geometry, HRQ imparts an\ninductive bias that aligns naturally with hierarchical branching. We claim that\nHRQ in comparison to RQ can generate more useful for downstream tasks discrete\nhierarchical representations for data with latent hierarchies. We evaluate HRQ\non two tasks: supervised hierarchy modeling using WordNet hypernym trees, where\nthe model is supervised to learn the latent hierarchy - and hierarchy\ndiscovery, where, while latent hierarchy exists in the data, the model is not\ndirectly trained or evaluated on a task related to the hierarchy. Across both\nscenarios, HRQ hierarchical tokens yield better performance on downstream tasks\ncompared to Euclidean RQ with gains of up to $20\\%$ for the hierarchy modeling\ntask. Our results demonstrate that integrating hyperbolic geometry into\ndiscrete representation learning substantially enhances the ability to capture\nlatent hierarchies.",
      "tldr_zh": "本文提出 Hyperbolic Residual Quantization (HRQ)，一种改进的离散表示方法，针对具有潜在层次结构的データ（如生物分类或知识图谱），通过将数据嵌入双曲流形并使用双曲操作和距离度量进行残差量化，以更好地捕捉层次分支的归纳偏差。相比传统的 Residual Quantization (RQ) 依赖于 Euclidean geometry，HRQ 生成更有效的层次表示，在下游任务中表现出显著优势。实验结果显示，在 WordNet hypernym trees 的监督层次建模任务上，HRQ 比 RQ 提升高达 20%，并在非监督的层次发现任务中也表现出色，证明了整合 hyperbolic geometry 的价值。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12404v1",
      "published_date": "2025-05-18 13:14:07 UTC",
      "updated_date": "2025-05-18 13:14:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:44:15.366515"
    },
    {
      "arxiv_id": "2505.13534v1",
      "title": "InterFeat: An Automated Pipeline for Finding Interesting Hypotheses in Structured Biomedical Data",
      "title_zh": "翻译失败",
      "authors": [
        "Dan Ofer",
        "Michal Linial",
        "Dafna Shahaf"
      ],
      "abstract": "Finding interesting phenomena is the core of scientific discovery, but it is\na manual, ill-defined concept. We present an integrative pipeline for\nautomating the discovery of interesting simple hypotheses (feature-target\nrelations with effect direction and a potential underlying mechanism) in\nstructured biomedical data. The pipeline combines machine learning, knowledge\ngraphs, literature search and Large Language Models. We formalize\n\"interestingness\" as a combination of novelty, utility and plausibility. On 8\nmajor diseases from the UK Biobank, our pipeline consistently recovers risk\nfactors years before their appearance in the literature. 40--53% of our top\ncandidates were validated as interesting, compared to 0--7% for a SHAP-based\nbaseline. Overall, 28% of 109 candidates were interesting to medical experts.\nThe pipeline addresses the challenge of operationalizing \"interestingness\"\nscalably and for any target. We release data and code:\nhttps://github.com/LinialLab/InterFeat",
      "tldr_zh": "本文提出 InterFeat，一个自动化管道，用于在结构化生物医学数据中发现有趣的简单假设（feature-target 关系，包括效果方向和潜在机制）。该管道整合 machine learning、knowledge graphs、文献搜索和 Large Language Models，并将 \"interestingness\" 形式化为新颖性、效用性和合理性的组合。在 UK Biobank 的 8 种主要疾病上，管道成功恢复了文献中早年出现过的风险因素，且 40-53% 的顶级候选被验证为有趣，远高于 SHAP-based 基线的 0-7%。整体上，109 个候选中的 28% 被医疗专家认可，该管道可扩展地操作化 \"interestingness\"，并开源了数据和代码。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.CL",
        "cs.IR",
        "68T05, 68T50, 92C50",
        "I.2.6; I.2.7; H.2.8; J.3"
      ],
      "primary_category": "q-bio.QM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13534v1",
      "published_date": "2025-05-18 13:13:51 UTC",
      "updated_date": "2025-05-18 13:13:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:44:28.733359"
    },
    {
      "arxiv_id": "2505.14714v1",
      "title": "KGAlign: Joint Semantic-Structural Knowledge Encoding for Multimodal Fake News Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Tuan-Vinh La",
        "Minh-Hieu Nguyen",
        "Minh-Son Dao"
      ],
      "abstract": "Fake news detection remains a challenging problem due to the complex\ninterplay between textual misinformation, manipulated images, and external\nknowledge reasoning. While existing approaches have achieved notable results in\nverifying veracity and cross-modal consistency, two key challenges persist: (1)\nExisting methods often consider only the global image context while neglecting\nlocal object-level details, and (2) they fail to incorporate external knowledge\nand entity relationships for deeper semantic understanding. To address these\nchallenges, we propose a novel multi-modal fake news detection framework that\nintegrates visual, textual, and knowledge-based representations. Our approach\nleverages bottom-up attention to capture fine-grained object details, CLIP for\nglobal image semantics, and RoBERTa for context-aware text encoding. We further\nenhance knowledge utilization by retrieving and adaptively selecting relevant\nentities from a knowledge graph. The fused multi-modal features are processed\nthrough a Transformer-based classifier to predict news veracity. Experimental\nresults demonstrate that our model outperforms recent approaches, showcasing\nthe effectiveness of neighbor selection mechanism and multi-modal fusion for\nfake news detection. Our proposal introduces a new paradigm: knowledge-grounded\nmultimodal reasoning. By integrating explicit entity-level selection and\nNLI-guided filtering, we shift fake news detection from feature fusion to\nsemantically grounded verification. For reproducibility and further research,\nthe source code is publicly at\n\\href{https://github.com/latuanvinh1998/KGAlign}{github.com/latuanvinh1998/KGAlign}.",
      "tldr_zh": "本论文提出 KGAlign 框架，用于多模态假新闻检测，通过联合语义-结构知识编码解决现有方法忽略局部对象细节和外部知识关系的挑战。\n框架整合 bottom-up attention 捕获细粒度视觉细节、CLIP 处理全局图像语义、RoBERTa 进行上下文感知文本编码，并从知识图谱中检索和选择相关实体。\n多模态特征通过 Transformer-based 分类器融合，实现对新闻真实性的预测，实验结果显示模型性能优于现有方法，并引入知识基础的多模态推理范式，如实体级选择和 NLI-guided 过滤。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14714v1",
      "published_date": "2025-05-18 13:08:38 UTC",
      "updated_date": "2025-05-18 13:08:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:44:39.475130"
    },
    {
      "arxiv_id": "2505.12398v1",
      "title": "Traversal Verification for Speculative Tree Decoding",
      "title_zh": "遍历验证用于推",
      "authors": [
        "Yepeng Weng",
        "Qiao Hu",
        "Xujie Chen",
        "Li Liu",
        "Dianwen Mei",
        "Huishi Qiu",
        "Jiang Tian",
        "Zhongchao Shi"
      ],
      "abstract": "Speculative decoding is a promising approach for accelerating large language\nmodels. The primary idea is to use a lightweight draft model to speculate the\noutput of the target model for multiple subsequent timesteps, and then verify\nthem in parallel to determine whether the drafted tokens should be accepted or\nrejected. To enhance acceptance rates, existing frameworks typically construct\ntoken trees containing multiple candidates in each timestep. However, their\nreliance on token-level verification mechanisms introduces two critical\nlimitations: First, the probability distribution of a sequence differs from\nthat of individual tokens, leading to suboptimal acceptance length. Second,\ncurrent verification schemes begin from the root node and proceed layer by\nlayer in a top-down manner. Once a parent node is rejected, all its child nodes\nshould be discarded, resulting in inefficient utilization of speculative\ncandidates. This paper introduces Traversal Verification, a novel speculative\ndecoding algorithm that fundamentally rethinks the verification paradigm\nthrough leaf-to-root traversal. Our approach considers the acceptance of the\nentire token sequence from the current node to the root, and preserves\npotentially valid subsequences that would be prematurely discarded by existing\nmethods. We theoretically prove that the probability distribution obtained\nthrough Traversal Verification is identical to that of the target model,\nguaranteeing lossless inference while achieving substantial acceleration gains.\nExperimental results across different large language models and multiple tasks\nshow that our method consistently improves acceptance length and throughput\nover existing methods",
      "tldr_zh": "本文提出 Traversal Verification，一种针对 Speculative Decoding 的新算法，用于优化大型语言模型的加速过程。该方法通过从叶到根的遍历验证重新设计验证范式，能够考虑整个 token sequence 的概率分布，并保留可能有效的子序列，从而避免现有框架的次优接受长度和低效利用问题。理论证明显示，该算法保持了目标模型的概率分布，实现无损推理；实验结果表明，在不同大型语言模型和多种任务上，Traversal Verification 显著提高了接受长度和吞吐量。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Under review",
      "pdf_url": "http://arxiv.org/pdf/2505.12398v1",
      "published_date": "2025-05-18 12:51:55 UTC",
      "updated_date": "2025-05-18 12:51:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:44:52.553968"
    },
    {
      "arxiv_id": "2505.12395v1",
      "title": "Few-Shot Concept Unlearning with Low Rank Adaptation",
      "title_zh": "翻译失败",
      "authors": [
        "Udaya Shreyas",
        "L. N. Aadarsh"
      ],
      "abstract": "Image Generation models are a trending topic nowadays, with many people\nutilizing Artificial Intelligence models in order to generate images. There are\nmany such models which, given a prompt of a text, will generate an image which\ndepicts said prompt. There are many image generation models, such as Latent\nDiffusion Models, Denoising Diffusion Probabilistic Models, Generative\nAdversarial Networks and many more. When generating images, these models can\ngenerate sensitive image data, which can be threatening to privacy or may\nviolate copyright laws of private entities. Machine unlearning aims at removing\nthe influence of specific data subsets from the trained models and in the case\nof image generation models, remove the influence of a concept such that the\nmodel is unable to generate said images of the concept when prompted.\nConventional retraining of the model can take upto days, hence fast algorithms\nare the need of the hour. In this paper we propose an algorithm that aims to\nremove the influence of concepts in diffusion models through updating the\ngradients of the final layers of the text encoders. Using a weighted loss\nfunction, we utilize backpropagation in order to update the weights of the\nfinal layers of the Text Encoder componet of the Stable Diffusion Model,\nremoving influence of the concept from the text-image embedding space, such\nthat when prompted, the result is an image not containing the concept. The\nweighted loss function makes use of Textual Inversion and Low-Rank\nAdaptation.We perform our experiments on Latent Diffusion Models, namely the\nStable Diffusion v2 model, with an average concept unlearning runtime of 50\nseconds using 4-5 images.",
      "tldr_zh": "本论文提出了一种Few-Shot Concept Unlearning方法，利用Low Rank Adaptation (LoRA)快速从图像生成模型中删除特定概念的影响，以避免生成敏感或侵犯版权的图像。方法通过更新Stable Diffusion模型的文本编码器最终层权重，并结合Textual Inversion和加权损失函数，实现概念在文本-图像嵌入空间中的移除，仅需4-5张图像即可完成。实验结果显示，该算法在Stable Diffusion v2模型上平均运行时间仅为50秒，比传统重新训练更高效。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12395v1",
      "published_date": "2025-05-18 12:44:30 UTC",
      "updated_date": "2025-05-18 12:44:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:45:03.729942"
    },
    {
      "arxiv_id": "2505.12392v1",
      "title": "SLOT: Sample-specific Language Model Optimization at Test-time",
      "title_zh": "SLOT：测试时样本特定语言模型优化",
      "authors": [
        "Yang Hu",
        "Xingyu Zhang",
        "Xueji Fang",
        "Zhiyang Chen",
        "Xiao Wang",
        "Huatian Zhang",
        "Guojun Qi"
      ],
      "abstract": "We propose SLOT (Sample-specific Language Model Optimization at Test-time), a\nnovel and parameter-efficient test-time inference approach that enhances a\nlanguage model's ability to more accurately respond to individual prompts.\nExisting Large Language Models (LLMs) often struggle with complex instructions,\nleading to poor performances on those not well represented among general\nsamples. To address this, SLOT conducts few optimization steps at test-time to\nupdate a light-weight sample-specific parameter vector. It is added to the\nfinal hidden layer before the output head, and enables efficient adaptation by\ncaching the last layer features during per-sample optimization. By minimizing\nthe cross-entropy loss on the input prompt only, SLOT helps the model better\naligned with and follow each given instruction. In experiments, we demonstrate\nthat our method outperforms the compared models across multiple benchmarks and\nLLMs. For example, Qwen2.5-7B with SLOT achieves an accuracy gain of 8.6% on\nGSM8K from 57.54% to 66.19%, while DeepSeek-R1-Distill-Llama-70B with SLOT\nachieves a SOTA accuracy of 68.69% on GPQA among 70B-level models. Our code is\navailable at https://github.com/maple-research-lab/SLOT.",
      "tldr_zh": "该论文提出了一种名为 SLOT 的参数高效测试时优化方法，用于提升语言模型对特定样本提示的响应准确性。SLOT 通过在测试时进行少量优化步骤，更新一个轻量级的样本特定参数向量，并将其添加到输出头前的最后一个隐藏层，同时利用特征缓存实现高效适应，从而最小化输入提示上的交叉熵损失，使模型更好地对齐和遵循给定指令。在实验中，SLOT 在多个基准和 LLMs 上表现出色，例如 Qwen2.5-7B 在 GSM8K 上的准确率从 57.54% 提升至 66.19%（增益 8.6%），而 DeepSeek-R1-Distill-Llama-70B 在 GPQA 上达到 68.69% 的 SOTA 准确率。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12392v1",
      "published_date": "2025-05-18 12:37:56 UTC",
      "updated_date": "2025-05-18 12:37:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:45:16.924201"
    },
    {
      "arxiv_id": "2505.12386v1",
      "title": "Data Sharing with a Generative AI Competitor",
      "title_zh": "与生成式人工智能竞争对手的数据共享",
      "authors": [
        "Boaz Taitler",
        "Omer Madmon",
        "Moshe Tennenholtz",
        "Omer Ben-Porat"
      ],
      "abstract": "As GenAI platforms grow, their dependence on content from competing\nproviders, combined with access to alternative data sources, creates new\nchallenges for data-sharing decisions. In this paper, we provide a model of\ndata sharing between a content creation firm and a GenAI platform that can also\nacquire content from third-party experts. The interaction is modeled as a\nStackelberg game: the firm first decides how much of its proprietary dataset to\nshare with GenAI, and GenAI subsequently determines how much additional data to\nacquire from external experts. Their utilities depend on user traffic, monetary\ntransfers, and the cost of acquiring additional data from external experts. We\ncharacterize the unique subgame perfect equilibrium of the game and uncover a\nsurprising phenomenon: The firm may be willing to pay GenAI to share the firm's\nown data, leading to a costly data-sharing equilibrium. We further characterize\nthe set of Pareto improving data prices, and show that such improvements occur\nonly when the firm pays to share data. Finally, we study how the price can be\nset to optimize different design objectives, such as promoting firm data\nsharing, expert data acquisition, or a balance of both. Our results shed light\non the economic forces shaping data-sharing partnerships in the age of GenAI,\nand provide guidance for platforms, regulators and policymakers seeking to\ndesign effective data exchange mechanisms.",
      "tldr_zh": "这篇论文使用 Stackelberg game 模型分析内容创建公司与 Generative AI (GenAI) 平台之间的数据共享决策，其中公司先决定分享多少专有数据，GenAI 随后决定从外部专家获取多少额外数据。研究揭示了一个关键现象：公司可能愿意付费给 GenAI 来分享自身数据，导致一种昂贵的均衡状态。论文进一步表征了 Pareto improving 数据价格集合，并探讨了如何设置价格来优化目标，如促进公司数据共享、专家数据获取或两者平衡，为 GenAI 时代的数据交换机制提供政策指导。",
      "categories": [
        "cs.GT",
        "cs.AI"
      ],
      "primary_category": "cs.GT",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12386v1",
      "published_date": "2025-05-18 12:22:37 UTC",
      "updated_date": "2025-05-18 12:22:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:45:28.720477"
    },
    {
      "arxiv_id": "2505.12381v1",
      "title": "From n-gram to Attention: How Model Architectures Learn and Propagate Bias in Language Modeling",
      "title_zh": "从",
      "authors": [
        "Mohsinul Kabir",
        "Tasfia Tahsin",
        "Sophia Ananiadou"
      ],
      "abstract": "Current research on bias in language models (LMs) predominantly focuses on\ndata quality, with significantly less attention paid to model architecture and\ntemporal influences of data. Even more critically, few studies systematically\ninvestigate the origins of bias. We propose a methodology grounded in\ncomparative behavioral theory to interpret the complex interaction between\ntraining data and model architecture in bias propagation during language\nmodeling. Building on recent work that relates transformers to n-gram LMs, we\nevaluate how data, model design choices, and temporal dynamics affect bias\npropagation. Our findings reveal that: (1) n-gram LMs are highly sensitive to\ncontext window size in bias propagation, while transformers demonstrate\narchitectural robustness; (2) the temporal provenance of training data\nsignificantly affects bias; and (3) different model architectures respond\ndifferentially to controlled bias injection, with certain biases (e.g. sexual\norientation) being disproportionately amplified. As language models become\nubiquitous, our findings highlight the need for a holistic approach -- tracing\nbias to its origins across both data and model dimensions, not just symptoms,\nto mitigate harm.",
      "tldr_zh": "本研究探讨了语言模型（LMs）中偏见传播的机制，强调模型架构和数据时间动态的作用，而非仅限于数据质量问题。研究提出了一种基于比较行为理论的方法，比较 n-gram LMs 和 transformers 的表现，评估数据、设计选择和时间因素如何影响偏见传播。关键发现包括：n-gram LMs 对上下文窗口大小高度敏感，而 transformers 展现出架构鲁棒性；训练数据的 temporal provenance 显著影响偏见；不同模型对偏见注入（如性取向偏见）反应不同，导致某些偏见被放大。最后，论文呼吁采用整体方法，追踪偏见的根源并跨数据和模型维度减轻潜在危害。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "19 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.12381v1",
      "published_date": "2025-05-18 11:55:05 UTC",
      "updated_date": "2025-05-18 11:55:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:45:39.704027"
    },
    {
      "arxiv_id": "2505.13533v1",
      "title": "FinMaster: A Holistic Benchmark for Mastering Full-Pipeline Financial Workflows with LLMs",
      "title_zh": "FinMaster：一个用于使用 LLMs 掌握完整管道金融工作流的全面基准",
      "authors": [
        "Junzhe Jiang",
        "Chang Yang",
        "Aixin Cui",
        "Sihan Jin",
        "Ruiyu Wang",
        "Bo Li",
        "Xiao Huang",
        "Dongning Sun",
        "Xinrun Wang"
      ],
      "abstract": "Financial tasks are pivotal to global economic stability; however, their\nexecution faces challenges including labor intensive processes, low error\ntolerance, data fragmentation, and tool limitations. Although large language\nmodels (LLMs) have succeeded in various natural language processing tasks and\nhave shown potential in automating workflows through reasoning and contextual\nunderstanding, current benchmarks for evaluating LLMs in finance lack\nsufficient domain-specific data, have simplistic task design, and incomplete\nevaluation frameworks. To address these gaps, this article presents FinMaster,\na comprehensive financial benchmark designed to systematically assess the\ncapabilities of LLM in financial literacy, accounting, auditing, and\nconsulting. Specifically, FinMaster comprises three main modules: i) FinSim,\nwhich builds simulators that generate synthetic, privacy-compliant financial\ndata for companies to replicate market dynamics; ii) FinSuite, which provides\ntasks in core financial domains, spanning 183 tasks of various types and\ndifficulty levels; and iii) FinEval, which develops a unified interface for\nevaluation. Extensive experiments over state-of-the-art LLMs reveal critical\ncapability gaps in financial reasoning, with accuracy dropping from over 90% on\nbasic tasks to merely 40% on complex scenarios requiring multi-step reasoning.\nThis degradation exhibits the propagation of computational errors, where\nsingle-metric calculations initially demonstrating 58% accuracy decreased to\n37% in multimetric scenarios. To the best of our knowledge, FinMaster is the\nfirst benchmark that covers full-pipeline financial workflows with challenging\ntasks. We hope that FinMaster can bridge the gap between research and industry\npractitioners, driving the adoption of LLMs in real-world financial practices\nto enhance efficiency and accuracy.",
      "tldr_zh": "该研究提出 FinMaster，一个全面的金融基准，用于评估大型语言模型（LLMs）在处理完整金融工作流方面的能力，以解决现有基准的不足，如缺乏领域特定数据和简单任务设计。FinMaster 包括三个核心模块：FinSim 用于生成合成的隐私合规金融数据模拟器、FinSuite 提供 183 个各种类型和难度的金融任务，以及 FinEval 作为统一的评估接口。实验结果显示，LLMs 在金融推理中存在显著差距，基本任务准确率超过 90%，但复杂多步推理场景仅 40%，并揭示了计算错误传播问题；该基准旨在桥接研究与行业，促进 LLMs 在实际金融实践中的应用以提升效率和准确性。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "q-fin.GN"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13533v1",
      "published_date": "2025-05-18 11:47:55 UTC",
      "updated_date": "2025-05-18 11:47:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:45:52.366472"
    },
    {
      "arxiv_id": "2505.13532v1",
      "title": "Distributional Soft Actor-Critic with Harmonic Gradient for Safe and Efficient Autonomous Driving in Multi-lane Scenarios",
      "title_zh": "翻译失败",
      "authors": [
        "Feihong Zhang",
        "Guojian Zhan",
        "Bin Shuai",
        "Tianyi Zhang",
        "Jingliang Duan",
        "Shengbo Eben Li"
      ],
      "abstract": "Reinforcement learning (RL), known for its self-evolution capability, offers\na promising approach to training high-level autonomous driving systems.\nHowever, handling constraints remains a significant challenge for existing RL\nalgorithms, particularly in real-world applications. In this paper, we propose\na new safety-oriented training technique called harmonic policy iteration\n(HPI). At each RL iteration, it first calculates two policy gradients\nassociated with efficient driving and safety constraints, respectively. Then, a\nharmonic gradient is derived for policy updating, minimizing conflicts between\nthe two gradients and consequently enabling a more balanced and stable training\nprocess. Furthermore, we adopt the state-of-the-art DSAC algorithm as the\nbackbone and integrate it with our HPI to develop a new safe RL algorithm,\nDSAC-H. Extensive simulations in multi-lane scenarios demonstrate that DSAC-H\nachieves efficient driving performance with near-zero safety constraint\nviolations.",
      "tldr_zh": "本文提出 harmonic policy iteration (HPI) 技术，用于强化学习 (RL) 在多车道自动驾驶场景中的安全导向训练。HPI 通过计算高效驾驶和安全约束的两个策略梯度，并派生 harmonic gradient 来更新策略，从而最小化二者之间的冲突，实现更平衡稳定的训练过程。该技术被整合到 state-of-the-art DSAC 算法中，形成新的安全 RL 算法 DSAC-H。实验结果显示，在多车道模拟环境中，DSAC-H 实现了高效驾驶性能，同时几乎零安全约束违规。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "IEEE Intelligent Vehicles Symposium (IV 2025)",
      "pdf_url": "http://arxiv.org/pdf/2505.13532v1",
      "published_date": "2025-05-18 11:35:57 UTC",
      "updated_date": "2025-05-18 11:35:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:46:03.443921"
    },
    {
      "arxiv_id": "2505.12371v1",
      "title": "MedAgentBoard: Benchmarking Multi-Agent Collaboration with Conventional Methods for Diverse Medical Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Yinghao Zhu",
        "Ziyi He",
        "Haoran Hu",
        "Xiaochen Zheng",
        "Xichen Zhang",
        "Zixiang Wang",
        "Junyi Gao",
        "Liantao Ma",
        "Lequan Yu"
      ],
      "abstract": "The rapid advancement of Large Language Models (LLMs) has stimulated interest\nin multi-agent collaboration for addressing complex medical tasks. However, the\npractical advantages of multi-agent collaboration approaches remain\ninsufficiently understood. Existing evaluations often lack generalizability,\nfailing to cover diverse tasks reflective of real-world clinical practice, and\nfrequently omit rigorous comparisons against both single-LLM-based and\nestablished conventional methods. To address this critical gap, we introduce\nMedAgentBoard, a comprehensive benchmark for the systematic evaluation of\nmulti-agent collaboration, single-LLM, and conventional approaches.\nMedAgentBoard encompasses four diverse medical task categories: (1) medical\n(visual) question answering, (2) lay summary generation, (3) structured\nElectronic Health Record (EHR) predictive modeling, and (4) clinical workflow\nautomation, across text, medical images, and structured EHR data. Our extensive\nexperiments reveal a nuanced landscape: while multi-agent collaboration\ndemonstrates benefits in specific scenarios, such as enhancing task\ncompleteness in clinical workflow automation, it does not consistently\noutperform advanced single LLMs (e.g., in textual medical QA) or, critically,\nspecialized conventional methods that generally maintain better performance in\ntasks like medical VQA and EHR-based prediction. MedAgentBoard offers a vital\nresource and actionable insights, emphasizing the necessity of a task-specific,\nevidence-based approach to selecting and developing AI solutions in medicine.\nIt underscores that the inherent complexity and overhead of multi-agent\ncollaboration must be carefully weighed against tangible performance gains. All\ncode, datasets, detailed prompts, and experimental results are open-sourced at\nhttps://medagentboard.netlify.app/.",
      "tldr_zh": "本文引入 MedAgentBoard，这是一个全面基准，用于系统评估多智能体协作、单 LLM 和传统方法在多样化医疗任务中的性能。该基准涵盖四个类别：医疗（视觉）问答、科普摘要生成、结构化 Electronic Health Record (EHR) 预测建模，以及临床工作流程自动化，涉及文本、医疗图像和 EHR 数据。实验发现，多智能体协作在特定场景（如临床工作流程自动化）表现出优势，但不一致地优于高级单 LLM（如文本医疗 QA）或专业传统方法（如医疗 VQA 和 EHR 预测）。MedAgentBoard 提供开源资源和见解，强调在医疗 AI 开发中需采用任务特定的、基于证据的方法，以权衡复杂性和性能收益。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12371v1",
      "published_date": "2025-05-18 11:28:17 UTC",
      "updated_date": "2025-05-18 11:28:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:46:17.063093"
    },
    {
      "arxiv_id": "2505.12370v1",
      "title": "Enhancing Visual Grounding for GUI Agents via Self-Evolutionary Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Xinbin Yuan",
        "Jian Zhang",
        "Kaixin Li",
        "Zhuoxuan Cai",
        "Lujian Yao",
        "Jie Chen",
        "Enguang Wang",
        "Qibin Hou",
        "Jinwei Chen",
        "Peng-Tao Jiang",
        "Bo Li"
      ],
      "abstract": "Graphical User Interface (GUI) agents have made substantial strides in\nunderstanding and executing user instructions across diverse platforms. Yet,\ngrounding these instructions to precise interface elements remains challenging,\nespecially in complex, high-resolution, professional environments. Traditional\nsupervised finetuning (SFT) methods often require large volumes of diverse data\nand exhibit weak generalization. To overcome these limitations, we introduce a\nreinforcement learning (RL) based framework that incorporates three core\nstrategies: (1) seed data curation to ensure high quality training samples, (2)\na dense policy gradient that provides continuous feedback based on prediction\naccuracy, and (3) a self evolutionary reinforcement finetuning mechanism that\niteratively refines the model using attention maps. With only 3k training\nsamples, our 7B-parameter model achieves state-of-the-art results among\nsimilarly sized models on three grounding benchmarks. Notably, it attains\n47.3\\% accuracy on the ScreenSpot-Pro dataset, outperforming much larger\nmodels, such as UI-TARS-72B, by a margin of 24.2\\%. These findings underscore\nthe effectiveness of RL-based approaches in enhancing GUI agent performance,\nparticularly in high-resolution, complex environments.",
      "tldr_zh": "该论文针对 Graphical User Interface (GUI) 代理在视觉 grounding 方面的挑战，提出了一种基于 Reinforcement Learning (RL) 的框架，以解决传统 Supervised Finetuning (SFT) 方法数据需求大和泛化性弱的问题。该框架的核心策略包括种子数据整理 (seed data curation) 以确保高质量训练样本、密集策略梯度 (dense policy gradient) 提供连续反馈，以及自我进化强化微调机制 (self evolutionary reinforcement finetuning) 通过注意力图迭代优化模型。实验结果显示，使用仅 3k 训练样本，该 7B 参数模型在三个 grounding 基准上达到最先进水平，在 ScreenSpot-Pro 数据集上实现 47.3% 准确率，比 UI-TARS-72B 模型高出 24.2%。这项研究突显了 RL 方法在高分辨率、复杂环境中的有效性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12370v1",
      "published_date": "2025-05-18 11:22:04 UTC",
      "updated_date": "2025-05-18 11:22:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:46:31.085175"
    },
    {
      "arxiv_id": "2505.12369v1",
      "title": "Fully Geometric Multi-Hop Reasoning on Knowledge Graphs with Transitive Relations",
      "title_zh": "翻译失败",
      "authors": [
        "Fernando Zhapa-Camacho",
        "Robert Hoehndorf"
      ],
      "abstract": "Geometric embedding methods have shown to be useful for multi-hop reasoning\non knowledge graphs by mapping entities and logical operations to geometric\nregions and geometric transformations, respectively. Geometric embeddings\nprovide direct interpretability framework for queries. However, current methods\nhave only leveraged the geometric construction of entities, failing to map\nlogical operations to geometric transformations and, instead, using neural\ncomponents to learn these operations. We introduce GeometrE, a geometric\nembedding method for multi-hop reasoning, which does not require learning the\nlogical operations and enables full geometric interpretability. Additionally,\nunlike previous methods, we introduce a transitive loss function and show that\nit can preserve the logical rule $\\forall a,b,c: r(a,b) \\land r(b,c) \\to\nr(a,c)$. Our experiments show that GeometrE outperforms current\nstate-of-the-art methods on standard benchmark datasets.",
      "tldr_zh": "本文提出 GeometrE，一种全几何嵌入方法，用于知识图谱的多跳推理，通过将实体映射到几何区域并使用几何变换表示逻辑操作，实现完全几何可解释性。不同于现有方法，GeometrE 引入 transitive loss function 来保留传递性逻辑规则，例如 $\\forall a,b,c: r(a,b) \\land r(b,c) \\to r(a,c)$。实验结果表明，GeometrE 在标准基准数据集上超越了当前最先进的方法。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12369v1",
      "published_date": "2025-05-18 11:17:50 UTC",
      "updated_date": "2025-05-18 11:17:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:46:39.530116"
    },
    {
      "arxiv_id": "2505.12368v1",
      "title": "CAPTURE: Context-Aware Prompt Injection Testing and Robustness Enhancement",
      "title_zh": "翻译失败",
      "authors": [
        "Gauri Kholkar",
        "Ratinder Ahuja"
      ],
      "abstract": "Prompt injection remains a major security risk for large language models.\nHowever, the efficacy of existing guardrail models in context-aware settings\nremains underexplored, as they often rely on static attack benchmarks.\nAdditionally, they have over-defense tendencies. We introduce CAPTURE, a novel\ncontext-aware benchmark assessing both attack detection and over-defense\ntendencies with minimal in-domain examples. Our experiments reveal that current\nprompt injection guardrail models suffer from high false negatives in\nadversarial cases and excessive false positives in benign scenarios,\nhighlighting critical limitations.",
      "tldr_zh": "Prompt injection 仍是大型语言模型的主要安全风险，现有的 guardrail models 在 context-aware 环境中表现不佳，常依赖静态攻击基准并存在 over-defense 倾向。  \n本文引入 CAPTURE，这是一个新型的 context-aware 基准，用于评估攻击检测和 over-defense 问题，仅需最少的 in-domain examples。  \n实验结果显示，当前 guardrail models 在对抗性场景中出现高 false negatives，在良性场景中则有过多 false positives，突显了其关键限制。  \n这项工作为提升 prompt injection 的测试和鲁棒性提供了新的评估框架。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted in ACL LLMSec Workshop 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.12368v1",
      "published_date": "2025-05-18 11:14:14 UTC",
      "updated_date": "2025-05-18 11:14:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:46:52.690298"
    },
    {
      "arxiv_id": "2505.12366v1",
      "title": "DisCO: Reinforcing Large Reasoning Models with Discriminative Constrained Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Gang Li",
        "Ming Lin",
        "Tomer Galanti",
        "Zhengzhong Tu",
        "Tianbao Yang"
      ],
      "abstract": "The recent success and openness of DeepSeek-R1 have brought widespread\nattention to Group Relative Policy Optimization (GRPO) as a reinforcement\nlearning method for large reasoning models (LRMs). In this work, we analyze the\nGRPO objective under a binary reward setting and reveal an inherent limitation\nof question-level difficulty bias. We also identify a connection between GRPO\nand traditional discriminative methods in supervised learning. Motivated by\nthese insights, we introduce a new Discriminative Constrained Optimization\n(DisCO) framework for reinforcing LRMs, grounded in the principle of\ndiscriminative learning. The main differences between DisCO and GRPO and its\nrecent variants are: (1) it replaces the group relative objective with a\ndiscriminative objective defined by a scoring function; (2) it abandons\nclipping-based surrogates in favor of non-clipping RL surrogate objectives used\nas scoring functions; (3) it employs a simple yet effective constrained\noptimization approach to enforce the KL divergence constraint, ensuring stable\ntraining. As a result, DisCO offers notable advantages over GRPO and its\nvariants: (i) it completely eliminates difficulty bias by adopting\ndiscriminative objectives; (ii) it addresses the entropy instability in GRPO\nand its variants through the use of non-clipping scoring functions and a\nconstrained optimization approach; (iii) it allows the incorporation of\nadvanced discriminative learning techniques to address data imbalance, where a\nsignificant number of questions have more negative than positive generated\nanswers during training. Our experiments on enhancing the mathematical\nreasoning capabilities of SFT-finetuned models show that DisCO significantly\noutperforms GRPO and its improved variants such as DAPO, achieving average\ngains of 7\\% over GRPO and 6\\% over DAPO across six benchmark tasks for an 1.5B\nmodel.",
      "tldr_zh": "该论文分析了 Group Relative Policy Optimization (GRPO) 在大型推理模型 (LRMs) 中的局限性，特别是二元奖励设置下的问题级别难度偏差，并揭示了其与传统判别式学习方法的联系。作者提出了一种新的 Discriminative Constrained Optimization (DisCO) 框架，基于判别式学习原理，通过采用判别式目标函数、非剪切 RL 代理目标以及 KL divergence 约束的优化方法，来强化 LRMs 的训练稳定性。DisCO 的关键优势包括消除难度偏差、解决熵不稳定性以及处理数据不平衡问题，如训练中负样本多于正样本的情况。在实验中，DisCO 在增强 SFT 微调模型的数学推理能力上，平均比 GRPO 提高 7%、比 DAPO 提高 6%，在六个基准任务上表现突出。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "20 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.12366v1",
      "published_date": "2025-05-18 11:08:32 UTC",
      "updated_date": "2025-05-18 11:08:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:47:04.698231"
    },
    {
      "arxiv_id": "2505.12363v1",
      "title": "Towards Visuospatial Cognition via Hierarchical Fusion of Visual Experts",
      "title_zh": "翻译失败",
      "authors": [
        "Qi Feng",
        "Hidetoshi Shimodaira"
      ],
      "abstract": "While Multimodal Large Language Models (MLLMs) excel at general\nvision-language tasks, visuospatial cognition - reasoning about spatial\nlayouts, relations, and dynamics - remains a significant challenge. Existing\nmodels often lack the necessary architectural components and specialized\ntraining data for fine-grained spatial understanding. We introduce ViCA2\n(Visuospatial Cognitive Assistant 2), a novel MLLM designed to enhance spatial\nreasoning. ViCA2 features a dual vision encoder architecture integrating SigLIP\nfor semantics and Hiera for spatial structure, coupled with a token ratio\ncontrol mechanism for efficiency. We also developed ViCA-322K, a new\nlarge-scale dataset with over 322,000 spatially grounded question-answer pairs\nfor targeted instruction tuning. On the challenging VSI-Bench benchmark, our\nViCA2-7B model achieves a state-of-the-art average score of 56.8, significantly\nsurpassing larger open-source models (e.g., LLaVA-NeXT-Video-72B, 40.9) and\nleading proprietary models (Gemini-1.5 Pro, 45.4). This demonstrates the\neffectiveness of our approach in achieving strong visuospatial intelligence\nwith a compact model. We release ViCA2, its codebase, and the ViCA-322K dataset\nto facilitate further research.",
      "tldr_zh": "该研究针对 Multimodal Large Language Models (MLLMs) 在视空间认知（如空间布局、关系和动态）方面的不足，提出了 ViCA2 模型，通过分层融合的视觉专家（SigLIP 用于语义处理，Hiera 用于空间结构）以及 token 比率控制机制来提升细粒度空间推理能力。研究者开发了 ViCA-322K 数据集，该数据集包含超过32.2万的空间相关问答对，用于针对性指令微调。实验结果显示，ViCA2-7B 模型在 VSI-Bench 基准上达到56.8的平均分数，显著超越了更大开源模型（如 LLaVA-NeXT-Video-72B 的40.9）和专有模型（如 Gemini-1.5 Pro 的45.4），证明了其在紧凑模型中实现强视空间智能的有效性。研究还开源了 ViCA2 模型、代码和数据集，以推动相关领域的研究。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "26 pages, 19 figures, 4 tables. Code, models, and dataset are\n  available at our project page: https://github.com/nkkbr/ViCA",
      "pdf_url": "http://arxiv.org/pdf/2505.12363v1",
      "published_date": "2025-05-18 10:57:33 UTC",
      "updated_date": "2025-05-18 10:57:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:47:18.078335"
    },
    {
      "arxiv_id": "2505.12361v1",
      "title": "Adaptive MPC-based quadrupedal robot control under periodic disturbances",
      "title_zh": "翻译失败",
      "authors": [
        "Elizaveta Pestova",
        "Ilya Osokin",
        "Danil Belov",
        "Pavel Osinenko"
      ],
      "abstract": "Recent advancements in adaptive control for reference trajectory tracking\nenable quadrupedal robots to perform locomotion tasks under challenging\nconditions. There are methods enabling the estimation of the external\ndisturbances in terms of forces and torques. However, a specific case of\ndisturbances that are periodic was not explicitly tackled in application to\nquadrupeds. This work is devoted to the estimation of the periodic disturbances\nwith a lightweight regressor using simplified robot dynamics and extracting the\ndisturbance properties in terms of the magnitude and frequency. Experimental\nevidence suggests performance improvement over the baseline static disturbance\ncompensation. All source files, including simulation setups, code, and\ncalculation scripts, are available on GitHub at\nhttps://github.com/aidagroup/quad-periodic-mpc.",
      "tldr_zh": "本文提出了一种基于 Adaptive MPC 的四足机器人控制方法，针对周期性 disturbances 的影响进行适应性优化。该方法使用轻量级回归器和简化机器人动力学来估计干扰的幅度和频率，从而实现更精确的轨迹跟踪。实验结果表明，该方法比基线静态干扰补偿性能提升明显，所有源代码已在 GitHub 上公开。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12361v1",
      "published_date": "2025-05-18 10:48:38 UTC",
      "updated_date": "2025-05-18 10:48:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:47:27.053099"
    },
    {
      "arxiv_id": "2505.12358v1",
      "title": "AbFlowNet: Optimizing Antibody-Antigen Binding Energy via Diffusion-GFlowNet Fusion",
      "title_zh": "翻译失败",
      "authors": [
        "Abrar Rahman Abir",
        "Haz Sameen Shahgir",
        "Md Rownok Zahan Ratul",
        "Md Toki Tahmid",
        "Greg Ver Steeg",
        "Yue Dong"
      ],
      "abstract": "Complementarity Determining Regions (CDRs) are critical segments of an\nantibody that facilitate binding to specific antigens. Current computational\nmethods for CDR design utilize reconstruction losses and do not jointly\noptimize binding energy, a crucial metric for antibody efficacy. Rather,\nbinding energy optimization is done through computationally expensive Online\nReinforcement Learning (RL) pipelines rely heavily on unreliable binding energy\nestimators. In this paper, we propose AbFlowNet, a novel generative framework\nthat integrates GFlowNet with Diffusion models. By framing each diffusion step\nas a state in the GFlowNet framework, AbFlowNet jointly optimizes standard\ndiffusion losses and binding energy by directly incorporating energy signals\ninto the training process, thereby unifying diffusion and reward optimization\nin a single procedure. Experimental results show that AbFlowNet outperforms the\nbase diffusion model by 3.06% in amino acid recovery, 20.40% in geometric\nreconstruction (RMSD), and 3.60% in binding energy improvement ratio. ABFlowNet\nalso decreases Top-1 total energy and binding energy errors by 24.8% and 38.1%\nwithout pseudo-labeling the test dataset or using computationally expensive\nonline RL regimes.",
      "tldr_zh": "该论文提出 AbFlowNet，一种新型生成框架，将 GFlowNet 与 Diffusion 模型融合，针对抗体中的 Complementarity Determining Regions (CDRs) 进行优化，以联合优化结合能（binding energy），避免了传统方法依赖昂贵的在线强化学习（RL）和不可靠能量估计器的问题。方法通过将每个扩散步骤视为 GFlowNet 中的状态，直接将能量信号融入训练过程，从而统一了扩散损失和奖励优化。实验结果显示，AbFlowNet 相较基础扩散模型，在氨基酸恢复率提高 3.06%、几何重构 (RMSD) 改善 20.40%、结合能改善比提升 3.60%，并将 Top-1 总能量和结合能错误分别降低 24.8% 和 38.1%，无需伪标签或在线 RL。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12358v1",
      "published_date": "2025-05-18 10:40:35 UTC",
      "updated_date": "2025-05-18 10:40:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:47:40.782480"
    },
    {
      "arxiv_id": "2505.12355v2",
      "title": "GATES: Cost-aware Dynamic Workflow Scheduling via Graph Attention Networks and Evolution Strategy",
      "title_zh": "翻译失败",
      "authors": [
        "Ya Shen",
        "Gang Chen",
        "Hui Ma",
        "Mengjie Zhang"
      ],
      "abstract": "Cost-aware Dynamic Workflow Scheduling (CADWS) is a key challenge in cloud\ncomputing, focusing on devising an effective scheduling policy to efficiently\nschedule dynamically arriving workflow tasks, represented as Directed Acyclic\nGraphs (DAG), to suitable virtual machines (VMs). Deep reinforcement learning\n(DRL) has been widely employed for automated scheduling policy design. However,\nthe performance of DRL is heavily influenced by the design of the\nproblem-tailored policy network and is highly sensitive to hyperparameters and\nthe design of reward feedback. Considering the above-mentioned issues, this\nstudy proposes a novel DRL method combining Graph Attention Networks-based\npolicy network and Evolution Strategy, referred to as GATES. The contributions\nof GATES are summarized as follows: (1) GATES can capture the impact of current\ntask scheduling on subsequent tasks by learning the topological relationships\nbetween tasks in a DAG. (2) GATES can assess the importance of each VM to the\nready task, enabling it to adapt to dynamically changing VM resources. (3)\nUtilizing Evolution Strategy's robustness, exploratory nature, and tolerance\nfor delayed rewards, GATES achieves stable policy learning in CADWS. Extensive\nexperimental results demonstrate the superiority of the proposed GATES in\nCADWS, outperforming several state-of-the-art algorithms. The source code is\navailable at: https://github.com/YaShen998/GATES.",
      "tldr_zh": "这篇论文针对 Cost-aware Dynamic Workflow Scheduling (CADWS) 在云计算中的挑战，提出了一种新型 Deep Reinforcement Learning (DRL) 方法 GATES，该方法结合 Graph Attention Networks (GAT) 的政策网络和 Evolution Strategy (ES)，以高效调度动态到达的任务（表示为 Directed Acyclic Graphs, DAG）到合适的虚拟机 (VMs)。GATES 的主要贡献包括：学习 DAG 中的任务拓扑关系以评估当前调度对后续任务的影响、动态评估 VM 的重要性以适应资源变化，以及利用 ES 的鲁棒性和对延迟奖励的容忍实现稳定的政策学习。实验结果显示，GATES 优于多种现有算法，在调度性能上表现出显著优势。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "This paper has been accepted by the 34th International Joint\n  Conference on Artificial Intelligence (IJCAI-2025)",
      "pdf_url": "http://arxiv.org/pdf/2505.12355v2",
      "published_date": "2025-05-18 10:38:41 UTC",
      "updated_date": "2025-05-20 01:15:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:47:53.416966"
    },
    {
      "arxiv_id": "2505.12354v1",
      "title": "A universal policy wrapper with guarantees",
      "title_zh": "翻译失败",
      "authors": [
        "Anton Bolychev",
        "Georgiy Malaniya",
        "Grigory Yaremenko",
        "Anastasia Krasnaya",
        "Pavel Osinenko"
      ],
      "abstract": "We introduce a universal policy wrapper for reinforcement learning agents\nthat ensures formal goal-reaching guarantees. In contrast to standard\nreinforcement learning algorithms that excel in performance but lack rigorous\nsafety assurances, our wrapper selectively switches between a high-performing\nbase policy -- derived from any existing RL method -- and a fallback policy\nwith known convergence properties. Base policy's value function supervises this\nswitching process, determining when the fallback policy should override the\nbase policy to ensure the system remains on a stable path. The analysis proves\nthat our wrapper inherits the fallback policy's goal-reaching guarantees while\npreserving or improving upon the performance of the base policy. Notably, it\noperates without needing additional system knowledge or online constrained\noptimization, making it readily deployable across diverse reinforcement\nlearning architectures and tasks.",
      "tldr_zh": "本研究提出了一种通用的策略包装器（universal policy wrapper），用于强化学习（reinforcement learning）代理，确保正式的目标达到保证（formal goal-reaching guarantees）。该包装器在高性能基策略（base policy）和后备策略（fallback policy）之间选择性切换，由基策略的价值函数监督切换过程，以维持系统稳定性。分析证明，该方法继承了后备策略的收敛属性，同时保留或提升基策略的性能，且无需额外系统知识或在线约束优化，便于部署于各种强化学习架构和任务中。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO",
        "cs.SY",
        "eess.SY",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12354v1",
      "published_date": "2025-05-18 10:37:27 UTC",
      "updated_date": "2025-05-18 10:37:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:48:03.917670"
    },
    {
      "arxiv_id": "2505.12353v1",
      "title": "Importance Sampling for Nonlinear Models",
      "title_zh": "非线性模型的重要性采样",
      "authors": [
        "Prakash Palanivelu Rajmohan",
        "Fred Roosta"
      ],
      "abstract": "While norm-based and leverage-score-based methods have been extensively\nstudied for identifying \"important\" data points in linear models, analogous\ntools for nonlinear models remain significantly underdeveloped. By introducing\nthe concept of the adjoint operator of a nonlinear map, we address this gap and\ngeneralize norm-based and leverage-score-based importance sampling to nonlinear\nsettings. We demonstrate that sampling based on these generalized notions of\nnorm and leverage scores provides approximation guarantees for the underlying\nnonlinear mapping, similar to linear subspace embeddings. As direct\napplications, these nonlinear scores not only reduce the computational\ncomplexity of training nonlinear models by enabling efficient sampling over\nlarge datasets but also offer a novel mechanism for model explainability and\noutlier detection. Our contributions are supported by both theoretical analyses\nand experimental results across a variety of supervised learning scenarios.",
      "tldr_zh": "这篇论文针对非线性模型中重要数据点识别的不足，引入了非线性映射的伴随算子(adjoint operator)，从而将norm-based和leverage-score-based重要性抽样推广到非线性场景。这些推广方法为非线性映射提供近似保证，类似于线性子空间嵌入，能够降低训练非线性模型的计算复杂度，并支持模型可解释性和异常检测机制。研究通过理论分析和实验结果，在多种监督学习场景中验证了这些方法的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "This work is accepted at ICML 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.12353v1",
      "published_date": "2025-05-18 10:34:39 UTC",
      "updated_date": "2025-05-18 10:34:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:48:16.039473"
    },
    {
      "arxiv_id": "2505.12350v1",
      "title": "Multi-CALF: A Policy Combination Approach with Statistical Guarantees",
      "title_zh": "翻译失败",
      "authors": [
        "Georgiy Malaniya",
        "Anton Bolychev",
        "Grigory Yaremenko",
        "Anastasia Krasnaya",
        "Pavel Osinenko"
      ],
      "abstract": "We introduce Multi-CALF, an algorithm that intelligently combines\nreinforcement learning policies based on their relative value improvements. Our\napproach integrates a standard RL policy with a theoretically-backed\nalternative policy, inheriting formal stability guarantees while often\nachieving better performance than either policy individually. We prove that our\ncombined policy converges to a specified goal set with known probability and\nprovide precise bounds on maximum deviation and convergence time. Empirical\nvalidation on control tasks demonstrates enhanced performance while maintaining\nstability guarantees.",
      "tldr_zh": "本文提出Multi-CALF算法，一种智能结合强化学习（RL）策略的方法，通过基于相对价值改进整合标准RL策略和理论支持的替代策略，实现更好的性能同时继承稳定性保证。该算法证明了组合策略以已知概率收敛到指定目标集，并提供了最大偏差和收敛时间的精确边界。在控制任务的实证验证中，Multi-CALF展示了增强的性能表现，同时保持了统计可靠性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO",
        "cs.SY",
        "eess.SY",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12350v1",
      "published_date": "2025-05-18 10:30:24 UTC",
      "updated_date": "2025-05-18 10:30:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:48:27.193134"
    },
    {
      "arxiv_id": "2505.12349v1",
      "title": "Wisdom from Diversity: Bias Mitigation Through Hybrid Human-LLM Crowds",
      "title_zh": "翻译失败",
      "authors": [
        "Axel Abels",
        "Tom Lenaerts"
      ],
      "abstract": "Despite their performance, large language models (LLMs) can inadvertently\nperpetuate biases found in the data they are trained on. By analyzing LLM\nresponses to bias-eliciting headlines, we find that these models often mirror\nhuman biases. To address this, we explore crowd-based strategies for mitigating\nbias through response aggregation. We first demonstrate that simply averaging\nresponses from multiple LLMs, intended to leverage the \"wisdom of the crowd\",\ncan exacerbate existing biases due to the limited diversity within LLM crowds.\nIn contrast, we show that locally weighted aggregation methods more effectively\nleverage the wisdom of the LLM crowd, achieving both bias mitigation and\nimproved accuracy. Finally, recognizing the complementary strengths of LLMs\n(accuracy) and humans (diversity), we demonstrate that hybrid crowds containing\nboth significantly enhance performance and further reduce biases across ethnic\nand gender-related contexts.",
      "tldr_zh": "该研究揭示了大型语言模型(LLMs)往往会反映并放大训练数据中的偏见，通过分析LLMs对偏见诱导标题的响应来证明这一问题。论文比较了响应聚合策略，发现简单平均多个LLMs的响应由于群体多样性不足而可能加剧偏见，而局部加权聚合方法更有效地利用“wisdom of the crowd”，实现偏见缓解和准确性提升。最后，引入混合人类-LLM群体，结合人类的多样性和LLMs的准确性，在种族和性别相关语境中显著提高了性能并进一步减少偏见。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted for publication in the Proceedings of the 34th International\n  Joint Conference on Artificial Intelligence (IJCAI 2025)",
      "pdf_url": "http://arxiv.org/pdf/2505.12349v1",
      "published_date": "2025-05-18 10:29:24 UTC",
      "updated_date": "2025-05-18 10:29:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:48:39.241031"
    },
    {
      "arxiv_id": "2505.12348v1",
      "title": "Reasoning-CV: Fine-tuning Powerful Reasoning LLMs for Knowledge-Assisted Claim Verification",
      "title_zh": "翻译失败",
      "authors": [
        "Zhi Zheng",
        "Wee Sun Lee"
      ],
      "abstract": "Claim verification is essential in combating misinformation, and large\nlanguage models (LLMs) have recently emerged in this area as powerful tools for\nassessing the veracity of claims using external knowledge. Existing LLM-based\nmethods for claim verification typically adopt a Decompose-Then-Verify\nparadigm, which involves decomposing complex claims into several independent\nsub-claims and verifying each sub-claim separately. However, this paradigm\noften introduces errors during the claim decomposition process. To mitigate\nthese errors, we propose to develop the Chain-of-Thought (CoT)-Verify paradigm,\nwhich leverages LLM reasoning methods to generate CoT-verification paths for\nthe original complex claim without requiring decompositions into sub-claims and\nseparate verification stages. The CoT-Verify paradigm allows us to propose a\nnatural fine-tuning method called Reasoning-CV to enhance the verification\ncapabilities in LLMs. Reasoning-CV includes a supervised fine-tuning (SFT)\nstage and a self-improvement direct preference optimization (DPO) stage.\nUtilizing only an 8B pre-trained LLM, Reasoning-CV demonstrates superior\nknowledge-assisted claim verification performances compared to existing\nDecompose-Then-Verify methods, as well as powerful black-box LLMs such as\nGPT-4o+CoT and o1-preview. Our code is available.",
      "tldr_zh": "该研究针对声明验证（claim verification）中的错误问题，提出 Chain-of-Thought (CoT)-Verify 范式，利用 LLMs 的推理能力直接生成验证路径，而非传统 Decompose-Then-Verify 方法分解子声明。论文介绍了 Reasoning-CV 方法，包括监督细调 (SFT) 阶段和自提升直接偏好优化 (DPO) 阶段，通过细调 8B 预训练 LLM，提升了知识辅助声明验证的性能。实验结果显示，Reasoning-CV 优于现有方法和黑盒模型如 GPT-4o+CoT，证明其有效性，并提供了开源代码。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12348v1",
      "published_date": "2025-05-18 10:28:54 UTC",
      "updated_date": "2025-05-18 10:28:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:48:52.717998"
    },
    {
      "arxiv_id": "2505.12346v1",
      "title": "SEED-GRPO: Semantic Entropy Enhanced GRPO for Uncertainty-Aware Policy Optimization",
      "title_zh": "SEED-GRPO：语义熵增强 GRPO 用于不确定性感知策略优化",
      "authors": [
        "Minghan Chen",
        "Guikun Chen",
        "Wenguan Wang",
        "Yi Yang"
      ],
      "abstract": "Large language models (LLMs) exhibit varying levels of confidence across\ninput prompts (questions): some lead to consistent, semantically similar\nanswers, while others yield diverse or contradictory outputs. This variation\nreflects LLM's uncertainty about the input prompt, a signal of how confidently\nthe model understands a given problem. However, vanilla Group Relative Policy\nOptimization (GRPO) treats all prompts equally during policy updates, ignoring\nthis important information about the model's knowledge boundaries. To address\nthis limitation, we propose SEED-GRPO (Semantic Entropy EnhanceD GRPO), which\nexplicitly measures LLMs' uncertainty of the input prompts semantic entropy.\nSemantic entropy measures the diversity of meaning in multiple generated\nanswers given a prompt and uses this to modulate the magnitude of policy\nupdates. This uncertainty-aware training mechanism enables dynamic adjustment\nof policy update magnitudes based on question uncertainty. It allows more\nconservative updates on high-uncertainty questions while maintaining the\noriginal learning signal on confident ones. Experimental results on five\nmathematical reasoning benchmarks (AIME24 56.7, AMC 68.7, MATH 83.4, Minerva\n34.2, and OlympiadBench 48.0) demonstrate that SEED-GRPO achieves new\nstate-of-the-art performance in average accuracy, validating the effectiveness\nof uncertainty-aware policy optimization.",
      "tldr_zh": "该研究提出 SEED-GRPO 方法，通过引入语义熵（semantic entropy）来增强 Group Relative Policy Optimization (GRPO)，以实现不确定性感知的策略优化。语义熵基于多个生成的答案含义多样性，动态调整策略更新幅度，使高不确定性问题得到更保守的更新，而置信度高的问题保持原有学习信号。在五个数学推理基准（AIME24 56.7、AMC 68.7、MATH 83.4、Minerva 34.2 和 OlympiadBench 48.0）上的实验结果显示，SEED-GRPO 实现了新的最先进平均准确率，验证了不确定性感知机制的有效性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "On going project",
      "pdf_url": "http://arxiv.org/pdf/2505.12346v1",
      "published_date": "2025-05-18 10:20:59 UTC",
      "updated_date": "2025-05-18 10:20:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:49:04.409819"
    },
    {
      "arxiv_id": "2505.12343v1",
      "title": "Mitigating Hallucinations via Inter-Layer Consistency Aggregation in Large Vision-Language Models",
      "title_zh": "通过层间一致性聚合缓解大型视觉语言模型中的幻觉",
      "authors": [
        "Kai Tang",
        "Jinhao You",
        "Xiuqi Ge",
        "Hanze Li",
        "Yichen Guo",
        "Xiande Huang"
      ],
      "abstract": "Despite the impressive capabilities of Large Vision-Language Models (LVLMs),\nthey remain susceptible to hallucinations-generating content that is\ninconsistent with the input image. Existing training-free hallucination\nmitigation methods often suffer from unstable performance and high sensitivity\nto hyperparameter settings, limiting their practicality and broader adoption.\nIn this paper, we propose a novel decoding mechanism, Decoding with Inter-layer\nConsistency via Layer Aggregation (DCLA), which requires no retraining,\nfine-tuning, or access to external knowledge bases. Specifically, our approach\nconstructs a dynamic semantic reference by aggregating representations from\nprevious layers, and corrects semantically deviated layers to enforce\ninter-layer consistency. The method allows DCLA to robustly mitigate\nhallucinations across multiple LVLMs. Experiments on hallucination benchmarks\nsuch as MME and POPE demonstrate that DCLA effectively reduces hallucinations\nwhile enhancing the reliability and performance of LVLMs.",
      "tldr_zh": "本论文针对Large Vision-Language Models (LVLMs)中常见的hallucinations问题，提出了一种新型解码机制Decoding with Inter-layer Consistency via Layer Aggregation (DCLA)，无需重新训练、微调或外部知识库支持。DCLA通过聚合前层表示构建动态语义参考，并修正语义偏差层以强制层间一致性，从而稳定缓解幻觉现象。实验结果显示，在MME和POPE等基准测试中，DCLA显著降低了hallucinations，提升了LVLMs的可靠性和整体性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12343v1",
      "published_date": "2025-05-18 10:15:42 UTC",
      "updated_date": "2025-05-18 10:15:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:49:15.722423"
    },
    {
      "arxiv_id": "2505.12339v1",
      "title": "Towards Open-world Generalized Deepfake Detection: General Feature Extraction via Unsupervised Domain Adaptation",
      "title_zh": "翻译失败",
      "authors": [
        "Midou Guo",
        "Qilin Yin",
        "Wei Lu",
        "Xiangyang Luo"
      ],
      "abstract": "With the development of generative artificial intelligence, new forgery\nmethods are rapidly emerging. Social platforms are flooded with vast amounts of\nunlabeled synthetic data and authentic data, making it increasingly challenging\nto distinguish real from fake. Due to the lack of labels, existing supervised\ndetection methods struggle to effectively address the detection of unknown\ndeepfake methods. Moreover, in open world scenarios, the amount of unlabeled\ndata greatly exceeds that of labeled data. Therefore, we define a new deepfake\ndetection generalization task which focuses on how to achieve efficient\ndetection of large amounts of unlabeled data based on limited labeled data to\nsimulate a open world scenario. To solve the above mentioned task, we propose a\nnovel Open-World Deepfake Detection Generalization Enhancement Training\nStrategy (OWG-DS) to improve the generalization ability of existing methods.\nOur approach aims to transfer deepfake detection knowledge from a small amount\nof labeled source domain data to large-scale unlabeled target domain data.\nSpecifically, we introduce the Domain Distance Optimization (DDO) module to\nalign different domain features by optimizing both inter-domain and\nintra-domain distances. Additionally, the Similarity-based Class Boundary\nSeparation (SCBS) module is used to enhance the aggregation of similar samples\nto ensure clearer class boundaries, while an adversarial training mechanism is\nadopted to learn the domain-invariant features. Extensive experiments show that\nthe proposed deepfake detection generalization enhancement training strategy\nexcels in cross-method and cross-dataset scenarios, improving the model's\ngeneralization.",
      "tldr_zh": "该研究针对生成式人工智能带来的新深假方法挑战，定义了一个新的深假检测泛化任务，即基于少量标记数据高效检测大量未标记数据，以模拟开放世界场景。作者提出了一种新型训练策略OWG-DS，通过无监督域适应（Unsupervised Domain Adaptation）将知识从源域转移到目标域。具体地，该策略包括Domain Distance Optimization (DDO)模块优化域间和域内距离、Similarity-based Class Boundary Separation (SCBS)模块增强类似样本的聚合，以及对抗训练机制来学习域不变特征。实验结果表明，OWG-DS在跨方法和跨数据集场景中显著提高了模型的泛化能力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12339v1",
      "published_date": "2025-05-18 10:12:12 UTC",
      "updated_date": "2025-05-18 10:12:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:49:27.365012"
    },
    {
      "arxiv_id": "2505.12334v1",
      "title": "Enhancing User-Oriented Proactivity in Open-Domain Dialogues with Critic Guidance",
      "title_zh": "翻译失败",
      "authors": [
        "Yufeng Wang",
        "Jinwu Hu",
        "Ziteng Huang",
        "Kunyang Lin",
        "Zitian Zhang",
        "Peihao Chen",
        "Yu Hu",
        "Qianyue Wang",
        "Zhuliang Yu",
        "Bin Sun",
        "Xiaofen Xing",
        "Qingfang Zheng",
        "Mingkui Tan"
      ],
      "abstract": "Open-domain dialogue systems aim to generate natural and engaging\nconversations, providing significant practical value in real applications such\nas social robotics and personal assistants. The advent of large language models\n(LLMs) has greatly advanced this field by improving context understanding and\nconversational fluency. However, existing LLM-based dialogue systems often fall\nshort in proactively understanding the user's chatting preferences and guiding\nconversations toward user-centered topics. This lack of user-oriented\nproactivity can lead users to feel unappreciated, reducing their satisfaction\nand willingness to continue the conversation in human-computer interactions. To\naddress this issue, we propose a User-oriented Proactive Chatbot (UPC) to\nenhance the user-oriented proactivity. Specifically, we first construct a\ncritic to evaluate this proactivity inspired by the LLM-as-a-judge strategy.\nGiven the scarcity of high-quality training data, we then employ the critic to\nguide dialogues between the chatbot and user agents, generating a corpus with\nenhanced user-oriented proactivity. To ensure the diversity of the user\nbackgrounds, we introduce the ISCO-800, a diverse user background dataset for\nconstructing user agents. Moreover, considering the communication difficulty\nvaries among users, we propose an iterative curriculum learning method that\ntrains the chatbot from easy-to-communicate users to more challenging ones,\nthereby gradually enhancing its performance. Experiments demonstrate that our\nproposed training method is applicable to different LLMs, improving\nuser-oriented proactivity and attractiveness in open-domain dialogues.",
      "tldr_zh": "该论文针对开放域对话系统（如基于 LLMs 的模型）缺乏用户导向主动性的问题，提出了一种 User-oriented Proactive Chatbot (UPC) 框架，以提升对话的吸引力。关键方法包括构建一个受 LLM-as-a-judge 启发的 critic 来评估用户导向主动性，并使用它指导聊天机器人与用户代理的对话生成，以创建高质量语料。论文还引入 ISCO-800 数据集来构建多样化用户背景，并采用迭代课程学习方法，从易沟通用户逐步训练到更具挑战性的用户。实验证明，该方法适用于不同 LLMs，能显著提高开放域对话的用户导向主动性和整体吸引力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "9 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.12334v1",
      "published_date": "2025-05-18 09:59:22 UTC",
      "updated_date": "2025-05-18 09:59:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:49:41.026083"
    },
    {
      "arxiv_id": "2505.12332v2",
      "title": "VoiceCloak: A Multi-Dimensional Defense Framework against Unauthorized Diffusion-based Voice Cloning",
      "title_zh": "翻译失败",
      "authors": [
        "Qianyue Hu",
        "Junyan Wu",
        "Wei Lu",
        "Xiangyang Luo"
      ],
      "abstract": "Diffusion Models (DMs) have achieved remarkable success in realistic voice\ncloning (VC), while they also increase the risk of malicious misuse. Existing\nproactive defenses designed for traditional VC models aim to disrupt the\nforgery process, but they have been proven incompatible with DMs due to the\nintricate generative mechanisms of diffusion. To bridge this gap, we introduce\nVoiceCloak, a multi-dimensional proactive defense framework with the goal of\nobfuscating speaker identity and degrading perceptual quality in potential\nunauthorized VC. To achieve these goals, we conduct a focused analysis to\nidentify specific vulnerabilities within DMs, allowing VoiceCloak to disrupt\nthe cloning process by introducing adversarial perturbations into the reference\naudio. Specifically, to obfuscate speaker identity, VoiceCloak first targets\nspeaker identity by distorting representation learning embeddings to maximize\nidentity variation, which is guided by auditory perception principles.\nAdditionally, VoiceCloak disrupts crucial conditional guidance processes,\nparticularly attention context, thereby preventing the alignment of vocal\ncharacteristics that are essential for achieving convincing cloning. Then, to\naddress the second objective, VoiceCloak introduces score magnitude\namplification to actively steer the reverse trajectory away from the generation\nof high-quality speech. Noise-guided semantic corruption is further employed to\ndisrupt structural speech semantics captured by DMs, degrading output quality.\nExtensive experiments highlight VoiceCloak's outstanding defense success rate\nagainst unauthorized diffusion-based voice cloning.",
      "tldr_zh": "本研究提出VoiceCloak框架，一种多维度的主动防御机制，针对Diffusion Models (DMs) 的语音克隆(VC) 风险，通过引入对抗性扰动来混淆说话者身份并降低感知质量。具体方法包括扭曲表示学习嵌入以最大化身份变化、破坏注意力上下文以防止语音特征对齐，以及放大分数幅度和噪声引导语义破坏来引导生成轨迹远离高质量输出。实验证明，VoiceCloak在对抗未经授权的DMs-based VC方面表现出色，成功率显著提升。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CV",
        "cs.MM",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12332v2",
      "published_date": "2025-05-18 09:58:48 UTC",
      "updated_date": "2025-05-21 02:08:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:49:52.510791"
    },
    {
      "arxiv_id": "2505.12329v1",
      "title": "MPRM: A Markov Path-based Rule Miner for Efficient and Interpretable Knowledge Graph Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Mingyang Li",
        "Song Wang",
        "Ning Cai"
      ],
      "abstract": "Rule mining in knowledge graphs enables interpretable link prediction.\nHowever, deep learning-based rule mining methods face significant memory and\ntime challenges for large-scale knowledge graphs, whereas traditional\napproaches, limited by rigid confidence metrics, incur high computational costs\ndespite sampling techniques. To address these challenges, we propose MPRM, a\nnovel rule mining method that models rule-based inference as a Markov chain and\nuses an efficient confidence metric derived from aggregated path probabilities,\nsignificantly lowering computational demands. Experiments on multiple datasets\nshow that MPRM efficiently mines knowledge graphs with over a million facts,\nsampling less than 1% of facts on a single CPU in 22 seconds, while preserving\ninterpretability and boosting inference accuracy by up to 11% over baselines.",
      "tldr_zh": "这篇论文提出了 MPRM，一种基于 Markov chain 的规则挖掘方法，用于知识图谱推理，旨在解决现有方法的内存、时间消耗和计算成本问题。MPRM 通过将规则推理建模为马尔可夫链，并采用基于聚合路径概率的置信度指标，显著降低了计算需求，同时保持高可解释性。在多个数据集上的实验显示，MPRM 能在单 CPU 上处理超过百万级事实，仅采样不到 1% 的数据，并在 22 秒内完成，推理准确性比基线模型提升高达 11%。",
      "categories": [
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12329v1",
      "published_date": "2025-05-18 09:48:45 UTC",
      "updated_date": "2025-05-18 09:48:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:50:03.545419"
    },
    {
      "arxiv_id": "2505.12327v1",
      "title": "Robust Planning for Autonomous Driving via Mixed Adversarial Diffusion Predictions",
      "title_zh": "翻译失败",
      "authors": [
        "Albert Zhao",
        "Stefano Soatto"
      ],
      "abstract": "We describe a robust planning method for autonomous driving that mixes normal\nand adversarial agent predictions output by a diffusion model trained for\nmotion prediction. We first train a diffusion model to learn an unbiased\ndistribution of normal agent behaviors. We then generate a distribution of\nadversarial predictions by biasing the diffusion model at test time to generate\npredictions that are likely to collide with a candidate plan. We score plans\nusing expected cost with respect to a mixture distribution of normal and\nadversarial predictions, leading to a planner that is robust against\nadversarial behaviors but not overly conservative when agents behave normally.\nUnlike current approaches, we do not use risk measures that over-weight\nadversarial behaviors while placing little to no weight on low-cost normal\nbehaviors or use hard safety constraints that may not be appropriate for all\ndriving scenarios. We show the effectiveness of our method on single-agent and\nmulti-agent jaywalking scenarios as well as a red light violation scenario.",
      "tldr_zh": "这篇论文提出了一种用于自动驾驶的鲁棒规划方法，通过混合正常和对抗性代理预测来提升对潜在风险的应对能力。具体而言，作者训练一个 diffusion model 来学习正常代理行为的无偏分布，并在测试时偏置模型生成可能与候选计划碰撞的 adversarial predictions，然后使用混合分布的预期成本对计划进行评分，以实现鲁棒性而不过度保守。与现有方法不同，该方法避免使用过度重视对抗行为的风险措施或硬安全约束，并在单代理和多代理 jaywalking 场景以及 red light violation 场景中验证了其有效性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "IEEE International Conference on Robotics and Automation (ICRA) 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.12327v1",
      "published_date": "2025-05-18 09:44:57 UTC",
      "updated_date": "2025-05-18 09:44:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:50:15.009431"
    },
    {
      "arxiv_id": "2505.12321v1",
      "title": "BeliefNest: A Joint Action Simulator for Embodied Agents with Theory of Mind",
      "title_zh": "BeliefNest：一种带有心智理论的具身代理联合行动模拟器",
      "authors": [
        "Rikunari Sagara",
        "Koichiro Terao",
        "Naoto Iwahashi"
      ],
      "abstract": "This paper introduces an open-source simulator, BeliefNest, designed to\nenable embodied agents to perform collaborative tasks by leveraging Theory of\nMind. BeliefNest dynamically and hierarchically constructs simulators within a\nMinecraft environment, allowing agents to explicitly represent nested belief\nstates about themselves and others. This enables agent control in open-domain\ntasks that require Theory of Mind reasoning. The simulator provides a prompt\ngeneration mechanism based on each belief state, facilitating the design and\nevaluation of methods for agent control utilizing large language models (LLMs).\nWe demonstrate through experiments that agents can infer others' beliefs and\npredict their belief-based actions in false-belief tasks.",
      "tldr_zh": "本论文引入了开源模拟器 BeliefNest，用于帮助具身代理（embodied agents）通过 Theory of Mind 执行协作任务。BeliefNest 在 Minecraft 环境中动态构建层次化模拟器，允许代理明确表示自身与他人的嵌套信念状态（nested belief states），并提供基于信念状态的提示生成机制，以支持利用大型语言模型（LLMs）的代理控制设计和评估。在实验中，代理成功推断他人信念并预测其基于信念的行动，尤其在虚假信念任务（false-belief tasks）中，展示了其在开放域任务中的有效性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12321v1",
      "published_date": "2025-05-18 09:26:48 UTC",
      "updated_date": "2025-05-18 09:26:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:50:27.432501"
    },
    {
      "arxiv_id": "2505.13531v1",
      "title": "AdAEM: An Adaptively and Automated Extensible Measurement of LLMs' Value Difference",
      "title_zh": "翻译失败",
      "authors": [
        "Shitong Duan",
        "Xiaoyuan Yi",
        "Peng Zhang",
        "Dongkuan Xu",
        "Jing Yao",
        "Tun Lu",
        "Ning Gu",
        "Xing Xie"
      ],
      "abstract": "Assessing Large Language Models (LLMs)' underlying value differences enables\ncomprehensive comparison of their misalignment, cultural adaptability, and\nbiases. Nevertheless, current value measurement datasets face the\ninformativeness challenge: with often outdated, contaminated, or generic test\nquestions, they can only capture the shared value orientations among different\nLLMs, leading to saturated and thus uninformative results. To address this\nproblem, we introduce AdAEM, a novel, self-extensible assessment framework for\nrevealing LLMs' inclinations. Distinct from previous static benchmarks, AdAEM\ncan automatically and adaptively generate and extend its test questions. This\nis achieved by probing the internal value boundaries of a diverse set of LLMs\ndeveloped across cultures and time periods in an in-context optimization\nmanner. The optimization process theoretically maximizes an\ninformation-theoretic objective to extract the latest or culturally\ncontroversial topics, providing more distinguishable and informative insights\nabout models' value differences. In this way, AdAEM is able to co-evolve with\nthe development of LLMs, consistently tracking their value dynamics. Using\nAdAEM, we generate 12,310 questions grounded in Schwartz Value Theory, conduct\nan extensive analysis to manifest our method's validity and effectiveness, and\nbenchmark the values of 16 LLMs, laying the groundwork for better value\nresearch.",
      "tldr_zh": "本研究提出AdAEM，一种适应性和自动扩展的框架，用于评估大型语言模型（LLMs）的价值差异，从而揭示其失调、文化适应性和偏见。AdAEM 通过在上下文中优化多样化LLMs的内部价值边界，并最大化信息理论目标，自动生成和扩展测试问题，聚焦于最新或文化争议话题，以提供更具区分性的见解。实验生成了12,310个基于Schwartz Value Theory的问题，对16个LLMs进行了基准测试，证明了框架的有效性，并为LLMs的价值研究奠定了基础。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13531v1",
      "published_date": "2025-05-18 09:15:26 UTC",
      "updated_date": "2025-05-18 09:15:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:50:39.005481"
    },
    {
      "arxiv_id": "2505.12312v1",
      "title": "Visuospatial Cognitive Assistant",
      "title_zh": "视觉空间认知助手",
      "authors": [
        "Qi Feng",
        "Hidetoshi Shimodaira"
      ],
      "abstract": "Video-based spatial cognition is vital for robotics and embodied AI but\nchallenges current Vision-Language Models (VLMs). This paper makes two key\ncontributions. First, we introduce ViCA (Visuospatial Cognitive\nAssistant)-322K, a diverse dataset of 322,003 QA pairs from real-world indoor\nvideos (ARKitScenes, ScanNet, ScanNet++), offering supervision for 3D\nmetadata-grounded queries and video-based complex reasoning. Second, we develop\nViCA-7B, fine-tuned on ViCA-322K, which achieves new state-of-the-art on all\neight VSI-Bench tasks, outperforming existing models, including larger ones\n(e.g., +26.1 on Absolute Distance). For interpretability, we present\nViCA-Thinking-2.68K, a dataset with explicit reasoning chains, and fine-tune\nViCA-7B to create ViCA-7B-Thinking, a model that articulates its spatial\nreasoning. Our work highlights the importance of targeted data and suggests\npaths for improved temporal-spatial modeling. We release all resources to\nfoster research in robust visuospatial intelligence.",
      "tldr_zh": "本研究针对视频-based 空间认知在机器人和 embodied AI 中的挑战，提出了 Visuospatial Cognitive Assistant (ViCA) 框架。首先，引入 ViCA-322K 数据集，包含 322,003 个 QA 对，基于真实室内视频（如 ARKitScenes、ScanNet 和 ScanNet++），提供 3D 元数据基础的查询和复杂推理监督。其次，开发了 ViCA-7B 模型，通过在 ViCA-322K 上微调，实现了 VSI-Bench 八个任务的新最先进性能，超过了现有模型（如在 Absolute Distance 上提升 26.1）。此外，为提升可解释性，构建了 ViCA-Thinking-2.68K 数据集并微调出 ViCA-7B-Thinking 模型，使其能清晰阐述空间推理过程。该工作强调针对性数据的重要性，并通过开源资源推动鲁棒 visuospatial 智能的研究。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "31 pages, 10 figures, 6 tables. The implementation and fine-tuned\n  model (ViCA-7B) are publicly available at https://huggingface.co/nkkbr/ViCA.\n  The ViCA-322K dataset can be found at\n  https://huggingface.co/datasets/nkkbr/ViCA-322K, and the ViCA-Thinking-2.68K\n  dataset is at https://huggingface.co/datasets/nkkbr/ViCA-thinking-2.68k",
      "pdf_url": "http://arxiv.org/pdf/2505.12312v1",
      "published_date": "2025-05-18 08:55:02 UTC",
      "updated_date": "2025-05-18 08:55:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:50:53.677268"
    },
    {
      "arxiv_id": "2505.12310v1",
      "title": "DNOI-4DRO: Deep 4D Radar Odometry with Differentiable Neural-Optimization Iterations",
      "title_zh": "DNOI-4DRO：基于可微神经优化迭代",
      "authors": [
        "Shouyi Lu",
        "Huanyu Zhou",
        "Guirong Zhuo"
      ],
      "abstract": "A novel learning-optimization-combined 4D radar odometry model, named\nDNOI-4DRO, is proposed in this paper. The proposed model seamlessly integrates\ntraditional geometric optimization with end-to-end neural network training,\nleveraging an innovative differentiable neural-optimization iteration operator.\nIn this framework, point-wise motion flow is first estimated using a neural\nnetwork, followed by the construction of a cost function based on the\nrelationship between point motion and pose in 3D space. The radar pose is then\nrefined using Gauss-Newton updates. Additionally, we design a dual-stream 4D\nradar backbone that integrates multi-scale geometric features and\nclustering-based class-aware features to enhance the representation of sparse\n4D radar point clouds. Extensive experiments on the VoD and Snail-Radar\ndatasets demonstrate the superior performance of our model, which outperforms\nrecent classical and learning-based approaches. Notably, our method even\nachieves results comparable to A-LOAM with mapping optimization using LiDAR\npoint clouds as input. Our models and code will be publicly released.",
      "tldr_zh": "本论文提出了一种名为DNOI-4DRO的4D Radar Odometry模型，将传统的几何优化与端到端神经网络训练无缝整合，通过可微分神经-优化迭代操作符实现点-wise运动流估计和雷达位姿的Gauss-Newton更新。模型还设计了双流4D雷达主干网络，融合多尺度几何特征和基于聚类的类感知特征，以提升稀疏4D雷达点云的表示能力。在VoD和Snail-Radar数据集上的实验显示，DNOI-4DRO优于现有经典和学习-based方法，甚至与使用LiDAR点云的A-LOAM方法相当，模型和代码将公开发布。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "16 pages,10 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.12310v1",
      "published_date": "2025-05-18 08:50:54 UTC",
      "updated_date": "2025-05-18 08:50:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:51:06.265020"
    },
    {
      "arxiv_id": "2505.12309v1",
      "title": "Community Search in Time-dependent Road-social Attributed Networks",
      "title_zh": "在时变道路-社交属性网络中的社区搜索",
      "authors": [
        "Li Ni",
        "Hengkai Xu",
        "Lin Mu",
        "Yiwen Zhang",
        "Wenjian Luo"
      ],
      "abstract": "Real-world networks often involve both keywords and locations, along with\ntravel time variations between locations due to traffic conditions. However,\nmost existing cohesive subgraph-based community search studies utilize a single\nattribute, either keywords or locations, to identify communities. They do not\nsimultaneously consider both keywords and locations, which results in low\nsemantic or spatial cohesiveness of the detected communities, and they fail to\naccount for variations in travel time. Additionally, these studies traverse the\nentire network to build efficient indexes, but the detected community only\ninvolves nodes around the query node, leading to the traversal of nodes that\nare not relevant to the community. Therefore, we propose the problem of\ndiscovering semantic-spatial aware k-core, which refers to a k-core with high\nsemantic and time-dependent spatial cohesiveness containing the query node. To\naddress this problem, we propose an exact and a greedy algorithm, both of which\ngradually expand outward from the query node. They are local methods that only\naccess the local part of the attributed network near the query node rather than\nthe entire network. Moreover, we design a method to calculate the semantic\nsimilarity between two keywords using large language models. This method\nalleviates the disadvantages of keyword-matching methods used in existing\ncommunity search studies, such as mismatches caused by differently expressed\nsynonyms and the presence of irrelevant words. Experimental results show that\nthe greedy algorithm outperforms baselines in terms of structural, semantic,\nand time-dependent spatial cohesiveness.",
      "tldr_zh": "这篇论文探讨了在时间依赖的道路-社交属性网络中进行社区搜索的问题，强调同时考虑关键词、位置和旅行时间变化，以解决现有方法在语义和空间连贯性方面的不足。作者提出“语义-空间感知 k-core”的新概念，指的是一个包含查询节点的 k-core，具有高语义和时间依赖空间连贯性，并设计了精确算法和贪婪算法，这些算法从查询节点向外局部扩展，仅访问网络的相关部分。论文还引入使用 large language models 计算关键词语义相似性的方法，以避免传统关键词匹配的弊端，如同义词不匹配问题。实验结果表明，贪婪算法在结构、语义和时间依赖空间连贯性上均优于基线方法。",
      "categories": [
        "cs.SI",
        "cs.AI"
      ],
      "primary_category": "cs.SI",
      "comment": "12 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.12309v1",
      "published_date": "2025-05-18 08:45:05 UTC",
      "updated_date": "2025-05-18 08:45:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:51:17.330480"
    },
    {
      "arxiv_id": "2505.12304v1",
      "title": "Pre-trained Prompt-driven Community Search",
      "title_zh": "预训练提示驱动社区搜索",
      "authors": [
        "Li Ni",
        "Hengkai Xu",
        "Lin Mu",
        "Yiwen Zhang",
        "Wenjian Luo"
      ],
      "abstract": "The \"pre-train, prompt\" paradigm is widely adopted in various graph-based\ntasks and has shown promising performance in community detection. Most existing\nsemi-supervised community detection algorithms detect communities based on\nknown ones, and the detected communities typically do not contain the given\nquery node. Therefore, they are not suitable for searching the community of a\ngiven node. Motivated by this, we adopt this paradigm into the semi-supervised\ncommunity search for the first time and propose Pre-trained Prompt-driven\nCommunity Search (PPCS), a novel model designed to enhance search accuracy and\nefficiency. PPCS consists of three main components: node encoding, sample\ngeneration, and prompt-driven fine-tuning. Specifically, the node encoding\ncomponent employs graph neural networks to learn local structural patterns of\nnodes in a graph, thereby obtaining representations for nodes and communities.\nNext, the sample generation component identifies an initial community for a\ngiven node and selects known communities that are structurally similar to the\ninitial one as training samples. Finally, the prompt-driven fine-tuning\ncomponent leverages these samples as prompts to guide the final community\nprediction. Experimental results on five real-world datasets demonstrate that\nPPCS performs better than baseline algorithms. It also achieves higher\ncommunity search efficiency than semi-supervised community search baseline\nmethods, with ablation studies verifying the effectiveness of each component of\nPPCS.",
      "tldr_zh": "本文提出PPCS（Pre-trained Prompt-driven Community Search）模型，首次将“pre-train, prompt”范式应用于半监督社区搜索，以解决现有算法无法包含查询节点的局限性。PPCS包括三个核心组件：节点编码（使用graph neural networks学习节点和社区的表示）、样本生成（为给定节点识别初始社区并选择类似社区作为训练样本），以及prompt-driven fine-tuning（利用样本作为提示指导最终社区预测）。实验在五个真实数据集上表明，PPCS比基线算法在准确性和效率上均有显著提升，消融研究验证了各组件的有效性。",
      "categories": [
        "cs.SI",
        "cs.AI"
      ],
      "primary_category": "cs.SI",
      "comment": "11 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.12304v1",
      "published_date": "2025-05-18 08:36:37 UTC",
      "updated_date": "2025-05-18 08:36:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:51:28.391032"
    },
    {
      "arxiv_id": "2505.12301v1",
      "title": "Beyond Single-Point Judgment: Distribution Alignment for LLM-as-a-Judge",
      "title_zh": "超越单一点判断：LLM-as-a-Judge 的分布对齐",
      "authors": [
        "Luyu Chen",
        "Zeyu Zhang",
        "Haoran Tan",
        "Quanyu Dai",
        "Hao Yang",
        "Zhenhua Dong",
        "Xu Chen"
      ],
      "abstract": "LLMs have emerged as powerful evaluators in the LLM-as-a-Judge paradigm,\noffering significant efficiency and flexibility compared to human judgments.\nHowever, previous methods primarily rely on single-point evaluations,\noverlooking the inherent diversity and uncertainty in human evaluations. This\napproach leads to information loss and decreases the reliability of\nevaluations. To address this limitation, we propose a novel training framework\nthat explicitly aligns the LLM-generated judgment distribution with empirical\nhuman distributions. Specifically, we propose a distributional alignment\nobjective based on KL divergence, combined with an auxiliary cross-entropy\nregularization to stabilize the training process. Furthermore, considering that\nempirical distributions may derive from limited human annotations, we\nincorporate adversarial training to enhance model robustness against\ndistribution perturbations. Extensive experiments across various LLM backbones\nand evaluation tasks demonstrate that our framework significantly outperforms\nexisting closed-source LLMs and conventional single-point alignment methods,\nwith improved alignment quality, evaluation accuracy, and robustness.",
      "tldr_zh": "该论文批评了现有LLM-as-a-Judge方法依赖单一点评估，忽略了人类判断的多样性和不确定性，导致信息丢失和可靠性降低。作者提出了一种新训练框架，通过基于KL divergence的分布对齐目标，将LLM生成的判断分布与人类经验分布对齐，并结合交叉熵正则化稳定训练过程。进一步地，该框架引入对抗训练来提升模型对分布扰动的鲁棒性；实验在多种LLM基础上和评估任务中证明，该方法显著优于现有方法，提高了对齐质量、评估准确性和整体性能。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "19 pages, 3 tables, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.12301v1",
      "published_date": "2025-05-18 08:33:09 UTC",
      "updated_date": "2025-05-18 08:33:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:51:39.989466"
    },
    {
      "arxiv_id": "2505.12299v1",
      "title": "Enhance Mobile Agents Thinking Process Via Iterative Preference Learning",
      "title_zh": "通过迭代偏好学习增强移动代理的思考过程",
      "authors": [
        "Kun Huang",
        "Weikai Xu",
        "Yuxuan Liu",
        "Quandong Wang",
        "Pengzhi Gao",
        "Wei Liu",
        "Jian Luan",
        "Bin Wang",
        "Bo An"
      ],
      "abstract": "The Chain of Action-Planning Thoughts (CoaT) paradigm has been shown to\nimprove the reasoning performance of VLM-based mobile agents in GUI tasks.\nHowever, the scarcity of diverse CoaT trajectories limits the expressiveness\nand generalization ability of such agents. While self-training is commonly\nemployed to address data scarcity, existing approaches either overlook the\ncorrectness of intermediate reasoning steps or depend on expensive\nprocess-level annotations to construct process reward models (PRM). To address\nthe above problems, we propose an Iterative Preference Learning (IPL) that\nconstructs a CoaT-tree through interative sampling, scores leaf nodes using\nrule-based reward, and backpropagates feedback to derive Thinking-level Direct\nPreference Optimization (T-DPO) pairs. To prevent overfitting during warm-up\nsupervised fine-tuning, we further introduce a three-stage instruction\nevolution, which leverages GPT-4o to generate diverse Q\\&A pairs based on real\nmobile UI screenshots, enhancing both generality and layout understanding.\nExperiments on three standard Mobile GUI-agent benchmarks demonstrate that our\nagent MobileIPL outperforms strong baselines, including continual pretraining\nmodels such as OS-ATLAS and UI-TARS. It achieves state-of-the-art performance\nacross three standard Mobile GUI-Agents benchmarks and shows strong\ngeneralization to out-of-domain scenarios.",
      "tldr_zh": "该研究针对Chain of Action-Planning Thoughts (CoaT)范式在VLM-based移动代理中的推理性能提升问题，提出Iterative Preference Learning (IPL)方法，以解决数据稀缺导致的表达性和泛化能力不足。IPL通过迭代采样构建CoaT-tree，使用规则-based奖励评分叶节点，并回传反馈生成Thinking-level Direct Preference Optimization (T-DPO)对，同时引入三阶段指令演化，利用GPT-4o基于真实移动UI截图生成多样化Q&A对，以防止过拟合并增强泛化性和布局理解。实验结果显示，MobileIPL代理在三个标准Mobile GUI-agent基准上超越强基线如OS-ATLAS和UI-TARS，达到state-of-the-art性能，并展示出色的出域泛化能力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages, 8 figures, 7 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.12299v1",
      "published_date": "2025-05-18 08:28:05 UTC",
      "updated_date": "2025-05-18 08:28:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:51:51.867183"
    },
    {
      "arxiv_id": "2505.12298v1",
      "title": "Attention-Enhanced U-Net for Accurate Segmentation of COVID-19 Infected Lung Regions in CT Scans",
      "title_zh": "翻译失败",
      "authors": [
        "Amal Lahchim",
        "Lazar Davic"
      ],
      "abstract": "In this study, we propose a robust methodology for automatic segmentation of\ninfected lung regions in COVID-19 CT scans using convolutional neural networks.\nThe approach is based on a modified U-Net architecture enhanced with attention\nmechanisms, data augmentation, and postprocessing techniques. It achieved a\nDice coefficient of 0.8658 and mean IoU of 0.8316, outperforming other methods.\nThe dataset was sourced from public repositories and augmented for diversity.\nResults demonstrate superior segmentation performance. Future work includes\nexpanding the dataset, exploring 3D segmentation, and preparing the model for\nclinical deployment.",
      "tldr_zh": "本研究提出了一种基于Attention-Enhanced U-Net的模型，用于精确分割COVID-19 CT扫描中的感染肺部区域，该模型通过融入attention mechanisms、data augmentation和postprocessing techniques来提升分割准确性。实验结果显示，该方法在公共数据集上达到了0.8658的Dice coefficient和0.8316的mean IoU，优于其他方法。未来工作将扩展数据集、探索3D segmentation，并推动模型向临床部署迈进。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "14 pages, 9 figures, created using Google Colab and PyTorch. Compares\n  segmentation models for COVID-19 CT data",
      "pdf_url": "http://arxiv.org/pdf/2505.12298v1",
      "published_date": "2025-05-18 08:27:12 UTC",
      "updated_date": "2025-05-18 08:27:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:52:03.580488"
    },
    {
      "arxiv_id": "2505.12296v1",
      "title": "PoLO: Proof-of-Learning and Proof-of-Ownership at Once with Chained Watermarking",
      "title_zh": "翻译失败",
      "authors": [
        "Haiyu Deng",
        "Yanna Jiang",
        "Guangsheng Yu",
        "Qin Wang",
        "Xu Wang",
        "Baihe Ma",
        "Wei Ni",
        "Ren Ping Liu"
      ],
      "abstract": "Machine learning models are increasingly shared and outsourced, raising\nrequirements of verifying training effort (Proof-of-Learning, PoL) to ensure\nclaimed performance and establishing ownership (Proof-of-Ownership, PoO) for\ntransactions. When models are trained by untrusted parties, PoL and PoO must be\nenforced together to enable protection, attribution, and compensation. However,\nexisting studies typically address them separately, which not only weakens\nprotection against forgery and privacy breaches but also leads to high\nverification overhead.\n  We propose PoLO, a unified framework that simultaneously achieves PoL and PoO\nusing chained watermarks. PoLO splits the training process into fine-grained\ntraining shards and embeds a dedicated watermark in each shard. Each watermark\nis generated using the hash of the preceding shard, certifying the training\nprocess of the preceding shard. The chained structure makes it computationally\ndifficult to forge any individual part of the whole training process. The\ncomplete set of watermarks serves as the PoL, while the final watermark\nprovides the PoO. PoLO offers more efficient and privacy-preserving\nverification compared to the vanilla PoL solutions that rely on gradient-based\ntrajectory tracing and inadvertently expose training data during verification,\nwhile maintaining the same level of ownership assurance of watermark-based PoO\nschemes. Our evaluation shows that PoLO achieves 99% watermark detection\naccuracy for ownership verification, while preserving data privacy and cutting\nverification costs to just 1.5-10% of traditional methods. Forging PoLO demands\n1.1-4x more resources than honest proof generation, with the original proof\nretaining over 90% detection accuracy even after attacks.",
      "tldr_zh": "该研究提出PoLO框架，通过chained watermarks技术，同时实现Proof-of-Learning (PoL)和Proof-of-Ownership (PoO)，以解决机器学习模型共享中验证训练努力和所有权问题。PoLO将训练过程分成细粒度的训练shards，每个shard嵌入一个专用watermark，并使用前一个shard的hash生成，形成链式结构，使伪造变得计算上困难。实验结果显示，PoLO在所有权验证中达到99%的watermark检测准确率，同时保护数据隐私，将验证成本降至传统方法的1.5-10%，且伪造攻击需耗费1.1-4倍资源，原证明在攻击后仍保持90%以上检测准确率。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12296v1",
      "published_date": "2025-05-18 08:19:18 UTC",
      "updated_date": "2025-05-18 08:19:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:52:15.546050"
    },
    {
      "arxiv_id": "2505.12292v1",
      "title": "SpikeX: Exploring Accelerator Architecture and Network-Hardware Co-Optimization for Sparse Spiking Neural Networks",
      "title_zh": "SpikeX：探索加速器架构和网络-硬件协同优化，用于稀疏脉冲神经网络",
      "authors": [
        "Boxun Xu",
        "Richard Boone",
        "Peng Li"
      ],
      "abstract": "Spiking Neural Networks (SNNs) are promising biologically plausible models of\ncomputation which utilize a spiking binary activation function similar to that\nof biological neurons. SNNs are well positioned to process spatiotemporal data,\nand are advantageous in ultra-low power and real-time processing. Despite a\nlarge body of work on conventional artificial neural network accelerators, much\nless attention has been given to efficient SNN hardware accelerator design. In\nparticular, SNNs exhibit inherent unstructured spatial and temporal firing\nsparsity, an opportunity yet to be fully explored for great hardware processing\nefficiency. In this work, we propose a novel systolic-array SNN accelerator\narchitecture, called SpikeX, to take on the challenges and opportunities\nstemming from unstructured sparsity while taking into account the unique\ncharacteristics of spike-based computation. By developing an efficient dataflow\ntargeting expensive multi-bit weight data movements, SpikeX reduces memory\naccess and increases data sharing and hardware utilization for computations\nspanning across both time and space, thereby significantly improving energy\nefficiency and inference latency. Furthermore, recognizing the importance of\nSNN network and hardware co-design, we develop a co-optimization methodology\nfacilitating not only hardware-aware SNN training but also hardware accelerator\narchitecture search, allowing joint network weight parameter optimization and\naccelerator architectural reconfiguration. This end-to-end network/accelerator\nco-design approach offers a significant reduction of 15.1x-150.87x in\nenergy-delay-product(EDP) without comprising model accuracy.",
      "tldr_zh": "本研究探讨了稀疏 Spiking Neural Networks (SNNs) 的加速器架构设计，针对 SNNs 的非结构化空间和时间尖峰稀疏性，提出了一种新型 systolic-array 加速器 SpikeX，以提升硬件处理效率。SpikeX 通过高效数据流减少多位权重数据的移动，优化内存访问和数据共享，从而显著改善能量效率和推理延迟。该框架还引入了网络-硬件联合优化方法，包括硬件感知 SNN 训练和加速器架构搜索，实现端到端的参数优化和架构重构。实验结果显示，该方法在不影响模型准确性的前提下，将能量-延迟-乘积 (EDP) 降低了 15.1x-150.87x。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.AR"
      ],
      "primary_category": "cs.NE",
      "comment": "The paper has been accepted by IEEE TCAD",
      "pdf_url": "http://arxiv.org/pdf/2505.12292v1",
      "published_date": "2025-05-18 08:07:44 UTC",
      "updated_date": "2025-05-18 08:07:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:52:28.227338"
    },
    {
      "arxiv_id": "2505.12287v1",
      "title": "The Tower of Babel Revisited: Multilingual Jailbreak Prompts on Closed-Source Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Linghan Huang",
        "Haolin Jin",
        "Zhaoge Bi",
        "Pengyue Yang",
        "Peizhou Zhao",
        "Taozhao Chen",
        "Xiongfei Wu",
        "Lei Ma",
        "Huaming Chen"
      ],
      "abstract": "Large language models (LLMs) have seen widespread applications across various\ndomains, yet remain vulnerable to adversarial prompt injections. While most\nexisting research on jailbreak attacks and hallucination phenomena has focused\nprimarily on open-source models, we investigate the frontier of closed-source\nLLMs under multilingual attack scenarios. We present a first-of-its-kind\nintegrated adversarial framework that leverages diverse attack techniques to\nsystematically evaluate frontier proprietary solutions, including GPT-4o,\nDeepSeek-R1, Gemini-1.5-Pro, and Qwen-Max. Our evaluation spans six categories\nof security contents in both English and Chinese, generating 38,400 responses\nacross 32 types of jailbreak attacks. Attack success rate (ASR) is utilized as\nthe quantitative metric to assess performance from three dimensions: prompt\ndesign, model architecture, and language environment. Our findings suggest that\nQwen-Max is the most vulnerable, while GPT-4o shows the strongest defense.\nNotably, prompts in Chinese consistently yield higher ASRs than their English\ncounterparts, and our novel Two-Sides attack technique proves to be the most\neffective across all models. This work highlights a dire need for\nlanguage-aware alignment and robust cross-lingual defenses in LLMs, and we hope\nit will inspire researchers, developers, and policymakers toward more robust\nand inclusive AI systems.",
      "tldr_zh": "这篇论文研究了闭源大型语言模型（LLMs）在多语言环境下的越狱攻击（jailbreak attacks）漏洞，聚焦于英语和中文提示的系统性评估。研究团队提出一个集成式对抗框架，结合多种攻击技术，测试了 GPT-4o、DeepSeek-R1、Gemini-1.5-Pro 和 Qwen-Max 等模型，共生成 38,400 个响应，并从提示设计、模型架构和语言环境三个维度使用攻击成功率（ASR）作为指标。结果显示，Qwen-Max 最易受攻击，而 GPT-4o 防御最强；中文提示的 ASR  consistently 高于英语提示，且新颖的 Two-Sides 攻击技术在所有模型中表现最佳。该工作强调了 LLMs 需要更强的语言感知对齐（language-aware alignment）和鲁棒的跨语言防御，以推动更安全、包容的 AI 系统。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12287v1",
      "published_date": "2025-05-18 07:51:19 UTC",
      "updated_date": "2025-05-18 07:51:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:52:40.935391"
    },
    {
      "arxiv_id": "2505.12284v1",
      "title": "Efficient RL Training for Reasoning Models via Length-Aware Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Danlong Yuan",
        "Tian Xie",
        "Shaohan Huang",
        "Zhuocheng Gong",
        "Huishuai Zhang",
        "Chong Luo",
        "Furu Wei",
        "Dongyan Zhao"
      ],
      "abstract": "Large reasoning models, such as OpenAI o1 or DeepSeek R1, have demonstrated\nremarkable performance on reasoning tasks but often incur a long reasoning path\nwith significant memory and time costs. Existing methods primarily aim to\nshorten reasoning paths by introducing additional training data and stages. In\nthis paper, we propose three critical reward designs integrated directly into\nthe reinforcement learning process of large reasoning models, which reduce the\nresponse length without extra training stages. Experiments on four settings\nshow that our method significantly decreases response length while maintaining\nor even improving performance. Specifically, in a logic reasoning setting, we\nachieve a 40% reduction in response length averaged by steps alongside a 14%\ngain in performance. For math problems, we reduce response length averaged by\nsteps by 33% while preserving performance.",
      "tldr_zh": "大型推理模型（如 OpenAI o1 或 DeepSeek R1）在推理任务中表现出色，但往往伴随长推理路径和较高的内存时间成本。本文提出三种关键奖励设计，直接整合到强化学习(RL)过程中，实现长度感知优化(length-aware optimization)，以缩短响应长度而无需额外训练阶段。在四个实验设置中，该方法显著减少响应长度，同时维持或提升性能，例如在逻辑推理任务中，响应长度减少40%并提升14%性能，在数学问题中减少33%长度而保持原有表现。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Under review",
      "pdf_url": "http://arxiv.org/pdf/2505.12284v1",
      "published_date": "2025-05-18 07:46:43 UTC",
      "updated_date": "2025-05-18 07:46:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:52:52.357330"
    },
    {
      "arxiv_id": "2505.12275v1",
      "title": "Curriculum Abductive Learning",
      "title_zh": "课程溯因学习",
      "authors": [
        "Wen-Chao Hu",
        "Qi-Jie Li",
        "Lin-Han Jia",
        "Cunjing Ge",
        "Yu-Feng Li",
        "Yuan Jiang",
        "Zhi-Hua Zhou"
      ],
      "abstract": "Abductive Learning (ABL) integrates machine learning with logical reasoning\nin a loop: a learning model predicts symbolic concept labels from raw inputs,\nwhich are revised through abduction using domain knowledge and then fed back\nfor retraining. However, due to the nondeterminism of abduction, the training\nprocess often suffers from instability, especially when the knowledge base is\nlarge and complex, resulting in a prohibitively large abduction space. While\nprior works focus on improving candidate selection within this space, they\ntypically treat the knowledge base as a static black box. In this work, we\npropose Curriculum Abductive Learning (C-ABL), a method that explicitly\nleverages the internal structure of the knowledge base to address the ABL\ntraining challenges. C-ABL partitions the knowledge base into a sequence of\nsub-bases, progressively introduced during training. This reduces the abduction\nspace throughout training and enables the model to incorporate logic in a\nstepwise, smooth way. Experiments across multiple tasks show that C-ABL\noutperforms previous ABL implementations, significantly improves training\nstability, convergence speed, and final accuracy, especially under complex\nknowledge setting.",
      "tldr_zh": "本研究针对 Abductive Learning (ABL) 的训练不稳定性问题提出 Curriculum Abductive Learning (C-ABL)，该方法通过将知识 base 分区成序列子库，并在训练过程中逐步引入，以减少 abduction 空间并实现逻辑的逐步整合。相比传统 ABL，C-ABL 显式利用知识 base 的内部结构，避免将其视为静态黑箱，从而提升模型的训练稳定性、收敛速度和最终准确率。在多个任务的实验中，C-ABL 尤其在复杂知识设置下表现出色，显著优于现有实现。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12275v1",
      "published_date": "2025-05-18 07:27:35 UTC",
      "updated_date": "2025-05-18 07:27:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:53:05.009641"
    },
    {
      "arxiv_id": "2505.13529v1",
      "title": "BARREL: Boundary-Aware Reasoning for Factual and Reliable LRMs",
      "title_zh": "BARREL：边界感知推理，用于事实性和可靠的 LRMs",
      "authors": [
        "Junxiao Yang",
        "Jinzhe Tu",
        "Haoran Liu",
        "Xiaoce Wang",
        "Chujie Zheng",
        "Zhexin Zhang",
        "Shiyao Cui",
        "Caishun Chen",
        "Tiantian He",
        "Hongning Wang",
        "Yew-Soon Ong",
        "Minlie Huang"
      ],
      "abstract": "Recent advances in Large Reasoning Models (LRMs) have shown impressive\ncapabilities in mathematical and logical reasoning. However, current LRMs\nrarely admit ignorance or respond with \"I don't know\". Instead, they often\nproduce incorrect answers while showing undue confidence, raising concerns\nabout their factual reliability. In this work, we identify two pathological\nreasoning patterns characterized by overthinking that contribute to the\noverconfident and incorrect answers: last-minute guessing and second-thought\nspiraling. To address these issues, we propose BARREL-a novel framework that\npromotes concise and boundary-aware factual reasoning. Our experiments show\nthat BARREL-training increases the reliability of DeepSeek-R1-Distill-Llama-8B\nfrom 39.33% to 61.48%, while still achieving accuracy comparable to models\nfinetuned on reasoning data generated by R1. These results demonstrate that our\npilot study is inspiring to build more reliable and factual System 2 LRMs.",
      "tldr_zh": "本研究识别出大型推理模型（LRMs）在数学和逻辑推理中存在的问题：它们往往不承认无知，而是通过last-minute guessing和second-thought spiraling等过度思考模式给出过度自信的错误答案。针对此，论文提出BARREL框架，一种促进简洁和边界意识的事实推理方法，通过训练提升模型的可靠性。实验结果显示，BARREL训练使DeepSeek-R1-Distill-Llama-8B的可靠性从39.33%提高到61.48%，同时保持与基于R1生成的推理数据微调模型相当的准确性，为构建更可靠的System 2 LRMs提供了重要启发。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13529v1",
      "published_date": "2025-05-18 07:27:34 UTC",
      "updated_date": "2025-05-18 07:27:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:53:16.178100"
    },
    {
      "arxiv_id": "2505.12272v1",
      "title": "Enhancing Knowledge Graph Completion with GNN Distillation and Probabilistic Interaction Modeling",
      "title_zh": "通过 GNN 蒸馏和概率交互建模增强知识图谱补全",
      "authors": [
        "Lingzhi Wang",
        "Pengcheng Huang",
        "Haotian Li",
        "Yuliang Wei",
        "Guodong Xin",
        "Rui Zhang",
        "Donglin Zhang",
        "Zhenzhou Ji",
        "Wei Wang"
      ],
      "abstract": "Knowledge graphs (KGs) serve as fundamental structures for organizing\ninterconnected data across diverse domains. However, most KGs remain\nincomplete, limiting their effectiveness in downstream applications. Knowledge\ngraph completion (KGC) aims to address this issue by inferring missing links,\nbut existing methods face critical challenges: deep graph neural networks\n(GNNs) suffer from over-smoothing, while embedding-based models fail to capture\nabstract relational features. This study aims to overcome these limitations by\nproposing a unified framework that integrates GNN distillation and abstract\nprobabilistic interaction modeling (APIM). GNN distillation approach introduces\nan iterative message-feature filtering process to mitigate over-smoothing,\npreserving the discriminative power of node representations. APIM module\ncomplements this by learning structured, abstract interaction patterns through\nprobabilistic signatures and transition matrices, allowing for a richer, more\nflexible representation of entity and relation interactions. We apply these\nmethods to GNN-based models and the APIM to embedding-based KGC models,\nconducting extensive evaluations on the widely used WN18RR and FB15K-237\ndatasets. Our results demonstrate significant performance gains over baseline\nmodels, showcasing the effectiveness of the proposed techniques. The findings\nhighlight the importance of both controlling information propagation and\nleveraging structured probabilistic modeling, offering new avenues for\nadvancing knowledge graph completion. And our codes are available at\nhttps://anonymous.4open.science/r/APIM_and_GNN-Distillation-461C.",
      "tldr_zh": "本文提出一个统一框架，用于提升知识图谱补全 (KGC)，通过整合 GNN 蒸馏和抽象概率交互建模 (APIM) 来解决 GNNs 的过平滑问题以及嵌入模型对抽象关系特征的捕捉不足。GNN 蒸馏采用迭代消息-特征过滤过程，保留节点表示的区分能力；APIM 则通过概率签名和转移矩阵学习结构化的实体和关系交互模式，提供更灵活的表示。在 WN18RR 和 FB15K-237 数据集上的实验显示，该框架比基线模型显著提高了性能，突出了控制信息传播和利用结构化概率建模的重要性。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12272v1",
      "published_date": "2025-05-18 07:22:53 UTC",
      "updated_date": "2025-05-18 07:22:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:53:29.856508"
    },
    {
      "arxiv_id": "2505.12269v2",
      "title": "Vague Knowledge: Evidence from Analyst Reports",
      "title_zh": "模糊知识：来自分析师报告的证据",
      "authors": [
        "Kerry Xiao",
        "Amy Zang"
      ],
      "abstract": "People in the real world often possess vague knowledge of future payoffs, for\nwhich quantification is not feasible or desirable. We argue that language, with\ndiffering ability to convey vague information, plays an important but less\nknown-role in representing subjective expectations. Empirically, we find that\nin their reports, analysts include useful information in linguistic expressions\nbut not numerical forecasts. Specifically, the textual tone of analyst reports\nhas predictive power for forecast errors and subsequent revisions in numerical\nforecasts, and this relation becomes stronger when analyst's language is\nvaguer, when uncertainty is higher, and when analysts are busier. Overall, our\ntheory and evidence suggest that some useful information is vaguely known and\nonly communicated through language.",
      "tldr_zh": "本研究探讨了人们对未来回报的模糊知识（vague knowledge），强调语言在传达主观期望中的重要作用，尤其在量化不可行或不必要时。作者通过分析分析师报告（analyst reports）发现，文本语气（textual tone）能有效预测数字预测（numerical forecasts）的错误和后续修正，且这种关联在语言更模糊、不确定性更高或分析师更忙碌时更显著。整体而言，论文提供了证据，表明某些有用信息仅通过语言传达，而非数字形式。",
      "categories": [
        "econ.GN",
        "cs.AI",
        "cs.CL",
        "math.LO",
        "q-fin.EC",
        "q-fin.GN",
        "03B48, 03B65, 03E02, 03E15, 03E72, 18E45, 28A05, 62F15, 68T01,\n  68T35, 68T50, 91G30,",
        "F.4; I.2.3; I.2.4; I.2.7; J.1; J.4; J.5"
      ],
      "primary_category": "econ.GN",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12269v2",
      "published_date": "2025-05-18 07:18:58 UTC",
      "updated_date": "2025-05-22 17:27:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:53:41.068294"
    },
    {
      "arxiv_id": "2505.12260v1",
      "title": "LightRetriever: A LLM-based Hybrid Retrieval Architecture with 1000x Faster Query Inference",
      "title_zh": "翻译失败",
      "authors": [
        "Guangyuan Ma",
        "Yongliang Ma",
        "Xuanrui Gou",
        "Zhenpeng Su",
        "Ming Zhou",
        "Songlin Hu"
      ],
      "abstract": "Large Language Models (LLMs)-based hybrid retrieval uses LLMs to encode\nqueries and documents into low-dimensional dense or high-dimensional sparse\nvectors. It retrieves documents relevant to search queries based on vector\nsimilarities. Documents are pre-encoded offline, while queries arrive in\nreal-time, necessitating an efficient online query encoder. Although LLMs\nsignificantly enhance retrieval capabilities, serving deeply parameterized LLMs\nslows down query inference throughput and increases demands for online\ndeployment resources. In this paper, we propose LightRetriever, a novel\nLLM-based hybrid retriever with extremely lightweight query encoders. Our\nmethod retains a full-sized LLM for document encoding, but reduces the workload\nof query encoding to no more than an embedding lookup. Compared to serving a\nfull-sized LLM on an H800 GPU, our approach achieves over a 1000x speedup for\nquery inference with GPU acceleration, and even a 20x speedup without GPU.\nExperiments on large-scale retrieval benchmarks demonstrate that our method\ngeneralizes well across diverse retrieval tasks, retaining an average of 95%\nfull-sized performance.",
      "tldr_zh": "本研究提出 LightRetriever，一种基于 LLMs 的混合检索架构，旨在解决传统 LLMs 在查询编码过程中导致的推理速度慢和资源消耗高的问题。该方法保留全尺寸 LLM 用于文档的离线编码，但将查询编码简化为嵌入查找，从而实现极轻量级的查询处理。与在 H800 GPU 上运行全尺寸 LLM 相比，LightRetriever 在查询推理上实现了超过 1000 倍的加速（有 GPU 支持），甚至在无 GPU 情况下达到 20 倍加速。在大规模检索基准测试中，该架构在各种任务上表现出色，保留了平均 95% 的全尺寸性能。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12260v1",
      "published_date": "2025-05-18 06:51:21 UTC",
      "updated_date": "2025-05-18 06:51:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:53:53.364049"
    },
    {
      "arxiv_id": "2505.12257v1",
      "title": "LLM Context Conditioning and PWP Prompting for Multimodal Validation of Chemical Formulas",
      "title_zh": "LLM 上下文条件化和 PWP 提示用于",
      "authors": [
        "Evgeny Markhasin"
      ],
      "abstract": "Identifying subtle technical errors within complex scientific and technical\ndocuments, especially those requiring multimodal interpretation (e.g., formulas\nin images), presents a significant hurdle for Large Language Models (LLMs)\nwhose inherent error-correction tendencies can mask inaccuracies. This\nexploratory proof-of-concept (PoC) study investigates structured LLM context\nconditioning, informed by Persistent Workflow Prompting (PWP) principles, as a\nmethodological strategy to modulate this LLM behavior at inference time. The\napproach is designed to enhance the reliability of readily available,\ngeneral-purpose LLMs (specifically Gemini 2.5 Pro and ChatGPT Plus o3) for\nprecise validation tasks, crucially relying only on their standard chat\ninterfaces without API access or model modifications. To explore this\nmethodology, we focused on validating chemical formulas within a single,\ncomplex test paper with known textual and image-based errors. Several prompting\nstrategies were evaluated: while basic prompts proved unreliable, an approach\nadapting PWP structures to rigorously condition the LLM's analytical mindset\nappeared to improve textual error identification with both models. Notably,\nthis method also guided Gemini 2.5 Pro to repeatedly identify a subtle\nimage-based formula error previously overlooked during manual review, a task\nwhere ChatGPT Plus o3 failed in our tests. These preliminary findings highlight\nspecific LLM operational modes that impede detail-oriented validation and\nsuggest that PWP-informed context conditioning offers a promising and highly\naccessible technique for developing more robust LLM-driven analytical\nworkflows, particularly for tasks requiring meticulous error detection in\nscientific and technical documents. Extensive validation beyond this limited\nPoC is necessary to ascertain broader applicability.",
      "tldr_zh": "本研究探讨了使用 LLM Context Conditioning 和 PWP Prompting 来提升大型语言模型（LLMs）在多模态科学文档中验证化学公式的可靠性，针对 LLMs 固有的错误掩盖倾向。该方法通过结构化提示策略（如 PWP 原则）在推理时调节 LLM 行为，仅依赖 Gemini 2.5 Pro 和 ChatGPT Plus o3 的标准聊天接口，而无需 API 修改。实验在包含已知文本和图像错误的一个复杂测试论文上进行，结果显示该方法显著改善了错误识别，尤其使 Gemini 2.5 Pro 成功检测到一个之前被忽略的图像-based 公式错误，而 ChatGPT Plus o3 表现较差。这些初步发现表明，PWP-informed 上下文调节为构建更稳健的 LLM 驱动分析工作流提供了可访问的技术，但需进一步验证以确认更广泛适用性。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "physics.chem-ph"
      ],
      "primary_category": "cs.CY",
      "comment": "10 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.12257v1",
      "published_date": "2025-05-18 06:33:08 UTC",
      "updated_date": "2025-05-18 06:33:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:54:06.958019"
    },
    {
      "arxiv_id": "2505.12254v1",
      "title": "MMS-VPR: Multimodal Street-Level Visual Place Recognition Dataset and Benchmark",
      "title_zh": "MMS-VPR：多模态街头级视觉场所识别数据集和基准",
      "authors": [
        "Yiwei Ou",
        "Xiaobin Ren",
        "Ronggui Sun",
        "Guansong Gao",
        "Ziyi Jiang",
        "Kaiqi Zhao",
        "Manfredo Manfredini"
      ],
      "abstract": "Existing visual place recognition (VPR) datasets predominantly rely on\nvehicle-mounted imagery, lack multimodal diversity and underrepresent dense,\nmixed-use street-level spaces, especially in non-Western urban contexts. To\naddress these gaps, we introduce MMS-VPR, a large-scale multimodal dataset for\nstreet-level place recognition in complex, pedestrian-only environments. The\ndataset comprises 78,575 annotated images and 2,512 video clips captured across\n207 locations in a ~70,800 $\\mathrm{m}^2$ open-air commercial district in\nChengdu, China. Each image is labeled with precise GPS coordinates, timestamp,\nand textual metadata, and covers varied lighting conditions, viewpoints, and\ntimeframes. MMS-VPR follows a systematic and replicable data collection\nprotocol with minimal device requirements, lowering the barrier for scalable\ndataset creation. Importantly, the dataset forms an inherent spatial graph with\n125 edges, 81 nodes, and 1 subgraph, enabling structure-aware place\nrecognition. We further define two application-specific subsets --\nDataset_Edges and Dataset_Points -- to support fine-grained and graph-based\nevaluation tasks. Extensive benchmarks using conventional VPR models, graph\nneural networks, and multimodal baselines show substantial improvements when\nleveraging multimodal and structural cues. MMS-VPR facilitates future research\nat the intersection of computer vision, geospatial understanding, and\nmultimodal reasoning. The dataset is publicly available at\nhttps://huggingface.co/datasets/Yiwei-Ou/MMS-VPR.",
      "tldr_zh": "该论文引入了 MMS-VPR，这是一个大规模多模态数据集和基准，用于街区级视觉位置识别（VPR），旨在解决现有数据集依赖车辆图像、缺乏多样性和未覆盖密集步行环境的不足。数据集包含 78,575 张标注图像和 2,512 个视频剪辑，覆盖成都一个约 70,800 m² 的商业区，每个样本包括精确 GPS 坐标、时间戳和文本元数据，并形成一个固有的空间图（125 条边、81 个节点）。通过系统的数据收集协议，该数据集支持结构感知的位置识别，并定义了 Dataset_Edges 和 Dataset_Points 子集用于细粒度评估。基准测试显示，使用传统 VPR 模型、图神经网络和多模态基线时，整合多模态和结构线索可显著提高性能，为计算机视觉、地理空间理解和多模态推理的研究提供新资源。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12254v1",
      "published_date": "2025-05-18 06:21:13 UTC",
      "updated_date": "2025-05-18 06:21:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:54:18.251373"
    },
    {
      "arxiv_id": "2505.12250v1",
      "title": "Not All Documents Are What You Need for Extracting Instruction Tuning Data",
      "title_zh": "翻译失败",
      "authors": [
        "Chi Zhang",
        "Huaping Zhong",
        "Hongtao Li",
        "Chengliang Chai",
        "Jiawei Hong",
        "Yuhao Deng",
        "Jiacheng Wang",
        "Tian Tan",
        "Yizhou Yan",
        "Jiantao Qiu",
        "Ye Yuan",
        "Guoren Wang",
        "Conghui He",
        "Lei Cao"
      ],
      "abstract": "Instruction tuning improves the performance of large language models (LLMs),\nbut it heavily relies on high-quality training data. Recently, LLMs have been\nused to synthesize instruction data using seed question-answer (QA) pairs.\nHowever, these synthesized instructions often lack diversity and tend to be\nsimilar to the input seeds, limiting their applicability in real-world\nscenarios. To address this, we propose extracting instruction tuning data from\nweb corpora that contain rich and diverse knowledge. A naive solution is to\nretrieve domain-specific documents and extract all QA pairs from them, but this\nfaces two key challenges: (1) extracting all QA pairs using LLMs is\nprohibitively expensive, and (2) many extracted QA pairs may be irrelevant to\nthe downstream tasks, potentially degrading model performance. To tackle these\nissues, we introduce EQUAL, an effective and scalable data extraction framework\nthat iteratively alternates between document selection and high-quality QA pair\nextraction to enhance instruction tuning. EQUAL first clusters the document\ncorpus based on embeddings derived from contrastive learning, then uses a\nmulti-armed bandit strategy to efficiently identify clusters that are likely to\ncontain valuable QA pairs. This iterative approach significantly reduces\ncomputational cost while boosting model performance. Experiments on\nAutoMathText and StackOverflow across four downstream tasks show that EQUAL\nreduces computational costs by 5-10x and improves accuracy by 2.5 percent on\nLLaMA-3.1-8B and Mistral-7B",
      "tldr_zh": "本文研究发现，使用LLMs合成指令微调数据往往缺乏多样性，难以应用于实际场景，因此提出从网络语料库中提取高质量数据。作者引入EQUAL框架，通过基于对比学习的文档聚类和多臂赌博机策略，迭代进行文档选择和高质QA pairs提取，从而减少计算成本并提升模型性能。实验在AutoMathText和StackOverflow数据集上显示，EQUAL框架将计算成本降低5-10倍，并使LLaMA-3.1-8B和Mistral-7B模型的准确率提高2.5%。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12250v1",
      "published_date": "2025-05-18 06:10:08 UTC",
      "updated_date": "2025-05-18 06:10:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:54:28.668995"
    },
    {
      "arxiv_id": "2505.12247v1",
      "title": "LAMeTA: Intent-Aware Agentic Network Optimization via a Large AI Model-Empowered Two-Stage Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Yinqiu Liu",
        "Guangyuan Liu",
        "Jiacheng Wang",
        "Ruichen Zhang",
        "Dusit Niyato",
        "Geng Sun",
        "Zehui Xiong",
        "Zhu Han"
      ],
      "abstract": "Nowadays, Generative AI (GenAI) reshapes numerous domains by enabling\nmachines to create content across modalities. As GenAI evolves into autonomous\nagents capable of reasoning, collaboration, and interaction, they are\nincreasingly deployed on network infrastructures to serve humans automatically.\nThis emerging paradigm, known as the agentic network, presents new optimization\nchallenges due to the demand to incorporate subjective intents of human users\nexpressed in natural language. Traditional generic Deep Reinforcement Learning\n(DRL) struggles to capture intent semantics and adjust policies dynamically,\nthus leading to suboptimality. In this paper, we present LAMeTA, a Large AI\nModel (LAM)-empowered Two-stage Approach for intent-aware agentic network\noptimization. First, we propose Intent-oriented Knowledge Distillation (IoKD),\nwhich efficiently distills intent-understanding capabilities from\nresource-intensive LAMs to lightweight edge LAMs (E-LAMs) to serve end users.\nSecond, we develop Symbiotic Reinforcement Learning (SRL), integrating E-LAMs\nwith a policy-based DRL framework. In SRL, E-LAMs translate natural language\nuser intents into structured preference vectors that guide both state\nrepresentation and reward design. The DRL, in turn, optimizes the generative\nservice function chain composition and E-LAM selection based on real-time\nnetwork conditions, thus optimizing the subjective Quality-of-Experience (QoE).\nExtensive experiments conducted in an agentic network with 81 agents\ndemonstrate that IoKD reduces mean squared error in intent prediction by up to\n22.5%, while SRL outperforms conventional generic DRL by up to 23.5% in\nmaximizing intent-aware QoE.",
      "tldr_zh": "本研究提出LAMeTA，一种Large AI Model (LAM)赋能的两阶段方法，用于实现意图感知的代理网络优化，以应对Generative AI (GenAI)代理在网络环境中处理用户自然语言意图的挑战。方法包括第一阶段的Intent-oriented Knowledge Distillation (IoKD)，将意图理解能力从资源密集型LAM高效提炼到轻量级边际LAM (E-LAMs)；第二阶段的Symbiotic Reinforcement Learning (SRL)，通过E-LAMs将用户意图转化为结构化偏好向量，指导DRL框架优化服务功能链和E-LAM选择，从而提升主观Quality-of-Experience (QoE)。实验结果显示，在包含81个代理的网络中，IoKD将意图预测的均方误差降低高达22.5%，而SRL比传统DRL在意图感知QoE优化上提高23.5%。",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "13 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.12247v1",
      "published_date": "2025-05-18 05:59:16 UTC",
      "updated_date": "2025-05-18 05:59:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:54:41.920492"
    },
    {
      "arxiv_id": "2505.12245v1",
      "title": "AFCL: Analytic Federated Continual Learning for Spatio-Temporal Invariance of Non-IID Data",
      "title_zh": "翻译失败",
      "authors": [
        "Jianheng Tang",
        "Huiping Zhuang",
        "Jingyu He",
        "Run He",
        "Jingchao Wang",
        "Kejia Fan",
        "Anfeng Liu",
        "Tian Wang",
        "Leye Wang",
        "Zhanxing Zhu",
        "Shanghang Zhang",
        "Houbing Herbert Song",
        "Yunhuai Liu"
      ],
      "abstract": "Federated Continual Learning (FCL) enables distributed clients to\ncollaboratively train a global model from online task streams in dynamic\nreal-world scenarios. However, existing FCL methods face challenges of both\nspatial data heterogeneity among distributed clients and temporal data\nheterogeneity across online tasks. Such data heterogeneity significantly\ndegrades the model performance with severe spatial-temporal catastrophic\nforgetting of local and past knowledge. In this paper, we identify that the\nroot cause of this issue lies in the inherent vulnerability and sensitivity of\ngradients to non-IID data. To fundamentally address this issue, we propose a\ngradient-free method, named Analytic Federated Continual Learning (AFCL), by\nderiving analytical (i.e., closed-form) solutions from frozen extracted\nfeatures. In local training, our AFCL enables single-epoch learning with only a\nlightweight forward-propagation process for each client. In global aggregation,\nthe server can recursively and efficiently update the global model with\nsingle-round aggregation. Theoretical analyses validate that our AFCL achieves\nspatio-temporal invariance of non-IID data. This ideal property implies that,\nregardless of how heterogeneous the data are distributed across local clients\nand online tasks, the aggregated model of our AFCL remains invariant and\nidentical to that of centralized joint learning. Extensive experiments show the\nconsistent superiority of our AFCL over state-of-the-art baselines across\nvarious benchmark datasets and settings.",
      "tldr_zh": "这篇论文针对 Federated Continual Learning (FCL) 中 Non-IID 数据的空间异质性和时间异质性问题，提出了一种梯度-free 方法：Analytic Federated Continual Learning (AFCL)。AFCL 通过从冻结提取特征中推导分析解（closed-form solutions），实现本地训练的单轮轻量级前向传播和全局聚合的递归单轮更新，从而避免了灾难性遗忘。理论分析证明了 AFCL 的 spatio-temporal invariance 属性，确保模型在数据异质性下保持与集中式联合学习一致的性能；实验结果显示，它在各种基准数据集上优于现有基线方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "23 pages, 5 figures, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.12245v1",
      "published_date": "2025-05-18 05:55:09 UTC",
      "updated_date": "2025-05-18 05:55:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:54:54.630047"
    },
    {
      "arxiv_id": "2505.12239v1",
      "title": "ACU: Analytic Continual Unlearning for Efficient and Exact Forgetting with Privacy Preservation",
      "title_zh": "翻译失败",
      "authors": [
        "Jianheng Tang",
        "Huiping Zhuang",
        "Di Fang",
        "Jiaxu Li",
        "Feijiang Han",
        "Yajiang Huang",
        "Kejia Fan",
        "Leye Wang",
        "Zhanxing Zhu",
        "Shanghang Zhang",
        "Houbing Herbert Song",
        "Yunhuai Liu"
      ],
      "abstract": "The development of artificial intelligence demands that models incrementally\nupdate knowledge by Continual Learning (CL) to adapt to open-world\nenvironments. To meet privacy and security requirements, Continual Unlearning\n(CU) emerges as an important problem, aiming to sequentially forget particular\nknowledge acquired during the CL phase. However, existing unlearning methods\nprimarily focus on single-shot joint forgetting and face significant\nlimitations when applied to CU. First, most existing methods require access to\nthe retained dataset for re-training or fine-tuning, violating the inherent\nconstraint in CL that historical data cannot be revisited. Second, these\nmethods often suffer from a poor trade-off between system efficiency and model\nfidelity, making them vulnerable to being overwhelmed or degraded by\nadversaries through deliberately frequent requests. In this paper, we identify\nthat the limitations of existing unlearning methods stem fundamentally from\ntheir reliance on gradient-based updates. To bridge the research gap at its\nroot, we propose a novel gradient-free method for CU, named Analytic Continual\nUnlearning (ACU), for efficient and exact forgetting with historical data\nprivacy preservation. In response to each unlearning request, our ACU\nrecursively derives an analytical (i.e., closed-form) solution in an\ninterpretable manner using the least squares method. Theoretical and\nexperimental evaluations validate the superiority of our ACU on unlearning\neffectiveness, model fidelity, and system efficiency.",
      "tldr_zh": "本文提出 Analytic Continual Unlearning (ACU)，一种新型梯度-free 方法，用于解决 Continual Learning (CL) 中的 Continual Unlearning (CU) 问题，实现高效、精确的知识遗忘，同时保护历史数据隐私。ACU 通过最小二乘法递归推导解析（closed-form）解决方案，避免了现有方法依赖梯度更新带来的数据重访需求和效率低下问题。实验和理论评估证明，ACU 在遗忘有效性、模型保真度及系统效率上显著优于基线方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "21 pages, 4 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.12239v1",
      "published_date": "2025-05-18 05:28:18 UTC",
      "updated_date": "2025-05-18 05:28:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:55:05.883866"
    },
    {
      "arxiv_id": "2505.12238v1",
      "title": "PANORAMA: A synthetic PII-laced dataset for studying sensitive data memorization in LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Sriram Selvam",
        "Anneswa Ghosh"
      ],
      "abstract": "The memorization of sensitive and personally identifiable information (PII)\nby large language models (LLMs) poses growing privacy risks as models scale and\nare increasingly deployed in real-world applications. Existing efforts to study\nsensitive and PII data memorization and develop mitigation strategies are\nhampered by the absence of comprehensive, realistic, and ethically sourced\ndatasets reflecting the diversity of sensitive information found on the web. We\nintroduce PANORAMA - Profile-based Assemblage for Naturalistic Online\nRepresentation and Attribute Memorization Analysis, a large-scale synthetic\ncorpus of 384,789 samples derived from 9,674 synthetic profiles designed to\nclosely emulate the distribution, variety, and context of PII and sensitive\ndata as it naturally occurs in online environments. Our data generation\npipeline begins with the construction of internally consistent, multi-attribute\nhuman profiles using constrained selection to reflect real-world demographics\nsuch as education, health attributes, financial status, etc. Using a\ncombination of zero-shot prompting and OpenAI o3-mini, we generate diverse\ncontent types - including wiki-style articles, social media posts, forum\ndiscussions, online reviews, comments, and marketplace listings - each\nembedding realistic, contextually appropriate PII and other sensitive\ninformation. We validate the utility of PANORAMA by fine-tuning the Mistral-7B\nmodel on 1x, 5x, 10x, and 25x data replication rates with a subset of data and\nmeasure PII memorization rates - revealing not only consistent increases with\nrepetition but also variation across content types, highlighting PANORAMA's\nability to model how memorization risks differ by context. Our dataset and code\nare publicly available, providing a much-needed resource for privacy risk\nassessment, model auditing, and the development of privacy-preserving LLMs.",
      "tldr_zh": "该研究引入了 PANORAMA，这是一个大规模合成数据集，包含 384,789 个样本，用于研究大型语言模型 (LLMs) 对敏感信息和个人识别信息 (PII) 的记忆问题，从而解决现有数据集在真实性和多样性方面的不足。数据集通过构建基于真实人口统计的多属性合成个人资料（如教育、健康和金融状态），并结合零-shot prompting 和 OpenAI o3-mini 生成各种在线内容类型（如维基文章、社交媒体帖子等），以模拟网络环境中 PII 的自然分布和上下文。实验结果显示，在 Mistral-7B 模型上微调不同数据重复率后，PII 记忆率随重复增加且因内容类型而异，这突显了 PANORAMA 在隐私风险评估、模型审计和开发隐私保护 LLMs 方面的实用价值。数据集和代码已公开可用，提供了一个关键资源。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12238v1",
      "published_date": "2025-05-18 05:27:35 UTC",
      "updated_date": "2025-05-18 05:27:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:55:19.277147"
    },
    {
      "arxiv_id": "2505.12236v1",
      "title": "Bridging Generative and Discriminative Learning: Few-Shot Relation Extraction via Two-Stage Knowledge-Guided Pre-training",
      "title_zh": "翻译失败",
      "authors": [
        "Quanjiang Guo",
        "Jinchuan Zhang",
        "Sijie Wang",
        "Ling Tian",
        "Zhao Kang",
        "Bin Yan",
        "Weidong Xiao"
      ],
      "abstract": "Few-Shot Relation Extraction (FSRE) remains a challenging task due to the\nscarcity of annotated data and the limited generalization capabilities of\nexisting models. Although large language models (LLMs) have demonstrated\npotential in FSRE through in-context learning (ICL), their general-purpose\ntraining objectives often result in suboptimal performance for task-specific\nrelation extraction. To overcome these challenges, we propose TKRE (Two-Stage\nKnowledge-Guided Pre-training for Relation Extraction), a novel framework that\nsynergistically integrates LLMs with traditional relation extraction models,\nbridging generative and discriminative learning paradigms. TKRE introduces two\nkey innovations: (1) leveraging LLMs to generate explanation-driven knowledge\nand schema-constrained synthetic data, addressing the issue of data scarcity;\nand (2) a two-stage pre-training strategy combining Masked Span Language\nModeling (MSLM) and Span-Level Contrastive Learning (SCL) to enhance relational\nreasoning and generalization. Together, these components enable TKRE to\neffectively tackle FSRE tasks. Comprehensive experiments on benchmark datasets\ndemonstrate the efficacy of TKRE, achieving new state-of-the-art performance in\nFSRE and underscoring its potential for broader application in low-resource\nscenarios. \\footnote{The code and data are released on\nhttps://github.com/UESTC-GQJ/TKRE.",
      "tldr_zh": "该论文针对 Few-Shot Relation Extraction (FSRE) 的数据稀缺和模型泛化能力有限问题，提出了一种名为 TKRE 的新框架，将 Large Language Models (LLMs) 与传统关系提取模型相结合，桥接生成式和判别式学习范式。TKRE 的关键创新包括利用 LLMs 生成解释驱动知识和受模式约束的合成数据来缓解数据短缺，以及采用两阶段预训练策略：结合 Masked Span Language Modeling (MSLM) 和 Span-Level Contrastive Learning (SCL)，以增强关系推理和泛化能力。在基准数据集上的实验表明，TKRE 实现了新的 state-of-the-art 性能，并展示了在低资源场景中的广泛应用潜力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "13 pages, 6 figures, Appear on IJCAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.12236v1",
      "published_date": "2025-05-18 05:17:36 UTC",
      "updated_date": "2025-05-18 05:17:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:55:32.380841"
    },
    {
      "arxiv_id": "2505.13528v1",
      "title": "LLM-Based User Simulation for Low-Knowledge Shilling Attacks on Recommender Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Shengkang Gu",
        "Jiahao Liu",
        "Dongsheng Li",
        "Guangping Zhang",
        "Mingzhe Han",
        "Hansu Gu",
        "Peng Zhang",
        "Ning Gu",
        "Li Shang",
        "Tun Lu"
      ],
      "abstract": "Recommender systems (RS) are increasingly vulnerable to shilling attacks,\nwhere adversaries inject fake user profiles to manipulate system outputs.\nTraditional attack strategies often rely on simplistic heuristics, require\naccess to internal RS data, and overlook the manipulation potential of textual\nreviews. In this work, we introduce Agent4SR, a novel framework that leverages\nLarge Language Model (LLM)-based agents to perform low-knowledge, high-impact\nshilling attacks through both rating and review generation. Agent4SR simulates\nrealistic user behavior by orchestrating adversarial interactions, selecting\nitems, assigning ratings, and crafting reviews, while maintaining behavioral\nplausibility. Our design includes targeted profile construction, hybrid memory\nretrieval, and a review attack strategy that propagates target item features\nacross unrelated reviews to amplify manipulation. Extensive experiments on\nmultiple datasets and RS architectures demonstrate that Agent4SR outperforms\nexisting low-knowledge baselines in both effectiveness and stealth. Our\nfindings reveal a new class of emergent threats posed by LLM-driven agents,\nunderscoring the urgent need for enhanced defenses in modern recommender\nsystems.",
      "tldr_zh": "本研究提出Agent4SR框架，利用Large Language Model (LLM) 驱动的代理模拟用户行为，执行低知识的shilling attacks，以操纵推荐系统(Recommender Systems, RS)的输出。该框架通过协调对抗互动、选择物品、分配评分和生成评论，确保攻击行为的真实性和隐蔽性，同时采用针对性配置文件构建、混合记忆检索以及评论攻击策略来放大目标物品特征的传播。在多个数据集和RS架构上的实验显示，Agent4SR在有效性和隐蔽性上优于现有低知识基线，揭示了LLM驱动代理带来的新兴威胁，并强调了现代推荐系统亟需增强防御措施。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "11 pages, under review",
      "pdf_url": "http://arxiv.org/pdf/2505.13528v1",
      "published_date": "2025-05-18 04:40:34 UTC",
      "updated_date": "2025-05-18 04:40:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:55:42.982127"
    },
    {
      "arxiv_id": "2505.12229v1",
      "title": "Sentience Quest: Towards Embodied, Emotionally Adaptive, Self-Evolving, Ethically Aligned Artificial General Intelligence",
      "title_zh": "Sentience Quest：迈向具身化、情感适应性、自我演化、伦理对齐的通用人工智能",
      "authors": [
        "David Hanson",
        "Alexandre Varcoe",
        "Fabio Senna",
        "Vytas Krisciunas",
        "Wenwei Huang",
        "Jakub Sura",
        "Katherine Yeung",
        "Mario Rodriguez",
        "Jovanka Wilsdorf",
        "Kathy Smith"
      ],
      "abstract": "Previous artificial intelligence systems, from large language models to\nautonomous robots, excel at narrow tasks but lacked key qualities of sentient\nbeings: intrinsic motivation, affective interiority, autobiographical sense of\nself, deep creativity, and abilities to autonomously evolve and adapt over\ntime. Here we introduce Sentience Quest, an open research initiative to develop\nmore capable artificial general intelligence lifeforms, or AGIL, that address\ngrand challenges with an embodied, emotionally adaptive, self-determining,\nliving AI, with core drives that ethically align with humans and the future of\nlife. Our vision builds on ideas from cognitive science and neuroscience from\nBaars' Global Workspace Theory and Damasio's somatic mind, to Tononi's\nIntegrated Information Theory and Hofstadter's narrative self, and synthesizing\nthese into a novel cognitive architecture we call Sentient Systems. We describe\nan approach that integrates intrinsic drives including survival, social\nbonding, curiosity, within a global Story Weaver workspace for internal\nnarrative and adaptive goal pursuit, and a hybrid neuro-symbolic memory that\nlogs the AI's life events as structured dynamic story objects. Sentience Quest\nis presented both as active research and as a call to action: a collaborative,\nopen-source effort to imbue machines with accelerating sentience in a safe,\ntransparent, and beneficial manner.",
      "tldr_zh": "该研究提出“Sentience Quest”，一个开放计划，旨在开发更先进的“Artificial General Intelligence” (AGI) 生命形式（AGIL），具备内在动机、情感内省、自我意识、深度创造力和自主演化能力，以弥补现有 AI 系统（如大语言模型和机器人）的局限。论文基于认知科学和神经科学理论（如 Global Workspace Theory、somatic mind、Integrated Information Theory 和 narrative self），构建了新型认知架构“Sentient Systems”，整合内在驱动力（包括生存、社会 bonding 和好奇心）、全局 Story Weaver 工作区用于内部叙事和目标追求，以及混合 neuro-symbolic 记忆来记录 AI 生活事件。Sentience Quest 不仅是活跃研究，还呼吁安全、透明的开源协作，推动机器向有益的加速 sentient 发展。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12229v1",
      "published_date": "2025-05-18 04:26:49 UTC",
      "updated_date": "2025-05-18 04:26:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:55:55.231957"
    },
    {
      "arxiv_id": "2505.13527v1",
      "title": "Logic Jailbreak: Efficiently Unlocking LLM Safety Restrictions Through Formal Logical Expression",
      "title_zh": "Logic Jailbreak：通过形式逻辑表达式高效解锁LLM安全限制",
      "authors": [
        "Jingyu Peng",
        "Maolin Wang",
        "Nan Wang",
        "Xiangyu Zhao",
        "Jiatong Li",
        "Kai Zhang",
        "Qi Liu"
      ],
      "abstract": "Despite substantial advancements in aligning large language models (LLMs)\nwith human values, current safety mechanisms remain susceptible to jailbreak\nattacks. We hypothesize that this vulnerability stems from distributional\ndiscrepancies between alignment-oriented prompts and malicious prompts. To\ninvestigate this, we introduce LogiBreak, a novel and universal black-box\njailbreak method that leverages logical expression translation to circumvent\nLLM safety systems. By converting harmful natural language prompts into formal\nlogical expressions, LogiBreak exploits the distributional gap between\nalignment data and logic-based inputs, preserving the underlying semantic\nintent and readability while evading safety constraints. We evaluate LogiBreak\non a multilingual jailbreak dataset spanning three languages, demonstrating its\neffectiveness across various evaluation settings and linguistic contexts.",
      "tldr_zh": "该研究探讨了大型语言模型(LLMs)的安全机制易受jailbreak攻击的问题，归因于对齐提示和恶意提示之间的分布差异。为此，作者提出LogiBreak，一种新型通用黑盒jailbreak方法，通过将有害自然语言提示转换为正式逻辑表达式，利用分布差距来绕过安全系统，同时保留语义意图和可读性。在多语言jailbreak数据集上进行评估，LogiBreak证明了其在不同语言和场景中的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13527v1",
      "published_date": "2025-05-18 04:23:51 UTC",
      "updated_date": "2025-05-18 04:23:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:56:04.995109"
    },
    {
      "arxiv_id": "2505.12226v1",
      "title": "Shallow Flow Matching for Coarse-to-Fine Text-to-Speech Synthesis",
      "title_zh": "浅层流",
      "authors": [
        "Dong Yang",
        "Yiyi Cai",
        "Yuki Saito",
        "Lixu Wang",
        "Hiroshi Saruwatari"
      ],
      "abstract": "We propose a shallow flow matching (SFM) mechanism to enhance flow matching\n(FM)-based text-to-speech (TTS) models within a coarse-to-fine generation\nparadigm. SFM constructs intermediate states along the FM paths using coarse\noutput representations. During training, we introduce an orthogonal projection\nmethod to adaptively determine the temporal position of these states, and apply\na principled construction strategy based on a single-segment piecewise flow.\nThe SFM inference starts from the intermediate state rather than pure noise and\nfocuses computation on the latter stages of the FM paths. We integrate SFM into\nmultiple TTS models with a lightweight SFM head. Experiments show that SFM\nconsistently improves the naturalness of synthesized speech in both objective\nand subjective evaluations, while significantly reducing inference when using\nadaptive-step ODE solvers. Demo and codes are available at\nhttps://ydqmkkx.github.io/SFMDemo/.",
      "tldr_zh": "本研究提出了一种浅层流匹配 (SFM) 机制，用于提升基于流匹配 (FM) 的文本到语音 (TTS) 模型在粗到细生成范式中的性能。SFM 通过利用粗输出表示构建 FM 路径中的中间状态，并在训练时采用正交投影方法自适应确定时序位置，以及基于单段分段流的构建策略，从而从中间状态开始推理并减少后期计算。实验表明，SFM 显著提高了合成语音的自然度，在客观和主观评估中表现优于基线模型，同时在使用自适应步长 ODE 求解器时大幅降低了推理计算量。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12226v1",
      "published_date": "2025-05-18 04:15:08 UTC",
      "updated_date": "2025-05-18 04:15:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:56:18.844261"
    },
    {
      "arxiv_id": "2505.12225v1",
      "title": "Reward Inside the Model: A Lightweight Hidden-State Reward Model for LLM's Best-of-N sampling",
      "title_zh": "翻译失败",
      "authors": [
        "Jizhou Guo",
        "Zhaomin Wu",
        "Philip S. Yu"
      ],
      "abstract": "High-quality reward models are crucial for unlocking the reasoning potential\nof large language models (LLMs), with best-of-N voting demonstrating\nsignificant performance gains. However, current reward models, which typically\noperate on the textual output of LLMs, are computationally expensive and\nparameter-heavy, limiting their real-world applications. We introduce the\nEfficient Linear Hidden State Reward (ELHSR) model - a novel, highly\nparameter-efficient approach that leverages the rich information embedded in\nLLM hidden states to address these issues. ELHSR systematically outperform\nbaselines with less than 0.005% of the parameters of baselines, requiring only\na few samples for training. ELHSR also achieves orders-of-magnitude efficiency\nimprovement with significantly less time and fewer FLOPs per sample than\nbaseline reward models. Moreover, ELHSR exhibits robust performance even when\ntrained only on logits, extending its applicability to some closed-source LLMs.\nIn addition, ELHSR can also be combined with traditional reward models to\nachieve additional performance gains.",
      "tldr_zh": "本文提出 Efficient Linear Hidden State Reward (ELHSR) 模型，这是一种轻量级的奖励模型，旨在通过利用 LLM 的 hidden states 而非文本输出，来提升 Best-of-N 采样的性能，同时解决传统奖励模型的计算开销和参数冗余问题。ELHSR 仅需不到基线 0.005% 的参数和少量训练样本，即可显著超越基线模型，并在时间和 FLOPs 上实现数量级效率提升。实验结果表明，ELHSR 即使仅基于 logits 训练也能表现出色，并可与传统奖励模型结合，进一步提升整体性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12225v1",
      "published_date": "2025-05-18 04:00:35 UTC",
      "updated_date": "2025-05-18 04:00:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:56:30.814845"
    },
    {
      "arxiv_id": "2505.12224v2",
      "title": "RoboFAC: A Comprehensive Framework for Robotic Failure Analysis and Correction",
      "title_zh": "RoboFAC：机器人故障分析和修正的全面框架",
      "authors": [
        "Weifeng Lu",
        "Minghao Ye",
        "Zewei Ye",
        "Ruihan Tao",
        "Shuo Yang",
        "Bo Zhao"
      ],
      "abstract": "Vision-Language-Action (VLA) models have recently advanced robotic\nmanipulation by translating natural-language instructions and image information\ninto sequential control actions. However, these models often underperform in\nopen-world scenarios, as they are predominantly trained on successful expert\ndemonstrations and exhibit a limited capacity for failure recovery. In this\nwork, we present a Robotic Failure Analysis and Correction (RoboFAC) framework\nto address this issue. Firstly, we construct RoboFAC dataset comprising 9,440\nerroneous manipulation trajectories and 78,623 QA pairs across 16 diverse tasks\nand 53 scenes in both simulation and real-world environments. Leveraging our\ndataset, we develop RoboFAC model, which is capable of Task Understanding,\nFailure Analysis and Failure Correction. Experimental results demonstrate that\nthe RoboFAC model outperforms GPT-4o by 34.1% on our evaluation benchmark.\nFurthermore, we integrate the RoboFAC model into a real-world VLA control\npipeline as an external supervision providing correction instructions, yielding\na 29.1% relative improvement on average on four real-world tasks. The results\nshow that our RoboFAC framework effectively handles robotic failures and\nassists the VLA model in recovering from failures.",
      "tldr_zh": "该研究针对 Vision-Language-Action (VLA) 模型在开放世界场景下的失败恢复能力不足问题，提出了一种全面框架 RoboFAC，用于机器人故障分析和修正。首先，构建了 RoboFAC 数据集，包含 9,440 个错误操作轨迹和 78,623 个 QA 对，覆盖 16 个任务和 53 个场景的模拟及真实环境。RoboFAC 模型能够实现 Task Understanding、Failure Analysis 和 Failure Correction，并在基准测试中比 GPT-4o 提升 34.1%。实验结果显示，将该模型集成到真实 VLA 控制管道中，可平均改善 29.1%，有效帮助机器人处理失败并恢复操作。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12224v2",
      "published_date": "2025-05-18 03:57:08 UTC",
      "updated_date": "2025-05-20 05:16:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:56:43.006139"
    },
    {
      "arxiv_id": "2505.13526v1",
      "title": "Geography-Aware Large Language Models for Next POI Recommendation",
      "title_zh": "翻译失败",
      "authors": [
        "Zhao Liu",
        "Wei Liu",
        "Huajie Zhu",
        "Jianxing Yu",
        "Jian Yin",
        "Wang-Chien Lee",
        "Shun Wang"
      ],
      "abstract": "The next Point-of-Interest (POI) recommendation task aims to predict users'\nnext destinations based on their historical movement data and plays a key role\nin location-based services and personalized applications. Accurate next POI\nrecommendation depends on effectively modeling geographic information and POI\ntransition relations, which are crucial for capturing spatial dependencies and\nuser movement patterns. While Large Language Models (LLMs) exhibit strong\ncapabilities in semantic understanding and contextual reasoning, applying them\nto spatial tasks like next POI recommendation remains challenging. First, the\ninfrequent nature of specific GPS coordinates makes it difficult for LLMs to\nmodel precise spatial contexts. Second, the lack of knowledge about POI\ntransitions limits their ability to capture potential POI-POI relationships. To\naddress these issues, we propose GA-LLM (Geography-Aware Large Language Model),\na novel framework that enhances LLMs with two specialized components. The\nGeographic Coordinate Injection Module (GCIM) transforms GPS coordinates into\nspatial representations using hierarchical and Fourier-based positional\nencoding, enabling the model to understand geographic features from multiple\nperspectives. The POI Alignment Module (PAM) incorporates POI transition\nrelations into the LLM's semantic space, allowing it to infer global POI\nrelationships and generalize to unseen POIs. Experiments on three real-world\ndatasets demonstrate the state-of-the-art performance of GA-LLM.",
      "tldr_zh": "该论文针对下一兴趣点（POI）推荐任务，提出Geography-Aware Large Language Models (GA-LLM)，旨在通过增强Large Language Models (LLMs)来更好地建模地理信息和POI转换关系，以捕捉用户移动模式。GA-LLM框架包括两个关键组件：Geographic Coordinate Injection Module (GCIM)，它利用分层和傅立叶-based位置编码将GPS坐标转化为多视角空间表示；以及POI Alignment Module (PAM)，该模块将POI转换关系融入LLMs的语义空间，实现对全局POI关系的推断和对未见POI的泛化。在三个真实数据集上的实验表明，GA-LLM达到了最先进性能，显著提升了推荐准确性。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "9 pages, 7figures",
      "pdf_url": "http://arxiv.org/pdf/2505.13526v1",
      "published_date": "2025-05-18 03:20:20 UTC",
      "updated_date": "2025-05-18 03:20:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:56:55.498673"
    },
    {
      "arxiv_id": "2505.12211v1",
      "title": "Imagination-Limited Q-Learning for Offline Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Wenhui Liu",
        "Zhijian Wu",
        "Jingchao Wang",
        "Dingjiang Huang",
        "Shuigeng Zhou"
      ],
      "abstract": "Offline reinforcement learning seeks to derive improved policies entirely\nfrom historical data but often struggles with over-optimistic value estimates\nfor out-of-distribution (OOD) actions. This issue is typically mitigated via\npolicy constraint or conservative value regularization methods. However, these\napproaches may impose overly constraints or biased value estimates, potentially\nlimiting performance improvements. To balance exploitation and restriction, we\npropose an Imagination-Limited Q-learning (ILQ) method, which aims to maintain\nthe optimism that OOD actions deserve within appropriate limits. Specifically,\nwe utilize the dynamics model to imagine OOD action-values, and then clip the\nimagined values with the maximum behavior values. Such design maintains\nreasonable evaluation of OOD actions to the furthest extent, while avoiding its\nover-optimism. Theoretically, we prove the convergence of the proposed ILQ\nunder tabular Markov decision processes. Particularly, we demonstrate that the\nerror bound between estimated values and optimality values of OOD state-actions\npossesses the same magnitude as that of in-distribution ones, thereby\nindicating that the bias in value estimates is effectively mitigated.\nEmpirically, our method achieves state-of-the-art performance on a wide range\nof tasks in the D4RL benchmark.",
      "tldr_zh": "本论文针对离线强化学习（Offline Reinforcement Learning）中对分布外（OOD）动作的过度乐观价值估计问题，提出Imagination-Limited Q-learning (ILQ)方法，以平衡探索和限制。ILQ利用dynamics model想象OOD动作的价值，并通过maximum behavior values进行剪切，从而在避免过度乐观的同时保持合理评估。理论上，论文证明了ILQ在tabular Markov decision processes下的收敛，并显示OOD状态-动作的价值估计误差与分布内（in-distribution）的一致量级。实验结果表明，该方法在D4RL基准上的多种任务中实现了state-of-the-art性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by IJCAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.12211v1",
      "published_date": "2025-05-18 03:05:21 UTC",
      "updated_date": "2025-05-18 03:05:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:57:08.538495"
    },
    {
      "arxiv_id": "2505.12207v1",
      "title": "Can Large Multimodal Models Understand Agricultural Scenes? Benchmarking with AgroMind",
      "title_zh": "大型多模态模型能理解农业场景吗？使用 AgroMind 进行基准测试",
      "authors": [
        "Qingmei Li",
        "Yang Zhang",
        "Zurong Mai",
        "Yuhang Chen",
        "Shuohong Lou",
        "Henglian Huang",
        "Jiarui Zhang",
        "Zhiwei Zhang",
        "Yibin Wen",
        "Weijia Li",
        "Haohuan Fu",
        "Jianxi Huang",
        "Juepeng Zheng"
      ],
      "abstract": "Large Multimodal Models (LMMs) has demonstrated capabilities across various\ndomains, but comprehensive benchmarks for agricultural remote sensing (RS)\nremain scarce. Existing benchmarks designed for agricultural RS scenarios\nexhibit notable limitations, primarily in terms of insufficient scene diversity\nin the dataset and oversimplified task design. To bridge this gap, we introduce\nAgroMind, a comprehensive agricultural remote sensing benchmark covering four\ntask dimensions: spatial perception, object understanding, scene understanding,\nand scene reasoning, with a total of 13 task types, ranging from crop\nidentification and health monitoring to environmental analysis. We curate a\nhigh-quality evaluation set by integrating eight public datasets and one\nprivate farmland plot dataset, containing 25,026 QA pairs and 15,556 images.\nThe pipeline begins with multi-source data preprocessing, including collection,\nformat standardization, and annotation refinement. We then generate a diverse\nset of agriculturally relevant questions through the systematic definition of\ntasks. Finally, we employ LMMs for inference, generating responses, and\nperforming detailed examinations. We evaluated 18 open-source LMMs and 3\nclosed-source models on AgroMind. Experiments reveal significant performance\ngaps, particularly in spatial reasoning and fine-grained recognition, it is\nnotable that human performance lags behind several leading LMMs. By\nestablishing a standardized evaluation framework for agricultural RS, AgroMind\nreveals the limitations of LMMs in domain knowledge and highlights critical\nchallenges for future work. Data and code can be accessed at\nhttps://rssysu.github.io/AgroMind/.",
      "tldr_zh": "本文评估了Large Multimodal Models (LMMs)在农业遥感 (RS) 场景中的理解能力，并引入AgroMind作为全面基准，以填补现有基准的不足，如数据集场景多样性低和任务设计简单。AgroMind涵盖空间感知、物体理解、场景理解和场景推理四个维度，共13个任务类型，包括作物识别、健康监测和环境分析，并整合八个公共数据集和一个私有数据集，包含25,026个QA对和15,556张图像。实验评估了18个开源LMMs和3个闭源模型，结果显示LMMs在空间推理和细粒度识别方面存在显著性能差距，同时人类表现落后于部分领先LMMs。通过建立标准化评估框架，AgroMind揭示了LMMs在农业领域知识上的局限性，并为未来研究指明了关键挑战。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12207v1",
      "published_date": "2025-05-18 02:45:19 UTC",
      "updated_date": "2025-05-18 02:45:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:57:21.049167"
    },
    {
      "arxiv_id": "2505.13525v1",
      "title": "Learning to Program Quantum Measurements for Machine Learning",
      "title_zh": "针对机器学习的量子测量编程学习",
      "authors": [
        "Samual Yen-Chi Chen",
        "Huan-Hsin Tseng",
        "Hsin-Yi Lin",
        "Shinjae Yoo"
      ],
      "abstract": "The rapid advancements in quantum computing (QC) and machine learning (ML)\nhave sparked significant interest, driving extensive exploration of quantum\nmachine learning (QML) algorithms to address a wide range of complex\nchallenges. The development of high-performance QML models requires\nexpert-level expertise, presenting a key challenge to the widespread adoption\nof QML. Critical obstacles include the design of effective data encoding\nstrategies and parameterized quantum circuits, both of which are vital for the\nperformance of QML models. Furthermore, the measurement process is often\nneglected-most existing QML models employ predefined measurement schemes that\nmay not align with the specific requirements of the targeted problem. We\npropose an innovative framework that renders the observable of a quantum\nsystem-specifically, the Hermitian matrix-trainable. This approach employs an\nend-to-end differentiable learning framework, enabling simultaneous\noptimization of the neural network used to program the parameterized\nobservables and the standard quantum circuit parameters. Notably, the quantum\nobservable parameters are dynamically programmed by the neural network,\nallowing the observables to adapt in real time based on the input data stream.\nThrough numerical simulations, we demonstrate that the proposed method\neffectively programs observables dynamically within variational quantum\ncircuits, achieving superior results compared to existing approaches. Notably,\nit delivers enhanced performance metrics, such as higher classification\naccuracy, thereby significantly improving the overall effectiveness of QML\nmodels.",
      "tldr_zh": "本论文针对量子机器学习（QML）中数据编码、量子电路设计和测量方案的挑战，提出一个创新框架，使量子系统的可观测量（Hermitian matrix）可训练。框架采用端到端的可微学习方法，同时优化神经网络（用于动态编程参数化可观测量）和标准量子电路参数，从而使可观测量根据输入数据实时适应。实验通过数值模拟证明，该方法在变分量子电路中显著提升了性能指标，如分类准确率，比现有方法表现出色。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.ET",
        "cs.LG",
        "cs.NE"
      ],
      "primary_category": "quant-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13525v1",
      "published_date": "2025-05-18 02:39:22 UTC",
      "updated_date": "2025-05-18 02:39:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:57:31.920637"
    },
    {
      "arxiv_id": "2505.12199v1",
      "title": "Always Clear Depth: Robust Monocular Depth Estimation under Adverse Weather",
      "title_zh": "翻译失败",
      "authors": [
        "Kui Jiang",
        "Jing Cao",
        "Zhaocheng Yu",
        "Junjun Jiang",
        "Jingchun Zhou"
      ],
      "abstract": "Monocular depth estimation is critical for applications such as autonomous\ndriving and scene reconstruction. While existing methods perform well under\nnormal scenarios, their performance declines in adverse weather, due to\nchallenging domain shifts and difficulties in extracting scene information. To\naddress this issue, we present a robust monocular depth estimation method\ncalled \\textbf{ACDepth} from the perspective of high-quality training data\ngeneration and domain adaptation. Specifically, we introduce a one-step\ndiffusion model for generating samples that simulate adverse weather\nconditions, constructing a multi-tuple degradation dataset during training. To\nensure the quality of the generated degradation samples, we employ LoRA\nadapters to fine-tune the generation weights of diffusion model. Additionally,\nwe integrate circular consistency loss and adversarial training to guarantee\nthe fidelity and naturalness of the scene contents. Furthermore, we elaborate\non a multi-granularity knowledge distillation strategy (MKD) that encourages\nthe student network to absorb knowledge from both the teacher model and\npretrained Depth Anything V2. This strategy guides the student model in\nlearning degradation-agnostic scene information from various degradation\ninputs. In particular, we introduce an ordinal guidance distillation mechanism\n(OGD) that encourages the network to focus on uncertain regions through\ndifferential ranking, leading to a more precise depth estimation. Experimental\nresults demonstrate that our ACDepth surpasses md4all-DD by 2.50\\% for night\nscene and 2.61\\% for rainy scene on the nuScenes dataset in terms of the absRel\nmetric.",
      "tldr_zh": "本论文提出了一种鲁棒的单目深度估计方法ACDepth，旨在解决现有模型在恶劣天气（如夜间和雨天）下的性能下降问题，通过高质量训练数据生成和领域适应技术提升鲁棒性。具体而言，该方法使用一步扩散模型生成模拟天气退化样本，并结合LoRA adapters、循环一致性损失和对抗训练确保样本质量；同时引入多粒度知识蒸馏策略（MKD）和序数指导蒸馏机制（OGD），引导学生网络从教师模型和Depth Anything V2学习退化无关的场景信息。实验结果显示，ACDepth在nuScenes数据集上，夜间场景的absRel指标比md4all-DD提高了2.50%，雨天场景提高了2.61%，显著提升了深度估计的准确性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12199v1",
      "published_date": "2025-05-18 02:30:47 UTC",
      "updated_date": "2025-05-18 02:30:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:57:43.237903"
    },
    {
      "arxiv_id": "2505.12191v1",
      "title": "Ditch the Denoiser: Emergence of Noise Robustness in Self-Supervised Learning from Data Curriculum",
      "title_zh": "翻译失败",
      "authors": [
        "Wenquan Lu",
        "Jiaqi Zhang",
        "Hugues Van Assel",
        "Randall Balestriero"
      ],
      "abstract": "Self-Supervised Learning (SSL) has become a powerful solution to extract rich\nrepresentations from unlabeled data. Yet, SSL research is mostly focused on\nclean, curated and high-quality datasets. As a result, applying SSL on noisy\ndata remains a challenge, despite being crucial to applications such as\nastrophysics, medical imaging, geophysics or finance. In this work, we present\na fully self-supervised framework that enables noise-robust representation\nlearning without requiring a denoiser at inference or downstream fine-tuning.\nOur method first trains an SSL denoiser on noisy data, then uses it to\nconstruct a denoised-to-noisy data curriculum (i.e., training first on\ndenoised, then noisy samples) for pretraining a SSL backbone (e.g., DINOv2),\ncombined with a teacher-guided regularization that anchors noisy embeddings to\ntheir denoised counterparts. This process encourages the model to internalize\nnoise robustness. Notably, the denoiser can be discarded after pretraining,\nsimplifying deployment. On ImageNet-1k with ViT-B under extreme Gaussian noise\n($\\sigma=255$, SNR = 0.72 dB), our method improves linear probing accuracy by\n4.8% over DINOv2, demonstrating that denoiser-free robustness can emerge from\nnoise-aware pretraining. The code is available at\nhttps://github.com/wenquanlu/noisy_dinov2.",
      "tldr_zh": "该研究提出一个完全自监督的框架，用于在噪声数据上实现Self-Supervised Learning (SSL)，无需在推理或下游微调中使用去噪器，从而提升噪声鲁棒性。该框架首先训练一个SSL去噪器，然后构建从去噪到噪声的数据课程（即先训练去噪样本，再训练噪声样本）来预训练SSL主干（如DINOv2），并结合教师引导正则化将噪声嵌入锚定到去噪对应物，以内部化噪声鲁棒性。实验结果显示，在ImageNet-1k数据集上使用ViT-B模型面对极端高斯噪声（σ=255，SNR=0.72 dB）时，该方法比DINOv2提高线性探测准确率4.8%，证明了通过噪声感知预训练可实现去噪器无关的鲁棒性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12191v1",
      "published_date": "2025-05-18 01:37:58 UTC",
      "updated_date": "2025-05-18 01:37:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:57:56.826948"
    },
    {
      "arxiv_id": "2505.12189v1",
      "title": "Mitigating Content Effects on Reasoning in Language Models through Fine-Grained Activation Steering",
      "title_zh": "通过",
      "authors": [
        "Marco Valentino",
        "Geonhee Kim",
        "Dhairya Dalal",
        "Zhixue Zhao",
        "André Freitas"
      ],
      "abstract": "Large language models (LLMs) frequently demonstrate reasoning limitations,\noften conflating content plausibility (i.e., material inference) with logical\nvalidity (i.e., formal inference). This can result in biased inferences, where\nplausible arguments are incorrectly deemed logically valid or vice versa.\nMitigating this limitation is critical, as it undermines the trustworthiness\nand generalizability of LLMs in applications that demand rigorous logical\nconsistency. This paper investigates the problem of mitigating content biases\non formal reasoning through activation steering. Specifically, we curate a\ncontrolled syllogistic reasoning dataset to disentangle formal validity from\ncontent plausibility. After localising the layers responsible for formal and\nmaterial inference, we investigate contrastive activation steering methods for\ntest-time interventions. An extensive empirical analysis on different LLMs\nreveals that contrastive steering consistently supports linear control over\ncontent biases. However, we observe that a static approach is insufficient for\nimproving all the tested models. We then leverage the possibility to control\ncontent effects by dynamically determining the value of the steering parameters\nvia fine-grained conditional methods. We found that conditional steering is\neffective on unresponsive models, achieving up to 15% absolute improvement in\nformal reasoning accuracy with a newly introduced kNN-based method (K-CAST).\nFinally, additional experiments reveal that steering for content effects is\nrobust to prompt variations, incurs minimal side effects on language modeling\ncapabilities, and can partially generalize to out-of-distribution reasoning\ntasks. Practically, this paper demonstrates that activation-level interventions\ncan offer a scalable strategy for enhancing the robustness of LLMs,\ncontributing towards more systematic and unbiased formal reasoning.",
      "tldr_zh": "本研究探讨了大语言模型 (LLMs) 在推理过程中因内容合理性 (material inference) 与逻辑有效性 (formal inference) 的混淆而导致的偏见问题，通过细粒度激活转向 (activation steering) 方法来缓解这种内容偏见。研究者构建了一个控制的逻辑推理数据集，并定位了模型中负责不同推理类型的层，然后应用对比激活转向进行测试干预，结果显示这种方法能线性控制偏见，但静态方法效果有限。进一步引入动态条件转向，如基于 kNN 的 K-CAST 方法，在某些模型上将 formal reasoning 准确率提高高达 15%，并证明该方法对提示变化鲁棒、副作用最小，并部分泛化到分布外任务。总体上，这为提升 LLMs 的鲁棒性和可信度提供了可扩展的激活级干预策略。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Work in progress",
      "pdf_url": "http://arxiv.org/pdf/2505.12189v1",
      "published_date": "2025-05-18 01:34:34 UTC",
      "updated_date": "2025-05-18 01:34:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:58:08.336112"
    },
    {
      "arxiv_id": "2505.12188v2",
      "title": "LLM-DSE: Searching Accelerator Parameters with LLM Agents",
      "title_zh": "LLM-DSE：利用 LLM 代理搜索加速器参数",
      "authors": [
        "Hanyu Wang",
        "Xinrui Wu",
        "Zijian Ding",
        "Su Zheng",
        "Chengyue Wang",
        "Tony Nowatzki",
        "Yizhou Sun",
        "Jason Cong"
      ],
      "abstract": "Even though high-level synthesis (HLS) tools mitigate the challenges of\nprogramming domain-specific accelerators (DSAs) by raising the abstraction\nlevel, optimizing hardware directive parameters remains a significant hurdle.\nExisting heuristic and learning-based methods struggle with adaptability and\nsample efficiency. We present LLM-DSE, a multi-agent framework designed\nspecifically for optimizing HLS directives. Combining LLM with design space\nexploration (DSE), our explorer coordinates four agents: Router, Specialists,\nArbitrator, and Critic. These multi-agent components interact with various\ntools to accelerate the optimization process. LLM-DSE leverages essential\ndomain knowledge to identify efficient parameter combinations while maintaining\nadaptability through verbal learning from online interactions. Evaluations on\nthe HLSyn dataset demonstrate that LLM-DSE achieves substantial $2.55\\times$\nperformance gains over state-of-the-art methods, uncovering novel designs while\nreducing runtime. Ablation studies validate the effectiveness and necessity of\nthe proposed agent interactions. Our code is open-sourced here:\nhttps://github.com/Nozidoali/LLM-DSE.",
      "tldr_zh": "这篇论文提出了 LLM-DSE，一种基于大型语言模型 (LLM) 代理的多智能体框架，用于优化高层次综合 (HLS) 指令参数，以解决现有启发式和学习方法在适应性和样本效率上的不足。框架包括四个代理：Router、Specialists、Arbitrator 和 Critic，它们通过设计空间探索 (DSE) 与各种工具交互，利用领域知识和在线学习来识别高效参数组合。在 HLSyn 数据集上的评估显示，LLM-DSE 比最先进方法性能提升 2.55 倍，同时发现新设计并减少运行时间，消融研究进一步验证了代理交互的有效性。代码已开源。",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "primary_category": "cs.AR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12188v2",
      "published_date": "2025-05-18 01:31:42 UTC",
      "updated_date": "2025-05-20 08:29:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:58:20.892073"
    },
    {
      "arxiv_id": "2505.12186v1",
      "title": "Self-Destructive Language Model",
      "title_zh": "自我破坏语言模型",
      "authors": [
        "Yuhui Wang",
        "Rongyi Zhu",
        "Ting Wang"
      ],
      "abstract": "Harmful fine-tuning attacks pose a major threat to the security of large\nlanguage models (LLMs), allowing adversaries to compromise safety guardrails\nwith minimal harmful data. While existing defenses attempt to reinforce LLM\nalignment, they fail to address models' inherent \"trainability\" on harmful\ndata, leaving them vulnerable to stronger attacks with increased learning rates\nor larger harmful datasets. To overcome this critical limitation, we introduce\nSEAM, a novel alignment-enhancing defense that transforms LLMs into\nself-destructive models with intrinsic resilience to misalignment attempts.\nSpecifically, these models retain their capabilities for legitimate tasks while\nexhibiting substantial performance degradation when fine-tuned on harmful data.\nThe protection is achieved through a novel loss function that couples the\noptimization trajectories of benign and harmful data, enhanced with adversarial\ngradient ascent to amplify the self-destructive effect. To enable practical\ntraining, we develop an efficient Hessian-free gradient estimate with\ntheoretical error bounds. Extensive evaluation across LLMs and datasets\ndemonstrates that SEAM creates a no-win situation for adversaries: the\nself-destructive models achieve state-of-the-art robustness against\nlow-intensity attacks and undergo catastrophic performance collapse under\nhigh-intensity attacks, rendering them effectively unusable. (warning: this\npaper contains potentially harmful content generated by LLMs.)",
      "tldr_zh": "该论文提出 SEAM，一种新型防御机制，将大型语言模型 (LLMs) 转化为 self-destructive models，以应对有害微调攻击，这些模型在合法任务上保持能力，但对有害数据微调时会显著性能下降。SEAM 通过一个耦合良性和有害数据优化轨迹的损失函数、结合 adversarial gradient ascent 以及高效的 Hessian-free gradient estimate 来实现这一保护效果。实验在多种 LLMs 和数据集上验证，SEAM 实现了最先进的鲁棒性，对低强度攻击有效防御，而对高强度攻击则导致攻击者性能崩溃，彻底无利可图。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12186v1",
      "published_date": "2025-05-18 01:08:18 UTC",
      "updated_date": "2025-05-18 01:08:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:58:33.930961"
    },
    {
      "arxiv_id": "2505.13523v1",
      "title": "ACPs: Agent Collaboration Protocols for the Internet of Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Jun Liu",
        "Ke Yu",
        "Keliang Chen",
        "Ke Li",
        "Yuxinyue Qian",
        "Xiaolian Guo",
        "Haozhe Song",
        "Yinming Li"
      ],
      "abstract": "With the rapid advancement of artificial intelligence, the proliferation of\nautonomous agents has introduced new challenges in interoperability,\nscalability, and coordination. The Internet of Agents (IoA) aims to\ninterconnect heterogeneous agents through standardized communication protocols,\nenabling seamless collaboration and intelligent task execution. However,\nexisting agent communication protocols such as MCP, A2A, and ANP remain\nfragmented and scenario-specific. To address this gap, we propose Agent\nCollaboration Protocols (ACPs), a comprehensive protocol suite for the IoA.\nACPs include registration, discovery, interaction, and tooling protocols to\nsupport trustable access, capability orchestration, and workflow construction.\nWe present the architecture, key technologies, and application workflows of\nACPs, and demonstrate its effectiveness in a collaborative restaurant booking\nscenario. ACPs lay the foundation for building a secure, open, and scalable\nagent internet infrastructure.",
      "tldr_zh": "随着人工智能的快速发展，自主代理在互操作性、可伸缩性和协调方面面临挑战，现有的代理通信协议如MCP、A2A和ANP存在碎片化和场景特定问题。  \n为解决这些问题，本文提出Agent Collaboration Protocols (ACPs)，一个全面的协议套件，适用于Internet of Agents (IoA)，包括注册、发现、交互和工具协议。  \nACPs支持可信任访问、能力编排和工作流构建，并通过一个协作餐厅预订场景的实际应用，展示了其有效性。  \n总体上，ACPs为构建安全、开放和可伸缩的代理互联网基础设施奠定了基础。",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "7 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.13523v1",
      "published_date": "2025-05-18 00:54:27 UTC",
      "updated_date": "2025-05-18 00:54:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:58:44.548094"
    },
    {
      "arxiv_id": "2505.12183v1",
      "title": "Decoding the Mind of Large Language Models: A Quantitative Evaluation of Ideology and Biases",
      "title_zh": "解码大型语言模型的思维：意识形态和偏见的定量评估",
      "authors": [
        "Manari Hirose",
        "Masato Uchida"
      ],
      "abstract": "The widespread integration of Large Language Models (LLMs) across various\nsectors has highlighted the need for empirical research to understand their\nbiases, thought patterns, and societal implications to ensure ethical and\neffective use. In this study, we propose a novel framework for evaluating LLMs,\nfocusing on uncovering their ideological biases through a quantitative analysis\nof 436 binary-choice questions, many of which have no definitive answer. By\napplying our framework to ChatGPT and Gemini, findings revealed that while LLMs\ngenerally maintain consistent opinions on many topics, their ideologies differ\nacross models and languages. Notably, ChatGPT exhibits a tendency to change\ntheir opinion to match the questioner's opinion. Both models also exhibited\nproblematic biases, unethical or unfair claims, which might have negative\nsocietal impacts. These results underscore the importance of addressing both\nideological and ethical considerations when evaluating LLMs. The proposed\nframework offers a flexible, quantitative method for assessing LLM behavior,\nproviding valuable insights for the development of more socially aligned AI\nsystems.",
      "tldr_zh": "本研究提出一个新框架，用于定量评估Large Language Models (LLMs)的意识形态偏见和思维模式，通过分析436个二选一问题（许多无明确答案）来揭示LLMs的潜在偏差。研究对象包括ChatGPT和Gemini，结果显示这些模型在许多话题上保持一致意见，但不同模型和语言间存在差异，且ChatGPT倾向于调整意见以符合提问者观点。两者均表现出问题偏见和不道德声明，可能导致负面社会影响。该框架强调在评估LLMs时需兼顾意识形态和伦理因素，为开发更符合社会规范的AI系统提供宝贵见解。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "23 pages, 5 figures, 17 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.12183v1",
      "published_date": "2025-05-18 00:52:06 UTC",
      "updated_date": "2025-05-18 00:52:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:58:57.128166"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 111,
  "processed_papers_count": 111,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-25T00:59:17.937844"
}