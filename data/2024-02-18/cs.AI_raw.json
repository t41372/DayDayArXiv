[
  {
    "arxiv_id": "2402.11737v1",
    "title": "Compression Repair for Feedforward Neural Networks Based on Model Equivalence Evaluation",
    "authors": [
      "Zihao Mo",
      "Yejiang Yang",
      "Shuaizheng Lu",
      "Weiming Xiang"
    ],
    "abstract": "In this paper, we propose a method of repairing compressed Feedforward Neural\nNetworks (FNNs) based on equivalence evaluation of two neural networks. In the\nrepairing framework, a novel neural network equivalence evaluation method is\ndeveloped to compute the output discrepancy between two neural networks. The\noutput discrepancy can quantitatively characterize the output difference\nproduced by compression procedures. Based on the computed output discrepancy,\nthe repairing method first initializes a new training set for the compressed\nnetworks to narrow down the discrepancy between the two neural networks and\nimprove the performance of the compressed network. Then, we repair the\ncompressed FNN by re-training based on the training set. We apply our developed\nmethod to the MNIST dataset to demonstrate the effectiveness and advantages of\nour proposed repair method.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "ACC 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.11737v1",
    "published_date": "2024-02-18 23:41:38 UTC",
    "updated_date": "2024-02-18 23:41:38 UTC"
  },
  {
    "arxiv_id": "2403.00784v1",
    "title": "Utilizing BERT for Information Retrieval: Survey, Applications, Resources, and Challenges",
    "authors": [
      "Jiajia Wang",
      "Jimmy X. Huang",
      "Xinhui Tu",
      "Junmei Wang",
      "Angela J. Huang",
      "Md Tahmid Rahman Laskar",
      "Amran Bhuiyan"
    ],
    "abstract": "Recent years have witnessed a substantial increase in the use of deep\nlearning to solve various natural language processing (NLP) problems. Early\ndeep learning models were constrained by their sequential or unidirectional\nnature, such that they struggled to capture the contextual relationships across\ntext inputs. The introduction of bidirectional encoder representations from\ntransformers (BERT) leads to a robust encoder for the transformer model that\ncan understand the broader context and deliver state-of-the-art performance\nacross various NLP tasks. This has inspired researchers and practitioners to\napply BERT to practical problems, such as information retrieval (IR). A survey\nthat focuses on a comprehensive analysis of prevalent approaches that apply\npretrained transformer encoders like BERT to IR can thus be useful for academia\nand the industry. In light of this, we revisit a variety of BERT-based methods\nin this survey, cover a wide range of techniques of IR, and group them into six\nhigh-level categories: (i) handling long documents, (ii) integrating semantic\ninformation, (iii) balancing effectiveness and efficiency, (iv) predicting the\nweights of terms, (v) query expansion, and (vi) document expansion. We also\nprovide links to resources, including datasets and toolkits, for BERT-based IR\nsystems. A key highlight of our survey is the comparison between BERT's\nencoder-based models and the latest generative Large Language Models (LLMs),\nsuch as ChatGPT, which rely on decoders. Despite the popularity of LLMs, we\nfind that for specific tasks, finely tuned BERT encoders still outperform, and\nat a lower deployment cost. Finally, we summarize the comprehensive outcomes of\nthe survey and suggest directions for future research in the area.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.00784v1",
    "published_date": "2024-02-18 23:22:40 UTC",
    "updated_date": "2024-02-18 23:22:40 UTC"
  },
  {
    "arxiv_id": "2402.11734v2",
    "title": "Solving Data-centric Tasks using Large Language Models",
    "authors": [
      "Shraddha Barke",
      "Christian Poelitz",
      "Carina Suzana Negreanu",
      "Benjamin Zorn",
      "José Cambronero",
      "Andrew D. Gordon",
      "Vu Le",
      "Elnaz Nouri",
      "Nadia Polikarpova",
      "Advait Sarkar",
      "Brian Slininger",
      "Neil Toronto",
      "Jack Williams"
    ],
    "abstract": "Large language models (LLMs) are rapidly replacing help forums like\nStackOverflow, and are especially helpful for non-professional programmers and\nend users. These users are often interested in data-centric tasks, such as\nspreadsheet manipulation and data wrangling, which are hard to solve if the\nintent is only communicated using a natural-language description, without\nincluding the data. But how do we decide how much data and which data to\ninclude in the prompt? This paper makes two contributions towards answering\nthis question. First, we create a dataset of real-world NL-to-code tasks\nmanipulating tabular data, mined from StackOverflow posts. Second, we introduce\na cluster-then-select prompting technique, which adds the most representative\nrows from the input data to the LLM prompt. Our experiments show that LLM\nperformance is indeed sensitive to the amount of data passed in the prompt, and\nthat for tasks with a lot of syntactic variation in the input table, our\ncluster-then-select technique outperforms a random selection baseline.",
    "categories": [
      "cs.PL",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.PL",
    "comment": "Paper accepted to NAACL 2024 (Findings)",
    "pdf_url": "http://arxiv.org/pdf/2402.11734v2",
    "published_date": "2024-02-18 23:19:21 UTC",
    "updated_date": "2024-03-25 03:23:01 UTC"
  },
  {
    "arxiv_id": "2402.11733v1",
    "title": "The Effectiveness of Random Forgetting for Robust Generalization",
    "authors": [
      "Vijaya Raghavan T Ramkumar",
      "Bahram Zonooz",
      "Elahe Arani"
    ],
    "abstract": "Deep neural networks are susceptible to adversarial attacks, which can\ncompromise their performance and accuracy. Adversarial Training (AT) has\nemerged as a popular approach for protecting neural networks against such\nattacks. However, a key challenge of AT is robust overfitting, where the\nnetwork's robust performance on test data deteriorates with further training,\nthus hindering generalization. Motivated by the concept of active forgetting in\nthe brain, we introduce a novel learning paradigm called \"Forget to Mitigate\nOverfitting (FOMO)\". FOMO alternates between the forgetting phase, which\nrandomly forgets a subset of weights and regulates the model's information\nthrough weight reinitialization, and the relearning phase, which emphasizes\nlearning generalizable features. Our experiments on benchmark datasets and\nadversarial attacks show that FOMO alleviates robust overfitting by\nsignificantly reducing the gap between the best and last robust test accuracy\nwhile improving the state-of-the-art robustness. Furthermore, FOMO provides a\nbetter trade-off between standard and robust accuracy, outperforming baseline\nadversarial methods. Finally, our framework is robust to AutoAttacks and\nincreases generalization in many real-world scenarios.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "Published as a conference paper at ICLR 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.11733v1",
    "published_date": "2024-02-18 23:14:40 UTC",
    "updated_date": "2024-02-18 23:14:40 UTC"
  },
  {
    "arxiv_id": "2402.14837v1",
    "title": "An Empirical Categorization of Prompting Techniques for Large Language Models: A Practitioner's Guide",
    "authors": [
      "Oluwole Fagbohun",
      "Rachel M. Harrison",
      "Anton Dereventsov"
    ],
    "abstract": "Due to rapid advancements in the development of Large Language Models (LLMs),\nprogramming these models with prompts has recently gained significant\nattention. However, the sheer number of available prompt engineering techniques\ncreates an overwhelming landscape for practitioners looking to utilize these\ntools. For the most efficient and effective use of LLMs, it is important to\ncompile a comprehensive list of prompting techniques and establish a\nstandardized, interdisciplinary categorization framework. In this survey, we\nexamine some of the most well-known prompting techniques from both academic and\npractical viewpoints and classify them into seven distinct categories. We\npresent an overview of each category, aiming to clarify their unique\ncontributions and showcase their practical applications in real-world examples\nin order to equip fellow practitioners with a structured framework for\nunderstanding and categorizing prompting techniques tailored to their specific\ndomains. We believe that this approach will help simplify the complex landscape\nof prompt engineering and enable more effective utilization of LLMs in various\napplications. By providing practitioners with a systematic approach to prompt\ncategorization, we aim to assist in navigating the intricacies of effective\nprompt design for conversational pre-trained LLMs and inspire new possibilities\nin their respective fields.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.14837v1",
    "published_date": "2024-02-18 23:03:56 UTC",
    "updated_date": "2024-02-18 23:03:56 UTC"
  },
  {
    "arxiv_id": "2402.11729v2",
    "title": "Prospector Heads: Generalized Feature Attribution for Large Models & Data",
    "authors": [
      "Gautam Machiraju",
      "Alexander Derry",
      "Arjun Desai",
      "Neel Guha",
      "Amir-Hossein Karimi",
      "James Zou",
      "Russ Altman",
      "Christopher Ré",
      "Parag Mallick"
    ],
    "abstract": "Feature attribution, the ability to localize regions of the input data that\nare relevant for classification, is an important capability for ML models in\nscientific and biomedical domains. Current methods for feature attribution,\nwhich rely on \"explaining\" the predictions of end-to-end classifiers, suffer\nfrom imprecise feature localization and are inadequate for use with small\nsample sizes and high-dimensional datasets due to computational challenges. We\nintroduce prospector heads, an efficient and interpretable alternative to\nexplanation-based attribution methods that can be applied to any encoder and\nany data modality. Prospector heads generalize across modalities through\nexperiments on sequences (text), images (pathology), and graphs (protein\nstructures), outperforming baseline attribution methods by up to 26.3 points in\nmean localization AUPRC. We also demonstrate how prospector heads enable\nimproved interpretation and discovery of class-specific patterns in input data.\nThrough their high performance, flexibility, and generalizability, prospectors\nprovide a framework for improving trust and transparency for ML models in\ncomplex domains.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.QM"
    ],
    "primary_category": "cs.LG",
    "comment": "30 pages, 16 figures, 8 tables. Accepted to ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.11729v2",
    "published_date": "2024-02-18 23:01:28 UTC",
    "updated_date": "2024-06-20 00:29:16 UTC"
  },
  {
    "arxiv_id": "2402.11709v2",
    "title": "GNNavi: Navigating the Information Flow in Large Language Models by Graph Neural Network",
    "authors": [
      "Shuzhou Yuan",
      "Ercong Nie",
      "Michael Färber",
      "Helmut Schmid",
      "Hinrich Schütze"
    ],
    "abstract": "Large Language Models (LLMs) exhibit strong In-Context Learning (ICL)\ncapabilities when prompts with demonstrations are used. However, fine-tuning\nstill remains crucial to further enhance their adaptability. Prompt-based\nfine-tuning proves to be an effective fine-tuning method in low-data scenarios,\nbut high demands on computing resources limit its practicality. We address this\nissue by introducing a prompt-based parameter-efficient fine-tuning (PEFT)\napproach. GNNavi leverages insights into ICL's information flow dynamics, which\nindicates that label words act in prompts as anchors for information\npropagation. GNNavi employs a Graph Neural Network (GNN) layer to precisely\nguide the aggregation and distribution of information flow during the\nprocessing of prompts by hardwiring the desired information flow into the GNN.\nOur experiments on text classification tasks with GPT-2 and Llama2 show GNNavi\nsurpasses standard prompt-based fine-tuning methods in few-shot settings by\nupdating just 0.2% to 0.5% of parameters. We compare GNNavi with prevalent PEFT\napproaches, such as prefix tuning, LoRA and Adapter in terms of performance and\nefficiency. Our analysis reveals that GNNavi enhances information flow and\nensures a clear aggregation process.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "ACL2024 Findings",
    "pdf_url": "http://arxiv.org/pdf/2402.11709v2",
    "published_date": "2024-02-18 21:13:05 UTC",
    "updated_date": "2024-06-07 14:36:33 UTC"
  },
  {
    "arxiv_id": "2402.11707v1",
    "title": "Search Engines Post-ChatGPT: How Generative Artificial Intelligence Could Make Search Less Reliable",
    "authors": [
      "Shahan Ali Memon",
      "Jevin D. West"
    ],
    "abstract": "In this commentary, we discuss the evolving nature of search engines, as they\nbegin to generate, index, and distribute content created by generative\nartificial intelligence (GenAI). Our discussion highlights challenges in the\nearly stages of GenAI integration, particularly around factual inconsistencies\nand biases. We discuss how output from GenAI carries an unwarranted sense of\ncredibility, while decreasing transparency and sourcing ability. Furthermore,\nsearch engines are already answering queries with error-laden, generated\ncontent, further blurring the provenance of information and impacting the\nintegrity of the information ecosystem. We argue how all these factors could\nreduce the reliability of search engines. Finally, we summarize some of the\nactive research directions and open questions.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.IR",
    "comment": "9 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.11707v1",
    "published_date": "2024-02-18 21:10:18 UTC",
    "updated_date": "2024-02-18 21:10:18 UTC"
  },
  {
    "arxiv_id": "2402.11702v2",
    "title": "Can ChatGPT Support Developers? An Empirical Evaluation of Large Language Models for Code Generation",
    "authors": [
      "Kailun Jin",
      "Chung-Yu Wang",
      "Hung Viet Pham",
      "Hadi Hemmati"
    ],
    "abstract": "Large language models (LLMs) have demonstrated notable proficiency in code\ngeneration, with numerous prior studies showing their promising capabilities in\nvarious development scenarios. However, these studies mainly provide\nevaluations in research settings, which leaves a significant gap in\nunderstanding how effectively LLMs can support developers in real-world. To\naddress this, we conducted an empirical analysis of conversations in DevGPT, a\ndataset collected from developers' conversations with ChatGPT (captured with\nthe Share Link feature on platforms such as GitHub). Our empirical findings\nindicate that the current practice of using LLM-generated code is typically\nlimited to either demonstrating high-level concepts or providing examples in\ndocumentation, rather than to be used as production-ready code. These findings\nindicate that there is much future work needed to improve LLMs in code\ngeneration before they can be integral parts of modern software development.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LG",
      "I.2.2"
    ],
    "primary_category": "cs.SE",
    "comment": "4 pages, 3 figures, 21st International Conference on Mining Software\n  Repositories (MSR '24), April 15-16, 2024, Lisbon, Portugal",
    "pdf_url": "http://arxiv.org/pdf/2402.11702v2",
    "published_date": "2024-02-18 20:48:09 UTC",
    "updated_date": "2024-03-16 22:16:40 UTC"
  },
  {
    "arxiv_id": "2402.11684v2",
    "title": "ALLaVA: Harnessing GPT4V-Synthesized Data for Lite Vision-Language Models",
    "authors": [
      "Guiming Hardy Chen",
      "Shunian Chen",
      "Ruifei Zhang",
      "Junying Chen",
      "Xiangbo Wu",
      "Zhiyi Zhang",
      "Zhihong Chen",
      "Jianquan Li",
      "Xiang Wan",
      "Benyou Wang"
    ],
    "abstract": "Large vision-language models (LVLMs) have shown premise in a broad range of\nvision-language tasks with their strong reasoning and generalization\ncapabilities. However, they require considerable computational resources for\ntraining and deployment. This study aims to bridge the performance gap between\ntraditional-scale LVLMs and resource-friendly lite versions by adopting\nhigh-quality training data. To this end, we propose a comprehensive pipeline\nfor generating a synthetic dataset. The key idea is to leverage strong\nproprietary models to generate (i) fine-grained image annotations for\nvision-language alignment and (ii) complex reasoning visual question-answering\npairs for visual instruction fine-tuning, yielding 1.3M samples in total. We\ntrain a series of lite VLMs on the synthetic dataset and experimental results\ndemonstrate the effectiveness of the proposed scheme, where they achieve\ncompetitive performance on 17 benchmarks among 4B LVLMs, and even perform on\npar with 7B/13B-scale models on various benchmarks. This work highlights the\nfeasibility of adopting high-quality data in crafting more efficient LVLMs. We\nname our dataset \\textit{ALLaVA}, and open-source it to research community for\ndeveloping better resource-efficient LVLMs for wider usage.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "22 pages",
    "pdf_url": "http://arxiv.org/pdf/2402.11684v2",
    "published_date": "2024-02-18 19:26:49 UTC",
    "updated_date": "2024-06-17 07:55:59 UTC"
  },
  {
    "arxiv_id": "2402.11680v1",
    "title": "3D Point Cloud Compression with Recurrent Neural Network and Image Compression Methods",
    "authors": [
      "Till Beemelmanns",
      "Yuchen Tao",
      "Bastian Lampe",
      "Lennart Reiher",
      "Raphael van Kempen",
      "Timo Woopen",
      "Lutz Eckstein"
    ],
    "abstract": "Storing and transmitting LiDAR point cloud data is essential for many AV\napplications, such as training data collection, remote control, cloud services\nor SLAM. However, due to the sparsity and unordered structure of the data, it\nis difficult to compress point cloud data to a low volume. Transforming the raw\npoint cloud data into a dense 2D matrix structure is a promising way for\napplying compression algorithms. We propose a new lossless and calibrated\n3D-to-2D transformation which allows compression algorithms to efficiently\nexploit spatial correlations within the 2D representation. To compress the\nstructured representation, we use common image compression methods and also a\nself-supervised deep compression approach using a recurrent neural network. We\nalso rearrange the LiDAR's intensity measurements to a dense 2D representation\nand propose a new metric to evaluate the compression performance of the\nintensity. Compared to approaches that are based on generic octree point cloud\ncompression or based on raw point cloud data compression, our approach achieves\nthe best quantitative and visual performance. Source code and dataset are\navailable at https://github.com/ika-rwth-aachen/Point-Cloud-Compression.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "Code: https://github.com/ika-rwth-aachen/Point-Cloud-Compression",
    "pdf_url": "http://arxiv.org/pdf/2402.11680v1",
    "published_date": "2024-02-18 19:08:19 UTC",
    "updated_date": "2024-02-18 19:08:19 UTC"
  },
  {
    "arxiv_id": "2402.11677v3",
    "title": "MultiCorrupt: A Multi-Modal Robustness Dataset and Benchmark of LiDAR-Camera Fusion for 3D Object Detection",
    "authors": [
      "Till Beemelmanns",
      "Quan Zhang",
      "Christian Geller",
      "Lutz Eckstein"
    ],
    "abstract": "Multi-modal 3D object detection models for automated driving have\ndemonstrated exceptional performance on computer vision benchmarks like\nnuScenes. However, their reliance on densely sampled LiDAR point clouds and\nmeticulously calibrated sensor arrays poses challenges for real-world\napplications. Issues such as sensor misalignment, miscalibration, and disparate\nsampling frequencies lead to spatial and temporal misalignment in data from\nLiDAR and cameras. Additionally, the integrity of LiDAR and camera data is\noften compromised by adverse environmental conditions such as inclement\nweather, leading to occlusions and noise interference. To address this\nchallenge, we introduce MultiCorrupt, a comprehensive benchmark designed to\nevaluate the robustness of multi-modal 3D object detectors against ten distinct\ntypes of corruptions. We evaluate five state-of-the-art multi-modal detectors\non MultiCorrupt and analyze their performance in terms of their resistance\nability. Our results show that existing methods exhibit varying degrees of\nrobustness depending on the type of corruption and their fusion strategy. We\nprovide insights into which multi-modal design choices make such models robust\nagainst certain perturbations. The dataset generation code and benchmark are\nopen-sourced at https://github.com/ika-rwth-aachen/MultiCorrupt.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Code: https://github.com/ika-rwth-aachen/MultiCorrupt",
    "pdf_url": "http://arxiv.org/pdf/2402.11677v3",
    "published_date": "2024-02-18 18:56:13 UTC",
    "updated_date": "2024-04-20 13:00:25 UTC"
  },
  {
    "arxiv_id": "2402.11676v2",
    "title": "A Multi-Aspect Framework for Counter Narrative Evaluation using Large Language Models",
    "authors": [
      "Jaylen Jones",
      "Lingbo Mo",
      "Eric Fosler-Lussier",
      "Huan Sun"
    ],
    "abstract": "Counter narratives - informed responses to hate speech contexts designed to\nrefute hateful claims and de-escalate encounters - have emerged as an effective\nhate speech intervention strategy. While previous work has proposed automatic\ncounter narrative generation methods to aid manual interventions, the\nevaluation of these approaches remains underdeveloped. Previous automatic\nmetrics for counter narrative evaluation lack alignment with human judgment as\nthey rely on superficial reference comparisons instead of incorporating key\naspects of counter narrative quality as evaluation criteria. To address prior\nevaluation limitations, we propose a novel evaluation framework prompting LLMs\nto provide scores and feedback for generated counter narrative candidates using\n5 defined aspects derived from guidelines from counter narrative specialized\nNGOs. We found that LLM evaluators achieve strong alignment to human-annotated\nscores and feedback and outperform alternative metrics, indicating their\npotential as multi-aspect, reference-free and interpretable evaluators for\ncounter narrative evaluation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "22 pages, camera-ready version; references added, typos corrected,\n  methodology section expanded, additional table",
    "pdf_url": "http://arxiv.org/pdf/2402.11676v2",
    "published_date": "2024-02-18 18:56:07 UTC",
    "updated_date": "2024-03-29 15:01:38 UTC"
  },
  {
    "arxiv_id": "2403.02342v2",
    "title": "Entanglement: Balancing Punishment and Compensation, Repeated Dilemma Game-Theoretic Analysis of Maximum Compensation Problem for Bypass and Least Cost Paths in Fact-Checking, Case of Fake News with Weak Wallace's Law",
    "authors": [
      "Yasuko Kawahata"
    ],
    "abstract": "This research note is organized with respect to a novel approach to solving\nproblems related to the spread of fake news and effective fact-checking.\nFocusing on the least-cost routing problem, the discussion is organized with\nrespect to the use of Metzler functions and Metzler matrices to model the\ndynamics of information propagation among news providers. With this approach,\nwe designed a strategy to minimize the spread of fake news, which is\ndetrimental to informational health, while at the same time maximizing the\nspread of credible information. In particular, through the punitive dominance\nproblem and the maximum compensation problem, we developed and examined a path\nto reassess the incentives of news providers to act and to analyze their impact\non the equilibrium of the information market. By applying the concept of\nentanglement to the context of information propagation, we shed light on the\ncomplexity of interactions among news providers and contribute to the\nformulation of more effective information management strategies. This study\nprovides new theoretical and practical insights into issues related to fake\nnews and fact-checking, and will be examined against improving informational\nhealth and public digital health.This paper is partially an attempt to utilize\n\"Generative AI\" and was written with educational intent. There are currently no\nplans for it to become a peer-reviewed paper.",
    "categories": [
      "physics.soc-ph",
      "cs.AI",
      "econ.TH"
    ],
    "primary_category": "physics.soc-ph",
    "comment": "Recurring Dilemma, Wallace's Law, Entanglement, Detour Path, Least\n  Cost Path, Metzler Function, Metzler Matrix, Fake News, Fact-Checking,\n  Punitive Dominance Problem, Maximum Compensation Problem, Informational\n  health",
    "pdf_url": "http://arxiv.org/pdf/2403.02342v2",
    "published_date": "2024-02-18 18:26:50 UTC",
    "updated_date": "2024-04-19 14:53:19 UTC"
  },
  {
    "arxiv_id": "2402.11671v1",
    "title": "Autocorrect for Estonian texts: final report from project EKTB25",
    "authors": [
      "Agnes Luhtaru",
      "Martin Vainikko",
      "Krista Liin",
      "Kais Allkivi-Metsoja",
      "Jaagup Kippar",
      "Pille Eslon",
      "Mark Fishel"
    ],
    "abstract": "The project was funded in 2021-2023 by the National Programme of Estonian\nLanguage Technology. Its main aim was to develop spelling and grammar\ncorrection tools for the Estonian language. The main challenge was the very\nsmall amount of available error correction data needed for such development. To\nmitigate this, (1) we annotated more correction data for model training and\ntesting, (2) we tested transfer-learning, i.e. retraining machine learning\nmodels created for other tasks, so as not to depend solely on correction data,\n(3) we compared the developed method and model with alternatives, including\nlarge language models. We also developed automatic evaluation, which can\ncalculate the accuracy and yield of corrections by error category, so that the\neffectiveness of different methods can be compared in detail.\n  There has been a breakthrough in large language models during the project:\nGPT4, a commercial language model with Estonian-language support, has been\ncreated. We took into account the existence of the model when adjusting plans\nand in the report we present a comparison with the ability of GPT4 to improve\nthe Estonian language text.\n  The final results show that the approach we have developed provides better\nscores than GPT4 and the result is usable but not entirely reliable yet. The\nreport also contains ideas on how GPT4 and other major language models can be\nimplemented in the future, focusing on open-source solutions.\n  All results of this project are open-data/open-source, with licenses that\nallow them to be used for purposes including commercial ones.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "in Estonian language",
    "pdf_url": "http://arxiv.org/pdf/2402.11671v1",
    "published_date": "2024-02-18 18:20:57 UTC",
    "updated_date": "2024-02-18 18:20:57 UTC"
  },
  {
    "arxiv_id": "2402.11658v3",
    "title": "Dynamic planning in hierarchical active inference",
    "authors": [
      "Matteo Priorelli",
      "Ivilin Peev Stoianov"
    ],
    "abstract": "By dynamic planning, we refer to the ability of the human brain to infer and\nimpose motor trajectories related to cognitive decisions. A recent paradigm,\nactive inference, brings fundamental insights into the adaptation of biological\norganisms, constantly striving to minimize prediction errors to restrict\nthemselves to life-compatible states. Over the past years, many studies have\nshown how human and animal behaviors could be explained in terms of active\ninference - either as discrete decision-making or continuous motor control -\ninspiring innovative solutions in robotics and artificial intelligence. Still,\nthe literature lacks a comprehensive outlook on effectively planning realistic\nactions in changing environments. Setting ourselves the goal of modeling\ncomplex tasks such as tool use, we delve into the topic of dynamic planning in\nactive inference, keeping in mind two crucial aspects of biological behavior:\nthe capacity to understand and exploit affordances for object manipulation, and\nto learn the hierarchical interactions between the self and the environment,\nincluding other agents. We start from a simple unit and gradually describe more\nadvanced structures, comparing recently proposed design choices and providing\nbasic examples. This study distances itself from traditional views centered on\nneural networks and reinforcement learning, and points toward a yet unexplored\ndirection in active inference: hybrid representations in hierarchical models.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.11658v3",
    "published_date": "2024-02-18 17:32:53 UTC",
    "updated_date": "2024-11-12 15:03:48 UTC"
  },
  {
    "arxiv_id": "2402.11653v2",
    "title": "Combinatorial Client-Master Multiagent Deep Reinforcement Learning for Task Offloading in Mobile Edge Computing",
    "authors": [
      "Tesfay Zemuy Gebrekidan",
      "Sebastian Stein",
      "Timothy J. Norman"
    ],
    "abstract": "Recently, there has been an explosion of mobile applications that perform\ncomputationally intensive tasks such as video streaming, data mining, virtual\nreality, augmented reality, image processing, video processing, face\nrecognition, and online gaming. However, user devices (UDs), such as tablets\nand smartphones, have a limited ability to perform the computation needs of the\ntasks. Mobile edge computing (MEC) has emerged as a promising technology to\nmeet the increasing computing demands of UDs. Task offloading in MEC is a\nstrategy that meets the demands of UDs by distributing tasks between UDs and\nMEC servers. Deep reinforcement learning (DRL) is gaining attention in\ntask-offloading problems because it can adapt to dynamic changes and minimize\nonline computational complexity. However, the various types of continuous and\ndiscrete resource constraints on UDs and MEC servers pose challenges to the\ndesign of an efficient DRL-based task-offloading strategy. Existing DRL-based\ntask-offloading algorithms focus on the constraints of the UDs, assuming the\navailability of enough storage resources on the server. Moreover, existing\nmultiagent DRL (MADRL)--based task-offloading algorithms are homogeneous agents\nand consider homogeneous constraints as a penalty in their reward function. We\nproposed a novel combinatorial client-master MADRL (CCM\\_MADRL) algorithm for\ntask offloading in MEC (CCM\\_MADRL\\_MEC) that enables UDs to decide their\nresource requirements and the server to make a combinatorial decision based on\nthe requirements of the UDs. CCM\\_MADRL\\_MEC is the first MADRL in task\noffloading to consider server storage capacity in addition to the constraints\nin the UDs. By taking advantage of the combinatorial action selection,\nCCM\\_MADRL\\_MEC has shown superior convergence over existing MADDPG and\nheuristic algorithms.",
    "categories": [
      "cs.AI",
      "cs.DC",
      "cs.NI",
      "I.2.11"
    ],
    "primary_category": "cs.AI",
    "comment": "12 pages, 5 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2402.11653v2",
    "published_date": "2024-02-18 17:17:15 UTC",
    "updated_date": "2024-11-06 20:27:34 UTC"
  },
  {
    "arxiv_id": "2402.11645v2",
    "title": "Image Denoising with Machine Learning: A Novel Approach to Improve Quantum Image Processing Quality and Reliability",
    "authors": [
      "Yifan Zhou",
      "Yan Shing Liang"
    ],
    "abstract": "Quantum Image Processing (QIP) is a field that aims to utilize the benefits\nof quantum computing for manipulating and analyzing images. However, QIP faces\ntwo challenges: the limitation of qubits and the presence of noise in a quantum\nmachine. In this research, we propose a novel approach to address the issue of\nnoise in QIP. By training and employing a machine learning model that\nidentifies and corrects the noise in quantum-processed images, we can\ncompensate for the noisiness caused by the machine and retrieve a processing\nresult similar to that performed by a classical computer with higher\nefficiency. The model is trained by learning a dataset consisting of both\nexisting processed images and quantum-processed images from open-access\ndatasets. This model will be capable of providing us with the confidence level\nfor each pixel and its potential original value. To assess the model's accuracy\nin compensating for loss and decoherence in QIP, we evaluate it using three\nmetrics: Peak Signal to Noise Ratio (PSNR), Structural Similarity Index (SSIM),\nand Mean Opinion Score (MOS). Additionally, we discuss the applicability of our\nmodel across domains well as its cost effectiveness compared to alternative\nmethods.",
    "categories": [
      "quant-ph",
      "cs.AI"
    ],
    "primary_category": "quant-ph",
    "comment": "9 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.11645v2",
    "published_date": "2024-02-18 16:55:54 UTC",
    "updated_date": "2024-09-26 05:15:00 UTC"
  },
  {
    "arxiv_id": "2402.14836v2",
    "title": "Stealthy Attack on Large Language Model based Recommendation",
    "authors": [
      "Jinghao Zhang",
      "Yuting Liu",
      "Qiang Liu",
      "Shu Wu",
      "Guibing Guo",
      "Liang Wang"
    ],
    "abstract": "Recently, the powerful large language models (LLMs) have been instrumental in\npropelling the progress of recommender systems (RS). However, while these\nsystems have flourished, their susceptibility to security threats has been\nlargely overlooked. In this work, we reveal that the introduction of LLMs into\nrecommendation models presents new security vulnerabilities due to their\nemphasis on the textual content of items. We demonstrate that attackers can\nsignificantly boost an item's exposure by merely altering its textual content\nduring the testing phase, without requiring direct interference with the\nmodel's training process. Additionally, the attack is notably stealthy, as it\ndoes not affect the overall recommendation performance and the modifications to\nthe text are subtle, making it difficult for users and platforms to detect. Our\ncomprehensive experiments across four mainstream LLM-based recommendation\nmodels demonstrate the superior efficacy and stealthiness of our approach. Our\nwork unveils a significant security gap in LLM-based recommendation systems and\npaves the way for future research on protecting these systems.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "ACL 2024 Main",
    "pdf_url": "http://arxiv.org/pdf/2402.14836v2",
    "published_date": "2024-02-18 16:51:02 UTC",
    "updated_date": "2024-06-05 17:02:47 UTC"
  },
  {
    "arxiv_id": "2402.11639v2",
    "title": "In-Context Learning with Transformers: Softmax Attention Adapts to Function Lipschitzness",
    "authors": [
      "Liam Collins",
      "Advait Parulekar",
      "Aryan Mokhtari",
      "Sujay Sanghavi",
      "Sanjay Shakkottai"
    ],
    "abstract": "A striking property of transformers is their ability to perform in-context\nlearning (ICL), a machine learning framework in which the learner is presented\nwith a novel context during inference implicitly through some data, and tasked\nwith making a prediction in that context. As such, that learner must adapt to\nthe context without additional training. We explore the role of softmax\nattention in an ICL setting where each context encodes a regression task. We\nshow that an attention unit learns a window that it uses to implement a\nnearest-neighbors predictor adapted to the landscape of the pretraining tasks.\nSpecifically, we show that this window widens with decreasing Lipschitzness and\nincreasing label noise in the pretraining tasks. We also show that on low-rank,\nlinear problems, the attention unit learns to project onto the appropriate\nsubspace before inference. Further, we show that this adaptivity relies\ncrucially on the softmax activation and thus cannot be replicated by the linear\nactivation often studied in prior theoretical analyses.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.11639v2",
    "published_date": "2024-02-18 16:37:32 UTC",
    "updated_date": "2024-05-28 05:15:53 UTC"
  },
  {
    "arxiv_id": "2403.00783v2",
    "title": "On the Roles of LLMs in Planning: Embedding LLMs into Planning Graphs",
    "authors": [
      "Hankz Hankui Zhuo",
      "Xin Chen",
      "Rong Pan"
    ],
    "abstract": "Plan synthesis aims to generate a course of actions or policies to transit\ngiven initial states to goal states, provided domain models that could be\ndesigned by experts or learnt from training data or interactions with the\nworld. Intrigued by the claims of emergent planning capabilities in large\nlanguage models (LLMs), works have been proposed to investigate the planning\neffectiveness of LLMs, without considering any utilization of off-the-shelf\nplanning techniques in LLMs. In this paper, we aim to further study the insight\nof the planning capability of LLMs by investigating the roles of LLMs in\noff-the-shelf planning frameworks. To do this, we investigate the effectiveness\nof embedding LLMs into one of the well-known planning frameworks, graph-based\nplanning, proposing a novel LLMs-based planning framework with LLMs embedded in\ntwo levels of planning graphs, i.e., mutual constraints generation level and\nconstraints solving level. We empirically exhibit the effectiveness of our\nproposed framework in various planning domains.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.00783v2",
    "published_date": "2024-02-18 15:53:32 UTC",
    "updated_date": "2024-07-26 11:54:04 UTC"
  },
  {
    "arxiv_id": "2402.11622v2",
    "title": "Logical Closed Loop: Uncovering Object Hallucinations in Large Vision-Language Models",
    "authors": [
      "Junfei Wu",
      "Qiang Liu",
      "Ding Wang",
      "Jinghao Zhang",
      "Shu Wu",
      "Liang Wang",
      "Tieniu Tan"
    ],
    "abstract": "Object hallucination has been an Achilles' heel which hinders the broader\napplications of large vision-language models (LVLMs). Object hallucination\nrefers to the phenomenon that the LVLMs claim non-existent objects in the\nimage. To mitigate the object hallucinations, instruction tuning and external\nmodel-based detection methods have been proposed, which either require\nlarge-scare computational resources or depend on the detection result of\nexternal models. However, there remains an under-explored field to utilize the\nLVLM itself to alleviate object hallucinations. In this work, we adopt the\nintuition that the LVLM tends to respond logically consistently for existent\nobjects but inconsistently for hallucinated objects. Therefore, we propose a\nLogical Closed Loop-based framework for Object Hallucination Detection and\nMitigation, namely LogicCheckGPT. In specific, we devise logical consistency\nprobing to raise questions with logical correlations, inquiring about\nattributes from objects and vice versa. Whether their responses can form a\nlogical closed loop serves as an indicator of object hallucination. As a\nplug-and-play method, it can be seamlessly applied to all existing LVLMs.\nComprehensive experiments conducted on three benchmarks across four LVLMs have\ndemonstrated significant improvements brought by our method, indicating its\neffectiveness and generality.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accept to ACL 2024; 19 Pages, 15 Figures, 6 Tables",
    "pdf_url": "http://arxiv.org/pdf/2402.11622v2",
    "published_date": "2024-02-18 15:28:39 UTC",
    "updated_date": "2024-06-28 07:20:22 UTC"
  },
  {
    "arxiv_id": "2402.11594v1",
    "title": "Simplifying Hyperparameter Tuning in Online Machine Learning -- The spotRiverGUI",
    "authors": [
      "Thomas Bartz-Beielstein"
    ],
    "abstract": "Batch Machine Learning (BML) reaches its limits when dealing with very large\namounts of streaming data. This is especially true for available memory,\nhandling drift in data streams, and processing new, unknown data. Online\nMachine Learning (OML) is an alternative to BML that overcomes the limitations\nof BML. OML is able to process data in a sequential manner, which is especially\nuseful for data streams. The `river` package is a Python OML-library, which\nprovides a variety of online learning algorithms for classification,\nregression, clustering, anomaly detection, and more. The `spotRiver` package\nprovides a framework for hyperparameter tuning of OML models. The\n`spotRiverGUI` is a graphical user interface for the `spotRiver` package. The\n`spotRiverGUI` releases the user from the burden of manually searching for the\noptimal hyperparameter setting. After the data is provided, users can compare\ndifferent OML algorithms from the powerful `river` package in a convenient way\nand tune the selected algorithms very efficiently.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "90C26",
      "I.2.6; G.1.6"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.11594v1",
    "published_date": "2024-02-18 14:12:15 UTC",
    "updated_date": "2024-02-18 14:12:15 UTC"
  },
  {
    "arxiv_id": "2402.11588v2",
    "title": "SDiT: Spiking Diffusion Model with Transformer",
    "authors": [
      "Shu Yang",
      "Hanzhi Ma",
      "Chengting Yu",
      "Aili Wang",
      "Er-Ping Li"
    ],
    "abstract": "Spiking neural networks (SNNs) have low power consumption and\nbio-interpretable characteristics, and are considered to have tremendous\npotential for energy-efficient computing. However, the exploration of SNNs on\nimage generation tasks remains very limited, and a unified and effective\nstructure for SNN-based generative models has yet to be proposed. In this\npaper, we explore a novel diffusion model architecture within spiking neural\nnetworks. We utilize transformer to replace the commonly used U-net structure\nin mainstream diffusion models. It can generate higher quality images with\nrelatively lower computational cost and shorter sampling time. It aims to\nprovide an empirical baseline for research of generative models based on SNNs.\nExperiments on MNIST, Fashion-MNIST, and CIFAR-10 datasets demonstrate that our\nwork is highly competitive compared to existing SNN generative models.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.11588v2",
    "published_date": "2024-02-18 13:42:11 UTC",
    "updated_date": "2024-02-24 07:24:09 UTC"
  },
  {
    "arxiv_id": "2402.16880v2",
    "title": "BESA: Pruning Large Language Models with Blockwise Parameter-Efficient Sparsity Allocation",
    "authors": [
      "Peng Xu",
      "Wenqi Shao",
      "Mengzhao Chen",
      "Shitao Tang",
      "Kaipeng Zhang",
      "Peng Gao",
      "Fengwei An",
      "Yu Qiao",
      "Ping Luo"
    ],
    "abstract": "Large language models (LLMs) have demonstrated outstanding performance in\nvarious tasks, such as text summarization, text question-answering, and etc.\nWhile their performance is impressive, the computational footprint due to their\nvast number of parameters can be prohibitive. Existing solutions such as\nSparseGPT and Wanda attempt to alleviate this issue through weight pruning.\nHowever, their layer-wise approach results in significant perturbation to the\nmodel's output and requires meticulous hyperparameter tuning, such as the\npruning rate, which can adversely affect overall model performance. To address\nthis, this paper introduces a novel LLM pruning technique dubbed blockwise\nparameter-efficient sparsity allocation (BESA) by applying a blockwise\nreconstruction loss. In contrast to the typical layer-wise pruning techniques,\nBESA is characterized by two distinctive attributes: i) it targets the overall\npruning error with respect to individual transformer blocks, and ii) it\nallocates layer-specific sparsity in a differentiable manner, both of which\nensure reduced performance degradation after pruning. Our experiments show that\nBESA achieves state-of-the-art performance, efficiently pruning LLMs like\nLLaMA1, and LLaMA2 with 7B to 70B parameters on a single A100 GPU in just five\nhours. Code is available at https://github.com/OpenGVLab/LLMPrune-BESA.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.16880v2",
    "published_date": "2024-02-18 12:44:15 UTC",
    "updated_date": "2024-04-19 07:54:27 UTC"
  },
  {
    "arxiv_id": "2402.11571v1",
    "title": "Ain't Misbehavin' -- Using LLMs to Generate Expressive Robot Behavior in Conversations with the Tabletop Robot Haru",
    "authors": [
      "Zining Wang",
      "Paul Reisert",
      "Eric Nichols",
      "Randy Gomez"
    ],
    "abstract": "Social robots aim to establish long-term bonds with humans through engaging\nconversation. However, traditional conversational approaches, reliant on\nscripted interactions, often fall short in maintaining engaging conversations.\nThis paper addresses this limitation by integrating large language models\n(LLMs) into social robots to achieve more dynamic and expressive conversations.\nWe introduce a fully-automated conversation system that leverages LLMs to\ngenerate robot responses with expressive behaviors, congruent with the robot's\npersonality. We incorporate robot behavior with two modalities: 1) a\ntext-to-speech (TTS) engine capable of various delivery styles, and 2) a\nlibrary of physical actions for the robot. We develop a custom,\nstate-of-the-art emotion recognition model to dynamically select the robot's\ntone of voice and utilize emojis from LLM output as cues for generating robot\nactions. A demo of our system is available here. To illuminate design and\nimplementation issues, we conduct a pilot study where volunteers chat with a\nsocial robot using our proposed system, and we analyze their feedback,\nconducting a rigorous error analysis of chat transcripts. Feedback was\noverwhelmingly positive, with participants commenting on the robot's empathy,\nhelpfulness, naturalness, and entertainment. Most negative feedback was due to\nautomatic speech recognition (ASR) errors which had limited impact on\nconversations. However, we observed a small class of errors, such as the LLM\nrepeating itself or hallucinating fictitious information and human responses,\nthat have the potential to derail conversations, raising important issues for\nLLM application.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted as Late Breaking Report (LBR) at the 19th Annual ACM/IEEE\n  International Conference on Human Robot Interaction (HRI '24)",
    "pdf_url": "http://arxiv.org/pdf/2402.11571v1",
    "published_date": "2024-02-18 12:35:52 UTC",
    "updated_date": "2024-02-18 12:35:52 UTC"
  },
  {
    "arxiv_id": "2402.11569v1",
    "title": "Developing Autonomous Robot-Mediated Behavior Coaching Sessions with Haru",
    "authors": [
      "Matouš Jelínek",
      "Eric Nichols",
      "Randy Gomez"
    ],
    "abstract": "This study presents an empirical investigation into the design and impact of\nautonomous dialogues in human-robot interaction for behavior change coaching.\nWe focus on the use of Haru, a tabletop social robot, and explore the\nimplementation of the Tiny Habits method for fostering positive behavior\nchange. The core of our study lies in developing a fully autonomous dialogue\nsystem that maximizes Haru's emotional expressiveness and unique personality.\nOur methodology involved iterative design and extensive testing of the dialogue\nsystem, ensuring it effectively embodied the principles of the Tiny Habits\nmethod while also incorporating strategies for trust-raising and\ntrust-dampening. The effectiveness of the final version of the dialogue was\nevaluated in an experimental study with human participants (N=12). The results\nindicated a significant improvement in perceptions of Haru's liveliness,\ninteractivity, and neutrality. Additionally, our study contributes to the\nbroader understanding of dialogue design in social robotics, offering practical\ninsights for future developments in the field.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted as Late Breaking Report (LBR) at the 19th Annual ACM/IEEE\n  International Conference on Human Robot Interaction (HRI '24)",
    "pdf_url": "http://arxiv.org/pdf/2402.11569v1",
    "published_date": "2024-02-18 12:33:54 UTC",
    "updated_date": "2024-02-18 12:33:54 UTC"
  },
  {
    "arxiv_id": "2402.11565v1",
    "title": "Continual Learning on Graphs: Challenges, Solutions, and Opportunities",
    "authors": [
      "Xikun Zhang",
      "Dongjin Song",
      "Dacheng Tao"
    ],
    "abstract": "Continual learning on graph data has recently attracted paramount attention\nfor its aim to resolve the catastrophic forgetting problem on existing tasks\nwhile adapting the sequentially updated model to newly emerged graph tasks.\nWhile there have been efforts to summarize progress on continual learning\nresearch over Euclidean data, e.g., images and texts, a systematic review of\nprogress in continual learning on graphs, a.k.a, continual graph learning (CGL)\nor lifelong graph learning, is still demanding. Graph data are far more complex\nin terms of data structures and application scenarios, making CGL task\nsettings, model designs, and applications extremely challenging. To bridge the\ngap, we provide a comprehensive review of existing continual graph learning\n(CGL) algorithms by elucidating the different task settings and categorizing\nthe existing methods based on their characteristics. We compare the CGL methods\nwith traditional continual learning techniques and analyze the applicability of\nthe traditional continual learning techniques to CGL tasks. Additionally, we\nreview the benchmark works that are crucial to CGL research. Finally, we\ndiscuss the remaining challenges and propose several future directions. We will\nmaintain an up-to-date GitHub repository featuring a comprehensive list of CGL\nalgorithms, accessible at\nhttps://github.com/UConn-DSIS/Survey-of-Continual-Learning-on-Graphs.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.11565v1",
    "published_date": "2024-02-18 12:24:45 UTC",
    "updated_date": "2024-02-18 12:24:45 UTC"
  },
  {
    "arxiv_id": "2402.11550v2",
    "title": "LongAgent: Scaling Language Models to 128k Context through Multi-Agent Collaboration",
    "authors": [
      "Jun Zhao",
      "Can Zu",
      "Hao Xu",
      "Yi Lu",
      "Wei He",
      "Yiwen Ding",
      "Tao Gui",
      "Qi Zhang",
      "Xuanjing Huang"
    ],
    "abstract": "Large language models (LLMs) have demonstrated impressive performance in\nunderstanding language and executing complex reasoning tasks. However, LLMs\nwith long context windows have been notorious for their expensive training\ncosts and high inference latency. Even the most advanced models such as GPT-4\nand Claude2 often make mistakes when processing inputs of over $100k$ tokens, a\nphenomenon also known as \\textit{lost in the middle}. In this paper, we propose\n\\textsc{LongAgent}, a method based on multi-agent collaboration, which scales\nLLMs (e.g., LLaMA) to a context of 128K and demonstrates potential superiority\nin long-text processing compared to GPT-4. In \\textsc{LongAgent}, a leader is\nresponsible for understanding user intent and directing team members to acquire\ninformation from documents. Due to members' hallucinations, it is non-trivial\nfor a leader to obtain accurate information from the responses of dozens to\nhundreds of members. To address this, we develop an \\textit{inter-member\ncommunication} mechanism to resolve response conflicts caused by hallucinations\nthrough information sharing. Our experimental results indicate that\n\\textsc{LongAgent} offers a promising alternative for long-text processing. The\nagent team instantiated with LLaMA-7B achieves significant improvements in\ntasks such as 128k-long text retrieval, multi-hop question answering, compared\nto GPT-4.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.11550v2",
    "published_date": "2024-02-18 11:46:52 UTC",
    "updated_date": "2024-03-13 07:16:42 UTC"
  },
  {
    "arxiv_id": "2402.11549v2",
    "title": "Syntactic Language Change in English and German: Metrics, Parsers, and Convergences",
    "authors": [
      "Yanran Chen",
      "Wei Zhao",
      "Anne Breitbarth",
      "Manuel Stoeckel",
      "Alexander Mehler",
      "Steffen Eger"
    ],
    "abstract": "Many studies have shown that human languages tend to optimize for lower\ncomplexity and increased communication efficiency. Syntactic dependency\ndistance, which measures the linear distance between dependent words, is often\nconsidered a key indicator of language processing difficulty and working memory\nload. The current paper looks at diachronic trends in syntactic language change\nin both English and German, using corpora of parliamentary debates from the\nlast c. 160 years. We base our observations on five dependency parsers,\nincluding the widely used Stanford CoreNLP as well as 4 newer alternatives. Our\nanalysis of syntactic language change goes beyond linear dependency distance\nand explores 15 metrics relevant to dependency distance minimization (DDM)\nand/or based on tree graph properties, such as the tree height and degree\nvariance. Even though we have evidence that recent parsers trained on modern\ntreebanks are not heavily affected by data 'noise' such as spelling changes and\nOCR errors in our historic data, we find that results of syntactic language\nchange are sensitive to the parsers involved, which is a caution against using\na single parser for evaluating syntactic language change as done in previous\nwork. We also show that syntactic language change over the time period\ninvestigated is largely similar between English and German for the different\nmetrics explored: only 4% of cases we examine yield opposite conclusions\nregarding upwards and downtrends of syntactic metrics across German and\nEnglish. We also show that changes in syntactic measures seem to be more\nfrequent at the tails of sentence length distributions. To our best knowledge,\nours is the most comprehensive analysis of syntactic language change using\nmodern NLP technology in recent corpora of English and German.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Updated to the current version",
    "pdf_url": "http://arxiv.org/pdf/2402.11549v2",
    "published_date": "2024-02-18 11:46:16 UTC",
    "updated_date": "2024-03-28 11:16:28 UTC"
  },
  {
    "arxiv_id": "2402.12408v1",
    "title": "ModelGPT: Unleashing LLM's Capabilities for Tailored Model Generation",
    "authors": [
      "Zihao Tang",
      "Zheqi Lv",
      "Shengyu Zhang",
      "Fei Wu",
      "Kun Kuang"
    ],
    "abstract": "The rapid advancement of Large Language Models (LLMs) has revolutionized\nvarious sectors by automating routine tasks, marking a step toward the\nrealization of Artificial General Intelligence (AGI). However, they still\nstruggle to accommodate the diverse and specific needs of users and simplify\nthe utilization of AI models for the average user. In response, we propose\nModelGPT, a novel framework designed to determine and generate AI models\nspecifically tailored to the data or task descriptions provided by the user,\nleveraging the capabilities of LLMs. Given user requirements, ModelGPT is able\nto provide tailored models at most 270x faster than the previous paradigms\n(e.g. all-parameter or LoRA finetuning). Comprehensive experiments on NLP, CV,\nand Tabular datasets attest to the effectiveness of our framework in making AI\nmodels more accessible and user-friendly. Our code is available at\nhttps://github.com/IshiKura-a/ModelGPT.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.12408v1",
    "published_date": "2024-02-18 11:24:34 UTC",
    "updated_date": "2024-02-18 11:24:34 UTC"
  },
  {
    "arxiv_id": "2402.11542v1",
    "title": "Question Answering Over Spatio-Temporal Knowledge Graph",
    "authors": [
      "Xinbang Dai",
      "Huiying Li",
      "Guilin Qi"
    ],
    "abstract": "Spatio-temporal knowledge graphs (STKGs) extend the concept of knowledge\ngraphs (KGs) by incorporating time and location information. While the research\ncommunity's focus on Knowledge Graph Question Answering (KGQA), the field of\nanswering questions incorporating both spatio-temporal information based on\nSTKGs remains largely unexplored. Furthermore, a lack of comprehensive datasets\nalso has hindered progress in this area. To address this issue, we present\nSTQAD, a dataset comprising 10,000 natural language questions for\nspatio-temporal knowledge graph question answering (STKGQA). Unfortunately,\nvarious state-of-the-art KGQA approaches fall far short of achieving\nsatisfactory performance on our dataset. In response, we propose STCQA, a new\nspatio-temporal KGQA approach that utilizes a novel STKG embedding method named\nSTComplEx. By extracting temporal and spatial information from a question, our\nQA model can better comprehend the question and retrieve accurate answers from\nthe STKG. Through extensive experiments, we demonstrate the quality of our\ndataset and the effectiveness of our STKGQA method.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.4; I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "11 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.11542v1",
    "published_date": "2024-02-18 10:44:48 UTC",
    "updated_date": "2024-02-18 10:44:48 UTC"
  },
  {
    "arxiv_id": "2402.11541v4",
    "title": "Large Language Models Can Better Understand Knowledge Graphs Than We Thought",
    "authors": [
      "Xinbang Dai",
      "Yuncheng Hua",
      "Tongtong Wu",
      "Yang Sheng",
      "Qiu Ji",
      "Guilin Qi"
    ],
    "abstract": "When we integrate factual knowledge from knowledge graphs (KGs) into large\nlanguage models (LLMs) to enhance their performance, the cost of injection\nthrough training increases with the scale of the models. Consequently, there is\nsignificant interest in developing prompt strategies that effectively\nincorporate KG information into LLMs. However, the community has not yet\ncomprehensively understood how LLMs process and interpret KG information in\ndifferent input formats and organizations within prompts, and researchers often\nrely on trial and error. To address this gap, we design extensive experiments\nto empirically study LLMs' comprehension of different KG prompts. At the\nliteral level, we reveal LLMs' preferences for various input formats (from\nlinearized triples to fluent natural language text). At the attention\ndistribution level, we discuss the underlying mechanisms driving these\npreferences. We then investigate how the organization of structured knowledge\nimpacts LLMs and evaluate LLMs' robustness in processing and utilizing KG\ninformation in practical scenarios. Our experiments show that (1) linearized\ntriples are more effective than fluent NL text in helping LLMs understand KG\ninformation and answer fact-intensive questions; (2) Different LLMs exhibit\nvarying preferences for different organizational formats of triples; (3) LLMs\nwith larger scales are more susceptible to noisy, incomplete subgraphs.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.4; I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "24 pages",
    "pdf_url": "http://arxiv.org/pdf/2402.11541v4",
    "published_date": "2024-02-18 10:44:03 UTC",
    "updated_date": "2025-01-23 07:21:35 UTC"
  },
  {
    "arxiv_id": "2402.11537v3",
    "title": "Deciphering the Impact of Pretraining Data on Large Language Models through Machine Unlearning",
    "authors": [
      "Yang Zhao",
      "Li Du",
      "Xiao Ding",
      "Kai Xiong",
      "Zhouhao Sun",
      "Jun Shi",
      "Ting Liu",
      "Bing Qin"
    ],
    "abstract": "Through pretraining on a corpus with various sources, Large Language Models\n(LLMs) have gained impressive performance. However, the impact of each\ncomponent of the pretraining corpus remains opaque. As a result, the\norganization of the pretraining corpus is still empirical and may deviate from\nthe optimal. To address this issue, we systematically analyze the impact of 48\ndatasets from 5 major categories of pretraining data of LLMs and measure their\nimpacts on LLMs using benchmarks about nine major categories of model\ncapabilities. Our analyses provide empirical results about the contribution of\nmultiple corpora on the performances of LLMs, along with their joint impact\npatterns, including complementary, orthogonal, and correlational relationships.\nWe also identify a set of ``high-impact data'' such as Books that is\nsignificantly related to a set of model capabilities. These findings provide\ninsights into the organization of data to support more efficient pretraining of\nLLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by ACL 2024 Findings",
    "pdf_url": "http://arxiv.org/pdf/2402.11537v3",
    "published_date": "2024-02-18 10:36:05 UTC",
    "updated_date": "2024-08-28 10:39:11 UTC"
  },
  {
    "arxiv_id": "2403.00782v1",
    "title": "Ploutos: Towards interpretable stock movement prediction with financial large language model",
    "authors": [
      "Hanshuang Tong",
      "Jun Li",
      "Ning Wu",
      "Ming Gong",
      "Dongmei Zhang",
      "Qi Zhang"
    ],
    "abstract": "Recent advancements in large language models (LLMs) have opened new pathways\nfor many domains. However, the full potential of LLMs in financial investments\nremains largely untapped. There are two main challenges for typical deep\nlearning-based methods for quantitative finance. First, they struggle to fuse\ntextual and numerical information flexibly for stock movement prediction.\nSecond, traditional methods lack clarity and interpretability, which impedes\ntheir application in scenarios where the justification for predictions is\nessential. To solve the above challenges, we propose Ploutos, a novel financial\nLLM framework that consists of PloutosGen and PloutosGPT. The PloutosGen\ncontains multiple primary experts that can analyze different modal data, such\nas text and numbers, and provide quantitative strategies from different\nperspectives. Then PloutosGPT combines their insights and predictions and\ngenerates interpretable rationales. To generate accurate and faithful\nrationales, the training strategy of PloutosGPT leverage rearview-mirror\nprompting mechanism to guide GPT-4 to generate rationales, and a dynamic token\nweighting mechanism to finetune LLM by increasing key tokens weight. Extensive\nexperiments show our framework outperforms the state-of-the-art methods on both\nprediction accuracy and interpretability.",
    "categories": [
      "q-fin.ST",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "q-fin.ST",
    "comment": "8 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.00782v1",
    "published_date": "2024-02-18 10:28:18 UTC",
    "updated_date": "2024-02-18 10:28:18 UTC"
  },
  {
    "arxiv_id": "2402.11534v2",
    "title": "PreAct: Prediction Enhances Agent's Planning Ability",
    "authors": [
      "Dayuan Fu",
      "Jianzhao Huang",
      "Siyuan Lu",
      "Guanting Dong",
      "Yejie Wang",
      "Keqing He",
      "Weiran Xu"
    ],
    "abstract": "Addressing the disparity between forecasts and actual results can enable\nindividuals to expand their thought processes and stimulate self-reflection,\nthus promoting accurate planning. In this research, we present **PreAct**, an\nagent framework that integrates **pre**diction, **rea**soning, and **act**ion.\nBy utilizing the information derived from predictions, the large language model\n(LLM) agent can provide a wider range and more strategically focused reasoning.\nThis leads to more efficient actions that aid the agent in accomplishing\nintricate tasks. Our experimental results show that PreAct surpasses the ReAct\nmethod in completing complex tasks and that PreAct's performance can be further\nimproved when paired with other memory or selection strategy techniques. We\npresented the model with varying quantities of historical predictions and\ndiscovered that these predictions consistently enhance LLM planning.The\nvariances in single-step reasoning between PreAct and ReAct indicate that\nPreAct indeed has benefits in terms of diversity and strategic orientation over\nReAct.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Coling 2025",
    "pdf_url": "http://arxiv.org/pdf/2402.11534v2",
    "published_date": "2024-02-18 10:15:38 UTC",
    "updated_date": "2024-12-05 04:40:54 UTC"
  },
  {
    "arxiv_id": "2402.11523v1",
    "title": "Neighborhood-Enhanced Supervised Contrastive Learning for Collaborative Filtering",
    "authors": [
      "Peijie Sun",
      "Le Wu",
      "Kun Zhang",
      "Xiangzhi Chen",
      "Meng Wang"
    ],
    "abstract": "While effective in recommendation tasks, collaborative filtering (CF)\ntechniques face the challenge of data sparsity. Researchers have begun\nleveraging contrastive learning to introduce additional self-supervised signals\nto address this. However, this approach often unintentionally distances the\ntarget user/item from their collaborative neighbors, limiting its efficacy. In\nresponse, we propose a solution that treats the collaborative neighbors of the\nanchor node as positive samples within the final objective loss function. This\npaper focuses on developing two unique supervised contrastive loss functions\nthat effectively combine supervision signals with contrastive loss. We analyze\nour proposed loss functions through the gradient lens, demonstrating that\ndifferent positive samples simultaneously influence updating the anchor node's\nembeddings. These samples' impact depends on their similarities to the anchor\nnode and the negative samples. Using the graph-based collaborative filtering\nmodel as our backbone and following the same data augmentation methods as the\nexisting contrastive learning model SGL, we effectively enhance the performance\nof the recommendation model. Our proposed Neighborhood-Enhanced Supervised\nContrastive Loss (NESCL) model substitutes the contrastive loss function in SGL\nwith our novel loss function, showing marked performance improvement. On three\nreal-world datasets, Yelp2018, Gowalla, and Amazon-Book, our model surpasses\nthe original SGL by 10.09%, 7.09%, and 35.36% on NDCG@20, respectively.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.11523v1",
    "published_date": "2024-02-18 09:46:51 UTC",
    "updated_date": "2024-02-18 09:46:51 UTC"
  },
  {
    "arxiv_id": "2402.11505v2",
    "title": "Federated Fine-tuning of Large Language Models under Heterogeneous Tasks and Client Resources",
    "authors": [
      "Jiamu Bai",
      "Daoyuan Chen",
      "Bingchen Qian",
      "Liuyi Yao",
      "Yaliang Li"
    ],
    "abstract": "Federated Learning (FL) has recently been applied to the parameter-efficient\nfine-tuning of Large Language Models (LLMs). While promising, it raises\nsignificant challenges due to the heterogeneous resources and data\ndistributions of clients. This study introduces FlexLoRA, a simple yet\neffective aggregation scheme for LLM fine-tuning, which mitigates the ``bucket\neffect'' in traditional FL that restricts the potential of clients with ample\nresources by tying them to the capabilities of the least-resourced\nparticipants. FlexLoRA allows for dynamic adjustment of local LoRA ranks,\nfostering the development of a global model imbued with broader, less\ntask-specific knowledge. By synthesizing a full-size LoRA weight from\nindividual client contributions and employing Singular Value Decomposition\n(SVD) for weight redistribution, FlexLoRA fully leverages heterogeneous client\nresources. Involving thousands of clients performing heterogeneous NLP tasks\nand client resources, our experiments validate the efficacy of FlexLoRA, with\nthe federated global model achieving consistently better improvement over SOTA\nFL methods in downstream NLP task performance across various heterogeneous\ndistributions. FlexLoRA's practicality is further underscored by our\ntheoretical analysis and its seamless integration with existing LoRA-based FL\nmethods, offering a path toward cross-device, privacy-preserving federated\ntuning for LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "19 pages, 13 tables, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.11505v2",
    "published_date": "2024-02-18 08:32:59 UTC",
    "updated_date": "2024-05-30 15:46:10 UTC"
  },
  {
    "arxiv_id": "2402.12406v1",
    "title": "Teacher as a Lenient Expert: Teacher-Agnostic Data-Free Knowledge Distillation",
    "authors": [
      "Hyunjune Shin",
      "Dong-Wan Choi"
    ],
    "abstract": "Data-free knowledge distillation (DFKD) aims to distill pretrained knowledge\nto a student model with the help of a generator without using original data. In\nsuch data-free scenarios, achieving stable performance of DFKD is essential due\nto the unavailability of validation data. Unfortunately, this paper has\ndiscovered that existing DFKD methods are quite sensitive to different teacher\nmodels, occasionally showing catastrophic failures of distillation, even when\nusing well-trained teacher models. Our observation is that the generator in\nDFKD is not always guaranteed to produce precise yet diverse samples using the\nexisting representative strategy of minimizing both class-prior and adversarial\nlosses. Through our empirical study, we focus on the fact that class-prior not\nonly decreases the diversity of generated samples, but also cannot completely\naddress the problem of generating unexpectedly low-quality samples depending on\nteacher models. In this paper, we propose the teacher-agnostic data-free\nknowledge distillation (TA-DFKD) method, with the goal of more robust and\nstable performance regardless of teacher models. Our basic idea is to assign\nthe teacher model a lenient expert role for evaluating samples, rather than a\nstrict supervisor that enforces its class-prior on the generator. Specifically,\nwe design a sample selection approach that takes only clean samples verified by\nthe teacher model without imposing restrictions on the power of generating\ndiverse samples. Through extensive experiments, we show that our method\nsuccessfully achieves both robustness and training stability across various\nteacher models, while outperforming the existing DFKD methods.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted in AAAI-2024",
    "pdf_url": "http://arxiv.org/pdf/2402.12406v1",
    "published_date": "2024-02-18 08:13:57 UTC",
    "updated_date": "2024-02-18 08:13:57 UTC"
  },
  {
    "arxiv_id": "2402.11498v3",
    "title": "Verifiably Following Complex Robot Instructions with Foundation Models",
    "authors": [
      "Benedict Quartey",
      "Eric Rosen",
      "Stefanie Tellex",
      "George Konidaris"
    ],
    "abstract": "When instructing robots, users want to flexibly express constraints, refer to\narbitrary landmarks, and verify robot behavior, while robots must disambiguate\ninstructions into specifications and ground instruction referents in the real\nworld. To address this problem, we propose Language Instruction grounding for\nMotion Planning (LIMP), an approach that enables robots to verifiably follow\ncomplex, open-ended instructions in real-world environments without prebuilt\nsemantic maps. LIMP constructs a symbolic instruction representation that\nreveals the robot's alignment with an instructor's intended motives and affords\nthe synthesis of correct-by-construction robot behaviors. We conduct a\nlarge-scale evaluation of LIMP on 150 instructions across five real-world\nenvironments, demonstrating its versatility and ease of deployment in diverse,\nunstructured domains. LIMP performs comparably to state-of-the-art baselines on\nstandard open-vocabulary tasks and additionally achieves a 79\\% success rate on\ncomplex spatiotemporal instructions, significantly outperforming baselines that\nonly reach 38\\%. See supplementary materials and demo videos at\nhttps://robotlimp.github.io",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.11498v3",
    "published_date": "2024-02-18 08:05:54 UTC",
    "updated_date": "2025-03-30 03:37:48 UTC"
  },
  {
    "arxiv_id": "2402.11485v2",
    "title": "LEIA: Facilitating Cross-lingual Knowledge Transfer in Language Models with Entity-based Data Augmentation",
    "authors": [
      "Ikuya Yamada",
      "Ryokan Ri"
    ],
    "abstract": "Adapting English-based large language models (LLMs) to other languages has\nbecome increasingly popular due to the efficiency and potential of\ncross-lingual transfer. However, existing language adaptation methods often\noverlook the benefits of cross-lingual supervision. In this study, we introduce\nLEIA, a language adaptation tuning method that utilizes Wikipedia entity names\naligned across languages. This method involves augmenting the target language\ncorpus with English entity names and training the model using left-to-right\nlanguage modeling. We assess LEIA on diverse question answering datasets using\n7B-parameter LLMs, demonstrating significant performance gains across various\nnon-English languages. The source code is available at\nhttps://github.com/studio-ousia/leia.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "ACL Findings 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.11485v2",
    "published_date": "2024-02-18 07:24:34 UTC",
    "updated_date": "2024-06-06 05:30:59 UTC"
  },
  {
    "arxiv_id": "2402.14835v1",
    "title": "MIKE: A New Benchmark for Fine-grained Multimodal Entity Knowledge Editing",
    "authors": [
      "Jiaqi Li",
      "Miaozeng Du",
      "Chuanyi Zhang",
      "Yongrui Chen",
      "Nan Hu",
      "Guilin Qi",
      "Haiyun Jiang",
      "Siyuan Cheng",
      "Bozhong Tian"
    ],
    "abstract": "Multimodal knowledge editing represents a critical advancement in enhancing\nthe capabilities of Multimodal Large Language Models (MLLMs). Despite its\npotential, current benchmarks predominantly focus on coarse-grained knowledge,\nleaving the intricacies of fine-grained (FG) multimodal entity knowledge\nlargely unexplored. This gap presents a notable challenge, as FG entity\nrecognition is pivotal for the practical deployment and effectiveness of MLLMs\nin diverse real-world scenarios. To bridge this gap, we introduce MIKE, a\ncomprehensive benchmark and dataset specifically designed for the FG multimodal\nentity knowledge editing. MIKE encompasses a suite of tasks tailored to assess\ndifferent perspectives, including Vanilla Name Answering, Entity-Level Caption,\nand Complex-Scenario Recognition. In addition, a new form of knowledge editing,\nMulti-step Editing, is introduced to evaluate the editing efficiency. Through\nour extensive evaluations, we demonstrate that the current state-of-the-art\nmethods face significant challenges in tackling our proposed benchmark,\nunderscoring the complexity of FG knowledge editing in MLLMs. Our findings\nspotlight the urgent need for novel approaches in this domain, setting a clear\nagenda for future research and development efforts within the community.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "8 pages",
    "pdf_url": "http://arxiv.org/pdf/2402.14835v1",
    "published_date": "2024-02-18 07:15:03 UTC",
    "updated_date": "2024-02-18 07:15:03 UTC"
  },
  {
    "arxiv_id": "2402.11472v5",
    "title": "DDIPrompt: Drug-Drug Interaction Event Prediction based on Graph Prompt Learning",
    "authors": [
      "Yingying Wang",
      "Yun Xiong",
      "Xixi Wu",
      "Xiangguo Sun",
      "Jiawei Zhang"
    ],
    "abstract": "Drug combinations can cause adverse drug-drug interactions(DDIs). Identifying\nspecific effects is crucial for developing safer therapies. Previous works on\nDDI event prediction have typically been limited to using labels of specific\nevents as supervision, which renders them insufficient to address two\nsignificant challenges: (1) the bias caused by \\textbf{highly imbalanced event\ndistribution} where certain interaction types are vastly under-represented. (2)\nthe \\textbf{scarcity of labeled data for rare events}, a pervasive issue where\nrare yet potentially critical interactions are often overlooked or\nunder-explored due to limited available data. In response, we offer\n``DDIPrompt'', an innovative solution inspired by the recent advancements in\ngraph prompt learning. Our framework aims to address these issues by leveraging\nthe intrinsic knowledge from pre-trained models, which can be efficiently\ndeployed with minimal downstream data. Specifically, to solve the first\nchallenge, DDIPrompt features a hierarchical pre-training strategy to foster a\ngeneralized and comprehensive understanding of drug properties. It captures\nintra-molecular structures through augmented links based on structural\nproximity between drugs, further learns inter-molecular interactions\nemphasizing edge connections rather than concrete catagories. For the second\nchallenge, we implement a prototype-enhanced prompting mechanism during\ninference. This mechanism, refined by few-shot examples from each category,\neffectively harnesses the rich pre-training knowledge to enhance prediction\naccuracy, particularly for these rare but crucial interactions. Extensive\nexperiments on two benchmark datasets demonstrate DDIPrompt's SOTA performance,\nespecially for those rare DDI events.",
    "categories": [
      "q-bio.BM",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.BM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.11472v5",
    "published_date": "2024-02-18 06:22:01 UTC",
    "updated_date": "2024-11-02 11:36:54 UTC"
  },
  {
    "arxiv_id": "2403.00781v3",
    "title": "ChatDiet: Empowering Personalized Nutrition-Oriented Food Recommender Chatbots through an LLM-Augmented Framework",
    "authors": [
      "Zhongqi Yang",
      "Elahe Khatibi",
      "Nitish Nagesh",
      "Mahyar Abbasian",
      "Iman Azimi",
      "Ramesh Jain",
      "Amir M. Rahmani"
    ],
    "abstract": "The profound impact of food on health necessitates advanced\nnutrition-oriented food recommendation services. Conventional methods often\nlack the crucial elements of personalization, explainability, and\ninteractivity. While Large Language Models (LLMs) bring interpretability and\nexplainability, their standalone use falls short of achieving true\npersonalization. In this paper, we introduce ChatDiet, a novel LLM-powered\nframework designed specifically for personalized nutrition-oriented food\nrecommendation chatbots. ChatDiet integrates personal and population models,\ncomplemented by an orchestrator, to seamlessly retrieve and process pertinent\ninformation. The personal model leverages causal discovery and inference\ntechniques to assess personalized nutritional effects for a specific user,\nwhereas the population model provides generalized information on food\nnutritional content. The orchestrator retrieves, synergizes and delivers the\noutput of both models to the LLM, providing tailored food recommendations\ndesigned to support targeted health outcomes. The result is a dynamic delivery\nof personalized and explainable food recommendations, tailored to individual\nuser preferences. Our evaluation of ChatDiet includes a compelling case study,\nwhere we establish a causal personal model to estimate individual nutrition\neffects. Our assessments, including a food recommendation test showcasing a\n92\\% effectiveness rate, coupled with illustrative dialogue examples,\nunderscore ChatDiet's strengths in explainability, personalization, and\ninteractivity.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG",
      "cs.MM"
    ],
    "primary_category": "cs.IR",
    "comment": "Published on Smart Health",
    "pdf_url": "http://arxiv.org/pdf/2403.00781v3",
    "published_date": "2024-02-18 06:07:17 UTC",
    "updated_date": "2024-09-25 06:31:09 UTC"
  },
  {
    "arxiv_id": "2402.14834v2",
    "title": "MSynFD: Multi-hop Syntax aware Fake News Detection",
    "authors": [
      "Liang Xiao",
      "Qi Zhang",
      "Chongyang Shi",
      "Shoujin Wang",
      "Usman Naseem",
      "Liang Hu"
    ],
    "abstract": "The proliferation of social media platforms has fueled the rapid\ndissemination of fake news, posing threats to our real-life society. Existing\nmethods use multimodal data or contextual information to enhance the detection\nof fake news by analyzing news content and/or its social context. However,\nthese methods often overlook essential textual news content (articles) and\nheavily rely on sequential modeling and global attention to extract semantic\ninformation. These existing methods fail to handle the complex, subtle twists\nin news articles, such as syntax-semantics mismatches and prior biases, leading\nto lower performance and potential failure when modalities or social context\nare missing. To bridge these significant gaps, we propose a novel multi-hop\nsyntax aware fake news detection (MSynFD) method, which incorporates\ncomplementary syntax information to deal with subtle twists in fake news.\nSpecifically, we introduce a syntactical dependency graph and design a\nmulti-hop subgraph aggregation mechanism to capture multi-hop syntax. It\nextends the effect of word perception, leading to effective noise filtering and\nadjacent relation enhancement. Subsequently, a sequential relative\nposition-aware Transformer is designed to capture the sequential information,\ntogether with an elaborate keyword debiasing module to mitigate the prior bias.\nExtensive experimental results on two public benchmark datasets verify the\neffectiveness and superior performance of our proposed MSynFD over\nstate-of-the-art detection models.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "10 pages",
    "pdf_url": "http://arxiv.org/pdf/2402.14834v2",
    "published_date": "2024-02-18 05:40:33 UTC",
    "updated_date": "2024-06-19 13:15:34 UTC"
  },
  {
    "arxiv_id": "2402.12405v1",
    "title": "scInterpreter: Training Large Language Models to Interpret scRNA-seq Data for Cell Type Annotation",
    "authors": [
      "Cong Li",
      "Meng Xiao",
      "Pengfei Wang",
      "Guihai Feng",
      "Xin Li",
      "Yuanchun Zhou"
    ],
    "abstract": "Despite the inherent limitations of existing Large Language Models in\ndirectly reading and interpreting single-cell omics data, they demonstrate\nsignificant potential and flexibility as the Foundation Model. This research\nfocuses on how to train and adapt the Large Language Model with the capability\nto interpret and distinguish cell types in single-cell RNA sequencing data. Our\npreliminary research results indicate that these foundational models excel in\naccurately categorizing known cell types, demonstrating the potential of the\nLarge Language Models as effective tools for uncovering new biological\ninsights.",
    "categories": [
      "q-bio.GN",
      "cs.AI"
    ],
    "primary_category": "q-bio.GN",
    "comment": "4 pages, submitted to FCS",
    "pdf_url": "http://arxiv.org/pdf/2402.12405v1",
    "published_date": "2024-02-18 05:39:00 UTC",
    "updated_date": "2024-02-18 05:39:00 UTC"
  },
  {
    "arxiv_id": "2402.11463v7",
    "title": "Attractor Memory for Long-Term Time Series Forecasting: A Chaos Perspective",
    "authors": [
      "Jiaxi Hu",
      "Yuehong Hu",
      "Wei Chen",
      "Ming Jin",
      "Shirui Pan",
      "Qingsong Wen",
      "Yuxuan Liang"
    ],
    "abstract": "In long-term time series forecasting (LTSF) tasks, an increasing number of\nmodels have acknowledged that discrete time series originate from continuous\ndynamic systems and have attempted to model their dynamical structures.\nRecognizing the chaotic nature of real-world data, our model,\n\\textbf{\\textit{Attraos}}, incorporates chaos theory into LTSF, perceiving\nreal-world time series as observations from unknown high-dimensional chaotic\ndynamic systems. Under the concept of attractor invariance, Attraos utilizes\nnon-parametric Phase Space Reconstruction embedding and the proposed\nmulti-scale dynamic memory unit to memorize historical dynamics structure and\npredicts by a frequency-enhanced local evolution strategy. Detailed theoretical\nanalysis and abundant empirical evidence consistently show that Attraos\noutperforms various LTSF methods on mainstream LTSF datasets and chaotic\ndatasets with only one-twelfth of the parameters compared to PatchTST.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "nlin.CD"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.11463v7",
    "published_date": "2024-02-18 05:35:01 UTC",
    "updated_date": "2024-11-02 14:11:52 UTC"
  },
  {
    "arxiv_id": "2402.11461v2",
    "title": "FGeo-HyperGNet: Geometric Problem Solving Integrating Formal Symbolic System and Hypergraph Neural Network",
    "authors": [
      "Xiaokai Zhang",
      "Na Zhu",
      "Cheng Qin",
      "Yang Li",
      "Zhenbing Zeng",
      "Tuo Leng"
    ],
    "abstract": "Geometric problem solving has always been a long-standing challenge in the\nfields of automated reasoning and artificial intelligence. We built a\nneural-symbolic system to automatically perform human-like geometric deductive\nreasoning. The symbolic part is a formal system built on FormalGeo, which can\nautomatically perform geomertic relational reasoning and algebraic calculations\nand organize the solving process into a solution hypertree with conditions as\nhypernodes and theorems as hyperedges. The neural part, called HyperGNet, is a\nhypergraph neural network based on the attention mechanism, including a encoder\nto effectively encode the structural and semantic information of the hypertree,\nand a solver to provide problem-solving guidance. The neural part predicts\ntheorems according to the hypertree, and the symbolic part applies theorems and\nupdates the hypertree, thus forming a predict-apply cycle to ultimately achieve\nreadable and traceable automatic solving of geometric problems. Experiments\ndemonstrate the correctness and effectiveness of this neural-symbolic\narchitecture. We achieved a step-wised accuracy of 87.65% and an overall\naccuracy of 85.53% on the formalgeo7k datasets.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "13 pages",
    "pdf_url": "http://arxiv.org/pdf/2402.11461v2",
    "published_date": "2024-02-18 05:23:15 UTC",
    "updated_date": "2024-04-22 07:31:15 UTC"
  },
  {
    "arxiv_id": "2402.11459v2",
    "title": "Re-Dock: Towards Flexible and Realistic Molecular Docking with Diffusion Bridge",
    "authors": [
      "Yufei Huang",
      "Odin Zhang",
      "Lirong Wu",
      "Cheng Tan",
      "Haitao Lin",
      "Zhangyang Gao",
      "Siyuan Li",
      "Stan. Z. Li"
    ],
    "abstract": "Accurate prediction of protein-ligand binding structures, a task known as\nmolecular docking is crucial for drug design but remains challenging. While\ndeep learning has shown promise, existing methods often depend on holo-protein\nstructures (docked, and not accessible in realistic tasks) or neglect pocket\nsidechain conformations, leading to limited practical utility and unrealistic\nconformation predictions. To fill these gaps, we introduce an under-explored\ntask, named flexible docking to predict poses of ligand and pocket sidechains\nsimultaneously and introduce Re-Dock, a novel diffusion bridge generative model\nextended to geometric manifolds. Specifically, we propose energy-to-geometry\nmapping inspired by the Newton-Euler equation to co-model the binding energy\nand conformations for reflecting the energy-constrained docking generative\nprocess. Comprehensive experiments on designed benchmark datasets including\napo-dock and cross-dock demonstrate our model's superior effectiveness and\nefficiency over current methods.",
    "categories": [
      "q-bio.BM",
      "cs.AI",
      "cs.LG",
      "physics.chem-ph"
    ],
    "primary_category": "q-bio.BM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.11459v2",
    "published_date": "2024-02-18 05:04:50 UTC",
    "updated_date": "2024-02-21 07:46:07 UTC"
  },
  {
    "arxiv_id": "2402.11451v2",
    "title": "SciAgent: Tool-augmented Language Models for Scientific Reasoning",
    "authors": [
      "Yubo Ma",
      "Zhibin Gou",
      "Junheng Hao",
      "Ruochen Xu",
      "Shuohang Wang",
      "Liangming Pan",
      "Yujiu Yang",
      "Yixin Cao",
      "Aixin Sun",
      "Hany Awadalla",
      "Weizhu Chen"
    ],
    "abstract": "Scientific reasoning poses an excessive challenge for even the most advanced\nLarge Language Models (LLMs). To make this task more practical and solvable for\nLLMs, we introduce a new task setting named tool-augmented scientific\nreasoning. This setting supplements LLMs with scalable toolsets, and shifts the\nfocus from pursuing an omniscient problem solver to a proficient tool-user. To\nfacilitate the research of such setting, we construct a tool-augmented training\ncorpus named MathFunc which encompasses over 30,000 samples and roughly 6,000\ntools. Building on MathFunc, we develop SciAgent to retrieve, understand and,\nif necessary, use tools for scientific problem solving. Additionally, we craft\na benchmark, SciToolBench, spanning five scientific domains to evaluate LLMs'\nabilities with tool assistance. Extensive experiments on SciToolBench confirm\nthe effectiveness of SciAgent. Notably, SciAgent-Mistral-7B surpasses other\nLLMs with the same size by more than 13% in absolute accuracy. Furthermore,\nSciAgent-DeepMath-7B shows much superior performance than ChatGPT.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.11451v2",
    "published_date": "2024-02-18 04:19:44 UTC",
    "updated_date": "2024-02-21 03:04:49 UTC"
  },
  {
    "arxiv_id": "2402.11444v3",
    "title": "Gauging Public Acceptance of Conditionally Automated Vehicles in the United States",
    "authors": [
      "Antonios Saravanos",
      "Eleftheria K. Pissadaki",
      "Wayne S. Singh",
      "Donatella Delfino"
    ],
    "abstract": "Public acceptance of conditionally automated vehicles is a crucial step in\nthe realization of smart cities. Prior research in Europe has shown that the\nfactors of hedonic motivation, social influence, and performance expectancy, in\ndecreasing order of importance, influence acceptance. Moreover, a generally\npositive acceptance of the technology was reported. However, there is a lack of\ninformation regarding the public acceptance of conditionally automated vehicles\nin the United States. In this study, we carried out a web-based experiment\nwhere participants were provided information regarding the technology and then\ncompleted a questionnaire on their perceptions. The collected data was analyzed\nusing PLS-SEM to examine the factors that may lead to public acceptance of the\ntechnology in the United States. Our findings showed that social influence,\nperformance expectancy, effort expectancy, hedonic motivation, and facilitating\nconditions determine conditionally automated vehicle acceptance. Additionally,\ncertain factors were found to influence the perception of how useful the\ntechnology is, the effort required to use it, and the facilitating conditions\nfor its use. By integrating the insights gained from this study, stakeholders\ncan better facilitate the adoption of autonomous vehicle technology,\ncontributing to safer, more efficient, and user-friendly transportation systems\nin the future that help realize the vision of the smart city.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.11444v3",
    "published_date": "2024-02-18 03:50:34 UTC",
    "updated_date": "2024-04-17 00:43:52 UTC"
  },
  {
    "arxiv_id": "2402.11441v2",
    "title": "InfuserKI: Enhancing Large Language Models with Knowledge Graphs via Infuser-Guided Knowledge Integration",
    "authors": [
      "Fali Wang",
      "Runxue Bao",
      "Suhang Wang",
      "Wenchao Yu",
      "Yanchi Liu",
      "Wei Cheng",
      "Haifeng Chen"
    ],
    "abstract": "Large Language Models (LLMs) have achieved exceptional capabilities in open\ngeneration across various domains, yet they encounter difficulties with tasks\nthat require intensive knowledge. To address these challenges, methods for\nintegrating knowledge have been developed, which augment LLMs with\ndomain-specific knowledge graphs through external modules. These approaches,\nhowever, face data inefficiency issues as they necessitate the processing of\nboth known and unknown knowledge for fine-tuning. Thus, our research focuses on\na novel problem: efficiently integrating unknown knowledge into LLMs without\nunnecessary overlap of known knowledge. A risk of introducing new knowledge is\nthe potential forgetting of existing knowledge. To mitigate this risk, we\npropose the innovative {\\method} framework. This framework employs transformer\ninternal states to determine when to enrich LLM outputs with additional\ninformation, effectively preventing knowledge forgetting. Performance\nevaluations using the UMLS-2.5k and MetaQA domain knowledge graphs reveal that\n{\\method} not only successfully integrates new knowledge but also outperforms\nstate-of-the-art baselines, reducing knowledge forgetting by 9\\% and 6\\%,\nrespectively.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "14 pages, 7 figures, EMNLP 2024 Findings",
    "pdf_url": "http://arxiv.org/pdf/2402.11441v2",
    "published_date": "2024-02-18 03:36:26 UTC",
    "updated_date": "2024-12-16 07:18:06 UTC"
  },
  {
    "arxiv_id": "2402.11436v2",
    "title": "Pride and Prejudice: LLM Amplifies Self-Bias in Self-Refinement",
    "authors": [
      "Wenda Xu",
      "Guanglei Zhu",
      "Xuandong Zhao",
      "Liangming Pan",
      "Lei Li",
      "William Yang Wang"
    ],
    "abstract": "Recent studies show that large language models (LLMs) improve their\nperformance through self-feedback on certain tasks while degrade on others. We\ndiscovered that such a contrary is due to LLM's bias in evaluating their own\noutput. In this paper, we formally define LLM's self-bias - the tendency to\nfavor its own generation - using two statistics. We analyze six LLMs (GPT-4,\nGPT-3.5, Gemini, LLaMA2, Mixtral and DeepSeek) on translation, constrained text\ngeneration, and mathematical reasoning tasks. We find that self-bias is\nprevalent in all examined LLMs across multiple languages and tasks. Our\nanalysis reveals that while the self-refine pipeline improves the fluency and\nunderstandability of model outputs, it further amplifies self-bias. To mitigate\nsuch biases, we discover that larger model size and external feedback with\naccurate assessment can significantly reduce bias in the self-refine pipeline,\nleading to actual performance improvement in downstream tasks. The code and\ndata are released at https://github.com/xu1998hz/llm_self_bias.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.11436v2",
    "published_date": "2024-02-18 03:10:39 UTC",
    "updated_date": "2024-06-18 04:41:07 UTC"
  },
  {
    "arxiv_id": "2402.11427v2",
    "title": "OptEx: Expediting First-Order Optimization with Approximately Parallelized Iterations",
    "authors": [
      "Yao Shu",
      "Jiongfeng Fang",
      "Ying Tiffany He",
      "Fei Richard Yu"
    ],
    "abstract": "First-order optimization (FOO) algorithms are pivotal in numerous\ncomputational domains such as machine learning and signal denoising. However,\ntheir application to complex tasks like neural network training often entails\nsignificant inefficiencies due to the need for many sequential iterations for\nconvergence. In response, we introduce first-order optimization expedited with\napproximately parallelized iterations (OptEx), the first framework that\nenhances the efficiency of FOO by leveraging parallel computing to mitigate its\niterative bottleneck. OptEx employs kernelized gradient estimation to make use\nof gradient history for future gradient prediction, enabling parallelization of\niterations -- a strategy once considered impractical because of the inherent\niterative dependency in FOO. We provide theoretical guarantees for the\nreliability of our kernelized gradient estimation and the iteration complexity\nof SGD-based OptEx, confirming that estimation errors diminish to zero as\nhistorical gradients accumulate and that SGD-based OptEx enjoys an effective\nacceleration rate of $\\Omega(\\sqrt{N})$ over standard SGD given parallelism of\nN. We also use extensive empirical studies, including synthetic functions,\nreinforcement learning tasks, and neural network training across various\ndatasets, to underscore the substantial efficiency improvements achieved by\nOptEx.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Published as a conference paper at NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.11427v2",
    "published_date": "2024-02-18 02:19:02 UTC",
    "updated_date": "2024-10-29 04:20:44 UTC"
  },
  {
    "arxiv_id": "2402.11424v1",
    "title": "Data Distribution Distilled Generative Model for Generalized Zero-Shot Recognition",
    "authors": [
      "Yijie Wang",
      "Mingjian Hong",
      "Luwen Huangfu",
      "Sheng Huang"
    ],
    "abstract": "In the realm of Zero-Shot Learning (ZSL), we address biases in Generalized\nZero-Shot Learning (GZSL) models, which favor seen data. To counter this, we\nintroduce an end-to-end generative GZSL framework called D$^3$GZSL. This\nframework respects seen and synthesized unseen data as in-distribution and\nout-of-distribution data, respectively, for a more balanced model. D$^3$GZSL\ncomprises two core modules: in-distribution dual space distillation (ID$^2$SD)\nand out-of-distribution batch distillation (O$^2$DBD). ID$^2$SD aligns\nteacher-student outcomes in embedding and label spaces, enhancing learning\ncoherence. O$^2$DBD introduces low-dimensional out-of-distribution\nrepresentations per batch sample, capturing shared structures between seen and\nunseen categories. Our approach demonstrates its effectiveness across\nestablished GZSL benchmarks, seamlessly integrating into mainstream generative\nframeworks. Extensive experiments consistently showcase that D$^3$GZSL elevates\nthe performance of existing generative GZSL methods, underscoring its potential\nto refine zero-shot learning practices.The code is available at:\nhttps://github.com/PJBQ/D3GZSL.git",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "accepted as AAAI 2024 oral paper",
    "pdf_url": "http://arxiv.org/pdf/2402.11424v1",
    "published_date": "2024-02-18 01:54:28 UTC",
    "updated_date": "2024-02-18 01:54:28 UTC"
  },
  {
    "arxiv_id": "2402.11417v1",
    "title": "LoRETTA: Low-Rank Economic Tensor-Train Adaptation for Ultra-Low-Parameter Fine-Tuning of Large Language Models",
    "authors": [
      "Yifan Yang",
      "Jiajun Zhou",
      "Ngai Wong",
      "Zheng Zhang"
    ],
    "abstract": "Various parameter-efficient fine-tuning (PEFT) techniques have been proposed\nto enable computationally efficient fine-tuning while maintaining model\nperformance. However, existing PEFT methods are still limited by the growing\nnumber of trainable parameters with the rapid deployment of Large Language\nModels (LLMs). To address this challenge, we present LoRETTA, an\nultra-parameter-efficient framework that significantly reduces trainable\nparameters through tensor-train decomposition. Specifically, we propose two\nmethods, named {LoRETTA}$_{adp}$ and {LoRETTA}$_{rep}$. The former employs\ntensorized adapters, offering a high-performance yet lightweight approach for\nthe fine-tuning of LLMs. The latter emphasizes fine-tuning via weight\nparameterization with a set of small tensor factors. LoRETTA achieves\ncomparable or better performance than most widely used PEFT methods with up to\n$100\\times$ fewer parameters on the LLaMA-2-7B models. Furthermore, empirical\nresults demonstrate that the proposed method effectively improves training\nefficiency, enjoys better multi-task learning performance, and enhances the\nanti-overfitting capability. Plug-and-play codes built upon the Huggingface\nframework and PEFT library will be released.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.11417v1",
    "published_date": "2024-02-18 01:20:00 UTC",
    "updated_date": "2024-02-18 01:20:00 UTC"
  }
]