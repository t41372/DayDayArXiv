[
  {
    "arxiv_id": "2507.20439v1",
    "title": "When Prompts Go Wrong: Evaluating Code Model Robustness to Ambiguous, Contradictory, and Incomplete Task Descriptions",
    "authors": [
      "Maya Larbi",
      "Amal Akli",
      "Mike Papadakis",
      "Rihab Bouyousfi",
      "Maxime Cordy",
      "Federica Sarro",
      "Yves Le Traon"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated impressive performance in code generation tasks under idealized conditions, where task descriptions are clear and precise. However, in practice, task descriptions frequently exhibit ambiguity, incompleteness, or internal contradictions. In this paper, we present the first empirical study examining the robustness of state-of-the-art code generation models when faced with such unclear task descriptions. We extend the HumanEval and MBPP benchmarks by systematically introducing realistic task descriptions flaws through guided mutation strategies, producing a dataset that mirrors the messiness of informal developer instructions. We evaluate multiple LLMs of varying sizes and architectures, analyzing their functional correctness and failure modes across task descriptions categories. Our findings reveal that even minor imperfections in task description phrasing can cause significant performance degradation, with contradictory task descriptions resulting in numerous logical errors. Moreover, while larger models tend to be more resilient than smaller variants, they are not immune to the challenges posed by unclear requirements. We further analyze semantic error patterns and identify correlations between description clarity, model behavior, and error types. Our results underscore the critical need for developing LLMs that are not only powerful but also robust to the imperfections inherent in natural user tasks, highlighting important considerations for improving model training strategies, designing more realistic evaluation benchmarks, and ensuring reliable deployment in practical software development environments.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.20439v1",
    "published_date": "2025-07-27 23:16:14 UTC",
    "updated_date": "2025-07-27 23:16:14 UTC"
  },
  {
    "arxiv_id": "2507.20433v1",
    "title": "FAST: Similarity-based Knowledge Transfer for Efficient Policy Learning",
    "authors": [
      "Alessandro Capurso",
      "Elia Piccoli",
      "Davide Bacciu"
    ],
    "abstract": "Transfer Learning (TL) offers the potential to accelerate learning by transferring knowledge across tasks. However, it faces critical challenges such as negative transfer, domain adaptation and inefficiency in selecting solid source policies. These issues often represent critical problems in evolving domains, i.e. game development, where scenarios transform and agents must adapt. The continuous release of new agents is costly and inefficient. In this work we challenge the key issues in TL to improve knowledge transfer, agents performance across tasks and reduce computational costs. The proposed methodology, called FAST - Framework for Adaptive Similarity-based Transfer, leverages visual frames and textual descriptions to create a latent representation of tasks dynamics, that is exploited to estimate similarity between environments. The similarity scores guides our method in choosing candidate policies from which transfer abilities to simplify learning of novel tasks. Experimental results, over multiple racing tracks, demonstrate that FAST achieves competitive final performance compared to learning-from-scratch methods while requiring significantly less training steps. These findings highlight the potential of embedding-driven task similarity estimations.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at IEEE Conference on Games (CoG) 2025",
    "pdf_url": "https://arxiv.org/pdf/2507.20433v1",
    "published_date": "2025-07-27 22:21:53 UTC",
    "updated_date": "2025-07-27 22:21:53 UTC"
  },
  {
    "arxiv_id": "2507.20426v1",
    "title": "ResCap-DBP: A Lightweight Residual-Capsule Network for Accurate DNA-Binding Protein Prediction Using Global ProteinBERT Embeddings",
    "authors": [
      "Samiul Based Shuvo",
      "Tasnia Binte Mamun",
      "U Rajendra Acharya"
    ],
    "abstract": "DNA-binding proteins (DBPs) are integral to gene regulation and cellular processes, making their accurate identification essential for understanding biological functions and disease mechanisms. Experimental methods for DBP identification are time-consuming and costly, driving the need for efficient computational prediction techniques. In this study, we propose a novel deep learning framework, ResCap-DBP, that combines a residual learning-based encoder with a one-dimensional Capsule Network (1D-CapsNet) to predict DBPs directly from raw protein sequences. Our architecture incorporates dilated convolutions within residual blocks to mitigate vanishing gradient issues and extract rich sequence features, while capsule layers with dynamic routing capture hierarchical and spatial relationships within the learned feature space. We conducted comprehensive ablation studies comparing global and local embeddings from ProteinBERT and conventional one-hot encoding. Results show that ProteinBERT embeddings substantially outperform other representations on large datasets. Although one-hot encoding showed marginal advantages on smaller datasets, such as PDB186, it struggled to scale effectively. Extensive evaluations on four pairs of publicly available benchmark datasets demonstrate that our model consistently outperforms current state-of-the-art methods. It achieved AUC scores of 98.0% and 89.5% on PDB14189andPDB1075, respectively. On independent test sets PDB2272 and PDB186, the model attained top AUCs of 83.2% and 83.3%, while maintaining competitive performance on larger datasets such as PDB20000. Notably, the model maintains a well balanced sensitivity and specificity across datasets. These results demonstrate the efficacy and generalizability of integrating global protein representations with advanced deep learning architectures for reliable and scalable DBP prediction in diverse genomic contexts.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP",
      "q-bio.BM"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.20426v1",
    "published_date": "2025-07-27 21:54:32 UTC",
    "updated_date": "2025-07-27 21:54:32 UTC"
  },
  {
    "arxiv_id": "2508.08266v1",
    "title": "Benchmarking Large Language Models for Geolocating Colonial Virginia Land Grants",
    "authors": [
      "Ryan Mioduski"
    ],
    "abstract": "Virginia's seventeenth- and eighteenth-century land patents survive primarily as narrative metes-and-bounds descriptions, limiting spatial analysis. This study systematically evaluates current-generation large language models (LLMs) in converting these prose abstracts into geographically accurate latitude/longitude coordinates within a focused evaluation context. A digitized corpus of 5,471 Virginia patent abstracts (1695-1732) is released, with 43 rigorously verified test cases serving as an initial, geographically focused benchmark. Six OpenAI models across three architectures (o-series, GPT-4-class, and GPT-3.5) were tested under two paradigms: direct-to-coordinate and tool-augmented chain-of-thought invoking external geocoding APIs. Results were compared with a GIS-analyst baseline, the Stanford NER geoparser, Mordecai-3, and a county-centroid heuristic.\n  The top single-call model, o3-2025-04-16, achieved a mean error of 23 km (median 14 km), outperforming the median LLM (37.4 km) by 37.5%, the weakest LLM (50.3 km) by 53.5%, and external baselines by 67% (GIS analyst) and 70% (Stanford NER). A five-call ensemble further reduced errors to 19 km (median 12 km) at minimal additional cost (approx. USD 0.20 per grant), outperforming the median LLM by 48.6%. A patentee-name-redaction ablation increased error by about 9%, indicating reliance on textual landmark and adjacency descriptions rather than memorization. The cost-efficient gpt-4o-2024-08-06 model maintained a 28 km mean error at USD 1.09 per 1,000 grants, establishing a strong cost-accuracy benchmark; external geocoding tools offered no measurable benefit in this evaluation.\n  These findings demonstrate the potential of LLMs for scalable, accurate, and cost-effective historical georeferencing.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.IR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.08266v1",
    "published_date": "2025-07-27 21:49:58 UTC",
    "updated_date": "2025-07-27 21:49:58 UTC"
  },
  {
    "arxiv_id": "2507.20423v3",
    "title": "CodeNER: Code Prompting for Named Entity Recognition",
    "authors": [
      "Sungwoo Han",
      "Jingun Kwon",
      "Hidetaka Kamigaito",
      "Manabu Okumura"
    ],
    "abstract": "Recent studies have explored various approaches for treating candidate named entity spans as both source and target sequences in named entity recognition (NER) by leveraging large language models (LLMs). Although previous approaches have successfully generated candidate named entity spans with suitable labels, they rely solely on input context information when using LLMs, particularly, ChatGPT. However, NER inherently requires capturing detailed labeling requirements with input context information. To address this issue, we propose a novel method that leverages code-based prompting to improve the capabilities of LLMs in understanding and performing NER. By embedding code within prompts, we provide detailed BIO schema instructions for labeling, thereby exploiting the ability of LLMs to comprehend long-range scopes in programming languages. Experimental results demonstrate that the proposed code-based prompting method outperforms conventional text-based prompting on ten benchmarks across English, Arabic, Finnish, Danish, and German datasets, indicating the effectiveness of explicitly structuring NER instructions. We also verify that combining the proposed code-based prompting method with the chain-of-thought prompting further improves performance.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "18 pages, 6 figures",
    "pdf_url": "https://arxiv.org/pdf/2507.20423v3",
    "published_date": "2025-07-27 21:49:36 UTC",
    "updated_date": "2025-12-20 10:58:40 UTC"
  },
  {
    "arxiv_id": "2507.20419v1",
    "title": "Survey of NLU Benchmarks Diagnosing Linguistic Phenomena: Why not Standardize Diagnostics Benchmarks?",
    "authors": [
      "Khloud AL Jallad",
      "Nada Ghneim",
      "Ghaida Rebdawi"
    ],
    "abstract": "Natural Language Understanding (NLU) is a basic task in Natural Language Processing (NLP). The evaluation of NLU capabilities has become a trending research topic that attracts researchers in the last few years, resulting in the development of numerous benchmarks. These benchmarks include various tasks and datasets in order to evaluate the results of pretrained models via public leaderboards. Notably, several benchmarks contain diagnostics datasets designed for investigation and fine-grained error analysis across a wide range of linguistic phenomena. This survey provides a comprehensive review of available English, Arabic, and Multilingual NLU benchmarks, with a particular emphasis on their diagnostics datasets and the linguistic phenomena they covered. We present a detailed comparison and analysis of these benchmarks, highlighting their strengths and limitations in evaluating NLU tasks and providing in-depth error analysis. When highlighting the gaps in the state-of-the-art, we noted that there is no naming convention for macro and micro categories or even a standard set of linguistic phenomena that should be covered. Consequently, we formulated a research question regarding the evaluation metrics of the evaluation diagnostics benchmarks: \"Why do not we have an evaluation standard for the NLU evaluation diagnostics benchmarks?\" similar to ISO standard in industry. We conducted a deep analysis and comparisons of the covered linguistic phenomena in order to support experts in building a global hierarchy for linguistic phenomena in future. We think that having evaluation metrics for diagnostics evaluation could be valuable to gain more insights when comparing the results of the studied models on different diagnostics benchmarks.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.20419v1",
    "published_date": "2025-07-27 21:30:50 UTC",
    "updated_date": "2025-07-27 21:30:50 UTC"
  },
  {
    "arxiv_id": "2507.20409v1",
    "title": "Cognitive Chain-of-Thought: Structured Multimodal Reasoning about Social Situations",
    "authors": [
      "Eunkyu Park",
      "Wesley Hanwen Deng",
      "Gunhee Kim",
      "Motahhare Eslami",
      "Maarten Sap"
    ],
    "abstract": "Chain-of-Thought (CoT) prompting helps models think step by step. But what happens when they must see, understand, and judge-all at once? In visual tasks grounded in social context, where bridging perception with norm-grounded judgments is essential, flat CoT often breaks down. We introduce Cognitive Chain-of-Thought (CoCoT), a prompting strategy that scaffolds VLM reasoning through three cognitively inspired stages: perception, situation, and norm. Our experiments show that, across multiple multimodal benchmarks (including intent disambiguation, commonsense reasoning, and safety), CoCoT consistently outperforms CoT and direct prompting (+8\\% on average). Our findings demonstrate that cognitively grounded reasoning stages enhance interpretability and social awareness in VLMs, paving the way for safer and more reliable multimodal systems.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "comment": "Under review; 17 pages",
    "pdf_url": "https://arxiv.org/pdf/2507.20409v1",
    "published_date": "2025-07-27 20:40:30 UTC",
    "updated_date": "2025-07-27 20:40:30 UTC"
  },
  {
    "arxiv_id": "2507.20408v2",
    "title": "A Multi-Stage Hybrid CNN-Transformer Network for Automated Pediatric Lung Sound Classification",
    "authors": [
      "Samiul Based Shuvo",
      "Taufiq Hasan"
    ],
    "abstract": "Automated analysis of lung sound auscultation is essential for monitoring respiratory health, especially in regions facing a shortage of skilled healthcare workers. While respiratory sound classification has been widely studied in adults, its ap plication in pediatric populations, particularly in children aged <6 years, remains an underexplored area. The developmental changes in pediatric lungs considerably alter the acoustic proper ties of respiratory sounds, necessitating specialized classification approaches tailored to this age group. To address this, we propose a multistage hybrid CNN-Transformer framework that combines CNN-extracted features with an attention-based architecture to classify pediatric respiratory diseases using scalogram images from both full recordings and individual breath events. Our model achieved an overall score of 0.9039 in binary event classifi cation and 0.8448 in multiclass event classification by employing class-wise focal loss to address data imbalance. At the recording level, the model attained scores of 0.720 for ternary and 0.571 for multiclass classification. These scores outperform the previous best models by 3.81% and 5.94%, respectively. This approach offers a promising solution for scalable pediatric respiratory disease diagnosis, especially in resource-limited settings.",
    "categories": [
      "eess.SP",
      "cs.AI"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.20408v2",
    "published_date": "2025-07-27 20:36:46 UTC",
    "updated_date": "2025-10-19 12:06:54 UTC"
  },
  {
    "arxiv_id": "2508.05652v1",
    "title": "Lessons from A Large Language Model-based Outdoor Trail Recommendation Chatbot with Retrieval Augmented Generation",
    "authors": [
      "Julia Ann Mathew",
      "Suining He"
    ],
    "abstract": "The increasing popularity of outdoor recreational activities (such as hiking and biking) has boosted the demand for a conversational AI system to provide informative and personalized suggestion on outdoor trails. Challenges arise in response to (1) how to provide accurate outdoor trail information via conversational AI; and (2) how to enable usable and efficient recommendation services. To address above, this paper discusses the preliminary and practical lessons learned from developing Judy, an outdoor trail recommendation chatbot based on the large language model (LLM) with retrieval augmented generation (RAG). To gain concrete system insights, we have performed case studies with the outdoor trails in Connecticut (CT), US. We have conducted web-based data collection, outdoor trail data management, and LLM model performance studies on the RAG-based recommendation. Our experimental results have demonstrated the accuracy, effectiveness, and usability of Judy in recommending outdoor trails based on the LLM with RAG.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "4 pages, UrbComp 2025",
    "pdf_url": "https://arxiv.org/pdf/2508.05652v1",
    "published_date": "2025-07-27 20:22:23 UTC",
    "updated_date": "2025-07-27 20:22:23 UTC"
  },
  {
    "arxiv_id": "2507.20395v1",
    "title": "MazeEval: A Benchmark for Testing Sequential Decision-Making in Language Models",
    "authors": [
      "Hafsteinn Einarsson"
    ],
    "abstract": "As Large Language Models (LLMs) increasingly power autonomous agents in robotics and embodied AI, understanding their spatial reasoning capabilities becomes crucial for ensuring reliable real-world deployment. Despite advances in language understanding, current research lacks evaluation of how LLMs perform spatial navigation without visual cues, a fundamental requirement for agents operating with limited sensory information. This paper addresses this gap by introducing MazeEval, a benchmark designed to isolate and evaluate pure spatial reasoning in LLMs through coordinate-based maze navigation tasks. Our methodology employs a function-calling interface where models navigate mazes of varying complexity ($5\\times 5$ to $15\\times 15$ grids) using only coordinate feedback and distance-to-wall information, excluding visual input to test fundamental spatial cognition. We evaluate eight state-of-the-art LLMs across identical mazes in both English and Icelandic to assess cross-linguistic transfer of spatial abilities. Our findings reveal striking disparities: while OpenAI's O3 achieves perfect navigation for mazes up to size $30\\times 30$, other models exhibit catastrophic failure beyond $9\\times 9$ mazes, with 100% of failures attributed to excessive looping behavior where models revisit a cell at least 10 times. We document a significant performance degradation in Icelandic, with models solving mazes 3-4 sizes smaller than in English, suggesting spatial reasoning in LLMs emerges from linguistic patterns rather than language-agnostic mechanisms. These results have important implications for global deployment of LLM-powered autonomous systems, showing spatial intelligence remains fundamentally constrained by training data availability and highlighting the need for architectural innovations to achieve reliable navigation across linguistic contexts.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.20395v1",
    "published_date": "2025-07-27 19:33:45 UTC",
    "updated_date": "2025-07-27 19:33:45 UTC"
  },
  {
    "arxiv_id": "2507.20389v1",
    "title": "Solving Scene Understanding for Autonomous Navigation in Unstructured Environments",
    "authors": [
      "Naveen Mathews Renji",
      "Kruthika K",
      "Manasa Keshavamurthy",
      "Pooja Kumari",
      "S. Rajarajeswari"
    ],
    "abstract": "Autonomous vehicles are the next revolution in the automobile industry and they are expected to revolutionize the future of transportation. Understanding the scenario in which the autonomous vehicle will operate is critical for its competent functioning. Deep Learning has played a massive role in the progress that has been made till date. Semantic Segmentation, the process of annotating every pixel of an image with an object class, is one crucial part of this scene comprehension using Deep Learning. It is especially useful in Autonomous Driving Research as it requires comprehension of drivable and non-drivable areas, roadside objects and the like. In this paper semantic segmentation has been performed on the Indian Driving Dataset which has been recently compiled on the urban and rural roads of Bengaluru and Hyderabad. This dataset is more challenging compared to other datasets like Cityscapes, since it is based on unstructured driving environments. It has a four level hierarchy and in this paper segmentation has been performed on the first level. Five different models have been trained and their performance has been compared using the Mean Intersection over Union. These are UNET, UNET+RESNET50, DeepLabsV3, PSPNet and SegNet. The highest MIOU of 0.6496 has been achieved. The paper discusses the dataset, exploratory data analysis, preparation, implementation of the five models and studies the performance and compares the results achieved in the process.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.20389v1",
    "published_date": "2025-07-27 19:11:21 UTC",
    "updated_date": "2025-07-27 19:11:21 UTC"
  },
  {
    "arxiv_id": "2507.20377v2",
    "title": "Multi-Agent Reinforcement Learning for Dynamic Mobility Resource Allocation with Hierarchical Adaptive Grouping",
    "authors": [
      "Farshid Nooshi",
      "Suining He"
    ],
    "abstract": "Allocating mobility resources (e.g., shared bikes/e-scooters, ride-sharing vehicles) is crucial for rebalancing the mobility demand and supply in the urban environments. We propose in this work a novel multi-agent reinforcement learning named Hierarchical Adaptive Grouping-based Parameter Sharing (HAG-PS) for dynamic mobility resource allocation. HAG-PS aims to address two important research challenges regarding multi-agent reinforcement learning for mobility resource allocation: (1) how to dynamically and adaptively share the mobility resource allocation policy (i.e., how to distribute mobility resources) across agents (i.e., representing the regional coordinators of mobility resources); and (2) how to achieve memory-efficient parameter sharing in an urban-scale setting. To address the above challenges, we have provided following novel designs within HAG-PS. To enable dynamic and adaptive parameter sharing, we have designed a hierarchical approach that consists of global and local information of the mobility resource states (e.g., distribution of mobility resources). We have developed an adaptive agent grouping approach in order to split or merge the groups of agents based on their relative closeness of encoded trajectories (i.e., states, actions, and rewards). We have designed a learnable identity (ID) embeddings to enable agent specialization beyond simple parameter copy. We have performed extensive experimental studies based on real-world NYC bike sharing data (a total of more than 1.2 million trips), and demonstrated the superior performance (e.g., improved bike availability) of HAG-PS compared with other baseline approaches.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "5 pages, UrbComp 2025",
    "pdf_url": "https://arxiv.org/pdf/2507.20377v2",
    "published_date": "2025-07-27 18:40:04 UTC",
    "updated_date": "2025-07-29 22:17:17 UTC"
  },
  {
    "arxiv_id": "2507.20373v1",
    "title": "WBHT: A Generative Attention Architecture for Detecting Black Hole Anomalies in Backbone Networks",
    "authors": [
      "Kiymet Kaya",
      "Elif Ak",
      "Sule Gunduz Oguducu"
    ],
    "abstract": "We propose the Wasserstein Black Hole Transformer (WBHT) framework for detecting black hole (BH) anomalies in communication networks. These anomalies cause packet loss without failure notifications, disrupting connectivity and leading to financial losses. WBHT combines generative modeling, sequential learning, and attention mechanisms to improve BH anomaly detection. It integrates a Wasserstein generative adversarial network with attention mechanisms for stable training and accurate anomaly identification. The model uses long-short-term memory layers to capture long-term dependencies and convolutional layers for local temporal patterns. A latent space encoding mechanism helps distinguish abnormal network behavior. Tested on real-world network data, WBHT outperforms existing models, achieving significant improvements in F1 score (ranging from 1.65% to 58.76%). Its efficiency and ability to detect previously undetected anomalies make it a valuable tool for proactive network monitoring and security, especially in mission-critical networks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.20373v1",
    "published_date": "2025-07-27 18:22:28 UTC",
    "updated_date": "2025-07-27 18:22:28 UTC"
  },
  {
    "arxiv_id": "2507.20369v1",
    "title": "Clustering by Attention: Leveraging Prior Fitted Transformers for Data Partitioning",
    "authors": [
      "Ahmed Shokry",
      "Ayman Khalafallah"
    ],
    "abstract": "Clustering is a core task in machine learning with wide-ranging applications in data mining and pattern recognition. However, its unsupervised nature makes it inherently challenging. Many existing clustering algorithms suffer from critical limitations: they often require careful parameter tuning, exhibit high computational complexity, lack interpretability, or yield suboptimal accuracy, especially when applied to large-scale datasets. In this paper, we introduce a novel clustering approach based on meta-learning. Our approach eliminates the need for parameter optimization while achieving accuracy that outperforms state-of-the-art clustering techniques. The proposed technique leverages a few pre-clustered samples to guide the clustering process for the entire dataset in a single forward pass. Specifically, we employ a pre-trained Prior-Data Fitted Transformer Network (PFN) to perform clustering. The algorithm computes attention between the pre-clustered samples and the unclustered samples, allowing it to infer cluster assignments for the entire dataset based on the learned relation. We theoretically and empirically demonstrate that, given just a few pre-clustered examples, the model can generalize to accurately cluster the rest of the dataset. Experiments on challenging benchmark datasets show that our approach can successfully cluster well-separated data without any pre-clustered samples, and significantly improves performance when a few clustered samples are provided. We show that our approach is superior to the state-of-the-art techniques. These results highlight the effectiveness and scalability of our approach, positioning it as a promising alternative to existing clustering techniques.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.20369v1",
    "published_date": "2025-07-27 17:53:19 UTC",
    "updated_date": "2025-07-27 17:53:19 UTC"
  },
  {
    "arxiv_id": "2507.20353v2",
    "title": "A Unified Theory of $θ$-Expectations",
    "authors": [
      "Qian Qi"
    ],
    "abstract": "We derive a new class of non-linear expectations from first-principles deterministic chaotic dynamics. The homogenization of the system's skew-adjoint microscopic generator is achieved using the spectral theory of transfer operators for uniformly hyperbolic flows. We prove convergence in the viscosity sense to a macroscopic evolution governed by a fully non-linear Hamilton-Jacobi-Bellman (HJB) equation. Our central result establishes that the HJB Hamiltonian possesses a rigid structure: affine in the Hessian but demonstrably non-convex in the gradient. This defines a new $θ$-expectation and constructively establishes a class of non-convex stochastic control problems fundamentally outside the sub-additive framework of G-expectations.",
    "categories": [
      "math.PR",
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "math.PR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.20353v2",
    "published_date": "2025-07-27 16:56:01 UTC",
    "updated_date": "2025-12-01 13:00:38 UTC"
  },
  {
    "arxiv_id": "2507.21188v1",
    "title": "Embeddings to Diagnosis: Latent Fragility under Agentic Perturbations in Clinical LLMs",
    "authors": [
      "Raj Krishnan Vijayaraj"
    ],
    "abstract": "LLMs for clinical decision support often fail under small but clinically meaningful input shifts such as masking a symptom or negating a finding, despite high performance on static benchmarks. These reasoning failures frequently go undetected by standard NLP metrics, which are insensitive to latent representation shifts that drive diagnosis instability. We propose a geometry-aware evaluation framework, LAPD (Latent Agentic Perturbation Diagnostics), which systematically probes the latent robustness of clinical LLMs under structured adversarial edits. Within this framework, we introduce Latent Diagnosis Flip Rate (LDFR), a model-agnostic diagnostic signal that captures representational instability when embeddings cross decision boundaries in PCA-reduced latent space. Clinical notes are generated using a structured prompting pipeline grounded in diagnostic reasoning, then perturbed along four axes: masking, negation, synonym replacement, and numeric variation to simulate common ambiguities and omissions. We compute LDFR across both foundation and clinical LLMs, finding that latent fragility emerges even under minimal surface-level changes. Finally, we validate our findings on 90 real clinical notes from the DiReCT benchmark (MIMIC-IV), confirming the generalizability of LDFR beyond synthetic settings. Our results reveal a persistent gap between surface robustness and semantic stability, underscoring the importance of geometry-aware auditing in safety-critical clinical AI.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.21188v1",
    "published_date": "2025-07-27 16:48:53 UTC",
    "updated_date": "2025-07-27 16:48:53 UTC"
  },
  {
    "arxiv_id": "2507.20342v1",
    "title": "VLMPlanner: Integrating Visual Language Models with Motion Planning",
    "authors": [
      "Zhipeng Tang",
      "Sha Zhang",
      "Jiajun Deng",
      "Chenjie Wang",
      "Guoliang You",
      "Yuting Huang",
      "Xinrui Lin",
      "Yanyong Zhang"
    ],
    "abstract": "Integrating large language models (LLMs) into autonomous driving motion planning has recently emerged as a promising direction, offering enhanced interpretability, better controllability, and improved generalization in rare and long-tail scenarios. However, existing methods often rely on abstracted perception or map-based inputs, missing crucial visual context, such as fine-grained road cues, accident aftermath, or unexpected obstacles, which are essential for robust decision-making in complex driving environments. To bridge this gap, we propose VLMPlanner, a hybrid framework that combines a learning-based real-time planner with a vision-language model (VLM) capable of reasoning over raw images. The VLM processes multi-view images to capture rich, detailed visual information and leverages its common-sense reasoning capabilities to guide the real-time planner in generating robust and safe trajectories. Furthermore, we develop the Context-Adaptive Inference Gate (CAI-Gate) mechanism that enables the VLM to mimic human driving behavior by dynamically adjusting its inference frequency based on scene complexity, thereby achieving an optimal balance between planning performance and computational efficiency. We evaluate our approach on the large-scale, challenging nuPlan benchmark, with comprehensive experimental results demonstrating superior planning performance in scenarios with intricate road conditions and dynamic elements. Code will be available.",
    "categories": [
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "8 pages, 3 figures, this paper has been accepted by ACM MM 2025",
    "pdf_url": "https://arxiv.org/pdf/2507.20342v1",
    "published_date": "2025-07-27 16:15:21 UTC",
    "updated_date": "2025-07-27 16:15:21 UTC"
  },
  {
    "arxiv_id": "2507.20335v1",
    "title": "Cultivating Helpful, Personalized, and Creative AI Tutors: A Framework for Pedagogical Alignment using Reinforcement Learning",
    "authors": [
      "Siyu Song",
      "Wentao Liu",
      "Ye Lu",
      "Ruohua Zhang",
      "Tao Liu",
      "Jinze Lv",
      "Xinyun Wang",
      "Aimin Zhou",
      "Fei Tan",
      "Bo Jiang",
      "Hao Hao"
    ],
    "abstract": "The integration of large language models (LLMs) into education presents unprecedented opportunities for scalable personalized learning. However, standard LLMs often function as generic information providers, lacking alignment with fundamental pedagogical principles such as helpfulness, student-centered personalization, and creativity cultivation. To bridge this gap, we propose EduAlign, a novel framework designed to guide LLMs toward becoming more effective and responsible educational assistants. EduAlign consists of two main stages. In the first stage, we curate a dataset of 8k educational interactions and annotate them-both manually and automatically-along three key educational dimensions: Helpfulness, Personalization, and Creativity (HPC). These annotations are used to train HPC-RM, a multi-dimensional reward model capable of accurately scoring LLM outputs according to these educational principles. We further evaluate the consistency and reliability of this reward model. In the second stage, we leverage HPC-RM as a reward signal to fine-tune a pre-trained LLM using Group Relative Policy Optimization (GRPO) on a set of 2k diverse prompts. We then assess the pre- and post-finetuning models on both educational and general-domain benchmarks across the three HPC dimensions. Experimental results demonstrate that the fine-tuned model exhibits significantly improved alignment with pedagogical helpfulness, personalization, and creativity stimulation. This study presents a scalable and effective approach to aligning LLMs with nuanced and desirable educational traits, paving the way for the development of more engaging, pedagogically aligned AI tutors.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.20335v1",
    "published_date": "2025-07-27 15:56:29 UTC",
    "updated_date": "2025-07-27 15:56:29 UTC"
  },
  {
    "arxiv_id": "2508.04713v1",
    "title": "AI Should Be More Human, Not More Complex",
    "authors": [
      "Carlo Esposito"
    ],
    "abstract": "Large Language Models (LLMs) in search applications increasingly prioritize verbose, lexically complex responses that paradoxically reduce user satisfaction and engagement. Through a comprehensive study of 10.000 (est.) participants comparing responses from five major AI-powered search systems, we demonstrate that users overwhelmingly prefer concise, source-attributed responses over elaborate explanations. Our analysis reveals that current AI development trends toward \"artificial sophistication\" create an uncanny valley effect where systems sound knowledgeable but lack genuine critical thinking, leading to reduced trust and increased cognitive load. We present evidence that optimal AI communication mirrors effective human discourse: direct, properly sourced, and honest about limitations. Our findings challenge the prevailing assumption that more complex AI responses indicate better performance, instead suggesting that human-like brevity and transparency are key to user engagement and system reliability.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "2025 - Knowledge Commons - Eyed Research Collection",
    "pdf_url": "https://arxiv.org/pdf/2508.04713v1",
    "published_date": "2025-07-27 15:55:52 UTC",
    "updated_date": "2025-07-27 15:55:52 UTC"
  },
  {
    "arxiv_id": "2507.20333v1",
    "title": "The Blessing and Curse of Dimensionality in Safety Alignment",
    "authors": [
      "Rachel S. Y. Teo",
      "Laziz U. Abdullaev",
      "Tan M. Nguyen"
    ],
    "abstract": "The focus on safety alignment in large language models (LLMs) has increased significantly due to their widespread adoption across different domains. The scale of LLMs play a contributing role in their success, and the growth in parameter count follows larger hidden dimensions. In this paper, we hypothesize that while the increase in dimensions has been a key advantage, it may lead to emergent problems as well. These problems emerge as the linear structures in the activation space can be exploited, in the form of activation engineering, to circumvent its safety alignment. Through detailed visualizations of linear subspaces associated with different concepts, such as safety, across various model scales, we show that the curse of high-dimensional representations uniquely impacts LLMs. Further substantiating our claim, we demonstrate that projecting the representations of the model onto a lower dimensional subspace can preserve sufficient information for alignment while avoiding those linear structures. Empirical results confirm that such dimensional reduction significantly reduces susceptibility to jailbreaking through representation engineering. Building on our empirical validations, we provide theoretical insights into these linear jailbreaking methods relative to a model's hidden dimensions. Broadly speaking, our work posits that the high dimensions of a model's internal representations can be both a blessing and a curse in safety alignment.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.AI",
    "comment": "Published as a conference paper at COLM 2025",
    "pdf_url": "https://arxiv.org/pdf/2507.20333v1",
    "published_date": "2025-07-27 15:51:23 UTC",
    "updated_date": "2025-07-27 15:51:23 UTC"
  },
  {
    "arxiv_id": "2507.20326v1",
    "title": "MIPS: a Multimodal Infinite Polymer Sequence Pre-training Framework for Polymer Property Prediction",
    "authors": [
      "Jiaxi Wang",
      "Yaosen Min",
      "Xun Zhu",
      "Miao Li",
      "Ji Wu"
    ],
    "abstract": "Polymers, composed of repeating structural units called monomers, are fundamental materials in daily life and industry. Accurate property prediction for polymers is essential for their design, development, and application. However, existing modeling approaches, which typically represent polymers by the constituent monomers, struggle to capture the whole properties of polymer, since the properties change during the polymerization process. In this study, we propose a Multimodal Infinite Polymer Sequence (MIPS) pre-training framework, which represents polymers as infinite sequences of monomers and integrates both topological and spatial information for comprehensive modeling. From the topological perspective, we generalize message passing mechanism (MPM) and graph attention mechanism (GAM) to infinite polymer sequences. For MPM, we demonstrate that applying MPM to infinite polymer sequences is equivalent to applying MPM on the induced star-linking graph of monomers. For GAM, we propose to further replace global graph attention with localized graph attention (LGA). Moreover, we show the robustness of the \"star linking\" strategy through Repeat and Shift Invariance Test (RSIT). Despite its robustness, \"star linking\" strategy exhibits limitations when monomer side chains contain ring structures, a common characteristic of polymers, as it fails the Weisfeiler-Lehman~(WL) test. To overcome this issue, we propose backbone embedding to enhance the capability of MPM and LGA on infinite polymer sequences. From the spatial perspective, we extract 3D descriptors of repeating monomers to capture spatial information. Finally, we design a cross-modal fusion mechanism to unify the topological and spatial information. Experimental validation across eight diverse polymer property prediction tasks reveals that MIPS achieves state-of-the-art performance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "14 pages, 8 figures, accepted by ACM Multimedia 2025 (oral)",
    "pdf_url": "https://arxiv.org/pdf/2507.20326v1",
    "published_date": "2025-07-27 15:34:51 UTC",
    "updated_date": "2025-07-27 15:34:51 UTC"
  },
  {
    "arxiv_id": "2507.20322v1",
    "title": "Artificial Intelligence In Patent And Market Intelligence: A New Paradigm For Technology Scouting",
    "authors": [
      "Manish Verma",
      "Vivek Sharma",
      "Vishal Singh"
    ],
    "abstract": "This paper presents the development of an AI powered software platform that leverages advanced large language models (LLMs) to transform technology scouting and solution discovery in industrial R&D. Traditional approaches to solving complex research and development challenges are often time consuming, manually driven, and heavily dependent on domain specific expertise. These methods typically involve navigating fragmented sources such as patent repositories, commercial product catalogs, and competitor data, leading to inefficiencies and incomplete insights. The proposed platform utilizes cutting edge LLM capabilities including semantic understanding, contextual reasoning, and cross-domain knowledge extraction to interpret problem statements and retrieve high-quality, sustainable solutions. The system processes unstructured patent texts, such as claims and technical descriptions, and systematically extracts potential innovations aligned with the given problem context. These solutions are then algorithmically organized under standardized technical categories and subcategories to ensure clarity and relevance across interdisciplinary domains. In addition to patent analysis, the platform integrates commercial intelligence by identifying validated market solutions and active organizations addressing similar challenges. This combined insight sourced from both intellectual property and real world product data enables R&D teams to assess not only technical novelty but also feasibility, scalability, and sustainability. The result is a comprehensive, AI driven scouting engine that reduces manual effort, accelerates innovation cycles, and enhances decision making in complex R&D environments.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "arXiv admin note: This version has been removed by arXiv administrators as the submitter did not have the right to agree to the license at the time of submission",
    "pdf_url": "https://arxiv.org/pdf/2507.20322v1",
    "published_date": "2025-07-27 15:22:39 UTC",
    "updated_date": "2025-07-27 15:22:39 UTC"
  },
  {
    "arxiv_id": "2507.20312v1",
    "title": "A Comparative Study of OpenMP Scheduling Algorithm Selection Strategies",
    "authors": [
      "Jonas H. Müller Korndörfer",
      "Ali Mohammed",
      "Ahmed Eleliemy",
      "Quentin Guilloteau",
      "Reto Krummenacher",
      "Florina M. Ciorba"
    ],
    "abstract": "Scientific and data science applications are becoming increasingly complex, with growing computational and memory demands. Modern high performance computing (HPC) systems provide high parallelism and heterogeneity across nodes, devices, and cores. To achieve good performance, effective scheduling and load balancing techniques are essential. Parallel programming frameworks such as OpenMP now offer a variety of advanced scheduling algorithms to support diverse applications and platforms. This creates an instance of the scheduling algorithm selection problem, which involves identifying the most suitable algorithm for a given combination of workload and system characteristics.\n  In this work, we explore learning-based approaches for selecting scheduling algorithms in OpenMP. We propose and evaluate expert-based and reinforcement learning (RL)-based methods, and conduct a detailed performance analysis across six applications and three systems. Our results show that RL methods are capable of learning high-performing scheduling decisions, although they require significant exploration, with the choice of reward function playing a key role. Expert-based methods, in contrast, rely on prior knowledge and involve less exploration, though they may not always identify the optimal algorithm for a specific application-system pair. By combining expert knowledge with RL-based learning, we achieve improved performance and greater adaptability.\n  Overall, this work demonstrates that dynamic selection of scheduling algorithms during execution is both viable and beneficial for OpenMP applications. The approach can also be extended to MPI-based programs, enabling optimization of scheduling decisions across multiple levels of parallelism.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.LG",
      "cs.PF"
    ],
    "primary_category": "cs.DC",
    "comment": "To appear at IEEE ACCESS",
    "pdf_url": "https://arxiv.org/pdf/2507.20312v1",
    "published_date": "2025-07-27 15:10:30 UTC",
    "updated_date": "2025-07-27 15:10:30 UTC"
  },
  {
    "arxiv_id": "2508.09991v2",
    "title": "Bridging AI Innovation and Healthcare Needs: Lessons Learned from Incorporating Modern NLP at The BC Cancer Registry",
    "authors": [
      "Lovedeep Gondara",
      "Gregory Arbour",
      "Raymond Ng",
      "Jonathan Simkin",
      "Shebnum Devji"
    ],
    "abstract": "Automating data extraction from clinical documents offers significant potential to improve efficiency in healthcare settings, yet deploying Natural Language Processing (NLP) solutions presents practical challenges. Drawing upon our experience implementing various NLP models for information extraction and classification tasks at the British Columbia Cancer Registry (BCCR), this paper shares key lessons learned throughout the project lifecycle. We emphasize the critical importance of defining problems based on clear business objectives rather than solely technical accuracy, adopting an iterative approach to development, and fostering deep interdisciplinary collaboration and co-design involving domain experts, end-users, and ML specialists from inception. Further insights highlight the need for pragmatic model selection (including hybrid approaches and simpler methods where appropriate), rigorous attention to data quality (representativeness, drift, annotation), robust error mitigation strategies involving human-in-the-loop validation and ongoing audits, and building organizational AI literacy. These practical considerations, generalizable beyond cancer registries, provide guidance for healthcare organizations seeking to successfully implement AI/NLP solutions to enhance data management processes and ultimately improve patient care and public health outcomes.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.SE"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.09991v2",
    "published_date": "2025-07-27 15:06:43 UTC",
    "updated_date": "2025-08-15 15:04:27 UTC"
  },
  {
    "arxiv_id": "2507.20295v1",
    "title": "Towards Generalized Parameter Tuning in Coherent Ising Machines: A Portfolio-Based Approach",
    "authors": [
      "Tatsuro Hanyu",
      "Takahiro Katagiri",
      "Daichi Mukunoki",
      "Tetsuya Hoshino"
    ],
    "abstract": "Coherent Ising Machines (CIMs) have recently gained attention as a promising computing model for solving combinatorial optimization problems. In particular, the Chaotic Amplitude Control (CAC) algorithm has demonstrated high solution quality, but its performance is highly sensitive to a large number of hyperparameters, making efficient tuning essential. In this study, we present an algorithm portfolio approach for hyperparameter tuning in CIMs employing Chaotic Amplitude Control with momentum (CACm) algorithm. Our method incorporates multiple search strategies, enabling flexible and effective adaptation to the characteristics of the hyperparameter space. Specifically, we propose two representative tuning methods, Method A and Method B. Method A optimizes each hyperparameter sequentially with a fixed total number of trials, while Method B prioritizes hyperparameters based on initial evaluations before applying Method A in order. Performance evaluations were conducted on the Supercomputer \"Flow\" at Nagoya University, using planted Wishart instances and Time to Solution (TTS) as the evaluation metric. Compared to the baseline performance with best-known hyperparameters, Method A achieved up to 1.47x improvement, and Method B achieved up to 1.65x improvement. These results demonstrate the effectiveness of the algorithm portfolio approach in enhancing the tuning process for CIMs.",
    "categories": [
      "cs.PF",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.PF",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.20295v1",
    "published_date": "2025-07-27 14:18:54 UTC",
    "updated_date": "2025-07-27 14:18:54 UTC"
  },
  {
    "arxiv_id": "2507.20280v1",
    "title": "SciToolAgent: A Knowledge Graph-Driven Scientific Agent for Multi-Tool Integration",
    "authors": [
      "Keyan Ding",
      "Jing Yu",
      "Junjie Huang",
      "Yuchen Yang",
      "Qiang Zhang",
      "Huajun Chen"
    ],
    "abstract": "Scientific research increasingly relies on specialized computational tools, yet effectively utilizing these tools demands substantial domain expertise. While Large Language Models (LLMs) show promise in tool automation, they struggle to seamlessly integrate and orchestrate multiple tools for complex scientific workflows. Here, we present SciToolAgent, an LLM-powered agent that automates hundreds of scientific tools across biology, chemistry, and materials science. At its core, SciToolAgent leverages a scientific tool knowledge graph that enables intelligent tool selection and execution through graph-based retrieval-augmented generation. The agent also incorporates a comprehensive safety-checking module to ensure responsible and ethical tool usage. Extensive evaluations on a curated benchmark demonstrate that SciToolAgent significantly outperforms existing approaches. Case studies in protein engineering, chemical reactivity prediction, chemical synthesis, and metal-organic framework screening further demonstrate SciToolAgent's capability to automate complex scientific workflows, making advanced research tools accessible to both experts and non-experts.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "21 pages, 6 figures",
    "pdf_url": "https://arxiv.org/pdf/2507.20280v1",
    "published_date": "2025-07-27 13:55:35 UTC",
    "updated_date": "2025-07-27 13:55:35 UTC"
  },
  {
    "arxiv_id": "2507.20263v1",
    "title": "Learning from Expert Factors: Trajectory-level Reward Shaping for Formulaic Alpha Mining",
    "authors": [
      "Junjie Zhao",
      "Chengxi Zhang",
      "Chenkai Wang",
      "Peng Yang"
    ],
    "abstract": "Reinforcement learning (RL) has successfully automated the complex process of mining formulaic alpha factors, for creating interpretable and profitable investment strategies. However, existing methods are hampered by the sparse rewards given the underlying Markov Decision Process. This inefficiency limits the exploration of the vast symbolic search space and destabilizes the training process. To address this, Trajectory-level Reward Shaping (TLRS), a novel reward shaping method, is proposed. TLRS provides dense, intermediate rewards by measuring the subsequence-level similarity between partially generated expressions and a set of expert-designed formulas. Furthermore, a reward centering mechanism is introduced to reduce training variance. Extensive experiments on six major Chinese and U.S. stock indices show that TLRS significantly improves the predictive power of mined factors, boosting the Rank Information Coefficient by 9.29% over existing potential-based shaping algorithms. Notably, TLRS achieves a major leap in computational efficiency by reducing its time complexity with respect to the feature dimension from linear to constant, which is a significant improvement over distance-based baselines.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-fin.PM"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.20263v1",
    "published_date": "2025-07-27 13:14:48 UTC",
    "updated_date": "2025-07-27 13:14:48 UTC"
  },
  {
    "arxiv_id": "2507.20252v3",
    "title": "Post-Completion Learning for Language Models",
    "authors": [
      "Xiang Fei",
      "Siqi Wang",
      "Shu Wei",
      "Yuxiang Nie",
      "Wei Shi",
      "Hao Feng",
      "Chao Feng",
      "Can Huang"
    ],
    "abstract": "Current language model training paradigms typically terminate learning upon reaching the end-of-sequence (<eos>) token, overlooking the potential learning opportunities in the post-completion space. We propose Post-Completion Learning (PCL), a novel training framework that systematically utilizes the sequence space after model output completion, to enhance both the reasoning and self-evaluation abilities. PCL enables models to continue generating self-assessments and reward predictions during training, while maintaining efficient inference by stopping at the completion point.\n  To fully utilize this post-completion space, we design a white-box reinforcement learning method: let the model evaluate the output content according to the reward rules, then calculate and align the score with the reward functions for supervision. We implement dual-track SFT to optimize both reasoning and evaluation capabilities, and mixed it with RL training to achieve multi-objective hybrid optimization.\n  Experimental results on different datasets and models demonstrate consistent improvements over traditional SFT and RL methods. Our method provides a new technical path for language model training that enhances output quality while preserving deployment efficiency.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.20252v3",
    "published_date": "2025-07-27 12:47:26 UTC",
    "updated_date": "2025-08-12 11:22:33 UTC"
  },
  {
    "arxiv_id": "2507.20243v1",
    "title": "Protein-SE(3): Benchmarking SE(3)-based Generative Models for Protein Structure Design",
    "authors": [
      "Lang Yu",
      "Zhangyang Gao",
      "Cheng Tan",
      "Qin Chen",
      "Jie Zhou",
      "Liang He"
    ],
    "abstract": "SE(3)-based generative models have shown great promise in protein geometry modeling and effective structure design. However, the field currently lacks a modularized benchmark to enable comprehensive investigation and fair comparison of different methods. In this paper, we propose Protein-SE(3), a new benchmark based on a unified training framework, which comprises protein scaffolding tasks, integrated generative models, high-level mathematical abstraction, and diverse evaluation metrics. Recent advanced generative models designed for protein scaffolding, from multiple perspectives like DDPM (Genie1 and Genie2), Score Matching (FrameDiff and RfDiffusion) and Flow Matching (FoldFlow and FrameFlow) are integrated into our framework. All integrated methods are fairly investigated with the same training dataset and evaluation metrics. Furthermore, we provide a high-level abstraction of the mathematical foundations behind the generative models, enabling fast prototyping of future algorithms without reliance on explicit protein structures. Accordingly, we release the first comprehensive benchmark built upon unified training framework for SE(3)-based protein structure design, which is publicly accessible at https://github.com/BruthYU/protein-se3.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.20243v1",
    "published_date": "2025-07-27 11:53:05 UTC",
    "updated_date": "2025-07-27 11:53:05 UTC"
  },
  {
    "arxiv_id": "2507.21186v1",
    "title": "Contrast-CAT: Contrasting Activations for Enhanced Interpretability in Transformer-based Text Classifiers",
    "authors": [
      "Sungmin Han",
      "Jeonghyun Lee",
      "Sangkyun Lee"
    ],
    "abstract": "Transformers have profoundly influenced AI research, but explaining their decisions remains challenging -- even for relatively simpler tasks such as classification -- which hinders trust and safe deployment in real-world applications. Although activation-based attribution methods effectively explain transformer-based text classification models, our findings reveal that these methods can be undermined by class-irrelevant features within activations, leading to less reliable interpretations. To address this limitation, we propose Contrast-CAT, a novel activation contrast-based attribution method that refines token-level attributions by filtering out class-irrelevant features. By contrasting the activations of an input sequence with reference activations, Contrast-CAT generates clearer and more faithful attribution maps. Experimental results across various datasets and models confirm that Contrast-CAT consistently outperforms state-of-the-art methods. Notably, under the MoRF setting, it achieves average improvements of x1.30 in AOPC and x2.25 in LOdds over the most competing methods, demonstrating its effectiveness in enhancing interpretability for transformer-based text classification.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.21186v1",
    "published_date": "2025-07-27 11:53:01 UTC",
    "updated_date": "2025-07-27 11:53:01 UTC"
  },
  {
    "arxiv_id": "2507.20230v2",
    "title": "A Multi-Agent System Enables Versatile Information Extraction from the Chemical Literature",
    "authors": [
      "Yufan Chen",
      "Ching Ting Leung",
      "Bowen Yu",
      "Jianwei Sun",
      "Yong Huang",
      "Linyan Li",
      "Hao Chen",
      "Hanyu Gao"
    ],
    "abstract": "To fully expedite AI-powered chemical research, high-quality chemical databases are the cornerstone. Automatic extraction of chemical information from the literature is essential for constructing reaction databases, but it is currently limited by the multimodality and style variability of chemical information. In this work, we developed a multimodal large language model (MLLM)-based multi-agent system for robust and automated chemical information extraction. It utilizes the MLLM's strong reasoning capability to understand the structure of diverse chemical graphics, decompose the extraction task into sub-tasks, and coordinate a set of specialized agents, each combining the capabilities of the MLLM with the precise, domain-specific strengths of dedicated tools, to solve them accurately and integrate the results into a unified output. Our system achieved an F1 score of 80.8% on a benchmark dataset of sophisticated multimodal chemical reaction graphics from the literature, surpassing the previous state-of-the-art model (F1 score of 35.6%) by a significant margin. Additionally, it demonstrated consistent improvements in key sub-tasks, including molecular image recognition, reaction image parsing, named entity recognition and text-based reaction extraction. This work is a critical step toward automated chemical information extraction into structured datasets, which will be a strong promoter of AI-driven chemical research.",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.20230v2",
    "published_date": "2025-07-27 11:16:57 UTC",
    "updated_date": "2025-07-29 02:55:37 UTC"
  },
  {
    "arxiv_id": "2507.20226v2",
    "title": "Improving Subgraph Matching by Combining Algorithms and Graph Neural Networks",
    "authors": [
      "Shuyang Guo",
      "Wenjin Xie",
      "Ping Lu",
      "Ting Deng",
      "Richong Zhang",
      "Jianxin Li",
      "Xiangping Huang",
      "Zhongyi Liu"
    ],
    "abstract": "Homomorphism is a key mapping technique between graphs that preserves their structure. Given a graph and a pattern, the subgraph homomorphism problem involves finding a mapping from the pattern to the graph, ensuring that adjacent vertices in the pattern are mapped to adjacent vertices in the graph. Unlike subgraph isomorphism, which requires a one-to-one mapping, homomorphism allows multiple vertices in the pattern to map to the same vertex in the graph, making it more complex. We propose HFrame, the first graph neural network-based framework for subgraph homomorphism, which integrates traditional algorithms with machine learning techniques. We demonstrate that HFrame outperforms standard graph neural networks by being able to distinguish more graph pairs where the pattern is not homomorphic to the graph. Additionally, we provide a generalization error bound for HFrame. Through experiments on both real-world and synthetic graphs, we show that HFrame is up to 101.91 times faster than exact matching algorithms and achieves an average accuracy of 0.962.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "KDD 2025",
    "pdf_url": "https://arxiv.org/pdf/2507.20226v2",
    "published_date": "2025-07-27 11:10:15 UTC",
    "updated_date": "2025-12-17 09:55:34 UTC"
  },
  {
    "arxiv_id": "2507.20221v1",
    "title": "Multi-Attention Stacked Ensemble for Lung Cancer Detection in CT Scans",
    "authors": [
      "Uzzal Saha",
      "Surya Prakash"
    ],
    "abstract": "In this work, we address the challenge of binary lung nodule classification (benign vs malignant) using CT images by proposing a multi-level attention stacked ensemble of deep neural networks. Three pretrained backbones -- EfficientNet V2 S, MobileViT XXS, and DenseNet201 -- are each adapted with a custom classification head tailored to 96 x 96 pixel inputs. A two-stage attention mechanism learns both model-wise and class-wise importance scores from concatenated logits, and a lightweight meta-learner refines the final prediction. To mitigate class imbalance and improve generalization, we employ dynamic focal loss with empirically calculated class weights, MixUp augmentation during training, and test-time augmentation at inference. Experiments on the LIDC-IDRI dataset demonstrate exceptional performance, achieving 98.09 accuracy and 0.9961 AUC, representing a 35 percent reduction in error rate compared to state-of-the-art methods. The model exhibits balanced performance across sensitivity (98.73) and specificity (98.96), with particularly strong results on challenging cases where radiologist disagreement was high. Statistical significance testing confirms the robustness of these improvements across multiple experimental runs. Our approach can serve as a robust, automated aid for radiologists in lung cancer screening.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "26 pages, 14 figures",
    "pdf_url": "https://arxiv.org/pdf/2507.20221v1",
    "published_date": "2025-07-27 11:03:07 UTC",
    "updated_date": "2025-07-27 11:03:07 UTC"
  },
  {
    "arxiv_id": "2507.20217v2",
    "title": "Humanoid Occupancy: Enabling A Generalized Multimodal Occupancy Perception System on Humanoid Robots",
    "authors": [
      "Wei Cui",
      "Haoyu Wang",
      "Wenkang Qin",
      "Yijie Guo",
      "Gang Han",
      "Wen Zhao",
      "Jiahang Cao",
      "Zhang Zhang",
      "Jiaru Zhong",
      "Jingkai Sun",
      "Pihai Sun",
      "Shuai Shi",
      "Botuo Jiang",
      "Jiahao Ma",
      "Jiaxu Wang",
      "Hao Cheng",
      "Zhichao Liu",
      "Yang Wang",
      "Zheng Zhu",
      "Guan Huang",
      "Jian Tang",
      "Qiang Zhang"
    ],
    "abstract": "Humanoid robot technology is advancing rapidly, with manufacturers introducing diverse heterogeneous visual perception modules tailored to specific scenarios. Among various perception paradigms, occupancy-based representation has become widely recognized as particularly suitable for humanoid robots, as it provides both rich semantic and 3D geometric information essential for comprehensive environmental understanding. In this work, we present Humanoid Occupancy, a generalized multimodal occupancy perception system that integrates hardware and software components, data acquisition devices, and a dedicated annotation pipeline. Our framework employs advanced multi-modal fusion techniques to generate grid-based occupancy outputs encoding both occupancy status and semantic labels, thereby enabling holistic environmental understanding for downstream tasks such as task planning and navigation. To address the unique challenges of humanoid robots, we overcome issues such as kinematic interference and occlusion, and establish an effective sensor layout strategy. Furthermore, we have developed the first panoramic occupancy dataset specifically for humanoid robots, offering a valuable benchmark and resource for future research and development in this domain. The network architecture incorporates multi-modal feature fusion and temporal information integration to ensure robust perception. Overall, Humanoid Occupancy delivers effective environmental perception for humanoid robots and establishes a technical foundation for standardizing universal visual modules, paving the way for the widespread deployment of humanoid robots in complex real-world scenarios.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.RO",
    "comment": "Tech Report",
    "pdf_url": "https://arxiv.org/pdf/2507.20217v2",
    "published_date": "2025-07-27 10:47:00 UTC",
    "updated_date": "2025-07-29 02:24:52 UTC"
  },
  {
    "arxiv_id": "2507.20199v3",
    "title": "StepFun-Prover Preview: Let's Think and Verify Step by Step",
    "authors": [
      "Shijie Shang",
      "Ruosi Wan",
      "Yue Peng",
      "Yutong Wu",
      "Xiong-hui Chen",
      "Jie Yan",
      "Xiangyu Zhang"
    ],
    "abstract": "We present StepFun-Prover Preview, a large language model designed for formal theorem proving through tool-integrated reasoning. Using a reinforcement learning pipeline that incorporates tool-based interactions, StepFun-Prover can achieve strong performance in generating Lean 4 proofs with minimal sampling. Our approach enables the model to emulate human-like problem-solving strategies by iteratively refining proofs based on real-time environment feedback. On the miniF2F-test benchmark, StepFun-Prover achieves a pass@1 success rate of $70.0\\%$. Beyond advancing benchmark performance, we introduce an end-to-end training framework for developing tool-integrated reasoning models, offering a promising direction for automated theorem proving and Math AI assistant.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Added links to GitHub and Hugging Face",
    "pdf_url": "https://arxiv.org/pdf/2507.20199v3",
    "published_date": "2025-07-27 09:38:32 UTC",
    "updated_date": "2025-08-13 10:58:50 UTC"
  },
  {
    "arxiv_id": "2507.20197v1",
    "title": "Color histogram equalization and fine-tuning to improve expression recognition of (partially occluded) faces on sign language datasets",
    "authors": [
      "Fabrizio Nunnari",
      "Alakshendra Jyotsnaditya Ramkrishna Singh",
      "Patrick Gebhard"
    ],
    "abstract": "The goal of this investigation is to quantify to what extent computer vision methods can correctly classify facial expressions on a sign language dataset. We extend our experiments by recognizing expressions using only the upper or lower part of the face, which is needed to further investigate the difference in emotion manifestation between hearing and deaf subjects. To take into account the peculiar color profile of a dataset, our method introduces a color normalization stage based on histogram equalization and fine-tuning. The results show the ability to correctly recognize facial expressions with 83.8% mean sensitivity and very little variance (.042) among classes. Like for humans, recognition of expressions from the lower half of the face (79.6%) is higher than that from the upper half (77.9%). Noticeably, the classification accuracy from the upper half of the face is higher than human level.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.20197v1",
    "published_date": "2025-07-27 09:29:15 UTC",
    "updated_date": "2025-07-27 09:29:15 UTC"
  },
  {
    "arxiv_id": "2507.20191v1",
    "title": "Partial Domain Adaptation via Importance Sampling-based Shift Correction",
    "authors": [
      "Cheng-Jun Guo",
      "Chuan-Xian Ren",
      "You-Wei Luo",
      "Xiao-Lin Xu",
      "Hong Yan"
    ],
    "abstract": "Partial domain adaptation (PDA) is a challenging task in real-world machine learning scenarios. It aims to transfer knowledge from a labeled source domain to a related unlabeled target domain, where the support set of the source label distribution subsumes the target one. Previous PDA works managed to correct the label distribution shift by weighting samples in the source domain. However, the simple reweighing technique cannot explore the latent structure and sufficiently use the labeled data, and then models are prone to over-fitting on the source domain. In this work, we propose a novel importance sampling-based shift correction (IS$^2$C) method, where new labeled data are sampled from a built sampling domain, whose label distribution is supposed to be the same as the target domain, to characterize the latent structure and enhance the generalization ability of the model. We provide theoretical guarantees for IS$^2$C by proving that the generalization error can be sufficiently dominated by IS$^2$C. In particular, by implementing sampling with the mixture distribution, the extent of shift between source and sampling domains can be connected to generalization error, which provides an interpretable way to build IS$^2$C. To improve knowledge transfer, an optimal transport-based independence criterion is proposed for conditional distribution alignment, where the computation of the criterion can be adjusted to reduce the complexity from $\\mathcal{O}(n^3)$ to $\\mathcal{O}(n^2)$ in realistic PDA scenarios. Extensive experiments on PDA benchmarks validate the theoretical results and demonstrate the effectiveness of our IS$^2$C over existing methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.20191v1",
    "published_date": "2025-07-27 09:19:07 UTC",
    "updated_date": "2025-07-27 09:19:07 UTC"
  },
  {
    "arxiv_id": "2507.20189v1",
    "title": "NeuroCLIP: A Multimodal Contrastive Learning Method for rTMS-treated Methamphetamine Addiction Analysis",
    "authors": [
      "Chengkai Wang",
      "Di Wu",
      "Yunsheng Liao",
      "Wenyao Zheng",
      "Ziyi Zeng",
      "Xurong Gao",
      "Hemmings Wu",
      "Zhoule Zhu",
      "Jie Yang",
      "Lihua Zhong",
      "Weiwei Cheng",
      "Yun-Hsuan Chen",
      "Mohamad Sawan"
    ],
    "abstract": "Methamphetamine dependence poses a significant global health challenge, yet its assessment and the evaluation of treatments like repetitive transcranial magnetic stimulation (rTMS) frequently depend on subjective self-reports, which may introduce uncertainties. While objective neuroimaging modalities such as electroencephalography (EEG) and functional near-infrared spectroscopy (fNIRS) offer alternatives, their individual limitations and the reliance on conventional, often hand-crafted, feature extraction can compromise the reliability of derived biomarkers. To overcome these limitations, we propose NeuroCLIP, a novel deep learning framework integrating simultaneously recorded EEG and fNIRS data through a progressive learning strategy. This approach offers a robust and trustworthy biomarker for methamphetamine addiction. Validation experiments show that NeuroCLIP significantly improves discriminative capabilities among the methamphetamine-dependent individuals and healthy controls compared to models using either EEG or only fNIRS alone. Furthermore, the proposed framework facilitates objective, brain-based evaluation of rTMS treatment efficacy, demonstrating measurable shifts in neural patterns towards healthy control profiles after treatment. Critically, we establish the trustworthiness of the multimodal data-driven biomarker by showing its strong correlation with psychometrically validated craving scores. These findings suggest that biomarker derived from EEG-fNIRS data via NeuroCLIP offers enhanced robustness and reliability over single-modality approaches, providing a valuable tool for addiction neuroscience research and potentially improving clinical assessments.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG",
      "q-bio.NC"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.20189v1",
    "published_date": "2025-07-27 09:16:39 UTC",
    "updated_date": "2025-07-27 09:16:39 UTC"
  },
  {
    "arxiv_id": "2507.20181v1",
    "title": "SGPO: Self-Generated Preference Optimization based on Self-Improver",
    "authors": [
      "Hyeonji Lee",
      "Daejin Jo",
      "Seohwan Yun",
      "Sungwoong Kim"
    ],
    "abstract": "Large language models (LLMs), despite their extensive pretraining on diverse datasets, require effective alignment to human preferences for practical and reliable deployment. Conventional alignment methods typically employ off-policy learning and depend on human-annotated datasets, which limits their broad applicability and introduces distribution shift issues during training. To address these challenges, we propose Self-Generated Preference Optimization based on Self-Improver (SGPO), an innovative alignment framework that leverages an on-policy self-improving mechanism. Specifically, the improver refines responses from a policy model to self-generate preference data for direct preference optimization (DPO) of the policy model. Here, the improver and policy are unified into a single model, and in order to generate higher-quality preference data, this self-improver learns to make incremental yet discernible improvements to the current responses by referencing supervised fine-tuning outputs. Experimental results on AlpacaEval 2.0 and Arena-Hard show that the proposed SGPO significantly improves performance over DPO and baseline self-improving methods without using external preference data.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.20181v1",
    "published_date": "2025-07-27 08:55:40 UTC",
    "updated_date": "2025-07-27 08:55:40 UTC"
  },
  {
    "arxiv_id": "2508.00892v1",
    "title": "HoneyImage: Verifiable, Harmless, and Stealthy Dataset Ownership Verification for Image Models",
    "authors": [
      "Zhihao Zhu",
      "Jiale Han",
      "Yi Yang"
    ],
    "abstract": "Image-based AI models are increasingly deployed across a wide range of domains, including healthcare, security, and consumer applications. However, many image datasets carry sensitive or proprietary content, raising critical concerns about unauthorized data usage. Data owners therefore need reliable mechanisms to verify whether their proprietary data has been misused to train third-party models. Existing solutions, such as backdoor watermarking and membership inference, face inherent trade-offs between verification effectiveness and preservation of data integrity. In this work, we propose HoneyImage, a novel method for dataset ownership verification in image recognition models. HoneyImage selectively modifies a small number of hard samples to embed imperceptible yet verifiable traces, enabling reliable ownership verification while maintaining dataset integrity. Extensive experiments across four benchmark datasets and multiple model architectures show that HoneyImage consistently achieves strong verification accuracy with minimal impact on downstream performance while maintaining imperceptible. The proposed HoneyImage method could provide data owners with a practical mechanism to protect ownership over valuable image datasets, encouraging safe sharing and unlocking the full transformative potential of data-driven AI.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.00892v1",
    "published_date": "2025-07-27 08:44:47 UTC",
    "updated_date": "2025-07-27 08:44:47 UTC"
  },
  {
    "arxiv_id": "2507.20174v2",
    "title": "LRR-Bench: Left, Right or Rotate? Vision-Language models Still Struggle With Spatial Understanding Tasks",
    "authors": [
      "Fei Kong"
    ],
    "abstract": "Real-world applications, such as autonomous driving and humanoid robot manipulation, require precise spatial perception. However, it remains underexplored how Vision-Language Models (VLMs) recognize spatial relationships and perceive spatial movement. In this work, we introduce a spatial evaluation pipeline and construct a corresponding benchmark. Specifically, we categorize spatial understanding into two main types: absolute spatial understanding, which involves querying the absolute spatial position (e.g., left, right) of an object within an image, and 3D spatial understanding, which includes movement and rotation. Notably, our dataset is entirely synthetic, enabling the generation of test samples at a low cost while also preventing dataset contamination. We conduct experiments on multiple state-of-the-art VLMs and observe that there is significant room for improvement in their spatial understanding abilities. Explicitly, in our experiments, humans achieve near-perfect performance on all tasks, whereas current VLMs attain human-level performance only on the two simplest tasks. For the remaining tasks, the performance of VLMs is distinctly lower than that of humans. In fact, the best-performing Vision-Language Models even achieve near-zero scores on multiple tasks. The dataset and code are available on https://github.com/kong13661/LRR-Bench.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.20174v2",
    "published_date": "2025-07-27 08:31:24 UTC",
    "updated_date": "2026-01-21 05:06:39 UTC"
  },
  {
    "arxiv_id": "2507.20173v1",
    "title": "High-Performance Parallel Optimization of the Fish School Behaviour on the Setonix Platform Using OpenMP",
    "authors": [
      "Haitian Wang",
      "Long Qin"
    ],
    "abstract": "This paper presents an in-depth investigation into the high-performance parallel optimization of the Fish School Behaviour (FSB) algorithm on the Setonix supercomputing platform using the OpenMP framework. Given the increasing demand for enhanced computational capabilities for complex, large-scale calculations across diverse domains, there's an imperative need for optimized parallel algorithms and computing structures. The FSB algorithm, inspired by nature's social behavior patterns, provides an ideal platform for parallelization due to its iterative and computationally intensive nature. This study leverages the capabilities of the Setonix platform and the OpenMP framework to analyze various aspects of multi-threading, such as thread counts, scheduling strategies, and OpenMP constructs, aiming to discern patterns and strategies that can elevate program performance. Experiments were designed to rigorously test different configurations, and our results not only offer insights for parallel optimization of FSB on Setonix but also provide valuable references for other parallel computational research using OpenMP. Looking forward, other factors, such as cache behavior and thread scheduling strategies at micro and macro levels, hold potential for further exploration and optimization.",
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.20173v1",
    "published_date": "2025-07-27 08:25:08 UTC",
    "updated_date": "2025-07-27 08:25:08 UTC"
  },
  {
    "arxiv_id": "2507.22174v2",
    "title": "Spatial-Temporal Reinforcement Learning for Network Routing with Non-Markovian Traffic",
    "authors": [
      "Molly Wang",
      "Kin. K Leung"
    ],
    "abstract": "Reinforcement Learning (RL) has been widely used for packet routing in communication networks, but traditional RL methods rely on the Markov assumption that the current state contains all necessary information for decision-making. In reality, internet traffic is non-Markovian, and past states do influence routing performance. Moreover, common deep RL approaches use function approximators, such as neural networks, that do not model the spatial structure in network topologies. To address these shortcomings, we design a network environment with non-Markovian traffic and introduce a spatial-temporal RL (STRL) framework for packet routing. Our approach outperforms traditional baselines by more than 19% during training and 7% for inference despite a change in network topology.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.22174v2",
    "published_date": "2025-07-27 08:00:43 UTC",
    "updated_date": "2025-07-31 17:34:18 UTC"
  },
  {
    "arxiv_id": "2507.20164v1",
    "title": "ASNN: Learning to Suggest Neural Architectures from Performance Distributions",
    "authors": [
      "Jinwook Hong"
    ],
    "abstract": "The architecture of a neural network (NN) plays a critical role in determining its performance. However, there is no general closed-form function that maps between network structure and accuracy, making the process of architecture design largely heuristic or search-based. In this study, we propose the Architecture Suggesting Neural Network (ASNN), a model designed to learn the relationship between NN architecture and its test accuracy, and to suggest improved architectures accordingly. To train ASNN, we constructed datasets using TensorFlow-based models with varying numbers of layers and nodes. Experimental results were collected for both 2-layer and 3-layer architectures across a grid of configurations, each evaluated with 10 repeated trials to account for stochasticity. Accuracy values were treated as inputs, and architectural parameters as outputs. The trained ASNN was then used iteratively to predict architectures that yield higher performance. In both 2-layer and 3-layer cases, ASNN successfully suggested architectures that outperformed the best results found in the original training data. Repeated prediction and retraining cycles led to the discovery of architectures with improved mean test accuracies, demonstrating the model's capacity to generalize the performance-structure relationship. These results suggest that ASNN provides an efficient alternative to random search for architecture optimization, and offers a promising approach toward automating neural network design. \"Parts of the manuscript, including text editing and expression refinement, were supported by OpenAI's ChatGPT. All content was reviewed and verified by the authors.\"",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "10 pages",
    "pdf_url": "https://arxiv.org/pdf/2507.20164v1",
    "published_date": "2025-07-27 07:39:33 UTC",
    "updated_date": "2025-07-27 07:39:33 UTC"
  },
  {
    "arxiv_id": "2507.20156v1",
    "title": "Trust the Model: Compact VLMs as In-Context Judges for Image-Text Data Quality",
    "authors": [
      "Daulet Toibazar",
      "Kesen Wang",
      "Sherif Mohamed",
      "Abdulaziz Al-Badawi",
      "Abdulrahman Alfulayt",
      "Pedro J. Moreno"
    ],
    "abstract": "Vision-language models (VLMs) extend the conventional large language models by integrating visual data, enabling richer multimodal reasoning and significantly broadens the practical applications of AI. However, including visual inputs also brings new challenges in maintaining data quality. Empirical evidence consistently shows that carefully curated and representative training examples often yield superior results compared to simply increasing the quantity of data. Inspired by this observation, we introduce a streamlined data filtration framework that employs a compact VLM, fine-tuned on a high-quality image-caption annotated dataset. This model effectively evaluates and filters potential training samples based on caption and image quality and alignment. Unlike previous approaches, which typically add auxiliary filtration modules on top of existing full-scale VLMs, our method exclusively utilizes the inherent evaluative capability of a purpose-built small VLM. This strategy eliminates the need for extra modules and reduces training overhead. Our lightweight model efficiently filters out inaccurate, noisy web data, improving image-text alignment and caption linguistic fluency. Experimental results show that datasets underwent high-precision filtration using our compact VLM perform on par with, or even surpass, larger and noisier datasets gathered through high-volume web crawling. Thus, our method provides a lightweight yet robust solution for building high-quality vision-language training corpora. \\\\ \\textbf{Availability and implementation:} Our compact VLM filtration model, training data, utility scripts, and Supplementary data (Appendices) are freely available at https://github.com/daulettoibazar/Compact_VLM_Filter.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.20156v1",
    "published_date": "2025-07-27 07:20:25 UTC",
    "updated_date": "2025-07-27 07:20:25 UTC"
  },
  {
    "arxiv_id": "2507.20152v1",
    "title": "Goal Alignment in LLM-Based User Simulators for Conversational AI",
    "authors": [
      "Shuhaib Mehri",
      "Xiaocheng Yang",
      "Takyoung Kim",
      "Gokhan Tur",
      "Shikib Mehri",
      "Dilek Hakkani-Tür"
    ],
    "abstract": "User simulators are essential to conversational AI, enabling scalable agent development and evaluation through simulated interactions. While current Large Language Models (LLMs) have advanced user simulation capabilities, we reveal that they struggle to consistently demonstrate goal-oriented behavior across multi-turn conversations--a critical limitation that compromises their reliability in downstream applications. We introduce User Goal State Tracking (UGST), a novel framework that tracks user goal progression throughout conversations. Leveraging UGST, we present a three-stage methodology for developing user simulators that can autonomously track goal progression and reason to generate goal-aligned responses. Moreover, we establish comprehensive evaluation metrics for measuring goal alignment in user simulators, and demonstrate that our approach yields substantial improvements across two benchmarks (MultiWOZ 2.4 and τ-Bench). Our contributions address a critical gap in conversational AI and establish UGST as an essential framework for developing goal-aligned user simulators.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.20152v1",
    "published_date": "2025-07-27 07:07:12 UTC",
    "updated_date": "2025-07-27 07:07:12 UTC"
  },
  {
    "arxiv_id": "2507.20150v1",
    "title": "The Policy Cliff: A Theoretical Analysis of Reward-Policy Maps in Large Language Models",
    "authors": [
      "Xingcheng Xu"
    ],
    "abstract": "Reinforcement learning (RL) plays a crucial role in shaping the behavior of large language and reasoning models (LLMs/LRMs). However, it often produces brittle and unstable policies, leading to critical failures such as spurious reasoning, deceptive alignment, and instruction disobedience that undermine the trustworthiness and safety of LLMs/LRMs. Currently, these issues lack a unified theoretical explanation and are typically addressed using ad-hoc heuristics. This paper presents a rigorous mathematical framework for analyzing the stability of the mapping from a reward function to the optimal policy. We show that policy brittleness often stems from non-unique optimal actions, a common occurrence when multiple valid traces exist in a reasoning task. This theoretical lens provides a unified explanation for a range of seemingly disparate failures, reframing them as rational outcomes of optimizing rewards that may be incomplete or noisy, especially in the presence of action degeneracy. We extend this analysis from the fundamental single-reward setting to the more realistic multi-reward RL across diverse domains, showing how stability is governed by an \"effective reward\" aggregation mechanism. We also prove that entropy regularization restores policy stability at the cost of increased stochasticity. Our framework provides a unified explanation for recent empirical findings on deceptive reasoning, instruction-following trade-offs, and RLHF-induced sophistry, and is further validated through perturbation experiments in multi-reward RL. This work advances policy-stability analysis from empirical heuristics towards a principled theory, offering essential insights for designing safer and more trustworthy AI systems.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.20150v1",
    "published_date": "2025-07-27 06:56:10 UTC",
    "updated_date": "2025-07-27 06:56:10 UTC"
  },
  {
    "arxiv_id": "2507.20145v1",
    "title": "Multi-Agent Interactive Question Generation Framework for Long Document Understanding",
    "authors": [
      "Kesen Wang",
      "Daulet Toibazar",
      "Abdulrahman Alfulayt",
      "Abdulaziz S. Albadawi",
      "Ranya A. Alkahtani",
      "Asma A. Ibrahim",
      "Haneen A. Alhomoud",
      "Sherif Mohamed",
      "Pedro J. Moreno"
    ],
    "abstract": "Document Understanding (DU) in long-contextual scenarios with complex layouts remains a significant challenge in vision-language research. Although Large Vision-Language Models (LVLMs) excel at short-context DU tasks, their performance declines in long-context settings. A key limitation is the scarcity of fine-grained training data, particularly for low-resource languages such as Arabic. Existing state-of-the-art techniques rely heavily on human annotation, which is costly and inefficient. We propose a fully automated, multi-agent interactive framework to generate long-context questions efficiently. Our approach efficiently generates high-quality single- and multi-page questions for extensive English and Arabic documents, covering hundreds of pages across diverse domains. This facilitates the development of LVLMs with enhanced long-context understanding ability. Experimental results in this work have shown that our generated English and Arabic questions (\\textbf{AraEngLongBench}) are quite challenging to major open- and close-source LVLMs. The code and data proposed in this work can be found in https://github.com/wangk0b/Multi_Agentic_QA_Long_Doc.git. Sample Question and Answer (QA) pairs and structured system prompts can be found in the Appendix.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.20145v1",
    "published_date": "2025-07-27 06:44:53 UTC",
    "updated_date": "2025-07-27 06:44:53 UTC"
  },
  {
    "arxiv_id": "2507.20144v1",
    "title": "Awesome-OL: An Extensible Toolkit for Online Learning",
    "authors": [
      "Zeyi Liu",
      "Songqiao Hu",
      "Pengyu Han",
      "Jiaming Liu",
      "Xiao He"
    ],
    "abstract": "In recent years, online learning has attracted increasing attention due to its adaptive capability to process streaming and non-stationary data. To facilitate algorithm development and practical deployment in this area, we introduce Awesome-OL, an extensible Python toolkit tailored for online learning research. Awesome-OL integrates state-of-the-art algorithm, which provides a unified framework for reproducible comparisons, curated benchmark datasets, and multi-modal visualization. Built upon the scikit-multiflow open-source infrastructure, Awesome-OL emphasizes user-friendly interactions without compromising research flexibility or extensibility. The source code is publicly available at: https://github.com/liuzy0708/Awesome-OL.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "7 pages",
    "pdf_url": "https://arxiv.org/pdf/2507.20144v1",
    "published_date": "2025-07-27 06:34:37 UTC",
    "updated_date": "2025-07-27 06:34:37 UTC"
  },
  {
    "arxiv_id": "2507.20143v1",
    "title": "Concept Learning for Cooperative Multi-Agent Reinforcement Learning",
    "authors": [
      "Zhonghan Ge",
      "Yuanyang Zhu",
      "Chunlin Chen"
    ],
    "abstract": "Despite substantial progress in applying neural networks (NN) to multi-agent reinforcement learning (MARL) areas, they still largely suffer from a lack of transparency and interoperability. However, its implicit cooperative mechanism is not yet fully understood due to black-box networks. In this work, we study an interpretable value decomposition framework via concept bottleneck models, which promote trustworthiness by conditioning credit assignment on an intermediate level of human-like cooperation concepts. To address this problem, we propose a novel value-based method, named Concepts learning for Multi-agent Q-learning (CMQ), that goes beyond the current performance-vs-interpretability trade-off by learning interpretable cooperation concepts. CMQ represents each cooperation concept as a supervised vector, as opposed to existing models where the information flowing through their end-to-end mechanism is concept-agnostic. Intuitively, using individual action value conditioning on global state embeddings to represent each concept allows for extra cooperation representation capacity. Empirical evaluations on the StarCraft II micromanagement challenge and level-based foraging (LBF) show that CMQ achieves superior performance compared with the state-of-the-art counterparts. The results also demonstrate that CMQ provides more cooperation concept representation capturing meaningful cooperation modes, and supports test-time concept interventions for detecting potential biases of cooperation mode and identifying spurious artifacts that impact cooperation.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "IEEE-China Conference on System Simulation Technology and its Applications, 2025",
    "pdf_url": "https://arxiv.org/pdf/2507.20143v1",
    "published_date": "2025-07-27 06:22:24 UTC",
    "updated_date": "2025-07-27 06:22:24 UTC"
  },
  {
    "arxiv_id": "2507.20140v1",
    "title": "Do Not Mimic My Voice: Speaker Identity Unlearning for Zero-Shot Text-to-Speech",
    "authors": [
      "Taesoo Kim",
      "Jinju Kim",
      "Dongchan Kim",
      "Jong Hwan Ko",
      "Gyeong-Moon Park"
    ],
    "abstract": "The rapid advancement of Zero-Shot Text-to-Speech (ZS-TTS) technology has enabled high-fidelity voice synthesis from minimal audio cues, raising significant privacy and ethical concerns. Despite the threats to voice privacy, research to selectively remove the knowledge to replicate unwanted individual voices from pre-trained model parameters has not been explored. In this paper, we address the new challenge of speaker identity unlearning for ZS-TTS systems. To meet this goal, we propose the first machine unlearning frameworks for ZS-TTS, especially Teacher-Guided Unlearning (TGU), designed to ensure the model forgets designated speaker identities while retaining its ability to generate accurate speech for other speakers. Our proposed methods incorporate randomness to prevent consistent replication of forget speakers' voices, assuring unlearned identities remain untraceable. Additionally, we propose a new evaluation metric, speaker-Zero Retrain Forgetting (spk-ZRF). This assesses the model's ability to disregard prompts associated with forgotten speakers, effectively neutralizing its knowledge of these voices. The experiments conducted on the state-of-the-art model demonstrate that TGU prevents the model from replicating forget speakers' voices while maintaining high quality for other speakers. The demo is available at https://speechunlearn.github.io/",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Proceedings of the 42nd International Conference on Machine Learning (ICML 2025), Vancouver, Canada. PMLR 267, 2025. Authors Jinju Kim and Taesoo Kim contributed equally",
    "pdf_url": "https://arxiv.org/pdf/2507.20140v1",
    "published_date": "2025-07-27 06:13:58 UTC",
    "updated_date": "2025-07-27 06:13:58 UTC"
  },
  {
    "arxiv_id": "2507.20136v2",
    "title": "Multi-Stage Verification-Centric Framework for Mitigating Hallucination in Multi-Modal RAG",
    "authors": [
      "Baiyu Chen",
      "Wilson Wongso",
      "Xiaoqian Hu",
      "Yue Tan",
      "Flora Salim"
    ],
    "abstract": "This paper presents the technical solution developed by team CRUISE for the KDD Cup 2025 Meta Comprehensive RAG Benchmark for Multi-modal, Multi-turn (CRAG-MM) challenge. The challenge aims to address a critical limitation of modern Vision Language Models (VLMs): their propensity to hallucinate, especially when faced with egocentric imagery, long-tail entities, and complex, multi-hop questions. This issue is particularly problematic in real-world applications where users pose fact-seeking queries that demand high factual accuracy across diverse modalities. To tackle this, we propose a robust, multi-stage framework that prioritizes factual accuracy and truthfulness over completeness. Our solution integrates a lightweight query router for efficiency, a query-aware retrieval and summarization pipeline, a dual-pathways generation and a post-hoc verification. This conservative strategy is designed to minimize hallucinations, which incur a severe penalty in the competition's scoring metric. Our approach achieved 3rd place in Task 1, demonstrating the effectiveness of prioritizing answer reliability in complex multi-modal RAG systems. Our implementation is available at https://github.com/Breezelled/KDD-Cup-2025-Meta-CRAG-MM .",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "KDD Cup 2025 Meta CRAG-MM Challenge: Third Prize in the Single-Source Augmentation Task",
    "pdf_url": "https://arxiv.org/pdf/2507.20136v2",
    "published_date": "2025-07-27 05:45:45 UTC",
    "updated_date": "2026-01-20 01:13:34 UTC"
  },
  {
    "arxiv_id": "2507.21184v5",
    "title": "Can Language Models Discover Scaling Laws?",
    "authors": [
      "Haowei Lin",
      "Haotian Ye",
      "Wenzheng Feng",
      "Quzhe Huang",
      "Yujun Li",
      "Hubert Lim",
      "Zhengrui Li",
      "Xiangyu Wang",
      "Jianzhu Ma",
      "Yitao Liang",
      "James Zou"
    ],
    "abstract": "Discovering scaling laws for predicting model performance at scale is a fundamental and open-ended challenge, mostly reliant on slow, case specific human experimentation. To investigate the potential for LLMs to automate this process, we collect over 5,000 experiments from existing literature and curate eight diverse scaling law discovery tasks. While existing agents struggle to produce accurate law formulas, this paper introduces SLDAgent, an evolution-based agent that co-optimize the scaling law model and the parameters, enabling it to autonomously explore complex relationships between variables. For the first time, we demonstrates that SLDAgent can automatically discover laws that exhibit consistently more accurate extrapolation than their established, human-derived counterparts across all tasks. Through comprehensive analysis, we elucidate why these discovered laws are superior and verify their practical utility in both pretraining and finetuning applications. This work establishes a new paradigm for agentic scientific discovery, showing that AI systems can understand their own scaling behavior, and can contribute novel and practical knowledge back to the research community.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.21184v5",
    "published_date": "2025-07-27 05:45:26 UTC",
    "updated_date": "2026-01-22 14:07:59 UTC"
  },
  {
    "arxiv_id": "2507.21183v3",
    "title": "MaPPO: Maximum a Posteriori Preference Optimization with Prior Knowledge",
    "authors": [
      "Guangchen Lan",
      "Sipeng Zhang",
      "Tianle Wang",
      "Yuwei Zhang",
      "Daoan Zhang",
      "Xinpeng Wei",
      "Xiaoman Pan",
      "Hongming Zhang",
      "Dong-Jun Han",
      "Christopher G. Brinton"
    ],
    "abstract": "As the era of large language models (LLMs) on behalf of users unfolds, Preference Optimization (PO) methods have become a central approach to aligning LLMs with human preferences and improving performance. We propose Maximum a Posteriori Preference Optimization (MaPPO), a framework for learning from preferences that explicitly incorporates prior reward knowledge into the optimization objective. While existing methods such as Direct Preference Optimization (DPO) and its variants treat preference learning as a Maximum Likelihood Estimation (MLE) problem, MaPPO extends this paradigm by integrating prior reward estimates into a principled Maximum a Posteriori (MaP) objective. This not only generalizes DPO and its variants, but also enhances alignment by mitigating the oversimplified binary classification of responses. More importantly, MaPPO introduces no additional hyperparameter, and supports preference optimization in both offline and online settings. In addition, MaPPO can be used as a plugin with consistent improvement on DPO variants, including widely used SimPO, IPO, and CPO. Extensive empirical evaluations of different model sizes and model series on three standard benchmarks, including MT-Bench, AlpacaEval 2.0, and Arena-Hard, demonstrate consistent improvements in alignment performance without sacrificing computational efficiency.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.21183v3",
    "published_date": "2025-07-27 05:26:50 UTC",
    "updated_date": "2026-01-16 22:47:57 UTC"
  },
  {
    "arxiv_id": "2507.20133v2",
    "title": "Sem-DPO: Mitigating Semantic Inconsistency in Preference Optimization for Prompt Engineering",
    "authors": [
      "Anas Mohamed",
      "Azal Ahmad Khan",
      "Xinran Wang",
      "Ahmad Faraz Khan",
      "Shuwen Ge",
      "Saman Bahzad Khan",
      "Ayaan Ahmad",
      "Ali Anwar"
    ],
    "abstract": "Generative AI can now synthesize strikingly realistic images from text, yet output quality remains highly sensitive to how prompts are phrased. Direct Preference Optimization (DPO) offers a lightweight, off-policy alternative to RL for automatic prompt engineering, but its token-level regularization leaves semantic inconsistency unchecked as prompts that win higher preference scores can still drift away from the user's intended meaning.\n  We introduce Sem-DPO, a variant of DPO that preserves semantic consistency yet retains its simplicity and efficiency. Sem-DPO adjusts the DPO loss using a weight based on how different the winning prompt is from the original, reducing the impact of training examples that are semantically misaligned. We provide the first analytical bound on semantic drift for preference-tuned prompt generators, showing that Sem-DPO keeps learned prompts within a provably bounded neighborhood of the original text. On three standard text-to-image prompt-optimization benchmarks and two language models, Sem-DPO achieves 8-12% higher CLIP similarity and 5-9% higher human-preference scores (HPSv2.1, PickScore) than DPO, while also outperforming state-of-the-art baselines. These findings suggest that strong flat baselines augmented with semantic weighting should become the new standard for prompt-optimization studies and lay the groundwork for broader, semantics-aware preference optimization in language models.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.20133v2",
    "published_date": "2025-07-27 05:20:13 UTC",
    "updated_date": "2025-07-29 04:18:09 UTC"
  },
  {
    "arxiv_id": "2507.20127v1",
    "title": "Aggregation-aware MLP: An Unsupervised Approach for Graph Message-passing",
    "authors": [
      "Xuanting Xie",
      "Bingheng Li",
      "Erlin Pan",
      "Zhao Kang",
      "Wenyu Chen"
    ],
    "abstract": "Graph Neural Networks (GNNs) have become a dominant approach to learning graph representations, primarily because of their message-passing mechanisms. However, GNNs typically adopt a fixed aggregator function such as Mean, Max, or Sum without principled reasoning behind the selection. This rigidity, especially in the presence of heterophily, often leads to poor, problem dependent performance. Although some attempts address this by designing more sophisticated aggregation functions, these methods tend to rely heavily on labeled data, which is often scarce in real-world tasks. In this work, we propose a novel unsupervised framework, \"Aggregation-aware Multilayer Perceptron\" (AMLP), which shifts the paradigm from directly crafting aggregation functions to making MLP adaptive to aggregation. Our lightweight approach consists of two key steps: First, we utilize a graph reconstruction method that facilitates high-order grouping effects, and second, we employ a single-layer network to encode varying degrees of heterophily, thereby improving the capacity and applicability of the model. Extensive experiments on node clustering and classification demonstrate the superior performance of AMLP, highlighting its potential for diverse graph learning scenarios.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.GR"
    ],
    "primary_category": "cs.LG",
    "comment": "11 pages, 6 figures",
    "pdf_url": "https://arxiv.org/pdf/2507.20127v1",
    "published_date": "2025-07-27 04:52:55 UTC",
    "updated_date": "2025-07-27 04:52:55 UTC"
  },
  {
    "arxiv_id": "2507.20118v1",
    "title": "Iterative Pretraining Framework for Interatomic Potentials",
    "authors": [
      "Taoyong Cui",
      "Zhongyao Wang",
      "Dongzhan Zhou",
      "Yuqiang Li",
      "Lei Bai",
      "Wanli Ouyang",
      "Mao Su",
      "Shufei Zhang"
    ],
    "abstract": "Machine learning interatomic potentials (MLIPs) enable efficient molecular dynamics (MD) simulations with ab initio accuracy and have been applied across various domains in physical science. However, their performance often relies on large-scale labeled training data. While existing pretraining strategies can improve model performance, they often suffer from a mismatch between the objectives of pretraining and downstream tasks or rely on extensive labeled datasets and increasingly complex architectures to achieve broad generalization. To address these challenges, we propose Iterative Pretraining for Interatomic Potentials (IPIP), a framework designed to iteratively improve the predictive performance of MLIP models. IPIP incorporates a forgetting mechanism to prevent iterative training from converging to suboptimal local minima. Unlike general-purpose foundation models, which frequently underperform on specialized tasks due to a trade-off between generality and system-specific accuracy, IPIP achieves higher accuracy and efficiency using lightweight architectures. Compared to general-purpose force fields, this approach achieves over 80% reduction in prediction error and up to 4x speedup in the challenging Mo-S-O system, enabling fast and accurate simulations.",
    "categories": [
      "physics.comp-ph",
      "cs.AI"
    ],
    "primary_category": "physics.comp-ph",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.20118v1",
    "published_date": "2025-07-27 03:59:41 UTC",
    "updated_date": "2025-07-27 03:59:41 UTC"
  },
  {
    "arxiv_id": "2507.20115v1",
    "title": "Packet-Level DDoS Data Augmentation Using Dual-Stream Temporal-Field Diffusion",
    "authors": [
      "Gongli Xi",
      "Ye Tian",
      "Yannan Hu",
      "Yuchao Zhang",
      "Yapeng Niu",
      "Xiangyang Gong"
    ],
    "abstract": "In response to Distributed Denial of Service (DDoS) attacks, recent research efforts increasingly rely on Machine Learning (ML)-based solutions, whose effectiveness largely depends on the quality of labeled training datasets. To address the scarcity of such datasets, data augmentation with synthetic traces is often employed. However, current synthetic trace generation methods struggle to capture the complex temporal patterns and spatial distributions exhibited in emerging DDoS attacks. This results in insufficient resemblance to real traces and unsatisfied detection accuracy when applied to ML tasks. In this paper, we propose Dual-Stream Temporal-Field Diffusion (DSTF-Diffusion), a multi-view, multi-stream network traffic generative model based on diffusion models, featuring two main streams: The field stream utilizes spatial mapping to bridge network data characteristics with pre-trained realms of stable diffusion models, effectively translating complex network interactions into formats that stable diffusion can process, while the spatial stream adopts a dynamic temporal modeling approach, meticulously capturing the intrinsic temporal patterns of network traffic. Extensive experiments demonstrate that data generated by our model exhibits higher statistical similarity to originals compared to current state-of-the-art solutions, and enhance performances on a wide range of downstream tasks.",
    "categories": [
      "cs.NI",
      "cs.AI"
    ],
    "primary_category": "cs.NI",
    "comment": "11 pages, 5 figures",
    "pdf_url": "https://arxiv.org/pdf/2507.20115v1",
    "published_date": "2025-07-27 03:40:56 UTC",
    "updated_date": "2025-07-27 03:40:56 UTC"
  },
  {
    "arxiv_id": "2507.20112v2",
    "title": "Online Learning with Probing for Sequential User-Centric Selection",
    "authors": [
      "Tianyi Xu",
      "Yiting Chen",
      "Henger Li",
      "Zheyong Bian",
      "Emiliano Dall'Anese",
      "Zizhan Zheng"
    ],
    "abstract": "We formalize sequential decision-making with information acquisition as the probing-augmented user-centric selection (PUCS) framework, where a learner first probes a subset of arms to obtain side information on resources and rewards, and then assigns $K$ plays to $M$ arms. PUCS covers applications such as ridesharing, wireless scheduling, and content recommendation, in which both resources and payoffs are initially unknown and probing is costly. For the offline setting with known distributions, we present a greedy probing algorithm with a constant-factor approximation guarantee $ζ= (e-1)/(2e-1)$. For the online setting with unknown distributions, we introduce OLPA, a stochastic combinatorial bandit algorithm that achieves a regret bound $\\mathcal{O}(\\sqrt{T} + \\ln^{2} T)$. We also prove a lower bound $Ω(\\sqrt{T})$, showing that the upper bound is tight up to logarithmic factors. Experiments on real-world data demonstrate the effectiveness of our solutions.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DS",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.20112v2",
    "published_date": "2025-07-27 03:32:51 UTC",
    "updated_date": "2025-08-17 18:43:53 UTC"
  },
  {
    "arxiv_id": "2507.20111v1",
    "title": "AI-Driven Generation of Old English: A Framework for Low-Resource Languages",
    "authors": [
      "Rodrigo Gabriel Salazar Alva",
      "Matías Nuñez",
      "Cristian López",
      "Javier Martín Arista"
    ],
    "abstract": "Preserving ancient languages is essential for understanding humanity's cultural and linguistic heritage, yet Old English remains critically under-resourced, limiting its accessibility to modern natural language processing (NLP) techniques. We present a scalable framework that uses advanced large language models (LLMs) to generate high-quality Old English texts, addressing this gap. Our approach combines parameter-efficient fine-tuning (Low-Rank Adaptation, LoRA), data augmentation via backtranslation, and a dual-agent pipeline that separates the tasks of content generation (in English) and translation (into Old English). Evaluation with automated metrics (BLEU, METEOR, and CHRF) shows significant improvements over baseline models, with BLEU scores increasing from 26 to over 65 for English-to-Old English translation. Expert human assessment also confirms high grammatical accuracy and stylistic fidelity in the generated texts. Beyond expanding the Old English corpus, our method offers a practical blueprint for revitalizing other endangered languages, effectively uniting AI innovation with the goals of cultural preservation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.20111v1",
    "published_date": "2025-07-27 03:29:19 UTC",
    "updated_date": "2025-07-27 03:29:19 UTC"
  },
  {
    "arxiv_id": "2507.20110v1",
    "title": "NeuroVoxel-LM: Language-Aligned 3D Perception via Dynamic Voxelization and Meta-Embedding",
    "authors": [
      "Shiyu Liu",
      "Lianlei Shan"
    ],
    "abstract": "Recent breakthroughs in Visual Language Models (VLMs) and Multimodal Large Language Models (MLLMs) have significantly advanced 3D scene perception towards language-driven cognition. However, existing 3D language models struggle with sparse, large-scale point clouds due to slow feature extraction and limited representation accuracy. To address these challenges, we propose NeuroVoxel-LM, a novel framework that integrates Neural Radiance Fields (NeRF) with dynamic resolution voxelization and lightweight meta-embedding. Specifically, we introduce a Dynamic Resolution Multiscale Voxelization (DR-MSV) technique that adaptively adjusts voxel granularity based on geometric and structural complexity, reducing computational cost while preserving reconstruction fidelity. In addition, we propose the Token-level Adaptive Pooling for Lightweight Meta-Embedding (TAP-LME) mechanism, which enhances semantic representation through attention-based weighting and residual fusion. Experimental results demonstrate that DR-MSV significantly improves point cloud feature extraction efficiency and accuracy, while TAP-LME outperforms conventional max-pooling in capturing fine-grained semantics from NeRF weights.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "**14 pages, 3 figures, 2 tables",
    "pdf_url": "https://arxiv.org/pdf/2507.20110v1",
    "published_date": "2025-07-27 03:11:08 UTC",
    "updated_date": "2025-07-27 03:11:08 UTC"
  },
  {
    "arxiv_id": "2508.00891v1",
    "title": "Accelerating multiparametric quantitative MRI using self-supervised scan-specific implicit neural representation with model reinforcement",
    "authors": [
      "Ruimin Feng",
      "Albert Jang",
      "Xingxin He",
      "Fang Liu"
    ],
    "abstract": "Purpose: To develop a self-supervised scan-specific deep learning framework for reconstructing accelerated multiparametric quantitative MRI (qMRI).\n  Methods: We propose REFINE-MORE (REference-Free Implicit NEural representation with MOdel REinforcement), combining an implicit neural representation (INR) architecture with a model reinforcement module that incorporates MR physics constraints. The INR component enables informative learning of spatiotemporal correlations to initialize multiparametric quantitative maps, which are then further refined through an unrolled optimization scheme enforcing data consistency. To improve computational efficiency, REFINE-MORE integrates a low-rank adaptation strategy that promotes rapid model convergence. We evaluated REFINE-MORE on accelerated multiparametric quantitative magnetization transfer imaging for simultaneous estimation of free water spin-lattice relaxation, tissue macromolecular proton fraction, and magnetization exchange rate, using both phantom and in vivo brain data.\n  Results: Under 4x and 5x accelerations on in vivo data, REFINE-MORE achieved superior reconstruction quality, demonstrating the lowest normalized root-mean-square error and highest structural similarity index compared to baseline methods and other state-of-the-art model-based and deep learning approaches. Phantom experiments further showed strong agreement with reference values, underscoring the robustness and generalizability of the proposed framework. Additionally, the model adaptation strategy improved reconstruction efficiency by approximately fivefold.\n  Conclusion: REFINE-MORE enables accurate and efficient scan-specific multiparametric qMRI reconstruction, providing a flexible solution for high-dimensional, accelerated qMRI applications.",
    "categories": [
      "physics.med-ph",
      "cs.AI"
    ],
    "primary_category": "physics.med-ph",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.00891v1",
    "published_date": "2025-07-27 03:06:49 UTC",
    "updated_date": "2025-07-27 03:06:49 UTC"
  },
  {
    "arxiv_id": "2507.20109v2",
    "title": "Learning to Align Human Code Preferences",
    "authors": [
      "Xin Yin",
      "Chao Ni",
      "Xiaohu Yang"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable potential in automating software development tasks. While recent advances leverage Supervised Fine-Tuning (SFT) and Direct Preference Optimization (DPO) to align models with human preferences, the optimal training strategy remains unclear across diverse code preference scenarios. This paper systematically investigates the roles of SFT and DPO in aligning LLMs with different code preferences. Through both theoretical analysis and empirical observation, we hypothesize that SFT excels in scenarios with objectively verifiable optimal solutions, while applying SFT followed by DPO (S&D) enables models to explore superior solutions in scenarios without objectively verifiable optimal solutions. Based on the analysis and experimental evidence, we propose Adaptive Preference Optimization (APO), a dynamic integration approach that adaptively amplifies preferred responses, suppresses dispreferred ones, and encourages exploration of potentially superior solutions during training. Extensive experiments across six representative code preference tasks validate our theoretical hypotheses and demonstrate that APO consistently matches or surpasses the performance of existing SFT and S&D strategies. Our work provides both theoretical foundations and practical guidance for selecting appropriate training strategies in different code preference alignment scenarios.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.20109v2",
    "published_date": "2025-07-27 02:48:26 UTC",
    "updated_date": "2025-12-08 12:57:25 UTC"
  },
  {
    "arxiv_id": "2507.21182v1",
    "title": "SDD: Self-Degraded Defense against Malicious Fine-tuning",
    "authors": [
      "Zixuan Chen",
      "Weikai Lu",
      "Xin Lin",
      "Ziqian Zeng"
    ],
    "abstract": "Open-source Large Language Models (LLMs) often employ safety alignment methods to resist harmful instructions. However, recent research shows that maliciously fine-tuning these LLMs on harmful data can easily bypass these safeguards. To counter this, we theoretically uncover why malicious fine-tuning succeeds and identify potential defense strategies. Building on the theoretical analysis, we introduce the Self-Degraded Defense (SDD) framework. SDD encourages LLMs to produce high-quality but irrelevant responses to harmful prompts. When attackers attempt malicious fine-tuning, the general capability of the LLM aligned by SDD will significantly decrease, rendering it incapable of following harmful instructions. Our experimental results confirm SDD's effectiveness against such attacks.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "Accepted by ACL2025",
    "pdf_url": "https://arxiv.org/pdf/2507.21182v1",
    "published_date": "2025-07-27 02:08:21 UTC",
    "updated_date": "2025-07-27 02:08:21 UTC"
  },
  {
    "arxiv_id": "2507.20096v2",
    "title": "EcoTransformer: Attention without Multiplication",
    "authors": [
      "Xin Gao",
      "Xingming Xu",
      "Shirin Amiraslani",
      "Hong Xu"
    ],
    "abstract": "The Transformer, with its scaled dot-product attention mechanism, has become a foundational architecture in modern AI. However, this mechanism is computationally intensive and incurs substantial energy costs. We propose a new Transformer architecture EcoTransformer, in which the output context vector is constructed as the convolution of the values using a Laplacian kernel, where the distances are measured by the L1 metric between the queries and keys. Compared to dot-product based attention, the new attention score calculation is free of matrix multiplication. It performs on par with, or even surpasses, scaled dot-product attention in NLP, bioinformatics, and vision tasks, while consuming significantly less energy.\n  (This version (v2) supersedes v1 and reflects the intended release and licensing.)",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "8 pages, 1 figure",
    "pdf_url": "https://arxiv.org/pdf/2507.20096v2",
    "published_date": "2025-07-27 01:32:54 UTC",
    "updated_date": "2025-08-06 02:41:31 UTC"
  },
  {
    "arxiv_id": "2507.20094v2",
    "title": "Local Prompt Adaptation for Style-Consistent Multi-Object Generation in Diffusion Models",
    "authors": [
      "Ankit Sanjyal"
    ],
    "abstract": "Diffusion models have become a powerful backbone for text-to-image generation, producing high-quality visuals from natural language prompts. However, when prompts involve multiple objects alongside global or local style instructions, the outputs often drift in style and lose spatial coherence, limiting their reliability for controlled, style-consistent scene generation. We present Local Prompt Adaptation (LPA), a lightweight, training-free method that splits the prompt into content and style tokens, then injects them selectively into the U-Net's attention layers at chosen timesteps. By conditioning object tokens early and style tokens later in the denoising process, LPA improves both layout control and stylistic uniformity without additional training cost. We conduct extensive ablations across parser settings and injection windows, finding that the best configuration -- lpa late only with a 300-650 step window -- delivers the strongest balance of prompt alignment and style consistency. On the T2I benchmark, LPA improves CLIP-prompt alignment over vanilla SDXL by +0.41% and over SD1.5 by +0.34%, with no diversity loss. On our custom 50-prompt style-rich benchmark, LPA achieves +0.09% CLIP-prompt and +0.08% CLIP-style gains over baseline. Our method is model-agnostic, easy to integrate, and requires only a single configuration change, making it a practical choice for controllable, style-consistent multi-object generation.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.CV",
    "comment": "10 Pages,10 figures, pre-print",
    "pdf_url": "https://arxiv.org/pdf/2507.20094v2",
    "published_date": "2025-07-27 01:32:13 UTC",
    "updated_date": "2025-08-17 15:58:51 UTC"
  }
]