{
  "date": "2024-01-02",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-01-02 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦于人工智能（AI）领域，包括大语言模型（LLM）的微调、知识编辑、跨语言能力，以及医疗图像分析和自动驾驶等应用。重点包括 Self-Play Fine-Tuning 方法提升 LLM 性能的创新研究（作者 Quanquan Gu 等，ICML 2024），LLM 在法律中的幻觉问题分析（作者 Daniel E. Ho），以及 LLM 知识编辑的全面综述（作者 Huajun Chen 等），这些文章具有高话题度和实际影响。\n\n下面，我将挑选几篇重要、令人印象深刻的论文先聊一聊（如 LLM 相关和医疗 AI），然后快速掠过其他较少话题度的文章。每篇论文会列出标题（中文 + 英文），并简要描述主要贡献和发现。\n\n### 重点论文讨论\n\n**1. Self-Play Fine-Tuning Converts Weak Language Models to Strong Language Models（自对弈微调将弱大语言模型转化为强模型）**  \n   作者：Zixiang Chen 等（包括 Quanquan Gu）。  \n   这篇论文提出 SPIN（Self-Play fIne-Tuning）框架，通过自对弈机制让 LLM 在不需额外标注数据的情况下自我迭代优化。贡献在于显著提升 LLM 在基准数据集（如 HuggingFace Open LLM Leaderboard 和 MT-Bench）的性能，甚至超越直接偏好优化方法。发现显示，这种方法能高效利用现有数据，实现更强的泛化能力，适用于资源有限的场景。\n\n**2. Large Legal Fictions: Profiling Legal Hallucinations in Large Language Models（大型法律幻觉：分析大语言模型中的法律错误）**  \n   作者：Matthew Dahl 等（包括 Daniel E. Ho）。  \n   论文评估 LLM（如 ChatGPT-4 和 Llama 2）在法律查询中的幻觉问题，定义了幻觉类型并测试在联邦法院案例上的表现。贡献是首次系统量化 LLM 的法律错误率（高达 58%~88%），并证明这些错误在不同编码方案下普遍存在。发现强调 LLM 在法律应用中的风险，需要进一步改进以提升鲁棒性。\n\n**3. A Comprehensive Study of Knowledge Editing for Large Language Models（大语言模型知识编辑的全面研究）**  \n   作者：Ningyu Zhang 等（包括 Huajun Chen）。  \n   这篇综述提出知识编辑框架，将方法分类为外部知识依赖、知识合并和内在知识编辑。贡献在于统一标准评估编辑技术，并在 KnowEdit 基准上实验，证明高效编辑能保持 LLM 性能。发现显示，编辑方法能适应动态知识更新，对 LLM 的持续优化有重要启发。\n\n**4. HA-HI: Synergising fMRI and DTI through Hierarchical Alignments and Hierarchical Interactions for Mild Cognitive Impairment Diagnosis（HA-HI：通过分层对齐和交互融合 fMRI 和 DTI 用于轻度认知障碍诊断）**  \n   作者：Xiongri Shen 等。  \n   论文开发 HA-HI 框架，融合 fMRI 和 DTI 图像进行认知障碍诊断。贡献在于分层对齐多模态数据，提高分类准确率，并引入 Synergistic Activation Map（协同激活图）增强可解释性。实验在 ADNI 数据集上显示，该方法优于现有模型，在医疗 AI 中有潜力提升诊断效率。\n\n**5. LLaMA Beyond English: An Empirical Study on Language Capability Transfer（LLaMA 超越英语：大语言模型语言能力迁移的实证研究）**  \n   作者：Jun Zhao 等。  \n   论文探索 LLaMA 在非英语语言的迁移能力，通过词汇扩展和指令微调评估。贡献是证明使用少量数据（不到 1%）即可实现高性能迁移，并在 C-Eval 和 MMLU 等基准上验证。发现显示，LLM 可跨语言泛化，但需优化以处理低资源语言。\n\n### 快速掠过其他论文\n其他论文涉及更窄领域，我仅简要列出标题（中文 + 英文）和核心发现，限于篇幅不深聊。\n\n- **Outlier Ranking in Large-Scale Public Health Streams（大规模公共卫生数据流中的异常排名）**：提出算法提升异常检测效率，发现能加速专家识别异常 9.1 倍。\n- **Concurrent Self-testing of Neural Networks Using Uncertainty Fingerprint（使用不确定性指纹的神经网络并发自测试）**：开发自测试框架，提高神经网络鲁棒性，发现减少内存开销达 243.7 MB。\n- **SwapTransformer: highway overtaking tactical planner model via imitation learning on OSHA dataset（SwapTransformer：在 OSHA 数据集上通过模仿学习的高速超车策略规划器）**：基于模仿学习优化自动驾驶决策，发现模型在不同交通密度下表现优异。\n- **Auffusion: Leveraging the Power of Diffusion and Large Language Models for Text-to-Audio Generation（Auffusion：利用扩散模型和大语言模型的文本到音频生成）**：提出多模态生成框架，发现能提升文本-音频对齐精度。\n- **NID-SLAM: Neural Implicit Representation-based RGB-D SLAM in dynamic environments（NID-SLAM：基于神经隐式表示的 RGB-D SLAM 在动态环境中的应用）**：改进 SLAM 算法，提升动态场景下的鲁棒性。\n- **其他（如第18、21、31、37、44 篇）**：这些论文如电路优化、拓扑推断或语音生成等，贡献较具体但话题度低，仅发现如语音生成模型的效率提升或电路面积减少 30%，不影响主流 AI 趋势。\n\n总之，今天的 arXiv 强调 AI 的实用性和优化，LLM 相关论文尤其值得关注。明天的快报见！",
  "papers": [
    {
      "arxiv_id": "2401.01459v1",
      "title": "Outlier Ranking in Large-Scale Public Health Streams",
      "title_zh": "大规模公共卫生数据流中的异常值排名",
      "authors": [
        "Ananya Joshi",
        "Tina Townes",
        "Nolan Gormley",
        "Luke Neureiter",
        "Roni Rosenfeld",
        "Bryan Wilder"
      ],
      "abstract": "Disease control experts inspect public health data streams daily for outliers\nworth investigating, like those corresponding to data quality issues or disease\noutbreaks. However, they can only examine a few of the thousands of\nmaximally-tied outliers returned by univariate outlier detection methods\napplied to large-scale public health data streams. To help experts distinguish\nthe most important outliers from these thousands of tied outliers, we propose a\nnew task for algorithms to rank the outputs of any univariate method applied to\neach of many streams. Our novel algorithm for this task, which leverages\nhierarchical networks and extreme value analysis, performed the best across\ntraditional outlier detection metrics in a human-expert evaluation using public\nhealth data streams. Most importantly, experts have used our open-source Python\nimplementation since April 2023 and report identifying outliers worth\ninvestigating 9.1x faster than their prior baseline. Other organizations can\nreadily adapt this implementation to create rankings from the outputs of their\ntailored univariate methods across large-scale streams.",
      "tldr_zh": "本研究针对大型公共卫生数据流中，单变量异常检测(outlier detection)方法产生的数千个平级异常值(outliers)问题，提出一个新任务：对这些异常值进行排名，以帮助专家快速识别值得调查的案例。研究开发了一种新算法，利用层次网络(hierarchical networks)和极值分析(extreme value analysis)，在多数据流上对异常值输出进行优先排序。在人类专家评估中，该算法在传统异常检测指标上表现出色，并使专家识别关键异常值的速度提高9.1倍。该开源Python实现已于2023年4月开始使用，其他组织可轻松适应应用于其自身的数据流分析。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "6 figures, 8 pages",
      "pdf_url": "http://arxiv.org/pdf/2401.01459v1",
      "published_date": "2024-01-02 23:08:49 UTC",
      "updated_date": "2024-01-02 23:08:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:15:19.432915"
    },
    {
      "arxiv_id": "2401.01458v1",
      "title": "Concurrent Self-testing of Neural Networks Using Uncertainty Fingerprint",
      "title_zh": "使用不确定性指纹的神经网络并发自我测试",
      "authors": [
        "Soyed Tuhin Ahmed",
        "Mehdi B. tahoori"
      ],
      "abstract": "Neural networks (NNs) are increasingly used in always-on safety-critical\napplications deployed on hardware accelerators (NN-HAs) employing various\nmemory technologies. Reliable continuous operation of NN is essential for\nsafety-critical applications. During online operation, NNs are susceptible to\nsingle and multiple permanent and soft errors due to factors such as radiation,\naging, and thermal effects. Explicit NN-HA testing methods cannot detect\ntransient faults during inference, are unsuitable for always-on applications,\nand require extensive test vector generation and storage. Therefore, in this\npaper, we propose the \\emph{uncertainty fingerprint} approach representing the\nonline fault status of NN. Furthermore, we propose a dual head NN topology\nspecifically designed to produce uncertainty fingerprints and the primary\nprediction of the NN in \\emph{a single shot}. During the online operation, by\nmatching the uncertainty fingerprint, we can concurrently self-test NNs with up\nto $100\\%$ coverage with a low false positive rate while maintaining a similar\nperformance of the primary task. Compared to existing works, memory overhead is\nreduced by up to $243.7$ MB, multiply and accumulate (MAC) operation is reduced\nby up to $10000\\times$, and false-positive rates are reduced by up to $89\\%$.",
      "tldr_zh": "该论文针对神经网络（NNs）在安全关键应用中面临的永久和软错误问题，提出了一种使用uncertainty fingerprint的并发自测试方法，以实时检测瞬时故障。研究设计了双头NN拓扑，能够在单次推理中同时生成uncertainty fingerprint和主要预测，从而实现高达100%的故障覆盖率，同时保持低假阳性率。相比现有方法，该方法减少了多达243.7 MB的内存开销、10000倍的乘-累加（MAC）操作，并将假阳性率降低多达89%。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.01458v1",
      "published_date": "2024-01-02 23:05:07 UTC",
      "updated_date": "2024-01-02 23:05:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:15:31.492211"
    },
    {
      "arxiv_id": "2401.01442v1",
      "title": "Hierarchical Over-the-Air Federated Learning with Awareness of Interference and Data Heterogeneity",
      "title_zh": "翻译失败",
      "authors": [
        "Seyed Mohammad Azimi-Abarghouyi",
        "Viktoria Fodor"
      ],
      "abstract": "When implementing hierarchical federated learning over wireless networks,\nscalability assurance and the ability to handle both interference and device\ndata heterogeneity are crucial. This work introduces a learning method designed\nto address these challenges, along with a scalable transmission scheme that\nefficiently uses a single wireless resource through over-the-air computation.\nTo provide resistance against data heterogeneity, we employ gradient\naggregations. Meanwhile, the impact of interference is minimized through\noptimized receiver normalizing factors. For this, we model a multi-cluster\nwireless network using stochastic geometry, and characterize the mean squared\nerror of the aggregation estimations as a function of the network parameters.\nWe show that despite the interference and the data heterogeneity, the proposed\nscheme achieves high learning accuracy and can significantly outperform the\nconventional hierarchical algorithm.",
      "tldr_zh": "这篇论文针对分层联邦学习（Hierarchical Federated Learning）在无线网络中的可扩展性问题，提出了一种新的学习方法和传输方案，以应对干扰（Interference）和数据异质性（Data Heterogeneity）。该方案利用 Over-the-Air Computation 高效利用单一无线资源，通过梯度聚合抵抗数据异质性，并通过优化的接收器归一化因子最小化干扰影响。基于随机几何（Stochastic Geometry）建模的多集群网络分析表明，该方法在干扰和异质性条件下仍能实现高学习准确率，并显著优于传统分层算法。",
      "categories": [
        "cs.IT",
        "cs.AI",
        "cs.LG",
        "math.IT"
      ],
      "primary_category": "cs.IT",
      "comment": "To appear at IEEE WCNC 2024. Overlap with arXiv:2211.16162",
      "pdf_url": "http://arxiv.org/pdf/2401.01442v1",
      "published_date": "2024-01-02 21:43:01 UTC",
      "updated_date": "2024-01-02 21:43:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:15:43.315043"
    },
    {
      "arxiv_id": "2401.01426v2",
      "title": "Modular Learning of Deep Causal Generative Models for High-dimensional Causal Inference",
      "title_zh": "翻译失败",
      "authors": [
        "Md Musfiqur Rahman",
        "Murat Kocaoglu"
      ],
      "abstract": "Sound and complete algorithms have been proposed to compute identifiable\ncausal queries using the causal structure and data. However, most of these\nalgorithms assume accurate estimation of the data distribution, which is\nimpractical for high-dimensional variables such as images. On the other hand,\nmodern deep generative architectures can be trained to sample from\nhigh-dimensional distributions. However, training these networks are typically\nvery costly. Thus, it is desirable to leverage pre-trained models to answer\ncausal queries using such high-dimensional data. To address this, we propose\nmodular training of deep causal generative models that not only makes learning\nmore efficient, but also allows us to utilize large, pre-trained conditional\ngenerative models. To the best of our knowledge, our algorithm, Modular-DCM is\nthe first algorithm that, given the causal structure, uses adversarial training\nto learn the network weights, and can make use of pre-trained models to\nprovably sample from any identifiable causal query in the presence of latent\nconfounders. With extensive experiments on the Colored-MNIST dataset, we\ndemonstrate that our algorithm outperforms the baselines. We also show our\nalgorithm's convergence on the COVIDx dataset and its utility with a causal\ninvariant prediction problem on CelebA-HQ.",
      "tldr_zh": "该论文提出 Modular-DCM 算法，通过模块化训练深度因果生成模型，解决高维数据（如图像）因果推理中的数据分布估计难题，提高学习效率并利用预训练条件生成模型。\n该算法采用对抗训练(adversarial training)学习网络权重，能够在存在潜在混杂因素的情况下，从可识别的因果查询(causal queries)中采样。\n实验结果显示，Modular-DCM 在 Colored-MNIST 数据集上优于基线模型，并在 COVIDx 和 CelebA-HQ 数据集上证明了其收敛性和在因果不变预测问题中的实用性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IT",
        "math.IT",
        "stat.ME",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.01426v2",
      "published_date": "2024-01-02 20:31:15 UTC",
      "updated_date": "2024-10-27 04:18:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:15:55.663847"
    },
    {
      "arxiv_id": "2401.01425v1",
      "title": "SwapTransformer: highway overtaking tactical planner model via imitation learning on OSHA dataset",
      "title_zh": "翻译失败",
      "authors": [
        "Alireza Shamsoshoara",
        "Safin B Salih",
        "Pedram Aghazadeh"
      ],
      "abstract": "This paper investigates the high-level decision-making problem in highway\nscenarios regarding lane changing and over-taking other slower vehicles. In\nparticular, this paper aims to improve the Travel Assist feature for automatic\novertaking and lane changes on highways. About 9 million samples including lane\nimages and other dynamic objects are collected in simulation. This data;\nOvertaking on Simulated HighwAys (OSHA) dataset is released to tackle this\nchallenge. To solve this problem, an architecture called SwapTransformer is\ndesigned and implemented as an imitation learning approach on the OSHA dataset.\nMoreover, auxiliary tasks such as future points and car distance network\npredictions are proposed to aid the model in better understanding the\nsurrounding environment. The performance of the proposed solution is compared\nwith a multi-layer perceptron (MLP) and multi-head self-attention networks as\nbaselines in a simulation environment. We also demonstrate the performance of\nthe model with and without auxiliary tasks. All models are evaluated based on\ndifferent metrics such as time to finish each lap, number of overtakes, and\nspeed difference with speed limit. The evaluation shows that the\nSwapTransformer model outperforms other models in different traffic densities\nin the inference phase.",
      "tldr_zh": "这篇论文针对高速公路场景中的高层决策问题，提出了一种名为SwapTransformer的模型，通过imitation learning在OSHA数据集上进行训练，以优化自动超车和变道功能。OSHA数据集包含约900万样本，包括车道图像和其他动态对象，并引入了辅助任务如未来点预测和车距离网络预测，以提升模型对环境的理解。实验结果显示，SwapTransformer在模拟环境中优于MLP和multi-head self-attention networks等基线模型，在不同交通密度下表现出更高的完成时间、超车次数和速度差表现。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "19 pages, 12 Figures, 1 Algorithm, 2 Tables",
      "pdf_url": "http://arxiv.org/pdf/2401.01425v1",
      "published_date": "2024-01-02 20:28:06 UTC",
      "updated_date": "2024-01-02 20:28:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:16:06.677818"
    },
    {
      "arxiv_id": "2401.01405v1",
      "title": "Quantifying the Uniqueness of Donald Trump in Presidential Discourse",
      "title_zh": "翻译失败",
      "authors": [
        "Karen Zhou",
        "Alexander A. Meitus",
        "Milo Chase",
        "Grace Wang",
        "Anne Mykland",
        "William Howell",
        "Chenhao Tan"
      ],
      "abstract": "Does Donald Trump speak differently from other presidents? If so, in what\nways? Are these differences confined to any single medium of communication? To\ninvestigate these questions, this paper introduces a novel metric of uniqueness\nbased on large language models, develops a new lexicon for divisive speech, and\npresents a framework for comparing the lexical features of political opponents.\nApplying these tools to a variety of corpora of presidential speeches, we find\nconsiderable evidence that Trump's speech patterns diverge from those of all\nmajor party nominees for the presidency in recent history. Some notable\nfindings include Trump's employment of particularly divisive and antagonistic\nlanguage targeting of his political opponents and his patterns of repetition\nfor emphasis. Furthermore, Trump is significantly more distinctive than his\nfellow Republicans, whose uniqueness values are comparably closer to those of\nthe Democrats. These differences hold across a variety of measurement\nstrategies, arise on both the campaign trail and in official presidential\naddresses, and do not appear to be an artifact of secular time trends.",
      "tldr_zh": "这篇论文探讨了唐纳德·特朗普在总统演讲中的独特性，引入了一个基于 large language models 的新独特性度量、一个新的 divisive speech 词汇表，以及一个框架来比较政治对手的词汇特征。研究分析了各种总统演讲语料库，发现特朗普的演讲模式与其他主要党派候选人显著不同，尤其体现在使用更多 divisive 和 antagonistic 语言、重复强调以及针对对手的对抗性表达。结果显示，特朗普的独特性远高于其他共和党人，这些差异在竞选和正式演讲中均存在，且非时间趋势的产物。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.SI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.01405v1",
      "published_date": "2024-01-02 19:00:17 UTC",
      "updated_date": "2024-01-02 19:00:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:16:19.218762"
    },
    {
      "arxiv_id": "2401.01335v3",
      "title": "Self-Play Fine-Tuning Converts Weak Language Models to Strong Language Models",
      "title_zh": "自我对弈微调将弱语言模型转换为强语言模型",
      "authors": [
        "Zixiang Chen",
        "Yihe Deng",
        "Huizhuo Yuan",
        "Kaixuan Ji",
        "Quanquan Gu"
      ],
      "abstract": "Harnessing the power of human-annotated data through Supervised Fine-Tuning\n(SFT) is pivotal for advancing Large Language Models (LLMs). In this paper, we\ndelve into the prospect of growing a strong LLM out of a weak one without the\nneed for acquiring additional human-annotated data. We propose a new\nfine-tuning method called Self-Play fIne-tuNing (SPIN), which starts from a\nsupervised fine-tuned model. At the heart of SPIN lies a self-play mechanism,\nwhere the LLM refines its capability by playing against instances of itself.\nMore specifically, the LLM generates its own training data from its previous\niterations, refining its policy by discerning these self-generated responses\nfrom those obtained from human-annotated data. Our method progressively\nelevates the LLM from a nascent model to a formidable one, unlocking the full\npotential of human-annotated demonstration data for SFT. Theoretically, we\nprove that the global optimum to the training objective function of our method\nis achieved only when the LLM policy aligns with the target data distribution.\nEmpirically, we evaluate our method on several benchmark datasets including the\nHuggingFace Open LLM Leaderboard, MT-Bench, and datasets from Big-Bench. Our\nresults show that SPIN can significantly improve the LLM's performance across a\nvariety of benchmarks and even outperform models trained through direct\npreference optimization (DPO) supplemented with extra GPT-4 preference data.\nThis sheds light on the promise of self-play, enabling the achievement of\nhuman-level performance in LLMs without the need for expert opponents. Codes\nare available at https://github.com/uclaml/SPIN.",
      "tldr_zh": "本论文提出了一种名为 Self-Play fIne-tuNing (SPIN) 的新 fine-tuning 方法，用于将弱 Large Language Models (LLMs) 提升为强模型，而无需额外人类标注数据。SPIN 以 Supervised Fine-Tuning (SFT) 模型为基础，通过自玩机制让 LLM 生成自身训练数据，并通过比较自生成响应与人类数据来逐步优化其策略。实验结果显示，SPIN 在 HuggingFace Open LLM Leaderboard、MT-Bench 和 Big-Bench 等基准数据集上显著提升了模型性能，甚至超过了使用额外 GPT-4 数据通过 Direct Preference Optimization (DPO) 训练的模型。理论上，该方法证明了其训练目标函数的全局最优解要求 LLM 策略与目标数据分布对齐，从而为无需专家对手即可实现人类水平性能的 LLM 发展提供了新路径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "22 pages, 6 figures, 7 tables. In ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.01335v3",
      "published_date": "2024-01-02 18:53:13 UTC",
      "updated_date": "2024-06-14 21:17:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:16:31.499097"
    },
    {
      "arxiv_id": "2401.01330v2",
      "title": "TREC iKAT 2023: The Interactive Knowledge Assistance Track Overview",
      "title_zh": "TREC",
      "authors": [
        "Mohammad Aliannejadi",
        "Zahra Abbasiantaeb",
        "Shubham Chatterjee",
        "Jeffery Dalton",
        "Leif Azzopardi"
      ],
      "abstract": "Conversational Information Seeking has evolved rapidly in the last few years\nwith the development of Large Language Models providing the basis for\ninterpreting and responding in a naturalistic manner to user requests. iKAT\nemphasizes the creation and research of conversational search agents that adapt\nresponses based on the user's prior interactions and present context. This\nmeans that the same question might yield varied answers, contingent on the\nuser's profile and preferences. The challenge lies in enabling Conversational\nSearch Agents (CSA) to incorporate personalized context to effectively guide\nusers through the relevant information to them. iKAT's first year attracted\nseven teams and a total of 24 runs. Most of the runs leveraged Large Language\nModels (LLMs) in their pipelines, with a few focusing on a\ngenerate-then-retrieve approach.",
      "tldr_zh": "TREC iKAT 2023 概述了对话式信息搜索（Conversational Information Seeking）的快速发展，特别是 Large Language Models (LLMs) 在构建自然交互式响应方面的作用。iKAT 专注于开发 Conversational Search Agents (CSA)，这些代理能根据用户的先前互动和个人偏好调整答案，从而为同一问题提供个性化的信息引导。首年吸引了七个团队和24个运行，大多数采用 LLMs 和“生成然后检索”（generate-then-retrieve）的策略，突显了这种方法的潜力。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "TREC iKAT 2023 Overview Paper",
      "pdf_url": "http://arxiv.org/pdf/2401.01330v2",
      "published_date": "2024-01-02 18:40:03 UTC",
      "updated_date": "2024-02-22 17:29:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:16:43.652757"
    },
    {
      "arxiv_id": "2401.01326v2",
      "title": "An Autoregressive Text-to-Graph Framework for Joint Entity and Relation Extraction",
      "title_zh": "翻译失败",
      "authors": [
        "Urchade Zaratiana",
        "Nadi Tomeh",
        "Pierre Holat",
        "Thierry Charnois"
      ],
      "abstract": "In this paper, we propose a novel method for joint entity and relation\nextraction from unstructured text by framing it as a conditional sequence\ngeneration problem. In contrast to conventional generative information\nextraction models that are left-to-right token-level generators, our approach\nis \\textit{span-based}. It generates a linearized graph where nodes represent\ntext spans and edges represent relation triplets. Our method employs a\ntransformer encoder-decoder architecture with pointing mechanism on a dynamic\nvocabulary of spans and relation types. Our model can capture the structural\ncharacteristics and boundaries of entities and relations through span\nrepresentations while simultaneously grounding the generated output in the\noriginal text thanks to the pointing mechanism. Evaluation on benchmark\ndatasets validates the effectiveness of our approach, demonstrating competitive\nresults. Code is available at https://github.com/urchade/ATG.",
      "tldr_zh": "本论文提出了一种 Autoregressive Text-to-Graph 框架，将联合实体和关系提取任务框架化为条件序列生成问题，采用 span-based 方法生成线性化图，其中节点表示文本 span，边表示关系三元组。框架使用 Transformer 编码器-解码器架构结合 pointing mechanism，在动态词汇表上操作，从而捕捉实体和关系的结构特征和边界，同时确保输出锚定到原始文本。该方法在基准数据集上表现出色，取得了竞争性的结果，代码已在 GitHub 上公开。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "AAAI 2024 (camera ready version)",
      "pdf_url": "http://arxiv.org/pdf/2401.01326v2",
      "published_date": "2024-01-02 18:32:14 UTC",
      "updated_date": "2024-01-15 13:39:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:16:54.937085"
    },
    {
      "arxiv_id": "2401.01325v3",
      "title": "LLM Maybe LongLM: Self-Extend LLM Context Window Without Tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Hongye Jin",
        "Xiaotian Han",
        "Jingfeng Yang",
        "Zhimeng Jiang",
        "Zirui Liu",
        "Chia-Yuan Chang",
        "Huiyuan Chen",
        "Xia Hu"
      ],
      "abstract": "It is well known that LLMs cannot generalize well to long contexts whose\nlengths are larger than the training sequence length. This poses challenges\nwhen employing LLMs for processing long input sequences during inference. In\nthis work, we argue that LLMs themselves have inherent capabilities to handle\nlong contexts without fine-tuning. To achieve this goal, we propose SelfExtend\nto extend the context window of LLMs by constructing bi-level attention\ninformation: the grouped attention and the neighbor attention. The grouped\nattention captures the dependencies among tokens that are far apart, while\nneighbor attention captures dependencies among adjacent tokens within a\nspecified range. The two-level attentions are computed based on the original\nmodel's self-attention mechanism during inference. With minor code\nmodification, our SelfExtend can effortlessly extend existing LLMs' context\nwindow without any fine-tuning. We conduct comprehensive experiments on\nmultiple benchmarks and the results show that our SelfExtend can effectively\nextend existing LLMs' context window length. The code can be found at\n\\url{https://github.com/datamllab/LongLM}.",
      "tldr_zh": "这篇论文解决了大型语言模型（LLMs）在处理超出训练序列长度的长上下文时泛化能力不足的问题，提出了一种无需微调的SelfExtend方法。SelfExtend通过构建双层注意力机制，包括grouped attention（捕捉远距离token依赖）和neighbor attention（捕捉相邻token依赖），基于原模型的自注意力在推理阶段进行计算。实验在多个基准上验证了该方法的有效性，能够显著扩展LLMs的context window长度，并提供了开源代码。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "ICML2024 Spotlight",
      "pdf_url": "http://arxiv.org/pdf/2401.01325v3",
      "published_date": "2024-01-02 18:30:51 UTC",
      "updated_date": "2024-07-11 06:11:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:17:05.654989"
    },
    {
      "arxiv_id": "2403.17011v1",
      "title": "SUDO: a framework for evaluating clinical artificial intelligence systems without ground-truth annotations",
      "title_zh": "翻译失败",
      "authors": [
        "Dani Kiyasseh",
        "Aaron Cohen",
        "Chengsheng Jiang",
        "Nicholas Altieri"
      ],
      "abstract": "A clinical artificial intelligence (AI) system is often validated on a\nheld-out set of data which it has not been exposed to before (e.g., data from a\ndifferent hospital with a distinct electronic health record system). This\nevaluation process is meant to mimic the deployment of an AI system on data in\nthe wild; those which are currently unseen by the system yet are expected to be\nencountered in a clinical setting. However, when data in the wild differ from\nthe held-out set of data, a phenomenon referred to as distribution shift, and\nlack ground-truth annotations, it becomes unclear the extent to which AI-based\nfindings can be trusted on data in the wild. Here, we introduce SUDO, a\nframework for evaluating AI systems without ground-truth annotations. SUDO\nassigns temporary labels to data points in the wild and directly uses them to\ntrain distinct models, with the highest performing model indicative of the most\nlikely label. Through experiments with AI systems developed for dermatology\nimages, histopathology patches, and clinical reports, we show that SUDO can be\na reliable proxy for model performance and thus identify unreliable\npredictions. We also demonstrate that SUDO informs the selection of models and\nallows for the previously out-of-reach assessment of algorithmic bias for data\nin the wild without ground-truth annotations. The ability to triage unreliable\npredictions for further inspection and assess the algorithmic bias of AI\nsystems can improve the integrity of research findings and contribute to the\ndeployment of ethical AI systems in medicine.",
      "tldr_zh": "这篇论文引入了 SUDO 框架，用于评估临床 AI 系统，而无需 ground-truth annotations（真实标签），以应对数据分布偏移（distribution shift）带来的挑战。SUDO 方法通过为野外数据分配临时标签并训练多个模型，选择表现最佳的模型来推断最可能的标签，从而作为模型性能的可靠代理。实验在皮肤病图像、病理切片和临床报告上验证了 SUDO 的有效性，能够识别不可靠预测、评估算法偏差，并促进伦理 AI 在医学中的部署。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.17011v1",
      "published_date": "2024-01-02 18:12:03 UTC",
      "updated_date": "2024-01-02 18:12:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:17:19.110157"
    },
    {
      "arxiv_id": "2401.01304v1",
      "title": "Experimental Validation of Sensor Fusion-based GNSS Spoofing Attack Detection Framework for Autonomous Vehicles",
      "title_zh": "翻译失败",
      "authors": [
        "Sagar Dasgupta",
        "Kazi Hassan Shakib",
        "Mizanur Rahman"
      ],
      "abstract": "In this paper, we validate the performance of the a sensor fusion-based\nGlobal Navigation Satellite System (GNSS) spoofing attack detection framework\nfor Autonomous Vehicles (AVs). To collect data, a vehicle equipped with a GNSS\nreceiver, along with Inertial Measurement Unit (IMU) is used. The detection\nframework incorporates two strategies: The first strategy involves comparing\nthe predicted location shift, which is the distance traveled between two\nconsecutive timestamps, with the inertial sensor-based location shift. For this\npurpose, data from low-cost in-vehicle inertial sensors such as the\naccelerometer and gyroscope sensor are fused and fed into a long short-term\nmemory (LSTM) neural network. The second strategy employs a Random-Forest\nsupervised machine learning model to detect and classify turns, distinguishing\nbetween left and right turns using the output from the steering angle sensor.\nIn experiments, two types of spoofing attack models: turn-by-turn and wrong\nturn are simulated. These spoofing attacks are modeled as SQL injection\nattacks, where, upon successful implementation, the navigation system perceives\ninjected spoofed location information as legitimate while being unable to\ndetect legitimate GNSS signals. Importantly, the IMU data remains uncompromised\nthroughout the spoofing attack. To test the effectiveness of the detection\nframework, experiments are conducted in Tuscaloosa, AL, mimicking urban road\nstructures. The results demonstrate the framework's ability to detect various\nsophisticated GNSS spoofing attacks, even including slow position drifting\nattacks. Overall, the experimental results showcase the robustness and efficacy\nof the sensor fusion-based spoofing attack detection approach in safeguarding\nAVs against GNSS spoofing threats.",
      "tldr_zh": "这篇论文验证了一个基于传感器融合的 GNSS 欺骗攻击检测框架，用于保护自动驾驶车辆 (AVs)。框架采用两种策略：首先，使用 LSTM 神经网络融合 IMU（惯性测量单元）数据比较预测位置偏移与实际偏移；其次，运用 Random Forest 机器学习模型分析转向角度传感器数据，以检测和分类左转或右转。实验在阿拉巴马州塔斯卡卢萨模拟 turn-by-turn 和 wrong turn 攻击（建模为 SQL injection 攻击），结果显示框架能有效识别各种复杂欺骗攻击，包括慢速位置漂移，提升了 AVs 的鲁棒性和安全性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.01304v1",
      "published_date": "2024-01-02 17:30:46 UTC",
      "updated_date": "2024-01-02 17:30:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:17:31.290284"
    },
    {
      "arxiv_id": "2401.01301v2",
      "title": "Large Legal Fictions: Profiling Legal Hallucinations in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Matthew Dahl",
        "Varun Magesh",
        "Mirac Suzgun",
        "Daniel E. Ho"
      ],
      "abstract": "Do large language models (LLMs) know the law? These models are increasingly\nbeing used to augment legal practice, education, and research, yet their\nrevolutionary potential is threatened by the presence of hallucinations --\ntextual output that is not consistent with legal facts. We present the first\nsystematic evidence of these hallucinations, documenting LLMs' varying\nperformance across jurisdictions, courts, time periods, and cases. Our work\nmakes four key contributions. First, we develop a typology of legal\nhallucinations, providing a conceptual framework for future research in this\narea. Second, we find that legal hallucinations are alarmingly prevalent,\noccurring between 58% of the time with ChatGPT 4 and 88% with Llama 2, when\nthese models are asked specific, verifiable questions about random federal\ncourt cases. Third, we illustrate that LLMs often fail to correct a user's\nincorrect legal assumptions in a contra-factual question setup. Fourth, we\nprovide evidence that LLMs cannot always predict, or do not always know, when\nthey are producing legal hallucinations. Taken together, our findings caution\nagainst the rapid and unsupervised integration of popular LLMs into legal\ntasks. Even experienced lawyers must remain wary of legal hallucinations, and\nthe risks are highest for those who stand to benefit from LLMs the most -- pro\nse litigants or those without access to traditional legal resources.",
      "tldr_zh": "本研究评估了大型语言模型（LLMs）在法律领域的幻觉问题，即模型输出与法律事实不一致的现象。研究者开发了法律幻觉的分类体系（typology），并通过测试发现，ChatGPT 4 在针对随机联邦法院案件的具体问题上产生幻觉的比例高达58%，而Llama 2则达到88%。此外，LLMs 往往无法纠正用户错误的法律假设，且不能总是预测自身幻觉的发生。总体而言，该研究警告快速无监督地将LLMs整合到法律任务中的风险，特别是对没有传统法律资源的人群。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.01301v2",
      "published_date": "2024-01-02 17:28:06 UTC",
      "updated_date": "2024-06-21 15:32:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:17:42.473697"
    },
    {
      "arxiv_id": "2401.02987v4",
      "title": "Has Your Pretrained Model Improved? A Multi-head Posterior Based Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Prince Aboagye",
        "Yan Zheng",
        "Junpeng Wang",
        "Uday Singh Saini",
        "Xin Dai",
        "Michael Yeh",
        "Yujie Fan",
        "Zhongfang Zhuang",
        "Shubham Jain",
        "Liang Wang",
        "Wei Zhang"
      ],
      "abstract": "The emergence of pre-trained models has significantly impacted Natural\nLanguage Processing (NLP) and Computer Vision to relational datasets.\nTraditionally, these models are assessed through fine-tuned downstream tasks.\nHowever, this raises the question of how to evaluate these models more\nefficiently and more effectively. In this study, we explore a novel approach\nwhere we leverage the meta-features associated with each entity as a source of\nworldly knowledge and employ entity representations from the models. We propose\nusing the consistency between these representations and the meta-features as a\nmetric for evaluating pre-trained models. Our method's effectiveness is\ndemonstrated across various domains, including models with relational datasets,\nlarge language models and image models.",
      "tldr_zh": "这篇论文探讨了评估预训练模型（pretrained models）改进的有效方法，提出一种基于多头后验（multi-head posterior）的创新方法，使用实体元特征作为世界知识来源，并通过实体表示与元特征的一致性作为评估指标。该方法超越传统微调下游任务的评估方式，能更高效地适用于NLP和计算机视觉领域。实验结果显示，该方法在关系数据集模型、大语言模型和图像模型等多种场景中表现出色，证明了其可靠性和广泛适用性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.02987v4",
      "published_date": "2024-01-02 17:08:26 UTC",
      "updated_date": "2024-02-14 19:05:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:17:54.751249"
    },
    {
      "arxiv_id": "2401.01288v1",
      "title": "Physics-informed Generalizable Wireless Channel Modeling with Segmentation and Deep Learning: Fundamentals, Methodologies, and Challenges",
      "title_zh": "翻译失败",
      "authors": [
        "Ethan Zhu",
        "Haijian Sun",
        "Mingyue Ji"
      ],
      "abstract": "Channel modeling is fundamental in advancing wireless systems and has thus\nattracted considerable research focus. Recent trends have seen a growing\nreliance on data-driven techniques to facilitate the modeling process and yield\naccurate channel predictions. In this work, we first provide a concise overview\nof data-driven channel modeling methods, highlighting their limitations.\nSubsequently, we introduce the concept and advantages of physics-informed\nneural network (PINN)-based modeling and a summary of recent contributions in\nthis area. Our findings demonstrate that PINN-based approaches in channel\nmodeling exhibit promising attributes such as generalizability,\ninterpretability, and robustness. We offer a comprehensive architecture for\nPINN methodology, designed to inform and inspire future model development. A\ncase-study of our recent work on precise indoor channel prediction with\nsemantic segmentation and deep learning is presented. The study concludes by\naddressing the challenges faced and suggesting potential research directions in\nthis field.",
      "tldr_zh": "本论文首先概述了数据驱动的无线信道建模方法及其局限性，如泛化性不足，然后引入 Physics-informed Neural Network (PINN) 建模的优势，包括更好的泛化性、可解释性和鲁棒性。作者提供了一个全面的 PINN 架构，并通过一个案例研究，利用 semantic segmentation 和 deep learning 实现了精确的室内信道预测。论文最后讨论了面临的挑战，如数据可用性和模型复杂性，并提出了潜在的研究方向。",
      "categories": [
        "cs.IT",
        "cs.AI",
        "cs.CV",
        "math.IT"
      ],
      "primary_category": "cs.IT",
      "comment": "Submitted to IEEE Magazine for potential future publications",
      "pdf_url": "http://arxiv.org/pdf/2401.01288v1",
      "published_date": "2024-01-02 16:56:13 UTC",
      "updated_date": "2024-01-02 16:56:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:18:07.252491"
    },
    {
      "arxiv_id": "2401.01286v5",
      "title": "A Comprehensive Study of Knowledge Editing for Large Language Models",
      "title_zh": "大型语言模型知识编辑的全面研究",
      "authors": [
        "Ningyu Zhang",
        "Yunzhi Yao",
        "Bozhong Tian",
        "Peng Wang",
        "Shumin Deng",
        "Mengru Wang",
        "Zekun Xi",
        "Shengyu Mao",
        "Jintian Zhang",
        "Yuansheng Ni",
        "Siyuan Cheng",
        "Ziwen Xu",
        "Xin Xu",
        "Jia-Chen Gu",
        "Yong Jiang",
        "Pengjun Xie",
        "Fei Huang",
        "Lei Liang",
        "Zhiqiang Zhang",
        "Xiaowei Zhu",
        "Jun Zhou",
        "Huajun Chen"
      ],
      "abstract": "Large Language Models (LLMs) have shown extraordinary capabilities in\nunderstanding and generating text that closely mirrors human communication.\nHowever, a primary limitation lies in the significant computational demands\nduring training, arising from their extensive parameterization. This challenge\nis further intensified by the dynamic nature of the world, necessitating\nfrequent updates to LLMs to correct outdated information or integrate new\nknowledge, thereby ensuring their continued relevance. Note that many\napplications demand continual model adjustments post-training to address\ndeficiencies or undesirable behaviors. There is an increasing interest in\nefficient, lightweight methods for on-the-fly model modifications. To this end,\nrecent years have seen a burgeoning in the techniques of knowledge editing for\nLLMs, which aim to efficiently modify LLMs' behaviors within specific domains\nwhile preserving overall performance across various inputs. In this paper, we\nfirst define the knowledge editing problem and then provide a comprehensive\nreview of cutting-edge approaches. Drawing inspiration from educational and\ncognitive research theories, we propose a unified categorization criterion that\nclassifies knowledge editing methods into three groups: resorting to external\nknowledge, merging knowledge into the model, and editing intrinsic knowledge.\nFurthermore, we introduce a new benchmark, KnowEdit, for a comprehensive\nempirical evaluation of representative knowledge editing approaches.\nAdditionally, we provide an in-depth analysis of knowledge location, which can\ngive a deeper understanding of the knowledge structures inherent within LLMs.\nFinally, we discuss several potential applications of knowledge editing,\noutlining its broad and impactful implications.",
      "tldr_zh": "本研究对大型语言模型 (LLMs) 的知识编辑技术进行了全面探讨，旨在解决模型训练计算需求高和需要频繁更新的问题，这些技术允许高效修改特定领域行为，同时保持整体性能。作者基于教育和认知理论，将知识编辑方法分类为：resorting to external knowledge、merging knowledge into the model 和 editing intrinsic knowledge，并引入新基准 KnowEdit 用于评估代表性方法。实验分析揭示了 LLMs 中知识结构的深入洞见，并讨论了知识编辑在实际应用中的广泛潜力，如模型持续优化和行为修正。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Ongoing work (v5): we have updated the Table 4 results after\n  optimizing certain methods (related to AdaLoRA) and fixing computational bugs\n  (related to ROME and MEMIT) in the EasyEdit. These improvements have led to\n  better results than before. We will continue updating this paper and welcome\n  everyone to discuss and exchange ideas",
      "pdf_url": "http://arxiv.org/pdf/2401.01286v5",
      "published_date": "2024-01-02 16:54:58 UTC",
      "updated_date": "2024-11-17 06:50:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:18:18.553699"
    },
    {
      "arxiv_id": "2401.01269v2",
      "title": "LLbezpeky: Leveraging Large Language Models for Vulnerability Detection",
      "title_zh": "LLbezpeky：利用大型语言模型进行漏洞检测",
      "authors": [
        "Noble Saji Mathews",
        "Yelizaveta Brus",
        "Yousra Aafer",
        "Meiyappan Nagappan",
        "Shane McIntosh"
      ],
      "abstract": "Despite the continued research and progress in building secure systems,\nAndroid applications continue to be ridden with vulnerabilities, necessitating\neffective detection methods. Current strategies involving static and dynamic\nanalysis tools come with limitations like overwhelming number of false\npositives and limited scope of analysis which make either difficult to adopt.\nOver the past years, machine learning based approaches have been extensively\nexplored for vulnerability detection, but its real-world applicability is\nconstrained by data requirements and feature engineering challenges. Large\nLanguage Models (LLMs), with their vast parameters, have shown tremendous\npotential in understanding semnatics in human as well as programming languages.\nWe dive into the efficacy of LLMs for detecting vulnerabilities in the context\nof Android security. We focus on building an AI-driven workflow to assist\ndevelopers in identifying and rectifying vulnerabilities. Our experiments show\nthat LLMs outperform our expectations in finding issues within applications\ncorrectly flagging insecure apps in 91.67% of cases in the Ghera benchmark. We\nuse inferences from our experiments towards building a robust and actionable\nvulnerability detection system and demonstrate its effectiveness. Our\nexperiments also shed light on how different various simple configurations can\naffect the True Positive (TP) and False Positive (FP) rates.",
      "tldr_zh": "这篇论文探讨了利用 Large Language Models (LLMs) 来检测 Android 应用中的漏洞，旨在解决现有静态和动态分析工具的局限性，如高假阳性(False Positive)率和分析范围有限的问题。研究团队开发了一个 AI 驱动的工作流，帮助开发者识别和修复安全漏洞，通过机器学习方法结合 LLMs 的语义理解能力。实验结果显示，在 Ghera 基准测试中，LLMs 正确标记不安全应用的准确率高达 91.67%，并分析了不同配置对 True Positive (TP) 和 False Positive (FP) 率的影响。最终，该系统为构建稳健的漏洞检测机制提供了实际指导。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.CR",
      "comment": "This project report was presented as a part of the course CS858 at\n  the University of Waterloo under the supervision of Prof. Yousra Aafer",
      "pdf_url": "http://arxiv.org/pdf/2401.01269v2",
      "published_date": "2024-01-02 16:14:30 UTC",
      "updated_date": "2024-02-13 17:56:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:18:31.406107"
    },
    {
      "arxiv_id": "2401.01265v1",
      "title": "Optimal Synthesis of Finite State Machines with Universal Gates using Evolutionary Algorithm",
      "title_zh": "翻译失败",
      "authors": [
        "Noor Ullah",
        "Khawaja M. Yahya",
        "Irfan Ahmed"
      ],
      "abstract": "This work presents an optimization method for the synthesis of finite state\nmachines. The focus is on the reduction in the on-chip area and the cost of the\ncircuit. A list of finite state machines from MCNC91 benchmark circuits have\nbeen evolved using Cartesian Genetic Programming. On the average, almost 30% of\nreduction in the total number of gates has been achieved. The effects of some\nparameters on the evolutionary process have also been discussed in the paper.",
      "tldr_zh": "这篇论文提出了一种使用演化算法优化有限状态机（Finite State Machines, FSMs）合成的方法，重点在于减少芯片面积和电路成本。研究采用Cartesian Genetic Programming（CGP）对MCNC91基准电路中的FSM进行演化，实现了平均近30%的门电路数量减少。论文还讨论了某些参数对演化过程的影响，为FSM设计提供了高效的优化策略。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.01265v1",
      "published_date": "2024-01-02 16:11:31 UTC",
      "updated_date": "2024-01-02 16:11:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:18:42.619207"
    },
    {
      "arxiv_id": "2401.01262v2",
      "title": "Fairness Certification for Natural Language Processing and Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Vincent Freiberger",
        "Erik Buchmann"
      ],
      "abstract": "Natural Language Processing (NLP) plays an important role in our daily lives,\nparticularly due to the enormous progress of Large Language Models (LLM).\nHowever, NLP has many fairness-critical use cases, e.g., as an expert system in\nrecruitment or as an LLM-based tutor in education. Since NLP is based on human\nlanguage, potentially harmful biases can diffuse into NLP systems and produce\nunfair results, discriminate against minorities or generate legal issues.\nHence, it is important to develop a fairness certification for NLP approaches.\nWe follow a qualitative research approach towards a fairness certification for\nNLP. In particular, we have reviewed a large body of literature on algorithmic\nfairness, and we have conducted semi-structured expert interviews with a wide\nrange of experts from that area. We have systematically devised six fairness\ncriteria for NLP, which can be further refined into 18 sub-categories. Our\ncriteria offer a foundation for operationalizing and testing processes to\ncertify fairness, both from the perspective of the auditor and the audited\norganization.",
      "tldr_zh": "本研究针对 Natural Language Processing (NLP) 和 Large Language Models (LLM) 在公平性方面的挑战，强调了这些系统可能引入偏见，导致不公平结果或歧视问题，如在招聘和教育中的应用。研究采用定性方法，包括文献综述和半结构化专家访谈，系统地制定了六项公平性标准，并进一步细分为 18 个子类别。这些标准为审计者和被审计组织提供了操作化和测试框架，以认证 NLP 系统的公平性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.LG",
        "68T50",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "In depth discussion of our results can be found in the Appendix B",
      "pdf_url": "http://arxiv.org/pdf/2401.01262v2",
      "published_date": "2024-01-02 16:09:36 UTC",
      "updated_date": "2024-01-03 08:17:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:18:54.585853"
    },
    {
      "arxiv_id": "2401.01259v3",
      "title": "Do Concept Bottleneck Models Respect Localities?",
      "title_zh": "翻译失败",
      "authors": [
        "Naveen Raman",
        "Mateo Espinosa Zarlenga",
        "Juyeon Heo",
        "Mateja Jamnik"
      ],
      "abstract": "Concept-based methods explain model predictions using human-understandable\nconcepts. These models require accurate concept predictors, yet the\nfaithfulness of existing concept predictors to their underlying concepts is\nunclear. In this paper, we investigate the faithfulness of Concept Bottleneck\nModels (CBMs), a popular family of concept-based architectures, by looking at\nwhether they respect \"localities\" in datasets. Localities involve using only\nrelevant features when predicting a concept's value. When localities are not\nconsidered, concepts may be predicted based on spuriously correlated features,\ndegrading performance and robustness. This work examines how CBM predictions\nchange when perturbing model inputs, and reveals that CBMs may not capture\nlocalities, even when independent concepts are localised to non-overlapping\nfeature subsets. Our empirical and theoretical results demonstrate that\ndatasets with correlated concepts may lead to accurate but uninterpretable\nmodels that fail to learn localities. Overall, we find that CBM\ninterpretability is fragile, as CBMs occasionally rely upon spurious features,\nnecessitating further research into the robustness of concept predictors.",
      "tldr_zh": "本研究探讨了 Concept Bottleneck Models (CBMs) 是否在预测概念时尊重“localities”，即只使用相关特征而非虚假相关特征(spurious correlated features)，以评估这些模型的可解释性和忠实度。作者通过扰动模型输入进行实证和理论分析，发现 CBMs 即使在独立概念被本地化时，也可能依赖虚假特征，导致准确但不可解释的模型。总体结果表明，概念相关的数据集会削弱 CBMs 的 localities 学习能力，强调需要进一步研究概念预测器的鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Previous Version Accepted at NeurIPs 23 XAI in Action Workshop",
      "pdf_url": "http://arxiv.org/pdf/2401.01259v3",
      "published_date": "2024-01-02 16:05:23 UTC",
      "updated_date": "2024-08-31 20:03:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:19:07.266916"
    },
    {
      "arxiv_id": "2401.01242v1",
      "title": "Encoding Binary Events from Continuous Time Series in Rooted Trees using Contrastive Learning",
      "title_zh": "利用对比学习从连续时间序列中编码有根树中的二进制事件",
      "authors": [
        "Tobias Engelhardt Rasmussen",
        "Siv Sørensen"
      ],
      "abstract": "Broadband infrastructure owners do not always know how their customers are\nconnected in the local networks, which are structured as rooted trees. A recent\nstudy is able to infer the topology of a local network using discrete time\nseries data from the leaves of the tree (customers). In this study we propose a\ncontrastive approach for learning a binary event encoder from continuous time\nseries data. As a preliminary result, we show that our approach has some\npotential in learning a valuable encoder.",
      "tldr_zh": "本文针对宽带基础设施中根树结构本地网络的拓扑推断问题，提出了一种使用对比学习（Contrastive Learning）的方法，从连续时间序列数据中编码二进制事件。相比先前基于离散数据的方案，该方法通过学习有效的二进制事件编码器，旨在更准确地推断网络连接。初步结果显示，该方法在学习有价值的编码器方面具有潜力，为网络拓扑分析提供新途径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Extended abstract presented as a poster at the Northern Lights Deep\n  Learning Conference 2024 in Troms{\\o}, Norway",
      "pdf_url": "http://arxiv.org/pdf/2401.01242v1",
      "published_date": "2024-01-02 15:18:23 UTC",
      "updated_date": "2024-01-02 15:18:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:19:19.410056"
    },
    {
      "arxiv_id": "2401.01227v2",
      "title": "IdentiFace : A VGG Based Multimodal Facial Biometric System",
      "title_zh": "IdentiFace：基于 VGG 的多模态面部",
      "authors": [
        "Mahmoud Rabea",
        "Hanya Ahmed",
        "Sohaila Mahmoud",
        "Nourhan Sayed"
      ],
      "abstract": "The development of facial biometric systems has contributed greatly to the\ndevelopment of the computer vision field. Nowadays, there's always a need to\ndevelop a multimodal system that combines multiple biometric traits in an\nefficient, meaningful way. In this paper, we introduce \"IdentiFace\" which is a\nmultimodal facial biometric system that combines the core of facial recognition\nwith some of the most important soft biometric traits such as gender, face\nshape, and emotion. We also focused on developing the system using only VGG-16\ninspired architecture with minor changes across different subsystems. This\nunification allows for simpler integration across modalities. It makes it\neasier to interpret the learned features between the tasks which gives a good\nindication about the decision-making process across the facial modalities and\npotential connection. For the recognition problem, we acquired a 99.2% test\naccuracy for five classes with high intra-class variations using data collected\nfrom the FERET database[1]. We achieved 99.4% on our dataset and 95.15% on the\npublic dataset[2] in the gender recognition problem. We were also able to\nachieve a testing accuracy of 88.03% in the face-shape problem using the\ncelebrity face-shape dataset[3]. Finally, we achieved a decent testing accuracy\nof 66.13% in the emotion task which is considered a very acceptable accuracy\ncompared to related work on the FER2013 dataset[4].",
      "tldr_zh": "这篇论文介绍了 IdentiFace，一个基于 VGG-16 启发架构的多模态面部生物识别系统，结合了核心面部识别与软生物特征如性别、面部形状和情感，以实现高效整合和特征解释。系统采用统一的架构设计，简化了不同模态之间的集成，并揭示了任务间的潜在联系。在实验中，IdentiFace 在 FERET 数据库上实现了99.2%的面部识别准确率，在性别识别任务上达到99.4%（自有数据集）和95.15%（公共数据集），面部形状识别准确率达88.03%，情感识别在 FER2013 数据集上为66.13%。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "12 pages, 22 figures and 9 images",
      "pdf_url": "http://arxiv.org/pdf/2401.01227v2",
      "published_date": "2024-01-02 14:36:28 UTC",
      "updated_date": "2024-01-10 12:13:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:19:32.719408"
    },
    {
      "arxiv_id": "2401.01218v3",
      "title": "Self-Supervised Position Debiasing for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zhongkun Liu",
        "Zheng Chen",
        "Mengqi Zhang",
        "Zhaochun Ren",
        "Pengjie Ren",
        "Zhumin Chen"
      ],
      "abstract": "Fine-tuning has been demonstrated to be an effective method to improve the\ndomain performance of large language models (LLMs). However, LLMs might fit the\ndataset bias and shortcuts for prediction, leading to poor generation\nperformance. Previous works have proven that LLMs are prone to exhibit position\nbias, i.e., leveraging information positioned at the beginning or end, or\nspecific positional cues within the input. Existing debiasing methods for LLMs\nrequire external bias knowledge or annotated non-biased samples, which is\nlacking for position debiasing and impractical in reality. In this work, we\npropose a self-supervised position debiasing (SOD) framework to mitigate\nposition bias for LLMs. SOD leverages unsupervised responses from pre-trained\nLLMs for debiasing without relying on any external knowledge. To improve the\nquality of unsupervised responses, we propose an objective alignment (OAM)\nmodule to prune these responses. Experiments on eight datasets and five tasks\nshow that SOD consistently outperforms existing methods in mitigating three\ntypes of position biases. Besides, SOD achieves this by sacrificing only a\nsmall performance on biased samples, which is general and effective. To\nfacilitate the reproducibility of the results, we share the code of all methods\nand datasets on https://github.com/LZKSKY/SOD.",
      "tldr_zh": "这篇论文提出了一种自监督位置去偏差（Self-Supervised Position Debiasing, SOD）框架，用于缓解大型语言模型（LLMs）在微调过程中因位置偏差（如依赖输入开头或结尾）而导致的性能问题。SOD 方法利用预训练 LLMs 的无监督响应进行去偏差，而无需外部知识，并引入目标对齐模块（Objective Alignment Module, OAM）来优化响应质量，从而提高去偏差效果。在八个数据集和五个任务的实验中，SOD 在减轻三种位置偏差方面优于现有方法，同时仅以小幅牺牲偏差样本性能为代价。该框架的通用性和有效性通过开源代码得以验证。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by ACL 2024 findings, this is the camera-ready version; 21\n  pages, 22 figures",
      "pdf_url": "http://arxiv.org/pdf/2401.01218v3",
      "published_date": "2024-01-02 14:12:41 UTC",
      "updated_date": "2024-06-29 05:20:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:19:44.497992"
    },
    {
      "arxiv_id": "2401.01204v2",
      "title": "PPBFL: A Privacy Protected Blockchain-based Federated Learning Model",
      "title_zh": "翻译失败",
      "authors": [
        "Yang Li",
        "Chunhe Xia",
        "Wanshuang Lin",
        "Tianbo Wang"
      ],
      "abstract": "With the rapid development of machine learning and a growing concern for data\nprivacy, federated learning has become a focal point of attention. However,\nattacks on model parameters and a lack of incentive mechanisms hinder the\neffectiveness of federated learning. Therefore, we propose A Privacy Protected\nBlockchain-based Federated Learning Model (PPBFL) to enhance the security of\nfederated learning and encourage active participation of nodes in model\ntraining. Blockchain technology ensures the integrity of model parameters\nstored in the InterPlanetary File System (IPFS), providing protection against\ntampering. Within the blockchain, we introduce a Proof of Training Work (PoTW)\nconsensus algorithm tailored for federated learning, aiming to incentive\ntraining nodes. This algorithm rewards nodes with greater computational power,\npromoting increased participation and effort in the federated learning process.\nA novel adaptive differential privacy algorithm is simultaneously applied to\nlocal and global models. This safeguards the privacy of local data at training\nclients, preventing malicious nodes from launching inference attacks.\nAdditionally, it enhances the security of the global model, preventing\npotential security degradation resulting from the combination of numerous local\nmodels. The possibility of security degradation is derived from the composition\ntheorem. By introducing reverse noise in the global model, a zero-bias estimate\nof differential privacy noise between local and global models is achieved.\nFurthermore, we propose a new mix transactions mechanism utilizing ring\nsignature technology to better protect the identity privacy of local training\nclients. Security analysis and experimental results demonstrate that PPBFL,\ncompared to baseline methods, not only exhibits superior model performance but\nalso achieves higher security.",
      "tldr_zh": "本研究提出PPBFL，一种基于区块链的联邦学习（federated learning）模型，旨在解决模型参数攻击和激励机制缺失等问题，以提升数据隐私保护和节点参与积极性。PPBFL利用区块链技术确保模型参数在InterPlanetary File System (IPFS)中的完整性，并引入Proof of Training Work (PoTW)共识算法来奖励计算能力强的训练节点，促进更多参与。模型还应用自适应差分隐私（adaptive differential privacy）算法到本地和全局模型中，通过引入反向噪声实现零偏差隐私估计，并采用环签名（ring signature）技术的混合交易机制保护本地训练客户端的身份隐私。实验结果显示，PPBFL相较于基线方法，不仅在模型性能上表现出色，还实现了更高的安全性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.01204v2",
      "published_date": "2024-01-02 13:13:28 UTC",
      "updated_date": "2024-01-08 15:38:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:19:56.129141"
    },
    {
      "arxiv_id": "2401.01200v1",
      "title": "Skin cancer diagnosis using NIR spectroscopy data of skin lesions in vivo using machine learning algorithms",
      "title_zh": "翻译失败",
      "authors": [
        "Flavio P. Loss",
        "Pedro H. da Cunha",
        "Matheus B. Rocha",
        "Madson Poltronieri Zanoni",
        "Leandro M. de Lima",
        "Isadora Tavares Nascimento",
        "Isabella Rezende",
        "Tania R. P. Canuto",
        "Luciana de Paula Vieira",
        "Renan Rossoni",
        "Maria C. S. Santos",
        "Patricia Lyra Frasson",
        "Wanderson Romão",
        "Paulo R. Filgueiras",
        "Renato A. Krohling"
      ],
      "abstract": "Skin lesions are classified in benign or malignant. Among the malignant,\nmelanoma is a very aggressive cancer and the major cause of deaths. So, early\ndiagnosis of skin cancer is very desired. In the last few years, there is a\ngrowing interest in computer aided diagnostic (CAD) using most image and\nclinical data of the lesion. These sources of information present limitations\ndue to their inability to provide information of the molecular structure of the\nlesion. NIR spectroscopy may provide an alternative source of information to\nautomated CAD of skin lesions. The most commonly used techniques and\nclassification algorithms used in spectroscopy are Principal Component Analysis\n(PCA), Partial Least Squares - Discriminant Analysis (PLS-DA), and Support\nVector Machines (SVM). Nonetheless, there is a growing interest in applying the\nmodern techniques of machine and deep learning (MDL) to spectroscopy. One of\nthe main limitations to apply MDL to spectroscopy is the lack of public\ndatasets. Since there is no public dataset of NIR spectral data to skin\nlesions, as far as we know, an effort has been made and a new dataset named\nNIR-SC-UFES, has been collected, annotated and analyzed generating the\ngold-standard for classification of NIR spectral data to skin cancer. Next, the\nmachine learning algorithms XGBoost, CatBoost, LightGBM, 1D-convolutional\nneural network (1D-CNN) were investigated to classify cancer and non-cancer\nskin lesions. Experimental results indicate the best performance obtained by\nLightGBM with pre-processing using standard normal variate (SNV), feature\nextraction providing values of 0.839 for balanced accuracy, 0.851 for recall,\n0.852 for precision, and 0.850 for F-score. The obtained results indicate the\nfirst steps in CAD of skin lesions aiming the automated triage of patients with\nskin lesions in vivo using NIR spectral data.",
      "tldr_zh": "本文研究了使用 NIR spectroscopy 数据和机器学习算法对活体皮肤病变进行诊断，旨在实现皮肤癌（如黑色素瘤）的早期检测，以降低死亡率。作者创建了新数据集 NIR-SC-UFES，并测试了 XGBoost、CatBoost、LightGBM 和 1D-CNN 等算法，其中 LightGBM 结合标准正态变异（SNV）预处理取得了最佳性能，包括 balanced accuracy 0.839、recall 0.851、precision 0.852 和 F-score 0.850。实验结果证明了 NIR spectroscopy 在计算机辅助诊断（CAD）中的潜力，为自动化皮肤病变患者分流提供了初步基础。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.01200v1",
      "published_date": "2024-01-02 13:03:39 UTC",
      "updated_date": "2024-01-02 13:03:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:20:09.399763"
    },
    {
      "arxiv_id": "2401.01199v1",
      "title": "JMA: a General Algorithm to Craft Nearly Optimal Targeted Adversarial Example",
      "title_zh": "JMA：一种通用算法，用于构建近乎最优的针对性对抗样本",
      "authors": [
        "Benedetta Tondi",
        "Wei Guo",
        "Mauro Barni"
      ],
      "abstract": "Most of the approaches proposed so far to craft targeted adversarial examples\nagainst Deep Learning classifiers are highly suboptimal and typically rely on\nincreasing the likelihood of the target class, thus implicitly focusing on\none-hot encoding settings. In this paper, we propose a more general,\ntheoretically sound, targeted attack that resorts to the minimization of a\nJacobian-induced MAhalanobis distance (JMA) term, taking into account the\neffort (in the input space) required to move the latent space representation of\nthe input sample in a given direction. The minimization is solved by exploiting\nthe Wolfe duality theorem, reducing the problem to the solution of a\nNon-Negative Least Square (NNLS) problem. The proposed algorithm provides an\noptimal solution to a linearized version of the adversarial example problem\noriginally introduced by Szegedy et al. \\cite{szegedy2013intriguing}. The\nexperiments we carried out confirm the generality of the proposed attack which\nis proven to be effective under a wide variety of output encoding schemes.\nNoticeably, the JMA attack is also effective in a multi-label classification\nscenario, being capable to induce a targeted modification of up to half the\nlabels in a complex multilabel classification scenario with 20 labels, a\ncapability that is out of reach of all the attacks proposed so far. As a\nfurther advantage, the JMA attack usually requires very few iterations, thus\nresulting more efficient than existing methods.",
      "tldr_zh": "本文提出了一种通用的 JMA 算法，用于生成近优化的针对性对抗样本，解决了现有方法在深度学习分类器上依赖 one-hot 编码的局限性。算法通过最小化基于 Jacobian 诱导的 Mahalanobis 距离（JMA）项，并运用 Wolfe duality theorem 将问题简化为 Non-Negative Least Square (NNLS) 问题，从而提供 Szegedy et al. 提出的对抗样本问题的一个线性化最优解。实验结果表明，JMA 攻击在多种输出编码方案下有效，尤其在多标签分类场景中能诱导修改多达一半的标签，且只需很少迭代，比现有方法更高效。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.01199v1",
      "published_date": "2024-01-02 13:03:29 UTC",
      "updated_date": "2024-01-02 13:03:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:20:20.612814"
    },
    {
      "arxiv_id": "2401.01197v1",
      "title": "Uncertainty Resolution in Misinformation Detection",
      "title_zh": "虚假信息检测中的不确定性",
      "authors": [
        "Yury Orlovskiy",
        "Camille Thibault",
        "Anne Imouza",
        "Jean-François Godbout",
        "Reihaneh Rabbany",
        "Kellin Pelrine"
      ],
      "abstract": "Misinformation poses a variety of risks, such as undermining public trust and\ndistorting factual discourse. Large Language Models (LLMs) like GPT-4 have been\nshown effective in mitigating misinformation, particularly in handling\nstatements where enough context is provided. However, they struggle to assess\nambiguous or context-deficient statements accurately. This work introduces a\nnew method to resolve uncertainty in such statements. We propose a framework to\ncategorize missing information and publish category labels for the LIAR-New\ndataset, which is adaptable to cross-domain content with missing information.\nWe then leverage this framework to generate effective user queries for missing\ncontext. Compared to baselines, our method improves the rate at which generated\nquestions are answerable by the user by 38 percentage points and classification\nperformance by over 10 percentage points macro F1. Thus, this approach may\nprovide a valuable component for future misinformation mitigation pipelines.",
      "tldr_zh": "该论文针对大型语言模型（LLMs）如GPT-4在虚假信息检测中处理模糊或缺少上下文语句的不足，提出了一种解决不确定性的新框架。该框架通过分类缺失信息并为LIAR-New数据集添加类别标签，使其适用于跨领域内容，并生成有效的用户查询来获取缺失上下文。与基线方法相比，该方法将用户查询的可回答率提高了38个百分点，并将分类性能的宏观F1分数提升超过10个百分点。这种方法为未来的虚假信息缓解管道提供了宝贵的组件。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.01197v1",
      "published_date": "2024-01-02 13:01:50 UTC",
      "updated_date": "2024-01-02 13:01:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:20:32.250829"
    },
    {
      "arxiv_id": "2401.06780v1",
      "title": "HA-HI: Synergising fMRI and DTI through Hierarchical Alignments and Hierarchical Interactions for Mild Cognitive Impairment Diagnosis",
      "title_zh": "翻译失败",
      "authors": [
        "Xiongri Shen",
        "Zhenxi Song",
        "Linling Li",
        "Min Zhang",
        "Lingyan Liang Honghai Liu",
        "Demao Deng",
        "Zhiguo Zhang"
      ],
      "abstract": "Early diagnosis of mild cognitive impairment (MCI) and subjective cognitive\ndecline (SCD) utilizing multi-modal magnetic resonance imaging (MRI) is a\npivotal area of research. While various regional and connectivity features from\nfunctional MRI (fMRI) and diffusion tensor imaging (DTI) have been employed to\ndevelop diagnosis models, most studies integrate these features without\nadequately addressing their alignment and interactions. This limits the\npotential to fully exploit the synergistic contributions of combined features\nand modalities. To solve this gap, our study introduces a novel Hierarchical\nAlignments and Hierarchical Interactions (HA-HI) method for MCI and SCD\nclassification, leveraging the combined strengths of fMRI and DTI. HA-HI\nefficiently learns significant MCI- or SCD- related regional and connectivity\nfeatures by aligning various feature types and hierarchically maximizing their\ninteractions. Furthermore, to enhance the interpretability of our approach, we\nhave developed the Synergistic Activation Map (SAM) technique, revealing the\ncritical brain regions and connections that are indicative of MCI/SCD.\nComprehensive evaluations on the ADNI dataset and our self-collected data\ndemonstrate that HA-HI outperforms other existing methods in diagnosing MCI and\nSCD, making it a potentially vital and interpretable tool for early detection.\nThe implementation of this method is publicly accessible at\nhttps://github.com/ICI-BCI/Dual-MRI-HA-HI.git.",
      "tldr_zh": "这篇论文提出了 HA-HI 方法，通过层次对齐和交互整合 fMRI 和 DTI 特征，用于早期诊断轻度认知障碍 (MCI) 和主观认知下降 (SCD)。HA-HI 通过对齐不同特征类型并层次化最大化它们的交互，高效学习与 MCI 或 SCD 相关的区域和连接性特征，同时引入 Synergistic Activation Map (SAM) 技术以提升模型的可解释性，揭示关键脑区和连接。实验在 ADNI 数据集和自收集数据上显示，HA-HI 优于现有方法，为临床早期检测提供了一个可靠且可解释的工具。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.06780v1",
      "published_date": "2024-01-02 12:46:02 UTC",
      "updated_date": "2024-01-02 12:46:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:20:44.493631"
    },
    {
      "arxiv_id": "2401.01189v2",
      "title": "NID-SLAM: Neural Implicit Representation-based RGB-D SLAM in dynamic environments",
      "title_zh": "翻译失败",
      "authors": [
        "Ziheng Xu",
        "Jianwei Niu",
        "Qingfeng Li",
        "Tao Ren",
        "Chen Chen"
      ],
      "abstract": "Neural implicit representations have been explored to enhance visual SLAM\nalgorithms, especially in providing high-fidelity dense map. Existing methods\noperate robustly in static scenes but struggle with the disruption caused by\nmoving objects. In this paper we present NID-SLAM, which significantly improves\nthe performance of neural SLAM in dynamic environments. We propose a new\napproach to enhance inaccurate regions in semantic masks, particularly in\nmarginal areas. Utilizing the geometric information present in depth images,\nthis method enables accurate removal of dynamic objects, thereby reducing the\nprobability of camera drift. Additionally, we introduce a keyframe selection\nstrategy for dynamic scenes, which enhances camera tracking robustness against\nlarge-scale objects and improves the efficiency of mapping. Experiments on\npublicly available RGB-D datasets demonstrate that our method outperforms\ncompetitive neural SLAM approaches in tracking accuracy and mapping quality in\ndynamic environments.",
      "tldr_zh": "本论文提出 NID-SLAM，一种基于 Neural Implicit Representation 的 RGB-D SLAM 系统，旨在提升动态环境下的视觉 SLAM 性能。方法包括增强语义掩码的准确性，利用深度图像的几何信息精确移除动态物体以减少相机漂移，以及引入动态场景的关键帧选择策略来提高跟踪鲁棒性和映射效率。在公开 RGB-D 数据集的实验中，NID-SLAM 在跟踪准确性和映射质量上优于竞争对手的神经 SLAM 方法。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.01189v2",
      "published_date": "2024-01-02 12:35:03 UTC",
      "updated_date": "2024-05-16 14:19:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:20:55.945737"
    },
    {
      "arxiv_id": "2401.01183v1",
      "title": "Unifying Structured Data as Graph for Data-to-Text Pre-Training",
      "title_zh": "将结构化数据统一为图以进行数据到文本预训练",
      "authors": [
        "Shujie Li",
        "Liang Li",
        "Ruiying Geng",
        "Min Yang",
        "Binhua Li",
        "Guanghu Yuan",
        "Wanwei He",
        "Shao Yuan",
        "Can Ma",
        "Fei Huang",
        "Yongbin Li"
      ],
      "abstract": "Data-to-text (D2T) generation aims to transform structured data into natural\nlanguage text. Data-to-text pre-training has proved to be powerful in enhancing\nD2T generation and yields impressive performances. However, previous\npre-training methods either oversimplified structured data into a sequence\nwithout considering input structures or designed training objectives tailored\nfor a specific data structure (e.g., table or knowledge graph). In this paper,\nwe unify different types of structured data (i.e., table, key-value data,\nknowledge graph) into the graph format and cast different data-to-text\ngeneration tasks as graph-to-text generation. To effectively exploit the\nstructural information of the input graph, we propose a structure-enhanced\npre-training method for D2T generation by designing a structure-enhanced\nTransformer. Concretely, we devise a position matrix for the Transformer,\nencoding relative positional information of connected nodes in the input graph.\nIn addition, we propose a new attention matrix to incorporate graph structures\ninto the original Transformer by taking the available explicit connectivity\nstructure into account. Extensive experiments on six benchmark datasets show\nthe effectiveness of our model. Our source codes are available at\nhttps://github.com/AlibabaResearch/DAMO-ConvAI/tree/main/unid2t.",
      "tldr_zh": "本文提出了一种统一方法，将不同类型的结构化数据（如表格、键值数据和知识图）转换为图格式，并将 Data-to-Text (D2T) 生成任务转化为图到文本生成，以更好地利用输入结构的特性。作者设计了结构增强的 Transformer 模型，包括一个位置矩阵来编码连接节点的相对位置信息，以及一个新的注意力矩阵来整合图的显式连接结构。实验结果显示，该方法在六个基准数据集上表现出色，证明了其在 D2T 预训练中的有效性和优越性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted for TACL. Pre-MIT Press publication version",
      "pdf_url": "http://arxiv.org/pdf/2401.01183v1",
      "published_date": "2024-01-02 12:23:49 UTC",
      "updated_date": "2024-01-02 12:23:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:21:08.208873"
    },
    {
      "arxiv_id": "2401.01180v1",
      "title": "Accurate and Efficient Urban Street Tree Inventory with Deep Learning on Mobile Phone Imagery",
      "title_zh": "翻译失败",
      "authors": [
        "Asim Khan",
        "Umair Nawaz",
        "Anwaar Ulhaq",
        "Iqbal Gondal",
        "Sajid Javed"
      ],
      "abstract": "Deforestation, a major contributor to climate change, poses detrimental\nconsequences such as agricultural sector disruption, global warming, flash\nfloods, and landslides. Conventional approaches to urban street tree inventory\nsuffer from inaccuracies and necessitate specialised equipment. To overcome\nthese challenges, this paper proposes an innovative method that leverages deep\nlearning techniques and mobile phone imaging for urban street tree inventory.\nOur approach utilises a pair of images captured by smartphone cameras to\naccurately segment tree trunks and compute the diameter at breast height (DBH).\nCompared to traditional methods, our approach exhibits several advantages,\nincluding superior accuracy, reduced dependency on specialised equipment, and\napplicability in hard-to-reach areas. We evaluated our method on a\ncomprehensive dataset of 400 trees and achieved a DBH estimation accuracy with\nan error rate of less than 2.5%. Our method holds significant potential for\nsubstantially improving forest management practices. By enhancing the accuracy\nand efficiency of tree inventory, our model empowers urban management to\nmitigate the adverse effects of deforestation and climate change.",
      "tldr_zh": "这篇论文提出了一种使用深度学习和手机图像进行城市街树库存的方法，以解决传统方法的准确性不足和对专业设备依赖的问题。方法利用智能手机拍摄的图像对来分割树干并计算胸高直径(DBH)，在400棵树的综合数据集上实现了DBH估计误差率小于2.5%。相比传统方法，该创新方案更高效且适用于偏远地区，有助于提升森林管理和城市应对气候变化的能力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "8 Pages, 7 figures and 5 Tables",
      "pdf_url": "http://arxiv.org/pdf/2401.01180v1",
      "published_date": "2024-01-02 12:16:01 UTC",
      "updated_date": "2024-01-02 12:16:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:21:20.789889"
    },
    {
      "arxiv_id": "2401.01179v1",
      "title": "Freeze the backbones: A Parameter-Efficient Contrastive Approach to Robust Medical Vision-Language Pre-training",
      "title_zh": "翻译失败",
      "authors": [
        "Jiuming Qin",
        "Che Liu",
        "Sibo Cheng",
        "Yike Guo",
        "Rossella Arcucci"
      ],
      "abstract": "Modern healthcare often utilises radiographic images alongside textual\nreports for diagnostics, encouraging the use of Vision-Language Self-Supervised\nLearning (VL-SSL) with large pre-trained models to learn versatile medical\nvision representations. However, most existing VL-SSL frameworks are trained\nend-to-end, which is computation-heavy and can lose vital prior information\nembedded in pre-trained encoders. To address both issues, we introduce the\nbackbone-agnostic Adaptor framework, which preserves medical knowledge in\npre-trained image and text encoders by keeping them frozen, and employs a\nlightweight Adaptor module for cross-modal learning. Experiments on medical\nimage classification and segmentation tasks across three datasets reveal that\nour framework delivers competitive performance while cutting trainable\nparameters by over 90% compared to current pre-training approaches. Notably,\nwhen fine-tuned with just 1% of data, Adaptor outperforms several\nTransformer-based methods trained on full datasets in medical image\nsegmentation.",
      "tldr_zh": "该研究针对医疗视觉语言自监督学习(VL-SSL)的端到端训练问题，提出了一种参数高效的对比学习方法，即backbone-agnostic Adaptor框架，通过冻结预训练的图像和文本编码器，仅训练轻量级Adaptor模块进行跨模态学习，从而保留先验知识并降低计算负担。  \n实验在三个数据集上的医疗图像分类和分割任务中表明，该框架的性能与现有方法相当，同时将可训练参数减少超过90%。  \n特别引人注目的是，仅使用1%的数据微调，Adaptor框架在医疗图像分割上就超过了多个在全数据集上训练的Transformer-based方法。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ICASSP 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.01179v1",
      "published_date": "2024-01-02 12:14:41 UTC",
      "updated_date": "2024-01-02 12:14:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:21:34.333564"
    },
    {
      "arxiv_id": "2401.02986v1",
      "title": "Identification of Regulatory Requirements Relevant to Business Processes: A Comparative Study on Generative AI, Embedding-based Ranking, Crowd and Expert-driven Methods",
      "title_zh": "翻译失败",
      "authors": [
        "Catherine Sai",
        "Shazia Sadiq",
        "Lei Han",
        "Gianluca Demartini",
        "Stefanie Rinderle-Ma"
      ],
      "abstract": "Organizations face the challenge of ensuring compliance with an increasing\namount of requirements from various regulatory documents. Which requirements\nare relevant depends on aspects such as the geographic location of the\norganization, its domain, size, and business processes. Considering these\ncontextual factors, as a first step, relevant documents (e.g., laws,\nregulations, directives, policies) are identified, followed by a more detailed\nanalysis of which parts of the identified documents are relevant for which step\nof a given business process. Nowadays the identification of regulatory\nrequirements relevant to business processes is mostly done manually by domain\nand legal experts, posing a tremendous effort on them, especially for a large\nnumber of regulatory documents which might frequently change. Hence, this work\nexamines how legal and domain experts can be assisted in the assessment of\nrelevant requirements. For this, we compare an embedding-based NLP ranking\nmethod, a generative AI method using GPT-4, and a crowdsourced method with the\npurely manual method of creating relevancy labels by experts. The proposed\nmethods are evaluated based on two case studies: an Australian insurance case\ncreated with domain experts and a global banking use case, adapted from SAP\nSignavio's workflow example of an international guideline. A gold standard is\ncreated for both BPMN2.0 processes and matched to real-world textual\nrequirements from multiple regulatory documents. The evaluation and discussion\nprovide insights into strengths and weaknesses of each method regarding\napplicability, automation, transparency, and reproducibility and provide\nguidelines on which method combinations will maximize benefits for given\ncharacteristics such as process usage, impact, and dynamics of an application\nscenario.",
      "tldr_zh": "该研究探讨了如何识别与业务流程相关的监管要求，比较了四种方法：基于嵌入的NLP排名(Embedding-based Ranking)、生成式AI(Generative AI，使用GPT-4)、众包(Crowd)和纯专家驱动(Expert-driven)方法，以减轻专家手动评估的负担。研究通过两个案例研究（澳大利亚保险和全球银行业用例）进行评估，使用BPMN2.0流程和真实监管文档创建金标准，并分析了每种方法的优势和劣势，如适用性、自动化、透明度和可重复性。结果显示，不同方法组合可根据过程的使用、影响和动态最大化益处，为高效合规管理提供实用指导。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.02986v1",
      "published_date": "2024-01-02 12:08:31 UTC",
      "updated_date": "2024-01-02 12:08:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:21:45.560026"
    },
    {
      "arxiv_id": "2401.01172v2",
      "title": "Quadratic Time-Frequency Analysis of Vibration Signals for Diagnosing Bearing Faults",
      "title_zh": "翻译失败",
      "authors": [
        "Mohammad Al-Sa'd",
        "Tuomas Jalonen",
        "Serkan Kiranyaz",
        "Moncef Gabbouj"
      ],
      "abstract": "Diagnosis of bearing faults is paramount to reducing maintenance costs and\noperational breakdowns. Bearing faults are primary contributors to machine\nvibrations, and analyzing their signal morphology offers insights into their\nhealth status. Unfortunately, existing approaches are optimized for controlled\nenvironments, neglecting realistic conditions such as time-varying rotational\nspeeds and the vibration's non-stationary nature. This paper presents a fusion\nof time-frequency analysis and deep learning techniques to diagnose bearing\nfaults under time-varying speeds and varying noise levels. First, we formulate\nthe bearing fault-induced vibrations and discuss the link between their\nnon-stationarity and the bearing's inherent and operational parameters. We also\nelucidate quadratic time-frequency distributions and validate their\neffectiveness in resolving distinctive dynamic patterns associated with\ndifferent bearing faults. Based on this, we design a time-frequency\nconvolutional neural network (TF-CNN) to diagnose various faults in\nrolling-element bearings. Our experimental findings undeniably demonstrate the\nsuperior performance of TF-CNN in comparison to recently developed techniques.\nThey also assert its versatility in capturing fault-relevant non-stationary\nfeatures that couple with speed changes and show its exceptional resilience to\nnoise, consistently surpassing competing methods across various signal-to-noise\nratios and performance metrics. Altogether, the TF-CNN achieves substantial\naccuracy improvements up to 15%, in severe noise conditions.",
      "tldr_zh": "本论文针对轴承故障诊断问题，提出了一种融合二次时频分析（quadratic time-frequency distributions）和深度学习的方法，以应对实际条件下旋转速度变化和振动非平稳性的挑战。该方法首先分析轴承故障引起的非平稳振动及其与参数的关系，然后设计时频卷积神经网络（TF-CNN）来识别不同故障的动态模式。实验结果显示，TF-CNN 在各种信噪比下显著优于现有技术，在严重噪声环境中准确率提高高达15%，并展现出卓越的抗噪性和适应性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.01172v2",
      "published_date": "2024-01-02 12:02:50 UTC",
      "updated_date": "2024-02-08 17:14:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:21:56.742749"
    },
    {
      "arxiv_id": "2401.01141v1",
      "title": "Spiker+: a framework for the generation of efficient Spiking Neural Networks FPGA accelerators for inference at the edge",
      "title_zh": "Spiker+：一种用于生成高效脉冲神经网络 FPGA 加速器的框架，以实现边缘推理",
      "authors": [
        "Alessio Carpegna",
        "Alessandro Savino",
        "Stefano Di Carlo"
      ],
      "abstract": "Including Artificial Neural Networks in embedded systems at the edge allows\napplications to exploit Artificial Intelligence capabilities directly within\ndevices operating at the network periphery. This paper introduces Spiker+, a\ncomprehensive framework for generating efficient, low-power, and low-area\ncustomized Spiking Neural Networks (SNN) accelerators on FPGA for inference at\nthe edge. Spiker+ presents a configurable multi-layer hardware SNN, a library\nof highly efficient neuron architectures, and a design framework, enabling the\ndevelopment of complex neural network accelerators with few lines of Python\ncode. Spiker+ is tested on two benchmark datasets, the MNIST and the Spiking\nHeidelberg Digits (SHD). On the MNIST, it demonstrates competitive performance\ncompared to state-of-the-art SNN accelerators. It outperforms them in terms of\nresource allocation, with a requirement of 7,612 logic cells and 18 Block RAMs\n(BRAMs), which makes it fit in very small FPGA, and power consumption, draining\nonly 180mW for a complete inference on an input image. The latency is\ncomparable to the ones observed in the state-of-the-art, with 780us/img. To the\nauthors' knowledge, Spiker+ is the first SNN accelerator tested on the SHD. In\nthis case, the accelerator requires 18,268 logic cells and 51 BRAM, with an\noverall power consumption of 430mW and a latency of 54 us for a complete\ninference on input data. This underscores the significance of Spiker+ in the\nhardware-accelerated SNN landscape, making it an excellent solution to deploy\nconfigurable and tunable SNN architectures in resource and power-constrained\nedge applications.",
      "tldr_zh": "本文提出 Spiker+ 框架，用于生成高效、低功耗和低面积的 Spiking Neural Networks (SNN) FPGA 加速器，针对边缘推理应用。该框架包括可配置的多层硬件 SNN、一个高效神经元架构库，以及基于 Python 的设计工具，允许用户用少量代码开发复杂加速器。在 MNIST 数据集上，Spiker+ 与最先进 SNN 加速器性能相当，但资源占用更低（7,612 逻辑单元和 18 Block RAMs），功耗仅 180mW，延迟为 780us/img。在 Spiking Heidelberg Digits (SHD) 数据集上首次测试，需 18,268 逻辑单元和 51 BRAM，功耗 430mW，延迟 54us，展示了其在资源受限边缘场景中的显著优势。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.AR"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.01141v1",
      "published_date": "2024-01-02 10:42:42 UTC",
      "updated_date": "2024-01-02 10:42:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:22:12.077991"
    },
    {
      "arxiv_id": "2401.01124v1",
      "title": "Explainable Adaptive Tree-based Model Selection for Time Series Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Matthias Jakobs",
        "Amal Saadallah"
      ],
      "abstract": "Tree-based models have been successfully applied to a wide variety of tasks,\nincluding time series forecasting. They are increasingly in demand and widely\naccepted because of their comparatively high level of interpretability.\nHowever, many of them suffer from the overfitting problem, which limits their\napplication in real-world decision-making. This problem becomes even more\nsevere in online-forecasting settings where time series observations are\nincrementally acquired, and the distributions from which they are drawn may\nkeep changing over time. In this context, we propose a novel method for the\nonline selection of tree-based models using the TreeSHAP explainability method\nin the task of time series forecasting. We start with an arbitrary set of\ndifferent tree-based models. Then, we outline a performance-based ranking with\na coherent design to make TreeSHAP able to specialize the tree-based\nforecasters across different regions in the input time series. In this\nframework, adequate model selection is performed online, adaptively following\ndrift detection in the time series. In addition, explainability is supported on\nthree levels, namely online input importance, model selection, and model output\nexplanation. An extensive empirical study on various real-world datasets\ndemonstrates that our method achieves excellent or on-par results in comparison\nto the state-of-the-art approaches as well as several baselines.",
      "tldr_zh": "本研究针对树-based 模型在时间序列 forecasting 中的过拟合问题，尤其是在线预测环境下数据分布变化带来的挑战，提出了一种可解释的自适应模型选择方法。方法利用 TreeSHAP 解释性技术，对一组树-based 模型进行性能-based 排名和专业化处理，使其在线适应不同输入区域，并通过漂移检测实现动态模型选择，同时提供在线输入重要性、模型选择和输出解释的多层次可解释性。在多个真实数据集上的实验表明，该方法与最先进方法相比表现出色或相当，显著提升了预测的鲁棒性和可解释性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted and presented at ICDM 2023",
      "pdf_url": "http://arxiv.org/pdf/2401.01124v1",
      "published_date": "2024-01-02 09:40:02 UTC",
      "updated_date": "2024-01-02 09:40:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:22:21.322944"
    },
    {
      "arxiv_id": "2401.01119v1",
      "title": "Utilizing Autoregressive Networks for Full Lifecycle Data Generation of Rolling Bearings for RUL Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Junliang Wang",
        "Qinghua Zhang",
        "Guanhua Zhu",
        "Guoxi Sun"
      ],
      "abstract": "The prediction of rolling bearing lifespan is of significant importance in\nindustrial production. However, the scarcity of high-quality, full lifecycle\ndata has been a major constraint in achieving precise predictions. To address\nthis challenge, this paper introduces the CVGAN model, a novel framework\ncapable of generating one-dimensional vibration signals in both horizontal and\nvertical directions, conditioned on historical vibration data and remaining\nuseful life. In addition, we propose an autoregressive generation method that\ncan iteratively utilize previously generated vibration information to guide the\ngeneration of current signals. The effectiveness of the CVGAN model is\nvalidated through experiments conducted on the PHM 2012 dataset. Our findings\ndemonstrate that the CVGAN model, in terms of both MMD and FID metrics,\noutperforms many advanced methods in both autoregressive and non-autoregressive\ngeneration modes. Notably, training using the full lifecycle data generated by\nthe CVGAN model significantly improves the performance of the predictive model.\nThis result highlights the effectiveness of the data generated by CVGans in\nenhancing the predictive power of these models.",
      "tldr_zh": "本研究针对滚动轴承剩余寿命（RUL）预测中数据稀缺问题，提出CVGAN模型，该模型能基于历史振动数据和剩余寿命生成全生命周期的一维振动信号，并引入自回归生成方法，利用先前生成的信号指导当前信号的迭代生成。实验在PHM 2012数据集上验证了CVGAN的有效性，其在MMD和FID指标上优于现有先进方法。结果显示，使用CVGAN生成的数据训练预测模型显著提升了性能，证明了该框架在工业应用中的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.01119v1",
      "published_date": "2024-01-02 09:31:14 UTC",
      "updated_date": "2024-01-02 09:31:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:22:32.253217"
    },
    {
      "arxiv_id": "2401.01104v1",
      "title": "AI-FLARES: Artificial Intelligence for the Analysis of Solar Flares Data",
      "title_zh": "翻译失败",
      "authors": [
        "Michele Piana",
        "Federico Benvenuto",
        "Anna Maria Massone",
        "Cristina Campi",
        "Sabrina Guastavino",
        "Francesco Marchetti",
        "Paolo Massa",
        "Emma Perracchione",
        "Anna Volpara"
      ],
      "abstract": "AI-FLARES (Artificial Intelligence for the Analysis of Solar Flares Data) is\na research project funded by the Agenzia Spaziale Italiana and by the Istituto\nNazionale di Astrofisica within the framework of the ``Attivit\\`a di Studio per\nla Comunit\\`a Scientifica Nazionale Sole, Sistema Solare ed Esopianeti''\nprogram. The topic addressed by this project was the development and use of\ncomputational methods for the analysis of remote sensing space data associated\nto solar flare emission. This paper overviews the main results obtained by the\nproject, with specific focus on solar flare forecasting, reconstruction of\nmorphologies of the flaring sources, and interpretation of acceleration\nmechanisms triggered by solar flares.",
      "tldr_zh": "AI-FLARES 项目由 Agenzia Spaziale Italiana 和 Istituto Nazionale di Astrofisica 资助，旨在开发和应用计算方法分析与 solar flares 相关的遥感空间数据。项目重点关注 solar flare forecasting、耀斑源形态重建，以及解释由太阳耀斑触发的加速机制。总体结果为太阳和行星科学社区提供了先进的 AI 工具，提升了数据分析和理解能力。",
      "categories": [
        "astro-ph.SR",
        "cs.AI",
        "85-04, 68T01"
      ],
      "primary_category": "astro-ph.SR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.01104v1",
      "published_date": "2024-01-02 08:56:01 UTC",
      "updated_date": "2024-01-02 08:56:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:22:45.648569"
    },
    {
      "arxiv_id": "2401.01099v1",
      "title": "Efficient Parallel Audio Generation using Group Masked Language Modeling",
      "title_zh": "使用组",
      "authors": [
        "Myeonghun Jeong",
        "Minchan Kim",
        "Joun Yeop Lee",
        "Nam Soo Kim"
      ],
      "abstract": "We present a fast and high-quality codec language model for parallel audio\ngeneration. While SoundStorm, a state-of-the-art parallel audio generation\nmodel, accelerates inference speed compared to autoregressive models, it still\nsuffers from slow inference due to iterative sampling. To resolve this problem,\nwe propose Group-Masked Language Modeling~(G-MLM) and Group Iterative Parallel\nDecoding~(G-IPD) for efficient parallel audio generation. Both the training and\nsampling schemes enable the model to synthesize high-quality audio with a small\nnumber of iterations by effectively modeling the group-wise conditional\ndependencies. In addition, our model employs a cross-attention-based\narchitecture to capture the speaker style of the prompt voice and improves\ncomputational efficiency. Experimental results demonstrate that our proposed\nmodel outperforms the baselines in prompt-based audio generation.",
      "tldr_zh": "本文提出了一种高效的并行音频生成方法，使用Group-Masked Language Modeling (G-MLM)和Group Iterative Parallel Decoding (G-IPD)，以解决现有模型如SoundStorm的迭代采样导致的推理速度慢问题。该方法通过有效建模组间条件依赖，实现少量迭代的高质量音频合成，并采用基于交叉注意力的架构来捕捉提示语音的说话者风格，提高计算效率。实验结果显示，该模型在基于提示的音频生成任务中优于基线模型。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.AS",
      "comment": "This work has been submitted to the IEEE for possible publication",
      "pdf_url": "http://arxiv.org/pdf/2401.01099v1",
      "published_date": "2024-01-02 08:42:48 UTC",
      "updated_date": "2024-01-02 08:42:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:22:56.726198"
    },
    {
      "arxiv_id": "2401.01089v1",
      "title": "Quokka: An Open-source Large Language Model ChatBot for Material Science",
      "title_zh": "翻译失败",
      "authors": [
        "Xianjun Yang",
        "Stephen D. Wilson",
        "Linda Petzold"
      ],
      "abstract": "This paper presents the development of a specialized chatbot for materials\nscience, leveraging the Llama-2 language model, and continuing pre-training on\nthe expansive research articles in the materials science domain from the S2ORC\ndataset. The methodology involves an initial pretraining phase on over one\nmillion domain-specific papers, followed by an instruction-tuning process to\nrefine the chatbot's capabilities. The chatbot is designed to assist\nresearchers, educators, and students by providing instant, context-aware\nresponses to queries in the field of materials science. We make the four\ntrained checkpoints (7B, 13B, with or without chat ability) freely available to\nthe research community at https://github.com/Xianjun-Yang/Quokka.",
      "tldr_zh": "这篇论文介绍了 Quokka，一款开源的大型语言模型聊天机器人，专为材料科学领域设计，基于 Llama-2 模型并在 S2ORC 数据集的超过一百万篇领域论文上进行持续预训练和 instruction-tuning 微调。Quokka 的目标是帮助研究人员、教育者和学生提供即时、上下文相关的查询响应，从而提升材料科学领域的交互效率。作者开源了四个训练检查点（包括 7B 和 13B 模型，有或无聊天能力），以供研究社区免费使用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.CL",
      "comment": "Work in progress",
      "pdf_url": "http://arxiv.org/pdf/2401.01089v1",
      "published_date": "2024-01-02 08:14:48 UTC",
      "updated_date": "2024-01-02 08:14:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:23:10.173182"
    },
    {
      "arxiv_id": "2401.01078v3",
      "title": "Vietnamese Poem Generation & The Prospect Of Cross-Language Poem-To-Poem Translation",
      "title_zh": "翻译失败",
      "authors": [
        "Triet Minh Huynh",
        "Quan Le Bao"
      ],
      "abstract": "Poetry generation has been a challenging task in the field of Natural\nLanguage Processing, as it requires the model to understand the nuances of\nlanguage, sentiment, and style. In this paper, we propose using Large Language\nModels to generate Vietnamese poems of various genres from natural language\nprompts, thereby facilitating an intuitive process with enhanced content\ncontrol. Our most efficacious model, the GPT-3 Babbage variant, achieves a\ncustom evaluation score of 0.8, specifically tailored to the \"luc bat\" genre of\nVietnamese poetry. Furthermore, we also explore the idea of paraphrasing poems\ninto normal text prompts and yield a relatively high score of 0.781 in the \"luc\nbat\" genre. This experiment presents the potential for cross-Language\npoem-to-poem translation with translated poems as the inputs while concurrently\nmaintaining complete control over the generated content.",
      "tldr_zh": "本研究探讨了使用 Large Language Models（如 GPT-3 Babbage 变体）从自然语言提示生成越南诗歌的方法，提高了内容控制并处理了诗歌的语言细微差别、情感和风格。模型在“luc bat”体裁上达到了0.8的自定义评估分数，而将诗歌改述成文本提示的实验则获得0.781的分数。研究进一步展示了跨语言诗歌到诗歌翻译的可能性，通过翻译后的诗歌作为输入，实现对生成内容的完全控制，从而为诗歌生成和翻译领域提供了新前景。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.01078v3",
      "published_date": "2024-01-02 07:46:34 UTC",
      "updated_date": "2024-01-04 17:29:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:23:22.249824"
    },
    {
      "arxiv_id": "2401.01068v1",
      "title": "Discovering Significant Topics from Legal Decisions with Selective Inference",
      "title_zh": "翻译失败",
      "authors": [
        "Jerrold Soh"
      ],
      "abstract": "We propose and evaluate an automated pipeline for discovering significant\ntopics from legal decision texts by passing features synthesized with topic\nmodels through penalised regressions and post-selection significance tests. The\nmethod identifies case topics significantly correlated with outcomes,\ntopic-word distributions which can be manually-interpreted to gain insights\nabout significant topics, and case-topic weights which can be used to identify\nrepresentative cases for each topic. We demonstrate the method on a new dataset\nof domain name disputes and a canonical dataset of European Court of Human\nRights violation cases. Topic models based on latent semantic analysis as well\nas language model embeddings are evaluated. We show that topics derived by the\npipeline are consistent with legal doctrines in both areas and can be useful in\nother related legal analysis tasks.",
      "tldr_zh": "本研究提出了一种自动化管道，用于从法律决策文本中发现重要主题，该管道通过主题模型(topic models)合成特征，并结合惩罚回归(penalised regressions)和后选择显著性测试(post-selection significance tests)来识别与结果相关的主题。方法还能生成可手动解释的主题-单词分布(topic-word distributions)和案例-主题权重(case-topic weights)，以识别代表性案例。该管道在域名争议数据集和欧洲人权法院违例案例数据集上进行了评估，使用基于潜在语义分析(latent semantic analysis)和语言模型嵌入(language model embeddings)的主题模型，结果显示发现的主题与法律原则一致，并可应用于其他法律分析任务。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "This is an accepted manuscript of work forthcoming in PhilTrans A.\n  Please cite the publisher's version only",
      "pdf_url": "http://arxiv.org/pdf/2401.01068v1",
      "published_date": "2024-01-02 07:00:24 UTC",
      "updated_date": "2024-01-02 07:00:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:23:35.573702"
    },
    {
      "arxiv_id": "2401.01065v2",
      "title": "BEV-TSR: Text-Scene Retrieval in BEV Space for Autonomous Driving",
      "title_zh": "翻译失败",
      "authors": [
        "Tao Tang",
        "Dafeng Wei",
        "Zhengyu Jia",
        "Tian Gao",
        "Changwei Cai",
        "Chengkai Hou",
        "Peng Jia",
        "Kun Zhan",
        "Haiyang Sun",
        "Jingchen Fan",
        "Yixing Zhao",
        "Fu Liu",
        "Xiaodan Liang",
        "Xianpeng Lang",
        "Yang Wang"
      ],
      "abstract": "The rapid development of the autonomous driving industry has led to a\nsignificant accumulation of autonomous driving data. Consequently, there comes\na growing demand for retrieving data to provide specialized optimization.\nHowever, directly applying previous image retrieval methods faces several\nchallenges, such as the lack of global feature representation and inadequate\ntext retrieval ability for complex driving scenes. To address these issues,\nfirstly, we propose the BEV-TSR framework which leverages descriptive text as\nan input to retrieve corresponding scenes in the Bird's Eye View (BEV) space.\nThen to facilitate complex scene retrieval with extensive text descriptions, we\nemploy a large language model (LLM) to extract the semantic features of the\ntext inputs and incorporate knowledge graph embeddings to enhance the semantic\nrichness of the language embedding. To achieve feature alignment between the\nBEV feature and language embedding, we propose Shared Cross-modal Embedding\nwith a set of shared learnable embeddings to bridge the gap between these two\nmodalities, and employ a caption generation task to further enhance the\nalignment. Furthermore, there lack of well-formed retrieval datasets for\neffective evaluation. To this end, we establish a multi-level retrieval\ndataset, nuScenes-Retrieval, based on the widely adopted nuScenes dataset.\nExperimental results on the multi-level nuScenes-Retrieval show that BEV-TSR\nachieves state-of-the-art performance, e.g., 85.78% and 87.66% top-1 accuracy\non scene-to-text and text-to-scene retrieval respectively. Codes and datasets\nwill be available.",
      "tldr_zh": "该研究提出 BEV-TSR 框架，用于自动驾驶领域的文本-场景检索，通过在 Bird's Eye View (BEV) 空间中利用描述性文本作为输入，解决现有方法在全局特征表示和文本检索能力上的不足。框架采用大型语言模型 (LLM) 提取文本语义特征，并结合知识图谱嵌入增强语义丰富性，同时通过 Shared Cross-modal Embedding 和标题生成任务实现 BEV 特征与语言嵌入的对齐。为评估框架，研究团队基于 nuScenes 数据集构建了多级检索数据集 nuScenes-Retrieval。实验结果显示，BEV-TSR 在该数据集上达到最先进性能，例如场景到文本检索的 top-1 准确率达 85.78%，文本到场景检索达 87.66%。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.01065v2",
      "published_date": "2024-01-02 06:56:23 UTC",
      "updated_date": "2024-06-18 04:20:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:23:48.119861"
    },
    {
      "arxiv_id": "2401.01056v1",
      "title": "Enhancing Automatic Modulation Recognition through Robust Global Feature Extraction",
      "title_zh": "通过鲁棒全局特征提取增强自动调制识别",
      "authors": [
        "Yunpeng Qu",
        "Zhilin Lu",
        "Rui Zeng",
        "Jintao Wang",
        "Jian Wang"
      ],
      "abstract": "Automatic Modulation Recognition (AMR) plays a crucial role in wireless\ncommunication systems. Deep learning AMR strategies have achieved tremendous\nsuccess in recent years. Modulated signals exhibit long temporal dependencies,\nand extracting global features is crucial in identifying modulation schemes.\nTraditionally, human experts analyze patterns in constellation diagrams to\nclassify modulation schemes. Classical convolutional-based networks, due to\ntheir limited receptive fields, excel at extracting local features but struggle\nto capture global relationships. To address this limitation, we introduce a\nnovel hybrid deep framework named TLDNN, which incorporates the architectures\nof the transformer and long short-term memory (LSTM). We utilize the\nself-attention mechanism of the transformer to model the global correlations in\nsignal sequences while employing LSTM to enhance the capture of temporal\ndependencies. To mitigate the impact like RF fingerprint features and channel\ncharacteristics on model generalization, we propose data augmentation\nstrategies known as segment substitution (SS) to enhance the model's robustness\nto modulation-related features. Experimental results on widely-used datasets\ndemonstrate that our method achieves state-of-the-art performance and exhibits\nsignificant advantages in terms of complexity. Our proposed framework serves as\na foundational backbone that can be extended to different datasets. We have\nverified the effectiveness of our augmentation approach in enhancing the\ngeneralization of the models, particularly in few-shot scenarios. Code is\navailable at \\url{https://github.com/AMR-Master/TLDNN}.",
      "tldr_zh": "本研究针对 Automatic Modulation Recognition (AMR) 在无线通信系统中的关键作用，提出了一种新型混合深度框架 TLDNN，以解决传统卷积网络在提取全局特征时的局限性。TLDNN 结合 Transformer 的自注意力机制捕捉信号序列的全局相关性，以及 LSTM 来增强时序依赖性捕捉，同时引入 segment substitution (SS) 数据增强策略，以提高模型对调制相关特征的鲁棒性和泛化能力。实验结果显示，该框架在常用数据集上实现了最先进性能，并在复杂性和少样本场景中表现出显著优势，可作为扩展到不同数据集的通用骨干框架。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "submitted to IEEE Transactions on Vehicular Technology, 14 pages, 11\n  figures",
      "pdf_url": "http://arxiv.org/pdf/2401.01056v1",
      "published_date": "2024-01-02 06:31:24 UTC",
      "updated_date": "2024-01-02 06:31:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:24:00.114441"
    },
    {
      "arxiv_id": "2401.01055v2",
      "title": "LLaMA Beyond English: An Empirical Study on Language Capability Transfer",
      "title_zh": "翻译失败",
      "authors": [
        "Jun Zhao",
        "Zhihao Zhang",
        "Luhui Gao",
        "Qi Zhang",
        "Tao Gui",
        "Xuanjing Huang"
      ],
      "abstract": "In recent times, substantial advancements have been witnessed in large\nlanguage models (LLMs), exemplified by ChatGPT, showcasing remarkable\nproficiency across a range of complex tasks. However, many mainstream LLMs\n(e.g. LLaMA) are pretrained on English-dominant corpus, which limits their\nperformance in other non-English languages. In this paper, we focus on how to\neffectively transfer the capabilities of language generation and following\ninstructions to a non-English language. To answer this question, we conduct an\nextensive empirical investigation based on LLaMA, accumulating over 1440 GPU\nhours. We analyze the impact of key factors such as vocabulary extension,\nfurther pretraining, and instruction tuning on transfer. To accurately assess\nthe model's level of knowledge, we employ four widely used standardized testing\nbenchmarks: C-Eval, MMLU, AGI-Eval, and GAOKAO-Bench. Furthermore, a\ncomprehensive evaluation of the model's response quality is conducted,\nconsidering aspects such as accuracy, fluency, informativeness, logical\ncoherence, and harmlessness, based on LLM-Eval, a benchmarks consisting\ninstruction tasks from 17 diverse categories. Our evaluation results\ndemonstrate that comparable performance to state-of-the-art transfer models can\nbe achieved with less than 1% of the pretraining data, both in terms of\nknowledge alignment and response quality. Furthermore, the experimental\noutcomes across the thirteen low-resource languages also exhibit similar\ntrends. We anticipate that the conclusions revealed by the experiments will aid\nthe community in developing non-English LLMs.",
      "tldr_zh": "这篇论文通过实证研究探讨了如何将LLaMA等英文主导的大型语言模型（LLMs）的语言生成和指令遵循能力转移到非英文语言。研究分析了关键因素，包括词汇扩展、进一步预训练和指令微调，并使用C-Eval、MMLU、AGI-Eval和GAOKAO-Bench等基准评估模型的知识水平，以及LLM-Eval基准评估响应质量（如准确性、流畅性和逻辑连贯性）。结果显示，使用不到1%的预训练数据即可实现与最先进转移模型相当的性能，且在13种低资源语言上观察到类似趋势。该研究为开发非英文LLMs提供了宝贵指导。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.01055v2",
      "published_date": "2024-01-02 06:29:02 UTC",
      "updated_date": "2024-01-12 08:14:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:24:14.018188"
    },
    {
      "arxiv_id": "2401.01054v1",
      "title": "Elastic Multi-Gradient Descent for Parallel Continual Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Fan Lyu",
        "Wei Feng",
        "Yuepan Li",
        "Qing Sun",
        "Fanhua Shang",
        "Liang Wan",
        "Liang Wang"
      ],
      "abstract": "The goal of Continual Learning (CL) is to continuously learn from new data\nstreams and accomplish the corresponding tasks. Previously studied CL assumes\nthat data are given in sequence nose-to-tail for different tasks, thus indeed\nbelonging to Serial Continual Learning (SCL). This paper studies the novel\nparadigm of Parallel Continual Learning (PCL) in dynamic multi-task scenarios,\nwhere a diverse set of tasks is encountered at different time points. PCL\npresents challenges due to the training of an unspecified number of tasks with\nvarying learning progress, leading to the difficulty of guaranteeing effective\nmodel updates for all encountered tasks. In our previous conference work, we\nfocused on measuring and reducing the discrepancy among gradients in a\nmulti-objective optimization problem, which, however, may still contain\nnegative transfers in every model update. To address this issue, in the dynamic\nmulti-objective optimization problem, we introduce task-specific elastic\nfactors to adjust the descent direction towards the Pareto front. The proposed\nmethod, called Elastic Multi-Gradient Descent (EMGD), ensures that each update\nfollows an appropriate Pareto descent direction, minimizing any negative impact\non previously learned tasks. To balance the training between old and new tasks,\nwe also propose a memory editing mechanism guided by the gradient computed\nusing EMGD. This editing process updates the stored data points, reducing\ninterference in the Pareto descent direction from previous tasks. Experiments\non public datasets validate the effectiveness of our EMGD in the PCL setting.",
      "tldr_zh": "本论文提出了一种新型的 Parallel Continual Learning (PCL) 范式，与传统的 Serial Continual Learning (SCL) 不同，PCL 涉及在不同时间点处理多样化任务的动态场景，面临模型更新不均和负面转移的挑战。作者引入 Elastic Multi-Gradient Descent (EMGD) 方法，通过任务特定的弹性因子调整梯度下降方向，确保每个更新朝向 Pareto front，从而最小化对先前任务的负面影响；同时，提出一个基于 EMGD 梯度引导的记忆编辑机制，以平衡旧任务和新任务的训练并减少干扰。实验在公共数据集上验证了 EMGD 在 PCL 设置中的有效性，展示了其在动态多任务优化中的优越性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Submited to IEEE TPAMI",
      "pdf_url": "http://arxiv.org/pdf/2401.01054v1",
      "published_date": "2024-01-02 06:26:25 UTC",
      "updated_date": "2024-01-02 06:26:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:24:25.936717"
    },
    {
      "arxiv_id": "2401.01044v1",
      "title": "Auffusion: Leveraging the Power of Diffusion and Large Language Models for Text-to-Audio Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Jinlong Xue",
        "Yayue Deng",
        "Yingming Gao",
        "Ya Li"
      ],
      "abstract": "Recent advancements in diffusion models and large language models (LLMs) have\nsignificantly propelled the field of AIGC. Text-to-Audio (TTA), a burgeoning\nAIGC application designed to generate audio from natural language prompts, is\nattracting increasing attention. However, existing TTA studies often struggle\nwith generation quality and text-audio alignment, especially for complex\ntextual inputs. Drawing inspiration from state-of-the-art Text-to-Image (T2I)\ndiffusion models, we introduce Auffusion, a TTA system adapting T2I model\nframeworks to TTA task, by effectively leveraging their inherent generative\nstrengths and precise cross-modal alignment. Our objective and subjective\nevaluations demonstrate that Auffusion surpasses previous TTA approaches using\nlimited data and computational resource. Furthermore, previous studies in T2I\nrecognizes the significant impact of encoder choice on cross-modal alignment,\nlike fine-grained details and object bindings, while similar evaluation is\nlacking in prior TTA works. Through comprehensive ablation studies and\ninnovative cross-attention map visualizations, we provide insightful\nassessments of text-audio alignment in TTA. Our findings reveal Auffusion's\nsuperior capability in generating audios that accurately match textual\ndescriptions, which further demonstrated in several related tasks, such as\naudio style transfer, inpainting and other manipulations. Our implementation\nand demos are available at https://auffusion.github.io.",
      "tldr_zh": "本研究提出 Auffusion，一种结合扩散模型和大型语言模型 (LLMs) 的 Text-to-Audio (TTA) 生成系统，旨在提升音频生成质量和文本-音频对齐，尤其针对复杂文本输入。Auffusion 通过借鉴 Text-to-Image (T2I) 扩散模型的框架，适应 TTA 任务，利用其生成优势和跨模态对齐能力，仅凭有限的数据和计算资源即超越现有方法。实验结果显示，Auffusion 在客观和主观评估中表现出色，并在音频风格转移、修复等相关任务中证明其精确匹配文本描述的能力。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CL",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Demo and implementation at https://auffusion.github.io",
      "pdf_url": "http://arxiv.org/pdf/2401.01044v1",
      "published_date": "2024-01-02 05:42:14 UTC",
      "updated_date": "2024-01-02 05:42:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:24:37.811655"
    },
    {
      "arxiv_id": "2401.01040v1",
      "title": "Towards Cognitive AI Systems: a Survey and Prospective on Neuro-Symbolic AI",
      "title_zh": "翻译失败",
      "authors": [
        "Zishen Wan",
        "Che-Kai Liu",
        "Hanchen Yang",
        "Chaojian Li",
        "Haoran You",
        "Yonggan Fu",
        "Cheng Wan",
        "Tushar Krishna",
        "Yingyan Lin",
        "Arijit Raychowdhury"
      ],
      "abstract": "The remarkable advancements in artificial intelligence (AI), primarily driven\nby deep neural networks, have significantly impacted various aspects of our\nlives. However, the current challenges surrounding unsustainable computational\ntrajectories, limited robustness, and a lack of explainability call for the\ndevelopment of next-generation AI systems. Neuro-symbolic AI (NSAI) emerges as\na promising paradigm, fusing neural, symbolic, and probabilistic approaches to\nenhance interpretability, robustness, and trustworthiness while facilitating\nlearning from much less data. Recent NSAI systems have demonstrated great\npotential in collaborative human-AI scenarios with reasoning and cognitive\ncapabilities. In this paper, we provide a systematic review of recent progress\nin NSAI and analyze the performance characteristics and computational operators\nof NSAI models. Furthermore, we discuss the challenges and potential future\ndirections of NSAI from both system and architectural perspectives.",
      "tldr_zh": "这篇论文审视了人工智能（AI）的发展，特别是由深度神经网络驱动的进步，但强调了当前面临的挑战，如不可持续的计算轨迹、有限的鲁棒性和缺乏可解释性。Neuro-Symbolic AI (NSAI) 被提出作为一种融合神经、符号和概率方法的范式，能够提升AI的可解释性、鲁棒性和可信度，同时减少数据需求，并在人类-AI协作场景中展现出推理和认知能力。论文系统回顾了NSAI的最新进展，分析了其性能特征和计算操作符，并讨论了从系统和架构角度的潜在挑战及未来方向。",
      "categories": [
        "cs.AI",
        "cs.AR"
      ],
      "primary_category": "cs.AI",
      "comment": "Workshop on Systems for Next-Gen AI Paradigms, 6th Conference on\n  Machine Learning and Systems (MLSys), June 4-8, 2023, Miami, FL, USA",
      "pdf_url": "http://arxiv.org/pdf/2401.01040v1",
      "published_date": "2024-01-02 05:00:54 UTC",
      "updated_date": "2024-01-02 05:00:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:24:49.883975"
    },
    {
      "arxiv_id": "2401.06168v1",
      "title": "A Survey on Game Theory Optimal Poker",
      "title_zh": "翻译失败",
      "authors": [
        "Prathamesh Sonawane",
        "Arav Chheda"
      ],
      "abstract": "Poker is in the family of imperfect information games unlike other games such\nas chess, connect four, etc which are perfect information game instead. While\nmany perfect information games have been solved, no non-trivial imperfect\ninformation game has been solved to date. This makes poker a great test bed for\nArtificial Intelligence research. In this paper we firstly compare Game theory\noptimal poker to Exploitative poker. Secondly, we discuss the intricacies of\nabstraction techniques, betting models, and specific strategies employed by\nsuccessful poker bots like Tartanian[1] and Pluribus[6]. Thirdly, we also\nexplore 2-player vs multi-player games and the limitations that come when\nplaying with more players. Finally, this paper discusses the role of machine\nlearning and theoretical approaches in developing winning strategies and\nsuggests future directions for this rapidly evolving field.",
      "tldr_zh": "这篇论文调查了游戏理论最优扑克（Game theory optimal poker），将它与利用性扑克（Exploitative poker）进行比较，强调扑克作为不完美信息游戏（imperfect information games）的AI研究测试平台，与完美信息游戏（perfect information games）形成鲜明对比。论文讨论了抽象技术（abstraction techniques）、投注模型（betting models）和成功扑克AI策略如Tartanian和Pluribus的具体应用，并探索了双人 vs 多玩家游戏的挑战和限制。同时，它分析了机器学习（machine learning）和理论方法在开发获胜策略中的作用，并为这个快速发展的领域提出未来方向。",
      "categories": [
        "cs.GT",
        "cs.AI"
      ],
      "primary_category": "cs.GT",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.06168v1",
      "published_date": "2024-01-02 04:19:25 UTC",
      "updated_date": "2024-01-02 04:19:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:25:04.962823"
    },
    {
      "arxiv_id": "2401.02985v1",
      "title": "Evaluating Large Language Models on the GMAT: Implications for the Future of Business Education",
      "title_zh": "在 GMAT 上评估大型语言模型：对商业教育未来的影响",
      "authors": [
        "Vahid Ashrafimoghari",
        "Necdet Gürkan",
        "Jordan W. Suchow"
      ],
      "abstract": "The rapid evolution of artificial intelligence (AI), especially in the domain\nof Large Language Models (LLMs) and generative AI, has opened new avenues for\napplication across various fields, yet its role in business education remains\nunderexplored. This study introduces the first benchmark to assess the\nperformance of seven major LLMs, OpenAI's models (GPT-3.5 Turbo, GPT-4, and\nGPT-4 Turbo), Google's models (PaLM 2, Gemini 1.0 Pro), and Anthropic's models\n(Claude 2 and Claude 2.1), on the GMAT, which is a key exam in the admission\nprocess for graduate business programs. Our analysis shows that most LLMs\noutperform human candidates, with GPT-4 Turbo not only outperforming the other\nmodels but also surpassing the average scores of graduate students at top\nbusiness schools. Through a case study, this research examines GPT-4 Turbo's\nability to explain answers, evaluate responses, identify errors, tailor\ninstructions, and generate alternative scenarios. The latest LLM versions,\nGPT-4 Turbo, Claude 2.1, and Gemini 1.0 Pro, show marked improvements in\nreasoning tasks compared to their predecessors, underscoring their potential\nfor complex problem-solving. While AI's promise in education, assessment, and\ntutoring is clear, challenges remain. Our study not only sheds light on LLMs'\nacademic potential but also emphasizes the need for careful development and\napplication of AI in education. As AI technology advances, it is imperative to\nestablish frameworks and protocols for AI interaction, verify the accuracy of\nAI-generated content, ensure worldwide access for diverse learners, and create\nan educational environment where AI supports human expertise. This research\nsets the stage for further exploration into the responsible use of AI to enrich\neducational experiences and improve exam preparation and assessment methods.",
      "tldr_zh": "这篇论文评估了七个主要 Large Language Models (LLMs)，包括 OpenAI 的 GPT-3.5 Turbo、GPT-4 和 GPT-4 Turbo，Google 的 PaLM 2 和 Gemini 1.0 Pro，以及 Anthropic 的 Claude 2 和 Claude 2.1，在 GMAT 考试中的表现，这是商业研究生入学考试的关键指标。结果显示，大多数 LLMs 超过了人类候选人的成绩，其中 GPT-4 Turbo 不仅优于其他模型，还超过了顶尖商学院研究生的平均分数。研究通过案例分析考察了 GPT-4 Turbo 的能力，如解释答案、评估响应、识别错误、定制指令和生成备选场景，并发现最新版本的 LLMs 在推理任务上有了显著改进。尽管 AI 在教育、评估和辅导方面显示出巨大潜力，该研究强调了挑战，包括需要建立框架验证 AI 内容准确性、确保全球访问和促进 AI 与人类专业知识的协作。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.02985v1",
      "published_date": "2024-01-02 03:54:50 UTC",
      "updated_date": "2024-01-02 03:54:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:25:18.954983"
    },
    {
      "arxiv_id": "2401.06167v1",
      "title": "Enhancing Multimodal Understanding with CLIP-Based Image-to-Text Transformation",
      "title_zh": "翻译失败",
      "authors": [
        "Chang Che",
        "Qunwei Lin",
        "Xinyu Zhao",
        "Jiaxin Huang",
        "Liqiang Yu"
      ],
      "abstract": "The process of transforming input images into corresponding textual\nexplanations stands as a crucial and complex endeavor within the domains of\ncomputer vision and natural language processing. In this paper, we propose an\ninnovative ensemble approach that harnesses the capabilities of Contrastive\nLanguage-Image Pretraining models.",
      "tldr_zh": "本文提出了一种创新的集成方法，利用 Contrastive Language-Image Pretraining (CLIP) 模型，将输入图像转化为对应的文本解释，以增强多模态理解。  \n这种方法针对计算机视觉和自然语言处理领域的关键挑战，旨在简化图像到文本转换过程。  \n实验结果表明，该方法能够有效提升模型在处理复杂多模态任务时的性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.06167v1",
      "published_date": "2024-01-02 03:49:41 UTC",
      "updated_date": "2024-01-02 03:49:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:25:36.503064"
    },
    {
      "arxiv_id": "2401.00996v1",
      "title": "Safety and Performance, Why Not Both? Bi-Objective Optimized Model Compression against Heterogeneous Attacks Toward AI Software Deployment",
      "title_zh": "安全性和性能，为什么不能两者兼得？针对异构攻击的双目标优化模型压缩，面向AI软件部署",
      "authors": [
        "Jie Zhu",
        "Leye Wang",
        "Xiao Han",
        "Anmin Liu",
        "Tao Xie"
      ],
      "abstract": "The size of deep learning models in artificial intelligence (AI) software is\nincreasing rapidly, hindering the large-scale deployment on resource-restricted\ndevices (e.g., smartphones). To mitigate this issue, AI software compression\nplays a crucial role, which aims to compress model size while keeping high\nperformance. However, the intrinsic defects in a big model may be inherited by\nthe compressed one. Such defects may be easily leveraged by adversaries, since\na compressed model is usually deployed in a large number of devices without\nadequate protection. In this article, we aim to address the safe model\ncompression problem from the perspective of safety-performance co-optimization.\nSpecifically, inspired by the test-driven development (TDD) paradigm in\nsoftware engineering, we propose a test-driven sparse training framework called\nSafeCompress. By simulating the attack mechanism as safety testing,\nSafeCompress can automatically compress a big model to a small one following\nthe dynamic sparse training paradigm. Then, considering two kinds of\nrepresentative and heterogeneous attack mechanisms, i.e., black-box membership\ninference attack and white-box membership inference attack, we develop two\nconcrete instances called BMIA-SafeCompress and WMIA-SafeCompress. Further, we\nimplement another instance called MMIA-SafeCompress by extending SafeCompress\nto defend against the occasion when adversaries conduct black-box and white-box\nmembership inference attacks simultaneously. We conduct extensive experiments\non five datasets for both computer vision and natural language processing\ntasks. The results show the effectiveness and generalizability of our\nframework. We also discuss how to adapt SafeCompress to other attacks besides\nmembership inference attack, demonstrating the flexibility of SafeCompress.",
      "tldr_zh": "这篇论文针对AI软件部署中的模型压缩问题，提出了一种双目标优化框架SafeCompress，以同时实现模型性能和安全性的平衡。框架借鉴测试驱动开发(TDD)范式，通过动态稀疏训练模拟黑盒和白盒成员推理攻击作为安全测试，自动压缩大模型并防御异构攻击，包括开发了BMIA-SafeCompress、WMIA-SafeCompress和MMIA-SafeCompress实例。实验在五种数据集上验证了框架的有效性、泛化性和灵活性，可扩展到其他攻击类型。",
      "categories": [
        "cs.AI",
        "cs.CR",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by IEEE Transactions on Software Engineering (TSE).\n  Camera-ready Version. arXiv admin note: substantial text overlap with\n  arXiv:2208.05969",
      "pdf_url": "http://arxiv.org/pdf/2401.00996v1",
      "published_date": "2024-01-02 02:31:36 UTC",
      "updated_date": "2024-01-02 02:31:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:25:49.220714"
    },
    {
      "arxiv_id": "2401.00986v1",
      "title": "Real-Time Object Detection in Occluded Environment with Background Cluttering Effects Using Deep Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Syed Muhammad Aamir",
        "Hongbin Ma",
        "Malak Abid Ali Khan",
        "Muhammad Aaqib"
      ],
      "abstract": "Detection of small, undetermined moving objects or objects in an occluded\nenvironment with a cluttered background is the main problem of computer vision.\nThis greatly affects the detection accuracy of deep learning models. To\novercome these problems, we concentrate on deep learning models for real-time\ndetection of cars and tanks in an occluded environment with a cluttered\nbackground employing SSD and YOLO algorithms and improved precision of\ndetection and reduce problems faced by these models. The developed method makes\nthe custom dataset and employs a preprocessing technique to clean the noisy\ndataset. For training the developed model we apply the data augmentation\ntechnique to balance and diversify the data. We fine-tuned, trained, and\nevaluated these models on the established dataset by applying these techniques\nand highlighting the results we got more accurately than without applying these\ntechniques. The accuracy and frame per second of the SSD-Mobilenet v2 model are\nhigher than YOLO V3 and YOLO V4. Furthermore, by employing various techniques\nlike data enhancement, noise reduction, parameter optimization, and model\nfusion we improve the effectiveness of detection and recognition. We further\nadded a counting algorithm, and target attributes experimental comparison, and\nmade a graphical user interface system for the developed model with features of\nobject counting, alerts, status, resolution, and frame per second.\nSubsequently, to justify the importance of the developed method analysis of\nYOLO V3, V4, and SSD were incorporated. Which resulted in the overall\ncompletion of the proposed method.",
      "tldr_zh": "这篇论文针对遮挡环境和杂乱背景下的实时物体检测问题，使用 SSD 和 YOLO 算法来提高对汽车和坦克等物体的检测精度。研究者创建了自定义数据集，并应用预处理、数据增强、噪声减少以及参数优化等技术来清理和平衡数据，从而提升模型性能。实验结果显示，SSD-Mobilenet v2 的准确性和帧率均优于 YOLO V3 和 YOLO V4；此外，论文还引入了物体计数算法、目标属性比较，并开发了图形用户界面系统，支持警报、状态显示等功能。总的来说，该方法显著改善了深度学习模型在复杂环境中的检测效果。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.00986v1",
      "published_date": "2024-01-02 01:30:03 UTC",
      "updated_date": "2024-01-02 01:30:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:26:02.468108"
    },
    {
      "arxiv_id": "2401.02941v2",
      "title": "Unsupervised Federated Domain Adaptation for Segmentation of MRI Images",
      "title_zh": "翻译失败",
      "authors": [
        "Navapat Nananukul",
        "Hamid Soltanian-zadeh",
        "Mohammad Rostami"
      ],
      "abstract": "Automatic semantic segmentation of magnetic resonance imaging (MRI) images\nusing deep neural networks greatly assists in evaluating and planning\ntreatments for various clinical applications. However, training these models is\nconditioned on the availability of abundant annotated data to implement the\nend-to-end supervised learning procedure. Even if we annotate enough data, MRI\nimages display considerable variability due to factors such as differences in\npatients, MRI scanners, and imaging protocols. This variability necessitates\nretraining neural networks for each specific application domain, which, in\nturn, requires manual annotation by expert radiologists for all new domains. To\nrelax the need for persistent data annotation, we develop a method for\nunsupervised federated domain adaptation using multiple annotated source\ndomains. Our approach enables the transfer of knowledge from several annotated\nsource domains to adapt a model for effective use in an unannotated target\ndomain. Initially, we ensure that the target domain data shares similar\nrepresentations with each source domain in a latent embedding space, modeled as\nthe output of a deep encoder, by minimizing the pair-wise distances of the\ndistributions for the target domain and the source domains. We then employ an\nensemble approach to leverage the knowledge obtained from all domains. We\nprovide theoretical analysis and perform experiments on the MICCAI 2016\nmulti-site dataset to demonstrate our method is effective.",
      "tldr_zh": "本文提出了一种无监督联邦域适应(Unsupervised Federated Domain Adaptation)方法，用于MRI图像的语义分割，旨在减少对大量标注数据的依赖，通过从多个标注源域转移知识适应无标注目标域。方法包括最小化目标域与源域在潜在嵌入空间中的分布成对距离，并采用集成方法整合多域知识，以实现模型的有效适应。实验结果在MICCAI 2016多站点数据集上验证了该方法的有效性，并提供了理论分析支持。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.02941v2",
      "published_date": "2024-01-02 00:31:41 UTC",
      "updated_date": "2024-01-14 01:12:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:26:13.591093"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 54,
  "processed_papers_count": 54,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-16T19:26:50.921500"
}