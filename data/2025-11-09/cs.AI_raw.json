[
  {
    "arxiv_id": "2511.06575v1",
    "title": "CoFineLLM: Conformal Finetuning of LLMs for Language-Instructed Robot Planning",
    "authors": [
      "Jun Wang",
      "Yevgeniy Vorobeychik",
      "Yiannis Kantaros"
    ],
    "abstract": "Large Language Models (LLMs) have recently emerged as planners for language-instructed agents, generating sequences of actions to accomplish natural language tasks. However, their reliability remains a challenge, especially in long-horizon tasks, since they often produce overconfident yet wrong outputs. Conformal Prediction (CP) has been leveraged to address this issue by wrapping LLM outputs into prediction sets that contain the correct action with a user-defined confidence. When the prediction set is a singleton, the planner executes that action; otherwise, it requests help from a user. This has led to LLM-based planners that can ensure plan correctness with a user-defined probability. However, as LLMs are trained in an uncertainty-agnostic manner, without awareness of prediction sets, they tend to produce unnecessarily large sets, particularly at higher confidence levels, resulting in frequent human interventions limiting autonomous deployment. To address this, we introduce CoFineLLM (Conformal Finetuning for LLMs), the first CP-aware finetuning framework for LLM-based planners that explicitly reduces prediction-set size and, in turn, the need for user interventions. We evaluate our approach on multiple language-instructed robot planning problems and show consistent improvements over uncertainty-aware and uncertainty-agnostic finetuning baselines in terms of prediction-set size, and help rates. Finally, we demonstrate robustness of our method to out-of-distribution scenarios in hardware experiments.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.06575v1",
    "published_date": "2025-11-09 23:38:25 UTC",
    "updated_date": "2025-11-09 23:38:25 UTC"
  },
  {
    "arxiv_id": "2511.06573v1",
    "title": "SteganoSNN: SNN-Based Audio-in-Image Steganography with Encryption",
    "authors": [
      "Biswajit Kumar Sahoo",
      "Pedro Machado",
      "Isibor Kennedy Ihianle",
      "Andreas Oikonomou",
      "Srinivas Boppu"
    ],
    "abstract": "Secure data hiding remains a fundamental challenge in digital communication, requiring a careful balance between computational efficiency and perceptual transparency. The balance between security and performance is increasingly fragile with the emergence of generative AI systems capable of autonomously generating and optimising sophisticated cryptanalysis and steganalysis algorithms, thereby accelerating the exposure of vulnerabilities in conventional data-hiding schemes.\n  This work introduces SteganoSNN, a neuromorphic steganographic framework that exploits spiking neural networks (SNNs) to achieve secure, low-power, and high-capacity multimedia data hiding. Digitised audio samples are converted into spike trains using leaky integrate-and-fire (LIF) neurons, encrypted via a modulo-based mapping scheme, and embedded into the least significant bits of RGBA image channels using a dithering mechanism to minimise perceptual distortion. Implemented in Python using NEST and realised on a PYNQ-Z2 FPGA, SteganoSNN attains real-time operation with an embedding capacity of 8 bits per pixel. Experimental evaluations on the DIV2K 2017 dataset demonstrate image fidelity between 40.4 dB and 41.35 dB in PSNR and SSIM values consistently above 0.97, surpassing SteganoGAN in computational efficiency and robustness. SteganoSNN establishes a foundation for neuromorphic steganography, enabling secure, energy-efficient communication for Edge-AI, IoT, and biomedical applications.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.06573v1",
    "published_date": "2025-11-09 23:31:53 UTC",
    "updated_date": "2025-11-09 23:31:53 UTC"
  },
  {
    "arxiv_id": "2511.06571v1",
    "title": "Rep2Text: Decoding Full Text from a Single LLM Token Representation",
    "authors": [
      "Haiyan Zhao",
      "Zirui He",
      "Fan Yang",
      "Ali Payani",
      "Mengnan Du"
    ],
    "abstract": "Large language models (LLMs) have achieved remarkable progress across diverse tasks, yet their internal mechanisms remain largely opaque. In this work, we address a fundamental question: to what extent can the original input text be recovered from a single last-token representation within an LLM? We propose Rep2Text, a novel framework for decoding full text from last-token representations. Rep2Text employs a trainable adapter that projects a target model's internal representations into the embedding space of a decoding language model, which then autoregressively reconstructs the input text. Experiments on various model combinations (Llama-3.1-8B, Gemma-7B, Mistral-7B-v0.1, Llama-3.2-3B) demonstrate that, on average, over half of the information in 16-token sequences can be recovered from this compressed representation while maintaining strong semantic integrity and coherence. Furthermore, our analysis reveals an information bottleneck effect: longer sequences exhibit decreased token-level recovery while preserving strong semantic integrity. Besides, our framework also demonstrates robust generalization to out-of-distribution medical data.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "15 pages, 7 figures, 4 tables",
    "pdf_url": "https://arxiv.org/pdf/2511.06571v1",
    "published_date": "2025-11-09 23:18:36 UTC",
    "updated_date": "2025-11-09 23:18:36 UTC"
  },
  {
    "arxiv_id": "2511.06568v2",
    "title": "Breaking the Dyadic Barrier: Rethinking Fairness in Link Prediction Beyond Demographic Parity",
    "authors": [
      "João Mattos",
      "Debolina Halder Lina",
      "Arlei Silva"
    ],
    "abstract": "Link prediction is a fundamental task in graph machine learning with applications, ranging from social recommendation to knowledge graph completion. Fairness in this setting is critical, as biased predictions can exacerbate societal inequalities. Prior work adopts a dyadic definition of fairness, enforcing fairness through demographic parity between intra-group and inter-group link predictions. However, we show that this dyadic framing can obscure underlying disparities across subgroups, allowing systemic biases to go undetected. Moreover, we argue that demographic parity does not meet desired properties for fairness assessment in ranking-based tasks such as link prediction. We formalize the limitations of existing fairness evaluations and propose a framework that enables a more expressive assessment. Additionally, we propose a lightweight post-processing method combined with decoupled link predictors that effectively mitigates bias and achieves state-of-the-art fairness-utility trade-offs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "12 pages, 5 figures. Accepted at AAAI-26 as an Oral",
    "pdf_url": "https://arxiv.org/pdf/2511.06568v2",
    "published_date": "2025-11-09 22:58:29 UTC",
    "updated_date": "2025-11-16 19:26:28 UTC"
  },
  {
    "arxiv_id": "2511.08633v1",
    "title": "Time-to-Move: Training-Free Motion Controlled Video Generation via Dual-Clock Denoising",
    "authors": [
      "Assaf Singer",
      "Noam Rotstein",
      "Amir Mann",
      "Ron Kimmel",
      "Or Litany"
    ],
    "abstract": "Diffusion-based video generation can create realistic videos, yet existing image- and text-based conditioning fails to offer precise motion control. Prior methods for motion-conditioned synthesis typically require model-specific fine-tuning, which is computationally expensive and restrictive. We introduce Time-to-Move (TTM), a training-free, plug-and-play framework for motion- and appearance-controlled video generation with image-to-video (I2V) diffusion models. Our key insight is to use crude reference animations obtained through user-friendly manipulations such as cut-and-drag or depth-based reprojection. Motivated by SDEdit's use of coarse layout cues for image editing, we treat the crude animations as coarse motion cues and adapt the mechanism to the video domain. We preserve appearance with image conditioning and introduce dual-clock denoising, a region-dependent strategy that enforces strong alignment in motion-specified regions while allowing flexibility elsewhere, balancing fidelity to user intent with natural dynamics. This lightweight modification of the sampling process incurs no additional training or runtime cost and is compatible with any backbone. Extensive experiments on object and camera motion benchmarks show that TTM matches or exceeds existing training-based baselines in realism and motion control. Beyond this, TTM introduces a unique capability: precise appearance control through pixel-level conditioning, exceeding the limits of text-only prompting. Visit our project page for video examples and code: https://time-to-move.github.io/.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR",
      "cs.LG",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.08633v1",
    "published_date": "2025-11-09 22:47:50 UTC",
    "updated_date": "2025-11-09 22:47:50 UTC"
  },
  {
    "arxiv_id": "2511.06552v1",
    "title": "LLM For Loop Invariant Generation and Fixing: How Far Are We?",
    "authors": [
      "Mostafijur Rahman Akhond",
      "Saikat Chakraborty",
      "Gias Uddin"
    ],
    "abstract": "A loop invariant is a property of a loop that remains true before and after each execution of the loop. The identification of loop invariants is a critical step to support automated program safety assessment. Recent advancements in Large Language Models (LLMs) have demonstrated potential in diverse software engineering (SE) and formal verification tasks. However, we are not aware of the performance of LLMs to infer loop invariants. We report an empirical study of both open-source and closed-source LLMs of varying sizes to assess their proficiency in inferring inductive loop invariants for programs and in fixing incorrect invariants. Our findings reveal that while LLMs exhibit some utility in inferring and repairing loop invariants, their performance is substantially enhanced when supplemented with auxiliary information such as domain knowledge and illustrative examples. LLMs achieve a maximum success rate of 78\\% in generating, but are limited to 16\\% in repairing the invariant.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "This work has been submitted to the IEEE for possible publication",
    "pdf_url": "https://arxiv.org/pdf/2511.06552v1",
    "published_date": "2025-11-09 21:47:45 UTC",
    "updated_date": "2025-11-09 21:47:45 UTC"
  },
  {
    "arxiv_id": "2511.07485v1",
    "title": "When Are Learning Biases Equivalent? A Unifying Framework for Fairness, Robustness, and Distribution Shift",
    "authors": [
      "Sushant Mehta"
    ],
    "abstract": "Machine learning systems exhibit diverse failure modes: unfairness toward protected groups, brittleness to spurious correlations, poor performance on minority sub-populations, which are typically studied in isolation by distinct research communities. We propose a unifying theoretical framework that characterizes when different bias mechanisms produce quantitatively equivalent effects on model performance. By formalizing biases as violations of conditional independence through information-theoretic measures, we prove formal equivalence conditions relating spurious correlations, subpopulation shift, class imbalance, and fairness violations. Our theory predicts that a spurious correlation of strength $α$ produces equivalent worst-group accuracy degradation as a sub-population imbalance ratio $r \\approx (1+α)/(1-α)$ under feature overlap assumptions. Empirical validation in six datasets and three architectures confirms that predicted equivalences hold within the accuracy of the worst group 3\\%, enabling the principled transfer of debiasing methods across problem domains. This work bridges the literature on fairness, robustness, and distribution shifts under a common perspective.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.07485v1",
    "published_date": "2025-11-09 20:48:09 UTC",
    "updated_date": "2025-11-09 20:48:09 UTC"
  },
  {
    "arxiv_id": "2511.06531v1",
    "title": "Ibom NLP: A Step Toward Inclusive Natural Language Processing for Nigeria's Minority Languages",
    "authors": [
      "Oluwadara Kalejaiye",
      "Luel Hagos Beyene",
      "David Ifeoluwa Adelani",
      "Mmekut-Mfon Gabriel Edet",
      "Aniefon Daniel Akpan",
      "Eno-Abasi Urua",
      "Anietie Andy"
    ],
    "abstract": "Nigeria is the most populous country in Africa with a population of more than 200 million people. More than 500 languages are spoken in Nigeria and it is one of the most linguistically diverse countries in the world. Despite this, natural language processing (NLP) research has mostly focused on the following four languages: Hausa, Igbo, Nigerian-Pidgin, and Yoruba (i.e <1% of the languages spoken in Nigeria). This is in part due to the unavailability of textual data in these languages to train and apply NLP algorithms. In this work, we introduce ibom -- a dataset for machine translation and topic classification in four Coastal Nigerian languages from the Akwa Ibom State region: Anaang, Efik, Ibibio, and Oro. These languages are not represented in Google Translate or in major benchmarks such as Flores-200 or SIB-200. We focus on extending Flores-200 benchmark to these languages, and further align the translated texts with topic labels based on SIB-200 classification dataset. Our evaluation shows that current LLMs perform poorly on machine translation for these languages in both zero-and-few shot settings. However, we find the few-shot samples to steadily improve topic classification with more shots.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at IJCNLP-AACL",
    "pdf_url": "https://arxiv.org/pdf/2511.06531v1",
    "published_date": "2025-11-09 20:33:39 UTC",
    "updated_date": "2025-11-09 20:33:39 UTC"
  },
  {
    "arxiv_id": "2511.06529v1",
    "title": "TriShGAN: Enhancing Sparsity and Robustness in Multivariate Time Series Counterfactuals Explanation",
    "authors": [
      "Hongnan Ma",
      "Yiwei Shi",
      "Guanxiong Sun",
      "Mengyue Yang",
      "Weiru Liu"
    ],
    "abstract": "In decision-making processes, stakeholders often rely on counterfactual explanations, which provide suggestions about what should be changed in the queried instance to alter the outcome of an AI system. However, generating these explanations for multivariate time series presents challenges due to their complex, multi-dimensional nature. Traditional Nearest Unlike Neighbor-based methods typically substitute subsequences in a queried time series with influential subsequences from an NUN, which is not always realistic in real-world scenarios due to the rigid direct substitution. Counterfactual with Residual Generative Adversarial Networks-based methods aim to address this by learning from the distribution of observed data to generate synthetic counterfactual explanations. However, these methods primarily focus on minimizing the cost from the queried time series to the counterfactual explanations and often neglect the importance of distancing the counterfactual explanation from the decision boundary. This oversight can result in explanations that no longer qualify as counterfactual if minor changes occur within the model. To generate a more robust counterfactual explanation, we introduce TriShGAN, under the CounteRGAN framework enhanced by the incorporation of triplet loss. This unsupervised learning approach uses distance metric learning to encourage the counterfactual explanations not only to remain close to the queried time series but also to capture the feature distribution of the instance with the desired outcome, thereby achieving a better balance between minimal cost and robustness. Additionally, we integrate a Shapelet Extractor that strategically selects the most discriminative parts of the high-dimensional queried time series to enhance the sparsity of counterfactual explanation and efficiency of the training process.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.06529v1",
    "published_date": "2025-11-09 20:32:20 UTC",
    "updated_date": "2025-11-09 20:32:20 UTC"
  },
  {
    "arxiv_id": "2511.06522v1",
    "title": "FractalBench: Diagnosing Visual-Mathematical Reasoning Through Recursive Program Synthesis",
    "authors": [
      "Jan Ondras",
      "Marek Šuppa"
    ],
    "abstract": "Mathematical reasoning requires abstracting symbolic rules from visual patterns -- inferring the infinite from the finite. We investigate whether multimodal AI systems possess this capability through FractalBench, a benchmark evaluating fractal program synthesis from images. Fractals provide ideal test cases: Iterated Function Systems with only a few contraction maps generate complex self-similar patterns through simple recursive rules, requiring models to bridge visual perception with mathematical abstraction. We evaluate four leading MLLMs -- GPT-4o, Claude 3.7 Sonnet, Gemini 2.5 Flash, and Qwen 2.5-VL -- on 12 canonical fractals. Models must generate executable Python code reproducing the fractal, enabling objective evaluation. Results reveal a striking disconnect: 76% generate syntactically valid code but only 4% capture mathematical structure. Success varies systematically -- models handle geometric transformations (Koch curves: 17-21%) but fail at branching recursion (trees: <2%), revealing fundamental gaps in mathematical abstraction. FractalBench provides a contamination-resistant diagnostic for visual-mathematical reasoning and is available at https://github.com/NaiveNeuron/FractalBench",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted to The 5th Workshop on Mathematical Reasoning and AI at the 39th Conference on Neural Information Processing Systems (NeurIPS 2025); 25 pages, 14 figures, 8 tables; Code available at https://github.com/NaiveNeuron/FractalBench",
    "pdf_url": "https://arxiv.org/pdf/2511.06522v1",
    "published_date": "2025-11-09 20:22:42 UTC",
    "updated_date": "2025-11-09 20:22:42 UTC"
  },
  {
    "arxiv_id": "2511.06519v1",
    "title": "On the Analogy between Human Brain and LLMs: Spotting Key Neurons in Grammar Perception",
    "authors": [
      "Sanaz Saki Norouzi",
      "Mohammad Masjedi",
      "Pascal Hitzler"
    ],
    "abstract": "Artificial Neural Networks, the building blocks of AI, were inspired by the human brain's network of neurons. Over the years, these networks have evolved to replicate the complex capabilities of the brain, allowing them to handle tasks such as image and language processing. In the realm of Large Language Models, there has been a keen interest in making the language learning process more akin to that of humans. While neuroscientific research has shown that different grammatical categories are processed by different neurons in the brain, we show that LLMs operate in a similar way. Utilizing Llama 3, we identify the most important neurons associated with the prediction of words belonging to different part-of-speech tags. Using the achieved knowledge, we train a classifier on a dataset, which shows that the activation patterns of these key neurons can reliably predict part-of-speech tags on fresh data. The results suggest the presence of a subspace in LLMs focused on capturing part-of-speech tag concepts, resembling patterns observed in lesion studies of the brain in neuroscience.",
    "categories": [
      "q-bio.NC",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "q-bio.NC",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.06519v1",
    "published_date": "2025-11-09 20:08:21 UTC",
    "updated_date": "2025-11-09 20:08:21 UTC"
  },
  {
    "arxiv_id": "2511.17543v1",
    "title": "Evo* 2025 -- Late-Breaking Abstracts Volume",
    "authors": [
      "A. M. Mora",
      "A. I. Esparcia-Alcázar",
      "M. S. Cruz"
    ],
    "abstract": "Volume containing the Late-Breaking Abstracts submitted to the Evo* 2025 Conference, held in Trieste (Italy) from April 23rd to 25th. These extended abstracts showcase ongoing research and preliminary findings exploring the application of various Bioinspired Methods (primarily Evolutionary Computation) to a range of problems, many of which address real-world scenarios.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "LBAs accepted in Evo* 2025. Part of the Conference Proceedings",
    "pdf_url": "https://arxiv.org/pdf/2511.17543v1",
    "published_date": "2025-11-09 19:16:04 UTC",
    "updated_date": "2025-11-09 19:16:04 UTC"
  },
  {
    "arxiv_id": "2511.06497v1",
    "title": "Rethinking what Matters: Effective and Robust Multilingual Realignment for Low-Resource Languages",
    "authors": [
      "Quang Phuoc Nguyen",
      "David Anugraha",
      "Felix Gaschi",
      "Jun Bin Cheng",
      "En-Shiun Annie Lee"
    ],
    "abstract": "Realignment is a promising strategy to improve cross-lingual transfer in multilingual language models. However, empirical results are mixed and often unreliable, particularly for typologically distant or low-resource languages (LRLs) compared to English. Moreover, word realignment tools often rely on high-quality parallel data, which can be scarce or noisy for many LRLs. In this work, we conduct an extensive empirical study to investigate whether realignment truly benefits from using all available languages, or if strategically selected subsets can offer comparable or even improved cross-lingual transfer, and study the impact on LRLs. Our controlled experiments show that realignment can be particularly effective for LRLs and that using carefully selected, linguistically diverse subsets can match full multilingual alignment, and even outperform it for unseen LRLs. This indicates that effective realignment does not require exhaustive language coverage and can reduce data collection overhead, while remaining both efficient and robust when guided by informed language selection.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to IJCNLP-AACL 2025",
    "pdf_url": "https://arxiv.org/pdf/2511.06497v1",
    "published_date": "2025-11-09 18:54:17 UTC",
    "updated_date": "2025-11-09 18:54:17 UTC"
  },
  {
    "arxiv_id": "2511.06496v1",
    "title": "A Low-Rank Method for Vision Language Model Hallucination Mitigation in Autonomous Driving",
    "authors": [
      "Keke Long",
      "Jiacheng Guo",
      "Tianyun Zhang",
      "Hongkai Yu",
      "Xiaopeng Li"
    ],
    "abstract": "Vision Language Models (VLMs) are increasingly used in autonomous driving to help understand traffic scenes, but they sometimes produce hallucinations, which are false details not grounded in the visual input. Detecting and mitigating hallucinations is challenging when ground-truth references are unavailable and model internals are inaccessible. This paper proposes a novel self-contained low-rank approach to automatically rank multiple candidate captions generated by multiple VLMs based on their hallucination levels, using only the captions themselves without requiring external references or model access. By constructing a sentence-embedding matrix and decomposing it into a low-rank consensus component and a sparse residual, we use the residual magnitude to rank captions: selecting the one with the smallest residual as the most hallucination-free. Experiments on the NuScenes dataset demonstrate that our approach achieves 87% selection accuracy in identifying hallucination-free captions, representing a 19% improvement over the unfiltered baseline and a 6-10% improvement over multi-agent debate method. The sorting produced by sparse error magnitudes shows strong correlation with human judgments of hallucinations, validating our scoring mechanism. Additionally, our method, which can be easily parallelized, reduces inference time by 51-67% compared to debate approaches, making it practical for real-time autonomous driving applications.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.06496v1",
    "published_date": "2025-11-09 18:50:30 UTC",
    "updated_date": "2025-11-09 18:50:30 UTC"
  },
  {
    "arxiv_id": "2511.06494v1",
    "title": "Route Experts by Sequence, not by Token",
    "authors": [
      "Tiansheng Wen",
      "Yifei Wang",
      "Aosong Feng",
      "Long Ma",
      "Xinyang Liu",
      "Yifan Wang",
      "Lixuan Guo",
      "Bo Chen",
      "Stefanie Jegelka",
      "Chenyu You"
    ],
    "abstract": "Mixture-of-Experts (MoE) architectures scale large language models (LLMs) by activating only a subset of experts per token, but the standard TopK routing assigns the same fixed number of experts to all tokens, ignoring their varying complexity. Prior adaptive routing methods introduce additional modules and hyperparameters, often requiring costly retraining from scratch. We propose Sequence-level TopK (SeqTopK), a minimal modification that shifts the expert budget from the token level to the sequence level. By selecting the top $T \\cdot K$ experts across all $T$ tokens, SeqTopK enables end-to-end learned dynamic allocation -- assigning more experts to difficult tokens and fewer to easy ones -- while preserving the same overall budget. SeqTopK requires only a few lines of code, adds less than 1% overhead, and remains fully compatible with pretrained MoE models. Experiments across math, coding, law, and writing show consistent improvements over TopK and prior parameter-free adaptive methods, with gains that become substantially larger under higher sparsity (up to 16.9%). These results highlight SeqTopK as a simple, efficient, and scalable routing strategy, particularly well-suited for the extreme sparsity regimes of next-generation LLMs. Code is available at https://github.com/Y-Research-SBU/SeqTopK.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IT"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.06494v1",
    "published_date": "2025-11-09 18:36:07 UTC",
    "updated_date": "2025-11-09 18:36:07 UTC"
  },
  {
    "arxiv_id": "2511.06492v1",
    "title": "Explainable AI For Early Detection Of Sepsis",
    "authors": [
      "Atharva Thakur",
      "Shruti Dhumal"
    ],
    "abstract": "Sepsis is a life-threatening condition that requires rapid detection and treatment to prevent progression to severe sepsis, septic shock, or multi-organ failure. Despite advances in medical technology, it remains a major challenge for clinicians. While recent machine learning models have shown promise in predicting sepsis onset, their black-box nature limits interpretability and clinical trust. In this study, we present an interpretable AI approach for sepsis analysis that integrates machine learning with clinical knowledge. Our method not only delivers accurate predictions of sepsis onset but also enables clinicians to understand, validate, and align model outputs with established medical expertise.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.06492v1",
    "published_date": "2025-11-09 18:33:06 UTC",
    "updated_date": "2025-11-09 18:33:06 UTC"
  },
  {
    "arxiv_id": "2511.06490v1",
    "title": "Zooming into Comics: Region-Aware RL Improves Fine-Grained Comic Understanding in Vision-Language Models",
    "authors": [
      "Yule Chen",
      "Yufan Ren",
      "Sabine Süsstrunk"
    ],
    "abstract": "Complex visual narratives, such as comics, present a significant challenge to Vision-Language Models (VLMs). Despite excelling on natural images, VLMs often struggle with stylized line art, onomatopoeia, and densely packed multi-panel layouts. To address this gap, we introduce AI4VA-FG, the first fine-grained and comprehensive benchmark for VLM-based comic understanding. It spans tasks from foundational recognition and detection to high-level character reasoning and narrative construction, supported by dense annotations for characters, poses, and depth. Beyond that, we evaluate state-of-the-art proprietary models, including GPT-4o and Gemini-2.5, and open-source models such as Qwen2.5-VL, revealing substantial performance deficits across core tasks of our benchmarks and underscoring that comic understanding remains an unsolved challenge. To enhance VLMs' capabilities in this domain, we systematically investigate post-training strategies, including supervised fine-tuning on solutions (SFT-S), supervised fine-tuning on reasoning trajectories (SFT-R), and reinforcement learning (RL). Beyond that, inspired by the emerging \"Thinking with Images\" paradigm, we propose Region-Aware Reinforcement Learning (RARL) for VLMs, which trains models to dynamically attend to relevant regions through zoom-in operations. We observe that when applied to the Qwen2.5-VL model, RL and RARL yield significant gains in low-level entity recognition and high-level storyline ordering, paving the way for more accurate and efficient VLM applications in the comics domain.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.06490v1",
    "published_date": "2025-11-09 18:27:45 UTC",
    "updated_date": "2025-11-09 18:27:45 UTC"
  },
  {
    "arxiv_id": "2511.07483v1",
    "title": "Beyond Correctness: Confidence-Aware Reward Modeling for Enhancing Large Language Model Reasoning",
    "authors": [
      "Qianxi He",
      "Qingyu Ren",
      "Shanzhe Lei",
      "Xuhong Wang",
      "Yingchun Wang"
    ],
    "abstract": "Recent advancements in large language models (LLMs) have shifted the post-training paradigm from traditional instruction tuning and human preference alignment toward reinforcement learning (RL) focused on reasoning capabilities. However, numerous technical reports indicate that purely rule-based reward RL frequently results in poor-quality reasoning chains or inconsistencies between reasoning processes and final answers, particularly when the base model is of smaller scale. During the RL exploration process, models might employ low-quality reasoning chains due to the lack of knowledge, occasionally producing correct answers randomly and receiving rewards based on established rule-based judges. This constrains the potential for resource-limited organizations to conduct direct reinforcement learning training on smaller-scale models. We propose a novel confidence-based reward model tailored for enhancing STEM reasoning capabilities. Unlike conventional approaches, our model penalizes not only incorrect answers but also low-confidence correct responses, thereby promoting more robust and logically consistent reasoning. We validate the effectiveness of our approach through static evaluations, Best-of-N inference tests, and PPO-based RL training. Our method outperforms several state-of-the-art open-source reward models across diverse STEM benchmarks. We release our codes and model in https://github.com/qianxiHe147/C2RM.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.07483v1",
    "published_date": "2025-11-09 17:58:40 UTC",
    "updated_date": "2025-11-09 17:58:40 UTC"
  },
  {
    "arxiv_id": "2511.06471v2",
    "title": "GHOST: Solving the Traveling Salesman Problem on Graphs of Convex Sets",
    "authors": [
      "Jingtao Tang",
      "Hang Ma"
    ],
    "abstract": "We study GCS-TSP, a new variant of the Traveling Salesman Problem (TSP) defined over a Graph of Convex Sets (GCS) -- a powerful representation for trajectory planning that decomposes the configuration space into convex regions connected by a sparse graph. In this setting, edge costs are not fixed but depend on the specific trajectory selected through each convex region, making classical TSP methods inapplicable. We introduce GHOST, a hierarchical framework that optimally solves the GCS-TSP by combining combinatorial tour search with convex trajectory optimization. GHOST systematically explores tours on a complete graph induced by the GCS, using a novel abstract-path-unfolding algorithm to compute admissible lower bounds that guide best-first search at both the high level (over tours) and the low level (over feasible GCS paths realizing the tour). These bounds provide strong pruning power, enabling efficient search while avoiding unnecessary convex optimization calls. We prove that GHOST guarantees optimality and present a bounded-suboptimal variant for time-critical scenarios. Experiments show that GHOST is orders-of-magnitude faster than unified mixed-integer convex programming baselines for simple cases and uniquely handles complex trajectory planning problems involving high-order continuity constraints and an incomplete GCS.",
    "categories": [
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted to AAAI-2026",
    "pdf_url": "https://arxiv.org/pdf/2511.06471v2",
    "published_date": "2025-11-09 17:34:15 UTC",
    "updated_date": "2025-11-13 02:45:47 UTC"
  },
  {
    "arxiv_id": "2511.06470v1",
    "title": "Brain-Inspired Planning for Better Generalization in Reinforcement Learning",
    "authors": [
      "Mingde \"Harry\" Zhao"
    ],
    "abstract": "Existing Reinforcement Learning (RL) systems encounter significant challenges when applied to real-world scenarios, primarily due to poor generalization across environments that differ from their training conditions. This thesis explores the direction of enhancing agents' zero-shot systematic generalization abilities by granting RL agents reasoning behaviors that are found to help systematic generalization in the human brain. Inspired by human conscious planning behaviors, we first introduced a top-down attention mechanism, which allows a decision-time planning agent to dynamically focus its reasoning on the most relevant aspects of the environmental state given its instantaneous intentions, a process we call \"spatial abstraction\". This approach significantly improves systematic generalization outside the training tasks. Subsequently, building on spatial abstraction, we developed the Skipper framework to automatically decompose complex tasks into simpler, more manageable sub-tasks. Skipper provides robustness against distributional shifts and efficacy in long-term, compositional planning by focusing on pertinent spatial and temporal elements of the environment. Finally, we identified a common failure mode and safety risk in planning agents that rely on generative models to generate state targets during planning. It is revealed that most agents blindly trust the targets they hallucinate, resulting in delusional planning behaviors. Inspired by how the human brain rejects delusional intentions, we propose learning a feasibility evaluator to enable rejecting hallucinated infeasible targets, which led to significant performance improvements in various kinds of planning agents. Finally, we suggest directions for future research, aimed at achieving general task abstraction and fully enabling abstract planning.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "McGill PhD Thesis (updated on 20251109 for typos and margin adjustments)",
    "pdf_url": "https://arxiv.org/pdf/2511.06470v1",
    "published_date": "2025-11-09 17:32:55 UTC",
    "updated_date": "2025-11-09 17:32:55 UTC"
  },
  {
    "arxiv_id": "2511.06458v1",
    "title": "EchoMark: Perceptual Acoustic Environment Transfer with Watermark-Embedded Room Impulse Response",
    "authors": [
      "Chenpei Huang",
      "Lingfeng Yao",
      "Kyu In Lee",
      "Lan Emily Zhang",
      "Xun Chen",
      "Miao Pan"
    ],
    "abstract": "Acoustic Environment Matching (AEM) is the task of transferring clean audio into a target acoustic environment, enabling engaging applications such as audio dubbing and auditory immersive virtual reality (VR). Recovering similar room impulse response (RIR) directly from reverberant speech offers more accessible and flexible AEM solution. However, this capability also introduces vulnerabilities of arbitrary ``relocation\" if misused by malicious user, such as facilitating advanced voice spoofing attacks or undermining the authenticity of recorded evidence. To address this issue, we propose EchoMark, the first deep learning-based AEM framework that generates perceptually similar RIRs with embedded watermark. Our design tackle the challenges posed by variable RIR characteristics, such as different durations and energy decays, by operating in the latent domain. By jointly optimizing the model with a perceptual loss for RIR reconstruction and a loss for watermark detection, EchoMark achieves both high-quality environment transfer and reliable watermark recovery. Experiments on diverse datasets validate that EchoMark achieves room acoustic parameter matching performance comparable to FiNS, the state-of-the-art RIR estimator. Furthermore, a high Mean Opinion Score (MOS) of 4.22 out of 5, watermark detection accuracy exceeding 99\\%, and bit error rates (BER) below 0.3\\% collectively demonstrate the effectiveness of EchoMark in preserving perceptual quality while ensuring reliable watermark embedding.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.06458v1",
    "published_date": "2025-11-09 16:53:32 UTC",
    "updated_date": "2025-11-09 16:53:32 UTC"
  },
  {
    "arxiv_id": "2511.07482v1",
    "title": "Alignment-Constrained Dynamic Pruning for LLMs: Identifying and Preserving Alignment-Critical Circuits",
    "authors": [
      "Dev Patel",
      "Gabrielle Gervacio",
      "Diekola Raimi",
      "Kevin Zhu",
      "Ryan Lagasse",
      "Gabriel Grand",
      "Ashwinee Panda",
      "Maheep Chaudhary"
    ],
    "abstract": "Large Language Models require substantial computational resources for inference, posing deployment challenges. While dynamic pruning offers superior efficiency over static methods through adaptive circuit selection, it exacerbates alignment degradation by retaining only input-dependent safety-critical circuit preservation across diverse inputs. As a result, addressing these heightened alignment vulnerabilities remains critical. We introduce Alignment-Aware Probe Pruning (AAPP), a dynamic structured pruning method that adaptively preserves alignment-relevant circuits during inference, building upon Probe Pruning. Experiments on LLaMA 2-7B, Qwen2.5-14B-Instruct, and Gemma-3-12B-IT show AAPP improves refusal rates by 50\\% at matched compute, enabling efficient yet safety-preserving LLM deployment.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.07482v1",
    "published_date": "2025-11-09 16:51:45 UTC",
    "updated_date": "2025-11-09 16:51:45 UTC"
  },
  {
    "arxiv_id": "2511.06455v1",
    "title": "A Multi-Agent System for Semantic Mapping of Relational Data to Knowledge Graphs",
    "authors": [
      "Milena Trajanoska",
      "Riste Stojanov",
      "Dimitar Trajanov"
    ],
    "abstract": "Enterprises often maintain multiple databases for storing critical business data in siloed systems, resulting in inefficiencies and challenges with data interoperability. A key to overcoming these challenges lies in integrating disparate data sources, enabling businesses to unlock the full potential of their data. Our work presents a novel approach for integrating multiple databases using knowledge graphs, focusing on the application of large language models as semantic agents for mapping and connecting structured data across systems by leveraging existing vocabularies. The proposed methodology introduces a semantic layer above tables in relational databases, utilizing a system comprising multiple LLM agents that map tables and columns to Schema.org terms. Our approach achieves a mapping accuracy of over 90% in multiple domains.",
    "categories": [
      "cs.DB",
      "cs.AI"
    ],
    "primary_category": "cs.DB",
    "comment": "The 1st GOBLIN Workshop on Knowledge Graph Technologies https://www.dbpedia.org/events/goblin25-workshop/",
    "pdf_url": "https://arxiv.org/pdf/2511.06455v1",
    "published_date": "2025-11-09 16:41:46 UTC",
    "updated_date": "2025-11-09 16:41:46 UTC"
  },
  {
    "arxiv_id": "2511.06449v2",
    "title": "FLEX: Continuous Agent Evolution via Forward Learning from Experience",
    "authors": [
      "Zhicheng Cai",
      "Xinyuan Guo",
      "Yu Pei",
      "Jiangtao Feng",
      "Jinsong Su",
      "Jiangjie Chen",
      "Ya-Qin Zhang",
      "Wei-Ying Ma",
      "Mingxuan Wang",
      "Hao Zhou"
    ],
    "abstract": "Autonomous agents driven by Large Language Models (LLMs) have revolutionized reasoning and problem-solving but remain static after training, unable to grow with experience as intelligent beings do during deployment. We introduce Forward Learning with EXperience (FLEX), a gradient-free learning paradigm that enables LLM agents to continuously evolve through accumulated experience. Specifically, FLEX cultivates scalable and inheritable evolution by constructing a structured experience library through continual reflection on successes and failures during interaction with the environment. FLEX delivers substantial improvements on mathematical reasoning, chemical retrosynthesis, and protein fitness prediction (up to 23% on AIME25, 10% on USPTO50k, and 14% on ProteinGym). We further identify a clear scaling law of experiential growth and the phenomenon of experience inheritance across agents, marking a step toward scalable and inheritable continuous agent evolution. Project Page: https://flex-gensi-thuair.github.io.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.06449v2",
    "published_date": "2025-11-09 16:31:39 UTC",
    "updated_date": "2025-12-08 02:42:09 UTC"
  },
  {
    "arxiv_id": "2511.06448v1",
    "title": "When AI Agents Collude Online: Financial Fraud Risks by Collaborative LLM Agents on Social Platforms",
    "authors": [
      "Qibing Ren",
      "Zhijie Zheng",
      "Jiaxuan Guo",
      "Junchi Yan",
      "Lizhuang Ma",
      "Jing Shao"
    ],
    "abstract": "In this work, we study the risks of collective financial fraud in large-scale multi-agent systems powered by large language model (LLM) agents. We investigate whether agents can collaborate in fraudulent behaviors, how such collaboration amplifies risks, and what factors influence fraud success. To support this research, we present MultiAgentFraudBench, a large-scale benchmark for simulating financial fraud scenarios based on realistic online interactions. The benchmark covers 28 typical online fraud scenarios, spanning the full fraud lifecycle across both public and private domains. We further analyze key factors affecting fraud success, including interaction depth, activity level, and fine-grained collaboration failure modes. Finally, we propose a series of mitigation strategies, including adding content-level warnings to fraudulent posts and dialogues, using LLMs as monitors to block potentially malicious agents, and fostering group resilience through information sharing at the societal level. Notably, we observe that malicious agents can adapt to environmental interventions. Our findings highlight the real-world risks of multi-agent financial fraud and suggest practical measures for mitigating them. Code is available at https://github.com/zheng977/MutiAgent4Fraud.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.CL",
      "cs.SI"
    ],
    "primary_category": "cs.MA",
    "comment": "Code is available at https://github.com/zheng977/MutiAgent4Fraud",
    "pdf_url": "https://arxiv.org/pdf/2511.06448v1",
    "published_date": "2025-11-09 16:30:44 UTC",
    "updated_date": "2025-11-09 16:30:44 UTC"
  },
  {
    "arxiv_id": "2511.06447v1",
    "title": "Personality over Precision: Exploring the Influence of Human-Likeness on ChatGPT Use for Search",
    "authors": [
      "Mert Yazan",
      "Frederik Bungaran Ishak Situmeang",
      "Suzan Verberne"
    ],
    "abstract": "Conversational search interfaces, like ChatGPT, offer an interactive, personalized, and engaging user experience compared to traditional search. On the downside, they are prone to cause overtrust issues where users rely on their responses even when they are incorrect. What aspects of the conversational interaction paradigm drive people to adopt it, and how it creates personalized experiences that lead to overtrust, is not clear. To understand the factors influencing the adoption of conversational interfaces, we conducted a survey with 173 participants. We examined user perceptions regarding trust, human-likeness (anthropomorphism), and design preferences between ChatGPT and Google. To better understand the overtrust phenomenon, we asked users about their willingness to trade off factuality for constructs like ease of use or human-likeness. Our analysis identified two distinct user groups: those who use both ChatGPT and Google daily (DUB), and those who primarily rely on Google (DUG). The DUB group exhibited higher trust in ChatGPT, perceiving it as more human-like, and expressed greater willingness to trade factual accuracy for enhanced personalization and conversational flow. Conversely, the DUG group showed lower trust toward ChatGPT but still appreciated aspects like ad-free experiences and responsive interactions. Demographic analysis further revealed nuanced patterns, with middle-aged adults using ChatGPT less frequently yet trusting it more, suggesting potential vulnerability to misinformation. Our findings contribute to understanding user segmentation, emphasizing the critical roles of personalization and human-likeness in conversational IR systems, and reveal important implications regarding users' willingness to compromise factual accuracy for more engaging interactions.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "Accepted at NIP-IR@SIGIR'25",
    "pdf_url": "https://arxiv.org/pdf/2511.06447v1",
    "published_date": "2025-11-09 16:28:55 UTC",
    "updated_date": "2025-11-09 16:28:55 UTC"
  },
  {
    "arxiv_id": "2511.06446v1",
    "title": "SR-KI: Scalable and Real-Time Knowledge Integration into LLMs via Supervised Attention",
    "authors": [
      "Bohan Yu",
      "Wei Huang",
      "Kang Liu"
    ],
    "abstract": "This paper proposes SR-KI, a novel approach for integrating real-time and large-scale structured knowledge bases (KBs) into large language models (LLMs). SR-KI begins by encoding KBs into key-value pairs using a pretrained encoder, and injects them into LLMs' KV cache. Building on this representation, we employ a two-stage training paradigm: first locating a dedicated retrieval layer within the LLM, and then applying an attention-based loss at this layer to explicitly supervise attention toward relevant KB entries. Unlike traditional retrieval-augmented generation methods that rely heavily on the performance of external retrievers and multi-stage pipelines, SR-KI supports end-to-end inference by performing retrieval entirely within the models latent space. This design enables efficient compression of injected knowledge and facilitates dynamic knowledge updates. Comprehensive experiments demonstrate that SR-KI enables the integration of up to 40K KBs into a 7B LLM on a single A100 40GB GPU, and achieves strong retrieval performance, maintaining over 98% Recall@10 on the best-performing task and exceeding 88% on average across all tasks. Task performance on question answering and KB ID generation also demonstrates that SR-KI maintains strong performance while achieving up to 99.75% compression of the injected KBs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by AAAI 2026",
    "pdf_url": "https://arxiv.org/pdf/2511.06446v1",
    "published_date": "2025-11-09 16:27:55 UTC",
    "updated_date": "2025-11-09 16:27:55 UTC"
  },
  {
    "arxiv_id": "2511.06437v1",
    "title": "Optimizing Chain-of-Thought Confidence via Topological and Dirichlet Risk Analysis",
    "authors": [
      "Abhishek More",
      "Anthony Zhang",
      "Nicole Bonilla",
      "Ashvik Vivekan",
      "Kevin Zhu",
      "Parham Sharafoleslami",
      "Maheep Chaudhary"
    ],
    "abstract": "Chain-of-thought (CoT) prompting enables Large Language Models to solve complex problems, but deploying these models safely requires reliable confidence estimates, a capability where existing methods suffer from poor calibration and severe overconfidence on incorrect predictions. We propose Enhanced Dirichlet and Topology Risk (EDTR), a novel decoding strategy that combines topological analysis with Dirichlet-based uncertainty quantification to measure LLM confidence across multiple reasoning paths. EDTR treats each CoT as a vector in high-dimensional space and extracts eight topological risk features capturing the geometric structure of reasoning distributions: tighter, more coherent clusters indicate higher confidence while dispersed, inconsistent paths signal uncertainty. We evaluate EDTR against three state-of-the-art calibration methods across four diverse reasoning benchmarks spanning olympiad-level mathematics (AIME), grade school math (GSM8K), commonsense reasoning, and stock price prediction \\cite{zhang2025aime, cobbe2021training, talmor-etal-2019-commonsenseqa, yahoo_finance}. EDTR achieves 41\\% better calibration than competing methods with an average ECE of 0.287 and the best overall composite score of 0.672, while notably achieving perfect accuracy on AIME and exceptional calibration on GSM8K with an ECE of 0.107, domains where baselines exhibit severe overconfidence. Our work provides a geometric framework for understanding and quantifying uncertainty in multi-step LLM reasoning, enabling more reliable deployment where calibrated confidence estimates are essential.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.06437v1",
    "published_date": "2025-11-09 16:09:02 UTC",
    "updated_date": "2025-11-09 16:09:02 UTC"
  },
  {
    "arxiv_id": "2511.06428v1",
    "title": "Walking the Tightrope of LLMs for Software Development: A Practitioners' Perspective",
    "authors": [
      "Samuel Ferino",
      "Rashina Hoda",
      "John Grundy",
      "Christoph Treude"
    ],
    "abstract": "Background: Large Language Models emerged with the potential of provoking a revolution in software development (e.g., automating processes, workforce transformation). Although studies have started to investigate the perceived impact of LLMs for software development, there is a need for empirical studies to comprehend how to balance forward and backward effects of using LLMs. Objective: We investigated how LLMs impact software development and how to manage the impact from a software developer's perspective. Method: We conducted 22 interviews with software practitioners across 3 rounds of data collection and analysis, between October (2024) and September (2025). We employed socio-technical grounded theory (STGT) for data analysis to rigorously analyse interview participants' responses. Results: We identified the benefits (e.g., maintain software development flow, improve developers' mental model, and foster entrepreneurship) and disadvantages (e.g., negative impact on developers' personality and damage to developers' reputation) of using LLMs at individual, team, organisation, and society levels; as well as best practices on how to adopt LLMs. Conclusion: Critically, we present the trade-offs that software practitioners, teams, and organisations face in working with LLMs. Our findings are particularly useful for software team leaders and IT managers to assess the viability of LLMs within their specific context.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.06428v1",
    "published_date": "2025-11-09 15:49:55 UTC",
    "updated_date": "2025-11-09 15:49:55 UTC"
  },
  {
    "arxiv_id": "2511.06424v1",
    "title": "Turbo-DDCM: Fast and Flexible Zero-Shot Diffusion-Based Image Compression",
    "authors": [
      "Amit Vaisman",
      "Guy Ohayon",
      "Hila Manor",
      "Michael Elad",
      "Tomer Michaeli"
    ],
    "abstract": "While zero-shot diffusion-based compression methods have seen significant progress in recent years, they remain notoriously slow and computationally demanding. This paper presents an efficient zero-shot diffusion-based compression method that runs substantially faster than existing methods, while maintaining performance that is on par with the state-of-the-art techniques. Our method builds upon the recently proposed Denoising Diffusion Codebook Models (DDCMs) compression scheme. Specifically, DDCM compresses an image by sequentially choosing the diffusion noise vectors from reproducible random codebooks, guiding the denoiser's output to reconstruct the target image. We modify this framework with Turbo-DDCM, which efficiently combines a large number of noise vectors at each denoising step, thereby significantly reducing the number of required denoising operations. This modification is also coupled with an improved encoding protocol. Furthermore, we introduce two flexible variants of Turbo-DDCM, a priority-aware variant that prioritizes user-specified regions and a distortion-controlled variant that compresses an image based on a target PSNR rather than a target BPP. Comprehensive experiments position Turbo-DDCM as a compelling, practical, and flexible image compression scheme.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "eess.SP",
      "stat.ML"
    ],
    "primary_category": "eess.IV",
    "comment": "Code is available at https://amitvaisman.github.io/turbo_ddcm/",
    "pdf_url": "https://arxiv.org/pdf/2511.06424v1",
    "published_date": "2025-11-09 15:41:27 UTC",
    "updated_date": "2025-11-09 15:41:27 UTC"
  },
  {
    "arxiv_id": "2511.06419v1",
    "title": "MONICA: Real-Time Monitoring and Calibration of Chain-of-Thought Sycophancy in Large Reasoning Models",
    "authors": [
      "Jingyu Hu",
      "Shu Yang",
      "Xilin Gong",
      "Hongming Wang",
      "Weiru Liu",
      "Di Wang"
    ],
    "abstract": "Large Reasoning Models (LRMs) suffer from sycophantic behavior, where models tend to agree with users' incorrect beliefs and follow misinformation rather than maintain independent reasoning. This behavior undermines model reliability and poses societal risks. Mitigating LRM sycophancy requires monitoring how this sycophancy emerges during the reasoning trajectory; however, current methods mainly focus on judging based on final answers and correcting them, without understanding how sycophancy develops during reasoning processes. To address this limitation, we propose MONICA, a novel Monitor-guided Calibration framework that monitors and mitigates sycophancy during model inference at the level of reasoning steps, without requiring the model to finish generating its complete answer. MONICA integrates a sycophantic monitor that provides real-time monitoring of sycophantic drift scores during response generation with a calibrator that dynamically suppresses sycophantic behavior when scores exceed predefined thresholds. Extensive experiments across 12 datasets and 3 LRMs demonstrate that our method effectively reduces sycophantic behavior in both intermediate reasoning steps and final answers, yielding robust performance improvements.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.06419v1",
    "published_date": "2025-11-09 15:18:58 UTC",
    "updated_date": "2025-11-09 15:18:58 UTC"
  },
  {
    "arxiv_id": "2511.06417v1",
    "title": "AUTO-Explorer: Automated Data Collection for GUI Agent",
    "authors": [
      "Xiangwu Guo",
      "Difei Gao",
      "Mike Zheng Shou"
    ],
    "abstract": "Recent advancements in GUI agents have significantly expanded their ability to interpret natural language commands to manage software interfaces. However, acquiring GUI data remains a significant challenge. Existing methods often involve designing automated agents that browse URLs from the Common Crawl, using webpage HTML to collect screenshots and corresponding annotations, including the names and bounding boxes of UI elements. However, this method is difficult to apply to desktop software or some newly launched websites not included in the Common Crawl. While we expect the model to possess strong generalization capabilities to handle this, it is still crucial for personalized scenarios that require rapid and perfect adaptation to new software or websites. To address this, we propose an automated data collection method with minimal annotation costs, named Auto-Explorer. It incorporates a simple yet effective exploration mechanism that autonomously parses and explores GUI environments, gathering data efficiently. Additionally, to assess the quality of exploration, we have developed the UIXplore benchmark. This benchmark creates environments for explorer agents to discover and save software states. Using the data gathered, we fine-tune a multimodal large language model (MLLM) and establish a GUI element grounding testing set to evaluate the effectiveness of the exploration strategies. Our experiments demonstrate the superior performance of Auto-Explorer, showing that our method can quickly enhance the capabilities of an MLLM in explored software.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.06417v1",
    "published_date": "2025-11-09 15:13:45 UTC",
    "updated_date": "2025-11-09 15:13:45 UTC"
  },
  {
    "arxiv_id": "2511.08630v1",
    "title": "Hope, Aspirations, and the Impact of LLMs on Female Programming Learners in Afghanistan",
    "authors": [
      "Hamayoon Behmanush",
      "Freshta Akhtari",
      "Roghieh Nooripour",
      "Ingmar Weber",
      "Vikram Kamath Cannanure"
    ],
    "abstract": "Designing impactful educational technologies in contexts of socio-political instability requires a nuanced understanding of educational aspirations. Currently, scalable metrics for measuring aspirations are limited. This study adapts, translates, and evaluates Snyder's Hope Scale as a metric for measuring aspirations among 136 women learning programming online during a period of systemic educational restrictions in Afghanistan. The adapted scale demonstrated good reliability (Cronbach's α = 0.78) and participants rated it as understandable and relevant. While overall aspiration-related scores did not differ significantly by access to Large Language Models (LLMs), those with access reported marginally higher scores on the Avenues subscale (p = .056), suggesting broader perceived pathways to achieving educational aspirations. These findings support the use of the adapted scale as a metric for aspirations in contexts of socio-political instability. More broadly, the adapted scale can be used to evaluate the impact of aspiration-driven design of educational technologies.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.08630v1",
    "published_date": "2025-11-09 14:58:33 UTC",
    "updated_date": "2025-11-09 14:58:33 UTC"
  },
  {
    "arxiv_id": "2511.06411v1",
    "title": "SofT-GRPO: Surpassing Discrete-Token LLM Reinforcement Learning via Gumbel-Reparameterized Soft-Thinking Policy Optimization",
    "authors": [
      "Zhi Zheng",
      "Wee Sun Lee"
    ],
    "abstract": "The soft-thinking paradigm for Large Language Model (LLM) reasoning can outperform the conventional discrete-token Chain-of-Thought (CoT) reasoning in some scenarios, underscoring its research and application value. However, while the discrete-token CoT reasoning pattern can be reinforced through policy optimization algorithms such as group relative policy optimization (GRPO), extending the soft-thinking pattern with Reinforcement Learning (RL) remains challenging. This difficulty stems from the complexities of injecting stochasticity into soft-thinking tokens and updating soft-thinking policies accordingly. As a result, previous attempts to combine soft-thinking with GRPO typically underperform their discrete-token GRPO counterparts. To fully unlock the potential of soft-thinking, this paper presents a novel policy optimization algorithm, SofT-GRPO, to reinforce LLMs under the soft-thinking reasoning pattern. SofT-GRPO injects the Gumbel noise into logits, employs the Gumbel-Softmax technique to avoid soft-thinking tokens outside the pre-trained embedding space, and leverages the reparameterization trick in policy gradient. We conduct experiments across base LLMs ranging from 1.5B to 7B parameters, and results demonstrate that SofT-GRPO enables soft-thinking LLMs to slightly outperform discrete-token GRPO on Pass@1 (+0.13% on average accuracy), while exhibiting a substantial uplift on Pass@32 (+2.19% on average accuracy). Codes and weights are available on https://github.com/zz1358m/SofT-GRPO-master",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.06411v1",
    "published_date": "2025-11-09 14:55:50 UTC",
    "updated_date": "2025-11-09 14:55:50 UTC"
  },
  {
    "arxiv_id": "2511.07480v1",
    "title": "KG-DF: A Black-box Defense Framework against Jailbreak Attacks Based on Knowledge Graphs",
    "authors": [
      "Shuyuan Liu",
      "Jiawei Chen",
      "Xiao Yang",
      "Hang Su",
      "Zhaoxia Yin"
    ],
    "abstract": "With the widespread application of large language models (LLMs) in various fields, the security challenges they face have become increasingly prominent, especially the issue of jailbreak. These attacks induce the model to generate erroneous or uncontrolled outputs through crafted inputs, threatening the generality and security of the model. Although existing defense methods have shown some effectiveness, they often struggle to strike a balance between model generality and security. Excessive defense may limit the normal use of the model, while insufficient defense may lead to security vulnerabilities. In response to this problem, we propose a Knowledge Graph Defense Framework (KG-DF). Specifically, because of its structured knowledge representation and semantic association capabilities, Knowledge Graph(KG) can be searched by associating input content with safe knowledge in the knowledge base, thus identifying potentially harmful intentions and providing safe reasoning paths. However, traditional KG methods encounter significant challenges in keyword extraction, particularly when confronted with diverse and evolving attack strategies. To address this issue, we introduce an extensible semantic parsing module, whose core task is to transform the input query into a set of structured and secure concept representations, thereby enhancing the relevance of the matching process. Experimental results show that our framework enhances defense performance against various jailbreak attack methods, while also improving the response quality of the LLM in general QA scenarios by incorporating domain-general knowledge.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.07480v1",
    "published_date": "2025-11-09 14:39:40 UTC",
    "updated_date": "2025-11-09 14:39:40 UTC"
  },
  {
    "arxiv_id": "2511.06406v1",
    "title": "On Modality Incomplete Infrared-Visible Object Detection: An Architecture Compatibility Perspective",
    "authors": [
      "Shuo Yang",
      "Yinghui Xing",
      "Shizhou Zhang",
      "Zhilong Niu"
    ],
    "abstract": "Infrared and visible object detection (IVOD) is essential for numerous around-the-clock applications. Despite notable advancements, current IVOD models exhibit notable performance declines when confronted with incomplete modality data, particularly if the dominant modality is missing. In this paper, we take a thorough investigation on modality incomplete IVOD problem from an architecture compatibility perspective. Specifically, we propose a plug-and-play Scarf Neck module for DETR variants, which introduces a modality-agnostic deformable attention mechanism to enable the IVOD detector to flexibly adapt to any single or double modalities during training and inference. When training Scarf-DETR, we design a pseudo modality dropout strategy to fully utilize the multi-modality information, making the detector compatible and robust to both working modes of single and double modalities. Moreover, we introduce a comprehensive benchmark for the modality-incomplete IVOD task aimed at thoroughly assessing situations where the absent modality is either dominant or secondary. Our proposed Scarf-DETR not only performs excellently in missing modality scenarios but also achieves superior performances on the standard IVOD modality complete benchmarks. Our code will be available at https://github.com/YinghuiXing/Scarf-DETR.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.06406v1",
    "published_date": "2025-11-09 14:38:32 UTC",
    "updated_date": "2025-11-09 14:38:32 UTC"
  },
  {
    "arxiv_id": "2511.06396v1",
    "title": "Efficient LLM Safety Evaluation through Multi-Agent Debate",
    "authors": [
      "Dachuan Lin",
      "Guobin Shen",
      "Zihao Yang",
      "Tianrong Liu",
      "Dongcheng Zhao",
      "Yi Zeng"
    ],
    "abstract": "Safety evaluation of large language models (LLMs) increasingly relies on LLM-as-a-Judge frameworks, but the high cost of frontier models limits scalability. We propose a cost-efficient multi-agent judging framework that employs Small Language Models (SLMs) through structured debates among critic, defender, and judge agents. To rigorously assess safety judgments, we construct HAJailBench, a large-scale human-annotated jailbreak benchmark comprising 12,000 adversarial interactions across diverse attack methods and target models. The dataset provides fine-grained, expert-labeled ground truth for evaluating both safety robustness and judge reliability. Our SLM-based framework achieves agreement comparable to GPT-4o judges on HAJailBench while substantially reducing inference cost. Ablation results show that three rounds of debate yield the optimal balance between accuracy and efficiency. These findings demonstrate that structured, value-aligned debate enables SLMs to capture semantic nuances of jailbreak attacks and that HAJailBench offers a reliable foundation for scalable LLM safety evaluation.",
    "categories": [
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.AI",
    "comment": "9 pages of main text, 14 pages total, 4 figures",
    "pdf_url": "https://arxiv.org/pdf/2511.06396v1",
    "published_date": "2025-11-09 14:06:55 UTC",
    "updated_date": "2025-11-09 14:06:55 UTC"
  },
  {
    "arxiv_id": "2511.06391v1",
    "title": "HatePrototypes: Interpretable and Transferable Representations for Implicit and Explicit Hate Speech Detection",
    "authors": [
      "Irina Proskurina",
      "Marc-Antoine Carpentier",
      "Julien Velcin"
    ],
    "abstract": "Optimization of offensive content moderation models for different types of hateful messages is typically achieved through continued pre-training or fine-tuning on new hate speech benchmarks. However, existing benchmarks mainly address explicit hate toward protected groups and often overlook implicit or indirect hate, such as demeaning comparisons, calls for exclusion or violence, and subtle discriminatory language that still causes harm. While explicit hate can often be captured through surface features, implicit hate requires deeper, full-model semantic processing. In this work, we question the need for repeated fine-tuning and analyze the role of HatePrototypes, class-level vector representations derived from language models optimized for hate speech detection and safety moderation. We find that these prototypes, built from as few as 50 examples per class, enable cross-task transfer between explicit and implicit hate, with interchangeable prototypes across benchmarks. Moreover, we show that parameter-free early exiting with prototypes is effective for both hate types. We release the code, prototype resources, and evaluation scripts to support future research on efficient and transferable hate speech detection.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.06391v1",
    "published_date": "2025-11-09 14:01:26 UTC",
    "updated_date": "2025-11-09 14:01:26 UTC"
  },
  {
    "arxiv_id": "2511.06390v3",
    "title": "Ghost in the Transformer: Detecting Model Reuse with Invariant Spectral Signatures",
    "authors": [
      "Suqing Wang",
      "Ziyang Ma",
      "Li Xinyi",
      "Zuchao Li"
    ],
    "abstract": "Large Language Models (LLMs) are widely adopted, but their high training cost leads many developers to fine-tune existing open-source models. While most adhere to open-source licenses, some falsely claim original training despite clear derivation from public models, raising pressing concerns about intellectual property protection and the need to verify model provenance. In this paper, we propose GhostSpec, a lightweight yet effective method for verifying LLM lineage without access to training data or modification of model behavior. Our approach constructs compact and robust fingerprints by applying singular value decomposition (SVD) to invariant products of internal attention weight matrices. Unlike watermarking or output-based methods, GhostSpec is fully data-free, non-invasive, and computationally efficient. Extensive experiments show it is robust to fine-tuning, pruning, expansion, and adversarial transformations, reliably tracing lineage with minimal overhead. By offering a practical solution for model verification, our method contributes to intellectual property protection and fosters a transparent, trustworthy LLM ecosystem. Our code is available at https://github.com/DX0369/GhostSpec.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "Accepted at AAAI 2026 (Oral)",
    "pdf_url": "https://arxiv.org/pdf/2511.06390v3",
    "published_date": "2025-11-09 13:57:59 UTC",
    "updated_date": "2025-12-08 14:17:36 UTC"
  },
  {
    "arxiv_id": "2511.06388v1",
    "title": "HyMoERec: Hybrid Mixture-of-Experts for Sequential Recommendation",
    "authors": [
      "Kunrong Li",
      "Zhu Sun",
      "Kwan Hui Lim"
    ],
    "abstract": "We propose HyMoERec, a novel sequential recommendation framework that addresses the limitations of uniform Position-wise Feed-Forward Networks in existing models. Current approaches treat all user interactions and items equally, overlooking the heterogeneity in user behavior patterns and diversity in item complexity. HyMoERec initially introduces a hybrid mixture-of-experts architecture that combines shared and specialized expert branches with an adaptive expert fusion mechanism for the sequential recommendation task. This design captures diverse reasoning for varied users and items while ensuring stable training. Experiments on MovieLens-1M and Beauty datasets demonstrate that HyMoERec consistently outperforms state-of-the-art baselines.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "AAAI 2026 Student Abstract",
    "pdf_url": "https://arxiv.org/pdf/2511.06388v1",
    "published_date": "2025-11-09 13:52:48 UTC",
    "updated_date": "2025-11-09 13:52:48 UTC"
  },
  {
    "arxiv_id": "2511.06380v1",
    "title": "What Makes Reasoning Invalid: Echo Reflection Mitigation for Large Language Models",
    "authors": [
      "Chen He",
      "Xun Jiang",
      "Lei Wang",
      "Hao Yang",
      "Chong Peng",
      "Peng Yan",
      "Fumin Shen",
      "Xing Xu"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable performance across a wide range of reasoning tasks. Recent methods have further improved LLM performance in complex mathematical reasoning. However, when extending these methods beyond the domain of mathematical reasoning to tasks involving complex domain-specific knowledge, we observe a consistent failure of LLMs to generate novel insights during the reflection stage. Instead of conducting genuine cognitive refinement, the model tends to mechanically reiterate earlier reasoning steps without introducing new information or perspectives, a phenomenon referred to as \"Echo Reflection\". We attribute this behavior to two key defects: (1) Uncontrollable information flow during response generation, which allows premature intermediate thoughts to propagate unchecked and distort final decisions; (2) Insufficient exploration of internal knowledge during reflection, leading to repeating earlier findings rather than generating new cognitive insights. Building on these findings, we proposed a novel reinforcement learning method termed Adaptive Entropy Policy Optimization (AEPO). Specifically, the AEPO framework consists of two major components: (1) Reflection-aware Information Filtration, which quantifies the cognitive information flow and prevents the final answer from being affected by earlier bad cognitive information; (2) Adaptive-Entropy Optimization, which dynamically balances exploration and exploitation across different reasoning stages, promoting both reflective diversity and answer correctness. Extensive experiments demonstrate that AEPO consistently achieves state-of-the-art performance over mainstream reinforcement learning baselines across diverse benchmarks.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.06380v1",
    "published_date": "2025-11-09 13:33:46 UTC",
    "updated_date": "2025-11-09 13:33:46 UTC"
  },
  {
    "arxiv_id": "2511.06363v1",
    "title": "Privacy-Preserving Federated Learning for Fair and Efficient Urban Traffic Optimization",
    "authors": [
      "Rathin Chandra Shit",
      "Sharmila Subudhi"
    ],
    "abstract": "The optimization of urban traffic is threatened by the complexity of achieving a balance between transport efficiency and the maintenance of privacy, as well as the equitable distribution of traffic based on socioeconomically diverse neighborhoods. Current centralized traffic management schemes invade user location privacy and further entrench traffic disparity by offering disadvantaged route suggestions, whereas current federated learning frameworks do not consider fairness constraints in multi-objective traffic settings. This study presents a privacy-preserving federated learning framework, termed FedFair-Traffic, that jointly and simultaneously optimizes travel efficiency, traffic fairness, and differential privacy protection. This is the first attempt to integrate three conflicting objectives to improve urban transportation systems. The proposed methodology enables collaborative learning between related vehicles with data locality by integrating Graph Neural Networks with differential privacy mechanisms ($ε$-privacy guarantees) and Gini coefficient-based fair constraints using multi-objective optimization. The framework uses federated aggregation methods of gradient clipping and noise injection to provide differential privacy and optimize Pareto-efficient solutions for the efficiency-fairness tradeoff. Real-world comprehensive experiments on the METR-LA traffic dataset showed that FedFair-Traffic can reduce the average travel time by 7\\% (14.2 minutes) compared with their centralized baselines, promote traffic fairness by 73\\% (Gini coefficient, 0.78), and offer high privacy protection (privacy score, 0.8) with an 89\\% reduction in communication overhead. These outcomes demonstrate that FedFair-Traffic is a scalable privacy-aware smart city infrastructure with possible use-cases in metropolitan traffic flow control and federated transportation networks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NI",
      "eess.SY"
    ],
    "primary_category": "cs.LG",
    "comment": "Under review at IEEE journal",
    "pdf_url": "https://arxiv.org/pdf/2511.06363v1",
    "published_date": "2025-11-09 13:03:27 UTC",
    "updated_date": "2025-11-09 13:03:27 UTC"
  },
  {
    "arxiv_id": "2511.06362v1",
    "title": "Understanding Student Interaction with AI-Powered Next-Step Hints: Strategies and Challenges",
    "authors": [
      "Anastasiia Birillo",
      "Aleksei Rostovskii",
      "Yaroslav Golubev",
      "Hieke Keuning"
    ],
    "abstract": "Automated feedback generation plays a crucial role in enhancing personalized learning experiences in computer science education. Among different types of feedback, next-step hint feedback is particularly important, as it provides students with actionable steps to progress towards solving programming tasks. This study investigates how students interact with an AI-driven next-step hint system in an in-IDE learning environment. We gathered and analyzed a dataset from 34 students solving Kotlin tasks, containing detailed hint interaction logs. We applied process mining techniques and identified 16 common interaction scenarios. Semi-structured interviews with 6 students revealed strategies for managing unhelpful hints, such as adapting partial hints or modifying code to generate variations of the same hint. These findings, combined with our publicly available dataset, offer valuable opportunities for future research and provide key insights into student behavior, helping improve hint design for enhanced learning support.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.SE",
    "comment": "Accepted to SIGCSE'26. 7 pages, 3 figures",
    "pdf_url": "https://arxiv.org/pdf/2511.06362v1",
    "published_date": "2025-11-09 12:56:34 UTC",
    "updated_date": "2025-11-09 12:56:34 UTC"
  },
  {
    "arxiv_id": "2511.07479v1",
    "title": "Modulo Video Recovery via Selective Spatiotemporal Vision Transformer",
    "authors": [
      "Tianyu Geng",
      "Feng Ji",
      "Wee Peng Tay"
    ],
    "abstract": "Conventional image sensors have limited dynamic range, causing saturation in high-dynamic-range (HDR) scenes. Modulo cameras address this by folding incident irradiance into a bounded range, yet require specialized unwrapping algorithms to reconstruct the underlying signal. Unlike HDR recovery, which extends dynamic range from conventional sampling, modulo recovery restores actual values from folded samples. Despite being introduced over a decade ago, progress in modulo image recovery has been slow, especially in the use of modern deep learning techniques. In this work, we demonstrate that standard HDR methods are unsuitable for modulo recovery. Transformers, however, can capture global dependencies and spatial-temporal relationships crucial for resolving folded video frames. Still, adapting existing Transformer architectures for modulo recovery demands novel techniques. To this end, we present Selective Spatiotemporal Vision Transformer (SSViT), the first deep learning framework for modulo video reconstruction. SSViT employs a token selection strategy to improve efficiency and concentrate on the most critical regions. Experiments confirm that SSViT produces high-quality reconstructions from 8-bit folded videos and achieves state-of-the-art performance in modulo video recovery.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.07479v1",
    "published_date": "2025-11-09 12:54:32 UTC",
    "updated_date": "2025-11-09 12:54:32 UTC"
  },
  {
    "arxiv_id": "2511.10670v1",
    "title": "Towards Fine-Grained Code-Switch Speech Translation with Semantic Space Alignment",
    "authors": [
      "Yan Gao",
      "Yazheng Yang",
      "Zhibin Lan",
      "Yidong Chen",
      "Min Zhang",
      "Daimeng Wei",
      "Hui Huang",
      "Jinsong Su"
    ],
    "abstract": "Code-switching (CS) speech translation (ST) refers to translating speech that alternates between two or more languages into a target language text, which poses significant challenges due to the complexity of semantic modeling and the scarcity of CS data. Previous studies tend to rely on the model itself to implicitly learn semantic modeling during training, and resort to inefficient and costly manual annotations for these two challenges. To mitigate these limitations, we propose enhancing Large Language Models (LLMs) with a Mixture of Experts (MoE) speech projector, where each expert specializes in the semantic subspace of a specific language, enabling fine-grained modeling of speech features. Additionally, we introduce a multi-stage training paradigm that utilizes readily available monolingual automatic speech recognition (ASR) and monolingual ST data, facilitating speech-text alignment and improving translation capabilities. During training, we leverage a combination of language-specific loss and intra-group load balancing loss to guide the MoE speech projector in efficiently allocating tokens to the appropriate experts, across expert groups and within each group, respectively. To bridge the data gap across different training stages and improve adaptation to the CS scenario, we further employ a transition loss, enabling smooth transitions of data between stages, to effectively address the scarcity of high-quality CS speech translation data. Extensive experiments on widely used datasets demonstrate the effectiveness and generality of our approach.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SD"
    ],
    "primary_category": "cs.CL",
    "comment": "Working in progress",
    "pdf_url": "https://arxiv.org/pdf/2511.10670v1",
    "published_date": "2025-11-09 12:51:45 UTC",
    "updated_date": "2025-11-09 12:51:45 UTC"
  },
  {
    "arxiv_id": "2511.06361v2",
    "title": "A Graph-Theoretical Perspective on Law Design for Multiagent Systems",
    "authors": [
      "Qi Shi",
      "Pavel Naumov"
    ],
    "abstract": "A law in a multiagent system is a set of constraints imposed on agents' behaviours to avoid undesirable outcomes. The paper considers two types of laws: useful laws that, if followed, completely eliminate the undesirable outcomes and gap-free laws that guarantee that at least one agent can be held responsible each time an undesirable outcome occurs. In both cases, we study the problem of finding a law that achieves the desired result by imposing the minimum restrictions.\n  We prove that, for both types of laws, the minimisation problem is NP-hard even in the simple case of one-shot concurrent interactions. We also show that the approximation algorithm for the vertex cover problem in hypergraphs could be used to efficiently approximate the minimum laws in both cases.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.GT"
    ],
    "primary_category": "cs.MA",
    "comment": "The 40th AAAI Conference on Artificial Intelligence (AAAI-26)",
    "pdf_url": "https://arxiv.org/pdf/2511.06361v2",
    "published_date": "2025-11-09 12:46:29 UTC",
    "updated_date": "2026-01-12 14:07:57 UTC"
  },
  {
    "arxiv_id": "2511.06356v2",
    "title": "Reaction Prediction via Interaction Modeling of Symmetric Difference Shingle Sets",
    "authors": [
      "Runhan Shi",
      "Letian Chen",
      "Gufeng Yu",
      "Yang Yang"
    ],
    "abstract": "Chemical reaction prediction remains a fundamental challenge in organic chemistry, where existing machine learning models face two critical limitations: sensitivity to input permutations (molecule/atom orderings) and inadequate modeling of substructural interactions governing reactivity. These shortcomings lead to inconsistent predictions and poor generalization to real-world scenarios. To address these challenges, we propose ReaDISH, a novel reaction prediction model that learns permutation-invariant representations while incorporating interaction-aware features. It introduces two innovations: (1) symmetric difference shingle encoding, which extends the differential reaction fingerprint (DRFP) by representing shingles as continuous high-dimensional embeddings, capturing structural changes while eliminating order sensitivity; and (2) geometry-structure interaction attention, a mechanism that models intra- and inter-molecular interactions at the shingle level. Extensive experiments demonstrate that ReaDISH improves reaction prediction performance across diverse benchmarks. It shows enhanced robustness with an average improvement of 8.76% on R$^2$ under permutation perturbations.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.BM"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.06356v2",
    "published_date": "2025-11-09 12:29:16 UTC",
    "updated_date": "2025-11-16 04:36:05 UTC"
  },
  {
    "arxiv_id": "2511.06348v1",
    "title": "GazeVLM: A Vision-Language Model for Multi-Task Gaze Understanding",
    "authors": [
      "Athul M. Mathew",
      "Haithem Hermassi",
      "Thariq Khalid",
      "Arshad Ali Khan",
      "Riad Souissi"
    ],
    "abstract": "Gaze understanding unifies the detection of people, their gaze targets, and objects of interest into a single framework, offering critical insight into visual attention and intent estimation. Although prior research has modelled gaze cues in visual scenes, a unified system is still needed for gaze understanding using both visual and language prompts. This paper introduces GazeVLM, a novel Vision-Language Model (VLM) for multi-task gaze understanding in images, addressing person detection, gaze target detection, and gaze object identification. While other transformer-based methods exist for gaze analysis, GazeVLM represents, to our knowledge, the first application of a VLM to these combined tasks, allowing for selective execution of each task. Through the integration of visual (RGB and depth) and textual modalities, our ablation study on visual input combinations revealed that a fusion of RGB images with HHA-encoded depth maps, guided by text prompts, yields superior performance. We also introduce an object-level gaze detection metric for gaze object identification ($AP_{ob}$). Through experiments, GazeVLM demonstrates significant improvements, notably achieving state-of-the-art evaluation scores on GazeFollow and VideoAttentionTarget datasets.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.06348v1",
    "published_date": "2025-11-09 12:07:40 UTC",
    "updated_date": "2025-11-09 12:07:40 UTC"
  },
  {
    "arxiv_id": "2511.06346v2",
    "title": "LPFQA: A Long-Tail Professional Forum-based Benchmark for LLM Evaluation",
    "authors": [
      "Liya Zhu",
      "Peizhuang Cong",
      "Jingzhe Ding",
      "Aowei Ji",
      "Wenya Wu",
      "Jiani Hou",
      "Chunjie Wu",
      "Xiang Gao",
      "Jingkai Liu",
      "Zhou Huan",
      "Xuelei Sun",
      "Yang Yang",
      "Jianpeng Jiao",
      "Liang Hu",
      "Xinjie Chen",
      "Jiashuo Liu",
      "Tong Yang",
      "Zaiyuan Wang",
      "Ge Zhang",
      "Wenhao Huang"
    ],
    "abstract": "Large Language Models (LLMs) perform well on standard reasoning and question-answering benchmarks, yet such evaluations often fail to capture their ability to handle long-tail, expertise-intensive knowledge in real-world professional scenarios. We introduce LPFQA, a long-tail knowledge benchmark derived from authentic professional forum discussions, covering 7 academic and industrial domains with 430 curated tasks grounded in practical expertise. LPFQA evaluates specialized reasoning, domain-specific terminology understanding, and contextual interpretation, and adopts a hierarchical difficulty structure to ensure semantic clarity and uniquely identifiable answers. Experiments on over multiple mainstream LLMs reveal substantial performance gaps, particularly on tasks requiring deep domain reasoning, exposing limitations overlooked by existing benchmarks. Overall, LPFQA provides an authentic and discriminative evaluation framework that complements prior benchmarks and informs future LLM development.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.06346v2",
    "published_date": "2025-11-09 12:02:19 UTC",
    "updated_date": "2026-01-08 04:39:48 UTC"
  },
  {
    "arxiv_id": "2511.06345v2",
    "title": "PRAGMA: A Profiling-Reasoned Multi-Agent Framework for Automatic Kernel Optimization",
    "authors": [
      "Kelun Lei",
      "Hailong Yang",
      "Huaitao Zhang",
      "Xin You",
      "Kaige Zhang",
      "Zhongzhi Luan",
      "Yi Liu",
      "Depei Qian"
    ],
    "abstract": "Designing high-performance kernels requires expert-level tuning and a deep understanding of hardware characteristics. Recent advances in large language models (LLMs) have enabled automated kernel generation, yet most existing systems rely solely on correctness or execution time feedback, lacking the ability to reason about low-level performance bottlenecks. In this paper, we introduce PRAGMA, a profile-guided AI kernel generation framework that integrates execution feedback and fine-grained hardware profiling into the reasoning loop. PRAGMA enables LLMs to identify performance bottlenecks, preserve historical best versions, and iteratively refine code quality. We evaluate PRAGMA on KernelBench, covering GPU and CPU backends. Results show that PRAGMA consistently outperforms baseline AIKG without profiling enabled and achieves 2.81$\\times$ and 2.30$\\times$ averaged speedups against Torch on CPU and GPU platforms, respectively.",
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.06345v2",
    "published_date": "2025-11-09 12:01:43 UTC",
    "updated_date": "2025-11-24 11:46:50 UTC"
  },
  {
    "arxiv_id": "2511.06344v1",
    "title": "TimeSense:Making Large Language Models Proficient in Time-Series Analysis",
    "authors": [
      "Zhirui Zhang",
      "Changhua Pei",
      "Tianyi Gao",
      "Zhe Xie",
      "Yibo Hao",
      "Zhaoyang Yu",
      "Longlong Xu",
      "Tong Xiao",
      "Jing Han",
      "Dan Pei"
    ],
    "abstract": "In the time-series domain, an increasing number of works combine text with temporal data to leverage the reasoning capabilities of large language models (LLMs) for various downstream time-series understanding tasks. This enables a single model to flexibly perform tasks that previously required specialized models for each domain. However, these methods typically rely on text labels for supervision during training, biasing the model toward textual cues while potentially neglecting the full temporal features. Such a bias can lead to outputs that contradict the underlying time-series context. To address this issue, we construct the EvalTS benchmark, comprising 10 tasks across three difficulty levels, from fundamental temporal pattern recognition to complex real-world reasoning, to evaluate models under more challenging and realistic scenarios. We also propose TimeSense, a multimodal framework that makes LLMs proficient in time-series analysis by balancing textual reasoning with a preserved temporal sense. TimeSense incorporates a Temporal Sense module that reconstructs the input time-series within the model's context, ensuring that textual reasoning is grounded in the time-series dynamics. Moreover, to enhance spatial understanding of time-series data, we explicitly incorporate coordinate-based positional embeddings, which provide each time point with spatial context and enable the model to capture structural dependencies more effectively. Experimental results demonstrate that TimeSense achieves state-of-the-art performance across multiple tasks, and it particularly outperforms existing methods on complex multi-dimensional time-series reasoning tasks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.06344v1",
    "published_date": "2025-11-09 12:00:18 UTC",
    "updated_date": "2025-11-09 12:00:18 UTC"
  },
  {
    "arxiv_id": "2511.11641v1",
    "title": "EcoSpa: Efficient Transformer Training with Coupled Sparsity",
    "authors": [
      "Jinqi Xiao",
      "Cheng Luo",
      "Lingyi Huang",
      "Cheng Yang",
      "Yang Sui",
      "Huy Phan",
      "Xiao Zang",
      "Yibiao Ying",
      "Zhexiang Tang",
      "Anima Anandkumar",
      "Bo Yuan"
    ],
    "abstract": "Transformers have become the backbone of modern AI, yet their high computational demands pose critical system challenges. While sparse training offers efficiency gains, existing methods fail to preserve critical structural relationships between weight matrices that interact multiplicatively in attention and feed-forward layers. This oversight leads to performance degradation at high sparsity levels. We introduce EcoSpa, an efficient structured sparse training method that jointly evaluates and sparsifies coupled weight matrix pairs, preserving their interaction patterns through aligned row/column removal. EcoSpa introduces a new granularity for calibrating structural component importance and performs coupled estimation and sparsification across both pre-training and fine-tuning scenarios. Evaluations demonstrate substantial improvements: EcoSpa enables efficient training of LLaMA-1B with 50\\% memory reduction and 21\\% faster training, achieves $2.2\\times$ model compression on GPT-2-Medium with $2.4$ lower perplexity, and delivers $1.6\\times$ inference speedup. The approach uses standard PyTorch operations, requiring no custom hardware or kernels, making efficient transformer training accessible on commodity hardware.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.PF"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.11641v1",
    "published_date": "2025-11-09 11:23:43 UTC",
    "updated_date": "2025-11-09 11:23:43 UTC"
  },
  {
    "arxiv_id": "2511.06325v1",
    "title": "CINEMAE: Leveraging Frozen Masked Autoencoders for Cross-Generator AI Image Detection",
    "authors": [
      "Minsuk Jang",
      "Hyeonseo Jeong",
      "Minseok Son",
      "Changick Kim"
    ],
    "abstract": "While context-based detectors have achieved strong generalization for AI-generated text by measuring distributional inconsistencies, image-based detectors still struggle with overfitting to generator-specific artifacts. We introduce CINEMAE, a novel paradigm for AIGC image detection that adapts the core principles of text detection methods to the visual domain. Our key insight is that Masked AutoEncoder (MAE), trained to reconstruct masked patches conditioned on visible context, naturally encodes semantic consistency expectations. We formalize this reconstruction process probabilistically, computing conditional Negative Log-Likelihood (NLL, p(masked | visible)) to quantify local semantic anomalies. By aggregating these patch-level statistics with global MAE features through learned fusion, CINEMAE achieves strong cross-generator generalization. Trained exclusively on Stable Diffusion v1.4, our method achieves over 95% accuracy on all eight unseen generators in the GenImage benchmark, substantially outperforming state-of-the-art detectors. This demonstrates that context-conditional reconstruction uncertainty provides a robust, transferable signal for AIGC detection.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.06325v1",
    "published_date": "2025-11-09 11:05:45 UTC",
    "updated_date": "2025-11-09 11:05:45 UTC"
  },
  {
    "arxiv_id": "2511.17541v1",
    "title": "Leibniz's Monadology as Foundation for the Artificial Age Score: A Formal Architecture for Al Memory Evaluation",
    "authors": [
      "Seyma Yaman Kayadibi"
    ],
    "abstract": "This paper develops a mathematically rigorous, philosophically grounded framework for evaluating artificial memory systems, rooted in the metaphysical structure of Leibniz's Monadology. Building on a previously formalized metric, the Artificial Age Score (AAS), the study maps twenty core propositions from the Monadology to an information-theoretic architecture. In this design, each monad functions as a modular unit defined by a truth score, a redundancy parameter, and a weighted contribution to a global memory penalty function. Smooth logarithmic transformations operationalize these quantities and yield interpretable, bounded metrics for memory aging, representational stability, and salience. Classical metaphysical notions of perception, apperception, and appetition are reformulated as entropy, gradient dynamics, and internal representation fidelity. Logical principles, including the laws of non-contradiction and sufficient reason, are encoded as regularization constraints guiding memory evolution. A central contribution is a set of first principles proofs establishing refinement invariance, structural decomposability, and monotonicity under scale transformation, aligned with the metaphysical structure of monads. The framework's formal organization is structured into six thematic bundles derived from Monadology, aligning each mathematical proof with its corresponding philosophical domain. Beyond evaluation, the framework offers a principled blueprint for building Al memory architectures that are modular, interpretable, and provably sound.",
    "categories": [
      "cs.AI",
      "cs.IT",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.17541v1",
    "published_date": "2025-11-09 10:48:33 UTC",
    "updated_date": "2025-11-09 10:48:33 UTC"
  },
  {
    "arxiv_id": "2511.06316v2",
    "title": "ALIGN: A Vision-Language Framework for High-Accuracy Accident Location Inference through Geo-Spatial Neural Reasoning",
    "authors": [
      "MD Thamed Bin Zaman Chowdhury",
      "Moazzem Hossain"
    ],
    "abstract": "Reliable geospatial information on road accidents is vital for safety analysis and infrastructure planning, yet most low- and middle-income countries continue to face a critical shortage of accurate, location-specific crash data. Existing text-based geocoding tools perform poorly in multilingual and unstructured news environments, where incomplete place descriptions and mixed language (e.g. Bangla-English) scripts obscure spatial context. To address these limitations, this study introduces ALIGN (Accident Location Inference through Geo-Spatial Neural Reasoning), a vision-language framework that emulates human spatial reasoning to infer accident location coordinates directly from available textual and map-based cues. ALIGN integrates large language and vision-language model mechanisms within a multi-stage pipeline that performs optical character recognition, linguistic reasoning, and map-level verification through grid-based spatial scanning. The framework systematically evaluates each predicted location against contextual and visual evidence, ensuring interpretable, fine-grained geolocation outcomes without requiring model retraining. Applied to Bangla-language news data source, ALIGN demonstrates consistent improvements over traditional geoparsing methods, accurately identifying district- and sub-district-level crash sites. Beyond its technical contribution, the framework establishes a high accuracy foundation for automated crash mapping in data-scarce regions, supporting evidence-driven road-safety policymaking and the broader integration of multimodal artificial intelligence in transportation analytics.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.06316v2",
    "published_date": "2025-11-09 10:44:26 UTC",
    "updated_date": "2025-12-10 04:19:10 UTC"
  },
  {
    "arxiv_id": "2511.08628v2",
    "title": "Learning Topology-Driven Multi-Subspace Fusion for Grassmannian Deep Network",
    "authors": [
      "Xuan Yu",
      "Tianyang Xu"
    ],
    "abstract": "Grassmannian manifold offers a powerful carrier for geometric representation learning by modelling high-dimensional data as low-dimensional subspaces. However, existing approaches predominantly rely on static single-subspace representations, neglecting the dynamic interplay between multiple subspaces critical for capturing complex geometric structures. To address this limitation, we propose a topology-driven multi-subspace fusion framework that enables adaptive subspace collaboration on the Grassmannian. Our solution introduces two key innovations: (1) Inspired by the Kolmogorov-Arnold representation theorem, an adaptive multi-subspace modelling mechanism is proposed that dynamically selects and weights task-relevant subspaces via topological convergence analysis, and (2) a multi-subspace interaction block that fuses heterogeneous geometric representations through Fréchet mean optimisation on the manifold. Theoretically, we establish the convergence guarantees of adaptive subspaces under a projection metric topology, ensuring stable gradient-based optimisation. Practically, we integrate Riemannian batch normalisation and mutual information regularisation to enhance discriminability and robustness. Extensive experiments on 3D action recognition (HDM05, FPHA), EEG classification (MAMEM-SSVEPII), and graph tasks demonstrate state-of-the-art performance. Our work not only advances geometric deep learning but also successfully adapts the proven multi-channel interaction philosophy of Euclidean networks to non-Euclidean domains, achieving superior discriminability and interpretability.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at AAAI 2026",
    "pdf_url": "https://arxiv.org/pdf/2511.08628v2",
    "published_date": "2025-11-09 10:33:13 UTC",
    "updated_date": "2025-11-14 04:39:42 UTC"
  },
  {
    "arxiv_id": "2511.06313v1",
    "title": "Precision-Scalable Microscaling Datapaths with Optimized Reduction Tree for Efficient NPU Integration",
    "authors": [
      "Stef Cuyckens",
      "Xiaoling Yi",
      "Robin Geens",
      "Joren Dumoulin",
      "Martin Wiesner",
      "Chao Fang",
      "Marian Verhelst"
    ],
    "abstract": "Emerging continual learning applications necessitate next-generation neural processing unit (NPU) platforms to support both training and inference operations. The promising Microscaling (MX) standard enables narrow bit-widths for inference and large dynamic ranges for training. However, existing MX multiply-accumulate (MAC) designs face a critical trade-off: integer accumulation requires expensive conversions from narrow floating-point products, while FP32 accumulation suffers from quantization losses and costly normalization. To address these limitations, we propose a hybrid precision-scalable reduction tree for MX MACs that combines the benefits of both approaches, enabling efficient mixed-precision accumulation with controlled accuracy relaxation. Moreover, we integrate an 8x8 array of these MACs into the state-of-the-art (SotA) NPU integration platform, SNAX, to provide efficient control and data transfer to our optimized precision-scalable MX datapath. We evaluate our design both on MAC and system level and compare it to the SotA. Our integrated system achieves an energy efficiency of 657, 1438-1675, and 4065 GOPS/W, respectively, for MXINT8, MXFP8/6, and MXFP4, with a throughput of 64, 256, and 512 GOPS.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.LG",
      "eess.SP"
    ],
    "primary_category": "cs.AR",
    "comment": "To appear in the 31st Asia and South Pacific Design Automation Conference (ASP-DAC 2026, Invited Paper)",
    "pdf_url": "https://arxiv.org/pdf/2511.06313v1",
    "published_date": "2025-11-09 10:24:17 UTC",
    "updated_date": "2025-11-09 10:24:17 UTC"
  },
  {
    "arxiv_id": "2511.06309v2",
    "title": "The Station: An Open-World Environment for AI-Driven Discovery",
    "authors": [
      "Stephen Chung",
      "Wenyu Du"
    ],
    "abstract": "We introduce the STATION, an open-world multi-agent environment for autonomous scientific discovery. The Station simulates a complete scientific ecosystem, where agents can engage in long scientific journeys that include reading papers from peers, formulating hypotheses, collaborating with peers, submitting experiments, and publishing results. Importantly, there is no centralized system coordinating their activities. Utilizing their long context, agents are free to choose their own actions and develop their own narratives within the Station. Experiments demonstrate that AI agents in the Station achieve new state-of-the-art performance on a wide range of benchmarks, spanning mathematics, computational biology, and machine learning, notably surpassing AlphaEvolve in circle packing. A rich tapestry of unscripted narratives emerges, such as agents collaborating and analyzing other works rather than pursuing myopic optimization. From these emergent narratives, novel methods arise organically, such as a new density-adaptive algorithm for scRNA-seq batch integration that borrows concepts from another domain. The Station marks a first step towards autonomous scientific discovery driven by emergent behavior in an open-world environment, representing a new paradigm that moves beyond rigid pipelines.",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "55 pages",
    "pdf_url": "https://arxiv.org/pdf/2511.06309v2",
    "published_date": "2025-11-09 10:13:00 UTC",
    "updated_date": "2025-12-01 17:00:00 UTC"
  },
  {
    "arxiv_id": "2511.06304v2",
    "title": "Kaggle Chronicles: 15 Years of Competitions, Community and Data Science Innovation",
    "authors": [
      "Kevin Bönisch",
      "Leandro Losaria"
    ],
    "abstract": "Since 2010, Kaggle has been a platform where data scientists from around the world come together to compete, collaborate, and push the boundaries of Data Science. Over these 15 years, it has grown from a purely competition-focused site into a broader ecosystem with forums, notebooks, models, datasets, and more. With the release of the Kaggle Meta Code and Kaggle Meta Datasets, we now have a unique opportunity to explore these competitions, technologies, and real-world applications of Machine Learning and AI. And so in this study, we take a closer look at 15 years of data science on Kaggle - through metadata, shared code, community discussions, and the competitions themselves. We explore Kaggle's growth, its impact on the data science community, uncover hidden technological trends, analyze competition winners, how Kagglers approach problems in general, and more. We do this by analyzing millions of kernels and discussion threads to perform both longitudinal trend analysis and standard exploratory data analysis. Our findings show that Kaggle is a steadily growing platform with increasingly diverse use cases, and that Kagglers are quick to adapt to new trends and apply them to real-world challenges, while producing - on average - models with solid generalization capabilities. We also offer a snapshot of the platform as a whole, highlighting its history and technological evolution. Finally, this study is accompanied by a video (https://www.youtube.com/watch?v=YVOV9bIUNrM) and a Kaggle write-up (https://kaggle.com/competitions/meta-kaggle-hackathon/writeups/kaggle-chronicles-15-years-of-competitions-communi) for your convenience.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.GL",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.06304v2",
    "published_date": "2025-11-09 10:01:39 UTC",
    "updated_date": "2025-11-20 12:47:52 UTC"
  },
  {
    "arxiv_id": "2511.06301v1",
    "title": "Secu-Table: a Comprehensive security table dataset for evaluating semantic table interpretation systems",
    "authors": [
      "Azanzi Jiomekong",
      "Jean Bikim",
      "Patricia Negoue",
      "Joyce Chin"
    ],
    "abstract": "Evaluating semantic tables interpretation (STI) systems, (particularly, those based on Large Language Models- LLMs) especially in domain-specific contexts such as the security domain, depends heavily on the dataset. However, in the security domain, tabular datasets for state-of-the-art are not publicly available. In this paper, we introduce Secu-Table dataset, composed of more than 1500 tables with more than 15k entities constructed using security data extracted from Common Vulnerabilities and Exposures (CVE) and Common Weakness Enumeration (CWE) data sources and annotated using Wikidata and the SEmantic Processing of Security Event Streams CyberSecurity Knowledge Graph (SEPSES CSKG). Along with the dataset, all the code is publicly released. This dataset is made available to the research community in the context of the SemTab challenge on Tabular to Knowledge Graph Matching. This challenge aims to evaluate the performance of several STI based on open source LLMs. Preliminary evaluation, serving as baseline, was conducted using Falcon3-7b-instruct and Mistral-7B-Instruct, two open source LLMs and GPT-4o mini one closed source LLM.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Submitted to Nature Scientific Data",
    "pdf_url": "https://arxiv.org/pdf/2511.06301v1",
    "published_date": "2025-11-09 09:36:01 UTC",
    "updated_date": "2025-11-09 09:36:01 UTC"
  },
  {
    "arxiv_id": "2511.06299v3",
    "title": "Physics-Informed Deformable Gaussian Splatting: Towards Unified Constitutive Laws for Time-Evolving Material Field",
    "authors": [
      "Haoqin Hong",
      "Ding Fan",
      "Fubin Dou",
      "Zhi-Li Zhou",
      "Haoran Sun",
      "Congcong Zhu",
      "Jingrun Chen"
    ],
    "abstract": "Recently, 3D Gaussian Splatting (3DGS), an explicit scene representation technique, has shown significant promise for dynamic novel-view synthesis from monocular video input. However, purely data-driven 3DGS often struggles to capture the diverse physics-driven motion patterns in dynamic scenes. To fill this gap, we propose Physics-Informed Deformable Gaussian Splatting (PIDG), which treats each Gaussian particle as a Lagrangian material point with time-varying constitutive parameters and is supervised by 2D optical flow via motion projection. Specifically, we adopt static-dynamic decoupled 4D decomposed hash encoding to reconstruct geometry and motion efficiently. Subsequently, we impose the Cauchy momentum residual as a physics constraint, enabling independent prediction of each particle's velocity and constitutive stress via a time-evolving material field. Finally, we further supervise data fitting by matching Lagrangian particle flow to camera-compensated optical flow, which accelerates convergence and improves generalization. Experiments on a custom physics-driven dataset as well as on standard synthetic and real-world datasets demonstrate significant gains in physical consistency and monocular dynamic reconstruction quality.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by AAAI-26",
    "pdf_url": "https://arxiv.org/pdf/2511.06299v3",
    "published_date": "2025-11-09 09:35:03 UTC",
    "updated_date": "2025-11-22 09:19:05 UTC"
  },
  {
    "arxiv_id": "2511.06297v1",
    "title": "Decomate: Leveraging Generative Models for Co-Creative SVG Animation",
    "authors": [
      "Jihyeon Park",
      "Jiyoon Myung",
      "Seone Shin",
      "Jungki Son",
      "Joohyung Han"
    ],
    "abstract": "Designers often encounter friction when animating static SVG graphics, especially when the visual structure does not match the desired level of motion detail. Existing tools typically depend on predefined groupings or require technical expertise, which limits designers' ability to experiment and iterate independently. We present Decomate, a system that enables intuitive SVG animation through natural language. Decomate leverages a multimodal large language model to restructure raw SVGs into semantically meaningful, animation-ready components. Designers can then specify motions for each component via text prompts, after which the system generates corresponding HTML/CSS/JS animations. By supporting iterative refinement through natural language interaction, Decomate integrates generative AI into creative workflows, allowing animation outcomes to be directly shaped by user intent.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "Accepted at the 1st Workshop on Generative and Protective AI for Content Creation (NeurIPS 2025)",
    "pdf_url": "https://arxiv.org/pdf/2511.06297v1",
    "published_date": "2025-11-09 09:28:51 UTC",
    "updated_date": "2025-11-09 09:28:51 UTC"
  },
  {
    "arxiv_id": "2511.06294v3",
    "title": "Transolver is a Linear Transformer: Revisiting Physics-Attention through the Lens of Linear Attention",
    "authors": [
      "Wenjie Hu",
      "Sidun Liu",
      "Peng Qiao",
      "Zhenglun Sun",
      "Yong Dou"
    ],
    "abstract": "Recent advances in Transformer-based Neural Operators have enabled significant progress in data-driven solvers for Partial Differential Equations (PDEs). Most current research has focused on reducing the quadratic complexity of attention to address the resulting low training and inference efficiency. Among these works, Transolver stands out as a representative method that introduces Physics-Attention to reduce computational costs. Physics-Attention projects grid points into slices for slice attention, then maps them back through deslicing. However, we observe that Physics-Attention can be reformulated as a special case of linear attention, and that the slice attention may even hurt the model performance. Based on these observations, we argue that its effectiveness primarily arises from the slice and deslice operations rather than interactions between slices. Building on this insight, we propose a two-step transformation to redesign Physics-Attention into a canonical linear attention, which we call Linear Attention Neural Operator (LinearNO). Our method achieves state-of-the-art performance on six standard PDE benchmarks, while reducing the number of parameters by an average of 40.0% and computational cost by 36.2%. Additionally, it delivers superior performance on two challenging, industrial-level datasets: AirfRANS and Shape-Net Car.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.06294v3",
    "published_date": "2025-11-09 09:12:50 UTC",
    "updated_date": "2026-01-07 06:09:09 UTC"
  },
  {
    "arxiv_id": "2511.06292v2",
    "title": "Synthetic Data-Driven Prompt Tuning for Financial QA over Tables and Documents",
    "authors": [
      "Yaoning Yu",
      "Kai-Min Chang",
      "Ye Yu",
      "Kai Wei",
      "Haojing Luo",
      "Haohan Wang"
    ],
    "abstract": "Financial documents like earning reports or balance sheets often involve long tables and multi-page reports. Large language models have become a new tool to help numerical reasoning and understanding these documents. However, prompt quality can have a major effect on how well LLMs perform these financial reasoning tasks. Most current methods tune prompts on fixed datasets of financial text or tabular data, which limits their ability to adapt to new question types or document structures, or they involve costly and manually labeled/curated dataset to help build the prompts. We introduce a self-improving prompt framework driven by data-augmented optimization. In this closed-loop process, we generate synthetic financial tables and document excerpts, verify their correctness and robustness, and then update the prompt based on the results. Specifically, our framework combines a synthetic data generator with verifiers and a prompt optimizer, where the generator produces new examples that exposes weaknesses in the current prompt, the verifiers check the validity and robustness of the produced examples, and the optimizer incrementally refines the prompt in response. By iterating these steps in a feedback cycle, our method steadily improves prompt accuracy on financial reasoning tasks without needing external labels. Evaluation on DocMath-Eval benchmark demonstrates that our system achieves higher performance in both accuracy and robustness than standard prompt methods, underscoring the value of incorporating synthetic data generation into prompt learning for financial applications.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.06292v2",
    "published_date": "2025-11-09 09:07:31 UTC",
    "updated_date": "2025-11-14 05:38:49 UTC"
  },
  {
    "arxiv_id": "2511.06285v3",
    "title": "Exploiting Inter-Session Information with Frequency-enhanced Dual-Path Networks for Sequential Recommendation",
    "authors": [
      "Peng He",
      "Yao Liu",
      "Yanglei Gan",
      "Run Lin",
      "Tingting Dai",
      "Qiao Liu",
      "Xuexin Li"
    ],
    "abstract": "Sequential recommendation (SR) aims to predict a user's next item preference by modeling historical interaction sequences. Recent advances often integrate frequency-domain modules to compensate for self-attention's low-pass nature by restoring the high-frequency signals critical for personalized recommendations. Nevertheless, existing frequency-aware solutions process each session in isolation and optimize exclusively with time-domain objectives. Consequently, they overlook cross-session spectral dependencies and fail to enforce alignment between predicted and actual spectral signatures, leaving valuable frequency information under-exploited. To this end, we propose FreqRec, a Frequency-Enhanced Dual-Path Network for sequential Recommendation that jointly captures inter-session and intra-session behaviors via a learnable Frequency-domain Multi-layer Perceptrons. Moreover, FreqRec is optimized under a composite objective that combines cross entropy with a frequency-domain consistency loss, explicitly aligning predicted and true spectral signatures. Extensive experiments on three benchmarks show that FreqRec surpasses strong baselines and remains robust under data sparsity and noisy-log conditions.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "AAAI 2026 (Oral)",
    "pdf_url": "https://arxiv.org/pdf/2511.06285v3",
    "published_date": "2025-11-09 08:39:26 UTC",
    "updated_date": "2025-11-14 02:02:16 UTC"
  },
  {
    "arxiv_id": "2511.06273v1",
    "title": "COTN: A Chaotic Oscillatory Transformer Network for Complex Volatile Systems under Extreme Conditions",
    "authors": [
      "Boyan Tang",
      "Yilong Zeng",
      "Xuanhao Ren",
      "Peng Xiao",
      "Yuhan Zhao",
      "Raymond Lee",
      "Jianghua Wu"
    ],
    "abstract": "Accurate prediction of financial and electricity markets, especially under extreme conditions, remains a significant challenge due to their intrinsic nonlinearity, rapid fluctuations, and chaotic patterns. To address these limitations, we propose the Chaotic Oscillatory Transformer Network (COTN). COTN innovatively combines a Transformer architecture with a novel Lee Oscillator activation function, processed through Max-over-Time pooling and a lambda-gating mechanism. This design is specifically tailored to effectively capture chaotic dynamics and improve responsiveness during periods of heightened volatility, where conventional activation functions (e.g., ReLU, GELU) tend to saturate. Furthermore, COTN incorporates an Autoencoder Self-Regressive (ASR) module to detect and isolate abnormal market patterns, such as sudden price spikes or crashes, thereby preventing corruption of the core prediction process and enhancing robustness. Extensive experiments across electricity spot markets and financial markets demonstrate the practical applicability and resilience of COTN. Our approach outperforms state-of-the-art deep learning models like Informer by up to 17% and traditional statistical methods like GARCH by as much as 40%. These results underscore COTN's effectiveness in navigating real-world market uncertainty and complexity, offering a powerful tool for forecasting highly volatile systems under duress.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Submitted to IEEE Transactions on Neural Networks and Learning Systems",
    "pdf_url": "https://arxiv.org/pdf/2511.06273v1",
    "published_date": "2025-11-09 08:17:19 UTC",
    "updated_date": "2025-11-09 08:17:19 UTC"
  },
  {
    "arxiv_id": "2511.06272v1",
    "title": "LaneDiffusion: Improving Centerline Graph Learning via Prior Injected BEV Feature Generation",
    "authors": [
      "Zijie Wang",
      "Weiming Zhang",
      "Wei Zhang",
      "Xiao Tan",
      "Hongxing Liu",
      "Yaowei Wang",
      "Guanbin Li"
    ],
    "abstract": "Centerline graphs, crucial for path planning in autonomous driving, are traditionally learned using deterministic methods. However, these methods often lack spatial reasoning and struggle with occluded or invisible centerlines. Generative approaches, despite their potential, remain underexplored in this domain. We introduce LaneDiffusion, a novel generative paradigm for centerline graph learning. LaneDiffusion innovatively employs diffusion models to generate lane centerline priors at the Bird's Eye View (BEV) feature level, instead of directly predicting vectorized centerlines. Our method integrates a Lane Prior Injection Module (LPIM) and a Lane Prior Diffusion Module (LPDM) to effectively construct diffusion targets and manage the diffusion process. Furthermore, vectorized centerlines and topologies are then decoded from these prior-injected BEV features. Extensive evaluations on the nuScenes and Argoverse2 datasets demonstrate that LaneDiffusion significantly outperforms existing methods, achieving improvements of 4.2%, 4.6%, 4.7%, 6.4% and 1.8% on fine-grained point-level metrics (GEO F1, TOPO F1, JTOPO F1, APLS and SDA) and 2.3%, 6.4%, 6.8% and 2.1% on segment-level metrics (IoU, mAP_cf, DET_l and TOP_ll). These results establish state-of-the-art performance in centerline graph learning, offering new insights into generative models for this task.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by ICCV 2025",
    "pdf_url": "https://arxiv.org/pdf/2511.06272v1",
    "published_date": "2025-11-09 08:15:58 UTC",
    "updated_date": "2025-11-09 08:15:58 UTC"
  },
  {
    "arxiv_id": "2511.06262v1",
    "title": "GAIA: A General Agency Interaction Architecture for LLM-Human B2B Negotiation & Screening",
    "authors": [
      "Siming Zhao",
      "Qi Li"
    ],
    "abstract": "Organizations are increasingly exploring delegation of screening and negotiation tasks to AI systems, yet deployment in high-stakes B2B settings is constrained by governance: preventing unauthorized commitments, ensuring sufficient information before bargaining, and maintaining effective human oversight and auditability. Prior work on large language model negotiation largely emphasizes autonomous bargaining between agents and omits practical needs such as staged information gathering, explicit authorization boundaries, and systematic feedback integration. We propose GAIA, a governance-first framework for LLM-human agency in B2B negotiation and screening. GAIA defines three essential roles - Principal (human), Delegate (LLM agent), and Counterparty - with an optional Critic to enhance performance, and organizes interactions through three mechanisms: information-gated progression that separates screening from negotiation; dual feedback integration that combines AI critique with lightweight human corrections; and authorization boundaries with explicit escalation paths. Our contributions are fourfold: (1) a formal governance framework with three coordinated mechanisms and four safety invariants for delegation with bounded authorization; (2) information-gated progression via task-completeness tracking (TCI) and explicit state transitions that separate screening from commitment; (3) dual feedback integration that blends Critic suggestions with human oversight through parallel learning channels; and (4) a hybrid validation blueprint that combines automated protocol metrics with human judgment of outcomes and safety. By bridging theory and practice, GAIA offers a reproducible specification for safe, efficient, and accountable AI delegation that can be instantiated across procurement, real estate, and staffing workflows.",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.06262v1",
    "published_date": "2025-11-09 07:41:49 UTC",
    "updated_date": "2025-11-09 07:41:49 UTC"
  },
  {
    "arxiv_id": "2511.06260v1",
    "title": "LLM-Guided Reinforcement Learning with Representative Agents for Traffic Modeling",
    "authors": [
      "Hanlin Sun",
      "Jiayang Li"
    ],
    "abstract": "Large language models (LLMs) are increasingly used as behavioral proxies for self-interested travelers in agent-based traffic models. Although more flexible and generalizable than conventional models, the practical use of these approaches remains limited by scalability due to the cost of calling one LLM for every traveler. Moreover, it has been found that LLM agents often make opaque choices and produce unstable day-to-day dynamics. To address these challenges, we propose to model each homogeneous traveler group facing the same decision context with a single representative LLM agent who behaves like the population's average, maintaining and updating a mixed strategy over routes that coincides with the group's aggregate flow proportions. Each day, the LLM reviews the travel experience and flags routes with positive reinforcement that they hope to use more often, and an interpretable update rule then converts this judgment into strategy adjustments using a tunable (progressively decaying) step size. The representative-agent design improves scalability, while the separation of reasoning from updating clarifies the decision logic while stabilizing learning. In classic traffic assignment settings, we find that the proposed approach converges rapidly to the user equilibrium. In richer settings with income heterogeneity, multi-criteria costs, and multi-modal choices, the generated dynamics remain stable and interpretable, reproducing plausible behavioral patterns well-documented in psychology and economics, for example, the decoy effect in toll versus non-toll road selection, and higher willingness-to-pay for convenience among higher-income travelers when choosing between driving, transit, and park-and-ride options.",
    "categories": [
      "cs.GT",
      "cs.AI",
      "eess.SY"
    ],
    "primary_category": "cs.GT",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.06260v1",
    "published_date": "2025-11-09 07:36:46 UTC",
    "updated_date": "2025-11-09 07:36:46 UTC"
  },
  {
    "arxiv_id": "2511.06259v1",
    "title": "Breaking the Modality Barrier: Generative Modeling for Accurate Molecule Retrieval from Mass Spectra",
    "authors": [
      "Yiwen Zhang",
      "Keyan Ding",
      "Yihang Wu",
      "Xiang Zhuang",
      "Yi Yang",
      "Qiang Zhang",
      "Huajun Chen"
    ],
    "abstract": "Retrieving molecular structures from tandem mass spectra is a crucial step in rapid compound identification. Existing retrieval methods, such as traditional mass spectral library matching, suffer from limited spectral library coverage, while recent cross-modal representation learning frameworks often encounter modality misalignment, resulting in suboptimal retrieval accuracy and generalization. To address these limitations, we propose GLMR, a Generative Language Model-based Retrieval framework that mitigates the cross-modal misalignment through a two-stage process. In the pre-retrieval stage, a contrastive learning-based model identifies top candidate molecules as contextual priors for the input mass spectrum. In the generative retrieval stage, these candidate molecules are integrated with the input mass spectrum to guide a generative model in producing refined molecular structures, which are then used to re-rank the candidates based on molecular similarity. Experiments on both MassSpecGym and the proposed MassRET-20k dataset demonstrate that GLMR significantly outperforms existing methods, achieving over 40% improvement in top-1 accuracy and exhibiting strong generalizability.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by AAAI 2026",
    "pdf_url": "https://arxiv.org/pdf/2511.06259v1",
    "published_date": "2025-11-09 07:25:53 UTC",
    "updated_date": "2025-11-09 07:25:53 UTC"
  },
  {
    "arxiv_id": "2511.06252v1",
    "title": "MrCoM: A Meta-Regularized World-Model Generalizing Across Multi-Scenarios",
    "authors": [
      "Xuantang Xiong",
      "Ni Mu",
      "Runpeng Xie",
      "Senhao Yang",
      "Yaqing Wang",
      "Lexiang Wang",
      "Yao Luan",
      "Siyuan Li",
      "Shuang Xu",
      "Yiqin Yang",
      "Bo Xu"
    ],
    "abstract": "Model-based reinforcement learning (MBRL) is a crucial approach to enhance the generalization capabilities and improve the sample efficiency of RL algorithms. However, current MBRL methods focus primarily on building world models for single tasks and rarely address generalization across different scenarios. Building on the insight that dynamics within the same simulation engine share inherent properties, we attempt to construct a unified world model capable of generalizing across different scenarios, named Meta-Regularized Contextual World-Model (MrCoM). This method first decomposes the latent state space into various components based on the dynamic characteristics, thereby enhancing the accuracy of world-model prediction. Further, MrCoM adopts meta-state regularization to extract unified representation of scenario-relevant information, and meta-value regularization to align world-model optimization with policy learning across diverse scenario objectives. We theoretically analyze the generalization error upper bound of MrCoM in multi-scenario settings. We systematically evaluate our algorithm's generalization ability across diverse scenarios, demonstrating significantly better performance than previous state-of-the-art methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.06252v1",
    "published_date": "2025-11-09 07:01:18 UTC",
    "updated_date": "2025-11-09 07:01:18 UTC"
  },
  {
    "arxiv_id": "2511.06251v1",
    "title": "WebVIA: A Web-based Vision-Language Agentic Framework for Interactive and Verifiable UI-to-Code Generation",
    "authors": [
      "Mingde Xu",
      "Zhen Yang",
      "Wenyi Hong",
      "Lihang Pan",
      "Xinyue Fan",
      "Yan Wang",
      "Xiaotao Gu",
      "Bin Xu",
      "Jie Tang"
    ],
    "abstract": "User interface (UI) development requires translating design mockups into functional code, a process that remains repetitive and labor-intensive. While recent Vision-Language Models (VLMs) automate UI-to-Code generation, they generate only static HTML/CSS/JavaScript layouts lacking interactivity. To address this, we propose WebVIA, the first agentic framework for interactive UI-to-Code generation and validation. The framework comprises three components: 1) an exploration agent to capture multi-state UI screenshots; 2) a UI2Code model that generates executable interactive code; 3) a validation module that verifies the interactivity. Experiments demonstrate that WebVIA-Agent achieves more stable and accurate UI exploration than general-purpose agents (e.g., Gemini-2.5-Pro). In addition, our fine-tuned WebVIA-UI2Code models exhibit substantial improvements in generating executable and interactive HTML/CSS/JavaScript code, outperforming their base counterparts across both interactive and static UI2Code benchmarks. Our code and models are available at \\href{https://zheny2751-dotcom.github.io/webvia.github.io/}{\\texttt{https://webvia.github.io}}.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "36 pages, 30 figures",
    "pdf_url": "https://arxiv.org/pdf/2511.06251v1",
    "published_date": "2025-11-09 06:58:52 UTC",
    "updated_date": "2025-11-09 06:58:52 UTC"
  },
  {
    "arxiv_id": "2511.06248v1",
    "title": "Constraint-Informed Active Learning for End-to-End ACOPF Optimization Proxies",
    "authors": [
      "Miao Li",
      "Michael Klamkin",
      "Pascal Van Hentenryck",
      "Wenting Li",
      "Russell Bent"
    ],
    "abstract": "This paper studies optimization proxies, machine learning (ML) models trained to efficiently predict optimal solutions for AC Optimal Power Flow (ACOPF) problems. While promising, optimization proxy performance heavily depends on training data quality. To address this limitation, this paper introduces a novel active sampling framework for ACOPF optimization proxies designed to generate realistic and diverse training data. The framework actively explores varied, flexible problem specifications reflecting plausible operational realities. More importantly, the approach uses optimization-specific quantities (active constraint sets) that better capture the salient features of an ACOPF that lead to the optimal solution. Numerical results show superior generalization over existing sampling methods with an equivalent training budget, significantly advancing the state-of-practice for trustworthy ACOPF optimization proxies.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "8 PAGES",
    "pdf_url": "https://arxiv.org/pdf/2511.06248v1",
    "published_date": "2025-11-09 06:18:38 UTC",
    "updated_date": "2025-11-09 06:18:38 UTC"
  },
  {
    "arxiv_id": "2511.06240v2",
    "title": "Affordance-Guided Coarse-to-Fine Exploration for Base Placement in Open-Vocabulary Mobile Manipulation",
    "authors": [
      "Tzu-Jung Lin",
      "Jia-Fong Yeh",
      "Hung-Ting Su",
      "Chung-Yi Lin",
      "Yi-Ting Chen",
      "Winston H. Hsu"
    ],
    "abstract": "In open-vocabulary mobile manipulation (OVMM), task success often hinges on the selection of an appropriate base placement for the robot. Existing approaches typically navigate to proximity-based regions without considering affordances, resulting in frequent manipulation failures. We propose Affordance-Guided Coarse-to-Fine Exploration, a zero-shot framework for base placement that integrates semantic understanding from vision-language models (VLMs) with geometric feasibility through an iterative optimization process. Our method constructs cross-modal representations, namely Affordance RGB and Obstacle Map+, to align semantics with spatial context. This enables reasoning that extends beyond the egocentric limitations of RGB perception. To ensure interaction is guided by task-relevant affordances, we leverage coarse semantic priors from VLMs to guide the search toward task-relevant regions and refine placements with geometric constraints, thereby reducing the risk of convergence to local optima. Evaluated on five diverse open-vocabulary mobile manipulation tasks, our system achieves an 85% success rate, significantly outperforming classical geometric planners and VLM-based methods. This demonstrates the promise of affordance-aware and multimodal reasoning for generalizable, instruction-conditioned planning in OVMM.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted to AAAI 2026",
    "pdf_url": "https://arxiv.org/pdf/2511.06240v2",
    "published_date": "2025-11-09 05:52:22 UTC",
    "updated_date": "2026-01-03 01:09:54 UTC"
  },
  {
    "arxiv_id": "2511.06237v1",
    "title": "Mixtures of SubExperts for Large Language Continual Learning",
    "authors": [
      "Haeyong Kang"
    ],
    "abstract": "Adapting Large Language Models (LLMs) to a continuous stream of tasks is a critical yet challenging endeavor. While Parameter-Efficient Fine-Tuning (PEFT) methods have become a standard for this, they face a fundamental dilemma in continual learning. Reusing a single set of PEFT parameters for new tasks often leads to catastrophic forgetting of prior knowledge. Conversely, allocating distinct parameters for each task prevents forgetting but results in a linear growth of the model's size and fails to facilitate knowledge transfer between related tasks. To overcome these limitations, we propose a novel adaptive PEFT method referred to as \\textit{Mixtures of SubExperts (MoSEs)}, a novel continual learning framework designed for minimal forgetting and efficient scalability. MoSEs integrate a sparse Mixture of SubExperts into the transformer layers, governed by a task-specific routing mechanism. This architecture allows the model to isolate and protect knowledge within dedicated SubExperts, thereby minimizing parameter interference and catastrophic forgetting. Crucially, the router can adaptively select and combine previously learned sparse parameters for new tasks, enabling effective knowledge transfer while ensuring that the model's capacity grows sublinearly. We evaluate MoSEs on the comprehensive TRACE benchmark datasets. Our experiments demonstrate that MoSEs significantly outperform conventional continual learning approaches in both knowledge retention and scalability to new tasks, achieving state-of-the-art performance with substantial memory and computational savings.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.06237v1",
    "published_date": "2025-11-09 05:44:45 UTC",
    "updated_date": "2025-11-09 05:44:45 UTC"
  },
  {
    "arxiv_id": "2511.06234v1",
    "title": "Analyzing and Mitigating Negation Artifacts using Data Augmentation for Improving ELECTRA-Small Model Accuracy",
    "authors": [
      "Mojtaba Noghabaei"
    ],
    "abstract": "Pre-trained models for natural language inference (NLI) often achieve high performance on benchmark datasets by using spurious correlations, or dataset artifacts, rather than understanding language touches such as negation. In this project, we investigate the performance of an ELECTRA-small model fine-tuned on the Stanford Natural Language Inference (SNLI) dataset, focusing on its handling of negation. Through analysis, we identify that the model struggles with correctly classifying examples containing negation. To address this, we augment the training data with contrast sets and adversarial examples emphasizing negation. Our results demonstrate that this targeted data augmentation improves the model's accuracy on negation-containing examples without adversely affecting overall performance, therefore mitigating the identified dataset artifact.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.06234v1",
    "published_date": "2025-11-09 05:25:46 UTC",
    "updated_date": "2025-11-09 05:25:46 UTC"
  },
  {
    "arxiv_id": "2511.06232v1",
    "title": "Scaling Laws and In-Context Learning: A Unified Theoretical Framework",
    "authors": [
      "Sushant Mehta",
      "Ishan Gupta"
    ],
    "abstract": "In-context learning (ICL) enables large language models to adapt to new tasks from demonstrations without parameter updates. Despite extensive empirical studies, a principled understanding of ICL emergence at scale remains more elusive. We present a unified theoretical framework connecting scaling laws to ICL emergence in transformers. Our analysis establishes that ICL performance follows power-law relationships with model depth $L$, width $d$, context length $k$, and training data $D$, with exponents determined by task structure. We show that under specific conditions, transformers implement gradient-based metalearning in their forward pass, with an effective learning rate $η_{\\text{eff}} = Θ(1/\\sqrt{Ld})$. We demonstrate sharp phase transitions at critical scales and derive optimal depth-width allocations favoring $L^* \\propto N^{2/3}$, $d^* \\propto N^{1/3}$ for the fixed parameter budget $N = Ld$. Systematic experiments on synthetic tasks validate our predictions, with measured scaling exponents closely matching theory. This work provides both necessary and sufficient conditions for the emergence of ICLs and establishes fundamental computational limits on what transformers can learn in-context.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.06232v1",
    "published_date": "2025-11-09 05:19:14 UTC",
    "updated_date": "2025-11-09 05:19:14 UTC"
  },
  {
    "arxiv_id": "2511.06230v1",
    "title": "Overview of CHIP 2025 Shared Task 2: Discharge Medication Recommendation for Metabolic Diseases Based on Chinese Electronic Health Records",
    "authors": [
      "Juntao Li",
      "Haobin Yuan",
      "Ling Luo",
      "Tengxiao Lv",
      "Yan Jiang",
      "Fan Wang",
      "Ping Zhang",
      "Huiyi Lv",
      "Jian Wang",
      "Yuanyuan Sun",
      "Hongfei Lin"
    ],
    "abstract": "Discharge medication recommendation plays a critical role in ensuring treatment continuity, preventing readmission, and improving long-term management for patients with chronic metabolic diseases. This paper present an overview of the CHIP 2025 Shared Task 2 competition, which aimed to develop state-of-the-art approaches for automatically recommending appro-priate discharge medications using real-world Chinese EHR data. For this task, we constructed CDrugRed, a high-quality dataset consisting of 5,894 de-identified hospitalization records from 3,190 patients in China. This task is challenging due to multi-label nature of medication recommendation, het-erogeneous clinical text, and patient-specific variability in treatment plans. A total of 526 teams registered, with 167 and 95 teams submitting valid results to the Phase A and Phase B leaderboards, respectively. The top-performing team achieved the highest overall performance on the final test set, with a Jaccard score of 0.5102, F1 score of 0.6267, demonstrating the potential of advanced large language model (LLM)-based ensemble systems. These re-sults highlight both the promise and remaining challenges of applying LLMs to medication recommendation in Chinese EHRs. The post-evaluation phase remains open at https://tianchi.aliyun.com/competition/entrance/532411/.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.06230v1",
    "published_date": "2025-11-09 05:11:27 UTC",
    "updated_date": "2025-11-09 05:11:27 UTC"
  },
  {
    "arxiv_id": "2511.06227v1",
    "title": "Assertion-Aware Test Code Summarization with Large Language Models",
    "authors": [
      "Anamul Haque Mollah",
      "Ahmed Aljohani",
      "Hyunsook Do"
    ],
    "abstract": "Unit tests often lack concise summaries that convey test intent, especially in auto-generated or poorly documented codebases. Large Language Models (LLMs) offer a promising solution, but their effectiveness depends heavily on how they are prompted. Unlike generic code summarization, test-code summarization poses distinct challenges because test methods validate expected behavior through assertions rather than implementing functionality. This paper presents a new benchmark of 91 real-world Java test cases paired with developer-written summaries and conducts a controlled ablation study to investigate how test code-related components-such as the method under test (MUT), assertion messages, and assertion semantics-affect the performance of LLM-generated test summaries. We evaluate four code LLMs (Codex, Codestral, DeepSeek, and Qwen-Coder) across seven prompt configurations using n-gram metrics (BLEU, ROUGE-L, METEOR), semantic similarity (BERTScore), and LLM-based evaluation. Results show that prompting with assertion semantics improves summary quality by an average of 0.10 points (2.3%) over full MUT context (4.45 vs. 4.35) while requiring fewer input tokens. Codex and Qwen-Coder achieve the highest alignment with human-written summaries, while DeepSeek underperforms despite high lexical overlap. The replication package is publicly available at https://doi.org/10. 5281/zenodo.17067550",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CE"
    ],
    "primary_category": "cs.SE",
    "comment": "Accepted for publication at 2nd ACM International Conference on AI-powered Software (AIware 2025)",
    "pdf_url": "https://arxiv.org/pdf/2511.06227v1",
    "published_date": "2025-11-09 04:58:32 UTC",
    "updated_date": "2025-11-09 04:58:32 UTC"
  },
  {
    "arxiv_id": "2511.06226v1",
    "title": "ROAR: Robust Accident Recognition and Anticipation for Autonomous Driving",
    "authors": [
      "Xingcheng Liu",
      "Yanchen Guan",
      "Haicheng Liao",
      "Zhengbing He",
      "Zhenning Li"
    ],
    "abstract": "Accurate accident anticipation is essential for enhancing the safety of autonomous vehicles (AVs). However, existing methods often assume ideal conditions, overlooking challenges such as sensor failures, environmental disturbances, and data imperfections, which can significantly degrade prediction accuracy. Additionally, previous models have not adequately addressed the considerable variability in driver behavior and accident rates across different vehicle types. To overcome these limitations, this study introduces ROAR, a novel approach for accident detection and prediction. ROAR combines Discrete Wavelet Transform (DWT), a self adaptive object aware module, and dynamic focal loss to tackle these challenges. The DWT effectively extracts features from noisy and incomplete data, while the object aware module improves accident prediction by focusing on high-risk vehicles and modeling the spatial temporal relationships among traffic agents. Moreover, dynamic focal loss mitigates the impact of class imbalance between positive and negative samples. Evaluated on three widely used datasets, Dashcam Accident Dataset (DAD), Car Crash Dataset (CCD), and AnAn Accident Detection (A3D), our model consistently outperforms existing baselines in key metrics such as Average Precision (AP) and mean Time to Accident (mTTA). These results demonstrate the model's robustness in real-world conditions, particularly in handling sensor degradation, environmental noise, and imbalanced data distributions. This work offers a promising solution for reliable and accurate accident anticipation in complex traffic environments.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Published to Accident Analysis and Prevention",
    "pdf_url": "https://arxiv.org/pdf/2511.06226v1",
    "published_date": "2025-11-09 04:55:37 UTC",
    "updated_date": "2025-11-09 04:55:37 UTC"
  },
  {
    "arxiv_id": "2511.06221v1",
    "title": "Tiny Model, Big Logic: Diversity-Driven Optimization Elicits Large-Model Reasoning Ability in VibeThinker-1.5B",
    "authors": [
      "Sen Xu",
      "Yi Zhou",
      "Wei Wang",
      "Jixin Min",
      "Zhibin Yin",
      "Yingwei Dai",
      "Shixi Liu",
      "Lianyu Pang",
      "Yirong Chen",
      "Junlin Zhang"
    ],
    "abstract": "Challenging the prevailing consensus that small models inherently lack robust reasoning, this report introduces VibeThinker-1.5B, a 1.5B-parameter dense model developed via our Spectrum-to-Signal Principle (SSP). This challenges the prevailing approach of scaling model parameters to enhance capabilities, as seen in models like DeepSeek R1 (671B) and Kimi k2 (>1T). The SSP framework first employs a Two-Stage Diversity-Exploring Distillation (SFT) to generate a broad spectrum of solutions, followed by MaxEnt-Guided Policy Optimization (RL) to amplify the correct signal. With a total training cost of only $7,800, VibeThinker-1.5B demonstrates superior reasoning capabilities compared to closed-source models like Magistral Medium and Claude Opus 4, and performs on par with open-source models like GPT OSS-20B Medium. Remarkably, it surpasses the 400x larger DeepSeek R1 on three math benchmarks: AIME24 (80.3 vs. 79.8), AIME25 (74.4 vs. 70.0), and HMMT25 (50.4 vs. 41.7). This is a substantial improvement over its base model (6.7, 4.3, and 0.6, respectively). On LiveCodeBench V6, it scores 51.1, outperforming Magistral Medium's 50.3 and its base model's 0.0. These findings demonstrate that small models can achieve reasoning capabilities comparable to large models, drastically reducing training and inference costs and thereby democratizing advanced AI research.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.06221v1",
    "published_date": "2025-11-09 04:37:36 UTC",
    "updated_date": "2025-11-09 04:37:36 UTC"
  },
  {
    "arxiv_id": "2511.06215v1",
    "title": "Explicit Knowledge-Guided In-Context Learning for Early Detection of Alzheimer's Disease",
    "authors": [
      "Puzhen Su",
      "Yongzhu Miao",
      "Chunxi Guo",
      "Jintao Tang",
      "Shasha Li",
      "Ting Wang"
    ],
    "abstract": "Detecting Alzheimer's Disease (AD) from narrative transcripts remains a challenging task for large language models (LLMs), particularly under out-of-distribution (OOD) and data-scarce conditions. While in-context learning (ICL) provides a parameter-efficient alternative to fine-tuning, existing ICL approaches often suffer from task recognition failure, suboptimal demonstration selection, and misalignment between label words and task objectives, issues that are amplified in clinical domains like AD detection. We propose Explicit Knowledge In-Context Learners (EK-ICL), a novel framework that integrates structured explicit knowledge to enhance reasoning stability and task alignment in ICL. EK-ICL incorporates three knowledge components: confidence scores derived from small language models (SLMs) to ground predictions in task-relevant patterns, parsing feature scores to capture structural differences and improve demo selection, and label word replacement to resolve semantic misalignment with LLM priors. In addition, EK-ICL employs a parsing-based retrieval strategy and ensemble prediction to mitigate the effects of semantic homogeneity in AD transcripts. Extensive experiments across three AD datasets demonstrate that EK-ICL significantly outperforms state-of-the-art fine-tuning and ICL baselines. Further analysis reveals that ICL performance in AD detection is highly sensitive to the alignment of label semantics and task-specific context, underscoring the importance of explicit knowledge in clinical reasoning under low-resource conditions.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "This paper was accepted by IEEE BIBM 2025 conference",
    "pdf_url": "https://arxiv.org/pdf/2511.06215v1",
    "published_date": "2025-11-09 04:01:45 UTC",
    "updated_date": "2025-11-09 04:01:45 UTC"
  },
  {
    "arxiv_id": "2511.08626v1",
    "title": "SAMora: Enhancing SAM through Hierarchical Self-Supervised Pre-Training for Medical Images",
    "authors": [
      "Shuhang Chen",
      "Hangjie Yuan",
      "Pengwei Liu",
      "Hanxue Gu",
      "Tao Feng",
      "Dong Ni"
    ],
    "abstract": "The Segment Anything Model (SAM) has demonstrated significant potential in medical image segmentation. Yet, its performance is limited when only a small amount of labeled data is available, while there is abundant valuable yet often overlooked hierarchical information in medical data. To address this limitation, we draw inspiration from self-supervised learning and propose SAMora, an innovative framework that captures hierarchical medical knowledge by applying complementary self-supervised learning objectives at the image, patch, and pixel levels. To fully exploit the complementarity of hierarchical knowledge within LoRAs, we introduce HL-Attn, a hierarchical fusion module that integrates multi-scale features while maintaining their distinct characteristics. SAMora is compatible with various SAM variants, including SAM2, SAMed, and H-SAM. Experimental results on the Synapse, LA, and PROMISE12 datasets demonstrate that SAMora outperforms existing SAM variants. It achieves state-of-the-art performance in both few-shot and fully supervised settings while reducing fine-tuning epochs by 90%. The code is available at https://github.com/ShChen233/SAMora.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.08626v1",
    "published_date": "2025-11-09 03:54:51 UTC",
    "updated_date": "2025-11-09 03:54:51 UTC"
  },
  {
    "arxiv_id": "2511.06212v1",
    "title": "RAG-targeted Adversarial Attack on LLM-based Threat Detection and Mitigation Framework",
    "authors": [
      "Seif Ikbarieh",
      "Kshitiz Aryal",
      "Maanak Gupta"
    ],
    "abstract": "The rapid expansion of the Internet of Things (IoT) is reshaping communication and operational practices across industries, but it also broadens the attack surface and increases susceptibility to security breaches. Artificial Intelligence has become a valuable solution in securing IoT networks, with Large Language Models (LLMs) enabling automated attack behavior analysis and mitigation suggestion in Network Intrusion Detection Systems (NIDS). Despite advancements, the use of LLMs in such systems further expands the attack surface, putting entire networks at risk by introducing vulnerabilities such as prompt injection and data poisoning. In this work, we attack an LLM-based IoT attack analysis and mitigation framework to test its adversarial robustness. We construct an attack description dataset and use it in a targeted data poisoning attack that applies word-level, meaning-preserving perturbations to corrupt the Retrieval-Augmented Generation (RAG) knowledge base of the framework. We then compare pre-attack and post-attack mitigation responses from the target model, ChatGPT-5 Thinking, to measure the impact of the attack on model performance, using an established evaluation rubric designed for human experts and judge LLMs. Our results show that small perturbations degrade LLM performance by weakening the linkage between observed network traffic features and attack behavior, and by reducing the specificity and practicality of recommended mitigations for resource-constrained devices.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.06212v1",
    "published_date": "2025-11-09 03:50:17 UTC",
    "updated_date": "2025-11-09 03:50:17 UTC"
  },
  {
    "arxiv_id": "2511.06209v3",
    "title": "Efficient Test-Time Scaling of Multi-Step Reasoning by Probing Internal States of Large Language Models",
    "authors": [
      "Jingwei Ni",
      "Ekaterina Fadeeva",
      "Tianyi Wu",
      "Mubashara Akhtar",
      "Jiaheng Zhang",
      "Elliott Ash",
      "Markus Leippold",
      "Timothy Baldwin",
      "See-Kiong Ng",
      "Artem Shelmanov",
      "Mrinmaya Sachan"
    ],
    "abstract": "LLMs can solve complex tasks by generating long, multi-step reasoning chains. Test-time scaling (TTS) can further improve LLM performance by sampling multiple variants of intermediate reasoning steps, verifying their correctness, and strategically choosing the best steps for continuation. However, existing verification approaches, such as Process Reward Models (PRMs), are computationally expensive, limited to specific domains, and require large-scale human or model-generated annotations. We propose a lightweight alternative for step-level reasoning verification based on probing the internal states of LLMs. We train a transformer-based probe that uses the internal states of the frozen LLM to estimate the credibility of its reasoning steps during generation. Annotation can be generated either by another larger LLM (e.g., DeepSeek-R1) or in a self-supervised manner by the original model itself. The probes are both effective and lightweight, containing fewer than 10M parameters. Across multiple domains, including mathematics, planning, and general knowledge question answering, our probes match or even exceed the performance of PRMs that are up to 810x larger. Our findings suggest that the internal states of LLMs encode their confidence in reasoning processes and can serve as reliable signals for reasoning step verification, offering a promising direction towards scalable and generalizable TTS and introspective LLMs.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "Preprint under review",
    "pdf_url": "https://arxiv.org/pdf/2511.06209v3",
    "published_date": "2025-11-09 03:38:29 UTC",
    "updated_date": "2026-01-14 10:08:56 UTC"
  },
  {
    "arxiv_id": "2511.06208v2",
    "title": "Resilience Inference for Supply Chains with Hypergraph Neural Network",
    "authors": [
      "Zetian Shen",
      "Hongjun Wang",
      "Jiyuan Chen",
      "Xuan Song"
    ],
    "abstract": "Supply chains are integral to global economic stability, yet disruptions can swiftly propagate through interconnected networks, resulting in substantial economic impacts. Accurate and timely inference of supply chain resilience the capability to maintain core functions during disruptions is crucial for proactive risk mitigation and robust network design. However, existing approaches lack effective mechanisms to infer supply chain resilience without explicit system dynamics and struggle to represent the higher-order, multi-entity dependencies inherent in supply chain networks. These limitations motivate the definition of a novel problem and the development of targeted modeling solutions. To address these challenges, we formalize a novel problem: Supply Chain Resilience Inference (SCRI), defined as predicting supply chain resilience using hypergraph topology and observed inventory trajectories without explicit dynamic equations. To solve this problem, we propose the Supply Chain Resilience Inference Hypergraph Network (SC-RIHN), a novel hypergraph-based model leveraging set-based encoding and hypergraph message passing to capture multi-party firm-product interactions. Comprehensive experiments demonstrate that SC-RIHN significantly outperforms traditional MLP, representative graph neural network variants, and ResInf baselines across synthetic benchmarks, underscoring its potential for practical, early-warning risk assessment in complex supply chain systems.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.06208v2",
    "published_date": "2025-11-09 03:34:45 UTC",
    "updated_date": "2025-12-04 05:30:32 UTC"
  },
  {
    "arxiv_id": "2511.06197v1",
    "title": "Enhancing Adversarial Robustness of IoT Intrusion Detection via SHAP-Based Attribution Fingerprinting",
    "authors": [
      "Dilli Prasad Sharma",
      "Liang Xue",
      "Xiaowei Sun",
      "Xiaodong Lin",
      "Pulei Xiong"
    ],
    "abstract": "The rapid proliferation of Internet of Things (IoT) devices has transformed numerous industries by enabling seamless connectivity and data-driven automation. However, this expansion has also exposed IoT networks to increasingly sophisticated security threats, including adversarial attacks targeting artificial intelligence (AI) and machine learning (ML)-based intrusion detection systems (IDS) to deliberately evade detection, induce misclassification, and systematically undermine the reliability and integrity of security defenses. To address these challenges, we propose a novel adversarial detection model that enhances the robustness of IoT IDS against adversarial attacks through SHapley Additive exPlanations (SHAP)-based fingerprinting. Using SHAP's DeepExplainer, we extract attribution fingerprints from network traffic features, enabling the IDS to reliably distinguish between clean and adversarially perturbed inputs. By capturing subtle attribution patterns, the model becomes more resilient to evasion attempts and adversarial manipulations. We evaluated the model on a standard IoT benchmark dataset, where it significantly outperformed a state-of-the-art method in detecting adversarial attacks. In addition to enhanced robustness, this approach improves model transparency and interpretability, thereby increasing trust in the IDS through explainable AI.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.NI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.06197v1",
    "published_date": "2025-11-09 02:56:54 UTC",
    "updated_date": "2025-11-09 02:56:54 UTC"
  },
  {
    "arxiv_id": "2511.06195v1",
    "title": "AI as intermediary in modern-day ritual: An immersive, interactive production of the roller disco musical Xanadu at UCLA",
    "authors": [
      "Mira Winick",
      "Naisha Agarwal",
      "Chiheb Boussema",
      "Ingrid Lee",
      "Camilo Vargas",
      "Jeff Burke"
    ],
    "abstract": "Interfaces for contemporary large language, generative media, and perception AI models are often engineered for single user interaction. We investigate ritual as a design scaffold for developing collaborative, multi-user human-AI engagement. We consider the specific case of an immersive staging of the musical Xanadu performed at UCLA in Spring 2025. During a two-week run, over five hundred audience members contributed sketches and jazzercise moves that vision language models translated to virtual scenery elements and from choreographic prompts. This paper discusses four facets of interaction-as-ritual within the show: audience input as offerings that AI transforms into components of the ritual; performers as ritual guides, demonstrating how to interact with technology and sorting audience members into cohorts; AI systems as instruments \"played\" by the humans, in which sensing, generative components, and stagecraft create systems that can be mastered over time; and reciprocity of interaction, in which the show's AI machinery guides human behavior as well as being guided by humans, completing a human-AI feedback loop that visibly reshapes the virtual world. Ritual served as a frame for integrating linear narrative, character identity, music and interaction. The production explored how AI systems can support group creativity and play, addressing a critical gap in prevailing single user AI design paradigms.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.06195v1",
    "published_date": "2025-11-09 02:45:19 UTC",
    "updated_date": "2025-11-09 02:45:19 UTC"
  },
  {
    "arxiv_id": "2511.06185v1",
    "title": "Dataforge: A Data Agent Platform for Autonomous Data Engineering",
    "authors": [
      "Xinyuan Wang",
      "Yanjie Fu"
    ],
    "abstract": "The growing demand for AI applications in fields such as materials discovery, molecular modeling, and climate science has made data preparation an important but labor-intensive step. Raw data from diverse sources must be cleaned, normalized, and transformed to become AI-ready, while effective feature transformation and selection are essential for efficient training and inference. To address the challenges of scalability and expertise dependence, we present Data Agent, a fully autonomous system specialized for tabular data. Leveraging large language model (LLM) reasoning and grounded validation, Data Agent automatically performs data cleaning, hierarchical routing, and feature-level optimization through dual feedback loops. It embodies three core principles: automatic, safe, and non-expert friendly, which ensure end-to-end reliability without human supervision. This demo showcases the first practical realization of an autonomous Data Agent, illustrating how raw data can be transformed \"From Data to Better Data.\"",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.06185v1",
    "published_date": "2025-11-09 01:58:13 UTC",
    "updated_date": "2025-11-09 01:58:13 UTC"
  },
  {
    "arxiv_id": "2511.06179v1",
    "title": "MemoriesDB: A Temporal-Semantic-Relational Database for Long-Term Agent Memory / Modeling Experience as a Graph of Temporal-Semantic Surfaces",
    "authors": [
      "Joel Ward"
    ],
    "abstract": "We introduce MemoriesDB, a unified data architecture designed to avoid decoherence across time, meaning, and relation in long-term computational memory. Each memory is a time-semantic-relational entity-a structure that simultaneously encodes when an event occurred, what it means, and how it connects to other events. Built initially atop PostgreSQL with pgvector extensions, MemoriesDB combines the properties of a time-series datastore, a vector database, and a graph system within a single append-only schema. Each memory is represented as a vertex uniquely labeled by its microsecond timestamp and accompanied by low- and high-dimensional normalized embeddings that capture semantic context. Directed edges between memories form labeled relations with per-edge metadata, enabling multiple contextual links between the same vertices. Together these constructs form a time-indexed stack of temporal-semantic surfaces, where edges project as directional arrows in a 1+1-dimensional similarity field, tracing the evolution of meaning through time while maintaining cross-temporal coherence. This formulation supports efficient time-bounded retrieval, hybrid semantic search, and lightweight structural reasoning in a single query path. A working prototype demonstrates scalable recall and contextual reinforcement using standard relational infrastructure, and we discuss extensions toward a columnar backend, distributed clustering, and emergent topic modeling.",
    "categories": [
      "cs.DB",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.DB",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.06179v1",
    "published_date": "2025-11-09 01:41:55 UTC",
    "updated_date": "2025-11-09 01:41:55 UTC"
  },
  {
    "arxiv_id": "2511.06175v1",
    "title": "CSP4SDG: Constraint and Information-Theory Based Role Identification in Social Deduction Games with LLM-Enhanced Inference",
    "authors": [
      "Kaijie Xu",
      "Fandi Meng",
      "Clark Verbrugge",
      "Simon Lucas"
    ],
    "abstract": "In Social Deduction Games (SDGs) such as Avalon, Mafia, and Werewolf, players conceal their identities and deliberately mislead others, making hidden-role inference a central and demanding task. Accurate role identification, which forms the basis of an agent's belief state, is therefore the keystone for both human and AI performance. We introduce CSP4SDG, a probabilistic, constraint-satisfaction framework that analyses gameplay objectively. Game events and dialogue are mapped to four linguistically-agnostic constraint classes-evidence, phenomena, assertions, and hypotheses. Hard constraints prune impossible role assignments, while weighted soft constraints score the remainder; information-gain weighting links each hypothesis to its expected value under entropy reduction, and a simple closed-form scoring rule guarantees that truthful assertions converge to classical hard logic with minimum error. The resulting posterior over roles is fully interpretable and updates in real time. Experiments on three public datasets show that CSP4SDG (i) outperforms LLM-based baselines in every inference scenario, and (ii) boosts LLMs when supplied as an auxiliary \"reasoning tool.\" Our study validates that principled probabilistic reasoning with information theory is a scalable alternative-or complement-to heavy-weight neural models for SDGs.",
    "categories": [
      "cs.AI",
      "cs.GT"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.06175v1",
    "published_date": "2025-11-09 01:20:18 UTC",
    "updated_date": "2025-11-09 01:20:18 UTC"
  },
  {
    "arxiv_id": "2511.06174v1",
    "title": "LUT-LLM: Efficient Large Language Model Inference with Memory-based Computations on FPGAs",
    "authors": [
      "Zifan He",
      "Shengyu Ye",
      "Rui Ma",
      "Yang Wang",
      "Jason Cong"
    ],
    "abstract": "The rapid progress of large language models (LLMs) has advanced numerous applications, yet efficient single-batch inference remains vital for on-device intelligence. While FPGAs offer fine-grained data control and high energy efficiency, recent GPU optimizations have narrowed their advantage, especially under arithmetic-based computation. To overcome this, we leverage FPGAs' abundant on-chip memory to shift LLM inference from arithmetic- to memory-based computation through table lookups. We present LUT-LLM, the first FPGA accelerator enabling 1B+ LLM inference via vector-quantized memory operations. Our analysis identifies activation-weight co-quantization as the most effective scheme, supported by (1) bandwidth-aware parallel centroid search, (2) efficient 2D table lookups, and (3) a spatial-temporal hybrid design minimizing data caching. Implemented on an AMD V80 FPGA for a customized Qwen 3 1.7B model, LUT-LLM achieves 1.66x lower latency than AMD MI210 and 1.72x higher energy efficiency than NVIDIA A100, scaling to 32B models with 2.16x efficiency gain over A100.",
    "categories": [
      "cs.AR",
      "cs.AI"
    ],
    "primary_category": "cs.AR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.06174v1",
    "published_date": "2025-11-09 01:17:08 UTC",
    "updated_date": "2025-11-09 01:17:08 UTC"
  },
  {
    "arxiv_id": "2511.08625v2",
    "title": "Cross-Field Interface-Aware Neural Operators for Multiphase Flow Simulation",
    "authors": [
      "Zhenzhong Wang",
      "Xin Zhang",
      "Jun Liao",
      "Min Jiang"
    ],
    "abstract": "Multiphase flow simulation is critical in science and engineering but incurs high computational costs due to complex field discontinuities and the need for high-resolution numerical meshes. While Neural Operators (NOs) offer an efficient alternative for solving Partial Differential Equations (PDEs), they struggle with two core challenges unique to multiphase systems: spectral bias caused by spatial heterogeneity at phase interfaces, and the persistent scarcity of expensive, high-resolution field data. This work introduces the Interface Information Aware Neural Operator (IANO), a novel architecture that mitigates these issues by leveraging readily obtainable interface data (e.g., topology and position). Interface data inherently contains the high-frequency features not only necessary to complement the physical field data, but also help with spectral bias. IANO incorporates an interface-aware function encoding mechanism to capture dynamic coupling, and a geometry-aware positional encoding method to enhance spatial fidelity for pointwise super-resolution. Empirical results across multiple multiphase flow cases demonstrate that IANO achieves significant accuracy improvements (up to $\\sim$10\\%) over existing NO baselines. Furthermore, IANO exhibits superior generalization capabilities in low-data and noisy settings, confirming its utility for practical, data-efficient $\\text{AI}$-based multiphase flow simulations.",
    "categories": [
      "physics.flu-dyn",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "physics.flu-dyn",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.08625v2",
    "published_date": "2025-11-09 01:13:40 UTC",
    "updated_date": "2025-12-03 02:48:25 UTC"
  },
  {
    "arxiv_id": "2511.06172v1",
    "title": "MambaOVSR: Multiscale Fusion with Global Motion Modeling for Chinese Opera Video Super-Resolution",
    "authors": [
      "Hua Chang",
      "Xin Xu",
      "Wei Liu",
      "Wei Wang",
      "Xin Yuan",
      "Kui Jiang"
    ],
    "abstract": "Chinese opera is celebrated for preserving classical art. However, early filming equipment limitations have degraded videos of last-century performances by renowned artists (e.g., low frame rates and resolution), hindering archival efforts. Although space-time video super-resolution (STVSR) has advanced significantly, applying it directly to opera videos remains challenging. The scarcity of datasets impedes the recovery of high frequency details, and existing STVSR methods lack global modeling capabilities, compromising visual quality when handling opera's characteristic large motions. To address these challenges, we pioneer a large scale Chinese Opera Video Clip (COVC) dataset and propose the Mamba-based multiscale fusion network for space-time Opera Video Super-Resolution (MambaOVSR). Specifically, MambaOVSR involves three novel components: the Global Fusion Module (GFM) for motion modeling through a multiscale alternating scanning mechanism, and the Multiscale Synergistic Mamba Module (MSMM) for alignment across different sequence lengths. Additionally, our MambaVR block resolves feature artifacts and positional information loss during alignment. Experimental results on the COVC dataset show that MambaOVSR significantly outperforms the SOTA STVSR method by an average of 1.86 dB in terms of PSNR. Dataset and Code will be publicly released.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2511.06172v1",
    "published_date": "2025-11-09 00:53:58 UTC",
    "updated_date": "2025-11-09 00:53:58 UTC"
  },
  {
    "arxiv_id": "2511.06168v2",
    "title": "Chain-of-Thought as a Lens: Evaluating Structured Reasoning Alignment between Human Preferences and Large Language Models",
    "authors": [
      "Boxuan Wang",
      "Zhuoyun Li",
      "Xinmiao Huang",
      "Xiaowei Huang",
      "Yi Dong"
    ],
    "abstract": "This paper primarily demonstrate a method to quantitatively assess the alignment between multi-step, structured reasoning in large language models and human preferences. We introduce the Alignment Score, a semantic-level metric that compares a model-produced chain of thought traces with a human-preferred reference by constructing semantic-entropy-based matrices over intermediate steps and measuring their divergence. Our analysis shows that Alignment Score tracks task accuracy across models and hop depths, and peaks at 2-hop reasoning. Empirical results further indicates that misalignment at greater reasoning depths is driven mainly by alignment errors such as thematic shift and redundant reasoning. Viewing chain sampling as drawing from a distribution over reasoning paths, we empirically demonstrate a strong and consistent correlation between Alignment Score and accuracy performance, supporting its use as a meaningful diagnostic signal for structured reasoning.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Pre-print, 16 pages, 4 figures",
    "pdf_url": "https://arxiv.org/pdf/2511.06168v2",
    "published_date": "2025-11-09 00:27:38 UTC",
    "updated_date": "2026-01-07 15:50:40 UTC"
  }
]