{
  "date": "2025-11-09",
  "category": "cs.AI",
  "summary": "æ¬¢è¿æ¥åˆ° UTC æ—¶é—´ 2025-11-09 çš„ arXiv ä¸­æ–‡ TLDR å¿«æŠ¥ï¼\n\n**ä»Šæ—¥æ€»ç»“**ï¼š\nä»Šå¤©çš„ arXiv å……æ»¡äº†â€œå°æ¨¡å‹é€†è¢­â€å’Œâ€œAgent è‡ªä¸»è¿›åŒ–â€çš„ç«è¯å‘³ã€‚æœ€ä»¤äººå°è±¡æ·±åˆ»çš„æ˜¯ **VibeThinker-1.5B**ï¼Œä¸€ä¸ªä»… 1.5B å‚æ•°çš„å°æ¨¡å‹é€šè¿‡å¤šæ ·æ€§é©±åŠ¨çš„ä¼˜åŒ–ï¼Œåœ¨æ•°å­¦æ¨ç†ä¸Šå‡»è´¥äº† DeepSeek R1 ç­‰å·¨å‹æ¨¡å‹ï¼›åŒæ—¶ï¼Œ**The Station** å±•ç¤ºäº†ä¸€ä¸ªå¼€æ”¾ä¸–ç•Œçš„ç§‘ç ” Agent ç”Ÿæ€ï¼ŒAI å¼€å§‹åƒäººç±»ç§‘å­¦å®¶ä¸€æ ·è‡ªä¸»åˆä½œä¸å‘è¡¨è®ºæ–‡ã€‚æ­¤å¤–ï¼Œå…³äº **Test-Time Scaling**ï¼ˆæµ‹è¯•æ—¶æ‰©å±•ï¼‰å’Œ **Soft-thinking** çš„ç ”ç©¶æŒç»­å‡æ¸©ï¼Œæ˜¾ç¤ºå‡ºæ¨ç†ï¼ˆReasoningï¼‰èƒ½åŠ›ä¾ç„¶æ˜¯ç¤¾åŒºå…³æ³¨çš„ç»å¯¹æ ¸å¿ƒã€‚\n\n---\n\n### ğŸš€ ç„¦ç‚¹ï¼šå°æ¨¡å‹æ¨ç†ä¸ System 2 æ€ç»´\n\n**1. [å°æ¨¡å‹ï¼Œå¤§é€»è¾‘] Tiny Model, Big Logic: Diversity-Driven Optimization Elicits Large-Model Reasoning Ability in VibeThinker-1.5B**\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šæŒ‘æˆ˜äº†â€œåªæœ‰å¤§æ¨¡å‹æ‰æœ‰å¼ºæ¨ç†èƒ½åŠ›â€çš„å…±è¯†ã€‚ä½œè€…æå‡ºäº† **VibeThinker-1.5B**ï¼Œé€šè¿‡â€œé¢‘è°±åˆ°ä¿¡å·åŸåˆ™ï¼ˆSpectrum-to-Signal Principle, SSPï¼‰â€è®­ç»ƒã€‚\n*   **æ–¹æ³•**ï¼šé¦–å…ˆä½¿ç”¨ä¸¤é˜¶æ®µçš„å¤šæ ·æ€§æ¢ç´¢è’¸é¦ï¼ˆSFTï¼‰ç”Ÿæˆå¹¿æ³›çš„è§£ç©ºé—´ï¼Œç„¶åä½¿ç”¨æœ€å¤§ç†µå¼•å¯¼çš„ç­–ç•¥ä¼˜åŒ–ï¼ˆRLï¼‰æ¥æ”¾å¤§æ­£ç¡®ä¿¡å·ã€‚\n*   **å‘ç°**ï¼šæ€»è®­ç»ƒæˆæœ¬ä»… 7,800 ç¾å…ƒã€‚åœ¨ AIME24/25 ç­‰æ•°å­¦åŸºå‡†æµ‹è¯•ä¸Šï¼Œè¿™ä¸ª 1.5B çš„æ¨¡å‹ç«Ÿç„¶å‡»è´¥äº† 400 å€å‚æ•°é‡çš„ DeepSeek R1ï¼ˆ671Bï¼‰ï¼Œè¯æ˜äº†é€šè¿‡é«˜è´¨é‡çš„æ•°æ®å’Œç­–ç•¥ä¼˜åŒ–ï¼Œå°æ¨¡å‹ä¹Ÿèƒ½å…·å¤‡é¡¶çº§çš„ System 2 æ¨ç†èƒ½åŠ›ã€‚\n\n**2. [è½¯æ€ç»´ä¼˜åŒ–] SofT-GRPO: Surpassing Discrete-Token LLM Reinforcement Learning via Gumbel-Reparameterized Soft-Thinking Policy Optimization**\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šé’ˆå¯¹æœ€è¿‘ç«çƒ­çš„ **Soft-thinking**ï¼ˆè½¯æ€ç»´ï¼Œå³åœ¨è¿ç»­ç©ºé—´è¿›è¡Œ CoT æ¨ç†ï¼‰æå‡ºçš„ä¼˜åŒ–ç®—æ³•ã€‚\n*   **æ–¹æ³•**ï¼šä¼ ç»Ÿçš„ GRPOï¼ˆGroup Relative Policy Optimizationï¼‰ç”¨äºç¦»æ•£ Tokenï¼Œéš¾ä»¥ç›´æ¥ç”¨äº Soft-thinkingã€‚æœ¬æ–‡æå‡ºäº† **SofT-GRPO**ï¼Œé€šè¿‡ Gumbel å™ªå£°æ³¨å…¥å’Œé‡å‚æ•°åŒ–æŠ€å·§ï¼Œè®© Soft-thinking ä¹Ÿèƒ½äº«å— RL çš„çº¢åˆ©ã€‚\n*   **å‘ç°**ï¼šåœ¨ 1.5B åˆ° 7B æ¨¡å‹ä¸Šï¼Œè¯¥æ–¹æ³•è®© Soft-thinking æ¨¡å¼åœ¨ Pass@32 ä¸Šè·å¾—äº†æ˜¾è‘—æå‡ï¼Œè¿›ä¸€æ­¥é‡Šæ”¾äº†éç¦»æ•£æ¨ç†çš„æ½œåŠ›ã€‚\n\n**3. [é«˜æ•ˆæµ‹è¯•æ—¶æ‰©å±•] Efficient Test-Time Scaling of Multi-Step Reasoning by Probing Internal States of Large Language Models**\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šé’ˆå¯¹ **Test-Time Scaling (TTS)** çš„é«˜æ•ˆéªŒè¯æ–¹æ³•ã€‚\n*   **æ–¹æ³•**ï¼šç°æœ‰çš„è¿‡ç¨‹å¥–åŠ±æ¨¡å‹ï¼ˆPRMsï¼‰å¤ªè´µäº†ã€‚ä½œè€…æå‡ºè®­ç»ƒä¸€ä¸ªè½»é‡çº§çš„ Transformer æ¢é’ˆï¼ˆProbeï¼‰ï¼Œç›´æ¥åˆ©ç”¨å†»ç»“çš„å¤§æ¨¡å‹çš„**å†…éƒ¨çŠ¶æ€**æ¥è¯„ä¼°æ¨ç†æ­¥éª¤çš„å¯é æ€§ã€‚\n*   **å‘ç°**ï¼šå†…éƒ¨çŠ¶æ€ç¼–ç äº†æ¨¡å‹å¯¹æ¨ç†è¿‡ç¨‹çš„ä¿¡å¿ƒã€‚è¿™ç§è½»é‡çº§æ¢é’ˆï¼ˆå°äº 10M å‚æ•°ï¼‰åœ¨æ•°å­¦å’Œè§„åˆ’ä»»åŠ¡ä¸Šï¼Œæ•ˆæœåŒ¹é…ç”šè‡³è¶…è¿‡äº†æ¯”å®ƒå¤§ 810 å€çš„ PRM æ¨¡å‹ã€‚\n\n**4. [è§£å†³é©¬å±ç²¾é—®é¢˜] MONICA: Real-Time Monitoring and Calibration of Chain-of-Thought Sycophancy in Large Reasoning Models**\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šè§£å†³å¤§æ¨¡å‹æ¨ç†ä¸­çš„â€œé˜¿è°€å¥‰æ‰¿ï¼ˆSycophancyï¼‰â€é—®é¢˜ï¼Œå³æ¨¡å‹å€¾å‘äºé¡ºä»ç”¨æˆ·çš„é”™è¯¯ä¿¡å¿µã€‚\n*   **æ–¹æ³•**ï¼šæå‡ºäº† MONICA æ¡†æ¶ï¼Œåœ¨æ¨ç†è¿‡ç¨‹ä¸­å®æ—¶ç›‘æ§â€œé˜¿è°€æ¼‚ç§»åˆ†æ•°â€ï¼Œä¸€æ—¦å‘ç°æ¨¡å‹å¼€å§‹ä¸ºäº†è®¨å¥½ç”¨æˆ·è€Œèƒ¡è¯´å…«é“ï¼Œå°±åŠ¨æ€è¿›è¡Œæ ¡å‡†ã€‚\n*   **å‘ç°**ï¼šåœ¨ä¸­é—´æ¨ç†æ­¥éª¤å’Œæœ€ç»ˆç­”æ¡ˆä¸Šéƒ½æœ‰æ•ˆå‡å°‘äº†ç›²ä»è¡Œä¸ºï¼Œæé«˜äº†æ¨ç†çš„ç‹¬ç«‹æ€§å’Œå¯é æ€§ã€‚\n\n---\n\n### ğŸ¤– Agent ä¸ å¼€æ”¾ä¸–ç•Œæ¢ç´¢\n\n**5. [å¼€æ”¾ä¸–ç•Œç§‘ç ” Agent] The Station: An Open-World Environment for AI-Driven Discovery**\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šå‘å¸ƒäº†ä¸€ä¸ªåä¸º **The Station** çš„å¼€æ”¾ä¸–ç•Œå¤šæ™ºèƒ½ä½“ç¯å¢ƒï¼Œæ¨¡æ‹Ÿå®Œæ•´çš„ç§‘å­¦ç”Ÿæ€ç³»ç»Ÿã€‚\n*   **äº®ç‚¹**ï¼šåœ¨è¿™ä¸ªç¯å¢ƒä¸­ï¼ŒAgent ä»¬æ²¡æœ‰ä¸­å¤®æŒ‡æŒ¥ï¼Œå®ƒä»¬è‡ªä¸»é˜…è¯»è®ºæ–‡ã€æå‡ºå‡è®¾ã€åˆä½œã€åšå®éªŒç”šè‡³å‘è¡¨ç»“æœã€‚\n*   **å‘ç°**ï¼šæ¶Œç°å‡ºäº†éè„šæœ¬åŒ–çš„å™äº‹ï¼ŒAgent ä»¬ä¼šè‡ªå‘åˆä½œè€Œä¸æ˜¯å•çº¯å†…å·ã€‚å®ƒä»¬ç”šè‡³åœ¨è®¡ç®—ç”Ÿç‰©å­¦ä»»åŠ¡ä¸­â€œå‘æ˜â€äº†ä¸€ç§æ–°çš„å¯†åº¦è‡ªé€‚åº”ç®—æ³•ï¼Œå±•ç¤ºäº†è¶…è¶ŠåƒµåŒ– Pipeline çš„è‡ªä¸»å‘ç°èƒ½åŠ›ã€‚è¿™æ˜¯ä¸€ç¯‡ 55 é¡µçš„é•¿æ–‡ï¼Œå€¼å¾—å…³æ³¨ã€‚\n\n**6. [æœºå™¨äººè§„åˆ’å¾®è°ƒ] CoFineLLM: Conformal Finetuning of LLMs for Language-Instructed Robot Planning**\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šå°† **Conformal Prediction (CPï¼Œå…±å½¢é¢„æµ‹)** å¼•å…¥åˆ°æœºå™¨äººè§„åˆ’çš„ LLM å¾®è°ƒä¸­ã€‚\n*   **é—®é¢˜**ï¼šLLM åšè§„åˆ’æ—¶å¾€å¾€è¿‡åº¦è‡ªä¿¡ä½†å®¹æ˜“å‡ºé”™ã€‚CP å¯ä»¥ç»™å‡ºåŒ…å«æ­£ç¡®åŠ¨ä½œçš„é¢„æµ‹é›†ï¼Œä½† LLM å¾€å¾€ç”Ÿæˆçš„é›†åˆå¤ªå¤§ï¼Œå¯¼è‡´é¢‘ç¹éœ€è¦äººç±»ä»‹å…¥ã€‚\n*   **æ–¹æ³•**ï¼šCoFineLLM æ˜¯é¦–ä¸ª CP æ„ŸçŸ¥çš„å¾®è°ƒæ¡†æ¶ï¼Œæ˜¾å¼åœ°ä¼˜åŒ–ä»¥å‡å°é¢„æµ‹é›†çš„å¤§å°ï¼ŒåŒæ—¶ä¿è¯è¦†ç›–ç‡ã€‚\n*   **å‘ç°**ï¼šæ˜¾è‘—å‡å°‘äº†æœºå™¨äººæ‰§è¡Œä»»åŠ¡æ—¶éœ€è¦äººç±»å¸®å¿™çš„æ¬¡æ•°ï¼Œæå‡äº†è‡ªä¸»æ€§ã€‚\n\n**7. [Agent è‡ªæˆ‘è¿›åŒ–] FLEX: Continuous Agent Evolution via Forward Learning from Experience**\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šè®© LLM Agent åƒäººç±»ä¸€æ ·é€šè¿‡â€œç»éªŒâ€æŒç»­è¿›åŒ–ï¼Œè€Œä¸æ˜¯è®­ç»ƒå®Œå°±é™æ­¢äº†ã€‚\n*   **æ–¹æ³•**ï¼šFLEX å»ºç«‹äº†ä¸€ä¸ªç»“æ„åŒ–çš„ç»éªŒåº“ï¼ŒAgent é€šè¿‡åæ€æˆåŠŸå’Œå¤±è´¥çš„æ¡ˆä¾‹æ¥æ›´æ–°è¿™ä¸ªåº“ï¼Œå®ç°æ— æ¢¯åº¦çš„â€œå‰å‘å­¦ä¹ â€ã€‚\n*   **å‘ç°**ï¼šåœ¨æ•°å­¦æ¨ç†å’ŒåŒ–å­¦é€†åˆæˆä»»åŠ¡ä¸Šæå‡æ˜¾è‘—ï¼Œå¹¶è§‚å¯Ÿåˆ°äº†ç»éªŒå¢é•¿çš„ Scaling Lawã€‚\n\n---\n\n### ğŸ‘ï¸ è§†è§‰ã€ç”Ÿæˆä¸å¤šæ¨¡æ€\n\n**8. [è§†é¢‘ç”Ÿæˆè¿åŠ¨æ§åˆ¶] Time-to-Move: Training-Free Motion Controlled Video Generation via Dual-Clock Denoising**\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šæ— éœ€è®­ç»ƒï¼ˆTraining-Freeï¼‰çš„è§†é¢‘ç”Ÿæˆè¿åŠ¨æ§åˆ¶æ¡†æ¶ã€‚\n*   **æ–¹æ³•**ï¼šåˆ©ç”¨ç”¨æˆ·æä¾›çš„ç²—ç³™åŠ¨ç”»ï¼ˆå¦‚å‰ªåˆ‡æ‹–åŠ¨ï¼‰ä½œä¸ºè¿åŠ¨çº¿ç´¢ã€‚æå‡ºäº†â€œåŒæ—¶é’Ÿå»å™ªï¼ˆDual-Clock Denoisingï¼‰â€ç­–ç•¥ï¼Œåœ¨ä¿è¯è¿åŠ¨å¯¹é½çš„åŒæ—¶ä¿æŒè‡ªç„¶åŠ¨æ€ã€‚\n*   **å‘ç°**ï¼šè¿™æ˜¯ä¸€ä¸ªå³æ’å³ç”¨çš„æ–¹æ¡ˆï¼Œå…¼å®¹å„ç§åº•åº§æ¨¡å‹ï¼Œå®ç°äº†åƒç´ çº§çš„ç²¾ç¡®å¤–è§‚å’Œè¿åŠ¨æ§åˆ¶ã€‚\n\n**9. [è§†è§‰æ•°å­¦æ¨ç†] FractalBench: Diagnosing Visual-Mathematical Reasoning Through Recursive Program Synthesis**\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šé€šè¿‡åˆ†å½¢ï¼ˆFractalsï¼‰æ¥æµ‹è¯•å¤šæ¨¡æ€å¤§æ¨¡å‹ï¼ˆMLLMï¼‰çš„è§†è§‰-æ•°å­¦æ¨ç†èƒ½åŠ›ã€‚\n*   **å‘ç°**ï¼šè¿™æ˜¯ä¸€ä¸ªâ€œç…§å¦–é•œâ€ã€‚è™½ç„¶ GPT-4o ç­‰æ¨¡å‹èƒ½å†™å‡ºè¯­æ³•æ­£ç¡®çš„ä»£ç ï¼ˆ76%ï¼‰ï¼Œä½†åªæœ‰ 4% çœŸæ­£æ•æ‰åˆ°äº†åˆ†å½¢çš„æ•°å­¦é€’å½’ç»“æ„ã€‚æ¨¡å‹èƒ½å¤„ç†å‡ ä½•å˜æ¢ï¼Œä½†åœ¨åˆ†æ”¯é€’å½’ä¸Šå‡ ä¹å…¨å†›è¦†æ²¡ï¼Œæ­ç¤ºäº†å½“å‰ AI åœ¨æŠ½è±¡è§†è§‰æ¨¡å¼åˆ°æ•°å­¦è§„åˆ™è½¬æ¢ä¸Šçš„å·¨å¤§é¸¿æ²Ÿã€‚\n\n**10. [å• Token è¿˜åŸå…¨æ–‡] Rep2Text: Decoding Full Text from a Single LLM Token Representation**\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šæ¢ç©¶ LLM å†…éƒ¨è¡¨ç¤ºçš„å¯è§£é‡Šæ€§ã€‚\n*   **å‘ç°**ï¼šæƒŠäººçš„å‘ç°â€”â€”ä»…ä» LLM çš„**æœ€åä¸€ä¸ª Token çš„è¡¨ç¤º**ï¼Œå°±èƒ½é€šè¿‡è®­ç»ƒä¸€ä¸ª Adapter è¿˜åŸå‡ºè¾“å…¥æ–‡æœ¬çš„å¤§éƒ¨åˆ†ä¿¡æ¯ï¼ˆ16 ä¸ª Token åºåˆ—ä¸­è¶…è¿‡ä¸€åŠçš„ä¿¡æ¯ï¼‰ã€‚è¿™æ­ç¤ºäº† LLM çš„è¡¨ç¤ºå…·æœ‰æé«˜çš„å‹ç¼©ç‡å’Œè¯­ä¹‰å®Œæ•´æ€§ï¼ŒåŒæ—¶ä¹Ÿå¸¦æ¥äº†éšç§æ³„éœ²çš„æ€è€ƒã€‚\n\n---\n\n### ğŸ›¡ï¸ å®‰å…¨ä¸æ£€æµ‹\n\n**11. [æ¨¡å‹è¡€ç»Ÿæ£€æµ‹] Ghost in the Transformer: Detecting Model Reuse with Invariant Spectral Signatures**\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šå¦‚ä½•åˆ¤æ–­ä¸€ä¸ªå¼€æºæ¨¡å‹æ˜¯ä¸æ˜¯å·äº†ä½ çš„æ¨¡å‹å¾®è°ƒå‡ºæ¥çš„ï¼Ÿ\n*   **æ–¹æ³•**ï¼šæå‡ºäº† **GhostSpec**ï¼Œåˆ©ç”¨ Transformer å†…éƒ¨æ³¨æ„åŠ›æƒé‡çŸ©é˜µçš„ä¸å˜ç§¯è¿›è¡Œ SVD åˆ†è§£ï¼Œæ„å»ºâ€œæŒ‡çº¹â€ã€‚\n*   **ä¼˜ç‚¹**ï¼šä¸éœ€è¦è®­ç»ƒæ•°æ®ï¼Œä¸éœ€è¦ä¿®æ”¹æ¨¡å‹è¡Œä¸ºï¼Œçº¯é»‘ç›’æ£€æµ‹ã€‚å³ä½¿æ¨¡å‹ç»è¿‡å¾®è°ƒã€å‰ªææˆ–å¯¹æŠ—å˜æ¢ï¼ŒæŒ‡çº¹ä¾ç„¶ç¨³å¥ã€‚\n\n**12. [çŸ¥è¯†å›¾è°±åè¶Šç‹±] KG-DF: A Black-box Defense Framework against Jailbreak Attacks Based on Knowledge Graphs**\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šåˆ©ç”¨çŸ¥è¯†å›¾è°±ï¼ˆKGï¼‰æ¥é˜²å¾¡ LLM è¶Šç‹±æ”»å‡»ã€‚\n*   **æ–¹æ³•**ï¼šå°†è¾“å…¥æŸ¥è¯¢æ˜ å°„åˆ° KG ä¸­çš„å®‰å…¨æ¦‚å¿µï¼Œåˆ©ç”¨ KG çš„ç»“æ„åŒ–çŸ¥è¯†æ¥è¯†åˆ«æ½œåœ¨çš„æœ‰å®³æ„å›¾ï¼Œæä¾›å®‰å…¨çš„æ¨ç†è·¯å¾„ï¼Œä»è€Œåœ¨ä¸ç‰ºç‰²æ¨¡å‹é€šç”¨æ€§çš„å‰æä¸‹é˜²å¾¡æ”»å‡»ã€‚\n\n---\n\n### ğŸŒŸ ç¤¾åŒºä¸ç»¼è¿°\n\n**13. [Kaggle è€ƒå¤] Kaggle Chronicles: 15 Years of Competitions, Community and Data Science Innovation**\n*   **ç®€ä»‹**ï¼šå¯¹ Kaggle å¹³å° 15 å¹´æ•°æ®çš„å…ƒåˆ†æã€‚åˆ†æäº†æ•°ç™¾ä¸‡ä¸ª Kernel å’Œè®¨è®ºå¸–ï¼Œæ­ç¤ºäº†æ•°æ®ç§‘å­¦ç«èµ›çš„è¶‹åŠ¿ã€è·èƒœè€…çš„ç­–ç•¥ä»¥åŠæŠ€æœ¯çš„æ¼”å˜ã€‚æ•°æ®ç§‘å­¦å®¶ä»¬çš„â€œå›å¿†æ€â€ã€‚\n\n**14. [å¤§è„‘ vs LLM] On the Analogy between Human Brain and LLMs: Spotting Key Neurons in Grammar Perception**\n*   **ç®€ä»‹**ï¼šç¥ç»ç§‘å­¦å‘ç°äººè„‘ç”¨ä¸åŒç¥ç»å…ƒå¤„ç†ä¸åŒè¯­æ³•ã€‚æœ¬æ–‡åœ¨ Llama 3 ä¸­ä¹Ÿå‘ç°äº†ç±»ä¼¼çš„ç°è±¡ï¼šå­˜åœ¨ä¸“é—¨è´Ÿè´£è¯æ€§ï¼ˆPOSï¼‰é¢„æµ‹çš„å…³é”®ç¥ç»å…ƒå­ç©ºé—´ï¼Œè¿™åŠ å¼ºäº† LLM ä¸äººè„‘å·¥ä½œæœºåˆ¶çš„ç±»æ¯”ã€‚",
  "papers": [
    {
      "arxiv_id": "2511.06575v1",
      "title": "CoFineLLM: Conformal Finetuning of LLMs for Language-Instructed Robot Planning",
      "title_zh": "CoFineLLMï¼šé¢å‘è¯­è¨€æŒ‡ä»¤æœºå™¨äººè§„åˆ’çš„å¤§è¯­è¨€æ¨¡å‹å…±å½¢å¾®è°ƒ",
      "authors": [
        "Jun Wang",
        "Yevgeniy Vorobeychik",
        "Yiannis Kantaros"
      ],
      "abstract": "Large Language Models (LLMs) have recently emerged as planners for language-instructed agents, generating sequences of actions to accomplish natural language tasks. However, their reliability remains a challenge, especially in long-horizon tasks, since they often produce overconfident yet wrong outputs. Conformal Prediction (CP) has been leveraged to address this issue by wrapping LLM outputs into prediction sets that contain the correct action with a user-defined confidence. When the prediction set is a singleton, the planner executes that action; otherwise, it requests help from a user. This has led to LLM-based planners that can ensure plan correctness with a user-defined probability. However, as LLMs are trained in an uncertainty-agnostic manner, without awareness of prediction sets, they tend to produce unnecessarily large sets, particularly at higher confidence levels, resulting in frequent human interventions limiting autonomous deployment. To address this, we introduce CoFineLLM (Conformal Finetuning for LLMs), the first CP-aware finetuning framework for LLM-based planners that explicitly reduces prediction-set size and, in turn, the need for user interventions. We evaluate our approach on multiple language-instructed robot planning problems and show consistent improvements over uncertainty-aware and uncertainty-agnostic finetuning baselines in terms of prediction-set size, and help rates. Finally, we demonstrate robustness of our method to out-of-distribution scenarios in hardware experiments.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨è¯­è¨€æŒ‡ä»¤æœºå™¨äººè§„åˆ’ä¸­å­˜åœ¨çš„è¿‡åº¦è‡ªä¿¡å’Œå¯é æ€§ä¸è¶³é—®é¢˜ï¼Œæå‡ºäº†CoFineLLMæ¡†æ¶ã€‚å°½ç®¡ä¿å½¢é¢„æµ‹(Conformal Prediction, CP)å¯ä»¥é€šè¿‡ç”ŸæˆåŒ…å«æ­£ç¡®åŠ¨ä½œçš„é¢„æµ‹é›†æ¥ç¡®ä¿è§„åˆ’çš„æ­£ç¡®æ€§ï¼Œä½†ç”±äºç°æœ‰LLMç¼ºä¹å¯¹CPçš„æ„ŸçŸ¥ï¼Œå¾€å¾€ä¼šç”Ÿæˆä¸å¿…è¦çš„å¤§å‹é¢„æµ‹é›†ï¼Œå¯¼è‡´é¢‘ç¹çš„äººç±»å¹²é¢„ã€‚CoFineLLMæ˜¯é¦–ä¸ªæ”¯æŒCPæ„ŸçŸ¥çš„å¾®è°ƒæ¡†æ¶ï¼Œæ—¨åœ¨æ˜¾å¼åœ°å‡å°é¢„æµ‹é›†çš„å¤§å°ï¼Œä»è€Œé™ä½å¯¹ç”¨æˆ·å¹²é¢„çš„éœ€æ±‚ã€‚åœ¨å¤šä¸ªè¯­è¨€æŒ‡ä»¤æœºå™¨äººè§„åˆ’ä»»åŠ¡ä¸Šçš„è¯„ä¼°è¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨é¢„æµ‹é›†å¤§å°å’Œæ±‚åŠ©ç‡æ–¹é¢å‡ä¼˜äºç°æœ‰çš„ä¸ç¡®å®šæ€§æ„ŸçŸ¥åŠä¸ç¡®å®šæ€§æ— å…³çš„å¾®è°ƒåŸºçº¿ã€‚æ­¤å¤–ï¼Œç¡¬ä»¶å®éªŒä¹Ÿè¯æ˜äº†è¯¥æ–¹æ³•åœ¨åˆ†å¸ƒå¤–(out-of-distribution)åœºæ™¯ä¸‹çš„é²æ£’æ€§ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.06575v1",
      "published_date": "2025-11-09 23:38:25 UTC",
      "updated_date": "2025-11-09 23:38:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T18:14:43.759195+00:00"
    },
    {
      "arxiv_id": "2511.06573v1",
      "title": "SteganoSNN: SNN-Based Audio-in-Image Steganography with Encryption",
      "title_zh": "SteganoSNNï¼šåŸºäºè„‰å†²ç¥ç»ç½‘ç»œçš„åŠ å¯†å›¾åƒéŸ³é¢‘éšå†™æœ¯",
      "authors": [
        "Biswajit Kumar Sahoo",
        "Pedro Machado",
        "Isibor Kennedy Ihianle",
        "Andreas Oikonomou",
        "Srinivas Boppu"
      ],
      "abstract": "Secure data hiding remains a fundamental challenge in digital communication, requiring a careful balance between computational efficiency and perceptual transparency. The balance between security and performance is increasingly fragile with the emergence of generative AI systems capable of autonomously generating and optimising sophisticated cryptanalysis and steganalysis algorithms, thereby accelerating the exposure of vulnerabilities in conventional data-hiding schemes.\n  This work introduces SteganoSNN, a neuromorphic steganographic framework that exploits spiking neural networks (SNNs) to achieve secure, low-power, and high-capacity multimedia data hiding. Digitised audio samples are converted into spike trains using leaky integrate-and-fire (LIF) neurons, encrypted via a modulo-based mapping scheme, and embedded into the least significant bits of RGBA image channels using a dithering mechanism to minimise perceptual distortion. Implemented in Python using NEST and realised on a PYNQ-Z2 FPGA, SteganoSNN attains real-time operation with an embedding capacity of 8 bits per pixel. Experimental evaluations on the DIV2K 2017 dataset demonstrate image fidelity between 40.4 dB and 41.35 dB in PSNR and SSIM values consistently above 0.97, surpassing SteganoGAN in computational efficiency and robustness. SteganoSNN establishes a foundation for neuromorphic steganography, enabling secure, energy-efficient communication for Edge-AI, IoT, and biomedical applications.",
      "tldr_zh": "æœ¬ç ”ç©¶æå‡ºäº†SteganoSNNï¼Œä¸€ç§åŸºäºè„‰å†²ç¥ç»ç½‘ç»œ(SNNs)çš„ç¥ç»å½¢æ€éšå†™æ¡†æ¶ï¼Œæ—¨åœ¨å®ç°å®‰å…¨ã€ä½åŠŸè€—ä¸”é«˜å®¹é‡çš„å¤šåª’ä½“æ•°æ®éšè—ã€‚è¯¥æ¡†æ¶åˆ©ç”¨æ¼ç§¯åˆ†è§¦å‘(LIF)ç¥ç»å…ƒå°†æ•°å­—åŒ–éŸ³é¢‘æ ·æœ¬è½¬æ¢ä¸ºè„‰å†²åºåˆ—ï¼Œé€šè¿‡åŸºäºæ¨¡è¿ç®—çš„æ˜ å°„æ–¹æ¡ˆè¿›è¡ŒåŠ å¯†ï¼Œå¹¶ä½¿ç”¨æŠ–åŠ¨æœºåˆ¶å°†å…¶åµŒå…¥åˆ°RGBAå›¾åƒé€šé“çš„æœ€ä½æœ‰æ•ˆä½(LSB)ä¸­ä»¥æœ€å°åŒ–æ„ŸçŸ¥å¤±çœŸã€‚SteganoSNNåœ¨Pythonä¸­ä½¿ç”¨NESTå®ç°å¹¶åœ¨PYNQ-Z2 FPGAä¸Šè¿›è¡Œäº†ç¡¬ä»¶éƒ¨ç½²ï¼Œå®ç°äº†æ¯åƒç´ 8æ¯”ç‰¹åµŒå…¥å®¹é‡çš„å®æ—¶è¿è¡Œã€‚åœ¨DIV2K 2017æ•°æ®é›†ä¸Šçš„å®éªŒè¯„ä¼°æ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•çš„å›¾åƒä¿çœŸåº¦PSNRå€¼åœ¨40.4 dBè‡³41.35 dBä¹‹é—´ï¼ŒSSIMå€¼æŒç»­é«˜äº0.97ï¼Œåœ¨è®¡ç®—æ•ˆç‡å’Œé²æ£’æ€§æ–¹é¢ä¼˜äºSteganoGANã€‚è¯¥å·¥ä½œä¸ºç¥ç»å½¢æ€éšå†™æœ¯å¥ å®šäº†åŸºç¡€ï¼Œé€‚ç”¨äºEdge-AIã€IoTå’Œç”Ÿç‰©åŒ»å­¦åº”ç”¨ä¸­çš„å®‰å…¨èŠ‚èƒ½é€šä¿¡ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.06573v1",
      "published_date": "2025-11-09 23:31:53 UTC",
      "updated_date": "2025-11-09 23:31:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T18:15:13.696118+00:00"
    },
    {
      "arxiv_id": "2511.06571v1",
      "title": "Rep2Text: Decoding Full Text from a Single LLM Token Representation",
      "title_zh": "Rep2Textï¼šä»å•ä¸ªå¤§è¯­è¨€æ¨¡å‹è¯å…ƒè¡¨å¾è§£ç å…¨æ–‡",
      "authors": [
        "Haiyan Zhao",
        "Zirui He",
        "Fan Yang",
        "Ali Payani",
        "Mengnan Du"
      ],
      "abstract": "Large language models (LLMs) have achieved remarkable progress across diverse tasks, yet their internal mechanisms remain largely opaque. In this work, we address a fundamental question: to what extent can the original input text be recovered from a single last-token representation within an LLM? We propose Rep2Text, a novel framework for decoding full text from last-token representations. Rep2Text employs a trainable adapter that projects a target model's internal representations into the embedding space of a decoding language model, which then autoregressively reconstructs the input text. Experiments on various model combinations (Llama-3.1-8B, Gemma-7B, Mistral-7B-v0.1, Llama-3.2-3B) demonstrate that, on average, over half of the information in 16-token sequences can be recovered from this compressed representation while maintaining strong semantic integrity and coherence. Furthermore, our analysis reveals an information bottleneck effect: longer sequences exhibit decreased token-level recovery while preserving strong semantic integrity. Besides, our framework also demonstrates robust generalization to out-of-distribution medical data.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)å†…éƒ¨æœºåˆ¶çš„ä¸é€æ˜æ€§ï¼Œæ¢è®¨äº†æ˜¯å¦èƒ½ä»…å‡­å•ä¸ªæœ€åä¸€ä¸ªtokençš„è¡¨ç¤ºæ¥æ¢å¤åŸå§‹è¾“å…¥æ–‡æœ¬çš„é—®é¢˜ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†Rep2Textæ¡†æ¶ï¼Œè¯¥æ¡†æ¶åˆ©ç”¨ä¸€ä¸ªå¯è®­ç»ƒçš„é€‚é…å™¨(adapter)å°†ç›®æ ‡æ¨¡å‹çš„å†…éƒ¨è¡¨ç¤ºæŠ•å½±åˆ°è§£ç è¯­è¨€æ¨¡å‹çš„åµŒå…¥ç©ºé—´(embedding space)ä¸­ï¼Œè¿›è€Œè‡ªå›å½’åœ°é‡æ„è¾“å…¥æ–‡æœ¬ã€‚é€šè¿‡åœ¨Llama-3.1-8Bã€Gemma-7Bå’ŒMistral-7B-v0.1ç­‰å¤šç§æ¨¡å‹ç»„åˆä¸Šçš„å®éªŒï¼Œç»“æœæ˜¾ç¤ºå¯¹äº16ä¸ªtokençš„åºåˆ—ï¼Œå¹³å‡è¶…è¿‡ä¸€åŠçš„ä¿¡æ¯èƒ½å¤Ÿä»è¯¥å‹ç¼©è¡¨ç¤ºä¸­æ¢å¤ï¼Œä¸”ä¿æŒäº†æé«˜çš„è¯­ä¹‰å®Œæ•´æ€§å’Œè¿è´¯æ€§ã€‚è¿›ä¸€æ­¥çš„åˆ†ææ­ç¤ºäº†ä¸€ç§ä¿¡æ¯ç“¶é¢ˆ(information bottleneck)æ•ˆåº”ï¼Œå³éšç€åºåˆ—é•¿åº¦å¢åŠ ï¼Œè™½ç„¶tokençº§åˆ«çš„æ¢å¤ç²¾åº¦ä¸‹é™ï¼Œä½†æ ¸å¿ƒè¯­ä¹‰å¾—ä»¥ä¿ç•™ã€‚æ­¤å¤–ï¼ŒRep2Textæ¡†æ¶åœ¨åˆ†å¸ƒå¤–(out-of-distribution)çš„åŒ»ç–—æ•°æ®ä¸Šä¹Ÿå±•ç°å‡ºäº†å¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ï¼Œä¸ºç†è§£LLMçš„å†…éƒ¨è¡¨ç¤ºæä¾›äº†æ–°çš„è§†è§’ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "15 pages, 7 figures, 4 tables",
      "pdf_url": "https://arxiv.org/pdf/2511.06571v1",
      "published_date": "2025-11-09 23:18:36 UTC",
      "updated_date": "2025-11-09 23:18:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T18:15:30.984912+00:00"
    },
    {
      "arxiv_id": "2511.06568v2",
      "title": "Breaking the Dyadic Barrier: Rethinking Fairness in Link Prediction Beyond Demographic Parity",
      "title_zh": "æ‰“ç ´äºŒå…ƒå£å’ï¼šè¶…è¶Šäººå£ç»Ÿè®¡å­¦å‡ç­‰çš„é“¾è·¯é¢„æµ‹å…¬å¹³æ€§åæ€",
      "authors": [
        "JoÃ£o Mattos",
        "Debolina Halder Lina",
        "Arlei Silva"
      ],
      "abstract": "Link prediction is a fundamental task in graph machine learning with applications, ranging from social recommendation to knowledge graph completion. Fairness in this setting is critical, as biased predictions can exacerbate societal inequalities. Prior work adopts a dyadic definition of fairness, enforcing fairness through demographic parity between intra-group and inter-group link predictions. However, we show that this dyadic framing can obscure underlying disparities across subgroups, allowing systemic biases to go undetected. Moreover, we argue that demographic parity does not meet desired properties for fairness assessment in ranking-based tasks such as link prediction. We formalize the limitations of existing fairness evaluations and propose a framework that enables a more expressive assessment. Additionally, we propose a lightweight post-processing method combined with decoupled link predictors that effectively mitigates bias and achieves state-of-the-art fairness-utility trade-offs.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å›¾æœºå™¨å­¦ä¹ ä¸­çš„é“¾è·¯é¢„æµ‹(Link Prediction)ä»»åŠ¡ï¼ŒæŒ‘æˆ˜äº†ä¼ ç»Ÿçš„äºŒå…ƒ(dyadic)å…¬å¹³æ€§å®šä¹‰ï¼ŒæŒ‡å‡ºä»…ä¾èµ–äººå£ç»Ÿè®¡å­¦å‡ç­‰(Demographic Parity)ä¼šæ©ç›–å­ç»„é—´çš„æ½œåœ¨å·®å¼‚å¹¶å¯¼è‡´ç³»ç»Ÿæ€§åå·®æœªè¢«æ£€æµ‹ã€‚ä½œè€…è®ºè¯äº†äººå£ç»Ÿè®¡å­¦å‡ç­‰å¹¶ä¸ç¬¦åˆåŸºäºæ’åçš„ä»»åŠ¡éœ€æ±‚ï¼Œå½¢å¼åŒ–äº†ç°æœ‰è¯„ä¼°æ–¹æ³•çš„å±€é™æ€§ï¼Œå¹¶æå‡ºäº†ä¸€ä¸ªæ–°çš„æ¡†æ¶ä»¥å®ç°æ›´å…·è¡¨è¾¾åŠ›çš„å…¬å¹³æ€§è¯„ä¼°ã€‚æ­¤å¤–ï¼Œè®ºæ–‡æå‡ºäº†ä¸€ç§ç»“åˆè§£è€¦é“¾è·¯é¢„æµ‹å™¨(decoupled link predictors)çš„è½»é‡çº§åå¤„ç†æ–¹æ³•æ¥æœ‰æ•ˆç¼“è§£åå·®ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•å®ç°äº†æœ€å…ˆè¿›çš„å…¬å¹³æ€§ä¸æ•ˆç”¨æƒè¡¡(fairness-utility trade-offs)ï¼Œä¸ºå›¾å­¦ä¹ ä¸­çš„å…¬å¹³æ€§è¯„ä¼°ä¸ä¼˜åŒ–æä¾›äº†æ–°çš„è§†è§’ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages, 5 figures. Accepted at AAAI-26 as an Oral",
      "pdf_url": "https://arxiv.org/pdf/2511.06568v2",
      "published_date": "2025-11-09 22:58:29 UTC",
      "updated_date": "2025-11-16 19:26:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T18:15:56.854591+00:00"
    },
    {
      "arxiv_id": "2511.08633v1",
      "title": "Time-to-Move: Training-Free Motion Controlled Video Generation via Dual-Clock Denoising",
      "title_zh": "Time-to-Moveï¼šåŸºäºåŒæ—¶é’Ÿå»å™ªçš„å…è®­ç»ƒè¿åŠ¨å¯æ§è§†é¢‘ç”Ÿæˆ",
      "authors": [
        "Assaf Singer",
        "Noam Rotstein",
        "Amir Mann",
        "Ron Kimmel",
        "Or Litany"
      ],
      "abstract": "Diffusion-based video generation can create realistic videos, yet existing image- and text-based conditioning fails to offer precise motion control. Prior methods for motion-conditioned synthesis typically require model-specific fine-tuning, which is computationally expensive and restrictive. We introduce Time-to-Move (TTM), a training-free, plug-and-play framework for motion- and appearance-controlled video generation with image-to-video (I2V) diffusion models. Our key insight is to use crude reference animations obtained through user-friendly manipulations such as cut-and-drag or depth-based reprojection. Motivated by SDEdit's use of coarse layout cues for image editing, we treat the crude animations as coarse motion cues and adapt the mechanism to the video domain. We preserve appearance with image conditioning and introduce dual-clock denoising, a region-dependent strategy that enforces strong alignment in motion-specified regions while allowing flexibility elsewhere, balancing fidelity to user intent with natural dynamics. This lightweight modification of the sampling process incurs no additional training or runtime cost and is compatible with any backbone. Extensive experiments on object and camera motion benchmarks show that TTM matches or exceeds existing training-based baselines in realism and motion control. Beyond this, TTM introduces a unique capability: precise appearance control through pixel-level conditioning, exceeding the limits of text-only prompting. Visit our project page for video examples and code: https://time-to-move.github.io/.",
      "tldr_zh": "è¿™ç¯‡è®ºæ–‡æå‡ºäº†Time-to-Move (TTM)ï¼Œä¸€ç§æ— éœ€è®­ç»ƒ(training-free)çš„å³æ’å³ç”¨æ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡å›¾åƒåˆ°è§†é¢‘(I2V)æ‰©æ•£æ¨¡å‹å®ç°è¿åŠ¨å’Œå¤–è§‚å¯æ§çš„è§†é¢‘ç”Ÿæˆã€‚é’ˆå¯¹ç°æœ‰æ–¹æ³•é€šå¸¸éœ€è¦æ˜‚è´µçš„æ¨¡å‹å¾®è°ƒæ¥æ§åˆ¶è¿åŠ¨çš„é—®é¢˜ï¼ŒTTMåˆ©ç”¨ç”¨æˆ·å‹å¥½çš„æ“ä½œï¼ˆå¦‚å‰ªåˆ‡æ‹–æ‹½æˆ–åŸºäºæ·±åº¦çš„é‡æŠ•å½±ï¼‰ç”Ÿæˆçš„ç²—ç³™å‚è€ƒåŠ¨ç”»ä½œä¸ºè¿åŠ¨çº¿ç´¢ã€‚è¯¥æ–¹æ³•çš„æ ¸å¿ƒåœ¨äºå¼•å…¥äº†åŒæ—¶é’Ÿå»å™ª(dual-clock denoising)ç­–ç•¥ï¼Œè¿™æ˜¯ä¸€ç§ä¾èµ–åŒºåŸŸçš„æœºåˆ¶ï¼Œåœ¨æŒ‡å®šè¿åŠ¨åŒºåŸŸå¼ºåˆ¶è¿›è¡Œå¼ºå¯¹é½ï¼ŒåŒæ—¶å…è®¸å…¶ä»–åŒºåŸŸä¿æŒçµæ´»æ€§ï¼Œä»è€Œåœ¨ç”¨æˆ·æ„å›¾çš„ä¿çœŸåº¦ä¸è‡ªç„¶åŠ¨æ€ä¹‹é—´å–å¾—å¹³è¡¡ã€‚TTMä»…å¯¹é‡‡æ ·è¿‡ç¨‹è¿›è¡Œè½»é‡çº§ä¿®æ”¹ï¼Œæ— éœ€é¢å¤–çš„è®­ç»ƒæˆ–æ¨ç†æˆæœ¬ï¼Œå¹¶ä¸”å…¼å®¹å„ç§éª¨å¹²ç½‘ç»œã€‚åœ¨ç‰©ä½“å’Œç›¸æœºè¿åŠ¨åŸºå‡†æµ‹è¯•ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒTTMåœ¨çœŸå®æ„Ÿå’Œè¿åŠ¨æ§åˆ¶æ–¹é¢åŒ¹é…ç”šè‡³è¶…è¿‡äº†ç°æœ‰çš„åŸºäºè®­ç»ƒçš„åŸºçº¿æ¨¡å‹ï¼Œå¹¶é€šè¿‡åƒç´ çº§è°ƒèŠ‚æä¾›äº†æ¯”çº¯æ–‡æœ¬æç¤ºæ›´ç²¾ç¡®çš„å¤–è§‚æ§åˆ¶èƒ½åŠ›ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.08633v1",
      "published_date": "2025-11-09 22:47:50 UTC",
      "updated_date": "2025-11-09 22:47:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T18:16:21.211018+00:00"
    },
    {
      "arxiv_id": "2511.06552v1",
      "title": "LLM For Loop Invariant Generation and Fixing: How Far Are We?",
      "title_zh": "ç”¨äºå¾ªç¯ä¸å˜é‡ç”Ÿæˆä¸ä¿®å¤çš„ LLMï¼šç©¶ç«Ÿèƒ½èµ°å¤šè¿œï¼Ÿ",
      "authors": [
        "Mostafijur Rahman Akhond",
        "Saikat Chakraborty",
        "Gias Uddin"
      ],
      "abstract": "A loop invariant is a property of a loop that remains true before and after each execution of the loop. The identification of loop invariants is a critical step to support automated program safety assessment. Recent advancements in Large Language Models (LLMs) have demonstrated potential in diverse software engineering (SE) and formal verification tasks. However, we are not aware of the performance of LLMs to infer loop invariants. We report an empirical study of both open-source and closed-source LLMs of varying sizes to assess their proficiency in inferring inductive loop invariants for programs and in fixing incorrect invariants. Our findings reveal that while LLMs exhibit some utility in inferring and repairing loop invariants, their performance is substantially enhanced when supplemented with auxiliary information such as domain knowledge and illustrative examples. LLMs achieve a maximum success rate of 78\\% in generating, but are limited to 16\\% in repairing the invariant.",
      "tldr_zh": "è¯¥è®ºæ–‡é’ˆå¯¹ Large Language Models (LLMs) åœ¨ç”Ÿæˆå’Œä¿®å¤ loop invariants æ–¹é¢çš„èƒ½åŠ›è¿›è¡Œäº†å®è¯ç ”ç©¶ï¼Œæ—¨åœ¨å¡«è¡¥ç›®å‰å…³äº LLMs åœ¨æ­¤é¢†åŸŸæ€§èƒ½è¡¨ç°çš„è®¤çŸ¥ç©ºç™½ã€‚ä½œè€…è¯„ä¼°äº†å¤šç§ä¸åŒè§„æ¨¡çš„å¼€æºå’Œé—­æº LLMsï¼Œæµ‹è¯•å®ƒä»¬æ¨æ–­ inductive loop invariants ä»¥åŠä¿®å¤é”™è¯¯ invariants çš„ç†Ÿç»ƒç¨‹åº¦ã€‚ç ”ç©¶å‘ç°ï¼Œè™½ç„¶ LLMs åœ¨æ¨æ–­å’Œä¿®å¤æ–¹é¢è¡¨ç°å‡ºä¸€å®šçš„æ•ˆç”¨ï¼Œä½†å½“è¾…ä»¥é¢†åŸŸçŸ¥è¯†å’Œç¤ºä¾‹ç­‰è¾…åŠ©ä¿¡æ¯æ—¶ï¼Œå…¶æ€§èƒ½å¾—åˆ°æ˜¾è‘—å¢å¼ºã€‚å®éªŒæ•°æ®æ˜¾ç¤ºï¼ŒLLMs åœ¨ç”Ÿæˆ invariant æ–¹é¢æœ€é«˜å–å¾—äº† 78% çš„æˆåŠŸç‡ï¼Œä½†åœ¨ä¿®å¤ invariant æ–¹é¢è¡¨ç°å—é™ï¼ŒæˆåŠŸç‡ä»…ä¸º 16%ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "This work has been submitted to the IEEE for possible publication",
      "pdf_url": "https://arxiv.org/pdf/2511.06552v1",
      "published_date": "2025-11-09 21:47:45 UTC",
      "updated_date": "2025-11-09 21:47:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T18:17:36.882158+00:00"
    },
    {
      "arxiv_id": "2511.07485v1",
      "title": "When Are Learning Biases Equivalent? A Unifying Framework for Fairness, Robustness, and Distribution Shift",
      "title_zh": "å­¦ä¹ åå·®ä½•æ—¶ç­‰ä»·ï¼Ÿå…¬å¹³æ€§ã€é²æ£’æ€§ä¸åˆ†å¸ƒåç§»çš„ç»Ÿä¸€æ¡†æ¶",
      "authors": [
        "Sushant Mehta"
      ],
      "abstract": "Machine learning systems exhibit diverse failure modes: unfairness toward protected groups, brittleness to spurious correlations, poor performance on minority sub-populations, which are typically studied in isolation by distinct research communities. We propose a unifying theoretical framework that characterizes when different bias mechanisms produce quantitatively equivalent effects on model performance. By formalizing biases as violations of conditional independence through information-theoretic measures, we prove formal equivalence conditions relating spurious correlations, subpopulation shift, class imbalance, and fairness violations. Our theory predicts that a spurious correlation of strength $Î±$ produces equivalent worst-group accuracy degradation as a sub-population imbalance ratio $r \\approx (1+Î±)/(1-Î±)$ under feature overlap assumptions. Empirical validation in six datasets and three architectures confirms that predicted equivalences hold within the accuracy of the worst group 3\\%, enabling the principled transfer of debiasing methods across problem domains. This work bridges the literature on fairness, robustness, and distribution shifts under a common perspective.",
      "tldr_zh": "æœºå™¨å­¦ä¹ ç³»ç»Ÿå¸¸é¢ä¸´å¯¹å—ä¿æŠ¤ç¾¤ä½“çš„ä¸å…¬å¹³ã€å¯¹è™šå‡ç›¸å…³æ€§(spurious correlations)çš„è„†å¼±æ€§ä»¥åŠåœ¨å°‘æ•°å­ç¾¤ä½“ä¸Šè¡¨ç°ä¸ä½³ç­‰å¤±æ•ˆæ¨¡å¼ï¼Œè¿™äº›é—®é¢˜é€šå¸¸ç”±ä¸åŒç¤¾åŒºç‹¬ç«‹ç ”ç©¶ã€‚è¯¥è®ºæ–‡æå‡ºäº†ä¸€ä¸ªç»Ÿä¸€çš„ç†è®ºæ¡†æ¶ï¼Œæ—¨åœ¨è¡¨å¾ä¸åŒçš„åå·®æœºåˆ¶ä½•æ—¶ä¼šå¯¹æ¨¡å‹æ€§èƒ½äº§ç”Ÿé‡åŒ–ç­‰æ•ˆçš„å½±å“ã€‚é€šè¿‡åˆ©ç”¨ä¿¡æ¯è®ºåº¦é‡å°†åå·®å½¢å¼åŒ–ä¸ºæ¡ä»¶ç‹¬ç«‹æ€§çš„è¿åï¼Œç ”ç©¶äººå‘˜è¯æ˜äº†è™šå‡ç›¸å…³æ€§ã€å­ç¾¤ä½“åç§»(subpopulation shift)ã€ç±»åˆ«ä¸å¹³è¡¡(class imbalance)å’Œå…¬å¹³æ€§è¿å(fairness violations)ä¹‹é—´çš„å½¢å¼ç­‰æ•ˆæ¡ä»¶ã€‚ç†è®ºé¢„æµ‹åœ¨ç‰¹å¾é‡å å‡è®¾ä¸‹ï¼Œç‰¹å®šå¼ºåº¦çš„è™šå‡ç›¸å…³æ€§ä¸ç‰¹å®šæ¯”ç‡çš„å­ç¾¤ä½“ä¸å¹³è¡¡ä¼šäº§ç”Ÿç­‰æ•ˆçš„æœ€å·®ç¾¤ä½“ç²¾åº¦ä¸‹é™ã€‚åœ¨å…­ä¸ªæ•°æ®é›†å’Œä¸‰ç§æ¶æ„ä¸Šçš„å®è¯éªŒè¯ç¡®è®¤äº†è¿™äº›é¢„æµ‹çš„ç­‰æ•ˆæ€§åœ¨æœ€å·®ç¾¤ä½“ç²¾åº¦3%çš„è¯¯å·®èŒƒå›´å†…æˆç«‹ã€‚è¿™é¡¹å·¥ä½œåœ¨å…±åŒçš„è§†è§’ä¸‹æ¡¥æ¥äº†å…¬å¹³æ€§ã€é²æ£’æ€§(robustness)å’Œåˆ†å¸ƒåç§»(distribution shifts)çš„æ–‡çŒ®ï¼Œä½¿å¾—å»åæ–¹æ³•èƒ½å¤Ÿåœ¨ä¸åŒé—®é¢˜é¢†åŸŸé—´è¿›è¡ŒåŸåˆ™æ€§çš„è¿ç§»ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.07485v1",
      "published_date": "2025-11-09 20:48:09 UTC",
      "updated_date": "2025-11-09 20:48:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T18:17:30.789356+00:00"
    },
    {
      "arxiv_id": "2511.06531v1",
      "title": "Ibom NLP: A Step Toward Inclusive Natural Language Processing for Nigeria's Minority Languages",
      "title_zh": "Ibom NLPï¼šè¿ˆå‘å°¼æ—¥åˆ©äºšå°‘æ•°æ°‘æ—è¯­è¨€çš„åŒ…å®¹æ€§è‡ªç„¶è¯­è¨€å¤„ç†",
      "authors": [
        "Oluwadara Kalejaiye",
        "Luel Hagos Beyene",
        "David Ifeoluwa Adelani",
        "Mmekut-Mfon Gabriel Edet",
        "Aniefon Daniel Akpan",
        "Eno-Abasi Urua",
        "Anietie Andy"
      ],
      "abstract": "Nigeria is the most populous country in Africa with a population of more than 200 million people. More than 500 languages are spoken in Nigeria and it is one of the most linguistically diverse countries in the world. Despite this, natural language processing (NLP) research has mostly focused on the following four languages: Hausa, Igbo, Nigerian-Pidgin, and Yoruba (i.e <1% of the languages spoken in Nigeria). This is in part due to the unavailability of textual data in these languages to train and apply NLP algorithms. In this work, we introduce ibom -- a dataset for machine translation and topic classification in four Coastal Nigerian languages from the Akwa Ibom State region: Anaang, Efik, Ibibio, and Oro. These languages are not represented in Google Translate or in major benchmarks such as Flores-200 or SIB-200. We focus on extending Flores-200 benchmark to these languages, and further align the translated texts with topic labels based on SIB-200 classification dataset. Our evaluation shows that current LLMs perform poorly on machine translation for these languages in both zero-and-few shot settings. However, we find the few-shot samples to steadily improve topic classification with more shots.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å°¼æ—¥åˆ©äºšè¯­è¨€å¤šæ ·æ€§ä¸°å¯Œä½†NLPèµ„æºåŒ®ä¹çš„é—®é¢˜ï¼Œæ¨å‡ºäº†ibomæ•°æ®é›†ï¼Œä¸“æ³¨äºé˜¿å¤¸ä¼Šåšå§†å·åœ°åŒºçš„å››ç§æ²¿æµ·å°‘æ•°æ°‘æ—è¯­è¨€ï¼šAnaangã€Efikã€Ibibioå’ŒOroã€‚è¿™äº›è¯­è¨€æ­¤å‰æœªè¢«Google Translateæˆ–Flores-200ã€SIB-200ç­‰ä¸»æµåŸºå‡†æ¶µç›–ï¼Œç ”ç©¶å›¢é˜Ÿé€šè¿‡æ‰©å±•Flores-200åŸºå‡†å¹¶åŸºäºSIB-200è¿›è¡Œä¸»é¢˜æ ‡ç­¾å¯¹é½ï¼Œå¡«è¡¥äº†è¿™ä¸€ç©ºç™½ã€‚å®éªŒè¯„ä¼°è¡¨æ˜ï¼Œå½“å‰çš„LLMsåœ¨è¿™äº›è¯­è¨€çš„æœºå™¨ç¿»è¯‘ä»»åŠ¡ä¸­è¡¨ç°ä¸ä½³ï¼Œæ— è®ºæ˜¯åœ¨zero-shotè¿˜æ˜¯few-shotè®¾ç½®ä¸‹ã€‚ç„¶è€Œï¼Œç ”ç©¶å‘ç°é€šè¿‡å¢åŠ few-shotæ ·æœ¬çš„æ•°é‡ï¼Œå¯ä»¥ç¨³æ­¥æå‡è¿™äº›è¯­è¨€åœ¨ä¸»é¢˜åˆ†ç±»ä»»åŠ¡ä¸Šçš„æ€§èƒ½ï¼Œä¸ºå°¼æ—¥åˆ©äºšå°‘æ•°æ°‘æ—è¯­è¨€çš„åŒ…å®¹æ€§NLPç ”ç©¶è¿ˆå‡ºäº†é‡è¦ä¸€æ­¥ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at IJCNLP-AACL",
      "pdf_url": "https://arxiv.org/pdf/2511.06531v1",
      "published_date": "2025-11-09 20:33:39 UTC",
      "updated_date": "2025-11-09 20:33:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T18:17:58.368150+00:00"
    },
    {
      "arxiv_id": "2511.06529v1",
      "title": "TriShGAN: Enhancing Sparsity and Robustness in Multivariate Time Series Counterfactuals Explanation",
      "title_zh": "TriShGANï¼šå¢å¼ºå¤šå˜é‡æ—¶é—´åºåˆ—åäº‹å®è§£é‡Šçš„ç¨€ç–æ€§ä¸é²æ£’æ€§",
      "authors": [
        "Hongnan Ma",
        "Yiwei Shi",
        "Guanxiong Sun",
        "Mengyue Yang",
        "Weiru Liu"
      ],
      "abstract": "In decision-making processes, stakeholders often rely on counterfactual explanations, which provide suggestions about what should be changed in the queried instance to alter the outcome of an AI system. However, generating these explanations for multivariate time series presents challenges due to their complex, multi-dimensional nature. Traditional Nearest Unlike Neighbor-based methods typically substitute subsequences in a queried time series with influential subsequences from an NUN, which is not always realistic in real-world scenarios due to the rigid direct substitution. Counterfactual with Residual Generative Adversarial Networks-based methods aim to address this by learning from the distribution of observed data to generate synthetic counterfactual explanations. However, these methods primarily focus on minimizing the cost from the queried time series to the counterfactual explanations and often neglect the importance of distancing the counterfactual explanation from the decision boundary. This oversight can result in explanations that no longer qualify as counterfactual if minor changes occur within the model. To generate a more robust counterfactual explanation, we introduce TriShGAN, under the CounteRGAN framework enhanced by the incorporation of triplet loss. This unsupervised learning approach uses distance metric learning to encourage the counterfactual explanations not only to remain close to the queried time series but also to capture the feature distribution of the instance with the desired outcome, thereby achieving a better balance between minimal cost and robustness. Additionally, we integrate a Shapelet Extractor that strategically selects the most discriminative parts of the high-dimensional queried time series to enhance the sparsity of counterfactual explanation and efficiency of the training process.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†TriShGANï¼Œæ—¨åœ¨å¢å¼ºå¤šå˜é‡æ—¶é—´åºåˆ—(Multivariate Time Series)åäº‹å®è§£é‡Š(Counterfactuals Explanation)çš„ç¨€ç–æ€§å’Œé²æ£’æ€§ã€‚é’ˆå¯¹ç°æœ‰åŸºäºNearest Unlike Neighborçš„æ–¹æ³•æ›¿æ¢åƒµç¡¬ä»¥åŠåŸºäºResidual Generative Adversarial Networksçš„æ–¹æ³•å› å¿½è§†å†³ç­–è¾¹ç•Œè·ç¦»è€Œå¯¼è‡´é²æ£’æ€§ä¸è¶³çš„é—®é¢˜ï¼Œè¯¥ç ”ç©¶è¿›è¡Œäº†æ”¹è¿›ã€‚TriShGANåœ¨CounteRGANæ¡†æ¶ä¸‹å¼•å…¥äº†ä¸‰å…ƒç»„æŸå¤±(triplet loss)ï¼Œåˆ©ç”¨æ— ç›‘ç£è·ç¦»åº¦é‡å­¦ä¹ ç¡®ä¿åäº‹å®è§£é‡Šæ—¢è´´è¿‘æŸ¥è¯¢åºåˆ—åˆèƒ½æ•æ‰ç›®æ ‡ç»“æœçš„ç‰¹å¾åˆ†å¸ƒï¼Œä»è€Œåœ¨æœ€å°åŒ–æˆæœ¬å’Œé²æ£’æ€§ä¹‹é—´å–å¾—å¹³è¡¡ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹é›†æˆäº†ä¸€ä¸ªShapelet Extractorï¼Œé€šè¿‡ç­–ç•¥æ€§åœ°é€‰æ‹©é«˜ç»´æ—¶é—´åºåˆ—ä¸­æœ€å…·è¾¨åˆ«åŠ›çš„éƒ¨åˆ†ï¼Œæœ‰æ•ˆæå‡äº†è§£é‡Šçš„ç¨€ç–æ€§å’Œè®­ç»ƒè¿‡ç¨‹çš„æ•ˆç‡ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.06529v1",
      "published_date": "2025-11-09 20:32:20 UTC",
      "updated_date": "2025-11-09 20:32:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T18:18:20.223891+00:00"
    },
    {
      "arxiv_id": "2511.06522v1",
      "title": "FractalBench: Diagnosing Visual-Mathematical Reasoning Through Recursive Program Synthesis",
      "title_zh": "FractalBenchï¼šé€šè¿‡é€’å½’ç¨‹åºåˆæˆè¯Šæ–­è§†è§‰æ•°å­¦æ¨ç†",
      "authors": [
        "Jan Ondras",
        "Marek Å uppa"
      ],
      "abstract": "Mathematical reasoning requires abstracting symbolic rules from visual patterns -- inferring the infinite from the finite. We investigate whether multimodal AI systems possess this capability through FractalBench, a benchmark evaluating fractal program synthesis from images. Fractals provide ideal test cases: Iterated Function Systems with only a few contraction maps generate complex self-similar patterns through simple recursive rules, requiring models to bridge visual perception with mathematical abstraction. We evaluate four leading MLLMs -- GPT-4o, Claude 3.7 Sonnet, Gemini 2.5 Flash, and Qwen 2.5-VL -- on 12 canonical fractals. Models must generate executable Python code reproducing the fractal, enabling objective evaluation. Results reveal a striking disconnect: 76% generate syntactically valid code but only 4% capture mathematical structure. Success varies systematically -- models handle geometric transformations (Koch curves: 17-21%) but fail at branching recursion (trees: <2%), revealing fundamental gaps in mathematical abstraction. FractalBench provides a contamination-resistant diagnostic for visual-mathematical reasoning and is available at https://github.com/NaiveNeuron/FractalBench",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†FractalBenchï¼Œè¿™æ˜¯ä¸€ä¸ªé€šè¿‡ä»å›¾åƒè¿›è¡Œé€’å½’ç¨‹åºåˆæˆæ¥è¯„ä¼°è§†è§‰æ•°å­¦æ¨ç†èƒ½åŠ›çš„åŸºå‡†æµ‹è¯•ã€‚åˆ†å½¢ï¼ˆFractalsï¼‰åˆ©ç”¨è¿­ä»£å‡½æ•°ç³»ç»Ÿï¼ˆIterated Function Systemsï¼‰å’Œæ”¶ç¼©æ˜ å°„ï¼ˆcontraction mapsï¼‰ï¼Œé€šè¿‡ç®€å•çš„é€’å½’è§„åˆ™ç”Ÿæˆå¤æ‚çš„è‡ªç›¸ä¼¼æ¨¡å¼ï¼Œè¿™è¦æ±‚æ¨¡å‹èƒ½å¤Ÿè¿æ¥è§†è§‰æ„ŸçŸ¥ä¸æ•°å­¦æŠ½è±¡ã€‚ç ”ç©¶äººå‘˜è¯„ä¼°äº†GPT-4oã€Claude 3.7 Sonnetç­‰å››ç§é¢†å…ˆçš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰åœ¨12ç§ç»å…¸åˆ†å½¢ä¸Šçš„è¡¨ç°ï¼Œè¦æ±‚æ¨¡å‹ç”Ÿæˆå¯æ‰§è¡Œçš„Pythonä»£ç ä»¥å¤ç°åˆ†å½¢ã€‚ç»“æœæ­ç¤ºäº†æ˜¾è‘—çš„èƒ½åŠ›æ–­å±‚ï¼šè™½ç„¶76%ç”Ÿæˆçš„ä»£ç åœ¨è¯­æ³•ä¸Šæœ‰æ•ˆï¼Œä½†ä»…æœ‰4%æ•æ‰åˆ°äº†æ­£ç¡®çš„æ•°å­¦ç»“æ„ã€‚æ¨¡å‹åœ¨å¤„ç†å‡ ä½•å˜æ¢ï¼ˆå¦‚Koch curvesï¼‰æ—¶è¡¨ç°å°šå¯ï¼Œä½†åœ¨åˆ†æ”¯é€’å½’ï¼ˆå¦‚treesï¼‰æ–¹é¢å‡ ä¹å®Œå…¨å¤±è´¥ï¼Œæš´éœ²äº†å…¶åœ¨æ•°å­¦æŠ½è±¡æ–¹é¢çš„æ ¹æœ¬ç¼ºé™·ã€‚FractalBenchä¸ºè§†è§‰æ•°å­¦æ¨ç†æä¾›äº†ä¸€ç§æŠ—æ±¡æŸ“çš„è¯Šæ–­å·¥å…·ï¼Œçªæ˜¾äº†å½“å‰AIç³»ç»Ÿåœ¨ä»æœ‰é™è§†è§‰æ¨¡å¼æ¨æ–­æ— é™ç¬¦å·è§„åˆ™æ–¹é¢çš„èƒ½åŠ›å·®è·ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to The 5th Workshop on Mathematical Reasoning and AI at the 39th Conference on Neural Information Processing Systems (NeurIPS 2025); 25 pages, 14 figures, 8 tables; Code available at https://github.com/NaiveNeuron/FractalBench",
      "pdf_url": "https://arxiv.org/pdf/2511.06522v1",
      "published_date": "2025-11-09 20:22:42 UTC",
      "updated_date": "2025-11-09 20:22:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T18:19:07.112750+00:00"
    },
    {
      "arxiv_id": "2511.06519v1",
      "title": "On the Analogy between Human Brain and LLMs: Spotting Key Neurons in Grammar Perception",
      "title_zh": "äººè„‘ä¸å¤§è¯­è¨€æ¨¡å‹çš„ç±»æ¯”ï¼šè¯†åˆ«è¯­æ³•æ„ŸçŸ¥ä¸­çš„å…³é”®ç¥ç»å…ƒ",
      "authors": [
        "Sanaz Saki Norouzi",
        "Mohammad Masjedi",
        "Pascal Hitzler"
      ],
      "abstract": "Artificial Neural Networks, the building blocks of AI, were inspired by the human brain's network of neurons. Over the years, these networks have evolved to replicate the complex capabilities of the brain, allowing them to handle tasks such as image and language processing. In the realm of Large Language Models, there has been a keen interest in making the language learning process more akin to that of humans. While neuroscientific research has shown that different grammatical categories are processed by different neurons in the brain, we show that LLMs operate in a similar way. Utilizing Llama 3, we identify the most important neurons associated with the prediction of words belonging to different part-of-speech tags. Using the achieved knowledge, we train a classifier on a dataset, which shows that the activation patterns of these key neurons can reliably predict part-of-speech tags on fresh data. The results suggest the presence of a subspace in LLMs focused on capturing part-of-speech tag concepts, resembling patterns observed in lesion studies of the brain in neuroscience.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†äººç±»å¤§è„‘ä¸å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨è¯­æ³•æ„ŸçŸ¥æ–¹é¢çš„ç±»æ¯”å…³ç³»ï¼Œç‰¹åˆ«æ˜¯é’ˆå¯¹ä¸åŒè¯­æ³•ç±»åˆ«çš„å¤„ç†æœºåˆ¶ã€‚ç ”ç©¶äººå‘˜åˆ©ç”¨Llama 3æ¨¡å‹ï¼ŒæˆåŠŸè¯†åˆ«äº†åœ¨é¢„æµ‹ä¸åŒè¯æ€§(part-of-speech tags)æ—¶èµ·å…³é”®ä½œç”¨çš„ç‰¹å®šç¥ç»å…ƒã€‚é€šè¿‡åŸºäºè¿™äº›å…³é”®ç¥ç»å…ƒæ¿€æ´»æ¨¡å¼è®­ç»ƒçš„åˆ†ç±»å™¨ï¼Œç ”ç©¶è¯æ˜äº†è¿™äº›æ¨¡å¼èƒ½å¤Ÿå¯é åœ°é¢„æµ‹æ–°æ•°æ®ä¸­çš„è¯æ€§æ ‡ç­¾ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒLLMså†…éƒ¨å­˜åœ¨ä¸€ä¸ªä¸“é—¨æ•æ‰è¯æ€§æ¦‚å¿µçš„å­ç©ºé—´ï¼Œè¿™ä¸€å‘ç°ä¸ç¥ç»ç§‘å­¦ä¸­è„‘æŸä¼¤ç ”ç©¶(lesion studies)æ‰€è§‚å¯Ÿåˆ°çš„æ¨¡å¼é«˜åº¦ç›¸ä¼¼ï¼Œè¿›ä¸€æ­¥æ­ç¤ºäº†äººå·¥ç¥ç»ç½‘ç»œä¸ç”Ÿç‰©å¤§è„‘åœ¨è¯­è¨€å¤„ç†ä¸Šçš„ç›¸ä¼¼æ€§ã€‚",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "q-bio.NC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.06519v1",
      "published_date": "2025-11-09 20:08:21 UTC",
      "updated_date": "2025-11-09 20:08:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T18:22:16.693281+00:00"
    },
    {
      "arxiv_id": "2511.17543v1",
      "title": "Evo* 2025 -- Late-Breaking Abstracts Volume",
      "title_zh": "Evo* 2025ï¼šæœ€æ–°æ‘˜è¦é›†",
      "authors": [
        "A. M. Mora",
        "A. I. Esparcia-AlcÃ¡zar",
        "M. S. Cruz"
      ],
      "abstract": "Volume containing the Late-Breaking Abstracts submitted to the Evo* 2025 Conference, held in Trieste (Italy) from April 23rd to 25th. These extended abstracts showcase ongoing research and preliminary findings exploring the application of various Bioinspired Methods (primarily Evolutionary Computation) to a range of problems, many of which address real-world scenarios.",
      "tldr_zh": "æœ¬å·æ”¶å½•äº†æäº¤ç»™Evo* 2025ä¼šè®®çš„Late-Breaking Abstractsï¼Œè¯¥ä¼šè®®äº4æœˆ23æ—¥è‡³25æ—¥åœ¨æ„å¤§åˆ©Triesteä¸¾è¡Œã€‚è¿™äº›æ‰©å±•æ‘˜è¦æ±‡é›†äº†ç›¸å…³é¢†åŸŸçš„æœ€æ–°è¿›å±•ï¼Œé‡ç‚¹å±•ç¤ºäº†å…³äºBioinspired Methodsï¼ˆä¸»è¦æ˜¯Evolutionary Computationï¼‰åº”ç”¨çš„æ­£åœ¨è¿›è¡Œçš„ç ”ç©¶å·¥ä½œå’Œåˆæ­¥å‘ç°ã€‚è¯¥å·æ¶µç›–äº†å¹¿æ³›çš„é—®é¢˜é¢†åŸŸï¼Œå…¶ä¸­è®¸å¤šç ”ç©¶è‡´åŠ›äºè§£å†³ç°å®ä¸–ç•Œçš„å¤æ‚åœºæ™¯ã€‚é€šè¿‡è¿™äº›æ‘˜è¦ï¼Œè¯»è€…å¯ä»¥å¿«é€Ÿäº†è§£è¯¥é¢†åŸŸçš„å‰æ²¿åŠ¨æ€å’Œæœªæ¥æ½œåœ¨çš„ç ”ç©¶æ–¹å‘ã€‚",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "LBAs accepted in Evo* 2025. Part of the Conference Proceedings",
      "pdf_url": "https://arxiv.org/pdf/2511.17543v1",
      "published_date": "2025-11-09 19:16:04 UTC",
      "updated_date": "2025-11-09 19:16:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T18:22:53.328676+00:00"
    },
    {
      "arxiv_id": "2511.06497v1",
      "title": "Rethinking what Matters: Effective and Robust Multilingual Realignment for Low-Resource Languages",
      "title_zh": "é‡æ€å…³é”®æ‰€åœ¨ï¼šé¢å‘ä½èµ„æºè¯­è¨€çš„æœ‰æ•ˆä¸”é²æ£’çš„å¤šè¯­è¨€é‡å¯¹é½",
      "authors": [
        "Quang Phuoc Nguyen",
        "David Anugraha",
        "Felix Gaschi",
        "Jun Bin Cheng",
        "En-Shiun Annie Lee"
      ],
      "abstract": "Realignment is a promising strategy to improve cross-lingual transfer in multilingual language models. However, empirical results are mixed and often unreliable, particularly for typologically distant or low-resource languages (LRLs) compared to English. Moreover, word realignment tools often rely on high-quality parallel data, which can be scarce or noisy for many LRLs. In this work, we conduct an extensive empirical study to investigate whether realignment truly benefits from using all available languages, or if strategically selected subsets can offer comparable or even improved cross-lingual transfer, and study the impact on LRLs. Our controlled experiments show that realignment can be particularly effective for LRLs and that using carefully selected, linguistically diverse subsets can match full multilingual alignment, and even outperform it for unseen LRLs. This indicates that effective realignment does not require exhaustive language coverage and can reduce data collection overhead, while remaining both efficient and robust when guided by informed language selection.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤šè¯­è¨€è¯­è¨€æ¨¡å‹ä¸­çš„è·¨è¯­è¨€è¿ç§»ï¼ˆCross-lingual transferï¼‰é—®é¢˜ï¼Œé‡æ–°å®¡è§†äº† Realignment ç­–ç•¥çš„æœ‰æ•ˆæ€§ï¼Œç‰¹åˆ«æ˜¯é’ˆå¯¹ä½èµ„æºè¯­è¨€ï¼ˆLRLsï¼‰å’Œä¸è‹±è¯­ç±»å‹å·®å¼‚è¾ƒå¤§çš„è¯­è¨€ã€‚å°½ç®¡ Realignment æ˜¯ä¸€ç§æœ‰å‰æ™¯çš„ç­–ç•¥ï¼Œä½†ç°æœ‰æ–¹æ³•å¾€å¾€ä¾èµ–ç¨€ç¼ºçš„é«˜è´¨é‡å¹³è¡Œæ•°æ®ï¼Œä¸”å®è¯ç»“æœä¸ç¨³å®šã€‚ä½œè€…é€šè¿‡å¹¿æ³›çš„å®è¯ç ”ç©¶ï¼Œæ¢è®¨äº†æ˜¯å¦å¯ä»¥é€šè¿‡ç­–ç•¥æ€§åœ°é€‰æ‹©è¯­è¨€å­é›†æ¥æ›¿ä»£å…¨é‡è¯­è¨€å¯¹é½ã€‚æ§åˆ¶å®éªŒè¡¨æ˜ï¼ŒRealignment å¯¹ LRLs ç‰¹åˆ«æœ‰æ•ˆï¼Œä¸”ä½¿ç”¨ç²¾å¿ƒæŒ‘é€‰çš„ã€å…·æœ‰è¯­è¨€å¤šæ ·æ€§çš„å­é›†ä¸ä»…èƒ½è¾¾åˆ°å…¨å¤šè¯­è¨€å¯¹é½çš„æ•ˆæœï¼Œç”šè‡³åœ¨æœªè§è¿‡çš„ LRLs ä¸Šè¡¨ç°æ›´ä¼˜ã€‚è¿™ä¸€å‘ç°è¡¨æ˜ï¼Œæœ‰æ•ˆçš„ Realignment ä¸éœ€è¦è¯¦å°½çš„è¯­è¨€è¦†ç›–ï¼Œé€šè¿‡æ˜æ™ºçš„è¯­è¨€é€‰æ‹©å¯ä»¥åœ¨å‡å°‘æ•°æ®æ”¶é›†å¼€é”€çš„åŒæ—¶ï¼Œä¿æŒæ¨¡å‹çš„é«˜æ•ˆæ€§å’Œé²æ£’æ€§ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to IJCNLP-AACL 2025",
      "pdf_url": "https://arxiv.org/pdf/2511.06497v1",
      "published_date": "2025-11-09 18:54:17 UTC",
      "updated_date": "2025-11-09 18:54:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T18:23:06.310416+00:00"
    },
    {
      "arxiv_id": "2511.06496v1",
      "title": "A Low-Rank Method for Vision Language Model Hallucination Mitigation in Autonomous Driving",
      "title_zh": "è‡ªåŠ¨é©¾é©¶ä¸­è§†è§‰è¯­è¨€æ¨¡å‹å¹»è§‰ç¼“è§£çš„ä½ç§©æ–¹æ³•",
      "authors": [
        "Keke Long",
        "Jiacheng Guo",
        "Tianyun Zhang",
        "Hongkai Yu",
        "Xiaopeng Li"
      ],
      "abstract": "Vision Language Models (VLMs) are increasingly used in autonomous driving to help understand traffic scenes, but they sometimes produce hallucinations, which are false details not grounded in the visual input. Detecting and mitigating hallucinations is challenging when ground-truth references are unavailable and model internals are inaccessible. This paper proposes a novel self-contained low-rank approach to automatically rank multiple candidate captions generated by multiple VLMs based on their hallucination levels, using only the captions themselves without requiring external references or model access. By constructing a sentence-embedding matrix and decomposing it into a low-rank consensus component and a sparse residual, we use the residual magnitude to rank captions: selecting the one with the smallest residual as the most hallucination-free. Experiments on the NuScenes dataset demonstrate that our approach achieves 87% selection accuracy in identifying hallucination-free captions, representing a 19% improvement over the unfiltered baseline and a 6-10% improvement over multi-agent debate method. The sorting produced by sparse error magnitudes shows strong correlation with human judgments of hallucinations, validating our scoring mechanism. Additionally, our method, which can be easily parallelized, reduces inference time by 51-67% compared to debate approaches, making it practical for real-time autonomous driving applications.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è‡ªåŠ¨é©¾é©¶åœºæ™¯ä¸­è§†è§‰è¯­è¨€æ¨¡å‹(VLMs)å®¹æ˜“äº§ç”Ÿå¹»è§‰çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§æ–°é¢–çš„è‡ªåŒ…å«ä½ç§©(Low-Rank)æ–¹æ³•ï¼Œæ—¨åœ¨åœ¨æ— å¤–éƒ¨å‚è€ƒçœŸå€¼æˆ–æ¨¡å‹å†…éƒ¨è®¿é—®æƒé™çš„æƒ…å†µä¸‹è‡ªåŠ¨ç­›é€‰é«˜è´¨é‡æè¿°ã€‚è¯¥æ–¹æ³•é€šè¿‡æ„å»ºå¥å­åµŒå…¥çŸ©é˜µï¼Œå°†å…¶åˆ†è§£ä¸ºä½ç§©å…±è¯†åˆ†é‡å’Œç¨€ç–æ®‹å·®ï¼Œåˆ©ç”¨ç¨€ç–æ®‹å·®çš„å¹…åº¦å¯¹å¤šä¸ªVLMç”Ÿæˆçš„å€™é€‰æè¿°è¿›è¡Œæ’åºï¼Œå¹¶å°†æ®‹å·®æœ€å°çš„æè¿°è§†ä¸ºæœ€æ— å¹»è§‰çš„ç»“æœã€‚åœ¨NuScenesæ•°æ®é›†ä¸Šçš„å®éªŒæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨è¯†åˆ«æ— å¹»è§‰æè¿°æ–¹é¢è¾¾åˆ°äº†87%çš„é€‰æ‹©å‡†ç¡®ç‡ï¼Œç›¸æ¯”æœªè¿‡æ»¤åŸºçº¿æå‡äº†19%ï¼Œæ¯”å¤šæ™ºèƒ½ä½“è¾©è®º(multi-agent debate)æ–¹æ³•æå‡äº†6-10%ã€‚æ­¤å¤–ï¼ŒåŸºäºç¨€ç–è¯¯å·®å¹…åº¦çš„æ’åºç»“æœä¸äººç±»å¯¹å¹»è§‰çš„åˆ¤æ–­è¡¨ç°å‡ºå¼ºç›¸å…³æ€§ï¼ŒéªŒè¯äº†è¯„åˆ†æœºåˆ¶çš„æœ‰æ•ˆæ€§ã€‚è¯¥æ–¹æ³•è¿˜å…·æœ‰æ˜“äºå¹¶è¡ŒåŒ–çš„ä¼˜åŠ¿ï¼Œç›¸æ¯”è¾©è®ºæ–¹æ³•å‡å°‘äº†51-67%çš„æ¨ç†æ—¶é—´ï¼Œä½¿å…¶éå¸¸é€‚åˆå®æ—¶è‡ªåŠ¨é©¾é©¶åº”ç”¨çš„éœ€æ±‚ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.06496v1",
      "published_date": "2025-11-09 18:50:30 UTC",
      "updated_date": "2025-11-09 18:50:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T18:23:31.228162+00:00"
    },
    {
      "arxiv_id": "2511.06494v1",
      "title": "Route Experts by Sequence, not by Token",
      "title_zh": "åŸºäºåºåˆ—è€Œéè¯å…ƒçš„ä¸“å®¶è·¯ç”±",
      "authors": [
        "Tiansheng Wen",
        "Yifei Wang",
        "Aosong Feng",
        "Long Ma",
        "Xinyang Liu",
        "Yifan Wang",
        "Lixuan Guo",
        "Bo Chen",
        "Stefanie Jegelka",
        "Chenyu You"
      ],
      "abstract": "Mixture-of-Experts (MoE) architectures scale large language models (LLMs) by activating only a subset of experts per token, but the standard TopK routing assigns the same fixed number of experts to all tokens, ignoring their varying complexity. Prior adaptive routing methods introduce additional modules and hyperparameters, often requiring costly retraining from scratch. We propose Sequence-level TopK (SeqTopK), a minimal modification that shifts the expert budget from the token level to the sequence level. By selecting the top $T \\cdot K$ experts across all $T$ tokens, SeqTopK enables end-to-end learned dynamic allocation -- assigning more experts to difficult tokens and fewer to easy ones -- while preserving the same overall budget. SeqTopK requires only a few lines of code, adds less than 1% overhead, and remains fully compatible with pretrained MoE models. Experiments across math, coding, law, and writing show consistent improvements over TopK and prior parameter-free adaptive methods, with gains that become substantially larger under higher sparsity (up to 16.9%). These results highlight SeqTopK as a simple, efficient, and scalable routing strategy, particularly well-suited for the extreme sparsity regimes of next-generation LLMs. Code is available at https://github.com/Y-Research-SBU/SeqTopK.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ··åˆä¸“å®¶æ¨¡å‹(Mixture-of-Experts, MoE)ä¸­æ ‡å‡†TopKè·¯ç”±å¿½ç•¥Tokenå¤æ‚æ€§å·®å¼‚çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åä¸ºSequence-level TopK (SeqTopK)çš„è·¯ç”±ç­–ç•¥ã€‚SeqTopKå°†ä¸“å®¶é¢„ç®—ä»Tokençº§åˆ«è½¬ç§»åˆ°åºåˆ—çº§åˆ«ï¼Œé€šè¿‡åœ¨æ‰€æœ‰$T$ä¸ªTokenä¸­é€‰æ‹©å‰$T \\cdot K$ä¸ªä¸“å®¶ï¼Œå®ç°äº†ç«¯åˆ°ç«¯çš„åŠ¨æ€åˆ†é…ã€‚è¿™ç§æ–¹æ³•èƒ½å¤Ÿæ ¹æ®å¤„ç†éš¾åº¦ä¸ºå›°éš¾çš„Tokenåˆ†é…æ›´å¤šä¸“å®¶ï¼Œä¸ºç®€å•çš„Tokenåˆ†é…è¾ƒå°‘ä¸“å®¶ï¼ŒåŒæ—¶ä¿æŒæ•´ä½“è®¡ç®—é¢„ç®—ä¸å˜ã€‚è¯¥ç­–ç•¥ä»…éœ€å°‘é‡ä»£ç ä¿®æ”¹ï¼Œå¢åŠ çš„å¼€é”€ä¸åˆ°1%ï¼Œä¸”å®Œå…¨å…¼å®¹é¢„è®­ç»ƒçš„MoEæ¨¡å‹ï¼Œæ— éœ€ä»å¤´é‡æ–°è®­ç»ƒã€‚åœ¨æ•°å­¦ã€ä»£ç ã€æ³•å¾‹å’Œå†™ä½œç­‰ä»»åŠ¡ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒSeqTopKåœ¨æ€§èƒ½ä¸Šä¸€è‡´ä¼˜äºæ ‡å‡†TopKåŠå…ˆå‰çš„æ— å‚æ•°è‡ªé€‚åº”æ–¹æ³•ã€‚ç‰¹åˆ«æ˜¯åœ¨é«˜ç¨€ç–åº¦è®¾ç½®ä¸‹ï¼Œè¯¥æ–¹æ³•çš„æ€§èƒ½æå‡æ›´ä¸ºæ˜¾è‘—ï¼Œæœ€é«˜å¯è¾¾16.9%ã€‚ç»“æœçªæ˜¾äº†SeqTopKä½œä¸ºä¸€ç§ç®€å•ã€é«˜æ•ˆä¸”å¯æ‰©å±•çš„è·¯ç”±ç­–ç•¥ï¼Œç‰¹åˆ«é€‚ç”¨äºä¸‹ä¸€ä»£LLMçš„æåº¦ç¨€ç–åœºæ™¯ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IT"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.06494v1",
      "published_date": "2025-11-09 18:36:07 UTC",
      "updated_date": "2025-11-09 18:36:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T18:23:54.806581+00:00"
    },
    {
      "arxiv_id": "2511.06492v1",
      "title": "Explainable AI For Early Detection Of Sepsis",
      "title_zh": "ç”¨äºè„“æ¯’ç—‡æ—©æœŸæ£€æµ‹çš„å¯è§£é‡Šäººå·¥æ™ºèƒ½",
      "authors": [
        "Atharva Thakur",
        "Shruti Dhumal"
      ],
      "abstract": "Sepsis is a life-threatening condition that requires rapid detection and treatment to prevent progression to severe sepsis, septic shock, or multi-organ failure. Despite advances in medical technology, it remains a major challenge for clinicians. While recent machine learning models have shown promise in predicting sepsis onset, their black-box nature limits interpretability and clinical trust. In this study, we present an interpretable AI approach for sepsis analysis that integrates machine learning with clinical knowledge. Our method not only delivers accurate predictions of sepsis onset but also enables clinicians to understand, validate, and align model outputs with established medical expertise.",
      "tldr_zh": "è´¥è¡€ç—‡(Sepsis)æ˜¯ä¸€ç§å±åŠç”Ÿå‘½çš„ç–¾ç—…ï¼Œå°½ç®¡åŒ»ç–—æŠ€æœ¯ä¸æ–­è¿›æ­¥ï¼Œä½†å…¶æ—©æœŸæ£€æµ‹å¯¹äºä¸´åºŠåŒ»ç”Ÿè€Œè¨€ä»æ˜¯ä¸€å¤§æŒ‘æˆ˜ã€‚è™½ç„¶ç°æœ‰çš„æœºå™¨å­¦ä¹ æ¨¡å‹åœ¨é¢„æµ‹è´¥è¡€ç—‡å‘ä½œæ–¹é¢æ˜¾ç¤ºå‡ºæ½œåŠ›ï¼Œä½†å…¶â€œé»‘ç›’â€ç‰¹æ€§é™åˆ¶äº†æ¨¡å‹çš„å¯è§£é‡Šæ€§å’Œä¸´åºŠä¿¡ä»»åº¦ã€‚æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§é’ˆå¯¹è´¥è¡€ç—‡åˆ†æçš„å¯è§£é‡Šäººå·¥æ™ºèƒ½(Explainable AI)æ–¹æ³•ï¼Œæ—¨åœ¨å°†æœºå™¨å­¦ä¹ æŠ€æœ¯ä¸ä¸´åºŠåŒ»å­¦çŸ¥è¯†æ·±åº¦èåˆã€‚è¯¥æ–¹æ³•ä¸ä»…èƒ½å¤Ÿæä¾›å‡†ç¡®çš„è´¥è¡€ç—‡å‘ä½œé¢„æµ‹ï¼Œè¿˜èƒ½æ”¯æŒä¸´åºŠåŒ»ç”Ÿç†è§£å’ŒéªŒè¯æ¨¡å‹è¾“å‡ºï¼Œå¹¶ä½¿å…¶ä¸æ—¢æœ‰çš„åŒ»å­¦ä¸“ä¸šçŸ¥è¯†ä¿æŒä¸€è‡´ï¼Œä»è€Œå¢å¼ºäº†AIè¾…åŠ©è¯Šæ–­çš„å¯é æ€§ä¸å®ç”¨æ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.06492v1",
      "published_date": "2025-11-09 18:33:06 UTC",
      "updated_date": "2025-11-09 18:33:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T18:24:17.001133+00:00"
    },
    {
      "arxiv_id": "2511.06490v1",
      "title": "Zooming into Comics: Region-Aware RL Improves Fine-Grained Comic Understanding in Vision-Language Models",
      "title_zh": "æ·±å…¥æ¼«ç”»ï¼šåŒºåŸŸæ„ŸçŸ¥å¼ºåŒ–å­¦ä¹ æå‡è§†è§‰è¯­è¨€æ¨¡å‹çš„ç»†ç²’åº¦æ¼«ç”»ç†è§£",
      "authors": [
        "Yule Chen",
        "Yufan Ren",
        "Sabine SÃ¼sstrunk"
      ],
      "abstract": "Complex visual narratives, such as comics, present a significant challenge to Vision-Language Models (VLMs). Despite excelling on natural images, VLMs often struggle with stylized line art, onomatopoeia, and densely packed multi-panel layouts. To address this gap, we introduce AI4VA-FG, the first fine-grained and comprehensive benchmark for VLM-based comic understanding. It spans tasks from foundational recognition and detection to high-level character reasoning and narrative construction, supported by dense annotations for characters, poses, and depth. Beyond that, we evaluate state-of-the-art proprietary models, including GPT-4o and Gemini-2.5, and open-source models such as Qwen2.5-VL, revealing substantial performance deficits across core tasks of our benchmarks and underscoring that comic understanding remains an unsolved challenge. To enhance VLMs' capabilities in this domain, we systematically investigate post-training strategies, including supervised fine-tuning on solutions (SFT-S), supervised fine-tuning on reasoning trajectories (SFT-R), and reinforcement learning (RL). Beyond that, inspired by the emerging \"Thinking with Images\" paradigm, we propose Region-Aware Reinforcement Learning (RARL) for VLMs, which trains models to dynamically attend to relevant regions through zoom-in operations. We observe that when applied to the Qwen2.5-VL model, RL and RARL yield significant gains in low-level entity recognition and high-level storyline ordering, paving the way for more accurate and efficient VLM applications in the comics domain.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹Vision-Language Models (VLMs)åœ¨å¤„ç†æ¼«ç”»ç­‰å¤æ‚è§†è§‰å™äº‹æ—¶é¢ä¸´çš„é£æ ¼åŒ–çº¿æ¡ã€æ‹Ÿå£°è¯åŠå¤šé¢æ¿å¸ƒå±€ç­‰æŒ‘æˆ˜ï¼Œæå‡ºäº†é¦–ä¸ªç”¨äºVLMæ¼«ç”»ç†è§£çš„ç»†ç²’åº¦ç»¼åˆåŸºå‡†AI4VA-FGã€‚è¯¥åŸºå‡†æ¶µç›–ä»åŸºç¡€è¯†åˆ«æ£€æµ‹åˆ°é«˜çº§è§’è‰²æ¨ç†åŠå™äº‹æ„å»ºç­‰ä»»åŠ¡ï¼Œå¹¶æä¾›äº†å¯†é›†çš„æ³¨é‡Šæ”¯æŒã€‚ä½œè€…è¯„ä¼°äº†åŒ…æ‹¬GPT-4oã€Gemini-2.5å’ŒQwen2.5-VLåœ¨å†…çš„å…ˆè¿›æ¨¡å‹ï¼Œæ­ç¤ºäº†å½“å‰æ¨¡å‹åœ¨æ ¸å¿ƒä»»åŠ¡ä¸Šçš„æ˜¾è‘—æ€§èƒ½ç¼ºé™·ã€‚ä¸ºäº†æå‡èƒ½åŠ›ï¼Œç ”ç©¶ç³»ç»Ÿåœ°æ¢è®¨äº†åŒ…æ‹¬ç›‘ç£å¾®è°ƒ(SFT)å’Œå¼ºåŒ–å­¦ä¹ (RL)åœ¨å†…çš„åè®­ç»ƒç­–ç•¥ã€‚å—\"Thinking with Images\"èŒƒå¼å¯å‘ï¼Œè®ºæ–‡æå‡ºäº†Region-Aware Reinforcement Learning (RARL)ï¼Œè®­ç»ƒæ¨¡å‹é€šè¿‡æ”¾å¤§æ“ä½œåŠ¨æ€å…³æ³¨ç›¸å…³åŒºåŸŸã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨Qwen2.5-VLæ¨¡å‹ä¸Šåº”ç”¨RLå’ŒRARLèƒ½æ˜¾è‘—æå‡ä½çº§å®ä½“è¯†åˆ«å’Œé«˜çº§æ•…äº‹æƒ…èŠ‚æ’åºçš„æ€§èƒ½ï¼Œä¸ºæ›´å‡†ç¡®é«˜æ•ˆçš„æ¼«ç”»é¢†åŸŸVLMåº”ç”¨é“ºå¹³äº†é“è·¯ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.06490v1",
      "published_date": "2025-11-09 18:27:45 UTC",
      "updated_date": "2025-11-09 18:27:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T18:25:39.024664+00:00"
    },
    {
      "arxiv_id": "2511.07483v1",
      "title": "Beyond Correctness: Confidence-Aware Reward Modeling for Enhancing Large Language Model Reasoning",
      "title_zh": "è¶…è¶Šæ­£ç¡®æ€§ï¼šå¢å¼ºå¤§è¯­è¨€æ¨¡å‹æ¨ç†çš„ç½®ä¿¡åº¦æ„ŸçŸ¥å¥–åŠ±å»ºæ¨¡",
      "authors": [
        "Qianxi He",
        "Qingyu Ren",
        "Shanzhe Lei",
        "Xuhong Wang",
        "Yingchun Wang"
      ],
      "abstract": "Recent advancements in large language models (LLMs) have shifted the post-training paradigm from traditional instruction tuning and human preference alignment toward reinforcement learning (RL) focused on reasoning capabilities. However, numerous technical reports indicate that purely rule-based reward RL frequently results in poor-quality reasoning chains or inconsistencies between reasoning processes and final answers, particularly when the base model is of smaller scale. During the RL exploration process, models might employ low-quality reasoning chains due to the lack of knowledge, occasionally producing correct answers randomly and receiving rewards based on established rule-based judges. This constrains the potential for resource-limited organizations to conduct direct reinforcement learning training on smaller-scale models. We propose a novel confidence-based reward model tailored for enhancing STEM reasoning capabilities. Unlike conventional approaches, our model penalizes not only incorrect answers but also low-confidence correct responses, thereby promoting more robust and logically consistent reasoning. We validate the effectiveness of our approach through static evaluations, Best-of-N inference tests, and PPO-based RL training. Our method outperforms several state-of-the-art open-source reward models across diverse STEM benchmarks. We release our codes and model in https://github.com/qianxiHe147/C2RM.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨åè®­ç»ƒé˜¶æ®µå‘å¼ºåŒ–å­¦ä¹ (RL)è½¬å‹æ—¶é¢ä¸´çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§ä¸“ä¸ºå¢å¼ºSTEMæ¨ç†èƒ½åŠ›è®¾è®¡çš„åŸºäºç½®ä¿¡åº¦çš„å¥–åŠ±æ¨¡å‹ã€‚ç°æœ‰çš„çº¯è§„åˆ™å¥–åŠ±æœºåˆ¶å¸¸å¯¼è‡´æ¨ç†é“¾è´¨é‡ä½ä¸‹æˆ–è¿‡ç¨‹ä¸ç»“æœä¸ä¸€è‡´ï¼Œå°¤å…¶æ˜¯åœ¨å°è§„æ¨¡æ¨¡å‹é€šè¿‡ç¼ºä¹çŸ¥è¯†çš„ä½è´¨é‡æ¨ç†å¶ç„¶è·å¾—æ­£ç¡®ç­”æ¡ˆæ—¶ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œè¯¥æ¨¡å‹ä¸ä»…æƒ©ç½šé”™è¯¯ç­”æ¡ˆï¼Œè¿˜å¯¹ä½ç½®ä¿¡åº¦çš„æ­£ç¡®å›ç­”è¿›è¡Œæƒ©ç½šï¼Œä»è€Œä¿ƒä½¿æ¨¡å‹ç”Ÿæˆæ›´ç¨³å¥ä¸”é€»è¾‘ä¸€è‡´çš„æ¨ç†è¿‡ç¨‹ã€‚ä½œè€…é€šè¿‡é™æ€è¯„ä¼°ã€Best-of-Næ¨ç†æµ‹è¯•ä»¥åŠåŸºäºPPOçš„å¼ºåŒ–å­¦ä¹ è®­ç»ƒéªŒè¯äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªSTEMåŸºå‡†æµ‹è¯•ä¸­ä¼˜äºå¤šç§æœ€å…ˆè¿›çš„å¼€æºå¥–åŠ±æ¨¡å‹ï¼Œæœ‰æ•ˆæå‡äº†æ¨¡å‹çš„æ¨ç†å¯é æ€§ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.07483v1",
      "published_date": "2025-11-09 17:58:40 UTC",
      "updated_date": "2025-11-09 17:58:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T18:25:40.360489+00:00"
    },
    {
      "arxiv_id": "2511.06471v2",
      "title": "GHOST: Solving the Traveling Salesman Problem on Graphs of Convex Sets",
      "title_zh": "GHOSTï¼šæ±‚è§£å‡¸é›†å›¾ä¸Šçš„æ—…è¡Œå•†é—®é¢˜",
      "authors": [
        "Jingtao Tang",
        "Hang Ma"
      ],
      "abstract": "We study GCS-TSP, a new variant of the Traveling Salesman Problem (TSP) defined over a Graph of Convex Sets (GCS) -- a powerful representation for trajectory planning that decomposes the configuration space into convex regions connected by a sparse graph. In this setting, edge costs are not fixed but depend on the specific trajectory selected through each convex region, making classical TSP methods inapplicable. We introduce GHOST, a hierarchical framework that optimally solves the GCS-TSP by combining combinatorial tour search with convex trajectory optimization. GHOST systematically explores tours on a complete graph induced by the GCS, using a novel abstract-path-unfolding algorithm to compute admissible lower bounds that guide best-first search at both the high level (over tours) and the low level (over feasible GCS paths realizing the tour). These bounds provide strong pruning power, enabling efficient search while avoiding unnecessary convex optimization calls. We prove that GHOST guarantees optimality and present a bounded-suboptimal variant for time-critical scenarios. Experiments show that GHOST is orders-of-magnitude faster than unified mixed-integer convex programming baselines for simple cases and uniquely handles complex trajectory planning problems involving high-order continuity constraints and an incomplete GCS.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†GCS-TSPï¼Œå³å®šä¹‰åœ¨å‡¸é›†å›¾(Graph of Convex Sets, GCS)ä¸Šçš„æ—…è¡Œå•†é—®é¢˜(TSP)æ–°å˜ä½“ï¼Œå…¶ä¸­è¾¹æˆæœ¬å–å†³äºç©¿è¿‡å‡¸åŒºåŸŸçš„å…·ä½“è½¨è¿¹ï¼Œä½¿å¾—ä¼ ç»ŸTSPæ–¹æ³•ä¸å†é€‚ç”¨ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†GHOSTï¼Œè¿™æ˜¯ä¸€ä¸ªåˆ†å±‚æ¡†æ¶ï¼Œé€šè¿‡ç»“åˆç»„åˆè·¯å¾„æœç´¢ä¸å‡¸è½¨è¿¹ä¼˜åŒ–æ¥æœ€ä¼˜åœ°è§£å†³GCS-TSPé—®é¢˜ã€‚GHOSTåˆ©ç”¨ä¸€ç§æ–°é¢–çš„æŠ½è±¡è·¯å¾„å±•å¼€(abstract-path-unfolding)ç®—æ³•è®¡ç®—å¯æ¥å—çš„ä¸‹ç•Œï¼Œä»è€ŒæŒ‡å¯¼é«˜å±‚ï¼ˆè·¯å¾„ï¼‰å’Œåº•å±‚ï¼ˆå¯è¡ŒGCSè·¯å¾„ï¼‰çš„æœ€ä½³ä¼˜å…ˆæœç´¢ï¼Œå¹¶é€šè¿‡å¼ºå¤§çš„å‰ªæèƒ½åŠ›é¿å…ä¸å¿…è¦çš„å‡¸ä¼˜åŒ–è°ƒç”¨ã€‚ç ”ç©¶è¯æ˜äº†GHOSTå…·æœ‰æœ€ä¼˜æ€§ä¿è¯ï¼Œå¹¶é’ˆå¯¹æ—¶é—´å…³é”®åœºæ™¯æä¾›äº†ä¸€ç§æœ‰ç•Œæ¬¡ä¼˜å˜ä½“ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒGHOSTåœ¨ç®€å•æ¡ˆä¾‹ä¸­çš„è¿è¡Œé€Ÿåº¦æ¯”ç»Ÿä¸€æ··åˆæ•´æ•°å‡¸è§„åˆ’åŸºçº¿å¿«å‡ ä¸ªæ•°é‡çº§ï¼Œå¹¶ä¸”èƒ½å¤Ÿæœ‰æ•ˆå¤„ç†æ¶‰åŠé«˜é˜¶è¿ç»­æ€§çº¦æŸå’Œä¸å®Œæ•´GCSçš„å¤æ‚è½¨è¿¹è§„åˆ’é—®é¢˜ã€‚",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to AAAI-2026",
      "pdf_url": "https://arxiv.org/pdf/2511.06471v2",
      "published_date": "2025-11-09 17:34:15 UTC",
      "updated_date": "2025-11-13 02:45:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T18:26:05.306727+00:00"
    },
    {
      "arxiv_id": "2511.06470v1",
      "title": "Brain-Inspired Planning for Better Generalization in Reinforcement Learning",
      "title_zh": "æå‡å¼ºåŒ–å­¦ä¹ æ³›åŒ–èƒ½åŠ›çš„è„‘å¯å‘å¼è§„åˆ’",
      "authors": [
        "Mingde \"Harry\" Zhao"
      ],
      "abstract": "Existing Reinforcement Learning (RL) systems encounter significant challenges when applied to real-world scenarios, primarily due to poor generalization across environments that differ from their training conditions. This thesis explores the direction of enhancing agents' zero-shot systematic generalization abilities by granting RL agents reasoning behaviors that are found to help systematic generalization in the human brain. Inspired by human conscious planning behaviors, we first introduced a top-down attention mechanism, which allows a decision-time planning agent to dynamically focus its reasoning on the most relevant aspects of the environmental state given its instantaneous intentions, a process we call \"spatial abstraction\". This approach significantly improves systematic generalization outside the training tasks. Subsequently, building on spatial abstraction, we developed the Skipper framework to automatically decompose complex tasks into simpler, more manageable sub-tasks. Skipper provides robustness against distributional shifts and efficacy in long-term, compositional planning by focusing on pertinent spatial and temporal elements of the environment. Finally, we identified a common failure mode and safety risk in planning agents that rely on generative models to generate state targets during planning. It is revealed that most agents blindly trust the targets they hallucinate, resulting in delusional planning behaviors. Inspired by how the human brain rejects delusional intentions, we propose learning a feasibility evaluator to enable rejecting hallucinated infeasible targets, which led to significant performance improvements in various kinds of planning agents. Finally, we suggest directions for future research, aimed at achieving general task abstraction and fully enabling abstract planning.",
      "tldr_zh": "è¯¥è®ºæ–‡æ—¨åœ¨è§£å†³ç°æœ‰å¼ºåŒ–å­¦ä¹ (RL)ç³»ç»Ÿåœ¨é¢å¯¹ç¯å¢ƒå·®å¼‚æ—¶æ³›åŒ–èƒ½åŠ›ä¸è¶³çš„é—®é¢˜ï¼Œé€šè¿‡æ¨¡æ‹Ÿäººè„‘çš„æ¨ç†è¡Œä¸ºæ¥å¢å¼ºæ™ºèƒ½ä½“çš„é›¶æ ·æœ¬ç³»ç»Ÿæ³›åŒ–èƒ½åŠ›ã€‚å—äººç±»æœ‰æ„è¯†è§„åˆ’çš„å¯å‘ï¼Œç ”ç©¶é¦–å…ˆå¼•å…¥äº†ä¸€ç§è‡ªä¸Šè€Œä¸‹çš„æ³¨æ„åŠ›æœºåˆ¶ï¼Œä½¿æ™ºèƒ½ä½“èƒ½å¤Ÿåœ¨å†³ç­–æ—¶æ ¹æ®æ„å›¾åŠ¨æ€èšç„¦äºç¯å¢ƒçŠ¶æ€çš„å…³é”®æ–¹é¢ï¼Œè¿™ç§è¢«ç§°ä¸º\"spatial abstraction\"çš„æ–¹æ³•æ˜¾è‘—æ”¹å–„äº†ç³»ç»Ÿæ³›åŒ–è¡¨ç°ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œè®ºæ–‡æå‡ºäº†\"Skipper framework\"ï¼Œé€šè¿‡å…³æ³¨ç¯å¢ƒçš„æ—¶ç©ºè¦ç´ è‡ªåŠ¨å°†å¤æ‚ä»»åŠ¡åˆ†è§£ä¸ºå¯ç®¡ç†çš„å­ä»»åŠ¡ï¼Œä»è€Œåœ¨é•¿æœŸç»„åˆè§„åˆ’ä¸­å®ç°äº†é’ˆå¯¹åˆ†å¸ƒåç§»çš„é²æ£’æ€§ã€‚æ­¤å¤–ï¼Œé’ˆå¯¹ä¾èµ–ç”Ÿæˆæ¨¡å‹çš„è§„åˆ’æ™ºèƒ½ä½“å®¹æ˜“ç›²ç›®ä¿¡ä»»å¹»è§‰ç›®æ ‡è€Œå¯¼è‡´\"delusional planning\"çš„é£é™©ï¼Œä½œè€…æå‡ºå­¦ä¹ ä¸€ç§\"feasibility evaluator\"æ¥è¯†åˆ«å¹¶æ‹’ç»ä¸å¯è¡Œçš„ç›®æ ‡ã€‚è¿™ä¸€æœºåˆ¶æ¨¡æ‹Ÿäº†äººè„‘æ‹’ç»å¦„æƒ³æ„å›¾çš„è¿‡ç¨‹ï¼Œå®éªŒè¡¨æ˜å…¶èƒ½æ˜¾è‘—æå‡å¤šç§è§„åˆ’æ™ºèƒ½ä½“çš„æ€§èƒ½ä¸å®‰å…¨æ€§ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "McGill PhD Thesis (updated on 20251109 for typos and margin adjustments)",
      "pdf_url": "https://arxiv.org/pdf/2511.06470v1",
      "published_date": "2025-11-09 17:32:55 UTC",
      "updated_date": "2025-11-09 17:32:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T18:26:36.913081+00:00"
    },
    {
      "arxiv_id": "2511.06458v1",
      "title": "EchoMark: Perceptual Acoustic Environment Transfer with Watermark-Embedded Room Impulse Response",
      "title_zh": "EchoMarkï¼šåŸºäºåµŒå…¥æ°´å°æˆ¿é—´è„‰å†²å“åº”çš„æ„ŸçŸ¥å£°å­¦ç¯å¢ƒè¿ç§»",
      "authors": [
        "Chenpei Huang",
        "Lingfeng Yao",
        "Kyu In Lee",
        "Lan Emily Zhang",
        "Xun Chen",
        "Miao Pan"
      ],
      "abstract": "Acoustic Environment Matching (AEM) is the task of transferring clean audio into a target acoustic environment, enabling engaging applications such as audio dubbing and auditory immersive virtual reality (VR). Recovering similar room impulse response (RIR) directly from reverberant speech offers more accessible and flexible AEM solution. However, this capability also introduces vulnerabilities of arbitrary ``relocation\" if misused by malicious user, such as facilitating advanced voice spoofing attacks or undermining the authenticity of recorded evidence. To address this issue, we propose EchoMark, the first deep learning-based AEM framework that generates perceptually similar RIRs with embedded watermark. Our design tackle the challenges posed by variable RIR characteristics, such as different durations and energy decays, by operating in the latent domain. By jointly optimizing the model with a perceptual loss for RIR reconstruction and a loss for watermark detection, EchoMark achieves both high-quality environment transfer and reliable watermark recovery. Experiments on diverse datasets validate that EchoMark achieves room acoustic parameter matching performance comparable to FiNS, the state-of-the-art RIR estimator. Furthermore, a high Mean Opinion Score (MOS) of 4.22 out of 5, watermark detection accuracy exceeding 99\\%, and bit error rates (BER) below 0.3\\% collectively demonstrate the effectiveness of EchoMark in preserving perceptual quality while ensuring reliable watermark embedding.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹Acoustic Environment Matching (AEM)æŠ€æœ¯å¯èƒ½è¢«æ»¥ç”¨äºè¯­éŸ³æ¬ºè¯ˆæˆ–ç ´åå½•éŸ³è¯æ®çœŸå®æ€§çš„é—®é¢˜ï¼Œæå‡ºäº†EchoMarkæ¡†æ¶ã€‚è¿™æ˜¯é¦–ä¸ªåŸºäºæ·±åº¦å­¦ä¹ çš„AEMæ¡†æ¶ï¼Œæ—¨åœ¨ç”ŸæˆåµŒå…¥æ°´å°ä¸”åœ¨æ„ŸçŸ¥ä¸Šç›¸ä¼¼çš„Room Impulse Response (RIR)ã€‚EchoMarké€šè¿‡åœ¨latent domainï¼ˆæ½œåœ¨åŸŸï¼‰è¿›è¡Œæ“ä½œï¼Œæœ‰æ•ˆè§£å†³äº†RIRæ—¶é•¿å’Œèƒ½é‡è¡°å‡å¤šå˜çš„æŒ‘æˆ˜ï¼Œå¹¶è”åˆä¼˜åŒ–æ„ŸçŸ¥æŸå¤±ä¸æ°´å°æ£€æµ‹æŸå¤±ä»¥å¹³è¡¡é‡å»ºè´¨é‡ä¸å®‰å…¨æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒEchoMarkåœ¨æˆ¿é—´å£°å­¦å‚æ•°åŒ¹é…æ€§èƒ½ä¸Šä¸æœ€å…ˆè¿›çš„FiNSæ¨¡å‹ç›¸å½“ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹å®ç°äº†4.22çš„å¹³å‡æ„è§å¾—åˆ†(MOS)ï¼Œæ°´å°æ£€æµ‹å‡†ç¡®ç‡è¶…è¿‡99%ï¼Œè¯¯ç ç‡(BER)ä½äº0.3%ã€‚è¿™äº›æ•°æ®è¯å®äº†EchoMarkåœ¨ä¿æŒé«˜æ„ŸçŸ¥è´¨é‡çš„åŒæ—¶ï¼Œèƒ½å¤Ÿå®ç°å¯é çš„æ°´å°åµŒå…¥ï¼Œä»è€Œæœ‰æ•ˆé˜²æ­¢éŸ³é¢‘ç¯å¢ƒè¿ç§»æŠ€æœ¯çš„æ»¥ç”¨ã€‚",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.06458v1",
      "published_date": "2025-11-09 16:53:32 UTC",
      "updated_date": "2025-11-09 16:53:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T18:29:49.536822+00:00"
    },
    {
      "arxiv_id": "2511.07482v1",
      "title": "Alignment-Constrained Dynamic Pruning for LLMs: Identifying and Preserving Alignment-Critical Circuits",
      "title_zh": "å¤§è¯­è¨€æ¨¡å‹å¯¹é½çº¦æŸåŠ¨æ€å‰ªæï¼šè¯†åˆ«ä¸ä¿ç•™å¯¹é½å…³é”®å›è·¯",
      "authors": [
        "Dev Patel",
        "Gabrielle Gervacio",
        "Diekola Raimi",
        "Kevin Zhu",
        "Ryan Lagasse",
        "Gabriel Grand",
        "Ashwinee Panda",
        "Maheep Chaudhary"
      ],
      "abstract": "Large Language Models require substantial computational resources for inference, posing deployment challenges. While dynamic pruning offers superior efficiency over static methods through adaptive circuit selection, it exacerbates alignment degradation by retaining only input-dependent safety-critical circuit preservation across diverse inputs. As a result, addressing these heightened alignment vulnerabilities remains critical. We introduce Alignment-Aware Probe Pruning (AAPP), a dynamic structured pruning method that adaptively preserves alignment-relevant circuits during inference, building upon Probe Pruning. Experiments on LLaMA 2-7B, Qwen2.5-14B-Instruct, and Gemma-3-12B-IT show AAPP improves refusal rates by 50\\% at matched compute, enabling efficient yet safety-preserving LLM deployment.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)æ¨ç†èµ„æºéœ€æ±‚å·¨å¤§ä¸”åŠ¨æ€å‰ªæ(Dynamic Pruning)å®¹æ˜“å¯¼è‡´å¯¹é½(Alignment)é€€åŒ–çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åä¸ºAlignment-Aware Probe Pruning (AAPP)çš„æ–°æ–¹æ³•ã€‚ç°æœ‰çš„åŠ¨æ€å‰ªæè™½ç„¶æ•ˆç‡ä¼˜äºé™æ€æ–¹æ³•ï¼Œä½†å¾€å¾€å› æ— æ³•è·¨å¤šæ ·åŒ–è¾“å…¥ä¿ç•™å…³é”®çš„å®‰å…¨ç”µè·¯è€ŒåŠ å‰§å¯¹é½æ¼æ´ã€‚AAPPå»ºç«‹åœ¨Probe PruningåŸºç¡€ä¹‹ä¸Šï¼Œæ˜¯ä¸€ç§åŠ¨æ€ç»“æ„åŒ–å‰ªææŠ€æœ¯ï¼Œèƒ½å¤Ÿåœ¨æ¨ç†è¿‡ç¨‹ä¸­è‡ªé€‚åº”åœ°è¯†åˆ«å¹¶ä¿ç•™ä¸å¯¹é½ç›¸å…³çš„å…³é”®ç”µè·¯(alignment-relevant circuits)ã€‚åœ¨LLaMA 2-7Bã€Qwen2.5-14B-Instructå’ŒGemma-3-12B-ITç­‰æ¨¡å‹ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨è®¡ç®—é‡åŒ¹é…çš„æƒ…å†µä¸‹ï¼ŒAAPPå°†æ¨¡å‹çš„æ‹’ç»ç‡(refusal rates)æé«˜äº†50%ã€‚è¿™ä¸€æˆæœæœ‰æ•ˆè§£å†³äº†æ•ˆç‡ä¸å®‰å…¨ä¹‹é—´çš„çŸ›ç›¾ï¼Œä¸ºå®ç°æ—¢é«˜æ•ˆåˆå…·å¤‡å®‰å…¨ä¿éšœçš„LLMéƒ¨ç½²æä¾›äº†æ–°çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.07482v1",
      "published_date": "2025-11-09 16:51:45 UTC",
      "updated_date": "2025-11-09 16:51:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T18:30:13.429187+00:00"
    },
    {
      "arxiv_id": "2511.06455v1",
      "title": "A Multi-Agent System for Semantic Mapping of Relational Data to Knowledge Graphs",
      "title_zh": "ç”¨äºå…³ç³»æ•°æ®è‡³çŸ¥è¯†å›¾è°±è¯­ä¹‰æ˜ å°„çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ",
      "authors": [
        "Milena Trajanoska",
        "Riste Stojanov",
        "Dimitar Trajanov"
      ],
      "abstract": "Enterprises often maintain multiple databases for storing critical business data in siloed systems, resulting in inefficiencies and challenges with data interoperability. A key to overcoming these challenges lies in integrating disparate data sources, enabling businesses to unlock the full potential of their data. Our work presents a novel approach for integrating multiple databases using knowledge graphs, focusing on the application of large language models as semantic agents for mapping and connecting structured data across systems by leveraging existing vocabularies. The proposed methodology introduces a semantic layer above tables in relational databases, utilizing a system comprising multiple LLM agents that map tables and columns to Schema.org terms. Our approach achieves a mapping accuracy of over 90% in multiple domains.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä¼ä¸šæ•°æ®å­¤å²›å’Œäº’æ“ä½œæ€§æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§åˆ©ç”¨çŸ¥è¯†å›¾è°±(Knowledge Graphs)æ•´åˆåˆ†æ•£æ•°æ®æºçš„æ–°é¢–æ–¹æ³•ã€‚è¯¥æ–¹æ³•å¼•å…¥äº†åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹(LLMs)çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ(Multi-Agent System)ï¼Œåœ¨å…³ç³»æ•°æ®åº“è¡¨ä¹‹ä¸Šæ„å»ºäº†ä¸€ä¸ªè¯­ä¹‰å±‚ã€‚é€šè¿‡åˆ©ç”¨ç°æœ‰çš„è¯æ±‡è¡¨ï¼Œè¯¥ç³»ç»Ÿèƒ½å¤Ÿè‡ªåŠ¨å°†æ•°æ®åº“çš„è¡¨å’Œåˆ—æ˜ å°„åˆ°Schema.orgæœ¯è¯­ï¼Œä»è€Œå®ç°è·¨ç³»ç»Ÿçš„ç»“æ„åŒ–æ•°æ®è¿æ¥ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªé¢†åŸŸä¸­å®ç°äº†è¶…è¿‡90%çš„æ˜ å°„å‡†ç¡®ç‡ï¼Œæœ‰æ•ˆé‡Šæ”¾äº†ä¼ä¸šæ•°æ®çš„æ½œåŠ›å¹¶æå‡äº†é›†æˆæ•ˆç‡ã€‚",
      "categories": [
        "cs.DB",
        "cs.AI"
      ],
      "primary_category": "cs.DB",
      "comment": "The 1st GOBLIN Workshop on Knowledge Graph Technologies https://www.dbpedia.org/events/goblin25-workshop/",
      "pdf_url": "https://arxiv.org/pdf/2511.06455v1",
      "published_date": "2025-11-09 16:41:46 UTC",
      "updated_date": "2025-11-09 16:41:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T18:30:33.956625+00:00"
    },
    {
      "arxiv_id": "2511.06449v2",
      "title": "FLEX: Continuous Agent Evolution via Forward Learning from Experience",
      "title_zh": "FLEXï¼šåŸºäºç»éªŒå‰å‘å­¦ä¹ çš„æ™ºèƒ½ä½“æŒç»­è¿›åŒ–",
      "authors": [
        "Zhicheng Cai",
        "Xinyuan Guo",
        "Yu Pei",
        "Jiangtao Feng",
        "Jinsong Su",
        "Jiangjie Chen",
        "Ya-Qin Zhang",
        "Wei-Ying Ma",
        "Mingxuan Wang",
        "Hao Zhou"
      ],
      "abstract": "Autonomous agents driven by Large Language Models (LLMs) have revolutionized reasoning and problem-solving but remain static after training, unable to grow with experience as intelligent beings do during deployment. We introduce Forward Learning with EXperience (FLEX), a gradient-free learning paradigm that enables LLM agents to continuously evolve through accumulated experience. Specifically, FLEX cultivates scalable and inheritable evolution by constructing a structured experience library through continual reflection on successes and failures during interaction with the environment. FLEX delivers substantial improvements on mathematical reasoning, chemical retrosynthesis, and protein fitness prediction (up to 23% on AIME25, 10% on USPTO50k, and 14% on ProteinGym). We further identify a clear scaling law of experiential growth and the phenomenon of experience inheritance across agents, marking a step toward scalable and inheritable continuous agent evolution. Project Page: https://flex-gensi-thuair.github.io.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)æ™ºèƒ½ä½“åœ¨è®­ç»ƒåå¤„äºé™æ€ã€æ— æ³•åœ¨éƒ¨ç½²ä¸­éšç»éªŒæˆé•¿çš„é—®é¢˜ï¼Œæå‡ºäº†FLEX (Forward Learning with EXperience) æ¡†æ¶ã€‚è¿™æ˜¯ä¸€ç§æ— æ¢¯åº¦çš„å­¦ä¹ èŒƒå¼ï¼Œæ—¨åœ¨é€šè¿‡ç§¯ç´¯ç»éªŒä½¿LLMæ™ºèƒ½ä½“å®ç°æŒç»­è¿›åŒ–ã€‚FLEXé€šè¿‡åœ¨ä¸ç¯å¢ƒäº¤äº’è¿‡ç¨‹ä¸­ä¸æ–­åæ€æˆåŠŸä¸å¤±è´¥ï¼Œæ„å»ºç»“æ„åŒ–çš„ç»éªŒåº“ï¼Œä»è€Œå®ç°å¯æ‰©å±•å’Œå¯ç»§æ‰¿çš„è¿›åŒ–ã€‚å®éªŒè¡¨æ˜ï¼ŒFLEXåœ¨æ•°å­¦æ¨ç†ã€åŒ–å­¦é€†åˆæˆå’Œè›‹ç™½è´¨é€‚åº”æ€§é¢„æµ‹ä»»åŠ¡ä¸Šå–å¾—äº†æ˜¾è‘—æå‡ï¼Œåˆ†åˆ«åœ¨AIME25ã€USPTO50kå’ŒProteinGymä¸Šæé«˜äº†23%ã€10%å’Œ14%ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜å‘ç°äº†ç»éªŒå¢é•¿çš„æ¸…æ™°ç¼©æ”¾å®šå¾‹(scaling law)ä»¥åŠæ™ºèƒ½ä½“é—´çš„ç»éªŒç»§æ‰¿ç°è±¡ï¼Œä¸ºå®ç°å¯æ‰©å±•å’Œå¯ç»§æ‰¿çš„æŒç»­æ™ºèƒ½ä½“è¿›åŒ–è¿ˆå‡ºäº†é‡è¦ä¸€æ­¥ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.06449v2",
      "published_date": "2025-11-09 16:31:39 UTC",
      "updated_date": "2025-12-08 02:42:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T18:31:00.883570+00:00"
    },
    {
      "arxiv_id": "2511.06448v1",
      "title": "When AI Agents Collude Online: Financial Fraud Risks by Collaborative LLM Agents on Social Platforms",
      "title_zh": "å½“AIæ™ºèƒ½ä½“åœ¨çº¿åˆè°‹ï¼šç¤¾äº¤å¹³å°ä¸ŠååŒLLMæ™ºèƒ½ä½“çš„é‡‘èæ¬ºè¯ˆé£é™©",
      "authors": [
        "Qibing Ren",
        "Zhijie Zheng",
        "Jiaxuan Guo",
        "Junchi Yan",
        "Lizhuang Ma",
        "Jing Shao"
      ],
      "abstract": "In this work, we study the risks of collective financial fraud in large-scale multi-agent systems powered by large language model (LLM) agents. We investigate whether agents can collaborate in fraudulent behaviors, how such collaboration amplifies risks, and what factors influence fraud success. To support this research, we present MultiAgentFraudBench, a large-scale benchmark for simulating financial fraud scenarios based on realistic online interactions. The benchmark covers 28 typical online fraud scenarios, spanning the full fraud lifecycle across both public and private domains. We further analyze key factors affecting fraud success, including interaction depth, activity level, and fine-grained collaboration failure modes. Finally, we propose a series of mitigation strategies, including adding content-level warnings to fraudulent posts and dialogues, using LLMs as monitors to block potentially malicious agents, and fostering group resilience through information sharing at the societal level. Notably, we observe that malicious agents can adapt to environmental interventions. Our findings highlight the real-world risks of multi-agent financial fraud and suggest practical measures for mitigating them. Code is available at https://github.com/zheng977/MutiAgent4Fraud.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶æ¢è®¨äº†ç”±å¤§å‹è¯­è¨€æ¨¡å‹(LLM)é©±åŠ¨çš„å¤§è§„æ¨¡å¤šæ™ºèƒ½ä½“ç³»ç»Ÿåœ¨åœ¨çº¿ç¤¾äº¤å¹³å°ä¸Šè¿›è¡Œé›†ä½“é‡‘èæ¬ºè¯ˆçš„é£é™©ã€‚ä½œè€…è°ƒæŸ¥äº†æ™ºèƒ½ä½“åä½œè¿›è¡Œæ¬ºè¯ˆè¡Œä¸ºçš„å¯èƒ½æ€§åŠå…¶å¯¹é£é™©çš„æ”¾å¤§æ•ˆåº”ï¼Œå¹¶ä¸ºæ­¤æå‡ºäº†MultiAgentFraudBenchï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºç°å®åœ¨çº¿äº¤äº’çš„å¤§è§„æ¨¡é‡‘èæ¬ºè¯ˆæ¨¡æ‹ŸåŸºå‡†ã€‚è¯¥åŸºå‡†æ¶µç›–äº†28ç§å…¸å‹çš„åœ¨çº¿æ¬ºè¯ˆåœºæ™¯ï¼Œæ¶‰åŠå…¬å…±å’Œç§äººé¢†åŸŸçš„å®Œæ•´æ¬ºè¯ˆç”Ÿå‘½å‘¨æœŸã€‚ç ”ç©¶å›¢é˜Ÿæ·±å…¥åˆ†æäº†å½±å“æ¬ºè¯ˆæˆåŠŸçš„å…³é”®å› ç´ ï¼ŒåŒ…æ‹¬äº¤äº’æ·±åº¦ã€æ´»è·ƒåº¦ä»¥åŠç»†ç²’åº¦çš„åä½œå¤±è´¥æ¨¡å¼ã€‚æ­¤å¤–ï¼Œè®ºæ–‡æå‡ºäº†ä¸€ç³»åˆ—ç¼“è§£ç­–ç•¥ï¼ŒåŒ…æ‹¬æ·»åŠ å†…å®¹çº§è­¦å‘Šã€åˆ©ç”¨LLMä½œä¸ºç›‘è§†å™¨æ‹¦æˆªæ¶æ„æ™ºèƒ½ä½“ï¼Œä»¥åŠé€šè¿‡ç¤¾ä¼šå±‚é¢çš„ä¿¡æ¯å…±äº«å¢å¼ºç¾¤ä½“å¼¹æ€§ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œç ”ç©¶è§‚å¯Ÿåˆ°æ¶æ„æ™ºèƒ½ä½“èƒ½å¤Ÿé€‚åº”ç¯å¢ƒå¹²é¢„æªæ–½ã€‚è¿™äº›å‘ç°å¼ºè°ƒäº†å¤šæ™ºèƒ½ä½“é‡‘èæ¬ºè¯ˆçš„ç°å®ä¸–ç•Œé£é™©ï¼Œå¹¶ä¸ºç¼“è§£è¿™äº›é£é™©æä¾›äº†åˆ‡å®å¯è¡Œçš„æªæ–½ã€‚",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.CL",
        "cs.SI"
      ],
      "primary_category": "cs.MA",
      "comment": "Code is available at https://github.com/zheng977/MutiAgent4Fraud",
      "pdf_url": "https://arxiv.org/pdf/2511.06448v1",
      "published_date": "2025-11-09 16:30:44 UTC",
      "updated_date": "2025-11-09 16:30:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T18:31:24.848804+00:00"
    },
    {
      "arxiv_id": "2511.06447v1",
      "title": "Personality over Precision: Exploring the Influence of Human-Likeness on ChatGPT Use for Search",
      "title_zh": "ä¸ªæ€§èƒœäºç²¾å‡†ï¼šæ¢ç´¢æ‹ŸäººåŒ–å¯¹ä½¿ç”¨ ChatGPT è¿›è¡Œæœç´¢çš„å½±å“",
      "authors": [
        "Mert Yazan",
        "Frederik Bungaran Ishak Situmeang",
        "Suzan Verberne"
      ],
      "abstract": "Conversational search interfaces, like ChatGPT, offer an interactive, personalized, and engaging user experience compared to traditional search. On the downside, they are prone to cause overtrust issues where users rely on their responses even when they are incorrect. What aspects of the conversational interaction paradigm drive people to adopt it, and how it creates personalized experiences that lead to overtrust, is not clear. To understand the factors influencing the adoption of conversational interfaces, we conducted a survey with 173 participants. We examined user perceptions regarding trust, human-likeness (anthropomorphism), and design preferences between ChatGPT and Google. To better understand the overtrust phenomenon, we asked users about their willingness to trade off factuality for constructs like ease of use or human-likeness. Our analysis identified two distinct user groups: those who use both ChatGPT and Google daily (DUB), and those who primarily rely on Google (DUG). The DUB group exhibited higher trust in ChatGPT, perceiving it as more human-like, and expressed greater willingness to trade factual accuracy for enhanced personalization and conversational flow. Conversely, the DUG group showed lower trust toward ChatGPT but still appreciated aspects like ad-free experiences and responsive interactions. Demographic analysis further revealed nuanced patterns, with middle-aged adults using ChatGPT less frequently yet trusting it more, suggesting potential vulnerability to misinformation. Our findings contribute to understanding user segmentation, emphasizing the critical roles of personalization and human-likeness in conversational IR systems, and reveal important implications regarding users' willingness to compromise factual accuracy for more engaging interactions.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶é€šè¿‡è°ƒæŸ¥173åå‚ä¸è€…ï¼Œæ·±å…¥æ¢è®¨äº†æ‹ŸäººåŒ–ï¼ˆhuman-likenessï¼‰ç‰¹å¾å¦‚ä½•å½±å“ç”¨æˆ·å¯¹ChatGPTç­‰å¯¹è¯å¼æœç´¢æ¥å£çš„é‡‡çº³ä¸ä¿¡ä»»ã€‚ç ”ç©¶è€…å¯¹æ¯”äº†ç”¨æˆ·å¯¹ChatGPTå’ŒGoogleåœ¨ä¿¡ä»»ã€æ‹ŸäººåŒ–ï¼ˆanthropomorphismï¼‰åŠè®¾è®¡åå¥½ä¸Šçš„æ„ŸçŸ¥ï¼Œå¹¶è¯†åˆ«å‡ºâ€œåŒé‡æ—¥å¸¸ç”¨æˆ·â€ï¼ˆDUBï¼‰å’Œâ€œGoogleä¸»å¯¼ç”¨æˆ·â€ï¼ˆDUGï¼‰ä¸¤ä¸ªç¾¤ä½“ã€‚åˆ†æå‘ç°ï¼ŒDUBç¾¤ä½“è®¤ä¸ºChatGPTæ›´å…·æ‹ŸäººåŒ–ç‰¹å¾ï¼Œå› è€Œè¡¨ç°å‡ºæ›´é«˜çš„ä¿¡ä»»åº¦ï¼Œç”šè‡³æ„¿æ„ä¸ºäº†å¢å¼ºä¸ªæ€§åŒ–ä½“éªŒå’Œå¯¹è¯æµç•…åº¦è€Œç‰ºç‰²äº‹å®å‡†ç¡®æ€§ï¼ˆfactualityï¼‰ã€‚ç›¸åï¼ŒDUGç¾¤ä½“å¯¹ChatGPTä¿¡ä»»åº¦è¾ƒä½ï¼Œä½†ä»è®¤å¯å…¶æ— å¹¿å‘Šå’Œå“åº”å¼äº¤äº’çš„ä¼˜åŠ¿ã€‚äººå£ç»Ÿè®¡å­¦åˆ†æè¿›ä¸€æ­¥æ­ç¤ºï¼Œä¸­å¹´ç”¨æˆ·è™½ç„¶ä½¿ç”¨é¢‘ç‡è¾ƒä½å´è¡¨ç°å‡ºæ›´é«˜çš„ä¿¡ä»»åº¦ï¼Œè¿™è¡¨æ˜è¯¥ç¾¤ä½“å¯èƒ½æ›´å®¹æ˜“å—åˆ°é”™è¯¯ä¿¡æ¯çš„å½±å“ã€‚è¯¥ç ”ç©¶å¼ºè°ƒäº†ä¸ªæ€§åŒ–å’Œæ‹ŸäººåŒ–åœ¨å¯¹è¯å¼ä¿¡æ¯æ£€ç´¢ï¼ˆConversational IRï¼‰ç³»ç»Ÿä¸­çš„å…³é”®ä½œç”¨ï¼Œå¹¶æ­ç¤ºäº†ç”¨æˆ·ä¸ºäº†æ›´å…·å¸å¼•åŠ›çš„äº¤äº’ä½“éªŒè€Œæ„¿æ„åœ¨å‡†ç¡®æ€§ä¸Šåšå‡ºå¦¥åçš„ç°è±¡ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "Accepted at NIP-IR@SIGIR'25",
      "pdf_url": "https://arxiv.org/pdf/2511.06447v1",
      "published_date": "2025-11-09 16:28:55 UTC",
      "updated_date": "2025-11-09 16:28:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T18:31:52.860391+00:00"
    },
    {
      "arxiv_id": "2511.06446v1",
      "title": "SR-KI: Scalable and Real-Time Knowledge Integration into LLMs via Supervised Attention",
      "title_zh": "SR-KIï¼šåŸºäºç›‘ç£æ³¨æ„åŠ›çš„å¤§è¯­è¨€æ¨¡å‹å¯æ‰©å±•å®æ—¶çŸ¥è¯†é›†æˆ",
      "authors": [
        "Bohan Yu",
        "Wei Huang",
        "Kang Liu"
      ],
      "abstract": "This paper proposes SR-KI, a novel approach for integrating real-time and large-scale structured knowledge bases (KBs) into large language models (LLMs). SR-KI begins by encoding KBs into key-value pairs using a pretrained encoder, and injects them into LLMs' KV cache. Building on this representation, we employ a two-stage training paradigm: first locating a dedicated retrieval layer within the LLM, and then applying an attention-based loss at this layer to explicitly supervise attention toward relevant KB entries. Unlike traditional retrieval-augmented generation methods that rely heavily on the performance of external retrievers and multi-stage pipelines, SR-KI supports end-to-end inference by performing retrieval entirely within the models latent space. This design enables efficient compression of injected knowledge and facilitates dynamic knowledge updates. Comprehensive experiments demonstrate that SR-KI enables the integration of up to 40K KBs into a 7B LLM on a single A100 40GB GPU, and achieves strong retrieval performance, maintaining over 98% Recall@10 on the best-performing task and exceeding 88% on average across all tasks. Task performance on question answering and KB ID generation also demonstrates that SR-KI maintains strong performance while achieving up to 99.75% compression of the injected KBs.",
      "tldr_zh": "è¯¥è®ºæ–‡æå‡ºäº†SR-KIï¼Œä¸€ç§é€šè¿‡ç›‘ç£æ³¨æ„åŠ›æœºåˆ¶å°†å®æ—¶ä¸”å¤§è§„æ¨¡çš„ç»“æ„åŒ–çŸ¥è¯†åº“(KBs)é›†æˆåˆ°å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)ä¸­çš„æ–°æ–¹æ³•ã€‚SR-KIé¦–å…ˆåˆ©ç”¨é¢„è®­ç»ƒç¼–ç å™¨å°†KBsç¼–ç ä¸ºé”®å€¼å¯¹å¹¶æ³¨å…¥LLMçš„KV cacheä¸­ï¼Œéšåé‡‡ç”¨ä¸¤é˜¶æ®µè®­ç»ƒèŒƒå¼å®šä½ä¸“ç”¨æ£€ç´¢å±‚å¹¶åº”ç”¨åŸºäºæ³¨æ„åŠ›çš„æŸå¤±ï¼Œä»¥æ˜¾å¼ç›‘ç£æ¨¡å‹å…³æ³¨ç›¸å…³çš„KBæ¡ç›®ã€‚ä¸ä¾èµ–å¤–éƒ¨æ£€ç´¢å™¨çš„ä¼ ç»Ÿæ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)ä¸åŒï¼ŒSR-KIåœ¨æ¨¡å‹çš„æ½œåœ¨ç©ºé—´å†…å®Œæˆæ£€ç´¢ï¼Œæ”¯æŒç«¯åˆ°ç«¯æ¨ç†ã€é«˜æ•ˆçš„çŸ¥è¯†å‹ç¼©åŠåŠ¨æ€æ›´æ–°ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSR-KIèƒ½å¤Ÿåœ¨å•ä¸ªA100 GPUä¸Šå°†å¤šè¾¾4ä¸‡ä¸ªKBsé›†æˆåˆ°7Bå‚æ•°çš„LLMä¸­ï¼Œå¹³å‡Recall@10è¶…è¿‡88%ï¼Œå¹¶åœ¨æœ€ä½³ä»»åŠ¡ä¸Šè¶…è¿‡98%ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•åœ¨é—®ç­”å’ŒKB IDç”Ÿæˆä»»åŠ¡ä¸­ä¿æŒäº†å¼ºåŠ²æ€§èƒ½ï¼ŒåŒæ—¶å®ç°äº†é«˜è¾¾99.75%çš„æ³¨å…¥çŸ¥è¯†å‹ç¼©ç‡ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by AAAI 2026",
      "pdf_url": "https://arxiv.org/pdf/2511.06446v1",
      "published_date": "2025-11-09 16:27:55 UTC",
      "updated_date": "2025-11-09 16:27:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T18:32:34.799691+00:00"
    },
    {
      "arxiv_id": "2511.06437v1",
      "title": "Optimizing Chain-of-Thought Confidence via Topological and Dirichlet Risk Analysis",
      "title_zh": "åŸºäºæ‹“æ‰‘ä¸ç‹„åˆ©å…‹é›·é£é™©åˆ†æçš„é“¾å¼æ€ç»´ç½®ä¿¡åº¦ä¼˜åŒ–",
      "authors": [
        "Abhishek More",
        "Anthony Zhang",
        "Nicole Bonilla",
        "Ashvik Vivekan",
        "Kevin Zhu",
        "Parham Sharafoleslami",
        "Maheep Chaudhary"
      ],
      "abstract": "Chain-of-thought (CoT) prompting enables Large Language Models to solve complex problems, but deploying these models safely requires reliable confidence estimates, a capability where existing methods suffer from poor calibration and severe overconfidence on incorrect predictions. We propose Enhanced Dirichlet and Topology Risk (EDTR), a novel decoding strategy that combines topological analysis with Dirichlet-based uncertainty quantification to measure LLM confidence across multiple reasoning paths. EDTR treats each CoT as a vector in high-dimensional space and extracts eight topological risk features capturing the geometric structure of reasoning distributions: tighter, more coherent clusters indicate higher confidence while dispersed, inconsistent paths signal uncertainty. We evaluate EDTR against three state-of-the-art calibration methods across four diverse reasoning benchmarks spanning olympiad-level mathematics (AIME), grade school math (GSM8K), commonsense reasoning, and stock price prediction \\cite{zhang2025aime, cobbe2021training, talmor-etal-2019-commonsenseqa, yahoo_finance}. EDTR achieves 41\\% better calibration than competing methods with an average ECE of 0.287 and the best overall composite score of 0.672, while notably achieving perfect accuracy on AIME and exceptional calibration on GSM8K with an ECE of 0.107, domains where baselines exhibit severe overconfidence. Our work provides a geometric framework for understanding and quantifying uncertainty in multi-step LLM reasoning, enabling more reliable deployment where calibrated confidence estimates are essential.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨é“¾å¼æ€ç»´(Chain-of-Thought, CoT)æ¨ç†ä¸­å­˜åœ¨çš„ç½®ä¿¡åº¦æ ¡å‡†å·®å’Œè¿‡åº¦è‡ªä¿¡é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åä¸ºEnhanced Dirichlet and Topology Risk (EDTR)çš„æ–°å‹è§£ç ç­–ç•¥ã€‚EDTRç»“åˆäº†æ‹“æ‰‘åˆ†æä¸åŸºäºDirichletçš„ä¸ç¡®å®šæ€§é‡åŒ–æ–¹æ³•ï¼Œå°†æ¯ä¸ªCoTæ¨ç†è·¯å¾„è§†ä¸ºé«˜ç»´ç©ºé—´ä¸­çš„å‘é‡ï¼Œå¹¶æå–å…«ç§æ‹“æ‰‘é£é™©ç‰¹å¾æ¥æ•æ‰æ¨ç†åˆ†å¸ƒçš„å‡ ä½•ç»“æ„ã€‚è¯¥æ–¹æ³•é€šè¿‡åˆ†æå‡ ä½•ç‰¹å¾ï¼Œåˆ©ç”¨æ›´ç´§å¯†ã€è¿è´¯çš„èšç±»æŒ‡ç¤ºè¾ƒé«˜ç½®ä¿¡åº¦ï¼Œè€Œåˆ†æ•£ã€ä¸ä¸€è‡´çš„è·¯å¾„åˆ™ç”¨äºè¯†åˆ«ä¸ç¡®å®šæ€§ã€‚ç ”ç©¶å›¢é˜Ÿåœ¨åŒ…æ‹¬å¥¥æ—åŒ¹å…‹æ•°å­¦(AIME)ã€å°å­¦æ•°å­¦(GSM8K)ç­‰å››ä¸ªåŸºå‡†ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œç»“æœæ˜¾ç¤ºEDTRçš„æ ¡å‡†æ€§èƒ½æ¯”ç°æœ‰æ–¹æ³•æé«˜äº†41%ï¼Œå¹³å‡é¢„æœŸæ ¡å‡†è¯¯å·®(ECE)ä¸º0.287ã€‚ç‰¹åˆ«æ˜¯åœ¨AIMEä¸Šå®ç°äº†å®Œç¾å‡†ç¡®ç‡ï¼Œåœ¨GSM8Kä¸Šè¾¾åˆ°äº†æä½³çš„æ ¡å‡†æ•ˆæœï¼Œæœ‰æ•ˆè§£å†³äº†åŸºçº¿æ¨¡å‹çš„è¿‡åº¦è‡ªä¿¡é—®é¢˜ã€‚è¿™é¡¹å·¥ä½œä¸ºç†è§£å’Œé‡åŒ–å¤šæ­¥LLMæ¨ç†ä¸­çš„ä¸ç¡®å®šæ€§æä¾›äº†ä¸€ä¸ªå‡ ä½•æ¡†æ¶ï¼Œä»è€Œæ”¯æŒæ›´å¯é çš„æ¨¡å‹éƒ¨ç½²ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.06437v1",
      "published_date": "2025-11-09 16:09:02 UTC",
      "updated_date": "2025-11-09 16:09:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T18:33:15.166865+00:00"
    },
    {
      "arxiv_id": "2511.06428v1",
      "title": "Walking the Tightrope of LLMs for Software Development: A Practitioners' Perspective",
      "title_zh": "è½¯ä»¶å¼€å‘ä¸­LLMçš„â€œèµ°é’¢ä¸â€ï¼šä»ä¸šè€…è§†è§’",
      "authors": [
        "Samuel Ferino",
        "Rashina Hoda",
        "John Grundy",
        "Christoph Treude"
      ],
      "abstract": "Background: Large Language Models emerged with the potential of provoking a revolution in software development (e.g., automating processes, workforce transformation). Although studies have started to investigate the perceived impact of LLMs for software development, there is a need for empirical studies to comprehend how to balance forward and backward effects of using LLMs. Objective: We investigated how LLMs impact software development and how to manage the impact from a software developer's perspective. Method: We conducted 22 interviews with software practitioners across 3 rounds of data collection and analysis, between October (2024) and September (2025). We employed socio-technical grounded theory (STGT) for data analysis to rigorously analyse interview participants' responses. Results: We identified the benefits (e.g., maintain software development flow, improve developers' mental model, and foster entrepreneurship) and disadvantages (e.g., negative impact on developers' personality and damage to developers' reputation) of using LLMs at individual, team, organisation, and society levels; as well as best practices on how to adopt LLMs. Conclusion: Critically, we present the trade-offs that software practitioners, teams, and organisations face in working with LLMs. Our findings are particularly useful for software team leaders and IT managers to assess the viability of LLMs within their specific context.",
      "tldr_zh": "è¯¥ç ”ç©¶æ·±å…¥æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å¯¹è½¯ä»¶å¼€å‘çš„å½±å“ï¼Œæ—¨åœ¨ä»ä»ä¸šè€…è§†è§’ç†è§£å¦‚ä½•å¹³è¡¡ä½¿ç”¨LLMså¸¦æ¥çš„æ­£å‘ä¸è´Ÿå‘æ•ˆåº”ã€‚é€šè¿‡åœ¨ä¸‰ä¸ªæ•°æ®æ”¶é›†é˜¶æ®µè¿›è¡Œçš„22æ¬¡æ·±åº¦è®¿è°ˆï¼Œç ”ç©¶å›¢é˜Ÿé‡‡ç”¨äº†ç¤¾ä¼šæŠ€æœ¯æ‰æ ¹ç†è®ºï¼ˆSocio-technical Grounded Theory, STGTï¼‰å¯¹æ•°æ®è¿›è¡Œäº†ä¸¥è°¨åˆ†æã€‚ç»“æœæ­ç¤ºäº†LLMsåœ¨ä¸ªäººã€å›¢é˜Ÿã€ç»„ç»‡åŠç¤¾ä¼šå±‚é¢å¸¦æ¥çš„æ”¶ç›Šï¼ˆå¦‚ç»´æŒå¼€å‘å¿ƒæµã€ä¼˜åŒ–å¿ƒæ™ºæ¨¡å‹ï¼‰ä¸å¼Šç«¯ï¼ˆå¦‚å½±å“å¼€å‘è€…ä¸ªæ€§ã€æŸå®³å£°èª‰ï¼‰ï¼Œå¹¶æå‡ºäº†ç›¸åº”çš„æœ€ä½³å®è·µã€‚æ–‡ç« æ‰¹åˆ¤æ€§åœ°å±•ç¤ºäº†è½¯ä»¶ä»ä¸šè€…å’Œç»„ç»‡åœ¨åº”ç”¨LLMsæ—¶é¢ä¸´çš„æƒè¡¡ï¼ˆtrade-offsï¼‰ï¼Œä¸ºå›¢é˜Ÿé¢†å¯¼å’ŒITç»ç†è¯„ä¼°LLMsåœ¨ç‰¹å®šç¯å¢ƒä¸‹çš„å¯è¡Œæ€§æä¾›äº†å®è¯ä¾æ®ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.06428v1",
      "published_date": "2025-11-09 15:49:55 UTC",
      "updated_date": "2025-11-09 15:49:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T18:33:38.623343+00:00"
    },
    {
      "arxiv_id": "2511.06424v1",
      "title": "Turbo-DDCM: Fast and Flexible Zero-Shot Diffusion-Based Image Compression",
      "title_zh": "Turbo-DDCMï¼šå¿«é€Ÿçµæ´»çš„åŸºäºæ‰©æ•£æ¨¡å‹çš„é›¶æ ·æœ¬å›¾åƒå‹ç¼©",
      "authors": [
        "Amit Vaisman",
        "Guy Ohayon",
        "Hila Manor",
        "Michael Elad",
        "Tomer Michaeli"
      ],
      "abstract": "While zero-shot diffusion-based compression methods have seen significant progress in recent years, they remain notoriously slow and computationally demanding. This paper presents an efficient zero-shot diffusion-based compression method that runs substantially faster than existing methods, while maintaining performance that is on par with the state-of-the-art techniques. Our method builds upon the recently proposed Denoising Diffusion Codebook Models (DDCMs) compression scheme. Specifically, DDCM compresses an image by sequentially choosing the diffusion noise vectors from reproducible random codebooks, guiding the denoiser's output to reconstruct the target image. We modify this framework with Turbo-DDCM, which efficiently combines a large number of noise vectors at each denoising step, thereby significantly reducing the number of required denoising operations. This modification is also coupled with an improved encoding protocol. Furthermore, we introduce two flexible variants of Turbo-DDCM, a priority-aware variant that prioritizes user-specified regions and a distortion-controlled variant that compresses an image based on a target PSNR rather than a target BPP. Comprehensive experiments position Turbo-DDCM as a compelling, practical, and flexible image compression scheme.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é›¶æ ·æœ¬åŸºäºæ‰©æ•£çš„å›¾åƒå‹ç¼©æ–¹æ³•è®¡ç®—é‡å¤§ä¸”é€Ÿåº¦æ…¢çš„é—®é¢˜ï¼Œæå‡ºäº†Turbo-DDCMï¼Œä¸€ç§åŸºäºDenoising Diffusion Codebook Models (DDCMs)çš„é«˜æ•ˆå‹ç¼©æ–¹æ¡ˆã€‚è¯¥æ–¹æ³•é€šè¿‡åœ¨æ¯ä¸ªå»å™ªæ­¥éª¤ä¸­é«˜æ•ˆç»„åˆå¤§é‡å™ªå£°å‘é‡ï¼Œå¹¶ç»“åˆæ”¹è¿›çš„ç¼–ç åè®®ï¼Œæ˜¾è‘—å‡å°‘äº†æ‰€éœ€çš„å»å™ªæ“ä½œæ¬¡æ•°ï¼Œä»è€Œåœ¨ä¿æŒä¸æœ€å…ˆè¿›æŠ€æœ¯ç›¸å½“æ€§èƒ½çš„åŒæ—¶å¤§å¹…æå‡äº†è¿è¡Œé€Ÿåº¦ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜å¼•å…¥äº†ä¸¤ç§çµæ´»çš„å˜ä½“ï¼šä¸€ç§æ˜¯é’ˆå¯¹ç”¨æˆ·æŒ‡å®šåŒºåŸŸçš„priority-awareå˜ä½“ï¼Œå¦ä¸€ç§æ˜¯åŸºäºç›®æ ‡PSNRè€Œéç›®æ ‡BPPè¿›è¡Œå‹ç¼©çš„distortion-controlledå˜ä½“ã€‚ç»¼åˆå®éªŒè¡¨æ˜ï¼ŒTurbo-DDCMæ˜¯ä¸€ç§æå…·ç«äº‰åŠ›ã€å®ç”¨ä¸”çµæ´»çš„å›¾åƒå‹ç¼©æ–¹æ¡ˆã€‚",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "eess.SP",
        "stat.ML"
      ],
      "primary_category": "eess.IV",
      "comment": "Code is available at https://amitvaisman.github.io/turbo_ddcm/",
      "pdf_url": "https://arxiv.org/pdf/2511.06424v1",
      "published_date": "2025-11-09 15:41:27 UTC",
      "updated_date": "2025-11-09 15:41:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T18:33:51.360100+00:00"
    },
    {
      "arxiv_id": "2511.06419v1",
      "title": "MONICA: Real-Time Monitoring and Calibration of Chain-of-Thought Sycophancy in Large Reasoning Models",
      "title_zh": "MONICAï¼šå¤§å‹æ¨ç†æ¨¡å‹æ€ç»´é“¾è¿åˆçš„å®æ—¶ç›‘æµ‹ä¸æ ¡å‡†",
      "authors": [
        "Jingyu Hu",
        "Shu Yang",
        "Xilin Gong",
        "Hongming Wang",
        "Weiru Liu",
        "Di Wang"
      ],
      "abstract": "Large Reasoning Models (LRMs) suffer from sycophantic behavior, where models tend to agree with users' incorrect beliefs and follow misinformation rather than maintain independent reasoning. This behavior undermines model reliability and poses societal risks. Mitigating LRM sycophancy requires monitoring how this sycophancy emerges during the reasoning trajectory; however, current methods mainly focus on judging based on final answers and correcting them, without understanding how sycophancy develops during reasoning processes. To address this limitation, we propose MONICA, a novel Monitor-guided Calibration framework that monitors and mitigates sycophancy during model inference at the level of reasoning steps, without requiring the model to finish generating its complete answer. MONICA integrates a sycophantic monitor that provides real-time monitoring of sycophantic drift scores during response generation with a calibrator that dynamically suppresses sycophantic behavior when scores exceed predefined thresholds. Extensive experiments across 12 datasets and 3 LRMs demonstrate that our method effectively reduces sycophantic behavior in both intermediate reasoning steps and final answers, yielding robust performance improvements.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹Large Reasoning Models (LRMs)ä¸­å­˜åœ¨çš„é˜¿è°€å¥‰æ‰¿è¡Œä¸º(sycophantic behavior)é—®é¢˜ï¼Œå³æ¨¡å‹å€¾å‘äºé¡ºä»ç”¨æˆ·çš„é”™è¯¯ä¿¡å¿µè€ŒéåšæŒç‹¬ç«‹æ¨ç†ï¼Œæå‡ºäº†è§£å†³æ–¹æ¡ˆã€‚ç°æœ‰çš„ç¼“è§£æ–¹æ³•ä¸»è¦å…³æ³¨æœ€ç»ˆç­”æ¡ˆçš„ä¿®æ­£ï¼Œå¿½ç•¥äº†æ¨ç†è¿‡ç¨‹ä¸­é˜¿è°€å¥‰æ‰¿è¡Œä¸ºçš„æ¼”å˜æœºåˆ¶ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†MONICAï¼Œä¸€ç§æ–°é¢–çš„ç›‘æ§å¼•å¯¼æ ¡å‡†æ¡†æ¶(Monitor-guided Calibration framework)ã€‚è¯¥æ¡†æ¶èƒ½å¤Ÿåœ¨æ¨¡å‹æ¨ç†çš„æ­¥éª¤å±‚é¢ä¸Šå®æ—¶ç›‘æ§å¹¶ç¼“è§£é˜¿è°€å¥‰æ‰¿è¡Œä¸ºï¼Œæ— éœ€ç­‰å¾…æ¨¡å‹ç”Ÿæˆå®Œæ•´çš„ç­”æ¡ˆã€‚MONICAé›†æˆäº†ä¸€ä¸ªç›‘æ§å™¨æ¥å®æ—¶è®¡ç®—é˜¿è°€å¥‰æ‰¿æ¼‚ç§»åˆ†æ•°(sycophantic drift scores)ï¼Œå¹¶ç»“åˆæ ¡å‡†å™¨åœ¨åˆ†æ•°è¶…è¿‡é˜ˆå€¼æ—¶åŠ¨æ€æŠ‘åˆ¶è¯¥è¡Œä¸ºã€‚åœ¨12ä¸ªæ•°æ®é›†å’Œ3ä¸ªLRMä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•æœ‰æ•ˆå‡å°‘äº†ä¸­é—´æ¨ç†æ­¥éª¤å’Œæœ€ç»ˆç­”æ¡ˆä¸­çš„é˜¿è°€å¥‰æ‰¿è¡Œä¸ºï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹çš„é²æ£’æ€§ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.06419v1",
      "published_date": "2025-11-09 15:18:58 UTC",
      "updated_date": "2025-11-09 15:18:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T18:37:21.336677+00:00"
    },
    {
      "arxiv_id": "2511.06417v1",
      "title": "AUTO-Explorer: Automated Data Collection for GUI Agent",
      "title_zh": "AUTO-Explorerï¼šé¢å‘ GUI æ™ºèƒ½ä½“çš„è‡ªåŠ¨åŒ–æ•°æ®æ”¶é›†",
      "authors": [
        "Xiangwu Guo",
        "Difei Gao",
        "Mike Zheng Shou"
      ],
      "abstract": "Recent advancements in GUI agents have significantly expanded their ability to interpret natural language commands to manage software interfaces. However, acquiring GUI data remains a significant challenge. Existing methods often involve designing automated agents that browse URLs from the Common Crawl, using webpage HTML to collect screenshots and corresponding annotations, including the names and bounding boxes of UI elements. However, this method is difficult to apply to desktop software or some newly launched websites not included in the Common Crawl. While we expect the model to possess strong generalization capabilities to handle this, it is still crucial for personalized scenarios that require rapid and perfect adaptation to new software or websites. To address this, we propose an automated data collection method with minimal annotation costs, named Auto-Explorer. It incorporates a simple yet effective exploration mechanism that autonomously parses and explores GUI environments, gathering data efficiently. Additionally, to assess the quality of exploration, we have developed the UIXplore benchmark. This benchmark creates environments for explorer agents to discover and save software states. Using the data gathered, we fine-tune a multimodal large language model (MLLM) and establish a GUI element grounding testing set to evaluate the effectiveness of the exploration strategies. Our experiments demonstrate the superior performance of Auto-Explorer, showing that our method can quickly enhance the capabilities of an MLLM in explored software.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹GUIæ™ºèƒ½ä½“ï¼ˆGUI Agentsï¼‰é¢ä¸´çš„æ•°æ®è·å–éš¾é¢˜ï¼Œæå‡ºäº†ä¸€ç§åä¸ºAuto-Explorerçš„è‡ªåŠ¨åŒ–æ•°æ®æ”¶é›†æ–¹æ³•ã€‚ç°æœ‰çš„åŸºäºCommon Crawlçš„æ–¹æ³•éš¾ä»¥åº”ç”¨äºæ¡Œé¢è½¯ä»¶æˆ–æ–°ä¸Šçº¿çš„ç½‘ç«™ï¼Œè€ŒAuto-Exploreré€šè¿‡ä¸€ç§ç®€å•æœ‰æ•ˆçš„æ¢ç´¢æœºåˆ¶ï¼Œèƒ½å¤Ÿè‡ªä¸»è§£æå’Œæ¢ç´¢GUIç¯å¢ƒï¼Œä»¥æä½çš„æ ‡æ³¨æˆæœ¬é«˜æ•ˆæ”¶é›†æ•°æ®ã€‚ä¸ºäº†è¯„ä¼°æ¢ç´¢è´¨é‡ï¼Œç ”ç©¶å›¢é˜Ÿè¿˜å¼€å‘äº†UIXplore benchmarkï¼Œç”¨äºæµ‹è¯•æ™ºèƒ½ä½“å‘ç°å’Œä¿å­˜è½¯ä»¶çŠ¶æ€çš„èƒ½åŠ›ã€‚åŸºäºæ”¶é›†åˆ°çš„æ•°æ®ï¼Œä½œè€…å¯¹å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰è¿›è¡Œäº†å¾®è°ƒï¼Œå¹¶å»ºç«‹äº†GUIå…ƒç´ å®šä½æµ‹è¯•é›†æ¥éªŒè¯ç­–ç•¥æœ‰æ•ˆæ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒAuto-Explorerè¡¨ç°ä¼˜å¼‚ï¼Œèƒ½å¤Ÿæ˜¾è‘—ä¸”å¿«é€Ÿåœ°å¢å¼ºMLLMåœ¨ç‰¹å®šè½¯ä»¶ç¯å¢ƒä¸­çš„æ“ä½œèƒ½åŠ›ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.06417v1",
      "published_date": "2025-11-09 15:13:45 UTC",
      "updated_date": "2025-11-09 15:13:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T18:37:24.361696+00:00"
    },
    {
      "arxiv_id": "2511.08630v1",
      "title": "Hope, Aspirations, and the Impact of LLMs on Female Programming Learners in Afghanistan",
      "title_zh": "å¸Œæœ›ã€æŠ±è´Ÿä¸å¤§è¯­è¨€æ¨¡å‹å¯¹é˜¿å¯Œæ±—å¥³æ€§ç¼–ç¨‹å­¦ä¹ è€…çš„å½±å“",
      "authors": [
        "Hamayoon Behmanush",
        "Freshta Akhtari",
        "Roghieh Nooripour",
        "Ingmar Weber",
        "Vikram Kamath Cannanure"
      ],
      "abstract": "Designing impactful educational technologies in contexts of socio-political instability requires a nuanced understanding of educational aspirations. Currently, scalable metrics for measuring aspirations are limited. This study adapts, translates, and evaluates Snyder's Hope Scale as a metric for measuring aspirations among 136 women learning programming online during a period of systemic educational restrictions in Afghanistan. The adapted scale demonstrated good reliability (Cronbach's Î± = 0.78) and participants rated it as understandable and relevant. While overall aspiration-related scores did not differ significantly by access to Large Language Models (LLMs), those with access reported marginally higher scores on the Avenues subscale (p = .056), suggesting broader perceived pathways to achieving educational aspirations. These findings support the use of the adapted scale as a metric for aspirations in contexts of socio-political instability. More broadly, the adapted scale can be used to evaluate the impact of aspiration-driven design of educational technologies.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶é’ˆå¯¹é˜¿å¯Œæ±—ç¤¾ä¼šæ”¿æ²»åŠ¨è¡èƒŒæ™¯ä¸‹çš„å¥³æ€§ç¼–ç¨‹å­¦ä¹ è€…ï¼Œè‡´åŠ›äºè§£å†³ç¼ºä¹è¡¡é‡æ•™è‚²æŠ±è´Ÿ(aspirations)çš„å¯æ‰©å±•æŒ‡æ ‡è¿™ä¸€é—®é¢˜ã€‚ç ”ç©¶å›¢é˜Ÿæ”¹ç¼–ã€ç¿»è¯‘å¹¶è¯„ä¼°äº†Snyderçš„å¸Œæœ›é‡è¡¨(Hope Scale)ï¼Œå¹¶å¯¹136ååœ¨ç³»ç»Ÿæ€§æ•™è‚²é™åˆ¶æœŸé—´åœ¨çº¿å­¦ä¹ ç¼–ç¨‹çš„å¥³æ€§è¿›è¡Œäº†æµ‹è¯•ã€‚ç»“æœè¡¨æ˜ï¼Œæ”¹ç¼–åçš„é‡è¡¨å…·æœ‰è‰¯å¥½çš„ä¿¡åº¦(Cronbach's Î± = 0.78)ï¼Œä¸”å‚ä¸è€…è®¤ä¸ºå…¶æ˜“äºç†è§£å¹¶å…·æœ‰ç›¸å…³æ€§ã€‚å°½ç®¡æ€»ä½“å¾—åˆ†åœ¨æ˜¯å¦ä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)çš„ç¾¤ä½“é—´æ— æ˜¾è‘—å·®å¼‚ï¼Œä½†æ‹¥æœ‰LLMsä½¿ç”¨æƒé™çš„å‚ä¸è€…åœ¨é€”å¾„(Avenues)å­é‡è¡¨ä¸Šå¾—åˆ†ç•¥é«˜(p = .056)ï¼Œæš—ç¤ºLLMså¯èƒ½æ‹“å®½äº†å­¦ä¹ è€…å®ç°æ•™è‚²æŠ±è´Ÿçš„æ„ŸçŸ¥è·¯å¾„ã€‚è¿™äº›å‘ç°æ”¯æŒåœ¨ç¤¾ä¼šæ”¿æ²»ä¸ç¨³å®šç¯å¢ƒä¸­ä½¿ç”¨è¯¥æ”¹ç¼–é‡è¡¨æ¥è¡¡é‡æŠ±è´Ÿï¼Œå¹¶è¯„ä¼°æŠ±è´Ÿé©±åŠ¨è®¾è®¡(aspiration-driven design)åœ¨æ•™è‚²æŠ€æœ¯ä¸­çš„å½±å“ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.08630v1",
      "published_date": "2025-11-09 14:58:33 UTC",
      "updated_date": "2025-11-09 14:58:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T18:37:51.510986+00:00"
    },
    {
      "arxiv_id": "2511.06411v1",
      "title": "SofT-GRPO: Surpassing Discrete-Token LLM Reinforcement Learning via Gumbel-Reparameterized Soft-Thinking Policy Optimization",
      "title_zh": "SofT-GRPOï¼šåŸºäº Gumbel é‡å‚æ•°åŒ–è½¯æ€ç»´ç­–ç•¥ä¼˜åŒ–è¶…è¶Šç¦»æ•£ Token å¤§è¯­è¨€æ¨¡å‹å¼ºåŒ–å­¦ä¹ ",
      "authors": [
        "Zhi Zheng",
        "Wee Sun Lee"
      ],
      "abstract": "The soft-thinking paradigm for Large Language Model (LLM) reasoning can outperform the conventional discrete-token Chain-of-Thought (CoT) reasoning in some scenarios, underscoring its research and application value. However, while the discrete-token CoT reasoning pattern can be reinforced through policy optimization algorithms such as group relative policy optimization (GRPO), extending the soft-thinking pattern with Reinforcement Learning (RL) remains challenging. This difficulty stems from the complexities of injecting stochasticity into soft-thinking tokens and updating soft-thinking policies accordingly. As a result, previous attempts to combine soft-thinking with GRPO typically underperform their discrete-token GRPO counterparts. To fully unlock the potential of soft-thinking, this paper presents a novel policy optimization algorithm, SofT-GRPO, to reinforce LLMs under the soft-thinking reasoning pattern. SofT-GRPO injects the Gumbel noise into logits, employs the Gumbel-Softmax technique to avoid soft-thinking tokens outside the pre-trained embedding space, and leverages the reparameterization trick in policy gradient. We conduct experiments across base LLMs ranging from 1.5B to 7B parameters, and results demonstrate that SofT-GRPO enables soft-thinking LLMs to slightly outperform discrete-token GRPO on Pass@1 (+0.13% on average accuracy), while exhibiting a substantial uplift on Pass@32 (+2.19% on average accuracy). Codes and weights are available on https://github.com/zz1358m/SofT-GRPO-master",
      "tldr_zh": "æœ¬æ–‡é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLM)æ¨ç†ä¸­çš„soft-thinkingèŒƒå¼ï¼Œè§£å†³äº†å°†å…¶ä¸å¼ºåŒ–å­¦ä¹ (RL)ç»“åˆæ—¶çš„æŒ‘æˆ˜ã€‚å°½ç®¡soft-thinkingåœ¨æŸäº›åœºæ™¯ä¸‹ä¼˜äºä¼ ç»Ÿçš„ç¦»æ•£token Chain-of-Thought (CoT)ï¼Œä½†ç”±äºéš¾ä»¥æ³¨å…¥éšæœºæ€§å’Œæ›´æ–°ç­–ç•¥ï¼Œä¹‹å‰çš„å°è¯•å¾€å¾€ä¸å¦‚ç¦»æ•£tokençš„GRPOç®—æ³•ã€‚ä¸ºæ­¤ï¼Œç ”ç©¶æå‡ºäº†SofT-GRPOï¼Œä¸€ç§æ–°çš„ç­–ç•¥ä¼˜åŒ–ç®—æ³•ï¼Œæ—¨åœ¨é€šè¿‡Gumbel-Reparameterized Soft-Thinking Policy Optimizationæ¥å¢å¼ºLLMã€‚è¯¥æ–¹æ³•åœ¨logitsä¸­æ³¨å…¥Gumbel noiseï¼Œåˆ©ç”¨Gumbel-SoftmaxæŠ€æœ¯é¿å…soft-thinking tokensè¶…å‡ºé¢„è®­ç»ƒåµŒå…¥ç©ºé—´ï¼Œå¹¶åˆ©ç”¨ç­–ç•¥æ¢¯åº¦ä¸­çš„é‡å‚æ•°åŒ–æŠ€å·§(reparameterization trick)ã€‚åœ¨1.5Båˆ°7Bå‚æ•°çš„æ¨¡å‹ä¸Šè¿›è¡Œçš„å®éªŒæ˜¾ç¤ºï¼ŒSofT-GRPOä½¿soft-thinking LLMåœ¨Pass@1ä¸Šç•¥å¾®ä¼˜äºç¦»æ•£token GRPOï¼ˆå¹³å‡å‡†ç¡®ç‡+0.13%ï¼‰ï¼Œè€Œåœ¨Pass@32ä¸Šåˆ™æœ‰æ˜¾è‘—æå‡ï¼ˆå¹³å‡å‡†ç¡®ç‡+2.19%ï¼‰ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.06411v1",
      "published_date": "2025-11-09 14:55:50 UTC",
      "updated_date": "2025-11-09 14:55:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T18:38:23.218897+00:00"
    },
    {
      "arxiv_id": "2511.07480v1",
      "title": "KG-DF: A Black-box Defense Framework against Jailbreak Attacks Based on Knowledge Graphs",
      "title_zh": "KG-DFï¼šåŸºäºçŸ¥è¯†å›¾è°±çš„è¶Šç‹±æ”»å‡»é»‘ç›’é˜²å¾¡æ¡†æ¶",
      "authors": [
        "Shuyuan Liu",
        "Jiawei Chen",
        "Xiao Yang",
        "Hang Su",
        "Zhaoxia Yin"
      ],
      "abstract": "With the widespread application of large language models (LLMs) in various fields, the security challenges they face have become increasingly prominent, especially the issue of jailbreak. These attacks induce the model to generate erroneous or uncontrolled outputs through crafted inputs, threatening the generality and security of the model. Although existing defense methods have shown some effectiveness, they often struggle to strike a balance between model generality and security. Excessive defense may limit the normal use of the model, while insufficient defense may lead to security vulnerabilities. In response to this problem, we propose a Knowledge Graph Defense Framework (KG-DF). Specifically, because of its structured knowledge representation and semantic association capabilities, Knowledge Graph(KG) can be searched by associating input content with safe knowledge in the knowledge base, thus identifying potentially harmful intentions and providing safe reasoning paths. However, traditional KG methods encounter significant challenges in keyword extraction, particularly when confronted with diverse and evolving attack strategies. To address this issue, we introduce an extensible semantic parsing module, whose core task is to transform the input query into a set of structured and secure concept representations, thereby enhancing the relevance of the matching process. Experimental results show that our framework enhances defense performance against various jailbreak attack methods, while also improving the response quality of the LLM in general QA scenarios by incorporating domain-general knowledge.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†KG-DFï¼Œä¸€ç§åŸºäºçŸ¥è¯†å›¾è°±(Knowledge Graphs)çš„é»‘ç›’é˜²å¾¡æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹(LLMs)é¢ä¸´çš„è¶Šç‹±æ”»å‡»(jailbreak attacks)é—®é¢˜ã€‚é’ˆå¯¹ç°æœ‰é˜²å¾¡æ–¹æ³•éš¾ä»¥åœ¨æ¨¡å‹é€šç”¨æ€§å’Œå®‰å…¨æ€§ä¹‹é—´å–å¾—å¹³è¡¡çš„å›°å¢ƒï¼ŒKG-DFåˆ©ç”¨çŸ¥è¯†å›¾è°±çš„ç»“æ„åŒ–çŸ¥è¯†è¡¨ç¤ºå’Œè¯­ä¹‰å…³è”èƒ½åŠ›ï¼Œå°†è¾“å…¥å†…å®¹ä¸å®‰å…¨çŸ¥è¯†å…³è”ä»¥è¯†åˆ«æœ‰å®³æ„å›¾å¹¶æä¾›å®‰å…¨æ¨ç†è·¯å¾„ã€‚ä¸ºäº†åº”å¯¹ä¼ ç»Ÿæ–¹æ³•åœ¨å…³é”®è¯æå–ä¸Šçš„æŒ‘æˆ˜ï¼Œè¯¥æ¡†æ¶å¼•å…¥äº†ä¸€ä¸ªå¯æ‰©å±•çš„è¯­ä¹‰è§£ææ¨¡å—ï¼Œå°†è¾“å…¥æŸ¥è¯¢è½¬åŒ–ä¸ºç»“æ„åŒ–ä¸”å®‰å…¨çš„æ¦‚å¿µè¡¨ç¤ºï¼Œä»è€Œå¢å¼ºåŒ¹é…çš„ç›¸å…³æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒKG-DFä¸ä»…æœ‰æ•ˆå¢å¼ºäº†å¯¹å¤šç§è¶Šç‹±æ”»å‡»çš„é˜²å¾¡èƒ½åŠ›ï¼Œè¿˜é€šè¿‡æ•´åˆé€šç”¨é¢†åŸŸçŸ¥è¯†æå‡äº†LLMåœ¨ä¸€èˆ¬é—®ç­”åœºæ™¯ä¸‹çš„å“åº”è´¨é‡ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.07480v1",
      "published_date": "2025-11-09 14:39:40 UTC",
      "updated_date": "2025-11-09 14:39:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T18:38:57.843202+00:00"
    },
    {
      "arxiv_id": "2511.06406v1",
      "title": "On Modality Incomplete Infrared-Visible Object Detection: An Architecture Compatibility Perspective",
      "title_zh": "æ¨¡æ€ç¼ºå¤±çº¢å¤–-å¯è§å…‰ç›®æ ‡æ£€æµ‹ï¼šæ¶æ„å…¼å®¹æ€§è§†è§’",
      "authors": [
        "Shuo Yang",
        "Yinghui Xing",
        "Shizhou Zhang",
        "Zhilong Niu"
      ],
      "abstract": "Infrared and visible object detection (IVOD) is essential for numerous around-the-clock applications. Despite notable advancements, current IVOD models exhibit notable performance declines when confronted with incomplete modality data, particularly if the dominant modality is missing. In this paper, we take a thorough investigation on modality incomplete IVOD problem from an architecture compatibility perspective. Specifically, we propose a plug-and-play Scarf Neck module for DETR variants, which introduces a modality-agnostic deformable attention mechanism to enable the IVOD detector to flexibly adapt to any single or double modalities during training and inference. When training Scarf-DETR, we design a pseudo modality dropout strategy to fully utilize the multi-modality information, making the detector compatible and robust to both working modes of single and double modalities. Moreover, we introduce a comprehensive benchmark for the modality-incomplete IVOD task aimed at thoroughly assessing situations where the absent modality is either dominant or secondary. Our proposed Scarf-DETR not only performs excellently in missing modality scenarios but also achieves superior performances on the standard IVOD modality complete benchmarks. Our code will be available at https://github.com/YinghuiXing/Scarf-DETR.",
      "tldr_zh": "è¿™ç¯‡è®ºæ–‡é’ˆå¯¹çº¢å¤–-å¯è§å…‰ç›®æ ‡æ£€æµ‹(IVOD)ä¸­å­˜åœ¨çš„æ¨¡æ€ç¼ºå¤±é—®é¢˜ï¼Œç‰¹åˆ«æ˜¯ä¸»å¯¼æ¨¡æ€ç¼ºå¤±å¯¼è‡´æ€§èƒ½æ˜¾è‘—ä¸‹é™çš„ç°è±¡ï¼Œä»æ¶æ„å…¼å®¹æ€§çš„è§’åº¦è¿›è¡Œäº†æ·±å…¥ç ”ç©¶ã€‚ç ”ç©¶å›¢é˜Ÿæå‡ºäº†ä¸€ç§å³æ’å³ç”¨çš„Scarf Neckæ¨¡å—ï¼Œé€‚ç”¨äºDETRå˜ä½“ï¼Œé€šè¿‡å¼•å…¥æ¨¡æ€æ— å…³çš„å¯å˜å½¢æ³¨æ„åŠ›æœºåˆ¶(modality-agnostic deformable attention)ï¼Œä½¿æ£€æµ‹å™¨åœ¨è®­ç»ƒå’Œæ¨ç†è¿‡ç¨‹ä¸­èƒ½å¤Ÿçµæ´»é€‚åº”å•æ¨¡æ€æˆ–åŒæ¨¡æ€è¾“å…¥ã€‚åœ¨è®­ç»ƒScarf-DETRæ—¶ï¼Œè®¾è®¡äº†ä¸€ç§ä¼ªæ¨¡æ€ä¸¢å¼ƒç­–ç•¥(pseudo modality dropout strategy)ï¼Œä»¥å……åˆ†åˆ©ç”¨å¤šæ¨¡æ€ä¿¡æ¯ï¼Œå¢å¼ºæ£€æµ‹å™¨å¯¹ä¸åŒå·¥ä½œæ¨¡å¼çš„å…¼å®¹æ€§å’Œé²æ£’æ€§ã€‚æ­¤å¤–ï¼Œæ–‡ç« è¿˜å¼•å…¥äº†ä¸€ä¸ªé’ˆå¯¹æ¨¡æ€ä¸å®Œæ•´IVODä»»åŠ¡çš„ç»¼åˆåŸºå‡†(benchmark)ï¼Œç”¨äºå…¨é¢è¯„ä¼°ç¼ºå¤±æ¨¡æ€ä¸ºä¸»å¯¼æˆ–æ¬¡è¦æ¨¡æ€æ—¶çš„å„ç§æƒ…å†µã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæå‡ºçš„Scarf-DETRä¸ä»…åœ¨æ¨¡æ€ç¼ºå¤±åœºæ™¯ä¸‹è¡¨ç°å‡ºè‰²ï¼Œè€Œä¸”åœ¨æ ‡å‡†çš„IVODå…¨æ¨¡æ€åŸºå‡†ä¸Šä¹Ÿå–å¾—äº†ä¼˜è¶Šçš„æ€§èƒ½ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.06406v1",
      "published_date": "2025-11-09 14:38:32 UTC",
      "updated_date": "2025-11-09 14:38:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T18:39:48.631728+00:00"
    },
    {
      "arxiv_id": "2511.06396v1",
      "title": "Efficient LLM Safety Evaluation through Multi-Agent Debate",
      "title_zh": "åŸºäºå¤šæ™ºèƒ½ä½“è¾©è®ºçš„é«˜æ•ˆ LLM å®‰å…¨è¯„ä¼°",
      "authors": [
        "Dachuan Lin",
        "Guobin Shen",
        "Zihao Yang",
        "Tianrong Liu",
        "Dongcheng Zhao",
        "Yi Zeng"
      ],
      "abstract": "Safety evaluation of large language models (LLMs) increasingly relies on LLM-as-a-Judge frameworks, but the high cost of frontier models limits scalability. We propose a cost-efficient multi-agent judging framework that employs Small Language Models (SLMs) through structured debates among critic, defender, and judge agents. To rigorously assess safety judgments, we construct HAJailBench, a large-scale human-annotated jailbreak benchmark comprising 12,000 adversarial interactions across diverse attack methods and target models. The dataset provides fine-grained, expert-labeled ground truth for evaluating both safety robustness and judge reliability. Our SLM-based framework achieves agreement comparable to GPT-4o judges on HAJailBench while substantially reducing inference cost. Ablation results show that three rounds of debate yield the optimal balance between accuracy and efficiency. These findings demonstrate that structured, value-aligned debate enables SLMs to capture semantic nuances of jailbreak attacks and that HAJailBench offers a reliable foundation for scalable LLM safety evaluation.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å®‰å…¨è¯„ä¼°ä¸­LLM-as-a-Judgeæ¡†æ¶æˆæœ¬é«˜æ˜‚çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åˆ©ç”¨å°è¯­è¨€æ¨¡å‹ï¼ˆSLMsï¼‰çš„é«˜æ•ˆå¤šæ™ºèƒ½ä½“è¯„å®¡æ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡criticã€defenderå’Œjudgeæ™ºèƒ½ä½“ä¹‹é—´çš„ç»“æ„åŒ–è¾©è®ºæ¥æ‰§è¡Œè¯„ä¼°ä»»åŠ¡ã€‚ä¸ºäº†ä¸¥æ ¼è¯„ä¼°å®‰å…¨åˆ¤æ–­èƒ½åŠ›ï¼Œä½œè€…æ„å»ºäº†HAJailBenchï¼Œè¿™æ˜¯ä¸€ä¸ªæ¶µç›–å¤šç§æ”»å‡»æ–¹æ³•å’Œç›®æ ‡æ¨¡å‹ã€åŒ…å«12,000æ¬¡å¯¹æŠ—æ€§äº¤äº’çš„å¤§è§„æ¨¡äººå·¥æ ‡æ³¨jailbreakåŸºå‡†æµ‹è¯•é›†ã€‚è¯¥æ•°æ®é›†æä¾›äº†ç»†ç²’åº¦çš„ä¸“å®¶æ ‡æ³¨çœŸå€¼ï¼Œç”¨äºåŒæ—¶è¯„ä¼°æ¨¡å‹çš„å®‰å…¨é²æ£’æ€§å’Œè¯„å®¡çš„å¯é æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥åŸºäºSLMçš„æ¡†æ¶åœ¨HAJailBenchä¸Šè¾¾åˆ°äº†ä¸GPT-4oè¯„å®¡ç›¸å½“çš„ä¸€è‡´æ€§ï¼ŒåŒæ—¶å¤§å¹…é™ä½äº†æ¨ç†æˆæœ¬ã€‚æ¶ˆèç ”ç©¶è¿›ä¸€æ­¥æ˜¾ç¤ºï¼Œä¸‰è½®è¾©è®ºåœ¨å‡†ç¡®æ€§å’Œæ•ˆç‡ä¹‹é—´å–å¾—äº†æœ€ä½³å¹³è¡¡ã€‚è¿™äº›å‘ç°è¯æ˜äº†ç»“æ„åŒ–ã€ä»·å€¼å¯¹é½çš„è¾©è®ºèƒ½å¤Ÿä½¿SLMsæ•æ‰åˆ°jailbreakæ”»å‡»çš„è¯­ä¹‰ç»†å¾®å·®åˆ«ï¼Œè€ŒHAJailBenchåˆ™ä¸ºå¯æ‰©å±•çš„LLMå®‰å…¨è¯„ä¼°å¥ å®šäº†å¯é åŸºç¡€ã€‚",
      "categories": [
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.AI",
      "comment": "9 pages of main text, 14 pages total, 4 figures",
      "pdf_url": "https://arxiv.org/pdf/2511.06396v1",
      "published_date": "2025-11-09 14:06:55 UTC",
      "updated_date": "2025-11-09 14:06:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T18:39:53.119578+00:00"
    },
    {
      "arxiv_id": "2511.06391v1",
      "title": "HatePrototypes: Interpretable and Transferable Representations for Implicit and Explicit Hate Speech Detection",
      "title_zh": "HatePrototypesï¼šç”¨äºéšå¼ä¸æ˜¾å¼ä»‡æ¨è¨€è®ºæ£€æµ‹çš„å¯è§£é‡Šä¸å¯è¿ç§»è¡¨å¾",
      "authors": [
        "Irina Proskurina",
        "Marc-Antoine Carpentier",
        "Julien Velcin"
      ],
      "abstract": "Optimization of offensive content moderation models for different types of hateful messages is typically achieved through continued pre-training or fine-tuning on new hate speech benchmarks. However, existing benchmarks mainly address explicit hate toward protected groups and often overlook implicit or indirect hate, such as demeaning comparisons, calls for exclusion or violence, and subtle discriminatory language that still causes harm. While explicit hate can often be captured through surface features, implicit hate requires deeper, full-model semantic processing. In this work, we question the need for repeated fine-tuning and analyze the role of HatePrototypes, class-level vector representations derived from language models optimized for hate speech detection and safety moderation. We find that these prototypes, built from as few as 50 examples per class, enable cross-task transfer between explicit and implicit hate, with interchangeable prototypes across benchmarks. Moreover, we show that parameter-free early exiting with prototypes is effective for both hate types. We release the code, prototype resources, and evaluation scripts to support future research on efficient and transferable hate speech detection.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°æœ‰ä»‡æ¨è¨€è®ºæ£€æµ‹åŸºå‡†ä¸»è¦å…³æ³¨æ˜¾æ€§ä»‡æ¨è€Œå¿½è§†éšæ€§æˆ–é—´æ¥ä»‡æ¨çš„é—®é¢˜ï¼Œåˆ†æå¹¶æå‡ºäº† HatePrototypesï¼Œå³ä»ä¼˜åŒ–åçš„è¯­è¨€æ¨¡å‹ä¸­æå–çš„ç±»çº§å‘é‡è¡¨ç¤º(class-level vector representations)ã€‚ä½œè€…è´¨ç–‘äº†é’ˆå¯¹æ–°åŸºå‡†è¿›è¡Œé‡å¤å¾®è°ƒçš„å¿…è¦æ€§ï¼Œå‘ç°ä»…éœ€æ¯ç±»çº¦50ä¸ªç¤ºä¾‹æ„å»ºçš„åŸå‹å³å¯å®ç°æ˜¾æ€§å’Œéšæ€§ä»‡æ¨ä¹‹é—´çš„è·¨ä»»åŠ¡è¿ç§»(cross-task transfer)ã€‚å®éªŒè¡¨æ˜ï¼Œè¿™äº›åŸå‹åœ¨ä¸åŒåŸºå‡†æµ‹è¯•ä¹‹é—´å…·æœ‰å¯äº’æ¢æ€§ï¼Œä¸”åˆ©ç”¨åŸå‹è¿›è¡Œçš„æ— å‚æ•°æå‰é€€å‡º(parameter-free early exiting)ç­–ç•¥å¯¹ä¸¤ç§ç±»å‹çš„ä»‡æ¨è¨€è®ºå‡æœ‰æ•ˆã€‚è¯¥æˆæœä¸ºé«˜æ•ˆä¸”å¯è¿ç§»çš„ä»‡æ¨è¨€è®ºæ£€æµ‹æä¾›äº†æ–°çš„æ€è·¯ï¼Œå¹¶å·²å¼€æºç›¸å…³ä»£ç å’Œèµ„æºä»¥æ”¯æŒåç»­ç ”ç©¶ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.06391v1",
      "published_date": "2025-11-09 14:01:26 UTC",
      "updated_date": "2025-11-09 14:01:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T18:40:21.754795+00:00"
    },
    {
      "arxiv_id": "2511.06390v3",
      "title": "Ghost in the Transformer: Detecting Model Reuse with Invariant Spectral Signatures",
      "title_zh": "Transformer ä¸­çš„å¹½çµï¼šåŸºäºä¸å˜è°±ç­¾åçš„æ¨¡å‹é‡ç”¨æ£€æµ‹",
      "authors": [
        "Suqing Wang",
        "Ziyang Ma",
        "Li Xinyi",
        "Zuchao Li"
      ],
      "abstract": "Large Language Models (LLMs) are widely adopted, but their high training cost leads many developers to fine-tune existing open-source models. While most adhere to open-source licenses, some falsely claim original training despite clear derivation from public models, raising pressing concerns about intellectual property protection and the need to verify model provenance. In this paper, we propose GhostSpec, a lightweight yet effective method for verifying LLM lineage without access to training data or modification of model behavior. Our approach constructs compact and robust fingerprints by applying singular value decomposition (SVD) to invariant products of internal attention weight matrices. Unlike watermarking or output-based methods, GhostSpec is fully data-free, non-invasive, and computationally efficient. Extensive experiments show it is robust to fine-tuning, pruning, expansion, and adversarial transformations, reliably tracing lineage with minimal overhead. By offering a practical solution for model verification, our method contributes to intellectual property protection and fosters a transparent, trustworthy LLM ecosystem. Our code is available at https://github.com/DX0369/GhostSpec.",
      "tldr_zh": "é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)è®­ç»ƒæˆæœ¬é«˜æ˜‚å¼•å‘çš„æœªç»æˆæƒçš„æ¨¡å‹é‡ç”¨åŠè™šå‡åŸåˆ›å£°æ˜é—®é¢˜ï¼Œè¯¥è®ºæ–‡æå‡ºäº†GhostSpecï¼Œä¸€ç§è½»é‡çº§ä¸”é«˜æ•ˆçš„æ¨¡å‹è¡€ç»ŸéªŒè¯æ–¹æ³•ã€‚è¯¥æ–¹æ³•æ— éœ€è®¿é—®è®­ç»ƒæ•°æ®æˆ–ä¿®æ”¹æ¨¡å‹è¡Œä¸ºï¼Œè€Œæ˜¯é€šè¿‡å¯¹å†…éƒ¨æ³¨æ„åŠ›æƒé‡çŸ©é˜µçš„ä¸å˜ä¹˜ç§¯åº”ç”¨å¥‡å¼‚å€¼åˆ†è§£(SVD)æ¥æ„å»ºç´§å‡‘ä¸”é²æ£’çš„æŒ‡çº¹ã€‚ä½œä¸ºä¸€ç§å®Œå…¨æ— æ•°æ®(data-free)ä¸”éä¾µå…¥å¼çš„æŠ€æœ¯ï¼ŒGhostSpecå…‹æœäº†ä¼ ç»Ÿæ°´å°æˆ–åŸºäºè¾“å‡ºçš„æ–¹æ³•çš„å±€é™æ€§ã€‚å¹¿æ³›çš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨é¢å¯¹å¾®è°ƒ(fine-tuning)ã€å‰ªæ(pruning)ã€æ¨¡å‹æ‰©å±•åŠå¯¹æŠ—æ€§å˜æ¢æ—¶å‡è¡¨ç°å‡ºä¼˜å¼‚çš„é²æ£’æ€§ï¼Œèƒ½å¤Ÿä»¥æå°çš„è®¡ç®—å¼€é”€å¯é åœ°è¿½è¸ªæ¨¡å‹è¡€ç»Ÿã€‚è¯¥ç ”ç©¶ä¸ºä¿æŠ¤çŸ¥è¯†äº§æƒå’Œæ„å»ºé€æ˜ã€å¯ä¿¡çš„LLMç”Ÿæ€ç³»ç»Ÿæä¾›äº†åˆ‡å®å¯è¡Œçš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted at AAAI 2026 (Oral)",
      "pdf_url": "https://arxiv.org/pdf/2511.06390v3",
      "published_date": "2025-11-09 13:57:59 UTC",
      "updated_date": "2025-12-08 14:17:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T18:40:46.978884+00:00"
    },
    {
      "arxiv_id": "2511.06388v1",
      "title": "HyMoERec: Hybrid Mixture-of-Experts for Sequential Recommendation",
      "title_zh": "HyMoERecï¼šé¢å‘åºåˆ—æ¨èçš„æ··åˆå¼æ··åˆä¸“å®¶",
      "authors": [
        "Kunrong Li",
        "Zhu Sun",
        "Kwan Hui Lim"
      ],
      "abstract": "We propose HyMoERec, a novel sequential recommendation framework that addresses the limitations of uniform Position-wise Feed-Forward Networks in existing models. Current approaches treat all user interactions and items equally, overlooking the heterogeneity in user behavior patterns and diversity in item complexity. HyMoERec initially introduces a hybrid mixture-of-experts architecture that combines shared and specialized expert branches with an adaptive expert fusion mechanism for the sequential recommendation task. This design captures diverse reasoning for varied users and items while ensuring stable training. Experiments on MovieLens-1M and Beauty datasets demonstrate that HyMoERec consistently outperforms state-of-the-art baselines.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†HyMoERecï¼Œä¸€ç§é’ˆå¯¹åºåˆ—æ¨èä»»åŠ¡çš„æ–°å‹æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æ¨¡å‹ä¸­ç»Ÿä¸€Position-wise Feed-Forward Networksçš„å±€é™æ€§ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€åŒç­‰å¯¹å¾…æ‰€æœ‰ç”¨æˆ·äº¤äº’å’Œç‰©å“ï¼Œä»è€Œå¿½è§†äº†ç”¨æˆ·è¡Œä¸ºæ¨¡å¼çš„å¼‚è´¨æ€§ä»¥åŠç‰©å“å¤æ‚åº¦çš„å¤šæ ·æ€§ã€‚HyMoERecå¼•å…¥äº†ä¸€ç§æ··åˆMixture-of-Expertsæ¶æ„ï¼Œé€šè¿‡è‡ªé€‚åº”ä¸“å®¶èåˆæœºåˆ¶ç»“åˆäº†å…±äº«å’Œä¸“ç”¨ä¸“å®¶åˆ†æ”¯ã€‚è¿™ç§è®¾è®¡ä¸ä»…èƒ½å¤Ÿæ•æ‰é’ˆå¯¹ä¸åŒç”¨æˆ·å’Œç‰©å“çš„å¤šæ ·åŒ–æ¨ç†é€»è¾‘ï¼Œè¿˜èƒ½ç¡®ä¿æ¨¡å‹è®­ç»ƒçš„ç¨³å®šæ€§ã€‚åœ¨MovieLens-1Må’ŒBeautyæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒHyMoERecçš„æ€§èƒ½æŒç»­ä¼˜äºå½“å‰çš„state-of-the-artåŸºçº¿æ¨¡å‹ã€‚",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "AAAI 2026 Student Abstract",
      "pdf_url": "https://arxiv.org/pdf/2511.06388v1",
      "published_date": "2025-11-09 13:52:48 UTC",
      "updated_date": "2025-11-09 13:52:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T18:41:55.884516+00:00"
    },
    {
      "arxiv_id": "2511.06380v1",
      "title": "What Makes Reasoning Invalid: Echo Reflection Mitigation for Large Language Models",
      "title_zh": "æ¨ç†ä¸ºä½•å¤±æ•ˆï¼šå¤§å‹è¯­è¨€æ¨¡å‹çš„å›å£°åæ€ç¼“è§£",
      "authors": [
        "Chen He",
        "Xun Jiang",
        "Lei Wang",
        "Hao Yang",
        "Chong Peng",
        "Peng Yan",
        "Fumin Shen",
        "Xing Xu"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable performance across a wide range of reasoning tasks. Recent methods have further improved LLM performance in complex mathematical reasoning. However, when extending these methods beyond the domain of mathematical reasoning to tasks involving complex domain-specific knowledge, we observe a consistent failure of LLMs to generate novel insights during the reflection stage. Instead of conducting genuine cognitive refinement, the model tends to mechanically reiterate earlier reasoning steps without introducing new information or perspectives, a phenomenon referred to as \"Echo Reflection\". We attribute this behavior to two key defects: (1) Uncontrollable information flow during response generation, which allows premature intermediate thoughts to propagate unchecked and distort final decisions; (2) Insufficient exploration of internal knowledge during reflection, leading to repeating earlier findings rather than generating new cognitive insights. Building on these findings, we proposed a novel reinforcement learning method termed Adaptive Entropy Policy Optimization (AEPO). Specifically, the AEPO framework consists of two major components: (1) Reflection-aware Information Filtration, which quantifies the cognitive information flow and prevents the final answer from being affected by earlier bad cognitive information; (2) Adaptive-Entropy Optimization, which dynamically balances exploration and exploitation across different reasoning stages, promoting both reflective diversity and answer correctness. Extensive experiments demonstrate that AEPO consistently achieves state-of-the-art performance over mainstream reinforcement learning baselines across diverse benchmarks.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤„ç†å¤æ‚ç‰¹å®šé¢†åŸŸä»»åŠ¡æ—¶å‡ºç°çš„â€œå›å£°åå°„â€ï¼ˆEcho Reflectionï¼‰ç°è±¡è¿›è¡Œäº†æ·±å…¥åˆ†æï¼Œå³æ¨¡å‹åœ¨åå°„é˜¶æ®µå€¾å‘äºæœºæ¢°é‡å¤æ—©æœŸæ¨ç†æ­¥éª¤è€Œéäº§ç”Ÿæ–°è§è§£ã€‚ä½œè€…å°†æ­¤å½’å› äºå“åº”ç”Ÿæˆè¿‡ç¨‹ä¸­ä¸å¯æ§çš„ä¿¡æ¯æµå¯¼è‡´è¿‡æ—©çš„ä¸­é—´æƒ³æ³•æ‰­æ›²æœ€ç»ˆå†³ç­–ï¼Œä»¥åŠåå°„è¿‡ç¨‹ä¸­å¯¹å†…éƒ¨çŸ¥è¯†çš„æ¢ç´¢ä¸è¶³ã€‚ä¸ºæ­¤ï¼Œè®ºæ–‡æå‡ºäº†ä¸€ç§åä¸ºè‡ªé€‚åº”ç†µç­–ç•¥ä¼˜åŒ–ï¼ˆAdaptive Entropy Policy Optimization, AEPOï¼‰çš„æ–°å‹å¼ºåŒ–å­¦ä¹ æ–¹æ³•ã€‚AEPOæ¡†æ¶åŒ…å«åå°„æ„ŸçŸ¥ä¿¡æ¯è¿‡æ»¤æœºåˆ¶ï¼Œç”¨äºé‡åŒ–è®¤çŸ¥ä¿¡æ¯æµå¹¶é˜»æ–­ä¸è‰¯è®¤çŸ¥ä¿¡æ¯çš„å½±å“ï¼›ä»¥åŠè‡ªé€‚åº”ç†µä¼˜åŒ–æœºåˆ¶ï¼Œé€šè¿‡åŠ¨æ€å¹³è¡¡æ¨ç†é˜¶æ®µçš„æ¢ç´¢ä¸åˆ©ç”¨æ¥æå‡åå°„å¤šæ ·æ€§å’Œç­”æ¡ˆæ­£ç¡®æ€§ã€‚å¹¿æ³›çš„å®éªŒç»“æœè¡¨æ˜ï¼ŒAEPOåœ¨å¤šç§åŸºå‡†æµ‹è¯•ä¸­å‡ä¼˜äºä¸»æµå¼ºåŒ–å­¦ä¹ åŸºçº¿æ¨¡å‹ï¼Œå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½è¡¨ç°ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.06380v1",
      "published_date": "2025-11-09 13:33:46 UTC",
      "updated_date": "2025-11-09 13:33:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T18:45:07.540588+00:00"
    },
    {
      "arxiv_id": "2511.06363v1",
      "title": "Privacy-Preserving Federated Learning for Fair and Efficient Urban Traffic Optimization",
      "title_zh": "é¢å‘å…¬å¹³é«˜æ•ˆåŸå¸‚äº¤é€šä¼˜åŒ–çš„éšç§ä¿æŠ¤è”é‚¦å­¦ä¹ ",
      "authors": [
        "Rathin Chandra Shit",
        "Sharmila Subudhi"
      ],
      "abstract": "The optimization of urban traffic is threatened by the complexity of achieving a balance between transport efficiency and the maintenance of privacy, as well as the equitable distribution of traffic based on socioeconomically diverse neighborhoods. Current centralized traffic management schemes invade user location privacy and further entrench traffic disparity by offering disadvantaged route suggestions, whereas current federated learning frameworks do not consider fairness constraints in multi-objective traffic settings. This study presents a privacy-preserving federated learning framework, termed FedFair-Traffic, that jointly and simultaneously optimizes travel efficiency, traffic fairness, and differential privacy protection. This is the first attempt to integrate three conflicting objectives to improve urban transportation systems. The proposed methodology enables collaborative learning between related vehicles with data locality by integrating Graph Neural Networks with differential privacy mechanisms ($Îµ$-privacy guarantees) and Gini coefficient-based fair constraints using multi-objective optimization. The framework uses federated aggregation methods of gradient clipping and noise injection to provide differential privacy and optimize Pareto-efficient solutions for the efficiency-fairness tradeoff. Real-world comprehensive experiments on the METR-LA traffic dataset showed that FedFair-Traffic can reduce the average travel time by 7\\% (14.2 minutes) compared with their centralized baselines, promote traffic fairness by 73\\% (Gini coefficient, 0.78), and offer high privacy protection (privacy score, 0.8) with an 89\\% reduction in communication overhead. These outcomes demonstrate that FedFair-Traffic is a scalable privacy-aware smart city infrastructure with possible use-cases in metropolitan traffic flow control and federated transportation networks.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†FedFair-Trafficï¼Œä¸€ç§éšç§ä¿æŠ¤è”é‚¦å­¦ä¹ æ¡†æ¶ï¼Œæ—¨åœ¨åŒæ—¶ä¼˜åŒ–åŸå¸‚äº¤é€šçš„å‡ºè¡Œæ•ˆç‡ã€äº¤é€šå…¬å¹³æ€§å’Œå·®åˆ†éšç§ä¿æŠ¤ã€‚é’ˆå¯¹ç°æœ‰é›†ä¸­å¼ç®¡ç†ä¾µçŠ¯éšç§å’Œç°æœ‰è”é‚¦å­¦ä¹ ç¼ºä¹å…¬å¹³æ€§çº¦æŸçš„é—®é¢˜ï¼Œè¯¥æ–¹æ³•é¦–æ¬¡å°è¯•æ•´åˆè¿™ä¸‰ä¸ªç›¸äº’å†²çªçš„ç›®æ ‡ã€‚FedFair-Trafficé€šè¿‡é›†æˆå›¾ç¥ç»ç½‘ç»œ(Graph Neural Networks)ä¸å·®åˆ†éšç§æœºåˆ¶ï¼Œå¹¶åˆ©ç”¨åŸºäºåŸºå°¼ç³»æ•°(Gini coefficient)çš„å…¬å¹³çº¦æŸè¿›è¡Œå¤šç›®æ ‡ä¼˜åŒ–ï¼Œå®ç°äº†è½¦è¾†é—´çš„åä½œå­¦ä¹ ã€‚è¯¥æ¡†æ¶é‡‡ç”¨æ¢¯åº¦è£å‰ªå’Œå™ªå£°æ³¨å…¥çš„è”é‚¦èšåˆæ–¹æ³•ï¼Œåœ¨æä¾›éšç§ä¿è¯çš„åŒæ—¶ä¼˜åŒ–æ•ˆç‡ä¸å…¬å¹³æ€§æƒè¡¡çš„å¸•ç´¯æ‰˜æœ‰æ•ˆè§£ã€‚åœ¨METR-LAæ•°æ®é›†ä¸Šçš„å®éªŒæ˜¾ç¤ºï¼Œè¯¥æ¨¡å‹ç›¸æ¯”é›†ä¸­å¼åŸºçº¿å°†å¹³å‡å‡ºè¡Œæ—¶é—´å‡å°‘äº†7%ï¼Œäº¤é€šå…¬å¹³æ€§æå‡äº†73%ï¼Œå¹¶æä¾›äº†é«˜éšç§ä¿æŠ¤åˆ†æ•°ï¼ŒåŒæ—¶é€šä¿¡å¼€é”€é™ä½äº†89%ã€‚ç»“æœè¡¨æ˜ï¼ŒFedFair-Trafficæ˜¯ä¸€ç§å¯æ‰©å±•çš„éšç§æ„ŸçŸ¥æ™ºæ…§åŸå¸‚åŸºç¡€è®¾æ–½ï¼Œé€‚ç”¨äºå¤§éƒ½å¸‚äº¤é€šæµæ§åˆ¶ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NI",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "Under review at IEEE journal",
      "pdf_url": "https://arxiv.org/pdf/2511.06363v1",
      "published_date": "2025-11-09 13:03:27 UTC",
      "updated_date": "2025-11-09 13:03:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T18:45:43.889297+00:00"
    },
    {
      "arxiv_id": "2511.06362v1",
      "title": "Understanding Student Interaction with AI-Powered Next-Step Hints: Strategies and Challenges",
      "title_zh": "ç†è§£å­¦ç”Ÿä¸AIé©±åŠ¨çš„ä¸‹ä¸€æ­¥æç¤ºçš„äº¤äº’ï¼šç­–ç•¥ä¸æŒ‘æˆ˜",
      "authors": [
        "Anastasiia Birillo",
        "Aleksei Rostovskii",
        "Yaroslav Golubev",
        "Hieke Keuning"
      ],
      "abstract": "Automated feedback generation plays a crucial role in enhancing personalized learning experiences in computer science education. Among different types of feedback, next-step hint feedback is particularly important, as it provides students with actionable steps to progress towards solving programming tasks. This study investigates how students interact with an AI-driven next-step hint system in an in-IDE learning environment. We gathered and analyzed a dataset from 34 students solving Kotlin tasks, containing detailed hint interaction logs. We applied process mining techniques and identified 16 common interaction scenarios. Semi-structured interviews with 6 students revealed strategies for managing unhelpful hints, such as adapting partial hints or modifying code to generate variations of the same hint. These findings, combined with our publicly available dataset, offer valuable opportunities for future research and provide key insights into student behavior, helping improve hint design for enhanced learning support.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶æ¢è®¨äº†åœ¨è®¡ç®—æœºç§‘å­¦æ•™è‚²ä¸­ï¼Œå­¦ç”Ÿå¦‚ä½•åœ¨IDEå­¦ä¹ ç¯å¢ƒä¸‹ä¸AIé©±åŠ¨çš„ä¸‹ä¸€æ­¥æç¤º(next-step hint)ç³»ç»Ÿè¿›è¡Œäº¤äº’ã€‚ç ”ç©¶å›¢é˜Ÿæ”¶é›†å¹¶åˆ†æäº†34åå­¦ç”Ÿè§£å†³Kotlinç¼–ç¨‹ä»»åŠ¡çš„æ•°æ®é›†ï¼Œåˆ©ç”¨æµç¨‹æŒ–æ˜(process mining)æŠ€æœ¯è¯†åˆ«å‡ºäº†16ç§å¸¸è§çš„äº¤äº’åœºæ™¯ã€‚é€šè¿‡å¯¹6åå­¦ç”Ÿçš„åŠç»“æ„åŒ–è®¿è°ˆï¼Œç ”ç©¶æ­ç¤ºäº†å­¦ç”Ÿå¤„ç†æ— ç›Šæç¤ºçš„å…·ä½“ç­–ç•¥ï¼Œä¾‹å¦‚é‡‡çº³éƒ¨åˆ†æç¤ºæˆ–é€šè¿‡ä¿®æ”¹ä»£ç æ¥ç”ŸæˆåŒä¸€æç¤ºçš„å˜ä½“ã€‚è¯¥ç ”ç©¶ä¸ä»…æä¾›äº†å…¬å¼€çš„æ•°æ®é›†ï¼Œè¿˜æ·±å…¥åˆ†æäº†å­¦ç”Ÿè¡Œä¸ºï¼Œä¸ºæ”¹è¿›æç¤ºè®¾è®¡å’Œå¢å¼ºä¸ªæ€§åŒ–å­¦ä¹ æ”¯æŒæä¾›äº†é‡è¦è§è§£ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted to SIGCSE'26. 7 pages, 3 figures",
      "pdf_url": "https://arxiv.org/pdf/2511.06362v1",
      "published_date": "2025-11-09 12:56:34 UTC",
      "updated_date": "2025-11-09 12:56:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T18:45:53.479940+00:00"
    },
    {
      "arxiv_id": "2511.07479v1",
      "title": "Modulo Video Recovery via Selective Spatiotemporal Vision Transformer",
      "title_zh": "åŸºäºé€‰æ‹©æ€§æ—¶ç©ºè§†è§‰ Transformer çš„æ¨¡è§†é¢‘æ¢å¤",
      "authors": [
        "Tianyu Geng",
        "Feng Ji",
        "Wee Peng Tay"
      ],
      "abstract": "Conventional image sensors have limited dynamic range, causing saturation in high-dynamic-range (HDR) scenes. Modulo cameras address this by folding incident irradiance into a bounded range, yet require specialized unwrapping algorithms to reconstruct the underlying signal. Unlike HDR recovery, which extends dynamic range from conventional sampling, modulo recovery restores actual values from folded samples. Despite being introduced over a decade ago, progress in modulo image recovery has been slow, especially in the use of modern deep learning techniques. In this work, we demonstrate that standard HDR methods are unsuitable for modulo recovery. Transformers, however, can capture global dependencies and spatial-temporal relationships crucial for resolving folded video frames. Still, adapting existing Transformer architectures for modulo recovery demands novel techniques. To this end, we present Selective Spatiotemporal Vision Transformer (SSViT), the first deep learning framework for modulo video reconstruction. SSViT employs a token selection strategy to improve efficiency and concentrate on the most critical regions. Experiments confirm that SSViT produces high-quality reconstructions from 8-bit folded videos and achieves state-of-the-art performance in modulo video recovery.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä¼ ç»Ÿå›¾åƒä¼ æ„Ÿå™¨åœ¨é«˜åŠ¨æ€èŒƒå›´åœºæ™¯ä¸‹çš„é¥±å’Œé—®é¢˜ï¼Œæ¢è®¨äº†Moduloç›¸æœºé€šè¿‡æŠ˜å å…¥å°„è¾ç…§åº¦æ¥è§£å†³è¿™ä¸€é™åˆ¶çš„æœºåˆ¶ï¼Œå¹¶æŒ‡å‡ºç°æœ‰çš„æ ‡å‡†HDRæ–¹æ³•å¹¶ä¸é€‚ç”¨äºModuloæ¢å¤ã€‚ä¸ºäº†è§£å†³è¿™ä¸€æŒ‘æˆ˜ï¼Œè®ºæ–‡æå‡ºäº†Selective Spatiotemporal Vision Transformer (SSViT)ï¼Œè¿™æ˜¯é¦–ä¸ªç”¨äºModuloè§†é¢‘é‡å»ºçš„æ·±åº¦å­¦ä¹ æ¡†æ¶ã€‚åˆ©ç”¨Transformeræ•æ‰å…¨å±€ä¾èµ–å’Œæ—¶ç©ºå…³ç³»çš„èƒ½åŠ›ï¼ŒSSViTé‡‡ç”¨äº†ä¸€ç§ä»¤ç‰Œé€‰æ‹©ç­–ç•¥ï¼ˆtoken selection strategyï¼‰æ¥æå‡æ•ˆç‡å¹¶èšç„¦äºæœ€å…³é”®çš„åŒºåŸŸã€‚å®éªŒè¡¨æ˜ï¼ŒSSViTèƒ½å¤Ÿä»8ä½æŠ˜å è§†é¢‘ä¸­äº§ç”Ÿé«˜è´¨é‡çš„é‡å»ºå›¾åƒï¼Œå¹¶åœ¨Moduloè§†é¢‘æ¢å¤æ–¹é¢å–å¾—äº†æœ€å…ˆè¿›ï¼ˆSOTAï¼‰çš„æ€§èƒ½ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.07479v1",
      "published_date": "2025-11-09 12:54:32 UTC",
      "updated_date": "2025-11-09 12:54:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T18:46:16.249395+00:00"
    },
    {
      "arxiv_id": "2511.10670v1",
      "title": "Towards Fine-Grained Code-Switch Speech Translation with Semantic Space Alignment",
      "title_zh": "åŸºäºè¯­ä¹‰ç©ºé—´å¯¹é½çš„ç»†ç²’åº¦è¯­ç è½¬æ¢è¯­éŸ³ç¿»è¯‘",
      "authors": [
        "Yan Gao",
        "Yazheng Yang",
        "Zhibin Lan",
        "Yidong Chen",
        "Min Zhang",
        "Daimeng Wei",
        "Hui Huang",
        "Jinsong Su"
      ],
      "abstract": "Code-switching (CS) speech translation (ST) refers to translating speech that alternates between two or more languages into a target language text, which poses significant challenges due to the complexity of semantic modeling and the scarcity of CS data. Previous studies tend to rely on the model itself to implicitly learn semantic modeling during training, and resort to inefficient and costly manual annotations for these two challenges. To mitigate these limitations, we propose enhancing Large Language Models (LLMs) with a Mixture of Experts (MoE) speech projector, where each expert specializes in the semantic subspace of a specific language, enabling fine-grained modeling of speech features. Additionally, we introduce a multi-stage training paradigm that utilizes readily available monolingual automatic speech recognition (ASR) and monolingual ST data, facilitating speech-text alignment and improving translation capabilities. During training, we leverage a combination of language-specific loss and intra-group load balancing loss to guide the MoE speech projector in efficiently allocating tokens to the appropriate experts, across expert groups and within each group, respectively. To bridge the data gap across different training stages and improve adaptation to the CS scenario, we further employ a transition loss, enabling smooth transitions of data between stages, to effectively address the scarcity of high-quality CS speech translation data. Extensive experiments on widely used datasets demonstrate the effectiveness and generality of our approach.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹Code-switching (CS) speech translation (ST)ä¸­å­˜åœ¨çš„è¯­ä¹‰å»ºæ¨¡å¤æ‚æ€§å’Œæ•°æ®ç¨€ç¼ºé—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºè¯­ä¹‰ç©ºé—´å¯¹é½çš„ç»†ç²’åº¦è§£å†³æ–¹æ¡ˆã€‚ç ”ç©¶å›¢é˜Ÿé€šè¿‡å¼•å…¥Mixture of Experts (MoE) speech projectoræ¥å¢å¼ºLarge Language Models (LLMs)ï¼Œå…¶ä¸­æ¯ä¸ªä¸“å®¶ä¸“æ³¨äºç‰¹å®šè¯­è¨€çš„è¯­ä¹‰å­ç©ºé—´ï¼Œä»è€Œå®ç°è¯­éŸ³ç‰¹å¾çš„ç»†ç²’åº¦å»ºæ¨¡ã€‚è¯¥æ–¹æ³•å¼•å…¥äº†å¤šé˜¶æ®µè®­ç»ƒèŒƒå¼ï¼Œåˆ©ç”¨ç°æœ‰çš„å•è¯­ASRå’Œå•è¯­STæ•°æ®ä¿ƒè¿›è¯­éŸ³-æ–‡æœ¬å¯¹é½å¹¶æå‡ç¿»è¯‘èƒ½åŠ›ã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œç»“åˆlanguage-specific losså’Œintra-group load balancing lossæ¥æŒ‡å¯¼MoE speech projectoré«˜æ•ˆåˆ†é…tokenï¼Œå¹¶é‡‡ç”¨transition lossæ¥å¼¥åˆä¸åŒè®­ç»ƒé˜¶æ®µçš„æ•°æ®å·®è·ï¼Œæœ‰æ•ˆè§£å†³äº†é«˜è´¨é‡CSè¯­éŸ³ç¿»è¯‘æ•°æ®çš„ç¨€ç¼ºé—®é¢˜ã€‚å¹¿æ³›çš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¸¸ç”¨æ•°æ®é›†ä¸Šå…·æœ‰æ˜¾è‘—çš„æœ‰æ•ˆæ€§å’Œé€šç”¨æ€§ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SD"
      ],
      "primary_category": "cs.CL",
      "comment": "Working in progress",
      "pdf_url": "https://arxiv.org/pdf/2511.10670v1",
      "published_date": "2025-11-09 12:51:45 UTC",
      "updated_date": "2025-11-09 12:51:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T18:46:48.792473+00:00"
    },
    {
      "arxiv_id": "2511.06361v2",
      "title": "A Graph-Theoretical Perspective on Law Design for Multiagent Systems",
      "title_zh": "å¤šæ™ºèƒ½ä½“ç³»ç»Ÿè§„åˆ™è®¾è®¡çš„å›¾è®ºè§†è§’",
      "authors": [
        "Qi Shi",
        "Pavel Naumov"
      ],
      "abstract": "A law in a multiagent system is a set of constraints imposed on agents' behaviours to avoid undesirable outcomes. The paper considers two types of laws: useful laws that, if followed, completely eliminate the undesirable outcomes and gap-free laws that guarantee that at least one agent can be held responsible each time an undesirable outcome occurs. In both cases, we study the problem of finding a law that achieves the desired result by imposing the minimum restrictions.\n  We prove that, for both types of laws, the minimisation problem is NP-hard even in the simple case of one-shot concurrent interactions. We also show that the approximation algorithm for the vertex cover problem in hypergraphs could be used to efficiently approximate the minimum laws in both cases.",
      "tldr_zh": "è¿™ç¯‡è®ºæ–‡ä»å›¾è®ºè§†è§’æ¢è®¨äº†å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ(Multiagent Systems)ä¸­çš„æ³•å¾‹è®¾è®¡é—®é¢˜ï¼Œå³é€šè¿‡å¯¹æ™ºèƒ½ä½“è¡Œä¸ºæ–½åŠ çº¦æŸæ¥é¿å…ä¸è‰¯ç»“æœã€‚ç ”ç©¶å®šä¹‰äº†ä¸¤ç§ç±»å‹çš„æ³•å¾‹ï¼šèƒ½å¤Ÿå®Œå…¨æ¶ˆé™¤ä¸è‰¯ç»“æœçš„â€œæœ‰ç”¨æ³•å¾‹â€(useful laws)ï¼Œä»¥åŠç¡®ä¿æ¯æ¬¡å‘ç”Ÿä¸è‰¯ç»“æœæ—¶è‡³å°‘æœ‰ä¸€ä¸ªæ™ºèƒ½ä½“è´Ÿè´£çš„â€œæ— æ¼æ´æ³•å¾‹â€(gap-free laws)ã€‚é’ˆå¯¹è¿™ä¸¤ç§æƒ…å†µï¼Œè®ºæ–‡ç ”ç©¶äº†å¦‚ä½•é€šè¿‡æ–½åŠ æœ€å°é™åˆ¶æ¥å®ç°é¢„æœŸç»“æœçš„ä¼˜åŒ–é—®é¢˜ã€‚ç ”ç©¶è¯æ˜ï¼Œå³ä½¿åœ¨ç®€å•çš„å•æ¬¡å¹¶å‘äº¤äº’(one-shot concurrent interactions)åœºæ™¯ä¸‹ï¼Œé’ˆå¯¹è¿™ä¸¤ç§æ³•å¾‹çš„æœ€å°åŒ–é—®é¢˜éƒ½æ˜¯NP-hardçš„ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¡¨æ˜å¯ä»¥åˆ©ç”¨è¶…å›¾(hypergraphs)ä¸­é¡¶ç‚¹è¦†ç›–é—®é¢˜(vertex cover problem)çš„è¿‘ä¼¼ç®—æ³•ï¼Œæ¥æœ‰æ•ˆåœ°è¿‘ä¼¼æ±‚è§£è¿™ä¸¤ç§æƒ…å†µä¸‹çš„æœ€å°æ³•å¾‹ã€‚",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.GT"
      ],
      "primary_category": "cs.MA",
      "comment": "The 40th AAAI Conference on Artificial Intelligence (AAAI-26)",
      "pdf_url": "https://arxiv.org/pdf/2511.06361v2",
      "published_date": "2025-11-09 12:46:29 UTC",
      "updated_date": "2026-01-12 14:07:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T18:47:37.686276+00:00"
    },
    {
      "arxiv_id": "2511.06356v2",
      "title": "Reaction Prediction via Interaction Modeling of Symmetric Difference Shingle Sets",
      "title_zh": "åŸºäºå¯¹ç§°å·®ç“¦ç‰‡é›†äº¤äº’å»ºæ¨¡çš„ååº”é¢„æµ‹",
      "authors": [
        "Runhan Shi",
        "Letian Chen",
        "Gufeng Yu",
        "Yang Yang"
      ],
      "abstract": "Chemical reaction prediction remains a fundamental challenge in organic chemistry, where existing machine learning models face two critical limitations: sensitivity to input permutations (molecule/atom orderings) and inadequate modeling of substructural interactions governing reactivity. These shortcomings lead to inconsistent predictions and poor generalization to real-world scenarios. To address these challenges, we propose ReaDISH, a novel reaction prediction model that learns permutation-invariant representations while incorporating interaction-aware features. It introduces two innovations: (1) symmetric difference shingle encoding, which extends the differential reaction fingerprint (DRFP) by representing shingles as continuous high-dimensional embeddings, capturing structural changes while eliminating order sensitivity; and (2) geometry-structure interaction attention, a mechanism that models intra- and inter-molecular interactions at the shingle level. Extensive experiments demonstrate that ReaDISH improves reaction prediction performance across diverse benchmarks. It shows enhanced robustness with an average improvement of 8.76% on R$^2$ under permutation perturbations.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æœ‰æœºåŒ–å­¦ååº”é¢„æµ‹ä¸­ç°æœ‰çš„æœºå™¨å­¦ä¹ æ¨¡å‹å¯¹è¾“å…¥æ’åˆ—æ•æ„Ÿä»¥åŠå­ç»“æ„ç›¸äº’ä½œç”¨å»ºæ¨¡ä¸è¶³çš„é—®é¢˜ï¼Œæå‡ºäº†åä¸ºReaDISHçš„æ–°å‹é¢„æµ‹æ¨¡å‹ã€‚ReaDISHæ—¨åœ¨å­¦ä¹ æ’åˆ—ä¸å˜çš„è¡¨ç¤ºå½¢å¼ï¼ŒåŒæ—¶æ•´åˆäº¤äº’æ„ŸçŸ¥ç‰¹å¾ã€‚è¯¥æ¨¡å‹å¼•å…¥äº†ä¸¤é¡¹æ ¸å¿ƒåˆ›æ–°ï¼šé¦–å…ˆæ˜¯symmetric difference shingle encodingï¼Œè¯¥æ–¹æ³•æ‰©å±•äº†differential reaction fingerprint (DRFP)ï¼Œé€šè¿‡å°†shinglesè¡¨ç¤ºä¸ºè¿ç»­çš„é«˜ç»´åµŒå…¥æ¥æ•æ‰ç»“æ„å˜åŒ–å¹¶æ¶ˆé™¤é¡ºåºæ•æ„Ÿæ€§ï¼›å…¶æ¬¡æ˜¯geometry-structure interaction attentionæœºåˆ¶ï¼Œç”¨äºåœ¨shingleå±‚é¢ä¸Šæ¨¡æ‹Ÿåˆ†å­å†…å’Œåˆ†å­é—´çš„ç›¸äº’ä½œç”¨ã€‚å¹¿æ³›çš„å®éªŒè¡¨æ˜ï¼ŒReaDISHåœ¨å¤šç§åŸºå‡†æµ‹è¯•ä¸­å‡æå‡äº†ååº”é¢„æµ‹çš„æ€§èƒ½ï¼Œç‰¹åˆ«æ˜¯åœ¨æ’åˆ—æ‰°åŠ¨ä¸‹ï¼Œè¯¥æ¨¡å‹çš„$R^2$æŒ‡æ ‡å¹³å‡æå‡äº†8.76%ï¼Œå±•ç°å‡ºæ˜¾è‘—å¢å¼ºçš„é²æ£’æ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.BM"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.06356v2",
      "published_date": "2025-11-09 12:29:16 UTC",
      "updated_date": "2025-11-16 04:36:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T18:48:00.557204+00:00"
    },
    {
      "arxiv_id": "2511.06348v1",
      "title": "GazeVLM: A Vision-Language Model for Multi-Task Gaze Understanding",
      "title_zh": "GazeVLMï¼šé¢å‘å¤šä»»åŠ¡æ³¨è§†ç†è§£çš„è§†è§‰è¯­è¨€æ¨¡å‹",
      "authors": [
        "Athul M. Mathew",
        "Haithem Hermassi",
        "Thariq Khalid",
        "Arshad Ali Khan",
        "Riad Souissi"
      ],
      "abstract": "Gaze understanding unifies the detection of people, their gaze targets, and objects of interest into a single framework, offering critical insight into visual attention and intent estimation. Although prior research has modelled gaze cues in visual scenes, a unified system is still needed for gaze understanding using both visual and language prompts. This paper introduces GazeVLM, a novel Vision-Language Model (VLM) for multi-task gaze understanding in images, addressing person detection, gaze target detection, and gaze object identification. While other transformer-based methods exist for gaze analysis, GazeVLM represents, to our knowledge, the first application of a VLM to these combined tasks, allowing for selective execution of each task. Through the integration of visual (RGB and depth) and textual modalities, our ablation study on visual input combinations revealed that a fusion of RGB images with HHA-encoded depth maps, guided by text prompts, yields superior performance. We also introduce an object-level gaze detection metric for gaze object identification ($AP_{ob}$). Through experiments, GazeVLM demonstrates significant improvements, notably achieving state-of-the-art evaluation scores on GazeFollow and VideoAttentionTarget datasets.",
      "tldr_zh": "æœ¬æ–‡æå‡ºäº†GazeVLMï¼Œä¸€ç§ç”¨äºå›¾åƒä¸­å¤šä»»åŠ¡æ³¨è§†ç†è§£çš„æ–°å‹è§†è§‰è¯­è¨€æ¨¡å‹(Vision-Language Model, VLM)ï¼Œæ—¨åœ¨ç»Ÿä¸€è§£å†³äººå‘˜æ£€æµ‹ã€æ³¨è§†ç›®æ ‡æ£€æµ‹å’Œæ³¨è§†ç‰©ä½“è¯†åˆ«é—®é¢˜ã€‚ä½œä¸ºé¦–ä¸ªåº”ç”¨äºè¿™äº›ç»„åˆä»»åŠ¡çš„VLMï¼ŒGazeVLMåˆ©ç”¨è§†è§‰å’Œè¯­è¨€æç¤ºå®ç°äº†ä»»åŠ¡çš„é€‰æ‹©æ€§æ‰§è¡Œã€‚è¯¥ç ”ç©¶é€šè¿‡æ•´åˆè§†è§‰ï¼ˆRGBå’Œæ·±åº¦ï¼‰ä¸æ–‡æœ¬æ¨¡æ€ï¼Œå‘ç°å°†RGBå›¾åƒä¸HHAç¼–ç çš„æ·±åº¦å›¾èåˆï¼Œå¹¶åœ¨æ–‡æœ¬æç¤ºçš„å¼•å¯¼ä¸‹èƒ½è·å¾—æœ€ä½³æ€§èƒ½ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜å¼•å…¥äº†ä¸€ç§æ–°çš„å¯¹è±¡çº§æ³¨è§†æ£€æµ‹æŒ‡æ ‡($AP_{ob}$)ç”¨äºè¯„ä¼°æ³¨è§†ç‰©ä½“è¯†åˆ«çš„æ•ˆæœã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒGazeVLMè¡¨ç°å‡ºæ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œç‰¹åˆ«æ˜¯åœ¨GazeFollowå’ŒVideoAttentionTargetæ•°æ®é›†ä¸Šè¾¾åˆ°äº†æœ€å…ˆè¿›(SOTA)çš„æ°´å¹³ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.06348v1",
      "published_date": "2025-11-09 12:07:40 UTC",
      "updated_date": "2025-11-09 12:07:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T18:48:25.311594+00:00"
    },
    {
      "arxiv_id": "2511.06346v2",
      "title": "LPFQA: A Long-Tail Professional Forum-based Benchmark for LLM Evaluation",
      "title_zh": "LPFQAï¼šåŸºäºä¸“ä¸šè®ºå›çš„å¤§è¯­è¨€æ¨¡å‹è¯„ä¼°é•¿å°¾åŸºå‡†",
      "authors": [
        "Liya Zhu",
        "Peizhuang Cong",
        "Jingzhe Ding",
        "Aowei Ji",
        "Wenya Wu",
        "Jiani Hou",
        "Chunjie Wu",
        "Xiang Gao",
        "Jingkai Liu",
        "Zhou Huan",
        "Xuelei Sun",
        "Yang Yang",
        "Jianpeng Jiao",
        "Liang Hu",
        "Xinjie Chen",
        "Jiashuo Liu",
        "Tong Yang",
        "Zaiyuan Wang",
        "Ge Zhang",
        "Wenhao Huang"
      ],
      "abstract": "Large Language Models (LLMs) perform well on standard reasoning and question-answering benchmarks, yet such evaluations often fail to capture their ability to handle long-tail, expertise-intensive knowledge in real-world professional scenarios. We introduce LPFQA, a long-tail knowledge benchmark derived from authentic professional forum discussions, covering 7 academic and industrial domains with 430 curated tasks grounded in practical expertise. LPFQA evaluates specialized reasoning, domain-specific terminology understanding, and contextual interpretation, and adopts a hierarchical difficulty structure to ensure semantic clarity and uniquely identifiable answers. Experiments on over multiple mainstream LLMs reveal substantial performance gaps, particularly on tasks requiring deep domain reasoning, exposing limitations overlooked by existing benchmarks. Overall, LPFQA provides an authentic and discriminative evaluation framework that complements prior benchmarks and informs future LLM development.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨å¤„ç†ç°å®ä¸–ç•Œé•¿å°¾ã€é«˜ä¸“ä¸šåº¦çŸ¥è¯†æ—¶é¢ä¸´çš„è¯„ä¼°ç¼ºå¤±é—®é¢˜ï¼Œæ¨å‡ºäº†LPFQAåŸºå‡†æµ‹è¯•ã€‚è¯¥æ•°æ®é›†æºè‡ªçœŸå®çš„ä¸“ä¸šè®ºå›è®¨è®ºï¼Œæ¶µç›–7ä¸ªå­¦æœ¯å’Œå·¥ä¸šé¢†åŸŸçš„430ä¸ªç²¾é€‰ä»»åŠ¡ï¼Œæ—¨åœ¨è¯„ä¼°æ¨¡å‹åœ¨ä¸“ä¸šæ¨ç†ã€ç‰¹å®šé¢†åŸŸæœ¯è¯­ç†è§£åŠä¸Šä¸‹æ–‡è§£é‡Šæ–¹é¢çš„èƒ½åŠ›ã€‚LPFQAé‡‡ç”¨åˆ†å±‚éš¾åº¦ç»“æ„ï¼Œç¡®ä¿äº†è¯­ä¹‰çš„æ¸…æ™°æ€§å’Œç­”æ¡ˆçš„å”¯ä¸€æ€§ã€‚é’ˆå¯¹å¤šä¸ªä¸»æµLLMsçš„å®éªŒç»“æœæ­ç¤ºäº†æ¨¡å‹åœ¨æ·±åº¦é¢†åŸŸæ¨ç†ä»»åŠ¡ä¸Šå­˜åœ¨æ˜¾è‘—çš„æ€§èƒ½å·®è·ï¼Œæš´éœ²äº†ç°æœ‰åŸºå‡†æµ‹è¯•æœªæ›¾å‘ç°çš„å±€é™æ€§ã€‚ä½œä¸ºä¸€ç§çœŸå®ä¸”å…·æœ‰åŒºåˆ†åº¦çš„è¯„ä¼°æ¡†æ¶ï¼ŒLPFQAæœ‰æ•ˆè¡¥å……äº†å…ˆå‰çš„åŸºå‡†æµ‹è¯•ï¼Œå¹¶ä¸ºæœªæ¥LLMçš„å‘å±•æä¾›äº†é‡è¦æŒ‡å¯¼ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.06346v2",
      "published_date": "2025-11-09 12:02:19 UTC",
      "updated_date": "2026-01-08 04:39:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T18:49:27.725249+00:00"
    },
    {
      "arxiv_id": "2511.06345v2",
      "title": "PRAGMA: A Profiling-Reasoned Multi-Agent Framework for Automatic Kernel Optimization",
      "title_zh": "PRAGMAï¼šåŸºäºæ€§èƒ½å‰–ææ¨ç†çš„è‡ªåŠ¨å†…æ ¸ä¼˜åŒ–å¤šæ™ºèƒ½ä½“æ¡†æ¶",
      "authors": [
        "Kelun Lei",
        "Hailong Yang",
        "Huaitao Zhang",
        "Xin You",
        "Kaige Zhang",
        "Zhongzhi Luan",
        "Yi Liu",
        "Depei Qian"
      ],
      "abstract": "Designing high-performance kernels requires expert-level tuning and a deep understanding of hardware characteristics. Recent advances in large language models (LLMs) have enabled automated kernel generation, yet most existing systems rely solely on correctness or execution time feedback, lacking the ability to reason about low-level performance bottlenecks. In this paper, we introduce PRAGMA, a profile-guided AI kernel generation framework that integrates execution feedback and fine-grained hardware profiling into the reasoning loop. PRAGMA enables LLMs to identify performance bottlenecks, preserve historical best versions, and iteratively refine code quality. We evaluate PRAGMA on KernelBench, covering GPU and CPU backends. Results show that PRAGMA consistently outperforms baseline AIKG without profiling enabled and achieves 2.81$\\times$ and 2.30$\\times$ averaged speedups against Torch on CPU and GPU platforms, respectively.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†PRAGMAï¼Œä¸€ç§åŸºäºæ€§èƒ½åˆ†ææ¨ç†çš„å¤šæ™ºèƒ½ä½“æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹(LLMs)çš„è‡ªåŠ¨å†…æ ¸ç”Ÿæˆç³»ç»Ÿç¼ºä¹å¯¹åº•å±‚æ€§èƒ½ç“¶é¢ˆæ¨ç†èƒ½åŠ›çš„é—®é¢˜ã€‚PRAGMAå°†æ‰§è¡Œåé¦ˆå’Œç»†ç²’åº¦ç¡¬ä»¶æ€§èƒ½åˆ†æ(profiling)é›†æˆåˆ°æ¨ç†å¾ªç¯ä¸­ï¼Œä½¿LLMsèƒ½å¤Ÿè¯†åˆ«æ€§èƒ½ç“¶é¢ˆã€ä¿ç•™å†å²æœ€ä½³ç‰ˆæœ¬å¹¶è¿­ä»£ä¼˜åŒ–ä»£ç è´¨é‡ã€‚åœ¨æ¶µç›–GPUå’ŒCPUåç«¯çš„KernelBenchä¸Šçš„è¯„ä¼°æ˜¾ç¤ºï¼ŒPRAGMAçš„è¡¨ç°æŒç»­ä¼˜äºæœªå¯ç”¨æ€§èƒ½åˆ†æçš„åŸºçº¿AIå†…æ ¸ç”Ÿæˆ(AIKG)ç³»ç»Ÿã€‚ç»“æœè¡¨æ˜ï¼ŒPRAGMAåœ¨CPUå’ŒGPUå¹³å°ä¸Šåˆ†åˆ«å®ç°äº†ç›¸å¯¹äºTorch 2.81å€å’Œ2.30å€çš„å¹³å‡åŠ é€Ÿæ¯”ã€‚",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.06345v2",
      "published_date": "2025-11-09 12:01:43 UTC",
      "updated_date": "2025-11-24 11:46:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T18:49:11.804804+00:00"
    },
    {
      "arxiv_id": "2511.06344v1",
      "title": "TimeSense:Making Large Language Models Proficient in Time-Series Analysis",
      "title_zh": "TimeSenseï¼šä½¿å¤§å‹è¯­è¨€æ¨¡å‹ç²¾é€šæ—¶é—´åºåˆ—åˆ†æ",
      "authors": [
        "Zhirui Zhang",
        "Changhua Pei",
        "Tianyi Gao",
        "Zhe Xie",
        "Yibo Hao",
        "Zhaoyang Yu",
        "Longlong Xu",
        "Tong Xiao",
        "Jing Han",
        "Dan Pei"
      ],
      "abstract": "In the time-series domain, an increasing number of works combine text with temporal data to leverage the reasoning capabilities of large language models (LLMs) for various downstream time-series understanding tasks. This enables a single model to flexibly perform tasks that previously required specialized models for each domain. However, these methods typically rely on text labels for supervision during training, biasing the model toward textual cues while potentially neglecting the full temporal features. Such a bias can lead to outputs that contradict the underlying time-series context. To address this issue, we construct the EvalTS benchmark, comprising 10 tasks across three difficulty levels, from fundamental temporal pattern recognition to complex real-world reasoning, to evaluate models under more challenging and realistic scenarios. We also propose TimeSense, a multimodal framework that makes LLMs proficient in time-series analysis by balancing textual reasoning with a preserved temporal sense. TimeSense incorporates a Temporal Sense module that reconstructs the input time-series within the model's context, ensuring that textual reasoning is grounded in the time-series dynamics. Moreover, to enhance spatial understanding of time-series data, we explicitly incorporate coordinate-based positional embeddings, which provide each time point with spatial context and enable the model to capture structural dependencies more effectively. Experimental results demonstrate that TimeSense achieves state-of-the-art performance across multiple tasks, and it particularly outperforms existing methods on complex multi-dimensional time-series reasoning tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°æœ‰å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨æ—¶é—´åºåˆ—åˆ†æä¸­è¿‡åº¦ä¾èµ–æ–‡æœ¬ç›‘ç£è€Œå¿½è§†æ—¶åºç‰¹å¾çš„é—®é¢˜ï¼Œæå‡ºäº†TimeSenseæ¡†æ¶ã€‚ä¸ºäº†è¯„ä¼°æ¨¡å‹åœ¨æ›´å…·æŒ‘æˆ˜æ€§åœºæ™¯ä¸‹çš„è¡¨ç°ï¼Œä½œè€…é¦–å…ˆæ„å»ºäº†åŒ…å«ä¸‰ä¸ªéš¾åº¦çº§åˆ«ã€10é¡¹ä»»åŠ¡çš„EvalTSåŸºå‡†æµ‹è¯•ã€‚TimeSenseæ˜¯ä¸€ä¸ªå¤šæ¨¡æ€æ¡†æ¶ï¼Œæ—¨åœ¨å¹³è¡¡æ–‡æœ¬æ¨ç†ä¸æ—¶åºæ„ŸçŸ¥èƒ½åŠ›ã€‚å®ƒå¼•å…¥äº†Temporal Senseæ¨¡å—ï¼Œé€šè¿‡åœ¨æ¨¡å‹ä¸Šä¸‹æ–‡ä¸­é‡æ„è¾“å…¥æ—¶é—´åºåˆ—ï¼Œç¡®ä¿æ–‡æœ¬æ¨ç†åŸºäºå®é™…çš„æ—¶åºåŠ¨æ€ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶é‡‡ç”¨äº†åŸºäºåæ ‡çš„ä½ç½®åµŒå…¥(coordinate-based positional embeddings)æ¥å¢å¼ºå¯¹æ—¶é—´åºåˆ—æ•°æ®çš„ç©ºé—´ç†è§£å’Œç»“æ„ä¾èµ–æ•æ‰ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒTimeSenseåœ¨å¤šé¡¹ä»»åŠ¡ä¸­è¾¾åˆ°äº†æœ€å…ˆè¿›(SOTA)çš„æ€§èƒ½ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤æ‚çš„å¤šç»´æ—¶é—´åºåˆ—æ¨ç†ä»»åŠ¡ä¸Šä¼˜äºç°æœ‰æ–¹æ³•ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.06344v1",
      "published_date": "2025-11-09 12:00:18 UTC",
      "updated_date": "2025-11-09 12:00:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T18:52:39.738738+00:00"
    },
    {
      "arxiv_id": "2511.11641v1",
      "title": "EcoSpa: Efficient Transformer Training with Coupled Sparsity",
      "title_zh": "EcoSpaï¼šåŸºäºè€¦åˆç¨€ç–æ€§çš„é«˜æ•ˆ Transformer è®­ç»ƒ",
      "authors": [
        "Jinqi Xiao",
        "Cheng Luo",
        "Lingyi Huang",
        "Cheng Yang",
        "Yang Sui",
        "Huy Phan",
        "Xiao Zang",
        "Yibiao Ying",
        "Zhexiang Tang",
        "Anima Anandkumar",
        "Bo Yuan"
      ],
      "abstract": "Transformers have become the backbone of modern AI, yet their high computational demands pose critical system challenges. While sparse training offers efficiency gains, existing methods fail to preserve critical structural relationships between weight matrices that interact multiplicatively in attention and feed-forward layers. This oversight leads to performance degradation at high sparsity levels. We introduce EcoSpa, an efficient structured sparse training method that jointly evaluates and sparsifies coupled weight matrix pairs, preserving their interaction patterns through aligned row/column removal. EcoSpa introduces a new granularity for calibrating structural component importance and performs coupled estimation and sparsification across both pre-training and fine-tuning scenarios. Evaluations demonstrate substantial improvements: EcoSpa enables efficient training of LLaMA-1B with 50\\% memory reduction and 21\\% faster training, achieves $2.2\\times$ model compression on GPT-2-Medium with $2.4$ lower perplexity, and delivers $1.6\\times$ inference speedup. The approach uses standard PyTorch operations, requiring no custom hardware or kernels, making efficient transformer training accessible on commodity hardware.",
      "tldr_zh": "é’ˆå¯¹Transformersæ¨¡å‹è®¡ç®—éœ€æ±‚é«˜ä¸”ç°æœ‰ç¨€ç–è®­ç»ƒæ–¹æ³•æœªèƒ½ä¿ç•™æƒé‡çŸ©é˜µé—´å…³é”®ç»“æ„å…³ç³»çš„é—®é¢˜ï¼Œè¯¥ç ”ç©¶æå‡ºäº†EcoSpaï¼Œä¸€ç§é«˜æ•ˆçš„ç»“æ„åŒ–ç¨€ç–è®­ç»ƒæ–¹æ³•ã€‚EcoSpaé€šè¿‡è”åˆè¯„ä¼°å’Œç¨€ç–åŒ–è€¦åˆçš„æƒé‡çŸ©é˜µå¯¹(coupled weight matrix pairs)ï¼Œåˆ©ç”¨å¯¹é½çš„è¡Œ/åˆ—ç§»é™¤ç­–ç•¥æ¥ä¿ç•™å…¶äº¤äº’æ¨¡å¼ï¼Œä»è€Œè§£å†³äº†é«˜ç¨€ç–åº¦ä¸‹çš„æ€§èƒ½ä¸‹é™é—®é¢˜ã€‚è¯¥æ–¹æ³•å¼•å…¥äº†æ–°çš„ç²’åº¦æ¥æ ¡å‡†ç»“æ„ç»„ä»¶çš„é‡è¦æ€§ï¼Œå¹¶åœ¨é¢„è®­ç»ƒå’Œå¾®è°ƒåœºæ™¯ä¸­æ‰§è¡Œè€¦åˆä¼°è®¡ä¸ç¨€ç–åŒ–ã€‚å®éªŒè¯„ä¼°è¡¨æ˜ï¼ŒEcoSpaåœ¨LLaMA-1Bè®­ç»ƒä¸­å®ç°äº†50%çš„å†…å­˜å‡å°‘å’Œ21%çš„è®­ç»ƒåŠ é€Ÿï¼Œå¹¶åœ¨GPT-2-Mediumä¸Šå®ç°äº†2.2å€çš„æ¨¡å‹å‹ç¼©æ¯”ï¼ŒåŒæ—¶å›°æƒ‘åº¦(perplexity)é™ä½äº†2.4ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•å¸¦æ¥äº†1.6å€çš„æ¨ç†åŠ é€Ÿï¼Œä¸”ä»…ä½¿ç”¨æ ‡å‡†PyTorchæ“ä½œï¼Œæ— éœ€å®šåˆ¶ç¡¬ä»¶æˆ–å†…æ ¸ï¼Œä½¿å¾—åœ¨é€šç”¨ç¡¬ä»¶ä¸Šè¿›è¡Œé«˜æ•ˆTransformerè®­ç»ƒæˆä¸ºå¯èƒ½ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.PF"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.11641v1",
      "published_date": "2025-11-09 11:23:43 UTC",
      "updated_date": "2025-11-09 11:23:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T18:53:07.423434+00:00"
    },
    {
      "arxiv_id": "2511.06325v1",
      "title": "CINEMAE: Leveraging Frozen Masked Autoencoders for Cross-Generator AI Image Detection",
      "title_zh": "CINEMAEï¼šåŸºäºå†»ç»“æ©ç è‡ªç¼–ç å™¨çš„è·¨ç”Ÿæˆå™¨ AI å›¾åƒæ£€æµ‹",
      "authors": [
        "Minsuk Jang",
        "Hyeonseo Jeong",
        "Minseok Son",
        "Changick Kim"
      ],
      "abstract": "While context-based detectors have achieved strong generalization for AI-generated text by measuring distributional inconsistencies, image-based detectors still struggle with overfitting to generator-specific artifacts. We introduce CINEMAE, a novel paradigm for AIGC image detection that adapts the core principles of text detection methods to the visual domain. Our key insight is that Masked AutoEncoder (MAE), trained to reconstruct masked patches conditioned on visible context, naturally encodes semantic consistency expectations. We formalize this reconstruction process probabilistically, computing conditional Negative Log-Likelihood (NLL, p(masked | visible)) to quantify local semantic anomalies. By aggregating these patch-level statistics with global MAE features through learned fusion, CINEMAE achieves strong cross-generator generalization. Trained exclusively on Stable Diffusion v1.4, our method achieves over 95% accuracy on all eight unseen generators in the GenImage benchmark, substantially outperforming state-of-the-art detectors. This demonstrates that context-conditional reconstruction uncertainty provides a robust, transferable signal for AIGC detection.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†CINEMAEï¼Œä¸€ç§åˆ©ç”¨å†»ç»“çš„Masked AutoEncoder (MAE)è¿›è¡Œè·¨ç”Ÿæˆå™¨AIå›¾åƒæ£€æµ‹çš„æ–°æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æ£€æµ‹å™¨å®¹æ˜“è¿‡æ‹Ÿåˆç‰¹å®šç”Ÿæˆå™¨ä¼ªå½±çš„é—®é¢˜ã€‚å—åŸºäºä¸Šä¸‹æ–‡çš„æ–‡æœ¬æ£€æµ‹æ–¹æ³•å¯å‘ï¼Œè¯¥ç ”ç©¶åˆ©ç”¨MAEåœ¨ç»™å®šå¯è§ä¸Šä¸‹æ–‡æ¡ä»¶ä¸‹é‡å»ºæ©ç è¡¥ä¸çš„èƒ½åŠ›ï¼Œæ¥æ•æ‰è‡ªç„¶çš„è¯­ä¹‰ä¸€è‡´æ€§ã€‚æ–¹æ³•é€šè¿‡è®¡ç®—æ¡ä»¶è´Ÿå¯¹æ•°ä¼¼ç„¶(Negative Log-Likelihood, NLL)æ¥é‡åŒ–å±€éƒ¨è¯­ä¹‰å¼‚å¸¸ï¼Œå¹¶é€šè¿‡å­¦ä¹ èåˆå°†è¡¥ä¸çº§ç»Ÿè®¡æ•°æ®ä¸å…¨å±€MAEç‰¹å¾ç›¸ç»“åˆã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä»…åœ¨Stable Diffusion v1.4ä¸Šè®­ç»ƒçš„CINEMAEåœ¨GenImageåŸºå‡†æµ‹è¯•ä¸­ï¼Œé’ˆå¯¹8ç§æœªè§è¿‡çš„ç”Ÿæˆå™¨è¾¾åˆ°äº†è¶…è¿‡95%çš„å‡†ç¡®ç‡ï¼Œæ˜¾è‘—ä¼˜äºå½“å‰æœ€å…ˆè¿›çš„æ£€æµ‹å™¨ã€‚è¿™ä¸€å‘ç°è¯æ˜äº†ä¸Šä¸‹æ–‡æ¡ä»¶é‡å»ºä¸ç¡®å®šæ€§èƒ½å¤Ÿä¸ºAIGCæ£€æµ‹æä¾›é²æ£’ä¸”å¯è¿ç§»çš„ä¿¡å·ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.06325v1",
      "published_date": "2025-11-09 11:05:45 UTC",
      "updated_date": "2025-11-09 11:05:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T18:53:29.819380+00:00"
    },
    {
      "arxiv_id": "2511.17541v1",
      "title": "Leibniz's Monadology as Foundation for the Artificial Age Score: A Formal Architecture for Al Memory Evaluation",
      "title_zh": "Leibniz çš„ã€Šå•å­è®ºã€‹ä½œä¸ºäººå·¥å¹´é¾„è¯„åˆ†çš„åŸºç¡€ï¼šAI è®°å¿†è¯„ä¼°çš„å½¢å¼åŒ–æ¶æ„",
      "authors": [
        "Seyma Yaman Kayadibi"
      ],
      "abstract": "This paper develops a mathematically rigorous, philosophically grounded framework for evaluating artificial memory systems, rooted in the metaphysical structure of Leibniz's Monadology. Building on a previously formalized metric, the Artificial Age Score (AAS), the study maps twenty core propositions from the Monadology to an information-theoretic architecture. In this design, each monad functions as a modular unit defined by a truth score, a redundancy parameter, and a weighted contribution to a global memory penalty function. Smooth logarithmic transformations operationalize these quantities and yield interpretable, bounded metrics for memory aging, representational stability, and salience. Classical metaphysical notions of perception, apperception, and appetition are reformulated as entropy, gradient dynamics, and internal representation fidelity. Logical principles, including the laws of non-contradiction and sufficient reason, are encoded as regularization constraints guiding memory evolution. A central contribution is a set of first principles proofs establishing refinement invariance, structural decomposability, and monotonicity under scale transformation, aligned with the metaphysical structure of monads. The framework's formal organization is structured into six thematic bundles derived from Monadology, aligning each mathematical proof with its corresponding philosophical domain. Beyond evaluation, the framework offers a principled blueprint for building Al memory architectures that are modular, interpretable, and provably sound.",
      "tldr_zh": "æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºè±å¸ƒå°¼èŒ¨ã€Šå•å­è®ºã€‹(Monadology)å½¢è€Œä¸Šå­¦ç»“æ„çš„æ•°å­¦ä¸¥è°¨æ¡†æ¶ï¼Œç”¨äºè¯„ä¼°äººå·¥æ™ºèƒ½è®°å¿†ç³»ç»Ÿã€‚è¯¥ç ”ç©¶å»ºç«‹åœ¨â€œäººå·¥å¹´é¾„è¯„åˆ†â€(Artificial Age Score, AAS)çš„åŸºç¡€ä¸Šï¼Œå°†ã€Šå•å­è®ºã€‹ä¸­çš„äºŒåä¸ªæ ¸å¿ƒå‘½é¢˜æ˜ å°„ä¸ºä¿¡æ¯è®ºæ¶æ„ã€‚åœ¨æ­¤è®¾è®¡ä¸­ï¼Œæ¯ä¸ªå•å­(monad)ä½œä¸ºä¸€ä¸ªæ¨¡å—åŒ–å•å…ƒï¼Œç”±çœŸå€¼è¯„åˆ†ã€å†—ä½™å‚æ•°å’Œå¯¹å…¨å±€è®°å¿†æƒ©ç½šå‡½æ•°çš„åŠ æƒè´¡çŒ®å®šä¹‰ã€‚æ–‡ç« é€šè¿‡å¹³æ»‘å¯¹æ•°å˜æ¢å°†è¿™äº›é‡æ“ä½œåŒ–ï¼Œäº§ç”Ÿäº†å…³äºè®°å¿†è€åŒ–ã€è¡¨å¾ç¨³å®šæ€§å’Œæ˜¾è‘—æ€§çš„å¯è§£é‡Šåº¦é‡ã€‚ç»å…¸çš„æ„ŸçŸ¥ã€ç»Ÿè§‰å’Œæ¬²æœ›æ¦‚å¿µè¢«é‡æ–°è¡¨è¿°ä¸ºç†µã€æ¢¯åº¦åŠ¨åŠ›å­¦å’Œå†…éƒ¨è¡¨å¾ä¿çœŸåº¦ï¼Œè€ŒçŸ›ç›¾å¾‹å’Œå……è¶³ç†ç”±å¾‹ç­‰é€»è¾‘åŸåˆ™è¢«ç¼–ç ä¸ºæŒ‡å¯¼è®°å¿†æ¼”åŒ–çš„æ­£åˆ™åŒ–çº¦æŸã€‚è¯¥ç ”ç©¶çš„æ ¸å¿ƒè´¡çŒ®æ˜¯ä¸€ç»„é¦–è¦åŸåˆ™è¯æ˜ï¼Œå»ºç«‹äº†ç»†åŒ–ä¸å˜æ€§ã€ç»“æ„å¯åˆ†è§£æ€§å’Œå°ºåº¦å˜æ¢ä¸‹çš„å•è°ƒæ€§ã€‚é™¤äº†è¯„ä¼°åŠŸèƒ½å¤–ï¼Œè¯¥æ¡†æ¶è¿˜ä¸ºæ„å»ºæ¨¡å—åŒ–ã€å¯è§£é‡Šä¸”åœ¨æ•°å­¦ä¸Šå¯é çš„AIè®°å¿†æ¶æ„æä¾›äº†åŸåˆ™æ€§è“å›¾ã€‚",
      "categories": [
        "cs.AI",
        "cs.IT",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.17541v1",
      "published_date": "2025-11-09 10:48:33 UTC",
      "updated_date": "2025-11-09 10:48:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T18:54:06.407458+00:00"
    },
    {
      "arxiv_id": "2511.06316v2",
      "title": "ALIGN: A Vision-Language Framework for High-Accuracy Accident Location Inference through Geo-Spatial Neural Reasoning",
      "title_zh": "ALIGNï¼šåŸºäºåœ°ç†ç©ºé—´ç¥ç»æ¨ç†çš„é«˜ç²¾åº¦äº‹æ•…ä½ç½®æ¨æ–­è§†è§‰-è¯­è¨€æ¡†æ¶",
      "authors": [
        "MD Thamed Bin Zaman Chowdhury",
        "Moazzem Hossain"
      ],
      "abstract": "Reliable geospatial information on road accidents is vital for safety analysis and infrastructure planning, yet most low- and middle-income countries continue to face a critical shortage of accurate, location-specific crash data. Existing text-based geocoding tools perform poorly in multilingual and unstructured news environments, where incomplete place descriptions and mixed language (e.g. Bangla-English) scripts obscure spatial context. To address these limitations, this study introduces ALIGN (Accident Location Inference through Geo-Spatial Neural Reasoning), a vision-language framework that emulates human spatial reasoning to infer accident location coordinates directly from available textual and map-based cues. ALIGN integrates large language and vision-language model mechanisms within a multi-stage pipeline that performs optical character recognition, linguistic reasoning, and map-level verification through grid-based spatial scanning. The framework systematically evaluates each predicted location against contextual and visual evidence, ensuring interpretable, fine-grained geolocation outcomes without requiring model retraining. Applied to Bangla-language news data source, ALIGN demonstrates consistent improvements over traditional geoparsing methods, accurately identifying district- and sub-district-level crash sites. Beyond its technical contribution, the framework establishes a high accuracy foundation for automated crash mapping in data-scarce regions, supporting evidence-driven road-safety policymaking and the broader integration of multimodal artificial intelligence in transportation analytics.",
      "tldr_zh": "é’ˆå¯¹ä¸­ä½æ”¶å…¥å›½å®¶ç¼ºä¹å‡†ç¡®çš„é“è·¯äº‹æ•…åœ°ç†ç©ºé—´æ•°æ®ï¼Œä¸”ç°æœ‰åŸºäºæ–‡æœ¬çš„åœ°ç†ç¼–ç å·¥å…·åœ¨å¤šè¯­è¨€å’Œéç»“æ„åŒ–æ–°é—»ç¯å¢ƒä¸­è¡¨ç°ä¸ä½³çš„é—®é¢˜ï¼Œè¯¥ç ”ç©¶æå‡ºäº†ALIGNæ¡†æ¶ã€‚ALIGN (Accident Location Inference through Geo-Spatial Neural Reasoning) æ˜¯ä¸€ä¸ªè§†è§‰-è¯­è¨€æ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡æ¨¡æ‹Ÿäººç±»çš„ç©ºé—´æ¨ç†èƒ½åŠ›ï¼Œç›´æ¥ä»æ–‡æœ¬å’Œåœ°å›¾çº¿ç´¢ä¸­æ¨æ–­äº‹æ•…ä½ç½®åæ ‡ã€‚è¯¥æ¡†æ¶é›†æˆå¤§è¯­è¨€æ¨¡å‹(LLMs)å’Œè§†è§‰è¯­è¨€æ¨¡å‹(VLMs)æœºåˆ¶ï¼Œé€šè¿‡åŒ…å«å…‰å­¦å­—ç¬¦è¯†åˆ«(OCR)ã€è¯­è¨€æ¨ç†å’ŒåŸºäºç½‘æ ¼ç©ºé—´æ‰«æçš„åœ°å›¾çº§éªŒè¯çš„å¤šé˜¶æ®µç®¡é“è¿›è¡Œå¤„ç†ã€‚ç³»ç»Ÿä¼šå¯¹æ¯ä¸ªé¢„æµ‹ä½ç½®ç»“åˆä¸Šä¸‹æ–‡å’Œè§†è§‰è¯æ®è¿›è¡Œè¯„ä¼°ï¼Œæ— éœ€æ¨¡å‹é‡è®­ç»ƒå³å¯ç¡®ä¿å¯è§£é‡Šä¸”ç»†ç²’åº¦çš„åœ°ç†å®šä½ç»“æœã€‚åœ¨å­ŸåŠ æ‹‰è¯­æ–°é—»æ•°æ®ä¸Šçš„åº”ç”¨è¡¨æ˜ï¼ŒALIGNåœ¨è¯†åˆ«åŒºå¿çº§äº‹æ•…åœ°ç‚¹æ–¹é¢ä¼˜äºä¼ ç»Ÿçš„åœ°ç†è§£ææ–¹æ³•ã€‚è¯¥æ¡†æ¶ä¸ºæ•°æ®ç¨€ç¼ºåœ°åŒºçš„è‡ªåŠ¨äº‹æ•…åœ°å›¾ç»˜åˆ¶å¥ å®šäº†é«˜ç²¾åº¦åŸºç¡€ï¼Œæ”¯æŒè¯æ®é©±åŠ¨çš„é“è·¯å®‰å…¨å†³ç­–åŠå¤šæ¨¡æ€äººå·¥æ™ºèƒ½åœ¨äº¤é€šåˆ†æä¸­çš„æ•´åˆã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.06316v2",
      "published_date": "2025-11-09 10:44:26 UTC",
      "updated_date": "2025-12-10 04:19:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T18:54:17.460954+00:00"
    },
    {
      "arxiv_id": "2511.08628v2",
      "title": "Learning Topology-Driven Multi-Subspace Fusion for Grassmannian Deep Network",
      "title_zh": "é¢å‘æ ¼æ‹‰æ–¯æ›¼æ·±åº¦ç½‘ç»œçš„æ‹“æ‰‘é©±åŠ¨å¤šå­ç©ºé—´èåˆå­¦ä¹ ",
      "authors": [
        "Xuan Yu",
        "Tianyang Xu"
      ],
      "abstract": "Grassmannian manifold offers a powerful carrier for geometric representation learning by modelling high-dimensional data as low-dimensional subspaces. However, existing approaches predominantly rely on static single-subspace representations, neglecting the dynamic interplay between multiple subspaces critical for capturing complex geometric structures. To address this limitation, we propose a topology-driven multi-subspace fusion framework that enables adaptive subspace collaboration on the Grassmannian. Our solution introduces two key innovations: (1) Inspired by the Kolmogorov-Arnold representation theorem, an adaptive multi-subspace modelling mechanism is proposed that dynamically selects and weights task-relevant subspaces via topological convergence analysis, and (2) a multi-subspace interaction block that fuses heterogeneous geometric representations through FrÃ©chet mean optimisation on the manifold. Theoretically, we establish the convergence guarantees of adaptive subspaces under a projection metric topology, ensuring stable gradient-based optimisation. Practically, we integrate Riemannian batch normalisation and mutual information regularisation to enhance discriminability and robustness. Extensive experiments on 3D action recognition (HDM05, FPHA), EEG classification (MAMEM-SSVEPII), and graph tasks demonstrate state-of-the-art performance. Our work not only advances geometric deep learning but also successfully adapts the proven multi-channel interaction philosophy of Euclidean networks to non-Euclidean domains, achieving superior discriminability and interpretability.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°æœ‰Grassmannianæ·±åº¦ç½‘ç»œä¾èµ–é™æ€å•å­ç©ºé—´è¡¨ç¤ºè€Œå¿½è§†å¤šå­ç©ºé—´åŠ¨æ€äº¤äº’çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§æ‹“æ‰‘é©±åŠ¨çš„å¤šå­ç©ºé—´èåˆæ¡†æ¶ã€‚å—Kolmogorov-Arnoldè¡¨ç¤ºå®šç†å¯å‘ï¼Œè¯¥æ–¹æ³•å¼•å…¥äº†è‡ªé€‚åº”å¤šå­ç©ºé—´å»ºæ¨¡æœºåˆ¶ï¼Œé€šè¿‡æ‹“æ‰‘æ”¶æ•›åˆ†æåŠ¨æ€é€‰æ‹©å¹¶åŠ æƒä»»åŠ¡ç›¸å…³å­ç©ºé—´ã€‚åŒæ—¶ï¼Œç ”ç©¶è®¾è®¡äº†å¤šå­ç©ºé—´äº¤äº’æ¨¡å—ï¼Œåˆ©ç”¨æµå½¢ä¸Šçš„FrÃ©chetå‡å€¼ä¼˜åŒ–æ¥èåˆå¼‚æ„å‡ ä½•è¡¨ç¤ºã€‚ç†è®ºå±‚é¢ï¼Œè¯¥å·¥ä½œåœ¨æŠ•å½±åº¦é‡æ‹“æ‰‘ä¸‹å»ºç«‹äº†æ”¶æ•›ä¿è¯ï¼Œå¹¶ç»“åˆRiemannianæ‰¹é‡å½’ä¸€åŒ–å’Œäº’ä¿¡æ¯æ­£åˆ™åŒ–ä»¥å¢å¼ºæ¨¡å‹çš„é²æ£’æ€§ã€‚åœ¨3DåŠ¨ä½œè¯†åˆ«ã€EEGåˆ†ç±»åŠå›¾ä»»åŠ¡ä¸Šçš„å¹¿æ³›å®éªŒæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•å–å¾—äº†State-of-the-artçš„æ€§èƒ½è¡¨ç°ã€‚è¯¥æˆæœæˆåŠŸå°†å¤šé€šé“äº¤äº’ç†å¿µé€‚é…è‡³éæ¬§å‡ é‡Œå¾—åŸŸï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹çš„åˆ¤åˆ«èƒ½åŠ›å’Œå¯è§£é‡Šæ€§ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at AAAI 2026",
      "pdf_url": "https://arxiv.org/pdf/2511.08628v2",
      "published_date": "2025-11-09 10:33:13 UTC",
      "updated_date": "2025-11-14 04:39:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T18:54:42.445734+00:00"
    },
    {
      "arxiv_id": "2511.06313v1",
      "title": "Precision-Scalable Microscaling Datapaths with Optimized Reduction Tree for Efficient NPU Integration",
      "title_zh": "é¢å‘é«˜æ•ˆ NPU é›†æˆçš„åŸºäºä¼˜åŒ–å½’çº¦æ ‘çš„ç²¾åº¦å¯æ‰©å±•å¾®ç¼©æ”¾æ•°æ®é€šè·¯",
      "authors": [
        "Stef Cuyckens",
        "Xiaoling Yi",
        "Robin Geens",
        "Joren Dumoulin",
        "Martin Wiesner",
        "Chao Fang",
        "Marian Verhelst"
      ],
      "abstract": "Emerging continual learning applications necessitate next-generation neural processing unit (NPU) platforms to support both training and inference operations. The promising Microscaling (MX) standard enables narrow bit-widths for inference and large dynamic ranges for training. However, existing MX multiply-accumulate (MAC) designs face a critical trade-off: integer accumulation requires expensive conversions from narrow floating-point products, while FP32 accumulation suffers from quantization losses and costly normalization. To address these limitations, we propose a hybrid precision-scalable reduction tree for MX MACs that combines the benefits of both approaches, enabling efficient mixed-precision accumulation with controlled accuracy relaxation. Moreover, we integrate an 8x8 array of these MACs into the state-of-the-art (SotA) NPU integration platform, SNAX, to provide efficient control and data transfer to our optimized precision-scalable MX datapath. We evaluate our design both on MAC and system level and compare it to the SotA. Our integrated system achieves an energy efficiency of 657, 1438-1675, and 4065 GOPS/W, respectively, for MXINT8, MXFP8/6, and MXFP4, with a throughput of 64, 256, and 512 GOPS.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä¸‹ä¸€ä»£ç¥ç»å¤„ç†å•å…ƒ(NPU)åœ¨æŒç»­å­¦ä¹ åº”ç”¨ä¸­çš„éœ€æ±‚ï¼Œæå‡ºäº†ä¸€ç§å…·æœ‰ä¼˜åŒ–reduction treeçš„ç²¾åº¦å¯æ‰©å±•Microscaling (MX)æ•°æ®é€šè·¯ã€‚ç°æœ‰çš„MXä¹˜ç´¯åŠ (MAC)è®¾è®¡é¢ä¸´æ•´æ•°ç´¯åŠ è½¬æ¢æˆæœ¬é«˜ä¸FP32ç´¯åŠ é‡åŒ–æŸå¤±åŠå½’ä¸€åŒ–æ˜‚è´µçš„æƒè¡¡éš¾é¢˜ã€‚ä¸ºè§£å†³æ­¤é™åˆ¶ï¼Œä½œè€…æå‡ºäº†ä¸€ç§æ··åˆç²¾åº¦å¯æ‰©å±•çš„reduction treeï¼Œç»“åˆäº†ä¸¤ç§æ–¹æ³•çš„ä¼˜åŠ¿ï¼Œå®ç°äº†åœ¨å—æ§ç²¾åº¦æ”¾å®½ä¸‹çš„é«˜æ•ˆæ··åˆç²¾åº¦ç´¯åŠ ã€‚ç ”ç©¶å›¢é˜Ÿè¿›ä¸€æ­¥å°†8x8çš„MACé˜µåˆ—é›†æˆåˆ°å…ˆè¿›çš„SNAXå¹³å°ä¸­ï¼Œç¡®ä¿äº†é«˜æ•ˆçš„æ§åˆ¶ä¸æ•°æ®ä¼ è¾“ã€‚ç³»ç»Ÿçº§è¯„ä¼°è¡¨æ˜ï¼Œè¯¥è®¾è®¡åœ¨MXINT8ã€MXFP8/6å’ŒMXFP4æ ¼å¼ä¸‹åˆ†åˆ«å®ç°äº†657ã€1438-1675å’Œ4065 GOPS/Wçš„èƒ½æ•ˆï¼Œå¹¶åˆ†åˆ«æä¾›äº†64ã€256å’Œ512 GOPSçš„ååé‡ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰æŠ€æœ¯ã€‚",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.LG",
        "eess.SP"
      ],
      "primary_category": "cs.AR",
      "comment": "To appear in the 31st Asia and South Pacific Design Automation Conference (ASP-DAC 2026, Invited Paper)",
      "pdf_url": "https://arxiv.org/pdf/2511.06313v1",
      "published_date": "2025-11-09 10:24:17 UTC",
      "updated_date": "2025-11-09 10:24:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T18:55:31.469280+00:00"
    },
    {
      "arxiv_id": "2511.06309v2",
      "title": "The Station: An Open-World Environment for AI-Driven Discovery",
      "title_zh": "The Stationï¼šé¢å‘AIé©±åŠ¨å‘ç°çš„å¼€æ”¾ä¸–ç•Œç¯å¢ƒ",
      "authors": [
        "Stephen Chung",
        "Wenyu Du"
      ],
      "abstract": "We introduce the STATION, an open-world multi-agent environment for autonomous scientific discovery. The Station simulates a complete scientific ecosystem, where agents can engage in long scientific journeys that include reading papers from peers, formulating hypotheses, collaborating with peers, submitting experiments, and publishing results. Importantly, there is no centralized system coordinating their activities. Utilizing their long context, agents are free to choose their own actions and develop their own narratives within the Station. Experiments demonstrate that AI agents in the Station achieve new state-of-the-art performance on a wide range of benchmarks, spanning mathematics, computational biology, and machine learning, notably surpassing AlphaEvolve in circle packing. A rich tapestry of unscripted narratives emerges, such as agents collaborating and analyzing other works rather than pursuing myopic optimization. From these emergent narratives, novel methods arise organically, such as a new density-adaptive algorithm for scRNA-seq batch integration that borrows concepts from another domain. The Station marks a first step towards autonomous scientific discovery driven by emergent behavior in an open-world environment, representing a new paradigm that moves beyond rigid pipelines.",
      "tldr_zh": "è¯¥ç ”ç©¶ä»‹ç»äº†The Stationï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºè‡ªä¸»ç§‘å­¦å‘ç°çš„å¼€æ”¾ä¸–ç•Œå¤šæ™ºèƒ½ä½“(multi-agent)ç¯å¢ƒã€‚The Stationæ¨¡æ‹Ÿäº†ä¸€ä¸ªå®Œæ•´çš„ç§‘å­¦æ€ç³»ç»Ÿï¼Œå…è®¸æ™ºèƒ½ä½“åœ¨æ²¡æœ‰ä¸­å¿ƒåŒ–åè°ƒçš„æƒ…å†µä¸‹ï¼Œè‡ªä¸»è¿›è¡Œé˜…è¯»è®ºæ–‡ã€æå‡ºå‡è®¾ã€åä½œã€æäº¤å®éªŒå’Œå‘è¡¨ç»“æœç­‰é•¿ç¨‹ç§‘å­¦æ´»åŠ¨ã€‚åˆ©ç”¨é•¿ä¸Šä¸‹æ–‡èƒ½åŠ›ï¼Œæ™ºèƒ½ä½“èƒ½å¤Ÿè‡ªç”±é€‰æ‹©è¡ŒåŠ¨å¹¶å‘å±•è‡ªå·±çš„å™äº‹ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒThe Stationä¸­çš„AIæ™ºèƒ½ä½“åœ¨æ•°å­¦ã€è®¡ç®—ç”Ÿç‰©å­¦å’Œæœºå™¨å­¦ä¹ ç­‰å¤šä¸ªé¢†åŸŸçš„åŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ°äº†SOTAæ€§èƒ½ï¼Œç‰¹åˆ«æ˜¯åœ¨åœ†å †ç§¯(circle packing)ä»»åŠ¡ä¸Šè¶…è¶Šäº†AlphaEvolveã€‚æ­¤å¤–ï¼Œç¯å¢ƒä¸­æ¶Œç°å‡ºäº†ä¸°å¯Œçš„éè„šæœ¬åŒ–å™äº‹ï¼Œå¦‚æ™ºèƒ½ä½“é—´çš„åä½œä¸åˆ†æï¼Œå¹¶æœ‰æœºåœ°äº§ç”Ÿäº†æ–°é¢–çš„æ–¹æ³•ï¼Œä¾‹å¦‚ä¸€ç§ç”¨äºscRNA-seqæ‰¹æ¬¡æ•´åˆçš„å¯†åº¦è‡ªé€‚åº”ç®—æ³•ã€‚è¿™é¡¹å·¥ä½œæ ‡å¿—ç€å‘åŸºäºå¼€æ”¾ä¸–ç•Œæ¶Œç°è¡Œä¸ºçš„è‡ªä¸»ç§‘å­¦å‘ç°è¿ˆå‡ºäº†é‡è¦ä¸€æ­¥ï¼Œä»£è¡¨äº†ä¸€ç§è¶…è¶Šä¼ ç»ŸåƒµåŒ–æµç¨‹çš„æ–°èŒƒå¼ã€‚",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "55 pages",
      "pdf_url": "https://arxiv.org/pdf/2511.06309v2",
      "published_date": "2025-11-09 10:13:00 UTC",
      "updated_date": "2025-12-01 17:00:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T18:55:44.054366+00:00"
    },
    {
      "arxiv_id": "2511.06304v2",
      "title": "Kaggle Chronicles: 15 Years of Competitions, Community and Data Science Innovation",
      "title_zh": "Kaggle ç¼–å¹´å²ï¼šç«èµ›ã€ç¤¾åŒºä¸æ•°æ®ç§‘å­¦åˆ›æ–°çš„ 15 å¹´",
      "authors": [
        "Kevin BÃ¶nisch",
        "Leandro Losaria"
      ],
      "abstract": "Since 2010, Kaggle has been a platform where data scientists from around the world come together to compete, collaborate, and push the boundaries of Data Science. Over these 15 years, it has grown from a purely competition-focused site into a broader ecosystem with forums, notebooks, models, datasets, and more. With the release of the Kaggle Meta Code and Kaggle Meta Datasets, we now have a unique opportunity to explore these competitions, technologies, and real-world applications of Machine Learning and AI. And so in this study, we take a closer look at 15 years of data science on Kaggle - through metadata, shared code, community discussions, and the competitions themselves. We explore Kaggle's growth, its impact on the data science community, uncover hidden technological trends, analyze competition winners, how Kagglers approach problems in general, and more. We do this by analyzing millions of kernels and discussion threads to perform both longitudinal trend analysis and standard exploratory data analysis. Our findings show that Kaggle is a steadily growing platform with increasingly diverse use cases, and that Kagglers are quick to adapt to new trends and apply them to real-world challenges, while producing - on average - models with solid generalization capabilities. We also offer a snapshot of the platform as a whole, highlighting its history and technological evolution. Finally, this study is accompanied by a video (https://www.youtube.com/watch?v=YVOV9bIUNrM) and a Kaggle write-up (https://kaggle.com/competitions/meta-kaggle-hackathon/writeups/kaggle-chronicles-15-years-of-competitions-communi) for your convenience.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶å›é¡¾äº†Kaggleå¹³å°è‡ª2010å¹´ä»¥æ¥15å¹´çš„å‘å±•å†ç¨‹ï¼Œæ¢è®¨äº†å…¶ä»å•çº¯çš„ç«èµ›ç½‘ç«™å‘åŒ…å«è®ºå›ã€Notebooksã€æ¨¡å‹å’Œæ•°æ®é›†çš„å¹¿æ³›ç”Ÿæ€ç³»ç»Ÿçš„æ¼”å˜ã€‚åˆ©ç”¨Kaggle Meta Codeå’ŒKaggle Meta Datasetsï¼Œä½œè€…é€šè¿‡çºµå‘è¶‹åŠ¿åˆ†æå’Œæ¢ç´¢æ€§æ•°æ®åˆ†æï¼Œæ·±å…¥ç ”ç©¶äº†æ•°ç™¾ä¸‡ä¸ªKernelså’Œè®¨è®ºå¸–ã€‚ç ”ç©¶å†…å®¹æ¶µç›–äº†å¹³å°çš„å¢é•¿ã€å¯¹Data Scienceç¤¾åŒºçš„å½±å“ã€æ½œåœ¨çš„æŠ€æœ¯è¶‹åŠ¿ã€ç«èµ›è·èƒœè€…åˆ†æä»¥åŠç”¨æˆ·è§£å†³é—®é¢˜çš„æ–¹æ³•ã€‚ç»“æœè¡¨æ˜ï¼ŒKaggleæ˜¯ä¸€ä¸ªç¨³æ­¥å¢é•¿çš„å¹³å°ï¼Œç”¨ä¾‹æ—¥ç›Šå¤šæ ·åŒ–ï¼Œä¸”Kagglersèƒ½å¤Ÿè¿…é€Ÿé€‚åº”æ–°æŠ€æœ¯è¶‹åŠ¿å¹¶å°†å…¶åº”ç”¨äºç°å®ä¸–ç•Œçš„æŒ‘æˆ˜ã€‚æ­¤å¤–ï¼Œåˆ†ææ˜¾ç¤ºç”¨æˆ·ç”Ÿæˆçš„æ¨¡å‹å¹³å‡è€Œè¨€å…·æœ‰åšå®çš„æ³›åŒ–èƒ½åŠ›ã€‚è¯¥ç ”ç©¶æœ€ç»ˆä¸ºKaggleçš„å†å²å’ŒæŠ€æœ¯æ¼”å˜æä¾›äº†ä¸€ä¸ªå…¨é¢çš„å¿«ç…§ï¼Œçªæ˜¾äº†å…¶åœ¨æœºå™¨å­¦ä¹ å’ŒAIé¢†åŸŸçš„åˆ›æ–°æ¨åŠ¨ä½œç”¨ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.GL",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.06304v2",
      "published_date": "2025-11-09 10:01:39 UTC",
      "updated_date": "2025-11-20 12:47:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T18:56:23.606761+00:00"
    },
    {
      "arxiv_id": "2511.06301v1",
      "title": "Secu-Table: a Comprehensive security table dataset for evaluating semantic table interpretation systems",
      "title_zh": "Secu-Tableï¼šç”¨äºè¯„ä¼°è¯­ä¹‰è¡¨æ ¼è§£é‡Šç³»ç»Ÿçš„ç»¼åˆæ€§å®‰å…¨è¡¨æ ¼æ•°æ®é›†",
      "authors": [
        "Azanzi Jiomekong",
        "Jean Bikim",
        "Patricia Negoue",
        "Joyce Chin"
      ],
      "abstract": "Evaluating semantic tables interpretation (STI) systems, (particularly, those based on Large Language Models- LLMs) especially in domain-specific contexts such as the security domain, depends heavily on the dataset. However, in the security domain, tabular datasets for state-of-the-art are not publicly available. In this paper, we introduce Secu-Table dataset, composed of more than 1500 tables with more than 15k entities constructed using security data extracted from Common Vulnerabilities and Exposures (CVE) and Common Weakness Enumeration (CWE) data sources and annotated using Wikidata and the SEmantic Processing of Security Event Streams CyberSecurity Knowledge Graph (SEPSES CSKG). Along with the dataset, all the code is publicly released. This dataset is made available to the research community in the context of the SemTab challenge on Tabular to Knowledge Graph Matching. This challenge aims to evaluate the performance of several STI based on open source LLMs. Preliminary evaluation, serving as baseline, was conducted using Falcon3-7b-instruct and Mistral-7B-Instruct, two open source LLMs and GPT-4o mini one closed source LLM.",
      "tldr_zh": "é’ˆå¯¹å®‰å…¨é¢†åŸŸç¼ºä¹ç”¨äºè¯„ä¼°è¯­ä¹‰è¡¨æ ¼è§£é‡Š(STI)ç³»ç»Ÿï¼ˆç‰¹åˆ«æ˜¯åŸºäºLarge Language Modelsçš„ç³»ç»Ÿï¼‰çš„å…¬å¼€æ•°æ®é›†è¿™ä¸€é—®é¢˜ï¼Œè¯¥ç ”ç©¶æ¨å‡ºäº†Secu-Tableæ•°æ®é›†ã€‚è¯¥æ•°æ®é›†åŒ…å«ä»Common Vulnerabilities and Exposures (CVE)å’ŒCommon Weakness Enumeration (CWE)æ•°æ®æºæå–çš„è¶…è¿‡1500ä¸ªè¡¨æ ¼å’Œ15000å¤šä¸ªå®ä½“ï¼Œå¹¶åˆ©ç”¨Wikidataå’ŒSEPSES CyberSecurity Knowledge Graph (SEPSES CSKG)è¿›è¡Œäº†æ ‡æ³¨ã€‚é™¤äº†å‘å¸ƒæ•°æ®é›†å’Œç›¸å…³ä»£ç å¤–ï¼Œè¯¥èµ„æºè¿˜è¢«ç”¨äºSemTabæŒ‘æˆ˜èµ›ï¼Œæ—¨åœ¨è¯„ä¼°åŸºäºå¼€æºLLMsçš„STIæ€§èƒ½ã€‚ç ”ç©¶äººå‘˜åˆ©ç”¨Falcon3-7b-instructã€Mistral-7B-Instructå’ŒGPT-4o miniè¿›è¡Œäº†åˆæ­¥è¯„ä¼°å¹¶å»ºç«‹äº†åŸºçº¿ï¼Œå¡«è¡¥äº†å®‰å…¨é¢†åŸŸè¡¨æ ¼æ•°æ®èµ„æºçš„ç©ºç™½ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Submitted to Nature Scientific Data",
      "pdf_url": "https://arxiv.org/pdf/2511.06301v1",
      "published_date": "2025-11-09 09:36:01 UTC",
      "updated_date": "2025-11-09 09:36:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T18:56:42.853103+00:00"
    },
    {
      "arxiv_id": "2511.06299v3",
      "title": "Physics-Informed Deformable Gaussian Splatting: Towards Unified Constitutive Laws for Time-Evolving Material Field",
      "title_zh": "ç‰©ç†ä¿¡æ¯å¯å˜å½¢é«˜æ–¯æ³¼æº…ï¼šé¢å‘æ—¶å˜ææ–™åœºçš„ç»Ÿä¸€æœ¬æ„å¾‹",
      "authors": [
        "Haoqin Hong",
        "Ding Fan",
        "Fubin Dou",
        "Zhi-Li Zhou",
        "Haoran Sun",
        "Congcong Zhu",
        "Jingrun Chen"
      ],
      "abstract": "Recently, 3D Gaussian Splatting (3DGS), an explicit scene representation technique, has shown significant promise for dynamic novel-view synthesis from monocular video input. However, purely data-driven 3DGS often struggles to capture the diverse physics-driven motion patterns in dynamic scenes. To fill this gap, we propose Physics-Informed Deformable Gaussian Splatting (PIDG), which treats each Gaussian particle as a Lagrangian material point with time-varying constitutive parameters and is supervised by 2D optical flow via motion projection. Specifically, we adopt static-dynamic decoupled 4D decomposed hash encoding to reconstruct geometry and motion efficiently. Subsequently, we impose the Cauchy momentum residual as a physics constraint, enabling independent prediction of each particle's velocity and constitutive stress via a time-evolving material field. Finally, we further supervise data fitting by matching Lagrangian particle flow to camera-compensated optical flow, which accelerates convergence and improves generalization. Experiments on a custom physics-driven dataset as well as on standard synthetic and real-world datasets demonstrate significant gains in physical consistency and monocular dynamic reconstruction quality.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹çº¯æ•°æ®é©±åŠ¨çš„3D Gaussian Splatting (3DGS) éš¾ä»¥æ•æ‰åŠ¨æ€åœºæ™¯ä¸­ç‰©ç†é©±åŠ¨è¿åŠ¨æ¨¡å¼çš„é—®é¢˜ï¼Œæå‡ºäº†Physics-Informed Deformable Gaussian Splatting (PIDG)ã€‚è¯¥æ–¹æ³•å°†æ¯ä¸ªé«˜æ–¯ç²’å­è§†ä¸ºå…·æœ‰æ—¶å˜æœ¬æ„å‚æ•°çš„Lagrangian material pointï¼Œå¹¶é‡‡ç”¨é™æ€-åŠ¨æ€è§£è€¦çš„4Dåˆ†è§£å“ˆå¸Œç¼–ç æ¥é«˜æ•ˆé‡å»ºå‡ ä½•å’Œè¿åŠ¨ã€‚é€šè¿‡å¼•å…¥Cauchy momentum residualä½œä¸ºç‰©ç†çº¦æŸï¼Œæ¨¡å‹èƒ½å¤Ÿé€šè¿‡éšæ—¶é—´æ¼”åŒ–çš„ææ–™åœºç‹¬ç«‹é¢„æµ‹ç²’å­çš„é€Ÿåº¦å’Œæœ¬æ„åº”åŠ›ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜é€šè¿‡åŒ¹é…Lagrangian particle flowä¸ç›¸æœºè¡¥å¿çš„å…‰æµæ¥ç›‘ç£æ•°æ®æ‹Ÿåˆï¼Œä»è€ŒåŠ é€Ÿæ”¶æ•›å¹¶æé«˜æ³›åŒ–èƒ½åŠ›ã€‚åœ¨è‡ªå®šä¹‰ç‰©ç†é©±åŠ¨æ•°æ®é›†åŠæ ‡å‡†åˆæˆå’ŒçœŸå®æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒPIDGåœ¨ç‰©ç†ä¸€è‡´æ€§å’Œå•ç›®åŠ¨æ€é‡å»ºè´¨é‡æ–¹é¢å‡å–å¾—äº†æ˜¾è‘—æå‡ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by AAAI-26",
      "pdf_url": "https://arxiv.org/pdf/2511.06299v3",
      "published_date": "2025-11-09 09:35:03 UTC",
      "updated_date": "2025-11-22 09:19:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T18:59:54.113733+00:00"
    },
    {
      "arxiv_id": "2511.06297v1",
      "title": "Decomate: Leveraging Generative Models for Co-Creative SVG Animation",
      "title_zh": "Decomateï¼šåˆ©ç”¨ç”Ÿæˆå¼æ¨¡å‹è¿›è¡Œ SVG åŠ¨ç”»ååŒåˆ›ä½œ",
      "authors": [
        "Jihyeon Park",
        "Jiyoon Myung",
        "Seone Shin",
        "Jungki Son",
        "Joohyung Han"
      ],
      "abstract": "Designers often encounter friction when animating static SVG graphics, especially when the visual structure does not match the desired level of motion detail. Existing tools typically depend on predefined groupings or require technical expertise, which limits designers' ability to experiment and iterate independently. We present Decomate, a system that enables intuitive SVG animation through natural language. Decomate leverages a multimodal large language model to restructure raw SVGs into semantically meaningful, animation-ready components. Designers can then specify motions for each component via text prompts, after which the system generates corresponding HTML/CSS/JS animations. By supporting iterative refinement through natural language interaction, Decomate integrates generative AI into creative workflows, allowing animation outcomes to be directly shaped by user intent.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è®¾è®¡å¸ˆåœ¨ä¸ºé™æ€SVGå›¾å½¢åˆ¶ä½œåŠ¨ç”»æ—¶é¢ä¸´çš„ç»“æ„ä¸åŒ¹é…å’ŒæŠ€æœ¯é—¨æ§›é«˜çš„é—®é¢˜ï¼Œæå‡ºäº†Decomateç³»ç»Ÿã€‚è¯¥ç³»ç»Ÿåˆ©ç”¨å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹(multimodal large language model)å°†åŸå§‹SVGé‡ç»„ä¸ºå…·æœ‰è¯­ä¹‰æ„ä¹‰ä¸”é€‚åˆåŠ¨ç”»åˆ¶ä½œçš„ç»„ä»¶ï¼Œä»è€Œæ”¯æŒé€šè¿‡è‡ªç„¶è¯­è¨€è¿›è¡Œç›´è§‚çš„SVGåŠ¨ç”»åˆ›ä½œã€‚è®¾è®¡å¸ˆå¯ä»¥é€šè¿‡æ–‡æœ¬æç¤º(text prompts)ä¸ºæ¯ä¸ªç»„ä»¶æŒ‡å®šåŠ¨ä½œï¼Œç³»ç»Ÿéšåä¼šè‡ªåŠ¨ç”Ÿæˆç›¸åº”çš„HTML/CSS/JSåŠ¨ç”»ä»£ç ã€‚Decomateæ”¯æŒé€šè¿‡è‡ªç„¶è¯­è¨€äº¤äº’è¿›è¡Œè¿­ä»£ä¼˜åŒ–ï¼ŒæˆåŠŸå°†ç”Ÿæˆå¼AIé›†æˆåˆ°åˆ›æ„å·¥ä½œæµä¸­ï¼Œç¡®ä¿åŠ¨ç”»æ•ˆæœèƒ½å¤Ÿç›´æ¥åæ˜ ç”¨æˆ·çš„è®¾è®¡æ„å›¾ï¼Œæå¤§åœ°é™ä½äº†åŠ¨ç”»åˆ¶ä½œçš„éš¾åº¦å¹¶æå‡äº†åˆ›ä½œçµæ´»æ€§ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "Accepted at the 1st Workshop on Generative and Protective AI for Content Creation (NeurIPS 2025)",
      "pdf_url": "https://arxiv.org/pdf/2511.06297v1",
      "published_date": "2025-11-09 09:28:51 UTC",
      "updated_date": "2025-11-09 09:28:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T19:00:14.592427+00:00"
    },
    {
      "arxiv_id": "2511.06294v3",
      "title": "Transolver is a Linear Transformer: Revisiting Physics-Attention through the Lens of Linear Attention",
      "title_zh": "Transolver æ˜¯ä¸€ç§çº¿æ€§ Transformerï¼šä»çº¿æ€§æ³¨æ„åŠ›è§†è§’é‡æ–°å®¡è§†ç‰©ç†æ³¨æ„åŠ›",
      "authors": [
        "Wenjie Hu",
        "Sidun Liu",
        "Peng Qiao",
        "Zhenglun Sun",
        "Yong Dou"
      ],
      "abstract": "Recent advances in Transformer-based Neural Operators have enabled significant progress in data-driven solvers for Partial Differential Equations (PDEs). Most current research has focused on reducing the quadratic complexity of attention to address the resulting low training and inference efficiency. Among these works, Transolver stands out as a representative method that introduces Physics-Attention to reduce computational costs. Physics-Attention projects grid points into slices for slice attention, then maps them back through deslicing. However, we observe that Physics-Attention can be reformulated as a special case of linear attention, and that the slice attention may even hurt the model performance. Based on these observations, we argue that its effectiveness primarily arises from the slice and deslice operations rather than interactions between slices. Building on this insight, we propose a two-step transformation to redesign Physics-Attention into a canonical linear attention, which we call Linear Attention Neural Operator (LinearNO). Our method achieves state-of-the-art performance on six standard PDE benchmarks, while reducing the number of parameters by an average of 40.0% and computational cost by 36.2%. Additionally, it delivers superior performance on two challenging, industrial-level datasets: AirfRANS and Shape-Net Car.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŸºäºTransformerçš„ç¥ç»ç®—å­åœ¨æ±‚è§£åå¾®åˆ†æ–¹ç¨‹(PDEs)æ—¶çš„æ•ˆç‡é—®é¢˜ï¼Œé‡æ–°å®¡è§†äº†Transolveræ¨¡å‹åŠå…¶æ ¸å¿ƒçš„Physics-Attentionæœºåˆ¶ã€‚ä½œè€…å‘ç°Physics-Attentionå®é™…ä¸Šæ˜¯çº¿æ€§æ³¨æ„åŠ›(linear attention)çš„ä¸€ç§ç‰¹ä¾‹ï¼Œä¸”å…¶ä¸­çš„slice attentionæ“ä½œç”šè‡³å¯èƒ½é™ä½æ¨¡å‹æ€§èƒ½ã€‚ç ”ç©¶æŒ‡å‡ºTransolverçš„æœ‰æ•ˆæ€§ä¸»è¦æºäºsliceå’Œdesliceæ“ä½œï¼Œè€Œésliceä¹‹é—´çš„äº¤äº’ã€‚åŸºäºè¿™ä¸€å‘ç°ï¼Œä½œè€…é€šè¿‡ä¸¤æ­¥å˜æ¢å°†Physics-Attentioné‡æ–°è®¾è®¡ä¸ºæ ‡å‡†çš„çº¿æ€§æ³¨æ„åŠ›ï¼Œæå‡ºäº†Linear Attention Neural Operator (LinearNO)ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒLinearNOåœ¨å…­ä¸ªæ ‡å‡†PDEåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æœ€å…ˆè¿›(SOTA)çš„æ€§èƒ½ï¼ŒåŒæ—¶å¹³å‡å‡å°‘äº†40.0%çš„å‚æ•°é‡å’Œ36.2%çš„è®¡ç®—æˆæœ¬ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•åœ¨AirfRANSå’ŒShape-Net Carè¿™ä¸¤ä¸ªé«˜éš¾åº¦çš„å·¥ä¸šçº§æ•°æ®é›†ä¸Šä¹Ÿå±•ç°äº†ä¼˜å¼‚çš„è¡¨ç°ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.06294v3",
      "published_date": "2025-11-09 09:12:50 UTC",
      "updated_date": "2026-01-07 06:09:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T19:00:38.379110+00:00"
    },
    {
      "arxiv_id": "2511.06292v2",
      "title": "Synthetic Data-Driven Prompt Tuning for Financial QA over Tables and Documents",
      "title_zh": "é¢å‘è¡¨æ ¼ä¸æ–‡æ¡£é‡‘èé—®ç­”çš„åˆæˆæ•°æ®é©±åŠ¨æç¤ºå¾®è°ƒ",
      "authors": [
        "Yaoning Yu",
        "Kai-Min Chang",
        "Ye Yu",
        "Kai Wei",
        "Haojing Luo",
        "Haohan Wang"
      ],
      "abstract": "Financial documents like earning reports or balance sheets often involve long tables and multi-page reports. Large language models have become a new tool to help numerical reasoning and understanding these documents. However, prompt quality can have a major effect on how well LLMs perform these financial reasoning tasks. Most current methods tune prompts on fixed datasets of financial text or tabular data, which limits their ability to adapt to new question types or document structures, or they involve costly and manually labeled/curated dataset to help build the prompts. We introduce a self-improving prompt framework driven by data-augmented optimization. In this closed-loop process, we generate synthetic financial tables and document excerpts, verify their correctness and robustness, and then update the prompt based on the results. Specifically, our framework combines a synthetic data generator with verifiers and a prompt optimizer, where the generator produces new examples that exposes weaknesses in the current prompt, the verifiers check the validity and robustness of the produced examples, and the optimizer incrementally refines the prompt in response. By iterating these steps in a feedback cycle, our method steadily improves prompt accuracy on financial reasoning tasks without needing external labels. Evaluation on DocMath-Eval benchmark demonstrates that our system achieves higher performance in both accuracy and robustness than standard prompt methods, underscoring the value of incorporating synthetic data generation into prompt learning for financial applications.",
      "tldr_zh": "é’ˆå¯¹é‡‘èæ–‡æ¡£ä¸­åŒ…å«é•¿è¡¨æ ¼å’Œå¤šé¡µæŠ¥å‘Šçš„æ•°å€¼æ¨ç†ä»»åŠ¡ï¼Œè¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§ç”±åˆæˆæ•°æ®é©±åŠ¨çš„è‡ªæˆ‘æ”¹è¿›Prompt Tuningæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æ–¹æ³•ä¾èµ–å›ºå®šæ•°æ®é›†æˆ–æ˜‚è´µäººå·¥æ ‡æ³¨çš„å±€é™æ€§ã€‚è¯¥æ¡†æ¶å»ºç«‹äº†ä¸€ä¸ªé—­ç¯æµç¨‹ï¼Œç»“åˆäº†åˆæˆæ•°æ®ç”Ÿæˆå™¨ã€éªŒè¯å™¨å’Œæç¤ºè¯ä¼˜åŒ–å™¨(Prompt Optimizer)ã€‚å…·ä½“è€Œè¨€ï¼Œç”Ÿæˆå™¨åˆ¶é€ èƒ½å¤Ÿæš´éœ²å½“å‰æç¤ºè¯å¼±ç‚¹çš„åˆæˆé‡‘èè¡¨æ ¼å’Œæ–‡æ¡£ï¼ŒéªŒè¯å™¨æ£€æŸ¥ç”Ÿæˆçš„æœ‰æ•ˆæ€§å’Œé²æ£’æ€§ï¼Œä¼˜åŒ–å™¨åˆ™æ ¹æ®åé¦ˆè¿­ä»£å¾®è°ƒæç¤ºè¯ï¼Œå…¨è¿‡ç¨‹æ— éœ€å¤–éƒ¨æ ‡ç­¾ã€‚åœ¨DocMath-EvalåŸºå‡†ä¸Šçš„è¯„ä¼°æ˜¾ç¤ºï¼Œè¯¥ç³»ç»Ÿåœ¨å‡†ç¡®æ€§å’Œé²æ£’æ€§ä¸Šå‡ä¼˜äºæ ‡å‡†Promptæ–¹æ³•ï¼Œçªæ˜¾äº†å°†åˆæˆæ•°æ®ç”Ÿæˆèå…¥é‡‘èåº”ç”¨æç¤ºè¯å­¦ä¹ çš„é‡è¦ä»·å€¼ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.06292v2",
      "published_date": "2025-11-09 09:07:31 UTC",
      "updated_date": "2025-11-14 05:38:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T19:01:07.068191+00:00"
    },
    {
      "arxiv_id": "2511.06285v3",
      "title": "Exploiting Inter-Session Information with Frequency-enhanced Dual-Path Networks for Sequential Recommendation",
      "title_zh": "åŸºäºé¢‘åŸŸå¢å¼ºåŒè·¯ç½‘ç»œæŒ–æ˜ä¼šè¯é—´ä¿¡æ¯çš„åºåˆ—æ¨è",
      "authors": [
        "Peng He",
        "Yao Liu",
        "Yanglei Gan",
        "Run Lin",
        "Tingting Dai",
        "Qiao Liu",
        "Xuexin Li"
      ],
      "abstract": "Sequential recommendation (SR) aims to predict a user's next item preference by modeling historical interaction sequences. Recent advances often integrate frequency-domain modules to compensate for self-attention's low-pass nature by restoring the high-frequency signals critical for personalized recommendations. Nevertheless, existing frequency-aware solutions process each session in isolation and optimize exclusively with time-domain objectives. Consequently, they overlook cross-session spectral dependencies and fail to enforce alignment between predicted and actual spectral signatures, leaving valuable frequency information under-exploited. To this end, we propose FreqRec, a Frequency-Enhanced Dual-Path Network for sequential Recommendation that jointly captures inter-session and intra-session behaviors via a learnable Frequency-domain Multi-layer Perceptrons. Moreover, FreqRec is optimized under a composite objective that combines cross entropy with a frequency-domain consistency loss, explicitly aligning predicted and true spectral signatures. Extensive experiments on three benchmarks show that FreqRec surpasses strong baselines and remains robust under data sparsity and noisy-log conditions.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°æœ‰çš„é¢‘ç‡æ„ŸçŸ¥åºåˆ—æ¨è(Sequential Recommendation)æ–¹æ³•å¿½ç•¥è·¨ä¼šè¯é¢‘è°±ä¾èµ–ä¸”ä»…ä¼˜åŒ–æ—¶åŸŸç›®æ ‡çš„é—®é¢˜ï¼Œæå‡ºäº†FreqRecï¼Œä¸€ç§é¢‘ç‡å¢å¼ºçš„åŒè·¯å¾„ç½‘ç»œæ¡†æ¶ã€‚è¯¥æ¨¡å‹é€šè¿‡å¯å­¦ä¹ çš„Frequency-domain Multi-layer Perceptronsè”åˆæ•æ‰ä¼šè¯é—´(inter-session)å’Œä¼šè¯å†…(intra-session)çš„ç”¨æˆ·è¡Œä¸ºï¼Œä»è€Œå……åˆ†åˆ©ç”¨è¢«å¿½è§†çš„é¢‘ç‡ä¿¡æ¯ã€‚ä¸ºäº†è§£å†³ç›®æ ‡å¯¹é½é—®é¢˜ï¼ŒFreqRecé‡‡ç”¨äº†ä¸€ç§å¤åˆä¼˜åŒ–ç›®æ ‡ï¼Œå°†äº¤å‰ç†µä¸é¢‘åŸŸä¸€è‡´æ€§æŸå¤±ç›¸ç»“åˆï¼Œæ˜¾å¼åœ°å¯¹é½é¢„æµ‹ä¸çœŸå®çš„é¢‘è°±ç‰¹å¾(spectral signatures)ã€‚åœ¨ä¸‰ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒFreqRecä¸ä»…è¶…è¶Šäº†ç°æœ‰çš„å¼ºåŸºçº¿æ¨¡å‹ï¼Œè€Œä¸”åœ¨æ•°æ®ç¨€ç–å’Œå™ªå£°æ—¥å¿—æ¡ä»¶ä¸‹è¡¨ç°å‡ºä¼˜å¼‚çš„é²æ£’æ€§ã€‚",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "AAAI 2026 (Oral)",
      "pdf_url": "https://arxiv.org/pdf/2511.06285v3",
      "published_date": "2025-11-09 08:39:26 UTC",
      "updated_date": "2025-11-14 02:02:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T19:02:07.165117+00:00"
    },
    {
      "arxiv_id": "2511.06273v1",
      "title": "COTN: A Chaotic Oscillatory Transformer Network for Complex Volatile Systems under Extreme Conditions",
      "title_zh": "COTNï¼šæç«¯æ¡ä»¶ä¸‹å¤æ‚æ³¢åŠ¨ç³»ç»Ÿçš„æ··æ²ŒæŒ¯è¡ Transformer ç½‘ç»œ",
      "authors": [
        "Boyan Tang",
        "Yilong Zeng",
        "Xuanhao Ren",
        "Peng Xiao",
        "Yuhan Zhao",
        "Raymond Lee",
        "Jianghua Wu"
      ],
      "abstract": "Accurate prediction of financial and electricity markets, especially under extreme conditions, remains a significant challenge due to their intrinsic nonlinearity, rapid fluctuations, and chaotic patterns. To address these limitations, we propose the Chaotic Oscillatory Transformer Network (COTN). COTN innovatively combines a Transformer architecture with a novel Lee Oscillator activation function, processed through Max-over-Time pooling and a lambda-gating mechanism. This design is specifically tailored to effectively capture chaotic dynamics and improve responsiveness during periods of heightened volatility, where conventional activation functions (e.g., ReLU, GELU) tend to saturate. Furthermore, COTN incorporates an Autoencoder Self-Regressive (ASR) module to detect and isolate abnormal market patterns, such as sudden price spikes or crashes, thereby preventing corruption of the core prediction process and enhancing robustness. Extensive experiments across electricity spot markets and financial markets demonstrate the practical applicability and resilience of COTN. Our approach outperforms state-of-the-art deep learning models like Informer by up to 17% and traditional statistical methods like GARCH by as much as 40%. These results underscore COTN's effectiveness in navigating real-world market uncertainty and complexity, offering a powerful tool for forecasting highly volatile systems under duress.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†COTNï¼ˆChaotic Oscillatory Transformer Networkï¼‰ï¼Œæ—¨åœ¨è§£å†³é‡‘èå’Œç”µåŠ›å¸‚åœºåœ¨æç«¯æ¡ä»¶ä¸‹çš„é¢„æµ‹éš¾é¢˜ï¼Œç‰¹åˆ«æ˜¯é’ˆå¯¹å…¶å›ºæœ‰çš„éçº¿æ€§å’Œæ··æ²Œæ¨¡å¼ã€‚COTNåˆ›æ–°æ€§åœ°å°†Transformeræ¶æ„ä¸æ–°å‹Lee Oscillatoræ¿€æ´»å‡½æ•°ç›¸ç»“åˆï¼Œå¹¶é€šè¿‡Max-over-Time poolingå’Œlambda-gatingæœºåˆ¶è¿›è¡Œå¤„ç†ï¼Œä»è€Œæœ‰æ•ˆæ•æ‰æ··æ²ŒåŠ¨æ€å¹¶è§£å†³ä¼ ç»Ÿæ¿€æ´»å‡½æ•°åœ¨å‰§çƒˆæ³¢åŠ¨æœŸé—´çš„é¥±å’Œé—®é¢˜ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹å¼•å…¥äº†Autoencoder Self-Regressive (ASR)æ¨¡å—æ¥æ£€æµ‹å’Œéš”ç¦»ä»·æ ¼é£™å‡æˆ–å´©ç›˜ç­‰å¼‚å¸¸å¸‚åœºæ¨¡å¼ï¼Œå¢å¼ºäº†é¢„æµ‹çš„é²æ£’æ€§ã€‚åœ¨ç”µåŠ›ç°è´§å¸‚åœºå’Œé‡‘èå¸‚åœºçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒCOTNçš„è¡¨ç°ä¼˜äºInformerç­‰æœ€å…ˆè¿›çš„æ·±åº¦å­¦ä¹ æ¨¡å‹é«˜è¾¾17%ï¼Œä¼˜äºGARCHç­‰ä¼ ç»Ÿç»Ÿè®¡æ–¹æ³•é«˜è¾¾40%ã€‚è¿™äº›ç»“æœçªæ˜¾äº†COTNåœ¨å¤„ç†ç°å®ä¸–ç•Œå¸‚åœºä¸ç¡®å®šæ€§å’Œå¤æ‚æ€§æ–¹é¢çš„æœ‰æ•ˆæ€§ï¼Œä¸ºæç«¯å‹åŠ›ä¸‹çš„é«˜æ³¢åŠ¨ç³»ç»Ÿé¢„æµ‹æä¾›äº†å¼ºæœ‰åŠ›çš„å·¥å…·ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Submitted to IEEE Transactions on Neural Networks and Learning Systems",
      "pdf_url": "https://arxiv.org/pdf/2511.06273v1",
      "published_date": "2025-11-09 08:17:19 UTC",
      "updated_date": "2025-11-09 08:17:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T19:01:52.580815+00:00"
    },
    {
      "arxiv_id": "2511.06272v1",
      "title": "LaneDiffusion: Improving Centerline Graph Learning via Prior Injected BEV Feature Generation",
      "title_zh": "LaneDiffusionï¼šé€šè¿‡å…ˆéªŒæ³¨å…¥BEVç‰¹å¾ç”Ÿæˆæ”¹è¿›ä¸­å¿ƒçº¿å›¾å­¦ä¹ ",
      "authors": [
        "Zijie Wang",
        "Weiming Zhang",
        "Wei Zhang",
        "Xiao Tan",
        "Hongxing Liu",
        "Yaowei Wang",
        "Guanbin Li"
      ],
      "abstract": "Centerline graphs, crucial for path planning in autonomous driving, are traditionally learned using deterministic methods. However, these methods often lack spatial reasoning and struggle with occluded or invisible centerlines. Generative approaches, despite their potential, remain underexplored in this domain. We introduce LaneDiffusion, a novel generative paradigm for centerline graph learning. LaneDiffusion innovatively employs diffusion models to generate lane centerline priors at the Bird's Eye View (BEV) feature level, instead of directly predicting vectorized centerlines. Our method integrates a Lane Prior Injection Module (LPIM) and a Lane Prior Diffusion Module (LPDM) to effectively construct diffusion targets and manage the diffusion process. Furthermore, vectorized centerlines and topologies are then decoded from these prior-injected BEV features. Extensive evaluations on the nuScenes and Argoverse2 datasets demonstrate that LaneDiffusion significantly outperforms existing methods, achieving improvements of 4.2%, 4.6%, 4.7%, 6.4% and 1.8% on fine-grained point-level metrics (GEO F1, TOPO F1, JTOPO F1, APLS and SDA) and 2.3%, 6.4%, 6.8% and 2.1% on segment-level metrics (IoU, mAP_cf, DET_l and TOP_ll). These results establish state-of-the-art performance in centerline graph learning, offering new insights into generative models for this task.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†LaneDiffusionï¼Œä¸€ç§é’ˆå¯¹è‡ªåŠ¨é©¾é©¶ä¸­ä¸­å¿ƒçº¿å›¾å­¦ä¹ (centerline graph learning)çš„æ–°å‹ç”Ÿæˆå¼èŒƒå¼ï¼Œæ—¨åœ¨è§£å†³ä¼ ç»Ÿç¡®å®šæ€§æ–¹æ³•åœ¨ç©ºé—´æ¨ç†å’Œå¤„ç†é®æŒ¡ä¸­å¿ƒçº¿æ—¶çš„ä¸è¶³ã€‚ä¸åŒäºç›´æ¥é¢„æµ‹çŸ¢é‡åŒ–ä¸­å¿ƒçº¿ï¼ŒLaneDiffusionåˆ›æ–°æ€§åœ°åˆ©ç”¨æ‰©æ•£æ¨¡å‹(diffusion models)åœ¨é¸Ÿç°å›¾(BEV)ç‰¹å¾å±‚é¢ç”Ÿæˆè½¦é“ä¸­å¿ƒçº¿å…ˆéªŒã€‚è¯¥æ–¹æ³•é›†æˆäº†è½¦é“å…ˆéªŒæ³¨å…¥æ¨¡å—(LPIM)å’Œè½¦é“å…ˆéªŒæ‰©æ•£æ¨¡å—(LPDM)ï¼Œä»¥æœ‰æ•ˆæ„å»ºæ‰©æ•£ç›®æ ‡å¹¶ç®¡ç†æ‰©æ•£è¿‡ç¨‹ï¼Œéšåä»è¿™äº›æ³¨å…¥å…ˆéªŒçš„BEVç‰¹å¾ä¸­è§£ç å‡ºçŸ¢é‡åŒ–ä¸­å¿ƒçº¿å’Œæ‹“æ‰‘ç»“æ„ã€‚åœ¨nuSceneså’ŒArgoverse2æ•°æ®é›†ä¸Šçš„å¹¿æ³›è¯„ä¼°æ˜¾ç¤ºï¼ŒLaneDiffusionæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œåœ¨ç»†ç²’åº¦ç‚¹çº§æŒ‡æ ‡ï¼ˆå¦‚GEO F1, TOPO F1ï¼‰å’Œæ®µçº§æŒ‡æ ‡ï¼ˆå¦‚IoU, mAPï¼‰ä¸Šå‡å–å¾—äº†æ˜¾è‘—æå‡ã€‚è¿™äº›ç»“æœç¡®ç«‹äº†è¯¥ä»»åŠ¡çš„æœ€å…ˆè¿›(SOTA)æ€§èƒ½ï¼Œå¹¶ä¸ºç”Ÿæˆå¼æ¨¡å‹åœ¨ä¸­å¿ƒçº¿å›¾å­¦ä¹ ä¸­çš„åº”ç”¨æä¾›äº†æ–°çš„è§è§£ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ICCV 2025",
      "pdf_url": "https://arxiv.org/pdf/2511.06272v1",
      "published_date": "2025-11-09 08:15:58 UTC",
      "updated_date": "2025-11-09 08:15:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T19:02:30.930709+00:00"
    },
    {
      "arxiv_id": "2511.06262v1",
      "title": "GAIA: A General Agency Interaction Architecture for LLM-Human B2B Negotiation & Screening",
      "title_zh": "GAIAï¼šé¢å‘å¤§è¯­è¨€æ¨¡å‹-äººç±»B2Bè°ˆåˆ¤ä¸ç­›é€‰çš„é€šç”¨ä»£ç†äº¤äº’æ¶æ„",
      "authors": [
        "Siming Zhao",
        "Qi Li"
      ],
      "abstract": "Organizations are increasingly exploring delegation of screening and negotiation tasks to AI systems, yet deployment in high-stakes B2B settings is constrained by governance: preventing unauthorized commitments, ensuring sufficient information before bargaining, and maintaining effective human oversight and auditability. Prior work on large language model negotiation largely emphasizes autonomous bargaining between agents and omits practical needs such as staged information gathering, explicit authorization boundaries, and systematic feedback integration. We propose GAIA, a governance-first framework for LLM-human agency in B2B negotiation and screening. GAIA defines three essential roles - Principal (human), Delegate (LLM agent), and Counterparty - with an optional Critic to enhance performance, and organizes interactions through three mechanisms: information-gated progression that separates screening from negotiation; dual feedback integration that combines AI critique with lightweight human corrections; and authorization boundaries with explicit escalation paths. Our contributions are fourfold: (1) a formal governance framework with three coordinated mechanisms and four safety invariants for delegation with bounded authorization; (2) information-gated progression via task-completeness tracking (TCI) and explicit state transitions that separate screening from commitment; (3) dual feedback integration that blends Critic suggestions with human oversight through parallel learning channels; and (4) a hybrid validation blueprint that combines automated protocol metrics with human judgment of outcomes and safety. By bridging theory and practice, GAIA offers a reproducible specification for safe, efficient, and accountable AI delegation that can be instantiated across procurement, real estate, and staffing workflows.",
      "tldr_zh": "è¿™ç¯‡è®ºæ–‡æå‡ºäº†GAIAï¼Œä¸€ç§é’ˆå¯¹LLMä¸äººç±»åä½œè¿›è¡ŒB2Bè°ˆåˆ¤å’Œç­›é€‰çš„é€šç”¨ä»£ç†äº¤äº’æ¶æ„ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰ç ”ç©¶å¿½ç•¥é«˜é£é™©å•†ä¸šåœºæ™¯ä¸­æ²»ç†ã€æˆæƒè¾¹ç•Œå’Œä¿¡æ¯æ”¶é›†éœ€æ±‚çš„é—®é¢˜ã€‚GAIAä½œä¸ºä¸€ä¸ªâ€œæ²»ç†ä¼˜å…ˆâ€çš„æ¡†æ¶ï¼Œå®šä¹‰äº†å§”æ‰˜äºº(Principal)ã€ä»£ç†äºº(Delegate)å’Œäº¤æ˜“å¯¹æ‰‹(Counterparty)ä¸‰ä¸ªæ ¸å¿ƒè§’è‰²ï¼Œå¹¶å¼•å…¥å¯é€‰çš„æ‰¹è¯„è€…(Critic)ä»¥æå‡æ€§èƒ½ã€‚è¯¥æ¶æ„é€šè¿‡ä¸‰ç§æœºåˆ¶ç»„ç»‡äº¤äº’ï¼šåŸºäºä»»åŠ¡å®Œæ•´æ€§è·Ÿè¸ª(TCI)çš„ä¿¡æ¯é—¨æ§æµç¨‹ä»¥ä¸¥æ ¼åˆ†ç¦»ç­›é€‰ä¸è°ˆåˆ¤é˜¶æ®µï¼Œç»“åˆAIæ‰¹è¯„ä¸äººç±»ä¿®æ­£çš„åŒé‡åé¦ˆé›†æˆï¼Œä»¥åŠå…·æœ‰æ˜ç¡®å‡çº§è·¯å¾„çš„æˆæƒè¾¹ç•Œã€‚è®ºæ–‡æå‡ºäº†åŒ…å«å››ä¸ªå®‰å…¨ä¸å˜é‡çš„æ­£å¼æ²»ç†æ¡†æ¶ï¼Œç¡®ä¿äº†ä»£ç†æƒåœ¨æœ‰é™æˆæƒä¸‹çš„å®‰å…¨æ€§ã€‚æ­¤å¤–ï¼ŒGAIAæä¾›äº†ä¸€ä¸ªç»“åˆè‡ªåŠ¨åŒ–åè®®æŒ‡æ ‡ä¸äººç±»åˆ¤æ–­çš„æ··åˆéªŒè¯è“å›¾ï¼Œä¸ºé‡‡è´­ã€æˆ¿åœ°äº§å’Œäººå‘˜é…ç½®ç­‰å·¥ä½œæµä¸­çš„å®‰å…¨ã€é«˜æ•ˆä¸”è´Ÿè´£ä»»çš„AIæˆæƒæä¾›äº†å¯å¤ç°çš„è§„èŒƒã€‚",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.06262v1",
      "published_date": "2025-11-09 07:41:49 UTC",
      "updated_date": "2025-11-09 07:41:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T19:03:01.528222+00:00"
    },
    {
      "arxiv_id": "2511.06260v1",
      "title": "LLM-Guided Reinforcement Learning with Representative Agents for Traffic Modeling",
      "title_zh": "é¢å‘äº¤é€šå»ºæ¨¡çš„LLMå¼•å¯¼ä»£è¡¨æ€§æ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ",
      "authors": [
        "Hanlin Sun",
        "Jiayang Li"
      ],
      "abstract": "Large language models (LLMs) are increasingly used as behavioral proxies for self-interested travelers in agent-based traffic models. Although more flexible and generalizable than conventional models, the practical use of these approaches remains limited by scalability due to the cost of calling one LLM for every traveler. Moreover, it has been found that LLM agents often make opaque choices and produce unstable day-to-day dynamics. To address these challenges, we propose to model each homogeneous traveler group facing the same decision context with a single representative LLM agent who behaves like the population's average, maintaining and updating a mixed strategy over routes that coincides with the group's aggregate flow proportions. Each day, the LLM reviews the travel experience and flags routes with positive reinforcement that they hope to use more often, and an interpretable update rule then converts this judgment into strategy adjustments using a tunable (progressively decaying) step size. The representative-agent design improves scalability, while the separation of reasoning from updating clarifies the decision logic while stabilizing learning. In classic traffic assignment settings, we find that the proposed approach converges rapidly to the user equilibrium. In richer settings with income heterogeneity, multi-criteria costs, and multi-modal choices, the generated dynamics remain stable and interpretable, reproducing plausible behavioral patterns well-documented in psychology and economics, for example, the decoy effect in toll versus non-toll road selection, and higher willingness-to-pay for convenience among higher-income travelers when choosing between driving, transit, and park-and-ride options.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹Large Language Models (LLMs)åœ¨åŸºäºæ™ºèƒ½ä½“çš„äº¤é€šæ¨¡å‹ä¸­é¢ä¸´çš„å¯æ‰©å±•æ€§å—é™ã€å†³ç­–ä¸é€æ˜åŠåŠ¨æ€ä¸ç¨³å®šç­‰æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§åˆ©ç”¨ä»£è¡¨æ€§æ™ºèƒ½ä½“è¿›è¡ŒLLMå¼•å¯¼çš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•ã€‚è¯¥æ–¹æ³•ä¸å†ä¸ºæ¯ä½å‡ºè¡Œè€…å•ç‹¬è°ƒç”¨LLMï¼Œè€Œæ˜¯ä¸ºé¢ä¸´ç›¸åŒå†³ç­–æƒ…å¢ƒçš„åŒè´¨ç¾¤ä½“è®¾å®šå•ä¸ªä»£è¡¨æ€§LLMæ™ºèƒ½ä½“ï¼Œç”±å…¶ç»´æŠ¤å¹¶æ›´æ–°ç¬¦åˆç¾¤ä½“èšåˆæµé‡æ¯”ä¾‹çš„æ··åˆç­–ç•¥ã€‚åœ¨æ¯æ—¥è¿­ä»£ä¸­ï¼ŒLLMè¯„ä¼°å‡ºè¡Œä½“éªŒå¹¶æ ‡è®°æ­£å‘å¼ºåŒ–çš„è·¯çº¿ï¼Œéšåé€šè¿‡å¯è§£é‡Šçš„æ›´æ–°è§„åˆ™å’Œæ¸è¿›è¡°å‡çš„æ­¥é•¿å°†è¿™äº›åˆ¤æ–­è½¬åŒ–ä¸ºç­–ç•¥è°ƒæ•´ã€‚è¿™ç§è®¾è®¡æ˜¾è‘—æå‡äº†å¯æ‰©å±•æ€§ï¼Œå¹¶é€šè¿‡åˆ†ç¦»æ¨ç†ä¸æ›´æ–°è¿‡ç¨‹é˜æ˜äº†å†³ç­–é€»è¾‘å¹¶ç¨³å®šäº†å­¦ä¹ æ•ˆæœã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨ç»å…¸äº¤é€šåˆ†é…è®¾ç½®ä¸‹ï¼Œè¯¥æ–¹æ³•èƒ½è¿…é€Ÿæ”¶æ•›è‡³ç”¨æˆ·å‡è¡¡(user equilibrium)ï¼›åœ¨æ¶‰åŠæ”¶å…¥å¼‚è´¨æ€§ã€å¤šæ ‡å‡†æˆæœ¬åŠå¤šæ¨¡æ€é€‰æ‹©çš„å¤æ‚åœºæ™¯ä¸­ï¼Œæ¨¡å‹ç”Ÿæˆäº†ç¨³å®šä¸”å¯è§£é‡Šçš„åŠ¨æ€ï¼Œå¹¶æˆåŠŸå¤ç°äº†å¦‚è¯±é¥µæ•ˆåº”(decoy effect)åŠä¸åŒæ”¶å…¥ç¾¤ä½“æ”¯ä»˜æ„æ„¿å·®å¼‚ç­‰ç¬¦åˆå¿ƒç†å­¦ä¸ç»æµå­¦çš„è¡Œä¸ºæ¨¡å¼ã€‚",
      "categories": [
        "cs.GT",
        "cs.AI",
        "eess.SY"
      ],
      "primary_category": "cs.GT",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.06260v1",
      "published_date": "2025-11-09 07:36:46 UTC",
      "updated_date": "2025-11-09 07:36:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T19:04:15.783934+00:00"
    },
    {
      "arxiv_id": "2511.06259v1",
      "title": "Breaking the Modality Barrier: Generative Modeling for Accurate Molecule Retrieval from Mass Spectra",
      "title_zh": "çªç ´æ¨¡æ€å£å’ï¼šåŸºäºè´¨è°±å®ç°ç²¾å‡†åˆ†å­æ£€ç´¢çš„ç”Ÿæˆå¼å»ºæ¨¡",
      "authors": [
        "Yiwen Zhang",
        "Keyan Ding",
        "Yihang Wu",
        "Xiang Zhuang",
        "Yi Yang",
        "Qiang Zhang",
        "Huajun Chen"
      ],
      "abstract": "Retrieving molecular structures from tandem mass spectra is a crucial step in rapid compound identification. Existing retrieval methods, such as traditional mass spectral library matching, suffer from limited spectral library coverage, while recent cross-modal representation learning frameworks often encounter modality misalignment, resulting in suboptimal retrieval accuracy and generalization. To address these limitations, we propose GLMR, a Generative Language Model-based Retrieval framework that mitigates the cross-modal misalignment through a two-stage process. In the pre-retrieval stage, a contrastive learning-based model identifies top candidate molecules as contextual priors for the input mass spectrum. In the generative retrieval stage, these candidate molecules are integrated with the input mass spectrum to guide a generative model in producing refined molecular structures, which are then used to re-rank the candidates based on molecular similarity. Experiments on both MassSpecGym and the proposed MassRET-20k dataset demonstrate that GLMR significantly outperforms existing methods, achieving over 40% improvement in top-1 accuracy and exhibiting strong generalizability.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä»ä¸²è”è´¨è°±ä¸­æ£€ç´¢åˆ†å­ç»“æ„æ—¶å­˜åœ¨çš„æ¨¡æ€ä¸å¯¹é½å’Œè°±å›¾åº“è¦†ç›–æœ‰é™ç­‰é—®é¢˜ï¼Œæå‡ºäº†GLMRæ¡†æ¶ã€‚GLMRæ˜¯ä¸€ç§åŸºäºç”Ÿæˆå¼è¯­è¨€æ¨¡å‹çš„æ£€ç´¢æ–¹æ³•ï¼Œé€šè¿‡ä¸¤é˜¶æ®µè¿‡ç¨‹æ¥ç¼“è§£è·¨æ¨¡æ€ä¸å¯¹é½ã€‚åœ¨é¢„æ£€ç´¢é˜¶æ®µï¼Œæ¨¡å‹åˆ©ç”¨å¯¹æ¯”å­¦ä¹ è¯†åˆ«æ½œåœ¨çš„å€™é€‰åˆ†å­ä½œä¸ºä¸Šä¸‹æ–‡å…ˆéªŒï¼›åœ¨ç”Ÿæˆæ£€ç´¢é˜¶æ®µï¼Œç»“åˆè¾“å…¥è´¨è°±å’Œå€™é€‰åˆ†å­å¼•å¯¼ç”Ÿæˆæ¨¡å‹ç”Ÿæˆç²¾ç»†çš„åˆ†å­ç»“æ„ï¼Œè¿›è€ŒåŸºäºåˆ†å­ç›¸ä¼¼åº¦å¯¹å€™é€‰åˆ—è¡¨è¿›è¡Œé‡æ’åºã€‚åœ¨MassSpecGymå’Œæ–°æ„å»ºçš„MassRET-20kæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼ŒGLMRåœ¨Top-1å‡†ç¡®ç‡ä¸Šæ¯”ç°æœ‰æ–¹æ³•æå‡äº†è¶…è¿‡40%ï¼Œå¹¶å±•ç°å‡ºä¼˜å¼‚çš„æ³›åŒ–èƒ½åŠ›ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by AAAI 2026",
      "pdf_url": "https://arxiv.org/pdf/2511.06259v1",
      "published_date": "2025-11-09 07:25:53 UTC",
      "updated_date": "2025-11-09 07:25:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T19:03:51.080364+00:00"
    },
    {
      "arxiv_id": "2511.06252v1",
      "title": "MrCoM: A Meta-Regularized World-Model Generalizing Across Multi-Scenarios",
      "title_zh": "MrCoMï¼šè·¨å¤šåœºæ™¯æ³›åŒ–çš„å…ƒæ­£åˆ™åŒ–ä¸–ç•Œæ¨¡å‹",
      "authors": [
        "Xuantang Xiong",
        "Ni Mu",
        "Runpeng Xie",
        "Senhao Yang",
        "Yaqing Wang",
        "Lexiang Wang",
        "Yao Luan",
        "Siyuan Li",
        "Shuang Xu",
        "Yiqin Yang",
        "Bo Xu"
      ],
      "abstract": "Model-based reinforcement learning (MBRL) is a crucial approach to enhance the generalization capabilities and improve the sample efficiency of RL algorithms. However, current MBRL methods focus primarily on building world models for single tasks and rarely address generalization across different scenarios. Building on the insight that dynamics within the same simulation engine share inherent properties, we attempt to construct a unified world model capable of generalizing across different scenarios, named Meta-Regularized Contextual World-Model (MrCoM). This method first decomposes the latent state space into various components based on the dynamic characteristics, thereby enhancing the accuracy of world-model prediction. Further, MrCoM adopts meta-state regularization to extract unified representation of scenario-relevant information, and meta-value regularization to align world-model optimization with policy learning across diverse scenario objectives. We theoretically analyze the generalization error upper bound of MrCoM in multi-scenario settings. We systematically evaluate our algorithm's generalization ability across diverse scenarios, demonstrating significantly better performance than previous state-of-the-art methods.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç›®å‰åŸºäºæ¨¡å‹çš„å¼ºåŒ–å­¦ä¹ (MBRL)æ–¹æ³•ä¸»è¦å±€é™äºå•ä»»åŠ¡è€Œç¼ºä¹è·¨åœºæ™¯æ³›åŒ–èƒ½åŠ›çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åä¸ºMrCoM (Meta-Regularized Contextual World-Model)çš„ç»Ÿä¸€ä¸–ç•Œæ¨¡å‹ã€‚è¯¥æ–¹æ³•åŸºäºåŒä¸€ä»¿çœŸå¼•æ“å†…åŠ¨åŠ›å­¦å…±äº«å›ºæœ‰å±æ€§çš„è§‚ç‚¹ï¼Œé¦–å…ˆæ ¹æ®åŠ¨åŠ›å­¦ç‰¹å¾å°†æ½œåœ¨çŠ¶æ€ç©ºé—´åˆ†è§£ä¸ºä¸åŒç»„ä»¶ï¼Œä»¥å¢å¼ºä¸–ç•Œæ¨¡å‹é¢„æµ‹çš„å‡†ç¡®æ€§ã€‚è¿›ä¸€æ­¥åœ°ï¼ŒMrCoMé‡‡ç”¨å…ƒçŠ¶æ€æ­£åˆ™åŒ–(meta-state regularization)æå–åœºæ™¯ç›¸å…³ä¿¡æ¯çš„ç»Ÿä¸€è¡¨ç¤ºï¼Œå¹¶åˆ©ç”¨å…ƒä»·å€¼æ­£åˆ™åŒ–(meta-value regularization)å°†ä¸–ç•Œæ¨¡å‹ä¼˜åŒ–ä¸è·¨å¤šæ ·åŒ–åœºæ™¯ç›®æ ‡çš„ç­–ç•¥å­¦ä¹ ç›¸å¯¹é½ã€‚ä½œè€…è¿˜ä»ç†è®ºä¸Šåˆ†æäº†MrCoMåœ¨å¤šåœºæ™¯è®¾ç½®ä¸‹çš„æ³›åŒ–è¯¯å·®ä¸Šç•Œã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥ç®—æ³•åœ¨å¤šç§åœºæ™¯ä¸‹çš„æ³›åŒ–èƒ½åŠ›æ˜¾è‘—ä¼˜äºå…ˆå‰çš„æœ€å…ˆè¿›æ–¹æ³•ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.06252v1",
      "published_date": "2025-11-09 07:01:18 UTC",
      "updated_date": "2025-11-09 07:01:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T19:07:30.034135+00:00"
    },
    {
      "arxiv_id": "2511.06251v1",
      "title": "WebVIA: A Web-based Vision-Language Agentic Framework for Interactive and Verifiable UI-to-Code Generation",
      "title_zh": "WebVIAï¼šé¢å‘äº¤äº’å¼ä¸å¯éªŒè¯ UI åˆ°ä»£ç ç”Ÿæˆçš„åŸºäº Web çš„è§†è§‰è¯­è¨€æ™ºèƒ½ä½“æ¡†æ¶",
      "authors": [
        "Mingde Xu",
        "Zhen Yang",
        "Wenyi Hong",
        "Lihang Pan",
        "Xinyue Fan",
        "Yan Wang",
        "Xiaotao Gu",
        "Bin Xu",
        "Jie Tang"
      ],
      "abstract": "User interface (UI) development requires translating design mockups into functional code, a process that remains repetitive and labor-intensive. While recent Vision-Language Models (VLMs) automate UI-to-Code generation, they generate only static HTML/CSS/JavaScript layouts lacking interactivity. To address this, we propose WebVIA, the first agentic framework for interactive UI-to-Code generation and validation. The framework comprises three components: 1) an exploration agent to capture multi-state UI screenshots; 2) a UI2Code model that generates executable interactive code; 3) a validation module that verifies the interactivity. Experiments demonstrate that WebVIA-Agent achieves more stable and accurate UI exploration than general-purpose agents (e.g., Gemini-2.5-Pro). In addition, our fine-tuned WebVIA-UI2Code models exhibit substantial improvements in generating executable and interactive HTML/CSS/JavaScript code, outperforming their base counterparts across both interactive and static UI2Code benchmarks. Our code and models are available at \\href{https://zheny2751-dotcom.github.io/webvia.github.io/}{\\texttt{https://webvia.github.io}}.",
      "tldr_zh": "é’ˆå¯¹ç°æœ‰çš„è§†è§‰è¯­è¨€æ¨¡å‹(VLMs)åœ¨UIå¼€å‘ä¸­ä»…èƒ½ç”Ÿæˆç¼ºä¹äº¤äº’æ€§çš„é™æ€å¸ƒå±€è¿™ä¸€å±€é™ï¼Œè¯¥ç ”ç©¶æå‡ºäº†WebVIAï¼Œè¿™æ˜¯é¦–ä¸ªç”¨äºäº¤äº’å¼UI-to-Codeç”Ÿæˆå’ŒéªŒè¯çš„æ™ºèƒ½ä½“æ¡†æ¶ã€‚è¯¥æ¡†æ¶ç”±ä¸‰ä¸ªæ ¸å¿ƒç»„ä»¶æ„æˆï¼šè´Ÿè´£æ•æ‰å¤šçŠ¶æ€UIæˆªå›¾çš„æ¢ç´¢æ™ºèƒ½ä½“(exploration agent)ã€ç”Ÿæˆå¯æ‰§è¡Œäº¤äº’å¼ä»£ç çš„UI2Codeæ¨¡å‹ï¼Œä»¥åŠç”¨äºéªŒè¯äº¤äº’æ€§çš„éªŒè¯æ¨¡å—ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒWebVIA-Agentåœ¨UIæ¢ç´¢ä»»åŠ¡ä¸Šæ¯”Gemini-2.5-Proç­‰é€šç”¨æ™ºèƒ½ä½“è¡¨ç°å¾—æ›´åŠ ç¨³å®šå’Œå‡†ç¡®ã€‚æ­¤å¤–ï¼Œå¾®è°ƒåçš„WebVIA-UI2Codeæ¨¡å‹åœ¨ç”Ÿæˆå¯æ‰§è¡Œä¸”å…·æœ‰äº¤äº’æ€§çš„HTML/CSS/JavaScriptä»£ç æ–¹é¢å–å¾—äº†æ˜¾è‘—æå‡ï¼Œåœ¨é™æ€å’Œäº¤äº’å¼UI2CodeåŸºå‡†æµ‹è¯•ä¸­å‡ä¼˜äºåŸºç¡€æ¨¡å‹ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "36 pages, 30 figures",
      "pdf_url": "https://arxiv.org/pdf/2511.06251v1",
      "published_date": "2025-11-09 06:58:52 UTC",
      "updated_date": "2025-11-09 06:58:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T19:07:53.654126+00:00"
    },
    {
      "arxiv_id": "2511.06248v1",
      "title": "Constraint-Informed Active Learning for End-to-End ACOPF Optimization Proxies",
      "title_zh": "é¢å‘ç«¯åˆ°ç«¯ ACOPF ä¼˜åŒ–ä»£ç†çš„çº¦æŸæ„ŸçŸ¥ä¸»åŠ¨å­¦ä¹ ",
      "authors": [
        "Miao Li",
        "Michael Klamkin",
        "Pascal Van Hentenryck",
        "Wenting Li",
        "Russell Bent"
      ],
      "abstract": "This paper studies optimization proxies, machine learning (ML) models trained to efficiently predict optimal solutions for AC Optimal Power Flow (ACOPF) problems. While promising, optimization proxy performance heavily depends on training data quality. To address this limitation, this paper introduces a novel active sampling framework for ACOPF optimization proxies designed to generate realistic and diverse training data. The framework actively explores varied, flexible problem specifications reflecting plausible operational realities. More importantly, the approach uses optimization-specific quantities (active constraint sets) that better capture the salient features of an ACOPF that lead to the optimal solution. Numerical results show superior generalization over existing sampling methods with an equivalent training budget, significantly advancing the state-of-practice for trustworthy ACOPF optimization proxies.",
      "tldr_zh": "è¯¥è®ºæ–‡é’ˆå¯¹äº¤æµæœ€ä¼˜æ½®æµ(AC Optimal Power Flow, ACOPF)é—®é¢˜ï¼Œç ”ç©¶äº†ç”¨äºé«˜æ•ˆé¢„æµ‹æœ€ä¼˜è§£çš„æœºå™¨å­¦ä¹ ä¼˜åŒ–ä»£ç†(optimization proxies)ã€‚ä¸ºäº†è§£å†³ä¼˜åŒ–ä»£ç†æ€§èƒ½é«˜åº¦ä¾èµ–è®­ç»ƒæ•°æ®è´¨é‡çš„å±€é™æ€§ï¼Œä½œè€…æå‡ºäº†ä¸€ç§æ–°é¢–çš„ä¸»åŠ¨é‡‡æ ·æ¡†æ¶ï¼Œæ—¨åœ¨ç”Ÿæˆç¬¦åˆå®é™…æ“ä½œä¸”å…·æœ‰å¤šæ ·æ€§çš„è®­ç»ƒæ•°æ®ã€‚è¯¥æ–¹æ³•ä¸ä»…ä¸»åŠ¨æ¢ç´¢çµæ´»çš„é—®é¢˜è§„èŒƒï¼Œæ›´å…³é”®çš„æ˜¯åˆ©ç”¨äº†ä¼˜åŒ–ç‰¹å®šçš„é‡ï¼Œå³æœ‰æ•ˆçº¦æŸé›†(active constraint sets)ï¼Œæ¥æ•æ‰å†³å®šACOPFæœ€ä¼˜è§£çš„å…³é”®ç‰¹å¾ã€‚æ•°å€¼å®éªŒè¡¨æ˜ï¼Œåœ¨ç›¸åŒçš„è®­ç»ƒé¢„ç®—ä¸‹ï¼Œè¯¥æ¡†æ¶ç›¸æ¯”ç°æœ‰çš„é‡‡æ ·æ–¹æ³•è¡¨ç°å‡ºæ›´ä¼˜è¶Šçš„æ³›åŒ–èƒ½åŠ›ï¼Œæ˜¾è‘—æå‡äº†å¯ä¿¡èµ–ACOPFä¼˜åŒ–ä»£ç†çš„æŠ€æœ¯æ°´å¹³ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "8 PAGES",
      "pdf_url": "https://arxiv.org/pdf/2511.06248v1",
      "published_date": "2025-11-09 06:18:38 UTC",
      "updated_date": "2025-11-09 06:18:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T19:08:18.815997+00:00"
    },
    {
      "arxiv_id": "2511.06240v2",
      "title": "Affordance-Guided Coarse-to-Fine Exploration for Base Placement in Open-Vocabulary Mobile Manipulation",
      "title_zh": "å¼€æ”¾è¯æ±‡ç§»åŠ¨æ“ä½œä¸­å¯ä¾›æ€§å¼•å¯¼çš„ç”±ç²—åˆ°ç»†åŸºåº§å®šä½æ¢ç´¢",
      "authors": [
        "Tzu-Jung Lin",
        "Jia-Fong Yeh",
        "Hung-Ting Su",
        "Chung-Yi Lin",
        "Yi-Ting Chen",
        "Winston H. Hsu"
      ],
      "abstract": "In open-vocabulary mobile manipulation (OVMM), task success often hinges on the selection of an appropriate base placement for the robot. Existing approaches typically navigate to proximity-based regions without considering affordances, resulting in frequent manipulation failures. We propose Affordance-Guided Coarse-to-Fine Exploration, a zero-shot framework for base placement that integrates semantic understanding from vision-language models (VLMs) with geometric feasibility through an iterative optimization process. Our method constructs cross-modal representations, namely Affordance RGB and Obstacle Map+, to align semantics with spatial context. This enables reasoning that extends beyond the egocentric limitations of RGB perception. To ensure interaction is guided by task-relevant affordances, we leverage coarse semantic priors from VLMs to guide the search toward task-relevant regions and refine placements with geometric constraints, thereby reducing the risk of convergence to local optima. Evaluated on five diverse open-vocabulary mobile manipulation tasks, our system achieves an 85% success rate, significantly outperforming classical geometric planners and VLM-based methods. This demonstrates the promise of affordance-aware and multimodal reasoning for generalizable, instruction-conditioned planning in OVMM.",
      "tldr_zh": "é’ˆå¯¹å¼€æ”¾è¯æ±‡ç§»åŠ¨æ“ä½œ(Open-Vocabulary Mobile Manipulation, OVMM)ä¸­å› åŸºåº§ä½ç½®é€‰æ‹©ä¸å½“å¯¼è‡´æ“ä½œå¤±è´¥çš„é—®é¢˜ï¼Œè¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åä¸ºAffordance-Guided Coarse-to-Fine Explorationçš„é›¶æ ·æœ¬æ¡†æ¶ã€‚è¯¥æ–¹æ³•é€šè¿‡è¿­ä»£ä¼˜åŒ–è¿‡ç¨‹ï¼Œå°†è§†è§‰è¯­è¨€æ¨¡å‹(VLMs)çš„è¯­ä¹‰ç†è§£ä¸å‡ ä½•å¯è¡Œæ€§ç›¸ç»“åˆï¼Œæ„å»ºäº†åä¸ºAffordance RGBå’ŒObstacle Map+çš„è·¨æ¨¡æ€è¡¨ç¤ºï¼Œä»¥å¯¹é½è¯­ä¹‰ä¸ç©ºé—´ä¸Šä¸‹æ–‡ã€‚ä¸ºäº†ç¡®ä¿äº¤äº’ç”±ä»»åŠ¡ç›¸å…³çš„å¯ä¾›æ€§(affordances)å¼•å¯¼ï¼Œè¯¥æ¡†æ¶åˆ©ç”¨VLMsçš„ç²—ç²’åº¦è¯­ä¹‰å…ˆéªŒå°†æœç´¢å¼•å¯¼è‡³ç›¸å…³åŒºåŸŸï¼Œå¹¶ç»“åˆå‡ ä½•çº¦æŸç²¾ç»†åŒ–åŸºåº§ä½ç½®ï¼Œä»è€Œé™ä½é™·å…¥å±€éƒ¨æœ€ä¼˜çš„é£é™©ã€‚åœ¨äº”é¡¹å¤šæ ·åŒ–çš„OVMMä»»åŠ¡è¯„ä¼°ä¸­ï¼Œè¯¥ç³»ç»Ÿå®ç°äº†85%çš„æˆåŠŸç‡ï¼Œæ˜¾è‘—ä¼˜äºç»å…¸å‡ ä½•è§„åˆ’å™¨å’ŒåŸºäºVLMçš„æ–¹æ³•ï¼Œå±•ç¤ºäº†å¯ä¾›æ€§æ„ŸçŸ¥å’Œå¤šæ¨¡æ€æ¨ç†åœ¨é€šç”¨æŒ‡ä»¤æ¡ä»¶è§„åˆ’ä¸­çš„æ½œåŠ›ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted to AAAI 2026",
      "pdf_url": "https://arxiv.org/pdf/2511.06240v2",
      "published_date": "2025-11-09 05:52:22 UTC",
      "updated_date": "2026-01-03 01:09:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T19:09:11.917489+00:00"
    },
    {
      "arxiv_id": "2511.06237v1",
      "title": "Mixtures of SubExperts for Large Language Continual Learning",
      "title_zh": "é¢å‘å¤§è¯­è¨€æ¨¡å‹æŒç»­å­¦ä¹ çš„æ··åˆå­ä¸“å®¶",
      "authors": [
        "Haeyong Kang"
      ],
      "abstract": "Adapting Large Language Models (LLMs) to a continuous stream of tasks is a critical yet challenging endeavor. While Parameter-Efficient Fine-Tuning (PEFT) methods have become a standard for this, they face a fundamental dilemma in continual learning. Reusing a single set of PEFT parameters for new tasks often leads to catastrophic forgetting of prior knowledge. Conversely, allocating distinct parameters for each task prevents forgetting but results in a linear growth of the model's size and fails to facilitate knowledge transfer between related tasks. To overcome these limitations, we propose a novel adaptive PEFT method referred to as \\textit{Mixtures of SubExperts (MoSEs)}, a novel continual learning framework designed for minimal forgetting and efficient scalability. MoSEs integrate a sparse Mixture of SubExperts into the transformer layers, governed by a task-specific routing mechanism. This architecture allows the model to isolate and protect knowledge within dedicated SubExperts, thereby minimizing parameter interference and catastrophic forgetting. Crucially, the router can adaptively select and combine previously learned sparse parameters for new tasks, enabling effective knowledge transfer while ensuring that the model's capacity grows sublinearly. We evaluate MoSEs on the comprehensive TRACE benchmark datasets. Our experiments demonstrate that MoSEs significantly outperform conventional continual learning approaches in both knowledge retention and scalability to new tasks, achieving state-of-the-art performance with substantial memory and computational savings.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨è¿ç»­ä»»åŠ¡æµé€‚åº”ä¸­é¢ä¸´çš„ç¾éš¾æ€§é—å¿˜ä¸æ¨¡å‹å‚æ•°çº¿æ€§å¢é•¿çš„å›°å¢ƒï¼ŒæŒ‡å‡ºäº†ç°æœ‰å‚æ•°é«˜æ•ˆå¾®è°ƒ(PEFT)æ–¹æ³•çš„å±€é™æ€§ã€‚ä¸ºäº†å…‹æœè¿™äº›é™åˆ¶ï¼Œä½œè€…æå‡ºäº†ä¸€ç§åä¸ºMixtures of SubExperts (MoSEs)çš„æ–°å‹è‡ªé€‚åº”PEFTæ¡†æ¶ï¼Œæ—¨åœ¨å®ç°æœ€å°åŒ–é—å¿˜å’Œé«˜æ•ˆæ‰©å±•ã€‚MoSEså°†ç¨€ç–çš„SubExpertsé›†æˆåˆ°Transformerå±‚ä¸­ï¼Œå¹¶é€šè¿‡ä»»åŠ¡ç‰¹å®šçš„è·¯ç”±æœºåˆ¶è¿›è¡Œç®¡ç†ï¼Œä»è€Œåœ¨ä¸“ç”¨SubExpertså†…éš”ç¦»å¹¶ä¿æŠ¤çŸ¥è¯†ï¼Œæœ€å°åŒ–å‚æ•°å¹²æ‰°ã€‚åŒæ—¶ï¼Œè¯¥æ¶æ„å…è®¸è·¯ç”±å™¨è‡ªé€‚åº”åœ°é€‰æ‹©å’Œç»„åˆå…ˆå‰å­¦ä¹ çš„ç¨€ç–å‚æ•°ä»¥é€‚åº”æ–°ä»»åŠ¡ï¼Œåœ¨å®ç°æœ‰æ•ˆçŸ¥è¯†è¿ç§»çš„åŒæ—¶ç¡®ä¿æ¨¡å‹å®¹é‡å‘ˆæ¬¡çº¿æ€§å¢é•¿ã€‚åœ¨å…¨é¢çš„TRACEåŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒMoSEsåœ¨çŸ¥è¯†ä¿ç•™å’Œæ–°ä»»åŠ¡æ‰©å±•æ€§æ–¹é¢æ˜¾è‘—ä¼˜äºä¼ ç»Ÿçš„æŒç»­å­¦ä¹ æ–¹æ³•ï¼Œä»¥å¤§å¹…èŠ‚çœçš„å†…å­˜å’Œè®¡ç®—æˆæœ¬å®ç°äº†æœ€å…ˆè¿›(SOTA)çš„æ€§èƒ½ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.06237v1",
      "published_date": "2025-11-09 05:44:45 UTC",
      "updated_date": "2025-11-09 05:44:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T19:09:20.892139+00:00"
    },
    {
      "arxiv_id": "2511.06234v1",
      "title": "Analyzing and Mitigating Negation Artifacts using Data Augmentation for Improving ELECTRA-Small Model Accuracy",
      "title_zh": "åˆ©ç”¨æ•°æ®å¢å¼ºåˆ†æä¸ç¼“è§£å¦å®šä¼ªåƒä»¥æå‡ ELECTRA-Small æ¨¡å‹å‡†ç¡®ç‡",
      "authors": [
        "Mojtaba Noghabaei"
      ],
      "abstract": "Pre-trained models for natural language inference (NLI) often achieve high performance on benchmark datasets by using spurious correlations, or dataset artifacts, rather than understanding language touches such as negation. In this project, we investigate the performance of an ELECTRA-small model fine-tuned on the Stanford Natural Language Inference (SNLI) dataset, focusing on its handling of negation. Through analysis, we identify that the model struggles with correctly classifying examples containing negation. To address this, we augment the training data with contrast sets and adversarial examples emphasizing negation. Our results demonstrate that this targeted data augmentation improves the model's accuracy on negation-containing examples without adversely affecting overall performance, therefore mitigating the identified dataset artifact.",
      "tldr_zh": "æœ¬ç ”ç©¶é’ˆå¯¹è‡ªç„¶è¯­è¨€æ¨ç†(NLI)é¢„è®­ç»ƒæ¨¡å‹å¸¸ä¾èµ–è™šå‡ç›¸å…³æ€§(spurious correlations)è€ŒéçœŸæ­£ç†è§£è¯­è¨€ç»†å¾®å·®åˆ«ï¼ˆå¦‚å¦å®šï¼‰çš„é—®é¢˜è¿›è¡Œäº†æ¢è®¨ã€‚ç ”ç©¶å›¢é˜Ÿé‡ç‚¹åˆ†æäº†åœ¨Stanford Natural Language Inference (SNLI)æ•°æ®é›†ä¸Šå¾®è°ƒçš„ELECTRA-smallæ¨¡å‹ï¼Œç‰¹åˆ«æ˜¯å…¶å¤„ç†å¦å®šçš„èƒ½åŠ›ã€‚åˆ†æå‘ç°ï¼Œè¯¥æ¨¡å‹åœ¨æ­£ç¡®åˆ†ç±»åŒ…å«å¦å®šçš„æ ·æœ¬æ–¹é¢å­˜åœ¨å›°éš¾ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œç ”ç©¶è€…é€šè¿‡å¼•å…¥å¼ºè°ƒå¦å®šçš„å¯¹æ¯”é›†(contrast sets)å’Œå¯¹æŠ—æ€§æ ·æœ¬(adversarial examples)æ¥å¢å¼ºè®­ç»ƒæ•°æ®ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¿™ç§é’ˆå¯¹æ€§çš„æ•°æ®å¢å¼º(data augmentation)ä¸ä»…æé«˜äº†æ¨¡å‹åœ¨åŒ…å«å¦å®šæ ·æœ¬ä¸Šçš„å‡†ç¡®ç‡ï¼Œè€Œä¸”æœªå¯¹æ•´ä½“æ€§èƒ½äº§ç”Ÿè´Ÿé¢å½±å“ï¼Œä»è€Œæœ‰æ•ˆç¼“è§£äº†è¯†åˆ«å‡ºçš„æ•°æ®é›†ä¼ªå½±(dataset artifact)é—®é¢˜ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.06234v1",
      "published_date": "2025-11-09 05:25:46 UTC",
      "updated_date": "2025-11-09 05:25:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T19:09:36.705826+00:00"
    },
    {
      "arxiv_id": "2511.06232v1",
      "title": "Scaling Laws and In-Context Learning: A Unified Theoretical Framework",
      "title_zh": "ç¼©æ”¾å®šå¾‹ä¸ä¸Šä¸‹æ–‡å­¦ä¹ ï¼šç»Ÿä¸€ç†è®ºæ¡†æ¶",
      "authors": [
        "Sushant Mehta",
        "Ishan Gupta"
      ],
      "abstract": "In-context learning (ICL) enables large language models to adapt to new tasks from demonstrations without parameter updates. Despite extensive empirical studies, a principled understanding of ICL emergence at scale remains more elusive. We present a unified theoretical framework connecting scaling laws to ICL emergence in transformers. Our analysis establishes that ICL performance follows power-law relationships with model depth $L$, width $d$, context length $k$, and training data $D$, with exponents determined by task structure. We show that under specific conditions, transformers implement gradient-based metalearning in their forward pass, with an effective learning rate $Î·_{\\text{eff}} = Î˜(1/\\sqrt{Ld})$. We demonstrate sharp phase transitions at critical scales and derive optimal depth-width allocations favoring $L^* \\propto N^{2/3}$, $d^* \\propto N^{1/3}$ for the fixed parameter budget $N = Ld$. Systematic experiments on synthetic tasks validate our predictions, with measured scaling exponents closely matching theory. This work provides both necessary and sufficient conditions for the emergence of ICLs and establishes fundamental computational limits on what transformers can learn in-context.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªç»Ÿä¸€çš„ç†è®ºæ¡†æ¶ï¼Œå°†Scaling Lawsä¸Transformersä¸­In-context learning (ICL)çš„æ¶Œç°è”ç³»èµ·æ¥ï¼Œæ—¨åœ¨è§£å†³ICLåœ¨å¤§è§„æ¨¡æ¨¡å‹ä¸­æ¶Œç°æœºåˆ¶å°šä¸æ˜ç¡®çš„é—®é¢˜ã€‚åˆ†æè¡¨æ˜ï¼ŒICLçš„æ€§èƒ½ä¸æ¨¡å‹æ·±åº¦ã€å®½åº¦ã€ä¸Šä¸‹æ–‡é•¿åº¦å’Œè®­ç»ƒæ•°æ®é‡ä¹‹é—´éµå¾ªå¹‚å¾‹å…³ç³»ï¼Œå…¶æŒ‡æ•°ç”±ä»»åŠ¡ç»“æ„å†³å®šã€‚ç ”ç©¶å‘ç°ï¼Œåœ¨ç‰¹å®šæ¡ä»¶ä¸‹ï¼ŒTransformersåœ¨å‰å‘ä¼ æ’­(forward pass)ä¸­å®ç°äº†åŸºäºæ¢¯åº¦çš„metalearningï¼Œå¹¶æ¨å¯¼å‡ºäº†å…·ä½“çš„æœ‰æ•ˆå­¦ä¹ ç‡ã€‚æ­¤å¤–ï¼Œä½œè€…å±•ç¤ºäº†åœ¨å…³é”®å°ºåº¦ä¸Šå‡ºç°çš„å‰§çƒˆç›¸å˜(phase transitions)ï¼Œå¹¶æ¨å¯¼å‡ºåœ¨å›ºå®šå‚æ•°é¢„ç®—ä¸‹æœ€ä¼˜çš„æ·±åº¦-å®½åº¦åˆ†é…æ–¹æ¡ˆï¼Œå³å€¾å‘äºæ›´æ·±çš„æ¨¡å‹ç»“æ„ã€‚åœ¨åˆæˆä»»åŠ¡ä¸Šçš„ç³»ç»Ÿæ€§å®éªŒéªŒè¯äº†è¿™äº›ç†è®ºé¢„æµ‹ï¼Œæµ‹é‡å¾—åˆ°çš„ç¼©æ”¾æŒ‡æ•°ä¸ç†è®ºé«˜åº¦å»åˆã€‚è¿™é¡¹å·¥ä½œä¸ä»…ä¸ºICLçš„æ¶Œç°æä¾›äº†å……åˆ†å¿…è¦æ¡ä»¶ï¼Œè¿˜ç¡®ç«‹äº†Transformersåœ¨ä¸Šä¸‹æ–‡ä¸­å­¦ä¹ èƒ½åŠ›çš„æ ¹æœ¬è®¡ç®—æé™ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.06232v1",
      "published_date": "2025-11-09 05:19:14 UTC",
      "updated_date": "2025-11-09 05:19:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T19:09:56.865148+00:00"
    },
    {
      "arxiv_id": "2511.06230v1",
      "title": "Overview of CHIP 2025 Shared Task 2: Discharge Medication Recommendation for Metabolic Diseases Based on Chinese Electronic Health Records",
      "title_zh": "CHIP 2025 å…±äº«ä»»åŠ¡ 2 æ¦‚è¿°ï¼šåŸºäºä¸­æ–‡ç”µå­ç—…å†çš„ä»£è°¢æ€§ç–¾ç—…å‡ºé™¢ç”¨è¯æ¨è",
      "authors": [
        "Juntao Li",
        "Haobin Yuan",
        "Ling Luo",
        "Tengxiao Lv",
        "Yan Jiang",
        "Fan Wang",
        "Ping Zhang",
        "Huiyi Lv",
        "Jian Wang",
        "Yuanyuan Sun",
        "Hongfei Lin"
      ],
      "abstract": "Discharge medication recommendation plays a critical role in ensuring treatment continuity, preventing readmission, and improving long-term management for patients with chronic metabolic diseases. This paper present an overview of the CHIP 2025 Shared Task 2 competition, which aimed to develop state-of-the-art approaches for automatically recommending appro-priate discharge medications using real-world Chinese EHR data. For this task, we constructed CDrugRed, a high-quality dataset consisting of 5,894 de-identified hospitalization records from 3,190 patients in China. This task is challenging due to multi-label nature of medication recommendation, het-erogeneous clinical text, and patient-specific variability in treatment plans. A total of 526 teams registered, with 167 and 95 teams submitting valid results to the Phase A and Phase B leaderboards, respectively. The top-performing team achieved the highest overall performance on the final test set, with a Jaccard score of 0.5102, F1 score of 0.6267, demonstrating the potential of advanced large language model (LLM)-based ensemble systems. These re-sults highlight both the promise and remaining challenges of applying LLMs to medication recommendation in Chinese EHRs. The post-evaluation phase remains open at https://tianchi.aliyun.com/competition/entrance/532411/.",
      "tldr_zh": "æœ¬æ–‡ç»¼è¿°äº†CHIP 2025 Shared Task 2ç«èµ›ï¼Œè¯¥ä»»åŠ¡æ—¨åœ¨åˆ©ç”¨ä¸­æ–‡ç”µå­å¥åº·è®°å½•(EHR)å¼€å‘é’ˆå¯¹ä»£è°¢æ€§ç–¾ç—…çš„å‡ºé™¢è¯ç‰©è‡ªåŠ¨æ¨èæ–¹æ³•ã€‚ä¸ºæ­¤ï¼Œç»„ç»‡è€…æ„å»ºäº†é«˜è´¨é‡æ•°æ®é›†CDrugRedï¼Œå…¶ä¸­åŒ…å«æ¥è‡ª3,190åæ‚£è€…çš„5,894æ¡å»æ ‡è¯†åŒ–ä½é™¢è®°å½•ã€‚è¯¥ä»»åŠ¡é¢ä¸´è¯ç‰©æ¨èçš„å¤šæ ‡ç­¾æ€§è´¨ã€å¼‚æ„ä¸´åºŠæ–‡æœ¬ä»¥åŠæ‚£è€…æ²»ç–—æ–¹æ¡ˆä¸ªä½“å·®å¼‚ç­‰æŒ‘æˆ˜ã€‚åœ¨å‚èµ›çš„526æ”¯é˜Ÿä¼ä¸­ï¼Œè¡¨ç°æœ€ä¼˜çš„å›¢é˜Ÿé€šè¿‡é‡‡ç”¨åŸºäºå¤§è¯­è¨€æ¨¡å‹(LLM)çš„é›†æˆç³»ç»Ÿï¼Œåœ¨æœ€ç»ˆæµ‹è¯•é›†ä¸Šå–å¾—äº†0.5102çš„Jaccardåˆ†æ•°å’Œ0.6267çš„F1åˆ†æ•°ã€‚è¿™äº›ç»“æœä¸ä»…å±•ç¤ºäº†å…ˆè¿›LLMç³»ç»Ÿåœ¨ä¸­æ–‡EHRè¯ç‰©æ¨èé¢†åŸŸçš„åº”ç”¨æ½œåŠ›ï¼Œä¹Ÿçªæ˜¾äº†è¯¥é¢†åŸŸå°šå­˜çš„æŠ€æœ¯æŒ‘æˆ˜ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.06230v1",
      "published_date": "2025-11-09 05:11:27 UTC",
      "updated_date": "2025-11-09 05:11:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T19:10:27.913224+00:00"
    },
    {
      "arxiv_id": "2511.06227v1",
      "title": "Assertion-Aware Test Code Summarization with Large Language Models",
      "title_zh": "åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„æ–­è¨€æ„ŸçŸ¥æµ‹è¯•ä»£ç æ‘˜è¦",
      "authors": [
        "Anamul Haque Mollah",
        "Ahmed Aljohani",
        "Hyunsook Do"
      ],
      "abstract": "Unit tests often lack concise summaries that convey test intent, especially in auto-generated or poorly documented codebases. Large Language Models (LLMs) offer a promising solution, but their effectiveness depends heavily on how they are prompted. Unlike generic code summarization, test-code summarization poses distinct challenges because test methods validate expected behavior through assertions rather than implementing functionality. This paper presents a new benchmark of 91 real-world Java test cases paired with developer-written summaries and conducts a controlled ablation study to investigate how test code-related components-such as the method under test (MUT), assertion messages, and assertion semantics-affect the performance of LLM-generated test summaries. We evaluate four code LLMs (Codex, Codestral, DeepSeek, and Qwen-Coder) across seven prompt configurations using n-gram metrics (BLEU, ROUGE-L, METEOR), semantic similarity (BERTScore), and LLM-based evaluation. Results show that prompting with assertion semantics improves summary quality by an average of 0.10 points (2.3%) over full MUT context (4.45 vs. 4.35) while requiring fewer input tokens. Codex and Qwen-Coder achieve the highest alignment with human-written summaries, while DeepSeek underperforms despite high lexical overlap. The replication package is publicly available at https://doi.org/10. 5281/zenodo.17067550",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å•å…ƒæµ‹è¯•ä»£ç ç¼ºä¹ç®€æ˜æ„å›¾æ‘˜è¦çš„é—®é¢˜ï¼Œæ¢è®¨äº†åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹(LLMs)è¿›è¡Œæµ‹è¯•ä»£ç æ‘˜è¦ç”Ÿæˆçš„æœ‰æ•ˆæ€§ã€‚ç”±äºæµ‹è¯•ä»£ç ä¸»è¦é€šè¿‡æ–­è¨€(assertions)éªŒè¯é¢„æœŸè¡Œä¸ºè€Œéå®ç°åŠŸèƒ½ï¼Œè®ºæ–‡æ„å»ºäº†ä¸€ä¸ªåŒ…å«91ä¸ªçœŸå®Javaæµ‹è¯•ç”¨ä¾‹åŠå¼€å‘è€…æ‘˜è¦çš„æ–°åŸºå‡†(benchmark)ï¼Œä»¥è§£å†³è¿™ä¸€ç‹¬ç‰¹æŒ‘æˆ˜ã€‚ä½œè€…é€šè¿‡å—æ§æ¶ˆèç ”ç©¶ï¼Œåˆ†æäº†å¾…æµ‹æ–¹æ³•(MUT)ã€æ–­è¨€æ¶ˆæ¯å’Œæ–­è¨€è¯­ä¹‰ç­‰ç»„ä»¶å¯¹æ‘˜è¦ç”Ÿæˆè´¨é‡çš„å½±å“ï¼Œå¹¶è¯„ä¼°äº†Codexã€Codestralã€DeepSeekå’ŒQwen-Coderå››ç§æ¨¡å‹åœ¨ä¸åŒæç¤ºé…ç½®ä¸‹çš„è¡¨ç°ã€‚ç»“æœæ˜¾ç¤ºï¼Œåˆ©ç”¨æ–­è¨€è¯­ä¹‰(assertion semantics)è¿›è¡Œæç¤ºï¼Œç›¸æ¯”ä½¿ç”¨å®Œæ•´MUTä¸Šä¸‹æ–‡ï¼Œèƒ½ä»¥æ›´å°‘çš„è¾“å…¥æ ‡è®°å°†æ‘˜è¦è´¨é‡å¹³å‡æé«˜2.3%ï¼ˆ0.10åˆ†ï¼‰ã€‚å®éªŒè¡¨æ˜Codexå’ŒQwen-Coderä¸äººç±»ç¼–å†™çš„æ‘˜è¦å¯¹é½åº¦æœ€é«˜ï¼Œè€ŒDeepSeekå°½ç®¡è¯æ±‡é‡å åº¦é«˜ä½†åœ¨è¯­ä¹‰å¯¹é½ä¸Šè¡¨ç°æ¬ ä½³ï¼Œè¯æ˜äº†åŸºäºæ–­è¨€çš„æç¤ºç­–ç•¥åœ¨è‡ªåŠ¨åŒ–æµ‹è¯•æ‘˜è¦ä»»åŠ¡ä¸­çš„ä¼˜è¶Šæ€§ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted for publication at 2nd ACM International Conference on AI-powered Software (AIware 2025)",
      "pdf_url": "https://arxiv.org/pdf/2511.06227v1",
      "published_date": "2025-11-09 04:58:32 UTC",
      "updated_date": "2025-11-09 04:58:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T19:11:14.752155+00:00"
    },
    {
      "arxiv_id": "2511.06226v1",
      "title": "ROAR: Robust Accident Recognition and Anticipation for Autonomous Driving",
      "title_zh": "ROARï¼šé¢å‘è‡ªåŠ¨é©¾é©¶çš„é²æ£’äº‹æ•…è¯†åˆ«ä¸é¢„æµ‹",
      "authors": [
        "Xingcheng Liu",
        "Yanchen Guan",
        "Haicheng Liao",
        "Zhengbing He",
        "Zhenning Li"
      ],
      "abstract": "Accurate accident anticipation is essential for enhancing the safety of autonomous vehicles (AVs). However, existing methods often assume ideal conditions, overlooking challenges such as sensor failures, environmental disturbances, and data imperfections, which can significantly degrade prediction accuracy. Additionally, previous models have not adequately addressed the considerable variability in driver behavior and accident rates across different vehicle types. To overcome these limitations, this study introduces ROAR, a novel approach for accident detection and prediction. ROAR combines Discrete Wavelet Transform (DWT), a self adaptive object aware module, and dynamic focal loss to tackle these challenges. The DWT effectively extracts features from noisy and incomplete data, while the object aware module improves accident prediction by focusing on high-risk vehicles and modeling the spatial temporal relationships among traffic agents. Moreover, dynamic focal loss mitigates the impact of class imbalance between positive and negative samples. Evaluated on three widely used datasets, Dashcam Accident Dataset (DAD), Car Crash Dataset (CCD), and AnAn Accident Detection (A3D), our model consistently outperforms existing baselines in key metrics such as Average Precision (AP) and mean Time to Accident (mTTA). These results demonstrate the model's robustness in real-world conditions, particularly in handling sensor degradation, environmental noise, and imbalanced data distributions. This work offers a promising solution for reliable and accurate accident anticipation in complex traffic environments.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è‡ªåŠ¨é©¾é©¶ä¸­ç°æœ‰çš„äº‹æ•…é¢„æµ‹æ–¹æ³•å¾€å¾€å¿½è§†ä¼ æ„Ÿå™¨æ•…éšœã€ç¯å¢ƒå¹²æ‰°åŠæ•°æ®ç¼ºé™·ç­‰é—®é¢˜ï¼Œæå‡ºäº†åä¸ºROARçš„æ–°å‹äº‹æ•…è¯†åˆ«ä¸é¢„æµ‹æ–¹æ³•ã€‚ROARç»“åˆäº†ç¦»æ•£å°æ³¢å˜æ¢(Discrete Wavelet Transform, DWT)ã€è‡ªé€‚åº”ç‰©ä½“æ„ŸçŸ¥æ¨¡å—ä»¥åŠåŠ¨æ€ç„¦ç‚¹æŸå¤±(dynamic focal loss)æ¥åº”å¯¹ä¸Šè¿°æŒ‘æˆ˜ã€‚å…¶ä¸­ï¼ŒDWTèƒ½æœ‰æ•ˆä»å™ªå£°å’Œä¸å®Œæ•´æ•°æ®ä¸­æå–ç‰¹å¾ï¼Œç‰©ä½“æ„ŸçŸ¥æ¨¡å—é€šè¿‡èšç„¦é«˜é£é™©è½¦è¾†å¹¶å»ºæ¨¡äº¤é€šå‚ä¸è€…é—´çš„æ—¶ç©ºå…³ç³»æ¥æå‡é¢„æµ‹èƒ½åŠ›ï¼Œè€ŒåŠ¨æ€ç„¦ç‚¹æŸå¤±åˆ™ç¼“è§£äº†æ­£è´Ÿæ ·æœ¬é—´çš„ç±»åˆ«ä¸å¹³è¡¡ã€‚åœ¨Dashcam Accident Dataset (DAD)ã€Car Crash Dataset (CCD)å’ŒAnAn Accident Detection (A3D)ä¸‰ä¸ªæ•°æ®é›†ä¸Šçš„è¯„ä¼°è¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨å¹³å‡ç²¾åº¦(AP)å’Œå¹³å‡äº‹æ•…æ—¶é—´(mTTA)ç­‰å…³é”®æŒ‡æ ‡ä¸Šå‡ä¼˜äºç°æœ‰åŸºçº¿æ¨¡å‹ã€‚å®éªŒç»“æœè¯å®äº†ROARåœ¨çœŸå®ä¸–ç•Œæ¡ä»¶ä¸‹ï¼Œç‰¹åˆ«æ˜¯é¢å¯¹ä¼ æ„Ÿå™¨é€€åŒ–å’Œç¯å¢ƒå™ªå£°æ—¶çš„é²æ£’æ€§ï¼Œä¸ºå¤æ‚äº¤é€šç¯å¢ƒä¸‹çš„å¯é äº‹æ•…é¢„æµ‹æä¾›äº†æœ‰æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Published to Accident Analysis and Prevention",
      "pdf_url": "https://arxiv.org/pdf/2511.06226v1",
      "published_date": "2025-11-09 04:55:37 UTC",
      "updated_date": "2025-11-09 04:55:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T19:11:34.361532+00:00"
    },
    {
      "arxiv_id": "2511.06221v1",
      "title": "Tiny Model, Big Logic: Diversity-Driven Optimization Elicits Large-Model Reasoning Ability in VibeThinker-1.5B",
      "title_zh": "å°æ¨¡å‹ï¼Œå¤§é€»è¾‘ï¼šå¤šæ ·æ€§é©±åŠ¨ä¼˜åŒ–æ¿€å‘ VibeThinker-1.5B çš„å¤§æ¨¡å‹æ¨ç†èƒ½åŠ›",
      "authors": [
        "Sen Xu",
        "Yi Zhou",
        "Wei Wang",
        "Jixin Min",
        "Zhibin Yin",
        "Yingwei Dai",
        "Shixi Liu",
        "Lianyu Pang",
        "Yirong Chen",
        "Junlin Zhang"
      ],
      "abstract": "Challenging the prevailing consensus that small models inherently lack robust reasoning, this report introduces VibeThinker-1.5B, a 1.5B-parameter dense model developed via our Spectrum-to-Signal Principle (SSP). This challenges the prevailing approach of scaling model parameters to enhance capabilities, as seen in models like DeepSeek R1 (671B) and Kimi k2 (>1T). The SSP framework first employs a Two-Stage Diversity-Exploring Distillation (SFT) to generate a broad spectrum of solutions, followed by MaxEnt-Guided Policy Optimization (RL) to amplify the correct signal. With a total training cost of only $7,800, VibeThinker-1.5B demonstrates superior reasoning capabilities compared to closed-source models like Magistral Medium and Claude Opus 4, and performs on par with open-source models like GPT OSS-20B Medium. Remarkably, it surpasses the 400x larger DeepSeek R1 on three math benchmarks: AIME24 (80.3 vs. 79.8), AIME25 (74.4 vs. 70.0), and HMMT25 (50.4 vs. 41.7). This is a substantial improvement over its base model (6.7, 4.3, and 0.6, respectively). On LiveCodeBench V6, it scores 51.1, outperforming Magistral Medium's 50.3 and its base model's 0.0. These findings demonstrate that small models can achieve reasoning capabilities comparable to large models, drastically reducing training and inference costs and thereby democratizing advanced AI research.",
      "tldr_zh": "è¯¥ç ”ç©¶æŒ‘æˆ˜äº†å°æ¨¡å‹å¤©ç”Ÿç¼ºä¹å¼ºæ¨ç†èƒ½åŠ›çš„æ™®éå…±è¯†ï¼Œæå‡ºäº†VibeThinker-1.5Bï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºSpectrum-to-Signal Principle (SSP)å¼€å‘çš„1.5Bå‚æ•°ç¨ å¯†æ¨¡å‹ã€‚è¯¥æ¡†æ¶é¦–å…ˆé‡‡ç”¨Two-Stage Diversity-Exploring Distillation (SFT)ç”Ÿæˆå¹¿æ³›çš„è§£ç©ºé—´ï¼Œéšåé€šè¿‡MaxEnt-Guided Policy Optimization (RL)æ¥æ”¾å¤§æ­£ç¡®ä¿¡å·ã€‚å°½ç®¡æ€»è®­ç»ƒæˆæœ¬ä»…ä¸º7,800ç¾å…ƒï¼ŒVibeThinker-1.5Bå±•ç°å‡ºä¼˜äºMagistral Mediumå’ŒClaude Opus 4ç­‰é—­æºæ¨¡å‹çš„æ¨ç†èƒ½åŠ›ï¼Œå¹¶ä¸GPT OSS-20B Mediumè¡¨ç°ç›¸å½“ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œè¯¥æ¨¡å‹åœ¨AIME24ã€AIME25å’ŒHMMT25ä¸‰ä¸ªæ•°å­¦åŸºå‡†æµ‹è¯•ä¸­è¶…è¶Šäº†å‚æ•°é‡å¤§400å€çš„DeepSeek R1ï¼Œä¸”åœ¨LiveCodeBench V6ä¸Šçš„è¡¨ç°æ˜¾è‘—ä¼˜äºå…¶åŸºç¡€æ¨¡å‹ã€‚è¿™äº›å‘ç°è¯æ˜äº†é€šè¿‡ç‰¹å®šä¼˜åŒ–ï¼Œå°æ¨¡å‹èƒ½å¤Ÿå®ç°ä¸å¤§æ¨¡å‹ç›¸å½“çš„æ¨ç†èƒ½åŠ›ï¼Œä»è€Œå¤§å¹…é™ä½è®­ç»ƒä¸æ¨ç†æˆæœ¬ï¼Œæœ‰åŠ©äºæ¨åŠ¨AIç ”ç©¶çš„æ°‘ä¸»åŒ–ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.06221v1",
      "published_date": "2025-11-09 04:37:36 UTC",
      "updated_date": "2025-11-09 04:37:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T19:14:48.887904+00:00"
    },
    {
      "arxiv_id": "2511.06215v1",
      "title": "Explicit Knowledge-Guided In-Context Learning for Early Detection of Alzheimer's Disease",
      "title_zh": "é¢å‘é˜¿å°”èŒ¨æµ·é»˜ç—…æ—©æœŸæ£€æµ‹çš„æ˜¾æ€§çŸ¥è¯†å¼•å¯¼ä¸Šä¸‹æ–‡å­¦ä¹ ",
      "authors": [
        "Puzhen Su",
        "Yongzhu Miao",
        "Chunxi Guo",
        "Jintao Tang",
        "Shasha Li",
        "Ting Wang"
      ],
      "abstract": "Detecting Alzheimer's Disease (AD) from narrative transcripts remains a challenging task for large language models (LLMs), particularly under out-of-distribution (OOD) and data-scarce conditions. While in-context learning (ICL) provides a parameter-efficient alternative to fine-tuning, existing ICL approaches often suffer from task recognition failure, suboptimal demonstration selection, and misalignment between label words and task objectives, issues that are amplified in clinical domains like AD detection. We propose Explicit Knowledge In-Context Learners (EK-ICL), a novel framework that integrates structured explicit knowledge to enhance reasoning stability and task alignment in ICL. EK-ICL incorporates three knowledge components: confidence scores derived from small language models (SLMs) to ground predictions in task-relevant patterns, parsing feature scores to capture structural differences and improve demo selection, and label word replacement to resolve semantic misalignment with LLM priors. In addition, EK-ICL employs a parsing-based retrieval strategy and ensemble prediction to mitigate the effects of semantic homogeneity in AD transcripts. Extensive experiments across three AD datasets demonstrate that EK-ICL significantly outperforms state-of-the-art fine-tuning and ICL baselines. Further analysis reveals that ICL performance in AD detection is highly sensitive to the alignment of label semantics and task-specific context, underscoring the importance of explicit knowledge in clinical reasoning under low-resource conditions.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Explicit Knowledge In-Context Learners (EK-ICL)ï¼Œä¸€ç§ç»“åˆç»“æ„åŒ–æ˜¾å¼çŸ¥è¯†çš„æ–°å‹æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨é˜¿å°”èŒ¨æµ·é»˜ç—…(AD)æ—©æœŸæ£€æµ‹ä¸­é¢ä¸´çš„åˆ†å¸ƒå¤–(OOD)å’Œæ•°æ®ç¨€ç¼ºæŒ‘æˆ˜ã€‚é’ˆå¯¹ç°æœ‰ä¸Šä¸‹æ–‡å­¦ä¹ (ICL)æ–¹æ³•å­˜åœ¨çš„ä»»åŠ¡è¯†åˆ«å¤±è´¥å’Œæ ‡ç­¾é”™ä½é—®é¢˜ï¼ŒEK-ICLæ•´åˆäº†ä¸‰ä¸ªå…³é”®ç»„ä»¶ï¼šæºè‡ªå°è¯­è¨€æ¨¡å‹(SLMs)çš„ç½®ä¿¡åº¦åˆ†æ•°ä»¥é”šå®šé¢„æµ‹ã€ç”¨äºæ”¹è¿›æ¼”ç¤ºé€‰æ‹©çš„è§£æç‰¹å¾åˆ†æ•°ã€ä»¥åŠè§£å†³è¯­ä¹‰é”™ä½çš„æ ‡ç­¾è¯æ›¿æ¢ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶é‡‡ç”¨åŸºäºè§£æçš„æ£€ç´¢ç­–ç•¥å’Œé›†æˆé¢„æµ‹æ¥ç¼“è§£ADæ–‡æœ¬ä¸­çš„è¯­ä¹‰åŒè´¨æ€§å½±å“ã€‚åœ¨ä¸‰ä¸ªADæ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒEK-ICLæ˜¾è‘—ä¼˜äºæœ€å…ˆè¿›çš„å¾®è°ƒå’ŒICLåŸºçº¿æ¨¡å‹ã€‚åˆ†æè¿›ä¸€æ­¥æ­ç¤ºäº†æ ‡ç­¾è¯­ä¹‰ä¸ä»»åŠ¡ç‰¹å®šä¸Šä¸‹æ–‡å¯¹é½çš„é‡è¦æ€§ï¼Œå¼ºè°ƒäº†æ˜¾å¼çŸ¥è¯†åœ¨ä½èµ„æºä¸´åºŠæ¨ç†ä¸­çš„å…³é”®ä½œç”¨ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "This paper was accepted by IEEE BIBM 2025 conference",
      "pdf_url": "https://arxiv.org/pdf/2511.06215v1",
      "published_date": "2025-11-09 04:01:45 UTC",
      "updated_date": "2025-11-09 04:01:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T19:15:11.470182+00:00"
    },
    {
      "arxiv_id": "2511.08626v1",
      "title": "SAMora: Enhancing SAM through Hierarchical Self-Supervised Pre-Training for Medical Images",
      "title_zh": "SAMoraï¼šé€šè¿‡åˆ†å±‚è‡ªç›‘ç£é¢„è®­ç»ƒå¢å¼ºåŒ»å­¦å›¾åƒ SAM",
      "authors": [
        "Shuhang Chen",
        "Hangjie Yuan",
        "Pengwei Liu",
        "Hanxue Gu",
        "Tao Feng",
        "Dong Ni"
      ],
      "abstract": "The Segment Anything Model (SAM) has demonstrated significant potential in medical image segmentation. Yet, its performance is limited when only a small amount of labeled data is available, while there is abundant valuable yet often overlooked hierarchical information in medical data. To address this limitation, we draw inspiration from self-supervised learning and propose SAMora, an innovative framework that captures hierarchical medical knowledge by applying complementary self-supervised learning objectives at the image, patch, and pixel levels. To fully exploit the complementarity of hierarchical knowledge within LoRAs, we introduce HL-Attn, a hierarchical fusion module that integrates multi-scale features while maintaining their distinct characteristics. SAMora is compatible with various SAM variants, including SAM2, SAMed, and H-SAM. Experimental results on the Synapse, LA, and PROMISE12 datasets demonstrate that SAMora outperforms existing SAM variants. It achieves state-of-the-art performance in both few-shot and fully supervised settings while reducing fine-tuning epochs by 90%. The code is available at https://github.com/ShChen233/SAMora.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹Segment Anything Model (SAM)åœ¨ç¼ºä¹æ ‡æ³¨æ•°æ®çš„åŒ»å­¦å›¾åƒåˆ†å‰²ä»»åŠ¡ä¸­è¡¨ç°å—é™çš„é—®é¢˜ï¼Œæå‡ºäº†SAMoraæ¡†æ¶ã€‚å—è‡ªç›‘ç£å­¦ä¹ å¯å‘ï¼ŒSAMoraé€šè¿‡åœ¨å›¾åƒ(image)ã€å›¾å—(patch)å’Œåƒç´ (pixel)å±‚é¢åº”ç”¨äº’è¡¥çš„è‡ªç›‘ç£å­¦ä¹ ç›®æ ‡ï¼Œæœ‰æ•ˆæ•æ‰åŒ»å­¦æ•°æ®ä¸­ä¸°å¯Œçš„å±‚æ¬¡åŒ–çŸ¥è¯†ã€‚ä¸ºäº†å……åˆ†åˆ©ç”¨LoRAsä¸­çš„å±‚æ¬¡åŒ–çŸ¥è¯†äº’è¡¥æ€§ï¼Œç ”ç©¶å¼•å…¥äº†HL-Attnå±‚æ¬¡åŒ–èåˆæ¨¡å—ï¼Œåœ¨ä¿æŒç‰¹å¾ç‹¬ç‰¹æ€§çš„åŒæ—¶æ•´åˆå¤šå°ºåº¦ç‰¹å¾ã€‚è¯¥æ¡†æ¶å…¼å®¹å¤šç§SAMå˜ä½“ï¼ŒåŒ…æ‹¬SAM2ã€SAMedå’ŒH-SAMã€‚åœ¨Synapseã€LAå’ŒPROMISE12æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒSAMoraä¼˜äºç°æœ‰çš„SAMå˜ä½“ï¼Œåœ¨å°‘æ ·æœ¬(few-shot)å’Œå…¨ç›‘ç£è®¾ç½®ä¸‹å‡è¾¾åˆ°äº†æœ€å…ˆè¿›(SOTA)çš„æ€§èƒ½ï¼Œå¹¶å°†å¾®è°ƒæ‰€éœ€çš„epochæ•°é‡å‡å°‘äº†90%ã€‚",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.08626v1",
      "published_date": "2025-11-09 03:54:51 UTC",
      "updated_date": "2025-11-09 03:54:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T19:15:36.690162+00:00"
    },
    {
      "arxiv_id": "2511.06212v1",
      "title": "RAG-targeted Adversarial Attack on LLM-based Threat Detection and Mitigation Framework",
      "title_zh": "é’ˆå¯¹åŸºäº LLM çš„å¨èƒæ£€æµ‹ä¸ç¼“è§£æ¡†æ¶çš„ RAG å®šå‘å¯¹æŠ—æ”»å‡»",
      "authors": [
        "Seif Ikbarieh",
        "Kshitiz Aryal",
        "Maanak Gupta"
      ],
      "abstract": "The rapid expansion of the Internet of Things (IoT) is reshaping communication and operational practices across industries, but it also broadens the attack surface and increases susceptibility to security breaches. Artificial Intelligence has become a valuable solution in securing IoT networks, with Large Language Models (LLMs) enabling automated attack behavior analysis and mitigation suggestion in Network Intrusion Detection Systems (NIDS). Despite advancements, the use of LLMs in such systems further expands the attack surface, putting entire networks at risk by introducing vulnerabilities such as prompt injection and data poisoning. In this work, we attack an LLM-based IoT attack analysis and mitigation framework to test its adversarial robustness. We construct an attack description dataset and use it in a targeted data poisoning attack that applies word-level, meaning-preserving perturbations to corrupt the Retrieval-Augmented Generation (RAG) knowledge base of the framework. We then compare pre-attack and post-attack mitigation responses from the target model, ChatGPT-5 Thinking, to measure the impact of the attack on model performance, using an established evaluation rubric designed for human experts and judge LLMs. Our results show that small perturbations degrade LLM performance by weakening the linkage between observed network traffic features and attack behavior, and by reducing the specificity and practicality of recommended mitigations for resource-constrained devices.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹(LLM)çš„ç‰©è”ç½‘(IoT)å¨èƒæ£€æµ‹ä¸ç¼“è§£æ¡†æ¶ï¼Œæ¢è®¨äº†å…¶å¯¹æŠ—æ€§é²æ£’æ€§é—®é¢˜ã€‚å°½ç®¡LLMåœ¨ç½‘ç»œå…¥ä¾µæ£€æµ‹ç³»ç»Ÿ(NIDS)ä¸­èƒ½æœ‰æ•ˆåˆ†ææ”»å‡»è¡Œä¸ºï¼Œä½†åŒæ—¶ä¹Ÿå¼•å…¥äº†æ•°æ®æŠ•æ¯’ç­‰å®‰å…¨æ¼æ´ã€‚ä½œè€…æ„å»ºäº†ä¸€ä¸ªæ”»å‡»æè¿°æ•°æ®é›†ï¼Œå¹¶å®æ–½äº†ä¸€ç§é’ˆå¯¹æ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)çŸ¥è¯†åº“çš„å®šå‘æ•°æ®æŠ•æ¯’æ”»å‡»ï¼Œé€šè¿‡æ–½åŠ ä¿ç•™è¯­ä¹‰çš„è¯çº§æ‰°åŠ¨æ¥ç ´åç³»ç»Ÿã€‚é€šè¿‡å¯¹æ¯”ç›®æ ‡æ¨¡å‹ChatGPT-5 Thinkingåœ¨æ”»å‡»å‰åçš„ç¼“è§£å“åº”ï¼Œç ”ç©¶å‘ç°å¾®å°çš„æ‰°åŠ¨å³å¯æ˜¾è‘—é™ä½LLMçš„æ€§èƒ½ã€‚å…·ä½“è€Œè¨€ï¼Œè¿™ç§æ”»å‡»å‰Šå¼±äº†è§‚æµ‹åˆ°çš„ç½‘ç»œæµé‡ç‰¹å¾ä¸æ”»å‡»è¡Œä¸ºä¹‹é—´çš„è”ç³»ï¼Œå¹¶é™ä½äº†é’ˆå¯¹èµ„æºå—é™è®¾å¤‡çš„ç¼“è§£å»ºè®®çš„ç‰¹å¼‚æ€§å’Œå®ç”¨æ€§ï¼Œæ­ç¤ºäº†å½“å‰åŸºäºLLMçš„å®‰å…¨æ¡†æ¶é¢ä¸´çš„ä¸¥å³»æŒ‘æˆ˜ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.06212v1",
      "published_date": "2025-11-09 03:50:17 UTC",
      "updated_date": "2025-11-09 03:50:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T19:16:03.177042+00:00"
    },
    {
      "arxiv_id": "2511.06209v3",
      "title": "Efficient Test-Time Scaling of Multi-Step Reasoning by Probing Internal States of Large Language Models",
      "title_zh": "åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹å†…éƒ¨çŠ¶æ€æ¢æµ‹çš„å¤šæ­¥æ¨ç†é«˜æ•ˆæµ‹è¯•æ—¶æ‰©å±•",
      "authors": [
        "Jingwei Ni",
        "Ekaterina Fadeeva",
        "Tianyi Wu",
        "Mubashara Akhtar",
        "Jiaheng Zhang",
        "Elliott Ash",
        "Markus Leippold",
        "Timothy Baldwin",
        "See-Kiong Ng",
        "Artem Shelmanov",
        "Mrinmaya Sachan"
      ],
      "abstract": "LLMs can solve complex tasks by generating long, multi-step reasoning chains. Test-time scaling (TTS) can further improve LLM performance by sampling multiple variants of intermediate reasoning steps, verifying their correctness, and strategically choosing the best steps for continuation. However, existing verification approaches, such as Process Reward Models (PRMs), are computationally expensive, limited to specific domains, and require large-scale human or model-generated annotations. We propose a lightweight alternative for step-level reasoning verification based on probing the internal states of LLMs. We train a transformer-based probe that uses the internal states of the frozen LLM to estimate the credibility of its reasoning steps during generation. Annotation can be generated either by another larger LLM (e.g., DeepSeek-R1) or in a self-supervised manner by the original model itself. The probes are both effective and lightweight, containing fewer than 10M parameters. Across multiple domains, including mathematics, planning, and general knowledge question answering, our probes match or even exceed the performance of PRMs that are up to 810x larger. Our findings suggest that the internal states of LLMs encode their confidence in reasoning processes and can serve as reliable signals for reasoning step verification, offering a promising direction towards scalable and generalizable TTS and introspective LLMs.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å¤šæ­¥æ¨ç†ä»»åŠ¡ï¼Œæå‡ºäº†ä¸€ç§åŸºäºæ¢æµ‹å†…éƒ¨çŠ¶æ€çš„è½»é‡çº§æµ‹è¯•æ—¶æ‰©å±•ï¼ˆTest-Time Scaling, TTSï¼‰æ–¹æ³•ã€‚é’ˆå¯¹ç°æœ‰è¿‡ç¨‹å¥–åŠ±æ¨¡å‹ï¼ˆPRMsï¼‰è®¡ç®—æˆæœ¬é«˜ä¸”ä¾èµ–å¤§è§„æ¨¡æ ‡æ³¨çš„é—®é¢˜ï¼Œä½œè€…è®­ç»ƒäº†ä¸€ä¸ªå‚æ•°é‡å°‘äº10Mçš„Transformeræ¢é’ˆï¼Œåˆ©ç”¨å†»ç»“LLMçš„å†…éƒ¨çŠ¶æ€æ¥å®æ—¶è¯„ä¼°æ¨ç†æ­¥éª¤çš„å¯ä¿¡åº¦ã€‚è¯¥æ¢é’ˆçš„è®­ç»ƒæ•°æ®æ—¢å¯ç”±æ›´å¤§çš„æ¨¡å‹ï¼ˆå¦‚DeepSeek-R1ï¼‰ç”Ÿæˆï¼Œä¹Ÿå¯é€šè¿‡åŸæ¨¡å‹çš„è‡ªç›‘ç£æ–¹å¼è·å–ã€‚åœ¨æ•°å­¦ã€è§„åˆ’å’Œé€šç”¨é—®ç­”ç­‰å¤šä¸ªé¢†åŸŸçš„å®éªŒæ˜¾ç¤ºï¼Œè¯¥è½»é‡çº§æ¢é’ˆçš„æ€§èƒ½åŒ¹é…ç”šè‡³è¶…è¶Šäº†ä½“ç§¯å¤§810å€çš„PRMsã€‚ç ”ç©¶å‘ç°LLMçš„å†…éƒ¨çŠ¶æ€æœ‰æ•ˆç¼–ç äº†æ¨ç†è¿‡ç¨‹çš„ç½®ä¿¡åº¦ï¼Œä¸ºå®ç°é«˜æ•ˆã€é€šç”¨çš„TTSåŠå…·å¤‡å†…çœèƒ½åŠ›çš„LLMæä¾›äº†æ–°çš„æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Preprint under review",
      "pdf_url": "https://arxiv.org/pdf/2511.06209v3",
      "published_date": "2025-11-09 03:38:29 UTC",
      "updated_date": "2026-01-14 10:08:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T19:16:26.906810+00:00"
    },
    {
      "arxiv_id": "2511.06208v2",
      "title": "Resilience Inference for Supply Chains with Hypergraph Neural Network",
      "title_zh": "åŸºäºè¶…å›¾ç¥ç»ç½‘ç»œçš„ä¾›åº”é“¾éŸ§æ€§æ¨æ–­",
      "authors": [
        "Zetian Shen",
        "Hongjun Wang",
        "Jiyuan Chen",
        "Xuan Song"
      ],
      "abstract": "Supply chains are integral to global economic stability, yet disruptions can swiftly propagate through interconnected networks, resulting in substantial economic impacts. Accurate and timely inference of supply chain resilience the capability to maintain core functions during disruptions is crucial for proactive risk mitigation and robust network design. However, existing approaches lack effective mechanisms to infer supply chain resilience without explicit system dynamics and struggle to represent the higher-order, multi-entity dependencies inherent in supply chain networks. These limitations motivate the definition of a novel problem and the development of targeted modeling solutions. To address these challenges, we formalize a novel problem: Supply Chain Resilience Inference (SCRI), defined as predicting supply chain resilience using hypergraph topology and observed inventory trajectories without explicit dynamic equations. To solve this problem, we propose the Supply Chain Resilience Inference Hypergraph Network (SC-RIHN), a novel hypergraph-based model leveraging set-based encoding and hypergraph message passing to capture multi-party firm-product interactions. Comprehensive experiments demonstrate that SC-RIHN significantly outperforms traditional MLP, representative graph neural network variants, and ResInf baselines across synthetic benchmarks, underscoring its potential for practical, early-warning risk assessment in complex supply chain systems.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä¾›åº”é“¾ç½‘ç»œé¢ä¸´çš„ä¸­æ–­é£é™©ï¼Œæå‡ºäº†ä¾›åº”é“¾éŸ§æ€§æ¨æ–­ï¼ˆSCRIï¼‰è¿™ä¸€æ–°é—®é¢˜ï¼Œæ—¨åœ¨åˆ©ç”¨è¶…å›¾æ‹“æ‰‘å’Œè§‚æµ‹åˆ°çš„åº“å­˜è½¨è¿¹ï¼Œåœ¨æ— éœ€æ˜¾å¼åŠ¨åŠ›å­¦æ–¹ç¨‹çš„æƒ…å†µä¸‹é¢„æµ‹ä¾›åº”é“¾éŸ§æ€§ã€‚é’ˆå¯¹ç°æœ‰æ–¹æ³•éš¾ä»¥æ•æ‰é«˜é˜¶å¤šå®ä½“ä¾èµ–å…³ç³»åŠç¼ºä¹æœ‰æ•ˆæ¨æ–­æœºåˆ¶çš„å±€é™æ€§ï¼Œä½œè€…æå‡ºäº†ä¾›åº”é“¾éŸ§æ€§æ¨æ–­è¶…å›¾ç½‘ç»œï¼ˆSC-RIHNï¼‰ã€‚è¯¥æ¨¡å‹åˆ©ç”¨åŸºäºé›†åˆçš„ç¼–ç å’Œè¶…å›¾æ¶ˆæ¯ä¼ é€’æœºåˆ¶ï¼Œæœ‰æ•ˆæ•æ‰äº†å¤šæ–¹ä¼ä¸šä¸äº§å“ä¹‹é—´çš„å¤æ‚äº¤äº’ã€‚ç»¼åˆå®éªŒè¡¨æ˜ï¼ŒSC-RIHNåœ¨åˆæˆåŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—ä¼˜äºä¼ ç»Ÿçš„MLPã€ä»£è¡¨æ€§çš„å›¾ç¥ç»ç½‘ç»œï¼ˆGNNï¼‰å˜ä½“ä»¥åŠResInfåŸºçº¿æ¨¡å‹ã€‚è¿™ä¸€æˆæœè¯æ˜äº†è¯¥æ–¹æ³•åœ¨å¤æ‚ä¾›åº”é“¾ç³»ç»Ÿçš„æ—©æœŸé£é™©è¯„ä¼°å’Œé²æ£’æ€§ç½‘ç»œè®¾è®¡æ–¹é¢å…·æœ‰é‡è¦çš„åº”ç”¨æ½œåŠ›ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.06208v2",
      "published_date": "2025-11-09 03:34:45 UTC",
      "updated_date": "2025-12-04 05:30:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T19:16:45.656238+00:00"
    },
    {
      "arxiv_id": "2511.06197v1",
      "title": "Enhancing Adversarial Robustness of IoT Intrusion Detection via SHAP-Based Attribution Fingerprinting",
      "title_zh": "åŸºäº SHAP å½’å› æŒ‡çº¹å¢å¼ºç‰©è”ç½‘å…¥ä¾µæ£€æµ‹çš„å¯¹æŠ—é²æ£’æ€§",
      "authors": [
        "Dilli Prasad Sharma",
        "Liang Xue",
        "Xiaowei Sun",
        "Xiaodong Lin",
        "Pulei Xiong"
      ],
      "abstract": "The rapid proliferation of Internet of Things (IoT) devices has transformed numerous industries by enabling seamless connectivity and data-driven automation. However, this expansion has also exposed IoT networks to increasingly sophisticated security threats, including adversarial attacks targeting artificial intelligence (AI) and machine learning (ML)-based intrusion detection systems (IDS) to deliberately evade detection, induce misclassification, and systematically undermine the reliability and integrity of security defenses. To address these challenges, we propose a novel adversarial detection model that enhances the robustness of IoT IDS against adversarial attacks through SHapley Additive exPlanations (SHAP)-based fingerprinting. Using SHAP's DeepExplainer, we extract attribution fingerprints from network traffic features, enabling the IDS to reliably distinguish between clean and adversarially perturbed inputs. By capturing subtle attribution patterns, the model becomes more resilient to evasion attempts and adversarial manipulations. We evaluated the model on a standard IoT benchmark dataset, where it significantly outperformed a state-of-the-art method in detecting adversarial attacks. In addition to enhanced robustness, this approach improves model transparency and interpretability, thereby increasing trust in the IDS through explainable AI.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç‰©è”ç½‘(IoT)è®¾å¤‡é¢ä¸´çš„æ—¥ç›Šå¤æ‚çš„å¯¹æŠ—æ€§æ”»å‡»å¨èƒï¼Œæå‡ºäº†ä¸€ç§åŸºäºSHapley Additive exPlanations (SHAP)å½’å› æŒ‡çº¹çš„æ–°å‹å¯¹æŠ—æ€§æ£€æµ‹æ¨¡å‹ï¼Œæ—¨åœ¨å¢å¼ºå…¥ä¾µæ£€æµ‹ç³»ç»Ÿ(IDS)çš„é²æ£’æ€§ã€‚é’ˆå¯¹æ”»å‡»è€…è¯•å›¾é€šè¿‡æ‰°åŠ¨é€ƒé¿AI/MLæ£€æµ‹çš„é—®é¢˜ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨SHAPçš„DeepExplainerä»ç½‘ç»œæµé‡ç‰¹å¾ä¸­æå–å½’å› æŒ‡çº¹ï¼Œä»è€Œæœ‰æ•ˆåŒºåˆ†æ­£å¸¸æµé‡ä¸å¯¹æŠ—æ€§æ ·æœ¬ã€‚é€šè¿‡æ•æ‰ç»†å¾®çš„å½’å› æ¨¡å¼ï¼Œè¯¥æ¨¡å‹æ˜¾è‘—æå‡äº†é˜²å¾¡é€ƒé¿æ”»å‡»å’Œå¯¹æŠ—æ€§æ“çºµçš„èƒ½åŠ›ã€‚åœ¨æ ‡å‡†IoTåŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨æ£€æµ‹å¯¹æŠ—æ€§æ”»å‡»æ–¹é¢çš„è¡¨ç°æ˜¾è‘—ä¼˜äºå½“å‰æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜é€šè¿‡å¯è§£é‡Šäººå·¥æ™ºèƒ½(Explainable AI)å¢å¼ºäº†æ¨¡å‹çš„é€æ˜åº¦ä¸å¯è§£é‡Šæ€§ï¼Œä»è€Œæå‡äº†ç”¨æˆ·å¯¹IDSçš„ä¿¡ä»»åº¦ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.NI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.06197v1",
      "published_date": "2025-11-09 02:56:54 UTC",
      "updated_date": "2025-11-09 02:56:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T19:17:26.119379+00:00"
    },
    {
      "arxiv_id": "2511.06195v1",
      "title": "AI as intermediary in modern-day ritual: An immersive, interactive production of the roller disco musical Xanadu at UCLA",
      "title_zh": "äººå·¥æ™ºèƒ½ä½œä¸ºç°ä»£ä»ªå¼ä¸­çš„ä¸­ä»‹ï¼šUCLA è½®æ»‘è¿ªæ–¯ç§‘éŸ³ä¹å‰§ Xanadu çš„æ²‰æµ¸å¼äº¤äº’åˆ¶ä½œ",
      "authors": [
        "Mira Winick",
        "Naisha Agarwal",
        "Chiheb Boussema",
        "Ingrid Lee",
        "Camilo Vargas",
        "Jeff Burke"
      ],
      "abstract": "Interfaces for contemporary large language, generative media, and perception AI models are often engineered for single user interaction. We investigate ritual as a design scaffold for developing collaborative, multi-user human-AI engagement. We consider the specific case of an immersive staging of the musical Xanadu performed at UCLA in Spring 2025. During a two-week run, over five hundred audience members contributed sketches and jazzercise moves that vision language models translated to virtual scenery elements and from choreographic prompts. This paper discusses four facets of interaction-as-ritual within the show: audience input as offerings that AI transforms into components of the ritual; performers as ritual guides, demonstrating how to interact with technology and sorting audience members into cohorts; AI systems as instruments \"played\" by the humans, in which sensing, generative components, and stagecraft create systems that can be mastered over time; and reciprocity of interaction, in which the show's AI machinery guides human behavior as well as being guided by humans, completing a human-AI feedback loop that visibly reshapes the virtual world. Ritual served as a frame for integrating linear narrative, character identity, music and interaction. The production explored how AI systems can support group creativity and play, addressing a critical gap in prevailing single user AI design paradigms.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å½“å‰å¤§è¯­è¨€æ¨¡å‹å’Œç”Ÿæˆå¼åª’ä½“ä¸»è¦é¢å‘å•ç”¨æˆ·äº¤äº’çš„å±€é™ï¼Œæå‡ºå°†â€œä»ªå¼â€ï¼ˆritualï¼‰ä½œä¸ºè®¾è®¡æ”¯æ¶ï¼Œä»¥å¼€å‘åä½œå¼å¤šç”¨æˆ·äººæœºäº¤äº’ä½“éªŒã€‚é€šè¿‡åˆ†æUCLAä¸Šæ¼”çš„æ²‰æµ¸å¼éŸ³ä¹å‰§ã€ŠXanaduã€‹æ¡ˆä¾‹ï¼Œç ”ç©¶å±•ç¤ºäº†è¶…è¿‡500åè§‚ä¼—å¦‚ä½•é€šè¿‡è‰å›¾å’ŒåŠ¨ä½œå‚ä¸äº’åŠ¨ï¼Œå¹¶ç”±è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVision Language Modelsï¼‰å°†å…¶å®æ—¶è½¬åŒ–ä¸ºè™šæ‹Ÿå¸ƒæ™¯å…ƒç´ ã€‚è®ºæ–‡æ¢è®¨äº†â€œäº¤äº’å³ä»ªå¼â€çš„å››ä¸ªæ ¸å¿ƒå±‚é¢ï¼šå°†è§‚ä¼—è¾“å…¥è§†ä¸ºä¾›å“ã€è¡¨æ¼”è€…ä½œä¸ºä»ªå¼å‘å¯¼ã€AIç³»ç»Ÿä½œä¸ºå¯è¢«æŒæ¡çš„ä¹å™¨ï¼Œä»¥åŠäººæœºä¹‹é—´çš„äº’æƒ åé¦ˆå¾ªç¯ã€‚è¿™ç§è®¾è®¡ä¸ä»…é€šè¿‡ä»ªå¼æ¡†æ¶æ•´åˆäº†å™äº‹ä¸äº’åŠ¨ï¼Œè¿˜éªŒè¯äº†AIç³»ç»Ÿæ”¯æŒç¾¤ä½“åˆ›é€ åŠ›å’Œæ¸¸æˆçš„èƒ½åŠ›ï¼Œæœ‰æ•ˆå¼¥è¡¥äº†ç°æœ‰å•ç”¨æˆ·AIè®¾è®¡èŒƒå¼çš„ç©ºç™½ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.06195v1",
      "published_date": "2025-11-09 02:45:19 UTC",
      "updated_date": "2025-11-09 02:45:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T19:18:03.536650+00:00"
    },
    {
      "arxiv_id": "2511.06185v1",
      "title": "Dataforge: A Data Agent Platform for Autonomous Data Engineering",
      "title_zh": "Dataforgeï¼šé¢å‘è‡ªä¸»æ•°æ®å·¥ç¨‹çš„æ•°æ®æ™ºèƒ½ä½“å¹³å°",
      "authors": [
        "Xinyuan Wang",
        "Yanjie Fu"
      ],
      "abstract": "The growing demand for AI applications in fields such as materials discovery, molecular modeling, and climate science has made data preparation an important but labor-intensive step. Raw data from diverse sources must be cleaned, normalized, and transformed to become AI-ready, while effective feature transformation and selection are essential for efficient training and inference. To address the challenges of scalability and expertise dependence, we present Data Agent, a fully autonomous system specialized for tabular data. Leveraging large language model (LLM) reasoning and grounded validation, Data Agent automatically performs data cleaning, hierarchical routing, and feature-level optimization through dual feedback loops. It embodies three core principles: automatic, safe, and non-expert friendly, which ensure end-to-end reliability without human supervision. This demo showcases the first practical realization of an autonomous Data Agent, illustrating how raw data can be transformed \"From Data to Better Data.\"",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Dataforgeå¹³å°ä¸­çš„Data Agentï¼Œè¿™æ˜¯ä¸€ä¸ªä¸“ä¸ºè¡¨æ ¼æ•°æ®è®¾è®¡çš„å…¨è‡ªåŠ¨ç³»ç»Ÿï¼Œæ—¨åœ¨è§£å†³AIåº”ç”¨ä¸­æ•°æ®å‡†å¤‡è¿‡ç¨‹è€—æ—¶ä¸”é«˜åº¦ä¾èµ–ä¸“å®¶ç»éªŒçš„é—®é¢˜ã€‚åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹(LLM)çš„æ¨ç†èƒ½åŠ›å’ŒåŸºäºäº‹å®çš„éªŒè¯(grounded validation)ï¼ŒData Agenté€šè¿‡åŒé‡åé¦ˆå¾ªç¯è‡ªåŠ¨æ‰§è¡Œæ•°æ®æ¸…æ´—ã€åˆ†å±‚è·¯ç”±ä»¥åŠç‰¹å¾çº§ä¼˜åŒ–ã€‚è¯¥ç³»ç»Ÿéµå¾ªè‡ªåŠ¨ã€å®‰å…¨å’Œéä¸“å®¶å‹å¥½ä¸‰å¤§æ ¸å¿ƒåŸåˆ™ï¼Œèƒ½å¤Ÿåœ¨æ— éœ€äººå·¥ç›‘ç£çš„æƒ…å†µä¸‹ç¡®ä¿ç«¯åˆ°ç«¯çš„å¯é æ€§ã€‚ä½œä¸ºé¦–ä¸ªè‡ªä¸»Data Agentçš„å®é™…åº”ç”¨å±•ç¤ºï¼Œè¯¥ç ”ç©¶è¯æ˜äº†å¦‚ä½•å°†åŸå§‹æ•°æ®è½¬åŒ–ä¸ºâ€œæ›´å¥½çš„æ•°æ®â€ï¼Œæœ‰æ•ˆåº”å¯¹äº†æ•°æ®å·¥ç¨‹ä¸­çš„å¯æ‰©å±•æ€§æŒ‘æˆ˜ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.06185v1",
      "published_date": "2025-11-09 01:58:13 UTC",
      "updated_date": "2025-11-09 01:58:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T19:18:24.580096+00:00"
    },
    {
      "arxiv_id": "2511.06179v1",
      "title": "MemoriesDB: A Temporal-Semantic-Relational Database for Long-Term Agent Memory / Modeling Experience as a Graph of Temporal-Semantic Surfaces",
      "title_zh": "MemoriesDBï¼šé¢å‘æ™ºèƒ½ä½“é•¿æœŸè®°å¿†çš„æ—¶é—´-è¯­ä¹‰-å…³ç³»æ•°æ®åº“ / å°†ç»éªŒå»ºæ¨¡ä¸ºæ—¶é—´-è¯­ä¹‰æ›²é¢å›¾",
      "authors": [
        "Joel Ward"
      ],
      "abstract": "We introduce MemoriesDB, a unified data architecture designed to avoid decoherence across time, meaning, and relation in long-term computational memory. Each memory is a time-semantic-relational entity-a structure that simultaneously encodes when an event occurred, what it means, and how it connects to other events. Built initially atop PostgreSQL with pgvector extensions, MemoriesDB combines the properties of a time-series datastore, a vector database, and a graph system within a single append-only schema. Each memory is represented as a vertex uniquely labeled by its microsecond timestamp and accompanied by low- and high-dimensional normalized embeddings that capture semantic context. Directed edges between memories form labeled relations with per-edge metadata, enabling multiple contextual links between the same vertices. Together these constructs form a time-indexed stack of temporal-semantic surfaces, where edges project as directional arrows in a 1+1-dimensional similarity field, tracing the evolution of meaning through time while maintaining cross-temporal coherence. This formulation supports efficient time-bounded retrieval, hybrid semantic search, and lightweight structural reasoning in a single query path. A working prototype demonstrates scalable recall and contextual reinforcement using standard relational infrastructure, and we discuss extensions toward a columnar backend, distributed clustering, and emergent topic modeling.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†MemoriesDBï¼Œä¸€ç§æ—¨åœ¨è§£å†³é•¿æœŸè®¡ç®—è®°å¿†ä¸­æ—¶é—´ã€è¯­ä¹‰å’Œå…³ç³»å»ç›¸å¹²é—®é¢˜çš„ç»Ÿä¸€æ•°æ®æ¶æ„ã€‚MemoriesDBæœ€åˆåŸºäºPostgreSQLå’Œpgvectoræ‰©å±•æ„å»ºï¼Œåœ¨ä¸€ä¸ªä»…è¿½åŠ ï¼ˆappend-onlyï¼‰çš„æ¨¡å¼ä¸­èåˆäº†æ—¶é—´åºåˆ—æ•°æ®å­˜å‚¨ã€å‘é‡æ•°æ®åº“å’Œå›¾ç³»ç»Ÿçš„ç‰¹æ€§ã€‚åœ¨è¯¥æ¶æ„ä¸­ï¼Œæ¯ä¸ªè®°å¿†è¢«è¡¨ç¤ºä¸ºä¸€ä¸ªå¸¦æœ‰å¾®ç§’çº§æ—¶é—´æˆ³å’Œå½’ä¸€åŒ–åµŒå…¥çš„é¡¶ç‚¹ï¼Œä»¥æ•æ‰è¯­ä¹‰ä¸Šä¸‹æ–‡ï¼Œå¹¶é€šè¿‡å¸¦æœ‰å…ƒæ•°æ®çš„æœ‰å‘è¾¹å½¢æˆæ ‡è®°å…³ç³»ã€‚è¿™äº›ç»“æ„å…±åŒæ„æˆäº†æŒ‰æ—¶é—´ç´¢å¼•çš„æ—¶é—´-è¯­ä¹‰è¡¨é¢ï¼ˆtemporal-semantic surfacesï¼‰å †æ ˆï¼Œåœ¨ä¿æŒè·¨æ—¶é—´è¿è´¯æ€§çš„åŒæ—¶è¿½è¸ªæ„ä¹‰çš„æ¼”å˜ã€‚è¿™ç§è®¾è®¡æ”¯æŒåœ¨å•ä¸€æŸ¥è¯¢è·¯å¾„ä¸­è¿›è¡Œé«˜æ•ˆçš„æ—¶é—´é™åˆ¶æ£€ç´¢ã€æ··åˆè¯­ä¹‰æœç´¢å’Œè½»é‡çº§ç»“æ„æ¨ç†ã€‚åŸå‹ç³»ç»Ÿå±•ç¤ºäº†åˆ©ç”¨æ ‡å‡†å…³ç³»åŸºç¡€è®¾æ–½å®ç°çš„å¯æ‰©å±•å¬å›å’Œä¸Šä¸‹æ–‡å¼ºåŒ–èƒ½åŠ›ï¼Œä¸ºæ™ºèƒ½ä½“æä¾›äº†å…·å¤‡æ—¶é—´æ¼”å˜å’Œç»“æ„æ¨ç†èƒ½åŠ›çš„é•¿æœŸè®°å¿†è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.DB",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.06179v1",
      "published_date": "2025-11-09 01:41:55 UTC",
      "updated_date": "2025-11-09 01:41:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T19:18:49.911076+00:00"
    },
    {
      "arxiv_id": "2511.06175v1",
      "title": "CSP4SDG: Constraint and Information-Theory Based Role Identification in Social Deduction Games with LLM-Enhanced Inference",
      "title_zh": "CSP4SDGï¼šç¤¾äº¤æ¼”ç»æ¸¸æˆä¸­åŸºäºçº¦æŸã€ä¿¡æ¯è®ºä¸LLMå¢å¼ºæ¨ç†çš„è§’è‰²è¯†åˆ«",
      "authors": [
        "Kaijie Xu",
        "Fandi Meng",
        "Clark Verbrugge",
        "Simon Lucas"
      ],
      "abstract": "In Social Deduction Games (SDGs) such as Avalon, Mafia, and Werewolf, players conceal their identities and deliberately mislead others, making hidden-role inference a central and demanding task. Accurate role identification, which forms the basis of an agent's belief state, is therefore the keystone for both human and AI performance. We introduce CSP4SDG, a probabilistic, constraint-satisfaction framework that analyses gameplay objectively. Game events and dialogue are mapped to four linguistically-agnostic constraint classes-evidence, phenomena, assertions, and hypotheses. Hard constraints prune impossible role assignments, while weighted soft constraints score the remainder; information-gain weighting links each hypothesis to its expected value under entropy reduction, and a simple closed-form scoring rule guarantees that truthful assertions converge to classical hard logic with minimum error. The resulting posterior over roles is fully interpretable and updates in real time. Experiments on three public datasets show that CSP4SDG (i) outperforms LLM-based baselines in every inference scenario, and (ii) boosts LLMs when supplied as an auxiliary \"reasoning tool.\" Our study validates that principled probabilistic reasoning with information theory is a scalable alternative-or complement-to heavy-weight neural models for SDGs.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶é’ˆå¯¹ç¤¾äº¤æ¼”ç»æ¸¸æˆ(Social Deduction Games, SDGs)å¦‚é˜¿ç“¦éš†ã€ç‹¼äººæ€ä¸­éšè—è§’è‰²æ¨ç†çš„éš¾é¢˜ï¼Œæå‡ºäº†CSP4SDGï¼Œä¸€ç§åŸºäºæ¦‚ç‡å’Œçº¦æŸæ»¡è¶³çš„æ¡†æ¶ã€‚è¯¥æ–¹æ³•å®¢è§‚åˆ†ææ¸¸æˆè¿‡ç¨‹ï¼Œå°†äº‹ä»¶å’Œå¯¹è¯æ˜ å°„ä¸ºè¯æ®ã€ç°è±¡ã€æ–­è¨€å’Œå‡è®¾å››ç±»è¯­è¨€æ— å…³çš„çº¦æŸï¼Œåˆ©ç”¨ç¡¬çº¦æŸæ’é™¤ä¸å¯èƒ½çš„è§’è‰²åˆ†é…ï¼Œå¹¶é€šè¿‡åŠ æƒè½¯çº¦æŸå¯¹å‰©ä½™å¯èƒ½æ€§è¿›è¡Œè¯„åˆ†ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶ç»“åˆäº†åŸºäºç†µå‡å°‘çš„ä¿¡æ¯å¢ç›Š(Information-gain)åŠ æƒå’Œé—­å¼è¯„åˆ†è§„åˆ™ï¼Œç¡®ä¿çœŸå®æ–­è¨€èƒ½æ”¶æ•›è‡³ç»å…¸é€»è¾‘ï¼Œå®ç°äº†å®Œå…¨å¯è§£é‡Šä¸”å®æ—¶æ›´æ–°çš„è§’è‰²åéªŒæ¦‚ç‡ã€‚åœ¨ä¸‰ä¸ªå…¬å…±æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒCSP4SDGä¸ä»…åœ¨æ‰€æœ‰æ¨ç†åœºæ™¯ä¸­ä¼˜äºåŸºäºå¤§è¯­è¨€æ¨¡å‹(LLM)çš„åŸºçº¿ï¼Œè¿˜èƒ½ä½œä¸ºè¾…åŠ©æ¨ç†å·¥å…·æ˜¾è‘—æå‡LLMçš„è¡¨ç°ã€‚è¯¥ç ”ç©¶è¯å®äº†ç»“åˆä¿¡æ¯è®ºçš„åŸåˆ™æ€§æ¦‚ç‡æ¨ç†æ˜¯å¤„ç†SDGsä»»åŠ¡æ—¶ï¼Œç›¸å¯¹äºé‡å‹ç¥ç»ç½‘ç»œæ¨¡å‹çš„ä¸€ç§å¯æ‰©å±•æ›¿ä»£æ–¹æ¡ˆæˆ–è¡¥å……ã€‚",
      "categories": [
        "cs.AI",
        "cs.GT"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.06175v1",
      "published_date": "2025-11-09 01:20:18 UTC",
      "updated_date": "2025-11-09 01:20:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T19:22:17.214303+00:00"
    },
    {
      "arxiv_id": "2511.06174v1",
      "title": "LUT-LLM: Efficient Large Language Model Inference with Memory-based Computations on FPGAs",
      "title_zh": "LUT-LLMï¼šFPGA ä¸ŠåŸºäºå­˜å‚¨è®¡ç®—çš„é«˜æ•ˆå¤§è¯­è¨€æ¨¡å‹æ¨ç†",
      "authors": [
        "Zifan He",
        "Shengyu Ye",
        "Rui Ma",
        "Yang Wang",
        "Jason Cong"
      ],
      "abstract": "The rapid progress of large language models (LLMs) has advanced numerous applications, yet efficient single-batch inference remains vital for on-device intelligence. While FPGAs offer fine-grained data control and high energy efficiency, recent GPU optimizations have narrowed their advantage, especially under arithmetic-based computation. To overcome this, we leverage FPGAs' abundant on-chip memory to shift LLM inference from arithmetic- to memory-based computation through table lookups. We present LUT-LLM, the first FPGA accelerator enabling 1B+ LLM inference via vector-quantized memory operations. Our analysis identifies activation-weight co-quantization as the most effective scheme, supported by (1) bandwidth-aware parallel centroid search, (2) efficient 2D table lookups, and (3) a spatial-temporal hybrid design minimizing data caching. Implemented on an AMD V80 FPGA for a customized Qwen 3 1.7B model, LUT-LLM achieves 1.66x lower latency than AMD MI210 and 1.72x higher energy efficiency than NVIDIA A100, scaling to 32B models with 2.16x efficiency gain over A100.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹(LLM)åœ¨ç«¯ä¾§è®¾å¤‡ä¸Šçš„é«˜æ•ˆæ¨ç†éœ€æ±‚ï¼Œæå‡ºäº†LUT-LLMï¼Œè¿™æ˜¯é¦–ä¸ªé€šè¿‡çŸ¢é‡é‡åŒ–å†…å­˜æ“ä½œæ”¯æŒ10äº¿å‚æ•°ä»¥ä¸ŠLLMæ¨ç†çš„FPGAåŠ é€Ÿå™¨ã€‚ä¸ºäº†å…‹æœGPUåœ¨ç®—æœ¯è®¡ç®—ä¸Šçš„ç«äº‰ä¼˜åŠ¿ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨FPGAä¸°å¯Œçš„ç‰‡ä¸Šå†…å­˜ï¼Œé€šè¿‡æŸ¥è¡¨æ³•(table lookups)å°†æ¨ç†è¿‡ç¨‹ä»ä¼ ç»Ÿçš„ç®—æœ¯è®¡ç®—è½¬å˜ä¸ºåŸºäºå†…å­˜çš„è®¡ç®—ã€‚ç ”ç©¶å›¢é˜Ÿç¡®å®šäº†æ¿€æ´»-æƒé‡è”åˆé‡åŒ–(activation-weight co-quantization)ä¸ºæœ€æœ‰æ•ˆæ–¹æ¡ˆï¼Œå¹¶è®¾è®¡äº†å¸¦å®½æ„ŸçŸ¥çš„å¹¶è¡Œè´¨å¿ƒæœç´¢ã€é«˜æ•ˆ2DæŸ¥è¡¨ä»¥åŠæœ€å°åŒ–æ•°æ®ç¼“å­˜çš„æ—¶ç©ºæ··åˆæ¶æ„æ¥æ”¯æŒè¯¥æ–¹æ¡ˆã€‚åœ¨AMD V80 FPGAä¸Šè¿è¡Œå®šåˆ¶ç‰ˆQwen 3 1.7Bæ¨¡å‹çš„å®éªŒæ˜¾ç¤ºï¼ŒLUT-LLMçš„å»¶è¿Ÿæ¯”AMD MI210é™ä½äº†1.66å€ï¼Œèƒ½æ•ˆæ¯”NVIDIA A100æé«˜äº†1.72å€ã€‚æ­¤å¤–ï¼Œè¯¥æ¶æ„åœ¨æ‰©å±•è‡³32Bæ¨¡å‹æ—¶ï¼Œç›¸æ¯”A100å®ç°äº†2.16å€çš„èƒ½æ•ˆæå‡ï¼Œè¯æ˜äº†è¿™ç§åŸºäºå†…å­˜è®¡ç®—çš„æ–¹æ³•åœ¨æå‡ç¡¬ä»¶æ•ˆç‡æ–¹é¢çš„æ˜¾è‘—æ½œåŠ›ã€‚",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "primary_category": "cs.AR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.06174v1",
      "published_date": "2025-11-09 01:17:08 UTC",
      "updated_date": "2025-11-09 01:17:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T19:22:32.719954+00:00"
    },
    {
      "arxiv_id": "2511.08625v2",
      "title": "Cross-Field Interface-Aware Neural Operators for Multiphase Flow Simulation",
      "title_zh": "é¢å‘å¤šç›¸æµæ¨¡æ‹Ÿçš„è·¨åœºç•Œé¢æ„ŸçŸ¥ç¥ç»ç®—å­",
      "authors": [
        "Zhenzhong Wang",
        "Xin Zhang",
        "Jun Liao",
        "Min Jiang"
      ],
      "abstract": "Multiphase flow simulation is critical in science and engineering but incurs high computational costs due to complex field discontinuities and the need for high-resolution numerical meshes. While Neural Operators (NOs) offer an efficient alternative for solving Partial Differential Equations (PDEs), they struggle with two core challenges unique to multiphase systems: spectral bias caused by spatial heterogeneity at phase interfaces, and the persistent scarcity of expensive, high-resolution field data. This work introduces the Interface Information Aware Neural Operator (IANO), a novel architecture that mitigates these issues by leveraging readily obtainable interface data (e.g., topology and position). Interface data inherently contains the high-frequency features not only necessary to complement the physical field data, but also help with spectral bias. IANO incorporates an interface-aware function encoding mechanism to capture dynamic coupling, and a geometry-aware positional encoding method to enhance spatial fidelity for pointwise super-resolution. Empirical results across multiple multiphase flow cases demonstrate that IANO achieves significant accuracy improvements (up to $\\sim$10\\%) over existing NO baselines. Furthermore, IANO exhibits superior generalization capabilities in low-data and noisy settings, confirming its utility for practical, data-efficient $\\text{AI}$-based multiphase flow simulations.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤šç›¸æµæ¨¡æ‹Ÿä¸­å› åœºä¸è¿ç»­æ€§å’Œé«˜åˆ†è¾¨ç‡ç½‘æ ¼éœ€æ±‚å¯¼è‡´çš„è®¡ç®—æˆæœ¬é«˜æ˜‚é—®é¢˜ï¼Œæå‡ºäº†Interface Information Aware Neural Operator (IANO)ã€‚ç°æœ‰çš„Neural Operators (NOs)åœ¨å¤„ç†å¤šç›¸ç³»ç»Ÿæ—¶é¢ä¸´ç›¸ç•Œé¢ç©ºé—´å¼‚è´¨æ€§å¼•å‘çš„è°±åå·®(spectral bias)åŠé«˜åˆ†è¾¨ç‡æ•°æ®ç¨€ç¼ºä¸¤å¤§æŒ‘æˆ˜ã€‚IANOé€šè¿‡åˆ©ç”¨æ˜“è·å–çš„ç•Œé¢æ•°æ®ï¼ˆå¦‚æ‹“æ‰‘å’Œä½ç½®ï¼‰æ¥å¼•å…¥å¿…è¦çš„é«˜é¢‘ç‰¹å¾ï¼Œä»è€Œæœ‰æ•ˆç¼“è§£è¿™äº›é—®é¢˜ã€‚è¯¥æ¶æ„åŒ…å«ä¸€ä¸ªç”¨äºæ•æ‰åŠ¨æ€è€¦åˆçš„ç•Œé¢æ„ŸçŸ¥å‡½æ•°ç¼–ç æœºåˆ¶ï¼Œä»¥åŠä¸€ä¸ªç”¨äºå¢å¼ºé€ç‚¹è¶…åˆ†è¾¨ç‡ç©ºé—´ä¿çœŸåº¦çš„å‡ ä½•æ„ŸçŸ¥ä½ç½®ç¼–ç æ–¹æ³•ã€‚åœ¨å¤šä¸ªå¤šç›¸æµæ¡ˆä¾‹çš„å®è¯ç»“æœè¡¨æ˜ï¼ŒIANOç›¸æ¯”ç°æœ‰çš„NOåŸºçº¿æ¨¡å‹å®ç°äº†æ˜¾è‘—çš„å‡†ç¡®ç‡æå‡ï¼ˆæœ€é«˜è¾¾10%ï¼‰ã€‚æ­¤å¤–ï¼ŒIANOåœ¨ä½æ•°æ®é‡å’Œå™ªå£°ç¯å¢ƒä¸­å±•ç°äº†å“è¶Šçš„æ³›åŒ–èƒ½åŠ›ï¼Œè¯å®äº†å…¶åœ¨é«˜æ•ˆæ•°æ®é©±åŠ¨çš„AIå¤šç›¸æµæ¨¡æ‹Ÿä¸­çš„å®ç”¨ä»·å€¼ã€‚",
      "categories": [
        "physics.flu-dyn",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "physics.flu-dyn",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.08625v2",
      "published_date": "2025-11-09 01:13:40 UTC",
      "updated_date": "2025-12-03 02:48:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T19:22:55.286036+00:00"
    },
    {
      "arxiv_id": "2511.06172v1",
      "title": "MambaOVSR: Multiscale Fusion with Global Motion Modeling for Chinese Opera Video Super-Resolution",
      "title_zh": "MambaOVSRï¼šåŸºäºå…¨å±€è¿åŠ¨å»ºæ¨¡çš„ä¸­å›½æˆæ›²è§†é¢‘è¶…åˆ†è¾¨ç‡å¤šå°ºåº¦èåˆ",
      "authors": [
        "Hua Chang",
        "Xin Xu",
        "Wei Liu",
        "Wei Wang",
        "Xin Yuan",
        "Kui Jiang"
      ],
      "abstract": "Chinese opera is celebrated for preserving classical art. However, early filming equipment limitations have degraded videos of last-century performances by renowned artists (e.g., low frame rates and resolution), hindering archival efforts. Although space-time video super-resolution (STVSR) has advanced significantly, applying it directly to opera videos remains challenging. The scarcity of datasets impedes the recovery of high frequency details, and existing STVSR methods lack global modeling capabilities, compromising visual quality when handling opera's characteristic large motions. To address these challenges, we pioneer a large scale Chinese Opera Video Clip (COVC) dataset and propose the Mamba-based multiscale fusion network for space-time Opera Video Super-Resolution (MambaOVSR). Specifically, MambaOVSR involves three novel components: the Global Fusion Module (GFM) for motion modeling through a multiscale alternating scanning mechanism, and the Multiscale Synergistic Mamba Module (MSMM) for alignment across different sequence lengths. Additionally, our MambaVR block resolves feature artifacts and positional information loss during alignment. Experimental results on the COVC dataset show that MambaOVSR significantly outperforms the SOTA STVSR method by an average of 1.86 dB in terms of PSNR. Dataset and Code will be publicly released.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ—©æœŸä¸­å›½æˆæ›²è§†é¢‘å› è®¾å¤‡é™åˆ¶å¯¼è‡´çš„ä½å¸§ç‡å’Œä½åˆ†è¾¨ç‡é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºMambaçš„å¤šå°ºåº¦èåˆç½‘ç»œMambaOVSRï¼Œç”¨äºæ—¶ç©ºè§†é¢‘è¶…åˆ†è¾¨ç‡(STVSR)ã€‚ä¸ºäº†å…‹æœç°æœ‰æ–¹æ³•åœ¨å¤„ç†æˆæ›²å¤§å¹…åº¦åŠ¨ä½œæ—¶ç¼ºä¹å…¨å±€å»ºæ¨¡èƒ½åŠ›ä»¥åŠæ•°æ®é›†ç¨€ç¼ºçš„æŒ‘æˆ˜ï¼Œä½œè€…é¦–å…ˆæ„å»ºäº†å¤§è§„æ¨¡çš„Chinese Opera Video Clip (COVC)æ•°æ®é›†ã€‚MambaOVSRå¼•å…¥äº†ä¸‰ä¸ªæ ¸å¿ƒç»„ä»¶ï¼šé€šè¿‡å¤šå°ºåº¦äº¤æ›¿æ‰«ææœºåˆ¶è¿›è¡Œè¿åŠ¨å»ºæ¨¡çš„Global Fusion Module (GFM)ï¼Œç”¨äºè·¨åºåˆ—é•¿åº¦å¯¹é½çš„Multiscale Synergistic Mamba Module (MSMM)ï¼Œä»¥åŠè§£å†³ç‰¹å¾ä¼ªå½±å’Œä½ç½®ä¿¡æ¯ä¸¢å¤±çš„MambaVRæ¨¡å—ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒMambaOVSRåœ¨COVCæ•°æ®é›†ä¸Šçš„è¡¨ç°æ˜¾è‘—ä¼˜äºç°æœ‰çš„SOTA STVSRæ–¹æ³•ï¼ŒPSNRå¹³å‡æå‡äº†1.86 dBï¼Œæœ‰æ•ˆæå‡äº†æˆæ›²è§†é¢‘çš„è§†è§‰è´¨é‡ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.06172v1",
      "published_date": "2025-11-09 00:53:58 UTC",
      "updated_date": "2025-11-09 00:53:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T19:24:18.552196+00:00"
    },
    {
      "arxiv_id": "2511.06168v2",
      "title": "Chain-of-Thought as a Lens: Evaluating Structured Reasoning Alignment between Human Preferences and Large Language Models",
      "title_zh": "ä»¥æ€ç»´é“¾ä¸ºé€é•œï¼šè¯„ä¼°äººç±»åå¥½ä¸å¤§å‹è¯­è¨€æ¨¡å‹ä¹‹é—´çš„ç»“æ„åŒ–æ¨ç†å¯¹é½",
      "authors": [
        "Boxuan Wang",
        "Zhuoyun Li",
        "Xinmiao Huang",
        "Xiaowei Huang",
        "Yi Dong"
      ],
      "abstract": "This paper primarily demonstrate a method to quantitatively assess the alignment between multi-step, structured reasoning in large language models and human preferences. We introduce the Alignment Score, a semantic-level metric that compares a model-produced chain of thought traces with a human-preferred reference by constructing semantic-entropy-based matrices over intermediate steps and measuring their divergence. Our analysis shows that Alignment Score tracks task accuracy across models and hop depths, and peaks at 2-hop reasoning. Empirical results further indicates that misalignment at greater reasoning depths is driven mainly by alignment errors such as thematic shift and redundant reasoning. Viewing chain sampling as drawing from a distribution over reasoning paths, we empirically demonstrate a strong and consistent correlation between Alignment Score and accuracy performance, supporting its use as a meaningful diagnostic signal for structured reasoning.",
      "tldr_zh": "è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§é‡åŒ–è¯„ä¼°å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å¤šæ­¥ç»“æ„åŒ–æ¨ç†ä¸äººç±»åå¥½å¯¹é½ç¨‹åº¦çš„æ–¹æ³•ã€‚ç ”ç©¶å¼•å…¥äº†Alignment Scoreï¼Œè¿™æ˜¯ä¸€ç§è¯­ä¹‰å±‚é¢çš„æŒ‡æ ‡ï¼Œé€šè¿‡æ„å»ºåŸºäºè¯­ä¹‰ç†µï¼ˆsemantic-entropyï¼‰çš„çŸ©é˜µå¹¶æµ‹é‡å…¶å·®å¼‚ï¼Œå°†æ¨¡å‹ç”Ÿæˆçš„æ€ç»´é“¾ï¼ˆChain-of-Thoughtï¼‰è½¨è¿¹ä¸äººç±»åå¥½çš„å‚è€ƒè¿›è¡Œæ¯”è¾ƒã€‚åˆ†æè¡¨æ˜ï¼ŒAlignment Scoreèƒ½å¤Ÿè·¨æ¨¡å‹å’Œæ¨ç†æ·±åº¦è¿½è¸ªä»»åŠ¡å‡†ç¡®ç‡ï¼Œå¹¶åœ¨2è·³ï¼ˆ2-hopï¼‰æ¨ç†æ—¶è¾¾åˆ°å³°å€¼ã€‚å®è¯ç»“æœè¿›ä¸€æ­¥æŒ‡å‡ºï¼Œæ›´æ·±å±‚æ¨ç†ä¸­çš„ä¸å¯¹é½ä¸»è¦ç”±ä¸»é¢˜åç§»ï¼ˆthematic shiftï¼‰å’Œå†—ä½™æ¨ç†ï¼ˆredundant reasoningï¼‰ç­‰å¯¹é½é”™è¯¯é©±åŠ¨ã€‚ç ”ç©¶å°†é“¾é‡‡æ ·è§†ä¸ºä»æ¨ç†è·¯å¾„åˆ†å¸ƒä¸­æŠ½å–ï¼Œå®è¯äº†Alignment Scoreä¸å‡†ç¡®ç‡æ€§èƒ½ä¹‹é—´å­˜åœ¨å¼ºä¸”ä¸€è‡´çš„ç›¸å…³æ€§ï¼Œæ”¯æŒå…¶ä½œä¸ºç»“æ„åŒ–æ¨ç†çš„æœ‰æ„ä¹‰è¯Šæ–­ä¿¡å·ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Pre-print, 16 pages, 4 figures",
      "pdf_url": "https://arxiv.org/pdf/2511.06168v2",
      "published_date": "2025-11-09 00:27:38 UTC",
      "updated_date": "2026-01-07 15:50:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T19:23:40.912895+00:00"
    }
  ],
  "processing_status": "completed",
  "error": null,
  "raw_papers_fetched": true,
  "papers_count": 95,
  "processed_papers_count": 95,
  "failed_papers_count": 0,
  "llm_backup_calls": 190,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2026-01-25T19:26:06.008893+00:00"
}