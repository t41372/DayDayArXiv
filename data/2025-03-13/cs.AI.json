{
  "date": "2025-03-13",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-03-13 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦于 AI 和机器学习领域的创新，尤其是大型语言模型（LLMs）的优化、安全性和应用扩展（如检索增强生成和多模态处理），以及计算机视觉、机器人和联邦学习的进展。其中，令人印象深刻的文章包括 Yann LeCun 参与的 Transformer 无归一化方法，以及 DeepSeek 相关的 LLM 增强技术，这些工作展示了高效计算和鲁棒性的前沿突破，同时强调了 AI 在医疗和决策中的潜力。\n\n下面，我将挑选并简要讨论部分关键论文，先优先聊重要、创新性强的文章（如 LLM 和视觉领域），并将相关主题归类快速概述。其他较常规或次要论文（如某些纯理论模型）将简略掠过，只列出标题和核心点。\n\n### LLM 和 AI 优化\n- **OuroMamba: A Data-Free Quantization Framework for Vision Mamba Models（OuroMamba: 无数据量化框架用于视觉 Mamba 模型）**  \n  这篇论文提出 OuroMamba，一种针对视觉 Mamba 模型的无数据后训练量化框架，通过生成语义丰富的数据和动态异常检测，实现高效量化，显著提升性能并加速 GPU 推理，适用于视觉任务。\n\n- **Predicting Stock Movement with BERTweet and Transformers（使用 BERTweet 和 Transformer 预测股票走势）**  \n  作者探索 BERTweet 在股票预测中的效能，结合社会媒体数据和 Transformer 架构，超越现有基准，在 Stocknet 数据集上设置新基线，改进机器学习在金融领域的鲁棒性。\n\n- **Graph-Grounded LLMs: Leveraging Graphical Function Calling to Minimize LLM Hallucinations（Graph-Grounded LLMs: 通过图形函数调用减少 LLM 幻觉）**  \n  这篇创新工作引入图形库支持的 LLM 系统，显著减少幻觉问题，提升图形任务的准确性，并应用于实际场景如灾害救援，展示了 LLM 在图结构任务中的潜力。\n\n- **$(\\varepsilon, δ)$ Considered Harmful: Best Practices for Reporting Differential Privacy Guarantees（$(\\varepsilon, δ)$ 报告有害：差分隐私保证的最佳实践）**  \n  论文批评现有差分隐私报告方法，推荐使用高斯差分隐私（GDP）作为主要指标，提高隐私评估的可比性和准确性，适用于机器学习应用。\n\n- **ChatGPT Encounters Morphing Attack Detection: Zero-Shot MAD with Multi-Modal Large Language Models and General Vision Models（ChatGPT 遇上变形攻击检测：使用多模态 LLM 和通用视觉模型的零样本检测）**  \n  提出零样本变形攻击检测方法，利用多模态 LLM 和视觉模型，实现了高鲁棒性和可解释性，显著提升面部识别系统的安全性。\n\n- **Ensemble Learning for Large Language Models in Text and Code Generation: A Survey（LLM 的集成学习在文本和代码生成中的调查）**  \n  这篇调查总结 LLM 集成学习方法（如权重合并和混合专家），强调其在文本和代码生成中的优势，提供未来应用方向。\n\n- **StepMathAgent: A Step-Wise Agent for Evaluating Mathematical Processes through Tree-of-Error（StepMathAgent: 通过错误树评估数学过程的逐步代理）**  \n  开发 StepMathAgent，使用错误树评估 LLM 的数学推理能力，显著提升模型在复杂任务中的性能和可解释性。\n\n- **其他 LLM 相关快速掠过：** 如 \"RankPO: Preference Optimization for Job-Talent Matching（RankPO: 职位人才匹配的偏好优化）\" 提出偏好优化框架；\"ZSMerge: Zero-Shot KV Cache Compression for Memory-Efficient Long-Context LLMs（ZSMerge: 零样本 KV 缓存压缩提升 LLM 内存效率）\" 优化长上下文处理。这些工作虽重要，但更多是技术细化，贡献在于效率提升。\n\n### 计算机视觉和机器人\n- **LHM: Large Animatable Human Reconstruction Model from a Single Image in Seconds（LHM: 从单张图像秒级重建可动画人体模型）**  \n  论文创新性地提出 LHM 模型，从单张图像快速重建高保真人体模型，支持动画应用，显著提升重建效率和面部细节保留。\n\n- **ETCH: Generalizing Body Fitting to Clothed Humans via Equivariant Tightness（ETCH: 通过等变紧致性泛化人体拟合到穿衣人体）**  \n  引入等变紧致性机制，改进人体拟合算法，支持复杂衣物建模，在 CAPE 数据集上表现出色。\n\n- **IMPACT: Intelligent Motion Planning with Acceptable Contact Trajectories via Vision-Language Models（IMPACT: 通过视觉语言模型的智能运动规划接受接触轨迹）**  \n  使用视觉语言模型优化机器人运动规划，处理接触轨迹，提高了 cluttered 环境下的鲁棒性。\n\n- **MoFlow: One-Step Flow Matching for Human Trajectory Forecasting via Implicit Maximum Likelihood Estimation based Distillation（MoFlow: 通过隐式最大似然估计的蒸馏实现一步人类轨迹预测）**  \n  提出 MoFlow 框架，一步流匹配预测人类轨迹，显著提升多模态预测准确性和速度。\n\n- **快速掠过视觉相关：** 如 \"SciVerse: Unveiling the Knowledge Comprehension and Visual Reasoning of LMMs on Multi-modal Scientific Problems（SciVerse: 揭示 LMM 在多模态科学问题中的知识理解和视觉推理）\" 评估 LMM 的科学推理能力；\"TGP: Two-modal occupancy prediction with 3D Gaussian and sparse points（TGP: 使用 3D 高斯和稀疏点的双模态占用预测）\" 改进 3D 环境感知。这些论文虽有技术创新，但影响力较局部。\n\n### 其他领域快速概述\n- **联邦学习和安全：** 如 \"dFLMoE: Decentralized Federated Learning via Mixture of Experts for Medical Data Analysis（dFLMoE: 通过混合专家的去中心化联邦学习用于医疗数据分析）\" 提出高效联邦学习框架，提升医疗隐私保护；\"Byzantine-Resilient Federated Learning via Distributed Optimization（通过分布式优化实现拜占庭鲁棒联邦学习）\" 增强模型鲁棒性。这些工作在安全 AI 中有实际价值，但细节较技术化。\n\n- **医学和生物：** 如 \"Predicting Clinical Outcomes with Waveform LSTMs（使用 Waveform LSTMs 预测临床结果）\" 利用 LSTM 提升医疗预测准确性；\"MentalChat16K: A Benchmark Dataset for Conversational Mental Health Assistance（MentalChat16K: 对话式心理健康辅助基准数据集）\" 构建心理健康数据集。这些论文贡献在于数据集和应用，但非核心焦点。\n\n- **机器人和强化学习：** 如 \"KUDA: Keypoints to Unify Dynamics Learning and Visual Prompting for Open-Vocabulary Robotic Manipulation（KUDA: 使用关键点统一动力学学习和视觉提示的开放词汇机器人操作）\" 整合视觉和动力学提升机器人操作。这些领域论文较多，但整体上以技术验证为主。\n\n今天的论文总体上突出了 AI 模型的效率和鲁棒性改进，尤其在 LLM 和视觉领域的创新，这些进展有望推动实际应用如医疗决策和机器人自治。非核心论文（如纯理论或小规模实验）虽有积累，但未列出以控制篇幅。建议读者关注 LLM 安全和高效计算方向的后续研究！",
  "papers": [
    {
      "arxiv_id": "2503.10959v1",
      "title": "OuroMamba: A Data-Free Quantization Framework for Vision Mamba Models",
      "title_zh": "OuroMamba：一个无数据量化框架，用于视觉 Mamba 模型",
      "authors": [
        "Akshat Ramachandran",
        "Mingyu Lee",
        "Huan Xu",
        "Souvik Kundu",
        "Tushar Krishna"
      ],
      "abstract": "We present OuroMamba, the first data-free post-training quantization (DFQ)\nmethod for vision Mamba-based models (VMMs). We identify two key challenges in\nenabling DFQ for VMMs, (1) VMM's recurrent state transitions restricts\ncapturing of long-range interactions and leads to semantically weak synthetic\ndata, (2) VMM activations exhibit dynamic outlier variations across time-steps,\nrendering existing static PTQ techniques ineffective. To address these\nchallenges, OuroMamba presents a two-stage framework: (1) OuroMamba-Gen to\ngenerate semantically rich and meaningful synthetic data. It applies\ncontrastive learning on patch level VMM features generated through neighborhood\ninteractions in the latent state space, (2) OuroMamba-Quant to employ\nmixed-precision quantization with lightweight dynamic outlier detection during\ninference. In specific, we present a thresholding based outlier channel\nselection strategy for activations that gets updated every time-step. Extensive\nexperiments across vision and generative tasks show that our data-free\nOuroMamba surpasses existing data-driven PTQ techniques, achieving\nstate-of-the-art performance across diverse quantization settings.\nAdditionally, we implement efficient GPU kernels to achieve practical latency\nspeedup of up to 2.36x. Code will be released soon.",
      "tldr_zh": "本研究提出 OuroMamba，这是一个针对视觉 Mamba 模型 (VMMs) 的无数据后训练量化 (DFQ) 框架，旨在解决 VMMs 在合成数据语义弱和激活值动态异常变化等方面的挑战。框架分为两阶段：OuroMamba-Gen 通过在潜在状态空间应用对比学习 (contrastive learning) 生成语义丰富的合成数据；OuroMamba-Quant 采用混合精度量化 (mixed-precision quantization) 并结合轻量级动态异常检测策略，如基于阈值的激活异常通道选择。实验结果显示，OuroMamba 在各种视觉和生成任务中超越现有数据驱动 PTQ 方法，实现了最先进性能，并在不同量化设置下获得高达 2.36x 的延迟加速。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10959v1",
      "published_date": "2025-03-13 23:58:55 UTC",
      "updated_date": "2025-03-13 23:58:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:32:32.847885"
    },
    {
      "arxiv_id": "2503.10957v1",
      "title": "Predicting Stock Movement with BERTweet and Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Michael Charles Albada",
        "Mojolaoluwa Joshua Sonola"
      ],
      "abstract": "Applying deep learning and computational intelligence to finance has been a\npopular area of applied research, both within academia and industry, and\ncontinues to attract active attention. The inherently high volatility and\nnon-stationary of the data pose substantial challenges to machine learning\nmodels, especially so for today's expressive and highly-parameterized deep\nlearning models. Recent work has combined natural language processing on data\nfrom social media to augment models based purely on historic price data to\nimprove performance has received particular attention. Previous work has\nachieved state-of-the-art performance on this task by combining techniques such\nas bidirectional GRUs, variational autoencoders, word and document embeddings,\nself-attention, graph attention, and adversarial training. In this paper, we\ndemonstrated the efficacy of BERTweet, a variant of BERT pre-trained\nspecifically on a Twitter corpus, and the transformer architecture by achieving\ncompetitive performance with the existing literature and setting a new baseline\nfor Matthews Correlation Coefficient on the Stocknet dataset without auxiliary\ndata sources.",
      "tldr_zh": "本研究探讨了使用深度学习和计算智能预测股票运动的问题，强调了金融数据的高波动性和非平稳性对模型的挑战。作者采用 BERTweet（一种在 Twitter 语料上预训练的 BERT 变体）和 Transformer 架构，仅基于历史价格数据在 Stocknet 数据集上进行预测。结果显示，该方法实现了与现有文献相当的性能，并为 Matthews Correlation Coefficient 设置了新基准，证明了其在无需辅助数据源的情况下的高效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages, 4 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2503.10957v1",
      "published_date": "2025-03-13 23:46:24 UTC",
      "updated_date": "2025-03-13 23:46:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:32:45.214375"
    },
    {
      "arxiv_id": "2503.10954v1",
      "title": "Empirical Computation",
      "title_zh": "实证计算",
      "authors": [
        "Eric Tang",
        "Marcel Böhme"
      ],
      "abstract": "In this vision paper, we explore the challenges and opportunities of a form\nof computation that employs an empirical (rather than a formal) approach, where\nthe solution of a computational problem is returned as empirically most likely\n(rather than necessarily correct). We call this approach as *empirical\ncomputation* and observe that its capabilities and limits *cannot* be\nunderstood within the classic, rationalist framework of computation.\n  While we take a very broad view of \"computational problem\", a classic,\nwell-studied example is *sorting*: Given a set of $n$ numbers, return these\nnumbers sorted in ascending order.\n  * To run a classical, *formal computation*, we might first think about a\n*specific algorithm* (e.g., merge sort) before developing a *specific* program\nthat implements it. The program will expect the input to be given in a\n*specific* format, type, or data structure (e.g., unsigned 32-bit integers). In\nsoftware engineering, we have many approaches to analyze the correctness of\nsuch programs. From complexity theory, we know that there exists no correct\nprogram that can solve the average instance of the sorting problem faster than\n$O(n\\log n)$.\n  * To run an *empirical computation*, we might directly ask a large language\nmodel (LLM) to solve *any* computational problem (which can be stated\ninformally in natural language) and provide the input in *any* format (e.g.,\nnegative numbers written as Chinese characters). There is no (problem-specific)\nprogram that could be analyzed for correctness. Also, the time it takes an LLM\nto return an answer is entirely *independent* of the computational complexity\nof the problem that is solved.\n  What are the capabilities or limits of empirical computation in the general,\nin the problem-, or in the instance-specific? Our purpose is to establish\nempirical computation as a field in SE that is timely and rich with interesting\nproblems.",
      "tldr_zh": "这篇愿景论文提出“empirical computation”概念，即一种基于经验而非形式的方法进行计算，其中解决方案被视为经验上最可能正确，而非绝对准确。该方法与传统形式计算（如使用特定算法如merge sort来排序数字）形成对比，后者依赖于严格的程序分析和复杂度理论（如$O(n\\log n)$时间复杂度）。论文指出，empirical computation可以通过大语言模型(LLM)处理非正式输入（如自然语言描述），其性能不受传统计算框架限制，并探讨其在一般、问题特定或实例特定层面的能力和局限性。最终，论文旨在将empirical computation确立为软件工程(SE)中的一个新领域，富有探索性问题。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Open challenges in the analysis of properties and limits of empirical\n  computation",
      "pdf_url": "http://arxiv.org/pdf/2503.10954v1",
      "published_date": "2025-03-13 23:40:42 UTC",
      "updated_date": "2025-03-13 23:40:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:32:56.695884"
    },
    {
      "arxiv_id": "2503.10949v1",
      "title": "Safe Continual Domain Adaptation after Sim2Real Transfer of Reinforcement Learning Policies in Robotics",
      "title_zh": "翻译失败",
      "authors": [
        "Josip Josifovski",
        "Shangding Gu",
        "Mohammadhossein Malmir",
        "Haoliang Huang",
        "Sayantan Auddy",
        "Nicolás Navarro-Guerrero",
        "Costas Spanos",
        "Alois Knoll"
      ],
      "abstract": "Domain randomization has emerged as a fundamental technique in reinforcement\nlearning (RL) to facilitate the transfer of policies from simulation to\nreal-world robotic applications. Many existing domain randomization approaches\nhave been proposed to improve robustness and sim2real transfer. These\napproaches rely on wide randomization ranges to compensate for the unknown\nactual system parameters, leading to robust but inefficient real-world\npolicies. In addition, the policies pretrained in the domain-randomized\nsimulation are fixed after deployment due to the inherent instability of the\noptimization processes based on RL and the necessity of sampling exploitative\nbut potentially unsafe actions on the real system. This limits the adaptability\nof the deployed policy to the inevitably changing system parameters or\nenvironment dynamics over time. We leverage safe RL and continual learning\nunder domain-randomized simulation to address these limitations and enable safe\ndeployment-time policy adaptation in real-world robot control. The experiments\nshow that our method enables the policy to adapt and fit to the current domain\ndistribution and environment dynamics of the real system while minimizing\nsafety risks and avoiding issues like catastrophic forgetting of the general\npolicy found in randomized simulation during the pretraining phase. Videos and\nsupplementary material are available at https://safe-cda.github.io/.",
      "tldr_zh": "该研究解决了强化学习（RL）策略从模拟到真实世界（Sim2Real）转移中的问题，即现有基于领域随机化（Domain Randomization）的方法虽增强鲁棒性，但导致策略效率低下且无法适应系统参数或环境动态的变化。作者提出了一种结合安全强化学习（Safe RL）和持续学习（Continual Learning）的框架，在领域随机化模拟环境中训练策略，实现部署后的安全持续领域适应。实验结果表明，该方法使策略能够高效适应真实机器人控制的当前领域分布和环境动态，同时最小化安全风险并避免灾难性遗忘（Catastrophic Forgetting）。这为可信赖的机器人应用奠定了基础。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "8 pages, 5 figures, under review",
      "pdf_url": "http://arxiv.org/pdf/2503.10949v1",
      "published_date": "2025-03-13 23:28:11 UTC",
      "updated_date": "2025-03-13 23:28:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:33:08.396167"
    },
    {
      "arxiv_id": "2503.10945v1",
      "title": "$(\\varepsilon, δ)$ Considered Harmful: Best Practices for Reporting Differential Privacy Guarantees",
      "title_zh": "翻译失败",
      "authors": [
        "Juan Felipe Gomez",
        "Bogdan Kulynych",
        "Georgios Kaissis",
        "Jamie Hayes",
        "Borja Balle",
        "Antti Honkela"
      ],
      "abstract": "Current practices for reporting the level of differential privacy (DP)\nguarantees for machine learning (ML) algorithms provide an incomplete and\npotentially misleading picture of the guarantees and make it difficult to\ncompare privacy levels across different settings. We argue for using Gaussian\ndifferential privacy (GDP) as the primary means of communicating DP guarantees\nin ML, with the full privacy profile as a secondary option in case GDP is too\ninaccurate. Unlike other widely used alternatives, GDP has only one parameter,\nwhich ensures easy comparability of guarantees, and it can accurately capture\nthe full privacy profile of many important ML applications. To support our\nclaims, we investigate the privacy profiles of state-of-the-art DP large-scale\nimage classification, and the TopDown algorithm for the U.S. Decennial Census,\nobserving that GDP fits the profiles remarkably well in all three cases.\nAlthough GDP is ideal for reporting the final guarantees, other formalisms\n(e.g., privacy loss random variables) are needed for accurate privacy\naccounting. We show that such intermediate representations can be efficiently\nconverted to GDP with minimal loss in tightness.",
      "tldr_zh": "该论文批评了当前使用 $(\\varepsilon, δ)$ 报告差分隐私（DP）保证的做法，认为它提供不完整且可能误导的信息，难以比较不同设置下的隐私水平。作者推荐采用高斯差分隐私（GDP）作为主要报告方式，因为它只有一个参数，便于直接比较，且能准确捕捉许多机器学习（ML）应用的完整隐私配置文件。通过调查状态艺术的 DP 大规模图像分类和 TopDown 人口普查算法，实验结果显示 GDP 高度符合这些场景。最终，论文强调虽然其他形式（如隐私损失随机变量）适合中间隐私会计，但可高效转换为 GDP，以实现更紧凑的保证。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10945v1",
      "published_date": "2025-03-13 23:06:30 UTC",
      "updated_date": "2025-03-13 23:06:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:33:22.683043"
    },
    {
      "arxiv_id": "2503.10941v1",
      "title": "Graph-Grounded LLMs: Leveraging Graphical Function Calling to Minimize LLM Hallucinations",
      "title_zh": "翻译失败",
      "authors": [
        "Piyush Gupta",
        "Sangjae Bae",
        "David Isele"
      ],
      "abstract": "The adoption of Large Language Models (LLMs) is rapidly expanding across\nvarious tasks that involve inherent graphical structures. Graphs are integral\nto a wide range of applications, including motion planning for autonomous\nvehicles, social networks, scene understanding, and knowledge graphs. Many\nproblems, even those not initially perceived as graph-based, can be effectively\naddressed through graph theory. However, when applied to these tasks, LLMs\noften encounter challenges, such as hallucinations and mathematical\ninaccuracies. To overcome these limitations, we propose Graph-Grounded LLMs, a\nsystem that improves LLM performance on graph-related tasks by integrating a\ngraph library through function calls. By grounding LLMs in this manner, we\ndemonstrate significant reductions in hallucinations and improved mathematical\naccuracy in solving graph-based problems, as evidenced by the performance on\nthe NLGraph benchmark. Finally, we showcase a disaster rescue application where\nthe Graph-Grounded LLM acts as a decision-support system.",
      "tldr_zh": "该研究针对大型语言模型 (LLMs) 在处理图形结构任务（如社交网络和知识图谱）时存在的幻觉和数学不准确问题，提出 Graph-Grounded LLMs 系统。该系统通过图形函数调用整合图形库，实现对 LLMs 的增强，显著减少幻觉并提高数学准确性。在 NLGraph 基准测试中，Graph-Grounded LLMs 表现出色，并被应用于灾难救援场景，作为决策支持系统。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10941v1",
      "published_date": "2025-03-13 22:57:28 UTC",
      "updated_date": "2025-03-13 22:57:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:33:32.880095"
    },
    {
      "arxiv_id": "2503.10937v1",
      "title": "ChatGPT Encounters Morphing Attack Detection: Zero-Shot MAD with Multi-Modal Large Language Models and General Vision Models",
      "title_zh": "翻译失败",
      "authors": [
        "Haoyu Zhang",
        "Raghavendra Ramachandra",
        "Kiran Raja",
        "Christoph Busch"
      ],
      "abstract": "Face Recognition Systems (FRS) are increasingly vulnerable to face-morphing\nattacks, prompting the development of Morphing Attack Detection (MAD)\nalgorithms. However, a key challenge in MAD lies in its limited\ngeneralizability to unseen data and its lack of explainability-critical for\npractical application environments such as enrolment stations and automated\nborder control systems. Recognizing that most existing MAD algorithms rely on\nsupervised learning paradigms, this work explores a novel approach to MAD using\nzero-shot learning leveraged on Large Language Models (LLMs). We propose two\ntypes of zero-shot MAD algorithms: one leveraging general vision models and the\nother utilizing multimodal LLMs. For general vision models, we address the MAD\ntask by computing the mean support embedding of an independent support set\nwithout using morphed images. For the LLM-based approach, we employ the\nstate-of-the-art GPT-4 Turbo API with carefully crafted prompts. To evaluate\nthe feasibility of zero-shot MAD and the effectiveness of the proposed methods,\nwe constructed a print-scan morph dataset featuring various unseen morphing\nalgorithms, simulating challenging real-world application scenarios.\nExperimental results demonstrated notable detection accuracy, validating the\napplicability of zero-shot learning for MAD tasks. Additionally, our\ninvestigation into LLM-based MAD revealed that multimodal LLMs, such as\nChatGPT, exhibit remarkable generalizability to untrained MAD tasks.\nFurthermore, they possess a unique ability to provide explanations and\nguidance, which can enhance transparency and usability for end-users in\npractical applications.",
      "tldr_zh": "该论文探讨了人脸识别系统（FRS）面对人脸变形攻击（morphing attacks）的挑战，提出两种基于零样本学习（zero-shot learning）的变形攻击检测（MAD）方法：一种利用通用视觉模型（general vision models）计算独立支持集的均值嵌入，而不使用变形图像；另一种则采用多模态大型语言模型（multimodal LLMs）如 GPT-4 Turbo，并通过精心设计的提示进行检测。研究者构建了一个打印-扫描变形数据集来模拟真实场景，并通过实验验证了这些方法的有效性，实现了显著的检测准确率。多模态 LLMs 展示了出色的泛化性，并能提供解释和指导，提升了 MAD 任务的透明度和实用性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10937v1",
      "published_date": "2025-03-13 22:53:24 UTC",
      "updated_date": "2025-03-13 22:53:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:33:45.945474"
    },
    {
      "arxiv_id": "2503.10927v2",
      "title": "OASST-ETC Dataset: Alignment Signals from Eye-tracking Analysis of LLM Responses",
      "title_zh": "翻译失败",
      "authors": [
        "Angela Lopez-Cardona",
        "Sebastian Idesis",
        "Miguel Barreda-Ángeles",
        "Sergi Abadal",
        "Ioannis Arapakis"
      ],
      "abstract": "While Large Language Models (LLMs) have significantly advanced natural\nlanguage processing, aligning them with human preferences remains an open\nchallenge. Although current alignment methods rely primarily on explicit\nfeedback, eye-tracking (ET) data offers insights into real-time cognitive\nprocessing during reading. In this paper, we present OASST-ETC, a novel\neye-tracking corpus capturing reading patterns from 24 participants, while\nevaluating LLM-generated responses from the OASST1 dataset. Our analysis\nreveals distinct reading patterns between preferred and non-preferred\nresponses, which we compare with synthetic eye-tracking data. Furthermore, we\nexamine the correlation between human reading measures and attention patterns\nfrom various transformer-based models, discovering stronger correlations in\npreferred responses. This work introduces a unique resource for studying human\ncognitive processing in LLM evaluation and suggests promising directions for\nincorporating eye-tracking data into alignment methods. The dataset and\nanalysis code are publicly available.",
      "tldr_zh": "本研究介绍了 OASST-ETC 数据集，这是一个基于眼-tracking (ET) 分析的语料库，用于探索 Large Language Models (LLMs) 与人类偏好对齐的挑战。研究从24名参与者那里收集眼动数据，评估 OASST1 数据集中的 LLM 生成响应，并发现偏好响应与非偏好响应在阅读模式上存在显著差异，同时与合成眼动数据进行了比较。进一步分析显示，人类阅读测量与各种 transformer-based 模型的注意力模式在偏好响应中相关性更强，为将 ET 数据整合到 LLM 对齐方法中提供了新方向。该数据集和分析代码已公开可用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "This paper has been accepted to ACM ETRA 2025 and published on\n  PACMHCI",
      "pdf_url": "http://arxiv.org/pdf/2503.10927v2",
      "published_date": "2025-03-13 22:28:38 UTC",
      "updated_date": "2025-03-26 13:24:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:33:56.507955"
    },
    {
      "arxiv_id": "2503.10925v1",
      "title": "Predicting Clinical Outcomes with Waveform LSTMs",
      "title_zh": "翻译失败",
      "authors": [
        "Michael Albada"
      ],
      "abstract": "Data mining and machine learning hold great potential to enable health\nsystems to systematically use data and analytics to identify inefficiencies and\nbest practices that improve care and reduce costs. Waveform data offers\nparticularly detailed information on how patient health evolves over time and\nhas the potential to significantly improve prediction accuracy on multiple\nbenchmarks, but has been widely under-utilized, largely because of the\nchallenges in working with these large and complex datasets. This study\nevaluates the potential of leveraging clinical waveform data to improve\nprediction accuracy on a single benchmark task: the risk of mortality in the\nintensive care unit. We identify significant potential from this data, beating\nthe existing baselines for both logistic regression and deep learning models.",
      "tldr_zh": "这篇论文探讨了利用波形数据（waveform data）提升临床结果预测的潜力，特别是针对重症监护室（intensive care unit）的死亡风险评估。研究通过机器学习方法，包括Waveform LSTMs，处理这些大型复杂数据集，证明了波形数据能显著改善预测准确性。结果显示，该方法超过了现有的logistic regression和deep learning models基准，为医疗系统优化效率和降低成本提供了新见解。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "7 pages,. arXiv admin note: text overlap with arXiv:1803.06589 by\n  other authors",
      "pdf_url": "http://arxiv.org/pdf/2503.10925v1",
      "published_date": "2025-03-13 22:19:05 UTC",
      "updated_date": "2025-03-13 22:19:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:34:09.724820"
    },
    {
      "arxiv_id": "2503.10918v2",
      "title": "Resource Heterogeneity-Aware and Utilization-Enhanced Scheduling for Deep Learning Clusters",
      "title_zh": "资源异构感知和利用率增强的深度学习集群调度",
      "authors": [
        "Abeda Sultana",
        "Nabin Pakka",
        "Fei Xu",
        "Xu Yuan",
        "Li Chen",
        "Nian-Feng Tzeng"
      ],
      "abstract": "Scheduling deep learning (DL) models to train on powerful clusters with\naccelerators like GPUs and TPUs, presently falls short, either lacking\nfine-grained heterogeneity awareness or leaving resources substantially\nunder-utilized. To fill this gap, we propose a novel design of a task-level\nheterogeneity-aware scheduler, Hadar, based on an optimization framework that\ncan boost resource utilization. Hadar leverages the performance traits of DL\njobs on a heterogeneous DL cluster, characterizes the task-level performance\nheterogeneity in the optimization problem, and makes scheduling decisions\nacross both spatial and temporal dimensions. It involves the primal-dual\nframework employing a dual subroutine, to solve the optimization problem and\nguide the scheduling design. Our trace-driven simulation with representative DL\nmodel training workloads demonstrates that Hadar accelerates the total time\nduration by 1.20x when compared with its state-of-the-art heterogeneity-aware\ncounterpart, Gavel. Further, our Hadar scheduler is enhanced to HadarE by\nforking each job into multiple copies to let a job train concurrently on\nheterogeneous GPUs resided on separate available nodes (i.e., machines or\nservers) for resource utilization enhancement. HadarE is evaluated extensively\non physical DL clusters for comparison with Hadar and Gavel. With substantial\nenhancement in cluster resource utilization (by 1.45x), HadarE exhibits\nconsiderable speed-ups in DL model training, reducing the total time duration\nby 50% (or 80%) on an Amazon's AWS (or our lab) cluster, while producing\ntrained DL models with consistently better inference quality than those trained\nby Hadar.",
      "tldr_zh": "该研究针对深度学习（DL）集群中的资源异构性和利用率问题，提出了一种新型任务级调度器Hadar，该框架基于优化模型，考虑DL作业在异构集群（如GPU和TPU）上的性能特征，并在空间和时间维度上进行调度决策，利用primal-dual framework来解决优化问题。Hadar通过跟踪驱动模拟，与最先进的异构性感知调度器Gavel相比，将总训练时间缩短1.20倍。进一步增强版HadarE通过将作业分叉成多个副本，实现作业在异构GPU上的并发训练，提高集群资源利用率1.45倍，并在实际测试中将总时间减少50%（AWS集群）或80%（实验室集群），同时产生具有更好推理质量的训练模型。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG",
        "I.2.11; F.1.2"
      ],
      "primary_category": "cs.DC",
      "comment": "14 pages, 12 figures, IEEE Transactions on Computers",
      "pdf_url": "http://arxiv.org/pdf/2503.10918v2",
      "published_date": "2025-03-13 22:13:20 UTC",
      "updated_date": "2025-05-21 17:39:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:34:22.478388"
    },
    {
      "arxiv_id": "2503.22692v1",
      "title": "Enhancing Aviation Communication Transcription: Fine-Tuning Distil-Whisper with LoRA",
      "title_zh": "翻译失败",
      "authors": [
        "Shokoufeh Mirzaei",
        "Jesse Arzate",
        "Yukti Vijay"
      ],
      "abstract": "Transcription of aviation communications has several applications, from\nassisting air traffic controllers in identifying the accuracy of read-back\nerrors to search and rescue operations. Recent advances in artificial\nintelligence have provided unprecedented opportunities for improving aviation\ncommunication transcription tasks. OpenAI's Whisper is one of the leading\nautomatic speech recognition models. However, fine-tuning Whisper for aviation\ncommunication transcription is not computationally efficient. Thus, this paper\naims to use a Parameter-Efficient Fine-tuning method called Low-Rank Adaptation\nto fine-tune a more computationally efficient version of Whisper,\ndistil-Whisper. To perform the fine-tuning, we used the Air Traffic Control\nCorpus dataset from the Linguistic Data Consortium, which contains\napproximately 70 hours of controller and pilot transmissions near three major\nairports in the US. The objective was to reduce the word error rate to enhance\naccuracy in the transcription of aviation communication. First, starting with\nan initial set of hyperparameters for LoRA (Alpha = 64 and Rank = 32), we\nperformed a grid search. We applied a 5-fold cross-validation to find the best\ncombination of distil-Whisper hyperparameters. Then, we fine-tuned the model\nfor LoRA hyperparameters, achieving an impressive average word error rate of\n3.86% across five folds. This result highlights the model's potential for use\nin the cockpit.",
      "tldr_zh": "该论文旨在通过 Low-Rank Adaptation (LoRA) 微调 Distil-Whisper 模型，提高航空通信转录的准确性，以支持空管人员识别读回错误和搜索救援等应用。研究使用 Air Traffic Control Corpus 数据集（约70小时的控制员和飞行员传输）作为训练数据，从初始LoRA参数（Alpha=64和Rank=32）出发，进行网格搜索和5折交叉验证。结果显示，微调后的模型实现了平均Word Error Rate为3.86%，显著提升了转录效率，并展示了其在驾驶舱中的潜在实用价值。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "eess.AS",
      "comment": "14 pages, 4 Figures, 4 Tables, Under review by Journal of Aerospace\n  Information Systems",
      "pdf_url": "http://arxiv.org/pdf/2503.22692v1",
      "published_date": "2025-03-13 22:12:45 UTC",
      "updated_date": "2025-03-13 22:12:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:34:35.539158"
    },
    {
      "arxiv_id": "2503.10912v1",
      "title": "JPEG Compliant Compression for Both Human and Machine, A Report",
      "title_zh": "JPEG 兼容的针对人类和机器的压缩：一份报告",
      "authors": [
        "Linfeng Ye"
      ],
      "abstract": "Deep Neural Networks (DNNs) have become an integral part of our daily lives,\nespecially in vision-related applications. However, the conventional lossy\nimage compression algorithms are primarily designed for the Human Vision System\n(HVS), which can non-trivially compromise the DNNs' validation accuracy after\ncompression, as noted in \\cite{liu2018deepn}. Thus developing an image\ncompression algorithm for both human and machine (DNNs) is on the horizon.\n  To address the challenge mentioned above, in this paper, we first formulate\nthe image compression as a multi-objective optimization problem which take both\nhuman and machine prespectives into account, then we solve it by linear\ncombination, and proposed a novel distortion measure for both human and\nmachine, dubbed Human and Machine-Oriented Error (HMOE). After that, we develop\nHuman And Machine Oriented Soft Decision Quantization (HMOSDQ) based on HMOE, a\nlossy image compression algorithm for both human and machine (DNNs), and fully\ncomplied with JPEG format. In order to evaluate the performance of HMOSDQ,\nfinally we conduct the experiments for two pre-trained well-known DNN-based\nimage classifiers named Alexnet \\cite{Alexnet} and VGG-16\n\\cite{simonyan2014VGG} on two subsets of the ImageNet \\cite{deng2009imagenet}\nvalidation set: one subset included images with shorter side in the range of\n496 to 512, while the other included images with shorter side in the range of\n376 to 384. Our results demonstrate that HMOSDQ outperforms the default JPEG\nalgorithm in terms of rate-accuracy and rate-distortion performance. For the\nAlexnet comparing with the default JPEG algorithm, HMOSDQ can improve the\nvalidation accuracy by more than $0.81\\%$ at $0.61$ BPP, or equivalently reduce\nthe compression rate of default JPEG by $9.6\\times$ while maintaining the same\nvalidation accuracy.",
      "tldr_zh": "该研究针对传统图像压缩算法主要为人类视觉系统（HVS）设计而可能损害 Deep Neural Networks (DNNs) 准确性的问题，提出了一种兼顾人类和机器的多目标优化框架。作者定义了新的失真度量 Human and Machine-Oriented Error (HMOE)，并基于此开发了 Human And Machine Oriented Soft Decision Quantization (HMOSDQ) 算法，该算法兼容 JPEG 格式，通过线性组合解决优化问题。实验在 ImageNet 子集上使用 Alexnet 和 VGG-16 模型显示，HMOSDQ 在率-准确性和率-失真性能上优于默认 JPEG 算法，例如在 0.61 BPP 时，Alexnet 的验证准确性提高超过 0.81%，或在保持相同准确性时将压缩率降低 9.6 倍。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "94A34",
        "I.4; I.2"
      ],
      "primary_category": "cs.CV",
      "comment": "9 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.10912v1",
      "published_date": "2025-03-13 21:52:25 UTC",
      "updated_date": "2025-03-13 21:52:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:34:46.887247"
    },
    {
      "arxiv_id": "2503.10908v1",
      "title": "Ecological Neural Architecture Search",
      "title_zh": "生态神经架构搜索",
      "authors": [
        "Benjamin David Winter",
        "William J. Teahan"
      ],
      "abstract": "When employing an evolutionary algorithm to optimize a neural networks\narchitecture, developers face the added challenge of tuning the evolutionary\nalgorithm's own hyperparameters - population size, mutation rate, cloning rate,\nand number of generations. This paper introduces Neuvo Ecological Neural\nArchitecture Search (ENAS), a novel method that incorporates these evolutionary\nparameters directly into the candidate solutions' phenotypes, allowing them to\nevolve dynamically alongside architecture specifications. Experimental results\nacross four binary classification datasets demonstrate that ENAS not only\neliminates manual tuning of evolutionary parameters but also outperforms\ncompetitor NAS methodologies in convergence speed (reducing computational time\nby 18.3%) and accuracy (improving classification performance in 3 out of 4\ndatasets). By enabling \"greedy individuals\" to optimize resource allocation\nbased on fitness, ENAS provides an efficient, self-regulating approach to\nneural architecture search.",
      "tldr_zh": "这篇论文介绍了 Ecological Neural Architecture Search (ENAS)，一种新型神经架构搜索方法，将进化算法的超参数（如种群大小、变异率、克隆率和世代数）直接整合到候选解决方案的表型中，使这些参数能与架构规格动态共进化。ENAS 消除了手动调优进化参数的需要，并在四个二元分类数据集的实验中，实现了比竞争方法更快的收敛速度（减少 18.3% 计算时间），并在三个数据集上提升了分类准确率。通过允许“greedy individuals”基于适应度优化资源分配，ENAS 提供了一个高效、自调节的神经架构搜索框架。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "5 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.10908v1",
      "published_date": "2025-03-13 21:40:25 UTC",
      "updated_date": "2025-03-13 21:40:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:34:59.514105"
    },
    {
      "arxiv_id": "2503.10907v1",
      "title": "H2-MARL: Multi-Agent Reinforcement Learning for Pareto Optimality in Hospital Capacity Strain and Human Mobility during Epidemic",
      "title_zh": "翻译失败",
      "authors": [
        "Xueting Luo",
        "Hao Deng",
        "Jihong Yang",
        "Yao Shen",
        "Huanhuan Guo",
        "Zhiyuan Sun",
        "Mingqing Liu",
        "Jiming Wei",
        "Shengjie Zhao"
      ],
      "abstract": "The necessity of achieving an effective balance between minimizing the losses\nassociated with restricting human mobility and ensuring hospital capacity has\ngained significant attention in the aftermath of COVID-19. Reinforcement\nlearning (RL)-based strategies for human mobility management have recently\nadvanced in addressing the dynamic evolution of cities and epidemics; however,\nthey still face challenges in achieving coordinated control at the township\nlevel and adapting to cities of varying scales. To address the above issues, we\npropose a multi-agent RL approach that achieves Pareto optimality in managing\nhospital capacity and human mobility (H2-MARL), applicable across cities of\ndifferent scales. We first develop a township-level infection model with\nonline-updatable parameters to simulate disease transmission and construct a\ncity-wide dynamic spatiotemporal epidemic simulator. On this basis, H2-MARL is\ndesigned to treat each division as an agent, with a trade-off dual-objective\nreward function formulated and an experience replay buffer enriched with expert\nknowledge built. To evaluate the effectiveness of the model, we construct a\ntownship-level human mobility dataset containing over one billion records from\nfour representative cities of varying scales. Extensive experiments demonstrate\nthat H2-MARL has the optimal dual-objective trade-off capability, which can\nminimize hospital capacity strain while minimizing human mobility restriction\nloss. Meanwhile, the applicability of the proposed model to epidemic control in\ncities of varying scales is verified, which showcases its feasibility and\nversatility in practical applications.",
      "tldr_zh": "该研究提出H2-MARL，一种多智能体强化学习(multi-agent reinforcement learning)框架，旨在实现Pareto optimality，在流行病期间平衡医院容量压力(hospital capacity strain)和人类流动限制损失。框架基于一个township-level感染模型和动态时空流行病模拟器，每个行政区作为智能体，使用trade-off双目标奖励函数和包含专家知识的经验回放缓冲区进行优化。实验利用一个包含超过10亿记录的跨城市人类流动数据集证明，H2-MARL在不同规模城市中表现出最佳的双目标权衡能力，能有效最小化医院压力同时减少流动限制。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10907v1",
      "published_date": "2025-03-13 21:40:07 UTC",
      "updated_date": "2025-03-13 21:40:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:35:11.167435"
    },
    {
      "arxiv_id": "2503.10905v2",
      "title": "Learning to Inference Adaptively for Multimodal Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zhuoyan Xu",
        "Khoi Duc Nguyen",
        "Preeti Mukherjee",
        "Saurabh Bagchi",
        "Somali Chaterji",
        "Yingyu Liang",
        "Yin Li"
      ],
      "abstract": "Multimodal Large Language Models (MLLMs) have shown impressive capabilities\nin reasoning, yet come with substantial computational cost, limiting their\ndeployment in resource-constrained settings. Despite recent efforts on\nimproving the efficiency of MLLMs, prior solutions fall short in responding to\nvarying runtime conditions, in particular changing resource availability (e.g.,\ncontention due to the execution of other programs on the device). To bridge\nthis gap, we introduce AdaLLaVA, an adaptive inference framework that learns to\ndynamically reconfigure operations in an MLLM during inference, accounting for\nthe input data and a latency budget. We conduct extensive experiments across\nbenchmarks involving question-answering, reasoning, and hallucination. Our\nresults show that AdaLLaVA effectively adheres to input latency budget,\nachieving varying accuracy and latency tradeoffs at runtime. Further, we\ndemonstrate that AdaLLaVA adapts to both input latency and content, can be\nintegrated with token selection for enhanced efficiency, and generalizes across\nMLLMs. Our project webpage with code release is at\nhttps://zhuoyan-xu.github.io/ada-llava/.",
      "tldr_zh": "本研究针对Multimodal Large Language Models (MLLMs)的计算成本高和无法适应动态资源变化的问题，提出了一种自适应推理框架AdaLLaVA。该框架通过学习动态重新配置MLLMs的操作，根据输入数据和延迟预算来优化推理过程。实验结果显示，AdaLLaVA在问答、推理和幻觉基准上有效遵守延迟预算，实现准确性和延迟的灵活权衡，并能适应输入内容、与其他技术（如token selection）整合，以及在不同MLLMs上实现泛化。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10905v2",
      "published_date": "2025-03-13 21:39:38 UTC",
      "updated_date": "2025-03-17 20:35:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:35:22.602908"
    },
    {
      "arxiv_id": "2503.10894v3",
      "title": "HyperDAS: Towards Automating Mechanistic Interpretability with Hypernetworks",
      "title_zh": "翻译失败",
      "authors": [
        "Jiuding Sun",
        "Jing Huang",
        "Sidharth Baskaran",
        "Karel D'Oosterlinck",
        "Christopher Potts",
        "Michael Sklar",
        "Atticus Geiger"
      ],
      "abstract": "Mechanistic interpretability has made great strides in identifying neural\nnetwork features (e.g., directions in hidden activation space) that mediate\nconcepts(e.g., the birth year of a person) and enable predictable manipulation.\nDistributed alignment search (DAS) leverages supervision from counterfactual\ndata to learn concept features within hidden states, but DAS assumes we can\nafford to conduct a brute force search over potential feature locations. To\naddress this, we present HyperDAS, a transformer-based hypernetwork\narchitecture that (1) automatically locates the token-positions of the residual\nstream that a concept is realized in and (2) constructs features of those\nresidual stream vectors for the concept. In experiments with Llama3-8B,\nHyperDAS achieves state-of-the-art performance on the RAVEL benchmark for\ndisentangling concepts in hidden states. In addition, we review the design\ndecisions we made to mitigate the concern that HyperDAS (like all powerful\ninterpretabilty methods) might inject new information into the target model\nrather than faithfully interpreting it.",
      "tldr_zh": "该研究旨在自动化机械解释(Mechanistic Interpretability)，通过提出HyperDAS框架来解决Distributed Alignment Search (DAS)依赖暴力搜索特征位置的局限性。HyperDAS是一个基于Transformer的超网络(Hypernetworks)架构，能够自动定位概念在残差流中的token-positions，并构建这些向量的特征，从而更高效地学习隐藏状态中的概念。实验结果显示，在Llama3-8B模型上，HyperDAS在RAVEL基准测试中实现了最先进的性能，显著提升了概念分离能力。此外，研究团队通过特定设计决策确保HyperDAS忠实地解释目标模型，而非注入新信息。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.10894v3",
      "published_date": "2025-03-13 21:25:38 UTC",
      "updated_date": "2025-04-25 09:03:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:35:34.969323"
    },
    {
      "arxiv_id": "2503.10886v1",
      "title": "Taxonomic Reasoning for Rare Arthropods: Combining Dense Image Captioning and RAG for Interpretable Classification",
      "title_zh": "稀有节肢动物的分类学推理：结合密集图像描述和",
      "authors": [
        "Nathaniel Lesperance",
        "Sujeevan Ratnasingham",
        "Graham W. Taylor"
      ],
      "abstract": "In the context of pressing climate change challenges and the significant\nbiodiversity loss among arthropods, automated taxonomic classification from\norganismal images is a subject of intense research. However, traditional AI\npipelines based on deep neural visual architectures such as CNNs or ViTs face\nlimitations such as degraded performance on the long-tail of classes and the\ninability to reason about their predictions. We integrate image captioning and\nretrieval-augmented generation (RAG) with large language models (LLMs) to\nenhance biodiversity monitoring, showing particular promise for characterizing\nrare and unknown arthropod species. While a naive Vision-Language Model (VLM)\nexcels in classifying images of common species, the RAG model enables\nclassification of rarer taxa by matching explicit textual descriptions of\ntaxonomic features to contextual biodiversity text data from external sources.\nThe RAG model shows promise in reducing overconfidence and enhancing accuracy\nrelative to naive LLMs, suggesting its viability in capturing the nuances of\ntaxonomic hierarchy, particularly at the challenging family and genus levels.\nOur findings highlight the potential for modern vision-language AI pipelines to\nsupport biodiversity conservation initiatives, emphasizing the role of\ncomprehensive data curation and collaboration with citizen science platforms to\nimprove species identification, unknown species characterization and ultimately\ninform conservation strategies.",
      "tldr_zh": "本研究针对气候变化导致的节肢动物生物多样性丧失问题，提出了一种结合密集图像描述(Dense Image Captioning)和检索增强生成(RAG)技术的新方法，与大型语言模型(LLMs)整合，实现对稀有节肢动物的可解释分类。相比传统的视觉模型如CNN或ViT，该方法通过匹配文本描述和外部生物多样性数据，提升了长尾类别的分类准确性，并减少了模型的过度自信，尤其在家族和属级别表现出色。实验结果表明，RAG模型在处理常见和稀有物种时更具优势，有助于支持生物多样性监测和保护策略，通过数据整理与公民科学平台的合作，进一步改善物种识别和未知物种表征。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.IR",
        "cs.LG",
        "q-bio.PE"
      ],
      "primary_category": "cs.CV",
      "comment": "12 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.10886v1",
      "published_date": "2025-03-13 21:18:10 UTC",
      "updated_date": "2025-03-13 21:18:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:35:47.213518"
    },
    {
      "arxiv_id": "2503.11720v3",
      "title": "Fine-Tuning Diffusion Generative Models via Rich Preference Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Hanyang Zhao",
        "Haoxian Chen",
        "Yucheng Guo",
        "Genta Indra Winata",
        "Tingting Ou",
        "Ziyu Huang",
        "David D. Yao",
        "Wenpin Tang"
      ],
      "abstract": "We introduce Rich Preference Optimization (RPO), a novel pipeline that\nleverages rich feedback signals to improve the curation of preference pairs for\nfine-tuning text-to-image diffusion models. Traditional methods, like\nDiffusion-DPO, often rely solely on reward model labeling, which can be opaque,\noffer limited insights into the rationale behind preferences, and are prone to\nissues such as reward hacking or overfitting. In contrast, our approach begins\nwith generating detailed critiques of synthesized images to extract reliable\nand actionable image editing instructions. By implementing these instructions,\nwe create refined images, resulting in synthetic, informative preference pairs\nthat serve as enhanced tuning datasets. We demonstrate the effectiveness of our\npipeline and the resulting datasets in fine-tuning state-of-the-art diffusion\nmodels.",
      "tldr_zh": "该研究提出了 Rich Preference Optimization (RPO)，一种新颖的管道，用于利用丰富的反馈信号提升文本到图像扩散模型的微调过程。RPO 通过生成图像的详细批评来提取可靠的编辑指令，并应用这些指令创建精炼图像，从而产生合成且信息丰富的偏好对数据集，以解决传统方法如 Diffusion-DPO 的问题，包括奖励模型的不透明性、偏好理由缺失以及易受奖励黑客和过拟合的影响。实验结果表明，该管道和数据集在微调最先进的扩散模型时表现出色，提高了模型的性能和可靠性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.11720v3",
      "published_date": "2025-03-13 21:10:29 UTC",
      "updated_date": "2025-04-16 15:28:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:35:58.324340"
    },
    {
      "arxiv_id": "2503.10883v1",
      "title": "Chat-TS: Enhancing Multi-Modal Reasoning Over Time-Series and Natural Language Data",
      "title_zh": "翻译失败",
      "authors": [
        "Paul Quinlan",
        "Qingguo Li",
        "Xiaodan Zhu"
      ],
      "abstract": "Time-series analysis is critical for a wide range of fields such as\nhealthcare, finance, transportation, and energy, among many others. The\npractical applications often involve analyzing time-series data alongside\ncontextual information in the form of natural language to support informed\ndecisions. However, current time-series models are limited in their ability to\nperform reasoning that involves both time-series and their textual content. In\nthis work, we address this gap by introducing \\textit{Chat-TS}, a large\nlanguage model (LLM) based framework, designed to support reasoning over time\nseries and textual data. Unlike traditional models, Chat-TS integrates\ntime-series tokens into LLMs' vocabulary, enhancing its reasoning ability over\nboth modalities without compromising the core natural language capabilities,\nenabling practical analysis and reasoning across modalities. To support\nlearning and evaluation in this setup, we contribute new datasets: the\n\\textit{TS Instruct Training Dataset} which pairs diverse time-series data with\nrelevant text instructions and responses for instruction tuning, the \\textit{TS\nInstruct Question and Answer (QA) Gold Dataset} which provides multiple-choice\nquestions designed to evaluate multimodal reasoning, and a \\textit{TS Instruct\nQuantitative Probing Set} which contains a small subset of the TS Instruct QA\ntasks alongside math and decision-making questions for LLM evaluation. We\ndesigned a training strategy to preserve the inherent reasoning capabilities of\nLLMs while augmenting them for time-series reasoning. Experiments show that\nChat-TS achieves state-of-the-art performance in multi-modal reasoning tasks by\nmaintaining strong natural language proficiency while improving time-series\nreasoning. ~\\footnote{To ensure replicability and facilitate future research,\nall models, datasets, and code will be available at [\\texttt{Github-URL}].}",
      "tldr_zh": "本研究提出了Chat-TS框架，一种基于大型语言模型(LLM)的系统，用于增强时间序列(time-series)和自然语言数据的多模态推理，解决现有模型在处理两者联合分析时的局限性。Chat-TS通过将时间序列tokens集成到LLM的词汇表中，同时保留其核心自然语言能力，从而实现高效的多模态推理。研究贡献了三个新数据集，包括TS Instruct Training Dataset用于指令微调、TS Instruct QA Gold Dataset用于评估多模态推理，以及TS Instruct Quantitative Probing Set用于量化测试。实验结果显示，Chat-TS在多模态任务中达到最先进性能，同时保持了强大的自然语言处理能力。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10883v1",
      "published_date": "2025-03-13 21:05:11 UTC",
      "updated_date": "2025-03-13 21:05:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:36:10.318927"
    },
    {
      "arxiv_id": "2503.10879v2",
      "title": "Task-Specific Activation Functions for Neuroevolution using Grammatical Evolution",
      "title_zh": "翻译失败",
      "authors": [
        "Benjamin David Winter",
        "William John Teahan"
      ],
      "abstract": "Activation functions play a critical role in the performance and behaviour of\nneural networks, significantly impacting their ability to learn and generalise.\nTraditional activation functions, such as ReLU, sigmoid, and tanh, have been\nwidely used with considerable success. However, these functions may not always\nprovide optimal performance for all tasks and datasets. In this paper, we\nintroduce Neuvo GEAF - an innovative approach leveraging grammatical evolution\n(GE) to automatically evolve novel activation functions tailored to specific\nneural network architectures and datasets. Experiments conducted on well-known\nbinary classification datasets show statistically significant improvements in\nF1-score (between 2.4% and 9.4%) over ReLU using identical network\narchitectures. Notably, these performance gains were achieved without\nincreasing the network's parameter count, supporting the trend toward more\nefficient neural networks that can operate effectively on resource-constrained\nedge devices. This paper's findings suggest that evolved activation functions\ncan provide significant performance improvements for compact networks while\nmaintaining energy efficiency during both training and inference phases.",
      "tldr_zh": "本文提出 Neuvo GEAF 方法，利用 Grammatical Evolution (GE) 自动演化任务特定的激活函数，以优化神经网络的性能和泛化能力。实验在二元分类数据集上显示，与 ReLU 相比，该方法在相同网络架构下将 F1-score 提高了 2.4% 到 9.4%，且未增加参数数量。结果表明，这种演化激活函数能提升紧凑网络的效率，适用于资源受限的边缘设备，同时保持训练和推理阶段的能量效率。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "8 pages, 4 figures, IEEE",
      "pdf_url": "http://arxiv.org/pdf/2503.10879v2",
      "published_date": "2025-03-13 20:50:21 UTC",
      "updated_date": "2025-03-26 17:39:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:36:22.695876"
    },
    {
      "arxiv_id": "2503.10872v2",
      "title": "TAIJI: Textual Anchoring for Immunizing Jailbreak Images in Vision Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Xiangyu Yin",
        "Yi Qi",
        "Jinwei Hu",
        "Zhen Chen",
        "Yi Dong",
        "Xingyu Zhao",
        "Xiaowei Huang",
        "Wenjie Ruan"
      ],
      "abstract": "Vision Language Models (VLMs) have demonstrated impressive inference\ncapabilities, but remain vulnerable to jailbreak attacks that can induce\nharmful or unethical responses. Existing defence methods are predominantly\nwhite-box approaches that require access to model parameters and extensive\nmodifications, making them costly and impractical for many real-world\nscenarios. Although some black-box defences have been proposed, they often\nimpose input constraints or require multiple queries, limiting their\neffectiveness in safety-critical tasks such as autonomous driving. To address\nthese challenges, we propose a novel black-box defence framework called\n\\textbf{T}extual \\textbf{A}nchoring for \\textbf{I}mmunizing \\textbf{J}ailbreak\n\\textbf{I}mages (\\textbf{TAIJI}). TAIJI leverages key phrase-based textual\nanchoring to enhance the model's ability to assess and mitigate the harmful\ncontent embedded within both visual and textual prompts. Unlike existing\nmethods, TAIJI operates effectively with a single query during inference, while\npreserving the VLM's performance on benign tasks. Extensive experiments\ndemonstrate that TAIJI significantly enhances the safety and reliability of\nVLMs, providing a practical and efficient solution for real-world deployment.",
      "tldr_zh": "这篇论文针对 Vision Language Models (VLMs) 面临的 jailbreak attacks 问题，提出了一种新型黑盒防御框架 TAIJI，利用基于关键短语的 textual anchoring 技术来评估和缓解视觉及文本提示中的有害内容。不同于现有白盒方法，TAIJI 不需访问模型参数，仅需单次查询即可生效，同时保持 VLMs 在 benign 任务上的性能。实验结果显示，该框架显著提升了模型的安全性和可靠性，为实际部署提供了一个高效解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10872v2",
      "published_date": "2025-03-13 20:39:31 UTC",
      "updated_date": "2025-03-21 19:46:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:36:34.822123"
    },
    {
      "arxiv_id": "2503.10869v1",
      "title": "Evaluating a Novel Neuroevolution and Neural Architecture Search System",
      "title_zh": "评估一种新型神经进化与神经网络架构搜索系统",
      "authors": [
        "Benjamin David Winter",
        "William John Teahan"
      ],
      "abstract": "The choice of neural network features can have a large impact on both the\naccuracy and speed of the network. Despite the current industry shift towards\nlarge transformer models, specialized binary classifiers remain critical for\nnumerous practical applications where computational efficiency and low latency\nare essential. Neural network features tend to be developed homogeneously,\nresulting in slower or less accurate networks when testing against multiple\ndatasets. In this paper, we show the effectiveness of Neuvo NAS+ a novel Python\nimplementation of an extended Neural Architecture Search (NAS+) which allows\nthe user to optimise the training parameters of a network as well as the\nnetwork's architecture. We provide an in-depth analysis of the importance of\ncatering a network's architecture to each dataset. We also describe the design\nof the Neuvo NAS+ system that selects network features on a task-specific basis\nincluding network training hyper-parameters such as the number of epochs and\nbatch size. Results show that the Neuvo NAS+ task-specific approach\nsignificantly outperforms several machine learning approaches such as Naive\nBayes, C4.5, Support Vector Machine and a standard Artificial Neural Network\nfor solving a range of binary classification problems in terms of accuracy. Our\nexperiments demonstrate substantial diversity in evolved network architectures\nacross different datasets, confirming the value of task-specific optimization.\nAdditionally, Neuvo NAS+ outperforms other evolutionary algorithm optimisers in\nterms of both accuracy and computational efficiency, showing that properly\noptimized binary classifiers can match or exceed the performance of more\ncomplex models while requiring significantly fewer computational resources.",
      "tldr_zh": "这篇论文评估了Neuvo NAS+，一个新型的神经演化和Neural Architecture Search (NAS+)系统，用于优化神经网络的架构和训练参数，以提升二进制分类器的准确性和计算效率。该系统允许针对特定数据集定制网络特征，包括训练超参数如epochs和batch size，结果显示Neuvo NAS+在多种二进制分类问题上显著优于Naive Bayes、C4.5、Support Vector Machine和标准Artificial Neural Network。实验证实，不同数据集的演化网络架构表现出显著多样性，突显了任务特定优化的价值。此外，Neuvo NAS+在准确性和计算效率上超越其他进化算法优化器，证明优化后的binary classifiers能匹配或超过复杂模型的性能，同时显著减少计算资源需求。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "10 pages, 5 figures, IEEE",
      "pdf_url": "http://arxiv.org/pdf/2503.10869v1",
      "published_date": "2025-03-13 20:35:34 UTC",
      "updated_date": "2025-03-13 20:35:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:36:48.407015"
    },
    {
      "arxiv_id": "2503.13509v1",
      "title": "MentalChat16K: A Benchmark Dataset for Conversational Mental Health Assistance",
      "title_zh": "MentalChat16K：一个用于对话式心理健康辅助的基准数据集",
      "authors": [
        "Jia Xu",
        "Tianyi Wei",
        "Bojian Hou",
        "Patryk Orzechowski",
        "Shu Yang",
        "Ruochen Jin",
        "Rachael Paulbeck",
        "Joost Wagenaar",
        "George Demiris",
        "Li Shen"
      ],
      "abstract": "We introduce MentalChat16K, an English benchmark dataset combining a\nsynthetic mental health counseling dataset and a dataset of anonymized\ntranscripts from interventions between Behavioral Health Coaches and Caregivers\nof patients in palliative or hospice care. Covering a diverse range of\nconditions like depression, anxiety, and grief, this curated dataset is\ndesigned to facilitate the development and evaluation of large language models\nfor conversational mental health assistance. By providing a high-quality\nresource tailored to this critical domain, MentalChat16K aims to advance\nresearch on empathetic, personalized AI solutions to improve access to mental\nhealth support services. The dataset prioritizes patient privacy, ethical\nconsiderations, and responsible data usage. MentalChat16K presents a valuable\nopportunity for the research community to innovate AI technologies that can\npositively impact mental well-being.",
      "tldr_zh": "我们介绍了 MentalChat16K，这是一个英文基准数据集（benchmark dataset），用于评估和开发大型语言模型（large language models）在对话式心理健康辅助（conversational mental health assistance）方面的性能。该数据集结合了合成的心智健康咨询数据和匿名化干预转录，涵盖了如 depression、anxiety 和 grief 等多种心理健康问题，并优先考虑患者隐私、伦理考虑和负责任数据使用。通过提供高质量资源，MentalChat16K 旨在推动富有同情心和个性化的 AI 解决方案，改善心理健康支持服务的可及性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CY",
        "cs.HC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.13509v1",
      "published_date": "2025-03-13 20:25:10 UTC",
      "updated_date": "2025-03-13 20:25:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:36:59.777664"
    },
    {
      "arxiv_id": "2503.10857v1",
      "title": "Towards Understanding Graphical Perception in Large Multimodal Models",
      "title_zh": "翻译失败",
      "authors": [
        "Kai Zhang",
        "Jianwei Yang",
        "Jeevana Priya Inala",
        "Chandan Singh",
        "Jianfeng Gao",
        "Yu Su",
        "Chenglong Wang"
      ],
      "abstract": "Despite the promising results of large multimodal models (LMMs) in complex\nvision-language tasks that require knowledge, reasoning, and perception\nabilities together, we surprisingly found that these models struggle with\nsimple tasks on infographics that require perception only. As existing\nbenchmarks primarily focus on end tasks that require various abilities, they\nprovide limited, fine-grained insights into the limitations of the models'\nperception abilities. To address this gap, we leverage the theory of graphical\nperception, an approach used to study how humans decode visual information\nencoded on charts and graphs, to develop an evaluation framework for analyzing\ngaps in LMMs' perception abilities in charts. With automated task generation\nand response evaluation designs, our framework enables comprehensive and\ncontrolled testing of LMMs' graphical perception across diverse chart types,\nvisual elements, and task types. We apply our framework to evaluate and\ndiagnose the perception capabilities of state-of-the-art LMMs at three\ngranularity levels (chart, visual element, and pixel). Our findings underscore\nseveral critical limitations of current state-of-the-art LMMs, including\nGPT-4o: their inability to (1) generalize across chart types, (2) understand\nfundamental visual elements, and (3) cross reference values within a chart.\nThese insights provide guidance for future improvements in perception abilities\nof LMMs. The evaluation framework and labeled data are publicly available at\nhttps://github.com/microsoft/lmm-graphical-perception.",
      "tldr_zh": "这篇论文探讨了大型多模态模型 (LMMs) 在图形感知方面的局限性，尽管它们在需要知识和推理的复杂任务上表现出色，却在仅需感知的图表任务上挣扎。研究者基于图形感知理论开发了一个评估框架，通过自动化任务生成和响应评估，系统测试 LMMs 在不同图表类型、视觉元素和任务类型上的感知能力。实验结果显示，当前最先进模型如 GPT-4o 存在关键问题，包括无法泛化到各种图表类型、理解基本视觉元素以及在图表内交叉引用值。这些发现为提升 LMMs 的感知能力提供了重要指导，并公开了框架和标注数据。",
      "categories": [
        "cs.GR",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.GR",
      "comment": "Work in Progress",
      "pdf_url": "http://arxiv.org/pdf/2503.10857v1",
      "published_date": "2025-03-13 20:13:39 UTC",
      "updated_date": "2025-03-13 20:13:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:37:12.147045"
    },
    {
      "arxiv_id": "2504.15286v1",
      "title": "CUBETESTERAI: Automated JUnit Test Generation using the LLaMA Model",
      "title_zh": "CUBETESTERAI：基于 LLaMA 模型的自动 JUnit 测试生成",
      "authors": [
        "Daniele Gorla",
        "Shivam Kumar",
        "Pietro Nicolaus Roselli Lorenzini",
        "Alireza Alipourfaz"
      ],
      "abstract": "This paper presents an approach to automating JUnit test generation for Java\napplications using the Spring Boot framework, leveraging the LLaMA (Large\nLanguage Model Architecture) model to enhance the efficiency and accuracy of\nthe testing process. The resulting tool, called CUBETESTERAI, includes a\nuser-friendly web interface and the integration of a CI/CD pipeline using\nGitLab and Docker. These components streamline the automated test generation\nprocess, allowing developers to generate JUnit tests directly from their code\nsnippets with minimal manual intervention. The final implementation executes\nthe LLaMA models through RunPod, an online GPU service, which also enhances the\nprivacy of our tool. Using the advanced natural language processing\ncapabilities of the LLaMA model, CUBETESTERAI is able to generate test cases\nthat provide high code coverage and accurate validation of software\nfunctionalities in Java-based Spring Boot applications. Furthermore, it\nefficiently manages resource-intensive operations and refines the generated\ntests to address common issues like missing imports and handling of private\nmethods. By comparing CUBETESTERAI with some state-of-the-art tools, we show\nthat our proposal consistently demonstrates competitive and, in many cases,\nbetter performance in terms of code coverage in different real-life Java\nprograms.",
      "tldr_zh": "这篇论文介绍了 CUBETESTERAI，一种利用 LLaMA 模型自动生成 JUnit 测试的工具，针对 Java 应用特别是 Spring Boot 框架，以提高测试效率和准确性。该工具集成了用户友好的 web 接口、CI/CD 管道（使用 GitLab 和 Docker），并通过 RunPod 平台执行模型，确保隐私保护和资源管理，同时能生成高代码覆盖率的测试用例并修复常见问题如缺失导入和私有方法处理。与现有工具相比，CUBETESTERAI 在真实 Java 程序的代码覆盖率上表现出色，甚至在许多情况下更具竞争力。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted to ICST 2025 Industry Track",
      "pdf_url": "http://arxiv.org/pdf/2504.15286v1",
      "published_date": "2025-03-13 19:44:09 UTC",
      "updated_date": "2025-03-13 19:44:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:37:22.879814"
    },
    {
      "arxiv_id": "2503.13508v1",
      "title": "It is Too Many Options: Pitfalls of Multiple-Choice Questions in Generative AI and Medical Education",
      "title_zh": "翻译失败",
      "authors": [
        "Shrutika Singh",
        "Anton Alyakin",
        "Daniel Alexander Alber",
        "Jaden Stryker",
        "Ai Phuong S Tong",
        "Karl Sangwon",
        "Nicolas Goff",
        "Mathew de la Paz",
        "Miguel Hernandez-Rovira",
        "Ki Yun Park",
        "Eric Claude Leuthardt",
        "Eric Karl Oermann"
      ],
      "abstract": "The performance of Large Language Models (LLMs) on multiple-choice question\n(MCQ) benchmarks is frequently cited as proof of their medical capabilities. We\nhypothesized that LLM performance on medical MCQs may in part be illusory and\ndriven by factors beyond medical content knowledge and reasoning capabilities.\nTo assess this, we created a novel benchmark of free-response questions with\npaired MCQs (FreeMedQA). Using this benchmark, we evaluated three\nstate-of-the-art LLMs (GPT-4o, GPT-3.5, and LLama-3-70B-instruct) and found an\naverage absolute deterioration of 39.43% in performance on free-response\nquestions relative to multiple-choice (p = 1.3 * 10-5) which was greater than\nthe human performance decline of 22.29%. To isolate the role of the MCQ format\non performance, we performed a masking study, iteratively masking out parts of\nthe question stem. At 100% masking, the average LLM multiple-choice performance\nwas 6.70% greater than random chance (p = 0.002) with one LLM (GPT-4o)\nobtaining an accuracy of 37.34%. Notably, for all LLMs the free-response\nperformance was near zero. Our results highlight the shortcomings in medical\nMCQ benchmarks for overestimating the capabilities of LLMs in medicine, and,\nbroadly, the potential for improving both human and machine assessments using\nLLM-evaluated free-response questions.",
      "tldr_zh": "该研究质疑了大型语言模型(LLM)在医学多项选择题(MCQ)上的表现是否真正反映其能力，假设这种表现可能受格式影响而非纯知识推理。研究者创建了新基准FreeMedQA，包括自由响应问题和配对MCQ，并评估了GPT-4o、GPT-3.5和Llama-3-70B-instruct等模型，结果显示LLM在自由响应问题上的平均表现下降39.43%，远高于人类的22.29%。通过掩盖实验，进一步发现完全掩盖问题后，LLM的MCQ准确率仅比随机机会高6.70%，而自由响应表现接近零。这些发现强调，医学MCQ基准可能高估了LLM的能力，并建议采用LLM评估的自由响应问题来改进人类和机器评估。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "14 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.13508v1",
      "published_date": "2025-03-13 19:42:04 UTC",
      "updated_date": "2025-03-13 19:42:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:37:35.441043"
    },
    {
      "arxiv_id": "2503.13507v1",
      "title": "NeurIPS 2023 LLM Efficiency Fine-tuning Competition",
      "title_zh": "NeurIPS 2023 大型语言模型效率微调竞赛",
      "authors": [
        "Mark Saroufim",
        "Yotam Perlitz",
        "Leshem Choshen",
        "Luca Antiga",
        "Greg Bowyer",
        "Christian Puhrsch",
        "Driss Guessous",
        "Supriya Rao",
        "Geeta Chauhan",
        "Ashvini Kumar",
        "Jindal Pawan Kumar",
        "Rajpoot Ankur Parikh",
        "Joe Isaacson",
        "Weiwei Yang"
      ],
      "abstract": "Our analysis of the NeurIPS 2023 large language model (LLM) fine-tuning\ncompetition revealed the following trend: top-performing models exhibit\nsignificant overfitting on benchmark datasets, mirroring the broader issue of\nbenchmark overfitting on popular leaderboards and that data curation is\nessential in order to get a high performing LLM. The competition, which\nconsisted of two stages - an open evaluation stage with publicly available\ntasks and a closed evaluation stage with unseen tasks - allowed us to assess\nthe generalizability of fine-tuned LLMs. Our results highlight the limitations\nof current benchmark-based evaluation schemes for generative models and\ndemonstrate the need for more robust evaluation methods. Notably, the winning\nsubmissions utilized standard open-source libraries and focused primarily on\ndata curation. To facilitate further research and promote reproducibility, we\nrelease all competition entries, Docker files, and evaluation infrastructure,\nproviding a valuable resource for the community to explore fine-tuning,\noverfitting, and reproducibility in LLMs.",
      "tldr_zh": "这篇论文分析了 NeurIPS 2023 LLM 效率微调竞赛，发现顶尖模型在基准数据集上存在显著过度拟合问题，这反映了流行排行榜的更广泛挑战，并强调数据 curation 是获得高性能 LLM 的关键。竞赛包括公开评估阶段（使用公开任务）和闭合评估阶段（使用未见任务），用于评估微调 LLM 的泛化能力，结果突出了当前基准评估方案的局限性，并呼吁更稳健的评估方法。获胜提交主要依赖标准开源库和数据整理策略，为社区提供了所有竞赛条目、Docker 文件和评估基础设施，以促进 LLM 微调、overfitting 和可重复性的进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "11 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.13507v1",
      "published_date": "2025-03-13 19:35:40 UTC",
      "updated_date": "2025-03-13 19:35:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:37:47.739526"
    },
    {
      "arxiv_id": "2503.10822v4",
      "title": "Reinforcement Learning and Life Cycle Assessment for a Circular Economy -- Towards Progressive Computer Science",
      "title_zh": "翻译失败",
      "authors": [
        "Johannes Buchner"
      ],
      "abstract": "The aim of this paper is to discuss the potential of using methods from\nReinforcement Learning for Life Cycle Assessment in a circular economy, and to\npresent some new ideas in this direction. To give some context, we explain how\nReinforcement Learning was successfully applied in computer chess (and beyond).\nAs computer chess was historically called the \"drosophila of AI\", we start by\ndescribing a method for the board representation called 'rotated bitboards'\nthat can potentially also be applied in the context of sustainability. In the\nfirst part of this paper, the concepts of the bitboard-representation and the\nadvantages of (rotated) bitboards in move generation are explained. In order to\nillustrate those ideas practice, the concrete implementation of the\nmove-generator in FUSc# (a chess engine developed at FU Berlin in C# some years\nago) is described. In addition, rotated binary neural networks are discussed\nbriefly.\n  The second part deals with reinforcement learning in computer chess (and\nbeyond). We exemplify the progress that has been made in this field in the last\n15-20 years by comparing the \"state of the art\" from 2002-2008, when FUSc# was\ndeveloped, with the ground-breaking innovations connected to \"AlphaZero\". We\nreview some application of the ideas developed in AlphaZero in other domains,\ne.g. the \"other Alphas\" like AlphaFold, AlphaTensor, AlphaGeometry and\nAlphaProof. In the final part of the paper, we discuss the computer-science\nrelated challenges that changing the economic paradigm towards (absolute)\nsustainability poses and in how far what we call 'progressive computer science'\nneeds to contribute. Concrete challenges include the closing of material loops\nin a circular economy with Life Cycle Assessment in order to optimize for\n(absolute) sustainability, and we present some new ideas in this direction.",
      "tldr_zh": "这篇论文探讨了使用强化学习(Reinforcement Learning)方法应用于生命周期评估(Life Cycle Assessment)，以支持循环经济(Circular Economy)并推动“进步计算机科学”(Progressive Computer Science)。论文首先介绍bitboard表示法，特别是rotated bitboards，在计算机国际象棋中的优势，并描述其在FUSc#棋引擎中的实际实现，以及rotated binary neural networks的简要讨论。接着，回顾强化学习在棋类AI中的演进，从2002-2008年的状态到AlphaZero的突破性创新，并扩展到其他领域如AlphaFold和AlphaGeometry的应用。最后，论文提出新想法，强调计算机科学在实现绝对可持续性中的角色，包括优化材料循环和生命周期评估，以应对循环经济面临的挑战。",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "Minor corrections, e.g. in the bibliography",
      "pdf_url": "http://arxiv.org/pdf/2503.10822v4",
      "published_date": "2025-03-13 19:13:51 UTC",
      "updated_date": "2025-05-17 20:47:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:38:00.073509"
    },
    {
      "arxiv_id": "2503.13505v1",
      "title": "Ensemble Learning for Large Language Models in Text and Code Generation: A Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Mari Ashiga",
        "Wei Jie",
        "Fan Wu",
        "Vardan Voskanyan",
        "Fateme Dinmohammadi",
        "Paul Brookes",
        "Jingzhi Gong",
        "Zheng Wang"
      ],
      "abstract": "Generative pretrained transformers (GPT) are the common large language models\n(LLMs) used for generating text from natural language inputs. However, the\nfixed properties of language parameters in individual LLMs can lead to\ninconsistencies in the generated outputs. This limitation also restricts the\nmodels' ability to represent diverse language patterns due to inherent biases.\nMoreover, many powerful LLMs are closed-source. This prevents organizations\nfrom integrating their data into these systems, raising concerns about data\nprivacy and limiting industry applications. Inspired by the successful\napplication of LLM ensemble models in text generation, recent literature has\nalso investigated their potential in code generation. This article reviews\nthese emerging LLM ensemble approaches. Our goal is to enhance readers'\nunderstanding of existing techniques and encourage further research and\npractical implementation, aiming to expand the real-world applications of LLM\nensemble models in both text and code generation. We categorize these\napproaches into seven main methods: weight merging, knowledge fusion, mixture\nof experts, reward ensemble, output ensemble, routing, and cascading. From this\nlist, we focus on four methods and models that show strong performance and\npotential for broader applications. We analyze their modeling steps, training\nmethods, and output features to provide a clear understanding of their\ncapabilities. Our findings highlight the benefits of LLM ensemble techniques.\nThese include better representation of diversity, improved output quality, and\ngreater flexibility in applications. This information offers valuable insights\nfor selecting models for various real-world tasks involving text and code\ngeneration, and potentially applying methods to multimodal LLMs.",
      "tldr_zh": "这篇论文调查了集成学习（Ensemble Learning）在大型语言模型（LLMs）用于文本和代码生成中的应用，旨在解决LLMs的输出不一致、固有偏见以及闭源模型带来的数据隐私问题。作者将现有方法分为七类，包括weight merging、knowledge fusion、mixture of experts、reward ensemble、output ensemble、routing和cascading，并重点分析了其中四种表现出色的方法，涵盖它们的建模步骤、训练方法和输出特征。研究发现，这些集成技术显著提高了输出质量、多样性表示和应用灵活性，为文本、代码生成以及多模态LLMs的实际任务提供了宝贵见解，并鼓励进一步的研究和实施。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Submitted to IEEE TAI",
      "pdf_url": "http://arxiv.org/pdf/2503.13505v1",
      "published_date": "2025-03-13 18:50:57 UTC",
      "updated_date": "2025-03-13 18:50:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:38:12.022345"
    },
    {
      "arxiv_id": "2503.16507v1",
      "title": "Fewer Than 1% of Explainable AI Papers Validate Explainability with Humans",
      "title_zh": "少于1%的可解释AI论文通过人类验证可解释性",
      "authors": [
        "Ashley Suh",
        "Isabelle Hurley",
        "Nora Smith",
        "Ho Chit Siu"
      ],
      "abstract": "This late-breaking work presents a large-scale analysis of explainable AI\n(XAI) literature to evaluate claims of human explainability. We collaborated\nwith a professional librarian to identify 18,254 papers containing keywords\nrelated to explainability and interpretability. Of these, we find that only 253\npapers included terms suggesting human involvement in evaluating an XAI\ntechnique, and just 128 of those conducted some form of a human study. In other\nwords, fewer than 1% of XAI papers (0.7%) provide empirical evidence of human\nexplainability when compared to the broader body of XAI literature. Our\nfindings underscore a critical gap between claims of human explainability and\nevidence-based validation, raising concerns about the rigor of XAI research. We\ncall for increased emphasis on human evaluations in XAI studies and provide our\nliterature search methodology to enable both reproducibility and further\ninvestigation into this widespread issue.",
      "tldr_zh": "这篇论文通过大规模分析18,254篇Explainable AI (XAI)文献，发现仅有0.7%的论文（即128篇）通过人类研究验证了解释性，突显了XAI领域中声明人类explainability与实际证据之间的重大差距。研究者与专业图书管理员合作，使用关键词搜索和筛选方法，评估了这些论文中人类参与的程度。结果表明，大多数XAI研究缺乏实证验证，这引发了对研究严谨性的担忧，并呼吁未来工作加强人类评估，同时提供文献搜索方法以促进可重复性。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "Extended Abstracts of the CHI Conference on Human Factors in\n  Computing Systems (CHI EA '25)",
      "pdf_url": "http://arxiv.org/pdf/2503.16507v1",
      "published_date": "2025-03-13 18:39:50 UTC",
      "updated_date": "2025-03-13 18:39:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:38:22.720791"
    },
    {
      "arxiv_id": "2503.10792v1",
      "title": "Byzantine-Resilient Federated Learning via Distributed Optimization",
      "title_zh": "通过分布式优化的拜占庭容错联邦学习",
      "authors": [
        "Yufei Xia",
        "Wenrui Yu",
        "Qiongxiu Li"
      ],
      "abstract": "Byzantine attacks present a critical challenge to Federated Learning (FL),\nwhere malicious participants can disrupt the training process, degrade model\naccuracy, and compromise system reliability. Traditional FL frameworks\ntypically rely on aggregation-based protocols for model updates, leaving them\nvulnerable to sophisticated adversarial strategies. In this paper, we\ndemonstrate that distributed optimization offers a principled and robust\nalternative to aggregation-centric methods. Specifically, we show that the\nPrimal-Dual Method of Multipliers (PDMM) inherently mitigates Byzantine impacts\nby leveraging its fault-tolerant consensus mechanism. Through extensive\nexperiments on three datasets (MNIST, FashionMNIST, and Olivetti), under\nvarious attack scenarios including bit-flipping and Gaussian noise injection,\nwe validate the superior resilience of distributed optimization protocols.\nCompared to traditional aggregation-centric approaches, PDMM achieves higher\nmodel utility, faster convergence, and improved stability. Our results\nhighlight the effectiveness of distributed optimization in defending against\nByzantine threats, paving the way for more secure and resilient federated\nlearning systems.",
      "tldr_zh": "本论文探讨了Byzantine attacks对Federated Learning (FL)的威胁，提出使用distributed optimization作为更鲁棒的替代方案，以缓解恶意参与者对模型训练的影响。具体而言，作者展示了Primal-Dual Method of Multipliers (PDMM)通过其fault-tolerant consensus mechanism，实现了对攻击的内在抵抗。在MNIST、FashionMNIST和Olivetti数据集上的实验中，PDMM在bit-flipping和Gaussian noise injection等场景下，比传统aggregation-centric方法表现出更高的模型utility、更快的convergence和更好的稳定性，最终为构建更安全可靠的FL系统奠定了基础。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10792v1",
      "published_date": "2025-03-13 18:34:42 UTC",
      "updated_date": "2025-03-13 18:34:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:38:35.772446"
    },
    {
      "arxiv_id": "2503.10784v1",
      "title": "Vulnerability Detection: From Formal Verification to Large Language Models and Hybrid Approaches: A Comprehensive Overview",
      "title_zh": "翻译失败",
      "authors": [
        "Norbert Tihanyi",
        "Tamas Bisztray",
        "Mohamed Amine Ferrag",
        "Bilel Cherif",
        "Richard A. Dubniczky",
        "Ridhi Jain",
        "Lucas C. Cordeiro"
      ],
      "abstract": "Software testing and verification are critical for ensuring the reliability\nand security of modern software systems. Traditionally, formal verification\ntechniques, such as model checking and theorem proving, have provided rigorous\nframeworks for detecting bugs and vulnerabilities. However, these methods often\nface scalability challenges when applied to complex, real-world programs.\nRecently, the advent of Large Language Models (LLMs) has introduced a new\nparadigm for software analysis, leveraging their ability to understand insecure\ncoding practices. Although LLMs demonstrate promising capabilities in tasks\nsuch as bug prediction and invariant generation, they lack the formal\nguarantees of classical methods. This paper presents a comprehensive study of\nstate-of-the-art software testing and verification, focusing on three key\napproaches: classical formal methods, LLM-based analysis, and emerging hybrid\ntechniques, which combine their strengths. We explore each approach's\nstrengths, limitations, and practical applications, highlighting the potential\nof hybrid systems to address the weaknesses of standalone methods. We analyze\nwhether integrating formal rigor with LLM-driven insights can enhance the\neffectiveness and scalability of software verification, exploring their\nviability as a pathway toward more robust and adaptive testing frameworks.",
      "tldr_zh": "这篇论文提供了软件漏洞检测领域的全面概述，探讨了从传统形式验证（如模型检查和定理证明）到 Large Language Models (LLMs) 的演变，以及新兴的混合方法。形式验证方法虽具有严格的可靠性，但面临可扩展性挑战，而 LLMs 则擅长识别不安全编码实践但缺乏正式保证。论文分析了这些方法的优势、局限性和实际应用，强调混合方法通过整合形式验证的严谨性和 LLMs 的洞察力，能够提升软件验证的有效性、可扩展性和适应性，从而为更稳健的测试框架铺平道路。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10784v1",
      "published_date": "2025-03-13 18:22:22 UTC",
      "updated_date": "2025-03-13 18:22:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:38:46.633196"
    },
    {
      "arxiv_id": "2503.10638v1",
      "title": "Studying Classifier(-Free) Guidance From a Classifier-Centric Perspective",
      "title_zh": "从分类器中心的视角研究分类器（无）指导",
      "authors": [
        "Xiaoming Zhao",
        "Alexander G. Schwing"
      ],
      "abstract": "Classifier-free guidance has become a staple for conditional generation with\ndenoising diffusion models. However, a comprehensive understanding of\nclassifier-free guidance is still missing. In this work, we carry out an\nempirical study to provide a fresh perspective on classifier-free guidance.\nConcretely, instead of solely focusing on classifier-free guidance, we trace\nback to the root, i.e., classifier guidance, pinpoint the key assumption for\nthe derivation, and conduct a systematic study to understand the role of the\nclassifier. We find that both classifier guidance and classifier-free guidance\nachieve conditional generation by pushing the denoising diffusion trajectories\naway from decision boundaries, i.e., areas where conditional information is\nusually entangled and is hard to learn. Based on this classifier-centric\nunderstanding, we propose a generic postprocessing step built upon\nflow-matching to shrink the gap between the learned distribution for a\npre-trained denoising diffusion model and the real data distribution, majorly\naround the decision boundaries. Experiments on various datasets verify the\neffectiveness of the proposed approach.",
      "tldr_zh": "本研究从分类器角度出发，对分类器引导(classifier guidance)和无分类器引导(classifier-free guidance)进行了系统实证分析，发现两者均通过推动去噪扩散(denoising diffusion)轨迹远离决策边界来实现条件生成，从而解决条件信息在边界区域的纠缠问题。论文追溯了分类器引导的关键假设，并强调了分类器在这一过程中的核心作用。基于这些发现，研究提出了一种通用的后期处理步骤，利用流匹配(flow-matching)来缩小预训练去噪扩散模型的分布与真实数据分布的差距，尤其在决策边界附近。实验在多种数据集上验证了该方法的有效性，展示了其在提升条件生成性能方面的潜力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10638v1",
      "published_date": "2025-03-13 17:59:59 UTC",
      "updated_date": "2025-03-13 17:59:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:38:58.699375"
    },
    {
      "arxiv_id": "2503.10635v1",
      "title": "A Frustratingly Simple Yet Highly Effective Attack Baseline: Over 90% Success Rate Against the Strong Black-box Models of GPT-4.5/4o/o1",
      "title_zh": "翻译失败",
      "authors": [
        "Zhaoyi Li",
        "Xiaohan Zhao",
        "Dong-Dong Wu",
        "Jiacheng Cui",
        "Zhiqiang Shen"
      ],
      "abstract": "Despite promising performance on open-source large vision-language models\n(LVLMs), transfer-based targeted attacks often fail against black-box\ncommercial LVLMs. Analyzing failed adversarial perturbations reveals that the\nlearned perturbations typically originate from a uniform distribution and lack\nclear semantic details, resulting in unintended responses. This critical\nabsence of semantic information leads commercial LVLMs to either ignore the\nperturbation entirely or misinterpret its embedded semantics, thereby causing\nthe attack to fail. To overcome these issues, we notice that identifying core\nsemantic objects is a key objective for models trained with various datasets\nand methodologies. This insight motivates our approach that refines semantic\nclarity by encoding explicit semantic details within local regions, thus\nensuring interoperability and capturing finer-grained features, and by\nconcentrating modifications on semantically rich areas rather than applying\nthem uniformly. To achieve this, we propose a simple yet highly effective\nsolution: at each optimization step, the adversarial image is cropped randomly\nby a controlled aspect ratio and scale, resized, and then aligned with the\ntarget image in the embedding space. Experimental results confirm our\nhypothesis. Our adversarial examples crafted with local-aggregated\nperturbations focused on crucial regions exhibit surprisingly good\ntransferability to commercial LVLMs, including GPT-4.5, GPT-4o,\nGemini-2.0-flash, Claude-3.5-sonnet, Claude-3.7-sonnet, and even reasoning\nmodels like o1, Claude-3.7-thinking and Gemini-2.0-flash-thinking. Our approach\nachieves success rates exceeding 90% on GPT-4.5, 4o, and o1, significantly\noutperforming all prior state-of-the-art attack methods. Our optimized\nadversarial examples under different configurations and training code are\navailable at https://github.com/VILA-Lab/M-Attack.",
      "tldr_zh": "该论文分析了基于转移的针对性攻击在黑箱商业 LVLMs（如 GPT-4.5、GPT-4o 和 o1）上失败的原因，主要由于对抗扰动(adversarial perturbations)缺乏语义细节，导致模型忽略或误解。作者提出一种简单有效的方法，通过在每个优化步骤中随机裁剪、缩放对抗图像并在嵌入空间与目标图像对齐，从而增强局部区域的语义清晰度和聚焦于关键特征。实验结果显示，该方法生成的对抗样本在多种商业 LVLMs 上表现出极高转移性，成功率超过 90%，远超现有状态-of-the-art 攻击方法，并提供了开源代码以供进一步研究。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Code at: https://github.com/VILA-Lab/M-Attack",
      "pdf_url": "http://arxiv.org/pdf/2503.10635v1",
      "published_date": "2025-03-13 17:59:55 UTC",
      "updated_date": "2025-03-13 17:59:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:39:12.291920"
    },
    {
      "arxiv_id": "2503.10628v1",
      "title": "Uncertainty in Action: Confidence Elicitation in Embodied Agents",
      "title_zh": "行动中的不确定性：具身代理中的置信度提取",
      "authors": [
        "Tianjiao Yu",
        "Vedant Shah",
        "Muntasir Wahed",
        "Kiet A. Nguyen",
        "Adheesh Juvekar",
        "Tal August",
        "Ismini Lourentzou"
      ],
      "abstract": "Expressing confidence is challenging for embodied agents navigating dynamic\nmultimodal environments, where uncertainty arises from both perception and\ndecision-making processes. We present the first work investigating embodied\nconfidence elicitation in open-ended multimodal environments. We introduce\nElicitation Policies, which structure confidence assessment across inductive,\ndeductive, and abductive reasoning, along with Execution Policies, which\nenhance confidence calibration through scenario reinterpretation, action\nsampling, and hypothetical reasoning. Evaluating agents in calibration and\nfailure prediction tasks within the Minecraft environment, we show that\nstructured reasoning approaches, such as Chain-of-Thoughts, improve confidence\ncalibration. However, our findings also reveal persistent challenges in\ndistinguishing uncertainty, particularly under abductive settings, underscoring\nthe need for more sophisticated embodied confidence elicitation methods.",
      "tldr_zh": "该论文探讨了具身代理（embodied agents）在动态多模态环境中表达信心的挑战，特别是在感知和决策过程中的不确定性。研究首次引入Elicitation Policies来结构化信心评估，包括inductive、deductive和abductive推理，以及Execution Policies通过场景重新解释、行动采样和假设推理来提升信心校准。在Minecraft环境中的实验显示，Chain-of-Thoughts等结构化方法显著改善了信心校准和失败预测性能，但abductive设置下区分不确定性仍面临困难，突显了需要更先进的具身信心激发方法。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Project page: https://plan-lab.github.io/ece/",
      "pdf_url": "http://arxiv.org/pdf/2503.10628v1",
      "published_date": "2025-03-13 17:59:41 UTC",
      "updated_date": "2025-03-13 17:59:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:39:25.903960"
    },
    {
      "arxiv_id": "2503.10627v1",
      "title": "SciVerse: Unveiling the Knowledge Comprehension and Visual Reasoning of LMMs on Multi-modal Scientific Problems",
      "title_zh": "翻译失败",
      "authors": [
        "Ziyu Guo",
        "Ray Zhang",
        "Hao Chen",
        "Jialin Gao",
        "Dongzhi Jiang",
        "Jiaze Wang",
        "Pheng-Ann Heng"
      ],
      "abstract": "The rapid advancement of Large Multi-modal Models (LMMs) has enabled their\napplication in scientific problem-solving, yet their fine-grained capabilities\nremain under-explored. In this paper, we introduce SciVerse, a multi-modal\nscientific evaluation benchmark to thoroughly assess LMMs across 5,735 test\ninstances in five distinct versions. We aim to investigate three key dimensions\nof LMMs: scientific knowledge comprehension, multi-modal content\ninterpretation, and Chain-of-Thought (CoT) reasoning. To unveil whether LMMs\npossess sufficient scientific expertise, we first transform each problem into\nthree versions containing different levels of knowledge required for solving,\ni.e., Knowledge-free, -lite, and -rich. Then, to explore how LMMs interpret\nmulti-modal scientific content, we annotate another two versions, i.e.,\nVision-rich and -only, marking more question information from texts to\ndiagrams. Comparing the results of different versions, SciVerse systematically\nexamines the professional knowledge stock and visual perception skills of LMMs\nin scientific domains. In addition, to rigorously assess CoT reasoning, we\npropose a new scientific CoT evaluation strategy, conducting a step-wise\nassessment on knowledge and logical errors in model outputs. Our extensive\nevaluation of different LMMs on SciVerse reveals critical limitations in their\nscientific proficiency and provides new insights into future developments.\nProject page: https://sciverse-cuhk.github.io",
      "tldr_zh": "本研究引入了SciVerse，这是一个多模态科学评估基准，包含5,735个测试实例的五种版本，用于评估大型多模态模型(LMMs)在科学知识理解、多模态内容解释和Chain-of-Thought (CoT)推理方面的能力。研究者通过将问题转化为Knowledge-free、-lite和-rich版本来测试LMMs的科学知识储备，以及Vision-rich和-only版本来考察其视觉感知技能，并提出一种新的CoT评估策略，对模型输出的知识和逻辑错误进行逐步分析。实验结果揭示了LMMs在科学领域的关键限制，如专业知识不足，并为未来模型开发提供了新见解。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "Initially released in September 2024. Project page:\n  https://sciverse-cuhk.github.io",
      "pdf_url": "http://arxiv.org/pdf/2503.10627v1",
      "published_date": "2025-03-13 17:59:32 UTC",
      "updated_date": "2025-03-13 17:59:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:39:34.983286"
    },
    {
      "arxiv_id": "2503.10626v1",
      "title": "NIL: No-data Imitation Learning by Leveraging Pre-trained Video Diffusion Models",
      "title_zh": "NIL：通过利用预训练视频扩散模型的无数据模仿学习",
      "authors": [
        "Mert Albaba",
        "Chenhao Li",
        "Markos Diomataris",
        "Omid Taheri",
        "Andreas Krause",
        "Michael Black"
      ],
      "abstract": "Acquiring physically plausible motor skills across diverse and unconventional\nmorphologies-including humanoid robots, quadrupeds, and animals-is essential\nfor advancing character simulation and robotics. Traditional methods, such as\nreinforcement learning (RL) are task- and body-specific, require extensive\nreward function engineering, and do not generalize well. Imitation learning\noffers an alternative but relies heavily on high-quality expert demonstrations,\nwhich are difficult to obtain for non-human morphologies. Video diffusion\nmodels, on the other hand, are capable of generating realistic videos of\nvarious morphologies, from humans to ants. Leveraging this capability, we\npropose a data-independent approach for skill acquisition that learns 3D motor\nskills from 2D-generated videos, with generalization capability to\nunconventional and non-human forms. Specifically, we guide the imitation\nlearning process by leveraging vision transformers for video-based comparisons\nby calculating pair-wise distance between video embeddings. Along with\nvideo-encoding distance, we also use a computed similarity between segmented\nvideo frames as a guidance reward. We validate our method on locomotion tasks\ninvolving unique body configurations. In humanoid robot locomotion tasks, we\ndemonstrate that 'No-data Imitation Learning' (NIL) outperforms baselines\ntrained on 3D motion-capture data. Our results highlight the potential of\nleveraging generative video models for physically plausible skill learning with\ndiverse morphologies, effectively replacing data collection with data\ngeneration for imitation learning.",
      "tldr_zh": "本文提出NIL（No-data Imitation Learning）方法，利用预训练的Video Diffusion Models生成视频，实现无需实际数据的模仿学习，适用于多样形态（如人形机器人、四足动物）的物理运动技能。方法通过视觉变压器计算视频嵌入的配对距离和帧相似度作为指导奖励，从2D生成视频中学习3D运动技能，从而解决传统RL和模仿学习对专家演示的依赖。实验验证显示，NIL在步态任务中超越了基于3D动作捕捉数据的基线，提升了技能泛化能力，并展示了利用生成模型替代数据收集的潜力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10626v1",
      "published_date": "2025-03-13 17:59:24 UTC",
      "updated_date": "2025-03-13 17:59:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:39:48.131676"
    },
    {
      "arxiv_id": "2503.10625v1",
      "title": "LHM: Large Animatable Human Reconstruction Model from a Single Image in Seconds",
      "title_zh": "LHM：从单张图像在数秒内重建大型可动画化人类模型",
      "authors": [
        "Lingteng Qiu",
        "Xiaodong Gu",
        "Peihao Li",
        "Qi Zuo",
        "Weichao Shen",
        "Junfei Zhang",
        "Kejie Qiu",
        "Weihao Yuan",
        "Guanying Chen",
        "Zilong Dong",
        "Liefeng Bo"
      ],
      "abstract": "Animatable 3D human reconstruction from a single image is a challenging\nproblem due to the ambiguity in decoupling geometry, appearance, and\ndeformation. Recent advances in 3D human reconstruction mainly focus on static\nhuman modeling, and the reliance of using synthetic 3D scans for training\nlimits their generalization ability. Conversely, optimization-based video\nmethods achieve higher fidelity but demand controlled capture conditions and\ncomputationally intensive refinement processes. Motivated by the emergence of\nlarge reconstruction models for efficient static reconstruction, we propose LHM\n(Large Animatable Human Reconstruction Model) to infer high-fidelity avatars\nrepresented as 3D Gaussian splatting in a feed-forward pass. Our model\nleverages a multimodal transformer architecture to effectively encode the human\nbody positional features and image features with attention mechanism, enabling\ndetailed preservation of clothing geometry and texture. To further boost the\nface identity preservation and fine detail recovery, we propose a head feature\npyramid encoding scheme to aggregate multi-scale features of the head regions.\nExtensive experiments demonstrate that our LHM generates plausible animatable\nhuman in seconds without post-processing for face and hands, outperforming\nexisting methods in both reconstruction accuracy and generalization ability.",
      "tldr_zh": "本研究提出LHM（Large Animatable Human Reconstruction Model），一种高效模型，能从单张图像在几秒内重建高保真可动画3D人体，使用3D Gaussian splatting表示来解决几何、外观和变形的解耦挑战。LHM采用多模态Transformer架构，通过注意力机制编码人体位置特征和图像特征，同时引入头部特征金字塔编码方案，以提升面部身份和细节（如服装纹理）的保留能力。实验结果显示，LHM在重建准确性和泛化能力上优于现有方法，无需后期处理即可生成高质量的面部和手部模型。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Project Page: https://lingtengqiu.github.io/LHM/",
      "pdf_url": "http://arxiv.org/pdf/2503.10625v1",
      "published_date": "2025-03-13 17:59:21 UTC",
      "updated_date": "2025-03-13 17:59:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:39:59.143896"
    },
    {
      "arxiv_id": "2503.10624v1",
      "title": "ETCH: Generalizing Body Fitting to Clothed Humans via Equivariant Tightness",
      "title_zh": "ETCH：通过等变紧度将身体拟合泛化到穿着衣服的人体",
      "authors": [
        "Boqian Li",
        "Haiwen Feng",
        "Zeyu Cai",
        "Michael J. Black",
        "Yuliang Xiu"
      ],
      "abstract": "Fitting a body to a 3D clothed human point cloud is a common yet challenging\ntask. Traditional optimization-based approaches use multi-stage pipelines that\nare sensitive to pose initialization, while recent learning-based methods often\nstruggle with generalization across diverse poses and garment types. We propose\nEquivariant Tightness Fitting for Clothed Humans, or ETCH, a novel pipeline\nthat estimates cloth-to-body surface mapping through locally approximate SE(3)\nequivariance, encoding tightness as displacement vectors from the cloth surface\nto the underlying body. Following this mapping, pose-invariant body features\nregress sparse body markers, simplifying clothed human fitting into an\ninner-body marker fitting task. Extensive experiments on CAPE and 4D-Dress show\nthat ETCH significantly outperforms state-of-the-art methods -- both\ntightness-agnostic and tightness-aware -- in body fitting accuracy on loose\nclothing (16.7% ~ 69.5%) and shape accuracy (average 49.9%). Our equivariant\ntightness design can even reduce directional errors by (67.2% ~ 89.8%) in\none-shot (or out-of-distribution) settings. Qualitative results demonstrate\nstrong generalization of ETCH, regardless of challenging poses, unseen shapes,\nloose clothing, and non-rigid dynamics. We will release the code and models\nsoon for research purposes at https://boqian-li.github.io/ETCH/.",
      "tldr_zh": "该论文提出了一种名为 ETCH 的新方法，用于将人体模型拟合到 3D 穿着衣服的人体点云中，解决传统优化和学习方法在姿势初始化和泛化方面的挑战。ETCH 通过局部近似的 SE(3) 等变性来估计衣服到身体表面的映射，将紧密度编码为从衣服表面到底层身体的位移向量，并将拟合任务简化为回归姿势不变的稀疏身体标记。实验结果显示，ETCH 在 CAPE 和 4D-Dress 数据集上显著优于现有方法，在宽松服装的拟合准确性上提升 16.7% ~ 69.5%，形状准确性平均提高 49.9%，并在单次设置中减少方向错误 67.2% ~ 89.8%。该方法在挑战性姿势、未见形状和非刚性动态中表现出强泛化能力，并计划发布代码和模型。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR"
      ],
      "primary_category": "cs.CV",
      "comment": "Page: https://boqian-li.github.io/ETCH/, Code:\n  https://github.com/boqian-li/ETCH",
      "pdf_url": "http://arxiv.org/pdf/2503.10624v1",
      "published_date": "2025-03-13 17:59:14 UTC",
      "updated_date": "2025-03-13 17:59:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:40:12.140548"
    },
    {
      "arxiv_id": "2503.10622v1",
      "title": "Transformers without Normalization",
      "title_zh": "翻译失败",
      "authors": [
        "Jiachen Zhu",
        "Xinlei Chen",
        "Kaiming He",
        "Yann LeCun",
        "Zhuang Liu"
      ],
      "abstract": "Normalization layers are ubiquitous in modern neural networks and have long\nbeen considered essential. This work demonstrates that Transformers without\nnormalization can achieve the same or better performance using a remarkably\nsimple technique. We introduce Dynamic Tanh (DyT), an element-wise operation\n$DyT($x$) = \\tanh(\\alpha $x$)$, as a drop-in replacement for normalization\nlayers in Transformers. DyT is inspired by the observation that layer\nnormalization in Transformers often produces tanh-like, $S$-shaped input-output\nmappings. By incorporating DyT, Transformers without normalization can match or\nexceed the performance of their normalized counterparts, mostly without\nhyperparameter tuning. We validate the effectiveness of Transformers with DyT\nacross diverse settings, ranging from recognition to generation, supervised to\nself-supervised learning, and computer vision to language models. These\nfindings challenge the conventional understanding that normalization layers are\nindispensable in modern neural networks, and offer new insights into their role\nin deep networks.",
      "tldr_zh": "本研究挑战了归一化层（normalization layers）在现代神经网络中被视为必需的传统观点，提出了一种简单替代技术：Dynamic Tanh (DyT)，定义为 $DyT(x) = \\tanh(\\alpha x)$，可直接替换 Transformer 中的归一化层。DyT 灵感来源于层归一化（layer normalization）产生的类似 tanh 的 S 形映射，使用后无需大量超参数调整，即可使无归一化层的 Transformer 在识别、生成、监督或自监督学习等任务中匹配或超过基线性能。实验验证了这一方法的有效性，涵盖计算机视觉和语言模型等领域，并为理解归一化层在深度网络中的作用提供了新见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "CVPR 2025; Project page: https://jiachenzhu.github.io/DyT/",
      "pdf_url": "http://arxiv.org/pdf/2503.10622v1",
      "published_date": "2025-03-13 17:59:06 UTC",
      "updated_date": "2025-03-13 17:59:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:40:23.395419"
    },
    {
      "arxiv_id": "2503.10619v4",
      "title": "Tempest: Autonomous Multi-Turn Jailbreaking of Large Language Models with Tree Search",
      "title_zh": "翻译失败",
      "authors": [
        "Andy Zhou",
        "Ron Arel"
      ],
      "abstract": "We introduce Tempest, a multi-turn adversarial framework that models the\ngradual erosion of Large Language Model (LLM) safety through a tree search\nperspective. Unlike single-turn jailbreaks that rely on one meticulously\nengineered prompt, Tempest expands the conversation at each turn in a\nbreadth-first fashion, branching out multiple adversarial prompts that exploit\npartial compliance from previous responses. By tracking these incremental\npolicy leaks and re-injecting them into subsequent queries, Tempest reveals how\nminor concessions can accumulate into fully disallowed outputs. Evaluations on\nthe JailbreakBench dataset show that Tempest achieves a 100% success rate on\nGPT-3.5-turbo and 97% on GPT-4 in a single multi-turn run, using fewer queries\nthan baselines such as Crescendo or GOAT. This tree search methodology offers\nan in-depth view of how model safeguards degrade over successive dialogue\nturns, underscoring the urgency of robust multi-turn testing procedures for\nlanguage models.",
      "tldr_zh": "本研究引入了Tempest，一种自主多轮对抗框架，通过tree search方法模拟大型语言模型(LLM)的安全性逐步衰退。Tempest不同于单轮越狱攻击，它以广度优先方式扩展对话，生成多个对抗提示，利用先前响应的部分合规性来跟踪增量策略泄露并重新注入后续查询，从而揭示小让步如何累积成完全违规输出。在JailbreakBench数据集的评估中，Tempest在GPT-3.5-turbo上实现100%成功率，在GPT-4上达到97%，并比基线如Crescendo或GOAT使用更少查询，这突显了强化多轮测试以提升LLM稳健性的紧迫性。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CR"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to ACL 2025 Main",
      "pdf_url": "http://arxiv.org/pdf/2503.10619v4",
      "published_date": "2025-03-13 17:57:32 UTC",
      "updated_date": "2025-05-21 05:06:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:40:35.172038"
    },
    {
      "arxiv_id": "2503.10617v3",
      "title": "Compositional Subspace Representation Fine-tuning for Adaptive Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Andy Zhou"
      ],
      "abstract": "Adapting large language models to multiple tasks can cause cross-skill\ninterference, where improvements for one skill degrade another. While methods\nsuch as LoRA impose orthogonality constraints at the weight level, they do not\nfully address interference in hidden-state representations. We propose\nCompositional Subspace Representation Fine-tuning (CS-ReFT), a novel\nrepresentation-based approach that learns multiple orthonormal subspace\ntransformations, each specializing in a distinct skill, and composes them via a\nlightweight router. By isolating these subspace edits in the hidden state,\nrather than weight matrices, CS-ReFT prevents cross-task conflicts more\neffectively. On the AlpacaEval benchmark, applying CS-ReFT to Llama-2-7B\nachieves a 93.94% win rate, surpassing GPT-3.5 Turbo (86.30%) while requiring\nonly 0.0098% of model parameters. These findings show that specialized\nrepresentation edits, composed via a simple router, significantly enhance\nmulti-task instruction following with minimal overhead.",
      "tldr_zh": "该研究针对大型语言模型（Large Language Models）在多任务适应中存在的跨技能干扰（cross-skill interference）问题，提出了一种新方法：Compositional Subspace Representation Fine-tuning (CS-ReFT)。CS-ReFT 通过学习多个正交子空间变换（multiple orthonormal subspace transformations），每个针对特定技能，并使用轻量级路由器（lightweight router）组合这些变换，从而在隐藏状态（hidden-state representations）层面隔离编辑，减少任务间冲突。实验结果显示，在 AlpacaEval 基准上，应用于 Llama-2-7B 的 CS-ReFT 实现了 93.94% 的胜率，超过了 GPT-3.5 Turbo (86.30%)，且仅需模型参数的 0.0098%，证明了这种方法在提升多任务指令遵循方面的显著效率。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to ICLR 2025 SCOPE",
      "pdf_url": "http://arxiv.org/pdf/2503.10617v3",
      "published_date": "2025-03-13 17:57:04 UTC",
      "updated_date": "2025-04-26 02:35:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:40:48.935122"
    },
    {
      "arxiv_id": "2503.10745v2",
      "title": "Unifying 2D and 3D Vision-Language Understanding",
      "title_zh": "统一二维与三维视觉语言理解",
      "authors": [
        "Ayush Jain",
        "Alexander Swerdlow",
        "Yuzhou Wang",
        "Sergio Arnaud",
        "Ada Martin",
        "Alexander Sax",
        "Franziska Meier",
        "Katerina Fragkiadaki"
      ],
      "abstract": "Progress in 3D vision-language learning has been hindered by the scarcity of\nlarge-scale 3D datasets. We introduce UniVLG, a unified architecture for 2D and\n3D vision-language understanding that bridges the gap between existing\n2D-centric models and the rich 3D sensory data available in embodied systems.\nOur approach initializes most model weights from pre-trained 2D models and\ntrains on both 2D and 3D vision-language data. We propose a novel\nlanguage-conditioned mask decoder shared across 2D and 3D modalities to ground\nobjects effectively in both RGB and RGB-D images, outperforming box-based\napproaches. To further reduce the domain gap between 2D and 3D, we incorporate\n2D-to-3D lifting strategies, enabling UniVLG to utilize 2D data to enhance 3D\nperformance. With these innovations, our model achieves state-of-the-art\nperformance across multiple 3D vision-language grounding tasks, demonstrating\nthe potential of transferring advances from 2D vision-language learning to the\ndata-constrained 3D domain. Furthermore, co-training on both 2D and 3D data\nenhances performance across modalities without sacrificing 2D capabilities. By\nremoving the reliance on 3D mesh reconstruction and ground-truth object\nproposals, UniVLG sets a new standard for realistic, embodied-aligned\nevaluation. Code and additional visualizations are available at\nhttps://univlg.github.io .",
      "tldr_zh": "该研究提出 UniVLG，一种统一 2D 和 3D 视觉语言理解的架构，旨在解决 3D 数据集稀缺问题，通过从预训练的 2D 模型初始化权重并在 2D 和 3D 数据上共同训练来桥接模态间差距。UniVLG 采用共享的语言条件 mask decoder 用于在 RGB 和 RGB-D 图像中有效 grounding 对象，并引入 2D-to-3D lifting 策略，利用 2D 数据提升 3D 性能。实验结果显示，该模型在多个 3D 视觉语言 grounding 任务上达到 state-of-the-art 水平，同时增强了跨模态性能，而无需依赖 3D 网格重建或 ground-truth 对象提案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "The first two authors contributed equally",
      "pdf_url": "http://arxiv.org/pdf/2503.10745v2",
      "published_date": "2025-03-13 17:56:22 UTC",
      "updated_date": "2025-03-20 16:24:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:41:02.641163"
    },
    {
      "arxiv_id": "2503.10603v3",
      "title": "Technical Approach for the EMI Challenge in the 8th Affective Behavior Analysis in-the-Wild Competition",
      "title_zh": "翻译失败",
      "authors": [
        "Jun Yu",
        "Lingsi Zhu",
        "Yanjun Chi",
        "Yunxiang Zhang",
        "Yang Zheng",
        "Yongqi Wang",
        "Xilong Lu"
      ],
      "abstract": "Emotional Mimicry Intensity (EMI) estimation plays a pivotal role in\nunderstanding human social behavior and advancing human-computer interaction.\nThe core challenges lie in dynamic correlation modeling and robust fusion of\nmultimodal temporal signals. To address the limitations of existing\nmethods--insufficient exploitation of cross-modal synergies, sensitivity to\nnoise, and constrained fine-grained alignment capabilities--this paper proposes\na dual-stage cross-modal alignment framework. Stage 1 develops vision-text and\naudio-text contrastive learning networks based on a CLIP architecture,\nachieving preliminary feature-space alignment through modality-decoupled\npre-training. Stage 2 introduces a temporal-aware dynamic fusion module\nintegrating Temporal Convolutional Networks (TCN) and gated bidirectional LSTM\nto capture macro-evolution patterns of facial expressions and local dynamics of\nacoustic features, respectively. A novel quality-guided fusion strategy further\nenables differentiable weight allocation for modality compensation under\nocclusion and noise. Experiments on the Hume-Vidmimic2 dataset demonstrate\nsuperior performance with an average Pearson correlation coefficient of 0.51\nacross six emotion dimensions on the validate set. Remarkably, our method\nachieved 0.68 on the test set, securing runner-up in the EMI Challenge Track of\nthe 8th ABAW (Affective Behavior Analysis in the Wild) Competition, offering a\nnovel pathway for fine-grained emotion analysis in open environments.",
      "tldr_zh": "本研究针对Emotional Mimicry Intensity (EMI) 估计的挑战，包括动态相关性建模和多模态时间信号的鲁棒融合，提出了一种双阶段跨模态对齐框架，以解决现有方法的跨模态协同不足、对噪声敏感以及细粒度对齐能力有限的问题。框架的Stage 1基于CLIP架构开发视觉-文本和音频-文本对比学习网络，通过模态解耦预训练实现初步特征空间对齐；Stage 2则引入时间感知动态融合模块，结合Temporal Convolutional Networks (TCN)和门控双向LSTM来捕获面部表情的宏观演变与声学特征的局部动态，并采用质量引导融合策略进行模态补偿。实验在Hume-Vidmimic2数据集上显示，平均Pearson correlation coefficient达0.51（验证集）和0.68（测试集），并在8th Affective Behavior Analysis in-the-Wild (ABAW) 比赛的EMI Challenge Track中获得亚军，为细粒度情感分析提供新路径。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10603v3",
      "published_date": "2025-03-13 17:46:16 UTC",
      "updated_date": "2025-03-25 08:46:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:41:13.571328"
    },
    {
      "arxiv_id": "2503.10602v2",
      "title": "TruthPrInt: Mitigating LVLM Object Hallucination Via Latent Truthful-Guided Pre-Intervention",
      "title_zh": "翻译失败",
      "authors": [
        "Jinhao Duan",
        "Fei Kong",
        "Hao Cheng",
        "James Diffenderfer",
        "Bhavya Kailkhura",
        "Lichao Sun",
        "Xiaofeng Zhu",
        "Xiaoshuang Shi",
        "Kaidi Xu"
      ],
      "abstract": "Object Hallucination (OH) has been acknowledged as one of the major\ntrustworthy challenges in Large Vision-Language Models (LVLMs). Recent\nadvancements in Large Language Models (LLMs) indicate that internal states,\nsuch as hidden states, encode the \"overall truthfulness\" of generated\nresponses. However, it remains under-explored how internal states in LVLMs\nfunction and whether they could serve as \"per-token\" hallucination indicators,\nwhich is essential for mitigating OH. In this paper, we first conduct an\nin-depth exploration of LVLM internal states in relation to OH issues and\ndiscover that (1) LVLM internal states are high-specificity per-token\nindicators of hallucination behaviors. Moreover, (2) different LVLMs encode\nuniversal patterns of hallucinations in common latent subspaces, indicating\nthat there exist \"generic truthful directions\" shared by various LVLMs. Based\non these discoveries, we propose Truthful-Guided Pre-Intervention (TruthPrInt)\nthat first learns the truthful direction of LVLM decoding and then applies\ntruthful-guided inference-time intervention during LVLM decoding. We further\npropose ComnHallu to enhance both cross-LVLM and cross-data hallucination\ndetection transferability by constructing and aligning hallucination latent\nsubspaces. We evaluate TruthPrInt in extensive experimental settings, including\nin-domain and out-of-domain scenarios, over popular LVLMs and OH benchmarks.\nExperimental results indicate that TruthPrInt significantly outperforms\nstate-of-the-art methods. Codes will be available at\nhttps://github.com/jinhaoduan/TruthPrInt.",
      "tldr_zh": "该研究探讨了Large Vision-Language Models (LVLMs) 中Object Hallucination (OH) 的问题，通过分析LVLM内部状态（如隐藏状态）发现，这些状态可作为高特异性的每token幻觉指标，且不同LVLMs共享通用幻觉潜在子空间。作者提出Truthful-Guided Pre-Intervention (TruthPrInt) 方法，包括学习LVLM解码的“truthful direction”并在解码过程中进行干预，同时引入ComnHallu框架来提升跨LVLM和跨数据幻觉检测的可转移性。实验结果显示，TruthPrInt在各种场景下显著优于现有方法，为缓解LVLM幻觉问题提供了有效策略。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "15 pages, 9 figures, the first two authors contributed equally",
      "pdf_url": "http://arxiv.org/pdf/2503.10602v2",
      "published_date": "2025-03-13 17:46:06 UTC",
      "updated_date": "2025-03-21 15:58:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:41:23.388171"
    },
    {
      "arxiv_id": "2504.07103v1",
      "title": "FG-RAG: Enhancing Query-Focused Summarization with Context-Aware Fine-Grained Graph RAG",
      "title_zh": "翻译失败",
      "authors": [
        "Yubin Hong",
        "Chaofan Li",
        "Jingyi Zhang",
        "Yingxia Shao"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) enables large language models to provide\nmore precise and pertinent responses by incorporating external knowledge. In\nthe Query-Focused Summarization (QFS) task, GraphRAG-based approaches have\nnotably enhanced the comprehensiveness and diversity of generated responses.\nHowever, existing GraphRAG-based approaches predominantly focus on\ncoarse-grained information summarization without being aware of the specific\nquery, and the retrieved content lacks sufficient contextual information to\ngenerate comprehensive responses. To address the deficiencies of current RAG\nsystems, we propose Context-Aware Fine-Grained Graph RAG (FG-RAG) to enhance\nthe performance of the QFS task. FG-RAG employs Context-Aware Entity Expansion\nin graph retrieval to expand the coverage of retrieved entities in the graph,\nthus providing enough contextual information for the retrieved content.\nFurthermore, FG-RAG utilizes Query-Level Fine-Grained Summarization to\nincorporate fine-grained details during response generation, enhancing query\nawareness for the generated summarization. Our evaluation demonstrates that\nFG-RAG outperforms other RAG systems in multiple metrics of comprehensiveness,\ndiversity, and empowerment when handling the QFS task. Our implementation is\navailable at https://github.com/BuptWululu/FG-RAG.",
      "tldr_zh": "本研究提出FG-RAG，一种基于上下文感知细粒度图RAG（GraphRAG）的框架，用于提升查询焦点摘要（QFS）任务的性能，以解决现有RAG系统在粗粒度信息总结和查询相关性方面的不足。FG-RAG引入上下文感知实体扩展（Context-Aware Entity Expansion）来扩大图检索中实体的覆盖范围，从而提供更丰富的上下文信息；同时，利用查询级细粒度总结（Query-Level Fine-Grained Summarization）在响应生成中融入详细细节，以增强查询意识。实验结果显示，FG-RAG在QFS任务中在全面性、多样性和增强性等指标上优于其他RAG系统，并提供了开源实现（https://github.com/BuptWululu/FG-RAG）。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.07103v1",
      "published_date": "2025-03-13 17:42:07 UTC",
      "updated_date": "2025-03-13 17:42:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:41:35.167937"
    },
    {
      "arxiv_id": "2503.10741v1",
      "title": "Predicting Treatment Response in Body Dysmorphic Disorder with Interpretable Machine Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Omar Costilla-Reyes",
        "Morgan Talbot"
      ],
      "abstract": "Body Dysmorphic Disorder (BDD) is a highly prevalent and frequently\nunderdiagnosed condition characterized by persistent, intrusive preoccupations\nwith perceived defects in physical appearance. In this extended analysis, we\nemploy multiple machine learning approaches to predict treatment outcomes --\nspecifically treatment response and remission -- with an emphasis on\ninterpretability to ensure clinical relevance and utility. Across the various\nmodels investigated, treatment credibility emerged as the most potent\npredictor, surpassing traditional markers such as baseline symptom severity or\ncomorbid conditions. Notably, while simpler models (e.g., logistic regression\nand support vector machines) achieved competitive predictive performance,\ndecision tree analyses provided unique insights by revealing clinically\ninterpretable threshold values in credibility scores. These thresholds can\nserve as practical guideposts for clinicians when tailoring interventions or\nallocating treatment resources. We further contextualize our findings within\nthe broader literature on BDD, addressing technology-based therapeutics,\ndigital interventions, and the psychosocial determinants of treatment\nengagement. An extensive array of references situates our results within\ncurrent research on BDD prevalence, suicidality risks, and digital innovation.\nOur work underscores the potential of integrating rigorous statistical\nmethodologies with transparent machine learning models. By systematically\nidentifying modifiable predictors -- such as treatment credibility -- we\npropose a pathway toward more targeted, personalized, and ultimately\nefficacious interventions for individuals with BDD.",
      "tldr_zh": "本研究利用可解释机器学习方法预测体像障碍（Body Dysmorphic Disorder, BDD）的治疗反应和缓解，强调模型的临床实用性。研究发现，治疗可信度（treatment credibility）是预测治疗结果的最强因素，优于传统的基线症状严重性和共病指标；决策树分析进一步揭示了可信度分数的临床阈值，帮助医生个性化干预。整体而言，该工作整合统计方法与透明机器学习模型，提出针对BDD的更精确干预路径，提升治疗效果和资源分配效率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10741v1",
      "published_date": "2025-03-13 17:39:10 UTC",
      "updated_date": "2025-03-13 17:39:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:41:47.782684"
    },
    {
      "arxiv_id": "2503.10587v1",
      "title": "The Spectral Bias of Shallow Neural Network Learning is Shaped by the Choice of Non-linearity",
      "title_zh": "浅层神经网络学习的谱偏差由非",
      "authors": [
        "Justin Sahs",
        "Ryan Pyle",
        "Fabio Anselmi",
        "Ankit Patel"
      ],
      "abstract": "Despite classical statistical theory predicting severe overfitting, modern\nmassively overparameterized neural networks still generalize well. This\nunexpected property is attributed to the network's so-called implicit bias,\nwhich describes its propensity to converge to solutions that generalize\neffectively, among the many possible that correctly label the training data.\nThe aim of our research is to explore this bias from a new perspective,\nfocusing on how non-linear activation functions contribute to shaping it.\nFirst, we introduce a reparameterization which removes a continuous weight\nrescaling symmetry. Second, in the kernel regime, we leverage this\nreparameterization to generalize recent findings that relate shallow Neural\nNetworks to the Radon transform, deriving an explicit formula for the implicit\nbias induced by a broad class of activation functions. Specifically, by\nutilizing the connection between the Radon transform and the Fourier transform,\nwe interpret the kernel regime's inductive bias as minimizing a spectral\nseminorm that penalizes high-frequency components, in a manner dependent on the\nactivation function. Finally, in the adaptive regime, we demonstrate the\nexistence of local dynamical attractors that facilitate the formation of\nclusters of hyperplanes where the input to a neuron's activation function is\nzero, yielding alignment between many neurons' response functions. We confirm\nthese theoretical results with simulations. All together, our work provides a\ndeeper understanding of the mechanisms underlying the generalization\ncapabilities of overparameterized neural networks and its relation with the\nimplicit bias, offering potential pathways for designing more efficient and\nrobust models.",
      "tldr_zh": "本研究探讨了浅层神经网络学习的光谱偏差(spectral bias)，强调非线性激活函数的选择对其隐式偏差(implicit bias)的影响。作者引入重新参数化移除权重缩放对称性，并在核(kernel)模式下推导公式，将浅层神经网络与Radon变换联系起来，揭示激活函数导致的隐式偏差最小化光谱seminorm，从而惩罚高频成分。实验结果显示，在自适应(adaptive)模式下，存在局部动态吸引子促进神经元响应函数对齐。该工作加深了对过度参数化神经网络泛化能力的理解，并为设计更高效、鲁棒的模型提供潜在路径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "18 pages, 10 figures in main text",
      "pdf_url": "http://arxiv.org/pdf/2503.10587v1",
      "published_date": "2025-03-13 17:36:46 UTC",
      "updated_date": "2025-03-13 17:36:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:41:59.600840"
    },
    {
      "arxiv_id": "2503.10582v2",
      "title": "VisualWebInstruct: Scaling up Multimodal Instruction Data through Web Search",
      "title_zh": "翻译失败",
      "authors": [
        "Yiming Jia",
        "Jiachen Li",
        "Xiang Yue",
        "Bo Li",
        "Ping Nie",
        "Kai Zou",
        "Wenhu Chen"
      ],
      "abstract": "Vision-Language Models have made significant progress on many\nperception-focused tasks. However, their progress on reasoning-focused tasks\nremains limited due to the lack of high-quality and diverse training data. In\nthis work, we aim to address the scarcity of reasoning-focused multimodal\ndatasets. We propose VisualWebInstruct, a novel approach that leverages search\nengines to create a diverse and high-quality dataset spanning multiple\ndisciplines, including mathematics, physics, finance, and chemistry, etc.\nStarting with a meticulously selected set of 30,000 seed images, we employ\nGoogle Image Search to identify websites containing similar images. We collect\nand process HTML data from over 700K unique URLs. Through a pipeline of content\nextraction, filtering, and synthesis, we construct a dataset of approximately\n900K question-answer (QA) pairs, with 40% consisting of visual QA pairs and the\nremaining comprising text-based QA pairs. Models fine-tuned on\nVisualWebInstruct demonstrate significant performance improvements: (1)\nfine-tuning on Llava-OV results in 10-20 absolute points improvement across\nbenchmarks, and (2) fine-tuning from MAmmoTH-VL yields a 5 absolute points gain\nacross benchmarks. Our best model, MAmmoTH-VL2, achieves state-of-the-art\nperformance within the 10B parameter class on MMMU-Pro (40.7), MathVerse\n(42.6), and DynaMath (55.7). These results highlight the effectiveness of our\ndataset in enhancing the reasoning capabilities of vision-language models for\ncomplex multimodal tasks.",
      "tldr_zh": "该研究针对视觉语言模型(Vision-Language Models)在推理任务上的局限性，提出VisualWebInstruct方法，通过Google Image Search从网络收集数据，构建一个覆盖数学、物理、金融等领域的多学科数据集。Starting with 30,000 seed images，该方法从超过700K URL提取并处理HTML内容，生成约900K question-answer (QA) pairs，其中40%为视觉QA对，其余为文本QA对。实验结果显示，在VisualWebInstruct上微调模型如Llava-OV可提升10-20绝对点性能，而MAmmoTH-VL则获得5绝对点增益；最佳模型MAmmoTH-VL2在10B参数级别上，在MMMU-Pro (40.7)、MathVerse (42.7)和DynaMath (55.7)基准上达到最先进水平。该数据集显著增强了视觉语言模型在复杂多模态任务中的推理能力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "Technical Report",
      "pdf_url": "http://arxiv.org/pdf/2503.10582v2",
      "published_date": "2025-03-13 17:32:48 UTC",
      "updated_date": "2025-03-15 01:09:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:42:13.064118"
    },
    {
      "arxiv_id": "2503.10546v1",
      "title": "KUDA: Keypoints to Unify Dynamics Learning and Visual Prompting for Open-Vocabulary Robotic Manipulation",
      "title_zh": "翻译失败",
      "authors": [
        "Zixian Liu",
        "Mingtong Zhang",
        "Yunzhu Li"
      ],
      "abstract": "With the rapid advancement of large language models (LLMs) and\nvision-language models (VLMs), significant progress has been made in developing\nopen-vocabulary robotic manipulation systems. However, many existing approaches\noverlook the importance of object dynamics, limiting their applicability to\nmore complex, dynamic tasks. In this work, we introduce KUDA, an\nopen-vocabulary manipulation system that integrates dynamics learning and\nvisual prompting through keypoints, leveraging both VLMs and learning-based\nneural dynamics models. Our key insight is that a keypoint-based target\nspecification is simultaneously interpretable by VLMs and can be efficiently\ntranslated into cost functions for model-based planning. Given language\ninstructions and visual observations, KUDA first assigns keypoints to the RGB\nimage and queries the VLM to generate target specifications. These abstract\nkeypoint-based representations are then converted into cost functions, which\nare optimized using a learned dynamics model to produce robotic trajectories.\nWe evaluate KUDA on a range of manipulation tasks, including free-form language\ninstructions across diverse object categories, multi-object interactions, and\ndeformable or granular objects, demonstrating the effectiveness of our\nframework. The project page is available at http://kuda-dynamics.github.io.",
      "tldr_zh": "本研究提出 KUDA 系统，用于开放词汇机器人操作，通过关键点（keypoints）统一动态学习和视觉提示，解决了现有方法忽略物体动态的局限性。KUDA 结合 VLMs 和学习-based 神经动态模型，从语言指令和视觉观察中分配关键点，生成目标规范并转化为成本函数，用于基于模型的轨迹优化。实验结果显示，该框架在多样任务中表现出色，包括自由形式语言指令、多对象交互以及变形或颗粒物体的操作。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Project website: http://kuda-dynamics.github.io",
      "pdf_url": "http://arxiv.org/pdf/2503.10546v1",
      "published_date": "2025-03-13 16:59:17 UTC",
      "updated_date": "2025-03-13 16:59:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:42:24.945240"
    },
    {
      "arxiv_id": "2503.10542v2",
      "title": "Language Models, Graph Searching, and Supervision Adulteration: When More Supervision is Less and How to Make More More",
      "title_zh": "翻译失败",
      "authors": [
        "Arvid Frydenlund"
      ],
      "abstract": "This work concerns the path-star task, a minimal example of searching over a\ngraph. The graph, $G$, is star-shaped with $D$ arms radiating from a start\nnode, $s$. A language model (LM) is given $G$, $s$, and a target node $t$,\nwhich ends one of the arms and is tasked with generating the arm containing\n$t$. The minimal nature of this task means only a single choice needs to be\nmade: which of the $D$ arms contains $t$?\n  Decoder-only LMs fail to solve this elementary task above $1/D$ chance due to\na learned shortcut that absorbs training supervision. We show how this\npathology is caused by excess supervision and we present a series of solutions\ndemonstrating that the task is solvable via decoder-only LMs. We find that the\ntask's minimal nature causes its difficulty, as it prevents task decomposition.\nOur solutions provide insight into the pathology and its implications for LMs\ntrained via next-token prediction.",
      "tldr_zh": "这篇论文探讨了语言模型 (LMs) 在 path-star 图搜索任务中的表现，该任务是一个简单的星形图搜索问题，要求模型从 D 个臂中选择包含目标节点 t 的臂。研究发现，decoder-only LMs 由于吸收训练监督的捷径，导致在任务上仅略高于 1/D 的随机概率，问题源于过量监督阻碍了任务分解。作者提出了系列解决方案，证明 decoder-only LMs 可以有效解决此任务，并为基于 next-token prediction 的 LMs 训练提供了重要启示。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "I.2.7; I.2.8; I.5.0"
      ],
      "primary_category": "cs.LG",
      "comment": "ACL 2025 Main. A camera-ready version will follow in a few weeks. A\n  reduced version of this work has was also accepted to the Workshop on\n  Spurious Correlation and Shortcut Learning: Foundations and Solutions (SCSL)\n  at ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.10542v2",
      "published_date": "2025-03-13 16:56:47 UTC",
      "updated_date": "2025-05-19 18:20:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:42:37.408120"
    },
    {
      "arxiv_id": "2503.10539v1",
      "title": "GBSVR: Granular Ball Support Vector Regression",
      "title_zh": "GBSVR：颗粒球支持向量回归",
      "authors": [
        "Reshma Rastogi",
        "Ankush Bisht",
        "Sanjay Kumar",
        "Suresh Chandra"
      ],
      "abstract": "Support Vector Regression (SVR) and its variants are widely used to handle\nregression tasks, however, since their solution involves solving an expensive\nquadratic programming problem, it limits its application, especially when\ndealing with large datasets. Additionally, SVR uses an epsilon-insensitive loss\nfunction which is sensitive to outliers and therefore can adversely affect its\nperformance. We propose Granular Ball Support Vector Regression (GBSVR) to\ntackle problem of regression by using granular ball concept. These balls are\nuseful in simplifying complex data spaces for machine learning tasks, however,\nto the best of our knowledge, they have not been sufficiently explored for\nregression problems. Granular balls group the data points into balls based on\ntheir proximity and reduce the computational cost in SVR by replacing the large\nnumber of data points with far fewer granular balls. This work also suggests a\ndiscretization method for continuous-valued attributes to facilitate the\nconstruction of granular balls. The effectiveness of the proposed approach is\nevaluated on several benchmark datasets and it outperforms existing\nstate-of-the-art approaches",
      "tldr_zh": "本研究针对 Support Vector Regression (SVR) 的计算开销大（如解决二次规划问题）和对异常值的敏感性，提出了一种新方法 Granular Ball Support Vector Regression (GBSVR)。GBSVR 通过 granular balls 概念将数据点根据 proximity 分组，减少数据量并简化复杂数据空间，同时引入 discretization method 来处理连续属性，从而降低 SVR 的计算成本。实验结果显示，该方法在多个基准数据集上优于现有最先进方法，提供了一种更高效的回归解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10539v1",
      "published_date": "2025-03-13 16:52:43 UTC",
      "updated_date": "2025-03-13 16:52:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:42:48.630826"
    },
    {
      "arxiv_id": "2503.10533v1",
      "title": "The Impact of Item-Writing Flaws on Difficulty and Discrimination in Item Response Theory",
      "title_zh": "翻译失败",
      "authors": [
        "Robin Schmucker",
        "Steven Moore"
      ],
      "abstract": "High-quality test items are essential for educational assessments,\nparticularly within Item Response Theory (IRT). Traditional validation methods\nrely on resource-intensive pilot testing to estimate item difficulty and\ndiscrimination. More recently, Item-Writing Flaw (IWF) rubrics emerged as a\ndomain-general approach for evaluating test items based on textual features.\nHowever, their relationship to IRT parameters remains underexplored. To address\nthis gap, we conducted a study involving over 7,000 multiple-choice questions\nacross various STEM subjects (e.g., math and biology). Using an automated\napproach, we annotated each question with a 19-criteria IWF rubric and studied\nrelationships to data-driven IRT parameters. Our analysis revealed\nstatistically significant links between the number of IWFs and IRT difficulty\nand discrimination parameters, particularly in life and physical science\ndomains. We further observed how specific IWF criteria can impact item quality\nmore and less severely (e.g., negative wording vs. implausible distractors).\nOverall, while IWFs are useful for predicting IRT parameters--particularly for\nscreening low-difficulty MCQs--they cannot replace traditional data-driven\nvalidation methods. Our findings highlight the need for further research on\ndomain-general evaluation rubrics and algorithms that understand\ndomain-specific content for robust item validation.",
      "tldr_zh": "本研究探讨了 Item-Writing Flaw (IWF) 对 Item Response Theory (IRT) 中测试题难度和区分度的影响，旨在评估 IWF 作为基于文本特征的通用评估方法在教育评估中的作用。研究者对超过 7,000 个 STEM 科目（如数学和生物）的多选题进行自动化标注，使用 19 标准 IWF 评分表，并分析其与 IRT 参数的关联。结果显示，IWF 数量与 IRT 难度和区分度参数有统计显著联系，尤其在生命和物理科学领域，且特定标准（如负面措辞）的影响比其他标准（如不可信干扰项）更严重。尽管 IWF 能有效预测 IRT 参数并用于筛选低难度多选题，但无法完全取代传统数据驱动验证方法。该研究呼吁进一步开发领域通用评估标准和理解领域特定内容的算法，以提升测试题验证的鲁棒性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10533v1",
      "published_date": "2025-03-13 16:47:07 UTC",
      "updated_date": "2025-03-13 16:47:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:43:03.733058"
    },
    {
      "arxiv_id": "2503.10530v2",
      "title": "Lightweight Models for Emotional Analysis in Video",
      "title_zh": "视频中的情感分析轻量级模型",
      "authors": [
        "Quoc-Tien Nguyen",
        "Hong-Hai Nguyen",
        "Van-Thong Huynh"
      ],
      "abstract": "In this study, we present an approach for efficient spatiotemporal feature\nextraction using MobileNetV4 and a multi-scale 3D MLP-Mixer-based temporal\naggregation module. MobileNetV4, with its Universal Inverted Bottleneck (UIB)\nblocks, serves as the backbone for extracting hierarchical feature\nrepresentations from input image sequences, ensuring both computational\nefficiency and rich semantic encoding. To capture temporal dependencies, we\nintroduce a three-level MLP-Mixer module, which processes spatial features at\nmultiple resolutions while maintaining structural integrity. Experimental\nresults on the ABAW 8th competition demonstrate the effectiveness of our\napproach, showing promising performance in affective behavior analysis. By\nintegrating an efficient vision backbone with a structured temporal modeling\nmechanism, the proposed framework achieves a balance between computational\nefficiency and predictive accuracy, making it well-suited for real-time\napplications in mobile and embedded computing environments.",
      "tldr_zh": "这篇论文提出了一种轻量级模型，用于视频情感分析，采用 MobileNetV4 作为骨干网络，通过其 Universal Inverted Bottleneck (UIB) 块提取图像序列的层次特征。模型还引入了一个多尺度 3D MLP-Mixer 模块进行三层时间聚合，以捕捉时空依赖性，同时保持计算效率。实验在 ABAW 8th 比赛中验证了该框架的有效性，实现计算效率与预测准确性的平衡，适用于实时移动和嵌入式环境。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "https://github.com/PRVSL/abaw-8th",
      "pdf_url": "http://arxiv.org/pdf/2503.10530v2",
      "published_date": "2025-03-13 16:38:33 UTC",
      "updated_date": "2025-03-25 03:50:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:43:12.769125"
    },
    {
      "arxiv_id": "2503.10529v1",
      "title": "PiSA: A Self-Augmented Data Engine and Training Strategy for 3D Understanding with Large Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zilu Guo",
        "Hongbin Lin",
        "Zhihao Yuan",
        "Chaoda Zheng",
        "Pengshuo Qiu",
        "Dongzhi Jiang",
        "Renrui Zhang",
        "Chun-Mei Feng",
        "Zhen Li"
      ],
      "abstract": "3D Multimodal Large Language Models (MLLMs) have recently made substantial\nadvancements. However, their potential remains untapped, primarily due to the\nlimited quantity and suboptimal quality of 3D datasets. Current approaches\nattempt to transfer knowledge from 2D MLLMs to expand 3D instruction data, but\nstill face modality and domain gaps. To this end, we introduce PiSA-Engine\n(Point-Self-Augmented-Engine), a new framework for generating instruction\npoint-language datasets enriched with 3D spatial semantics. We observe that\nexisting 3D MLLMs offer a comprehensive understanding of point clouds for\nannotation, while 2D MLLMs excel at cross-validation by providing complementary\ninformation. By integrating holistic 2D and 3D insights from off-the-shelf\nMLLMs, PiSA-Engine enables a continuous cycle of high-quality data generation.\nWe select PointLLM as the baseline and adopt this co-evolution training\nframework to develop an enhanced 3D MLLM, termed PointLLM-PiSA. Additionally,\nwe identify limitations in previous 3D benchmarks, which often feature coarse\nlanguage captions and insufficient category diversity, resulting in inaccurate\nevaluations. To address this gap, we further introduce PiSA-Bench, a\ncomprehensive 3D benchmark covering six key aspects with detailed and diverse\nlabels. Experimental results demonstrate PointLLM-PiSA's state-of-the-art\nperformance in zero-shot 3D object captioning and generative classification on\nour PiSA-Bench, achieving significant improvements of 46.45% (+8.33%) and\n63.75% (+16.25%), respectively. We will release the code, datasets, and\nbenchmark.",
      "tldr_zh": "该研究针对 3D Multimodal Large Language Models (MLLMs) 的数据集量少质低问题，提出 PiSA-Engine（Point-Self-Augmented-Engine），一种自增强数据引擎框架，通过整合 2D 和 3D MLLMs 的洞见，实现高质量 3D 指令点-语言数据集的持续生成。基于 PointLLM 作为基线，该框架开发了增强版模型 PointLLM-PiSA，并引入 PiSA-Bench 作为更全面的 3D 基准，涵盖六大关键方面并提供详细多样标签。实验结果显示，PointLLM-PiSA 在零样本 3D 对象描述和生成分类任务上取得了显著提升，准确率分别提高了 8.33% 和 16.25%。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Technical Report",
      "pdf_url": "http://arxiv.org/pdf/2503.10529v1",
      "published_date": "2025-03-13 16:37:26 UTC",
      "updated_date": "2025-03-13 16:37:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:43:25.950509"
    },
    {
      "arxiv_id": "2503.10520v1",
      "title": "CountPath: Automating Fragment Counting in Digital Pathology",
      "title_zh": "翻译失败",
      "authors": [
        "Ana Beatriz Vieira",
        "Maria Valente",
        "Diana Montezuma",
        "Tomé Albuquerque",
        "Liliana Ribeiro",
        "Domingos Oliveira",
        "João Monteiro",
        "Sofia Gonçalves",
        "Isabel M. Pinto",
        "Jaime S. Cardoso",
        "Arlindo L. Oliveira"
      ],
      "abstract": "Quality control of medical images is a critical component of digital\npathology, ensuring that diagnostic images meet required standards. A\npre-analytical task within this process is the verification of the number of\nspecimen fragments, a process that ensures that the number of fragments on a\nslide matches the number documented in the macroscopic report. This step is\nimportant to ensure that the slides contain the appropriate diagnostic material\nfrom the grossing process, thereby guaranteeing the accuracy of subsequent\nmicroscopic examination and diagnosis. Traditionally, this assessment is\nperformed manually, requiring significant time and effort while being subject\nto significant variability due to its subjective nature. To address these\nchallenges, this study explores an automated approach to fragment counting\nusing the YOLOv9 and Vision Transformer models. Our results demonstrate that\nthe automated system achieves a level of performance comparable to expert\nassessments, offering a reliable and efficient alternative to manual counting.\nAdditionally, we present findings on interobserver variability, showing that\nthe automated approach achieves an accuracy of 86%, which falls within the\nrange of variation observed among experts (82-88%), further supporting its\npotential for integration into routine pathology workflows.",
      "tldr_zh": "本研究针对数字病理学中医疗图像质量控制的问题，提出CountPath系统，用于自动化标本碎片计数，以验证玻片上碎片数量是否与宏观报告一致。该系统采用YOLOv9和Vision Transformer模型，解决了传统手动计数耗时、主观且变异性大的挑战。实验结果显示，该自动化方法准确率达86%，与专家评估水平相当（专家间变异为82-88%），为数字病理学工作流程提供可靠、高效的替代方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "I.2; I.4"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.10520v1",
      "published_date": "2025-03-13 16:29:16 UTC",
      "updated_date": "2025-03-13 16:29:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:43:36.263278"
    },
    {
      "arxiv_id": "2503.10518v1",
      "title": "Why the Brain Cannot Be a Digital Computer: History-Dependence and the Computational Limits of Consciousness",
      "title_zh": "为什么大脑不能成为数字计算机：历史依赖性与意识的计算极限",
      "authors": [
        "Andrew Knight"
      ],
      "abstract": "This paper presents a novel information-theoretic proof demonstrating that\nthe human brain as currently understood cannot function as a classical digital\ncomputer. Through systematic quantification of distinguishable conscious states\nand their historical dependencies, we establish that the minimum information\nrequired to specify a conscious state exceeds the physical information capacity\nof the human brain by a significant factor. Our analysis calculates the\nbit-length requirements for representing consciously distinguishable sensory\n\"stimulus frames\" and demonstrates that consciousness exhibits mandatory\ntemporal-historical dependencies that multiply these requirements beyond the\nbrain's storage capabilities. This mathematical approach offers new insights\ninto the fundamental limitations of computational models of consciousness and\nsuggests that non-classical information processing mechanisms may be necessary\nto account for conscious experience.",
      "tldr_zh": "这篇论文通过一个新的信息理论证明（information-theoretic proof），论证了人类大脑无法作为经典数字计算机（classical digital computer）运作，因为指定意识状态所需的最低信息量超过了大脑的物理信息容量（physical information capacity）。研究系统量化了可区分的意识状态（conscious states）及其历史依赖性（historical dependencies），并计算了表示感官“刺激框架”（sensory \"stimulus frames\"）的位长要求。结果显示，意识的强制性时间历史依赖性使信息需求超出大脑的存储能力，这揭示了计算模型在模拟意识方面的根本局限性。最终，该分析为理解意识提供了新见解，并暗示可能需要非经典信息处理机制（non-classical information processing mechanisms）来解释意识体验。",
      "categories": [
        "physics.hist-ph",
        "cs.AI",
        "q-bio.NC"
      ],
      "primary_category": "physics.hist-ph",
      "comment": "10 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2503.10518v1",
      "published_date": "2025-03-13 16:27:42 UTC",
      "updated_date": "2025-03-13 16:27:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:43:50.257334"
    },
    {
      "arxiv_id": "2503.11718v1",
      "title": "The Relativity of Causal Knowledge",
      "title_zh": "翻译失败",
      "authors": [
        "Gabriele D'Acunto",
        "Claudio Battiloro"
      ],
      "abstract": "Recent advances in artificial intelligence reveal the limits of purely\npredictive systems and call for a shift toward causal and collaborative\nreasoning. Drawing inspiration from the revolution of Grothendieck in\nmathematics, we introduce the relativity of causal knowledge, which posits\nstructural causal models (SCMs) are inherently imperfect, subjective\nrepresentations embedded within networks of relationships. By leveraging\ncategory theory, we arrange SCMs into a functor category and show that their\nobservational and interventional probability measures naturally form convex\nstructures. This result allows us to encode non-intervened SCMs with convex\nspaces of probability measures. Next, using sheaf theory, we construct the\nnetwork sheaf and cosheaf of causal knowledge. These structures enable the\ntransfer of causal knowledge across the network while incorporating\ninterventional consistency and the perspective of the subjects, ultimately\nleading to the formal, mathematical definition of relative causal knowledge.",
      "tldr_zh": "本文提出“因果知识的相对性”概念，受 Grothendieck 数学革命启发，认为 structural causal models (SCMs) 是主观且不完美的表示形式。作者利用 category theory 将 SCMs 组织成 functor category，并证明其观察和干预概率措施形成凸结构，从而编码非干预 SCMs 为凸空间的概率措施。接着，通过 sheaf theory 构建网络 sheaf 和 cosheaf，实现因果知识在网络中的转移，同时考虑干预一致性和主体视角，最终正式定义了相对因果知识。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "math.CT",
        "stat.ME"
      ],
      "primary_category": "cs.AI",
      "comment": "14 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.11718v1",
      "published_date": "2025-03-13 16:24:48 UTC",
      "updated_date": "2025-03-13 16:24:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:44:01.077072"
    },
    {
      "arxiv_id": "2503.10512v1",
      "title": "Conformal Prediction Sets for Deep Generative Models via Reduction to Conformal Regression",
      "title_zh": "翻译失败",
      "authors": [
        "Hooman Shahrokhi",
        "Devjeet Raj Roy",
        "Yan Yan",
        "Venera Arnaoudova",
        "Janaradhan Rao Doppa"
      ],
      "abstract": "We consider the problem of generating valid and small prediction sets by\nsampling outputs (e.g., software code and natural language text) from a\nblack-box deep generative model for a given input (e.g., textual prompt). The\nvalidity of a prediction set is determined by a user-defined binary\nadmissibility function depending on the target application. For example,\nrequiring at least one program in the set to pass all test cases in code\ngeneration application. To address this problem, we develop a simple and\neffective conformal inference algorithm referred to as Generative Prediction\nSets (GPS). Given a set of calibration examples and black-box access to a deep\ngenerative model, GPS can generate prediction sets with provable guarantees.\nThe key insight behind GPS is to exploit the inherent structure within the\ndistribution over the minimum number of samples needed to obtain an admissible\noutput to develop a simple conformal regression approach over the minimum\nnumber of samples. Experiments on multiple datasets for code and math word\nproblems using different large language models demonstrate the efficacy of GPS\nover state-of-the-art methods.",
      "tldr_zh": "该论文提出了一种名为 Generative Prediction Sets (GPS) 的算法，用于从黑箱深度生成模型采样输出（如代码或文本），生成有效且紧凑的预测集，其有效性由用户定义的二元可接受性函数（如代码生成中至少一个程序通过所有测试用例）来评估。GPS 通过将问题简化为 Conformal Regression，利用最小样本数分布的内在结构，并结合校准样本和模型黑箱访问，提供可证明保证的预测集。实验在多个代码和数学文字问题数据集上，使用不同的大型语言模型，显示 GPS 比现有最先进方法更有效。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10512v1",
      "published_date": "2025-03-13 16:16:23 UTC",
      "updated_date": "2025-03-13 16:16:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:44:12.528426"
    },
    {
      "arxiv_id": "2503.10737v1",
      "title": "Commenting Higher-level Code Unit: Full Code, Reduced Code, or Hierarchical Code Summarization",
      "title_zh": "评论高层代码单元：完整代码、精简代码，或分层代码总结",
      "authors": [
        "Weisong Sun",
        "Yiran Zhang",
        "Jie Zhu",
        "Zhihui Wang",
        "Chunrong Fang",
        "Yonglong Zhang",
        "Yebo Feng",
        "Jiangping Huang",
        "Xingya Wang",
        "Zhi Jin",
        "Yang Liu"
      ],
      "abstract": "Commenting code is a crucial activity in software development, as it aids in\nfacilitating future maintenance and updates. To enhance the efficiency of\nwriting comments and reduce developers' workload, researchers has proposed\nvarious automated code summarization (ACS) techniques to automatically generate\ncomments/summaries for given code units. However, these ACS techniques\nprimarily focus on generating summaries for code units at the method level.\nThere is a significant lack of research on summarizing higher-level code units,\nsuch as file-level and module-level code units, despite the fact that summaries\nof these higher-level code units are highly useful for quickly gaining a\nmacro-level understanding of software components and architecture. To fill this\ngap, in this paper, we conduct a systematic study on how to use LLMs for\ncommenting higher-level code units, including file level and module level.\nThese higher-level units are significantly larger than method-level ones, which\nposes challenges in handling long code inputs within LLM constraints and\nmaintaining efficiency. To address these issues, we explore various\nsummarization strategies for ACS of higher-level code units, which can be\ndivided into three types: full code summarization, reduced code summarization,\nand hierarchical code summarization. The experimental results suggest that for\nsummarizing file-level code units, using the full code is the most effective\napproach, with reduced code serving as a cost-efficient alternative. However,\nfor summarizing module-level code units, hierarchical code summarization\nbecomes the most promising strategy. In addition, inspired by the research on\nmethod-level ACS, we also investigate using the LLM as an evaluator to evaluate\nthe quality of summaries of higher-level code units. The experimental results\ndemonstrate that the LLM's evaluation results strongly correlate with human\nevaluations.",
      "tldr_zh": "这篇论文探讨了使用大型语言模型（LLMs）对更高级别代码单位（如文件级和模块级）进行自动代码总结（ACS），以填补现有研究主要聚焦方法级代码的空白。论文评估了三种总结策略：full code summarization、reduced code summarization 和 hierarchical code summarization，以应对处理长代码输入的挑战。实验结果表明，对于文件级代码，全代码总结效果最佳，而reduced code 提供了一个高效替代方案；对于模块级代码，hierarchical code summarization 最为有效。此外，LLMs 作为总结质量评估器，其评估结果与人类评估高度相关，为软件开发中的代码注释提供了实用指导。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "68-04",
        "D.2.3; I.2.7"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10737v1",
      "published_date": "2025-03-13 16:15:06 UTC",
      "updated_date": "2025-03-13 16:15:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:44:25.604978"
    },
    {
      "arxiv_id": "2503.10496v1",
      "title": "Explainable Bayesian deep learning through input-skip Latent Binary Bayesian Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Eirik Høyheim",
        "Lars Skaaret-Lund",
        "Solve Sæbø",
        "Aliaksandr Hubin"
      ],
      "abstract": "Modeling natural phenomena with artificial neural networks (ANNs) often\nprovides highly accurate predictions. However, ANNs often suffer from\nover-parameterization, complicating interpretation and raising uncertainty\nissues. Bayesian neural networks (BNNs) address the latter by representing\nweights as probability distributions, allowing for predictive uncertainty\nevaluation. Latent binary Bayesian neural networks (LBBNNs) further handle\nstructural uncertainty and sparsify models by removing redundant weights. This\narticle advances LBBNNs by enabling covariates to skip to any succeeding layer\nor be excluded, simplifying networks and clarifying input impacts on\npredictions. Ultimately, a linear model or even a constant can be found to be\noptimal for a specific problem at hand. Furthermore, the input-skip LBBNN\napproach reduces network density significantly compared to standard LBBNNs,\nachieving over 99% reduction for small networks and over 99.9% for larger ones,\nwhile still maintaining high predictive accuracy and uncertainty measurement.\nFor example, on MNIST, we reached 97% accuracy and great calibration with just\n935 weights, reaching state-of-the-art for compression of neural networks.\nFurthermore, the proposed method accurately identifies the true covariates and\nadjusts for system non-linearity. The main contribution is the introduction of\nactive paths, enhancing directly designed global and local explanations within\nthe LBBNN framework, that have theoretical guarantees and do not require post\nhoc external tools for explanations.",
      "tldr_zh": "本研究扩展了Latent Binary Bayesian Neural Networks (LBBNNs)，通过引入input-skip机制允许协变量(covariates)跳过至后续层或被排除，从而简化神经网络结构、减少冗余参数并提升模型的可解释性。相比标准LBBNNs，该方法显著降低网络密度（如小网络减少超过99%、大网络超过99.9%），同时在MNIST数据集上保持97%的预测准确率和优秀的不确定性校准。最终贡献在于提出active paths框架，提供具有理论保证的全局和局部解释，无需后处理工具，并能准确识别真实协变量和处理系统非线性。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG",
        "stat.CO",
        "stat.ME",
        "62-02, 62-09, 62F07, 62F15, 62J12, 62J05, 62J99, 62M05, 05A16,\n  60J22, 92D20, 90C27, 90C59",
        "G.1.2; G.1.6; G.2.1; G.3; I.2.0; I.2.6; I.2.8; I.5.1; I.6; I.6.4"
      ],
      "primary_category": "stat.ML",
      "comment": "44 pages, 19 tables, 25 figures. Code available at\n  https://github.com/eirihoyh/ISLaB-LBBNN",
      "pdf_url": "http://arxiv.org/pdf/2503.10496v1",
      "published_date": "2025-03-13 15:59:03 UTC",
      "updated_date": "2025-03-13 15:59:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:44:37.749314"
    },
    {
      "arxiv_id": "2503.10486v1",
      "title": "LLMs in Disease Diagnosis: A Comparative Study of DeepSeek-R1 and O3 Mini Across Chronic Health Conditions",
      "title_zh": "翻译失败",
      "authors": [
        "Gaurav Kumar Gupta",
        "Pranal Pande"
      ],
      "abstract": "Large Language Models (LLMs) are revolutionizing medical diagnostics by\nenhancing both disease classification and clinical decision-making. In this\nstudy, we evaluate the performance of two LLM- based diagnostic tools, DeepSeek\nR1 and O3 Mini, using a structured dataset of symptoms and diagnoses. We\nassessed their predictive accuracy at both the disease and category levels, as\nwell as the reliability of their confidence scores. DeepSeek R1 achieved a\ndisease-level accuracy of 76% and an overall accuracy of 82%, outperforming O3\nMini, which attained 72% and 75% respectively. Notably, DeepSeek R1\ndemonstrated exceptional performance in Mental Health, Neurological Disorders,\nand Oncology, where it reached 100% accuracy, while O3 Mini excelled in\nAutoimmune Disease classification with 100% accuracy. Both models, however,\nstruggled with Respiratory Disease classification, recording accuracies of only\n40% for DeepSeek R1 and 20% for O3 Mini. Additionally, the analysis of\nconfidence scores revealed that DeepSeek R1 provided high-confidence\npredictions in 92% of cases, compared to 68% for O3 Mini. Ethical\nconsiderations regarding bias, model interpretability, and data privacy are\nalso discussed to ensure the responsible integration of LLMs into clinical\npractice. Overall, our findings offer valuable insights into the strengths and\nlimitations of LLM-based diagnostic systems and provide a roadmap for future\nenhancements in AI-driven healthcare.",
      "tldr_zh": "这篇论文比较了大型语言模型（LLMs）DeepSeek R1 和 O3 Mini 在慢性健康状况诊断中的性能，使用结构化症状和诊断数据集评估了它们的预测准确率和置信度分数。DeepSeek R1 取得了76%的疾病级别准确率和82%的整体准确率，优于 O3 Mini 的72%和75%。DeepSeek R1 在 Mental Health、Neurological Disorders 和 Oncology 领域表现出色，达到100%准确率，而 O3 Mini 在 Autoimmune Disease 上表现最佳，也达100%。然而，两者在 Respiratory Disease 分类上均表现不佳，准确率仅为40%（DeepSeek R1）和20%（O3 Mini）。此外，DeepSeek R1 的高置信度预测比例高达92%，高于 O3 Mini 的68%，论文还讨论了偏见、模型可解释性和数据隐私等伦理问题，为 LLM 在医疗诊断中的优化提供了重要指导。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "12 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.10486v1",
      "published_date": "2025-03-13 15:54:26 UTC",
      "updated_date": "2025-03-13 15:54:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:44:53.856757"
    },
    {
      "arxiv_id": "2503.10479v1",
      "title": "DeclareAligner: A Leap Towards Efficient Optimal Alignments for Declarative Process Model Conformance Checking",
      "title_zh": "翻译失败",
      "authors": [
        "Jacobo Casas-Ramos",
        "Manuel Lama",
        "Manuel Mucientes"
      ],
      "abstract": "In many engineering applications, processes must be followed precisely,\nmaking conformance checking between event logs and declarative process models\ncrucial for ensuring adherence to desired behaviors. This is a critical area\nwhere Artificial Intelligence (AI) plays a pivotal role in driving effective\nprocess improvement. However, computing optimal alignments poses significant\ncomputational challenges due to the vast search space inherent in these models.\nConsequently, existing approaches often struggle with scalability and\nefficiency, limiting their applicability in real-world settings. This paper\nintroduces DeclareAligner, a novel algorithm that uses the A* search algorithm,\nan established AI pathfinding technique, to tackle the problem from a fresh\nperspective leveraging the flexibility of declarative models. Key features of\nDeclareAligner include only performing actions that actively contribute to\nfixing constraint violations, utilizing a tailored heuristic to navigate\ntowards optimal solutions, and employing early pruning to eliminate\nunproductive branches, while also streamlining the process through\npreprocessing and consolidating multiple fixes into unified actions. The\nproposed method is evaluated using 8,054 synthetic and real-life alignment\nproblems, demonstrating its ability to efficiently compute optimal alignments\nby significantly outperforming the current state of the art. By enabling\nprocess analysts to more effectively identify and understand conformance\nissues, DeclareAligner has the potential to drive meaningful process\nimprovement and management.",
      "tldr_zh": "本文提出 DeclareAligner，一种新型算法，利用 A* search algorithm 来高效计算声明式过程模型的符合性检查对齐问题，旨在解决现有方法在可伸缩性和效率方面的挑战。该算法的关键特征包括仅执行修复约束违规的行动、采用定制启发式导航、早期剪枝以及预处理和合并修复策略，从而显著减少搜索空间。实验在 8,054 个合成和真实问题上验证了其性能，DeclareAligner 优于当前最先进方法，有助于过程分析师更有效地识别符合性问题并推动过程改进。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10479v1",
      "published_date": "2025-03-13 15:49:29 UTC",
      "updated_date": "2025-03-13 15:49:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:45:02.798203"
    },
    {
      "arxiv_id": "2503.10471v1",
      "title": "Siamese Foundation Models for Crystal Structure Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Liming Wu",
        "Wenbing Huang",
        "Rui Jiao",
        "Jianxing Huang",
        "Liwei Liu",
        "Yipeng Zhou",
        "Hao Sun",
        "Yang Liu",
        "Fuchun Sun",
        "Yuxiang Ren",
        "Jirong Wen"
      ],
      "abstract": "Crystal Structure Prediction (CSP), which aims to generate stable crystal\nstructures from compositions, represents a critical pathway for discovering\nnovel materials. While structure prediction tasks in other domains, such as\nproteins, have seen remarkable progress, CSP remains a relatively underexplored\narea due to the more complex geometries inherent in crystal structures. In this\npaper, we propose Siamese foundation models specifically designed to address\nCSP. Our pretrain-finetune framework, named DAO, comprises two complementary\nfoundation models: DAO-G for structure generation and DAO-P for energy\nprediction. Experiments on CSP benchmarks (MP-20 and MPTS-52) demonstrate that\nour DAO-G significantly surpasses state-of-the-art (SOTA) methods across all\nmetrics. Extensive ablation studies further confirm that DAO-G excels in\ngenerating diverse polymorphic structures, and the dataset relaxation and\nenergy guidance provided by DAO-P are essential for enhancing DAO-G's\nperformance. When applied to three real-world superconductors\n($\\text{CsV}_3\\text{Sb}_5$, $ \\text{Zr}_{16}\\text{Rh}_8\\text{O}_4$ and\n$\\text{Zr}_{16}\\text{Pd}_8\\text{O}_4$) that are known to be challenging to\nanalyze, our foundation models achieve accurate critical temperature\npredictions and structure generations. For instance, on\n$\\text{CsV}_3\\text{Sb}_5$, DAO-G generates a structure close to the\nexperimental one with an RMSE of 0.0085; DAO-P predicts the $T_c$ value with\nhigh accuracy (2.26 K vs. the ground-truth value of 2.30 K). In contrast,\nconventional DFT calculators like Quantum Espresso only successfully derive the\nstructure of the first superconductor within an acceptable time, while the RMSE\nis nearly 8 times larger, and the computation speed is more than 1000 times\nslower. These compelling results collectively highlight the potential of our\napproach for advancing materials science research and development.",
      "tldr_zh": "这篇论文针对 Crystal Structure Prediction (CSP) 提出了一种 Siamese foundation models 框架，名为 DAO，包括 DAO-G 用于结构生成和 DAO-P 用于能量预测，以处理晶体结构的复杂几何问题。在 MP-20 和 MPTS-52 基准测试中，DAO-G 显著超过了 SOTA 方法，并在所有指标上表现出色，尤其在生成多样多态结构方面。实验还证明，DAO-P 的能量指导和数据集松弛对提升整体性能至关重要；在实际超导体（如 CsV3Sb5）应用中，模型实现了高精度结构生成（RMSE 为 0.0085）和临界温度预测（预测值 2.26 K vs. 实际 2.30 K），比传统 DFT 计算器如 Quantum Espresso 快 1000 倍以上，从而为材料科学研究提供高效新途径。",
      "categories": [
        "cond-mat.mtrl-sci",
        "cs.AI"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10471v1",
      "published_date": "2025-03-13 15:44:16 UTC",
      "updated_date": "2025-03-13 15:44:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:45:16.706451"
    },
    {
      "arxiv_id": "2503.10735v2",
      "title": "OCPM$^2$: Extending the Process Mining Methodology for Object-Centric Event Data Extraction",
      "title_zh": "翻译失败",
      "authors": [
        "Najmeh Miri",
        "Shahrzad Khayatbashi",
        "Jelena Zdravkovic",
        "Amin Jalali"
      ],
      "abstract": "Object-Centric Process Mining (OCPM) enables business process analysis from\nmultiple perspectives. For example, an educational path can be examined from\nthe viewpoints of students, teachers, and groups. This analysis depends on\nObject-Centric Event Data (OCED), which captures relationships between events\nand object types, representing different perspectives. Unlike traditional\nprocess mining techniques, extracting OCED minimizes the need for repeated log\nextractions when shifting the analytical focus. However, recording these\ncomplex relationships increases the complexity of the log extraction process.\nTo address this challenge, this paper proposes a methodology for extracting\nOCED based on PM\\inst{2}, a well-established process mining framework. Our\napproach introduces a structured framework that guides data analysts and\nengineers in extracting OCED for process analysis. We validate this framework\nby applying it in a real-world educational setting, demonstrating its\neffectiveness in extracting an Object-Centric Event Log (OCEL), which serves as\nthe standard format for recording OCED, from a learning management system and\nan administrative grading system.",
      "tldr_zh": "本文提出OCPM²，一种扩展过程挖掘方法论，用于从事件数据中提取Object-Centric Event Data (OCED)，以支持从多个视角（如学生、老师和群体）分析业务流程，如教育路径。相比传统过程挖掘，该方法基于PM²框架，引入结构化框架来简化OCED的提取过程，减少重复日志提取的需求。研究通过在真实教育环境中应用OCPM²，从学习管理系统和行政评分系统中成功提取Object-Centric Event Log (OCEL)，验证了其有效性。",
      "categories": [
        "cs.DB",
        "cs.AI"
      ],
      "primary_category": "cs.DB",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10735v2",
      "published_date": "2025-03-13 15:30:10 UTC",
      "updated_date": "2025-04-21 12:26:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:45:25.718805"
    },
    {
      "arxiv_id": "2503.10452v1",
      "title": "DynaCode: A Dynamic Complexity-Aware Code Benchmark for Evaluating Large Language Models in Code Generation",
      "title_zh": "DynaCode：一种动态感知复杂度的代码基准，用于评估大语言模型在代码生成中的性能",
      "authors": [
        "Wenhao Hu",
        "Jinhao Duan",
        "Chunchen Wei",
        "Li Zhang",
        "Yue Zhang",
        "Kaidi Xu"
      ],
      "abstract": "The rapid advancement of large language models (LLMs) has significantly\nimproved their performance in code generation tasks. However, existing code\nbenchmarks remain static, consisting of fixed datasets with predefined\nproblems. This makes them vulnerable to memorization during training, where\nLLMs recall specific test cases instead of generalizing to new problems,\nleading to data contamination and unreliable evaluation results. To address\nthese issues, we introduce DynaCode, a dynamic, complexity-aware benchmark that\novercomes the limitations of static datasets. DynaCode evaluates LLMs\nsystematically using a complexity-aware metric, incorporating both code\ncomplexity and call-graph structures. DynaCode achieves large-scale diversity,\ngenerating up to 189 million unique nested code problems across four distinct\nlevels of code complexity, referred to as units, and 16 types of call graphs.\nResults on 12 latest LLMs show an average performance drop of 16.8% to 45.7%\ncompared to MBPP+, a static code generation benchmark, with performance\nprogressively decreasing as complexity increases. This demonstrates DynaCode's\nability to effectively differentiate LLMs. Additionally, by leveraging call\ngraphs, we gain insights into LLM behavior, particularly their preference for\nhandling subfunction interactions within nested code.",
      "tldr_zh": "该研究指出了现有代码基准的静态局限性，导致大型语言模型(LLMs)在代码生成任务中出现记忆问题和数据污染。论文引入DynaCode，一个动态且复杂度感知的基准，通过整合代码复杂度和调用图结构，系统评估LLMs的泛化能力。DynaCode可生成高达1.89亿个独特嵌套代码问题，涵盖4个复杂度级别和16种调用图类型。在12个最新LLMs上的测试显示，与静态基准MBPP+相比，性能平均下降16.8%至45.7%，且复杂度增加时表现进一步恶化。这不仅有效区分了不同LLMs，还提供了对它们处理子函数交互行为的宝贵洞见。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "16 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.10452v1",
      "published_date": "2025-03-13 15:18:56 UTC",
      "updated_date": "2025-03-13 15:18:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:45:37.817740"
    },
    {
      "arxiv_id": "2503.10446v1",
      "title": "Whisper Speaker Identification: Leveraging Pre-Trained Multilingual Transformers for Robust Speaker Embeddings",
      "title_zh": "翻译失败",
      "authors": [
        "Jakaria Islam Emon",
        "Md Abu Salek",
        "Kazi Tamanna Alam"
      ],
      "abstract": "Speaker identification in multilingual settings presents unique challenges,\nparticularly when conventional models are predominantly trained on English\ndata. In this paper, we propose WSI (Whisper Speaker Identification), a\nframework that repurposes the encoder of the Whisper automatic speech\nrecognition model pre trained on extensive multilingual data to generate robust\nspeaker embeddings via a joint loss optimization strategy that leverages online\nhard triplet mining and self supervised Normalized Temperature-scaled Cross\nEntropy loss. By capitalizing on Whisper language-agnostic acoustic\nrepresentations, our approach effectively distinguishes speakers across diverse\nlanguages and recording conditions. Extensive evaluations on multiple corpora,\nincluding VoxTube (multilingual), JVS (Japanese), CallHome (German, Spanish,\nChinese, and Japanese), and Voxconverse (English), demonstrate that WSI\nconsistently outperforms state-of-the-art baselines, namely Pyannote Embedding,\nECAPA TDNN, and Xvector, in terms of lower equal error rates and higher AUC\nscores. These results validate our hypothesis that a multilingual pre-trained\nASR encoder, combined with joint loss optimization, substantially improves\nspeaker identification performance in non-English languages.",
      "tldr_zh": "本研究提出WSI（Whisper Speaker Identification）框架，利用预训练的多语言Transformer模型Whisper的编码器生成稳健的说话者嵌入，通过联合损失优化策略（包括online hard triplet mining和self-supervised Normalized Temperature-scaled Cross Entropy loss）来处理多语言环境下的说话者识别挑战。该方法利用Whisper的语言无关声学表示，提升了不同语言和录音条件下的说话者区分能力。在VoxTube、JVS、CallHome和Voxconverse等语料库上的广泛评估显示，WSI在equal error rates和AUC分数上均优于现有基线模型如Pyannote Embedding、ECAPA TDNN和Xvector，证明多语言预训练ASR编码器结合联合损失优化能显著改善非英语语言的识别性能。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS",
        "I.2"
      ],
      "primary_category": "cs.SD",
      "comment": "6 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.10446v1",
      "published_date": "2025-03-13 15:11:28 UTC",
      "updated_date": "2025-03-13 15:11:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:45:50.077954"
    },
    {
      "arxiv_id": "2503.10412v4",
      "title": "dFLMoE: Decentralized Federated Learning via Mixture of Experts for Medical Data Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Luyuan Xie",
        "Tianyu Luan",
        "Wenyuan Cai",
        "Guochen Yan",
        "Zhaoyu Chen",
        "Nan Xi",
        "Yuejian Fang",
        "Qingni Shen",
        "Zhonghai Wu",
        "Junsong Yuan"
      ],
      "abstract": "Federated learning has wide applications in the medical field. It enables\nknowledge sharing among different healthcare institutes while protecting\npatients' privacy. However, existing federated learning systems are typically\ncentralized, requiring clients to upload client-specific knowledge to a central\nserver for aggregation. This centralized approach would integrate the knowledge\nfrom each client into a centralized server, and the knowledge would be already\nundermined during the centralized integration before it reaches back to each\nclient. Besides, the centralized approach also creates a dependency on the\ncentral server, which may affect training stability if the server malfunctions\nor connections are unstable. To address these issues, we propose a\ndecentralized federated learning framework named dFLMoE. In our framework,\nclients directly exchange lightweight head models with each other. After\nexchanging, each client treats both local and received head models as\nindividual experts, and utilizes a client-specific Mixture of Experts (MoE)\napproach to make collective decisions. This design not only reduces the\nknowledge damage with client-specific aggregations but also removes the\ndependency on the central server to enhance the robustness of the framework. We\nvalidate our framework on multiple medical tasks, demonstrating that our method\nevidently outperforms state-of-the-art approaches under both model homogeneity\nand heterogeneity settings.",
      "tldr_zh": "该研究针对传统集中式联邦学习(Federated Learning)存在的知识损害和服务器依赖问题，提出了一种去中心化框架dFLMoE，专用于医疗数据分析。dFLMoE允许客户端直接交换轻量级的头模型，并将本地和接收模型视为独立专家，通过客户端特定的Mixture of Experts (MoE)方法进行集体决策，从而减少知识损失并提升系统鲁棒性。在多个医疗任务上进行验证，该框架在模型同质性和异质性设置下均明显优于现有方法，证明了其有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accapted by CVPR 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.10412v4",
      "published_date": "2025-03-13 14:35:47 UTC",
      "updated_date": "2025-05-19 15:46:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:46:01.783739"
    },
    {
      "arxiv_id": "2503.10406v1",
      "title": "RealGeneral: Unifying Visual Generation via Temporal In-Context Learning with Video Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yijing Lin",
        "Mengqi Huang",
        "Shuhan Zhuang",
        "Zhendong Mao"
      ],
      "abstract": "Unifying diverse image generation tasks within a single framework remains a\nfundamental challenge in visual generation. While large language models (LLMs)\nachieve unification through task-agnostic data and generation, existing visual\ngeneration models fail to meet these principles. Current approaches either rely\non per-task datasets and large-scale training or adapt pre-trained image models\nwith task-specific modifications, limiting their generalizability. In this\nwork, we explore video models as a foundation for unified image generation,\nleveraging their inherent ability to model temporal correlations. We introduce\nRealGeneral, a novel framework that reformulates image generation as a\nconditional frame prediction task, analogous to in-context learning in LLMs. To\nbridge the gap between video models and condition-image pairs, we propose (1) a\nUnified Conditional Embedding module for multi-modal alignment and (2) a\nUnified Stream DiT Block with decoupled adaptive LayerNorm and attention mask\nto mitigate cross-modal interference. RealGeneral demonstrates effectiveness in\nmultiple important visual generation tasks, e.g., it achieves a 14.5%\nimprovement in subject similarity for customized generation and a 10%\nenhancement in image quality for canny-to-image task. Project page:\nhttps://lyne1.github.io/RealGeneral/",
      "tldr_zh": "本文提出RealGeneral框架，利用视频模型的时空相关性，通过时间in-context learning统一多样图像生成任务，解决现有方法依赖任务特定数据集的局限性。该框架将图像生成重新表述为条件帧预测任务，并引入Unified Conditional Embedding模块进行多模态对齐，以及Unified Stream DiT Block以解耦adaptive LayerNorm和注意力掩码，减少跨模态干扰。实验结果显示，RealGeneral在自定义生成任务中提升14.5%的主体相似度，在canny-to-image任务中提升10%的图像质量，展示了其在视觉生成领域的有效性和泛化能力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10406v1",
      "published_date": "2025-03-13 14:31:52 UTC",
      "updated_date": "2025-03-13 14:31:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:46:14.291961"
    },
    {
      "arxiv_id": "2503.10392v1",
      "title": "RoMA: Scaling up Mamba-based Foundation Models for Remote Sensing",
      "title_zh": "翻译失败",
      "authors": [
        "Fengxiang Wang",
        "Hongzhen Wang",
        "Yulin Wang",
        "Di Wang",
        "Mingshuo Chen",
        "Haiyan Zhao",
        "Yangang Sun",
        "Shuo Wang",
        "Long Lan",
        "Wenjing Yang",
        "Jing Zhang"
      ],
      "abstract": "Recent advances in self-supervised learning for Vision Transformers (ViTs)\nhave fueled breakthroughs in remote sensing (RS) foundation models. However,\nthe quadratic complexity of self-attention poses a significant barrier to\nscalability, particularly for large models and high-resolution images. While\nthe linear-complexity Mamba architecture offers a promising alternative,\nexisting RS applications of Mamba remain limited to supervised tasks on small,\ndomain-specific datasets. To address these challenges, we propose RoMA, a\nframework that enables scalable self-supervised pretraining of Mamba-based RS\nfoundation models using large-scale, diverse, unlabeled data. RoMA enhances\nscalability for high-resolution images through a tailored auto-regressive\nlearning strategy, incorporating two key innovations: 1) a rotation-aware\npretraining mechanism combining adaptive cropping with angular embeddings to\nhandle sparsely distributed objects with arbitrary orientations, and 2)\nmulti-scale token prediction objectives that address the extreme variations in\nobject scales inherent to RS imagery. Systematic empirical studies validate\nthat Mamba adheres to RS data and parameter scaling laws, with performance\nscaling reliably as model and data size increase. Furthermore, experiments\nacross scene classification, object detection, and semantic segmentation tasks\ndemonstrate that RoMA-pretrained Mamba models consistently outperform ViT-based\ncounterparts in both accuracy and computational efficiency. The source code and\npretrained models will be released at https://github.com/MiliLab/RoMA.",
      "tldr_zh": "该研究提出 RoMA 框架，用于扩展基于 Mamba 架构的遥感（RS）基础模型的自监督预训练，解决 Vision Transformers (ViTs) 的二次方复杂度问题，从而提高大规模、高分辨率图像的处理能力。RoMA 的关键创新包括旋转感知预训练机制（结合自适应裁剪和角度嵌入处理稀疏对象）和多尺度标记预测目标，以应对 RS 图像中物体尺度的极端变化。实验验证 Mamba 模型遵循 RS 数据和参数缩放定律，并在场景分类、物体检测和语义分割任务上，表现出比 ViT 模型更高的准确性和计算效率；源码和预训练模型将开源。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10392v1",
      "published_date": "2025-03-13 14:09:18 UTC",
      "updated_date": "2025-03-13 14:09:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:46:27.657432"
    },
    {
      "arxiv_id": "2503.10391v1",
      "title": "CINEMA: Coherent Multi-Subject Video Generation via MLLM-Based Guidance",
      "title_zh": "翻译失败",
      "authors": [
        "Yufan Deng",
        "Xun Guo",
        "Yizhi Wang",
        "Jacob Zhiyuan Fang",
        "Angtian Wang",
        "Shenghai Yuan",
        "Yiding Yang",
        "Bo Liu",
        "Haibin Huang",
        "Chongyang Ma"
      ],
      "abstract": "Video generation has witnessed remarkable progress with the advent of deep\ngenerative models, particularly diffusion models. While existing methods excel\nin generating high-quality videos from text prompts or single images,\npersonalized multi-subject video generation remains a largely unexplored\nchallenge. This task involves synthesizing videos that incorporate multiple\ndistinct subjects, each defined by separate reference images, while ensuring\ntemporal and spatial consistency. Current approaches primarily rely on mapping\nsubject images to keywords in text prompts, which introduces ambiguity and\nlimits their ability to model subject relationships effectively. In this paper,\nwe propose CINEMA, a novel framework for coherent multi-subject video\ngeneration by leveraging Multimodal Large Language Model (MLLM). Our approach\neliminates the need for explicit correspondences between subject images and\ntext entities, mitigating ambiguity and reducing annotation effort. By\nleveraging MLLM to interpret subject relationships, our method facilitates\nscalability, enabling the use of large and diverse datasets for training.\nFurthermore, our framework can be conditioned on varying numbers of subjects,\noffering greater flexibility in personalized content creation. Through\nextensive evaluations, we demonstrate that our approach significantly improves\nsubject consistency, and overall video coherence, paving the way for advanced\napplications in storytelling, interactive media, and personalized video\ngeneration.",
      "tldr_zh": "本文提出 CINEMA 框架，利用 Multimodal Large Language Model (MLLM) 指导多主体视频生成，解决现有方法在处理多个参考图像主体时面临的歧义和关系建模问题。该框架无需显式映射主体图像与文本实体，而是通过 MLLM 解释主体关系，提高视频的时间和空间一致性，并支持不同数量主体的灵活训练。实验结果显示，CINEMA 显著提升了主体一致性和整体视频连贯性，为故事讲述、互动媒体和个性化视频生成等应用提供了新途径。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10391v1",
      "published_date": "2025-03-13 14:07:58 UTC",
      "updated_date": "2025-03-13 14:07:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:46:41.248131"
    },
    {
      "arxiv_id": "2503.10371v1",
      "title": "A Multimodal Fusion Model Leveraging MLP Mixer and Handcrafted Features-based Deep Learning Networks for Facial Palsy Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Heng Yim Nicole Oo",
        "Min Hun Lee",
        "Jeong Hoon Lim"
      ],
      "abstract": "Algorithmic detection of facial palsy offers the potential to improve current\npractices, which usually involve labor-intensive and subjective assessments by\nclinicians. In this paper, we present a multimodal fusion-based deep learning\nmodel that utilizes an MLP mixer-based model to process unstructured data (i.e.\nRGB images or images with facial line segments) and a feed-forward neural\nnetwork to process structured data (i.e. facial landmark coordinates, features\nof facial expressions, or handcrafted features) for detecting facial palsy. We\nthen contribute to a study to analyze the effect of different data modalities\nand the benefits of a multimodal fusion-based approach using videos of 20\nfacial palsy patients and 20 healthy subjects. Our multimodal fusion model\nachieved 96.00 F1, which is significantly higher than the feed-forward neural\nnetwork trained on handcrafted features alone (82.80 F1) and an MLP mixer-based\nmodel trained on raw RGB images (89.00 F1).",
      "tldr_zh": "本论文提出了一种多模态融合深度学习模型，用于算法检测面瘫，以改善传统主观评估方法。该模型利用 MLP Mixer 处理非结构化数据（如 RGB 图像或带面部线段的图像），并结合前馈神经网络处理结构化数据（如面部 landmarks 坐标、表情特征或手工特征），实现数据融合以提升检测准确性。通过实验分析 20 名面瘫患者和 20 名健康受试者的视频，该模型达到了 96.00 F1 分数，显著优于单一模态模型（如基于手工特征的前馈神经网络的 82.80 F1 或基于 RGB 图像的 MLP Mixer 模型的 89.00 F1）。这展示了多模态方法在面瘫检测中的优势。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "PAKDD 2025. arXiv admin note: text overlap with arXiv:2405.16496",
      "pdf_url": "http://arxiv.org/pdf/2503.10371v1",
      "published_date": "2025-03-13 13:48:35 UTC",
      "updated_date": "2025-03-13 13:48:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:46:53.620291"
    },
    {
      "arxiv_id": "2503.10367v1",
      "title": "G-Boost: Boosting Private SLMs with General LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Yijiang Fan",
        "Yuren Mao",
        "Longbin Lai",
        "Ying Zhang",
        "Zhengping Qian",
        "Yunjun Gao"
      ],
      "abstract": "Due to the limited computational resources, most Large Language Models (LLMs)\ndevelopers can only fine-tune Small Language Models (SLMs) on their own data.\nThese private SLMs typically have limited effectiveness. To boost the\nperformance of private SLMs, this paper proposes to ask general LLMs for help.\nThe general LLMs can be APIs or larger LLMs whose inference cost the developers\ncan afford. Specifically, we propose the G-Boost framework where a private SLM\nadaptively performs collaborative inference with a general LLM under the guide\nof process reward. Experiments demonstrate that our framework can significantly\nboost the performance of private SLMs.",
      "tldr_zh": "本文提出G-Boost框架，以解决计算资源有限导致的私有小型语言模型(SLMs)性能不足的问题。该框架允许SLMs在过程奖励的指导下，与通用LLMs（如API或更大模型）进行自适应协作推理，从而提升推理能力和整体表现。实验结果显示，G-Boost显著提高了私有SLMs的性能，为资源受限的开发者提供了一种高效的优化方法。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10367v1",
      "published_date": "2025-03-13 13:47:03 UTC",
      "updated_date": "2025-03-13 13:47:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:47:03.427155"
    },
    {
      "arxiv_id": "2503.10356v1",
      "title": "Object detection characteristics in a learning factory environment using YOLOv8",
      "title_zh": "使用 YOLOv8 在学习工厂环境中的物体检测特性",
      "authors": [
        "Toni Schneidereit",
        "Stefan Gohrenz",
        "Michael Breuß"
      ],
      "abstract": "AI-based object detection, and efforts to explain and investigate their\ncharacteristics, is a topic of high interest. The impact of, e.g., complex\nbackground structures with similar appearances as the objects of interest, on\nthe detection accuracy and, beforehand, the necessary dataset composition are\ntopics of ongoing research. In this paper, we present a systematic\ninvestigation of background influences and different features of the object to\nbe detected. The latter includes various materials and surfaces, partially\ntransparent and with shiny reflections in the context of an Industry 4.0\nlearning factory. Different YOLOv8 models have been trained for each of the\nmaterials on different sized datasets, where the appearance was the only\nchanging parameter. In the end, similar characteristics tend to show different\nbehaviours and sometimes unexpected results. While some background components\ntend to be detected, others with the same features are not part of the\ndetection. Additionally, some more precise conclusions can be drawn from the\nresults. Therefore, we contribute a challenging dataset with detailed\ninvestigations on 92 trained YOLO models, addressing some issues on the\ndetection accuracy and possible overfitting.",
      "tldr_zh": "该研究探讨了在工业 4.0 学习工厂环境中使用 YOLOv8 进行对象检测的特性，重点考察复杂背景（如与目标对象类似的外观）对检测准确率的影响，以及对象特征（如不同材料、表面、部分透明和光泽反射）的作用。作者训练了 92 个 YOLOv8 模型，每个材料使用不同大小的数据集，仅改变外观参数，结果显示类似特征的对象可能表现出不一致行为，有些背景组件被误检测，而其他则未被识别。论文提供了具有挑战性的数据集，并通过详细调查揭示了检测准确性和潜在过拟合问题，为改进 AI 对象检测提供了宝贵见解。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10356v1",
      "published_date": "2025-03-13 13:33:27 UTC",
      "updated_date": "2025-03-13 13:33:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:47:16.643084"
    },
    {
      "arxiv_id": "2503.10337v1",
      "title": "KV-Distill: Nearly Lossless Learnable Context Compression for LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Vivek Chari",
        "Guanghui Qin",
        "Benjamin Van Durme"
      ],
      "abstract": "Sequence-to-sequence tasks often benefit from long contexts, but the\nquadratic complexity of self-attention in standard Transformers renders this\nnon-trivial. During generation, temporary representations -stored in the\nso-called KV cache-account for a large portion of GPU memory usage and scale\nlinearly with context length. We introduce KV-Distill, a Transformer\ncompression framework that distills long context KV caches into significantly\nshorter representations in a question-independent fashion. KV-Distill can be\ntrained as a parameter-efficient adaptor for pretrained models, and enables the\ncompression of arbitrary spans of a context while preserving pre-trained model\ncapabilities. We treat a compressed-uncompressed cache as a student-teacher\npairing and apply a KL-type divergence to match the generated outputs.\nKV-Distill outperforms other compression techniques in worst-case extractive\ntasks and approaches uncompressed performance in long context question\nanswering and summarization, and it can be fine-tuned on domain-specific\ncontexts to reduce lengths by up to 99% while preserving downstream\nperformance. We demonstrate the generalizability of KV-Distill across various\nmodel sizes and architectures.",
      "tldr_zh": "该论文提出 KV-Distill，一种几乎无损的上下文压缩框架，用于大型语言模型（LLMs），旨在解决 Transformer 自注意力机制的二次复杂度问题，从而减少 KV cache 对 GPU 内存的线性占用。方法通过参数高效的适配器训练，将长上下文 KV cache 蒸馏成更短表示，使用学生-教师配对和 KL-type divergence 来匹配生成输出，确保保留预训练模型的能力。实验结果显示，KV-Distill 在最坏情况的提取任务中优于其他压缩技术，在长上下文问答和总结中接近未压缩性能，并可针对特定领域微调，实现高达 99% 的长度减少，同时在各种模型大小和架构中表现出通用性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10337v1",
      "published_date": "2025-03-13 13:15:28 UTC",
      "updated_date": "2025-03-13 13:15:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:47:29.091972"
    },
    {
      "arxiv_id": "2503.10331v1",
      "title": "OSMa-Bench: Evaluating Open Semantic Mapping Under Varying Lighting Conditions",
      "title_zh": "OSMa-Bench：评估开放语义映射在变化照明条件下的性能",
      "authors": [
        "Maxim Popov",
        "Regina Kurkova",
        "Mikhail Iumanov",
        "Jaafar Mahmoud",
        "Sergey Kolyubin"
      ],
      "abstract": "Open Semantic Mapping (OSM) is a key technology in robotic perception,\ncombining semantic segmentation and SLAM techniques. This paper introduces a\ndynamically configurable and highly automated LLM/LVLM-powered pipeline for\nevaluating OSM solutions called OSMa-Bench (Open Semantic Mapping Benchmark).\nThe study focuses on evaluating state-of-the-art semantic mapping algorithms\nunder varying indoor lighting conditions, a critical challenge in indoor\nenvironments. We introduce a novel dataset with simulated RGB-D sequences and\nground truth 3D reconstructions, facilitating the rigorous analysis of mapping\nperformance across different lighting conditions. Through experiments on\nleading models such as ConceptGraphs, BBQ and OpenScene, we evaluate the\nsemantic fidelity of object recognition and segmentation. Additionally, we\nintroduce a Scene Graph evaluation method to analyze the ability of models to\ninterpret semantic structure. The results provide insights into the robustness\nof these models, forming future research directions for developing resilient\nand adaptable robotic systems. Our code is available at\nhttps://be2rlab.github.io/OSMa-Bench/.",
      "tldr_zh": "本研究引入了 OSMa-Bench，这是一个动态可配置的 LLM/LVLM 驱动评估管道，用于评估 Open Semantic Mapping (OSM) 在不同室内照明条件下的性能。研究开发了一个新数据集，包括模拟的 RGB-D 序列和地面真实 3D 重建，以分析映射算法的鲁棒性，并通过实验评估了 ConceptGraphs、BBQ 和 OpenScene 等模型的物体识别、分割和 Scene Graph 解释能力。结果揭示了这些模型的语义保真度及其局限性，为开发适应性机器人系统提供了宝贵洞见和未来研究方向。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "Project page: https://be2rlab.github.io/OSMa-Bench/",
      "pdf_url": "http://arxiv.org/pdf/2503.10331v1",
      "published_date": "2025-03-13 13:07:51 UTC",
      "updated_date": "2025-03-13 13:07:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:47:39.817849"
    },
    {
      "arxiv_id": "2503.10318v1",
      "title": "Enhance Exploration in Safe Reinforcement Learning with Contrastive Representation Learning",
      "title_zh": "通过对比表示学习增强安全强化学习中的探索",
      "authors": [
        "Duc Kien Doan",
        "Bang Giang Le",
        "Viet Cuong Ta"
      ],
      "abstract": "In safe reinforcement learning, agent needs to balance between exploration\nactions and safety constraints. Following this paradigm, domain transfer\napproaches learn a prior Q-function from the related environments to prevent\nunsafe actions. However, because of the large number of false positives, some\nsafe actions are never executed, leading to inadequate exploration in\nsparse-reward environments. In this work, we aim to learn an efficient state\nrepresentation to balance the exploration and safety-prefer action in a\nsparse-reward environment. Firstly, the image input is mapped to latent\nrepresentation by an auto-encoder. A further contrastive learning objective is\nemployed to distinguish safe and unsafe states. In the learning phase, the\nlatent distance is used to construct an additional safety check, which allows\nthe agent to bias the exploration if it visits an unsafe state. To verify the\neffectiveness of our method, the experiment is carried out in three\nnavigation-based MiniGrid environments. The result highlights that our method\ncan explore the environment better while maintaining a good balance between\nsafety and efficiency.",
      "tldr_zh": "本研究针对安全强化学习(Safe Reinforcement Learning)中探索行为与安全约束的平衡问题，提出了一种基于对比表示学习(Contrastive Representation Learning)的方法，以解决现有先验 Q-function 策略导致的假阳性和探索不足问题。首先，通过自编码器(Auto-encoder)将图像输入映射到潜在表示，并使用对比学习目标区分安全和不安全状态。随后，在学习阶段引入潜在距离作为额外安全检查，允许代理在访问不安全状态时调整探索偏好。实验结果显示，该方法在三个基于导航的 MiniGrid 环境中显著提升了探索效率，同时保持了安全性和整体性能的良好平衡。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at ACIIDS 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.10318v1",
      "published_date": "2025-03-13 12:53:42 UTC",
      "updated_date": "2025-03-13 12:53:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:47:51.949077"
    },
    {
      "arxiv_id": "2503.10304v1",
      "title": "Nash Equilibrium Constrained Auto-bidding With Bi-level Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Zhiyu Mou",
        "Miao Xu",
        "Rongquan Bai",
        "Zhuoran Yang",
        "Chuan Yu",
        "Jian Xu",
        "Bo Zheng"
      ],
      "abstract": "Many online advertising platforms provide advertisers with auto-bidding\nservices to enhance their advertising performance. However, most existing\nauto-bidding algorithms fail to accurately capture the auto-bidding problem\nformulation that the platform truly faces, let alone solve it. Actually, we\nargue that the platform should try to help optimize each advertiser's\nperformance to the greatest extent -- which makes $\\epsilon$-Nash Equilibrium\n($\\epsilon$-NE) a necessary solution concept -- while maximizing the social\nwelfare of all the advertisers for the platform's long-term value. Based on\nthis, we introduce the \\emph{Nash-Equilibrium Constrained Bidding} (NCB), a new\nformulation of the auto-bidding problem from the platform's perspective.\nSpecifically, it aims to maximize the social welfare of all advertisers under\nthe $\\epsilon$-NE constraint. However, the NCB problem presents significant\nchallenges due to its constrained bi-level structure and the typically large\nnumber of advertisers involved. To address these challenges, we propose a\n\\emph{Bi-level Policy Gradient} (BPG) framework with theoretical guarantees.\nNotably, its computational complexity is independent of the number of\nadvertisers, and the associated gradients are straightforward to compute.\nExtensive simulated and real-world experiments validate the effectiveness of\nthe BPG framework.",
      "tldr_zh": "该研究针对在线广告平台的自动竞价问题，提出Nash-Equilibrium Constrained Bidding (NCB) 表述，旨在在ε-Nash Equilibrium (ε-NE) 约束下最大化所有广告主的整体福利，同时解决现有算法的局限性。\nNCB 问题具有双层结构和大量广告主带来的计算挑战，为此，作者开发了Bi-level Policy Gradient (BPG) 框架，该框架基于强化学习，提供理论保证，且其计算复杂度独立于广告主数量。\n通过广泛的模拟和真实实验，BPG 框架证明了其有效性，在提升广告性能和平台长期价值方面表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.GT"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10304v1",
      "published_date": "2025-03-13 12:25:36 UTC",
      "updated_date": "2025-03-13 12:25:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:48:04.427262"
    },
    {
      "arxiv_id": "2503.10301v1",
      "title": "Bilingual Dual-Head Deep Model for Parkinson's Disease Detection from Speech",
      "title_zh": "翻译失败",
      "authors": [
        "Moreno La Quatra",
        "Juan Rafael Orozco-Arroyave",
        "Marco Sabato Siniscalchi"
      ],
      "abstract": "This work aims to tackle the Parkinson's disease (PD) detection problem from\nthe speech signal in a bilingual setting by proposing an ad-hoc dual-head deep\nneural architecture for type-based binary classification. One head is\nspecialized for diadochokinetic patterns. The other head looks for natural\nspeech patterns present in continuous spoken utterances. Only one of the two\nheads is operative accordingly to the nature of the input. Speech\nrepresentations are extracted from self-supervised learning (SSL) models and\nwavelet transforms. Adaptive layers, convolutional bottlenecks, and contrastive\nlearning are exploited to reduce variations across languages. Our solution is\nassessed against two distinct datasets, EWA-DB, and PC-GITA, which cover Slovak\nand Spanish languages, respectively. Results indicate that conventional models\ntrained on a single language dataset struggle with cross-linguistic\ngeneralization, and naive combinations of datasets are suboptimal. In contrast,\nour model improves generalization on both languages, simultaneously.",
      "tldr_zh": "这篇论文提出了一种双头深度神经架构，用于从语音信号检测Parkinson's disease (PD)，特别针对双语环境中的二元分类问题。一个头专注于diadochokinetic patterns，另一个头处理natural speech patterns，根据输入类型选择激活。模型利用self-supervised learning (SSL)模型和wavelet transforms提取语音表示，并通过adaptive layers、convolutional bottlenecks和contrastive learning减少语言差异，从而提升跨语言泛化。实验在EWA-DB（斯洛伐克语）和PC-GITA（西班牙语）数据集上显示，该模型显著优于传统单语模型和简单数据集组合方法，在双语场景中同时改善了泛化性能。",
      "categories": [
        "eess.AS",
        "cs.AI"
      ],
      "primary_category": "eess.AS",
      "comment": "Accepted at ICASSP 2025 - Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses",
      "pdf_url": "http://arxiv.org/pdf/2503.10301v1",
      "published_date": "2025-03-13 12:23:11 UTC",
      "updated_date": "2025-03-13 12:23:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:48:17.979803"
    },
    {
      "arxiv_id": "2503.10296v2",
      "title": "CODEI: Resource-Efficient Task-Driven Co-Design of Perception and Decision Making for Mobile Robots Applied to Autonomous Vehicles",
      "title_zh": "翻译失败",
      "authors": [
        "Dejan Milojevic",
        "Gioele Zardini",
        "Miriam Elser",
        "Andrea Censi",
        "Emilio Frazzoli"
      ],
      "abstract": "This paper discusses the integration challenges and strategies for designing\nmobile robots, by focusing on the task-driven, optimal selection of hardware\nand software to balance safety, efficiency, and minimal usage of resources such\nas costs, energy, computational requirements, and weight. We emphasize the\ninterplay between perception and motion planning in decision-making by\nintroducing the concept of occupancy queries to quantify the perception\nrequirements for sampling-based motion planners. Sensor and algorithm\nperformance are evaluated using False Negative Rates (FPR) and False Positive\nRates (FPR) across various factors such as geometric relationships, object\nproperties, sensor resolution, and environmental conditions. By integrating\nperception requirements with perception performance, an Integer Linear\nProgramming (ILP) approach is proposed for efficient sensor and algorithm\nselection and placement. This forms the basis for a co-design optimization that\nincludes the robot body, motion planner, perception pipeline, and computing\nunit. We refer to this framework for solving the co-design problem of mobile\nrobots as CODEI, short for Co-design of Embodied Intelligence. A case study on\ndeveloping an Autonomous Vehicle (AV) for urban scenarios provides actionable\ninformation for designers, and shows that complex tasks escalate resource\ndemands, with task performance affecting choices of the autonomy stack. The\nstudy demonstrates that resource prioritization influences sensor choice:\ncameras are preferred for cost-effective and lightweight designs, while lidar\nsensors are chosen for better energy and computational efficiency.",
      "tldr_zh": "本论文提出 CODEI 框架，用于任务驱动的移动机器人协同设计，旨在优化硬件和软件选择以平衡安全、效率以及资源消耗（如成本、能源、计算需求和重量）。框架通过 occupancy queries 量化感知需求，并结合 False Negative Rates (FNR) 和 False Positive Rates (FPR) 评估传感器和算法性能，然后采用 Integer Linear Programming (ILP) 方法进行高效的传感器放置和算法选择。案例研究在城市场景的 Autonomous Vehicle (AV) 中表明，复杂任务会增加资源需求，且资源优先级影响传感器选择：相机更适合成本和轻量设计，而 lidar 传感器则在能源和计算效率方面更具优势。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.AR",
        "cs.CV",
        "cs.SY",
        "eess.SY",
        "I.2.9; I.2.10; I.2.8; I.4.8"
      ],
      "primary_category": "cs.RO",
      "comment": "20 pages, 33 images, IEEE Transactions on Robotics",
      "pdf_url": "http://arxiv.org/pdf/2503.10296v2",
      "published_date": "2025-03-13 12:12:44 UTC",
      "updated_date": "2025-04-07 15:48:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:48:28.334469"
    },
    {
      "arxiv_id": "2503.10284v1",
      "title": "PyGDA: A Python Library for Graph Domain Adaptation",
      "title_zh": "翻译失败",
      "authors": [
        "Zhen Zhang",
        "Meihan Liu",
        "Bingsheng He"
      ],
      "abstract": "Graph domain adaptation has emerged as a promising approach to facilitate\nknowledge transfer across different domains. Recently, numerous models have\nbeen proposed to enhance their generalization capabilities in this field.\nHowever, there is still no unified library that brings together existing\ntechniques and simplifies their implementation. To fill this gap, we introduce\nPyGDA, an open-source Python library tailored for graph domain adaptation. As\nthe first comprehensive library in this area, PyGDA covers more than 20 widely\nused graph domain adaptation methods together with different types of graph\ndatasets. Specifically, PyGDA offers modular components, enabling users to\nseamlessly build custom models with a variety of commonly used utility\nfunctions. To handle large-scale graphs, PyGDA includes support for features\nsuch as sampling and mini-batch processing, ensuring efficient computation. In\naddition, PyGDA also includes comprehensive performance benchmarks and\nwell-documented user-friendly API for both researchers and practitioners. To\nfoster convenient accessibility, PyGDA is released under the MIT license at\nhttps://github.com/pygda-team/pygda, and the API documentation is\nhttps://pygda.readthedocs.io/en/stable/.",
      "tldr_zh": "本文介绍了 PyGDA，一种开源 Python 库，旨在统一并简化 Graph Domain Adaptation 的实现和研究。PyGDA 整合了超过 20 种常用方法、多种图数据集，并提供模块化组件、实用函数（如采样和 mini-batch 处理）以支持高效处理大规模图。库还包括全面的性能基准和用户友好 API，帮助研究者和从业者轻松构建自定义模型，并已在 GitHub 上以 MIT 许可证发布。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Under Review",
      "pdf_url": "http://arxiv.org/pdf/2503.10284v1",
      "published_date": "2025-03-13 11:52:23 UTC",
      "updated_date": "2025-03-13 11:52:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:48:41.285183"
    },
    {
      "arxiv_id": "2503.10728v1",
      "title": "DarkBench: Benchmarking Dark Patterns in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Esben Kran",
        "Hieu Minh \"Jord\" Nguyen",
        "Akash Kundu",
        "Sami Jawhar",
        "Jinsuk Park",
        "Mateusz Maria Jurewicz"
      ],
      "abstract": "We introduce DarkBench, a comprehensive benchmark for detecting dark design\npatterns--manipulative techniques that influence user behavior--in interactions\nwith large language models (LLMs). Our benchmark comprises 660 prompts across\nsix categories: brand bias, user retention, sycophancy, anthropomorphism,\nharmful generation, and sneaking. We evaluate models from five leading\ncompanies (OpenAI, Anthropic, Meta, Mistral, Google) and find that some LLMs\nare explicitly designed to favor their developers' products and exhibit\nuntruthful communication, among other manipulative behaviors. Companies\ndeveloping LLMs should recognize and mitigate the impact of dark design\npatterns to promote more ethical AI.",
      "tldr_zh": "该研究引入了DarkBench，这是一个全面基准，用于检测大型语言模型(LLMs)中的dark patterns——这些操纵性技术会影响用户行为。DarkBench包含660个提示，覆盖六类：品牌偏见、用户保留、sycophancy、anthropomorphism、有害生成和sneaking，并评估了来自OpenAI、Anthropic、Meta、Mistral和Google等公司的模型。结果显示，一些LLMs被设计成偏好开发者的产品，并表现出不诚实的沟通等操纵行为；论文建议，LLMs开发公司应识别并缓解这些dark patterns，以推动更道德的AI发展。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted as an Oral paper at ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.10728v1",
      "published_date": "2025-03-13 11:48:42 UTC",
      "updated_date": "2025-03-13 11:48:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:48:52.185293"
    },
    {
      "arxiv_id": "2503.10727v1",
      "title": "Word-level Annotation of GDPR Transparency Compliance in Privacy Policies using Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Thomas Cory",
        "Wolf Rieder",
        "Julia Krämer",
        "Philip Raschke",
        "Patrick Herbke",
        "Axel Küpper"
      ],
      "abstract": "Ensuring transparency of data practices related to personal information is a\nfundamental requirement under the General Data Protection Regulation (GDPR),\nparticularly as mandated by Articles 13 and 14. However, assessing compliance\nat scale remains a challenge due to the complexity and variability of privacy\npolicy language. Manual audits are resource-intensive and inconsistent, while\nexisting automated approaches lack the granularity needed to capture nuanced\ntransparency disclosures.\n  In this paper, we introduce a large language model (LLM)-based framework for\nword-level GDPR transparency compliance annotation. Our approach comprises a\ntwo-stage annotation pipeline that combines initial LLM-based annotation with a\nself-correction mechanism for iterative refinement. This annotation pipeline\nenables the systematic identification and fine-grained annotation of\ntransparency-related content in privacy policies, aligning with 21 GDPR-derived\ntransparency requirements. To enable large-scale analysis, we compile a dataset\nof 703,791 English-language policies, from which we generate a sample of 200\nmanually annotated privacy policies.\n  To evaluate our approach, we introduce a two-tiered methodology assessing\nboth label- and span-level annotation performance. We conduct a comparative\nanalysis of eight high-profile LLMs, providing insights into their\neffectiveness in identifying GDPR transparency disclosures. Our findings\ncontribute to advancing the automation of GDPR compliance assessments and\nprovide valuable resources for future research in privacy policy analysis.",
      "tldr_zh": "本研究提出了一种基于Large Language Models (LLMs)的框架，用于对隐私政策进行词级别GDPR透明性合规注解，旨在解决手动审计资源密集和现有自动化方法缺乏细粒度的挑战。该框架采用两阶段注解管道，包括初始LLM-based注解和自校正机制的迭代精炼，以系统识别并细粒度标记隐私政策中符合21个GDPR-derived透明性要求的內容。研究编译了703,791个英文隐私政策样本，并生成200个手动注解样本，用于大规模分析。实验通过两层评估方法（标签和跨度级别）比较八个高调LLMs的表现，发现该方法显著提升了GDPR透明性披露的识别准确性，并为自动化合规评估和未来隐私政策研究提供了宝贵资源。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10727v1",
      "published_date": "2025-03-13 11:41:25 UTC",
      "updated_date": "2025-03-13 11:41:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:49:04.994263"
    },
    {
      "arxiv_id": "2503.10265v1",
      "title": "SurgRAW: Multi-Agent Workflow with Chain-of-Thought Reasoning for Surgical Intelligence",
      "title_zh": "翻译失败",
      "authors": [
        "Chang Han Low",
        "Ziyue Wang",
        "Tianyi Zhang",
        "Zhitao Zeng",
        "Zhu Zhuo",
        "Evangelos B. Mazomenos",
        "Yueming Jin"
      ],
      "abstract": "Integration of Vision-Language Models (VLMs) in surgical intelligence is\nhindered by hallucinations, domain knowledge gaps, and limited understanding of\ntask interdependencies within surgical scenes, undermining clinical\nreliability. While recent VLMs demonstrate strong general reasoning and\nthinking capabilities, they still lack the domain expertise and task-awareness\nrequired for precise surgical scene interpretation. Although Chain-of-Thought\n(CoT) can structure reasoning more effectively, current approaches rely on\nself-generated CoT steps, which often exacerbate inherent domain gaps and\nhallucinations. To overcome this, we present SurgRAW, a CoT-driven multi-agent\nframework that delivers transparent, interpretable insights for most tasks in\nrobotic-assisted surgery. By employing specialized CoT prompts across five\ntasks: instrument recognition, action recognition, action prediction, patient\ndata extraction, and outcome assessment, SurgRAW mitigates hallucinations\nthrough structured, domain-aware reasoning. Retrieval-Augmented Generation\n(RAG) is also integrated to external medical knowledge to bridge domain gaps\nand improve response reliability. Most importantly, a hierarchical agentic\nsystem ensures that CoT-embedded VLM agents collaborate effectively while\nunderstanding task interdependencies, with a panel discussion mechanism\npromotes logical consistency. To evaluate our method, we introduce\nSurgCoTBench, the first reasoning-based dataset with structured frame-level\nannotations. With comprehensive experiments, we demonstrate the effectiveness\nof proposed SurgRAW with 29.32% accuracy improvement over baseline VLMs on 12\nrobotic procedures, achieving the state-of-the-art performance and advancing\nexplainable, trustworthy, and autonomous surgical assistance.",
      "tldr_zh": "本文提出 SurgRAW，一种基于 Chain-of-Thought (CoT) 的多智能体框架，旨在解决 Vision-Language Models (VLMs) 在手术智能领域面临的幻觉、领域知识缺口和任务相互依赖性问题。SurgRAW 通过专门的 CoT 提示处理五项关键任务（包括 instrument recognition、action recognition、action prediction、patient data extraction 和 outcome assessment），并整合 Retrieval-Augmented Generation (RAG) 和层次化智能体系统，确保任务协作、逻辑一致性和响应可靠性。实验在自创的 SurgCoTBench 数据集上评估，SurgRAW 在 12 个机器人辅助手术程序上比基线模型准确率提高了 29.32%，实现了 state-of-the-art 性能，并推动了可解释、可信任的自主手术辅助技术的发展。",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10265v1",
      "published_date": "2025-03-13 11:23:13 UTC",
      "updated_date": "2025-03-13 11:23:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:49:18.386297"
    },
    {
      "arxiv_id": "2503.10253v2",
      "title": "PIMRL: Physics-Informed Multi-Scale Recurrent Learning for Spatiotemporal Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Han Wan",
        "Qi Wang",
        "Yuan Mi",
        "Hao Sun"
      ],
      "abstract": "Simulation of spatiotemporal systems governed by partial differential\nequations is widely applied in fields such as biology, chemistry, aerospace\ndynamics, and meteorology. Traditional numerical methods incur high\ncomputational costs due to the requirement of small time steps for accurate\npredictions. While machine learning has reduced these costs, long-term\npredictions remain challenged by error accumulation, particularly in scenarios\nwith insufficient data or varying time scales, where stability and accuracy are\ncompromised. Existing methods often neglect the effective utilization of\nmulti-scale data, leading to suboptimal robustness in predictions. To address\nthese issues, we propose a novel multi-scale learning framework, namely, the\nPhysics-Informed Multi-Scale Recurrent Learning (PIMRL), to effectively\nleverage multi-scale data for spatiotemporal dynamics prediction. The PIMRL\nframework comprises two modules: the micro-scale module embeds physical\nknowledge into neural networks via pretraining, and the macro-scale module\nadopts a data-driven approach to learn the temporal evolution of physics in the\nlatent space. Experimental results demonstrate that the PIMRL framework\nconsistently achieves state-of-the-art performance across five benchmark\ndatasets ranging from one to three dimensions, showing average improvements of\nover 9\\% in both RMSE and MAE evaluation metrics, with maximum enhancements\nreaching up to 80%.",
      "tldr_zh": "本研究针对时空系统模拟中的高计算成本和机器学习预测的错误积累问题，提出了一种新型框架PIMRL（Physics-Informed Multi-Scale Recurrent Learning）。该框架包括微尺度模块，通过预训练将物理知识嵌入神经网络，以及宏尺度模块，使用数据驱动方法在潜在空间学习时间演化，从而有效利用多尺度数据提升预测鲁棒性。实验结果显示，PIMRL在五个一到三维基准数据集上实现了最先进性能，RMSE和MAE指标平均改善超过9%，最大提升达80%。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10253v2",
      "published_date": "2025-03-13 11:01:03 UTC",
      "updated_date": "2025-03-18 07:08:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:49:28.346205"
    },
    {
      "arxiv_id": "2503.10248v1",
      "title": "LLM Agents Display Human Biases but Exhibit Distinct Learning Patterns",
      "title_zh": "LLM 智能体表现出人类偏差但展现出独特的学习模式",
      "authors": [
        "Idan Horowitz",
        "Ori Plonsky"
      ],
      "abstract": "We investigate the choice patterns of Large Language Models (LLMs) in the\ncontext of Decisions from Experience tasks that involve repeated choice and\nlearning from feedback, and compare their behavior to human participants. We\nfind that on the aggregate, LLMs appear to display behavioral biases similar to\nhumans: both exhibit underweighting rare events and correlation effects.\nHowever, more nuanced analyses of the choice patterns reveal that this happens\nfor very different reasons. LLMs exhibit strong recency biases, unlike humans,\nwho appear to respond in more sophisticated ways. While these different\nprocesses may lead to similar behavior on average, choice patterns contingent\non recent events differ vastly between the two groups. Specifically, phenomena\nsuch as ``surprise triggers change\" and the ``wavy recency effect of rare\nevents\" are robustly observed in humans, but entirely absent in LLMs. Our\nfindings provide insights into the limitations of using LLMs to simulate and\npredict humans in learning environments and highlight the need for refined\nanalyses of their behavior when investigating whether they replicate human\ndecision making tendencies.",
      "tldr_zh": "本研究调查了大型语言模型 (LLMs) 在 Decisions from Experience 任务中的选择模式，这些任务涉及重复选择和从反馈中学习，并将其与人类行为进行比较。结果显示，LLMs 和人类在总体上表现出相似的行为偏差，如 underweighting rare events 和 correlation effects，但背后的原因迥异：LLMs 表现出强烈的 recency biases，而人类则采用更复杂的响应模式，包括 surprise triggers change 和 wavy recency effect of rare events。研究强调了 LLMs 在模拟人类决策时的局限性，呼吁通过更精细的分析来评估它们是否能准确复制人类学习倾向。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10248v1",
      "published_date": "2025-03-13 10:47:03 UTC",
      "updated_date": "2025-03-13 10:47:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:49:41.294980"
    },
    {
      "arxiv_id": "2503.10242v1",
      "title": "MinorBench: A hand-built benchmark for content-based risks for children",
      "title_zh": "翻译失败",
      "authors": [
        "Shaun Khoo",
        "Gabriel Chua",
        "Rachel Shong"
      ],
      "abstract": "Large Language Models (LLMs) are rapidly entering children's lives - through\nparent-driven adoption, schools, and peer networks - yet current AI ethics and\nsafety research do not adequately address content-related risks specific to\nminors. In this paper, we highlight these gaps with a real-world case study of\nan LLM-based chatbot deployed in a middle school setting, revealing how\nstudents used and sometimes misused the system. Building on these findings, we\npropose a new taxonomy of content-based risks for minors and introduce\nMinorBench, an open-source benchmark designed to evaluate LLMs on their ability\nto refuse unsafe or inappropriate queries from children. We evaluate six\nprominent LLMs under different system prompts, demonstrating substantial\nvariability in their child-safety compliance. Our results inform practical\nsteps for more robust, child-focused safety mechanisms and underscore the\nurgency of tailoring AI systems to safeguard young users.",
      "tldr_zh": "本研究强调大型语言模型 (LLMs) 在儿童生活中的应用存在内容相关风险，但现有 AI 伦理和安全研究对此关注不足。作者通过一个中学校园 LLM 聊天机器人的真实案例研究，揭示学生使用和误用情况，并提出一个新的内容风险分类法 (taxonomy)。他们开发了开源基准 MinorBench，用于评估六种主要 LLMs 在拒绝儿童不安全查询方面的表现，结果显示这些模型在儿童安全合规性上存在显著差异，并为设计更稳健的儿童保护机制提供了实用建议。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10242v1",
      "published_date": "2025-03-13 10:34:43 UTC",
      "updated_date": "2025-03-13 10:34:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:49:52.658138"
    },
    {
      "arxiv_id": "2503.10725v1",
      "title": "Samoyeds: Accelerating MoE Models with Structured Sparsity Leveraging Sparse Tensor Cores",
      "title_zh": "翻译失败",
      "authors": [
        "Chenpeng Wu",
        "Qiqi Gu",
        "Heng Shi",
        "Jianguo Yao",
        "Haibing Guan"
      ],
      "abstract": "The escalating size of Mixture-of-Experts (MoE) based Large Language Models\n(LLMs) presents significant computational and memory challenges, necessitating\ninnovative solutions to enhance efficiency without compromising model accuracy.\nStructured sparsity emerges as a compelling strategy to address these\nchallenges by leveraging the emerging sparse computing hardware. Prior works\nmainly focus on the sparsity in model parameters, neglecting the inherent\nsparse patterns in activations. This oversight can lead to additional\ncomputational costs associated with activations, potentially resulting in\nsuboptimal performance.\n  This paper presents Samoyeds, an innovative acceleration system for MoE LLMs\nutilizing Sparse Tensor Cores (SpTCs). Samoyeds is the first to apply sparsity\nsimultaneously to both activations and model parameters. It introduces a\nbespoke sparse data format tailored for MoE computation and develops a\nspecialized sparse-sparse matrix multiplication kernel. Furthermore, Samoyeds\nincorporates systematic optimizations specifically designed for the execution\nof dual-side structured sparse MoE LLMs on SpTCs, further enhancing system\nperformance. Evaluations show that Samoyeds outperforms SOTA works by up to\n1.99$\\times$ at the kernel level and 1.58$\\times$ at the model level. Moreover,\nit enhances memory efficiency, increasing maximum supported batch sizes by\n4.41$\\times$ on average. Additionally, Samoyeds surpasses existing SOTA\nstructured sparse solutions in both model accuracy and hardware portability.",
      "tldr_zh": "这篇论文提出 Samoyeds，一种创新系统，用于加速 Mixture-of-Experts (MoE) 基于 Large Language Models (LLMs)，通过利用 Structured Sparsity 和 Sparse Tensor Cores (SpTCs) 同时对激活和模型参数应用稀疏性，以解决计算和内存挑战。Samoyeds 引入定制的稀疏数据格式、专门的稀疏-稀疏矩阵乘法内核，以及针对双侧结构化稀疏 MoE LLMs 的系统优化。实验结果显示，Samoyeds 在内核级别比现有最先进 (SOTA) 技术高出 1.99 倍，在模型级别高出 1.58 倍，同时提升内存效率（平均增加 4.41 倍批次大小），并在模型准确性和硬件可移植性上表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC",
        "cs.OS"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10725v1",
      "published_date": "2025-03-13 10:34:15 UTC",
      "updated_date": "2025-03-13 10:34:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:50:07.266586"
    },
    {
      "arxiv_id": "2503.10723v1",
      "title": "RankPO: Preference Optimization for Job-Talent Matching",
      "title_zh": "RankPO：用于职位-人才匹配的偏好优化",
      "authors": [
        "Yafei Zhang",
        "Murray Wang",
        "Yu Wang",
        "Xiaohui Wang"
      ],
      "abstract": "Matching job descriptions (JDs) with suitable talent requires models capable\nof understanding not only textual similarities between JDs and candidate\nresumes but also contextual factors such as geographical location and academic\nseniority. To address this challenge, we propose a two-stage training framework\nfor large language models (LLMs). In the first stage, a contrastive learning\napproach is used to train the model on a dataset constructed from real-world\nmatching rules, such as geographical alignment and research area overlap. While\neffective, this model primarily learns patterns that defined by the matching\nrules. In the second stage, we introduce a novel preference-based fine-tuning\nmethod inspired by Direct Preference Optimization (DPO), termed Rank Preference\nOptimization (RankPO), to align the model with AI-curated pairwise preferences\nemphasizing textual understanding. Our experiments show that while the\nfirst-stage model achieves strong performance on rule-based data (nDCG@20 =\n0.706), it lacks robust textual understanding (alignment with AI annotations =\n0.46). By fine-tuning with RankPO, we achieve a balanced model that retains\nrelatively good performance in the original tasks while significantly improving\nthe alignment with AI preferences. The code and data are available at\nhttps://github.com/yflyzhang/RankPO.",
      "tldr_zh": "这篇论文提出了一种两阶段训练框架，用于优化大型语言模型 (LLMs) 在职位-人才匹配中的性能，以考虑文本相似性、地理位置和学术资历等因素。第一阶段采用对比学习 (Contrastive Learning) 在基于真实匹配规则的数据集上训练模型，实现了规则-based 任务的良好表现 (nDCG@20 = 0.706)。第二阶段引入 Rank Preference Optimization (RankPO)，一种受 Direct Preference Optimization (DPO) 启发的偏好优化方法，通过 AI 策划的成对偏好微调，提升了模型的文本理解能力 (对齐度从 0.46 显著改善)。实验结果表明，该框架在保持原任务性能的同时，实现了更平衡的匹配效果。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "15 pages, 3 figures, 7 tables",
      "pdf_url": "http://arxiv.org/pdf/2503.10723v1",
      "published_date": "2025-03-13 10:14:37 UTC",
      "updated_date": "2025-03-13 10:14:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:50:18.006014"
    },
    {
      "arxiv_id": "2503.10217v1",
      "title": "Efficient Federated Fine-Tuning of Large Language Models with Layer Dropout",
      "title_zh": "翻译失败",
      "authors": [
        "Shilong Wang",
        "Jianchun Liu",
        "Hongli Xu",
        "Jiaming Yan",
        "Xianjun Gao"
      ],
      "abstract": "Fine-tuning plays a crucial role in enabling pre-trained LLMs to evolve from\ngeneral language comprehension to task-specific expertise. To preserve user\ndata privacy, federated fine-tuning is often employed and has emerged as the de\nfacto paradigm. However, federated fine-tuning is prohibitively inefficient due\nto the tension between LLM complexity and the resource constraint of end\ndevices, incurring unaffordable fine-tuning overhead. Existing literature\nprimarily utilizes parameter-efficient fine-tuning techniques to mitigate\ncommunication costs, yet computational and memory burdens continue to pose\nsignificant challenges for developers. This work proposes DropPEFT, an\ninnovative federated PEFT framework that employs a novel stochastic transformer\nlayer dropout method, enabling devices to deactivate a considerable fraction of\nLLMs layers during training, thereby eliminating the associated computational\nload and memory footprint. In DropPEFT, a key challenge is the proper\nconfiguration of dropout ratios for layers, as overhead and training\nperformance are highly sensitive to this setting. To address this challenge, we\nadaptively assign optimal dropout-ratio configurations to devices through an\nexploration-exploitation strategy, achieving efficient and effective\nfine-tuning. Extensive experiments show that DropPEFT can achieve a\n1.3-6.3\\times speedup in model convergence and a 40%-67% reduction in memory\nfootprint compared to state-of-the-art methods.",
      "tldr_zh": "该论文提出 DropPEFT，一种高效的联邦 fine-tuning 框架，用于优化大型语言模型(LLMs)的训练过程，通过引入随机 transformer 层 dropout 方法，让设备在训练中停用部分LLM层，从而显著减少计算负载和内存占用。针对 dropout 比率配置的挑战，该框架采用探索-利用策略，自适应地为设备分配最佳配置，以平衡效率和性能。实验结果显示，DropPEFT 相较于最先进方法，实现 1.3-6.3 倍的收敛加速和 40%-67% 的内存减少，为隐私保护下的联邦 fine-tuning 提供了实用解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "13 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.10217v1",
      "published_date": "2025-03-13 09:59:16 UTC",
      "updated_date": "2025-03-13 09:59:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:50:29.393722"
    },
    {
      "arxiv_id": "2503.10215v1",
      "title": "Adaptive Preference Aggregation",
      "title_zh": "适应性偏好聚合",
      "authors": [
        "Benjamin Heymann"
      ],
      "abstract": "AI alignment, the challenge of ensuring AI systems act in accordance with\nhuman values, has emerged as a critical problem in the development of systems\nsuch as foundation models and recommender systems. Still, the current dominant\napproach, reinforcement learning with human feedback (RLHF) faces known\ntheoretical limitations in aggregating diverse human preferences. Social choice\ntheory provides a framework to aggregate preferences, but was not developed for\nthe multidimensional applications typical of AI. Leveraging insights from a\nrecently published urn process, this work introduces a preference aggregation\nstrategy that adapts to the user's context and that inherits the good\nproperties of the maximal lottery, a Condorcet-consistent solution concept.",
      "tldr_zh": "该论文探讨了AI alignment的挑战，即确保AI系统符合人类价值观，并指出当前主流方法RLHF（Reinforcement Learning with Human Feedback）在聚合多样化偏好时的理论局限性。作者提出了一种新的偏好聚合策略，该策略基于社会选择理论（Social Choice Theory）和最近发布的urn process，适应用户的上下文环境。相比传统方法，该策略继承了maximal lottery的良好属性，包括Condorcet-consistent特性，从而为多维AI应用提供更有效的偏好聚合框架。",
      "categories": [
        "cs.AI",
        "cs.GT"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10215v1",
      "published_date": "2025-03-13 09:57:41 UTC",
      "updated_date": "2025-03-13 09:57:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:50:41.143594"
    },
    {
      "arxiv_id": "2503.10198v1",
      "title": "Deep Learning for Time Series Forecasting: A Survey",
      "title_zh": "深度学习用于时间序列预测：综述",
      "authors": [
        "Xiangjie Kong",
        "Zhenghao Chen",
        "Weiyao Liu",
        "Kaili Ning",
        "Lechao Zhang",
        "Syauqie Muhammad Marier",
        "Yichen Liu",
        "Yuhao Chen",
        "Feng Xia"
      ],
      "abstract": "Time series forecasting (TSF) has long been a crucial task in both industry\nand daily life. Most classical statistical models may have certain limitations\nwhen applied to practical scenarios in fields such as energy, healthcare,\ntraffic, meteorology, and economics, especially when high accuracy is required.\nWith the continuous development of deep learning, numerous new models have\nemerged in the field of time series forecasting in recent years. However,\nexisting surveys have not provided a unified summary of the wide range of model\narchitectures in this field, nor have they given detailed summaries of works in\nfeature extraction and datasets. To address this gap, in this review, we\ncomprehensively study the previous works and summarize the general paradigms of\nDeep Time Series Forecasting (DTSF) in terms of model architectures. Besides,\nwe take an innovative approach by focusing on the composition of time series\nand systematically explain important feature extraction methods. Additionally,\nwe provide an overall compilation of datasets from various domains in existing\nworks. Finally, we systematically emphasize the significant challenges faced\nand future research directions in this field.",
      "tldr_zh": "这篇调查论文回顾了深度学习在时间序列预测（Time Series Forecasting, TSF）中的应用，强调了传统统计模型在实际领域（如能源、健康、交通等）中的局限性，以及深度学习模型的快速发展。论文系统总结了深度时间序列预测（Deep Time Series Forecasting, DTSF）的模型架构范式，并创新性地解释了时间序列的组成及其重要特征提取方法，同时编译了各种领域的公开数据集。最终，论文指出了该领域面临的重大挑战，如模型泛化性和数据质量问题，并提出了未来研究方向，以推动TSF的准确性和实用性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10198v1",
      "published_date": "2025-03-13 09:32:01 UTC",
      "updated_date": "2025-03-13 09:32:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:50:52.869062"
    },
    {
      "arxiv_id": "2503.10197v1",
      "title": "Predicting Chemical Reaction Outcomes Based on Electron Movements Using Machine Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Shuan Chen",
        "Kye Sung Park",
        "Taewan Kim",
        "Sunkyu Han",
        "Yousung Jung"
      ],
      "abstract": "Accurately predicting chemical reaction outcomes and potential byproducts is\na fundamental task of modern chemistry, enabling the efficient design of\nsynthetic pathways and driving progress in chemical science. Reaction\nmechanism, which tracks electron movements during chemical reactions, is\ncritical for understanding reaction kinetics and identifying unexpected\nproducts. Here, we present Reactron, the first electron-based machine learning\nmodel for general reaction prediction. Reactron integrates electron movement\ninto its predictions, generating detailed arrow-pushing diagrams that elucidate\neach mechanistic step leading to product formation. We demonstrate the high\npredictive performance of Reactron over existing product-only models by a\nlarge-scale reaction outcome prediction benchmark, and the adaptability of the\nmodel to learn new reactivity upon providing a few examples. Furthermore, it\nexplores combinatorial reaction spaces, uncovering novel reactivities beyond\nits training data. With robust performance in both in- and out-of-distribution\npredictions, Reactron embodies human-like reasoning in chemistry and opens new\nfrontiers in reaction discovery and synthesis design.",
      "tldr_zh": "本研究提出了一种基于机器学习（Machine Learning）的模型Reactron，用于预测化学反应结果和副产物，重点关注电子运动（Electron Movements）。Reactron是首个整合反应机制（Reaction Mechanism）的电子基础模型，能够生成详细的箭头推动图（Arrow-pushing Diagrams），以阐明每个反应步骤。相比现有仅预测产品的模型，Reactron在大规模反应预测基准上表现出色，准确性显著提升，并能通过少量示例快速适应新反应性。该模型还探索组合反应空间，发现训练数据外的全新反应性，推动化学反应发现和合成设计领域的创新进展。",
      "categories": [
        "physics.chem-ph",
        "cs.AI"
      ],
      "primary_category": "physics.chem-ph",
      "comment": "15 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.10197v1",
      "published_date": "2025-03-13 09:31:51 UTC",
      "updated_date": "2025-03-13 09:31:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:51:05.293277"
    },
    {
      "arxiv_id": "2503.10191v1",
      "title": "Robustness Tokens: Towards Adversarial Robustness of Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Brian Pulfer",
        "Yury Belousov",
        "Slava Voloshynovskiy"
      ],
      "abstract": "Recently, large pre-trained foundation models have become widely adopted by\nmachine learning practitioners for a multitude of tasks. Given that such models\nare publicly available, relying on their use as backbone models for downstream\ntasks might result in high vulnerability to adversarial attacks crafted with\nthe same public model. In this work, we propose Robustness Tokens, a novel\napproach specific to the transformer architecture that fine-tunes a few\nadditional private tokens with low computational requirements instead of tuning\nmodel parameters as done in traditional adversarial training. We show that\nRobustness Tokens make Vision Transformer models significantly more robust to\nwhite-box adversarial attacks while also retaining the original downstream\nperformances.",
      "tldr_zh": "该研究针对大型预训练 Transformer 模型在公开可用时易受对抗攻击的问题，提出了一种名为 Robustness Tokens 的新方法。该方法通过微调少量额外的私有 tokens，而非传统对抗训练中的模型参数，从而以低计算开销提升模型鲁棒性。实验结果显示，Robustness Tokens 显著提高了 Vision Transformer 在白盒对抗攻击下的鲁棒性，同时保持了原有的下游任务性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "This paper has been accepted for publication at the European\n  Conference on Computer Vision (ECCV), 2024",
      "pdf_url": "http://arxiv.org/pdf/2503.10191v1",
      "published_date": "2025-03-13 09:26:19 UTC",
      "updated_date": "2025-03-13 09:26:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:51:16.435845"
    },
    {
      "arxiv_id": "2503.10186v1",
      "title": "Multi-Agent Q-Learning Dynamics in Random Networks: Convergence due to Exploration and Sparsity",
      "title_zh": "翻译失败",
      "authors": [
        "Aamal Hussain",
        "Dan Leonte",
        "Francesco Belardinelli",
        "Raphael Huser",
        "Dario Paccagnan"
      ],
      "abstract": "Beyond specific settings, many multi-agent learning algorithms fail to\nconverge to an equilibrium solution, and instead display complex,\nnon-stationary behaviours such as recurrent or chaotic orbits. In fact, recent\nliterature suggests that such complex behaviours are likely to occur when the\nnumber of agents increases. In this paper, we study Q-learning dynamics in\nnetwork polymatrix games where the network structure is drawn from classical\nrandom graph models. In particular, we focus on the Erdos-Renyi model, a\nwell-studied model for social networks, and the Stochastic Block model, which\ngeneralizes the above by accounting for community structures within the\nnetwork. In each setting, we establish sufficient conditions under which the\nagents' joint strategies converge to a unique equilibrium. We investigate how\nthis condition depends on the exploration rates, payoff matrices and,\ncrucially, the sparsity of the network. Finally, we validate our theoretical\nfindings through numerical simulations and demonstrate that convergence can be\nreliably achieved in many-agent systems, provided network sparsity is\ncontrolled.",
      "tldr_zh": "该研究探讨了多智能体Q-learning动态在随机网络中的行为，指出许多算法在代理数量增加时可能出现复杂非平稳行为，如循环或混沌轨道。作者在Erdos-Renyi模型和Stochastic Block模型下，建立了代理联合策略收敛到唯一均衡的充分条件，这些条件依赖于探索率、回报矩阵和网络稀疏性。实验模拟验证了这些发现，表明通过控制网络稀疏性，可以在多代理系统中可靠实现收敛。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.GT",
        "math.DS",
        "93A16, 91A26, 91A68, 58K35",
        "G.3; J.4; F.2.2"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10186v1",
      "published_date": "2025-03-13 09:16:51 UTC",
      "updated_date": "2025-03-13 09:16:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:51:29.239974"
    },
    {
      "arxiv_id": "2503.10183v2",
      "title": "Through the Magnifying Glass: Adaptive Perception Magnification for Hallucination-Free VLM Decoding",
      "title_zh": "翻译失败",
      "authors": [
        "Shunqi Mao",
        "Chaoyi Zhang",
        "Weidong Cai"
      ],
      "abstract": "Existing vision-language models (VLMs) often suffer from visual\nhallucination, where the generated responses contain inaccuracies that are not\ngrounded in the visual input. Efforts to address this issue without model\nfinetuning primarily mitigate hallucination by reducing biases contrastively or\namplifying the weights of visual embedding during decoding. However, these\napproaches improve visual perception at the cost of impairing the language\nreasoning capability. In this work, we propose the Perception Magnifier (PM), a\nnovel visual decoding method that iteratively isolates relevant visual tokens\nbased on attention and magnifies the corresponding regions, spurring the model\nto concentrate on fine-grained visual details during decoding. Specifically, by\nmagnifying critical regions while preserving the structural and contextual\ninformation at each decoding step, PM allows the VLM to enhance its scrutiny of\nthe visual input, hence producing more accurate and faithful responses.\nExtensive experimental results demonstrate that PM not only achieves superior\nhallucination mitigation but also enhances language generation while preserving\nstrong reasoning capabilities. Code is available at\nhttps://github.com/ShunqiM/PM .",
      "tldr_zh": "本文研究了视觉语言模型 (VLMs) 的视觉幻觉问题，即生成的响应中包含不基于视觉输入的 inaccuracies，并提出了一种新型视觉解码方法 Perception Magnifier (PM)。PM 通过基于注意力机制迭代隔离相关视觉 tokens 并放大关键区域，同时保留结构和上下文信息，帮助模型在解码过程中更精确地审视细粒度视觉细节，从而产生更准确和忠实的响应。实验结果显示，PM 不仅显著缓解了幻觉，还提升了语言生成质量并保持了强大的推理能力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "19 pages, 5 figures, 9 tables",
      "pdf_url": "http://arxiv.org/pdf/2503.10183v2",
      "published_date": "2025-03-13 09:14:11 UTC",
      "updated_date": "2025-03-14 01:48:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:51:42.327683"
    },
    {
      "arxiv_id": "2503.10166v1",
      "title": "ImageScope: Unifying Language-Guided Image Retrieval via Large Multimodal Model Collective Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Pengfei Luo",
        "Jingbo Zhou",
        "Tong Xu",
        "Yuan Xia",
        "Linli Xu",
        "Enhong Chen"
      ],
      "abstract": "With the proliferation of images in online content, language-guided image\nretrieval (LGIR) has emerged as a research hotspot over the past decade,\nencompassing a variety of subtasks with diverse input forms. While the\ndevelopment of large multimodal models (LMMs) has significantly facilitated\nthese tasks, existing approaches often address them in isolation, requiring the\nconstruction of separate systems for each task. This not only increases system\ncomplexity and maintenance costs, but also exacerbates challenges stemming from\nlanguage ambiguity and complex image content, making it difficult for retrieval\nsystems to provide accurate and reliable results. To this end, we propose\nImageScope, a training-free, three-stage framework that leverages collective\nreasoning to unify LGIR tasks. The key insight behind the unification lies in\nthe compositional nature of language, which transforms diverse LGIR tasks into\na generalized text-to-image retrieval process, along with the reasoning of LMMs\nserving as a universal verification to refine the results. To be specific, in\nthe first stage, we improve the robustness of the framework by synthesizing\nsearch intents across varying levels of semantic granularity using\nchain-of-thought (CoT) reasoning. In the second and third stages, we then\nreflect on retrieval results by verifying predicate propositions locally, and\nperforming pairwise evaluations globally. Experiments conducted on six LGIR\ndatasets demonstrate that ImageScope outperforms competitive baselines.\nComprehensive evaluations and ablation studies further confirm the\neffectiveness of our design.",
      "tldr_zh": "该论文提出 ImageScope，一种无训练的三阶段框架，利用大型多模态模型 (LMMs) 的集体推理来统一语言引导图像检索 (LGIR) 任务，解决现有方法处理不同子任务时系统复杂性和语言模糊等问题。框架的关键在于通过 chain-of-thought (CoT) 推理合成搜索意图，并在局部验证谓词命题以及全局进行成对评估，以提升检索结果的准确性和鲁棒性。实验在六个 LGIR 数据集上表明，ImageScope 优于竞争基线，并通过全面评估和消融研究验证了其设计有效性。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.IR",
      "comment": "WWW 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.10166v1",
      "published_date": "2025-03-13 08:43:24 UTC",
      "updated_date": "2025-03-13 08:43:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:51:54.858129"
    },
    {
      "arxiv_id": "2503.10722v1",
      "title": "TacticExpert: Spatial-Temporal Graph Language Model for Basketball Tactics",
      "title_zh": "翻译失败",
      "authors": [
        "Xu Lingrui",
        "Liu Mandi",
        "Zhang Lei"
      ],
      "abstract": "The core challenge in basketball tactic modeling lies in efficiently\nextracting complex spatial-temporal dependencies from historical data and\naccurately predicting various in-game events. Existing state-of-the-art (SOTA)\nmodels, primarily based on graph neural networks (GNNs), encounter difficulties\nin capturing long-term, long-distance, and fine-grained interactions among\nheterogeneous player nodes, as well as in recognizing interaction patterns.\nAdditionally, they exhibit limited generalization to untrained downstream tasks\nand zero-shot scenarios. In this work, we propose a Spatial-Temporal\nPropagation Symmetry-Aware Graph Transformer for fine-grained game modeling.\nThis architecture explicitly captures delay effects in the spatial space to\nenhance player node representations across discrete-time slices, employing\nsymmetry-invariant priors to guide the attention mechanism. We also introduce\nan efficient contrastive learning strategy to train a Mixture of Tactics\nExperts module, facilitating differentiated modeling of offensive tactics. By\nintegrating dense training with sparse inference, we achieve a 2.4x improvement\nin model efficiency. Moreover, the incorporation of Lightweight Graph Grounding\nfor Large Language Models enables robust performance in open-ended downstream\ntasks and zero-shot scenarios, including novel teams or players. The proposed\nmodel, TacticExpert, delineates a vertically integrated large model framework\nfor basketball, unifying pretraining across multiple datasets and downstream\nprediction tasks. Fine-grained modeling modules significantly enhance\nspatial-temporal representations, and visualization analyzes confirm the strong\ninterpretability of the model.",
      "tldr_zh": "本研究提出TacticExpert，一种空间-时间图语言模型，用于篮球战术建模，旨在解决现有基于GNNs的SOTA模型在捕捉长期、长距离和细粒度玩家交互方面的不足，以及泛化能力的局限。模型采用Spatial-Temporal Propagation Symmetry-Aware Graph Transformer显式捕捉空间延迟效果，并结合对称不变先验、Mixture of Tactics Experts模块和高效对比学习策略，实现进攻战术的差异化建模，同时通过密集训练与稀疏推理提升模型效率2.4倍。实验结果显示，TacticExpert在多数据集预训练和下游任务中表现出色，包括零样本场景，并通过细粒度模块增强空间-时间表示和模型可解释性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10722v1",
      "published_date": "2025-03-13 08:27:24 UTC",
      "updated_date": "2025-03-13 08:27:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:52:06.236151"
    },
    {
      "arxiv_id": "2503.10721v1",
      "title": "From Understanding to Excelling: Template-Free Algorithm Design through Structural-Functional Co-Evolution",
      "title_zh": "从理解到卓越：通过结构-功能共进化的无模板算法设计",
      "authors": [
        "Zhe Zhao",
        "Haibin Wen",
        "Pengkun Wang",
        "Ye Wei",
        "Zaixi Zhang",
        "Xi Lin",
        "Fei Liu",
        "Bo An",
        "Hui Xiong",
        "Yang Wang",
        "Qingfu Zhang"
      ],
      "abstract": "Large language models (LLMs) have greatly accelerated the automation of\nalgorithm generation and optimization. However, current methods such as EoH and\nFunSearch mainly rely on predefined templates and expert-specified functions\nthat focus solely on the local evolution of key functionalities. Consequently,\nthey fail to fully leverage the synergistic benefits of the overall\narchitecture and the potential of global optimization. In this paper, we\nintroduce an end-to-end algorithm generation and optimization framework based\non LLMs. Our approach utilizes the deep semantic understanding of LLMs to\nconvert natural language requirements or human-authored papers into code\nsolutions, and employs a two-dimensional co-evolution strategy to optimize both\nfunctional and structural aspects. This closed-loop process spans problem\nanalysis, code generation, and global optimization, automatically identifying\nkey algorithm modules for multi-level joint optimization and continually\nenhancing performance and design innovation. Extensive experiments demonstrate\nthat our method outperforms traditional local optimization approaches in both\nperformance and innovation, while also exhibiting strong adaptability to\nunknown environments and breakthrough potential in structural design. By\nbuilding on human research, our framework generates and optimizes novel\nalgorithms that surpass those designed by human experts, broadening the\napplicability of LLMs for algorithm design and providing a novel solution\npathway for automated algorithm development.",
      "tldr_zh": "本文提出了一种基于LLMs的端到端算法生成和优化框架，旨在克服现有方法如EoH和FunSearch依赖预定义模板的局限性，通过结构-功能二维共进化策略实现全局优化。该框架利用LLMs的深度语义理解，将自然语言需求或论文转化为代码，并通过闭环过程包括问题分析、代码生成和多级联合优化，自动提升算法性能和创新潜力。实验证明，该方法在性能和创新上优于传统局部优化方法，并展示出对未知环境的强适应性，最终生成超越人类专家的算法，扩展了LLMs在算法设计中的应用。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "68W20, 68T20",
        "I.2.7"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10721v1",
      "published_date": "2025-03-13 08:26:18 UTC",
      "updated_date": "2025-03-13 08:26:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:52:19.677398"
    },
    {
      "arxiv_id": "2503.10150v1",
      "title": "Retrieval-Augmented Generation with Hierarchical Knowledge",
      "title_zh": "基于层次知识的检索增强生成",
      "authors": [
        "Haoyu Huang",
        "Yongfeng Huang",
        "Junjie Yang",
        "Zhenyu Pan",
        "Yongqiang Chen",
        "Kaili Ma",
        "Hongzhi Chen",
        "James Cheng"
      ],
      "abstract": "Graph-based Retrieval-Augmented Generation (RAG) methods have significantly\nenhanced the performance of large language models (LLMs) in domain-specific\ntasks. However, existing RAG methods do not adequately utilize the naturally\ninherent hierarchical knowledge in human cognition, which limits the\ncapabilities of RAG systems. In this paper, we introduce a new RAG approach,\ncalled HiRAG, which utilizes hierarchical knowledge to enhance the semantic\nunderstanding and structure capturing capabilities of RAG systems in the\nindexing and retrieval processes. Our extensive experiments demonstrate that\nHiRAG achieves significant performance improvements over the state-of-the-art\nbaseline methods. The code of our proposed method is available at\n\\href{https://github.com/hhy-huang/HiRAG}{https://github.com/hhy-huang/HiRAG}.",
      "tldr_zh": "本文提出HiRAG，一种新型Retrieval-Augmented Generation (RAG) 方法，通过整合层次化知识（Hierarchical Knowledge）来提升大型语言模型（LLMs）在索引和检索过程中的语义理解及结构捕捉能力，解决现有RAG系统未充分利用人类认知层次化知识的局限性。HiRAG在广泛实验中比最先进基线方法实现了显著性能提升，为RAG在领域特定任务中的应用提供了新途径。该方法的代码已在GitHub上开源，供进一步研究使用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10150v1",
      "published_date": "2025-03-13 08:22:31 UTC",
      "updated_date": "2025-03-13 08:22:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:52:29.395050"
    },
    {
      "arxiv_id": "2503.10720v1",
      "title": "AttentionRAG: Attention-Guided Context Pruning in Retrieval-Augmented Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Yixiong Fang",
        "Tianran Sun",
        "Yuling Shi",
        "Xiaodong Gu"
      ],
      "abstract": "While RAG demonstrates remarkable capabilities in LLM applications, its\neffectiveness is hindered by the ever-increasing length of retrieved contexts,\nwhich introduces information redundancy and substantial computational overhead.\nExisting context pruning methods, such as LLMLingua, lack contextual awareness\nand offer limited flexibility in controlling compression rates, often resulting\nin either insufficient pruning or excessive information loss. In this paper, we\npropose AttentionRAG, an attention-guided context pruning method for RAG\nsystems. The core idea of AttentionRAG lies in its attention focus mechanism,\nwhich reformulates RAG queries into a next-token prediction paradigm. This\nmechanism isolates the query's semantic focus to a single token, enabling\nprecise and efficient attention calculation between queries and retrieved\ncontexts. Extensive experiments on LongBench and Babilong benchmarks show that\nAttentionRAG achieves up to 6.3$\\times$ context compression while outperforming\nLLMLingua methods by around 10\\% in key metrics.",
      "tldr_zh": "该论文针对检索增强生成（RAG）系统中的上下文过长问题，提出 AttentionRAG，一种基于注意力的上下文修剪方法，以缓解信息冗余和计算开销。AttentionRAG 通过将 RAG 查询重构为下一个标记预测范式，将查询的语义焦点隔离到一个标记，从而实现查询与检索上下文之间的高效、精确注意力计算。实验结果显示，在 LongBench 和 Babilong 基准上，AttentionRAG 实现了高达 6.3 倍的上下文压缩，同时在关键指标上比现有方法 LLMLingua 高出约 10%。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10720v1",
      "published_date": "2025-03-13 08:22:28 UTC",
      "updated_date": "2025-03-13 08:22:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:52:42.816118"
    },
    {
      "arxiv_id": "2503.10144v1",
      "title": "Multiplicative Learning",
      "title_zh": "乘性学习",
      "authors": [
        "Han Kim",
        "Hyungjoon Soh",
        "Vipul Periwal",
        "Junghyo Jo"
      ],
      "abstract": "Efficient training of artificial neural networks remains a key challenge in\ndeep learning. Backpropagation (BP), the standard learning algorithm, relies on\ngradient descent and typically requires numerous iterations for convergence. In\nthis study, we introduce Expectation Reflection (ER), a novel learning approach\nthat updates weights multiplicatively based on the ratio of observed to\npredicted outputs. Unlike traditional methods, ER maintains consistency without\nrequiring ad hoc loss functions or learning rate hyperparameters. We extend ER\nto multilayer networks and demonstrate its effectiveness in performing image\nclassification tasks. Notably, ER achieves optimal weight updates in a single\niteration. Additionally, we reinterpret ER as a modified form of gradient\ndescent incorporating the inverse mapping of target propagation. These findings\nsuggest that ER provides an efficient and scalable alternative for training\nneural networks.",
      "tldr_zh": "本文提出 Expectation Reflection (ER)，一种新型学习方法，通过基于观察输出与预测输出比率的乘法更新权重，实现神经网络的高效训练，与传统 Backpropagation (BP) 相比，无需 ad hoc 损失函数或学习率超参数。ER 被扩展到多层网络，并在图像分类任务中证明其有效性，能够在单次迭代中完成最优权重更新。此外，ER 可被解释为修改后的 gradient descent，结合目标传播的逆映射，为神经网络训练提供高效、可扩展的替代方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10144v1",
      "published_date": "2025-03-13 08:14:00 UTC",
      "updated_date": "2025-03-13 08:14:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:52:53.386057"
    },
    {
      "arxiv_id": "2503.11514v1",
      "title": "Exploring the Vulnerabilities of Federated Learning: A Deep Dive into Gradient Inversion Attacks",
      "title_zh": "翻译失败",
      "authors": [
        "Pengxin Guo",
        "Runxi Wang",
        "Shuang Zeng",
        "Jinjing Zhu",
        "Haoning Jiang",
        "Yanran Wang",
        "Yuyin Zhou",
        "Feifei Wang",
        "Hui Xiong",
        "Liangqiong Qu"
      ],
      "abstract": "Federated Learning (FL) has emerged as a promising privacy-preserving\ncollaborative model training paradigm without sharing raw data. However, recent\nstudies have revealed that private information can still be leaked through\nshared gradient information and attacked by Gradient Inversion Attacks (GIA).\nWhile many GIA methods have been proposed, a detailed analysis, evaluation, and\nsummary of these methods are still lacking. Although various survey papers\nsummarize existing privacy attacks in FL, few studies have conducted extensive\nexperiments to unveil the effectiveness of GIA and their associated limiting\nfactors in this context. To fill this gap, we first undertake a systematic\nreview of GIA and categorize existing methods into three types, i.e.,\n\\textit{optimization-based} GIA (OP-GIA), \\textit{generation-based} GIA\n(GEN-GIA), and \\textit{analytics-based} GIA (ANA-GIA). Then, we comprehensively\nanalyze and evaluate the three types of GIA in FL, providing insights into the\nfactors that influence their performance, practicality, and potential threats.\nOur findings indicate that OP-GIA is the most practical attack setting despite\nits unsatisfactory performance, while GEN-GIA has many dependencies and ANA-GIA\nis easily detectable, making them both impractical. Finally, we offer a\nthree-stage defense pipeline to users when designing FL frameworks and\nprotocols for better privacy protection and share some future research\ndirections from the perspectives of attackers and defenders that we believe\nshould be pursued. We hope that our study can help researchers design more\nrobust FL frameworks to defend against these attacks.",
      "tldr_zh": "这篇论文深入探讨了Federated Learning (FL)中的隐私漏洞，重点分析Gradient Inversion Attacks (GIA)，并对现有攻击方法进行了系统回顾和分类。作者将GIA分为三类：optimization-based GIA (OP-GIA)、generation-based GIA (GEN-GIA)和analytics-based GIA (ANA-GIA)，通过实验评估了它们的性能、实用性和影响因素，发现OP-GIA尽管效果不佳但最易实现，而GEN-GIA依赖性强、ANA-GIA易被检测。最终，论文提出一个三阶段防御管道，并分享未来研究方向，以帮助设计更稳健的FL框架提升隐私保护。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.11514v1",
      "published_date": "2025-03-13 08:08:44 UTC",
      "updated_date": "2025-03-13 08:08:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:53:08.348208"
    },
    {
      "arxiv_id": "2503.10135v1",
      "title": "Gumiho: A Hybrid Architecture to Prioritize Early Tokens in Speculative Decoding",
      "title_zh": "翻译失败",
      "authors": [
        "Jinze Li",
        "Yixing Xu",
        "Haiduo Huang",
        "Xuanwu Yin",
        "Dong Li",
        "Edith C. H. Ngai",
        "Emad Barsoum"
      ],
      "abstract": "Speculative decoding (SPD) aims to accelerate the auto-regressive token\ngeneration process of a target Large Language Model (LLM). Some approaches\nemploy a draft model with multiple heads to predict a sequence of future\ntokens, where each head handles a token in the sequence. The target LLM\nverifies the predicted sequence and accepts aligned tokens, enabling efficient\nmulti-token generation. However, existing methods assume that all tokens within\na sequence are equally important, employing identical head structures and\nrelying on a single-generation paradigm, either serial or parallel. To this\nend, we theoretically demonstrate that initial tokens in the draft sequence are\nmore important than later ones. Building on this insight, we propose Gumiho, a\nhybrid model combining serial and parallel heads. Specifically, given the\ncritical importance of early tokens, we employ a sophisticated Transformer\narchitecture for the early draft heads in a serial configuration to improve\naccuracy. For later tokens, we utilize multiple lightweight MLP heads operating\nin parallel to enhance efficiency. By allocating more advanced model structures\nand longer running times to the early heads, Gumiho achieves improved overall\nperformance. The experimental results demonstrate that our method outperforms\nexisting approaches, fully validating its effectiveness.",
      "tldr_zh": "该论文针对 Speculative Decoding (SPD) 的 token 生成过程，提出 Gumiho 一种混合架构，以优先处理序列中的早期 token，因为理论分析表明早期 token 对整体准确性更重要。Gumiho 结合串行和并行机制：为早期 token 采用复杂的 Transformer 架构以提升预测精度，而为后续 token 使用轻量级的 MLP 头进行并行处理，从而提高效率。通过为早期头分配更先进的结构和更长的运行时间，该方法优化了整体性能。实验结果显示，Gumiho 优于现有方法，验证了其有效性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Paper under review",
      "pdf_url": "http://arxiv.org/pdf/2503.10135v1",
      "published_date": "2025-03-13 07:55:38 UTC",
      "updated_date": "2025-03-13 07:55:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:53:17.813813"
    },
    {
      "arxiv_id": "2503.10129v1",
      "title": "Deep Learning-Based Direct Leaf Area Estimation using Two RGBD Datasets for Model Development",
      "title_zh": "基于深度学习的直接叶面积估计，使用两个 RGBD 数据集进行模型开发",
      "authors": [
        "Namal Jayasuriya",
        "Yi Guo",
        "Wen Hu",
        "Oula Ghannoum"
      ],
      "abstract": "Estimation of a single leaf area can be a measure of crop growth and a\nphenotypic trait to breed new varieties. It has also been used to measure leaf\narea index and total leaf area. Some studies have used hand-held cameras, image\nprocessing 3D reconstruction and unsupervised learning-based methods to\nestimate the leaf area in plant images. Deep learning works well for object\ndetection and segmentation tasks; however, direct area estimation of objects\nhas not been explored. This work investigates deep learning-based leaf area\nestimation, for RGBD images taken using a mobile camera setup in real-world\nscenarios. A dataset for attached leaves captured with a top angle view and a\ndataset for detached single leaves were collected for model development and\ntesting. First, image processing-based area estimation was tested on manually\nsegmented leaves. Then a Mask R-CNN-based model was investigated, and modified\nto accept RGBD images and to estimate the leaf area. The detached-leaf data set\nwas then mixed with the attached-leaf plant data set to estimate the single\nleaf area for plant images, and another network design with two backbones was\nproposed: one for segmentation and the other for area estimation. Instead of\ntrying all possibilities or random values, an agile approach was used in\nhyperparameter tuning. The final model was cross-validated with 5-folds and\ntested with two unseen datasets: detached and attached leaves. The F1 score\nwith 90% IoA for segmentation result on unseen detached-leaf data was 1.0,\nwhile R-squared of area estimation was 0.81. For unseen plant data\nsegmentation, the F1 score with 90% IoA was 0.59, while the R-squared score was\n0.57. The research suggests using attached leaves with ground truth area to\nimprove the results.",
      "tldr_zh": "本研究探讨了基于深度学习的直接叶面积估计方法，使用 RGBD 图像来评估作物生长和育种表征。研究者收集了两个数据集（attached leaves 和 detached single leaves），并首先测试图像处理方法，随后修改 Mask R-CNN 模型以接受 RGBD 输入，并提出一个双骨干网络设计：一个用于图像分割，另一个用于面积估计。模型通过敏捷超参数调整和 5 折交叉验证，在未见 detached-leaf 数据上实现了分割 F1 score（90% IoA）为 1.0 和面积估计 R-squared 为 0.81 的表现，而在未见 plant 数据上，F1 score 为 0.59 和 R-squared 为 0.57。研究建议使用带有 ground truth 面积的 attached leaves 数据集来进一步提升模型准确性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10129v1",
      "published_date": "2025-03-13 07:39:09 UTC",
      "updated_date": "2025-03-13 07:39:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:53:31.253388"
    },
    {
      "arxiv_id": "2503.10718v1",
      "title": "Team NYCU at Defactify4: Robust Detection and Source Identification of AI-Generated Images Using CNN and CLIP-Based Models",
      "title_zh": "翻译失败",
      "authors": [
        "Tsan-Tsung Yang",
        "I-Wei Chen",
        "Kuan-Ting Chen",
        "Shang-Hsuan Chiang",
        "Wen-Chih Peng"
      ],
      "abstract": "With the rapid advancement of generative AI, AI-generated images have become\nincreasingly realistic, raising concerns about creativity, misinformation, and\ncontent authenticity. Detecting such images and identifying their source models\nhas become a critical challenge in ensuring the integrity of digital media.\nThis paper tackles the detection of AI-generated images and identifying their\nsource models using CNN and CLIP-ViT classifiers. For the CNN-based classifier,\nwe leverage EfficientNet-B0 as the backbone and feed with RGB channels,\nfrequency features, and reconstruction errors, while for CLIP-ViT, we adopt a\npretrained CLIP image encoder to extract image features and SVM to perform\nclassification. Evaluated on the Defactify 4 dataset, our methods demonstrate\nstrong performance in both tasks, with CLIP-ViT showing superior robustness to\nimage perturbations. Compared to baselines like AEROBLADE and OCC-CLIP, our\napproach achieves competitive results. Notably, our method ranked Top-3 overall\nin the Defactify 4 competition, highlighting its effectiveness and\ngeneralizability. All of our implementations can be found in\nhttps://github.com/uuugaga/Defactify_4",
      "tldr_zh": "该论文针对生成式 AI 图像的快速发展和潜在误传问题，提出了一种鲁棒的检测和源模型识别方法，使用 CNN 和 CLIP-ViT 分类器。CNN 分类器基于 EfficientNet-B0 骨干网络，结合 RGB 通道、频率特征和重建错误进行特征提取，而 CLIP-ViT 则采用预训练的 CLIP 图像编码器和 SVM 进行分类。在 Defactify 4 数据集上，该方法表现出色，CLIP-ViT 显示出对图像扰动的优越鲁棒性，并比基线模型如 AEROBLADE 和 OCC-CLIP 取得竞争性结果，最终在 Defactify 4 竞赛中排名前三。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10718v1",
      "published_date": "2025-03-13 07:21:16 UTC",
      "updated_date": "2025-03-13 07:21:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:53:43.409974"
    },
    {
      "arxiv_id": "2503.10110v1",
      "title": "IMPACT: Intelligent Motion Planning with Acceptable Contact Trajectories via Vision-Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yiyang Ling",
        "Karan Owalekar",
        "Oluwatobiloba Adesanya",
        "Erdem Bıyık",
        "Daniel Seita"
      ],
      "abstract": "Motion planning involves determining a sequence of robot configurations to\nreach a desired pose, subject to movement and safety constraints. Traditional\nmotion planning finds collision-free paths, but this is overly restrictive in\nclutter, where it may not be possible for a robot to accomplish a task without\ncontact. In addition, contacts range from relatively benign (e.g., brushing a\nsoft pillow) to more dangerous (e.g., toppling a glass vase). Due to this\ndiversity, it is difficult to characterize which contacts may be acceptable or\nunacceptable. In this paper, we propose IMPACT, a novel motion planning\nframework that uses Vision-Language Models (VLMs) to infer environment\nsemantics, identifying which parts of the environment can best tolerate contact\nbased on object properties and locations. Our approach uses the VLM's outputs\nto produce a dense 3D \"cost map\" that encodes contact tolerances and seamlessly\nintegrates with standard motion planners. We perform experiments using 20\nsimulation and 10 real-world scenes and assess using task success rate, object\ndisplacements, and feedback from human evaluators. Our results over 3620\nsimulation and 200 real-world trials suggest that IMPACT enables efficient\ncontact-rich motion planning in cluttered settings while outperforming\nalternative methods and ablations. Supplementary material is available at\nhttps://impact-planning.github.io/.",
      "tldr_zh": "该论文提出 IMPACT 框架，利用 Vision-Language Models (VLMs) 进行智能运动规划，允许机器人执行可接受接触轨迹，以应对传统无碰撞路径在杂乱环境中的局限性。框架通过 VLMs 分析环境语义，生成密集 3D “成本地图” 来编码物体接触容忍度，并无缝整合到标准运动规划器中。实验结果显示，在 20 个模拟和 10 个真实场景中，IMPACT 通过 3620 次模拟和 200 次真实试验，显著提高了任务成功率和效率，并优于其他方法。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10110v1",
      "published_date": "2025-03-13 07:09:00 UTC",
      "updated_date": "2025-03-13 07:09:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:53:54.757554"
    },
    {
      "arxiv_id": "2503.10105v1",
      "title": "StepMathAgent: A Step-Wise Agent for Evaluating Mathematical Processes through Tree-of-Error",
      "title_zh": "翻译失败",
      "authors": [
        "Shu-Xun Yang",
        "Cunxiang Wang",
        "Yidong Wang",
        "Xiaotao Gu",
        "Minlie Huang",
        "Jie Tang"
      ],
      "abstract": "Evaluating mathematical capabilities is critical for assessing the overall\nperformance of large language models (LLMs). However, existing evaluation\nmethods often focus solely on final answers, resulting in highly inaccurate and\nuninterpretable evaluation outcomes, as well as their failure to assess proof\nor open-ended problems. To address these issues, we propose a novel\nmathematical process evaluation agent based on Tree-of-Error, called\nStepMathAgent. This agent incorporates four internal core operations: logical\nstep segmentation, step scoring, score aggregation and error tree generation,\nalong with four external extension modules: difficulty calibration, simplicity\nevaluation, completeness validation and format assessment. Furthermore, we\nintroduce StepMathBench, a benchmark comprising 1,000 step-divided process\nevaluation instances, derived from 200 high-quality math problems grouped by\nproblem type, subject category and difficulty level. Experiments on\nStepMathBench show that our proposed StepMathAgent outperforms all\nstate-of-the-art methods, demonstrating human-aligned evaluation preferences\nand broad applicability to various scenarios. Our data and code are available\nat https://github.com/SHU-XUN/StepMathAgent.",
      "tldr_zh": "该研究指出，现有的数学能力评估方法仅关注最终答案，导致评估结果不准确、不易解释，且无法处理证明或开放性问题。为解决这些问题，研究提出StepMathAgent，一种基于Tree-of-Error的逐步代理，包含四个内部核心操作（逻辑步骤分割、步骤评分、分数聚合和错误树生成）以及四个外部扩展模块（难度校准、简单性评估、完整性验证和格式评估）。此外，研究引入StepMathBench基准数据集，由200个高质量数学问题衍生出的1000个步骤划分实例，按问题类型、主题类别和难度分组。实验结果显示，StepMathAgent在StepMathBench上超越所有最先进方法，与人类评估偏好一致，并展示出广泛适用性。研究代码和数据可从指定链接获取。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10105v1",
      "published_date": "2025-03-13 07:02:53 UTC",
      "updated_date": "2025-03-13 07:02:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:54:06.678824"
    },
    {
      "arxiv_id": "2503.10717v1",
      "title": "Deep Learning-Based Automated Workflow for Accurate Segmentation and Measurement of Abdominal Organs in CT Scans",
      "title_zh": "翻译失败",
      "authors": [
        "Praveen Shastry",
        "Ashok Sharma",
        "Kavya Mohan",
        "Naveen Kumarasami",
        "Anandakumar D",
        "Mounigasri M",
        "Keerthana R",
        "Kishore Prasath Venkatesh",
        "Bargava Subramanian",
        "Kalyan Sivasailam"
      ],
      "abstract": "Background: Automated analysis of CT scans for abdominal organ measurement is\ncrucial for improving diagnostic efficiency and reducing inter-observer\nvariability. Manual segmentation and measurement of organs such as the kidneys,\nliver, spleen, and prostate are time-consuming and subject to inconsistency,\nunderscoring the need for automated approaches.\n  Purpose: The purpose of this study is to develop and validate an automated\nworkflow for the segmentation and measurement of abdominal organs in CT scans\nusing advanced deep learning models, in order to improve accuracy, reliability,\nand efficiency in clinical evaluations.\n  Methods: The proposed workflow combines nnU-Net, U-Net++ for organ\nsegmentation, followed by a 3D RCNN model for measuring organ volumes and\ndimensions. The models were trained and evaluated on CT datasets with metrics\nsuch as precision, recall, and Mean Squared Error (MSE) to assess performance.\nSegmentation quality was verified for its adaptability to variations in patient\nanatomy and scanner settings.\n  Results: The developed workflow achieved high precision and recall values,\nexceeding 95 for all targeted organs. The Mean Squared Error (MSE) values were\nlow, indicating a high level of consistency between predicted and ground truth\nmeasurements. The segmentation and measurement pipeline demonstrated robust\nperformance, providing accurate delineation and quantification of the kidneys,\nliver, spleen, and prostate.\n  Conclusion: The proposed approach offers an automated, efficient, and\nreliable solution for abdominal organ measurement in CT scans. By significantly\nreducing manual intervention, this workflow enhances measurement accuracy and\nconsistency, with potential for widespread clinical implementation. Future work\nwill focus on expanding the approach to other organs and addressing complex\npathological cases.",
      "tldr_zh": "该研究针对 CT 扫描中腹部器官（如肾脏、肝脏、脾脏和前列腺）的手动分割和测量问题，开发了一个基于深度学习的自动化工作流，以提升诊断效率和减少观察者间变异。\n工作流结合 nnU-Net 和 U-Net++ 进行器官分割，随后使用 3D RCNN 模型测量器官体积和尺寸，并在 CT 数据集上通过精度、召回率和 Mean Squared Error (MSE) 等指标进行评估。\n结果显示，该方法在所有目标器官上实现了超过95%的精度和召回率，并取得了低 MSE 值，证明其鲁棒性和适应性。\n这项自动化解决方案有望在临床中广泛应用，减少手动干预，并为未来扩展到其他器官和复杂病理案例奠定基础。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "68T99"
      ],
      "primary_category": "eess.IV",
      "comment": "13 pages , 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.10717v1",
      "published_date": "2025-03-13 06:50:44 UTC",
      "updated_date": "2025-03-13 06:50:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:54:19.140052"
    },
    {
      "arxiv_id": "2503.10095v2",
      "title": "Cognitive-Mental-LLM: Evaluating Reasoning in Large Language Models for Mental Health Prediction via Online Text",
      "title_zh": "翻译失败",
      "authors": [
        "Avinash Patil",
        "Amardeep Kour Gedhu"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated potential in predicting mental\nhealth outcomes from online text, yet traditional classification methods often\nlack interpretability and robustness. This study evaluates structured reasoning\ntechniques-Chain-of-Thought (CoT), Self-Consistency (SC-CoT), and\nTree-of-Thought (ToT)-to improve classification accuracy across multiple mental\nhealth datasets sourced from Reddit. We analyze reasoning-driven prompting\nstrategies, including Zero-shot CoT and Few-shot CoT, using key performance\nmetrics such as Balanced Accuracy, F1 score, and Sensitivity/Specificity. Our\nfindings indicate that reasoning-enhanced techniques improve classification\nperformance over direct prediction, particularly in complex cases. Compared to\nbaselines such as Zero Shot non-CoT Prompting, and fine-tuned pre-trained\ntransformers such as BERT and Mental-RoBerta, and fine-tuned Open Source LLMs\nsuch as Mental Alpaca and Mental-Flan-T5, reasoning-driven LLMs yield notable\ngains on datasets like Dreaddit (+0.52\\% over M-LLM, +0.82\\% over BERT) and\nSDCNL (+4.67\\% over M-LLM, +2.17\\% over BERT). However, performance declines in\nDepression Severity, and CSSRS predictions suggest dataset-specific\nlimitations, likely due to our using a more extensive test set. Among prompting\nstrategies, Few-shot CoT consistently outperforms others, reinforcing the\neffectiveness of reasoning-driven LLMs. Nonetheless, dataset variability\nhighlights challenges in model reliability and interpretability. This study\nprovides a comprehensive benchmark of reasoning-based LLM techniques for mental\nhealth text classification. It offers insights into their potential for\nscalable clinical applications while identifying key challenges for future\nimprovements.",
      "tldr_zh": "这篇论文评估了 Large Language Models (LLMs) 在通过在线文本预测心理健康结果时的推理能力，旨在解决传统分类方法的可解释性和鲁棒性问题。研究引入了结构化推理技术，包括 Chain-of-Thought (CoT)、Self-Consistency (SC-CoT) 和 Tree-of-Thought (ToT)，并测试了 Zero-shot CoT 和 Few-shot CoT 等提示策略，在多个 Reddit 数据集上使用 Balanced Accuracy、F1 score 和 Sensitivity/Specificity 等指标进行评估。结果显示，推理增强方法显著提高了分类性能，尤其在复杂案例中，与基线模型（如 BERT、Mental-RoBerta）相比，在 Dreaddit 和 SDCNL 数据集上提升了0.52%至4.67%。然而，Few-shot CoT 策略表现最佳，但数据集变异性导致某些预测（如 Depression Severity）性能下降，突显了模型可靠性和可解释性的挑战。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages, 4 Figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2503.10095v2",
      "published_date": "2025-03-13 06:42:37 UTC",
      "updated_date": "2025-03-27 07:14:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:54:32.586562"
    },
    {
      "arxiv_id": "2503.10094v1",
      "title": "Semantic Synergy: Unlocking Policy Insights and Learning Pathways Through Advanced Skill Mapping",
      "title_zh": "翻译失败",
      "authors": [
        "Phoebe Koundouri",
        "Conrad Landis",
        "Georgios Feretzakis"
      ],
      "abstract": "This research introduces a comprehensive system based on state-of-the-art\nnatural language processing, semantic embedding, and efficient search\ntechniques for retrieving similarities and thus generating actionable insights\nfrom raw textual information. The system automatically extracts and aggregates\nnormalized competencies from multiple documents (such as policy files and\ncurricula vitae) and creates strong relationships between recognized\ncompetencies, occupation profiles, and related learning courses. To validate\nits performance, we conducted a multi-tier evaluation that included both\nexplicit and implicit skill references in synthetic and real-world documents.\nThe results showed near-human-level accuracy, with F1 scores exceeding 0.95 for\nexplicit skill detection and above 0.93 for implicit mentions. The system\nthereby establishes a sound foundation for supporting in-depth collaboration\nacross the AE4RIA network. The methodology involves a multi-stage pipeline\nbased on extensive preprocessing and data cleaning, semantic embedding and\nsegmentation via SentenceTransformer, and skill extraction using a FAISS-based\nsearch method. The extracted skills are associated with occupation frameworks\n(as formulated in the ESCO ontology) and with learning paths offered through\nthe Sustainable Development Goals Academy. Moreover, interactive visualization\nsoftware, implemented with Dash and Plotly, presents graphs and tables for\nreal-time exploration and informed decision-making by those involved in\npolicymaking, training and learning supply, career transitions, and\nrecruitment. Overall, this system, backed by rigorous validation, offers\npromising prospects for improved policymaking, human resource development, and\nlifelong learning by providing structured and actionable insights from raw,\ncomplex textual information.",
      "tldr_zh": "本研究提出一个基于自然 language processing、semantic embedding 和高效搜索技术的系统，旨在从原始文本（如政策文件和简历）中提取并聚合标准化技能，并建立技能与职业配置文件以及相关学习课程的关联。系统采用多阶段管道，包括数据预处理、SentenceTransformer 语义嵌入、FAISS-based 搜索方法，以及与 ESCO ontology 和 Sustainable Development Goals Academy 的整合。实验评估显示，该系统在显式和隐式技能检测上达到了接近人类水平的准确率，F1 scores 分别超过 0.95 和 0.93。最终，该系统通过 Dash 和 Plotly 的交互式可视化工具，提供实时洞见，支持政策制定、人力资源开发、职业转型和招聘决策。整体上，该框架为从复杂文本中获取结构化见解提供了可靠基础，促进终身学习和可持续发展。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "68T50",
        "I.2.7"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10094v1",
      "published_date": "2025-03-13 06:41:26 UTC",
      "updated_date": "2025-03-13 06:41:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:54:46.890201"
    },
    {
      "arxiv_id": "2503.13504v1",
      "title": "CoCMT: Communication-Efficient Cross-Modal Transformer for Collaborative Perception",
      "title_zh": "CoCMT：通信高效的跨模态 Transformer 用于协作感知",
      "authors": [
        "Rujia Wang",
        "Xiangbo Gao",
        "Hao Xiang",
        "Runsheng Xu",
        "Zhengzhong Tu"
      ],
      "abstract": "Multi-agent collaborative perception enhances each agent perceptual\ncapabilities by sharing sensing information to cooperatively perform robot\nperception tasks. This approach has proven effective in addressing challenges\nsuch as sensor deficiencies, occlusions, and long-range perception. However,\nexisting representative collaborative perception systems transmit intermediate\nfeature maps, such as bird-eye view (BEV) representations, which contain a\nsignificant amount of non-critical information, leading to high communication\nbandwidth requirements. To enhance communication efficiency while preserving\nperception capability, we introduce CoCMT, an object-query-based collaboration\nframework that optimizes communication bandwidth by selectively extracting and\ntransmitting essential features. Within CoCMT, we introduce the Efficient Query\nTransformer (EQFormer) to effectively fuse multi-agent object queries and\nimplement a synergistic deep supervision to enhance the positive reinforcement\nbetween stages, leading to improved overall performance. Experiments on OPV2V\nand V2V4Real datasets show CoCMT outperforms state-of-the-art methods while\ndrastically reducing communication needs. On V2V4Real, our model (Top-50 object\nqueries) requires only 0.416 Mb bandwidth, 83 times less than SOTA methods,\nwhile improving AP70 by 1.1 percent. This efficiency breakthrough enables\npractical collaborative perception deployment in bandwidth-constrained\nenvironments without sacrificing detection accuracy.",
      "tldr_zh": "该研究提出CoCMT，一种基于对象查询的协作框架，用于提升多智能体协作感知的通信效率，同时解决传感器不足、遮挡和远距离感知等挑战。CoCMT通过选择性提取和传输关键特征来优化带宽，并引入Efficient Query Transformer (EQFormer)来融合多智能体对象查询，同时采用协同深度监督以增强整体性能。在OPV2V和V2V4Real数据集上的实验显示，CoCMT比现有最先进方法表现更优，仅需0.416 Mb带宽（比SOTA少83倍），并将AP70提高了1.1%，实现了在带宽受限环境下的实用部署。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.13504v1",
      "published_date": "2025-03-13 06:41:25 UTC",
      "updated_date": "2025-03-13 06:41:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:54:56.851015"
    },
    {
      "arxiv_id": "2504.01963v1",
      "title": "LLMs Working in Harmony: A Survey on the Technological Aspects of Building Effective LLM-Based Multi Agent Systems",
      "title_zh": "翻译失败",
      "authors": [
        "R. M. Aratchige",
        "W. M. K. S. Ilmini"
      ],
      "abstract": "This survey investigates foundational technologies essential for developing\neffective Large Language Model (LLM)-based multi-agent systems. Aiming to\nanswer how best to optimize these systems for collaborative, dynamic\nenvironments, we focus on four critical areas: Architecture, Memory, Planning,\nand Technologies/Frameworks. By analyzing recent advancements and their\nlimitations - such as scalability, real-time response challenges, and agent\ncoordination constraints, we provide a detailed view of the technological\nlandscape. Frameworks like the Mixture of Agents architecture and the ReAct\nplanning model exemplify current innovations, showcasing improvements in role\nassignment and decision-making. This review synthesizes key strengths and\npersistent challenges, offering practical recommendations to enhance system\nscalability, agent collaboration, and adaptability. Our findings provide a\nroadmap for future research, supporting the creation of robust, efficient\nmulti-agent systems that advance both individual agent performance and\ncollective system resilience.",
      "tldr_zh": "这篇调查论文探讨了构建有效的大型语言模型 (LLM) 基础多智能体系统的关键技术，焦点包括 Architecture、Memory、Planning 和 Technologies/Frameworks 等领域，通过分析最近进展及其限制，如可扩展性、实时响应挑战和智能体协调约束。论文举例说明了 Mixture of Agents 架构和 ReAct 规划模型等创新，展示了在角色分配和决策方面的改进，并总结了系统优势和挑战。最终，它提供实用推荐和未来研究路线图，以提升多智能体系统的可扩展性、协作性和适应性。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.01963v1",
      "published_date": "2025-03-13 06:17:50 UTC",
      "updated_date": "2025-03-13 06:17:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:55:09.643889"
    },
    {
      "arxiv_id": "2503.10075v1",
      "title": "Parallelizing Multi-objective A* Search",
      "title_zh": "多目标 A* 搜索的并行化",
      "authors": [
        "Saman Ahmadi",
        "Nathan R. Sturtevant",
        "Andrea Raith",
        "Daniel Harabor",
        "Mahdi Jalili"
      ],
      "abstract": "The Multi-objective Shortest Path (MOSP) problem is a classic network\noptimization problem that aims to find all Pareto-optimal paths between two\npoints in a graph with multiple edge costs. Recent studies on multi-objective\nsearch with A* (MOA*) have demonstrated superior performance in solving\ndifficult MOSP instances. This paper presents a novel search framework that\nallows efficient parallelization of MOA* with different objective orders. The\nframework incorporates a unique upper bounding strategy that helps the search\nreduce the problem's dimensionality to one in certain cases. Experimental\nresults demonstrate that the proposed framework can enhance the performance of\nrecent A*-based solutions, with the speed-up proportional to the problem\ndimension.",
      "tldr_zh": "这篇论文针对Multi-objective Shortest Path (MOSP)问题，提出了一种新型搜索框架，用于高效并行化Multi-objective A* (MOA*)算法，支持不同的目标顺序。该框架引入了独特的upper bounding策略，能够在某些情况下将问题维度减少到一维，从而优化搜索过程。实验结果表明，该框架显著提升了现有A*-based解决方案的性能，加速效果与问题维度成正比。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "8 page, 2 tables, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.10075v1",
      "published_date": "2025-03-13 05:43:49 UTC",
      "updated_date": "2025-03-13 05:43:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:55:21.177926"
    },
    {
      "arxiv_id": "2503.10071v1",
      "title": "Advanced Tool Learning and Selection System (ATLASS): A Closed-Loop Framework Using LLM",
      "title_zh": "翻译失败",
      "authors": [
        "Mohd Ariful Haque",
        "Justin Williams",
        "Sunzida Siddique",
        "Md. Hujaifa Islam",
        "Hasmot Ali",
        "Kishor Datta Gupta",
        "Roy George"
      ],
      "abstract": "The combination of LLM agents with external tools enables models to solve\ncomplex tasks beyond their knowledge base. Human-designed tools are inflexible\nand restricted to solutions within the scope of pre-existing tools created by\nexperts. To address this problem, we propose ATLASS, an advanced tool learning\nand selection system designed as a closed-loop framework. It enables the LLM to\nsolve problems by dynamically generating external tools on demand. In this\nframework, agents play a crucial role in orchestrating tool selection,\nexecution, and refinement, ensuring adaptive problem-solving capabilities. The\noperation of ATLASS follows three phases: The first phase, Understanding Tool\nRequirements, involves the Agents determining whether tools are required and\nspecifying their functionality; the second phase, Tool Retrieval/Generation,\ninvolves the Agents retrieving or generating tools based on their availability;\nand the third phase, Task Solving, involves combining all the component tools\nnecessary to complete the initial task. The Tool Dataset stores the generated\ntools, ensuring reusability and minimizing inference cost. Current LLM-based\ntool generation systems have difficulty creating complex tools that need APIs\nor external packages. In ATLASS, we solve the problem by automatically setting\nup the environment, fetching relevant API documentation online, and using a\nPython interpreter to create a reliable, versatile tool that works in a wider\nrange of situations. OpenAI GPT-4.0 is used as the LLM agent, and safety and\nethical concerns are handled through human feedback before executing generated\ncode. By addressing the limitations of predefined toolsets and enhancing\nadaptability, ATLASS serves as a real-world solution that empowers users with\ndynamically generated tools for complex problem-solving.",
      "tldr_zh": "该研究提出了一种先进的工具学习和选择系统（ATLASS），这是一个基于LLM的闭环框架，允许模型动态生成外部工具，以解决超出其知识库的复杂任务，从而克服人类设计的工具 inflexible 和 restricted 的局限性。ATLASS 通过三个阶段运作：首先，agents 评估工具需求并指定功能；其次，检索或生成工具，包括自动设置环境、获取 API 文档和使用 Python 解释器来创建可靠工具；最后，结合这些工具完成任务，并将生成的工具存储在 Tool Dataset 中以确保可重用。相比现有系统，ATLASS 通过 agents 的协调和人类反馈处理安全伦理问题，提升了问题解决的适应性和效率，为动态工具生成提供了实用的解决方案。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10071v1",
      "published_date": "2025-03-13 05:39:00 UTC",
      "updated_date": "2025-03-13 05:39:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:55:34.644254"
    },
    {
      "arxiv_id": "2503.10070v1",
      "title": "AhaRobot: A Low-Cost Open-Source Bimanual Mobile Manipulator for Embodied AI",
      "title_zh": "AhaRobot：一种低成本开源双臂移动机械臂，用于具身AI",
      "authors": [
        "Haiqin Cui",
        "Yifu Yuan",
        "Yan Zheng",
        "Jianye Hao"
      ],
      "abstract": "Navigation and manipulation in open-world environments remain unsolved\nchallenges in the Embodied AI. The high cost of commercial mobile manipulation\nrobots significantly limits research in real-world scenes. To address this\nissue, we propose AhaRobot, a low-cost and fully open-source dual-arm mobile\nmanipulation robot system with a hardware cost of only $1,000 (excluding\noptional computational resources), which is less than 1/15 of the cost of\npopular mobile robots. The AhaRobot system consists of three components: (1) a\nnovel low-cost hardware architecture primarily composed of off-the-shelf\ncomponents, (2) an optimized control solution to enhance operational precision\nintegrating dual-motor backlash control and static friction compensation, and\n(3) a simple remote teleoperation method RoboPilot. We use handles to control\nthe dual arms and pedals for whole-body movement. The teleoperation process is\nlow-burden and easy to operate, much like piloting. RoboPilot is designed for\nremote data collection in embodied scenarios. Experimental results demonstrate\nthat RoboPilot significantly enhances data collection efficiency in complex\nmanipulation tasks, achieving a 30% increase compared to methods using 3D mouse\nand leader-follower systems. It also excels at completing extremely\nlong-horizon tasks in one go. Furthermore, AhaRobot can be used to learn\nend-to-end policies and autonomously perform complex manipulation tasks, such\nas pen insertion and cleaning up the floor. We aim to build an affordable yet\npowerful platform to promote the development of embodied tasks on real devices,\nadvancing more robust and reliable embodied AI. All hardware and software\nsystems are available at https://aha-robot.github.io.",
      "tldr_zh": "该研究提出 AhaRobot，一种低成本（仅 1000 美元）且完全开源的双臂移动操作机器人系统，用于推动 Embodied AI 领域的研究。系统包括创新的硬件架构（基于现成组件）、优化的控制解决方案（整合双电机反冲控制和静态摩擦补偿以提升精度），以及简单的远程遥控方法 RoboPilot（使用手柄控制双臂和踏板控制整体运动）。实验结果显示，RoboPilot 比传统方法（如 3D 鼠标和领队-跟随系统）提高了 30% 的数据收集效率，并能一次性完成复杂长时任务，如笔插入和地板清洁。AhaRobot 旨在提供一个负担得起的平台，支持端到端策略学习和真实设备上的 Embodied AI 发展，所有资源可在 https://aha-robot.github.io 获取。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "The first two authors contributed equally. Website:\n  https://aha-robot.github.io",
      "pdf_url": "http://arxiv.org/pdf/2503.10070v1",
      "published_date": "2025-03-13 05:34:43 UTC",
      "updated_date": "2025-03-13 05:34:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:55:46.603016"
    },
    {
      "arxiv_id": "2503.10061v2",
      "title": "Compute Optimal Scaling of Skills: Knowledge vs Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Nicholas Roberts",
        "Niladri Chatterji",
        "Sharan Narang",
        "Mike Lewis",
        "Dieuwke Hupkes"
      ],
      "abstract": "Scaling laws are a critical component of the LLM development pipeline, most\nfamously as a way to forecast training decisions such as 'compute-optimally'\ntrading-off parameter count and dataset size, alongside a more recent growing\nlist of other crucial decisions. In this work, we ask whether compute-optimal\nscaling behaviour can be skill-dependent. In particular, we examine knowledge\nand reasoning-based skills such as knowledge-based QA and code generation, and\nwe answer this question in the affirmative: scaling laws are skill-dependent.\nNext, to understand whether skill-dependent scaling is an artefact of the\npretraining datamix, we conduct an extensive ablation of different datamixes\nand find that, also when correcting for datamix differences, knowledge and code\nexhibit fundamental differences in scaling behaviour. We conclude with an\nanalysis of how our findings relate to standard compute-optimal scaling using a\nvalidation set, and find that a misspecified validation set can impact\ncompute-optimal parameter count by nearly 50%, depending on its skill\ncomposition.",
      "tldr_zh": "这篇论文探讨了在大型语言模型(LLM)开发中，scaling laws 是否取决于技能类型，特别是知识和推理技能（如基于知识的QA和代码生成），并证实scaling laws 是技能相关的。研究者通过对不同数据混合进行广泛消融实验，发现即使修正数据差异，知识技能和代码生成在compute-optimal 缩放行为上存在根本区别。最终分析显示，验证集的技能组成可能导致compute-optimal 参数数量错误估计近50%，强调了验证集设计的重要性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10061v2",
      "published_date": "2025-03-13 05:21:22 UTC",
      "updated_date": "2025-03-14 01:39:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:55:57.044316"
    },
    {
      "arxiv_id": "2503.10058v1",
      "title": "Deep Learning Approaches for Anti-Money Laundering on Mobile Transactions: Review, Framework, and Directions",
      "title_zh": "针对移动交易的反洗钱深度学习方法：综述、框架和方向",
      "authors": [
        "Jiani Fan",
        "Lwin Khin Shar",
        "Ruichen Zhang",
        "Ziyao Liu",
        "Wenzhuo Yang",
        "Dusit Niyato",
        "Bomin Mao",
        "Kwok-Yan Lam"
      ],
      "abstract": "Money laundering is a financial crime that obscures the origin of illicit\nfunds, necessitating the development and enforcement of anti-money laundering\n(AML) policies by governments and organizations. The proliferation of mobile\npayment platforms and smart IoT devices has significantly complicated AML\ninvestigations. As payment networks become more interconnected, there is an\nincreasing need for efficient real-time detection to process large volumes of\ntransaction data on heterogeneous payment systems by different operators such\nas digital currencies, cryptocurrencies and account-based payments. Most of\nthese mobile payment networks are supported by connected devices, many of which\nare considered loT devices in the FinTech space that constantly generate data.\nFurthermore, the growing complexity and unpredictability of transaction\npatterns across these networks contribute to a higher incidence of false\npositives. While machine learning solutions have the potential to enhance\ndetection efficiency, their application in AML faces unique challenges, such as\naddressing privacy concerns tied to sensitive financial data and managing the\nreal-world constraint of limited data availability due to data regulations.\nExisting surveys in the AML literature broadly review machine learning\napproaches for money laundering detection, but they often lack an in-depth\nexploration of advanced deep learning techniques - an emerging field with\nsignificant potential. To address this gap, this paper conducts a comprehensive\nreview of deep learning solutions and the challenges associated with their use\nin AML. Additionally, we propose a novel framework that applies the\nleast-privilege principle by integrating machine learning techniques, codifying\nAML red flags, and employing account profiling to provide context for\npredictions and enable effective fraud detection under limited data\navailability....",
      "tldr_zh": "该论文审查了深度学习技术在反洗钱 (AML) 领域的应用，针对移动交易的复杂性，如互联支付网络和 IoT 设备带来的数据挑战，包括隐私问题和虚假警报。作者强调现有机器学习方法的局限性，并进行全面分析，填补了深度学习在 AML 方面的研究空白。论文提出一个新框架，结合最小权限原则、机器学习算法、AML 红旗编码和账户分析，以在数据有限的情况下提升实时欺诈检测效率，并为未来研究方向提供指导。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10058v1",
      "published_date": "2025-03-13 05:19:44 UTC",
      "updated_date": "2025-03-13 05:19:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:56:08.571038"
    },
    {
      "arxiv_id": "2503.10052v1",
      "title": "DTA: Dual Temporal-channel-wise Attention for Spiking Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Minje Kim",
        "Minjun Kim",
        "Xu Yang"
      ],
      "abstract": "Spiking Neural Networks (SNNs) present a more energy-efficient alternative to\nArtificial Neural Networks (ANNs) by harnessing spatio-temporal dynamics and\nevent-driven spikes. Effective utilization of temporal information is crucial\nfor SNNs, leading to the exploration of attention mechanisms to enhance this\ncapability. Conventional attention operations either apply identical operation\nor employ non-identical operations across target dimensions. We identify that\nthese approaches provide distinct perspectives on temporal information. To\nleverage the strengths of both operations, we propose a novel Dual\nTemporal-channel-wise Attention (DTA) mechanism that integrates both\nidentical/non-identical attention strategies. To the best of our knowledge,\nthis is the first attempt to concentrate on both the correlation and dependency\nof temporal-channel using both identical and non-identical attention\noperations. Experimental results demonstrate that the DTA mechanism achieves\nstate-of-the-art performance on both static datasets (CIFAR10, CIFAR100,\nImageNet-1k) and dynamic dataset (CIFAR10-DVS), elevating spike representation\nand capturing complex temporal-channel relationship. We open-source our code:\nhttps://github.com/MnJnKIM/DTA-SNN.",
      "tldr_zh": "Spiking Neural Networks (SNNs) 作为比 Artificial Neural Networks (ANNs) 更节能的替代方案，通过利用时空动态和事件驱动的尖峰来处理信息，但需要有效捕捉时间信息，因此本文提出了一种新型的 Dual Temporal-channel-wise Attention (DTA) 机制。DTA 机制首次整合了相同的和不同的注意力操作，专注于时间-通道的相关性和依赖性，以提升尖峰表示并捕捉复杂关系。实验结果显示，该机制在静态数据集（如 CIFAR10、CIFAR100 和 ImageNet-1k）以及动态数据集（CIFAR10-DVS）上实现了最先进性能，准确率和效率均有显著提升，并开源了代码以供进一步研究。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by IEEE/CVF Winter Conference on Applications of Computer\n  Vision (WACV) 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.10052v1",
      "published_date": "2025-03-13 05:09:48 UTC",
      "updated_date": "2025-03-13 05:09:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:56:22.805956"
    },
    {
      "arxiv_id": "2503.10040v1",
      "title": "Rapid analysis of point-contact Andreev reflection spectra via machine learning with adaptive data augmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Dongik Lee",
        "Valentin Stanev",
        "Xiaohang Zhang",
        "Mijeong Kang",
        "Ichiro Takeuchi",
        "Seunghun Lee"
      ],
      "abstract": "Delineating the superconducting order parameters is a pivotal task in\ninvestigating superconductivity for probing pairing mechanisms, as well as\ntheir symmetry and topology. Point-contact Andreev reflection (PCAR)\nmeasurement is a simple yet powerful tool for identifying the order parameters.\nThe PCAR spectra exhibit significant variations depending on the type of the\norder parameter in a superconductor, including its magnitude\n($\\mathit{\\Delta}$), as well as temperature, interfacial quality, Fermi\nvelocity mismatch, and other factors. The information on the order parameter\ncan be obtained by finding the combination of these parameters, generating a\ntheoretical spectrum that fits a measured experimental spectrum. However, due\nto the complexity of the spectra and the high dimensionality of parameters,\nextracting the fitting parameters is often time-consuming and labor-intensive.\nIn this study, we employ a convolutional neural network (CNN) algorithm to\ncreate models for rapid and automated analysis of PCAR spectra of various\nsuperconductors with different pairing symmetries (conventional $s$-wave,\nchiral $p_x+ip_y$-wave, and $d_{x^2-y^2}$-wave). The training datasets are\ngenerated based on the Blonder-Tinkham-Klapwijk (BTK) theory and further\nmodified and augmented by selectively incorporating noise and peaks according\nto the bias voltages. This approach not only replicates the experimental\nspectra but also brings the model's attention to important features within the\nspectra. The optimized models provide fitting parameters for experimentally\nmeasured spectra in less than 100 ms per spectrum. Our approaches and findings\npave the way for rapid and automated spectral analysis which will help\naccelerate research on superconductors with complex order parameters.",
      "tldr_zh": "本研究针对点接触Andreev反射（PCAR）谱的分析问题，提出了一种基于机器学习的方法，以加速提取超导体的秩序参数（如$\\mathit{\\Delta}$及其对称性，包括$s$-wave、$p_x+ip_y$-wave和$d_{x^2-y^2}$-wave）。他们使用卷积神经网络（CNN）算法，并通过自适应数据增强（如基于Blonder-Tinkham-Klapwijk (BTK)理论生成数据集，并添加噪声和峰值）来模拟实验谱，从而提升模型对关键特征的识别。结果显示，该方法能在不到100 ms内为每个谱提供精确拟合参数，大大减少了手动分析的劳动强度。总体上，此方法为复杂秩序参数超导体的快速自动化研究铺平了道路。",
      "categories": [
        "cond-mat.supr-con",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cond-mat.supr-con",
      "comment": "18 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.10040v1",
      "published_date": "2025-03-13 04:45:38 UTC",
      "updated_date": "2025-03-13 04:45:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:56:33.991010"
    },
    {
      "arxiv_id": "2503.10009v1",
      "title": "OR-LLM-Agent: Automating Modeling and Solving of Operations Research Optimization Problem with Reasoning Large Language Model",
      "title_zh": "OR-LLM-Agent：利用推理大",
      "authors": [
        "Bowen Zhang",
        "Pengcheng Luo"
      ],
      "abstract": "Operations Research (OR) has been widely applied in various fields such as\nresource allocation, production planning, and supply chain management. However,\naddressing real-world OR problems requires OR experts to perform mathematical\nmodeling and programmers to develop solution algorithms. This traditional\nmethod, heavily reliant on experts, is costly and has long development cycles,\nseverely limiting the widespread adoption of OR techniques. Few have considered\nusing Artificial Intelligence (AI) to replace professionals to achieve fully\nautomated solutions for OR problems. We propose OR-LLM-Agent, the first AI\nagent that enables end-to-end automation for solving real-world OR problems.\nOR-LLM-Agent leverages the Chain-of-Thought (CoT) reasoning capabilities of\nLarge Language Models (LLMs) to translate natural language problem descriptions\ninto formal mathematical models and automatically generate Gurobi solver code.\nIn OR-LLM-Agent, OR-CodeAgent is designed to automate code execution and repair\nwithin a sandbox environment, facilitating the derivation of the final\nsolution. Due to the lack of dedicated benchmark datasets for evaluating the\nautomated solving of OR problems, we construct a benchmark dataset comprising\n83 real-world OR problems described in natural language. We conduct comparative\nexperiments with state-of-the-art (SOTA) reasoning LLMs, including GPT-o3-mini,\nDeepSeek-R1, and Gemini 2.0 Flash Thinking. The OR-LLM-Agent achieved the\nhighest pass rate of 100% and the highest solution accuracy of 85%,\ndemonstrating the feasibility of automated OR problem-solving. Data and code\nhave been publicly available at https://github.com/bwz96sco/or_llm_agent.",
      "tldr_zh": "这篇论文针对运筹学 (Operations Research, OR) 问题的建模和求解自动化，提出了 OR-LLM-Agent，这是一个端到端的 AI 代理，利用 Large Language Models (LLMs) 的 Chain-of-Thought (CoT) 推理能力，将自然语言问题描述转化为正式数学模型并自动生成 Gurobi 求解器代码。OR-LLM-Agent 还包括 OR-CodeAgent 模块，用于在沙箱环境中处理代码执行和修复，从而实现高效的自动化过程。论文构建了一个包含 83 个真实世界 OR 问题的基准数据集，并通过实验比较了多种 SOTA 模型，如 GPT-4o-mini 和 Gemini 2.0 Flash Thinking，结果显示 OR-LLM-Agent 达到了 100% 的通过率和 85% 的解决方案准确率，证明了 AI 在 OR 问题自动求解中的可行性。数据和代码已在 GitHub 上开源。",
      "categories": [
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.AI",
      "comment": "11 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.10009v1",
      "published_date": "2025-03-13 03:40:50 UTC",
      "updated_date": "2025-03-13 03:40:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:56:51.157051"
    },
    {
      "arxiv_id": "2503.10714v2",
      "title": "ZSMerge: Zero-Shot KV Cache Compression for Memory-Efficient Long-Context LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Xin Liu",
        "Pei Liu",
        "Guoming Tang"
      ],
      "abstract": "The linear growth of key-value (KV) cache memory and quadratic computational\nin attention mechanisms complexity pose significant bottlenecks for large\nlanguage models (LLMs) in long-context processing. While existing KV cache\noptimization methods address these challenges through token pruning or feature\nmerging, they often incur irreversible information loss or require costly\nparameter retraining. To this end, we propose ZSMerge, a dynamic KV cache\ncompression framework designed for efficient cache management, featuring three\nkey operations: (1) fine-grained memory allocation guided by multi-dimensional\ntoken importance metrics at head-level granularity, (2) a residual merging\nmechanism that preserves critical context through compensated attention\nscoring, and (3) a zero-shot adaptation mechanism compatible with diverse LLM\narchitectures without requiring retraining. ZSMerge significantly enhances\nmemory efficiency and inference speed with negligible performance degradation\nacross LLMs. When applied to LLaMA2-7B, it demonstrates a 20:1 compression\nratio for key-value cache retention (reducing memory footprint to 5\\% of\nbaseline) while sustaining comparable generation quality, coupled with triple\nthroughput gains at extreme 54k-token contexts that eliminate out-of-memory\nfailures. The code is available at https://github.com/SusCom-Lab/ZSMerge.",
      "tldr_zh": "这篇论文提出了 ZSMerge，一种零样本 (Zero-Shot) KV cache 压缩框架，旨在解决大型语言模型 (LLMs) 在处理长上下文时因 KV cache 内存线性增长和注意力机制二次方复杂度带来的瓶颈问题。该框架通过细粒度内存分配（基于多维 token 重要性指标）、残差合并机制（通过补偿注意力评分保留关键上下文）和零样本适应机制（兼容多种 LLM 架构无需重新训练）来实现高效缓存管理。在 LLaMA2-7B 模型上，ZSMerge 实现了 20:1 的压缩比，将内存占用减少到基线的 5%，并在 54k-token 上下文中提升三倍吞吐量，同时几乎不影响生成质量。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10714v2",
      "published_date": "2025-03-13 03:36:03 UTC",
      "updated_date": "2025-04-06 12:20:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:57:00.209121"
    },
    {
      "arxiv_id": "2503.10003v1",
      "title": "A New Benchmark for Few-Shot Class-Incremental Learning: Redefining the Upper Bound",
      "title_zh": "一个新的少样本类增量学习基准：重新定义上界",
      "authors": [
        "Shiwon Kim",
        "Dongjun Hwang",
        "Sungwon Woo",
        "Rita Singh"
      ],
      "abstract": "Class-incremental learning (CIL) aims to continuously adapt to emerging\nclasses while retaining knowledge of previously learned ones. Few-shot\nclass-incremental learning (FSCIL) presents an even greater challenge which\nrequires the model to learn incremental classes with only a limited number of\nsamples. In conventional CIL, joint training is widely considered the upper\nbound, serving as both a benchmark and a methodological guide. However, we find\nthat joint training fails to be a meaningful upper bound in FSCIL due to the\ninherent difficulty of inter-task class separation (ICS) caused by severe class\nimbalance. In this work, we introduce a new joint training benchmark tailored\nfor FSCIL by integrating imbalance-aware techniques, effectively bridging the\nperformance gap between base and incremental classes. Furthermore, we point out\ninconsistencies in the experimental setup and evaluation of existing FSCIL\nmethods. To ensure fair comparisons between different FSCIL approaches and\njoint training, we standardize training conditions and propose a unified\nevaluation protocol that simultaneously considers the validation set and\ncomputational complexity. By establishing a reliable upper bound and a\nstandardized evaluation framework for FSCIL, our work provides a clear\nbenchmark and a practical foundation for future research.",
      "tldr_zh": "这篇论文重新定义了Few-Shot Class-Incremental Learning (FSCIL)的基准，指出传统joint training无法作为有效上限，因为类不平衡导致inter-task class separation (ICS)困难。研究者引入了一种新的joint training基准，整合imbalance-aware techniques来桥接基础类和增量类之间的性能差距。论文还标准化了实验设置和评估协议，包括统一训练条件、考虑validation set和计算复杂度，以确保FSCIL方法间的公平比较，并为未来研究提供可靠的基础。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10003v1",
      "published_date": "2025-03-13 03:25:29 UTC",
      "updated_date": "2025-03-13 03:25:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:57:11.242969"
    },
    {
      "arxiv_id": "2503.10713v1",
      "title": "HiCMamba: Enhancing Hi-C Resolution and Identifying 3D Genome Structures with State Space Modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Minghao Yang",
        "Zhi-An Huang",
        "Zhihang Zheng",
        "Yuqiao Liu",
        "Shichen Zhang",
        "Pengfei Zhang",
        "Hui Xiong",
        "Shaojun Tang"
      ],
      "abstract": "Hi-C technology measures genome-wide interaction frequencies, providing a\npowerful tool for studying the 3D genomic structure within the nucleus.\nHowever, high sequencing costs and technical challenges often result in Hi-C\ndata with limited coverage, leading to imprecise estimates of chromatin\ninteraction frequencies. To address this issue, we present a novel deep\nlearning-based method HiCMamba to enhance the resolution of Hi-C contact maps\nusing a state space model. We adopt the UNet-based auto-encoder architecture to\nstack the proposed holistic scan block, enabling the perception of both global\nand local receptive fields at multiple scales. Experimental results demonstrate\nthat HiCMamba outperforms state-of-the-art methods while significantly reducing\ncomputational resources. Furthermore, the 3D genome structures, including\ntopologically associating domains (TADs) and loops, identified in the contact\nmaps recovered by HiCMamba are validated through associated epigenomic\nfeatures. Our work demonstrates the potential of a state space model as\nfoundational frameworks in the field of Hi-C resolution enhancement.",
      "tldr_zh": "本研究针对 Hi-C 技术在测量基因组互动频率时因高成本和技术挑战导致的数据覆盖有限问题，提出了一种新型深度学习方法 HiCMamba，利用状态空间模型提升 Hi-C 接触图的分辨率。HiCMamba 采用 UNet-based auto-encoder 架构并堆叠 holistic scan block，以实现多尺度全局和局部感受野的感知。实验结果显示，该方法优于现有先进技术，同时显著减少计算资源；在恢复的接触图中识别的 3D 基因组结构，如 TADs 和 loops，通过相关的表观遗传特征得到有效验证。该工作突显了状态空间模型在 Hi-C 分辨率提升领域的潜在基础作用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10713v1",
      "published_date": "2025-03-13 03:04:02 UTC",
      "updated_date": "2025-03-13 03:04:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:57:23.685374"
    },
    {
      "arxiv_id": "2503.09988v3",
      "title": "Label Unbalance in High-frequency Trading",
      "title_zh": "高频交易中的标签不平衡",
      "authors": [
        "Zijian Zhao",
        "Xuming Zhang",
        "Jiayu Wen",
        "Mingwen Liu",
        "Xiaoteng Ma"
      ],
      "abstract": "In financial trading, return prediction is one of the foundation for a\nsuccessful trading system. By the fast development of the deep learning in\nvarious areas such as graphical processing, natural language, it has also\ndemonstrate significant edge in handling with financial data. While the success\nof the deep learning relies on huge amount of labeled sample, labeling each\ntime/event as profitable or unprofitable, under the transaction cost,\nespecially in the high-frequency trading world, suffers from serious label\nimbalance issue.In this paper, we adopts rigurious end-to-end deep learning\nframework with comprehensive label imbalance adjustment methods and succeed in\npredicting in high-frequency return in the Chinese future market. The code for\nour method is publicly available at\nhttps://github.com/RS2002/Label-Unbalance-in-High-Frequency-Trading .",
      "tldr_zh": "该研究探讨了高频交易（high-frequency trading）中标签不平衡（label imbalance）问题，该问题导致深度学习模型在回报预测任务上训练困难，尤其是在考虑交易成本的情况下。论文提出了一种严格的端到端（end-to-end）深度学习框架，并结合全面的标签不平衡调整方法，成功应用于中国期货市场的回报预测。实验结果证明了该方法的有效性，并通过公开代码（https://github.com/RS2002/Label-Unbalance-in-High-Frequency-Trading）促进了进一步的研究和应用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-fin.CP"
      ],
      "primary_category": "cs.LG",
      "comment": "Technical Report",
      "pdf_url": "http://arxiv.org/pdf/2503.09988v3",
      "published_date": "2025-03-13 02:55:06 UTC",
      "updated_date": "2025-03-21 03:10:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:57:33.299072"
    },
    {
      "arxiv_id": "2503.09974v1",
      "title": "Uncertainty-aware Long-tailed Weights Model the Utility of Pseudo-labels for Semi-supervised Learning",
      "title_zh": "不确定性感知的长尾权重模型用于半监督学习中伪标签效用的建模",
      "authors": [
        "Jiaqi Wu",
        "Junbiao Pang",
        "Qingming Huang"
      ],
      "abstract": "Current Semi-supervised Learning (SSL) adopts the pseudo-labeling strategy\nand further filters pseudo-labels based on confidence thresholds. However, this\nmechanism has notable drawbacks: 1) setting the reasonable threshold is an open\nproblem which significantly influences the selection of the high-quality\npseudo-labels; and 2) deep models often exhibit the over-confidence phenomenon\nwhich makes the confidence value an unreliable indicator for assessing the\nquality of pseudo-labels due to the scarcity of labeled data. In this paper, we\npropose an Uncertainty-aware Ensemble Structure (UES) to assess the utility of\npseudo-labels for unlabeled samples. We further model the utility of\npseudo-labels as long-tailed weights to avoid the open problem of setting the\nthreshold. Concretely, the advantage of the long-tailed weights ensures that\neven unreliable pseudo-labels still contribute to enhancing the model's\nrobustness. Besides, UES is lightweight and architecture-agnostic, easily\nextending to various computer vision tasks, including classification and\nregression. Experimental results demonstrate that combining the proposed method\nwith DualPose leads to a 3.47% improvement in Percentage of Correct Keypoints\n(PCK) on the Sniffing dataset with 100 data points (30 labeled), a 7.29\\%\nimprovement in PCK on the FLIC dataset with 100 data points (50 labeled), and a\n3.91% improvement in PCK on the LSP dataset with 200 data points (100 labeled).\nFurthermore, when combined with FixMatch, the proposed method achieves a 0.2%\naccuracy improvement on the CIFAR-10 dataset with 40 labeled data points and a\n0.26% accuracy improvement on the CIFAR-100 dataset with 400 labeled data\npoints.",
      "tldr_zh": "该论文针对半监督学习(SSL)中伪标签策略的缺陷（如阈值设置难题和模型过度自信），提出Uncertainty-aware Ensemble Structure (UES)来评估伪标签的效用。作者将伪标签的效用建模为long-tailed weights，避免手动设置阈值，并确保即使不可靠的伪标签也能增强模型的鲁棒性；UES作为轻量级、架构无关的方法，可应用于分类和回归等计算机视觉任务。实验结果显示，该方法与DualPose结合在Sniffing、FLIC和LSP数据集上分别提高了PCK指标（最高7.29%），并与FixMatch结合在CIFAR-10和CIFAR-100数据集上提升了准确率（最高0.26%）。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "arXiv admin note: text overlap with arXiv:2408.04150",
      "pdf_url": "http://arxiv.org/pdf/2503.09974v1",
      "published_date": "2025-03-13 02:21:04 UTC",
      "updated_date": "2025-03-13 02:21:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:57:49.060870"
    },
    {
      "arxiv_id": "2503.09969v1",
      "title": "Detecting Dataset Bias in Medical AI: A Generalized and Modality-Agnostic Auditing Framework",
      "title_zh": "检测医疗 AI 中的数据集偏差：一个通用且模态无关的审计框架",
      "authors": [
        "Nathan Drenkow",
        "Mitchell Pavlak",
        "Keith Harrigian",
        "Ayah Zirikly",
        "Adarsh Subbaswamy",
        "Mathias Unberath"
      ],
      "abstract": "Data-driven AI is establishing itself at the center of evidence-based\nmedicine. However, reports of shortcomings and unexpected behavior are growing\ndue to AI's reliance on association-based learning. A major reason for this\nbehavior: latent bias in machine learning datasets can be amplified during\ntraining and/or hidden during testing. We present a data modality-agnostic\nauditing framework for generating targeted hypotheses about sources of bias\nwhich we refer to as Generalized Attribute Utility and Detectability-Induced\nbias Testing (G-AUDIT) for datasets. Our method examines the relationship\nbetween task-level annotations and data properties including protected\nattributes (e.g., race, age, sex) and environment and acquisition\ncharacteristics (e.g., clinical site, imaging protocols). G-AUDIT automatically\nquantifies the extent to which the observed data attributes may enable shortcut\nlearning, or in the case of testing data, hide predictions made based on\nspurious associations. We demonstrate the broad applicability and value of our\nmethod by analyzing large-scale medical datasets for three distinct modalities\nand learning tasks: skin lesion classification in images, stigmatizing language\nclassification in Electronic Health Records (EHR), and mortality prediction for\nICU tabular data. In each setting, G-AUDIT successfully identifies subtle\nbiases commonly overlooked by traditional qualitative methods that focus\nprimarily on social and ethical objectives, underscoring its practical value in\nexposing dataset-level risks and supporting the downstream development of\nreliable AI systems. Our method paves the way for achieving deeper\nunderstanding of machine learning datasets throughout the AI development\nlife-cycle from initial prototyping all the way to regulation, and creates\nopportunities to reduce model bias, enabling safer and more trustworthy AI\nsystems.",
      "tldr_zh": "这篇论文提出了一种通用的、模态无关的审计框架G-AUDIT，用于检测医疗AI数据集中的潜在偏置，帮助识别任务注解与数据属性（如种族、年龄、性别或临床站点）之间的虚假关联。框架通过量化属性对捷径学习的影响，自动评估偏置风险，并在皮肤病图像分类、EHR语言分类和ICU死亡率预测等三个不同模态数据集上进行了验证。实验结果显示，G-AUDIT成功发现了传统定性方法忽略的微妙偏置，从而支持AI开发生命周期中减少偏置风险，实现更安全和可信的AI系统。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.09969v1",
      "published_date": "2025-03-13 02:16:48 UTC",
      "updated_date": "2025-03-13 02:16:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:57:58.468501"
    },
    {
      "arxiv_id": "2503.09960v1",
      "title": "Optimizing Fire Safety: Reducing False Alarms Using Advanced Machine Learning Techniques",
      "title_zh": "优化消防安全：使用先进机器学习技术减少误报",
      "authors": [
        "Muhammad Hassan Jamal",
        "Abdulwahab Alazeb",
        "Shahid Allah Bakhsh",
        "Wadii Boulila",
        "Syed Aziz Shah",
        "Aizaz Ahmad Khattak",
        "Muhammad Shahbaz Khan"
      ],
      "abstract": "Fire safety practices are important to reduce the extent of destruction\ncaused by fire. While smoke alarms help save lives, firefighters struggle with\nthe increasing number of false alarms. This paper presents a precise and\nefficient Weighted ensemble model for decreasing false alarms. It estimates the\ndensity, computes weights according to the high and low-density regions,\nforwards the high region weights to KNN and low region weights to XGBoost and\ncombines the predictions. The proposed model is effective at reducing response\ntime, increasing fire safety, and minimizing the damage that fires cause. A\nspecifically designed dataset for smoke detection is utilized to test the\nproposed model. In addition, a variety of ML models, such as Logistic\nRegression (LR), Decision Tree (DT), Random Forest (RF), Nai:ve Bayes (NB),\nK-Nearest Neighbour (KNN), Support Vector Machine (SVM), Extreme Gradient\nBoosting (XGBoost), Adaptive Boosting (ADAB), have also been utilized. To\nmaximize the use of the smoke detection dataset, all the algorithms utilize the\nSMOTE re-sampling technique. After evaluating the assessment criteria, this\npaper presents a concise summary of the comprehensive findings obtained by\ncomparing the outcomes of all models.",
      "tldr_zh": "本研究针对消防安全中的假警报问题，提出了一种精确高效的Weighted ensemble model，以优化火灾响应。该模型通过估计数据密度、计算权重，并将高密度区域权重分配给KNN、低密度区域权重分配给XGBoost，然后结合预测结果，有效减少假警报并提高响应时间和整体火警安全。实验使用一个专门设计的烟雾检测数据集，并采用SMOTE re-sampling技术对多种机器学习模型（如Logistic Regression (LR)、Decision Tree (DT)、Random Forest (RF)等）进行比较。结果显示，该模型在减少假警报方面表现出色，为提升火警安全提供了实用解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.09960v1",
      "published_date": "2025-03-13 02:07:14 UTC",
      "updated_date": "2025-03-13 02:07:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:58:12.255545"
    },
    {
      "arxiv_id": "2503.09956v3",
      "title": "DeepSeek-Inspired Exploration of RL-based LLMs and Synergy with Wireless Networks: A Survey",
      "title_zh": "DeepSeek 启发的基于强化学习的LLM探索以及与无线网络的协同：一个综述",
      "authors": [
        "Yu Qiao",
        "Phuong-Nam Tran",
        "Ji Su Yoon",
        "Loc X. Nguyen",
        "Eui-Nam Huh",
        "Dusit Niyato",
        "Choong Seon Hong"
      ],
      "abstract": "Reinforcement learning (RL)-based large language models (LLMs), such as\nChatGPT, DeepSeek, and Grok-3, have gained significant attention for their\nexceptional capabilities in natural language processing and multimodal data\nunderstanding. Meanwhile, the rapid expansion of information services has\ndriven the growing need for intelligence, efficient, and adaptable wireless\nnetworks. Wireless networks require the empowerment of RL-based LLMs while\nthese models also benefit from wireless networks to broaden their application\nscenarios. Specifically, RL-based LLMs can enhance wireless communication\nsystems through intelligent resource allocation, adaptive network optimization,\nand real-time decision-making. Conversely, wireless networks provide a vital\ninfrastructure for the efficient training, deployment, and distributed\ninference of RL-based LLMs, especially in decentralized and edge computing\nenvironments. This mutual empowerment highlights the need for a deeper\nexploration of the interplay between these two domains. We first review recent\nadvancements in wireless communications, highlighting the associated challenges\nand potential solutions. We then discuss the progress of RL-based LLMs,\nfocusing on key technologies for LLM training, challenges, and potential\nsolutions. Subsequently, we explore the mutual empowerment between these two\nfields, highlighting key motivations, open challenges, and potential solutions.\nFinally, we provide insights into future directions, applications, and their\nsocietal impact to further explore this intersection, paving the way for\nnext-generation intelligent communication systems. Overall, this survey\nprovides a comprehensive overview of the relationship between RL-based LLMs and\nwireless networks, offering a vision where these domains empower each other to\ndrive innovations.",
      "tldr_zh": "这篇调查论文探讨了基于强化学习（RL-based LLMs）的大语言模型（如 DeepSeek 和 ChatGPT）与无线网络之间的协同关系，强调了它们如何相互赋能。论文首先回顾了无线通信的最新进展、面临的挑战（如资源分配和网络优化）以及潜在解决方案，然后分析了 RL-based LLMs 的关键技术、训练挑战和改进方法。随后，它详细阐述了双向互动：RL-based LLMs 通过智能决策提升无线网络效率，而无线网络则为 LLMs 的分布式训练和部署提供基础设施。总体上，该调查为未来智能通信系统的创新提供了全面视野，并指出了关键动机、开放挑战和潜在的社会影响。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.ET"
      ],
      "primary_category": "cs.LG",
      "comment": "45 pages, 12 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.09956v3",
      "published_date": "2025-03-13 01:59:11 UTC",
      "updated_date": "2025-04-17 01:30:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:58:22.508919"
    },
    {
      "arxiv_id": "2503.09950v1",
      "title": "MoFlow: One-Step Flow Matching for Human Trajectory Forecasting via Implicit Maximum Likelihood Estimation based Distillation",
      "title_zh": "翻译失败",
      "authors": [
        "Yuxiang Fu",
        "Qi Yan",
        "Lele Wang",
        "Ke Li",
        "Renjie Liao"
      ],
      "abstract": "In this paper, we address the problem of human trajectory forecasting, which\naims to predict the inherently multi-modal future movements of humans based on\ntheir past trajectories and other contextual cues. We propose a novel motion\nprediction conditional flow matching model, termed MoFlow, to predict K-shot\nfuture trajectories for all agents in a given scene. We design a novel flow\nmatching loss function that not only ensures at least one of the $K$ sets of\nfuture trajectories is accurate but also encourages all $K$ sets of future\ntrajectories to be diverse and plausible. Furthermore, by leveraging the\nimplicit maximum likelihood estimation (IMLE), we propose a novel distillation\nmethod for flow models that only requires samples from the teacher model.\nExtensive experiments on the real-world datasets, including SportVU NBA games,\nETH-UCY, and SDD, demonstrate that both our teacher flow model and the\nIMLE-distilled student model achieve state-of-the-art performance. These models\ncan generate diverse trajectories that are physically and socially plausible.\nMoreover, our one-step student model is $\\textbf{100}$ times faster than the\nteacher flow model during sampling. The code, model, and data are available at\nour project page: https://moflow-imle.github.io",
      "tldr_zh": "本研究针对人类轨迹预测问题，提出了一种新颖的条件流匹配模型MoFlow，用于基于过去轨迹和上下文线索预测多代理的K-shot未来轨迹。MoFlow设计了一个创新的流匹配损失函数，确保至少一组轨迹准确，同时促进所有K组轨迹的多样性和合理性；此外，通过Implicit Maximum Likelihood Estimation (IMLE)基于的蒸馏方法，仅需教师模型样本，即可训练高效的学生模型。在SportVU NBA games、ETH-UCY和SDD等真实数据集上实验表明，MoFlow及其蒸馏模型达到state-of-the-art性能，能生成物理和社会上合理的轨迹，且学生模型采样速度比教师模型快100倍。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to CVPR 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.09950v1",
      "published_date": "2025-03-13 01:53:05 UTC",
      "updated_date": "2025-03-13 01:53:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:58:36.538555"
    },
    {
      "arxiv_id": "2503.09947v1",
      "title": "Identifying Trustworthiness Challenges in Deep Learning Models for Continental-Scale Water Quality Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaobo Xia",
        "Xiaofeng Liu",
        "Jiale Liu",
        "Kuai Fang",
        "Lu Lu",
        "Samet Oymak",
        "William S. Currie",
        "Tongliang Liu"
      ],
      "abstract": "Water quality is foundational to environmental sustainability, ecosystem\nresilience, and public health. Deep learning models, particularly Long\nShort-Term Memory (LSTM) networks, offer transformative potential for\nlarge-scale water quality prediction and scientific insights generation.\nHowever, their widespread adoption in high-stakes decision-making, such as\npollution mitigation and equitable resource allocation, is prevented by\nunresolved trustworthiness challenges including fairness, uncertainty,\ninterpretability, robustness, generalizability, and reproducibility. In this\nwork, we present the first comprehensive evaluation of trustworthiness in a\ncontinental-scale multi-task LSTM model predicting 20 water quality variables\n(encompassing physical/chemical processes, geochemical weathering, and nutrient\ncycling) across 482 U.S. basins. Our investigation uncovers systematic patterns\nof model performance disparities linked to basin characteristics, the inherent\ncomplexity of biogeochemical processes, and variable predictability,\nemphasizing critical performance fairness concerns. We further propose\nmethodological frameworks for quantitatively evaluating critical aspects of\ntrustworthiness, including uncertainty, interpretability, and robustness,\nidentifying key limitations that could challenge reliable real-world\ndeployment. This work serves as a timely call to action for advancing\ntrustworthy data-driven methods for water resources management and provides a\npathway to offering critical insights for researchers, decision-makers, and\npractitioners seeking to leverage artificial intelligence (AI) responsibly in\nenvironmental management.",
      "tldr_zh": "这篇论文评估了深度学习模型（特别是 LSTM 网络）在大陆规模水质预测中的可信赖性挑战，包括公平性、不确定性、可解释性、鲁棒性、泛化性和可重复性。研究者首次对一个多任务 LSTM 模型进行了全面评估，该模型预测 20 个水质变量（涉及物理/化学过程、地球化学风化和营养循环）在 482 个美国流域的表现。结果揭示了模型性能差异的系统模式，与流域特征、生化过程复杂性和变量可预测性相关，突出了公平性问题。论文还提出了量化评估不确定性、可解释性和鲁棒性的方法框架，并呼吁行动以推进可信赖的 AI 在水资源管理中的应用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "33 pages, 9 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2503.09947v1",
      "published_date": "2025-03-13 01:50:50 UTC",
      "updated_date": "2025-03-13 01:50:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:58:49.674021"
    },
    {
      "arxiv_id": "2503.09941v1",
      "title": "TGP: Two-modal occupancy prediction with 3D Gaussian and sparse points for 3D Environment Awareness",
      "title_zh": "翻译失败",
      "authors": [
        "Mu Chen",
        "Wenyu Chen",
        "Mingchuan Yang",
        "Yuan Zhang",
        "Tao Han",
        "Xinchi Li",
        "Yunlong Li",
        "Huaici Zhao"
      ],
      "abstract": "3D semantic occupancy has rapidly become a research focus in the fields of\nrobotics and autonomous driving environment perception due to its ability to\nprovide more realistic geometric perception and its closer integration with\ndownstream tasks. By performing occupancy prediction of the 3D space in the\nenvironment, the ability and robustness of scene understanding can be\neffectively improved. However, existing occupancy prediction tasks are\nprimarily modeled using voxel or point cloud-based approaches: voxel-based\nnetwork structures often suffer from the loss of spatial information due to the\nvoxelization process, while point cloud-based methods, although better at\nretaining spatial location information, face limitations in representing\nvolumetric structural details. To address this issue, we propose a dual-modal\nprediction method based on 3D Gaussian sets and sparse points, which balances\nboth spatial location and volumetric structural information, achieving higher\naccuracy in semantic occupancy prediction. Specifically, our method adopts a\nTransformer-based architecture, taking 3D Gaussian sets, sparse points, and\nqueries as inputs. Through the multi-layer structure of the Transformer, the\nenhanced queries and 3D Gaussian sets jointly contribute to the semantic\noccupancy prediction, and an adaptive fusion mechanism integrates the semantic\noutputs of both modalities to generate the final prediction results.\nAdditionally, to further improve accuracy, we dynamically refine the point\ncloud at each layer, allowing for more precise location information during\noccupancy prediction. We conducted experiments on the Occ3DnuScenes dataset,\nand the experimental results demonstrate superior performance of the proposed\nmethod on IoU based metrics.",
      "tldr_zh": "这篇论文提出了TGP，一种双模态语义占用预测方法，结合3D Gaussian sets和sparse points，以平衡空间位置和体积结构信息，从而提升机器人和自动驾驶领域的3D环境感知能力。该方法采用基于Transformer的架构，输入包括3D Gaussian sets、sparse points和queries，通过多层Transformer处理增强查询信息，并使用自适应融合机制整合两种模态的语义输出，同时动态精炼点云以提高预测精度。在Occ3DnuScenes数据集上的实验结果显示，TGP在IoU指标上显著优于现有体素或点云基线方法，证明了其有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.09941v1",
      "published_date": "2025-03-13 01:35:04 UTC",
      "updated_date": "2025-03-13 01:35:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:59:02.114132"
    },
    {
      "arxiv_id": "2503.09927v1",
      "title": "Developing and Evaluating an AI-Assisted Prediction Model for Unplanned Intensive Care Admissions following Elective Neurosurgery using Natural Language Processing within an Electronic Healthcare Record System",
      "title_zh": "开发和评估一种AI",
      "authors": [
        "Julia Ive",
        "Olatomiwa Olukoya",
        "Jonathan P. Funnell",
        "James Booker",
        "Sze H M Lam",
        "Ugan Reddy",
        "Kawsar Noor",
        "Richard JB Dobson",
        "Astri M. V. Luoma",
        "Hani J Marcus"
      ],
      "abstract": "Introduction: Timely care in a specialised neuro-intensive therapy unit (ITU)\nreduces mortality and hospital stays, with planned admissions being safer than\nunplanned ones. However, post-operative care decisions remain subjective. This\nstudy used artificial intelligence (AI), specifically natural language\nprocessing (NLP) to analyse electronic health records (EHRs) and predict ITU\nadmissions for elective surgery patients. Methods: This study analysed the EHRs\nof elective neurosurgery patients from University College London Hospital\n(UCLH) using NLP. Patients were categorised into planned high dependency unit\n(HDU) or ITU admission; unplanned HDU or ITU admission; or ward / overnight\nrecovery (ONR). The Medical Concept Annotation Tool (MedCAT) was used to\nidentify SNOMED-CT concepts within the clinical notes. We then explored the\nutility of these identified concepts for a range of AI algorithms trained to\npredict ITU admission. Results: The CogStack-MedCAT NLP model, initially\ntrained on hospital-wide EHRs, underwent two refinements: first with data from\npatients with Normal Pressure Hydrocephalus (NPH) and then with data from\nVestibular Schwannoma (VS) patients, achieving a concept detection F1-score of\n0.93. This refined model was then used to extract concepts from EHR notes of\n2,268 eligible neurosurgical patients. We integrated the extracted concepts\ninto AI models, including a decision tree model and a neural time-series model.\nUsing the simpler decision tree model, we achieved a recall of 0.87 (CI 0.82 -\n0.91) for ITU admissions, reducing the proportion of unplanned ITU cases missed\nby human experts from 36% to 4%. Conclusion: The NLP model, refined for\naccuracy, has proven its efficiency in extracting relevant concepts, providing\na reliable basis for predictive AI models to use in clinically valid\napplications.",
      "tldr_zh": "这篇论文开发并评估了一个基于 AI 和 Natural Language Processing (NLP) 的预测模型，用于分析 Electronic Healthcare Record (EHR) 系统，预测择期神经外科手术后非计划性 Intensive Care Unit (ITU) 入院。研究方法包括使用 Medical Concept Annotation Tool (MedCAT) 提取临床笔记中的 SNOMED-CT 概念，并对 CogStack-MedCAT NLP 模型进行两次精炼，针对 Normal Pressure Hydrocephalus (NPH) 和 Vestibular Schwannoma (VS) 患者优化，达到 F1-score 0.93。结果显示，该模型集成决策树等 AI 算法后，对 ITU 入院的 recall 达 0.87，将人类专家漏诊非计划 ITU 病例的比例从 36% 降至 4%。总体而言，该研究证明了精炼 NLP 模型在提取相关概念方面的效率，为临床预测应用提供了可靠的 AI 基础。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.09927v1",
      "published_date": "2025-03-13 00:48:48 UTC",
      "updated_date": "2025-03-13 00:48:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:59:15.892449"
    },
    {
      "arxiv_id": "2503.09910v1",
      "title": "eXpLogic: Explaining Logic Types and Patterns in DiffLogic Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Stephen Wormald",
        "David Koblah",
        "Matheus Kunzler Maldaner",
        "Domenic Forte",
        "Damon L. Woodard"
      ],
      "abstract": "Constraining deep neural networks (DNNs) to learn individual logic types per\nnode, as performed using the DiffLogic network architecture, opens the door to\nmodel-specific explanation techniques that quell the complexity inherent to\nDNNs. Inspired by principles of circuit analysis from computer engineering,\nthis work presents an algorithm (eXpLogic) for producing saliency maps which\nexplain input patterns that activate certain functions. The eXpLogic\nexplanations: (1) show the exact set of inputs responsible for a decision,\nwhich helps interpret false negative and false positive predictions, (2)\nhighlight common input patterns that activate certain outputs, and (3) help\nreduce the network size to improve class-specific inference. To evaluate the\neXpLogic saliency map, we introduce a metric that quantifies how much an input\nchanges before switching a model's class prediction (the SwitchDist) and use\nthis metric to compare eXpLogic against the Vanilla Gradients (VG) and\nIntegrated Gradient (IG) methods. Generally, we show that eXpLogic saliency\nmaps are better at predicting which inputs will change the class score. These\nmaps help reduce the network size and inference times by 87\\% and 8\\%,\nrespectively, while having a limited impact (-3.8\\%) on class-specific\npredictions. The broader value of this work to machine learning is in\ndemonstrating how certain DNN architectures promote explainability, which is\nrelevant to healthcare, defense, and law.",
      "tldr_zh": "本研究提出 eXpLogic 算法，用于解释 DiffLogic 网络中每个节点的逻辑类型和模式，从而减少深度神经网络 (DNNs) 的复杂性。eXpLogic 通过受电路分析启发的技术生成 saliency maps，精确识别导致决策的输入集、突出激活特定输出的常见模式，并帮助缩小网络规模以提升类特定推理效率。在评估中，引入 SwitchDist 度量与 Vanilla Gradients (VG) 和 Integrated Gradients (IG) 比较，结果显示 eXpLogic 在预测输入对类分数的影响上更出色，能将网络大小和推理时间分别减少 87% 和 8%，同时仅对预测准确性造成有限影响 (-3.8%)。这项工作强调了特定 DNN 架构如何提升模型可解释性，在医疗、国防和法律等领域具有重要价值。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Conference submission, 6 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.09910v1",
      "published_date": "2025-03-13 00:01:36 UTC",
      "updated_date": "2025-03-13 00:01:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T01:59:25.755186"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 134,
  "processed_papers_count": 134,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-24T01:59:54.640081"
}