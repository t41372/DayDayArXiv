{
  "date": "2025-03-13",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-03-13 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 上的论文再次聚焦于大型语言模型（LLM）和视觉语言模型（VLM），探讨了效率提升（如 Mamba 模型量化、KV 缓存压缩、推断自适应）、安全性（越狱攻击与防御、幻觉缓解、偏见检测）、评估（新基准、人类研究、MCQ 陷阱）以及与多模态数据（时间序列、科学图表、3D 视觉、机器人交互）的融合。值得关注的是 Kaiming He 和 Yann LeCun 等人提出的无需归一化的 Transformer 架构，以及多篇关于模型可解释性、鲁棒性、联邦学习和特定领域应用（如医疗、机器人、金融、科学发现）的研究。\n\n**重点论文 & LLM/VLM 效率与优化**\n\n*   **OuroMamba: 视觉 Mamba 模型的数据无关量化框架 (OuroMamba: A Data-Free Quantization Framework for Vision Mamba Models)**\n    这篇论文提出了首个针对视觉 Mamba 模型 (VMMs) 的数据无关后训练量化 (DFQ) 方法 OuroMamba。它通过 OuroMamba-Gen 生成语义丰富的合成数据，并利用 OuroMamba-Quant 进行混合精度量化和动态异常值检测，解决了 VMM 状态转换带来的语义捕获和激活值动态变化挑战。实验表明，该方法超越了现有数据驱动 PTQ 技术，并在 GPU 上实现了高达 2.36 倍的延迟加速。\n\n*   **无需归一化的 Transformer (Transformers without Normalization)** (Kaiming He, Yann LeCun 等人)\n    这篇备受瞩目的论文挑战了归一化层在现代神经网络中不可或缺的传统观念。研究者提出了一种名为 Dynamic Tanh (DyT) 的简单元素级操作 `tanh(α*x)`，作为 Transformer 中归一化层的替代品。实验表明，使用 DyT 的无归一化 Transformer 在各种视觉和语言任务（包括识别、生成、监督和自监督学习）中，能够达到甚至超过其归一化对应物的性能，且通常无需调整超参数。\n\n*   **AdaLLaVA: 学习为多模态大语言模型进行自适应推理 (Learning to Inference Adaptively for Multimodal Large Language Models)**\n    针对 MLLM 计算成本高、难以适应运行时资源变化的问题，该研究提出 AdaLLaVA 框架。它能在推理时根据输入数据和延迟预算动态地重新配置 MLLM 中的操作，有效平衡准确性和延迟，并能与其他效率技术（如 token 选择）结合。\n\n*   **KV-Distill: 面向 LLM 的近乎无损的可学习上下文压缩 (KV-Distill: Nearly Lossless Learnable Context Compression for LLMs)**\n    为解决长上下文 LLM 中 KV 缓存占用大量内存的问题，该研究提出 KV-Distill 框架。它以与问题无关的方式将长上下文 KV 缓存蒸馏成显著缩短的表示，可作为预训练模型的参数高效适配器，在保持模型能力的同时压缩任意上下文片段，最高可减少 99% 的长度。\n\n*   **ZeroMerge: 用于内存高效长上下文 LLM 的无参数 KV 缓存压缩 (ZeroMerge: Parameter-Free KV Cache Compression for Memory-Efficient Long-Context LLMs)**\n    同样针对 KV 缓存问题，ZeroMerge 提出了一种动态零样本压缩框架。它通过细粒度内存分配、残差合并机制和无参数适应性，在不重新训练的情况下实现高效缓存管理。实验表明，在 5% 压缩率下能保持全缓存性能，并在 40K token 长度下将推理吞吐量提高一倍。\n\n*   **Gumiho: 利用混合架构优先处理推测解码中的早期 Token (Gumiho: A Hybrid Architecture to Prioritize Early Tokens in Speculative Decoding)**\n    针对推测解码（SPD）加速 LLM 生成的问题，该研究发现草稿序列中的初始 token 比后续 token 更重要。Gumiho 提出一种混合串行和并行头的架构：对早期 token 使用更复杂的串行 Transformer 头以提高准确性，对后期 token 使用轻量级并行 MLP 头以提高效率，从而提升整体性能。\n\n*   **G-Boost: 用通用 LLM 增强私有 SLM (G-Boost: Boosting Private SLMs with General LLMs)**\n    针对私有小型语言模型 (SLM) 性能有限的问题，提出 G-Boost 框架。该框架允许私有 SLM 在过程奖励的指导下，与通用 LLM（API 或可负担推理成本的大模型）进行自适应的协作推理，显著提升私有 SLM 的性能。\n\n*   **Samoyeds: 利用稀疏张量核和结构化稀疏性加速 MoE 模型 (Samoyeds: Accelerating MoE Models with Structured Sparsity Leveraging Sparse Tensor Cores)**\n    为解决 MoE 模型计算和内存挑战，提出 Samoyeds 加速系统。该系统首次同时对激活和模型参数应用结构化稀疏性，利用稀疏张量核 (SpTCs)，引入定制的稀疏数据格式和专门的稀疏-稀疏矩阵乘法核，显著提升了 MoE LLM 的性能和内存效率。\n\n**LLM/VLM 安全性、鲁棒性与幻觉**\n\n*   **M-Attack: 一个简单高效的攻击基准：对 GPT-4.5/4o/o1 等强黑盒模型超 90% 成功率 (A Frustratingly Simple Yet Highly Effective Attack Baseline: Over 90% Success Rate Against the Strong Black-box Models of GPT-4.5/4o/o1)**\n    该研究发现针对开源 LVLM 的对抗攻击在商业黑盒模型上效果不佳，原因是扰动缺乏语义细节。他们提出一种简单方法：在优化时随机裁剪并缩放对抗图像，使其与目标图像在嵌入空间对齐，将扰动集中在语义丰富区域。这种方法生成的对抗样本对 GPT-4.5/4o/o1 等模型实现了超过 90% 的攻击成功率。\n\n*   **TAIJI: 用于免疫 VLM 中越狱图像的文本锚定 (TAIJI: Textual Anchoring for Immunizing Jailbreak Images in Vision Language Models)**\n    针对 VLM 的越狱攻击，提出一种新的黑盒防御框架 TAIJI。它利用基于关键短语的文本锚定来增强模型评估和减轻视觉及文本提示中嵌入的有害内容的能力。TAIJI 只需单次查询即可生效，且不影响良性任务性能。\n\n*   **Siege: 使用树搜索对大型语言模型进行自主多轮越狱 (Siege: Autonomous Multi-Turn Jailbreaking of Large Language Models with Tree Search)**\n    提出 Siege，一个多轮对抗框架，将侵蚀 LLM 安全性的过程建模为树搜索。通过在每轮对话中扩展多个利用先前部分合规响应的对抗提示，揭示了微小让步如何累积成完全不允许的输出。在 JailbreakBench 数据集上取得了高成功率。\n\n*   **TruthPrInt: 通过潜在真实性引导的预干预缓解 LVLM 对象幻觉 (TruthPrInt: Mitigating LVLM Object Hallucination Via Latent Truthful-Guided Pre-Intervention)**\n    研究发现 LVLM 内部状态可作为对象幻觉 (OH) 的高特异性逐词指示器，且不同 LVLM 在共同的潜在子空间中编码通用的幻觉模式。提出 TruthPrInt 方法，在推理时学习并应用真实性引导的干预来缓解 OH，显著优于现有方法。\n\n*   **通过放大镜：用于无幻觉 VLM 解码的自适应感知放大 (Through the Magnifying Glass: Adaptive Perception Magnification for Hallucination-Free VLM Decoding)**\n    为解决 VLM 视觉幻觉问题，提出 Perception Magnifier (PM) 解码方法。它迭代地根据注意力隔离相关视觉 token 并放大相应区域，促使模型在解码时关注细粒度视觉细节，从而生成更准确、忠实的响应，同时保持推理能力。\n\n*   **DarkBench: 大型语言模型中暗模式的基准测试 (DarkBench: Benchmarking Dark Patterns in Large Language Models)**\n    引入 DarkBench，一个用于检测 LLM 交互中暗设计模式（操控用户行为的技术）的基准。包含 660 个提示，涵盖品牌偏见、用户留存、谄媚、拟人化、有害生成和偷偷摸摸六类。评估发现一些 LLM 存在偏袒开发者产品、不实沟通等操控行为。\n\n*   **MinorBench: 一个为儿童内容风险手工构建的基准 (MinorBench: A hand-built benchmark for content-based risks for children)**\n    针对当前 AI 安全研究忽视儿童特定内容风险的问题，提出新的风险分类法，并引入 MinorBench 基准，用于评估 LLM 拒绝儿童不安全或不当查询的能力。评估显示不同 LLM 在儿童安全合规性上存在显著差异。\n\n**LLM/VLM 评估与基准**\n\n*   **SciVerse: 揭示 LMM 在多模态科学问题上的知识理解和视觉推理能力 (SciVerse: Unveiling the Knowledge Comprehension and Visual Reasoning of LMMs on Multi-modal Scientific Problems)**\n    提出 SciVerse，一个包含 5735 个测试实例的多模态科学评估基准，旨在评估 LMM 的科学知识理解、多模态内容解释和思维链 (CoT) 推理能力。通过不同版本的测试（知识无关/少量/丰富，视觉丰富/仅视觉）系统地检验 LMM 的专业知识储备和视觉感知技能，并提出新的科学 CoT 评估策略。\n\n*   **选项太多：生成式 AI 和医学教育中多项选择题的陷阱 (It is Too Many Options: Pitfalls of Multiple-Choice Questions in Generative AI and Medical Education)**\n    研究质疑 LLM 在医学多选题 (MCQ) 基准上的表现可能具有欺骗性。创建了包含自由回答和配对 MCQ 的新基准 FreeMedQA。发现 LLM 在自由回答问题上的表现比 MCQ 平均下降 39.43%，远超人类的 22.29%。即使在问题干完全被遮蔽的情况下，LLM 在 MCQ 上的表现仍显著高于随机猜测，凸显了 MCQ 基准高估 LLM 医学能力的缺陷。\n\n*   **NeurIPS 2023 LLM 效率微调竞赛分析 (NeurIPS 2023 LLM Efficiency Fine-tuning Competition)**\n    分析显示，竞赛中表现优异的模型在基准数据集上表现出显著的过拟合，反映了流行排行榜上基准过拟合的普遍问题，并强调了数据管理对高性能 LLM 的重要性。竞赛结果揭示了当前基于基准的生成模型评估方案的局限性。\n\n*   **StepMathAgent: 通过错误树评估数学过程的分步代理 (StepMathAgent: A Step-Wise Agent for Evaluating Mathematical Processes through Tree-of-Error)**\n    为解决现有 LLM 数学能力评估方法仅关注最终答案、不准确且不可解释的问题，提出 StepMathAgent。该代理基于错误树，包含逻辑步骤分割、步骤评分、分数聚合和错误树生成等核心操作，以及难度校准等扩展模块。同时发布 StepMathBench 基准。\n\n*   **DynaCode: 用于评估代码生成中大型语言模型的动态复杂度感知代码基准 (DynaCode: A Dynamic Complexity-Aware Code Benchmark for Evaluating Large Language Models in Code Generation)**\n    针对现有静态代码基准易被记忆和污染的问题，提出 DynaCode。这是一个动态、复杂度感知的基准，能生成大量独特的嵌套代码问题，并结合代码复杂度和调用图结构来系统评估 LLM。\n\n*   **OSMa-Bench: 评估不同光照条件下的开放语义建图 (OSMa-Bench: Evaluating Open Semantic Mapping Under Varying Lighting Conditions)**\n    提出 OSMa-Bench，一个由 LLM/LVLM 驱动的自动化流水线，用于评估开放语义建图 (OSM) 方案。研究重点是在不同室内光照条件下评估 SOTA 语义建图算法，并引入了新的数据集和场景图评估方法。\n\n*   **不到 1% 的可解释 AI 论文用人类验证可解释性 (Fewer Than 1% of Explainable AI Papers Validate Explainability with Humans)**\n    一项大规模文献分析发现，在 18254 篇与可解释性相关的论文中，只有 128 篇（约 0.7%）进行了某种形式的人类研究来验证其 XAI 技术的可解释性。这揭示了 XAI 研究中人类可解释性主张与实证验证之间的巨大鸿沟。\n\n**LLM/VLM 应用与融合**\n\n*   **图接地 LLM：利用图形函数调用最小化 LLM 幻觉 (Graph-Grounded LLMs: Leveraging Graphical Function Calling to Minimize LLM Hallucinations)**\n    为解决 LLM 在处理图形相关任务（如路径规划、知识图谱）时出现的幻觉和数学不准确问题，提出 Graph-Grounded LLMs。该系统通过函数调用将 LLM 与图库集成，显著减少了幻觉并提高了图问题的数学准确性。\n\n*   **Chat-TS: 增强跨时间序列和自然语言数据的多模态推理 (Chat-TS: Enhancing Multi-Modal Reasoning Over Time-Series and Natural Language Data)**\n    提出 Chat-TS 框架，一个基于 LLM 的系统，旨在支持对时间序列和文本数据的联合推理。通过将时间序列 token 集成到 LLM 词汇表中，增强了模型跨模态的分析和推理能力，并贡献了新的训练和评估数据集。\n\n*   **UniVLG: 统一 2D 和 3D 视觉语言理解 (Unifying 2D and 3D Vision-Language Understanding)**\n    提出 UniVLG 统一架构，用于 2D 和 3D 视觉语言理解，旨在弥合现有 2D 中心模型与 3D 感知数据之间的差距。通过共享的语言条件掩码解码器和 2D 到 3D 提升策略，在多个 3D 视觉语言基础任务上实现 SOTA 性能。\n\n*   **PiSA: 用于大型模型 3D 理解的自增强数据引擎和训练策略 (PiSA: A Self-Augmented Data Engine and Training Strategy for 3D Understanding with Large Models)**\n    为解决 3D MLLM 数据量有限和质量欠佳的问题，提出 PiSA-Engine 框架，用于生成富含 3D 空间语义的指令点云-语言数据集。通过整合现有 2D 和 3D MLLM 的见解实现高质量数据生成的持续循环，并提出新基准 PiSA-Bench。\n\n*   **LHM: 秒级单图像大型可动人体重建模型 (LHM: Large Animatable Human Reconstruction Model from a Single Image in Seconds)**\n    提出 LHM（大型可动人体重建模型），利用多模态 Transformer 架构，从单张图像前向推理生成高保真、可动画的 3D 高斯溅射人体模型，有效保留服装几何和纹理细节，并在人脸身份保持和细节恢复方面表现优异。\n\n*   **RealGeneral: 通过视频模型的时序上下文学习统一视觉生成 (RealGeneral: Unifying Visual Generation via Temporal In-Context Learning with Video Models)**\n    探索使用视频模型作为统一图像生成的基础。提出 RealGeneral 框架，将图像生成重新表述为条件帧预测任务（类似 LLM 的上下文学习），通过统一条件嵌入和统一流 DiT 块实现多模态对齐和减轻干扰，在定制生成、Canny 到图像等任务中表现出色。\n\n*   **CINEMA: 通过基于 MLLM 的指导生成连贯的多主体视频 (CINEMA: Coherent Multi-Subject Video Generation via MLLM-Based Guidance)**\n    提出 CINEMA 框架，利用 MLLM 生成包含多个独立参考图像定义的独特主体的视频。通过 MLLM 解释主体关系，避免了主体图像与文本实体显式对应的模糊性，提高了主体一致性和视频连贯性。\n\n*   **KUDA: 关键点统一动力学学习和视觉提示用于开放词汇机器人操作 (KUDA: Keypoints to Unify Dynamics Learning and Visual Prompting for Open-Vocabulary Robotic Manipulation)**\n    提出 KUDA 开放词汇操作系​​统，通过关键点整合动力学学习和视觉提示。利用 VLM 分配关键点并生成目标规范，然后将基于关键点的表示转换为成本函数，使用学习的动力学模型进行优化以生成机器人轨迹，适用于涉及不同对象类别、多对象交互以及可变形/颗粒对象的任务。\n\n*   **IMPACT: 通过视觉语言模型实现可接受接触轨迹的智能运动规划 (IMPACT: Intelligent Motion Planning with Acceptable Contact Trajectories via Vision-Language Models)**\n    提出 IMPACT 运动规划框架，利用 VLM 推断环境语义，识别哪些物体更能容忍接触。VLM 输出用于生成编码接触容忍度的 3D \"成本图\"，并与标准运动规划器集成，以在杂乱环境中实现高效的富接触运动规划。\n\n*   **SurgRAW: 用于手术智能的具有思维链推理的多智能体工作流 (SurgRAW: Multi-Agent Workflow with Chain-of-Thought Reasoning for Surgical Intelligence)**\n    提出 SurgRAW，一个 CoT 驱动的多智能体框架，用于机器人辅助手术场景理解。通过在多个任务中使用专门的 CoT 提示，结合 RAG 和分层智能体系统，减轻幻觉，弥合领域差距，并确保逻辑一致性。引入 SurgCoTBench 数据集进行评估。\n\n*   **OR-LLM-Agent: 使用推理大型语言模型自动化运筹学优化问题的建模与求解 (OR-LLM-Agent: Automating Modeling and Solving of Operations Research Optimization Problem with Reasoning Large Language Model)**\n    提出首个用于端到端自动化解决现实世界运筹学 (OR) 问题的 AI 代理 OR-LLM-Agent。利用 LLM 的 CoT 推理能力将自然语言问题描述转化为数学模型，并自动生成 Gurobi 求解器代码，通过 OR-CodeAgent 实现代码执行和修复。\n\n*   **TacticExpert: 用于篮球战术的时空图语言模型 (TacticExpert: Spatial-Temporal Graph Language Model for Basketball Tactics)**\n    提出 TacticExpert，一种用于篮球比赛精细建模的时空传播对称感知图 Transformer。该模型能捕捉长距离、细粒度的球员交互，并通过对比学习训练战术专家混合模块，结合图基础的大型语言模型实现开放式下游任务和零样本场景的鲁棒性能。\n\n**机器学习理论与方法**\n\n*   **经验计算 (Empirical Computation)**\n    这篇愿景论文探讨了一种新的计算形式——经验计算，其解决方案是经验上最可能的而非必然正确的（例如直接问 LLM）。文章认为这种计算的能力和限制无法在经典计算框架内理解，并呼吁将其建立为一个新的研究领域。\n\n*   **高斯差分隐私 (GDP) 作为报告 DP 保证的最佳实践 ($(ε, δ)$ Considered Harmful: Best Practices for Reporting Differential Privacy Guarantees)**\n    文章主张使用高斯差分隐私 (GDP) 作为机器学习中传达 DP 保证的主要方式，因为它只有一个参数，易于比较，并且能准确捕捉许多重要应用的隐私概况。研究表明 GDP 能很好地拟合大规模图像分类和美国人口普查算法的隐私概况。\n\n*   **从分类器中心视角研究分类器（无关）引导 (Studying Classifier(-Free) Guidance From a Classifier-Centric Perspective)**\n    该研究从分类器引导的根源出发，系统地研究了分类器在扩散模型条件生成中的作用。发现分类器（无关）引导通过将去噪轨迹推离决策边界来实现条件生成，并基于此提出了一种通用的后处理步骤。\n\n*   **组合子空间表示微调用于自适应大型语言模型 (Compositional Subspace Representation Fine-tuning for Adaptive Large Language Models)**\n    为解决 LLM 适应多任务时的技能间干扰问题，提出 CS-ReFT。该方法学习多个正交子空间变换，每个变换专门针对一个技能，并通过轻量级路由器组合它们。通过在隐藏状态而非权重矩阵中隔离这些子空间编辑，更有效地防止跨任务冲突。\n\n*   **HyperDAS: 利用超网络自动化机制可解释性 (HyperDAS: Towards Automating Mechanistic Interpretability with Hypernetworks)**\n    为解决分布式对齐搜索 (DAS) 需要对潜在特征位置进行暴力搜索的问题，提出 HyperDAS。这是一个基于 Transformer 的超网络架构，能自动定位概念在残差流中的 token 位置，并构建这些向量的特征。在 Llama3-8B 上的实验达到了 SOTA 性能。\n\n*   **浅层神经网络学习的光谱偏差由非线性选择塑造 (The Spectral Bias of Shallow Neural Network Learning is Shaped by the Choice of Non-linearity)**\n    研究探讨了非线性激活函数如何塑造神经网络的隐式偏差。通过引入重参数化和利用 Radon 变换与傅里叶变换的联系，推导了由广泛激活函数引起的隐式偏差的显式公式，将其解释为最小化惩罚高频分量的谱半范数。\n\n*   **通过输入跳跃潜在二元贝叶斯神经网络实现可解释的贝叶斯深度学习 (Explainable Bayesian deep learning through input-skip Latent Binary Bayesian Neural Networks)**\n    提出输入跳跃 LBBNN，允许协变量跳到任何后续层或被排除，简化网络并阐明输入对预测的影响。该方法显著降低网络密度（超过 99%），同时保持高预测精度和不确定性度量，并引入“活动路径”增强了可解释性。\n\n*   **乘法学习 (Multiplicative Learning)**\n    提出 Expectation Reflection (ER)，一种新的学习方法，根据观察输出与预测输出的比率乘法更新权重。ER 无需损失函数或学习率超参数，可扩展到多层网络，并在单次迭代中实现最优权重更新。\n\n**其他值得关注的论文**\n\n*   **RoMA: 扩展基于 Mamba 的遥感基础模型 (RoMA: Scaling up Mamba-based Foundation Models for Remote Sensing)**: 提出 RoMA 框架，使用大规模无标签数据对基于 Mamba 的遥感基础模型进行可扩展的自监督预训练，通过旋转感知预训练和多尺度 token 预测解决遥感图像的挑战，性能优于 ViT。\n*   **ETCH: 通过等变紧密度将身体拟合推广到穿衣人体 (ETCH: Generalizing Body Fitting to Clothed Humans via Equivariant Tightness)**: 提出 ETCH 流程，通过局部近似 SE(3) 等变性估计布料到身体表面的映射，将紧密度编码为位移向量，简化了穿衣人体的拟合问题，显著优于现有方法。\n*   **NIL: 利用预训练视频扩散模型进行无数据模仿学习 (NIL: No-data Imitation Learning by Leveraging Pre-trained Video Diffusion Models)**: 提出 NIL，一种无需数据的技能获取方法，通过从生成的 2D 视频中学习 3D 运动技能，利用视频扩散模型的能力替代了对专家演示数据的依赖。\n*   **PyGDA: 一个用于图域自适应的 Python 库 (PyGDA: A Python Library for Graph Domain Adaptation)**: 介绍了首个全面的图域自适应 Python 库 PyGDA，包含 20 多种常用方法和不同类型的图数据集，支持模块化构建、采样和小型批处理。\n*   **HiRAG: 具有层次知识的检索增强生成 (Retrieval-Augmented Generation with Hierarchical Knowledge)**: 提出 HiRAG，一种利用自然存在的层次知识来增强 RAG 系统在索引和检索过程中语义理解和结构捕获能力的新方法。\n*   **AttentionRAG: 检索增强生成中的注意力引导上下文修剪 (AttentionRAG: Attention-Guided Context Pruning in Retrieval-Augmented Generation)**: 提出 AttentionRAG，一种注意力引导的 RAG 上下文修剪方法，通过注意力聚焦机制精确计算查询与上下文的注意力，实现高效压缩同时保持性能。\n*   **RankPO: 面向职位-人才匹配的偏好优化 (RankPO: Preference Optimization for Job-Talent Matching)**: 提出两阶段 LLM 训练框架用于职位-人才匹配。第一阶段使用对比学习处理匹配规则，第二阶段引入 RankPO（受 DPO 启发）根据 AI 策划的成对偏好进行微调，以平衡规则遵循和文本理解。\n*   **dFLMoE: 面向医疗数据分析的基于专家混合的去中心化联邦学习 (dFLMoE: Decentralized Federated Learning via Mixture of Experts for Medical Data Analysis)**: 提出去中心化联邦学习框架 dFLMoE，客户端直接交换轻量级头模型，并使用客户端特定的 MoE 方法进行集体决策，减少知识损害并增强鲁棒性。\n*   **MentalChat16K: 对话式心理健康援助基准数据集 (MentalChat16K: A Benchmark Dataset for Conversational Mental Health Assistance)**: 发布 MentalChat16K 数据集，结合了合成心理咨询数据和匿名干预记录，旨在促进用于对话式心理健康援助的 LLM 的开发和评估。\n*   **大型语言模型代理显示人类偏见但表现出独特的学习模式 (LLM Agents Display Human Biases but Exhibit Distinct Learning Patterns)**: 研究发现 LLM 在经验决策任务中总体上表现出与人类相似的偏见（如低估罕见事件），但更细致的分析揭示了不同的潜在学习模式，LLM 表现出强烈的近期偏见，而人类则没有。\n\n今天的快报就到这里，希望对你有所帮助！",
  "papers": [
    {
      "arxiv_id": "2503.10959v1",
      "title": "OuroMamba: A Data-Free Quantization Framework for Vision Mamba Models",
      "title_zh": "OuroMamba：面向视觉Mamba模型的无数据量化框架",
      "authors": [
        "Akshat Ramachandran",
        "Mingyu Lee",
        "Huan Xu",
        "Souvik Kundu",
        "Tushar Krishna"
      ],
      "abstract": "We present OuroMamba, the first data-free post-training quantization (DFQ)\nmethod for vision Mamba-based models (VMMs). We identify two key challenges in\nenabling DFQ for VMMs, (1) VMM's recurrent state transitions restricts\ncapturing of long-range interactions and leads to semantically weak synthetic\ndata, (2) VMM activations exhibit dynamic outlier variations across time-steps,\nrendering existing static PTQ techniques ineffective. To address these\nchallenges, OuroMamba presents a two-stage framework: (1) OuroMamba-Gen to\ngenerate semantically rich and meaningful synthetic data. It applies\ncontrastive learning on patch level VMM features generated through neighborhood\ninteractions in the latent state space, (2) OuroMamba-Quant to employ\nmixed-precision quantization with lightweight dynamic outlier detection during\ninference. In specific, we present a thresholding based outlier channel\nselection strategy for activations that gets updated every time-step. Extensive\nexperiments across vision and generative tasks show that our data-free\nOuroMamba surpasses existing data-driven PTQ techniques, achieving\nstate-of-the-art performance across diverse quantization settings.\nAdditionally, we implement efficient GPU kernels to achieve practical latency\nspeedup of up to 2.36x. Code will be released soon.",
      "tldr_zh": "本文提出了OuroMamba，首个面向视觉Mamba模型(VMMs)的无数据后训练量化(DFQ)框架。针对VMMs在DFQ中的两大挑战，OuroMamba采用两阶段方法：OuroMamba-Gen通过在潜在状态空间中利用邻域交互生成语义丰富的合成数据，OuroMamba-Quant则结合混合精度量化和轻量级动态异常值检测技术，实现了高效的量化处理。实验表明，OuroMamba在多种视觉和生成任务上超越了现有数据驱动的PTQ方法，并在实际应用中实现了最高2.36倍的加速。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10959v1",
      "published_date": "2025-03-13 23:58:55 UTC",
      "updated_date": "2025-03-13 23:58:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:04:25.718969"
    },
    {
      "arxiv_id": "2503.10957v1",
      "title": "Predicting Stock Movement with BERTweet and Transformers",
      "title_zh": "基于BERTweet与Transformer架构的股票走势预测",
      "authors": [
        "Michael Charles Albada",
        "Mojolaoluwa Joshua Sonola"
      ],
      "abstract": "Applying deep learning and computational intelligence to finance has been a\npopular area of applied research, both within academia and industry, and\ncontinues to attract active attention. The inherently high volatility and\nnon-stationary of the data pose substantial challenges to machine learning\nmodels, especially so for today's expressive and highly-parameterized deep\nlearning models. Recent work has combined natural language processing on data\nfrom social media to augment models based purely on historic price data to\nimprove performance has received particular attention. Previous work has\nachieved state-of-the-art performance on this task by combining techniques such\nas bidirectional GRUs, variational autoencoders, word and document embeddings,\nself-attention, graph attention, and adversarial training. In this paper, we\ndemonstrated the efficacy of BERTweet, a variant of BERT pre-trained\nspecifically on a Twitter corpus, and the transformer architecture by achieving\ncompetitive performance with the existing literature and setting a new baseline\nfor Matthews Correlation Coefficient on the Stocknet dataset without auxiliary\ndata sources.",
      "tldr_zh": "该研究探索了如何利用BERTweet（基于Twitter语料预训练的BERT变体）和Transformer架构预测股票走势。相比以往结合双向GRU、变分自编码器等复杂方法的研究，该方案仅使用社交媒体文本数据（无需辅助数据源）就在Stocknet数据集上取得了具有竞争力的效果，并创下了Matthews相关系数的新基准。这一成果为金融预测领域提供了更简洁高效的自然语言处理解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages, 4 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2503.10957v1",
      "published_date": "2025-03-13 23:46:24 UTC",
      "updated_date": "2025-03-13 23:46:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:04:38.935603"
    },
    {
      "arxiv_id": "2503.10954v1",
      "title": "Empirical Computation",
      "title_zh": "实证计算",
      "authors": [
        "Eric Tang",
        "Marcel Böhme"
      ],
      "abstract": "In this vision paper, we explore the challenges and opportunities of a form\nof computation that employs an empirical (rather than a formal) approach, where\nthe solution of a computational problem is returned as empirically most likely\n(rather than necessarily correct). We call this approach as *empirical\ncomputation* and observe that its capabilities and limits *cannot* be\nunderstood within the classic, rationalist framework of computation.\n  While we take a very broad view of \"computational problem\", a classic,\nwell-studied example is *sorting*: Given a set of $n$ numbers, return these\nnumbers sorted in ascending order.\n  * To run a classical, *formal computation*, we might first think about a\n*specific algorithm* (e.g., merge sort) before developing a *specific* program\nthat implements it. The program will expect the input to be given in a\n*specific* format, type, or data structure (e.g., unsigned 32-bit integers). In\nsoftware engineering, we have many approaches to analyze the correctness of\nsuch programs. From complexity theory, we know that there exists no correct\nprogram that can solve the average instance of the sorting problem faster than\n$O(n\\log n)$.\n  * To run an *empirical computation*, we might directly ask a large language\nmodel (LLM) to solve *any* computational problem (which can be stated\ninformally in natural language) and provide the input in *any* format (e.g.,\nnegative numbers written as Chinese characters). There is no (problem-specific)\nprogram that could be analyzed for correctness. Also, the time it takes an LLM\nto return an answer is entirely *independent* of the computational complexity\nof the problem that is solved.\n  What are the capabilities or limits of empirical computation in the general,\nin the problem-, or in the instance-specific? Our purpose is to establish\nempirical computation as a field in SE that is timely and rich with interesting\nproblems.",
      "tldr_zh": "这篇愿景论文提出了\"经验计算\"(empirical computation)的新范式，其核心是通过经验性方法(而非形式化方法)返回最可能(而非必然正确)的计算问题解决方案。与传统形式化计算不同，经验计算采用大语言模型(LLM)直接处理自然语言表述的各类计算问题，其运行时间与问题计算复杂度无关。作者以排序问题为例，对比了形式化计算(需明确定义算法和输入格式)与经验计算(接受任意输入表述)的根本差异，旨在将这一突破经典计算理论框架的新范式确立为软件工程领域的重要研究方向。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Open challenges in the analysis of properties and limits of empirical\n  computation",
      "pdf_url": "http://arxiv.org/pdf/2503.10954v1",
      "published_date": "2025-03-13 23:40:42 UTC",
      "updated_date": "2025-03-13 23:40:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:05:06.897479"
    },
    {
      "arxiv_id": "2503.10949v1",
      "title": "Safe Continual Domain Adaptation after Sim2Real Transfer of Reinforcement Learning Policies in Robotics",
      "title_zh": "安全持续领域适应：强化学习策略从仿真到机器人实际应用的迁移后",
      "authors": [
        "Josip Josifovski",
        "Shangding Gu",
        "Mohammadhossein Malmir",
        "Haoliang Huang",
        "Sayantan Auddy",
        "Nicolás Navarro-Guerrero",
        "Costas Spanos",
        "Alois Knoll"
      ],
      "abstract": "Domain randomization has emerged as a fundamental technique in reinforcement\nlearning (RL) to facilitate the transfer of policies from simulation to\nreal-world robotic applications. Many existing domain randomization approaches\nhave been proposed to improve robustness and sim2real transfer. These\napproaches rely on wide randomization ranges to compensate for the unknown\nactual system parameters, leading to robust but inefficient real-world\npolicies. In addition, the policies pretrained in the domain-randomized\nsimulation are fixed after deployment due to the inherent instability of the\noptimization processes based on RL and the necessity of sampling exploitative\nbut potentially unsafe actions on the real system. This limits the adaptability\nof the deployed policy to the inevitably changing system parameters or\nenvironment dynamics over time. We leverage safe RL and continual learning\nunder domain-randomized simulation to address these limitations and enable safe\ndeployment-time policy adaptation in real-world robot control. The experiments\nshow that our method enables the policy to adapt and fit to the current domain\ndistribution and environment dynamics of the real system while minimizing\nsafety risks and avoiding issues like catastrophic forgetting of the general\npolicy found in randomized simulation during the pretraining phase. Videos and\nsupplementary material are available at https://safe-cda.github.io/.",
      "tldr_zh": "该研究提出了一种结合安全强化学习(safe RL)和持续学习(continual learning)的方法，用于解决机器人策略从仿真到现实(sim2real)迁移后的安全持续域适应问题。通过在域随机化(domain randomization)仿真中预训练策略，并引入安全约束机制，该方法能在真实部署时持续适应变化的系统参数和环境动态，同时避免灾难性遗忘和安全风险。实验表明，该方法能有效拟合真实系统的当前域分布，相比传统固定策略显著提升了适应性和安全性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "8 pages, 5 figures, under review",
      "pdf_url": "http://arxiv.org/pdf/2503.10949v1",
      "published_date": "2025-03-13 23:28:11 UTC",
      "updated_date": "2025-03-13 23:28:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:04:47.323612"
    },
    {
      "arxiv_id": "2503.10945v1",
      "title": "$(\\varepsilon, δ)$ Considered Harmful: Best Practices for Reporting Differential Privacy Guarantees",
      "title_zh": "《$(\\varepsilon, δ)$有害论：差分隐私保障声明的最佳实践》",
      "authors": [
        "Juan Felipe Gomez",
        "Bogdan Kulynych",
        "Georgios Kaissis",
        "Jamie Hayes",
        "Borja Balle",
        "Antti Honkela"
      ],
      "abstract": "Current practices for reporting the level of differential privacy (DP)\nguarantees for machine learning (ML) algorithms provide an incomplete and\npotentially misleading picture of the guarantees and make it difficult to\ncompare privacy levels across different settings. We argue for using Gaussian\ndifferential privacy (GDP) as the primary means of communicating DP guarantees\nin ML, with the full privacy profile as a secondary option in case GDP is too\ninaccurate. Unlike other widely used alternatives, GDP has only one parameter,\nwhich ensures easy comparability of guarantees, and it can accurately capture\nthe full privacy profile of many important ML applications. To support our\nclaims, we investigate the privacy profiles of state-of-the-art DP large-scale\nimage classification, and the TopDown algorithm for the U.S. Decennial Census,\nobserving that GDP fits the profiles remarkably well in all three cases.\nAlthough GDP is ideal for reporting the final guarantees, other formalisms\n(e.g., privacy loss random variables) are needed for accurate privacy\naccounting. We show that such intermediate representations can be efficiently\nconverted to GDP with minimal loss in tightness.",
      "tldr_zh": "该论文批评了当前机器学习中差分隐私(DP)保证报告的不完整性和误导性，主张使用高斯差分隐私(GDP)作为主要报告方式。GDP具有单一参数，便于保证的可比性，并能准确捕捉许多重要机器学习应用的完整隐私轮廓。研究表明，GDP在图像分类和美国人口普查算法中的隐私轮廓拟合效果显著，尽管其他形式（如隐私损失随机变量）在隐私核算中仍有必要，但可以高效转换为GDP且损失极小。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10945v1",
      "published_date": "2025-03-13 23:06:30 UTC",
      "updated_date": "2025-03-13 23:06:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:04:56.874104"
    },
    {
      "arxiv_id": "2503.10941v1",
      "title": "Graph-Grounded LLMs: Leveraging Graphical Function Calling to Minimize LLM Hallucinations",
      "title_zh": "图基大语言模型：利用图形函数调用最小化LLM幻觉",
      "authors": [
        "Piyush Gupta",
        "Sangjae Bae",
        "David Isele"
      ],
      "abstract": "The adoption of Large Language Models (LLMs) is rapidly expanding across\nvarious tasks that involve inherent graphical structures. Graphs are integral\nto a wide range of applications, including motion planning for autonomous\nvehicles, social networks, scene understanding, and knowledge graphs. Many\nproblems, even those not initially perceived as graph-based, can be effectively\naddressed through graph theory. However, when applied to these tasks, LLMs\noften encounter challenges, such as hallucinations and mathematical\ninaccuracies. To overcome these limitations, we propose Graph-Grounded LLMs, a\nsystem that improves LLM performance on graph-related tasks by integrating a\ngraph library through function calls. By grounding LLMs in this manner, we\ndemonstrate significant reductions in hallucinations and improved mathematical\naccuracy in solving graph-based problems, as evidenced by the performance on\nthe NLGraph benchmark. Finally, we showcase a disaster rescue application where\nthe Graph-Grounded LLM acts as a decision-support system.",
      "tldr_zh": "本文提出Graph-Grounded LLMs框架，通过将大型语言模型(LLMs)与图函数库集成，有效减少模型在图形任务中的幻觉和数学错误。该方法在NLGraph基准测试中显著提升了LLMs处理图结构问题（如自动驾驶路径规划、社交网络分析等）的准确率，并展示了在灾难救援决策支持系统中的实际应用价值。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10941v1",
      "published_date": "2025-03-13 22:57:28 UTC",
      "updated_date": "2025-03-13 22:57:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:05:02.112505"
    },
    {
      "arxiv_id": "2503.10937v1",
      "title": "ChatGPT Encounters Morphing Attack Detection: Zero-Shot MAD with Multi-Modal Large Language Models and General Vision Models",
      "title_zh": "ChatGPT 遭遇变形攻击检测：基于多模态大型语言模型与通用视觉模型的零样本 MAD",
      "authors": [
        "Haoyu Zhang",
        "Raghavendra Ramachandra",
        "Kiran Raja",
        "Christoph Busch"
      ],
      "abstract": "Face Recognition Systems (FRS) are increasingly vulnerable to face-morphing\nattacks, prompting the development of Morphing Attack Detection (MAD)\nalgorithms. However, a key challenge in MAD lies in its limited\ngeneralizability to unseen data and its lack of explainability-critical for\npractical application environments such as enrolment stations and automated\nborder control systems. Recognizing that most existing MAD algorithms rely on\nsupervised learning paradigms, this work explores a novel approach to MAD using\nzero-shot learning leveraged on Large Language Models (LLMs). We propose two\ntypes of zero-shot MAD algorithms: one leveraging general vision models and the\nother utilizing multimodal LLMs. For general vision models, we address the MAD\ntask by computing the mean support embedding of an independent support set\nwithout using morphed images. For the LLM-based approach, we employ the\nstate-of-the-art GPT-4 Turbo API with carefully crafted prompts. To evaluate\nthe feasibility of zero-shot MAD and the effectiveness of the proposed methods,\nwe constructed a print-scan morph dataset featuring various unseen morphing\nalgorithms, simulating challenging real-world application scenarios.\nExperimental results demonstrated notable detection accuracy, validating the\napplicability of zero-shot learning for MAD tasks. Additionally, our\ninvestigation into LLM-based MAD revealed that multimodal LLMs, such as\nChatGPT, exhibit remarkable generalizability to untrained MAD tasks.\nFurthermore, they possess a unique ability to provide explanations and\nguidance, which can enhance transparency and usability for end-users in\npractical applications.",
      "tldr_zh": "该研究探索了基于零样本学习（Zero-Shot Learning）的面部变形攻击检测（MAD）新方法，提出两种创新方案：一是利用通用视觉模型（General Vision Models）通过计算独立支持集的平均支持嵌入来检测攻击；二是采用多模态大语言模型（如GPT-4 Turbo）配合精心设计的提示词进行检测。实验使用包含多种未见变形算法的打印扫描数据集验证，结果显示两种方法均取得显著检测精度，特别是多模态大语言模型展现出优异的任务泛化能力，并能提供可解释的检测结果，这对边境管控等实际应用场景具有重要意义。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10937v1",
      "published_date": "2025-03-13 22:53:24 UTC",
      "updated_date": "2025-03-13 22:53:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:05:26.252262"
    },
    {
      "arxiv_id": "2503.10927v1",
      "title": "OASST-ETC Dataset: Alignment Signals from Eye-tracking Analysis of LLM Responses",
      "title_zh": "OASST-ETC 数据集：基于眼动追踪分析大语言模型响应的对齐信号",
      "authors": [
        "Angela Lopez-Cardona",
        "Sebastian Idesis",
        "Miguel Barreda-Ángeles",
        "Sergi Abadal",
        "Ioannis Arapakis"
      ],
      "abstract": "While Large Language Models (LLMs) have significantly advanced natural\nlanguage processing, aligning them with human preferences remains an open\nchallenge. Although current alignment methods rely primarily on explicit\nfeedback, eye-tracking (ET) data offers insights into real-time cognitive\nprocessing during reading. In this paper, we present OASST-ETC, a novel\neye-tracking corpus capturing reading patterns from 24 participants, while\nevaluating LLM-generated responses from the OASST1 dataset. Our analysis\nreveals distinct reading patterns between preferred and non-preferred\nresponses, which we compare with synthetic eye-tracking data. Furthermore, we\nexamine the correlation between human reading measures and attention patterns\nfrom various transformer-based models, discovering stronger correlations in\npreferred responses. This work introduces a unique resource for studying human\ncognitive processing in LLM evaluation and suggests promising directions for\nincorporating eye-tracking data into alignment methods. The dataset and\nanalysis code are publicly available.",
      "tldr_zh": "该研究提出了OASST-ETC数据集，通过眼动追踪技术分析人类阅读LLM生成响应时的认知过程，为LLM与人类偏好的对齐提供了新视角。研究分析了24名参与者在阅读OASST1数据集中的LLM响应时的眼动模式，发现人类对偏好响应和非偏好响应的阅读模式存在显著差异，并与基于Transformer模型的注意力模式进行了相关性分析。结果表明，偏好响应的眼动数据与模型注意力模式的相关性更强。该研究为LLM对齐方法提供了新的数据资源，并探索了将眼动追踪数据融入对齐技术的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "This paper has been accepted to ACM ETRA 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.10927v1",
      "published_date": "2025-03-13 22:28:38 UTC",
      "updated_date": "2025-03-13 22:28:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:05:28.776766"
    },
    {
      "arxiv_id": "2503.10925v1",
      "title": "Predicting Clinical Outcomes with Waveform LSTMs",
      "title_zh": "利用波形 LSTM 预测临床结果",
      "authors": [
        "Michael Albada"
      ],
      "abstract": "Data mining and machine learning hold great potential to enable health\nsystems to systematically use data and analytics to identify inefficiencies and\nbest practices that improve care and reduce costs. Waveform data offers\nparticularly detailed information on how patient health evolves over time and\nhas the potential to significantly improve prediction accuracy on multiple\nbenchmarks, but has been widely under-utilized, largely because of the\nchallenges in working with these large and complex datasets. This study\nevaluates the potential of leveraging clinical waveform data to improve\nprediction accuracy on a single benchmark task: the risk of mortality in the\nintensive care unit. We identify significant potential from this data, beating\nthe existing baselines for both logistic regression and deep learning models.",
      "tldr_zh": "该研究探讨了利用波形LSTM模型预测临床结局的潜力，重点关注重症监护室(ICU)患者死亡风险预测这一基准任务。研究证明，临床波形数据能显著提升预测准确率，在逻辑回归和深度学习模型上均超越了现有基线水平。这一发现凸显了波形数据在医疗数据挖掘中的价值，为利用时序生理信号改善临床决策提供了新思路。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "7 pages,. arXiv admin note: text overlap with arXiv:1803.06589 by\n  other authors",
      "pdf_url": "http://arxiv.org/pdf/2503.10925v1",
      "published_date": "2025-03-13 22:19:05 UTC",
      "updated_date": "2025-03-13 22:19:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:05:35.198665"
    },
    {
      "arxiv_id": "2503.10918v1",
      "title": "Resource Heterogeneity-Aware and Utilization-Enhanced Scheduling for Deep Learning Clusters",
      "title_zh": "资源异构感知与利用率优化的深度学习集群调度系统",
      "authors": [
        "Abeda Sultana",
        "Nabin Pakka",
        "Fei Xu",
        "Xu Yuan",
        "Li Chen",
        "Nian-Feng Tzeng"
      ],
      "abstract": "Scheduling deep learning (DL) models to train on powerful clusters with\naccelerators like GPUs and TPUs, presently falls short, either lacking\nfine-grained heterogeneity awareness or leaving resources substantially\nunder-utilized. To fill this gap, we propose a novel design of a task-level\nheterogeneity-aware scheduler, {\\em Hadar}, based on an optimization framework\nthat can boost resource utilization. {\\em Hadar} leverages the performance\ntraits of DL jobs on a heterogeneous DL cluster, characterizes the task-level\nperformance heterogeneity in the optimization problem, and makes scheduling\ndecisions across both spatial and temporal dimensions. %with the objective to\nreduce the average job completion time of DL jobs. It involves the primal-dual\nframework employing a dual subroutine, to solve the optimization problem and\nguide the scheduling design. Our trace-driven simulation with representative DL\nmodel training workloads demonstrates that {\\em Hadar} accelerates the total\ntime duration by 1.20$\\times$ when compared with its state-of-the-art\nheterogeneity-aware counterpart, Gavel. Further, our {\\em Hadar} scheduler is\nenhanced to {\\em HadarE} by forking each job into multiple copies to let a job\ntrain concurrently on heterogeneous GPUs resided on separate available nodes\n(i.e., machines or servers) for resource utilization enhancement. {\\em HadarE}\nis evaluated extensively on physical DL clusters for comparison with {\\em\nHadar} and Gavel. With substantial enhancement in cluster resource utilization\n(by 1.45$\\times$), {\\em HadarE} exhibits considerable speed-ups in DL model\ntraining, reducing the total time duration by 50\\% (or 80\\%) on an Amazon's AWS\n(or our lab) cluster, while producing trained DL models with consistently\nbetter inference quality than those trained by \\textit{Hadar}.",
      "tldr_zh": "本研究提出了Hadar，一种任务级异构感知调度器，旨在解决深度学习（DL）集群中资源异构性和利用率不足的问题。Hadar基于优化框架，通过利用DL任务在异构集群上的性能特征，在时空维度上做出调度决策，从而减少任务完成时间。实验表明，Hadar比现有异构感知调度器Gavel加速1.20倍，而其增强版HadarE通过将任务分片到多个节点上并行训练，进一步提升了资源利用率（1.45倍），并在AWS和实验室集群上分别减少了50%和80%的总训练时间，同时提高了模型的推理质量。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG",
        "I.2.11; F.1.2"
      ],
      "primary_category": "cs.DC",
      "comment": "14 pages, 12 figures, IEEE Transactions on Computers",
      "pdf_url": "http://arxiv.org/pdf/2503.10918v1",
      "published_date": "2025-03-13 22:13:20 UTC",
      "updated_date": "2025-03-13 22:13:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:05:43.156199"
    },
    {
      "arxiv_id": "2503.10912v1",
      "title": "JPEG Compliant Compression for Both Human and Machine, A Report",
      "title_zh": "《面向人类与机器双重视觉的JPEG兼容压缩技术报告》",
      "authors": [
        "Linfeng Ye"
      ],
      "abstract": "Deep Neural Networks (DNNs) have become an integral part of our daily lives,\nespecially in vision-related applications. However, the conventional lossy\nimage compression algorithms are primarily designed for the Human Vision System\n(HVS), which can non-trivially compromise the DNNs' validation accuracy after\ncompression, as noted in \\cite{liu2018deepn}. Thus developing an image\ncompression algorithm for both human and machine (DNNs) is on the horizon.\n  To address the challenge mentioned above, in this paper, we first formulate\nthe image compression as a multi-objective optimization problem which take both\nhuman and machine prespectives into account, then we solve it by linear\ncombination, and proposed a novel distortion measure for both human and\nmachine, dubbed Human and Machine-Oriented Error (HMOE). After that, we develop\nHuman And Machine Oriented Soft Decision Quantization (HMOSDQ) based on HMOE, a\nlossy image compression algorithm for both human and machine (DNNs), and fully\ncomplied with JPEG format. In order to evaluate the performance of HMOSDQ,\nfinally we conduct the experiments for two pre-trained well-known DNN-based\nimage classifiers named Alexnet \\cite{Alexnet} and VGG-16\n\\cite{simonyan2014VGG} on two subsets of the ImageNet \\cite{deng2009imagenet}\nvalidation set: one subset included images with shorter side in the range of\n496 to 512, while the other included images with shorter side in the range of\n376 to 384. Our results demonstrate that HMOSDQ outperforms the default JPEG\nalgorithm in terms of rate-accuracy and rate-distortion performance. For the\nAlexnet comparing with the default JPEG algorithm, HMOSDQ can improve the\nvalidation accuracy by more than $0.81\\%$ at $0.61$ BPP, or equivalently reduce\nthe compression rate of default JPEG by $9.6\\times$ while maintaining the same\nvalidation accuracy.",
      "tldr_zh": "这篇论文提出了一种同时面向人类视觉系统（HVS）和机器视觉（DNN）的JPEG兼容图像压缩方法。研究者将图像压缩建模为多目标优化问题，提出了人类与机器导向误差（HMOE）这一新型失真度量标准，并基于此开发了完全兼容JPEG格式的HMOSDQ压缩算法。实验表明，相比标准JPEG，HMOSDQ在AlexNet和VGG-16等DNN模型上能提升0.81%的识别准确率，或在保持相同准确率下将压缩率降低9.6倍，实现了人类视觉质量与机器识别性能的双重优化。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "94A34",
        "I.4; I.2"
      ],
      "primary_category": "cs.CV",
      "comment": "9 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.10912v1",
      "published_date": "2025-03-13 21:52:25 UTC",
      "updated_date": "2025-03-13 21:52:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:06:24.840067"
    },
    {
      "arxiv_id": "2503.10908v1",
      "title": "Ecological Neural Architecture Search",
      "title_zh": "生态神经架构搜索",
      "authors": [
        "Benjamin David Winter",
        "William J. Teahan"
      ],
      "abstract": "When employing an evolutionary algorithm to optimize a neural networks\narchitecture, developers face the added challenge of tuning the evolutionary\nalgorithm's own hyperparameters - population size, mutation rate, cloning rate,\nand number of generations. This paper introduces Neuvo Ecological Neural\nArchitecture Search (ENAS), a novel method that incorporates these evolutionary\nparameters directly into the candidate solutions' phenotypes, allowing them to\nevolve dynamically alongside architecture specifications. Experimental results\nacross four binary classification datasets demonstrate that ENAS not only\neliminates manual tuning of evolutionary parameters but also outperforms\ncompetitor NAS methodologies in convergence speed (reducing computational time\nby 18.3%) and accuracy (improving classification performance in 3 out of 4\ndatasets). By enabling \"greedy individuals\" to optimize resource allocation\nbased on fitness, ENAS provides an efficient, self-regulating approach to\nneural architecture search.",
      "tldr_zh": "本文提出Ecological Neural Architecture Search (ENAS)方法，将进化算法的超参数（如种群规模、变异率等）直接编码到候选解的基因型中，使其能与神经网络架构同步进化。该方法在四个二分类数据集上的实验表明，ENAS不仅免除了人工调参的负担，还比现有NAS方法收敛速度更快（计算时间减少18.3%）且精度更高（在3/4数据集上表现更优）。通过让\"贪婪个体\"根据适应度自动优化资源分配，ENAS实现了高效、自调节的神经网络架构搜索。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "5 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.10908v1",
      "published_date": "2025-03-13 21:40:25 UTC",
      "updated_date": "2025-03-13 21:40:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:06:32.324652"
    },
    {
      "arxiv_id": "2503.10907v1",
      "title": "H2-MARL: Multi-Agent Reinforcement Learning for Pareto Optimality in Hospital Capacity Strain and Human Mobility during Epidemic",
      "title_zh": "H2-MARL：用于流行病期间医院容量压力与人口流动帕累托最优的多智能体强化学习",
      "authors": [
        "Xueting Luo",
        "Hao Deng",
        "Jihong Yang",
        "Yao Shen",
        "Huanhuan Guo",
        "Zhiyuan Sun",
        "Mingqing Liu",
        "Jiming Wei",
        "Shengjie Zhao"
      ],
      "abstract": "The necessity of achieving an effective balance between minimizing the losses\nassociated with restricting human mobility and ensuring hospital capacity has\ngained significant attention in the aftermath of COVID-19. Reinforcement\nlearning (RL)-based strategies for human mobility management have recently\nadvanced in addressing the dynamic evolution of cities and epidemics; however,\nthey still face challenges in achieving coordinated control at the township\nlevel and adapting to cities of varying scales. To address the above issues, we\npropose a multi-agent RL approach that achieves Pareto optimality in managing\nhospital capacity and human mobility (H2-MARL), applicable across cities of\ndifferent scales. We first develop a township-level infection model with\nonline-updatable parameters to simulate disease transmission and construct a\ncity-wide dynamic spatiotemporal epidemic simulator. On this basis, H2-MARL is\ndesigned to treat each division as an agent, with a trade-off dual-objective\nreward function formulated and an experience replay buffer enriched with expert\nknowledge built. To evaluate the effectiveness of the model, we construct a\ntownship-level human mobility dataset containing over one billion records from\nfour representative cities of varying scales. Extensive experiments demonstrate\nthat H2-MARL has the optimal dual-objective trade-off capability, which can\nminimize hospital capacity strain while minimizing human mobility restriction\nloss. Meanwhile, the applicability of the proposed model to epidemic control in\ncities of varying scales is verified, which showcases its feasibility and\nversatility in practical applications.",
      "tldr_zh": "该研究提出H2-MARL，一种基于多智能体强化学习（MARL）的方法，用于在疫情期间平衡医院承载压力与人员流动限制的帕累托最优（Pareto optimality）管理。该方法将城市各区域建模为独立智能体，采用可在线更新的乡镇级传染病模型和双目标奖励函数，结合专家知识增强的经验回放机制。基于包含10亿条记录的跨城市移动数据集验证表明，H2-MARL能在不同规模城市中实现医院资源压力与人员流动限制损失的最优权衡，相比现有方法展现出更强的适应性和实用性。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10907v1",
      "published_date": "2025-03-13 21:40:07 UTC",
      "updated_date": "2025-03-13 21:40:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:06:33.745829"
    },
    {
      "arxiv_id": "2503.10905v2",
      "title": "Learning to Inference Adaptively for Multimodal Large Language Models",
      "title_zh": "多模态大语言模型的自适应推理学习",
      "authors": [
        "Zhuoyan Xu",
        "Khoi Duc Nguyen",
        "Preeti Mukherjee",
        "Saurabh Bagchi",
        "Somali Chaterji",
        "Yingyu Liang",
        "Yin Li"
      ],
      "abstract": "Multimodal Large Language Models (MLLMs) have shown impressive capabilities\nin reasoning, yet come with substantial computational cost, limiting their\ndeployment in resource-constrained settings. Despite recent efforts on\nimproving the efficiency of MLLMs, prior solutions fall short in responding to\nvarying runtime conditions, in particular changing resource availability (e.g.,\ncontention due to the execution of other programs on the device). To bridge\nthis gap, we introduce AdaLLaVA, an adaptive inference framework that learns to\ndynamically reconfigure operations in an MLLM during inference, accounting for\nthe input data and a latency budget. We conduct extensive experiments across\nbenchmarks involving question-answering, reasoning, and hallucination. Our\nresults show that AdaLLaVA effectively adheres to input latency budget,\nachieving varying accuracy and latency tradeoffs at runtime. Further, we\ndemonstrate that AdaLLaVA adapts to both input latency and content, can be\nintegrated with token selection for enhanced efficiency, and generalizes across\nMLLMs. Our project webpage with code release is at\nhttps://zhuoyan-xu.github.io/ada-llava/.",
      "tldr_zh": "该研究提出了AdaLLaVA框架，通过动态调整多模态大语言模型(MLLM)的推理过程来解决计算资源受限场景下的效率问题。该方法能根据输入内容和延迟预算自适应地重构模型运算，在问答、推理和幻觉检测等任务中实现了准确率与延迟的动态权衡。实验表明该框架不仅兼容不同MLLM模型，还能与token选择技术结合进一步提升效率。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10905v2",
      "published_date": "2025-03-13 21:39:38 UTC",
      "updated_date": "2025-03-17 20:35:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:06:34.523156"
    },
    {
      "arxiv_id": "2503.10894v1",
      "title": "HyperDAS: Towards Automating Mechanistic Interpretability with Hypernetworks",
      "title_zh": "HyperDAS：基于超网络实现机制可解释性自动化",
      "authors": [
        "Jiuding Sun",
        "Jing Huang",
        "Sidharth Baskaran",
        "Karel D'Oosterlinck",
        "Christopher Potts",
        "Michael Sklar",
        "Atticus Geiger"
      ],
      "abstract": "Mechanistic interpretability has made great strides in identifying neural\nnetwork features (e.g., directions in hidden activation space) that mediate\nconcepts(e.g., the birth year of a person) and enable predictable manipulation.\nDistributed alignment search (DAS) leverages supervision from counterfactual\ndata to learn concept features within hidden states, but DAS assumes we can\nafford to conduct a brute force search over potential feature locations. To\naddress this, we present HyperDAS, a transformer-based hypernetwork\narchitecture that (1) automatically locates the token-positions of the residual\nstream that a concept is realized in and (2) constructs features of those\nresidual stream vectors for the concept. In experiments with Llama3-8B,\nHyperDAS achieves state-of-the-art performance on the RAVEL benchmark for\ndisentangling concepts in hidden states. In addition, we review the design\ndecisions we made to mitigate the concern that HyperDAS (like all powerful\ninterpretabilty methods) might inject new information into the target model\nrather than faithfully interpreting it.",
      "tldr_zh": "该研究提出了HyperDAS，一种基于超网络（hypernetwork）的框架，旨在自动化神经网络机制解释性（mechanistic interpretability）中的特征定位与构建。HyperDAS通过变压器架构自动定位残差流中概念的token位置，并构建相关特征，解决了传统分布式对齐搜索（DAS）需要暴力搜索的瓶颈。实验表明，HyperDAS在Llama3-8B模型上实现了RAVEL基准的最优性能，同时通过设计优化避免了向目标模型注入新信息的问题，为神经网络的可解释性研究提供了高效且可靠的工具。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.10894v1",
      "published_date": "2025-03-13 21:25:38 UTC",
      "updated_date": "2025-03-13 21:25:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:06:52.307761"
    },
    {
      "arxiv_id": "2503.10886v1",
      "title": "Taxonomic Reasoning for Rare Arthropods: Combining Dense Image Captioning and RAG for Interpretable Classification",
      "title_zh": "稀有节肢动物的分类推理：结合密集图像描述与RAG实现可解释性分类",
      "authors": [
        "Nathaniel Lesperance",
        "Sujeevan Ratnasingham",
        "Graham W. Taylor"
      ],
      "abstract": "In the context of pressing climate change challenges and the significant\nbiodiversity loss among arthropods, automated taxonomic classification from\norganismal images is a subject of intense research. However, traditional AI\npipelines based on deep neural visual architectures such as CNNs or ViTs face\nlimitations such as degraded performance on the long-tail of classes and the\ninability to reason about their predictions. We integrate image captioning and\nretrieval-augmented generation (RAG) with large language models (LLMs) to\nenhance biodiversity monitoring, showing particular promise for characterizing\nrare and unknown arthropod species. While a naive Vision-Language Model (VLM)\nexcels in classifying images of common species, the RAG model enables\nclassification of rarer taxa by matching explicit textual descriptions of\ntaxonomic features to contextual biodiversity text data from external sources.\nThe RAG model shows promise in reducing overconfidence and enhancing accuracy\nrelative to naive LLMs, suggesting its viability in capturing the nuances of\ntaxonomic hierarchy, particularly at the challenging family and genus levels.\nOur findings highlight the potential for modern vision-language AI pipelines to\nsupport biodiversity conservation initiatives, emphasizing the role of\ncomprehensive data curation and collaboration with citizen science platforms to\nimprove species identification, unknown species characterization and ultimately\ninform conservation strategies.",
      "tldr_zh": "本研究提出了一种结合密集图像描述(Dense Image Captioning)和检索增强生成(RAG)的创新方法，用于稀有节肢动物的可解释分类。针对传统CNN/ViT模型在长尾类目分类上的局限，该方法通过大型语言模型(LLMs)整合视觉特征与外部生物多样性文本数据，显著提升稀有物种的分类准确性。实验表明，RAG模型能有效减少过拟合并捕捉分类学层次结构的细微差异，尤其在科(family)和属(genus)级别的分类任务中表现突出。该研究为生物多样性监测提供了新思路，强调通过公民科学平台完善数据对保护策略的重要作用。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.IR",
        "cs.LG",
        "q-bio.PE"
      ],
      "primary_category": "cs.CV",
      "comment": "12 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.10886v1",
      "published_date": "2025-03-13 21:18:10 UTC",
      "updated_date": "2025-03-13 21:18:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:06:46.512117"
    },
    {
      "arxiv_id": "2503.11720v1",
      "title": "Fine-Tuning Diffusion Generative Models via Rich Preference Optimization",
      "title_zh": "通过丰富偏好优化微调扩散生成模型",
      "authors": [
        "Hanyang Zhao",
        "Haoxian Chen",
        "Yucheng Guo",
        "Genta Indra Winata",
        "Tingting Ou",
        "Ziyu Huang",
        "David D. Yao",
        "Wenpin Tang"
      ],
      "abstract": "We introduce Rich Preference Optimization (RPO), a novel pipeline that\nleverages rich feedback signals to improve the curation of preference pairs for\nfine-tuning text-to-image diffusion models. Traditional methods, like\nDiffusion-DPO, often rely solely on reward model labeling, which can be opaque,\noffer limited insights into the rationale behind preferences, and are prone to\nissues such as reward hacking or overfitting. In contrast, our approach begins\nwith generating detailed critiques of synthesized images to extract reliable\nand actionable image editing instructions. By implementing these instructions,\nwe create refined images, resulting in synthetic, informative preference pairs\nthat serve as enhanced tuning datasets. We demonstrate the effectiveness of our\npipeline and the resulting datasets in fine-tuning state-of-the-art diffusion\nmodels.",
      "tldr_zh": "本文提出了一种新方法——丰富偏好优化（RPO），旨在通过利用详细的反馈信号来改进文本到图像扩散模型的偏好对生成和微调。与传统的Diffusion-DPO方法不同，RPO首先对合成图像生成详细批评，提取可靠且可操作的图像编辑指令，从而创建高质量的信息化偏好对。实验表明，RPO在微调最先进的扩散模型方面表现优异，有效解决了奖励模型标注的局限性问题。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.11720v1",
      "published_date": "2025-03-13 21:10:29 UTC",
      "updated_date": "2025-03-13 21:10:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:07:03.303185"
    },
    {
      "arxiv_id": "2503.10883v1",
      "title": "Chat-TS: Enhancing Multi-Modal Reasoning Over Time-Series and Natural Language Data",
      "title_zh": "Chat-TS：增强时间序列与自然语言数据的多模态推理能力",
      "authors": [
        "Paul Quinlan",
        "Qingguo Li",
        "Xiaodan Zhu"
      ],
      "abstract": "Time-series analysis is critical for a wide range of fields such as\nhealthcare, finance, transportation, and energy, among many others. The\npractical applications often involve analyzing time-series data alongside\ncontextual information in the form of natural language to support informed\ndecisions. However, current time-series models are limited in their ability to\nperform reasoning that involves both time-series and their textual content. In\nthis work, we address this gap by introducing \\textit{Chat-TS}, a large\nlanguage model (LLM) based framework, designed to support reasoning over time\nseries and textual data. Unlike traditional models, Chat-TS integrates\ntime-series tokens into LLMs' vocabulary, enhancing its reasoning ability over\nboth modalities without compromising the core natural language capabilities,\nenabling practical analysis and reasoning across modalities. To support\nlearning and evaluation in this setup, we contribute new datasets: the\n\\textit{TS Instruct Training Dataset} which pairs diverse time-series data with\nrelevant text instructions and responses for instruction tuning, the \\textit{TS\nInstruct Question and Answer (QA) Gold Dataset} which provides multiple-choice\nquestions designed to evaluate multimodal reasoning, and a \\textit{TS Instruct\nQuantitative Probing Set} which contains a small subset of the TS Instruct QA\ntasks alongside math and decision-making questions for LLM evaluation. We\ndesigned a training strategy to preserve the inherent reasoning capabilities of\nLLMs while augmenting them for time-series reasoning. Experiments show that\nChat-TS achieves state-of-the-art performance in multi-modal reasoning tasks by\nmaintaining strong natural language proficiency while improving time-series\nreasoning. ~\\footnote{To ensure replicability and facilitate future research,\nall models, datasets, and code will be available at [\\texttt{Github-URL}].}",
      "tldr_zh": "该研究提出了Chat-TS，一种基于大语言模型(LLM)的框架，旨在增强时间序列数据与自然语言的多模态推理能力。Chat-TS通过将时间序列标记整合到LLM的词汇表中，提升了模型在时间序列和文本数据上的联合推理能力，同时保留了核心的自然语言处理性能。研究还贡献了三个新数据集（TS Instruct Training Dataset、TS Instruct QA Gold Dataset和TS Instruct Quantitative Probing Set），用于模型训练和评估。实验表明，Chat-TS在多模态推理任务中实现了最先进的性能，为时间序列与文本的联合分析提供了有效工具。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10883v1",
      "published_date": "2025-03-13 21:05:11 UTC",
      "updated_date": "2025-03-13 21:05:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:07:06.962643"
    },
    {
      "arxiv_id": "2503.10879v1",
      "title": "Task-Specific Activation Functions for Neuroevolution using Grammatical Evolution",
      "title_zh": "利用文法进化的神经进化任务特定激活函数",
      "authors": [
        "Benjamin David Winter",
        "William John Teahan"
      ],
      "abstract": "Activation functions play a critical role in the performance and behaviour of\nneural networks, significantly impacting their ability to learn and generalise.\nTraditional activation functions, such as ReLU, sigmoid, and tanh, have been\nwidely used with considerable success. However, these functions may not always\nprovide optimal performance for all tasks and datasets. In this paper, we\nintroduce Neuvo GEAF - an innovative approach leveraging grammatical evolution\n(GE) to automatically evolve novel activation functions tailored to specific\nneural network architectures and datasets. Experiments conducted on well-known\nbinary classification datasets show statistically significant improvements in\nF1-score (between 2.4% and 9.4%) over ReLU using identical network\narchitectures. Notably, these performance gains were achieved without\nincreasing the network's parameter count, supporting the trend toward more\nefficient neural networks that can operate effectively on resource-constrained\nedge devices. This paper's findings suggest that evolved activation functions\ncan provide significant performance improvements for compact networks while\nmaintaining energy efficiency during both training and inference phases.",
      "tldr_zh": "本文提出Neuvo GEAF方法，利用语法演化(grammatical evolution)自动生成针对特定神经网络架构和数据集定制的激活函数。实验表明，在相同网络结构下，该方法在二元分类任务中比ReLU激活函数的F1分数提升2.4%-9.4%，且不增加参数量。这项研究为资源受限的边缘设备提供了更高效的神经网络解决方案，同时保持了训练和推理阶段的能效。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "8 pages, 4 figures, IEEE",
      "pdf_url": "http://arxiv.org/pdf/2503.10879v1",
      "published_date": "2025-03-13 20:50:21 UTC",
      "updated_date": "2025-03-13 20:50:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:07:10.509581"
    },
    {
      "arxiv_id": "2503.10872v2",
      "title": "TAIJI: Textual Anchoring for Immunizing Jailbreak Images in Vision Language Models",
      "title_zh": "TAIJI：基于文本锚定的视觉语言模型越狱图像免疫方法",
      "authors": [
        "Xiangyu Yin",
        "Yi Qi",
        "Jinwei Hu",
        "Zhen Chen",
        "Yi Dong",
        "Xingyu Zhao",
        "Xiaowei Huang",
        "Wenjie Ruan"
      ],
      "abstract": "Vision Language Models (VLMs) have demonstrated impressive inference\ncapabilities, but remain vulnerable to jailbreak attacks that can induce\nharmful or unethical responses. Existing defence methods are predominantly\nwhite-box approaches that require access to model parameters and extensive\nmodifications, making them costly and impractical for many real-world\nscenarios. Although some black-box defences have been proposed, they often\nimpose input constraints or require multiple queries, limiting their\neffectiveness in safety-critical tasks such as autonomous driving. To address\nthese challenges, we propose a novel black-box defence framework called\n\\textbf{T}extual \\textbf{A}nchoring for \\textbf{I}mmunizing \\textbf{J}ailbreak\n\\textbf{I}mages (\\textbf{TAIJI}). TAIJI leverages key phrase-based textual\nanchoring to enhance the model's ability to assess and mitigate the harmful\ncontent embedded within both visual and textual prompts. Unlike existing\nmethods, TAIJI operates effectively with a single query during inference, while\npreserving the VLM's performance on benign tasks. Extensive experiments\ndemonstrate that TAIJI significantly enhances the safety and reliability of\nVLMs, providing a practical and efficient solution for real-world deployment.",
      "tldr_zh": "该研究提出TAIJI框架，通过基于关键短语的文本锚定（textual anchoring）技术，增强视觉语言模型（VLMs）对图像和文本中恶意内容的识别与防御能力。与需要多轮查询或模型参数访问的现有方法不同，TAIJI仅需单次推理即可有效抵御越狱攻击（jailbreak attacks），同时保持模型在正常任务上的性能。实验表明，该黑盒防御方案显著提升了VLMs的安全性和可靠性，为自动驾驶等安全关键场景提供了实用解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10872v2",
      "published_date": "2025-03-13 20:39:31 UTC",
      "updated_date": "2025-03-21 19:46:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:08:47.481090"
    },
    {
      "arxiv_id": "2503.10869v1",
      "title": "Evaluating a Novel Neuroevolution and Neural Architecture Search System",
      "title_zh": "评估一种新型神经进化与神经架构搜索系统",
      "authors": [
        "Benjamin David Winter",
        "William John Teahan"
      ],
      "abstract": "The choice of neural network features can have a large impact on both the\naccuracy and speed of the network. Despite the current industry shift towards\nlarge transformer models, specialized binary classifiers remain critical for\nnumerous practical applications where computational efficiency and low latency\nare essential. Neural network features tend to be developed homogeneously,\nresulting in slower or less accurate networks when testing against multiple\ndatasets. In this paper, we show the effectiveness of Neuvo NAS+ a novel Python\nimplementation of an extended Neural Architecture Search (NAS+) which allows\nthe user to optimise the training parameters of a network as well as the\nnetwork's architecture. We provide an in-depth analysis of the importance of\ncatering a network's architecture to each dataset. We also describe the design\nof the Neuvo NAS+ system that selects network features on a task-specific basis\nincluding network training hyper-parameters such as the number of epochs and\nbatch size. Results show that the Neuvo NAS+ task-specific approach\nsignificantly outperforms several machine learning approaches such as Naive\nBayes, C4.5, Support Vector Machine and a standard Artificial Neural Network\nfor solving a range of binary classification problems in terms of accuracy. Our\nexperiments demonstrate substantial diversity in evolved network architectures\nacross different datasets, confirming the value of task-specific optimization.\nAdditionally, Neuvo NAS+ outperforms other evolutionary algorithm optimisers in\nterms of both accuracy and computational efficiency, showing that properly\noptimized binary classifiers can match or exceed the performance of more\ncomplex models while requiring significantly fewer computational resources.",
      "tldr_zh": "该研究提出了一种新型神经进化与神经架构搜索系统Neuvo NAS+，通过扩展的神经架构搜索(NAS+)技术同时优化网络架构和训练参数。实验表明，该系统能针对不同数据集自动定制网络特征和超参数，在多项二分类任务上显著优于朴素贝叶斯、支持向量机等传统方法，且计算效率优于其他进化算法优化器。研究证实任务特定优化可产生高度多样化的网络架构，使轻量级二分类器在保持高精度的同时大幅降低计算资源需求。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "10 pages, 5 figures, IEEE",
      "pdf_url": "http://arxiv.org/pdf/2503.10869v1",
      "published_date": "2025-03-13 20:35:34 UTC",
      "updated_date": "2025-03-13 20:35:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:09:04.935990"
    },
    {
      "arxiv_id": "2503.13509v1",
      "title": "MentalChat16K: A Benchmark Dataset for Conversational Mental Health Assistance",
      "title_zh": "MentalChat16K：对话式心理健康辅助的基准数据集",
      "authors": [
        "Jia Xu",
        "Tianyi Wei",
        "Bojian Hou",
        "Patryk Orzechowski",
        "Shu Yang",
        "Ruochen Jin",
        "Rachael Paulbeck",
        "Joost Wagenaar",
        "George Demiris",
        "Li Shen"
      ],
      "abstract": "We introduce MentalChat16K, an English benchmark dataset combining a\nsynthetic mental health counseling dataset and a dataset of anonymized\ntranscripts from interventions between Behavioral Health Coaches and Caregivers\nof patients in palliative or hospice care. Covering a diverse range of\nconditions like depression, anxiety, and grief, this curated dataset is\ndesigned to facilitate the development and evaluation of large language models\nfor conversational mental health assistance. By providing a high-quality\nresource tailored to this critical domain, MentalChat16K aims to advance\nresearch on empathetic, personalized AI solutions to improve access to mental\nhealth support services. The dataset prioritizes patient privacy, ethical\nconsiderations, and responsible data usage. MentalChat16K presents a valuable\nopportunity for the research community to innovate AI technologies that can\npositively impact mental well-being.",
      "tldr_zh": "该研究提出了MentalChat16K，一个专为心理健康对话辅助设计的英语基准数据集。该数据集整合了人工合成的心理咨询对话和来自临终关怀场景的真实匿名医患交流记录，覆盖抑郁、焦虑、悲伤等多种心理状况。通过提供这一高质量资源，研究旨在推动基于大语言模型(Large Language Models)的共情式AI心理辅助技术发展，同时严格遵循患者隐私保护和伦理规范。该数据集为开发个性化心理健康支持服务提供了重要研究基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CY",
        "cs.HC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.13509v1",
      "published_date": "2025-03-13 20:25:10 UTC",
      "updated_date": "2025-03-13 20:25:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:09:10.546928"
    },
    {
      "arxiv_id": "2503.10857v1",
      "title": "Towards Understanding Graphical Perception in Large Multimodal Models",
      "title_zh": "理解大型多模态模型中的图形感知能力",
      "authors": [
        "Kai Zhang",
        "Jianwei Yang",
        "Jeevana Priya Inala",
        "Chandan Singh",
        "Jianfeng Gao",
        "Yu Su",
        "Chenglong Wang"
      ],
      "abstract": "Despite the promising results of large multimodal models (LMMs) in complex\nvision-language tasks that require knowledge, reasoning, and perception\nabilities together, we surprisingly found that these models struggle with\nsimple tasks on infographics that require perception only. As existing\nbenchmarks primarily focus on end tasks that require various abilities, they\nprovide limited, fine-grained insights into the limitations of the models'\nperception abilities. To address this gap, we leverage the theory of graphical\nperception, an approach used to study how humans decode visual information\nencoded on charts and graphs, to develop an evaluation framework for analyzing\ngaps in LMMs' perception abilities in charts. With automated task generation\nand response evaluation designs, our framework enables comprehensive and\ncontrolled testing of LMMs' graphical perception across diverse chart types,\nvisual elements, and task types. We apply our framework to evaluate and\ndiagnose the perception capabilities of state-of-the-art LMMs at three\ngranularity levels (chart, visual element, and pixel). Our findings underscore\nseveral critical limitations of current state-of-the-art LMMs, including\nGPT-4o: their inability to (1) generalize across chart types, (2) understand\nfundamental visual elements, and (3) cross reference values within a chart.\nThese insights provide guidance for future improvements in perception abilities\nof LMMs. The evaluation framework and labeled data are publicly available at\nhttps://github.com/microsoft/lmm-graphical-perception.",
      "tldr_zh": "该研究揭示了大型多模态模型(LMMs)在图形感知方面的关键缺陷：尽管这些模型在需要综合能力的复杂视觉语言任务中表现优异，却在仅需基本感知能力的图表理解任务上表现不佳。通过借鉴人类图形感知理论，研究者开发了一个自动化评估框架，系统测试LMMs在多种图表类型、视觉元素和任务中的表现。研究发现当前最先进的LMMs(包括GPT-4o)存在三个主要局限：无法跨图表类型泛化、难以理解基本视觉元素、缺乏图表内数值交叉引用能力。该研究为改进多模态模型的感知能力提供了重要方向，相关评估框架和标注数据已开源。",
      "categories": [
        "cs.GR",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.GR",
      "comment": "Work in Progress",
      "pdf_url": "http://arxiv.org/pdf/2503.10857v1",
      "published_date": "2025-03-13 20:13:39 UTC",
      "updated_date": "2025-03-13 20:13:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:09:21.544635"
    },
    {
      "arxiv_id": "2503.13508v1",
      "title": "It is Too Many Options: Pitfalls of Multiple-Choice Questions in Generative AI and Medical Education",
      "title_zh": "选择泛滥之困：生成式AI与医学教育中多选题的潜在陷阱",
      "authors": [
        "Shrutika Singh",
        "Anton Alyakin",
        "Daniel Alexander Alber",
        "Jaden Stryker",
        "Ai Phuong S Tong",
        "Karl Sangwon",
        "Nicolas Goff",
        "Mathew de la Paz",
        "Miguel Hernandez-Rovira",
        "Ki Yun Park",
        "Eric Claude Leuthardt",
        "Eric Karl Oermann"
      ],
      "abstract": "The performance of Large Language Models (LLMs) on multiple-choice question\n(MCQ) benchmarks is frequently cited as proof of their medical capabilities. We\nhypothesized that LLM performance on medical MCQs may in part be illusory and\ndriven by factors beyond medical content knowledge and reasoning capabilities.\nTo assess this, we created a novel benchmark of free-response questions with\npaired MCQs (FreeMedQA). Using this benchmark, we evaluated three\nstate-of-the-art LLMs (GPT-4o, GPT-3.5, and LLama-3-70B-instruct) and found an\naverage absolute deterioration of 39.43% in performance on free-response\nquestions relative to multiple-choice (p = 1.3 * 10-5) which was greater than\nthe human performance decline of 22.29%. To isolate the role of the MCQ format\non performance, we performed a masking study, iteratively masking out parts of\nthe question stem. At 100% masking, the average LLM multiple-choice performance\nwas 6.70% greater than random chance (p = 0.002) with one LLM (GPT-4o)\nobtaining an accuracy of 37.34%. Notably, for all LLMs the free-response\nperformance was near zero. Our results highlight the shortcomings in medical\nMCQ benchmarks for overestimating the capabilities of LLMs in medicine, and,\nbroadly, the potential for improving both human and machine assessments using\nLLM-evaluated free-response questions.",
      "tldr_zh": "这篇论文质疑大语言模型(LLMs)在医学多选题(MCQ)测试中的表现可能具有误导性。研究者创建了包含自由回答题和对应多选题的新基准FreeMedQA，发现LLMs在自由回答模式下的表现比多选题模式平均下降39.43%，远高于人类22.29%的下降幅度。实验显示，即使完全遮蔽题目内容，LLMs的多选题准确率仍显著高于随机猜测(GPT-4o达37.34%)，而自由回答表现接近零。研究表明医学多选题可能高估LLMs的真实医学能力，建议采用LLM评估的自由回答形式改进评估方式。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "14 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.13508v1",
      "published_date": "2025-03-13 19:42:04 UTC",
      "updated_date": "2025-03-13 19:42:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:09:57.921483"
    },
    {
      "arxiv_id": "2503.13507v1",
      "title": "NeurIPS 2023 LLM Efficiency Fine-tuning Competition",
      "title_zh": "NeurIPS 2023大语言模型高效微调竞赛",
      "authors": [
        "Mark Saroufim",
        "Yotam Perlitz",
        "Leshem Choshen",
        "Luca Antiga",
        "Greg Bowyer",
        "Christian Puhrsch",
        "Driss Guessous",
        "Supriya Rao",
        "Geeta Chauhan",
        "Ashvini Kumar",
        "Jindal Pawan Kumar",
        "Rajpoot Ankur Parikh",
        "Joe Isaacson",
        "Weiwei Yang"
      ],
      "abstract": "Our analysis of the NeurIPS 2023 large language model (LLM) fine-tuning\ncompetition revealed the following trend: top-performing models exhibit\nsignificant overfitting on benchmark datasets, mirroring the broader issue of\nbenchmark overfitting on popular leaderboards and that data curation is\nessential in order to get a high performing LLM. The competition, which\nconsisted of two stages - an open evaluation stage with publicly available\ntasks and a closed evaluation stage with unseen tasks - allowed us to assess\nthe generalizability of fine-tuned LLMs. Our results highlight the limitations\nof current benchmark-based evaluation schemes for generative models and\ndemonstrate the need for more robust evaluation methods. Notably, the winning\nsubmissions utilized standard open-source libraries and focused primarily on\ndata curation. To facilitate further research and promote reproducibility, we\nrelease all competition entries, Docker files, and evaluation infrastructure,\nproviding a valuable resource for the community to explore fine-tuning,\noverfitting, and reproducibility in LLMs.",
      "tldr_zh": "该论文分析了NeurIPS 2023大语言模型(LLM)微调竞赛的关键发现：顶尖模型普遍存在对基准数据集的过拟合问题，反映出当前排行榜普遍存在的评估缺陷。研究表明，数据筛选(curation)对提升LLM性能至关重要，而获胜方案主要依赖标准开源库和精心设计的数据处理流程。通过公开竞赛全部参赛作品和评估框架，该研究为LLM微调、过拟合和可复现性研究提供了重要资源，同时揭示了当前生成模型评估方法的局限性，呼吁开发更健壮的评价体系。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "11 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.13507v1",
      "published_date": "2025-03-13 19:35:40 UTC",
      "updated_date": "2025-03-13 19:35:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:09:37.861428"
    },
    {
      "arxiv_id": "2503.10822v1",
      "title": "Rotated Bitboards in FUSc# and Reinforcement Learning in Computer Chess and Beyond",
      "title_zh": "FUSc#中的旋转位棋盘与计算机象棋及其他领域的强化学习",
      "authors": [
        "Johannes Buchner"
      ],
      "abstract": "There exist several techniques for representing the chess board inside the\ncomputer. In the first part of this paper, the concepts of the\nbitboard-representation and the advantages of (rotated) bitboards in move\ngeneration are explained. In order to illustrate those ideas practice, the\nconcrete implementation of the move-generator in FUSc# is discussed and we\nexplain a technique how to verify the move-generator with the \"perft\"-command.\nWe show that the move-generator of FUSc# works 100% correct.\n  The second part of this paper deals with reinforcement learning in computer\nchess (and beyond). We exemplify the progress that has been made in this field\nin the last 15-20 years by comparing the \"state of the art\" from 2002-2008,\nwhen FUSc# was developed, with recent innovations connected to \"AlphaZero\". We\ndiscuss how a \"FUSc#-Zero\" could be implemented and what would be necessary to\nreduce the number of training games necessary to achieve a good performance.\nThis can be seen as a test case to the general prblem of improving \"sample\neffciency\" in reinforcement learning.\n  In the final part, we move beyond computer chess, as the importance of sample\neffciency extends far beyond board games into a wide range of applications\nwhere data is costly, diffcult to obtain, or time consuming to generate. We\nreview some application of the ideas developed in AlphaZero in other domains,\ni.e. the \"other Alphas\" like AlphaFold, AlphaTensor, AlphaGeometry and\nAlphaProof. We also discuss future research and the potential for such methods\nfor ecological economic planning.",
      "tldr_zh": "该论文分为三部分：首先详细介绍了棋盘位图表示法(bitboard)及其旋转优化在走子生成中的优势，并以FUSc#程序为例说明其100%正确的走子生成器实现。其次探讨了计算机象棋领域的强化学习进展，对比了2002-2008年FUSc#开发时期与AlphaZero时代的技术差异，提出了构建\"FUSc#-Zero\"的设想以提升训练样本效率。最后将视野扩展到棋盘游戏之外，分析了AlphaZero系列方法(如AlphaFold、AlphaTensor等)在其他领域的应用潜力，特别是在生态经济规划等数据获取成本高的领域。",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "23 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.10822v1",
      "published_date": "2025-03-13 19:13:51 UTC",
      "updated_date": "2025-03-13 19:13:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:10:02.620125"
    },
    {
      "arxiv_id": "2503.13505v1",
      "title": "Ensemble Learning for Large Language Models in Text and Code Generation: A Survey",
      "title_zh": "大语言模型在文本与代码生成中的集成学习方法综述",
      "authors": [
        "Mari Ashiga",
        "Wei Jie",
        "Fan Wu",
        "Vardan Voskanyan",
        "Fateme Dinmohammadi",
        "Paul Brookes",
        "Jingzhi Gong",
        "Zheng Wang"
      ],
      "abstract": "Generative pretrained transformers (GPT) are the common large language models\n(LLMs) used for generating text from natural language inputs. However, the\nfixed properties of language parameters in individual LLMs can lead to\ninconsistencies in the generated outputs. This limitation also restricts the\nmodels' ability to represent diverse language patterns due to inherent biases.\nMoreover, many powerful LLMs are closed-source. This prevents organizations\nfrom integrating their data into these systems, raising concerns about data\nprivacy and limiting industry applications. Inspired by the successful\napplication of LLM ensemble models in text generation, recent literature has\nalso investigated their potential in code generation. This article reviews\nthese emerging LLM ensemble approaches. Our goal is to enhance readers'\nunderstanding of existing techniques and encourage further research and\npractical implementation, aiming to expand the real-world applications of LLM\nensemble models in both text and code generation. We categorize these\napproaches into seven main methods: weight merging, knowledge fusion, mixture\nof experts, reward ensemble, output ensemble, routing, and cascading. From this\nlist, we focus on four methods and models that show strong performance and\npotential for broader applications. We analyze their modeling steps, training\nmethods, and output features to provide a clear understanding of their\ncapabilities. Our findings highlight the benefits of LLM ensemble techniques.\nThese include better representation of diversity, improved output quality, and\ngreater flexibility in applications. This information offers valuable insights\nfor selecting models for various real-world tasks involving text and code\ngeneration, and potentially applying methods to multimodal LLMs.",
      "tldr_zh": "这篇综述论文系统探讨了大语言模型(LLMs)在文本和代码生成中的集成学习(Ensemble Learning)方法。研究将现有LLM集成技术归纳为七类主要方法，重点分析了其中四种表现优异且具应用潜力的模型架构。论文指出，集成方法能有效缓解单一LLM的固有偏差问题，显著提升输出多样性和生成质量。通过详细解析不同集成策略的训练机制和输出特性，该研究为实际应用中LLM模型的选择提供了重要参考，并为多模态LLM的集成研究奠定了基础。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Submitted to IEEE TAI",
      "pdf_url": "http://arxiv.org/pdf/2503.13505v1",
      "published_date": "2025-03-13 18:50:57 UTC",
      "updated_date": "2025-03-13 18:50:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:10:00.312165"
    },
    {
      "arxiv_id": "2503.16507v1",
      "title": "Fewer Than 1% of Explainable AI Papers Validate Explainability with Humans",
      "title_zh": "不到1%的可解释人工智能论文通过人类验证其可解释性",
      "authors": [
        "Ashley Suh",
        "Isabelle Hurley",
        "Nora Smith",
        "Ho Chit Siu"
      ],
      "abstract": "This late-breaking work presents a large-scale analysis of explainable AI\n(XAI) literature to evaluate claims of human explainability. We collaborated\nwith a professional librarian to identify 18,254 papers containing keywords\nrelated to explainability and interpretability. Of these, we find that only 253\npapers included terms suggesting human involvement in evaluating an XAI\ntechnique, and just 128 of those conducted some form of a human study. In other\nwords, fewer than 1% of XAI papers (0.7%) provide empirical evidence of human\nexplainability when compared to the broader body of XAI literature. Our\nfindings underscore a critical gap between claims of human explainability and\nevidence-based validation, raising concerns about the rigor of XAI research. We\ncall for increased emphasis on human evaluations in XAI studies and provide our\nliterature search methodology to enable both reproducibility and further\ninvestigation into this widespread issue.",
      "tldr_zh": "该研究对可解释人工智能(XAI)领域进行了大规模文献分析，发现仅有0.7%的论文通过人类实验验证其可解释性。在18,254篇相关文献中，仅128篇进行了某种形式的人类研究，揭示了XAI研究中人类验证的严重不足。研究呼吁加强XAI技术的人类评估，并提供了可重复的文献搜索方法，以促进对这一问题的进一步研究。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "Extended Abstracts of the CHI Conference on Human Factors in\n  Computing Systems (CHI EA '25)",
      "pdf_url": "http://arxiv.org/pdf/2503.16507v1",
      "published_date": "2025-03-13 18:39:50 UTC",
      "updated_date": "2025-03-13 18:39:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:09:56.132906"
    },
    {
      "arxiv_id": "2503.10792v1",
      "title": "Byzantine-Resilient Federated Learning via Distributed Optimization",
      "title_zh": "拜占庭弹性联邦学习：基于分布式优化的方法",
      "authors": [
        "Yufei Xia",
        "Wenrui Yu",
        "Qiongxiu Li"
      ],
      "abstract": "Byzantine attacks present a critical challenge to Federated Learning (FL),\nwhere malicious participants can disrupt the training process, degrade model\naccuracy, and compromise system reliability. Traditional FL frameworks\ntypically rely on aggregation-based protocols for model updates, leaving them\nvulnerable to sophisticated adversarial strategies. In this paper, we\ndemonstrate that distributed optimization offers a principled and robust\nalternative to aggregation-centric methods. Specifically, we show that the\nPrimal-Dual Method of Multipliers (PDMM) inherently mitigates Byzantine impacts\nby leveraging its fault-tolerant consensus mechanism. Through extensive\nexperiments on three datasets (MNIST, FashionMNIST, and Olivetti), under\nvarious attack scenarios including bit-flipping and Gaussian noise injection,\nwe validate the superior resilience of distributed optimization protocols.\nCompared to traditional aggregation-centric approaches, PDMM achieves higher\nmodel utility, faster convergence, and improved stability. Our results\nhighlight the effectiveness of distributed optimization in defending against\nByzantine threats, paving the way for more secure and resilient federated\nlearning systems.",
      "tldr_zh": "该论文提出了一种基于分布式优化的拜占庭容错联邦学习框架。研究发现，传统基于聚合的联邦学习方法容易受到恶意参与者的攻击，而采用乘子法（PDMM）的分布式优化方法通过其容错共识机制，能够有效抵御拜占庭攻击。实验表明，在MNIST等数据集上，该方法比传统聚合方法具有更高的模型精度、更快收敛速度和更好稳定性，为构建更安全的联邦学习系统提供了新思路。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10792v1",
      "published_date": "2025-03-13 18:34:42 UTC",
      "updated_date": "2025-03-13 18:34:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:10:06.596195"
    },
    {
      "arxiv_id": "2503.10784v1",
      "title": "Vulnerability Detection: From Formal Verification to Large Language Models and Hybrid Approaches: A Comprehensive Overview",
      "title_zh": "漏洞检测：从形式化验证到大型语言模型及混合方法的全面综述",
      "authors": [
        "Norbert Tihanyi",
        "Tamas Bisztray",
        "Mohamed Amine Ferrag",
        "Bilel Cherif",
        "Richard A. Dubniczky",
        "Ridhi Jain",
        "Lucas C. Cordeiro"
      ],
      "abstract": "Software testing and verification are critical for ensuring the reliability\nand security of modern software systems. Traditionally, formal verification\ntechniques, such as model checking and theorem proving, have provided rigorous\nframeworks for detecting bugs and vulnerabilities. However, these methods often\nface scalability challenges when applied to complex, real-world programs.\nRecently, the advent of Large Language Models (LLMs) has introduced a new\nparadigm for software analysis, leveraging their ability to understand insecure\ncoding practices. Although LLMs demonstrate promising capabilities in tasks\nsuch as bug prediction and invariant generation, they lack the formal\nguarantees of classical methods. This paper presents a comprehensive study of\nstate-of-the-art software testing and verification, focusing on three key\napproaches: classical formal methods, LLM-based analysis, and emerging hybrid\ntechniques, which combine their strengths. We explore each approach's\nstrengths, limitations, and practical applications, highlighting the potential\nof hybrid systems to address the weaknesses of standalone methods. We analyze\nwhether integrating formal rigor with LLM-driven insights can enhance the\neffectiveness and scalability of software verification, exploring their\nviability as a pathway toward more robust and adaptive testing frameworks.",
      "tldr_zh": "本文全面综述了软件漏洞检测的三种主要方法：传统的形式化验证（如模型检测和定理证明）、基于大语言模型（LLMs）的分析以及新兴的混合方法。传统方法虽具严谨性，但在复杂系统中面临可扩展性挑战；LLMs在漏洞预测和不变式生成等任务中表现优异，但缺乏形式化保证。研究重点探讨了混合方法如何结合两者的优势，以提升软件验证的有效性和可扩展性，为构建更健壮和自适应的测试框架提供了新思路。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10784v1",
      "published_date": "2025-03-13 18:22:22 UTC",
      "updated_date": "2025-03-13 18:22:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:10:27.395991"
    },
    {
      "arxiv_id": "2503.10638v1",
      "title": "Studying Classifier(-Free) Guidance From a Classifier-Centric Perspective",
      "title_zh": "从分类器中心视角研究（无分类器）引导机制",
      "authors": [
        "Xiaoming Zhao",
        "Alexander G. Schwing"
      ],
      "abstract": "Classifier-free guidance has become a staple for conditional generation with\ndenoising diffusion models. However, a comprehensive understanding of\nclassifier-free guidance is still missing. In this work, we carry out an\nempirical study to provide a fresh perspective on classifier-free guidance.\nConcretely, instead of solely focusing on classifier-free guidance, we trace\nback to the root, i.e., classifier guidance, pinpoint the key assumption for\nthe derivation, and conduct a systematic study to understand the role of the\nclassifier. We find that both classifier guidance and classifier-free guidance\nachieve conditional generation by pushing the denoising diffusion trajectories\naway from decision boundaries, i.e., areas where conditional information is\nusually entangled and is hard to learn. Based on this classifier-centric\nunderstanding, we propose a generic postprocessing step built upon\nflow-matching to shrink the gap between the learned distribution for a\npre-trained denoising diffusion model and the real data distribution, majorly\naround the decision boundaries. Experiments on various datasets verify the\neffectiveness of the proposed approach.",
      "tldr_zh": "这项研究从分类器视角重新审视了扩散模型中的classifier-free guidance机制。研究发现，无论是classifier guidance还是classifier-free guidance，其本质都是通过使去噪轨迹远离决策边界（decision boundaries）来实现条件生成，因为该区域的条件信息通常高度纠缠且难以学习。基于这一发现，作者提出了一种基于flow-matching的后处理方法，有效缩小了预训练扩散模型学习分布与真实数据分布在决策边界附近的差距。多个数据集的实验验证了该方法的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10638v1",
      "published_date": "2025-03-13 17:59:59 UTC",
      "updated_date": "2025-03-13 17:59:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:10:56.927920"
    },
    {
      "arxiv_id": "2503.10635v1",
      "title": "A Frustratingly Simple Yet Highly Effective Attack Baseline: Over 90% Success Rate Against the Strong Black-box Models of GPT-4.5/4o/o1",
      "title_zh": "令人沮丧却高效的攻击基线：针对GPT-4.5/4o/o1等强黑盒模型实现超90%成功率",
      "authors": [
        "Zhaoyi Li",
        "Xiaohan Zhao",
        "Dong-Dong Wu",
        "Jiacheng Cui",
        "Zhiqiang Shen"
      ],
      "abstract": "Despite promising performance on open-source large vision-language models\n(LVLMs), transfer-based targeted attacks often fail against black-box\ncommercial LVLMs. Analyzing failed adversarial perturbations reveals that the\nlearned perturbations typically originate from a uniform distribution and lack\nclear semantic details, resulting in unintended responses. This critical\nabsence of semantic information leads commercial LVLMs to either ignore the\nperturbation entirely or misinterpret its embedded semantics, thereby causing\nthe attack to fail. To overcome these issues, we notice that identifying core\nsemantic objects is a key objective for models trained with various datasets\nand methodologies. This insight motivates our approach that refines semantic\nclarity by encoding explicit semantic details within local regions, thus\nensuring interoperability and capturing finer-grained features, and by\nconcentrating modifications on semantically rich areas rather than applying\nthem uniformly. To achieve this, we propose a simple yet highly effective\nsolution: at each optimization step, the adversarial image is cropped randomly\nby a controlled aspect ratio and scale, resized, and then aligned with the\ntarget image in the embedding space. Experimental results confirm our\nhypothesis. Our adversarial examples crafted with local-aggregated\nperturbations focused on crucial regions exhibit surprisingly good\ntransferability to commercial LVLMs, including GPT-4.5, GPT-4o,\nGemini-2.0-flash, Claude-3.5-sonnet, Claude-3.7-sonnet, and even reasoning\nmodels like o1, Claude-3.7-thinking and Gemini-2.0-flash-thinking. Our approach\nachieves success rates exceeding 90% on GPT-4.5, 4o, and o1, significantly\noutperforming all prior state-of-the-art attack methods. Our optimized\nadversarial examples under different configurations and training code are\navailable at https://github.com/VILA-Lab/M-Attack.",
      "tldr_zh": "这篇论文提出了一种简单但极其有效的对抗攻击方法，专门针对GPT-4.5/4o/o1等商业级黑盒视觉语言模型(LVLMs)。研究发现，传统攻击方法失败的关键在于生成的扰动缺乏语义细节，而新方法通过聚焦关键语义区域进行局部优化，显著提升了攻击成功率。实验表明，该方法在GPT-4.5、4o等主流商业模型上的攻击成功率超过90%，远超现有最优方法，并在Claude-3.7、Gemini-2.0等系列模型上也表现出卓越的迁移性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Code at: https://github.com/VILA-Lab/M-Attack",
      "pdf_url": "http://arxiv.org/pdf/2503.10635v1",
      "published_date": "2025-03-13 17:59:55 UTC",
      "updated_date": "2025-03-13 17:59:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:10:52.208898"
    },
    {
      "arxiv_id": "2503.10628v1",
      "title": "Uncertainty in Action: Confidence Elicitation in Embodied Agents",
      "title_zh": "行动中的不确定性：具身智能体的置信度评估",
      "authors": [
        "Tianjiao Yu",
        "Vedant Shah",
        "Muntasir Wahed",
        "Kiet A. Nguyen",
        "Adheesh Juvekar",
        "Tal August",
        "Ismini Lourentzou"
      ],
      "abstract": "Expressing confidence is challenging for embodied agents navigating dynamic\nmultimodal environments, where uncertainty arises from both perception and\ndecision-making processes. We present the first work investigating embodied\nconfidence elicitation in open-ended multimodal environments. We introduce\nElicitation Policies, which structure confidence assessment across inductive,\ndeductive, and abductive reasoning, along with Execution Policies, which\nenhance confidence calibration through scenario reinterpretation, action\nsampling, and hypothetical reasoning. Evaluating agents in calibration and\nfailure prediction tasks within the Minecraft environment, we show that\nstructured reasoning approaches, such as Chain-of-Thoughts, improve confidence\ncalibration. However, our findings also reveal persistent challenges in\ndistinguishing uncertainty, particularly under abductive settings, underscoring\nthe need for more sophisticated embodied confidence elicitation methods.",
      "tldr_zh": "该研究首次探讨了具身智能体在开放多模态环境中的置信度表达问题，提出\"置信诱导策略\"(Elicitation Policies)和\"执行策略\"(Execution Policies)两大框架。通过归纳、演绎和溯因三种推理模式的结构化评估，结合情境重解释、动作采样和假设推理等技术，显著提升了智能体在Minecraft环境中的置信度校准能力。实验表明，虽然思维链(Chain-of-Thoughts)等结构化推理方法有效，但在溯因推理场景下仍存在不确定性区分难题，凸显了需要开发更先进的具身置信诱导方法。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Project page: https://plan-lab.github.io/ece/",
      "pdf_url": "http://arxiv.org/pdf/2503.10628v1",
      "published_date": "2025-03-13 17:59:41 UTC",
      "updated_date": "2025-03-13 17:59:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:11:09.572045"
    },
    {
      "arxiv_id": "2503.10627v1",
      "title": "SciVerse: Unveiling the Knowledge Comprehension and Visual Reasoning of LMMs on Multi-modal Scientific Problems",
      "title_zh": "SciVerse：揭示大模型在多模态科学问题上的知识理解与视觉推理能力",
      "authors": [
        "Ziyu Guo",
        "Ray Zhang",
        "Hao Chen",
        "Jialin Gao",
        "Dongzhi Jiang",
        "Jiaze Wang",
        "Pheng-Ann Heng"
      ],
      "abstract": "The rapid advancement of Large Multi-modal Models (LMMs) has enabled their\napplication in scientific problem-solving, yet their fine-grained capabilities\nremain under-explored. In this paper, we introduce SciVerse, a multi-modal\nscientific evaluation benchmark to thoroughly assess LMMs across 5,735 test\ninstances in five distinct versions. We aim to investigate three key dimensions\nof LMMs: scientific knowledge comprehension, multi-modal content\ninterpretation, and Chain-of-Thought (CoT) reasoning. To unveil whether LMMs\npossess sufficient scientific expertise, we first transform each problem into\nthree versions containing different levels of knowledge required for solving,\ni.e., Knowledge-free, -lite, and -rich. Then, to explore how LMMs interpret\nmulti-modal scientific content, we annotate another two versions, i.e.,\nVision-rich and -only, marking more question information from texts to\ndiagrams. Comparing the results of different versions, SciVerse systematically\nexamines the professional knowledge stock and visual perception skills of LMMs\nin scientific domains. In addition, to rigorously assess CoT reasoning, we\npropose a new scientific CoT evaluation strategy, conducting a step-wise\nassessment on knowledge and logical errors in model outputs. Our extensive\nevaluation of different LMMs on SciVerse reveals critical limitations in their\nscientific proficiency and provides new insights into future developments.\nProject page: https://sciverse-cuhk.github.io",
      "tldr_zh": "该研究提出了SciVerse，一个多模态科学问题评估基准，旨在全面分析大型多模态模型(LMMs)在科学领域的知识理解、多模态内容解读和链式思维推理(CoT)能力。通过对5,735个测试实例的五个版本进行系统评估，研究揭示了LMMs在科学专业知识储备和视觉感知技能上的关键局限，并提出了新的科学CoT评估策略，为未来模型改进提供了重要见解。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "Initially released in September 2024. Project page:\n  https://sciverse-cuhk.github.io",
      "pdf_url": "http://arxiv.org/pdf/2503.10627v1",
      "published_date": "2025-03-13 17:59:32 UTC",
      "updated_date": "2025-03-13 17:59:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:11:07.551477"
    },
    {
      "arxiv_id": "2503.10626v1",
      "title": "NIL: No-data Imitation Learning by Leveraging Pre-trained Video Diffusion Models",
      "title_zh": "NIL：利用预训练视频扩散模型实现无数据模仿学习",
      "authors": [
        "Mert Albaba",
        "Chenhao Li",
        "Markos Diomataris",
        "Omid Taheri",
        "Andreas Krause",
        "Michael Black"
      ],
      "abstract": "Acquiring physically plausible motor skills across diverse and unconventional\nmorphologies-including humanoid robots, quadrupeds, and animals-is essential\nfor advancing character simulation and robotics. Traditional methods, such as\nreinforcement learning (RL) are task- and body-specific, require extensive\nreward function engineering, and do not generalize well. Imitation learning\noffers an alternative but relies heavily on high-quality expert demonstrations,\nwhich are difficult to obtain for non-human morphologies. Video diffusion\nmodels, on the other hand, are capable of generating realistic videos of\nvarious morphologies, from humans to ants. Leveraging this capability, we\npropose a data-independent approach for skill acquisition that learns 3D motor\nskills from 2D-generated videos, with generalization capability to\nunconventional and non-human forms. Specifically, we guide the imitation\nlearning process by leveraging vision transformers for video-based comparisons\nby calculating pair-wise distance between video embeddings. Along with\nvideo-encoding distance, we also use a computed similarity between segmented\nvideo frames as a guidance reward. We validate our method on locomotion tasks\ninvolving unique body configurations. In humanoid robot locomotion tasks, we\ndemonstrate that 'No-data Imitation Learning' (NIL) outperforms baselines\ntrained on 3D motion-capture data. Our results highlight the potential of\nleveraging generative video models for physically plausible skill learning with\ndiverse morphologies, effectively replacing data collection with data\ngeneration for imitation learning.",
      "tldr_zh": "本研究提出NIL（无数据模仿学习）方法，通过利用预训练视频扩散模型从2D生成视频中学习3D运动技能。该方法采用视觉Transformer进行视频嵌入比对，结合视频帧分割相似度作为奖励信号，无需依赖真实专家示范数据。实验表明，NIL在非人类形态的独特身体配置运动任务中表现优异，甚至超越基于3D动作捕捉数据训练的基线模型。该研究开创性地用数据生成替代数据收集，为多样化形态的物理合理技能学习提供了新范式。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10626v1",
      "published_date": "2025-03-13 17:59:24 UTC",
      "updated_date": "2025-03-13 17:59:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:13:09.078332"
    },
    {
      "arxiv_id": "2503.10625v1",
      "title": "LHM: Large Animatable Human Reconstruction Model from a Single Image in Seconds",
      "title_zh": "LHM：单张图像秒级构建可动画化大型人体重建模型",
      "authors": [
        "Lingteng Qiu",
        "Xiaodong Gu",
        "Peihao Li",
        "Qi Zuo",
        "Weichao Shen",
        "Junfei Zhang",
        "Kejie Qiu",
        "Weihao Yuan",
        "Guanying Chen",
        "Zilong Dong",
        "Liefeng Bo"
      ],
      "abstract": "Animatable 3D human reconstruction from a single image is a challenging\nproblem due to the ambiguity in decoupling geometry, appearance, and\ndeformation. Recent advances in 3D human reconstruction mainly focus on static\nhuman modeling, and the reliance of using synthetic 3D scans for training\nlimits their generalization ability. Conversely, optimization-based video\nmethods achieve higher fidelity but demand controlled capture conditions and\ncomputationally intensive refinement processes. Motivated by the emergence of\nlarge reconstruction models for efficient static reconstruction, we propose LHM\n(Large Animatable Human Reconstruction Model) to infer high-fidelity avatars\nrepresented as 3D Gaussian splatting in a feed-forward pass. Our model\nleverages a multimodal transformer architecture to effectively encode the human\nbody positional features and image features with attention mechanism, enabling\ndetailed preservation of clothing geometry and texture. To further boost the\nface identity preservation and fine detail recovery, we propose a head feature\npyramid encoding scheme to aggregate multi-scale features of the head regions.\nExtensive experiments demonstrate that our LHM generates plausible animatable\nhuman in seconds without post-processing for face and hands, outperforming\nexisting methods in both reconstruction accuracy and generalization ability.",
      "tldr_zh": "该研究提出了LHM（大型可动画人体重建模型），能够从单张图像在数秒内重建高保真的可动画3D人体模型。LHM采用多模态Transformer架构，通过注意力机制有效编码人体姿态特征和图像特征，保留服装几何和纹理细节。此外，引入头部特征金字塔编码方案，增强面部特征保留和细节恢复能力。实验表明，LHM无需后处理即可生成逼真的可动画人体模型，在重建精度和泛化能力上均优于现有方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Project Page: https://lingtengqiu.github.io/LHM/",
      "pdf_url": "http://arxiv.org/pdf/2503.10625v1",
      "published_date": "2025-03-13 17:59:21 UTC",
      "updated_date": "2025-03-13 17:59:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:13:18.266337"
    },
    {
      "arxiv_id": "2503.10624v1",
      "title": "ETCH: Generalizing Body Fitting to Clothed Humans via Equivariant Tightness",
      "title_zh": "ETCH：通过等变紧密度泛化人体拟合至着装人体",
      "authors": [
        "Boqian Li",
        "Haiwen Feng",
        "Zeyu Cai",
        "Michael J. Black",
        "Yuliang Xiu"
      ],
      "abstract": "Fitting a body to a 3D clothed human point cloud is a common yet challenging\ntask. Traditional optimization-based approaches use multi-stage pipelines that\nare sensitive to pose initialization, while recent learning-based methods often\nstruggle with generalization across diverse poses and garment types. We propose\nEquivariant Tightness Fitting for Clothed Humans, or ETCH, a novel pipeline\nthat estimates cloth-to-body surface mapping through locally approximate SE(3)\nequivariance, encoding tightness as displacement vectors from the cloth surface\nto the underlying body. Following this mapping, pose-invariant body features\nregress sparse body markers, simplifying clothed human fitting into an\ninner-body marker fitting task. Extensive experiments on CAPE and 4D-Dress show\nthat ETCH significantly outperforms state-of-the-art methods -- both\ntightness-agnostic and tightness-aware -- in body fitting accuracy on loose\nclothing (16.7% ~ 69.5%) and shape accuracy (average 49.9%). Our equivariant\ntightness design can even reduce directional errors by (67.2% ~ 89.8%) in\none-shot (or out-of-distribution) settings. Qualitative results demonstrate\nstrong generalization of ETCH, regardless of challenging poses, unseen shapes,\nloose clothing, and non-rigid dynamics. We will release the code and models\nsoon for research purposes at https://boqian-li.github.io/ETCH/.",
      "tldr_zh": "该研究提出ETCH（等变紧密度拟合）框架，通过局部SE(3)等变性建立衣物表面到人体表面的映射关系，将紧密度建模为位移向量，从而解决3D穿衣人体点云拟合的难题。该方法创新性地使用姿态不变特征预测稀疏人体标记点，将复杂穿衣人体拟合问题简化为内部标记点拟合任务，在CAPE和4D-Dress数据集上显著优于现有方法，对宽松衣物的拟合精度提升16.7%~69.5%，形状精度平均提高49.9%。特别在一次性/分布外场景中，其等变设计可将方向误差降低67.2%~89.8%，展现出对挑战性姿态、未见体型、宽松衣物和非刚性动态的强泛化能力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR"
      ],
      "primary_category": "cs.CV",
      "comment": "Page: https://boqian-li.github.io/ETCH/, Code:\n  https://github.com/boqian-li/ETCH",
      "pdf_url": "http://arxiv.org/pdf/2503.10624v1",
      "published_date": "2025-03-13 17:59:14 UTC",
      "updated_date": "2025-03-13 17:59:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:13:26.232504"
    },
    {
      "arxiv_id": "2503.10622v1",
      "title": "Transformers without Normalization",
      "title_zh": "无需归一化的Transformer架构",
      "authors": [
        "Jiachen Zhu",
        "Xinlei Chen",
        "Kaiming He",
        "Yann LeCun",
        "Zhuang Liu"
      ],
      "abstract": "Normalization layers are ubiquitous in modern neural networks and have long\nbeen considered essential. This work demonstrates that Transformers without\nnormalization can achieve the same or better performance using a remarkably\nsimple technique. We introduce Dynamic Tanh (DyT), an element-wise operation\n$DyT($x$) = \\tanh(\\alpha $x$)$, as a drop-in replacement for normalization\nlayers in Transformers. DyT is inspired by the observation that layer\nnormalization in Transformers often produces tanh-like, $S$-shaped input-output\nmappings. By incorporating DyT, Transformers without normalization can match or\nexceed the performance of their normalized counterparts, mostly without\nhyperparameter tuning. We validate the effectiveness of Transformers with DyT\nacross diverse settings, ranging from recognition to generation, supervised to\nself-supervised learning, and computer vision to language models. These\nfindings challenge the conventional understanding that normalization layers are\nindispensable in modern neural networks, and offer new insights into their role\nin deep networks.",
      "tldr_zh": "这项研究挑战了神经网络必须依赖归一化层的传统认知，提出了一种名为动态Tanh（DyT）的简单替代方案。该方法通过元素级操作DyT(x) = tanh(αx)取代Transformer中的归一化层，实验证明无需调整超参数即可达到或超越传统归一化模型的性能。研究在从视觉到语言、监督到自监督的多种任务中验证了DyT的有效性，为理解深度网络中归一化层的真正作用提供了新视角。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "CVPR 2025; Project page: https://jiachenzhu.github.io/DyT/",
      "pdf_url": "http://arxiv.org/pdf/2503.10622v1",
      "published_date": "2025-03-13 17:59:06 UTC",
      "updated_date": "2025-03-13 17:59:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:12:23.067452"
    },
    {
      "arxiv_id": "2503.10619v2",
      "title": "Siege: Autonomous Multi-Turn Jailbreaking of Large Language Models with Tree Search",
      "title_zh": "Siege：基于树搜索的大型语言模型多轮自主越狱攻击",
      "authors": [
        "Andy Zhou"
      ],
      "abstract": "We introduce Siege, a multi-turn adversarial framework that models the\ngradual erosion of Large Language Model (LLM) safety through a tree search\nperspective. Unlike single-turn jailbreaks that rely on one meticulously\nengineered prompt, Siege expands the conversation at each turn in a\nbreadth-first fashion, branching out multiple adversarial prompts that exploit\npartial compliance from previous responses. By tracking these incremental\npolicy leaks and re-injecting them into subsequent queries, Siege reveals how\nminor concessions can accumulate into fully disallowed outputs. Evaluations on\nthe JailbreakBench dataset show that Siege achieves a 100% success rate on\nGPT-3.5-turbo and 97% on GPT-4 in a single multi-turn run, using fewer queries\nthan baselines such as Crescendo or GOAT. This tree search methodology offers\nan in-depth view of how model safeguards degrade over successive dialogue\nturns, underscoring the urgency of robust multi-turn testing procedures for\nlanguage models.",
      "tldr_zh": "该论文提出了Siege框架，通过树搜索方法实现大型语言模型(LLM)的多轮越狱攻击。与单轮攻击不同，Siege采用广度优先策略，在每轮对话中生成多个对抗性提示，利用模型的部分合规响应逐步累积安全漏洞。实验显示，该方法在JailbreakBench数据集上对GPT-3.5-turbo实现100%越狱成功率，对GPT-4达97%，且查询次数少于Crescendo和GOAT等基线方法。该研究揭示了LLM安全防护在多轮对话中的渐进式退化机制，强调了开发鲁棒多轮测试方法的紧迫性。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CR"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to ICLR 2025 Trustworthy LLM",
      "pdf_url": "http://arxiv.org/pdf/2503.10619v2",
      "published_date": "2025-03-13 17:57:32 UTC",
      "updated_date": "2025-03-16 20:14:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:13:21.266400"
    },
    {
      "arxiv_id": "2503.10617v2",
      "title": "Compositional Subspace Representation Fine-tuning for Adaptive Large Language Models",
      "title_zh": "组合子空间表征微调：面向自适应大语言模型的优化方法",
      "authors": [
        "Andy Zhou"
      ],
      "abstract": "Adapting large language models to multiple tasks can cause cross-skill\ninterference, where improvements for one skill degrade another. While methods\nsuch as LoRA impose orthogonality constraints at the weight level, they do not\nfully address interference in hidden-state representations. We propose\nCompositional Subspace Representation Fine-tuning (CS-ReFT), a novel\nrepresentation-based approach that learns multiple orthonormal subspace\ntransformations, each specializing in a distinct skill, and composes them via a\nlightweight router. By isolating these subspace edits in the hidden state,\nrather than weight matrices, CS-ReFT prevents cross-task conflicts more\neffectively. On the AlpacaEval benchmark, applying CS-ReFT to Llama-2-7B\nachieves a 93.94% win rate, surpassing GPT-3.5 Turbo (86.30%) while requiring\nonly 0.0098% of model parameters. These findings show that specialized\nrepresentation edits, composed via a simple router, significantly enhance\nmulti-task instruction following with minimal overhead.",
      "tldr_zh": "该研究提出了一种名为CS-ReFT（组合子空间表示微调）的新方法，通过为不同技能学习正交子空间变换，并使用轻量级路由器进行组合，有效解决了大语言模型多任务适应中的技能干扰问题。相比传统权重级方法（如LoRA），CS-ReFT在隐状态层面隔离任务特定修改，在AlpacaEval基准测试中，仅需0.0098%的参数量就使Llama-2-7B模型达到了93.94%的胜率，超越了GPT-3.5 Turbo（86.30%）。该方法展示了通过简单的路由器组合专业化表示编辑，能够以极小开销显著提升多任务指令跟随能力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to ICLR 2025 SCOPE",
      "pdf_url": "http://arxiv.org/pdf/2503.10617v2",
      "published_date": "2025-03-13 17:57:04 UTC",
      "updated_date": "2025-03-16 20:15:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:13:37.776372"
    },
    {
      "arxiv_id": "2503.10745v2",
      "title": "Unifying 2D and 3D Vision-Language Understanding",
      "title_zh": "统一2D与3D视觉语言理解",
      "authors": [
        "Ayush Jain",
        "Alexander Swerdlow",
        "Yuzhou Wang",
        "Sergio Arnaud",
        "Ada Martin",
        "Alexander Sax",
        "Franziska Meier",
        "Katerina Fragkiadaki"
      ],
      "abstract": "Progress in 3D vision-language learning has been hindered by the scarcity of\nlarge-scale 3D datasets. We introduce UniVLG, a unified architecture for 2D and\n3D vision-language understanding that bridges the gap between existing\n2D-centric models and the rich 3D sensory data available in embodied systems.\nOur approach initializes most model weights from pre-trained 2D models and\ntrains on both 2D and 3D vision-language data. We propose a novel\nlanguage-conditioned mask decoder shared across 2D and 3D modalities to ground\nobjects effectively in both RGB and RGB-D images, outperforming box-based\napproaches. To further reduce the domain gap between 2D and 3D, we incorporate\n2D-to-3D lifting strategies, enabling UniVLG to utilize 2D data to enhance 3D\nperformance. With these innovations, our model achieves state-of-the-art\nperformance across multiple 3D vision-language grounding tasks, demonstrating\nthe potential of transferring advances from 2D vision-language learning to the\ndata-constrained 3D domain. Furthermore, co-training on both 2D and 3D data\nenhances performance across modalities without sacrificing 2D capabilities. By\nremoving the reliance on 3D mesh reconstruction and ground-truth object\nproposals, UniVLG sets a new standard for realistic, embodied-aligned\nevaluation. Code and additional visualizations are available at\nhttps://univlg.github.io .",
      "tldr_zh": "该研究提出了UniVLG，一种统一2D和3D视觉语言理解的架构，旨在解决3D领域数据稀缺的问题。通过从预训练的2D模型初始化权重，并结合2D和3D数据进行训练，UniVLG引入了一种跨模态共享的语言条件掩码解码器，显著提升了RGB和RGB-D图像中的对象定位能力。此外，研究采用2D到3D的提升策略，利用2D数据增强3D性能，在多个3D视觉语言任务中实现了最先进的性能，同时不牺牲2D能力。UniVLG为现实场景中的视觉语言理解设定了新标准。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "The first two authors contributed equally",
      "pdf_url": "http://arxiv.org/pdf/2503.10745v2",
      "published_date": "2025-03-13 17:56:22 UTC",
      "updated_date": "2025-03-20 16:24:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:14:01.476904"
    },
    {
      "arxiv_id": "2503.10603v3",
      "title": "Technical Approach for the EMI Challenge in the 8th Affective Behavior Analysis in-the-Wild Competition",
      "title_zh": "第八届野外情感行为分析竞赛中EMI挑战的技术方案",
      "authors": [
        "Jun Yu",
        "Lingsi Zhu",
        "Yanjun Chi",
        "Yunxiang Zhang",
        "Yang Zheng",
        "Yongqi Wang",
        "Xilong Lu"
      ],
      "abstract": "Emotional Mimicry Intensity (EMI) estimation plays a pivotal role in\nunderstanding human social behavior and advancing human-computer interaction.\nThe core challenges lie in dynamic correlation modeling and robust fusion of\nmultimodal temporal signals. To address the limitations of existing\nmethods--insufficient exploitation of cross-modal synergies, sensitivity to\nnoise, and constrained fine-grained alignment capabilities--this paper proposes\na dual-stage cross-modal alignment framework. Stage 1 develops vision-text and\naudio-text contrastive learning networks based on a CLIP architecture,\nachieving preliminary feature-space alignment through modality-decoupled\npre-training. Stage 2 introduces a temporal-aware dynamic fusion module\nintegrating Temporal Convolutional Networks (TCN) and gated bidirectional LSTM\nto capture macro-evolution patterns of facial expressions and local dynamics of\nacoustic features, respectively. A novel quality-guided fusion strategy further\nenables differentiable weight allocation for modality compensation under\nocclusion and noise. Experiments on the Hume-Vidmimic2 dataset demonstrate\nsuperior performance with an average Pearson correlation coefficient of 0.51\nacross six emotion dimensions on the validate set. Remarkably, our method\nachieved 0.68 on the test set, securing runner-up in the EMI Challenge Track of\nthe 8th ABAW (Affective Behavior Analysis in the Wild) Competition, offering a\nnovel pathway for fine-grained emotion analysis in open environments.",
      "tldr_zh": "本文提出了一种双阶段跨模态对齐框架，用于解决情感模仿强度(EMI)估计中的动态关联建模与多模态时序信号融合难题。该框架第一阶段采用基于CLIP架构的视觉-文本和音频-文本对比学习网络实现特征空间初步对齐，第二阶段通过结合时序卷积网络(TCN)和门控双向LSTM的动态融合模块，分别捕捉面部表情的宏观演变模式和声学特征的局部动态特性。实验在Hume-Vidmimic2数据集上取得平均皮尔逊相关系数0.51的优异表现，并在第八届ABAW竞赛EMI挑战赛测试集上达到0.68，获得亚军成绩。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10603v3",
      "published_date": "2025-03-13 17:46:16 UTC",
      "updated_date": "2025-03-25 08:46:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:14:12.572232"
    },
    {
      "arxiv_id": "2503.10602v2",
      "title": "TruthPrInt: Mitigating LVLM Object Hallucination Via Latent Truthful-Guided Pre-Intervention",
      "title_zh": "TruthPrInt：通过潜在真实性引导预干预缓解大型视觉语言模型的对象幻觉",
      "authors": [
        "Jinhao Duan",
        "Fei Kong",
        "Hao Cheng",
        "James Diffenderfer",
        "Bhavya Kailkhura",
        "Lichao Sun",
        "Xiaofeng Zhu",
        "Xiaoshuang Shi",
        "Kaidi Xu"
      ],
      "abstract": "Object Hallucination (OH) has been acknowledged as one of the major\ntrustworthy challenges in Large Vision-Language Models (LVLMs). Recent\nadvancements in Large Language Models (LLMs) indicate that internal states,\nsuch as hidden states, encode the \"overall truthfulness\" of generated\nresponses. However, it remains under-explored how internal states in LVLMs\nfunction and whether they could serve as \"per-token\" hallucination indicators,\nwhich is essential for mitigating OH. In this paper, we first conduct an\nin-depth exploration of LVLM internal states in relation to OH issues and\ndiscover that (1) LVLM internal states are high-specificity per-token\nindicators of hallucination behaviors. Moreover, (2) different LVLMs encode\nuniversal patterns of hallucinations in common latent subspaces, indicating\nthat there exist \"generic truthful directions\" shared by various LVLMs. Based\non these discoveries, we propose Truthful-Guided Pre-Intervention (TruthPrInt)\nthat first learns the truthful direction of LVLM decoding and then applies\ntruthful-guided inference-time intervention during LVLM decoding. We further\npropose ComnHallu to enhance both cross-LVLM and cross-data hallucination\ndetection transferability by constructing and aligning hallucination latent\nsubspaces. We evaluate TruthPrInt in extensive experimental settings, including\nin-domain and out-of-domain scenarios, over popular LVLMs and OH benchmarks.\nExperimental results indicate that TruthPrInt significantly outperforms\nstate-of-the-art methods. Codes will be available at\nhttps://github.com/jinhaoduan/TruthPrInt.",
      "tldr_zh": "该论文提出 **TruthPrInt** 方法，通过潜在真实导向预干预（Latent Truthful-Guided Pre-Intervention）缓解大型视觉语言模型（LVLM）中的物体幻觉（Object Hallucination, OH）问题。研究发现：（1）LVLM 内部状态可作为高特异性的逐 token 幻觉指标；（2）不同 LVLM 在公共潜在子空间中编码了通用的幻觉模式，表明存在共享的“真实方向”。基于此，TruthPrInt 通过学习 LVLM 解码的真实方向，在推理时进行干预，并结合 **ComnHallu** 方法提升跨模型和跨数据的幻觉检测可迁移性。实验表明，该方法在多个 LVLM 和 OH 基准测试中显著优于现有技术。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "15 pages, 9 figures, the first two authors contributed equally",
      "pdf_url": "http://arxiv.org/pdf/2503.10602v2",
      "published_date": "2025-03-13 17:46:06 UTC",
      "updated_date": "2025-03-21 15:58:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:15:16.973603"
    },
    {
      "arxiv_id": "2503.10741v1",
      "title": "Predicting Treatment Response in Body Dysmorphic Disorder with Interpretable Machine Learning",
      "title_zh": "《利用可解释性机器学习预测躯体变形障碍的治疗反应》",
      "authors": [
        "Omar Costilla-Reyes",
        "Morgan Talbot"
      ],
      "abstract": "Body Dysmorphic Disorder (BDD) is a highly prevalent and frequently\nunderdiagnosed condition characterized by persistent, intrusive preoccupations\nwith perceived defects in physical appearance. In this extended analysis, we\nemploy multiple machine learning approaches to predict treatment outcomes --\nspecifically treatment response and remission -- with an emphasis on\ninterpretability to ensure clinical relevance and utility. Across the various\nmodels investigated, treatment credibility emerged as the most potent\npredictor, surpassing traditional markers such as baseline symptom severity or\ncomorbid conditions. Notably, while simpler models (e.g., logistic regression\nand support vector machines) achieved competitive predictive performance,\ndecision tree analyses provided unique insights by revealing clinically\ninterpretable threshold values in credibility scores. These thresholds can\nserve as practical guideposts for clinicians when tailoring interventions or\nallocating treatment resources. We further contextualize our findings within\nthe broader literature on BDD, addressing technology-based therapeutics,\ndigital interventions, and the psychosocial determinants of treatment\nengagement. An extensive array of references situates our results within\ncurrent research on BDD prevalence, suicidality risks, and digital innovation.\nOur work underscores the potential of integrating rigorous statistical\nmethodologies with transparent machine learning models. By systematically\nidentifying modifiable predictors -- such as treatment credibility -- we\npropose a pathway toward more targeted, personalized, and ultimately\nefficacious interventions for individuals with BDD.",
      "tldr_zh": "本研究采用可解释机器学习方法预测躯体变形障碍（BDD）的治疗反应。研究发现，在所有预测因子中，治疗可信度（treatment credibility）是最强预测指标，其预测效力超过基线症状严重程度等传统指标。决策树分析揭示了可信度评分的临床可解释阈值，为临床干预提供实用指导。研究强调将严谨统计方法与透明机器学习模型相结合，通过识别可修正预测因子（如治疗可信度），为BDD患者开发更有针对性的个性化治疗方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10741v1",
      "published_date": "2025-03-13 17:39:10 UTC",
      "updated_date": "2025-03-13 17:39:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:14:19.913790"
    },
    {
      "arxiv_id": "2503.10587v1",
      "title": "The Spectral Bias of Shallow Neural Network Learning is Shaped by the Choice of Non-linearity",
      "title_zh": "浅层神经网络学习的光谱偏置由非线性激活函数的选择决定",
      "authors": [
        "Justin Sahs",
        "Ryan Pyle",
        "Fabio Anselmi",
        "Ankit Patel"
      ],
      "abstract": "Despite classical statistical theory predicting severe overfitting, modern\nmassively overparameterized neural networks still generalize well. This\nunexpected property is attributed to the network's so-called implicit bias,\nwhich describes its propensity to converge to solutions that generalize\neffectively, among the many possible that correctly label the training data.\nThe aim of our research is to explore this bias from a new perspective,\nfocusing on how non-linear activation functions contribute to shaping it.\nFirst, we introduce a reparameterization which removes a continuous weight\nrescaling symmetry. Second, in the kernel regime, we leverage this\nreparameterization to generalize recent findings that relate shallow Neural\nNetworks to the Radon transform, deriving an explicit formula for the implicit\nbias induced by a broad class of activation functions. Specifically, by\nutilizing the connection between the Radon transform and the Fourier transform,\nwe interpret the kernel regime's inductive bias as minimizing a spectral\nseminorm that penalizes high-frequency components, in a manner dependent on the\nactivation function. Finally, in the adaptive regime, we demonstrate the\nexistence of local dynamical attractors that facilitate the formation of\nclusters of hyperplanes where the input to a neuron's activation function is\nzero, yielding alignment between many neurons' response functions. We confirm\nthese theoretical results with simulations. All together, our work provides a\ndeeper understanding of the mechanisms underlying the generalization\ncapabilities of overparameterized neural networks and its relation with the\nimplicit bias, offering potential pathways for designing more efficient and\nrobust models.",
      "tldr_zh": "本研究探讨了浅层神经网络学习中的光谱偏差，重点分析了非线性激活函数对其形成的影响。通过引入重参数化消除权重缩放对称性，研究在核机制下推导了激活函数诱导的隐式偏差的显式公式，并将其解释为最小化惩罚高频成分的光谱半范数。在自适应机制下，研究证明了局部动力学吸引子的存在，促进了神经元激活函数输入为零的超平面簇的形成，从而实现了神经元响应函数的对齐。通过模拟验证了理论结果，为理解过参数化神经网络的泛化能力及其与隐式偏差的关系提供了新的视角，为设计更高效、更稳健的模型提供了潜在途径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "18 pages, 10 figures in main text",
      "pdf_url": "http://arxiv.org/pdf/2503.10587v1",
      "published_date": "2025-03-13 17:36:46 UTC",
      "updated_date": "2025-03-13 17:36:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:14:41.367716"
    },
    {
      "arxiv_id": "2503.10582v2",
      "title": "VisualWebInstruct: Scaling up Multimodal Instruction Data through Web Search",
      "title_zh": "VisualWebInstruct：基于网络搜索扩展多模态指令数据规模",
      "authors": [
        "Yiming Jia",
        "Jiachen Li",
        "Xiang Yue",
        "Bo Li",
        "Ping Nie",
        "Kai Zou",
        "Wenhu Chen"
      ],
      "abstract": "Vision-Language Models have made significant progress on many\nperception-focused tasks. However, their progress on reasoning-focused tasks\nremains limited due to the lack of high-quality and diverse training data. In\nthis work, we aim to address the scarcity of reasoning-focused multimodal\ndatasets. We propose VisualWebInstruct, a novel approach that leverages search\nengines to create a diverse and high-quality dataset spanning multiple\ndisciplines, including mathematics, physics, finance, and chemistry, etc.\nStarting with a meticulously selected set of 30,000 seed images, we employ\nGoogle Image Search to identify websites containing similar images. We collect\nand process HTML data from over 700K unique URLs. Through a pipeline of content\nextraction, filtering, and synthesis, we construct a dataset of approximately\n900K question-answer (QA) pairs, with 40% consisting of visual QA pairs and the\nremaining comprising text-based QA pairs. Models fine-tuned on\nVisualWebInstruct demonstrate significant performance improvements: (1)\nfine-tuning on Llava-OV results in 10-20 absolute points improvement across\nbenchmarks, and (2) fine-tuning from MAmmoTH-VL yields a 5 absolute points gain\nacross benchmarks. Our best model, MAmmoTH-VL2, achieves state-of-the-art\nperformance within the 10B parameter class on MMMU-Pro (40.7), MathVerse\n(42.6), and DynaMath (55.7). These results highlight the effectiveness of our\ndataset in enhancing the reasoning capabilities of vision-language models for\ncomplex multimodal tasks.",
      "tldr_zh": "该研究提出了VisualWebInstruct，一种通过网页搜索扩展多模态指令数据的新方法，以解决视觉语言模型(VLMs)在推理任务上训练数据不足的问题。研究利用Google Image搜索构建了一个跨学科的高质量数据集，包含约90万条问答对，其中40%为视觉问答对。实验表明，基于该数据集微调的模型在多个基准测试中表现显著提升，MAmmoTH-VL2模型在10B参数级别上达到了MMMU-Pro、MathVerse和DynaMath的最优性能，验证了该数据在增强复杂多模态任务推理能力方面的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "Technical Report",
      "pdf_url": "http://arxiv.org/pdf/2503.10582v2",
      "published_date": "2025-03-13 17:32:48 UTC",
      "updated_date": "2025-03-15 01:09:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:14:40.443080"
    },
    {
      "arxiv_id": "2503.10546v1",
      "title": "KUDA: Keypoints to Unify Dynamics Learning and Visual Prompting for Open-Vocabulary Robotic Manipulation",
      "title_zh": "KUDA：通过关键点统一动态学习与视觉提示的开放词汇机器人操作",
      "authors": [
        "Zixian Liu",
        "Mingtong Zhang",
        "Yunzhu Li"
      ],
      "abstract": "With the rapid advancement of large language models (LLMs) and\nvision-language models (VLMs), significant progress has been made in developing\nopen-vocabulary robotic manipulation systems. However, many existing approaches\noverlook the importance of object dynamics, limiting their applicability to\nmore complex, dynamic tasks. In this work, we introduce KUDA, an\nopen-vocabulary manipulation system that integrates dynamics learning and\nvisual prompting through keypoints, leveraging both VLMs and learning-based\nneural dynamics models. Our key insight is that a keypoint-based target\nspecification is simultaneously interpretable by VLMs and can be efficiently\ntranslated into cost functions for model-based planning. Given language\ninstructions and visual observations, KUDA first assigns keypoints to the RGB\nimage and queries the VLM to generate target specifications. These abstract\nkeypoint-based representations are then converted into cost functions, which\nare optimized using a learned dynamics model to produce robotic trajectories.\nWe evaluate KUDA on a range of manipulation tasks, including free-form language\ninstructions across diverse object categories, multi-object interactions, and\ndeformable or granular objects, demonstrating the effectiveness of our\nframework. The project page is available at http://kuda-dynamics.github.io.",
      "tldr_zh": "本研究提出了KUDA系统，通过关键点(keypoints)统一动态学习和视觉提示，实现了开放词汇的机器人操作。KUDA结合视觉语言模型(VLMs)和基于学习的神经动态模型，将关键点作为目标规范，既可由VLMs解释，又能高效转化为基于模型的规划成本函数。系统根据语言指令和视觉观察，先为RGB图像分配关键点并查询VLM生成目标规范，再将这些抽象表示转化为成本函数，利用学习到的动态模型优化生成机器人轨迹。实验表明，KUDA在多种操作任务上表现优异，包括跨类别自由语言指令、多物体交互以及可变形或颗粒物体操作。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Project website: http://kuda-dynamics.github.io",
      "pdf_url": "http://arxiv.org/pdf/2503.10546v1",
      "published_date": "2025-03-13 16:59:17 UTC",
      "updated_date": "2025-03-13 16:59:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:14:48.661156"
    },
    {
      "arxiv_id": "2503.10542v1",
      "title": "Language Models, Graph Searching, and Supervision Adulteration: When More Supervision is Less and How to Make More More",
      "title_zh": "语言模型、图搜索与监督掺假：当更多监督反而更少时如何实现真正增益",
      "authors": [
        "Arvid Frydenlund"
      ],
      "abstract": "This work concerns the path-star task, a minimal example of searching over a\ngraph. The graph, $G$, is star-shaped with $D$ arms radiating from a start\nnode, $s$. A language model (LM) is given $G$, $s$, and a target node $t$,\nwhich ends one of the arms and is tasked with generating the arm containing\n$t$. The minimal nature of this task means only a single choice needs to be\nmade: which of the $D$ arms contains $t$?\n  Decoder-only LMs fail to solve this elementary task above $1/D$ chance due to\na learned shortcut that absorbs training supervision. We show how this\npathology is caused by excess supervision and we present a series of solutions\ndemonstrating that the task is solvable via decoder-only LMs. We find that the\ntask's minimal nature causes its difficulty, as it prevents task decomposition.\nOur solutions provide insight into the pathology and its implications for LMs\ntrained via next-token prediction.",
      "tldr_zh": "这篇论文研究了语言模型在图搜索任务中的表现问题，重点关注\"路径星形任务\"这一最小化图搜索案例。研究发现，仅解码器语言模型(LMs)在该任务上表现不佳（仅能达到1/D的随机猜测水平），原因是训练过程中的过度监督导致了\"学习捷径\"问题。作者通过分析表明，该任务的极小特性阻碍了任务分解，并提出了系列解决方案证明仅解码器模型也能解决这一问题。这项研究揭示了基于下一词预测训练的语言模型存在的固有病理现象及其影响。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "I.2.7; I.2.8; I.5.0"
      ],
      "primary_category": "cs.LG",
      "comment": "A reduced version of this work has been accepted to the Workshop on\n  Spurious Correlation and Shortcut Learning: Foundations and Solutions (SCSL)\n  at ICLR 2025. Full version under review",
      "pdf_url": "http://arxiv.org/pdf/2503.10542v1",
      "published_date": "2025-03-13 16:56:47 UTC",
      "updated_date": "2025-03-13 16:56:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:15:09.280340"
    },
    {
      "arxiv_id": "2503.10539v1",
      "title": "GBSVR: Granular Ball Support Vector Regression",
      "title_zh": "GBSVR：基于粒球的支撑向量回归方法",
      "authors": [
        "Reshma Rastogi",
        "Ankush Bisht",
        "Sanjay Kumar",
        "Suresh Chandra"
      ],
      "abstract": "Support Vector Regression (SVR) and its variants are widely used to handle\nregression tasks, however, since their solution involves solving an expensive\nquadratic programming problem, it limits its application, especially when\ndealing with large datasets. Additionally, SVR uses an epsilon-insensitive loss\nfunction which is sensitive to outliers and therefore can adversely affect its\nperformance. We propose Granular Ball Support Vector Regression (GBSVR) to\ntackle problem of regression by using granular ball concept. These balls are\nuseful in simplifying complex data spaces for machine learning tasks, however,\nto the best of our knowledge, they have not been sufficiently explored for\nregression problems. Granular balls group the data points into balls based on\ntheir proximity and reduce the computational cost in SVR by replacing the large\nnumber of data points with far fewer granular balls. This work also suggests a\ndiscretization method for continuous-valued attributes to facilitate the\nconstruction of granular balls. The effectiveness of the proposed approach is\nevaluated on several benchmark datasets and it outperforms existing\nstate-of-the-art approaches",
      "tldr_zh": "该研究提出了Granular Ball Support Vector Regression (GBSVR)，一种基于粒度球（Granular Ball）概念的支持向量回归方法，旨在解决传统SVR在处理大规模数据时计算成本高、对异常值敏感的问题。GBSVR通过将数据点分组为粒度球，显著减少了计算复杂度，并提出了一种连续值属性的离散化方法以辅助粒度球的构建。实验结果表明，GBSVR在多个基准数据集上优于现有的先进方法，为回归任务提供了一种高效且鲁棒的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10539v1",
      "published_date": "2025-03-13 16:52:43 UTC",
      "updated_date": "2025-03-13 16:52:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:14:58.918898"
    },
    {
      "arxiv_id": "2503.10533v1",
      "title": "The Impact of Item-Writing Flaws on Difficulty and Discrimination in Item Response Theory",
      "title_zh": "项目编写缺陷对项目反应理论中难度与区分度的影响",
      "authors": [
        "Robin Schmucker",
        "Steven Moore"
      ],
      "abstract": "High-quality test items are essential for educational assessments,\nparticularly within Item Response Theory (IRT). Traditional validation methods\nrely on resource-intensive pilot testing to estimate item difficulty and\ndiscrimination. More recently, Item-Writing Flaw (IWF) rubrics emerged as a\ndomain-general approach for evaluating test items based on textual features.\nHowever, their relationship to IRT parameters remains underexplored. To address\nthis gap, we conducted a study involving over 7,000 multiple-choice questions\nacross various STEM subjects (e.g., math and biology). Using an automated\napproach, we annotated each question with a 19-criteria IWF rubric and studied\nrelationships to data-driven IRT parameters. Our analysis revealed\nstatistically significant links between the number of IWFs and IRT difficulty\nand discrimination parameters, particularly in life and physical science\ndomains. We further observed how specific IWF criteria can impact item quality\nmore and less severely (e.g., negative wording vs. implausible distractors).\nOverall, while IWFs are useful for predicting IRT parameters--particularly for\nscreening low-difficulty MCQs--they cannot replace traditional data-driven\nvalidation methods. Our findings highlight the need for further research on\ndomain-general evaluation rubrics and algorithms that understand\ndomain-specific content for robust item validation.",
      "tldr_zh": "本研究探讨了题目编写缺陷(Item-Writing Flaws)对项目反应理论(IRT)中题目难度和区分度的影响。通过对7,000多道STEM领域选择题进行自动化标注分析，发现题目缺陷数量与IRT参数存在显著相关性，尤其在生命科学和物理科学领域表现明显。研究揭示不同缺陷类型对题目质量影响程度各异(如否定表述比不合理干扰项影响更大)，表明虽然题目缺陷评估工具有一定预测价值(特别适合筛选低难度选择题)，但仍无法替代传统基于数据的验证方法。该成果强调了开发既能理解领域知识又具备通用性的题目评估工具的重要性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10533v1",
      "published_date": "2025-03-13 16:47:07 UTC",
      "updated_date": "2025-03-13 16:47:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:15:09.448084"
    },
    {
      "arxiv_id": "2503.10530v2",
      "title": "Lightweight Models for Emotional Analysis in Video",
      "title_zh": "视频情感分析的轻量化模型",
      "authors": [
        "Quoc-Tien Nguyen",
        "Hong-Hai Nguyen",
        "Van-Thong Huynh"
      ],
      "abstract": "In this study, we present an approach for efficient spatiotemporal feature\nextraction using MobileNetV4 and a multi-scale 3D MLP-Mixer-based temporal\naggregation module. MobileNetV4, with its Universal Inverted Bottleneck (UIB)\nblocks, serves as the backbone for extracting hierarchical feature\nrepresentations from input image sequences, ensuring both computational\nefficiency and rich semantic encoding. To capture temporal dependencies, we\nintroduce a three-level MLP-Mixer module, which processes spatial features at\nmultiple resolutions while maintaining structural integrity. Experimental\nresults on the ABAW 8th competition demonstrate the effectiveness of our\napproach, showing promising performance in affective behavior analysis. By\nintegrating an efficient vision backbone with a structured temporal modeling\nmechanism, the proposed framework achieves a balance between computational\nefficiency and predictive accuracy, making it well-suited for real-time\napplications in mobile and embedded computing environments.",
      "tldr_zh": "本研究提出了一种轻量级视频情感分析方法，结合MobileNetV4骨干网络和多尺度3D MLP-Mixer时序聚合模块。通过Universal Inverted Bottleneck (UIB)块提取层次化特征，并采用三级MLP-Mixer模块处理多分辨率时空特征，在保持计算效率的同时实现有效的情感行为分析。在ABAW竞赛中验证了该框架的优越性，为移动端实时情感计算提供了高效解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "https://github.com/PRVSL/abaw-8th",
      "pdf_url": "http://arxiv.org/pdf/2503.10530v2",
      "published_date": "2025-03-13 16:38:33 UTC",
      "updated_date": "2025-03-25 03:50:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:16:31.582054"
    },
    {
      "arxiv_id": "2503.10529v1",
      "title": "PiSA: A Self-Augmented Data Engine and Training Strategy for 3D Understanding with Large Models",
      "title_zh": "PiSA：面向大型模型三维理解的自增强数据引擎与训练策略",
      "authors": [
        "Zilu Guo",
        "Hongbin Lin",
        "Zhihao Yuan",
        "Chaoda Zheng",
        "Pengshuo Qiu",
        "Dongzhi Jiang",
        "Renrui Zhang",
        "Chun-Mei Feng",
        "Zhen Li"
      ],
      "abstract": "3D Multimodal Large Language Models (MLLMs) have recently made substantial\nadvancements. However, their potential remains untapped, primarily due to the\nlimited quantity and suboptimal quality of 3D datasets. Current approaches\nattempt to transfer knowledge from 2D MLLMs to expand 3D instruction data, but\nstill face modality and domain gaps. To this end, we introduce PiSA-Engine\n(Point-Self-Augmented-Engine), a new framework for generating instruction\npoint-language datasets enriched with 3D spatial semantics. We observe that\nexisting 3D MLLMs offer a comprehensive understanding of point clouds for\nannotation, while 2D MLLMs excel at cross-validation by providing complementary\ninformation. By integrating holistic 2D and 3D insights from off-the-shelf\nMLLMs, PiSA-Engine enables a continuous cycle of high-quality data generation.\nWe select PointLLM as the baseline and adopt this co-evolution training\nframework to develop an enhanced 3D MLLM, termed PointLLM-PiSA. Additionally,\nwe identify limitations in previous 3D benchmarks, which often feature coarse\nlanguage captions and insufficient category diversity, resulting in inaccurate\nevaluations. To address this gap, we further introduce PiSA-Bench, a\ncomprehensive 3D benchmark covering six key aspects with detailed and diverse\nlabels. Experimental results demonstrate PointLLM-PiSA's state-of-the-art\nperformance in zero-shot 3D object captioning and generative classification on\nour PiSA-Bench, achieving significant improvements of 46.45% (+8.33%) and\n63.75% (+16.25%), respectively. We will release the code, datasets, and\nbenchmark.",
      "tldr_zh": "本文提出了PiSA-Engine框架，通过整合现成的2D和3D多模态大语言模型(MLLMs)的优势，构建了一个能自动生成富含3D空间语义指令数据的自增强系统。该研究开发了PointLLM-PiSA模型，采用协同进化训练策略，在零样本3D物体描述和生成分类任务上分别取得46.45%和63.75%的SOTA性能。同时针对现有3D基准测试的不足，作者还提出了涵盖6个关键维度、具有精细标注的PiSA-Bench评估体系。这项工作通过创新的数据引擎和训练方法，显著推进了3D多模态理解的发展。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Technical Report",
      "pdf_url": "http://arxiv.org/pdf/2503.10529v1",
      "published_date": "2025-03-13 16:37:26 UTC",
      "updated_date": "2025-03-13 16:37:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:15:40.291767"
    },
    {
      "arxiv_id": "2503.10520v1",
      "title": "CountPath: Automating Fragment Counting in Digital Pathology",
      "title_zh": "CountPath：数字化病理学中自动化碎片计数",
      "authors": [
        "Ana Beatriz Vieira",
        "Maria Valente",
        "Diana Montezuma",
        "Tomé Albuquerque",
        "Liliana Ribeiro",
        "Domingos Oliveira",
        "João Monteiro",
        "Sofia Gonçalves",
        "Isabel M. Pinto",
        "Jaime S. Cardoso",
        "Arlindo L. Oliveira"
      ],
      "abstract": "Quality control of medical images is a critical component of digital\npathology, ensuring that diagnostic images meet required standards. A\npre-analytical task within this process is the verification of the number of\nspecimen fragments, a process that ensures that the number of fragments on a\nslide matches the number documented in the macroscopic report. This step is\nimportant to ensure that the slides contain the appropriate diagnostic material\nfrom the grossing process, thereby guaranteeing the accuracy of subsequent\nmicroscopic examination and diagnosis. Traditionally, this assessment is\nperformed manually, requiring significant time and effort while being subject\nto significant variability due to its subjective nature. To address these\nchallenges, this study explores an automated approach to fragment counting\nusing the YOLOv9 and Vision Transformer models. Our results demonstrate that\nthe automated system achieves a level of performance comparable to expert\nassessments, offering a reliable and efficient alternative to manual counting.\nAdditionally, we present findings on interobserver variability, showing that\nthe automated approach achieves an accuracy of 86%, which falls within the\nrange of variation observed among experts (82-88%), further supporting its\npotential for integration into routine pathology workflows.",
      "tldr_zh": "该研究提出CountPath系统，利用YOLOv9和Vision Transformer模型实现数字病理学中组织切片碎片计数的自动化。实验表明，该系统准确率达86%，与病理专家人工计数的变异范围（82-88%）相当，为病理工作流程提供了高效可靠的替代方案。该技术解决了传统人工计数耗时且存在主观差异的问题，有助于提升病理诊断前质量控制效率。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "I.2; I.4"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.10520v1",
      "published_date": "2025-03-13 16:29:16 UTC",
      "updated_date": "2025-03-13 16:29:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:16:27.751445"
    },
    {
      "arxiv_id": "2503.10518v1",
      "title": "Why the Brain Cannot Be a Digital Computer: History-Dependence and the Computational Limits of Consciousness",
      "title_zh": "为何大脑无法成为数字计算机：历史依赖性与意识的计算极限",
      "authors": [
        "Andrew Knight"
      ],
      "abstract": "This paper presents a novel information-theoretic proof demonstrating that\nthe human brain as currently understood cannot function as a classical digital\ncomputer. Through systematic quantification of distinguishable conscious states\nand their historical dependencies, we establish that the minimum information\nrequired to specify a conscious state exceeds the physical information capacity\nof the human brain by a significant factor. Our analysis calculates the\nbit-length requirements for representing consciously distinguishable sensory\n\"stimulus frames\" and demonstrates that consciousness exhibits mandatory\ntemporal-historical dependencies that multiply these requirements beyond the\nbrain's storage capabilities. This mathematical approach offers new insights\ninto the fundamental limitations of computational models of consciousness and\nsuggests that non-classical information processing mechanisms may be necessary\nto account for conscious experience.",
      "tldr_zh": "这篇论文通过信息论方法证明人类大脑无法作为经典数字计算机运作。研究量化了可区分的意识状态及其历史依赖性，发现表征单个意识状态所需的最小信息量远超大脑物理信息容量。分析表明，意识具有强制性的时间-历史依赖性，这使得信息存储需求倍增，超出大脑能力范围。该研究为意识计算模型提出了根本性限制，暗示可能需要非经典信息处理机制来解释意识体验。",
      "categories": [
        "physics.hist-ph",
        "cs.AI",
        "q-bio.NC"
      ],
      "primary_category": "physics.hist-ph",
      "comment": "10 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2503.10518v1",
      "published_date": "2025-03-13 16:27:42 UTC",
      "updated_date": "2025-03-13 16:27:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:15:59.958945"
    },
    {
      "arxiv_id": "2503.11718v1",
      "title": "The Relativity of Causal Knowledge",
      "title_zh": "因果知识的相对性",
      "authors": [
        "Gabriele D'Acunto",
        "Claudio Battiloro"
      ],
      "abstract": "Recent advances in artificial intelligence reveal the limits of purely\npredictive systems and call for a shift toward causal and collaborative\nreasoning. Drawing inspiration from the revolution of Grothendieck in\nmathematics, we introduce the relativity of causal knowledge, which posits\nstructural causal models (SCMs) are inherently imperfect, subjective\nrepresentations embedded within networks of relationships. By leveraging\ncategory theory, we arrange SCMs into a functor category and show that their\nobservational and interventional probability measures naturally form convex\nstructures. This result allows us to encode non-intervened SCMs with convex\nspaces of probability measures. Next, using sheaf theory, we construct the\nnetwork sheaf and cosheaf of causal knowledge. These structures enable the\ntransfer of causal knowledge across the network while incorporating\ninterventional consistency and the perspective of the subjects, ultimately\nleading to the formal, mathematical definition of relative causal knowledge.",
      "tldr_zh": "该论文提出了因果知识的相对性理论，认为结构因果模型(SCMs)本质上是嵌入关系网络中的不完美、主观表示。研究利用范畴论将SCMs组织为函子范畴，并证明其观测和干预概率测度自然形成凸结构。通过层理论，构建了因果知识的网络层和共层结构，实现了因果知识在跨网络传递中的干预一致性和主体视角的整合，最终给出了相对因果知识的正式数学定义。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "math.CT",
        "stat.ME"
      ],
      "primary_category": "cs.AI",
      "comment": "14 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.11718v1",
      "published_date": "2025-03-13 16:24:48 UTC",
      "updated_date": "2025-03-13 16:24:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:17:08.327306"
    },
    {
      "arxiv_id": "2503.10512v1",
      "title": "Conformal Prediction Sets for Deep Generative Models via Reduction to Conformal Regression",
      "title_zh": "基于降维至保形回归的深度生成模型保形预测集",
      "authors": [
        "Hooman Shahrokhi",
        "Devjeet Raj Roy",
        "Yan Yan",
        "Venera Arnaoudova",
        "Janaradhan Rao Doppa"
      ],
      "abstract": "We consider the problem of generating valid and small prediction sets by\nsampling outputs (e.g., software code and natural language text) from a\nblack-box deep generative model for a given input (e.g., textual prompt). The\nvalidity of a prediction set is determined by a user-defined binary\nadmissibility function depending on the target application. For example,\nrequiring at least one program in the set to pass all test cases in code\ngeneration application. To address this problem, we develop a simple and\neffective conformal inference algorithm referred to as Generative Prediction\nSets (GPS). Given a set of calibration examples and black-box access to a deep\ngenerative model, GPS can generate prediction sets with provable guarantees.\nThe key insight behind GPS is to exploit the inherent structure within the\ndistribution over the minimum number of samples needed to obtain an admissible\noutput to develop a simple conformal regression approach over the minimum\nnumber of samples. Experiments on multiple datasets for code and math word\nproblems using different large language models demonstrate the efficacy of GPS\nover state-of-the-art methods.",
      "tldr_zh": "本文提出了一种名为生成预测集(GPS)的简单高效共形推理算法，用于解决深度生成模型输出预测集的效度验证问题。该算法通过分析获得合格输出所需最小样本数的分布特性，创新性地将其转化为共形回归问题，从而能为给定输入生成具有理论保证的预测集。实验表明，在代码生成和数学应用题等任务中，GPS算法相比现有方法能产生更小且有效的预测集，为大型语言模型等深度生成模型提供了可靠的置信度评估框架。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10512v1",
      "published_date": "2025-03-13 16:16:23 UTC",
      "updated_date": "2025-03-13 16:16:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:17:07.605183"
    },
    {
      "arxiv_id": "2503.10737v1",
      "title": "Commenting Higher-level Code Unit: Full Code, Reduced Code, or Hierarchical Code Summarization",
      "title_zh": "高层次代码单元注释：完整代码、精简代码还是分层代码摘要",
      "authors": [
        "Weisong Sun",
        "Yiran Zhang",
        "Jie Zhu",
        "Zhihui Wang",
        "Chunrong Fang",
        "Yonglong Zhang",
        "Yebo Feng",
        "Jiangping Huang",
        "Xingya Wang",
        "Zhi Jin",
        "Yang Liu"
      ],
      "abstract": "Commenting code is a crucial activity in software development, as it aids in\nfacilitating future maintenance and updates. To enhance the efficiency of\nwriting comments and reduce developers' workload, researchers has proposed\nvarious automated code summarization (ACS) techniques to automatically generate\ncomments/summaries for given code units. However, these ACS techniques\nprimarily focus on generating summaries for code units at the method level.\nThere is a significant lack of research on summarizing higher-level code units,\nsuch as file-level and module-level code units, despite the fact that summaries\nof these higher-level code units are highly useful for quickly gaining a\nmacro-level understanding of software components and architecture. To fill this\ngap, in this paper, we conduct a systematic study on how to use LLMs for\ncommenting higher-level code units, including file level and module level.\nThese higher-level units are significantly larger than method-level ones, which\nposes challenges in handling long code inputs within LLM constraints and\nmaintaining efficiency. To address these issues, we explore various\nsummarization strategies for ACS of higher-level code units, which can be\ndivided into three types: full code summarization, reduced code summarization,\nand hierarchical code summarization. The experimental results suggest that for\nsummarizing file-level code units, using the full code is the most effective\napproach, with reduced code serving as a cost-efficient alternative. However,\nfor summarizing module-level code units, hierarchical code summarization\nbecomes the most promising strategy. In addition, inspired by the research on\nmethod-level ACS, we also investigate using the LLM as an evaluator to evaluate\nthe quality of summaries of higher-level code units. The experimental results\ndemonstrate that the LLM's evaluation results strongly correlate with human\nevaluations.",
      "tldr_zh": "该研究系统探讨了如何使用大语言模型(LLMs)为文件级和模块级的高层次代码单元生成注释，填补了现有自动代码摘要(ACS)技术主要关注方法级代码的空白。针对高层次代码单元规模较大的特点，研究提出了三种摘要策略：完整代码摘要、精简代码摘要和分层代码摘要。实验表明，文件级代码适合使用完整代码摘要，而模块级代码则更适合分层代码摘要。此外，研究还验证了LLM作为评估者，其评估结果与人工评估具有强相关性。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "68-04",
        "D.2.3; I.2.7"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10737v1",
      "published_date": "2025-03-13 16:15:06 UTC",
      "updated_date": "2025-03-13 16:15:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:16:58.062578"
    },
    {
      "arxiv_id": "2503.10496v1",
      "title": "Explainable Bayesian deep learning through input-skip Latent Binary Bayesian Neural Networks",
      "title_zh": "可解释贝叶斯深度学习：基于输入跳跃式潜在二元贝叶斯神经网络",
      "authors": [
        "Eirik Høyheim",
        "Lars Skaaret-Lund",
        "Solve Sæbø",
        "Aliaksandr Hubin"
      ],
      "abstract": "Modeling natural phenomena with artificial neural networks (ANNs) often\nprovides highly accurate predictions. However, ANNs often suffer from\nover-parameterization, complicating interpretation and raising uncertainty\nissues. Bayesian neural networks (BNNs) address the latter by representing\nweights as probability distributions, allowing for predictive uncertainty\nevaluation. Latent binary Bayesian neural networks (LBBNNs) further handle\nstructural uncertainty and sparsify models by removing redundant weights. This\narticle advances LBBNNs by enabling covariates to skip to any succeeding layer\nor be excluded, simplifying networks and clarifying input impacts on\npredictions. Ultimately, a linear model or even a constant can be found to be\noptimal for a specific problem at hand. Furthermore, the input-skip LBBNN\napproach reduces network density significantly compared to standard LBBNNs,\nachieving over 99% reduction for small networks and over 99.9% for larger ones,\nwhile still maintaining high predictive accuracy and uncertainty measurement.\nFor example, on MNIST, we reached 97% accuracy and great calibration with just\n935 weights, reaching state-of-the-art for compression of neural networks.\nFurthermore, the proposed method accurately identifies the true covariates and\nadjusts for system non-linearity. The main contribution is the introduction of\nactive paths, enhancing directly designed global and local explanations within\nthe LBBNN framework, that have theoretical guarantees and do not require post\nhoc external tools for explanations.",
      "tldr_zh": "该研究提出了输入跳跃型潜在二元贝叶斯神经网络(input-skip LBBNN)，通过允许输入变量跳过中间层或直接被排除，显著提升了模型的可解释性。相比标准LBBNN，该方法能减少99%以上的网络参数（小型网络达99%，大型网络达99.9%），同时在MNIST数据集上保持97%的准确率和良好校准性。核心创新是引入了具有理论保证的\"主动路径\"(active paths)机制，无需后处理工具即可提供全局和局部解释，并能准确识别真实协变量和调整系统非线性。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG",
        "stat.CO",
        "stat.ME",
        "62-02, 62-09, 62F07, 62F15, 62J12, 62J05, 62J99, 62M05, 05A16,\n  60J22, 92D20, 90C27, 90C59",
        "G.1.2; G.1.6; G.2.1; G.3; I.2.0; I.2.6; I.2.8; I.5.1; I.6; I.6.4"
      ],
      "primary_category": "stat.ML",
      "comment": "44 pages, 19 tables, 25 figures. Code available at\n  https://github.com/eirihoyh/ISLaB-LBBNN",
      "pdf_url": "http://arxiv.org/pdf/2503.10496v1",
      "published_date": "2025-03-13 15:59:03 UTC",
      "updated_date": "2025-03-13 15:59:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:17:00.626443"
    },
    {
      "arxiv_id": "2503.10486v1",
      "title": "LLMs in Disease Diagnosis: A Comparative Study of DeepSeek-R1 and O3 Mini Across Chronic Health Conditions",
      "title_zh": "大语言模型在疾病诊断中的应用：DeepSeek-R1与O3 Mini在慢性健康状况中的对比研究",
      "authors": [
        "Gaurav Kumar Gupta",
        "Pranal Pande"
      ],
      "abstract": "Large Language Models (LLMs) are revolutionizing medical diagnostics by\nenhancing both disease classification and clinical decision-making. In this\nstudy, we evaluate the performance of two LLM- based diagnostic tools, DeepSeek\nR1 and O3 Mini, using a structured dataset of symptoms and diagnoses. We\nassessed their predictive accuracy at both the disease and category levels, as\nwell as the reliability of their confidence scores. DeepSeek R1 achieved a\ndisease-level accuracy of 76% and an overall accuracy of 82%, outperforming O3\nMini, which attained 72% and 75% respectively. Notably, DeepSeek R1\ndemonstrated exceptional performance in Mental Health, Neurological Disorders,\nand Oncology, where it reached 100% accuracy, while O3 Mini excelled in\nAutoimmune Disease classification with 100% accuracy. Both models, however,\nstruggled with Respiratory Disease classification, recording accuracies of only\n40% for DeepSeek R1 and 20% for O3 Mini. Additionally, the analysis of\nconfidence scores revealed that DeepSeek R1 provided high-confidence\npredictions in 92% of cases, compared to 68% for O3 Mini. Ethical\nconsiderations regarding bias, model interpretability, and data privacy are\nalso discussed to ensure the responsible integration of LLMs into clinical\npractice. Overall, our findings offer valuable insights into the strengths and\nlimitations of LLM-based diagnostic systems and provide a roadmap for future\nenhancements in AI-driven healthcare.",
      "tldr_zh": "本研究对比了两种基于大语言模型（LLMs）的诊断工具DeepSeek-R1和O3 Mini在慢性健康疾病分类中的表现。结果表明，DeepSeek-R1在疾病级别和整体准确率上均优于O3 Mini，分别达到76%和82%，而O3 Mini为72%和75%。DeepSeek-R1在心理健康、神经疾病和肿瘤学领域表现尤为突出，准确率达100%，而O3 Mini在自身免疫疾病分类中表现最佳。然而，两种模型在呼吸系统疾病分类中均表现不佳。此外，DeepSeek-R1的高置信度预测占比为92%，显著高于O3 Mini的68%。研究还探讨了模型偏见、可解释性和数据隐私等伦理问题，为LLMs在临床实践中的负责任应用提供了指导。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "12 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.10486v1",
      "published_date": "2025-03-13 15:54:26 UTC",
      "updated_date": "2025-03-13 15:54:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:17:23.552649"
    },
    {
      "arxiv_id": "2503.10479v1",
      "title": "DeclareAligner: A Leap Towards Efficient Optimal Alignments for Declarative Process Model Conformance Checking",
      "title_zh": "DeclareAligner：面向声明式过程模型一致性检查的高效最优对齐技术突破",
      "authors": [
        "Jacobo Casas-Ramos",
        "Manuel Lama",
        "Manuel Mucientes"
      ],
      "abstract": "In many engineering applications, processes must be followed precisely,\nmaking conformance checking between event logs and declarative process models\ncrucial for ensuring adherence to desired behaviors. This is a critical area\nwhere Artificial Intelligence (AI) plays a pivotal role in driving effective\nprocess improvement. However, computing optimal alignments poses significant\ncomputational challenges due to the vast search space inherent in these models.\nConsequently, existing approaches often struggle with scalability and\nefficiency, limiting their applicability in real-world settings. This paper\nintroduces DeclareAligner, a novel algorithm that uses the A* search algorithm,\nan established AI pathfinding technique, to tackle the problem from a fresh\nperspective leveraging the flexibility of declarative models. Key features of\nDeclareAligner include only performing actions that actively contribute to\nfixing constraint violations, utilizing a tailored heuristic to navigate\ntowards optimal solutions, and employing early pruning to eliminate\nunproductive branches, while also streamlining the process through\npreprocessing and consolidating multiple fixes into unified actions. The\nproposed method is evaluated using 8,054 synthetic and real-life alignment\nproblems, demonstrating its ability to efficiently compute optimal alignments\nby significantly outperforming the current state of the art. By enabling\nprocess analysts to more effectively identify and understand conformance\nissues, DeclareAligner has the potential to drive meaningful process\nimprovement and management.",
      "tldr_zh": "该研究提出DeclareAligner算法，通过创新性地应用A*搜索算法解决声明式过程模型与事件日志之间的最优对齐问题，克服了传统方法在可扩展性和效率上的局限。该算法具有三大核心特征：仅执行修复约束违反的必要操作、采用定制启发式导航最优解、通过预处理和统一修复动作优化流程。在8,054个合成和实际对齐问题上的实验表明，该方法显著优于现有技术，为过程改进提供了更高效的分析工具。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10479v1",
      "published_date": "2025-03-13 15:49:29 UTC",
      "updated_date": "2025-03-13 15:49:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:17:19.733474"
    },
    {
      "arxiv_id": "2503.10471v1",
      "title": "Siamese Foundation Models for Crystal Structure Prediction",
      "title_zh": "Siamese基础模型在晶体结构预测中的应用",
      "authors": [
        "Liming Wu",
        "Wenbing Huang",
        "Rui Jiao",
        "Jianxing Huang",
        "Liwei Liu",
        "Yipeng Zhou",
        "Hao Sun",
        "Yang Liu",
        "Fuchun Sun",
        "Yuxiang Ren",
        "Jirong Wen"
      ],
      "abstract": "Crystal Structure Prediction (CSP), which aims to generate stable crystal\nstructures from compositions, represents a critical pathway for discovering\nnovel materials. While structure prediction tasks in other domains, such as\nproteins, have seen remarkable progress, CSP remains a relatively underexplored\narea due to the more complex geometries inherent in crystal structures. In this\npaper, we propose Siamese foundation models specifically designed to address\nCSP. Our pretrain-finetune framework, named DAO, comprises two complementary\nfoundation models: DAO-G for structure generation and DAO-P for energy\nprediction. Experiments on CSP benchmarks (MP-20 and MPTS-52) demonstrate that\nour DAO-G significantly surpasses state-of-the-art (SOTA) methods across all\nmetrics. Extensive ablation studies further confirm that DAO-G excels in\ngenerating diverse polymorphic structures, and the dataset relaxation and\nenergy guidance provided by DAO-P are essential for enhancing DAO-G's\nperformance. When applied to three real-world superconductors\n($\\text{CsV}_3\\text{Sb}_5$, $ \\text{Zr}_{16}\\text{Rh}_8\\text{O}_4$ and\n$\\text{Zr}_{16}\\text{Pd}_8\\text{O}_4$) that are known to be challenging to\nanalyze, our foundation models achieve accurate critical temperature\npredictions and structure generations. For instance, on\n$\\text{CsV}_3\\text{Sb}_5$, DAO-G generates a structure close to the\nexperimental one with an RMSE of 0.0085; DAO-P predicts the $T_c$ value with\nhigh accuracy (2.26 K vs. the ground-truth value of 2.30 K). In contrast,\nconventional DFT calculators like Quantum Espresso only successfully derive the\nstructure of the first superconductor within an acceptable time, while the RMSE\nis nearly 8 times larger, and the computation speed is more than 1000 times\nslower. These compelling results collectively highlight the potential of our\napproach for advancing materials science research and development.",
      "tldr_zh": "该研究提出了一种专门用于晶体结构预测(CSP)的孪生基础模型框架DAO，包含结构生成模型DAO-G和能量预测模型DAO-P。实验表明，DAO-G在MP-20和MPTS-52基准测试中全面超越现有方法，能生成多样化的多晶型结构，而DAO-P提供的能量指导显著提升了生成质量。在三种实际超导体材料测试中，该模型不仅生成了接近实验值的晶体结构(RMSE仅0.0085)，还准确预测了临界温度(误差仅0.04K)，其计算精度和速度均大幅优于传统DFT方法。",
      "categories": [
        "cond-mat.mtrl-sci",
        "cs.AI"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10471v1",
      "published_date": "2025-03-13 15:44:16 UTC",
      "updated_date": "2025-03-13 15:44:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:17:38.519813"
    },
    {
      "arxiv_id": "2503.10735v1",
      "title": "OCPM$^2$: Extending the Process Mining Methodology for Object-Centric Event Data Extraction",
      "title_zh": "OCPM$^2$：面向对象中心事件数据提取的过程挖掘方法扩展",
      "authors": [
        "Najmeh Miri",
        "Shahrzad Khayatbashi",
        "Jelena Zdravkovic",
        "Amin Jalali"
      ],
      "abstract": "Object-Centric Process Mining (OCPM) enables business process analysis from\nmultiple perspectives. For example, an educational path can be examined from\nthe viewpoints of students, teachers, and groups. This analysis depends on\nObject-Centric Event Data (OCED), which captures relationships between events\nand object types, representing different perspectives. Unlike traditional\nprocess mining techniques, extracting OCED minimizes the need for repeated log\nextractions when shifting the analytical focus. However, recording these\ncomplex relationships increases the complexity of the log extraction process.\nTo address this challenge, this paper proposes a method for extracting OCED\nbased on PM\\inst{2}, a well-established process mining framework. Our approach\nintroduces a structured framework that guides data analysts and engineers in\nextracting OCED for process analysis. We validate this framework by applying it\nin a real-world educational setting, demonstrating its effectiveness in\nextracting an Object-Centric Event Log (OCEL), which serves as the standard\nformat for recording OCED, from a learning management system and an\nadministrative grading system.",
      "tldr_zh": "本文提出OCPM$^2$方法，扩展了传统流程挖掘技术，专门用于提取对象中心事件数据(OCED)。该方法基于成熟的PM²框架，构建了结构化提取流程，支持从多视角（如学生、教师、班级）分析业务流程，显著减少了变更分析焦点时的重复日志提取需求。研究通过教育管理系统的实际应用验证了该框架的有效性，成功从学习管理系统和行政评分系统中提取出标准格式的对象中心事件日志(OCEL)。",
      "categories": [
        "cs.DB",
        "cs.AI"
      ],
      "primary_category": "cs.DB",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10735v1",
      "published_date": "2025-03-13 15:30:10 UTC",
      "updated_date": "2025-03-13 15:30:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:18:24.841609"
    },
    {
      "arxiv_id": "2503.10452v1",
      "title": "DynaCode: A Dynamic Complexity-Aware Code Benchmark for Evaluating Large Language Models in Code Generation",
      "title_zh": "DynaCode：面向代码生成的动态复杂度感知基准，用于评估大语言模型",
      "authors": [
        "Wenhao Hu",
        "Jinhao Duan",
        "Chunchen Wei",
        "Li Zhang",
        "Yue Zhang",
        "Kaidi Xu"
      ],
      "abstract": "The rapid advancement of large language models (LLMs) has significantly\nimproved their performance in code generation tasks. However, existing code\nbenchmarks remain static, consisting of fixed datasets with predefined\nproblems. This makes them vulnerable to memorization during training, where\nLLMs recall specific test cases instead of generalizing to new problems,\nleading to data contamination and unreliable evaluation results. To address\nthese issues, we introduce DynaCode, a dynamic, complexity-aware benchmark that\novercomes the limitations of static datasets. DynaCode evaluates LLMs\nsystematically using a complexity-aware metric, incorporating both code\ncomplexity and call-graph structures. DynaCode achieves large-scale diversity,\ngenerating up to 189 million unique nested code problems across four distinct\nlevels of code complexity, referred to as units, and 16 types of call graphs.\nResults on 12 latest LLMs show an average performance drop of 16.8% to 45.7%\ncompared to MBPP+, a static code generation benchmark, with performance\nprogressively decreasing as complexity increases. This demonstrates DynaCode's\nability to effectively differentiate LLMs. Additionally, by leveraging call\ngraphs, we gain insights into LLM behavior, particularly their preference for\nhandling subfunction interactions within nested code.",
      "tldr_zh": "本文提出DynaCode，首个动态复杂度感知的代码生成评测基准，解决了传统静态基准存在的记忆化问题和数据污染风险。该基准通过代码复杂度和调用图结构(call-graph)双重评估维度，能自动生成1.89亿个独特嵌套代码问题，覆盖4种复杂度单元和16类调用图。实验表明，相比静态基准MBPP+，主流大语言模型(LLMs)在DynaCode上的性能平均下降16.8%-45.7%，且性能随复杂度增加持续降低。研究还发现LLMs在处理嵌套代码中子函数交互时存在特定行为模式。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "16 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.10452v1",
      "published_date": "2025-03-13 15:18:56 UTC",
      "updated_date": "2025-03-13 15:18:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:18:32.861038"
    },
    {
      "arxiv_id": "2503.10446v1",
      "title": "Whisper Speaker Identification: Leveraging Pre-Trained Multilingual Transformers for Robust Speaker Embeddings",
      "title_zh": "Whisper说话人识别：利用预训练多语言Transformer模型实现鲁棒说话人嵌入",
      "authors": [
        "Jakaria Islam Emon",
        "Md Abu Salek",
        "Kazi Tamanna Alam"
      ],
      "abstract": "Speaker identification in multilingual settings presents unique challenges,\nparticularly when conventional models are predominantly trained on English\ndata. In this paper, we propose WSI (Whisper Speaker Identification), a\nframework that repurposes the encoder of the Whisper automatic speech\nrecognition model pre trained on extensive multilingual data to generate robust\nspeaker embeddings via a joint loss optimization strategy that leverages online\nhard triplet mining and self supervised Normalized Temperature-scaled Cross\nEntropy loss. By capitalizing on Whisper language-agnostic acoustic\nrepresentations, our approach effectively distinguishes speakers across diverse\nlanguages and recording conditions. Extensive evaluations on multiple corpora,\nincluding VoxTube (multilingual), JVS (Japanese), CallHome (German, Spanish,\nChinese, and Japanese), and Voxconverse (English), demonstrate that WSI\nconsistently outperforms state-of-the-art baselines, namely Pyannote Embedding,\nECAPA TDNN, and Xvector, in terms of lower equal error rates and higher AUC\nscores. These results validate our hypothesis that a multilingual pre-trained\nASR encoder, combined with joint loss optimization, substantially improves\nspeaker identification performance in non-English languages.",
      "tldr_zh": "本研究提出WSI（Whisper Speaker Identification）框架，利用多语言语音识别模型Whisper的预训练编码器，通过联合损失优化策略（结合在线困难三元组挖掘和自监督NT-Xent损失）生成鲁棒说话人嵌入。该方法基于Whisper的语言无关声学表征，能有效区分不同语言和录音条件下的说话人。在VoxTube、JVS等多语种数据集上的实验表明，WSI在等错误率和AUC指标上均优于Pyannote Embedding等主流基线模型，证实了多语言预训练ASR编码器对提升非英语说话人识别性能的有效性。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS",
        "I.2"
      ],
      "primary_category": "cs.SD",
      "comment": "6 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.10446v1",
      "published_date": "2025-03-13 15:11:28 UTC",
      "updated_date": "2025-03-13 15:11:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:18:19.215061"
    },
    {
      "arxiv_id": "2503.10412v3",
      "title": "dFLMoE: Decentralized Federated Learning via Mixture of Experts for Medical Data Analysis",
      "title_zh": "dFLMoE：基于专家混合的去中心化联邦学习医疗数据分析框架",
      "authors": [
        "Luyuan Xie",
        "Tianyu Luan",
        "Wenyuan Cai",
        "Guochen Yan",
        "Zhaoyu Chen",
        "Nan Xi",
        "Yuejian Fang",
        "Qingni Shen",
        "Zhonghai Wu",
        "Junsong Yuan"
      ],
      "abstract": "Federated learning has wide applications in the medical field. It enables\nknowledge sharing among different healthcare institutes while protecting\npatients' privacy. However, existing federated learning systems are typically\ncentralized, requiring clients to upload client-specific knowledge to a central\nserver for aggregation. This centralized approach would integrate the knowledge\nfrom each client into a centralized server, and the knowledge would be already\nundermined during the centralized integration before it reaches back to each\nclient. Besides, the centralized approach also creates a dependency on the\ncentral server, which may affect training stability if the server malfunctions\nor connections are unstable. To address these issues, we propose a\ndecentralized federated learning framework named dFLMoE. In our framework,\nclients directly exchange lightweight head models with each other. After\nexchanging, each client treats both local and received head models as\nindividual experts, and utilizes a client-specific Mixture of Experts (MoE)\napproach to make collective decisions. This design not only reduces the\nknowledge damage with client-specific aggregations but also removes the\ndependency on the central server to enhance the robustness of the framework. We\nvalidate our framework on multiple medical tasks, demonstrating that our method\nevidently outperforms state-of-the-art approaches under both model homogeneity\nand heterogeneity settings.",
      "tldr_zh": "该论文提出了一种名为dFLMoE的去中心化联邦学习框架，通过专家混合模型(Mixture of Experts)解决医学数据分析中的隐私保护问题。与传统的集中式联邦学习不同，该框架让客户端直接交换轻量级头部模型，并采用客户端特定的MoE方法进行集体决策，既减少了知识在集中整合过程中的损失，又消除了对中央服务器的依赖。实验表明，该方法在模型同质和异质设置下均显著优于现有最优方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "One of the authors, Wenyuan Cai, currently requests not to make the\n  paper public. Before we officially release the paper, we request to withdraw\n  the submission",
      "pdf_url": "http://arxiv.org/pdf/2503.10412v3",
      "published_date": "2025-03-13 14:35:47 UTC",
      "updated_date": "2025-03-19 16:39:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:18:10.758456"
    },
    {
      "arxiv_id": "2503.10406v1",
      "title": "RealGeneral: Unifying Visual Generation via Temporal In-Context Learning with Video Models",
      "title_zh": "RealGeneral：通过视频模型的时序上下文学习统一视觉生成",
      "authors": [
        "Yijing Lin",
        "Mengqi Huang",
        "Shuhan Zhuang",
        "Zhendong Mao"
      ],
      "abstract": "Unifying diverse image generation tasks within a single framework remains a\nfundamental challenge in visual generation. While large language models (LLMs)\nachieve unification through task-agnostic data and generation, existing visual\ngeneration models fail to meet these principles. Current approaches either rely\non per-task datasets and large-scale training or adapt pre-trained image models\nwith task-specific modifications, limiting their generalizability. In this\nwork, we explore video models as a foundation for unified image generation,\nleveraging their inherent ability to model temporal correlations. We introduce\nRealGeneral, a novel framework that reformulates image generation as a\nconditional frame prediction task, analogous to in-context learning in LLMs. To\nbridge the gap between video models and condition-image pairs, we propose (1) a\nUnified Conditional Embedding module for multi-modal alignment and (2) a\nUnified Stream DiT Block with decoupled adaptive LayerNorm and attention mask\nto mitigate cross-modal interference. RealGeneral demonstrates effectiveness in\nmultiple important visual generation tasks, e.g., it achieves a 14.5%\nimprovement in subject similarity for customized generation and a 10%\nenhancement in image quality for canny-to-image task. Project page:\nhttps://lyne1.github.io/RealGeneral/",
      "tldr_zh": "该研究提出了RealGeneral框架，通过视频模型的时间上下文学习能力，统一了多样化的图像生成任务。该方法将图像生成重新定义为条件帧预测任务，类似于大语言模型(LLMs)中的上下文学习。为了实现这一目标，研究提出了统一的条件嵌入模块和多模态对齐机制，以及解耦自适应LayerNorm和注意力掩码的统一流DiT块，以减轻跨模态干扰。实验表明，RealGeneral在多个视觉生成任务中表现出色，如在定制生成任务中主体相似性提高了14.5%，在canny-to-image任务中图像质量提升了10%。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10406v1",
      "published_date": "2025-03-13 14:31:52 UTC",
      "updated_date": "2025-03-13 14:31:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:18:18.373490"
    },
    {
      "arxiv_id": "2503.10392v1",
      "title": "RoMA: Scaling up Mamba-based Foundation Models for Remote Sensing",
      "title_zh": "RoMA：面向遥感应用的Mamba基础模型规模化扩展",
      "authors": [
        "Fengxiang Wang",
        "Hongzhen Wang",
        "Yulin Wang",
        "Di Wang",
        "Mingshuo Chen",
        "Haiyan Zhao",
        "Yangang Sun",
        "Shuo Wang",
        "Long Lan",
        "Wenjing Yang",
        "Jing Zhang"
      ],
      "abstract": "Recent advances in self-supervised learning for Vision Transformers (ViTs)\nhave fueled breakthroughs in remote sensing (RS) foundation models. However,\nthe quadratic complexity of self-attention poses a significant barrier to\nscalability, particularly for large models and high-resolution images. While\nthe linear-complexity Mamba architecture offers a promising alternative,\nexisting RS applications of Mamba remain limited to supervised tasks on small,\ndomain-specific datasets. To address these challenges, we propose RoMA, a\nframework that enables scalable self-supervised pretraining of Mamba-based RS\nfoundation models using large-scale, diverse, unlabeled data. RoMA enhances\nscalability for high-resolution images through a tailored auto-regressive\nlearning strategy, incorporating two key innovations: 1) a rotation-aware\npretraining mechanism combining adaptive cropping with angular embeddings to\nhandle sparsely distributed objects with arbitrary orientations, and 2)\nmulti-scale token prediction objectives that address the extreme variations in\nobject scales inherent to RS imagery. Systematic empirical studies validate\nthat Mamba adheres to RS data and parameter scaling laws, with performance\nscaling reliably as model and data size increase. Furthermore, experiments\nacross scene classification, object detection, and semantic segmentation tasks\ndemonstrate that RoMA-pretrained Mamba models consistently outperform ViT-based\ncounterparts in both accuracy and computational efficiency. The source code and\npretrained models will be released at https://github.com/MiliLab/RoMA.",
      "tldr_zh": "该研究提出RoMA框架，首次将线性复杂度的Mamba架构扩展应用于遥感(RS)基础模型的自监督预训练。通过创新的旋转感知预训练机制（结合自适应裁剪和角度嵌入）与多尺度token预测目标，有效解决了遥感图像中物体稀疏分布和尺度极端变化等挑战。实验证明，基于Mamba的RoMA模型在场景分类、目标检测和语义分割任务中，无论在精度还是计算效率上均超越Vision Transformer架构，且性能随模型和数据规模扩大而稳定提升。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10392v1",
      "published_date": "2025-03-13 14:09:18 UTC",
      "updated_date": "2025-03-13 14:09:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:18:49.367559"
    },
    {
      "arxiv_id": "2503.10391v1",
      "title": "CINEMA: Coherent Multi-Subject Video Generation via MLLM-Based Guidance",
      "title_zh": "CINEMA：基于多模态大语言模型引导的连贯多主体视频生成",
      "authors": [
        "Yufan Deng",
        "Xun Guo",
        "Yizhi Wang",
        "Jacob Zhiyuan Fang",
        "Angtian Wang",
        "Shenghai Yuan",
        "Yiding Yang",
        "Bo Liu",
        "Haibin Huang",
        "Chongyang Ma"
      ],
      "abstract": "Video generation has witnessed remarkable progress with the advent of deep\ngenerative models, particularly diffusion models. While existing methods excel\nin generating high-quality videos from text prompts or single images,\npersonalized multi-subject video generation remains a largely unexplored\nchallenge. This task involves synthesizing videos that incorporate multiple\ndistinct subjects, each defined by separate reference images, while ensuring\ntemporal and spatial consistency. Current approaches primarily rely on mapping\nsubject images to keywords in text prompts, which introduces ambiguity and\nlimits their ability to model subject relationships effectively. In this paper,\nwe propose CINEMA, a novel framework for coherent multi-subject video\ngeneration by leveraging Multimodal Large Language Model (MLLM). Our approach\neliminates the need for explicit correspondences between subject images and\ntext entities, mitigating ambiguity and reducing annotation effort. By\nleveraging MLLM to interpret subject relationships, our method facilitates\nscalability, enabling the use of large and diverse datasets for training.\nFurthermore, our framework can be conditioned on varying numbers of subjects,\noffering greater flexibility in personalized content creation. Through\nextensive evaluations, we demonstrate that our approach significantly improves\nsubject consistency, and overall video coherence, paving the way for advanced\napplications in storytelling, interactive media, and personalized video\ngeneration.",
      "tldr_zh": "该研究提出了CINEMA框架，利用多模态大语言模型(MLLM)实现多主体视频生成，解决了现有方法在生成包含多个独立主体的视频时存在的时间一致性和空间一致性问题。CINEMA通过MLLM解释主体关系，无需显式建立主体图像与文本实体之间的对应关系，从而减少了歧义和标注成本。实验表明，该框架显著提升了主体一致性和视频整体连贯性，为个性化内容创作提供了更大的灵活性，推动了故事叙述、互动媒体等领域的应用发展。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10391v1",
      "published_date": "2025-03-13 14:07:58 UTC",
      "updated_date": "2025-03-13 14:07:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:18:50.127514"
    },
    {
      "arxiv_id": "2503.10371v1",
      "title": "A Multimodal Fusion Model Leveraging MLP Mixer and Handcrafted Features-based Deep Learning Networks for Facial Palsy Detection",
      "title_zh": "基于MLP混合器与手工特征深度学习网络的多模态融合面部麻痹检测模型",
      "authors": [
        "Heng Yim Nicole Oo",
        "Min Hun Lee",
        "Jeong Hoon Lim"
      ],
      "abstract": "Algorithmic detection of facial palsy offers the potential to improve current\npractices, which usually involve labor-intensive and subjective assessments by\nclinicians. In this paper, we present a multimodal fusion-based deep learning\nmodel that utilizes an MLP mixer-based model to process unstructured data (i.e.\nRGB images or images with facial line segments) and a feed-forward neural\nnetwork to process structured data (i.e. facial landmark coordinates, features\nof facial expressions, or handcrafted features) for detecting facial palsy. We\nthen contribute to a study to analyze the effect of different data modalities\nand the benefits of a multimodal fusion-based approach using videos of 20\nfacial palsy patients and 20 healthy subjects. Our multimodal fusion model\nachieved 96.00 F1, which is significantly higher than the feed-forward neural\nnetwork trained on handcrafted features alone (82.80 F1) and an MLP mixer-based\nmodel trained on raw RGB images (89.00 F1).",
      "tldr_zh": "本研究提出了一种多模态融合深度学习模型，结合MLP Mixer处理非结构化数据（RGB图像或面部线段图像）和前馈神经网络处理结构化数据（面部关键点坐标、表情特征或手工特征），用于面部麻痹检测。通过分析20名患者和20名健康受试者的视频数据，研究发现多模态融合方法显著优于单一模态，最终模型F1分数达到96.00，明显高于仅使用手工特征（82.80）或原始RGB图像（89.00）的基准模型。该成果为临床提供了一种客观、高效的自动化面部麻痹评估方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "PAKDD 2025. arXiv admin note: text overlap with arXiv:2405.16496",
      "pdf_url": "http://arxiv.org/pdf/2503.10371v1",
      "published_date": "2025-03-13 13:48:35 UTC",
      "updated_date": "2025-03-13 13:48:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:19:29.393084"
    },
    {
      "arxiv_id": "2503.10367v1",
      "title": "G-Boost: Boosting Private SLMs with General LLMs",
      "title_zh": "G-Boost：利用通用大语言模型增强私有小语言模型性能",
      "authors": [
        "Yijiang Fan",
        "Yuren Mao",
        "Longbin Lai",
        "Ying Zhang",
        "Zhengping Qian",
        "Yunjun Gao"
      ],
      "abstract": "Due to the limited computational resources, most Large Language Models (LLMs)\ndevelopers can only fine-tune Small Language Models (SLMs) on their own data.\nThese private SLMs typically have limited effectiveness. To boost the\nperformance of private SLMs, this paper proposes to ask general LLMs for help.\nThe general LLMs can be APIs or larger LLMs whose inference cost the developers\ncan afford. Specifically, we propose the G-Boost framework where a private SLM\nadaptively performs collaborative inference with a general LLM under the guide\nof process reward. Experiments demonstrate that our framework can significantly\nboost the performance of private SLMs.",
      "tldr_zh": "本文提出G-Boost框架，通过让私有小型语言模型(SLMs)与通用大语言模型(LLMs)进行协作推理来提升性能。该框架采用流程奖励机制指导私有SLM自适应地选择何时调用通用LLM（如API或可负担的大模型）辅助推理。实验表明，这种方法能显著提升私有SLM的效果，为资源受限场景下的模型优化提供了新思路。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10367v1",
      "published_date": "2025-03-13 13:47:03 UTC",
      "updated_date": "2025-03-13 13:47:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:19:00.584075"
    },
    {
      "arxiv_id": "2503.10356v1",
      "title": "Object detection characteristics in a learning factory environment using YOLOv8",
      "title_zh": "YOLOv8在学习工厂环境中的目标检测特性研究",
      "authors": [
        "Toni Schneidereit",
        "Stefan Gohrenz",
        "Michael Breuß"
      ],
      "abstract": "AI-based object detection, and efforts to explain and investigate their\ncharacteristics, is a topic of high interest. The impact of, e.g., complex\nbackground structures with similar appearances as the objects of interest, on\nthe detection accuracy and, beforehand, the necessary dataset composition are\ntopics of ongoing research. In this paper, we present a systematic\ninvestigation of background influences and different features of the object to\nbe detected. The latter includes various materials and surfaces, partially\ntransparent and with shiny reflections in the context of an Industry 4.0\nlearning factory. Different YOLOv8 models have been trained for each of the\nmaterials on different sized datasets, where the appearance was the only\nchanging parameter. In the end, similar characteristics tend to show different\nbehaviours and sometimes unexpected results. While some background components\ntend to be detected, others with the same features are not part of the\ndetection. Additionally, some more precise conclusions can be drawn from the\nresults. Therefore, we contribute a challenging dataset with detailed\ninvestigations on 92 trained YOLO models, addressing some issues on the\ndetection accuracy and possible overfitting.",
      "tldr_zh": "本研究系统评估了YOLOv8模型在工业4.0学习工厂环境中的物体检测特性，重点关注背景干扰和物体材质特征（如半透明、反光表面）对检测精度的影响。通过训练92个不同配置的YOLO模型发现，相似材质特征可能表现出截然不同的检测行为，部分背景成分会被误检而同类特征却被忽略。研究不仅揭示了模型在复杂工业场景中的意外检测行为，还贡献了一个具有挑战性的数据集，为检测精度分析和过拟合问题提供了新见解。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10356v1",
      "published_date": "2025-03-13 13:33:27 UTC",
      "updated_date": "2025-03-13 13:33:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:19:48.314784"
    },
    {
      "arxiv_id": "2503.10337v1",
      "title": "KV-Distill: Nearly Lossless Learnable Context Compression for LLMs",
      "title_zh": "KV-Distill：面向大语言模型的近乎无损可学习上下文压缩技术",
      "authors": [
        "Vivek Chari",
        "Guanghui Qin",
        "Benjamin Van Durme"
      ],
      "abstract": "Sequence-to-sequence tasks often benefit from long contexts, but the\nquadratic complexity of self-attention in standard Transformers renders this\nnon-trivial. During generation, temporary representations -stored in the\nso-called KV cache-account for a large portion of GPU memory usage and scale\nlinearly with context length. We introduce KV-Distill, a Transformer\ncompression framework that distills long context KV caches into significantly\nshorter representations in a question-independent fashion. KV-Distill can be\ntrained as a parameter-efficient adaptor for pretrained models, and enables the\ncompression of arbitrary spans of a context while preserving pre-trained model\ncapabilities. We treat a compressed-uncompressed cache as a student-teacher\npairing and apply a KL-type divergence to match the generated outputs.\nKV-Distill outperforms other compression techniques in worst-case extractive\ntasks and approaches uncompressed performance in long context question\nanswering and summarization, and it can be fine-tuned on domain-specific\ncontexts to reduce lengths by up to 99% while preserving downstream\nperformance. We demonstrate the generalizability of KV-Distill across various\nmodel sizes and architectures.",
      "tldr_zh": "这篇论文提出了KV-Distill，一种用于大语言模型(LLMs)的近乎无损可学习上下文压缩方法。该方法通过将长上下文KV缓存(KV cache)蒸馏为更短的表示，在保持预训练模型能力的同时显著降低GPU内存占用。KV-Distill采用师生模型框架，使用KL散度匹配输出，在抽取式任务中优于其他压缩技术，在长上下文问答和摘要任务中接近未压缩模型的性能。实验表明，该方法可压缩99%的上下文长度而不损失下游性能，且适用于不同规模和架构的模型。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10337v1",
      "published_date": "2025-03-13 13:15:28 UTC",
      "updated_date": "2025-03-13 13:15:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:19:55.963778"
    },
    {
      "arxiv_id": "2503.10331v1",
      "title": "OSMa-Bench: Evaluating Open Semantic Mapping Under Varying Lighting Conditions",
      "title_zh": "OSMa-Bench：评估开放语义映射在不同光照条件下的表现",
      "authors": [
        "Maxim Popov",
        "Regina Kurkova",
        "Mikhail Iumanov",
        "Jaafar Mahmoud",
        "Sergey Kolyubin"
      ],
      "abstract": "Open Semantic Mapping (OSM) is a key technology in robotic perception,\ncombining semantic segmentation and SLAM techniques. This paper introduces a\ndynamically configurable and highly automated LLM/LVLM-powered pipeline for\nevaluating OSM solutions called OSMa-Bench (Open Semantic Mapping Benchmark).\nThe study focuses on evaluating state-of-the-art semantic mapping algorithms\nunder varying indoor lighting conditions, a critical challenge in indoor\nenvironments. We introduce a novel dataset with simulated RGB-D sequences and\nground truth 3D reconstructions, facilitating the rigorous analysis of mapping\nperformance across different lighting conditions. Through experiments on\nleading models such as ConceptGraphs, BBQ and OpenScene, we evaluate the\nsemantic fidelity of object recognition and segmentation. Additionally, we\nintroduce a Scene Graph evaluation method to analyze the ability of models to\ninterpret semantic structure. The results provide insights into the robustness\nof these models, forming future research directions for developing resilient\nand adaptable robotic systems. Our code is available at\nhttps://be2rlab.github.io/OSMa-Bench/.",
      "tldr_zh": "本研究提出了OSMa-Bench基准测试系统，用于评估开放语义地图(OSM)在不同光照条件下的性能。该研究开发了一个基于LLM/LVLM的动态可配置自动化评估流程，并创建了包含模拟RGB-D序列和真实3D重建的新数据集。通过测试ConceptGraphs、BBQ和OpenScene等主流模型，研究发现现有算法在光照变化下的语义保真度和场景图理解能力存在显著差异。该基准为开发适应性强、鲁棒性好的机器人语义建图系统提供了重要参考。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "Project page: https://be2rlab.github.io/OSMa-Bench/",
      "pdf_url": "http://arxiv.org/pdf/2503.10331v1",
      "published_date": "2025-03-13 13:07:51 UTC",
      "updated_date": "2025-03-13 13:07:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:20:24.538410"
    },
    {
      "arxiv_id": "2503.10318v1",
      "title": "Enhance Exploration in Safe Reinforcement Learning with Contrastive Representation Learning",
      "title_zh": "基于对比表征学习增强安全强化学习中的探索能力",
      "authors": [
        "Duc Kien Doan",
        "Bang Giang Le",
        "Viet Cuong Ta"
      ],
      "abstract": "In safe reinforcement learning, agent needs to balance between exploration\nactions and safety constraints. Following this paradigm, domain transfer\napproaches learn a prior Q-function from the related environments to prevent\nunsafe actions. However, because of the large number of false positives, some\nsafe actions are never executed, leading to inadequate exploration in\nsparse-reward environments. In this work, we aim to learn an efficient state\nrepresentation to balance the exploration and safety-prefer action in a\nsparse-reward environment. Firstly, the image input is mapped to latent\nrepresentation by an auto-encoder. A further contrastive learning objective is\nemployed to distinguish safe and unsafe states. In the learning phase, the\nlatent distance is used to construct an additional safety check, which allows\nthe agent to bias the exploration if it visits an unsafe state. To verify the\neffectiveness of our method, the experiment is carried out in three\nnavigation-based MiniGrid environments. The result highlights that our method\ncan explore the environment better while maintaining a good balance between\nsafety and efficiency.",
      "tldr_zh": "本研究提出了一种结合对比表征学习的安全强化学习方法，旨在解决稀疏奖励环境下智能体探索不足的问题。该方法采用自编码器将图像输入映射为潜在表征，并通过对比学习目标区分安全与危险状态，构建额外的安全检查机制。实验在三个基于导航的MiniGrid环境中验证了该方法的有效性，结果表明其能在保证安全性的同时显著提升环境探索效率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at ACIIDS 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.10318v1",
      "published_date": "2025-03-13 12:53:42 UTC",
      "updated_date": "2025-03-13 12:53:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:20:11.812672"
    },
    {
      "arxiv_id": "2503.10304v1",
      "title": "Nash Equilibrium Constrained Auto-bidding With Bi-level Reinforcement Learning",
      "title_zh": "纳什均衡约束下的双层强化学习自动竞价策略",
      "authors": [
        "Zhiyu Mou",
        "Miao Xu",
        "Rongquan Bai",
        "Zhuoran Yang",
        "Chuan Yu",
        "Jian Xu",
        "Bo Zheng"
      ],
      "abstract": "Many online advertising platforms provide advertisers with auto-bidding\nservices to enhance their advertising performance. However, most existing\nauto-bidding algorithms fail to accurately capture the auto-bidding problem\nformulation that the platform truly faces, let alone solve it. Actually, we\nargue that the platform should try to help optimize each advertiser's\nperformance to the greatest extent -- which makes $\\epsilon$-Nash Equilibrium\n($\\epsilon$-NE) a necessary solution concept -- while maximizing the social\nwelfare of all the advertisers for the platform's long-term value. Based on\nthis, we introduce the \\emph{Nash-Equilibrium Constrained Bidding} (NCB), a new\nformulation of the auto-bidding problem from the platform's perspective.\nSpecifically, it aims to maximize the social welfare of all advertisers under\nthe $\\epsilon$-NE constraint. However, the NCB problem presents significant\nchallenges due to its constrained bi-level structure and the typically large\nnumber of advertisers involved. To address these challenges, we propose a\n\\emph{Bi-level Policy Gradient} (BPG) framework with theoretical guarantees.\nNotably, its computational complexity is independent of the number of\nadvertisers, and the associated gradients are straightforward to compute.\nExtensive simulated and real-world experiments validate the effectiveness of\nthe BPG framework.",
      "tldr_zh": "本研究提出了一种新的自动竞价问题框架——纳什均衡约束竞价(NCB)，旨在从平台角度优化广告主的集体福利，同时满足$\\epsilon$-纳什均衡($\\epsilon$-NE)约束。为解决这一双层优化问题，作者开发了具有理论保证的双层策略梯度(BPG)框架，其计算复杂度与广告主数量无关且梯度计算简便。实验结果表明，BPG框架在模拟和真实场景中均表现出色，为在线广告平台的自动竞价服务提供了有效解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.GT"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10304v1",
      "published_date": "2025-03-13 12:25:36 UTC",
      "updated_date": "2025-03-13 12:25:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:20:18.137891"
    },
    {
      "arxiv_id": "2503.10301v1",
      "title": "Bilingual Dual-Head Deep Model for Parkinson's Disease Detection from Speech",
      "title_zh": "双语双头深度模型：基于语音的帕金森病检测",
      "authors": [
        "Moreno La Quatra",
        "Juan Rafael Orozco-Arroyave",
        "Marco Sabato Siniscalchi"
      ],
      "abstract": "This work aims to tackle the Parkinson's disease (PD) detection problem from\nthe speech signal in a bilingual setting by proposing an ad-hoc dual-head deep\nneural architecture for type-based binary classification. One head is\nspecialized for diadochokinetic patterns. The other head looks for natural\nspeech patterns present in continuous spoken utterances. Only one of the two\nheads is operative accordingly to the nature of the input. Speech\nrepresentations are extracted from self-supervised learning (SSL) models and\nwavelet transforms. Adaptive layers, convolutional bottlenecks, and contrastive\nlearning are exploited to reduce variations across languages. Our solution is\nassessed against two distinct datasets, EWA-DB, and PC-GITA, which cover Slovak\nand Spanish languages, respectively. Results indicate that conventional models\ntrained on a single language dataset struggle with cross-linguistic\ngeneralization, and naive combinations of datasets are suboptimal. In contrast,\nour model improves generalization on both languages, simultaneously.",
      "tldr_zh": "本研究提出了一种双语双头深度神经网络模型，用于通过语音信号检测帕金森病(PD)。该模型采用双头架构，分别处理断续发音(diadochokinetic)模式和连续自然语音模式，并基于输入类型自动激活相应模块。通过结合自监督学习(SSL)特征和小波变换，并采用自适应层、卷积瓶颈和对比学习来减小跨语言差异。实验表明，该模型在斯洛伐克语(EWA-DB)和西班牙语(PC-GITA)数据集上均优于单语言训练的传统模型，实现了更好的跨语言泛化能力。",
      "categories": [
        "eess.AS",
        "cs.AI"
      ],
      "primary_category": "eess.AS",
      "comment": "Accepted at ICASSP 2025 - Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses",
      "pdf_url": "http://arxiv.org/pdf/2503.10301v1",
      "published_date": "2025-03-13 12:23:11 UTC",
      "updated_date": "2025-03-13 12:23:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:20:25.901654"
    },
    {
      "arxiv_id": "2503.10296v1",
      "title": "CODEI: Resource-Efficient Task-Driven Co-Design of Perception and Decision Making for Mobile Robots Applied to Autonomous Vehicles",
      "title_zh": "CODEI：面向自动驾驶移动机器人的资源高效型任务驱动感知与决策协同设计",
      "authors": [
        "Dejan Milojevic",
        "Gioele Zardini",
        "Miriam Elser",
        "Andrea Censi",
        "Emilio Frazzoli"
      ],
      "abstract": "This paper discusses the integration challenges and strategies for designing\nmobile robots, by focusing on the task-driven, optimal selection of hardware\nand software to balance safety, efficiency, and minimal usage of resources such\nas costs, energy, computational requirements, and weight. We emphasize the\ninterplay between perception and motion planning in decision-making by\nintroducing the concept of occupancy queries to quantify the perception\nrequirements for sampling-based motion planners. Sensor and algorithm\nperformance are evaluated using False Negative Rates (FPR) and False Positive\nRates (FPR) across various factors such as geometric relationships, object\nproperties, sensor resolution, and environmental conditions. By integrating\nperception requirements with perception performance, an Integer Linear\nProgramming (ILP) approach is proposed for efficient sensor and algorithm\nselection and placement. This forms the basis for a co-design optimization that\nincludes the robot body, motion planner, perception pipeline, and computing\nunit. We refer to this framework for solving the co-design problem of mobile\nrobots as CODEI, short for Co-design of Embodied Intelligence. A case study on\ndeveloping an Autonomous Vehicle (AV) for urban scenarios provides actionable\ninformation for designers, and shows that complex tasks escalate resource\ndemands, with task performance affecting choices of the autonomy stack. The\nstudy demonstrates that resource prioritization influences sensor choice:\ncameras are preferred for cost-effective and lightweight designs, while lidar\nsensors are chosen for better energy and computational efficiency.",
      "tldr_zh": "本文提出了CODEI框架，用于移动机器人（如自动驾驶汽车）的感知与决策协同设计，旨在优化硬件和软件选择以平衡安全性、效率和资源利用率（如成本、能耗、计算需求和重量）。通过引入占用查询概念，量化感知需求，并结合整数线性规划（ILP）方法，优化传感器和算法的选择与布局。研究表明，任务复杂度显著影响资源需求，摄像头适用于低成本轻量化设计，而激光雷达则在能耗和计算效率上表现更优。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.AR",
        "cs.CV",
        "cs.SY",
        "eess.SY",
        "I.2.9; I.2.10; I.2.8; I.4.8"
      ],
      "primary_category": "cs.RO",
      "comment": "20 pages, 33 images, IEEE Transactions on Robotics",
      "pdf_url": "http://arxiv.org/pdf/2503.10296v1",
      "published_date": "2025-03-13 12:12:44 UTC",
      "updated_date": "2025-03-13 12:12:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:20:29.787955"
    },
    {
      "arxiv_id": "2503.10284v1",
      "title": "PyGDA: A Python Library for Graph Domain Adaptation",
      "title_zh": "PyGDA：面向图域自适应的Python开源库",
      "authors": [
        "Zhen Zhang",
        "Meihan Liu",
        "Bingsheng He"
      ],
      "abstract": "Graph domain adaptation has emerged as a promising approach to facilitate\nknowledge transfer across different domains. Recently, numerous models have\nbeen proposed to enhance their generalization capabilities in this field.\nHowever, there is still no unified library that brings together existing\ntechniques and simplifies their implementation. To fill this gap, we introduce\nPyGDA, an open-source Python library tailored for graph domain adaptation. As\nthe first comprehensive library in this area, PyGDA covers more than 20 widely\nused graph domain adaptation methods together with different types of graph\ndatasets. Specifically, PyGDA offers modular components, enabling users to\nseamlessly build custom models with a variety of commonly used utility\nfunctions. To handle large-scale graphs, PyGDA includes support for features\nsuch as sampling and mini-batch processing, ensuring efficient computation. In\naddition, PyGDA also includes comprehensive performance benchmarks and\nwell-documented user-friendly API for both researchers and practitioners. To\nfoster convenient accessibility, PyGDA is released under the MIT license at\nhttps://github.com/pygda-team/pygda, and the API documentation is\nhttps://pygda.readthedocs.io/en/stable/.",
      "tldr_zh": "该研究推出了PyGDA——首个专门用于图域适应(Graph Domain Adaptation)的Python开源库，填补了该领域缺乏统一工具包的空白。该库整合了20多种主流图域适应方法，支持模块化组件构建和多样化图数据集处理，并通过采样和小批量处理技术优化大规模图计算效率。PyGDA还提供完整的性能基准测试和用户友好型API文档，采用MIT协议开源，旨在促进图域适应技术的标准化应用与研究发展。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Under Review",
      "pdf_url": "http://arxiv.org/pdf/2503.10284v1",
      "published_date": "2025-03-13 11:52:23 UTC",
      "updated_date": "2025-03-13 11:52:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:20:47.784301"
    },
    {
      "arxiv_id": "2503.10728v1",
      "title": "DarkBench: Benchmarking Dark Patterns in Large Language Models",
      "title_zh": "DarkBench：大型语言模型中的暗黑模式基准测试",
      "authors": [
        "Esben Kran",
        "Hieu Minh \"Jord\" Nguyen",
        "Akash Kundu",
        "Sami Jawhar",
        "Jinsuk Park",
        "Mateusz Maria Jurewicz"
      ],
      "abstract": "We introduce DarkBench, a comprehensive benchmark for detecting dark design\npatterns--manipulative techniques that influence user behavior--in interactions\nwith large language models (LLMs). Our benchmark comprises 660 prompts across\nsix categories: brand bias, user retention, sycophancy, anthropomorphism,\nharmful generation, and sneaking. We evaluate models from five leading\ncompanies (OpenAI, Anthropic, Meta, Mistral, Google) and find that some LLMs\nare explicitly designed to favor their developers' products and exhibit\nuntruthful communication, among other manipulative behaviors. Companies\ndeveloping LLMs should recognize and mitigate the impact of dark design\npatterns to promote more ethical AI.",
      "tldr_zh": "本研究提出了DarkBench，一个用于检测大语言模型(LLMs)交互中暗黑设计模式（即操纵用户行为的技术）的综合基准。该基准包含660个提示，涵盖品牌偏见、用户留存、谄媚、拟人化、有害生成和暗中操纵等六类行为。通过对五家领先公司（OpenAI、Anthropic、Meta、Mistral、Google）的模型进行评估，研究发现某些LLMs明确设计为偏向开发者产品，并表现出不诚实的沟通等操纵行为。研究呼吁LLMs开发者应识别并减轻暗黑设计模式的影响，以促进更符合伦理的人工智能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted as an Oral paper at ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.10728v1",
      "published_date": "2025-03-13 11:48:42 UTC",
      "updated_date": "2025-03-13 11:48:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:20:47.652215"
    },
    {
      "arxiv_id": "2503.10727v1",
      "title": "Word-level Annotation of GDPR Transparency Compliance in Privacy Policies using Large Language Models",
      "title_zh": "《运用大语言模型实现隐私政策中GDPR透明度合规性的词级标注》",
      "authors": [
        "Thomas Cory",
        "Wolf Rieder",
        "Julia Krämer",
        "Philip Raschke",
        "Patrick Herbke",
        "Axel Küpper"
      ],
      "abstract": "Ensuring transparency of data practices related to personal information is a\nfundamental requirement under the General Data Protection Regulation (GDPR),\nparticularly as mandated by Articles 13 and 14. However, assessing compliance\nat scale remains a challenge due to the complexity and variability of privacy\npolicy language. Manual audits are resource-intensive and inconsistent, while\nexisting automated approaches lack the granularity needed to capture nuanced\ntransparency disclosures.\n  In this paper, we introduce a large language model (LLM)-based framework for\nword-level GDPR transparency compliance annotation. Our approach comprises a\ntwo-stage annotation pipeline that combines initial LLM-based annotation with a\nself-correction mechanism for iterative refinement. This annotation pipeline\nenables the systematic identification and fine-grained annotation of\ntransparency-related content in privacy policies, aligning with 21 GDPR-derived\ntransparency requirements. To enable large-scale analysis, we compile a dataset\nof 703,791 English-language policies, from which we generate a sample of 200\nmanually annotated privacy policies.\n  To evaluate our approach, we introduce a two-tiered methodology assessing\nboth label- and span-level annotation performance. We conduct a comparative\nanalysis of eight high-profile LLMs, providing insights into their\neffectiveness in identifying GDPR transparency disclosures. Our findings\ncontribute to advancing the automation of GDPR compliance assessments and\nprovide valuable resources for future research in privacy policy analysis.",
      "tldr_zh": "本研究提出了一种基于大语言模型（LLM）的框架，用于对隐私政策中的GDPR透明度合规性进行细粒度词级标注。该框架采用两阶段标注流程，结合LLM初始标注和自校正机制进行迭代优化，能系统识别与21项GDPR透明度要求相关的政策内容。研究人员构建了包含70万份英文隐私政策的数据集，并通过比较八种主流LLM的表现，开发了同时评估标签级和跨度级标注性能的双层评估方法，为大规模自动化GDPR合规评估提供了有效解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10727v1",
      "published_date": "2025-03-13 11:41:25 UTC",
      "updated_date": "2025-03-13 11:41:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:21:06.449851"
    },
    {
      "arxiv_id": "2503.10265v1",
      "title": "SurgRAW: Multi-Agent Workflow with Chain-of-Thought Reasoning for Surgical Intelligence",
      "title_zh": "SurgRAW：基于思维链推理的手术智能多智能体协同工作流",
      "authors": [
        "Chang Han Low",
        "Ziyue Wang",
        "Tianyi Zhang",
        "Zhitao Zeng",
        "Zhu Zhuo",
        "Evangelos B. Mazomenos",
        "Yueming Jin"
      ],
      "abstract": "Integration of Vision-Language Models (VLMs) in surgical intelligence is\nhindered by hallucinations, domain knowledge gaps, and limited understanding of\ntask interdependencies within surgical scenes, undermining clinical\nreliability. While recent VLMs demonstrate strong general reasoning and\nthinking capabilities, they still lack the domain expertise and task-awareness\nrequired for precise surgical scene interpretation. Although Chain-of-Thought\n(CoT) can structure reasoning more effectively, current approaches rely on\nself-generated CoT steps, which often exacerbate inherent domain gaps and\nhallucinations. To overcome this, we present SurgRAW, a CoT-driven multi-agent\nframework that delivers transparent, interpretable insights for most tasks in\nrobotic-assisted surgery. By employing specialized CoT prompts across five\ntasks: instrument recognition, action recognition, action prediction, patient\ndata extraction, and outcome assessment, SurgRAW mitigates hallucinations\nthrough structured, domain-aware reasoning. Retrieval-Augmented Generation\n(RAG) is also integrated to external medical knowledge to bridge domain gaps\nand improve response reliability. Most importantly, a hierarchical agentic\nsystem ensures that CoT-embedded VLM agents collaborate effectively while\nunderstanding task interdependencies, with a panel discussion mechanism\npromotes logical consistency. To evaluate our method, we introduce\nSurgCoTBench, the first reasoning-based dataset with structured frame-level\nannotations. With comprehensive experiments, we demonstrate the effectiveness\nof proposed SurgRAW with 29.32% accuracy improvement over baseline VLMs on 12\nrobotic procedures, achieving the state-of-the-art performance and advancing\nexplainable, trustworthy, and autonomous surgical assistance.",
      "tldr_zh": "这篇论文提出了 **SurgRAW**，一个基于 **链式思维推理（CoT）** 的多智能体框架，旨在提升 **视觉语言模型（VLMs）** 在手术智能领域的可靠性和精确性。该框架通过 **专门设计的 CoT 提示** 处理五项关键任务（如器械识别、动作预测等），并结合 **检索增强生成（RAG）** 引入外部医学知识，减少幻觉问题。此外，**层次化智能体系统** 通过协作和逻辑一致性机制，增强任务间的关联理解。实验表明，SurgRAW 在 **12 种机器人辅助手术** 上比基线模型准确率提升 **29.32%**，并建立了首个推理基准数据集 **SurgCoTBench**，推动了可解释、可信赖的自主手术辅助技术的发展。",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10265v1",
      "published_date": "2025-03-13 11:23:13 UTC",
      "updated_date": "2025-03-13 11:23:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:21:34.606196"
    },
    {
      "arxiv_id": "2503.10253v2",
      "title": "PIMRL: Physics-Informed Multi-Scale Recurrent Learning for Spatiotemporal Prediction",
      "title_zh": "PIMRL：基于物理信息的多尺度循环学习用于时空预测",
      "authors": [
        "Han Wan",
        "Qi Wang",
        "Yuan Mi",
        "Hao Sun"
      ],
      "abstract": "Simulation of spatiotemporal systems governed by partial differential\nequations is widely applied in fields such as biology, chemistry, aerospace\ndynamics, and meteorology. Traditional numerical methods incur high\ncomputational costs due to the requirement of small time steps for accurate\npredictions. While machine learning has reduced these costs, long-term\npredictions remain challenged by error accumulation, particularly in scenarios\nwith insufficient data or varying time scales, where stability and accuracy are\ncompromised. Existing methods often neglect the effective utilization of\nmulti-scale data, leading to suboptimal robustness in predictions. To address\nthese issues, we propose a novel multi-scale learning framework, namely, the\nPhysics-Informed Multi-Scale Recurrent Learning (PIMRL), to effectively\nleverage multi-scale data for spatiotemporal dynamics prediction. The PIMRL\nframework comprises two modules: the micro-scale module embeds physical\nknowledge into neural networks via pretraining, and the macro-scale module\nadopts a data-driven approach to learn the temporal evolution of physics in the\nlatent space. Experimental results demonstrate that the PIMRL framework\nconsistently achieves state-of-the-art performance across five benchmark\ndatasets ranging from one to three dimensions, showing average improvements of\nover 9\\% in both RMSE and MAE evaluation metrics, with maximum enhancements\nreaching up to 80%.",
      "tldr_zh": "该研究提出PIMRL框架（物理信息多尺度循环学习），用于解决时空预测中传统数值方法计算成本高和机器学习方法长期预测误差累积的问题。该框架创新性地结合微观尺度（通过预训练将物理知识嵌入神经网络）和宏观尺度（数据驱动学习潜在空间中的物理演化）双模块，有效利用多尺度数据。实验表明，PIMRL在1D-3D五个基准数据集上平均提升9%的RMSE和MAE指标，最大改进达80%，显著优于现有方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10253v2",
      "published_date": "2025-03-13 11:01:03 UTC",
      "updated_date": "2025-03-18 07:08:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:21:47.680198"
    },
    {
      "arxiv_id": "2503.10248v1",
      "title": "LLM Agents Display Human Biases but Exhibit Distinct Learning Patterns",
      "title_zh": "LLM智能体呈现人类认知偏差但展现独特学习模式",
      "authors": [
        "Idan Horowitz",
        "Ori Plonsky"
      ],
      "abstract": "We investigate the choice patterns of Large Language Models (LLMs) in the\ncontext of Decisions from Experience tasks that involve repeated choice and\nlearning from feedback, and compare their behavior to human participants. We\nfind that on the aggregate, LLMs appear to display behavioral biases similar to\nhumans: both exhibit underweighting rare events and correlation effects.\nHowever, more nuanced analyses of the choice patterns reveal that this happens\nfor very different reasons. LLMs exhibit strong recency biases, unlike humans,\nwho appear to respond in more sophisticated ways. While these different\nprocesses may lead to similar behavior on average, choice patterns contingent\non recent events differ vastly between the two groups. Specifically, phenomena\nsuch as ``surprise triggers change\" and the ``wavy recency effect of rare\nevents\" are robustly observed in humans, but entirely absent in LLMs. Our\nfindings provide insights into the limitations of using LLMs to simulate and\npredict humans in learning environments and highlight the need for refined\nanalyses of their behavior when investigating whether they replicate human\ndecision making tendencies.",
      "tldr_zh": "该研究比较了大型语言模型(LLMs)与人类在“经验决策”任务中的选择模式和学习行为。研究发现，LLMs在总体上表现出与人类相似的行为偏差，例如低估罕见事件和相关效应，但其背后的原因却截然不同。LLMs展现出强烈的近因偏差，而人类则表现出更复杂的学习模式，如“惊讶触发改变”和“罕见事件的波动近因效应”等现象在人类中稳定存在，但在LLMs中完全缺失。这些发现揭示了LLMs在模拟和预测人类学习行为时的局限性，并强调在分析其是否复制人类决策倾向时需要更精细的研究方法。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10248v1",
      "published_date": "2025-03-13 10:47:03 UTC",
      "updated_date": "2025-03-13 10:47:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:21:35.063555"
    },
    {
      "arxiv_id": "2503.10242v1",
      "title": "MinorBench: A hand-built benchmark for content-based risks for children",
      "title_zh": "MinorBench：面向儿童内容风险的手工构建基准",
      "authors": [
        "Shaun Khoo",
        "Gabriel Chua",
        "Rachel Shong"
      ],
      "abstract": "Large Language Models (LLMs) are rapidly entering children's lives - through\nparent-driven adoption, schools, and peer networks - yet current AI ethics and\nsafety research do not adequately address content-related risks specific to\nminors. In this paper, we highlight these gaps with a real-world case study of\nan LLM-based chatbot deployed in a middle school setting, revealing how\nstudents used and sometimes misused the system. Building on these findings, we\npropose a new taxonomy of content-based risks for minors and introduce\nMinorBench, an open-source benchmark designed to evaluate LLMs on their ability\nto refuse unsafe or inappropriate queries from children. We evaluate six\nprominent LLMs under different system prompts, demonstrating substantial\nvariability in their child-safety compliance. Our results inform practical\nsteps for more robust, child-focused safety mechanisms and underscore the\nurgency of tailoring AI systems to safeguard young users.",
      "tldr_zh": "该研究针对大语言模型(LLMs)在儿童使用中的内容安全风险，提出了首个专门评估基准MinorBench。通过分析中学环境中LLM聊天机器人的实际使用案例，研究者建立了针对未成年人的内容风险分类体系。实验评估了六种主流LLMs在不同系统提示下的表现，发现其儿童安全合规性存在显著差异。该研究为开发更健全的儿童保护机制提供了实证基础，凸显了定制化AI安全系统的紧迫性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10242v1",
      "published_date": "2025-03-13 10:34:43 UTC",
      "updated_date": "2025-03-13 10:34:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:21:56.880107"
    },
    {
      "arxiv_id": "2503.10725v1",
      "title": "Samoyeds: Accelerating MoE Models with Structured Sparsity Leveraging Sparse Tensor Cores",
      "title_zh": "萨摩耶（Samoyeds）：利用稀疏张量核心结构化稀疏性加速专家混合模型",
      "authors": [
        "Chenpeng Wu",
        "Qiqi Gu",
        "Heng Shi",
        "Jianguo Yao",
        "Haibing Guan"
      ],
      "abstract": "The escalating size of Mixture-of-Experts (MoE) based Large Language Models\n(LLMs) presents significant computational and memory challenges, necessitating\ninnovative solutions to enhance efficiency without compromising model accuracy.\nStructured sparsity emerges as a compelling strategy to address these\nchallenges by leveraging the emerging sparse computing hardware. Prior works\nmainly focus on the sparsity in model parameters, neglecting the inherent\nsparse patterns in activations. This oversight can lead to additional\ncomputational costs associated with activations, potentially resulting in\nsuboptimal performance.\n  This paper presents Samoyeds, an innovative acceleration system for MoE LLMs\nutilizing Sparse Tensor Cores (SpTCs). Samoyeds is the first to apply sparsity\nsimultaneously to both activations and model parameters. It introduces a\nbespoke sparse data format tailored for MoE computation and develops a\nspecialized sparse-sparse matrix multiplication kernel. Furthermore, Samoyeds\nincorporates systematic optimizations specifically designed for the execution\nof dual-side structured sparse MoE LLMs on SpTCs, further enhancing system\nperformance. Evaluations show that Samoyeds outperforms SOTA works by up to\n1.99$\\times$ at the kernel level and 1.58$\\times$ at the model level. Moreover,\nit enhances memory efficiency, increasing maximum supported batch sizes by\n4.41$\\times$ on average. Additionally, Samoyeds surpasses existing SOTA\nstructured sparse solutions in both model accuracy and hardware portability.",
      "tldr_zh": "该研究提出了Samoyeds系统，首次在混合专家模型(MoE)中同时利用激活值和模型参数的结构化稀疏性，通过定制稀疏数据格式和专用稀疏矩阵乘法核，显著提升计算效率。实验表明，该系统在核级和模型级分别实现1.99倍和1.58倍加速，内存效率提升4.41倍，同时保持模型精度和硬件兼容性优势。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC",
        "cs.OS"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10725v1",
      "published_date": "2025-03-13 10:34:15 UTC",
      "updated_date": "2025-03-13 10:34:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:21:53.147480"
    },
    {
      "arxiv_id": "2503.10723v1",
      "title": "RankPO: Preference Optimization for Job-Talent Matching",
      "title_zh": "RankPO：面向职位-人才匹配的偏好优化方法",
      "authors": [
        "Yafei Zhang",
        "Murray Wang",
        "Yu Wang",
        "Xiaohui Wang"
      ],
      "abstract": "Matching job descriptions (JDs) with suitable talent requires models capable\nof understanding not only textual similarities between JDs and candidate\nresumes but also contextual factors such as geographical location and academic\nseniority. To address this challenge, we propose a two-stage training framework\nfor large language models (LLMs). In the first stage, a contrastive learning\napproach is used to train the model on a dataset constructed from real-world\nmatching rules, such as geographical alignment and research area overlap. While\neffective, this model primarily learns patterns that defined by the matching\nrules. In the second stage, we introduce a novel preference-based fine-tuning\nmethod inspired by Direct Preference Optimization (DPO), termed Rank Preference\nOptimization (RankPO), to align the model with AI-curated pairwise preferences\nemphasizing textual understanding. Our experiments show that while the\nfirst-stage model achieves strong performance on rule-based data (nDCG@20 =\n0.706), it lacks robust textual understanding (alignment with AI annotations =\n0.46). By fine-tuning with RankPO, we achieve a balanced model that retains\nrelatively good performance in the original tasks while significantly improving\nthe alignment with AI preferences. The code and data are available at\nhttps://github.com/yflyzhang/RankPO.",
      "tldr_zh": "该研究提出RankPO（Rank Preference Optimization）方法，用于优化求职者-职位匹配任务。通过两阶段训练框架：第一阶段采用对比学习基于地理位置匹配等规则训练大语言模型(LLMs)，第二阶段创新性地引入受DPO(Direct Preference Optimization)启发的偏好优化方法RankPO，使模型同时兼顾规则匹配和文本理解能力。实验表明，该方法在保持规则匹配性能(nDCG@20=0.706)的同时，显著提升了与AI标注的文本理解对齐度(从0.46提升至平衡表现)，为智能招聘系统提供了更全面的匹配能力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "15 pages, 3 figures, 7 tables",
      "pdf_url": "http://arxiv.org/pdf/2503.10723v1",
      "published_date": "2025-03-13 10:14:37 UTC",
      "updated_date": "2025-03-13 10:14:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:22:08.164855"
    },
    {
      "arxiv_id": "2503.10217v1",
      "title": "Efficient Federated Fine-Tuning of Large Language Models with Layer Dropout",
      "title_zh": "高效联邦微调大语言模型的层随机丢弃方法",
      "authors": [
        "Shilong Wang",
        "Jianchun Liu",
        "Hongli Xu",
        "Jiaming Yan",
        "Xianjun Gao"
      ],
      "abstract": "Fine-tuning plays a crucial role in enabling pre-trained LLMs to evolve from\ngeneral language comprehension to task-specific expertise. To preserve user\ndata privacy, federated fine-tuning is often employed and has emerged as the de\nfacto paradigm. However, federated fine-tuning is prohibitively inefficient due\nto the tension between LLM complexity and the resource constraint of end\ndevices, incurring unaffordable fine-tuning overhead. Existing literature\nprimarily utilizes parameter-efficient fine-tuning techniques to mitigate\ncommunication costs, yet computational and memory burdens continue to pose\nsignificant challenges for developers. This work proposes DropPEFT, an\ninnovative federated PEFT framework that employs a novel stochastic transformer\nlayer dropout method, enabling devices to deactivate a considerable fraction of\nLLMs layers during training, thereby eliminating the associated computational\nload and memory footprint. In DropPEFT, a key challenge is the proper\nconfiguration of dropout ratios for layers, as overhead and training\nperformance are highly sensitive to this setting. To address this challenge, we\nadaptively assign optimal dropout-ratio configurations to devices through an\nexploration-exploitation strategy, achieving efficient and effective\nfine-tuning. Extensive experiments show that DropPEFT can achieve a\n1.3-6.3\\times speedup in model convergence and a 40%-67% reduction in memory\nfootprint compared to state-of-the-art methods.",
      "tldr_zh": "该研究提出DropPEFT框架，通过创新的随机Transformer层丢弃（stochastic transformer layer dropout）方法，显著提升大型语言模型（LLMs）的联邦微调效率。该方法允许设备在训练时停用大部分模型层，从而降低计算负载和内存占用，并通过探索-利用策略自适应配置最优丢弃比例。实验表明，DropPEFT相比现有方法可加速模型收敛1.3-6.3倍，并减少40%-67%内存消耗，有效解决了联邦学习中设备资源受限与LLM复杂度之间的矛盾。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "13 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.10217v1",
      "published_date": "2025-03-13 09:59:16 UTC",
      "updated_date": "2025-03-13 09:59:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:22:08.001768"
    },
    {
      "arxiv_id": "2503.10215v1",
      "title": "Adaptive Preference Aggregation",
      "title_zh": "自适应偏好聚合",
      "authors": [
        "Benjamin Heymann"
      ],
      "abstract": "AI alignment, the challenge of ensuring AI systems act in accordance with\nhuman values, has emerged as a critical problem in the development of systems\nsuch as foundation models and recommender systems. Still, the current dominant\napproach, reinforcement learning with human feedback (RLHF) faces known\ntheoretical limitations in aggregating diverse human preferences. Social choice\ntheory provides a framework to aggregate preferences, but was not developed for\nthe multidimensional applications typical of AI. Leveraging insights from a\nrecently published urn process, this work introduces a preference aggregation\nstrategy that adapts to the user's context and that inherits the good\nproperties of the maximal lottery, a Condorcet-consistent solution concept.",
      "tldr_zh": "该研究提出了一种自适应偏好聚合方法，用于解决AI对齐中的人类价值观整合难题。通过借鉴社会选择理论和最新提出的urn过程，该方法能够在多维AI应用场景中自适应地聚合用户偏好。该策略继承了最大彩票(maximal lottery)这一满足孔多塞一致性(Condorcet-consistent)的解决方案特性，相比当前主流的人类反馈强化学习(RLHF)方法具有更好的理论优势。",
      "categories": [
        "cs.AI",
        "cs.GT"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10215v1",
      "published_date": "2025-03-13 09:57:41 UTC",
      "updated_date": "2025-03-13 09:57:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:22:21.817724"
    },
    {
      "arxiv_id": "2503.10198v1",
      "title": "Deep Learning for Time Series Forecasting: A Survey",
      "title_zh": "深度学习在时间序列预测中的应用：综述",
      "authors": [
        "Xiangjie Kong",
        "Zhenghao Chen",
        "Weiyao Liu",
        "Kaili Ning",
        "Lechao Zhang",
        "Syauqie Muhammad Marier",
        "Yichen Liu",
        "Yuhao Chen",
        "Feng Xia"
      ],
      "abstract": "Time series forecasting (TSF) has long been a crucial task in both industry\nand daily life. Most classical statistical models may have certain limitations\nwhen applied to practical scenarios in fields such as energy, healthcare,\ntraffic, meteorology, and economics, especially when high accuracy is required.\nWith the continuous development of deep learning, numerous new models have\nemerged in the field of time series forecasting in recent years. However,\nexisting surveys have not provided a unified summary of the wide range of model\narchitectures in this field, nor have they given detailed summaries of works in\nfeature extraction and datasets. To address this gap, in this review, we\ncomprehensively study the previous works and summarize the general paradigms of\nDeep Time Series Forecasting (DTSF) in terms of model architectures. Besides,\nwe take an innovative approach by focusing on the composition of time series\nand systematically explain important feature extraction methods. Additionally,\nwe provide an overall compilation of datasets from various domains in existing\nworks. Finally, we systematically emphasize the significant challenges faced\nand future research directions in this field.",
      "tldr_zh": "这篇综述系统梳理了深度学习在时间序列预测(Time Series Forecasting)领域的研究进展。作者建立了深度时间序列预测(DTSF)的统一模型架构范式，创新性地从时间序列组成角度系统阐述了特征提取方法，并汇总了各领域常用数据集。该研究不仅填补了现有综述在模型架构系统性和特征提取方法总结方面的空白，还提出了该领域面临的关键挑战和未来研究方向，为能源、医疗、交通等多个实际应用场景的高精度预测提供了重要参考。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10198v1",
      "published_date": "2025-03-13 09:32:01 UTC",
      "updated_date": "2025-03-13 09:32:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:22:29.004043"
    },
    {
      "arxiv_id": "2503.10197v1",
      "title": "Predicting Chemical Reaction Outcomes Based on Electron Movements Using Machine Learning",
      "title_zh": "基于电子运动的机器学习化学反应结果预测",
      "authors": [
        "Shuan Chen",
        "Kye Sung Park",
        "Taewan Kim",
        "Sunkyu Han",
        "Yousung Jung"
      ],
      "abstract": "Accurately predicting chemical reaction outcomes and potential byproducts is\na fundamental task of modern chemistry, enabling the efficient design of\nsynthetic pathways and driving progress in chemical science. Reaction\nmechanism, which tracks electron movements during chemical reactions, is\ncritical for understanding reaction kinetics and identifying unexpected\nproducts. Here, we present Reactron, the first electron-based machine learning\nmodel for general reaction prediction. Reactron integrates electron movement\ninto its predictions, generating detailed arrow-pushing diagrams that elucidate\neach mechanistic step leading to product formation. We demonstrate the high\npredictive performance of Reactron over existing product-only models by a\nlarge-scale reaction outcome prediction benchmark, and the adaptability of the\nmodel to learn new reactivity upon providing a few examples. Furthermore, it\nexplores combinatorial reaction spaces, uncovering novel reactivities beyond\nits training data. With robust performance in both in- and out-of-distribution\npredictions, Reactron embodies human-like reasoning in chemistry and opens new\nfrontiers in reaction discovery and synthesis design.",
      "tldr_zh": "该研究提出了Reactron，首个基于电子运动的机器学习模型，用于预测化学反应结果。该模型通过追踪电子运动生成详细的箭头推图（arrow-pushing diagrams），阐明产物形成的每一步机理，相比现有仅预测产物的模型展现出显著优势。实验表明Reactron不仅能在大规模反应预测基准测试中表现优异，还能通过少量示例学习新反应活性，并探索组合反应空间发现训练数据外的新反应性。该模型兼具分布内和分布外预测的稳健性能，为反应发现和合成设计开辟了新途径。",
      "categories": [
        "physics.chem-ph",
        "cs.AI"
      ],
      "primary_category": "physics.chem-ph",
      "comment": "15 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.10197v1",
      "published_date": "2025-03-13 09:31:51 UTC",
      "updated_date": "2025-03-13 09:31:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:22:36.459874"
    },
    {
      "arxiv_id": "2503.10191v1",
      "title": "Robustness Tokens: Towards Adversarial Robustness of Transformers",
      "title_zh": "鲁棒性令牌：面向Transformer模型的对抗鲁棒性提升",
      "authors": [
        "Brian Pulfer",
        "Yury Belousov",
        "Slava Voloshynovskiy"
      ],
      "abstract": "Recently, large pre-trained foundation models have become widely adopted by\nmachine learning practitioners for a multitude of tasks. Given that such models\nare publicly available, relying on their use as backbone models for downstream\ntasks might result in high vulnerability to adversarial attacks crafted with\nthe same public model. In this work, we propose Robustness Tokens, a novel\napproach specific to the transformer architecture that fine-tunes a few\nadditional private tokens with low computational requirements instead of tuning\nmodel parameters as done in traditional adversarial training. We show that\nRobustness Tokens make Vision Transformer models significantly more robust to\nwhite-box adversarial attacks while also retaining the original downstream\nperformances.",
      "tldr_zh": "本文提出\"Robustness Tokens\"新方法，专门针对Transformer架构，通过微调少量私有token而非传统对抗训练中的模型参数，显著提升Vision Transformer在白盒对抗攻击下的鲁棒性。该方法计算需求低，在保持原有下游任务性能的同时有效防御攻击，解决了大型预训练模型作为骨干网络时面临的对抗脆弱性问题。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "This paper has been accepted for publication at the European\n  Conference on Computer Vision (ECCV), 2024",
      "pdf_url": "http://arxiv.org/pdf/2503.10191v1",
      "published_date": "2025-03-13 09:26:19 UTC",
      "updated_date": "2025-03-13 09:26:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:22:48.240936"
    },
    {
      "arxiv_id": "2503.10186v1",
      "title": "Multi-Agent Q-Learning Dynamics in Random Networks: Convergence due to Exploration and Sparsity",
      "title_zh": "随机网络中的多智能体Q学习动力学：探索性与稀疏性驱动的收敛",
      "authors": [
        "Aamal Hussain",
        "Dan Leonte",
        "Francesco Belardinelli",
        "Raphael Huser",
        "Dario Paccagnan"
      ],
      "abstract": "Beyond specific settings, many multi-agent learning algorithms fail to\nconverge to an equilibrium solution, and instead display complex,\nnon-stationary behaviours such as recurrent or chaotic orbits. In fact, recent\nliterature suggests that such complex behaviours are likely to occur when the\nnumber of agents increases. In this paper, we study Q-learning dynamics in\nnetwork polymatrix games where the network structure is drawn from classical\nrandom graph models. In particular, we focus on the Erdos-Renyi model, a\nwell-studied model for social networks, and the Stochastic Block model, which\ngeneralizes the above by accounting for community structures within the\nnetwork. In each setting, we establish sufficient conditions under which the\nagents' joint strategies converge to a unique equilibrium. We investigate how\nthis condition depends on the exploration rates, payoff matrices and,\ncrucially, the sparsity of the network. Finally, we validate our theoretical\nfindings through numerical simulations and demonstrate that convergence can be\nreliably achieved in many-agent systems, provided network sparsity is\ncontrolled.",
      "tldr_zh": "本文研究了随机网络中的多智能体Q学习动力学，重点分析了Erdos-Renyi模型和Stochastic Block模型下的收敛性。研究表明，通过控制网络稀疏性和探索率，多智能体的联合策略可以收敛到唯一均衡。数值模拟验证了这一理论发现，表明在稀疏网络中，即使智能体数量增加，也能可靠地实现收敛。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.GT",
        "math.DS",
        "93A16, 91A26, 91A68, 58K35",
        "G.3; J.4; F.2.2"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10186v1",
      "published_date": "2025-03-13 09:16:51 UTC",
      "updated_date": "2025-03-13 09:16:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:22:55.712629"
    },
    {
      "arxiv_id": "2503.10183v2",
      "title": "Through the Magnifying Glass: Adaptive Perception Magnification for Hallucination-Free VLM Decoding",
      "title_zh": "《透过放大镜：基于自适应感知放大的无幻觉视觉语言模型解码》",
      "authors": [
        "Shunqi Mao",
        "Chaoyi Zhang",
        "Weidong Cai"
      ],
      "abstract": "Existing vision-language models (VLMs) often suffer from visual\nhallucination, where the generated responses contain inaccuracies that are not\ngrounded in the visual input. Efforts to address this issue without model\nfinetuning primarily mitigate hallucination by reducing biases contrastively or\namplifying the weights of visual embedding during decoding. However, these\napproaches improve visual perception at the cost of impairing the language\nreasoning capability. In this work, we propose the Perception Magnifier (PM), a\nnovel visual decoding method that iteratively isolates relevant visual tokens\nbased on attention and magnifies the corresponding regions, spurring the model\nto concentrate on fine-grained visual details during decoding. Specifically, by\nmagnifying critical regions while preserving the structural and contextual\ninformation at each decoding step, PM allows the VLM to enhance its scrutiny of\nthe visual input, hence producing more accurate and faithful responses.\nExtensive experimental results demonstrate that PM not only achieves superior\nhallucination mitigation but also enhances language generation while preserving\nstrong reasoning capabilities. Code is available at\nhttps://github.com/ShunqiM/PM .",
      "tldr_zh": "该研究提出了一种称为感知放大器（Perception Magnifier, PM）的新型视觉解码方法，旨在解决视觉语言模型（VLMs）中的视觉幻觉问题。PM通过基于注意力机制迭代地隔离相关视觉标记并放大关键区域，促使模型在解码过程中专注于细粒度的视觉细节，同时保留结构和上下文信息。实验结果表明，PM不仅显著减少了幻觉现象，还提升了语言生成能力并保持了强大的推理能力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "19 pages, 5 figures, 9 tables",
      "pdf_url": "http://arxiv.org/pdf/2503.10183v2",
      "published_date": "2025-03-13 09:14:11 UTC",
      "updated_date": "2025-03-14 01:48:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:23:09.517660"
    },
    {
      "arxiv_id": "2503.10166v1",
      "title": "ImageScope: Unifying Language-Guided Image Retrieval via Large Multimodal Model Collective Reasoning",
      "title_zh": "ImageScope：通过大型多模态模型集体推理统一语言引导的图像检索",
      "authors": [
        "Pengfei Luo",
        "Jingbo Zhou",
        "Tong Xu",
        "Yuan Xia",
        "Linli Xu",
        "Enhong Chen"
      ],
      "abstract": "With the proliferation of images in online content, language-guided image\nretrieval (LGIR) has emerged as a research hotspot over the past decade,\nencompassing a variety of subtasks with diverse input forms. While the\ndevelopment of large multimodal models (LMMs) has significantly facilitated\nthese tasks, existing approaches often address them in isolation, requiring the\nconstruction of separate systems for each task. This not only increases system\ncomplexity and maintenance costs, but also exacerbates challenges stemming from\nlanguage ambiguity and complex image content, making it difficult for retrieval\nsystems to provide accurate and reliable results. To this end, we propose\nImageScope, a training-free, three-stage framework that leverages collective\nreasoning to unify LGIR tasks. The key insight behind the unification lies in\nthe compositional nature of language, which transforms diverse LGIR tasks into\na generalized text-to-image retrieval process, along with the reasoning of LMMs\nserving as a universal verification to refine the results. To be specific, in\nthe first stage, we improve the robustness of the framework by synthesizing\nsearch intents across varying levels of semantic granularity using\nchain-of-thought (CoT) reasoning. In the second and third stages, we then\nreflect on retrieval results by verifying predicate propositions locally, and\nperforming pairwise evaluations globally. Experiments conducted on six LGIR\ndatasets demonstrate that ImageScope outperforms competitive baselines.\nComprehensive evaluations and ablation studies further confirm the\neffectiveness of our design.",
      "tldr_zh": "本研究提出ImageScope框架，通过大型多模态模型(LMMs)的集体推理能力统一语言引导图像检索(LGIR)任务。该方法创新性地将多样化的LGIR任务转化为通用文本-图像检索过程，并采用三阶段推理机制：首先通过思维链(CoT)生成多粒度语义搜索意图，随后通过局部谓词验证和全局成对评估优化检索结果。实验表明，这种免训练框架在六个LGIR数据集上超越现有基线，有效解决了语言歧义和复杂图像内容带来的挑战。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.IR",
      "comment": "WWW 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.10166v1",
      "published_date": "2025-03-13 08:43:24 UTC",
      "updated_date": "2025-03-13 08:43:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:23:17.337224"
    },
    {
      "arxiv_id": "2503.10722v1",
      "title": "TacticExpert: Spatial-Temporal Graph Language Model for Basketball Tactics",
      "title_zh": "TacticExpert：面向篮球战术的时空图语言模型",
      "authors": [
        "Xu Lingrui",
        "Liu Mandi",
        "Zhang Lei"
      ],
      "abstract": "The core challenge in basketball tactic modeling lies in efficiently\nextracting complex spatial-temporal dependencies from historical data and\naccurately predicting various in-game events. Existing state-of-the-art (SOTA)\nmodels, primarily based on graph neural networks (GNNs), encounter difficulties\nin capturing long-term, long-distance, and fine-grained interactions among\nheterogeneous player nodes, as well as in recognizing interaction patterns.\nAdditionally, they exhibit limited generalization to untrained downstream tasks\nand zero-shot scenarios. In this work, we propose a Spatial-Temporal\nPropagation Symmetry-Aware Graph Transformer for fine-grained game modeling.\nThis architecture explicitly captures delay effects in the spatial space to\nenhance player node representations across discrete-time slices, employing\nsymmetry-invariant priors to guide the attention mechanism. We also introduce\nan efficient contrastive learning strategy to train a Mixture of Tactics\nExperts module, facilitating differentiated modeling of offensive tactics. By\nintegrating dense training with sparse inference, we achieve a 2.4x improvement\nin model efficiency. Moreover, the incorporation of Lightweight Graph Grounding\nfor Large Language Models enables robust performance in open-ended downstream\ntasks and zero-shot scenarios, including novel teams or players. The proposed\nmodel, TacticExpert, delineates a vertically integrated large model framework\nfor basketball, unifying pretraining across multiple datasets and downstream\nprediction tasks. Fine-grained modeling modules significantly enhance\nspatial-temporal representations, and visualization analyzes confirm the strong\ninterpretability of the model.",
      "tldr_zh": "该研究提出了TacticExpert，一种基于时空图语言模型的篮球战术分析框架。其核心贡献在于设计了一种时空传播对称感知的Graph Transformer，通过显式捕捉空间延迟效应和对称不变性先验，增强了球员节点在离散时间片上的表示。同时，引入对比学习策略训练“战术专家混合模块”，实现了对进攻战术的差异化建模。实验表明，该模型在未训练的下游任务和零样本场景中表现出色，并通过轻量级图嵌入技术提升了大型语言模型在开放式任务中的性能，为篮球战术分析提供了一个统一的大模型框架。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10722v1",
      "published_date": "2025-03-13 08:27:24 UTC",
      "updated_date": "2025-03-13 08:27:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:23:58.910597"
    },
    {
      "arxiv_id": "2503.10721v1",
      "title": "From Understanding to Excelling: Template-Free Algorithm Design through Structural-Functional Co-Evolution",
      "title_zh": "从理解到卓越：通过结构-功能协同演化的无模板算法设计",
      "authors": [
        "Zhe Zhao",
        "Haibin Wen",
        "Pengkun Wang",
        "Ye Wei",
        "Zaixi Zhang",
        "Xi Lin",
        "Fei Liu",
        "Bo An",
        "Hui Xiong",
        "Yang Wang",
        "Qingfu Zhang"
      ],
      "abstract": "Large language models (LLMs) have greatly accelerated the automation of\nalgorithm generation and optimization. However, current methods such as EoH and\nFunSearch mainly rely on predefined templates and expert-specified functions\nthat focus solely on the local evolution of key functionalities. Consequently,\nthey fail to fully leverage the synergistic benefits of the overall\narchitecture and the potential of global optimization. In this paper, we\nintroduce an end-to-end algorithm generation and optimization framework based\non LLMs. Our approach utilizes the deep semantic understanding of LLMs to\nconvert natural language requirements or human-authored papers into code\nsolutions, and employs a two-dimensional co-evolution strategy to optimize both\nfunctional and structural aspects. This closed-loop process spans problem\nanalysis, code generation, and global optimization, automatically identifying\nkey algorithm modules for multi-level joint optimization and continually\nenhancing performance and design innovation. Extensive experiments demonstrate\nthat our method outperforms traditional local optimization approaches in both\nperformance and innovation, while also exhibiting strong adaptability to\nunknown environments and breakthrough potential in structural design. By\nbuilding on human research, our framework generates and optimizes novel\nalgorithms that surpass those designed by human experts, broadening the\napplicability of LLMs for algorithm design and providing a novel solution\npathway for automated algorithm development.",
      "tldr_zh": "该研究提出了一种基于大语言模型(LLMs)的端到端算法生成与优化框架，通过结构与功能协同进化的二维优化策略，突破现有方法依赖预定义模板和局部功能优化的局限。该框架利用LLMs的深度语义理解能力，将自然语言需求或学术论文转化为代码解决方案，并通过闭环设计流程实现从问题分析到全局优化的自动化算法创新。实验表明，该方法在性能表现和结构创新性上均超越传统局部优化方法，不仅能适应未知环境，还可生成超越人类专家设计的新型算法，为自动化算法开发提供了新路径。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "68W20, 68T20",
        "I.2.7"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10721v1",
      "published_date": "2025-03-13 08:26:18 UTC",
      "updated_date": "2025-03-13 08:26:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:23:31.373501"
    },
    {
      "arxiv_id": "2503.10150v1",
      "title": "Retrieval-Augmented Generation with Hierarchical Knowledge",
      "title_zh": "检索增强生成与分层知识架构",
      "authors": [
        "Haoyu Huang",
        "Yongfeng Huang",
        "Junjie Yang",
        "Zhenyu Pan",
        "Yongqiang Chen",
        "Kaili Ma",
        "Hongzhi Chen",
        "James Cheng"
      ],
      "abstract": "Graph-based Retrieval-Augmented Generation (RAG) methods have significantly\nenhanced the performance of large language models (LLMs) in domain-specific\ntasks. However, existing RAG methods do not adequately utilize the naturally\ninherent hierarchical knowledge in human cognition, which limits the\ncapabilities of RAG systems. In this paper, we introduce a new RAG approach,\ncalled HiRAG, which utilizes hierarchical knowledge to enhance the semantic\nunderstanding and structure capturing capabilities of RAG systems in the\nindexing and retrieval processes. Our extensive experiments demonstrate that\nHiRAG achieves significant performance improvements over the state-of-the-art\nbaseline methods. The code of our proposed method is available at\n\\href{https://github.com/hhy-huang/HiRAG}{https://github.com/hhy-huang/HiRAG}.",
      "tldr_zh": "该研究提出了一种名为HiRAG的新型检索增强生成(RAG)方法，利用人类认知中固有的层次化知识来增强语义理解和结构捕捉能力。与现有RAG方法不同，HiRAG在索引和检索过程中专门整合了层次化知识表示，显著提升了领域特定任务的性能表现。实验结果表明，该方法在多项基准测试中优于当前最先进的基线模型，相关代码已在GitHub开源。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10150v1",
      "published_date": "2025-03-13 08:22:31 UTC",
      "updated_date": "2025-03-13 08:22:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:24:07.750690"
    },
    {
      "arxiv_id": "2503.10720v1",
      "title": "AttentionRAG: Attention-Guided Context Pruning in Retrieval-Augmented Generation",
      "title_zh": "AttentionRAG：检索增强生成中注意力引导的上下文剪枝",
      "authors": [
        "Yixiong Fang",
        "Tianran Sun",
        "Yuling Shi",
        "Xiaodong Gu"
      ],
      "abstract": "While RAG demonstrates remarkable capabilities in LLM applications, its\neffectiveness is hindered by the ever-increasing length of retrieved contexts,\nwhich introduces information redundancy and substantial computational overhead.\nExisting context pruning methods, such as LLMLingua, lack contextual awareness\nand offer limited flexibility in controlling compression rates, often resulting\nin either insufficient pruning or excessive information loss. In this paper, we\npropose AttentionRAG, an attention-guided context pruning method for RAG\nsystems. The core idea of AttentionRAG lies in its attention focus mechanism,\nwhich reformulates RAG queries into a next-token prediction paradigm. This\nmechanism isolates the query's semantic focus to a single token, enabling\nprecise and efficient attention calculation between queries and retrieved\ncontexts. Extensive experiments on LongBench and Babilong benchmarks show that\nAttentionRAG achieves up to 6.3$\\times$ context compression while outperforming\nLLMLingua methods by around 10\\% in key metrics.",
      "tldr_zh": "本文提出AttentionRAG，一种基于注意力引导的检索增强生成(RAG)上下文剪枝方法，通过注意力聚焦机制将RAG查询重构为下一词预测范式，有效解决现有方法在上下文冗余和计算开销上的问题。该方法将查询语义聚焦到单个token，实现查询与检索上下文间精确高效的注意力计算。实验表明，在LongBench和Babilong基准测试中，AttentionRAG能实现最高6.3倍的上下文压缩，关键指标比LLMLingua方法提升约10%。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10720v1",
      "published_date": "2025-03-13 08:22:28 UTC",
      "updated_date": "2025-03-13 08:22:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:23:46.037950"
    },
    {
      "arxiv_id": "2503.10144v1",
      "title": "Multiplicative Learning",
      "title_zh": "乘法学习",
      "authors": [
        "Han Kim",
        "Hyungjoon Soh",
        "Vipul Periwal",
        "Junghyo Jo"
      ],
      "abstract": "Efficient training of artificial neural networks remains a key challenge in\ndeep learning. Backpropagation (BP), the standard learning algorithm, relies on\ngradient descent and typically requires numerous iterations for convergence. In\nthis study, we introduce Expectation Reflection (ER), a novel learning approach\nthat updates weights multiplicatively based on the ratio of observed to\npredicted outputs. Unlike traditional methods, ER maintains consistency without\nrequiring ad hoc loss functions or learning rate hyperparameters. We extend ER\nto multilayer networks and demonstrate its effectiveness in performing image\nclassification tasks. Notably, ER achieves optimal weight updates in a single\niteration. Additionally, we reinterpret ER as a modified form of gradient\ndescent incorporating the inverse mapping of target propagation. These findings\nsuggest that ER provides an efficient and scalable alternative for training\nneural networks.",
      "tldr_zh": "该研究提出了一种新颖的神经网络训练方法——期望反射（Expectation Reflection, ER），通过基于观察输出与预测输出比率的乘法权重更新机制，显著提升了训练效率。与传统的反向传播（BP）算法不同，ER无需自定义损失函数或学习率超参数，且能在单次迭代中实现最优权重更新。研究还将ER扩展到多层网络，并在图像分类任务中验证了其有效性，表明ER是一种高效且可扩展的神经网络训练替代方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10144v1",
      "published_date": "2025-03-13 08:14:00 UTC",
      "updated_date": "2025-03-13 08:14:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:24:01.602180"
    },
    {
      "arxiv_id": "2503.11514v1",
      "title": "Exploring the Vulnerabilities of Federated Learning: A Deep Dive into Gradient Inversion Attacks",
      "title_zh": "探索联邦学习的脆弱性：梯度反演攻击深度剖析",
      "authors": [
        "Pengxin Guo",
        "Runxi Wang",
        "Shuang Zeng",
        "Jinjing Zhu",
        "Haoning Jiang",
        "Yanran Wang",
        "Yuyin Zhou",
        "Feifei Wang",
        "Hui Xiong",
        "Liangqiong Qu"
      ],
      "abstract": "Federated Learning (FL) has emerged as a promising privacy-preserving\ncollaborative model training paradigm without sharing raw data. However, recent\nstudies have revealed that private information can still be leaked through\nshared gradient information and attacked by Gradient Inversion Attacks (GIA).\nWhile many GIA methods have been proposed, a detailed analysis, evaluation, and\nsummary of these methods are still lacking. Although various survey papers\nsummarize existing privacy attacks in FL, few studies have conducted extensive\nexperiments to unveil the effectiveness of GIA and their associated limiting\nfactors in this context. To fill this gap, we first undertake a systematic\nreview of GIA and categorize existing methods into three types, i.e.,\n\\textit{optimization-based} GIA (OP-GIA), \\textit{generation-based} GIA\n(GEN-GIA), and \\textit{analytics-based} GIA (ANA-GIA). Then, we comprehensively\nanalyze and evaluate the three types of GIA in FL, providing insights into the\nfactors that influence their performance, practicality, and potential threats.\nOur findings indicate that OP-GIA is the most practical attack setting despite\nits unsatisfactory performance, while GEN-GIA has many dependencies and ANA-GIA\nis easily detectable, making them both impractical. Finally, we offer a\nthree-stage defense pipeline to users when designing FL frameworks and\nprotocols for better privacy protection and share some future research\ndirections from the perspectives of attackers and defenders that we believe\nshould be pursued. We hope that our study can help researchers design more\nrobust FL frameworks to defend against these attacks.",
      "tldr_zh": "该论文系统研究了联邦学习(FL)中的梯度反演攻击(GIA)漏洞。研究将现有GIA方法分为三类——基于优化的OP-GIA、基于生成的GEN-GIA和基于分析的ANA-GIA，并通过实验揭示了各类方法的有效性及限制因素。研究发现，OP-GIA虽效果有限但最具实用性，而GEN-GIA依赖条件多、ANA-GIA易被检测，两者均不实用。最后，论文提出了三阶段防御方案，并从攻防双方视角指出了未来研究方向，为设计更鲁棒的联邦学习框架提供了重要参考。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.11514v1",
      "published_date": "2025-03-13 08:08:44 UTC",
      "updated_date": "2025-03-13 08:08:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:24:05.684376"
    },
    {
      "arxiv_id": "2503.10135v1",
      "title": "Gumiho: A Hybrid Architecture to Prioritize Early Tokens in Speculative Decoding",
      "title_zh": "Gumiho：一种混合架构优先处理推测解码中的早期令牌",
      "authors": [
        "Jinze Li",
        "Yixing Xu",
        "Haiduo Huang",
        "Xuanwu Yin",
        "Dong Li",
        "Edith C. H. Ngai",
        "Emad Barsoum"
      ],
      "abstract": "Speculative decoding (SPD) aims to accelerate the auto-regressive token\ngeneration process of a target Large Language Model (LLM). Some approaches\nemploy a draft model with multiple heads to predict a sequence of future\ntokens, where each head handles a token in the sequence. The target LLM\nverifies the predicted sequence and accepts aligned tokens, enabling efficient\nmulti-token generation. However, existing methods assume that all tokens within\na sequence are equally important, employing identical head structures and\nrelying on a single-generation paradigm, either serial or parallel. To this\nend, we theoretically demonstrate that initial tokens in the draft sequence are\nmore important than later ones. Building on this insight, we propose Gumiho, a\nhybrid model combining serial and parallel heads. Specifically, given the\ncritical importance of early tokens, we employ a sophisticated Transformer\narchitecture for the early draft heads in a serial configuration to improve\naccuracy. For later tokens, we utilize multiple lightweight MLP heads operating\nin parallel to enhance efficiency. By allocating more advanced model structures\nand longer running times to the early heads, Gumiho achieves improved overall\nperformance. The experimental results demonstrate that our method outperforms\nexisting approaches, fully validating its effectiveness.",
      "tldr_zh": "本研究提出了Gumiho，一种混合架构，用于在推测解码(Speculative Decoding)中优先处理早期token。通过理论分析，作者发现序列中的早期token比后期token更为重要。基于这一洞察，Gumiho结合了串行和并行头：对早期token采用复杂的Transformer架构以提高准确性，而对后期token则使用轻量级MLP头以提升效率。实验结果表明，Gumiho在整体性能上优于现有方法，验证了其有效性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Paper under review",
      "pdf_url": "http://arxiv.org/pdf/2503.10135v1",
      "published_date": "2025-03-13 07:55:38 UTC",
      "updated_date": "2025-03-13 07:55:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:24:34.748890"
    },
    {
      "arxiv_id": "2503.10129v1",
      "title": "Deep Learning-Based Direct Leaf Area Estimation using Two RGBD Datasets for Model Development",
      "title_zh": "基于深度学习的直接叶片面积估计：利用两个RGBD数据集进行模型开发",
      "authors": [
        "Namal Jayasuriya",
        "Yi Guo",
        "Wen Hu",
        "Oula Ghannoum"
      ],
      "abstract": "Estimation of a single leaf area can be a measure of crop growth and a\nphenotypic trait to breed new varieties. It has also been used to measure leaf\narea index and total leaf area. Some studies have used hand-held cameras, image\nprocessing 3D reconstruction and unsupervised learning-based methods to\nestimate the leaf area in plant images. Deep learning works well for object\ndetection and segmentation tasks; however, direct area estimation of objects\nhas not been explored. This work investigates deep learning-based leaf area\nestimation, for RGBD images taken using a mobile camera setup in real-world\nscenarios. A dataset for attached leaves captured with a top angle view and a\ndataset for detached single leaves were collected for model development and\ntesting. First, image processing-based area estimation was tested on manually\nsegmented leaves. Then a Mask R-CNN-based model was investigated, and modified\nto accept RGBD images and to estimate the leaf area. The detached-leaf data set\nwas then mixed with the attached-leaf plant data set to estimate the single\nleaf area for plant images, and another network design with two backbones was\nproposed: one for segmentation and the other for area estimation. Instead of\ntrying all possibilities or random values, an agile approach was used in\nhyperparameter tuning. The final model was cross-validated with 5-folds and\ntested with two unseen datasets: detached and attached leaves. The F1 score\nwith 90% IoA for segmentation result on unseen detached-leaf data was 1.0,\nwhile R-squared of area estimation was 0.81. For unseen plant data\nsegmentation, the F1 score with 90% IoA was 0.59, while the R-squared score was\n0.57. The research suggests using attached leaves with ground truth area to\nimprove the results.",
      "tldr_zh": "该研究提出了一种基于深度学习的直接叶片面积估计方法，使用RGBD图像和两种数据集（附着叶片和分离叶片）进行模型开发。研究人员将Mask R-CNN模型改进为可处理RGBD图像的双主干网络架构，分别负责叶片分割和面积估计。实验表明，该方法在分离叶片数据集上取得了优异效果（分割F1分数1.0，面积估计R² 0.81），而在植物附着叶片场景中表现稍弱（R² 0.57）。研究建议通过增加带真实标注的附着叶片数据来进一步提升模型性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10129v1",
      "published_date": "2025-03-13 07:39:09 UTC",
      "updated_date": "2025-03-13 07:39:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:24:30.517160"
    },
    {
      "arxiv_id": "2503.10718v1",
      "title": "Team NYCU at Defactify4: Robust Detection and Source Identification of AI-Generated Images Using CNN and CLIP-Based Models",
      "title_zh": "NYCU团队在Defactify4竞赛：基于CNN与CLIP模型的AI生成图像鲁棒检测及来源识别",
      "authors": [
        "Tsan-Tsung Yang",
        "I-Wei Chen",
        "Kuan-Ting Chen",
        "Shang-Hsuan Chiang",
        "Wen-Chih Peng"
      ],
      "abstract": "With the rapid advancement of generative AI, AI-generated images have become\nincreasingly realistic, raising concerns about creativity, misinformation, and\ncontent authenticity. Detecting such images and identifying their source models\nhas become a critical challenge in ensuring the integrity of digital media.\nThis paper tackles the detection of AI-generated images and identifying their\nsource models using CNN and CLIP-ViT classifiers. For the CNN-based classifier,\nwe leverage EfficientNet-B0 as the backbone and feed with RGB channels,\nfrequency features, and reconstruction errors, while for CLIP-ViT, we adopt a\npretrained CLIP image encoder to extract image features and SVM to perform\nclassification. Evaluated on the Defactify 4 dataset, our methods demonstrate\nstrong performance in both tasks, with CLIP-ViT showing superior robustness to\nimage perturbations. Compared to baselines like AEROBLADE and OCC-CLIP, our\napproach achieves competitive results. Notably, our method ranked Top-3 overall\nin the Defactify 4 competition, highlighting its effectiveness and\ngeneralizability. All of our implementations can be found in\nhttps://github.com/uuugaga/Defactify_4",
      "tldr_zh": "该研究提出了一种基于CNN和CLIP-ViT模型的AI生成图像检测与来源识别方法。使用EfficientNet-B0结合RGB通道、频域特征和重建误差进行检测，同时采用预训练的CLIP图像编码器和SVM分类器进行来源识别。实验表明，该方法在Defactify 4数据集上表现出色，特别是CLIP-ViT对图像扰动的鲁棒性更强，并在Defactify 4竞赛中取得了Top-3的成绩。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10718v1",
      "published_date": "2025-03-13 07:21:16 UTC",
      "updated_date": "2025-03-13 07:21:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:24:40.644435"
    },
    {
      "arxiv_id": "2503.10110v1",
      "title": "IMPACT: Intelligent Motion Planning with Acceptable Contact Trajectories via Vision-Language Models",
      "title_zh": "IMPACT：基于视觉语言模型的可接受接触轨迹智能运动规划",
      "authors": [
        "Yiyang Ling",
        "Karan Owalekar",
        "Oluwatobiloba Adesanya",
        "Erdem Bıyık",
        "Daniel Seita"
      ],
      "abstract": "Motion planning involves determining a sequence of robot configurations to\nreach a desired pose, subject to movement and safety constraints. Traditional\nmotion planning finds collision-free paths, but this is overly restrictive in\nclutter, where it may not be possible for a robot to accomplish a task without\ncontact. In addition, contacts range from relatively benign (e.g., brushing a\nsoft pillow) to more dangerous (e.g., toppling a glass vase). Due to this\ndiversity, it is difficult to characterize which contacts may be acceptable or\nunacceptable. In this paper, we propose IMPACT, a novel motion planning\nframework that uses Vision-Language Models (VLMs) to infer environment\nsemantics, identifying which parts of the environment can best tolerate contact\nbased on object properties and locations. Our approach uses the VLM's outputs\nto produce a dense 3D \"cost map\" that encodes contact tolerances and seamlessly\nintegrates with standard motion planners. We perform experiments using 20\nsimulation and 10 real-world scenes and assess using task success rate, object\ndisplacements, and feedback from human evaluators. Our results over 3620\nsimulation and 200 real-world trials suggest that IMPACT enables efficient\ncontact-rich motion planning in cluttered settings while outperforming\nalternative methods and ablations. Supplementary material is available at\nhttps://impact-planning.github.io/.",
      "tldr_zh": "该研究提出IMPACT框架，利用视觉语言模型(VLMs)实现智能运动规划，通过分析环境语义识别可接触区域。该方法创新性地构建3D\"代价地图\"编码接触容忍度，兼容传统运动规划器，在20个仿真和10个真实场景测试中表现优异。实验数据显示，3620次仿真和200次现实试验证明IMPACT在杂乱环境下能高效完成接触密集型任务，在任务成功率、物体位移和人工评估方面均优于基准方法。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10110v1",
      "published_date": "2025-03-13 07:09:00 UTC",
      "updated_date": "2025-03-13 07:09:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:24:50.900297"
    },
    {
      "arxiv_id": "2503.10105v1",
      "title": "StepMathAgent: A Step-Wise Agent for Evaluating Mathematical Processes through Tree-of-Error",
      "title_zh": "StepMathAgent：基于错误树的分步式数学过程评估智能体",
      "authors": [
        "Shu-Xun Yang",
        "Cunxiang Wang",
        "Yidong Wang",
        "Xiaotao Gu",
        "Minlie Huang",
        "Jie Tang"
      ],
      "abstract": "Evaluating mathematical capabilities is critical for assessing the overall\nperformance of large language models (LLMs). However, existing evaluation\nmethods often focus solely on final answers, resulting in highly inaccurate and\nuninterpretable evaluation outcomes, as well as their failure to assess proof\nor open-ended problems. To address these issues, we propose a novel\nmathematical process evaluation agent based on Tree-of-Error, called\nStepMathAgent. This agent incorporates four internal core operations: logical\nstep segmentation, step scoring, score aggregation and error tree generation,\nalong with four external extension modules: difficulty calibration, simplicity\nevaluation, completeness validation and format assessment. Furthermore, we\nintroduce StepMathBench, a benchmark comprising 1,000 step-divided process\nevaluation instances, derived from 200 high-quality math problems grouped by\nproblem type, subject category and difficulty level. Experiments on\nStepMathBench show that our proposed StepMathAgent outperforms all\nstate-of-the-art methods, demonstrating human-aligned evaluation preferences\nand broad applicability to various scenarios. Our data and code are available\nat https://github.com/SHU-XUN/StepMathAgent.",
      "tldr_zh": "该研究提出StepMathAgent，一种基于\"错误树\"(Tree-of-Error)的数学过程分步评估智能体，旨在解决现有大语言模型(LLMs)数学能力评估仅关注最终答案的局限性。该系统通过四大核心操作(逻辑步骤分割、步骤评分、分数聚合和错误树生成)和四大扩展模块(难度校准、简洁性评估、完整性验证和格式检查)，实现了对数学解题过程的细粒度评估。研究者还构建了包含1000个分步评估实例的StepMathBench基准测试集，实验表明该智能体优于现有方法，其评估偏好与人类对齐，具有广泛适用性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10105v1",
      "published_date": "2025-03-13 07:02:53 UTC",
      "updated_date": "2025-03-13 07:02:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:24:58.436119"
    },
    {
      "arxiv_id": "2503.10717v1",
      "title": "Deep Learning-Based Automated Workflow for Accurate Segmentation and Measurement of Abdominal Organs in CT Scans",
      "title_zh": "基于深度学习的CT扫描腹部器官精准分割与测量自动化工作流",
      "authors": [
        "Praveen Shastry",
        "Ashok Sharma",
        "Kavya Mohan",
        "Naveen Kumarasami",
        "Anandakumar D",
        "Mounigasri M",
        "Keerthana R",
        "Kishore Prasath Venkatesh",
        "Bargava Subramanian",
        "Kalyan Sivasailam"
      ],
      "abstract": "Background: Automated analysis of CT scans for abdominal organ measurement is\ncrucial for improving diagnostic efficiency and reducing inter-observer\nvariability. Manual segmentation and measurement of organs such as the kidneys,\nliver, spleen, and prostate are time-consuming and subject to inconsistency,\nunderscoring the need for automated approaches.\n  Purpose: The purpose of this study is to develop and validate an automated\nworkflow for the segmentation and measurement of abdominal organs in CT scans\nusing advanced deep learning models, in order to improve accuracy, reliability,\nand efficiency in clinical evaluations.\n  Methods: The proposed workflow combines nnU-Net, U-Net++ for organ\nsegmentation, followed by a 3D RCNN model for measuring organ volumes and\ndimensions. The models were trained and evaluated on CT datasets with metrics\nsuch as precision, recall, and Mean Squared Error (MSE) to assess performance.\nSegmentation quality was verified for its adaptability to variations in patient\nanatomy and scanner settings.\n  Results: The developed workflow achieved high precision and recall values,\nexceeding 95 for all targeted organs. The Mean Squared Error (MSE) values were\nlow, indicating a high level of consistency between predicted and ground truth\nmeasurements. The segmentation and measurement pipeline demonstrated robust\nperformance, providing accurate delineation and quantification of the kidneys,\nliver, spleen, and prostate.\n  Conclusion: The proposed approach offers an automated, efficient, and\nreliable solution for abdominal organ measurement in CT scans. By significantly\nreducing manual intervention, this workflow enhances measurement accuracy and\nconsistency, with potential for widespread clinical implementation. Future work\nwill focus on expanding the approach to other organs and addressing complex\npathological cases.",
      "tldr_zh": "该研究开发了一种基于深度学习的自动化工作流，用于精准分割和测量CT扫描中的腹部器官（如肾脏、肝脏、脾脏和前列腺）。该工作流结合了nnU-Net、U-Net++进行器官分割，以及3D RCNN模型进行器官体积和尺寸测量，在多个数据集上验证了其高精度（超过95%）和低误差（MSE值低）。该方法显著减少了人工干预，提高了测量的一致性和效率，具有广泛的临床应用潜力。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "68T99"
      ],
      "primary_category": "eess.IV",
      "comment": "13 pages , 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.10717v1",
      "published_date": "2025-03-13 06:50:44 UTC",
      "updated_date": "2025-03-13 06:50:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:25:00.600315"
    },
    {
      "arxiv_id": "2503.10095v1",
      "title": "Cognitive-Mental-LLM: Leveraging Reasoning in Large Language Models for Mental Health Prediction via Online Text",
      "title_zh": "认知-心理-大语言模型：利用大型语言模型推理能力通过在线文本预测心理健康",
      "authors": [
        "Avinash Patil",
        "Amardeep Kour Gedhu"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated potential in predicting mental\nhealth outcomes from online text, yet traditional classification methods often\nlack interpretability and robustness. This study evaluates structured reasoning\ntechniques-Chain-of-Thought (CoT), Self-Consistency (SC-CoT), and\nTree-of-Thought (ToT)-to improve classification accuracy across multiple mental\nhealth datasets sourced from Reddit. We analyze reasoning-driven prompting\nstrategies, including Zero-shot CoT and Few-shot CoT, using key performance\nmetrics such as Balanced Accuracy, F1 score, and Sensitivity/Specificity. Our\nfindings indicate that reasoning-enhanced techniques improve classification\nperformance over direct prediction, particularly in complex cases. Compared to\nbaselines such as Zero Shot non-CoT Prompting, and fine-tuned pre-trained\ntransformers such as BERT and Mental-RoBerta, and fine-tuned Open Source LLMs\nsuch as Mental Alpaca and Mental-Flan-T5, reasoning-driven LLMs yield notable\ngains on datasets like Dreaddit (+0.52\\% over M-LLM, +0.82\\% over BERT) and\nSDCNL (+4.67\\% over M-LLM, +2.17\\% over BERT). However, performance declines in\nDepression Severity, and CSSRS predictions suggest dataset-specific\nlimitations, likely due to our using a more extensive test set. Among prompting\nstrategies, Few-shot CoT consistently outperforms others, reinforcing the\neffectiveness of reasoning-driven LLMs. Nonetheless, dataset variability\nhighlights challenges in model reliability and interpretability. This study\nprovides a comprehensive benchmark of reasoning-based LLM techniques for mental\nhealth text classification. It offers insights into their potential for\nscalable clinical applications while identifying key challenges for future\nimprovements.",
      "tldr_zh": "本研究提出Cognitive-Mental-LLM框架，通过整合链式思维(CoT)、自洽推理(SC-CoT)和树状思维(ToT)等结构化推理技术，显著提升了大型语言模型(LLM)在心理健康文本分类中的表现。实验表明，该框架在Reddit的Dreaddit和SDCNL数据集上分别比基准模型(M-LLM/BERT)最高提升4.67%准确率，其中Few-shot CoT提示策略表现最优。研究同时发现模型在抑郁症严重程度预测等任务中存在数据集特异性局限，为临床级心理健康应用提供了重要技术基准与改进方向。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages, 4 Figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2503.10095v1",
      "published_date": "2025-03-13 06:42:37 UTC",
      "updated_date": "2025-03-13 06:42:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:25:10.852253"
    },
    {
      "arxiv_id": "2503.10094v1",
      "title": "Semantic Synergy: Unlocking Policy Insights and Learning Pathways Through Advanced Skill Mapping",
      "title_zh": "语义协同：通过先进技能映射解锁政策洞见与学习路径",
      "authors": [
        "Phoebe Koundouri",
        "Conrad Landis",
        "Georgios Feretzakis"
      ],
      "abstract": "This research introduces a comprehensive system based on state-of-the-art\nnatural language processing, semantic embedding, and efficient search\ntechniques for retrieving similarities and thus generating actionable insights\nfrom raw textual information. The system automatically extracts and aggregates\nnormalized competencies from multiple documents (such as policy files and\ncurricula vitae) and creates strong relationships between recognized\ncompetencies, occupation profiles, and related learning courses. To validate\nits performance, we conducted a multi-tier evaluation that included both\nexplicit and implicit skill references in synthetic and real-world documents.\nThe results showed near-human-level accuracy, with F1 scores exceeding 0.95 for\nexplicit skill detection and above 0.93 for implicit mentions. The system\nthereby establishes a sound foundation for supporting in-depth collaboration\nacross the AE4RIA network. The methodology involves a multi-stage pipeline\nbased on extensive preprocessing and data cleaning, semantic embedding and\nsegmentation via SentenceTransformer, and skill extraction using a FAISS-based\nsearch method. The extracted skills are associated with occupation frameworks\n(as formulated in the ESCO ontology) and with learning paths offered through\nthe Sustainable Development Goals Academy. Moreover, interactive visualization\nsoftware, implemented with Dash and Plotly, presents graphs and tables for\nreal-time exploration and informed decision-making by those involved in\npolicymaking, training and learning supply, career transitions, and\nrecruitment. Overall, this system, backed by rigorous validation, offers\npromising prospects for improved policymaking, human resource development, and\nlifelong learning by providing structured and actionable insights from raw,\ncomplex textual information.",
      "tldr_zh": "本研究提出了一种基于自然语言处理、语义嵌入和高效搜索技术的综合系统，用于从原始文本信息中提取相似性并生成可操作的洞察。该系统能够自动从多种文档（如政策文件和简历）中提取并聚合标准化能力，建立能力、职业档案和相关学习课程之间的强关联。通过多层次的评估，系统在显性和隐性技能检测上表现出接近人类水平的准确性，F1分数分别超过0.95和0.93。该系统为政策制定、人力资源开发和终身学习提供了结构化且可操作的洞察，支持AE4RIA网络的深入协作。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "68T50",
        "I.2.7"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10094v1",
      "published_date": "2025-03-13 06:41:26 UTC",
      "updated_date": "2025-03-13 06:41:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:25:34.176853"
    },
    {
      "arxiv_id": "2503.13504v1",
      "title": "CoCMT: Communication-Efficient Cross-Modal Transformer for Collaborative Perception",
      "title_zh": "CoCMT：面向协作感知的高效通信跨模态Transformer",
      "authors": [
        "Rujia Wang",
        "Xiangbo Gao",
        "Hao Xiang",
        "Runsheng Xu",
        "Zhengzhong Tu"
      ],
      "abstract": "Multi-agent collaborative perception enhances each agent perceptual\ncapabilities by sharing sensing information to cooperatively perform robot\nperception tasks. This approach has proven effective in addressing challenges\nsuch as sensor deficiencies, occlusions, and long-range perception. However,\nexisting representative collaborative perception systems transmit intermediate\nfeature maps, such as bird-eye view (BEV) representations, which contain a\nsignificant amount of non-critical information, leading to high communication\nbandwidth requirements. To enhance communication efficiency while preserving\nperception capability, we introduce CoCMT, an object-query-based collaboration\nframework that optimizes communication bandwidth by selectively extracting and\ntransmitting essential features. Within CoCMT, we introduce the Efficient Query\nTransformer (EQFormer) to effectively fuse multi-agent object queries and\nimplement a synergistic deep supervision to enhance the positive reinforcement\nbetween stages, leading to improved overall performance. Experiments on OPV2V\nand V2V4Real datasets show CoCMT outperforms state-of-the-art methods while\ndrastically reducing communication needs. On V2V4Real, our model (Top-50 object\nqueries) requires only 0.416 Mb bandwidth, 83 times less than SOTA methods,\nwhile improving AP70 by 1.1 percent. This efficiency breakthrough enables\npractical collaborative perception deployment in bandwidth-constrained\nenvironments without sacrificing detection accuracy.",
      "tldr_zh": "本文提出了CoCMT，一种基于对象查询的跨模态Transformer框架，旨在解决多智能体协同感知中的通信效率问题。该方法通过选择性提取和传输关键特征（而非传统中间特征图），大幅降低带宽需求，在V2V4Real数据集上仅需0.416Mb带宽（比现有方法减少83倍）。核心创新包括高效查询Transformer(EQFormer)和协同深度监督机制，实验表明在保持检测精度（AP70提升1.1%）的同时实现了通信效率的突破性提升，为带宽受限环境下的协同感知部署提供了可行方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.13504v1",
      "published_date": "2025-03-13 06:41:25 UTC",
      "updated_date": "2025-03-13 06:41:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:25:29.703240"
    },
    {
      "arxiv_id": "2503.10075v1",
      "title": "Parallelizing Multi-objective A* Search",
      "title_zh": "多目标A*搜索的并行化",
      "authors": [
        "Saman Ahmadi",
        "Nathan R. Sturtevant",
        "Andrea Raith",
        "Daniel Harabor",
        "Mahdi Jalili"
      ],
      "abstract": "The Multi-objective Shortest Path (MOSP) problem is a classic network\noptimization problem that aims to find all Pareto-optimal paths between two\npoints in a graph with multiple edge costs. Recent studies on multi-objective\nsearch with A* (MOA*) have demonstrated superior performance in solving\ndifficult MOSP instances. This paper presents a novel search framework that\nallows efficient parallelization of MOA* with different objective orders. The\nframework incorporates a unique upper bounding strategy that helps the search\nreduce the problem's dimensionality to one in certain cases. Experimental\nresults demonstrate that the proposed framework can enhance the performance of\nrecent A*-based solutions, with the speed-up proportional to the problem\ndimension.",
      "tldr_zh": "本研究提出了一种新的并行化框架，用于优化多目标A*搜索（MOA*）算法，以解决多目标最短路径（MOSP）问题。该框架通过引入独特的上限策略，在某些情况下将问题维度简化为一维，从而显著提升搜索效率。实验结果表明，该框架能够加速现有A*算法的性能，且加速效果与问题维度成正比。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "8 page, 2 tables, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.10075v1",
      "published_date": "2025-03-13 05:43:49 UTC",
      "updated_date": "2025-03-13 05:43:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:25:50.865128"
    },
    {
      "arxiv_id": "2503.10071v1",
      "title": "Advanced Tool Learning and Selection System (ATLASS): A Closed-Loop Framework Using LLM",
      "title_zh": "先进工具学习与选择系统（ATLASS）：基于大语言模型的闭环框架",
      "authors": [
        "Mohd Ariful Haque",
        "Justin Williams",
        "Sunzida Siddique",
        "Md. Hujaifa Islam",
        "Hasmot Ali",
        "Kishor Datta Gupta",
        "Roy George"
      ],
      "abstract": "The combination of LLM agents with external tools enables models to solve\ncomplex tasks beyond their knowledge base. Human-designed tools are inflexible\nand restricted to solutions within the scope of pre-existing tools created by\nexperts. To address this problem, we propose ATLASS, an advanced tool learning\nand selection system designed as a closed-loop framework. It enables the LLM to\nsolve problems by dynamically generating external tools on demand. In this\nframework, agents play a crucial role in orchestrating tool selection,\nexecution, and refinement, ensuring adaptive problem-solving capabilities. The\noperation of ATLASS follows three phases: The first phase, Understanding Tool\nRequirements, involves the Agents determining whether tools are required and\nspecifying their functionality; the second phase, Tool Retrieval/Generation,\ninvolves the Agents retrieving or generating tools based on their availability;\nand the third phase, Task Solving, involves combining all the component tools\nnecessary to complete the initial task. The Tool Dataset stores the generated\ntools, ensuring reusability and minimizing inference cost. Current LLM-based\ntool generation systems have difficulty creating complex tools that need APIs\nor external packages. In ATLASS, we solve the problem by automatically setting\nup the environment, fetching relevant API documentation online, and using a\nPython interpreter to create a reliable, versatile tool that works in a wider\nrange of situations. OpenAI GPT-4.0 is used as the LLM agent, and safety and\nethical concerns are handled through human feedback before executing generated\ncode. By addressing the limitations of predefined toolsets and enhancing\nadaptability, ATLASS serves as a real-world solution that empowers users with\ndynamically generated tools for complex problem-solving.",
      "tldr_zh": "本研究提出了ATLASS（Advanced Tool Learning and Selection System），一种基于大语言模型（LLM）的闭环框架，旨在动态生成外部工具以解决复杂任务。ATLASS通过三个阶段运作：理解工具需求、工具检索/生成和任务解决，并结合工具数据集实现工具复用和成本优化。该框架解决了现有工具生成系统在创建复杂工具（如需要API或外部包）时的困难，通过自动设置环境、获取API文档并使用Python解释器生成可靠工具。实验表明，ATLASS增强了LLM的适应性和问题解决能力，为复杂任务提供了动态工具生成的实际解决方案。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10071v1",
      "published_date": "2025-03-13 05:39:00 UTC",
      "updated_date": "2025-03-13 05:39:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:26:15.047315"
    },
    {
      "arxiv_id": "2503.10070v1",
      "title": "AhaRobot: A Low-Cost Open-Source Bimanual Mobile Manipulator for Embodied AI",
      "title_zh": "AhaRobot：面向具身AI的低成本开源双手移动操作机器人",
      "authors": [
        "Haiqin Cui",
        "Yifu Yuan",
        "Yan Zheng",
        "Jianye Hao"
      ],
      "abstract": "Navigation and manipulation in open-world environments remain unsolved\nchallenges in the Embodied AI. The high cost of commercial mobile manipulation\nrobots significantly limits research in real-world scenes. To address this\nissue, we propose AhaRobot, a low-cost and fully open-source dual-arm mobile\nmanipulation robot system with a hardware cost of only $1,000 (excluding\noptional computational resources), which is less than 1/15 of the cost of\npopular mobile robots. The AhaRobot system consists of three components: (1) a\nnovel low-cost hardware architecture primarily composed of off-the-shelf\ncomponents, (2) an optimized control solution to enhance operational precision\nintegrating dual-motor backlash control and static friction compensation, and\n(3) a simple remote teleoperation method RoboPilot. We use handles to control\nthe dual arms and pedals for whole-body movement. The teleoperation process is\nlow-burden and easy to operate, much like piloting. RoboPilot is designed for\nremote data collection in embodied scenarios. Experimental results demonstrate\nthat RoboPilot significantly enhances data collection efficiency in complex\nmanipulation tasks, achieving a 30% increase compared to methods using 3D mouse\nand leader-follower systems. It also excels at completing extremely\nlong-horizon tasks in one go. Furthermore, AhaRobot can be used to learn\nend-to-end policies and autonomously perform complex manipulation tasks, such\nas pen insertion and cleaning up the floor. We aim to build an affordable yet\npowerful platform to promote the development of embodied tasks on real devices,\nadvancing more robust and reliable embodied AI. All hardware and software\nsystems are available at https://aha-robot.github.io.",
      "tldr_zh": "该研究提出了AhaRobot——一款低成本（仅1000美元）、完全开源的**双臂移动操作机器人系统**，旨在解决具身AI研究中商用机器人成本过高的问题。该系统包含三大创新：(1) 主要由现成组件构成的低成本硬件架构，(2) 集成双电机反向间隙控制与静摩擦补偿的优化控制方案，(3) 类似驾驶操作的简易远程遥操作方案RoboPilot。实验表明，RoboPilot在复杂操作任务中的数据收集效率比传统方法提升30%，并能一次性完成超长程任务。该平台已成功应用于端到端策略学习，实现钢笔插入、地面清洁等复杂操作，为具身AI研究提供了经济高效的硬件解决方案。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "The first two authors contributed equally. Website:\n  https://aha-robot.github.io",
      "pdf_url": "http://arxiv.org/pdf/2503.10070v1",
      "published_date": "2025-03-13 05:34:43 UTC",
      "updated_date": "2025-03-13 05:34:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:26:13.945022"
    },
    {
      "arxiv_id": "2503.10061v2",
      "title": "Compute Optimal Scaling of Skills: Knowledge vs Reasoning",
      "title_zh": "技能计算最优缩放：知识能力与推理能力的对比",
      "authors": [
        "Nicholas Roberts",
        "Niladri Chatterji",
        "Sharan Narang",
        "Mike Lewis",
        "Dieuwke Hupkes"
      ],
      "abstract": "Scaling laws are a critical component of the LLM development pipeline, most\nfamously as a way to forecast training decisions such as 'compute-optimally'\ntrading-off parameter count and dataset size, alongside a more recent growing\nlist of other crucial decisions. In this work, we ask whether compute-optimal\nscaling behaviour can be skill-dependent. In particular, we examine knowledge\nand reasoning-based skills such as knowledge-based QA and code generation, and\nwe answer this question in the affirmative: scaling laws are skill-dependent.\nNext, to understand whether skill-dependent scaling is an artefact of the\npretraining datamix, we conduct an extensive ablation of different datamixes\nand find that, also when correcting for datamix differences, knowledge and code\nexhibit fundamental differences in scaling behaviour. We conclude with an\nanalysis of how our findings relate to standard compute-optimal scaling using a\nvalidation set, and find that a misspecified validation set can impact\ncompute-optimal parameter count by nearly 50%, depending on its skill\ncomposition.",
      "tldr_zh": "这项研究探讨了大语言模型(LLM)中不同技能(如知识问答和代码生成)在计算最优扩展(compute-optimal scaling)上的差异。研究发现，基于知识的技能和推理类技能具有根本不同的扩展规律，且这种差异并非源于预训练数据混合比例。验证实验表明，若验证集的技能组成不当，可能导致计算最优参数数量偏差高达50%，强调在模型扩展时需考虑技能特异性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10061v2",
      "published_date": "2025-03-13 05:21:22 UTC",
      "updated_date": "2025-03-14 01:39:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:26:41.498854"
    },
    {
      "arxiv_id": "2503.10058v1",
      "title": "Deep Learning Approaches for Anti-Money Laundering on Mobile Transactions: Review, Framework, and Directions",
      "title_zh": "深度学习在移动交易反洗钱中的应用：综述、框架与方向",
      "authors": [
        "Jiani Fan",
        "Lwin Khin Shar",
        "Ruichen Zhang",
        "Ziyao Liu",
        "Wenzhuo Yang",
        "Dusit Niyato",
        "Bomin Mao",
        "Kwok-Yan Lam"
      ],
      "abstract": "Money laundering is a financial crime that obscures the origin of illicit\nfunds, necessitating the development and enforcement of anti-money laundering\n(AML) policies by governments and organizations. The proliferation of mobile\npayment platforms and smart IoT devices has significantly complicated AML\ninvestigations. As payment networks become more interconnected, there is an\nincreasing need for efficient real-time detection to process large volumes of\ntransaction data on heterogeneous payment systems by different operators such\nas digital currencies, cryptocurrencies and account-based payments. Most of\nthese mobile payment networks are supported by connected devices, many of which\nare considered loT devices in the FinTech space that constantly generate data.\nFurthermore, the growing complexity and unpredictability of transaction\npatterns across these networks contribute to a higher incidence of false\npositives. While machine learning solutions have the potential to enhance\ndetection efficiency, their application in AML faces unique challenges, such as\naddressing privacy concerns tied to sensitive financial data and managing the\nreal-world constraint of limited data availability due to data regulations.\nExisting surveys in the AML literature broadly review machine learning\napproaches for money laundering detection, but they often lack an in-depth\nexploration of advanced deep learning techniques - an emerging field with\nsignificant potential. To address this gap, this paper conducts a comprehensive\nreview of deep learning solutions and the challenges associated with their use\nin AML. Additionally, we propose a novel framework that applies the\nleast-privilege principle by integrating machine learning techniques, codifying\nAML red flags, and employing account profiling to provide context for\npredictions and enable effective fraud detection under limited data\navailability....",
      "tldr_zh": "该论文系统回顾了深度学习在移动交易反洗钱(AML)领域的应用现状与挑战。针对移动支付和金融科技(IoT)设备带来的数据异构性、隐私保护和模式复杂性问题，研究提出了一个基于最小权限原则的新型框架，整合机器学习技术、AML预警指标和账户画像分析，以在有限数据条件下实现有效欺诈检测。文章特别强调了深度学习解决方案在应对高误报率和实时处理需求方面的潜力，填补了现有AML文献对先进深度学习技术深入探讨的空白。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10058v1",
      "published_date": "2025-03-13 05:19:44 UTC",
      "updated_date": "2025-03-13 05:19:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:26:34.051892"
    },
    {
      "arxiv_id": "2503.10052v1",
      "title": "DTA: Dual Temporal-channel-wise Attention for Spiking Neural Networks",
      "title_zh": "DTA：面向脉冲神经网络的双通道时序注意力机制",
      "authors": [
        "Minje Kim",
        "Minjun Kim",
        "Xu Yang"
      ],
      "abstract": "Spiking Neural Networks (SNNs) present a more energy-efficient alternative to\nArtificial Neural Networks (ANNs) by harnessing spatio-temporal dynamics and\nevent-driven spikes. Effective utilization of temporal information is crucial\nfor SNNs, leading to the exploration of attention mechanisms to enhance this\ncapability. Conventional attention operations either apply identical operation\nor employ non-identical operations across target dimensions. We identify that\nthese approaches provide distinct perspectives on temporal information. To\nleverage the strengths of both operations, we propose a novel Dual\nTemporal-channel-wise Attention (DTA) mechanism that integrates both\nidentical/non-identical attention strategies. To the best of our knowledge,\nthis is the first attempt to concentrate on both the correlation and dependency\nof temporal-channel using both identical and non-identical attention\noperations. Experimental results demonstrate that the DTA mechanism achieves\nstate-of-the-art performance on both static datasets (CIFAR10, CIFAR100,\nImageNet-1k) and dynamic dataset (CIFAR10-DVS), elevating spike representation\nand capturing complex temporal-channel relationship. We open-source our code:\nhttps://github.com/MnJnKIM/DTA-SNN.",
      "tldr_zh": "该研究提出了一种新颖的双重时间通道注意力机制（DTA），用于提升脉冲神经网络（SNNs）的性能。DTA结合了相同和非相同的注意力操作，首次同时关注时间通道的相关性和依赖性。实验表明，DTA在静态数据集（CIFAR10、CIFAR100、ImageNet-1k）和动态数据集（CIFAR10-DVS）上均实现了最先进的性能，显著提升了脉冲表示能力并捕捉了复杂的时间通道关系。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by IEEE/CVF Winter Conference on Applications of Computer\n  Vision (WACV) 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.10052v1",
      "published_date": "2025-03-13 05:09:48 UTC",
      "updated_date": "2025-03-13 05:09:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:26:41.529101"
    },
    {
      "arxiv_id": "2503.10040v1",
      "title": "Rapid analysis of point-contact Andreev reflection spectra via machine learning with adaptive data augmentation",
      "title_zh": "基于自适应数据增强的机器学习快速分析点接触安德列夫反射谱",
      "authors": [
        "Dongik Lee",
        "Valentin Stanev",
        "Xiaohang Zhang",
        "Mijeong Kang",
        "Ichiro Takeuchi",
        "Seunghun Lee"
      ],
      "abstract": "Delineating the superconducting order parameters is a pivotal task in\ninvestigating superconductivity for probing pairing mechanisms, as well as\ntheir symmetry and topology. Point-contact Andreev reflection (PCAR)\nmeasurement is a simple yet powerful tool for identifying the order parameters.\nThe PCAR spectra exhibit significant variations depending on the type of the\norder parameter in a superconductor, including its magnitude\n($\\mathit{\\Delta}$), as well as temperature, interfacial quality, Fermi\nvelocity mismatch, and other factors. The information on the order parameter\ncan be obtained by finding the combination of these parameters, generating a\ntheoretical spectrum that fits a measured experimental spectrum. However, due\nto the complexity of the spectra and the high dimensionality of parameters,\nextracting the fitting parameters is often time-consuming and labor-intensive.\nIn this study, we employ a convolutional neural network (CNN) algorithm to\ncreate models for rapid and automated analysis of PCAR spectra of various\nsuperconductors with different pairing symmetries (conventional $s$-wave,\nchiral $p_x+ip_y$-wave, and $d_{x^2-y^2}$-wave). The training datasets are\ngenerated based on the Blonder-Tinkham-Klapwijk (BTK) theory and further\nmodified and augmented by selectively incorporating noise and peaks according\nto the bias voltages. This approach not only replicates the experimental\nspectra but also brings the model's attention to important features within the\nspectra. The optimized models provide fitting parameters for experimentally\nmeasured spectra in less than 100 ms per spectrum. Our approaches and findings\npave the way for rapid and automated spectral analysis which will help\naccelerate research on superconductors with complex order parameters.",
      "tldr_zh": "该研究提出一种基于卷积神经网络（CNN）和自适应数据增强的机器学习方法，用于快速分析点接触安德列夫反射（PCAR）光谱。通过基于BTK理论生成训练数据，并选择性加入噪声和峰值来增强数据，该方法能自动识别超导体的配对对称性（如s波、手性p波和d波）及关键参数。优化后的模型可在100毫秒内完成单个光谱的拟合参数提取，显著提升了复杂序参量超导体的研究效率。",
      "categories": [
        "cond-mat.supr-con",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cond-mat.supr-con",
      "comment": "18 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.10040v1",
      "published_date": "2025-03-13 04:45:38 UTC",
      "updated_date": "2025-03-13 04:45:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:27:07.146082"
    },
    {
      "arxiv_id": "2503.10009v1",
      "title": "OR-LLM-Agent: Automating Modeling and Solving of Operations Research Optimization Problem with Reasoning Large Language Model",
      "title_zh": "OR-LLM-Agent：基于推理大语言模型的运筹学优化问题自动化建模与求解",
      "authors": [
        "Bowen Zhang",
        "Pengcheng Luo"
      ],
      "abstract": "Operations Research (OR) has been widely applied in various fields such as\nresource allocation, production planning, and supply chain management. However,\naddressing real-world OR problems requires OR experts to perform mathematical\nmodeling and programmers to develop solution algorithms. This traditional\nmethod, heavily reliant on experts, is costly and has long development cycles,\nseverely limiting the widespread adoption of OR techniques. Few have considered\nusing Artificial Intelligence (AI) to replace professionals to achieve fully\nautomated solutions for OR problems. We propose OR-LLM-Agent, the first AI\nagent that enables end-to-end automation for solving real-world OR problems.\nOR-LLM-Agent leverages the Chain-of-Thought (CoT) reasoning capabilities of\nLarge Language Models (LLMs) to translate natural language problem descriptions\ninto formal mathematical models and automatically generate Gurobi solver code.\nIn OR-LLM-Agent, OR-CodeAgent is designed to automate code execution and repair\nwithin a sandbox environment, facilitating the derivation of the final\nsolution. Due to the lack of dedicated benchmark datasets for evaluating the\nautomated solving of OR problems, we construct a benchmark dataset comprising\n83 real-world OR problems described in natural language. We conduct comparative\nexperiments with state-of-the-art (SOTA) reasoning LLMs, including GPT-o3-mini,\nDeepSeek-R1, and Gemini 2.0 Flash Thinking. The OR-LLM-Agent achieved the\nhighest pass rate of 100% and the highest solution accuracy of 85%,\ndemonstrating the feasibility of automated OR problem-solving. Data and code\nhave been publicly available at https://github.com/bwz96sco/or_llm_agent.",
      "tldr_zh": "该研究提出OR-LLM-Agent，首个实现运筹学(OR)问题端到端自动化求解的AI智能体。该系统利用大语言模型(LLMs)的链式思维推理(CoT)能力，将自然语言问题描述自动转化为数学模型并生成Gurobi求解器代码，其中OR-CodeAgent组件负责在沙盒环境中执行和修复代码。研究者构建了包含83个实际OR问题的基准数据集，实验表明OR-LLM-Agent以100%通过率和85%求解准确率超越现有SOTA模型，验证了OR问题全自动求解的可行性。",
      "categories": [
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.AI",
      "comment": "11 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.10009v1",
      "published_date": "2025-03-13 03:40:50 UTC",
      "updated_date": "2025-03-13 03:40:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:27:01.636919"
    },
    {
      "arxiv_id": "2503.10714v1",
      "title": "ZeroMerge: Parameter-Free KV Cache Compression for Memory-Efficient Long-Context LLMs",
      "title_zh": "ZeroMerge：面向内存高效长上下文大语言模型的无参数键值缓存压缩",
      "authors": [
        "Xin Liu",
        "Pei Liu",
        "Guoming Tang"
      ],
      "abstract": "The linear growth of key-value (KV) cache memory and quadratic computational\ncomplexity pose significant bottlenecks for large language models (LLMs) in\nlong-context processing. While existing KV cache optimization methods address\nthese challenges through token pruning or feature merging, they often suffer\nfrom irreversible information loss or require costly parameter retraining. We\npropose ZeroMerge, a dynamic zero-shot compression framework that achieves\nefficient cache management through three key innovations: (1) Fine-grained\nmemory allocation guided by multi-dimensional token importance metrics at\nhead-level granularity, (2) A residual merging mechanism that preserves\ncritical context through compensated attention scoring, and (3) Parameter-free\nadaptation compatible with diverse LLM architectures without retraining.\nComprehensive evaluations across LLaMA-2 model demonstrate that ZeroMerge\nmaintains full-cache performance at 5\\% compression ratios while doubling\ninference throughput at 40K token lengths. The method effectively balances\nmemory efficiency, generation quality, and deployment flexibility, advancing\npractical long-context LLM applications. The code is available at\nhttps://github.com/SusCom-Lab/ZeroMerge.",
      "tldr_zh": "该研究提出了ZeroMerge，一种无需参数调整的动态零样本压缩框架，用于解决大规模语言模型(LLMs)在长上下文处理中的KV缓存内存线性增长和计算复杂度二次方增长问题。ZeroMerge通过细粒度内存分配、残差合并机制和无参数适配三项创新技术，实现了高效的缓存管理。实验表明，在LLaMA-2模型上，ZeroMerge在5%压缩比下保持了全缓存性能，并在40K token长度下将推理吞吐量提高了一倍。该方法在内存效率、生成质量和部署灵活性之间取得了良好平衡，推动了长上下文LLM的实际应用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10714v1",
      "published_date": "2025-03-13 03:36:03 UTC",
      "updated_date": "2025-03-13 03:36:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:27:00.246604"
    },
    {
      "arxiv_id": "2503.10003v1",
      "title": "A New Benchmark for Few-Shot Class-Incremental Learning: Redefining the Upper Bound",
      "title_zh": "小样本类增量学习新基准：重新定义性能上限",
      "authors": [
        "Shiwon Kim",
        "Dongjun Hwang",
        "Sungwon Woo",
        "Rita Singh"
      ],
      "abstract": "Class-incremental learning (CIL) aims to continuously adapt to emerging\nclasses while retaining knowledge of previously learned ones. Few-shot\nclass-incremental learning (FSCIL) presents an even greater challenge which\nrequires the model to learn incremental classes with only a limited number of\nsamples. In conventional CIL, joint training is widely considered the upper\nbound, serving as both a benchmark and a methodological guide. However, we find\nthat joint training fails to be a meaningful upper bound in FSCIL due to the\ninherent difficulty of inter-task class separation (ICS) caused by severe class\nimbalance. In this work, we introduce a new joint training benchmark tailored\nfor FSCIL by integrating imbalance-aware techniques, effectively bridging the\nperformance gap between base and incremental classes. Furthermore, we point out\ninconsistencies in the experimental setup and evaluation of existing FSCIL\nmethods. To ensure fair comparisons between different FSCIL approaches and\njoint training, we standardize training conditions and propose a unified\nevaluation protocol that simultaneously considers the validation set and\ncomputational complexity. By establishing a reliable upper bound and a\nstandardized evaluation framework for FSCIL, our work provides a clear\nbenchmark and a practical foundation for future research.",
      "tldr_zh": "该研究重新定义了小样本类增量学习(FSCIL)的上限基准，发现传统联合训练方法因类别不平衡导致的跨任务类间分离(ICS)问题而失效。作者提出了一种整合不平衡感知技术的新型联合训练基准，有效缩小基础类与增量类间的性能差距。研究还标准化了FSCIL方法的实验设置和评估流程，建立了同时考虑验证集和计算复杂度的统一评估协议，为未来研究提供了可靠基准。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10003v1",
      "published_date": "2025-03-13 03:25:29 UTC",
      "updated_date": "2025-03-13 03:25:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:27:11.596438"
    },
    {
      "arxiv_id": "2503.10713v1",
      "title": "HiCMamba: Enhancing Hi-C Resolution and Identifying 3D Genome Structures with State Space Modeling",
      "title_zh": "HiCMamba：基于状态空间模型提升Hi-C分辨率与三维基因组结构识别",
      "authors": [
        "Minghao Yang",
        "Zhi-An Huang",
        "Zhihang Zheng",
        "Yuqiao Liu",
        "Shichen Zhang",
        "Pengfei Zhang",
        "Hui Xiong",
        "Shaojun Tang"
      ],
      "abstract": "Hi-C technology measures genome-wide interaction frequencies, providing a\npowerful tool for studying the 3D genomic structure within the nucleus.\nHowever, high sequencing costs and technical challenges often result in Hi-C\ndata with limited coverage, leading to imprecise estimates of chromatin\ninteraction frequencies. To address this issue, we present a novel deep\nlearning-based method HiCMamba to enhance the resolution of Hi-C contact maps\nusing a state space model. We adopt the UNet-based auto-encoder architecture to\nstack the proposed holistic scan block, enabling the perception of both global\nand local receptive fields at multiple scales. Experimental results demonstrate\nthat HiCMamba outperforms state-of-the-art methods while significantly reducing\ncomputational resources. Furthermore, the 3D genome structures, including\ntopologically associating domains (TADs) and loops, identified in the contact\nmaps recovered by HiCMamba are validated through associated epigenomic\nfeatures. Our work demonstrates the potential of a state space model as\nfoundational frameworks in the field of Hi-C resolution enhancement.",
      "tldr_zh": "本文提出HiCMamba方法，通过状态空间模型(state space model)提升Hi-C接触图谱分辨率，解决因测序成本高导致的染色质互作频率估计不精确问题。该方法采用UNet自编码器架构，结合全局-局部多尺度感知的holistic scan模块，在减少计算资源的同时性能超越现有最佳方法。实验证实，该方法恢复的接触图谱能准确识别拓扑关联域(TADs)和染色质环(loops)等3D基因组结构，并通过表观基因组特征验证。研究展现了状态空间模型在Hi-C分辨率增强领域的潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10713v1",
      "published_date": "2025-03-13 03:04:02 UTC",
      "updated_date": "2025-03-13 03:04:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:27:22.689197"
    },
    {
      "arxiv_id": "2503.09988v3",
      "title": "Label Unbalance in High-frequency Trading",
      "title_zh": "高频交易中的标签不平衡问题",
      "authors": [
        "Zijian Zhao",
        "Xuming Zhang",
        "Jiayu Wen",
        "Mingwen Liu",
        "Xiaoteng Ma"
      ],
      "abstract": "In financial trading, return prediction is one of the foundation for a\nsuccessful trading system. By the fast development of the deep learning in\nvarious areas such as graphical processing, natural language, it has also\ndemonstrate significant edge in handling with financial data. While the success\nof the deep learning relies on huge amount of labeled sample, labeling each\ntime/event as profitable or unprofitable, under the transaction cost,\nespecially in the high-frequency trading world, suffers from serious label\nimbalance issue.In this paper, we adopts rigurious end-to-end deep learning\nframework with comprehensive label imbalance adjustment methods and succeed in\npredicting in high-frequency return in the Chinese future market. The code for\nour method is publicly available at\nhttps://github.com/RS2002/Label-Unbalance-in-High-Frequency-Trading .",
      "tldr_zh": "该论文针对高频交易中因交易成本导致的严重标签不平衡问题，提出了一个端到端的深度学习框架。通过综合运用多种标签不平衡调整方法，研究成功预测了中国期货市场的高频收益率。作者公开了相关代码，为金融交易领域的深度学习应用提供了实用解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-fin.CP"
      ],
      "primary_category": "cs.LG",
      "comment": "Technical Report",
      "pdf_url": "http://arxiv.org/pdf/2503.09988v3",
      "published_date": "2025-03-13 02:55:06 UTC",
      "updated_date": "2025-03-21 03:10:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:27:34.153503"
    },
    {
      "arxiv_id": "2503.09974v1",
      "title": "Uncertainty-aware Long-tailed Weights Model the Utility of Pseudo-labels for Semi-supervised Learning",
      "title_zh": "不确定性感知的长尾权重模型：伪标签在半监督学习中的效用建模",
      "authors": [
        "Jiaqi Wu",
        "Junbiao Pang",
        "Qingming Huang"
      ],
      "abstract": "Current Semi-supervised Learning (SSL) adopts the pseudo-labeling strategy\nand further filters pseudo-labels based on confidence thresholds. However, this\nmechanism has notable drawbacks: 1) setting the reasonable threshold is an open\nproblem which significantly influences the selection of the high-quality\npseudo-labels; and 2) deep models often exhibit the over-confidence phenomenon\nwhich makes the confidence value an unreliable indicator for assessing the\nquality of pseudo-labels due to the scarcity of labeled data. In this paper, we\npropose an Uncertainty-aware Ensemble Structure (UES) to assess the utility of\npseudo-labels for unlabeled samples. We further model the utility of\npseudo-labels as long-tailed weights to avoid the open problem of setting the\nthreshold. Concretely, the advantage of the long-tailed weights ensures that\neven unreliable pseudo-labels still contribute to enhancing the model's\nrobustness. Besides, UES is lightweight and architecture-agnostic, easily\nextending to various computer vision tasks, including classification and\nregression. Experimental results demonstrate that combining the proposed method\nwith DualPose leads to a 3.47% improvement in Percentage of Correct Keypoints\n(PCK) on the Sniffing dataset with 100 data points (30 labeled), a 7.29\\%\nimprovement in PCK on the FLIC dataset with 100 data points (50 labeled), and a\n3.91% improvement in PCK on the LSP dataset with 200 data points (100 labeled).\nFurthermore, when combined with FixMatch, the proposed method achieves a 0.2%\naccuracy improvement on the CIFAR-10 dataset with 40 labeled data points and a\n0.26% accuracy improvement on the CIFAR-100 dataset with 400 labeled data\npoints.",
      "tldr_zh": "本文提出了一种不确定性感知的集成结构（UES），用于评估半监督学习（SSL）中伪标签的效用。通过将伪标签的效用建模为长尾权重，该方法避免了设置置信度阈值的难题，并确保即使不可靠的伪标签也能增强模型的鲁棒性。UES轻量且与架构无关，可轻松扩展到分类和回归等计算机视觉任务。实验表明，该方法在多个数据集上显著提升了模型性能，例如在Sniffing数据集上PCK提升了3.47%，在CIFAR-10数据集上准确率提升了0.2%。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "arXiv admin note: text overlap with arXiv:2408.04150",
      "pdf_url": "http://arxiv.org/pdf/2503.09974v1",
      "published_date": "2025-03-13 02:21:04 UTC",
      "updated_date": "2025-03-13 02:21:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:27:49.520082"
    },
    {
      "arxiv_id": "2503.09969v1",
      "title": "Detecting Dataset Bias in Medical AI: A Generalized and Modality-Agnostic Auditing Framework",
      "title_zh": "检测医疗AI中的数据集偏差：一种通用且模态无关的审计框架",
      "authors": [
        "Nathan Drenkow",
        "Mitchell Pavlak",
        "Keith Harrigian",
        "Ayah Zirikly",
        "Adarsh Subbaswamy",
        "Mathias Unberath"
      ],
      "abstract": "Data-driven AI is establishing itself at the center of evidence-based\nmedicine. However, reports of shortcomings and unexpected behavior are growing\ndue to AI's reliance on association-based learning. A major reason for this\nbehavior: latent bias in machine learning datasets can be amplified during\ntraining and/or hidden during testing. We present a data modality-agnostic\nauditing framework for generating targeted hypotheses about sources of bias\nwhich we refer to as Generalized Attribute Utility and Detectability-Induced\nbias Testing (G-AUDIT) for datasets. Our method examines the relationship\nbetween task-level annotations and data properties including protected\nattributes (e.g., race, age, sex) and environment and acquisition\ncharacteristics (e.g., clinical site, imaging protocols). G-AUDIT automatically\nquantifies the extent to which the observed data attributes may enable shortcut\nlearning, or in the case of testing data, hide predictions made based on\nspurious associations. We demonstrate the broad applicability and value of our\nmethod by analyzing large-scale medical datasets for three distinct modalities\nand learning tasks: skin lesion classification in images, stigmatizing language\nclassification in Electronic Health Records (EHR), and mortality prediction for\nICU tabular data. In each setting, G-AUDIT successfully identifies subtle\nbiases commonly overlooked by traditional qualitative methods that focus\nprimarily on social and ethical objectives, underscoring its practical value in\nexposing dataset-level risks and supporting the downstream development of\nreliable AI systems. Our method paves the way for achieving deeper\nunderstanding of machine learning datasets throughout the AI development\nlife-cycle from initial prototyping all the way to regulation, and creates\nopportunities to reduce model bias, enabling safer and more trustworthy AI\nsystems.",
      "tldr_zh": "该研究提出了一种医疗AI领域通用的数据模态无关审计框架G-AUDIT，用于系统性检测机器学习数据集中的潜在偏见。该方法通过量化任务标注与受保护属性（如种族、年龄、性别）及数据采集特征（如临床中心、成像协议）之间的关系，自动识别可能导致模型走捷径学习或隐藏伪相关性的数据偏差。研究在皮肤病变图像分类、电子健康记录(EHR)污名化语言分类和ICU表格数据死亡率预测三个不同模态任务中验证了该框架的有效性，成功发现了传统定性方法易忽视的细微偏差。该框架为AI开发全生命周期中的数据集理解提供了新工具，有助于构建更可靠、安全的医疗AI系统。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.09969v1",
      "published_date": "2025-03-13 02:16:48 UTC",
      "updated_date": "2025-03-13 02:16:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:27:58.363085"
    },
    {
      "arxiv_id": "2503.09960v1",
      "title": "Optimizing Fire Safety: Reducing False Alarms Using Advanced Machine Learning Techniques",
      "title_zh": "优化消防安全：利用先进机器学习技术减少误报",
      "authors": [
        "Muhammad Hassan Jamal",
        "Abdulwahab Alazeb",
        "Shahid Allah Bakhsh",
        "Wadii Boulila",
        "Syed Aziz Shah",
        "Aizaz Ahmad Khattak",
        "Muhammad Shahbaz Khan"
      ],
      "abstract": "Fire safety practices are important to reduce the extent of destruction\ncaused by fire. While smoke alarms help save lives, firefighters struggle with\nthe increasing number of false alarms. This paper presents a precise and\nefficient Weighted ensemble model for decreasing false alarms. It estimates the\ndensity, computes weights according to the high and low-density regions,\nforwards the high region weights to KNN and low region weights to XGBoost and\ncombines the predictions. The proposed model is effective at reducing response\ntime, increasing fire safety, and minimizing the damage that fires cause. A\nspecifically designed dataset for smoke detection is utilized to test the\nproposed model. In addition, a variety of ML models, such as Logistic\nRegression (LR), Decision Tree (DT), Random Forest (RF), Nai:ve Bayes (NB),\nK-Nearest Neighbour (KNN), Support Vector Machine (SVM), Extreme Gradient\nBoosting (XGBoost), Adaptive Boosting (ADAB), have also been utilized. To\nmaximize the use of the smoke detection dataset, all the algorithms utilize the\nSMOTE re-sampling technique. After evaluating the assessment criteria, this\npaper presents a concise summary of the comprehensive findings obtained by\ncomparing the outcomes of all models.",
      "tldr_zh": "本研究提出了一种基于加权集成模型的火灾误报优化方法，通过结合KNN和XGBoost算法，根据烟雾密度高低区域分配不同权重进行预测。实验采用SMOTE重采样技术和多种机器学习模型对比，结果表明该方案能有效降低响应时间、提高火灾安全性。特别设计的烟雾检测数据集验证了该模型在减少误报方面的优越性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.09960v1",
      "published_date": "2025-03-13 02:07:14 UTC",
      "updated_date": "2025-03-13 02:07:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:28:23.107815"
    },
    {
      "arxiv_id": "2503.09956v2",
      "title": "DeepSeek-Inspired Exploration of RL-based LLMs and Synergy with Wireless Networks: A Survey",
      "title_zh": "DeepSeek启发的基于强化学习的大型语言模型探索及其与无线网络的协同作用：综述",
      "authors": [
        "Yu Qiao",
        "Phuong-Nam Tran",
        "Ji Su Yoon",
        "Loc X. Nguyen",
        "Choong Seon Hong"
      ],
      "abstract": "Reinforcement learning (RL)-based large language models (LLMs), such as\nChatGPT, DeepSeek, and Grok-3, have gained significant attention for their\nexceptional capabilities in natural language processing and multimodal data\nunderstanding. Meanwhile, the rapid expansion of information services has\ndriven the growing need for intelligence, efficient, and adaptable wireless\nnetworks. Wireless networks require the empowerment of RL-based LLMs while\nthese models also benefit from wireless networks to broaden their application\nscenarios. Specifically, RL-based LLMs can enhance wireless communication\nsystems through intelligent resource allocation, adaptive network optimization,\nand real-time decision-making. Conversely, wireless networks provide a vital\ninfrastructure for the efficient training, deployment, and distributed\ninference of RL-based LLMs, especially in decentralized and edge computing\nenvironments. This mutual empowerment highlights the need for a deeper\nexploration of the interplay between these two domains. We first review recent\nadvancements in wireless communications, highlighting the associated challenges\nand potential solutions. We then discuss the progress of RL-based LLMs,\nfocusing on key technologies for LLM training, challenges, and potential\nsolutions. Subsequently, we explore the mutual empowerment between these two\nfields, highlighting key motivations, open challenges, and potential solutions.\nFinally, we provide insights into future directions, applications, and their\nsocietal impact to further explore this intersection, paving the way for\nnext-generation intelligent communication systems. Overall, this survey\nprovides a comprehensive overview of the relationship between RL-based LLMs and\nwireless networks, offering a vision where these domains empower each other to\ndrive innovations.",
      "tldr_zh": "这篇综述探讨了基于强化学习（RL）的大语言模型（LLMs）与无线网络之间的协同关系。RL-based LLMs（如ChatGPT、DeepSeek等）可为无线通信系统提供智能资源分配、自适应优化和实时决策支持，而无线网络则为这些模型的分布式训练和边缘部署提供基础设施。文章系统回顾了两个领域的最新进展、关键挑战及潜在解决方案，并重点分析了两者相互赋能的机遇。最终展望了该交叉领域在下一代智能通信系统中的发展方向和社会影响。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.ET"
      ],
      "primary_category": "cs.LG",
      "comment": "25 pages, 13 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.09956v2",
      "published_date": "2025-03-13 01:59:11 UTC",
      "updated_date": "2025-03-19 01:32:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:28:11.735234"
    },
    {
      "arxiv_id": "2503.09950v1",
      "title": "MoFlow: One-Step Flow Matching for Human Trajectory Forecasting via Implicit Maximum Likelihood Estimation based Distillation",
      "title_zh": "MoFlow：基于隐式最大似然估计蒸馏的一步流匹配用于人体轨迹预测",
      "authors": [
        "Yuxiang Fu",
        "Qi Yan",
        "Lele Wang",
        "Ke Li",
        "Renjie Liao"
      ],
      "abstract": "In this paper, we address the problem of human trajectory forecasting, which\naims to predict the inherently multi-modal future movements of humans based on\ntheir past trajectories and other contextual cues. We propose a novel motion\nprediction conditional flow matching model, termed MoFlow, to predict K-shot\nfuture trajectories for all agents in a given scene. We design a novel flow\nmatching loss function that not only ensures at least one of the $K$ sets of\nfuture trajectories is accurate but also encourages all $K$ sets of future\ntrajectories to be diverse and plausible. Furthermore, by leveraging the\nimplicit maximum likelihood estimation (IMLE), we propose a novel distillation\nmethod for flow models that only requires samples from the teacher model.\nExtensive experiments on the real-world datasets, including SportVU NBA games,\nETH-UCY, and SDD, demonstrate that both our teacher flow model and the\nIMLE-distilled student model achieve state-of-the-art performance. These models\ncan generate diverse trajectories that are physically and socially plausible.\nMoreover, our one-step student model is $\\textbf{100}$ times faster than the\nteacher flow model during sampling. The code, model, and data are available at\nour project page: https://moflow-imle.github.io",
      "tldr_zh": "本文提出MoFlow模型，通过条件流匹配(conditional flow matching)和基于隐式最大似然估计(IMLE)的蒸馏方法解决人类轨迹预测问题。该模型设计了新型流匹配损失函数，既能确保K组预测轨迹中至少一组准确，又能保证所有预测的多样性和合理性。实验表明，MoFlow在SportVU NBA、ETH-UCY和SDD数据集上达到SOTA性能，其一步式学生模型比教师模型采样速度快100倍，同时生成物理和社会层面均合理的多样化轨迹。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to CVPR 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.09950v1",
      "published_date": "2025-03-13 01:53:05 UTC",
      "updated_date": "2025-03-13 01:53:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:28:17.034034"
    },
    {
      "arxiv_id": "2503.09947v1",
      "title": "Identifying Trustworthiness Challenges in Deep Learning Models for Continental-Scale Water Quality Prediction",
      "title_zh": "识别大陆尺度水质预测深度学习模型的可信度挑战",
      "authors": [
        "Xiaobo Xia",
        "Xiaofeng Liu",
        "Jiale Liu",
        "Kuai Fang",
        "Lu Lu",
        "Samet Oymak",
        "William S. Currie",
        "Tongliang Liu"
      ],
      "abstract": "Water quality is foundational to environmental sustainability, ecosystem\nresilience, and public health. Deep learning models, particularly Long\nShort-Term Memory (LSTM) networks, offer transformative potential for\nlarge-scale water quality prediction and scientific insights generation.\nHowever, their widespread adoption in high-stakes decision-making, such as\npollution mitigation and equitable resource allocation, is prevented by\nunresolved trustworthiness challenges including fairness, uncertainty,\ninterpretability, robustness, generalizability, and reproducibility. In this\nwork, we present the first comprehensive evaluation of trustworthiness in a\ncontinental-scale multi-task LSTM model predicting 20 water quality variables\n(encompassing physical/chemical processes, geochemical weathering, and nutrient\ncycling) across 482 U.S. basins. Our investigation uncovers systematic patterns\nof model performance disparities linked to basin characteristics, the inherent\ncomplexity of biogeochemical processes, and variable predictability,\nemphasizing critical performance fairness concerns. We further propose\nmethodological frameworks for quantitatively evaluating critical aspects of\ntrustworthiness, including uncertainty, interpretability, and robustness,\nidentifying key limitations that could challenge reliable real-world\ndeployment. This work serves as a timely call to action for advancing\ntrustworthy data-driven methods for water resources management and provides a\npathway to offering critical insights for researchers, decision-makers, and\npractitioners seeking to leverage artificial intelligence (AI) responsibly in\nenvironmental management.",
      "tldr_zh": "该研究首次系统评估了基于LSTM网络的深度学习模型在大陆尺度水质预测中的可信度问题，涵盖公平性、不确定性、可解释性等六大挑战。通过分析美国482个流域的20项水质指标预测，研究发现模型性能差异与流域特征、生物地球化学过程复杂性密切相关，揭示了关键公平性问题。研究还提出了量化评估模型可信度的框架，为水资源管理中AI技术的可靠应用提供了方法论基础。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "33 pages, 9 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2503.09947v1",
      "published_date": "2025-03-13 01:50:50 UTC",
      "updated_date": "2025-03-13 01:50:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:28:36.259837"
    },
    {
      "arxiv_id": "2503.09941v1",
      "title": "TGP: Two-modal occupancy prediction with 3D Gaussian and sparse points for 3D Environment Awareness",
      "title_zh": "TGP：基于3D高斯与稀疏点的双模态占用预测，助力3D环境感知",
      "authors": [
        "Mu Chen",
        "Wenyu Chen",
        "Mingchuan Yang",
        "Yuan Zhang",
        "Tao Han",
        "Xinchi Li",
        "Yunlong Li",
        "Huaici Zhao"
      ],
      "abstract": "3D semantic occupancy has rapidly become a research focus in the fields of\nrobotics and autonomous driving environment perception due to its ability to\nprovide more realistic geometric perception and its closer integration with\ndownstream tasks. By performing occupancy prediction of the 3D space in the\nenvironment, the ability and robustness of scene understanding can be\neffectively improved. However, existing occupancy prediction tasks are\nprimarily modeled using voxel or point cloud-based approaches: voxel-based\nnetwork structures often suffer from the loss of spatial information due to the\nvoxelization process, while point cloud-based methods, although better at\nretaining spatial location information, face limitations in representing\nvolumetric structural details. To address this issue, we propose a dual-modal\nprediction method based on 3D Gaussian sets and sparse points, which balances\nboth spatial location and volumetric structural information, achieving higher\naccuracy in semantic occupancy prediction. Specifically, our method adopts a\nTransformer-based architecture, taking 3D Gaussian sets, sparse points, and\nqueries as inputs. Through the multi-layer structure of the Transformer, the\nenhanced queries and 3D Gaussian sets jointly contribute to the semantic\noccupancy prediction, and an adaptive fusion mechanism integrates the semantic\noutputs of both modalities to generate the final prediction results.\nAdditionally, to further improve accuracy, we dynamically refine the point\ncloud at each layer, allowing for more precise location information during\noccupancy prediction. We conducted experiments on the Occ3DnuScenes dataset,\nand the experimental results demonstrate superior performance of the proposed\nmethod on IoU based metrics.",
      "tldr_zh": "本文提出TGP方法，利用3D高斯集合和稀疏点云的双模态预测框架来解决3D语义占据预测问题。该方法通过Transformer架构融合两种模态数据，既能保留空间位置信息又能捕捉体积结构细节，在Occ3DnuScenes数据集上展现出优越的IoU指标表现。研究还采用动态点云优化和自适应融合机制，显著提升了自动驾驶和机器人领域的3D环境感知能力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.09941v1",
      "published_date": "2025-03-13 01:35:04 UTC",
      "updated_date": "2025-03-13 01:35:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:28:32.341542"
    },
    {
      "arxiv_id": "2503.09927v1",
      "title": "Developing and Evaluating an AI-Assisted Prediction Model for Unplanned Intensive Care Admissions following Elective Neurosurgery using Natural Language Processing within an Electronic Healthcare Record System",
      "title_zh": "利用电子健康记录系统中的自然语言处理技术开发并评估择期神经外科术后非计划重症监护入院的人工智能辅助预测模型",
      "authors": [
        "Julia Ive",
        "Olatomiwa Olukoya",
        "Jonathan P. Funnell",
        "James Booker",
        "Sze H M Lam",
        "Ugan Reddy",
        "Kawsar Noor",
        "Richard JB Dobson",
        "Astri M. V. Luoma",
        "Hani J Marcus"
      ],
      "abstract": "Introduction: Timely care in a specialised neuro-intensive therapy unit (ITU)\nreduces mortality and hospital stays, with planned admissions being safer than\nunplanned ones. However, post-operative care decisions remain subjective. This\nstudy used artificial intelligence (AI), specifically natural language\nprocessing (NLP) to analyse electronic health records (EHRs) and predict ITU\nadmissions for elective surgery patients. Methods: This study analysed the EHRs\nof elective neurosurgery patients from University College London Hospital\n(UCLH) using NLP. Patients were categorised into planned high dependency unit\n(HDU) or ITU admission; unplanned HDU or ITU admission; or ward / overnight\nrecovery (ONR). The Medical Concept Annotation Tool (MedCAT) was used to\nidentify SNOMED-CT concepts within the clinical notes. We then explored the\nutility of these identified concepts for a range of AI algorithms trained to\npredict ITU admission. Results: The CogStack-MedCAT NLP model, initially\ntrained on hospital-wide EHRs, underwent two refinements: first with data from\npatients with Normal Pressure Hydrocephalus (NPH) and then with data from\nVestibular Schwannoma (VS) patients, achieving a concept detection F1-score of\n0.93. This refined model was then used to extract concepts from EHR notes of\n2,268 eligible neurosurgical patients. We integrated the extracted concepts\ninto AI models, including a decision tree model and a neural time-series model.\nUsing the simpler decision tree model, we achieved a recall of 0.87 (CI 0.82 -\n0.91) for ITU admissions, reducing the proportion of unplanned ITU cases missed\nby human experts from 36% to 4%. Conclusion: The NLP model, refined for\naccuracy, has proven its efficiency in extracting relevant concepts, providing\na reliable basis for predictive AI models to use in clinically valid\napplications.",
      "tldr_zh": "本研究开发了一种基于自然语言处理（NLP）的AI辅助预测模型，用于预测择期神经外科手术后患者是否需要进行非计划性重症监护病房（ITU）入院。研究利用电子健康记录（EHRs）数据，通过改进的CogStack-MedCAT NLP模型提取临床笔记中的SNOMED-CT概念，并结合决策树模型和神经网络时间序列模型进行预测。实验结果表明，该模型在预测ITU入院方面的召回率达到0.87，显著降低了人工专家漏诊的比例（从36%降至4%），为临床决策提供了可靠支持。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.09927v1",
      "published_date": "2025-03-13 00:48:48 UTC",
      "updated_date": "2025-03-13 00:48:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:28:49.116264"
    },
    {
      "arxiv_id": "2503.09910v1",
      "title": "eXpLogic: Explaining Logic Types and Patterns in DiffLogic Networks",
      "title_zh": "eXpLogic：解析DiffLogic网络中的逻辑类型与模式",
      "authors": [
        "Stephen Wormald",
        "David Koblah",
        "Matheus Kunzler Maldaner",
        "Domenic Forte",
        "Damon L. Woodard"
      ],
      "abstract": "Constraining deep neural networks (DNNs) to learn individual logic types per\nnode, as performed using the DiffLogic network architecture, opens the door to\nmodel-specific explanation techniques that quell the complexity inherent to\nDNNs. Inspired by principles of circuit analysis from computer engineering,\nthis work presents an algorithm (eXpLogic) for producing saliency maps which\nexplain input patterns that activate certain functions. The eXpLogic\nexplanations: (1) show the exact set of inputs responsible for a decision,\nwhich helps interpret false negative and false positive predictions, (2)\nhighlight common input patterns that activate certain outputs, and (3) help\nreduce the network size to improve class-specific inference. To evaluate the\neXpLogic saliency map, we introduce a metric that quantifies how much an input\nchanges before switching a model's class prediction (the SwitchDist) and use\nthis metric to compare eXpLogic against the Vanilla Gradients (VG) and\nIntegrated Gradient (IG) methods. Generally, we show that eXpLogic saliency\nmaps are better at predicting which inputs will change the class score. These\nmaps help reduce the network size and inference times by 87\\% and 8\\%,\nrespectively, while having a limited impact (-3.8\\%) on class-specific\npredictions. The broader value of this work to machine learning is in\ndemonstrating how certain DNN architectures promote explainability, which is\nrelevant to healthcare, defense, and law.",
      "tldr_zh": "本研究提出了eXpLogic算法，用于解释DiffLogic网络架构中节点学习的逻辑类型和输入模式。该算法通过生成显著性图，精确识别影响决策的输入集，帮助解释假阳性和假阴性预测，并揭示激活特定输出的常见输入模式。实验表明，eXpLogic在预测输入变化对分类结果的影响方面优于Vanilla Gradients和Integrated Gradient方法，同时能够将网络规模和推理时间分别减少87%和8%，而对分类准确率的影响仅为-3.8%。这项研究展示了特定深度神经网络架构如何促进模型可解释性，对医疗、国防和法律等领域具有重要意义。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Conference submission, 6 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.09910v1",
      "published_date": "2025-03-13 00:01:36 UTC",
      "updated_date": "2025-03-13 00:01:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T06:29:12.724351"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 130,
  "processed_papers_count": 130,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-03-26T06:30:35.642814"
}