[
  {
    "arxiv_id": "2503.10959v1",
    "title": "OuroMamba: A Data-Free Quantization Framework for Vision Mamba Models",
    "authors": [
      "Akshat Ramachandran",
      "Mingyu Lee",
      "Huan Xu",
      "Souvik Kundu",
      "Tushar Krishna"
    ],
    "abstract": "We present OuroMamba, the first data-free post-training quantization (DFQ)\nmethod for vision Mamba-based models (VMMs). We identify two key challenges in\nenabling DFQ for VMMs, (1) VMM's recurrent state transitions restricts\ncapturing of long-range interactions and leads to semantically weak synthetic\ndata, (2) VMM activations exhibit dynamic outlier variations across time-steps,\nrendering existing static PTQ techniques ineffective. To address these\nchallenges, OuroMamba presents a two-stage framework: (1) OuroMamba-Gen to\ngenerate semantically rich and meaningful synthetic data. It applies\ncontrastive learning on patch level VMM features generated through neighborhood\ninteractions in the latent state space, (2) OuroMamba-Quant to employ\nmixed-precision quantization with lightweight dynamic outlier detection during\ninference. In specific, we present a thresholding based outlier channel\nselection strategy for activations that gets updated every time-step. Extensive\nexperiments across vision and generative tasks show that our data-free\nOuroMamba surpasses existing data-driven PTQ techniques, achieving\nstate-of-the-art performance across diverse quantization settings.\nAdditionally, we implement efficient GPU kernels to achieve practical latency\nspeedup of up to 2.36x. Code will be released soon.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.10959v1",
    "published_date": "2025-03-13 23:58:55 UTC",
    "updated_date": "2025-03-13 23:58:55 UTC"
  },
  {
    "arxiv_id": "2503.10957v1",
    "title": "Predicting Stock Movement with BERTweet and Transformers",
    "authors": [
      "Michael Charles Albada",
      "Mojolaoluwa Joshua Sonola"
    ],
    "abstract": "Applying deep learning and computational intelligence to finance has been a\npopular area of applied research, both within academia and industry, and\ncontinues to attract active attention. The inherently high volatility and\nnon-stationary of the data pose substantial challenges to machine learning\nmodels, especially so for today's expressive and highly-parameterized deep\nlearning models. Recent work has combined natural language processing on data\nfrom social media to augment models based purely on historic price data to\nimprove performance has received particular attention. Previous work has\nachieved state-of-the-art performance on this task by combining techniques such\nas bidirectional GRUs, variational autoencoders, word and document embeddings,\nself-attention, graph attention, and adversarial training. In this paper, we\ndemonstrated the efficacy of BERTweet, a variant of BERT pre-trained\nspecifically on a Twitter corpus, and the transformer architecture by achieving\ncompetitive performance with the existing literature and setting a new baseline\nfor Matthews Correlation Coefficient on the Stocknet dataset without auxiliary\ndata sources.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CE"
    ],
    "primary_category": "cs.LG",
    "comment": "9 pages, 4 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2503.10957v1",
    "published_date": "2025-03-13 23:46:24 UTC",
    "updated_date": "2025-03-13 23:46:24 UTC"
  },
  {
    "arxiv_id": "2503.10954v1",
    "title": "Empirical Computation",
    "authors": [
      "Eric Tang",
      "Marcel Böhme"
    ],
    "abstract": "In this vision paper, we explore the challenges and opportunities of a form\nof computation that employs an empirical (rather than a formal) approach, where\nthe solution of a computational problem is returned as empirically most likely\n(rather than necessarily correct). We call this approach as *empirical\ncomputation* and observe that its capabilities and limits *cannot* be\nunderstood within the classic, rationalist framework of computation.\n  While we take a very broad view of \"computational problem\", a classic,\nwell-studied example is *sorting*: Given a set of $n$ numbers, return these\nnumbers sorted in ascending order.\n  * To run a classical, *formal computation*, we might first think about a\n*specific algorithm* (e.g., merge sort) before developing a *specific* program\nthat implements it. The program will expect the input to be given in a\n*specific* format, type, or data structure (e.g., unsigned 32-bit integers). In\nsoftware engineering, we have many approaches to analyze the correctness of\nsuch programs. From complexity theory, we know that there exists no correct\nprogram that can solve the average instance of the sorting problem faster than\n$O(n\\log n)$.\n  * To run an *empirical computation*, we might directly ask a large language\nmodel (LLM) to solve *any* computational problem (which can be stated\ninformally in natural language) and provide the input in *any* format (e.g.,\nnegative numbers written as Chinese characters). There is no (problem-specific)\nprogram that could be analyzed for correctness. Also, the time it takes an LLM\nto return an answer is entirely *independent* of the computational complexity\nof the problem that is solved.\n  What are the capabilities or limits of empirical computation in the general,\nin the problem-, or in the instance-specific? Our purpose is to establish\nempirical computation as a field in SE that is timely and rich with interesting\nproblems.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "Open challenges in the analysis of properties and limits of empirical\n  computation",
    "pdf_url": "http://arxiv.org/pdf/2503.10954v1",
    "published_date": "2025-03-13 23:40:42 UTC",
    "updated_date": "2025-03-13 23:40:42 UTC"
  },
  {
    "arxiv_id": "2503.10949v1",
    "title": "Safe Continual Domain Adaptation after Sim2Real Transfer of Reinforcement Learning Policies in Robotics",
    "authors": [
      "Josip Josifovski",
      "Shangding Gu",
      "Mohammadhossein Malmir",
      "Haoliang Huang",
      "Sayantan Auddy",
      "Nicolás Navarro-Guerrero",
      "Costas Spanos",
      "Alois Knoll"
    ],
    "abstract": "Domain randomization has emerged as a fundamental technique in reinforcement\nlearning (RL) to facilitate the transfer of policies from simulation to\nreal-world robotic applications. Many existing domain randomization approaches\nhave been proposed to improve robustness and sim2real transfer. These\napproaches rely on wide randomization ranges to compensate for the unknown\nactual system parameters, leading to robust but inefficient real-world\npolicies. In addition, the policies pretrained in the domain-randomized\nsimulation are fixed after deployment due to the inherent instability of the\noptimization processes based on RL and the necessity of sampling exploitative\nbut potentially unsafe actions on the real system. This limits the adaptability\nof the deployed policy to the inevitably changing system parameters or\nenvironment dynamics over time. We leverage safe RL and continual learning\nunder domain-randomized simulation to address these limitations and enable safe\ndeployment-time policy adaptation in real-world robot control. The experiments\nshow that our method enables the policy to adapt and fit to the current domain\ndistribution and environment dynamics of the real system while minimizing\nsafety risks and avoiding issues like catastrophic forgetting of the general\npolicy found in randomized simulation during the pretraining phase. Videos and\nsupplementary material are available at https://safe-cda.github.io/.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "8 pages, 5 figures, under review",
    "pdf_url": "http://arxiv.org/pdf/2503.10949v1",
    "published_date": "2025-03-13 23:28:11 UTC",
    "updated_date": "2025-03-13 23:28:11 UTC"
  },
  {
    "arxiv_id": "2503.10945v1",
    "title": "$(\\varepsilon, δ)$ Considered Harmful: Best Practices for Reporting Differential Privacy Guarantees",
    "authors": [
      "Juan Felipe Gomez",
      "Bogdan Kulynych",
      "Georgios Kaissis",
      "Jamie Hayes",
      "Borja Balle",
      "Antti Honkela"
    ],
    "abstract": "Current practices for reporting the level of differential privacy (DP)\nguarantees for machine learning (ML) algorithms provide an incomplete and\npotentially misleading picture of the guarantees and make it difficult to\ncompare privacy levels across different settings. We argue for using Gaussian\ndifferential privacy (GDP) as the primary means of communicating DP guarantees\nin ML, with the full privacy profile as a secondary option in case GDP is too\ninaccurate. Unlike other widely used alternatives, GDP has only one parameter,\nwhich ensures easy comparability of guarantees, and it can accurately capture\nthe full privacy profile of many important ML applications. To support our\nclaims, we investigate the privacy profiles of state-of-the-art DP large-scale\nimage classification, and the TopDown algorithm for the U.S. Decennial Census,\nobserving that GDP fits the profiles remarkably well in all three cases.\nAlthough GDP is ideal for reporting the final guarantees, other formalisms\n(e.g., privacy loss random variables) are needed for accurate privacy\naccounting. We show that such intermediate representations can be efficiently\nconverted to GDP with minimal loss in tightness.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.10945v1",
    "published_date": "2025-03-13 23:06:30 UTC",
    "updated_date": "2025-03-13 23:06:30 UTC"
  },
  {
    "arxiv_id": "2503.10941v1",
    "title": "Graph-Grounded LLMs: Leveraging Graphical Function Calling to Minimize LLM Hallucinations",
    "authors": [
      "Piyush Gupta",
      "Sangjae Bae",
      "David Isele"
    ],
    "abstract": "The adoption of Large Language Models (LLMs) is rapidly expanding across\nvarious tasks that involve inherent graphical structures. Graphs are integral\nto a wide range of applications, including motion planning for autonomous\nvehicles, social networks, scene understanding, and knowledge graphs. Many\nproblems, even those not initially perceived as graph-based, can be effectively\naddressed through graph theory. However, when applied to these tasks, LLMs\noften encounter challenges, such as hallucinations and mathematical\ninaccuracies. To overcome these limitations, we propose Graph-Grounded LLMs, a\nsystem that improves LLM performance on graph-related tasks by integrating a\ngraph library through function calls. By grounding LLMs in this manner, we\ndemonstrate significant reductions in hallucinations and improved mathematical\naccuracy in solving graph-based problems, as evidenced by the performance on\nthe NLGraph benchmark. Finally, we showcase a disaster rescue application where\nthe Graph-Grounded LLM acts as a decision-support system.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.10941v1",
    "published_date": "2025-03-13 22:57:28 UTC",
    "updated_date": "2025-03-13 22:57:28 UTC"
  },
  {
    "arxiv_id": "2503.10937v1",
    "title": "ChatGPT Encounters Morphing Attack Detection: Zero-Shot MAD with Multi-Modal Large Language Models and General Vision Models",
    "authors": [
      "Haoyu Zhang",
      "Raghavendra Ramachandra",
      "Kiran Raja",
      "Christoph Busch"
    ],
    "abstract": "Face Recognition Systems (FRS) are increasingly vulnerable to face-morphing\nattacks, prompting the development of Morphing Attack Detection (MAD)\nalgorithms. However, a key challenge in MAD lies in its limited\ngeneralizability to unseen data and its lack of explainability-critical for\npractical application environments such as enrolment stations and automated\nborder control systems. Recognizing that most existing MAD algorithms rely on\nsupervised learning paradigms, this work explores a novel approach to MAD using\nzero-shot learning leveraged on Large Language Models (LLMs). We propose two\ntypes of zero-shot MAD algorithms: one leveraging general vision models and the\nother utilizing multimodal LLMs. For general vision models, we address the MAD\ntask by computing the mean support embedding of an independent support set\nwithout using morphed images. For the LLM-based approach, we employ the\nstate-of-the-art GPT-4 Turbo API with carefully crafted prompts. To evaluate\nthe feasibility of zero-shot MAD and the effectiveness of the proposed methods,\nwe constructed a print-scan morph dataset featuring various unseen morphing\nalgorithms, simulating challenging real-world application scenarios.\nExperimental results demonstrated notable detection accuracy, validating the\napplicability of zero-shot learning for MAD tasks. Additionally, our\ninvestigation into LLM-based MAD revealed that multimodal LLMs, such as\nChatGPT, exhibit remarkable generalizability to untrained MAD tasks.\nFurthermore, they possess a unique ability to provide explanations and\nguidance, which can enhance transparency and usability for end-users in\npractical applications.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.10937v1",
    "published_date": "2025-03-13 22:53:24 UTC",
    "updated_date": "2025-03-13 22:53:24 UTC"
  },
  {
    "arxiv_id": "2503.10927v2",
    "title": "OASST-ETC Dataset: Alignment Signals from Eye-tracking Analysis of LLM Responses",
    "authors": [
      "Angela Lopez-Cardona",
      "Sebastian Idesis",
      "Miguel Barreda-Ángeles",
      "Sergi Abadal",
      "Ioannis Arapakis"
    ],
    "abstract": "While Large Language Models (LLMs) have significantly advanced natural\nlanguage processing, aligning them with human preferences remains an open\nchallenge. Although current alignment methods rely primarily on explicit\nfeedback, eye-tracking (ET) data offers insights into real-time cognitive\nprocessing during reading. In this paper, we present OASST-ETC, a novel\neye-tracking corpus capturing reading patterns from 24 participants, while\nevaluating LLM-generated responses from the OASST1 dataset. Our analysis\nreveals distinct reading patterns between preferred and non-preferred\nresponses, which we compare with synthetic eye-tracking data. Furthermore, we\nexamine the correlation between human reading measures and attention patterns\nfrom various transformer-based models, discovering stronger correlations in\npreferred responses. This work introduces a unique resource for studying human\ncognitive processing in LLM evaluation and suggests promising directions for\nincorporating eye-tracking data into alignment methods. The dataset and\nanalysis code are publicly available.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "This paper has been accepted to ACM ETRA 2025 and published on\n  PACMHCI",
    "pdf_url": "http://arxiv.org/pdf/2503.10927v2",
    "published_date": "2025-03-13 22:28:38 UTC",
    "updated_date": "2025-03-26 13:24:43 UTC"
  },
  {
    "arxiv_id": "2503.10925v1",
    "title": "Predicting Clinical Outcomes with Waveform LSTMs",
    "authors": [
      "Michael Albada"
    ],
    "abstract": "Data mining and machine learning hold great potential to enable health\nsystems to systematically use data and analytics to identify inefficiencies and\nbest practices that improve care and reduce costs. Waveform data offers\nparticularly detailed information on how patient health evolves over time and\nhas the potential to significantly improve prediction accuracy on multiple\nbenchmarks, but has been widely under-utilized, largely because of the\nchallenges in working with these large and complex datasets. This study\nevaluates the potential of leveraging clinical waveform data to improve\nprediction accuracy on a single benchmark task: the risk of mortality in the\nintensive care unit. We identify significant potential from this data, beating\nthe existing baselines for both logistic regression and deep learning models.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "7 pages,. arXiv admin note: text overlap with arXiv:1803.06589 by\n  other authors",
    "pdf_url": "http://arxiv.org/pdf/2503.10925v1",
    "published_date": "2025-03-13 22:19:05 UTC",
    "updated_date": "2025-03-13 22:19:05 UTC"
  },
  {
    "arxiv_id": "2503.10918v2",
    "title": "Resource Heterogeneity-Aware and Utilization-Enhanced Scheduling for Deep Learning Clusters",
    "authors": [
      "Abeda Sultana",
      "Nabin Pakka",
      "Fei Xu",
      "Xu Yuan",
      "Li Chen",
      "Nian-Feng Tzeng"
    ],
    "abstract": "Scheduling deep learning (DL) models to train on powerful clusters with\naccelerators like GPUs and TPUs, presently falls short, either lacking\nfine-grained heterogeneity awareness or leaving resources substantially\nunder-utilized. To fill this gap, we propose a novel design of a task-level\nheterogeneity-aware scheduler, Hadar, based on an optimization framework that\ncan boost resource utilization. Hadar leverages the performance traits of DL\njobs on a heterogeneous DL cluster, characterizes the task-level performance\nheterogeneity in the optimization problem, and makes scheduling decisions\nacross both spatial and temporal dimensions. It involves the primal-dual\nframework employing a dual subroutine, to solve the optimization problem and\nguide the scheduling design. Our trace-driven simulation with representative DL\nmodel training workloads demonstrates that Hadar accelerates the total time\nduration by 1.20x when compared with its state-of-the-art heterogeneity-aware\ncounterpart, Gavel. Further, our Hadar scheduler is enhanced to HadarE by\nforking each job into multiple copies to let a job train concurrently on\nheterogeneous GPUs resided on separate available nodes (i.e., machines or\nservers) for resource utilization enhancement. HadarE is evaluated extensively\non physical DL clusters for comparison with Hadar and Gavel. With substantial\nenhancement in cluster resource utilization (by 1.45x), HadarE exhibits\nconsiderable speed-ups in DL model training, reducing the total time duration\nby 50% (or 80%) on an Amazon's AWS (or our lab) cluster, while producing\ntrained DL models with consistently better inference quality than those trained\nby Hadar.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.LG",
      "I.2.11; F.1.2"
    ],
    "primary_category": "cs.DC",
    "comment": "14 pages, 12 figures, IEEE Transactions on Computers",
    "pdf_url": "http://arxiv.org/pdf/2503.10918v2",
    "published_date": "2025-03-13 22:13:20 UTC",
    "updated_date": "2025-05-21 17:39:17 UTC"
  },
  {
    "arxiv_id": "2503.22692v1",
    "title": "Enhancing Aviation Communication Transcription: Fine-Tuning Distil-Whisper with LoRA",
    "authors": [
      "Shokoufeh Mirzaei",
      "Jesse Arzate",
      "Yukti Vijay"
    ],
    "abstract": "Transcription of aviation communications has several applications, from\nassisting air traffic controllers in identifying the accuracy of read-back\nerrors to search and rescue operations. Recent advances in artificial\nintelligence have provided unprecedented opportunities for improving aviation\ncommunication transcription tasks. OpenAI's Whisper is one of the leading\nautomatic speech recognition models. However, fine-tuning Whisper for aviation\ncommunication transcription is not computationally efficient. Thus, this paper\naims to use a Parameter-Efficient Fine-tuning method called Low-Rank Adaptation\nto fine-tune a more computationally efficient version of Whisper,\ndistil-Whisper. To perform the fine-tuning, we used the Air Traffic Control\nCorpus dataset from the Linguistic Data Consortium, which contains\napproximately 70 hours of controller and pilot transmissions near three major\nairports in the US. The objective was to reduce the word error rate to enhance\naccuracy in the transcription of aviation communication. First, starting with\nan initial set of hyperparameters for LoRA (Alpha = 64 and Rank = 32), we\nperformed a grid search. We applied a 5-fold cross-validation to find the best\ncombination of distil-Whisper hyperparameters. Then, we fine-tuned the model\nfor LoRA hyperparameters, achieving an impressive average word error rate of\n3.86% across five folds. This result highlights the model's potential for use\nin the cockpit.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "eess.AS",
    "comment": "14 pages, 4 Figures, 4 Tables, Under review by Journal of Aerospace\n  Information Systems",
    "pdf_url": "http://arxiv.org/pdf/2503.22692v1",
    "published_date": "2025-03-13 22:12:45 UTC",
    "updated_date": "2025-03-13 22:12:45 UTC"
  },
  {
    "arxiv_id": "2503.10912v1",
    "title": "JPEG Compliant Compression for Both Human and Machine, A Report",
    "authors": [
      "Linfeng Ye"
    ],
    "abstract": "Deep Neural Networks (DNNs) have become an integral part of our daily lives,\nespecially in vision-related applications. However, the conventional lossy\nimage compression algorithms are primarily designed for the Human Vision System\n(HVS), which can non-trivially compromise the DNNs' validation accuracy after\ncompression, as noted in \\cite{liu2018deepn}. Thus developing an image\ncompression algorithm for both human and machine (DNNs) is on the horizon.\n  To address the challenge mentioned above, in this paper, we first formulate\nthe image compression as a multi-objective optimization problem which take both\nhuman and machine prespectives into account, then we solve it by linear\ncombination, and proposed a novel distortion measure for both human and\nmachine, dubbed Human and Machine-Oriented Error (HMOE). After that, we develop\nHuman And Machine Oriented Soft Decision Quantization (HMOSDQ) based on HMOE, a\nlossy image compression algorithm for both human and machine (DNNs), and fully\ncomplied with JPEG format. In order to evaluate the performance of HMOSDQ,\nfinally we conduct the experiments for two pre-trained well-known DNN-based\nimage classifiers named Alexnet \\cite{Alexnet} and VGG-16\n\\cite{simonyan2014VGG} on two subsets of the ImageNet \\cite{deng2009imagenet}\nvalidation set: one subset included images with shorter side in the range of\n496 to 512, while the other included images with shorter side in the range of\n376 to 384. Our results demonstrate that HMOSDQ outperforms the default JPEG\nalgorithm in terms of rate-accuracy and rate-distortion performance. For the\nAlexnet comparing with the default JPEG algorithm, HMOSDQ can improve the\nvalidation accuracy by more than $0.81\\%$ at $0.61$ BPP, or equivalently reduce\nthe compression rate of default JPEG by $9.6\\times$ while maintaining the same\nvalidation accuracy.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "94A34",
      "I.4; I.2"
    ],
    "primary_category": "cs.CV",
    "comment": "9 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.10912v1",
    "published_date": "2025-03-13 21:52:25 UTC",
    "updated_date": "2025-03-13 21:52:25 UTC"
  },
  {
    "arxiv_id": "2503.10908v1",
    "title": "Ecological Neural Architecture Search",
    "authors": [
      "Benjamin David Winter",
      "William J. Teahan"
    ],
    "abstract": "When employing an evolutionary algorithm to optimize a neural networks\narchitecture, developers face the added challenge of tuning the evolutionary\nalgorithm's own hyperparameters - population size, mutation rate, cloning rate,\nand number of generations. This paper introduces Neuvo Ecological Neural\nArchitecture Search (ENAS), a novel method that incorporates these evolutionary\nparameters directly into the candidate solutions' phenotypes, allowing them to\nevolve dynamically alongside architecture specifications. Experimental results\nacross four binary classification datasets demonstrate that ENAS not only\neliminates manual tuning of evolutionary parameters but also outperforms\ncompetitor NAS methodologies in convergence speed (reducing computational time\nby 18.3%) and accuracy (improving classification performance in 3 out of 4\ndatasets). By enabling \"greedy individuals\" to optimize resource allocation\nbased on fitness, ENAS provides an efficient, self-regulating approach to\nneural architecture search.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "5 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.10908v1",
    "published_date": "2025-03-13 21:40:25 UTC",
    "updated_date": "2025-03-13 21:40:25 UTC"
  },
  {
    "arxiv_id": "2503.10907v1",
    "title": "H2-MARL: Multi-Agent Reinforcement Learning for Pareto Optimality in Hospital Capacity Strain and Human Mobility during Epidemic",
    "authors": [
      "Xueting Luo",
      "Hao Deng",
      "Jihong Yang",
      "Yao Shen",
      "Huanhuan Guo",
      "Zhiyuan Sun",
      "Mingqing Liu",
      "Jiming Wei",
      "Shengjie Zhao"
    ],
    "abstract": "The necessity of achieving an effective balance between minimizing the losses\nassociated with restricting human mobility and ensuring hospital capacity has\ngained significant attention in the aftermath of COVID-19. Reinforcement\nlearning (RL)-based strategies for human mobility management have recently\nadvanced in addressing the dynamic evolution of cities and epidemics; however,\nthey still face challenges in achieving coordinated control at the township\nlevel and adapting to cities of varying scales. To address the above issues, we\npropose a multi-agent RL approach that achieves Pareto optimality in managing\nhospital capacity and human mobility (H2-MARL), applicable across cities of\ndifferent scales. We first develop a township-level infection model with\nonline-updatable parameters to simulate disease transmission and construct a\ncity-wide dynamic spatiotemporal epidemic simulator. On this basis, H2-MARL is\ndesigned to treat each division as an agent, with a trade-off dual-objective\nreward function formulated and an experience replay buffer enriched with expert\nknowledge built. To evaluate the effectiveness of the model, we construct a\ntownship-level human mobility dataset containing over one billion records from\nfour representative cities of varying scales. Extensive experiments demonstrate\nthat H2-MARL has the optimal dual-objective trade-off capability, which can\nminimize hospital capacity strain while minimizing human mobility restriction\nloss. Meanwhile, the applicability of the proposed model to epidemic control in\ncities of varying scales is verified, which showcases its feasibility and\nversatility in practical applications.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.MA",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.10907v1",
    "published_date": "2025-03-13 21:40:07 UTC",
    "updated_date": "2025-03-13 21:40:07 UTC"
  },
  {
    "arxiv_id": "2503.10905v2",
    "title": "Learning to Inference Adaptively for Multimodal Large Language Models",
    "authors": [
      "Zhuoyan Xu",
      "Khoi Duc Nguyen",
      "Preeti Mukherjee",
      "Saurabh Bagchi",
      "Somali Chaterji",
      "Yingyu Liang",
      "Yin Li"
    ],
    "abstract": "Multimodal Large Language Models (MLLMs) have shown impressive capabilities\nin reasoning, yet come with substantial computational cost, limiting their\ndeployment in resource-constrained settings. Despite recent efforts on\nimproving the efficiency of MLLMs, prior solutions fall short in responding to\nvarying runtime conditions, in particular changing resource availability (e.g.,\ncontention due to the execution of other programs on the device). To bridge\nthis gap, we introduce AdaLLaVA, an adaptive inference framework that learns to\ndynamically reconfigure operations in an MLLM during inference, accounting for\nthe input data and a latency budget. We conduct extensive experiments across\nbenchmarks involving question-answering, reasoning, and hallucination. Our\nresults show that AdaLLaVA effectively adheres to input latency budget,\nachieving varying accuracy and latency tradeoffs at runtime. Further, we\ndemonstrate that AdaLLaVA adapts to both input latency and content, can be\nintegrated with token selection for enhanced efficiency, and generalizes across\nMLLMs. Our project webpage with code release is at\nhttps://zhuoyan-xu.github.io/ada-llava/.",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.10905v2",
    "published_date": "2025-03-13 21:39:38 UTC",
    "updated_date": "2025-03-17 20:35:28 UTC"
  },
  {
    "arxiv_id": "2503.10894v3",
    "title": "HyperDAS: Towards Automating Mechanistic Interpretability with Hypernetworks",
    "authors": [
      "Jiuding Sun",
      "Jing Huang",
      "Sidharth Baskaran",
      "Karel D'Oosterlinck",
      "Christopher Potts",
      "Michael Sklar",
      "Atticus Geiger"
    ],
    "abstract": "Mechanistic interpretability has made great strides in identifying neural\nnetwork features (e.g., directions in hidden activation space) that mediate\nconcepts(e.g., the birth year of a person) and enable predictable manipulation.\nDistributed alignment search (DAS) leverages supervision from counterfactual\ndata to learn concept features within hidden states, but DAS assumes we can\nafford to conduct a brute force search over potential feature locations. To\naddress this, we present HyperDAS, a transformer-based hypernetwork\narchitecture that (1) automatically locates the token-positions of the residual\nstream that a concept is realized in and (2) constructs features of those\nresidual stream vectors for the concept. In experiments with Llama3-8B,\nHyperDAS achieves state-of-the-art performance on the RAVEL benchmark for\ndisentangling concepts in hidden states. In addition, we review the design\ndecisions we made to mitigate the concern that HyperDAS (like all powerful\ninterpretabilty methods) might inject new information into the target model\nrather than faithfully interpreting it.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.10894v3",
    "published_date": "2025-03-13 21:25:38 UTC",
    "updated_date": "2025-04-25 09:03:38 UTC"
  },
  {
    "arxiv_id": "2503.10886v1",
    "title": "Taxonomic Reasoning for Rare Arthropods: Combining Dense Image Captioning and RAG for Interpretable Classification",
    "authors": [
      "Nathaniel Lesperance",
      "Sujeevan Ratnasingham",
      "Graham W. Taylor"
    ],
    "abstract": "In the context of pressing climate change challenges and the significant\nbiodiversity loss among arthropods, automated taxonomic classification from\norganismal images is a subject of intense research. However, traditional AI\npipelines based on deep neural visual architectures such as CNNs or ViTs face\nlimitations such as degraded performance on the long-tail of classes and the\ninability to reason about their predictions. We integrate image captioning and\nretrieval-augmented generation (RAG) with large language models (LLMs) to\nenhance biodiversity monitoring, showing particular promise for characterizing\nrare and unknown arthropod species. While a naive Vision-Language Model (VLM)\nexcels in classifying images of common species, the RAG model enables\nclassification of rarer taxa by matching explicit textual descriptions of\ntaxonomic features to contextual biodiversity text data from external sources.\nThe RAG model shows promise in reducing overconfidence and enhancing accuracy\nrelative to naive LLMs, suggesting its viability in capturing the nuances of\ntaxonomic hierarchy, particularly at the challenging family and genus levels.\nOur findings highlight the potential for modern vision-language AI pipelines to\nsupport biodiversity conservation initiatives, emphasizing the role of\ncomprehensive data curation and collaboration with citizen science platforms to\nimprove species identification, unknown species characterization and ultimately\ninform conservation strategies.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.IR",
      "cs.LG",
      "q-bio.PE"
    ],
    "primary_category": "cs.CV",
    "comment": "12 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.10886v1",
    "published_date": "2025-03-13 21:18:10 UTC",
    "updated_date": "2025-03-13 21:18:10 UTC"
  },
  {
    "arxiv_id": "2503.11720v3",
    "title": "Fine-Tuning Diffusion Generative Models via Rich Preference Optimization",
    "authors": [
      "Hanyang Zhao",
      "Haoxian Chen",
      "Yucheng Guo",
      "Genta Indra Winata",
      "Tingting Ou",
      "Ziyu Huang",
      "David D. Yao",
      "Wenpin Tang"
    ],
    "abstract": "We introduce Rich Preference Optimization (RPO), a novel pipeline that\nleverages rich feedback signals to improve the curation of preference pairs for\nfine-tuning text-to-image diffusion models. Traditional methods, like\nDiffusion-DPO, often rely solely on reward model labeling, which can be opaque,\noffer limited insights into the rationale behind preferences, and are prone to\nissues such as reward hacking or overfitting. In contrast, our approach begins\nwith generating detailed critiques of synthesized images to extract reliable\nand actionable image editing instructions. By implementing these instructions,\nwe create refined images, resulting in synthetic, informative preference pairs\nthat serve as enhanced tuning datasets. We demonstrate the effectiveness of our\npipeline and the resulting datasets in fine-tuning state-of-the-art diffusion\nmodels.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.11720v3",
    "published_date": "2025-03-13 21:10:29 UTC",
    "updated_date": "2025-04-16 15:28:55 UTC"
  },
  {
    "arxiv_id": "2503.10883v1",
    "title": "Chat-TS: Enhancing Multi-Modal Reasoning Over Time-Series and Natural Language Data",
    "authors": [
      "Paul Quinlan",
      "Qingguo Li",
      "Xiaodan Zhu"
    ],
    "abstract": "Time-series analysis is critical for a wide range of fields such as\nhealthcare, finance, transportation, and energy, among many others. The\npractical applications often involve analyzing time-series data alongside\ncontextual information in the form of natural language to support informed\ndecisions. However, current time-series models are limited in their ability to\nperform reasoning that involves both time-series and their textual content. In\nthis work, we address this gap by introducing \\textit{Chat-TS}, a large\nlanguage model (LLM) based framework, designed to support reasoning over time\nseries and textual data. Unlike traditional models, Chat-TS integrates\ntime-series tokens into LLMs' vocabulary, enhancing its reasoning ability over\nboth modalities without compromising the core natural language capabilities,\nenabling practical analysis and reasoning across modalities. To support\nlearning and evaluation in this setup, we contribute new datasets: the\n\\textit{TS Instruct Training Dataset} which pairs diverse time-series data with\nrelevant text instructions and responses for instruction tuning, the \\textit{TS\nInstruct Question and Answer (QA) Gold Dataset} which provides multiple-choice\nquestions designed to evaluate multimodal reasoning, and a \\textit{TS Instruct\nQuantitative Probing Set} which contains a small subset of the TS Instruct QA\ntasks alongside math and decision-making questions for LLM evaluation. We\ndesigned a training strategy to preserve the inherent reasoning capabilities of\nLLMs while augmenting them for time-series reasoning. Experiments show that\nChat-TS achieves state-of-the-art performance in multi-modal reasoning tasks by\nmaintaining strong natural language proficiency while improving time-series\nreasoning. ~\\footnote{To ensure replicability and facilitate future research,\nall models, datasets, and code will be available at [\\texttt{Github-URL}].}",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.10883v1",
    "published_date": "2025-03-13 21:05:11 UTC",
    "updated_date": "2025-03-13 21:05:11 UTC"
  },
  {
    "arxiv_id": "2503.10879v2",
    "title": "Task-Specific Activation Functions for Neuroevolution using Grammatical Evolution",
    "authors": [
      "Benjamin David Winter",
      "William John Teahan"
    ],
    "abstract": "Activation functions play a critical role in the performance and behaviour of\nneural networks, significantly impacting their ability to learn and generalise.\nTraditional activation functions, such as ReLU, sigmoid, and tanh, have been\nwidely used with considerable success. However, these functions may not always\nprovide optimal performance for all tasks and datasets. In this paper, we\nintroduce Neuvo GEAF - an innovative approach leveraging grammatical evolution\n(GE) to automatically evolve novel activation functions tailored to specific\nneural network architectures and datasets. Experiments conducted on well-known\nbinary classification datasets show statistically significant improvements in\nF1-score (between 2.4% and 9.4%) over ReLU using identical network\narchitectures. Notably, these performance gains were achieved without\nincreasing the network's parameter count, supporting the trend toward more\nefficient neural networks that can operate effectively on resource-constrained\nedge devices. This paper's findings suggest that evolved activation functions\ncan provide significant performance improvements for compact networks while\nmaintaining energy efficiency during both training and inference phases.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "8 pages, 4 figures, IEEE",
    "pdf_url": "http://arxiv.org/pdf/2503.10879v2",
    "published_date": "2025-03-13 20:50:21 UTC",
    "updated_date": "2025-03-26 17:39:57 UTC"
  },
  {
    "arxiv_id": "2503.10872v2",
    "title": "TAIJI: Textual Anchoring for Immunizing Jailbreak Images in Vision Language Models",
    "authors": [
      "Xiangyu Yin",
      "Yi Qi",
      "Jinwei Hu",
      "Zhen Chen",
      "Yi Dong",
      "Xingyu Zhao",
      "Xiaowei Huang",
      "Wenjie Ruan"
    ],
    "abstract": "Vision Language Models (VLMs) have demonstrated impressive inference\ncapabilities, but remain vulnerable to jailbreak attacks that can induce\nharmful or unethical responses. Existing defence methods are predominantly\nwhite-box approaches that require access to model parameters and extensive\nmodifications, making them costly and impractical for many real-world\nscenarios. Although some black-box defences have been proposed, they often\nimpose input constraints or require multiple queries, limiting their\neffectiveness in safety-critical tasks such as autonomous driving. To address\nthese challenges, we propose a novel black-box defence framework called\n\\textbf{T}extual \\textbf{A}nchoring for \\textbf{I}mmunizing \\textbf{J}ailbreak\n\\textbf{I}mages (\\textbf{TAIJI}). TAIJI leverages key phrase-based textual\nanchoring to enhance the model's ability to assess and mitigate the harmful\ncontent embedded within both visual and textual prompts. Unlike existing\nmethods, TAIJI operates effectively with a single query during inference, while\npreserving the VLM's performance on benign tasks. Extensive experiments\ndemonstrate that TAIJI significantly enhances the safety and reliability of\nVLMs, providing a practical and efficient solution for real-world deployment.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.10872v2",
    "published_date": "2025-03-13 20:39:31 UTC",
    "updated_date": "2025-03-21 19:46:59 UTC"
  },
  {
    "arxiv_id": "2503.10869v1",
    "title": "Evaluating a Novel Neuroevolution and Neural Architecture Search System",
    "authors": [
      "Benjamin David Winter",
      "William John Teahan"
    ],
    "abstract": "The choice of neural network features can have a large impact on both the\naccuracy and speed of the network. Despite the current industry shift towards\nlarge transformer models, specialized binary classifiers remain critical for\nnumerous practical applications where computational efficiency and low latency\nare essential. Neural network features tend to be developed homogeneously,\nresulting in slower or less accurate networks when testing against multiple\ndatasets. In this paper, we show the effectiveness of Neuvo NAS+ a novel Python\nimplementation of an extended Neural Architecture Search (NAS+) which allows\nthe user to optimise the training parameters of a network as well as the\nnetwork's architecture. We provide an in-depth analysis of the importance of\ncatering a network's architecture to each dataset. We also describe the design\nof the Neuvo NAS+ system that selects network features on a task-specific basis\nincluding network training hyper-parameters such as the number of epochs and\nbatch size. Results show that the Neuvo NAS+ task-specific approach\nsignificantly outperforms several machine learning approaches such as Naive\nBayes, C4.5, Support Vector Machine and a standard Artificial Neural Network\nfor solving a range of binary classification problems in terms of accuracy. Our\nexperiments demonstrate substantial diversity in evolved network architectures\nacross different datasets, confirming the value of task-specific optimization.\nAdditionally, Neuvo NAS+ outperforms other evolutionary algorithm optimisers in\nterms of both accuracy and computational efficiency, showing that properly\noptimized binary classifiers can match or exceed the performance of more\ncomplex models while requiring significantly fewer computational resources.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "10 pages, 5 figures, IEEE",
    "pdf_url": "http://arxiv.org/pdf/2503.10869v1",
    "published_date": "2025-03-13 20:35:34 UTC",
    "updated_date": "2025-03-13 20:35:34 UTC"
  },
  {
    "arxiv_id": "2503.13509v1",
    "title": "MentalChat16K: A Benchmark Dataset for Conversational Mental Health Assistance",
    "authors": [
      "Jia Xu",
      "Tianyi Wei",
      "Bojian Hou",
      "Patryk Orzechowski",
      "Shu Yang",
      "Ruochen Jin",
      "Rachael Paulbeck",
      "Joost Wagenaar",
      "George Demiris",
      "Li Shen"
    ],
    "abstract": "We introduce MentalChat16K, an English benchmark dataset combining a\nsynthetic mental health counseling dataset and a dataset of anonymized\ntranscripts from interventions between Behavioral Health Coaches and Caregivers\nof patients in palliative or hospice care. Covering a diverse range of\nconditions like depression, anxiety, and grief, this curated dataset is\ndesigned to facilitate the development and evaluation of large language models\nfor conversational mental health assistance. By providing a high-quality\nresource tailored to this critical domain, MentalChat16K aims to advance\nresearch on empathetic, personalized AI solutions to improve access to mental\nhealth support services. The dataset prioritizes patient privacy, ethical\nconsiderations, and responsible data usage. MentalChat16K presents a valuable\nopportunity for the research community to innovate AI technologies that can\npositively impact mental well-being.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CY",
      "cs.HC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.13509v1",
    "published_date": "2025-03-13 20:25:10 UTC",
    "updated_date": "2025-03-13 20:25:10 UTC"
  },
  {
    "arxiv_id": "2503.10857v1",
    "title": "Towards Understanding Graphical Perception in Large Multimodal Models",
    "authors": [
      "Kai Zhang",
      "Jianwei Yang",
      "Jeevana Priya Inala",
      "Chandan Singh",
      "Jianfeng Gao",
      "Yu Su",
      "Chenglong Wang"
    ],
    "abstract": "Despite the promising results of large multimodal models (LMMs) in complex\nvision-language tasks that require knowledge, reasoning, and perception\nabilities together, we surprisingly found that these models struggle with\nsimple tasks on infographics that require perception only. As existing\nbenchmarks primarily focus on end tasks that require various abilities, they\nprovide limited, fine-grained insights into the limitations of the models'\nperception abilities. To address this gap, we leverage the theory of graphical\nperception, an approach used to study how humans decode visual information\nencoded on charts and graphs, to develop an evaluation framework for analyzing\ngaps in LMMs' perception abilities in charts. With automated task generation\nand response evaluation designs, our framework enables comprehensive and\ncontrolled testing of LMMs' graphical perception across diverse chart types,\nvisual elements, and task types. We apply our framework to evaluate and\ndiagnose the perception capabilities of state-of-the-art LMMs at three\ngranularity levels (chart, visual element, and pixel). Our findings underscore\nseveral critical limitations of current state-of-the-art LMMs, including\nGPT-4o: their inability to (1) generalize across chart types, (2) understand\nfundamental visual elements, and (3) cross reference values within a chart.\nThese insights provide guidance for future improvements in perception abilities\nof LMMs. The evaluation framework and labeled data are publicly available at\nhttps://github.com/microsoft/lmm-graphical-perception.",
    "categories": [
      "cs.GR",
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.GR",
    "comment": "Work in Progress",
    "pdf_url": "http://arxiv.org/pdf/2503.10857v1",
    "published_date": "2025-03-13 20:13:39 UTC",
    "updated_date": "2025-03-13 20:13:39 UTC"
  },
  {
    "arxiv_id": "2504.15286v1",
    "title": "CUBETESTERAI: Automated JUnit Test Generation using the LLaMA Model",
    "authors": [
      "Daniele Gorla",
      "Shivam Kumar",
      "Pietro Nicolaus Roselli Lorenzini",
      "Alireza Alipourfaz"
    ],
    "abstract": "This paper presents an approach to automating JUnit test generation for Java\napplications using the Spring Boot framework, leveraging the LLaMA (Large\nLanguage Model Architecture) model to enhance the efficiency and accuracy of\nthe testing process. The resulting tool, called CUBETESTERAI, includes a\nuser-friendly web interface and the integration of a CI/CD pipeline using\nGitLab and Docker. These components streamline the automated test generation\nprocess, allowing developers to generate JUnit tests directly from their code\nsnippets with minimal manual intervention. The final implementation executes\nthe LLaMA models through RunPod, an online GPU service, which also enhances the\nprivacy of our tool. Using the advanced natural language processing\ncapabilities of the LLaMA model, CUBETESTERAI is able to generate test cases\nthat provide high code coverage and accurate validation of software\nfunctionalities in Java-based Spring Boot applications. Furthermore, it\nefficiently manages resource-intensive operations and refines the generated\ntests to address common issues like missing imports and handling of private\nmethods. By comparing CUBETESTERAI with some state-of-the-art tools, we show\nthat our proposal consistently demonstrates competitive and, in many cases,\nbetter performance in terms of code coverage in different real-life Java\nprograms.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "Accepted to ICST 2025 Industry Track",
    "pdf_url": "http://arxiv.org/pdf/2504.15286v1",
    "published_date": "2025-03-13 19:44:09 UTC",
    "updated_date": "2025-03-13 19:44:09 UTC"
  },
  {
    "arxiv_id": "2503.13508v1",
    "title": "It is Too Many Options: Pitfalls of Multiple-Choice Questions in Generative AI and Medical Education",
    "authors": [
      "Shrutika Singh",
      "Anton Alyakin",
      "Daniel Alexander Alber",
      "Jaden Stryker",
      "Ai Phuong S Tong",
      "Karl Sangwon",
      "Nicolas Goff",
      "Mathew de la Paz",
      "Miguel Hernandez-Rovira",
      "Ki Yun Park",
      "Eric Claude Leuthardt",
      "Eric Karl Oermann"
    ],
    "abstract": "The performance of Large Language Models (LLMs) on multiple-choice question\n(MCQ) benchmarks is frequently cited as proof of their medical capabilities. We\nhypothesized that LLM performance on medical MCQs may in part be illusory and\ndriven by factors beyond medical content knowledge and reasoning capabilities.\nTo assess this, we created a novel benchmark of free-response questions with\npaired MCQs (FreeMedQA). Using this benchmark, we evaluated three\nstate-of-the-art LLMs (GPT-4o, GPT-3.5, and LLama-3-70B-instruct) and found an\naverage absolute deterioration of 39.43% in performance on free-response\nquestions relative to multiple-choice (p = 1.3 * 10-5) which was greater than\nthe human performance decline of 22.29%. To isolate the role of the MCQ format\non performance, we performed a masking study, iteratively masking out parts of\nthe question stem. At 100% masking, the average LLM multiple-choice performance\nwas 6.70% greater than random chance (p = 0.002) with one LLM (GPT-4o)\nobtaining an accuracy of 37.34%. Notably, for all LLMs the free-response\nperformance was near zero. Our results highlight the shortcomings in medical\nMCQ benchmarks for overestimating the capabilities of LLMs in medicine, and,\nbroadly, the potential for improving both human and machine assessments using\nLLM-evaluated free-response questions.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "comment": "14 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.13508v1",
    "published_date": "2025-03-13 19:42:04 UTC",
    "updated_date": "2025-03-13 19:42:04 UTC"
  },
  {
    "arxiv_id": "2503.13507v1",
    "title": "NeurIPS 2023 LLM Efficiency Fine-tuning Competition",
    "authors": [
      "Mark Saroufim",
      "Yotam Perlitz",
      "Leshem Choshen",
      "Luca Antiga",
      "Greg Bowyer",
      "Christian Puhrsch",
      "Driss Guessous",
      "Supriya Rao",
      "Geeta Chauhan",
      "Ashvini Kumar",
      "Jindal Pawan Kumar",
      "Rajpoot Ankur Parikh",
      "Joe Isaacson",
      "Weiwei Yang"
    ],
    "abstract": "Our analysis of the NeurIPS 2023 large language model (LLM) fine-tuning\ncompetition revealed the following trend: top-performing models exhibit\nsignificant overfitting on benchmark datasets, mirroring the broader issue of\nbenchmark overfitting on popular leaderboards and that data curation is\nessential in order to get a high performing LLM. The competition, which\nconsisted of two stages - an open evaluation stage with publicly available\ntasks and a closed evaluation stage with unseen tasks - allowed us to assess\nthe generalizability of fine-tuned LLMs. Our results highlight the limitations\nof current benchmark-based evaluation schemes for generative models and\ndemonstrate the need for more robust evaluation methods. Notably, the winning\nsubmissions utilized standard open-source libraries and focused primarily on\ndata curation. To facilitate further research and promote reproducibility, we\nrelease all competition entries, Docker files, and evaluation infrastructure,\nproviding a valuable resource for the community to explore fine-tuning,\noverfitting, and reproducibility in LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "11 pages, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.13507v1",
    "published_date": "2025-03-13 19:35:40 UTC",
    "updated_date": "2025-03-13 19:35:40 UTC"
  },
  {
    "arxiv_id": "2503.10822v4",
    "title": "Reinforcement Learning and Life Cycle Assessment for a Circular Economy -- Towards Progressive Computer Science",
    "authors": [
      "Johannes Buchner"
    ],
    "abstract": "The aim of this paper is to discuss the potential of using methods from\nReinforcement Learning for Life Cycle Assessment in a circular economy, and to\npresent some new ideas in this direction. To give some context, we explain how\nReinforcement Learning was successfully applied in computer chess (and beyond).\nAs computer chess was historically called the \"drosophila of AI\", we start by\ndescribing a method for the board representation called 'rotated bitboards'\nthat can potentially also be applied in the context of sustainability. In the\nfirst part of this paper, the concepts of the bitboard-representation and the\nadvantages of (rotated) bitboards in move generation are explained. In order to\nillustrate those ideas practice, the concrete implementation of the\nmove-generator in FUSc# (a chess engine developed at FU Berlin in C# some years\nago) is described. In addition, rotated binary neural networks are discussed\nbriefly.\n  The second part deals with reinforcement learning in computer chess (and\nbeyond). We exemplify the progress that has been made in this field in the last\n15-20 years by comparing the \"state of the art\" from 2002-2008, when FUSc# was\ndeveloped, with the ground-breaking innovations connected to \"AlphaZero\". We\nreview some application of the ideas developed in AlphaZero in other domains,\ne.g. the \"other Alphas\" like AlphaFold, AlphaTensor, AlphaGeometry and\nAlphaProof. In the final part of the paper, we discuss the computer-science\nrelated challenges that changing the economic paradigm towards (absolute)\nsustainability poses and in how far what we call 'progressive computer science'\nneeds to contribute. Concrete challenges include the closing of material loops\nin a circular economy with Life Cycle Assessment in order to optimize for\n(absolute) sustainability, and we present some new ideas in this direction.",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "Minor corrections, e.g. in the bibliography",
    "pdf_url": "http://arxiv.org/pdf/2503.10822v4",
    "published_date": "2025-03-13 19:13:51 UTC",
    "updated_date": "2025-05-17 20:47:34 UTC"
  },
  {
    "arxiv_id": "2503.13505v1",
    "title": "Ensemble Learning for Large Language Models in Text and Code Generation: A Survey",
    "authors": [
      "Mari Ashiga",
      "Wei Jie",
      "Fan Wu",
      "Vardan Voskanyan",
      "Fateme Dinmohammadi",
      "Paul Brookes",
      "Jingzhi Gong",
      "Zheng Wang"
    ],
    "abstract": "Generative pretrained transformers (GPT) are the common large language models\n(LLMs) used for generating text from natural language inputs. However, the\nfixed properties of language parameters in individual LLMs can lead to\ninconsistencies in the generated outputs. This limitation also restricts the\nmodels' ability to represent diverse language patterns due to inherent biases.\nMoreover, many powerful LLMs are closed-source. This prevents organizations\nfrom integrating their data into these systems, raising concerns about data\nprivacy and limiting industry applications. Inspired by the successful\napplication of LLM ensemble models in text generation, recent literature has\nalso investigated their potential in code generation. This article reviews\nthese emerging LLM ensemble approaches. Our goal is to enhance readers'\nunderstanding of existing techniques and encourage further research and\npractical implementation, aiming to expand the real-world applications of LLM\nensemble models in both text and code generation. We categorize these\napproaches into seven main methods: weight merging, knowledge fusion, mixture\nof experts, reward ensemble, output ensemble, routing, and cascading. From this\nlist, we focus on four methods and models that show strong performance and\npotential for broader applications. We analyze their modeling steps, training\nmethods, and output features to provide a clear understanding of their\ncapabilities. Our findings highlight the benefits of LLM ensemble techniques.\nThese include better representation of diversity, improved output quality, and\ngreater flexibility in applications. This information offers valuable insights\nfor selecting models for various real-world tasks involving text and code\ngeneration, and potentially applying methods to multimodal LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Submitted to IEEE TAI",
    "pdf_url": "http://arxiv.org/pdf/2503.13505v1",
    "published_date": "2025-03-13 18:50:57 UTC",
    "updated_date": "2025-03-13 18:50:57 UTC"
  },
  {
    "arxiv_id": "2503.16507v1",
    "title": "Fewer Than 1% of Explainable AI Papers Validate Explainability with Humans",
    "authors": [
      "Ashley Suh",
      "Isabelle Hurley",
      "Nora Smith",
      "Ho Chit Siu"
    ],
    "abstract": "This late-breaking work presents a large-scale analysis of explainable AI\n(XAI) literature to evaluate claims of human explainability. We collaborated\nwith a professional librarian to identify 18,254 papers containing keywords\nrelated to explainability and interpretability. Of these, we find that only 253\npapers included terms suggesting human involvement in evaluating an XAI\ntechnique, and just 128 of those conducted some form of a human study. In other\nwords, fewer than 1% of XAI papers (0.7%) provide empirical evidence of human\nexplainability when compared to the broader body of XAI literature. Our\nfindings underscore a critical gap between claims of human explainability and\nevidence-based validation, raising concerns about the rigor of XAI research. We\ncall for increased emphasis on human evaluations in XAI studies and provide our\nliterature search methodology to enable both reproducibility and further\ninvestigation into this widespread issue.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "Extended Abstracts of the CHI Conference on Human Factors in\n  Computing Systems (CHI EA '25)",
    "pdf_url": "http://arxiv.org/pdf/2503.16507v1",
    "published_date": "2025-03-13 18:39:50 UTC",
    "updated_date": "2025-03-13 18:39:50 UTC"
  },
  {
    "arxiv_id": "2503.10792v1",
    "title": "Byzantine-Resilient Federated Learning via Distributed Optimization",
    "authors": [
      "Yufei Xia",
      "Wenrui Yu",
      "Qiongxiu Li"
    ],
    "abstract": "Byzantine attacks present a critical challenge to Federated Learning (FL),\nwhere malicious participants can disrupt the training process, degrade model\naccuracy, and compromise system reliability. Traditional FL frameworks\ntypically rely on aggregation-based protocols for model updates, leaving them\nvulnerable to sophisticated adversarial strategies. In this paper, we\ndemonstrate that distributed optimization offers a principled and robust\nalternative to aggregation-centric methods. Specifically, we show that the\nPrimal-Dual Method of Multipliers (PDMM) inherently mitigates Byzantine impacts\nby leveraging its fault-tolerant consensus mechanism. Through extensive\nexperiments on three datasets (MNIST, FashionMNIST, and Olivetti), under\nvarious attack scenarios including bit-flipping and Gaussian noise injection,\nwe validate the superior resilience of distributed optimization protocols.\nCompared to traditional aggregation-centric approaches, PDMM achieves higher\nmodel utility, faster convergence, and improved stability. Our results\nhighlight the effectiveness of distributed optimization in defending against\nByzantine threats, paving the way for more secure and resilient federated\nlearning systems.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.10792v1",
    "published_date": "2025-03-13 18:34:42 UTC",
    "updated_date": "2025-03-13 18:34:42 UTC"
  },
  {
    "arxiv_id": "2503.10784v1",
    "title": "Vulnerability Detection: From Formal Verification to Large Language Models and Hybrid Approaches: A Comprehensive Overview",
    "authors": [
      "Norbert Tihanyi",
      "Tamas Bisztray",
      "Mohamed Amine Ferrag",
      "Bilel Cherif",
      "Richard A. Dubniczky",
      "Ridhi Jain",
      "Lucas C. Cordeiro"
    ],
    "abstract": "Software testing and verification are critical for ensuring the reliability\nand security of modern software systems. Traditionally, formal verification\ntechniques, such as model checking and theorem proving, have provided rigorous\nframeworks for detecting bugs and vulnerabilities. However, these methods often\nface scalability challenges when applied to complex, real-world programs.\nRecently, the advent of Large Language Models (LLMs) has introduced a new\nparadigm for software analysis, leveraging their ability to understand insecure\ncoding practices. Although LLMs demonstrate promising capabilities in tasks\nsuch as bug prediction and invariant generation, they lack the formal\nguarantees of classical methods. This paper presents a comprehensive study of\nstate-of-the-art software testing and verification, focusing on three key\napproaches: classical formal methods, LLM-based analysis, and emerging hybrid\ntechniques, which combine their strengths. We explore each approach's\nstrengths, limitations, and practical applications, highlighting the potential\nof hybrid systems to address the weaknesses of standalone methods. We analyze\nwhether integrating formal rigor with LLM-driven insights can enhance the\neffectiveness and scalability of software verification, exploring their\nviability as a pathway toward more robust and adaptive testing frameworks.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.10784v1",
    "published_date": "2025-03-13 18:22:22 UTC",
    "updated_date": "2025-03-13 18:22:22 UTC"
  },
  {
    "arxiv_id": "2503.10638v1",
    "title": "Studying Classifier(-Free) Guidance From a Classifier-Centric Perspective",
    "authors": [
      "Xiaoming Zhao",
      "Alexander G. Schwing"
    ],
    "abstract": "Classifier-free guidance has become a staple for conditional generation with\ndenoising diffusion models. However, a comprehensive understanding of\nclassifier-free guidance is still missing. In this work, we carry out an\nempirical study to provide a fresh perspective on classifier-free guidance.\nConcretely, instead of solely focusing on classifier-free guidance, we trace\nback to the root, i.e., classifier guidance, pinpoint the key assumption for\nthe derivation, and conduct a systematic study to understand the role of the\nclassifier. We find that both classifier guidance and classifier-free guidance\nachieve conditional generation by pushing the denoising diffusion trajectories\naway from decision boundaries, i.e., areas where conditional information is\nusually entangled and is hard to learn. Based on this classifier-centric\nunderstanding, we propose a generic postprocessing step built upon\nflow-matching to shrink the gap between the learned distribution for a\npre-trained denoising diffusion model and the real data distribution, majorly\naround the decision boundaries. Experiments on various datasets verify the\neffectiveness of the proposed approach.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.10638v1",
    "published_date": "2025-03-13 17:59:59 UTC",
    "updated_date": "2025-03-13 17:59:59 UTC"
  },
  {
    "arxiv_id": "2503.10635v1",
    "title": "A Frustratingly Simple Yet Highly Effective Attack Baseline: Over 90% Success Rate Against the Strong Black-box Models of GPT-4.5/4o/o1",
    "authors": [
      "Zhaoyi Li",
      "Xiaohan Zhao",
      "Dong-Dong Wu",
      "Jiacheng Cui",
      "Zhiqiang Shen"
    ],
    "abstract": "Despite promising performance on open-source large vision-language models\n(LVLMs), transfer-based targeted attacks often fail against black-box\ncommercial LVLMs. Analyzing failed adversarial perturbations reveals that the\nlearned perturbations typically originate from a uniform distribution and lack\nclear semantic details, resulting in unintended responses. This critical\nabsence of semantic information leads commercial LVLMs to either ignore the\nperturbation entirely or misinterpret its embedded semantics, thereby causing\nthe attack to fail. To overcome these issues, we notice that identifying core\nsemantic objects is a key objective for models trained with various datasets\nand methodologies. This insight motivates our approach that refines semantic\nclarity by encoding explicit semantic details within local regions, thus\nensuring interoperability and capturing finer-grained features, and by\nconcentrating modifications on semantically rich areas rather than applying\nthem uniformly. To achieve this, we propose a simple yet highly effective\nsolution: at each optimization step, the adversarial image is cropped randomly\nby a controlled aspect ratio and scale, resized, and then aligned with the\ntarget image in the embedding space. Experimental results confirm our\nhypothesis. Our adversarial examples crafted with local-aggregated\nperturbations focused on crucial regions exhibit surprisingly good\ntransferability to commercial LVLMs, including GPT-4.5, GPT-4o,\nGemini-2.0-flash, Claude-3.5-sonnet, Claude-3.7-sonnet, and even reasoning\nmodels like o1, Claude-3.7-thinking and Gemini-2.0-flash-thinking. Our approach\nachieves success rates exceeding 90% on GPT-4.5, 4o, and o1, significantly\noutperforming all prior state-of-the-art attack methods. Our optimized\nadversarial examples under different configurations and training code are\navailable at https://github.com/VILA-Lab/M-Attack.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Code at: https://github.com/VILA-Lab/M-Attack",
    "pdf_url": "http://arxiv.org/pdf/2503.10635v1",
    "published_date": "2025-03-13 17:59:55 UTC",
    "updated_date": "2025-03-13 17:59:55 UTC"
  },
  {
    "arxiv_id": "2503.10628v1",
    "title": "Uncertainty in Action: Confidence Elicitation in Embodied Agents",
    "authors": [
      "Tianjiao Yu",
      "Vedant Shah",
      "Muntasir Wahed",
      "Kiet A. Nguyen",
      "Adheesh Juvekar",
      "Tal August",
      "Ismini Lourentzou"
    ],
    "abstract": "Expressing confidence is challenging for embodied agents navigating dynamic\nmultimodal environments, where uncertainty arises from both perception and\ndecision-making processes. We present the first work investigating embodied\nconfidence elicitation in open-ended multimodal environments. We introduce\nElicitation Policies, which structure confidence assessment across inductive,\ndeductive, and abductive reasoning, along with Execution Policies, which\nenhance confidence calibration through scenario reinterpretation, action\nsampling, and hypothetical reasoning. Evaluating agents in calibration and\nfailure prediction tasks within the Minecraft environment, we show that\nstructured reasoning approaches, such as Chain-of-Thoughts, improve confidence\ncalibration. However, our findings also reveal persistent challenges in\ndistinguishing uncertainty, particularly under abductive settings, underscoring\nthe need for more sophisticated embodied confidence elicitation methods.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Project page: https://plan-lab.github.io/ece/",
    "pdf_url": "http://arxiv.org/pdf/2503.10628v1",
    "published_date": "2025-03-13 17:59:41 UTC",
    "updated_date": "2025-03-13 17:59:41 UTC"
  },
  {
    "arxiv_id": "2503.10627v1",
    "title": "SciVerse: Unveiling the Knowledge Comprehension and Visual Reasoning of LMMs on Multi-modal Scientific Problems",
    "authors": [
      "Ziyu Guo",
      "Ray Zhang",
      "Hao Chen",
      "Jialin Gao",
      "Dongzhi Jiang",
      "Jiaze Wang",
      "Pheng-Ann Heng"
    ],
    "abstract": "The rapid advancement of Large Multi-modal Models (LMMs) has enabled their\napplication in scientific problem-solving, yet their fine-grained capabilities\nremain under-explored. In this paper, we introduce SciVerse, a multi-modal\nscientific evaluation benchmark to thoroughly assess LMMs across 5,735 test\ninstances in five distinct versions. We aim to investigate three key dimensions\nof LMMs: scientific knowledge comprehension, multi-modal content\ninterpretation, and Chain-of-Thought (CoT) reasoning. To unveil whether LMMs\npossess sufficient scientific expertise, we first transform each problem into\nthree versions containing different levels of knowledge required for solving,\ni.e., Knowledge-free, -lite, and -rich. Then, to explore how LMMs interpret\nmulti-modal scientific content, we annotate another two versions, i.e.,\nVision-rich and -only, marking more question information from texts to\ndiagrams. Comparing the results of different versions, SciVerse systematically\nexamines the professional knowledge stock and visual perception skills of LMMs\nin scientific domains. In addition, to rigorously assess CoT reasoning, we\npropose a new scientific CoT evaluation strategy, conducting a step-wise\nassessment on knowledge and logical errors in model outputs. Our extensive\nevaluation of different LMMs on SciVerse reveals critical limitations in their\nscientific proficiency and provides new insights into future developments.\nProject page: https://sciverse-cuhk.github.io",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "Initially released in September 2024. Project page:\n  https://sciverse-cuhk.github.io",
    "pdf_url": "http://arxiv.org/pdf/2503.10627v1",
    "published_date": "2025-03-13 17:59:32 UTC",
    "updated_date": "2025-03-13 17:59:32 UTC"
  },
  {
    "arxiv_id": "2503.10626v1",
    "title": "NIL: No-data Imitation Learning by Leveraging Pre-trained Video Diffusion Models",
    "authors": [
      "Mert Albaba",
      "Chenhao Li",
      "Markos Diomataris",
      "Omid Taheri",
      "Andreas Krause",
      "Michael Black"
    ],
    "abstract": "Acquiring physically plausible motor skills across diverse and unconventional\nmorphologies-including humanoid robots, quadrupeds, and animals-is essential\nfor advancing character simulation and robotics. Traditional methods, such as\nreinforcement learning (RL) are task- and body-specific, require extensive\nreward function engineering, and do not generalize well. Imitation learning\noffers an alternative but relies heavily on high-quality expert demonstrations,\nwhich are difficult to obtain for non-human morphologies. Video diffusion\nmodels, on the other hand, are capable of generating realistic videos of\nvarious morphologies, from humans to ants. Leveraging this capability, we\npropose a data-independent approach for skill acquisition that learns 3D motor\nskills from 2D-generated videos, with generalization capability to\nunconventional and non-human forms. Specifically, we guide the imitation\nlearning process by leveraging vision transformers for video-based comparisons\nby calculating pair-wise distance between video embeddings. Along with\nvideo-encoding distance, we also use a computed similarity between segmented\nvideo frames as a guidance reward. We validate our method on locomotion tasks\ninvolving unique body configurations. In humanoid robot locomotion tasks, we\ndemonstrate that 'No-data Imitation Learning' (NIL) outperforms baselines\ntrained on 3D motion-capture data. Our results highlight the potential of\nleveraging generative video models for physically plausible skill learning with\ndiverse morphologies, effectively replacing data collection with data\ngeneration for imitation learning.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.10626v1",
    "published_date": "2025-03-13 17:59:24 UTC",
    "updated_date": "2025-03-13 17:59:24 UTC"
  },
  {
    "arxiv_id": "2503.10625v1",
    "title": "LHM: Large Animatable Human Reconstruction Model from a Single Image in Seconds",
    "authors": [
      "Lingteng Qiu",
      "Xiaodong Gu",
      "Peihao Li",
      "Qi Zuo",
      "Weichao Shen",
      "Junfei Zhang",
      "Kejie Qiu",
      "Weihao Yuan",
      "Guanying Chen",
      "Zilong Dong",
      "Liefeng Bo"
    ],
    "abstract": "Animatable 3D human reconstruction from a single image is a challenging\nproblem due to the ambiguity in decoupling geometry, appearance, and\ndeformation. Recent advances in 3D human reconstruction mainly focus on static\nhuman modeling, and the reliance of using synthetic 3D scans for training\nlimits their generalization ability. Conversely, optimization-based video\nmethods achieve higher fidelity but demand controlled capture conditions and\ncomputationally intensive refinement processes. Motivated by the emergence of\nlarge reconstruction models for efficient static reconstruction, we propose LHM\n(Large Animatable Human Reconstruction Model) to infer high-fidelity avatars\nrepresented as 3D Gaussian splatting in a feed-forward pass. Our model\nleverages a multimodal transformer architecture to effectively encode the human\nbody positional features and image features with attention mechanism, enabling\ndetailed preservation of clothing geometry and texture. To further boost the\nface identity preservation and fine detail recovery, we propose a head feature\npyramid encoding scheme to aggregate multi-scale features of the head regions.\nExtensive experiments demonstrate that our LHM generates plausible animatable\nhuman in seconds without post-processing for face and hands, outperforming\nexisting methods in both reconstruction accuracy and generalization ability.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Project Page: https://lingtengqiu.github.io/LHM/",
    "pdf_url": "http://arxiv.org/pdf/2503.10625v1",
    "published_date": "2025-03-13 17:59:21 UTC",
    "updated_date": "2025-03-13 17:59:21 UTC"
  },
  {
    "arxiv_id": "2503.10624v1",
    "title": "ETCH: Generalizing Body Fitting to Clothed Humans via Equivariant Tightness",
    "authors": [
      "Boqian Li",
      "Haiwen Feng",
      "Zeyu Cai",
      "Michael J. Black",
      "Yuliang Xiu"
    ],
    "abstract": "Fitting a body to a 3D clothed human point cloud is a common yet challenging\ntask. Traditional optimization-based approaches use multi-stage pipelines that\nare sensitive to pose initialization, while recent learning-based methods often\nstruggle with generalization across diverse poses and garment types. We propose\nEquivariant Tightness Fitting for Clothed Humans, or ETCH, a novel pipeline\nthat estimates cloth-to-body surface mapping through locally approximate SE(3)\nequivariance, encoding tightness as displacement vectors from the cloth surface\nto the underlying body. Following this mapping, pose-invariant body features\nregress sparse body markers, simplifying clothed human fitting into an\ninner-body marker fitting task. Extensive experiments on CAPE and 4D-Dress show\nthat ETCH significantly outperforms state-of-the-art methods -- both\ntightness-agnostic and tightness-aware -- in body fitting accuracy on loose\nclothing (16.7% ~ 69.5%) and shape accuracy (average 49.9%). Our equivariant\ntightness design can even reduce directional errors by (67.2% ~ 89.8%) in\none-shot (or out-of-distribution) settings. Qualitative results demonstrate\nstrong generalization of ETCH, regardless of challenging poses, unseen shapes,\nloose clothing, and non-rigid dynamics. We will release the code and models\nsoon for research purposes at https://boqian-li.github.io/ETCH/.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR"
    ],
    "primary_category": "cs.CV",
    "comment": "Page: https://boqian-li.github.io/ETCH/, Code:\n  https://github.com/boqian-li/ETCH",
    "pdf_url": "http://arxiv.org/pdf/2503.10624v1",
    "published_date": "2025-03-13 17:59:14 UTC",
    "updated_date": "2025-03-13 17:59:14 UTC"
  },
  {
    "arxiv_id": "2503.10622v1",
    "title": "Transformers without Normalization",
    "authors": [
      "Jiachen Zhu",
      "Xinlei Chen",
      "Kaiming He",
      "Yann LeCun",
      "Zhuang Liu"
    ],
    "abstract": "Normalization layers are ubiquitous in modern neural networks and have long\nbeen considered essential. This work demonstrates that Transformers without\nnormalization can achieve the same or better performance using a remarkably\nsimple technique. We introduce Dynamic Tanh (DyT), an element-wise operation\n$DyT($x$) = \\tanh(\\alpha $x$)$, as a drop-in replacement for normalization\nlayers in Transformers. DyT is inspired by the observation that layer\nnormalization in Transformers often produces tanh-like, $S$-shaped input-output\nmappings. By incorporating DyT, Transformers without normalization can match or\nexceed the performance of their normalized counterparts, mostly without\nhyperparameter tuning. We validate the effectiveness of Transformers with DyT\nacross diverse settings, ranging from recognition to generation, supervised to\nself-supervised learning, and computer vision to language models. These\nfindings challenge the conventional understanding that normalization layers are\nindispensable in modern neural networks, and offer new insights into their role\nin deep networks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "CVPR 2025; Project page: https://jiachenzhu.github.io/DyT/",
    "pdf_url": "http://arxiv.org/pdf/2503.10622v1",
    "published_date": "2025-03-13 17:59:06 UTC",
    "updated_date": "2025-03-13 17:59:06 UTC"
  },
  {
    "arxiv_id": "2503.10619v4",
    "title": "Tempest: Autonomous Multi-Turn Jailbreaking of Large Language Models with Tree Search",
    "authors": [
      "Andy Zhou",
      "Ron Arel"
    ],
    "abstract": "We introduce Tempest, a multi-turn adversarial framework that models the\ngradual erosion of Large Language Model (LLM) safety through a tree search\nperspective. Unlike single-turn jailbreaks that rely on one meticulously\nengineered prompt, Tempest expands the conversation at each turn in a\nbreadth-first fashion, branching out multiple adversarial prompts that exploit\npartial compliance from previous responses. By tracking these incremental\npolicy leaks and re-injecting them into subsequent queries, Tempest reveals how\nminor concessions can accumulate into fully disallowed outputs. Evaluations on\nthe JailbreakBench dataset show that Tempest achieves a 100% success rate on\nGPT-3.5-turbo and 97% on GPT-4 in a single multi-turn run, using fewer queries\nthan baselines such as Crescendo or GOAT. This tree search methodology offers\nan in-depth view of how model safeguards degrade over successive dialogue\nturns, underscoring the urgency of robust multi-turn testing procedures for\nlanguage models.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CR"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted to ACL 2025 Main",
    "pdf_url": "http://arxiv.org/pdf/2503.10619v4",
    "published_date": "2025-03-13 17:57:32 UTC",
    "updated_date": "2025-05-21 05:06:50 UTC"
  },
  {
    "arxiv_id": "2503.10617v3",
    "title": "Compositional Subspace Representation Fine-tuning for Adaptive Large Language Models",
    "authors": [
      "Andy Zhou"
    ],
    "abstract": "Adapting large language models to multiple tasks can cause cross-skill\ninterference, where improvements for one skill degrade another. While methods\nsuch as LoRA impose orthogonality constraints at the weight level, they do not\nfully address interference in hidden-state representations. We propose\nCompositional Subspace Representation Fine-tuning (CS-ReFT), a novel\nrepresentation-based approach that learns multiple orthonormal subspace\ntransformations, each specializing in a distinct skill, and composes them via a\nlightweight router. By isolating these subspace edits in the hidden state,\nrather than weight matrices, CS-ReFT prevents cross-task conflicts more\neffectively. On the AlpacaEval benchmark, applying CS-ReFT to Llama-2-7B\nachieves a 93.94% win rate, surpassing GPT-3.5 Turbo (86.30%) while requiring\nonly 0.0098% of model parameters. These findings show that specialized\nrepresentation edits, composed via a simple router, significantly enhance\nmulti-task instruction following with minimal overhead.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to ICLR 2025 SCOPE",
    "pdf_url": "http://arxiv.org/pdf/2503.10617v3",
    "published_date": "2025-03-13 17:57:04 UTC",
    "updated_date": "2025-04-26 02:35:54 UTC"
  },
  {
    "arxiv_id": "2503.10745v2",
    "title": "Unifying 2D and 3D Vision-Language Understanding",
    "authors": [
      "Ayush Jain",
      "Alexander Swerdlow",
      "Yuzhou Wang",
      "Sergio Arnaud",
      "Ada Martin",
      "Alexander Sax",
      "Franziska Meier",
      "Katerina Fragkiadaki"
    ],
    "abstract": "Progress in 3D vision-language learning has been hindered by the scarcity of\nlarge-scale 3D datasets. We introduce UniVLG, a unified architecture for 2D and\n3D vision-language understanding that bridges the gap between existing\n2D-centric models and the rich 3D sensory data available in embodied systems.\nOur approach initializes most model weights from pre-trained 2D models and\ntrains on both 2D and 3D vision-language data. We propose a novel\nlanguage-conditioned mask decoder shared across 2D and 3D modalities to ground\nobjects effectively in both RGB and RGB-D images, outperforming box-based\napproaches. To further reduce the domain gap between 2D and 3D, we incorporate\n2D-to-3D lifting strategies, enabling UniVLG to utilize 2D data to enhance 3D\nperformance. With these innovations, our model achieves state-of-the-art\nperformance across multiple 3D vision-language grounding tasks, demonstrating\nthe potential of transferring advances from 2D vision-language learning to the\ndata-constrained 3D domain. Furthermore, co-training on both 2D and 3D data\nenhances performance across modalities without sacrificing 2D capabilities. By\nremoving the reliance on 3D mesh reconstruction and ground-truth object\nproposals, UniVLG sets a new standard for realistic, embodied-aligned\nevaluation. Code and additional visualizations are available at\nhttps://univlg.github.io .",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "The first two authors contributed equally",
    "pdf_url": "http://arxiv.org/pdf/2503.10745v2",
    "published_date": "2025-03-13 17:56:22 UTC",
    "updated_date": "2025-03-20 16:24:10 UTC"
  },
  {
    "arxiv_id": "2503.10603v3",
    "title": "Technical Approach for the EMI Challenge in the 8th Affective Behavior Analysis in-the-Wild Competition",
    "authors": [
      "Jun Yu",
      "Lingsi Zhu",
      "Yanjun Chi",
      "Yunxiang Zhang",
      "Yang Zheng",
      "Yongqi Wang",
      "Xilong Lu"
    ],
    "abstract": "Emotional Mimicry Intensity (EMI) estimation plays a pivotal role in\nunderstanding human social behavior and advancing human-computer interaction.\nThe core challenges lie in dynamic correlation modeling and robust fusion of\nmultimodal temporal signals. To address the limitations of existing\nmethods--insufficient exploitation of cross-modal synergies, sensitivity to\nnoise, and constrained fine-grained alignment capabilities--this paper proposes\na dual-stage cross-modal alignment framework. Stage 1 develops vision-text and\naudio-text contrastive learning networks based on a CLIP architecture,\nachieving preliminary feature-space alignment through modality-decoupled\npre-training. Stage 2 introduces a temporal-aware dynamic fusion module\nintegrating Temporal Convolutional Networks (TCN) and gated bidirectional LSTM\nto capture macro-evolution patterns of facial expressions and local dynamics of\nacoustic features, respectively. A novel quality-guided fusion strategy further\nenables differentiable weight allocation for modality compensation under\nocclusion and noise. Experiments on the Hume-Vidmimic2 dataset demonstrate\nsuperior performance with an average Pearson correlation coefficient of 0.51\nacross six emotion dimensions on the validate set. Remarkably, our method\nachieved 0.68 on the test set, securing runner-up in the EMI Challenge Track of\nthe 8th ABAW (Affective Behavior Analysis in the Wild) Competition, offering a\nnovel pathway for fine-grained emotion analysis in open environments.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.10603v3",
    "published_date": "2025-03-13 17:46:16 UTC",
    "updated_date": "2025-03-25 08:46:00 UTC"
  },
  {
    "arxiv_id": "2503.10602v2",
    "title": "TruthPrInt: Mitigating LVLM Object Hallucination Via Latent Truthful-Guided Pre-Intervention",
    "authors": [
      "Jinhao Duan",
      "Fei Kong",
      "Hao Cheng",
      "James Diffenderfer",
      "Bhavya Kailkhura",
      "Lichao Sun",
      "Xiaofeng Zhu",
      "Xiaoshuang Shi",
      "Kaidi Xu"
    ],
    "abstract": "Object Hallucination (OH) has been acknowledged as one of the major\ntrustworthy challenges in Large Vision-Language Models (LVLMs). Recent\nadvancements in Large Language Models (LLMs) indicate that internal states,\nsuch as hidden states, encode the \"overall truthfulness\" of generated\nresponses. However, it remains under-explored how internal states in LVLMs\nfunction and whether they could serve as \"per-token\" hallucination indicators,\nwhich is essential for mitigating OH. In this paper, we first conduct an\nin-depth exploration of LVLM internal states in relation to OH issues and\ndiscover that (1) LVLM internal states are high-specificity per-token\nindicators of hallucination behaviors. Moreover, (2) different LVLMs encode\nuniversal patterns of hallucinations in common latent subspaces, indicating\nthat there exist \"generic truthful directions\" shared by various LVLMs. Based\non these discoveries, we propose Truthful-Guided Pre-Intervention (TruthPrInt)\nthat first learns the truthful direction of LVLM decoding and then applies\ntruthful-guided inference-time intervention during LVLM decoding. We further\npropose ComnHallu to enhance both cross-LVLM and cross-data hallucination\ndetection transferability by constructing and aligning hallucination latent\nsubspaces. We evaluate TruthPrInt in extensive experimental settings, including\nin-domain and out-of-domain scenarios, over popular LVLMs and OH benchmarks.\nExperimental results indicate that TruthPrInt significantly outperforms\nstate-of-the-art methods. Codes will be available at\nhttps://github.com/jinhaoduan/TruthPrInt.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "15 pages, 9 figures, the first two authors contributed equally",
    "pdf_url": "http://arxiv.org/pdf/2503.10602v2",
    "published_date": "2025-03-13 17:46:06 UTC",
    "updated_date": "2025-03-21 15:58:26 UTC"
  },
  {
    "arxiv_id": "2504.07103v1",
    "title": "FG-RAG: Enhancing Query-Focused Summarization with Context-Aware Fine-Grained Graph RAG",
    "authors": [
      "Yubin Hong",
      "Chaofan Li",
      "Jingyi Zhang",
      "Yingxia Shao"
    ],
    "abstract": "Retrieval-Augmented Generation (RAG) enables large language models to provide\nmore precise and pertinent responses by incorporating external knowledge. In\nthe Query-Focused Summarization (QFS) task, GraphRAG-based approaches have\nnotably enhanced the comprehensiveness and diversity of generated responses.\nHowever, existing GraphRAG-based approaches predominantly focus on\ncoarse-grained information summarization without being aware of the specific\nquery, and the retrieved content lacks sufficient contextual information to\ngenerate comprehensive responses. To address the deficiencies of current RAG\nsystems, we propose Context-Aware Fine-Grained Graph RAG (FG-RAG) to enhance\nthe performance of the QFS task. FG-RAG employs Context-Aware Entity Expansion\nin graph retrieval to expand the coverage of retrieved entities in the graph,\nthus providing enough contextual information for the retrieved content.\nFurthermore, FG-RAG utilizes Query-Level Fine-Grained Summarization to\nincorporate fine-grained details during response generation, enhancing query\nawareness for the generated summarization. Our evaluation demonstrates that\nFG-RAG outperforms other RAG systems in multiple metrics of comprehensiveness,\ndiversity, and empowerment when handling the QFS task. Our implementation is\navailable at https://github.com/BuptWululu/FG-RAG.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07103v1",
    "published_date": "2025-03-13 17:42:07 UTC",
    "updated_date": "2025-03-13 17:42:07 UTC"
  },
  {
    "arxiv_id": "2503.10741v1",
    "title": "Predicting Treatment Response in Body Dysmorphic Disorder with Interpretable Machine Learning",
    "authors": [
      "Omar Costilla-Reyes",
      "Morgan Talbot"
    ],
    "abstract": "Body Dysmorphic Disorder (BDD) is a highly prevalent and frequently\nunderdiagnosed condition characterized by persistent, intrusive preoccupations\nwith perceived defects in physical appearance. In this extended analysis, we\nemploy multiple machine learning approaches to predict treatment outcomes --\nspecifically treatment response and remission -- with an emphasis on\ninterpretability to ensure clinical relevance and utility. Across the various\nmodels investigated, treatment credibility emerged as the most potent\npredictor, surpassing traditional markers such as baseline symptom severity or\ncomorbid conditions. Notably, while simpler models (e.g., logistic regression\nand support vector machines) achieved competitive predictive performance,\ndecision tree analyses provided unique insights by revealing clinically\ninterpretable threshold values in credibility scores. These thresholds can\nserve as practical guideposts for clinicians when tailoring interventions or\nallocating treatment resources. We further contextualize our findings within\nthe broader literature on BDD, addressing technology-based therapeutics,\ndigital interventions, and the psychosocial determinants of treatment\nengagement. An extensive array of references situates our results within\ncurrent research on BDD prevalence, suicidality risks, and digital innovation.\nOur work underscores the potential of integrating rigorous statistical\nmethodologies with transparent machine learning models. By systematically\nidentifying modifiable predictors -- such as treatment credibility -- we\npropose a pathway toward more targeted, personalized, and ultimately\nefficacious interventions for individuals with BDD.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.10741v1",
    "published_date": "2025-03-13 17:39:10 UTC",
    "updated_date": "2025-03-13 17:39:10 UTC"
  },
  {
    "arxiv_id": "2503.10587v1",
    "title": "The Spectral Bias of Shallow Neural Network Learning is Shaped by the Choice of Non-linearity",
    "authors": [
      "Justin Sahs",
      "Ryan Pyle",
      "Fabio Anselmi",
      "Ankit Patel"
    ],
    "abstract": "Despite classical statistical theory predicting severe overfitting, modern\nmassively overparameterized neural networks still generalize well. This\nunexpected property is attributed to the network's so-called implicit bias,\nwhich describes its propensity to converge to solutions that generalize\neffectively, among the many possible that correctly label the training data.\nThe aim of our research is to explore this bias from a new perspective,\nfocusing on how non-linear activation functions contribute to shaping it.\nFirst, we introduce a reparameterization which removes a continuous weight\nrescaling symmetry. Second, in the kernel regime, we leverage this\nreparameterization to generalize recent findings that relate shallow Neural\nNetworks to the Radon transform, deriving an explicit formula for the implicit\nbias induced by a broad class of activation functions. Specifically, by\nutilizing the connection between the Radon transform and the Fourier transform,\nwe interpret the kernel regime's inductive bias as minimizing a spectral\nseminorm that penalizes high-frequency components, in a manner dependent on the\nactivation function. Finally, in the adaptive regime, we demonstrate the\nexistence of local dynamical attractors that facilitate the formation of\nclusters of hyperplanes where the input to a neuron's activation function is\nzero, yielding alignment between many neurons' response functions. We confirm\nthese theoretical results with simulations. All together, our work provides a\ndeeper understanding of the mechanisms underlying the generalization\ncapabilities of overparameterized neural networks and its relation with the\nimplicit bias, offering potential pathways for designing more efficient and\nrobust models.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "18 pages, 10 figures in main text",
    "pdf_url": "http://arxiv.org/pdf/2503.10587v1",
    "published_date": "2025-03-13 17:36:46 UTC",
    "updated_date": "2025-03-13 17:36:46 UTC"
  },
  {
    "arxiv_id": "2503.10582v2",
    "title": "VisualWebInstruct: Scaling up Multimodal Instruction Data through Web Search",
    "authors": [
      "Yiming Jia",
      "Jiachen Li",
      "Xiang Yue",
      "Bo Li",
      "Ping Nie",
      "Kai Zou",
      "Wenhu Chen"
    ],
    "abstract": "Vision-Language Models have made significant progress on many\nperception-focused tasks. However, their progress on reasoning-focused tasks\nremains limited due to the lack of high-quality and diverse training data. In\nthis work, we aim to address the scarcity of reasoning-focused multimodal\ndatasets. We propose VisualWebInstruct, a novel approach that leverages search\nengines to create a diverse and high-quality dataset spanning multiple\ndisciplines, including mathematics, physics, finance, and chemistry, etc.\nStarting with a meticulously selected set of 30,000 seed images, we employ\nGoogle Image Search to identify websites containing similar images. We collect\nand process HTML data from over 700K unique URLs. Through a pipeline of content\nextraction, filtering, and synthesis, we construct a dataset of approximately\n900K question-answer (QA) pairs, with 40% consisting of visual QA pairs and the\nremaining comprising text-based QA pairs. Models fine-tuned on\nVisualWebInstruct demonstrate significant performance improvements: (1)\nfine-tuning on Llava-OV results in 10-20 absolute points improvement across\nbenchmarks, and (2) fine-tuning from MAmmoTH-VL yields a 5 absolute points gain\nacross benchmarks. Our best model, MAmmoTH-VL2, achieves state-of-the-art\nperformance within the 10B parameter class on MMMU-Pro (40.7), MathVerse\n(42.6), and DynaMath (55.7). These results highlight the effectiveness of our\ndataset in enhancing the reasoning capabilities of vision-language models for\ncomplex multimodal tasks.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "Technical Report",
    "pdf_url": "http://arxiv.org/pdf/2503.10582v2",
    "published_date": "2025-03-13 17:32:48 UTC",
    "updated_date": "2025-03-15 01:09:17 UTC"
  },
  {
    "arxiv_id": "2503.10546v1",
    "title": "KUDA: Keypoints to Unify Dynamics Learning and Visual Prompting for Open-Vocabulary Robotic Manipulation",
    "authors": [
      "Zixian Liu",
      "Mingtong Zhang",
      "Yunzhu Li"
    ],
    "abstract": "With the rapid advancement of large language models (LLMs) and\nvision-language models (VLMs), significant progress has been made in developing\nopen-vocabulary robotic manipulation systems. However, many existing approaches\noverlook the importance of object dynamics, limiting their applicability to\nmore complex, dynamic tasks. In this work, we introduce KUDA, an\nopen-vocabulary manipulation system that integrates dynamics learning and\nvisual prompting through keypoints, leveraging both VLMs and learning-based\nneural dynamics models. Our key insight is that a keypoint-based target\nspecification is simultaneously interpretable by VLMs and can be efficiently\ntranslated into cost functions for model-based planning. Given language\ninstructions and visual observations, KUDA first assigns keypoints to the RGB\nimage and queries the VLM to generate target specifications. These abstract\nkeypoint-based representations are then converted into cost functions, which\nare optimized using a learned dynamics model to produce robotic trajectories.\nWe evaluate KUDA on a range of manipulation tasks, including free-form language\ninstructions across diverse object categories, multi-object interactions, and\ndeformable or granular objects, demonstrating the effectiveness of our\nframework. The project page is available at http://kuda-dynamics.github.io.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Project website: http://kuda-dynamics.github.io",
    "pdf_url": "http://arxiv.org/pdf/2503.10546v1",
    "published_date": "2025-03-13 16:59:17 UTC",
    "updated_date": "2025-03-13 16:59:17 UTC"
  },
  {
    "arxiv_id": "2503.10542v2",
    "title": "Language Models, Graph Searching, and Supervision Adulteration: When More Supervision is Less and How to Make More More",
    "authors": [
      "Arvid Frydenlund"
    ],
    "abstract": "This work concerns the path-star task, a minimal example of searching over a\ngraph. The graph, $G$, is star-shaped with $D$ arms radiating from a start\nnode, $s$. A language model (LM) is given $G$, $s$, and a target node $t$,\nwhich ends one of the arms and is tasked with generating the arm containing\n$t$. The minimal nature of this task means only a single choice needs to be\nmade: which of the $D$ arms contains $t$?\n  Decoder-only LMs fail to solve this elementary task above $1/D$ chance due to\na learned shortcut that absorbs training supervision. We show how this\npathology is caused by excess supervision and we present a series of solutions\ndemonstrating that the task is solvable via decoder-only LMs. We find that the\ntask's minimal nature causes its difficulty, as it prevents task decomposition.\nOur solutions provide insight into the pathology and its implications for LMs\ntrained via next-token prediction.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "I.2.7; I.2.8; I.5.0"
    ],
    "primary_category": "cs.LG",
    "comment": "ACL 2025 Main. A camera-ready version will follow in a few weeks. A\n  reduced version of this work has was also accepted to the Workshop on\n  Spurious Correlation and Shortcut Learning: Foundations and Solutions (SCSL)\n  at ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.10542v2",
    "published_date": "2025-03-13 16:56:47 UTC",
    "updated_date": "2025-05-19 18:20:06 UTC"
  },
  {
    "arxiv_id": "2503.10539v1",
    "title": "GBSVR: Granular Ball Support Vector Regression",
    "authors": [
      "Reshma Rastogi",
      "Ankush Bisht",
      "Sanjay Kumar",
      "Suresh Chandra"
    ],
    "abstract": "Support Vector Regression (SVR) and its variants are widely used to handle\nregression tasks, however, since their solution involves solving an expensive\nquadratic programming problem, it limits its application, especially when\ndealing with large datasets. Additionally, SVR uses an epsilon-insensitive loss\nfunction which is sensitive to outliers and therefore can adversely affect its\nperformance. We propose Granular Ball Support Vector Regression (GBSVR) to\ntackle problem of regression by using granular ball concept. These balls are\nuseful in simplifying complex data spaces for machine learning tasks, however,\nto the best of our knowledge, they have not been sufficiently explored for\nregression problems. Granular balls group the data points into balls based on\ntheir proximity and reduce the computational cost in SVR by replacing the large\nnumber of data points with far fewer granular balls. This work also suggests a\ndiscretization method for continuous-valued attributes to facilitate the\nconstruction of granular balls. The effectiveness of the proposed approach is\nevaluated on several benchmark datasets and it outperforms existing\nstate-of-the-art approaches",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.10539v1",
    "published_date": "2025-03-13 16:52:43 UTC",
    "updated_date": "2025-03-13 16:52:43 UTC"
  },
  {
    "arxiv_id": "2503.10533v1",
    "title": "The Impact of Item-Writing Flaws on Difficulty and Discrimination in Item Response Theory",
    "authors": [
      "Robin Schmucker",
      "Steven Moore"
    ],
    "abstract": "High-quality test items are essential for educational assessments,\nparticularly within Item Response Theory (IRT). Traditional validation methods\nrely on resource-intensive pilot testing to estimate item difficulty and\ndiscrimination. More recently, Item-Writing Flaw (IWF) rubrics emerged as a\ndomain-general approach for evaluating test items based on textual features.\nHowever, their relationship to IRT parameters remains underexplored. To address\nthis gap, we conducted a study involving over 7,000 multiple-choice questions\nacross various STEM subjects (e.g., math and biology). Using an automated\napproach, we annotated each question with a 19-criteria IWF rubric and studied\nrelationships to data-driven IRT parameters. Our analysis revealed\nstatistically significant links between the number of IWFs and IRT difficulty\nand discrimination parameters, particularly in life and physical science\ndomains. We further observed how specific IWF criteria can impact item quality\nmore and less severely (e.g., negative wording vs. implausible distractors).\nOverall, while IWFs are useful for predicting IRT parameters--particularly for\nscreening low-difficulty MCQs--they cannot replace traditional data-driven\nvalidation methods. Our findings highlight the need for further research on\ndomain-general evaluation rubrics and algorithms that understand\ndomain-specific content for robust item validation.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.10533v1",
    "published_date": "2025-03-13 16:47:07 UTC",
    "updated_date": "2025-03-13 16:47:07 UTC"
  },
  {
    "arxiv_id": "2503.10530v2",
    "title": "Lightweight Models for Emotional Analysis in Video",
    "authors": [
      "Quoc-Tien Nguyen",
      "Hong-Hai Nguyen",
      "Van-Thong Huynh"
    ],
    "abstract": "In this study, we present an approach for efficient spatiotemporal feature\nextraction using MobileNetV4 and a multi-scale 3D MLP-Mixer-based temporal\naggregation module. MobileNetV4, with its Universal Inverted Bottleneck (UIB)\nblocks, serves as the backbone for extracting hierarchical feature\nrepresentations from input image sequences, ensuring both computational\nefficiency and rich semantic encoding. To capture temporal dependencies, we\nintroduce a three-level MLP-Mixer module, which processes spatial features at\nmultiple resolutions while maintaining structural integrity. Experimental\nresults on the ABAW 8th competition demonstrate the effectiveness of our\napproach, showing promising performance in affective behavior analysis. By\nintegrating an efficient vision backbone with a structured temporal modeling\nmechanism, the proposed framework achieves a balance between computational\nefficiency and predictive accuracy, making it well-suited for real-time\napplications in mobile and embedded computing environments.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "https://github.com/PRVSL/abaw-8th",
    "pdf_url": "http://arxiv.org/pdf/2503.10530v2",
    "published_date": "2025-03-13 16:38:33 UTC",
    "updated_date": "2025-03-25 03:50:11 UTC"
  },
  {
    "arxiv_id": "2503.10529v1",
    "title": "PiSA: A Self-Augmented Data Engine and Training Strategy for 3D Understanding with Large Models",
    "authors": [
      "Zilu Guo",
      "Hongbin Lin",
      "Zhihao Yuan",
      "Chaoda Zheng",
      "Pengshuo Qiu",
      "Dongzhi Jiang",
      "Renrui Zhang",
      "Chun-Mei Feng",
      "Zhen Li"
    ],
    "abstract": "3D Multimodal Large Language Models (MLLMs) have recently made substantial\nadvancements. However, their potential remains untapped, primarily due to the\nlimited quantity and suboptimal quality of 3D datasets. Current approaches\nattempt to transfer knowledge from 2D MLLMs to expand 3D instruction data, but\nstill face modality and domain gaps. To this end, we introduce PiSA-Engine\n(Point-Self-Augmented-Engine), a new framework for generating instruction\npoint-language datasets enriched with 3D spatial semantics. We observe that\nexisting 3D MLLMs offer a comprehensive understanding of point clouds for\nannotation, while 2D MLLMs excel at cross-validation by providing complementary\ninformation. By integrating holistic 2D and 3D insights from off-the-shelf\nMLLMs, PiSA-Engine enables a continuous cycle of high-quality data generation.\nWe select PointLLM as the baseline and adopt this co-evolution training\nframework to develop an enhanced 3D MLLM, termed PointLLM-PiSA. Additionally,\nwe identify limitations in previous 3D benchmarks, which often feature coarse\nlanguage captions and insufficient category diversity, resulting in inaccurate\nevaluations. To address this gap, we further introduce PiSA-Bench, a\ncomprehensive 3D benchmark covering six key aspects with detailed and diverse\nlabels. Experimental results demonstrate PointLLM-PiSA's state-of-the-art\nperformance in zero-shot 3D object captioning and generative classification on\nour PiSA-Bench, achieving significant improvements of 46.45% (+8.33%) and\n63.75% (+16.25%), respectively. We will release the code, datasets, and\nbenchmark.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Technical Report",
    "pdf_url": "http://arxiv.org/pdf/2503.10529v1",
    "published_date": "2025-03-13 16:37:26 UTC",
    "updated_date": "2025-03-13 16:37:26 UTC"
  },
  {
    "arxiv_id": "2503.10520v1",
    "title": "CountPath: Automating Fragment Counting in Digital Pathology",
    "authors": [
      "Ana Beatriz Vieira",
      "Maria Valente",
      "Diana Montezuma",
      "Tomé Albuquerque",
      "Liliana Ribeiro",
      "Domingos Oliveira",
      "João Monteiro",
      "Sofia Gonçalves",
      "Isabel M. Pinto",
      "Jaime S. Cardoso",
      "Arlindo L. Oliveira"
    ],
    "abstract": "Quality control of medical images is a critical component of digital\npathology, ensuring that diagnostic images meet required standards. A\npre-analytical task within this process is the verification of the number of\nspecimen fragments, a process that ensures that the number of fragments on a\nslide matches the number documented in the macroscopic report. This step is\nimportant to ensure that the slides contain the appropriate diagnostic material\nfrom the grossing process, thereby guaranteeing the accuracy of subsequent\nmicroscopic examination and diagnosis. Traditionally, this assessment is\nperformed manually, requiring significant time and effort while being subject\nto significant variability due to its subjective nature. To address these\nchallenges, this study explores an automated approach to fragment counting\nusing the YOLOv9 and Vision Transformer models. Our results demonstrate that\nthe automated system achieves a level of performance comparable to expert\nassessments, offering a reliable and efficient alternative to manual counting.\nAdditionally, we present findings on interobserver variability, showing that\nthe automated approach achieves an accuracy of 86%, which falls within the\nrange of variation observed among experts (82-88%), further supporting its\npotential for integration into routine pathology workflows.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "I.2; I.4"
    ],
    "primary_category": "cs.CV",
    "comment": "10 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.10520v1",
    "published_date": "2025-03-13 16:29:16 UTC",
    "updated_date": "2025-03-13 16:29:16 UTC"
  },
  {
    "arxiv_id": "2503.10518v1",
    "title": "Why the Brain Cannot Be a Digital Computer: History-Dependence and the Computational Limits of Consciousness",
    "authors": [
      "Andrew Knight"
    ],
    "abstract": "This paper presents a novel information-theoretic proof demonstrating that\nthe human brain as currently understood cannot function as a classical digital\ncomputer. Through systematic quantification of distinguishable conscious states\nand their historical dependencies, we establish that the minimum information\nrequired to specify a conscious state exceeds the physical information capacity\nof the human brain by a significant factor. Our analysis calculates the\nbit-length requirements for representing consciously distinguishable sensory\n\"stimulus frames\" and demonstrates that consciousness exhibits mandatory\ntemporal-historical dependencies that multiply these requirements beyond the\nbrain's storage capabilities. This mathematical approach offers new insights\ninto the fundamental limitations of computational models of consciousness and\nsuggests that non-classical information processing mechanisms may be necessary\nto account for conscious experience.",
    "categories": [
      "physics.hist-ph",
      "cs.AI",
      "q-bio.NC"
    ],
    "primary_category": "physics.hist-ph",
    "comment": "10 pages, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2503.10518v1",
    "published_date": "2025-03-13 16:27:42 UTC",
    "updated_date": "2025-03-13 16:27:42 UTC"
  },
  {
    "arxiv_id": "2503.11718v1",
    "title": "The Relativity of Causal Knowledge",
    "authors": [
      "Gabriele D'Acunto",
      "Claudio Battiloro"
    ],
    "abstract": "Recent advances in artificial intelligence reveal the limits of purely\npredictive systems and call for a shift toward causal and collaborative\nreasoning. Drawing inspiration from the revolution of Grothendieck in\nmathematics, we introduce the relativity of causal knowledge, which posits\nstructural causal models (SCMs) are inherently imperfect, subjective\nrepresentations embedded within networks of relationships. By leveraging\ncategory theory, we arrange SCMs into a functor category and show that their\nobservational and interventional probability measures naturally form convex\nstructures. This result allows us to encode non-intervened SCMs with convex\nspaces of probability measures. Next, using sheaf theory, we construct the\nnetwork sheaf and cosheaf of causal knowledge. These structures enable the\ntransfer of causal knowledge across the network while incorporating\ninterventional consistency and the perspective of the subjects, ultimately\nleading to the formal, mathematical definition of relative causal knowledge.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "math.CT",
      "stat.ME"
    ],
    "primary_category": "cs.AI",
    "comment": "14 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.11718v1",
    "published_date": "2025-03-13 16:24:48 UTC",
    "updated_date": "2025-03-13 16:24:48 UTC"
  },
  {
    "arxiv_id": "2503.10512v1",
    "title": "Conformal Prediction Sets for Deep Generative Models via Reduction to Conformal Regression",
    "authors": [
      "Hooman Shahrokhi",
      "Devjeet Raj Roy",
      "Yan Yan",
      "Venera Arnaoudova",
      "Janaradhan Rao Doppa"
    ],
    "abstract": "We consider the problem of generating valid and small prediction sets by\nsampling outputs (e.g., software code and natural language text) from a\nblack-box deep generative model for a given input (e.g., textual prompt). The\nvalidity of a prediction set is determined by a user-defined binary\nadmissibility function depending on the target application. For example,\nrequiring at least one program in the set to pass all test cases in code\ngeneration application. To address this problem, we develop a simple and\neffective conformal inference algorithm referred to as Generative Prediction\nSets (GPS). Given a set of calibration examples and black-box access to a deep\ngenerative model, GPS can generate prediction sets with provable guarantees.\nThe key insight behind GPS is to exploit the inherent structure within the\ndistribution over the minimum number of samples needed to obtain an admissible\noutput to develop a simple conformal regression approach over the minimum\nnumber of samples. Experiments on multiple datasets for code and math word\nproblems using different large language models demonstrate the efficacy of GPS\nover state-of-the-art methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.10512v1",
    "published_date": "2025-03-13 16:16:23 UTC",
    "updated_date": "2025-03-13 16:16:23 UTC"
  },
  {
    "arxiv_id": "2503.10737v1",
    "title": "Commenting Higher-level Code Unit: Full Code, Reduced Code, or Hierarchical Code Summarization",
    "authors": [
      "Weisong Sun",
      "Yiran Zhang",
      "Jie Zhu",
      "Zhihui Wang",
      "Chunrong Fang",
      "Yonglong Zhang",
      "Yebo Feng",
      "Jiangping Huang",
      "Xingya Wang",
      "Zhi Jin",
      "Yang Liu"
    ],
    "abstract": "Commenting code is a crucial activity in software development, as it aids in\nfacilitating future maintenance and updates. To enhance the efficiency of\nwriting comments and reduce developers' workload, researchers has proposed\nvarious automated code summarization (ACS) techniques to automatically generate\ncomments/summaries for given code units. However, these ACS techniques\nprimarily focus on generating summaries for code units at the method level.\nThere is a significant lack of research on summarizing higher-level code units,\nsuch as file-level and module-level code units, despite the fact that summaries\nof these higher-level code units are highly useful for quickly gaining a\nmacro-level understanding of software components and architecture. To fill this\ngap, in this paper, we conduct a systematic study on how to use LLMs for\ncommenting higher-level code units, including file level and module level.\nThese higher-level units are significantly larger than method-level ones, which\nposes challenges in handling long code inputs within LLM constraints and\nmaintaining efficiency. To address these issues, we explore various\nsummarization strategies for ACS of higher-level code units, which can be\ndivided into three types: full code summarization, reduced code summarization,\nand hierarchical code summarization. The experimental results suggest that for\nsummarizing file-level code units, using the full code is the most effective\napproach, with reduced code serving as a cost-efficient alternative. However,\nfor summarizing module-level code units, hierarchical code summarization\nbecomes the most promising strategy. In addition, inspired by the research on\nmethod-level ACS, we also investigate using the LLM as an evaluator to evaluate\nthe quality of summaries of higher-level code units. The experimental results\ndemonstrate that the LLM's evaluation results strongly correlate with human\nevaluations.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "68-04",
      "D.2.3; I.2.7"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.10737v1",
    "published_date": "2025-03-13 16:15:06 UTC",
    "updated_date": "2025-03-13 16:15:06 UTC"
  },
  {
    "arxiv_id": "2503.10496v1",
    "title": "Explainable Bayesian deep learning through input-skip Latent Binary Bayesian Neural Networks",
    "authors": [
      "Eirik Høyheim",
      "Lars Skaaret-Lund",
      "Solve Sæbø",
      "Aliaksandr Hubin"
    ],
    "abstract": "Modeling natural phenomena with artificial neural networks (ANNs) often\nprovides highly accurate predictions. However, ANNs often suffer from\nover-parameterization, complicating interpretation and raising uncertainty\nissues. Bayesian neural networks (BNNs) address the latter by representing\nweights as probability distributions, allowing for predictive uncertainty\nevaluation. Latent binary Bayesian neural networks (LBBNNs) further handle\nstructural uncertainty and sparsify models by removing redundant weights. This\narticle advances LBBNNs by enabling covariates to skip to any succeeding layer\nor be excluded, simplifying networks and clarifying input impacts on\npredictions. Ultimately, a linear model or even a constant can be found to be\noptimal for a specific problem at hand. Furthermore, the input-skip LBBNN\napproach reduces network density significantly compared to standard LBBNNs,\nachieving over 99% reduction for small networks and over 99.9% for larger ones,\nwhile still maintaining high predictive accuracy and uncertainty measurement.\nFor example, on MNIST, we reached 97% accuracy and great calibration with just\n935 weights, reaching state-of-the-art for compression of neural networks.\nFurthermore, the proposed method accurately identifies the true covariates and\nadjusts for system non-linearity. The main contribution is the introduction of\nactive paths, enhancing directly designed global and local explanations within\nthe LBBNN framework, that have theoretical guarantees and do not require post\nhoc external tools for explanations.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG",
      "stat.CO",
      "stat.ME",
      "62-02, 62-09, 62F07, 62F15, 62J12, 62J05, 62J99, 62M05, 05A16,\n  60J22, 92D20, 90C27, 90C59",
      "G.1.2; G.1.6; G.2.1; G.3; I.2.0; I.2.6; I.2.8; I.5.1; I.6; I.6.4"
    ],
    "primary_category": "stat.ML",
    "comment": "44 pages, 19 tables, 25 figures. Code available at\n  https://github.com/eirihoyh/ISLaB-LBBNN",
    "pdf_url": "http://arxiv.org/pdf/2503.10496v1",
    "published_date": "2025-03-13 15:59:03 UTC",
    "updated_date": "2025-03-13 15:59:03 UTC"
  },
  {
    "arxiv_id": "2503.10486v1",
    "title": "LLMs in Disease Diagnosis: A Comparative Study of DeepSeek-R1 and O3 Mini Across Chronic Health Conditions",
    "authors": [
      "Gaurav Kumar Gupta",
      "Pranal Pande"
    ],
    "abstract": "Large Language Models (LLMs) are revolutionizing medical diagnostics by\nenhancing both disease classification and clinical decision-making. In this\nstudy, we evaluate the performance of two LLM- based diagnostic tools, DeepSeek\nR1 and O3 Mini, using a structured dataset of symptoms and diagnoses. We\nassessed their predictive accuracy at both the disease and category levels, as\nwell as the reliability of their confidence scores. DeepSeek R1 achieved a\ndisease-level accuracy of 76% and an overall accuracy of 82%, outperforming O3\nMini, which attained 72% and 75% respectively. Notably, DeepSeek R1\ndemonstrated exceptional performance in Mental Health, Neurological Disorders,\nand Oncology, where it reached 100% accuracy, while O3 Mini excelled in\nAutoimmune Disease classification with 100% accuracy. Both models, however,\nstruggled with Respiratory Disease classification, recording accuracies of only\n40% for DeepSeek R1 and 20% for O3 Mini. Additionally, the analysis of\nconfidence scores revealed that DeepSeek R1 provided high-confidence\npredictions in 92% of cases, compared to 68% for O3 Mini. Ethical\nconsiderations regarding bias, model interpretability, and data privacy are\nalso discussed to ensure the responsible integration of LLMs into clinical\npractice. Overall, our findings offer valuable insights into the strengths and\nlimitations of LLM-based diagnostic systems and provide a roadmap for future\nenhancements in AI-driven healthcare.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "12 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.10486v1",
    "published_date": "2025-03-13 15:54:26 UTC",
    "updated_date": "2025-03-13 15:54:26 UTC"
  },
  {
    "arxiv_id": "2503.10479v1",
    "title": "DeclareAligner: A Leap Towards Efficient Optimal Alignments for Declarative Process Model Conformance Checking",
    "authors": [
      "Jacobo Casas-Ramos",
      "Manuel Lama",
      "Manuel Mucientes"
    ],
    "abstract": "In many engineering applications, processes must be followed precisely,\nmaking conformance checking between event logs and declarative process models\ncrucial for ensuring adherence to desired behaviors. This is a critical area\nwhere Artificial Intelligence (AI) plays a pivotal role in driving effective\nprocess improvement. However, computing optimal alignments poses significant\ncomputational challenges due to the vast search space inherent in these models.\nConsequently, existing approaches often struggle with scalability and\nefficiency, limiting their applicability in real-world settings. This paper\nintroduces DeclareAligner, a novel algorithm that uses the A* search algorithm,\nan established AI pathfinding technique, to tackle the problem from a fresh\nperspective leveraging the flexibility of declarative models. Key features of\nDeclareAligner include only performing actions that actively contribute to\nfixing constraint violations, utilizing a tailored heuristic to navigate\ntowards optimal solutions, and employing early pruning to eliminate\nunproductive branches, while also streamlining the process through\npreprocessing and consolidating multiple fixes into unified actions. The\nproposed method is evaluated using 8,054 synthetic and real-life alignment\nproblems, demonstrating its ability to efficiently compute optimal alignments\nby significantly outperforming the current state of the art. By enabling\nprocess analysts to more effectively identify and understand conformance\nissues, DeclareAligner has the potential to drive meaningful process\nimprovement and management.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.10479v1",
    "published_date": "2025-03-13 15:49:29 UTC",
    "updated_date": "2025-03-13 15:49:29 UTC"
  },
  {
    "arxiv_id": "2503.10471v1",
    "title": "Siamese Foundation Models for Crystal Structure Prediction",
    "authors": [
      "Liming Wu",
      "Wenbing Huang",
      "Rui Jiao",
      "Jianxing Huang",
      "Liwei Liu",
      "Yipeng Zhou",
      "Hao Sun",
      "Yang Liu",
      "Fuchun Sun",
      "Yuxiang Ren",
      "Jirong Wen"
    ],
    "abstract": "Crystal Structure Prediction (CSP), which aims to generate stable crystal\nstructures from compositions, represents a critical pathway for discovering\nnovel materials. While structure prediction tasks in other domains, such as\nproteins, have seen remarkable progress, CSP remains a relatively underexplored\narea due to the more complex geometries inherent in crystal structures. In this\npaper, we propose Siamese foundation models specifically designed to address\nCSP. Our pretrain-finetune framework, named DAO, comprises two complementary\nfoundation models: DAO-G for structure generation and DAO-P for energy\nprediction. Experiments on CSP benchmarks (MP-20 and MPTS-52) demonstrate that\nour DAO-G significantly surpasses state-of-the-art (SOTA) methods across all\nmetrics. Extensive ablation studies further confirm that DAO-G excels in\ngenerating diverse polymorphic structures, and the dataset relaxation and\nenergy guidance provided by DAO-P are essential for enhancing DAO-G's\nperformance. When applied to three real-world superconductors\n($\\text{CsV}_3\\text{Sb}_5$, $ \\text{Zr}_{16}\\text{Rh}_8\\text{O}_4$ and\n$\\text{Zr}_{16}\\text{Pd}_8\\text{O}_4$) that are known to be challenging to\nanalyze, our foundation models achieve accurate critical temperature\npredictions and structure generations. For instance, on\n$\\text{CsV}_3\\text{Sb}_5$, DAO-G generates a structure close to the\nexperimental one with an RMSE of 0.0085; DAO-P predicts the $T_c$ value with\nhigh accuracy (2.26 K vs. the ground-truth value of 2.30 K). In contrast,\nconventional DFT calculators like Quantum Espresso only successfully derive the\nstructure of the first superconductor within an acceptable time, while the RMSE\nis nearly 8 times larger, and the computation speed is more than 1000 times\nslower. These compelling results collectively highlight the potential of our\napproach for advancing materials science research and development.",
    "categories": [
      "cond-mat.mtrl-sci",
      "cs.AI"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.10471v1",
    "published_date": "2025-03-13 15:44:16 UTC",
    "updated_date": "2025-03-13 15:44:16 UTC"
  },
  {
    "arxiv_id": "2503.10735v2",
    "title": "OCPM$^2$: Extending the Process Mining Methodology for Object-Centric Event Data Extraction",
    "authors": [
      "Najmeh Miri",
      "Shahrzad Khayatbashi",
      "Jelena Zdravkovic",
      "Amin Jalali"
    ],
    "abstract": "Object-Centric Process Mining (OCPM) enables business process analysis from\nmultiple perspectives. For example, an educational path can be examined from\nthe viewpoints of students, teachers, and groups. This analysis depends on\nObject-Centric Event Data (OCED), which captures relationships between events\nand object types, representing different perspectives. Unlike traditional\nprocess mining techniques, extracting OCED minimizes the need for repeated log\nextractions when shifting the analytical focus. However, recording these\ncomplex relationships increases the complexity of the log extraction process.\nTo address this challenge, this paper proposes a methodology for extracting\nOCED based on PM\\inst{2}, a well-established process mining framework. Our\napproach introduces a structured framework that guides data analysts and\nengineers in extracting OCED for process analysis. We validate this framework\nby applying it in a real-world educational setting, demonstrating its\neffectiveness in extracting an Object-Centric Event Log (OCEL), which serves as\nthe standard format for recording OCED, from a learning management system and\nan administrative grading system.",
    "categories": [
      "cs.DB",
      "cs.AI"
    ],
    "primary_category": "cs.DB",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.10735v2",
    "published_date": "2025-03-13 15:30:10 UTC",
    "updated_date": "2025-04-21 12:26:40 UTC"
  },
  {
    "arxiv_id": "2503.10452v1",
    "title": "DynaCode: A Dynamic Complexity-Aware Code Benchmark for Evaluating Large Language Models in Code Generation",
    "authors": [
      "Wenhao Hu",
      "Jinhao Duan",
      "Chunchen Wei",
      "Li Zhang",
      "Yue Zhang",
      "Kaidi Xu"
    ],
    "abstract": "The rapid advancement of large language models (LLMs) has significantly\nimproved their performance in code generation tasks. However, existing code\nbenchmarks remain static, consisting of fixed datasets with predefined\nproblems. This makes them vulnerable to memorization during training, where\nLLMs recall specific test cases instead of generalizing to new problems,\nleading to data contamination and unreliable evaluation results. To address\nthese issues, we introduce DynaCode, a dynamic, complexity-aware benchmark that\novercomes the limitations of static datasets. DynaCode evaluates LLMs\nsystematically using a complexity-aware metric, incorporating both code\ncomplexity and call-graph structures. DynaCode achieves large-scale diversity,\ngenerating up to 189 million unique nested code problems across four distinct\nlevels of code complexity, referred to as units, and 16 types of call graphs.\nResults on 12 latest LLMs show an average performance drop of 16.8% to 45.7%\ncompared to MBPP+, a static code generation benchmark, with performance\nprogressively decreasing as complexity increases. This demonstrates DynaCode's\nability to effectively differentiate LLMs. Additionally, by leveraging call\ngraphs, we gain insights into LLM behavior, particularly their preference for\nhandling subfunction interactions within nested code.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "16 pages, 11 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.10452v1",
    "published_date": "2025-03-13 15:18:56 UTC",
    "updated_date": "2025-03-13 15:18:56 UTC"
  },
  {
    "arxiv_id": "2503.10446v1",
    "title": "Whisper Speaker Identification: Leveraging Pre-Trained Multilingual Transformers for Robust Speaker Embeddings",
    "authors": [
      "Jakaria Islam Emon",
      "Md Abu Salek",
      "Kazi Tamanna Alam"
    ],
    "abstract": "Speaker identification in multilingual settings presents unique challenges,\nparticularly when conventional models are predominantly trained on English\ndata. In this paper, we propose WSI (Whisper Speaker Identification), a\nframework that repurposes the encoder of the Whisper automatic speech\nrecognition model pre trained on extensive multilingual data to generate robust\nspeaker embeddings via a joint loss optimization strategy that leverages online\nhard triplet mining and self supervised Normalized Temperature-scaled Cross\nEntropy loss. By capitalizing on Whisper language-agnostic acoustic\nrepresentations, our approach effectively distinguishes speakers across diverse\nlanguages and recording conditions. Extensive evaluations on multiple corpora,\nincluding VoxTube (multilingual), JVS (Japanese), CallHome (German, Spanish,\nChinese, and Japanese), and Voxconverse (English), demonstrate that WSI\nconsistently outperforms state-of-the-art baselines, namely Pyannote Embedding,\nECAPA TDNN, and Xvector, in terms of lower equal error rates and higher AUC\nscores. These results validate our hypothesis that a multilingual pre-trained\nASR encoder, combined with joint loss optimization, substantially improves\nspeaker identification performance in non-English languages.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS",
      "I.2"
    ],
    "primary_category": "cs.SD",
    "comment": "6 pages",
    "pdf_url": "http://arxiv.org/pdf/2503.10446v1",
    "published_date": "2025-03-13 15:11:28 UTC",
    "updated_date": "2025-03-13 15:11:28 UTC"
  },
  {
    "arxiv_id": "2503.10412v4",
    "title": "dFLMoE: Decentralized Federated Learning via Mixture of Experts for Medical Data Analysis",
    "authors": [
      "Luyuan Xie",
      "Tianyu Luan",
      "Wenyuan Cai",
      "Guochen Yan",
      "Zhaoyu Chen",
      "Nan Xi",
      "Yuejian Fang",
      "Qingni Shen",
      "Zhonghai Wu",
      "Junsong Yuan"
    ],
    "abstract": "Federated learning has wide applications in the medical field. It enables\nknowledge sharing among different healthcare institutes while protecting\npatients' privacy. However, existing federated learning systems are typically\ncentralized, requiring clients to upload client-specific knowledge to a central\nserver for aggregation. This centralized approach would integrate the knowledge\nfrom each client into a centralized server, and the knowledge would be already\nundermined during the centralized integration before it reaches back to each\nclient. Besides, the centralized approach also creates a dependency on the\ncentral server, which may affect training stability if the server malfunctions\nor connections are unstable. To address these issues, we propose a\ndecentralized federated learning framework named dFLMoE. In our framework,\nclients directly exchange lightweight head models with each other. After\nexchanging, each client treats both local and received head models as\nindividual experts, and utilizes a client-specific Mixture of Experts (MoE)\napproach to make collective decisions. This design not only reduces the\nknowledge damage with client-specific aggregations but also removes the\ndependency on the central server to enhance the robustness of the framework. We\nvalidate our framework on multiple medical tasks, demonstrating that our method\nevidently outperforms state-of-the-art approaches under both model homogeneity\nand heterogeneity settings.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accapted by CVPR 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.10412v4",
    "published_date": "2025-03-13 14:35:47 UTC",
    "updated_date": "2025-05-19 15:46:38 UTC"
  },
  {
    "arxiv_id": "2503.10406v1",
    "title": "RealGeneral: Unifying Visual Generation via Temporal In-Context Learning with Video Models",
    "authors": [
      "Yijing Lin",
      "Mengqi Huang",
      "Shuhan Zhuang",
      "Zhendong Mao"
    ],
    "abstract": "Unifying diverse image generation tasks within a single framework remains a\nfundamental challenge in visual generation. While large language models (LLMs)\nachieve unification through task-agnostic data and generation, existing visual\ngeneration models fail to meet these principles. Current approaches either rely\non per-task datasets and large-scale training or adapt pre-trained image models\nwith task-specific modifications, limiting their generalizability. In this\nwork, we explore video models as a foundation for unified image generation,\nleveraging their inherent ability to model temporal correlations. We introduce\nRealGeneral, a novel framework that reformulates image generation as a\nconditional frame prediction task, analogous to in-context learning in LLMs. To\nbridge the gap between video models and condition-image pairs, we propose (1) a\nUnified Conditional Embedding module for multi-modal alignment and (2) a\nUnified Stream DiT Block with decoupled adaptive LayerNorm and attention mask\nto mitigate cross-modal interference. RealGeneral demonstrates effectiveness in\nmultiple important visual generation tasks, e.g., it achieves a 14.5%\nimprovement in subject similarity for customized generation and a 10%\nenhancement in image quality for canny-to-image task. Project page:\nhttps://lyne1.github.io/RealGeneral/",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.10406v1",
    "published_date": "2025-03-13 14:31:52 UTC",
    "updated_date": "2025-03-13 14:31:52 UTC"
  },
  {
    "arxiv_id": "2503.10392v1",
    "title": "RoMA: Scaling up Mamba-based Foundation Models for Remote Sensing",
    "authors": [
      "Fengxiang Wang",
      "Hongzhen Wang",
      "Yulin Wang",
      "Di Wang",
      "Mingshuo Chen",
      "Haiyan Zhao",
      "Yangang Sun",
      "Shuo Wang",
      "Long Lan",
      "Wenjing Yang",
      "Jing Zhang"
    ],
    "abstract": "Recent advances in self-supervised learning for Vision Transformers (ViTs)\nhave fueled breakthroughs in remote sensing (RS) foundation models. However,\nthe quadratic complexity of self-attention poses a significant barrier to\nscalability, particularly for large models and high-resolution images. While\nthe linear-complexity Mamba architecture offers a promising alternative,\nexisting RS applications of Mamba remain limited to supervised tasks on small,\ndomain-specific datasets. To address these challenges, we propose RoMA, a\nframework that enables scalable self-supervised pretraining of Mamba-based RS\nfoundation models using large-scale, diverse, unlabeled data. RoMA enhances\nscalability for high-resolution images through a tailored auto-regressive\nlearning strategy, incorporating two key innovations: 1) a rotation-aware\npretraining mechanism combining adaptive cropping with angular embeddings to\nhandle sparsely distributed objects with arbitrary orientations, and 2)\nmulti-scale token prediction objectives that address the extreme variations in\nobject scales inherent to RS imagery. Systematic empirical studies validate\nthat Mamba adheres to RS data and parameter scaling laws, with performance\nscaling reliably as model and data size increase. Furthermore, experiments\nacross scene classification, object detection, and semantic segmentation tasks\ndemonstrate that RoMA-pretrained Mamba models consistently outperform ViT-based\ncounterparts in both accuracy and computational efficiency. The source code and\npretrained models will be released at https://github.com/MiliLab/RoMA.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.10392v1",
    "published_date": "2025-03-13 14:09:18 UTC",
    "updated_date": "2025-03-13 14:09:18 UTC"
  },
  {
    "arxiv_id": "2503.10391v1",
    "title": "CINEMA: Coherent Multi-Subject Video Generation via MLLM-Based Guidance",
    "authors": [
      "Yufan Deng",
      "Xun Guo",
      "Yizhi Wang",
      "Jacob Zhiyuan Fang",
      "Angtian Wang",
      "Shenghai Yuan",
      "Yiding Yang",
      "Bo Liu",
      "Haibin Huang",
      "Chongyang Ma"
    ],
    "abstract": "Video generation has witnessed remarkable progress with the advent of deep\ngenerative models, particularly diffusion models. While existing methods excel\nin generating high-quality videos from text prompts or single images,\npersonalized multi-subject video generation remains a largely unexplored\nchallenge. This task involves synthesizing videos that incorporate multiple\ndistinct subjects, each defined by separate reference images, while ensuring\ntemporal and spatial consistency. Current approaches primarily rely on mapping\nsubject images to keywords in text prompts, which introduces ambiguity and\nlimits their ability to model subject relationships effectively. In this paper,\nwe propose CINEMA, a novel framework for coherent multi-subject video\ngeneration by leveraging Multimodal Large Language Model (MLLM). Our approach\neliminates the need for explicit correspondences between subject images and\ntext entities, mitigating ambiguity and reducing annotation effort. By\nleveraging MLLM to interpret subject relationships, our method facilitates\nscalability, enabling the use of large and diverse datasets for training.\nFurthermore, our framework can be conditioned on varying numbers of subjects,\noffering greater flexibility in personalized content creation. Through\nextensive evaluations, we demonstrate that our approach significantly improves\nsubject consistency, and overall video coherence, paving the way for advanced\napplications in storytelling, interactive media, and personalized video\ngeneration.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.10391v1",
    "published_date": "2025-03-13 14:07:58 UTC",
    "updated_date": "2025-03-13 14:07:58 UTC"
  },
  {
    "arxiv_id": "2503.10371v1",
    "title": "A Multimodal Fusion Model Leveraging MLP Mixer and Handcrafted Features-based Deep Learning Networks for Facial Palsy Detection",
    "authors": [
      "Heng Yim Nicole Oo",
      "Min Hun Lee",
      "Jeong Hoon Lim"
    ],
    "abstract": "Algorithmic detection of facial palsy offers the potential to improve current\npractices, which usually involve labor-intensive and subjective assessments by\nclinicians. In this paper, we present a multimodal fusion-based deep learning\nmodel that utilizes an MLP mixer-based model to process unstructured data (i.e.\nRGB images or images with facial line segments) and a feed-forward neural\nnetwork to process structured data (i.e. facial landmark coordinates, features\nof facial expressions, or handcrafted features) for detecting facial palsy. We\nthen contribute to a study to analyze the effect of different data modalities\nand the benefits of a multimodal fusion-based approach using videos of 20\nfacial palsy patients and 20 healthy subjects. Our multimodal fusion model\nachieved 96.00 F1, which is significantly higher than the feed-forward neural\nnetwork trained on handcrafted features alone (82.80 F1) and an MLP mixer-based\nmodel trained on raw RGB images (89.00 F1).",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "PAKDD 2025. arXiv admin note: text overlap with arXiv:2405.16496",
    "pdf_url": "http://arxiv.org/pdf/2503.10371v1",
    "published_date": "2025-03-13 13:48:35 UTC",
    "updated_date": "2025-03-13 13:48:35 UTC"
  },
  {
    "arxiv_id": "2503.10367v1",
    "title": "G-Boost: Boosting Private SLMs with General LLMs",
    "authors": [
      "Yijiang Fan",
      "Yuren Mao",
      "Longbin Lai",
      "Ying Zhang",
      "Zhengping Qian",
      "Yunjun Gao"
    ],
    "abstract": "Due to the limited computational resources, most Large Language Models (LLMs)\ndevelopers can only fine-tune Small Language Models (SLMs) on their own data.\nThese private SLMs typically have limited effectiveness. To boost the\nperformance of private SLMs, this paper proposes to ask general LLMs for help.\nThe general LLMs can be APIs or larger LLMs whose inference cost the developers\ncan afford. Specifically, we propose the G-Boost framework where a private SLM\nadaptively performs collaborative inference with a general LLM under the guide\nof process reward. Experiments demonstrate that our framework can significantly\nboost the performance of private SLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.10367v1",
    "published_date": "2025-03-13 13:47:03 UTC",
    "updated_date": "2025-03-13 13:47:03 UTC"
  },
  {
    "arxiv_id": "2503.10356v1",
    "title": "Object detection characteristics in a learning factory environment using YOLOv8",
    "authors": [
      "Toni Schneidereit",
      "Stefan Gohrenz",
      "Michael Breuß"
    ],
    "abstract": "AI-based object detection, and efforts to explain and investigate their\ncharacteristics, is a topic of high interest. The impact of, e.g., complex\nbackground structures with similar appearances as the objects of interest, on\nthe detection accuracy and, beforehand, the necessary dataset composition are\ntopics of ongoing research. In this paper, we present a systematic\ninvestigation of background influences and different features of the object to\nbe detected. The latter includes various materials and surfaces, partially\ntransparent and with shiny reflections in the context of an Industry 4.0\nlearning factory. Different YOLOv8 models have been trained for each of the\nmaterials on different sized datasets, where the appearance was the only\nchanging parameter. In the end, similar characteristics tend to show different\nbehaviours and sometimes unexpected results. While some background components\ntend to be detected, others with the same features are not part of the\ndetection. Additionally, some more precise conclusions can be drawn from the\nresults. Therefore, we contribute a challenging dataset with detailed\ninvestigations on 92 trained YOLO models, addressing some issues on the\ndetection accuracy and possible overfitting.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.10356v1",
    "published_date": "2025-03-13 13:33:27 UTC",
    "updated_date": "2025-03-13 13:33:27 UTC"
  },
  {
    "arxiv_id": "2503.10337v1",
    "title": "KV-Distill: Nearly Lossless Learnable Context Compression for LLMs",
    "authors": [
      "Vivek Chari",
      "Guanghui Qin",
      "Benjamin Van Durme"
    ],
    "abstract": "Sequence-to-sequence tasks often benefit from long contexts, but the\nquadratic complexity of self-attention in standard Transformers renders this\nnon-trivial. During generation, temporary representations -stored in the\nso-called KV cache-account for a large portion of GPU memory usage and scale\nlinearly with context length. We introduce KV-Distill, a Transformer\ncompression framework that distills long context KV caches into significantly\nshorter representations in a question-independent fashion. KV-Distill can be\ntrained as a parameter-efficient adaptor for pretrained models, and enables the\ncompression of arbitrary spans of a context while preserving pre-trained model\ncapabilities. We treat a compressed-uncompressed cache as a student-teacher\npairing and apply a KL-type divergence to match the generated outputs.\nKV-Distill outperforms other compression techniques in worst-case extractive\ntasks and approaches uncompressed performance in long context question\nanswering and summarization, and it can be fine-tuned on domain-specific\ncontexts to reduce lengths by up to 99% while preserving downstream\nperformance. We demonstrate the generalizability of KV-Distill across various\nmodel sizes and architectures.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.10337v1",
    "published_date": "2025-03-13 13:15:28 UTC",
    "updated_date": "2025-03-13 13:15:28 UTC"
  },
  {
    "arxiv_id": "2503.10331v1",
    "title": "OSMa-Bench: Evaluating Open Semantic Mapping Under Varying Lighting Conditions",
    "authors": [
      "Maxim Popov",
      "Regina Kurkova",
      "Mikhail Iumanov",
      "Jaafar Mahmoud",
      "Sergey Kolyubin"
    ],
    "abstract": "Open Semantic Mapping (OSM) is a key technology in robotic perception,\ncombining semantic segmentation and SLAM techniques. This paper introduces a\ndynamically configurable and highly automated LLM/LVLM-powered pipeline for\nevaluating OSM solutions called OSMa-Bench (Open Semantic Mapping Benchmark).\nThe study focuses on evaluating state-of-the-art semantic mapping algorithms\nunder varying indoor lighting conditions, a critical challenge in indoor\nenvironments. We introduce a novel dataset with simulated RGB-D sequences and\nground truth 3D reconstructions, facilitating the rigorous analysis of mapping\nperformance across different lighting conditions. Through experiments on\nleading models such as ConceptGraphs, BBQ and OpenScene, we evaluate the\nsemantic fidelity of object recognition and segmentation. Additionally, we\nintroduce a Scene Graph evaluation method to analyze the ability of models to\ninterpret semantic structure. The results provide insights into the robustness\nof these models, forming future research directions for developing resilient\nand adaptable robotic systems. Our code is available at\nhttps://be2rlab.github.io/OSMa-Bench/.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "Project page: https://be2rlab.github.io/OSMa-Bench/",
    "pdf_url": "http://arxiv.org/pdf/2503.10331v1",
    "published_date": "2025-03-13 13:07:51 UTC",
    "updated_date": "2025-03-13 13:07:51 UTC"
  },
  {
    "arxiv_id": "2503.10318v1",
    "title": "Enhance Exploration in Safe Reinforcement Learning with Contrastive Representation Learning",
    "authors": [
      "Duc Kien Doan",
      "Bang Giang Le",
      "Viet Cuong Ta"
    ],
    "abstract": "In safe reinforcement learning, agent needs to balance between exploration\nactions and safety constraints. Following this paradigm, domain transfer\napproaches learn a prior Q-function from the related environments to prevent\nunsafe actions. However, because of the large number of false positives, some\nsafe actions are never executed, leading to inadequate exploration in\nsparse-reward environments. In this work, we aim to learn an efficient state\nrepresentation to balance the exploration and safety-prefer action in a\nsparse-reward environment. Firstly, the image input is mapped to latent\nrepresentation by an auto-encoder. A further contrastive learning objective is\nemployed to distinguish safe and unsafe states. In the learning phase, the\nlatent distance is used to construct an additional safety check, which allows\nthe agent to bias the exploration if it visits an unsafe state. To verify the\neffectiveness of our method, the experiment is carried out in three\nnavigation-based MiniGrid environments. The result highlights that our method\ncan explore the environment better while maintaining a good balance between\nsafety and efficiency.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at ACIIDS 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.10318v1",
    "published_date": "2025-03-13 12:53:42 UTC",
    "updated_date": "2025-03-13 12:53:42 UTC"
  },
  {
    "arxiv_id": "2503.10304v1",
    "title": "Nash Equilibrium Constrained Auto-bidding With Bi-level Reinforcement Learning",
    "authors": [
      "Zhiyu Mou",
      "Miao Xu",
      "Rongquan Bai",
      "Zhuoran Yang",
      "Chuan Yu",
      "Jian Xu",
      "Bo Zheng"
    ],
    "abstract": "Many online advertising platforms provide advertisers with auto-bidding\nservices to enhance their advertising performance. However, most existing\nauto-bidding algorithms fail to accurately capture the auto-bidding problem\nformulation that the platform truly faces, let alone solve it. Actually, we\nargue that the platform should try to help optimize each advertiser's\nperformance to the greatest extent -- which makes $\\epsilon$-Nash Equilibrium\n($\\epsilon$-NE) a necessary solution concept -- while maximizing the social\nwelfare of all the advertisers for the platform's long-term value. Based on\nthis, we introduce the \\emph{Nash-Equilibrium Constrained Bidding} (NCB), a new\nformulation of the auto-bidding problem from the platform's perspective.\nSpecifically, it aims to maximize the social welfare of all advertisers under\nthe $\\epsilon$-NE constraint. However, the NCB problem presents significant\nchallenges due to its constrained bi-level structure and the typically large\nnumber of advertisers involved. To address these challenges, we propose a\n\\emph{Bi-level Policy Gradient} (BPG) framework with theoretical guarantees.\nNotably, its computational complexity is independent of the number of\nadvertisers, and the associated gradients are straightforward to compute.\nExtensive simulated and real-world experiments validate the effectiveness of\nthe BPG framework.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.GT"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.10304v1",
    "published_date": "2025-03-13 12:25:36 UTC",
    "updated_date": "2025-03-13 12:25:36 UTC"
  },
  {
    "arxiv_id": "2503.10301v1",
    "title": "Bilingual Dual-Head Deep Model for Parkinson's Disease Detection from Speech",
    "authors": [
      "Moreno La Quatra",
      "Juan Rafael Orozco-Arroyave",
      "Marco Sabato Siniscalchi"
    ],
    "abstract": "This work aims to tackle the Parkinson's disease (PD) detection problem from\nthe speech signal in a bilingual setting by proposing an ad-hoc dual-head deep\nneural architecture for type-based binary classification. One head is\nspecialized for diadochokinetic patterns. The other head looks for natural\nspeech patterns present in continuous spoken utterances. Only one of the two\nheads is operative accordingly to the nature of the input. Speech\nrepresentations are extracted from self-supervised learning (SSL) models and\nwavelet transforms. Adaptive layers, convolutional bottlenecks, and contrastive\nlearning are exploited to reduce variations across languages. Our solution is\nassessed against two distinct datasets, EWA-DB, and PC-GITA, which cover Slovak\nand Spanish languages, respectively. Results indicate that conventional models\ntrained on a single language dataset struggle with cross-linguistic\ngeneralization, and naive combinations of datasets are suboptimal. In contrast,\nour model improves generalization on both languages, simultaneously.",
    "categories": [
      "eess.AS",
      "cs.AI"
    ],
    "primary_category": "eess.AS",
    "comment": "Accepted at ICASSP 2025 - Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses",
    "pdf_url": "http://arxiv.org/pdf/2503.10301v1",
    "published_date": "2025-03-13 12:23:11 UTC",
    "updated_date": "2025-03-13 12:23:11 UTC"
  },
  {
    "arxiv_id": "2503.10296v2",
    "title": "CODEI: Resource-Efficient Task-Driven Co-Design of Perception and Decision Making for Mobile Robots Applied to Autonomous Vehicles",
    "authors": [
      "Dejan Milojevic",
      "Gioele Zardini",
      "Miriam Elser",
      "Andrea Censi",
      "Emilio Frazzoli"
    ],
    "abstract": "This paper discusses the integration challenges and strategies for designing\nmobile robots, by focusing on the task-driven, optimal selection of hardware\nand software to balance safety, efficiency, and minimal usage of resources such\nas costs, energy, computational requirements, and weight. We emphasize the\ninterplay between perception and motion planning in decision-making by\nintroducing the concept of occupancy queries to quantify the perception\nrequirements for sampling-based motion planners. Sensor and algorithm\nperformance are evaluated using False Negative Rates (FPR) and False Positive\nRates (FPR) across various factors such as geometric relationships, object\nproperties, sensor resolution, and environmental conditions. By integrating\nperception requirements with perception performance, an Integer Linear\nProgramming (ILP) approach is proposed for efficient sensor and algorithm\nselection and placement. This forms the basis for a co-design optimization that\nincludes the robot body, motion planner, perception pipeline, and computing\nunit. We refer to this framework for solving the co-design problem of mobile\nrobots as CODEI, short for Co-design of Embodied Intelligence. A case study on\ndeveloping an Autonomous Vehicle (AV) for urban scenarios provides actionable\ninformation for designers, and shows that complex tasks escalate resource\ndemands, with task performance affecting choices of the autonomy stack. The\nstudy demonstrates that resource prioritization influences sensor choice:\ncameras are preferred for cost-effective and lightweight designs, while lidar\nsensors are chosen for better energy and computational efficiency.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.AR",
      "cs.CV",
      "cs.SY",
      "eess.SY",
      "I.2.9; I.2.10; I.2.8; I.4.8"
    ],
    "primary_category": "cs.RO",
    "comment": "20 pages, 33 images, IEEE Transactions on Robotics",
    "pdf_url": "http://arxiv.org/pdf/2503.10296v2",
    "published_date": "2025-03-13 12:12:44 UTC",
    "updated_date": "2025-04-07 15:48:11 UTC"
  },
  {
    "arxiv_id": "2503.10284v1",
    "title": "PyGDA: A Python Library for Graph Domain Adaptation",
    "authors": [
      "Zhen Zhang",
      "Meihan Liu",
      "Bingsheng He"
    ],
    "abstract": "Graph domain adaptation has emerged as a promising approach to facilitate\nknowledge transfer across different domains. Recently, numerous models have\nbeen proposed to enhance their generalization capabilities in this field.\nHowever, there is still no unified library that brings together existing\ntechniques and simplifies their implementation. To fill this gap, we introduce\nPyGDA, an open-source Python library tailored for graph domain adaptation. As\nthe first comprehensive library in this area, PyGDA covers more than 20 widely\nused graph domain adaptation methods together with different types of graph\ndatasets. Specifically, PyGDA offers modular components, enabling users to\nseamlessly build custom models with a variety of commonly used utility\nfunctions. To handle large-scale graphs, PyGDA includes support for features\nsuch as sampling and mini-batch processing, ensuring efficient computation. In\naddition, PyGDA also includes comprehensive performance benchmarks and\nwell-documented user-friendly API for both researchers and practitioners. To\nfoster convenient accessibility, PyGDA is released under the MIT license at\nhttps://github.com/pygda-team/pygda, and the API documentation is\nhttps://pygda.readthedocs.io/en/stable/.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Under Review",
    "pdf_url": "http://arxiv.org/pdf/2503.10284v1",
    "published_date": "2025-03-13 11:52:23 UTC",
    "updated_date": "2025-03-13 11:52:23 UTC"
  },
  {
    "arxiv_id": "2503.10728v1",
    "title": "DarkBench: Benchmarking Dark Patterns in Large Language Models",
    "authors": [
      "Esben Kran",
      "Hieu Minh \"Jord\" Nguyen",
      "Akash Kundu",
      "Sami Jawhar",
      "Jinsuk Park",
      "Mateusz Maria Jurewicz"
    ],
    "abstract": "We introduce DarkBench, a comprehensive benchmark for detecting dark design\npatterns--manipulative techniques that influence user behavior--in interactions\nwith large language models (LLMs). Our benchmark comprises 660 prompts across\nsix categories: brand bias, user retention, sycophancy, anthropomorphism,\nharmful generation, and sneaking. We evaluate models from five leading\ncompanies (OpenAI, Anthropic, Meta, Mistral, Google) and find that some LLMs\nare explicitly designed to favor their developers' products and exhibit\nuntruthful communication, among other manipulative behaviors. Companies\ndeveloping LLMs should recognize and mitigate the impact of dark design\npatterns to promote more ethical AI.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted as an Oral paper at ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.10728v1",
    "published_date": "2025-03-13 11:48:42 UTC",
    "updated_date": "2025-03-13 11:48:42 UTC"
  },
  {
    "arxiv_id": "2503.10727v1",
    "title": "Word-level Annotation of GDPR Transparency Compliance in Privacy Policies using Large Language Models",
    "authors": [
      "Thomas Cory",
      "Wolf Rieder",
      "Julia Krämer",
      "Philip Raschke",
      "Patrick Herbke",
      "Axel Küpper"
    ],
    "abstract": "Ensuring transparency of data practices related to personal information is a\nfundamental requirement under the General Data Protection Regulation (GDPR),\nparticularly as mandated by Articles 13 and 14. However, assessing compliance\nat scale remains a challenge due to the complexity and variability of privacy\npolicy language. Manual audits are resource-intensive and inconsistent, while\nexisting automated approaches lack the granularity needed to capture nuanced\ntransparency disclosures.\n  In this paper, we introduce a large language model (LLM)-based framework for\nword-level GDPR transparency compliance annotation. Our approach comprises a\ntwo-stage annotation pipeline that combines initial LLM-based annotation with a\nself-correction mechanism for iterative refinement. This annotation pipeline\nenables the systematic identification and fine-grained annotation of\ntransparency-related content in privacy policies, aligning with 21 GDPR-derived\ntransparency requirements. To enable large-scale analysis, we compile a dataset\nof 703,791 English-language policies, from which we generate a sample of 200\nmanually annotated privacy policies.\n  To evaluate our approach, we introduce a two-tiered methodology assessing\nboth label- and span-level annotation performance. We conduct a comparative\nanalysis of eight high-profile LLMs, providing insights into their\neffectiveness in identifying GDPR transparency disclosures. Our findings\ncontribute to advancing the automation of GDPR compliance assessments and\nprovide valuable resources for future research in privacy policy analysis.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.10727v1",
    "published_date": "2025-03-13 11:41:25 UTC",
    "updated_date": "2025-03-13 11:41:25 UTC"
  },
  {
    "arxiv_id": "2503.10265v1",
    "title": "SurgRAW: Multi-Agent Workflow with Chain-of-Thought Reasoning for Surgical Intelligence",
    "authors": [
      "Chang Han Low",
      "Ziyue Wang",
      "Tianyi Zhang",
      "Zhitao Zeng",
      "Zhu Zhuo",
      "Evangelos B. Mazomenos",
      "Yueming Jin"
    ],
    "abstract": "Integration of Vision-Language Models (VLMs) in surgical intelligence is\nhindered by hallucinations, domain knowledge gaps, and limited understanding of\ntask interdependencies within surgical scenes, undermining clinical\nreliability. While recent VLMs demonstrate strong general reasoning and\nthinking capabilities, they still lack the domain expertise and task-awareness\nrequired for precise surgical scene interpretation. Although Chain-of-Thought\n(CoT) can structure reasoning more effectively, current approaches rely on\nself-generated CoT steps, which often exacerbate inherent domain gaps and\nhallucinations. To overcome this, we present SurgRAW, a CoT-driven multi-agent\nframework that delivers transparent, interpretable insights for most tasks in\nrobotic-assisted surgery. By employing specialized CoT prompts across five\ntasks: instrument recognition, action recognition, action prediction, patient\ndata extraction, and outcome assessment, SurgRAW mitigates hallucinations\nthrough structured, domain-aware reasoning. Retrieval-Augmented Generation\n(RAG) is also integrated to external medical knowledge to bridge domain gaps\nand improve response reliability. Most importantly, a hierarchical agentic\nsystem ensures that CoT-embedded VLM agents collaborate effectively while\nunderstanding task interdependencies, with a panel discussion mechanism\npromotes logical consistency. To evaluate our method, we introduce\nSurgCoTBench, the first reasoning-based dataset with structured frame-level\nannotations. With comprehensive experiments, we demonstrate the effectiveness\nof proposed SurgRAW with 29.32% accuracy improvement over baseline VLMs on 12\nrobotic procedures, achieving the state-of-the-art performance and advancing\nexplainable, trustworthy, and autonomous surgical assistance.",
    "categories": [
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.10265v1",
    "published_date": "2025-03-13 11:23:13 UTC",
    "updated_date": "2025-03-13 11:23:13 UTC"
  },
  {
    "arxiv_id": "2503.10253v2",
    "title": "PIMRL: Physics-Informed Multi-Scale Recurrent Learning for Spatiotemporal Prediction",
    "authors": [
      "Han Wan",
      "Qi Wang",
      "Yuan Mi",
      "Hao Sun"
    ],
    "abstract": "Simulation of spatiotemporal systems governed by partial differential\nequations is widely applied in fields such as biology, chemistry, aerospace\ndynamics, and meteorology. Traditional numerical methods incur high\ncomputational costs due to the requirement of small time steps for accurate\npredictions. While machine learning has reduced these costs, long-term\npredictions remain challenged by error accumulation, particularly in scenarios\nwith insufficient data or varying time scales, where stability and accuracy are\ncompromised. Existing methods often neglect the effective utilization of\nmulti-scale data, leading to suboptimal robustness in predictions. To address\nthese issues, we propose a novel multi-scale learning framework, namely, the\nPhysics-Informed Multi-Scale Recurrent Learning (PIMRL), to effectively\nleverage multi-scale data for spatiotemporal dynamics prediction. The PIMRL\nframework comprises two modules: the micro-scale module embeds physical\nknowledge into neural networks via pretraining, and the macro-scale module\nadopts a data-driven approach to learn the temporal evolution of physics in the\nlatent space. Experimental results demonstrate that the PIMRL framework\nconsistently achieves state-of-the-art performance across five benchmark\ndatasets ranging from one to three dimensions, showing average improvements of\nover 9\\% in both RMSE and MAE evaluation metrics, with maximum enhancements\nreaching up to 80%.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.10253v2",
    "published_date": "2025-03-13 11:01:03 UTC",
    "updated_date": "2025-03-18 07:08:41 UTC"
  },
  {
    "arxiv_id": "2503.10248v1",
    "title": "LLM Agents Display Human Biases but Exhibit Distinct Learning Patterns",
    "authors": [
      "Idan Horowitz",
      "Ori Plonsky"
    ],
    "abstract": "We investigate the choice patterns of Large Language Models (LLMs) in the\ncontext of Decisions from Experience tasks that involve repeated choice and\nlearning from feedback, and compare their behavior to human participants. We\nfind that on the aggregate, LLMs appear to display behavioral biases similar to\nhumans: both exhibit underweighting rare events and correlation effects.\nHowever, more nuanced analyses of the choice patterns reveal that this happens\nfor very different reasons. LLMs exhibit strong recency biases, unlike humans,\nwho appear to respond in more sophisticated ways. While these different\nprocesses may lead to similar behavior on average, choice patterns contingent\non recent events differ vastly between the two groups. Specifically, phenomena\nsuch as ``surprise triggers change\" and the ``wavy recency effect of rare\nevents\" are robustly observed in humans, but entirely absent in LLMs. Our\nfindings provide insights into the limitations of using LLMs to simulate and\npredict humans in learning environments and highlight the need for refined\nanalyses of their behavior when investigating whether they replicate human\ndecision making tendencies.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.10248v1",
    "published_date": "2025-03-13 10:47:03 UTC",
    "updated_date": "2025-03-13 10:47:03 UTC"
  },
  {
    "arxiv_id": "2503.10242v1",
    "title": "MinorBench: A hand-built benchmark for content-based risks for children",
    "authors": [
      "Shaun Khoo",
      "Gabriel Chua",
      "Rachel Shong"
    ],
    "abstract": "Large Language Models (LLMs) are rapidly entering children's lives - through\nparent-driven adoption, schools, and peer networks - yet current AI ethics and\nsafety research do not adequately address content-related risks specific to\nminors. In this paper, we highlight these gaps with a real-world case study of\nan LLM-based chatbot deployed in a middle school setting, revealing how\nstudents used and sometimes misused the system. Building on these findings, we\npropose a new taxonomy of content-based risks for minors and introduce\nMinorBench, an open-source benchmark designed to evaluate LLMs on their ability\nto refuse unsafe or inappropriate queries from children. We evaluate six\nprominent LLMs under different system prompts, demonstrating substantial\nvariability in their child-safety compliance. Our results inform practical\nsteps for more robust, child-focused safety mechanisms and underscore the\nurgency of tailoring AI systems to safeguard young users.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.10242v1",
    "published_date": "2025-03-13 10:34:43 UTC",
    "updated_date": "2025-03-13 10:34:43 UTC"
  },
  {
    "arxiv_id": "2503.10725v1",
    "title": "Samoyeds: Accelerating MoE Models with Structured Sparsity Leveraging Sparse Tensor Cores",
    "authors": [
      "Chenpeng Wu",
      "Qiqi Gu",
      "Heng Shi",
      "Jianguo Yao",
      "Haibing Guan"
    ],
    "abstract": "The escalating size of Mixture-of-Experts (MoE) based Large Language Models\n(LLMs) presents significant computational and memory challenges, necessitating\ninnovative solutions to enhance efficiency without compromising model accuracy.\nStructured sparsity emerges as a compelling strategy to address these\nchallenges by leveraging the emerging sparse computing hardware. Prior works\nmainly focus on the sparsity in model parameters, neglecting the inherent\nsparse patterns in activations. This oversight can lead to additional\ncomputational costs associated with activations, potentially resulting in\nsuboptimal performance.\n  This paper presents Samoyeds, an innovative acceleration system for MoE LLMs\nutilizing Sparse Tensor Cores (SpTCs). Samoyeds is the first to apply sparsity\nsimultaneously to both activations and model parameters. It introduces a\nbespoke sparse data format tailored for MoE computation and develops a\nspecialized sparse-sparse matrix multiplication kernel. Furthermore, Samoyeds\nincorporates systematic optimizations specifically designed for the execution\nof dual-side structured sparse MoE LLMs on SpTCs, further enhancing system\nperformance. Evaluations show that Samoyeds outperforms SOTA works by up to\n1.99$\\times$ at the kernel level and 1.58$\\times$ at the model level. Moreover,\nit enhances memory efficiency, increasing maximum supported batch sizes by\n4.41$\\times$ on average. Additionally, Samoyeds surpasses existing SOTA\nstructured sparse solutions in both model accuracy and hardware portability.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC",
      "cs.OS"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.10725v1",
    "published_date": "2025-03-13 10:34:15 UTC",
    "updated_date": "2025-03-13 10:34:15 UTC"
  },
  {
    "arxiv_id": "2503.10723v1",
    "title": "RankPO: Preference Optimization for Job-Talent Matching",
    "authors": [
      "Yafei Zhang",
      "Murray Wang",
      "Yu Wang",
      "Xiaohui Wang"
    ],
    "abstract": "Matching job descriptions (JDs) with suitable talent requires models capable\nof understanding not only textual similarities between JDs and candidate\nresumes but also contextual factors such as geographical location and academic\nseniority. To address this challenge, we propose a two-stage training framework\nfor large language models (LLMs). In the first stage, a contrastive learning\napproach is used to train the model on a dataset constructed from real-world\nmatching rules, such as geographical alignment and research area overlap. While\neffective, this model primarily learns patterns that defined by the matching\nrules. In the second stage, we introduce a novel preference-based fine-tuning\nmethod inspired by Direct Preference Optimization (DPO), termed Rank Preference\nOptimization (RankPO), to align the model with AI-curated pairwise preferences\nemphasizing textual understanding. Our experiments show that while the\nfirst-stage model achieves strong performance on rule-based data (nDCG@20 =\n0.706), it lacks robust textual understanding (alignment with AI annotations =\n0.46). By fine-tuning with RankPO, we achieve a balanced model that retains\nrelatively good performance in the original tasks while significantly improving\nthe alignment with AI preferences. The code and data are available at\nhttps://github.com/yflyzhang/RankPO.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "15 pages, 3 figures, 7 tables",
    "pdf_url": "http://arxiv.org/pdf/2503.10723v1",
    "published_date": "2025-03-13 10:14:37 UTC",
    "updated_date": "2025-03-13 10:14:37 UTC"
  },
  {
    "arxiv_id": "2503.10217v1",
    "title": "Efficient Federated Fine-Tuning of Large Language Models with Layer Dropout",
    "authors": [
      "Shilong Wang",
      "Jianchun Liu",
      "Hongli Xu",
      "Jiaming Yan",
      "Xianjun Gao"
    ],
    "abstract": "Fine-tuning plays a crucial role in enabling pre-trained LLMs to evolve from\ngeneral language comprehension to task-specific expertise. To preserve user\ndata privacy, federated fine-tuning is often employed and has emerged as the de\nfacto paradigm. However, federated fine-tuning is prohibitively inefficient due\nto the tension between LLM complexity and the resource constraint of end\ndevices, incurring unaffordable fine-tuning overhead. Existing literature\nprimarily utilizes parameter-efficient fine-tuning techniques to mitigate\ncommunication costs, yet computational and memory burdens continue to pose\nsignificant challenges for developers. This work proposes DropPEFT, an\ninnovative federated PEFT framework that employs a novel stochastic transformer\nlayer dropout method, enabling devices to deactivate a considerable fraction of\nLLMs layers during training, thereby eliminating the associated computational\nload and memory footprint. In DropPEFT, a key challenge is the proper\nconfiguration of dropout ratios for layers, as overhead and training\nperformance are highly sensitive to this setting. To address this challenge, we\nadaptively assign optimal dropout-ratio configurations to devices through an\nexploration-exploitation strategy, achieving efficient and effective\nfine-tuning. Extensive experiments show that DropPEFT can achieve a\n1.3-6.3\\times speedup in model convergence and a 40%-67% reduction in memory\nfootprint compared to state-of-the-art methods.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "13 pages",
    "pdf_url": "http://arxiv.org/pdf/2503.10217v1",
    "published_date": "2025-03-13 09:59:16 UTC",
    "updated_date": "2025-03-13 09:59:16 UTC"
  },
  {
    "arxiv_id": "2503.10215v1",
    "title": "Adaptive Preference Aggregation",
    "authors": [
      "Benjamin Heymann"
    ],
    "abstract": "AI alignment, the challenge of ensuring AI systems act in accordance with\nhuman values, has emerged as a critical problem in the development of systems\nsuch as foundation models and recommender systems. Still, the current dominant\napproach, reinforcement learning with human feedback (RLHF) faces known\ntheoretical limitations in aggregating diverse human preferences. Social choice\ntheory provides a framework to aggregate preferences, but was not developed for\nthe multidimensional applications typical of AI. Leveraging insights from a\nrecently published urn process, this work introduces a preference aggregation\nstrategy that adapts to the user's context and that inherits the good\nproperties of the maximal lottery, a Condorcet-consistent solution concept.",
    "categories": [
      "cs.AI",
      "cs.GT"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.10215v1",
    "published_date": "2025-03-13 09:57:41 UTC",
    "updated_date": "2025-03-13 09:57:41 UTC"
  },
  {
    "arxiv_id": "2503.10198v1",
    "title": "Deep Learning for Time Series Forecasting: A Survey",
    "authors": [
      "Xiangjie Kong",
      "Zhenghao Chen",
      "Weiyao Liu",
      "Kaili Ning",
      "Lechao Zhang",
      "Syauqie Muhammad Marier",
      "Yichen Liu",
      "Yuhao Chen",
      "Feng Xia"
    ],
    "abstract": "Time series forecasting (TSF) has long been a crucial task in both industry\nand daily life. Most classical statistical models may have certain limitations\nwhen applied to practical scenarios in fields such as energy, healthcare,\ntraffic, meteorology, and economics, especially when high accuracy is required.\nWith the continuous development of deep learning, numerous new models have\nemerged in the field of time series forecasting in recent years. However,\nexisting surveys have not provided a unified summary of the wide range of model\narchitectures in this field, nor have they given detailed summaries of works in\nfeature extraction and datasets. To address this gap, in this review, we\ncomprehensively study the previous works and summarize the general paradigms of\nDeep Time Series Forecasting (DTSF) in terms of model architectures. Besides,\nwe take an innovative approach by focusing on the composition of time series\nand systematically explain important feature extraction methods. Additionally,\nwe provide an overall compilation of datasets from various domains in existing\nworks. Finally, we systematically emphasize the significant challenges faced\nand future research directions in this field.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.10198v1",
    "published_date": "2025-03-13 09:32:01 UTC",
    "updated_date": "2025-03-13 09:32:01 UTC"
  },
  {
    "arxiv_id": "2503.10197v1",
    "title": "Predicting Chemical Reaction Outcomes Based on Electron Movements Using Machine Learning",
    "authors": [
      "Shuan Chen",
      "Kye Sung Park",
      "Taewan Kim",
      "Sunkyu Han",
      "Yousung Jung"
    ],
    "abstract": "Accurately predicting chemical reaction outcomes and potential byproducts is\na fundamental task of modern chemistry, enabling the efficient design of\nsynthetic pathways and driving progress in chemical science. Reaction\nmechanism, which tracks electron movements during chemical reactions, is\ncritical for understanding reaction kinetics and identifying unexpected\nproducts. Here, we present Reactron, the first electron-based machine learning\nmodel for general reaction prediction. Reactron integrates electron movement\ninto its predictions, generating detailed arrow-pushing diagrams that elucidate\neach mechanistic step leading to product formation. We demonstrate the high\npredictive performance of Reactron over existing product-only models by a\nlarge-scale reaction outcome prediction benchmark, and the adaptability of the\nmodel to learn new reactivity upon providing a few examples. Furthermore, it\nexplores combinatorial reaction spaces, uncovering novel reactivities beyond\nits training data. With robust performance in both in- and out-of-distribution\npredictions, Reactron embodies human-like reasoning in chemistry and opens new\nfrontiers in reaction discovery and synthesis design.",
    "categories": [
      "physics.chem-ph",
      "cs.AI"
    ],
    "primary_category": "physics.chem-ph",
    "comment": "15 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.10197v1",
    "published_date": "2025-03-13 09:31:51 UTC",
    "updated_date": "2025-03-13 09:31:51 UTC"
  },
  {
    "arxiv_id": "2503.10191v1",
    "title": "Robustness Tokens: Towards Adversarial Robustness of Transformers",
    "authors": [
      "Brian Pulfer",
      "Yury Belousov",
      "Slava Voloshynovskiy"
    ],
    "abstract": "Recently, large pre-trained foundation models have become widely adopted by\nmachine learning practitioners for a multitude of tasks. Given that such models\nare publicly available, relying on their use as backbone models for downstream\ntasks might result in high vulnerability to adversarial attacks crafted with\nthe same public model. In this work, we propose Robustness Tokens, a novel\napproach specific to the transformer architecture that fine-tunes a few\nadditional private tokens with low computational requirements instead of tuning\nmodel parameters as done in traditional adversarial training. We show that\nRobustness Tokens make Vision Transformer models significantly more robust to\nwhite-box adversarial attacks while also retaining the original downstream\nperformances.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "This paper has been accepted for publication at the European\n  Conference on Computer Vision (ECCV), 2024",
    "pdf_url": "http://arxiv.org/pdf/2503.10191v1",
    "published_date": "2025-03-13 09:26:19 UTC",
    "updated_date": "2025-03-13 09:26:19 UTC"
  },
  {
    "arxiv_id": "2503.10186v1",
    "title": "Multi-Agent Q-Learning Dynamics in Random Networks: Convergence due to Exploration and Sparsity",
    "authors": [
      "Aamal Hussain",
      "Dan Leonte",
      "Francesco Belardinelli",
      "Raphael Huser",
      "Dario Paccagnan"
    ],
    "abstract": "Beyond specific settings, many multi-agent learning algorithms fail to\nconverge to an equilibrium solution, and instead display complex,\nnon-stationary behaviours such as recurrent or chaotic orbits. In fact, recent\nliterature suggests that such complex behaviours are likely to occur when the\nnumber of agents increases. In this paper, we study Q-learning dynamics in\nnetwork polymatrix games where the network structure is drawn from classical\nrandom graph models. In particular, we focus on the Erdos-Renyi model, a\nwell-studied model for social networks, and the Stochastic Block model, which\ngeneralizes the above by accounting for community structures within the\nnetwork. In each setting, we establish sufficient conditions under which the\nagents' joint strategies converge to a unique equilibrium. We investigate how\nthis condition depends on the exploration rates, payoff matrices and,\ncrucially, the sparsity of the network. Finally, we validate our theoretical\nfindings through numerical simulations and demonstrate that convergence can be\nreliably achieved in many-agent systems, provided network sparsity is\ncontrolled.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.GT",
      "math.DS",
      "93A16, 91A26, 91A68, 58K35",
      "G.3; J.4; F.2.2"
    ],
    "primary_category": "cs.MA",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.10186v1",
    "published_date": "2025-03-13 09:16:51 UTC",
    "updated_date": "2025-03-13 09:16:51 UTC"
  },
  {
    "arxiv_id": "2503.10183v2",
    "title": "Through the Magnifying Glass: Adaptive Perception Magnification for Hallucination-Free VLM Decoding",
    "authors": [
      "Shunqi Mao",
      "Chaoyi Zhang",
      "Weidong Cai"
    ],
    "abstract": "Existing vision-language models (VLMs) often suffer from visual\nhallucination, where the generated responses contain inaccuracies that are not\ngrounded in the visual input. Efforts to address this issue without model\nfinetuning primarily mitigate hallucination by reducing biases contrastively or\namplifying the weights of visual embedding during decoding. However, these\napproaches improve visual perception at the cost of impairing the language\nreasoning capability. In this work, we propose the Perception Magnifier (PM), a\nnovel visual decoding method that iteratively isolates relevant visual tokens\nbased on attention and magnifies the corresponding regions, spurring the model\nto concentrate on fine-grained visual details during decoding. Specifically, by\nmagnifying critical regions while preserving the structural and contextual\ninformation at each decoding step, PM allows the VLM to enhance its scrutiny of\nthe visual input, hence producing more accurate and faithful responses.\nExtensive experimental results demonstrate that PM not only achieves superior\nhallucination mitigation but also enhances language generation while preserving\nstrong reasoning capabilities. Code is available at\nhttps://github.com/ShunqiM/PM .",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "19 pages, 5 figures, 9 tables",
    "pdf_url": "http://arxiv.org/pdf/2503.10183v2",
    "published_date": "2025-03-13 09:14:11 UTC",
    "updated_date": "2025-03-14 01:48:33 UTC"
  },
  {
    "arxiv_id": "2503.10166v1",
    "title": "ImageScope: Unifying Language-Guided Image Retrieval via Large Multimodal Model Collective Reasoning",
    "authors": [
      "Pengfei Luo",
      "Jingbo Zhou",
      "Tong Xu",
      "Yuan Xia",
      "Linli Xu",
      "Enhong Chen"
    ],
    "abstract": "With the proliferation of images in online content, language-guided image\nretrieval (LGIR) has emerged as a research hotspot over the past decade,\nencompassing a variety of subtasks with diverse input forms. While the\ndevelopment of large multimodal models (LMMs) has significantly facilitated\nthese tasks, existing approaches often address them in isolation, requiring the\nconstruction of separate systems for each task. This not only increases system\ncomplexity and maintenance costs, but also exacerbates challenges stemming from\nlanguage ambiguity and complex image content, making it difficult for retrieval\nsystems to provide accurate and reliable results. To this end, we propose\nImageScope, a training-free, three-stage framework that leverages collective\nreasoning to unify LGIR tasks. The key insight behind the unification lies in\nthe compositional nature of language, which transforms diverse LGIR tasks into\na generalized text-to-image retrieval process, along with the reasoning of LMMs\nserving as a universal verification to refine the results. To be specific, in\nthe first stage, we improve the robustness of the framework by synthesizing\nsearch intents across varying levels of semantic granularity using\nchain-of-thought (CoT) reasoning. In the second and third stages, we then\nreflect on retrieval results by verifying predicate propositions locally, and\nperforming pairwise evaluations globally. Experiments conducted on six LGIR\ndatasets demonstrate that ImageScope outperforms competitive baselines.\nComprehensive evaluations and ablation studies further confirm the\neffectiveness of our design.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.IR",
    "comment": "WWW 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.10166v1",
    "published_date": "2025-03-13 08:43:24 UTC",
    "updated_date": "2025-03-13 08:43:24 UTC"
  },
  {
    "arxiv_id": "2503.10722v1",
    "title": "TacticExpert: Spatial-Temporal Graph Language Model for Basketball Tactics",
    "authors": [
      "Xu Lingrui",
      "Liu Mandi",
      "Zhang Lei"
    ],
    "abstract": "The core challenge in basketball tactic modeling lies in efficiently\nextracting complex spatial-temporal dependencies from historical data and\naccurately predicting various in-game events. Existing state-of-the-art (SOTA)\nmodels, primarily based on graph neural networks (GNNs), encounter difficulties\nin capturing long-term, long-distance, and fine-grained interactions among\nheterogeneous player nodes, as well as in recognizing interaction patterns.\nAdditionally, they exhibit limited generalization to untrained downstream tasks\nand zero-shot scenarios. In this work, we propose a Spatial-Temporal\nPropagation Symmetry-Aware Graph Transformer for fine-grained game modeling.\nThis architecture explicitly captures delay effects in the spatial space to\nenhance player node representations across discrete-time slices, employing\nsymmetry-invariant priors to guide the attention mechanism. We also introduce\nan efficient contrastive learning strategy to train a Mixture of Tactics\nExperts module, facilitating differentiated modeling of offensive tactics. By\nintegrating dense training with sparse inference, we achieve a 2.4x improvement\nin model efficiency. Moreover, the incorporation of Lightweight Graph Grounding\nfor Large Language Models enables robust performance in open-ended downstream\ntasks and zero-shot scenarios, including novel teams or players. The proposed\nmodel, TacticExpert, delineates a vertically integrated large model framework\nfor basketball, unifying pretraining across multiple datasets and downstream\nprediction tasks. Fine-grained modeling modules significantly enhance\nspatial-temporal representations, and visualization analyzes confirm the strong\ninterpretability of the model.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.10722v1",
    "published_date": "2025-03-13 08:27:24 UTC",
    "updated_date": "2025-03-13 08:27:24 UTC"
  },
  {
    "arxiv_id": "2503.10721v1",
    "title": "From Understanding to Excelling: Template-Free Algorithm Design through Structural-Functional Co-Evolution",
    "authors": [
      "Zhe Zhao",
      "Haibin Wen",
      "Pengkun Wang",
      "Ye Wei",
      "Zaixi Zhang",
      "Xi Lin",
      "Fei Liu",
      "Bo An",
      "Hui Xiong",
      "Yang Wang",
      "Qingfu Zhang"
    ],
    "abstract": "Large language models (LLMs) have greatly accelerated the automation of\nalgorithm generation and optimization. However, current methods such as EoH and\nFunSearch mainly rely on predefined templates and expert-specified functions\nthat focus solely on the local evolution of key functionalities. Consequently,\nthey fail to fully leverage the synergistic benefits of the overall\narchitecture and the potential of global optimization. In this paper, we\nintroduce an end-to-end algorithm generation and optimization framework based\non LLMs. Our approach utilizes the deep semantic understanding of LLMs to\nconvert natural language requirements or human-authored papers into code\nsolutions, and employs a two-dimensional co-evolution strategy to optimize both\nfunctional and structural aspects. This closed-loop process spans problem\nanalysis, code generation, and global optimization, automatically identifying\nkey algorithm modules for multi-level joint optimization and continually\nenhancing performance and design innovation. Extensive experiments demonstrate\nthat our method outperforms traditional local optimization approaches in both\nperformance and innovation, while also exhibiting strong adaptability to\nunknown environments and breakthrough potential in structural design. By\nbuilding on human research, our framework generates and optimizes novel\nalgorithms that surpass those designed by human experts, broadening the\napplicability of LLMs for algorithm design and providing a novel solution\npathway for automated algorithm development.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "68W20, 68T20",
      "I.2.7"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.10721v1",
    "published_date": "2025-03-13 08:26:18 UTC",
    "updated_date": "2025-03-13 08:26:18 UTC"
  },
  {
    "arxiv_id": "2503.10150v1",
    "title": "Retrieval-Augmented Generation with Hierarchical Knowledge",
    "authors": [
      "Haoyu Huang",
      "Yongfeng Huang",
      "Junjie Yang",
      "Zhenyu Pan",
      "Yongqiang Chen",
      "Kaili Ma",
      "Hongzhi Chen",
      "James Cheng"
    ],
    "abstract": "Graph-based Retrieval-Augmented Generation (RAG) methods have significantly\nenhanced the performance of large language models (LLMs) in domain-specific\ntasks. However, existing RAG methods do not adequately utilize the naturally\ninherent hierarchical knowledge in human cognition, which limits the\ncapabilities of RAG systems. In this paper, we introduce a new RAG approach,\ncalled HiRAG, which utilizes hierarchical knowledge to enhance the semantic\nunderstanding and structure capturing capabilities of RAG systems in the\nindexing and retrieval processes. Our extensive experiments demonstrate that\nHiRAG achieves significant performance improvements over the state-of-the-art\nbaseline methods. The code of our proposed method is available at\n\\href{https://github.com/hhy-huang/HiRAG}{https://github.com/hhy-huang/HiRAG}.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.10150v1",
    "published_date": "2025-03-13 08:22:31 UTC",
    "updated_date": "2025-03-13 08:22:31 UTC"
  },
  {
    "arxiv_id": "2503.10720v1",
    "title": "AttentionRAG: Attention-Guided Context Pruning in Retrieval-Augmented Generation",
    "authors": [
      "Yixiong Fang",
      "Tianran Sun",
      "Yuling Shi",
      "Xiaodong Gu"
    ],
    "abstract": "While RAG demonstrates remarkable capabilities in LLM applications, its\neffectiveness is hindered by the ever-increasing length of retrieved contexts,\nwhich introduces information redundancy and substantial computational overhead.\nExisting context pruning methods, such as LLMLingua, lack contextual awareness\nand offer limited flexibility in controlling compression rates, often resulting\nin either insufficient pruning or excessive information loss. In this paper, we\npropose AttentionRAG, an attention-guided context pruning method for RAG\nsystems. The core idea of AttentionRAG lies in its attention focus mechanism,\nwhich reformulates RAG queries into a next-token prediction paradigm. This\nmechanism isolates the query's semantic focus to a single token, enabling\nprecise and efficient attention calculation between queries and retrieved\ncontexts. Extensive experiments on LongBench and Babilong benchmarks show that\nAttentionRAG achieves up to 6.3$\\times$ context compression while outperforming\nLLMLingua methods by around 10\\% in key metrics.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.10720v1",
    "published_date": "2025-03-13 08:22:28 UTC",
    "updated_date": "2025-03-13 08:22:28 UTC"
  },
  {
    "arxiv_id": "2503.10144v1",
    "title": "Multiplicative Learning",
    "authors": [
      "Han Kim",
      "Hyungjoon Soh",
      "Vipul Periwal",
      "Junghyo Jo"
    ],
    "abstract": "Efficient training of artificial neural networks remains a key challenge in\ndeep learning. Backpropagation (BP), the standard learning algorithm, relies on\ngradient descent and typically requires numerous iterations for convergence. In\nthis study, we introduce Expectation Reflection (ER), a novel learning approach\nthat updates weights multiplicatively based on the ratio of observed to\npredicted outputs. Unlike traditional methods, ER maintains consistency without\nrequiring ad hoc loss functions or learning rate hyperparameters. We extend ER\nto multilayer networks and demonstrate its effectiveness in performing image\nclassification tasks. Notably, ER achieves optimal weight updates in a single\niteration. Additionally, we reinterpret ER as a modified form of gradient\ndescent incorporating the inverse mapping of target propagation. These findings\nsuggest that ER provides an efficient and scalable alternative for training\nneural networks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.10144v1",
    "published_date": "2025-03-13 08:14:00 UTC",
    "updated_date": "2025-03-13 08:14:00 UTC"
  },
  {
    "arxiv_id": "2503.11514v1",
    "title": "Exploring the Vulnerabilities of Federated Learning: A Deep Dive into Gradient Inversion Attacks",
    "authors": [
      "Pengxin Guo",
      "Runxi Wang",
      "Shuang Zeng",
      "Jinjing Zhu",
      "Haoning Jiang",
      "Yanran Wang",
      "Yuyin Zhou",
      "Feifei Wang",
      "Hui Xiong",
      "Liangqiong Qu"
    ],
    "abstract": "Federated Learning (FL) has emerged as a promising privacy-preserving\ncollaborative model training paradigm without sharing raw data. However, recent\nstudies have revealed that private information can still be leaked through\nshared gradient information and attacked by Gradient Inversion Attacks (GIA).\nWhile many GIA methods have been proposed, a detailed analysis, evaluation, and\nsummary of these methods are still lacking. Although various survey papers\nsummarize existing privacy attacks in FL, few studies have conducted extensive\nexperiments to unveil the effectiveness of GIA and their associated limiting\nfactors in this context. To fill this gap, we first undertake a systematic\nreview of GIA and categorize existing methods into three types, i.e.,\n\\textit{optimization-based} GIA (OP-GIA), \\textit{generation-based} GIA\n(GEN-GIA), and \\textit{analytics-based} GIA (ANA-GIA). Then, we comprehensively\nanalyze and evaluate the three types of GIA in FL, providing insights into the\nfactors that influence their performance, practicality, and potential threats.\nOur findings indicate that OP-GIA is the most practical attack setting despite\nits unsatisfactory performance, while GEN-GIA has many dependencies and ANA-GIA\nis easily detectable, making them both impractical. Finally, we offer a\nthree-stage defense pipeline to users when designing FL frameworks and\nprotocols for better privacy protection and share some future research\ndirections from the perspectives of attackers and defenders that we believe\nshould be pursued. We hope that our study can help researchers design more\nrobust FL frameworks to defend against these attacks.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.11514v1",
    "published_date": "2025-03-13 08:08:44 UTC",
    "updated_date": "2025-03-13 08:08:44 UTC"
  },
  {
    "arxiv_id": "2503.10135v1",
    "title": "Gumiho: A Hybrid Architecture to Prioritize Early Tokens in Speculative Decoding",
    "authors": [
      "Jinze Li",
      "Yixing Xu",
      "Haiduo Huang",
      "Xuanwu Yin",
      "Dong Li",
      "Edith C. H. Ngai",
      "Emad Barsoum"
    ],
    "abstract": "Speculative decoding (SPD) aims to accelerate the auto-regressive token\ngeneration process of a target Large Language Model (LLM). Some approaches\nemploy a draft model with multiple heads to predict a sequence of future\ntokens, where each head handles a token in the sequence. The target LLM\nverifies the predicted sequence and accepts aligned tokens, enabling efficient\nmulti-token generation. However, existing methods assume that all tokens within\na sequence are equally important, employing identical head structures and\nrelying on a single-generation paradigm, either serial or parallel. To this\nend, we theoretically demonstrate that initial tokens in the draft sequence are\nmore important than later ones. Building on this insight, we propose Gumiho, a\nhybrid model combining serial and parallel heads. Specifically, given the\ncritical importance of early tokens, we employ a sophisticated Transformer\narchitecture for the early draft heads in a serial configuration to improve\naccuracy. For later tokens, we utilize multiple lightweight MLP heads operating\nin parallel to enhance efficiency. By allocating more advanced model structures\nand longer running times to the early heads, Gumiho achieves improved overall\nperformance. The experimental results demonstrate that our method outperforms\nexisting approaches, fully validating its effectiveness.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Paper under review",
    "pdf_url": "http://arxiv.org/pdf/2503.10135v1",
    "published_date": "2025-03-13 07:55:38 UTC",
    "updated_date": "2025-03-13 07:55:38 UTC"
  },
  {
    "arxiv_id": "2503.10129v1",
    "title": "Deep Learning-Based Direct Leaf Area Estimation using Two RGBD Datasets for Model Development",
    "authors": [
      "Namal Jayasuriya",
      "Yi Guo",
      "Wen Hu",
      "Oula Ghannoum"
    ],
    "abstract": "Estimation of a single leaf area can be a measure of crop growth and a\nphenotypic trait to breed new varieties. It has also been used to measure leaf\narea index and total leaf area. Some studies have used hand-held cameras, image\nprocessing 3D reconstruction and unsupervised learning-based methods to\nestimate the leaf area in plant images. Deep learning works well for object\ndetection and segmentation tasks; however, direct area estimation of objects\nhas not been explored. This work investigates deep learning-based leaf area\nestimation, for RGBD images taken using a mobile camera setup in real-world\nscenarios. A dataset for attached leaves captured with a top angle view and a\ndataset for detached single leaves were collected for model development and\ntesting. First, image processing-based area estimation was tested on manually\nsegmented leaves. Then a Mask R-CNN-based model was investigated, and modified\nto accept RGBD images and to estimate the leaf area. The detached-leaf data set\nwas then mixed with the attached-leaf plant data set to estimate the single\nleaf area for plant images, and another network design with two backbones was\nproposed: one for segmentation and the other for area estimation. Instead of\ntrying all possibilities or random values, an agile approach was used in\nhyperparameter tuning. The final model was cross-validated with 5-folds and\ntested with two unseen datasets: detached and attached leaves. The F1 score\nwith 90% IoA for segmentation result on unseen detached-leaf data was 1.0,\nwhile R-squared of area estimation was 0.81. For unseen plant data\nsegmentation, the F1 score with 90% IoA was 0.59, while the R-squared score was\n0.57. The research suggests using attached leaves with ground truth area to\nimprove the results.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.10129v1",
    "published_date": "2025-03-13 07:39:09 UTC",
    "updated_date": "2025-03-13 07:39:09 UTC"
  },
  {
    "arxiv_id": "2503.10718v1",
    "title": "Team NYCU at Defactify4: Robust Detection and Source Identification of AI-Generated Images Using CNN and CLIP-Based Models",
    "authors": [
      "Tsan-Tsung Yang",
      "I-Wei Chen",
      "Kuan-Ting Chen",
      "Shang-Hsuan Chiang",
      "Wen-Chih Peng"
    ],
    "abstract": "With the rapid advancement of generative AI, AI-generated images have become\nincreasingly realistic, raising concerns about creativity, misinformation, and\ncontent authenticity. Detecting such images and identifying their source models\nhas become a critical challenge in ensuring the integrity of digital media.\nThis paper tackles the detection of AI-generated images and identifying their\nsource models using CNN and CLIP-ViT classifiers. For the CNN-based classifier,\nwe leverage EfficientNet-B0 as the backbone and feed with RGB channels,\nfrequency features, and reconstruction errors, while for CLIP-ViT, we adopt a\npretrained CLIP image encoder to extract image features and SVM to perform\nclassification. Evaluated on the Defactify 4 dataset, our methods demonstrate\nstrong performance in both tasks, with CLIP-ViT showing superior robustness to\nimage perturbations. Compared to baselines like AEROBLADE and OCC-CLIP, our\napproach achieves competitive results. Notably, our method ranked Top-3 overall\nin the Defactify 4 competition, highlighting its effectiveness and\ngeneralizability. All of our implementations can be found in\nhttps://github.com/uuugaga/Defactify_4",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.10718v1",
    "published_date": "2025-03-13 07:21:16 UTC",
    "updated_date": "2025-03-13 07:21:16 UTC"
  },
  {
    "arxiv_id": "2503.10110v1",
    "title": "IMPACT: Intelligent Motion Planning with Acceptable Contact Trajectories via Vision-Language Models",
    "authors": [
      "Yiyang Ling",
      "Karan Owalekar",
      "Oluwatobiloba Adesanya",
      "Erdem Bıyık",
      "Daniel Seita"
    ],
    "abstract": "Motion planning involves determining a sequence of robot configurations to\nreach a desired pose, subject to movement and safety constraints. Traditional\nmotion planning finds collision-free paths, but this is overly restrictive in\nclutter, where it may not be possible for a robot to accomplish a task without\ncontact. In addition, contacts range from relatively benign (e.g., brushing a\nsoft pillow) to more dangerous (e.g., toppling a glass vase). Due to this\ndiversity, it is difficult to characterize which contacts may be acceptable or\nunacceptable. In this paper, we propose IMPACT, a novel motion planning\nframework that uses Vision-Language Models (VLMs) to infer environment\nsemantics, identifying which parts of the environment can best tolerate contact\nbased on object properties and locations. Our approach uses the VLM's outputs\nto produce a dense 3D \"cost map\" that encodes contact tolerances and seamlessly\nintegrates with standard motion planners. We perform experiments using 20\nsimulation and 10 real-world scenes and assess using task success rate, object\ndisplacements, and feedback from human evaluators. Our results over 3620\nsimulation and 200 real-world trials suggest that IMPACT enables efficient\ncontact-rich motion planning in cluttered settings while outperforming\nalternative methods and ablations. Supplementary material is available at\nhttps://impact-planning.github.io/.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.10110v1",
    "published_date": "2025-03-13 07:09:00 UTC",
    "updated_date": "2025-03-13 07:09:00 UTC"
  },
  {
    "arxiv_id": "2503.10105v1",
    "title": "StepMathAgent: A Step-Wise Agent for Evaluating Mathematical Processes through Tree-of-Error",
    "authors": [
      "Shu-Xun Yang",
      "Cunxiang Wang",
      "Yidong Wang",
      "Xiaotao Gu",
      "Minlie Huang",
      "Jie Tang"
    ],
    "abstract": "Evaluating mathematical capabilities is critical for assessing the overall\nperformance of large language models (LLMs). However, existing evaluation\nmethods often focus solely on final answers, resulting in highly inaccurate and\nuninterpretable evaluation outcomes, as well as their failure to assess proof\nor open-ended problems. To address these issues, we propose a novel\nmathematical process evaluation agent based on Tree-of-Error, called\nStepMathAgent. This agent incorporates four internal core operations: logical\nstep segmentation, step scoring, score aggregation and error tree generation,\nalong with four external extension modules: difficulty calibration, simplicity\nevaluation, completeness validation and format assessment. Furthermore, we\nintroduce StepMathBench, a benchmark comprising 1,000 step-divided process\nevaluation instances, derived from 200 high-quality math problems grouped by\nproblem type, subject category and difficulty level. Experiments on\nStepMathBench show that our proposed StepMathAgent outperforms all\nstate-of-the-art methods, demonstrating human-aligned evaluation preferences\nand broad applicability to various scenarios. Our data and code are available\nat https://github.com/SHU-XUN/StepMathAgent.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.10105v1",
    "published_date": "2025-03-13 07:02:53 UTC",
    "updated_date": "2025-03-13 07:02:53 UTC"
  },
  {
    "arxiv_id": "2503.10717v1",
    "title": "Deep Learning-Based Automated Workflow for Accurate Segmentation and Measurement of Abdominal Organs in CT Scans",
    "authors": [
      "Praveen Shastry",
      "Ashok Sharma",
      "Kavya Mohan",
      "Naveen Kumarasami",
      "Anandakumar D",
      "Mounigasri M",
      "Keerthana R",
      "Kishore Prasath Venkatesh",
      "Bargava Subramanian",
      "Kalyan Sivasailam"
    ],
    "abstract": "Background: Automated analysis of CT scans for abdominal organ measurement is\ncrucial for improving diagnostic efficiency and reducing inter-observer\nvariability. Manual segmentation and measurement of organs such as the kidneys,\nliver, spleen, and prostate are time-consuming and subject to inconsistency,\nunderscoring the need for automated approaches.\n  Purpose: The purpose of this study is to develop and validate an automated\nworkflow for the segmentation and measurement of abdominal organs in CT scans\nusing advanced deep learning models, in order to improve accuracy, reliability,\nand efficiency in clinical evaluations.\n  Methods: The proposed workflow combines nnU-Net, U-Net++ for organ\nsegmentation, followed by a 3D RCNN model for measuring organ volumes and\ndimensions. The models were trained and evaluated on CT datasets with metrics\nsuch as precision, recall, and Mean Squared Error (MSE) to assess performance.\nSegmentation quality was verified for its adaptability to variations in patient\nanatomy and scanner settings.\n  Results: The developed workflow achieved high precision and recall values,\nexceeding 95 for all targeted organs. The Mean Squared Error (MSE) values were\nlow, indicating a high level of consistency between predicted and ground truth\nmeasurements. The segmentation and measurement pipeline demonstrated robust\nperformance, providing accurate delineation and quantification of the kidneys,\nliver, spleen, and prostate.\n  Conclusion: The proposed approach offers an automated, efficient, and\nreliable solution for abdominal organ measurement in CT scans. By significantly\nreducing manual intervention, this workflow enhances measurement accuracy and\nconsistency, with potential for widespread clinical implementation. Future work\nwill focus on expanding the approach to other organs and addressing complex\npathological cases.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "68T99"
    ],
    "primary_category": "eess.IV",
    "comment": "13 pages , 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.10717v1",
    "published_date": "2025-03-13 06:50:44 UTC",
    "updated_date": "2025-03-13 06:50:44 UTC"
  },
  {
    "arxiv_id": "2503.10095v2",
    "title": "Cognitive-Mental-LLM: Evaluating Reasoning in Large Language Models for Mental Health Prediction via Online Text",
    "authors": [
      "Avinash Patil",
      "Amardeep Kour Gedhu"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated potential in predicting mental\nhealth outcomes from online text, yet traditional classification methods often\nlack interpretability and robustness. This study evaluates structured reasoning\ntechniques-Chain-of-Thought (CoT), Self-Consistency (SC-CoT), and\nTree-of-Thought (ToT)-to improve classification accuracy across multiple mental\nhealth datasets sourced from Reddit. We analyze reasoning-driven prompting\nstrategies, including Zero-shot CoT and Few-shot CoT, using key performance\nmetrics such as Balanced Accuracy, F1 score, and Sensitivity/Specificity. Our\nfindings indicate that reasoning-enhanced techniques improve classification\nperformance over direct prediction, particularly in complex cases. Compared to\nbaselines such as Zero Shot non-CoT Prompting, and fine-tuned pre-trained\ntransformers such as BERT and Mental-RoBerta, and fine-tuned Open Source LLMs\nsuch as Mental Alpaca and Mental-Flan-T5, reasoning-driven LLMs yield notable\ngains on datasets like Dreaddit (+0.52\\% over M-LLM, +0.82\\% over BERT) and\nSDCNL (+4.67\\% over M-LLM, +2.17\\% over BERT). However, performance declines in\nDepression Severity, and CSSRS predictions suggest dataset-specific\nlimitations, likely due to our using a more extensive test set. Among prompting\nstrategies, Few-shot CoT consistently outperforms others, reinforcing the\neffectiveness of reasoning-driven LLMs. Nonetheless, dataset variability\nhighlights challenges in model reliability and interpretability. This study\nprovides a comprehensive benchmark of reasoning-based LLM techniques for mental\nhealth text classification. It offers insights into their potential for\nscalable clinical applications while identifying key challenges for future\nimprovements.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "8 pages, 4 Figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2503.10095v2",
    "published_date": "2025-03-13 06:42:37 UTC",
    "updated_date": "2025-03-27 07:14:15 UTC"
  },
  {
    "arxiv_id": "2503.10094v1",
    "title": "Semantic Synergy: Unlocking Policy Insights and Learning Pathways Through Advanced Skill Mapping",
    "authors": [
      "Phoebe Koundouri",
      "Conrad Landis",
      "Georgios Feretzakis"
    ],
    "abstract": "This research introduces a comprehensive system based on state-of-the-art\nnatural language processing, semantic embedding, and efficient search\ntechniques for retrieving similarities and thus generating actionable insights\nfrom raw textual information. The system automatically extracts and aggregates\nnormalized competencies from multiple documents (such as policy files and\ncurricula vitae) and creates strong relationships between recognized\ncompetencies, occupation profiles, and related learning courses. To validate\nits performance, we conducted a multi-tier evaluation that included both\nexplicit and implicit skill references in synthetic and real-world documents.\nThe results showed near-human-level accuracy, with F1 scores exceeding 0.95 for\nexplicit skill detection and above 0.93 for implicit mentions. The system\nthereby establishes a sound foundation for supporting in-depth collaboration\nacross the AE4RIA network. The methodology involves a multi-stage pipeline\nbased on extensive preprocessing and data cleaning, semantic embedding and\nsegmentation via SentenceTransformer, and skill extraction using a FAISS-based\nsearch method. The extracted skills are associated with occupation frameworks\n(as formulated in the ESCO ontology) and with learning paths offered through\nthe Sustainable Development Goals Academy. Moreover, interactive visualization\nsoftware, implemented with Dash and Plotly, presents graphs and tables for\nreal-time exploration and informed decision-making by those involved in\npolicymaking, training and learning supply, career transitions, and\nrecruitment. Overall, this system, backed by rigorous validation, offers\npromising prospects for improved policymaking, human resource development, and\nlifelong learning by providing structured and actionable insights from raw,\ncomplex textual information.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "68T50",
      "I.2.7"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.10094v1",
    "published_date": "2025-03-13 06:41:26 UTC",
    "updated_date": "2025-03-13 06:41:26 UTC"
  },
  {
    "arxiv_id": "2503.13504v1",
    "title": "CoCMT: Communication-Efficient Cross-Modal Transformer for Collaborative Perception",
    "authors": [
      "Rujia Wang",
      "Xiangbo Gao",
      "Hao Xiang",
      "Runsheng Xu",
      "Zhengzhong Tu"
    ],
    "abstract": "Multi-agent collaborative perception enhances each agent perceptual\ncapabilities by sharing sensing information to cooperatively perform robot\nperception tasks. This approach has proven effective in addressing challenges\nsuch as sensor deficiencies, occlusions, and long-range perception. However,\nexisting representative collaborative perception systems transmit intermediate\nfeature maps, such as bird-eye view (BEV) representations, which contain a\nsignificant amount of non-critical information, leading to high communication\nbandwidth requirements. To enhance communication efficiency while preserving\nperception capability, we introduce CoCMT, an object-query-based collaboration\nframework that optimizes communication bandwidth by selectively extracting and\ntransmitting essential features. Within CoCMT, we introduce the Efficient Query\nTransformer (EQFormer) to effectively fuse multi-agent object queries and\nimplement a synergistic deep supervision to enhance the positive reinforcement\nbetween stages, leading to improved overall performance. Experiments on OPV2V\nand V2V4Real datasets show CoCMT outperforms state-of-the-art methods while\ndrastically reducing communication needs. On V2V4Real, our model (Top-50 object\nqueries) requires only 0.416 Mb bandwidth, 83 times less than SOTA methods,\nwhile improving AP70 by 1.1 percent. This efficiency breakthrough enables\npractical collaborative perception deployment in bandwidth-constrained\nenvironments without sacrificing detection accuracy.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.13504v1",
    "published_date": "2025-03-13 06:41:25 UTC",
    "updated_date": "2025-03-13 06:41:25 UTC"
  },
  {
    "arxiv_id": "2504.01963v1",
    "title": "LLMs Working in Harmony: A Survey on the Technological Aspects of Building Effective LLM-Based Multi Agent Systems",
    "authors": [
      "R. M. Aratchige",
      "W. M. K. S. Ilmini"
    ],
    "abstract": "This survey investigates foundational technologies essential for developing\neffective Large Language Model (LLM)-based multi-agent systems. Aiming to\nanswer how best to optimize these systems for collaborative, dynamic\nenvironments, we focus on four critical areas: Architecture, Memory, Planning,\nand Technologies/Frameworks. By analyzing recent advancements and their\nlimitations - such as scalability, real-time response challenges, and agent\ncoordination constraints, we provide a detailed view of the technological\nlandscape. Frameworks like the Mixture of Agents architecture and the ReAct\nplanning model exemplify current innovations, showcasing improvements in role\nassignment and decision-making. This review synthesizes key strengths and\npersistent challenges, offering practical recommendations to enhance system\nscalability, agent collaboration, and adaptability. Our findings provide a\nroadmap for future research, supporting the creation of robust, efficient\nmulti-agent systems that advance both individual agent performance and\ncollective system resilience.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.MA",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.01963v1",
    "published_date": "2025-03-13 06:17:50 UTC",
    "updated_date": "2025-03-13 06:17:50 UTC"
  },
  {
    "arxiv_id": "2503.10075v1",
    "title": "Parallelizing Multi-objective A* Search",
    "authors": [
      "Saman Ahmadi",
      "Nathan R. Sturtevant",
      "Andrea Raith",
      "Daniel Harabor",
      "Mahdi Jalili"
    ],
    "abstract": "The Multi-objective Shortest Path (MOSP) problem is a classic network\noptimization problem that aims to find all Pareto-optimal paths between two\npoints in a graph with multiple edge costs. Recent studies on multi-objective\nsearch with A* (MOA*) have demonstrated superior performance in solving\ndifficult MOSP instances. This paper presents a novel search framework that\nallows efficient parallelization of MOA* with different objective orders. The\nframework incorporates a unique upper bounding strategy that helps the search\nreduce the problem's dimensionality to one in certain cases. Experimental\nresults demonstrate that the proposed framework can enhance the performance of\nrecent A*-based solutions, with the speed-up proportional to the problem\ndimension.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "8 page, 2 tables, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.10075v1",
    "published_date": "2025-03-13 05:43:49 UTC",
    "updated_date": "2025-03-13 05:43:49 UTC"
  },
  {
    "arxiv_id": "2503.10071v1",
    "title": "Advanced Tool Learning and Selection System (ATLASS): A Closed-Loop Framework Using LLM",
    "authors": [
      "Mohd Ariful Haque",
      "Justin Williams",
      "Sunzida Siddique",
      "Md. Hujaifa Islam",
      "Hasmot Ali",
      "Kishor Datta Gupta",
      "Roy George"
    ],
    "abstract": "The combination of LLM agents with external tools enables models to solve\ncomplex tasks beyond their knowledge base. Human-designed tools are inflexible\nand restricted to solutions within the scope of pre-existing tools created by\nexperts. To address this problem, we propose ATLASS, an advanced tool learning\nand selection system designed as a closed-loop framework. It enables the LLM to\nsolve problems by dynamically generating external tools on demand. In this\nframework, agents play a crucial role in orchestrating tool selection,\nexecution, and refinement, ensuring adaptive problem-solving capabilities. The\noperation of ATLASS follows three phases: The first phase, Understanding Tool\nRequirements, involves the Agents determining whether tools are required and\nspecifying their functionality; the second phase, Tool Retrieval/Generation,\ninvolves the Agents retrieving or generating tools based on their availability;\nand the third phase, Task Solving, involves combining all the component tools\nnecessary to complete the initial task. The Tool Dataset stores the generated\ntools, ensuring reusability and minimizing inference cost. Current LLM-based\ntool generation systems have difficulty creating complex tools that need APIs\nor external packages. In ATLASS, we solve the problem by automatically setting\nup the environment, fetching relevant API documentation online, and using a\nPython interpreter to create a reliable, versatile tool that works in a wider\nrange of situations. OpenAI GPT-4.0 is used as the LLM agent, and safety and\nethical concerns are handled through human feedback before executing generated\ncode. By addressing the limitations of predefined toolsets and enhancing\nadaptability, ATLASS serves as a real-world solution that empowers users with\ndynamically generated tools for complex problem-solving.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.10071v1",
    "published_date": "2025-03-13 05:39:00 UTC",
    "updated_date": "2025-03-13 05:39:00 UTC"
  },
  {
    "arxiv_id": "2503.10070v1",
    "title": "AhaRobot: A Low-Cost Open-Source Bimanual Mobile Manipulator for Embodied AI",
    "authors": [
      "Haiqin Cui",
      "Yifu Yuan",
      "Yan Zheng",
      "Jianye Hao"
    ],
    "abstract": "Navigation and manipulation in open-world environments remain unsolved\nchallenges in the Embodied AI. The high cost of commercial mobile manipulation\nrobots significantly limits research in real-world scenes. To address this\nissue, we propose AhaRobot, a low-cost and fully open-source dual-arm mobile\nmanipulation robot system with a hardware cost of only $1,000 (excluding\noptional computational resources), which is less than 1/15 of the cost of\npopular mobile robots. The AhaRobot system consists of three components: (1) a\nnovel low-cost hardware architecture primarily composed of off-the-shelf\ncomponents, (2) an optimized control solution to enhance operational precision\nintegrating dual-motor backlash control and static friction compensation, and\n(3) a simple remote teleoperation method RoboPilot. We use handles to control\nthe dual arms and pedals for whole-body movement. The teleoperation process is\nlow-burden and easy to operate, much like piloting. RoboPilot is designed for\nremote data collection in embodied scenarios. Experimental results demonstrate\nthat RoboPilot significantly enhances data collection efficiency in complex\nmanipulation tasks, achieving a 30% increase compared to methods using 3D mouse\nand leader-follower systems. It also excels at completing extremely\nlong-horizon tasks in one go. Furthermore, AhaRobot can be used to learn\nend-to-end policies and autonomously perform complex manipulation tasks, such\nas pen insertion and cleaning up the floor. We aim to build an affordable yet\npowerful platform to promote the development of embodied tasks on real devices,\nadvancing more robust and reliable embodied AI. All hardware and software\nsystems are available at https://aha-robot.github.io.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "The first two authors contributed equally. Website:\n  https://aha-robot.github.io",
    "pdf_url": "http://arxiv.org/pdf/2503.10070v1",
    "published_date": "2025-03-13 05:34:43 UTC",
    "updated_date": "2025-03-13 05:34:43 UTC"
  },
  {
    "arxiv_id": "2503.10061v2",
    "title": "Compute Optimal Scaling of Skills: Knowledge vs Reasoning",
    "authors": [
      "Nicholas Roberts",
      "Niladri Chatterji",
      "Sharan Narang",
      "Mike Lewis",
      "Dieuwke Hupkes"
    ],
    "abstract": "Scaling laws are a critical component of the LLM development pipeline, most\nfamously as a way to forecast training decisions such as 'compute-optimally'\ntrading-off parameter count and dataset size, alongside a more recent growing\nlist of other crucial decisions. In this work, we ask whether compute-optimal\nscaling behaviour can be skill-dependent. In particular, we examine knowledge\nand reasoning-based skills such as knowledge-based QA and code generation, and\nwe answer this question in the affirmative: scaling laws are skill-dependent.\nNext, to understand whether skill-dependent scaling is an artefact of the\npretraining datamix, we conduct an extensive ablation of different datamixes\nand find that, also when correcting for datamix differences, knowledge and code\nexhibit fundamental differences in scaling behaviour. We conclude with an\nanalysis of how our findings relate to standard compute-optimal scaling using a\nvalidation set, and find that a misspecified validation set can impact\ncompute-optimal parameter count by nearly 50%, depending on its skill\ncomposition.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.10061v2",
    "published_date": "2025-03-13 05:21:22 UTC",
    "updated_date": "2025-03-14 01:39:39 UTC"
  },
  {
    "arxiv_id": "2503.10058v1",
    "title": "Deep Learning Approaches for Anti-Money Laundering on Mobile Transactions: Review, Framework, and Directions",
    "authors": [
      "Jiani Fan",
      "Lwin Khin Shar",
      "Ruichen Zhang",
      "Ziyao Liu",
      "Wenzhuo Yang",
      "Dusit Niyato",
      "Bomin Mao",
      "Kwok-Yan Lam"
    ],
    "abstract": "Money laundering is a financial crime that obscures the origin of illicit\nfunds, necessitating the development and enforcement of anti-money laundering\n(AML) policies by governments and organizations. The proliferation of mobile\npayment platforms and smart IoT devices has significantly complicated AML\ninvestigations. As payment networks become more interconnected, there is an\nincreasing need for efficient real-time detection to process large volumes of\ntransaction data on heterogeneous payment systems by different operators such\nas digital currencies, cryptocurrencies and account-based payments. Most of\nthese mobile payment networks are supported by connected devices, many of which\nare considered loT devices in the FinTech space that constantly generate data.\nFurthermore, the growing complexity and unpredictability of transaction\npatterns across these networks contribute to a higher incidence of false\npositives. While machine learning solutions have the potential to enhance\ndetection efficiency, their application in AML faces unique challenges, such as\naddressing privacy concerns tied to sensitive financial data and managing the\nreal-world constraint of limited data availability due to data regulations.\nExisting surveys in the AML literature broadly review machine learning\napproaches for money laundering detection, but they often lack an in-depth\nexploration of advanced deep learning techniques - an emerging field with\nsignificant potential. To address this gap, this paper conducts a comprehensive\nreview of deep learning solutions and the challenges associated with their use\nin AML. Additionally, we propose a novel framework that applies the\nleast-privilege principle by integrating machine learning techniques, codifying\nAML red flags, and employing account profiling to provide context for\npredictions and enable effective fraud detection under limited data\navailability....",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.10058v1",
    "published_date": "2025-03-13 05:19:44 UTC",
    "updated_date": "2025-03-13 05:19:44 UTC"
  },
  {
    "arxiv_id": "2503.10052v1",
    "title": "DTA: Dual Temporal-channel-wise Attention for Spiking Neural Networks",
    "authors": [
      "Minje Kim",
      "Minjun Kim",
      "Xu Yang"
    ],
    "abstract": "Spiking Neural Networks (SNNs) present a more energy-efficient alternative to\nArtificial Neural Networks (ANNs) by harnessing spatio-temporal dynamics and\nevent-driven spikes. Effective utilization of temporal information is crucial\nfor SNNs, leading to the exploration of attention mechanisms to enhance this\ncapability. Conventional attention operations either apply identical operation\nor employ non-identical operations across target dimensions. We identify that\nthese approaches provide distinct perspectives on temporal information. To\nleverage the strengths of both operations, we propose a novel Dual\nTemporal-channel-wise Attention (DTA) mechanism that integrates both\nidentical/non-identical attention strategies. To the best of our knowledge,\nthis is the first attempt to concentrate on both the correlation and dependency\nof temporal-channel using both identical and non-identical attention\noperations. Experimental results demonstrate that the DTA mechanism achieves\nstate-of-the-art performance on both static datasets (CIFAR10, CIFAR100,\nImageNet-1k) and dynamic dataset (CIFAR10-DVS), elevating spike representation\nand capturing complex temporal-channel relationship. We open-source our code:\nhttps://github.com/MnJnKIM/DTA-SNN.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by IEEE/CVF Winter Conference on Applications of Computer\n  Vision (WACV) 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.10052v1",
    "published_date": "2025-03-13 05:09:48 UTC",
    "updated_date": "2025-03-13 05:09:48 UTC"
  },
  {
    "arxiv_id": "2503.10040v1",
    "title": "Rapid analysis of point-contact Andreev reflection spectra via machine learning with adaptive data augmentation",
    "authors": [
      "Dongik Lee",
      "Valentin Stanev",
      "Xiaohang Zhang",
      "Mijeong Kang",
      "Ichiro Takeuchi",
      "Seunghun Lee"
    ],
    "abstract": "Delineating the superconducting order parameters is a pivotal task in\ninvestigating superconductivity for probing pairing mechanisms, as well as\ntheir symmetry and topology. Point-contact Andreev reflection (PCAR)\nmeasurement is a simple yet powerful tool for identifying the order parameters.\nThe PCAR spectra exhibit significant variations depending on the type of the\norder parameter in a superconductor, including its magnitude\n($\\mathit{\\Delta}$), as well as temperature, interfacial quality, Fermi\nvelocity mismatch, and other factors. The information on the order parameter\ncan be obtained by finding the combination of these parameters, generating a\ntheoretical spectrum that fits a measured experimental spectrum. However, due\nto the complexity of the spectra and the high dimensionality of parameters,\nextracting the fitting parameters is often time-consuming and labor-intensive.\nIn this study, we employ a convolutional neural network (CNN) algorithm to\ncreate models for rapid and automated analysis of PCAR spectra of various\nsuperconductors with different pairing symmetries (conventional $s$-wave,\nchiral $p_x+ip_y$-wave, and $d_{x^2-y^2}$-wave). The training datasets are\ngenerated based on the Blonder-Tinkham-Klapwijk (BTK) theory and further\nmodified and augmented by selectively incorporating noise and peaks according\nto the bias voltages. This approach not only replicates the experimental\nspectra but also brings the model's attention to important features within the\nspectra. The optimized models provide fitting parameters for experimentally\nmeasured spectra in less than 100 ms per spectrum. Our approaches and findings\npave the way for rapid and automated spectral analysis which will help\naccelerate research on superconductors with complex order parameters.",
    "categories": [
      "cond-mat.supr-con",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cond-mat.supr-con",
    "comment": "18 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.10040v1",
    "published_date": "2025-03-13 04:45:38 UTC",
    "updated_date": "2025-03-13 04:45:38 UTC"
  },
  {
    "arxiv_id": "2503.10009v1",
    "title": "OR-LLM-Agent: Automating Modeling and Solving of Operations Research Optimization Problem with Reasoning Large Language Model",
    "authors": [
      "Bowen Zhang",
      "Pengcheng Luo"
    ],
    "abstract": "Operations Research (OR) has been widely applied in various fields such as\nresource allocation, production planning, and supply chain management. However,\naddressing real-world OR problems requires OR experts to perform mathematical\nmodeling and programmers to develop solution algorithms. This traditional\nmethod, heavily reliant on experts, is costly and has long development cycles,\nseverely limiting the widespread adoption of OR techniques. Few have considered\nusing Artificial Intelligence (AI) to replace professionals to achieve fully\nautomated solutions for OR problems. We propose OR-LLM-Agent, the first AI\nagent that enables end-to-end automation for solving real-world OR problems.\nOR-LLM-Agent leverages the Chain-of-Thought (CoT) reasoning capabilities of\nLarge Language Models (LLMs) to translate natural language problem descriptions\ninto formal mathematical models and automatically generate Gurobi solver code.\nIn OR-LLM-Agent, OR-CodeAgent is designed to automate code execution and repair\nwithin a sandbox environment, facilitating the derivation of the final\nsolution. Due to the lack of dedicated benchmark datasets for evaluating the\nautomated solving of OR problems, we construct a benchmark dataset comprising\n83 real-world OR problems described in natural language. We conduct comparative\nexperiments with state-of-the-art (SOTA) reasoning LLMs, including GPT-o3-mini,\nDeepSeek-R1, and Gemini 2.0 Flash Thinking. The OR-LLM-Agent achieved the\nhighest pass rate of 100% and the highest solution accuracy of 85%,\ndemonstrating the feasibility of automated OR problem-solving. Data and code\nhave been publicly available at https://github.com/bwz96sco/or_llm_agent.",
    "categories": [
      "cs.AI",
      "math.OC"
    ],
    "primary_category": "cs.AI",
    "comment": "11 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.10009v1",
    "published_date": "2025-03-13 03:40:50 UTC",
    "updated_date": "2025-03-13 03:40:50 UTC"
  },
  {
    "arxiv_id": "2503.10714v2",
    "title": "ZSMerge: Zero-Shot KV Cache Compression for Memory-Efficient Long-Context LLMs",
    "authors": [
      "Xin Liu",
      "Pei Liu",
      "Guoming Tang"
    ],
    "abstract": "The linear growth of key-value (KV) cache memory and quadratic computational\nin attention mechanisms complexity pose significant bottlenecks for large\nlanguage models (LLMs) in long-context processing. While existing KV cache\noptimization methods address these challenges through token pruning or feature\nmerging, they often incur irreversible information loss or require costly\nparameter retraining. To this end, we propose ZSMerge, a dynamic KV cache\ncompression framework designed for efficient cache management, featuring three\nkey operations: (1) fine-grained memory allocation guided by multi-dimensional\ntoken importance metrics at head-level granularity, (2) a residual merging\nmechanism that preserves critical context through compensated attention\nscoring, and (3) a zero-shot adaptation mechanism compatible with diverse LLM\narchitectures without requiring retraining. ZSMerge significantly enhances\nmemory efficiency and inference speed with negligible performance degradation\nacross LLMs. When applied to LLaMA2-7B, it demonstrates a 20:1 compression\nratio for key-value cache retention (reducing memory footprint to 5\\% of\nbaseline) while sustaining comparable generation quality, coupled with triple\nthroughput gains at extreme 54k-token contexts that eliminate out-of-memory\nfailures. The code is available at https://github.com/SusCom-Lab/ZSMerge.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.10714v2",
    "published_date": "2025-03-13 03:36:03 UTC",
    "updated_date": "2025-04-06 12:20:25 UTC"
  },
  {
    "arxiv_id": "2503.10003v1",
    "title": "A New Benchmark for Few-Shot Class-Incremental Learning: Redefining the Upper Bound",
    "authors": [
      "Shiwon Kim",
      "Dongjun Hwang",
      "Sungwon Woo",
      "Rita Singh"
    ],
    "abstract": "Class-incremental learning (CIL) aims to continuously adapt to emerging\nclasses while retaining knowledge of previously learned ones. Few-shot\nclass-incremental learning (FSCIL) presents an even greater challenge which\nrequires the model to learn incremental classes with only a limited number of\nsamples. In conventional CIL, joint training is widely considered the upper\nbound, serving as both a benchmark and a methodological guide. However, we find\nthat joint training fails to be a meaningful upper bound in FSCIL due to the\ninherent difficulty of inter-task class separation (ICS) caused by severe class\nimbalance. In this work, we introduce a new joint training benchmark tailored\nfor FSCIL by integrating imbalance-aware techniques, effectively bridging the\nperformance gap between base and incremental classes. Furthermore, we point out\ninconsistencies in the experimental setup and evaluation of existing FSCIL\nmethods. To ensure fair comparisons between different FSCIL approaches and\njoint training, we standardize training conditions and propose a unified\nevaluation protocol that simultaneously considers the validation set and\ncomputational complexity. By establishing a reliable upper bound and a\nstandardized evaluation framework for FSCIL, our work provides a clear\nbenchmark and a practical foundation for future research.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.10003v1",
    "published_date": "2025-03-13 03:25:29 UTC",
    "updated_date": "2025-03-13 03:25:29 UTC"
  },
  {
    "arxiv_id": "2503.10713v1",
    "title": "HiCMamba: Enhancing Hi-C Resolution and Identifying 3D Genome Structures with State Space Modeling",
    "authors": [
      "Minghao Yang",
      "Zhi-An Huang",
      "Zhihang Zheng",
      "Yuqiao Liu",
      "Shichen Zhang",
      "Pengfei Zhang",
      "Hui Xiong",
      "Shaojun Tang"
    ],
    "abstract": "Hi-C technology measures genome-wide interaction frequencies, providing a\npowerful tool for studying the 3D genomic structure within the nucleus.\nHowever, high sequencing costs and technical challenges often result in Hi-C\ndata with limited coverage, leading to imprecise estimates of chromatin\ninteraction frequencies. To address this issue, we present a novel deep\nlearning-based method HiCMamba to enhance the resolution of Hi-C contact maps\nusing a state space model. We adopt the UNet-based auto-encoder architecture to\nstack the proposed holistic scan block, enabling the perception of both global\nand local receptive fields at multiple scales. Experimental results demonstrate\nthat HiCMamba outperforms state-of-the-art methods while significantly reducing\ncomputational resources. Furthermore, the 3D genome structures, including\ntopologically associating domains (TADs) and loops, identified in the contact\nmaps recovered by HiCMamba are validated through associated epigenomic\nfeatures. Our work demonstrates the potential of a state space model as\nfoundational frameworks in the field of Hi-C resolution enhancement.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.10713v1",
    "published_date": "2025-03-13 03:04:02 UTC",
    "updated_date": "2025-03-13 03:04:02 UTC"
  },
  {
    "arxiv_id": "2503.09988v3",
    "title": "Label Unbalance in High-frequency Trading",
    "authors": [
      "Zijian Zhao",
      "Xuming Zhang",
      "Jiayu Wen",
      "Mingwen Liu",
      "Xiaoteng Ma"
    ],
    "abstract": "In financial trading, return prediction is one of the foundation for a\nsuccessful trading system. By the fast development of the deep learning in\nvarious areas such as graphical processing, natural language, it has also\ndemonstrate significant edge in handling with financial data. While the success\nof the deep learning relies on huge amount of labeled sample, labeling each\ntime/event as profitable or unprofitable, under the transaction cost,\nespecially in the high-frequency trading world, suffers from serious label\nimbalance issue.In this paper, we adopts rigurious end-to-end deep learning\nframework with comprehensive label imbalance adjustment methods and succeed in\npredicting in high-frequency return in the Chinese future market. The code for\nour method is publicly available at\nhttps://github.com/RS2002/Label-Unbalance-in-High-Frequency-Trading .",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-fin.CP"
    ],
    "primary_category": "cs.LG",
    "comment": "Technical Report",
    "pdf_url": "http://arxiv.org/pdf/2503.09988v3",
    "published_date": "2025-03-13 02:55:06 UTC",
    "updated_date": "2025-03-21 03:10:17 UTC"
  },
  {
    "arxiv_id": "2503.09974v1",
    "title": "Uncertainty-aware Long-tailed Weights Model the Utility of Pseudo-labels for Semi-supervised Learning",
    "authors": [
      "Jiaqi Wu",
      "Junbiao Pang",
      "Qingming Huang"
    ],
    "abstract": "Current Semi-supervised Learning (SSL) adopts the pseudo-labeling strategy\nand further filters pseudo-labels based on confidence thresholds. However, this\nmechanism has notable drawbacks: 1) setting the reasonable threshold is an open\nproblem which significantly influences the selection of the high-quality\npseudo-labels; and 2) deep models often exhibit the over-confidence phenomenon\nwhich makes the confidence value an unreliable indicator for assessing the\nquality of pseudo-labels due to the scarcity of labeled data. In this paper, we\npropose an Uncertainty-aware Ensemble Structure (UES) to assess the utility of\npseudo-labels for unlabeled samples. We further model the utility of\npseudo-labels as long-tailed weights to avoid the open problem of setting the\nthreshold. Concretely, the advantage of the long-tailed weights ensures that\neven unreliable pseudo-labels still contribute to enhancing the model's\nrobustness. Besides, UES is lightweight and architecture-agnostic, easily\nextending to various computer vision tasks, including classification and\nregression. Experimental results demonstrate that combining the proposed method\nwith DualPose leads to a 3.47% improvement in Percentage of Correct Keypoints\n(PCK) on the Sniffing dataset with 100 data points (30 labeled), a 7.29\\%\nimprovement in PCK on the FLIC dataset with 100 data points (50 labeled), and a\n3.91% improvement in PCK on the LSP dataset with 200 data points (100 labeled).\nFurthermore, when combined with FixMatch, the proposed method achieves a 0.2%\naccuracy improvement on the CIFAR-10 dataset with 40 labeled data points and a\n0.26% accuracy improvement on the CIFAR-100 dataset with 400 labeled data\npoints.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "arXiv admin note: text overlap with arXiv:2408.04150",
    "pdf_url": "http://arxiv.org/pdf/2503.09974v1",
    "published_date": "2025-03-13 02:21:04 UTC",
    "updated_date": "2025-03-13 02:21:04 UTC"
  },
  {
    "arxiv_id": "2503.09969v1",
    "title": "Detecting Dataset Bias in Medical AI: A Generalized and Modality-Agnostic Auditing Framework",
    "authors": [
      "Nathan Drenkow",
      "Mitchell Pavlak",
      "Keith Harrigian",
      "Ayah Zirikly",
      "Adarsh Subbaswamy",
      "Mathias Unberath"
    ],
    "abstract": "Data-driven AI is establishing itself at the center of evidence-based\nmedicine. However, reports of shortcomings and unexpected behavior are growing\ndue to AI's reliance on association-based learning. A major reason for this\nbehavior: latent bias in machine learning datasets can be amplified during\ntraining and/or hidden during testing. We present a data modality-agnostic\nauditing framework for generating targeted hypotheses about sources of bias\nwhich we refer to as Generalized Attribute Utility and Detectability-Induced\nbias Testing (G-AUDIT) for datasets. Our method examines the relationship\nbetween task-level annotations and data properties including protected\nattributes (e.g., race, age, sex) and environment and acquisition\ncharacteristics (e.g., clinical site, imaging protocols). G-AUDIT automatically\nquantifies the extent to which the observed data attributes may enable shortcut\nlearning, or in the case of testing data, hide predictions made based on\nspurious associations. We demonstrate the broad applicability and value of our\nmethod by analyzing large-scale medical datasets for three distinct modalities\nand learning tasks: skin lesion classification in images, stigmatizing language\nclassification in Electronic Health Records (EHR), and mortality prediction for\nICU tabular data. In each setting, G-AUDIT successfully identifies subtle\nbiases commonly overlooked by traditional qualitative methods that focus\nprimarily on social and ethical objectives, underscoring its practical value in\nexposing dataset-level risks and supporting the downstream development of\nreliable AI systems. Our method paves the way for achieving deeper\nunderstanding of machine learning datasets throughout the AI development\nlife-cycle from initial prototyping all the way to regulation, and creates\nopportunities to reduce model bias, enabling safer and more trustworthy AI\nsystems.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.09969v1",
    "published_date": "2025-03-13 02:16:48 UTC",
    "updated_date": "2025-03-13 02:16:48 UTC"
  },
  {
    "arxiv_id": "2503.09960v1",
    "title": "Optimizing Fire Safety: Reducing False Alarms Using Advanced Machine Learning Techniques",
    "authors": [
      "Muhammad Hassan Jamal",
      "Abdulwahab Alazeb",
      "Shahid Allah Bakhsh",
      "Wadii Boulila",
      "Syed Aziz Shah",
      "Aizaz Ahmad Khattak",
      "Muhammad Shahbaz Khan"
    ],
    "abstract": "Fire safety practices are important to reduce the extent of destruction\ncaused by fire. While smoke alarms help save lives, firefighters struggle with\nthe increasing number of false alarms. This paper presents a precise and\nefficient Weighted ensemble model for decreasing false alarms. It estimates the\ndensity, computes weights according to the high and low-density regions,\nforwards the high region weights to KNN and low region weights to XGBoost and\ncombines the predictions. The proposed model is effective at reducing response\ntime, increasing fire safety, and minimizing the damage that fires cause. A\nspecifically designed dataset for smoke detection is utilized to test the\nproposed model. In addition, a variety of ML models, such as Logistic\nRegression (LR), Decision Tree (DT), Random Forest (RF), Nai:ve Bayes (NB),\nK-Nearest Neighbour (KNN), Support Vector Machine (SVM), Extreme Gradient\nBoosting (XGBoost), Adaptive Boosting (ADAB), have also been utilized. To\nmaximize the use of the smoke detection dataset, all the algorithms utilize the\nSMOTE re-sampling technique. After evaluating the assessment criteria, this\npaper presents a concise summary of the comprehensive findings obtained by\ncomparing the outcomes of all models.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.09960v1",
    "published_date": "2025-03-13 02:07:14 UTC",
    "updated_date": "2025-03-13 02:07:14 UTC"
  },
  {
    "arxiv_id": "2503.09956v3",
    "title": "DeepSeek-Inspired Exploration of RL-based LLMs and Synergy with Wireless Networks: A Survey",
    "authors": [
      "Yu Qiao",
      "Phuong-Nam Tran",
      "Ji Su Yoon",
      "Loc X. Nguyen",
      "Eui-Nam Huh",
      "Dusit Niyato",
      "Choong Seon Hong"
    ],
    "abstract": "Reinforcement learning (RL)-based large language models (LLMs), such as\nChatGPT, DeepSeek, and Grok-3, have gained significant attention for their\nexceptional capabilities in natural language processing and multimodal data\nunderstanding. Meanwhile, the rapid expansion of information services has\ndriven the growing need for intelligence, efficient, and adaptable wireless\nnetworks. Wireless networks require the empowerment of RL-based LLMs while\nthese models also benefit from wireless networks to broaden their application\nscenarios. Specifically, RL-based LLMs can enhance wireless communication\nsystems through intelligent resource allocation, adaptive network optimization,\nand real-time decision-making. Conversely, wireless networks provide a vital\ninfrastructure for the efficient training, deployment, and distributed\ninference of RL-based LLMs, especially in decentralized and edge computing\nenvironments. This mutual empowerment highlights the need for a deeper\nexploration of the interplay between these two domains. We first review recent\nadvancements in wireless communications, highlighting the associated challenges\nand potential solutions. We then discuss the progress of RL-based LLMs,\nfocusing on key technologies for LLM training, challenges, and potential\nsolutions. Subsequently, we explore the mutual empowerment between these two\nfields, highlighting key motivations, open challenges, and potential solutions.\nFinally, we provide insights into future directions, applications, and their\nsocietal impact to further explore this intersection, paving the way for\nnext-generation intelligent communication systems. Overall, this survey\nprovides a comprehensive overview of the relationship between RL-based LLMs and\nwireless networks, offering a vision where these domains empower each other to\ndrive innovations.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.ET"
    ],
    "primary_category": "cs.LG",
    "comment": "45 pages, 12 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.09956v3",
    "published_date": "2025-03-13 01:59:11 UTC",
    "updated_date": "2025-04-17 01:30:17 UTC"
  },
  {
    "arxiv_id": "2503.09950v1",
    "title": "MoFlow: One-Step Flow Matching for Human Trajectory Forecasting via Implicit Maximum Likelihood Estimation based Distillation",
    "authors": [
      "Yuxiang Fu",
      "Qi Yan",
      "Lele Wang",
      "Ke Li",
      "Renjie Liao"
    ],
    "abstract": "In this paper, we address the problem of human trajectory forecasting, which\naims to predict the inherently multi-modal future movements of humans based on\ntheir past trajectories and other contextual cues. We propose a novel motion\nprediction conditional flow matching model, termed MoFlow, to predict K-shot\nfuture trajectories for all agents in a given scene. We design a novel flow\nmatching loss function that not only ensures at least one of the $K$ sets of\nfuture trajectories is accurate but also encourages all $K$ sets of future\ntrajectories to be diverse and plausible. Furthermore, by leveraging the\nimplicit maximum likelihood estimation (IMLE), we propose a novel distillation\nmethod for flow models that only requires samples from the teacher model.\nExtensive experiments on the real-world datasets, including SportVU NBA games,\nETH-UCY, and SDD, demonstrate that both our teacher flow model and the\nIMLE-distilled student model achieve state-of-the-art performance. These models\ncan generate diverse trajectories that are physically and socially plausible.\nMoreover, our one-step student model is $\\textbf{100}$ times faster than the\nteacher flow model during sampling. The code, model, and data are available at\nour project page: https://moflow-imle.github.io",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to CVPR 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.09950v1",
    "published_date": "2025-03-13 01:53:05 UTC",
    "updated_date": "2025-03-13 01:53:05 UTC"
  },
  {
    "arxiv_id": "2503.09947v1",
    "title": "Identifying Trustworthiness Challenges in Deep Learning Models for Continental-Scale Water Quality Prediction",
    "authors": [
      "Xiaobo Xia",
      "Xiaofeng Liu",
      "Jiale Liu",
      "Kuai Fang",
      "Lu Lu",
      "Samet Oymak",
      "William S. Currie",
      "Tongliang Liu"
    ],
    "abstract": "Water quality is foundational to environmental sustainability, ecosystem\nresilience, and public health. Deep learning models, particularly Long\nShort-Term Memory (LSTM) networks, offer transformative potential for\nlarge-scale water quality prediction and scientific insights generation.\nHowever, their widespread adoption in high-stakes decision-making, such as\npollution mitigation and equitable resource allocation, is prevented by\nunresolved trustworthiness challenges including fairness, uncertainty,\ninterpretability, robustness, generalizability, and reproducibility. In this\nwork, we present the first comprehensive evaluation of trustworthiness in a\ncontinental-scale multi-task LSTM model predicting 20 water quality variables\n(encompassing physical/chemical processes, geochemical weathering, and nutrient\ncycling) across 482 U.S. basins. Our investigation uncovers systematic patterns\nof model performance disparities linked to basin characteristics, the inherent\ncomplexity of biogeochemical processes, and variable predictability,\nemphasizing critical performance fairness concerns. We further propose\nmethodological frameworks for quantitatively evaluating critical aspects of\ntrustworthiness, including uncertainty, interpretability, and robustness,\nidentifying key limitations that could challenge reliable real-world\ndeployment. This work serves as a timely call to action for advancing\ntrustworthy data-driven methods for water resources management and provides a\npathway to offering critical insights for researchers, decision-makers, and\npractitioners seeking to leverage artificial intelligence (AI) responsibly in\nenvironmental management.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "33 pages, 9 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2503.09947v1",
    "published_date": "2025-03-13 01:50:50 UTC",
    "updated_date": "2025-03-13 01:50:50 UTC"
  },
  {
    "arxiv_id": "2503.09941v1",
    "title": "TGP: Two-modal occupancy prediction with 3D Gaussian and sparse points for 3D Environment Awareness",
    "authors": [
      "Mu Chen",
      "Wenyu Chen",
      "Mingchuan Yang",
      "Yuan Zhang",
      "Tao Han",
      "Xinchi Li",
      "Yunlong Li",
      "Huaici Zhao"
    ],
    "abstract": "3D semantic occupancy has rapidly become a research focus in the fields of\nrobotics and autonomous driving environment perception due to its ability to\nprovide more realistic geometric perception and its closer integration with\ndownstream tasks. By performing occupancy prediction of the 3D space in the\nenvironment, the ability and robustness of scene understanding can be\neffectively improved. However, existing occupancy prediction tasks are\nprimarily modeled using voxel or point cloud-based approaches: voxel-based\nnetwork structures often suffer from the loss of spatial information due to the\nvoxelization process, while point cloud-based methods, although better at\nretaining spatial location information, face limitations in representing\nvolumetric structural details. To address this issue, we propose a dual-modal\nprediction method based on 3D Gaussian sets and sparse points, which balances\nboth spatial location and volumetric structural information, achieving higher\naccuracy in semantic occupancy prediction. Specifically, our method adopts a\nTransformer-based architecture, taking 3D Gaussian sets, sparse points, and\nqueries as inputs. Through the multi-layer structure of the Transformer, the\nenhanced queries and 3D Gaussian sets jointly contribute to the semantic\noccupancy prediction, and an adaptive fusion mechanism integrates the semantic\noutputs of both modalities to generate the final prediction results.\nAdditionally, to further improve accuracy, we dynamically refine the point\ncloud at each layer, allowing for more precise location information during\noccupancy prediction. We conducted experiments on the Occ3DnuScenes dataset,\nand the experimental results demonstrate superior performance of the proposed\nmethod on IoU based metrics.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.09941v1",
    "published_date": "2025-03-13 01:35:04 UTC",
    "updated_date": "2025-03-13 01:35:04 UTC"
  },
  {
    "arxiv_id": "2503.09927v1",
    "title": "Developing and Evaluating an AI-Assisted Prediction Model for Unplanned Intensive Care Admissions following Elective Neurosurgery using Natural Language Processing within an Electronic Healthcare Record System",
    "authors": [
      "Julia Ive",
      "Olatomiwa Olukoya",
      "Jonathan P. Funnell",
      "James Booker",
      "Sze H M Lam",
      "Ugan Reddy",
      "Kawsar Noor",
      "Richard JB Dobson",
      "Astri M. V. Luoma",
      "Hani J Marcus"
    ],
    "abstract": "Introduction: Timely care in a specialised neuro-intensive therapy unit (ITU)\nreduces mortality and hospital stays, with planned admissions being safer than\nunplanned ones. However, post-operative care decisions remain subjective. This\nstudy used artificial intelligence (AI), specifically natural language\nprocessing (NLP) to analyse electronic health records (EHRs) and predict ITU\nadmissions for elective surgery patients. Methods: This study analysed the EHRs\nof elective neurosurgery patients from University College London Hospital\n(UCLH) using NLP. Patients were categorised into planned high dependency unit\n(HDU) or ITU admission; unplanned HDU or ITU admission; or ward / overnight\nrecovery (ONR). The Medical Concept Annotation Tool (MedCAT) was used to\nidentify SNOMED-CT concepts within the clinical notes. We then explored the\nutility of these identified concepts for a range of AI algorithms trained to\npredict ITU admission. Results: The CogStack-MedCAT NLP model, initially\ntrained on hospital-wide EHRs, underwent two refinements: first with data from\npatients with Normal Pressure Hydrocephalus (NPH) and then with data from\nVestibular Schwannoma (VS) patients, achieving a concept detection F1-score of\n0.93. This refined model was then used to extract concepts from EHR notes of\n2,268 eligible neurosurgical patients. We integrated the extracted concepts\ninto AI models, including a decision tree model and a neural time-series model.\nUsing the simpler decision tree model, we achieved a recall of 0.87 (CI 0.82 -\n0.91) for ITU admissions, reducing the proportion of unplanned ITU cases missed\nby human experts from 36% to 4%. Conclusion: The NLP model, refined for\naccuracy, has proven its efficiency in extracting relevant concepts, providing\na reliable basis for predictive AI models to use in clinically valid\napplications.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.09927v1",
    "published_date": "2025-03-13 00:48:48 UTC",
    "updated_date": "2025-03-13 00:48:48 UTC"
  },
  {
    "arxiv_id": "2503.09910v1",
    "title": "eXpLogic: Explaining Logic Types and Patterns in DiffLogic Networks",
    "authors": [
      "Stephen Wormald",
      "David Koblah",
      "Matheus Kunzler Maldaner",
      "Domenic Forte",
      "Damon L. Woodard"
    ],
    "abstract": "Constraining deep neural networks (DNNs) to learn individual logic types per\nnode, as performed using the DiffLogic network architecture, opens the door to\nmodel-specific explanation techniques that quell the complexity inherent to\nDNNs. Inspired by principles of circuit analysis from computer engineering,\nthis work presents an algorithm (eXpLogic) for producing saliency maps which\nexplain input patterns that activate certain functions. The eXpLogic\nexplanations: (1) show the exact set of inputs responsible for a decision,\nwhich helps interpret false negative and false positive predictions, (2)\nhighlight common input patterns that activate certain outputs, and (3) help\nreduce the network size to improve class-specific inference. To evaluate the\neXpLogic saliency map, we introduce a metric that quantifies how much an input\nchanges before switching a model's class prediction (the SwitchDist) and use\nthis metric to compare eXpLogic against the Vanilla Gradients (VG) and\nIntegrated Gradient (IG) methods. Generally, we show that eXpLogic saliency\nmaps are better at predicting which inputs will change the class score. These\nmaps help reduce the network size and inference times by 87\\% and 8\\%,\nrespectively, while having a limited impact (-3.8\\%) on class-specific\npredictions. The broader value of this work to machine learning is in\ndemonstrating how certain DNN architectures promote explainability, which is\nrelevant to healthcare, defense, and law.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Conference submission, 6 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.09910v1",
    "published_date": "2025-03-13 00:01:36 UTC",
    "updated_date": "2025-03-13 00:01:36 UTC"
  }
]