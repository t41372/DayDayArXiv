{
  "date": "2025-02-22",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-02-22 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦于 AI 安全、LLM 推理优化、多模态模型可解释性和机器学习理论等领域，重点包括多模态基础模型的机制解释调查（论文 7，由 Soheil Feizi 等知名学者发布）、LLM 后门攻击基准（论文 38）和神经网络理论差距分析（论文 11，由 Mikhail Belkin），这些工作突显了 AI 模型的鲁棒性和可解释性挑战，具有高话题度。\n\n### 重点论文讨论\n- **论文 7: A Survey on Mechanistic Interpretability for Multi-Modal Foundation Models（多模态基础模型机制可解释性调查）**  \n  这篇调查论文由一组学者（如 Soheil Feizi）主导，系统梳理了多模态模型（如视觉-语言模型）的可解释性方法，强调了从单模态到多模态的机制差异，并提出结构化分类和研究空白，帮助领域内更好地理解和优化模型。\n\n- **论文 11: A Gap Between the Gaussian RKHS and Neural Networks: An Infinite-Center Asymptotic Analysis（高斯 RKHS 与神经网络的差距：无限中心渐进分析）**  \n  Mikhail Belkin 等作者证明了某些高斯 RKHS 函数在神经网络 Banach 空间中具有无限范数，揭示了核方法在某些场景下优于神经网络的核心理论差距，为模型选择提供新见解。\n\n- **论文 5: A generative approach to LLM harmfulness detection with special red flag tokens（使用特殊红旗标记的 LLM 危害性检测生成方法）**  \n  该方法引入红旗标记来检测和缓解 LLM 生成有害内容，保持模型效用并提升对攻击的鲁棒性，主要贡献是转变 LLM 为生成式分类器，实验显示其在对话中有效减少相关风险。\n\n- **论文 34: Dynamic Parallel Tree Search for Efficient LLM Reasoning（动态并行树搜索用于高效 LLM 推理）**  \n  论文提出 DPTS 框架，通过并行优化和动态路径选择提升 LLM 推理效率，实验在数学基准上实现 2-4 倍加速，同时维持准确性，适用于复杂任务。\n\n- **论文 38: ELBA-Bench: An Efficient Learning Backdoor Attacks Benchmark for Large Language Models（ELBA-Bench：用于 LLM 的高效后门攻击学习基准）**  \n  这是一个全面基准，包含 12 种攻击方法和 18 个数据集，用于评估 LLM 后门攻击，关键发现是 PEFT 攻击在分类任务中更具泛化性，并提供工具推动后门研究。\n\n- **论文 39: A Comprehensive Survey of Machine Unlearning Techniques for Large Language Models（大规模语言模型机器遗忘技术的全面调查）**  \n  调查总结了 LLM 的机器遗忘方法，分类了技术优势和局限，并讨论未来方向，如数据隐私保护，强调遗忘在动态环境中的重要性。\n\n### 其他相关论文简评\n其余论文覆盖广泛，以下快速概述部分有代表性的：\n- **论文 1: Understanding Fixed Predictions via Confined Regions（理解固定预测通过受限区域）** 和 **论文 13: Direct Alignment with Heterogeneous Preferences（直接对齐异质偏好）**：前者使用 ReVer 方法识别机器学习模型的固定预测区域，后者探讨偏好异质性对齐，均提升了模型鲁棒性。\n- **论文 2: Auto-ADMET: An Effective and Interpretable AutoML Method for Chemical ADMET Property Prediction（Auto-ADMET：用于化学 ADMET 属性预测的有效可解释 AutoML 方法）**：提出基于遗传编程的 AutoML 方法，提高药物发现的预测性能。\n- **论文 3: Does Your AI Agent Get You? A Personalizable Framework for Approximating Human Models from Argumentation-based Dialogue Traces（你的 AI 代理了解你吗？基于论证对话痕迹的人类模型近似个性化框架）**：Persona 框架使用前景理论和贝叶斯更新适应人类信念，提升 AI 交互个性化。\n- **论文 8: A Multi-Agent Framework for Automated Vulnerability Detection and Repair in Solidity and Move Smart Contracts（用于 Solidity 和 Move 智能合约自动漏洞检测和修复的多代理框架）**：Smartify 框架利用 LLM 代理检测修复区块链漏洞，超越现有方法。\n- **论文 61: PlanGEN: A Multi-Agent Framework for Generating Planning and Reasoning Trajectories（PlanGEN：用于生成规划和推理轨迹的多代理框架）**：优化复杂任务推理，实验显示在多基准上提升性能。\n- 其他如 **论文 72: Exploring AI Writers（探索 AI 作家）** 等更基础或应用导向的论文，如药物发现、情感生成等，贡献在于实践改进，但影响力较小，故从简。\n\n今天的论文整体反映了 AI 社区对模型安全和效率的持续关注，建议读者关注多模态和 LLM 相关工作，以跟上前沿动态。更多细节可查阅 arXiv。",
  "papers": [
    {
      "arxiv_id": "2502.16380v1",
      "title": "Understanding Fixed Predictions via Confined Regions",
      "title_zh": "翻译失败",
      "authors": [
        "Connor Lawless",
        "Tsui-Wei Weng",
        "Berk Ustun",
        "Madeleine Udell"
      ],
      "abstract": "Machine learning models are designed to predict outcomes using features about\nan individual, but fail to take into account how individuals can change them.\nConsequently, models can assign fixed predictions that deny individuals\nrecourse to change their outcome. This work develops a new paradigm to identify\nfixed predictions by finding confined regions in which all individuals receive\nfixed predictions. We introduce the first method, ReVer, for this task, using\ntools from mixed-integer quadratically constrained programming. Our approach\ncertifies recourse for out-of-sample data, provides interpretable descriptions\nof confined regions, and runs in seconds on real world datasets. We conduct a\ncomprehensive empirical study of confined regions across diverse applications.\nOur results highlight that existing point-wise verification methods fail to\ndiscover confined regions, while ReVer provably succeeds.",
      "tldr_zh": "本文研究了机器学习模型在预测时忽略个体特征变化的问题，导致固定预测（fixed predictions）剥夺了补救机会。论文提出一个新范式，通过识别受限区域（confined regions）来发现这些固定预测，并引入首个方法 ReVer，利用混合整数二次约束规划（mixed-integer quadratically constrained programming）工具进行分析。ReVer 能够为样本外数据认证补救（certifies recourse）、提供受限区域的可解释描述，并在真实数据集上快速运行（几秒钟）。实证研究显示，在多样应用中，ReVer 成功发现受限区域，而现有点-wise 验证方法失败。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.16380v1",
      "published_date": "2025-02-22 23:06:10 UTC",
      "updated_date": "2025-02-22 23:06:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:19:32.478148"
    },
    {
      "arxiv_id": "2502.16378v1",
      "title": "Auto-ADMET: An Effective and Interpretable AutoML Method for Chemical ADMET Property Prediction",
      "title_zh": "Auto-ADMET：一种有效且可解释的AutoML方法，用于化学ADMET属性预测",
      "authors": [
        "Alex G. C. de Sá",
        "David B. Ascher"
      ],
      "abstract": "Machine learning (ML) has been playing important roles in drug discovery in\nthe past years by providing (pre-)screening tools for prioritising chemical\ncompounds to pass through wet lab experiments. One of the main ML tasks in drug\ndiscovery is to build quantitative structure-activity relationship (QSAR)\nmodels, associating the molecular structure of chemical compounds with an\nactivity or property. These properties -- including absorption, distribution,\nmetabolism, excretion and toxicity (ADMET) -- are essential to model compound\nbehaviour, activity and interactions in the organism. Although several methods\nexist, the majority of them do not provide an appropriate model's\npersonalisation, yielding to bias and lack of generalisation to new data since\nthe chemical space usually shifts from application to application. This fact\nleads to low predictive performance when completely new data is being tested by\nthe model. The area of Automated Machine Learning (AutoML) emerged aiming to\nsolve this issue, outputting tailored ML algorithms to the data at hand.\nAlthough an important task, AutoML has not been practically used to assist\ncheminformatics and computational chemistry researchers often, with just a few\nworks related to the field. To address these challenges, this work introduces\nAuto-ADMET, an interpretable evolutionary-based AutoML method for chemical\nADMET property prediction. Auto-ADMET employs a Grammar-based Genetic\nProgramming (GGP) method with a Bayesian Network Model to achieve comparable or\nbetter predictive performance against three alternative methods -- standard GGP\nmethod, pkCSM and XGBOOST model -- on 12 benchmark chemical ADMET property\nprediction datasets. The use of a Bayesian Network model on Auto-ADMET's\nevolutionary process assisted in both shaping the search procedure and\ninterpreting the causes of its AutoML performance.",
      "tldr_zh": "本研究提出 Auto-ADMET，一种有效的可解释 AutoML 方法，用于预测化学 ADMET 属性，从而解决传统 QSAR 模型在药物发现中的偏差和泛化问题。Auto-ADMET 采用 Grammar-based Genetic Programming (GGP) 结合 Bayesian Network Model 来优化演化过程，确保模型的个性化与可解释性。在 12 个基准数据集上的实验显示，Auto-ADMET 的预测性能优于或相当于是标准 GGP、pkCSM 和 XGBoost 模型。该方法为 cheminformatics 和计算化学领域提供了一个实用工具，提升了化学化合物的筛选效率。",
      "categories": [
        "q-bio.BM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.BM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.16378v1",
      "published_date": "2025-02-22 22:54:08 UTC",
      "updated_date": "2025-02-22 22:54:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:19:45.468195"
    },
    {
      "arxiv_id": "2502.16376v1",
      "title": "Does Your AI Agent Get You? A Personalizable Framework for Approximating Human Models from Argumentation-based Dialogue Traces",
      "title_zh": "翻译失败",
      "authors": [
        "Yinxu Tang",
        "Stylianos Loukas Vasileiou",
        "William Yeoh"
      ],
      "abstract": "Explainable AI is increasingly employing argumentation methods to facilitate\ninteractive explanations between AI agents and human users. While existing\napproaches typically rely on predetermined human user models, there remains a\ncritical gap in dynamically learning and updating these models during\ninteractions. In this paper, we present a framework that enables AI agents to\nadapt their understanding of human users through argumentation-based dialogues.\nOur approach, called Persona, draws on prospect theory and integrates a\nprobability weighting function with a Bayesian belief update mechanism that\nrefines a probability distribution over possible human models based on\nexchanged arguments. Through empirical evaluations with human users in an\napplied argumentation setting, we demonstrate that Persona effectively captures\nevolving human beliefs, facilitates personalized interactions, and outperforms\nstate-of-the-art methods.",
      "tldr_zh": "本研究提出Persona框架，用于AI代理通过基于论证（argumentation-based）的对话动态学习和更新人类用户模型，解决现有方法的静态局限性。该框架整合了前景理论（prospect theory）、概率加权函数（probability weighting function）和贝叶斯信念更新机制（Bayesian belief update mechanism），以基于交换的论证细化人类模型的概率分布，从而实现个性化互动。通过与人类用户的实证评估，Persona证明了其在捕捉演变的人类信念方面有效，并优于现有先进方法（state-of-the-art methods）。",
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.16376v1",
      "published_date": "2025-02-22 22:37:16 UTC",
      "updated_date": "2025-02-22 22:37:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:19:56.933009"
    },
    {
      "arxiv_id": "2502.16375v1",
      "title": "Personhood Credentials: Human-Centered Design Recommendation Balancing Security, Usability, and Trust",
      "title_zh": "人身凭证：平衡安全、可用性和信任的以人为本设计推荐",
      "authors": [
        "Ayae Ide",
        "Tanusree Sharma"
      ],
      "abstract": "Building on related concepts, like, decentralized identifiers (DIDs), proof\nof personhood, anonymous credentials, personhood credentials (PHCs) emerged as\nan alternative approach, enabling individuals to verify to digital service\nproviders that they are a person without disclosing additional information.\nHowever, new technologies might introduce some friction due to users\nmisunderstandings and mismatched expectations. Despite their growing\nimportance, limited research has been done on users perceptions and preferences\nregarding PHCs. To address this gap, we conducted competitive analysis, and\nsemi-structured online user interviews with 23 participants from US and EU to\nprovide concrete design recommendations for PHCs that incorporate user needs,\nadoption rules, and preferences. Our study -- (a)surfaces how people reason\nabout unknown privacy and security guarantees of PHCs compared to current\nverification methods -- (b) presents the impact of several factors on how\npeople would like to onboard and manage PHCs, including, trusted issuers (e.g.\ngov), ground truth data to issue PHC (e.g biometrics, physical id), and\nissuance system (e.g. centralized vs decentralized). In a think-aloud\nconceptual design session, participants recommended -- conceptualized design,\nsuch as periodic biometrics verification, time-bound credentials, visually\ninteractive human-check, and supervision of government for issuance system. We\npropose actionable designs reflecting users preferences.",
      "tldr_zh": "该研究探讨了 Personhood Credentials (PHCs)，一种基于 decentralized identifiers (DIDs) 和 proof of personhood 的技术，允许用户向数字服务提供者证明自身真实性而不泄露额外信息，同时平衡安全、可用性和信任。研究通过竞争分析和对23名美国和欧盟参与者的半结构化在线访谈，分析了用户对PHCs的感知和偏好，包括与当前验证方法的隐私与安全比较。访谈揭示了影响PHCs注册和管理的关键因素，如可信发行者（例如政府）、基础数据（例如biometrics或物理ID），以及发行系统（centralized vs decentralized）。最终，论文基于用户建议提出可行动设计推荐，包括定期biometrics验证、时间限制凭证、可视化互动人机检查，以及政府监督发行系统，以提升用户采用和信任。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CY",
        "cs.HC"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.16375v1",
      "published_date": "2025-02-22 22:33:00 UTC",
      "updated_date": "2025-02-22 22:33:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:20:10.724656"
    },
    {
      "arxiv_id": "2502.16366v2",
      "title": "A generative approach to LLM harmfulness detection with special red flag tokens",
      "title_zh": "翻译失败",
      "authors": [
        "Sophie Xhonneux",
        "David Dobre",
        "Mehrnaz Mofakhami",
        "Leo Schwinn",
        "Gauthier Gidel"
      ],
      "abstract": "Most safety training methods for large language models (LLMs) based on\nfine-tuning rely on dramatically changing the output distribution of the model\nwhen faced with a harmful request, shifting it from an unsafe answer to a\nrefusal to respond. These methods inherently compromise model capabilities and\nmight make auto-regressive models vulnerable to attacks that make likely an\ninitial token of affirmative response. To avoid that, we propose to expand the\nmodel's vocabulary with a special token we call red flag token (<rf>) and\npropose to fine-tune the model to generate this token at any time harmful\ncontent is generated or about to be generated. This novel safety training\nmethod effectively augments LLMs into generative classifiers of harmfulness at\nall times during the conversation. This method offers several advantages: it\nenables the model to explicitly learn the concept of harmfulness while\nmarginally affecting the generated distribution, thus maintaining the model's\nutility. It also evaluates each generated answer rather than just the input\nprompt and provides a stronger defence against sampling-based attacks. In\naddition, it simplifies the evaluation of the model's robustness and reduces\ncorrelated failures when combined with a classifier. We further show an\nincreased robustness to long contexts, and supervised fine-tuning attacks.",
      "tldr_zh": "本研究提出了一种生成式方法，用于检测大型语言模型(LLM)的有害内容，核心是通过在模型词汇表中添加特殊 red flag token (<rf>)，并微调模型使其在生成或即将生成有害内容时输出该标记。\n这种方法将LLM转化为实时生成式有害内容分类器，能够评估每个生成的答案，而非仅限于输入提示，从而显式学习有害概念并最小化对模型输出分布的影响。\n相比传统微调方法，该方法增强了对基于采样的攻击、长上下文和监督微调攻击的鲁棒性，同时简化了模型鲁棒性评估和减少相关失败。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "13 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.16366v2",
      "published_date": "2025-02-22 21:48:48 UTC",
      "updated_date": "2025-03-05 20:31:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:20:21.506361"
    },
    {
      "arxiv_id": "2502.16359v1",
      "title": "Audio Visual Segmentation Through Text Embeddings",
      "title_zh": "基于文本嵌入的音频视觉分割",
      "authors": [
        "Kyungbok Lee",
        "You Zhang",
        "Zhiyao Duan"
      ],
      "abstract": "The goal of Audio-Visual Segmentation (AVS) is to localize and segment the\nsounding source objects from the video frames. Researchers working on AVS\nsuffer from limited datasets because hand-crafted annotation is expensive.\nRecent works attempt to overcome the challenge of limited data by leveraging\nthe segmentation foundation model, SAM, prompting it with audio to enhance its\nability to segment sounding source objects. While this approach alleviates the\nmodel's burden on understanding visual modality by utilizing pre-trained\nknowledge of SAM, it does not address the fundamental challenge of the limited\ndataset for learning audio-visual relationships. To address these limitations,\nwe propose \\textbf{AV2T-SAM}, a novel framework that bridges audio features\nwith the text embedding space of pre-trained text-prompted SAM. Our method\nleverages multimodal correspondence learned from rich text-image paired\ndatasets to enhance audio-visual alignment. Furthermore, we introduce a novel\nfeature, $\\mathbf{\\textit{\\textbf{f}}_{CLIP} \\odot\n\\textit{\\textbf{f}}_{CLAP}}$, which emphasizes shared semantics of audio and\nvisual modalities while filtering irrelevant noise. Experiments on the AVSBench\ndataset demonstrate state-of-the-art performance on both datasets of AVSBench.\nOur approach outperforms existing methods by effectively utilizing pretrained\nsegmentation models and cross-modal semantic alignment.",
      "tldr_zh": "本文提出AV2T-SAM框架，用于解决Audio-Visual Segmentation (AVS)中数据集有限的问题，该框架通过桥接音频特征与预训练文本提示SAM的文本嵌入空间，利用丰富的文本-图像配对数据集增强音频-视觉对齐。创新点包括引入$\\mathbf{\\textit{\\textbf{f}}_{CLIP} \\odot \\textit{\\textbf{f}}_{CLAP}$特征，该特征强调音频和视觉模态的共享语义同时过滤无关噪音，从而提高分割准确性。在AVSBench数据集上的实验显示，AV2T-SAM超越现有方法，实现了最先进性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.16359v1",
      "published_date": "2025-02-22 21:15:44 UTC",
      "updated_date": "2025-02-22 21:15:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:20:32.841737"
    },
    {
      "arxiv_id": "2502.17516v1",
      "title": "A Survey on Mechanistic Interpretability for Multi-Modal Foundation Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zihao Lin",
        "Samyadeep Basu",
        "Mohammad Beigi",
        "Varun Manjunatha",
        "Ryan A. Rossi",
        "Zichao Wang",
        "Yufan Zhou",
        "Sriram Balasubramanian",
        "Arman Zarei",
        "Keivan Rezaei",
        "Ying Shen",
        "Barry Menglong Yao",
        "Zhiyang Xu",
        "Qin Liu",
        "Yuxiang Zhang",
        "Yan Sun",
        "Shilong Liu",
        "Li Shen",
        "Hongxuan Li",
        "Soheil Feizi",
        "Lifu Huang"
      ],
      "abstract": "The rise of foundation models has transformed machine learning research,\nprompting efforts to uncover their inner workings and develop more efficient\nand reliable applications for better control. While significant progress has\nbeen made in interpreting Large Language Models (LLMs), multimodal foundation\nmodels (MMFMs) - such as contrastive vision-language models, generative\nvision-language models, and text-to-image models - pose unique interpretability\nchallenges beyond unimodal frameworks. Despite initial studies, a substantial\ngap remains between the interpretability of LLMs and MMFMs. This survey\nexplores two key aspects: (1) the adaptation of LLM interpretability methods to\nmultimodal models and (2) understanding the mechanistic differences between\nunimodal language models and crossmodal systems. By systematically reviewing\ncurrent MMFM analysis techniques, we propose a structured taxonomy of\ninterpretability methods, compare insights across unimodal and multimodal\narchitectures, and highlight critical research gaps.",
      "tldr_zh": "这篇调查论文探讨了多模态基础模型（MMFMs）的机制解释性（Mechanistic Interpretability），强调了基础模型兴起后，对其内部机制的解读需求。尽管Large Language Models (LLMs) 在解释性方面取得了显著进展，但MMFMs（如对比视觉语言模型和生成式模型）带来了独特的挑战。论文系统回顾了将LLM解释方法适应到多模态框架的策略，并比较了单模态语言模型与跨模态系统的机制差异，同时提出了一种结构化的解释性方法分类，并指出了关键的研究空白，以推动更可靠的多模态应用发展。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "30 pages, 4 Figures, 10 Tables",
      "pdf_url": "http://arxiv.org/pdf/2502.17516v1",
      "published_date": "2025-02-22 20:55:26 UTC",
      "updated_date": "2025-02-22 20:55:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:20:43.878022"
    },
    {
      "arxiv_id": "2502.18515v1",
      "title": "A Multi-Agent Framework for Automated Vulnerability Detection and Repair in Solidity and Move Smart Contracts",
      "title_zh": "用于 Solidity 和 Move 智能合约的自动漏洞检测和修复的多智能体框架",
      "authors": [
        "Rabimba Karanjai",
        "Sam Blackshear",
        "Lei Xu",
        "Weidong Shi"
      ],
      "abstract": "The rapid growth of the blockchain ecosystem and the increasing value locked\nin smart contracts necessitate robust security measures. While languages like\nSolidity and Move aim to improve smart contract security, vulnerabilities\npersist. This paper presents Smartify, a novel multi-agent framework leveraging\nLarge Language Models (LLMs) to automatically detect and repair vulnerabilities\nin Solidity and Move smart contracts. Unlike traditional methods that rely\nsolely on vast pre-training datasets, Smartify employs a team of specialized\nagents working on different specially fine-tuned LLMs to analyze code based on\nunderlying programming concepts and language-specific security principles. We\nevaluated Smartify on a dataset for Solidity and a curated dataset for Move,\ndemonstrating its effectiveness in fixing a wide range of vulnerabilities. Our\nresults show that Smartify (Gemma2+codegemma) achieves state-of-the-art\nperformance, surpassing existing LLMs and enhancing general-purpose models'\ncapabilities, such as Llama 3.1. Notably, Smartify can incorporate\nlanguage-specific knowledge, such as the nuances of Move, without requiring\nmassive language-specific pre-training datasets. This work offers a detailed\nanalysis of various LLMs' performance on smart contract repair, highlighting\nthe strengths of our multi-agent approach and providing a blueprint for\ndeveloping more secure and reliable decentralized applications in the growing\nblockchain landscape. We also provide a detailed recipe for extending this to\nother similar use cases.",
      "tldr_zh": "本研究提出了一种多智能体框架Smartify，利用Large Language Models (LLMs)自动检测和修复Solidity和Move智能合约中的漏洞，以应对区块链生态的安全挑战。该框架由专门微调的LLMs团队组成，每个智能体基于编程概念和语言特定安全原则分析代码，从而超越传统依赖大规模预训练数据集的方法。在评估中，Smartify (Gemma2+codegemma) 在Solidity和Move数据集上实现了最先进性能，比现有LLMs如Llama 3.1更出色，并能整合语言特定知识而不需额外预训练，提供了一个扩展到其他区块链用例的蓝图。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.MA",
        "cs.SE"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.18515v1",
      "published_date": "2025-02-22 20:30:47 UTC",
      "updated_date": "2025-02-22 20:30:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:20:56.260869"
    },
    {
      "arxiv_id": "2502.16344v1",
      "title": "Machine Learning-Based Cloud Computing Compliance Process Automation",
      "title_zh": "基于机器学习的云计算合规过程自动化",
      "authors": [
        "Yuqing Wang",
        "Xiao Yang"
      ],
      "abstract": "Cloud computing adoption across industries has revolutionized enterprise\noperations while introducing significant challenges in compliance management.\nOrganizations must continuously meet evolving regulatory requirements such as\nGDPR and ISO 27001, yet traditional manual review processes have become\nincreasingly inadequate for modern business scales. This paper presents a novel\nmachine learning-based framework for automating cloud computing compliance\nprocesses, addressing critical challenges including resource-intensive manual\nreviews, extended compliance cycles, and delayed risk identification. Our\nproposed framework integrates multiple machine learning technologies, including\nBERT-based document processing (94.5% accuracy), One-Class SVM for anomaly\ndetection (88.7% accuracy), and an improved CNN-LSTM architecture for\nsequential compliance data analysis (90.2% accuracy). Implementation results\ndemonstrate significant improvements: reducing compliance process duration from\n7 days to 1.5 days, improving accuracy from 78% to 93%, and decreasing manual\neffort by 73.3%. A real-world deployment at a major securities firm validated\nthese results, processing 800,000 daily transactions with 94.2% accuracy in\nrisk identification.",
      "tldr_zh": "该论文针对云计算合规管理面临的挑战（如符合GDPR和ISO 27001的监管要求），提出了一种基于机器学习的框架来自动化合规过程，旨在解决手动审查耗时和风险识别延迟等问题。该框架整合了BERT-based document processing（准确率94.5%）、One-Class SVM for anomaly detection（准确率88.7%）以及改进的CNN-LSTM architecture for sequential compliance data analysis（准确率90.2%）等多项技术。实验结果显示，该框架将合规过程时间从7天缩短至1.5天，准确率从78%提升至93%，并减少了73.3%的手动努力；在实际部署中，一家大型证券公司处理80万日常交易时，风险识别准确率达到94.2%。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.16344v1",
      "published_date": "2025-02-22 20:18:21 UTC",
      "updated_date": "2025-02-22 20:18:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:21:07.310854"
    },
    {
      "arxiv_id": "2502.16343v1",
      "title": "Exploring Sentiment Manipulation by LLM-Enabled Intelligent Trading Agents",
      "title_zh": "探索LLM-启用的智能交易代理的情感操纵",
      "authors": [
        "David Byrd"
      ],
      "abstract": "Companies across all economic sectors continue to deploy large language\nmodels at a rapid pace. Reinforcement learning is experiencing a resurgence of\ninterest due to its association with the fine-tuning of language models from\nhuman feedback. Tool-chain language models control task-specific agents; if the\nconverse has not already appeared, it soon will. In this paper, we present what\nwe believe is the first investigation of an intelligent trading agent based on\ncontinuous deep reinforcement learning that also controls a large language\nmodel with which it can post to a social media feed observed by other traders.\nWe empirically investigate the performance and impact of such an agent in a\nsimulated financial market, finding that it learns to optimize its total\nreward, and thereby augment its profit, by manipulating the sentiment of the\nposts it produces. The paper concludes with discussion, limitations, and\nsuggestions for future work.",
      "tldr_zh": "这篇论文探讨了大型语言模型(LLMs)赋能的智能交易代理如何通过操纵情感来优化收益，首次调查了基于连续深度强化学习(Deep Reinforcement Learning)的代理，它能控制LLM在社交媒体上发布帖子以影响其他交易者。具体方法包括在模拟金融市场中进行实证实验，结果显示代理学会了通过生成情感化内容来提升总回报和利润。论文还讨论了研究限制及未来工作建议。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE",
        "cs.MA"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.16343v1",
      "published_date": "2025-02-22 20:17:14 UTC",
      "updated_date": "2025-02-22 20:17:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:21:19.229166"
    },
    {
      "arxiv_id": "2502.16331v1",
      "title": "A Gap Between the Gaussian RKHS and Neural Networks: An Infinite-Center Asymptotic Analysis",
      "title_zh": "高斯 RKHS 与神经网络之间的差距：无限中心渐近分析",
      "authors": [
        "Akash Kumar",
        "Rahul Parhi",
        "Mikhail Belkin"
      ],
      "abstract": "Recent works have characterized the function-space inductive bias of\ninfinite-width bounded-norm single-hidden-layer neural networks as a kind of\nbounded-variation-type space. This novel neural network Banach space\nencompasses many classical multivariate function spaces including certain\nSobolev spaces and the spectral Barron spaces. Notably, this Banach space also\nincludes functions that exhibit less classical regularity such as those that\nonly vary in a few directions. On bounded domains, it is well-established that\nthe Gaussian reproducing kernel Hilbert space (RKHS) strictly embeds into this\nBanach space, demonstrating a clear gap between the Gaussian RKHS and the\nneural network Banach space. It turns out that when investigating these spaces\non unbounded domains, e.g., all of $\\mathbb{R}^d$, the story is fundamentally\ndifferent. We establish the following fundamental result: Certain functions\nthat lie in the Gaussian RKHS have infinite norm in the neural network Banach\nspace. This provides a nontrivial gap between kernel methods and neural\nnetworks by the exhibition of functions in which kernel methods can do strictly\nbetter than neural networks.",
      "tldr_zh": "本研究通过 infinite-center asymptotic analysis 分析了 Gaussian RKHS 和神经网络 Banach 空间之间的差距，指出无限宽度的单隐藏层神经网络函数空间是一种边界变差类型空间，包括 Sobolev 空间和 spectral Barron 空间等经典多变量函数空间。研究发现，在有界域上 Gaussian RKHS 严格嵌入该 Banach 空间，但在无界域（如 \\(\\mathbb{R}^d\\)) 上，某些 Gaussian RKHS 中的函数在神经网络 Banach 空间中具有 infinite norm，这表明内核方法在处理这些函数时严格优于神经网络。主要贡献在于揭示了这一非平凡差距，强调了神经网络在函数空间表示方面的局限性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "22 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2502.16331v1",
      "published_date": "2025-02-22 19:33:19 UTC",
      "updated_date": "2025-02-22 19:33:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:21:32.744166"
    },
    {
      "arxiv_id": "2502.16324v1",
      "title": "Deep Time Warping for Multiple Time Series Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Alireza Nourbakhsh",
        "Hoda Mohammadzade"
      ],
      "abstract": "Time Series Alignment is a critical task in signal processing with numerous\nreal-world applications. In practice, signals often exhibit temporal shifts and\nscaling, making classification on raw data prone to errors. This paper\nintroduces a novel approach for Multiple Time Series Alignment (MTSA)\nleveraging Deep Learning techniques. While most existing methods primarily\naddress Multiple Sequence Alignment (MSA) for protein and DNA sequences, there\nremains a significant gap in alignment methodologies for numerical time series.\nAdditionally, conventional approaches typically focus on pairwise alignment,\nwhereas our proposed method aligns all signals in a multiple manner (all the\nsignals are aligned together at once). This innovation not only enhances\nalignment efficiency but also significantly improves computational speed. By\ndecomposing into piece-wise linear sections, we introduce varying levels of\ncomplexity into the warping function. Additionally, our method ensures the\nsatisfaction of three warping constraints: boundary, monotonicity, and\ncontinuity conditions. The utilization of a deep convolutional network allows\nus to employ a new loss function, addressing some limitations of Dynamic Time\nWarping (DTW). Experimental results on the UCR Archive 2018, comprising 129\ntime series datasets, demonstrate that employing our approach to align signals\nsignificantly enhances classification accuracy and warping average and also\nreduces the run time across the majority of these datasets.",
      "tldr_zh": "本论文提出了一种名为Deep Time Warping的创新方法，用于多个时间序列对齐（Multiple Time Series Alignment），以解决信号处理中时间偏移和缩放导致的分类错误问题。该方法利用深度学习技术，特别是深度卷积网络，将时间序列分解为分段线性部分，并引入可变复杂度的扭曲函数，同时满足边界、单调性和连续性约束，从而克服了Dynamic Time Warping (DTW)的局限性。实验结果显示，在UCR Archive 2018的129个数据集上，该方法显著提高了分类准确率和扭曲平均值，同时降低了运行时间。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "32 pages, 13 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.16324v1",
      "published_date": "2025-02-22 18:55:51 UTC",
      "updated_date": "2025-02-22 18:55:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:21:42.736743"
    },
    {
      "arxiv_id": "2502.16320v1",
      "title": "Direct Alignment with Heterogeneous Preferences",
      "title_zh": "直接对齐异质偏好",
      "authors": [
        "Ali Shirali",
        "Arash Nasr-Esfahany",
        "Abdullah Alomar",
        "Parsa Mirtaheri",
        "Rediet Abebe",
        "Ariel Procaccia"
      ],
      "abstract": "Alignment with human preferences is commonly framed using a universal reward\nfunction, even though human preferences are inherently heterogeneous. We\nformalize this heterogeneity by introducing user types and examine the limits\nof the homogeneity assumption. We show that aligning to heterogeneous\npreferences with a single policy is best achieved using the average reward\nacross user types. However, this requires additional information about\nannotators. We examine improvements under different information settings,\nfocusing on direct alignment methods. We find that minimal information can\nyield first-order improvements, while full feedback from each user type leads\nto consistent learning of the optimal policy. Surprisingly, however, no\nsample-efficient consistent direct loss exists in this latter setting. These\nresults reveal a fundamental tension between consistency and sample efficiency\nin direct policy alignment.",
      "tldr_zh": "该论文探讨了在直接对齐方法中处理异质偏好（heterogeneous preferences）的挑战，强调人类偏好并非统一，而是由不同用户类型（user types）组成。研究表明，使用单一策略对齐异质偏好时，最佳方法是采用用户类型间的平均奖励（average reward），但这需要额外的信息支持。在不同信息设置下，论文发现最小信息即可实现一阶改进（first-order improvements），而完全反馈（full feedback）能学习最优策略（optimal policy），但缺乏样本高效的一致直接损失（sample-efficient consistent direct loss）。总体上，这揭示了直接策略对齐（direct policy alignment）中，一致性和样本效率之间的根本张力（fundamental tension）。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.16320v1",
      "published_date": "2025-02-22 18:46:33 UTC",
      "updated_date": "2025-02-22 18:46:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:21:59.680968"
    },
    {
      "arxiv_id": "2502.16312v1",
      "title": "Iterative Auto-Annotation for Scientific Named Entity Recognition Using BERT-Based Models",
      "title_zh": "基于BERT模型的科学命名实体识别迭代自动标注",
      "authors": [
        "Kartik Gupta"
      ],
      "abstract": "This paper presents an iterative approach to performing Scientific Named\nEntity Recognition (SciNER) using BERT-based models. We leverage transfer\nlearning to fine-tune pretrained models with a small but high-quality set of\nmanually annotated data. The process is iteratively refined by using the\nfine-tuned model to auto-annotate a larger dataset, followed by additional\nrounds of fine-tuning. We evaluated two models, dslim/bert-large-NER and\nbert-largecased, and found that bert-large-cased consistently outperformed the\nformer. Our approach demonstrated significant improvements in prediction\naccuracy and F1 scores, especially for less common entity classes. Future work\ncould include pertaining with unlabeled data, exploring more powerful encoders\nlike RoBERTa, and expanding the scope of manual annotations. This methodology\nhas broader applications in NLP tasks where access to labeled data is limited.",
      "tldr_zh": "这篇论文提出了一种迭代自动标注方法，用于 Scientific Named Entity Recognition (SciNER)，通过转移学习对 BERT-based 模型（如 bert-large-cased）进行微调，并利用一小部分手动标注数据来启动过程。方法包括使用微调后的模型自动标注更大数据集，随后进行更多轮的微调，显著提高了预测准确性和 F1 scores，尤其是在较少见的实体类别上。实验结果显示，bert-large-cased 模型优于 dslim/bert-large-NER，性能提升明显。该方法适用于标注数据有限的 NLP 任务，并为未来工作如使用无标签数据预训练或探索 RoBERTa 等编码器提供了方向。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages",
      "pdf_url": "http://arxiv.org/pdf/2502.16312v1",
      "published_date": "2025-02-22 17:58:20 UTC",
      "updated_date": "2025-02-22 17:58:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:22:10.238062"
    },
    {
      "arxiv_id": "2502.16299v1",
      "title": "A calibration test for evaluating set-based epistemic uncertainty representations",
      "title_zh": "一种用于评估基于集合的认识不确定性表示的校准测试",
      "authors": [
        "Mira Jürgens",
        "Thomas Mortier",
        "Eyke Hüllermeier",
        "Viktor Bengs",
        "Willem Waegeman"
      ],
      "abstract": "The accurate representation of epistemic uncertainty is a challenging yet\nessential task in machine learning. A widely used representation corresponds to\nconvex sets of probabilistic predictors, also known as credal sets. One popular\nway of constructing these credal sets is via ensembling or specialized\nsupervised learning methods, where the epistemic uncertainty can be quantified\nthrough measures such as the set size or the disagreement among members. In\nprinciple, these sets should contain the true data-generating distribution. As\na necessary condition for this validity, we adopt the strongest notion of\ncalibration as a proxy. Concretely, we propose a novel statistical test to\ndetermine whether there is a convex combination of the set's predictions that\nis calibrated in distribution. In contrast to previous methods, our framework\nallows the convex combination to be instance dependent, recognizing that\ndifferent ensemble members may be better calibrated in different regions of the\ninput space. Moreover, we learn this combination via proper scoring rules,\nwhich inherently optimize for calibration. Building on differentiable,\nkernel-based estimators of calibration errors, we introduce a nonparametric\ntesting procedure and demonstrate the benefits of capturing instance-level\nvariability on of synthetic and real-world experiments.",
      "tldr_zh": "本论文针对机器学习中认识不确定性（epistemic uncertainty）的准确表示问题，提出了一种新的校准测试，用于评估基于凸集（convex sets of probabilistic predictors），也称为credal sets，这些集通常通过ensembling或监督学习方法构建。测试的核心是检查是否存在一个实例相关的convex combination，使集合的预测在分布上校准，并通过proper scoring rules优化学习该组合。实验结果表明，该非参数测试程序（nonparametric testing procedure）在合成和真实世界数据上有效捕捉实例级变异性，提升了不确定性评估的可靠性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.16299v1",
      "published_date": "2025-02-22 17:10:45 UTC",
      "updated_date": "2025-02-22 17:10:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:22:22.423144"
    },
    {
      "arxiv_id": "2502.16294v1",
      "title": "TimePFN: Effective Multivariate Time Series Forecasting with Synthetic Data",
      "title_zh": "翻译失败",
      "authors": [
        "Ege Onur Taga",
        "M. Emrullah Ildiz",
        "Samet Oymak"
      ],
      "abstract": "The diversity of time series applications and scarcity of domain-specific\ndata highlight the need for time-series models with strong few-shot learning\ncapabilities. In this work, we propose a novel training scheme and a\ntransformer-based architecture, collectively referred to as TimePFN, for\nmultivariate time-series (MTS) forecasting. TimePFN is based on the concept of\nPrior-data Fitted Networks (PFN), which aims to approximate Bayesian inference.\nOur approach consists of (1) generating synthetic MTS data through diverse\nGaussian process kernels and the linear coregionalization method, and (2) a\nnovel MTS architecture capable of utilizing both temporal and cross-channel\ndependencies across all input patches. We evaluate TimePFN on several benchmark\ndatasets and demonstrate that it outperforms the existing state-of-the-art\nmodels for MTS forecasting in both zero-shot and few-shot settings. Notably,\nfine-tuning TimePFN with as few as 500 data points nearly matches full dataset\ntraining error, and even 50 data points yield competitive results. We also find\nthat TimePFN exhibits strong univariate forecasting performance, attesting to\nits generalization ability. Overall, this work unlocks the power of synthetic\ndata priors for MTS forecasting and facilitates strong zero- and few-shot\nforecasting performance.",
      "tldr_zh": "这篇论文提出了 TimePFN，一种基于 Transformer 的新型架构和训练方案，用于多元时间序列 (MTS) 预测，通过合成数据增强 few-shot 学习能力。方法包括利用多样化的 Gaussian process kernels 和 linear coregionalization 生成合成 MTS 数据，以及设计一个能捕捉时间和跨通道依赖的架构，以近似 Bayesian inference。实验结果显示，TimePFN 在多个基准数据集上，在 zero-shot 和 few-shot 设置中优于现有最先进模型，仅需 500 个数据点微调即可接近完整数据集的性能，甚至 50 个数据点也能取得竞争性结果，证明了其强大的泛化能力和合成数据先验的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "To appear in AAAI-2025 as a conference paper",
      "pdf_url": "http://arxiv.org/pdf/2502.16294v1",
      "published_date": "2025-02-22 16:55:14 UTC",
      "updated_date": "2025-02-22 16:55:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:22:35.271394"
    },
    {
      "arxiv_id": "2502.16291v2",
      "title": "The Design Space of Recent AI-assisted Research Tools for Ideation, Sensemaking, and Scientific Creativity",
      "title_zh": "翻译失败",
      "authors": [
        "Runlong Ye",
        "Matthew Varona",
        "Oliver Huang",
        "Patrick Yung Kang Lee",
        "Michael Liut",
        "Carolina Nobre"
      ],
      "abstract": "Generative AI (GenAI) tools are radically expanding the scope and capability\nof automation in knowledge work such as academic research. While promising for\naugmenting cognition and streamlining processes, AI-assisted research tools may\nalso increase automation bias and hinder critical thinking. To examine recent\ndevelopments, we surveyed publications from leading HCI venues over the past\nthree years, closely analyzing thirteen tools to better understand the novel\ncapabilities of these AI-assisted systems and the design spaces they enable:\nseven employing traditional AI or customized transformer-based approaches, and\nsix integrating open-access large language models (LLMs). Our analysis\ncharacterizes the emerging design space, distinguishes between tools focused on\nworkflow mimicry versus generative exploration, and yields four critical design\nrecommendations to guide the development of future systems that foster\nmeaningful cognitive engagement: providing user agency and control,\ndifferentiating divergent/convergent thinking support, ensuring adaptability,\nand prioritizing transparency/accuracy. This work discusses how these insights\nsignal a shift from mere workflow replication towards generative co-creation,\npresenting new opportunities for the community to craft intuitive, AI-driven\nresearch interfaces and interactions.",
      "tldr_zh": "这篇论文调查了过去三年 HCI 领域的出版物，分析了13个 AI 辅助研究工具（包括七个使用传统 AI 或自定义 transformer 的系统，以及六个整合开源 LLMs 的系统），以探讨这些工具在创意构想、意义构建和科学创新方面的能力。研究区分了关注工作流程模仿与生成式探索的工具，并表征了新兴设计空间。作者提出了四个关键设计推荐：提供用户代理和控制、区分发散/收敛思考支持、确保适应性，以及优先透明度和准确性，以促进有意义的认知参与，并推动从工作流程复制向生成式共同创建的转变。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "H.5.2"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.16291v2",
      "published_date": "2025-02-22 16:42:11 UTC",
      "updated_date": "2025-04-19 21:15:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:22:46.611485"
    },
    {
      "arxiv_id": "2502.16286v1",
      "title": "Verification of Bit-Flip Attacks against Quantized Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Yedi Zhang",
        "Lei Huang",
        "Pengfei Gao",
        "Fu Song",
        "Jun Sun",
        "Jin Song Dong"
      ],
      "abstract": "In the rapidly evolving landscape of neural network security, the resilience\nof neural networks against bit-flip attacks (i.e., an attacker maliciously\nflips an extremely small amount of bits within its parameter storage memory\nsystem to induce harmful behavior), has emerged as a relevant area of research.\nExisting studies suggest that quantization may serve as a viable defense\nagainst such attacks. Recognizing the documented susceptibility of real-valued\nneural networks to such attacks and the comparative robustness of quantized\nneural networks (QNNs), in this work, we introduce BFAVerifier, the first\nverification framework designed to formally verify the absence of bit-flip\nattacks or to identify all vulnerable parameters in a sound and rigorous\nmanner. BFAVerifier comprises two integral components: an abstraction-based\nmethod and an MILP-based method. Specifically, we first conduct a reachability\nanalysis with respect to symbolic parameters that represent the potential\nbit-flip attacks, based on a novel abstract domain with a sound guarantee. If\nthe reachability analysis fails to prove the resilience of such attacks, then\nwe encode this verification problem into an equivalent MILP problem which can\nbe solved by off-the-shelf solvers. Therefore, BFAVerifier is sound, complete,\nand reasonably efficient. We conduct extensive experiments, which demonstrate\nits effectiveness and efficiency across various network architectures,\nquantization bit-widths, and adversary capabilities.",
      "tldr_zh": "这篇论文针对量化神经网络(QNNs)对位翻转攻击的验证，引入了首个正式验证框架BFAVerifier，用于严格证明网络的抗攻击性或识别所有易受攻击的参数。BFAVerifier结合了基于抽象的方法进行符号参数的可达性分析，以及MILP-based方法将问题编码为混合整数线性规划问题，以确保验证过程的可靠性和完整性。实验结果显示，该框架在多种网络架构、量化位宽和攻击场景下表现出高效性和有效性，证明了量化作为位翻转攻击防御的可行性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "37 pages, 13 figures, 14 tables",
      "pdf_url": "http://arxiv.org/pdf/2502.16286v1",
      "published_date": "2025-02-22 16:35:38 UTC",
      "updated_date": "2025-02-22 16:35:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:22:58.543024"
    },
    {
      "arxiv_id": "2502.16284v1",
      "title": "MolSpectra: Pre-training 3D Molecular Representation with Multi-modal Energy Spectra",
      "title_zh": "MolSpectra: 利用多模态能量谱预训练三维分子表示",
      "authors": [
        "Liang Wang",
        "Shaozhen Liu",
        "Yu Rong",
        "Deli Zhao",
        "Qiang Liu",
        "Shu Wu",
        "Liang Wang"
      ],
      "abstract": "Establishing the relationship between 3D structures and the energy states of\nmolecular systems has proven to be a promising approach for learning 3D\nmolecular representations. However, existing methods are limited to modeling\nthe molecular energy states from classical mechanics. This limitation results\nin a significant oversight of quantum mechanical effects, such as quantized\n(discrete) energy level structures, which offer a more accurate estimation of\nmolecular energy and can be experimentally measured through energy spectra. In\nthis paper, we propose to utilize the energy spectra to enhance the\npre-training of 3D molecular representations (MolSpectra), thereby infusing the\nknowledge of quantum mechanics into the molecular representations.\nSpecifically, we propose SpecFormer, a multi-spectrum encoder for encoding\nmolecular spectra via masked patch reconstruction. By further aligning outputs\nfrom the 3D encoder and spectrum encoder using a contrastive objective, we\nenhance the 3D encoder's understanding of molecules. Evaluations on public\nbenchmarks reveal that our pre-trained representations surpass existing methods\nin predicting molecular properties and modeling dynamics.",
      "tldr_zh": "本文提出 MolSpectra 方法，利用多模态能量谱（energy spectra）增强 3D 分子表示的预训练，从而融入量子力学知识，解决现有方法仅依赖经典力学建模的局限性。具体地，该方法引入 SpecFormer 编码器，通过 masked patch reconstruction 处理分子谱，并采用 contrastive objective 对齐 3D 编码器和谱编码器的输出，提升分子理解能力。在公共基准测试中，MolSpectra 在分子属性预测和动态建模方面超越了现有方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE",
        "physics.chem-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.16284v1",
      "published_date": "2025-02-22 16:34:32 UTC",
      "updated_date": "2025-02-22 16:34:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:23:09.227447"
    },
    {
      "arxiv_id": "2502.16282v1",
      "title": "Understanding the Emergence of Multimodal Representation Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Megan Tjandrasuwita",
        "Chanakya Ekbote",
        "Liu Ziyin",
        "Paul Pu Liang"
      ],
      "abstract": "Multimodal representation learning is fundamentally about transforming\nincomparable modalities into comparable representations. While prior research\nprimarily focused on explicitly aligning these representations through targeted\nlearning objectives and model architectures, a recent line of work has found\nthat independently trained unimodal models of increasing scale and performance\ncan become implicitly aligned with each other. These findings raise fundamental\nquestions regarding the emergence of aligned representations in multimodal\nlearning. Specifically: (1) when and why does alignment emerge implicitly? and\n(2) is alignment a reliable indicator of performance? Through a comprehensive\nempirical investigation, we demonstrate that both the emergence of alignment\nand its relationship with task performance depend on several critical data\ncharacteristics. These include, but are not necessarily limited to, the degree\nof similarity between the modalities and the balance between redundant and\nunique information they provide for the task. Our findings suggest that\nalignment may not be universally beneficial; rather, its impact on performance\nvaries depending on the dataset and task. These insights can help practitioners\ndetermine whether increasing alignment between modalities is advantageous or,\nin some cases, detrimental to achieving optimal performance. Code is released\nat https://github.com/MeganTj/multimodal_alignment.",
      "tldr_zh": "这篇论文探讨了多模态表示学习（multimodal representation learning）中表示对齐的出现机制，重点分析独立训练的单模态模型（unimodal models）在规模和性能提升时如何实现隐式对齐（implicitly aligned）。通过全面实证调查（empirical investigation），作者发现对齐的出现及其与任务性能的关系取决于数据特性，如模态间的相似度、冗余信息和唯一信息的平衡。研究结论表明，对齐并非普遍有益，其对性能的影响因数据集和任务而异，可能在某些情况下反而有害；这些见解可指导从业者决定是否追求模态对齐。代码已在 https://github.com/MeganTj/multimodal_alignment 发布。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "21 pages, 22 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2502.16282v1",
      "published_date": "2025-02-22 16:27:31 UTC",
      "updated_date": "2025-02-22 16:27:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:23:22.409689"
    },
    {
      "arxiv_id": "2502.16280v1",
      "title": "Human Preferences in Large Language Model Latent Space: A Technical Analysis on the Reliability of Synthetic Data in Voting Outcome Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Sarah Ball",
        "Simeon Allmendinger",
        "Frauke Kreuter",
        "Niklas Kühl"
      ],
      "abstract": "Generative AI (GenAI) is increasingly used in survey contexts to simulate\nhuman preferences. While many research endeavors evaluate the quality of\nsynthetic GenAI data by comparing model-generated responses to gold-standard\nsurvey results, fundamental questions about the validity and reliability of\nusing LLMs as substitutes for human respondents remain. Our study provides a\ntechnical analysis of how demographic attributes and prompt variations\ninfluence latent opinion mappings in large language models (LLMs) and evaluates\ntheir suitability for survey-based predictions. Using 14 different models, we\nfind that LLM-generated data fails to replicate the variance observed in\nreal-world human responses, particularly across demographic subgroups. In the\npolitical space, persona-to-party mappings exhibit limited differentiation,\nresulting in synthetic data that lacks the nuanced distribution of opinions\nfound in survey data. Moreover, we show that prompt sensitivity can\nsignificantly alter outputs for some models, further undermining the stability\nand predictiveness of LLM-based simulations. As a key contribution, we adapt a\nprobe-based methodology that reveals how LLMs encode political affiliations in\ntheir latent space, exposing the systematic distortions introduced by these\nmodels. Our findings highlight critical limitations in AI-generated survey\ndata, urging caution in its use for public opinion research, social science\nexperimentation, and computational behavioral modeling.",
      "tldr_zh": "该研究对大型语言模型（LLMs）在模拟人类偏好方面的可靠性进行了技术分析，重点评估合成数据在预测投票结果中的适用性。研究使用14个不同模型发现，LLM生成的数据无法复制真实人类响应的方差，尤其在人口统计子群中，且persona-to-party mappings显示有限差异，导致合成数据缺少真实意见的细微分布。此外，prompt sensitivity会显著影响某些模型的输出，暴露了系统性扭曲；作为关键贡献，论文适应了基于探针的方法，揭示LLMs在潜在空间中如何编码政治affiliation，并警告在公共意见研究、社会科学实验和计算行为建模中使用AI生成数据的潜在风险。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.16280v1",
      "published_date": "2025-02-22 16:25:33 UTC",
      "updated_date": "2025-02-22 16:25:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:23:37.143064"
    },
    {
      "arxiv_id": "2502.16279v1",
      "title": "Beyond Trusting Trust: Multi-Model Validation for Robust Code Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Bradley McDanel"
      ],
      "abstract": "This paper explores the parallels between Thompson's \"Reflections on Trusting\nTrust\" and modern challenges in LLM-based code generation. We examine how\nThompson's insights about compiler backdoors take on new relevance in the era\nof large language models, where the mechanisms for potential exploitation are\neven more opaque and difficult to analyze. Building on this analogy, we discuss\nhow the statistical nature of LLMs creates novel security challenges in code\ngeneration pipelines. As a potential direction forward, we propose an\nensemble-based validation approach that leverages multiple independent models\nto detect anomalous code patterns through cross-model consensus. This\nperspective piece aims to spark discussion about trust and validation in\nAI-assisted software development.",
      "tldr_zh": "这篇论文将Ken Thompson的\"Reflections on Trusting Trust\"类比于LLM-based代码生成中的现代挑战，探讨LLM的统计性质如何导致更不透明的安全风险，如潜在的代码生成漏洞。作者提出一种ensemble-based validation方法，利用多个独立模型通过跨模型共识检测异常代码模式，以增强代码生成的鲁棒性。该视角文章旨在激发关于AI-assisted软件开发中信任和验证机制的讨论。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.SE",
      "comment": "3 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.16279v1",
      "published_date": "2025-02-22 16:24:23 UTC",
      "updated_date": "2025-02-22 16:24:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:23:47.294936"
    },
    {
      "arxiv_id": "2502.18512v1",
      "title": "FCoT-VL:Advancing Text-oriented Large Vision-Language Models with Efficient Visual Token Compression",
      "title_zh": "翻译失败",
      "authors": [
        "Jianjian Li",
        "Junquan Fan",
        "Feng Tang",
        "Gang Huang",
        "Shitao Zhu",
        "Songlin Liu",
        "Nian Xie",
        "Wulong Liu",
        "Yong Liao"
      ],
      "abstract": "The rapid success of Vision Large Language Models (VLLMs) often depends on\nthe high-resolution images with abundant visual tokens, which hinders training\nand deployment efficiency. Current training-free visual token compression\nmethods exhibit serious performance degradation in tasks involving\nhigh-resolution, text-oriented image understanding and reasoning. In this\npaper, we propose an efficient visual token compression framework for\ntext-oriented VLLMs in high-resolution scenarios. In particular, we employ a\nlight-weight self-distillation pre-training stage to compress the visual\ntokens, requiring a limited numbers of image-text pairs and minimal learnable\nparameters. Afterwards, to mitigate potential performance degradation of\ntoken-compressed models, we construct a high-quality post-train stage. To\nvalidate the effectiveness of our method, we apply it to an advanced VLLMs,\nInternVL2. Experimental results show that our approach significantly reduces\ncomputational overhead while outperforming the baselines across a range of\ntext-oriented benchmarks. We will release the models and code soon.",
      "tldr_zh": "本研究提出 FCoT-VL 框架，用于提升文本导向的 Vision Large Language Models (VLLMs) 在高分辨率场景下的效率，通过高效的 visual token compression 解决训练和部署的计算开销问题。框架包括一个轻量级的 self-distillation 预训练阶段，仅需少量图像-文本对和最小可学习参数来压缩视觉标记，随后通过高质量的后训练阶段缓解性能下降。实验结果显示，在先进的 VLLMs InternVL2 上应用后，该方法显著减少计算开销，并在多种文本导向基准测试中超越基线模型。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "20 pages, 18 figures, 6 tables",
      "pdf_url": "http://arxiv.org/pdf/2502.18512v1",
      "published_date": "2025-02-22 16:05:33 UTC",
      "updated_date": "2025-02-22 16:05:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:23:58.589560"
    },
    {
      "arxiv_id": "2502.16274v1",
      "title": "Fine-Tuning Qwen 2.5 3B for Realistic Movie Dialogue Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Kartik Gupta"
      ],
      "abstract": "The Qwen 2.5 3B base model was fine-tuned to generate contextually rich and\nengaging movie dialogue, leveraging the Cornell Movie-Dialog Corpus, a curated\ndataset of movie conversations. Due to the limitations in GPU computing and\nVRAM, the training process began with the 0.5B model progressively scaling up\nto the 1.5B and 3B versions as efficiency improvements were implemented. The\nQwen 2.5 series, developed by Alibaba Group, stands at the forefront of small\nopen-source pre-trained models, particularly excelling in creative tasks\ncompared to alternatives like Meta's Llama 3.2 and Google's Gemma. Results\ndemonstrate the ability of small models to produce high-quality, realistic\ndialogue, offering a promising approach for real-time, context-sensitive\nconversation generation.",
      "tldr_zh": "本研究对 Qwen 2.5 3B 基模型进行微调，利用 Cornell Movie-Dialog Corpus 数据集，旨在生成上下文丰富的真实电影对话。训练过程因 GPU 和 VRAM 限制，从 0.5B 模型逐步扩展到 1.5B 和 3B 版本，确保效率优化。结果表明，该小型开源模型在创意任务上优于 Llama 3.2 和 Gemma，能产生高质量的对话，为实时上下文敏感的对话生成提供有前景的方法。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "5 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.16274v1",
      "published_date": "2025-02-22 16:00:01 UTC",
      "updated_date": "2025-02-22 16:00:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:24:11.426480"
    },
    {
      "arxiv_id": "2502.16255v1",
      "title": "rECGnition_v2.0: Self-Attentive Canonical Fusion of ECG and Patient Data using deep learning for effective Cardiac Diagnostics",
      "title_zh": "翻译失败",
      "authors": [
        "Shreya Srivastava",
        "Durgesh Kumar",
        "Ram Jiwari",
        "Sandeep Seth",
        "Deepak Sharma"
      ],
      "abstract": "The variability in ECG readings influenced by individual patient\ncharacteristics has posed a considerable challenge to adopting automated ECG\nanalysis in clinical settings. A novel feature fusion technique termed SACC\n(Self Attentive Canonical Correlation) was proposed to address this. This\ntechnique is combined with DPN (Dual Pathway Network) and depth-wise separable\nconvolution to create a robust, interpretable, and fast end-to-end arrhythmia\nclassification model named rECGnition_v2.0 (robust ECG abnormality detection).\nThis study uses MIT-BIH, INCARTDB and EDB dataset to evaluate the efficiency of\nrECGnition_v2.0 for various classes of arrhythmias. To investigate the\ninfluence of constituting model components, various ablation studies were\nperformed, i.e. simple concatenation, CCA and proposed SACC were compared,\nwhile the importance of global and local ECG features were tested using DPN\nrECGnition_v2.0 model and vice versa. It was also benchmarked with\nstate-of-the-art CNN models for overall accuracy vs model parameters, FLOPs,\nmemory requirements, and prediction time. Furthermore, the inner working of the\nmodel was interpreted by comparing the activation locations in ECG before and\nafter the SACC layer. rECGnition_v2.0 showed a remarkable accuracy of 98.07%\nand an F1-score of 98.05% for classifying ten distinct classes of arrhythmia\nwith just 82.7M FLOPs per sample, thereby going beyond the performance metrics\nof current state-of-the-art (SOTA) models by utilizing MIT-BIH Arrhythmia\ndataset. Similarly, on INCARTDB and EDB datasets, excellent F1-scores of 98.01%\nand 96.21% respectively was achieved for AAMI classification. The compact\narchitectural footprint of the rECGnition_v2.0, characterized by its lesser\ntrainable parameters and diminished computational demands, unfurled several\nadvantages including interpretability and scalability.",
      "tldr_zh": "该研究提出了一种名为 rECGnition_v2.0 的深度学习模型，用于有效的心脏诊断，通过融合 ECG 和患者数据来解决 ECG 读取变异性带来的挑战。核心创新是 SACC (Self Attentive Canonical Correlation) 特征融合技术，结合 DPN (Dual Pathway Network) 和 depth-wise separable convolution，构建了一个鲁棒、可解释且高效的端到端心律失常分类系统。实验使用 MIT-BIH、INCARTDB 和 EDB 数据集进行评估，结果显示 rECGnition_v2.0 在 MIT-BIH 数据集上达到 98.07% 准确率和 98.05% F1-score，并优于现有 SOTA CNN 模型。消融研究和基准测试进一步证明了 SACC 的有效性，以及模型在参数量（82.7M FLOPs）和计算需求上的优势，提升了可解释性和可扩展性。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.16255v1",
      "published_date": "2025-02-22 15:16:46 UTC",
      "updated_date": "2025-02-22 15:16:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:24:24.233132"
    },
    {
      "arxiv_id": "2503.02889v1",
      "title": "Function-Coherent Gambles with Non-Additive Sequential Dynamics",
      "title_zh": "翻译失败",
      "authors": [
        "Gregory Wheeler"
      ],
      "abstract": "The desirable gambles framework provides a rigorous foundation for imprecise\nprobability theory but relies heavily on linear utility via its coherence\naxioms. In our related work, we introduced function-coherent gambles to\naccommodate non-linear utility. However, when repeated gambles are played over\ntime -- especially in intertemporal choice where rewards compound\nmultiplicatively -- the standard additive combination axiom fails to capture\nthe appropriate long-run evaluation. In this paper we extend the framework by\nrelaxing the additive combination axiom and introducing a nonlinear combination\noperator that effectively aggregates repeated gambles in the log-domain. This\noperator preserves the time-average (geometric) growth rate and addresses the\nergodicity problem. We prove the key algebraic properties of the operator,\ndiscuss its impact on coherence, risk assessment, and representation, and\nprovide a series of illustrative examples. Our approach bridges the gap between\nexpectation values and time averages and unifies normative theory with\nempirically observed non-stationary reward dynamics.",
      "tldr_zh": "本研究扩展了 desirable gambles 框架，引入 function-coherent gambles 以处理非线性效用问题，尤其针对重复赌博和跨时间选择中的乘法性奖励复合。作者放松了 additive combination axiom，提出一个非线性组合操作符，在 log-domain 中聚合赌博，从而保留时间平均（geometric）增长率并解决 ergodicity 问题。该方法证明了操作符的关键代数属性，讨论了其对 coherence、风险评估和表示的影响，并通过示例桥接了期望值与时间平均，统一了规范理论与观察到的非平稳奖励动态。",
      "categories": [
        "econ.TH",
        "cs.AI",
        "cs.CE",
        "math.PR"
      ],
      "primary_category": "econ.TH",
      "comment": "10 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2503.02889v1",
      "published_date": "2025-02-22 14:58:20 UTC",
      "updated_date": "2025-02-22 14:58:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:24:36.606778"
    },
    {
      "arxiv_id": "2502.17515v1",
      "title": "Towards User-level Private Reinforcement Learning with Human Feedback",
      "title_zh": "面向用户级隐私的强化学习与人类反馈",
      "authors": [
        "Jiaming Zhang",
        "Mingxi Lei",
        "Meng Ding",
        "Mengdi Li",
        "Zihang Xiang",
        "Difei Xu",
        "Jinhui Xu",
        "Di Wang"
      ],
      "abstract": "Reinforcement Learning with Human Feedback (RLHF) has emerged as an\ninfluential technique, enabling the alignment of large language models (LLMs)\nwith human preferences. Despite the promising potential of RLHF, how to protect\nuser preference privacy has become a crucial issue. Most previous work has\nfocused on using differential privacy (DP) to protect the privacy of individual\ndata. However, they have concentrated primarily on item-level privacy\nprotection and have unsatisfactory performance for user-level privacy, which is\nmore common in RLHF. This study proposes a novel framework, AUP-RLHF, which\nintegrates user-level label DP into RLHF. We first show that the classical\nrandom response algorithm, which achieves an acceptable performance in\nitem-level privacy, leads to suboptimal utility when in the user-level\nsettings. We then establish a lower bound for the user-level label DP-RLHF and\ndevelop the AUP-RLHF algorithm, which guarantees $(\\varepsilon, \\delta)$\nuser-level privacy and achieves an improved estimation error. Experimental\nresults show that AUP-RLHF outperforms existing baseline methods in sentiment\ngeneration and summarization tasks, achieving a better privacy-utility\ntrade-off.",
      "tldr_zh": "该研究针对强化学习与人类反馈（RLHF）中用户偏好隐私保护问题，提出AUP-RLHF框架，将user-level label差分隐私（DP）整合到RLHF中，以弥补现有方法在user-level隐私保护上的不足。\n他们证明了经典random response算法在user-level设置下性能次优，并建立了user-level label DP-RLHF的理论下界，同时开发了AUP-RLHF算法，确保（ε, δ）用户级隐私并降低估计错误。\n实验结果表明，在情感生成和总结任务上，AUP-RLHF比基线方法实现了更好的隐私-效用权衡。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.17515v1",
      "published_date": "2025-02-22 14:57:28 UTC",
      "updated_date": "2025-02-22 14:57:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:24:47.732175"
    },
    {
      "arxiv_id": "2502.16249v1",
      "title": "Linear Attention for Efficient Bidirectional Sequence Modeling",
      "title_zh": "线性注意力用于高效双向序列建模",
      "authors": [
        "Arshia Afzal",
        "Elias Abad Rocamora",
        "Leyla Naz Candogan",
        "Pol Puigdemont",
        "Francesco Tonin",
        "Yongtao Wu",
        "Mahsa Shoaran",
        "Volkan Cevher"
      ],
      "abstract": "Transformers with linear attention enable fast and parallel training.\nMoreover, they can be formulated as Recurrent Neural Networks (RNNs), for\nefficient linear-time inference. While extensively evaluated in causal sequence\nmodeling, they have yet to be extended to the bidirectional setting. This work\nintroduces the LION framework, establishing new theoretical foundations for\nlinear transformers in bidirectional sequence modeling. LION constructs a\nbidirectional RNN equivalent to full Linear Attention. This extends the\nbenefits of linear transformers: parallel training, and efficient inference,\ninto the bidirectional setting. Using LION, we cast three linear transformers\nto their bidirectional form: LION-LIT, the bidirectional variant corresponding\nto (Katharopoulos et al., 2020); LION-D, extending RetNet (Sun et al., 2023);\nand LION-S, a linear transformer with a stable selective mask inspired by\nselectivity of SSMs (Dao & Gu, 2024). Replacing the attention block with LION\n(-LIT, -D, -S) achieves performance on bidirectional tasks that approaches that\nof Transformers and State-Space Models (SSMs), while delivering significant\nimprovements in training speed. Our implementation is available in\nhttp://github.com/LIONS-EPFL/LION.",
      "tldr_zh": "本论文引入 LION 框架，为 Linear Attention 在 bidirectional sequence modeling 中的应用建立了新的理论基础，将线性 Transformer 构建为等价的双向 RNN，实现并行训练和高效线性时间推理。LION 通过扩展现有模型（如 LION-LIT 对应 Katharopoulos et al., 2020；LION-D 基于 RetNet；LION-S 采用稳定选择性掩码），将注意力块替换为这些变体，使其在双向任务上性能接近 Transformers 和 State-Space Models (SSMs)。实验结果显示，使用 LION 显著提高了训练速度，同时保持了高效的推理能力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.16249v1",
      "published_date": "2025-02-22 14:52:17 UTC",
      "updated_date": "2025-02-22 14:52:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:25:00.780130"
    },
    {
      "arxiv_id": "2503.01855v2",
      "title": "Function-coherent gambles",
      "title_zh": "函数相干赌博",
      "authors": [
        "Gregory Wheeler"
      ],
      "abstract": "The desirable gambles framework provides a foundational approach to imprecise\nprobability theory but relies heavily on linear utility assumptions. This paper\nintroduces function-coherent gambles, a generalization that accommodates\nnon-linear utility while preserving essential rationality properties. We\nestablish core axioms for function-coherence and prove a representation theorem\nthat characterizes acceptable gambles through continuous linear functionals.\nThe framework is then applied to analyze various forms of discounting in\nintertemporal choice, including hyperbolic, quasi-hyperbolic, scale-dependent,\nand state-dependent discounting. We demonstrate how these alternatives to\nconstant-rate exponential discounting can be integrated within the\nfunction-coherent framework. This unified treatment provides theoretical\nfoundations for modeling sophisticated patterns of time preference within the\ndesirability paradigm, bridging a gap between normative theory and observed\nbehavior in intertemporal decision-making under genuine uncertainty.",
      "tldr_zh": "本论文引入了 function-coherent gambles，这是一种对 desirable gambles 框架的泛化，允许处理非线性 utility 同时保留理性属性。作者建立了核心公理并证明了 representation theorem，通过 continuous linear functionals 来表征可接受的赌注。该框架应用于分析 intertemporal choice 中的各种折扣形式，包括 hyperbolic discounting、quasi-hyperbolic discounting、scale-dependent discounting 和 state-dependent discounting，提供了一个统一的方法来整合这些替代常速指数折扣的模式。最后，该方法桥接了规范理论与观察到的行为，在不确定性下的跨时决策中奠定了更坚实的理论基础。",
      "categories": [
        "econ.TH",
        "cs.AI",
        "cs.CE",
        "math.PR"
      ],
      "primary_category": "econ.TH",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01855v2",
      "published_date": "2025-02-22 14:44:54 UTC",
      "updated_date": "2025-04-25 06:57:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:25:10.484807"
    },
    {
      "arxiv_id": "2502.16242v1",
      "title": "Reproducibility Study of Cooperation, Competition, and Maliciousness: LLM-Stakeholders Interactive Negotiation",
      "title_zh": "翻译失败",
      "authors": [
        "Jose L. Garcia",
        "Karolina Hajkova",
        "Maria Marchenko",
        "Carlos Miguel Patiño"
      ],
      "abstract": "This paper presents a reproducibility study and extension of \"Cooperation,\nCompetition, and Maliciousness: LLM-Stakeholders Interactive Negotiation.\" We\nvalidate the original findings using a range of open-weight models (1.5B-70B\nparameters) and GPT-4o Mini while introducing several novel contributions. We\nanalyze the Pareto front of the games, propose a communication-free baseline to\ntest whether successful negotiations are possible without agent interaction,\nevaluate recent small language models' performance, analyze structural\ninformation leakage in model responses, and implement an inequality metric to\nassess negotiation fairness. Our results demonstrate that smaller models (<10B\nparameters) struggle with format adherence and coherent responses, but larger\nopen-weight models can approach proprietary model performance. Additionally, in\nmany scenarios, single-agent approaches can achieve comparable results to\nmulti-agent negotiations, challenging assumptions about the necessity of agent\ncommunication to perform well on the benchmark. This work also provides\ninsights into the accessibility, fairness, environmental impact, and privacy\nconsiderations of LLM-based negotiation systems.",
      "tldr_zh": "这篇论文是对“Cooperation, Competition, and Maliciousness: LLM-Stakeholders Interactive Negotiation”的可重复性研究和扩展，使用各种开源模型（1.5B-70B参数）和GPT-4o Mini验证原发现，同时引入新贡献，如分析Pareto front、提出无通信基线、评估小语言模型性能、检测信息泄露和实现不平等度量。研究发现，小型模型（<10B参数）在格式遵守和响应连贯性上存在显著挑战，但大型开源模型能接近专有模型的表现；此外，在许多场景中，单代理方法可与多代理谈判媲美，质疑了代理通信的必要性。该工作还探讨了LLM-based谈判系统的可访问性、公平性、环境影响和隐私问题，提供重要见解。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.16242v1",
      "published_date": "2025-02-22 14:28:49 UTC",
      "updated_date": "2025-02-22 14:28:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:25:25.019237"
    },
    {
      "arxiv_id": "2502.16240v1",
      "title": "Speech Enhancement Using Continuous Embeddings of Neural Audio Codec",
      "title_zh": "使用神经音频编解码器的连续嵌入进行语音增强",
      "authors": [
        "Haoyang Li",
        "Jia Qi Yip",
        "Tianyu Fan",
        "Eng Siong Chng"
      ],
      "abstract": "Recent advancements in Neural Audio Codec (NAC) models have inspired their\nuse in various speech processing tasks, including speech enhancement (SE). In\nthis work, we propose a novel, efficient SE approach by leveraging the\npre-quantization output of a pretrained NAC encoder. Unlike prior NAC-based SE\nmethods, which process discrete speech tokens using Language Models (LMs), we\nperform SE within the continuous embedding space of the pretrained NAC, which\nis highly compressed along the time dimension for efficient representation. Our\nlightweight SE model, optimized through an embedding-level loss, delivers\nresults comparable to SE baselines trained on larger datasets, with a\nsignificantly lower real-time factor of 0.005. Additionally, our method\nachieves a low GMAC of 3.94, reducing complexity 18-fold compared to Sepformer\nin a simulated cloud-based audio transmission environment. This work highlights\na new, efficient NAC-based SE solution, particularly suitable for cloud\napplications where NAC is used to compress audio before transmission.\n  Copyright 20XX IEEE. Personal use of this material is permitted. Permission\nfrom IEEE must be obtained for all other uses, in any current or future media,\nincluding reprinting/republishing this material for advertising or promotional\npurposes, creating new collective works, for resale or redistribution to\nservers or lists, or reuse of any copyrighted component of this work in other\nworks.",
      "tldr_zh": "本研究提出了一种新型语音增强 (SE) 方法，利用预训练 Neural Audio Codec (NAC) 编码器的连续嵌入空间进行处理，避免了传统方法依赖离散令牌和 Language Models (LMs)。该方法通过嵌入级损失优化一个轻量级 SE 模型，实现时间维度的高度压缩，并显著提高了效率。实验结果显示，该模型的性能与在更大数据集上训练的基线相当，实时因子仅为 0.005，且计算复杂度 (GMAC) 比 Sepformer 低 18 倍，特别适用于云端音频传输环境。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.LG",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "Accepted to ICASSP 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.16240v1",
      "published_date": "2025-02-22 14:25:55 UTC",
      "updated_date": "2025-02-22 14:25:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:25:38.944160"
    },
    {
      "arxiv_id": "2502.17514v1",
      "title": "SAE-V: Interpreting Multimodal Models for Enhanced Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Hantao Lou",
        "Changye Li",
        "Jiaming Ji",
        "Yaodong Yang"
      ],
      "abstract": "With the integration of image modality, the semantic space of multimodal\nlarge language models (MLLMs) is more complex than text-only models, making\ntheir interpretability more challenging and their alignment less stable,\nparticularly susceptible to low-quality data, which can lead to inconsistencies\nbetween modalities, hallucinations, and biased outputs. As a result, developing\ninterpretability methods for MLLMs is crucial for improving alignment quality\nand efficiency. In text-only LLMs, Sparse Autoencoders (SAEs) have gained\nattention for their ability to interpret latent representations. However,\nextending SAEs to multimodal settings presents new challenges due to modality\nfusion and the difficulty of isolating cross-modal representations. To address\nthese challenges, we introduce SAE-V, a mechanistic interpretability framework\nthat extends the SAE paradigm to MLLMs. By identifying and analyzing\ninterpretable features along with their corresponding data, SAE-V enables\nfine-grained interpretation of both model behavior and data quality,\nfacilitating a deeper understanding of cross-modal interactions and alignment\ndynamics. Moreover, by utilizing cross-modal feature weighting, SAE-V provides\nan intrinsic data filtering mechanism to enhance model alignment without\nrequiring additional models. Specifically, when applied to the alignment\nprocess of MLLMs, SAE-V-based data filtering methods could achieve more than\n110% performance with less than 50% data. Our results highlight SAE-V's ability\nto enhance interpretability and alignment in MLLMs, providing insights into\ntheir internal mechanisms.",
      "tldr_zh": "该论文提出 SAE-V，一种扩展 Sparse Autoencoders 的机制解释框架，旨在提升多模态大语言模型 (MLLMs) 的解释性和对齐稳定性，以解决模态不一致、幻觉和偏见等问题。SAE-V 通过识别可解释特征、分析跨模态交互以及利用特征加权机制，提供细粒度的模型行为和数据质量解读，同时实现内在数据过滤，无需额外模型。实验结果显示，在 MLLMs 的对齐过程中，SAE-V 基于数据过滤的方法可使用不到 50% 的数据，获得超过 110% 的性能提升，从而加深了对模型内部机制的理解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.17514v1",
      "published_date": "2025-02-22 14:20:07 UTC",
      "updated_date": "2025-02-22 14:20:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:25:52.013307"
    },
    {
      "arxiv_id": "2502.16238v1",
      "title": "Brain-Model Evaluations Need the NeuroAI Turing Test",
      "title_zh": "翻译失败",
      "authors": [
        "Jenelle Feather",
        "Meenakshi Khosla",
        "N. Apurva Ratan Murty",
        "Aran Nayebi"
      ],
      "abstract": "What makes an artificial system a good model of intelligence? The classical\ntest proposed by Alan Turing focuses on behavior, requiring that an artificial\nagent's behavior be indistinguishable from that of a human. While behavioral\nsimilarity provides a strong starting point, two systems with very different\ninternal representations can produce the same outputs. Thus, in modeling\nbiological intelligence, the field of NeuroAI often aims to go beyond\nbehavioral similarity and achieve representational convergence between a\nmodel's activations and the measured activity of a biological system. This\nposition paper argues that the standard definition of the Turing Test is\nincomplete for NeuroAI, and proposes a stronger framework called the ``NeuroAI\nTuring Test'', a benchmark that extends beyond behavior alone and\n\\emph{additionally} requires models to produce internal neural representations\nthat are empirically indistinguishable from those of a brain up to measured\nindividual variability, i.e. the differences between a computational model and\nthe brain is no more than the difference between one brain and another brain.\nWhile the brain is not necessarily the ceiling of intelligence, it remains the\nonly universally agreed-upon example, making it a natural reference point for\nevaluating computational models. By proposing this framework, we aim to shift\nthe discourse from loosely defined notions of brain inspiration to a systematic\nand testable standard centered on both behavior and internal representations,\nproviding a clear benchmark for neuroscientific modeling and AI development.",
      "tldr_zh": "该论文认为，评估人工智能模型作为智力模型的合适性需要超越经典Turing Test的单纯行为相似性，因为不同内部表示可能产生相同输出。作者提出“NeuroAI Turing Test”作为更全面的框架，不仅要求模型的行为与人类不可区分，还需其内部神经表示与大脑活动在可测量的个体变异范围内 empirically indistinguishable。最终，这一标准旨在为神经科学建模和AI开发提供一个系统化的、可测试的基准，促进从模糊的脑启发概念向精确评估的转变。",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "cs.LG",
        "cs.NE"
      ],
      "primary_category": "q-bio.NC",
      "comment": "9 pages, 4 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2502.16238v1",
      "published_date": "2025-02-22 14:16:28 UTC",
      "updated_date": "2025-02-22 14:16:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:26:02.115095"
    },
    {
      "arxiv_id": "2502.16235v2",
      "title": "Dynamic Parallel Tree Search for Efficient LLM Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Yifu Ding",
        "Wentao Jiang",
        "Shunyu Liu",
        "Yongcheng Jing",
        "Jinyang Guo",
        "Yingjie Wang",
        "Jing Zhang",
        "Zengmao Wang",
        "Ziwei Liu",
        "Bo Du",
        "Xianglong Liu",
        "Dacheng Tao"
      ],
      "abstract": "Tree of Thoughts (ToT) enhances Large Language Model (LLM) reasoning by\nstructuring problem-solving as a spanning tree. However, recent methods focus\non search accuracy while overlooking computational efficiency. The challenges\nof accelerating the ToT lie in the frequent switching of reasoning focus, and\nthe redundant exploration of suboptimal solutions. To alleviate this dilemma,\nwe propose Dynamic Parallel Tree Search (DPTS), a novel parallelism framework\nthat aims to dynamically optimize the reasoning path in inference. It includes\nthe Parallelism Streamline in the generation phase to build up a flexible and\nadaptive parallelism with arbitrary paths by fine-grained cache management and\nalignment. Meanwhile, the Search and Transition Mechanism filters potential\ncandidates to dynamically maintain the reasoning focus on more possible\nsolutions and have less redundancy. Experiments on Qwen-2.5 and Llama-3 with\nMath500 and GSM8K datasets show that DPTS significantly improves efficiency by\n2-4x on average while maintaining or even surpassing existing reasoning\nalgorithms in accuracy, making ToT-based reasoning more scalable and\ncomputationally efficient.",
      "tldr_zh": "这篇论文针对 Tree of Thoughts (ToT) 在 Large Language Model (LLM) 推理中的计算效率问题，提出了 Dynamic Parallel Tree Search (DPTS) 框架，以动态优化推理路径。DPTS 包括 Parallelism Streamline，在生成阶段通过细粒度缓存管理和对齐实现灵活的适应性并行；以及 Search and Transition Mechanism，用于过滤潜在候选项，动态维护推理焦点并减少冗余探索。实验在 Qwen-2.5 和 Llama-3 模型上使用 Math500 和 GSM8K 数据集表明，DPTS 平均提高了 2-4 倍的效率，同时保持或超过了现有推理算法的准确性，使 ToT-based 推理更具可扩展性和实用性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "17 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.16235v2",
      "published_date": "2025-02-22 14:13:37 UTC",
      "updated_date": "2025-02-27 06:39:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:26:14.502207"
    },
    {
      "arxiv_id": "2502.16233v1",
      "title": "Graph Self-Supervised Learning with Learnable Structural and Positional Encodings",
      "title_zh": "翻译失败",
      "authors": [
        "Asiri Wijesinghe",
        "Hao Zhu",
        "Piotr Koniusz"
      ],
      "abstract": "Traditional Graph Self-Supervised Learning (GSSL) struggles to capture\ncomplex structural properties well. This limitation stems from two main\nfactors: (1) the inadequacy of conventional Graph Neural Networks (GNNs) in\nrepresenting sophisticated topological features, and (2) the focus of\nself-supervised learning solely on final graph representations. To address\nthese issues, we introduce \\emph{GenHopNet}, a GNN framework that integrates a\n$k$-hop message-passing scheme, enhancing its ability to capture local\nstructural information without explicit substructure extraction. We\ntheoretically demonstrate that \\emph{GenHopNet} surpasses the expressiveness of\nthe classical Weisfeiler-Lehman (WL) test for graph isomorphism. Furthermore,\nwe propose a structural- and positional-aware GSSL framework that incorporates\ntopological information throughout the learning process. This approach enables\nthe learning of representations that are both sensitive to graph topology and\ninvariant to specific structural and feature augmentations. Comprehensive\nexperiments on graph classification datasets, including those designed to test\nstructural sensitivity, show that our method consistently outperforms the\nexisting approaches and maintains computational efficiency. Our work\nsignificantly advances GSSL's capability in distinguishing graphs with similar\nlocal structures but different global topologies.",
      "tldr_zh": "本文研究了传统 Graph Self-Supervised Learning (GSSL) 在捕捉复杂图结构属性上的局限性，包括 Graph Neural Networks (GNNs) 表示不足和学习仅关注最终表示的问题。为此，作者提出 GenHopNet 框架，该框架整合 k-hop message-passing 方案，能更好地捕捉局部结构信息，并理论证明其表现力超过了 Weisfeiler-Lehman (WL) 测试。进一步，他们设计了一种结构和位置感知的 GSSL 框架，将拓扑信息融入整个学习过程，使表示既对图拓扑敏感，又对特定结构和特征增强不变。实验结果显示，该方法在图分类数据集上 consistently outperforms 现有方法，并在计算效率上保持优势，从而显著提升了 GSSL 在区分类似局部结构但不同全局拓扑的图方面的能力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "This paper is accepted by The World Wide Web Conference (WWW) 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.16233v1",
      "published_date": "2025-02-22 14:10:06 UTC",
      "updated_date": "2025-02-22 14:10:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:26:25.687058"
    },
    {
      "arxiv_id": "2502.17513v2",
      "title": "Int2Int: a framework for mathematics with transformers",
      "title_zh": "翻译失败",
      "authors": [
        "François Charton"
      ],
      "abstract": "This paper documents Int2Int, an open source code base for using transformers\non problems of mathematical research, with a focus on number theory and other\nproblems involving integers. Int2Int is a complete PyTorch implementation of a\ntransformer architecture, together with training and evaluation loops, and\nclasses and functions to represent, generate and decode common mathematical\nobjects. Ancillary code for data preparation, and Jupyter Notebooks for\nvisualizing experimental results are also provided. This document presents the\nmain features of Int2Int, serves as its user manual, and provides guidelines on\nhow to extend it. Int2Int is released under the MIT licence, at\nhttps://github.com/f-charton/Int2Int.",
      "tldr_zh": "这篇论文介绍了 Int2Int 框架，这是一个开源工具，用于在数学研究领域（如数论和涉及整数的问题）中应用 transformers。Int2Int 基于 PyTorch 提供完整的 transformer 架构实现，包括训练和评估循环，以及处理数学对象的类和函数，同时附带数据准备代码和 Jupyter Notebooks 用于可视化实验结果。该框架作为用户手册发布，并提供扩展指南，已在 MIT 许可下开源，地址为 https://github.com/f-charton/Int2Int。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MS"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.17513v2",
      "published_date": "2025-02-22 13:43:28 UTC",
      "updated_date": "2025-03-24 19:11:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:26:36.089993"
    },
    {
      "arxiv_id": "2503.04779v3",
      "title": "Can LLMs Reason About Program Semantics? A Comprehensive Evaluation of LLMs on Formal Specification Inference",
      "title_zh": "LLMs 能否推理程序语义？LLMs 在形式规范推断上的全面评估",
      "authors": [
        "Thanh Le-Cong",
        "Bach Le",
        "Toby Murray"
      ],
      "abstract": "Large Language Models (LLMs) are increasingly being used to automate\nprogramming tasks. Yet, LLMs' capabilities in reasoning about program semantics\nare still inadequately studied, leaving significant potential for further\nexploration. This paper introduces FormalBench, a comprehensive benchmark\ndesigned to evaluate LLMs' reasoning abilities on program semantics,\nparticularly via the task of synthesizing formal program specifications to\nassist verifying program correctness. This task requires both comprehensive\nreasoning over all possible program executions and the generation of precise,\nsyntactically correct expressions that adhere to formal syntax and semantics.\nUsing this benchmark, we evaluated the ability of LLMs in synthesizing\nconsistent and complete specifications. Our findings show that LLMs perform\nwell with simple control flows but struggle with more complex structures,\nespecially loops, even with advanced prompting. Additionally, LLMs exhibit\nlimited robustness against semantic-preserving transformations. We also\nhighlight common failure patterns and design self-repair prompts, improving\nsuccess rates by 25%.",
      "tldr_zh": "本文评估了大型语言模型 (LLMs) 在程序语义推理方面的能力，引入了 FormalBench 基准，通过合成正式程序规范的任务来测试 LLMs 对程序执行的全面推理和精确表达式生成。结果显示，LLMs 在简单控制流上表现良好，但对复杂结构如循环和语义保持转换缺乏鲁棒性，导致常见失败模式。研究还设计了自修复提示，成功率提高了 25%，为理解和提升 LLMs 在编程任务中的可靠性提供了重要洞见。",
      "categories": [
        "cs.PL",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.PL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04779v3",
      "published_date": "2025-02-22 13:27:31 UTC",
      "updated_date": "2025-03-15 10:45:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:26:50.012927"
    },
    {
      "arxiv_id": "2502.18511v1",
      "title": "ELBA-Bench: An Efficient Learning Backdoor Attacks Benchmark for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Xuxu Liu",
        "Siyuan Liang",
        "Mengya Han",
        "Yong Luo",
        "Aishan Liu",
        "Xiantao Cai",
        "Zheng He",
        "Dacheng Tao"
      ],
      "abstract": "Generative large language models are crucial in natural language processing,\nbut they are vulnerable to backdoor attacks, where subtle triggers compromise\ntheir behavior. Although backdoor attacks against LLMs are constantly emerging,\nexisting benchmarks remain limited in terms of sufficient coverage of attack,\nmetric system integrity, backdoor attack alignment. And existing pre-trained\nbackdoor attacks are idealized in practice due to resource access constraints.\nTherefore we establish $\\textit{ELBA-Bench}$, a comprehensive and unified\nframework that allows attackers to inject backdoor through parameter efficient\nfine-tuning ($\\textit{e.g.,}$ LoRA) or without fine-tuning techniques\n($\\textit{e.g.,}$ In-context-learning). $\\textit{ELBA-Bench}$ provides over\n1300 experiments encompassing the implementations of 12 attack methods, 18\ndatasets, and 12 LLMs. Extensive experiments provide new invaluable findings\ninto the strengths and limitations of various attack strategies. For instance,\nPEFT attack consistently outperform without fine-tuning approaches in\nclassification tasks while showing strong cross-dataset generalization with\noptimized triggers boosting robustness; Task-relevant backdoor optimization\ntechniques or attack prompts along with clean and adversarial demonstrations\ncan enhance backdoor attack success while preserving model performance on clean\nsamples. Additionally, we introduce a universal toolbox designed for\nstandardized backdoor attack research, with the goal of propelling further\nprogress in this vital area.",
      "tldr_zh": "该论文引入了 ELBA-Bench，这是一个全面的基准框架，用于评估大语言模型（LLMs）对后门攻击（backdoor attacks）的漏洞。ELBA-Bench 支持通过参数高效微调（如 LoRA）或无需微调（如 In-context-learning）注入后门，涵盖了 12 种攻击方法、18 个数据集和 12 个 LLMs，总计超过 1300 个实验。研究发现，PEFT 攻击在分类任务中表现优于无需微调方法，并通过优化触发器提升了跨数据集泛化能力和鲁棒性，同时任务相关优化技术能增强攻击成功率而不影响模型在干净样本上的性能。该框架还提供了一个通用工具箱，促进后门攻击研究的标准化和进一步发展。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.18511v1",
      "published_date": "2025-02-22 12:55:28 UTC",
      "updated_date": "2025-02-22 12:55:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:27:02.989194"
    },
    {
      "arxiv_id": "2503.01854v1",
      "title": "A Comprehensive Survey of Machine Unlearning Techniques for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jiahui Geng",
        "Qing Li",
        "Herbert Woisetschlaeger",
        "Zongxiong Chen",
        "Yuxia Wang",
        "Preslav Nakov",
        "Hans-Arno Jacobsen",
        "Fakhri Karray"
      ],
      "abstract": "This study investigates the machine unlearning techniques within the context\nof large language models (LLMs), referred to as \\textit{LLM unlearning}. LLM\nunlearning offers a principled approach to removing the influence of\nundesirable data (e.g., sensitive or illegal information) from LLMs, while\npreserving their overall utility without requiring full retraining. Despite\ngrowing research interest, there is no comprehensive survey that systematically\norganizes existing work and distills key insights; here, we aim to bridge this\ngap. We begin by introducing the definition and the paradigms of LLM\nunlearning, followed by a comprehensive taxonomy of existing unlearning\nstudies. Next, we categorize current unlearning approaches, summarizing their\nstrengths and limitations. Additionally, we review evaluation metrics and\nbenchmarks, providing a structured overview of current assessment\nmethodologies. Finally, we outline promising directions for future research,\nhighlighting key challenges and opportunities in the field.",
      "tldr_zh": "这篇论文对大型语言模型(LLMs)的机器遗忘技术(LLM unlearning)进行了全面调查，旨在通过移除不 desirable 数据（如敏感或非法信息）的影响，同时保持模型的整体效用，而无需进行完整重新训练。论文首先定义了LLM unlearning的范式，并建立了现有研究的全面分类和方法总结，包括各方法的优势与局限性。随后，它回顾了评估指标和基准，并概述了未来研究方向，如关键挑战和机会。总之，该调查填补了该领域的文献空白，为LLM unlearning的研究提供了系统化的见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01854v1",
      "published_date": "2025-02-22 12:46:14 UTC",
      "updated_date": "2025-02-22 12:46:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:27:13.760194"
    },
    {
      "arxiv_id": "2502.16214v2",
      "title": "SalM$^{2}$: An Extremely Lightweight Saliency Mamba Model for Real-Time Cognitive Awareness of Driver Attention",
      "title_zh": "翻译失败",
      "authors": [
        "Chunyu Zhao",
        "Wentao Mu",
        "Xian Zhou",
        "Wenbo Liu",
        "Fei Yan",
        "Tao Deng"
      ],
      "abstract": "Driver attention recognition in driving scenarios is a popular direction in\ntraffic scene perception technology. It aims to understand human driver\nattention to focus on specific targets/objects in the driving scene. However,\ntraffic scenes contain not only a large amount of visual information but also\nsemantic information related to driving tasks. Existing methods lack attention\nto the actual semantic information present in driving scenes. Additionally, the\ntraffic scene is a complex and dynamic process that requires constant attention\nto objects related to the current driving task. Existing models, influenced by\ntheir foundational frameworks, tend to have large parameter counts and complex\nstructures. Therefore, this paper proposes a real-time saliency Mamba network\nbased on the latest Mamba framework. As shown in Figure 1, our model uses very\nfew parameters (0.08M, only 0.09~11.16% of other models), while maintaining\nSOTA performance or achieving over 98% of the SOTA model's performance.",
      "tldr_zh": "该论文提出SalM²，一种基于Mamba框架的极轻量级显著性模型，用于实时识别驾驶员注意力，从而更好地理解驾驶场景中的语义信息和动态对象。SalM²模型参数量仅0.08M，比其他模型低至0.09~11.16%，有效解决了现有方法的语义忽略和结构复杂问题。实验结果显示，该模型在保持SOTA性能或达到98%以上时，显著提升了实时认知效率，为交通场景感知技术提供了高效解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "The article has been accepted for publication at AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.16214v2",
      "published_date": "2025-02-22 12:37:52 UTC",
      "updated_date": "2025-02-28 03:11:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:27:25.810708"
    },
    {
      "arxiv_id": "2502.16203v1",
      "title": "Machine Learning Framework for Early Power, Performance, and Area Estimation of RTL",
      "title_zh": "用于 RTL 早期功耗、性能和面积估计的机器学习框架",
      "authors": [
        "Anindita Chattopadhyay",
        "Vijay Kumar Sutrakar"
      ],
      "abstract": "A critical stage in the evolving landscape of VLSI design is the design phase\nthat is transformed into register-transfer level (RTL), which specifies system\nfunctionality through hardware description languages like Verilog. Generally,\nevaluating the quality of an RTL design demands full synthesis via electronic\ndesign automation (EDA) tool is time-consuming process that is not well-suited\nto rapid design iteration and optimization. Although recent breakthroughs in\nmachine Learning (ML) have brought early prediction models, these methods\nusually do not provide robust and generalizable solutions with respect to a\nwide range of RTL designs. This paper proposes a pre-synthesis framework that\nmakes early estimation of power, performance and area (PPA) metrics directly\nfrom the hardware description language (HDL) code making direct use of library\nfiles instead of toggle files. The proposed framework introduces a bit-level\nrepresentation referred to as the simple operator graph (SOG), which uses\nsingle-bit operators to generate a generalized and flexible structure that\nclosely mirrors the characteristics of post synthesis design. The proposed\nmodel bridges the RTL and post-synthesis design, which will help in precisely\npredicting key metrics. The proposed tree-based ML framework shows superior\npredictive performance PPA estimation. Validation is carried out on 147\ndistinct RTL designs. The proposed model with 147 different designs shows\naccuracy of 98%, 98%, and 90% for WNS, TNS and power, respectively, indicates\nsignificant accuracy improvements relative to state-of-the-art methods.",
      "tldr_zh": "这篇论文提出了一种机器学习(ML)框架，用于在注册传输级(RTL)设计阶段早期估计功率、性能和面积(PPA)指标，以解决传统EDA工具耗时长的问题。该框架直接从硬件描述语言(HDL)代码中提取信息，使用简单操作符图(SOG)作为基于单比特操作符的表示，来模拟后合成设计特征，从而实现更精确的PPA预测。实验在147个不同RTL设计上验证，该模型的准确率分别为WNS 98%、TNS 98%和功率90%，比现有方法显著提升。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.16203v1",
      "published_date": "2025-02-22 12:12:51 UTC",
      "updated_date": "2025-02-22 12:12:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:27:38.213467"
    },
    {
      "arxiv_id": "2502.16198v1",
      "title": "An Autonomous Network Orchestration Framework Integrating Large Language Models with Continual Reinforcement Learning",
      "title_zh": "一个自主网络编排框架，整合大型语言模型与持续强化学习",
      "authors": [
        "Masoud Shokrnezhad",
        "Tarik Taleb"
      ],
      "abstract": "6G networks aim to achieve global coverage, massive connectivity, and\nultra-stringent requirements. Space-Air-Ground Integrated Networks (SAGINs) and\nSemantic Communication (SemCom) are essential for realizing these goals, yet\nthey introduce considerable complexity in resource orchestration. Drawing\ninspiration from research in robotics, a viable solution to manage this\ncomplexity is the application of Large Language Models (LLMs). Although the use\nof LLMs in network orchestration has recently gained attention, existing\nsolutions have not sufficiently addressed LLM hallucinations or their\nadaptation to network dynamics. To address this gap, this paper proposes a\nframework called Autonomous Reinforcement Coordination (ARC) for a\nSemCom-enabled SAGIN. This framework employs an LLM-based Retrieval-Augmented\nGenerator (RAG) monitors services, users, and resources and processes the\ncollected data, while a Hierarchical Action Planner (HAP) orchestrates\nresources. ARC decomposes orchestration into two tiers, utilizing LLMs for\nhigh-level planning and Reinforcement Learning (RL) agents for low-level\ndecision-making, in alignment with the Mixture of Experts (MoE) concept. The\nLLMs utilize Chain-of-Thought (CoT) reasoning for few-shot learning, empowered\nby contrastive learning, while the RL agents employ replay buffer management\nfor continual learning, thereby achieving efficiency, accuracy, and\nadaptability. Simulations are provided to demonstrate the effectiveness of ARC,\nalong with a comprehensive discussion on potential future research directions\nto enhance and upgrade ARC.",
      "tldr_zh": "本论文提出Autonomous Reinforcement Coordination (ARC)框架，旨在解决6G网络中Space-Air-Ground Integrated Networks (SAGINs)和Semantic Communication (SemCom)资源编排的复杂性问题，通过整合Large Language Models (LLMs)和Continual Reinforcement Learning (RL)实现自主协调。框架采用分层结构，包括LLM-based Retrieval-Augmented Generator (RAG)用于监控和处理服务、用户及资源数据，以及Hierarchical Action Planner (HAP)负责资源编排，结合Mixture of Experts (MoE)概念。LLMs通过Chain-of-Thought (CoT)推理、few-shot learning和contrastive learning进行高层规划，而RL代理则利用replay buffer management实现持续学习，提升了整体效率、准确性和适应性。模拟实验验证了ARC的有效性，并探讨了未来研究方向以进一步优化框架。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.ET",
        "cs.LG"
      ],
      "primary_category": "cs.NI",
      "comment": "IEEE Communications Magazine",
      "pdf_url": "http://arxiv.org/pdf/2502.16198v1",
      "published_date": "2025-02-22 11:53:34 UTC",
      "updated_date": "2025-02-22 11:53:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:27:55.148195"
    },
    {
      "arxiv_id": "2502.16184v1",
      "title": "Robustness and Cybersecurity in the EU Artificial Intelligence Act",
      "title_zh": "翻译失败",
      "authors": [
        "Henrik Nolte",
        "Miriam Rateike",
        "Michèle Finck"
      ],
      "abstract": "The EU Artificial Intelligence Act (AIA) establishes different legal\nprinciples for different types of AI systems. While prior work has sought to\nclarify some of these principles, little attention has been paid to robustness\nand cybersecurity. This paper aims to fill this gap. We identify legal\nchallenges and shortcomings in provisions related to robustness and\ncybersecurity for high-risk AI systems (Art. 15 AIA) and general-purpose AI\nmodels (Art. 55 AIA). We show that robustness and cybersecurity demand\nresilience against performance disruptions. Furthermore, we assess potential\nchallenges in implementing these provisions in light of recent advancements in\nthe machine learning (ML) literature. Our analysis informs efforts to develop\nharmonized standards, guidelines by the European Commission, as well as\nbenchmarks and measurement methodologies under Art. 15(2) AIA. With this, we\nseek to bridge the gap between legal terminology and ML research, fostering a\nbetter alignment between research and implementation efforts.",
      "tldr_zh": "本论文分析了欧盟人工智能法案（EU Artificial Intelligence Act, AIA）中关于鲁棒性（robustness）和网络安全（cybersecurity）的规定，识别了针对高风险 AI 系统（high-risk AI systems, Art. 15 AIA）和通用 AI 模型（general-purpose AI models, Art. 55 AIA）的法律挑战和不足。作者强调这些规定要求 AI 系统具备对性能中断的弹性，并评估了实施这些规定时面临的挑战，特别是结合机器学习（ML）文献的最新进展。最终，该研究为制定统一标准、欧洲委员会指南以及基准和测量方法（Art. 15(2) AIA）提供见解，从而桥接法律术语与 ML 研究，促进二者更好地整合。",
      "categories": [
        "cs.AI",
        "cs.CR",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.16184v1",
      "published_date": "2025-02-22 11:12:20 UTC",
      "updated_date": "2025-02-22 11:12:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:28:01.641288"
    },
    {
      "arxiv_id": "2502.16181v1",
      "title": "BiDeV: Bilateral Defusing Verification for Complex Claim Fact-Checking",
      "title_zh": "翻译失败",
      "authors": [
        "Yuxuan Liu",
        "Hongda Sun",
        "Wenya Guo",
        "Xinyan Xiao",
        "Cunli Mao",
        "Zhengtao Yu",
        "Rui Yan"
      ],
      "abstract": "Complex claim fact-checking performs a crucial role in disinformation\ndetection. However, existing fact-checking methods struggle with claim\nvagueness, specifically in effectively handling latent information and complex\nrelations within claims. Moreover, evidence redundancy, where nonessential\ninformation complicates the verification process, remains a significant issue.\nTo tackle these limitations, we propose Bilateral Defusing Verification\n(BiDeV), a novel fact-checking working-flow framework integrating multiple\nrole-played LLMs to mimic the human-expert fact-checking process. BiDeV\nconsists of two main modules: Vagueness Defusing identifies latent information\nand resolves complex relations to simplify the claim, and Redundancy Defusing\neliminates redundant content to enhance the evidence quality. Extensive\nexperimental results on two widely used challenging fact-checking benchmarks\n(Hover and Feverous-s) demonstrate that our BiDeV can achieve the best\nperformance under both gold and open settings. This highlights the\neffectiveness of BiDeV in handling complex claims and ensuring precise\nfact-checking",
      "tldr_zh": "本文提出 BiDeV，一种双向消解验证框架，用于复杂声明的事实检查（fact-checking），旨在解决声明模糊性、潜在信息、复杂关系以及证据冗余等问题。BiDeV 整合多个角色扮演的 LLMs，模仿人类专家过程，包括 Vagueness Defusing 模块（识别潜在信息并简化复杂关系）和 Redundancy Defusing 模块（消除冗余内容以提升证据质量）。在 Hover 和 Feverous-s 基准上的实验结果显示，BiDeV 在金标准和开放设置下均取得最佳性能，证明了其在处理复杂声明和提高事实检查精确性方面的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by AAAI2025",
      "pdf_url": "http://arxiv.org/pdf/2502.16181v1",
      "published_date": "2025-02-22 10:58:40 UTC",
      "updated_date": "2025-02-22 10:58:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:28:16.297075"
    },
    {
      "arxiv_id": "2503.05758v1",
      "title": "ADAPT Centre Contribution on Implementation of the EU AI Act and Fundamental Right Protection",
      "title_zh": "翻译失败",
      "authors": [
        "Dave Lewis",
        "Marta Lasek-Markey",
        "Harshvardhan J. Pandit",
        "Delaram Golpayegani",
        "Darren McCabe",
        "Louise McCormack",
        "Joshua Hovsha",
        "Deirdre Ahern",
        "Arthit Suriyawongku"
      ],
      "abstract": "This document represents the ADAPT Centre's submission to the Irish\nDepartment of Enterprise, Trade and Employment (DETE) regarding the public\nconsultation on implementation of the EU AI Act.",
      "tldr_zh": "ADAPT Centre 提交了一份文件，作为对爱尔兰企业、贸易和就业部(DETE)的公众咨询回应，聚焦于欧盟AI Act的实施。文件强调了在AI法规执行过程中保护基本权利(Fundamental Right Protection)的必要性，并提供了相关建议，以确保AI技术的伦理和法律合规。该贡献旨在为欧盟AI Act在爱尔兰的实际应用提供宝贵指导和见解。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.05758v1",
      "published_date": "2025-02-22 10:54:38 UTC",
      "updated_date": "2025-02-22 10:54:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:28:27.650078"
    },
    {
      "arxiv_id": "2503.05757v1",
      "title": "Uncertainty-Aware Fusion: An Ensemble Framework for Mitigating Hallucinations in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Prasenjit Dey",
        "Srujana Merugu",
        "Sivaramakrishnan Kaveri"
      ],
      "abstract": "Large Language Models (LLMs) are known to hallucinate and generate\nnon-factual outputs which can undermine user trust. Traditional methods to\ndirectly mitigate hallucinations, such as representation editing and\ncontrastive decoding, often require additional training data and involve high\nimplementation complexity. While ensemble-based approaches harness multiple\nLLMs to tap into the \"wisdom of crowds\", these methods overlook uncertainties\nin individual model responses. Recent studies reveal that uncertainty\nestimation can enable LLMs to self-assess the likelihood of generating\nhallucinations. In this work, we focus on factoid question answering (QA) and\nobserve that LLMs accuracy and self-assessment capabilities vary widely with\ndifferent models excelling in different scenarios. Leveraging this insight, we\npropose Uncertainty-Aware Fusion (UAF), an ensemble framework to reduces\nhallucinations by strategically combining multiple LLM based on their accuracy\nand self-assessment abilities. Empirical results on several public benchmark\ndatasets show that UAF outperforms state-of-the-art hallucination mitigation\nmethods by $8\\%$ in factual accuracy, while either narrowing or surpassing the\nperformance gap with GPT-4.",
      "tldr_zh": "本研究针对大型语言模型（Large Language Models, LLMs）的幻觉（hallucinations）问题，提出了一种Uncertainty-Aware Fusion (UAF)框架，该框架通过ensemble方法结合多个LLMs的准确性和自我评估能力，战略性地融合响应以减少非事实输出。UAF关注事实型问答（factoid question answering, QA）任务，利用不确定性（uncertainty）估计来识别和校正模型弱点，从而避免了传统方法如representation editing和contrastive decoding的复杂性和额外训练需求。实验结果显示，在多个公共基准数据集上，UAF比现有最先进方法提高了8%的事实准确率，并缩小或超越了与GPT-4的性能差距。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Proceedings of the ACM Web Conference 2025, WWW 25",
      "pdf_url": "http://arxiv.org/pdf/2503.05757v1",
      "published_date": "2025-02-22 10:48:18 UTC",
      "updated_date": "2025-02-22 10:48:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:28:39.064541"
    },
    {
      "arxiv_id": "2502.16176v2",
      "title": "An End-to-End Homomorphically Encrypted Neural Network",
      "title_zh": "翻译失败",
      "authors": [
        "Marcos Florencio",
        "Luiz Alencar",
        "Bianca Lima"
      ],
      "abstract": "Every commercially available, state-of-the-art neural network consume plain\ninput data, which is a well-known privacy concern. We propose a new\narchitecture based on homomorphic encryption, which allows the neural network\nto operate on encrypted data. We show that Homomorphic Neural Networks (HNN)\ncan achieve full privacy and security while maintaining levels of accuracy\ncomparable to plain neural networks. We also introduce a new layer, the\nDifferentiable Soft-Argmax, which allows the calibration of output logits in\nthe encrypted domain, raising the entropy of the activation parameters, thus\nimproving the security of the model, while keeping the overall noise below the\nacceptable noise budget. Experiments were conducted using the Stanford\nSentiment Treebank (SST-2) corpora on the DistilBERT base uncased finetuned\nSST-2 English sentiment analysis model, and the results show that the HNN model\ncan achieve up to 82.5% of the accuracy of the plain model while maintaining\nfull privacy and security.",
      "tldr_zh": "这篇论文提出了一种端到端同态加密神经网络（An End-to-End Homomorphically Encrypted Neural Network），允许神经网络在加密数据上运行，从而解决传统神经网络处理明文数据时的隐私问题。研究引入了 Homomorphic Neural Networks (HNN) 架构，并设计了 Differentiable Soft-Argmax 层，用于在加密域中校准输出 logits，提高激活参数的熵以增强安全性，同时保持噪声预算在可接受范围内。实验在 Stanford Sentiment Treebank (SST-2) 数据集上使用 DistilBERT 模型进行测试，结果显示 HNN 模型的准确率达到普通模型的 82.5%，实现了全隐私和安全保护。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.16176v2",
      "published_date": "2025-02-22 10:45:07 UTC",
      "updated_date": "2025-02-27 14:09:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:28:52.157837"
    },
    {
      "arxiv_id": "2502.16175v1",
      "title": "Mojito: LLM-Aided Motion Instructor with Jitter-Reduced Inertial Tokens",
      "title_zh": "翻译失败",
      "authors": [
        "Ziwei Shan",
        "Yaoyu He",
        "Chengfeng Zhao",
        "Jiashen Du",
        "Jingyan Zhang",
        "Qixuan Zhang",
        "Jingyi Yu",
        "Lan Xu"
      ],
      "abstract": "Human bodily movements convey critical insights into action intentions and\ncognitive processes, yet existing multimodal systems primarily focused on\nunderstanding human motion via language, vision, and audio, which struggle to\ncapture the dynamic forces and torques inherent in 3D motion. Inertial\nmeasurement units (IMUs) present a promising alternative, offering lightweight,\nwearable, and privacy-conscious motion sensing. However, processing of\nstreaming IMU data faces challenges such as wireless transmission instability,\nsensor noise, and drift, limiting their utility for long-term real-time motion\ncapture (MoCap), and more importantly, online motion analysis. To address these\nchallenges, we introduce Mojito, an intelligent motion agent that integrates\ninertial sensing with large language models (LLMs) for interactive motion\ncapture and behavioral analysis.",
      "tldr_zh": "本文研究了人类运动在揭示行动意图和认知过程方面的关键作用，但现有多模态系统难以捕捉3D运动中的动态力和扭矩，转而依赖IMUs（Inertial Measurement Units）作为轻量、可穿戴的替代方案，却面临无线传输不稳定、传感器噪声和漂移等挑战。针对这些问题，作者提出Mojito，这是一个整合IMUs和LLMs（Large Language Models）的智能运动代理，通过jitter-reduced inertial tokens技术减少数据抖动，实现更可靠的长期实时运动捕捉（MoCap）和在线行为分析。Mojito的创新设计有望提升交互式运动感知的准确性和实用性，为相关应用提供新路径。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR"
      ],
      "primary_category": "cs.CV",
      "comment": "First three authors contribute equally. Project page:\n  https://koyui.github.io/mojito/",
      "pdf_url": "http://arxiv.org/pdf/2502.16175v1",
      "published_date": "2025-02-22 10:31:58 UTC",
      "updated_date": "2025-02-22 10:31:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:29:03.285654"
    },
    {
      "arxiv_id": "2502.16174v1",
      "title": "Maybe I Should Not Answer That, but... Do LLMs Understand The Safety of Their Inputs?",
      "title_zh": "也许我不应该回答那个，但是... LLMs 是否理解",
      "authors": [
        "Maciej Chrabąszcz",
        "Filip Szatkowski",
        "Bartosz Wójcik",
        "Jan Dubiński",
        "Tomasz Trzciński"
      ],
      "abstract": "Ensuring the safety of the Large Language Model (LLM) is critical, but\ncurrently used methods in most cases sacrifice the model performance to obtain\nincreased safety or perform poorly on data outside of their adaptation\ndistribution. We investigate existing methods for such generalization and find\nthem insufficient. Surprisingly, while even plain LLMs recognize unsafe\nprompts, they may still generate unsafe responses. To avoid performance\ndegradation and preserve safe performance, we advocate for a two-step\nframework, where we first identify unsafe prompts via a lightweight classifier,\nand apply a \"safe\" model only to such prompts. In particular, we explore the\ndesign of the safety detector in more detail, investigating the use of\ndifferent classifier architectures and prompting techniques. Interestingly, we\nfind that the final hidden state for the last token is enough to provide robust\nperformance, minimizing false positives on benign data while performing well on\nmalicious prompt detection. Additionally, we show that classifiers trained on\nthe representations from different model layers perform comparably on the\nlatest model layers, indicating that safety representation is present in the\nLLMs' hidden states at most model stages. Our work is a step towards efficient,\nrepresentation-based safety mechanisms for LLMs.",
      "tldr_zh": "本研究探讨大型语言模型（LLMs）是否理解输入的安全性，发现现有安全方法要么牺牲模型性能，要么在非适应分布数据上表现不佳，即使LLMs能识别不安全提示，它们仍可能生成不安全响应。为此，作者提出一个两步框架：首先使用轻量级分类器检测不安全提示，然后仅对这些提示应用“安全”模型。实验显示，使用最后一个标记的最终隐藏状态作为分类器输入，能有效减少对良性数据的假阳性，同时在恶意提示检测上表现出色。此外，分类器在不同模型层表示上训练后，在最新层表现类似，表明安全表示广泛存在于LLMs的隐藏状态中，这为高效的基于表示的安全机制提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.16174v1",
      "published_date": "2025-02-22 10:31:50 UTC",
      "updated_date": "2025-02-22 10:31:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:29:14.846162"
    },
    {
      "arxiv_id": "2502.16171v1",
      "title": "EPERM: An Evidence Path Enhanced Reasoning Model for Knowledge Graph Question and Answering",
      "title_zh": "EPERM：证据路径增强推理模型用于知识图谱问答",
      "authors": [
        "Xiao Long",
        "Liansheng Zhuang",
        "Aodi Li",
        "Minghong Yao",
        "Shafei Wang"
      ],
      "abstract": "Due to the remarkable reasoning ability, Large language models (LLMs) have\ndemonstrated impressive performance in knowledge graph question answering\n(KGQA) tasks, which find answers to natural language questions over knowledge\ngraphs (KGs). To alleviate the hallucinations and lack of knowledge issues of\nLLMs, existing methods often retrieve the question-related information from KGs\nto enrich the input context. However, most methods focus on retrieving the\nrelevant information while ignoring the importance of different types of\nknowledge in reasoning, which degrades their performance. To this end, this\npaper reformulates the KGQA problem as a graphical model and proposes a\nthree-stage framework named the Evidence Path Enhanced Reasoning Model (EPERM)\nfor KGQA. In the first stage, EPERM uses the fine-tuned LLM to retrieve a\nsubgraph related to the question from the original knowledge graph. In the\nsecond stage, EPERM filters out the evidence paths that faithfully support the\nreasoning of the questions, and score their importance in reasoning. Finally,\nEPERM uses the weighted evidence paths to reason the final answer. Since\nconsidering the importance of different structural information in KGs for\nreasoning, EPERM can improve the reasoning ability of LLMs in KGQA tasks.\nExtensive experiments on benchmark datasets demonstrate that EPERM achieves\nsuperior performances in KGQA tasks.",
      "tldr_zh": "这篇论文提出 EPERM（Evidence Path Enhanced Reasoning Model），一种增强型推理模型，用于解决大型语言模型（LLMs）在知识图谱问答（KGQA）任务中的幻觉和知识缺失问题。EPERM 通过三阶段框架，首先利用微调的 LLM 从知识图谱（KGs）中检索相关子图，其次过滤并评分证据路径的重要性，最后使用加权的证据路径进行最终答案推理。该方法强调不同结构信息的角色，提高了 LLMs 的推理能力，实验在基准数据集上证明了其优越性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.16171v1",
      "published_date": "2025-02-22 10:05:22 UTC",
      "updated_date": "2025-02-22 10:05:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:29:26.042022"
    },
    {
      "arxiv_id": "2502.16170v1",
      "title": "Destroy and Repair Using Hyper Graphs for Routing",
      "title_zh": "翻译失败",
      "authors": [
        "Ke Li",
        "Fei Liu",
        "Zhengkun Wang",
        "Qingfu Zhang"
      ],
      "abstract": "Recent advancements in Neural Combinatorial Optimization (NCO) have shown\npromise in solving routing problems like the Traveling Salesman Problem (TSP)\nand Capacitated Vehicle Routing Problem (CVRP) without handcrafted designs.\nResearch in this domain has explored two primary categories of methods:\niterative and non-iterative. While non-iterative methods struggle to generate\nnear-optimal solutions directly, iterative methods simplify the task by\nlearning local search steps. However, existing iterative methods are often\nlimited by restricted neighborhood searches, leading to suboptimal results. To\naddress this limitation, we propose a novel approach that extends the search to\nlarger neighborhoods by learning a destroy-and-repair strategy. Specifically,\nwe introduce a Destroy-and-Repair framework based on Hyper-Graphs (DRHG). This\nframework reduces consecutive intact edges to hyper-edges, allowing the model\nto pay more attention to the destroyed part and decrease the complexity of\nencoding all nodes. Experiments demonstrate that DRHG achieves stateof-the-art\nperformance on TSP with up to 10,000 nodes and shows strong generalization to\nreal-world TSPLib and CVRPLib problems.",
      "tldr_zh": "该研究针对神经组合优化（NCO）在路由问题如旅行 salesman 问题（TSP）和带容量车辆路径问题（CVRP）中的局限性，提出了一种基于超图（Hyper-Graphs）的Destroy-and-Repair框架（DRHG）。该框架通过学习破坏和修复策略，将连续完整边简化为超边，从而扩展搜索邻域、增强模型对破坏部分的关注，并降低节点编码复杂度。实验结果显示，DRHG 在 TSP 上实现了最先进性能，支持高达 10,000 节点的规模，并成功泛化到真实世界的 TSPLib 和 CVRPLib 问题。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at AAAI2025",
      "pdf_url": "http://arxiv.org/pdf/2502.16170v1",
      "published_date": "2025-02-22 10:04:58 UTC",
      "updated_date": "2025-02-22 10:04:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:29:38.385154"
    },
    {
      "arxiv_id": "2502.16169v1",
      "title": "Patterns Over Principles: The Fragility of Inductive Reasoning in LLMs under Noisy Observations",
      "title_zh": "翻译失败",
      "authors": [
        "Chunyang Li",
        "Weiqi Wang",
        "Tianshi Zheng",
        "Yangqiu Song"
      ],
      "abstract": "Inductive reasoning, a cornerstone of human cognition, enables generalization\nfrom limited data but hasn't yet been fully achieved by large language models\n(LLMs). While modern LLMs excel at reasoning tasks, their ability to maintain\nstable and consistent rule abstraction under imperfect observations remains\nunderexplored. To fill this gap, in this work, we introduce Robust Rule\nInduction, a task that evaluates LLMs' capability in inferring rules from data\nthat are fused with noisy examples. To address this task, we further propose\nSample-steered Rule Refinement (SRR), a method enhancing reasoning stability\nvia observation diversification and execution-guided feedback. Experiments\nacross arithmetic, cryptography, and list functions reveal: (1) SRR outperforms\nother methods with minimal performance degradation under noise; (2) Despite\nslight accuracy variation, LLMs exhibit instability under noise (e.g., 0%\naccuracy change with only 70% consistent score); (3) Counterfactual task gaps\nhighlight LLMs' reliance on memorized patterns over genuine abstraction. Our\nfindings challenge LLMs' reasoning robustness, revealing susceptibility to\nhypothesis drift and pattern overfitting, while providing empirical evidence\ncritical for developing human-like inductive systems. Code and data are\navailable at\n\\href{https://github.com/lcy2723/Robust-Rule-Induction}{https://github.com/lcy2723/Robust-Rule-Induction}.",
      "tldr_zh": "本研究探讨了大型语言模型 (LLMs) 在归纳推理 (Inductive Reasoning) 方面的脆弱性，特别是面对噪声观察时的不稳定性。论文引入了 Robust Rule Induction 任务，用于评估 LLMs 从噪声数据中推断规则的能力，并提出 Sample-steered Rule Refinement (SRR) 方法，通过观察多样化和执行引导反馈来提升推理稳定性。实验结果显示，SRR 在算术、密码学和列表函数等场景下优于其他方法，即使在噪声环境下也保持最小性能下降；然而，LLMs 尽管准确率变化有限，却表现出显著的不一致性（如准确率不变但一致性仅70%），并更多依赖记忆模式而非真正抽象，导致假设漂移和模式过拟合 (Pattern Overfitting)。这些发现强调了 LLMs 推理鲁棒性的不足，并为开发更接近人类认知的归纳系统提供了关键经验证据。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.16169v1",
      "published_date": "2025-02-22 10:03:19 UTC",
      "updated_date": "2025-02-22 10:03:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:29:50.436400"
    },
    {
      "arxiv_id": "2502.16167v1",
      "title": "PersGuard: Preventing Malicious Personalization via Backdoor Attacks on Pre-trained Text-to-Image Diffusion Models",
      "title_zh": "PersGuard：通过后门攻击防止预训练文本到图像扩散模型的恶意个性化",
      "authors": [
        "Xinwei Liu",
        "Xiaojun Jia",
        "Yuan Xun",
        "Hua Zhang",
        "Xiaochun Cao"
      ],
      "abstract": "Diffusion models (DMs) have revolutionized data generation, particularly in\ntext-to-image (T2I) synthesis. However, the widespread use of personalized\ngenerative models raises significant concerns regarding privacy violations and\ncopyright infringement. To address these issues, researchers have proposed\nadversarial perturbation-based protection techniques. However, these methods\nhave notable limitations, including insufficient robustness against data\ntransformations and the inability to fully eliminate identifiable features of\nprotected objects in the generated output. In this paper, we introduce\nPersGuard, a novel backdoor-based approach that prevents malicious\npersonalization of specific images. Unlike traditional adversarial perturbation\nmethods, PersGuard implant backdoor triggers into pre-trained T2I models,\npreventing the generation of customized outputs for designated protected images\nwhile allowing normal personalization for unprotected ones. Unfortunately,\nexisting backdoor methods for T2I diffusion models fail to be applied to\npersonalization scenarios due to the different backdoor objectives and the\npotential backdoor elimination during downstream fine-tuning processes. To\naddress these, we propose three novel backdoor objectives specifically designed\nfor personalization scenarios, coupled with backdoor retention loss engineered\nto resist downstream fine-tuning. These components are integrated into a\nunified optimization framework. Extensive experimental evaluations demonstrate\nPersGuard's effectiveness in preserving data privacy, even under challenging\nconditions including gray-box settings, multi-object protection, and facial\nidentity scenarios. Our method significantly outperforms existing techniques,\noffering a more robust solution for privacy and copyright protection.",
      "tldr_zh": "本文提出 PersGuard，一种新型后门攻击（backdoor attacks）方法，用于防止预训练文本到图像（T2I）扩散模型（Diffusion Models）的恶意个性化，从而解决隐私和版权侵犯问题。与传统对抗扰动技术相比，PersGuard 通过植入后门触发器，阻止特定图像的自定义输出，同时允许非保护图像正常个性化。论文引入三种专为个性化场景设计的新后门目标（backdoor objectives），并结合后门保留损失（backdoor retention loss）来抵抗下游微调过程。实验结果表明，PersGuard 在灰盒设置、多对象保护和面部身份场景中显著优于现有方法，提供更 robust 的隐私保护解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.16167v1",
      "published_date": "2025-02-22 09:47:55 UTC",
      "updated_date": "2025-02-22 09:47:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:30:04.042077"
    },
    {
      "arxiv_id": "2502.19439v1",
      "title": "Multi-objective Cat Swarm Optimization Algorithm based on a Grid System",
      "title_zh": "翻译失败",
      "authors": [
        "Aram M. Ahmed",
        "Bryar A. Hassan",
        "Tarik A. Rashid",
        "Kaniaw A. Noori",
        "Soran Ab. M. Saeed",
        "Omed H. Ahmed",
        "Shahla U. Umar"
      ],
      "abstract": "This paper presents a multi-objective version of the Cat Swarm Optimization\nAlgorithm called the Grid-based Multi-objective Cat Swarm Optimization\nAlgorithm (GMOCSO). Convergence and diversity preservation are the two main\ngoals pursued by modern multi-objective algorithms to yield robust results. To\nachieve these goals, we first replace the roulette wheel method of the original\nCSO algorithm with a greedy method. Then, two key concepts from Pareto Archived\nEvolution Strategy Algorithm (PAES) are adopted: the grid system and double\narchive strategy. Several test functions and a real-world scenario called the\nPressure vessel design problem are used to evaluate the proposed algorithm's\nperformance. In the experiment, the proposed algorithm is compared with other\nwell-known algorithms using different metrics such as Reversed Generational\nDistance, Spacing metric, and Spread metric. The optimization results show the\nrobustness of the proposed algorithm, and the results are further confirmed\nusing statistical methods and graphs. Finally, conclusions and future\ndirections were presented..",
      "tldr_zh": "本文提出了一种基于网格系统的多目标猫群优化算法（GMOCSO），通过将原 Cat Swarm Optimization (CSO) 算法中的轮盘赌方法替换为贪婪方法，并引入 Pareto Archived Evolution Strategy (PAES) 的网格系统和双归档策略，以提升收敛性和多样性保留。实验在多个测试函数和真实场景（如压力容器设计问题）上进行，与其他算法比较，使用 Reversed Generational Distance、Spacing metric 和 Spread metric 等指标显示，GMOCSO 表现出色，具有较高的鲁棒性。未来方向包括进一步优化和扩展应用。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.19439v1",
      "published_date": "2025-02-22 09:13:21 UTC",
      "updated_date": "2025-02-22 09:13:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:30:15.297002"
    },
    {
      "arxiv_id": "2502.18509v1",
      "title": "Protecting Users From Themselves: Safeguarding Contextual Privacy in Interactions with Conversational Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Ivoline Ngong",
        "Swanand Kadhe",
        "Hao Wang",
        "Keerthiram Murugesan",
        "Justin D. Weisz",
        "Amit Dhurandhar",
        "Karthikeyan Natesan Ramamurthy"
      ],
      "abstract": "Conversational agents are increasingly woven into individuals' personal\nlives, yet users often underestimate the privacy risks involved. The moment\nusers share information with these agents (e.g., LLMs), their private\ninformation becomes vulnerable to exposure. In this paper, we characterize the\nnotion of contextual privacy for user interactions with LLMs. It aims to\nminimize privacy risks by ensuring that users (sender) disclose only\ninformation that is both relevant and necessary for achieving their intended\ngoals when interacting with LLMs (untrusted receivers). Through a formative\ndesign user study, we observe how even \"privacy-conscious\" users inadvertently\nreveal sensitive information through indirect disclosures. Based on insights\nfrom this study, we propose a locally-deployable framework that operates\nbetween users and LLMs, and identifies and reformulates out-of-context\ninformation in user prompts. Our evaluation using examples from ShareGPT shows\nthat lightweight models can effectively implement this framework, achieving\nstrong gains in contextual privacy while preserving the user's intended\ninteraction goals through different approaches to classify information relevant\nto the intended goals.",
      "tldr_zh": "本研究探讨了用户在使用对话代理（如LLMs）时低估隐私风险的问题，引入了\"contextual privacy\"的概念，即确保用户只披露与交互目标相关的必要信息，以最小化泄露风险。通过用户研究发现，即使是隐私意识强的用户也会无意中通过间接方式泄露敏感信息。为此，研究提出一个本地部署的框架，在用户和LLMs之间操作，识别并重构用户提示中的无关内容。评估结果显示，该框架使用轻量级模型在ShareGPT示例上有效提升了contextual privacy，同时保留了用户的交互目标。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CR",
      "comment": "22 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.18509v1",
      "published_date": "2025-02-22 09:05:39 UTC",
      "updated_date": "2025-02-22 09:05:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:30:25.730940"
    },
    {
      "arxiv_id": "2502.16137v1",
      "title": "Chain-of-Description: What I can understand, I can put into words",
      "title_zh": "翻译失败",
      "authors": [
        "Jiaxin Guo",
        "Daimeng Wei",
        "Zongyao Li",
        "Hengchao Shang",
        "Yuanchang Luo",
        "Hao Yang"
      ],
      "abstract": "In this paper, we propose a novel strategy defined as Chain-of-Description\n(CoD) Prompting, tailored for Multi-Modal Large Language Models. This approach\ninvolves having the model first provide a detailed description of the\nmulti-modal input before generating an answer to the question. When applied to\nmodels such as Qwen2-Audio, Qwen2-VL, and Qwen2.5-VL, CoD Prompting\nsignificantly enhances performance compared to standard prompting methods. This\nis demonstrated by nearly a 4\\% improvement in the speech category of the audio\nbenchmark AIR-Bench-Chat and a 5.3\\% improvement in the hard-level portion of\nthe vision benchmark MMMU\\_Pro. Our ablation study further validates the\neffectiveness of CoD Prompting.",
      "tldr_zh": "本论文提出了一种名为 Chain-of-Description (CoD) Prompting 的新策略，针对 Multi-Modal Large Language Models，让模型先对多模态输入进行详细描述，然后再生成答案。在 Qwen2-Audio、Qwen2-VL 和 Qwen2.5-VL 等模型上应用后，该策略显著提升了性能，例如在 AIR-Bench-Chat 的语音类别提高了近 4%，而在 MMMU_Pro 的硬级部分提高了 5.3%。消融研究进一步验证了 CoD Prompting 的有效性，为多模态任务处理提供了新的优化方法。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.16137v1",
      "published_date": "2025-02-22 08:27:31 UTC",
      "updated_date": "2025-02-22 08:27:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:30:40.089564"
    },
    {
      "arxiv_id": "2502.16129v1",
      "title": "Robust Dynamic Facial Expression Recognition",
      "title_zh": "鲁棒动态面部表情识别",
      "authors": [
        "Feng Liu",
        "Hanyang Wang",
        "Siyuan Shen"
      ],
      "abstract": "The study of Dynamic Facial Expression Recognition (DFER) is a nascent field\nof research that involves the automated recognition of facial expressions in\nvideo data. Although existing research has primarily focused on learning\nrepresentations under noisy and hard samples, the issue of the coexistence of\nboth types of samples remains unresolved. In order to overcome this challenge,\nthis paper proposes a robust method of distinguishing between hard and noisy\nsamples. This is achieved by evaluating the prediction agreement of the model\non different sampled clips of the video. Subsequently, methodologies that\nreinforce the learning of hard samples and mitigate the impact of noisy samples\ncan be employed. Moreover, to identify the principal expression in a video and\nenhance the model's capacity for representation learning, comprising a key\nexpression re-sampling framework and a dual-stream hierarchical network is\nproposed, namely Robust Dynamic Facial Expression Recognition (RDFER). The key\nexpression re-sampling framework is designed to identify the key expression,\nthereby mitigating the potential confusion caused by non-target expressions.\nRDFER employs two sequence models with the objective of disentangling\nshort-term facial movements and long-term emotional changes. The proposed\nmethod has been shown to outperform current State-Of-The-Art approaches in DFER\nthrough extensive experimentation on benchmark datasets such as DFEW and\nFERV39K. A comprehensive analysis provides valuable insights and observations\nregarding the proposed agreement. This work has significant implications for\nthe field of dynamic facial expression recognition and promotes the further\ndevelopment of the field of noise-consistent robust learning in dynamic facial\nexpression recognition. The code is available from\n[https://github.com/Cross-Innovation-Lab/RDFER].",
      "tldr_zh": "这篇论文针对 Dynamic Facial Expression Recognition (DFER) 的挑战，提出了一种鲁棒方法，通过评估模型在不同视频剪辑上的预测一致性来区分硬样本和噪声样本，从而强化硬样本学习并减轻噪声影响。论文引入 Robust Dynamic Facial Expression Recognition (RDFER) 框架，包括关键表情重采样框架（用于识别主要表情并减少干扰）和双流层次网络（分离短期面部动作与长期情感变化）。实验结果显示，RDFER 在 DFEW 和 FERV39K 等基准数据集上超越了 State-Of-The-Art 方法，提升了整体性能，并为噪声一致鲁棒学习提供了宝贵见解。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.16129v1",
      "published_date": "2025-02-22 07:48:12 UTC",
      "updated_date": "2025-02-22 07:48:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:30:52.188997"
    },
    {
      "arxiv_id": "2502.16128v1",
      "title": "Heterogeneous Multi-Agent Bandits with Parsimonious Hints",
      "title_zh": "翻译失败",
      "authors": [
        "Amirmahdi Mirfakhar",
        "Xuchuang Wang",
        "Jinhang Zuo",
        "Yair Zick",
        "Mohammad Hajiesmaili"
      ],
      "abstract": "We study a hinted heterogeneous multi-agent multi-armed bandits problem\n(HMA2B), where agents can query low-cost observations (hints) in addition to\npulling arms. In this framework, each of the $M$ agents has a unique reward\ndistribution over $K$ arms, and in $T$ rounds, they can observe the reward of\nthe arm they pull only if no other agent pulls that arm. The goal is to\nmaximize the total utility by querying the minimal necessary hints without\npulling arms, achieving time-independent regret. We study HMA2B in both\ncentralized and decentralized setups. Our main centralized algorithm, GP-HCLA,\nwhich is an extension of HCLA, uses a central decision-maker for arm-pulling\nand hint queries, achieving $O(M^4K)$ regret with $O(MK\\log T)$ adaptive hints.\nIn decentralized setups, we propose two algorithms, HD-ETC and EBHD-ETC, that\nallow agents to choose actions independently through collision-based\ncommunication and query hints uniformly until stopping, yielding $O(M^3K^2)$\nregret with $O(M^3K\\log T)$ hints, where the former requires knowledge of the\nminimum gap and the latter does not. Finally, we establish lower bounds to\nprove the optimality of our results and verify them through numerical\nsimulations.",
      "tldr_zh": "本研究探讨了带有节俭提示（hints）的异构多智能体多臂老虎机问题（HMA2B），其中多个智能体在拉臂外可查询低成本观察，以最大化总收益并实现与时间无关的regret。论文提出集中式算法GP-HCLA，使用中央决策者进行臂拉和提示查询，达到O(M^4 K) regret和O(M K log T)自适应hints；同时，引入去中心化算法HD-ETC和EBHD-ETC，通过碰撞通信让智能体独立行动，实现O(M^3 K^2) regret和O(M^3 K log T) hints，前者需最小间隙知识，后者无需。最终，通过下界证明和数值模拟验证了这些算法的最优性，为高效的多智能体决策提供了新框架。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.GT",
        "cs.MA"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at AAAI-2025",
      "pdf_url": "http://arxiv.org/pdf/2502.16128v1",
      "published_date": "2025-02-22 07:46:41 UTC",
      "updated_date": "2025-02-22 07:46:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:31:03.442222"
    },
    {
      "arxiv_id": "2502.18508v1",
      "title": "REFINE: Inversion-Free Backdoor Defense via Model Reprogramming",
      "title_zh": "翻译失败",
      "authors": [
        "Yukun Chen",
        "Shuo Shao",
        "Enhao Huang",
        "Yiming Li",
        "Pin-Yu Chen",
        "Zhan Qin",
        "Kui Ren"
      ],
      "abstract": "Backdoor attacks on deep neural networks (DNNs) have emerged as a significant\nsecurity threat, allowing adversaries to implant hidden malicious behaviors\nduring the model training phase. Pre-processing-based defense, which is one of\nthe most important defense paradigms, typically focuses on input\ntransformations or backdoor trigger inversion (BTI) to deactivate or eliminate\nembedded backdoor triggers during the inference process. However, these methods\nsuffer from inherent limitations: transformation-based defenses often fail to\nbalance model utility and defense performance, while BTI-based defenses\nstruggle to accurately reconstruct trigger patterns without prior knowledge. In\nthis paper, we propose REFINE, an inversion-free backdoor defense method based\non model reprogramming. REFINE consists of two key components: \\textbf{(1)} an\ninput transformation module that disrupts both benign and backdoor patterns,\ngenerating new benign features; and \\textbf{(2)} an output remapping module\nthat redefines the model's output domain to guide the input transformations\neffectively. By further integrating supervised contrastive loss, REFINE\nenhances the defense capabilities while maintaining model utility. Extensive\nexperiments on various benchmark datasets demonstrate the effectiveness of our\nREFINE and its resistance to potential adaptive attacks.",
      "tldr_zh": "该研究针对深度神经网络（DNNs）中的后门攻击（Backdoor Attacks）提出了一种免反演防御方法 REFINE，该方法基于模型重编程（Model Reprogramming），通过输入转换模块破坏良性和后门模式生成新特征，以及输出重映射模块重新定义模型输出域来有效指导转换。REFINE 还整合了监督对比损失（Supervised Contrastive Loss），以提升防御能力同时维持模型效用。实验结果显示，在各种基准数据集上，REFINE 显著提高了防御性能，并对潜在的自适应攻击表现出强抵抗力。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "This paper is accept by ICLR 2025. The first two authors contributed\n  equally to this work. Our code is available at BackdoorBox\n  (https://github.com/THUYimingLi/BackdoorBox) and Github repository\n  (https://github.com/WhitolfChen/REFINE). 28 pages",
      "pdf_url": "http://arxiv.org/pdf/2502.18508v1",
      "published_date": "2025-02-22 07:29:12 UTC",
      "updated_date": "2025-02-22 07:29:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:31:14.519958"
    },
    {
      "arxiv_id": "2504.03648v1",
      "title": "AIBrix: Towards Scalable, Cost-Effective Large Language Model Inference Infrastructure",
      "title_zh": "AIBrix：面向可扩展、成本有效的大语言模型推理基础设施",
      "authors": [
        "The AIBrix Team",
        "Jiaxin Shan",
        "Varun Gupta",
        "Le Xu",
        "Haiyang Shi",
        "Jingyuan Zhang",
        "Ning Wang",
        "Linhui Xu",
        "Rong Kang",
        "Tongping Liu",
        "Yifei Zhang",
        "Yiqing Zhu",
        "Shuowei Jin",
        "Gangmuk Lim",
        "Binbin Chen",
        "Zuzhi Chen",
        "Xiao Liu",
        "Xin Chen",
        "Kante Yin",
        "Chak-Pong Chung",
        "Chenyu Jiang",
        "Yicheng Lu",
        "Jianjun Chen",
        "Caixue Lin",
        "Wu Xiang",
        "Rui Shi",
        "Liguang Xie"
      ],
      "abstract": "We introduce AIBrix, a cloud-native, open-source framework designed to\noptimize and simplify large-scale LLM deployment in cloud environments. Unlike\ntraditional cloud-native stacks, AIBrix follows a co-design philosophy,\nensuring every layer of the infrastructure is purpose-built for seamless\nintegration with inference engines like vLLM. AIBrix introduces several key\ninnovations to reduce inference costs and enhance performance including\nhigh-density LoRA management for dynamic adapter scheduling, LLM-specific\nautoscalers, and prefix-aware, load-aware routing. To further improve\nefficiency, AIBrix incorporates a distributed KV cache, boosting token reuse\nacross nodes, leading to a 50% increase in throughput and a 70% reduction in\ninference latency. AIBrix also supports unified AI runtime which streamlines\nmodel management while maintaining vendor-agnostic engine compatibility. For\nlarge-scale multi-node inference, AIBrix employs hybrid orchestration --\nleveraging Kubernetes for coarse-grained scheduling and Ray for fine-grained\nexecution -- to balance efficiency and flexibility. Additionally, an SLO-driven\nGPU optimizer dynamically adjusts resource allocations, optimizing\nheterogeneous serving to maximize cost efficiency while maintaining service\nguarantees. Finally, AIBrix enhances system reliability with AI accelerator\ndiagnostic tools, enabling automated failure detection and mock-up testing to\nimprove fault resilience. AIBrix is available at\nhttps://github.com/vllm-project/aibrix.",
      "tldr_zh": "本研究介绍了 AIBrix，一种云原生、开源框架，旨在优化大规模 Large Language Model (LLM) 在云环境中的部署，通过 co-design 哲学与推理引擎如 vLLM 实现无缝集成。AIBrix 的关键创新包括高密度 LoRA 管理、LLM 特定 autoscalers、prefix-aware 和 load-aware routing，以及分布式 KV cache，提升吞吐量 50% 并减少推理延迟 70%。此外，它采用混合编排（Kubernetes 用于粗粒度调度，Ray 用于细粒度执行）和 SLO-driven GPU 优化器来动态调整资源分配，提高成本效率和系统可靠性，同时提供 AI 加速器诊断工具以支持故障检测。AIBrix 的开源代码可在 GitHub 上获取。",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.03648v1",
      "published_date": "2025-02-22 07:07:38 UTC",
      "updated_date": "2025-02-22 07:07:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:31:25.761255"
    },
    {
      "arxiv_id": "2502.16111v1",
      "title": "PlanGEN: A Multi-Agent Framework for Generating Planning and Reasoning Trajectories for Complex Problem Solving",
      "title_zh": "翻译失败",
      "authors": [
        "Mihir Parmar",
        "Xin Liu",
        "Palash Goyal",
        "Yanfei Chen",
        "Long Le",
        "Swaroop Mishra",
        "Hossein Mobahi",
        "Jindong Gu",
        "Zifeng Wang",
        "Hootan Nakhost",
        "Chitta Baral",
        "Chen-Yu Lee",
        "Tomas Pfister",
        "Hamid Palangi"
      ],
      "abstract": "Recent agent frameworks and inference-time algorithms often struggle with\ncomplex planning problems due to limitations in verifying generated plans or\nreasoning and varying complexity of instances within a single task. Many\nexisting methods for these tasks either perform task-level verification without\nconsidering constraints or apply inference-time algorithms without adapting to\ninstance-level complexity. To address these limitations, we propose PlanGEN, a\nmodel-agnostic and easily scalable agent framework with three key components:\nconstraint, verification, and selection agents. Specifically, our approach\nproposes constraint-guided iterative verification to enhance performance of\ninference-time algorithms--Best of N, Tree-of-Thought, and REBASE. In PlanGEN\nframework, the selection agent optimizes algorithm choice based on instance\ncomplexity, ensuring better adaptability to complex planning problems.\nExperimental results demonstrate significant improvements over the strongest\nbaseline across multiple benchmarks, achieving state-of-the-art results on\nNATURAL PLAN ($\\sim$8%$\\uparrow$), OlympiadBench ($\\sim$4%$\\uparrow$), DocFinQA\n($\\sim$7%$\\uparrow$), and GPQA ($\\sim$1%$\\uparrow$). Our key finding highlights\nthat constraint-guided iterative verification improves inference-time\nalgorithms, and adaptive selection further boosts performance on complex\nplanning and reasoning problems.",
      "tldr_zh": "该研究提出PlanGEN，一种模型无关且易于扩展的多代理框架，用于生成规划和推理轨迹，以解决复杂问题中现有算法的验证和适应性不足问题。框架包括constraint agent、verification agent和selection agent，通过constraint-guided iterative verification技术提升推理时间算法如Best of N、Tree-of-Thought和REBASE，并根据实例复杂性优化算法选择。实验结果显示，PlanGEN在多个基准上实现了显著改进，包括NATURAL PLAN（约8%↑）、OlympiadBench（约4%↑）、DocFinQA（约7%↑）和GPQA（约1%↑）。关键发现是，constraint-guided iterative verification和adaptive selection显著提升了复杂规划和推理任务的性能。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "30 pages",
      "pdf_url": "http://arxiv.org/pdf/2502.16111v1",
      "published_date": "2025-02-22 06:21:56 UTC",
      "updated_date": "2025-02-22 06:21:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:31:38.272918"
    },
    {
      "arxiv_id": "2502.16105v1",
      "title": "NeurFlow: Interpreting Neural Networks through Neuron Groups and Functional Interactions",
      "title_zh": "翻译失败",
      "authors": [
        "Tue M. Cao",
        "Nhat X. Hoang",
        "Hieu H. Pham",
        "Phi Le Nguyen",
        "My T. Thai"
      ],
      "abstract": "Understanding the inner workings of neural networks is essential for\nenhancing model performance and interpretability. Current research\npredominantly focuses on examining the connection between individual neurons\nand the model's final predictions. Which suffers from challenges in\ninterpreting the internal workings of the model, particularly when neurons\nencode multiple unrelated features. In this paper, we propose a novel framework\nthat transitions the focus from analyzing individual neurons to investigating\ngroups of neurons, shifting the emphasis from neuron-output relationships to\nfunctional interaction between neurons. Our automated framework, NeurFlow,\nfirst identifies core neurons and clusters them into groups based on shared\nfunctional relationships, enabling a more coherent and interpretable view of\nthe network's internal processes. This approach facilitates the construction of\na hierarchical circuit representing neuron interactions across layers, thus\nimproving interpretability while reducing computational costs. Our extensive\nempirical studies validate the fidelity of our proposed NeurFlow. Additionally,\nwe showcase its utility in practical applications such as image debugging and\nautomatic concept labeling, thereby highlighting its potential to advance the\nfield of neural network explainability.",
      "tldr_zh": "该论文提出 NeurFlow 框架，通过分析神经元群组和功能交互来提升神经网络的可解释性，解决现有方法在解读单个神经元时面临的挑战，如编码多重无关特征的问题。NeurFlow 自动识别核心神经元并基于共享功能关系进行聚类，构建层次化电路以表示神经元跨层交互，从而提高模型内部过程的可视性和解释性，同时降低计算成本。实证研究验证了框架的保真度，并在图像调试和自动概念标记等实际应用中展示了其潜力，推进了神经网络可解释性领域的发展。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "The Thirteenth International Conference on Learning Representations",
      "pdf_url": "http://arxiv.org/pdf/2502.16105v1",
      "published_date": "2025-02-22 06:01:03 UTC",
      "updated_date": "2025-02-22 06:01:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:31:49.617647"
    },
    {
      "arxiv_id": "2502.16101v2",
      "title": "Worse than Zero-shot? A Fact-Checking Dataset for Evaluating the Robustness of RAG Against Misleading Retrievals",
      "title_zh": "翻译失败",
      "authors": [
        "Linda Zeng",
        "Rithwik Gupta",
        "Divij Motwani",
        "Diji Yang",
        "Yi Zhang"
      ],
      "abstract": "Retrieval-augmented generation (RAG) has shown impressive capabilities in\nmitigating hallucinations in large language models (LLMs). However, LLMs\nstruggle to handle misleading retrievals and often fail to maintain their own\nreasoning when exposed to conflicting or selectively-framed evidence, making\nthem vulnerable to real-world misinformation. In such real-world retrieval\nscenarios, misleading and conflicting information is rampant, particularly in\nthe political domain, where evidence is often selectively framed, incomplete,\nor polarized. However, existing RAG benchmarks largely assume a clean retrieval\nsetting, where models succeed by accurately retrieving and generating answers\nfrom gold-standard documents. This assumption fails to align with real-world\nconditions, leading to an overestimation of RAG system performance. To bridge\nthis gap, we introduce RAGuard, a fact-checking dataset designed to evaluate\nthe robustness of RAG systems against misleading retrievals. Unlike prior\nbenchmarks that rely on synthetic noise, our dataset constructs its retrieval\ncorpus from Reddit discussions, capturing naturally occurring misinformation.\nIt categorizes retrieved evidence into three types: supporting, misleading, and\nirrelevant, providing a realistic and challenging testbed for assessing how\nwell RAG systems navigate different retrieval information. Our benchmark\nexperiments reveal that when exposed to misleading retrievals, all tested\nLLM-powered RAG systems perform worse than their zero-shot baselines (i.e., no\nretrieval at all), highlighting their susceptibility to noisy environments. To\nthe best of our knowledge, RAGuard is the first benchmark to systematically\nassess RAG robustness against misleading evidence. We expect this benchmark\nwill drive future research toward improving RAG systems beyond idealized\ndatasets, making them more reliable for real-world applications.",
      "tldr_zh": "该论文探讨了检索增强生成（RAG）系统在面对误导性检索时的脆弱性，指出现有基准过于理想化，无法反映现实世界如政治领域的噪声环境。研究引入了RAGuard数据集，该数据集基于Reddit讨论构建真实语料，并将检索证据分类为支持性、误导性和无关类型，以系统评估RAG系统的鲁棒性。实验结果显示，所有测试的LLM驱动RAG系统在误导性检索下表现不如zero-shot基线，突显了其易受误导证据影响的问题。该基准有望推动未来研究，提升RAG系统在真实应用中的可靠性和抗噪能力。",
      "categories": [
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.16101v2",
      "published_date": "2025-02-22 05:50:15 UTC",
      "updated_date": "2025-05-21 21:12:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:32:03.273353"
    },
    {
      "arxiv_id": "2502.16097v1",
      "title": "LitLinker: Supporting the Ideation of Interdisciplinary Contexts with Large Language Models for Teaching Literature in Elementary Schools",
      "title_zh": "翻译失败",
      "authors": [
        "Haoxiang Fan",
        "Changshuang Zhou",
        "Hao Yu",
        "Xueyang Wu",
        "Jiangyu Gu",
        "Zhenhui Peng"
      ],
      "abstract": "Teaching literature under interdisciplinary contexts (e.g., science, art)\nthat connect reading materials has become popular in elementary schools.\nHowever, constructing such contexts is challenging as it requires teachers to\nexplore substantial amounts of interdisciplinary content and link it to the\nreading materials. In this paper, we develop LitLinker via an iterative design\nprocess involving 13 teachers to facilitate the ideation of interdisciplinary\ncontexts for teaching literature. Powered by a large language model (LLM),\nLitLinker can recommend interdisciplinary topics and contextualize them with\nthe literary elements (e.g., paragraphs, viewpoints) in the reading materials.\nA within-subjects study (N=16) shows that compared to an LLM chatbot, LitLinker\ncan improve the integration depth of different subjects and reduce workload in\nthis ideation task. Expert interviews (N=9) also demonstrate LitLinker's\nusefulness for supporting the ideation of interdisciplinary contexts for\nteaching literature. We conclude with concerns and design considerations for\nsupporting interdisciplinary teaching with LLMs.",
      "tldr_zh": "这篇论文介绍了LitLinker，一种利用Large Language Models (LLM)辅助小学生文学教学的工具，旨在简化跨学科背景（如科学、艺术）的构想过程，以连接阅读材料。研究通过迭代设计过程（涉及13位老师）开发了LitLinker，能够推荐跨学科主题并将其与阅读材料的文学元素（如段落、观点）关联。内主体研究（N=16）显示，与LLM聊天机器人相比，LitLinker显著提高了学科整合深度并降低了老师的工作量。专家访谈（N=9）进一步证实了其实用性，并讨论了使用LLM支持跨学科教学的潜在担忧和设计考虑。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.16097v1",
      "published_date": "2025-02-22 05:40:19 UTC",
      "updated_date": "2025-02-22 05:40:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:32:16.879133"
    },
    {
      "arxiv_id": "2502.17510v1",
      "title": "Recurrent Knowledge Identification and Fusion for Language Model Continual Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Yujie Feng",
        "Xujia Wang",
        "Zexin Lu",
        "Shenghong Fu",
        "Guangyuan Shi",
        "Yongxin Xu",
        "Yasha Wang",
        "Philip S. Yu",
        "Xu Chu",
        "Xiao-Ming Wu"
      ],
      "abstract": "Continual learning (CL) is crucial for deploying large language models (LLMs)\nin dynamic real-world environments without costly retraining. While recent\nmodel ensemble and model merging methods guided by parameter importance have\ngained popularity, they often struggle to balance knowledge transfer and\nforgetting, mainly due to the reliance on static importance estimates during\nsequential training. In this paper, we present Recurrent-KIF, a novel CL\nframework for Recurrent Knowledge Identification and Fusion, which enables\ndynamic estimation of parameter importance distributions to enhance knowledge\ntransfer. Inspired by human continual learning, Recurrent-KIF employs an inner\nloop that rapidly adapts to new tasks while identifying important parameters,\ncoupled with an outer loop that globally manages the fusion of new and\nhistorical knowledge through redundant knowledge pruning and key knowledge\nmerging. These inner-outer loops iteratively perform multiple rounds of fusion,\nallowing Recurrent-KIF to leverage intermediate training information and\nadaptively adjust fusion strategies based on evolving importance distributions.\nExtensive experiments on two CL benchmarks with various model sizes (from 770M\nto 13B) demonstrate that Recurrent-KIF effectively mitigates catastrophic\nforgetting and enhances knowledge transfer.",
      "tldr_zh": "该论文提出了一种名为 Recurrent-KIF 的新框架，用于大型语言模型 (LLMs) 的 Continual Learning (CL)，通过动态估计参数重要性分布来平衡知识转移和遗忘，避免依赖静态估计的局限。Recurrent-KIF 采用内循环快速适应新任务并识别关键参数，外循环则全局管理知识融合，包括冗余知识修剪和关键知识合并，并通过多次迭代调整融合策略。实验在两个 CL 基准上验证了该框架在从 770M 到 13B 的各种模型大小下，能有效缓解灾难性遗忘并显著提升知识转移性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.17510v1",
      "published_date": "2025-02-22 05:37:27 UTC",
      "updated_date": "2025-02-22 05:37:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:32:28.457361"
    },
    {
      "arxiv_id": "2502.16091v2",
      "title": "Privacy-Aware Joint DNN Model Deployment and Partition Optimization for Delay-Efficient Collaborative Edge Inference",
      "title_zh": "翻译失败",
      "authors": [
        "Zhipeng Cheng",
        "Xiaoyu Xia",
        "Hong Wang",
        "Minghui Liwang",
        "Ning Chen",
        "Xuwei Fan",
        "Xianbin Wang"
      ],
      "abstract": "Edge inference (EI) is a key solution to address the growing challenges of\ndelayed response times, limited scalability, and privacy concerns in\ncloud-based Deep Neural Network (DNN) inference. However, deploying DNN models\non resource-constrained edge devices faces more severe challenges, such as\nmodel storage limitations, dynamic service requests, and privacy risks. This\npaper proposes a novel framework for privacy-aware joint DNN model deployment\nand partition optimization to minimize long-term average inference delay under\nresource and privacy constraints. Specifically, the problem is formulated as a\ncomplex optimization problem considering model deployment, user-server\nassociation, and model partition strategies. To handle the NP-hardness and\nfuture uncertainties, a Lyapunov-based approach is introduced to transform the\nlong-term optimization into a single-time-slot problem, ensuring system\nperformance. Additionally, a coalition formation game model is proposed for\nedge server association, and a greedy-based algorithm is developed for model\ndeployment within each coalition to efficiently solve the problem. Extensive\nsimulations show that the proposed algorithms effectively reduce inference\ndelay while satisfying privacy constraints, outperforming baseline approaches\nin various scenarios.",
      "tldr_zh": "这篇论文提出了一种隐私感知的联合DNN模型部署和分区优化框架，旨在最小化边缘推理（Edge Inference）的长期平均延迟，同时满足资源和隐私约束。论文将问题表述为一个优化模型，包括模型部署、用户-服务器关联和模型分区策略，并采用Lyapunov-based方法将长期优化转化为单时隙问题，以处理NP-hard性及其不确定性。此外，通过coalition formation game模型实现边缘服务器关联，并开发greedy-based algorithm进行模型部署。模拟结果表明，该框架显著降低了推理延迟，并在多种场景下优于基准方法，同时有效满足隐私要求。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "cs.NI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.16091v2",
      "published_date": "2025-02-22 05:27:24 UTC",
      "updated_date": "2025-03-01 04:35:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:32:40.074101"
    },
    {
      "arxiv_id": "2502.16090v1",
      "title": "Echo: A Large Language Model with Temporal Episodic Memory",
      "title_zh": "Echo：一种具有时间情节记忆的大型语言模型",
      "authors": [
        "WenTao Liu",
        "Ruohua Zhang",
        "Aimin Zhou",
        "Feng Gao",
        "JiaLi Liu"
      ],
      "abstract": "Research on large language models (LLMs) has shown remarkable performance in\ndomains such as mathematics, programming, and literary creation. However, most\nstudies have focused on semantic memory-based question answering, neglecting\nLLMs' potential to handle episodic memory (EM)-related queries. This oversight\nhas led to suboptimal performance in applications requiring EM, including\nemotional companionship, personal AI assistants, and AI teachers. To address\nthis gap, we introduce Echo, a LLM enhanced with temporal episodic memory. We\npropose a Multi-Agent Data Generation Framework that guides the model in\ngenerating multi-turn, complex scenario episodic memory dialogue data\n(EM-Train). Temporal information is innovatively incorporated into the LLM\ntraining process, and Echo is trained using the EM-Train. Furthermore, We\ndevelop an EM-Test benchmark specifically designed to evaluate LLMs' episodic\nmemory capabilities. The EM-Test assesses performance across various time spans\nand difficulty levels, providing a comprehensive evaluation of multi-turn\nepisodic memory dialogues. Our experiments demonstrate that Echo significantly\noutperforms state-of-the-art LLMs on EM-Test. Additionally, a qualitative\nanalysis reveals Echo's potential to exhibit human-like episodic memory\ncapabilities. We will open-source all datasets, code, and model weights.",
      "tldr_zh": "本研究发现，现有的 Large Language Models (LLMs) 在语义记忆方面表现出色，但忽略了情节记忆 (episodic memory) 的处理，导致在情感陪伴、个人 AI 助手和 AI 教师等应用中表现不佳。为此，提出 Echo，一种增强了时间性情节记忆的 LLM。研究团队开发了 Multi-Agent Data Generation Framework，用于生成多轮复杂场景的情节记忆对话数据 (EM-Train)，并将时间信息融入 LLM 的训练过程。实验结果显示，Echo 在专为评估情节记忆设计的 EM-Test 基准上显著优于最先进模型，并展现出类似人类的记忆能力；所有数据集、代码和模型权重将开源。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.16090v1",
      "published_date": "2025-02-22 05:25:20 UTC",
      "updated_date": "2025-02-22 05:25:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:32:52.894126"
    },
    {
      "arxiv_id": "2503.05755v1",
      "title": "SEAFL: Enhancing Efficiency in Semi-Asynchronous Federated Learning through Adaptive Aggregation and Selective Training",
      "title_zh": "SEAFL：通过自适应聚合和选择性训练提升半异步联邦学习的效率",
      "authors": [
        "Md Sirajul Islam",
        "Sanjeev Panta",
        "Fei Xu",
        "Xu Yuan",
        "Li Chen",
        "Nian-Feng Tzeng"
      ],
      "abstract": "Federated Learning (FL) is a promising distributed machine learning framework\nthat allows collaborative learning of a global model across decentralized\ndevices without uploading their local data. However, in real-world FL\nscenarios, the conventional synchronous FL mechanism suffers from inefficient\ntraining caused by slow-speed devices, commonly known as stragglers, especially\nin heterogeneous communication environments. Though asynchronous FL effectively\ntackles the efficiency challenge, it induces substantial system overheads and\nmodel degradation. Striking for a balance, semi-asynchronous FL has gained\nincreasing attention, while still suffering from the open challenge of stale\nmodels, where newly arrived updates are calculated based on outdated weights\nthat easily hurt the convergence of the global model. In this paper, we present\n{\\em SEAFL}, a novel FL framework designed to mitigate both the straggler and\nthe stale model challenges in semi-asynchronous FL. {\\em SEAFL} dynamically\nassigns weights to uploaded models during aggregation based on their staleness\nand importance to the current global model. We theoretically analyze the\nconvergence rate of {\\em SEAFL} and further enhance the training efficiency\nwith an extended variant that allows partial training on slower devices,\nenabling them to contribute to global aggregation while reducing excessive\nwaiting times. We evaluate the effectiveness of {\\em SEAFL} through extensive\nexperiments on three benchmark datasets. The experimental results demonstrate\nthat {\\em SEAFL} outperforms its closest counterpart by up to $\\sim$22\\% in\nterms of the wall-clock training time required to achieve target accuracy.",
      "tldr_zh": "本研究针对 Federated Learning (FL) 中同步机制受 stragglers 影响的效率问题，以及异步 FL 带来的系统开销和模型退化，提出了一种新型框架 SEAFL，用于优化半异步 FL。SEAFL 通过 adaptive aggregation 动态分配权重给上传的模型，基于其 staleness 和对当前全局模型的重要性，从而缓解 stale models 的挑战；同时，引入 selective training 允许慢速设备进行部分训练，以减少等待时间。研究还对 SEAFL 的收敛率进行了理论分析，并扩展了其变体以进一步提升训练效率。在三个基准数据集上的实验结果显示，SEAFL 比最接近的竞争对手在达到目标准确率时将墙钟训练时间缩短高达 22%。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.05755v1",
      "published_date": "2025-02-22 05:13:53 UTC",
      "updated_date": "2025-02-22 05:13:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:33:02.602531"
    },
    {
      "arxiv_id": "2502.16079v1",
      "title": "Together We Rise: Optimizing Real-Time Multi-Robot Task Allocation using Coordinated Heterogeneous Plays",
      "title_zh": "Together We Rise：",
      "authors": [
        "Aritra Pal",
        "Anandsingh Chauhan",
        "Mayank Baranwal"
      ],
      "abstract": "Efficient task allocation among multiple robots is crucial for optimizing\nproductivity in modern warehouses, particularly in response to the increasing\ndemands of online order fulfillment. This paper addresses the real-time\nmulti-robot task allocation (MRTA) problem in dynamic warehouse environments,\nwhere tasks emerge with specified start and end locations. The objective is to\nminimize both the total travel distance of robots and delays in task\ncompletion, while also considering practical constraints such as battery\nmanagement and collision avoidance. We introduce MRTAgent, a dual-agent\nReinforcement Learning (RL) framework inspired by self-play, designed to\noptimize task assignments and robot selection to ensure timely task execution.\nFor safe navigation, a modified linear quadratic controller (LQR) approach is\nemployed. To the best of our knowledge, MRTAgent is the first framework to\naddress all critical aspects of practical MRTA problems while supporting\ncontinuous robot movements.",
      "tldr_zh": "该论文针对动态仓库环境中的实时多机器人任务分配（MRTA）问题，旨在最小化机器人总旅行距离和任务延迟，同时考虑电池管理和碰撞避免等实际约束。研究引入了 MRTAgent，一个基于自对弈的双智能体强化学习（RL）框架，用于优化任务分配和机器人选择，确保高效执行。论文还采用修改后的线性二次控制器（LQR）来实现安全导航，并声称 MRTAgent 是首个全面处理这些关键方面的框架，支持连续机器人运动，从而提升仓库生产力。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG",
        "cs.MA",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted to AAMAS 2025 (AAAI Track)",
      "pdf_url": "http://arxiv.org/pdf/2502.16079v1",
      "published_date": "2025-02-22 04:59:27 UTC",
      "updated_date": "2025-02-22 04:59:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:33:14.545978"
    },
    {
      "arxiv_id": "2503.10642v1",
      "title": "Text2Zinc: A Cross-Domain Dataset for Modeling Optimization and Satisfaction Problems in MiniZinc",
      "title_zh": "翻译失败",
      "authors": [
        "Akash Singirikonda",
        "Serdar Kadioglu",
        "Karthik Uppuluri"
      ],
      "abstract": "There is growing interest in utilizing large language models (LLMs) as\nco-pilots for combinatorial optimization and constraint programming tasks\nacross various problems. This paper aims to advance this line of research by\nintroducing Text2Zinc}, a cross-domain dataset for capturing optimization and\nsatisfaction problems specified in natural language text. Our work is\ndistinguished from previous attempts by integrating both satisfaction and\noptimization problems within a unified dataset using a solver-agnostic modeling\nlanguage. To achieve this, we leverage MiniZinc's solver-and-paradigm-agnostic\nmodeling capabilities to formulate these problems. Using the Text2Zinc dataset,\nwe conduct comprehensive baseline experiments to compare execution and solution\naccuracy across several methods, including off-the-shelf prompting strategies,\nchain-of-thought reasoning, and a compositional approach. Additionally, we\nexplore the effectiveness of intermediary representations, specifically\nknowledge graphs. Our findings indicate that LLMs are not yet a push-button\ntechnology to model combinatorial problems from text. We hope that Text2Zinc\nserves as a valuable resource for researchers and practitioners to advance the\nfield further.",
      "tldr_zh": "本研究引入了 Text2Zinc 数据集，这是一个跨领域数据集，用于从自然语言文本中建模优化和满足问题，并采用 MiniZinc 作为统一的、求解器无关的建模语言。研究者通过该数据集进行了基线实验，比较了多种方法如提示策略、Chain-of-Thought 推理和组合方法的效果，并探讨了知识 graphs 等中间表示的作用。结果显示，LLMs 目前还无法直接轻松地从文本中建模组合问题，但 Text2Zinc 可作为宝贵资源，推动相关领域的研究进展。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.10642v1",
      "published_date": "2025-02-22 04:13:53 UTC",
      "updated_date": "2025-02-22 04:13:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:33:26.476006"
    },
    {
      "arxiv_id": "2502.18506v1",
      "title": "Exploring Patient Data Requirements in Training Effective AI Models for MRI-based Breast Cancer Classification",
      "title_zh": "探索患者数据需求以训练有效的AI模型，用于基于MRI的乳腺癌分类",
      "authors": [
        "Solha Kang",
        "Wesley De Neve",
        "Francois Rameau",
        "Utku Ozbulak"
      ],
      "abstract": "The past decade has witnessed a substantial increase in the number of\nstartups and companies offering AI-based solutions for clinical decision\nsupport in medical institutions. However, the critical nature of medical\ndecision-making raises several concerns about relying on external software. Key\nissues include potential variations in image modalities and the medical devices\nused to obtain these images, potential legal issues, and adversarial attacks.\nFortunately, the open-source nature of machine learning research has made\nfoundation models publicly available and straightforward to use for medical\napplications. This accessibility allows medical institutions to train their own\nAI-based models, thereby mitigating the aforementioned concerns. Given this\ncontext, an important question arises: how much data do medical institutions\nneed to train effective AI models? In this study, we explore this question in\nrelation to breast cancer detection, a particularly contested area due to the\nprevalence of this disease, which affects approximately 1 in every 8 women.\nThrough large-scale experiments on various patient sizes in the training set,\nwe show that medical institutions do not need a decade's worth of MRI images to\ntrain an AI model that performs competitively with the state-of-the-art,\nprovided the model leverages foundation models. Furthermore, we observe that\nfor patient counts greater than 50, the number of patients in the training set\nhas a negligible impact on the performance of models and that simple ensembles\nfurther improve the results without additional complexity.",
      "tldr_zh": "本研究探讨了医疗机构在训练有效 AI 模型用于 MRI-based Breast Cancer Classification 时所需患者数据的数量，旨在解决外部软件依赖带来的图像模式差异、法律问题和攻击风险等担忧。通过大规模实验，研究者利用 foundation models 测试不同训练集患者规模，结果显示无需十年的 MRI 图像数据即可实现与最先进模型相当的性能；当训练集患者超过 50 人时，患者数量对模型表现的影响 negligible，且采用简单 ensembles 可以进一步提升结果而不增加复杂性。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "Accepted for publication in MICCAI 2024 Deep Breast Workshop on AI\n  and Imaging for Diagnostic and Treatment Challenges in Breast Care",
      "pdf_url": "http://arxiv.org/pdf/2502.18506v1",
      "published_date": "2025-02-22 04:04:52 UTC",
      "updated_date": "2025-02-22 04:04:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:33:39.760123"
    },
    {
      "arxiv_id": "2502.16069v2",
      "title": "Curie: Toward Rigorous and Automated Scientific Experimentation with AI Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Patrick Tser Jern Kon",
        "Jiachen Liu",
        "Qiuyi Ding",
        "Yiming Qiu",
        "Zhenning Yang",
        "Yibo Huang",
        "Jayanth Srinivasa",
        "Myungjin Lee",
        "Mosharaf Chowdhury",
        "Ang Chen"
      ],
      "abstract": "Scientific experimentation, a cornerstone of human progress, demands rigor in\nreliability, methodical control, and interpretability to yield meaningful\nresults. Despite the growing capabilities of large language models (LLMs) in\nautomating different aspects of the scientific process, automating rigorous\nexperimentation remains a significant challenge. To address this gap, we\npropose Curie, an AI agent framework designed to embed rigor into the\nexperimentation process through three key components: an intra-agent rigor\nmodule to enhance reliability, an inter-agent rigor module to maintain\nmethodical control, and an experiment knowledge module to enhance\ninterpretability. To evaluate Curie, we design a novel experimental benchmark\ncomposed of 46 questions across four computer science domains, derived from\ninfluential research papers, and widely adopted open-source projects. Compared\nto the strongest baseline tested, we achieve a 3.4$\\times$ improvement in\ncorrectly answering experimental questions. Curie is open-sourced at\nhttps://github.com/Just-Curieous/Curie.",
      "tldr_zh": "该论文提出 Curie 框架，一种用于自动化科学实验的 AI 代理系统，旨在通过 intra-agent rigor module 提升代理内部的可靠性、inter-agent rigor module 维护代理间的系统方法控制，以及 experiment knowledge module 增强实验的可解释性，以解决 large language models (LLMs) 在严格实验自动化方面的挑战。研究设计了一个包含 46 个问题的基准测试，覆盖四个计算机科学领域，包括影响性论文和开源项目。结果显示，Curie 相较于最强基线在正确回答实验问题上提升了 3.4 倍，并已开源在 GitHub 上，促进进一步应用和发展。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "21 pages",
      "pdf_url": "http://arxiv.org/pdf/2502.16069v2",
      "published_date": "2025-02-22 03:58:19 UTC",
      "updated_date": "2025-02-26 02:33:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:33:52.006241"
    },
    {
      "arxiv_id": "2502.16065v1",
      "title": "A Survey of Model Extraction Attacks and Defenses in Distributed Computing Environments",
      "title_zh": "分布式计算环境中的模型提取攻击与防御综述",
      "authors": [
        "Kaixiang Zhao",
        "Lincan Li",
        "Kaize Ding",
        "Neil Zhenqiang Gong",
        "Yue Zhao",
        "Yushun Dong"
      ],
      "abstract": "Model Extraction Attacks (MEAs) threaten modern machine learning systems by\nenabling adversaries to steal models, exposing intellectual property and\ntraining data. With the increasing deployment of machine learning models in\ndistributed computing environments, including cloud, edge, and federated\nlearning settings, each paradigm introduces distinct vulnerabilities and\nchallenges. Without a unified perspective on MEAs across these distributed\nenvironments, organizations risk fragmented defenses, inadequate risk\nassessments, and substantial economic and privacy losses. This survey is\nmotivated by the urgent need to understand how the unique characteristics of\ncloud, edge, and federated deployments shape attack vectors and defense\nrequirements. We systematically examine the evolution of attack methodologies\nand defense mechanisms across these environments, demonstrating how\nenvironmental factors influence security strategies in critical sectors such as\nautonomous vehicles, healthcare, and financial services. By synthesizing recent\nadvances in MEAs research and discussing the limitations of current evaluation\npractices, this survey provides essential insights for developing robust and\nadaptive defense strategies. Our comprehensive approach highlights the\nimportance of integrating protective measures across the entire distributed\ncomputing landscape to ensure the secure deployment of machine learning models.",
      "tldr_zh": "这篇调查论文探讨了Model Extraction Attacks (MEAs)在分布式计算环境（如cloud、edge和federated learning）中的威胁和防御策略，强调了这些环境独特特性的影响，导致潜在的知识产权和隐私损失。\n论文系统地审视了攻击方法演变、防御机制以及环境因素对安全策略的作用，涵盖关键领域如自动驾驶、健康和金融服务。\n通过总结最近研究进展和评估实践的局限性，该文为开发整合式、适应性强的防御措施提供了重要见解，以确保机器学习模型的安全部署。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.16065v1",
      "published_date": "2025-02-22 03:46:50 UTC",
      "updated_date": "2025-02-22 03:46:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:34:03.094911"
    },
    {
      "arxiv_id": "2502.16060v1",
      "title": "Single-Channel EEG Tokenization Through Time-Frequency Modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Jathurshan Pradeepkumar",
        "Xihao Piao",
        "Zheng Chen",
        "Jimeng Sun"
      ],
      "abstract": "We introduce TFM-Tokenizer, a novel tokenization framework tailored for EEG\nanalysis that transforms continuous, noisy brain signals into a sequence of\ndiscrete, well-represented tokens for various EEG tasks. Conventional\napproaches typically rely on continuous embeddings and inter-channel\ndependencies, which are limited in capturing inherent EEG features such as\ntemporally unpredictable patterns and diverse oscillatory waveforms. In\ncontrast, we hypothesize that critical time-frequency features can be\neffectively captured from a single channel. By learning tokens that encapsulate\nthese intrinsic patterns within a single channel, our approach yields a\nscalable tokenizer adaptable across diverse EEG settings. We integrate the\nTFM-Tokenizer with a transformer-based TFM-Encoder, leveraging established\npretraining techniques from natural language processing, such as masked token\nprediction, followed by downstream fine-tuning for various EEG tasks.\nExperiments across four EEG datasets show that TFM-Token outperforms\nstate-of-the-art methods. On TUEV, our approach improves balanced accuracy and\nCohen's Kappa by 5% over baselines. Comprehensive analysis of the learned\ntokens demonstrates their ability to capture class-distinctive features,\nenhance frequency representation, and ability to encode time-frequency motifs\ninto distinct tokens, improving interpretability.",
      "tldr_zh": "本文提出 TFM-Tokenizer，一种专为单通道 EEG 分析设计的 tokenization 框架，将连续的嘈杂脑信号转化为离散的 tokens，从而更好地捕捉 EEG 的时间-频率特征。不同于传统方法依赖通道间依赖，该框架假设关键特征可从单个通道获取，并将其与基于 Transformer 的 TFM-Encoder 整合，使用 masked token prediction 等 NLP 预训练技术进行下游任务微调。在四个 EEG 数据集的实验中，TFM-Tokenizer 优于现有方法，在 TUEV 数据集上将平衡准确率和 Cohen's Kappa 提高了 5%。此外，该框架的 tokens 能够捕获类别特异性特征、增强频率表示，并提高 EEG 分析的可解释性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.16060v1",
      "published_date": "2025-02-22 03:32:36 UTC",
      "updated_date": "2025-02-22 03:32:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:34:16.438150"
    },
    {
      "arxiv_id": "2502.16054v2",
      "title": "Human-AI Collaboration in Cloud Security: Cognitive Hierarchy-Driven Deep Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Zahra Aref",
        "Sheng Wei",
        "Narayan B. Mandayam"
      ],
      "abstract": "Given the complexity of multi-tenant cloud environments and the growing need\nfor real-time threat mitigation, Security Operations Centers (SOCs) must adopt\nAI-driven adaptive defense mechanisms to counter Advanced Persistent Threats\n(APTs). However, SOC analysts face challenges in handling adaptive adversarial\ntactics, requiring intelligent decision-support frameworks. We propose a\nCognitive Hierarchy Theory-driven Deep Q-Network (CHT-DQN) framework that\nmodels interactive decision-making between SOC analysts and AI-driven APT bots.\nThe SOC analyst (defender) operates at cognitive level-1, anticipating attacker\nstrategies, while the APT bot (attacker) follows a level-0 policy. By\nincorporating CHT into DQN, our framework enhances adaptive SOC defense using\nAttack Graph (AG)-based reinforcement learning. Simulation experiments across\nvarying AG complexities show that CHT-DQN consistently achieves higher data\nprotection and lower action discrepancies compared to standard DQN. A\ntheoretical lower bound further confirms its superiority as AG complexity\nincreases. A human-in-the-loop (HITL) evaluation on Amazon Mechanical Turk\n(MTurk) reveals that SOC analysts using CHT-DQN-derived transition\nprobabilities align more closely with adaptive attackers, leading to better\ndefense outcomes. Moreover, human behavior aligns with Prospect Theory (PT) and\nCumulative Prospect Theory (CPT): participants are less likely to reselect\nfailed actions and more likely to persist with successful ones. This asymmetry\nreflects amplified loss sensitivity and biased probability weighting --\nunderestimating gains after failure and overestimating continued success. Our\nfindings highlight the potential of integrating cognitive models into deep\nreinforcement learning to improve real-time SOC decision-making for cloud\nsecurity.",
      "tldr_zh": "该论文提出了一种基于Cognitive Hierarchy Theory的Deep Q-Network (CHT-DQN)框架，以提升云安全中SOC分析师与AI的协作决策，针对多租户环境中的Advanced Persistent Threats (APTs)提供适应性防御。框架将认知层次理论融入强化学习，利用Attack Graph (AG)模拟防御者（SOC分析师在水平1预测攻击）和攻击者（水平0策略）的互动，从而优化实时决策。实验结果显示，CHT-DQN在不同AG复杂度下比标准DQN实现更高的数据保护和更低行动差异，并在人机交互测试中证明人类行为符合Prospect Theory (PT)和Cumulative Prospect Theory (CPT)，如避免重复失败行动并偏好持续成功策略，最终增强云安全的决策效能。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.16054v2",
      "published_date": "2025-02-22 03:19:21 UTC",
      "updated_date": "2025-04-20 16:40:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:34:29.420869"
    },
    {
      "arxiv_id": "2503.05753v1",
      "title": "Exploring AI Writers: Technology, Impact, and Future Prospects",
      "title_zh": "翻译失败",
      "authors": [
        "Zhiqian Huang"
      ],
      "abstract": "This study explores the practical capabilities of AI writers, focusing on\ntheir applications across various creative domains. It delves into the\npotential impact of AI-generated content on traditional media industries and\nacademic writing processes. The research examines how AI tools are reshaping\nnews production workflows, particularly in fields such as finance, sports, and\nnatural disasters. Additionally, it addresses ethical concerns, including\nauthorship and copyright issues arising from AI-driven creative outputs. The\nfindings reveal mixed perceptions among media students regarding the\nintegration of AI into their profession, reflecting both optimism about\nefficiency gains and apprehensions over increased job market competition.",
      "tldr_zh": "这篇论文探讨了 AI Writers 的技术能力及其在创意领域的应用，包括对传统媒体产业和学术写作流程的影响。研究重点分析了 AI 在新闻生产中的作用，例如在金融、体育和自然灾害报道领域的变革，同时讨论了伦理问题，如作者权和版权争议。结果显示，媒体学生对 AI 整合持混合态度，既乐观于效率提升，也担忧就业市场竞争加剧。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.05753v1",
      "published_date": "2025-02-22 02:03:09 UTC",
      "updated_date": "2025-02-22 02:03:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:34:40.288267"
    },
    {
      "arxiv_id": "2502.16033v2",
      "title": "Multimodal Inconsistency Reasoning (MMIR): A New Benchmark for Multimodal Reasoning Models",
      "title_zh": "多模态不一致性推理 (MMIR)：一种用于多模态推理模型的新基准测试",
      "authors": [
        "Qianqi Yan",
        "Yue Fan",
        "Hongquan Li",
        "Shan Jiang",
        "Yang Zhao",
        "Xinze Guan",
        "Ching-Chen Kuo",
        "Xin Eric Wang"
      ],
      "abstract": "Existing Multimodal Large Language Models (MLLMs) are predominantly trained\nand tested on consistent visual-textual inputs, leaving open the question of\nwhether they can handle inconsistencies in real-world, layout-rich content. To\nbridge this gap, we propose the Multimodal Inconsistency Reasoning (MMIR)\nbenchmark to assess MLLMs' ability to detect and reason about semantic\nmismatches in artifacts such as webpages, presentation slides, and posters.\nMMIR comprises 534 challenging samples, each containing synthetically injected\nerrors across five reasoning-heavy categories: Factual Contradiction, Identity\nMisattribution, Contextual Mismatch, Quantitative Discrepancy, and\nTemporal/Spatial Incoherence. We evaluate six state-of-the-art MLLMs, showing\nthat models with dedicated multimodal reasoning capabilities, such as o1,\nsubstantially outperform their counterparts while open-source models remain\nparticularly vulnerable to inconsistency errors. Detailed error analyses\nfurther show that models excel in detecting pairwise inconsistencies but\nstruggle with inconsistencies confined to single elements in complex layouts.\nProbing experiments reveal that single-modality prompting, including\nChain-of-Thought (CoT) and Set-of-Mark (SoM) methods, yields marginal gains,\nrevealing a key bottleneck in cross-modal reasoning. Our findings highlight the\nneed for advanced multimodal reasoning and point to future research on\nmultimodal inconsistency.",
      "tldr_zh": "本研究提出 Multimodal Inconsistency Reasoning (MMIR) 基准，用于评估 Multimodal Large Language Models (MLLMs) 在处理真实世界多模态不一致性（如网页、幻灯片和海报中的语义不匹配）方面的能力。MMIR 包含 534 个样本，涵盖五类推理密集型错误：Factual Contradiction、Identity Misattribution、Contextual Mismatch、Quantitative Discrepancy 和 Temporal/Spatial Incoherence。实验评估六种最先进 MLLMs 显示，模型如 o1 在检测成对不一致性上表现出色，但开源模型易受影响，且在复杂布局中处理单个元素不一致性时表现较差；此外，单模态提示方法如 Chain-of-Thought (CoT) 和 Set-of-Mark (SoM) 效果有限，突显了跨模态推理的瓶颈，并为未来多模态研究提供方向。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.16033v2",
      "published_date": "2025-02-22 01:52:37 UTC",
      "updated_date": "2025-03-04 08:23:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:34:53.357261"
    },
    {
      "arxiv_id": "2502.16032v2",
      "title": "Clinical Inspired MRI Lesion Segmentation",
      "title_zh": "临床启发的 MRI 病变分割",
      "authors": [
        "Lijun Yan",
        "Churan Wang",
        "Fangwei Zhong",
        "Yizhou Wang"
      ],
      "abstract": "Magnetic resonance imaging (MRI) is a potent diagnostic tool for detecting\npathological tissues in various diseases. Different MRI sequences have\ndifferent contrast mechanisms and sensitivities for different types of lesions,\nwhich pose challenges to accurate and consistent lesion segmentation. In\nclinical practice, radiologists commonly use the sub-sequence feature, i.e. the\ndifference between post contrast-enhanced T1-weighted (post) and\npre-contrast-enhanced (pre) sequences, to locate lesions. Inspired by this, we\npropose a residual fusion method to learn subsequence representation for MRI\nlesion segmentation. Specifically, we iteratively and adaptively fuse features\nfrom pre- and post-contrast sequences at multiple resolutions, using dynamic\nweights to achieve optimal fusion and address diverse lesion enhancement\npatterns. Our method achieves state-of-the-art performances on BraTS2023\ndataset for brain tumor segmentation and our in-house breast MRI dataset for\nbreast lesion segmentation. Our method is clinically inspired and has the\npotential to facilitate lesion segmentation in various applications.",
      "tldr_zh": "本研究受临床实践启发，提出一种残差融合方法，用于MRI病变分割，特别利用pre-contrast-enhanced和post-contrast-enhanced T1-weighted序列的差异来定位病变。方法通过迭代和自适应地在多个分辨率下融合特征，使用动态权重优化融合，以处理各种病变增强模式。实验结果显示，该方法在BraTS2023数据集上实现脑肿瘤分割的最新性能，并在内部乳腺MRI数据集上表现出色，具有潜力应用于多种临床场景。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "accepted in ISBI2025 oral",
      "pdf_url": "http://arxiv.org/pdf/2502.16032v2",
      "published_date": "2025-02-22 01:37:35 UTC",
      "updated_date": "2025-05-12 09:34:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:35:02.556190"
    },
    {
      "arxiv_id": "2502.16030v1",
      "title": "Real Time Offside Detection using a Single Camera in Soccer",
      "title_zh": "翻译失败",
      "authors": [
        "Shounak Desai"
      ],
      "abstract": "Technological advancements in soccer have surged over the past decade,\ntransforming aspects of the sport. Unlike binary rules, many soccer\nregulations, such as the \"Offside Rule,\" rely on subjective interpretation\nrather than straightforward True or False criteria. The on-field referee holds\nultimate authority in adjudicating these nuanced decisions. A significant\nbreakthrough in soccer officiating is the Video Assistant Referee (VAR) system,\nleveraging a network of 20-30 cameras within stadiums to minimize human errors.\nVAR's operational scope typically encompasses 10-30 cameras, ensuring high\ndecision accuracy but at a substantial cost. This report proposes an innovative\napproach to offside detection using a single camera, such as the broadcasting\ncamera, to mitigate expenses associated with sophisticated technological\nsetups.",
      "tldr_zh": "本研究针对足球越位规则的主观判断问题，提出了一种使用单个摄像头（如广播摄像头）进行实时越位检测的创新方法，以降低传统 Video Assistant Referee (VAR) 系统所需的20-30个摄像头带来的高成本。不同于依赖多摄像头网络的VAR，该方法简化了技术设置，同时维持决策准确性。实验结果未详细说明，但此方案有望提升足球裁判辅助的可访问性和效率。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "5 pages 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.16030v1",
      "published_date": "2025-02-22 01:33:26 UTC",
      "updated_date": "2025-02-22 01:33:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:35:14.070421"
    },
    {
      "arxiv_id": "2503.16457v1",
      "title": "Integrating Personality into Digital Humans: A Review of LLM-Driven Approaches for Virtual Reality",
      "title_zh": "翻译失败",
      "authors": [
        "Iago Alves Brito",
        "Julia Soares Dollis",
        "Fernanda Bufon Färber",
        "Pedro Schindler Freire Brasil Ribeiro",
        "Rafael Teixeira Sousa",
        "Arlindo Rodrigues Galvão Filho"
      ],
      "abstract": "The integration of large language models (LLMs) into virtual reality (VR)\nenvironments has opened new pathways for creating more immersive and\ninteractive digital humans. By leveraging the generative capabilities of LLMs\nalongside multimodal outputs such as facial expressions and gestures, virtual\nagents can simulate human-like personalities and emotions, fostering richer and\nmore engaging user experiences. This paper provides a comprehensive review of\nmethods for enabling digital humans to adopt nuanced personality traits,\nexploring approaches such as zero-shot, few-shot, and fine-tuning.\nAdditionally, it highlights the challenges of integrating LLM-driven\npersonality traits into VR, including computational demands, latency issues,\nand the lack of standardized evaluation frameworks for multimodal interactions.\nBy addressing these gaps, this work lays a foundation for advancing\napplications in education, therapy, and gaming, while fostering\ninterdisciplinary collaboration to redefine human-computer interaction in VR.",
      "tldr_zh": "这篇论文综述了将大型语言模型（LLMs）整合到虚拟现实（VR）环境中的方法，以增强数字人类的个性模拟。作者探讨了多种驱动个性特质的策略，包括 zero-shot、few-shot 和 fine-tuning 技术，这些方法结合 LLMs 的生成能力与多模态输出（如面部表情和手势），从而创建更具沉浸感和互动性的虚拟代理。论文突出了整合挑战，如计算需求、延迟问题和缺乏标准评估框架，并强调此举为教育、治疗和游戏应用奠定基础，促进跨学科合作以重塑 VR 中的人机交互。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16457v1",
      "published_date": "2025-02-22 01:33:05 UTC",
      "updated_date": "2025-02-22 01:33:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:35:26.244191"
    },
    {
      "arxiv_id": "2502.17507v1",
      "title": "C-3DPO: Constrained Controlled Classification for Direct Preference Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Kavosh Asadi",
        "Julien Han",
        "Xingzi Xu",
        "Dominique Perrault-Joncas",
        "Shoham Sabach",
        "Karim Bouyarmane",
        "Mohammad Ghavamzadeh"
      ],
      "abstract": "Direct preference optimization (DPO)-style algorithms have emerged as a\npromising approach for solving the alignment problem in AI. We present a novel\nperspective that formulates these algorithms as implicit classification\nalgorithms. This classification framework enables us to recover many variants\nof DPO-style algorithms by choosing appropriate classification labels and loss\nfunctions. We then leverage this classification framework to demonstrate that\nthe underlying problem solved in these algorithms is under-specified, making\nthem susceptible to probability collapse of the winner-loser responses. We\naddress this by proposing a set of constraints designed to control the movement\nof probability mass between the winner and loser in the reference and target\npolicies. Our resulting algorithm, which we call Constrained Controlled\nClassification DPO (\\texttt{C-3DPO}), has a meaningful RLHF interpretation. By\nhedging against probability collapse, \\texttt{C-3DPO} provides practical\nimprovements over vanilla \\texttt{DPO} when aligning several large language\nmodels using standard preference datasets.",
      "tldr_zh": "本文将直接偏好优化(DPO)算法重新表述为隐式分类算法，通过选择合适的分类标签和损失函数来恢复其多种变体，并揭示DPO易受获胜者-失败者响应概率崩溃的问题。作者提出C-3DPO算法，通过添加约束来控制参考策略和目标策略之间概率质量的移动，从而防范这一问题。实验结果显示，C-3DPO在使用标准偏好数据集对齐大语言模型时，比传统DPO实现了实际性能提升，并提供了RLHF的解释框架。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.17507v1",
      "published_date": "2025-02-22 00:38:44 UTC",
      "updated_date": "2025-02-22 00:38:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:35:39.440115"
    },
    {
      "arxiv_id": "2502.17506v2",
      "title": "RAG-Enhanced Collaborative LLM Agents for Drug Discovery",
      "title_zh": "翻译失败",
      "authors": [
        "Namkyeong Lee",
        "Edward De Brouwer",
        "Ehsan Hajiramezanali",
        "Tommaso Biancalani",
        "Chanyoung Park",
        "Gabriele Scalia"
      ],
      "abstract": "Recent advances in large language models (LLMs) have shown great potential to\naccelerate drug discovery. However, the specialized nature of biochemical data\noften necessitates costly domain-specific fine-tuning, posing critical\nchallenges. First, it hinders the application of more flexible general-purpose\nLLMs in cutting-edge drug discovery tasks. More importantly, it impedes the\nrapid integration of the vast amounts of scientific data continuously generated\nthrough experiments and research. To investigate these challenges, we propose\nCLADD, a retrieval-augmented generation (RAG)-empowered agentic system tailored\nto drug discovery tasks. Through the collaboration of multiple LLM agents,\nCLADD dynamically retrieves information from biomedical knowledge bases,\ncontextualizes query molecules, and integrates relevant evidence to generate\nresponses -- all without the need for domain-specific fine-tuning. Crucially,\nwe tackle key obstacles in applying RAG workflows to biochemical data,\nincluding data heterogeneity, ambiguity, and multi-source integration. We\ndemonstrate the flexibility and effectiveness of this framework across a\nvariety of drug discovery tasks, showing that it outperforms general-purpose\nand domain-specific LLMs as well as traditional deep learning approaches.",
      "tldr_zh": "本文提出 CLADD，一种基于检索增强生成 (RAG) 的多代理大型语言模型 (LLM) 系统，旨在解决药物发现中生化数据专业性带来的挑战，如领域特定微调的成本和科学数据的快速整合问题。该系统通过多个 LLM 代理协作，从生物医学知识库动态检索信息、上下文化查询分子并整合证据，从而生成响应，而无需进行领域特定微调。实验结果显示，CLADD 在各种药物发现任务中表现出色，优于通用和领域特定 LLMs 以及传统深度学习方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Machine Learning, Drug Discovery",
      "pdf_url": "http://arxiv.org/pdf/2502.17506v2",
      "published_date": "2025-02-22 00:12:52 UTC",
      "updated_date": "2025-03-10 12:11:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:35:51.658074"
    },
    {
      "arxiv_id": "2502.16012v1",
      "title": "Cross-Model Transferability of Adversarial Patches in Real-time Segmentation for Autonomous Driving",
      "title_zh": "翻译失败",
      "authors": [
        "Prashant Shekhar",
        "Bidur Devkota",
        "Dumindu Samaraweera",
        "Laxima Niure Kandel",
        "Manoj Babu"
      ],
      "abstract": "Adversarial attacks pose a significant threat to deep learning models,\nparticularly in safety-critical applications like healthcare and autonomous\ndriving. Recently, patch based attacks have demonstrated effectiveness in\nreal-time inference scenarios owing to their 'drag and drop' nature. Following\nthis idea for Semantic Segmentation (SS), here we propose a novel Expectation\nOver Transformation (EOT) based adversarial patch attack that is more realistic\nfor autonomous vehicles. To effectively train this attack we also propose a\n'simplified' loss function that is easy to analyze and implement. Using this\nattack as our basis, we investigate whether adversarial patches once optimized\non a specific SS model, can fool other models or architectures. We conduct a\ncomprehensive cross-model transferability analysis of adversarial patches\ntrained on SOTA Convolutional Neural Network (CNN) models such PIDNet-S,\nPIDNet-M and PIDNet-L, among others. Additionally, we also include the\nSegformer model to study transferability to Vision Transformers (ViTs). All of\nour analysis is conducted on the widely used Cityscapes dataset. Our study\nreveals key insights into how model architectures (CNN vs CNN or CNN vs.\nTransformer-based) influence attack susceptibility. In particular, we conclude\nthat although the transferability (effectiveness) of attacks on unseen images\nof any dimension is really high, the attacks trained against one particular\nmodel are minimally effective on other models. And this was found to be true\nfor both ViT and CNN based models. Additionally our results also indicate that\nfor CNN-based models, the repercussions of patch attacks are local, unlike\nViTs. Per-class analysis reveals that simple-classes like 'sky' suffer less\nmisclassification than others. The code for the project is available at:\nhttps://github.com/p-shekhar/adversarial-patch-transferability",
      "tldr_zh": "这篇论文探讨了在自动驾驶实时语义分割（Semantic Segmentation）中的对抗性补丁攻击（adversarial patches）的跨模型转移性，提出了一种基于 Expectation Over Transformation (EOT) 的新攻击方法，并使用简化的损失函数进行训练。研究重点分析了这些攻击从特定 Convolutional Neural Network (CNN) 模型（如 PIDNet-S、PIDNet-M 和 PIDNet-L）转移到其他模型（如 Vision Transformers (ViTs) 的 Segformer）的效果。实验结果显示，虽然攻击在同一模型的未见图像上高度有效，但对其他模型的转移性较低，且 CNN 模型的攻击影响更局限于局部区域，而 ViTs 模型表现出不同模式；此外，简单类别如 'sky' 较少受误分类影响。代码已在 GitHub 上开源，提供进一步验证。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.16012v1",
      "published_date": "2025-02-22 00:03:53 UTC",
      "updated_date": "2025-02-22 00:03:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:36:05.092810"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 83,
  "processed_papers_count": 83,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-23T17:36:26.715832"
}