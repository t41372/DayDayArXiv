[
  {
    "arxiv_id": "2401.06171v1",
    "title": "Harnessing Artificial Intelligence for Sustainable Agricultural Development in Africa: Opportunities, Challenges, and Impact",
    "authors": [
      "Kinyua Gikunda"
    ],
    "abstract": "This paper explores the transformative potential of artificial intelligence\n(AI) in the context of sustainable agricultural development across diverse\nregions in Africa. Delving into opportunities, challenges, and impact, the\nstudy navigates through the dynamic landscape of AI applications in\nagriculture. Opportunities such as precision farming, crop monitoring, and\nclimate-resilient practices are examined, alongside challenges related to\ntechnological infrastructure, data accessibility, and skill gaps. The article\nanalyzes the impact of AI on smallholder farmers, supply chains, and inclusive\ngrowth. Ethical considerations and policy implications are also discussed,\noffering insights into responsible AI integration. By providing a nuanced\nunderstanding, this paper contributes to the ongoing discourse on leveraging AI\nfor fostering sustainability in African agriculture.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.06171v1",
    "published_date": "2024-01-03 23:02:13 UTC",
    "updated_date": "2024-01-03 23:02:13 UTC"
  },
  {
    "arxiv_id": "2401.01993v1",
    "title": "On Time-Indexing as Inductive Bias in Deep RL for Sequential Manipulation Tasks",
    "authors": [
      "M. Nomaan Qureshi",
      "Ben Eisner",
      "David Held"
    ],
    "abstract": "While solving complex manipulation tasks, manipulation policies often need to\nlearn a set of diverse skills to accomplish these tasks. The set of skills is\noften quite multimodal - each one may have a quite distinct distribution of\nactions and states. Standard deep policy-learning algorithms often model\npolicies as deep neural networks with a single output head (deterministic or\nstochastic). This structure requires the network to learn to switch between\nmodes internally, which can lead to lower sample efficiency and poor\nperformance. In this paper we explore a simple structure which is conducive to\nskill learning required for so many of the manipulation tasks. Specifically, we\npropose a policy architecture that sequentially executes different action heads\nfor fixed durations, enabling the learning of primitive skills such as reaching\nand grasping. Our empirical evaluation on the Metaworld tasks reveals that this\nsimple structure outperforms standard policy learning methods, highlighting its\npotential for improved skill acquisition.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.01993v1",
    "published_date": "2024-01-03 22:05:48 UTC",
    "updated_date": "2024-01-03 22:05:48 UTC"
  },
  {
    "arxiv_id": "2401.05426v2",
    "title": "CoSS: Co-optimizing Sensor and Sampling Rate for Data-Efficient AI in Human Activity Recognition",
    "authors": [
      "Mengxi Liu",
      "Zimin Zhao",
      "Daniel Gei√üler",
      "Bo Zhou",
      "Sungho Suh",
      "Paul Lukowicz"
    ],
    "abstract": "Recent advancements in Artificial Neural Networks have significantly improved\nhuman activity recognition using multiple time-series sensors. While employing\nnumerous sensors with high-frequency sampling rates usually improves the\nresults, it often leads to data inefficiency and unnecessary expansion of the\nANN, posing a challenge for their practical deployment on edge devices.\nAddressing these issues, our work introduces a pragmatic framework for\ndata-efficient utilization in HAR tasks, considering the optimization of both\nsensor modalities and sampling rate simultaneously. Central to our approach are\nthe designed trainable parameters, termed 'Weight Scores,' which assess the\nsignificance of each sensor modality and sampling rate during the training\nphase. These scores guide the sensor modalities and sampling rate selection.\nThe pruning method allows users to make a trade-off between computational\nbudgets and performance by selecting the sensor modalities and sampling rates\naccording to the weight score ranking. We tested our framework's effectiveness\nin optimizing sensor modality and sampling rate selection using three public\nHAR benchmark datasets. The results show that the sensor and sampling rate\ncombination selected via CoSS achieves similar classification performance to\nconfigurations using the highest sampling rate with all sensors but at a\nreduced hardware cost.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "Accepeted by the 2nd Workshop on Sustainable AI (AAAI24)",
    "pdf_url": "http://arxiv.org/pdf/2401.05426v2",
    "published_date": "2024-01-03 22:04:40 UTC",
    "updated_date": "2024-10-10 15:18:58 UTC"
  },
  {
    "arxiv_id": "2401.01990v2",
    "title": "GPS-SSL: Guided Positive Sampling to Inject Prior Into Self-Supervised Learning",
    "authors": [
      "Aarash Feizi",
      "Randall Balestriero",
      "Adriana Romero-Soriano",
      "Reihaneh Rabbany"
    ],
    "abstract": "We propose Guided Positive Sampling Self-Supervised Learning (GPS-SSL), a\ngeneral method to inject a priori knowledge into Self-Supervised Learning (SSL)\npositive samples selection. Current SSL methods leverage Data-Augmentations\n(DA) for generating positive samples and incorporate prior knowledge - an\nincorrect, or too weak DA will drastically reduce the quality of the learned\nrepresentation. GPS-SSL proposes instead to design a metric space where\nEuclidean distances become a meaningful proxy for semantic relationship. In\nthat space, it is now possible to generate positive samples from nearest\nneighbor sampling. Any prior knowledge can now be embedded into that metric\nspace independently from the employed DA. From its simplicity, GPS-SSL is\napplicable to any SSL method, e.g. SimCLR or BYOL. A key benefit of GPS-SSL is\nin reducing the pressure in tailoring strong DAs. For example GPS-SSL reaches\n85.58% on Cifar10 with weak DA while the baseline only reaches 37.51%. We\ntherefore move a step forward towards the goal of making SSL less reliant on\nDA. We also show that even when using strong DAs, GPS-SSL outperforms the\nbaselines on under-studied domains. We evaluate GPS-SSL along with multiple\nbaseline SSL methods on numerous downstream datasets from different domains\nwhen the models use strong or minimal data augmentations. We hope that GPS-SSL\nwill open new avenues in studying how to inject a priori knowledge into SSL in\na principled manner.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.01990v2",
    "published_date": "2024-01-03 21:39:06 UTC",
    "updated_date": "2024-01-09 18:24:05 UTC"
  },
  {
    "arxiv_id": "2401.01989v3",
    "title": "Revisiting Zero-Shot Abstractive Summarization in the Era of Large Language Models from the Perspective of Position Bias",
    "authors": [
      "Anshuman Chhabra",
      "Hadi Askari",
      "Prasant Mohapatra"
    ],
    "abstract": "We characterize and study zero-shot abstractive summarization in Large\nLanguage Models (LLMs) by measuring position bias, which we propose as a\ngeneral formulation of the more restrictive lead bias phenomenon studied\npreviously in the literature. Position bias captures the tendency of a model\nunfairly prioritizing information from certain parts of the input text over\nothers, leading to undesirable behavior. Through numerous experiments on four\ndiverse real-world datasets, we study position bias in multiple LLM models such\nas GPT 3.5-Turbo, Llama-2, and Dolly-v2, as well as state-of-the-art pretrained\nencoder-decoder abstractive summarization models such as Pegasus and BART. Our\nfindings lead to novel insights and discussion on performance and position bias\nof models for zero-shot summarization tasks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to NAACL 2024 Main Conference",
    "pdf_url": "http://arxiv.org/pdf/2401.01989v3",
    "published_date": "2024-01-03 21:38:40 UTC",
    "updated_date": "2024-03-18 20:09:01 UTC"
  },
  {
    "arxiv_id": "2401.10266v2",
    "title": "Intelligent Condition Monitoring of Industrial Plants: An Overview of Methodologies and Uncertainty Management Strategies",
    "authors": [
      "Maryam Ahang",
      "Todd Charter",
      "Oluwaseyi Ogunfowora",
      "Maziyar Khadivi",
      "Mostafa Abbasi",
      "Homayoun Najjaran"
    ],
    "abstract": "Condition monitoring plays a significant role in the safety and reliability\nof modern industrial systems. Artificial intelligence (AI) approaches are\ngaining attention from academia and industry as a growing subject in industrial\napplications and as a powerful way of identifying faults. This paper provides\nan overview of intelligent condition monitoring and fault detection and\ndiagnosis methods for industrial plants with a focus on the open-source\nbenchmark Tennessee Eastman Process (TEP). In this survey, the most popular and\nstate-of-the-art deep learning (DL) and machine learning (ML) algorithms for\nindustrial plant condition monitoring, fault detection, and diagnosis are\nsummarized and the advantages and disadvantages of each algorithm are studied.\nChallenges like imbalanced data, unlabelled samples and how deep learning\nmodels can handle them are also covered. Finally, a comparison of the\naccuracies and specifications of different algorithms utilizing the Tennessee\nEastman Process (TEP) is conducted. This research will be beneficial for both\nresearchers who are new to the field and experts, as it covers the literature\non condition monitoring and state-of-the-art methods alongside the challenges\nand possible solutions to them.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SY",
      "eess.SP",
      "eess.SY"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.10266v2",
    "published_date": "2024-01-03 21:35:03 UTC",
    "updated_date": "2025-04-28 22:03:34 UTC"
  },
  {
    "arxiv_id": "2401.01974v2",
    "title": "Towards Truly Zero-shot Compositional Visual Reasoning with LLMs as Programmers",
    "authors": [
      "Aleksandar Staniƒá",
      "Sergi Caelles",
      "Michael Tschannen"
    ],
    "abstract": "Visual reasoning is dominated by end-to-end neural networks scaled to\nbillions of model parameters and training examples. However, even the largest\nmodels struggle with compositional reasoning, generalization, fine-grained\nspatial and temporal reasoning, and counting. Visual reasoning with large\nlanguage models (LLMs) as controllers can, in principle, address these\nlimitations by decomposing the task and solving subtasks by orchestrating a set\nof (visual) tools. Recently, these models achieved great performance on tasks\nsuch as compositional visual question answering, visual grounding, and video\ntemporal reasoning. Nevertheless, in their current form, these models heavily\nrely on human engineering of in-context examples in the prompt, which are often\ndataset- and task-specific and require significant labor by highly skilled\nprogrammers. In this work, we present a framework that mitigates these issues\nby introducing spatially and temporally abstract routines and by leveraging a\nsmall number of labeled examples to automatically generate in-context examples,\nthereby avoiding human-created in-context examples. On a number of visual\nreasoning tasks, we show that our framework leads to consistent gains in\nperformance, makes LLMs as controllers setup more robust, and removes the need\nfor human engineering of in-context examples.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.01974v2",
    "published_date": "2024-01-03 20:48:47 UTC",
    "updated_date": "2024-05-14 22:43:40 UTC"
  },
  {
    "arxiv_id": "2401.01970v2",
    "title": "FMGS: Foundation Model Embedded 3D Gaussian Splatting for Holistic 3D Scene Understanding",
    "authors": [
      "Xingxing Zuo",
      "Pouya Samangouei",
      "Yunwen Zhou",
      "Yan Di",
      "Mingyang Li"
    ],
    "abstract": "Precisely perceiving the geometric and semantic properties of real-world 3D\nobjects is crucial for the continued evolution of augmented reality and robotic\napplications. To this end, we present Foundation Model Embedded Gaussian\nSplatting (FMGS), which incorporates vision-language embeddings of foundation\nmodels into 3D Gaussian Splatting (GS). The key contribution of this work is an\nefficient method to reconstruct and represent 3D vision-language models. This\nis achieved by distilling feature maps generated from image-based foundation\nmodels into those rendered from our 3D model. To ensure high-quality rendering\nand fast training, we introduce a novel scene representation by integrating\nstrengths from both GS and multi-resolution hash encodings (MHE). Our effective\ntraining procedure also introduces a pixel alignment loss that makes the\nrendered feature distance of the same semantic entities close, following the\npixel-level semantic boundaries. Our results demonstrate remarkable multi-view\nsemantic consistency, facilitating diverse downstream tasks, beating\nstate-of-the-art methods by 10.2 percent on open-vocabulary language-based\nobject detection, despite that we are 851X faster for inference. This research\nexplores the intersection of vision, language, and 3D scene representation,\npaving the way for enhanced scene understanding in uncontrolled real-world\nenvironments. We plan to release the code on the project page.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Project page: https://xingxingzuo.github.io/fmgs",
    "pdf_url": "http://arxiv.org/pdf/2401.01970v2",
    "published_date": "2024-01-03 20:39:02 UTC",
    "updated_date": "2024-05-03 23:33:07 UTC"
  },
  {
    "arxiv_id": "2401.01967v1",
    "title": "A Mechanistic Understanding of Alignment Algorithms: A Case Study on DPO and Toxicity",
    "authors": [
      "Andrew Lee",
      "Xiaoyan Bai",
      "Itamar Pres",
      "Martin Wattenberg",
      "Jonathan K. Kummerfeld",
      "Rada Mihalcea"
    ],
    "abstract": "While alignment algorithms are now commonly used to tune pre-trained language\nmodels towards a user's preferences, we lack explanations for the underlying\nmechanisms in which models become ``aligned'', thus making it difficult to\nexplain phenomena like jailbreaks. In this work we study a popular algorithm,\ndirect preference optimization (DPO), and the mechanisms by which it reduces\ntoxicity. Namely, we first study how toxicity is represented and elicited in a\npre-trained language model, GPT2-medium. We then apply DPO with a carefully\ncrafted pairwise dataset to reduce toxicity. We examine how the resulting model\naverts toxic outputs, and find that capabilities learned from pre-training are\nnot removed, but rather bypassed. We use this insight to demonstrate a simple\nmethod to un-align the model, reverting it back to its toxic behavior.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.01967v1",
    "published_date": "2024-01-03 20:26:15 UTC",
    "updated_date": "2024-01-03 20:26:15 UTC"
  },
  {
    "arxiv_id": "2401.01952v1",
    "title": "Instruct-Imagen: Image Generation with Multi-modal Instruction",
    "authors": [
      "Hexiang Hu",
      "Kelvin C. K. Chan",
      "Yu-Chuan Su",
      "Wenhu Chen",
      "Yandong Li",
      "Kihyuk Sohn",
      "Yang Zhao",
      "Xue Ben",
      "Boqing Gong",
      "William Cohen",
      "Ming-Wei Chang",
      "Xuhui Jia"
    ],
    "abstract": "This paper presents instruct-imagen, a model that tackles heterogeneous image\ngeneration tasks and generalizes across unseen tasks. We introduce *multi-modal\ninstruction* for image generation, a task representation articulating a range\nof generation intents with precision. It uses natural language to amalgamate\ndisparate modalities (e.g., text, edge, style, subject, etc.), such that\nabundant generation intents can be standardized in a uniform format.\n  We then build instruct-imagen by fine-tuning a pre-trained text-to-image\ndiffusion model with a two-stage framework. First, we adapt the model using the\nretrieval-augmented training, to enhance model's capabilities to ground its\ngeneration on external multimodal context. Subsequently, we fine-tune the\nadapted model on diverse image generation tasks that requires vision-language\nunderstanding (e.g., subject-driven generation, etc.), each paired with a\nmulti-modal instruction encapsulating the task's essence. Human evaluation on\nvarious image generation datasets reveals that instruct-imagen matches or\nsurpasses prior task-specific models in-domain and demonstrates promising\ngeneralization to unseen and more complex tasks.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "20 pages, 18 figures",
    "pdf_url": "http://arxiv.org/pdf/2401.01952v1",
    "published_date": "2024-01-03 19:31:58 UTC",
    "updated_date": "2024-01-03 19:31:58 UTC"
  },
  {
    "arxiv_id": "2401.01951v2",
    "title": "GeoPos: A Minimal Positional Encoding for Enhanced Fine-Grained Details in Image Synthesis Using Convolutional Neural Networks",
    "authors": [
      "Mehran Hosseini",
      "Peyman Hosseini"
    ],
    "abstract": "The enduring inability of image generative models to recreate intricate\ngeometric features, such as those present in human hands and fingers has been\nan ongoing problem in image generation for nearly a decade. While strides have\nbeen made by increasing model sizes and diversifying training datasets, this\nissue remains prevalent across all models, from denoising diffusion models to\nGenerative Adversarial Networks (GAN), pointing to a fundamental shortcoming in\nthe underlying architectures. In this paper, we demonstrate how this problem\ncan be mitigated by augmenting convolution layers geometric capabilities\nthrough providing them with a single input channel incorporating the relative\nn-dimensional Cartesian coordinate system. We show this drastically improves\nquality of images generated by Diffusion Models, GANs, and Variational\nAutoEncoders (VAE).",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "51",
      "I.2.10; I.4.0; I.4.10"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at WACV 2025. Contains 19 pages, 15 figures, and 9 tables",
    "pdf_url": "http://arxiv.org/pdf/2401.01951v2",
    "published_date": "2024-01-03 19:27:20 UTC",
    "updated_date": "2024-12-05 17:31:43 UTC"
  },
  {
    "arxiv_id": "2401.01943v2",
    "title": "Generalist embedding models are better at short-context clinical semantic search than specialized embedding models",
    "authors": [
      "Jean-Baptiste Excoffier",
      "Tom Roehr",
      "Alexei Figueroa",
      "Jens-Michalis Papaioannou",
      "Keno Bressem",
      "Matthieu Ortala"
    ],
    "abstract": "The increasing use of tools and solutions based on Large Language Models\n(LLMs) for various tasks in the medical domain has become a prominent trend.\nTheir use in this highly critical and sensitive domain has thus raised\nimportant questions about their robustness, especially in response to\nvariations in input, and the reliability of the generated outputs. This study\naddresses these questions by constructing a textual dataset based on the\nICD-10-CM code descriptions, widely used in US hospitals and containing many\nclinical terms, and their easily reproducible rephrasing. We then benchmarked\nexisting embedding models, either generalist or specialized in the clinical\ndomain, in a semantic search task where the goal was to correctly match the\nrephrased text to the original description. Our results showed that generalist\nmodels performed better than clinical models, suggesting that existing clinical\nspecialized models are more sensitive to small changes in input that confuse\nthem. The highlighted problem of specialized models may be due to the fact that\nthey have not been trained on sufficient data, and in particular on datasets\nthat are not diverse enough to have a reliable global language understanding,\nwhich is still necessary for accurate handling of medical documents.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "11 pages, 1 figure, 5 tables",
    "pdf_url": "http://arxiv.org/pdf/2401.01943v2",
    "published_date": "2024-01-03 19:03:32 UTC",
    "updated_date": "2024-01-06 09:51:09 UTC"
  },
  {
    "arxiv_id": "2401.01868v1",
    "title": "Step length measurement in the wild using FMCW radar",
    "authors": [
      "Parthipan Siva",
      "Alexander Wong",
      "Patricia Hewston",
      "George Ioannidis",
      "Jonathan Adachi",
      "Alexander Rabinovich",
      "Andrea Lee",
      "Alexandra Papaioannou"
    ],
    "abstract": "With an aging population, numerous assistive and monitoring technologies are\nunder development to enable older adults to age in place. To facilitate aging\nin place predicting risk factors such as falls, and hospitalization and\nproviding early interventions are important. Much of the work on ambient\nmonitoring for risk prediction has centered on gait speed analysis, utilizing\nprivacy-preserving sensors like radar. Despite compelling evidence that\nmonitoring step length, in addition to gait speed, is crucial for predicting\nrisk, radar-based methods have not explored step length measurement in the\nhome. Furthermore, laboratory experiments on step length measurement using\nradars are limited to proof of concept studies with few healthy subjects. To\naddress this gap, a radar-based step length measurement system for the home is\nproposed based on detection and tracking using radar point cloud, followed by\nDoppler speed profiling of the torso to obtain step lengths in the home. The\nproposed method was evaluated in a clinical environment, involving 35 frail\nolder adults, to establish its validity. Additionally, the method was assessed\nin people's homes, with 21 frail older adults who had participated in the\nclinical assessment. The proposed radar-based step length measurement method\nwas compared to the gold standard Zeno Walkway Gait Analysis System, revealing\na 4.5cm/8.3% error in a clinical setting. Furthermore, it exhibited excellent\nreliability (ICC(2,k)=0.91, 95% CI 0.82 to 0.96) in uncontrolled home settings.\nThe method also proved accurate in uncontrolled home settings, as indicated by\na strong agreement (ICC(3,k)=0.81 (95% CI 0.53 to 0.92)) between home\nmeasurements and in-clinic assessments.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "I.5.4; C.3; J.7"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.01868v1",
    "published_date": "2024-01-03 18:23:30 UTC",
    "updated_date": "2024-01-03 18:23:30 UTC"
  },
  {
    "arxiv_id": "2401.01854v4",
    "title": "Multilingual Instruction Tuning With Just a Pinch of Multilinguality",
    "authors": [
      "Uri Shaham",
      "Jonathan Herzig",
      "Roee Aharoni",
      "Idan Szpektor",
      "Reut Tsarfaty",
      "Matan Eyal"
    ],
    "abstract": "As instruction-tuned large language models (LLMs) gain global adoption, their\nability to follow instructions in multiple languages becomes increasingly\ncrucial. In this work, we investigate how multilinguality during instruction\ntuning of a multilingual LLM affects instruction-following across languages\nfrom the pre-training corpus. We first show that many languages transfer some\ninstruction-following capabilities to other languages from even monolingual\ntuning. Furthermore, we find that only 40 multilingual examples integrated in\nan English tuning set substantially improve multilingual instruction-following,\nboth in seen and unseen languages during tuning. In general, we observe that\nmodels tuned on multilingual mixtures exhibit comparable or superior\nperformance in multiple languages compared to monolingually tuned models,\ndespite training on 10x fewer examples in those languages. Finally, we find\nthat diversifying the instruction tuning set with even just 2-4 languages\nsignificantly improves cross-lingual generalization. Our results suggest that\nbuilding massively multilingual instruction-tuned models can be done with only\na very small set of multilingual instruction-responses.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Findings of ACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2401.01854v4",
    "published_date": "2024-01-03 17:48:10 UTC",
    "updated_date": "2024-05-21 09:19:33 UTC"
  },
  {
    "arxiv_id": "2401.01851v4",
    "title": "The Power of Training: How Different Neural Network Setups Influence the Energy Demand",
    "authors": [
      "Daniel Gei√üler",
      "Bo Zhou",
      "Mengxi Liu",
      "Sungho Suh",
      "Paul Lukowicz"
    ],
    "abstract": "This work offers a heuristic evaluation of the effects of variations in\nmachine learning training regimes and learning paradigms on the energy\nconsumption of computing, especially HPC hardware with a life-cycle aware\nperspective. While increasing data availability and innovation in\nhigh-performance hardware fuels the training of sophisticated models, it also\nfosters the fading perception of energy consumption and carbon emission.\nTherefore, the goal of this work is to raise awareness about the energy impact\nof general training parameters and processes, from learning rate over batch\nsize to knowledge transfer. Multiple setups with different hyperparameter\nconfigurations are evaluated on three different hardware systems. Among many\nresults, we have found out that even with the same model and hardware to reach\nthe same accuracy, improperly set training hyperparameters consume up to 5\ntimes the energy of the optimal setup. We also extensively examined the\nenergy-saving benefits of learning paradigms including recycling knowledge\nthrough pretraining and sharing knowledge through multitask training.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.PF"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.01851v4",
    "published_date": "2024-01-03 17:44:17 UTC",
    "updated_date": "2024-10-05 06:13:26 UTC"
  },
  {
    "arxiv_id": "2401.02991v1",
    "title": "GLIDE-RL: Grounded Language Instruction through DEmonstration in RL",
    "authors": [
      "Chaitanya Kharyal",
      "Sai Krishna Gottipati",
      "Tanmay Kumar Sinha",
      "Srijita Das",
      "Matthew E. Taylor"
    ],
    "abstract": "One of the final frontiers in the development of complex human - AI\ncollaborative systems is the ability of AI agents to comprehend the natural\nlanguage and perform tasks accordingly. However, training efficient\nReinforcement Learning (RL) agents grounded in natural language has been a\nlong-standing challenge due to the complexity and ambiguity of the language and\nsparsity of the rewards, among other factors. Several advances in reinforcement\nlearning, curriculum learning, continual learning, language models have\nindependently contributed to effective training of grounded agents in various\nenvironments. Leveraging these developments, we present a novel algorithm,\nGrounded Language Instruction through DEmonstration in RL (GLIDE-RL) that\nintroduces a teacher-instructor-student curriculum learning framework for\ntraining an RL agent capable of following natural language instructions that\ncan generalize to previously unseen language instructions. In this multi-agent\nframework, the teacher and the student agents learn simultaneously based on the\nstudent's current skill level. We further demonstrate the necessity for\ntraining the student agent with not just one, but multiple teacher agents.\nExperiments on a complex sparse reward environment validates the effectiveness\nof our proposed approach.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "12 pages, 6 figures, to be presented at AAMAS 2024",
    "pdf_url": "http://arxiv.org/pdf/2401.02991v1",
    "published_date": "2024-01-03 17:32:13 UTC",
    "updated_date": "2024-01-03 17:32:13 UTC"
  },
  {
    "arxiv_id": "2401.01843v2",
    "title": "Investigating Semi-Supervised Learning Algorithms in Text Datasets",
    "authors": [
      "Himmet Toprak Kesgin",
      "Mehmet Fatih Amasyali"
    ],
    "abstract": "Using large training datasets enhances the generalization capabilities of\nneural networks. Semi-supervised learning (SSL) is useful when there are few\nlabeled data and a lot of unlabeled data. SSL methods that use data\naugmentation are most successful for image datasets. In contrast, texts do not\nhave consistent augmentation methods as images. Consequently, methods that use\naugmentation are not as effective in text data as they are in image data. In\nthis study, we compared SSL algorithms that do not require augmentation; these\nare self-training, co-training, tri-training, and tri-training with\ndisagreement. In the experiments, we used 4 different text datasets for\ndifferent tasks. We examined the algorithms from a variety of perspectives by\nasking experiment questions and suggested several improvements. Among the\nalgorithms, tri-training with disagreement showed the closest performance to\nthe Oracle; however, performance gap shows that new semi-supervised algorithms\nor improvements in existing methods are needed.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Innovations in Intelligent Systems and Applications Conference (ASYU)",
    "pdf_url": "http://arxiv.org/pdf/2401.01843v2",
    "published_date": "2024-01-03 17:22:48 UTC",
    "updated_date": "2024-01-07 11:51:33 UTC"
  },
  {
    "arxiv_id": "2401.01841v3",
    "title": "Act as You Learn: Adaptive Decision-Making in Non-Stationary Markov Decision Processes",
    "authors": [
      "Baiting Luo",
      "Yunuo Zhang",
      "Abhishek Dubey",
      "Ayan Mukhopadhyay"
    ],
    "abstract": "A fundamental (and largely open) challenge in sequential decision-making is\ndealing with non-stationary environments, where exogenous environmental\nconditions change over time. Such problems are traditionally modeled as\nnon-stationary Markov decision processes (NSMDP). However, existing approaches\nfor decision-making in NSMDPs have two major shortcomings: first, they assume\nthat the updated environmental dynamics at the current time are known (although\nfuture dynamics can change); and second, planning is largely pessimistic, i.e.,\nthe agent acts ``safely'' to account for the non-stationary evolution of the\nenvironment. We argue that both these assumptions are invalid in practice --\nupdated environmental conditions are rarely known, and as the agent interacts\nwith the environment, it can learn about the updated dynamics and avoid being\npessimistic, at least in states whose dynamics it is confident about. We\npresent a heuristic search algorithm called \\textit{Adaptive Monte Carlo Tree\nSearch (ADA-MCTS)} that addresses these challenges. We show that the agent can\nlearn the updated dynamics of the environment over time and then act as it\nlearns, i.e., if the agent is in a region of the state space about which it has\nupdated knowledge, it can avoid being pessimistic. To quantify ``updated\nknowledge,'' we disintegrate the aleatoric and epistemic uncertainty in the\nagent's updated belief and show how the agent can use these estimates for\ndecision-making. We compare the proposed approach with the multiple\nstate-of-the-art approaches in decision-making across multiple well-established\nopen-source problems and empirically show that our approach is faster and\nhighly adaptive without sacrificing safety.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted for publication at the International Conference on\n  Autonomous Agents and MultiAgent Systems (AAMAS), 2024",
    "pdf_url": "http://arxiv.org/pdf/2401.01841v3",
    "published_date": "2024-01-03 17:19:54 UTC",
    "updated_date": "2024-01-22 03:43:34 UTC"
  },
  {
    "arxiv_id": "2401.01836v4",
    "title": "Neural Control: Concurrent System Identification and Control Learning with Neural ODE",
    "authors": [
      "Cheng Chi"
    ],
    "abstract": "Controlling continuous-time dynamical systems is generally a two step\nprocess: first, identify or model the system dynamics with differential\nequations, then, minimize the control objectives to achieve optimal control\nfunction and optimal state trajectories. However, any inaccuracy in dynamics\nmodeling will lead to sub-optimality in the resulting control function. To\naddress this, we propose a neural ODE based method for controlling unknown\ndynamical systems, denoted as Neural Control (NC), which combines dynamics\nidentification and optimal control learning using a coupled neural ODE. Through\nan intriguing interplay between the two neural networks in coupled neural ODE\nstructure, our model concurrently learns system dynamics as well as optimal\ncontrols that guides towards target states. Our experiments demonstrate the\neffectiveness of our model for learning optimal control of unknown dynamical\nsystems. Codes available at\nhttps://github.com/chichengmessi/neural_ode_control/tree/main",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "9 pages, code open sourced in format of Google Colab notebooks;\n  Resubmitted for adding missed references in the last submission",
    "pdf_url": "http://arxiv.org/pdf/2401.01836v4",
    "published_date": "2024-01-03 17:05:17 UTC",
    "updated_date": "2024-04-22 16:43:11 UTC"
  },
  {
    "arxiv_id": "2401.01835v1",
    "title": "Concurrent Brainstorming & Hypothesis Satisfying: An Iterative Framework for Enhanced Retrieval-Augmented Generation (R2CBR3H-SR)",
    "authors": [
      "Arash Shahmansoori"
    ],
    "abstract": "Addressing the complexity of comprehensive information retrieval, this study\nintroduces an innovative, iterative retrieval-augmented generation system. Our\napproach uniquely integrates a vector-space driven re-ranking mechanism with\nconcurrent brainstorming to expedite the retrieval of highly relevant\ndocuments, thereby streamlining the generation of potential queries. This sets\nthe stage for our novel hybrid process, which synergistically combines\nhypothesis formulation with satisfying decision-making strategy to determine\ncontent adequacy, leveraging a chain of thought-based prompting technique. This\nunified hypothesize-satisfied phase intelligently distills information to\nascertain whether user queries have been satisfactorily addressed. Upon\nreaching this criterion, the system refines its output into a concise\nrepresentation, maximizing conceptual density with minimal verbosity. The\niterative nature of the workflow enhances process efficiency and accuracy.\nCrucially, the concurrency within the brainstorming phase significantly\naccelerates recursive operations, facilitating rapid convergence to solution\nsatisfaction. Compared to conventional methods, our system demonstrates a\nmarked improvement in computational time and cost-effectiveness. This research\nadvances the state-of-the-art in intelligent retrieval systems, setting a new\nbenchmark for resource-efficient information extraction and abstraction in\nknowledge-intensive applications.",
    "categories": [
      "cs.IT",
      "cs.AI",
      "cs.IR",
      "math.IT"
    ],
    "primary_category": "cs.IT",
    "comment": "3 pages, 1 table, double column IEEE journal format paper",
    "pdf_url": "http://arxiv.org/pdf/2401.01835v1",
    "published_date": "2024-01-03 17:01:44 UTC",
    "updated_date": "2024-01-03 17:01:44 UTC"
  },
  {
    "arxiv_id": "2401.01830v1",
    "title": "Iterative Mask Filling: An Effective Text Augmentation Method Using Masked Language Modeling",
    "authors": [
      "Himmet Toprak Kesgin",
      "Mehmet Fatih Amasyali"
    ],
    "abstract": "Data augmentation is an effective technique for improving the performance of\nmachine learning models. However, it has not been explored as extensively in\nnatural language processing (NLP) as it has in computer vision. In this paper,\nwe propose a novel text augmentation method that leverages the Fill-Mask\nfeature of the transformer-based BERT model. Our method involves iteratively\nmasking words in a sentence and replacing them with language model predictions.\nWe have tested our proposed method on various NLP tasks and found it to be\neffective in many cases. Our results are presented along with a comparison to\nexisting augmentation methods. Experimental results show that our proposed\nmethod significantly improves performance, especially on topic classification\ndatasets.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Published in International Conference on Advanced Engineering,\n  Technology and Applications (ICAETA 2023). The final version is available\n  online at https://link.springer.com/chapter/10.1007/978-3-031-50920-9_35",
    "pdf_url": "http://arxiv.org/pdf/2401.01830v1",
    "published_date": "2024-01-03 16:47:13 UTC",
    "updated_date": "2024-01-03 16:47:13 UTC"
  },
  {
    "arxiv_id": "2401.01814v1",
    "title": "Large Language Models Relearn Removed Concepts",
    "authors": [
      "Michelle Lo",
      "Shay B. Cohen",
      "Fazl Barez"
    ],
    "abstract": "Advances in model editing through neuron pruning hold promise for removing\nundesirable concepts from large language models. However, it remains unclear\nwhether models have the capacity to reacquire pruned concepts after editing. To\ninvestigate this, we evaluate concept relearning in models by tracking concept\nsaliency and similarity in pruned neurons during retraining. Our findings\nreveal that models can quickly regain performance post-pruning by relocating\nadvanced concepts to earlier layers and reallocating pruned concepts to primed\nneurons with similar semantics. This demonstrates that models exhibit\npolysemantic capacities and can blend old and new concepts in individual\nneurons. While neuron pruning provides interpretability into model concepts,\nour results highlight the challenges of permanent concept removal for improved\nmodel \\textit{safety}. Monitoring concept reemergence and developing techniques\nto mitigate relearning of unsafe concepts will be important directions for more\nrobust model editing. Overall, our work strongly demonstrates the resilience\nand fluidity of concept representations in LLMs post concept removal.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.01814v1",
    "published_date": "2024-01-03 16:15:57 UTC",
    "updated_date": "2024-01-03 16:15:57 UTC"
  },
  {
    "arxiv_id": "2401.01801v2",
    "title": "A quatum inspired neural network for geometric modeling",
    "authors": [
      "Weitao Du",
      "Shengchao Liu",
      "Xuecang Zhang"
    ],
    "abstract": "By conceiving physical systems as 3D many-body point clouds, geometric graph\nneural networks (GNNs), such as SE(3)/E(3) equivalent GNNs, have showcased\npromising performance. In particular, their effective message-passing mechanics\nmake them adept at modeling molecules and crystalline materials. However,\ncurrent geometric GNNs only offer a mean-field approximation of the many-body\nsystem, encapsulated within two-body message passing, thus falling short in\ncapturing intricate relationships within these geometric graphs. To address\nthis limitation, tensor networks, widely employed by computational physics to\nhandle manybody systems using high-order tensors, have been introduced.\nNevertheless, integrating these tensorized networks into the message-passing\nframework of GNNs faces scalability and symmetry conservation (e.g.,\npermutation and rotation) challenges. In response, we introduce an innovative\nequivariant Matrix Product State (MPS)-based message-passing strategy, through\nachieving an efficient implementation of the tensor contraction operation. Our\nmethod effectively models complex many-body relationships, suppressing\nmean-field approximations, and captures symmetries within geometric graphs.\nImportantly, it seamlessly replaces the standard message-passing and\nlayer-aggregation modules intrinsic to geometric GNNs. We empirically validate\nthe superior accuracy of our approach on benchmark tasks, including predicting\nclassical Newton systems and quantum tensor Hamiltonian matrices. To our\nknowledge, our approach represents the inaugural utilization of parameterized\ngeometric tensor networks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.comp-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.01801v2",
    "published_date": "2024-01-03 15:59:35 UTC",
    "updated_date": "2024-01-28 16:13:37 UTC"
  },
  {
    "arxiv_id": "2401.01792v1",
    "title": "CoMoSVC: Consistency Model-based Singing Voice Conversion",
    "authors": [
      "Yiwen Lu",
      "Zhen Ye",
      "Wei Xue",
      "Xu Tan",
      "Qifeng Liu",
      "Yike Guo"
    ],
    "abstract": "The diffusion-based Singing Voice Conversion (SVC) methods have achieved\nremarkable performances, producing natural audios with high similarity to the\ntarget timbre. However, the iterative sampling process results in slow\ninference speed, and acceleration thus becomes crucial. In this paper, we\npropose CoMoSVC, a consistency model-based SVC method, which aims to achieve\nboth high-quality generation and high-speed sampling. A diffusion-based teacher\nmodel is first specially designed for SVC, and a student model is further\ndistilled under self-consistency properties to achieve one-step sampling.\nExperiments on a single NVIDIA GTX4090 GPU reveal that although CoMoSVC has a\nsignificantly faster inference speed than the state-of-the-art (SOTA)\ndiffusion-based SVC system, it still achieves comparable or superior conversion\nperformance based on both subjective and objective metrics. Audio samples and\ncodes are available at https://comosvc.github.io/.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.LG",
      "cs.SD"
    ],
    "primary_category": "eess.AS",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.01792v1",
    "published_date": "2024-01-03 15:47:17 UTC",
    "updated_date": "2024-01-03 15:47:17 UTC"
  },
  {
    "arxiv_id": "2401.01789v1",
    "title": "Deep learning the Hurst parameter of linear fractional processes and assessing its reliability",
    "authors": [
      "D√°niel Boros",
      "B√°lint Csan√°dy",
      "Iv√°n Ivkovic",
      "L√≥r√°nt Nagy",
      "Andr√°s Luk√°cs",
      "L√°szl√≥ M√°rkus"
    ],
    "abstract": "This research explores the reliability of deep learning, specifically Long\nShort-Term Memory (LSTM) networks, for estimating the Hurst parameter in\nfractional stochastic processes. The study focuses on three types of processes:\nfractional Brownian motion (fBm), fractional Ornstein-Uhlenbeck (fOU) process,\nand linear fractional stable motions (lfsm). The work involves a fast\ngeneration of extensive datasets for fBm and fOU to train the LSTM network on a\nlarge volume of data in a feasible time. The study analyses the accuracy of the\nLSTM network's Hurst parameter estimation regarding various performance\nmeasures like RMSE, MAE, MRE, and quantiles of the absolute and relative\nerrors. It finds that LSTM outperforms the traditional statistical methods in\nthe case of fBm and fOU processes; however, it has limited accuracy on lfsm\nprocesses. The research also delves into the implications of training length\nand valuation sequence length on the LSTM's performance. The methodology is\napplied by estimating the Hurst parameter in Li-ion battery degradation data\nand obtaining confidence bounds for the estimation. The study concludes that\nwhile deep learning methods show promise in parameter estimation of fractional\nprocesses, their effectiveness is contingent on the process type and the\nquality of training data.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG",
      "68T07"
    ],
    "primary_category": "stat.ML",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.01789v1",
    "published_date": "2024-01-03 15:42:45 UTC",
    "updated_date": "2024-01-03 15:42:45 UTC"
  },
  {
    "arxiv_id": "2401.01788v1",
    "title": "Applications of machine learning and IoT for Outdoor Air Pollution Monitoring and Prediction: A Systematic Literature Review",
    "authors": [
      "Ihsane Gryech",
      "Chaimae Assad",
      "Mounir Ghogho",
      "Abdellatif Kobbane"
    ],
    "abstract": "According to the World Health Organization (WHO), air pollution kills seven\nmillion people every year. Outdoor air pollution is a major environmental\nhealth problem affecting low, middle, and high-income countries. In the past\nfew years, the research community has explored IoT-enabled machine learning\napplications for outdoor air pollution prediction. The general objective of\nthis paper is to systematically review applications of machine learning and\nInternet of Things (IoT) for outdoor air pollution prediction and the\ncombination of monitoring sensors and input features used. Two research\nquestions were formulated for this review. 1086 publications were collected in\nthe initial PRISMA stage. After the screening and eligibility phases, 37 papers\nwere selected for inclusion. A cost-based analysis was conducted on the\nfindings to highlight high-cost monitoring, low-cost IoT and hybrid enabled\nprediction. Three methods of prediction were identified: time series,\nfeature-based and spatio-temporal. This review's findings identify major\nlimitations in applications found in the literature, namely lack of coverage,\nlack of diversity of data and lack of inclusion of context-specific features.\nThis review proposes directions for future research and underlines practical\nimplications in healthcare, urban planning, global synergy and smart cities.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.01788v1",
    "published_date": "2024-01-03 15:36:33 UTC",
    "updated_date": "2024-01-03 15:36:33 UTC"
  },
  {
    "arxiv_id": "2401.01772v2",
    "title": "A Novel Paradigm for Neural Computation: X-Net with Learnable Neurons and Adaptable Structure",
    "authors": [
      "Yanjie Li",
      "Weijun Li",
      "Lina Yu",
      "Min Wu",
      "Jinyi Liu",
      "Wenqiang Li",
      "Meilan Hao",
      "Shu Wei",
      "Yusong Deng",
      "Liping Zhang",
      "Xiaoli Dong",
      "Hong Qin",
      "Xin Ning",
      "Yugui Zhang",
      "Baoli Lu",
      "Jian Xu",
      "Shuang Li"
    ],
    "abstract": "Multilayer perception (MLP) has permeated various disciplinary domains,\nranging from bioinformatics to financial analytics, where their application has\nbecome an indispensable facet of contemporary scientific research endeavors.\nHowever, MLP has obvious drawbacks. 1), The type of activation function is\nsingle and relatively fixed, which leads to poor `representation ability' of\nthe network, and it is often to solve simple problems with complex networks;\n2), the network structure is not adaptive, it is easy to cause network\nstructure redundant or insufficient. In this work, we propose a novel neural\nnetwork paradigm X-Net promising to replace MLPs. X-Net can dynamically learn\nactivation functions individually based on derivative information during\ntraining to improve the network's representational ability for specific tasks.\nAt the same time, X-Net can precisely adjust the network structure at the\nneuron level to accommodate tasks of varying complexity and reduce\ncomputational costs. We show that X-Net outperforms MLPs in terms of\nrepresentational capability. X-Net can achieve comparable or even better\nperformance than MLP with much smaller parameters on regression and\nclassification tasks. Specifically, in terms of the number of parameters, X-Net\nis only 3% of MLP on average and only 1.1% under some tasks. We also\ndemonstrate X-Net's ability to perform scientific discovery on data from\nvarious disciplines such as energy, environment, and aerospace, where X-Net is\nshown to help scientists discover new laws of mathematics or physics.",
    "categories": [
      "cs.AI",
      "cs.NI"
    ],
    "primary_category": "cs.AI",
    "comment": "35 pages",
    "pdf_url": "http://arxiv.org/pdf/2401.01772v2",
    "published_date": "2024-01-03 14:52:18 UTC",
    "updated_date": "2024-07-12 09:21:00 UTC"
  },
  {
    "arxiv_id": "2401.01755v1",
    "title": "Incremental FastPitch: Chunk-based High Quality Text to Speech",
    "authors": [
      "Muyang Du",
      "Chuan Liu",
      "Junjie Lai"
    ],
    "abstract": "Parallel text-to-speech models have been widely applied for real-time speech\nsynthesis, and they offer more controllability and a much faster synthesis\nprocess compared with conventional auto-regressive models. Although parallel\nmodels have benefits in many aspects, they become naturally unfit for\nincremental synthesis due to their fully parallel architecture such as\ntransformer. In this work, we propose Incremental FastPitch, a novel FastPitch\nvariant capable of incrementally producing high-quality Mel chunks by improving\nthe architecture with chunk-based FFT blocks, training with receptive-field\nconstrained chunk attention masks, and inference with fixed size past model\nstates. Experimental results show that our proposal can produce speech quality\ncomparable to the parallel FastPitch, with a significant lower latency that\nallows even lower response time for real-time speech applications.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "5 pages, 4 figures, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2401.01755v1",
    "published_date": "2024-01-03 14:17:35 UTC",
    "updated_date": "2024-01-03 14:17:35 UTC"
  },
  {
    "arxiv_id": "2401.01754v1",
    "title": "Using AI/ML to Find and Remediate Enterprise Secrets in Code & Document Sharing Platforms",
    "authors": [
      "Gregor Kerr",
      "David Algorry",
      "Senad Ibraimoski",
      "Peter Maciver",
      "Sean Moran"
    ],
    "abstract": "We introduce a new challenge to the software development community: 1)\nleveraging AI to accurately detect and flag up secrets in code and on popular\ndocument sharing platforms that frequently used by developers, such as\nConfluence and 2) automatically remediating the detections (e.g. by suggesting\npassword vault functionality). This is a challenging, and mostly unaddressed\ntask. Existing methods leverage heuristics and regular expressions, that can be\nvery noisy, and therefore increase toil on developers. The next step -\nmodifying code itself - to automatically remediate a detection, is a complex\ntask. We introduce two baseline AI models that have good detection performance\nand propose an automatic mechanism for remediating secrets found in code,\nopening up the study of this task to the wider community.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.01754v1",
    "published_date": "2024-01-03 14:15:25 UTC",
    "updated_date": "2024-01-03 14:15:25 UTC"
  },
  {
    "arxiv_id": "2401.01753v1",
    "title": "A Generative AI Assistant to Accelerate Cloud Migration",
    "authors": [
      "Amal Vaidya",
      "Mohan Krishna Vankayalapati",
      "Jacky Chan",
      "Senad Ibraimoski",
      "Sean Moran"
    ],
    "abstract": "We present a tool that leverages generative AI to accelerate the migration of\non-premises applications to the cloud. The Cloud Migration LLM accepts input\nfrom the user specifying the parameters of their migration, and outputs a\nmigration strategy with an architecture diagram. A user study suggests that the\nmigration LLM can assist inexperienced users in finding the right cloud\nmigration profile, while avoiding complexities of a manual approach.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "arXiv admin comment: This version has been removed by arXiv\n  administrators as the submitter did not have the rights to agree to the\n  license at the time of submission",
    "pdf_url": "http://arxiv.org/pdf/2401.01753v1",
    "published_date": "2024-01-03 14:13:24 UTC",
    "updated_date": "2024-01-03 14:13:24 UTC"
  },
  {
    "arxiv_id": "2401.01732v1",
    "title": "Task and Explanation Network",
    "authors": [
      "Moshe Sipper"
    ],
    "abstract": "Explainability in deep networks has gained increased importance in recent\nyears. We argue herein that an AI must be tasked not just with a task but also\nwith an explanation of why said task was accomplished as such. We present a\nbasic framework -- Task and Explanation Network (TENet) -- which fully\nintegrates task completion and its explanation. We believe that the field of AI\nas a whole should insist -- quite emphatically -- on explainability.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.01732v1",
    "published_date": "2024-01-03 13:11:59 UTC",
    "updated_date": "2024-01-03 13:11:59 UTC"
  },
  {
    "arxiv_id": "2401.01728v2",
    "title": "Ravnest: Decentralized Asynchronous Training on Heterogeneous Devices",
    "authors": [
      "Anirudh Rajiv Menon",
      "Unnikrishnan Menon",
      "Kailash Ahirwar"
    ],
    "abstract": "Modern deep learning models, growing larger and more complex, have\ndemonstrated exceptional generalization and accuracy due to training on huge\ndatasets. This trend is expected to continue. However, the increasing size of\nthese models poses challenges in training, as traditional centralized methods\nare limited by memory constraints at such scales. This paper proposes an\nasynchronous decentralized training paradigm for large modern deep learning\nmodels that harnesses the compute power of regular heterogeneous PCs with\nlimited resources connected across the internet to achieve favourable\nperformance metrics. Ravnest facilitates decentralized training by efficiently\norganizing compute nodes into clusters with similar data transfer rates and\ncompute capabilities, without necessitating that each node hosts the entire\nmodel. These clusters engage in $\\textit{Zero-Bubble Asynchronous Model\nParallel}$ training, and a $\\textit{Parallel Multi-Ring All-Reduce}$ method is\nemployed to effectively execute global parameter averaging across all clusters.\nWe have framed our asynchronous SGD loss function as a block structured\noptimization problem with delayed updates and derived an optimal convergence\nrate of $O\\left(\\frac{1}{\\sqrt{K}}\\right)$. We further discuss linear speedup\nwith respect to the number of participating clusters and the bound on the\nstaleness parameter.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "29 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2401.01728v2",
    "published_date": "2024-01-03 13:07:07 UTC",
    "updated_date": "2024-05-23 08:01:25 UTC"
  },
  {
    "arxiv_id": "2401.10264v1",
    "title": "Harnessing Transparent Learning Analytics for Individualized Support through Auto-detection of Engagement in Face-to-Face Collaborative Learning",
    "authors": [
      "Qi Zhou",
      "Wannapon Suraworachet",
      "Mutlu Cukurova"
    ],
    "abstract": "Using learning analytics to investigate and support collaborative learning\nhas been explored for many years. Recently, automated approaches with various\nartificial intelligence approaches have provided promising results for\nmodelling and predicting student engagement and performance in collaborative\nlearning tasks. However, due to the lack of transparency and interpretability\ncaused by the use of \"black box\" approaches in learning analytics design and\nimplementation, guidance for teaching and learning practice may become a\nchallenge. On the one hand, the black box created by machine learning\nalgorithms and models prevents users from obtaining educationally meaningful\nlearning and teaching suggestions. On the other hand, focusing on group and\ncohort level analysis only can make it difficult to provide specific support\nfor individual students working in collaborative groups. This paper proposes a\ntransparent approach to automatically detect student's individual engagement in\nthe process of collaboration. The results show that the proposed approach can\nreflect student's individual engagement and can be used as an indicator to\ndistinguish students with different collaborative learning challenges\n(cognitive, behavioural and emotional) and learning outcomes. The potential of\nthe proposed collaboration analytics approach for scaffolding collaborative\nlearning practice in face-to-face contexts is discussed and future research\nsuggestions are provided.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "12 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2401.10264v1",
    "published_date": "2024-01-03 12:20:28 UTC",
    "updated_date": "2024-01-03 12:20:28 UTC"
  },
  {
    "arxiv_id": "2401.01656v2",
    "title": "Deep Automated Mechanism Design for Integrating Ad Auction and Allocation in Feed",
    "authors": [
      "Xuejian Li",
      "Ze Wang",
      "Bingqi Zhu",
      "Fei He",
      "Yongkang Wang",
      "Xingxing Wang"
    ],
    "abstract": "E-commerce platforms usually present an ordered list, mixed with several\norganic items and an advertisement, in response to each user's page view\nrequest. This list, the outcome of ad auction and allocation processes,\ndirectly impacts the platform's ad revenue and gross merchandise volume (GMV).\nSpecifically, the ad auction determines which ad is displayed and the\ncorresponding payment, while the ad allocation decides the display positions of\nthe advertisement and organic items. The prevalent methods of segregating the\nad auction and allocation into two distinct stages face two problems: 1) Ad\nauction does not consider externalities, such as the influence of actual\ndisplay position and context on ad Click-Through Rate (CTR); 2) The ad\nallocation, which utilizes the auction-winning ad's payment to determine the\ndisplay position dynamically, fails to maintain incentive compatibility (IC)\nfor the advertisement. For instance, in the auction stage employing the\ntraditional Generalized Second Price (GSP) , even if the winning ad increases\nits bid, its payment remains unchanged. This implies that the advertisement\ncannot secure a better position and thus loses the opportunity to achieve\nhigher utility in the subsequent ad allocation stage. Previous research often\nfocused on one of the two stages, neglecting the two-stage problem, which may\nresult in suboptimal outcomes...",
    "categories": [
      "cs.GT",
      "cs.AI"
    ],
    "primary_category": "cs.GT",
    "comment": "9 pages, 2 figures, Posting",
    "pdf_url": "http://arxiv.org/pdf/2401.01656v2",
    "published_date": "2024-01-03 10:27:39 UTC",
    "updated_date": "2024-04-11 08:51:51 UTC"
  },
  {
    "arxiv_id": "2401.01651v3",
    "title": "AIGCBench: Comprehensive Evaluation of Image-to-Video Content Generated by AI",
    "authors": [
      "Fanda Fan",
      "Chunjie Luo",
      "Wanling Gao",
      "Jianfeng Zhan"
    ],
    "abstract": "The burgeoning field of Artificial Intelligence Generated Content (AIGC) is\nwitnessing rapid advancements, particularly in video generation. This paper\nintroduces AIGCBench, a pioneering comprehensive and scalable benchmark\ndesigned to evaluate a variety of video generation tasks, with a primary focus\non Image-to-Video (I2V) generation. AIGCBench tackles the limitations of\nexisting benchmarks, which suffer from a lack of diverse datasets, by including\na varied and open-domain image-text dataset that evaluates different\nstate-of-the-art algorithms under equivalent conditions. We employ a novel text\ncombiner and GPT-4 to create rich text prompts, which are then used to generate\nimages via advanced Text-to-Image models. To establish a unified evaluation\nframework for video generation tasks, our benchmark includes 11 metrics\nspanning four dimensions to assess algorithm performance. These dimensions are\ncontrol-video alignment, motion effects, temporal consistency, and video\nquality. These metrics are both reference video-dependent and video-free,\nensuring a comprehensive evaluation strategy. The evaluation standard proposed\ncorrelates well with human judgment, providing insights into the strengths and\nweaknesses of current I2V algorithms. The findings from our extensive\nexperiments aim to stimulate further research and development in the I2V field.\nAIGCBench represents a significant step toward creating standardized benchmarks\nfor the broader AIGC landscape, proposing an adaptable and equitable framework\nfor future assessments of video generation tasks. We have open-sourced the\ndataset and evaluation code on the project website:\nhttps://www.benchcouncil.org/AIGCBench.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to BenchCouncil Transactions on Benchmarks, Standards and\n  Evaluations (TBench)",
    "pdf_url": "http://arxiv.org/pdf/2401.01651v3",
    "published_date": "2024-01-03 10:08:40 UTC",
    "updated_date": "2024-01-23 15:31:17 UTC"
  },
  {
    "arxiv_id": "2401.10904v1",
    "title": "A Review of Findings from Neuroscience and Cognitive Psychology as Possible Inspiration for the Path to Artificial General Intelligence",
    "authors": [
      "Florin Leon"
    ],
    "abstract": "This review aims to contribute to the quest for artificial general\nintelligence by examining neuroscience and cognitive psychology methods for\npotential inspiration. Despite the impressive advancements achieved by deep\nlearning models in various domains, they still have shortcomings in abstract\nreasoning and causal understanding. Such capabilities should be ultimately\nintegrated into artificial intelligence systems in order to surpass data-driven\nlimitations and support decision making in a way more similar to human\nintelligence. This work is a vertical review that attempts a wide-ranging\nexploration of brain function, spanning from lower-level biological neurons,\nspiking neural networks, and neuronal ensembles to higher-level concepts such\nas brain anatomy, vector symbolic architectures, cognitive and categorization\nmodels, and cognitive architectures. The hope is that these concepts may offer\ninsights for solutions in artificial general intelligence.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "143 pages, 49 figures, 244 references",
    "pdf_url": "http://arxiv.org/pdf/2401.10904v1",
    "published_date": "2024-01-03 09:46:36 UTC",
    "updated_date": "2024-01-03 09:46:36 UTC"
  },
  {
    "arxiv_id": "2401.01630v1",
    "title": "A Cybersecurity Risk Analysis Framework for Systems with Artificial Intelligence Components",
    "authors": [
      "Jose Manuel Camacho",
      "Aitor Couce-Vieira",
      "David Arroyo",
      "David Rios Insua"
    ],
    "abstract": "The introduction of the European Union Artificial Intelligence Act, the NIST\nArtificial Intelligence Risk Management Framework, and related norms demands a\nbetter understanding and implementation of novel risk analysis approaches to\nevaluate systems with Artificial Intelligence components. This paper provides a\ncybersecurity risk analysis framework that can help assessing such systems. We\nuse an illustrative example concerning automated driving systems.",
    "categories": [
      "cs.AI",
      "cs.CR",
      "stat.AP"
    ],
    "primary_category": "cs.AI",
    "comment": "54 pages, 18 tables, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2401.01630v1",
    "published_date": "2024-01-03 09:06:39 UTC",
    "updated_date": "2024-01-03 09:06:39 UTC"
  },
  {
    "arxiv_id": "2401.01629v1",
    "title": "Synthetic Data in AI: Challenges, Applications, and Ethical Implications",
    "authors": [
      "Shuang Hao",
      "Wenfeng Han",
      "Tao Jiang",
      "Yiping Li",
      "Haonan Wu",
      "Chunlin Zhong",
      "Zhangjun Zhou",
      "He Tang"
    ],
    "abstract": "In the rapidly evolving field of artificial intelligence, the creation and\nutilization of synthetic datasets have become increasingly significant. This\nreport delves into the multifaceted aspects of synthetic data, particularly\nemphasizing the challenges and potential biases these datasets may harbor. It\nexplores the methodologies behind synthetic data generation, spanning\ntraditional statistical models to advanced deep learning techniques, and\nexamines their applications across diverse domains. The report also critically\naddresses the ethical considerations and legal implications associated with\nsynthetic datasets, highlighting the urgent need for mechanisms to ensure\nfairness, mitigate biases, and uphold ethical standards in AI development.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.01629v1",
    "published_date": "2024-01-03 09:03:30 UTC",
    "updated_date": "2024-01-03 09:03:30 UTC"
  },
  {
    "arxiv_id": "2401.01626v2",
    "title": "On the Expressive Power of Graph Neural Networks",
    "authors": [
      "Ashwin Nalwade",
      "Kelly Marshall",
      "Axel Eladi",
      "Umang Sharma"
    ],
    "abstract": "The study of Graph Neural Networks has received considerable interest in the\npast few years. By extending deep learning to graph-structured data, GNNs can\nsolve a diverse set of tasks in fields including social science, chemistry, and\nmedicine. The development of GNN architectures has largely been focused on\nimproving empirical performance on tasks like node or graph classification.\nHowever, a line of recent work has instead sought to find GNN architectures\nthat have desirable theoretical properties - by studying their expressive power\nand designing architectures that maximize this expressiveness.\n  While there is no consensus on the best way to define the expressiveness of a\nGNN, it can be viewed from several well-motivated perspectives. Perhaps the\nmost natural approach is to study the universal approximation properties of\nGNNs, much in the way that this has been studied extensively for MLPs. Another\ndirection focuses on the extent to which GNNs can distinguish between different\ngraph structures, relating this to the graph isomorphism test. Besides, a GNN's\nability to compute graph properties such as graph moments has been suggested as\nanother form of expressiveness. All of these different definitions are\ncomplementary and have yielded different recommendations for GNN architecture\nchoices. In this paper, we would like to give an overview of the notion of\n\"expressive power\" of GNNs and provide some valuable insights regarding the\ndesign choices of GNNs.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "We felt that significantly more work was needed to improve the\n  quality before it should be put out in its current state. No replacement is\n  available at the moment or in the near future",
    "pdf_url": "http://arxiv.org/pdf/2401.01626v2",
    "published_date": "2024-01-03 08:54:56 UTC",
    "updated_date": "2024-03-08 19:57:35 UTC"
  },
  {
    "arxiv_id": "2401.01623v4",
    "title": "Can AI Be as Creative as Humans?",
    "authors": [
      "Haonan Wang",
      "James Zou",
      "Michael Mozer",
      "Anirudh Goyal",
      "Alex Lamb",
      "Linjun Zhang",
      "Weijie J Su",
      "Zhun Deng",
      "Michael Qizhe Xie",
      "Hannah Brown",
      "Kenji Kawaguchi"
    ],
    "abstract": "Creativity serves as a cornerstone for societal progress and innovation. With\nthe rise of advanced generative AI models capable of tasks once reserved for\nhuman creativity, the study of AI's creative potential becomes imperative for\nits responsible development and application. In this paper, we prove in theory\nthat AI can be as creative as humans under the condition that it can properly\nfit the data generated by human creators. Therefore, the debate on AI's\ncreativity is reduced into the question of its ability to fit a sufficient\namount of data. To arrive at this conclusion, this paper first addresses the\ncomplexities in defining creativity by introducing a new concept called\nRelative Creativity. Rather than attempting to define creativity universally,\nwe shift the focus to whether AI can match the creative abilities of a\nhypothetical human. The methodological shift leads to a statistically\nquantifiable assessment of AI's creativity, term Statistical Creativity. This\nconcept, statistically comparing the creative abilities of AI with those of\nspecific human groups, facilitates theoretical exploration of AI's creative\npotential. Our analysis reveals that by fitting extensive conditional data\nwithout marginalizing out the generative conditions, AI can emerge as a\nhypothetical new creator. The creator possesses the same creative abilities on\npar with the human creators it was trained on. Building on theoretical\nfindings, we discuss the application in prompt-conditioned autoregressive\nmodels, providing a practical means for evaluating creative abilities of\ngenerative AI models, such as Large Language Models (LLMs). Additionally, this\nstudy provides an actionable training guideline, bridging the theoretical\nquantification of creativity with practical model training.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "The paper examines AI's creativity, introducing Relative and\n  Statistical Creativity for theoretical and practical analysis, along with\n  practical training guidelines. Project Page: ai-relative-creativity.github.io",
    "pdf_url": "http://arxiv.org/pdf/2401.01623v4",
    "published_date": "2024-01-03 08:49:12 UTC",
    "updated_date": "2024-01-25 13:10:15 UTC"
  },
  {
    "arxiv_id": "2401.01620v1",
    "title": "Large Language Model Capabilities in Perioperative Risk Prediction and Prognostication",
    "authors": [
      "Philip Chung",
      "Christine T Fong",
      "Andrew M Walters",
      "Nima Aghaeepour",
      "Meliha Yetisgen",
      "Vikas N O'Reilly-Shah"
    ],
    "abstract": "We investigate whether general-domain large language models such as GPT-4\nTurbo can perform risk stratification and predict post-operative outcome\nmeasures using a description of the procedure and a patient's clinical notes\nderived from the electronic health record. We examine predictive performance on\n8 different tasks: prediction of ASA Physical Status Classification, hospital\nadmission, ICU admission, unplanned admission, hospital mortality, PACU Phase 1\nduration, hospital duration, and ICU duration. Few-shot and chain-of-thought\nprompting improves predictive performance for several of the tasks. We achieve\nF1 scores of 0.50 for ASA Physical Status Classification, 0.81 for ICU\nadmission, and 0.86 for hospital mortality. Performance on duration prediction\ntasks were universally poor across all prompt strategies. Current generation\nlarge language models can assist clinicians in perioperative risk\nstratification on classification tasks and produce high-quality natural\nlanguage summaries and explanations.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.01620v1",
    "published_date": "2024-01-03 08:41:27 UTC",
    "updated_date": "2024-01-03 08:41:27 UTC"
  },
  {
    "arxiv_id": "2401.01614v2",
    "title": "GPT-4V(ision) is a Generalist Web Agent, if Grounded",
    "authors": [
      "Boyuan Zheng",
      "Boyu Gou",
      "Jihyung Kil",
      "Huan Sun",
      "Yu Su"
    ],
    "abstract": "The recent development on large multimodal models (LMMs), especially\nGPT-4V(ision) and Gemini, has been quickly expanding the capability boundaries\nof multimodal models beyond traditional tasks like image captioning and visual\nquestion answering. In this work, we explore the potential of LMMs like GPT-4V\nas a generalist web agent that can follow natural language instructions to\ncomplete tasks on any given website. We propose SEEACT, a generalist web agent\nthat harnesses the power of LMMs for integrated visual understanding and acting\non the web. We evaluate on the recent MIND2WEB benchmark. In addition to\nstandard offline evaluation on cached websites, we enable a new online\nevaluation setting by developing a tool that allows running web agents on live\nwebsites. We show that GPT-4V presents a great potential for web agents -- it\ncan successfully complete 51.1 of the tasks on live websites if we manually\nground its textual plans into actions on the websites. This substantially\noutperforms text-only LLMs like GPT-4 or smaller models (FLAN-T5 and BLIP-2)\nspecifically fine-tuned for web agents. However, grounding still remains a\nmajor challenge. Existing LMM grounding strategies like set-of-mark prompting\nturns out to be not effective for web agents, and the best grounding strategy\nwe develop in this paper leverages both the HTML structure and visuals. Yet,\nthere is still a substantial gap with oracle grounding, leaving ample room for\nfurther improvement. All code, data, and evaluation tools are available at\nhttps://github.com/OSU-NLP-Group/SeeAct.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.01614v2",
    "published_date": "2024-01-03 08:33:09 UTC",
    "updated_date": "2024-03-12 23:14:33 UTC"
  },
  {
    "arxiv_id": "2401.01600v1",
    "title": "PLLaMa: An Open-source Large Language Model for Plant Science",
    "authors": [
      "Xianjun Yang",
      "Junfeng Gao",
      "Wenxin Xue",
      "Erik Alexandersson"
    ],
    "abstract": "Large Language Models (LLMs) have exhibited remarkable capabilities in\nunderstanding and interacting with natural language across various sectors.\nHowever, their effectiveness is limited in specialized areas requiring high\naccuracy, such as plant science, due to a lack of specific expertise in these\nfields. This paper introduces PLLaMa, an open-source language model that\nevolved from LLaMa-2. It's enhanced with a comprehensive database, comprising\nmore than 1.5 million scholarly articles in plant science. This development\nsignificantly enriches PLLaMa with extensive knowledge and proficiency in plant\nand agricultural sciences. Our initial tests, involving specific datasets\nrelated to plants and agriculture, show that PLLaMa substantially improves its\nunderstanding of plant science-related topics. Moreover, we have formed an\ninternational panel of professionals, including plant scientists, agricultural\nengineers, and plant breeders. This team plays a crucial role in verifying the\naccuracy of PLLaMa's responses to various academic inquiries, ensuring its\neffective and reliable application in the field. To support further research\nand development, we have made the model's checkpoints and source codes\naccessible to the scientific community. These resources are available for\ndownload at \\url{https://github.com/Xianjun-Yang/PLLaMa}.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CE",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Work in progress",
    "pdf_url": "http://arxiv.org/pdf/2401.01600v1",
    "published_date": "2024-01-03 08:06:26 UTC",
    "updated_date": "2024-01-03 08:06:26 UTC"
  },
  {
    "arxiv_id": "2401.01596v1",
    "title": "MedSumm: A Multimodal Approach to Summarizing Code-Mixed Hindi-English Clinical Queries",
    "authors": [
      "Akash Ghosh",
      "Arkadeep Acharya",
      "Prince Jha",
      "Aniket Gaudgaul",
      "Rajdeep Majumdar",
      "Sriparna Saha",
      "Aman Chadha",
      "Raghav Jain",
      "Setu Sinha",
      "Shivani Agarwal"
    ],
    "abstract": "In the healthcare domain, summarizing medical questions posed by patients is\ncritical for improving doctor-patient interactions and medical decision-making.\nAlthough medical data has grown in complexity and quantity, the current body of\nresearch in this domain has primarily concentrated on text-based methods,\noverlooking the integration of visual cues. Also prior works in the area of\nmedical question summarisation have been limited to the English language. This\nwork introduces the task of multimodal medical question summarization for\ncodemixed input in a low-resource setting. To address this gap, we introduce\nthe Multimodal Medical Codemixed Question Summarization MMCQS dataset, which\ncombines Hindi-English codemixed medical queries with visual aids. This\nintegration enriches the representation of a patient's medical condition,\nproviding a more comprehensive perspective. We also propose a framework named\nMedSumm that leverages the power of LLMs and VLMs for this task. By utilizing\nour MMCQS dataset, we demonstrate the value of integrating visual information\nfrom images to improve the creation of medically detailed summaries. This\nmultimodal strategy not only improves healthcare decision-making but also\npromotes a deeper comprehension of patient queries, paving the way for future\nexploration in personalized and responsive medical care. Our dataset, code, and\npre-trained models will be made publicly available.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "ECIR 2024",
    "pdf_url": "http://arxiv.org/pdf/2401.01596v1",
    "published_date": "2024-01-03 07:58:25 UTC",
    "updated_date": "2024-01-03 07:58:25 UTC"
  },
  {
    "arxiv_id": "2402.03319v1",
    "title": "Physical Reservoir Computing Enabled by Solitary Waves and Biologically-Inspired Nonlinear Transformation of Input Data",
    "authors": [
      "Ivan S. Maksymov"
    ],
    "abstract": "Reservoir computing (RC) systems can efficiently forecast chaotic time series\nusing nonlinear dynamical properties of an artificial neural network of random\nconnections. The versatility of RC systems has motivated further research on\nboth hardware counterparts of traditional RC algorithms and more efficient\nRC-like schemes. Inspired by the nonlinear processes in a living biological\nbrain and using solitary waves excited on the surface of a flowing liquid film,\nin this paper we experimentally validate a physical RC system that substitutes\nthe effect of randomness for a nonlinear transformation of input data. Carrying\nout all operations using a microcontroller with a minimal computational power,\nwe demonstrate that the so-designed RC system serves as a technically simple\nhardware counterpart to the `next-generation' improvement of the traditional RC\nalgorithm.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "nlin.CD",
      "nlin.PS",
      "physics.flu-dyn"
    ],
    "primary_category": "cs.NE",
    "comment": "The Supplementary Video can be found here:\n  https://youtu.be/Zwu3KEo8f00",
    "pdf_url": "http://arxiv.org/pdf/2402.03319v1",
    "published_date": "2024-01-03 06:22:36 UTC",
    "updated_date": "2024-01-03 06:22:36 UTC"
  },
  {
    "arxiv_id": "2401.01542v1",
    "title": "Adversarial Machine Learning-Enabled Anonymization of OpenWiFi Data",
    "authors": [
      "Samhita Kuili",
      "Kareem Dabbour",
      "Irtiza Hasan",
      "Andrea Herscovich",
      "Burak Kantarci",
      "Marcel Chenier",
      "Melike Erol-Kantarci"
    ],
    "abstract": "Data privacy and protection through anonymization is a critical issue for\nnetwork operators or data owners before it is forwarded for other possible use\nof data. With the adoption of Artificial Intelligence (AI), data anonymization\naugments the likelihood of covering up necessary sensitive information;\npreventing data leakage and information loss. OpenWiFi networks are vulnerable\nto any adversary who is trying to gain access or knowledge on traffic\nregardless of the knowledge possessed by data owners. The odds for discovery of\nactual traffic information is addressed by applied conditional tabular\ngenerative adversarial network (CTGAN). CTGAN yields synthetic data; which\ndisguises as actual data but fostering hidden acute information of actual data.\nIn this paper, the similarity assessment of synthetic with actual data is\nshowcased in terms of clustering algorithms followed by a comparison of\nperformance for unsupervised cluster validation metrics. A well-known\nalgorithm, K-means outperforms other algorithms in terms of similarity\nassessment of synthetic data over real data while achieving nearest scores\n0.634, 23714.57, and 0.598 as Silhouette, Calinski and Harabasz and Davies\nBouldin metric respectively. On exploiting a comparative analysis in validation\nscores among several algorithms, K-means forms the epitome of unsupervised\nclustering algorithms ensuring explicit usage of synthetic data at the same\ntime a replacement for real data. Hence, the experimental results aim to show\nthe viability of using CTGAN-generated synthetic data in lieu of publishing\nanonymized data to be utilized in various applications.",
    "categories": [
      "cs.NI",
      "cs.AI"
    ],
    "primary_category": "cs.NI",
    "comment": "8 pages, 4 Figures, \"Wireless World Research and Trends\" Magazine.\n  Initial version was presented in 47th Wireless World Research Forum",
    "pdf_url": "http://arxiv.org/pdf/2401.01542v1",
    "published_date": "2024-01-03 04:59:03 UTC",
    "updated_date": "2024-01-03 04:59:03 UTC"
  },
  {
    "arxiv_id": "2401.01537v4",
    "title": "The Art of Deception: Robust Backdoor Attack using Dynamic Stacking of Triggers",
    "authors": [
      "Orson Mengara"
    ],
    "abstract": "The area of Machine Learning as a Service (MLaaS) is experiencing increased\nimplementation due to recent advancements in the AI (Artificial Intelligence)\nindustry. However, this spike has prompted concerns regarding AI defense\nmechanisms, specifically regarding potential covert attacks from third-party\nproviders that cannot be entirely trusted. Recent research has uncovered that\nauditory backdoors may use certain modifications as their initiating mechanism.\nDynamicTrigger is introduced as a methodology for carrying out dynamic backdoor\nattacks that use cleverly designed tweaks to ensure that corrupted samples are\nindistinguishable from clean. By utilizing fluctuating signal sampling rates\nand masking speaker identities through dynamic sound triggers (such as the\nclapping of hands), it is possible to deceive speech recognition systems (ASR).\nOur empirical testing demonstrates that DynamicTrigger is both potent and\nstealthy, achieving impressive success rates during covert attacks while\nmaintaining exceptional accuracy with non-poisoned datasets.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "Accepted by AAAI Workshop 2024",
    "pdf_url": "http://arxiv.org/pdf/2401.01537v4",
    "published_date": "2024-01-03 04:31:59 UTC",
    "updated_date": "2024-09-28 08:23:18 UTC"
  },
  {
    "arxiv_id": "2401.01523v4",
    "title": "GOAT-Bench: Safety Insights to Large Multimodal Models through Meme-Based Social Abuse",
    "authors": [
      "Hongzhan Lin",
      "Ziyang Luo",
      "Bo Wang",
      "Ruichao Yang",
      "Jing Ma"
    ],
    "abstract": "The exponential growth of social media has profoundly transformed how\ninformation is created, disseminated, and absorbed, exceeding any precedent in\nthe digital age. Regrettably, this explosion has also spawned a significant\nincrease in the online abuse of memes. Evaluating the negative impact of memes\nis notably challenging, owing to their often subtle and implicit meanings,\nwhich are not directly conveyed through the overt text and image. In light of\nthis, large multimodal models (LMMs) have emerged as a focal point of interest\ndue to their remarkable capabilities in handling diverse multimodal tasks. In\nresponse to this development, our paper aims to thoroughly examine the capacity\nof various LMMs (e.g., GPT-4o) to discern and respond to the nuanced aspects of\nsocial abuse manifested in memes. We introduce the comprehensive meme\nbenchmark, GOAT-Bench, comprising over 6K varied memes encapsulating themes\nsuch as implicit hate speech, sexism, and cyberbullying, etc. Utilizing\nGOAT-Bench, we delve into the ability of LMMs to accurately assess hatefulness,\nmisogyny, offensiveness, sarcasm, and harmful content. Our extensive\nexperiments across a range of LMMs reveal that current models still exhibit a\ndeficiency in safety awareness, showing insensitivity to various forms of\nimplicit abuse. We posit that this shortfall represents a critical impediment\nto the realization of safe artificial intelligence. The GOAT-Bench and\naccompanying resources are publicly accessible at https://goatlmm.github.io/,\ncontributing to ongoing research in this vital field.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "The first work to benchmark Large Multimodal Models in safety insight\n  on social media",
    "pdf_url": "http://arxiv.org/pdf/2401.01523v4",
    "published_date": "2024-01-03 03:28:55 UTC",
    "updated_date": "2025-02-28 15:13:46 UTC"
  },
  {
    "arxiv_id": "2401.01519v4",
    "title": "Exploring the Frontiers of LLMs in Psychological Applications: A Comprehensive Review",
    "authors": [
      "Luoma Ke",
      "Song Tong",
      "Peng Cheng",
      "Kaiping Peng"
    ],
    "abstract": "This paper explores the frontiers of large language models (LLMs) in\npsychology applications. Psychology has undergone several theoretical changes,\nand the current use of Artificial Intelligence (AI) and Machine Learning,\nparticularly LLMs, promises to open up new research directions. We provide a\ndetailed exploration of how LLMs like ChatGPT are transforming psychological\nresearch. It discusses the impact of LLMs across various branches of\npsychology, including cognitive and behavioral, clinical and counseling,\neducational and developmental, and social and cultural psychology, highlighting\ntheir potential to simulate aspects of human cognition and behavior. The paper\ndelves into the capabilities of these models to emulate human-like text\ngeneration, offering innovative tools for literature review, hypothesis\ngeneration, experimental design, experimental subjects, data analysis, academic\nwriting, and peer review in psychology. While LLMs are essential in advancing\nresearch methodologies in psychology, the paper also cautions about their\ntechnical and ethical challenges. There are issues like data privacy, the\nethical implications of using LLMs in psychological research, and the need for\na deeper understanding of these models' limitations. Researchers should\nresponsibly use LLMs in psychological studies, adhering to ethical standards\nand considering the potential consequences of deploying these technologies in\nsensitive areas. Overall, the article provides a comprehensive overview of the\ncurrent state of LLMs in psychology, exploring potential benefits and\nchallenges. It serves as a call to action for researchers to leverage LLMs'\nadvantages responsibly while addressing associated risks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.01519v4",
    "published_date": "2024-01-03 03:01:29 UTC",
    "updated_date": "2025-04-20 08:45:26 UTC"
  },
  {
    "arxiv_id": "2401.01496v1",
    "title": "From Pixel to Slide image: Polarization Modality-based Pathological Diagnosis Using Representation Learning",
    "authors": [
      "Jia Dong",
      "Yao Yao",
      "Yang Dong",
      "Hui Ma"
    ],
    "abstract": "Thyroid cancer is the most common endocrine malignancy, and accurately\ndistinguishing between benign and malignant thyroid tumors is crucial for\ndeveloping effective treatment plans in clinical practice. Pathologically,\nthyroid tumors pose diagnostic challenges due to improper specimen sampling. In\nthis study, we have designed a three-stage model using representation learning\nto integrate pixel-level and slice-level annotations for distinguishing thyroid\ntumors. This structure includes a pathology structure recognition method to\npredict structures related to thyroid tumors, an encoder-decoder network to\nextract pixel-level annotation information by learning the feature\nrepresentations of image blocks, and an attention-based learning mechanism for\nthe final classification task. This mechanism learns the importance of\ndifferent image blocks in a pathological region, globally considering the\ninformation from each block. In the third stage, all information from the image\nblocks in a region is aggregated using attention mechanisms, followed by\nclassification to determine the category of the region. Experimental results\ndemonstrate that our proposed method can predict microscopic structures more\naccurately. After color-coding, the method achieves results on unstained\npathology slides that approximate the quality of Hematoxylin and eosin\nstaining, reducing the need for stained pathology slides. Furthermore, by\nleveraging the concept of indirect measurement and extracting polarized\nfeatures from structures correlated with lesions, the proposed method can also\nclassify samples where membrane structures cannot be obtained through sampling,\nproviding a potential objective and highly accurate indirect diagnostic\ntechnique for thyroid tumors.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.01496v1",
    "published_date": "2024-01-03 02:01:09 UTC",
    "updated_date": "2024-01-03 02:01:09 UTC"
  },
  {
    "arxiv_id": "2401.01493v1",
    "title": "Free Lunch for Federated Remote Sensing Target Fine-Grained Classification: A Parameter-Efficient Framework",
    "authors": [
      "Shengchao Chen",
      "Ting Shu",
      "Huan Zhao",
      "Jiahao Wang",
      "Sufen Ren",
      "Lina Yang"
    ],
    "abstract": "Remote Sensing Target Fine-grained Classification (TFGC) is of great\nsignificance in both military and civilian fields. Due to location differences,\ngrowth in data size, and centralized server storage constraints, these data are\nusually stored under different databases across regions/countries. However,\nprivacy laws and national security concerns constrain researchers from\naccessing these sensitive remote sensing images for further analysis.\nAdditionally, low-resource remote sensing devices encounter challenges in terms\nof communication overhead and efficiency when dealing with the ever-increasing\ndata and model scales. To solve the above challenges, this paper proposes a\nnovel Privacy-Reserving TFGC Framework based on Federated Learning, dubbed\nPRFL. The proposed framework allows each client to learn global and local\nknowledge to enhance the local representation of private data in environments\nwith extreme statistical heterogeneity (non. Independent and Identically\nDistributed, IID). Thus, it provides highly customized models to clients with\ndifferentiated data distributions. Moreover, the framework minimizes\ncommunication overhead and improves efficiency while ensuring satisfactory\nperformance, thereby enhancing robustness and practical applicability under\nresource-scarce conditions. We demonstrate the effectiveness of the proposed\nPRFL on the classical TFGC task by leveraging four public datasets.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "Under Review, 23 pages, 3 figures, 12 tables",
    "pdf_url": "http://arxiv.org/pdf/2401.01493v1",
    "published_date": "2024-01-03 01:45:00 UTC",
    "updated_date": "2024-01-03 01:45:00 UTC"
  },
  {
    "arxiv_id": "2401.01489v1",
    "title": "The Neuron as a Direct Data-Driven Controller",
    "authors": [
      "Jason Moore",
      "Alexander Genkin",
      "Magnus Tournoy",
      "Joshua Pughe-Sanford",
      "Rob R. de Ruyter van Steveninck",
      "Dmitri B. Chklovskii"
    ],
    "abstract": "In the quest to model neuronal function amidst gaps in physiological data, a\npromising strategy is to develop a normative theory that interprets neuronal\nphysiology as optimizing a computational objective. This study extends the\ncurrent normative models, which primarily optimize prediction, by\nconceptualizing neurons as optimal feedback controllers. We posit that neurons,\nespecially those beyond early sensory areas, act as controllers, steering their\nenvironment towards a specific desired state through their output. This\nenvironment comprises both synaptically interlinked neurons and external motor\nsensory feedback loops, enabling neurons to evaluate the effectiveness of their\ncontrol via synaptic feedback. Utilizing the novel Direct Data-Driven Control\n(DD-DC) framework, we model neurons as biologically feasible controllers which\nimplicitly identify loop dynamics, infer latent states and optimize control.\nOur DD-DC neuron model explains various neurophysiological phenomena: the shift\nfrom potentiation to depression in Spike-Timing-Dependent Plasticity (STDP)\nwith its asymmetry, the duration and adaptive nature of feedforward and\nfeedback neuronal filters, the imprecision in spike generation under constant\nstimulation, and the characteristic operational variability and noise in the\nbrain. Our model presents a significant departure from the traditional,\nfeedforward, instant-response McCulloch-Pitts-Rosenblatt neuron, offering a\nnovel and biologically-informed fundamental unit for constructing neural\nnetworks.",
    "categories": [
      "q-bio.NC",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "q-bio.NC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.01489v1",
    "published_date": "2024-01-03 01:24:10 UTC",
    "updated_date": "2024-01-03 01:24:10 UTC"
  },
  {
    "arxiv_id": "2401.01484v1",
    "title": "Uncertainty Regularized Evidential Regression",
    "authors": [
      "Kai Ye",
      "Tiejin Chen",
      "Hua Wei",
      "Liang Zhan"
    ],
    "abstract": "The Evidential Regression Network (ERN) represents a novel approach that\nintegrates deep learning with Dempster-Shafer's theory to predict a target and\nquantify the associated uncertainty. Guided by the underlying theory, specific\nactivation functions must be employed to enforce non-negative values, which is\na constraint that compromises model performance by limiting its ability to\nlearn from all samples. This paper provides a theoretical analysis of this\nlimitation and introduces an improvement to overcome it. Initially, we define\nthe region where the models can't effectively learn from the samples. Following\nthis, we thoroughly analyze the ERN and investigate this constraint. Leveraging\nthe insights from our analysis, we address the limitation by introducing a\nnovel regularization term that empowers the ERN to learn from the whole\ntraining set. Our extensive experiments substantiate our theoretical findings\nand demonstrate the effectiveness of the proposed solution.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to AAAI 2024 main track",
    "pdf_url": "http://arxiv.org/pdf/2401.01484v1",
    "published_date": "2024-01-03 01:18:18 UTC",
    "updated_date": "2024-01-03 01:18:18 UTC"
  },
  {
    "arxiv_id": "2401.01482v2",
    "title": "Incorporating Geo-Diverse Knowledge into Prompting for Increased Geographical Robustness in Object Recognition",
    "authors": [
      "Kyle Buettner",
      "Sina Malakouti",
      "Xiang Lorraine Li",
      "Adriana Kovashka"
    ],
    "abstract": "Existing object recognition models have been shown to lack robustness in\ndiverse geographical scenarios due to domain shifts in design and context.\nClass representations need to be adapted to more accurately reflect an object\nconcept under these shifts. In the absence of training data from target\ngeographies, we hypothesize that geographically diverse descriptive knowledge\nof categories can enhance robustness. For this purpose, we explore the\nfeasibility of probing a large language model for geography-based object\nknowledge, and we examine the effects of integrating knowledge into zero-shot\nand learnable soft prompting with CLIP. Within this exploration, we propose\ngeography knowledge regularization to ensure that soft prompts trained on a\nsource set of geographies generalize to an unseen target set. Accuracy gains\nover prompting baselines on DollarStreet while training only on Europe data are\nup to +2.8/1.2/1.6 on target data from Africa/Asia/Americas, and +4.6 overall\non the hardest classes. Competitive performance is shown vs. few-shot target\ntraining, and analysis is provided to direct future study of geographical\nrobustness.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "To appear in IEEE/CVF Computer Vision and Pattern Recognition\n  Conference (CVPR), 2024",
    "pdf_url": "http://arxiv.org/pdf/2401.01482v2",
    "published_date": "2024-01-03 01:11:16 UTC",
    "updated_date": "2024-03-29 18:52:59 UTC"
  },
  {
    "arxiv_id": "2401.01470v2",
    "title": "TPC-ViT: Token Propagation Controller for Efficient Vision Transformer",
    "authors": [
      "Wentao Zhu"
    ],
    "abstract": "Vision transformers (ViTs) have achieved promising results on a variety of\nComputer Vision tasks, however their quadratic complexity in the number of\ninput tokens has limited their application specially in resource-constrained\nsettings. Previous approaches that employ gradual token reduction to address\nthis challenge assume that token redundancy in one layer implies redundancy in\nall the following layers. We empirically demonstrate that this assumption is\noften not correct, i.e., tokens that are redundant in one layer can be useful\nin later layers. We employ this key insight to propose a novel token\npropagation controller (TPC) that incorporates two different\ntoken-distributions, i.e., pause probability and restart probability to control\nthe reduction and reuse of tokens respectively, which results in more efficient\ntoken utilization. To improve the estimates of token distributions, we propose\na smoothing mechanism that acts as a regularizer and helps remove noisy\noutliers. Furthermore, to improve the training-stability of our proposed TPC,\nwe introduce a model stabilizer that is able to implicitly encode local image\nstructures and minimize accuracy fluctuations during model training. We present\nextensive experimental results on the ImageNet-1K dataset using DeiT, LV-ViT\nand Swin models to demonstrate the effectiveness of our proposed method. For\nexample, compared to baseline models, our proposed method improves the\ninference speed of the DeiT-S by 250% while increasing the classification\naccuracy by 1.0%.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.MM",
      "cs.NE"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by the main conference of WACV 2024; well-formatted PDF is\n  in\n  https://drive.google.com/file/d/1Id3oEdYv3OWing1qojQMyjvhZO-gG-Dm/view?usp=sharing\n  ; supplementary is in\n  https://drive.google.com/file/d/15LhYlBdCXtompA0_TLAp_ZJb4_sq2N5V/view?usp=sharing",
    "pdf_url": "http://arxiv.org/pdf/2401.01470v2",
    "published_date": "2024-01-03 00:10:33 UTC",
    "updated_date": "2024-01-08 17:03:15 UTC"
  },
  {
    "arxiv_id": "2401.01469v1",
    "title": "Question-Answering Based Summarization of Electronic Health Records using Retrieval Augmented Generation",
    "authors": [
      "Walid Saba",
      "Suzanne Wendelken",
      "James. Shanahan"
    ],
    "abstract": "Summarization of electronic health records (EHRs) can substantially minimize\n'screen time' for both patients as well as medical personnel. In recent years\nsummarization of EHRs have employed machine learning pipelines using state of\nthe art neural models. However, these models have produced less than adequate\nresults that are attributed to the difficulty of obtaining sufficient annotated\ndata for training. Moreover, the requirement to consider the entire content of\nan EHR in summarization has resulted in poor performance due to the fact that\nattention mechanisms in modern large language models (LLMs) adds a quadratic\ncomplexity in terms of the size of the input. We propose here a method that\nmitigates these shortcomings by combining semantic search, retrieval augmented\ngeneration (RAG) and question-answering using the latest LLMs. In our approach\nsummarization is the extraction of answers to specific questions that are\ndeemed important by subject-matter experts (SMEs). Our approach is quite\nefficient; requires minimal to no training; does not suffer from the\n'hallucination' problem of LLMs; and it ensures diversity, since the summary\nwill not have repeated content but diverse answers to specific questions.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.01469v1",
    "published_date": "2024-01-03 00:09:34 UTC",
    "updated_date": "2024-01-03 00:09:34 UTC"
  }
]