{
  "date": "2024-01-03",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-01-03 的 arXiv 中文 TLDR 快报！今天 arXiv 更新了 56 篇论文，主要聚焦 AI 模型优化、图像生成、医疗应用和机器学习算法等领域，其中令人印象深刻的包括 GPT-4 在医疗风险预测中的应用，以及多模态模型在图像生成和安全性上的突破，同时有知名学者如 David Held 和 Google 团队参与的相关工作。\n\n### 重点论文亮点\n我们挑选了今天最重要和话题性的论文，首先聊聊那些涉及大型语言模型（LLMs）和多模态 AI 的创新，这些工作展示了 AI 在实际应用中的潜力，并可能引发伦理讨论。接下来，快速概述其他相关论文。\n\n1. **On Time-Indexing as Inductive Bias in Deep RL for Sequential Manipulation Tasks（时间索引作为深度强化学习中的归纳偏差，用于顺序操作任务）**  \n   作者：M. Nomaan Qureshi, Ben Eisner, David Held  \n   这篇论文提出了一种新策略，使用时间索引作为归纳偏差，在深度强化学习中构建多模态策略架构，允许模型顺序执行不同动作头（如抓取和到达），显著提高了 Metaworld 任务中的样本效率和性能。贡献：提升了机器人操作任务的鲁棒性和效率，由知名学者 David Held 参与，值得关注 AI 在机器人领域的应用。\n\n2. **Revisiting Zero-Shot Abstractive Summarization in the Era of Large Language Models from the Perspective of Position Bias（从位置偏差角度重新审视大型语言模型时代的零样本抽象摘要生成）**  \n   作者：Anshuman Chhabra, Hadi Askari, Prasant Mohapatra  \n   论文分析了 LLMs（如 GPT-3.5-Turbo 和 Llama-2）在摘要任务中的位置偏差问题，通过实验揭示模型偏好特定输入部分，导致不公平输出。贡献：为零样本摘要提供新见解，并被 NAACL 2024 主会接受，强调了 LLMs 的局限性及其在文本处理的启示。\n\n3. **Instruct-Imagen: Image Generation with Multi-modal Instruction（多模态指令图像生成）**  \n   作者：Hexiang Hu, Kelvin C. K. Chan, Yu-Chuan Su, Wenhu Chen, Yandong Li, Kihyuk Sohn, Yang Zhao, Xue Ben, Boqing Gong, William Cohen, Ming-Wei Chang, Xuhui Jia  \n   Google 团队的作品，利用多模态指令（如文本和边缘）微调扩散模型，实现高效图像生成。贡献：提升了主观驱动生成任务的性能，并在新任务上泛化良好，展示了 LLMs 在多模态生成中的潜力。\n\n4. **GPS-SSL: Guided Positive Sampling to Inject Prior Into Self-Supervised Learning（引导正样本采样以注入先验知识的自监督学习）**  \n   作者：Aarash Feizi, Randall Balestriero, Adriana Romero-Soriano, Reihaneh Rabbany  \n   论文引入一种新方法，通过度量空间引导正样本采样，减少对数据增强的依赖，提升自监督学习效果。贡献：在 CIFAR-10 上达到 85.58% 准确率，即使使用弱增强，远超基线，适用于各种下游任务。\n\n5. **Harnessing Artificial Intelligence for Sustainable Agricultural Development in Africa: Opportunities, Challenges, and Impact（利用人工智能推动非洲可持续农业发展：机会、挑战和影响）**  \n   作者：Kinyua Gikunda  \n   这篇综述探讨 AI 在非洲农业中的应用，如精准农业和气候适应性实践，同时分析挑战（如基础设施问题）。贡献：提供政策洞见，促进 AI 在可持续发展中的作用，虽非前沿方法，但对实际应用有启发。\n\n6. **CoSS: Co-optimizing Sensor and Sampling Rate for Data-Efficient AI in Human Activity Recognition（传感器和采样率协同优化，用于数据高效的人类活动识别 AI）**  \n   作者：Mengxi Liu, Zimin Zhao, Daniel Geißler, Bo Zhou, Sungho Suh, Paul Lukowicz  \n   论文提出框架使用“权重分数”优化传感器和采样率，减少计算成本。贡献：在 HAR 基准数据集上实现类似全传感器性能但硬件成本更低，已被 AAAI24 研讨会接受。\n\n7. **FMGS: Foundation Model Embedded 3D Gaussian Splatting for Holistic 3D Scene Understanding（基础模型嵌入的 3D 高斯喷溅，用于整体 3D 场景理解）**  \n   作者：Xingxing Zuo, Pouya Samangouei, Yunwen Zhou, Yan Di, Mingyang Li  \n   工作整合视觉-语言模型到 3D 高斯喷溅中，提升语义一致性。贡献：在开放词汇对象检测上超越 SOTA 10.2%，推理速度快 851 倍，适用于增强现实和机器人。\n\n### 其他论文速览\n剩余论文涉及广泛主题，我们快速掠过不太核心的：\n- **A Mechanistic Understanding of Alignment Algorithms: A Case Study on DPO and Toxicity（对齐算法的机制理解：以 DPO 和毒性为例）**：分析 DPO 如何减少模型毒性，但易被逆转。贡献：揭示模型可逆性风险。\n- **Multilingual Instruction Tuning With Just a Pinch of Multilinguality（只需少量多语言的 multilingual 指令微调）**：作者：Uri Shaham 等。发现少量多语言样本即可提升 LLMs 的跨语言性能。贡献：简化多语言训练。\n- **GeoPos: A Minimal Positional Encoding for Enhanced Fine-Grained Details in Image Synthesis（最小位置编码用于提升图像合成的细粒度细节）**：通过相对坐标增强卷积层，改善图像生成质量。贡献：解决手部等几何细节问题。\n- **Large Language Models Relearn Removed Concepts（大型语言模型重新学习移除的概念）**：探索神经元修剪后模型重现概念。贡献：揭示模型记忆弹性，但安全风险高。\n- 其他如农业监测、量子神经网络、文本增强等论文（如第13、23、21篇），虽有技术创新，但影响力较小，仅提及其核心如雷达步长测量或文本数据增强方法。\n\n今天的 arXiv 更新突显 AI 在多领域应用的潜力，但也提醒我们关注模型的安全性和泛化问题。感兴趣的读者可查阅具体论文深入探讨！",
  "papers": [
    {
      "arxiv_id": "2401.06171v1",
      "title": "Harnessing Artificial Intelligence for Sustainable Agricultural Development in Africa: Opportunities, Challenges, and Impact",
      "title_zh": "翻译失败",
      "authors": [
        "Kinyua Gikunda"
      ],
      "abstract": "This paper explores the transformative potential of artificial intelligence\n(AI) in the context of sustainable agricultural development across diverse\nregions in Africa. Delving into opportunities, challenges, and impact, the\nstudy navigates through the dynamic landscape of AI applications in\nagriculture. Opportunities such as precision farming, crop monitoring, and\nclimate-resilient practices are examined, alongside challenges related to\ntechnological infrastructure, data accessibility, and skill gaps. The article\nanalyzes the impact of AI on smallholder farmers, supply chains, and inclusive\ngrowth. Ethical considerations and policy implications are also discussed,\noffering insights into responsible AI integration. By providing a nuanced\nunderstanding, this paper contributes to the ongoing discourse on leveraging AI\nfor fostering sustainability in African agriculture.",
      "tldr_zh": "这篇论文探讨了人工智能(AI)在非洲可持续农业发展中的潜力，分析了机会、挑战和影响。机会包括精准 farming、作物监测以及气候适应性实践，这些有助于提升农业效率；然而，挑战涉及技术基础设施不足、数据可访问性问题以及技能差距。论文评估了AI对小农、供应链和包容性增长的影响，并讨论了伦理考虑和政策含义。总体上，该研究为负责任地整合AI以促进非洲农业可持续发展提供了宝贵见解。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.06171v1",
      "published_date": "2024-01-03 23:02:13 UTC",
      "updated_date": "2024-01-03 23:02:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:27:13.084728"
    },
    {
      "arxiv_id": "2401.01993v1",
      "title": "On Time-Indexing as Inductive Bias in Deep RL for Sequential Manipulation Tasks",
      "title_zh": "论时间",
      "authors": [
        "M. Nomaan Qureshi",
        "Ben Eisner",
        "David Held"
      ],
      "abstract": "While solving complex manipulation tasks, manipulation policies often need to\nlearn a set of diverse skills to accomplish these tasks. The set of skills is\noften quite multimodal - each one may have a quite distinct distribution of\nactions and states. Standard deep policy-learning algorithms often model\npolicies as deep neural networks with a single output head (deterministic or\nstochastic). This structure requires the network to learn to switch between\nmodes internally, which can lead to lower sample efficiency and poor\nperformance. In this paper we explore a simple structure which is conducive to\nskill learning required for so many of the manipulation tasks. Specifically, we\npropose a policy architecture that sequentially executes different action heads\nfor fixed durations, enabling the learning of primitive skills such as reaching\nand grasping. Our empirical evaluation on the Metaworld tasks reveals that this\nsimple structure outperforms standard policy learning methods, highlighting its\npotential for improved skill acquisition.",
      "tldr_zh": "本文探讨了在深度强化学习(Deep RL)中引入时间索引作为诱导偏差(Inductive Bias)，以提升顺序操作任务的多模态技能学习效率。作者提出了一种策略架构，该架构通过固定持续时间顺序执行不同的动作头，方便学习基本技能如到达和抓取，从而避免标准神经网络单一输出头的模式切换问题。在Metaworld任务的实证评估中，这种方法比传统策略学习方法表现出色，显著提高了样本效率和整体性能。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.01993v1",
      "published_date": "2024-01-03 22:05:48 UTC",
      "updated_date": "2024-01-03 22:05:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:27:26.762734"
    },
    {
      "arxiv_id": "2401.05426v2",
      "title": "CoSS: Co-optimizing Sensor and Sampling Rate for Data-Efficient AI in Human Activity Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Mengxi Liu",
        "Zimin Zhao",
        "Daniel Geißler",
        "Bo Zhou",
        "Sungho Suh",
        "Paul Lukowicz"
      ],
      "abstract": "Recent advancements in Artificial Neural Networks have significantly improved\nhuman activity recognition using multiple time-series sensors. While employing\nnumerous sensors with high-frequency sampling rates usually improves the\nresults, it often leads to data inefficiency and unnecessary expansion of the\nANN, posing a challenge for their practical deployment on edge devices.\nAddressing these issues, our work introduces a pragmatic framework for\ndata-efficient utilization in HAR tasks, considering the optimization of both\nsensor modalities and sampling rate simultaneously. Central to our approach are\nthe designed trainable parameters, termed 'Weight Scores,' which assess the\nsignificance of each sensor modality and sampling rate during the training\nphase. These scores guide the sensor modalities and sampling rate selection.\nThe pruning method allows users to make a trade-off between computational\nbudgets and performance by selecting the sensor modalities and sampling rates\naccording to the weight score ranking. We tested our framework's effectiveness\nin optimizing sensor modality and sampling rate selection using three public\nHAR benchmark datasets. The results show that the sensor and sampling rate\ncombination selected via CoSS achieves similar classification performance to\nconfigurations using the highest sampling rate with all sensors but at a\nreduced hardware cost.",
      "tldr_zh": "该论文提出了 CoSS 框架，用于在人类活动识别 (HAR) 任务中联合优化传感器模态和采样率，以实现数据高效的 AI 应用。框架的核心是引入可训练的 Weight Scores 参数，这些参数在训练阶段评估每个传感器模态和采样率的显著性，并指导通过修剪方法进行选择，从而平衡计算预算和性能。实验结果显示，在三个公共 HAR 基准数据集上，CoSS 选定的传感器和采样率组合能达到与使用所有传感器和最高采样率相似的分类性能，但显著降低了硬件成本。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "Accepeted by the 2nd Workshop on Sustainable AI (AAAI24)",
      "pdf_url": "http://arxiv.org/pdf/2401.05426v2",
      "published_date": "2024-01-03 22:04:40 UTC",
      "updated_date": "2024-10-10 15:18:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:27:37.925161"
    },
    {
      "arxiv_id": "2401.01990v2",
      "title": "GPS-SSL: Guided Positive Sampling to Inject Prior Into Self-Supervised Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Aarash Feizi",
        "Randall Balestriero",
        "Adriana Romero-Soriano",
        "Reihaneh Rabbany"
      ],
      "abstract": "We propose Guided Positive Sampling Self-Supervised Learning (GPS-SSL), a\ngeneral method to inject a priori knowledge into Self-Supervised Learning (SSL)\npositive samples selection. Current SSL methods leverage Data-Augmentations\n(DA) for generating positive samples and incorporate prior knowledge - an\nincorrect, or too weak DA will drastically reduce the quality of the learned\nrepresentation. GPS-SSL proposes instead to design a metric space where\nEuclidean distances become a meaningful proxy for semantic relationship. In\nthat space, it is now possible to generate positive samples from nearest\nneighbor sampling. Any prior knowledge can now be embedded into that metric\nspace independently from the employed DA. From its simplicity, GPS-SSL is\napplicable to any SSL method, e.g. SimCLR or BYOL. A key benefit of GPS-SSL is\nin reducing the pressure in tailoring strong DAs. For example GPS-SSL reaches\n85.58% on Cifar10 with weak DA while the baseline only reaches 37.51%. We\ntherefore move a step forward towards the goal of making SSL less reliant on\nDA. We also show that even when using strong DAs, GPS-SSL outperforms the\nbaselines on under-studied domains. We evaluate GPS-SSL along with multiple\nbaseline SSL methods on numerous downstream datasets from different domains\nwhen the models use strong or minimal data augmentations. We hope that GPS-SSL\nwill open new avenues in studying how to inject a priori knowledge into SSL in\na principled manner.",
      "tldr_zh": "该论文提出了一种名为 GPS-SSL 的通用方法，用于将先验知识注入自监督学习 (SSL) 的正样本选择中，通过设计一个度量空间，使欧氏距离成为语义关系的代理，从而从最近邻采样生成正样本。不同于传统 SSL 方法依赖数据增强 (DA)，GPS-SSL 允许独立嵌入先验知识，适用于如 SimCLR 或 BYOL 等框架，并显著减少了对强 DA 的需求。实验结果显示，在 Cifar10 数据集上，使用弱 DA 时，GPS-SSL 达到 85.58% 的性能，而基线仅为 37.51%；即使采用强 DA，它也在欠研究领域优于基线。总体而言，该方法为以原则方式提升 SSL 的鲁棒性和泛化能力提供了新途径。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.01990v2",
      "published_date": "2024-01-03 21:39:06 UTC",
      "updated_date": "2024-01-09 18:24:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:27:52.803695"
    },
    {
      "arxiv_id": "2401.01989v3",
      "title": "Revisiting Zero-Shot Abstractive Summarization in the Era of Large Language Models from the Perspective of Position Bias",
      "title_zh": "在大型语言模型时代，从位置偏差视角重新审视零样本抽象式摘要生成",
      "authors": [
        "Anshuman Chhabra",
        "Hadi Askari",
        "Prasant Mohapatra"
      ],
      "abstract": "We characterize and study zero-shot abstractive summarization in Large\nLanguage Models (LLMs) by measuring position bias, which we propose as a\ngeneral formulation of the more restrictive lead bias phenomenon studied\npreviously in the literature. Position bias captures the tendency of a model\nunfairly prioritizing information from certain parts of the input text over\nothers, leading to undesirable behavior. Through numerous experiments on four\ndiverse real-world datasets, we study position bias in multiple LLM models such\nas GPT 3.5-Turbo, Llama-2, and Dolly-v2, as well as state-of-the-art pretrained\nencoder-decoder abstractive summarization models such as Pegasus and BART. Our\nfindings lead to novel insights and discussion on performance and position bias\nof models for zero-shot summarization tasks.",
      "tldr_zh": "本研究从位置偏差（Position Bias）的角度重新审视大型语言模型（Large Language Models, LLMs）时代下的零样本抽象摘要生成（Zero-Shot Abstractive Summarization），将位置偏差定义为模型偏好特定输入部分信息的倾向，比以往研究的 lead bias 更具普遍性。通过在四个多样化数据集上的实验，评估了如 GPT-3.5-Turbo、Llama-2 和 Dolly-v2 等 LLMs，以及 Pegasus 和 BART 等预训练模型的性能和偏差。结果揭示了这些模型在零样本摘要任务中的新洞见，包括偏差如何影响摘要质量，并为未来优化提供讨论。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to NAACL 2024 Main Conference",
      "pdf_url": "http://arxiv.org/pdf/2401.01989v3",
      "published_date": "2024-01-03 21:38:40 UTC",
      "updated_date": "2024-03-18 20:09:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:28:01.445533"
    },
    {
      "arxiv_id": "2401.10266v2",
      "title": "Intelligent Condition Monitoring of Industrial Plants: An Overview of Methodologies and Uncertainty Management Strategies",
      "title_zh": "工业厂房的智能状态监测：方法论和不确定性管理策略概述",
      "authors": [
        "Maryam Ahang",
        "Todd Charter",
        "Oluwaseyi Ogunfowora",
        "Maziyar Khadivi",
        "Mostafa Abbasi",
        "Homayoun Najjaran"
      ],
      "abstract": "Condition monitoring plays a significant role in the safety and reliability\nof modern industrial systems. Artificial intelligence (AI) approaches are\ngaining attention from academia and industry as a growing subject in industrial\napplications and as a powerful way of identifying faults. This paper provides\nan overview of intelligent condition monitoring and fault detection and\ndiagnosis methods for industrial plants with a focus on the open-source\nbenchmark Tennessee Eastman Process (TEP). In this survey, the most popular and\nstate-of-the-art deep learning (DL) and machine learning (ML) algorithms for\nindustrial plant condition monitoring, fault detection, and diagnosis are\nsummarized and the advantages and disadvantages of each algorithm are studied.\nChallenges like imbalanced data, unlabelled samples and how deep learning\nmodels can handle them are also covered. Finally, a comparison of the\naccuracies and specifications of different algorithms utilizing the Tennessee\nEastman Process (TEP) is conducted. This research will be beneficial for both\nresearchers who are new to the field and experts, as it covers the literature\non condition monitoring and state-of-the-art methods alongside the challenges\nand possible solutions to them.",
      "tldr_zh": "这篇论文概述了工业植物的智能条件监测及其方法论，特别是针对故障检测和诊断的AI方法。作者总结了最流行的深度学习(DL)和机器学习(ML)算法，包括它们的优缺点，并以开源基准Tennessee Eastman Process (TEP)为例进行比较，突出了算法在处理数据不平衡和无标签样本等挑战时的表现。该研究还讨论了这些算法的准确性和规格差异，为初学者和专家提供了一个全面的文献综述和潜在解决方案，从而提升工业系统的安全性和可靠性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SY",
        "eess.SP",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.10266v2",
      "published_date": "2024-01-03 21:35:03 UTC",
      "updated_date": "2025-04-28 22:03:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:28:12.757995"
    },
    {
      "arxiv_id": "2401.01974v2",
      "title": "Towards Truly Zero-shot Compositional Visual Reasoning with LLMs as Programmers",
      "title_zh": "翻译失败",
      "authors": [
        "Aleksandar Stanić",
        "Sergi Caelles",
        "Michael Tschannen"
      ],
      "abstract": "Visual reasoning is dominated by end-to-end neural networks scaled to\nbillions of model parameters and training examples. However, even the largest\nmodels struggle with compositional reasoning, generalization, fine-grained\nspatial and temporal reasoning, and counting. Visual reasoning with large\nlanguage models (LLMs) as controllers can, in principle, address these\nlimitations by decomposing the task and solving subtasks by orchestrating a set\nof (visual) tools. Recently, these models achieved great performance on tasks\nsuch as compositional visual question answering, visual grounding, and video\ntemporal reasoning. Nevertheless, in their current form, these models heavily\nrely on human engineering of in-context examples in the prompt, which are often\ndataset- and task-specific and require significant labor by highly skilled\nprogrammers. In this work, we present a framework that mitigates these issues\nby introducing spatially and temporally abstract routines and by leveraging a\nsmall number of labeled examples to automatically generate in-context examples,\nthereby avoiding human-created in-context examples. On a number of visual\nreasoning tasks, we show that our framework leads to consistent gains in\nperformance, makes LLMs as controllers setup more robust, and removes the need\nfor human engineering of in-context examples.",
      "tldr_zh": "该论文探讨了视觉推理领域的挑战，包括端到端神经网络在组合推理（compositional reasoning）、泛化和细粒度空间/时间推理方面的局限性，并提出一种新框架，使用大型语言模型（LLMs）作为控制器来协调工具解决子任务。该框架引入空间和时间抽象例程（spatially and temporally abstract routines），并利用少量标记示例自动生成 in-context examples，从而避免了人工设计这些示例的劳动密集型工作。在多个视觉推理任务上，实验结果显示该框架显著提高了性能，使 LLMs 作为控制器的设置更鲁棒，并实现了真正的 zero-shot 组合视觉推理。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.01974v2",
      "published_date": "2024-01-03 20:48:47 UTC",
      "updated_date": "2024-05-14 22:43:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:28:26.996799"
    },
    {
      "arxiv_id": "2401.01970v2",
      "title": "FMGS: Foundation Model Embedded 3D Gaussian Splatting for Holistic 3D Scene Understanding",
      "title_zh": "翻译失败",
      "authors": [
        "Xingxing Zuo",
        "Pouya Samangouei",
        "Yunwen Zhou",
        "Yan Di",
        "Mingyang Li"
      ],
      "abstract": "Precisely perceiving the geometric and semantic properties of real-world 3D\nobjects is crucial for the continued evolution of augmented reality and robotic\napplications. To this end, we present Foundation Model Embedded Gaussian\nSplatting (FMGS), which incorporates vision-language embeddings of foundation\nmodels into 3D Gaussian Splatting (GS). The key contribution of this work is an\nefficient method to reconstruct and represent 3D vision-language models. This\nis achieved by distilling feature maps generated from image-based foundation\nmodels into those rendered from our 3D model. To ensure high-quality rendering\nand fast training, we introduce a novel scene representation by integrating\nstrengths from both GS and multi-resolution hash encodings (MHE). Our effective\ntraining procedure also introduces a pixel alignment loss that makes the\nrendered feature distance of the same semantic entities close, following the\npixel-level semantic boundaries. Our results demonstrate remarkable multi-view\nsemantic consistency, facilitating diverse downstream tasks, beating\nstate-of-the-art methods by 10.2 percent on open-vocabulary language-based\nobject detection, despite that we are 851X faster for inference. This research\nexplores the intersection of vision, language, and 3D scene representation,\npaving the way for enhanced scene understanding in uncontrolled real-world\nenvironments. We plan to release the code on the project page.",
      "tldr_zh": "本研究提出 FMGS，一种将 Foundation Model 的视觉语言嵌入整合到 3D Gaussian Splatting (GS) 中的框架，用于实现全面的 3D 场景理解。关键方法包括通过特征图蒸馏将图像基础模型的输出转移到 3D 模型中，并结合 GS 和多分辨率哈希编码 (MHE) 的优势，同时引入像素对齐损失 (pixel alignment loss) 以提升语义边界一致性。实验结果显示，FMGS 在开放词汇语言-based 对象检测任务上比最先进方法提升 10.2%，且推理速度快 851 倍，为增强现实和机器人应用中的真实世界场景理解提供了高效解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Project page: https://xingxingzuo.github.io/fmgs",
      "pdf_url": "http://arxiv.org/pdf/2401.01970v2",
      "published_date": "2024-01-03 20:39:02 UTC",
      "updated_date": "2024-05-03 23:33:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:28:38.543885"
    },
    {
      "arxiv_id": "2401.01967v1",
      "title": "A Mechanistic Understanding of Alignment Algorithms: A Case Study on DPO and Toxicity",
      "title_zh": "翻译失败",
      "authors": [
        "Andrew Lee",
        "Xiaoyan Bai",
        "Itamar Pres",
        "Martin Wattenberg",
        "Jonathan K. Kummerfeld",
        "Rada Mihalcea"
      ],
      "abstract": "While alignment algorithms are now commonly used to tune pre-trained language\nmodels towards a user's preferences, we lack explanations for the underlying\nmechanisms in which models become ``aligned'', thus making it difficult to\nexplain phenomena like jailbreaks. In this work we study a popular algorithm,\ndirect preference optimization (DPO), and the mechanisms by which it reduces\ntoxicity. Namely, we first study how toxicity is represented and elicited in a\npre-trained language model, GPT2-medium. We then apply DPO with a carefully\ncrafted pairwise dataset to reduce toxicity. We examine how the resulting model\naverts toxic outputs, and find that capabilities learned from pre-training are\nnot removed, but rather bypassed. We use this insight to demonstrate a simple\nmethod to un-align the model, reverting it back to its toxic behavior.",
      "tldr_zh": "本研究探讨了alignment algorithms（对齐算法）的底层机制，以DPO（Direct Preference Optimization）减少语言模型毒性（toxicity）为例。研究者首先分析了在预训练模型如GPT2-medium中毒性是如何表示和引发的，然后使用精心设计的配对数据集应用DPO来降低毒性。结果发现，DPO并未移除模型的预训练能力，而是通过绕过机制避免毒性输出；基于此，他们演示了一种简单方法来逆转模型的对齐，使其恢复毒性行为。该工作为解释现象如jailbreaks（越狱攻击）提供了新见解，有助于提升语言模型的安全性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.01967v1",
      "published_date": "2024-01-03 20:26:15 UTC",
      "updated_date": "2024-01-03 20:26:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:28:48.360894"
    },
    {
      "arxiv_id": "2401.01952v1",
      "title": "Instruct-Imagen: Image Generation with Multi-modal Instruction",
      "title_zh": "Instruct-Imagen：基于多模态指令的图像生成",
      "authors": [
        "Hexiang Hu",
        "Kelvin C. K. Chan",
        "Yu-Chuan Su",
        "Wenhu Chen",
        "Yandong Li",
        "Kihyuk Sohn",
        "Yang Zhao",
        "Xue Ben",
        "Boqing Gong",
        "William Cohen",
        "Ming-Wei Chang",
        "Xuhui Jia"
      ],
      "abstract": "This paper presents instruct-imagen, a model that tackles heterogeneous image\ngeneration tasks and generalizes across unseen tasks. We introduce *multi-modal\ninstruction* for image generation, a task representation articulating a range\nof generation intents with precision. It uses natural language to amalgamate\ndisparate modalities (e.g., text, edge, style, subject, etc.), such that\nabundant generation intents can be standardized in a uniform format.\n  We then build instruct-imagen by fine-tuning a pre-trained text-to-image\ndiffusion model with a two-stage framework. First, we adapt the model using the\nretrieval-augmented training, to enhance model's capabilities to ground its\ngeneration on external multimodal context. Subsequently, we fine-tune the\nadapted model on diverse image generation tasks that requires vision-language\nunderstanding (e.g., subject-driven generation, etc.), each paired with a\nmulti-modal instruction encapsulating the task's essence. Human evaluation on\nvarious image generation datasets reveals that instruct-imagen matches or\nsurpasses prior task-specific models in-domain and demonstrates promising\ngeneralization to unseen and more complex tasks.",
      "tldr_zh": "本文提出 Instruct-Imagen 模型，用于处理异构图像生成任务并实现对未见任务的泛化。它引入 multi-modal instruction 作为任务表示方法，通过自然语言整合不同模态（如文本、边缘、风格和主题），以标准化各种生成意图。模型采用两阶段框架微调预训练的文本到图像扩散模型：首先通过 retrieval-augmented training 增强基于外部多模态上下文的生成能力，然后在需要视觉语言理解的任务（如主体驱动生成）上进一步微调。人类评估结果显示，Instruct-Imagen 在多种图像生成数据集上匹配或超越先前特定任务模型，并在未见和更复杂任务上表现出良好的泛化性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "20 pages, 18 figures",
      "pdf_url": "http://arxiv.org/pdf/2401.01952v1",
      "published_date": "2024-01-03 19:31:58 UTC",
      "updated_date": "2024-01-03 19:31:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:29:03.193625"
    },
    {
      "arxiv_id": "2401.01951v2",
      "title": "GeoPos: A Minimal Positional Encoding for Enhanced Fine-Grained Details in Image Synthesis Using Convolutional Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Mehran Hosseini",
        "Peyman Hosseini"
      ],
      "abstract": "The enduring inability of image generative models to recreate intricate\ngeometric features, such as those present in human hands and fingers has been\nan ongoing problem in image generation for nearly a decade. While strides have\nbeen made by increasing model sizes and diversifying training datasets, this\nissue remains prevalent across all models, from denoising diffusion models to\nGenerative Adversarial Networks (GAN), pointing to a fundamental shortcoming in\nthe underlying architectures. In this paper, we demonstrate how this problem\ncan be mitigated by augmenting convolution layers geometric capabilities\nthrough providing them with a single input channel incorporating the relative\nn-dimensional Cartesian coordinate system. We show this drastically improves\nquality of images generated by Diffusion Models, GANs, and Variational\nAutoEncoders (VAE).",
      "tldr_zh": "本论文针对图像生成模型在重现复杂几何特征（如人手和手指细节）上的长期问题，提出了一种名为GeoPos的最小位置编码方法。GeoPos通过在卷积神经网络的卷积层中添加一个输入通道，提供相对的n维笛卡尔坐标系统，从而增强模型对精细几何细节的处理能力。实验结果表明，该方法显著改善了Diffusion Models、Generative Adversarial Networks (GANs) 和 Variational AutoEncoders (VAE) 生成图像的质量。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "51",
        "I.2.10; I.4.0; I.4.10"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at WACV 2025. Contains 19 pages, 15 figures, and 9 tables",
      "pdf_url": "http://arxiv.org/pdf/2401.01951v2",
      "published_date": "2024-01-03 19:27:20 UTC",
      "updated_date": "2024-12-05 17:31:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:29:19.606945"
    },
    {
      "arxiv_id": "2401.01943v2",
      "title": "Generalist embedding models are better at short-context clinical semantic search than specialized embedding models",
      "title_zh": "泛化嵌入模型在短上下文临床语义搜索中比专业化嵌入模型表现更好",
      "authors": [
        "Jean-Baptiste Excoffier",
        "Tom Roehr",
        "Alexei Figueroa",
        "Jens-Michalis Papaioannou",
        "Keno Bressem",
        "Matthieu Ortala"
      ],
      "abstract": "The increasing use of tools and solutions based on Large Language Models\n(LLMs) for various tasks in the medical domain has become a prominent trend.\nTheir use in this highly critical and sensitive domain has thus raised\nimportant questions about their robustness, especially in response to\nvariations in input, and the reliability of the generated outputs. This study\naddresses these questions by constructing a textual dataset based on the\nICD-10-CM code descriptions, widely used in US hospitals and containing many\nclinical terms, and their easily reproducible rephrasing. We then benchmarked\nexisting embedding models, either generalist or specialized in the clinical\ndomain, in a semantic search task where the goal was to correctly match the\nrephrased text to the original description. Our results showed that generalist\nmodels performed better than clinical models, suggesting that existing clinical\nspecialized models are more sensitive to small changes in input that confuse\nthem. The highlighted problem of specialized models may be due to the fact that\nthey have not been trained on sufficient data, and in particular on datasets\nthat are not diverse enough to have a reliable global language understanding,\nwhich is still necessary for accurate handling of medical documents.",
      "tldr_zh": "这篇论文比较了通用 embedding models 与专业临床 embedding models 在短语境临床语义搜索中的性能，通过构建基于 ICD-10-CM 代码描述的文本数据集（包括原描述和再表述）进行基准测试。结果显示，通用模型的表现优于专业模型，尤其在处理输入小变化时更鲁棒。研究发现，专业模型的敏感性可能源于训练数据不足和多样性不够，导致全球语言理解能力较弱。该发现为提升医疗领域 Large Language Models (LLMs) 的可靠性提供了重要启示。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "11 pages, 1 figure, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2401.01943v2",
      "published_date": "2024-01-03 19:03:32 UTC",
      "updated_date": "2024-01-06 09:51:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:29:31.307544"
    },
    {
      "arxiv_id": "2401.01868v1",
      "title": "Step length measurement in the wild using FMCW radar",
      "title_zh": "翻译失败",
      "authors": [
        "Parthipan Siva",
        "Alexander Wong",
        "Patricia Hewston",
        "George Ioannidis",
        "Jonathan Adachi",
        "Alexander Rabinovich",
        "Andrea Lee",
        "Alexandra Papaioannou"
      ],
      "abstract": "With an aging population, numerous assistive and monitoring technologies are\nunder development to enable older adults to age in place. To facilitate aging\nin place predicting risk factors such as falls, and hospitalization and\nproviding early interventions are important. Much of the work on ambient\nmonitoring for risk prediction has centered on gait speed analysis, utilizing\nprivacy-preserving sensors like radar. Despite compelling evidence that\nmonitoring step length, in addition to gait speed, is crucial for predicting\nrisk, radar-based methods have not explored step length measurement in the\nhome. Furthermore, laboratory experiments on step length measurement using\nradars are limited to proof of concept studies with few healthy subjects. To\naddress this gap, a radar-based step length measurement system for the home is\nproposed based on detection and tracking using radar point cloud, followed by\nDoppler speed profiling of the torso to obtain step lengths in the home. The\nproposed method was evaluated in a clinical environment, involving 35 frail\nolder adults, to establish its validity. Additionally, the method was assessed\nin people's homes, with 21 frail older adults who had participated in the\nclinical assessment. The proposed radar-based step length measurement method\nwas compared to the gold standard Zeno Walkway Gait Analysis System, revealing\na 4.5cm/8.3% error in a clinical setting. Furthermore, it exhibited excellent\nreliability (ICC(2,k)=0.91, 95% CI 0.82 to 0.96) in uncontrolled home settings.\nThe method also proved accurate in uncontrolled home settings, as indicated by\na strong agreement (ICC(3,k)=0.81 (95% CI 0.53 to 0.92)) between home\nmeasurements and in-clinic assessments.",
      "tldr_zh": "这篇论文针对老龄化人口的居家养老需求，提出了一种基于 FMCW radar 的步长测量系统，用于预测风险因素如跌倒和住院。该系统通过雷达点云检测和跟踪结合躯干的多普勒速度分析（Doppler speed profiling），在家中环境实现步长测量。实验在临床设置中（35 名虚弱老年人）验证，与黄金标准 Zeno Walkway Gait Analysis System 相比，误差为 4.5 cm / 8.3%；在家中测试（21 名虚弱老年人）中，显示出优秀可靠性（ICC(2,k)=0.91）和与临床评估的高度一致性（ICC(3,k)=0.81），为非侵入式健康监测提供了重要进展。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "I.5.4; C.3; J.7"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.01868v1",
      "published_date": "2024-01-03 18:23:30 UTC",
      "updated_date": "2024-01-03 18:23:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:29:47.018130"
    },
    {
      "arxiv_id": "2401.01854v4",
      "title": "Multilingual Instruction Tuning With Just a Pinch of Multilinguality",
      "title_zh": "翻译失败",
      "authors": [
        "Uri Shaham",
        "Jonathan Herzig",
        "Roee Aharoni",
        "Idan Szpektor",
        "Reut Tsarfaty",
        "Matan Eyal"
      ],
      "abstract": "As instruction-tuned large language models (LLMs) gain global adoption, their\nability to follow instructions in multiple languages becomes increasingly\ncrucial. In this work, we investigate how multilinguality during instruction\ntuning of a multilingual LLM affects instruction-following across languages\nfrom the pre-training corpus. We first show that many languages transfer some\ninstruction-following capabilities to other languages from even monolingual\ntuning. Furthermore, we find that only 40 multilingual examples integrated in\nan English tuning set substantially improve multilingual instruction-following,\nboth in seen and unseen languages during tuning. In general, we observe that\nmodels tuned on multilingual mixtures exhibit comparable or superior\nperformance in multiple languages compared to monolingually tuned models,\ndespite training on 10x fewer examples in those languages. Finally, we find\nthat diversifying the instruction tuning set with even just 2-4 languages\nsignificantly improves cross-lingual generalization. Our results suggest that\nbuilding massively multilingual instruction-tuned models can be done with only\na very small set of multilingual instruction-responses.",
      "tldr_zh": "该研究探讨了在指令调优（instruction tuning）多语言大型语言模型（LLMs）中，添加少量多语言数据如何提升跨语言指令跟随能力。结果显示，即使使用单语言调优，许多语言也能转移指令跟随能力，而仅在英语调优集中加入40个多语言示例，就能显著改善多语言性能，包括调优中未见过的语言。多语言混合调优的模型在多种语言中表现出色或优于单语言调优模型，尽管在那些语言中训练样本减少10倍；此外，通过在调优集中多样化2-4种语言，可显著增强跨语言泛化。这些发现表明，构建大规模多语言指令调优模型只需极少的多语言指令响应集。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Findings of ACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.01854v4",
      "published_date": "2024-01-03 17:48:10 UTC",
      "updated_date": "2024-05-21 09:19:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:29:56.303073"
    },
    {
      "arxiv_id": "2401.01851v4",
      "title": "The Power of Training: How Different Neural Network Setups Influence the Energy Demand",
      "title_zh": "训练的力量：不同神经网络设置如何影响能源需求",
      "authors": [
        "Daniel Geißler",
        "Bo Zhou",
        "Mengxi Liu",
        "Sungho Suh",
        "Paul Lukowicz"
      ],
      "abstract": "This work offers a heuristic evaluation of the effects of variations in\nmachine learning training regimes and learning paradigms on the energy\nconsumption of computing, especially HPC hardware with a life-cycle aware\nperspective. While increasing data availability and innovation in\nhigh-performance hardware fuels the training of sophisticated models, it also\nfosters the fading perception of energy consumption and carbon emission.\nTherefore, the goal of this work is to raise awareness about the energy impact\nof general training parameters and processes, from learning rate over batch\nsize to knowledge transfer. Multiple setups with different hyperparameter\nconfigurations are evaluated on three different hardware systems. Among many\nresults, we have found out that even with the same model and hardware to reach\nthe same accuracy, improperly set training hyperparameters consume up to 5\ntimes the energy of the optimal setup. We also extensively examined the\nenergy-saving benefits of learning paradigms including recycling knowledge\nthrough pretraining and sharing knowledge through multitask training.",
      "tldr_zh": "本研究评估了机器学习训练参数和范式对计算能源消耗的影响，特别是针对高性能计算(HPC)硬件，并从生命周期角度提高能源和碳排放意识。研究者通过在三种不同硬件系统上测试多种超参数配置（如学习率、批量大小和知识转移），发现相同的模型和硬件下，不适当的训练超参数可能导致能源消耗增加高达5倍。实验还证明了预训练和多任务训练等学习范式在能源节约方面的显著益处，为优化神经网络训练提供指导。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.PF"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.01851v4",
      "published_date": "2024-01-03 17:44:17 UTC",
      "updated_date": "2024-10-05 06:13:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:30:05.731870"
    },
    {
      "arxiv_id": "2401.02991v1",
      "title": "GLIDE-RL: Grounded Language Instruction through DEmonstration in RL",
      "title_zh": "翻译失败",
      "authors": [
        "Chaitanya Kharyal",
        "Sai Krishna Gottipati",
        "Tanmay Kumar Sinha",
        "Srijita Das",
        "Matthew E. Taylor"
      ],
      "abstract": "One of the final frontiers in the development of complex human - AI\ncollaborative systems is the ability of AI agents to comprehend the natural\nlanguage and perform tasks accordingly. However, training efficient\nReinforcement Learning (RL) agents grounded in natural language has been a\nlong-standing challenge due to the complexity and ambiguity of the language and\nsparsity of the rewards, among other factors. Several advances in reinforcement\nlearning, curriculum learning, continual learning, language models have\nindependently contributed to effective training of grounded agents in various\nenvironments. Leveraging these developments, we present a novel algorithm,\nGrounded Language Instruction through DEmonstration in RL (GLIDE-RL) that\nintroduces a teacher-instructor-student curriculum learning framework for\ntraining an RL agent capable of following natural language instructions that\ncan generalize to previously unseen language instructions. In this multi-agent\nframework, the teacher and the student agents learn simultaneously based on the\nstudent's current skill level. We further demonstrate the necessity for\ntraining the student agent with not just one, but multiple teacher agents.\nExperiments on a complex sparse reward environment validates the effectiveness\nof our proposed approach.",
      "tldr_zh": "该论文提出 GLIDE-RL 算法，一个基于教师-指导者-学生课程学习框架的多代理系统，用于训练 Reinforcement Learning (RL) 代理理解和执行自然语言指令。该框架允许教师代理和学生代理同时学习，根据学生的当前技能水平动态调整训练过程，并强调使用多个教师代理来提升代理的泛化能力。实验结果在复杂稀疏奖励环境中证明了 GLIDE-RL 的有效性，使代理能够处理先前未见过的语言指令，从而推进 AI 与人类的协作系统发展。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "12 pages, 6 figures, to be presented at AAMAS 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.02991v1",
      "published_date": "2024-01-03 17:32:13 UTC",
      "updated_date": "2024-01-03 17:32:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:30:20.628005"
    },
    {
      "arxiv_id": "2401.01843v2",
      "title": "Investigating Semi-Supervised Learning Algorithms in Text Datasets",
      "title_zh": "翻译失败",
      "authors": [
        "Himmet Toprak Kesgin",
        "Mehmet Fatih Amasyali"
      ],
      "abstract": "Using large training datasets enhances the generalization capabilities of\nneural networks. Semi-supervised learning (SSL) is useful when there are few\nlabeled data and a lot of unlabeled data. SSL methods that use data\naugmentation are most successful for image datasets. In contrast, texts do not\nhave consistent augmentation methods as images. Consequently, methods that use\naugmentation are not as effective in text data as they are in image data. In\nthis study, we compared SSL algorithms that do not require augmentation; these\nare self-training, co-training, tri-training, and tri-training with\ndisagreement. In the experiments, we used 4 different text datasets for\ndifferent tasks. We examined the algorithms from a variety of perspectives by\nasking experiment questions and suggested several improvements. Among the\nalgorithms, tri-training with disagreement showed the closest performance to\nthe Oracle; however, performance gap shows that new semi-supervised algorithms\nor improvements in existing methods are needed.",
      "tldr_zh": "这篇论文探讨了半监督学习(SSL)算法在文本数据集中的应用，强调了文本数据与图像数据在数据增强方面的差异，导致传统SSL方法效果不佳。研究者比较了不依赖增强的算法，包括self-training、co-training、tri-training和tri-training with disagreement，在4个不同文本任务数据集上进行实验。结果显示，tri-training with disagreement的表现最接近Oracle，但仍存在性能差距，建议需要开发新算法或对现有方法进行改进。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Innovations in Intelligent Systems and Applications Conference (ASYU)",
      "pdf_url": "http://arxiv.org/pdf/2401.01843v2",
      "published_date": "2024-01-03 17:22:48 UTC",
      "updated_date": "2024-01-07 11:51:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:30:31.542254"
    },
    {
      "arxiv_id": "2401.01841v3",
      "title": "Act as You Learn: Adaptive Decision-Making in Non-Stationary Markov Decision Processes",
      "title_zh": "翻译失败",
      "authors": [
        "Baiting Luo",
        "Yunuo Zhang",
        "Abhishek Dubey",
        "Ayan Mukhopadhyay"
      ],
      "abstract": "A fundamental (and largely open) challenge in sequential decision-making is\ndealing with non-stationary environments, where exogenous environmental\nconditions change over time. Such problems are traditionally modeled as\nnon-stationary Markov decision processes (NSMDP). However, existing approaches\nfor decision-making in NSMDPs have two major shortcomings: first, they assume\nthat the updated environmental dynamics at the current time are known (although\nfuture dynamics can change); and second, planning is largely pessimistic, i.e.,\nthe agent acts ``safely'' to account for the non-stationary evolution of the\nenvironment. We argue that both these assumptions are invalid in practice --\nupdated environmental conditions are rarely known, and as the agent interacts\nwith the environment, it can learn about the updated dynamics and avoid being\npessimistic, at least in states whose dynamics it is confident about. We\npresent a heuristic search algorithm called \\textit{Adaptive Monte Carlo Tree\nSearch (ADA-MCTS)} that addresses these challenges. We show that the agent can\nlearn the updated dynamics of the environment over time and then act as it\nlearns, i.e., if the agent is in a region of the state space about which it has\nupdated knowledge, it can avoid being pessimistic. To quantify ``updated\nknowledge,'' we disintegrate the aleatoric and epistemic uncertainty in the\nagent's updated belief and show how the agent can use these estimates for\ndecision-making. We compare the proposed approach with the multiple\nstate-of-the-art approaches in decision-making across multiple well-established\nopen-source problems and empirically show that our approach is faster and\nhighly adaptive without sacrificing safety.",
      "tldr_zh": "这篇论文针对非平稳马尔可夫决策过程 (NSMDP) 中的顺序决策挑战，提出了一种自适应方法，以解决现有方法对环境动态的假设和过度悲观规划问题。作者开发了 Adaptive Monte Carlo Tree Search (ADA-MCTS) 算法，该算法允许代理在互动中学习更新后的环境动态，并通过区分 aleatoric 和 epistemic 不确定性来量化知识，从而在有信心的状态下进行更灵活的决策。与现有方法比较，实验结果显示 ADA-MCTS 在多个开源问题上更快、更适应性，同时保持安全性。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted for publication at the International Conference on\n  Autonomous Agents and MultiAgent Systems (AAMAS), 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.01841v3",
      "published_date": "2024-01-03 17:19:54 UTC",
      "updated_date": "2024-01-22 03:43:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:30:43.647875"
    },
    {
      "arxiv_id": "2401.01836v4",
      "title": "Neural Control: Concurrent System Identification and Control Learning with Neural ODE",
      "title_zh": "翻译失败",
      "authors": [
        "Cheng Chi"
      ],
      "abstract": "Controlling continuous-time dynamical systems is generally a two step\nprocess: first, identify or model the system dynamics with differential\nequations, then, minimize the control objectives to achieve optimal control\nfunction and optimal state trajectories. However, any inaccuracy in dynamics\nmodeling will lead to sub-optimality in the resulting control function. To\naddress this, we propose a neural ODE based method for controlling unknown\ndynamical systems, denoted as Neural Control (NC), which combines dynamics\nidentification and optimal control learning using a coupled neural ODE. Through\nan intriguing interplay between the two neural networks in coupled neural ODE\nstructure, our model concurrently learns system dynamics as well as optimal\ncontrols that guides towards target states. Our experiments demonstrate the\neffectiveness of our model for learning optimal control of unknown dynamical\nsystems. Codes available at\nhttps://github.com/chichengmessi/neural_ode_control/tree/main",
      "tldr_zh": "该论文提出了一种名为 Neural Control (NC) 的方法，用于控制未知的连续时间动态系统，通过耦合的 Neural ODE 结构同时实现系统动态识别和最优控制学习。这种方法利用两个神经网络的互动，边学习系统动态边优化控制函数，以引导系统达到目标状态，从而避免传统两步过程（先建模再控制）中动态模型不准导致的次优问题。实验结果证明了 NC 在未知动态系统的最优控制学习中有效性，并提供了开源代码以供进一步验证。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "9 pages, code open sourced in format of Google Colab notebooks;\n  Resubmitted for adding missed references in the last submission",
      "pdf_url": "http://arxiv.org/pdf/2401.01836v4",
      "published_date": "2024-01-03 17:05:17 UTC",
      "updated_date": "2024-04-22 16:43:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:30:53.573081"
    },
    {
      "arxiv_id": "2401.01835v1",
      "title": "Concurrent Brainstorming & Hypothesis Satisfying: An Iterative Framework for Enhanced Retrieval-Augmented Generation (R2CBR3H-SR)",
      "title_zh": "翻译失败",
      "authors": [
        "Arash Shahmansoori"
      ],
      "abstract": "Addressing the complexity of comprehensive information retrieval, this study\nintroduces an innovative, iterative retrieval-augmented generation system. Our\napproach uniquely integrates a vector-space driven re-ranking mechanism with\nconcurrent brainstorming to expedite the retrieval of highly relevant\ndocuments, thereby streamlining the generation of potential queries. This sets\nthe stage for our novel hybrid process, which synergistically combines\nhypothesis formulation with satisfying decision-making strategy to determine\ncontent adequacy, leveraging a chain of thought-based prompting technique. This\nunified hypothesize-satisfied phase intelligently distills information to\nascertain whether user queries have been satisfactorily addressed. Upon\nreaching this criterion, the system refines its output into a concise\nrepresentation, maximizing conceptual density with minimal verbosity. The\niterative nature of the workflow enhances process efficiency and accuracy.\nCrucially, the concurrency within the brainstorming phase significantly\naccelerates recursive operations, facilitating rapid convergence to solution\nsatisfaction. Compared to conventional methods, our system demonstrates a\nmarked improvement in computational time and cost-effectiveness. This research\nadvances the state-of-the-art in intelligent retrieval systems, setting a new\nbenchmark for resource-efficient information extraction and abstraction in\nknowledge-intensive applications.",
      "tldr_zh": "本研究提出了一种名为 R2CBR3H-SR 的迭代框架，用于增强 Retrieval-Augmented Generation（RAG），通过整合向量空间驱动的重排机制和 concurrent brainstorming 来加速相关文档的检索并生成潜在查询。框架进一步结合 hypothesis formulation 与 satisfying decision-making 策略，利用 chain of thought-based prompting 技术，来评估查询是否得到满意回答，并将输出提炼为简洁、高密度表示。相比传统方法，该系统显著提高了计算效率和成本效益，在知识密集型应用中设定了新的基准。",
      "categories": [
        "cs.IT",
        "cs.AI",
        "cs.IR",
        "math.IT"
      ],
      "primary_category": "cs.IT",
      "comment": "3 pages, 1 table, double column IEEE journal format paper",
      "pdf_url": "http://arxiv.org/pdf/2401.01835v1",
      "published_date": "2024-01-03 17:01:44 UTC",
      "updated_date": "2024-01-03 17:01:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:31:10.343588"
    },
    {
      "arxiv_id": "2401.01830v1",
      "title": "Iterative Mask Filling: An Effective Text Augmentation Method Using Masked Language Modeling",
      "title_zh": "迭代掩码填充：一种使用掩码语言建模的有效文本增强方法",
      "authors": [
        "Himmet Toprak Kesgin",
        "Mehmet Fatih Amasyali"
      ],
      "abstract": "Data augmentation is an effective technique for improving the performance of\nmachine learning models. However, it has not been explored as extensively in\nnatural language processing (NLP) as it has in computer vision. In this paper,\nwe propose a novel text augmentation method that leverages the Fill-Mask\nfeature of the transformer-based BERT model. Our method involves iteratively\nmasking words in a sentence and replacing them with language model predictions.\nWe have tested our proposed method on various NLP tasks and found it to be\neffective in many cases. Our results are presented along with a comparison to\nexisting augmentation methods. Experimental results show that our proposed\nmethod significantly improves performance, especially on topic classification\ndatasets.",
      "tldr_zh": "本论文提出了一种名为 Iterative Mask Filling 的文本增强方法，利用 Masked Language Modeling 来改进 NLP 任务的模型性能。该方法通过迭代掩盖句子中的单词，并使用如 BERT 的 Fill-Mask 功能替换为语言模型预测，从而生成多样化的增强数据。实验结果显示，该方法在多种 NLP 任务上表现出色，尤其在主题分类数据集上显著提升性能，并优于现有增强方法。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Published in International Conference on Advanced Engineering,\n  Technology and Applications (ICAETA 2023). The final version is available\n  online at https://link.springer.com/chapter/10.1007/978-3-031-50920-9_35",
      "pdf_url": "http://arxiv.org/pdf/2401.01830v1",
      "published_date": "2024-01-03 16:47:13 UTC",
      "updated_date": "2024-01-03 16:47:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:31:26.228890"
    },
    {
      "arxiv_id": "2401.01814v1",
      "title": "Large Language Models Relearn Removed Concepts",
      "title_zh": "大型语言模型重新学习移除的概念",
      "authors": [
        "Michelle Lo",
        "Shay B. Cohen",
        "Fazl Barez"
      ],
      "abstract": "Advances in model editing through neuron pruning hold promise for removing\nundesirable concepts from large language models. However, it remains unclear\nwhether models have the capacity to reacquire pruned concepts after editing. To\ninvestigate this, we evaluate concept relearning in models by tracking concept\nsaliency and similarity in pruned neurons during retraining. Our findings\nreveal that models can quickly regain performance post-pruning by relocating\nadvanced concepts to earlier layers and reallocating pruned concepts to primed\nneurons with similar semantics. This demonstrates that models exhibit\npolysemantic capacities and can blend old and new concepts in individual\nneurons. While neuron pruning provides interpretability into model concepts,\nour results highlight the challenges of permanent concept removal for improved\nmodel \\textit{safety}. Monitoring concept reemergence and developing techniques\nto mitigate relearning of unsafe concepts will be important directions for more\nrobust model editing. Overall, our work strongly demonstrates the resilience\nand fluidity of concept representations in LLMs post concept removal.",
      "tldr_zh": "这篇论文探讨了大语言模型(Large Language Models)是否能通过重新训练重新学习neuron pruning移除的概念。研究通过追踪概念显著性和相似性，发现模型能在修剪后快速恢复性能，将高级概念移至早期层，并将移除的概念重新分配到语义相似的神经元中。结果显示模型具有polysemantic capacities，能在单个神经元中混合旧新概念，这突显了永久移除不安全概念的挑战，并强调了监控概念重新出现和开发缓解技术的必要性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.01814v1",
      "published_date": "2024-01-03 16:15:57 UTC",
      "updated_date": "2024-01-03 16:15:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:31:39.214022"
    },
    {
      "arxiv_id": "2401.01801v2",
      "title": "A quatum inspired neural network for geometric modeling",
      "title_zh": "量子启发的神经网络用于几何建模",
      "authors": [
        "Weitao Du",
        "Shengchao Liu",
        "Xuecang Zhang"
      ],
      "abstract": "By conceiving physical systems as 3D many-body point clouds, geometric graph\nneural networks (GNNs), such as SE(3)/E(3) equivalent GNNs, have showcased\npromising performance. In particular, their effective message-passing mechanics\nmake them adept at modeling molecules and crystalline materials. However,\ncurrent geometric GNNs only offer a mean-field approximation of the many-body\nsystem, encapsulated within two-body message passing, thus falling short in\ncapturing intricate relationships within these geometric graphs. To address\nthis limitation, tensor networks, widely employed by computational physics to\nhandle manybody systems using high-order tensors, have been introduced.\nNevertheless, integrating these tensorized networks into the message-passing\nframework of GNNs faces scalability and symmetry conservation (e.g.,\npermutation and rotation) challenges. In response, we introduce an innovative\nequivariant Matrix Product State (MPS)-based message-passing strategy, through\nachieving an efficient implementation of the tensor contraction operation. Our\nmethod effectively models complex many-body relationships, suppressing\nmean-field approximations, and captures symmetries within geometric graphs.\nImportantly, it seamlessly replaces the standard message-passing and\nlayer-aggregation modules intrinsic to geometric GNNs. We empirically validate\nthe superior accuracy of our approach on benchmark tasks, including predicting\nclassical Newton systems and quantum tensor Hamiltonian matrices. To our\nknowledge, our approach represents the inaugural utilization of parameterized\ngeometric tensor networks.",
      "tldr_zh": "本研究针对现有几何图神经网络（geometric GNNs，如SE(3)/E(3) equivalent GNNs）在建模3D多体点云系统时，仅依赖二体消息传递的均场近似问题，提出了一种创新的等变Matrix Product State (MPS)-based消息传递策略。 该方法通过高效的张量收缩操作，实现了对复杂多体关系的精确建模，同时保留了系统对称性（如置换和旋转），并能无缝替换标准GNNs的模块。 实验结果显示，该策略在预测经典Newton系统和量子张量Hamiltonian矩阵等基准任务上显著提高了准确性，并首次实现了参数化geometric tensor networks的应用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.comp-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.01801v2",
      "published_date": "2024-01-03 15:59:35 UTC",
      "updated_date": "2024-01-28 16:13:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:31:51.338724"
    },
    {
      "arxiv_id": "2401.01792v1",
      "title": "CoMoSVC: Consistency Model-based Singing Voice Conversion",
      "title_zh": "CoMoSVC：基于一致性模型的演唱语音转换",
      "authors": [
        "Yiwen Lu",
        "Zhen Ye",
        "Wei Xue",
        "Xu Tan",
        "Qifeng Liu",
        "Yike Guo"
      ],
      "abstract": "The diffusion-based Singing Voice Conversion (SVC) methods have achieved\nremarkable performances, producing natural audios with high similarity to the\ntarget timbre. However, the iterative sampling process results in slow\ninference speed, and acceleration thus becomes crucial. In this paper, we\npropose CoMoSVC, a consistency model-based SVC method, which aims to achieve\nboth high-quality generation and high-speed sampling. A diffusion-based teacher\nmodel is first specially designed for SVC, and a student model is further\ndistilled under self-consistency properties to achieve one-step sampling.\nExperiments on a single NVIDIA GTX4090 GPU reveal that although CoMoSVC has a\nsignificantly faster inference speed than the state-of-the-art (SOTA)\ndiffusion-based SVC system, it still achieves comparable or superior conversion\nperformance based on both subjective and objective metrics. Audio samples and\ncodes are available at https://comosvc.github.io/.",
      "tldr_zh": "该论文提出CoMoSVC，一种基于Consistency Model的Singing Voice Conversion (SVC) 方法，旨在解决扩散模型(diffusion-based) SVC 生成高质量音频但推理速度慢的问题。通过设计一个扩散模型教师模型，并通过自一致性属性蒸馏到一个学生模型，实现一步采样，从而显著提高推理效率。实验在NVIDIA GTX4090 GPU上显示，CoMoSVC的推理速度远超最先进(SOTA)扩散模型，同时在主观和客观指标上达到相当或更好的转换性能。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.LG",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.01792v1",
      "published_date": "2024-01-03 15:47:17 UTC",
      "updated_date": "2024-01-03 15:47:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:32:01.457295"
    },
    {
      "arxiv_id": "2401.01789v1",
      "title": "Deep learning the Hurst parameter of linear fractional processes and assessing its reliability",
      "title_zh": "翻译失败",
      "authors": [
        "Dániel Boros",
        "Bálint Csanády",
        "Iván Ivkovic",
        "Lóránt Nagy",
        "András Lukács",
        "László Márkus"
      ],
      "abstract": "This research explores the reliability of deep learning, specifically Long\nShort-Term Memory (LSTM) networks, for estimating the Hurst parameter in\nfractional stochastic processes. The study focuses on three types of processes:\nfractional Brownian motion (fBm), fractional Ornstein-Uhlenbeck (fOU) process,\nand linear fractional stable motions (lfsm). The work involves a fast\ngeneration of extensive datasets for fBm and fOU to train the LSTM network on a\nlarge volume of data in a feasible time. The study analyses the accuracy of the\nLSTM network's Hurst parameter estimation regarding various performance\nmeasures like RMSE, MAE, MRE, and quantiles of the absolute and relative\nerrors. It finds that LSTM outperforms the traditional statistical methods in\nthe case of fBm and fOU processes; however, it has limited accuracy on lfsm\nprocesses. The research also delves into the implications of training length\nand valuation sequence length on the LSTM's performance. The methodology is\napplied by estimating the Hurst parameter in Li-ion battery degradation data\nand obtaining confidence bounds for the estimation. The study concludes that\nwhile deep learning methods show promise in parameter estimation of fractional\nprocesses, their effectiveness is contingent on the process type and the\nquality of training data.",
      "tldr_zh": "这篇论文使用 Long Short-Term Memory (LSTM) 网络来估计分形随机过程的 Hurst parameter，并评估其可靠性，涉及 fractional Brownian motion (fBm)、fractional Ornstein-Uhlenbeck (fOU) 过程和 linear fractional stable motions (lfsm)。研究通过快速生成大量数据集训练 LSTM，并采用 RMSE、MAE、MRE 等指标分析其估计准确性，结果显示 LSTM 在 fBm 和 fOU 上优于传统统计方法，但在 lfsm 上表现有限。论文还探讨了训练长度和序列长度对性能的影响，并将其应用于 Li-ion 电池退化数据的参数估计，获得置信区间。总体结论是，深度学习方法在分形过程参数估计中显示出潜力，但其有效性取决于过程类型和训练数据质量。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG",
        "68T07"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.01789v1",
      "published_date": "2024-01-03 15:42:45 UTC",
      "updated_date": "2024-01-03 15:42:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:32:15.583588"
    },
    {
      "arxiv_id": "2401.01788v1",
      "title": "Applications of machine learning and IoT for Outdoor Air Pollution Monitoring and Prediction: A Systematic Literature Review",
      "title_zh": "机器学习和物联网在室外空气污染监测和预测中的应用：系统文献综述",
      "authors": [
        "Ihsane Gryech",
        "Chaimae Assad",
        "Mounir Ghogho",
        "Abdellatif Kobbane"
      ],
      "abstract": "According to the World Health Organization (WHO), air pollution kills seven\nmillion people every year. Outdoor air pollution is a major environmental\nhealth problem affecting low, middle, and high-income countries. In the past\nfew years, the research community has explored IoT-enabled machine learning\napplications for outdoor air pollution prediction. The general objective of\nthis paper is to systematically review applications of machine learning and\nInternet of Things (IoT) for outdoor air pollution prediction and the\ncombination of monitoring sensors and input features used. Two research\nquestions were formulated for this review. 1086 publications were collected in\nthe initial PRISMA stage. After the screening and eligibility phases, 37 papers\nwere selected for inclusion. A cost-based analysis was conducted on the\nfindings to highlight high-cost monitoring, low-cost IoT and hybrid enabled\nprediction. Three methods of prediction were identified: time series,\nfeature-based and spatio-temporal. This review's findings identify major\nlimitations in applications found in the literature, namely lack of coverage,\nlack of diversity of data and lack of inclusion of context-specific features.\nThis review proposes directions for future research and underlines practical\nimplications in healthcare, urban planning, global synergy and smart cities.",
      "tldr_zh": "这篇论文通过系统文献回顾（Systematic Literature Review）探讨了机器学习和 IoT 在户外空气污染监测和预测中的应用，强调这些技术在应对全球健康问题（如 WHO 报告的每年 700 万人死亡）方面的潜力。研究者制定了两个研究问题，采用 PRISMA 流程从 1086 篇出版物中筛选出 37 篇，进行成本分析，并识别了三种预测方法：时间序列、基于特征的和时空的。论文发现现有应用存在主要局限性，包括缺乏覆盖范围、数据多样性和上下文特定特征的包含，并提出未来研究方向，如在医疗、城市规划、全球协同和智能城市中的实际影响。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.01788v1",
      "published_date": "2024-01-03 15:36:33 UTC",
      "updated_date": "2024-01-03 15:36:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:32:27.957943"
    },
    {
      "arxiv_id": "2401.01772v2",
      "title": "A Novel Paradigm for Neural Computation: X-Net with Learnable Neurons and Adaptable Structure",
      "title_zh": "翻译失败",
      "authors": [
        "Yanjie Li",
        "Weijun Li",
        "Lina Yu",
        "Min Wu",
        "Jinyi Liu",
        "Wenqiang Li",
        "Meilan Hao",
        "Shu Wei",
        "Yusong Deng",
        "Liping Zhang",
        "Xiaoli Dong",
        "Hong Qin",
        "Xin Ning",
        "Yugui Zhang",
        "Baoli Lu",
        "Jian Xu",
        "Shuang Li"
      ],
      "abstract": "Multilayer perception (MLP) has permeated various disciplinary domains,\nranging from bioinformatics to financial analytics, where their application has\nbecome an indispensable facet of contemporary scientific research endeavors.\nHowever, MLP has obvious drawbacks. 1), The type of activation function is\nsingle and relatively fixed, which leads to poor `representation ability' of\nthe network, and it is often to solve simple problems with complex networks;\n2), the network structure is not adaptive, it is easy to cause network\nstructure redundant or insufficient. In this work, we propose a novel neural\nnetwork paradigm X-Net promising to replace MLPs. X-Net can dynamically learn\nactivation functions individually based on derivative information during\ntraining to improve the network's representational ability for specific tasks.\nAt the same time, X-Net can precisely adjust the network structure at the\nneuron level to accommodate tasks of varying complexity and reduce\ncomputational costs. We show that X-Net outperforms MLPs in terms of\nrepresentational capability. X-Net can achieve comparable or even better\nperformance than MLP with much smaller parameters on regression and\nclassification tasks. Specifically, in terms of the number of parameters, X-Net\nis only 3% of MLP on average and only 1.1% under some tasks. We also\ndemonstrate X-Net's ability to perform scientific discovery on data from\nvarious disciplines such as energy, environment, and aerospace, where X-Net is\nshown to help scientists discover new laws of mathematics or physics.",
      "tldr_zh": "本研究指出了多层感知器(MLP)的两大缺点：激活函数类型单一导致网络表示能力不足，以及网络结构不适应易造成冗余或不足。为此，提出了一种新型神经网络范式X-Net，该框架允许动态学习激活函数基于衍生信息，并通过神经元级别精确调整网络结构，以适应不同任务复杂度和降低计算成本。实验结果显示，X-Net在回归和分类任务上比MLP表现出色，使用参数平均仅为MLP的3%（某些任务仅1.1%），并在能源、环境和航空航天等领域辅助发现新的数学或物理定律。",
      "categories": [
        "cs.AI",
        "cs.NI"
      ],
      "primary_category": "cs.AI",
      "comment": "35 pages",
      "pdf_url": "http://arxiv.org/pdf/2401.01772v2",
      "published_date": "2024-01-03 14:52:18 UTC",
      "updated_date": "2024-07-12 09:21:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:32:38.655905"
    },
    {
      "arxiv_id": "2401.01755v1",
      "title": "Incremental FastPitch: Chunk-based High Quality Text to Speech",
      "title_zh": "翻译失败",
      "authors": [
        "Muyang Du",
        "Chuan Liu",
        "Junjie Lai"
      ],
      "abstract": "Parallel text-to-speech models have been widely applied for real-time speech\nsynthesis, and they offer more controllability and a much faster synthesis\nprocess compared with conventional auto-regressive models. Although parallel\nmodels have benefits in many aspects, they become naturally unfit for\nincremental synthesis due to their fully parallel architecture such as\ntransformer. In this work, we propose Incremental FastPitch, a novel FastPitch\nvariant capable of incrementally producing high-quality Mel chunks by improving\nthe architecture with chunk-based FFT blocks, training with receptive-field\nconstrained chunk attention masks, and inference with fixed size past model\nstates. Experimental results show that our proposal can produce speech quality\ncomparable to the parallel FastPitch, with a significant lower latency that\nallows even lower response time for real-time speech applications.",
      "tldr_zh": "本文提出 Incremental FastPitch，一种基于块的文本到语音(Text to Speech, TTS)模型，旨在解决平行模型在增量合成中的局限性。改进包括采用 chunk-based FFT blocks、训练时的 receptive-field constrained chunk attention masks 以及推理时的 fixed size past model states，从而实现逐步产生高质量 Mel chunks。实验结果表明，该模型的语音质量与原 FastPitch 相当，但延迟显著降低，适用于实时语音应用。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "5 pages, 4 figures, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2401.01755v1",
      "published_date": "2024-01-03 14:17:35 UTC",
      "updated_date": "2024-01-03 14:17:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:32:50.337744"
    },
    {
      "arxiv_id": "2401.01754v1",
      "title": "Using AI/ML to Find and Remediate Enterprise Secrets in Code & Document Sharing Platforms",
      "title_zh": "翻译失败",
      "authors": [
        "Gregor Kerr",
        "David Algorry",
        "Senad Ibraimoski",
        "Peter Maciver",
        "Sean Moran"
      ],
      "abstract": "We introduce a new challenge to the software development community: 1)\nleveraging AI to accurately detect and flag up secrets in code and on popular\ndocument sharing platforms that frequently used by developers, such as\nConfluence and 2) automatically remediating the detections (e.g. by suggesting\npassword vault functionality). This is a challenging, and mostly unaddressed\ntask. Existing methods leverage heuristics and regular expressions, that can be\nvery noisy, and therefore increase toil on developers. The next step -\nmodifying code itself - to automatically remediate a detection, is a complex\ntask. We introduce two baseline AI models that have good detection performance\nand propose an automatic mechanism for remediating secrets found in code,\nopening up the study of this task to the wider community.",
      "tldr_zh": "这篇论文针对软件开发中的机密泄露问题，提出使用AI/ML技术来准确检测代码和文档共享平台（如Confluence）中的企业机密，并自动修复这些问题，以减少开发者负担。现有方法依赖启发式和regular expressions，容易产生noisy结果，而论文引入两个baseline AI models，提升了检测性能，并设计了自动修复机制，例如建议使用密码保险库功能。总体上，这为机密检测与修复任务开辟了新研究方向，供社区进一步探索。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.01754v1",
      "published_date": "2024-01-03 14:15:25 UTC",
      "updated_date": "2024-01-03 14:15:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:33:02.147589"
    },
    {
      "arxiv_id": "2401.01753v1",
      "title": "A Generative AI Assistant to Accelerate Cloud Migration",
      "title_zh": "翻译失败",
      "authors": [
        "Amal Vaidya",
        "Mohan Krishna Vankayalapati",
        "Jacky Chan",
        "Senad Ibraimoski",
        "Sean Moran"
      ],
      "abstract": "We present a tool that leverages generative AI to accelerate the migration of\non-premises applications to the cloud. The Cloud Migration LLM accepts input\nfrom the user specifying the parameters of their migration, and outputs a\nmigration strategy with an architecture diagram. A user study suggests that the\nmigration LLM can assist inexperienced users in finding the right cloud\nmigration profile, while avoiding complexities of a manual approach.",
      "tldr_zh": "本研究提出了一种基于 Generative AI 的工具，用于加速本地应用向云端的迁移。名为 Cloud Migration LLM 的工具接受用户输入的迁移参数，并输出相应的迁移策略和 architecture diagram。通过用户研究发现，该工具能帮助经验不足的用户快速找到合适的云迁移方案，同时规避了手动方法带来的复杂性，从而提升了迁移效率。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "arXiv admin comment: This version has been removed by arXiv\n  administrators as the submitter did not have the rights to agree to the\n  license at the time of submission",
      "pdf_url": "http://arxiv.org/pdf/2401.01753v1",
      "published_date": "2024-01-03 14:13:24 UTC",
      "updated_date": "2024-01-03 14:13:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:33:12.360786"
    },
    {
      "arxiv_id": "2401.01732v1",
      "title": "Task and Explanation Network",
      "title_zh": "任务与解释网络",
      "authors": [
        "Moshe Sipper"
      ],
      "abstract": "Explainability in deep networks has gained increased importance in recent\nyears. We argue herein that an AI must be tasked not just with a task but also\nwith an explanation of why said task was accomplished as such. We present a\nbasic framework -- Task and Explanation Network (TENet) -- which fully\nintegrates task completion and its explanation. We believe that the field of AI\nas a whole should insist -- quite emphatically -- on explainability.",
      "tldr_zh": "该论文强调AI系统应不仅完成任务，还需提供任务完成原因的解释，以提升可解释性。作者提出Task and Explanation Network (TENet)框架，该框架将任务执行和其解释完全整合，实现AI决策的透明化。通过TENet，论文主张AI领域应强烈推动可解释性，以构建更可靠的系统。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.01732v1",
      "published_date": "2024-01-03 13:11:59 UTC",
      "updated_date": "2024-01-03 13:11:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:33:25.165663"
    },
    {
      "arxiv_id": "2401.01728v2",
      "title": "Ravnest: Decentralized Asynchronous Training on Heterogeneous Devices",
      "title_zh": "翻译失败",
      "authors": [
        "Anirudh Rajiv Menon",
        "Unnikrishnan Menon",
        "Kailash Ahirwar"
      ],
      "abstract": "Modern deep learning models, growing larger and more complex, have\ndemonstrated exceptional generalization and accuracy due to training on huge\ndatasets. This trend is expected to continue. However, the increasing size of\nthese models poses challenges in training, as traditional centralized methods\nare limited by memory constraints at such scales. This paper proposes an\nasynchronous decentralized training paradigm for large modern deep learning\nmodels that harnesses the compute power of regular heterogeneous PCs with\nlimited resources connected across the internet to achieve favourable\nperformance metrics. Ravnest facilitates decentralized training by efficiently\norganizing compute nodes into clusters with similar data transfer rates and\ncompute capabilities, without necessitating that each node hosts the entire\nmodel. These clusters engage in $\\textit{Zero-Bubble Asynchronous Model\nParallel}$ training, and a $\\textit{Parallel Multi-Ring All-Reduce}$ method is\nemployed to effectively execute global parameter averaging across all clusters.\nWe have framed our asynchronous SGD loss function as a block structured\noptimization problem with delayed updates and derived an optimal convergence\nrate of $O\\left(\\frac{1}{\\sqrt{K}}\\right)$. We further discuss linear speedup\nwith respect to the number of participating clusters and the bound on the\nstaleness parameter.",
      "tldr_zh": "本文提出 Ravnest 框架，一种异步去中心化训练范式，旨在解决现代深度学习模型规模增大导致的内存限制问题，通过利用互联网连接的异构设备（如普通 PC）实现高效训练。Ravnest 将计算节点组织成类似数据传输率和计算能力的集群，进行 Zero-Bubble Asynchronous Model Parallel 训练，并采用 Parallel Multi-Ring All-Reduce 方法实现全局参数平均，同时避免每个节点托管整个模型。该框架将异步 SGD 损失函数视为块结构优化问题，推导出收敛率 O(1/√K)，并证明了与集群数量相关的线性加速和延迟参数边界，从而提升了训练的可扩展性和性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "29 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2401.01728v2",
      "published_date": "2024-01-03 13:07:07 UTC",
      "updated_date": "2024-05-23 08:01:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:33:41.438895"
    },
    {
      "arxiv_id": "2401.10264v1",
      "title": "Harnessing Transparent Learning Analytics for Individualized Support through Auto-detection of Engagement in Face-to-Face Collaborative Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Qi Zhou",
        "Wannapon Suraworachet",
        "Mutlu Cukurova"
      ],
      "abstract": "Using learning analytics to investigate and support collaborative learning\nhas been explored for many years. Recently, automated approaches with various\nartificial intelligence approaches have provided promising results for\nmodelling and predicting student engagement and performance in collaborative\nlearning tasks. However, due to the lack of transparency and interpretability\ncaused by the use of \"black box\" approaches in learning analytics design and\nimplementation, guidance for teaching and learning practice may become a\nchallenge. On the one hand, the black box created by machine learning\nalgorithms and models prevents users from obtaining educationally meaningful\nlearning and teaching suggestions. On the other hand, focusing on group and\ncohort level analysis only can make it difficult to provide specific support\nfor individual students working in collaborative groups. This paper proposes a\ntransparent approach to automatically detect student's individual engagement in\nthe process of collaboration. The results show that the proposed approach can\nreflect student's individual engagement and can be used as an indicator to\ndistinguish students with different collaborative learning challenges\n(cognitive, behavioural and emotional) and learning outcomes. The potential of\nthe proposed collaboration analytics approach for scaffolding collaborative\nlearning practice in face-to-face contexts is discussed and future research\nsuggestions are provided.",
      "tldr_zh": "该研究探讨了使用透明的学习 analytics 来支持面对面协作学习中的个体参与度自动检测问题，以解决传统“黑箱”AI 方法缺乏可解释性和个性化指导的挑战。论文提出了一种透明方法，通过分析学生的个体参与度行为，来区分认知、行为和情感方面的协作学习挑战。实验结果显示，该方法能准确反映学生的参与水平，并作为指标预测不同学习成果。该方法为教学实践提供个性化支持，具有潜力应用于真实情境，并为未来研究提出建议。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "12 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2401.10264v1",
      "published_date": "2024-01-03 12:20:28 UTC",
      "updated_date": "2024-01-03 12:20:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:33:52.014202"
    },
    {
      "arxiv_id": "2401.01656v2",
      "title": "Deep Automated Mechanism Design for Integrating Ad Auction and Allocation in Feed",
      "title_zh": "翻译失败",
      "authors": [
        "Xuejian Li",
        "Ze Wang",
        "Bingqi Zhu",
        "Fei He",
        "Yongkang Wang",
        "Xingxing Wang"
      ],
      "abstract": "E-commerce platforms usually present an ordered list, mixed with several\norganic items and an advertisement, in response to each user's page view\nrequest. This list, the outcome of ad auction and allocation processes,\ndirectly impacts the platform's ad revenue and gross merchandise volume (GMV).\nSpecifically, the ad auction determines which ad is displayed and the\ncorresponding payment, while the ad allocation decides the display positions of\nthe advertisement and organic items. The prevalent methods of segregating the\nad auction and allocation into two distinct stages face two problems: 1) Ad\nauction does not consider externalities, such as the influence of actual\ndisplay position and context on ad Click-Through Rate (CTR); 2) The ad\nallocation, which utilizes the auction-winning ad's payment to determine the\ndisplay position dynamically, fails to maintain incentive compatibility (IC)\nfor the advertisement. For instance, in the auction stage employing the\ntraditional Generalized Second Price (GSP) , even if the winning ad increases\nits bid, its payment remains unchanged. This implies that the advertisement\ncannot secure a better position and thus loses the opportunity to achieve\nhigher utility in the subsequent ad allocation stage. Previous research often\nfocused on one of the two stages, neglecting the two-stage problem, which may\nresult in suboptimal outcomes...",
      "tldr_zh": "该研究针对电子商务平台在Feed中整合广告拍卖和分配的问题，提出了一种Deep Automated Mechanism Design方法，以解决传统方法将拍卖和分配分阶段处理导致的局限性，例如广告拍卖忽略外部因素（如显示位置对CTR的影响）和分配无法维持激励兼容性（IC）。具体而言，该方法整合了拍卖和分配过程，确保考虑实际显示位置和上下文，同时维持IC，避免了如GSP拍卖中出价增加却无法获益的情况。实验结果表明，这种整合机制可优化平台的广告收入和GMV，实现比分离方法更优的整体性能。",
      "categories": [
        "cs.GT",
        "cs.AI"
      ],
      "primary_category": "cs.GT",
      "comment": "9 pages, 2 figures, Posting",
      "pdf_url": "http://arxiv.org/pdf/2401.01656v2",
      "published_date": "2024-01-03 10:27:39 UTC",
      "updated_date": "2024-04-11 08:51:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:34:05.304856"
    },
    {
      "arxiv_id": "2401.01651v3",
      "title": "AIGCBench: Comprehensive Evaluation of Image-to-Video Content Generated by AI",
      "title_zh": "AIGCBench：AI生成图像到视频内容的全面评估",
      "authors": [
        "Fanda Fan",
        "Chunjie Luo",
        "Wanling Gao",
        "Jianfeng Zhan"
      ],
      "abstract": "The burgeoning field of Artificial Intelligence Generated Content (AIGC) is\nwitnessing rapid advancements, particularly in video generation. This paper\nintroduces AIGCBench, a pioneering comprehensive and scalable benchmark\ndesigned to evaluate a variety of video generation tasks, with a primary focus\non Image-to-Video (I2V) generation. AIGCBench tackles the limitations of\nexisting benchmarks, which suffer from a lack of diverse datasets, by including\na varied and open-domain image-text dataset that evaluates different\nstate-of-the-art algorithms under equivalent conditions. We employ a novel text\ncombiner and GPT-4 to create rich text prompts, which are then used to generate\nimages via advanced Text-to-Image models. To establish a unified evaluation\nframework for video generation tasks, our benchmark includes 11 metrics\nspanning four dimensions to assess algorithm performance. These dimensions are\ncontrol-video alignment, motion effects, temporal consistency, and video\nquality. These metrics are both reference video-dependent and video-free,\nensuring a comprehensive evaluation strategy. The evaluation standard proposed\ncorrelates well with human judgment, providing insights into the strengths and\nweaknesses of current I2V algorithms. The findings from our extensive\nexperiments aim to stimulate further research and development in the I2V field.\nAIGCBench represents a significant step toward creating standardized benchmarks\nfor the broader AIGC landscape, proposing an adaptable and equitable framework\nfor future assessments of video generation tasks. We have open-sourced the\ndataset and evaluation code on the project website:\nhttps://www.benchcouncil.org/AIGCBench.",
      "tldr_zh": "本研究引入了AIGCBench，这是一个全面且可扩展的基准，用于评估AI生成内容(AIGC)中的Image-to-Video (I2V)生成任务，旨在解决现有基准缺乏多样数据集的问题。AIGCBench采用开放域图像-文本数据集、文本组合器和GPT-4生成丰富的文本提示，并通过Text-to-Image模型创建图像，然后使用11个指标（覆盖控制-视频对齐、运动效果、时间一致性和视频质量等四个维度）进行统一评估，这些指标包括依赖参考视频和不依赖视频的类型。实验结果显示，该基准与人类判断高度相关，揭示了当前I2V算法的优缺点，并推动了该领域的进一步研究；数据集和评估代码已开源以促进未来发展。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to BenchCouncil Transactions on Benchmarks, Standards and\n  Evaluations (TBench)",
      "pdf_url": "http://arxiv.org/pdf/2401.01651v3",
      "published_date": "2024-01-03 10:08:40 UTC",
      "updated_date": "2024-01-23 15:31:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:34:17.449872"
    },
    {
      "arxiv_id": "2401.10904v1",
      "title": "A Review of Findings from Neuroscience and Cognitive Psychology as Possible Inspiration for the Path to Artificial General Intelligence",
      "title_zh": "神经科学和认知心理学发现的综述：作为通往人工通用智能之路的可能灵感",
      "authors": [
        "Florin Leon"
      ],
      "abstract": "This review aims to contribute to the quest for artificial general\nintelligence by examining neuroscience and cognitive psychology methods for\npotential inspiration. Despite the impressive advancements achieved by deep\nlearning models in various domains, they still have shortcomings in abstract\nreasoning and causal understanding. Such capabilities should be ultimately\nintegrated into artificial intelligence systems in order to surpass data-driven\nlimitations and support decision making in a way more similar to human\nintelligence. This work is a vertical review that attempts a wide-ranging\nexploration of brain function, spanning from lower-level biological neurons,\nspiking neural networks, and neuronal ensembles to higher-level concepts such\nas brain anatomy, vector symbolic architectures, cognitive and categorization\nmodels, and cognitive architectures. The hope is that these concepts may offer\ninsights for solutions in artificial general intelligence.",
      "tldr_zh": "这篇综述探讨了神经科学和认知心理学的发现，作为推动人工智能通用智能（AGI）发展的潜在灵感来源，尽管深度学习模型在抽象推理和因果理解方面存在不足。论文强调，需要将这些人类智能能力整合到AI系统中，以超越数据驱动的限制，并更接近人类决策方式。该综述从低级别的生物神经元、脉冲神经网络（spiking neural networks）和神经元集合，扩展到高级概念如脑解剖（brain anatomy）、向量符号架构（vector symbolic architectures）、认知和分类模型，以及认知架构，进行广泛探索。这些概念有望为AGI提供关键见解和解决方案。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "143 pages, 49 figures, 244 references",
      "pdf_url": "http://arxiv.org/pdf/2401.10904v1",
      "published_date": "2024-01-03 09:46:36 UTC",
      "updated_date": "2024-01-03 09:46:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:34:27.103761"
    },
    {
      "arxiv_id": "2401.01630v1",
      "title": "A Cybersecurity Risk Analysis Framework for Systems with Artificial Intelligence Components",
      "title_zh": "一种用于具有人工智能组件的系统的网络安全风险分析框架",
      "authors": [
        "Jose Manuel Camacho",
        "Aitor Couce-Vieira",
        "David Arroyo",
        "David Rios Insua"
      ],
      "abstract": "The introduction of the European Union Artificial Intelligence Act, the NIST\nArtificial Intelligence Risk Management Framework, and related norms demands a\nbetter understanding and implementation of novel risk analysis approaches to\nevaluate systems with Artificial Intelligence components. This paper provides a\ncybersecurity risk analysis framework that can help assessing such systems. We\nuse an illustrative example concerning automated driving systems.",
      "tldr_zh": "这篇论文针对欧盟人工智能法案(European Union Artificial Intelligence Act)和NIST人工智能风险管理框架(NIST Artificial Intelligence Risk Management Framework)等规范，提出一个网络安全风险分析框架，用于评估包含人工智能组件的系统。框架旨在帮助更好地理解和实施风险分析方法，以应对AI系统潜在的安全挑战。作者使用自动驾驶系统作为示例，展示了框架的实际应用潜力。",
      "categories": [
        "cs.AI",
        "cs.CR",
        "stat.AP"
      ],
      "primary_category": "cs.AI",
      "comment": "54 pages, 18 tables, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2401.01630v1",
      "published_date": "2024-01-03 09:06:39 UTC",
      "updated_date": "2024-01-03 09:06:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:34:39.446883"
    },
    {
      "arxiv_id": "2401.01629v1",
      "title": "Synthetic Data in AI: Challenges, Applications, and Ethical Implications",
      "title_zh": "人工智能中的合成数据：挑战、应用和伦理含义",
      "authors": [
        "Shuang Hao",
        "Wenfeng Han",
        "Tao Jiang",
        "Yiping Li",
        "Haonan Wu",
        "Chunlin Zhong",
        "Zhangjun Zhou",
        "He Tang"
      ],
      "abstract": "In the rapidly evolving field of artificial intelligence, the creation and\nutilization of synthetic datasets have become increasingly significant. This\nreport delves into the multifaceted aspects of synthetic data, particularly\nemphasizing the challenges and potential biases these datasets may harbor. It\nexplores the methodologies behind synthetic data generation, spanning\ntraditional statistical models to advanced deep learning techniques, and\nexamines their applications across diverse domains. The report also critically\naddresses the ethical considerations and legal implications associated with\nsynthetic datasets, highlighting the urgent need for mechanisms to ensure\nfairness, mitigate biases, and uphold ethical standards in AI development.",
      "tldr_zh": "这篇报告探讨了人工智能(AI)中合成数据(synthetic data)的关键问题，包括生成过程中的挑战、潜在偏见及其在不同领域的应用，如从传统统计模型到深度学习技术的多种方法。报告强调了合成数据在AI发展中的重要性，同时分析了其可能带来的伦理和法律风险，例如公平性缺失和偏见问题。最终，它呼吁建立机制来缓解这些问题，确保AI的伦理标准和可信度。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.01629v1",
      "published_date": "2024-01-03 09:03:30 UTC",
      "updated_date": "2024-01-03 09:03:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:34:50.521304"
    },
    {
      "arxiv_id": "2401.01626v2",
      "title": "On the Expressive Power of Graph Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Ashwin Nalwade",
        "Kelly Marshall",
        "Axel Eladi",
        "Umang Sharma"
      ],
      "abstract": "The study of Graph Neural Networks has received considerable interest in the\npast few years. By extending deep learning to graph-structured data, GNNs can\nsolve a diverse set of tasks in fields including social science, chemistry, and\nmedicine. The development of GNN architectures has largely been focused on\nimproving empirical performance on tasks like node or graph classification.\nHowever, a line of recent work has instead sought to find GNN architectures\nthat have desirable theoretical properties - by studying their expressive power\nand designing architectures that maximize this expressiveness.\n  While there is no consensus on the best way to define the expressiveness of a\nGNN, it can be viewed from several well-motivated perspectives. Perhaps the\nmost natural approach is to study the universal approximation properties of\nGNNs, much in the way that this has been studied extensively for MLPs. Another\ndirection focuses on the extent to which GNNs can distinguish between different\ngraph structures, relating this to the graph isomorphism test. Besides, a GNN's\nability to compute graph properties such as graph moments has been suggested as\nanother form of expressiveness. All of these different definitions are\ncomplementary and have yielded different recommendations for GNN architecture\nchoices. In this paper, we would like to give an overview of the notion of\n\"expressive power\" of GNNs and provide some valuable insights regarding the\ndesign choices of GNNs.",
      "tldr_zh": "这篇论文探讨了图神经网络 (GNNs) 的表现力 (expressive power)，回顾了其在社会科学、化学和医学等领域处理图结构数据任务的发展历程。论文从多个角度定义 GNNs 的表现力，包括通用逼近性质 (universal approximation properties)、区分不同图结构的能力 (related to graph isomorphism test)，以及计算图属性的潜力，如图矩 (graph moments)。最终，它总结了这些定义的互补性，并为 GNN 架构设计提供有价值的见解，以最大化其理论性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "We felt that significantly more work was needed to improve the\n  quality before it should be put out in its current state. No replacement is\n  available at the moment or in the near future",
      "pdf_url": "http://arxiv.org/pdf/2401.01626v2",
      "published_date": "2024-01-03 08:54:56 UTC",
      "updated_date": "2024-03-08 19:57:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:35:04.482218"
    },
    {
      "arxiv_id": "2401.01623v4",
      "title": "Can AI Be as Creative as Humans?",
      "title_zh": "人工智能是否能像人类一样富有创造力？",
      "authors": [
        "Haonan Wang",
        "James Zou",
        "Michael Mozer",
        "Anirudh Goyal",
        "Alex Lamb",
        "Linjun Zhang",
        "Weijie J Su",
        "Zhun Deng",
        "Michael Qizhe Xie",
        "Hannah Brown",
        "Kenji Kawaguchi"
      ],
      "abstract": "Creativity serves as a cornerstone for societal progress and innovation. With\nthe rise of advanced generative AI models capable of tasks once reserved for\nhuman creativity, the study of AI's creative potential becomes imperative for\nits responsible development and application. In this paper, we prove in theory\nthat AI can be as creative as humans under the condition that it can properly\nfit the data generated by human creators. Therefore, the debate on AI's\ncreativity is reduced into the question of its ability to fit a sufficient\namount of data. To arrive at this conclusion, this paper first addresses the\ncomplexities in defining creativity by introducing a new concept called\nRelative Creativity. Rather than attempting to define creativity universally,\nwe shift the focus to whether AI can match the creative abilities of a\nhypothetical human. The methodological shift leads to a statistically\nquantifiable assessment of AI's creativity, term Statistical Creativity. This\nconcept, statistically comparing the creative abilities of AI with those of\nspecific human groups, facilitates theoretical exploration of AI's creative\npotential. Our analysis reveals that by fitting extensive conditional data\nwithout marginalizing out the generative conditions, AI can emerge as a\nhypothetical new creator. The creator possesses the same creative abilities on\npar with the human creators it was trained on. Building on theoretical\nfindings, we discuss the application in prompt-conditioned autoregressive\nmodels, providing a practical means for evaluating creative abilities of\ngenerative AI models, such as Large Language Models (LLMs). Additionally, this\nstudy provides an actionable training guideline, bridging the theoretical\nquantification of creativity with practical model training.",
      "tldr_zh": "本论文探讨了 AI 是否能与人类一样富有创造力，通过理论证明指出，AI 在正确拟合人类生成数据的前提下，可以达到与人类相当的创造力水平，从而将这一辩论简化为 AI 的数据拟合能力。论文引入 Relative Creativity 和 Statistical Creativity 概念，通过统计方法比较 AI 与特定人类群体的创造力，避免了普遍定义创造力的复杂性。研究进一步分析了 AI 通过拟合大量条件数据来模拟人类创造者，并为提示条件自回归模型如 Large Language Models (LLMs) 提供了实际评估和训练指南。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "The paper examines AI's creativity, introducing Relative and\n  Statistical Creativity for theoretical and practical analysis, along with\n  practical training guidelines. Project Page: ai-relative-creativity.github.io",
      "pdf_url": "http://arxiv.org/pdf/2401.01623v4",
      "published_date": "2024-01-03 08:49:12 UTC",
      "updated_date": "2024-01-25 13:10:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:35:15.164333"
    },
    {
      "arxiv_id": "2401.01620v1",
      "title": "Large Language Model Capabilities in Perioperative Risk Prediction and Prognostication",
      "title_zh": "大语言模型在围手术期风险预测和预后评估中的能力",
      "authors": [
        "Philip Chung",
        "Christine T Fong",
        "Andrew M Walters",
        "Nima Aghaeepour",
        "Meliha Yetisgen",
        "Vikas N O'Reilly-Shah"
      ],
      "abstract": "We investigate whether general-domain large language models such as GPT-4\nTurbo can perform risk stratification and predict post-operative outcome\nmeasures using a description of the procedure and a patient's clinical notes\nderived from the electronic health record. We examine predictive performance on\n8 different tasks: prediction of ASA Physical Status Classification, hospital\nadmission, ICU admission, unplanned admission, hospital mortality, PACU Phase 1\nduration, hospital duration, and ICU duration. Few-shot and chain-of-thought\nprompting improves predictive performance for several of the tasks. We achieve\nF1 scores of 0.50 for ASA Physical Status Classification, 0.81 for ICU\nadmission, and 0.86 for hospital mortality. Performance on duration prediction\ntasks were universally poor across all prompt strategies. Current generation\nlarge language models can assist clinicians in perioperative risk\nstratification on classification tasks and produce high-quality natural\nlanguage summaries and explanations.",
      "tldr_zh": "本文研究了通用大语言模型（如 GPT-4 Turbo）在围手术期风险预测中的能力，使用手术描述和患者临床笔记进行8个任务的预测，包括ASA Physical Status Classification、ICU入院、医院死亡率等。 通过少样本和链式思维提示，模型在分类任务上取得了显著性能，F1分数分别为ASA Physical Status Classification 0.50、ICU入院 0.81和医院死亡率 0.86，但在持续时间预测任务上表现普遍较差。 总体而言，该研究证明了LLM可辅助临床医生进行风险分层，并生成高质量的自然语言摘要和解释。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.01620v1",
      "published_date": "2024-01-03 08:41:27 UTC",
      "updated_date": "2024-01-03 08:41:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:35:33.238229"
    },
    {
      "arxiv_id": "2401.01614v2",
      "title": "GPT-4V(ision) is a Generalist Web Agent, if Grounded",
      "title_zh": "翻译失败",
      "authors": [
        "Boyuan Zheng",
        "Boyu Gou",
        "Jihyung Kil",
        "Huan Sun",
        "Yu Su"
      ],
      "abstract": "The recent development on large multimodal models (LMMs), especially\nGPT-4V(ision) and Gemini, has been quickly expanding the capability boundaries\nof multimodal models beyond traditional tasks like image captioning and visual\nquestion answering. In this work, we explore the potential of LMMs like GPT-4V\nas a generalist web agent that can follow natural language instructions to\ncomplete tasks on any given website. We propose SEEACT, a generalist web agent\nthat harnesses the power of LMMs for integrated visual understanding and acting\non the web. We evaluate on the recent MIND2WEB benchmark. In addition to\nstandard offline evaluation on cached websites, we enable a new online\nevaluation setting by developing a tool that allows running web agents on live\nwebsites. We show that GPT-4V presents a great potential for web agents -- it\ncan successfully complete 51.1 of the tasks on live websites if we manually\nground its textual plans into actions on the websites. This substantially\noutperforms text-only LLMs like GPT-4 or smaller models (FLAN-T5 and BLIP-2)\nspecifically fine-tuned for web agents. However, grounding still remains a\nmajor challenge. Existing LMM grounding strategies like set-of-mark prompting\nturns out to be not effective for web agents, and the best grounding strategy\nwe develop in this paper leverages both the HTML structure and visuals. Yet,\nthere is still a substantial gap with oracle grounding, leaving ample room for\nfurther improvement. All code, data, and evaluation tools are available at\nhttps://github.com/OSU-NLP-Group/SeeAct.",
      "tldr_zh": "本研究探讨了大型多模态模型 (LMMs) 如 GPT-4V 在网页代理方面的潜力，提出 SEEACT 框架，利用 GPT-4V 进行视觉理解和网页操作，以执行自然语言指令。研究在 MIND2WEB 基准上进行离线和在线评估，结果显示，GPT-4V 在手动 grounding 的情况下，能成功完成 51.1% 的实时网站任务，显著优于文本-only LLMs（如 GPT-4）和微调模型（如 FLAN-T5 和 BLIP-2）。然而，grounding 仍是主要挑战，现有的策略（如 set-of-mark prompting）效果有限，作者开发了基于 HTML 结构和视觉的改进策略，但与理想 grounding 仍有差距，为未来优化提供了空间。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.01614v2",
      "published_date": "2024-01-03 08:33:09 UTC",
      "updated_date": "2024-03-12 23:14:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:35:44.267839"
    },
    {
      "arxiv_id": "2401.01600v1",
      "title": "PLLaMa: An Open-source Large Language Model for Plant Science",
      "title_zh": "翻译失败",
      "authors": [
        "Xianjun Yang",
        "Junfeng Gao",
        "Wenxin Xue",
        "Erik Alexandersson"
      ],
      "abstract": "Large Language Models (LLMs) have exhibited remarkable capabilities in\nunderstanding and interacting with natural language across various sectors.\nHowever, their effectiveness is limited in specialized areas requiring high\naccuracy, such as plant science, due to a lack of specific expertise in these\nfields. This paper introduces PLLaMa, an open-source language model that\nevolved from LLaMa-2. It's enhanced with a comprehensive database, comprising\nmore than 1.5 million scholarly articles in plant science. This development\nsignificantly enriches PLLaMa with extensive knowledge and proficiency in plant\nand agricultural sciences. Our initial tests, involving specific datasets\nrelated to plants and agriculture, show that PLLaMa substantially improves its\nunderstanding of plant science-related topics. Moreover, we have formed an\ninternational panel of professionals, including plant scientists, agricultural\nengineers, and plant breeders. This team plays a crucial role in verifying the\naccuracy of PLLaMa's responses to various academic inquiries, ensuring its\neffective and reliable application in the field. To support further research\nand development, we have made the model's checkpoints and source codes\naccessible to the scientific community. These resources are available for\ndownload at \\url{https://github.com/Xianjun-Yang/PLLaMa}.",
      "tldr_zh": "本研究引入 PLLaMa，这是一个基于 LLaMa-2 演变而来的开源 Large Language Models (LLMs)，专门针对植物科学领域。PLLaMa 通过整合超过 150 万篇学术文章的数据库，显著提升了模型在植物和农业科学方面的知识和理解能力。初步测试显示，PLLaMa 在相关数据集上表现出色，并由一个国际专业面板（包括植物科学家、农业工程师和植物育种专家）验证了其响应的准确性和可靠性。为促进进一步研究，该模型的检查点和源代码已开源，可在 GitHub 下载。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CE",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Work in progress",
      "pdf_url": "http://arxiv.org/pdf/2401.01600v1",
      "published_date": "2024-01-03 08:06:26 UTC",
      "updated_date": "2024-01-03 08:06:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:35:54.444260"
    },
    {
      "arxiv_id": "2401.01596v1",
      "title": "MedSumm: A Multimodal Approach to Summarizing Code-Mixed Hindi-English Clinical Queries",
      "title_zh": "翻译失败",
      "authors": [
        "Akash Ghosh",
        "Arkadeep Acharya",
        "Prince Jha",
        "Aniket Gaudgaul",
        "Rajdeep Majumdar",
        "Sriparna Saha",
        "Aman Chadha",
        "Raghav Jain",
        "Setu Sinha",
        "Shivani Agarwal"
      ],
      "abstract": "In the healthcare domain, summarizing medical questions posed by patients is\ncritical for improving doctor-patient interactions and medical decision-making.\nAlthough medical data has grown in complexity and quantity, the current body of\nresearch in this domain has primarily concentrated on text-based methods,\noverlooking the integration of visual cues. Also prior works in the area of\nmedical question summarisation have been limited to the English language. This\nwork introduces the task of multimodal medical question summarization for\ncodemixed input in a low-resource setting. To address this gap, we introduce\nthe Multimodal Medical Codemixed Question Summarization MMCQS dataset, which\ncombines Hindi-English codemixed medical queries with visual aids. This\nintegration enriches the representation of a patient's medical condition,\nproviding a more comprehensive perspective. We also propose a framework named\nMedSumm that leverages the power of LLMs and VLMs for this task. By utilizing\nour MMCQS dataset, we demonstrate the value of integrating visual information\nfrom images to improve the creation of medically detailed summaries. This\nmultimodal strategy not only improves healthcare decision-making but also\npromotes a deeper comprehension of patient queries, paving the way for future\nexploration in personalized and responsive medical care. Our dataset, code, and\npre-trained models will be made publicly available.",
      "tldr_zh": "该研究针对混合印地语-英语（Code-Mixed）临床查询的总结问题，引入了多模态（Multimodal）方法，以整合文本和视觉线索，填补现有文本主导研究的空白。论文提出了MedSumm框架，利用LLMs（大型语言模型）和VLMs（视觉语言模型）来处理低资源环境下的医疗问题总结，并发布了MMCQS数据集，该数据集结合了混合语言查询和视觉辅助，以提供更全面的患者条件表示。实验结果显示，这种多模态策略显著提升了总结的医疗细节和准确性，从而改善医疗决策和患者查询理解，并为个性化医疗开辟新路径。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "ECIR 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.01596v1",
      "published_date": "2024-01-03 07:58:25 UTC",
      "updated_date": "2024-01-03 07:58:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:36:06.413608"
    },
    {
      "arxiv_id": "2402.03319v1",
      "title": "Physical Reservoir Computing Enabled by Solitary Waves and Biologically-Inspired Nonlinear Transformation of Input Data",
      "title_zh": "翻译失败",
      "authors": [
        "Ivan S. Maksymov"
      ],
      "abstract": "Reservoir computing (RC) systems can efficiently forecast chaotic time series\nusing nonlinear dynamical properties of an artificial neural network of random\nconnections. The versatility of RC systems has motivated further research on\nboth hardware counterparts of traditional RC algorithms and more efficient\nRC-like schemes. Inspired by the nonlinear processes in a living biological\nbrain and using solitary waves excited on the surface of a flowing liquid film,\nin this paper we experimentally validate a physical RC system that substitutes\nthe effect of randomness for a nonlinear transformation of input data. Carrying\nout all operations using a microcontroller with a minimal computational power,\nwe demonstrate that the so-designed RC system serves as a technically simple\nhardware counterpart to the `next-generation' improvement of the traditional RC\nalgorithm.",
      "tldr_zh": "本研究提出了一种物理 Reservoir Computing (RC) 系统，利用流动液体薄膜表面的孤立波(solitary waves)和生物大脑启发的非线性数据变换，取代传统RC算法中的随机连接，从而实现高效的混沌时间序列预测。该系统通过微控制器进行简单操作，实验验证其作为“下一代”RC改进方案的硬件对应物，显著简化了设计过程。结果表明，该方法在保持RC核心功能的同时，提升了系统的实用性和效率。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "nlin.CD",
        "nlin.PS",
        "physics.flu-dyn"
      ],
      "primary_category": "cs.NE",
      "comment": "The Supplementary Video can be found here:\n  https://youtu.be/Zwu3KEo8f00",
      "pdf_url": "http://arxiv.org/pdf/2402.03319v1",
      "published_date": "2024-01-03 06:22:36 UTC",
      "updated_date": "2024-01-03 06:22:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:36:19.822877"
    },
    {
      "arxiv_id": "2401.01542v1",
      "title": "Adversarial Machine Learning-Enabled Anonymization of OpenWiFi Data",
      "title_zh": "翻译失败",
      "authors": [
        "Samhita Kuili",
        "Kareem Dabbour",
        "Irtiza Hasan",
        "Andrea Herscovich",
        "Burak Kantarci",
        "Marcel Chenier",
        "Melike Erol-Kantarci"
      ],
      "abstract": "Data privacy and protection through anonymization is a critical issue for\nnetwork operators or data owners before it is forwarded for other possible use\nof data. With the adoption of Artificial Intelligence (AI), data anonymization\naugments the likelihood of covering up necessary sensitive information;\npreventing data leakage and information loss. OpenWiFi networks are vulnerable\nto any adversary who is trying to gain access or knowledge on traffic\nregardless of the knowledge possessed by data owners. The odds for discovery of\nactual traffic information is addressed by applied conditional tabular\ngenerative adversarial network (CTGAN). CTGAN yields synthetic data; which\ndisguises as actual data but fostering hidden acute information of actual data.\nIn this paper, the similarity assessment of synthetic with actual data is\nshowcased in terms of clustering algorithms followed by a comparison of\nperformance for unsupervised cluster validation metrics. A well-known\nalgorithm, K-means outperforms other algorithms in terms of similarity\nassessment of synthetic data over real data while achieving nearest scores\n0.634, 23714.57, and 0.598 as Silhouette, Calinski and Harabasz and Davies\nBouldin metric respectively. On exploiting a comparative analysis in validation\nscores among several algorithms, K-means forms the epitome of unsupervised\nclustering algorithms ensuring explicit usage of synthetic data at the same\ntime a replacement for real data. Hence, the experimental results aim to show\nthe viability of using CTGAN-generated synthetic data in lieu of publishing\nanonymized data to be utilized in various applications.",
      "tldr_zh": "本研究探讨了利用对抗机器学习(Adversarial Machine Learning)对OpenWiFi数据进行匿名化，以保护敏感信息并防止数据泄露。论文采用Conditional Tabular Generative Adversarial Network (CTGAN)生成合成数据，并通过聚类算法评估其与真实数据的相似性。实验结果显示，K-means算法在相似性评估中表现最佳，Silhouette分数为0.634、Calinski and Harabasz为23714.57以及Davies Bouldin为0.598，从而证明CTGAN生成的合成数据可作为真实数据的有效替代，用于各种应用中。",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "8 pages, 4 Figures, \"Wireless World Research and Trends\" Magazine.\n  Initial version was presented in 47th Wireless World Research Forum",
      "pdf_url": "http://arxiv.org/pdf/2401.01542v1",
      "published_date": "2024-01-03 04:59:03 UTC",
      "updated_date": "2024-01-03 04:59:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:36:32.021751"
    },
    {
      "arxiv_id": "2401.01537v4",
      "title": "The Art of Deception: Robust Backdoor Attack using Dynamic Stacking of Triggers",
      "title_zh": "翻译失败",
      "authors": [
        "Orson Mengara"
      ],
      "abstract": "The area of Machine Learning as a Service (MLaaS) is experiencing increased\nimplementation due to recent advancements in the AI (Artificial Intelligence)\nindustry. However, this spike has prompted concerns regarding AI defense\nmechanisms, specifically regarding potential covert attacks from third-party\nproviders that cannot be entirely trusted. Recent research has uncovered that\nauditory backdoors may use certain modifications as their initiating mechanism.\nDynamicTrigger is introduced as a methodology for carrying out dynamic backdoor\nattacks that use cleverly designed tweaks to ensure that corrupted samples are\nindistinguishable from clean. By utilizing fluctuating signal sampling rates\nand masking speaker identities through dynamic sound triggers (such as the\nclapping of hands), it is possible to deceive speech recognition systems (ASR).\nOur empirical testing demonstrates that DynamicTrigger is both potent and\nstealthy, achieving impressive success rates during covert attacks while\nmaintaining exceptional accuracy with non-poisoned datasets.",
      "tldr_zh": "该论文探讨了机器学习即服务 (MLaaS) 中的后门攻击风险，提出了一种名为 DynamicTrigger 的鲁棒后门攻击方法，通过动态堆叠触发器（如波动信号采样率和掩盖说话者身份的动态声音触发器，例如拍手声）来使篡改样本与正常样本难以区分，从而欺骗语音识别系统 (ASR)。这种方法确保攻击的隐蔽性和有效性，同时在实验中证明了其强大性能，在后门攻击中实现了高成功率。研究结果显示，DynamicTrigger 在非毒化数据集上保持了出色的准确率，为评估AI防御机制提供了新洞见。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted by AAAI Workshop 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.01537v4",
      "published_date": "2024-01-03 04:31:59 UTC",
      "updated_date": "2024-09-28 08:23:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:36:44.195783"
    },
    {
      "arxiv_id": "2401.01523v4",
      "title": "GOAT-Bench: Safety Insights to Large Multimodal Models through Meme-Based Social Abuse",
      "title_zh": "翻译失败",
      "authors": [
        "Hongzhan Lin",
        "Ziyang Luo",
        "Bo Wang",
        "Ruichao Yang",
        "Jing Ma"
      ],
      "abstract": "The exponential growth of social media has profoundly transformed how\ninformation is created, disseminated, and absorbed, exceeding any precedent in\nthe digital age. Regrettably, this explosion has also spawned a significant\nincrease in the online abuse of memes. Evaluating the negative impact of memes\nis notably challenging, owing to their often subtle and implicit meanings,\nwhich are not directly conveyed through the overt text and image. In light of\nthis, large multimodal models (LMMs) have emerged as a focal point of interest\ndue to their remarkable capabilities in handling diverse multimodal tasks. In\nresponse to this development, our paper aims to thoroughly examine the capacity\nof various LMMs (e.g., GPT-4o) to discern and respond to the nuanced aspects of\nsocial abuse manifested in memes. We introduce the comprehensive meme\nbenchmark, GOAT-Bench, comprising over 6K varied memes encapsulating themes\nsuch as implicit hate speech, sexism, and cyberbullying, etc. Utilizing\nGOAT-Bench, we delve into the ability of LMMs to accurately assess hatefulness,\nmisogyny, offensiveness, sarcasm, and harmful content. Our extensive\nexperiments across a range of LMMs reveal that current models still exhibit a\ndeficiency in safety awareness, showing insensitivity to various forms of\nimplicit abuse. We posit that this shortfall represents a critical impediment\nto the realization of safe artificial intelligence. The GOAT-Bench and\naccompanying resources are publicly accessible at https://goatlmm.github.io/,\ncontributing to ongoing research in this vital field.",
      "tldr_zh": "该论文探讨了社交媒体 meme 滥用对大型多模态模型 (LMMs) 安全性的影响，强调 meme 的隐含含义（如仇恨言论和性别歧视）使得评估难度增大。研究者引入了 GOAT-Bench，这是一个包含超过 6K 个 meme 的全面基准数据集，用于测试 LMMs（如 GPT-4o）识别仇恨、厌女症、冒犯性、讽刺和有害内容的能力。实验结果显示，当前 LMMs 在处理隐含社会滥用方面存在显著缺陷，导致安全意识不足，这阻碍了安全人工智能的发展。GOAT-Bench 和相关资源已公开提供，旨在推动该领域的进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "The first work to benchmark Large Multimodal Models in safety insight\n  on social media",
      "pdf_url": "http://arxiv.org/pdf/2401.01523v4",
      "published_date": "2024-01-03 03:28:55 UTC",
      "updated_date": "2025-02-28 15:13:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:36:55.381313"
    },
    {
      "arxiv_id": "2401.01519v4",
      "title": "Exploring the Frontiers of LLMs in Psychological Applications: A Comprehensive Review",
      "title_zh": "探索 LLMs 在心理应用的前沿：全面综述",
      "authors": [
        "Luoma Ke",
        "Song Tong",
        "Peng Cheng",
        "Kaiping Peng"
      ],
      "abstract": "This paper explores the frontiers of large language models (LLMs) in\npsychology applications. Psychology has undergone several theoretical changes,\nand the current use of Artificial Intelligence (AI) and Machine Learning,\nparticularly LLMs, promises to open up new research directions. We provide a\ndetailed exploration of how LLMs like ChatGPT are transforming psychological\nresearch. It discusses the impact of LLMs across various branches of\npsychology, including cognitive and behavioral, clinical and counseling,\neducational and developmental, and social and cultural psychology, highlighting\ntheir potential to simulate aspects of human cognition and behavior. The paper\ndelves into the capabilities of these models to emulate human-like text\ngeneration, offering innovative tools for literature review, hypothesis\ngeneration, experimental design, experimental subjects, data analysis, academic\nwriting, and peer review in psychology. While LLMs are essential in advancing\nresearch methodologies in psychology, the paper also cautions about their\ntechnical and ethical challenges. There are issues like data privacy, the\nethical implications of using LLMs in psychological research, and the need for\na deeper understanding of these models' limitations. Researchers should\nresponsibly use LLMs in psychological studies, adhering to ethical standards\nand considering the potential consequences of deploying these technologies in\nsensitive areas. Overall, the article provides a comprehensive overview of the\ncurrent state of LLMs in psychology, exploring potential benefits and\nchallenges. It serves as a call to action for researchers to leverage LLMs'\nadvantages responsibly while addressing associated risks.",
      "tldr_zh": "这篇论文对大型语言模型（LLMs）在心理学应用中的前沿发展进行全面综述，探讨了LLMs如ChatGPT如何推动心理学研究变革，包括在认知行为、临床咨询、教育发展和社交文化等领域模拟人类认知和行为。论文强调LLMs可提供创新工具，如文献综述、假设生成、实验设计、数据分析和学术写作，从而提升研究效率。另一方面，它警示了技术挑战和伦理问题，包括数据隐私风险和模型局限性，并呼吁研究者负责任地使用LLMs，遵守伦理标准并权衡潜在风险，以实现可持续应用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.01519v4",
      "published_date": "2024-01-03 03:01:29 UTC",
      "updated_date": "2025-04-20 08:45:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:37:07.573569"
    },
    {
      "arxiv_id": "2401.01496v1",
      "title": "From Pixel to Slide image: Polarization Modality-based Pathological Diagnosis Using Representation Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Jia Dong",
        "Yao Yao",
        "Yang Dong",
        "Hui Ma"
      ],
      "abstract": "Thyroid cancer is the most common endocrine malignancy, and accurately\ndistinguishing between benign and malignant thyroid tumors is crucial for\ndeveloping effective treatment plans in clinical practice. Pathologically,\nthyroid tumors pose diagnostic challenges due to improper specimen sampling. In\nthis study, we have designed a three-stage model using representation learning\nto integrate pixel-level and slice-level annotations for distinguishing thyroid\ntumors. This structure includes a pathology structure recognition method to\npredict structures related to thyroid tumors, an encoder-decoder network to\nextract pixel-level annotation information by learning the feature\nrepresentations of image blocks, and an attention-based learning mechanism for\nthe final classification task. This mechanism learns the importance of\ndifferent image blocks in a pathological region, globally considering the\ninformation from each block. In the third stage, all information from the image\nblocks in a region is aggregated using attention mechanisms, followed by\nclassification to determine the category of the region. Experimental results\ndemonstrate that our proposed method can predict microscopic structures more\naccurately. After color-coding, the method achieves results on unstained\npathology slides that approximate the quality of Hematoxylin and eosin\nstaining, reducing the need for stained pathology slides. Furthermore, by\nleveraging the concept of indirect measurement and extracting polarized\nfeatures from structures correlated with lesions, the proposed method can also\nclassify samples where membrane structures cannot be obtained through sampling,\nproviding a potential objective and highly accurate indirect diagnostic\ntechnique for thyroid tumors.",
      "tldr_zh": "本文提出了一种基于极化模态的病理诊断方法，使用 representation learning 整合像素级和切片级注释，以准确区分甲状腺肿瘤的良性和恶性。该三阶段模型包括病理结构识别、encoder-decoder 网络提取图像块特征，以及attention-based 学习机制聚合信息进行分类。实验结果表明，该方法能更精确预测微观结构，并在未染色病理切片上实现类似 Hematoxylin and eosin 染色的质量，减少染色需求，并为采样不足的样本提供客观、高精度的间接诊断技术。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.01496v1",
      "published_date": "2024-01-03 02:01:09 UTC",
      "updated_date": "2024-01-03 02:01:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:37:18.795168"
    },
    {
      "arxiv_id": "2401.01493v1",
      "title": "Free Lunch for Federated Remote Sensing Target Fine-Grained Classification: A Parameter-Efficient Framework",
      "title_zh": "翻译失败",
      "authors": [
        "Shengchao Chen",
        "Ting Shu",
        "Huan Zhao",
        "Jiahao Wang",
        "Sufen Ren",
        "Lina Yang"
      ],
      "abstract": "Remote Sensing Target Fine-grained Classification (TFGC) is of great\nsignificance in both military and civilian fields. Due to location differences,\ngrowth in data size, and centralized server storage constraints, these data are\nusually stored under different databases across regions/countries. However,\nprivacy laws and national security concerns constrain researchers from\naccessing these sensitive remote sensing images for further analysis.\nAdditionally, low-resource remote sensing devices encounter challenges in terms\nof communication overhead and efficiency when dealing with the ever-increasing\ndata and model scales. To solve the above challenges, this paper proposes a\nnovel Privacy-Reserving TFGC Framework based on Federated Learning, dubbed\nPRFL. The proposed framework allows each client to learn global and local\nknowledge to enhance the local representation of private data in environments\nwith extreme statistical heterogeneity (non. Independent and Identically\nDistributed, IID). Thus, it provides highly customized models to clients with\ndifferentiated data distributions. Moreover, the framework minimizes\ncommunication overhead and improves efficiency while ensuring satisfactory\nperformance, thereby enhancing robustness and practical applicability under\nresource-scarce conditions. We demonstrate the effectiveness of the proposed\nPRFL on the classical TFGC task by leveraging four public datasets.",
      "tldr_zh": "该论文针对远程感应目标细粒度分类（TFGC）面临的隐私保护、数据分布异质性（non-IID）和通信开销挑战，提出了一种基于Federated Learning的创新框架PRFL（Privacy-Reserving TFGC Framework）。该框架允许每个客户端同时学习全局和本地知识，从而增强私有数据的本地表示，并为不同数据分布提供高度自定义的模型，同时显著减少通信开销和提高效率。实验在四个公共数据集上验证了PRFL的有效性，展示了其在资源有限环境下的鲁棒性和实际应用潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "Under Review, 23 pages, 3 figures, 12 tables",
      "pdf_url": "http://arxiv.org/pdf/2401.01493v1",
      "published_date": "2024-01-03 01:45:00 UTC",
      "updated_date": "2024-01-03 01:45:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:37:35.269889"
    },
    {
      "arxiv_id": "2401.01489v1",
      "title": "The Neuron as a Direct Data-Driven Controller",
      "title_zh": "神经元作为直接数据驱动控制器",
      "authors": [
        "Jason Moore",
        "Alexander Genkin",
        "Magnus Tournoy",
        "Joshua Pughe-Sanford",
        "Rob R. de Ruyter van Steveninck",
        "Dmitri B. Chklovskii"
      ],
      "abstract": "In the quest to model neuronal function amidst gaps in physiological data, a\npromising strategy is to develop a normative theory that interprets neuronal\nphysiology as optimizing a computational objective. This study extends the\ncurrent normative models, which primarily optimize prediction, by\nconceptualizing neurons as optimal feedback controllers. We posit that neurons,\nespecially those beyond early sensory areas, act as controllers, steering their\nenvironment towards a specific desired state through their output. This\nenvironment comprises both synaptically interlinked neurons and external motor\nsensory feedback loops, enabling neurons to evaluate the effectiveness of their\ncontrol via synaptic feedback. Utilizing the novel Direct Data-Driven Control\n(DD-DC) framework, we model neurons as biologically feasible controllers which\nimplicitly identify loop dynamics, infer latent states and optimize control.\nOur DD-DC neuron model explains various neurophysiological phenomena: the shift\nfrom potentiation to depression in Spike-Timing-Dependent Plasticity (STDP)\nwith its asymmetry, the duration and adaptive nature of feedforward and\nfeedback neuronal filters, the imprecision in spike generation under constant\nstimulation, and the characteristic operational variability and noise in the\nbrain. Our model presents a significant departure from the traditional,\nfeedforward, instant-response McCulloch-Pitts-Rosenblatt neuron, offering a\nnovel and biologically-informed fundamental unit for constructing neural\nnetworks.",
      "tldr_zh": "这篇论文提出了一种新规范理论，将神经元视为最佳反馈控制器（optimal feedback controllers），尤其是在早期感觉区域之外的神经元，通过输出引导其环境（如突触连接和外部反馈回路）达到特定状态，从而扩展了传统的预测优化模型。研究利用 Direct Data-Driven Control (DD-DC) 框架来构建生物上可行的神经元模型，该模型能隐式识别回路动态、推断潜在状态并优化控制。论文的关键发现是，该模型成功解释了多种神经生理现象，包括 Spike-Timing-Dependent Plasticity (STDP) 的从增强到抑制的不对称转变、神经元过滤器的持续性和适应性、尖峰生成的不精确性，以及脑部操作的可变性和噪声。与传统的 McCulloch-Pitts-Rosenblatt 神经元模型不同，该框架提供了一个新的反馈式基础单元，为构建更生物学真实的神经网络奠定基础。",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "q-bio.NC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.01489v1",
      "published_date": "2024-01-03 01:24:10 UTC",
      "updated_date": "2024-01-03 01:24:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:37:49.661332"
    },
    {
      "arxiv_id": "2401.01484v1",
      "title": "Uncertainty Regularized Evidential Regression",
      "title_zh": "翻译失败",
      "authors": [
        "Kai Ye",
        "Tiejin Chen",
        "Hua Wei",
        "Liang Zhan"
      ],
      "abstract": "The Evidential Regression Network (ERN) represents a novel approach that\nintegrates deep learning with Dempster-Shafer's theory to predict a target and\nquantify the associated uncertainty. Guided by the underlying theory, specific\nactivation functions must be employed to enforce non-negative values, which is\na constraint that compromises model performance by limiting its ability to\nlearn from all samples. This paper provides a theoretical analysis of this\nlimitation and introduces an improvement to overcome it. Initially, we define\nthe region where the models can't effectively learn from the samples. Following\nthis, we thoroughly analyze the ERN and investigate this constraint. Leveraging\nthe insights from our analysis, we address the limitation by introducing a\nnovel regularization term that empowers the ERN to learn from the whole\ntraining set. Our extensive experiments substantiate our theoretical findings\nand demonstrate the effectiveness of the proposed solution.",
      "tldr_zh": "该论文分析了Evidential Regression Network (ERN)，一种结合深度学习和Dempster-Shafer理论的模型，用于预测目标并量化不确定性，但其强制非负值的激活函数限制了模型从所有样本中学习，导致性能下降。作者通过理论分析定义了模型无法有效学习样本的区域，并引入了一个新的正则化项，使ERN能够从整个训练集获取知识。实验结果验证了这一改进的有效性，提升了模型的整体表现。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to AAAI 2024 main track",
      "pdf_url": "http://arxiv.org/pdf/2401.01484v1",
      "published_date": "2024-01-03 01:18:18 UTC",
      "updated_date": "2024-01-03 01:18:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:37:57.053974"
    },
    {
      "arxiv_id": "2401.01482v2",
      "title": "Incorporating Geo-Diverse Knowledge into Prompting for Increased Geographical Robustness in Object Recognition",
      "title_zh": "将地理多样性知识融入提示中以提高对象识别中的地理鲁棒性",
      "authors": [
        "Kyle Buettner",
        "Sina Malakouti",
        "Xiang Lorraine Li",
        "Adriana Kovashka"
      ],
      "abstract": "Existing object recognition models have been shown to lack robustness in\ndiverse geographical scenarios due to domain shifts in design and context.\nClass representations need to be adapted to more accurately reflect an object\nconcept under these shifts. In the absence of training data from target\ngeographies, we hypothesize that geographically diverse descriptive knowledge\nof categories can enhance robustness. For this purpose, we explore the\nfeasibility of probing a large language model for geography-based object\nknowledge, and we examine the effects of integrating knowledge into zero-shot\nand learnable soft prompting with CLIP. Within this exploration, we propose\ngeography knowledge regularization to ensure that soft prompts trained on a\nsource set of geographies generalize to an unseen target set. Accuracy gains\nover prompting baselines on DollarStreet while training only on Europe data are\nup to +2.8/1.2/1.6 on target data from Africa/Asia/Americas, and +4.6 overall\non the hardest classes. Competitive performance is shown vs. few-shot target\ntraining, and analysis is provided to direct future study of geographical\nrobustness.",
      "tldr_zh": "该研究发现，现有的物体识别模型在不同地理场景下因领域偏移而缺乏地理鲁棒性（geographical robustness），因此提出通过整合地理多样性知识来提升模型性能。作者从大语言模型中提取geography-based object知识，并将其融入CLIP的zero-shot和可学习软prompting（soft prompting）中，同时引入geography knowledge regularization技术，以确保软prompt从源地理（如欧洲）训练后能泛化到未见目标地理。实验在DollarStreet数据集上显示，仅使用欧洲数据训练，目标数据（Africa/Asia/Americas）的准确率分别提升高达+2.8/1.2/1.6，整体hardest classes提升+4.6，与few-shot目标训练相比表现出色，并为未来地理鲁棒性研究提供分析指导。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "To appear in IEEE/CVF Computer Vision and Pattern Recognition\n  Conference (CVPR), 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.01482v2",
      "published_date": "2024-01-03 01:11:16 UTC",
      "updated_date": "2024-03-29 18:52:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:38:11.472036"
    },
    {
      "arxiv_id": "2401.01470v2",
      "title": "TPC-ViT: Token Propagation Controller for Efficient Vision Transformer",
      "title_zh": "翻译失败",
      "authors": [
        "Wentao Zhu"
      ],
      "abstract": "Vision transformers (ViTs) have achieved promising results on a variety of\nComputer Vision tasks, however their quadratic complexity in the number of\ninput tokens has limited their application specially in resource-constrained\nsettings. Previous approaches that employ gradual token reduction to address\nthis challenge assume that token redundancy in one layer implies redundancy in\nall the following layers. We empirically demonstrate that this assumption is\noften not correct, i.e., tokens that are redundant in one layer can be useful\nin later layers. We employ this key insight to propose a novel token\npropagation controller (TPC) that incorporates two different\ntoken-distributions, i.e., pause probability and restart probability to control\nthe reduction and reuse of tokens respectively, which results in more efficient\ntoken utilization. To improve the estimates of token distributions, we propose\na smoothing mechanism that acts as a regularizer and helps remove noisy\noutliers. Furthermore, to improve the training-stability of our proposed TPC,\nwe introduce a model stabilizer that is able to implicitly encode local image\nstructures and minimize accuracy fluctuations during model training. We present\nextensive experimental results on the ImageNet-1K dataset using DeiT, LV-ViT\nand Swin models to demonstrate the effectiveness of our proposed method. For\nexample, compared to baseline models, our proposed method improves the\ninference speed of the DeiT-S by 250% while increasing the classification\naccuracy by 1.0%.",
      "tldr_zh": "本研究针对 Vision Transformers (ViTs) 的二次方复杂度问题，提出了一种高效的 Token Propagation Controller (TPC)，通过 pause probability 和 restart probability 动态控制 token 的减少和重用，从而更好地利用 token 并纠正现有方法的冗余假设。TPC 还引入 smoothing mechanism 作为正则化器以去除噪声异常值，以及 model stabilizer 来编码局部图像结构并提升训练稳定性。在 ImageNet-1K 数据集上的实验显示，与基线模型相比，该方法使 DeiT-S 的推理速度提升 250%，同时分类准确率提高 1.0%。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.MM",
        "cs.NE"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by the main conference of WACV 2024; well-formatted PDF is\n  in\n  https://drive.google.com/file/d/1Id3oEdYv3OWing1qojQMyjvhZO-gG-Dm/view?usp=sharing\n  ; supplementary is in\n  https://drive.google.com/file/d/15LhYlBdCXtompA0_TLAp_ZJb4_sq2N5V/view?usp=sharing",
      "pdf_url": "http://arxiv.org/pdf/2401.01470v2",
      "published_date": "2024-01-03 00:10:33 UTC",
      "updated_date": "2024-01-08 17:03:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:38:22.604992"
    },
    {
      "arxiv_id": "2401.01469v1",
      "title": "Question-Answering Based Summarization of Electronic Health Records using Retrieval Augmented Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Walid Saba",
        "Suzanne Wendelken",
        "James. Shanahan"
      ],
      "abstract": "Summarization of electronic health records (EHRs) can substantially minimize\n'screen time' for both patients as well as medical personnel. In recent years\nsummarization of EHRs have employed machine learning pipelines using state of\nthe art neural models. However, these models have produced less than adequate\nresults that are attributed to the difficulty of obtaining sufficient annotated\ndata for training. Moreover, the requirement to consider the entire content of\nan EHR in summarization has resulted in poor performance due to the fact that\nattention mechanisms in modern large language models (LLMs) adds a quadratic\ncomplexity in terms of the size of the input. We propose here a method that\nmitigates these shortcomings by combining semantic search, retrieval augmented\ngeneration (RAG) and question-answering using the latest LLMs. In our approach\nsummarization is the extraction of answers to specific questions that are\ndeemed important by subject-matter experts (SMEs). Our approach is quite\nefficient; requires minimal to no training; does not suffer from the\n'hallucination' problem of LLMs; and it ensures diversity, since the summary\nwill not have repeated content but diverse answers to specific questions.",
      "tldr_zh": "该论文提出了一种基于问答的电子健康记录 (EHRs) 总结化方法，利用检索增强生成 (RAG) 结合语义搜索和最新的大型语言模型 (LLMs)，以解决传统神经模型在数据标注不足和输入规模导致的性能问题。方法通过提取对专家认定的特定问题的答案来生成总结，确保内容高效、避免 LLMs 的幻觉问题，并实现多样性而无重复信息。该方法无需或仅需最少训练，为减少患者和医疗人员屏幕时间提供了实用解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.01469v1",
      "published_date": "2024-01-03 00:09:34 UTC",
      "updated_date": "2024-01-03 00:09:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:38:33.092979"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 56,
  "processed_papers_count": 56,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-16T19:38:59.107740"
}