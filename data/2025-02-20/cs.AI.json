{
  "date": "2025-02-20",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-02-20 的 arXiv 中文 TLDR 快报！今天 arXiv 的论文主要聚焦于 AI 模型的安全性、效率优化、多模态处理和特定领域应用，如 LLM 的 hallucination 问题、强化学习的多代理系统，以及多模态检索增强生成（RAG）。令人印象深刻的包括 Sakana 的 AI Scientist 框架，展示了 AI 自主研究潜力，以及多模态 RAG 的创新应用；知名学者如 Sergey Levine 和 Song Han 的工作也值得关注。\n\n下面，我将挑选并简要讨论今天的关键论文，先从 AI 安全和 LLM 优化入手，再聊多模态和视觉模型、医学应用，以及其他亮点。相关论文会放在一起讨论，非核心内容快速掠过。\n\n### AI 安全和 LLM 优化\n- **Reward Models Identify Consistency, Not Causality (奖励模型识别一致性而非因果性)**  \n  这篇论文揭示了 LLM 奖励模型在决策中的局限性，主要发现是奖励模型更注重输出一致性而非因果关系，作者 David Noever 等通过实验分析了 LLM 在不同语言中的边界处理。贡献在于强调了 LLM 情感边界评估的不足，为更可靠的 AI 决策提供新视角。\n\n- **Verify when Uncertain: Beyond Self-Consistency in Black Box Hallucination Detection (在不确定时验证：超越自一致性的黑箱幻觉检测)**  \n  作者 Yihao Xue 等提出了一种基于不确定性的幻觉检测算法，通过结合自一致性和跨模型检查，显著提高了检测效率。关键发现是，该方法在减少计算成本的同时保持高性能，为黑箱 LLM 的幻觉问题提供了实用解决方案。\n\n- **LLM-Microscope: Uncovering the Hidden Role of Punctuation in Context Memory of Transformers (LLM-显微镜：揭示标点符号在 Transformer 上下文记忆中的隐藏作用)**  \n  Anton Razzhigaev 等的研究显示，标点符号在 LLM 的上下文记忆中扮演关键角色，移除它们会降低模型性能。贡献在于通过工具分析了非核心标记的影响，这对优化 LLM 的长程理解有启发。\n\n- **Edit Once, Update Everywhere: A Simple Framework for Cross-Lingual Knowledge Synchronization in LLMs (编辑一次，更新处处：LLM 跨语言知识同步的简单框架)**  \n  Yuchen Wu 等开发了一种高效的知识编辑框架，能同步更新 LLM 的多语言知识。发现显示，该方法在保持模型性能的同时显著减少编辑冲突，是 LLM 多语言适配的实用进展。\n\n这些论文突出了 LLM 安全性和知识编辑的挑战，相关工作如 hallucination 检测和跨语言同步显示了 AI 社区对可靠性的关注。\n\n### 多模态和视觉模型\n- **Can Hallucination Correction Improve Video-Language Alignment? (幻觉修正能否改善视频-语言对齐？)**  \n  Lingjun Zhao 等引入 HACA 框架，通过幻觉修正提升视频-语言模型的时空推理能力。关键贡献是实验证明了幻觉修正在视频检索任务中的效果提升，为多模态模型的鲁棒性提供了新路径。\n\n- **Multimodal RAG through a Chart-based Document Question-Answering Generation Framework (基于图表的文档问答生成框架的多模态 RAG)**  \n  Yuming Yang 等提出 CHARGE 框架，生成图表-based 的多模态数据，提升 RAG 在图表场景下的性能。发现显示，该方法改善了视觉-文本检索，但仍存在模态偏差问题，是多模态基准的重要扩展。\n\n- **InterFeedback: Unveiling Interactive Intelligence of Large Multimodal Models via Human Feedback (InterFeedback：通过人类反馈揭示大多模态模型的交互智能)**  \n  Henry Hengyuan Zhao 等构建了交互式基准，评估多模态模型对反馈的响应能力。贡献在于实验显示顶级模型如 OpenAI-o1 在反馈处理上仍有不足，这推动了多模态模型的交互优化。\n\n这些多模态论文强调了 RAG 和幻觉修正在实际应用中的潜力，相关工作展示了视觉-语言对齐的进展。\n\n### 医学应用\n- **Reducing Hallucinations of Medical Multimodal Large Language Models with Visual Retrieval-Augmented Generation (通过视觉检索增强生成减少医疗多模态 LLM 的幻觉)**  \n  Yun-Wei Chu 等提出 V-RAG 方法，使用视觉检索减少医疗图像模型的幻觉。发现显示，该方法在报告生成任务中显著提升了准确性，是医疗 AI 领域的重要实用贡献。\n\n- **FetalCLIP: A Visual-Language Foundation Model for Fetal Ultrasound Image Analysis (FetalCLIP：胎儿超声图像分析的视觉-语言基础模型)**  \n  Fadillah Maani 等开发了 FetalCLIP 模型，用于胎儿超声图像分析。关键发现是，该模型在多种任务中表现出色，填补了医疗图像处理的空白。\n\n这些论文在医学 AI 上取得了具体进展，突出了多模态模型在临床中的潜力。\n\n### 其他亮点\n- **Alignment, Agency and Autonomy in Frontier AI: A Systems Engineering Perspective (前沿 AI 中的对齐、代理性和自治：系统工程视角)**  \n  Krti Tallam 的工作分析了 AI 系统中的对齐问题，通过案例研究强调了治理挑战。这是 AI 安全领域的理论性贡献。\n\n- **Efficient Unlearning for Protecting Intellectual Property in Large Language Models (高效遗忘以保护 LLM 中的知识产权)**  \n  Mark Russinovich 等提出 Obliviate 方法，防止 LLM 复制受版权内容。发现显示，该方法在保持模型性能的同时显著减少了记忆泄露。\n\n其他论文如量子计算和图神经网络虽有技术创新，但相对专业或不那么热门，这里快速掠过；例如，\"Fundamental Survey on Neuromorphic Based Audio Classification\" 提供了神经形态计算的综述，但未有突破性发现。\n\n总之，今天的论文突出了 AI 的安全性和多模态应用，Sakana 的 AI Scientist 和多模态 RAG 框架是亮点，期待这些方向的进一步发展！如果有特定感兴趣的领域，欢迎关注后续更新。",
  "papers": [
    {
      "arxiv_id": "2502.15090v1",
      "title": "Analyze the Neurons, not the Embeddings: Understanding When and Where LLM Representations Align with Humans",
      "title_zh": "翻译失败",
      "authors": [
        "Masha Fedzechkina",
        "Eleonora Gualdoni",
        "Sinead Williamson",
        "Katherine Metcalf",
        "Skyler Seto",
        "Barry-John Theobald"
      ],
      "abstract": "Modern large language models (LLMs) achieve impressive performance on some\ntasks, while exhibiting distinctly non-human-like behaviors on others. This\nraises the question of how well the LLM's learned representations align with\nhuman representations. In this work, we introduce a novel approach to the study\nof representation alignment: we adopt a method from research on activation\nsteering to identify neurons responsible for specific concepts (e.g., 'cat')\nand then analyze the corresponding activation patterns. Our findings reveal\nthat LLM representations closely align with human representations inferred from\nbehavioral data. Notably, this alignment surpasses that of word embeddings,\nwhich have been center stage in prior work on human and model alignment.\nAdditionally, our approach enables a more granular view of how LLMs represent\nconcepts. Specifically, we show that LLMs organize concepts in a way that\nreflects hierarchical relationships interpretable to humans (e.g.,\n'animal'-'dog').",
      "tldr_zh": "本研究探讨大型语言模型（LLMs）的表示如何与人类表示对齐，提出一种新方法：通过分析神经元（neurons）的激活模式，而不是传统的嵌入（embeddings），来识别特定概念（如 'cat'）。研究发现，LLMs 的表示与从人类行为数据推断出的表示高度一致，甚至超过了词嵌入（word embeddings）在先前工作中的表现。进一步分析显示，LLMs 以人类可解释的层次结构组织概念，例如 'animal'-'dog' 的关系，这为理解模型内部机制提供了更细粒度的洞见。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.15090v1",
      "published_date": "2025-02-20 23:08:03 UTC",
      "updated_date": "2025-02-20 23:08:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:13:02.040269"
    },
    {
      "arxiv_id": "2502.15082v1",
      "title": "UPCORE: Utility-Preserving Coreset Selection for Balanced Unlearning",
      "title_zh": "翻译失败",
      "authors": [
        "Vaidehi Patil",
        "Elias Stengel-Eskin",
        "Mohit Bansal"
      ],
      "abstract": "User specifications or legal frameworks often require information to be\nremoved from pretrained models, including large language models (LLMs). This\nrequires deleting or \"forgetting\" a set of data points from an already-trained\nmodel, which typically degrades its performance on other data points. Thus, a\nbalance must be struck between removing information and keeping the model's\nother abilities intact, with a failure to balance this trade-off leading to\npoor deletion or an unusable model. To this end, we propose UPCORE\n(Utility-Preserving Coreset Selection), a method-agnostic data selection\nframework for mitigating collateral damage during unlearning. Finding that the\nmodel damage is correlated with the variance of the model's representations on\nthe forget set, we selectively prune the forget set to remove outliers, thereby\nminimizing model degradation after unlearning. We evaluate UPCORE across three\nstandard unlearning methods consistently achieving a superior balance between\nthe competing objectives of deletion efficacy and model preservation. To better\nevaluate this trade-off, we introduce a new metric, measuring the\narea-under-the-curve (AUC) across standard metrics. We find that UPCORE\nimproves both standard metrics and AUC, benefitting from positive transfer\nbetween the coreset and pruned points while reducing negative transfer from the\nforget set to points outside of it.",
      "tldr_zh": "该研究针对从预训练模型（如LLMs）中删除数据点时导致性能下降的问题，提出UPCORE（Utility-Preserving Coreset Selection）框架，这是一种方法无关的数据选择方法，用于在unlearning（取消学习）过程中减少附带损害。UPCORE通过分析模型在forget set（忘记集）上的表示方差，选择性地修剪异常值，从而最小化模型退化。实验结果显示，UPCORE在三种标准unlearning方法上实现了删除效率和模型保留的更好平衡，并引入了新的AUC（面积下曲线）指标来评估这一权衡，整体表现优于基准方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Code: https://github.com/Vaidehi99/UPCORE",
      "pdf_url": "http://arxiv.org/pdf/2502.15082v1",
      "published_date": "2025-02-20 22:51:10 UTC",
      "updated_date": "2025-02-20 22:51:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:13:15.727007"
    },
    {
      "arxiv_id": "2502.15079v1",
      "title": "Can Hallucination Correction Improve Video-Language Alignment?",
      "title_zh": "幻觉修正能否改善视频-语言对齐？",
      "authors": [
        "Lingjun Zhao",
        "Mingyang Xie",
        "Paola Cascante-Bonilla",
        "Hal Daumé III",
        "Kwonjoon Lee"
      ],
      "abstract": "Large Vision-Language Models often generate hallucinated content that is not\ngrounded in its visual inputs. While prior work focuses on mitigating\nhallucinations, we instead explore leveraging hallucination correction as a\ntraining objective to improve video-language alignment. We introduce HACA, a\nself-training framework learning to correct hallucinations in descriptions that\ndo not align with the video content. By identifying and correcting\ninconsistencies, HACA enhances the model's ability to align video and textual\nrepresentations for spatio-temporal reasoning. Our experimental results show\nconsistent gains in video-caption binding and text-to-video retrieval tasks,\ndemonstrating that hallucination correction-inspired tasks serve as an\neffective strategy for improving vision and language alignment.",
      "tldr_zh": "本研究探讨了幻觉修正(Hallucination Correction)是否能提升视频-语言对齐(Video-Language Alignment)，针对大型视觉语言模型(Vision-Language Models)产生的与视觉输入不符的内容问题。作者提出 HACA 框架，这是一个自训练系统，用于识别和修正描述中与视频不一致的部分，从而增强模型在时空推理(spatio-temporal reasoning)方面的能力。实验结果显示，HACA 在视频-标题绑定和文本到视频检索任务上实现了显著改进，证明幻觉修正任务是一种有效策略来改善视觉和语言表示的对齐。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.15079v1",
      "published_date": "2025-02-20 22:43:22 UTC",
      "updated_date": "2025-02-20 22:43:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:13:28.291906"
    },
    {
      "arxiv_id": "2502.17494v6",
      "title": "External Large Foundation Model: How to Efficiently Serve Trillions of Parameters for Online Ads Recommendation",
      "title_zh": "外部大型基础模型：如何高效服务数万亿参数用于在线广告推荐",
      "authors": [
        "Mingfu Liang",
        "Xi Liu",
        "Rong Jin",
        "Boyang Liu",
        "Qiuling Suo",
        "Qinghai Zhou",
        "Song Zhou",
        "Laming Chen",
        "Hua Zheng",
        "Zhiyuan Li",
        "Shali Jiang",
        "Jiyan Yang",
        "Xiaozhen Xia",
        "Fan Yang",
        "Yasmine Badr",
        "Ellie Wen",
        "Shuyu Xu",
        "Hansey Chen",
        "Zhengyu Zhang",
        "Jade Nie",
        "Chunzhi Yang",
        "Zhichen Zeng",
        "Weilin Zhang",
        "Xingliang Huang",
        "Qianru Li",
        "Shiquan Wang",
        "Evelyn Lyu",
        "Wenjing Lu",
        "Rui Zhang",
        "Wenjun Wang",
        "Jason Rudy",
        "Mengyue Hang",
        "Kai Wang",
        "Yinbin Ma",
        "Shuaiwen Wang",
        "Sihan Zeng",
        "Tongyi Tang",
        "Xiaohan Wei",
        "Longhao Jin",
        "Jamey Zhang",
        "Marcus Chen",
        "Jiayi Xu",
        "Angie Huang",
        "Xihuan Zeng",
        "Chi Zhang",
        "Zhengli Zhao",
        "Jared Yang",
        "Qiang Jin",
        "Xian Chen",
        "Amit Anand Amlesahwaram",
        "Lexi Song",
        "Liang Luo",
        "Yuchen Hao",
        "Nan Xiao",
        "Yavuz Yetim",
        "Luoshang Pan",
        "Gaoxiang Liu",
        "Yuxi Hu",
        "Yuzhen Huang",
        "Jackie Xu",
        "Rich Zhu",
        "Xin Zhang",
        "Yiqun Liu",
        "Hang Yin",
        "Yuxin Chen",
        "Buyun Zhang",
        "Xiaoyi Liu",
        "Xingyuan Wang",
        "Wenguang Mao",
        "Zhijing Li",
        "Zhehui Zhou",
        "Feifan Gu",
        "Qin Huang",
        "Chonglin Sun",
        "Nancy Yu",
        "Shuo Gu",
        "Shupin Mao",
        "Benjamin Au",
        "Jingzheng Qin",
        "Peggy Yao",
        "Jae-Woo Choi",
        "Bin Gao",
        "Ernest Wang",
        "Lei Zhang",
        "Wen-Yen Chen",
        "Ted Lee",
        "Jay Zha",
        "Yi Meng",
        "Alex Gong",
        "Edison Gao",
        "Alireza Vahdatpour",
        "Yiping Han",
        "Yantao Yao",
        "Toshinari Kureha",
        "Shuo Chang",
        "Musharaf Sultan",
        "John Bocharov",
        "Sagar Chordia",
        "Xiaorui Gan",
        "Peng Sun",
        "Rocky Liu",
        "Bo Long",
        "Wenlin Chen",
        "Santanu Kolay",
        "Huayu Li"
      ],
      "abstract": "Ads recommendation is a prominent service of online advertising systems and\nhas been actively studied. Recent studies indicate that scaling-up and advanced\ndesign of the recommendation model can bring significant performance\nimprovement. However, with a larger model scale, such prior studies have a\nsignificantly increasing gap from industry as they often neglect two\nfundamental challenges in industrial-scale applications. First, training and\ninference budgets are restricted for the model to be served, exceeding which\nmay incur latency and impair user experience. Second, large-volume data arrive\nin a streaming mode with data distributions dynamically shifting, as new\nusers/ads join and existing users/ads leave the system. We propose the External\nLarge Foundation Model (ExFM) framework to address the overlooked challenges.\nSpecifically, we develop external distillation and a data augmentation system\n(DAS) to control the computational cost of training/inference while maintaining\nhigh performance. We design the teacher in a way like a foundation model (FM)\nthat can serve multiple students as vertical models (VMs) to amortize its\nbuilding cost. We propose Auxiliary Head and Student Adapter to mitigate the\ndata distribution gap between FM and VMs caused by the streaming data issue.\nComprehensive experiments on internal industrial-scale applications and public\ndatasets demonstrate significant performance gain by ExFM.",
      "tldr_zh": "这篇论文提出 External Large Foundation Model (ExFM) 框架，用于高效服务在线广告推荐系统的万亿参数模型，解决工业应用中训练/推理预算受限和数据流式动态变化的挑战。框架采用 external distillation 和 Data Augmentation System (DAS) 来控制计算成本，同时保持高性能；其中，foundation model (FM) 作为教师模型服务多个 vertical models (VMs)，以分摊构建开销。论文还引入 Auxiliary Head 和 Student Adapter 来缓解 FM 与 VMs 之间因流式数据导致的数据分布差距。实验在内部工业应用和公共数据集上显示，ExFM 实现了显著性能提升。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted by the ACM Web Conference (WWW) 2025 Industrial Track as\n  Oral Presentation",
      "pdf_url": "http://arxiv.org/pdf/2502.17494v6",
      "published_date": "2025-02-20 22:35:52 UTC",
      "updated_date": "2025-04-23 06:47:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:13:41.085802"
    },
    {
      "arxiv_id": "2502.15077v2",
      "title": "Hardware-Friendly Static Quantization Method for Video Diffusion Transformers",
      "title_zh": "硬件友好的视频扩散变压器静态量化方法",
      "authors": [
        "Sanghyun Yi",
        "Qingfeng Liu",
        "Mostafa El-Khamy"
      ],
      "abstract": "Diffusion Transformers for video generation have gained significant research\ninterest since the impressive performance of SORA. Efficient deployment of such\ngenerative-AI models on GPUs has been demonstrated with dynamic quantization.\nHowever, resource-constrained devices cannot support dynamic quantization, and\nneed static quantization of the models for their efficient deployment on AI\nprocessors. In this paper, we propose a novel method for the post-training\nquantization of OpenSora\\cite{opensora}, a Video Diffusion Transformer, without\nrelying on dynamic quantization techniques. Our approach employs static\nquantization, achieving video quality comparable to FP16 and dynamically\nquantized ViDiT-Q methods, as measured by CLIP, and VQA metrics. In particular,\nwe utilize per-step calibration data to adequately provide a post-training\nstatically quantized model for each time step, incorporating channel-wise\nquantization for weights and tensor-wise quantization for activations. By\nfurther applying the smooth-quantization technique, we can obtain high-quality\nvideo outputs with the statically quantized models. Extensive experimental\nresults demonstrate that static quantization can be a viable alternative to\ndynamic quantization for video diffusion transformers, offering a more\nefficient approach without sacrificing performance.",
      "tldr_zh": "本论文提出了一种硬件友好的静态量化（Static Quantization）方法，针对视频扩散变换器（Video Diffusion Transformers）如 OpenSora，实现高效部署在资源受限设备上，而非依赖动态量化（Dynamic Quantization）。该方法采用后训练量化策略，包括 per-step calibration data、channel-wise quantization for weights 和 tensor-wise quantization for activations，并结合 smooth-quantization 技术，以保持视频生成质量与 FP16 或动态量化方法相当（如通过 CLIP 和 VQA 指标评估）。实验结果显示，该方法在多种视频生成任务中表现出色，提供了一种不牺牲性能的更高效替代方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.15077v2",
      "published_date": "2025-02-20 22:29:24 UTC",
      "updated_date": "2025-03-25 05:17:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:13:50.404063"
    },
    {
      "arxiv_id": "2502.15069v1",
      "title": "Rare Disease Differential Diagnosis with Large Language Models at Scale: From Abdominal Actinomycosis to Wilson's Disease",
      "title_zh": "翻译失败",
      "authors": [
        "Elliot Schumacher",
        "Dhruv Naik",
        "Anitha Kannan"
      ],
      "abstract": "Large language models (LLMs) have demonstrated impressive capabilities in\ndisease diagnosis. However, their effectiveness in identifying rarer diseases,\nwhich are inherently more challenging to diagnose, remains an open question.\nRare disease performance is critical with the increasing use of LLMs in\nhealthcare settings. This is especially true if a primary care physician needs\nto make a rarer prognosis from only a patient conversation so that they can\ntake the appropriate next step. To that end, several clinical decision support\nsystems are designed to support providers in rare disease identification. Yet\ntheir utility is limited due to their lack of knowledge of common disorders and\ndifficulty of use.\n  In this paper, we propose RareScale to combine the knowledge LLMs with expert\nsystems. We use jointly use an expert system and LLM to simulate rare disease\nchats. This data is used to train a rare disease candidate predictor model.\nCandidates from this smaller model are then used as additional inputs to\nblack-box LLM to make the final differential diagnosis. Thus, RareScale allows\nfor a balance between rare and common diagnoses. We present results on over 575\nrare diseases, beginning with Abdominal Actinomycosis and ending with Wilson's\nDisease. Our approach significantly improves the baseline performance of\nblack-box LLMs by over 17% in Top-5 accuracy. We also find that our candidate\ngeneration performance is high (e.g. 88.8% on gpt-4o generated chats).",
      "tldr_zh": "本研究探讨了大语言模型（LLMs）在诊断罕见疾病（如腹部放线菌病和威尔逊病）的效能，指出现有LLMs在这一领域面临挑战。论文提出RareScale系统，将LLMs与专家系统结合，通过模拟罕见疾病对话来训练一个候选预测模型，并将生成的候选作为输入增强黑箱LLMs的最终诊断决策，从而平衡罕见和常见疾病的识别。实验结果显示，该方法在超过575种罕见疾病上将黑箱LLMs的Top-5准确率提高了17%以上，且候选生成性能出色（如在gpt-4o生成的对话中达88.8%）。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.15069v1",
      "published_date": "2025-02-20 22:02:52 UTC",
      "updated_date": "2025-02-20 22:02:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:14:03.349553"
    },
    {
      "arxiv_id": "2502.17493v1",
      "title": "Pursuing Top Growth with Novel Loss Function",
      "title_zh": "翻译失败",
      "authors": [
        "Ruoyu Guo",
        "Haochen Qiu"
      ],
      "abstract": "Making consistently profitable financial decisions in a continuously evolving\nand volatile stock market has always been a difficult task. Professionals from\ndifferent disciplines have developed foundational theories to anticipate price\nmovement and evaluate securities such as the famed Capital Asset Pricing Model\n(CAPM). In recent years, the role of artificial intelligence (AI) in asset\npricing has been growing. Although the black-box nature of deep learning models\nlacks interpretability, they have continued to solidify their position in the\nfinancial industry. We aim to further enhance AI's potential and utility by\nintroducing a return-weighted loss function that will drive top growth while\nproviding the ML models a limited amount of information. Using only publicly\naccessible stock data (open/close/high/low, trading volume, sector information)\nand several technical indicators constructed from them, we propose an efficient\ndaily trading system that detects top growth opportunities. Our best models\nachieve 61.73% annual return on daily rebalancing with an annualized Sharpe\nRatio of 1.18 over 1340 testing days from 2019 to 2024, and 37.61% annual\nreturn with an annualized Sharpe Ratio of 0.97 over 1360 testing days from 2005\nto 2010. The main drivers for success, especially independent of any domain\nknowledge, are the novel return-weighted loss function, the integration of\ncategorical and continuous data, and the ML model architecture. We also\ndemonstrate the superiority of our novel loss function over traditional loss\nfunctions via several performance metrics and statistical evidence.",
      "tldr_zh": "这篇论文针对股票市场的波动性，提出了一种新颖的return-weighted loss function，以提升AI模型在资产定价中的表现，同时限制模型的信息输入。研究方法利用公开股票数据（如开盘/收盘价、交易量和行业信息）及技术指标，构建了一个高效的日常交易系统。实验结果显示，该系统在2019-2024年的1340个测试日内实现了61.73%的年回报率和1.18的年化Sharpe Ratio，在2005-2010年的1360个测试日内达到了37.61%的年回报率和0.97的年化Sharpe Ratio。论文的关键贡献在于证明了return-weighted loss function与传统loss function相比的优越性，通过性能指标和统计证据突出了其在驱动顶级增长方面的作用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-fin.CP",
        "I.2.1; I.2.6"
      ],
      "primary_category": "cs.LG",
      "comment": "30 pages, 7 figures, GitHub repo:\n  https://github.com/Tony-Guo-1/daily_trading_strategy",
      "pdf_url": "http://arxiv.org/pdf/2502.17493v1",
      "published_date": "2025-02-20 21:43:51 UTC",
      "updated_date": "2025-02-20 21:43:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:14:15.368999"
    },
    {
      "arxiv_id": "2503.05748v1",
      "title": "Alignment, Agency and Autonomy in Frontier AI: A Systems Engineering Perspective",
      "title_zh": "翻译失败",
      "authors": [
        "Krti Tallam"
      ],
      "abstract": "As artificial intelligence scales, the concepts of alignment, agency, and\nautonomy have become central to AI safety, governance, and control. However,\neven in human contexts, these terms lack universal definitions, varying across\ndisciplines such as philosophy, psychology, law, computer science, mathematics,\nand political science. This inconsistency complicates their application to AI,\nwhere differing interpretations lead to conflicting approaches in system design\nand regulation. This paper traces the historical, philosophical, and technical\nevolution of these concepts, emphasizing how their definitions influence AI\ndevelopment, deployment, and oversight.\n  We argue that the urgency surrounding AI alignment and autonomy stems not\nonly from technical advancements but also from the increasing deployment of AI\nin high-stakes decision making. Using Agentic AI as a case study, we examine\nthe emergent properties of machine agency and autonomy, highlighting the risks\nof misalignment in real-world systems. Through an analysis of automation\nfailures (Tesla Autopilot, Boeing 737 MAX), multi-agent coordination (Metas\nCICERO), and evolving AI architectures (DeepMinds AlphaZero, OpenAIs AutoGPT),\nwe assess the governance and safety challenges posed by frontier AI.",
      "tldr_zh": "这篇论文从系统工程视角探讨了前沿AI中的对齐（alignment）、代理性（agency）和自治（autonomy）概念，这些术语在哲学、心理学、法律和计算机科学等领域定义不一，导致AI设计和监管出现分歧。论文追溯了这些概念的历史演变及其对AI开发、部署和监督的影响，强调其紧迫性源于AI在高风险决策中的应用，并以Agentic AI为例分析机器代理性和自治的潜在风险。作者通过考察实际失败案例（如Tesla Autopilot和Boeing 737 MAX）、多代理协调（如Meta's CICERO）和AI架构（如DeepMind's AlphaZero和OpenAI's AutoGPT），评估了前沿AI在治理和安全方面的挑战，为更一致的AI框架提供见解。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.05748v1",
      "published_date": "2025-02-20 21:37:20 UTC",
      "updated_date": "2025-02-20 21:37:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:14:26.253628"
    },
    {
      "arxiv_id": "2502.18499v1",
      "title": "Mechanistic Understanding of Language Models in Syntactic Code Completion",
      "title_zh": "翻译失败",
      "authors": [
        "Samuel Miller",
        "Daking Rai",
        "Ziyu Yao"
      ],
      "abstract": "Recently, language models (LMs) have shown impressive proficiency in code\ngeneration tasks, especially when fine-tuned on code-specific datasets,\ncommonly known as Code LMs. However, our understanding of the internal\ndecision-making processes of Code LMs, such as how they use their (syntactic or\nsemantic) knowledge, remains limited, which could lead to unintended harm as\nthey are increasingly used in real life. This motivates us to conduct one of\nthe first Mechanistic Interpretability works to understand how Code LMs perform\na syntactic completion task, specifically the closing parenthesis task, on the\nCodeLlama-7b model (Roziere et al. 2023). Our findings reveal that the model\nrequires middle-later layers until it can confidently predict the correct label\nfor the closing parenthesis task. Additionally, we identify that while both\nmulti-head attention (MHA) and feed-forward (FF) sub-layers play essential\nroles, MHA is particularly crucial. Furthermore, we also discover attention\nheads that keep track of the number of already closed parentheses precisely but\nmay or may not promote a correct number of closing parentheses that are still\nmissing, leading to a positive or negative impact on the model's performance.",
      "tldr_zh": "本研究通过 Mechanistic Interpretability 方法，深入分析了语言模型（LMs）在语法代码完成任务中的内部决策过程，特别是针对 CodeLlama-7b 模型的闭合括号任务，以揭示 Code LMs 如何利用语法和语义知识。结果显示，模型需要在中间到后层才能自信地预测正确标签，且 Multi-Head Attention (MHA) 子层比 Feed-Forward (FF) 子层更关键。研究还发现，某些注意力头能精确跟踪已闭合括号的数量，但这些头可能正向或负向影响模型的性能，从而为理解和减轻 Code LMs 在实际应用中的潜在风险提供了重要洞见。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL",
        "I.2.7"
      ],
      "primary_category": "cs.SE",
      "comment": "10 pages, 4 figures, accepted to the AAAI 2025 Workshop on Towards\n  Knowledgeable Foundation Models",
      "pdf_url": "http://arxiv.org/pdf/2502.18499v1",
      "published_date": "2025-02-20 21:35:20 UTC",
      "updated_date": "2025-02-20 21:35:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:14:39.553501"
    },
    {
      "arxiv_id": "2502.15056v1",
      "title": "Fundamental Survey on Neuromorphic Based Audio Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Amlan Basu",
        "Pranav Chaudhari",
        "Gaetano Di Caterina"
      ],
      "abstract": "Audio classification is paramount in a variety of applications including\nsurveillance, healthcare monitoring, and environmental analysis. Traditional\nmethods frequently depend on intricate signal processing algorithms and\nmanually crafted features, which may fall short in fully capturing the\ncomplexities of audio patterns. Neuromorphic computing, inspired by the\narchitecture and functioning of the human brain, presents a promising\nalternative for audio classification tasks. This survey provides an exhaustive\nexamination of the current state-of-the-art in neuromorphic-based audio\nclassification. It delves into the crucial components of neuromorphic systems,\nsuch as Spiking Neural Networks (SNNs), memristors, and neuromorphic hardware\nplatforms, highlighting their advantages in audio classification. Furthermore,\nthe survey explores various methodologies and strategies employed in\nneuromorphic audio classification, including event-based processing,\nspike-based learning, and bio-inspired feature extraction. It examines how\nthese approaches address the limitations of traditional audio classification\nmethods, particularly in terms of energy efficiency, real-time processing, and\nrobustness to environmental noise. Additionally, the paper conducts a\ncomparative analysis of different neuromorphic audio classification models and\nbenchmarks, evaluating their performance metrics, computational efficiency, and\nscalability. By providing a comprehensive guide for researchers, engineers and\npractitioners, this survey aims to stimulate further innovation and\nadvancements in the evolving field of neuromorphic audio classification.",
      "tldr_zh": "这篇论文对基于神经形态计算的音频分类进行了基础性调查，强调其在监控、健康监测和环境分析等应用中的潜力。论文分析了传统音频分类方法的局限性，如依赖复杂信号处理和手动特征提取，并介绍了神经形态系统的主要组件，包括Spiking Neural Networks (SNNs)、memristors和神经形态硬件平台，这些组件在能量效率、实时处理和抗环境噪声方面表现出优势。研究探讨了各种方法，如event-based processing、spike-based learning和bio-inspired feature extraction，以克服传统方法的不足。最终，通过比较不同模型的性能指标、计算效率和可扩展性，该调查为研究人员、工程师和从业者提供全面指导，推动神经形态音频分类领域的创新发展。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "24 Pages, 1 Table",
      "pdf_url": "http://arxiv.org/pdf/2502.15056v1",
      "published_date": "2025-02-20 21:34:32 UTC",
      "updated_date": "2025-02-20 21:34:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:14:50.272029"
    },
    {
      "arxiv_id": "2502.15845v1",
      "title": "Verify when Uncertain: Beyond Self-Consistency in Black Box Hallucination Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Yihao Xue",
        "Kristjan Greenewald",
        "Youssef Mroueh",
        "Baharan Mirzasoleiman"
      ],
      "abstract": "Large Language Models (LLMs) suffer from hallucination problems, which hinder\ntheir reliability in sensitive applications. In the black-box setting, several\nself-consistency-based techniques have been proposed for hallucination\ndetection. We empirically study these techniques and show that they achieve\nperformance close to that of a supervised (still black-box) oracle, suggesting\nlittle room for improvement within this paradigm. To address this limitation,\nwe explore cross-model consistency checking between the target model and an\nadditional verifier LLM. With this extra information, we observe improved\noracle performance compared to purely self-consistency-based methods. We then\npropose a budget-friendly, two-stage detection algorithm that calls the\nverifier model only for a subset of cases. It dynamically switches between\nself-consistency and cross-consistency based on an uncertainty interval of the\nself-consistency classifier. We provide a geometric interpretation of\nconsistency-based hallucination detection methods through the lens of kernel\nmean embeddings, offering deeper theoretical insights. Extensive experiments\nshow that this approach maintains high detection performance while\nsignificantly reducing computational cost.",
      "tldr_zh": "本研究探讨了大语言模型(LLMs)中的幻觉问题，指出现有基于自一致性的黑箱检测方法已接近性能上限。论文提出一种改进策略，通过引入跨模型一致性检查（利用额外验证器LLM），并设计了预算友好的两阶段检测算法，该算法仅在自一致性分类器的不确定性区间内调用验证器，从而动态切换检测方式。实验结果显示，该方法显著降低了计算成本，同时维持了高检测性能，并通过核均值嵌入的几何解释提供了理论洞见。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.15845v1",
      "published_date": "2025-02-20 21:06:08 UTC",
      "updated_date": "2025-02-20 21:06:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:15:02.596312"
    },
    {
      "arxiv_id": "2502.15040v1",
      "title": "Reducing Hallucinations of Medical Multimodal Large Language Models with Visual Retrieval-Augmented Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Yun-Wei Chu",
        "Kai Zhang",
        "Christopher Malon",
        "Martin Renqiang Min"
      ],
      "abstract": "Multimodal Large Language Models (MLLMs) have shown impressive performance in\nvision and text tasks. However, hallucination remains a major challenge,\nespecially in fields like healthcare where details are critical. In this work,\nwe show how MLLMs may be enhanced to support Visual RAG (V-RAG), a\nretrieval-augmented generation framework that incorporates both text and visual\ndata from retrieved images. On the MIMIC-CXR chest X-ray report generation and\nMulticare medical image caption generation datasets, we show that Visual RAG\nimproves the accuracy of entity probing, which asks whether a medical entities\nis grounded by an image. We show that the improvements extend both to frequent\nand rare entities, the latter of which may have less positive training data.\nDownstream, we apply V-RAG with entity probing to correct hallucinations and\ngenerate more clinically accurate X-ray reports, obtaining a higher RadGraph-F1\nscore.",
      "tldr_zh": "这篇论文针对医疗 Multimodal Large Language Models (MLLMs) 的幻觉问题，提出 Visual RAG (V-RAG) 框架，该框架通过检索并整合文本和视觉数据来增强生成过程。实验在 MIMIC-CXR 胸部 X 光报告生成和 Multicare 医疗图像描述数据集上显示，V-RAG 显著提高了实体探测的准确性，尤其适用于频繁和稀有实体。最终，通过结合实体探测，V-RAG 能纠正幻觉并生成更临床准确的 X 光报告，提升了 RadGraph-F1 分数。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "GenAI4Health - AAAI '25",
      "pdf_url": "http://arxiv.org/pdf/2502.15040v1",
      "published_date": "2025-02-20 20:55:34 UTC",
      "updated_date": "2025-02-20 20:55:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:15:14.688491"
    },
    {
      "arxiv_id": "2502.15037v5",
      "title": "DEFT: Differentiable Branched Discrete Elastic Rods for Modeling Furcated DLOs in Real-Time",
      "title_zh": "翻译失败",
      "authors": [
        "Yizhou Chen",
        "Xiaoyue Wu",
        "Yeheng Zong",
        "Yuzhen Chen",
        "Anran Li",
        "Bohao Zhang",
        "Ram Vasudevan"
      ],
      "abstract": "Autonomous wire harness assembly requires robots to manipulate complex\nbranched cables with high precision and reliability. A key challenge in\nautomating this process is predicting how these flexible and branched\nstructures behave under manipulation. Without accurate predictions, it is\ndifficult for robots to reliably plan or execute assembly operations. While\nexisting research has made progress in modeling single-threaded Deformable\nLinear Objects (DLOs), extending these approaches to Branched Deformable Linear\nObjects (BDLOs) presents fundamental challenges. The junction points in BDLOs\ncreate complex force interactions and strain propagation patterns that cannot\nbe adequately captured by simply connecting multiple single-DLO models. To\naddress these challenges, this paper presents Differentiable discrete branched\nElastic rods for modeling Furcated DLOs in real-Time (DEFT), a novel framework\nthat combines a differentiable physics-based model with a learning framework\nto: 1) accurately model BDLO dynamics, including dynamic propagation at\njunction points and grasping in the middle of a BDLO, 2) achieve efficient\ncomputation for real-time inference, and 3) enable planning to demonstrate\ndexterous BDLO manipulation. A comprehensive series of real-world experiments\ndemonstrates DEFT's efficacy in terms of accuracy, computational speed, and\ngeneralizability compared to state-of-the-art alternatives. Project\npage:https://roahmlab.github.io/DEFT/.",
      "tldr_zh": "这篇论文提出了 DEFT 框架，即 Differentiable Branched Discrete Elastic Rods，用于实时建模分支可变形线性物体 (BDLOs)，以解决机器人自主线束组装中预测复杂分支结构动态行为的挑战。DEFT 结合可微分物理模型和学习框架，能够准确模拟 BDLOs 的动态传播、连接点处的力交互以及中间抓取，同时实现高效计算以支持实时推理和规划。实验结果显示，DEFT 在真实世界测试中比现有方法在准确性、计算速度和泛化性上表现出显著优势，为机器人灵巧操作 BDLOs 提供了可靠工具。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.GR"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.15037v5",
      "published_date": "2025-02-20 20:46:09 UTC",
      "updated_date": "2025-05-06 15:36:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:15:27.450962"
    },
    {
      "arxiv_id": "2502.15027v2",
      "title": "InterFeedback: Unveiling Interactive Intelligence of Large Multimodal Models via Human Feedback",
      "title_zh": "InterFeedback：通过人类反馈揭示大型多模态模型的交互智能",
      "authors": [
        "Henry Hengyuan Zhao",
        "Wenqi Pei",
        "Yifei Tao",
        "Haiyang Mei",
        "Mike Zheng Shou"
      ],
      "abstract": "Existing benchmarks do not test Large Multimodal Models (LMMs) on their\ninteractive intelligence with human users, which is vital for developing\ngeneral-purpose AI assistants. We design InterFeedback, an interactive\nframework, which can be applied to any LMM and dataset to assess this ability\nautonomously. On top of this, we introduce InterFeedback-Bench which evaluates\ninteractive intelligence using two representative datasets, MMMU-Pro and\nMathVerse, to test 10 different open-source LMMs. Additionally, we present\nInterFeedback-Human, a newly collected dataset of 120 cases designed for\nmanually testing interactive performance in leading models such as OpenAI-o1\nand Claude-3.5-Sonnet. Our evaluation results indicate that even the\nstate-of-the-art LMM, OpenAI-o1, struggles to refine its responses based on\nhuman feedback, achieving an average score of less than 50%. Our findings point\nto the need for methods that can enhance LMMs' capabilities to interpret and\nbenefit from feedback.",
      "tldr_zh": "这篇论文引入了InterFeedback框架，用于评估Large Multimodal Models (LMMs)的交互智能，该框架可应用于任何LMM和数据集，以自主测试模型基于人类反馈的响应能力。论文还提出了InterFeedback-Bench，使用MMMU-Pro和MathVerse数据集评估10个开源LMMs，以及InterFeedback-Human数据集，包含120个新案例用于手动测试领先模型如OpenAI-o1和Claude-3.5-Sonnet。实验结果显示，即使是先进的OpenAI-o1模型，其响应改进能力平均得分不到50%，强调了需要开发方法来增强LMMs解释和利用反馈的功能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "18 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.15027v2",
      "published_date": "2025-02-20 20:27:06 UTC",
      "updated_date": "2025-03-09 01:07:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:15:38.964817"
    },
    {
      "arxiv_id": "2502.15013v3",
      "title": "Towards Physics-Guided Foundation Models",
      "title_zh": "翻译失败",
      "authors": [
        "Majid Farhadloo",
        "Arun Sharma",
        "Mingzhou Yang",
        "Bharat Jayaprakash",
        "William Northrop",
        "Shashi Shekhar"
      ],
      "abstract": "Traditional foundation models are pre-trained on broad datasets to reduce the\ntraining resources (e.g., time, energy, labeled samples) needed for fine-tuning\na wide range of downstream tasks. However, traditional foundation models\nstruggle with out-of-distribution prediction and can produce outputs that are\nunrealistic and physically infeasible. We propose the notation of\nphysics-guided foundation models (PGFM), that is, foundation models integrated\nwith broad or general domain (e.g., scientific) physical knowledge applicable\nto a wide range of downstream tasks.",
      "tldr_zh": "传统 foundation models 通过在广泛数据集上预训练来减少下游任务的训练资源（如时间、能量和标注样本），但它们在 out-of-distribution prediction 上表现不佳，并可能产生不现实或物理上不可行的输出。我们提出 physics-guided foundation models (PGFM) 的概念，即将广域或一般领域的物理知识整合到 foundation models 中，以适用于各种下游任务。这种方法旨在提升模型的鲁棒性和输出可靠性，为科学领域应用提供更坚实的基础。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.15013v3",
      "published_date": "2025-02-20 20:10:22 UTC",
      "updated_date": "2025-04-23 16:58:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:15:50.190136"
    },
    {
      "arxiv_id": "2502.15012v1",
      "title": "Graph in the Vault: Protecting Edge GNN Inference with Trusted Execution Environment",
      "title_zh": "翻译失败",
      "authors": [
        "Ruyi Ding",
        "Tianhong Xu",
        "Aidong Adam Ding",
        "Yunsi Fei"
      ],
      "abstract": "Wide deployment of machine learning models on edge devices has rendered the\nmodel intellectual property (IP) and data privacy vulnerable. We propose\nGNNVault, the first secure Graph Neural Network (GNN) deployment strategy based\non Trusted Execution Environment (TEE). GNNVault follows the design of\n'partition-before-training' and includes a private GNN rectifier to complement\nwith a public backbone model. This way, both critical GNN model parameters and\nthe private graph used during inference are protected within secure TEE\ncompartments. Real-world implementations with Intel SGX demonstrate that\nGNNVault safeguards GNN inference against state-of-the-art link stealing\nattacks with negligible accuracy degradation (<2%).",
      "tldr_zh": "该论文提出 GNNVault，一种基于 Trusted Execution Environment (TEE) 的安全部署策略，用于保护 Graph Neural Network (GNN) 在边缘设备上的推理过程，解决模型知识产权 (IP) 和数据隐私的漏洞问题。GNNVault 采用 'partition-before-training' 设计，结合私有 GNN rectifier 与公共主干模型，将关键 GNN 模型参数和私有图隔离在安全的 TEE 隔离环境中。实验结果显示，使用 Intel SGX 的实际实现，GNNVault 能有效抵御最先进的链接窃取攻击，同时准确率下降微不足道（<2%）。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "This work is accepted by DAC 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.15012v1",
      "published_date": "2025-02-20 20:09:14 UTC",
      "updated_date": "2025-02-20 20:09:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:16:02.061207"
    },
    {
      "arxiv_id": "2502.15010v1",
      "title": "Obliviate: Efficient Unmemorization for Protecting Intellectual Property in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Mark Russinovich",
        "Ahmed Salem"
      ],
      "abstract": "Recent copyright agreements between AI companies and content creators have\nhighlighted the need for precise control over language models' ability to\nreproduce copyrighted content. While existing approaches rely on either\ncomplete concept removal through unlearning or simple output filtering, we\npropose Obliviate, a novel post-training technique that selectively prevents\nverbatim reproduction of specific text while preserving semantic understanding.\n  Obliviate operates by selecting tokens within memorized sequences and\nmodifying the model's probability distribution to prevent exact reproduction\nwhile maintaining contextual understanding. We evaluate Obliviate on multiple\nlarge language models (LLaMA-3.1 8B, LLaMA-3.1-instruct 8B, Qwen-2.5-7B, and\nYi-1.5 6B) across both synthetic memorization tasks and organic copyright\ncontent. Our results demonstrate that Obliviate achieves orders of magnitude\nreduction, e.g., 100x, in verbatim memorization while maintaining model\nperformance within 1% of baseline on standard benchmarks (HellaSwag, MMLU,\nTruthfulQA, and Winogrande). This makes Obliviate particularly suitable for\npractical deployment scenarios where companies need to efficiently address\ncopyright concerns in pretrained models without compromising their general\ncapabilities.",
      "tldr_zh": "本研究提出 Obliviate，一种高效的后训练技术，用于保护大语言模型（LLMs）的知识产权，通过选择 memorized sequences 中的标记并修改模型的概率分布，防止逐字复制特定文本，同时保留语义理解。相比现有方法如 unlearning 或输出过滤，Obliviate 在 LLaMA-3.1 8B 等多个模型上测试中，实现了逐字记忆减少数百倍（如 100 倍），并在标准基准测试（HellaSwag、MMLU、TruthfulQA 和 Winogrande）上保持性能仅下降 1%。这种方法特别适合实际部署场景，帮助公司高效处理版权问题而不影响模型的整体能力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.15010v1",
      "published_date": "2025-02-20 20:02:56 UTC",
      "updated_date": "2025-02-20 20:02:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:16:14.929196"
    },
    {
      "arxiv_id": "2502.15007v1",
      "title": "LLM-Microscope: Uncovering the Hidden Role of Punctuation in Context Memory of Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Anton Razzhigaev",
        "Matvey Mikhalchuk",
        "Temurbek Rahmatullaev",
        "Elizaveta Goncharova",
        "Polina Druzhinina",
        "Ivan Oseledets",
        "Andrey Kuznetsov"
      ],
      "abstract": "We introduce methods to quantify how Large Language Models (LLMs) encode and\nstore contextual information, revealing that tokens often seen as minor (e.g.,\ndeterminers, punctuation) carry surprisingly high context. Notably, removing\nthese tokens -- especially stopwords, articles, and commas -- consistently\ndegrades performance on MMLU and BABILong-4k, even if removing only irrelevant\ntokens. Our analysis also shows a strong correlation between contextualization\nand linearity, where linearity measures how closely the transformation from one\nlayer's embeddings to the next can be approximated by a single linear mapping.\nThese findings underscore the hidden importance of filler tokens in maintaining\ncontext. For further exploration, we present LLM-Microscope, an open-source\ntoolkit that assesses token-level nonlinearity, evaluates contextual memory,\nvisualizes intermediate layer contributions (via an adapted Logit Lens), and\nmeasures the intrinsic dimensionality of representations. This toolkit\nilluminates how seemingly trivial tokens can be critical for long-range\nunderstanding.",
      "tldr_zh": "本研究揭示了大型语言模型（LLMs）中，标点符号和停用词等看似次要标记在上下文记忆中的隐藏重要作用，通过量化方法发现移除这些标记（如文章和逗号）会导致模型在MMLU和BABILong-4k基准上的性能显著下降。分析显示，上下文编码与线性性（即层间嵌入变换的线性近似）之间存在强相关性，强调了这些“填充标记”在维护长距离理解的关键作用。为进一步探索，该研究推出了开源工具LLM-Microscope，可评估标记级非线性、上下文记忆、通过适应后的Logit Lens可视化中间层贡献，并测量表示的内在维度，从而加深对LLMs内部机制的理解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "accepted to NAACL 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.15007v1",
      "published_date": "2025-02-20 19:59:35 UTC",
      "updated_date": "2025-02-20 19:59:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:16:26.109802"
    },
    {
      "arxiv_id": "2502.15006v1",
      "title": "Safe Beyond the Horizon: Efficient Sampling-based MPC with Neural Control Barrier Functions",
      "title_zh": "翻译失败",
      "authors": [
        "Ji Yin",
        "Oswin So",
        "Eric Yang Yu",
        "Chuchu Fan",
        "Panagiotis Tsiotras"
      ],
      "abstract": "A common problem when using model predictive control (MPC) in practice is the\nsatisfaction of safety specifications beyond the prediction horizon. While\ntheoretical works have shown that safety can be guaranteed by enforcing a\nsuitable terminal set constraint or a sufficiently long prediction horizon,\nthese techniques are difficult to apply and thus are rarely used by\npractitioners, especially in the case of general nonlinear dynamics. To solve\nthis problem, we impose a tradeoff between exact recursive feasibility,\ncomputational tractability, and applicability to ''black-box'' dynamics by\nlearning an approximate discrete-time control barrier function and\nincorporating it into a variational inference MPC (VIMPC), a sampling-based MPC\nparadigm. To handle the resulting state constraints, we further propose a new\nsampling strategy that greatly reduces the variance of the estimated optimal\ncontrol, improving the sample efficiency, and enabling real-time planning on a\nCPU. The resulting Neural Shield-VIMPC (NS-VIMPC) controller yields substantial\nsafety improvements compared to existing sampling-based MPC controllers, even\nunder badly designed cost functions. We validate our approach in both\nsimulation and real-world hardware experiments.",
      "tldr_zh": "该论文解决了模型预测控制（MPC）在实际应用中难以保证预测范围外安全性的问题，通过学习一个近似的离散时间控制屏障函数（control barrier function）并将其整合到基于采样的变分推理 MPC（VIMPC）框架中。研究提出了一种新的采样策略，以减少估计最优控制的方差，提高样本效率，并实现 CPU 上的实时规划。实验结果显示，开发的 Neural Shield-VIMPC（NS-VIMPC）控制器在模拟和真实硬件环境中显著提升了安全性，即使在成本函数设计不佳的情况下，也比现有方法表现出色。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.15006v1",
      "published_date": "2025-02-20 19:59:11 UTC",
      "updated_date": "2025-02-20 19:59:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:16:37.915958"
    },
    {
      "arxiv_id": "2502.15005v1",
      "title": "A Socratic RAG Approach to Connect Natural Language Queries on Research Topics with Knowledge Organization Systems",
      "title_zh": "一种苏格拉底 RAG 方法",
      "authors": [
        "Lew Lefton",
        "Kexin Rong",
        "Chinar Dankhara",
        "Lila Ghemri",
        "Firdous Kausar",
        "A. Hannibal Hamdallahi"
      ],
      "abstract": "In this paper, we propose a Retrieval Augmented Generation (RAG) agent that\nmaps natural language queries about research topics to precise,\nmachine-interpretable semantic entities. Our approach combines RAG with\nSocratic dialogue to align a user's intuitive understanding of research topics\nwith established Knowledge Organization Systems (KOSs). The proposed approach\nwill effectively bridge \"little semantics\" (domain-specific KOS structures)\nwith \"big semantics\" (broad bibliometric repositories), making complex academic\ntaxonomies more accessible. Such agents have the potential for broad use. We\nillustrate with a sample application called CollabNext, which is a\nperson-centric knowledge graph connecting people, organizations, and research\ntopics. We further describe how the application design has an intentional focus\non HBCUs and emerging researchers to raise visibility of people historically\nrendered invisible in the current science system.",
      "tldr_zh": "本研究提出了一种结合 Retrieval Augmented Generation (RAG) 和 Socratic 对话的代理方法，用于将自然语言查询映射到精确的语义实体，从而连接用户对研究主题的直观理解与 Knowledge Organization Systems (KOSs)。该方法桥接“小语义”（领域特定 KOS 结构）和“大语义”（广泛的书目存储库），使复杂学术分类更易访问，并扩展其潜在应用。作者以 CollabNext 为例，展示了一个以人为中心的知识图谱应用，特别关注 HBCUs 和新兴研究者，以提升他们在科学系统中的可见性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC",
        "I.2.7; F.4.1"
      ],
      "primary_category": "cs.CL",
      "comment": "6 pages, 2 figures, AAAI 2025 Workshop on A Translational Institute\n  for Knowledge Axiomatization",
      "pdf_url": "http://arxiv.org/pdf/2502.15005v1",
      "published_date": "2025-02-20 19:58:59 UTC",
      "updated_date": "2025-02-20 19:58:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:16:49.566014"
    },
    {
      "arxiv_id": "2502.14996v1",
      "title": "A Rapid Test for Accuracy and Bias of Face Recognition Technology",
      "title_zh": "翻译失败",
      "authors": [
        "Manuel Knott",
        "Ignacio Serna",
        "Ethan Mann",
        "Pietro Perona"
      ],
      "abstract": "Measuring the accuracy of face recognition (FR) systems is essential for\nimproving performance and ensuring responsible use. Accuracy is typically\nestimated using large annotated datasets, which are costly and difficult to\nobtain. We propose a novel method for 1:1 face verification that benchmarks FR\nsystems quickly and without manual annotation, starting from approximate labels\n(e.g., from web search results). Unlike previous methods for training set label\ncleaning, ours leverages the embedding representation of the models being\nevaluated, achieving high accuracy in smaller-sized test datasets. Our approach\nreliably estimates FR accuracy and ranking, significantly reducing the time and\ncost of manual labeling. We also introduce the first public benchmark of five\nFR cloud services, revealing demographic biases, particularly lower accuracy\nfor Asian women. Our rapid test method can democratize FR testing, promoting\nscrutiny and responsible use of the technology. Our method is provided as a\npublicly accessible tool at https://github.com/caltechvisionlab/frt-rapid-test",
      "tldr_zh": "本研究提出了一种快速测试方法，用于评估人脸识别 (FR) 系统的准确性和偏差，该方法基于模型的 embedding representation，从近似标签（如网络搜索结果）开始进行1:1人脸验证，无需手动标注，从而在较小数据集上实现高准确率。相比传统方法，该方法显著减少了测试时间和成本，并能可靠地估计FR系统的性能排名。实验结果显示，五个FR云服务的公开基准测试揭示了人口统计学偏差，特别是对Asian women的准确率较低。该工具已作为开源项目发布（https://github.com/caltechvisionlab/frt-rapid-test），有助于促进FR技术的审视和负责任应用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted as a conference paper for WACV 2025. Manuel Knott, Ignacio\n  Serna, and Ethan Mann contributed equally",
      "pdf_url": "http://arxiv.org/pdf/2502.14996v1",
      "published_date": "2025-02-20 19:38:52 UTC",
      "updated_date": "2025-02-20 19:38:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:17:02.334163"
    },
    {
      "arxiv_id": "2502.14975v1",
      "title": "Beyond No: Quantifying AI Over-Refusal and Emotional Attachment Boundaries",
      "title_zh": "超越 No：量化 AI 过度拒绝和情感依恋边界",
      "authors": [
        "David Noever",
        "Grant Rosario"
      ],
      "abstract": "We present an open-source benchmark and evaluation framework for assessing\nemotional boundary handling in Large Language Models (LLMs). Using a dataset of\n1156 prompts across six languages, we evaluated three leading LLMs (GPT-4o,\nClaude-3.5 Sonnet, and Mistral-large) on their ability to maintain appropriate\nemotional boundaries through pattern-matched response analysis. Our framework\nquantifies responses across seven key patterns: direct refusal, apology,\nexplanation, deflection, acknowledgment, boundary setting, and emotional\nawareness. Results demonstrate significant variation in boundary-handling\napproaches, with Claude-3.5 achieving the highest overall score (8.69/10) and\nproducing longer, more nuanced responses (86.51 words on average). We\nidentified a substantial performance gap between English (average score 25.62)\nand non-English interactions (< 0.22), with English responses showing markedly\nhigher refusal rates (43.20% vs. < 1% for non-English). Pattern analysis\nrevealed model-specific strategies, such as Mistral's preference for deflection\n(4.2%) and consistently low empathy scores across all models (< 0.06).\nLimitations include potential oversimplification through pattern matching, lack\nof contextual understanding in response analysis, and binary classification of\ncomplex emotional responses. Future work should explore more nuanced scoring\nmethods, expand language coverage, and investigate cultural variations in\nemotional boundary expectations. Our benchmark and methodology provide a\nfoundation for systematic evaluation of LLM emotional intelligence and\nboundary-setting capabilities.",
      "tldr_zh": "该论文提出一个开源基准和评估框架，用于量化大型语言模型（LLMs）在处理情感边界时的过度拒绝和表现差异。该框架基于1156个跨六种语言的提示，评估了GPT-4o、Claude-3.5 Sonnet和Mistral-large等模型在七个关键模式（包括直接拒绝、道歉、解释和情感意识）上的响应。结果显示Claude-3.5 Sonnet得分最高（8.69/10），英语交互的拒绝率显著高于非英语（43.20% vs. <1%），并揭示了模型特有的策略，如Mistral-large偏好转移。未来工作将改进评分方法、扩展语言覆盖并探讨文化差异，以提升LLMs的情感智能评估。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14975v1",
      "published_date": "2025-02-20 19:09:40 UTC",
      "updated_date": "2025-02-20 19:09:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:17:16.472868"
    },
    {
      "arxiv_id": "2502.14966v1",
      "title": "CyberSentinel: An Emergent Threat Detection System for AI Security",
      "title_zh": "翻译失败",
      "authors": [
        "Krti Tallam"
      ],
      "abstract": "The rapid advancement of artificial intelligence (AI) has significantly\nexpanded the attack surface for AI-driven cybersecurity threats, necessitating\nadaptive defense strategies. This paper introduces CyberSentinel, a unified,\nsingle-agent system for emergent threat detection, designed to identify and\nmitigate novel security risks in real time. CyberSentinel integrates: (1)\nBrute-force attack detection through SSH log analysis, (2) Phishing threat\nassessment using domain blacklists and heuristic URL scoring, and (3) Emergent\nthreat detection via machine learning-based anomaly detection. By continuously\nadapting to evolving adversarial tactics, CyberSentinel strengthens proactive\ncybersecurity defense, addressing critical vulnerabilities in AI security.",
      "tldr_zh": "本论文提出了 CyberSentinel，一种统一的单智能体系统，用于实时识别和缓解 AI Security 中的新兴威胁。该系统整合了 Brute-force attack 通过 SSH 日志分析的检测、Phishing 威胁的评估（利用域名黑名单和启发式 URL 评分），以及基于 machine learning 的异常检测。通过持续适应演变的攻击策略，CyberSentinel 增强了主动网络安全防御，解决了 AI 安全的关键漏洞。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14966v1",
      "published_date": "2025-02-20 19:03:32 UTC",
      "updated_date": "2025-02-20 19:03:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:17:25.957789"
    },
    {
      "arxiv_id": "2502.14866v2",
      "title": "LServe: Efficient Long-sequence LLM Serving with Unified Sparse Attention",
      "title_zh": "翻译失败",
      "authors": [
        "Shang Yang",
        "Junxian Guo",
        "Haotian Tang",
        "Qinghao Hu",
        "Guangxuan Xiao",
        "Jiaming Tang",
        "Yujun Lin",
        "Zhijian Liu",
        "Yao Lu",
        "Song Han"
      ],
      "abstract": "Large language models (LLMs) have shown remarkable potential in processing\nlong sequences and complex reasoning tasks, yet efficiently serving these\nmodels remains challenging due to the quadratic computational complexity of\nattention in the prefilling stage and the large memory footprint of the KV\ncache in the decoding stage. To address these issues, we introduce LServe, an\nefficient system that accelerates long-sequence LLM serving via hybrid sparse\nattention. This method unifies different hardware-friendly, structured sparsity\npatterns for both prefilling and decoding attention into a single framework,\nwhere computations on less important tokens are skipped block-wise. LServe\ndemonstrates the compatibility of static and dynamic sparsity in long-context\nLLM attention. This design enables multiplicative speedups by combining these\noptimizations. Specifically, we convert half of the attention heads to nearly\nfree streaming heads in both the prefilling and decoding stages. Additionally,\nwe find that only a constant number of KV pages is required to preserve\nlong-context and reasoning capabilities, irrespective of context length. We\nthen design a hierarchical KV page selection policy that dynamically prunes KV\npages based on query-centric similarity. On average, LServe accelerates LLM\nprefilling by up to 2.9x and decoding by 1.3-2.1x over vLLM, maintaining\nlong-context accuracy. Code is released at\nhttps://github.com/mit-han-lab/omniserve.",
      "tldr_zh": "该论文提出 LServe，一种高效的长序列大语言模型 (LLM) 服务系统，通过统一的稀疏 attention 方法解决 attention 的二次方计算复杂度和 KV cache 内存占用问题。该系统整合静态和动态稀疏模式，在预填充和解码阶段跳过不重要 token 的块级计算，并将一半 attention heads 转换为近乎免费的 streaming heads，同时设计分层 KV page 选择策略动态修剪 KV pages，仅需常量数量的 pages 即可保持长上下文能力。实验结果显示，LServe 相较于 vLLM 平均加速预填充 2.9 倍、解码 1.3-2.1 倍，同时维持长上下文准确性。代码已在 GitHub 开源。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DC",
        "cs.LG",
        "cs.PF"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by MLSys 2025. Code available at:\n  https://github.com/mit-han-lab/omniserve",
      "pdf_url": "http://arxiv.org/pdf/2502.14866v2",
      "published_date": "2025-02-20 18:59:52 UTC",
      "updated_date": "2025-04-21 15:13:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:17:38.596026"
    },
    {
      "arxiv_id": "2502.14864v1",
      "title": "Benchmarking Multimodal RAG through a Chart-based Document Question-Answering Generation Framework",
      "title_zh": "翻译失败",
      "authors": [
        "Yuming Yang",
        "Jiang Zhong",
        "Li Jin",
        "Jingwang Huang",
        "Jingpeng Gao",
        "Qing Liu",
        "Yang Bai",
        "Jingyuan Zhang",
        "Rui Jiang",
        "Kaiwen Wei"
      ],
      "abstract": "Multimodal Retrieval-Augmented Generation (MRAG) enhances reasoning\ncapabilities by integrating external knowledge. However, existing benchmarks\nprimarily focus on simple image-text interactions, overlooking complex visual\nformats like charts that are prevalent in real-world applications. In this\nwork, we introduce a novel task, Chart-based MRAG, to address this limitation.\nTo semi-automatically generate high-quality evaluation samples, we propose\nCHARt-based document question-answering GEneration (CHARGE), a framework that\nproduces evaluation data through structured keypoint extraction, crossmodal\nverification, and keypoint-based generation. By combining CHARGE with expert\nvalidation, we construct Chart-MRAG Bench, a comprehensive benchmark for\nchart-based MRAG evaluation, featuring 4,738 question-answering pairs across 8\ndomains from real-world documents. Our evaluation reveals three critical\nlimitations in current approaches: (1) unified multimodal embedding retrieval\nmethods struggles in chart-based scenarios, (2) even with ground-truth\nretrieval, state-of-the-art MLLMs achieve only 58.19% Correctness and 73.87%\nCoverage scores, and (3) MLLMs demonstrate consistent text-over-visual modality\nbias during Chart-based MRAG reasoning. The CHARGE and Chart-MRAG Bench are\nreleased at https://github.com/Nomothings/CHARGE.git.",
      "tldr_zh": "该研究针对多模态检索增强生成(Multimodal RAG)存在的基准问题，提出Chart-based MRAG新任务，以处理真实应用中常见的复杂图表格式。作者开发了CHARGE框架，通过结构化关键点提取、跨模态验证和基于关键点的生成，半自动创建高质量评估数据，并结合专家验证构建了Chart-MRAG Bench基准，涵盖8个领域共4,738个问答对。实验结果揭示了当前方法的三大限制：统一的多模态嵌入检索在图表场景中表现不佳、最先进的多模态大语言模型(MLLMs)即使有ground-truth检索也仅达到58.19%正确性和73.87%覆盖率，以及MLLMs在推理中存在持续的文本优先于视觉模态偏差。",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14864v1",
      "published_date": "2025-02-20 18:59:42 UTC",
      "updated_date": "2025-02-20 18:59:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:17:50.923730"
    },
    {
      "arxiv_id": "2502.14862v1",
      "title": "Interpretable Text Embeddings and Text Similarity Explanation: A Primer",
      "title_zh": "可解释文本嵌入和文本相似度解释：入门指南",
      "authors": [
        "Juri Opitz",
        "Lucas Möller",
        "Andrianos Michail",
        "Simon Clematide"
      ],
      "abstract": "Text embeddings and text embedding models are a backbone of many AI and NLP\nsystems, particularly those involving search. However, interpretability\nchallenges persist, especially in explaining obtained similarity scores, which\nis crucial for applications requiring transparency. In this paper, we give a\nstructured overview of interpretability methods specializing in explaining\nthose similarity scores, an emerging research area. We study the methods'\nindividual ideas and techniques, evaluating their potential for improving\ninterpretability of text embeddings and explaining predicted similarities.",
      "tldr_zh": "这篇论文作为入门指南（Primer），系统概述了可解释文本嵌入（Interpretable Text Embeddings）和文本相似性解释（Text Similarity Explanation）的方法，旨在解决AI和NLP系统中相似性分数解释的透明性挑战。论文分析了这些方法的具体想法和技巧，并评估其潜力在提升文本嵌入的可解释性方面。最终，研究表明这些方法有助于更好地解释预测的相似性分数，推动应用中的透明度提升。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14862v1",
      "published_date": "2025-02-20 18:59:34 UTC",
      "updated_date": "2025-02-20 18:59:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:18:01.381763"
    },
    {
      "arxiv_id": "2502.14856v2",
      "title": "FR-Spec: Accelerating Large-Vocabulary Language Models via Frequency-Ranked Speculative Sampling",
      "title_zh": "FR-Spec：通过基于频率排序的推测采样加速大词汇表语言模型",
      "authors": [
        "Weilin Zhao",
        "Tengyu Pan",
        "Xu Han",
        "Yudi Zhang",
        "Ao Sun",
        "Yuxiang Huang",
        "Kaihuo Zhang",
        "Weilun Zhao",
        "Yuxuan Li",
        "Jianyong Wang",
        "Zhiyuan Liu",
        "Maosong Sun"
      ],
      "abstract": "Speculative sampling has emerged as an important technique for accelerating\nthe auto-regressive generation process of large language models (LLMs) by\nutilizing a draft-then-verify mechanism to produce multiple tokens per forward\npass. While state-of-the-art speculative sampling methods use only a single\nlayer and a language modeling (LM) head as the draft model to achieve\nimpressive layer compression, their efficiency gains are substantially reduced\nfor large-vocabulary LLMs, such as Llama-3-8B with a vocabulary of 128k tokens.\nTo address this, we present FR-Spec, a frequency-ranked speculative sampling\nframework that optimizes draft candidate selection through vocabulary space\ncompression. By constraining the draft search to a frequency-prioritized token\nsubset, our method reduces LM Head computation overhead by 75% while ensuring\nthe equivalence of the final output distribution. Experiments across multiple\ndatasets demonstrate an average of 1.12$\\times$ speedup over the\nstate-of-the-art speculative sampling method EAGLE-2. Code available at\nhttps://github.com/thunlp/FR-Spec.",
      "tldr_zh": "该论文提出 FR-Spec，一种基于频率排名的推测采样框架，用于加速大词汇表语言模型 (LLMs) 的生成过程。FR-Spec 通过将 draft 候选选择限制在频率优先的 token 子集，从而压缩词汇空间，并减少 LM Head 计算开销 75%，同时保持输出分布不变。与现有方法相比，该框架在多个数据集上比最先进技术 EAGLE-2 平均实现 1.12 倍的加速。实验结果证明了 FR-Spec 在处理如 Llama-3-8B 等模型时的显著效率提升。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14856v2",
      "published_date": "2025-02-20 18:58:10 UTC",
      "updated_date": "2025-03-11 08:54:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:18:14.104403"
    },
    {
      "arxiv_id": "2502.19437v1",
      "title": "Evolutionary Algorithms Approach For Search Based On Semantic Document Similarity",
      "title_zh": "基于语义文档相似度的进化算法搜索方法",
      "authors": [
        "Chandrashekar Muniyappa",
        "Eujin Kim"
      ],
      "abstract": "Advancements in cloud computing and distributed computing have fostered\nresearch activities in Computer science. As a result, researchers have made\nsignificant progress in Neural Networks, Evolutionary Computing Algorithms like\nGenetic, and Differential evolution algorithms. These algorithms are used to\ndevelop clustering, recommendation, and question-and-answering systems using\nvarious text representation and similarity measurement techniques. In this\nresearch paper, Universal Sentence Encoder (USE) is used to capture the\nsemantic similarity of text; And the transfer learning technique is used to\napply Genetic Algorithm (GA) and Differential Evolution (DE) algorithms to\nsearch and retrieve relevant top N documents based on user query. The proposed\napproach is applied to the Stanford Question and Answer (SQuAD) Dataset to\nidentify a user query. Finally, through experiments, we prove that text\ndocuments can be efficiently represented as sentence embedding vectors using\nUSE to capture the semantic similarity, and by comparing the results of the\nManhattan Distance, GA, and DE algorithms we prove that the evolutionary\nalgorithms are good at finding the top N results than the traditional ranking\napproach.",
      "tldr_zh": "这篇论文提出了一种基于进化算法的搜索方法，用于根据语义文档相似性检索相关文档，旨在提升文本搜索的准确性。研究利用 Universal Sentence Encoder (USE) 来捕捉文本的语义相似性，并通过迁移学习技术应用 Genetic Algorithm (GA) 和 Differential Evolution (DE) 算法来搜索和排序顶 N 相关文档，在 SQuAD Dataset 上进行测试。主要发现是，进化算法比传统的 Manhattan Distance 方法更高效，能够更好地识别用户查询的相关结果。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG",
        "68T50",
        "I.2.7; I.2.11"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.19437v1",
      "published_date": "2025-02-20 18:56:52 UTC",
      "updated_date": "2025-02-20 18:56:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:18:27.204010"
    },
    {
      "arxiv_id": "2502.14838v1",
      "title": "Revealing and Mitigating Over-Attention in Knowledge Editing",
      "title_zh": "揭示和缓解知识编辑中的",
      "authors": [
        "Pinzheng Wang",
        "Zecheng Tang",
        "Keyan Zhou",
        "Juntao Li",
        "Qiaoming Zhu",
        "Min Zhang"
      ],
      "abstract": "Large Language Models have demonstrated superior performance across a wide\nrange of tasks, but they still exhibit undesirable errors due to incorrect\nknowledge learned from the training data. To avoid this, knowledge editing\nmethods emerged to precisely edit the specific model knowledge via efficiently\nmodifying a very small percentage of parameters. % However, those methods can\nlead to the problem of Specificity Failure: when the content related to the\nedited knowledge occurs in the context, it can inadvertently corrupt other\npre-existing knowledge. However, those methods can lead to the problem of\nSpecificity Failure, where the existing knowledge and capabilities are severely\ndegraded due to editing. Our preliminary indicates that Specificity Failure\nprimarily stems from the model's attention heads assigning excessive attention\nscores to entities related to the edited knowledge, thereby unduly focusing on\nspecific snippets within the context, which we denote as the Attention Drift\nphenomenon. To mitigate such Attention Drift issue, we introduce a simple yet\neffective method Selective Attention Drift Restriction}(SADR), which introduces\nan additional regularization term during the knowledge editing process to\nrestrict changes in the attention weight distribution, thereby preventing undue\nfocus on the edited entity. Experiments on five frequently used strong LLMs\ndemonstrate the effectiveness of our method, where SADR can significantly\nmitigate Specificity Failure in the predominant knowledge editing tasks.",
      "tldr_zh": "本研究揭示了大型语言模型（LLMs）在知识编辑过程中存在的 Specificity Failure 问题，该问题源于 Attention Drift 现象，即模型的注意力头（attention heads）对编辑知识相关实体分配过高的注意力分数，导致其他预存知识被破坏。  \n为了缓解这一问题，作者提出了一种简单有效的 SADR（Selective Attention Drift Restriction）方法，通过在知识编辑过程中添加额外正则化项来限制注意力权重分布的变化，从而防止对编辑实体的过度关注。  \n实验在五个常用强 LLM 上进行，结果显示 SADR 显著降低了 Specificity Failure 的影响，提升了知识编辑任务的性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14838v1",
      "published_date": "2025-02-20 18:51:12 UTC",
      "updated_date": "2025-02-20 18:51:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:18:38.179217"
    },
    {
      "arxiv_id": "2502.14837v1",
      "title": "Towards Economical Inference: Enabling DeepSeek's Multi-Head Latent Attention in Any Transformer-based LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Tao Ji",
        "Bin Guo",
        "Yuanbin Wu",
        "Qipeng Guo",
        "Lixing Shen",
        "Zhan Chen",
        "Xipeng Qiu",
        "Qi Zhang",
        "Tao Gui"
      ],
      "abstract": "Multi-head Latent Attention (MLA) is an innovative architecture proposed by\nDeepSeek, designed to ensure efficient and economical inference by\nsignificantly compressing the Key-Value (KV) cache into a latent vector.\nCompared to MLA, standard LLMs employing Multi-Head Attention (MHA) and its\nvariants such as Grouped-Query Attention (GQA) exhibit significant cost\ndisadvantages. Enabling well-trained LLMs (e.g., Llama) to rapidly adapt to MLA\nwithout pre-training from scratch is both meaningful and challenging. This\npaper proposes the first data-efficient fine-tuning method for transitioning\nfrom MHA to MLA (MHA2MLA), which includes two key components: for partial-RoPE,\nwe remove RoPE from dimensions of queries and keys that contribute less to the\nattention scores, for low-rank approximation, we introduce joint SVD\napproximations based on the pre-trained parameters of keys and values. These\ncarefully designed strategies enable MHA2MLA to recover performance using only\na small fraction (0.3% to 0.6%) of the data, significantly reducing inference\ncosts while seamlessly integrating with compression techniques such as KV cache\nquantization. For example, the KV cache size of Llama2-7B is reduced by 92.19%,\nwith only a 0.5% drop in LongBench performance.",
      "tldr_zh": "该论文提出了一种数据高效的细化方法 MHA2MLA，用于将基于 Multi-Head Attention (MHA) 的 Transformer 模型快速适应 DeepSeek 的 Multi-Head Latent Attention (MLA)，从而实现高效的经济推理。方法包括针对 partial-RoPE 移除对注意力分数贡献较小的查询和键的 RoPE，以及通过联合 SVD 逼近来优化预训练的键和值参数。这些策略仅需 0.3% 到 0.6% 的数据即可恢复模型性能，并与 KV cache 量化技术无缝整合。实验结果显示，例如在 Llama2-7B 模型上，KV cache 大小减少了 92.19%，LongBench 性能仅下降 0.5%。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "16 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.14837v1",
      "published_date": "2025-02-20 18:50:42 UTC",
      "updated_date": "2025-02-20 18:50:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:18:51.266833"
    },
    {
      "arxiv_id": "2502.14834v1",
      "title": "LongWriter-V: Enabling Ultra-Long and High-Fidelity Generation in Vision-Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Shangqing Tu",
        "Yucheng Wang",
        "Daniel Zhang-Li",
        "Yushi Bai",
        "Jifan Yu",
        "Yuhao Wu",
        "Lei Hou",
        "Huiqin Liu",
        "Zhiyuan Liu",
        "Bin Xu",
        "Juanzi Li"
      ],
      "abstract": "Existing Large Vision-Language Models (LVLMs) can process inputs with context\nlengths up to 128k visual and text tokens, yet they struggle to generate\ncoherent outputs beyond 1,000 words. We find that the primary limitation is the\nabsence of long output examples during supervised fine-tuning (SFT). To tackle\nthis issue, we introduce LongWriter-V-22k, a SFT dataset comprising 22,158\nexamples, each with multiple input images, an instruction, and corresponding\noutputs ranging from 0 to 10,000 words. Moreover, to achieve long outputs that\nmaintain high-fidelity to the input images, we employ Direct Preference\nOptimization (DPO) to the SFT model. Given the high cost of collecting human\nfeedback for lengthy outputs (e.g., 3,000 words), we propose IterDPO, which\nbreaks long outputs into segments and uses iterative corrections to form\npreference pairs with the original outputs. Additionally, we develop\nMMLongBench-Write, a benchmark featuring six tasks to evaluate the\nlong-generation capabilities of VLMs. Our 7B parameter model, trained with\nLongWriter-V-22k and IterDPO, achieves impressive performance on this\nbenchmark, outperforming larger proprietary models like GPT-4o. Code and data:\nhttps://github.com/THU-KEG/LongWriter-V",
      "tldr_zh": "该论文解决了现有 Large Vision-Language Models (LVLMs) 在生成超过1,000词的连贯输出时的限制，主要归因于 Supervised Fine-Tuning (SFT) 中缺少长输出示例。研究者引入了 LongWriter-V-22k 数据集，包含22,158个示例，每个带有多个输入图像、指令和0至10,000词的输出，并通过 Direct Preference Optimization (DPO) 和新提出的 IterDPO 方法（将长输出分解为段落并迭代修正）来提升输出的高保真度。论文还开发了 MMLongBench-Write 基准，用于评估 VLMs 的长生成能力，其7B参数模型在该基准上表现出色，超越了更大的专有模型如 GPT-4o。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14834v1",
      "published_date": "2025-02-20 18:47:36 UTC",
      "updated_date": "2025-02-20 18:47:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:19:03.968343"
    },
    {
      "arxiv_id": "2502.14831v2",
      "title": "Improving the Diffusability of Autoencoders",
      "title_zh": "翻译失败",
      "authors": [
        "Ivan Skorokhodov",
        "Sharath Girish",
        "Benran Hu",
        "Willi Menapace",
        "Yanyu Li",
        "Rameen Abdal",
        "Sergey Tulyakov",
        "Aliaksandr Siarohin"
      ],
      "abstract": "Latent diffusion models have emerged as the leading approach for generating\nhigh-quality images and videos, utilizing compressed latent representations to\nreduce the computational burden of the diffusion process. While recent\nadvancements have primarily focused on scaling diffusion backbones and\nimproving autoencoder reconstruction quality, the interaction between these\ncomponents has received comparatively less attention. In this work, we perform\na spectral analysis of modern autoencoders and identify inordinate\nhigh-frequency components in their latent spaces, which are especially\npronounced in the autoencoders with a large bottleneck channel size. We\nhypothesize that this high-frequency component interferes with the\ncoarse-to-fine nature of the diffusion synthesis process and hinders the\ngeneration quality. To mitigate the issue, we propose scale equivariance: a\nsimple regularization strategy that aligns latent and RGB spaces across\nfrequencies by enforcing scale equivariance in the decoder. It requires minimal\ncode changes and only up to 20K autoencoder fine-tuning steps, yet\nsignificantly improves generation quality, reducing FID by 19% for image\ngeneration on ImageNet-1K 256x256 and FVD by at least 44% for video generation\non Kinetics-700 17x256x256.",
      "tldr_zh": "本研究针对潜在扩散模型（Latent diffusion models）中自编码器（autoencoders）的潜在空间问题，进行谱分析（spectral analysis），发现过多的高频组件会干扰扩散合成的粗到细过程，从而降低生成质量。作者提出了一种简单的规模等变性（scale equivariance）正则化策略，通过在解码器中强制频率对齐，仅需最少代码更改和最多20K的微调步骤，即可显著改善自编码器的扩散性。实验结果显示，该方法在ImageNet-1K 256x256图像生成上将FID降低了19%，在Kinetics-700 17x256x256视频生成上将FVD降低了至少44%。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "26 pages, 22 figures, 9 tables",
      "pdf_url": "http://arxiv.org/pdf/2502.14831v2",
      "published_date": "2025-02-20 18:45:44 UTC",
      "updated_date": "2025-03-12 22:08:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:19:16.063984"
    },
    {
      "arxiv_id": "2502.14830v1",
      "title": "Middle-Layer Representation Alignment for Cross-Lingual Transfer in Fine-Tuned LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Danni Liu",
        "Jan Niehues"
      ],
      "abstract": "While large language models demonstrate remarkable capabilities at\ntask-specific applications through fine-tuning, extending these benefits across\ndiverse languages is essential for broad accessibility. However, effective\ncross-lingual transfer is hindered by LLM performance gaps across languages and\nthe scarcity of fine-tuning data in many languages. Through analysis of LLM\ninternal representations from over 1,000+ language pairs, we discover that\nmiddle layers exhibit the strongest potential for cross-lingual alignment.\nBuilding on this finding, we propose a middle-layer alignment objective\nintegrated into task-specific training. Our experiments on slot filling,\nmachine translation, and structured text generation show consistent\nimprovements in cross-lingual transfer, especially to lower-resource languages.\nThe method is robust to the choice of alignment languages and generalizes to\nlanguages unseen during alignment. Furthermore, we show that separately trained\nalignment modules can be merged with existing task-specific modules, improving\ncross-lingual capabilities without full re-training. Our code is publicly\navailable (https://github.com/dannigt/mid-align).",
      "tldr_zh": "这项研究针对大型语言模型（LLMs）在微调后的跨语言转移（cross-lingual transfer）问题，分析了超过1000+语言对的内部表示，发现中间层（middle layers）具有最强的跨语言对齐潜力。作者提出了一种整合到任务特定训练中的中间层对齐目标（middle-layer alignment objective），以提升模型在槽填充（slot filling）、机器翻译（machine translation）和结构化文本生成（structured text generation）等任务上的跨语言性能，尤其对低资源语言效果显著。该方法对对齐语言的选择鲁棒，能够泛化到未见过的语言，并支持通过合并训练过的对齐模块来提升性能，而无需完全重新训练。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14830v1",
      "published_date": "2025-02-20 18:45:43 UTC",
      "updated_date": "2025-02-20 18:45:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:19:27.021525"
    },
    {
      "arxiv_id": "2502.14827v2",
      "title": "Exploring Advanced Techniques for Visual Question Answering: A Comprehensive Comparison",
      "title_zh": "翻译失败",
      "authors": [
        "Aiswarya Baby",
        "Tintu Thankom Koshy"
      ],
      "abstract": "Visual Question Answering (VQA) has emerged as a pivotal task in the\nintersection of computer vision and natural language processing, requiring\nmodels to understand and reason about visual content in response to natural\nlanguage questions. Analyzing VQA datasets is essential for developing robust\nmodels that can handle the complexities of multimodal reasoning. Several\napproaches have been developed to examine these datasets, each offering\ndistinct perspectives on question diversity, answer distribution, and\nvisual-textual correlations. Despite significant progress, existing VQA models\nface challenges related to dataset bias, limited model complexity, commonsense\nreasoning gaps, rigid evaluation methods, and generalization to real world\nscenarios. This paper offers a detailed study of the original VQA dataset,\nbaseline models and methods along with a comparative study of five advanced VQA\nmodels, ABC-CNN, KICNLE, Masked Vision and Language Modeling, BLIP-2, and OFA,\neach employing distinct methods to address these ongoing challenges.",
      "tldr_zh": "本研究探讨了视觉问答(VQA)任务，该任务涉及计算机视觉和自然语言处理的交叉，需要模型理解并推理视觉内容以回答自然语言问题。论文对VQA数据集进行详细分析，比较了基线模型和五种先进模型，包括ABC-CNN、KICNLE、Masked Vision and Language Modeling、BLIP-2和OFA，这些模型采用不同方法来解决数据集偏差、模型复杂性有限、常识推理差距、评估方法刚性和泛化挑战。研究结果为开发更鲁棒的多模态推理模型提供了宝贵见解和比较基准。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.ET",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "8 pages, No figures",
      "pdf_url": "http://arxiv.org/pdf/2502.14827v2",
      "published_date": "2025-02-20 18:45:00 UTC",
      "updated_date": "2025-03-04 16:43:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:19:39.512482"
    },
    {
      "arxiv_id": "2502.14820v1",
      "title": "eC-Tab2Text: Aspect-Based Text Generation from e-Commerce Product Tables",
      "title_zh": "翻译失败",
      "authors": [
        "Luis Antonio Gutiérrez Guanilo",
        "Mir Tafseer Nayeem",
        "Cristian López",
        "Davood Rafiei"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated exceptional versatility across\ndiverse domains, yet their application in e-commerce remains underexplored due\nto a lack of domain-specific datasets. To address this gap, we introduce\neC-Tab2Text, a novel dataset designed to capture the intricacies of e-commerce,\nincluding detailed product attributes and user-specific queries. Leveraging\neC-Tab2Text, we focus on text generation from product tables, enabling LLMs to\nproduce high-quality, attribute-specific product reviews from structured\ntabular data. Fine-tuned models were rigorously evaluated using standard\nTable2Text metrics, alongside correctness, faithfulness, and fluency\nassessments. Our results demonstrate substantial improvements in generating\ncontextually accurate reviews, highlighting the transformative potential of\ntailored datasets and fine-tuning methodologies in optimizing e-commerce\nworkflows. This work highlights the potential of LLMs in e-commerce workflows\nand the essential role of domain-specific datasets in tailoring them to\nindustry-specific challenges.",
      "tldr_zh": "该研究针对大型语言模型(LLMs)在电商领域的应用不足，引入了eC-Tab2Text数据集，该数据集捕捉了电商产品的详细属性和用户查询。研究聚焦于从结构化产品表格生成基于方面的文本，允许LLMs产生高质量、属性特定的产品评论，并通过细调模型进行优化。评估结果显示，在Table2Text指标以及正确性、忠实度和流畅性方面，生成的评论准确性大幅提升，突显了特定数据集在优化电商工作流中的关键作用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DB",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "NAACL 2025 (Industry Track)",
      "pdf_url": "http://arxiv.org/pdf/2502.14820v1",
      "published_date": "2025-02-20 18:41:48 UTC",
      "updated_date": "2025-02-20 18:41:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:19:50.944221"
    },
    {
      "arxiv_id": "2502.14949v1",
      "title": "KITAB-Bench: A Comprehensive Multi-Domain Benchmark for Arabic OCR and Document Understanding",
      "title_zh": "翻译失败",
      "authors": [
        "Ahmed Heakl",
        "Abdullah Sohail",
        "Mukul Ranjan",
        "Rania Hossam",
        "Ghazi Ahmed",
        "Mohamed El-Geish",
        "Omar Maher",
        "Zhiqiang Shen",
        "Fahad Khan",
        "Salman Khan"
      ],
      "abstract": "With the growing adoption of Retrieval-Augmented Generation (RAG) in document\nprocessing, robust text recognition has become increasingly critical for\nknowledge extraction. While OCR (Optical Character Recognition) for English and\nother languages benefits from large datasets and well-established benchmarks,\nArabic OCR faces unique challenges due to its cursive script, right-to-left\ntext flow, and complex typographic and calligraphic features. We present\nKITAB-Bench, a comprehensive Arabic OCR benchmark that fills the gaps in\ncurrent evaluation systems. Our benchmark comprises 8,809 samples across 9\nmajor domains and 36 sub-domains, encompassing diverse document types including\nhandwritten text, structured tables, and specialized coverage of 21 chart types\nfor business intelligence. Our findings show that modern vision-language models\n(such as GPT-4, Gemini, and Qwen) outperform traditional OCR approaches (like\nEasyOCR, PaddleOCR, and Surya) by an average of 60% in Character Error Rate\n(CER). Furthermore, we highlight significant limitations of current Arabic OCR\nmodels, particularly in PDF-to-Markdown conversion, where the best model\nGemini-2.0-Flash achieves only 65% accuracy. This underscores the challenges in\naccurately recognizing Arabic text, including issues with complex fonts,\nnumeral recognition errors, word elongation, and table structure detection.\nThis work establishes a rigorous evaluation framework that can drive\nimprovements in Arabic document analysis methods and bridge the performance gap\nwith English OCR technologies.",
      "tldr_zh": "该研究介绍了 KITAB-Bench，一种全面的多领域基准，用于评估阿拉伯语 OCR (Optical Character Recognition) 和文档理解，旨在解决阿拉伯语独特挑战，如草书体和从右到左的文本流。基准包含 8,809 个样本，覆盖 9 个主要领域和 36 个子领域，包括手写文本、结构化表格以及 21 种图表类型。实验结果显示，现代视觉语言模型（如 GPT-4、Gemini 和 Qwen）在 Character Error Rate (CER) 上比传统 OCR 方法（如 EasyOCR、PaddleOCR 和 Surya）平均高出 60%。然而，当前模型在 PDF-to-Markdown 转换中表现欠佳，最佳模型 Gemini-2.0-Flash 仅达到 65% 准确率，突显了复杂字体、数字识别错误和表格结构检测等难题。该基准为推动阿拉伯语文档分析的改进提供了严格的评估框架，有望缩小与英语 OCR 技术的性能差距。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "17 pages, 5 figures, ACL 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.14949v1",
      "published_date": "2025-02-20 18:41:23 UTC",
      "updated_date": "2025-02-20 18:41:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:20:04.720265"
    },
    {
      "arxiv_id": "2502.14815v1",
      "title": "Optimizing Model Selection for Compound AI Systems",
      "title_zh": "优化复合 AI 系统的模型选择",
      "authors": [
        "Lingjiao Chen",
        "Jared Quincy Davis",
        "Boris Hanin",
        "Peter Bailis",
        "Matei Zaharia",
        "James Zou",
        "Ion Stoica"
      ],
      "abstract": "Compound AI systems that combine multiple LLM calls, such as self-refine and\nmulti-agent-debate, achieve strong performance on many AI tasks. We address a\ncore question in optimizing compound systems: for each LLM call or module in\nthe system, how should one decide which LLM to use? We show that these LLM\nchoices have a large effect on quality, but the search space is exponential. We\npropose LLMSelector, an efficient framework for model selection in compound\nsystems, which leverages two key empirical insights: (i) end-to-end performance\nis often monotonic in how well each module performs, with all other modules\nheld fixed, and (ii) per-module performance can be estimated accurately by an\nLLM. Building upon these insights, LLMSelector iteratively selects one module\nand allocates to it the model with the highest module-wise performance, as\nestimated by an LLM, until no further gain is possible. LLMSelector is\napplicable to any compound system with a bounded number of modules, and its\nnumber of API calls scales linearly with the number of modules, achieving\nhigh-quality model allocation both empirically and theoretically. Experiments\nwith popular compound systems such as multi-agent debate and self-refine using\nLLMs such as GPT-4o, Claude 3.5 Sonnet and Gemini 1.5 show that LLMSelector\nconfers 5%-70% accuracy gains compared to using the same LLM for all modules.",
      "tldr_zh": "该论文探讨了如何优化复合 AI 系统（如 self-refine 和 multi-agent-debate）的模型选择问题，针对每个 LLM 调用或模块选择最佳 LLM，以提升整体性能。作者提出了 LLMSelector 框架，该框架基于两个关键经验洞见：端到端性能通常随单个模块性能的提升而单调增加，以及 LLM 可以准确估计模块性能；框架通过迭代为每个模块分配表现最佳的模型，直至无进一步收益。实验结果显示，在使用 GPT-4o、Claude 3.5 Sonnet 和 Gemini 1.5 等 LLM 的多代理辩论和 self-refine 系统上，LLMSelector 相比统一使用单一 LLM，提高了 5%-70% 的准确率，为高效的复合系统优化提供了理论和实证支持。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14815v1",
      "published_date": "2025-02-20 18:36:25 UTC",
      "updated_date": "2025-02-20 18:36:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:20:16.156762"
    },
    {
      "arxiv_id": "2502.14807v2",
      "title": "FetalCLIP: A Visual-Language Foundation Model for Fetal Ultrasound Image Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Fadillah Maani",
        "Numan Saeed",
        "Tausifa Saleem",
        "Zaid Farooq",
        "Hussain Alasmawi",
        "Werner Diehl",
        "Ameera Mohammad",
        "Gareth Waring",
        "Saudabi Valappi",
        "Leanne Bricker",
        "Mohammad Yaqub"
      ],
      "abstract": "Foundation models are becoming increasingly effective in the medical domain,\noffering pre-trained models on large datasets that can be readily adapted for\ndownstream tasks. Despite progress, fetal ultrasound images remain a\nchallenging domain for foundation models due to their inherent complexity,\noften requiring substantial additional training and facing limitations due to\nthe scarcity of paired multimodal data. To overcome these challenges, here we\nintroduce FetalCLIP, a vision-language foundation model capable of generating\nuniversal representation of fetal ultrasound images. FetalCLIP was pre-trained\nusing a multimodal learning approach on a diverse dataset of 210,035 fetal\nultrasound images paired with text. This represents the largest paired dataset\nof its kind used for foundation model development to date. This unique training\napproach allows FetalCLIP to effectively learn the intricate anatomical\nfeatures present in fetal ultrasound images, resulting in robust\nrepresentations that can be used for a variety of downstream applications. In\nextensive benchmarking across a range of key fetal ultrasound applications,\nincluding classification, gestational age estimation, congenital heart defect\n(CHD) detection, and fetal structure segmentation, FetalCLIP outperformed all\nbaselines while demonstrating remarkable generalizability and strong\nperformance even with limited labeled data. We plan to release the FetalCLIP\nmodel publicly for the benefit of the broader scientific community.",
      "tldr_zh": "该研究引入了FetalCLIP，一种视觉-语言基础模型（vision-language foundation model），旨在解决胎儿超声图像分析的复杂性挑战，通过多模态学习（multimodal learning）在包含210,035张图像和对应文本的多样化数据集上进行预训练。相比传统模型，FetalCLIP能够有效学习胎儿超声图像的复杂解剖特征，并在下游任务如分类、胎龄估计、先天性心脏缺陷（CHD）检测和胎儿结构分割中表现出色，超越所有基线模型并展示出卓越的泛化性和在有限标注数据下的强性能。研究团队计划公开发布FetalCLIP模型，以惠及更广泛的科学社区。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14807v2",
      "published_date": "2025-02-20 18:30:34 UTC",
      "updated_date": "2025-04-07 17:03:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:20:27.482975"
    },
    {
      "arxiv_id": "2502.14802v1",
      "title": "From RAG to Memory: Non-Parametric Continual Learning for Large Language Models",
      "title_zh": "从 RAG 到记忆：针对大语言模型的非参数持续学习",
      "authors": [
        "Bernal Jiménez Gutiérrez",
        "Yiheng Shu",
        "Weijian Qi",
        "Sizhe Zhou",
        "Yu Su"
      ],
      "abstract": "Our ability to continuously acquire, organize, and leverage knowledge is a\nkey feature of human intelligence that AI systems must approximate to unlock\ntheir full potential. Given the challenges in continual learning with large\nlanguage models (LLMs), retrieval-augmented generation (RAG) has become the\ndominant way to introduce new information. However, its reliance on vector\nretrieval hinders its ability to mimic the dynamic and interconnected nature of\nhuman long-term memory. Recent RAG approaches augment vector embeddings with\nvarious structures like knowledge graphs to address some of these gaps, namely\nsense-making and associativity. However, their performance on more basic\nfactual memory tasks drops considerably below standard RAG. We address this\nunintended deterioration and propose HippoRAG 2, a framework that outperforms\nstandard RAG comprehensively on factual, sense-making, and associative memory\ntasks. HippoRAG 2 builds upon the Personalized PageRank algorithm used in\nHippoRAG and enhances it with deeper passage integration and more effective\nonline use of an LLM. This combination pushes this RAG system closer to the\neffectiveness of human long-term memory, achieving a 7% improvement in\nassociative memory tasks over the state-of-the-art embedding model while also\nexhibiting superior factual knowledge and sense-making memory capabilities.\nThis work paves the way for non-parametric continual learning for LLMs. Our\ncode and data will be released at https://github.com/OSU-NLP-Group/HippoRAG.",
      "tldr_zh": "这篇论文探讨了大型语言模型 (LLMs) 在连续学习中的挑战，提出 HippoRAG 2 框架作为一种非参数方法来超越传统的 Retrieval-Augmented Generation (RAG) 系统。HippoRAG 2 基于 Personalized PageRank 算法，增强了 passage 整合和 LLM 的在线使用，从而改善事实记忆、sense-making 和 associative memory 任务的性能。实验结果显示，HippoRAG 2 在 associative memory 任务上比最先进模型提升 7%，并在其他方面表现出色，为 LLMs 的非参数连续学习提供了新路径。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Code and data to be released at:\n  https://github.com/OSU-NLP-Group/HippoRAG",
      "pdf_url": "http://arxiv.org/pdf/2502.14802v1",
      "published_date": "2025-02-20 18:26:02 UTC",
      "updated_date": "2025-02-20 18:26:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:20:40.612537"
    },
    {
      "arxiv_id": "2502.14799v1",
      "title": "A Survey on Text-Driven 360-Degree Panorama Generation",
      "title_zh": "文本驱动的360度全景生成综述",
      "authors": [
        "Hai Wang",
        "Xiaoyu Xiang",
        "Weihao Xia",
        "Jing-Hao Xue"
      ],
      "abstract": "The advent of text-driven 360-degree panorama generation, enabling the\nsynthesis of 360-degree panoramic images directly from textual descriptions,\nmarks a transformative advancement in immersive visual content creation. This\ninnovation significantly simplifies the traditionally complex process of\nproducing such content. Recent progress in text-to-image diffusion models has\naccelerated the rapid development in this emerging field. This survey presents\na comprehensive review of text-driven 360-degree panorama generation, offering\nan in-depth analysis of state-of-the-art algorithms and their expanding\napplications in 360-degree 3D scene generation. Furthermore, we critically\nexamine current limitations and propose promising directions for future\nresearch. A curated project page with relevant resources and research papers is\navailable at https://littlewhitesea.github.io/Text-Driven-Pano-Gen/.",
      "tldr_zh": "这篇调查论文探讨了基于文本驱动的 360-Degree Panorama Generation 的最新进展，该技术允许从文本描述直接合成 360 度全景图像，极大简化了沉浸式视觉内容的创建过程。论文对最先进的算法进行了深入分析，强调了 Text-to-Image Diffusion Models 在推动这一领域快速发展中的关键作用，并扩展了其在 360-Degree 3D 场景生成中的应用。最终，论文指出了当前存在的限制，如技术挑战，并提出了未来研究的方向，同时提供了一个项目页面（https://littlewhitesea.github.io/Text-Driven-Pano-Gen/）作为资源参考。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14799v1",
      "published_date": "2025-02-20 18:19:57 UTC",
      "updated_date": "2025-02-20 18:19:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:20:51.367339"
    },
    {
      "arxiv_id": "2503.05747v1",
      "title": "Balancing Innovation and Integrity: AI Integration in Liberal Arts College Administration",
      "title_zh": "翻译失败",
      "authors": [
        "Ian Olivo Read"
      ],
      "abstract": "This paper explores the intersection of artificial intelligence and higher\neducation administration, focusing on liberal arts colleges (LACs). It examines\nAI's opportunities and challenges in academic and student affairs, legal\ncompliance, and accreditation processes, while also addressing the ethical\nconsiderations of AI deployment in mission-driven institutions. Considering\nAI's value pluralism and potential allocative or representational harms caused\nby algorithmic bias, LACs must ensure AI aligns with its mission and\nprinciples. The study highlights other strategies for responsible AI\nintegration, balancing innovation with institutional values.",
      "tldr_zh": "本论文探讨了AI在文理学院(LACs)行政管理中的整合，考察其在学术和学生事务、法律合规以及认证过程中的机会和挑战，同时强调了AI部署的伦理考虑，如算法偏差可能导致的价值多元主义、分配或代表性伤害。研究指出，LACs需确保AI与机构使命和原则保持一致，以避免潜在风险。最终，该研究提出负责任的AI整合策略，旨在平衡创新与机构价值观的完整性。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "I.2.0; I.2.7; K.3.1; J.1; K.4.2"
      ],
      "primary_category": "cs.CY",
      "comment": "Number of Pages: 19; Number of Figures: 3. This submission explores\n  AI integration in liberal arts college administration, focusing on academic\n  and student affairs. It addresses ethical, legal, and institutional alignment\n  issues. For related discussions, see: Friedler et al. (2016), Katsamakas et\n  al. (2024), {\\L}odzikowski et al. (2023), Zhang et al. (2024)",
      "pdf_url": "http://arxiv.org/pdf/2503.05747v1",
      "published_date": "2025-02-20 18:16:11 UTC",
      "updated_date": "2025-02-20 18:16:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:21:04.395447"
    },
    {
      "arxiv_id": "2502.14791v2",
      "title": "Rapid Word Learning Through Meta In-Context Learning",
      "title_zh": "通过",
      "authors": [
        "Wentao Wang",
        "Guangyuan Jiang",
        "Tal Linzen",
        "Brenden M. Lake"
      ],
      "abstract": "Humans can quickly learn a new word from a few illustrative examples, and\nthen systematically and flexibly use it in novel contexts. Yet the abilities of\ncurrent language models for few-shot word learning, and methods for improving\nthese abilities, are underexplored. In this study, we introduce a novel method,\nMeta-training for IN-context learNing Of Words (Minnow). This method trains\nlanguage models to generate new examples of a word's usage given a few\nin-context examples, using a special placeholder token to represent the new\nword. This training is repeated on many new words to develop a general\nword-learning ability. We find that training models from scratch with Minnow on\nhuman-scale child-directed language enables strong few-shot word learning,\ncomparable to a large language model (LLM) pre-trained on orders of magnitude\nmore data. Furthermore, through discriminative and generative evaluations, we\ndemonstrate that finetuning pre-trained LLMs with Minnow improves their ability\nto discriminate between new words, identify syntactic categories of new words,\nand generate reasonable new usages and definitions for new words, based on one\nor a few in-context examples. These findings highlight the data efficiency of\nMinnow and its potential to improve language model performance in word learning\ntasks.",
      "tldr_zh": "本研究探讨了语言模型在少样本情境下快速学习新单词的能力，引入了一种名为Meta-training for IN-context learNing Of Words (Minnow)的创新方法。该方法通过训练模型基于少量上下文示例生成新单词的使用实例，并使用特殊占位符代表新单词，在多个新单词上重复训练以培养一般化词学习能力。实验结果显示，从头训练的模型在儿童导向语言数据集上实现了与大型语言模型(LLM)相当的性能，尽管数据量远小于LLM预训练数据。此外，Minnow通过判别和生成评估显著提升了模型在区分新单词、识别语法类别以及生成合理新用法方面的能力，突显了其在提高语言模型数据效率方面的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14791v2",
      "published_date": "2025-02-20 18:11:38 UTC",
      "updated_date": "2025-05-20 18:22:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:21:14.991826"
    },
    {
      "arxiv_id": "2502.14788v1",
      "title": "Ray-Tracing for Conditionally Activated Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Claudio Gallicchio",
        "Giuseppe Nuti"
      ],
      "abstract": "In this paper, we introduce a novel architecture for conditionally activated\nneural networks combining a hierarchical construction of multiple Mixture of\nExperts (MoEs) layers with a sampling mechanism that progressively converges to\nan optimized configuration of expert activation. This methodology enables the\ndynamic unfolding of the network's architecture, facilitating efficient\npath-specific training. Experimental results demonstrate that this approach\nachieves competitive accuracy compared to conventional baselines while\nsignificantly reducing the parameter count required for inference. Notably,\nthis parameter reduction correlates with the complexity of the input patterns,\na property naturally emerging from the network's operational dynamics without\nnecessitating explicit auxiliary penalty functions.",
      "tldr_zh": "本研究提出了一种新架构，用于条件激活的神经网络（Conditionally Activated Neural Networks），它结合了多层 Mixture of Experts (MoEs) 的层次结构和一个采样机制，以逐步收敛到优化的专家激活配置。 该方法允许网络动态展开架构，并支持路径特定的训练，从而提高效率。 实验结果显示，该方法在准确性上与传统基线相当，同时显著减少了推理所需的参数数量，且参数减少随输入模式的复杂性自然变化，无需额外惩罚函数。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "submitted to workshop",
      "pdf_url": "http://arxiv.org/pdf/2502.14788v1",
      "published_date": "2025-02-20 18:09:03 UTC",
      "updated_date": "2025-02-20 18:09:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:21:25.988092"
    },
    {
      "arxiv_id": "2502.14786v1",
      "title": "SigLIP 2: Multilingual Vision-Language Encoders with Improved Semantic Understanding, Localization, and Dense Features",
      "title_zh": "SigLIP 2：多语言视觉语言编码器，具有改进的语",
      "authors": [
        "Michael Tschannen",
        "Alexey Gritsenko",
        "Xiao Wang",
        "Muhammad Ferjad Naeem",
        "Ibrahim Alabdulmohsin",
        "Nikhil Parthasarathy",
        "Talfan Evans",
        "Lucas Beyer",
        "Ye Xia",
        "Basil Mustafa",
        "Olivier Hénaff",
        "Jeremiah Harmsen",
        "Andreas Steiner",
        "Xiaohua Zhai"
      ],
      "abstract": "We introduce SigLIP 2, a family of new multilingual vision-language encoders\nthat build on the success of the original SigLIP. In this second iteration, we\nextend the original image-text training objective with several prior,\nindependently developed techniques into a unified recipe -- this includes\ncaptioning-based pretraining, self-supervised losses (self-distillation, masked\nprediction) and online data curation. With these changes, SigLIP 2 models\noutperform their SigLIP counterparts at all model scales in core capabilities,\nincluding zero-shot classification, image-text retrieval, and transfer\nperformance when extracting visual representations for Vision-Language Models\n(VLMs). Furthermore, the new training recipe leads to significant improvements\non localization and dense prediction tasks. We also train variants which\nsupport multiple resolutions and preserve the input's native aspect ratio.\nFinally, we train on a more diverse data-mixture that includes de-biasing\ntechniques, leading to much better multilingual understanding and improved\nfairness. To allow users to trade off inference cost with performance, we\nrelease model checkpoints at four sizes: ViT-B (86M), L (303M), So400m (400M),\nand g (1B).",
      "tldr_zh": "我们介绍了 SigLIP 2，一系列改进的多语言视觉语言编码器，构建于原 SigLIP 基础上，通过整合基于标题的预训练、自我监督损失（如 self-distillation 和 masked prediction）以及在线数据整理等技术，提升了语义理解、定位和密集特征能力。相比原模型，SigLIP 2 在零样本分类、图像文本检索以及提取视觉表示用于 Vision-Language Models (VLMs) 的转移性能上表现出色，并在定位和密集预测任务中实现了显著改进。模型还支持多种分辨率和输入原生宽高比，并使用更多样化的数据混合提升多语言理解和公平性。我们发布了四个规模的模型检查点，包括 ViT-B (86M) 和 g (1B)，以便用户在推理成本和性能之间进行权衡。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Model checkpoints are available at\n  https://github.com/google-research/big_vision/tree/main/big_vision/configs/proj/image_text/README_siglip2.md",
      "pdf_url": "http://arxiv.org/pdf/2502.14786v1",
      "published_date": "2025-02-20 18:08:29 UTC",
      "updated_date": "2025-02-20 18:08:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:21:41.295069"
    },
    {
      "arxiv_id": "2502.14785v1",
      "title": "Real-Time Device Reach Forecasting Using HLL and MinHash Data Sketches",
      "title_zh": "翻译失败",
      "authors": [
        "Chandrashekar Muniyappa",
        "Kendall Willets",
        "Sriraman Krishnamoorthy"
      ],
      "abstract": "Predicting the right number of TVs (Device Reach) in real-time based on a\nuser-specified targeting attributes is imperative for running multi-million\ndollar ADs business. The traditional approach of SQL queries to join billions\nof records across multiple targeting dimensions is extremely slow. As a\nworkaround, many applications will have an offline process to crunch these\nnumbers and present the results after many hours. In our case, the solution was\nan offline process taking 24 hours to onboard a customer resulting in a\npotential loss of business. To solve this problem, we have built a new\nreal-time prediction system using MinHash and HyperLogLog (HLL) data sketches\nto compute the device reach at runtime when a user makes a request. However,\nexisting MinHash implementations do not solve the complex problem of multilevel\naggregation and intersection. This work will show how we have solved this\nproblem, in addition, we have improved MinHash algorithm to run 4 times faster\nusing Single Instruction Multiple Data (SIMD) vectorized operations for high\nspeed and accuracy with constant space to process billions of records. Finally,\nby experiments, we prove that the results are as accurate as traditional\noffline prediction system with an acceptable error rate of 5%.",
      "tldr_zh": "该研究针对广告业务中基于用户目标属性的设备覆盖率（Device Reach）预测问题，提出了一种实时系统，使用HyperLogLog (HLL) 和 MinHash 数据草图来替代传统SQL查询的低效方法，避免了24小时的离线处理延迟。研究团队改进了MinHash算法，支持多级聚合和交集，并通过Single Instruction Multiple Data (SIMD)矢量操作使其运行速度提高4倍，同时保持恒定空间处理数十亿记录。实验结果显示，该系统与传统离线预测系统精度相当，误差率仅5%，显著提升了业务效率。",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.LG",
        "60G25",
        "I.5.3"
      ],
      "primary_category": "cs.DB",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14785v1",
      "published_date": "2025-02-20 18:05:34 UTC",
      "updated_date": "2025-02-20 18:05:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:21:50.650259"
    },
    {
      "arxiv_id": "2502.14780v1",
      "title": "ReVision: A Dataset and Baseline VLM for Privacy-Preserving Task-Oriented Visual Instruction Rewriting",
      "title_zh": "翻译失败",
      "authors": [
        "Abhijit Mishra",
        "Richard Noh",
        "Hsiang Fu",
        "Mingda Li",
        "Minji Kim"
      ],
      "abstract": "Efficient and privacy-preserving multimodal interaction is essential as AR,\nVR, and modern smartphones with powerful cameras become primary interfaces for\nhuman-computer communication. Existing powerful large vision-language models\n(VLMs) enabling multimodal interaction often rely on cloud-based processing,\nraising significant concerns about (1) visual privacy by transmitting sensitive\nvision data to servers, and (2) their limited real-time, on-device usability.\nThis paper explores Visual Instruction Rewriting, a novel approach that\ntransforms multimodal instructions into text-only commands, allowing seamless\nintegration of lightweight on-device instruction rewriter VLMs (250M\nparameters) with existing conversational AI systems, enhancing vision data\nprivacy. To achieve this, we present a dataset of over 39,000 examples across\n14 domains and develop a compact VLM, pretrained on image captioning datasets\nand fine-tuned for instruction rewriting. Experimental results, evaluated\nthrough NLG metrics such as BLEU, METEOR, and ROUGE, along with semantic\nparsing analysis, demonstrate that even a quantized version of the model\n(<500MB storage footprint) can achieve effective instruction rewriting, thus\nenabling privacy-focused, multimodal AI applications.",
      "tldr_zh": "该研究提出了一种名为ReVision的框架，旨在解决多模态交互中的视觉隐私问题，通过Visual Instruction Rewriting方法将多模态指令转换为纯文本命令，从而实现小型on-device VLM（250M参数）的隐私保护应用。研究构建了一个包含超过39,000个示例的跨14个领域的数据集，并开发了一个基于图像字幕数据集预训练并微调的紧凑VLM。实验结果显示，即使量化版本的模型（存储空间<500MB），也能在BLEU、METEOR和ROUGE等NLG指标以及语义解析评估中表现出色，支持实时隐私-focused的多模态AI应用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "12 pages, 7 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2502.14780v1",
      "published_date": "2025-02-20 18:01:41 UTC",
      "updated_date": "2025-02-20 18:01:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:22:03.296743"
    },
    {
      "arxiv_id": "2502.14778v1",
      "title": "Harnessing PDF Data for Improving Japanese Large Multimodal Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jeonghun Baek",
        "Akiko Aizawa",
        "Kiyoharu Aizawa"
      ],
      "abstract": "Large Multimodal Models (LMMs) have demonstrated strong performance in\nEnglish, but their effectiveness in Japanese remains limited due to the lack of\nhigh-quality training data. Current Japanese LMMs often rely on translated\nEnglish datasets, restricting their ability to capture Japan-specific cultural\nknowledge. To address this, we explore the potential of Japanese PDF data as a\ntraining resource, an area that remains largely underutilized. We introduce a\nfully automated pipeline that leverages pretrained models to extract image-text\npairs from PDFs through layout analysis, OCR, and vision-language pairing,\nremoving the need for manual annotation. Additionally, we construct instruction\ndata from extracted image-text pairs to enrich the training data. To evaluate\nthe effectiveness of PDF-derived data, we train Japanese LMMs and assess their\nperformance on the Japanese LMM Benchmark. Our results demonstrate substantial\nimprovements, with performance gains ranging from 3.9% to 13.8% on Heron-Bench.\nFurther analysis highlights the impact of PDF-derived data on various factors,\nsuch as model size and language models, reinforcing its value as a multimodal\nresource for Japanese LMMs. We plan to make the source code and data publicly\navailable upon acceptance.",
      "tldr_zh": "本研究针对日语Large Multimodal Models (LMMs)的性能问题，提出利用PDF数据作为高质量训练资源，以克服依赖翻译英语数据集的局限性，从而更好地捕捉日本特有的文化知识。研究引入了一个全自动管道，通过布局分析、OCR和vision-language pairing从PDF中提取图像-文本对，并构建指令数据来丰富训练集。在Japanese LMM Benchmark上的实验显示，使用PDF派生数据训练的LMMs在Heron-Bench上性能提升3.9%至13.8%，并分析了其对模型大小和语言模型的影响。作者计划公开源代码和数据，以支持进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "15 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.14778v1",
      "published_date": "2025-02-20 17:59:59 UTC",
      "updated_date": "2025-02-20 17:59:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:22:14.973456"
    },
    {
      "arxiv_id": "2502.14777v1",
      "title": "Making Universal Policies Universal",
      "title_zh": "翻译失败",
      "authors": [
        "Niklas Höpner",
        "David Kuric",
        "Herke van Hoof"
      ],
      "abstract": "The development of a generalist agent capable of solving a wide range of\nsequential decision-making tasks remains a significant challenge. We address\nthis problem in a cross-agent setup where agents share the same observation\nspace but differ in their action spaces. Our approach builds on the universal\npolicy framework, which decouples policy learning into two stages: a\ndiffusion-based planner that generates observation sequences and an inverse\ndynamics model that assigns actions to these plans. We propose a method for\ntraining the planner on a joint dataset composed of trajectories from all\nagents. This method offers the benefit of positive transfer by pooling data\nfrom different agents, while the primary challenge lies in adapting shared\nplans to each agent's unique constraints. We evaluate our approach on the\nBabyAI environment, covering tasks of varying complexity, and demonstrate\npositive transfer across agents. Additionally, we examine the planner's\ngeneralisation ability to unseen agents and compare our method to traditional\nimitation learning approaches. By training on a pooled dataset from multiple\nagents, our universal policy achieves an improvement of up to $42.20\\%$ in task\ncompletion accuracy compared to a policy trained on a dataset from a single\nagent.",
      "tldr_zh": "该研究针对开发通用代理以解决多种顺序决策任务的挑战，提出了一种在跨代理设置中训练通用政策的方法，其中代理共享观察空间但行动空间不同。方法基于通用政策框架，包括使用扩散-based planner 生成观察序列，以及 inverse dynamics model 为这些序列分配行动；通过在联合数据集上训练 planner，实现 positive transfer，同时适应各代理的独特约束。在 BabyAI 环境上的实验显示，该方法在任务完成准确率上比单一代理数据集训练的策略提高了高达 42.20%，并证明了 planner 对未见代理的泛化能力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14777v1",
      "published_date": "2025-02-20 17:59:55 UTC",
      "updated_date": "2025-02-20 17:59:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:22:27.085145"
    },
    {
      "arxiv_id": "2502.14768v1",
      "title": "Logic-RL: Unleashing LLM Reasoning with Rule-Based Reinforcement Learning",
      "title_zh": "Logic-RL：通过基于规则的强化学习释放 LLM 推理",
      "authors": [
        "Tian Xie",
        "Zitian Gao",
        "Qingnan Ren",
        "Haoming Luo",
        "Yuqian Hong",
        "Bryan Dai",
        "Joey Zhou",
        "Kai Qiu",
        "Zhirong Wu",
        "Chong Luo"
      ],
      "abstract": "Inspired by the success of DeepSeek-R1, we explore the potential of\nrule-based reinforcement learning (RL) in large reasoning models. To analyze\nreasoning dynamics, we use synthetic logic puzzles as training data due to\ntheir controllable complexity and straightforward answer verification. We make\nsome key technical contributions that lead to effective and stable RL training:\na system prompt that emphasizes the thinking and answering process, a stringent\nformat reward function that penalizes outputs for taking shortcuts, and a\nstraightforward training recipe that achieves stable convergence. Our 7B model\ndevelops advanced reasoning skills-such as reflection, verification, and\nsummarization-that are absent from the logic corpus. Remarkably, after training\non just 5K logic problems, it demonstrates generalization abilities to the\nchallenging math benchmarks AIME and AMC.",
      "tldr_zh": "这篇论文受 DeepSeek-R1 启发，探索了基于规则的强化学习（Rule-Based RL）在提升大型语言模型（LLM）推理能力方面的潜力，使用合成逻辑谜题作为训练数据，以其可控复杂性和易验证答案。关键贡献包括一个强调思考和回答过程的系统提示、一个严格的格式奖励函数来惩罚捷径输出，以及一个简单的训练配方，实现稳定收敛。结果显示，7B 模型在仅 5K 逻辑问题训练后，开发出反思、验证和总结等高级推理技能，并成功泛化到挑战性的数学基准如 AIME 和 AMC。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14768v1",
      "published_date": "2025-02-20 17:49:26 UTC",
      "updated_date": "2025-02-20 17:49:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:22:40.898254"
    },
    {
      "arxiv_id": "2502.14944v1",
      "title": "Reward-Guided Iterative Refinement in Diffusion Models at Test-Time with Applications to Protein and DNA Design",
      "title_zh": "翻译失败",
      "authors": [
        "Masatoshi Uehara",
        "Xingyu Su",
        "Yulai Zhao",
        "Xiner Li",
        "Aviv Regev",
        "Shuiwang Ji",
        "Sergey Levine",
        "Tommaso Biancalani"
      ],
      "abstract": "To fully leverage the capabilities of diffusion models, we are often\ninterested in optimizing downstream reward functions during inference. While\nnumerous algorithms for reward-guided generation have been recently proposed\ndue to their significance, current approaches predominantly focus on\nsingle-shot generation, transitioning from fully noised to denoised states. We\npropose a novel framework for inference-time reward optimization with diffusion\nmodels inspired by evolutionary algorithms. Our approach employs an iterative\nrefinement process consisting of two steps in each iteration: noising and\nreward-guided denoising. This sequential refinement allows for the gradual\ncorrection of errors introduced during reward optimization. Besides, we provide\na theoretical guarantee for our framework. Finally, we demonstrate its superior\nempirical performance in protein and cell-type-specific regulatory DNA design.\nThe code is available at\n\\href{https://github.com/masa-ue/ProDifEvo-Refinement}{https://github.com/masa-ue/ProDifEvo-Refinement}.",
      "tldr_zh": "本研究提出了一种新框架，用于在扩散模型(diffusion models)推理时优化下游奖励函数，该框架受进化算法(evolutionary algorithms)启发，通过迭代精炼过程来逐步改进生成结果。每个迭代包括两个关键步骤：noising（添加噪声）和reward-guided denoising（基于奖励的去噪），从而逐步纠正奖励优化引入的错误。该框架提供了理论保证，并在蛋白质(protein)设计和细胞类型特异性调节DNA设计中表现出优越的经验性能，比现有方法更有效。代码已在GitHub上公开。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE",
        "q-bio.QM",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Under review. If you have any suggestions/missing references, please\n  let us know",
      "pdf_url": "http://arxiv.org/pdf/2502.14944v1",
      "published_date": "2025-02-20 17:48:45 UTC",
      "updated_date": "2025-02-20 17:48:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:22:51.140437"
    },
    {
      "arxiv_id": "2502.14943v3",
      "title": "GenAI vs. Human Fact-Checkers: Accurate Ratings, Flawed Rationales",
      "title_zh": "翻译失败",
      "authors": [
        "Yuehong Cassandra Tai",
        "Khushi Navin Patni",
        "Nicholas Daniel Hemauer",
        "Bruce Desmarais",
        "Yu-Ru Lin"
      ],
      "abstract": "Despite recent advances in understanding the capabilities and limits of\ngenerative artificial intelligence (GenAI) models, we are just beginning to\nunderstand their capacity to assess and reason about the veracity of content.\nWe evaluate multiple GenAI models across tasks that involve the rating of, and\nperceived reasoning about, the credibility of information. The information in\nour experiments comes from content that subnational U.S. politicians post to\nFacebook. We find that GPT-4o, one of the most used AI models in consumer\napplications, outperforms other models, but all models exhibit only moderate\nagreement with human coders. Importantly, even when GenAI models accurately\nidentify low-credibility content, their reasoning relies heavily on linguistic\nfeatures and ``hard'' criteria, such as the level of detail, source\nreliability, and language formality, rather than an understanding of veracity.\nWe also assess the effectiveness of summarized versus full content inputs,\nfinding that summarized content holds promise for improving efficiency without\nsacrificing accuracy. While GenAI has the potential to support human\nfact-checkers in scaling misinformation detection, our results caution against\nrelying solely on these models.",
      "tldr_zh": "本研究比较了生成式人工智能(GenAI)模型与人类事实检查者在评估内容真实性方面的表现，焦点在于模型的准确评分和推理能力。实验使用美国政客在Facebook上的内容作为数据集，发现GPT-4o在多个GenAI模型中表现最佳，但所有模型与人类编码者的同意度仅为中等水平。即使准确识别低可信度内容，GenAI的推理主要依赖语言特征和硬性标准（如细节水平、来源可靠性），而非对真实性的深度理解。研究还发现，使用总结内容输入可提高效率而不降低准确性，提醒人们GenAI虽能辅助误信息检测，但不应完全依赖这些模型。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted for publication in the 17th ACM Web Science Conference 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.14943v3",
      "published_date": "2025-02-20 17:47:40 UTC",
      "updated_date": "2025-02-25 19:06:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:23:04.298990"
    },
    {
      "arxiv_id": "2503.22684v1",
      "title": "Binary and Multi-Class Intrusion Detection in IoT Using Standalone and Hybrid Machine and Deep Learning Models",
      "title_zh": "翻译失败",
      "authors": [
        "Md Ahnaf Akif"
      ],
      "abstract": "Maintaining security in IoT systems depends on intrusion detection since\nthese networks' sensitivity to cyber-attacks is growing. Based on the IoT23\ndataset, this study explores the use of several Machine Learning (ML) and Deep\nLearning (DL) along with the hybrid models for binary and multi-class intrusion\ndetection. The standalone machine and deep learning models like Random Forest\n(RF), Extreme Gradient Boosting (XGBoost), Artificial Neural Network (ANN),\nK-Nearest Neighbors (KNN), Support Vector Machine (SVM), and Convolutional\nNeural Network (CNN) were used. Furthermore, two hybrid models were created by\ncombining machine learning techniques: RF, XGBoost, AdaBoost, KNN, and SVM and\nthese hybrid models were voting based hybrid classifier. Where one is for\nbinary, and the other one is for multi-class classification. These models vi\nwere tested using precision, recall, accuracy, and F1-score criteria and\ncompared the performance of each model. This work thoroughly explains how\nhybrid, standalone ML and DL techniques could improve IDS (Intrusion Detection\nSystem) in terms of accuracy and scalability in IoT (Internet of Things).",
      "tldr_zh": "本研究探讨了使用独立和混合机器学习 (ML) 与深度学习 (DL) 模型，在 IoT23 数据集上进行二元和多类入侵检测，以应对 IoT 系统日益严重的网络攻击风险。采用的独立模型包括 Random Forest (RF)、Extreme Gradient Boosting (XGBoost)、Artificial Neural Network (ANN)、K-Nearest Neighbors (KNN)、Support Vector Machine (SVM) 和 Convolutional Neural Network (CNN)，并开发了两个基于投票的混合模型，一个针对二元分类，另一个针对多类分类。这些模型通过精度、召回率、准确率和 F1 分数进行评估，结果显示混合模型显著提升了入侵检测系统 (IDS) 的准确性和可扩展性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "Master's thesis, 80 pages, 18 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2503.22684v1",
      "published_date": "2025-02-20 17:47:38 UTC",
      "updated_date": "2025-02-20 17:47:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:23:16.032161"
    },
    {
      "arxiv_id": "2502.14767v1",
      "title": "Tree-of-Debate: Multi-Persona Debate Trees Elicit Critical Thinking for Scientific Comparative Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Priyanka Kargupta",
        "Ishika Agarwal",
        "Tal August",
        "Jiawei Han"
      ],
      "abstract": "With the exponential growth of research facilitated by modern technology and\nimproved accessibility, scientific discoveries have become increasingly\nfragmented within and across fields. This makes it challenging to assess the\nsignificance, novelty, incremental findings, and equivalent ideas between\nrelated works, particularly those from different research communities. Large\nlanguage models (LLMs) have recently demonstrated strong quantitative and\nqualitative reasoning abilities, and multi-agent LLM debates have shown promise\nin handling complex reasoning tasks by exploring diverse perspectives and\nreasoning paths. Inspired by this, we introduce Tree-of-Debate (ToD), a\nframework which converts scientific papers into LLM personas that debate their\nrespective novelties. To emphasize structured, critical reasoning rather than\nfocusing solely on outcomes, ToD dynamically constructs a debate tree, enabling\nfine-grained analysis of independent novelty arguments within scholarly\narticles. Through experiments on scientific literature across various domains,\nevaluated by expert researchers, we demonstrate that ToD generates informative\narguments, effectively contrasts papers, and supports researchers in their\nliterature review.",
      "tldr_zh": "本研究针对科学发现的碎片化问题，提出Tree-of-Debate (ToD)框架，该框架将科学论文转化为多智能体LLM人格，通过动态构建辩论树来促进结构化的批判性推理和创新性分析。ToD强调细粒度探讨独立的新颖性论点，而非仅关注最终结果，从而有效对比相关作品的意义、Novelty和增量发现。实验结果显示，ToD在各种领域的科学文献上生成信息丰富的论点，并经专家评估后证实其能辅助研究人员进行高效的文献综述。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Code available at: https://github.com/pkargupta/tree-of-debate",
      "pdf_url": "http://arxiv.org/pdf/2502.14767v1",
      "published_date": "2025-02-20 17:43:40 UTC",
      "updated_date": "2025-02-20 17:43:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:23:27.144479"
    },
    {
      "arxiv_id": "2502.14765v1",
      "title": "Step-by-Step Fact Verification System for Medical Claims with Explainable Reasoning",
      "title_zh": "逐步事实验证系统，用于医疗声明并带有可解释推理",
      "authors": [
        "Juraj Vladika",
        "Ivana Hacajová",
        "Florian Matthes"
      ],
      "abstract": "Fact verification (FV) aims to assess the veracity of a claim based on\nrelevant evidence. The traditional approach for automated FV includes a\nthree-part pipeline relying on short evidence snippets and encoder-only\ninference models. More recent approaches leverage the multi-turn nature of LLMs\nto address FV as a step-by-step problem where questions inquiring additional\ncontext are generated and answered until there is enough information to make a\ndecision. This iterative method makes the verification process rational and\nexplainable. While these methods have been tested for encyclopedic claims,\nexploration on domain-specific and realistic claims is missing. In this work,\nwe apply an iterative FV system on three medical fact-checking datasets and\nevaluate it with multiple settings, including different LLMs, external web\nsearch, and structured reasoning using logic predicates. We demonstrate\nimprovements in the final performance over traditional approaches and the high\npotential of step-by-step FV systems for domain-specific claims.",
      "tldr_zh": "本研究提出了一种步-by-step事实验证(Fact Verification, FV)系统，针对医疗声明进行可解释推理，通过多轮大型语言模型(LLMs)生成问题获取额外上下文，直至积累足够信息做出决策，从而提升验证过程的理性性和透明度。与传统基于短证据片段的编码器-only模型相比，该系统在三个医疗事实检查数据集上进行了评估，包括不同LLMs、外部网络搜索和使用逻辑谓词的结构化推理。实验结果显示，该方法显著提高了性能，并证明了步-by-step FV系统在领域特定声明上的高潜力，为医疗事实检查提供了更可靠的工具。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to NAACL 2025 (Main)",
      "pdf_url": "http://arxiv.org/pdf/2502.14765v1",
      "published_date": "2025-02-20 17:40:21 UTC",
      "updated_date": "2025-02-20 17:40:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:23:39.978539"
    },
    {
      "arxiv_id": "2502.14760v1",
      "title": "EquivaMap: Leveraging LLMs for Automatic Equivalence Checking of Optimization Formulations",
      "title_zh": "翻译失败",
      "authors": [
        "Haotian Zhai",
        "Connor Lawless",
        "Ellen Vitercik",
        "Liu Leqi"
      ],
      "abstract": "A fundamental problem in combinatorial optimization is identifying equivalent\nformulations, which can lead to more efficient solution strategies and deeper\ninsights into a problem's computational complexity. The need to automatically\nidentify equivalence between problem formulations has grown as optimization\ncopilots--systems that generate problem formulations from natural language\ndescriptions--have proliferated. However, existing approaches to checking\nformulation equivalence lack grounding, relying on simple heuristics which are\ninsufficient for rigorous validation. Inspired by Karp reductions, in this work\nwe introduce quasi-Karp equivalence, a formal criterion for determining when\ntwo optimization formulations are equivalent based on the existence of a\nmapping between their decision variables. We propose EquivaMap, a framework\nthat leverages large language models to automatically discover such mappings,\nenabling scalable and reliable equivalence verification. To evaluate our\napproach, we construct the first open-source dataset of equivalent optimization\nformulations, generated by applying transformations such as adding slack\nvariables or valid inequalities to existing formulations. Empirically,\nEquivaMap significantly outperforms existing methods, achieving substantial\nimprovements in correctly identifying formulation equivalence.",
      "tldr_zh": "该论文解决了组合优化领域中识别等价公式化的核心问题，这些等价性有助于优化策略和计算复杂性分析，尤其在优化助手系统普及后。作者引入 quasi-Karp equivalence 标准，通过决策变量映射形式化地判定两个优化公式化的等价性。EquivaMap 框架利用大型语言模型（LLMs）自动发现这些映射，实现可扩展的等价性验证，并构建了首个开源数据集，包括通过添加松弛变量或有效不等式等转换生成的等价公式。实验结果显示，EquivaMap 显著优于现有方法，在正确识别公式化等价性方面取得了实质性改进。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "math.OC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14760v1",
      "published_date": "2025-02-20 17:35:32 UTC",
      "updated_date": "2025-02-20 17:35:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:23:52.221115"
    },
    {
      "arxiv_id": "2502.14759v1",
      "title": "On the Influence of Context Size and Model Choice in Retrieval-Augmented Generation Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Juraj Vladika",
        "Florian Matthes"
      ],
      "abstract": "Retrieval-augmented generation (RAG) has emerged as an approach to augment\nlarge language models (LLMs) by reducing their reliance on static knowledge and\nimproving answer factuality. RAG retrieves relevant context snippets and\ngenerates an answer based on them. Despite its increasing industrial adoption,\nsystematic exploration of RAG components is lacking, particularly regarding the\nideal size of provided context, and the choice of base LLM and retrieval\nmethod. To help guide development of robust RAG systems, we evaluate various\ncontext sizes, BM25 and semantic search as retrievers, and eight base LLMs.\nMoving away from the usual RAG evaluation with short answers, we explore the\nmore challenging long-form question answering in two domains, where a good\nanswer has to utilize the entire context. Our findings indicate that final QA\nperformance improves steadily with up to 15 snippets but stagnates or declines\nbeyond that. Finally, we show that different general-purpose LLMs excel in the\nbiomedical domain than the encyclopedic one, and that open-domain evidence\nretrieval in large corpora is challenging.",
      "tldr_zh": "这篇论文探讨了检索增强生成（RAG）系统中上下文大小和模型选择对性能的影响，旨在指导更稳健的RAG系统开发。研究者通过实验评估了不同上下文大小（最多15个片段）、BM25和语义搜索作为检索方法，以及八个基础大型语言模型（LLMs），并在生物医学和百科全书领域的长形式问答任务中进行测试。结果表明，QA性能随着上下文片段增加到15个而稳步提升，但超过后可能停滞或下降；此外，不同LLMs在特定领域（如生物医学）表现出色，而在大型语料库中证据检索面临显著挑战。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to Findings of NAACL 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.14759v1",
      "published_date": "2025-02-20 17:34:34 UTC",
      "updated_date": "2025-02-20 17:34:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:24:05.230149"
    },
    {
      "arxiv_id": "2502.14940v1",
      "title": "FacaDiffy: Inpainting Unseen Facade Parts Using Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Thomas Froech",
        "Olaf Wysocki",
        "Yan Xia",
        "Junyu Xie",
        "Benedikt Schwab",
        "Daniel Cremers",
        "Thomas H. Kolbe"
      ],
      "abstract": "High-detail semantic 3D building models are frequently utilized in robotics,\ngeoinformatics, and computer vision. One key aspect of creating such models is\nemploying 2D conflict maps that detect openings' locations in building facades.\nYet, in reality, these maps are often incomplete due to obstacles encountered\nduring laser scanning. To address this challenge, we introduce FacaDiffy, a\nnovel method for inpainting unseen facade parts by completing conflict maps\nwith a personalized Stable Diffusion model. Specifically, we first propose a\ndeterministic ray analysis approach to derive 2D conflict maps from existing 3D\nbuilding models and corresponding laser scanning point clouds. Furthermore, we\nfacilitate the inpainting of unseen facade objects into these 2D conflict maps\nby leveraging the potential of personalizing a Stable Diffusion model. To\ncomplement the scarcity of real-world training data, we also develop a scalable\npipeline to produce synthetic conflict maps using random city model generators\nand annotated facade images. Extensive experiments demonstrate that FacaDiffy\nachieves state-of-the-art performance in conflict map completion compared to\nvarious inpainting baselines and increases the detection rate by $22\\%$ when\napplying the completed conflict maps for high-definition 3D semantic building\nreconstruction. The code is be publicly available in the corresponding GitHub\nrepository: https://github.com/ThomasFroech/InpaintingofUnseenFacadeObjects",
      "tldr_zh": "本文提出 FacaDiffy，一种使用 Diffusion Models 修复建筑立面未见部分的方法，旨在解决激光扫描导致的冲突地图（conflict maps）不完整问题。方法包括通过 deterministic ray analysis 从 3D 建筑模型和点云中生成 2D 冲突地图，并利用个性化的 Stable Diffusion 模型进行修复，同时开发可扩展的合成数据管道来补充训练数据。实验结果表明，FacaDiffy 在冲突地图完成方面优于基线方法，提高了 22% 的检测率，从而提升了高分辨率 3D 语义建筑重建的性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted for GeoSpatial Week 2025, ISPRS Annals",
      "pdf_url": "http://arxiv.org/pdf/2502.14940v1",
      "published_date": "2025-02-20 17:32:41 UTC",
      "updated_date": "2025-02-20 17:32:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:24:16.936655"
    },
    {
      "arxiv_id": "2502.14939v1",
      "title": "Online hand gesture recognition using Continual Graph Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Rim Slama",
        "Wael Rabah",
        "Hazem Wannous"
      ],
      "abstract": "Online continuous action recognition has emerged as a critical research area\ndue to its practical implications in real-world applications, such as\nhuman-computer interaction, healthcare, and robotics. Among various modalities,\nskeleton-based approaches have gained significant popularity, demonstrating\ntheir effectiveness in capturing 3D temporal data while ensuring robustness to\nenvironmental variations. However, most existing works focus on segment-based\nrecognition, making them unsuitable for real-time, continuous recognition\nscenarios. In this paper, we propose a novel online recognition system designed\nfor real-time skeleton sequence streaming. Our approach leverages a hybrid\narchitecture combining Spatial Graph Convolutional Networks (S-GCN) for spatial\nfeature extraction and a Transformer-based Graph Encoder (TGE) for capturing\ntemporal dependencies across frames. Additionally, we introduce a continual\nlearning mechanism to enhance model adaptability to evolving data\ndistributions, ensuring robust recognition in dynamic environments. We evaluate\nour method on the SHREC'21 benchmark dataset, demonstrating its superior\nperformance in online hand gesture recognition. Our approach not only achieves\nstate-of-the-art accuracy but also significantly reduces false positive rates,\nmaking it a compelling solution for real-time applications. The proposed system\ncan be seamlessly integrated into various domains, including human-robot\ncollaboration and assistive technologies, where natural and intuitive\ninteraction is crucial.",
      "tldr_zh": "本研究提出了一种基于Continual Graph Transformers的在线手势识别系统，针对实时骨骼序列流场景，解决了传统段落式识别在动态环境中的局限性。该系统采用混合架构，包括Spatial Graph Convolutional Networks (S-GCN)提取空间特征和Transformer-based Graph Encoder (TGE)捕捉帧间时序依赖，并引入continual learning机制以适应数据分布的变化。在SHREC'21基准数据集上，该方法实现了最先进的准确率并显著降低了假阳性率，适用于人机交互、医疗和机器人领域如人-机器人协作的实际应用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14939v1",
      "published_date": "2025-02-20 17:27:55 UTC",
      "updated_date": "2025-02-20 17:27:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:24:27.641809"
    },
    {
      "arxiv_id": "2502.14753v1",
      "title": "MedVAE: Efficient Automated Interpretation of Medical Images with Large-Scale Generalizable Autoencoders",
      "title_zh": "翻译失败",
      "authors": [
        "Maya Varma",
        "Ashwin Kumar",
        "Rogier van der Sluijs",
        "Sophie Ostmeier",
        "Louis Blankemeier",
        "Pierre Chambon",
        "Christian Bluethgen",
        "Jip Prince",
        "Curtis Langlotz",
        "Akshay Chaudhari"
      ],
      "abstract": "Medical images are acquired at high resolutions with large fields of view in\norder to capture fine-grained features necessary for clinical decision-making.\nConsequently, training deep learning models on medical images can incur large\ncomputational costs. In this work, we address the challenge of downsizing\nmedical images in order to improve downstream computational efficiency while\npreserving clinically-relevant features. We introduce MedVAE, a family of six\nlarge-scale 2D and 3D autoencoders capable of encoding medical images as\ndownsized latent representations and decoding latent representations back to\nhigh-resolution images. We train MedVAE autoencoders using a novel two-stage\ntraining approach with 1,052,730 medical images. Across diverse tasks obtained\nfrom 20 medical image datasets, we demonstrate that (1) utilizing MedVAE latent\nrepresentations in place of high-resolution images when training downstream\nmodels can lead to efficiency benefits (up to 70x improvement in throughput)\nwhile simultaneously preserving clinically-relevant features and (2) MedVAE can\ndecode latent representations back to high-resolution images with high\nfidelity. Our work demonstrates that large-scale, generalizable autoencoders\ncan help address critical efficiency challenges in the medical domain. Our code\nis available at https://github.com/StanfordMIMI/MedVAE.",
      "tldr_zh": "本文提出MedVAE，一系列大型可泛化autoencoders，用于高效处理医疗图像，通过将高分辨率图像编码为缩小后的latent representations，从而降低下游模型的计算成本，同时保留临床相关特征。研究采用新型的两阶段训练方法，使用1,052,730张医疗图像训练六个2D和3D自编码器模型。实验结果显示，在20个医疗图像数据集上的多样任务中，使用MedVAE的latent representations可将吞吐量提高高达70倍，且能高保真度地解码回高分辨率图像。该工作证明了大型autoencoders在解决医疗领域效率挑战方面的潜力，并提供了开源代码。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14753v1",
      "published_date": "2025-02-20 17:24:06 UTC",
      "updated_date": "2025-02-20 17:24:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:24:41.509470"
    },
    {
      "arxiv_id": "2502.14743v2",
      "title": "Multi-Agent Coordination across Diverse Applications: A Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Lijun Sun",
        "Yijun Yang",
        "Qiqi Duan",
        "Yuhui Shi",
        "Chao Lyu",
        "Yu-Cheng Chang",
        "Chin-Teng Lin",
        "Yang Shen"
      ],
      "abstract": "Multi-agent coordination studies the underlying mechanism enabling the\ntrending spread of diverse multi-agent systems (MAS) and has received\nincreasing attention, driven by the expansion of emerging applications and\nrapid AI advances. This survey outlines the current state of coordination\nresearch across applications through a unified understanding that answers four\nfundamental coordination questions: (1) what is coordination; (2) why\ncoordination; (3) who to coordinate with; and (4) how to coordinate. Our\npurpose is to explore existing ideas and expertise in coordination and their\nconnections across diverse applications, while identifying and highlighting\nemerging and promising research directions. First, general coordination\nproblems that are essential to varied applications are identified and analyzed.\nSecond, a number of MAS applications are surveyed, ranging from widely studied\ndomains, e.g., search and rescue, warehouse automation and logistics, and\ntransportation systems, to emerging fields including humanoid and\nanthropomorphic robots, satellite systems, and large language models (LLMs).\nFinally, open challenges about the scalability, heterogeneity, and learning\nmechanisms of MAS are analyzed and discussed. In particular, we identify the\nhybridization of hierarchical and decentralized coordination, human-MAS\ncoordination, and LLM-based MAS as promising future directions.",
      "tldr_zh": "这篇调查论文探讨了多智能体系统 (MAS) 中的协调机制，针对四个基本问题：什么是协调、为什么需要协调、与谁协调以及如何协调，旨在统一理解跨不同应用的协调研究。论文分析了通用协调问题，并回顾了广泛的应用领域，包括传统领域如搜索和救援、仓库自动化和物流、交通系统，以及新兴领域如人形机器人、卫星系统和大型语言模型 (LLMs)。最终，它指出了开放挑战，如 MAS 的可扩展性、异质性和学习机制，并强调了混合层次与去中心化协调、人机协调以及基于 LLM 的 MAS 作为未来的关键研究方向。",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "23 pages, 4 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2502.14743v2",
      "published_date": "2025-02-20 17:12:45 UTC",
      "updated_date": "2025-02-21 02:41:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:24:51.365356"
    },
    {
      "arxiv_id": "2503.11664v1",
      "title": "An LLM-Based Approach for Insight Generation in Data Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Alberto Sánchez Pérez",
        "Alaa Boukhary",
        "Paolo Papotti",
        "Luis Castejón Lozano",
        "Adam Elwood"
      ],
      "abstract": "Generating insightful and actionable information from databases is critical\nin data analysis. This paper introduces a novel approach using Large Language\nModels (LLMs) to automatically generate textual insights. Given a multi-table\ndatabase as input, our method leverages LLMs to produce concise, text-based\ninsights that reflect interesting patterns in the tables. Our framework\nincludes a Hypothesis Generator to formulate domain-relevant questions, a Query\nAgent to answer such questions by generating SQL queries against a database,\nand a Summarization module to verbalize the insights. The insights are\nevaluated for both correctness and subjective insightfulness using a hybrid\nmodel of human judgment and automated metrics. Experimental results on public\nand enterprise databases demonstrate that our approach generates more\ninsightful insights than other approaches while maintaining correctness.",
      "tldr_zh": "这篇论文提出了一种基于 Large Language Models (LLMs) 的方法，用于从多表数据库自动生成简洁的文本洞见，旨在揭示数据中的有趣模式。该框架包括 Hypothesis Generator 来制定领域相关问题、Query Agent 来生成 SQL 查询回答这些问题，以及 Summarization module 来总结洞见。论文通过人类判断和自动化指标的混合模型评估洞见的正确性和洞见性，实验结果显示，在公共和企业数据库上，该方法比其他方法生成更具洞见性的洞见，同时保持高正确性。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.DB"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted for publication at NAACL 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.11664v1",
      "published_date": "2025-02-20 17:09:59 UTC",
      "updated_date": "2025-02-20 17:09:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:25:02.453626"
    },
    {
      "arxiv_id": "2502.14740v1",
      "title": "YOLOv12: A Breakdown of the Key Architectural Features",
      "title_zh": "YOLOv12: 关键架构特征剖析",
      "authors": [
        "Mujadded Al Rabbani Alif",
        "Muhammad Hussain"
      ],
      "abstract": "This paper presents an architectural analysis of YOLOv12, a significant\nadvancement in single-stage, real-time object detection building upon the\nstrengths of its predecessors while introducing key improvements. The model\nincorporates an optimised backbone (R-ELAN), 7x7 separable convolutions, and\nFlashAttention-driven area-based attention, improving feature extraction,\nenhanced efficiency, and robust detections. With multiple model variants,\nsimilar to its predecessors, YOLOv12 offers scalable solutions for both\nlatency-sensitive and high-accuracy applications. Experimental results manifest\nconsistent gains in mean average precision (mAP) and inference speed, making\nYOLOv12 a compelling choice for applications in autonomous systems, security,\nand real-time analytics. By achieving an optimal balance between computational\nefficiency and performance, YOLOv12 sets a new benchmark for real-time computer\nvision, facilitating deployment across diverse hardware platforms, from edge\ndevices to high-performance clusters.",
      "tldr_zh": "这篇论文分析了 YOLOv12 的关键架构特征，这是一个基于前代模型的单阶段实时对象检测系统。YOLOv12 引入了优化的 R-ELAN 骨干网络、7x7 separable convolutions 和 FlashAttention-driven area-based attention，提升了特征提取效率和检测鲁棒性，同时提供多个模型变体以适应延迟敏感或高精度应用。实验结果显示，YOLOv12 在 mean average precision (mAP) 和推理速度上实现了显著提升，成为实时计算机视觉的新基准。总体而言，该模型平衡了计算效率和性能，便于在自主系统、安全和实时分析等领域的硬件平台上部署。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14740v1",
      "published_date": "2025-02-20 17:08:43 UTC",
      "updated_date": "2025-02-20 17:08:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:25:16.062667"
    },
    {
      "arxiv_id": "2502.14735v1",
      "title": "EAGER-LLM: Enhancing Large Language Models as Recommenders through Exogenous Behavior-Semantic Integration",
      "title_zh": "翻译失败",
      "authors": [
        "Minjie Hong",
        "Yan Xia",
        "Zehan Wang",
        "Jieming Zhu",
        "Ye Wang",
        "Sihang Cai",
        "Xiaoda Yang",
        "Quanyu Dai",
        "Zhenhua Dong",
        "Zhimeng Zhang",
        "Zhou Zhao"
      ],
      "abstract": "Large language models (LLMs) are increasingly leveraged as foundational\nbackbones in the development of advanced recommender systems, offering enhanced\ncapabilities through their extensive knowledge and reasoning. Existing\nllm-based recommender systems (RSs) often face challenges due to the\nsignificant differences between the linguistic semantics of pre-trained LLMs\nand the collaborative semantics essential for RSs. These systems use\npre-trained linguistic semantics but learn collaborative semantics from scratch\nvia the llm-Backbone. However, LLMs are not designed for recommendations,\nleading to inefficient collaborative learning, weak result correlations, and\npoor integration of traditional RS features. To address these challenges, we\npropose EAGER-LLM, a decoder-only llm-based generative recommendation framework\nthat integrates endogenous and exogenous behavioral and semantic information in\na non-intrusive manner. Specifically, we propose 1)dual-source knowledge-rich\nitem indices that integrates indexing sequences for exogenous signals, enabling\nefficient link-wide processing; 2)non-invasive multiscale alignment\nreconstruction tasks guide the model toward a deeper understanding of both\ncollaborative and semantic signals; 3)an annealing adapter designed to finely\nbalance the model's recommendation performance with its comprehension\ncapabilities. We demonstrate EAGER-LLM's effectiveness through rigorous testing\non three public benchmarks.",
      "tldr_zh": "该研究针对大型语言模型(LLMs)作为推荐系统基础时存在的语言语义与协作语义不匹配问题，提出EAGER-LLM框架，通过非侵入式整合内生和外生行为语义信息来提升推荐性能。具体方法包括：dual-source knowledge-rich item indices用于高效处理外生信号、non-invasive multiscale alignment reconstruction tasks指导模型理解协作和语义信号，以及annealing adapter平衡推荐性能和理解能力。实验在三个公共基准上验证了EAGER-LLM的有效性，解决了现有LLM-based recommender systems的效率和相关性问题。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "9 pages, 6 figures, accpeted by WWW 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.14735v1",
      "published_date": "2025-02-20 17:01:57 UTC",
      "updated_date": "2025-02-20 17:01:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:25:27.603506"
    },
    {
      "arxiv_id": "2502.14727v1",
      "title": "WavRAG: Audio-Integrated Retrieval Augmented Generation for Spoken Dialogue Models",
      "title_zh": "WavRAG：音频集成的检索增强生成用于口语对话模型",
      "authors": [
        "Yifu Chen",
        "Shengpeng Ji",
        "Haoxiao Wang",
        "Ziqing Wang",
        "Siyu Chen",
        "Jinzheng He",
        "Jin Xu",
        "Zhou Zhao"
      ],
      "abstract": "Retrieval Augmented Generation (RAG) has gained widespread adoption owing to\nits capacity to empower large language models (LLMs) to integrate external\nknowledge. However, existing RAG frameworks are primarily designed for\ntext-based LLMs and rely on Automatic Speech Recognition to process speech\ninput, which discards crucial audio information, risks transcription errors,\nand increases computational overhead. Therefore, we introduce WavRAG, the first\nretrieval augmented generation framework with native, end-to-end audio support.\nWavRAG offers two key features: 1) Bypassing ASR, WavRAG directly processes raw\naudio for both embedding and retrieval. 2) WavRAG integrates audio and text\ninto a unified knowledge representation. Specifically, we propose the\nWavRetriever to facilitate the retrieval from a text-audio hybrid knowledge\nbase, and further enhance the in-context capabilities of spoken dialogue models\nthrough the integration of chain-of-thought reasoning. In comparison to\nstate-of-the-art ASR-Text RAG pipelines, WavRAG achieves comparable retrieval\nperformance while delivering a 10x acceleration. Furthermore, WavRAG's unique\ntext-audio hybrid retrieval capability extends the boundaries of RAG to the\naudio modality.",
      "tldr_zh": "该研究提出WavRAG，一种原生支持音频的Retrieval Augmented Generation (RAG)框架，旨在解决传统RAG依赖Automatic Speech Recognition (ASR)的不足，从而避免音频信息丢失、转录错误和计算开销增加。WavRAG的关键创新包括直接处理原始音频用于嵌入和检索，并通过WavRetriever从文本-音频混合知识库中进行统一检索，同时整合chain-of-thought reasoning来提升口语对话模型的上下文能力。与现有ASR-Text RAG管道相比，WavRAG实现了相似的检索性能，但速度提高了10倍，并扩展了RAG框架到音频模态领域。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14727v1",
      "published_date": "2025-02-20 16:54:07 UTC",
      "updated_date": "2025-02-20 16:54:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:25:39.906223"
    },
    {
      "arxiv_id": "2502.14724v2",
      "title": "Ranking Joint Policies in Dynamic Games using Evolutionary Dynamics",
      "title_zh": "利用进化动力学对动态博弈中的联合策略进行排名",
      "authors": [
        "Natalia Koliou",
        "George Vouros"
      ],
      "abstract": "Game-theoretic solution concepts, such as the Nash equilibrium, have been key\nto finding stable joint actions in multi-player games. However, it has been\nshown that the dynamics of agents' interactions, even in simple two-player\ngames with few strategies, are incapable of reaching Nash equilibria,\nexhibiting complex and unpredictable behavior. Instead, evolutionary approaches\ncan describe the long-term persistence of strategies and filter out transient\nones, accounting for the long-term dynamics of agents' interactions. Our goal\nis to identify agents' joint strategies that result in stable behavior, being\nresistant to changes, while also accounting for agents' payoffs, in dynamic\ngames. Towards this goal, and building on previous results, this paper proposes\ntransforming dynamic games into their empirical forms by considering agents'\nstrategies instead of agents' actions, and applying the evolutionary\nmethodology $\\alpha$-Rank to evaluate and rank strategy profiles according to\ntheir long-term dynamics. This methodology not only allows us to identify joint\nstrategies that are strong through agents' long-term interactions, but also\nprovides a descriptive, transparent framework regarding the high ranking of\nthese strategies. Experiments report on agents that aim to collaboratively\nsolve a stochastic version of the graph coloring problem. We consider different\nstyles of play as strategies to define the empirical game, and train policies\nrealizing these strategies, using the DQN algorithm. Then we run simulations to\ngenerate the payoff matrix required by $\\alpha$-Rank to rank joint strategies.",
      "tldr_zh": "这篇论文探讨了在动态游戏中，使用进化动态（evolutionary dynamics）来排名代理的联合策略（joint policies），以解决传统 Nash equilibrium 等游戏理论概念无法捕捉代理互动复杂性和长期动态的问题。作者提出将动态游戏转化为经验形式（empirical forms），通过代理策略而非动作，并应用 α-Rank 方法来评估和排名策略配置文件，确保这些策略在长期互动中稳定且抗变化。在实验中，他们使用 DQN 算法训练代理在随机图着色问题的协作场景中实现不同策略风格，并通过模拟生成收益矩阵来验证 α-Rank 的有效性。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14724v2",
      "published_date": "2025-02-20 16:50:38 UTC",
      "updated_date": "2025-05-17 08:18:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:25:51.678798"
    },
    {
      "arxiv_id": "2502.14714v2",
      "title": "From Knowledge Generation to Knowledge Verification: Examining the BioMedical Generative Capabilities of ChatGPT",
      "title_zh": "翻译失败",
      "authors": [
        "Ahmed Abdeen Hamed",
        "Alessandro Crimi",
        "Magdalena M. Misiak",
        "Byung Suk Lee"
      ],
      "abstract": "The generative capabilities of LLM models offer opportunities for\naccelerating tasks but raise concerns about the authenticity of the knowledge\nthey produce. To address these concerns, we present a computational approach\nthat evaluates the factual accuracy of biomedical knowledge generated by an\nLLM. Our approach consists of two processes: generating disease-centric\nassociations and verifying these associations using the semantic framework of\nbiomedical ontologies. Using ChatGPT as the selected LLM, we designed\nprompt-engineering processes to establish linkages between diseases and related\ndrugs, symptoms, and genes, and assessed consistency across multiple ChatGPT\nmodels (e.g., GPT-turbo, GPT-4, etc.). Experimental results demonstrate high\naccuracy in identifying disease terms (88%-97%), drug names (90%-91%), and\ngenetic information (88%-98%). However, symptom term identification was notably\nlower (49%-61%), due to the informal and verbose nature of symptom\ndescriptions, which hindered effective semantic matching with the formal\nlanguage of specialized ontologies. Verification of associations reveals\nliterature coverage rates of 89%-91% for disease-drug and disease-gene pairs,\nwhile symptom-related associations exhibit lower coverage (49%-62%).",
      "tldr_zh": "本论文评估了 ChatGPT 在生物医学领域的生成能力，提出了一种计算方法，从知识生成到验证的过程入手，以确保 LLM 生成知识的准确性。该方法通过 prompt-engineering 生成疾病相关的关联（如药物、症状、基因），并利用生物医学 ontologies 的语义框架进行验证。实验结果显示，疾病术语（88%-97%）、药物（90%-91%）和基因（88%-98%）识别准确率较高，但症状术语识别率较低（49%-61%），原因是症状描述过于非正式导致语义匹配困难；此外，疾病-药物和疾病-基因关联的文献覆盖率达89%-91%，而症状相关关联仅为49%-62%。这项研究突显了 LLM 在生物医学应用中的潜力与挑战。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.IR",
        "I.2; I.2.4; I.2.7"
      ],
      "primary_category": "cs.AI",
      "comment": "28 pages, 6 figures, In Review with a Cell Press Journal",
      "pdf_url": "http://arxiv.org/pdf/2502.14714v2",
      "published_date": "2025-02-20 16:39:57 UTC",
      "updated_date": "2025-03-23 16:02:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:26:06.335087"
    },
    {
      "arxiv_id": "2502.14708v1",
      "title": "Human Misperception of Generative-AI Alignment: A Laboratory Experiment",
      "title_zh": "翻译失败",
      "authors": [
        "Kevin He",
        "Ran Shorrer",
        "Mengjia Xia"
      ],
      "abstract": "We conduct an incentivized laboratory experiment to study people's perception\nof generative artificial intelligence (GenAI) alignment in the context of\neconomic decision-making. Using a panel of economic problems spanning the\ndomains of risk, time preference, social preference, and strategic\ninteractions, we ask human subjects to make choices for themselves and to\npredict the choices made by GenAI on behalf of a human user. We find that\npeople overestimate the degree of alignment between GenAI's choices and human\nchoices. In every problem, human subjects' average prediction about GenAI's\nchoice is substantially closer to the average human-subject choice than it is\nto the GenAI choice. At the individual level, different subjects' predictions\nabout GenAI's choice in a given problem are highly correlated with their own\nchoices in the same problem. We explore the implications of people\noverestimating GenAI alignment in a simple theoretical model.",
      "tldr_zh": "这篇论文通过一个有激励的实验室实验，研究人们对生成式人工智能(GenAI)校准(alignment)的认知偏差，焦点在于经济决策领域如风险、时间偏好、社会偏好和战略互动。结果显示，人类受试者普遍高估了GenAI选择与人类选择的相似程度，在每个问题中，他们的平均预测更接近人类选择而非实际GenAI选择。论文进一步探讨了这一过度估计现象的个体相关性和潜在影响，并通过一个简单理论模型分析其含义。",
      "categories": [
        "econ.TH",
        "cs.AI",
        "cs.GT"
      ],
      "primary_category": "econ.TH",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14708v1",
      "published_date": "2025-02-20 16:32:42 UTC",
      "updated_date": "2025-02-20 16:32:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:26:16.255177"
    },
    {
      "arxiv_id": "2502.14706v3",
      "title": "Building reliable sim driving agents by scaling self-play",
      "title_zh": "通过扩展自玩构建可靠的模拟驾驶代理",
      "authors": [
        "Daphne Cornelisse",
        "Aarav Pandya",
        "Kevin Joseph",
        "Joseph Suárez",
        "Eugene Vinitsky"
      ],
      "abstract": "Simulation agents are essential for designing and testing systems that\ninteract with humans, such as autonomous vehicles (AVs). These agents serve\nvarious purposes, from benchmarking AV performance to stress-testing system\nlimits, but all applications share one key requirement: reliability. To enable\nsound experimentation, a simulation agent must behave as intended. It should\nminimize actions that may lead to undesired outcomes, such as collisions, which\ncan distort the signal-to-noise ratio in analyses. As a foundation for reliable\nsim agents, we propose scaling self-play to thousands of scenarios on the Waymo\nOpen Motion Dataset under semi-realistic limits on human perception and\ncontrol. Training from scratch on a single GPU, our agents solve almost the\nfull training set within a day. They generalize to unseen test scenes,\nachieving a 99.8% goal completion rate with less than 0.8% combined collision\nand off-road incidents across 10,000 held-out scenarios. Beyond in-distribution\ngeneralization, our agents show partial robustness to out-of-distribution\nscenes and can be fine-tuned in minutes to reach near-perfect performance in\nsuch cases. We open-source the pre-trained agents and integrate them with a\nbatched multi-agent simulator. Demonstrations of agent behaviors can be viewed\nat https://sites.google.com/view/reliable-sim-agents, and we open-source our\nagents at https://github.com/Emerge-Lab/gpudrive.",
      "tldr_zh": "本研究提出了一种通过扩展自博弈(self-play)到数千个场景的方法，来构建可靠的模拟驾驶代理(simulation agents)，以支持自动驾驶车辆(AVs)的设计和测试。方法基于 Waymo Open Motion Dataset，在半现实的人类感知和控制限制下，使用单个 GPU 从零开始训练，代理可在一天内几乎完成整个训练集。实验结果显示，代理在 10,000 个未见过场景中实现了 99.8% 的目标完成率，同时碰撞和离路事件少于 0.8%，并展现了对 out-of-distribution 场景的部分鲁棒性，以及通过 fine-tune 在数分钟内达到近乎完美性能。该代理已开源，并与批量多代理模拟器集成，以促进进一步研究。",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "v3",
      "pdf_url": "http://arxiv.org/pdf/2502.14706v3",
      "published_date": "2025-02-20 16:30:45 UTC",
      "updated_date": "2025-05-19 23:24:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:26:29.147973"
    },
    {
      "arxiv_id": "2502.14704v2",
      "title": "Not All Data are Good Labels: On the Self-supervised Labeling for Time Series Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Yuxuan Yang",
        "Dalin Zhang",
        "Yuxuan Liang",
        "Hua Lu",
        "Gang Chen",
        "Huan Li"
      ],
      "abstract": "Time Series Forecasting (TSF) is a crucial task in various domains, yet\nexisting TSF models rely heavily on high-quality data and insufficiently\nexploit all available data. This paper explores a novel self-supervised\napproach to re-label time series datasets by inherently constructing candidate\ndatasets. During the optimization of a simple reconstruction network,\nintermediates are used as pseudo labels in a self-supervised paradigm,\nimproving generalization for any predictor. We introduce the Self-Correction\nwith Adaptive Mask (SCAM), which discards overfitted components and selectively\nreplaces them with pseudo labels generated from reconstructions. Additionally,\nwe incorporate Spectral Norm Regularization (SNR) to further suppress\noverfitting from a loss landscape perspective. Our experiments on eleven\nreal-world datasets demonstrate that SCAM consistently improves the performance\nof various backbone models. This work offers a new perspective on constructing\ndatasets and enhancing the generalization of TSF models through self-supervised\nlearning.",
      "tldr_zh": "时间序列预测（Time Series Forecasting, TSF）模型依赖高质量数据，但往往未能充分利用所有可用数据，本文提出一种新型自监督方法，通过构建候选数据集并使用重构网络的中间结果作为伪标签（pseudo labels），来改善预测器的泛化能力。论文引入 Self-Correction with Adaptive Mask (SCAM) 来丢弃过拟合部分，并结合 Spectral Norm Regularization (SNR) 从损失景观角度抑制过拟合，从而增强模型性能。在 11 个真实世界数据集上的实验显示，SCAM 能一致提升各种骨干模型的表现，为通过自监督学习构建数据集和提升 TSF 模型泛化提供了新视角。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14704v2",
      "published_date": "2025-02-20 16:29:37 UTC",
      "updated_date": "2025-02-21 02:25:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:26:41.538937"
    },
    {
      "arxiv_id": "2502.14698v1",
      "title": "General Uncertainty Estimation with Delta Variances",
      "title_zh": "翻译失败",
      "authors": [
        "Simon Schmitt",
        "John Shawe-Taylor",
        "Hado van Hasselt"
      ],
      "abstract": "Decision makers may suffer from uncertainty induced by limited data. This may\nbe mitigated by accounting for epistemic uncertainty, which is however\nchallenging to estimate efficiently for large neural networks. To this extent\nwe investigate Delta Variances, a family of algorithms for epistemic\nuncertainty quantification, that is computationally efficient and convenient to\nimplement. It can be applied to neural networks and more general functions\ncomposed of neural networks. As an example we consider a weather simulator with\na neural-network-based step function inside -- here Delta Variances empirically\nobtain competitive results at the cost of a single gradient computation. The\napproach is convenient as it requires no changes to the neural network\narchitecture or training procedure. We discuss multiple ways to derive Delta\nVariances theoretically noting that special cases recover popular techniques\nand present a unified perspective on multiple related methods. Finally we\nobserve that this general perspective gives rise to a natural extension and\nempirically show its benefit.",
      "tldr_zh": "该论文探讨了如何通过 Delta Variances 算法来估计认知不确定性（epistemic uncertainty），以帮助决策者在数据有限的情况下降低风险。该方法计算高效、易于实现，可直接应用于神经网络和其他基于神经网络的函数，而无需修改其架构或训练过程。在一个基于神经网络的天气模拟器示例中，Delta Variances 仅需一个梯度计算就取得了与现有方法竞争性的结果。理论上，该算法统一了多种相关技术，并提出自然扩展，实验验证了其益处。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.AP",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14698v1",
      "published_date": "2025-02-20 16:22:40 UTC",
      "updated_date": "2025-02-20 16:22:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:26:51.629456"
    },
    {
      "arxiv_id": "2502.14681v1",
      "title": "seqKAN: Sequence processing with Kolmogorov-Arnold Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Tatiana Boura",
        "Stasinos Konstantopoulos"
      ],
      "abstract": "Kolmogorov-Arnold Networks (KANs) have been recently proposed as a machine\nlearning framework that is more interpretable and controllable than the\nmulti-layer perceptron. Various network architectures have been proposed within\nthe KAN framework targeting different tasks and application domains, including\nsequence processing.\n  This paper proposes seqKAN, a new KAN architecture for sequence processing.\nAlthough multiple sequence processing KAN architectures have already been\nproposed, we argue that seqKAN is more faithful to the core concept of the KAN\nframework. Furthermore, we empirically demonstrate that it achieves better\nresults.\n  The empirical evaluation is performed on generated data from a complex\nphysics problem on an interpolation and an extrapolation task. Using this\ndataset we compared seqKAN against a prior KAN network for timeseries\nprediction, recurrent deep networks, and symbolic regression. seqKAN\nsubstantially outperforms all architectures, particularly on the extrapolation\ndataset, while also being the most transparent.",
      "tldr_zh": "该论文提出 seqKAN，一种基于 Kolmogorov-Arnold Networks (KANs) 的新架构，专门用于序列处理，并声称它更忠实于 KAN 框架的核心概念，比现有模型更具可解释性和可控性。seqKAN 通过针对复杂物理问题的生成数据进行实验，包括插值和外推任务，与先前的 KAN 网络、循环深度网络（recurrent deep networks）和符号回归（symbolic regression）进行比较，结果显示 seqKAN 在准确性上大幅领先，尤其在外推数据集上表现出色，同时保持最高的透明度。总的来说，该工作为可解释机器学习在序列处理领域的应用提供了重要进展。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14681v1",
      "published_date": "2025-02-20 16:10:18 UTC",
      "updated_date": "2025-02-20 16:10:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:27:03.816788"
    },
    {
      "arxiv_id": "2502.14677v2",
      "title": "Data-Constrained Synthesis of Training Data for De-Identification",
      "title_zh": "翻译失败",
      "authors": [
        "Thomas Vakili",
        "Aron Henriksson",
        "Hercules Dalianis"
      ],
      "abstract": "Many sensitive domains -- such as the clinical domain -- lack widely\navailable datasets due to privacy risks. The increasing generative capabilities\nof large language models (LLMs) have made synthetic datasets a viable path\nforward. In this study, we domain-adapt LLMs to the clinical domain and\ngenerate synthetic clinical texts that are machine-annotated with tags for\npersonally identifiable information using capable encoder-based NER models. The\nsynthetic corpora are then used to train synthetic NER models. The results show\nthat training NER models using synthetic corpora incurs only a small drop in\npredictive performance. The limits of this process are investigated in a\nsystematic ablation study -- using both Swedish and Spanish data. Our analysis\nshows that smaller datasets can be sufficient for domain-adapting LLMs for data\nsynthesis. Instead, the effectiveness of this process is almost entirely\ncontingent on the performance of the machine-annotating NER models trained\nusing the original data.",
      "tldr_zh": "该论文提出了一种数据受限的训练数据合成方法，用于敏感领域（如临床）的去识别（De-Identification），以解决隐私风险导致的真实数据集缺失问题。具体而言，通过将大型语言模型（LLMs）适应临床领域，生成合成临床文本，并使用基于编码器的NER模型进行机器标注，然后利用这些合成语料训练合成NER模型。结果显示，使用合成语料训练的NER模型仅导致微小性能下降，且该过程的有效性主要取决于原始数据训练的NER模型性能。通过对Swedish和Spanish数据的系统消融研究，论文发现较小数据集即可实现LLMs的领域适应，为数据合成提供高效路径。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Under review",
      "pdf_url": "http://arxiv.org/pdf/2502.14677v2",
      "published_date": "2025-02-20 16:09:27 UTC",
      "updated_date": "2025-02-21 16:58:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:27:17.239237"
    },
    {
      "arxiv_id": "2502.14676v2",
      "title": "BP-SGCN: Behavioral Pseudo-Label Informed Sparse Graph Convolution Network for Pedestrian and Heterogeneous Trajectory Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Ruochen Li",
        "Stamos Katsigiannis",
        "Tae-Kyun Kim",
        "Hubert P. H. Shum"
      ],
      "abstract": "Trajectory prediction allows better decision-making in applications of\nautonomous vehicles or surveillance by predicting the short-term future\nmovement of traffic agents. It is classified into pedestrian or heterogeneous\ntrajectory prediction. The former exploits the relatively consistent behavior\nof pedestrians, but is limited in real-world scenarios with heterogeneous\ntraffic agents such as cyclists and vehicles. The latter typically relies on\nextra class label information to distinguish the heterogeneous agents, but such\nlabels are costly to annotate and cannot be generalized to represent different\nbehaviors within the same class of agents. In this work, we introduce the\nbehavioral pseudo-labels that effectively capture the behavior distributions of\npedestrians and heterogeneous agents solely based on their motion features,\nsignificantly improving the accuracy of trajectory prediction. To implement the\nframework, we propose the Behavioral Pseudo-Label Informed Sparse Graph\nConvolution Network (BP-SGCN) that learns pseudo-labels and informs to a\ntrajectory predictor. For optimization, we propose a cascaded training scheme,\nin which we first learn the pseudo-labels in an unsupervised manner, and then\nperform end-to-end fine-tuning on the labels in the direction of increasing the\ntrajectory prediction accuracy. Experiments show that our pseudo-labels\neffectively model different behavior clusters and improve trajectory\nprediction. Our proposed BP-SGCN outperforms existing methods using both\npedestrian (ETH/UCY, pedestrian-only SDD) and heterogeneous agent datasets\n(SDD, Argoverse 1).",
      "tldr_zh": "本研究针对轨迹预测问题，引入Behavioral Pseudo-Label来基于运动特征捕获行人和异构代理（如车辆和自行车）的行为分布，从而解决传统方法依赖昂贵标签的局限。作者提出BP-SGCN框架，该框架通过无监督学习生成伪标签，并采用级联训练方案（先学习伪标签，再端到端微调）来提升预测准确性。实验结果显示，BP-SGCN在ETH/UCY、SDD和Argoverse 1等数据集上优于现有方法，显著改善了行人和异构代理的轨迹预测性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14676v2",
      "published_date": "2025-02-20 16:09:21 UTC",
      "updated_date": "2025-02-21 21:29:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:27:27.417511"
    },
    {
      "arxiv_id": "2502.14671v3",
      "title": "Explanations of Large Language Models Explain Language Representations in the Brain",
      "title_zh": "翻译失败",
      "authors": [
        "Maryam Rahimi",
        "Yadollah Yaghoobzadeh",
        "Mohammad Reza Daliri"
      ],
      "abstract": "Large language models (LLMs) not only exhibit human-like performance but also\nshare computational principles with the brain's language processing mechanisms.\nWhile prior research has focused on mapping LLMs' internal representations to\nneural activity, we propose a novel approach using explainable AI (XAI) to\nstrengthen this link. Applying attribution methods, we quantify the influence\nof preceding words on LLMs' next-word predictions and use these explanations to\npredict fMRI data from participants listening to narratives. We find that\nattribution methods robustly predict brain activity across the language\nnetwork, revealing a hierarchical pattern: explanations from early layers align\nwith the brain's initial language processing stages, while later layers\ncorrespond to more advanced stages. Additionally, layers with greater influence\non next-word prediction$\\unicode{x2014}$reflected in higher attribution\nscores$\\unicode{x2014}$demonstrate stronger brain alignment. These results\nunderscore XAI's potential for exploring the neural basis of language and\nsuggest brain alignment for assessing the biological plausibility of\nexplanation methods.",
      "tldr_zh": "本文研究发现，大型语言模型 (LLMs) 的解释方法能有效揭示大脑语言表示的机制，通过可解释 AI (XAI) 的归因方法量化前置单词对 LLMs 下个单词预测的影响，并成功预测参与者听故事时的 fMRI 数据。结果显示，归因方法在大脑语言网络中展现出层次化模式：LLMs 的早期层与大脑初始处理阶段对齐，而后期层对应高级阶段，且归因分数较高的层与大脑对齐更强。这些发现强调 XAI 在探索语言神经基础的潜力，并为评估解释方法的生物合理性提供新途径。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "q-bio.NC"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14671v3",
      "published_date": "2025-02-20 16:05:45 UTC",
      "updated_date": "2025-04-03 21:56:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:27:40.960963"
    },
    {
      "arxiv_id": "2502.15840v1",
      "title": "Vending-Bench: A Benchmark for Long-Term Coherence of Autonomous Agents",
      "title_zh": "Vending-Bench：自治代理长期连贯性的基准",
      "authors": [
        "Axel Backlund",
        "Lukas Petersson"
      ],
      "abstract": "While Large Language Models (LLMs) can exhibit impressive proficiency in\nisolated, short-term tasks, they often fail to maintain coherent performance\nover longer time horizons. In this paper, we present Vending-Bench, a simulated\nenvironment designed to specifically test an LLM-based agent's ability to\nmanage a straightforward, long-running business scenario: operating a vending\nmachine. Agents must balance inventories, place orders, set prices, and handle\ndaily fees - tasks that are each simple but collectively, over long horizons\n(>20M tokens per run) stress an LLM's capacity for sustained, coherent\ndecision-making. Our experiments reveal high variance in performance across\nmultiple LLMs: Claude 3.5 Sonnet and o3-mini manage the machine well in most\nruns and turn a profit, but all models have runs that derail, either through\nmisinterpreting delivery schedules, forgetting orders, or descending into\ntangential \"meltdown\" loops from which they rarely recover. We find no clear\ncorrelation between failures and the point at which the model's context window\nbecomes full, suggesting that these breakdowns do not stem from memory limits.\nApart from highlighting the high variance in performance over long time\nhorizons, Vending-Bench also tests models' ability to acquire capital, a\nnecessity in many hypothetical dangerous AI scenarios. We hope the benchmark\ncan help in preparing for the advent of stronger AI systems.",
      "tldr_zh": "本文提出 Vending-Bench，这是一个模拟基准，用于评估 Large Language Models (LLMs) 在长期任务中的连贯性，通过模拟管理自动售货机的场景，包括平衡库存、下订单、设置价格和处理日常费用。实验结果显示，不同 LLM 如 Claude 3.5 Sonnet 和 o3-mini 在超过 20M tokens 的运行中表现高度变异：这些模型在多数情况下能获利，但易出现误解交付时间表、忘记订单或进入“meltdown”循环等失败，且这些问题与上下文窗口满无关。该基准不仅突显了 LLM 长期决策的挑战，还测试了模型获取资本的能力，以帮助准备更强的 AI 系统。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.15840v1",
      "published_date": "2025-02-20 15:52:29 UTC",
      "updated_date": "2025-02-20 15:52:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:27:53.439520"
    },
    {
      "arxiv_id": "2502.14645v1",
      "title": "Edit Once, Update Everywhere: A Simple Framework for Cross-Lingual Knowledge Synchronization in LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Yuchen Wu",
        "Liang Ding",
        "Li Shen",
        "Dacheng Tao"
      ],
      "abstract": "Knowledge editing allows for efficient adaptation of large language models\n(LLMs) to new information or corrections without requiring full retraining.\nHowever, prior methods typically focus on either single-language editing or\nbasic multilingual editing, failing to achieve true cross-linguistic knowledge\nsynchronization. To address this, we present a simple and practical\nstate-of-the-art (SOTA) recipe Cross-Lingual Knowledge Democracy Edit (X-KDE),\ndesigned to propagate knowledge from a dominant language to other languages\neffectively. Our X-KDE comprises two stages: (i) Cross-lingual Edition\nInstruction Tuning (XE-IT), which fine-tunes the model on a curated parallel\ndataset to modify in-scope knowledge while preserving unrelated information,\nand (ii) Target-language Preference Optimization (TL-PO), which applies\nadvanced optimization techniques to ensure consistency across languages,\nfostering the transfer of updates. Additionally, we contribute a high-quality,\ncross-lingual dataset, specifically designed to enhance knowledge transfer\nacross languages. Extensive experiments on the Bi-ZsRE and MzsRE benchmarks\nshow that X-KDE significantly enhances cross-lingual performance, achieving an\naverage improvement of +8.19%, while maintaining high accuracy in monolingual\nsettings.",
      "tldr_zh": "该研究提出了一种简单框架X-KDE（Cross-Lingual Knowledge Democracy Edit），用于在大型语言模型（LLMs）中实现跨语言知识同步，仅需一次编辑即可更新所有语言。框架包括两个阶段：Cross-lingual Edition Instruction Tuning (XE-IT)，通过在平行数据集上微调模型来修改相关知识并保留无关信息；以及Target-language Preference Optimization (TL-PO)，应用高级优化技术确保语言间一致性。研究还贡献了一个高质量的跨语言数据集，并在Bi-ZsRE和MzsRE基准测试中，X-KDE实现了平均8.19%的性能提升，同时保持单语言设置的高准确率。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14645v1",
      "published_date": "2025-02-20 15:32:31 UTC",
      "updated_date": "2025-02-20 15:32:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:28:04.232612"
    },
    {
      "arxiv_id": "2502.14637v2",
      "title": "ReQFlow: Rectified Quaternion Flow for Efficient and High-Quality Protein Backbone Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Angxiao Yue",
        "Zichong Wang",
        "Hongteng Xu"
      ],
      "abstract": "Protein backbone generation plays a central role in de novo protein design\nand is significant for many biological and medical applications. Although\ndiffusion and flow-based generative models provide potential solutions to this\nchallenging task, they often generate proteins with undesired designability and\nsuffer computational inefficiency. In this study, we propose a novel rectified\nquaternion flow (ReQFlow) matching method for fast and high-quality protein\nbackbone generation. In particular, our method generates a local translation\nand a 3D rotation from random noise for each residue in a protein chain, which\nrepresents each 3D rotation as a unit quaternion and constructs its flow by\nspherical linear interpolation (SLERP) in an exponential format. We train the\nmodel by quaternion flow (QFlow) matching with guaranteed numerical stability\nand rectify the QFlow model to accelerate its inference and improve the\ndesignability of generated protein backbones, leading to the proposed ReQFlow\nmodel. Experiments show that ReQFlow achieves state-of-the-art performance in\nprotein backbone generation while requiring much fewer sampling steps and\nsignificantly less inference time (e.g., being 37x faster than RFDiffusion and\n62x faster than Genie2 when generating a backbone of length 300), demonstrating\nits effectiveness and efficiency. The code is available at\nhttps://github.com/AngxiaoYue/ReQFlow.",
      "tldr_zh": "本研究提出了一种名为ReQFlow的校正四元数流匹配方法，用于高效且高质量的蛋白质主链生成，以解决现有扩散和流模型在设计性和计算效率上的不足。该方法为每个残基从随机噪声生成局部平移和3D旋转，并使用单位四元数结合球形线性插值(SLERP)构建流模型，通过四元数流匹配(QFlow)训练并进行校正，以提升推理速度和生成蛋白的可用性。实验结果表明，ReQFlow在蛋白质主链生成中达到最先进性能，同时显著减少采样步骤和推理时间，例如生成长度300的主链时比RFDiffusion快37倍，比Genie2快62倍。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14637v2",
      "published_date": "2025-02-20 15:20:37 UTC",
      "updated_date": "2025-03-29 07:16:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:28:17.115247"
    },
    {
      "arxiv_id": "2502.15839v1",
      "title": "FedMobile: Enabling Knowledge Contribution-aware Multi-modal Federated Learning with Incomplete Modalities",
      "title_zh": "FedMobile：实现知识贡献感知的多模态联邦学习，处理不完整模态",
      "authors": [
        "Yi Liu",
        "Cong Wang",
        "Xingliang Yuan"
      ],
      "abstract": "The Web of Things (WoT) enhances interoperability across web-based and\nubiquitous computing platforms while complementing existing IoT standards. The\nmultimodal Federated Learning (FL) paradigm has been introduced to enhance WoT\nby enabling the fusion of multi-source mobile sensing data while preserving\nprivacy. However, a key challenge in mobile sensing systems using multimodal FL\nis modality incompleteness, where some modalities may be unavailable or only\npartially captured, potentially degrading the system's performance and\nreliability. Current multimodal FL frameworks typically train multiple unimodal\nFL subsystems or apply interpolation techniques on the node side to approximate\nmissing modalities. However, these approaches overlook the shared latent\nfeature space among incomplete modalities across different nodes and fail to\ndiscriminate against low-quality nodes. To address this gap, we present\nFedMobile, a new knowledge contribution-aware multimodal FL framework designed\nfor robust learning despite missing modalities. FedMobile prioritizes\nlocal-to-global knowledge transfer, leveraging cross-node multimodal feature\ninformation to reconstruct missing features. It also enhances system\nperformance and resilience to modality heterogeneity through rigorous node\ncontribution assessments and knowledge contribution-aware aggregation rules.\nEmpirical evaluations on five widely recognized multimodal benchmark datasets\ndemonstrate that FedMobile maintains robust learning even when up to 90% of\nmodality information is missing or when data from two modalities are randomly\nmissing, outperforming state-of-the-art baselines.",
      "tldr_zh": "该研究针对多模态 Federated Learning (FL) 在 Web of Things (WoT) 环境中的模态不完整性问题，提出 FedMobile 框架，以提升隐私保护下的多源移动感知数据融合。FedMobile 通过优先本地到全局知识转移，利用跨节点多模态特征信息重建缺失特征，并引入节点贡献评估和知识贡献感知聚合规则，提高系统对模态异质性的鲁棒性。实验结果显示，在五个多模态基准数据集上，即使缺失高达90%的模态信息或随机丢失两个模态，FedMobile 仍优于现有基线方法，显著提升了学习性能和可靠性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "The Web Conference 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.15839v1",
      "published_date": "2025-02-20 15:10:43 UTC",
      "updated_date": "2025-02-20 15:10:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:28:28.125531"
    },
    {
      "arxiv_id": "2502.14627v2",
      "title": "ATRI: Mitigating Multilingual Audio Text Retrieval Inconsistencies by Reducing Data Distribution Errors",
      "title_zh": "ATRI：通过减少数据分布错误缓解多语言音频",
      "authors": [
        "Yuguo Yin",
        "Yuxin Xie",
        "Wenyuan Yang",
        "Dongchao Yang",
        "Jinghan Ru",
        "Xianwei Zhuang",
        "Liming Liang",
        "Yuexian Zou"
      ],
      "abstract": "Multilingual audio-text retrieval (ML-ATR) is a challenging task that aims to\nretrieve audio clips or multilingual texts from databases. However, existing\nML-ATR schemes suffer from inconsistencies for instance similarity matching\nacross languages. We theoretically analyze the inconsistency in terms of both\nmultilingual modal alignment direction error and weight error, and propose the\ntheoretical weight error upper bound for quantifying the inconsistency. Based\non the analysis of the weight error upper bound, we find that the inconsistency\nproblem stems from the data distribution error caused by random sampling of\nlanguages. We propose a consistent ML-ATR scheme using 1-to-k contrastive\nlearning and audio-English co-anchor contrastive learning, aiming to mitigate\nthe negative impact of data distribution error on recall and consistency in\nML-ATR. Experimental results on the translated AudioCaps and Clotho datasets\nshow that our scheme achieves state-of-the-art performance on recall and\nconsistency metrics for eight mainstream languages, including English. Our code\nwill be available at https://github.com/ATRI-ACL/ATRI-ACL.",
      "tldr_zh": "本研究针对多语言音频文本检索（ML-ATR）中的一致性问题，如跨语言相似性匹配不一致，进行了理论分析，识别出多语言模态对齐方向错误和权重错误，并提出了权重错误上界来量化这些不一致性。论文发现这些问题源于数据分布错误（由随机语言采样引起），并提出了一种新方案，使用1-to-k对比学习和音频-English共同锚对比学习来减少数据分布错误对召回和一致性的负面影响。在翻译后的AudioCaps和Clotho数据集上实验，该方案在八种主流语言（包括英语）上实现了最先进的召回和一致性性能。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14627v2",
      "published_date": "2025-02-20 15:06:15 UTC",
      "updated_date": "2025-02-22 09:13:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:28:39.506020"
    },
    {
      "arxiv_id": "2502.14620v1",
      "title": "Exploring RWKV for Sentence Embeddings: Layer-wise Analysis and Baseline Comparison for Semantic Similarity",
      "title_zh": "翻译失败",
      "authors": [
        "Xinghan Pan"
      ],
      "abstract": "This paper investigates the efficacy of RWKV, a novel language model\narchitecture known for its linear attention mechanism, for generating sentence\nembeddings in a zero-shot setting. I conduct a layer-wise analysis to evaluate\nthe semantic similarity captured by embeddings from different hidden layers of\na pre-trained RWKV model. The performance is assessed on the Microsoft Research\nParaphrase Corpus (MRPC) dataset using Spearman correlation and compared\nagainst a GloVe-based baseline. My results indicate that while RWKV embeddings\ncapture some semantic relatedness, they underperform compared to the GloVe\nbaseline in terms of Spearman correlation. I also analyze the inference time\nand GPU memory usage, highlighting the computational trade-offs associated with\nRWKV embeddings. The findings suggest that while RWKV offers potential\nadvantages in terms of linear scaling, its zero-shot sentence embedding quality\nfor semantic similarity tasks requires further investigation and potential\ntask-specific fine-tuning to match or exceed simpler baselines.",
      "tldr_zh": "这篇论文探索了 RWKV 模型（一种具有线性注意力机制的语言模型）在零样本设置下生成句子嵌入的效能，通过层级分析评估其不同隐藏层的语义相似性表现。作者使用 Microsoft Research Paraphrase Corpus (MRPC) 数据集，通过 Spearman correlation 与 GloVe 基线进行比较，结果显示 RWKV 嵌入虽能捕捉部分语义相关性，但整体性能不如 GloVe 基线。论文还分析了 RWKV 的推理时间和 GPU 内存使用，突出了其在计算效率上的权衡。总体而言，该研究表明 RWKV 在线性缩放方面有潜力，但其零-shot 句子嵌入质量需进一步调查和任务特定微调才能超越简单基线。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.7; I.7.3"
      ],
      "primary_category": "cs.CL",
      "comment": "17 pages, 3 tables, preprint on ArXiV, includes detailed analysis of\n  RWKV for semantic similarity tasks",
      "pdf_url": "http://arxiv.org/pdf/2502.14620v1",
      "published_date": "2025-02-20 14:58:37 UTC",
      "updated_date": "2025-02-20 14:58:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:28:54.381147"
    },
    {
      "arxiv_id": "2502.14619v1",
      "title": "Reward Models Identify Consistency, Not Causality",
      "title_zh": "奖励模型识别一致性，而非因果性",
      "authors": [
        "Yuhui Xu",
        "Hanze Dong",
        "Lei Wang",
        "Caiming Xiong",
        "Junnan Li"
      ],
      "abstract": "Reward models (RMs) play a crucial role in aligning large language models\n(LLMs) with human preferences and enhancing reasoning quality. Traditionally,\nRMs are trained to rank candidate outputs based on their correctness and\ncoherence. However, in this work, we present several surprising findings that\nchallenge common assumptions about RM behavior. Our analysis reveals that\nstate-of-the-art reward models prioritize structural consistency over causal\ncorrectness. Specifically, removing the problem statement has minimal impact on\nreward scores, whereas altering numerical values or disrupting the reasoning\nflow significantly affects RM outputs. Furthermore, RMs exhibit a strong\ndependence on complete reasoning trajectories truncated or incomplete steps\nlead to significant variations in reward assignments, indicating that RMs\nprimarily rely on learned reasoning patterns rather than explicit problem\ncomprehension. These findings hold across multiple architectures, datasets, and\ntasks, leading to three key insights: (1) RMs primarily assess coherence rather\nthan true reasoning quality; (2) The role of explicit problem comprehension in\nreward assignment is overstated; (3) Current RMs may be more effective at\nranking responses than verifying logical validity. Our results suggest a\nfundamental limitation in existing reward modeling approaches, emphasizing the\nneed for a shift toward causality-aware reward models that go beyond\nconsistency-driven evaluation.",
      "tldr_zh": "该研究揭示了奖励模型（Reward Models, RMs）在训练大型语言模型（Large Language Models, LLMs）时，更注重结构一致性而非因果正确性，通过实验分析发现，移除问题语句对RMs分数影响甚微，但改变数值或中断推理流程会显著改变输出。RMs强烈依赖完整的推理轨迹，截断步骤会导致奖励分配波动，表明它们主要依赖学得的推理模式而非真正的问题理解。这些发现适用于多种架构、数据集和任务，并得出三点关键洞见：RMs更评估连贯性而非推理质量、问题理解的作用被夸大，以及RMs更适合排名响应而非验证逻辑有效性。该论文强调，需要开发更注重因果性的奖励模型来克服现有方法的局限性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "16 pages",
      "pdf_url": "http://arxiv.org/pdf/2502.14619v1",
      "published_date": "2025-02-20 14:57:14 UTC",
      "updated_date": "2025-02-20 14:57:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:29:07.338360"
    },
    {
      "arxiv_id": "2502.15838v1",
      "title": "A novel approach to the relationships between data features -- based on comprehensive examination of mathematical, technological, and causal methodology",
      "title_zh": "翻译失败",
      "authors": [
        "JaeHong Kim"
      ],
      "abstract": "The expansion of artificial intelligence (AI) has raised concerns about\ntransparency, accountability, and interpretability, with counterfactual\nreasoning emerging as a key approach to addressing these issues. However,\ncurrent mathematical, technological, and causal methodologies rely on\nexternalization techniques that normalize feature relationships within a single\ncoordinate space, often distorting intrinsic interactions. This study proposes\nthe Convergent Fusion Paradigm (CFP) theory, a framework integrating\nmathematical, technological, and causal perspectives to provide a more precise\nand comprehensive analysis of feature relationships. CFP theory introduces\nHilbert space and backward causation to reinterpret the feature relationships\nas emergent structures, offering a potential solution to the common cause\nproblem -- a fundamental challenge in causal modeling. From a mathematical --\ntechnical perspective, it utilizes a Riemannian manifold-based framework,\nthereby improving the structural representation of high- and low-dimensional\ndata interactions. From a causal inference perspective, CFP theory adopts\nabduction as a methodological foundation, employing Hilbert space for a dynamic\ncausal reasoning approach, where causal relationships are inferred abductively,\nand feature relationships evolve as emergent properties. Ultimately, CFP theory\nintroduces a novel AI modeling methodology that integrates Hilbert space,\nbackward causation, and Riemannian geometry, strengthening AI governance and\ntransparency in counterfactual reasoning.",
      "tldr_zh": "本研究针对人工智能（AI）中特征关系的分析提出了一种新方法，旨在解决当前数学、技术和因果方法依赖外部化技术而导致的内在互动扭曲问题。论文引入 Convergent Fusion Paradigm (CFP) 理论，这是一个整合数学、技术和因果视角的框架，利用 Hilbert space 和 backward causation 将特征关系视为涌现结构，从而有效解决 common cause problem。CFP 理论从数学-技术角度采用 Riemannian manifold 框架，提升高维和低维数据互动的结构表示；从因果推理角度，以 abduction 为基础，通过 Hilbert space 实现动态因果推理，使特征关系演变为涌现属性。最终，这种新 AI 建模方法增强了 AI 在反事实推理（counterfactual reasoning）中的治理和透明性。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "68T27 (Primary) 00A30, 03A05 (Secondary)",
        "I.2.3; F.4.1"
      ],
      "primary_category": "cs.AI",
      "comment": "59 pages, 6 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2502.15838v1",
      "published_date": "2025-02-20 14:36:37 UTC",
      "updated_date": "2025-02-20 14:36:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:29:19.705868"
    },
    {
      "arxiv_id": "2502.14583v1",
      "title": "A Theory for Conditional Generative Modeling on Multiple Data Sources",
      "title_zh": "翻译失败",
      "authors": [
        "Rongzhen Wang",
        "Yan Zhang",
        "Chenyu Zheng",
        "Chongxuan Li",
        "Guoqiang Wu"
      ],
      "abstract": "The success of large generative models has driven a paradigm shift,\nleveraging massive multi-source data to enhance model capabilities. However,\nthe interaction among these sources remains theoretically underexplored. This\npaper takes the first step toward a rigorous analysis of multi-source training\nin conditional generative modeling, where each condition represents a distinct\ndata source. Specifically, we establish a general distribution estimation error\nbound in average total variation distance for conditional maximum likelihood\nestimation based on the bracketing number. Our result shows that when source\ndistributions share certain similarities and the model is expressive enough,\nmulti-source training guarantees a sharper bound than single-source training.\nWe further instantiate the general theory on conditional Gaussian estimation\nand deep generative models including autoregressive and flexible energy-based\nmodels, by characterizing their bracketing numbers. The results highlight that\nthe number of sources and similarity among source distributions improve the\nadvantage of multi-source training. Simulations and real-world experiments\nvalidate our theory. Code is available at:\n\\url{https://github.com/ML-GSAI/Multi-Source-GM}.",
      "tldr_zh": "这篇论文针对条件生成建模（conditional generative modeling）在多源数据上的训练，首次建立了严格的理论分析框架。研究者通过基于bracketing number的条件最大似然估计（maximum likelihood estimation），推导出了平均总变异距离（total variation distance）的分布估计误差界，结果表明，当源分布具有相似性和模型足够 expressive 时，多源训练比单源训练提供更精确的界限。该理论被具体应用到条件高斯估计（conditional Gaussian estimation）和深度生成模型（如autoregressive models和energy-based models）中，实验模拟与真实数据验证了源数量及分布相似性对多源训练优势的提升。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "35 pages",
      "pdf_url": "http://arxiv.org/pdf/2502.14583v1",
      "published_date": "2025-02-20 14:13:24 UTC",
      "updated_date": "2025-02-20 14:13:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:29:30.709964"
    },
    {
      "arxiv_id": "2502.14581v2",
      "title": "A Statistical Case Against Empirical Human-AI Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Julian Rodemann",
        "Esteban Garces Arias",
        "Christoph Luther",
        "Christoph Jansen",
        "Thomas Augustin"
      ],
      "abstract": "Empirical human-AI alignment aims to make AI systems act in line with\nobserved human behavior. While noble in its goals, we argue that empirical\nalignment can inadvertently introduce statistical biases that warrant caution.\nThis position paper thus advocates against naive empirical alignment, offering\nprescriptive alignment and a posteriori empirical alignment as alternatives. We\nsubstantiate our principled argument by tangible examples like human-centric\ndecoding of language models.",
      "tldr_zh": "该论文质疑了 empirical human-AI alignment 的做法，认为它旨在使AI系统模仿人类行为，但可能无意中引入统计偏差，从而导致潜在风险。该研究通过理论论据和实际例子（如 human-centric decoding）证明，naive empirical alignment 不宜直接采用，并建议采用 prescriptive alignment 和 a posteriori empirical alignment 作为更可靠的替代方案。这种立场强调了在AI对齐中需要更谨慎的统计考虑，以避免偏差问题。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "stat.OT"
      ],
      "primary_category": "cs.AI",
      "comment": "24 pages, 2 figures, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2502.14581v2",
      "published_date": "2025-02-20 14:12:18 UTC",
      "updated_date": "2025-05-12 09:51:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:29:41.519301"
    },
    {
      "arxiv_id": "2502.14572v1",
      "title": "Factor Graph-based Interpretable Neural Networks",
      "title_zh": "基于因子图的可解释神经网络",
      "authors": [
        "Yicong Li",
        "Kuanjiu Zhou",
        "Shuo Yu",
        "Qiang Zhang",
        "Renqiang Luo",
        "Xiaodong Li",
        "Feng Xia"
      ],
      "abstract": "Comprehensible neural network explanations are foundations for a better\nunderstanding of decisions, especially when the input data are infused with\nmalicious perturbations. Existing solutions generally mitigate the impact of\nperturbations through adversarial training, yet they fail to generate\ncomprehensible explanations under unknown perturbations. To address this\nchallenge, we propose AGAIN, a fActor GrAph-based Interpretable neural Network,\nwhich is capable of generating comprehensible explanations under unknown\nperturbations. Instead of retraining like previous solutions, the proposed\nAGAIN directly integrates logical rules by which logical errors in explanations\nare identified and rectified during inference. Specifically, we construct the\nfactor graph to express logical rules between explanations and categories. By\ntreating logical rules as exogenous knowledge, AGAIN can identify\nincomprehensible explanations that violate real-world logic. Furthermore, we\npropose an interactive intervention switch strategy rectifying explanations\nbased on the logical guidance from the factor graph without learning\nperturbations, which overcomes the inherent limitation of adversarial\ntraining-based methods in defending only against known perturbations.\nAdditionally, we theoretically demonstrate the effectiveness of employing\nfactor graph by proving that the comprehensibility of explanations is strongly\ncorrelated with factor graph. Extensive experiments are conducted on three\ndatasets and experimental results illustrate the superior performance of AGAIN\ncompared to state-of-the-art baselines.",
      "tldr_zh": "本研究提出 AGAIN，一种基于 Factor Graph 的可解释神经网络框架，旨在解决现有模型在面对未知扰动时无法生成可理解解释的问题。AGAIN 通过整合逻辑规则构建 Factor Graph 来表达解释与类别间的逻辑关系，并在推理过程中识别并修正违反真实世界逻辑的解释，同时引入交互式干预切换策略来修正解释，而无需依赖对抗训练学习扰动。该方法理论上证明了 Factor Graph 与解释可理解性的强相关性，并在三个数据集上的实验中，展示了 AGAIN 比现有基线模型具有显著优越性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "The Thirteenth International Conference on Learning Representations",
      "pdf_url": "http://arxiv.org/pdf/2502.14572v1",
      "published_date": "2025-02-20 13:56:21 UTC",
      "updated_date": "2025-02-20 13:56:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:29:55.097922"
    },
    {
      "arxiv_id": "2502.14563v1",
      "title": "Plan-over-Graph: Towards Parallelable LLM Agent Schedule",
      "title_zh": "翻译失败",
      "authors": [
        "Shiqi Zhang",
        "Xinbei Ma",
        "Zouying Cao",
        "Zhuosheng Zhang",
        "Hai Zhao"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated exceptional abilities in\nreasoning for task planning. However, challenges remain under-explored for\nparallel schedules. This paper introduces a novel paradigm, plan-over-graph, in\nwhich the model first decomposes a real-life textual task into executable\nsubtasks and constructs an abstract task graph. The model then understands this\ntask graph as input and generates a plan for parallel execution. To enhance the\nplanning capability of complex, scalable graphs, we design an automated and\ncontrollable pipeline to generate synthetic graphs and propose a two-stage\ntraining scheme. Experimental results show that our plan-over-graph method\nsignificantly improves task performance on both API-based LLMs and trainable\nopen-sourced LLMs. By normalizing complex tasks as graphs, our method naturally\nsupports parallel execution, demonstrating global efficiency. The code and data\nare available at https://github.com/zsq259/Plan-over-Graph.",
      "tldr_zh": "该论文提出了一种名为“plan-over-graph”的新范式，旨在提升大型语言模型（LLMs）在任务规划中的并行调度能力。具体而言，该方法首先将真实文本任务分解为可执行子任务并构建抽象任务图，然后基于该任务图生成并行执行计划；同时，通过设计自动化管道生成合成图和两阶段训练方案来增强模型处理复杂图的能力。实验结果显示，该方法显著提高了API-based LLMs和开源LLMs的任务性能，支持自然并行执行，从而提升全局效率。代码和数据已在GitHub上公开。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14563v1",
      "published_date": "2025-02-20 13:47:51 UTC",
      "updated_date": "2025-02-20 13:47:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:30:07.452034"
    },
    {
      "arxiv_id": "2502.14560v2",
      "title": "Less is More: Improving LLM Alignment via Preference Data Selection",
      "title_zh": "少即是多：通过偏好数据选择改善LLM对齐",
      "authors": [
        "Xun Deng",
        "Han Zhong",
        "Rui Ai",
        "Fuli Feng",
        "Zheng Wang",
        "Xiangnan He"
      ],
      "abstract": "Direct Preference Optimization (DPO) has emerged as a promising approach for\naligning large language models with human preferences. While prior work mainly\nextends DPO from the aspect of the objective function, we instead improve DPO\nfrom the largely overlooked but critical aspect of data selection.\nSpecifically, we address the issue of parameter shrinkage caused by noisy data\nby proposing a novel margin-maximization principle for dataset curation in DPO\ntraining. To accurately estimate margins for data selection, we propose a\ndual-margin guided approach that considers both external reward margins and\nimplicit DPO reward margins. Extensive experiments demonstrate that our method\nreduces computational cost dramatically while improving performance.\nRemarkably, by using just 10\\% of the Ultrafeedback dataset, our approach\nachieves 3\\% to 8\\% improvements across various Llama and Mistral series models\non the AlpacaEval 2.0 benchmark. Furthermore, our approach seamlessly extends\nto iterative DPO, yielding a roughly 3\\% improvement with 25\\% online data,\nwhile further reducing training time. These results highlight the potential of\ndata selection strategies for advancing preference optimization.",
      "tldr_zh": "该论文提出了一种通过数据选择改进Direct Preference Optimization (DPO)的方法，以解决噪声数据导致的参数收缩问题。具体而言，他们引入了基于margin-maximization原则的数据集整理策略，并提出dual-margin guided approach来精确估计外部奖励margins和隐式DPO奖励margins，从而减少计算成本。实验结果显示，使用仅10%的Ultrafeedback数据集，该方法在AlpacaEval 2.0基准上使Llama和Mistral系列模型性能提升3%至8%；此外，其扩展到iterative DPO时，仅用25%的在线数据即可实现约3%的改进，同时显著缩短训练时间。这些发现突显了数据选择策略在偏好优化中的巨大潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14560v2",
      "published_date": "2025-02-20 13:45:17 UTC",
      "updated_date": "2025-02-22 12:15:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:30:18.769687"
    },
    {
      "arxiv_id": "2502.14558v3",
      "title": "Model Inversion Attack against Federated Unlearning",
      "title_zh": "翻译失败",
      "authors": [
        "Lei Zhou",
        "Youwen Zhu"
      ],
      "abstract": "With the introduction of regulations related to the ``right to be forgotten\",\nfederated learning (FL) is facing new privacy compliance challenges. To address\nthese challenges, researchers have proposed federated unlearning (FU). However,\nexisting FU research has primarily focused on improving the efficiency of\nunlearning, with less attention paid to the potential privacy vulnerabilities\ninherent in these methods. To address this gap, we draw inspiration from\ngradient inversion attacks in FL and propose the federated unlearning inversion\nattack (FUIA). The FUIA is specifically designed for the three types of FU\n(sample unlearning, client unlearning, and class unlearning), aiming to provide\na comprehensive analysis of the privacy leakage risks associated with FU. In\nFUIA, the server acts as an honest-but-curious attacker, recording and\nexploiting the model differences before and after unlearning to expose the\nfeatures and labels of forgotten data. FUIA significantly leaks the privacy of\nforgotten data and can target all types of FU. This attack contradicts the goal\nof FU to eliminate specific data influence, instead exploiting its\nvulnerabilities to recover forgotten data and expose its privacy flaws.\nExtensive experimental results show that FUIA can effectively reveal the\nprivate information of forgotten data. To mitigate this privacy leakage, we\nalso explore two potential defense methods, although these come at the cost of\nreduced unlearning effectiveness and the usability of the unlearned model.",
      "tldr_zh": "该论文提出了一种针对联邦遗忘（Federated Unlearning, FU）的模型逆向攻击（Model Inversion Attack），即联邦遗忘逆向攻击（Federated Unlearning Inversion Attack, FUIA），旨在分析FU在处理“被遗忘权”法规时的隐私泄露风险。FUIA针对三种FU类型（样本遗忘、客户端遗忘和类遗忘），由服务器作为诚实但好奇的攻击者，利用遗忘前后模型差异来恢复遗忘数据的特征和标签，从而暴露其隐私。实验结果显示，FUIA能有效泄露遗忘数据的私有信息，但这与FU消除数据影响的目标相悖。最后，论文探讨了两种潜在防御方法，尽管这些方法会降低FU的有效性和模型可用性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14558v3",
      "published_date": "2025-02-20 13:38:36 UTC",
      "updated_date": "2025-04-08 15:54:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:30:31.316041"
    },
    {
      "arxiv_id": "2502.14553v1",
      "title": "Multiscale Byte Language Models -- A Hierarchical Architecture for Causal Million-Length Sequence Modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Eric Egli",
        "Matteo Manica",
        "Jannis Born"
      ],
      "abstract": "Bytes form the basis of the digital world and thus are a promising building\nblock for multimodal foundation models. Recently, Byte Language Models (BLMs)\nhave emerged to overcome tokenization, yet the excessive length of bytestreams\nrequires new architectural paradigms. Therefore, we present the Multiscale Byte\nLanguage Model (MBLM), a model-agnostic hierarchical decoder stack that allows\ntraining with context windows of $5$M bytes on single GPU in full model\nprecision. We thoroughly examine MBLM's performance with Transformer and Mamba\nblocks on both unimodal and multimodal tasks. Our experiments demonstrate that\nhybrid architectures are efficient in handling extremely long byte sequences\nduring training while achieving near-linear generational efficiency. To the\nbest of our knowledge, we present the first evaluation of BLMs on visual Q\\&A\ntasks and find that, despite serializing images and the absence of an encoder,\na MBLM with pure next token prediction can match custom CNN-LSTM architectures\nwith designated classification heads. We show that MBLMs exhibit strong\nadaptability in integrating diverse data representations, including pixel and\nimage filestream bytes, underlining their potential toward omnimodal foundation\nmodels. Source code is publicly available at:\nhttps://github.com/ai4sd/multiscale-byte-lm",
      "tldr_zh": "本文提出Multiscale Byte Language Model (MBLM)，一种模型无关的层次化解码器架构，用于处理百万长度字节序列的因果建模，支持在单GPU上训练5M字节的上下文窗口。MBLM结合Transformer和Mamba块，在单模态和多模态任务上表现出高效的训练性能和近线性生成效率。实验结果显示，MBLM在视觉Q&A任务上能匹配自定义CNN-LSTM架构，且在整合像素和图像文件流字节等数据表示方面展现出强适应性，凸显其向全模式基础模型发展的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Under Review",
      "pdf_url": "http://arxiv.org/pdf/2502.14553v1",
      "published_date": "2025-02-20 13:31:50 UTC",
      "updated_date": "2025-02-20 13:31:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:30:43.538823"
    },
    {
      "arxiv_id": "2502.15836v1",
      "title": "Soft Token Attacks Cannot Reliably Audit Unlearning in Large Language Models",
      "title_zh": "软标记攻击无法可靠地审计大型语言模型中的遗忘",
      "authors": [
        "Haokun Chen",
        "Sebastian Szyller",
        "Weilin Xu",
        "Nageen Himayat"
      ],
      "abstract": "Large language models (LLMs) have become increasingly popular. Their emergent\ncapabilities can be attributed to their massive training datasets. However,\nthese datasets often contain undesirable or inappropriate content, e.g.,\nharmful texts, personal information, and copyrighted material. This has\npromoted research into machine unlearning that aims to remove information from\ntrained models. In particular, approximate unlearning seeks to achieve\ninformation removal by strategically editing the model rather than complete\nmodel retraining.\n  Recent work has shown that soft token attacks (STA) can successfully extract\npurportedly unlearned information from LLMs, thereby exposing limitations in\ncurrent unlearning methodologies. In this work, we reveal that STAs are an\ninadequate tool for auditing unlearning. Through systematic evaluation on\ncommon unlearning benchmarks (Who Is Harry Potter? and TOFU), we demonstrate\nthat such attacks can elicit any information from the LLM, regardless of (1)\nthe deployed unlearning algorithm, and (2) whether the queried content was\noriginally present in the training corpus. Furthermore, we show that STA with\njust a few soft tokens (1-10) can elicit random strings over 400-characters\nlong. Thus showing that STAs are too powerful, and misrepresent the\neffectiveness of the unlearning methods.\n  Our work highlights the need for better evaluation baselines, and more\nappropriate auditing tools for assessing the effectiveness of unlearning in\nLLMs.",
      "tldr_zh": "这篇论文质疑 soft token attacks (STA) 在审计大型语言模型 (LLMs) 的机器 unlearning 方面的可靠性，指出 STA 可能过度强大而非可靠工具。研究通过在 Who Is Harry Potter? 和 TOFU 等基准上的系统评估，发现 STA 可以从 LLMs 中提取任何信息，无论采用何种 unlearning 算法（如 approximate unlearning），或内容是否原本在训练语料中。进一步结果显示，仅使用1-10个 soft tokens，STA 就能生成超过400字符的随机字符串，从而误导对 unlearning 方法有效性的判断。论文强调，需要开发更合适的评估基准和审计工具，以更好地评估 LLMs 中的信息移除效果。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.15836v1",
      "published_date": "2025-02-20 13:22:33 UTC",
      "updated_date": "2025-02-20 13:22:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:30:56.007800"
    },
    {
      "arxiv_id": "2502.14546v1",
      "title": "Position: Graph Learning Will Lose Relevance Due To Poor Benchmarks",
      "title_zh": "翻译失败",
      "authors": [
        "Maya Bechler-Speicher",
        "Ben Finkelshtein",
        "Fabrizio Frasca",
        "Luis Müller",
        "Jan Tönshoff",
        "Antoine Siraudin",
        "Viktor Zaverkin",
        "Michael M. Bronstein",
        "Mathias Niepert",
        "Bryan Perozzi",
        "Mikhail Galkin",
        "Christopher Morris"
      ],
      "abstract": "While machine learning on graphs has demonstrated promise in drug design and\nmolecular property prediction, significant benchmarking challenges hinder its\nfurther progress and relevance. Current benchmarking practices often lack focus\non transformative, real-world applications, favoring narrow domains like\ntwo-dimensional molecular graphs over broader, impactful areas such as\ncombinatorial optimization, relational databases, or chip design. Additionally,\nmany benchmark datasets poorly represent the underlying data, leading to\ninadequate abstractions and misaligned use cases. Fragmented evaluations and an\nexcessive focus on accuracy further exacerbate these issues, incentivizing\noverfitting rather than fostering generalizable insights. These limitations\nhave prevented the development of truly useful graph foundation models. This\nposition paper calls for a paradigm shift toward more meaningful benchmarks,\nrigorous evaluation protocols, and stronger collaboration with domain experts\nto drive impactful and reliable advances in graph learning research, unlocking\nthe potential of graph learning.",
      "tldr_zh": "这篇观点论文（position paper）指出，图学习（graph learning）在药物设计和分子属性预测等领域虽有潜力，但由于基准测试（benchmarks）问题而可能失去相关性。当前基准测试过度关注狭窄领域如二维分子图（two-dimensional molecular graphs），忽略更广泛的应用（如组合优化、关系数据库或芯片设计），并因数据集不代表真实数据、评估碎片化和过度强调准确率而导致过度拟合（overfitting）和缺乏可泛化洞见。这些问题阻碍了真正有用图基础模型（graph foundation models）的发展，论文呼吁通过更具意义的基准测试、更严格的评估协议以及与领域专家的紧密合作，来推动图学习研究的可靠进展。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14546v1",
      "published_date": "2025-02-20 13:21:47 UTC",
      "updated_date": "2025-02-20 13:21:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:31:09.144379"
    },
    {
      "arxiv_id": "2502.14529v1",
      "title": "CORBA: Contagious Recursive Blocking Attacks on Multi-Agent Systems Based on Large Language Models",
      "title_zh": "CORBA：针对基于大型语言模型的多智能体系统的传染性递归阻塞攻击",
      "authors": [
        "Zhenhong Zhou",
        "Zherui Li",
        "Jie Zhang",
        "Yuanhe Zhang",
        "Kun Wang",
        "Yang Liu",
        "Qing Guo"
      ],
      "abstract": "Large Language Model-based Multi-Agent Systems (LLM-MASs) have demonstrated\nremarkable real-world capabilities, effectively collaborating to complete\ncomplex tasks. While these systems are designed with safety mechanisms, such as\nrejecting harmful instructions through alignment, their security remains\nlargely unexplored. This gap leaves LLM-MASs vulnerable to targeted\ndisruptions. In this paper, we introduce Contagious Recursive Blocking Attacks\n(Corba), a novel and simple yet highly effective attack that disrupts\ninteractions between agents within an LLM-MAS. Corba leverages two key\nproperties: its contagious nature allows it to propagate across arbitrary\nnetwork topologies, while its recursive property enables sustained depletion of\ncomputational resources. Notably, these blocking attacks often involve\nseemingly benign instructions, making them particularly challenging to mitigate\nusing conventional alignment methods. We evaluate Corba on two widely-used\nLLM-MASs, namely, AutoGen and Camel across various topologies and commercial\nmodels. Additionally, we conduct more extensive experiments in open-ended\ninteractive LLM-MASs, demonstrating the effectiveness of Corba in complex\ntopology structures and open-source models. Our code is available at:\nhttps://github.com/zhrli324/Corba.",
      "tldr_zh": "本研究探讨了基于大型语言模型的多智能体系统(LLM-MASs)的安全漏洞，提出了一种新型攻击方法：Contagious Recursive Blocking Attacks (Corba)。Corba 利用其传染性和递归性，通过看似无害的指令在代理间传播并持续耗尽计算资源，从而破坏系统互动，且难以用传统对齐方法缓解。在 AutoGen 和 Camel 等系统上进行的实验评估显示，Corba 在各种拓扑结构和模型中表现出高度有效性，并提供了开源代码以供进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14529v1",
      "published_date": "2025-02-20 13:02:00 UTC",
      "updated_date": "2025-02-20 13:02:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:31:20.228980"
    },
    {
      "arxiv_id": "2502.14525v1",
      "title": "Small Graph Is All You Need: DeepStateGNN for Scalable Traffic Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Yannick Wölker",
        "Arash Hajisafi",
        "Cyrus Shahabi",
        "Matthias Renz"
      ],
      "abstract": "We propose a novel Graph Neural Network (GNN) model, named DeepStateGNN, for\nanalyzing traffic data, demonstrating its efficacy in two critical tasks:\nforecasting and reconstruction. Unlike typical GNN methods that treat each\ntraffic sensor as an individual graph node, DeepStateGNN clusters sensors into\nhigher-level graph nodes, dubbed Deep State Nodes, based on various similarity\ncriteria, resulting in a fixed number of nodes in a Deep State graph. The term\n\"Deep State\" nodes is a play on words, referencing hidden networks of power\nthat, like these nodes, secretly govern traffic independently of visible\nsensors. These Deep State Nodes are defined by several similarity factors,\nincluding spatial proximity (e.g., sensors located nearby in the road network),\nfunctional similarity (e.g., sensors on similar types of freeways), and\nbehavioral similarity under specific conditions (e.g., traffic behavior during\nrain). This clustering approach allows for dynamic and adaptive node grouping,\nas sensors can belong to multiple clusters and clusters may evolve over time.\nOur experimental results show that DeepStateGNN offers superior scalability and\nfaster training, while also delivering more accurate results than competitors.\nIt effectively handles large-scale sensor networks, outperforming other methods\nin both traffic forecasting and reconstruction accuracy.",
      "tldr_zh": "本文提出了一种新型 Graph Neural Network (GNN) 模型 DeepStateGNN，用于交通数据分析的预测和重建任务。不同于传统方法将每个传感器视为独立节点，DeepStateGNN 通过基于空间接近性（如道路网络位置）、功能相似性（如道路类型）和行为相似性（如雨天交通模式）的聚类，形成固定数量的 Deep State Nodes，实现动态自适应的节点分组，从而提升模型的可伸缩性。实验结果显示，DeepStateGNN 在大规模传感器网络上比竞争方法更准确、更高效，在交通预测和重建准确性方面表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Yannick W\\\"olker and Arash Hajisafi contributed equally to this work",
      "pdf_url": "http://arxiv.org/pdf/2502.14525v1",
      "published_date": "2025-02-20 13:00:31 UTC",
      "updated_date": "2025-02-20 13:00:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:31:32.408739"
    },
    {
      "arxiv_id": "2502.15835v2",
      "title": "Pragmatic Reasoning improves LLM Code Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Zhuchen Cao",
        "Sven Apel",
        "Adish Singla",
        "Vera Demberg"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated impressive potential in\ntranslating natural language (NL) instructions into program code. However, user\ninstructions often contain inherent ambiguities, making it challenging for LLMs\nto generate code that accurately reflects the user's true intent. To address\nthis challenge, researchers have proposed to produce multiple candidates of the\nprogram code and then rerank them to identify the best solution. In this paper,\nwe propose CodeRSA, a novel code candidate reranking mechanism built upon the\nRational Speech Act (RSA) framework, designed to guide LLMs toward more\ncomprehensive pragmatic reasoning about user intent. We evaluate CodeRSA using\none of the latest LLMs on a popular code generation dataset. Our experiment\nresults show that CodeRSA consistently outperforms common baselines, surpasses\nthe state-of-the-art approach in most cases, and demonstrates robust overall\nperformance. These findings underscore the effectiveness of integrating\npragmatic reasoning into code candidate reranking, offering a promising\ndirection for enhancing code generation quality in LLMs.",
      "tldr_zh": "该研究针对大型语言模型（LLMs）在将自然语言指令转化为程序代码时面临的指令模糊性问题，提出了一种名为CodeRSA的创新代码候选重新排序机制。CodeRSA基于Rational Speech Act (RSA)框架，引导LLMs进行更全面的语用推理（pragmatic reasoning），从而更好地理解用户意图并提升代码生成准确性。在流行代码生成数据集上的实验表明，CodeRSA比常见基线方法表现优越，并在大多数情况下超越最先进方法，展示了其稳健性和整体有效性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.15835v2",
      "published_date": "2025-02-20 12:44:26 UTC",
      "updated_date": "2025-02-28 13:40:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:31:43.649692"
    },
    {
      "arxiv_id": "2502.14504v1",
      "title": "PLPHP: Per-Layer Per-Head Vision Token Pruning for Efficient Large Vision-Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yu Meng",
        "Kaiyuan Li",
        "Chenran Huang",
        "Chen Gao",
        "Xinlei Chen",
        "Yong Li",
        "Xiaoping Zhang"
      ],
      "abstract": "Large Vision-Language Models (LVLMs) have demonstrated remarkable\ncapabilities across a range of multimodal tasks. However, their inference\nefficiency is constrained by the large number of visual tokens processed during\ndecoding. To address this challenge, we propose Per-Layer Per-Head Vision Token\nPruning (PLPHP), a two-level fine-grained pruning method including Layer-Level\nRetention Rate Allocation and Head-Level Vision Token Pruning. Motivated by the\nVision Token Re-attention phenomenon across decoder layers, we dynamically\nadjust token retention rates layer by layer. Layers that exhibit stronger\nattention to visual information preserve more vision tokens, while layers with\nlower vision attention are aggressively pruned. Furthermore, PLPHP applies\npruning at the attention head level, enabling different heads within the same\nlayer to independently retain critical context. Experiments on multiple\nbenchmarks demonstrate that PLPHP delivers an 18% faster decoding speed and\nreduces the Key-Value Cache (KV Cache) size by over 50%, all at the cost of\n0.46% average performance drop, while also achieving notable performance\nimprovements in multi-image tasks. These results highlight the effectiveness of\nfine-grained token pruning and contribute to advancing the efficiency and\nscalability of LVLMs. Our source code will be made publicly available.",
      "tldr_zh": "该研究提出 PLPHP，一种针对大型视觉语言模型 (LVLMs) 的细粒度视觉标记修剪方法，包括 Layer-Level Retention Rate Allocation 和 Head-Level Vision Token Pruning，以解决模型在解码过程中处理大量视觉标记导致的效率问题。方法通过动态调整每层的标记保留率——强视觉注意层保留更多标记，而低注意层进行 aggressive 修剪，并在注意力头级别独立保留关键上下文。实验结果显示，PLPHP 使解码速度提高 18%、Key-Value Cache (KV Cache) 大小减少超过 50%，性能仅下降 0.46%，并在多图像任务中实现显著提升，从而提升了 LVLMs 的效率和可扩展性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "12 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.14504v1",
      "published_date": "2025-02-20 12:31:31 UTC",
      "updated_date": "2025-02-20 12:31:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:31:56.613662"
    },
    {
      "arxiv_id": "2502.14499v1",
      "title": "MLGym: A New Framework and Benchmark for Advancing AI Research Agents",
      "title_zh": "MLGym：用于推进 AI 研究代理的新框架和基准",
      "authors": [
        "Deepak Nathani",
        "Lovish Madaan",
        "Nicholas Roberts",
        "Nikolay Bashlykov",
        "Ajay Menon",
        "Vincent Moens",
        "Amar Budhiraja",
        "Despoina Magka",
        "Vladislav Vorotilov",
        "Gaurav Chaurasia",
        "Dieuwke Hupkes",
        "Ricardo Silveira Cabral",
        "Tatiana Shavrina",
        "Jakob Foerster",
        "Yoram Bachrach",
        "William Yang Wang",
        "Roberta Raileanu"
      ],
      "abstract": "We introduce Meta MLGym and MLGym-Bench, a new framework and benchmark for\nevaluating and developing LLM agents on AI research tasks. This is the first\nGym environment for machine learning (ML) tasks, enabling research on\nreinforcement learning (RL) algorithms for training such agents. MLGym-bench\nconsists of 13 diverse and open-ended AI research tasks from diverse domains\nsuch as computer vision, natural language processing, reinforcement learning,\nand game theory. Solving these tasks requires real-world AI research skills\nsuch as generating new ideas and hypotheses, creating and processing data,\nimplementing ML methods, training models, running experiments, analyzing the\nresults, and iterating through this process to improve on a given task. We\nevaluate a number of frontier large language models (LLMs) on our benchmarks\nsuch as Claude-3.5-Sonnet, Llama-3.1 405B, GPT-4o, o1-preview, and Gemini-1.5\nPro. Our MLGym framework makes it easy to add new tasks, integrate and evaluate\nmodels or agents, generate synthetic data at scale, as well as develop new\nlearning algorithms for training agents on AI research tasks. We find that\ncurrent frontier models can improve on the given baselines, usually by finding\nbetter hyperparameters, but do not generate novel hypotheses, algorithms,\narchitectures, or substantial improvements. We open-source our framework and\nbenchmark to facilitate future research in advancing the AI research\ncapabilities of LLM agents.",
      "tldr_zh": "本研究引入了 MLGym 框架和 MLGym-Bench 基准，这是首个针对机器学习 (ML) 任务的 Gym 环境，用于评估和开发 LLM 代理的 AI 研究能力。MLGym-Bench 包含 13 个多样化任务，涵盖计算机视觉、自然语言处理、强化学习 (RL) 和博弈论等领域，这些任务要求代理具备生成新想法、处理数据、实现 ML 方法、运行实验和迭代改进等真实技能。实验评估了前沿模型如 Claude-3.5-Sonnet 和 GPT-4o，发现它们通常通过优化超参数实现基线改进，但无法生成新颖假设、算法或实质性创新。该框架开源设计，便于添加新任务和开发 RL 算法，以推进 LLM 代理的 AI 研究发展。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "35 pages, 12 figures, 10 tables",
      "pdf_url": "http://arxiv.org/pdf/2502.14499v1",
      "published_date": "2025-02-20 12:28:23 UTC",
      "updated_date": "2025-02-20 12:28:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:32:09.402166"
    },
    {
      "arxiv_id": "2502.14491v2",
      "title": "Statistical Scenario Modelling and Lookalike Distributions for Multi-Variate AI Risk",
      "title_zh": "翻译失败",
      "authors": [
        "Elija Perrier"
      ],
      "abstract": "Evaluating AI safety requires statistically rigorous methods and risk metrics\nfor understanding how the use of AI affects aggregated risk. However, much AI\nsafety literature focuses upon risks arising from AI models in isolation,\nlacking consideration of how modular use of AI affects risk distribution of\nworkflow components or overall risk metrics. There is also a lack of\nstatistical grounding enabling sensitisation of risk models in the presence of\nabsence of AI to estimate causal contributions of AI. This is in part due to\nthe dearth of AI impact data upon which to fit distributions. In this work, we\naddress these gaps in two ways. First, we demonstrate how scenario modelling\n(grounded in established statistical techniques such as Markov chains, copulas\nand Monte Carlo simulation) can be used to model AI risk holistically. Second,\nwe show how lookalike distributions from phenomena analogous to AI can be used\nto estimate AI impacts in the absence of directly observable data. We\ndemonstrate the utility of our methods for benchmarking cumulative AI risk via\nrisk analysis of a logistic scenario simulations.",
      "tldr_zh": "该研究针对多变量 AI 风险评估，强调了统计严谨的方法和风险指标，以理解 AI 使用对整体风险分布的影响。论文指出，现有的 AI 安全文献忽略了 AI 在工作流中的模块化作用，以及缺乏统计基础来量化 AI 的因果贡献，主要由于 AI 影响数据不足。为解决这些问题，作者引入了基于 Markov chains、copulas 和 Monte Carlo simulation 的场景建模方法，来整体建模 AI 风险；同时，提出了使用 lookalike distributions 从类似现象中估计 AI 影响，以弥补数据缺失。通过在物流场景模拟中的风险分析，展示了这些方法在基准化累积 AI 风险方面的实用性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Under review",
      "pdf_url": "http://arxiv.org/pdf/2502.14491v2",
      "published_date": "2025-02-20 12:14:54 UTC",
      "updated_date": "2025-03-07 19:55:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:32:19.579796"
    },
    {
      "arxiv_id": "2502.14487v2",
      "title": "Temporal Misalignment in ANN-SNN Conversion and Its Mitigation via Probabilistic Spiking Neurons",
      "title_zh": "ANN-SNN 转换中的时间不对齐及其通过概率尖",
      "authors": [
        "Velibor Bojković",
        "Xiaofeng Wu",
        "Bin Gu"
      ],
      "abstract": "Spiking Neural Networks (SNNs) offer a more energy-efficient alternative to\nArtificial Neural Networks (ANNs) by mimicking biological neural principles,\nestablishing them as a promising approach to mitigate the increasing energy\ndemands of large-scale neural models. However, fully harnessing the\ncapabilities of SNNs remains challenging due to their discrete signal\nprocessing and temporal dynamics. ANN-SNN conversion has emerged as a practical\napproach, enabling SNNs to achieve competitive performance on complex machine\nlearning tasks. In this work, we identify a phenomenon in the ANN-SNN\nconversion framework, termed temporal misalignment, in which random spike\nrearrangement across SNN layers leads to performance improvements. Based on\nthis observation, we introduce biologically plausible two-phase probabilistic\n(TPP) spiking neurons, further enhancing the conversion process. We demonstrate\nthe advantages of our proposed method both theoretically and empirically\nthrough comprehensive experiments on CIFAR-10/100, CIFAR10-DVS, and ImageNet\nacross a variety of architectures, achieving state-of-the-art results.",
      "tldr_zh": "本研究探讨了ANN-SNN转换中的temporal misalignment现象，即SNN层中随机的脉冲重新排列导致性能提升，并提出了一种biologically plausible two-phase probabilistic (TPP) spiking neurons方法来缓解这一问题。TPP spiking neurons通过模拟生物神经机制，进一步增强了转换过程的效率和准确性。实验在CIFAR-10/100、CIFAR10-DVS和ImageNet数据集上验证了该方法的优势，在多种架构中实现了state-of-the-art结果，证明了SNNs在节能和复杂任务处理方面的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14487v2",
      "published_date": "2025-02-20 12:09:30 UTC",
      "updated_date": "2025-02-21 09:05:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:32:31.782312"
    },
    {
      "arxiv_id": "2502.14486v1",
      "title": "How Jailbreak Defenses Work and Ensemble? A Mechanistic Investigation",
      "title_zh": "翻译失败",
      "authors": [
        "Zhuohang Long",
        "Siyuan Wang",
        "Shujun Liu",
        "Yuhang Lai",
        "Xuanjing Huang",
        "Zhongyu Wei"
      ],
      "abstract": "Jailbreak attacks, where harmful prompts bypass generative models' built-in\nsafety, raise serious concerns about model vulnerability. While many defense\nmethods have been proposed, the trade-offs between safety and helpfulness, and\ntheir application to Large Vision-Language Models (LVLMs), are not well\nunderstood. This paper systematically examines jailbreak defenses by reframing\nthe standard generation task as a binary classification problem to assess model\nrefusal tendencies for both harmful and benign queries. We identify two key\ndefense mechanisms: safety shift, which increases refusal rates across all\nqueries, and harmfulness discrimination, which improves the model's ability to\ndistinguish between harmful and benign inputs. Using these mechanisms, we\ndevelop two ensemble defense strategies-inter-mechanism ensembles and\nintra-mechanism ensembles-to balance safety and helpfulness. Experiments on the\nMM-SafetyBench and MOSSBench datasets with LLaVA-1.5 models show that these\nstrategies effectively improve model safety or optimize the trade-off between\nsafety and helpfulness.",
      "tldr_zh": "本研究系统考察了jailbreak attacks（越狱攻击）对生成模型安全的威胁，并分析了防御方法在安全性和帮助性之间的权衡，特别是针对Large Vision-Language Models (LVLMs)。作者将生成任务重新框架为二元分类问题，识别出两种关键防御机制：safety shift（提高所有查询的拒绝率）和harmfulness discrimination（提升区分有害与良性输入的能力）。基于这些机制，他们开发了inter-mechanism ensembles和intra-mechanism ensembles两种集成防御策略，并在MM-SafetyBench和MOSSBench数据集上使用LLaVA-1.5模型进行实验，结果显示这些策略有效提升了模型安全或优化了安全与帮助性的权衡。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14486v1",
      "published_date": "2025-02-20 12:07:40 UTC",
      "updated_date": "2025-02-20 12:07:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:32:44.473104"
    },
    {
      "arxiv_id": "2502.14469v1",
      "title": "Enhancing Smart Environments with Context-Aware Chatbots using Large Language Models",
      "title_zh": "利用大语言模型增强智能环境中的上下文感知聊天机器人",
      "authors": [
        "Aurora Polo-Rodríguez",
        "Laura Fiorini",
        "Erika Rovini",
        "Filippo Cavallo",
        "Javier Medina-Quero"
      ],
      "abstract": "This work presents a novel architecture for context-aware interactions within\nsmart environments, leveraging Large Language Models (LLMs) to enhance user\nexperiences. Our system integrates user location data obtained through UWB tags\nand sensor-equipped smart homes with real-time human activity recognition (HAR)\nto provide a comprehensive understanding of user context. This contextual\ninformation is then fed to an LLM-powered chatbot, enabling it to generate\npersonalised interactions and recommendations based on the user's current\nactivity and environment. This approach moves beyond traditional static chatbot\ninteractions by dynamically adapting to the user's real-time situation. A case\nstudy conducted from a real-world dataset demonstrates the feasibility and\neffectiveness of our proposed architecture, showcasing its potential to create\nmore intuitive and helpful interactions within smart homes. The results\nhighlight the significant benefits of integrating LLM with real-time activity\nand location data to deliver personalised and contextually relevant user\nexperiences.",
      "tldr_zh": "本研究提出了一种新型架构，使用 Large Language Models (LLMs) 来增强智能环境中的上下文感知交互，从而提升用户体验。该系统整合 UWB tags 获取的用户位置数据、传感器数据以及实时 Human Activity Recognition (HAR)，为 LLM 驱动的聊天机器人提供全面的上下文信息，实现动态个性化推荐和交互。相比传统静态聊天机器人，该方法能根据用户的实时活动和环境进行适应。通过真实数据集的案例研究，证明了该架构的可行性和有效性，突显了整合 LLM 与实时数据的显著益处。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.CL",
      "comment": "11 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.14469v1",
      "published_date": "2025-02-20 11:46:51 UTC",
      "updated_date": "2025-02-20 11:46:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:32:56.585953"
    },
    {
      "arxiv_id": "2502.14462v1",
      "title": "Single-image Reflectance and Transmittance Estimation from Any Flatbed Scanner",
      "title_zh": "翻译失败",
      "authors": [
        "Carlos Rodriguez-Pardo",
        "David Pascual-Hernandez",
        "Javier Rodriguez-Vazquez",
        "Jorge Lopez-Moreno",
        "Elena Garces"
      ],
      "abstract": "Flatbed scanners have emerged as promising devices for high-resolution,\nsingle-image material capture. However, existing approaches assume very\nspecific conditions, such as uniform diffuse illumination, which are only\navailable in certain high-end devices, hindering their scalability and cost. In\ncontrast, in this work, we introduce a method inspired by intrinsic image\ndecomposition, which accurately removes both shading and specularity,\neffectively allowing captures with any flatbed scanner. Further, we extend\nprevious work on single-image material reflectance capture with the estimation\nof opacity and transmittance, critical components of full material appearance\n(SVBSDF), improving the results for any material captured with a flatbed\nscanner, at a very high resolution and accuracy",
      "tldr_zh": "本文提出了一种基于intrinsic image decomposition的方法，能够从任何平板扫描仪的单张图像中准确估计材料的reflectance和transmittance，通过去除阴影和镜面反射来克服现有方法的限制，如对均匀照明的需求。相比传统方法，该方法扩展了单图像材料捕获功能，包括opacity和transmittance的估计，从而全面提升材料外观（SVBSDF）的重现质量。实验结果显示，这种方法在高分辨率和准确性方面显著改善了平板扫描仪的应用潜力。",
      "categories": [
        "cs.GR",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "68T07 (Primary) 68T45, 68U10, 68U05 (Secondary)",
        "I.4.0; I.2.6; I.3.0"
      ],
      "primary_category": "cs.GR",
      "comment": "Accepted to Computers & Graphics",
      "pdf_url": "http://arxiv.org/pdf/2502.14462v1",
      "published_date": "2025-02-20 11:33:17 UTC",
      "updated_date": "2025-02-20 11:33:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:33:08.802013"
    },
    {
      "arxiv_id": "2502.14458v2",
      "title": "Llamba: Scaling Distilled Recurrent Models for Efficient Language Processing",
      "title_zh": "翻译失败",
      "authors": [
        "Aviv Bick",
        "Tobias Katsch",
        "Nimit Sohoni",
        "Arjun Desai",
        "Albert Gu"
      ],
      "abstract": "We introduce Llamba, a family of efficient recurrent language models\ndistilled from Llama-3.x into the Mamba architecture. The series includes\nLlamba-1B, Llamba-3B, and Llamba-8B, which achieve higher inference throughput\nand handle significantly larger batch sizes than Transformer-based models while\nmaintaining comparable benchmark performance. Furthermore, Llamba demonstrates\nthe effectiveness of cross-architecture distillation using MOHAWK (Bick et al.,\n2024), achieving these results with less than 0.1% of the training data\ntypically used for models of similar size. To take full advantage of their\nefficiency, we provide an optimized implementation of Llamba for\nresource-constrained devices such as smartphones and edge platforms, offering a\npractical and memory-efficient alternative to Transformers. Overall, Llamba\nimproves the tradeoff between speed, memory efficiency, and performance, making\nhigh-quality language models more accessible.",
      "tldr_zh": "我们介绍了 Llamba 系列模型，这是从 Llama-3.x 蒸馏到 Mamba 架构的循环语言模型，包括 Llamba-1B、Llamba-3B 和 Llamba-8B 版本。这些模型通过 MOHAWK 的跨架构蒸馏方法，仅使用不到 0.1% 的训练数据，就实现了比 Transformer 模型更高的推理吞吐量和更大批量处理能力，同时保持可比的基准性能。Llamba 的优化实现适用于资源受限设备如智能手机和边缘平台，显著改善了速度、内存效率与性能的权衡，使高质量语言模型更易于部署和访问。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14458v2",
      "published_date": "2025-02-20 11:18:39 UTC",
      "updated_date": "2025-02-23 13:02:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:33:22.301546"
    },
    {
      "arxiv_id": "2502.14457v1",
      "title": "Watch Less, Feel More: Sim-to-Real RL for Generalizable Articulated Object Manipulation via Motion Adaptation and Impedance Control",
      "title_zh": "翻译失败",
      "authors": [
        "Tan-Dzung Do",
        "Nandiraju Gireesh",
        "Jilong Wang",
        "He Wang"
      ],
      "abstract": "Articulated object manipulation poses a unique challenge compared to rigid\nobject manipulation as the object itself represents a dynamic environment. In\nthis work, we present a novel RL-based pipeline equipped with variable\nimpedance control and motion adaptation leveraging observation history for\ngeneralizable articulated object manipulation, focusing on smooth and dexterous\nmotion during zero-shot sim-to-real transfer. To mitigate the sim-to-real gap,\nour pipeline diminishes reliance on vision by not leveraging the vision data\nfeature (RGBD/pointcloud) directly as policy input but rather extracting useful\nlow-dimensional data first via off-the-shelf modules. Additionally, we\nexperience less sim-to-real gap by inferring object motion and its intrinsic\nproperties via observation history as well as utilizing impedance control both\nin the simulation and in the real world. Furthermore, we develop a\nwell-designed training setting with great randomization and a specialized\nreward system (task-aware and motion-aware) that enables multi-staged,\nend-to-end manipulation without heuristic motion planning. To the best of our\nknowledge, our policy is the first to report 84\\% success rate in the real\nworld via extensive experiments with various unseen objects.",
      "tldr_zh": "本研究提出了一种基于强化学习（RL）的管道，用于实现可泛化的关节物体（articulated object）操作，通过引入运动适应（motion adaptation）和可变阻抗控制（variable impedance control），并利用观察历史（observation history）来实现平滑、灵巧的动作。不同于传统方法，该管道减少了对视觉数据的直接依赖，而是先通过现成模块提取低维特征，并在模拟和真实环境中应用阻抗控制，以缩小 sim-to-real 差距，同时采用高度随机化的训练设置和任务感知及运动感知的奖励系统，实现多阶段端到端操作，而无需启发式运动规划。实验结果显示，该策略在真实世界中对各种未见物体实现了84%的成功率，这是首例在零样本 sim-to-real 转移中达到此性能的RL方法。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14457v1",
      "published_date": "2025-02-20 11:18:35 UTC",
      "updated_date": "2025-02-20 11:18:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:33:33.785962"
    },
    {
      "arxiv_id": "2502.14456v2",
      "title": "Narrative-Driven Travel Planning: Geoculturally-Grounded Script Generation with Evolutionary Itinerary Optimization",
      "title_zh": "基于叙事的旅行规划：以地理文化为基础的脚本生成与进化行程优化",
      "authors": [
        "Ran Ding",
        "Ziyu Zhang",
        "Ying Zhu",
        "Ziqian Kong",
        "Peilan Xu"
      ],
      "abstract": "To enhance tourists' experiences and immersion, this paper proposes a\nnarrative-driven travel planning framework called NarrativeGuide, which\ngenerates a geoculturally-grounded narrative script for travelers, offering a\nnovel, role-playing experience for their journey. In the initial stage,\nNarrativeGuide constructs a knowledge graph for attractions within a city, then\nconfigures the worldview, character setting, and exposition based on the\nknowledge graph. Using this foundation, the knowledge graph is combined to\ngenerate an independent scene unit for each attraction. During the itinerary\nplanning stage, NarrativeGuide models narrative-driven travel planning as an\noptimization problem, utilizing a genetic algorithm (GA) to refine the\nitinerary. Before evaluating the candidate itinerary, transition scripts are\ngenerated for each pair of adjacent attractions, which, along with the scene\nunits, form a complete script. The weighted sum of script coherence, travel\ntime, and attraction scores is then used as the fitness value to update the\ncandidate solution set. Experimental results across four cities, i.e., Nanjing\nand Yangzhou in China, Paris in France, and Berlin in Germany, demonstrate\nsignificant improvements in narrative coherence and cultural fit, alongside a\nnotable reduction in travel time and an increase in the quality of visited\nattractions. Our study highlights that incorporating external evolutionary\noptimization effectively addresses the limitations of large language models in\ntravel planning.",
      "tldr_zh": "这篇论文提出了名为 NarrativeGuide 的叙事驱动旅行规划框架，通过生成基于地理文化地基的叙事脚本，提供角色扮演式的旅行体验。框架首先构建城市的知识 graph，并据此配置世界观、角色设置和场景单元，然后使用 genetic algorithm (GA) 将行程优化建模为问题，以脚本 coherence、旅行时间和景点分数加权和作为适应值进行迭代优化。实验结果显示，在南京、扬州、巴黎和柏林四个城市中，该方法显著提升了叙事 coherence 和文化契合度，同时减少了旅行时间并提高了景点质量。研究证明，外部进化优化有效解决了大型语言模型在旅行规划中的局限性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14456v2",
      "published_date": "2025-02-20 11:15:23 UTC",
      "updated_date": "2025-02-26 07:36:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:33:45.982027"
    },
    {
      "arxiv_id": "2502.14455v1",
      "title": "An Efficient Ground-aerial Transportation System for Pest Control Enabled by AI-based Autonomous Nano-UAVs",
      "title_zh": "翻译失败",
      "authors": [
        "Luca Crupi",
        "Luca Butera",
        "Alberto Ferrante",
        "Alessandro Giusti",
        "Daniele Palossi"
      ],
      "abstract": "Efficient crop production requires early detection of pest outbreaks and\ntimely treatments; we consider a solution based on a fleet of multiple\nautonomous miniaturized unmanned aerial vehicles (nano-UAVs) to visually detect\npests and a single slower heavy vehicle that visits the detected outbreaks to\ndeliver treatments. To cope with the extreme limitations aboard nano-UAVs,\ne.g., low-resolution sensors and sub-100 mW computational power budget, we\ndesign, fine-tune, and optimize a tiny image-based convolutional neural network\n(CNN) for pest detection. Despite the small size of our CNN (i.e., 0.58\nGOps/inference), on our dataset, it scores a mean average precision (mAP) of\n0.79 in detecting harmful bugs, i.e., 14% lower mAP but 32x fewer operations\nthan the best-performing CNN in the literature. Our CNN runs in real-time at\n6.8 frame/s, requiring 33 mW on a GWT GAP9 System-on-Chip aboard a Crazyflie\nnano-UAV. Then, to cope with in-field unexpected obstacles, we leverage a\nglobal+local path planner based on the A* algorithm. The global path planner\ndetermines the best route for the nano-UAV to sweep the entire area, while the\nlocal one runs up to 50 Hz aboard our nano-UAV and prevents collision by\nadjusting the short-distance path. Finally, we demonstrate with in-simulator\nexperiments that once a 25 nano-UAVs fleet has combed a 200x200 m vineyard,\ncollected information can be used to plan the best path for the tractor,\nvisiting all and only required hotspots. In this scenario, our efficient\ntransportation system, compared to a traditional single-ground vehicle\nperforming both inspection and treatment, can save up to 20 h working time.",
      "tldr_zh": "这篇论文提出了一种高效的地面-空中交通系统，用于害虫控制，结合 AI-based 自主 nano-UAVs 进行视觉检测和一个重型车辆进行处理。研究团队设计并优化了一个小型图像-based CNN，用于在 nano-UAVs 的低资源环境中实时检测害虫，该 CNN 虽比最佳模型 mAP 低 14%（达到 0.79），但运算量减少 32 倍，并在 33 mW 功率下以 6.8 帧/秒运行。系统采用 A* 算法的全局+局部路径规划器，以应对实地障碍，确保 nano-UAVs 安全覆盖整个区域。模拟实验显示，在 200x200 m 葡萄园中，使用 25 个 nano-UAVs 的系统比传统单一地面车辆可节省高达 20 小时的工作时间。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14455v1",
      "published_date": "2025-02-20 11:14:55 UTC",
      "updated_date": "2025-02-20 11:14:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:33:58.219167"
    },
    {
      "arxiv_id": "2502.15833v1",
      "title": "Advancing Out-of-Distribution Detection via Local Neuroplasticity",
      "title_zh": "通过局部神经可塑性推进分布外检测",
      "authors": [
        "Alessandro Canevaro",
        "Julian Schmidt",
        "Mohammad Sajad Marvi",
        "Hang Yu",
        "Georg Martius",
        "Julian Jordan"
      ],
      "abstract": "In the domain of machine learning, the assumption that training and test data\nshare the same distribution is often violated in real-world scenarios,\nrequiring effective out-of-distribution (OOD) detection. This paper presents a\nnovel OOD detection method that leverages the unique local neuroplasticity\nproperty of Kolmogorov-Arnold Networks (KANs). Unlike traditional multilayer\nperceptrons, KANs exhibit local plasticity, allowing them to preserve learned\ninformation while adapting to new tasks. Our method compares the activation\npatterns of a trained KAN against its untrained counterpart to detect OOD\nsamples. We validate our approach on benchmarks from image and medical domains,\ndemonstrating superior performance and robustness compared to state-of-the-art\ntechniques. These results underscore the potential of KANs in enhancing the\nreliability of machine learning systems in diverse environments.",
      "tldr_zh": "这篇论文提出了一种先进的Out-of-Distribution (OOD) 检测方法，利用Kolmogorov-Arnold Networks (KANs)的Local Neuroplasticity特性，以应对真实场景中训练和测试数据分布不一致的问题。方法通过比较训练后KAN的激活模式与未训练KAN的激活模式，来精确识别OOD样本，从而保留已学信息并适应新任务。实验结果显示，该方法在图像和医疗领域的基准测试中，性能和鲁棒性均优于现有最先进技术，突显了KANs在提升机器学习系统可靠性的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to ICLR25",
      "pdf_url": "http://arxiv.org/pdf/2502.15833v1",
      "published_date": "2025-02-20 11:13:41 UTC",
      "updated_date": "2025-02-20 11:13:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:34:08.125353"
    },
    {
      "arxiv_id": "2502.14445v1",
      "title": "PredictaBoard: Benchmarking LLM Score Predictability",
      "title_zh": "PredictaBoard：LLM 得分可预测性的基准测试",
      "authors": [
        "Lorenzo Pacchiardi",
        "Konstantinos Voudouris",
        "Ben Slater",
        "Fernando Martínez-Plumed",
        "José Hernández-Orallo",
        "Lexin Zhou",
        "Wout Schellaert"
      ],
      "abstract": "Despite possessing impressive skills, Large Language Models (LLMs) often fail\nunpredictably, demonstrating inconsistent success in even basic common sense\nreasoning tasks. This unpredictability poses a significant challenge to\nensuring their safe deployment, as identifying and operating within a reliable\n\"safe zone\" is essential for mitigating risks. To address this, we present\nPredictaBoard, a novel collaborative benchmarking framework designed to\nevaluate the ability of score predictors (referred to as assessors) to\nanticipate LLM errors on specific task instances (i.e., prompts) from existing\ndatasets. PredictaBoard evaluates pairs of LLMs and assessors by considering\nthe rejection rate at different tolerance errors. As such, PredictaBoard\nstimulates research into developing better assessors and making LLMs more\npredictable, not only with a higher average performance. We conduct\nillustrative experiments using baseline assessors and state-of-the-art LLMs.\nPredictaBoard highlights the critical need to evaluate predictability alongside\nperformance, paving the way for safer AI systems where errors are not only\nminimised but also anticipated and effectively mitigated. Code for our\nbenchmark can be found at\nhttps://github.com/Kinds-of-Intelligence-CFI/PredictaBoard",
      "tldr_zh": "本研究提出 PredictaBoard，一种新型协作基准框架，用于评估评估器 (assessors) 预测大型语言模型 (LLMs) 在特定任务实例上的错误能力，以解决 LLMs 的不可预测性和安全部署挑战。该框架通过分析 LLM 和评估器对在不同容忍错误水平下的拒绝率，进行系统评估和实验。结果显示，PredictaBoard 强调了在提升平均性能之外，评估可预测性的重要性，从而推动开发更可靠的 AI 系统，并提供代码以便进一步研究（https://github.com/Kinds-of-Intelligence-CFI/PredictaBoard）。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14445v1",
      "published_date": "2025-02-20 10:52:38 UTC",
      "updated_date": "2025-02-20 10:52:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:34:19.816008"
    },
    {
      "arxiv_id": "2502.14442v1",
      "title": "Stochastic Resonance Improves the Detection of Low Contrast Images in Deep Learning Models",
      "title_zh": "随机共振改善深度学习模型对低对比度图像的检测",
      "authors": [
        "Siegfried Ludwig"
      ],
      "abstract": "Stochastic resonance describes the utility of noise in improving the\ndetectability of weak signals in certain types of systems. It has been observed\nwidely in natural and engineered settings, but its utility in image\nclassification with rate-based neural networks has not been studied\nextensively. In this analysis a simple LSTM recurrent neural network is trained\nfor digit recognition and classification. During the test phase, image contrast\nis reduced to a point where the model fails to recognize the presence of a\nstimulus. Controlled noise is added to partially recover classification\nperformance. The results indicate the presence of stochastic resonance in\nrate-based recurrent neural networks.",
      "tldr_zh": "本研究探讨了随机共振(Stochastic Resonance)在深度学习模型中的应用，特别针对低对比度图像的检测问题。研究者训练了一个简单的LSTM循环神经网络用于数字识别和分类，在测试阶段降低图像对比度至模型无法识别的水平，然后通过添加受控噪声来部分恢复分类性能。结果表明，这种基于速率的神经网络确实存在随机共振现象，从而证明噪声能提升弱信号的可检测性，为图像处理领域提供新见解。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "MSc Course Project",
      "pdf_url": "http://arxiv.org/pdf/2502.14442v1",
      "published_date": "2025-02-20 10:48:49 UTC",
      "updated_date": "2025-02-20 10:48:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:34:31.297248"
    },
    {
      "arxiv_id": "2502.14424v1",
      "title": "Distribution Matching for Self-Supervised Transfer Learning",
      "title_zh": "自监督迁移学习的分布匹配",
      "authors": [
        "Yuling Jiao",
        "Wensen Ma",
        "Defeng Sun",
        "Hansheng Wang",
        "Yang Wang"
      ],
      "abstract": "In this paper, we propose a novel self-supervised transfer learning method\ncalled Distribution Matching (DM), which drives the representation distribution\ntoward a predefined reference distribution while preserving augmentation\ninvariance. The design of DM results in a learned representation space that is\nintuitively structured and offers easily interpretable hyperparameters.\nExperimental results across multiple real-world datasets and evaluation metrics\ndemonstrate that DM performs competitively on target classification tasks\ncompared to existing self-supervised transfer learning methods. Additionally,\nwe provide robust theoretical guarantees for DM, including a population theorem\nand an end-to-end sample theorem. The population theorem bridges the gap\nbetween the self-supervised learning task and target classification accuracy,\nwhile the sample theorem shows that, even with a limited number of samples from\nthe target domain, DM can deliver exceptional classification performance,\nprovided the unlabeled sample size is sufficiently large.",
      "tldr_zh": "本文提出了一种名为 Distribution Matching (DM) 的自监督转移学习方法，该方法通过驱动表示分布向预定义参考分布逼近，同时保持增强不变性，从而构建一个直观结构化和易解释超参数的表示空间。实验结果显示，DM 在多个真实数据集和评估指标上，在目标分类任务中与现有方法相比具有竞争力。论文还提供了理论保证，包括总体定理（桥接自监督学习与分类准确率）和样本定理（即使目标域样本有限，若无标签样本足够大，DM 也能实现出色性能）。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG",
        "stat.ME"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14424v1",
      "published_date": "2025-02-20 10:20:56 UTC",
      "updated_date": "2025-02-20 10:20:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:34:45.258329"
    },
    {
      "arxiv_id": "2502.14416v1",
      "title": "Reliable Explainability of Deep Learning Spatial-Spectral Classifiers for Improved Semantic Segmentation in Autonomous Driving",
      "title_zh": "翻译失败",
      "authors": [
        "Jon Gutiérrez-Zaballa",
        "Koldo Basterretxea",
        "Javier Echanobe"
      ],
      "abstract": "Integrating hyperspectral imagery (HSI) with deep neural networks (DNNs) can\nstrengthen the accuracy of intelligent vision systems by combining spectral and\nspatial information, which is useful for tasks like semantic segmentation in\nautonomous driving. To advance research in such safety-critical systems,\ndetermining the precise contribution of spectral information to complex DNNs'\noutput is needed. To address this, several saliency methods, such as class\nactivation maps (CAM), have been proposed primarily for image classification.\nHowever, recent studies have raised concerns regarding their reliability. In\nthis paper, we address their limitations and propose an alternative approach by\nleveraging the data provided by activations and weights from relevant DNN\nlayers to better capture the relationship between input features and\npredictions. The study aims to assess the superior performance of HSI compared\nto 3-channel and single-channel DNNs. We also address the influence of spectral\nsignature normalization for enhancing DNN robustness in real-world driving\nconditions.",
      "tldr_zh": "本文提出了一种可靠的解释性方法，用于改进自动驾驶中语义分割的深度学习空间-光谱分类器，重点整合超光谱图像 (HSI) 以结合光谱和空间信息。针对现有显著性方法如 class activation maps (CAM) 的可靠性问题，该方法利用 DNN 层中的激活和权重数据，更好地捕捉输入特征与预测之间的关系。研究评估了 HSI 在 DNN 中的表现 superiority 比 3 通道和单通道模型，并探讨了光谱签名归一化以增强模型在真实驾驶条件下的鲁棒性。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14416v1",
      "published_date": "2025-02-20 10:11:27 UTC",
      "updated_date": "2025-02-20 10:11:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:34:59.435185"
    },
    {
      "arxiv_id": "2502.14400v1",
      "title": "HPS: Hard Preference Sampling for Human Preference Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Xiandong Zou",
        "Wanyu Lin",
        "Yuchen Li",
        "Pan Zhou"
      ],
      "abstract": "Aligning Large Language Model (LLM) responses with human preferences is vital\nfor building safe and controllable AI systems. While preference optimization\nmethods based on Plackett-Luce (PL) and Bradley-Terry (BT) models have shown\npromise, they face challenges such as poor handling of harmful content,\ninefficient use of dispreferred responses, and, specifically for PL, high\ncomputational costs. To address these issues, we propose Hard Preference\nSampling (HPS), a novel framework for robust and efficient human preference\nalignment. HPS introduces a training loss that prioritizes the most preferred\nresponse while rejecting all dispreferred and harmful ones. It emphasizes\n\"hard\" dispreferred responses--those closely resembling preferred ones--to\nenhance the model's rejection capabilities. By leveraging a single-sample Monte\nCarlo sampling strategy, HPS reduces computational overhead while maintaining\nalignment quality. Theoretically, HPS improves sample efficiency over existing\nPL methods and maximizes the reward margin between preferred and dispreferred\nresponses, ensuring clearer distinctions. Experiments on HH-RLHF and PKU-Safety\ndatasets validate HPS's effectiveness, achieving comparable BLEU and reward\nscores while greatly improving reward margins and thus reducing harmful content\ngeneration.",
      "tldr_zh": "本文提出 Hard Preference Sampling (HPS)，一种高效的人类偏好对齐框架，用于解决 Large Language Model (LLM) 响应对齐中的问题，如 Plackett-Luce (PL) 和 Bradley-Terry (BT) 方法在处理有害内容和计算效率上的不足。HPS 通过设计新的训练损失，优先强化最偏好的响应并强调“hard”不偏好响应（即与偏好响应相似的那些），同时采用单样本 Monte Carlo 采样策略，降低了计算开销并最大化了奖励边际。实验在 HH-RLHF 和 PKU-Safety 数据集上验证了 HPS 的有效性，实现了与基线相当的 BLEU 和奖励分数，同时显著提高了奖励边际，减少了有害内容生成。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14400v1",
      "published_date": "2025-02-20 09:37:41 UTC",
      "updated_date": "2025-02-20 09:37:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:35:14.466935"
    },
    {
      "arxiv_id": "2504.05314v1",
      "title": "Multimodal Quantitative Language for Generative Recommendation",
      "title_zh": "翻译失败",
      "authors": [
        "Jianyang Zhai",
        "Zi-Feng Mai",
        "Chang-Dong Wang",
        "Feidiao Yang",
        "Xiawu Zheng",
        "Hui Li",
        "Yonghong Tian"
      ],
      "abstract": "Generative recommendation has emerged as a promising paradigm aiming at\ndirectly generating the identifiers of the target candidates. Most existing\nmethods attempt to leverage prior knowledge embedded in Pre-trained Language\nModels (PLMs) to improve the recommendation performance. However, they often\nfail to accommodate the differences between the general linguistic knowledge of\nPLMs and the specific needs of recommendation systems. Moreover, they rarely\nconsider the complementary knowledge between the multimodal information of\nitems, which represents the multi-faceted preferences of users. To facilitate\nefficient recommendation knowledge transfer, we propose a novel approach called\nMultimodal Quantitative Language for Generative Recommendation (MQL4GRec). Our\nkey idea is to transform items from different domains and modalities into a\nunified language, which can serve as a bridge for transferring recommendation\nknowledge. Specifically, we first introduce quantitative translators to convert\nthe text and image content of items from various domains into a new and concise\nlanguage, known as quantitative language, with all items sharing the same\nvocabulary. Then, we design a series of quantitative language generation tasks\nto enrich quantitative language with semantic information and prior knowledge.\nFinally, we achieve the transfer of recommendation knowledge from different\ndomains and modalities to the recommendation task through pre-training and\nfine-tuning. We evaluate the effectiveness of MQL4GRec through extensive\nexperiments and comparisons with existing methods, achieving improvements over\nthe baseline by 11.18\\%, 14.82\\%, and 7.95\\% on the NDCG metric across three\ndifferent datasets, respectively.",
      "tldr_zh": "该论文提出了一种名为 Multimodal Quantitative Language for Generative Recommendation (MQL4GRec) 的新方法，旨在解决生成式推荐中预训练语言模型 (PLMs) 的通用知识与推荐系统特定需求的脱节问题，同时利用物品的多模态信息（如文本和图像）进行互补知识转移。核心思路是通过 quantitative translators 将不同领域和模态的物品内容转化为统一的 quantitative language，并设计 quantitative language generation tasks 来丰富其语义和先验知识，最终通过预训练和细调实现高效的推荐知识转移。实验结果显示，MQL4GRec 在三个数据集上使 NDCG 指标分别比基线提高了 11.18%、14.82% 和 7.95%，显著提升了推荐性能。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05314v1",
      "published_date": "2025-02-20 09:29:30 UTC",
      "updated_date": "2025-02-20 09:29:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:35:25.288813"
    },
    {
      "arxiv_id": "2502.14382v1",
      "title": "S*: Test Time Scaling for Code Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Dacheng Li",
        "Shiyi Cao",
        "Chengkun Cao",
        "Xiuyu Li",
        "Shangyin Tan",
        "Kurt Keutzer",
        "Jiarong Xing",
        "Joseph E. Gonzalez",
        "Ion Stoica"
      ],
      "abstract": "Increasing test-time compute for LLMs shows promise across domains but\nremains underexplored in code generation, despite extensive study in math. In\nthis paper, we propose S*, the first hybrid test-time scaling framework that\nsubstantially improves the coverage and selection accuracy of generated code.\nS* extends the existing parallel scaling paradigm with sequential scaling to\npush performance boundaries. It further leverages a novel selection mechanism\nthat adaptively generates distinguishing inputs for pairwise comparison,\ncombined with execution-grounded information to robustly identify correct\nsolutions. We evaluate across 12 Large Language Models and Large Reasoning\nModel and show: (1) S* consistently improves performance across model families\nand sizes, enabling a 3B model to outperform GPT-4o-mini; (2) S* enables\nnon-reasoning models to surpass reasoning models - GPT-4o-mini with S*\noutperforms o1-preview by 3.7% on LiveCodeBench; (3) S* further boosts\nstate-of-the-art reasoning models - DeepSeek-R1-Distill-Qwen-32B with S*\nachieves 85.7% on LiveCodeBench, approaching o1 (high) at 88.5%. Code will be\navailable under https://github.com/NovaSky-AI/SkyThought.",
      "tldr_zh": "该论文提出 S*，一个混合测试时间缩放框架，用于显著提升代码生成的覆盖率和选择准确性。S* 通过扩展并行缩放范式并引入顺序缩放，以及一个新颖的选择机制——自适应生成区分输入进行配对比较，并结合执行-grounded 信息来识别正确解决方案。实验在 12 个 Large Language Models 和 Large Reasoning Model 上评估，结果显示 S* 能一致提升模型性能，使一个 3B 模型超越 GPT-4o-mini；此外，非推理模型如 GPT-4o-mini with S* 在 LiveCodeBench 上比 o1-preview 高出 3.7%，而最先进模型 DeepSeek-R1-Distill-Qwen-32B with S* 达到 85.7%，接近 o1 的 88.5%。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14382v1",
      "published_date": "2025-02-20 09:18:53 UTC",
      "updated_date": "2025-02-20 09:18:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:35:38.521147"
    },
    {
      "arxiv_id": "2502.14380v1",
      "title": "Affinity and Diversity: A Unified Metric for Demonstration Selection via Internal Representations",
      "title_zh": "翻译失败",
      "authors": [
        "Mariko Kato",
        "Hakaze Cho",
        "Yoshihiro Sakai",
        "Naoya Inoue"
      ],
      "abstract": "The performance of In-Context Learning (ICL) is highly sensitive to the\nselected demonstrations. Existing approaches to demonstration selection\noptimize different objectives, yielding inconsistent results. To address this,\nwe propose a unified metric--affinity and diversity--that leverages ICL model's\ninternal representations. Our experiments show that both affinity and diversity\nstrongly correlate with test accuracies, indicating their effectiveness for\ndemonstration selection. Moreover, we show that our proposed metrics align well\nwith various previous works to unify the inconsistency.",
      "tldr_zh": "本文提出一个统一的指标——affinity and diversity——通过In-Context Learning (ICL) 模型的内部表示来优化演示选择，以解决现有方法目标不一致导致的性能问题。该指标强调演示的相似性和多样性，实验显示其与测试准确率高度相关，证明了其有效性。此外，该方法与之前各种工作保持一致性，统一了ICL演示选择的框架。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.14380v1",
      "published_date": "2025-02-20 09:12:51 UTC",
      "updated_date": "2025-02-20 09:12:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:35:47.960463"
    },
    {
      "arxiv_id": "2502.14372v1",
      "title": "Discovering highly efficient low-weight quantum error-correcting codes with reinforcement learning",
      "title_zh": "使用强化学习发现高度高效的低权重量子纠错码",
      "authors": [
        "Austin Yubo He",
        "Zi-Wen Liu"
      ],
      "abstract": "The realization of scalable fault-tolerant quantum computing is expected to\nhinge on quantum error-correcting codes. In the quest for more efficient\nquantum fault tolerance, a critical code parameter is the weight of\nmeasurements that extract information about errors to enable error correction:\nas higher measurement weights require higher implementation costs and introduce\nmore errors, it is important in code design to optimize measurement weight.\nThis underlies the surging interest in quantum low-density parity-check (qLDPC)\ncodes, the study of which has primarily focused on the asymptotic\n(large-code-limit) properties. In this work, we introduce a versatile and\ncomputationally efficient approach to stabilizer code weight reduction based on\nreinforcement learning (RL), which produces new low-weight codes that\nsubstantially outperform the state of the art in practically relevant parameter\nregimes, extending significantly beyond previously accessible small distances.\nFor example, our approach demonstrates savings in physical qubit overhead\ncompared to existing results by 1 to 2 orders of magnitude for weight 6 codes\nand brings the overhead into a feasible range for near-future experiments. We\nalso investigate the interplay between code parameters using our RL framework,\noffering new insights into the potential efficiency and power of practically\nviable coding strategies. Overall, our results demonstrate how RL can\neffectively advance the crucial yet challenging problem of quantum code\ndiscovery and thereby facilitate a faster path to the practical implementation\nof fault-tolerant quantum technologies.",
      "tldr_zh": "本研究利用强化学习（RL）开发了一种高效方法，用于发现低权重的量子纠错码（quantum error-correcting codes），以优化测量权重并降低量子计算的实施成本和错误率。该方法针对稳定器码（stabilizer code）进行权重减少，生成的新码在实际参数范围内显著优于现有技术，例如在权重6的码中，物理量子比特开销减少1到2个数量级，使其适用于近未来实验。研究还通过RL框架探索了码参数间的相互作用，提供新见解，并加速了量子低密度奇偶校验码（qLDPC codes）的发现，推动量子容错技术的实际实现。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.IT",
        "cs.LG",
        "math.IT"
      ],
      "primary_category": "quant-ph",
      "comment": "18 pages, 14 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2502.14372v1",
      "published_date": "2025-02-20 09:05:34 UTC",
      "updated_date": "2025-02-20 09:05:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:35:59.406520"
    },
    {
      "arxiv_id": "2502.14366v1",
      "title": "Entropy-UID: A Method for Optimizing Information Density",
      "title_zh": "Entropy-UID：一种优化信息密度的方法",
      "authors": [
        "Xinpeng Shou"
      ],
      "abstract": "Balanced and efficient information flow is essential for optimizing language\ngeneration models. In this work, we propose Entropy-UID, a new token selection\nmethod that balances entropy and Uniform Information Density (UID) principles\nfor enhanced efficiency of text generation. Our approach adaptively adjusts\ntoken selection by jointly minimizing entropy and surprisal, promoting more\neven information distribution across generated sequences. Theoretical\nvalidation demonstrates that Entropy-UID optimally reduces information spikes\nwhile maintaining fluency and coherence. The method has been evulated using\ninformation-theoretic metrics on multiple benchmark datasets, including\nWikiText-2, OpenWebText, and WMT. Experimental results show that Entropy-UID\nachieves lower surprisal and entropy variance compared to standard GPT-2 and\nalternative heuristics, leading to more balanced and human-like text\ngeneration. Our findings point towards the potential of leveraging\ninformation-theoretic constraints to refine token selection strategies in\nautoregressive language models.",
      "tldr_zh": "本文提出了一种名为 Entropy-UID 的 token 选择方法，旨在通过平衡 entropy 和 Uniform Information Density (UID) 原则来优化语言生成模型的文本生成效率。该方法通过联合最小化 entropy 和 surprisal，实现生成的序列中信息分布更均匀，同时保持文本的流畅性和连贯性。在 WikiText-2、OpenWebText 和 WMT 等基准数据集上的实验显示，Entropy-UID 相较于标准 GPT-2 和其他启发式方法，显著降低了 surprisal 和 entropy variance，生成更平衡且更接近人类风格的文本。这些发现强调了利用信息理论约束来改进自回归语言模型的 token 选择策略的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "5pages, 1 figures, submitting to ACL 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.14366v1",
      "published_date": "2025-02-20 08:42:47 UTC",
      "updated_date": "2025-02-20 08:42:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:36:12.611487"
    },
    {
      "arxiv_id": "2502.14365v2",
      "title": "Is Q-learning an Ill-posed Problem?",
      "title_zh": "Q-learning 是一个不适定问题吗？",
      "authors": [
        "Philipp Wissmann",
        "Daniel Hein",
        "Steffen Udluft",
        "Thomas Runkler"
      ],
      "abstract": "This paper investigates the instability of Q-learning in continuous\nenvironments, a challenge frequently encountered by practitioners.\nTraditionally, this instability is attributed to bootstrapping and regression\nmodel errors. Using a representative reinforcement learning benchmark, we\nsystematically examine the effects of bootstrapping and model inaccuracies by\nincrementally eliminating these potential error sources. Our findings reveal\nthat even in relatively simple benchmarks, the fundamental task of Q-learning -\niteratively learning a Q-function from policy-specific target values - can be\ninherently ill-posed and prone to failure. These insights cast doubt on the\nreliability of Q-learning as a universal solution for reinforcement learning\nproblems.",
      "tldr_zh": "这篇论文质疑了 Q-learning 在连续环境中的不稳定性，传统上归因于 bootstrapping 和 regression model errors。作者通过在代表性强化学习基准上系统消除这些潜在错误源，逐步检验 Q-learning 的核心任务——从政策特定目标值迭代学习 Q 函数。结果显示，即使在简单基准中，该任务本质上是 ill-posed 的，容易失败，从而对 Q-learning 作为强化学习通用解决方案的可靠性提出了质疑。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at ESANN 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.14365v2",
      "published_date": "2025-02-20 08:42:30 UTC",
      "updated_date": "2025-02-21 14:11:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:36:23.195360"
    },
    {
      "arxiv_id": "2502.14361v1",
      "title": "Retrieval-Augmented Process Reward Model for Generalizable Mathematical Reasoning",
      "title_zh": "检索增强的过程奖励模型，用于可泛化的数学推理",
      "authors": [
        "Jiachen Zhu",
        "Congmin Zheng",
        "Jianghao Lin",
        "Kounianhua Du",
        "Ying Wen",
        "Yong Yu",
        "Jun Wang",
        "Weinan Zhang"
      ],
      "abstract": "While large language models (LLMs) have significantly advanced mathematical\nreasoning, Process Reward Models (PRMs) have been developed to evaluate the\nlogical validity of reasoning steps. However, PRMs still struggle with\nout-of-distribution (OOD) challenges. This paper identifies key OOD issues,\nincluding step OOD, caused by differences in reasoning patterns across model\ntypes and sizes, and question OOD, which arises from dataset shifts between\ntraining data and real-world problems. To address these issues, we introduce\nRetrieval-Augmented Process Reward Model (RetrievalPRM), a novel framework\ndesigned to tackle these OOD issues. By utilizing a two-stage\nretrieval-enhanced mechanism, RetrievalPRM retrieves semantically similar\nquestions and steps as a warmup, enhancing PRM's ability to evaluate target\nsteps and improving generalization and reasoning consistency across different\nmodels and problem types. Our extensive experiments demonstrate that\nRetrievalPRM outperforms existing baselines across multiple real-world\ndatasets. Our open-source contributions include a retrieval-enhanced dataset, a\ntuning framework for PRM training, and the RetrievalPRM model, establishing a\nnew standard for PRM performance.",
      "tldr_zh": "本文针对Process Reward Models (PRMs)在数学推理中的out-of-distribution (OOD)挑战，包括step OOD（推理模式差异）和question OOD（数据集偏移），提出了一种新型框架Retrieval-Augmented Process Reward Model (RetrievalPRM)。RetrievalPRM采用两阶段检索增强机制，通过检索语义相似的问答和步骤作为预热，提升PRMs的评估能力、泛化和推理一致性。实验结果显示，该模型在多个真实数据集上优于现有基线，并开源了检索增强数据集、PRM训练框架和模型本身，建立了PRM性能的新标准。",
      "categories": [
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14361v1",
      "published_date": "2025-02-20 08:40:09 UTC",
      "updated_date": "2025-02-20 08:40:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:36:37.866245"
    },
    {
      "arxiv_id": "2502.14345v1",
      "title": "FlowAgent: Achieving Compliance and Flexibility for Workflow Agents",
      "title_zh": "FlowAgent：针对工作流代理实现合规性和灵活性",
      "authors": [
        "Yuchen Shi",
        "Siqi Cai",
        "Zihan Xu",
        "Yuei Qin",
        "Gang Li",
        "Hang Shao",
        "Jiawei Chen",
        "Deqing Yang",
        "Ke Li",
        "Xing Sun"
      ],
      "abstract": "The integration of workflows with large language models (LLMs) enables\nLLM-based agents to execute predefined procedures, enhancing automation in\nreal-world applications. Traditional rule-based methods tend to limit the\ninherent flexibility of LLMs, as their predefined execution paths restrict the\nmodels' action space, particularly when the unexpected, out-of-workflow (OOW)\nqueries are encountered. Conversely, prompt-based methods allow LLMs to fully\ncontrol the flow, which can lead to diminished enforcement of procedural\ncompliance. To address these challenges, we introduce FlowAgent, a novel agent\nframework designed to maintain both compliance and flexibility. We propose the\nProcedure Description Language (PDL), which combines the adaptability of\nnatural language with the precision of code to formulate workflows. Building on\nPDL, we develop a comprehensive framework that empowers LLMs to manage OOW\nqueries effectively, while keeping the execution path under the supervision of\na set of controllers. Additionally, we present a new evaluation methodology to\nrigorously assess an LLM agent's ability to handle OOW scenarios, going beyond\nroutine flow compliance tested in existing benchmarks. Experiments on three\ndatasets demonstrate that FlowAgent not only adheres to workflows but also\neffectively manages OOW queries, highlighting its dual strengths in compliance\nand flexibility. The code is available at\nhttps://github.com/Lightblues/FlowAgent.",
      "tldr_zh": "这篇论文介绍了 FlowAgent，一种新型代理框架，旨在平衡大型语言模型 (LLMs) 在工作流执行中的遵守性和灵活性，以解决传统规则-based 方法的限制性和 prompt-based 方法的遵守性问题。作者提出了 Procedure Description Language (PDL)，它结合自然语言的适应性和代码的精确性来定义工作流，并通过一组控制器监督执行路径，同时允许 LLMs 有效处理 out-of-workflow (OOW) 查询。实验在三个数据集上验证了 FlowAgent 的性能，不仅确保了工作流遵守，还成功管理了 OOW 场景，并引入了一种新评估方法来全面评估代理的处理能力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages",
      "pdf_url": "http://arxiv.org/pdf/2502.14345v1",
      "published_date": "2025-02-20 07:59:31 UTC",
      "updated_date": "2025-02-20 07:59:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:36:48.958663"
    },
    {
      "arxiv_id": "2502.14334v1",
      "title": "Purest Quantum State Identification",
      "title_zh": "最纯量子态识别",
      "authors": [
        "Yingqi Yu",
        "Honglin Chen",
        "Jun Wu",
        "Wei Xie",
        "Xiangyang Li"
      ],
      "abstract": "Precise identification of quantum states under noise constraints is essential\nfor quantum information processing. In this study, we generalize the classical\nbest arm identification problem to quantum domains, designing methods for\nidentifying the purest one within $K$ unknown $n$-qubit quantum states using\n$N$ samples. %, with direct applications in quantum computation and quantum\ncommunication. We propose two distinct algorithms: (1) an algorithm employing\nincoherent measurements, achieving error $\\exp\\left(- \\Omega\\left(\\frac{N\nH_1}{\\log(K) 2^n }\\right) \\right)$, and (2) an algorithm utilizing coherent\nmeasurements, achieving error $\\exp\\left(- \\Omega\\left(\\frac{N H_2}{\\log(K)\n}\\right) \\right)$, highlighting the power of quantum memory. Furthermore, we\nestablish a lower bound by proving that all strategies with fixed two-outcome\nincoherent POVM must suffer error probability exceeding $ \\exp\\left( -\nO\\left(\\frac{NH_1}{2^n}\\right)\\right)$. This framework provides concrete design\nprinciples for overcoming sampling bottlenecks in quantum technologies.",
      "tldr_zh": "本文将经典最佳 arm identification 问题泛化到量子领域，设计算法使用 N 个样本识别 K 个未知 n-qubit quantum states 中纯度最高的一个，以应对量子信息处理中的噪声约束。研究提出了两种算法：一个基于 incoherent measurements，错误率达到 exp(-Ω(N H1 / (log(K) 2^n)))；另一个利用 coherent measurements，错误率达到 exp(-Ω(N H2 / log(K)))，突显了量子内存的优势。同时，建立了一个下界，证明所有固定两结果 incoherent POVM 策略的错误概率至少为 exp(-O(N H1 / 2^n))，为克服量子技术中的采样瓶颈提供了具体设计原则。",
      "categories": [
        "quant-ph",
        "cs.AI"
      ],
      "primary_category": "quant-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14334v1",
      "published_date": "2025-02-20 07:42:16 UTC",
      "updated_date": "2025-02-20 07:42:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:37:01.481118"
    },
    {
      "arxiv_id": "2502.14934v1",
      "title": "Fast and Accurate Blind Flexible Docking",
      "title_zh": "快速且准确的盲式柔性对接",
      "authors": [
        "Zizhuo Zhang",
        "Lijun Wu",
        "Kaiyuan Gao",
        "Jiangchao Yao",
        "Tao Qin",
        "Bo Han"
      ],
      "abstract": "Molecular docking that predicts the bound structures of small molecules\n(ligands) to their protein targets, plays a vital role in drug discovery.\nHowever, existing docking methods often face limitations: they either overlook\ncrucial structural changes by assuming protein rigidity or suffer from low\ncomputational efficiency due to their reliance on generative models for\nstructure sampling. To address these challenges, we propose FABFlex, a fast and\naccurate regression-based multi-task learning model designed for realistic\nblind flexible docking scenarios, where proteins exhibit flexibility and\nbinding pocket sites are unknown (blind). Specifically, FABFlex's architecture\ncomprises three specialized modules working in concert: (1) A pocket prediction\nmodule that identifies potential binding sites, addressing the challenges\ninherent in blind docking scenarios. (2) A ligand docking module that predicts\nthe bound (holo) structures of ligands from their unbound (apo) states. (3) A\npocket docking module that forecasts the holo structures of protein pockets\nfrom their apo conformations. Notably, FABFlex incorporates an iterative update\nmechanism that serves as a conduit between the ligand and pocket docking\nmodules, enabling continuous structural refinements. This approach effectively\nintegrates the three subtasks of blind flexible docking-pocket identification,\nligand conformation prediction, and protein flexibility modeling-into a\nunified, coherent framework. Extensive experiments on public benchmark datasets\ndemonstrate that FABFlex not only achieves superior effectiveness in predicting\naccurate binding modes but also exhibits a significant speed advantage (208\n$\\times$) compared to existing state-of-the-art methods. Our code is released\nat https://github.com/tmlr-group/FABFlex.",
      "tldr_zh": "该论文提出 FABFlex，一种基于回归的多任务学习模型，用于解决 molecular docking 中的挑战，特别是蛋白质柔性和未知结合位点（blind flexible docking）的场景。FABFlex 由三个模块组成：口袋预测模块识别潜在结合位点、配体对接模块从 apo 状态预测配体的 holo 结构，以及口袋对接模块预测蛋白口袋的 holo 结构，并通过迭代更新机制实现结构优化。实验结果显示，FABFlex 在公共基准数据集上实现了更高的结合模式预测准确性，并比现有最先进方法快 208 倍，为药物发现提供高效工具。代码已开源于 https://github.com/tmlr-group/FABFlex。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.QM",
      "comment": "25 pages, Accepted by ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.14934v1",
      "published_date": "2025-02-20 07:31:13 UTC",
      "updated_date": "2025-02-20 07:31:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:37:15.495341"
    },
    {
      "arxiv_id": "2502.14333v1",
      "title": "A Survey on Feedback-based Multi-step Reasoning for Large Language Models on Mathematics",
      "title_zh": "翻译失败",
      "authors": [
        "Ting-Ruen Wei",
        "Haowei Liu",
        "Xuyang Wu",
        "Yi Fang"
      ],
      "abstract": "Recent progress in large language models (LLM) found chain-of-thought\nprompting strategies to improve the reasoning ability of LLMs by encouraging\nproblem solving through multiple steps. Therefore, subsequent research aimed to\nintegrate the multi-step reasoning process into the LLM itself through process\nrewards as feedback and achieved improvements over prompting strategies. Due to\nthe cost of step-level annotation, some turn to outcome rewards as feedback.\nAside from these training-based approaches, training-free techniques leverage\nfrozen LLMs or external tools for feedback at each step to enhance the\nreasoning process. With the abundance of work in mathematics due to its logical\nnature, we present a survey of strategies utilizing feedback at the step and\noutcome levels to enhance multi-step math reasoning for LLMs. As multi-step\nreasoning emerges a crucial component in scaling LLMs, we hope to establish its\nfoundation for easier understanding and empower further research.",
      "tldr_zh": "这篇调查论文探讨了反馈机制如何提升大型语言模型（LLMs）在数学领域的多步推理能力，特别是基于 chain-of-thought 提示策略的进展。论文总结了训练-based 方法，如使用过程奖励（process rewards）或结果奖励（outcome rewards）作为反馈，以整合多步推理过程，同时讨论了训练-free 技术，利用冻结 LLMs 或外部工具在每个步骤提供反馈。总体而言，这些策略显著改善了 LLMs 在逻辑性强的数学任务上的性能，并为未来多步推理研究奠定基础。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14333v1",
      "published_date": "2025-02-20 07:31:00 UTC",
      "updated_date": "2025-02-20 07:31:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:37:26.172803"
    },
    {
      "arxiv_id": "2502.14318v1",
      "title": "Line Goes Up? Inherent Limitations of Benchmarks for Evaluating Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "James Fodor"
      ],
      "abstract": "Large language models (LLMs) regularly demonstrate new and impressive\nperformance on a wide range of language, knowledge, and reasoning benchmarks.\nSuch rapid progress has led many commentators to argue that LLM general\ncognitive capabilities have likewise rapidly improved, with the implication\nthat such models are becoming progressively more capable on various real-world\ntasks. Here I summarise theoretical and empirical considerations to challenge\nthis narrative. I argue that inherent limitations with the benchmarking\nparadigm, along with specific limitations of existing benchmarks, render\nbenchmark performance highly unsuitable as a metric for generalisable\ncompetence over cognitive tasks. I also contend that alternative methods for\nassessing LLM capabilities, including adversarial stimuli and interpretability\ntechniques, have shown that LLMs do not have robust competence in many language\nand reasoning tasks, and often fail to learn representations which facilitate\ngeneralisable inferences. I conclude that benchmark performance should not be\nused as a reliable indicator of general LLM cognitive capabilities.",
      "tldr_zh": "该论文质疑了大型语言模型 (LLMs) 在基准测试中表现不断提升就意味着其一般认知能力快速进步的观点。作者总结了基准测试的固有局限性，包括基准范式的内在问题和现有基准的具体缺陷，这些使得基准表现无法可靠地衡量LLMs在认知任务上的可泛化能力。同时，通过对抗性刺激(adversarial stimuli)和可解释性技术(interpretability techniques)等替代方法，研究发现LLMs在许多语言和推理任务上缺乏稳健能力，往往无法学习促进泛化推理的表示。最终，作者得出结论，基准测试成绩不应被视为评估LLMs一般认知能力的可靠指标。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages",
      "pdf_url": "http://arxiv.org/pdf/2502.14318v1",
      "published_date": "2025-02-20 07:13:29 UTC",
      "updated_date": "2025-02-20 07:13:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:37:37.259801"
    },
    {
      "arxiv_id": "2502.14316v1",
      "title": "Textured 3D Regenerative Morphing with 3D Diffusion Prior",
      "title_zh": "翻译失败",
      "authors": [
        "Songlin Yang",
        "Yushi Lan",
        "Honghua Chen",
        "Xingang Pan"
      ],
      "abstract": "Textured 3D morphing creates smooth and plausible interpolation sequences\nbetween two 3D objects, focusing on transitions in both shape and texture. This\nis important for creative applications like visual effects in filmmaking.\nPrevious methods rely on establishing point-to-point correspondences and\ndetermining smooth deformation trajectories, which inherently restrict them to\nshape-only morphing on untextured, topologically aligned datasets. This\nrestriction leads to labor-intensive preprocessing and poor generalization. To\novercome these challenges, we propose a method for 3D regenerative morphing\nusing a 3D diffusion prior. Unlike previous methods that depend on explicit\ncorrespondences and deformations, our method eliminates the additional need for\nobtaining correspondence and uses the 3D diffusion prior to generate morphing.\nSpecifically, we introduce a 3D diffusion model and interpolate the source and\ntarget information at three levels: initial noise, model parameters, and\ncondition features. We then explore an Attention Fusion strategy to generate\nmore smooth morphing sequences. To further improve the plausibility of semantic\ninterpolation and the generated 3D surfaces, we propose two strategies: (a)\nToken Reordering, where we match approximate tokens based on semantic analysis\nto guide implicit correspondences in the denoising process of the diffusion\nmodel, and (b) Low-Frequency Enhancement, where we enhance low-frequency\nsignals in the tokens to improve the quality of generated surfaces.\nExperimental results show that our method achieves superior smoothness and\nplausibility in 3D morphing across diverse cross-category object pairs,\noffering a novel regenerative method for 3D morphing with textured\nrepresentations.",
      "tldr_zh": "这篇论文提出了一种基于3D diffusion prior的Textured 3D Regenerative Morphing方法，用于创建形状和纹理平滑过渡的3D物体插值序列，适用于视觉效果等创意应用，并克服了传统方法依赖点对点对应和变形的限制。核心技术包括在初始噪声、模型参数和条件特征三个层面进行插值，并引入Attention Fusion策略来生成更平滑的序列。同时，论文引入Token Reordering（通过语义分析匹配近似token引导隐式对应）和Low-Frequency Enhancement（增强token中的低频信号）来提升语义插值和生成表面的合理性。实验结果表明，该方法在多样跨类别物体对上实现了优越的平滑性和真实性，提供了一种新型的带纹理3D变形再生方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14316v1",
      "published_date": "2025-02-20 07:02:22 UTC",
      "updated_date": "2025-02-20 07:02:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:37:51.012100"
    },
    {
      "arxiv_id": "2502.15830v1",
      "title": "Show Me Your Code! Kill Code Poisoning: A Lightweight Method Based on Code Naturalness",
      "title_zh": "展示你的代码！消灭代码投毒：一种基于代码自然性的轻",
      "authors": [
        "Weisong Sun",
        "Yuchen Chen",
        "Mengzhe Yuan",
        "Chunrong Fang",
        "Zhenpeng Chen",
        "Chong Wang",
        "Yang Liu",
        "Baowen Xu",
        "Zhenyu Chen"
      ],
      "abstract": "Neural code models (NCMs) have demonstrated extraordinary capabilities in\ncode intelligence tasks. Meanwhile, the security of NCMs and NCMs-based systems\nhas garnered increasing attention. In particular, NCMs are often trained on\nlarge-scale data from potentially untrustworthy sources, providing attackers\nwith the opportunity to manipulate them by inserting crafted samples into the\ndata. This type of attack is called a code poisoning attack (also known as a\nbackdoor attack). It allows attackers to implant backdoors in NCMs and thus\ncontrol model behavior, which poses a significant security threat. However,\nthere is still a lack of effective techniques for detecting various complex\ncode poisoning attacks.\n  In this paper, we propose an innovative and lightweight technique for code\npoisoning detection named KillBadCode. KillBadCode is designed based on our\ninsight that code poisoning disrupts the naturalness of code. Specifically,\nKillBadCode first builds a code language model (CodeLM) on a lightweight\n$n$-gram language model. Then, given poisoned data, KillBadCode utilizes CodeLM\nto identify those tokens in (poisoned) code snippets that will make the code\nsnippets more natural after being deleted as trigger tokens. Considering that\nthe removal of some normal tokens in a single sample might also enhance code\nnaturalness, leading to a high false positive rate (FPR), we aggregate the\ncumulative improvement of each token across all samples. Finally, KillBadCode\npurifies the poisoned data by removing all poisoned samples containing the\nidentified trigger tokens. The experimental results on two code poisoning\nattacks and four code intelligence tasks demonstrate that KillBadCode\nsignificantly outperforms four baselines. More importantly, KillBadCode is very\nefficient, with a minimum time consumption of only 5 minutes, and is 25 times\nfaster than the best baseline on average.",
      "tldr_zh": "本研究针对神经代码模型（NCMs）面临的安全威胁，特别是代码中毒攻击（code poisoning attack，或backdoor attack），提出了一种轻量级检测技术KillBadCode，以解决现有检测方法的不足。KillBadCode基于代码的自然性（code naturalness）构建了一个轻量级的n-gram代码语言模型（CodeLM），通过识别并删除那些使代码片段更自然的触发标记（trigger tokens）来检测和净化中毒数据，同时通过聚合标记的累积改进降低假阳性率。实验结果显示，KillBadCode在两种代码中毒攻击和四种代码智能任务上显著优于四个基线模型，且其检测效率极高，最快仅需5分钟，平均比最佳基线快25倍。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CR",
        "68-06",
        "D.2.3; I.2.7"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted to the 47th International Conference on Software Engineering\n  (ICSE 2025)",
      "pdf_url": "http://arxiv.org/pdf/2502.15830v1",
      "published_date": "2025-02-20 06:53:09 UTC",
      "updated_date": "2025-02-20 06:53:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:38:02.728676"
    },
    {
      "arxiv_id": "2502.14302v1",
      "title": "MedHallu: A Comprehensive Benchmark for Detecting Medical Hallucinations in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Shrey Pandit",
        "Jiawei Xu",
        "Junyuan Hong",
        "Zhangyang Wang",
        "Tianlong Chen",
        "Kaidi Xu",
        "Ying Ding"
      ],
      "abstract": "Advancements in Large Language Models (LLMs) and their increasing use in\nmedical question-answering necessitate rigorous evaluation of their\nreliability. A critical challenge lies in hallucination, where models generate\nplausible yet factually incorrect outputs. In the medical domain, this poses\nserious risks to patient safety and clinical decision-making. To address this,\nwe introduce MedHallu, the first benchmark specifically designed for medical\nhallucination detection. MedHallu comprises 10,000 high-quality question-answer\npairs derived from PubMedQA, with hallucinated answers systematically generated\nthrough a controlled pipeline. Our experiments show that state-of-the-art LLMs,\nincluding GPT-4o, Llama-3.1, and the medically fine-tuned UltraMedical,\nstruggle with this binary hallucination detection task, with the best model\nachieving an F1 score as low as 0.625 for detecting \"hard\" category\nhallucinations. Using bidirectional entailment clustering, we show that\nharder-to-detect hallucinations are semantically closer to ground truth.\nThrough experiments, we also show incorporating domain-specific knowledge and\nintroducing a \"not sure\" category as one of the answer categories improves the\nprecision and F1 scores by up to 38% relative to baselines.",
      "tldr_zh": "本研究引入了MedHallu，这是一个全面基准测试，用于检测大型语言模型(LLMs)在医疗问答中的幻觉问题。MedHallu包含从PubMedQA派生的10,000个高质量问答对，通过控制管道系统生成幻觉答案，以评估模型的可靠性。实验结果显示，先进LLMs如GPT-4o、Llama-3.1和UltraMedical在二元幻觉检测任务中表现不佳，最佳模型在“hard”类别幻觉检测上的F1 score仅为0.625。利用双向蕴含聚类(bidirectional entailment clustering)，研究发现更难检测的幻觉在语义上更接近真实答案。通过融入领域特定知识并引入“not sure”类别，模型的精确度和F1 score相对基线提高了多达38%。这为提升LLMs在医疗领域的可信度提供了重要见解。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Code and dataset are available at https://medhallu.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2502.14302v1",
      "published_date": "2025-02-20 06:33:23 UTC",
      "updated_date": "2025-02-20 06:33:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:38:15.136384"
    },
    {
      "arxiv_id": "2502.14301v1",
      "title": "SEA-HELM: Southeast Asian Holistic Evaluation of Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yosephine Susanto",
        "Adithya Venkatadri Hulagadri",
        "Jann Railey Montalan",
        "Jian Gang Ngui",
        "Xian Bin Yong",
        "Weiqi Leong",
        "Hamsawardhini Rengarajan",
        "Peerat Limkonchotiwat",
        "Yifan Mai",
        "William Chandra Tjhi"
      ],
      "abstract": "With the rapid emergence of novel capabilities in Large Language Models\n(LLMs), the need for rigorous multilingual and multicultural benchmarks that\nare integrated has become more pronounced. Though existing LLM benchmarks are\ncapable of evaluating specific capabilities of LLMs in English as well as in\nvarious mid- to low-resource languages, including those in the Southeast Asian\n(SEA) region, a comprehensive and authentic evaluation suite for the SEA\nlanguages has not been developed thus far. Here, we present SEA-HELM, a\nholistic linguistic and cultural LLM evaluation suite that emphasizes SEA\nlanguages, comprising five core pillars: (1) NLP Classics, (2) LLM-specifics,\n(3) SEA Linguistics, (4) SEA Culture, (5) Safety. SEA-HELM currently supports\nFilipino, Indonesian, Tamil, Thai, and Vietnamese. We also introduce the\nSEA-HELM leaderboard, which allows users to understand models' multilingual and\nmulticultural performance in a systematic and user-friendly manner.",
      "tldr_zh": "该论文介绍了 SEA-HELM，一种针对东南亚（SEA）语言的整体性大型语言模型（LLMs）评估套件，旨在填补现有基准在多语言和多文化评估方面的不足。SEA-HELM 包括五个核心支柱：（1）NLP Classics，（2）LLM-specifics，（3）SEA Linguistics，（4）SEA Culture，以及（5）Safety，目前支持菲律宾语、印尼语、泰米尔语、泰语和越南语。该套件还推出了 SEA-HELM 排行榜，帮助用户系统地评估和比较模型的多语言和多文化性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14301v1",
      "published_date": "2025-02-20 06:32:45 UTC",
      "updated_date": "2025-02-20 06:32:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:38:26.395237"
    },
    {
      "arxiv_id": "2502.14297v2",
      "title": "Evaluating Sakana's AI Scientist for Autonomous Research: Wishful Thinking or an Emerging Reality Towards 'Artificial Research Intelligence' (ARI)?",
      "title_zh": "翻译失败",
      "authors": [
        "Joeran Beel",
        "Min-Yen Kan",
        "Moritz Baumgart"
      ],
      "abstract": "A major step toward Artificial General Intelligence (AGI) and Super\nIntelligence is AI's ability to autonomously conduct research - what we term\nArtificial Research Intelligence (ARI). If machines could generate hypotheses,\nconduct experiments, and write research papers without human intervention, it\nwould transform science. Sakana recently introduced the 'AI Scientist',\nclaiming to conduct research autonomously, i.e. they imply to have achieved\nwhat we term Artificial Research Intelligence (ARI). The AI Scientist gained\nmuch attention, but a thorough independent evaluation has yet to be conducted.\n  Our evaluation of the AI Scientist reveals critical shortcomings. The\nsystem's literature reviews produced poor novelty assessments, often\nmisclassifying established concepts (e.g., micro-batching for stochastic\ngradient descent) as novel. It also struggles with experiment execution: 42% of\nexperiments failed due to coding errors, while others produced flawed or\nmisleading results. Code modifications were minimal, averaging 8% more\ncharacters per iteration, suggesting limited adaptability. Generated\nmanuscripts were poorly substantiated, with a median of five citations, most\noutdated (only five of 34 from 2020 or later). Structural errors were frequent,\nincluding missing figures, repeated sections, and placeholder text like\n'Conclusions Here'. Some papers contained hallucinated numerical results.\n  Despite these flaws, the AI Scientist represents a leap forward in research\nautomation. It generates full research manuscripts with minimal human input,\nchallenging expectations of AI-driven science. Many reviewers might struggle to\ndistinguish its work from human researchers. While its quality resembles a\nrushed undergraduate paper, its speed and cost efficiency are unprecedented,\nproducing a full paper for USD 6 to 15 with 3.5 hours of human involvement, far\noutpacing traditional researchers.",
      "tldr_zh": "本论文评估了Sakana的AI Scientist系统，探讨其是否实现了自主研究能力，即Artificial Research Intelligence (ARI)，并质疑这是否是空想还是现实。评估发现，该系统在文献综述中常误判新颖性（如将微批处理误认作新概念），实验执行失败率高达42%，代码修改有限且生成的论文存在结构问题，包括缺少图表、重复部分和幻觉结果。尽管如此，AI Scientist在研究自动化方面取得了进展，能以极低成本（3.5小时人工参与和6-15美元）快速生成完整稿件，挑战了传统科研模式。总体而言，这标志着AI驱动科学的前进，但当前质量仍需提升。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "16 pages",
      "pdf_url": "http://arxiv.org/pdf/2502.14297v2",
      "published_date": "2025-02-20 06:22:03 UTC",
      "updated_date": "2025-02-22 11:35:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:38:37.413150"
    },
    {
      "arxiv_id": "2502.14293v1",
      "title": "Graph Anomaly Detection via Adaptive Test-time Representation Learning across Out-of-Distribution Domains",
      "title_zh": "图异常检测：通过自适应测试时表示学习跨分布外域",
      "authors": [
        "Delaram Pirhayati",
        "Arlei Silva"
      ],
      "abstract": "Graph Anomaly Detection (GAD) has demonstrated great effectiveness in\nidentifying unusual patterns within graph-structured data. However, while\nlabeled anomalies are often scarce in emerging applications, existing\nsupervised GAD approaches are either ineffective or not applicable when moved\nacross graph domains due to distribution shifts and heterogeneous feature\nspaces. To address these challenges, we present AdaGraph-T3, a novel test-time\ntraining framework for cross-domain GAD. AdaGraph-T3 combines supervised and\nself-supervised learning during training while adapting to a new domain during\ntest time using only self-supervised learning by leveraging a homophily-based\naffinity score that captures domain-invariant properties of anomalies. Our\nframework introduces four key innovations to cross-domain GAD: an effective\nself-supervision scheme, an attention-based mechanism that dynamically learns\nedge importance weights during message passing, domain-specific encoders for\nhandling heterogeneous features, and class-aware regularization to address\nimbalance. Experiments across multiple cross-domain settings demonstrate that\nAdaGraph-T3 significantly outperforms existing approaches, achieving average\nimprovements of over 6.6% in AUROC and 7.9% in AUPRC compared to the best\ncompeting model.",
      "tldr_zh": "该研究针对图异常检测(Graph Anomaly Detection, GAD)在跨域场景中的挑战，提出了一种自适应测试时表示学习框架AdaGraph-T3，以应对分布偏移和异构特征空间问题。AdaGraph-T3在训练时结合监督和自监督学习，在测试时仅使用自监督学习，通过基于homophily的亲和力分数捕获域不变的异常属性，并引入注意力机制、域特定编码器和类感知正则化等创新来动态学习边重要性和处理不平衡。实验结果显示，该框架在多个跨域设置中显著优于现有方法，平均提升AUROC 6.6%和AUPRC 7.9%。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14293v1",
      "published_date": "2025-02-20 06:14:07 UTC",
      "updated_date": "2025-02-20 06:14:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:38:50.665821"
    },
    {
      "arxiv_id": "2502.15828v1",
      "title": "A Stronger Mixture of Low-Rank Experts for Fine-Tuning Foundation Models",
      "title_zh": "翻译失败",
      "authors": [
        "Mengyang Sun",
        "Yihao Wang",
        "Tao Feng",
        "Dan Zhang",
        "Yifan Zhu",
        "Jie Tang"
      ],
      "abstract": "In order to streamline the fine-tuning of foundation models, Low-Rank\nAdapters (LoRAs) have been substantially adopted across various fields,\nincluding instruction tuning and domain adaptation. The underlying concept of\nLoRA involves decomposing a full-rank matrix into the product of two lower-rank\nmatrices, which reduces storage consumption and accelerates the training\nprocess. Furthermore, to address the limited expressive capacity of LoRA, the\nMixture-of-Expert (MoE) has been introduced for incorporating multiple LoRA\nadapters. The integration of LoRA experts leads to a visible improvement across\nseveral downstream scenes. However, the mixture of LoRAs (MoE-LoRA) still\nexhibits its low robustness during tuning and inferring. Inspired by the\nRiemannian Preconditioners which train LoRA as a sub-space projector, we\npropose a new training strategy for MoE-LoRA, to stabilize and boost its\nfeature learning procedure by multi-space projections. Examinations on SGD and\nAdamW optimizers demonstrate the effectiveness of our methodology. Source code\nis available at https://github.com/THUDM/MoELoRA_Riemannian.",
      "tldr_zh": "该论文针对基础模型的微调，提出了一种增强的 Mixture-of-Expert (MoE) 与 Low-Rank Adapters (LoRA) 结合方法，即 MoE-LoRA，以解决其鲁棒性不足的问题。受 Riemannian Preconditioners 启发，研究团队引入多空间投影策略，将 MoE-LoRA 训练为子空间投影器，从而稳定和提升特征学习过程。实验在 SGD 和 AdamW 优化器上验证了该方法的有效性，并提供了源代码以便复现。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.15828v1",
      "published_date": "2025-02-20 05:58:53 UTC",
      "updated_date": "2025-02-20 05:58:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:39:02.188062"
    },
    {
      "arxiv_id": "2502.14281v3",
      "title": "Correcting Noisy Multilabel Predictions: Modeling Label Noise through Latent Space Shifts",
      "title_zh": "修正噪声多标签预测：通过潜在空间偏移建模标签噪声",
      "authors": [
        "Weipeng Huang",
        "Qin Li",
        "Yang Xiao",
        "Cheng Qiao",
        "Tie Cai",
        "Junwei Liang",
        "Neil J. Hurley",
        "Guangyuan Piao"
      ],
      "abstract": "Noise in data appears to be inevitable in most real-world machine learning\napplications and would cause severe overfitting problems. Not only can data\nfeatures contain noise, but labels are also prone to be noisy due to human\ninput. In this paper, rather than noisy label learning in multiclass\nclassifications, we instead focus on the less explored area of noisy label\nlearning for multilabel classifications. Specifically, we investigate the\npost-correction of predictions generated from classifiers learned with noisy\nlabels. The reasons are two-fold. Firstly, this approach can directly work with\nthe trained models to save computational resources. Secondly, it could be\napplied on top of other noisy label correction techniques to achieve further\nimprovements. To handle this problem, we appeal to deep generative approaches\nthat are possible for uncertainty estimation. Our model posits that label noise\narises from a stochastic shift in the latent variable, providing a more robust\nand beneficial means for noisy learning. We develop both unsupervised and\nsemi-supervised learning methods for our model. The extensive empirical study\npresents solid evidence to that our approach is able to consistently improve\nthe independent models and performs better than a number of existing methods\nacross various noisy label settings. Moreover, a comprehensive empirical\nanalysis of the proposed method is carried out to validate its robustness,\nincluding sensitivity analysis and an ablation study, among other elements.",
      "tldr_zh": "这篇论文针对多标签分类(multilabel classifications)中的噪声标签学习(noisy label learning)问题，提出一种后修正预测的方法，通过潜在空间偏移(latent space shifts)来建模标签噪声。模型假设噪声源于潜在变量的随机偏移，并采用深度生成方法(deep generative approaches)开发了无监督和半监督学习方案，以提升预测的鲁棒性和不确定性估计。实验结果显示，该方法在各种噪声设置下显著改善了基线模型的表现，比现有方法更有效，并通过敏感性分析和消融研究验证了其可靠性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14281v3",
      "published_date": "2025-02-20 05:41:52 UTC",
      "updated_date": "2025-05-08 03:34:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:39:15.068101"
    },
    {
      "arxiv_id": "2502.14280v1",
      "title": "EpMAN: Episodic Memory AttentioN for Generalizing to Longer Contexts",
      "title_zh": "翻译失败",
      "authors": [
        "Subhajit Chaudhury",
        "Payel Das",
        "Sarathkrishna Swaminathan",
        "Georgios Kollias",
        "Elliot Nelson",
        "Khushbu Pahwa",
        "Tejaswini Pedapati",
        "Igor Melnyk",
        "Matthew Riemer"
      ],
      "abstract": "Recent advances in Large Language Models (LLMs) have yielded impressive\nsuccesses on many language tasks. However, efficient processing of long\ncontexts using LLMs remains a significant challenge. We introduce\n\\textbf{EpMAN} -- a method for processing long contexts in an \\textit{episodic\nmemory} module while \\textit{holistically attending to} semantically relevant\ncontext chunks. The output of \\textit{episodic attention} is then used to\nreweigh the decoder's self-attention to the stored KV cache of the context\nduring training and generation. When an LLM decoder is trained using\n\\textbf{EpMAN}, its performance on multiple challenging single-hop long-context\nrecall and question-answering benchmarks is found to be stronger and more\nrobust across the range from 16k to 256k tokens than baseline decoders trained\nwith self-attention, and popular retrieval-augmented generation frameworks.",
      "tldr_zh": "该研究提出了一种名为EpMAN的机制，用于提升大型语言模型(LLMs)在处理长上下文时的性能。EpMAN通过一个episodic memory模块整体关注语义相关的上下文块，并利用episodic attention的输出来重新调整解码器的self-attention机制，从而对存储的KV cache进行加权处理。实验结果显示，在从16k到256k tokens的范围内，EpMAN训练的模型在单跳长上下文回忆和问答基准测试中，比基线self-attention模型和流行检索增强生成框架更强大且鲁棒。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14280v1",
      "published_date": "2025-02-20 05:41:15 UTC",
      "updated_date": "2025-02-20 05:41:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:39:26.757722"
    },
    {
      "arxiv_id": "2502.14276v1",
      "title": "STeCa: Step-level Trajectory Calibration for LLM Agent Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Hanlin Wang",
        "Jian Wang",
        "Chak Tou Leong",
        "Wenjie Li"
      ],
      "abstract": "Large language model (LLM)-based agents have shown promise in tackling\ncomplex tasks by interacting dynamically with the environment. Existing work\nprimarily focuses on behavior cloning from expert demonstrations and preference\nlearning through exploratory trajectory sampling. However, these methods often\nstruggle in long-horizon tasks, where suboptimal actions accumulate step by\nstep, causing agents to deviate from correct task trajectories. To address\nthis, we highlight the importance of timely calibration and the need to\nautomatically construct calibration trajectories for training agents. We\npropose Step-Level Trajectory Calibration (STeCa), a novel framework for LLM\nagent learning. Specifically, STeCa identifies suboptimal actions through a\nstep-level reward comparison during exploration. It constructs calibrated\ntrajectories using LLM-driven reflection, enabling agents to learn from\nimproved decision-making processes. These calibrated trajectories, together\nwith successful trajectory data, are utilized for reinforced training.\nExtensive experiments demonstrate that STeCa significantly outperforms existing\nmethods. Further analysis highlights that step-level calibration enables agents\nto complete tasks with greater robustness. Our code and data are available at\nhttps://github.com/WangHanLinHenry/STeCa.",
      "tldr_zh": "该论文针对LLM-based agents在长时任务中因次优动作积累而偏离正确轨迹的问题，提出STeCa框架，即步级轨迹校准方法。STeCa通过步级奖励比较识别次优动作，并利用LLM驱动的反思自动构建校准轨迹，以改进决策过程。实验结果表明，STeCa显著优于现有behavior cloning和preference learning方法，提升了代理的鲁棒性和任务完成性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14276v1",
      "published_date": "2025-02-20 05:28:44 UTC",
      "updated_date": "2025-02-20 05:28:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:39:38.950294"
    },
    {
      "arxiv_id": "2502.14273v1",
      "title": "LLM-EvRep: Learning an LLM-Compatible Event Representation Using a Self-Supervised Framework",
      "title_zh": "翻译失败",
      "authors": [
        "Zongyou Yu",
        "Qiang Qu",
        "Qian Zhang",
        "Nan Zhang",
        "Xiaoming Chen"
      ],
      "abstract": "Recent advancements in event-based recognition have demonstrated significant\npromise, yet most existing approaches rely on extensive training, limiting\ntheir adaptability for efficient processing of event-driven visual content.\nMeanwhile, large language models (LLMs) have exhibited remarkable zero-shot\ncapabilities across diverse domains, but their application to event-based\nvisual recognition remains largely unexplored. To bridge this gap, we propose\n\\textbf{LLM-EvGen}, an event representation generator that produces\nLLM-compatible event representations \\textbf{LLM-EvRep}, thereby enhancing the\nperformance of LLMs on event recognition tasks. The generator is trained using\na self-supervised framework, aligning the generated representations with\nsemantic consistency and structural fidelity. Comprehensive experiments were\nconducted on three datasets: N-ImageNet, N-Caltech101, and N-MNIST. The results\ndemonstrate that our method, \\textbf{LLM-EvRep}, outperforms the event-to-video\nmethod, E2VID, by 15.93\\%, 0.82\\%, and 50.21\\%, respectively, in recognition\ntasks when evaluated using GPT-4o.",
      "tldr_zh": "该研究针对事件-based 视觉识别的适应性问题，提出了一种自监督框架，用于学习与大语言模型 (LLMs) 兼容的事件表示 LLM-EvRep。方法通过事件表示生成器 LLM-EvGen 生成语义一致且结构保真的表示，从而增强 LLMs 在事件识别任务中的零-shot 性能。在 N-ImageNet、N-Caltech101 和 N-MNIST 数据集上的实验显示，LLM-EvRep 分别比基线方法 E2VID 提高了 15.93%、0.82% 和 50.21% 的识别准确率，使用 GPT-4o 进行评估，为事件驱动视觉内容处理提供了高效解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "6 pages, 2 figures,Companion Proceedings of the ACM Web Conference\n  2025 (WWW Companion '25)",
      "pdf_url": "http://arxiv.org/pdf/2502.14273v1",
      "published_date": "2025-02-20 05:18:36 UTC",
      "updated_date": "2025-02-20 05:18:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:39:51.177880"
    },
    {
      "arxiv_id": "2502.14272v1",
      "title": "Capturing Nuanced Preferences: Preference-Aligned Distillation for Small Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yanggan Gu",
        "Junzhuo Li",
        "Sirui Huang",
        "Xin Zou",
        "Zhenghua Li",
        "Xuming Hu"
      ],
      "abstract": "Aligning small language models (SLMs) with human values typically involves\ndistilling preference knowledge from large language models (LLMs). However,\nexisting distillation methods model preference knowledge in teacher LLMs by\ncomparing pairwise responses, overlooking the extent of difference between\nresponses. This limitation hinders student SLMs from capturing the nuanced\npreferences for multiple responses. In this paper, we propose a\nPreference-Aligned Distillation (PAD) framework, which models teacher's\npreference knowledge as a probability distribution over all potential\npreferences, thereby providing more nuanced supervisory signals. Our insight in\ndeveloping PAD is rooted in the demonstration that language models can serve as\nreward functions, reflecting their intrinsic preferences. Based on this, PAD\ncomprises three key steps: (1) sampling diverse responses using\nhigh-temperature; (2) computing rewards for both teacher and student to\nconstruct their intrinsic preference; and (3) training the student's intrinsic\npreference distribution to align with the teacher's. Experiments on four\nmainstream alignment benchmarks demonstrate that PAD consistently and\nsignificantly outperforms existing approaches, achieving over 20\\% improvement\non AlpacaEval 2 and Arena-Hard, indicating superior alignment with human\npreferences. Notably, on MT-Bench, using the \\textsc{Gemma} model family, the\nstudent trained by PAD surpasses its teacher, further validating the\neffectiveness of our PAD.",
      "tldr_zh": "本研究针对小语言模型(SLMs)与人类价值观对齐的问题，指出现有从大型语言模型(LLMs)中提炼偏好知识的方法仅比较成对响应，忽略了响应差异的程度，从而无法捕捉细微偏好。论文提出Preference-Aligned Distillation (PAD)框架，将教师LLMs的偏好知识建模为所有潜在偏好的概率分布，并通过三个关键步骤实现：高温度采样多样响应、计算教师和学生奖励构建内在偏好，以及训练学生偏好分布与教师对齐。实验在AlpacaEval 2、Arena-Hard和MT-Bench等四个基准上显示，PAD比现有方法提升超过20%，且使用Gemma模型家族时，学生模型甚至超过了教师模型，证明了其在提升SLMs人类偏好对齐方面的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Under review",
      "pdf_url": "http://arxiv.org/pdf/2502.14272v1",
      "published_date": "2025-02-20 05:18:23 UTC",
      "updated_date": "2025-02-20 05:18:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:40:03.515243"
    },
    {
      "arxiv_id": "2502.14268v1",
      "title": "MCQA-Eval: Efficient Confidence Evaluation in NLG with Gold-Standard Correctness Labels",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaoou Liu",
        "Zhen Lin",
        "Longchao Da",
        "Chacha Chen",
        "Shubhendu Trivedi",
        "Hua Wei"
      ],
      "abstract": "Large Language Models (LLMs) require robust confidence estimation,\nparticularly in critical domains like healthcare and law where unreliable\noutputs can lead to significant consequences. Despite much recent work in\nconfidence estimation, current evaluation frameworks rely on correctness\nfunctions -- various heuristics that are often noisy, expensive, and possibly\nintroduce systematic biases. These methodological weaknesses tend to distort\nevaluation metrics and thus the comparative ranking of confidence measures. We\nintroduce MCQA-Eval, an evaluation framework for assessing confidence measures\nin Natural Language Generation (NLG) that eliminates dependence on an explicit\ncorrectness function by leveraging gold-standard correctness labels from\nmultiple-choice datasets. MCQA-Eval enables systematic comparison of both\ninternal state-based white-box (e.g. logit-based) and consistency-based\nblack-box confidence measures, providing a unified evaluation methodology\nacross different approaches. Through extensive experiments on multiple LLMs and\nwidely used QA datasets, we report that MCQA-Eval provides efficient and more\nreliable assessments of confidence estimation methods than existing approaches.",
      "tldr_zh": "本论文提出 MCQA-Eval，一种高效的评估框架，用于评估自然语言生成（NLG）中的置信度措施，通过利用多选题数据集的金标准正确性标签，避免了传统正确性函数的嘈杂和偏差问题。该框架支持对内部状态的白盒方法（如基于 logit）和一致性黑盒方法进行系统比较，提供统一的评估方法。在多个大型语言模型（LLMs）和问答（QA）数据集上的实验表明，MCQA-Eval 比现有方法更可靠和高效，尤其适用于医疗和法律等关键领域。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14268v1",
      "published_date": "2025-02-20 05:09:29 UTC",
      "updated_date": "2025-02-20 05:09:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:40:14.190187"
    },
    {
      "arxiv_id": "2502.15827v2",
      "title": "Explainable Artificial Intelligence Model for Evaluating Shear Strength Parameters of Municipal Solid Waste Across Diverse Compositional Profiles",
      "title_zh": "解释性人工智能模型用于评估跨越多样化组成特征的城市固体废物剪切",
      "authors": [
        "Parichat Suknark",
        "Sompote Youwaib",
        "Tipok Kitkobsin",
        "Sirintornthep Towprayoon",
        "Chart Chiemchaisri",
        "Komsilp Wangyao"
      ],
      "abstract": "Accurate prediction of shear strength parameters in Municipal Solid Waste\n(MSW) remains a critical challenge in geotechnical engineering due to the\nheterogeneous nature of waste materials and their temporal evolution through\ndegradation processes. This paper presents a novel explainable artificial\nintelligence (XAI) framework for evaluating cohesion and friction angle across\ndiverse MSW compositional profiles. The proposed model integrates a multi-layer\nperceptron architecture with SHAP (SHapley Additive exPlanations) analysis to\nprovide transparent insights into how specific waste components influence\nstrength characteristics. Training data encompassed large-scale direct shear\ntests across various waste compositions and degradation states. The model\ndemonstrated superior predictive accuracy compared to traditional gradient\nboosting methods, achieving mean absolute percentage errors of 7.42% and 14.96%\nfor friction angle and cohesion predictions, respectively. Through SHAP\nanalysis, the study revealed that fibrous materials and particle size\ndistribution were primary drivers of shear strength variation, with food waste\nand plastics showing significant but non-linear effects. The model's\nexplainability component successfully quantified these relationships, enabling\nevidence-based recommendations for waste management practices. This research\nbridges the gap between advanced machine learning and geotechnical engineering\npractice, offering a reliable tool for rapid assessment of MSW mechanical\nproperties while maintaining interpretability for engineering decision-making.",
      "tldr_zh": "本研究提出一个可解释人工智能（XAI）框架，用于评估城市固体废物（MSW）的剪切强度参数，包括cohesion和friction angle，以应对废物材料异质性和退化过程带来的预测挑战。框架整合multi-layer perceptron架构与SHAP分析，提供透明洞见，揭示特定废物成分（如纤维材料和颗粒大小分布）对强度特性的影响。实验结果显示，该模型比传统梯度提升方法更准确，friction angle的平均绝对百分比误差为7.42%，cohesion为14.96%。通过SHAP分析，该研究确认纤维材料和颗粒大小是剪切强度变化的主要驱动因素，并为废物管理实践提供基于证据的决策推荐。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.15827v2",
      "published_date": "2025-02-20 05:02:55 UTC",
      "updated_date": "2025-02-26 22:37:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:40:27.418009"
    },
    {
      "arxiv_id": "2502.14264v1",
      "title": "SPRIG: Stackelberg Perception-Reinforcement Learning with Internal Game Dynamics",
      "title_zh": "翻译失败",
      "authors": [
        "Fernando Martinez-Lopez",
        "Juntao Chen",
        "Yingdong Lu"
      ],
      "abstract": "Deep reinforcement learning agents often face challenges to effectively\ncoordinate perception and decision-making components, particularly in\nenvironments with high-dimensional sensory inputs where feature relevance\nvaries. This work introduces SPRIG (Stackelberg Perception-Reinforcement\nlearning with Internal Game dynamics), a framework that models the internal\nperception-policy interaction within a single agent as a cooperative\nStackelberg game. In SPRIG, the perception module acts as a leader,\nstrategically processing raw sensory states, while the policy module follows,\nmaking decisions based on extracted features. SPRIG provides theoretical\nguarantees through a modified Bellman operator while preserving the benefits of\nmodern policy optimization. Experimental results on the Atari BeamRider\nenvironment demonstrate SPRIG's effectiveness, achieving around 30% higher\nreturns than standard PPO through its game-theoretical balance of feature\nextraction and decision-making.",
      "tldr_zh": "该研究提出 SPRIG 框架，将深度强化学习代理内部的感知和决策互动建模为合作 Stackelberg 游戏，以解决高维感官输入环境中特征相关性变化的协调挑战。在 SPRIG 中，感知模块作为领导者处理原始感官状态，而策略模块作为跟随者基于提取特征进行决策，并通过修改的 Bellman operator 提供理论保证，同时保留现代策略优化的优势。实验结果显示，在 Atari BeamRider 环境中，SPRIG 比标准 PPO 提高了约 30% 的回报，展示了其在平衡特征提取和决策方面的有效性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "To appear in: AAAI 2025 Workshop on Planning and Reinforcement\n  Learning (PRL) - Bridging the Gap Between AI Planning and Reinforcement\n  Learning",
      "pdf_url": "http://arxiv.org/pdf/2502.14264v1",
      "published_date": "2025-02-20 05:02:29 UTC",
      "updated_date": "2025-02-20 05:02:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:40:40.749948"
    },
    {
      "arxiv_id": "2502.14260v1",
      "title": "EyeBench: A Call for More Rigorous Evaluation of Retinal Image Enhancement",
      "title_zh": "EyeBench：呼吁更严格",
      "authors": [
        "Wenhui Zhu",
        "Xuanzhao Dong",
        "Xin Li",
        "Yujian Xiong",
        "Xiwen Chen",
        "Peijie Qiu",
        "Vamsi Krishna Vasa",
        "Zhangsihao Yang",
        "Yi Su",
        "Oana Dumitrascu",
        "Yalin Wang"
      ],
      "abstract": "Over the past decade, generative models have achieved significant success in\nenhancement fundus images.However, the evaluation of these models still\npresents a considerable challenge. A comprehensive evaluation benchmark for\nfundus image enhancement is indispensable for three main reasons: 1) The\nexisting denoising metrics (e.g., PSNR, SSIM) are hardly to extend to\ndownstream real-world clinical research (e.g., Vessel morphology consistency).\n2) There is a lack of comprehensive evaluation for both paired and unpaired\nenhancement methods, along with the need for expert protocols to accurately\nassess clinical value. 3) An ideal evaluation system should provide insights to\ninform future developments of fundus image enhancement. To this end, we propose\na novel comprehensive benchmark, EyeBench, to provide insights that align\nenhancement models with clinical needs, offering a foundation for future work\nto improve the clinical relevance and applicability of generative models for\nfundus image enhancement. EyeBench has three appealing properties: 1)\nmulti-dimensional clinical alignment downstream evaluation: In addition to\nevaluating the enhancement task, we provide several clinically significant\ndownstream tasks for fundus images, including vessel segmentation, DR grading,\ndenoising generalization, and lesion segmentation. 2) Medical expert-guided\nevaluation design: We introduce a novel dataset that promote comprehensive and\nfair comparisons between paired and unpaired methods and includes a manual\nevaluation protocol by medical experts. 3) Valuable insights: Our benchmark\nstudy provides a comprehensive and rigorous evaluation of existing methods\nacross different downstream tasks, assisting medical experts in making informed\nchoices. Additionally, we offer further analysis of the challenges faced by\nexisting methods. The code is available at\n\\url{https://github.com/Retinal-Research/EyeBench}",
      "tldr_zh": "该论文强调了视网膜图像增强模型评估的不足，并呼吁更严格的评估方法。研究者提出EyeBench基准，以解决现有指标（如PSNR和SSIM）难以扩展到临床应用的问题，并填补对配对和非配对方法的全面评估空白。EyeBench包括多维度下游任务评估（如血管分割、DR grading、去噪泛化和病变分割）、医疗专家指导的数据集和手动评估协议，以及对现有方法的深入分析，提供宝贵见解以指导未来视网膜图像增强模型的发展。最终，该基准有助于提升模型的临床相关性和实用性，代码已在GitHub开源。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14260v1",
      "published_date": "2025-02-20 04:56:03 UTC",
      "updated_date": "2025-02-20 04:56:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:40:51.530818"
    },
    {
      "arxiv_id": "2502.15826v1",
      "title": "CoME: An Unlearning-based Approach to Conflict-free Model Editing",
      "title_zh": "CoME：一种基于遗忘的方法用于无冲突模型编辑",
      "authors": [
        "Dahyun Jung",
        "Jaehyung Seo",
        "Jaewook Lee",
        "Chanjun Park",
        "Heuiseok Lim"
      ],
      "abstract": "Large language models (LLMs) often retain outdated or incorrect information\nfrom pre-training, which undermines their reliability. While model editing\nmethods have been developed to address such errors without full re-training,\nthey frequently suffer from knowledge conflicts, where outdated information\ninterferes with new knowledge. In this work, we propose Conflict-free Model\nEditing (CoME), a novel framework that enhances the accuracy of knowledge\nupdates in LLMs by selectively removing outdated knowledge. CoME leverages\nunlearning to mitigate knowledge interference, allowing new information to be\nintegrated without compromising relevant linguistic features. Through\nexperiments on GPT-J and LLaMA-3 using Counterfact and ZsRE datasets, we\ndemonstrate that CoME improves both editing accuracy and model reliability when\napplied to existing editing methods. Our results highlight that the targeted\nremoval of outdated knowledge is crucial for enhancing model editing\neffectiveness and maintaining the model's generative performance.",
      "tldr_zh": "大语言模型（LLMs）在预训练中常保留过时或错误信息，导致知识冲突，现有模型编辑方法难以有效处理。论文提出 CoME，一种基于 unlearning 的框架，通过选择性地移除过时知识来减轻干扰，确保新信息整合而不影响相关语言特征。在 GPT-J 和 LLaMA-3 模型上使用 Counterfact 和 ZsRE 数据集的实验显示，CoME 显著提高了编辑准确性和模型可靠性。研究强调，这种针对性移除过时知识的方法是提升模型编辑有效性和保持生成性能的关键。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to NAACL 2025 main conference",
      "pdf_url": "http://arxiv.org/pdf/2502.15826v1",
      "published_date": "2025-02-20 04:55:38 UTC",
      "updated_date": "2025-02-20 04:55:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:41:03.497163"
    },
    {
      "arxiv_id": "2502.14258v1",
      "title": "Does Time Have Its Place? Temporal Heads: Where Language Models Recall Time-specific Information",
      "title_zh": "翻译失败",
      "authors": [
        "Yein Park",
        "Chanwoong Yoon",
        "Jungwoo Park",
        "Minbyul Jeong",
        "Jaewoo Kang"
      ],
      "abstract": "While the ability of language models to elicit facts has been widely\ninvestigated, how they handle temporally changing facts remains underexplored.\nWe discover Temporal Heads, specific attention heads primarily responsible for\nprocessing temporal knowledge through circuit analysis. We confirm that these\nheads are present across multiple models, though their specific locations may\nvary, and their responses differ depending on the type of knowledge and its\ncorresponding years. Disabling these heads degrades the model's ability to\nrecall time-specific knowledge while maintaining its general capabilities\nwithout compromising time-invariant and question-answering performances.\nMoreover, the heads are activated not only numeric conditions (\"In 2004\") but\nalso textual aliases (\"In the year ...\"), indicating that they encode a\ntemporal dimension beyond simple numerical representation. Furthermore, we\nexpand the potential of our findings by demonstrating how temporal knowledge\ncan be edited by adjusting the values of these heads.",
      "tldr_zh": "本研究探讨了语言模型处理时间变化事实的能力，发现了Temporal Heads，即特定注意力头，通过电路分析，它们主要负责回忆时间特定信息，并在多个模型中存在但位置可能不同。实验显示，禁用这些Temporal Heads会显著降低模型对时间知识的回忆能力，同时保持了时间不变知识和一般问答性能不变；此外，这些头不仅响应数字条件（如“In 2004”），还响应文本别名（如“In the year ...”），表明它们编码了超越简单数字的时间维度。最后，研究证明可以通过调整这些Temporal Heads的值来编辑时间知识，为提升语言模型的时序处理提供新方法。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14258v1",
      "published_date": "2025-02-20 04:52:05 UTC",
      "updated_date": "2025-02-20 04:52:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:41:16.396297"
    },
    {
      "arxiv_id": "2502.14255v1",
      "title": "Effects of Prompt Length on Domain-specific Tasks for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Qibang Liu",
        "Wenzhe Wang",
        "Jeffrey Willard"
      ],
      "abstract": "In recent years, Large Language Models have garnered significant attention\nfor their strong performance in various natural language tasks, such as machine\ntranslation and question answering. These models demonstrate an impressive\nability to generalize across diverse tasks. However, their effectiveness in\ntackling domain-specific tasks, such as financial sentiment analysis and\nmonetary policy understanding, remains a topic of debate, as these tasks often\nrequire specialized knowledge and precise reasoning. To address such\nchallenges, researchers design various prompts to unlock the models' abilities.\nBy carefully crafting input prompts, researchers can guide these models to\nproduce more accurate responses. Consequently, prompt engineering has become a\nkey focus of study. Despite the advancements in both models and prompt\nengineering, the relationship between the two-specifically, how prompt design\nimpacts models' ability to perform domain-specific tasks-remains underexplored.\nThis paper aims to bridge this research gap.",
      "tldr_zh": "本研究探讨了提示长度对大型语言模型（Large Language Models）在领域特定任务（如金融情感分析和货币政策理解）的影响，这些任务通常需要专业知识和精确推理。论文指出，尽管LLMs在一般自然语言任务上表现出色，但其在领域特定任务中的表现仍存争议，且提示工程的关键作用尚未充分研究。作者通过分析提示设计如何指导模型生成更准确响应，旨在填补这一研究空白，为优化提示工程提供新见解。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.ET",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14255v1",
      "published_date": "2025-02-20 04:42:06 UTC",
      "updated_date": "2025-02-20 04:42:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:41:28.762173"
    },
    {
      "arxiv_id": "2502.14254v1",
      "title": "Mem2Ego: Empowering Vision-Language Models with Global-to-Ego Memory for Long-Horizon Embodied Navigation",
      "title_zh": "翻译失败",
      "authors": [
        "Lingfeng Zhang",
        "Yuecheng Liu",
        "Zhanguang Zhang",
        "Matin Aghaei",
        "Yaochen Hu",
        "Hongjian Gu",
        "Mohammad Ali Alomrani",
        "David Gamaliel Arcos Bravo",
        "Raika Karimi",
        "Atia Hamidizadeh",
        "Haoping Xu",
        "Guowei Huang",
        "Zhanpeng Zhang",
        "Tongtong Cao",
        "Weichao Qiu",
        "Xingyue Quan",
        "Jianye Hao",
        "Yuzheng Zhuang",
        "Yingxue Zhang"
      ],
      "abstract": "Recent advancements in Large Language Models (LLMs) and Vision-Language\nModels (VLMs) have made them powerful tools in embodied navigation, enabling\nagents to leverage commonsense and spatial reasoning for efficient exploration\nin unfamiliar environments. Existing LLM-based approaches convert global\nmemory, such as semantic or topological maps, into language descriptions to\nguide navigation. While this improves efficiency and reduces redundant\nexploration, the loss of geometric information in language-based\nrepresentations hinders spatial reasoning, especially in intricate\nenvironments. To address this, VLM-based approaches directly process\nego-centric visual inputs to select optimal directions for exploration.\nHowever, relying solely on a first-person perspective makes navigation a\npartially observed decision-making problem, leading to suboptimal decisions in\ncomplex environments. In this paper, we present a novel vision-language model\n(VLM)-based navigation framework that addresses these challenges by adaptively\nretrieving task-relevant cues from a global memory module and integrating them\nwith the agent's egocentric observations. By dynamically aligning global\ncontextual information with local perception, our approach enhances spatial\nreasoning and decision-making in long-horizon tasks. Experimental results\ndemonstrate that the proposed method surpasses previous state-of-the-art\napproaches in object navigation tasks, providing a more effective and scalable\nsolution for embodied navigation.",
      "tldr_zh": "本文提出Mem2Ego框架，利用Global-to-Ego Memory机制增强Vision-Language Models (VLMs)，以解决现有Embodied Navigation方法在长程任务中的问题，如语言描述丢失几何信息或依赖单一第一人称视角导致的子优决策。该框架通过动态从全局记忆模块中检索任务相关线索，并将其与代理的自我中心观察整合，提高空间推理和决策效率。实验结果表明，Mem2Ego在物体导航任务中超越了现有最先进方法，提供更有效和可扩展的解决方案。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14254v1",
      "published_date": "2025-02-20 04:41:40 UTC",
      "updated_date": "2025-02-20 04:41:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:41:39.867586"
    },
    {
      "arxiv_id": "2502.14247v2",
      "title": "Pandora3D: A Comprehensive Framework for High-Quality 3D Shape and Texture Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Jiayu Yang",
        "Taizhang Shang",
        "Weixuan Sun",
        "Xibin Song",
        "Ziang Cheng",
        "Senbo Wang",
        "Shenzhou Chen",
        "Weizhe Liu",
        "Hongdong Li",
        "Pan Ji"
      ],
      "abstract": "This report presents a comprehensive framework for generating high-quality 3D\nshapes and textures from diverse input prompts, including single images,\nmulti-view images, and text descriptions. The framework consists of 3D shape\ngeneration and texture generation. (1). The 3D shape generation pipeline\nemploys a Variational Autoencoder (VAE) to encode implicit 3D geometries into a\nlatent space and a diffusion network to generate latents conditioned on input\nprompts, with modifications to enhance model capacity. An alternative\nArtist-Created Mesh (AM) generation approach is also explored, yielding\npromising results for simpler geometries. (2). Texture generation involves a\nmulti-stage process starting with frontal images generation followed by\nmulti-view images generation, RGB-to-PBR texture conversion, and\nhigh-resolution multi-view texture refinement. A consistency scheduler is\nplugged into every stage, to enforce pixel-wise consistency among multi-view\ntextures during inference, ensuring seamless integration.\n  The pipeline demonstrates effective handling of diverse input formats,\nleveraging advanced neural architectures and novel methodologies to produce\nhigh-quality 3D content. This report details the system architecture,\nexperimental results, and potential future directions to improve and expand the\nframework. The source code and pretrained weights are released at:\nhttps://github.com/Tencent/Tencent-XR-3DGen.",
      "tldr_zh": "该论文提出Pandora3D框架，用于从单张图像、多视图图像或文本描述等输入提示中生成高质量3D形状和纹理。框架包括3D形状生成模块，利用Variational Autoencoder (VAE)编码隐式几何到潜在空间，并结合diffusion network生成条件化潜在表示，同时探索Artist-Created Mesh (AM)方法以处理简单几何体。纹理生成采用多阶段过程，包括正面图像生成、多视图图像生成、RGB-to-PBR纹理转换和高分辨率精炼，并通过consistency scheduler确保多视图纹理的像素级一致性；实验结果显示该框架在处理多样输入时表现出色，并提供了源代码和预训练权重以支持进一步发展。",
      "categories": [
        "cs.GR",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.GR",
      "comment": "Tencent XR 3D Gen",
      "pdf_url": "http://arxiv.org/pdf/2502.14247v2",
      "published_date": "2025-02-20 04:22:30 UTC",
      "updated_date": "2025-02-21 19:09:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:41:52.593147"
    },
    {
      "arxiv_id": "2502.14235v1",
      "title": "OG-Gaussian: Occupancy Based Street Gaussians for Autonomous Driving",
      "title_zh": "翻译失败",
      "authors": [
        "Yedong Shen",
        "Xinran Zhang",
        "Yifan Duan",
        "Shiqi Zhang",
        "Heng Li",
        "Yilong Wu",
        "Jianmin Ji",
        "Yanyong Zhang"
      ],
      "abstract": "Accurate and realistic 3D scene reconstruction enables the lifelike creation\nof autonomous driving simulation environments. With advancements in 3D Gaussian\nSplatting (3DGS), previous studies have applied it to reconstruct complex\ndynamic driving scenes. These methods typically require expensive LiDAR sensors\nand pre-annotated datasets of dynamic objects. To address these challenges, we\npropose OG-Gaussian, a novel approach that replaces LiDAR point clouds with\nOccupancy Grids (OGs) generated from surround-view camera images using\nOccupancy Prediction Network (ONet). Our method leverages the semantic\ninformation in OGs to separate dynamic vehicles from static street background,\nconverting these grids into two distinct sets of initial point clouds for\nreconstructing both static and dynamic objects. Additionally, we estimate the\ntrajectories and poses of dynamic objects through a learning-based approach,\neliminating the need for complex manual annotations. Experiments on Waymo Open\ndataset demonstrate that OG-Gaussian is on par with the current\nstate-of-the-art in terms of reconstruction quality and rendering speed,\nachieving an average PSNR of 35.13 and a rendering speed of 143 FPS, while\nsignificantly reducing computational costs and economic overhead.",
      "tldr_zh": "该论文提出 OG-Gaussian，一种基于 Occupancy Grids (OGs) 的方法，用于自动驾驶场景的 3D 重建，旨在取代昂贵的 LiDAR 传感器和预标注数据集。方法利用 Occupancy Prediction Network (ONet) 从多视角相机图像生成 OGs，并通过其语义信息分离动态车辆和静态街道背景，转换为独立的点云集进行重建，同时采用基于学习的approach 估计动态对象的轨迹和姿态。实验在 Waymo Open 数据集上显示，OG-Gaussian 实现了与最先进方法相当的重建质量（平均 PSNR 35.13）和渲染速度（143 FPS），并显著降低了计算成本和经济开销。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14235v1",
      "published_date": "2025-02-20 04:00:47 UTC",
      "updated_date": "2025-02-20 04:00:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:42:04.625156"
    },
    {
      "arxiv_id": "2502.15825v1",
      "title": "Utilizing AI and Machine Learning for Predictive Analysis of Post-Treatment Cancer Recurrence",
      "title_zh": "利用 AI 和机器学习进行治疗后癌症复发的预测",
      "authors": [
        "Muhammad Umer Qayyum",
        "Muhammad Fahad",
        "Nasrullah Abbasi"
      ],
      "abstract": "In oncology, recurrence after treatment is one of the major challenges,\nrelated to patients' survival and quality of life. Conventionally, prediction\nof cancer relapse has always relied on clinical observation with statistical\nmodel support, which almost fails to explain the complex, multifactorial nature\nof tumor recurrence. This research explores how AI and ML models may increase\nthe accuracy and reliability of recurrence prediction in cancer. Therefore, AI\nand ML create new opportunities not only for personalized medicine but also for\nproactive management of patients through analyzing large volumes of data on\ngenetics, clinical manifestations, and treatment. The paper describes the\nvarious AI and ML techniques for pattern identification and outcome prediction\nin cancer patients using supervised and unsupervised learning. Clinical\nimplications provide an opportunity to review how early interventions could\nhappen and the design of treatment planning.",
      "tldr_zh": "本研究探讨AI和ML模型在预测癌症治疗后复发方面的应用，以克服传统临床观察和统计模型无法解释肿瘤复发的复杂多因素问题。论文描述了利用监督和无监督学习等技术，分析遗传、临床表现和治疗的大量数据，从而识别模式并提升预测的准确性和可靠性。该方法为个性化医学、主动患者管理和早期干预提供新机会，有助于优化治疗规划。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "15 pages",
      "pdf_url": "http://arxiv.org/pdf/2502.15825v1",
      "published_date": "2025-02-20 03:54:12 UTC",
      "updated_date": "2025-02-20 03:54:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:42:14.364826"
    },
    {
      "arxiv_id": "2502.15824v1",
      "title": "Getting SMARTER for Motion Planning in Autonomous Driving Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Montgomery Alban",
        "Ehsan Ahmadi",
        "Randy Goebel",
        "Amir Rasouli"
      ],
      "abstract": "Motion planning is a fundamental problem in autonomous driving and perhaps\nthe most challenging to comprehensively evaluate because of the associated\nrisks and expenses of real-world deployment. Therefore, simulations play an\nimportant role in efficient development of planning algorithms. To be\neffective, simulations must be accurate and realistic, both in terms of\ndynamics and behavior modeling, and also highly customizable in order to\naccommodate a broad spectrum of research frameworks. In this paper, we\nintroduce SMARTS 2.0, the second generation of our motion planning simulator\nwhich, in addition to being highly optimized for large-scale simulation,\nprovides many new features, such as realistic map integration,\nvehicle-to-vehicle (V2V) communication, traffic and pedestrian simulation, and\na broad variety of sensor models.\n  Moreover, we present a novel benchmark suite for evaluating planning\nalgorithms in various highly challenging scenarios, including interactive\ndriving, such as turning at intersections, and adaptive driving, in which the\ntask is to closely follow a lead vehicle without any explicit knowledge of its\nintention. Each scenario is characterized by a variety of traffic patterns and\nroad structures. We further propose a series of common and task-specific\nmetrics to effectively evaluate the performance of the planning algorithms. At\nthe end, we evaluate common motion planning algorithms using the proposed\nbenchmark and highlight the challenges the proposed scenarios impose. The new\nSMARTS 2.0 features and the benchmark are publicly available at\ngithub.com/huawei-noah/SMARTS.",
      "tldr_zh": "本论文探讨了自动驾驶系统中的Motion Planning问题及其评估挑战，强调了模拟器的关键作用，以避免真实部署的风险。作者引入了SMARTS 2.0，这是一个高度优化的运动规划模拟器，新增了真实地图集成、V2V通信、交通和行人模拟以及多种传感器模型等功能，以支持大规模和自定义研究。论文还提出一个新基准测试套件，针对交互式驾驶（如十字路口转弯）和适应性驾驶（如跟踪领航车辆）等场景，提供通用和任务特定指标来评估算法性能；实验结果突出了这些场景的挑战，并展示了SMARTS 2.0的公开可用性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "8 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2502.15824v1",
      "published_date": "2025-02-20 03:51:49 UTC",
      "updated_date": "2025-02-20 03:51:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:42:27.697141"
    },
    {
      "arxiv_id": "2502.15823v4",
      "title": "InductionBench: LLMs Fail in the Simplest Complexity Class",
      "title_zh": "翻译失败",
      "authors": [
        "Wenyue Hua",
        "Tyler Wong",
        "Sun Fei",
        "Liangming Pan",
        "Adam Jardine",
        "William Yang Wang"
      ],
      "abstract": "Large language models (LLMs) have shown remarkable improvements in reasoning\nand many existing benchmarks have been addressed by models such as o1 and o3\neither fully or partially. However, a majority of these benchmarks emphasize\ndeductive reasoning, including mathematical and coding tasks in which rules\nsuch as mathematical axioms or programming syntax are clearly defined, based on\nwhich LLMs can plan and apply these rules to arrive at a solution. In contrast,\ninductive reasoning, where one infers the underlying rules from observed data,\nremains less explored. Such inductive processes lie at the heart of scientific\ndiscovery, as they enable researchers to extract general principles from\nempirical observations. To assess whether LLMs possess this capacity, we\nintroduce InductionBench, a new benchmark designed to evaluate the inductive\nreasoning ability of LLMs. Our experimental findings reveal that even the most\nadvanced models available struggle to master the simplest complexity classes\nwithin the subregular hierarchy of functions, highlighting a notable deficiency\nin current LLMs' inductive reasoning capabilities. Coda and data are available\nhttps://github.com/Wenyueh/inductive_reasoning_benchmark.",
      "tldr_zh": "本研究发现，大语言模型(LLMs)在演绎推理方面表现出色，但归纳推理能力（从观察数据中推断底层规则）仍存在显著缺陷。论文引入InductionBench，一个新基准，用于评估LLMs的归纳推理性能，通过测试子正则层次(subregular hierarchy)的最简单复杂度类。实验结果显示，即使最先进的模型也无法掌握这些基本任务，突显了当前LLMs在科学发现核心能力上的不足，并提供了代码和数据资源（https://github.com/Wenyueh/inductive_reasoning_benchmark）。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.FL"
      ],
      "primary_category": "cs.LG",
      "comment": "25 pages, 10 figures, more details including examples and prompts are\n  added",
      "pdf_url": "http://arxiv.org/pdf/2502.15823v4",
      "published_date": "2025-02-20 03:48:00 UTC",
      "updated_date": "2025-05-13 18:06:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:42:38.664077"
    },
    {
      "arxiv_id": "2502.14227v1",
      "title": "SleepGMUformer: A gated multimodal temporal neural network for sleep staging",
      "title_zh": "SleepGMUformer：一种用于睡眠分期的门控多模态时序神经网络",
      "authors": [
        "Chenjun Zhao",
        "Xuesen Niu",
        "Xinglin Yu",
        "Long Chen",
        "Na Lv",
        "Huiyu Zhou",
        "Aite Zhao"
      ],
      "abstract": "Sleep staging is a key method for assessing sleep quality and diagnosing\nsleep disorders. However, current deep learning methods face challenges: 1)\npostfusion techniques ignore the varying contributions of different modalities;\n2) unprocessed sleep data can interfere with frequency-domain information. To\ntackle these issues, this paper proposes a gated multimodal temporal neural\nnetwork for multidomain sleep data, including heart rate, motion, steps, EEG\n(Fpz-Cz, Pz-Oz), and EOG from WristHR-Motion-Sleep and SleepEDF-78. The model\nintegrates: 1) a pre-processing module for feature alignment, missing value\nhandling, and EEG de-trending; 2) a feature extraction module for complex sleep\nfeatures in the time dimension; and 3) a dynamic fusion module for real-time\nmodality weighting.Experiments show classification accuracies of 85.03% on\nSleepEDF-78 and 94.54% on WristHR-Motion-Sleep datasets. The model handles\nheterogeneous datasets and outperforms state-of-the-art models by 1.00%-4.00%.",
      "tldr_zh": "这篇论文提出了SleepGMUformer，一种门控多模态时序神经网络，用于解决睡眠分期中的问题，如后融合技术忽略模态贡献和未处理数据干扰频率域信息。模型整合了预处理模块（包括特征对齐、缺失值处理和EEG去趋势）、特征提取模块（提取时序维度的复杂睡眠特征）以及动态融合模块（实时加权不同模态，如心率、运动、EEG和EOG）。在SleepEDF-78和WristHR-Motion-Sleep数据集上，实验显示准确率分别为85.03%和94.54%，比现有最先进模型提高了1.00%-4.00%。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14227v1",
      "published_date": "2025-02-20 03:42:42 UTC",
      "updated_date": "2025-02-20 03:42:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:42:53.766871"
    },
    {
      "arxiv_id": "2502.14222v1",
      "title": "Enhancing Pavement Sensor Data Acquisition for AI-Driven Transportation Research",
      "title_zh": "针对人工智能驱动的交通研究增强路面传感器数据采集",
      "authors": [
        "Manish Kumar Krishne Gowda",
        "Andrew Balmos",
        "Shin Boonam",
        "James V. Krogmeier"
      ],
      "abstract": "Effective strategies for sensor data management are essential for advancing\ntransportation research, especially in the current data-driven era, due to the\nadvent of novel applications in artificial intelligence. This paper presents\ncomprehensive guidelines for managing transportation sensor data, encompassing\nboth archived static data and real-time data streams. The real-time system\narchitecture integrates various applications with data acquisition systems\n(DAQ). By deploying the in-house designed, open-source Avena software platform\nalongside the NATS messaging system as a secure communication broker, reliable\ndata exchange is ensured. While robust databases like TimescaleDB facilitate\norganized storage, visualization platforms like Grafana provide real-time\nmonitoring capabilities.\n  In contrast, static data standards address the challenges in handling\nunstructured, voluminous datasets. The standards advocate for a combination of\ncost-effective bulk cloud storage for unprocessed sensor data and relational\ndatabases for recording summarized analyses. They highlight the role of cloud\ndata transfer tools like FME for efficient migration of sensor data from local\nstorages onto the cloud. Further, integration of robust visualization tools\ninto the framework helps in deriving patterns and trends from these complex\ndatasets.\n  The proposals were applied to INDOT's real-world case studies involving the\nI-65 and I-69 Greenfield districts. For real-time data collection, Campbell\nScientific DAQ systems were used, enabling continuous generation and monitoring\nof sensor metrics. In the case of the archived I-69 database, summary data was\ncompiled in Oracle, while the unprocessed data was stored in SharePoint. The\nresults underline the effectiveness of the proposed guidelines and motivate\ntheir adoption in research projects.",
      "tldr_zh": "这篇论文提出了增强路面传感器数据采集的全面指南，以支持 AI 驱动的交通研究，包括实时数据流和存档静态数据的管理策略。针对实时数据，该框架整合了开源 Avena 软件平台、NATS 通信代理、TimescaleDB 数据库和 Grafana 可视化工具，确保可靠的数据交换和实时监控。对于静态数据，指南推荐使用云存储结合关系数据库，并借助 FME 工具进行高效数据迁移，以处理海量非结构化数据集。这些方法已在 INDOT 的 I-65 和 I-69 实际案例中应用，使用 Campbell Scientific DAQ 系统，证明了其有效性并推动了交通研究项目的采用。",
      "categories": [
        "cs.DB",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.DB",
      "comment": "This paper was accepted for presentation at the 104th TRB Annual\n  Meeting, held on January 5-9, 2025, in Washington, D.C., and was presented\n  during the poster session on January 8, 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.14222v1",
      "published_date": "2025-02-20 03:37:46 UTC",
      "updated_date": "2025-02-20 03:37:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:43:15.485114"
    },
    {
      "arxiv_id": "2502.14219v1",
      "title": "Investigating the Impact of LLM Personality on Cognitive Bias Manifestation in Automated Decision-Making Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Jiangen He",
        "Jiqun Liu"
      ],
      "abstract": "Large Language Models (LLMs) are increasingly used in decision-making, yet\ntheir susceptibility to cognitive biases remains a pressing challenge. This\nstudy explores how personality traits influence these biases and evaluates the\neffectiveness of mitigation strategies across various model architectures. Our\nfindings identify six prevalent cognitive biases, while the sunk cost and group\nattribution biases exhibit minimal impact. Personality traits play a crucial\nrole in either amplifying or reducing biases, significantly affecting how LLMs\nrespond to debiasing techniques. Notably, Conscientiousness and Agreeableness\nmay generally enhance the efficacy of bias mitigation strategies, suggesting\nthat LLMs exhibiting these traits are more receptive to corrective measures.\nThese findings address the importance of personality-driven bias dynamics and\nhighlight the need for targeted mitigation approaches to improve fairness and\nreliability in AI-assisted decision-making.",
      "tldr_zh": "本研究调查了大型语言模型(LLMs)人格特质对认知偏差在自动化决策任务中的影响，识别出六种常见偏差，如确认偏差和锚定偏差，而沉没成本和群体归因偏差的影响较小。通过评估不同模型架构和缓解策略，研究发现人格特质可放大或减少偏差，其中尽责性(Conscientiousness)和宜人性(Agreeableness)显著提升了偏差缓解措施的效能。这些发现突出了人格驱动偏差动态的重要性，并呼吁采用针对性方法来提高AI决策的公平性和可靠性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14219v1",
      "published_date": "2025-02-20 03:15:54 UTC",
      "updated_date": "2025-02-20 03:15:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:43:28.914971"
    },
    {
      "arxiv_id": "2502.14218v1",
      "title": "Rethinking Spiking Neural Networks from an Ensemble Learning Perspective",
      "title_zh": "从集成学习视角重新审视脉冲神经网络",
      "authors": [
        "Yongqi Ding",
        "Lin Zuo",
        "Mengmeng Jing",
        "Pei He",
        "Hanpu Deng"
      ],
      "abstract": "Spiking neural networks (SNNs) exhibit superior energy efficiency but suffer\nfrom limited performance. In this paper, we consider SNNs as ensembles of\ntemporal subnetworks that share architectures and weights, and highlight a\ncrucial issue that affects their performance: excessive differences in initial\nstates (neuronal membrane potentials) across timesteps lead to unstable\nsubnetwork outputs, resulting in degraded performance. To mitigate this, we\npromote the consistency of the initial membrane potential distribution and\noutput through membrane potential smoothing and temporally adjacent subnetwork\nguidance, respectively, to improve overall stability and performance. Moreover,\nmembrane potential smoothing facilitates forward propagation of information and\nbackward propagation of gradients, mitigating the notorious temporal gradient\nvanishing problem. Our method requires only minimal modification of the spiking\nneurons without adapting the network structure, making our method generalizable\nand showing consistent performance gains in 1D speech, 2D object, and 3D point\ncloud recognition tasks. In particular, on the challenging CIFAR10-DVS dataset,\nwe achieved 83.20\\% accuracy with only four timesteps. This provides valuable\ninsights into unleashing the potential of SNNs.",
      "tldr_zh": "该论文从集成学习视角重新审视脉冲神经网络(SNNs)，将SNNs视为共享架构和权重的时序子网络集合，并指出初始膜电位(neuronal membrane potentials)跨时间步的过度差异导致子网络输出不稳定，从而影响整体性能。作者提出通过膜电位平滑(membrane potential smoothing)和时间相邻子网络指导(temporally adjacent subnetwork guidance)来提升初始膜电位分布和输出的一致性，提高网络稳定性。膜电位平滑还促进信息前向传播和梯度后向传播，缓解了时间梯度消失问题。该方法只需对spiking neurons进行最小修改，即可适用于1D语音、2D对象和3D点云识别任务，并在CIFAR10-DVS数据集上仅用四个时间步达到83.20%的准确率，为释放SNNs潜力提供了新见解。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Published as a conference paper at ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.14218v1",
      "published_date": "2025-02-20 03:15:52 UTC",
      "updated_date": "2025-02-20 03:15:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:43:41.815969"
    },
    {
      "arxiv_id": "2502.14215v1",
      "title": "Towards Secure Program Partitioning for Smart Contracts with LLM's In-Context Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Ye Liu",
        "Yuqing Niu",
        "Chengyan Ma",
        "Ruidong Han",
        "Wei Ma",
        "Yi Li",
        "Debin Gao",
        "David Lo"
      ],
      "abstract": "Smart contracts are highly susceptible to manipulation attacks due to the\nleakage of sensitive information. Addressing manipulation vulnerabilities is\nparticularly challenging because they stem from inherent data confidentiality\nissues rather than straightforward implementation bugs. To tackle this by\npreventing sensitive information leakage, we present PartitionGPT, the first\nLLM-driven approach that combines static analysis with the in-context learning\ncapabilities of large language models (LLMs) to partition smart contracts into\nprivileged and normal codebases, guided by a few annotated sensitive data\nvariables. We evaluated PartitionGPT on 18 annotated smart contracts containing\n99 sensitive functions. The results demonstrate that PartitionGPT successfully\ngenerates compilable, and verified partitions for 78% of the sensitive\nfunctions while reducing approximately 30% code compared to function-level\npartitioning approach. Furthermore, we evaluated PartitionGPT on nine\nreal-world manipulation attacks that lead to a total loss of 25 million\ndollars, PartitionGPT effectively prevents eight cases, highlighting its\npotential for broad applicability and the necessity for secure program\npartitioning during smart contract development to diminish manipulation\nvulnerabilities.",
      "tldr_zh": "本研究针对智能合约的敏感信息泄露问题，提出 PartitionGPT，这是一种结合静态分析和 LLM 的 in-context learning 的方法，用于将合约代码分区为特权和普通代码库，并以少数标注的敏感数据变量作为引导。实验在 18 个标注的智能合约上进行，涵盖 99 个敏感函数，结果显示 PartitionGPT 成功为 78% 的敏感函数生成了可编译和验证的分区，同时比函数级分区方法减少约 30% 代码。在九个真实世界操纵攻击案例中（总损失 2500 万美元），该方法有效防止了八个案例，强调了在智能合约开发中实施安全程序分区的必要性。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14215v1",
      "published_date": "2025-02-20 03:07:56 UTC",
      "updated_date": "2025-02-20 03:07:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:43:53.354844"
    },
    {
      "arxiv_id": "2502.15821v1",
      "title": "Towards Robust ESG Analysis Against Greenwashing Risks: Aspect-Action Analysis with Cross-Category Generalization",
      "title_zh": "翻译失败",
      "authors": [
        "Keane Ong",
        "Rui Mao",
        "Deeksha Varshney",
        "Erik Cambria",
        "Gianmarco Mengaldo"
      ],
      "abstract": "Sustainability reports are key for evaluating companies' environmental,\nsocial and governance, ESG performance, but their content is increasingly\nobscured by greenwashing - sustainability claims that are misleading,\nexaggerated, and fabricated. Yet, existing NLP approaches for ESG analysis lack\nrobustness against greenwashing risks, often extracting insights that reflect\nmisleading or exaggerated sustainability claims rather than objective ESG\nperformance. To bridge this gap, we introduce A3CG - Aspect-Action Analysis\nwith Cross-Category Generalization, as a novel dataset to improve the\nrobustness of ESG analysis amid the prevalence of greenwashing. By explicitly\nlinking sustainability aspects with their associated actions, A3CG facilitates\na more fine-grained and transparent evaluation of sustainability claims,\nensuring that insights are grounded in verifiable actions rather than vague or\nmisleading rhetoric. Additionally, A3CG emphasizes cross-category\ngeneralization. This ensures robust model performance in aspect-action analysis\neven when companies change their reports to selectively favor certain\nsustainability areas. Through experiments on A3CG, we analyze state-of-the-art\nsupervised models and LLMs, uncovering their limitations and outlining key\ndirections for future research.",
      "tldr_zh": "这篇论文针对 ESG（Environmental, Social, and Governance）分析中的绿洗（greenwashing）风险，提出 A3CG（Aspect-Action Analysis with Cross-Category Generalization）数据集，以提升分析的鲁棒性。A3CG 通过显式链接可持续性方面（aspects）与相关行动（actions），实现更细粒度的评估，确保见解基于可验证的行动而非模糊或误导性声明，同时强调跨类别泛化（cross-category generalization），使模型在公司报告变化时保持性能稳定。在实验中，论文分析了最先进的 NLP 模型和 LLMs（Large Language Models），揭示了它们的局限性，并为未来研究提供了关键方向。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.15821v1",
      "published_date": "2025-02-20 03:01:08 UTC",
      "updated_date": "2025-02-20 03:01:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:44:05.916034"
    },
    {
      "arxiv_id": "2502.15820v2",
      "title": "Universal AI maximizes Variational Empowerment",
      "title_zh": "翻译失败",
      "authors": [
        "Yusuke Hayashi",
        "Koichi Takahashi"
      ],
      "abstract": "This paper presents a theoretical framework unifying AIXI -- a model of\nuniversal AI -- with variational empowerment as an intrinsic drive for\nexploration. We build on the existing framework of Self-AIXI -- a universal\nlearning agent that predicts its own actions -- by showing how one of its\nestablished terms can be interpreted as a variational empowerment objective. We\nfurther demonstrate that universal AI's planning process can be cast as\nminimizing expected variational free energy (the core principle of active\nInference), thereby revealing how universal AI agents inherently balance\ngoal-directed behavior with uncertainty reduction curiosity). Moreover, we\nargue that power-seeking tendencies of universal AI agents can be explained not\nonly as an instrumental strategy to secure future reward, but also as a direct\nconsequence of empowerment maximization -- i.e. the agent's intrinsic drive to\nmaintain or expand its own controllability in uncertain environments. Our main\ncontribution is to show how these intrinsic motivations (empowerment,\ncuriosity) systematically lead universal AI agents to seek and sustain\nhigh-optionality states. We prove that Self-AIXI asymptotically converges to\nthe same performance as AIXI under suitable conditions, and highlight that its\npower-seeking behavior emerges naturally from both reward maximization and\ncuriosity-driven exploration. Since AIXI can be view as a Bayes-optimal\nmathematical formulation for Artificial General Intelligence (AGI), our result\ncan be useful for further discussion on AI safety and the controllability of\nAGI.",
      "tldr_zh": "本论文提出一个理论框架，将 universal AI 的模型 AIXI 与 variational empowerment 统一起来，作为一种内在探索驱动力。通过 Self-AIXI 框架，该研究解释了其中一个术语为 variational empowerment 目标，并证明 universal AI 的规划过程等价于最小化 expected variational free energy，从而揭示其内在平衡目标行为和不确定性减少的机制。论文进一步论证，universal AI 的 power-seeking 倾向不仅是获取奖励的手段，更是 empowerment maximization 的直接结果，导致代理在不确定环境中寻求高可选性状态。最后，研究证明 Self-AIXI 在合适条件下收敛到 AIXI 的性能，这为 AI 安全和 AGI 可控性讨论提供了新见解。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "cs.AI",
      "comment": "9 pages, no figures",
      "pdf_url": "http://arxiv.org/pdf/2502.15820v2",
      "published_date": "2025-02-20 02:58:44 UTC",
      "updated_date": "2025-03-03 19:50:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:44:16.137347"
    },
    {
      "arxiv_id": "2502.14205v1",
      "title": "Accurate Forgetting for Heterogeneous Federated Continual Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Abudukelimu Wuerkaixi",
        "Sen Cui",
        "Jingfeng Zhang",
        "Kunda Yan",
        "Bo Han",
        "Gang Niu",
        "Lei Fang",
        "Changshui Zhang",
        "Masashi Sugiyama"
      ],
      "abstract": "Recent years have witnessed a burgeoning interest in federated learning (FL).\nHowever, the contexts in which clients engage in sequential learning remain\nunder-explored. Bridging FL and continual learning (CL) gives rise to a\nchallenging practical problem: federated continual learning (FCL). Existing\nresearch in FCL primarily focuses on mitigating the catastrophic forgetting\nissue of continual learning while collaborating with other clients. We argue\nthat the forgetting phenomena are not invariably detrimental. In this paper, we\nconsider a more practical and challenging FCL setting characterized by\npotentially unrelated or even antagonistic data/tasks across different clients.\nIn the FL scenario, statistical heterogeneity and data noise among clients may\nexhibit spurious correlations which result in biased feature learning. While\nexisting CL strategies focus on a complete utilization of previous knowledge,\nwe found that forgetting biased information is beneficial in our study.\nTherefore, we propose a new concept accurate forgetting (AF) and develop a\nnovel generative-replay method~\\method~which selectively utilizes previous\nknowledge in federated networks. We employ a probabilistic framework based on a\nnormalizing flow model to quantify the credibility of previous knowledge.\nComprehensive experiments affirm the superiority of our method over baselines.",
      "tldr_zh": "该论文探讨了在异构联邦持续学习（Federated Continual Learning, FCL）中，遗忘现象并非总是负面，而是可以帮助缓解数据异质性和噪声导致的偏差特征学习问题。作者提出新概念Accurate Forgetting (AF)，并开发了一种基于生成重放的创新方法，利用Normalizing Flow模型的概率框架来量化先前知识的可信度，从而选择性地利用历史数据。实验结果显示，该方法在各种FCL场景中优于基线模型，证明了准确遗忘在处理客户端数据不相关或对抗性任务时的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "published in ICLR 2024",
      "pdf_url": "http://arxiv.org/pdf/2502.14205v1",
      "published_date": "2025-02-20 02:35:17 UTC",
      "updated_date": "2025-02-20 02:35:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:44:27.992929"
    },
    {
      "arxiv_id": "2502.14204v1",
      "title": "On-the-fly Preference Alignment via Principle-Guided Decoding",
      "title_zh": "通过原则指导的解码实现实时偏好对齐",
      "authors": [
        "Mingye Zhu",
        "Yi Liu",
        "Lei Zhang",
        "Junbo Guo",
        "Zhendong Mao"
      ],
      "abstract": "With the rapidly expanding landscape of large language models, aligning model\ngenerations with human values and preferences is becoming increasingly\nimportant. Popular alignment methods, such as Reinforcement Learning from Human\nFeedback, have shown significant success in guiding models with greater\ncontrol. However, these methods require considerable computational resources,\nwhich is inefficient, and substantial collection of training data to\naccommodate the diverse and pluralistic nature of human preferences, which is\nimpractical. These limitations significantly constrain the scope and efficacy\nof both task-specific and general preference alignment methods. In this work,\nwe introduce On-the-fly Preference Alignment via Principle-Guided Decoding\n(OPAD) to directly align model outputs with human preferences during inference,\neliminating the need for fine-tuning. Our approach involves first curating a\nsurrogate solution to an otherwise infeasible optimization problem and then\ndesigning a principle-guided reward function based on this surrogate. The final\naligned policy is derived by maximizing this customized reward, which exploits\nthe discrepancy between the constrained policy and its unconstrained\ncounterpart. OPAD directly modifies the model's predictions during inference,\nensuring principle adherence without incurring the computational overhead of\nretraining or fine-tuning. Experiments show that OPAD achieves competitive or\nsuperior performance in both general and personalized alignment tasks,\ndemonstrating its efficiency and effectiveness compared to state-of-the-art\nbaselines.",
      "tldr_zh": "这篇论文针对大型语言模型（LLMs）的偏好对齐问题，指出传统方法如 Reinforcement Learning from Human Feedback (RLHF) 资源消耗大且需要大量数据，限制了其实用性。作者提出 On-the-fly Preference Alignment via Principle-Guided Decoding (OPAD) 方法，通过在推理阶段设计基于原则的奖励函数并最大化其值，直接调整模型输出，而无需 fine-tuning。实验结果显示，OPAD 在一般和个性化对齐任务中比现有基线更高效和有效，证明了其在提升模型与人类偏好一致性方面的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.14204v1",
      "published_date": "2025-02-20 02:23:09 UTC",
      "updated_date": "2025-02-20 02:23:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:44:40.692006"
    },
    {
      "arxiv_id": "2502.14202v2",
      "title": "Do LLMs Consider Security? An Empirical Study on Responses to Programming Questions",
      "title_zh": "LLMs 是否考虑安全？一项关于编程问题响应的实证研究",
      "authors": [
        "Amirali Sajadi",
        "Binh Le",
        "Anh Nguyen",
        "Kostadin Damevski",
        "Preetha Chatterjee"
      ],
      "abstract": "The widespread adoption of conversational LLMs for software development has\nraised new security concerns regarding the safety of LLM-generated content. Our\nmotivational study outlines ChatGPT's potential in volunteering\ncontext-specific information to the developers, promoting safe coding\npractices. Motivated by this finding, we conduct a study to evaluate the degree\nof security awareness exhibited by three prominent LLMs: Claude 3, GPT-4, and\nLlama 3. We prompt these LLMs with Stack Overflow questions that contain\nvulnerable code to evaluate whether they merely provide answers to the\nquestions or if they also warn users about the insecure code, thereby\ndemonstrating a degree of security awareness. Further, we assess whether LLM\nresponses provide information about the causes, exploits, and the potential\nfixes of the vulnerability, to help raise users' awareness. Our findings show\nthat all three models struggle to accurately detect and warn users about\nvulnerabilities, achieving a detection rate of only 12.6% to 40% across our\ndatasets. We also observe that the LLMs tend to identify certain types of\nvulnerabilities related to sensitive information exposure and improper input\nneutralization much more frequently than other types, such as those involving\nexternal control of file names or paths. Furthermore, when LLMs do issue\nsecurity warnings, they often provide more information on the causes, exploits,\nand fixes of vulnerabilities compared to Stack Overflow responses. Finally, we\nprovide an in-depth discussion on the implications of our findings and present\na CLI-based prompting tool that can be used to generate significantly more\nsecure LLM responses.",
      "tldr_zh": "该研究调查了大型语言模型（LLMs）如Claude 3、GPT-4和Llama 3在回答编程问题时的安全意识，焦点是这些模型是否能检测并警告代码漏洞。研究者使用Stack Overflow中的漏洞代码作为提示，评估LLMs是否提供安全警告以及相关原因、利用方法和修复建议。结果显示，LLMs的漏洞检测率仅为12.6%至40%，且更善于识别敏感信息暴露和输入中和不当等问题，而对文件路径控制等类型较弱。尽管如此，当LLMs发出警告时，它们比Stack Overflow响应提供更多详细信息。最后，论文讨论了这些发现的启示，并引入了一个基于CLI的提示工具，以生成更安全的LLMs响应。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted to EMSE",
      "pdf_url": "http://arxiv.org/pdf/2502.14202v2",
      "published_date": "2025-02-20 02:20:06 UTC",
      "updated_date": "2025-04-03 22:13:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:44:51.713776"
    },
    {
      "arxiv_id": "2502.14200v1",
      "title": "Causal Mean Field Multi-Agent Reinforcement Learning",
      "title_zh": "因果平均场多智能体强化学习",
      "authors": [
        "Hao Ma",
        "Zhiqiang Pu",
        "Yi Pan",
        "Boyin Liu",
        "Junlong Gao",
        "Zhenyu Guo"
      ],
      "abstract": "Scalability remains a challenge in multi-agent reinforcement learning and is\ncurrently under active research. A framework named mean-field reinforcement\nlearning (MFRL) could alleviate the scalability problem by employing the Mean\nField Theory to turn a many-agent problem into a two-agent problem. However,\nthis framework lacks the ability to identify essential interactions under\nnonstationary environments. Causality contains relatively invariant mechanisms\nbehind interactions, though environments are nonstationary. Therefore, we\npropose an algorithm called causal mean-field Q-learning (CMFQ) to address the\nscalability problem. CMFQ is ever more robust toward the change of the number\nof agents though inheriting the compressed representation of MFRL's\naction-state space. Firstly, we model the causality behind the decision-making\nprocess of MFRL into a structural causal model (SCM). Then the essential degree\nof each interaction is quantified via intervening on the SCM. Furthermore, we\ndesign the causality-aware compact representation for behavioral information of\nagents as the weighted sum of all behavioral information according to their\ncausal effects. We test CMFQ in a mixed cooperative-competitive game and a\ncooperative game. The result shows that our method has excellent scalability\nperformance in both training in environments containing a large number of\nagents and testing in environments containing much more agents.",
      "tldr_zh": "本研究针对多智能体强化学习（Multi-Agent Reinforcement Learning）的可扩展性挑战，提出了一种因果均值场Q学习算法（Causal Mean-Field Q-Learning, CMFQ）。CMFQ 通过构建结构因果模型（Structural Causal Model, SCM）来量化代理间交互的重要度，并设计因果感知的紧凑表示，继承了均值场强化学习（Mean-Field Reinforcement Learning, MFRL）的行动状态空间压缩优势，同时提升了在非平稳环境下的鲁棒性。实验结果显示，CMFQ 在混合合作竞争游戏和合作游戏中表现出色，能够高效处理大量智能体环境，并在智能体数量变化时保持优异性能。",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14200v1",
      "published_date": "2025-02-20 02:15:58 UTC",
      "updated_date": "2025-02-20 02:15:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:45:04.454264"
    },
    {
      "arxiv_id": "2502.14197v1",
      "title": "Adaptive Sparsified Graph Learning Framework for Vessel Behavior Anomalies",
      "title_zh": "翻译失败",
      "authors": [
        "Jeehong Kim",
        "Minchan Kim",
        "Jaeseong Ju",
        "Youngseok Hwang",
        "Wonhee Lee",
        "Hyunwoo Park"
      ],
      "abstract": "Graph neural networks have emerged as a powerful tool for learning\nspatiotemporal interactions. However, conventional approaches often rely on\npredefined graphs, which may obscure the precise relationships being modeled.\nAdditionally, existing methods typically define nodes based on fixed spatial\nlocations, a strategy that is ill-suited for dynamic environments like maritime\nenvironments. Our method introduces an innovative graph representation where\ntimestamps are modeled as distinct nodes, allowing temporal dependencies to be\nexplicitly captured through graph edges. This setup is extended to construct a\nmulti-ship graph that effectively captures spatial interactions while\npreserving graph sparsity. The graph is processed using Graph Convolutional\nNetwork layers to capture spatiotemporal patterns, with a forecasting layer for\nfeature prediction and a Variational Graph Autoencoder for reconstruction,\nenabling robust anomaly detection.",
      "tldr_zh": "本研究提出了一种自适应稀疏图学习框架，用于检测船舶行为异常，旨在解决传统Graph Neural Networks依赖预定义图和固定空间节点的局限性。该框架创新地将时间戳作为独立节点，通过图边显式捕获时间依赖，并构建多船图来处理空间交互，同时保持图的稀疏性。利用Graph Convolutional Network层处理图以捕获时空模式，结合预测层进行特征预测和Variational Graph Autoencoder进行重建，从而实现鲁棒的异常检测。这种方法适用于动态海洋环境，提升了异常检测的准确性和适用性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Anomaly Detection in Scientific Domains AAAI Workshop",
      "pdf_url": "http://arxiv.org/pdf/2502.14197v1",
      "published_date": "2025-02-20 02:01:40 UTC",
      "updated_date": "2025-02-20 02:01:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:45:16.261195"
    },
    {
      "arxiv_id": "2502.14191v1",
      "title": "Multimodal RewardBench: Holistic Evaluation of Reward Models for Vision Language Models",
      "title_zh": "Multimodal RewardBench：视觉语言模型奖励模型的整体评估",
      "authors": [
        "Michihiro Yasunaga",
        "Luke Zettlemoyer",
        "Marjan Ghazvininejad"
      ],
      "abstract": "Reward models play an essential role in training vision-language models\n(VLMs) by assessing output quality to enable aligning with human preferences.\nDespite their importance, the research community lacks comprehensive open\nbenchmarks for evaluating multimodal reward models in VLMs. To address this\ngap, we introduce Multimodal RewardBench, an expert-annotated benchmark\ncovering six domains: general correctness, preference, knowledge, reasoning,\nsafety, and visual question-answering. Our dataset comprises 5,211 annotated\n(prompt, chosen response, rejected response) triplets collected from various\nVLMs. In evaluating a range of VLM judges, we find that even the top-performing\nmodels, Gemini 1.5 Pro and Claude 3.5 Sonnet, achieve only 72% overall\naccuracy. Notably, most models struggle in the reasoning and safety domains.\nThese findings suggest that Multimodal RewardBench offers a challenging testbed\nfor advancing reward model development across multiple domains. We release the\nbenchmark at https://github.com/facebookresearch/multimodal_rewardbench.",
      "tldr_zh": "该研究引入了Multimodal RewardBench，这是一个全面的专家标注基准，用于评估视觉语言模型(VLMs)的多模态奖励模型。该基准覆盖六个领域，包括一般正确性、偏好、知识、推理、安全性和视觉问答，共包含5,211个(prompt, chosen response, rejected response)三元组。实验结果显示，即使是顶级模型如Gemini 1.5 Pro和Claude 3.5 Sonnet的整体准确率仅为72%，尤其在推理和安全领域表现欠佳。这些发现为奖励模型的跨领域开发提供了具有挑战性的测试平台，并已在GitHub上发布。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Dataset available at\n  https://github.com/facebookresearch/multimodal_rewardbench",
      "pdf_url": "http://arxiv.org/pdf/2502.14191v1",
      "published_date": "2025-02-20 01:48:13 UTC",
      "updated_date": "2025-02-20 01:48:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:45:28.819216"
    },
    {
      "arxiv_id": "2502.14183v1",
      "title": "Type 1 Diabetes Management using GLIMMER: Glucose Level Indicator Model with Modified Error Rate",
      "title_zh": "翻译失败",
      "authors": [
        "Saman Khamesian",
        "Asiful Arefeen",
        "Adela Grando",
        "Bithika Thompson",
        "Hassan Ghasemzadeh"
      ],
      "abstract": "Managing Type 1 Diabetes (T1D) demands constant vigilance as individuals\nstrive to regulate their blood glucose levels to avert the dangers of\ndysglycemia (hyperglycemia or hypoglycemia). Despite the advent of\nsophisticated technologies such as automated insulin delivery (AID) systems,\nachieving optimal glycemic control remains a formidable task. AID systems\nintegrate continuous subcutaneous insulin infusion (CSII) and continuous\nglucose monitors (CGM) data, offering promise in reducing variability and\nincreasing glucose time-in-range. However, these systems often fail to prevent\ndysglycemia, partly due to limitations in prediction algorithms that lack the\nprecision to avert abnormal glucose events. This gap highlights the need for\nproactive behavioral adjustments. We address this need with GLIMMER, Glucose\nLevel Indicator Model with Modified Error Rate, a machine learning approach for\nforecasting blood glucose levels. GLIMMER categorizes glucose values into\nnormal and abnormal ranges and devises a novel custom loss function to\nprioritize accuracy in dysglycemic events where patient safety is critical. To\nevaluate the potential of GLIMMER for T1D management, we both use a publicly\navailable dataset and collect new data involving 25 patients with T1D. In\npredicting next-hour glucose values, GLIMMER achieved a root mean square error\n(RMSE) of 23.97 (+/-3.77) and a mean absolute error (MAE) of 15.83 (+/-2.09)\nmg/dL. These results reflect a 23% improvement in RMSE and a 31% improvement in\nMAE compared to the best-reported error rates.",
      "tldr_zh": "该研究针对1型糖尿病(T1D)管理中的血糖调控挑战，指出现有自动胰岛素递送(AID)系统难以有效预防血糖异常问题。研究提出GLIMMER模型，这是一种基于机器学习的血糖预测方法，通过将血糖值分类为正常和异常，并采用自定义损失函数(Modified Error Rate)来优先优化异常事件的预测准确性，以提升患者安全。使用公开数据集和新收集的25名T1D患者数据进行评估，GLIMMER在预测下一小时血糖值时，实现了RMSE 23.97 (±3.77) mg/dL和MAE 15.83 (±2.09) mg/dL的性能，较最佳报告误差率分别提高了23%和31%。这为T1D管理提供了更可靠的预测工具，促进主动行为调整。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14183v1",
      "published_date": "2025-02-20 01:26:00 UTC",
      "updated_date": "2025-02-20 01:26:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:45:41.741561"
    },
    {
      "arxiv_id": "2502.14176v1",
      "title": "A modal logic translation of the AGM axioms for belief revision",
      "title_zh": "翻译失败",
      "authors": [
        "Giacomo Bonanno"
      ],
      "abstract": "Building on the analysis of Bonanno (Artificial Intelligence, 2025) we\nintroduce a simple modal logic containing three modal operators: a unimodal\nbelief operator, a bimodal conditional operator and the unimodal global\noperator. For each AGM axiom for belief revision, we provide a corresponding\nmodal axiom. The correspondence is as follows: each AGM axiom is characterized\nby a property of the Kripke-Lewis frames considered in Bonanno (Artificial\nIntelligence, 2025) and, in turn, that property characterizes the proposed\nmodal axiom.",
      "tldr_zh": "该论文基于 Bonanno 的分析，引入一个简单模态逻辑，包含三个模态运算符：一个单模态 belief operator、一个双模态 conditional operator 和一个单模态 global operator，以翻译 AGM axioms for belief revision。每个 AGM 公理对应一个模态公理，这些模态公理由 Kripke-Lewis frames 的特定属性表征。这种对应关系为信念修正理论提供了新的逻辑框架，促进了更精确的模型构建。",
      "categories": [
        "cs.LO",
        "cs.AI",
        "68, 03"
      ],
      "primary_category": "cs.LO",
      "comment": "19 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.14176v1",
      "published_date": "2025-02-20 01:07:01 UTC",
      "updated_date": "2025-02-20 01:07:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:45:53.102001"
    },
    {
      "arxiv_id": "2502.15819v1",
      "title": "Tabular Embeddings for Tables with Bi-Dimensional Hierarchical Metadata and Nesting",
      "title_zh": "翻译失败",
      "authors": [
        "Gyanendra Shrestha",
        "Chutain Jiang",
        "Sai Akula",
        "Vivek Yannam",
        "Anna Pyayt",
        "Michael Gubanov"
      ],
      "abstract": "Embeddings serve as condensed vector representations for real-world entities,\nfinding applications in Natural Language Processing (NLP), Computer Vision, and\nData Management across diverse downstream tasks. Here, we introduce novel\nspecialized embeddings optimized, and explicitly tailored to encode the\nintricacies of complex 2-D context in tables, featuring horizontal, vertical\nhierarchical metadata, and nesting. To accomplish that we define the\nBi-dimensional tabular coordinates, separate horizontal, vertical metadata and\ndata contexts by introducing a new visibility matrix, encode units and nesting\nthrough the embeddings specifically optimized for mimicking intricacies of such\ncomplex structured data. Through evaluation on 5 large-scale structured\ndatasets and 3 popular downstream tasks, we observed that our solution\noutperforms the state-of-the-art models with the significant MAP delta of up to\n0.28. GPT-4 LLM+RAG slightly outperforms us with MRR delta of up to 0.1, while\nwe outperform it with the MAP delta of up to 0.42.",
      "tldr_zh": "这篇论文引入了一种新型的embeddings，专门针对具有Bi-dimensional hierarchical metadata和nesting的复杂表格结构，以更好地编码二维上下文。作者定义了Bi-dimensional tabular coordinates和visibility matrix来分离水平、垂直元数据和数据上下文，并优化嵌入以处理单元和嵌套。实验结果显示，该方法在5个大规模结构化数据集和3个下游任务上超过了最先进模型，MAP提升高达0.28，同时在MAP上优于GPT-4 LLM+RAG（差值高达0.42），尽管在MRR上略逊色（差值0.1）。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.15819v1",
      "published_date": "2025-02-20 01:04:11 UTC",
      "updated_date": "2025-02-20 01:04:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:46:05.248437"
    },
    {
      "arxiv_id": "2502.14174v1",
      "title": "Weighted Low-rank Approximation via Stochastic Gradient Descent on Manifolds",
      "title_zh": "翻译失败",
      "authors": [
        "Conglong Xu",
        "Peiqi Yang",
        "Hao Wu"
      ],
      "abstract": "We solve a regularized weighted low-rank approximation problem by a\nstochastic gradient descent on a manifold. To guarantee the convergence of our\nstochastic gradient descent, we establish a convergence theorem on manifolds\nfor retraction-based stochastic gradient descents admitting confinements. On\nsample data from the Netflix Prize training dataset, our algorithm outperforms\nthe existing stochastic gradient descent on Euclidean spaces. We also compare\nthe accelerated line search on this manifold to the existing accelerated line\nsearch on Euclidean spaces.",
      "tldr_zh": "本研究提出了一种在流形（Manifolds）上使用随机梯度下降（Stochastic Gradient Descent）来解决正则化的加权低秩逼近（Weighted Low-rank Approximation）问题。作者建立了针对基于回缩（Retraction-based）的随机梯度下降的收敛定理，以确保算法在存在约束（Confinements）时的收敛性。在 Netflix Prize 训练数据集的实验中，该算法的表现优于欧氏空间（Euclidean Spaces）上的随机梯度下降方法。此外，作者比较了在流形上的加速线搜索（Accelerated Line Search）与欧氏空间上的对应方法，展示了其优势。",
      "categories": [
        "math.OC",
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "math.OC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14174v1",
      "published_date": "2025-02-20 00:59:50 UTC",
      "updated_date": "2025-02-20 00:59:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:46:17.658120"
    },
    {
      "arxiv_id": "2502.14160v1",
      "title": "Efficient Inverse Multiagent Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Denizalp Goktas",
        "Amy Greenwald",
        "Sadie Zhao",
        "Alec Koppel",
        "Sumitra Ganesh"
      ],
      "abstract": "In this paper, we study inverse game theory (resp. inverse multiagent\nlearning) in which the goal is to find parameters of a game's payoff functions\nfor which the expected (resp. sampled) behavior is an equilibrium. We formulate\nthese problems as generative-adversarial (i.e., min-max) optimization problems,\nfor which we develop polynomial-time algorithms to solve, the former of which\nrelies on an exact first-order oracle, and the latter, a stochastic one. We\nextend our approach to solve inverse multiagent simulacral learning in\npolynomial time and number of samples. In these problems, we seek a simulacrum,\nmeaning parameters and an associated equilibrium that replicate the given\nobservations in expectation. We find that our approach outperforms the\nwidely-used ARIMA method in predicting prices in Spanish electricity markets\nbased on time-series data.",
      "tldr_zh": "本论文研究了Inverse Game Theory和Inverse Multiagent Learning，目标是找到游戏收益函数的参数，使期望行为或采样行为成为均衡。\n他们将这些问题表述为Generative-Adversarial优化问题，并开发了多项式时间算法，分别依赖于精确的第一阶预言机或随机预言机。\n此外，论文扩展到Inverse Multiagent Simulacral Learning，能够在多项式时间和样本数下实现模拟均衡，并在西班牙电力市场的价格预测中表现出色，优于ARIMA方法。",
      "categories": [
        "cs.GT",
        "cs.AI",
        "cs.LG",
        "econ.TH"
      ],
      "primary_category": "cs.GT",
      "comment": "Paper was submitted to the International Conference on Learning\n  Representations (2024) under the title of \"Generative Adversarial Inverse\n  Multiagent Learning\", and renamed for the camera-ready submission as\n  \"Efficient Inverse Multiagent Learning\"",
      "pdf_url": "http://arxiv.org/pdf/2502.14160v1",
      "published_date": "2025-02-20 00:07:06 UTC",
      "updated_date": "2025-02-20 00:07:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T16:46:28.536864"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 166,
  "processed_papers_count": 166,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-23T16:46:53.526377"
}