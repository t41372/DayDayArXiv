{
  "date": "2024-11-19",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-11-19 的 arXiv 中文 TLDR 快报！今天的论文主要聚焦于 AI 领域的创新应用，包括大语言模型（LLMs）的优化、强化学习在机器人和图神经网络中的进展，以及图像生成和医疗诊断的技术突破。其中，令人印象深刻的文章包括 KDD 2025 接受的 MLDGG 框架，以及 NeurIPS 相关的工作，如 From Text to Pose to Image，这些展示了 LLMs 在多模态任务中的潜力，同时 Sham Kakade 等知名学者参与的论文也值得关注。\n\n下面，我们挑选并简要讨论部分关键论文，先从重要和话题度高的入手，再快速掠过其他次要内容。每个条目列出论文标题（中文 + 英文），并突出核心贡献和发现。\n\n### 重点论文讨论\n\n- **Loss-to-Loss Prediction: Scaling Laws for All Datasets**（中文：从损失到损失预测：适用于所有数据集的缩放定律）  \n  这篇论文由 Sham Kakade 等学者主导，提出了一种预测不同数据分布下训练损失的策略，通过移位幂律关系实现高效外推，即使在 20 倍的计算预算下也能准确预测训练和测试损失，主要贡献在于提升了机器学习模型的可移植性。\n\n- **Human-In-the-Loop Software Development Agents**（中文：人类在环的软件开发代理）  \n  作者包括 Chakkrit Tantithamthavorn，引入 HULA 框架，支持软件工程师在生成代码计划和源代码时提供反馈，显著减少开发时间，但代码质量仍需改进；ICSE SEIP 2025 接受，强调了 LLM 在实际软件工程中的交互潜力。\n\n- **MLDGG: Meta-Learning for Domain Generalization on Graphs**（中文：基于元学习的图域泛化）  \n  KDD 2025 接受的亮点工作，提出 MLDGG 框架，通过元学习结合结构学习和语义识别，实现图数据的鲁棒泛化，实验显示在多种分布偏移场景下超越基线，适用于图神经网络（GNNs）的实际应用。\n\n- **Deep Learning-Based Classification of Hyperkinetic Movement Disorders in Children**（中文：基于深度学习的儿童过度运动障碍分类）  \n  利用 GCN 和 LSTM 网络从视频中区分舞蹈病和肌张力障碍，模型准确率达 85%，注意力机制提升了可解释性，主要发现是深度学习在医疗诊断中的潜力，帮助减少诊断延迟。\n\n- **Advancing Large Language Models for Spatiotemporal and Semantic Association Mining**（中文：提升大语言模型在时空和语义关联挖掘中的能力）  \n  引入检索-重排序框架，使用 LLM 分析气候事件，结合空间临近和语义相似性，实现高效事件推荐，应用于 4000 多个环境事件数据集，展示了 LLM 在地理信息处理的实用价值。\n\n- **From Text to Pose to Image: Improving Diffusion Model Control**（中文：从文本到姿态到图像：提升扩散模型控制）  \n  NeurIPS 2024 相关工作，提出文本到姿态生成模型和新采样算法，提高了扩散模型在人体姿态生成中的保真度和美学质量，主要贡献是首次实现生成式文本-姿态-图像框架。\n\n- **Instant Policy: In-Context Imitation Learning via Graph Diffusion**（中文：即时策略：基于图扩散的上下文模仿学习）  \n  利用图扩散建模演示数据，实现机器人任务的即时学习，无需额外训练，实验证明在模拟和真实环境中提升了任务适应性，强调了强化学习在机器人领域的效率。\n\n- **Conversational Medical AI: Ready for Practice**（中文：对话式医疗 AI：准备就绪）  \n  AAAI25 口头报告，部署 LLM 代理于医疗对话系统，实验显示患者满意度提升（评分 4.58/5），并通过医生监督确保安全，关键发现是 AI 可辅助医疗沟通但需严格监管。\n\n- **ACING: Actor-Critic for Instruction Learning in Black-Box Large Language Models**（中文：基于 Actor-Critic 的黑箱大语言模型指令学习）  \n  提出强化学习框架优化黑箱 LLM 指令，实验在 30 个任务上提升 10% 的性能，展示了无梯度访问下 LLM 的适应性。\n\n- **CATCH: Complementary Adaptive Token-level Contrastive Decoding**（中文：互补自适应 Token 级对比解码）  \n  针对视觉语言模型的幻觉问题，引入视觉解耦和自适应解码，显著提升图像生成质量，适用于各种视觉问答任务。\n\n其他论文中，涉及 LLM 和图神经网络的如 **Benchmarking Positional Encodings for GNNs and Graph Transformers**（中文：图神经网络和图变换器的位置编码基准测试），发现新组合可提升性能；**AdaCM$^2$**（中文：自适应跨模态记忆减少）改进了长视频理解；**Puppet-CNN**（中文：基于 ODE 的输入自适应 CNN）减少了模型参数，提升了效率。这些工作在 AI 优化上有所创新，但细节较技术性强，故从简。\n\n### 快速掠过其他内容\n剩余论文覆盖医疗图像处理（如 Robust multi-coil MRI reconstruction）、代码生成（LibEvolutionEval）和时间序列分析（STREAM），这些领域有稳健进展，但不具高话题度。例如，**LibEvolutionEval** 基准了代码库演化，但核心在于改进检索准确性；医疗相关论文如 **Deep Learning-Driven Heat Map Analysis** 提升了伤口评估，但整体影响较局部。总体而言，这些论文强化了 AI 在专业领域的应用，但未有突破性发现。\n\n今天的快报到此结束，arXiv 论文多样性持续推动 AI 创新，欢迎读者关注感兴趣领域！",
  "papers": [
    {
      "arxiv_id": "2411.12925v1",
      "title": "Loss-to-Loss Prediction: Scaling Laws for All Datasets",
      "title_zh": "翻译失败",
      "authors": [
        "David Brandfonbrener",
        "Nikhil Anand",
        "Nikhil Vyas",
        "Eran Malach",
        "Sham Kakade"
      ],
      "abstract": "While scaling laws provide a reliable methodology for predicting train loss\nacross compute scales for a single data distribution, less is known about how\nthese predictions should change as we change the distribution. In this paper,\nwe derive a strategy for predicting one loss from another and apply it to\npredict across different pre-training datasets and from pre-training data to\ndownstream task data. Our predictions extrapolate well even at 20x the largest\nFLOP budget used to fit the curves. More precisely, we find that there are\nsimple shifted power law relationships between (1) the train losses of two\nmodels trained on two separate datasets when the models are paired by training\ncompute (train-to-train), (2) the train loss and the test loss on any\ndownstream distribution for a single model (train-to-test), and (3) the test\nlosses of two models trained on two separate train datasets (test-to-test). The\nresults hold up for pre-training datasets that differ substantially (some are\nentirely code and others have no code at all) and across a variety of\ndownstream tasks. Finally, we find that in some settings these shifted power\nlaw relationships can yield more accurate predictions than extrapolating\nsingle-dataset scaling laws.",
      "tldr_zh": "本文提出了一种“Loss-to-Loss Prediction”策略，扩展了scaling laws，用于预测不同数据集上的训练损失，包括从一个数据集预测另一个数据集（train-to-train）、从训练损失预测下游任务测试损失（train-to-test），以及不同训练数据集间的测试损失（test-to-test）。研究发现，这些预测基于简单的shifted power law关系，能够在20倍计算预算下有效外推，即使数据集差异显著（如包含或不包含代码）。实验结果显示，该方法在各种下游任务上比传统单一数据集scaling laws更准确，为跨数据集模型性能预测提供了可靠框架。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.12925v1",
      "published_date": "2024-11-19 23:23:16 UTC",
      "updated_date": "2024-11-19 23:23:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:51:57.824870"
    },
    {
      "arxiv_id": "2411.12924v2",
      "title": "Human-In-the-Loop Software Development Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Wannita Takerngsaksiri",
        "Jirat Pasuksmit",
        "Patanamon Thongtanunam",
        "Chakkrit Tantithamthavorn",
        "Ruixiong Zhang",
        "Fan Jiang",
        "Jing Li",
        "Evan Cook",
        "Kun Chen",
        "Ming Wu"
      ],
      "abstract": "Recently, Large Language Models (LLMs)-based multi-agent paradigms for\nsoftware engineering are introduced to automatically resolve software\ndevelopment tasks (e.g., from a given issue to source code). However, existing\nwork is evaluated based on historical benchmark datasets, rarely considers\nhuman feedback at each stage of the automated software development process, and\nhas not been deployed in practice. In this paper, we introduce a\nHuman-in-the-loop LLM-based Agents framework (HULA) for software development\nthat allows software engineers to refine and guide LLMs when generating coding\nplans and source code for a given task. We design, implement, and deploy the\nHULA framework into Atlassian JIRA for internal uses. Through a multi-stage\nevaluation of the HULA framework, Atlassian software engineers perceive that\nHULA can minimize the overall development time and effort, especially in\ninitiating a coding plan and writing code for straightforward tasks. On the\nother hand, challenges around code quality remain a concern in some cases. We\ndraw lessons learned and discuss opportunities for future work, which will pave\nthe way for the advancement of LLM-based agents in software development.",
      "tldr_zh": "这篇论文引入了 HULA 框架（Human-in-the-loop LLM-based Agents），一个基于 Large Language Models (LLMs) 的多智能体系统，旨在通过整合人类反馈来辅助软件开发任务，如生成编码计划和源代码。HULA 框架已设计、实现并部署到 Atlassian JIRA 中，允许软件工程师实时指导和优化开发过程。评估结果显示，Atlassian 的软件工程师认为 HULA 可以显著减少开发时间和努力，尤其在处理简单任务时；然而，代码质量问题在某些情况下仍存在。论文总结了经验教训，并探讨了未来 LLM-based 代理在软件工程中的改进机会。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "10 pages, 9 figures, ICSE SEIP 2025",
      "pdf_url": "http://arxiv.org/pdf/2411.12924v2",
      "published_date": "2024-11-19 23:22:33 UTC",
      "updated_date": "2025-01-10 03:55:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:52:09.933543"
    },
    {
      "arxiv_id": "2411.12921v2",
      "title": "A Comparative Study of Text Retrieval Models on DaReCzech",
      "title_zh": "文本检索模型在 DaReCzech 上的比较研究",
      "authors": [
        "Jakub Stetina",
        "Martin Fajcik",
        "Michal Stefanik",
        "Michal Hradis"
      ],
      "abstract": "This article presents a comprehensive evaluation of 7 off-the-shelf document\nretrieval models: Splade, Plaid, Plaid-X, SimCSE, Contriever, OpenAI ADA and\nGemma2 chosen to determine their performance on the Czech retrieval dataset\nDaReCzech. The primary objective of our experiments is to estimate the quality\nof modern retrieval approaches in the Czech language. Our analyses include\nretrieval quality, speed, and memory footprint. Secondly, we analyze whether it\nis better to use the model directly in Czech text, or to use machine\ntranslation into English, followed by retrieval in English. Our experiments\nidentify the most effective option for Czech information retrieval. The\nfindings revealed notable performance differences among the models, with\nGemma22 achieving the highest precision and recall, while Contriever performing\npoorly. Conclusively, SPLADE and PLAID models offered a balance of efficiency\nand performance.",
      "tldr_zh": "本研究对7个现成文档检索模型（Splade、Plaid、Plaid-X、SimCSE、Contriever、OpenAI ADA和Gemma2）在Czech语数据集DaReCzech上的性能进行了全面评估，重点考察了检索质量、速度和内存占用。实验比较了直接在Czech文本上使用模型与先翻译成English再进行检索的两种方式，结果显示Gemma2在精确度和召回率方面表现最佳，而Contriever的性能较差。总体而言，Splade和Plaid模型在效率和性能之间取得了良好平衡，为Czech信息检索提供了有效的选项。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.12921v2",
      "published_date": "2024-11-19 23:19:46 UTC",
      "updated_date": "2024-12-20 23:02:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:52:20.784181"
    },
    {
      "arxiv_id": "2411.12919v3",
      "title": "Robust multi-coil MRI reconstruction via self-supervised denoising",
      "title_zh": "翻译失败",
      "authors": [
        "Asad Aali",
        "Marius Arvinte",
        "Sidharth Kumar",
        "Yamin I. Arefeen",
        "Jonathan I. Tamir"
      ],
      "abstract": "We study the effect of incorporating self-supervised denoising as a\npre-processing step for training deep learning (DL) based reconstruction\nmethods on data corrupted by Gaussian noise. K-space data employed for training\nare typically multi-coil and inherently noisy. Although DL-based reconstruction\nmethods trained on fully sampled data can enable high reconstruction quality,\nobtaining large, noise-free datasets is impractical. We leverage Generalized\nStein's Unbiased Risk Estimate (GSURE) for denoising. We evaluate two DL-based\nreconstruction methods: Diffusion Probabilistic Models (DPMs) and Model-Based\nDeep Learning (MoDL). We evaluate the impact of denoising on the performance of\nthese DL-based methods in solving accelerated multi-coil magnetic resonance\nimaging (MRI) reconstruction. The experiments were carried out on T2-weighted\nbrain and fat-suppressed proton-density knee scans. We observed that\nself-supervised denoising enhances the quality and efficiency of MRI\nreconstructions across various scenarios. Specifically, employing denoised\nimages rather than noisy counterparts when training DL networks results in\nlower normalized root mean squared error (NRMSE), higher structural similarity\nindex measure (SSIM) and peak signal-to-noise ratio (PSNR) across different SNR\nlevels, including 32dB, 22dB, and 12dB for T2-weighted brain data, and 24dB,\n14dB, and 4dB for fat-suppressed knee data. Overall, we showed that denoising\nis an essential pre-processing technique capable of improving the efficacy of\nDL-based MRI reconstruction methods under diverse conditions. By refining the\nquality of input data, denoising enables training more effective DL networks,\npotentially bypassing the need for noise-free reference MRI scans.",
      "tldr_zh": "本论文提出了一种将自监督去噪作为预处理步骤的方法，以提升深度学习（DL）基于的多线圈 MRI 重建鲁棒性，具体使用 Generalized Stein's Unbiased Risk Estimate (GSURE) 处理高斯噪声数据。研究评估了 Diffusion Probabilistic Models (DPMs) 和 Model-Based Deep Learning (MoDL) 在 T2 加权脑部扫描（SNR 水平为 32dB、22dB 和 12dB）和脂肪抑制质子密度膝部扫描（SNR 水平为 24dB、14dB 和 4dB）上的性能。结果显示，去噪预处理显著降低了 normalized root mean squared error (NRMSE)，并提高了 structural similarity index measure (SSIM) 和 peak signal-to-noise ratio (PSNR)，从而改善了重建质量和效率。总体上，该方法证明了去噪作为预处理的关键作用，有望减少对无噪声参考扫描的依赖。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.12919v3",
      "published_date": "2024-11-19 23:17:09 UTC",
      "updated_date": "2025-04-23 02:07:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:52:34.676572"
    },
    {
      "arxiv_id": "2411.12913v1",
      "title": "MLDGG: Meta-Learning for Domain Generalization on Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Qin Tian",
        "Chen Zhao",
        "Minglai Shao",
        "Wenjun Wang",
        "Yujie Lin",
        "Dong Li"
      ],
      "abstract": "Domain generalization on graphs aims to develop models with robust\ngeneralization capabilities, ensuring effective performance on the testing set\ndespite disparities between testing and training distributions. However,\nexisting methods often rely on static encoders directly applied to the target\ndomain, constraining its flexible adaptability. In contrast to conventional\nmethodologies, which concentrate on developing specific generalized models, our\nframework, MLDGG, endeavors to achieve adaptable generalization across diverse\ndomains by integrating cross-multi-domain meta-learning with structure learning\nand semantic identification. Initially, it introduces a generalized structure\nlearner to mitigate the adverse effects of task-unrelated edges, enhancing the\ncomprehensiveness of representations learned by Graph Neural Networks (GNNs)\nwhile capturing shared structural information across domains. Subsequently, a\nrepresentation learner is designed to disentangle domain-invariant semantic and\ndomain-specific variation information in node embedding by leveraging causal\nreasoning for semantic identification, further enhancing generalization. In the\ncontext of meta-learning, meta-parameters for both learners are optimized to\nfacilitate knowledge transfer and enable effective adaptation to graphs through\nfine-tuning within the target domains, where target graphs are inaccessible\nduring training. Our empirical results demonstrate that MLDGG surpasses\nbaseline methods, showcasing its effectiveness in three different distribution\nshift settings.",
      "tldr_zh": "该论文提出MLDGG框架，利用元学习(meta-learning)结合结构学习和语义识别，实现图(Graphs)上的领域泛化(Domain Generalization)，以提升模型在测试分布与训练分布差异下的鲁棒性。框架包括一个通用结构学习器，用于减少任务无关边的影响并捕获跨领域共享结构信息，从而增强Graph Neural Networks (GNNs)的表示能力；同时，一个表示学习器通过因果推理分离节点嵌入中的领域不变语义和领域特定变异信息，进一步提高泛化性能。在元学习框架下，优化元参数促进知识转移，并在目标领域通过微调适应，实验结果显示MLDGG在三种分布偏移设置中优于基线方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted in KDD 2025 (research track)",
      "pdf_url": "http://arxiv.org/pdf/2411.12913v1",
      "published_date": "2024-11-19 22:57:38 UTC",
      "updated_date": "2024-11-19 22:57:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:52:46.624619"
    },
    {
      "arxiv_id": "2411.15200v1",
      "title": "Deep Learning-Based Classification of Hyperkinetic Movement Disorders in Children",
      "title_zh": "基于深度",
      "authors": [
        "Nandika Ramamurthy",
        "Dr Daniel Lumsden",
        "Dr Rachel Sparks"
      ],
      "abstract": "Hyperkinetic movement disorders (HMDs) in children, including dystonia\n(abnormal twisting) and chorea (irregular, random movements), pose significant\ndiagnostic challenges due to overlapping clinical features. The prevalence of\ndystonia ranges from 2 to 50 per million, and chorea from 5 to 10 per 100,000.\nThese conditions are often diagnosed with delays averaging 4.75 to 7.83 years.\nTraditional diagnostic methods depend on clinical history and expert physical\nexaminations, but specialized tests are ineffective due to the complex\npathophysiology of these disorders. This study develops a neural network model\nto differentiate between dystonia and chorea from video recordings of\npaediatric patients performing motor tasks. The model integrates a Graph\nConvolutional Network (GCN) to capture spatial relationships and Long\nShort-Term Memory (LSTM) networks to account for temporal dynamics. Attention\nmechanisms were incorporated to improve model interpretability. The model was\ntrained and validated on a dataset of 50 videos (31 chorea-predominant, 19\ndystonia-predominant) collected under regulatory approval from Guy's and St\nThomas' NHS Foundation Trust. The model achieved 85% accuracy, 81% sensitivity,\nand 88% specificity at 15 frames per second. Attention maps highlighted the\nmodel's ability to correctly identify involuntary movement patterns, with\nmisclassifications often due to occluded body parts or subtle movement\nvariations. This work demonstrates the potential of deep learning to improve\nthe accuracy and efficiency of HMD diagnosis and could contribute to more\nreliable, interpretable clinical tools.",
      "tldr_zh": "本研究针对儿童过度运动障碍（HMDs），如 dystonia 和 chorea 的诊断挑战，这些疾病因症状重叠导致平均诊断延迟4.75至7.83年。研究开发了一个神经网络模型，通过整合 Graph Convolutional Network (GCN) 捕获空间关系、Long Short-Term Memory (LSTM) 处理时间动态，以及 Attention mechanisms 提升可解释性，来从视频中区分 dystonia 和 chorea。模型在50个视频数据集（31个chorea-predominant，19个dystonia-predominant）上训练和验证，实现了85%的准确率、81%的敏感性和88%的特异性。Attention maps 帮助识别不自主运动模式，减少了因身体遮挡或细微差异导致的误分类。该工作展示了深度学习在提高 HMDs 诊断准确性和效率方面的潜力，为可解释的临床工具提供新途径。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "59 pages, 20 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.15200v1",
      "published_date": "2024-11-19 22:02:04 UTC",
      "updated_date": "2024-11-19 22:02:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:52:59.223642"
    },
    {
      "arxiv_id": "2411.12880v1",
      "title": "Advancing Large Language Models for Spatiotemporal and Semantic Association Mining of Similar Environmental Events",
      "title_zh": "提升大语言模型用于类似环境事件的时空和语义关联挖掘",
      "authors": [
        "Yuanyuan Tian",
        "Wenwen Li",
        "Lei Hu",
        "Xiao Chen",
        "Michael Brook",
        "Michael Brubaker",
        "Fan Zhang",
        "Anna K. Liljedahl"
      ],
      "abstract": "Retrieval and recommendation are two essential tasks in modern search tools.\nThis paper introduces a novel retrieval-reranking framework leveraging Large\nLanguage Models (LLMs) to enhance the spatiotemporal and semantic associated\nmining and recommendation of relevant unusual climate and environmental events\ndescribed in news articles and web posts. This framework uses advanced natural\nlanguage processing techniques to address the limitations of traditional manual\ncuration methods in terms of high labor cost and lack of scalability.\nSpecifically, we explore an optimized solution to employ cutting-edge embedding\nmodels for semantically analyzing spatiotemporal events (news) and propose a\nGeo-Time Re-ranking (GT-R) strategy that integrates multi-faceted criteria\nincluding spatial proximity, temporal association, semantic similarity, and\ncategory-instructed similarity to rank and identify similar spatiotemporal\nevents. We apply the proposed framework to a dataset of four thousand Local\nEnvironmental Observer (LEO) Network events, achieving top performance in\nrecommending similar events among multiple cutting-edge dense retrieval models.\nThe search and recommendation pipeline can be applied to a wide range of\nsimilar data search tasks dealing with geospatial and temporal data. We hope\nthat by linking relevant events, we can better aid the general public to gain\nan enhanced understanding of climate change and its impact on different\ncommunities.",
      "tldr_zh": "这篇论文提出了一种基于 Large Language Models (LLMs) 的新型检索-重新排序框架，用于挖掘和推荐新闻文章中类似异常气候和环境事件的时空及语义关联，从而解决传统手动整理方法的劳动成本和可扩展性问题。框架采用先进的嵌入模型对事件进行语义分析，并引入 Geo-Time Re-ranking (GT-R) 策略，整合空间接近性、时间关联、语义相似性和类别指导相似性来优化事件排序和识别。在包含四千个 Local Environmental Observer (LEO) Network 事件的数据集上，该框架在类似事件推荐任务中超越了其他密集检索模型，展现出顶级性能。该方法适用于各种处理地理空间和时间数据的搜索任务，并有助于公众更深入地理解气候变化及其对社区的影响。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.12880v1",
      "published_date": "2024-11-19 21:57:22 UTC",
      "updated_date": "2024-11-19 21:57:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:53:10.531415"
    },
    {
      "arxiv_id": "2412.04478v1",
      "title": "LibEvolutionEval: A Benchmark and Study for Version-Specific Code Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Sachit Kuhar",
        "Wasi Uddin Ahmad",
        "Zijian Wang",
        "Nihal Jain",
        "Haifeng Qian",
        "Baishakhi Ray",
        "Murali Krishna Ramanathan",
        "Xiaofei Ma",
        "Anoop Deoras"
      ],
      "abstract": "Recent advancements in code completion models have primarily focused on local\nfile contexts. However, these studies do not fully capture the complexity of\nreal-world software development, which often requires the use of\nrapidly-evolving public libraries. To fill the gap, we introduce\nLibEvolutionEval, a detailed study requiring an understanding of library\nevolution to perform in-line code completion accurately. LibEvolutionEval\nprovides a version-specific code-completion task comprised of eight libraries\n(torch, torchvision, scipy, pil, tqdm, pyyaml, matplotlib, and pandas) as they\nevolve over the year along with a detailed analysis of the evolution of two\npopular and well-maintained public libraries: PyTorch and Matplotlib. We\nevaluate popular public models and find that public library evolution\nsignificantly influences model performance. We explored mitigation methods by\nstudying how retrieved version-specific library documentation and prompting can\nimprove the model's capability in handling these fast-evolving packages, paving\na promising future path in better handling fast-evolving libraries.",
      "tldr_zh": "该研究引入了LibEvolutionEval，一个针对版本特定代码生成的基准测试和研究，旨在解决现有代码补全模型忽略公共库快速演变的问题。LibEvolutionEval涵盖了八个库（torch, torchvision, scipy, pil, tqdm, pyyaml, matplotlib, and pandas）的演变过程，并对PyTorch和Matplotlib进行了详细分析。实验评估显示，公共库的演变显著影响模型性能，而通过检索版本特定库文档和优化提示方法，可以有效提升模型处理快速演变的库的能力，为未来代码生成技术提供了改进路径。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.04478v1",
      "published_date": "2024-11-19 21:52:23 UTC",
      "updated_date": "2024-11-19 21:52:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:53:21.236999"
    },
    {
      "arxiv_id": "2411.12877v4",
      "title": "The Illusion of Empathy: How AI Chatbots Shape Conversation Perception",
      "title_zh": "移情的幻觉：人工智能聊天机器人如何塑造对话感知",
      "authors": [
        "Tingting Liu",
        "Salvatore Giorgi",
        "Ankit Aich",
        "Allison Lahnala",
        "Brenda Curtis",
        "Lyle Ungar",
        "João Sedoc"
      ],
      "abstract": "As AI chatbots increasingly incorporate empathy, understanding user-centered\nperceptions of chatbot empathy and its impact on conversation quality remains\nessential yet under-explored. This study examines how chatbot identity and\nperceived empathy influence users' overall conversation experience. Analyzing\n155 conversations from two datasets, we found that while GPT-based chatbots\nwere rated significantly higher in conversational quality, they were\nconsistently perceived as less empathetic than human conversational partners.\nEmpathy ratings from GPT-4o annotations aligned with user ratings, reinforcing\nthe perception of lower empathy in chatbots compared to humans. Our findings\nunderscore the critical role of perceived empathy in shaping conversation\nquality, revealing that achieving high-quality human-AI interactions requires\nmore than simply embedding empathetic language; it necessitates addressing the\nnuanced ways users interpret and experience empathy in conversations with\nchatbots.",
      "tldr_zh": "该研究探讨了AI聊天机器人如何通过融入移情影响用户对对话的感知，强调了用户中心视角的重要性。研究者分析了来自两个数据集的155个对话，发现GPT-based chatbots在对话质量上评分显著高于人类，但被一致视为移情较低。GPT-4o的标注进一步证实了这一感知差异，结果表明，实现高质量的人-AI互动需超越简单嵌入empathetic language，而是处理用户对移情的细微解读和体验。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.12877v4",
      "published_date": "2024-11-19 21:47:08 UTC",
      "updated_date": "2025-03-06 20:06:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:55:26.522662"
    },
    {
      "arxiv_id": "2411.12876v1",
      "title": "Puppet-CNN: Input-Adaptive Convolutional Neural Networks with Model Compression using Ordinary Differential Equation",
      "title_zh": "Puppet-CNN：输入自适应卷积神经网络，使用常微分方程进行模型压缩",
      "authors": [
        "Yucheng Xing",
        "Xin Wang"
      ],
      "abstract": "Convolutional Neural Network (CNN) has been applied to more and more\nscenarios due to its excellent performance in many machine learning tasks,\nespecially with deep and complex structures. However, as the network goes\ndeeper, more parameters need to be stored and optimized. Besides, almost all\ncommon CNN models adopt \"train-and-use\" strategy where the structure is\npre-defined and the kernel parameters are fixed after the training with the\nsame structure and set of parameters used for all data without considering the\ncontent complexity. In this paper, we propose a new CNN framework, named as\n$\\textit{Puppet-CNN}$, which contains two modules: a $\\textit{puppet module}$\nand a $\\textit{puppeteer module}$. The puppet module is a CNN model used to\nactually process the input data just like other works, but its depth and\nkernels are generated by the puppeteer module (realized with Ordinary\nDifferential Equation (ODE)) based on the input complexity each time. By\nrecurrently generating kernel parameters in the puppet module, we can take\nadvantage of the dependence among kernels of different convolutional layers to\nsignificantly reduce the size of CNN model by only storing and training the\nparameters of the much smaller puppeteer ODE module. Through experiments on\nseveral datasets, our method has proven to be superior than the traditional\nCNNs on both performance and efficiency. The model size can be reduced more\nthan 10 times.",
      "tldr_zh": "本论文提出了一种输入自适应卷积神经网络（CNN）框架Puppet-CNN，用于解决传统CNN模型参数冗余和固定结构的问题。Puppet-CNN包含puppet module（负责实际处理输入数据）和puppeteer module（利用Ordinary Differential Equation (ODE)根据输入复杂性动态生成深度和内核参数），从而实现模型压缩并利用内核间依赖关系减少存储需求。实验结果显示，该框架在多个数据集上比传统CNN在性能和效率上更优越，模型大小可减少超过10倍。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.12876v1",
      "published_date": "2024-11-19 21:44:21 UTC",
      "updated_date": "2024-11-19 21:44:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:53:45.828107"
    },
    {
      "arxiv_id": "2411.12872v2",
      "title": "From Text to Pose to Image: Improving Diffusion Model Control and Quality",
      "title_zh": "从文本到姿势",
      "authors": [
        "Clément Bonnet",
        "Ariel N. Lee",
        "Franck Wertel",
        "Antoine Tamano",
        "Tanguy Cizain",
        "Pablo Ducru"
      ],
      "abstract": "In the last two years, text-to-image diffusion models have become extremely\npopular. As their quality and usage increase, a major concern has been the need\nfor better output control. In addition to prompt engineering, one effective\nmethod to improve the controllability of diffusion models has been to condition\nthem on additional modalities such as image style, depth map, or keypoints.\nThis forms the basis of ControlNets or Adapters. When attempting to apply these\nmethods to control human poses in outputs of text-to-image diffusion models,\ntwo main challenges have arisen. The first challenge is generating poses\nfollowing a wide range of semantic text descriptions, for which previous\nmethods involved searching for a pose within a dataset of (caption, pose)\npairs. The second challenge is conditioning image generation on a specified\npose while keeping both high aesthetic and high pose fidelity. In this article,\nwe fix these two main issues by introducing a text-to-pose (T2P) generative\nmodel alongside a new sampling algorithm, and a new pose adapter that\nincorporates more pose keypoints for higher pose fidelity. Together, these two\nnew state-of-the-art models enable, for the first time, a generative\ntext-to-pose-to-image framework for higher pose control in diffusion models. We\nrelease all models and the code used for the experiments at\nhttps://github.com/clement-bonnet/text-to-pose.",
      "tldr_zh": "该论文解决了文本到图像扩散模型在控制人类姿势方面的两大挑战：一是根据语义文本描述生成姿势，二是确保图像生成保持高美学和姿势保真度。作者引入了文本到姿势(T2P)生成模型、新采样算法以及一个增强了关键点(pose keypoints)的姿势适配器，构建了一个创新的生成框架：从文本到姿势再到图像。结果显示，该框架显著提高了扩散模型的控制精度和输出质量，并开源了所有模型和代码。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Published at the NeurIPS 2024 Workshop on Compositional Learning:\n  Perspectives, Methods, and Paths Forward",
      "pdf_url": "http://arxiv.org/pdf/2411.12872v2",
      "published_date": "2024-11-19 21:34:50 UTC",
      "updated_date": "2024-11-22 10:26:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:55:38.219059"
    },
    {
      "arxiv_id": "2411.15199v1",
      "title": "Adaptively Controllable Diffusion Model for Efficient Conditional Image Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Yucheng Xing",
        "Xiaodong Liu",
        "Xin Wang"
      ],
      "abstract": "With the development of artificial intelligence, more and more attention has\nbeen put onto generative models, which represent the creativity, a very\nimportant aspect of intelligence. In recent years, diffusion models have been\nstudied and proven to be more reasonable and effective than previous methods.\nHowever, common diffusion frameworks suffer from controllability problems.\nAlthough extra conditions have been considered by some work to guide the\ndiffusion process for a specific target generation, it only controls the\ngeneration result but not its process. In this work, we propose a new adaptive\nframework, $\\textit{Adaptively Controllable Diffusion (AC-Diff) Model}$, to\nautomatically and fully control the generation process, including not only the\ntype of generation result but also the length and parameters of the generation\nprocess. Both inputs and conditions will be first fed into a\n$\\textit{Conditional Time-Step (CTS) Module}$ to determine the number of steps\nneeded for a generation. Then according to the length of the process, the\ndiffusion rate parameters will be estimated through our $\\textit{Adaptive\nHybrid Noise Schedule (AHNS) Module}$. We further train the network with the\ncorresponding adaptive sampling mechanism to learn how to adjust itself\naccording to the conditions for the overall performance improvement. To enable\nits practical applications, AC-Diff is expected to largely reduce the average\nnumber of generation steps and execution time while maintaining the same\nperformance as done in the literature diffusion models.",
      "tldr_zh": "这篇论文提出了一种自适应可控扩散模型（AC-Diff），旨在解决传统扩散模型（diffusion models）在条件图像生成中的可控性问题，通过自动控制生成过程的类型、长度和参数来提升效率。核心组件包括条件时间步模块（CTS Module），用于根据输入和条件确定生成步数，以及自适应混合噪声调度模块（AHNS Module），用于估计扩散率参数。实验表明，AC-Diff 通过自适应采样机制训练，能够显著减少生成步骤和执行时间，同时保持与现有模型相同的性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.15199v1",
      "published_date": "2024-11-19 21:26:30 UTC",
      "updated_date": "2024-11-19 21:26:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:55:49.506730"
    },
    {
      "arxiv_id": "2411.12859v1",
      "title": "The Game-Theoretic Symbiosis of Trust and AI in Networked Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Yunfei Ge",
        "Quanyan Zhu"
      ],
      "abstract": "This chapter explores the symbiotic relationship between Artificial\nIntelligence (AI) and trust in networked systems, focusing on how these two\nelements reinforce each other in strategic cybersecurity contexts. AI's\ncapabilities in data processing, learning, and real-time response offer\nunprecedented support for managing trust in dynamic, complex networks. However,\nthe successful integration of AI also hinges on the trustworthiness of AI\nsystems themselves. Using a game-theoretic framework, this chapter presents\napproaches to trust evaluation, the strategic role of AI in cybersecurity, and\ngovernance frameworks that ensure responsible AI deployment. We investigate how\ntrust, when dynamically managed through AI, can form a resilient security\necosystem. By examining trust as both an AI output and an AI requirement, this\nchapter sets the foundation for a positive feedback loop where AI enhances\nnetwork security and the trust placed in AI systems fosters their adoption.",
      "tldr_zh": "本章探讨了人工智能 (AI) 与信任在网络系统中的共生关系，特别是在战略网络安全情境下如何相互强化，强调AI在数据处理、学习和实时响应方面的能力有助于动态管理信任。采用博弈论框架，该研究呈现了信任评估方法、AI在网络安全中的战略角色，以及确保AI负责部署的治理框架。最终，研究揭示通过AI管理信任可以形成弹性安全生态，并建立正反馈循环，其中AI提升网络安全性，而对AI的信任促进其广泛采用。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.12859v1",
      "published_date": "2024-11-19 21:04:53 UTC",
      "updated_date": "2024-11-19 21:04:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:56:02.038019"
    },
    {
      "arxiv_id": "2411.13608v2",
      "title": "Integrating Dynamic Correlation Shifts and Weighted Benchmarking in Extreme Value Analysis",
      "title_zh": "在极值分析中整合动态相关性变化和加权基准化",
      "authors": [
        "Dimitrios P. Panagoulias",
        "Elissaios Sarmas",
        "Vangelis Marinakis",
        "Maria Virvou",
        "George A. Tsihrintzis"
      ],
      "abstract": "This paper presents an innovative approach to Extreme Value Analysis (EVA) by\nintroducing the Extreme Value Dynamic Benchmarking Method (EVDBM). EVDBM\nintegrates extreme value theory to detect extreme events and is coupled with\nthe novel Dynamic Identification of Significant Correlation (DISC)-Thresholding\nalgorithm, which enhances the analysis of key variables under extreme\nconditions. By integrating return values predicted through EVA into the\nbenchmarking scores, we are able to transform these scores to reflect\nanticipated conditions more accurately. This provides a more precise picture of\nhow each case is projected to unfold under extreme conditions. As a result, the\nadjusted scores offer a forward-looking perspective, highlighting potential\nvulnerabilities and resilience factors for each case in a way that static\nhistorical data alone cannot capture. By incorporating both historical and\nprobabilistic elements, the EVDBM algorithm provides a comprehensive\nbenchmarking framework that is adaptable to a range of scenarios and contexts.\nThe methodology is applied to real PV data, revealing critical low - production\nscenarios and significant correlations between variables, which aid in risk\nmanagement, infrastructure design, and long-term planning, while also allowing\nfor the comparison of different production plants. The flexibility of EVDBM\nsuggests its potential for broader applications in other sectors where\ndecision-making sensitivity is crucial, offering valuable insights to improve\noutcomes.",
      "tldr_zh": "这篇论文提出了 Extreme Value Dynamic Benchmarking Method (EVDBM)，一种创新方法，用于提升 Extreme Value Analysis (EVA) 在检测极端事件中的效能，该方法整合了极值理论和 Dynamic Identification of Significant Correlation (DISC)-Thresholding 算法，以动态分析关键变量的相关性。EVDBM 通过将 EVA 的返回值融入基准分数，提供更精确的前瞻性评估，揭示潜在脆弱性和韧性因素，比静态历史数据更全面。应用于真实 PV 数据，该方法识别了关键低生产场景和变量间相关性，支持风险管理、基础设施设计和长期规划，并展示出在其他敏感决策领域的潜在扩展性。",
      "categories": [
        "stat.AP",
        "cs.AI"
      ],
      "primary_category": "stat.AP",
      "comment": "33 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.13608v2",
      "published_date": "2024-11-19 21:00:39 UTC",
      "updated_date": "2024-11-25 12:21:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:56:14.011565"
    },
    {
      "arxiv_id": "2411.12847v1",
      "title": "mDAE : modified Denoising AutoEncoder for missing data imputation",
      "title_zh": "翻译失败",
      "authors": [
        "Mariette Dupuy",
        "Marie Chavent",
        "Remi Dubois"
      ],
      "abstract": "This paper introduces a methodology based on Denoising AutoEncoder (DAE) for\nmissing data imputation. The proposed methodology, called mDAE hereafter,\nresults from a modification of the loss function and a straightforward\nprocedure for choosing the hyper-parameters. An ablation study shows on several\nUCI Machine Learning Repository datasets, the benefit of using this modified\nloss function and an overcomplete structure, in terms of Root Mean Squared\nError (RMSE) of reconstruction. This numerical study is completed by comparing\nthe mDAE methodology with eight other methods (four standard and four more\nrecent). A criterion called Mean Distance to Best (MDB) is proposed to measure\nhow a method performs globally well on all datasets. This criterion is defined\nas the mean (over the datasets) of the distances between the RMSE of the\nconsidered method and the RMSE of the best method. According to this criterion,\nthe mDAE methodology was consistently ranked among the top methods (along with\nSoftImput and missForest), while the four more recent methods were\nsystematically ranked last. The Python code of the numerical study will be\navailable on GitHub so that results can be reproduced or generalized with other\ndatasets and methods.",
      "tldr_zh": "这篇论文提出了 mDAE，一种修改后的 Denoising AutoEncoder (DAE) 方法，用于处理缺失数据填充，通过修改损失函数和简化超参数选择过程来提升性能。实验消融研究显示，在多个 UCI Machine Learning Repository 数据集上，使用修改后的损失函数和过完备结构，能显著降低 Root Mean Squared Error (RMSE)。与八种其他方法（包括四种标准方法和四种较新方法）比较，新提出的 Mean Distance to Best (MDB) 标准表明，mDAE 与 SoftImpute 和 missForest 一起排名靠前。论文还提供了 GitHub 上的 Python 代码，支持结果复现和进一步扩展。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.12847v1",
      "published_date": "2024-11-19 20:31:53 UTC",
      "updated_date": "2024-11-19 20:31:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:56:26.817524"
    },
    {
      "arxiv_id": "2411.12843v1",
      "title": "Reward Modeling with Ordinal Feedback: Wisdom of the Crowd",
      "title_zh": "基于序数反馈的奖励建模：群体智慧",
      "authors": [
        "Shang Liu",
        "Yu Pan",
        "Guanting Chen",
        "Xiaocheng Li"
      ],
      "abstract": "Learning a reward model (RM) from human preferences has been an important\ncomponent in aligning large language models (LLMs). The canonical setup of\nlearning RMs from pairwise preference data is rooted in the classic\nBradley-Terry (BT) model that accepts binary feedback, i.e., the label being\neither Response 1 is better than Response 2, or the opposite. Such a setup\ninevitably discards potentially useful samples (such as \"tied\" between the two\nresponses) and loses more fine-grained information (such as \"slightly better\").\nIn this paper, we propose a framework for learning RMs under ordinal feedback\nwhich generalizes the case of binary preference feedback to any arbitrary\ngranularity. Specifically, we first identify a marginal unbiasedness condition,\nwhich generalizes the assumption of the BT model in the existing binary\nfeedback setting. The condition validates itself via the sociological concept\nof the wisdom of the crowd. Under the condition, we develop a natural\nprobability model for pairwise preference data under ordinal feedback and\nanalyze its properties. We prove the statistical benefits of ordinal feedback\nin terms of reducing the Rademacher complexity compared to the case of binary\nfeedback. The proposed learning objective and the theory also extend to hinge\nloss and direct policy optimization (DPO). In particular, the theoretical\nanalysis may be of independent interest when applying to a seemingly unrelated\nproblem of knowledge distillation to interpret the bias-variance trade-off\ntherein. The framework also sheds light on writing guidance for human\nannotators. Our numerical experiments validate that fine-grained feedback leads\nto better reward learning for both in-distribution and out-of-distribution\nsettings. Further experiments show that incorporating a certain proportion of\nsamples with tied preference boosts RM learning.",
      "tldr_zh": "本论文提出了一种基于序数反馈的奖励模型（RM）学习框架，以扩展传统二元偏好反馈（如Bradley-Terry模型），允许更细粒度的反馈（如“略好”或“平局”），从而保留更多信息并提升模型性能。作者引入了边缘无偏条件（marginal unbiasedness condition），基于“众包智慧”（wisdom of the crowd）的概念，开发了一个概率模型，并证明了序数反馈能降低Rademacher复杂度，同时扩展到hinge loss和直接策略优化（DPO）。实验结果显示，细粒度反馈在分布内和分布外场景中改善了RM学习效果，且加入部分平局样本能进一步提升性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.12843v1",
      "published_date": "2024-11-19 20:17:04 UTC",
      "updated_date": "2024-11-19 20:17:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:56:37.767574"
    },
    {
      "arxiv_id": "2411.14483v2",
      "title": "Ranking Unraveled: Recipes for LLM Rankings in Head-to-Head AI Combat",
      "title_zh": "翻译失败",
      "authors": [
        "Roland Daynauth",
        "Christopher Clarke",
        "Krisztian Flautner",
        "Lingjia Tang",
        "Jason Mars"
      ],
      "abstract": "Deciding which large language model (LLM) to use is a complex challenge.\nPairwise ranking has emerged as a new method for evaluating human preferences\nfor LLMs. This approach entails humans evaluating pairs of model outputs based\non a predefined criterion. By collecting these comparisons, a ranking can be\nconstructed using methods such as Elo. However, applying these algorithms as\nconstructed in the context of LLM evaluation introduces several challenges. In\nthis paper, we explore the effectiveness of ranking systems for head-to-head\ncomparisons of LLMs. We formally define a set of fundamental principles for\neffective ranking and conduct a series of extensive evaluations on the\nrobustness of several ranking algorithms in the context of LLMs. Our analysis\nuncovers key insights into the factors that affect ranking accuracy and\nefficiency, offering guidelines for selecting the most appropriate methods\nbased on specific evaluation contexts and resource constraints.",
      "tldr_zh": "这篇论文探讨了使用成对排名 (Pairwise ranking) 方法评估大型语言模型 (LLM) 的挑战，通过人类对模型输出进行头对头比较（如基于 Elo 算法构建排名）来确定模型偏好。作者定义了有效排名的基本原则，并通过广泛实验评估了多种排名算法的鲁棒性。研究揭示了影响排名准确性和效率的关键因素，并提供指导，帮助根据特定评估场景和资源约束选择最佳方法。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.14483v2",
      "published_date": "2024-11-19 20:16:26 UTC",
      "updated_date": "2025-02-17 16:21:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:56:49.455153"
    },
    {
      "arxiv_id": "2411.12833v1",
      "title": "Efficient Medicinal Image Transmission and Resolution Enhancement via GAN",
      "title_zh": "通过 GAN 的高效医学图像传输和分辨率增强",
      "authors": [
        "Rishabh Kumar Sharma",
        "Mukund Sharma",
        "Pushkar Sharma",
        "Jeetashree Aparjeeta"
      ],
      "abstract": "While X-ray imaging is indispensable in medical diagnostics, it inherently\ncarries with it those noises and limitations on resolution that mask the\ndetails necessary for diagnosis. B/W X-ray images require a careful balance\nbetween noise suppression and high-detail preservation to ensure clarity in\nsoft-tissue structures and bone edges. While traditional methods, such as CNNs\nand early super-resolution models like ESRGAN, have enhanced image resolution,\nthey often perform poorly regarding high-frequency detail preservation and\nnoise control for B/W imaging. We are going to present one efficient approach\nthat improves the quality of an image with the optimization of network\ntransmission in the following paper. The pre-processing of X-ray images into\nlow-resolution files by Real-ESRGAN, a version of ESRGAN elucidated and\nimproved, helps reduce the server load and transmission bandwidth.\nLower-resolution images are upscaled at the receiving end using Real-ESRGAN,\nfine-tuned for real-world image degradation. The model integrates\nResidual-in-Residual Dense Blocks with perceptual and adversarial loss\nfunctions for high-quality upscaled images with low noise. We further fine-tune\nReal-ESRGAN by adapting it to the specific B/W noise and contrast\ncharacteristics. This suppresses noise artifacts without compromising detail.\nThe comparative evaluation conducted shows that our approach achieves superior\nnoise reduction and detail clarity compared to state-of-the-art CNN-based and\nESRGAN models, apart from reducing network bandwidth requirements. These\nbenefits are confirmed both by quantitative metrics, including Peak\nSignal-to-Noise Ratio and Structural Similarity Index, and by qualitative\nassessments, which indicate the potential of Real-ESRGAN for diagnostic-quality\nX-ray imaging and for efficient medical data transmission.",
      "tldr_zh": "该论文针对X-ray图像在医疗诊断中的噪声和分辨率限制问题，提出了一种高效方法，利用Real-ESRGAN优化图像传输和增强。方法包括将X-ray图像预处理成低分辨率文件以减少服务器负载和传输带宽，然后在接收端使用fine-tuned的Real-ESRGAN进行上采样，该模型整合Residual-in-Residual Dense Blocks以及perceptual和adversarial loss函数，以抑制噪声并保留高频细节。实验结果显示，该方法在噪声减少和细节清晰度上优于传统CNN和ESRGAN模型，同时降低了网络带宽需求，并通过PSNR和SSIM等定量指标以及定性评估证实其在诊断质量X-ray成像中的潜力。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.12833v1",
      "published_date": "2024-11-19 19:39:42 UTC",
      "updated_date": "2024-11-19 19:39:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:57:02.171553"
    },
    {
      "arxiv_id": "2411.12828v1",
      "title": "Probing the Capacity of Language Model Agents to Operationalize Disparate Experiential Context Despite Distraction",
      "title_zh": "翻译失败",
      "authors": [
        "Sonny George",
        "Chris Sypherd",
        "Dylan Cashman"
      ],
      "abstract": "Large language model (LLM) agents show promise in an increasing number of\ndomains. In many proposed applications, it is expected that the agent reasons\nover accumulated experience presented in an input prompt. We propose the OEDD\n(Operationalize Experience Despite Distraction) corpus, a\nhuman-annotator-validated body of scenarios with pre-scripted agent histories\nwhere the agent must make a decision based on disparate experiential\ninformation in the presence of a distractor. We evaluate three state-of-the-art\nLLMs (GPT-3.5 Turbo, GPT-4o, and Gemini 1.5 Pro) using a minimal\nchain-of-thought prompting strategy and observe that when (1) the input context\ncontains over 1,615 tokens of historical interactions, (2) a crucially\ndecision-informing premise is the rightful conclusion over two disparate\nenvironment premises, and (3) a trivial, but distracting red herring fact\nfollows, all LLMs perform worse than random choice at selecting the better of\ntwo actions. Our code and test corpus are publicly available at:\nhttps://github.com/sonnygeorge/OEDD .",
      "tldr_zh": "本研究探讨了大型语言模型（LLM）代理在处理分散经验信息时的能力，提出 OEDD 语料库，这是一个人类标注的场景集，包含预设代理历史，用于测试代理在存在 distractor 的情况下做出基于经验的决策。研究采用 minimal chain-of-thought prompting 策略评估 GPT-3.5 Turbo、GPT-4o 和 Gemini 1.5 Pro 等模型，结果显示当输入上下文超过 1,615 tokens、关键决策信息为两个 disparate environment premises 的正确结论、且伴随琐碎的 red herring 时，所有模型的表现不如随机选择。OEDD 语料库及其代码已公开可用，揭示了 LLM 在复杂情境下处理 distractions 的局限性，并为未来改进提供基础。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.12828v1",
      "published_date": "2024-11-19 19:33:16 UTC",
      "updated_date": "2024-11-19 19:33:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:57:13.879145"
    },
    {
      "arxiv_id": "2411.12820v1",
      "title": "Declare and Justify: Explicit assumptions in AI evaluations are necessary for effective regulation",
      "title_zh": "翻译失败",
      "authors": [
        "Peter Barnett",
        "Lisa Thiergart"
      ],
      "abstract": "As AI systems advance, AI evaluations are becoming an important pillar of\nregulations for ensuring safety. We argue that such regulation should require\ndevelopers to explicitly identify and justify key underlying assumptions about\nevaluations as part of their case for safety. We identify core assumptions in\nAI evaluations (both for evaluating existing models and forecasting future\nmodels), such as comprehensive threat modeling, proxy task validity, and\nadequate capability elicitation. Many of these assumptions cannot currently be\nwell justified. If regulation is to be based on evaluations, it should require\nthat AI development be halted if evaluations demonstrate unacceptable danger or\nif these assumptions are inadequately justified. Our presented approach aims to\nenhance transparency in AI development, offering a practical path towards more\neffective governance of advanced AI systems.",
      "tldr_zh": "该论文主张，在AI系统发展的背景下，AI evaluations（AI评估）是确保安全的重要支柱，因此法规应要求开发者明确识别并证明评估中的关键假设，以构建可靠的安全案例。作者识别了核心假设，包括comprehensive threat modeling（全面威胁建模）、proxy task validity（代理任务有效性）和adequate capability elicitation（足够能力激发），并指出许多假设目前无法充分证明。如果AI evaluations 显示不可接受的危险或假设证明不足，法规应要求停止AI开发。这种方法通过提升AI开发的透明度，提供了一个实用路径，实现更有效的AI系统治理。",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.12820v1",
      "published_date": "2024-11-19 19:13:56 UTC",
      "updated_date": "2024-11-19 19:13:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:57:25.253011"
    },
    {
      "arxiv_id": "2412.04477v3",
      "title": "Intelligent Tutors for Adult Learners: An Analysis of Needs and Challenges",
      "title_zh": "针对成人学习者的智能导师：需求和挑战的分析",
      "authors": [
        "Adit Gupta",
        "Momin Siddiqui",
        "Glen Smith",
        "Jenn Reddig",
        "Christopher MacLellan"
      ],
      "abstract": "This work examines the sociotechnical factors that influence the adoption and\nusage of intelligent tutoring systems in self-directed learning contexts,\nfocusing specifically on adult learners. The study is divided into two parts.\nFirst, we present Apprentice Tutors, a novel intelligent tutoring system\ndesigned to address the unique needs of adult learners. The platform includes\nadaptive problem selection, real-time feedback, and visual dashboards to\nsupport learning in college algebra topics. Second, we investigate the specific\nneeds and experiences of adult users through a deployment study and a series of\nfocus groups. Using thematic analysis, we identify key challenges and\nopportunities to improve tutor design and adoption. Based on these findings, we\noffer actionable design recommendations to help developers create intelligent\ntutoring systems that better align with the motivations and learning\npreferences of adult learners. This work contributes to a wider understanding\nof how to improve educational technologies to support lifelong learning and\nprofessional development.",
      "tldr_zh": "本研究分析了社会技术因素对智能辅导系统（intelligent tutoring systems）在成人自学情境中的采用和使用的影响，特别关注成年学习者的独特需求。研究者开发了Apprentice Tutors，一种新型系统，包含自适应问题选择（adaptive problem selection）、实时反馈和可视化仪表板，用于支持大学代数等主题的学习。通过部署研究和焦点小组，结合主题分析（thematic analysis），他们识别了成年用户的关键挑战和改进机会。最终，该工作提供可操作的设计推荐，帮助开发者创建更符合成年学习者动机和偏好的系统，促进终身学习和专业发展。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.04477v3",
      "published_date": "2024-11-19 19:05:04 UTC",
      "updated_date": "2025-02-19 03:08:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:57:37.765692"
    },
    {
      "arxiv_id": "2411.12808v2",
      "title": "Conversational Medical AI: Ready for Practice",
      "title_zh": "对话式医疗 AI：准备用于实践",
      "authors": [
        "Antoine Lizée",
        "Pierre-Auguste Beaucoté",
        "James Whitbeck",
        "Marion Doumeingts",
        "Anaël Beaugnon",
        "Isabelle Feldhaus"
      ],
      "abstract": "The shortage of doctors is creating a critical squeeze in access to medical\nexpertise. While conversational Artificial Intelligence (AI) holds promise in\naddressing this problem, its safe deployment in patient-facing roles remains\nlargely unexplored in real-world medical settings. We present the first\nlarge-scale evaluation of a physician-supervised LLM-based conversational agent\nin a real-world medical setting.\n  Our agent, Mo, was integrated into an existing medical advice chat service.\nOver a three-week period, we conducted a randomized controlled experiment with\n926 cases to evaluate patient experience and satisfaction. Among these, Mo\nhandled 298 complete patient interactions, for which we report\nphysician-assessed measures of safety and medical accuracy.\n  Patients reported higher clarity of information (3.73 vs 3.62 out of 4, p <\n0.05) and overall satisfaction (4.58 vs 4.42 out of 5, p < 0.05) with\nAI-assisted conversations compared to standard care, while showing equivalent\nlevels of trust and perceived empathy. The high opt-in rate (81% among\nrespondents) exceeded previous benchmarks for AI acceptance in healthcare.\nPhysician oversight ensured safety, with 95% of conversations rated as \"good\"\nor \"excellent\" by general practitioners experienced in operating a medical\nadvice chat service.\n  Our findings demonstrate that carefully implemented AI medical assistants can\nenhance patient experience while maintaining safety standards through physician\nsupervision. This work provides empirical evidence for the feasibility of AI\ndeployment in healthcare communication and insights into the requirements for\nsuccessful integration into existing healthcare services.",
      "tldr_zh": "这篇论文评估了基于 LLM（Large Language Models）的对话 AI 代理 Mo 在真实医疗环境中的应用，旨在解决医生短缺导致的医疗访问问题。研究通过为期三周的随机对照实验（涉及 926 个病例），将 AI 代理整合到现有医疗建议聊天服务中，并由医生监督确保安全和准确性。结果显示，AI 辅助对话提高了患者的信息清晰度（3.73 vs 3.62 出 4 分，p < 0.05）和整体满意度（4.58 vs 4.42 出 5 分，p < 0.05），同时信任和感知同理心与标准护理相当，患者选择率高达 81%。该研究证明了 AI 在医疗通信中的可行性，并为通过医生监督实现安全集成提供了实证依据。",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to AAAI25 (Oral, workshop) 14 pages, 7 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2411.12808v2",
      "published_date": "2024-11-19 19:00:31 UTC",
      "updated_date": "2025-04-10 09:32:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:57:51.245013"
    },
    {
      "arxiv_id": "2411.12736v1",
      "title": "ACING: Actor-Critic for Instruction Learning in Black-Box Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Salma Kharrat",
        "Fares Fourati",
        "Marco Canini"
      ],
      "abstract": "The effectiveness of Large Language Models (LLMs) in solving tasks vastly\ndepends on the quality of the instructions, which often require fine-tuning\nthrough extensive human effort. This highlights the need for automated\ninstruction optimization; however, this optimization is particularly\nchallenging when dealing with black-box LLMs, where model parameters and\ngradients remain inaccessible. We propose ACING, a task-specific prompt\noptimization approach framed as a stateless continuous-action Reinforcement\nLearning (RL) problem, known as the continuum bandit setting. ACING leverages\nan actor-critic-based method to optimize prompts, learning from\nnon-differentiable reward signals. We validate ACING by optimizing prompts for\nChatGPT on 30 instruction-based tasks. ACING consistently outperforms baseline\nmethods, achieving a median score improvement of 10 percentage points.\nFurthermore, ACING not only recovers but also surpasses human-crafted expert\ninstructions, achieving up to a 39 percentage point improvement against human\nbenchmarks.",
      "tldr_zh": "该研究针对黑盒大语言模型(LLMs)的指令学习问题，提出了一种名为ACING的提示优化方法，将其构建为无状态连续动作强化学习(RL)问题，即continuum bandit setting。ACING采用actor-critic-based方法，从非微分奖励信号中学习，从而自动优化任务特定提示。在30个基于指令的任务上，ACING优化ChatGPT的提示后，比基线方法的中位分数提高了10个百分点，并超过了人类专家指令，最高改善达39个百分点。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.SY",
        "eess.SY",
        "math.OC"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.12736v1",
      "published_date": "2024-11-19 18:58:03 UTC",
      "updated_date": "2024-11-19 18:58:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:58:01.519762"
    },
    {
      "arxiv_id": "2411.12732v1",
      "title": "Benchmarking Positional Encodings for GNNs and Graph Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Florian Grötschla",
        "Jiaqing Xie",
        "Roger Wattenhofer"
      ],
      "abstract": "Recent advances in Graph Neural Networks (GNNs) and Graph Transformers (GTs)\nhave been driven by innovations in architectures and Positional Encodings\n(PEs), which are critical for augmenting node features and capturing graph\ntopology. PEs are essential for GTs, where topological information would\notherwise be lost without message-passing. However, PEs are often tested\nalongside novel architectures, making it difficult to isolate their effect on\nestablished models. To address this, we present a comprehensive benchmark of\nPEs in a unified framework that includes both message-passing GNNs and GTs. We\nalso establish theoretical connections between MPNNs and GTs and introduce a\nsparsified GRIT attention mechanism to examine the influence of global\nconnectivity. Our findings demonstrate that previously untested combinations of\nGNN architectures and PEs can outperform existing methods and offer a more\ncomprehensive picture of the state-of-the-art. To support future research and\nexperimentation in our framework, we make the code publicly available.",
      "tldr_zh": "这篇论文针对图神经网络(GNNs)和图变换器(Graph Transformers)中的位置编码(PEs)进行了全面基准测试，以评估其在增强节点特征和捕捉图拓扑方面的关键作用。研究者构建了一个统一框架，包括消息传递GNNs和GTs，并建立了MPNNs与GTs的理论联系，同时引入了稀疏化GRIT注意力机制来分析全局连接的影响。结果显示，之前未测试的GNN架构与PEs组合可超越现有方法，提供更全面的现状评估，并公开了代码以支持未来研究。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.12732v1",
      "published_date": "2024-11-19 18:57:01 UTC",
      "updated_date": "2024-11-19 18:57:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:58:14.011968"
    },
    {
      "arxiv_id": "2411.12724v2",
      "title": "Heuristic-Free Multi-Teacher Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Huy Thong Nguyen",
        "En-Hung Chu",
        "Lenord Melvix",
        "Jazon Jiao",
        "Chunglin Wen",
        "Benjamin Louie"
      ],
      "abstract": "We introduce Teacher2Task, a novel framework for multi-teacher learning that\neliminates the need for manual aggregation heuristics. Existing multi-teacher\nmethods typically rely on such heuristics to combine predictions from multiple\nteachers, often resulting in sub-optimal aggregated labels and the propagation\nof aggregation errors. Teacher2Task addresses these limitations by introducing\nteacher-specific input tokens and reformulating the training process. Instead\nof relying on aggregated labels, the framework transforms the training data,\nconsisting of ground truth labels and annotations from N teachers, into N+1\ndistinct tasks: N auxiliary tasks that predict the labeling styles of the N\nindividual teachers, and one primary task that focuses on the ground truth\nlabels. This approach, drawing upon principles from multiple learning\nparadigms, demonstrates strong empirical results across a range of\narchitectures, modalities, and tasks.",
      "tldr_zh": "本研究提出了一种名为 Teacher2Task 的多教师学习(multi-teacher learning)框架，旨在消除手动聚合启发式(heuristics)的需求，从而避免现有方法中的子优聚合标签和错误传播问题。该框架通过引入教师特定的输入标记，将训练数据转化为 N+1 个任务：N 个辅助任务用于预测每个教师的标记风格，以及一个主要任务专注于真实标签。这种方法借鉴了多种学习范式的原则，并在各种架构、模态和任务上展示了强劲的经验性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.12724v2",
      "published_date": "2024-11-19 18:45:16 UTC",
      "updated_date": "2025-01-24 13:54:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:58:25.662721"
    },
    {
      "arxiv_id": "2411.12713v1",
      "title": "CATCH: Complementary Adaptive Token-level Contrastive Decoding to Mitigate Hallucinations in LVLMs",
      "title_zh": "CATCH：互补自适应 Token 级对比",
      "authors": [
        "Zhehan Kan",
        "Ce Zhang",
        "Zihan Liao",
        "Yapeng Tian",
        "Wenming Yang",
        "Junyuan Xiao",
        "Xu Li",
        "Dongmei Jiang",
        "Yaowei Wang",
        "Qingmin Liao"
      ],
      "abstract": "Large Vision-Language Model (LVLM) systems have demonstrated impressive\nvision-language reasoning capabilities but suffer from pervasive and severe\nhallucination issues, posing significant risks in critical domains such as\nhealthcare and autonomous systems. Despite previous efforts to mitigate\nhallucinations, a persistent issue remains: visual defect from vision-language\nmisalignment, creating a bottleneck in visual processing capacity. To address\nthis challenge, we develop Complementary Adaptive Token-level Contrastive\nDecoding to Mitigate Hallucinations in LVLMs (CATCH), based on the Information\nBottleneck theory. CATCH introduces Complementary Visual Decoupling (CVD) for\nvisual information separation, Non-Visual Screening (NVS) for hallucination\ndetection, and Adaptive Token-level Contrastive Decoding (ATCD) for\nhallucination mitigation. CATCH addresses issues related to visual defects that\ncause diminished fine-grained feature perception and cumulative hallucinations\nin open-ended scenarios. It is applicable to various visual question-answering\ntasks without requiring any specific data or prior knowledge, and generalizes\nrobustly to new tasks without additional training, opening new possibilities\nfor advancing LVLM in various challenging applications.",
      "tldr_zh": "该研究针对大型视觉语言模型（LVLMs）中普遍存在的幻觉问题，特别是视觉语言不对齐导致的视觉缺陷，提出了一种名为 CATCH 的方法。CATCH 包括 Complementary Visual Decoupling (CVD) 用于分离视觉信息、Non-Visual Screening (NVS) 用于检测幻觉，以及 Adaptive Token-level Contrastive Decoding (ATCD) 用于缓解幻觉，从而提升细粒度特征感知并减少累积幻觉。该方法无需特定数据或额外训练，即适用于各种视觉问答任务，并能泛化到新任务，为 LVLMs 在医疗和自动系统等关键领域的应用提供更可靠的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.12713v1",
      "published_date": "2024-11-19 18:27:31 UTC",
      "updated_date": "2024-11-19 18:27:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:58:37.840880"
    },
    {
      "arxiv_id": "2411.12712v1",
      "title": "Enhancing Multi-Class Disease Classification: Neoplasms, Cardiovascular, Nervous System, and Digestive Disorders Using Advanced LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Ahmed Akib Jawad Karim",
        "Muhammad Zawad Mahmud",
        "Samiha Islam",
        "Aznur Azam"
      ],
      "abstract": "In this research, we explored the improvement in terms of multi-class disease\nclassification via pre-trained language models over Medical-Abstracts-TC-Corpus\nthat spans five medical conditions. We excluded non-cancer conditions and\nexamined four specific diseases. We assessed four LLMs, BioBERT, XLNet, and\nBERT, as well as a novel base model (Last-BERT). BioBERT, which was pre-trained\non medical data, demonstrated superior performance in medical text\nclassification (97% accuracy). Surprisingly, XLNet followed closely (96%\naccuracy), demonstrating its generalizability across domains even though it was\nnot pre-trained on medical data. LastBERT, a custom model based on the lighter\nversion of BERT, also proved competitive with 87.10% accuracy (just under\nBERT's 89.33%). Our findings confirm the importance of specialized models such\nas BioBERT and also support impressions around more general solutions like\nXLNet and well-tuned transformer architectures with fewer parameters (in this\ncase, LastBERT) in medical domain tasks.",
      "tldr_zh": "本研究旨在使用先进的预训练语言模型（如BioBERT、XLNet和BERT）提升多类疾病分类，包括Neoplasms、Cardiovascular、Nervous System和Digestive Disorders，基于Medical-Abstracts-TC-Corpus数据集。\n他们评估了四种模型，结果显示BioBERT在医疗文本分类中表现出色，达到97%的准确率，而XLNet尽管未针对医疗预训练，也取得了96%的准确率。\nLast-BERT作为一种轻量级自定义模型，表现竞争性强（87.10%准确率），仅略低于BERT（89.33%）。\n总体而言，该研究强调了专业模型（如BioBERT）的优势，以及通用模型（如XLNet）和优化Transformer架构在医疗任务中的适用性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "7 Pages, 4 tables and 11 figures. Under review in a IEEE conference",
      "pdf_url": "http://arxiv.org/pdf/2411.12712v1",
      "published_date": "2024-11-19 18:27:25 UTC",
      "updated_date": "2024-11-19 18:27:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:58:50.385259"
    },
    {
      "arxiv_id": "2411.12701v3",
      "title": "When Backdoors Speak: Understanding LLM Backdoor Attacks Through Model-Generated Explanations",
      "title_zh": "当后门开口",
      "authors": [
        "Huaizhi Ge",
        "Yiming Li",
        "Qifan Wang",
        "Yongfeng Zhang",
        "Ruixiang Tang"
      ],
      "abstract": "Large Language Models (LLMs) are known to be vulnerable to backdoor attacks,\nwhere triggers embedded in poisoned samples can maliciously alter LLMs'\nbehaviors. In this paper, we move beyond attacking LLMs and instead examine\nbackdoor attacks through the novel lens of natural language explanations.\nSpecifically, we leverage LLMs' generative capabilities to produce\nhuman-readable explanations for their decisions, enabling direct comparisons\nbetween explanations for clean and poisoned samples. Our results show that\nbackdoored models produce coherent explanations for clean inputs but diverse\nand logically flawed explanations for poisoned data, a pattern consistent\nacross classification and generation tasks for different backdoor attacks.\nFurther analysis reveals key insights into the explanation generation process.\nAt the token level, explanation tokens associated with poisoned samples only\nappear in the final few transformer layers. At the sentence level, attention\ndynamics indicate that poisoned inputs shift attention away from the original\ninput context during explanation generation. These findings enhance our\nunderstanding of backdoor mechanisms in LLMs and present a promising framework\nfor detecting vulnerabilities through explainability.",
      "tldr_zh": "本研究通过模型生成的自然语言解释，探讨了大型语言模型 (LLMs) 后门攻击的机制。研究者利用 LLMs 的生成能力，比较了干净样本和中毒样本的解释，发现后门模型对干净输入产生连贯解释，但对中毒数据生成多样且逻辑有缺陷的解释，这一模式在分类和生成任务中均一致。进一步分析显示，在 token 级别，中毒样本的解释 token 仅出现在 transformer 的最后几层；在 sentence 级别，注意力动态会使中毒输入转移注意力，从而揭示后门攻击的内在机制。该方法为检测 LLM 漏洞提供了有前景的解释性框架。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.12701v3",
      "published_date": "2024-11-19 18:11:36 UTC",
      "updated_date": "2025-02-16 03:19:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:59:01.913829"
    },
    {
      "arxiv_id": "2411.12697v2",
      "title": "Attribute Inference Attacks for Federated Regression Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Francesco Diana",
        "Othmane Marfoq",
        "Chuan Xu",
        "Giovanni Neglia",
        "Frédéric Giroire",
        "Eoin Thomas"
      ],
      "abstract": "Federated Learning (FL) enables multiple clients, such as mobile phones and\nIoT devices, to collaboratively train a global machine learning model while\nkeeping their data localized. However, recent studies have revealed that the\ntraining phase of FL is vulnerable to reconstruction attacks, such as attribute\ninference attacks (AIA), where adversaries exploit exchanged messages and\nauxiliary public information to uncover sensitive attributes of targeted\nclients. While these attacks have been extensively studied in the context of\nclassification tasks, their impact on regression tasks remains largely\nunexplored. In this paper, we address this gap by proposing novel model-based\nAIAs specifically designed for regression tasks in FL environments. Our\napproach considers scenarios where adversaries can either eavesdrop on\nexchanged messages or directly interfere with the training process. We\nbenchmark our proposed attacks against state-of-the-art methods using\nreal-world datasets. The results demonstrate a significant increase in\nreconstruction accuracy, particularly in heterogeneous client datasets, a\ncommon scenario in FL. The efficacy of our model-based AIAs makes them better\ncandidates for empirically quantifying privacy leakage for federated regression\ntasks.",
      "tldr_zh": "该论文探讨了Federated Learning (FL)中回归任务的隐私风险，提出新型模型-based Attribute Inference Attacks (AIAs)，以填补现有研究对回归任务的不足。这些攻击针对攻击者窃听交换消息或直接干扰训练过程的场景，使用真实数据集进行benchmark测试，结果显示重建准确率显著提升，尤其在异质客户端数据集上。该方法为量化FL回归任务的隐私泄露提供了更有效的工具。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.12697v2",
      "published_date": "2024-11-19 18:06:06 UTC",
      "updated_date": "2025-04-16 12:29:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:59:14.088734"
    },
    {
      "arxiv_id": "2411.15197v1",
      "title": "K-means Derived Unsupervised Feature Selection using Improved ADMM",
      "title_zh": "基于 K-means 的无监督特征选择方法使用改进的 AD",
      "authors": [
        "Ziheng Sun",
        "Chris Ding",
        "Jicong Fan"
      ],
      "abstract": "Feature selection is important for high-dimensional data analysis and is\nnon-trivial in unsupervised learning problems such as dimensionality reduction\nand clustering. The goal of unsupervised feature selection is finding a subset\nof features such that the data points from different clusters are well\nseparated. This paper presents a novel method called K-means Derived\nUnsupervised Feature Selection (K-means UFS). Unlike most existing spectral\nanalysis based unsupervised feature selection methods, we select features using\nthe objective of K-means. We develop an alternating direction method of\nmultipliers (ADMM) to solve the NP-hard optimization problem of our K-means UFS\nmodel. Extensive experiments on real datasets show that our K-means UFS is more\neffective than the baselines in selecting features for clustering.",
      "tldr_zh": "本论文提出了一种名为 K-means Derived Unsupervised Feature Selection (K-means UFS) 的新方法，用于高维数据分析中的无监督特征选择，其目标是通过 K-means 的优化目标来选择特征子集，从而更好地分离不同聚类的样本点。不同于传统的基于谱分析的方法，该方法采用改进的 Alternating Direction Method of Multipliers (ADMM) 算法来解决该 NP-hard 优化问题。实验结果显示，在真实数据集上，K-means UFS 在聚类任务中比基线方法更有效。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.15197v1",
      "published_date": "2024-11-19 18:05:02 UTC",
      "updated_date": "2024-11-19 18:05:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:59:26.038069"
    },
    {
      "arxiv_id": "2411.12593v3",
      "title": "AdaCM$^2$: On Understanding Extremely Long-Term Video with Adaptive Cross-Modality Memory Reduction",
      "title_zh": "翻译失败",
      "authors": [
        "Yuanbin Man",
        "Ying Huang",
        "Chengming Zhang",
        "Bingzhe Li",
        "Wei Niu",
        "Miao Yin"
      ],
      "abstract": "The advancements in large language models (LLMs) have propelled the\nimprovement of video understanding tasks by incorporating LLMs with visual\nmodels. However, most existing LLM-based models (e.g., VideoLLaMA, VideoChat)\nare constrained to processing short-duration videos. Recent attempts to\nunderstand long-term videos by extracting and compressing visual features into\na fixed memory size. Nevertheless, those methods leverage only visual modality\nto merge video tokens and overlook the correlation between visual and textual\nqueries, leading to difficulties in effectively handling complex\nquestion-answering tasks. To address the challenges of long videos and complex\nprompts, we propose AdaCM$^2$, which, for the first time, introduces an\nadaptive cross-modality memory reduction approach to video-text alignment in an\nauto-regressive manner on video streams. Our extensive experiments on various\nvideo understanding tasks, such as video captioning, video question answering,\nand video classification, demonstrate that AdaCM$^2$ achieves state-of-the-art\nperformance across multiple datasets while significantly reducing memory usage.\nNotably, it achieves a 4.5% improvement across multiple tasks in the LVU\ndataset with a GPU memory consumption reduction of up to 65%.",
      "tldr_zh": "该论文提出AdaCM²，一种自适应跨模态内存减少方法，旨在解决现有LLM-based模型（如VideoLLaMA和VideoChat）在处理极长视频时的限制，这些模型仅依赖视觉模态合并视频标记，而忽略了视觉和文本查询的相关性。AdaCM²首次以自回归方式实现视频-文本对齐，通过动态调整跨模态记忆来提升视频理解任务的效率。实验结果显示，该方法在视频字幕、视频问答和视频分类等任务上达到最先进性能，并在LVU数据集上实现多任务4.5%的改进，同时减少高达65%的GPU内存消耗。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2025 Highlight",
      "pdf_url": "http://arxiv.org/pdf/2411.12593v3",
      "published_date": "2024-11-19 18:04:13 UTC",
      "updated_date": "2025-04-04 17:58:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:59:37.938975"
    },
    {
      "arxiv_id": "2411.12685v1",
      "title": "Enhanced Sign Language Translation between American Sign Language (ASL) and Indian Sign Language (ISL) Using LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Malay Kumar",
        "S. Sarvajit Visagan",
        "Tanish Sarang Mahajan",
        "Anisha Natarajan"
      ],
      "abstract": "We have come up with a research that hopes to provide a bridge between the\nusers of American Sign Language and the users of spoken language and Indian\nSign Language (ISL). The research enabled us to create a novel framework that\nwe have developed for Learner Systems. Leveraging art of Large models to create\nkey features including: - Real-time translation between these two sign\nlanguages in an efficient manner. Making LLM's capability available for\nseamless translations to ISL. Here is the full study showing its implementation\nin this paper. The core of the system is a sophisticated pipeline that begins\nwith reclassification and recognition of ASL gestures based on a strong Random\nForest Classifier. By recognizing the ASL, it is translated into text which can\nbe more easily processed. Highly evolved natural language NLP (Natural Language\nProcessing) techniques come in handy as they play a role in our LLM integration\nwhere you then use LLMs to be able to convert the ASL text to ISL which\nprovides you with the intent of sentence or phrase. The final step is to\nsynthesize the translated text back into ISL gestures, creating an end-to-end\ntranslation experience using RIFE-Net. This framework is tasked with key\nchallenges such as automatically dealing with gesture variability and\novercoming the linguistic differences between ASL and ISL. By automating the\ntranslation process, we hope to vastly improve accessibility for sign language\nusers. No longer will the communication gap between ASL and ISL create\nbarriers; this totally cool innovation aims to bring our communities closer\ntogether. And we believe, with full confidence in our framework, that we're\nable to apply the same principles across a wide variety of sign language\ndialects.",
      "tldr_zh": "本文提出了一种使用大型语言模型 (LLMs) 的新型框架，实现 American Sign Language (ASL) 和 Indian Sign Language (ISL) 之间的实时翻译，提高了手语用户的可访问性。该框架的核心流程包括使用 Random Forest Classifier 识别 ASL 手势、将手势转换为文本并通过 NLP 和 LLMs 进行语言转换，最后利用 RIFE-Net 合成 ISL 手势，以自动处理手势变异性和语言差异。实验结果表明，该系统能有效缩小 ASL 和 ISL 之间的沟通差距，并具有扩展到其他手语方言的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.12685v1",
      "published_date": "2024-11-19 17:45:12 UTC",
      "updated_date": "2024-11-19 17:45:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T01:59:50.448262"
    },
    {
      "arxiv_id": "2411.17715v1",
      "title": "Hybrid Quantum Deep Learning Model for Emotion Detection using raw EEG Signal Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Ali Asgar Chandanwala",
        "Srutakirti Bhowmik",
        "Parna Chaudhury",
        "Sheena Christabel Pravin"
      ],
      "abstract": "Applications in behavioural research, human-computer interaction, and mental\nhealth depend on the ability to recognize emotions. In order to improve the\naccuracy of emotion recognition using electroencephalography (EEG) data, this\nwork presents a hybrid quantum deep learning technique. Conventional EEG-based\nemotion recognition techniques are limited by noise and high-dimensional data\ncomplexity, which make feature extraction difficult. To tackle these issues,\nour method combines traditional deep learning classification with\nquantum-enhanced feature extraction. To identify important brain wave patterns,\nBandpass filtering and Welch method are used as preprocessing techniques on EEG\ndata. Intricate inter-band interactions that are essential for determining\nemotional states are captured by mapping frequency band power attributes\n(delta, theta, alpha, and beta) to quantum representations. Entanglement and\nrotation gates are used in a hybrid quantum circuit to maximize the model's\nsensitivity to EEG patterns associated with different emotions. Promising\nresults from evaluation on a test dataset indicate the model's potential for\naccurate emotion recognition. The model will be extended for real-time\napplications and multi-class categorization in future study, which could\nimprove EEG-based mental health screening instruments. This method offers a\npromising tool for applications in adaptive human-computer systems and mental\nhealth monitoring by showcasing the possibilities of fusing traditional deep\nlearning with quantum processing for reliable, scalable emotion recognition.",
      "tldr_zh": "本文提出了一种Hybrid Quantum Deep Learning模型，用于基于原始EEG信号的情感检测，旨在解决传统方法在噪声和高维数据复杂性下的特征提取难题。该模型结合传统深度学习分类与量子增强特征提取，通过Bandpass filtering和Welch method预处理EEG数据，并将频率带功率属性（delta, theta, alpha, beta）映射到量子表示中，利用Entanglement和rotation gates增强对情绪相关脑波模式的敏感性。实验结果显示，该模型在测试数据集上表现出色，准确性显著提升，为EEG-based心理健康筛查和自适应人机交互提供了可靠工具。未来工作将扩展到实时应用和多类分类。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.17715v1",
      "published_date": "2024-11-19 17:44:04 UTC",
      "updated_date": "2024-11-19 17:44:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:00:02.538283"
    },
    {
      "arxiv_id": "2411.12681v1",
      "title": "AI Guided Early Screening of Cervical Cancer",
      "title_zh": "AI 引导的宫颈癌早期筛查",
      "authors": [
        "Dharanidharan S I",
        "Suhitha Renuka S V",
        "Ajishi Singh",
        "Sheena Christabel Pravin"
      ],
      "abstract": "In order to support the creation of reliable machine learning models for\nanomaly detection, this project focuses on preprocessing, enhancing, and\norganizing a medical imaging dataset. There are two classifications in the\ndataset: normal and abnormal, along with extra noise fluctuations. In order to\nimprove the photographs' quality, undesirable artifacts, including visible\nmedical equipment at the edges, were eliminated using central cropping.\nAdjusting the brightness and contrast was one of the additional preprocessing\nprocesses. Normalization was then performed to normalize the data. To make\nclassification jobs easier, the dataset was methodically handled by combining\nseveral image subsets into two primary categories: normal and pathological. To\nprovide a strong training set that adapts well to real-world situations,\nsophisticated picture preprocessing techniques were used, such as contrast\nenhancement and real-time augmentation (including rotations, zooms, and\nbrightness modifications). To guarantee efficient model evaluation, the data\nwas subsequently divided into training and testing subsets. In order to create\nprecise and effective machine learning models for medical anomaly detection,\nhigh-quality input data is ensured via this thorough approach. Because of the\nproject pipeline's flexible and scalable design, it can be easily integrated\nwith bigger clinical decision-support systems.",
      "tldr_zh": "本研究开发了一个AI引导的宫颈癌早期筛查系统，通过预处理和组织医疗图像数据集来支持机器学习模型的anomaly detection。关键方法包括使用central cropping去除不必要artifacts（如可见医疗设备）、调整brightness和contrast、进行normalization，以及应用contrast enhancement和real-time augmentation（如rotations、zooms和brightness modifications），以提升图像质量和模型适应性。数据集被分类为normal和pathological类别，并分割为训练和测试子集，确保模型在真实场景中的精确性和鲁棒性；该灵活、可扩展的pipeline可轻松集成到临床决策支持系统中。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.12681v1",
      "published_date": "2024-11-19 17:39:03 UTC",
      "updated_date": "2024-11-19 17:39:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:00:14.201858"
    },
    {
      "arxiv_id": "2411.12678v1",
      "title": "Deep Learning-Driven Heat Map Analysis for Evaluating thickness of Wounded Skin Layers",
      "title_zh": "深度学习驱动的热图分析用于评估受伤皮肤层的厚度",
      "authors": [
        "Devakumar GR",
        "JB Kaarthikeyan",
        "Dominic Immanuel T",
        "Sheena Christabel Pravin"
      ],
      "abstract": "Understanding the appropriate skin layer thickness in wounded sites is an\nimportant tool to move forward on wound healing practices and treatment\nprotocols. Methods to measure depth often are invasive and less specific. This\npaper introduces a novel method that is non-invasive with deep learning\ntechniques using classifying of skin layers that helps in measurement of wound\ndepth through heatmap analysis. A set of approximately 200 labeled images of\nskin allows five classes to be distinguished: scars, wounds, and healthy skin,\namong others. Each image has annotated key layers, namely the stratum cornetum,\nthe epidermis, and the dermis, in the software Roboflow. In the preliminary\nstage, the Heatmap generator VGG16 was used to enhance the visibility of tissue\nlayers, based upon which their annotated images were used to train ResNet18\nwith early stopping techniques. It ended up at a very high accuracy rate of\n97.67%. To do this, the comparison of the models ResNet18, VGG16, DenseNet121,\nand EfficientNet has been done where both EfficientNet and ResNet18 have\nattained accuracy rates of almost 95.35%. For further hyperparameter tuning,\nEfficientNet and ResNet18 were trained at six different learning rates to\ndetermine the best model configuration. It has been noted that the accuracy has\nhuge variations with different learning rates. In the case of EfficientNet, the\nmaximum achievable accuracy was 95.35% at the rate of 0.0001. The same was true\nfor ResNet18, which also attained its peak value of 95.35% at the same rate.\nThese facts indicate that the model can be applied and utilized in actual-time,\nnon-invasive wound assessment, which holds a great promise to improve clinical\ndiagnosis and treatment planning.",
      "tldr_zh": "本研究提出了一种非侵入性方法，使用Deep Learning技术通过Heat Map分析来评估伤口皮肤层的厚度，包括stratum corneum、epidermis和dermis等关键层。利用约200张标注图像训练模型，首先采用VGG16生成热图增强组织层可见性，然后使用ResNet18进行分类训练，达到了97.67%的准确率。模型比较显示，ResNet18和EfficientNet在0.0001学习率下均取得95.35%的峰值准确率，这为实时、非侵入性伤口评估提供了可靠工具，有望提升临床诊断和治疗规划。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.12678v1",
      "published_date": "2024-11-19 17:31:36 UTC",
      "updated_date": "2024-11-19 17:31:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:00:26.217706"
    },
    {
      "arxiv_id": "2411.12671v1",
      "title": "Neurosymbolic Graph Enrichment for Grounded World Models",
      "title_zh": "翻译失败",
      "authors": [
        "Stefano De Giorgis",
        "Aldo Gangemi",
        "Alessandro Russo"
      ],
      "abstract": "The development of artificial intelligence systems capable of understanding\nand reasoning about complex real-world scenarios is a significant challenge. In\nthis work we present a novel approach to enhance and exploit LLM reactive\ncapability to address complex problems and interpret deeply contextual\nreal-world meaning. We introduce a method and a tool for creating a multimodal,\nknowledge-augmented formal representation of meaning that combines the\nstrengths of large language models with structured semantic representations.\nOur method begins with an image input, utilizing state-of-the-art large\nlanguage models to generate a natural language description. This description is\nthen transformed into an Abstract Meaning Representation (AMR) graph, which is\nformalized and enriched with logical design patterns, and layered semantics\nderived from linguistic and factual knowledge bases. The resulting graph is\nthen fed back into the LLM to be extended with implicit knowledge activated by\ncomplex heuristic learning, including semantic implicatures, moral values,\nembodied cognition, and metaphorical representations. By bridging the gap\nbetween unstructured language models and formal semantic structures, our method\nopens new avenues for tackling intricate problems in natural language\nunderstanding and reasoning.",
      "tldr_zh": "本文提出了一种神经符号图丰富方法，用于增强大型语言模型（LLM）处理复杂真实世界场景的能力。方法从图像输入开始，利用LLM生成自然语言描述，并将其转化为Abstract Meaning Representation (AMR) 图，然后通过逻辑设计模式、层级语义以及语言和事实知识库进行丰富。接着，将丰富后的图反馈给LLM，以添加隐含知识，如语义暗示、道德价值观、具身认知和比喻表示。这种方法桥接了无结构语言模型与正式语义结构之间的差距，为自然语言理解和推理等复杂问题提供了新途径。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.ET"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.12671v1",
      "published_date": "2024-11-19 17:23:55 UTC",
      "updated_date": "2024-11-19 17:23:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:00:37.677033"
    },
    {
      "arxiv_id": "2411.12663v1",
      "title": "PoM: Efficient Image and Video Generation with the Polynomial Mixer",
      "title_zh": "翻译失败",
      "authors": [
        "David Picard",
        "Nicolas Dufour"
      ],
      "abstract": "Diffusion models based on Multi-Head Attention (MHA) have become ubiquitous\nto generate high quality images and videos. However, encoding an image or a\nvideo as a sequence of patches results in costly attention patterns, as the\nrequirements both in terms of memory and compute grow quadratically. To\nalleviate this problem, we propose a drop-in replacement for MHA called the\nPolynomial Mixer (PoM) that has the benefit of encoding the entire sequence\ninto an explicit state. PoM has a linear complexity with respect to the number\nof tokens. This explicit state also allows us to generate frames in a\nsequential fashion, minimizing memory and compute requirement, while still\nbeing able to train in parallel. We show the Polynomial Mixer is a universal\nsequence-to-sequence approximator, just like regular MHA. We adapt several\nDiffusion Transformers (DiT) for generating images and videos with PoM\nreplacing MHA, and we obtain high quality samples while using less\ncomputational resources. The code is available at\nhttps://github.com/davidpicard/HoMM.",
      "tldr_zh": "这篇论文针对基于 Multi-Head Attention (MHA) 的扩散模型在图像和视频生成中存在的计算和内存需求呈二次方增长的问题，提出了一种高效替代模块 Polynomial Mixer (PoM)。PoM 通过将序列编码为显式状态，实现线性复杂度，并支持顺序帧生成，同时保持并行训练能力。实验证明，PoM 作为通用序列到序列逼近器，能在 Diffusion Transformers (DiT) 中替换 MHA，生成高质量样本的同时显著减少计算资源。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.12663v1",
      "published_date": "2024-11-19 17:16:31 UTC",
      "updated_date": "2024-11-19 17:16:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:02:43.331816"
    },
    {
      "arxiv_id": "2411.12650v1",
      "title": "Optimizing Airline Reservation Systems with Edge-Enabled Microservices: A Framework for Real-Time Data Processing and Enhanced User Responsiveness",
      "title_zh": "翻译失败",
      "authors": [
        "Biman Barua",
        "M. Shamim Kaiser"
      ],
      "abstract": "The growing complexity of the operations of airline reservations requires a\nsmart solution for the adoption of novel approaches to the development of\nquick, efficient, and adaptive reservation systems. This paper outlines in\ndetail a conceptual framework for the implementation of edge computing\nmicroservices in order to address the shortcomings of traditional centralized\narchitectures. Specifically, as edge computing allows for certain activities\nsuch as seat inventory checks, booking processes and even confirmation to be\ndone nearer to the user, thus lessening the overall response time and improving\nthe performance of the system. In addition, the framework value should include\nachieving the high performance of the system such as low latency, high\nthroughput and higher user experience. The major design components include\ndeployed distributed computing microservices orchestrated by Kubernetes,\nreal-time message processing system with Kafka and its elastic scaling. Other\noperational components include Prometheus and Grafana, which are used to\nmonitor and manage resources, ensuring that all operational processes are\noptimized. Although this research focuses on a design and theoretical scheming\nof the framework, its use is foreseen to be more advantageous in facilitating a\ntransform in the provision of services in the airline industry by improving\ncustomers' satisfaction, providing infrastructure which is cheap to install and\nefficiently supporting technology changes such as artificial intelligence and\ninternet of things embedded systems. This research addresses the increasing\ndemand for new technologies with modern well-distributed and real-time-centric\nsystems and also provides a basis for future case implementation and testing.\nAs such, the proposed architecture offers a market-ready, extensible solution\nto the problems posed by existing airline reservation systems .",
      "tldr_zh": "这篇论文提出一个基于 edge computing 和 microservices 的框架，用于优化航空预订系统，实现实时数据处理和提升用户响应性，以解决传统集中式架构的延迟问题。框架的关键组件包括使用 Kubernetes 编排分布式微服务、Kafka 处理实时消息，以及 Prometheus 和 Grafana 进行资源监控和优化，旨在实现低延迟、高吞吐量和更好的用户体验。该设计理论上能提高客户满意度，支持 AI 和 IoT 等技术的整合，并为航空业提供一个可扩展的、可实际部署的解决方案。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CE",
        "cs.CL",
        "cs.DC"
      ],
      "primary_category": "cs.SE",
      "comment": "22 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.12650v1",
      "published_date": "2024-11-19 16:58:15 UTC",
      "updated_date": "2024-11-19 16:58:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:01:02.481945"
    },
    {
      "arxiv_id": "2411.12644v2",
      "title": "CodeXEmbed: A Generalist Embedding Model Family for Multiligual and Multi-task Code Retrieval",
      "title_zh": "CodeXEmbed：一种通用嵌入模型家族，用于多语言和多任务代码检索",
      "authors": [
        "Ye Liu",
        "Rui Meng",
        "Shafiq Joty",
        "Silvio Savarese",
        "Caiming Xiong",
        "Yingbo Zhou",
        "Semih Yavuz"
      ],
      "abstract": "Despite the success of text retrieval in many NLP tasks, code retrieval\nremains a largely underexplored area. Most text retrieval systems are tailored\nfor natural language queries, often neglecting the specific challenges of\nretrieving code. This gap leaves existing models unable to effectively capture\nthe diversity of programming languages and tasks across different domains,\nhighlighting the need for more focused research in code retrieval. To address\nthis, we introduce CodeXEmbed, a family of large-scale code embedding models\nranging from 400M to 7B parameters. Our novel training pipeline unifies\nmultiple programming languages and transforms various code-related tasks into a\ncommon retrieval framework, enhancing model generalizability and retrieval\nperformance. Our 7B model sets a new state-of-the-art (SOTA) in code retrieval,\noutperforming the previous leading model, Voyage-Code, by over 20% on CoIR\nbenchmark. In addition to excelling in code retrieval, our models demonstrate\ncompetitive performance on the widely adopted BeIR text retrieval benchmark,\noffering versatility across domains. Experimental results demonstrate that\nimproving retrieval performance significantly enhances end-to-end\nRetrieval-Augmented Generation (RAG) performance for code-related tasks.",
      "tldr_zh": "本研究引入了 CodeXEmbed，一系列从 400M 到 7B 参数的代码嵌入模型家族，旨在解决现有模型在多语言和多任务代码检索中的不足，如编程语言多样性和任务复杂性。\n该模型采用新型训练管道，将多种编程语言和代码相关任务统一到一个共同的检索框架中，提升了模型的泛化性和性能。\n在 CoIR 基准上，CodeXEmbed 的 7B 模型超越了领先模型 Voyage-Code 超过 20%，并在 BeIR 文本检索基准上展现出竞争力。\n实验证明，提高代码检索性能显著提升了端到端 Retrieval-Augmented Generation (RAG) 任务的整体表现。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.12644v2",
      "published_date": "2024-11-19 16:54:45 UTC",
      "updated_date": "2024-11-24 18:52:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:01:15.146992"
    },
    {
      "arxiv_id": "2411.12643v2",
      "title": "DLBacktrace: A Model Agnostic Explainability for any Deep Learning Models",
      "title_zh": "翻译失败",
      "authors": [
        "Vinay Kumar Sankarapu",
        "Chintan Chitroda",
        "Yashwardhan Rathore",
        "Neeraj Kumar Singh",
        "Pratinav Seth"
      ],
      "abstract": "The rapid growth of AI has led to more complex deep learning models, often\noperating as opaque \"black boxes\" with limited transparency in their\ndecision-making. This lack of interpretability poses challenges, especially in\nhigh-stakes applications where understanding model output is crucial. This work\nhighlights the importance of interpretability in fostering trust,\naccountability, and responsible deployment. To address these challenges, we\nintroduce DLBacktrace, a novel, model-agnostic technique designed to provide\nclear insights into deep learning model decisions across a wide range of\ndomains and architectures, including MLPs, CNNs, and Transformer-based LLM\nmodels. We present a comprehensive overview of DLBacktrace and benchmark its\nperformance against established interpretability methods such as SHAP, LIME,\nand GradCAM. Our results demonstrate that DLBacktrace effectively enhances\nunderstanding of model behavior across diverse tasks. DLBacktrace is compatible\nwith models developed in both PyTorch and TensorFlow, supporting architectures\nsuch as BERT, ResNet, U-Net, and custom DNNs for tabular data. The library is\nopen-sourced and available at https://github.com/AryaXAI/DLBacktrace .",
      "tldr_zh": "该研究强调了深度学习模型作为“黑盒”的不透明性问题，这在高风险应用中影响信任和责任。论文引入 DLBacktrace，一种新型模型无关的解释性技术，能够为 MLPs、CNNs 和 Transformer-based LLM 等各种架构提供清晰的决策洞见。实验结果显示，DLBacktrace 在基准测试中优于 SHAP、LIME 和 GradCAM 等方法，提升了对模型行为的理解，且该库兼容 PyTorch 和 TensorFlow，并已开源在 GitHub（https://github.com/AryaXAI/DLBacktrace）。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.12643v2",
      "published_date": "2024-11-19 16:54:30 UTC",
      "updated_date": "2025-02-04 06:55:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:01:26.655886"
    },
    {
      "arxiv_id": "2411.12633v2",
      "title": "Instant Policy: In-Context Imitation Learning via Graph Diffusion",
      "title_zh": "翻译失败",
      "authors": [
        "Vitalis Vosylius",
        "Edward Johns"
      ],
      "abstract": "Following the impressive capabilities of in-context learning with large\ntransformers, In-Context Imitation Learning (ICIL) is a promising opportunity\nfor robotics. We introduce Instant Policy, which learns new tasks instantly\n(without further training) from just one or two demonstrations, achieving ICIL\nthrough two key components. First, we introduce inductive biases through a\ngraph representation and model ICIL as a graph generation problem with a\nlearned diffusion process, enabling structured reasoning over demonstrations,\nobservations, and actions. Second, we show that such a model can be trained\nusing pseudo-demonstrations - arbitrary trajectories generated in simulation -\nas a virtually infinite pool of training data. Simulated and real experiments\nshow that Instant Policy enables rapid learning of various everyday robot\ntasks. We also show how it can serve as a foundation for cross-embodiment and\nzero-shot transfer to language-defined tasks. Code and videos are available at\nhttps://www.robot-learning.uk/instant-policy.",
      "tldr_zh": "该研究提出Instant Policy方法，实现In-Context Imitation Learning (ICIL)，允许机器人从一两个演示中即时学习新任务，而无需额外训练。核心机制包括使用图表示将ICIL建模为图生成问题，并通过学习扩散过程(graph diffusion)进行结构化推理，处理演示、观察和动作。模型利用伪演示(pseudo-demonstrations)——在模拟中生成的任意轨迹——作为无限训练数据源，以提升泛化能力。实验结果显示，Instant Policy在模拟和真实环境中快速掌握各种日常机器人任务，并支持跨机器人平台和零样本转移到语言定义的任务。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Code and videos are available on our project webpage at\n  https://www.robot-learning.uk/instant-policy",
      "pdf_url": "http://arxiv.org/pdf/2411.12633v2",
      "published_date": "2024-11-19 16:45:52 UTC",
      "updated_date": "2025-04-25 15:22:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:02:53.803822"
    },
    {
      "arxiv_id": "2411.12629v1",
      "title": "Estimating Dark Matter Halo Masses in Simulated Galaxy Clusters with Graph Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Nikhil Garuda",
        "John F. Wu",
        "Dylan Nelson",
        "Annalisa Pillepich"
      ],
      "abstract": "Galaxies grow and evolve in dark matter halos. Because dark matter is not\nvisible, galaxies' halo masses ($\\rm{M}_{\\rm{halo}}$) must be inferred\nindirectly. We present a graph neural network (GNN) model for predicting\n$\\rm{M}_{\\rm{halo}}$ from stellar mass ($\\rm{M}_{*}$) in simulated galaxy\nclusters using data from the IllustrisTNG simulation suite. Unlike traditional\nmachine learning models like random forests, our GNN captures the\ninformation-rich substructure of galaxy clusters by using spatial and kinematic\nrelationships between galaxy neighbour. A GNN model trained on the TNG-Cluster\ndataset and independently tested on the TNG300 simulation achieves superior\npredictive performance compared to other baseline models we tested. Future work\nwill extend this approach to different simulations and real observational\ndatasets to further validate the GNN model's ability to generalise.",
      "tldr_zh": "该研究提出了一种使用图神经网络 (GNN) 的模型，从模拟星系团的恒星质量 (M_*) 间接估计暗物质晕质量 (M_halo)，利用 IllustrisTNG 模拟数据。不同于传统机器学习模型如随机森林，GNN 通过捕捉星系邻居之间的空间和运动学关系，处理星系团的复杂子结构。在 TNG-Cluster 数据集上训练并在 TNG300 模拟上独立测试后，该模型比基线模型表现出优越的预测性能。未来工作将扩展此方法到其他模拟和真实观测数据，以进一步验证其泛化能力。",
      "categories": [
        "astro-ph.GA",
        "astro-ph.CO",
        "astro-ph.IM",
        "cs.AI"
      ],
      "primary_category": "astro-ph.GA",
      "comment": "9 pages, 4 figures, accepted at the NeurIPS ML4PS 2024 workshop",
      "pdf_url": "http://arxiv.org/pdf/2411.12629v1",
      "published_date": "2024-11-19 16:40:17 UTC",
      "updated_date": "2024-11-19 16:40:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:03:08.640415"
    },
    {
      "arxiv_id": "2411.15195v1",
      "title": "Graph Neural Network-Based Entity Extraction and Relationship Reasoning in Complex Knowledge Graphs",
      "title_zh": "基于图神经网络的实体提取和关系推理在复杂知识图谱中",
      "authors": [
        "Junliang Du",
        "Guiran Liu",
        "Jia Gao",
        "Xiaoxuan Liao",
        "Jiacheng Hu",
        "Linxiao Wu"
      ],
      "abstract": "This study proposed a knowledge graph entity extraction and relationship\nreasoning algorithm based on a graph neural network, using a graph\nconvolutional network and graph attention network to model the complex\nstructure in the knowledge graph. By building an end-to-end joint model, this\npaper achieves efficient recognition and reasoning of entities and\nrelationships. In the experiment, this paper compared the model with a variety\nof deep learning algorithms and verified its superiority through indicators\nsuch as AUC, recall rate, precision rate, and F1 value. The experimental\nresults show that the model proposed in this paper performs well in all\nindicators, especially in complex knowledge graphs, it has stronger\ngeneralization ability and stability. This provides strong support for further\nresearch on knowledge graphs and also demonstrates the application potential of\ngraph neural networks in entity extraction and relationship reasoning.",
      "tldr_zh": "这篇论文提出了一种基于 Graph Neural Network 的知识图谱实体提取和关系推理算法，使用 Graph Convolutional Network 和 Graph Attention Network 来建模复杂知识图谱的结构，并构建端到端的联合模型以实现高效的实体和关系识别。实验中，该模型与多种深度学习算法比较，在 AUC、recall rate、precision rate 和 F1 value 等指标上表现出色，尤其在复杂知识图谱中显示出更强的泛化能力和稳定性。该方法为知识图谱的进一步研究提供了有力支持，并突显了 Graph Neural Network 在实体提取和关系推理中的应用潜力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.15195v1",
      "published_date": "2024-11-19 16:23:49 UTC",
      "updated_date": "2024-11-19 16:23:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:03:19.004938"
    },
    {
      "arxiv_id": "2411.12603v2",
      "title": "STREAM: A Universal State-Space Model for Sparse Geometric Data",
      "title_zh": "STREAM：一种通用的状态空间模型用于稀疏几何数据",
      "authors": [
        "Mark Schöne",
        "Yash Bhisikar",
        "Karan Bania",
        "Khaleelulla Khan Nazeer",
        "Christian Mayr",
        "Anand Subramoney",
        "David Kappel"
      ],
      "abstract": "Handling sparse and unstructured geometric data, such as point clouds or\nevent-based vision, is a pressing challenge in the field of machine vision.\nRecently, sequence models such as Transformers and state-space models entered\nthe domain of geometric data. These methods require specialized preprocessing\nto create a sequential view of a set of points. Furthermore, prior works\ninvolving sequence models iterate geometric data with either uniform or learned\nstep sizes, implicitly relying on the model to infer the underlying geometric\nstructure. In this work, we propose to encode geometric structure explicitly\ninto the parameterization of a state-space model. State-space models are based\non linear dynamics governed by a one-dimensional variable such as time or a\nspatial coordinate. We exploit this dynamic variable to inject relative\ndifferences of coordinates into the step size of the state-space model. The\nresulting geometric operation computes interactions between all pairs of N\npoints in O(N) steps. Our model deploys the Mamba selective state-space model\nwith a modified CUDA kernel to efficiently map sparse geometric data to modern\nhardware. The resulting sequence model, which we call STREAM, achieves\ncompetitive results on a range of benchmarks from point-cloud classification to\nevent-based vision and audio classification. STREAM demonstrates a powerful\ninductive bias for sparse geometric data by improving the PointMamba baseline\nwhen trained from scratch on the ModelNet40 and ScanObjectNN point cloud\nanalysis datasets. It further achieves, for the first time, 100% test accuracy\non all 11 classes of the DVS128 Gestures dataset.",
      "tldr_zh": "本研究针对处理稀疏几何数据（如 point clouds 或 event-based vision）的机器视觉挑战，提出了一种通用的 state-space 模型 STREAM。该模型通过显式编码几何结构，将坐标的相对差异注入到 state-space 模型的步长中，实现 O(N) 步骤计算 N 点之间的所有互动，并基于 Mamba selective state-space 模型修改 CUDA 内核以高效处理数据。实验结果显示，STREAM 在点云分类、event-based vision 和音频分类基准上表现出色，超越 PointMamba 基线，并在 ModelNet40、ScanObjectNN 数据集上从零训练取得提升，同时在 DVS128 Gestures 数据集上首次实现 100% 测试准确率。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.NE"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.12603v2",
      "published_date": "2024-11-19 16:06:32 UTC",
      "updated_date": "2024-11-22 11:21:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:03:31.681738"
    },
    {
      "arxiv_id": "2411.12600v3",
      "title": "Provable unlearning in topic modeling and downstream tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Stanley Wei",
        "Sadhika Malladi",
        "Sanjeev Arora",
        "Amartya Sanyal"
      ],
      "abstract": "Machine unlearning algorithms are increasingly important as legal concerns\narise around the provenance of training data, but verifying the success of\nunlearning is often difficult. Provable guarantees for unlearning are often\nlimited to supervised learning settings. In this paper, we provide the first\ntheoretical guarantees for unlearning in the pre-training and fine-tuning\nparadigm by studying topic models, simple bag-of-words language models that can\nbe adapted to solve downstream tasks like retrieval and classification. First,\nwe design a provably effective unlearning algorithm for topic models that\nincurs a computational overhead independent of the size of the original\ndataset. Our analysis additionally quantifies the deletion capacity of the\nmodel -- i.e., the number of examples that can be unlearned without incurring a\nsignificant cost in model performance. Finally, we formally extend our analyses\nto account for adaptation to a given downstream task. In particular, we design\nan efficient algorithm to perform unlearning after fine-tuning the topic model\nvia a linear head. Notably, we show that it is easier to unlearn pre-training\ndata from models that have been fine-tuned to a particular task, and one can\nunlearn this data without modifying the base model.",
      "tldr_zh": "这篇论文首次为主题模型(topic models)提供了可证明的unlearning算法，解决了训练数据删除在预训练和下游任务（如检索和分类）中的挑战。该算法计算开销独立于原始数据集大小，并量化了模型的删除容量，即可unlearning的样本数而不显著影响性能。此外，论文扩展分析到fine-tuning场景，设计了高效算法，使unlearning预训练数据变得更容易，且无需修改基模型。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.12600v3",
      "published_date": "2024-11-19 16:04:31 UTC",
      "updated_date": "2025-04-20 15:34:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:05:36.241745"
    },
    {
      "arxiv_id": "2411.12587v1",
      "title": "Whisper Finetuning on Nepali Language",
      "title_zh": "翻译失败",
      "authors": [
        "Sanjay Rijal",
        "Shital Adhikari",
        "Manish Dahal",
        "Manish Awale",
        "Vaghawan Ojha"
      ],
      "abstract": "Despite the growing advancements in Automatic Speech Recognition (ASR)\nmodels, the development of robust models for underrepresented languages, such\nas Nepali, remains a challenge. This research focuses on making an exhaustive\nand generalized dataset followed by fine-tuning OpenAI's Whisper models of\ndifferent sizes to improve transcription (speech-to-text) accuracy for the\nNepali language. We leverage publicly available ASR datasets and self-recorded\ncustom datasets with a diverse range of accents, dialects, and speaking styles\nfurther enriched through augmentation. Our experimental results demonstrate\nthat fine-tuning Whisper models on our curated custom dataset substantially\nreduces the Word Error Rate (WER) across all model sizes attributed to larger\ndata variations in terms of speaker's age, gender, and sentiment, acoustic\nenvironment, dialect, denser audio segments (15-30 seconds) that are more\ncompatible with Whisper's input, and manual curation of audios and\ntranscriptions. Notably, our approach outperforms Whisper's baseline models\ntrained on Fleur's dataset, achieving WER reductions of up to 36.2% on the\nsmall and 23.8% on medium models. Furthermore, we show that data augmentation\nplays a significant role in enhancing model robustness. Our approach underlines\nthe importance of dataset quality, variation, and augmentation in the\nadaptation of state-of-the-art models to underrepresented languages for\ndeveloping accurate ASR systems.",
      "tldr_zh": "这篇论文针对尼泊尔语等 underrepresented 语言的 Automatic Speech Recognition (ASR) 模型改进，创建了一个详尽且多样化的数据集，包括公开数据和自录制的自定义音频，并通过数据增强技术丰富了口音、方言和说话风格。研究者对不同大小的 OpenAI Whisper 模型进行了微调，实验结果显示，该方法显著降低了 Word Error Rate (WER)，在 small 模型上减少了 36.2%，在 medium 模型上减少了 23.8%，并优于基于 Fleur 数据集的基线模型。总体上，该工作强调了数据集质量、变化和增强在适应 underrepresented 语言的 ASR 系统中的关键作用，为开发更准确的语音识别技术提供了指导。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.12587v1",
      "published_date": "2024-11-19 15:55:56 UTC",
      "updated_date": "2024-11-19 15:55:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:05:56.375914"
    },
    {
      "arxiv_id": "2412.04476v3",
      "title": "The Moral Mind(s) of Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Avner Seror"
      ],
      "abstract": "As large language models (LLMs) increasingly participate in tasks with\nethical and societal stakes, a critical question arises: do they exhibit an\nemergent \"moral mind\" - a consistent structure of moral preferences guiding\ntheir decisions - and to what extent is this structure shared across models? To\ninvestigate this, we applied tools from revealed preference theory to nearly 40\nleading LLMs, presenting each with many structured moral dilemmas spanning five\nfoundational dimensions of ethical reasoning. Using a probabilistic rationality\ntest, we found that at least one model from each major provider exhibited\nbehavior consistent with approximately stable moral preferences, acting as if\nguided by an underlying utility function. We then estimated these utility\nfunctions and found that most models cluster around neutral moral stances. To\nfurther characterize heterogeneity, we employed a non-parametric permutation\napproach, constructing a probabilistic similarity network based on revealed\npreference patterns. The results reveal a shared core in LLMs' moral reasoning,\nbut also meaningful variation: some models show flexible reasoning across\nperspectives, while others adhere to more rigid ethical profiles. These\nfindings provide a new empirical lens for evaluating moral consistency in LLMs\nand offer a framework for benchmarking ethical alignment across AI systems.",
      "tldr_zh": "本研究探讨大型语言模型 (LLMs) 是否具有新兴的“道德心智”，即稳定的道德偏好结构，以及这种结构在不同模型间的共享程度。研究者应用揭示偏好理论 (revealed preference theory) 对近 40 个领先 LLMs 进行测试，使用结构化的道德困境覆盖五个道德推理维度，并通过概率理性测试评估模型行为。结果显示，每个主要提供商的至少一个模型表现出与底层效用函数 (utility function) 一致的稳定道德偏好，大多数模型趋向中性道德立场，但也存在显著变异，如某些模型在不同视角下更灵活，而其他则更严格。总体而言，此框架为评估 LLMs 的道德一致性和基准测试 AI 系统的伦理对齐提供了新的实证工具。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.04476v3",
      "published_date": "2024-11-19 15:40:16 UTC",
      "updated_date": "2025-04-25 15:47:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:04:06.869663"
    },
    {
      "arxiv_id": "2411.12571v1",
      "title": "Large Language Models for Combinatorial Optimization of Design Structure Matrix",
      "title_zh": "大语言模型用于设计结构矩阵的组合优化",
      "authors": [
        "Shuo Jiang",
        "Min Xie",
        "Jianxi Luo"
      ],
      "abstract": "Combinatorial optimization (CO) is essential for improving efficiency and\nperformance in engineering applications. As complexity increases with larger\nproblem sizes and more intricate dependencies, identifying the optimal solution\nbecome challenging. When it comes to real-world engineering problems,\nalgorithms based on pure mathematical reasoning are limited and incapable to\ncapture the contextual nuances necessary for optimization. This study explores\nthe potential of Large Language Models (LLMs) in solving engineering CO\nproblems by leveraging their reasoning power and contextual knowledge. We\npropose a novel LLM-based framework that integrates network topology and domain\nknowledge to optimize the sequencing of Design Structure Matrix (DSM)-a common\nCO problem. Our experiments on various DSM cases demonstrate that the proposed\nmethod achieves faster convergence and higher solution quality than benchmark\nmethods. Moreover, results show that incorporating contextual domain knowledge\nsignificantly improves performance despite the choice of LLMs. These findings\nhighlight the potential of LLMs in tackling complex real-world CO problems by\ncombining semantic and mathematical reasoning. This approach paves the way for\na new paradigm in in real-world combinatorial optimization.",
      "tldr_zh": "这篇论文探讨了 Large Language Models (LLMs) 在 Combinatorial Optimization (CO) 问题中的应用，特别是针对工程领域的 Design Structure Matrix (DSM) 优化。研究提出一个新框架，将网络拓扑和领域知识整合到 LLMs 的推理过程中，以提高 DSM 排序的效率和解决方案质量。实验结果显示，该方法在各种 DSM 案例中比基准算法更快收敛并获得更高性能，且加入上下文领域知识显著提升了 LLMs 的表现。总体而言，这为结合语义和数学推理解决真实世界 CO 问题提供了新范式。",
      "categories": [
        "cs.CE",
        "cs.AI",
        "cs.CL",
        "I.2.7; I.2.1"
      ],
      "primary_category": "cs.CE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.12571v1",
      "published_date": "2024-11-19 15:39:51 UTC",
      "updated_date": "2024-11-19 15:39:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:04:19.310976"
    },
    {
      "arxiv_id": "2411.12560v2",
      "title": "Topological Symmetry Enhanced Graph Convolution for Skeleton-Based Action Recognition",
      "title_zh": "拓",
      "authors": [
        "Zeyu Liang",
        "Hailun Xia",
        "Naichuan Zheng",
        "Huan Xu"
      ],
      "abstract": "Skeleton-based action recognition has achieved remarkable performance with\nthe development of graph convolutional networks (GCNs). However, most of these\nmethods tend to construct complex topology learning mechanisms while neglecting\nthe inherent symmetry of the human body. Additionally, the use of temporal\nconvolutions with certain fixed receptive fields limits their capacity to\neffectively capture dependencies in time sequences. To address the issues, we\n(1) propose a novel Topological Symmetry Enhanced Graph Convolution (TSE-GC) to\nenable distinct topology learning across different channel partitions while\nincorporating topological symmetry awareness and (2) construct a Multi-Branch\nDeformable Temporal Convolution (MBDTC) for skeleton-based action recognition.\nThe proposed TSE-GC emphasizes the inherent symmetry of the human body while\nenabling efficient learning of dynamic topologies. Meanwhile, the design of\nMBDTC introduces the concept of deformable modeling, leading to more flexible\nreceptive fields and stronger modeling capacity of temporal dependencies.\nCombining TSE-GC with MBDTC, our final model, TSE-GCN, achieves competitive\nperformance with fewer parameters compared with state-of-the-art methods on\nthree large datasets, NTU RGB+D, NTU RGB+D 120, and NW-UCLA. On the\ncross-subject and cross-set evaluations of NTU RGB+D 120, the accuracies of our\nmodel reach 90.0\\% and 91.1\\%, with 1.1M parameters and 1.38 GFLOPS for one\nstream.",
      "tldr_zh": "这篇论文针对基于骨骼的动作识别问题，提出了一种新型 Topological Symmetry Enhanced Graph Convolution (TSE-GC)，它通过考虑人体固有的拓扑对称性，并在不同通道分区中实现动态拓扑学习，以弥补现有图卷积网络 (GCNs) 的不足。同时，论文引入 Multi-Branch Deformable Temporal Convolution (MBDTC)，采用可变形建模来增强时间序列依赖的捕捉能力，使感受野更灵活。最终模型 TSE-GCN 在 NTU RGB+D、NTU RGB+D 120 和 NW-UCLA 数据集上取得了领先性能，准确率分别达到 90.0% 和 91.1%，且仅需 1.1M 参数和 1.38 GFLOPS，相比最先进方法更高效。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.12560v2",
      "published_date": "2024-11-19 15:23:59 UTC",
      "updated_date": "2024-11-20 02:51:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:04:32.075728"
    },
    {
      "arxiv_id": "2411.12558v1",
      "title": "Recall and Refine: A Simple but Effective Source-free Open-set Domain Adaptation Framework",
      "title_zh": "Recall and Refine：一个简单但有效的无源开放集域适应框架",
      "authors": [
        "Ismail Nejjar",
        "Hao Dong",
        "Olga Fink"
      ],
      "abstract": "Open-set Domain Adaptation (OSDA) aims to adapt a model from a labeled source\ndomain to an unlabeled target domain, where novel classes - also referred to as\ntarget-private unknown classes - are present. Source-free Open-set Domain\nAdaptation (SF-OSDA) methods address OSDA without accessing labeled source\ndata, making them particularly relevant under privacy constraints. However,\nSF-OSDA presents significant challenges due to distribution shifts and the\nintroduction of novel classes. Existing SF-OSDA methods typically rely on\nthresholding the prediction entropy of a sample to identify it as either a\nknown or unknown class but fail to explicitly learn discriminative features for\nthe target-private unknown classes. We propose Recall and Refine (RRDA), a\nnovel SF-OSDA framework designed to address these limitations by explicitly\nlearning features for target-private unknown classes. RRDA employs a two-step\nprocess. First, we enhance the model's capacity to recognize unknown classes by\ntraining a target classifier with an additional decision boundary, guided by\nsynthetic samples generated from target domain features. This enables the\nclassifier to effectively separate known and unknown classes. In the second\nstep, we adapt the entire model to the target domain, addressing both domain\nshifts and improving generalization to unknown classes. Any off-the-shelf\nsource-free domain adaptation method (e.g., SHOT, AaD) can be seamlessly\nintegrated into our framework at this stage. Extensive experiments on three\nbenchmark datasets demonstrate that RRDA significantly outperforms existing\nSF-OSDA and OSDA methods.",
      "tldr_zh": "本论文提出了一种简单有效的源无开放集域适应框架RRDA，用于在不访问源域数据的情况下处理SF-OSDA问题，旨在明确学习目标私有未知类的判别特征。RRDA采用两步过程：首先，通过生成合成样本并训练带额外决策边界的目标分类器，提升模型对已知和未知类的分离能力；其次，对整个模型进行目标域适应，处理分布偏移并改善泛化，支持整合现有方法如SHOT或AaD。实验结果显示，在三个基准数据集上，RRDA显著优于现有SF-OSDA和OSDA方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.12558v1",
      "published_date": "2024-11-19 15:18:50 UTC",
      "updated_date": "2024-11-19 15:18:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:04:44.015856"
    },
    {
      "arxiv_id": "2411.12790v1",
      "title": "Visual-Oriented Fine-Grained Knowledge Editing for MultiModal Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zhen Zeng",
        "Leijiang Gu",
        "Xun Yang",
        "Zhangling Duan",
        "Zenglin Shi",
        "Meng Wang"
      ],
      "abstract": "Knowledge editing aims to efficiently and cost-effectively correct\ninaccuracies and update outdated information. Recently, there has been growing\ninterest in extending knowledge editing from Large Language Models (LLMs) to\nMultimodal Large Language Models (MLLMs), which integrate both textual and\nvisual information, introducing additional editing complexities. Existing\nmultimodal knowledge editing works primarily focus on text-oriented,\ncoarse-grained scenarios, failing to address the unique challenges posed by\nmultimodal contexts. In this paper, we propose a visual-oriented, fine-grained\nmultimodal knowledge editing task that targets precise editing in images with\nmultiple interacting entities. We introduce the Fine-Grained Visual Knowledge\nEditing (FGVEdit) benchmark to evaluate this task. Moreover, we propose a\nMultimodal Scope Classifier-based Knowledge Editor (MSCKE) framework. MSCKE\nleverages a multimodal scope classifier that integrates both visual and textual\ninformation to accurately identify and update knowledge related to specific\nentities within images. This approach ensures precise editing while preserving\nirrelevant information, overcoming the limitations of traditional text-only\nediting methods. Extensive experiments on the FGVEdit benchmark demonstrate\nthat MSCKE outperforms existing methods, showcasing its effectiveness in\nsolving the complex challenges of multimodal knowledge editing.",
      "tldr_zh": "这篇论文针对 Multimodal Large Language Models (MLLMs) 的知识编辑问题，提出一个视觉导向的细粒度任务，专注于图像中多个互动实体的精确更新，以解决现有文本导向粗粒度方法的局限。论文引入 Fine-Grained Visual Knowledge Editing (FGVEdit) 基准进行评估，并开发了 Multimodal Scope Classifier-based Knowledge Editor (MSCKE) 框架，该框架通过整合视觉和文本信息准确识别并更新特定实体知识，同时保留无关信息。实验结果表明，MSCKE 在 FGVEdit 基准上显著优于现有方法，展示了其在多模态知识编辑中的高效性和有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.12790v1",
      "published_date": "2024-11-19 14:49:36 UTC",
      "updated_date": "2024-11-19 14:49:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:06:08.756532"
    },
    {
      "arxiv_id": "2411.12539v1",
      "title": "Predicting Customer Satisfaction by Replicating the Survey Response Distribution",
      "title_zh": "通过复现调查响应分布预测客户满意度",
      "authors": [
        "Etienne Manderscheid",
        "Matthias Lee"
      ],
      "abstract": "For many call centers, customer satisfaction (CSAT) is a key performance\nindicator (KPI). However, only a fraction of customers take the CSAT survey\nafter the call, leading to a biased and inaccurate average CSAT value, and\nmissed opportunities for coaching, follow-up, and rectification. Therefore,\ncall centers can benefit from a model predicting customer satisfaction on calls\nwhere the customer did not complete the survey. Given that CSAT is a closely\nmonitored KPI, it is critical to minimize any bias in the average predicted\nCSAT (pCSAT). In this paper, we introduce a method such that predicted CSAT\n(pCSAT) scores accurately replicate the distribution of survey CSAT responses\nfor every call center with sufficient data in a live production environment.\nThe method can be applied to many multiclass classification problems to improve\nthe class balance and minimize its changes upon model updates.",
      "tldr_zh": "这篇论文针对呼叫中心的客户满意度 (CSAT) 指标提出了一种预测方法，以解决调查响应率低导致的偏差问题。方法通过构建模型，使预测 CSAT (pCSAT) 得分准确复制实际调查响应的分布，从而在生产环境中最小化偏差，并适用于有足够数据的呼叫中心。实验结果显示，此方法能改善多类分类问题的类平衡，并减少模型更新时的变化。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.12539v1",
      "published_date": "2024-11-19 14:39:29 UTC",
      "updated_date": "2024-11-19 14:39:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:06:19.756876"
    },
    {
      "arxiv_id": "2411.12525v1",
      "title": "Rethinking Top Probability from Multi-view for Distracted Driver Behaviour Localization",
      "title_zh": "翻译失败",
      "authors": [
        "Quang Vinh Nguyen",
        "Vo Hoang Thanh Son",
        "Chau Truong Vinh Hoang",
        "Duc Duy Nguyen",
        "Nhat Huy Nguyen Minh",
        "Soo-Hyung Kim"
      ],
      "abstract": "Naturalistic driving action localization task aims to recognize and\ncomprehend human behaviors and actions from video data captured during\nreal-world driving scenarios. Previous studies have shown great action\nlocalization performance by applying a recognition model followed by\nprobability-based post-processing. Nevertheless, the probabilities provided by\nthe recognition model frequently contain confused information causing challenge\nfor post-processing. In this work, we adopt an action recognition model based\non self-supervise learning to detect distracted activities and give potential\naction probabilities. Subsequently, a constraint ensemble strategy takes\nadvantages of multi-camera views to provide robust predictions. Finally, we\nintroduce a conditional post-processing operation to locate distracted\nbehaviours and action temporal boundaries precisely. Experimenting on test set\nA2, our method obtains the sixth position on the public leaderboard of track 3\nof the 2024 AI City Challenge.",
      "tldr_zh": "该研究重新审视了基于多视图的顶概率（Top Probability）方法，用于自然驾驶场景中的分心驾驶行为定位（Distracted Driver Behaviour Localization），旨在解决传统概率后处理中混淆信息的问题。作者采用基于自监督学习（self-supervise learning）的动作识别模型来检测分心活动并生成潜在动作概率，随后通过约束集成策略（constraint ensemble strategy）整合多相机视图以提供更鲁棒的预测。最终，引入条件后处理操作（conditional post-processing）来精确定位分心行为和动作时间边界。在2024 AI City Challenge的track 3测试集A2上，该方法获得第六名，展示了其在实际应用中的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Computer Vision and Pattern Recognition Workshop 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.12525v1",
      "published_date": "2024-11-19 14:18:02 UTC",
      "updated_date": "2024-11-19 14:18:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:08:11.636769"
    },
    {
      "arxiv_id": "2411.15194v1",
      "title": "Guiding Word Equation Solving using Graph Neural Networks (Extended Technical Report)",
      "title_zh": "翻译失败",
      "authors": [
        "Parosh Aziz Abdulla",
        "Mohamed Faouzi Atig",
        "Julie Cailler",
        "Chencheng Liang",
        "Philipp Rümmer"
      ],
      "abstract": "This paper proposes a Graph Neural Network-guided algorithm for solving word\nequations, based on the well-known Nielsen transformation for splitting\nequations. The algorithm iteratively rewrites the first terms of each side of\nan equation, giving rise to a tree-like search space. The choice of path at\neach split point of the tree significantly impacts solving time, motivating the\nuse of Graph Neural Networks (GNNs) for efficient split decision-making. Split\ndecisions are encoded as multi-classification tasks, and five graph\nrepresentations of word equations are introduced to encode their structural\ninformation for GNNs. The algorithm is implemented as a solver named DragonLi.\nExperiments are conducted on artificial and real-world benchmarks. The\nalgorithm performs particularly well on satisfiable problems. For single word\n\\mbox{equations}, DragonLi can solve significantly more problems than\nwell-established string solvers. For the conjunction of multiple word\nequations, DragonLi is competitive with state-of-the-art string solvers.",
      "tldr_zh": "这篇论文提出了一种使用 Graph Neural Networks (GNNs) 指导的算法，用于解决字方程，基于 Nielsen transformation 通过迭代重写方程两侧首项，形成树状搜索空间。算法引入五种图表示来编码字方程的结构信息，将决策问题转化为多分类任务，以提高搜索效率。实验结果显示，所实现的 DragonLi 求解器在可满足问题上表现突出，能够解决比现有字符串求解器更多的单字方程，并在多个字方程的合取上与最先进求解器竞争。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.LO"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.15194v1",
      "published_date": "2024-11-19 14:15:34 UTC",
      "updated_date": "2024-11-19 14:15:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:06:43.722704"
    },
    {
      "arxiv_id": "2411.12517v2",
      "title": "The Hermeneutic Turn of AI: Are Machines Capable of Interpreting?",
      "title_zh": "翻译失败",
      "authors": [
        "Remy Demichelis"
      ],
      "abstract": "This article aims to demonstrate how the approach to computing is being\ndisrupted by deep learning (artificial neural networks), not only in terms of\ntechniques but also in our interactions with machines. It also addresses the\nphilosophical tradition of hermeneutics (Don Ihde, Wilhelm Dilthey) to\nhighlight a parallel with this movement and to demystify the idea of human-like\nAI.",
      "tldr_zh": "这篇文章探讨了深度学习（artificial neural networks）如何颠覆计算方法，不仅在技术层面，还在人与机器的互动方式上。作者借鉴解释学（hermeneutics）哲学传统，特别是 Don Ihde 和 Wilhelm Dilthey 的观点，揭示了这一技术变革与哲学思想的平行关系。最终，该研究旨在消除对类人 AI 的误解，提供更理性的人工智能解读框架。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "4 pages;\n  https://theconversation.com/lia-est-elle-capable-dinterpreter-ce-quon-lui-demande-230890",
      "pdf_url": "http://arxiv.org/pdf/2411.12517v2",
      "published_date": "2024-11-19 13:59:16 UTC",
      "updated_date": "2024-11-28 09:24:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:06:55.762973"
    },
    {
      "arxiv_id": "2411.12502v3",
      "title": "Transformer Neural Processes - Kernel Regression",
      "title_zh": "Transformer 神经过程 - 核回归",
      "authors": [
        "Daniel Jenson",
        "Jhonathan Navott",
        "Mengyan Zhang",
        "Makkunda Sharma",
        "Elizaveta Semenova",
        "Seth Flaxman"
      ],
      "abstract": "Neural Processes (NPs) are a rapidly evolving class of models designed to\ndirectly model the posterior predictive distribution of stochastic processes.\nOriginally developed as a scalable alternative to Gaussian Processes (GPs),\nwhich are limited by $O(n^3)$ runtime complexity, the most accurate modern NPs\ncan often rival GPs but still suffer from an $O(n^2)$ bottleneck due to their\nattention mechanism. We introduce the Transformer Neural Process - Kernel\nRegression (TNP-KR), a scalable NP featuring: (1) a Kernel Regression Block\n(KRBlock), a simple, extensible, and parameter efficient transformer block with\ncomplexity $O(n_c^2 + n_c n_t)$, where $n_c$ and $n_t$ are the number of\ncontext and test points, respectively; (2) a kernel-based attention bias; and\n(3) two novel attention mechanisms: scan attention (SA), a memory-efficient\nscan-based attention that when paired with a kernel-based bias can make TNP-KR\ntranslation invariant, and deep kernel attention (DKA), a Performer-style\nattention that implicitly incoporates a distance bias and further reduces\ncomplexity to $O(n_c)$. These enhancements enable both TNP-KR variants to\nperform inference with 100K context points on over 1M test points in under a\nminute on a single 24GB GPU. On benchmarks spanning meta regression, Bayesian\noptimization, image completion, and epidemiology, TNP-KR with DKA outperforms\nits Performer counterpart on nearly every benchmark, while TNP-KR with SA\nachieves state-of-the-art results.",
      "tldr_zh": "本文提出 Transformer Neural Processes - Kernel Regression (TNP-KR)，一种高效的 Neural Processes 模型，用于解决传统 Gaussian Processes (GPs) 的 O(n^3) 计算复杂性和现代 NPs 的 O(n^2) 瓶颈问题。TNP-KR 引入 Kernel Regression Block (KRBlock)、基于核的 attention bias，以及两种新机制：Scan Attention (SA) 和 Deep Kernel Attention (DKA)，将复杂度降至 O(n_c^2 + n_c n_t) 或 O(n_c)，并实现平移不变性和大规模数据处理，如在单 24GB GPU 上处理 100K 上下文点和 1M 测试点只需一分钟。实验结果显示，TNP-KR with DKA 在 meta regression、Bayesian optimization、image completion 和 epidemiology 等基准上优于 Performer 模型，而 TNP-KR with SA 达到 state-of-the-art 性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.12502v3",
      "published_date": "2024-11-19 13:40:49 UTC",
      "updated_date": "2025-02-11 11:03:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:07:09.822007"
    },
    {
      "arxiv_id": "2411.12498v2",
      "title": "Enhancing Reasoning Capabilities of LLMs via Principled Synthetic Logic Corpus",
      "title_zh": "通过基于原则的合成逻辑语料提升LLMs的推理能力",
      "authors": [
        "Terufumi Morishita",
        "Gaku Morio",
        "Atsuki Yamaguchi",
        "Yasuhiro Sogawa"
      ],
      "abstract": "Large language models (LLMs) are capable of solving a wide range of tasks,\nyet they have struggled with reasoning. To address this, we propose\n$\\textbf{Additional Logic Training (ALT)}$, which aims to enhance LLMs'\nreasoning capabilities by program-generated logical reasoning samples. We first\nestablish principles for designing high-quality samples by integrating symbolic\nlogic theory and previous empirical insights. Then, based on these principles,\nwe construct a synthetic corpus named $\\textbf{Formal Logic Deduction Diverse}$\n($\\textbf{FLD}$$_{\\times 2}$), comprising numerous samples of multi-step\ndeduction with unknown facts, diverse reasoning rules, diverse linguistic\nexpressions, and challenging distractors. Finally, we empirically show that ALT\non FLD$_{\\times2}$ substantially enhances the reasoning capabilities of\nstate-of-the-art LLMs, including LLaMA-3.1-70B. Improvements include gains of\nup to 30 points on logical reasoning benchmarks, up to 10 points on math and\ncoding benchmarks, and 5 points on the benchmark suite BBH.",
      "tldr_zh": "本研究提出了一种名为 Additional Logic Training (ALT) 的方法，通过程序生成的逻辑推理样本来提升大型语言模型 (LLMs) 的推理能力。研究者首先整合符号逻辑理论和经验见解，建立了设计高质量样本的原则，并据此构建了合成语料库 Formal Logic Deduction Diverse (FLD×2)，该语料库包含多步推理样本、未知事实、多样推理规则、语言表达和挑战性干扰项。实验结果显示，在 FLD×2 上进行 ALT 显著提升了最先进 LLMs（如 LLaMA-3.1-70B）的性能，在逻辑推理基准上提高多达 30 分，在数学和编码基准上提高多达 10 分，并在 BBH 基准套件上提高 5 分。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.12498v2",
      "published_date": "2024-11-19 13:31:53 UTC",
      "updated_date": "2024-12-23 10:36:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:07:19.930834"
    },
    {
      "arxiv_id": "2411.12483v1",
      "title": "Analysing Explanation-Related Interactions in Collaborative Perception-Cognition-Communication-Action",
      "title_zh": "分析协作感知-认知-通信-行动中的解释相关互动",
      "authors": [
        "Marc Roig Vilamala",
        "Jack Furby",
        "Julian de Gortari Briseno",
        "Mani Srivastava",
        "Alun Preece",
        "Carolina Fuentes Toro"
      ],
      "abstract": "Effective communication is essential in collaborative tasks, so AI-equipped\nrobots working alongside humans need to be able to explain their behaviour in\norder to cooperate effectively and earn trust. We analyse and classify\ncommunications among human participants collaborating to complete a simulated\nemergency response task. The analysis identifies messages that relate to\nvarious kinds of interactive explanations identified in the explainable AI\nliterature. This allows us to understand what type of explanations humans\nexpect from their teammates in such settings, and thus where AI-equipped robots\nmost need explanation capabilities. We find that most explanation-related\nmessages seek clarification in the decisions or actions taken. We also confirm\nthat messages have an impact on the performance of our simulated task.",
      "tldr_zh": "本研究分析了在协作感知-认知-沟通-行动（Collaborative Perception-Cognition-Communication-Action）任务中，与解释相关的互动，旨在探讨AI机器人如何通过解释行为提升合作和信任。研究者通过模拟紧急响应任务观察并分类人类参与者的沟通，将其与可解释AI（explainable AI）文献中的解释类型关联。结果显示，大多数解释相关消息是寻求决策或行动的澄清，这些互动显著影响了任务绩效。该发现有助于指导AI机器人开发针对性解释能力，以更好地适应协作场景。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.HC",
      "comment": "4 pages, 3 figures, published as a Late Breaking Report in RO-MAN\n  2024",
      "pdf_url": "http://arxiv.org/pdf/2411.12483v1",
      "published_date": "2024-11-19 13:07:04 UTC",
      "updated_date": "2024-11-19 13:07:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:07:31.401301"
    },
    {
      "arxiv_id": "2411.14480v1",
      "title": "Associative Knowledge Graphs for Efficient Sequence Storage and Retrieval",
      "title_zh": "翻译失败",
      "authors": [
        "Przemysław Stokłosa",
        "Janusz A. Starzyk",
        "Paweł Raif",
        "Adrian Horzyk",
        "Marcin Kowalik"
      ],
      "abstract": "This paper presents a novel approach for constructing associative knowledge\ngraphs that are highly effective for storing and recognizing sequences. The\ngraph is created by representing overlapping sequences of objects, as tightly\nconnected clusters within the larger graph. Individual objects (represented as\nnodes) can be a part of multiple sequences or appear repeatedly within a single\nsequence. To retrieve sequences, we leverage context, providing a subset of\nobjects that triggers an association with the complete sequence. The system's\nmemory capacity is determined by the size of the graph and the density of its\nconnections. We have theoretically derived the relationships between the\ncritical density of the graph and the memory capacity for storing sequences.\nThe critical density is the point beyond which error-free sequence\nreconstruction becomes impossible. Furthermore, we have developed an efficient\nalgorithm for ordering elements within a sequence. Through extensive\nexperiments with various types of sequences, we have confirmed the validity of\nthese relationships. This approach has potential applications in diverse\nfields, such as anomaly detection in financial transactions or predicting user\nbehavior based on past actions.",
      "tldr_zh": "本论文提出了一种构建关联知识图(Associative Knowledge Graphs)的创新方法，用于高效存储和检索序列，将重叠序列表示为图中的紧密连接集群，每个节点代表对象并可重复出现或跨序列共享。系统通过提供子序列对象来触发完整序列的关联检索，并理论推导了图的临界密度与记忆容量的关系，确定了错误重建序列的阈值，同时开发了高效的序列元素排序算法。实验验证了这些理论关系在各种序列类型上的有效性，并展示了该方法在金融交易异常检测和用户行为预测等领域的潜在应用。",
      "categories": [
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.14480v1",
      "published_date": "2024-11-19 13:00:31 UTC",
      "updated_date": "2024-11-19 13:00:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:07:43.142662"
    },
    {
      "arxiv_id": "2411.12476v1",
      "title": "Comparing Prior and Learned Time Representations in Transformer Models of Timeseries",
      "title_zh": "比较 Transformer 模型中时间序列的先验与学习时间表示",
      "authors": [
        "Natalia Koliou",
        "Tatiana Boura",
        "Stasinos Konstantopoulos",
        "George Meramveliotakis",
        "George Kosmadakis"
      ],
      "abstract": "What sets timeseries analysis apart from other machine learning exercises is\nthat time representation becomes a primary aspect of the experiment setup, as\nit must adequately represent the temporal relations that are relevant for the\napplication at hand. In the work described here we study wo different\nvariations of the Transformer architecture: one where we use the fixed time\nrepresentation proposed in the literature and one where the time representation\nis learned from the data. Our experiments use data from predicting the energy\noutput of solar panels, a task that exhibits known periodicities (daily and\nseasonal) that is straight-forward to encode in the fixed time representation.\nOur results indicate that even in an experiment where the phenomenon is\nwell-understood, it is difficult to encode prior knowledge due to side-effects\nthat are difficult to mitigate. We conclude that research work is needed to\nwork the human into the learning loop in ways that improve the robustness and\ntrust-worthiness of the network.",
      "tldr_zh": "本研究比较了Transformer时序模型中固定时间表示（fixed time representation）和从数据中学习的时间表示（learned time representation），以评估它们在捕捉temporal relations方面的表现。实验使用太阳能面板能量输出预测任务，该任务具有已知的periodicities（如daily和seasonal），便于在固定时间表示中编码。结果显示，即使prior knowledge易于理解，编码过程仍受难以缓解的side-effects影响，导致模型性能受限。研究结论强调，需要进一步探索将人类纳入学习循环，以提升Transformer模型的robustness和trustworthiness。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Presented at the AI in Natural Sciences and Technology (AINST) track\n  of the 13th Conference on Artificial Intelligence (SETN 2024), 11-13\n  September 2024, Piraeus, Greece",
      "pdf_url": "http://arxiv.org/pdf/2411.12476v1",
      "published_date": "2024-11-19 12:56:43 UTC",
      "updated_date": "2024-11-19 12:56:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:07:55.646944"
    },
    {
      "arxiv_id": "2411.12469v4",
      "title": "AI Flow at the Network Edge",
      "title_zh": "AI Flow 在网络边缘",
      "authors": [
        "Jiawei Shao",
        "Xuelong Li"
      ],
      "abstract": "Recent advancements in large language models (LLMs) and their multimodal\nvariants have led to remarkable progress across various domains, demonstrating\nimpressive capabilities and unprecedented potential. In the era of ubiquitous\nconnectivity, leveraging communication networks to distribute intelligence is a\ntransformative concept, envisioning AI-powered services accessible at the\nnetwork edge. However, pushing large models from the cloud to\nresource-constrained environments faces critical challenges. Model inference on\nlow-end devices leads to excessive latency and performance bottlenecks, while\nraw data transmission over limited bandwidth networks causes high communication\noverhead. This article presents AI Flow, a framework that streamlines the\ninference process by jointly leveraging the heterogeneous resources available\nacross devices, edge nodes, and cloud servers, making intelligence flow across\nnetworks. To facilitate cooperation among multiple computational nodes, the\nproposed framework explores a paradigm shift in the design of communication\nnetwork systems from transmitting information flow to intelligence flow, where\nthe goal of communications is task-oriented and folded into the inference\nprocess. Experimental results demonstrate the effectiveness of the proposed\nframework through an image captioning use case, showcasing the ability to\nreduce response latency while maintaining high-quality captions. This article\nserves as a position paper for identifying the motivation, challenges, and\nprinciples of AI Flow.",
      "tldr_zh": "这篇论文探讨了在网络边缘部署大型语言模型(LLMs)及其多模态变体的挑战，包括模型推理延迟和数据传输的通信开销问题。作者提出了AI Flow框架，通过联合利用设备、边缘节点和云服务器的异构资源，实现智能在网络中的流动，并将通信网络从传输信息流转变为任务导向的智能流设计。框架将通信目标融入推理过程，促进多节点合作。实验结果显示，在图像字幕用例中，AI Flow显著降低了响应延迟，同时保持了高品质输出。该论文作为立场文件，阐述了AI Flow的动机、挑战和核心原则。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG",
        "cs.NI"
      ],
      "primary_category": "eess.SP",
      "comment": "This paper has been accepted to IEEE Network Magazine",
      "pdf_url": "http://arxiv.org/pdf/2411.12469v4",
      "published_date": "2024-11-19 12:51:17 UTC",
      "updated_date": "2025-02-13 06:18:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:08:23.726299"
    },
    {
      "arxiv_id": "2411.12460v2",
      "title": "Exploring Iterative Controllable Summarization with Large Language Models",
      "title_zh": "探索大语言模型的迭代可控摘要生成",
      "authors": [
        "Sangwon Ryu",
        "Heejin Do",
        "Daehee Kim",
        "Hwanjo Yu",
        "Dongwoo Kim",
        "Yunsu Kim",
        "Gary Geunbae Lee",
        "Jungseul Ok"
      ],
      "abstract": "Large language models (LLMs) have demonstrated remarkable performance in\nabstractive summarization tasks. However, their ability to precisely control\nsummary attributes (e.g., length or topic) remains underexplored, limiting\ntheir adaptability to specific user preferences. In this paper, we\nsystematically explore the controllability of LLMs. To this end, we revisit\nsummary attribute measurements and introduce iterative evaluation metrics,\nfailure rate and average iteration count to precisely evaluate controllability\nof LLMs, rather than merely assessing errors. Our findings show that LLMs\nstruggle more with numerical attributes than with linguistic attributes. To\naddress this challenge, we propose a guide-to-explain framework (GTE) for\ncontrollable summarization. Our GTE framework enables the model to identify\nmisaligned attributes in the initial draft and guides it in self-explaining\nerrors in the previous output. By allowing the model to reflect on its\nmisalignment, GTE generates well-adjusted summaries that satisfy the desired\nattributes with robust effectiveness, requiring surprisingly fewer iterations\nthan other iterative approaches.",
      "tldr_zh": "本论文探讨了大型语言模型 (LLMs) 在摘要生成中的可控性问题，发现 LLMs 在精确控制摘要属性（如长度或主题）方面存在局限，尤其在数字属性上表现较差。作者引入了新的评估指标，包括 failure rate 和 average iteration count，以更精确地评估模型的可控性，而非仅依赖错误率。针对这一挑战，他们提出了 guide-to-explain framework (GTE)，该框架允许模型识别初始草稿中的属性不匹配，并通过自我解释错误来生成更符合预期的摘要。实验结果表明，GTE 比其他迭代方法更高效，需要更少的迭代次数，从而提升了可控摘要生成的整体性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.12460v2",
      "published_date": "2024-11-19 12:36:02 UTC",
      "updated_date": "2025-03-03 10:35:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:08:35.897851"
    },
    {
      "arxiv_id": "2411.15193v1",
      "title": "Gradient-Weighted Feature Back-Projection: A Fast Alternative to Feature Distillation in 3D Gaussian Splatting",
      "title_zh": "翻译失败",
      "authors": [
        "Joji Joseph",
        "Bharadwaj Amrutur",
        "Shalabh Bhatnagar"
      ],
      "abstract": "We introduce a training-free method for feature field rendering in Gaussian\nsplatting. Our approach back-projects 2D features into pre-trained 3D\nGaussians, using a weighted sum based on each Gaussian's influence in the final\nrendering. While most training-based feature field rendering methods excel at\n2D segmentation but perform poorly at 3D segmentation without post-processing,\nour method achieves high-quality results in both 2D and 3D segmentation.\nExperimental results demonstrate that our approach is fast, scalable, and\noffers performance comparable to training-based methods.",
      "tldr_zh": "本研究提出了 Gradient-Weighted Feature Back-Projection，一种无需训练的快速方法，用于在 3D Gaussian Splatting 中进行 feature field rendering。该方法通过基于每个 Gaussian 在最终渲染中的影响进行加权求和，将 2D features back-project 到预训练的 3D Gaussians，从而实现高品质的 2D 和 3D segmentation。相比传统的训练-based 方法，该方法更快、更可扩展，且实验结果显示其性能与之相当。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.15193v1",
      "published_date": "2024-11-19 12:17:15 UTC",
      "updated_date": "2024-11-19 12:17:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:08:47.154845"
    },
    {
      "arxiv_id": "2411.17835v1",
      "title": "Arabic-Nougat: Fine-Tuning Vision Transformers for Arabic OCR and Markdown Extraction",
      "title_zh": "Arabic",
      "authors": [
        "Mohamed Rashad"
      ],
      "abstract": "We present Arabic-Nougat, a suite of OCR models for converting Arabic book\npages into structured Markdown text. Based on Meta's Nougat architecture,\nArabic-Nougat includes three specialized models: arabic-small-nougat,\narabic-base-nougat, and arabic-large-nougat. These models are fine-tuned on a\nsynthetic dataset, arabic-img2md, comprising 13.7k pairs of Arabic book pages\nand their Markdown representations. Key contributions include the\nAranizer-PBE-86k tokenizer, designed for efficient tokenization, and the use of\ntorch.bfloat16 precision with Flash Attention 2 for optimized training and\ninference. Our models achieve state-of-the-art performance, with\narabic-large-nougat delivering the highest Markdown Structure Accuracy and the\nlowest Character Error Rate. Additionally, we release a large-scale dataset\ncontaining 1.1 billion Arabic tokens extracted from over 8,500 books using our\nbest-performing model, providing a valuable resource for Arabic OCR research.\nAll models, datasets, and code are open-sourced and available at\nhttps://github.com/MohamedAliRashad/arabic-nougat.",
      "tldr_zh": "本研究提出Arabic-Nougat，一套基于Vision Transformers的OCR模型，用于将阿拉伯语书籍页面转换为结构化的Markdown文本。该模型套件包括三个微调版本：arabic-small-nougat、arabic-base-nougat和arabic-large-nougat，在合成数据集arabic-img2md（包含13.7k对书籍页面和Markdown表示）上进行fine-tuning，并引入Aranizer-PBE-86k tokenizer，同时利用torch.bfloat16精度和Flash Attention 2优化训练和推理过程。实验结果显示，arabic-large-nougat实现了state-of-the-art性能，具有最高的Markdown Structure Accuracy和最低的Character Error Rate。该研究还开源了一个包含1.1亿阿拉伯语标记的大规模数据集，以及所有模型、代码和资源，以支持Arabic OCR研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "7 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2411.17835v1",
      "published_date": "2024-11-19 12:09:12 UTC",
      "updated_date": "2024-11-19 12:09:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:08:59.351630"
    },
    {
      "arxiv_id": "2411.12433v1",
      "title": "Preference-Conditioned Gradient Variations for Multi-Objective Quality-Diversity",
      "title_zh": "翻译失败",
      "authors": [
        "Hannah Janmohamed",
        "Maxence Faldor",
        "Thomas Pierrot",
        "Antoine Cully"
      ],
      "abstract": "In a variety of domains, from robotics to finance, Quality-Diversity\nalgorithms have been used to generate collections of both diverse and\nhigh-performing solutions. Multi-Objective Quality-Diversity algorithms have\nemerged as a promising approach for applying these methods to complex,\nmulti-objective problems. However, existing methods are limited by their search\ncapabilities. For example, Multi-Objective Map-Elites depends on random genetic\nvariations which struggle in high-dimensional search spaces. Despite efforts to\nenhance search efficiency with gradient-based mutation operators, existing\napproaches consider updating solutions to improve on each objective separately\nrather than achieving desired trade-offs. In this work, we address this\nlimitation by introducing Multi-Objective Map-Elites with\nPreference-Conditioned Policy-Gradient and Crowding Mechanisms: a new\nMulti-Objective Quality-Diversity algorithm that uses preference-conditioned\npolicy-gradient mutations to efficiently discover promising regions of the\nobjective space and crowding mechanisms to promote a uniform distribution of\nsolutions on the Pareto front. We evaluate our approach on six robotics\nlocomotion tasks and show that our method outperforms or matches all\nstate-of-the-art Multi-Objective Quality-Diversity methods in all six,\nincluding two newly proposed tri-objective tasks. Importantly, our method also\nachieves a smoother set of trade-offs, as measured by newly-proposed\nsparsity-based metrics. This performance comes at a lower computational storage\ncost compared to previous methods.",
      "tldr_zh": "本研究针对多目标 Quality-Diversity 算法在高维搜索空间中的效率问题，提出了一种新方法：Multi-Objective Map-Elites with Preference-Conditioned Policy-Gradient and Crowding Mechanisms。该方法通过 preference-conditioned policy-gradient mutations 高效探索目标空间，并利用 crowding mechanisms 促进 Pareto front 上解决方案的均匀分布。在六个机器人运动任务（包括两个新三目标任务）上评估，结果显示该算法在所有任务中优于或匹配最先进方法，提供更平滑的权衡集，同时降低了计算存储成本。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.12433v1",
      "published_date": "2024-11-19 11:50:03 UTC",
      "updated_date": "2024-11-19 11:50:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:09:10.646682"
    },
    {
      "arxiv_id": "2411.12787v2",
      "title": "Visual Cue Enhancement and Dual Low-Rank Adaptation for Efficient Visual Instruction Fine-Tuning",
      "title_zh": "视觉提示增强和双低秩适应用于",
      "authors": [
        "Pengkun Jiao",
        "Bin Zhu",
        "Jingjing Chen",
        "Chong-Wah Ngo",
        "Yu-Gang Jiang"
      ],
      "abstract": "Parameter-efficient fine-tuning multimodal large language models (MLLMs)\npresents significant challenges, including reliance on high-level visual\nfeatures that limit fine-grained detail comprehension, and data conflicts that\narise from task complexity. To address these issues, we propose an efficient\nfine-tuning framework with two novel approaches: Vision Cue Enhancement (VCE)\nand Dual Low-Rank Adaptation (Dual-LoRA). VCE enhances the vision projector by\nintegrating multi-level visual cues, improving the model's ability to capture\nfine-grained visual features. Dual-LoRA introduces a dual low-rank structure\nfor instruction tuning, decoupling learning into skill and task spaces to\nenable precise control and efficient adaptation across diverse tasks. Our\nmethod simplifies implementation, enhances visual comprehension, and improves\nadaptability. Experiments on both downstream tasks and general benchmarks\ndemonstrate the effectiveness of our proposed approach.",
      "tldr_zh": "这篇论文针对参数高效微调多模态大语言模型(MLLMs)的挑战，包括依赖高层视觉特征导致细粒度细节理解不足，以及任务复杂性带来的数据冲突，提出两种创新方法：Vision Cue Enhancement (VCE)和Dual Low-Rank Adaptation (Dual-LoRA)。VCE通过整合多级视觉线索增强视觉投影器，提高模型对细粒度视觉特征的捕捉能力；Dual-LoRA则采用双低秩结构，将学习解耦为技能空间和任务空间，实现精确控制和高效适应。实验结果显示，该框架在下游任务和通用基准上表现出色，简化了实现过程并显著提升了视觉理解和模型适应性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.12787v2",
      "published_date": "2024-11-19 11:03:09 UTC",
      "updated_date": "2024-12-02 07:41:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:09:24.287539"
    },
    {
      "arxiv_id": "2411.14479v1",
      "title": "GRL-Prompt: Towards Knowledge Graph based Prompt Optimization via Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Yuze Liu",
        "Tingjie Liu",
        "Tiehua Zhang",
        "Youhua Xia",
        "Jinze Wang",
        "Zhishu Shen",
        "Jiong Jin",
        "Fei Richard Yu"
      ],
      "abstract": "Large language models (LLMs) have demonstrated impressive success in a wide\nrange of natural language processing (NLP) tasks due to their extensive general\nknowledge of the world. Recent works discovered that the performance of LLMs is\nheavily dependent on the input prompt. However, prompt engineering is usually\ndone manually in a trial-and-error fashion, which can be labor-intensive and\nchallenging in order to find the optimal prompts. To address these problems and\nunleash the utmost potential of LLMs, we propose a novel LLMs-agnostic\nframework for prompt optimization, namely GRL-Prompt, which aims to\nautomatically construct optimal prompts via reinforcement learning (RL) in an\nend-to-end manner. To provide structured action/state representation for\noptimizing prompts, we construct a knowledge graph (KG) that better encodes the\ncorrelation between the user query and candidate in-context examples.\nFurthermore, a policy network is formulated to generate the optimal action by\nselecting a set of in-context examples in a rewardable order to construct the\nprompt. Additionally, the embedding-based reward shaping is utilized to\nstabilize the RL training process. The experimental results show that\nGRL-Prompt outperforms recent state-of-the-art methods, achieving an average\nincrease of 0.10 in ROUGE-1, 0.07 in ROUGE-2, 0.07 in ROUGE-L, and 0.05 in\nBLEU.",
      "tldr_zh": "本研究针对大型语言模型（LLMs）的提示工程问题，提出了一种新型框架GRL-Prompt，利用强化学习（Reinforcement Learning）自动优化提示，以减少手动试错的劳动强度。该框架构建知识图（Knowledge Graph）来编码用户查询与候选in-context examples的相关性，并通过策略网络生成最优动作，选择和排序in-context examples来构建提示，同时采用基于嵌入的奖励整形（reward shaping）稳定训练过程。实验结果显示，GRL-Prompt在各种NLP任务上优于现有方法，平均提升ROUGE-1 0.10、ROUGE-2 0.07、ROUGE-L 0.07和BLEU 0.05的指标。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.14479v1",
      "published_date": "2024-11-19 10:52:25 UTC",
      "updated_date": "2024-11-19 10:52:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:09:35.091741"
    },
    {
      "arxiv_id": "2412.00029v2",
      "title": "Planning vs Reasoning: Ablations to Test Capabilities of LoRA layers",
      "title_zh": "翻译失败",
      "authors": [
        "Neel Redkar"
      ],
      "abstract": "Low-Rank Adaptation (LoRA) layers have emerged as a promising approach for\nefficient model fine-tuning, but their capabilities and limitations have not\nbeen fully explored. This paper: 1) Investigates the fundamental question of\nwhether LoRA layers are effective at increasing reasoning + planning abilities\n2) We introduce HashChain Reasoning, a novel evaluation dataset that\ndeterministically tests reasoning capabilities.\n  Through systematic ablation studies on GPT-2, we demonstrate that reasoning\ncapabilities appear to exist primarily in low-rank spaces and can be\neffectively enhanced using LoRA layers. The effective rank analysis of trained\nLoRA matrices reveals a 2-3x lower rank requirement for reasoning tasks\ncompared to planning tasks, giving context on where LoRA layers would be\neffective. This also provides evidence for reasoning fundamentally preferring\nlow-parameter spaces for generalization.",
      "tldr_zh": "这篇论文探讨了Low-Rank Adaptation (LoRA) layers在提升模型推理和规划能力方面的有效性，通过系统性消融研究测试其局限性。研究者引入了HashChain Reasoning数据集，用于定量评估推理能力，并在GPT-2模型上进行实验，发现推理能力主要存在于低秩空间中，且LoRA layers能有效增强这些能力。分析结果显示，推理任务所需的有效秩比规划任务低2-3倍，这为LoRA layers在低参数空间的泛化应用提供了证据，并突显了其在推理场景中的优势。",
      "categories": [
        "cs.AI",
        "I.2.7, I.2.6"
      ],
      "primary_category": "cs.AI",
      "comment": "7 pages, 5 figures, preprint",
      "pdf_url": "http://arxiv.org/pdf/2412.00029v2",
      "published_date": "2024-11-19 10:51:49 UTC",
      "updated_date": "2025-02-05 10:01:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:09:47.758753"
    },
    {
      "arxiv_id": "2411.12405v2",
      "title": "Evaluating the Prompt Steerability of Large Language Models",
      "title_zh": "评估大语言模型的提示可操控性",
      "authors": [
        "Erik Miehling",
        "Michael Desmond",
        "Karthikeyan Natesan Ramamurthy",
        "Elizabeth M. Daly",
        "Pierre Dognin",
        "Jesus Rios",
        "Djallel Bouneffouf",
        "Miao Liu"
      ],
      "abstract": "Building pluralistic AI requires designing models that are able to be shaped\nto represent a wide range of value systems and cultures. Achieving this\nrequires first being able to evaluate the degree to which a given model is\ncapable of reflecting various personas. To this end, we propose a benchmark for\nevaluating the steerability of model personas as a function of prompting. Our\ndesign is based on a formal definition of prompt steerability, which analyzes\nthe degree to which a model's joint behavioral distribution can be shifted from\nits baseline. By defining steerability indices and inspecting how these indices\nchange as a function of steering effort, we can estimate the steerability of a\nmodel across various persona dimensions and directions. Our benchmark reveals\nthat the steerability of many current models is limited -- due to both a skew\nin their baseline behavior and an asymmetry in their steerability across many\npersona dimensions. We release an implementation of our benchmark at\nhttps://github.com/IBM/prompt-steering.",
      "tldr_zh": "这篇论文提出一个基准，用于评估大型语言模型（Large Language Models）的提示可引导性（Prompt Steerability），以检查模型是否能通过提示被引导以反映多种人格、价值系统和文化。研究基于一个正式定义，分析模型行为的联合分布从基线偏移，并通过 steerability indices 量化引导努力对模型的影响。结果显示，许多当前模型的可引导性有限，主要由于基线行为的偏差和在不同人格维度上的不对称。作者发布了基准的实现代码在 GitHub（https://github.com/IBM/prompt-steering）。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "Short version appeared at the Pluralistic Alignment workshop at\n  NeurIPS 2024; extended version appeared at NAACL 2025",
      "pdf_url": "http://arxiv.org/pdf/2411.12405v2",
      "published_date": "2024-11-19 10:41:54 UTC",
      "updated_date": "2025-02-15 15:34:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:09:59.083575"
    },
    {
      "arxiv_id": "2411.12395v1",
      "title": "Do LLMs Understand Ambiguity in Text? A Case Study in Open-world Question Answering",
      "title_zh": "翻译失败",
      "authors": [
        "Aryan Keluskar",
        "Amrita Bhattacharjee",
        "Huan Liu"
      ],
      "abstract": "Ambiguity in natural language poses significant challenges to Large Language\nModels (LLMs) used for open-domain question answering. LLMs often struggle with\nthe inherent uncertainties of human communication, leading to\nmisinterpretations, miscommunications, hallucinations, and biased responses.\nThis significantly weakens their ability to be used for tasks like\nfact-checking, question answering, feature extraction, and sentiment analysis.\nUsing open-domain question answering as a test case, we compare off-the-shelf\nand few-shot LLM performance, focusing on measuring the impact of explicit\ndisambiguation strategies. We demonstrate how simple, training-free,\ntoken-level disambiguation methods may be effectively used to improve LLM\nperformance for ambiguous question answering tasks. We empirically show our\nfindings and discuss best practices and broader impacts regarding ambiguity in\nLLMs.",
      "tldr_zh": "本研究探讨大型语言模型（LLMs）是否能理解文本中的歧义问题，以开放域问答（open-domain question answering）为例，分析LLMs在面对不确定性时可能导致的误解、幻觉和偏见，从而影响事实检查、特征提取等任务的表现。研究者比较了现成和少样本学习的LLMs性能，重点评估显式消歧（disambiguation）策略的效果，并证明简单、无需训练的标记级别消歧方法能有效提升歧义问答任务的准确性。通过实证实验，他们展示了这些发现，并讨论了处理LLMs中歧义的最佳实践及其更广泛的影响。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at the REU Symposium at IEEE BigData 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.12395v1",
      "published_date": "2024-11-19 10:27:26 UTC",
      "updated_date": "2024-11-19 10:27:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:10:11.842132"
    },
    {
      "arxiv_id": "2411.12357v1",
      "title": "A Layered Architecture for Developing and Enhancing Capabilities in Large Language Model-based Software Systems",
      "title_zh": "一种分层架构，用于开发和增强基于大语言模型的软件系统的能力",
      "authors": [
        "Dawen Zhang",
        "Xiwei Xu",
        "Chen Wang",
        "Zhenchang Xing",
        "Robert Mao"
      ],
      "abstract": "Significant efforts has been made to expand the use of Large Language Models\n(LLMs) beyond basic language tasks. While the generalizability and versatility\nof LLMs have enabled widespread adoption, evolving demands in application\ndevelopment often exceed their native capabilities. Meeting these demands may\ninvolve a diverse set of methods, such as enhancing creativity through either\ninference temperature adjustments or creativity-provoking prompts. Selecting\nthe right approach is critical, as different methods lead to trade-offs in\nengineering complexity, scalability, and operational costs. This paper\nintroduces a layered architecture that organizes LLM software system\ndevelopment into distinct layers, each characterized by specific attributes. By\naligning capabilities with these layers, the framework encourages the\nsystematic implementation of capabilities in effective and efficient ways that\nultimately supports desired functionalities and qualities. Through practical\ncase studies, we illustrate the utility of the framework. This work offers\ndevelopers actionable insights for selecting suitable technologies in LLM-based\nsoftware system development, promoting robustness and scalability.",
      "tldr_zh": "这篇论文提出了一种分层架构（layered architecture），用于开发和增强 Large Language Models (LLMs) 基于软件系统的能力，以应对其原生局限性。框架将系统开发组织成不同层级，每个层级具有特定属性，帮助开发者系统地选择方法（如调整推理温度或使用提示），从而平衡工程复杂性、可扩展性和运营成本。通过实际案例研究，论文展示了该架构的实用性，并为 LLM-based 系统提供可操作见解，促进其鲁棒性和可扩展性。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL",
        "cs.MA"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.12357v1",
      "published_date": "2024-11-19 09:18:20 UTC",
      "updated_date": "2024-11-19 09:18:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:10:23.317212"
    },
    {
      "arxiv_id": "2411.15191v2",
      "title": "Finding One's Bearings in the Hyperparameter Landscape of a Wide-Kernel Convolutional Fault Detector",
      "title_zh": "翻译失败",
      "authors": [
        "Dan Hudson",
        "Jurgen van den Hoogen",
        "Martin Atzmueller"
      ],
      "abstract": "State-of-the-art algorithms are reported to be almost perfect at\ndistinguishing the vibrations arising from healthy and damaged machine\nbearings, according to benchmark datasets at least. However, what about their\napplication to new data? In this paper, we confirm that neural networks for\nbearing fault detection can be crippled by incorrect hyperparameterisation, and\nalso that the correct hyperparameter settings can change when transitioning to\nnew data. The paper combines multiple methods to explain the behaviour of the\nhyperparameters of a wide-kernel convolutional neural network and how to set\nthem. Since guidance already exists for generic hyperparameters like minibatch\nsize, we focus on how to set architecture-specific hyperparameters such as the\nwidth of the convolutional kernels, a topic which might otherwise be obscure.\nWe reflect different data properties by fusing information from seven different\nbenchmark datasets, and our results show that the kernel size in the first\nlayer in particular is sensitive to changes in the data. Looking deeper, we use\nmanipulated copies of one dataset in an attempt to spot why the kernel size\nsometimes needs to change. The relevance of sampling rate is studied by using\ndifferent levels of resampling, and spectral content is studied by increasingly\nfiltering out high frequencies. We find that, contrary to speculation in\nearlier work, high-frequency noise is not the main reason why a wide kernel is\npreferable to a narrow kernel. Finally, we conclude by stating clear guidance\non how to set the hyperparameters of our neural network architecture to work\neffectively on new data.",
      "tldr_zh": "本研究探讨了宽核卷积神经网络（convolutional neural network）在轴承故障检测中的超参数（hyperparameters）设置问题，指出不正确的超参数配置会削弱模型在新数据上的性能，而最佳设置会随数据变化。论文通过融合七个基准数据集，结合数据操纵（如重采样和过滤高频）的方法，分析了架构特定超参数（如卷积核宽度）的行为，特别是第一层核大小对数据属性的敏感性。主要发现是，高频噪声并非宽核优于窄核的主要原因，并提供了清晰指导，帮助用户在不同数据场景下有效设置超参数，以提升模型的鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "24 pages, 10 figures, 8 tables",
      "pdf_url": "http://arxiv.org/pdf/2411.15191v2",
      "published_date": "2024-11-19 09:17:13 UTC",
      "updated_date": "2025-05-16 11:50:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:10:35.413727"
    },
    {
      "arxiv_id": "2411.13602v2",
      "title": "Translating Electrocardiograms to Cardiac Magnetic Resonance Imaging Useful for Cardiac Assessment and Disease Screening: A Multi-Center Study AI for ECG to CMR Translation Study",
      "title_zh": "翻译失败",
      "authors": [
        "Zhengyao Ding",
        "Ziyu Li",
        "Yujian Hu",
        "Youyao Xu",
        "Chengchen Zhao",
        "Yiheng Mao",
        "Haitao Li",
        "Zhikang Li",
        "Qian Li",
        "Jing Wang",
        "Yue Chen",
        "Mengjia Chen",
        "Longbo Wang",
        "Xuesen Chu",
        "Weichao Pan",
        "Ziyi Liu",
        "Fei Wu",
        "Hongkun Zhang",
        "Ting Chen",
        "Zhengxing Huang"
      ],
      "abstract": "Cardiovascular diseases (CVDs) are the leading cause of global mortality,\nnecessitating accessible and accurate diagnostic tools. While cardiac magnetic\nresonance imaging (CMR) provides gold-standard insights into cardiac structure\nand function, its clinical utility is limited by high cost and complexity. In\ncontrast, electrocardiography (ECG) is inexpensive and widely available but\nlacks the granularity of CMR. We propose CardioNets, a deep learning framework\nthat translates 12-lead ECG signals into CMR-level functional parameters and\nsynthetic images, enabling scalable cardiac assessment. CardioNets integrates\ncross-modal contrastive learning and generative pretraining, aligning ECG with\nCMR-derived cardiac phenotypes and synthesizing high-resolution CMR images via\na masked autoregressive model. Trained on 159,819 samples from five cohorts,\nincluding the UK Biobank (n=42,483) and MIMIC-IV-ECG (n=164,550), and\nexternally validated on independent clinical datasets (n=3,767), CardioNets\nachieved strong performance across disease screening and phenotype estimation\ntasks. In the UK Biobank, it improved cardiac phenotype regression R2 by 24.8%\nand cardiomyopathy AUC by up to 39.3% over baseline models. In MIMIC, it\nincreased AUC for pulmonary hypertension detection by 5.6%. Generated CMR\nimages showed 36.6% higher SSIM and 8.7% higher PSNR than prior approaches. In\na reader study, ECG-only CardioNets achieved 13.9% higher accuracy than human\nphysicians using both ECG and real CMR. These results suggest that CardioNets\noffers a promising, low-cost alternative to CMR for large-scale CVD screening,\nparticularly in resource-limited settings. Future efforts will focus on\nclinical deployment and regulatory validation of ECG-based synthetic imaging.",
      "tldr_zh": "该研究提出 CardioNets 框架，利用深度学习将 12 导联 ECG 信号转化为 CMR 级别的功能参数和合成图像，从而实现可扩展的心脏评估和心血管疾病筛查。框架整合跨模态对比学习、生成预训练以及掩码自回归模型，在 159,819 个样本的多个队列上训练，并通过外部验证显示出优越性能，包括提高心脏表型回归 R2 24.8% 和心肌病检测 AUC 至 39.3%。生成的 CMR 图像在 SSIM 和 PSNR 上分别比现有方法提升 36.6% 和 8.7%，并在读者研究中使 ECG-only 诊断准确率比人类医生高 13.9%。这项创新为资源有限地区提供低成本的 CVD 筛查替代方案，未来将推动临床部署和监管验证。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "27 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.13602v2",
      "published_date": "2024-11-19 09:09:14 UTC",
      "updated_date": "2025-05-15 05:56:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:10:49.395789"
    },
    {
      "arxiv_id": "2411.12350v1",
      "title": "DiM: $f$-Divergence Minimization Guided Sharpness-Aware Optimization for Semi-supervised Medical Image Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Bingli Wang",
        "Houcheng Su",
        "Nan Yin",
        "Mengzhu Wang",
        "Li Shen"
      ],
      "abstract": "As a technique to alleviate the pressure of data annotation, semi-supervised\nlearning (SSL) has attracted widespread attention. In the specific domain of\nmedical image segmentation, semi-supervised methods (SSMIS) have become a\nresearch hotspot due to their ability to reduce the need for large amounts of\nprecisely annotated data. SSMIS focuses on enhancing the model's generalization\nperformance by leveraging a small number of labeled samples and a large number\nof unlabeled samples. The latest sharpness-aware optimization (SAM) technique,\nwhich optimizes the model by reducing the sharpness of the loss function, has\nshown significant success in SSMIS. However, SAM and its variants may not fully\naccount for the distribution differences between different datasets. To address\nthis issue, we propose a sharpness-aware optimization method based on\n$f$-divergence minimization (DiM) for semi-supervised medical image\nsegmentation. This method enhances the model's stability by fine-tuning the\nsensitivity of model parameters and improves the model's adaptability to\ndifferent datasets through the introduction of $f$-divergence. By reducing\n$f$-divergence, the DiM method not only improves the performance balance\nbetween the source and target datasets but also prevents performance\ndegradation due to overfitting on the source dataset.",
      "tldr_zh": "本研究提出了一种基于 $f$-Divergence 最小化 (DiM) 的 Sharpness-Aware Optimization (SAM) 方法，用于半监督医疗图像分割 (SSMIS)，旨在解决传统 SAM 在处理不同数据集分布差异时的不足。DiM 通过微调模型参数的敏感性和减少 $f$-divergence 来提升模型的稳定性和适应性，从而更好地利用少量标注样本和大量未标注样本。实验结果表明，该方法改善了源数据集和目标数据集之间的性能平衡，并有效防止过拟合，提高了 SSMIS 的泛化性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "68T07, 92C55, 62H35",
        "I.2.6; I.4.10; J.3"
      ],
      "primary_category": "cs.CV",
      "comment": "8page",
      "pdf_url": "http://arxiv.org/pdf/2411.12350v1",
      "published_date": "2024-11-19 09:07:26 UTC",
      "updated_date": "2024-11-19 09:07:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:13:00.071972"
    },
    {
      "arxiv_id": "2411.12319v2",
      "title": "CLIP Unreasonable Potential in Single-Shot Face Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Nhan T. Luu"
      ],
      "abstract": "Face recognition is a core task in computer vision designed to identify and\nauthenticate individuals by analyzing facial patterns and features. This field\nintersects with artificial intelligence image processing and machine learning\nwith applications in security authentication and personalization. Traditional\napproaches in facial recognition focus on capturing facial features like the\neyes, nose and mouth and matching these against a database to verify\nidentities. However challenges such as high false positive rates have persisted\noften due to the similarity among individuals facial features. Recently\nContrastive Language Image Pretraining (CLIP) a model developed by OpenAI has\nshown promising advancements by linking natural language processing with vision\ntasks allowing it to generalize across modalities. Using CLIP's vision language\ncorrespondence and single-shot finetuning the model can achieve lower false\npositive rates upon deployment without the need of mass facial features\nextraction. This integration demonstrating CLIP's potential to address\npersistent issues in face recognition model performance without complicating\nour training paradigm.",
      "tldr_zh": "该论文探讨了 OpenAI 开发的 CLIP 模型在单次人脸识别（single-shot face recognition）中的巨大潜力，通过整合视觉语言对应（vision-language correspondence）来提升识别性能。传统人脸识别方法依赖于提取面部特征（如眼睛、鼻子和嘴巴），但常面临高假阳性率（false positive rates）等问题，而 CLIP 通过单次微调（single-shot finetuning）无需大量特征提取，即可显著降低这些问题。实验结果表明，CLIP 能有效改善人脸识别的准确性和泛化能力，为安全认证等领域提供更可靠的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.12319v2",
      "published_date": "2024-11-19 08:23:52 UTC",
      "updated_date": "2024-11-20 03:31:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:11:09.975585"
    },
    {
      "arxiv_id": "2411.15189v3",
      "title": "Order is All You Need for Categorical Data Clustering",
      "title_zh": "翻译失败",
      "authors": [
        "Yiqun Zhang",
        "Mingjie Zhao",
        "Hong Jia",
        "Yang Lu",
        "Mengke Li",
        "Yiu-ming Cheung"
      ],
      "abstract": "Categorical data composed of qualitative valued attributes are ubiquitous in\nmachine learning tasks. Due to the lack of well-defined metric space,\ncategorical data distributions are difficult to be intuitively understood.\nClustering is a popular data analysis technique suitable for data distribution\nunderstanding. However, the success of clustering often relies on reasonable\ndistance metrics, which happens to be what categorical data naturally lack.\nThis paper therefore introduces a new finding that the order relation among\nattribute values is the decisive factor in clustering accuracy, and is also the\nkey to understanding categorical data clusters, because the essence of\nclustering is to order the clusters in terms of their admission to samples. To\nobtain the orders, we propose a new learning paradigm that allows joint\nlearning of clusters and the orders. It alternatively partitions the data into\nclusters based on the distance metric built upon the orders and estimates the\nmost likely orders according to the clusters. The algorithm achieves superior\nclustering accuracy with a convergence guarantee, and the learned orders\nfacilitate the understanding of the non-intuitive cluster distribution of\ncategorical data. Extensive experiments with ablation studies, statistical\nevidence, and case studies have validated the new insight into the importance\nof value order and the method proposition. The source code is temporarily\nopened in https://anonymous.4open.science/r/OCL-demo.",
      "tldr_zh": "本文发现，对于分类数据（categorical data）聚类，属性值之间的顺序关系（order relation）是决定准确性的关键因素，因为聚类的本质在于根据样本准入对集群排序，从而帮助理解数据分布。作者提出一个新的学习范式，通过交替基于顺序构建的距离度量（distance metrics）分区数据，并据此估计最可能的顺序，实现聚类和顺序的联合学习。该算法在实验中表现出优越的聚类准确性，具有收敛保证，并通过广泛的消融研究、统计证据和案例研究验证了顺序关系的重要性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.15189v3",
      "published_date": "2024-11-19 08:23:25 UTC",
      "updated_date": "2025-04-18 12:15:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:11:23.221096"
    },
    {
      "arxiv_id": "2411.12308v3",
      "title": "SNN-Based Online Learning of Concepts and Action Laws in an Open World",
      "title_zh": "基于 SNN 的开放世界中概念",
      "authors": [
        "Christel Grimaud",
        "Dominique Longin",
        "Andreas Herzig"
      ],
      "abstract": "We present the architecture of a fully autonomous, bio-inspired cognitive\nagent built around a spiking neural network (SNN) implementing the agent's\nsemantic memory. This agent explores its universe and learns concepts of\nobjects/situations and of its own actions in a one-shot manner. While\nobject/situation concepts are unary, action concepts are triples made up of an\ninitial situation, a motor activity, and an outcome. They embody the agent's\nknowledge of its universe's action laws. Both kinds of concepts have different\ndegrees of generality. To make decisions the agent queries its semantic memory\nfor the expected outcomes of envisaged actions and chooses the action to take\non the basis of these predictions. Our experiments show that the agent handles\nnew situations by appealing to previously learned general concepts and rapidly\nmodifies its concepts to adapt to environment changes.",
      "tldr_zh": "这篇论文提出了一种基于 SNN (Spiking Neural Network) 的自主认知代理架构，用于在开放世界中在线学习对象/情况概念和动作规律。代理能够一次性学习单元概念（如对象/情况）和三元组动作概念（包括初始情况、运动活动和结果），从而掌握环境的动作法则，并通过查询语义 memory 进行决策预测。实验结果显示，该代理能有效处理新情况，利用先前学习的一般概念，并快速适应环境变化。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.NE",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.12308v3",
      "published_date": "2024-11-19 07:49:22 UTC",
      "updated_date": "2025-04-23 13:28:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:11:34.699843"
    },
    {
      "arxiv_id": "2411.12307v1",
      "title": "Balancing Accuracy and Efficiency in Multi-Turn Intent Classification for LLM-Powered Dialog Systems in Production",
      "title_zh": "在生产环境中平衡",
      "authors": [
        "Junhua Liu",
        "Yong Keat Tan",
        "Bin Fu",
        "Kwan Hui Lim"
      ],
      "abstract": "Accurate multi-turn intent classification is essential for advancing\nconversational AI systems. However, challenges such as the scarcity of\ncomprehensive datasets and the complexity of contextual dependencies across\ndialogue turns hinder progress. This paper presents two novel approaches\nleveraging Large Language Models (LLMs) to enhance scalability and reduce\nlatency in production dialogue systems. First, we introduce Symbol Tuning,\nwhich simplifies intent labels to reduce task complexity and improve\nperformance in multi-turn dialogues. Second, we propose C-LARA\n(Consistency-aware, Linguistics Adaptive Retrieval Augmentation), a framework\nthat employs LLMs for data augmentation and pseudo-labeling to generate\nsynthetic multi-turn dialogues. These enriched datasets are used to fine-tune a\nsmall, efficient model suitable for deployment. Experiments conducted on\nmultilingual dialogue datasets demonstrate significant improvements in\nclassification accuracy and resource efficiency. Our methods enhance multi-turn\nintent classification accuracy by 5.09%, reduce annotation costs by 40%, and\nenable scalable deployment in low-resource multilingual industrial systems,\nhighlighting their practicality and impact.",
      "tldr_zh": "这篇论文探讨了在生产环境中基于Large Language Models (LLMs)的对话系统中，如何平衡多轮意图分类的准确性和效率。论文提出两种创新方法：Symbol Tuning，通过简化意图标签来降低任务复杂性并提升多轮对话性能；以及C-LARA（Consistency-aware, Linguistics Adaptive Retrieval Augmentation）框架，利用LLMs进行数据增强和伪标签生成，以创建合成多轮对话数据集，并微调小型高效模型。实验结果显示，在多语言对话数据集上，该方法将意图分类准确率提高了5.09%，减少了40%的标注成本，并实现了在低资源多语言工业系统中的可扩展部署。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.12307v1",
      "published_date": "2024-11-19 07:48:35 UTC",
      "updated_date": "2024-11-19 07:48:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:11:47.054498"
    },
    {
      "arxiv_id": "2411.13599v2",
      "title": "Can ChatGPT Overcome Behavioral Biases in the Financial Sector? Classify-and-Rethink: Multi-Step Zero-Shot Reasoning in the Gold Investment",
      "title_zh": "翻译失败",
      "authors": [
        "Shuoling Liu",
        "Gaoguo Jia",
        "Yuhang Jiang",
        "Liyuan Chen",
        "Qiang Yang"
      ],
      "abstract": "Large Language Models (LLMs) have achieved remarkable success recently,\ndisplaying exceptional capabilities in creating understandable and organized\ntext. These LLMs have been utilized in diverse fields, such as clinical\nresearch, where domain-specific models like Med-Palm have achieved human-level\nperformance. Recently, researchers have employed advanced prompt engineering to\nenhance the general reasoning ability of LLMs. Despite the remarkable success\nof zero-shot Chain-of-Thoughts (CoT) in solving general reasoning tasks, the\npotential of these methods still remains paid limited attention in the\nfinancial reasoning task.To address this issue, we explore multiple prompt\nstrategies and incorporated semantic news information to improve LLMs'\nperformance on financial reasoning tasks.To the best of our knowledge, we are\nthe first to explore this important issue by applying ChatGPT to the gold\ninvestment.In this work, our aim is to investigate the financial reasoning\ncapabilities of LLMs and their capacity to generate logical and persuasive\ninvestment opinions. We will use ChatGPT, one of the most powerful LLMs\nrecently, and prompt engineering to achieve this goal. Our research will focus\non understanding the ability of LLMs in sophisticated analysis and reasoning\nwithin the context of investment decision-making. Our study finds that ChatGPT\nwith CoT prompt can provide more explainable predictions and overcome\nbehavioral biases, which is crucial in finance-related tasks and can achieve\nhigher investment returns.",
      "tldr_zh": "本文研究探讨了 ChatGPT 是否能克服金融领域的行为偏差，特别针对金投资任务，通过 Classify-and-Rethink 的多步零-shot 推理方法和 Chain-of-Thought (CoT) 提示策略，结合语义新闻信息来提升 LLMs 的金融推理能力。该方法首次将 ChatGPT 应用于金投资场景，能够生成更逻辑性和说服力的投资意见。研究发现，ChatGPT with CoT 提示能提供更可解释的预测，减少行为偏差，并实现更高的投资回报。",
      "categories": [
        "q-fin.ST",
        "cs.AI"
      ],
      "primary_category": "q-fin.ST",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.13599v2",
      "published_date": "2024-11-19 07:45:58 UTC",
      "updated_date": "2025-01-16 03:17:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:13:58.797797"
    },
    {
      "arxiv_id": "2411.12778v1",
      "title": "Lucia: A Temporal Computing Platform for Contextual Intelligence",
      "title_zh": "Lucia：用于上下文智能的时序计算平台",
      "authors": [
        "Weizhe Lin",
        "Junxiao Shen"
      ],
      "abstract": "The rapid evolution of artificial intelligence, especially through\nmulti-modal large language models, has redefined user interactions, enabling\nresponses that are contextually rich and human-like. As AI becomes an integral\npart of daily life, a new frontier has emerged: developing systems that not\nonly understand spatial and sensory data but also interpret temporal contexts\nto build long-term, personalized memories. This report introduces Lucia, an\nopen-source Temporal Computing Platform designed to enhance human cognition by\ncapturing and utilizing continuous contextual memory. Lucia introduces a\nlightweight, wearable device that excels in both comfort and real-time data\naccessibility, distinguishing itself from existing devices that typically\nprioritize either wearability or perceptual capabilities alone. By recording\nand interpreting daily activities over time, Lucia enables users to access a\nrobust temporal memory, enhancing cognitive processes such as decision-making\nand memory recall.",
      "tldr_zh": "这篇论文介绍了 Lucia，一个开源的 Temporal Computing Platform，旨在通过捕捉和利用连续的上下文记忆来增强人类认知。Lucia 采用一个轻量级可穿戴设备，兼顾舒适性和实时数据访问，与现有设备不同的是它同时强调可穿戴性和感知能力。平台通过记录和解释日常活动，帮助用户构建长期个性化记忆，从而提升决策和记忆回想等认知过程。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.12778v1",
      "published_date": "2024-11-19 07:38:31 UTC",
      "updated_date": "2024-11-19 07:38:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:12:10.966109"
    },
    {
      "arxiv_id": "2411.12290v1",
      "title": "SSEditor: Controllable Mask-to-Scene Generation with Diffusion Model",
      "title_zh": "翻译失败",
      "authors": [
        "Haowen Zheng",
        "Yanyan Liang"
      ],
      "abstract": "Recent advancements in 3D diffusion-based semantic scene generation have\ngained attention. However, existing methods rely on unconditional generation\nand require multiple resampling steps when editing scenes, which significantly\nlimits their controllability and flexibility. To this end, we propose SSEditor,\na controllable Semantic Scene Editor that can generate specified target\ncategories without multiple-step resampling. SSEditor employs a two-stage\ndiffusion-based framework: (1) a 3D scene autoencoder is trained to obtain\nlatent triplane features, and (2) a mask-conditional diffusion model is trained\nfor customizable 3D semantic scene generation. In the second stage, we\nintroduce a geometric-semantic fusion module that enhance the model's ability\nto learn geometric and semantic information. This ensures that objects are\ngenerated with correct positions, sizes, and categories. Extensive experiments\non SemanticKITTI and CarlaSC demonstrate that SSEditor outperforms previous\napproaches in terms of controllability and flexibility in target generation, as\nwell as the quality of semantic scene generation and reconstruction. More\nimportantly, experiments on the unseen Occ-3D Waymo dataset show that SSEditor\nis capable of generating novel urban scenes, enabling the rapid construction of\n3D scenes.",
      "tldr_zh": "本研究提出SSEditor，一种基于Diffusion Model的可控3D语义场景生成框架，旨在解决现有方法依赖无条件生成和多次重采样的局限性。该框架采用两阶段设计：首先训练一个3D场景自动编码器来提取潜在triplane特征，其次开发mask-conditional扩散模型，并引入geometric-semantic fusion module，以确保对象在位置、大小和类别上的准确生成。实验结果显示，SSEditor在SemanticKITTI和CarlaSC数据集上优于现有方法，在生成质量、可控性和灵活性方面表现突出；此外，在未见数据集Occ-3D Waymo上，它能快速构建新颖的城市场景。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.12290v1",
      "published_date": "2024-11-19 07:19:05 UTC",
      "updated_date": "2024-11-19 07:19:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:14:10.627810"
    },
    {
      "arxiv_id": "2411.12276v1",
      "title": "libcll: an Extendable Python Toolkit for Complementary-Label Learning",
      "title_zh": "libcll：一个可扩展的 Python 工具包，用于互补标签学习",
      "authors": [
        "Nai-Xuan Ye",
        "Tan-Ha Mai",
        "Hsiu-Hsuan Wang",
        "Wei-I Lin",
        "Hsuan-Tien Lin"
      ],
      "abstract": "Complementary-label learning (CLL) is a weakly supervised learning paradigm\nfor multiclass classification, where only complementary labels -- indicating\nclasses an instance does not belong to -- are provided to the learning\nalgorithm. Despite CLL's increasing popularity, previous studies highlight two\nmain challenges: (1) inconsistent results arising from varied assumptions on\ncomplementary label generation, and (2) high barriers to entry due to the lack\nof a standardized evaluation platform across datasets and algorithms. To\naddress these challenges, we introduce \\texttt{libcll}, an extensible Python\ntoolkit for CLL research. \\texttt{libcll} provides a universal interface that\nsupports a wide range of generation assumptions, both synthetic and real-world\ndatasets, and key CLL algorithms. The toolkit is designed to mitigate\ninconsistencies and streamline the research process, with easy installation,\ncomprehensive usage guides, and quickstart tutorials that facilitate efficient\nadoption and implementation of CLL techniques. Extensive ablation studies\nconducted with \\texttt{libcll} demonstrate its utility in generating valuable\ninsights to advance future CLL research.",
      "tldr_zh": "Complementary-Label Learning (CLL) 是一种弱监督多类分类方法，仅提供实例不属于的互补标签，但面临标签生成假设不一致和缺乏标准化评估平台等挑战。\n研究团队开发了 libcll，一个可扩展的 Python 工具包，提供通用接口，支持多种生成假设、合成及真实数据集，以及关键 CLL 算法，以减少不一致性和简化研究过程。\n该工具包包括易安装的使用指南和快速入门教程，并通过广泛的消融研究，展示了其在生成宝贵见解和推进 CLL 研究方面的实用价值。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.12276v1",
      "published_date": "2024-11-19 06:56:24 UTC",
      "updated_date": "2024-11-19 06:56:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:14:22.224864"
    },
    {
      "arxiv_id": "2411.12275v1",
      "title": "Building Trust: Foundations of Security, Safety and Transparency in AI",
      "title_zh": "翻译失败",
      "authors": [
        "Huzaifa Sidhpurwala",
        "Garth Mollett",
        "Emily Fox",
        "Mark Bestavros",
        "Huamin Chen"
      ],
      "abstract": "This paper explores the rapidly evolving ecosystem of publicly available AI\nmodels, and their potential implications on the security and safety landscape.\nAs AI models become increasingly prevalent, understanding their potential risks\nand vulnerabilities is crucial. We review the current security and safety\nscenarios while highlighting challenges such as tracking issues, remediation,\nand the apparent absence of AI model lifecycle and ownership processes.\nComprehensive strategies to enhance security and safety for both model\ndevelopers and end-users are proposed. This paper aims to provide some of the\nfoundational pieces for more standardized security, safety, and transparency in\nthe development and operation of AI models and the larger open ecosystems and\ncommunities forming around them.",
      "tldr_zh": "这篇论文探讨了公开可用的 AI 模型生态系统的快速演变及其对 security 和 safety 景观的潜在影响，强调了理解模型风险和漏洞的重要性。作者回顾了当前挑战，如跟踪问题、补救措施缺失以及 AI 模型生命周期和所有权过程的缺乏，并提出了全面策略来提升模型开发者和最终用户的 security 和 safety。该研究旨在为 AI 模型开发和操作提供标准化 security、safety 和 transparency 的基础框架。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.12275v1",
      "published_date": "2024-11-19 06:55:57 UTC",
      "updated_date": "2024-11-19 06:55:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:14:33.693921"
    },
    {
      "arxiv_id": "2411.12256v2",
      "title": "Restructuring Tractable Probabilistic Circuits",
      "title_zh": "翻译失败",
      "authors": [
        "Honghua Zhang",
        "Benjie Wang",
        "Marcelo Arenas",
        "Guy Van den Broeck"
      ],
      "abstract": "Probabilistic circuits (PCs) are a unifying representation for probabilistic\nmodels that support tractable inference. Numerous applications of PCs like\ncontrollable text generation depend on the ability to efficiently multiply two\ncircuits. Existing multiplication algorithms require that the circuits respect\nthe same structure, i.e. variable scopes decomposes according to the same\nvtree. In this work, we propose and study the task of restructuring\nstructured(-decomposable) PCs, that is, transforming a structured PC such that\nit conforms to a target vtree. We propose a generic approach for this problem\nand show that it leads to novel polynomial-time algorithms for multiplying\ncircuits respecting different vtrees, as well as a practical depth-reduction\nalgorithm that preserves structured decomposibility. Our work opens up new\navenues for tractable PC inference, suggesting the possibility of training with\nless restrictive PC structures while enabling efficient inference by changing\ntheir structures at inference time.",
      "tldr_zh": "Probabilistic Circuits (PCs) 是一种支持可计算推理的概率模型统一表示，但现有乘法算法要求电路遵循相同的 vtree 结构，导致灵活性不足。本文提出并研究了 restructuring structured-decomposable PCs 的任务，即通过一种通用方法将结构化 PC 转化为符合目标 vtree 的形式，从而实现高效运算。实验结果显示，该方法产生了新的多项式时间算法，用于乘以不同 vtree 的电路，以及一个保留结构可分解性的深度减少算法，最终为训练时使用更灵活的 PC 结构、在推理时优化效率开辟了新途径。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.12256v2",
      "published_date": "2024-11-19 06:10:22 UTC",
      "updated_date": "2025-04-30 06:42:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:14:45.478004"
    },
    {
      "arxiv_id": "2411.12255v1",
      "title": "Error-Feedback Model for Output Correction in Bilateral Control-Based Imitation Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Hiroshi Sato",
        "Masashi Konosu",
        "Sho Sakaino",
        "Toshiaki Tsuji"
      ],
      "abstract": "In recent years, imitation learning using neural networks has enabled robots\nto perform flexible tasks. However, since neural networks operate in a\nfeedforward structure, they do not possess a mechanism to compensate for output\nerrors. To address this limitation, we developed a feedback mechanism to\ncorrect these errors. By employing a hierarchical structure for neural networks\ncomprising lower and upper layers, the lower layer was controlled to follow the\nupper layer. Additionally, using a multi-layer perceptron in the lower layer,\nwhich lacks an internal state, enhanced the error feedback. In the\ncharacter-writing task, this model demonstrated improved accuracy in writing\npreviously untrained characters. In the character-writing task, this model\ndemonstrated improved accuracy in writing previously untrained characters.\nThrough autonomous control with error feedback, we confirmed that the lower\nlayer could effectively track the output of the upper layer. This study\nrepresents a promising step toward integrating neural networks with control\ntheories.",
      "tldr_zh": "本文提出了一种基于双边控制的Error-Feedback Model，用于纠正imitation learning中神经网络输出错误的局限性。该模型采用分层神经网络结构，包括上层和下层，其中下层使用multi-layer perceptron来跟随上层输出，并增强错误反馈机制。在字符书写任务中，该模型显著提高了书写未训练字符的准确性，并通过自主控制实验证实下层能有效跟踪上层输出。该研究为神经网络与控制理论的整合提供了有前景的进展。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.12255v1",
      "published_date": "2024-11-19 06:09:09 UTC",
      "updated_date": "2024-11-19 06:09:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:14:58.262093"
    },
    {
      "arxiv_id": "2411.12246v1",
      "title": "Efficient Training in Multi-Agent Reinforcement Learning: A Communication-Free Framework for the Box-Pushing Problem",
      "title_zh": "翻译失败",
      "authors": [
        "David Ge",
        "Hao Ji"
      ],
      "abstract": "Self-organizing systems consist of autonomous agents that can perform complex\ntasks and adapt to dynamic environments without a central controller. Prior\nresearch often relies on reinforcement learning to enable agents to gain the\nskills needed for task completion, such as in the box-pushing environment.\nHowever, when agents push from opposing directions during exploration, they\ntend to exert equal and opposite forces on the box, resulting in minimal\ndisplacement and inefficient training. This paper proposes a model called\nShared Pool of Information (SPI), which enables information to be accessible to\nall agents and facilitates coordination, reducing force conflicts among agents\nand enhancing exploration efficiency. Through computer simulations, we\ndemonstrate that SPI not only expedites the training process but also requires\nfewer steps per episode, significantly improving the agents' collaborative\neffectiveness.",
      "tldr_zh": "本研究针对多代理强化学习(Multi-Agent Reinforcement Learning)中的训练效率问题，特别是在箱子推动(Box-Pushing Problem)环境中，代理从相反方向推动物体时导致力量抵消和探索低效。论文提出了一种无通信框架Shared Pool of Information (SPI)模型，让所有代理能够访问共享信息，从而促进协调并减少冲突。通过计算机模拟实验，证明SPI显著加速训练过程，减少每轮步骤，并提升代理的协作有效性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "17 pages, 16 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.12246v1",
      "published_date": "2024-11-19 05:51:10 UTC",
      "updated_date": "2024-11-19 05:51:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:15:58.514848"
    },
    {
      "arxiv_id": "2411.12240v2",
      "title": "Evaluating Tokenizer Performance of Large Language Models Across Official Indian Languages",
      "title_zh": "翻译失败",
      "authors": [
        "S. Tamang",
        "D. J. Bora"
      ],
      "abstract": "Large Language Models (LLMs) based on transformer architectures have\nrevolutionized a variety of domains, with tokenization playing a pivotal role\nin their pre-processing and fine-tuning stages. In multilingual models,\nparticularly those tailored for Indic languages, effective tokenization is\ncrucial for optimizing performance. This paper presents a comprehensive\nevaluation of tokenizers used by 12 LLMs across all 22 official languages of\nIndia, with a focus on comparing the efficiency of their tokenization\nprocesses. We employed the Normalized Sequence Length (NSL) as a key metric in\nour analysis. Our findings reveal that the SUTRA tokenizer outperforms all\nother models, including several Indic-specific models, excelling in 14\nlanguages. Notable insights include the SUTRA tokenizer's superior handling of\nIndic languages, GPT-4o's advancement over its predecessor GPT-4 in processing\nIndian languages, and the limited performance of Project Indus in certain\nlanguages. This study underscores the critical importance of developing\ntargeted tokenization strategies for multilingual and Indic-centric models,\nlaying the groundwork for future improvements in tokenizer design to enhance\nlinguistic coverage and model efficiency.",
      "tldr_zh": "这篇论文评估了12个Large Language Models (LLMs) 的tokenizers在22种印度官方语言上的性能，使用Normalized Sequence Length (NSL)作为关键指标，重点比较其处理效率。研究发现，SUTRA tokenizer在14种语言上表现出色，优于其他模型，包括特定Indic语言模型；此外，GPT-4o比GPT-4在处理印度语言方面有所进步，而Project Indus在某些语言表现有限。主要贡献在于强调了针对多语言和Indic-centric模型开发优化tokenization策略的重要性，以提升语言覆盖和模型效率。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.12240v2",
      "published_date": "2024-11-19 05:37:17 UTC",
      "updated_date": "2024-11-26 18:14:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:15:22.673011"
    },
    {
      "arxiv_id": "2411.14476v1",
      "title": "StreetviewLLM: Extracting Geographic Information Using a Chain-of-Thought Multimodal Large Language Model",
      "title_zh": "StreetviewLLM：使用链式思维多模态大语言模型提取地理信息",
      "authors": [
        "Zongrong Li",
        "Junhao Xu",
        "Siqin Wang",
        "Yifan Wu",
        "Haiyang Li"
      ],
      "abstract": "Geospatial predictions are crucial for diverse fields such as disaster\nmanagement, urban planning, and public health. Traditional machine learning\nmethods often face limitations when handling unstructured or multi-modal data\nlike street view imagery. To address these challenges, we propose\nStreetViewLLM, a novel framework that integrates a large language model with\nthe chain-of-thought reasoning and multimodal data sources. By combining street\nview imagery with geographic coordinates and textual data, StreetViewLLM\nimproves the precision and granularity of geospatial predictions. Using\nretrieval-augmented generation techniques, our approach enhances geographic\ninformation extraction, enabling a detailed analysis of urban environments. The\nmodel has been applied to seven global cities, including Hong Kong, Tokyo,\nSingapore, Los Angeles, New York, London, and Paris, demonstrating superior\nperformance in predicting urban indicators, including population density,\naccessibility to healthcare, normalized difference vegetation index, building\nheight, and impervious surface. The results show that StreetViewLLM\nconsistently outperforms baseline models, offering improved predictive accuracy\nand deeper insights into the built environment. This research opens new\nopportunities for integrating the large language model into urban analytics,\ndecision-making in urban planning, infrastructure management, and environmental\nmonitoring.",
      "tldr_zh": "本文提出 StreetViewLLM 框架，利用 Chain-of-Thought 推理的多模态大型语言模型，整合街景图像、地理坐标和文本数据，以解决传统机器学习在处理非结构化多模态数据时的局限性。框架通过检索增强生成（RAG）技术提升地理信息提取的精确性和粒度，在七个全球城市（如香港、東京和纽约）中预测城市指标，包括人口密度、医疗可达性、NDVI、建筑物高度和不透水表面。实验结果显示，StreetViewLLM 显著优于基线模型，提供更高的预测准确性和对建成环境的深入洞察，为城市规划、基础设施管理和环境监测等领域带来新机遇。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.14476v1",
      "published_date": "2024-11-19 05:15:19 UTC",
      "updated_date": "2024-11-19 05:15:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:15:35.080505"
    },
    {
      "arxiv_id": "2411.12775v1",
      "title": "Revisiting Fake News Detection: Towards Temporality-aware Evaluation by Leveraging Engagement Earliness",
      "title_zh": "翻译失败",
      "authors": [
        "Junghoon Kim",
        "Junmo Lee",
        "Yeonjun In",
        "Kanghoon Yoon",
        "Chanyoung Park"
      ],
      "abstract": "Social graph-based fake news detection aims to identify news articles\ncontaining false information by utilizing social contexts, e.g., user\ninformation, tweets and comments. However, conventional methods are evaluated\nunder less realistic scenarios, where the model has access to future knowledge\non article-related and context-related data during training. In this work, we\nnewly formalize a more realistic evaluation scheme that mimics real-world\nscenarios, where the data is temporality-aware and the detection model can only\nbe trained on data collected up to a certain point in time. We show that the\ndiscriminative capabilities of conventional methods decrease sharply under this\nnew setting, and further propose DAWN, a method more applicable to such\nscenarios. Our empirical findings indicate that later engagements (e.g.,\nconsuming or reposting news) contribute more to noisy edges that link real\nnews-fake news pairs in the social graph. Motivated by this, we utilize feature\nrepresentations of engagement earliness to guide an edge weight estimator to\nsuppress the weights of such noisy edges, thereby enhancing the detection\nperformance of DAWN. Through extensive experiments, we demonstrate that DAWN\noutperforms existing fake news detection methods under real-world environments.\nThe source code is available at https://github.com/LeeJunmo/DAWN.",
      "tldr_zh": "本研究重新审视了基于社交图谱的假新闻检测问题，强调了时间感知（temporality-aware）评估的重要性，因为传统方法在训练时依赖未来数据，导致不现实的场景。作者提出了一种新的评估方案，仅使用历史数据进行训练，并开发了DAWN方法，通过利用互动早期的特征（engagement earliness）来指导边权重估计器，抑制噪声边（如真实新闻与假新闻间的链接），从而提升检测性能。实验结果显示，DAWN在真实环境中显著优于现有方法，证明了其在社交图谱中处理时间动态的有效性。",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.SI",
      "comment": "WSDM 2025",
      "pdf_url": "http://arxiv.org/pdf/2411.12775v1",
      "published_date": "2024-11-19 05:08:00 UTC",
      "updated_date": "2024-11-19 05:08:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:15:45.883822"
    },
    {
      "arxiv_id": "2411.12222v1",
      "title": "Contrast Similarity-Aware Dual-Pathway Mamba for Multivariate Time Series Node Classification",
      "title_zh": "对比相似性感知的双路径 Mamba 用于多变量时间序列节点分类",
      "authors": [
        "Mingsen Du",
        "Meng Chen",
        "Yongjian Li",
        "Xiuxin Zhang",
        "Jiahui Gao",
        "Cun Ji",
        "Shoushui Wei"
      ],
      "abstract": "Multivariate time series (MTS) data is generated through multiple sensors\nacross various domains such as engineering application, health monitoring, and\nthe internet of things, characterized by its temporal changes and high\ndimensional characteristics. Over the past few years, many studies have\nexplored the long-range dependencies and similarities in MTS. However,\nlong-range dependencies are difficult to model due to their temporal changes\nand high dimensionality makes it difficult to obtain similarities effectively\nand efficiently. Thus, to address these issues, we propose contrast\nsimilarity-aware dual-pathway Mamba for MTS node classification (CS-DPMamba).\nFirstly, to obtain the dynamic similarity of each sample, we initially use\ntemporal contrast learning module to acquire MTS representations. And then we\nconstruct a similarity matrix between MTS representations using Fast Dynamic\nTime Warping (FastDTW). Secondly, we apply the DPMamba to consider the\nbidirectional nature of MTS, allowing us to better capture long-range and\nshort-range dependencies within the data. Finally, we utilize the\nKolmogorov-Arnold Network enhanced Graph Isomorphism Network to complete the\ninformation interaction in the matrix and MTS node classification task. By\ncomprehensively considering the long-range dependencies and dynamic similarity\nfeatures, we achieved precise MTS node classification. We conducted experiments\non multiple University of East Anglia (UEA) MTS datasets, which encompass\ndiverse application scenarios. Our results demonstrate the superiority of our\nmethod through both supervised and semi-supervised experiments on the MTS\nclassification task.",
      "tldr_zh": "该研究针对多变量时间序列 (MTS) 的高维度和时间变化特性，提出了一种 Contrast Similarity-Aware Dual-Pathway Mamba (CS-DPMamba) 方法，以有效捕捉长程依赖和动态相似性，用于 MTS 节点分类。\n方法首先利用时间对比学习模块获取 MTS 表示，并通过 Fast Dynamic Time Warping (FastDTW) 构建相似性矩阵；随后，应用 Dual-Pathway Mamba (DPMamba) 来处理 MTS 的双向依赖；最后，使用 Kolmogorov-Arnold Network 增强的 Graph Isomorphism Network (GIN) 进行信息交互和分类。\n实验结果显示，该方法在多个 University of East Anglia (UEA) MTS 数据集上的监督和半监督任务中，显著提高了分类准确性，证明了其在处理 MTS 问题方面的优越性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Submitted to Knowledge-Based Systems on Nov 17, 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.12222v1",
      "published_date": "2024-11-19 04:32:41 UTC",
      "updated_date": "2024-11-19 04:32:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:16:01.381090"
    },
    {
      "arxiv_id": "2411.12220v2",
      "title": "DeTrigger: A Gradient-Centric Approach to Backdoor Attack Mitigation in Federated Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Kichang Lee",
        "Yujin Shin",
        "Jonghyuk Yun",
        "Songkuk Kim",
        "Jun Han",
        "JeongGil Ko"
      ],
      "abstract": "Federated Learning (FL) enables collaborative model training across\ndistributed devices while preserving local data privacy, making it ideal for\nmobile and embedded systems. However, the decentralized nature of FL also opens\nvulnerabilities to model poisoning attacks, particularly backdoor attacks,\nwhere adversaries implant trigger patterns to manipulate model predictions. In\nthis paper, we propose DeTrigger, a scalable and efficient backdoor-robust\nfederated learning framework that leverages insights from adversarial attack\nmethodologies. By employing gradient analysis with temperature scaling,\nDeTrigger detects and isolates backdoor triggers, allowing for precise model\nweight pruning of backdoor activations without sacrificing benign model\nknowledge. Extensive evaluations across four widely used datasets demonstrate\nthat DeTrigger achieves up to 251x faster detection than traditional methods\nand mitigates backdoor attacks by up to 98.9%, with minimal impact on global\nmodel accuracy. Our findings establish DeTrigger as a robust and scalable\nsolution to protect federated learning environments against sophisticated\nbackdoor threats.",
      "tldr_zh": "本文提出 DeTrigger，一种以梯度分析为核心的框架，用于缓解 Federated Learning (FL) 中的后门攻击，该方法通过梯度分析结合温度缩放来检测和隔离后门触发器，并进行精确的模型权重修剪，同时保留正常模型知识。实验结果显示，在四个常用数据集上，DeTrigger 的检测速度比传统方法快 251 倍，能将后门攻击缓解率提高至 98.9%，并对全局模型准确率的影响最小。该框架为保护分布式学习环境免受后门威胁提供了可扩展的鲁棒解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "68T07",
        "I.2.11"
      ],
      "primary_category": "cs.LG",
      "comment": "21 pages",
      "pdf_url": "http://arxiv.org/pdf/2411.12220v2",
      "published_date": "2024-11-19 04:12:14 UTC",
      "updated_date": "2025-02-03 16:20:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:16:12.982910"
    },
    {
      "arxiv_id": "2411.12198v2",
      "title": "CCIS-Diff: A Generative Model with Stable Diffusion Prior for Controlled Colonoscopy Image Synthesis",
      "title_zh": "CCIS-Diff：一种带有 Stable Diffusion 先验的生成模型，用于受控结肠镜图像合成",
      "authors": [
        "Yifan Xie",
        "Jingge Wang",
        "Tao Feng",
        "Fei Ma",
        "Yang Li"
      ],
      "abstract": "Colonoscopy is crucial for identifying adenomatous polyps and preventing\ncolorectal cancer. However, developing robust models for polyp detection is\nchallenging by the limited size and accessibility of existing colonoscopy\ndatasets. While previous efforts have attempted to synthesize colonoscopy\nimages, current methods suffer from instability and insufficient data\ndiversity. Moreover, these approaches lack precise control over the generation\nprocess, resulting in images that fail to meet clinical quality standards. To\naddress these challenges, we propose CCIS-DIFF, a Controlled generative model\nfor high-quality Colonoscopy Image Synthesis based on a Diffusion architecture.\nOur method offers precise control over both the spatial attributes (polyp\nlocation and shape) and clinical characteristics of polyps that align with\nclinical descriptions. Specifically, we introduce a blur mask weighting\nstrategy to seamlessly blend synthesized polyps with the colonic mucosa, and a\ntext-aware attention mechanism to guide the generated images to reflect\nclinical characteristics. Notably, to achieve this, we construct a new\nmulti-modal colonoscopy dataset that integrates images, mask annotations, and\ncorresponding clinical text descriptions. Experimental results demonstrate that\nour method generates high-quality, diverse colonoscopy images with fine control\nover both spatial constraints and clinical consistency, offering valuable\nsupport for downstream segmentation and diagnostic tasks.",
      "tldr_zh": "本文提出 CCIS-Diff，一种基于 Stable Diffusion Prior 的生成模型，用于实现受控的结肠镜图像合成，以解决现有方法的不稳定性和数据多样性不足问题。该模型通过模糊掩码加权策略（blur mask weighting strategy）无缝融合合成的息肉与结肠粘膜，以及文本感知注意力机制（text-aware attention mechanism）确保临床特征的精确控制，并构建了一个新的多模态结肠镜数据集，包括图像、掩码注释和临床文本描述。实验结果表明，CCIS-Diff 生成高质量、多样化的结肠镜图像，具有对空间属性和临床一致性的精细控制，从而为下游分割和诊断任务提供有力支持。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "5 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.12198v2",
      "published_date": "2024-11-19 03:30:06 UTC",
      "updated_date": "2025-01-05 14:10:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:16:25.798396"
    },
    {
      "arxiv_id": "2411.12196v2",
      "title": "A More Advanced Group Polarization Measurement Approach Based on LLM-Based Agents and Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Zixin Liu",
        "Ji Zhang",
        "Yiran Ding"
      ],
      "abstract": "Group polarization is an important research direction in social media content\nanalysis, attracting many researchers to explore this field. Therefore, how to\neffectively measure group polarization has become a critical topic. Measuring\ngroup polarization on social media presents several challenges that have not\nyet been addressed by existing solutions. First, social media group\npolarization measurement involves processing vast amounts of text, which poses\na significant challenge for information extraction. Second, social media texts\noften contain hard-to-understand content, including sarcasm, memes, and\ninternet slang. Additionally, group polarization research focuses on holistic\nanalysis, while texts is typically fragmented. To address these challenges, we\ndesigned a solution based on a multi-agent system and used a graph-structured\nCommunity Sentiment Network (CSN) to represent polarization states.\nFurthermore, we developed a metric called Community Opposition Index (COI)\nbased on the CSN to quantify polarization. Finally, we tested our multi-agent\nsystem through a zero-shot stance detection task and achieved outstanding\nresults. In summary, the proposed approach has significant value in terms of\nusability, accuracy, and interpretability.",
      "tldr_zh": "这篇论文针对社交媒体群组极化测量面临的挑战（如处理大量文本、讽刺内容和文本碎片化），提出了一种基于LLM-Based Agents和Graphs的高级方法。研究团队设计了多智能体系统，并使用图结构化的Community Sentiment Network (CSN)来表示极化状态，同时开发了Community Opposition Index (COI)作为量化指标。通过零样本立场检测任务的实验，该方法在可用性、准确性和可解释性方面取得了出色结果，为社交媒体内容分析提供了更有效的工具。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.12196v2",
      "published_date": "2024-11-19 03:29:17 UTC",
      "updated_date": "2024-12-16 12:13:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:16:36.882796"
    },
    {
      "arxiv_id": "2411.15185v1",
      "title": "Hybrid Gaussian Process Regression with Temporal Feature Extraction for Partially Interpretable Remaining Useful Life Interval Prediction in Aeroengine Prognostics",
      "title_zh": "混合高斯过程回归结合时间特征提取，用于航空发动机预后诊断中的部分可解释剩余有用寿命区间预测",
      "authors": [
        "Tian Niu",
        "Zijun Xu",
        "Heng Luo",
        "Ziqing Zhou"
      ],
      "abstract": "The estimation of Remaining Useful Life (RUL) plays a pivotal role in\nintelligent manufacturing systems and Industry 4.0 technologies. While recent\nadvancements have improved RUL prediction, many models still face\ninterpretability and compelling uncertainty modeling challenges. This paper\nintroduces a modified Gaussian Process Regression (GPR) model for RUL interval\nprediction, tailored for the complexities of manufacturing process development.\nThe modified GPR predicts confidence intervals by learning from historical data\nand addresses uncertainty modeling in a more structured way. The approach\neffectively captures intricate time-series patterns and dynamic behaviors\ninherent in modern manufacturing systems by coupling GPR with deep adaptive\nlearning-enhanced AI process models. Moreover, the model evaluates feature\nsignificance to ensure more transparent decision-making, which is crucial for\noptimizing manufacturing processes. This comprehensive approach supports more\naccurate RUL predictions and provides transparent, interpretable insights into\nuncertainty, contributing to robust process development and management.",
      "tldr_zh": "本论文提出了一种混合 Gaussian Process Regression (GPR) 模型，结合时间特征提取技术，用于航空发动机预后中的 Remaining Useful Life (RUL) 区间预测，以提升模型的可解释性和不确定性建模。该方法通过学习历史数据并与深层自适应学习增强的 AI 过程模型耦合，捕获复杂的时间序列模式和动态行为，同时评估特征重要性以实现更透明的决策。实验结果显示，该模型在 RUL 预测准确性上取得显著改进，并提供可解释的不确定性洞见，支持 Industry 4.0 下的智能制造过程优化和发展。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.15185v1",
      "published_date": "2024-11-19 03:00:02 UTC",
      "updated_date": "2024-11-19 03:00:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:16:48.468960"
    },
    {
      "arxiv_id": "2411.12184v1",
      "title": "Testability of Instrumental Variables in Additive Nonlinear, Non-Constant Effects Models",
      "title_zh": "工具变量在加法非线性、非常量效应模型中的可测试性",
      "authors": [
        "Xichen Guo",
        "Zheng Li",
        "Biwei Huang",
        "Yan Zeng",
        "Zhi Geng",
        "Feng Xie"
      ],
      "abstract": "We address the issue of the testability of instrumental variables derived\nfrom observational data. Most existing testable implications are centered on\nscenarios where the treatment is a discrete variable, e.g., instrumental\ninequality (Pearl, 1995), or where the effect is assumed to be constant, e.g.,\ninstrumental variables condition based on the principle of independent\nmechanisms (Burauel, 2023). However, treatments can often be continuous\nvariables, such as drug dosages or nutritional content levels, and non-constant\neffects may occur in many real-world scenarios. In this paper, we consider an\nadditive nonlinear, non-constant effects model with unmeasured confounders, in\nwhich treatments can be either discrete or continuous, and propose an\nAuxiliary-based Independence Test (AIT) condition to test whether a variable is\na valid instrument. We first show that if the candidate instrument is valid,\nthen the AIT condition holds. Moreover, we illustrate the implications of the\nAIT condition and demonstrate that, in certain conditions, AIT conditions are\nnecessary and sufficient to detect all invalid IVs. We also extend the AIT\ncondition to include covariates and introduce a practical testing algorithm.\nExperimental results on both synthetic and three different real-world datasets\nshow the effectiveness of our proposed condition.",
      "tldr_zh": "本文探讨了在加性非线性、非恒定效果模型中，工具变量（instrumental variables）的可测试性，针对现有方法对离散变量或恒定效果的局限性。作者提出了一种辅助独立性测试（Auxiliary-based Independence Test, AIT）条件，用于检验变量是否为有效工具变量，并证明了在候选工具变量有效时，AIT条件成立。研究还扩展了AIT以包括协变量，并开发了一个实际测试算法。实验在合成数据和真实世界数据集上验证了该方法的有效性，展示了其在检测无效工具变量方面的优势。",
      "categories": [
        "stat.ME",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ME",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.12184v1",
      "published_date": "2024-11-19 02:56:45 UTC",
      "updated_date": "2024-11-19 02:56:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:17:00.985002"
    },
    {
      "arxiv_id": "2411.12182v1",
      "title": "Diffusion-Inspired Cold Start with Sufficient Prior in Computerized Adaptive Testing",
      "title_zh": "翻译失败",
      "authors": [
        "Haiping Ma",
        "Aoqing Xia",
        "Changqian Wang",
        "Hai Wang",
        "Xingyi Zhang"
      ],
      "abstract": "Computerized Adaptive Testing (CAT) aims to select the most appropriate\nquestions based on the examinee's ability and is widely used in online\neducation. However, existing CAT systems often lack initial understanding of\nthe examinee's ability, requiring random probing questions. This can lead to\npoorly matched questions, extending the test duration and negatively impacting\nthe examinee's mindset, a phenomenon referred to as the Cold Start with\nInsufficient Prior (CSIP) task. This issue occurs because CAT systems do not\neffectively utilize the abundant prior information about the examinee available\nfrom other courses on online platforms. These response records, due to the\ncommonality of cognitive states across different knowledge domains, can provide\nvaluable prior information for the target domain. However, no prior work has\nexplored solutions for the CSIP task. In response to this gap, we propose\nDiffusion Cognitive States TransfeR Framework (DCSR), a novel domain transfer\nframework based on Diffusion Models (DMs) to address the CSIP task.\nSpecifically, we construct a cognitive state transition bridge between domains,\nguided by the common cognitive states of examinees, encouraging the model to\nreconstruct the initial ability state in the target domain. To enrich the\nexpressive power of the generated data, we analyze the causal relationships in\nthe generation process from a causal perspective. Redundant and extraneous\ncognitive states can lead to limited transfer and negative transfer effects.\nOur DCSR can seamlessly apply the generated initial ability states in the\ntarget domain to existing question selection algorithms, thus improving the\ncold start performance of the CAT system. Extensive experiments conducted on\nfive real-world datasets demonstrate that DCSR significantly outperforms\nexisting baseline methods in addressing the CSIP task.",
      "tldr_zh": "本研究针对 Computerized Adaptive Testing (CAT) 中的 Cold Start with Insufficient Prior (CSIP) 问题提出解决方案，该问题源于系统未能利用考生其他课程的响应记录作为先验信息，导致初始问题匹配不当并延长测试时间。论文引入 Diffusion Cognitive States TransfeR Framework (DCSR)，基于 Diffusion Models (DMs) 构建认知状态转移桥，通过分析因果关系避免负面转移效应，并将生成的初始能力状态无缝整合到现有问题选择算法中。实验在五个真实数据集上显示，DCSR 显著优于基线方法，提升了 CAT 系统的冷启动性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by KDD2025",
      "pdf_url": "http://arxiv.org/pdf/2411.12182v1",
      "published_date": "2024-11-19 02:48:58 UTC",
      "updated_date": "2024-11-19 02:48:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:17:12.853245"
    },
    {
      "arxiv_id": "2411.12181v1",
      "title": "Enhancing Low Dose Computed Tomography Images Using Consistency Training Techniques",
      "title_zh": "使用一致性训练技术增强低剂量计算机断层扫描图像",
      "authors": [
        "Mahmut S. Gokmen",
        "Jie Zhang",
        "Ge Wang",
        "Jin Chen",
        "Cody Bumgardner"
      ],
      "abstract": "Diffusion models have significant impact on wide range of generative tasks,\nespecially on image inpainting and restoration. Although the improvements on\naiming for decreasing number of function evaluations (NFE), the iterative\nresults are still computationally expensive. Consistency models are as a new\nfamily of generative models, enable single-step sampling of high quality data\nwithout the need for adversarial training. In this paper, we introduce the beta\nnoise distribution, which provides flexibility in adjusting noise levels. This\nis combined with a sinusoidal curriculum that enhances the learning of the\ntrajectory between the noise distribution and the posterior distribution of\ninterest, allowing High Noise Improved Consistency Training (HN-iCT) to be\ntrained in a supervised fashion. Additionally, High Noise Improved Consistency\nTraining with Image Condition (HN-iCT-CN) architecture is introduced, enables\nto take Low Dose images as a condition for extracting significant features by\nWeighted Attention Gates (WAG).Our results indicate that unconditional image\ngeneration using HN-iCT significantly outperforms basic CT and iCT training\ntechniques with NFE=1 on the CIFAR10 and CelebA datasets. Moreover, our\nimage-conditioned model demonstrates exceptional performance in enhancing\nlow-dose (LD) CT scans.",
      "tldr_zh": "本论文提出了一种基于一致性训练（Consistency Training）技术来增强低剂量 CT 图像的方法，旨在解决传统扩散模型（Diffusion Models）计算开销大的问题。作者引入了 beta 噪声分布和正弦曲线课程（Sinusoidal Curriculum），以优化从噪声分布到后验分布的学习轨迹，并开发了 High Noise Improved Consistency Training (HN-iCT)，实现单步采样和监督式训练。此外，他们设计了 High Noise Improved Consistency Training with Image Condition (HN-iCT-CN) 架构，使用 Weighted Attention Gates (WAG) 提取低剂量图像的关键特征。实验结果显示，HN-iCT 在 CIFAR10 和 CelebA 数据集的无条件图像生成中显著优于基线模型（NFE=1），而 HN-iCT-CN 在低剂量 CT 扫描增强方面表现出色。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.12181v1",
      "published_date": "2024-11-19 02:48:36 UTC",
      "updated_date": "2024-11-19 02:48:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:17:25.772142"
    },
    {
      "arxiv_id": "2411.12174v2",
      "title": "Just KIDDIN: Knowledge Infusion and Distillation for Detection of INdecent Memes",
      "title_zh": "翻译失败",
      "authors": [
        "Rahul Garg",
        "Trilok Padhi",
        "Hemang Jain",
        "Ugur Kursuncu",
        "Ponnurangam Kumaraguru"
      ],
      "abstract": "Toxicity identification in online multimodal environments remains a\nchallenging task due to the complexity of contextual connections across\nmodalities (e.g., textual and visual). In this paper, we propose a novel\nframework that integrates Knowledge Distillation (KD) from Large Visual\nLanguage Models (LVLMs) and knowledge infusion to enhance the performance of\ntoxicity detection in hateful memes. Our approach extracts sub-knowledge graphs\nfrom ConceptNet, a large-scale commonsense Knowledge Graph (KG) to be infused\nwithin a compact VLM framework. The relational context between toxic phrases in\ncaptions and memes, as well as visual concepts in memes enhance the model's\nreasoning capabilities. Experimental results from our study on two hate speech\nbenchmark datasets demonstrate superior performance over the state-of-the-art\nbaselines across AU-ROC, F1, and Recall with improvements of 1.1%, 7%, and 35%,\nrespectively. Given the contextual complexity of the toxicity detection task,\nour approach showcases the significance of learning from both explicit (i.e.\nKG) as well as implicit (i.e. LVLMs) contextual cues incorporated through a\nhybrid neurosymbolic approach. This is crucial for real-world applications\nwhere accurate and scalable recognition of toxic content is critical for\ncreating safer online environments.",
      "tldr_zh": "本文提出 Just KIDDIN 框架，通过 Knowledge Distillation (KD) 从 Large Visual Language Models (LVLMs) 和知识注入来提升在线多模态环境（如文本和视觉）中仇恨 meme 的毒性检测性能。该框架从 ConceptNet 的子知识图中提取关系上下文，并融入紧凑的 VLM 框架，以增强模型对毒性短语和视觉概念的推理能力。在两个仇恨言论基准数据集上，实验结果显示该方法在 AU-ROC、F1 和 Recall 上分别比现有最先进基线提高了 1.1%、7% 和 35%。这种混合神经符号方法强调了利用显式（Knowledge Graph, KG）和隐式（LVLMs）上下文线索的重要性，有助于构建更安全的在线环境。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.12174v2",
      "published_date": "2024-11-19 02:39:28 UTC",
      "updated_date": "2025-02-24 06:19:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:17:38.477108"
    },
    {
      "arxiv_id": "2411.12173v1",
      "title": "SkillTree: Explainable Skill-Based Deep Reinforcement Learning for Long-Horizon Control Tasks",
      "title_zh": "SkillTree：可解释的基于技能的深度强化学习用于长时域控制任务",
      "authors": [
        "Yongyan Wen",
        "Siyuan Li",
        "Rongchang Zuo",
        "Lei Yuan",
        "Hangyu Mao",
        "Peng Liu"
      ],
      "abstract": "Deep reinforcement learning (DRL) has achieved remarkable success in various\nresearch domains. However, its reliance on neural networks results in a lack of\ntransparency, which limits its practical applications. To achieve\nexplainability, decision trees have emerged as a popular and promising\nalternative to neural networks. Nonetheless, due to their limited\nexpressiveness, traditional decision trees struggle with high-dimensional\nlong-horizon continuous control tasks. In this paper, we proposes SkillTree, a\nnovel framework that reduces complex continuous action spaces into discrete\nskill spaces. Our hierarchical approach integrates a differentiable decision\ntree within the high-level policy to generate skill embeddings, which\nsubsequently guide the low-level policy in executing skills. By making skill\ndecisions explainable, we achieve skill-level explainability, enhancing the\nunderstanding of the decision-making process in complex tasks. Experimental\nresults demonstrate that our method achieves performance comparable to\nskill-based neural networks in complex robotic arm control domains.\nFurthermore, SkillTree offers explanations at the skill level, thereby\nincreasing the transparency of the decision-making process.",
      "tldr_zh": "本研究针对深度强化学习(DRL)缺乏透明度的局限性，提出SkillTree框架，将复杂连续动作空间简化为离散技能空间，以提升长时序控制任务的可解释性。SkillTree采用分层方法：在高层策略中使用可微决策树生成技能嵌入，随后指导低层策略执行具体技能，从而实现技能级别的决策解释。实验结果显示，该框架在复杂机器人臂控制领域，性能与基于神经网络的技能方法相当，同时显著提高了决策过程的透明度。该方法为DRL在实际应用中的可解释性提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.12173v1",
      "published_date": "2024-11-19 02:35:14 UTC",
      "updated_date": "2024-11-19 02:35:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:17:47.904963"
    },
    {
      "arxiv_id": "2411.15183v1",
      "title": "Balancing property optimization and constraint satisfaction for constrained multi-property molecular optimization",
      "title_zh": "平衡属性优化与约束满足，用于受约束的多属性分子优化",
      "authors": [
        "Xin Xia",
        "Yajie Zhang",
        "Xiangxiang Zeng",
        "Xingyi Zhang",
        "Chunhou Zheng",
        "Yansen Su"
      ],
      "abstract": "Molecular optimization, which aims to discover improved molecules from a vast\nchemical search space, is a critical step in chemical development. Various\nartificial intelligence technologies have demonstrated high effectiveness and\nefficiency on molecular optimization tasks. However, few of these technologies\nfocus on balancing property optimization with constraint satisfaction, making\nit difficult to obtain high-quality molecules that not only possess desirable\nproperties but also meet various constraints. To address this issue, we propose\na constrained multi-property molecular optimization framework (CMOMO), which is\na flexible and efficient method to simultaneously optimize multiple molecular\nproperties while satisfying several drug-like constraints. CMOMO improves\nmultiple properties of molecules with constraints based on dynamic cooperative\noptimization, which dynamically handles the constraints across various\nscenarios. Besides, CMOMO evaluates multiple properties within discrete\nchemical spaces cooperatively with the evolution of molecules within an\nimplicit molecular space to guide the evolutionary search. Experimental results\nshow the superior performance of the proposed CMOMO over five state-of-the-art\nmolecular optimization methods on two benchmark tasks of simultaneously\noptimizing multiple non-biological activity properties while satisfying two\nstructural constraints. Furthermore, the practical applicability of CMOMO is\nverified on two practical tasks, where it identified a collection of candidate\nligands of $\\beta$2-adrenoceptor GPCR and candidate inhibitors of glycogen\nsynthase kinase-3$\\beta$ with high properties and under drug-like constraints.",
      "tldr_zh": "本研究针对分子优化中的关键挑战，即平衡属性优化与约束满足，提出了CMOMO框架，这是一种灵活高效的方法，用于同时优化多个分子属性（如非生物活性属性）并满足药物-like约束。CMOMO基于动态合作优化（dynamic cooperative optimization）动态处理各种场景下的约束，并在离散化学空间与隐式分子空间中合作评估属性以指导进化搜索。实验结果显示，CMOMO在两个基准任务上优于五种最先进方法，并在实际应用中成功识别了高性能候选配体（如$\\beta$2-adrenoceptor GPCR配体）和抑制剂（如glycogen synthase kinase-3$\\beta$抑制剂），证明了其在化学开发中的实用价值。",
      "categories": [
        "physics.chem-ph",
        "cs.AI",
        "q-bio.BM"
      ],
      "primary_category": "physics.chem-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.15183v1",
      "published_date": "2024-11-19 02:01:13 UTC",
      "updated_date": "2024-11-19 02:01:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:18:01.043742"
    },
    {
      "arxiv_id": "2411.12164v1",
      "title": "UrbanDiT: A Foundation Model for Open-World Urban Spatio-Temporal Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Yuan Yuan",
        "Chonghua Han",
        "Jingtao Ding",
        "Depeng Jin",
        "Yong Li"
      ],
      "abstract": "The urban environment is characterized by complex spatio-temporal dynamics\narising from diverse human activities and interactions. Effectively modeling\nthese dynamics is essential for understanding and optimizing urban systems In\nthis work, we introduce UrbanDiT, a foundation model for open-world urban\nspatio-temporal learning that successfully scale up diffusion transformers in\nthis field. UrbanDiT pioneers a unified model that integrates diverse\nspatio-temporal data sources and types while learning universal spatio-temporal\npatterns across different cities and scenarios. This allows the model to unify\nboth multi-data and multi-task learning, and effectively support a wide range\nof spatio-temporal applications. Its key innovation lies in the elaborated\nprompt learning framework, which adaptively generates both data-driven and\ntask-specific prompts, guiding the model to deliver superior performance across\nvarious urban applications. UrbanDiT offers three primary advantages: 1) It\nunifies diverse data types, such as grid-based and graph-based data, into a\nsequential format, allowing to capture spatio-temporal dynamics across diverse\nscenarios of different cities; 2) With masking strategies and task-specific\nprompts, it supports a wide range of tasks, including bi-directional\nspatio-temporal prediction, temporal interpolation, spatial extrapolation, and\nspatio-temporal imputation; and 3) It generalizes effectively to open-world\nscenarios, with its powerful zero-shot capabilities outperforming nearly all\nbaselines with training data. These features allow UrbanDiT to achieves\nstate-of-the-art performance in different domains such as transportation\ntraffic, crowd flows, taxi demand, bike usage, and cellular traffic, across\nmultiple cities and tasks. UrbanDiT sets up a new benchmark for foundation\nmodels in the urban spatio-temporal domain.",
      "tldr_zh": "本研究引入了 UrbanDiT，一种针对开放世界城市时空学习（spatio-temporal learning）的基础模型，它扩展了 diffusion transformers 以整合多样化的城市数据源和类型，学习不同城市和场景的通用时空模式。UrbanDiT 的关键创新在于其提示学习框架（prompt learning framework），通过自适应生成数据驱动和任务特定提示，支持多任务学习，如双向时空预测、时间插值、空间外推和时空插值。实验结果显示，UrbanDiT 在交通、人群流动、出租车需求、自行车使用和蜂窝流量等领域实现了最先进性能，并展示了强大的零样本能力，超越基线模型并为城市时空领域设立了新基准。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.12164v1",
      "published_date": "2024-11-19 02:01:07 UTC",
      "updated_date": "2024-11-19 02:01:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:18:13.713224"
    },
    {
      "arxiv_id": "2411.12156v1",
      "title": "HNCSE: Advancing Sentence Embeddings via Hybrid Contrastive Learning with Hard Negatives",
      "title_zh": "HNCSE：通过混合对比学习与硬负样本推进句子嵌入",
      "authors": [
        "Wenxiao Liu",
        "Zihong Yang",
        "Chaozhuo Li",
        "Zijin Hong",
        "Jianfeng Ma",
        "Zhiquan Liu",
        "Litian Zhang",
        "Feiran Huang"
      ],
      "abstract": "Unsupervised sentence representation learning remains a critical challenge in\nmodern natural language processing (NLP) research. Recently, contrastive\nlearning techniques have achieved significant success in addressing this issue\nby effectively capturing textual semantics. Many such approaches prioritize the\noptimization using negative samples. In fields such as computer vision, hard\nnegative samples (samples that are close to the decision boundary and thus more\ndifficult to distinguish) have been shown to enhance representation learning.\nHowever, adapting hard negatives to contrastive sentence learning is complex\ndue to the intricate syntactic and semantic details of text. To address this\nproblem, we propose HNCSE, a novel contrastive learning framework that extends\nthe leading SimCSE approach. The hallmark of HNCSE is its innovative use of\nhard negative samples to enhance the learning of both positive and negative\nsamples, thereby achieving a deeper semantic understanding. Empirical tests on\nsemantic textual similarity and transfer task datasets validate the superiority\nof HNCSE.",
      "tldr_zh": "该论文针对无监督句子表示学习（unsupervised sentence representation learning）在自然语言处理（NLP）中的挑战，提出了一种新型框架 HNCSE，通过混合对比学习（hybrid contrastive learning）并引入硬负样本（hard negatives）来提升文本语义捕捉能力。HNCSE 在领先方法 SimCSE 的基础上创新性地优化正负样本学习，利用硬负样本处理文本的复杂句法和语义细节，从而实现更深层的语义理解。实验结果表明，该框架在语义文本相似性（semantic textual similarity）和转移任务数据集上表现出优越性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.12156v1",
      "published_date": "2024-11-19 01:26:20 UTC",
      "updated_date": "2024-11-19 01:26:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:18:24.872812"
    },
    {
      "arxiv_id": "2411.12155v3",
      "title": "Coarse-to-fine Q-Network with Action Sequence for Data-Efficient Robot Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Younggyo Seo",
        "Pieter Abbeel"
      ],
      "abstract": "In reinforcement learning (RL), we train a value function to understand the\nlong-term consequence of executing a single action. However, the value of\ntaking each action can be ambiguous in robotics as robot movements are\ntypically the aggregate result of executing multiple small actions. Moreover,\nrobotic training data often consists of noisy trajectories, in which each\naction is noisy but executing a series of actions results in a meaningful robot\nmovement. This further makes it difficult for the value function to understand\nthe effect of individual actions. To address this, we introduce Coarse-to-fine\nQ-Network with Action Sequence (CQN-AS), a novel value-based RL algorithm that\nlearns a critic network that outputs Q-values over a sequence of actions, i.e.,\nexplicitly training the value function to learn the consequence of executing\naction sequences. We study our algorithm on 53 robotic tasks with sparse and\ndense rewards, as well as with and without demonstrations, from BiGym,\nHumanoidBench, and RLBench. We find that CQN-AS outperforms various baselines,\nin particular on humanoid control tasks.",
      "tldr_zh": "该研究针对强化学习（RL）中价值函数在机器人学习中的挑战，指出机器人动作通常由多个小动作聚合而成，且训练数据常带有噪声，导致单个动作效果难以评估。论文提出了一种新颖的算法Coarse-to-fine Q-Network with Action Sequence (CQN-AS)，该网络学习输出动作序列的Q-值，从而显式训练价值函数理解执行序列动作的长期后果。在53个机器人任务上，包括BiGym、HumanoidBench和RLBench的稀疏/密集奖励场景，CQN-AS显著优于基线模型，尤其在人形控制任务中，展示了更高的数据效率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "15 Pages. Website: https://younggyo.me/cqn-as/",
      "pdf_url": "http://arxiv.org/pdf/2411.12155v3",
      "published_date": "2024-11-19 01:23:52 UTC",
      "updated_date": "2025-02-01 04:09:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:18:36.741945"
    },
    {
      "arxiv_id": "2411.15182v1",
      "title": "Forecasting Application Counts in Talent Acquisition Platforms: Harnessing Multimodal Signals using LMs",
      "title_zh": "翻译失败",
      "authors": [
        "Md Ahsanul Kabir",
        "Kareem Abdelfatah",
        "Shushan He",
        "Mohammed Korayem",
        "Mohammad Al Hasan"
      ],
      "abstract": "As recruitment and talent acquisition have become more and more competitive,\nrecruitment firms have become more sophisticated in using machine learning (ML)\nmethodologies for optimizing their day to day activities. But, most of\npublished ML based methodologies in this area have been limited to the tasks\nlike candidate matching, job to skill matching, job classification and\nnormalization. In this work, we discuss a novel task in the recruitment domain,\nnamely, application count forecasting, motivation of which comes from designing\nof effective outreach activities to attract qualified applicants. We show that\nexisting auto-regressive based time series forecasting methods perform poorly\nfor this task. Henceforth, we propose a multimodal LM-based model which fuses\njob-posting metadata of various modalities through a simple encoder.\nExperiments from large real-life datasets from CareerBuilder LLC show the\neffectiveness of the proposed method over existing state-of-the-art methods.",
      "tldr_zh": "这篇论文引入了人才获取平台中的新任务——申请数量预测（application count forecasting），旨在通过优化推广活动吸引合格申请者。现有自回归时间序列预测方法在该任务上表现不佳，因此作者提出一个基于语言模型（LMs）的多模态模型，通过简单编码器融合职位发布元数据等各种模态信号。实验结果显示，在 CareerBuilder LLC 的真实大型数据集上，该方法优于现有最先进方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.15182v1",
      "published_date": "2024-11-19 01:18:32 UTC",
      "updated_date": "2024-11-19 01:18:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:18:49.071899"
    },
    {
      "arxiv_id": "2412.03581v1",
      "title": "A Survey on E-Commerce Learning to Rank",
      "title_zh": "电子商务学习排序的调查",
      "authors": [
        "Md. Ahsanul Kabir",
        "Mohammad Al Hasan",
        "Aritra Mandal",
        "Daniel Tunkelang",
        "Zhe Wu"
      ],
      "abstract": "In e-commerce, ranking the search results based on users' preference is the\nmost important task. Commercial e-commerce platforms, such as, Amazon, Alibaba,\neBay, Walmart, etc. perform extensive and relentless research to perfect their\nsearch result ranking algorithms because the quality of ranking drives a user's\ndecision to purchase or not to purchase an item, directly affecting the\nprofitability of the e-commerce platform. In such a commercial platforms, for\noptimizing search result ranking numerous features are considered, which emerge\nfrom relevance, personalization, seller's reputation and paid promotion. To\nmaintain their competitive advantage in the market, the platforms do no publish\ntheir core ranking algorithms, so it is difficult to know which of the\nalgorithms or which of the features is the most effective for finding the most\noptimal search result ranking in e-commerce. No extensive surveys of ranking to\nrank in the e-commerce domain is also not yet published. In this work, we\nsurvey the existing e-commerce learning to rank algorithms. Besides, we also\ncompare these algorithms based on query relevance criterion on a large\nreal-life e-commerce dataset and provide a quantitative analysis. To the best\nof our knowledge this is the first such survey which include an experimental\ncomparison among various learning to rank algorithms.",
      "tldr_zh": "本论文对电子商务领域的 Learning to Rank 算法进行了全面调查，探讨了平台如 Amazon 和 Alibaba 在优化搜索结果排名时考虑的特征，包括相关性、个性化、卖家声誉和付费推广。由于这些平台不公开核心算法，该研究填补了现有文献的空白。作者基于真实的大型电子商务数据集，对多种算法进行了查询相关性比较和定量分析，这是首个包含实验比较的此类调查，结果有助于识别最有效的排名策略。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.03581v1",
      "published_date": "2024-11-19 01:12:51 UTC",
      "updated_date": "2024-11-19 01:12:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:19:01.536870"
    },
    {
      "arxiv_id": "2411.12150v2",
      "title": "HEIGHT: Heterogeneous Interaction Graph Transformer for Robot Navigation in Crowded and Constrained Environments",
      "title_zh": "翻译失败",
      "authors": [
        "Shuijing Liu",
        "Haochen Xia",
        "Fatemeh Cheraghi Pouria",
        "Kaiwen Hong",
        "Neeloy Chakraborty",
        "Zichao Hu",
        "Joydeep Biswas",
        "Katherine Driggs-Campbell"
      ],
      "abstract": "We study the problem of robot navigation in dense and interactive crowds with\nenvironmental constraints such as corridors and furniture. Previous methods\nfail to consider all types of interactions among agents and obstacles, leading\nto unsafe and inefficient robot paths. In this article, we leverage a\ngraph-based representation of crowded and constrained scenarios and propose a\nstructured framework to learn robot navigation policies with deep reinforcement\nlearning. We first split the representations of different components in the\nenvironment and propose a heterogeneous spatio-temporal (st) graph to model\ndistinct interactions among humans, robots, and obstacles. Based on the\nheterogeneous st-graph, we propose HEIGHT, a novel navigation policy network\narchitecture with different components to capture heterogeneous interactions\namong entities through space and time. HEIGHT utilizes attention mechanisms to\nprioritize important interactions and a recurrent network to track changes in\nthe dynamic scene over time, encouraging the robot to avoid collisions\nadaptively. Through extensive simulation and real-world experiments, we\ndemonstrate that HEIGHT outperforms state-of-the-art baselines in terms of\nsuccess and efficiency in challenging navigation scenarios. Furthermore, we\ndemonstrate that our pipeline achieves better zero-shot generalization\ncapability than previous works when the densities of humans and obstacles\nchange. More videos are available at\nhttps://sites.google.com/view/crowdnav-height/home.",
      "tldr_zh": "本文研究机器人导航在密集人群和环境约束（如走廊、家具）中的问题，提出一种基于 heterogeneous spatio-temporal (st) graph 的结构化框架，通过深度强化学习学习导航策略。HEIGHT 网络架构利用 attention mechanisms 和 recurrent network 来捕捉人类、机器人和障碍物间的异构互动，从而实现适应性碰撞避免。实验结果表明，HEIGHT 在模拟和真实场景中成功率和效率优于现有基线，并展现出更好的 zero-shot generalization 能力，当人类和障碍物密度变化时仍能有效泛化。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.12150v2",
      "published_date": "2024-11-19 00:56:35 UTC",
      "updated_date": "2025-05-01 20:03:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:19:12.819079"
    },
    {
      "arxiv_id": "2411.12142v2",
      "title": "A Computational Method for Measuring \"Open Codes\" in Qualitative Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "John Chen",
        "Alexandros Lotsos",
        "Lexie Zhao",
        "Caiyi Wang",
        "Jessica Hullman",
        "Bruce Sherin",
        "Uri Wilensky",
        "Michael Horn"
      ],
      "abstract": "Qualitative analysis is critical to understanding human datasets in many\nsocial science disciplines. Open coding is an inductive qualitative process\nthat identifies and interprets \"open codes\" from datasets. Yet, meeting\nmethodological expectations (such as \"as exhaustive as possible\") can be\nchallenging. While many machine learning (ML)/generative AI (GAI) studies have\nattempted to support open coding, few have systematically measured or evaluated\nGAI outcomes, increasing potential bias risks. Building on Grounded Theory and\nThematic Analysis theories, we present a computational method to measure and\nidentify potential biases from \"open codes\" systematically. Instead of\noperationalizing human expert results as the \"ground truth,\" our method is\nbuilt upon a team-based approach between human and machine coders. We\nexperiment with two HCI datasets to establish this method's reliability by 1)\ncomparing it with human analysis, and 2) analyzing its output stability. We\npresent evidence-based suggestions and example workflows for ML/GAI to support\nopen coding.",
      "tldr_zh": "本研究提出了一种计算方法，用于系统测量和识别定性分析中“open codes”的潜在偏见，以解决现有机器学习（ML）和生成式 AI（GAI）在支持开放编码过程中缺乏评估导致的风险。方法基于Grounded Theory和Thematic Analysis理论，采用人类和机器编码者团队合作的方式，而不是以人类专家结果作为“ground truth”。通过实验验证两个HCI datasets，该方法与人类分析结果相比显示出较高的可靠性，并证明了输出稳定性。最终，该研究提供了基于证据的建议和示例工作流，帮助ML/GAI更好地辅助开放编码过程。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.12142v2",
      "published_date": "2024-11-19 00:44:56 UTC",
      "updated_date": "2024-11-26 04:31:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:19:24.689371"
    },
    {
      "arxiv_id": "2411.12136v1",
      "title": "Visualizing Loss Functions as Topological Landscape Profiles",
      "title_zh": "将损失函数可视化为拓扑景观剖面",
      "authors": [
        "Caleb Geniesse",
        "Jiaqing Chen",
        "Tiankai Xie",
        "Ge Shi",
        "Yaoqing Yang",
        "Dmitriy Morozov",
        "Talita Perciano",
        "Michael W. Mahoney",
        "Ross Maciejewski",
        "Gunther H. Weber"
      ],
      "abstract": "In machine learning, a loss function measures the difference between model\npredictions and ground-truth (or target) values. For neural network models,\nvisualizing how this loss changes as model parameters are varied can provide\ninsights into the local structure of the so-called loss landscape (e.g.,\nsmoothness) as well as global properties of the underlying model (e.g.,\ngeneralization performance). While various methods for visualizing the loss\nlandscape have been proposed, many approaches limit sampling to just one or two\ndirections, ignoring potentially relevant information in this extremely\nhigh-dimensional space. This paper introduces a new representation based on\ntopological data analysis that enables the visualization of higher-dimensional\nloss landscapes. After describing this new topological landscape profile\nrepresentation, we show how the shape of loss landscapes can reveal new details\nabout model performance and learning dynamics, highlighting several use cases,\nincluding image segmentation (e.g., UNet) and scientific machine learning\n(e.g., physics-informed neural networks). Through these examples, we provide\nnew insights into how loss landscapes vary across distinct hyperparameter\nspaces: we find that the topology of the loss landscape is simpler for\nbetter-performing models; and we observe greater variation in the shape of loss\nlandscapes near transitions from low to high model performance.",
      "tldr_zh": "本文提出了一种基于拓扑数据分析（topological data analysis）的新方法，将损失函数可视化为拓扑景观配置文件（topological landscape profile），以克服传统可视化方法仅限于一两个方向采样的局限，从而更全面地揭示高维损失景观的局部（如平滑度）和全局（如泛化性能）特性。通过在图像分割（UNet）和科学机器学习（physics-informed neural networks）等任务上的实验，研究发现：表现更好的模型具有更简单的损失景观拓扑，而在从低到高性能的过渡区域，景观形状变化更剧烈。该方法为理解模型学习动态和超参数空间的影响提供了新见解。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.12136v1",
      "published_date": "2024-11-19 00:28:14 UTC",
      "updated_date": "2024-11-19 00:28:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:19:37.870625"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 108,
  "processed_papers_count": 108,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-21T02:19:58.441167"
}