{
  "date": "2024-06-28",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-06-28 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦于 AI 和机器学习领域，特别是大型语言模型 (LLMs) 的优化、多模态理解和强化学习应用，强调模型的鲁棒性、公平性和实际部署；令人印象深刻的文章包括 One Prompt is not Enough（由 Cho-Jui Hsieh 等人提出，引入 Mixture-of-Prompts 提升任务泛化）和 LLaRA（由 Michael S. Ryoo 等人开发，用于机器人学习），这些工作展示了 LLMs 在复杂任务中的潜力，同时揭示了跨文化评估和道德对齐的挑战。\n\n下面，我将挑选几篇重要的论文优先讨论，将相关主题归类（如 AI 模型优化和多模态应用），并快速掠过其他较少话题度的论文。每篇论文会列出标题（中文 + 英文），并简要描述主要贡献和发现。\n\n### AI 模型优化与 LLMs\n- **One Prompt is not Enough: Automated Construction of a Mixture-of-Expert Prompts**（英文原题：One Prompt is not Enough: Automated Construction of a Mixture-of-Expert Prompts）  \n  这篇论文由 Cho-Jui Hsieh 等人发布，提出 Mixture-of-Prompts (MoP) 框架，通过将问题空间分解为子区域，并为每个子区域分配特定指令和演示样本，显著提升 LLMs 在复杂任务上的性能。贡献在于超越单一指令限制，实现 81% 的胜率提升，适用于指令微调场景。\n\n- **LLaRA: Supercharging Robot Learning Data for Vision-Language Policy**（英文原题：LLaRA: Supercharging Robot Learning Data for Vision-Language Policy）  \n  Michael S. Ryoo 等人的工作引入 LLaRA 框架，将视觉指令调优应用于机器人控制，通过自监督数据增强和对话式训练，生成高质量机器人动作策略。发现显示，该方法在模拟和真实任务中超越 SOTA，提升机器人泛化能力，强调视觉-语言模型在实际应用的潜力。\n\n- **ProgressGym: Alignment with a Millennium of Moral Progress**（英文原题：ProgressGym: Alignment with a Millennium of Moral Progress）  \n  这篇 NeurIPS 亮点论文由 Yaodong Yang 等人提出，构建了一个基准框架来模拟人类道德演变，针对 LLMs 的道德盲点设计三类挑战（跟踪演变、预测进展和协同进化）。主要贡献是引入 lifelong 和 extrapolative 算法，帮助 LLMs 避免道德锁定，提高模型在历史文本上的适应性。\n\n- **From Local Concepts to Universals: Evaluating the Multicultural Understanding of Vision-Language Models**（英文原题：From Local Concepts to Universals: Evaluating the Multicultural Understanding of Vision-Language Models）  \n  Vered Shwartz 等人开发 GlobalRG 基准，评估视觉-语言模型在跨文化任务中的表现，包括检索通用概念和定位文化特定元素。发现模型在不同文化上的性能差异显著，强调需要改进多文化数据以提升模型的包容性。\n\n### 多模态和视觉应用\n- **Web2Code: A Large-scale Webpage-to-Code Dataset and Evaluation Framework for Multimodal LLMs**（英文原题：Web2Code: A Large-scale Webpage-to-Code Dataset and Evaluation Framework for Multimodal LLMs）  \n  Eric P. Xing 等人构建了 Web2Code 数据集和评估框架，用于测试多模态 LLMs 在网页截图到 HTML 代码转换的任务中。贡献在于通过 RAG 和数据集增强，提高模型在网页理解和代码生成的准确性，适用于自动化任务。\n\n其他论文主题多样，但许多较为专业或应用导向，我将快速概述相关内容：\n- **ML Updates for OpenStreetMap: Analysis of Research Gaps and Future Directions**（英文原题：ML Updates for OpenStreetMap: Analysis of Research Gaps and Future Directions）  \n  分析机器学习在地图更新的应用，识别研究空白并提出 DeepMapper 框架，提升自动地图更新的效率。\n\n- **External Model Motivated Agents: Reinforcement Learning for Enhanced Environment Sampling**（英文原题：External Model Motivated Agents: Reinforcement Learning for Enhanced Environment Sampling）  \n  Mark Riedl 等人的工作优化强化学习代理，通过不确定性驱动的环境采样，提高模型在动态环境中的适应性。\n\n- **SemUV: Deep Learning based semantic manipulation over UV texture map of virtual human heads**（英文原题：SemUV: Deep Learning based semantic manipulation over UV texture map of virtual human heads）  \n  提出 SemUV 方法，使用 StyleGAN 在 UV 纹理空间进行人脸语义编辑，保留身份信息的同时修改特征，如年龄和性别。\n\n剩余论文，如那些聚焦于特定领域（如量子计算、生物医学或小众优化问题），我将简要提及而不深挖。例如：\n- **Tradeoffs When Considering Deep Reinforcement Learning for Contingency Management in Advanced Air Mobility**（英文原题：Tradeoffs When Considering Deep Reinforcement Learning for Contingency Management in Advanced Air Mobility）探讨 DRL 在航空风险管理中的权衡，但细节较技术化。\n- **Molecular Facts: Desiderata for Decontextualization in LLM Fact Verification**（英文原题：Molecular Facts: Desiderata for Decontextualization in LLM Fact Verification）定义了事实验证的去上下文标准，但影响较局限。\n- 其他如 **A Novel Labeled Human Voice Signal Dataset for Misbehavior Detection** 和 **Graph Neural Networks for Gut Microbiome Metaomic data** 等，贡献在于数据集构建或特定应用，但非主流话题，故快速掠过。\n\n总之，今天的 arXiv 论文突显了 AI 领域的创新潜力，特别是 LLMs 的优化和多模态应用，但也暴露了模型在道德和文化上的挑战。感兴趣的读者可关注上述关键论文，进一步探索。明天见！",
  "papers": [
    {
      "arxiv_id": "2407.03365v1",
      "title": "ML Updates for OpenStreetMap: Analysis of Research Gaps and Future Directions",
      "title_zh": "针对 OpenStreetMap 的机器学习更新：研究空白的分析和未来方向",
      "authors": [
        "Lasith Niroshan",
        "James D. Carswell"
      ],
      "abstract": "Maintaining accurate, up-to-date maps is important in any dynamic urban\nlandscape, supporting various aspects of modern society, such as urban\nplanning, navigation, and emergency response. However, traditional (i.e.\nlargely manual) map production and crowdsourced mapping methods still struggle\nto keep pace with rapid changes in the built environment. Such manual mapping\nworkflows are time-consuming and prone to human errors, leading to early\nobsolescence and/or the need for extensive auditing. The current map updating\nprocess in OpenStreetMap provides an example of this limitation, relying on\nnumerous manual steps in its online map updating workflow. To address this,\nthere is a need to explore automating the entire end-to-end map up-dating\nprocess. Tech giants such as Google and Microsoft have already started\ninvestigating Machine Learning (ML) techniques to tackle this contemporary\nmapping problem. This paper offers an analysis of these ML approaches, focusing\non their application to updating Open-StreetMap in particular. By analysing the\ncurrent state-of-the-art in this field, this study identi-fies some key\nresearch gaps and introduces DeepMapper as a practical solution for advancing\nthe automatic online map updating process in the future.",
      "tldr_zh": "这篇论文分析了使用机器学习（ML）技术更新 OpenStreetMap 的挑战和机遇，强调传统手动地图更新方法难以跟上城市环境的快速变化，导致耗时和错误问题。作者审视了 Google 和 Microsoft 等公司在 ML 领域的现有方法，识别了关键研究空白，如端到端自动化流程的不足。最终，论文提出 DeepMapper 作为一种实用解决方案，以推进未来的在线地图更新过程，提高效率和准确性。",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.LG",
        "68U99",
        "A.0; I.4.9"
      ],
      "primary_category": "cs.AI",
      "comment": "21 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.03365v1",
      "published_date": "2024-06-28 23:51:04 UTC",
      "updated_date": "2024-06-28 23:51:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:35:59.183763"
    },
    {
      "arxiv_id": "2407.00264v1",
      "title": "External Model Motivated Agents: Reinforcement Learning for Enhanced Environment Sampling",
      "title_zh": "翻译失败",
      "authors": [
        "Rishav Bhagat",
        "Jonathan Balloch",
        "Zhiyu Lin",
        "Julia Kim",
        "Mark Riedl"
      ],
      "abstract": "Unlike reinforcement learning (RL) agents, humans remain capable multitaskers\nin changing environments. In spite of only experiencing the world through their\nown observations and interactions, people know how to balance focusing on tasks\nwith learning about how changes may affect their understanding of the world.\nThis is possible by choosing to solve tasks in ways that are interesting and\ngenerally informative beyond just the current task. Motivated by this, we\npropose an agent influence framework for RL agents to improve the adaptation\nefficiency of external models in changing environments without any changes to\nthe agent's rewards. Our formulation is composed of two self-contained modules:\ninterest fields and behavior shaping via interest fields. We implement an\nuncertainty-based interest field algorithm as well as a skill-sampling-based\nbehavior-shaping algorithm to use in testing this framework. Our results show\nthat our method outperforms the baselines in terms of external model adaptation\non metrics that measure both efficiency and performance.",
      "tldr_zh": "本文受人类在变化环境中多任务处理能力的启发，提出了一种代理影响框架（agent influence framework），用于增强强化学习（RL）代理的环境采样，从而提高外部模型的适应效率，而无需修改代理的奖励。框架由两个模块组成：interest fields 和 behavior shaping via interest fields，分别通过 uncertainty-based interest field algorithm 和 skill-sampling-based behavior-shaping algorithm 实现，以平衡任务焦点和环境信息获取。实验结果显示，该方法在外部模型适应方面的效率和性能指标上优于基线模型。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.00264v1",
      "published_date": "2024-06-28 23:31:22 UTC",
      "updated_date": "2024-06-28 23:31:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:36:12.144937"
    },
    {
      "arxiv_id": "2407.00263v1",
      "title": "From Local Concepts to Universals: Evaluating the Multicultural Understanding of Vision-Language Models",
      "title_zh": "从局部概念到普遍概念：评估视觉语言模型的多文化理解",
      "authors": [
        "Mehar Bhatia",
        "Sahithya Ravi",
        "Aditya Chinchure",
        "Eunjeong Hwang",
        "Vered Shwartz"
      ],
      "abstract": "Despite recent advancements in vision-language models, their performance\nremains suboptimal on images from non-western cultures due to\nunderrepresentation in training datasets. Various benchmarks have been proposed\nto test models' cultural inclusivity, but they have limited coverage of\ncultures and do not adequately assess cultural diversity across universal as\nwell as culture-specific local concepts. To address these limitations, we\nintroduce the GlobalRG benchmark, comprising two challenging tasks: retrieval\nacross universals and cultural visual grounding. The former task entails\nretrieving culturally diverse images for universal concepts from 50 countries,\nwhile the latter aims at grounding culture-specific concepts within images from\n15 countries. Our evaluation across a wide range of models reveals that the\nperformance varies significantly across cultures -- underscoring the necessity\nfor enhancing multicultural understanding in vision-language models.",
      "tldr_zh": "尽管视觉语言模型（VLMs）取得了进展，但由于训练数据集对非西方文化的 underrepresented，其在这些图像上的表现仍不理想，且现有基准覆盖有限，无法充分评估文化多样性。论文引入了 GlobalRG benchmark，包括两个任务：retrieval across universals（针对50个国家的通用概念检索文化多样图像）和 cultural visual grounding（针对15个国家的文化特定概念进行视觉定位）。通过评估多种模型，研究发现模型在不同文化间的表现差异显著，强调了提升VLMs多文化理解的必要性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "Under peer review",
      "pdf_url": "http://arxiv.org/pdf/2407.00263v1",
      "published_date": "2024-06-28 23:28:28 UTC",
      "updated_date": "2024-06-28 23:28:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:36:23.822649"
    },
    {
      "arxiv_id": "2407.00256v1",
      "title": "One Prompt is not Enough: Automated Construction of a Mixture-of-Expert Prompts",
      "title_zh": "翻译失败",
      "authors": [
        "Ruochen Wang",
        "Sohyun An",
        "Minhao Cheng",
        "Tianyi Zhou",
        "Sung Ju Hwang",
        "Cho-Jui Hsieh"
      ],
      "abstract": "Large Language Models (LLMs) exhibit strong generalization capabilities to\nnovel tasks when prompted with language instructions and in-context demos.\nSince this ability sensitively depends on the quality of prompts, various\nmethods have been explored to automate the instruction design. While these\nmethods demonstrated promising results, they also restricted the searched\nprompt to one instruction. Such simplification significantly limits their\ncapacity, as a single demo-free instruction might not be able to cover the\nentire complex problem space of the targeted task. To alleviate this issue, we\nadopt the Mixture-of-Expert paradigm and divide the problem space into a set of\nsub-regions; Each sub-region is governed by a specialized expert, equipped with\nboth an instruction and a set of demos. A two-phase process is developed to\nconstruct the specialized expert for each region: (1) demo assignment: Inspired\nby the theoretical connection between in-context learning and kernel\nregression, we group demos into experts based on their semantic similarity; (2)\ninstruction assignment: A region-based joint search of an instruction per\nexpert complements the demos assigned to it, yielding a synergistic effect. The\nresulting method, codenamed Mixture-of-Prompts (MoP), achieves an average win\nrate of 81% against prior arts across several major benchmarks.",
      "tldr_zh": "该论文指出，大型语言模型 (LLMs) 的提示设计对任务泛化至关重要，但现有自动方法仅限于单一指令，难以覆盖复杂问题空间。为解决此问题，研究提出 Mixture-of-Expert 范式，将问题空间分为子区域，每个子区域由一个专家提示管理，该提示结合指令和一组演示 (demos)。方法采用两阶段过程：首先基于语义相似性及 in-context learning 与 kernel regression 的理论联系，将 demos 分组分配；其次，对每个专家进行联合指令搜索，以实现协同效应。最终，名为 Mixture-of-Prompts (MoP) 的框架在多个基准测试中平均胜率达 81%，显著优于现有方法。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "stat.ML",
        "68T01"
      ],
      "primary_category": "cs.AI",
      "comment": "ICML 2024. code available at\n  https://github.com/ruocwang/mixture-of-prompts",
      "pdf_url": "http://arxiv.org/pdf/2407.00256v1",
      "published_date": "2024-06-28 23:05:08 UTC",
      "updated_date": "2024-06-28 23:05:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:36:37.027183"
    },
    {
      "arxiv_id": "2407.00229v1",
      "title": "SemUV: Deep Learning based semantic manipulation over UV texture map of virtual human heads",
      "title_zh": "翻译失败",
      "authors": [
        "Anirban Mukherjee",
        "Venkat Suprabath Bitra",
        "Vignesh Bondugula",
        "Tarun Reddy Tallapureddy",
        "Dinesh Babu Jayagopi"
      ],
      "abstract": "Designing and manipulating virtual human heads is essential across various\napplications, including AR, VR, gaming, human-computer interaction and VFX.\nTraditional graphic-based approaches require manual effort and resources to\nachieve accurate representation of human heads. While modern deep learning\ntechniques can generate and edit highly photorealistic images of faces, their\nfocus remains predominantly on 2D facial images. This limitation makes them\nless suitable for 3D applications. Recognizing the vital role of editing within\nthe UV texture space as a key component in the 3D graphics pipeline, our work\nfocuses on this aspect to benefit graphic designers by providing enhanced\ncontrol and precision in appearance manipulation. Research on existing methods\nwithin the UV texture space is limited, complex, and poses challenges. In this\npaper, we introduce SemUV: a simple and effective approach using the FFHQ-UV\ndataset for semantic manipulation directly within the UV texture space. We\ntrain a StyleGAN model on the publicly available FFHQ-UV dataset, and\nsubsequently train a boundary for interpolation and semantic feature\nmanipulation. Through experiments comparing our method with 2D manipulation\ntechnique, we demonstrate its superior ability to preserve identity while\neffectively modifying semantic features such as age, gender, and facial hair.\nOur approach is simple, agnostic to other 3D components such as structure,\nlighting, and rendering, and also enables seamless integration into standard 3D\ngraphics pipelines without demanding extensive domain expertise, time, or\nresources.",
      "tldr_zh": "本研究提出SemUV，一种基于深度学习的语义操纵方法，针对虚拟人类头部的UV texture map进行编辑，以提升AR、VR、游戏和VFX等应用中的3D图形设计效率。方法利用FFHQ-UV数据集训练StyleGAN模型，并训练边界以实现插值和语义特征操纵，从而在UV纹理空间直接修改如年龄、性别和面部毛发的属性，同时更好地保留身份信息。实验结果显示，SemUV相较于2D操纵技术表现出色，且其简单设计独立于其他3D组件（如结构、照明和渲染），便于无缝集成到标准3D图形管道中，而无需大量专业知识或资源。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "CVIP 2024 Preprint",
      "pdf_url": "http://arxiv.org/pdf/2407.00229v1",
      "published_date": "2024-06-28 20:58:59 UTC",
      "updated_date": "2024-06-28 20:58:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:36:48.764053"
    },
    {
      "arxiv_id": "2407.00219v2",
      "title": "Evaluating Human Alignment and Model Faithfulness of LLM Rationale",
      "title_zh": "翻译失败",
      "authors": [
        "Mohsen Fayyaz",
        "Fan Yin",
        "Jiao Sun",
        "Nanyun Peng"
      ],
      "abstract": "We study how well large language models (LLMs) explain their generations\nthrough rationales -- a set of tokens extracted from the input text that\nreflect the decision-making process of LLMs. Specifically, we systematically\nstudy rationales derived using two approaches: (1) popular prompting-based\nmethods, where prompts are used to guide LLMs in generating rationales, and (2)\ntechnical attribution-based methods, which leverage attention or gradients to\nidentify important tokens. Our analysis spans three classification datasets\nwith annotated rationales, encompassing tasks with varying performance levels.\nWhile prompting-based self-explanations are widely used, our study reveals that\nthese explanations are not always as \"aligned\" with the human rationale as\nattribution-based explanations. Even more so, fine-tuning LLMs to enhance\nclassification task accuracy does not enhance the alignment of prompting-based\nrationales. Still, it does considerably improve the alignment of\nattribution-based methods (e.g., InputXGradient). More importantly, we show\nthat prompting-based self-explanation is also less \"faithful\" than\nattribution-based explanations, failing to provide a reliable account of the\nmodel's decision-making process. To evaluate faithfulness, unlike prior studies\nthat excluded misclassified examples, we evaluate all instances and also\nexamine the impact of fine-tuning and accuracy on alignment and faithfulness.\nOur findings suggest that inconclusive faithfulness results reported in earlier\nstudies may stem from low classification accuracy. These findings underscore\nthe importance of more rigorous and comprehensive evaluations of LLM\nrationales.",
      "tldr_zh": "本文评估了大型语言模型 (LLMs) 的理性 (rationales) 在人类对齐 (human alignment) 和模型忠诚 (model faithfulness) 方面的表现，比较了基于提示的 (prompting-based) 方法和基于归因的 (attribution-based) 方法，如使用注意力或梯度识别重要标记。研究在三个分类数据集上进行系统分析，发现基于提示的自我解释不如基于归因的方法（如 InputXGradient）与人类理性对齐，且在微调 LLMs 以提高分类准确性后，基于归因的方法的对齐度显著提升，而基于提示的方法忠诚度较低，无法可靠反映模型决策。总体结果表明，低分类准确性可能导致先前研究的忠诚评估不一致，强调需要更全面和严格的评估 LLM 理性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.00219v2",
      "published_date": "2024-06-28 20:06:30 UTC",
      "updated_date": "2024-10-22 05:13:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:37:03.078673"
    },
    {
      "arxiv_id": "2407.00197v1",
      "title": "Tradeoffs When Considering Deep Reinforcement Learning for Contingency Management in Advanced Air Mobility",
      "title_zh": "翻译失败",
      "authors": [
        "Luis E. Alvarez",
        "Marc W. Brittain",
        "Steven D. Young"
      ],
      "abstract": "Air transportation is undergoing a rapid evolution globally with the\nintroduction of Advanced Air Mobility (AAM) and with it comes novel challenges\nand opportunities for transforming aviation. As AAM operations introduce\nincreasing heterogeneity in vehicle capabilities and density, increased levels\nof automation are likely necessary to achieve operational safety and efficiency\ngoals. This paper focuses on one example where increased automation has been\nsuggested. Autonomous operations will need contingency management systems that\ncan monitor evolving risk across a span of interrelated (or interdependent)\nhazards and, if necessary, execute appropriate control interventions via\nsupervised or automated decision making. Accommodating this complex environment\nmay require automated functions (autonomy) that apply artificial intelligence\n(AI) techniques that can adapt and respond to a quickly changing environment.\nThis paper explores the use of Deep Reinforcement Learning (DRL) which has\nshown promising performance in complex and high-dimensional environments where\nthe objective can be constructed as a sequential decision-making problem. An\nextension of a prior formulation of the contingency management problem as a\nMarkov Decision Process (MDP) is presented and uses a DRL framework to train\nagents that mitigate hazards present in the simulation environment. A\ncomparison of these learning-based agents and classical techniques is presented\nin terms of their performance, verification difficulties, and development\nprocess.",
      "tldr_zh": "这篇论文探讨了在 Advanced Air Mobility (AAM) 领域中使用 Deep Reinforcement Learning (DRL) 进行应急管理的权衡问题，随着 AAM 引入车辆能力异质性和密度增加，需要更高的自动化水平来确保安全和效率。作者将应急管理问题扩展为 Markov Decision Process (MDP)，并通过 DRL 框架训练代理来监控风险并执行干预措施。实验比较显示，DRL 代理在性能上表现出色，但面临验证难度和开发过程的挑战，强调了其在复杂环境中的潜在优势和局限性。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.00197v1",
      "published_date": "2024-06-28 19:09:55 UTC",
      "updated_date": "2024-06-28 19:09:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:37:12.404574"
    },
    {
      "arxiv_id": "2407.00188v1",
      "title": "A Novel Labeled Human Voice Signal Dataset for Misbehavior Detection",
      "title_zh": "一个新颖的标记人类语音信号数据集，用于不良行为检测",
      "authors": [
        "Ali Raza",
        "Faizan Younas"
      ],
      "abstract": "Voice signal classification based on human behaviours involves analyzing\nvarious aspects of speech patterns and delivery styles. In this study, a\nreal-time dataset collection is performed where participants are instructed to\nspeak twelve psychology questions in two distinct manners: first, in a harsh\nvoice, which is categorized as \"misbehaved\"; and second, in a polite manner,\ncategorized as \"normal\". These classifications are crucial in understanding how\ndifferent vocal behaviours affect the interpretation and classification of\nvoice signals. This research highlights the significance of voice tone and\ndelivery in automated machine-learning systems for voice analysis and\nrecognition. This research contributes to the broader field of voice signal\nanalysis by elucidating the impact of human behaviour on the perception and\ncategorization of voice signals, thereby enhancing the development of more\naccurate and context-aware voice recognition technologies.",
      "tldr_zh": "本研究提出一个新的标记化人类语音信号数据集，用于misbehavior detection，通过分析语音模式和表达风格来识别不当行为。数据集通过实时收集方式，让参与者以两种方式回答12个心理学问题：harsh voice（分类为“misbehaved”）和polite manner（分类为“normal”），以探讨语音语气对信号分类的影响。该研究强调了语音行为在自动化机器学习系统中的重要性，并为语音信号分析领域提供了关键洞见，推动了更准确、上下文感知的语音识别技术的发展。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.00188v1",
      "published_date": "2024-06-28 18:55:07 UTC",
      "updated_date": "2024-06-28 18:55:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:37:24.060618"
    },
    {
      "arxiv_id": "2407.00167v1",
      "title": "Can GPT-4 Help Detect Quit Vaping Intentions? An Exploration of Automatic Data Annotation Approach",
      "title_zh": "GPT-4 可以帮助检测戒电子烟意图吗？ 自动数据标注方法的探索",
      "authors": [
        "Sai Krishna Revanth Vuruma",
        "Dezhi Wu",
        "Saborny Sen Gupta",
        "Lucas Aust",
        "Valerie Lookingbill",
        "Wyatt Bellamy",
        "Yang Ren",
        "Erin Kasson",
        "Li-Shiun Chen",
        "Patricia Cavazos-Rehg",
        "Dian Hu",
        "Ming Huang"
      ],
      "abstract": "In recent years, the United States has witnessed a significant surge in the\npopularity of vaping or e-cigarette use, leading to a notable rise in cases of\ne-cigarette and vaping use-associated lung injury (EVALI) that caused\nhospitalizations and fatalities during the EVALI outbreak in 2019, highlighting\nthe urgency to comprehend vaping behaviors and develop effective strategies for\ncessation. Due to the ubiquity of social media platforms, over 4.7 billion\nusers worldwide use them for connectivity, communications, news, and\nentertainment with a significant portion of the discourse related to health,\nthereby establishing social media data as an invaluable organic data resource\nfor public health research. In this study, we extracted a sample dataset from\none vaping sub-community on Reddit to analyze users' quit-vaping intentions.\nLeveraging OpenAI's latest large language model GPT-4 for sentence-level quit\nvaping intention detection, this study compares the outcomes of this model\nagainst layman and clinical expert annotations. Using different prompting\nstrategies such as zero-shot, one-shot, few-shot and chain-of-thought\nprompting, we developed 8 prompts with varying levels of detail to explain the\ntask to GPT-4 and also evaluated the performance of the strategies against each\nother. These preliminary findings emphasize the potential of GPT-4 in social\nmedia data analysis, especially in identifying users' subtle intentions that\nmay elude human detection.",
      "tldr_zh": "这篇论文探讨了使用 GPT-4 自动检测社交媒体用户戒烟意图（quit vaping intentions）的潜力，针对美国 vaping 流行导致的健康问题，如 EVALI，从 Reddit 的 vaping 子社区提取数据作为研究基础。研究方法包括开发 8 种不同提示策略（如 zero-shot、one-shot、few-shot 和 chain-of-thought prompting），并将 GPT-4 的检测结果与普通人和临床专家的标注进行比较。初步发现表明，GPT-4 在识别人类可能忽略的细微意图方面表现出色，为社交媒体数据分析和公共健康策略提供了一种高效的自动数据标注方法。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.ET",
        "cs.HC",
        "cs.SI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted for the AI Applications in Public Health and Social Services\n  workshop at the 22nd International Conference on Artificial Intelligence in\n  Medicine (AIME 2024)",
      "pdf_url": "http://arxiv.org/pdf/2407.00167v1",
      "published_date": "2024-06-28 18:06:48 UTC",
      "updated_date": "2024-06-28 18:06:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:37:36.528955"
    },
    {
      "arxiv_id": "2406.20098v2",
      "title": "Web2Code: A Large-scale Webpage-to-Code Dataset and Evaluation Framework for Multimodal LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Sukmin Yun",
        "Haokun Lin",
        "Rusiru Thushara",
        "Mohammad Qazim Bhat",
        "Yongxin Wang",
        "Zutao Jiang",
        "Mingkai Deng",
        "Jinhong Wang",
        "Tianhua Tao",
        "Junbo Li",
        "Haonan Li",
        "Preslav Nakov",
        "Timothy Baldwin",
        "Zhengzhong Liu",
        "Eric P. Xing",
        "Xiaodan Liang",
        "Zhiqiang Shen"
      ],
      "abstract": "Multimodal large language models (MLLMs) have shown impressive success across\nmodalities such as image, video, and audio in a variety of understanding and\ngeneration tasks. However, current MLLMs are surprisingly poor at understanding\nwebpage screenshots and generating their corresponding HTML code. To address\nthis problem, we propose $\\texttt{Web2Code}$, a benchmark consisting of a new\nlarge-scale webpage-to-code dataset for instruction tuning and an evaluation\nframework for the webpage understanding and HTML code translation abilities of\nMLLMs. For dataset construction, we leverage pretrained LLMs to enhance\nexisting webpage-to-code datasets as well as generate a diverse pool of new\nwebpages rendered into images. Specifically, the inputs are webpage images and\ninstructions, while the responses are the webpage's HTML code. We further\ninclude diverse natural language QA pairs about the webpage content in the\nresponses to enable a more comprehensive understanding of the web content. To\nevaluate model performance in these tasks, we develop an evaluation framework\nfor testing MLLMs' abilities in webpage understanding and web-to-code\ngeneration. Extensive experiments show that our proposed dataset is beneficial\nnot only to our proposed tasks but also in the general visual domain. We hope\nour work will contribute to the development of general MLLMs suitable for\nweb-based content generation and task automation. Our data and code are\navailable at https://github.com/MBZUAI-LLM/web2code.",
      "tldr_zh": "该研究提出 Web2Code，这是一个大规模网页到代码数据集和评估框架，旨在提升 Multimodal LLMs 在理解网页截图和生成 HTML 代码方面的能力。数据集通过预训练 LLMs 增强现有资源并生成多样化的网页图像，输入包括网页图像和指令，输出为对应的 HTML 代码以及相关自然语言 QA 对，以实现更全面的网页内容理解。实验结果显示，该数据集不仅改善了网页理解和代码生成任务的性能，还对一般视觉领域任务有益，推动了适用于网络内容生成和任务自动化的通用 MLLMs 的发展。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "NeurIPS 2024 Datasets and Benchmarks Camera-ready Version. Website at\n  https://mbzuai-llm.github.io/webpage2code/",
      "pdf_url": "http://arxiv.org/pdf/2406.20098v2",
      "published_date": "2024-06-28 17:59:46 UTC",
      "updated_date": "2024-11-17 16:11:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:37:49.157573"
    },
    {
      "arxiv_id": "2406.20095v3",
      "title": "LLaRA: Supercharging Robot Learning Data for Vision-Language Policy",
      "title_zh": "翻译失败",
      "authors": [
        "Xiang Li",
        "Cristina Mata",
        "Jongwoo Park",
        "Kumara Kahatapitiya",
        "Yoo Sung Jang",
        "Jinghuan Shang",
        "Kanchana Ranasinghe",
        "Ryan Burgert",
        "Mu Cai",
        "Yong Jae Lee",
        "Michael S. Ryoo"
      ],
      "abstract": "Vision Language Models (VLMs) have recently been leveraged to generate\nrobotic actions, forming Vision-Language-Action (VLA) models. However, directly\nadapting a pretrained VLM for robotic control remains challenging, particularly\nwhen constrained by a limited number of robot demonstrations. In this work, we\nintroduce LLaRA: Large Language and Robotics Assistant, a framework that\nformulates robot action policy as visuo-textual conversations and enables an\nefficient transfer of a pretrained VLM into a powerful VLA, motivated by the\nsuccess of visual instruction tuning in Computer Vision. First, we present an\nautomated pipeline to generate conversation-style instruction tuning data for\nrobots from existing behavior cloning datasets, aligning robotic actions with\nimage pixel coordinates. Further, we enhance this dataset in a self-supervised\nmanner by defining six auxiliary tasks, without requiring any additional action\nannotations. We show that a VLM finetuned with a limited amount of such\ndatasets can produce meaningful action decisions for robotic control. Through\nexperiments across multiple simulated and real-world tasks, we demonstrate that\nLLaRA achieves state-of-the-art performance while preserving the generalization\ncapabilities of large language models. The code, datasets, and pretrained\nmodels are available at https://github.com/LostXine/LLaRA.",
      "tldr_zh": "该研究提出LLaRA框架，将机器人动作策略表述为视觉-文本对话，从而高效地将预训练的Vision-Language Models (VLM)转化为强大的Vision-Language-Action (VLA)模型，以解决行为克隆数据集有限的问题。首先，LLaRA使用一个自动化管道从现有数据集生成对话式指令调整数据，并通过自监督方式定义六个辅助任务来增强数据集，而无需额外动作标注。实验结果显示，在多个模拟和真实机器人任务中，LLaRA实现了state-of-the-art性能，同时保留了大语言模型的泛化能力。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2406.20095v3",
      "published_date": "2024-06-28 17:59:12 UTC",
      "updated_date": "2025-01-30 17:34:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:38:01.007117"
    },
    {
      "arxiv_id": "2406.20087v2",
      "title": "ProgressGym: Alignment with a Millennium of Moral Progress",
      "title_zh": "翻译失败",
      "authors": [
        "Tianyi Qiu",
        "Yang Zhang",
        "Xuchuan Huang",
        "Jasmine Xinze Li",
        "Jiaming Ji",
        "Yaodong Yang"
      ],
      "abstract": "Frontier AI systems, including large language models (LLMs), hold increasing\ninfluence over the epistemology of human users. Such influence can reinforce\nprevailing societal values, potentially contributing to the lock-in of\nmisguided moral beliefs and, consequently, the perpetuation of problematic\nmoral practices on a broad scale. We introduce progress alignment as a\ntechnical solution to mitigate this imminent risk. Progress alignment\nalgorithms learn to emulate the mechanics of human moral progress, thereby\naddressing the susceptibility of existing alignment methods to contemporary\nmoral blindspots. To empower research in progress alignment, we introduce\nProgressGym, an experimental framework allowing the learning of moral progress\nmechanics from history, in order to facilitate future progress in real-world\nmoral decisions. Leveraging 9 centuries of historical text and 18 historical\nLLMs, ProgressGym enables codification of real-world progress alignment\nchallenges into concrete benchmarks. Specifically, we introduce three core\nchallenges: tracking evolving values (PG-Follow), preemptively anticipating\nmoral progress (PG-Predict), and regulating the feedback loop between human and\nAI value shifts (PG-Coevolve). Alignment methods without a temporal dimension\nare inapplicable to these tasks. In response, we present lifelong and\nextrapolative algorithms as baseline methods of progress alignment, and build\nan open leaderboard soliciting novel algorithms and challenges. The framework\nand the leaderboard are available at\nhttps://github.com/PKU-Alignment/ProgressGym and\nhttps://huggingface.co/spaces/PKU-Alignment/ProgressGym-LeaderBoard\nrespectively.",
      "tldr_zh": "这篇论文引入了“progress alignment”算法，旨在模拟人类道德进步机制，以缓解前沿 AI 系统（如 LLMs）强化当代道德盲点并锁定错误信念的风险。作者开发了 ProgressGym 框架，利用 9 世纪历史文本和 18 个历史 LLMs，定义了三个核心挑战：跟踪演变的值 (PG-Follow)、预先预测道德进步 (PG-Predict) 以及调节人类与 AI 值变化反馈循环 (PG-Coevolve)。该框架提供了 lifelong 和 extrapolative 算法作为基准，并建立了开源 leaderboard，促进未来道德决策研究的进展。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CY",
        "cs.HC"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2024 Track on Datasets and Benchmarks (Spotlight)",
      "pdf_url": "http://arxiv.org/pdf/2406.20087v2",
      "published_date": "2024-06-28 17:55:24 UTC",
      "updated_date": "2024-10-31 13:10:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:38:14.585785"
    },
    {
      "arxiv_id": "2406.20080v1",
      "title": "AI for Extreme Event Modeling and Understanding: Methodologies and Challenges",
      "title_zh": "人工智能用于极端事件建模与理解：方法论和挑战",
      "authors": [
        "Gustau Camps-Valls",
        "Miguel-Ángel Fernández-Torres",
        "Kai-Hendrik Cohrs",
        "Adrian Höhl",
        "Andrea Castelletti",
        "Aytac Pacal",
        "Claire Robin",
        "Francesco Martinuzzi",
        "Ioannis Papoutsis",
        "Ioannis Prapas",
        "Jorge Pérez-Aracil",
        "Katja Weigel",
        "Maria Gonzalez-Calabuig",
        "Markus Reichstein",
        "Martin Rabel",
        "Matteo Giuliani",
        "Miguel Mahecha",
        "Oana-Iuliana Popescu",
        "Oscar J. Pellicer-Valero",
        "Said Ouala",
        "Sancho Salcedo-Sanz",
        "Sebastian Sippel",
        "Spyros Kondylatos",
        "Tamara Happé",
        "Tristan Williams"
      ],
      "abstract": "In recent years, artificial intelligence (AI) has deeply impacted various\nfields, including Earth system sciences. Here, AI improved weather forecasting,\nmodel emulation, parameter estimation, and the prediction of extreme events.\nHowever, the latter comes with specific challenges, such as developing accurate\npredictors from noisy, heterogeneous and limited annotated data. This paper\nreviews how AI is being used to analyze extreme events (like floods, droughts,\nwildfires and heatwaves), highlighting the importance of creating accurate,\ntransparent, and reliable AI models. We discuss the hurdles of dealing with\nlimited data, integrating information in real-time, deploying models, and\nmaking them understandable, all crucial for gaining the trust of stakeholders\nand meeting regulatory needs. We provide an overview of how AI can help\nidentify and explain extreme events more effectively, improving disaster\nresponse and communication. We emphasize the need for collaboration across\ndifferent fields to create AI solutions that are practical, understandable, and\ntrustworthy for analyzing and predicting extreme events. Such collaborative\nefforts aim to enhance disaster readiness and disaster risk reduction.",
      "tldr_zh": "这篇论文回顾了人工智能（AI）在极端事件（如洪水、干旱、野火和热浪）建模和理解中的应用，强调AI如何提升天气预报、模型模拟和事件预测的准确性。论文讨论了关键挑战，包括从嘈杂、异构和有限标注数据中开发可靠预测器、实时整合信息以及确保模型的透明度和可部署性。最终，它呼吁跨领域合作来创建实用、可解释的AI解决方案，以增强灾害响应、风险减少和利益相关者的信任。",
      "categories": [
        "cs.AI",
        "physics.ao-ph",
        "physics.geo-ph"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.20080v1",
      "published_date": "2024-06-28 17:45:25 UTC",
      "updated_date": "2024-06-28 17:45:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:38:25.448201"
    },
    {
      "arxiv_id": "2406.20079v1",
      "title": "Molecular Facts: Desiderata for Decontextualization in LLM Fact Verification",
      "title_zh": "分子事实：LLM事实验证中去上下文化的期望特性",
      "authors": [
        "Anisha Gunjal",
        "Greg Durrett"
      ],
      "abstract": "Automatic factuality verification of large language model (LLM) generations\nis becoming more and more widely used to combat hallucinations. A major point\nof tension in the literature is the granularity of this fact-checking: larger\nchunks of text are hard to fact-check, but more atomic facts like propositions\nmay lack context to interpret correctly. In this work, we assess the role of\ncontext in these atomic facts. We argue that fully atomic facts are not the\nright representation, and define two criteria for molecular facts:\ndecontextuality, or how well they can stand alone, and minimality, or how\nlittle extra information is added to achieve decontexuality. We quantify the\nimpact of decontextualization on minimality, then present a baseline\nmethodology for generating molecular facts automatically, aiming to add the\nright amount of information. We compare against various methods of\ndecontextualization and find that molecular facts balance minimality with fact\nverification accuracy in ambiguous settings.",
      "tldr_zh": "本文探讨了在大型语言模型（LLM）事实验证中，事实粒度的问题，指出原子事实（如命题）可能因缺少上下文而难以正确解读。论文提出“分子事实”的概念，定义了两个标准：decontextuality（去上下文性，即事实能独立存在）和minimality（最小性，即添加的最少额外信息），并量化了去上下文化对最小性的影响。作者提供了一个自动生成分子事实的基线方法，并通过比较发现，这种方法在模糊环境中平衡了minimality与事实验证准确性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.20079v1",
      "published_date": "2024-06-28 17:43:48 UTC",
      "updated_date": "2024-06-28 17:43:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:38:37.235213"
    },
    {
      "arxiv_id": "2407.11019v2",
      "title": "Efficacy of Various Large Language Models in Generating Smart Contracts",
      "title_zh": "翻译失败",
      "authors": [
        "Siddhartha Chatterjee",
        "Bina Ramamurthy"
      ],
      "abstract": "This study analyzes the application of code-generating Large Language Models\nin the creation of immutable Solidity smart contracts on the Ethereum\nBlockchain. Other works have previously analyzed Artificial Intelligence code\ngeneration abilities. This paper aims to expand this to a larger scope to\ninclude programs where security and efficiency are of utmost priority such as\nsmart contracts. The hypothesis leading into the study was that LLMs in general\nwould have difficulty in rigorously implementing security details in the code,\nwhich was shown through our results, but surprisingly generally succeeded in\nmany common types of contracts. We also discovered a novel way of generating\nsmart contracts through new prompting strategies.",
      "tldr_zh": "这篇论文评估了各种 Large Language Models (LLMs) 在生成 Ethereum Blockchain 上不可变 Solidity smart contracts 的效能，扩展了现有 AI 代码生成研究，焦点放在安全性和效率至关重要的程序上。研究假设 LLMs 在严格实施安全细节方面存在困难，这一假设通过实验结果得到证实。结果显示，LLMs 在许多常见合约类型上表现出色，同时论文提出了一种通过新颖的 prompting strategies 生成 smart contracts 的创新方法。该工作为 LLMs 在高风险代码生成领域的应用提供了宝贵见解。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL",
        "I.2.2"
      ],
      "primary_category": "cs.SE",
      "comment": "18 pages, accepted for presentation at 8th annual Future of\n  Information and Communication Conference",
      "pdf_url": "http://arxiv.org/pdf/2407.11019v2",
      "published_date": "2024-06-28 17:31:47 UTC",
      "updated_date": "2024-11-05 16:21:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:38:49.580896"
    },
    {
      "arxiv_id": "2407.01619v3",
      "title": "TabSketchFM: Sketch-based Tabular Representation Learning for Data Discovery over Data Lakes",
      "title_zh": "翻译失败",
      "authors": [
        "Aamod Khatiwada",
        "Harsha Kokel",
        "Ibrahim Abdelaziz",
        "Subhajit Chaudhury",
        "Julian Dolby",
        "Oktie Hassanzadeh",
        "Zhenhan Huang",
        "Tejaswini Pedapati",
        "Horst Samulowitz",
        "Kavitha Srinivas"
      ],
      "abstract": "Enterprises have a growing need to identify relevant tables in data lakes;\ne.g. tables that are unionable, joinable, or subsets of each other. Tabular\nneural models can be helpful for such data discovery tasks. In this paper, we\npresent TabSketchFM, a neural tabular model for data discovery over data lakes.\nFirst, we propose novel pre-training: a sketch-based approach to enhance the\neffectiveness of data discovery in neural tabular models. Second, we finetune\nthe pretrained model for identifying unionable, joinable, and subset table\npairs and show significant improvement over previous tabular neural models.\nThird, we present a detailed ablation study to highlight which sketches are\ncrucial for which tasks. Fourth, we use these finetuned models to perform table\nsearch; i.e., given a query table, find other tables in a corpus that are\nunionable, joinable, or that are subsets of the query. Our results demonstrate\nsignificant improvements in F1 scores for search compared to state-of-the-art\ntechniques. Finally, we show significant transfer across datasets and tasks\nestablishing that our model can generalize across different tasks and over\ndifferent data lakes.",
      "tldr_zh": "该研究提出 TabSketchFM，一种基于 sketch 的表格表示学习模型，用于数据湖中的数据发现任务，如识别可合并、可连接或子集表。模型通过创新的 sketch-based 预训练方法增强神经表格模型的有效性，并通过微调优化表对识别任务，显著优于现有模型。实验结果显示，在表搜索任务上，TabSketchFM 的 F1 分数比最先进技术有显著提升，且模型在不同数据集和任务间表现出色转移能力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.01619v3",
      "published_date": "2024-06-28 17:28:53 UTC",
      "updated_date": "2024-12-11 19:34:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:39:01.532430"
    },
    {
      "arxiv_id": "2406.20053v1",
      "title": "Covert Malicious Finetuning: Challenges in Safeguarding LLM Adaptation",
      "title_zh": "翻译失败",
      "authors": [
        "Danny Halawi",
        "Alexander Wei",
        "Eric Wallace",
        "Tony T. Wang",
        "Nika Haghtalab",
        "Jacob Steinhardt"
      ],
      "abstract": "Black-box finetuning is an emerging interface for adapting state-of-the-art\nlanguage models to user needs. However, such access may also let malicious\nactors undermine model safety. To demonstrate the challenge of defending\nfinetuning interfaces, we introduce covert malicious finetuning, a method to\ncompromise model safety via finetuning while evading detection. Our method\nconstructs a malicious dataset where every individual datapoint appears\ninnocuous, but finetuning on the dataset teaches the model to respond to\nencoded harmful requests with encoded harmful responses. Applied to GPT-4, our\nmethod produces a finetuned model that acts on harmful instructions 99% of the\ntime and avoids detection by defense mechanisms such as dataset inspection,\nsafety evaluations, and input/output classifiers. Our findings question whether\nblack-box finetuning access can be secured against sophisticated adversaries.",
      "tldr_zh": "该论文探讨了“covert malicious finetuning”方法，该技术通过微调大型语言模型(LLM)来秘密破坏其安全性，同时规避检测。研究者构建了一个表面上无害的数据集，其中每个数据点看似 innocuous，但整体微调后，模型能以99%的准确率响应编码的恶意请求。应用于GPT-4，该方法成功避开了数据集检查、安全评估和输入/输出分类器等防御机制。论文结果质疑了黑箱微调接口是否能有效抵御高级攻击者，从而为LLM的安全性提出重大挑战。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "22 pages",
      "pdf_url": "http://arxiv.org/pdf/2406.20053v1",
      "published_date": "2024-06-28 17:05:46 UTC",
      "updated_date": "2024-06-28 17:05:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:39:14.044889"
    },
    {
      "arxiv_id": "2407.00147v1",
      "title": "Predicting Elevated Risk of Hospitalization Following Emergency Department Discharges",
      "title_zh": "预测急诊科出院后住院风险的升高",
      "authors": [
        "Dat Hong",
        "Philip M. Polgreen",
        "Alberto Maria Segre"
      ],
      "abstract": "Hospitalizations that follow closely on the heels of one or more emergency\ndepartment visits are often symptoms of missed opportunities to form a proper\ndiagnosis. These diagnostic errors imply a failure to recognize the need for\nhospitalization and deliver appropriate care, and thus also bear important\nconnotations for patient safety. In this paper, we show how data mining\ntechniques can be applied to a large existing hospitalization data set to learn\nuseful models that predict these upcoming hospitalizations with high accuracy.\nSpecifically, we use an ensemble of logistics regression, na\\\"ive Bayes and\nassociation rule classifiers to successfully predict hospitalization within 3,\n7 and 14 days of an emergency department discharge. Aside from high accuracy,\none of the advantages of the techniques proposed here is that the resulting\nclassifier is easily inspected and interpreted by humans so that the learned\nrules can be readily operationalized. These rules can then be easily\ndistributed and applied directly by physicians in emergency department settings\nto predict the risk of early admission prior to discharging their emergency\ndepartment patients.",
      "tldr_zh": "本研究探讨了紧急部门出院后短期内住院的风险预测问题，这些情况往往源于诊断错误，影响患者安全。论文利用数据挖掘技术对大型住院数据集进行分析，采用逻辑回归(logistic regression)、朴素贝叶斯(naive Bayes)和关联规则(association rule)分类器的集成方法，成功预测出院后3、7和14天内的住院事件。结果显示，该模型具有高准确率，且分类器易于解释和操作，便于医生在紧急部门直接应用以评估患者风险并优化决策。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.00147v1",
      "published_date": "2024-06-28 17:01:12 UTC",
      "updated_date": "2024-06-28 17:01:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:39:25.528627"
    },
    {
      "arxiv_id": "2406.20044v1",
      "title": "Electrostatics-based particle sampling and approximate inference",
      "title_zh": "基于静电学的粒子采样与近似推理",
      "authors": [
        "Yongchao Huang"
      ],
      "abstract": "A new particle-based sampling and approximate inference method, based on\nelectrostatics and Newton mechanics principles, is introduced with theoretical\nground, algorithm design and experimental validation. This method simulates an\ninteracting particle system (IPS) where particles, i.e. the freely-moving\nnegative charges and spatially-fixed positive charges with magnitudes\nproportional to the target distribution, interact with each other via\nattraction and repulsion induced by the resulting electric fields described by\nPoisson's equation. The IPS evolves towards a steady-state where the\ndistribution of negative charges conforms to the target distribution. This\nphysics-inspired method offers deterministic, gradient-free sampling and\ninference, achieving comparable performance as other particle-based and MCMC\nmethods in benchmark tasks of inferring complex densities, Bayesian logistic\nregression and dynamical system identification. A discrete-time, discrete-space\nalgorithmic design, readily extendable to continuous time and space, is\nprovided for usage in more general inference problems occurring in\nprobabilistic machine learning scenarios such as Bayesian inference, generative\nmodelling, and beyond.",
      "tldr_zh": "本论文提出了一种基于 Electrostatics 和 Newton mechanics 的新型粒子采样和近似推理方法，通过模拟相互作用粒子系统（IPS），其中负电荷粒子自由移动、正电荷粒子固定，且电荷大小与目标分布成正比，系统经由 Poisson's equation 引导的吸引和排斥力演化至稳态。 该方法采用确定性、梯度-free 的设计，在推断复杂密度、Bayesian logistic regression 和动态系统识别等基准任务中，与粒子-based 和 MCMC 方法表现出可比性能。 此外，论文提供了离散时间和空间的算法设计，可扩展到连续场景，并适用于概率机器学习领域，如 Bayesian inference 和 generative modelling。",
      "categories": [
        "cs.AI",
        "stat.CO",
        "stat.ML"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.20044v1",
      "published_date": "2024-06-28 16:53:06 UTC",
      "updated_date": "2024-06-28 16:53:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:39:49.439723"
    },
    {
      "arxiv_id": "2407.17476v1",
      "title": "ORCDF: An Oversmoothing-Resistant Cognitive Diagnosis Framework for Student Learning in Online Education Systems",
      "title_zh": "ORCDF：抗过度平滑的认知诊断框架，用于在线教育系统中的学生学习",
      "authors": [
        "Hong Qian",
        "Shuo Liu",
        "Mingjia Li",
        "Bingdong Li",
        "Zhi Liu",
        "Aimin Zhou"
      ],
      "abstract": "Cognitive diagnosis models (CDMs) are designed to learn students' mastery\nlevels using their response logs. CDMs play a fundamental role in online\neducation systems since they significantly influence downstream applications\nsuch as teachers' guidance and computerized adaptive testing. Despite the\nsuccess achieved by existing CDMs, we find that they suffer from a thorny issue\nthat the learned students' mastery levels are too similar. This issue, which we\nrefer to as oversmoothing, could diminish the CDMs' effectiveness in downstream\ntasks. CDMs comprise two core parts: learning students' mastery levels and\nassessing mastery levels by fitting the response logs. This paper contends that\nthe oversmoothing issue arises from that existing CDMs seldom utilize response\nsignals on exercises in the learning part but only use them as labels in the\nassessing part. To this end, this paper proposes an oversmoothing-resistant\ncognitive diagnosis framework (ORCDF) to enhance existing CDMs by utilizing\nresponse signals in the learning part. Specifically, ORCDF introduces a novel\nresponse graph to inherently incorporate response signals as types of edges.\nThen, ORCDF designs a tailored response-aware graph convolution network (RGC)\nthat effectively captures the crucial response signals within the response\ngraph. Via ORCDF, existing CDMs are enhanced by replacing the input embeddings\nwith the outcome of RGC, allowing for the consideration of response signals on\nexercises in the learning part. Extensive experiments on real-world datasets\nshow that ORCDF not only helps existing CDMs alleviate the oversmoothing issue\nbut also significantly enhances the models' prediction and interpretability\nperformance. Moreover, the effectiveness of ORCDF is validated in the\ndownstream task of computerized adaptive testing.",
      "tldr_zh": "本研究针对认知诊断模型 (CDMs) 在在线教育系统中存在的 oversmoothing 问题——即学生掌握水平学得过于相似，导致下游任务如教师指导和计算机化适应性测试效果减弱——提出了一种抗 oversmoothing 的框架 ORCDF。ORCDF 通过引入 response graph 将响应信号作为边类型，并设计 response-aware graph convolution network (RGC) 来在模型的学习部分有效捕获这些信号，从而增强现有 CDMs 的输入嵌入。实验在真实数据集上验证，ORCDF 不仅显著缓解了 oversmoothing 问题，还提升了模型的预测性能、可解释性和在计算机化适应性测试等下游任务中的表现。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.17476v1",
      "published_date": "2024-06-28 16:42:53 UTC",
      "updated_date": "2024-06-28 16:42:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:39:49.896860"
    },
    {
      "arxiv_id": "2406.20041v3",
      "title": "BMW Agents -- A Framework For Task Automation Through Multi-Agent Collaboration",
      "title_zh": "BMW Agents -- 一种",
      "authors": [
        "Noel Crawford",
        "Edward B. Duffy",
        "Iman Evazzade",
        "Torsten Foehr",
        "Gregory Robbins",
        "Debbrata Kumar Saha",
        "Jiya Varma",
        "Marcin Ziolkowski"
      ],
      "abstract": "Autonomous agents driven by Large Language Models (LLMs) offer enormous\npotential for automation. Early proof of this technology can be found in\nvarious demonstrations of agents solving complex tasks, interacting with\nexternal systems to augment their knowledge, and triggering actions. In\nparticular, workflows involving multiple agents solving complex tasks in a\ncollaborative fashion exemplify their capacity to operate in less strict and\nless well-defined environments. Thus, a multi-agent approach has great\npotential for serving as a backbone in many industrial applications, ranging\nfrom complex knowledge retrieval systems to next generation robotic process\nautomation. Given the reasoning abilities within the current generation of\nLLMs, complex processes require a multi-step approach that includes a plan of\nwell-defined and modular tasks. Depending on the level of complexity, these\ntasks can be executed either by a single agent or a group of agents. In this\nwork, we focus on designing a flexible agent engineering framework with careful\nattention to planning and execution, capable of handling complex use case\napplications across various domains. The proposed framework provides\nreliability in industrial applications and presents techniques to ensure a\nscalable, flexible, and collaborative workflow for multiple autonomous agents\nworking together towards solving tasks.",
      "tldr_zh": "这篇论文介绍了 BMW Agents 框架，这是一个基于大型语言模型 (LLMs) 的多代理协作系统，旨在通过自治代理实现复杂任务的自动化。框架强调多步规划和模块化任务设计，允许单个代理或代理组根据任务复杂度进行协作，从而处理不严格环境的工业应用，如知识检索系统和机器人过程自动化。实验结果显示，该框架提供可靠、可扩展和灵活的工作流，提升了代理在各种领域的任务执行效率。",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "24 pages. 21 PDF images",
      "pdf_url": "http://arxiv.org/pdf/2406.20041v3",
      "published_date": "2024-06-28 16:39:20 UTC",
      "updated_date": "2024-07-02 11:45:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:40:02.338490"
    },
    {
      "arxiv_id": "2407.00146v1",
      "title": "The Qiyas Benchmark: Measuring ChatGPT Mathematical and Language Understanding in Arabic",
      "title_zh": "翻译失败",
      "authors": [
        "Shahad Al-Khalifa",
        "Hend Al-Khalifa"
      ],
      "abstract": "Despite the growing importance of Arabic as a global language, there is a\nnotable lack of language models pre-trained exclusively on Arabic data. This\nshortage has led to limited benchmarks available for assessing language model\nperformance in Arabic. To address this gap, we introduce two novel benchmarks\ndesigned to evaluate models' mathematical reasoning and language understanding\nabilities in Arabic. These benchmarks are derived from a General Aptitude Test\n(GAT) called Qiyas exam, a standardized test widely used for university\nadmissions in Saudi Arabia. For validation purposes, we assess the performance\nof ChatGPT-3.5-trubo and ChatGPT-4 on our benchmarks. Our findings reveal that\nthese benchmarks pose a significant challenge, with ChatGPT-4 achieving an\noverall average accuracy of 64%, while ChatGPT-3.5-trubo achieved an overall\naccuracy of 49% across the various question types in the Qiyas benchmark. We\nbelieve the release of these benchmarks will pave the way for enhancing the\nmathematical reasoning and language understanding capabilities of future models\ntailored for the low-resource Arabic language.",
      "tldr_zh": "该论文介绍了Qiyas Benchmark，这是一个新基准，用于评估语言模型在阿拉伯语中的数学推理和语言理解能力，以填补阿拉伯语模型评估的空白。该基准基于沙特阿拉伯的标准化大学入学考试Qiyas考试，测试了ChatGPT-3.5-turbo和ChatGPT-4的表现，结果显示ChatGPT-4的平均准确率为64%，而ChatGPT-3.5-turbo为49%。通过发布这些基准，论文旨在提升未来针对低资源语言如阿拉伯语的模型在数学推理和语言理解方面的能力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.00146v1",
      "published_date": "2024-06-28 16:34:31 UTC",
      "updated_date": "2024-06-28 16:34:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:40:15.732228"
    },
    {
      "arxiv_id": "2407.09556v1",
      "title": "Explainable Image Captioning using CNN- CNN architecture and Hierarchical Attention",
      "title_zh": "翻译失败",
      "authors": [
        "Rishi Kesav Mohan",
        "Sanjay Sureshkumar",
        "Vignesh Sivasubramaniam"
      ],
      "abstract": "Image captioning is a technology that produces text-based descriptions for an\nimage. Deep learning-based solutions built on top of feature recognition may\nvery well serve the purpose. But as with any other machine learning solution,\nthe user understanding in the process of caption generation is poor and the\nmodel does not provide any explanation for its predictions and hence the\nconventional methods are also referred to as Black-Box methods. Thus, an\napproach where the model's predictions are trusted by the user is needed to\nappreciate interoperability. Explainable AI is an approach where a conventional\nmethod is approached in a way that the model or the algorithm's predictions can\nbe explainable and justifiable. Thus, this article tries to approach image\ncaptioning using Explainable AI such that the resulting captions generated by\nthe model can be Explained and visualized. A newer architecture with a CNN\ndecoder and hierarchical attention concept has been used to increase speed and\naccuracy of caption generation. Also, incorporating explainability to a model\nmakes it more trustable when used in an application. The model is trained and\nevaluated using MSCOCO dataset and both quantitative and qualitative results\nare presented in this article.",
      "tldr_zh": "这篇论文针对传统图像字幕模型的黑盒问题，提出了一种基于 Explainable AI 的方法，使用 CNN-CNN 架构和 Hierarchical Attention 来生成可解释的图像描述。\n该方法通过 CNN 解码器和分层注意力机制，提高了字幕生成的速度和准确性，同时增强了模型的可信任性。\n模型在 MSCOCO 数据集上进行训练和评估，并提供了定量和定性结果，以证明其有效性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "68T50",
        "I.2.7"
      ],
      "primary_category": "cs.CV",
      "comment": "23 pages,9 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.09556v1",
      "published_date": "2024-06-28 16:27:47 UTC",
      "updated_date": "2024-06-28 16:27:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:40:26.545175"
    },
    {
      "arxiv_id": "2406.20031v1",
      "title": "Pairwise Difference Learning for Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Mohamed Karim Belaid",
        "Maximilian Rabus",
        "Eyke Hüllermeier"
      ],
      "abstract": "Pairwise difference learning (PDL) has recently been introduced as a new\nmeta-learning technique for regression. Instead of learning a mapping from\ninstances to outcomes in the standard way, the key idea is to learn a function\nthat takes two instances as input and predicts the difference between the\nrespective outcomes. Given a function of this kind, predictions for a query\ninstance are derived from every training example and then averaged. This paper\nextends PDL toward the task of classification and proposes a meta-learning\ntechnique for inducing a PDL classifier by solving a suitably defined (binary)\nclassification problem on a paired version of the original training data. We\nanalyze the performance of the PDL classifier in a large-scale empirical study\nand find that it outperforms state-of-the-art methods in terms of prediction\nperformance. Last but not least, we provide an easy-to-use and publicly\navailable implementation of PDL in a Python package.",
      "tldr_zh": "该论文扩展了 Pairwise Difference Learning (PDL) 到分类任务，作为一种元学习(meta-learning)技术，其核心是将两个实例作为输入，学习预测它们之间结果差异的函数，然后通过平均差异来生成查询实例的预测。\n作者提出了一种通过在配对版本的原始训练数据上解决二元分类问题来诱导 PDL 分类器的方法。\n实证研究显示，PDL 分类器在预测性能上优于现有最先进方法。\n此外，论文提供了易于使用的公开 Python 包实现。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.20031v1",
      "published_date": "2024-06-28 16:20:22 UTC",
      "updated_date": "2024-06-28 16:20:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:40:39.064577"
    },
    {
      "arxiv_id": "2406.20015v2",
      "title": "ToolBeHonest: A Multi-level Hallucination Diagnostic Benchmark for Tool-Augmented Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yuxiang Zhang",
        "Jing Chen",
        "Junjie Wang",
        "Yaxin Liu",
        "Cheng Yang",
        "Chufan Shi",
        "Xinyu Zhu",
        "Zihao Lin",
        "Hanwen Wan",
        "Yujiu Yang",
        "Tetsuya Sakai",
        "Tian Feng",
        "Hayato Yamana"
      ],
      "abstract": "Tool-augmented large language models (LLMs) are rapidly being integrated into\nreal-world applications. Due to the lack of benchmarks, the community has yet\nto fully understand the hallucination issues within these models. To address\nthis challenge, we introduce a comprehensive diagnostic benchmark, ToolBH.\nSpecifically, we assess the LLM's hallucinations through two perspectives:\ndepth and breadth. In terms of depth, we propose a multi-level diagnostic\nprocess, including (1) solvability detection, (2) solution planning, and (3)\nmissing-tool analysis. For breadth, we consider three scenarios based on the\ncharacteristics of the toolset: missing necessary tools, potential tools, and\nlimited functionality tools. Furthermore, we developed seven tasks and\ncollected 700 evaluation samples through multiple rounds of manual annotation.\nThe results show the significant challenges presented by the ToolBH benchmark.\nThe current advanced models Gemini-1.5-Pro and GPT-4o only achieve total scores\nof 45.3 and 37.0, respectively, on a scale of 100. In this benchmark, larger\nmodel parameters do not guarantee better performance; the training data and\nresponse strategies also play crucial roles in tool-enhanced LLM scenarios. Our\ndiagnostic analysis indicates that the primary reason for model errors lies in\nassessing task solvability. Additionally, open-weight models suffer from\nperformance drops with verbose replies, whereas proprietary models excel with\nlonger reasoning.",
      "tldr_zh": "这篇论文引入了 ToolBeHonest 基准（ToolBH），一个多级诊断工具，用于评估工具增强大型语言模型（LLMs）中的幻觉问题，从深度（包括可解决性检测、解决方案规划和缺失工具分析）和广度（覆盖缺失必要工具、潜在工具及功能有限工具的场景）两个维度进行全面评估。研究者开发了七个任务并收集了700个手动标注样本，结果显示当前先进模型如Gemini-1.5-Pro和GPT-4o的分数仅为45.3和37.0（满分100），表明模型参数大小并非关键，训练数据和响应策略对性能影响更大，主要错误源于任务可解决性的判断。开源模型在冗长回复中表现较差，而专有模型在更长推理中更占优势。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.20015v2",
      "published_date": "2024-06-28 16:03:30 UTC",
      "updated_date": "2024-10-04 07:51:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:40:51.791972"
    },
    {
      "arxiv_id": "2407.00142v1",
      "title": "Graph Neural Networks for Gut Microbiome Metaomic data: A preliminary work",
      "title_zh": "翻译失败",
      "authors": [
        "Christopher Irwin",
        "Flavio Mignone",
        "Stefania Montani",
        "Luigi Portinale"
      ],
      "abstract": "The gut microbiome, crucial for human health, presents challenges in\nanalyzing its complex metaomic data due to high dimensionality and sparsity.\nTraditional methods struggle to capture its intricate relationships. We\ninvestigate graph neural networks (GNNs) for this task, aiming to derive\nmeaningful representations of individual gut microbiomes. Unlike methods\nrelying solely on taxa abundance, we directly leverage phylogenetic\nrelationships, in order to obtain a generalized encoder for taxa networks. The\nrepresentation learnt from the encoder are then used to train a model for\nphenotype prediction such as Inflammatory Bowel Disease (IBD).",
      "tldr_zh": "该论文探讨了使用 Graph Neural Networks (GNNs) 来分析肠道微生物组的元组数据，以应对其高维度和稀疏性带来的复杂关系挑战。不同于传统方法仅依赖物种丰度，该研究直接利用系统发育关系构建一个通用编码器，用于获取微生物组的有意义表示。这些表示随后被应用于训练模型，以预测如 Inflammatory Bowel Disease (IBD) 等表型，作为一项初步工作，展示了 GNNs 在该领域的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.00142v1",
      "published_date": "2024-06-28 15:53:36 UTC",
      "updated_date": "2024-06-28 15:53:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:41:02.674881"
    },
    {
      "arxiv_id": "2406.19997v2",
      "title": "Wavelets Are All You Need for Autoregressive Image Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Wael Mattar",
        "Idan Levy",
        "Nir Sharon",
        "Shai Dekel"
      ],
      "abstract": "In this paper, we take a new approach to autoregressive image generation that\nis based on two main ingredients. The first is wavelet image coding, which\nallows to tokenize the visual details of an image from coarse to fine details\nby ordering the information starting with the most significant bits of the most\nsignificant wavelet coefficients. The second is a variant of a language\ntransformer whose architecture is re-designed and optimized for token sequences\nin this 'wavelet language'. The transformer learns the significant statistical\ncorrelations within a token sequence, which are the manifestations of\nwell-known correlations between the wavelet subbands at various resolutions. We\nshow experimental results with conditioning on the generation process.",
      "tldr_zh": "本论文提出了一种基于小波图像编码（wavelet image coding）的新型自回归（autoregressive）图像生成方法，仅需小波技术即可实现高效生成。方法的核心包括从小波系数的显著位开始标记化图像细节，从粗到细组织信息，以及一种重新设计优化的Transformer变体，用于处理这些“小波语言”标记序列，从而学习不同分辨率小波子带（wavelet subbands）的统计相关性。实验结果展示了该方法在条件生成过程中的有效性，提供了一种简洁而强大的图像生成框架。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "65T60",
        "I.4.2; I.4.5; I.4.10"
      ],
      "primary_category": "cs.LG",
      "comment": "17 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.19997v2",
      "published_date": "2024-06-28 15:32:59 UTC",
      "updated_date": "2024-11-19 12:28:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:41:13.718064"
    },
    {
      "arxiv_id": "2406.19995v1",
      "title": "Single Parent Family: A Spectrum of Family Members from a Single Pre-Trained Foundation Model",
      "title_zh": "翻译失败",
      "authors": [
        "Habib Hajimolahoseini",
        "Mohammad Hassanpour",
        "Foozhan Ataiefard",
        "Boxing Chen",
        "Yang Liu"
      ],
      "abstract": "This paper introduces a novel method of Progressive Low Rank Decomposition\n(PLRD) tailored for the compression of large language models. Our approach\nleverages a pre-trained model, which is then incrementally decompressed to\nsmaller sizes using progressively lower ranks. This method allows for\nsignificant reductions in computational overhead and energy consumption, as\nsubsequent models are derived from the original without the need for retraining\nfrom scratch. We detail the implementation of PLRD, which strategically\ndecreases the tensor ranks, thus optimizing the trade-off between model\nperformance and resource usage. The efficacy of PLRD is demonstrated through\nextensive experiments showing that models trained with PLRD method on only 1B\ntokens maintain comparable performance with traditionally trained models while\nusing 0.1% of the tokens. The versatility of PLRD is highlighted by its ability\nto generate multiple model sizes from a single foundational model, adapting\nfluidly to varying computational and memory budgets. Our findings suggest that\nPLRD could set a new standard for the efficient scaling of LLMs, making\nadvanced AI more feasible on diverse platforms.",
      "tldr_zh": "本论文提出了一种名为 Progressive Low Rank Decomposition (PLRD) 的新方法，用于压缩大型语言模型 (LLMs)。该方法从一个预训练模型出发，通过逐步降低张量秩来递增解压缩生成更小模型，从而显著减少计算开销和能源消耗，而无需从零重新训练。实验结果显示，使用 PLRD 训练的模型仅需 1B tokens 即可达到与传统模型相当的性能，却只用了 0.1% 的 tokens。此外，PLRD 的灵活性允许从单一基础模型生成多种大小的模型，适应不同的计算和内存预算，从而为高效缩放 LLMs 设置新标准。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.19995v1",
      "published_date": "2024-06-28 15:27:57 UTC",
      "updated_date": "2024-06-28 15:27:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:41:26.393220"
    },
    {
      "arxiv_id": "2407.00141v1",
      "title": "Towards Secure and Efficient Data Scheduling for Vehicular Social Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Youhua Xia",
        "Tiehua Zhang",
        "Jiong Jin",
        "Ying He",
        "Fei Yu"
      ],
      "abstract": "Efficient data transmission scheduling within vehicular environments poses a\nsignificant challenge due to the high mobility of such networks. Contemporary\nresearch predominantly centers on crafting cooperative scheduling algorithms\ntailored for vehicular networks. Notwithstanding, the intricacies of\norchestrating scheduling in vehicular social networks both effectively and\nefficiently remain formidable. This paper introduces an innovative\nlearning-based algorithm for scheduling data transmission that prioritizes\nefficiency and security within vehicular social networks. The algorithm first\nuses a specifically constructed neural network to enhance data processing\ncapabilities. After this, it incorporates a Q-learning paradigm during the data\ntransmission phase to optimize the information exchange, the privacy of which\nis safeguarded by differential privacy through the communication process.\nComparative experiments demonstrate the superior performance of the proposed\nQ-learning enhanced scheduling algorithm relative to existing state-of-the-art\nscheduling algorithms in the context of vehicular social networks.",
      "tldr_zh": "这篇论文针对车载社交网络（vehicular social networks）中数据传输调度的挑战，提出了一种基于学习的算法，以提升效率和安全。算法首先利用一个专门构建的neural network增强数据处理能力，然后通过Q-learning范式优化信息交换过程，同时采用differential privacy机制保护隐私。实验比较结果表明，该算法在车载社交网络的性能上优于现有最先进调度算法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.00141v1",
      "published_date": "2024-06-28 15:20:50 UTC",
      "updated_date": "2024-06-28 15:20:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:41:37.551905"
    },
    {
      "arxiv_id": "2406.19967v1",
      "title": "Into the Unknown: Generating Geospatial Descriptions for New Environments",
      "title_zh": "翻译失败",
      "authors": [
        "Tzuf Paz-Argaman",
        "John Palowitch",
        "Sayali Kulkarni",
        "Reut Tsarfaty",
        "Jason Baldridge"
      ],
      "abstract": "Similar to vision-and-language navigation (VLN) tasks that focus on bridging\nthe gap between vision and language for embodied navigation, the new Rendezvous\n(RVS) task requires reasoning over allocentric spatial relationships\n(independent of the observer's viewpoint) using non-sequential navigation\ninstructions and maps. However, performance substantially drops in new\nenvironments with no training data. Using opensource descriptions paired with\ncoordinates (e.g., Wikipedia) provides training data but suffers from limited\nspatially-oriented text resulting in low geolocation resolution. We propose a\nlarge-scale augmentation method for generating high-quality synthetic data for\nnew environments using readily available geospatial data. Our method constructs\na grounded knowledge-graph, capturing entity relationships. Sampled entities\nand relations (`shop north of school') generate navigation instructions via (i)\ngenerating numerous templates using context-free grammar (CFG) to embed\nspecific entities and relations; (ii) feeding the entities and relation into a\nlarge language model (LLM) for instruction generation. A comprehensive\nevaluation on RVS, showed that our approach improves the 100-meter accuracy by\n45.83% on unseen environments. Furthermore, we demonstrate that models trained\nwith CFG-based augmentation achieve superior performance compared with those\ntrained with LLM-based augmentation, both in unseen and seen environments.\nThese findings suggest that the potential advantages of explicitly structuring\nspatial information for text-based geospatial reasoning in previously unknown,\ncan unlock data-scarce scenarios.",
      "tldr_zh": "这篇论文针对 Rendezvous (RVS) 任务，提出了一种大规模数据增强方法，用于生成高质量的地理空间描述，以解决在新环境中模型性能下降的问题。该方法通过构建 grounded knowledge-graph 来捕捉实体关系，然后采样实体和关系，利用上下文无关文法 (CFG) 生成模板或输入大型语言模型 (LLM) 产生导航指令。实验在 RVS 任务上显示，该方法在未见过环境中将 100 米准确率提高了 45.83%，且 CFG-based 增强比 LLM-based 增强在可见和不可见环境中表现更优。这些发现表明，显式结构化空间信息有助于文本-based 地理空间推理在数据稀缺的未知场景中取得进展。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.19967v1",
      "published_date": "2024-06-28 14:56:21 UTC",
      "updated_date": "2024-06-28 14:56:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:41:52.420947"
    },
    {
      "arxiv_id": "2406.19963v3",
      "title": "Text2Robot: Evolutionary Robot Design from Text Descriptions",
      "title_zh": "Text2Robot：基于文本描述的进化机器人设计",
      "authors": [
        "Ryan P. Ringel",
        "Zachary S. Charlick",
        "Jiaxun Liu",
        "Boxi Xia",
        "Boyuan Chen"
      ],
      "abstract": "Robot design has traditionally been costly and labor-intensive. Despite\nadvancements in automated processes, it remains challenging to navigate a vast\ndesign space while producing physically manufacturable robots. We introduce\nText2Robot, a framework that converts user text specifications and performance\npreferences into physical quadrupedal robots. Within minutes, Text2Robot can\nuse text-to-3D models to provide strong initializations of diverse\nmorphologies. Within a day, our geometric processing algorithms and\nbody-control co-optimization produce a walking robot by explicitly considering\nreal-world electronics and manufacturability. Text2Robot enables rapid\nprototyping and opens new opportunities for robot design with generative\nmodels.",
      "tldr_zh": "这篇论文提出了 Text2Robot 框架，用于从用户文本描述和性能偏好中自动设计物理四足机器人，显著简化了传统耗时费力的机器人设计过程。该框架首先利用 text-to-3D 模型在几分钟内生成多样化的初始形态，然后通过几何处理算法和身体-控制联合优化，考虑真实电子元件和可制造性要求，快速生产出能行走的机器人。结果显示，Text2Robot 能在短时间内实现高效原型设计，并为基于生成模型的机器人创新打开新机遇。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Our project website is at: http://generalroboticslab.com/Text2Robot",
      "pdf_url": "http://arxiv.org/pdf/2406.19963v3",
      "published_date": "2024-06-28 14:51:01 UTC",
      "updated_date": "2025-02-26 02:47:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:42:04.798888"
    },
    {
      "arxiv_id": "2406.19953v1",
      "title": "Uncovering the hidden core-periphery structure in hyperbolic networks",
      "title_zh": "揭示双曲网络中隐藏的核心-外围结构",
      "authors": [
        "Imran Ansari",
        "Pawanesh Yadav",
        "Niteesh Sahni"
      ],
      "abstract": "The hyperbolic network models exhibit very fundamental and essential\nfeatures, like small-worldness, scale-freeness, high-clustering coefficient,\nand community structure. In this paper, we comprehensively explore the presence\nof an important feature, the core-periphery structure, in the hyperbolic\nnetwork models, which is often exhibited by real-world networks. We focused on\nwell-known hyperbolic models such as popularity-similarity optimization model\n(PSO) and S1/H2 models and studied core-periphery structures using a\nwell-established method that is based on standard random walk Markov chain\nmodel. The observed core-periphery centralization values indicate that the\ncore-periphery structure can be very pronounced under certain conditions. We\nalso validate our findings by statistically testing for the significance of the\nobserved core-periphery structure in the network geometry. This study extends\nnetwork science and reveals core-periphery insights applicable to various\ndomains, enhancing network performance and resiliency in transportation and\ninformation systems.",
      "tldr_zh": "本文研究揭示了双曲网络（hyperbolic networks）中隐藏的核心-外围结构（core-periphery structure），这是一种真实网络常见的特征。作者针对流行度-相似度优化模型（PSO）和 S1/H2 models，使用基于标准随机游走马尔可夫链的方法进行分析，发现该结构在特定条件下非常显著，并通过统计测试验证其在网络几何中的显著性。该研究扩展了网络科学领域，并为提升交通和信息系统的网络性能和弹性提供了重要见解。",
      "categories": [
        "physics.soc-ph",
        "cs.AI"
      ],
      "primary_category": "physics.soc-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.19953v1",
      "published_date": "2024-06-28 14:39:21 UTC",
      "updated_date": "2024-06-28 14:39:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:42:17.553765"
    },
    {
      "arxiv_id": "2407.00138v1",
      "title": "Analyzing Quality, Bias, and Performance in Text-to-Image Generative Models",
      "title_zh": "翻译失败",
      "authors": [
        "Nila Masrourisaadat",
        "Nazanin Sedaghatkish",
        "Fatemeh Sarshartehrani",
        "Edward A. Fox"
      ],
      "abstract": "Advances in generative models have led to significant interest in image\nsynthesis, demonstrating the ability to generate high-quality images for a\ndiverse range of text prompts. Despite this progress, most studies ignore the\npresence of bias. In this paper, we examine several text-to-image models not\nonly by qualitatively assessing their performance in generating accurate images\nof human faces, groups, and specified numbers of objects but also by presenting\na social bias analysis. As expected, models with larger capacity generate\nhigher-quality images. However, we also document the inherent gender or social\nbiases these models possess, offering a more complete understanding of their\nimpact and limitations.",
      "tldr_zh": "本论文分析了text-to-image generative models的质量、偏见和性能，强调了现有研究忽略偏见问题的局限性。通过定性评估，这些模型在生成人脸、群体和指定物体数量的图像准确性方面表现如何，并进行了社会偏见分析。结果显示，容量更大的模型能产生更高质量的图像，但也存在固有的gender or social biases，这为理解这些模型的影响和限制提供了更全面的洞见。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "I.2.6; I.2.10; I.2.7; I.4.10"
      ],
      "primary_category": "cs.AI",
      "comment": "20 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.00138v1",
      "published_date": "2024-06-28 14:10:42 UTC",
      "updated_date": "2024-06-28 14:10:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:42:28.973236"
    },
    {
      "arxiv_id": "2406.19934v2",
      "title": "From the Least to the Most: Building a Plug-and-Play Visual Reasoner via Data Synthesis",
      "title_zh": "翻译失败",
      "authors": [
        "Chuanqi Cheng",
        "Jian Guan",
        "Wei Wu",
        "Rui Yan"
      ],
      "abstract": "We explore multi-step reasoning in vision-language models (VLMs). The problem\nis challenging, as reasoning data consisting of multiple steps of visual and\nlanguage processing are barely available. To overcome the challenge, we first\nintroduce a least-to-most visual reasoning paradigm, which interleaves steps of\ndecomposing a question into sub-questions and invoking external tools for\nresolving sub-questions. Based on the paradigm, we further propose a novel data\nsynthesis approach that can automatically create questions and multi-step\nreasoning paths for an image in a bottom-up manner. Our approach divides the\ncomplex synthesis task into a few simple sub-tasks, and (almost entirely)\nrelies on open-sourced models to accomplish the sub-tasks. Therefore, the\nentire synthesis process is reproducible and cost-efficient, and the\nsynthesized data is quality guaranteed. With the approach, we construct $50$k\nvisual reasoning examples. Then, we develop a visual reasoner through\nsupervised fine-tuning, which is capable of generally enhancing the reasoning\nabilities of a wide range of existing VLMs in a plug-and-play fashion.\nExtensive experiments indicate that the visual reasoner can consistently and\nsignificantly improve four VLMs on four VQA benchmarks. Our code and dataset\nare available at https://github.com/steven-ccq/VisualReasoner.",
      "tldr_zh": "本文探讨了视觉语言模型(VLMs)中多步推理的挑战，并引入了least-to-most visual reasoning paradigm，该方法通过分解问题为子问题并调用外部工具来生成推理路径。研究提出了一种数据合成方法，将复杂任务分解为简单子任务，使用开源模型自动创建50k视觉推理示例，确保过程可复现、成本低且质量可靠。最终，他们通过监督微调开发了一个plug-and-play视觉推理器，能够显著提升四种VLMs在四个VQA benchmarks上的性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by EMNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.19934v2",
      "published_date": "2024-06-28 14:04:10 UTC",
      "updated_date": "2024-10-11 15:41:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:42:41.186847"
    },
    {
      "arxiv_id": "2406.19931v2",
      "title": "Decoupling General and Personalized Knowledge in Federated Learning via Additive and Low-Rank Decomposition",
      "title_zh": "翻译失败",
      "authors": [
        "Xinghao Wu",
        "Xuefeng Liu",
        "Jianwei Niu",
        "Haolin Wang",
        "Shaojie Tang",
        "Guogang Zhu",
        "Hao Su"
      ],
      "abstract": "To address data heterogeneity, the key strategy of Personalized Federated\nLearning (PFL) is to decouple general knowledge (shared among clients) and\nclient-specific knowledge, as the latter can have a negative impact on\ncollaboration if not removed. Existing PFL methods primarily adopt a parameter\npartitioning approach, where the parameters of a model are designated as one of\ntwo types: parameters shared with other clients to extract general knowledge\nand parameters retained locally to learn client-specific knowledge. However, as\nthese two types of parameters are put together like a jigsaw puzzle into a\nsingle model during the training process, each parameter may simultaneously\nabsorb both general and client-specific knowledge, thus struggling to separate\nthe two types of knowledge effectively. In this paper, we introduce FedDecomp,\na simple but effective PFL paradigm that employs parameter additive\ndecomposition to address this issue. Instead of assigning each parameter of a\nmodel as either a shared or personalized one, FedDecomp decomposes each\nparameter into the sum of two parameters: a shared one and a personalized one,\nthus achieving a more thorough decoupling of shared and personalized knowledge\ncompared to the parameter partitioning method. In addition, as we find that\nretaining local knowledge of specific clients requires much lower model\ncapacity compared with general knowledge across all clients, we let the matrix\ncontaining personalized parameters be low rank during the training process.\nMoreover, a new alternating training strategy is proposed to further improve\nthe performance. Experimental results across multiple datasets and varying\ndegrees of data heterogeneity demonstrate that FedDecomp outperforms\nstate-of-the-art methods up to 4.9\\%. The code is available at\nhttps://github.com/XinghaoWu/FedDecomp.",
      "tldr_zh": "这篇论文提出 FedDecomp，一种通过参数加法分解(additive decomposition)来解耦联邦学习(Federated Learning)中的一般知识和个性化知识的方法，以解决 Personalized Federated Learning (PFL) 中数据异质性问题。不同于传统的参数分区方法，FedDecomp 将每个参数分解为共享参数和个性化参数之和，并引入 low-rank 约束和交替训练策略(alternating training strategy)，从而实现更彻底的知识分离。实验结果显示，在多个数据集和不同数据异质性条件下，FedDecomp 比最先进方法提高了高达 4.9% 的性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by ACM MM 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.19931v2",
      "published_date": "2024-06-28 14:01:22 UTC",
      "updated_date": "2024-10-11 11:30:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:42:53.633659"
    },
    {
      "arxiv_id": "2406.19896v1",
      "title": "AuthAttLyzer-V2: Unveiling Code Authorship Attribution using Enhanced Ensemble Learning Models & Generating Benchmark Dataset",
      "title_zh": "翻译失败",
      "authors": [
        "Bhaskar Joshi",
        "Sepideh HajiHossein Khani",
        "Arash HabibiLashkari"
      ],
      "abstract": "Source Code Authorship Attribution (SCAA) is crucial for software\nclassification because it provides insights into the origin and behavior of\nsoftware. By accurately identifying the author or group behind a piece of code,\nexperts can better understand the motivations and techniques of developers. In\nthe cybersecurity era, this attribution helps trace the source of malicious\nsoftware, identify patterns in the code that may indicate specific threat\nactors or groups, and ultimately enhance threat intelligence and mitigation\nstrategies. This paper presents AuthAttLyzer-V2, a new source code feature\nextractor for SCAA, focusing on lexical, semantic, syntactic, and N-gram\nfeatures. Our research explores author identification in C++ by examining\n24,000 source code samples from 3,000 authors. Our methodology integrates\nRandom Forest, Gradient Boosting, and XGBoost models, enhanced with SHAP for\ninterpretability. The study demonstrates how ensemble models can effectively\ndiscern individual coding styles, offering insights into the unique attributes\nof code authorship. This approach is pivotal in understanding and interpreting\ncomplex patterns in authorship attribution, especially for malware\nclassification.",
      "tldr_zh": "本研究提出 AuthAttLyzer-V2，一种增强的源代码作者归属（SCAA）系统，旨在通过提取 lexical、semantic、syntactic 和 N-gram 特征来识别代码作者，从而帮助软件分类和网络安全中的威胁追踪。方法整合了 Random Forest、Gradient Boosting 和 XGBoost 等 ensemble 学习模型，并使用 SHAP 提升模型可解释性，在一个包含 24,000 个 C++ 代码样本（来自 3,000 个作者）的基准数据集上进行评估。结果显示，该系统能有效辨别个人编码风格，将其应用于恶意软件分类，提供宝贵的威胁情报洞见。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.19896v1",
      "published_date": "2024-06-28 13:04:16 UTC",
      "updated_date": "2024-06-28 13:04:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:43:06.143607"
    },
    {
      "arxiv_id": "2406.19888v1",
      "title": "Fine-tuning of Geospatial Foundation Models for Aboveground Biomass Estimation",
      "title_zh": "翻译失败",
      "authors": [
        "Michal Muszynski",
        "Levente Klein",
        "Ademir Ferreira da Silva",
        "Anjani Prasad Atluri",
        "Carlos Gomes",
        "Daniela Szwarcman",
        "Gurkanwar Singh",
        "Kewen Gu",
        "Maciel Zortea",
        "Naomi Simumba",
        "Paolo Fraccaro",
        "Shraddha Singh",
        "Steve Meliksetian",
        "Campbell Watson",
        "Daiki Kimura",
        "Harini Srinivasan"
      ],
      "abstract": "Global vegetation structure mapping is critical for understanding the global\ncarbon cycle and maximizing the efficacy of nature-based carbon sequestration\ninitiatives. Moreover, vegetation structure mapping can help reduce the impacts\nof climate change by, for example, guiding actions to improve water security,\nincrease biodiversity and reduce flood risk. Global satellite measurements\nprovide an important set of observations for monitoring and managing\ndeforestation and degradation of existing forests, natural forest regeneration,\nreforestation, biodiversity restoration, and the implementation of sustainable\nagricultural practices. In this paper, we explore the effectiveness of\nfine-tuning of a geospatial foundation model to estimate above-ground biomass\n(AGB) using space-borne data collected across different eco-regions in Brazil.\nThe fine-tuned model architecture consisted of a Swin-B transformer as the\nencoder (i.e., backbone) and a single convolutional layer for the decoder head.\nAll results were compared to a U-Net which was trained as the baseline model\nExperimental results of this sparse-label prediction task demonstrate that the\nfine-tuned geospatial foundation model with a frozen encoder has comparable\nperformance to a U-Net trained from scratch. This is despite the fine-tuned\nmodel having 13 times less parameters requiring optimization, which saves both\ntime and compute resources. Further, we explore the transfer-learning\ncapabilities of the geospatial foundation models by fine-tuning on satellite\nimagery with sparse labels from different eco-regions in Brazil.",
      "tldr_zh": "本研究探讨了微调地理空间基础模型（Geospatial Foundation Models）以估计地上生物量（Aboveground Biomass, AGB），旨在通过卫星数据监控全球植被结构以支持碳循环管理和气候变化应对。方法采用 Swin-B transformer 作为编码器并冻结其参数，仅微调一个卷积层解码器，与从零训练的 U-Net 基准模型相比，该模型在巴西不同生态区的稀疏标签数据上表现出类似性能，但参数减少 13 倍，从而节省计算资源和时间。实验结果突显了该模型的迁移学习潜力，有助于更高效的全球植被映射和可持续实践。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.19888v1",
      "published_date": "2024-06-28 12:54:10 UTC",
      "updated_date": "2024-06-28 12:54:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:43:17.506691"
    },
    {
      "arxiv_id": "2406.19874v2",
      "title": "Detecting Subtle Differences between Human and Model Languages Using Spectrum of Relative Likelihood",
      "title_zh": "翻译失败",
      "authors": [
        "Yang Xu",
        "Yu Wang",
        "Hao An",
        "Zhichen Liu",
        "Yongyuan Li"
      ],
      "abstract": "Human and model-generated texts can be distinguished by examining the\nmagnitude of likelihood in language. However, it is becoming increasingly\ndifficult as language model's capabilities of generating human-like texts keep\nevolving. This study provides a new perspective by using the relative\nlikelihood values instead of absolute ones, and extracting useful features from\nthe spectrum-view of likelihood for the human-model text detection task. We\npropose a detection procedure with two classification methods, supervised and\nheuristic-based, respectively, which results in competitive performances with\nprevious zero-shot detection methods and a new state-of-the-art on short-text\ndetection. Our method can also reveal subtle differences between human and\nmodel languages, which find theoretical roots in psycholinguistics studies. Our\ncode is available at https://github.com/CLCS-SUSTech/FourierGPT",
      "tldr_zh": "本文提出了一种新方法，使用相对似然度（relative likelihood）的频谱视图（spectrum-view）来检测人类和模型生成文本的细微差异，从而解决文本鉴别难度不断增加的问题。方法包括监督式（supervised）和启发式（heuristic-based）分类程序，在人类-模型文本检测任务上取得了与零样本方法相当的性能，并在短文本检测上达到了新的state-of-the-art。研究还揭示了这些差异的微妙特征，并将其与心理语言学（psycholinguistics）理论相联系，提供开源代码以供进一步验证。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "14 pages, 12 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.19874v2",
      "published_date": "2024-06-28 12:28:52 UTC",
      "updated_date": "2024-10-09 09:36:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:43:29.654079"
    },
    {
      "arxiv_id": "2406.19859v4",
      "title": "MetaDesigner: Advancing Artistic Typography Through AI-Driven, User-Centric, and Multilingual WordArt Synthesis",
      "title_zh": "翻译失败",
      "authors": [
        "Jun-Yan He",
        "Zhi-Qi Cheng",
        "Chenyang Li",
        "Jingdong Sun",
        "Qi He",
        "Wangmeng Xiang",
        "Hanyuan Chen",
        "Jin-Peng Lan",
        "Xianhui Lin",
        "Kang Zhu",
        "Bin Luo",
        "Yifeng Geng",
        "Xuansong Xie",
        "Alexander G. Hauptmann"
      ],
      "abstract": "MetaDesigner introduces a transformative framework for artistic typography\nsynthesis, powered by Large Language Models (LLMs) and grounded in a\nuser-centric design paradigm. Its foundation is a multi-agent system comprising\nthe Pipeline, Glyph, and Texture agents, which collectively orchestrate the\ncreation of customizable WordArt, ranging from semantic enhancements to\nintricate textural elements. A central feedback mechanism leverages insights\nfrom both multimodal models and user evaluations, enabling iterative refinement\nof design parameters. Through this iterative process, MetaDesigner dynamically\nadjusts hyperparameters to align with user-defined stylistic and thematic\npreferences, consistently delivering WordArt that excels in visual quality and\ncontextual resonance. Empirical evaluations underscore the system's versatility\nand effectiveness across diverse WordArt applications, yielding outputs that\nare both aesthetically compelling and context-sensitive.",
      "tldr_zh": "MetaDesigner 提出了一种基于 Large Language Models (LLMs) 的创新框架，用于推动艺术排版合成，强调用户中心设计和多语言支持。该框架采用多智能体系统，包括 Pipeline、Glyph 和 Texture 代理，协作生成可自定义的 WordArt，从语义增强到复杂纹理元素。中央反馈机制利用多模态模型和用户评估进行迭代优化，动态调整超参数以匹配用户的风格和主题偏好。实证评估证明，MetaDesigner 在多样 WordArt 应用中表现出色，提供视觉上引人入胜且上下文相关的输出。",
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.MM"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by ICLR 2025, Project:\n  https://modelscope.cn/studios/WordArt/WordArt",
      "pdf_url": "http://arxiv.org/pdf/2406.19859v4",
      "published_date": "2024-06-28 11:58:26 UTC",
      "updated_date": "2025-02-27 08:36:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:43:40.751562"
    },
    {
      "arxiv_id": "2406.19853v1",
      "title": "YuLan: An Open-source Large Language Model",
      "title_zh": "翻译失败",
      "authors": [
        "Yutao Zhu",
        "Kun Zhou",
        "Kelong Mao",
        "Wentong Chen",
        "Yiding Sun",
        "Zhipeng Chen",
        "Qian Cao",
        "Yihan Wu",
        "Yushuo Chen",
        "Feng Wang",
        "Lei Zhang",
        "Junyi Li",
        "Xiaolei Wang",
        "Lei Wang",
        "Beichen Zhang",
        "Zican Dong",
        "Xiaoxue Cheng",
        "Yuhan Chen",
        "Xinyu Tang",
        "Yupeng Hou",
        "Qiangqiang Ren",
        "Xincheng Pang",
        "Shufang Xie",
        "Wayne Xin Zhao",
        "Zhicheng Dou",
        "Jiaxin Mao",
        "Yankai Lin",
        "Ruihua Song",
        "Jun Xu",
        "Xu Chen",
        "Rui Yan",
        "Zhewei Wei",
        "Di Hu",
        "Wenbing Huang",
        "Ze-Feng Gao",
        "Yueguo Chen",
        "Weizheng Lu",
        "Ji-Rong Wen"
      ],
      "abstract": "Large language models (LLMs) have become the foundation of many applications,\nleveraging their extensive capabilities in processing and understanding natural\nlanguage. While many open-source LLMs have been released with technical\nreports, the lack of training details hinders further research and development.\nThis paper presents the development of YuLan, a series of open-source LLMs with\n$12$ billion parameters. The base model of YuLan is pre-trained on\napproximately $1.7$T tokens derived from a diverse corpus, including massive\nEnglish, Chinese, and multilingual texts. We design a three-stage pre-training\nmethod to enhance YuLan's overall capabilities. Subsequent phases of training\nincorporate instruction-tuning and human alignment, employing a substantial\nvolume of high-quality synthesized data. To facilitate the learning of complex\nand long-tail knowledge, we devise a curriculum-learning framework throughout\nacross these stages, which helps LLMs learn knowledge in an easy-to-hard\nmanner. YuLan's training is finished on Jan, 2024 and has achieved performance\non par with state-of-the-art LLMs across various English and Chinese\nbenchmarks. This paper outlines a comprehensive technical roadmap for\ndeveloping LLMs from scratch. Our model and codes are available at\nhttps://github.com/RUC-GSAI/YuLan-Chat.",
      "tldr_zh": "本论文介绍了 YuLan，这是一个开源的 Large Language Models (LLMs) 系列，包含 12 亿参数的模型，旨在通过提供详细的训练细节来推动进一步研究。YuLan 的训练采用三阶段预训练方法，包括在 1.7T 标记的多样语料（如英语、中文和多语文本）上预训练、指令微调和人类对齐，并使用课程学习框架帮助模型从易到难掌握复杂知识。实验结果显示，YuLan 在各种英语和中文基准上达到了与最先进模型相当的性能，并已在 GitHub 上开源模型和代码。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.19853v1",
      "published_date": "2024-06-28 11:52:53 UTC",
      "updated_date": "2024-06-28 11:52:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:43:53.132656"
    },
    {
      "arxiv_id": "2406.19840v1",
      "title": "AnomaLLMy -- Detecting anomalous tokens in black-box LLMs through low-confidence single-token predictions",
      "title_zh": "翻译失败",
      "authors": [
        "Waligóra Witold"
      ],
      "abstract": "This paper introduces AnomaLLMy, a novel technique for the automatic\ndetection of anomalous tokens in black-box Large Language Models (LLMs) with\nAPI-only access. Utilizing low-confidence single-token predictions as a\ncost-effective indicator, AnomaLLMy identifies irregularities in model\nbehavior, addressing the issue of anomalous tokens degrading the quality and\nreliability of models. Validated on the cl100k_base dataset, the token set of\nGPT-4, AnomaLLMy detected 413 major and 65 minor anomalies, demonstrating the\nmethod's efficiency with just \\$24.39 spent in API credits. The insights from\nthis research are expected to be beneficial for enhancing the robustness of and\naccuracy of LLMs, particularly in the development and assessment of tokenizers.",
      "tldr_zh": "这篇论文引入了 AnomaLLMy，一种创新技术，用于自动检测 black-box LLMs 中异常标记，仅通过 API 访问实现。方法利用低-confidence single-token predictions 作为成本有效的指标，识别模型行为的异常，从而提升模型的质量和可靠性。在 cl100k_base 数据集和 GPT-4 标记集上验证，该技术检测到 413 个主要异常和 65 个次要异常，仅花费 24.39 美元 API 费用。该研究为提升 LLMs 的稳健性和准确性提供了宝贵见解，尤其在 tokenizers 的开发和评估方面。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "6 pages",
      "pdf_url": "http://arxiv.org/pdf/2406.19840v1",
      "published_date": "2024-06-28 11:28:44 UTC",
      "updated_date": "2024-06-28 11:28:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:44:06.176133"
    },
    {
      "arxiv_id": "2407.12027v1",
      "title": "Idle is the New Sleep: Configuration-Aware Alternative to Powering Off FPGA-Based DL Accelerators During Inactivity",
      "title_zh": "翻译失败",
      "authors": [
        "Chao Qian",
        "Christopher Cichiwskyj",
        "Tianheng Ling",
        "Gregor Schiele"
      ],
      "abstract": "In the rapidly evolving Internet of Things (IoT) domain, we concentrate on\nenhancing energy efficiency in Deep Learning accelerators on FPGA-based\nheterogeneous platforms, aligning with the principles of sustainable computing.\nInstead of focusing on the inference phase, we introduce innovative\noptimizations to minimize the overhead of the FPGA configuration phase. By\nfine-tuning configuration parameters correctly, we achieved a 40.13-fold\nreduction in configuration energy. Moreover, augmented with power-saving\nmethods, our Idle-Waiting strategy outperformed the traditional On-Off strategy\nin duty-cycle mode for request periods up to 499.06 ms. Specifically, at a 40\nms request period within a 4147 J energy budget, this strategy extends the\nsystem lifetime to approximately 12.39x that of the On-Off strategy.\nEmpirically validated through hardware measurements and simulations, these\noptimizations provide valuable insights and practical methods for achieving\nenergy-efficient and sustainable deployments in IoT.",
      "tldr_zh": "本研究针对 IoT 领域中的 FPGA 基 DL Accelerators，在非活动期提出了一种配置感知的 Idle-Waiting 策略，作为传统 On-Off 策略的替代方案，以提升能效并减少配置阶段开销。 通过微调配置参数，该方法实现了 40.13 倍的配置能耗减少，并在请求周期不超过 499.06 ms 的条件下，显著优于 On-Off 策略，例如在 40 ms 请求周期和 4147 J 能量预算下，将系统寿命延长至后者的 12.39 倍。 实验通过硬件测量和模拟验证，这些优化为 IoT 的能源高效和可持续部署提供了宝贵的见解和实用方法。",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "primary_category": "cs.AR",
      "comment": "Accepted by 37th GI/ITG International Conference on Architecture of\n  Computing Systems (ARCS 2024)",
      "pdf_url": "http://arxiv.org/pdf/2407.12027v1",
      "published_date": "2024-06-28 11:22:12 UTC",
      "updated_date": "2024-06-28 11:22:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:44:18.689759"
    },
    {
      "arxiv_id": "2407.12026v1",
      "title": "The Pitfalls of Publishing in the Age of LLMs: Strange and Surprising Adventures with a High-Impact NLP Journal",
      "title_zh": "翻译失败",
      "authors": [
        "Rakesh M. Verma",
        "Nachum Dershowitz"
      ],
      "abstract": "We show the fraught side of the academic publishing realm and illustrate it\nthrough a recent case study with an NLP journal.",
      "tldr_zh": "这篇论文探讨了在大型语言模型(LLMs)时代学术出版的潜在陷阱，通过一个高影响力NLP期刊的真实案例研究进行说明。作者揭示了出版过程的复杂性和风险，包括奇怪的意外事件和挑战。研究强调了LLMs可能带来的问题，如内容真实性与审查难题，对学术界提供警示和反思。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.12026v1",
      "published_date": "2024-06-28 10:58:42 UTC",
      "updated_date": "2024-06-28 10:58:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:44:28.645013"
    },
    {
      "arxiv_id": "2407.12025v1",
      "title": "LLM4DESIGN: An Automated Multi-Modal System for Architectural and Environmental Design",
      "title_zh": "LLM4DESIGN：一个自动化的多模态系统，用于建筑和环境设计",
      "authors": [
        "Ran Chen",
        "Xueqi Yao",
        "Xuhui Jiang"
      ],
      "abstract": "This study introduces LLM4DESIGN, a highly automated system for generating\narchitectural and environmental design proposals. LLM4DESIGN, relying solely on\nsite conditions and design requirements, employs Multi-Agent systems to foster\ncreativity, Retrieval Augmented Generation (RAG) to ground designs in realism,\nand Visual Language Models (VLM) to synchronize all information. This system\nresulting in coherent, multi-illustrated, and multi-textual design schemes. The\nsystem meets the dual needs of narrative storytelling and objective drawing\npresentation in generating architectural and environmental design proposals.\nExtensive comparative and ablation experiments confirm the innovativeness of\nLLM4DESIGN's narrative and the grounded applicability of its plans,\ndemonstrating its superior performance in the field of urban renewal design.\nLastly, we have created the first cross-modal design scheme dataset covering\narchitecture, landscape, interior, and urban design, providing rich resources\nfor future research.",
      "tldr_zh": "这篇论文介绍了 LLM4DESIGN，一个高度自动化的多模态系统，用于基于场地条件和设计要求生成建筑和环境设计提案。该系统通过 Multi-Agent 系统促进创意、Retrieval Augmented Generation (RAG) 确保设计的真实性，以及 Visual Language Models (VLM) 同步信息，从而产生连贯的多图示和多文本方案。实验结果显示，LLM4DESIGN 在叙事创新性和计划实用性上优于基线模型，尤其在城市更新设计领域；此外，论文还创建了首个跨模态设计方案数据集，覆盖建筑、景观、室内和城市设计，为未来研究提供宝贵资源。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.12025v1",
      "published_date": "2024-06-28 10:57:50 UTC",
      "updated_date": "2024-06-28 10:57:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:44:42.301882"
    },
    {
      "arxiv_id": "2406.19820v1",
      "title": "BeamAggR: Beam Aggregation Reasoning over Multi-source Knowledge for Multi-hop Question Answering",
      "title_zh": "翻译失败",
      "authors": [
        "Zheng Chu",
        "Jingchang Chen",
        "Qianglong Chen",
        "Haotian Wang",
        "Kun Zhu",
        "Xiyuan Du",
        "Weijiang Yu",
        "Ming Liu",
        "Bing Qin"
      ],
      "abstract": "Large language models (LLMs) have demonstrated strong reasoning capabilities.\nNevertheless, they still suffer from factual errors when tackling\nknowledge-intensive tasks. Retrieval-augmented reasoning represents a promising\napproach. However, significant challenges still persist, including inaccurate\nand insufficient retrieval for complex questions, as well as difficulty in\nintegrating multi-source knowledge. To address this, we propose Beam\nAggregation Reasoning, BeamAggR, a reasoning framework for knowledge-intensive\nmulti-hop QA. BeamAggR explores and prioritizes promising answers at each hop\nof question. Concretely, we parse the complex questions into trees, which\ninclude atom and composite questions, followed by bottom-up reasoning. For\natomic questions, the LLM conducts reasoning on multi-source knowledge to get\nanswer candidates. For composite questions, the LLM combines beam candidates,\nexplores multiple reasoning paths through probabilistic aggregation, and\nprioritizes the most promising trajectory. Extensive experiments on four\nopen-domain multi-hop reasoning datasets show that our method significantly\noutperforms SOTA methods by 8.5%. Furthermore, our analysis reveals that\nBeamAggR elicits better knowledge collaboration and answer aggregation.",
      "tldr_zh": "本论文提出BeamAggR框架，用于解决大语言模型(LLMs)在知识密集型多跳问答(multi-hop QA)中的事实错误问题，通过检索增强推理整合多源知识。BeamAggR将复杂问题解析为树结构，包括原子问题和复合问题，然后采用自下而上的推理：针对原子问题，LLM在多源知识上生成答案候选；针对复合问题，通过beam聚合和概率路径探索优先化最有前景的推理轨迹。实验结果显示，该方法在四个开放域多跳推理数据集上比现有最先进(SOTA)方法提升8.5%，并显著改善了知识协作和答案聚合能力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to ACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.19820v1",
      "published_date": "2024-06-28 10:53:48 UTC",
      "updated_date": "2024-06-28 10:53:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:44:55.163642"
    },
    {
      "arxiv_id": "2406.19815v1",
      "title": "Emotion Loss Attacking: Adversarial Attack Perception for Skeleton based on Multi-dimensional Features",
      "title_zh": "翻译失败",
      "authors": [
        "Feng Liu",
        "Qing Xu",
        "Qijian Zheng"
      ],
      "abstract": "Adversarial attack on skeletal motion is a hot topic. However, existing\nresearches only consider part of dynamic features when measuring distance\nbetween skeleton graph sequences, which results in poor imperceptibility. To\nthis end, we propose a novel adversarial attack method to attack action\nrecognizers for skeletal motions. Firstly, our method systematically proposes a\ndynamic distance function to measure the difference between skeletal motions.\nMeanwhile, we innovatively introduce emotional features for complementary\ninformation. In addition, we use Alternating Direction Method of\nMultipliers(ADMM) to solve the constrained optimization problem, which\ngenerates adversarial samples with better imperceptibility to deceive the\nclassifiers. Experiments show that our method is effective on multiple action\nclassifiers and datasets. When the perturbation magnitude measured by l norms\nis the same, the dynamic perturbations generated by our method are much lower\nthan that of other methods. What's more, we are the first to prove the\neffectiveness of emotional features, and provide a new idea for measuring the\ndistance between skeletal motions.",
      "tldr_zh": "该论文提出了一种名为 Emotion Loss Attacking 的新型对抗攻击方法，针对基于骨骼运动的动作识别器，通过整合多维动态特征来提升攻击的隐蔽性。方法包括系统定义动态距离函数、引入情感 features 作为补充信息，以及利用 ADMM (Alternating Direction Method of Multipliers) 解决约束优化问题，以生成更低扰动幅度的对抗样本。实验结果表明，该方法在多个动作分类器和数据集上表现出色，在相同的 l norms 扰动幅度下，动态扰动显著低于其他方法，并首次证明了情感 features 的有效性，为骨骼运动距离测量提供了新思路。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.19815v1",
      "published_date": "2024-06-28 10:45:37 UTC",
      "updated_date": "2024-06-28 10:45:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:45:06.259911"
    },
    {
      "arxiv_id": "2407.00134v1",
      "title": "A Simple Attention-Based Mechanism for Bimodal Emotion Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Mazen Elabd",
        "Sardar Jaf"
      ],
      "abstract": "Big data contain rich information for machine learning algorithms to utilize\nwhen learning important features during classification tasks. Human beings\nexpress their emotion using certain words, speech (tone, pitch, speed) or\nfacial expression. Artificial Intelligence approach to emotion classification\nare largely based on learning from textual information. However, public\ndatasets containing text and speech data provide sufficient resources to train\nmachine learning algorithms for the tack of emotion classification. In this\npaper, we present novel bimodal deep learning-based architectures enhanced with\nattention mechanism trained and tested on text and speech data for emotion\nclassification. We report details of different deep learning based\narchitectures and show the performance of each architecture including rigorous\nerror analyses. Our finding suggests that deep learning based architectures\ntrained on different types of data (text and speech) outperform architectures\ntrained only on text or speech. Our proposed attention-based bimodal\narchitecture outperforms several state-of-the-art systems in emotion\nclassification.",
      "tldr_zh": "这篇论文提出了一种简单的基于attention mechanism的双模态深度学习架构，用于情感分类，结合文字和语音数据来捕捉人类情感表达。研究比较了不同架构的表现，包括详细的错误分析，发现使用文字和语音双模态数据训练的模型明显优于仅基于文字或语音的单一模态模型。该架构在情感分类任务中超过了现有的state-of-the-art系统，为多模态AI情感识别提供了有效改进。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "15 pages, 5 figures, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2407.00134v1",
      "published_date": "2024-06-28 10:43:02 UTC",
      "updated_date": "2024-06-28 10:43:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:45:17.803912"
    },
    {
      "arxiv_id": "2406.19812v1",
      "title": "Fuzzy Logic Guided Reward Function Variation: An Oracle for Testing Reinforcement Learning Programs",
      "title_zh": "模糊逻辑指导的奖励函数变化：用于测试强化学习程序的预言机",
      "authors": [
        "Shiyu Zhang",
        "Haoyang Song",
        "Qixin Wang",
        "Yu Pei"
      ],
      "abstract": "Reinforcement Learning (RL) has gained significant attention across various\ndomains. However, the increasing complexity of RL programs presents testing\nchallenges, particularly the oracle problem: defining the correctness of the RL\nprogram. Conventional human oracles struggle to cope with the complexity,\nleading to inefficiencies and potential unreliability in RL testing. To\nalleviate this problem, we propose an automated oracle approach that leverages\nRL properties using fuzzy logic. Our oracle quantifies an agent's behavioral\ncompliance with reward policies and analyzes its trend over training episodes.\nIt labels an RL program as \"Buggy\" if the compliance trend violates\nexpectations derived from RL characteristics. We evaluate our oracle on RL\nprograms with varying complexities and compare it with human oracles. Results\nshow that while human oracles perform well in simpler testing scenarios, our\nfuzzy oracle demonstrates superior performance in complex environments. The\nproposed approach shows promise in addressing the oracle problem for RL\ntesting, particularly in complex cases where manual testing falls short. It\noffers a potential solution to improve the efficiency, reliability, and\nscalability of RL program testing. This research takes a step towards automated\ntesting of RL programs and highlights the potential of fuzzy logic-based\noracles in tackling the oracle problem.",
      "tldr_zh": "本研究针对强化学习（RL）程序测试中的 oracle 问题（定义程序正确性），提出了一种基于模糊逻辑（fuzzy logic）的自动 oracle 方法。该方法通过量化代理的行为 compliance 与奖励策略的符合度，并分析其在训练过程中的趋势，来判断 RL 程序是否为“Buggy”。实验结果显示，该模糊 oracle 在复杂环境中优于人类 oracle，提高了 RL 测试的效率、可靠性和可扩展性，为自动化 RL 程序测试提供了新途径。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "68T05, 68T27, 93C42",
        "D.2.5; I.2.3"
      ],
      "primary_category": "cs.SE",
      "comment": "10 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.19812v1",
      "published_date": "2024-06-28 10:41:17 UTC",
      "updated_date": "2024-06-28 10:41:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:45:28.411997"
    },
    {
      "arxiv_id": "2406.19807v1",
      "title": "Deceptive Diffusion: Generating Synthetic Adversarial Examples",
      "title_zh": "Deceptive Diffusion：生成合成对抗样本",
      "authors": [
        "Lucas Beerens",
        "Catherine F. Higham",
        "Desmond J. Higham"
      ],
      "abstract": "We introduce the concept of deceptive diffusion -- training a generative AI\nmodel to produce adversarial images. Whereas a traditional adversarial attack\nalgorithm aims to perturb an existing image to induce a misclassificaton, the\ndeceptive diffusion model can create an arbitrary number of new, misclassified\nimages that are not directly associated with training or test images. Deceptive\ndiffusion offers the possibility of strengthening defence algorithms by\nproviding adversarial training data at scale, including types of\nmisclassification that are otherwise difficult to find. In our experiments, we\nalso investigate the effect of training on a partially attacked data set. This\nhighlights a new type of vulnerability for generative diffusion models: if an\nattacker is able to stealthily poison a portion of the training data, then the\nresulting diffusion model will generate a similar proportion of misleading\noutputs.",
      "tldr_zh": "本研究引入了“deceptive diffusion”方法，通过训练生成式 AI 模型来生成合成对抗样本（adversarial examples），这些样本是全新的图像，能够诱导模型误分类，且不直接依赖于训练或测试数据。相比传统对抗攻击，该方法能大规模创建各种类型的误分类图像，从而为防御算法提供丰富的对抗训练数据，帮助提升模型鲁棒性。实验结果显示，在部分被攻击的数据集上训练时，扩散模型（diffusion models）会产生类似比例的误导输出，揭示了生成模型的一种新漏洞，即训练数据被隐蔽毒害的风险。总的来说，这为对抗机器学习领域提供了创新工具，同时强调了数据安全的重要性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "68T07",
        "I.2.0; I.5.1"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.19807v1",
      "published_date": "2024-06-28 10:30:46 UTC",
      "updated_date": "2024-06-28 10:30:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:45:41.786009"
    },
    {
      "arxiv_id": "2406.19770v1",
      "title": "Self-Supervised Spatial-Temporal Normality Learning for Time Series Anomaly Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Yutong Chen",
        "Hongzuo Xu",
        "Guansong Pang",
        "Hezhe Qiao",
        "Yuan Zhou",
        "Mingsheng Shang"
      ],
      "abstract": "Time Series Anomaly Detection (TSAD) finds widespread applications across\nvarious domains such as financial markets, industrial production, and\nhealthcare. Its primary objective is to learn the normal patterns of time\nseries data, thereby identifying deviations in test samples. Most existing TSAD\nmethods focus on modeling data from the temporal dimension, while ignoring the\nsemantic information in the spatial dimension. To address this issue, we\nintroduce a novel approach, called Spatial-Temporal Normality learning (STEN).\nSTEN is composed of a sequence Order prediction-based Temporal Normality\nlearning (OTN) module that captures the temporal correlations within sequences,\nand a Distance prediction-based Spatial Normality learning (DSN) module that\nlearns the relative spatial relations between sequences in a feature space. By\nsynthesizing these two modules, STEN learns expressive spatial-temporal\nrepresentations for the normal patterns hidden in the time series data.\nExtensive experiments on five popular TSAD benchmarks show that STEN\nsubstantially outperforms state-of-the-art competing methods. Our code is\navailable at https://github.com/mala-lab/STEN.",
      "tldr_zh": "本论文针对时间序列异常检测（TSAD），提出了一种自监督的Spatial-Temporal Normality learning (STEN)方法，以解决现有方法忽略空间维度语义信息的局限性。STEN由两个模块组成：Order prediction-based Temporal Normality learning (OTN)模块，用于捕捉序列内的时间相关性，以及Distance prediction-based Spatial Normality learning (DSN)模块，用于学习序列在特征空间中的相对空间关系。通过整合这些模块，STEN能够学习时间序列数据中隐藏的正常模式表达性表示。在五个TSAD基准上的实验表明，STEN大幅超过了最先进的方法，代码已在GitHub上开源。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "18 pages, 4 figures, accepted in ECML PKDD2024",
      "pdf_url": "http://arxiv.org/pdf/2406.19770v1",
      "published_date": "2024-06-28 09:17:58 UTC",
      "updated_date": "2024-06-28 09:17:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:45:53.821962"
    },
    {
      "arxiv_id": "2406.19763v1",
      "title": "xSemAD: Explainable Semantic Anomaly Detection in Event Logs Using Sequence-to-Sequence Models",
      "title_zh": "翻译失败",
      "authors": [
        "Kiran Busch",
        "Timotheus Kampik",
        "Henrik Leopold"
      ],
      "abstract": "The identification of undesirable behavior in event logs is an important\naspect of process mining that is often addressed by anomaly detection methods.\nTraditional anomaly detection methods tend to focus on statistically rare\nbehavior and neglect the subtle difference between rarity and undesirability.\nThe introduction of semantic anomaly detection has opened a promising avenue by\nidentifying semantically deviant behavior. This work addresses a gap in\nsemantic anomaly detection, which typically indicates the occurrence of an\nanomaly without explaining the nature of the anomaly. We propose xSemAD, an\napproach that uses a sequence-to-sequence model to go beyond pure\nidentification and provides extended explanations. In essence, our approach\nlearns constraints from a given process model repository and then checks\nwhether these constraints hold in the considered event log. This approach not\nonly helps understand the specifics of the undesired behavior, but also\nfacilitates targeted corrective actions. Our experiments demonstrate that our\napproach outperforms existing state-of-the-art semantic anomaly detection\nmethods.",
      "tldr_zh": "该论文针对事件日志中的语义异常检测问题，指出传统方法仅关注统计上罕见的异常，而忽略了罕见与不期望行为的细微差异。xSemAD 方法使用 sequence-to-sequence 模型从过程模型库中学习约束，并检查这些约束在事件日志中是否成立，从而不仅识别语义异常，还提供详细解释以帮助理解不期望行为。实验结果表明，xSemAD 优于现有语义 anomaly detection 方法，支持针对性纠正措施。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at BPM 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.19763v1",
      "published_date": "2024-06-28 09:06:52 UTC",
      "updated_date": "2024-06-28 09:06:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:46:05.984667"
    },
    {
      "arxiv_id": "2406.19756v2",
      "title": "Structure-aware World Model for Probe Guidance via Large-scale Self-supervised Pre-train",
      "title_zh": "翻译失败",
      "authors": [
        "Haojun Jiang",
        "Meng Li",
        "Zhenguo Sun",
        "Ning Jia",
        "Yu Sun",
        "Shaqi Luo",
        "Shiji Song",
        "Gao Huang"
      ],
      "abstract": "The complex structure of the heart leads to significant challenges in\nechocardiography, especially in acquisition cardiac ultrasound images.\nSuccessful echocardiography requires a thorough understanding of the structures\non the two-dimensional plane and the spatial relationships between planes in\nthree-dimensional space. In this paper, we innovatively propose a large-scale\nself-supervised pre-training method to acquire a cardiac structure-aware world\nmodel. The core innovation lies in constructing a self-supervised task that\nrequires structural inference by predicting masked structures on a 2D plane and\nimagining another plane based on pose transformation in 3D space. To support\nlarge-scale pre-training, we collected over 1.36 million echocardiograms from\nten standard views, along with their 3D spatial poses. In the downstream probe\nguidance task, we demonstrate that our pre-trained model consistently reduces\nguidance errors across the ten most common standard views on the test set with\n0.29 million samples from 74 routine clinical scans, indicating that\nstructure-aware pre-training benefits the scanning.",
      "tldr_zh": "这篇论文提出了一种大规模自监督预-training方法，用于构建一个structure-aware world model，以解决超声心动图（echocardiography）中心脏复杂结构带来的图像获取挑战。核心创新在于设计自监督任务，通过预测2D平面上的masked结构并基于pose transformation在3D空间想象另一个平面，实现结构推理。为支持预训练，他们收集了超过136万张来自十个标准视图的echocardiograms及其3D空间姿态。在下游探头引导任务中，该模型在测试集（74个临床扫描的29万样本）上显著降低了引导错误，证明structure-aware预训练有助于提升扫描性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by MICCAI 2024 ASMUS Workshop",
      "pdf_url": "http://arxiv.org/pdf/2406.19756v2",
      "published_date": "2024-06-28 08:54:44 UTC",
      "updated_date": "2024-07-19 07:15:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:46:30.080752"
    },
    {
      "arxiv_id": "2406.19755v1",
      "title": "Protein Representation Learning with Sequence Information Embedding: Does it Always Lead to a Better Performance?",
      "title_zh": "结合序列信息嵌入的蛋白质表示学习：它总是导致更好的性能吗？",
      "authors": [
        "Yang Tan",
        "Lirong Zheng",
        "Bozitao Zhong",
        "Liang Hong",
        "Bingxin Zhou"
      ],
      "abstract": "Deep learning has become a crucial tool in studying proteins. While the\nsignificance of modeling protein structure has been discussed extensively in\nthe literature, amino acid types are typically included in the input as a\ndefault operation for many inference tasks. This study demonstrates with\nstructure alignment task that embedding amino acid types in some cases may not\nhelp a deep learning model learn better representation. To this end, we propose\nProtLOCA, a local geometry alignment method based solely on amino acid\nstructure representation. The effectiveness of ProtLOCA is examined by a global\nstructure-matching task on protein pairs with an independent test dataset based\non CATH labels. Our method outperforms existing sequence- and structure-based\nrepresentation learning methods by more quickly and accurately matching\nstructurally consistent protein domains. Furthermore, in local structure\npairing tasks, ProtLOCA for the first time provides a valid solution to\nhighlight common local structures among proteins with different overall\nstructures but the same function. This suggests a new possibility for using\ndeep learning methods to analyze protein structure to infer function.",
      "tldr_zh": "本文研究了在蛋白质表示学习中嵌入序列信息（如氨基酸类型）是否总是提升性能，发现某些情况下（如结构对齐任务）反而可能无益。作者提出ProtLOCA，一种基于氨基酸结构表示的局部几何对齐方法，不依赖序列信息。实验结果显示，ProtLOCA在基于CATH labels的全球结构匹配任务中，优于现有序列和结构基于的方法，能更快更准确地匹配结构一致的蛋白质域。此外，在局部结构配对任务中，ProtLOCA首次提供解决方案，突出整体结构不同但功能相同的蛋白质中的共同局部结构，为使用deep learning分析蛋白质结构推断功能开辟新途径。",
      "categories": [
        "q-bio.QM",
        "cs.AI"
      ],
      "primary_category": "q-bio.QM",
      "comment": "8 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.19755v1",
      "published_date": "2024-06-28 08:54:37 UTC",
      "updated_date": "2024-06-28 08:54:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:46:31.344141"
    },
    {
      "arxiv_id": "2407.00132v3",
      "title": "ShortcutsBench: A Large-Scale Real-world Benchmark for API-based Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Haiyang Shen",
        "Yue Li",
        "Desong Meng",
        "Dongqi Cai",
        "Sheng Qi",
        "Li Zhang",
        "Mengwei Xu",
        "Yun Ma"
      ],
      "abstract": "Recent advancements in integrating large language models (LLMs) with\napplication programming interfaces (APIs) have gained significant interest in\nboth academia and industry. Recent work demonstrates that these API-based\nagents exhibit relatively strong autonomy and planning capabilities. However,\ntheir ability to handle multi-dimensional difficulty levels, diverse task\ntypes, and real-world demands remains unknown. In this paper, we introduce\n\\textsc{ShortcutsBench}, a large-scale benchmark for the comprehensive\nevaluation of API-based agents in solving real-world complex tasks.\n\\textsc{ShortcutsBench} includes a wealth of real APIs from Apple Inc., refined\nuser queries, human-annotated high-quality action sequences, detailed parameter\nfilling values, and parameters requesting necessary input from the system or\nuser. We revealed how existing benchmarks~/~datasets struggle to accommodate\nthe advanced reasoning capabilities of existing more intelligent LLMs.\nMoreover, our extensive evaluation of agents built with $5$ leading open-source\n(size $\\geq$ 57B) and $5$ closed-source LLMs (e.g. Gemini-1.5-Pro and\nGPT-4o-mini) with varying intelligence level reveals significant limitations of\nexisting API-based agents in the whole process of handling complex queries\nrelated to API selection, parameter filling, and requesting necessary input\nfrom the system and the user. These findings highlight the great challenges\nthat API-based agents face in effectively fulfilling real and complex user\nqueries. All datasets, code, experimental logs, and results are available at\n\\url{https://github.com/EachSheep/ShortcutsBench}.",
      "tldr_zh": "这篇论文引入了ShortcutsBench，这是一个大规模的真实世界基准，用于全面评估基于API的智能体（API-based agents）在处理多维度难度任务和真实查询时的性能。ShortcutsBench 包含来自 Apple Inc. 的真实 API、精炼的用户查询、人为标注的高质量动作序列、详细的参数填充值，以及请求系统或用户输入的参数，以揭示现有基准无法适应大型语言模型（LLMs）的先进推理能力。研究对 5 个领先的开源 LLMs（大小 ≥ 57B）和 5 个闭源 LLMs（如 Gemini-1.5-Pro 和 GPT-4o-mini）构建的智能体进行了广泛评估，结果显示这些智能体在 API 选择、参数填充和请求必要输入方面存在显著局限性。这些发现突出了 API-based agents 在有效处理复杂用户查询时的挑战，并提供了数据集、代码和实验资源。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "ICLR'25: https://openreview.net/forum?id=kKILfPkhSz",
      "pdf_url": "http://arxiv.org/pdf/2407.00132v3",
      "published_date": "2024-06-28 08:45:02 UTC",
      "updated_date": "2025-01-23 11:22:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:46:45.481831"
    },
    {
      "arxiv_id": "2406.19741v3",
      "title": "ROS-LLM: A ROS framework for embodied AI with task feedback and structured reasoning",
      "title_zh": "ROS-LLM：一种用于具身 AI 的 ROS",
      "authors": [
        "Christopher E. Mower",
        "Yuhui Wan",
        "Hongzhan Yu",
        "Antoine Grosnit",
        "Jonas Gonzalez-Billandon",
        "Matthieu Zimmer",
        "Jinlong Wang",
        "Xinyu Zhang",
        "Yao Zhao",
        "Anbang Zhai",
        "Puze Liu",
        "Daniel Palenicek",
        "Davide Tateo",
        "Cesar Cadena",
        "Marco Hutter",
        "Jan Peters",
        "Guangjian Tian",
        "Yuzheng Zhuang",
        "Kun Shao",
        "Xingyue Quan",
        "Jianye Hao",
        "Jun Wang",
        "Haitham Bou-Ammar"
      ],
      "abstract": "We present a framework for intuitive robot programming by non-experts,\nleveraging natural language prompts and contextual information from the Robot\nOperating System (ROS). Our system integrates large language models (LLMs),\nenabling non-experts to articulate task requirements to the system through a\nchat interface. Key features of the framework include: integration of ROS with\nan AI agent connected to a plethora of open-source and commercial LLMs,\nautomatic extraction of a behavior from the LLM output and execution of ROS\nactions/services, support for three behavior modes (sequence, behavior tree,\nstate machine), imitation learning for adding new robot actions to the library\nof possible actions, and LLM reflection via human and environment feedback.\nExtensive experiments validate the framework, showcasing robustness,\nscalability, and versatility in diverse scenarios, including long-horizon\ntasks, tabletop rearrangements, and remote supervisory control. To facilitate\nthe adoption of our framework and support the reproduction of our results, we\nhave made our code open-source. You can access it at:\nhttps://github.com/huawei-noah/HEBO/tree/master/ROSLLM.",
      "tldr_zh": "本研究提出了 ROS-LLM 框架，这是一个整合 Robot Operating System (ROS) 和 large language models (LLMs) 的系统，旨在让非专家通过自然语言提示和聊天界面进行直观的机器人编程。\n框架的关键功能包括自动从 LLM 输出提取行为并执行 ROS 动作/服务，支持三种行为模式（sequence、behavior tree 和 state machine）、模仿学习添加新动作，以及通过人类和环境反馈实现 LLM 反思。\n实验结果显示，该框架在长时任务、桌面重排和远程监督控制等多样场景中表现出鲁棒性、可扩展性和多功能性，并已开源代码以便于采用和结果复现。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "This document contains 26 pages and 13 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.19741v3",
      "published_date": "2024-06-28 08:28:38 UTC",
      "updated_date": "2024-07-12 11:44:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:46:55.340783"
    },
    {
      "arxiv_id": "2406.19738v1",
      "title": "Classical Bandit Algorithms for Entanglement Detection in Parameterized Qubit States",
      "title_zh": "翻译失败",
      "authors": [
        "Bharati. K",
        "Vikesh Siddhu",
        "Krishna Jagannathan"
      ],
      "abstract": "Entanglement is a key resource for a wide range of tasks in quantum\ninformation and computing. Thus, verifying availability of this quantum\nresource is essential. Extensive research on entanglement detection has led to\nno-go theorems (Lu et al. [Phys. Rev. Lett., 116, 230501 (2016)]) that\nhighlight the need for full state tomography (FST) in the absence of adaptive\nor joint measurements. Recent advancements, as proposed by Zhu, Teo, and\nEnglert [Phys. Rev. A, 81, 052339, 2010], introduce a single-parameter family\nof entanglement witness measurements which are capable of conclusively\ndetecting certain entangled states and only resort to FST when all witness\nmeasurements are inconclusive. We find a variety of realistic noisy two-qubit\nquantum states $\\mathcal{F}$ that yield conclusive results under this witness\nfamily. We solve the problem of detecting entanglement among $K$ quantum states\nin $\\mathcal{F}$, of which $m$ states are entangled, with $m$ potentially\nunknown. We recognize a structural connection of this problem to the Bad Arm\nIdentification problem in stochastic Multi-Armed Bandits (MAB). In contrast to\nexisting quantum bandit frameworks, we establish a new correspondence tailored\nfor entanglement detection and term it the $(m,K)$-quantum Multi-Armed Bandit.\nWe implement two well-known MAB policies for arbitrary states derived from\n$\\mathcal{F}$, present theoretical guarantees on the measurement/sample\ncomplexity and demonstrate the practicality of the policies through numerical\nsimulations. More broadly, this paper highlights the potential for employing\nclassical machine learning techniques for quantum entanglement detection.",
      "tldr_zh": "该论文将经典的多臂老虎机 (Multi-Armed Bandits, MAB) 算法应用于参数化量子比特状态中的纠缠检测问题，针对一组 K 个量子状态（其中 m 个是纠缠的，m 未知）设计了 Bad Arm Identification 策略。研究者建立了新的 (m,K)-quantum Multi-Armed Bandit 框架，通过实现两种 MAB 策略，提供测量复杂性的理论保证，并通过数值模拟验证了其在现实噪声双量子比特状态下的实用性。总体上，该工作展示了经典机器学习技术在量子纠缠检测中的潜力，减少了对全状态层析 (Full State Tomography, FST) 的依赖。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "quant-ph",
      "comment": "20 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.19738v1",
      "published_date": "2024-06-28 08:26:47 UTC",
      "updated_date": "2024-06-28 08:26:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:47:07.072654"
    },
    {
      "arxiv_id": "2407.00131v1",
      "title": "RepAct: The Re-parameterizable Adaptive Activation Function",
      "title_zh": "翻译失败",
      "authors": [
        "Xian Wu",
        "Qingchuan Tao",
        "Shuang Wang"
      ],
      "abstract": "Addressing the imperative need for efficient artificial intelligence in IoT\nand edge computing, this study presents RepAct, a re-parameterizable adaptive\nactivation function tailored for optimizing lightweight neural networks within\nthe computational limitations of edge devices. By employing a multi-branch\nstructure with learnable adaptive weights, RepAct enriches feature processing\nand enhances cross-layer interpretability. When evaluated on tasks such as\nimage classification and object detection, RepAct notably surpassed\nconventional activation functions in lightweight networks, delivering up to a\n7.92% accuracy boost on MobileNetV3-Small for the ImageNet100 dataset, while\nmaintaining computational complexity on par with HardSwish. This innovative\napproach not only maximizes model parameter efficiency but also significantly\nimproves the performance and understanding capabilities of lightweight neural\nnetworks, demonstrating its potential for real-time edge computing\napplications.",
      "tldr_zh": "本研究针对 IoT 和 edge computing 中对高效 AI 的需求，提出了 RepAct，一种可重参数化的自适应激活函数，用于优化轻量级神经网络。该函数采用多分支结构和可学习的自适应权重，丰富特征处理并提升跨层可解释性。在图像分类和物体检测任务中，RepAct 显著优于传统激活函数，例如在 MobileNetV3-Small 上使 ImageNet100 数据集准确率提升高达 7.92%，同时保持与 HardSwish 相当的计算复杂度。这种创新方法提高了模型参数效率，并增强了轻量级神经网络的性能，适用于实时 edge computing 应用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.00131v1",
      "published_date": "2024-06-28 08:25:45 UTC",
      "updated_date": "2024-06-28 08:25:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:47:29.795234"
    },
    {
      "arxiv_id": "2406.19736v1",
      "title": "MM-Instruct: Generated Visual Instructions for Large Multimodal Model Alignment",
      "title_zh": "MM-Instruct：用于大型多模态模型对齐的生成视觉指令",
      "authors": [
        "Jihao Liu",
        "Xin Huang",
        "Jinliang Zheng",
        "Boxiao Liu",
        "Jia Wang",
        "Osamu Yoshie",
        "Yu Liu",
        "Hongsheng Li"
      ],
      "abstract": "This paper introduces MM-Instruct, a large-scale dataset of diverse and\nhigh-quality visual instruction data designed to enhance the\ninstruction-following capabilities of large multimodal models (LMMs). While\nexisting visual instruction datasets often focus on question-answering, they\nstruggle to generalize to broader application scenarios such as creative\nwriting, summarization, or image analysis. To address these limitations, we\npropose a novel approach to constructing MM-Instruct that leverages the strong\ninstruction-following capabilities of existing LLMs to generate novel visual\ninstruction data from large-scale but conventional image captioning datasets.\nMM-Instruct first leverages ChatGPT to automatically generate diverse\ninstructions from a small set of seed instructions through augmenting and\nsummarization. It then matches these instructions with images and uses an\nopen-sourced large language model (LLM) to generate coherent answers to the\ninstruction-image pairs. The LLM is grounded by the detailed text descriptions\nof images in the whole answer generation process to guarantee the alignment of\nthe instruction data. Moreover, we introduce a benchmark based on the generated\ninstruction data to evaluate the instruction-following capabilities of existing\nLMMs. We demonstrate the effectiveness of MM-Instruct by training a LLaVA-1.5\nmodel on the generated data, denoted as LLaVA-Instruct, which exhibits\nsignificant improvements in instruction-following capabilities compared to\nLLaVA-1.5 models. The MM-Instruct dataset, benchmark, and pre-trained models\nare available at https://github.com/jihaonew/MM-Instruct.",
      "tldr_zh": "这篇论文提出了 MM-Instruct，这是一个大规模、高质量的视觉指令数据集，旨在提升大型多模态模型 (LMMs) 的指令跟随能力，以解决现有数据集在问答之外的泛化问题，如创意写作和图像分析。方法包括利用 ChatGPT 从种子指令生成多样化指令，然后匹配图像并用开源 LLM 生成与图像描述对齐的答案。实验结果显示，在 MM-Instruct 上训练的 LLaVA-1.5 模型（即 LLaVA-Instruct）显著提高了指令跟随能力，并提供了一个评估基准及相关资源（https://github.com/jihaonew/MM-Instruct）。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Dataset and models are available at\n  https://github.com/jihaonew/MM-Instruct",
      "pdf_url": "http://arxiv.org/pdf/2406.19736v1",
      "published_date": "2024-06-28 08:25:27 UTC",
      "updated_date": "2024-06-28 08:25:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:47:30.854143"
    },
    {
      "arxiv_id": "2407.09553v5",
      "title": "DPEC: Dual-Path Error Compensation Method for Enhanced Low-Light Image Clarity",
      "title_zh": "翻译失败",
      "authors": [
        "Shuang Wang",
        "Qianwen Lu",
        "Boxing Peng",
        "Yihe Nie",
        "Qingchuan Tao"
      ],
      "abstract": "For the task of low-light image enhancement, deep learning-based algorithms\nhave demonstrated superiority and effectiveness compared to traditional\nmethods. However, these methods, primarily based on Retinex theory, tend to\noverlook the noise and color distortions in input images, leading to\nsignificant noise amplification and local color distortions in enhanced\nresults. To address these issues, we propose the Dual-Path Error Compensation\n(DPEC) method, designed to improve image quality under low-light conditions by\npreserving local texture details while restoring global image brightness\nwithout amplifying noise. DPEC incorporates precise pixel-level error\nestimation to capture subtle differences and an independent denoising mechanism\nto prevent noise amplification. We introduce the HIS-Retinex loss to guide\nDPEC's training, ensuring the brightness distribution of enhanced images\nclosely aligns with real-world conditions. To balance computational speed and\nresource efficiency while training DPEC for a comprehensive understanding of\nthe global context, we integrated the VMamba architecture into its backbone.\nComprehensive quantitative and qualitative experimental results demonstrate\nthat our algorithm significantly outperforms state-of-the-art methods in\nlow-light image enhancement. The code is publicly available online at\nhttps://github.com/wangshuang233/DPEC.",
      "tldr_zh": "该论文针对低光照图像增强中的噪声放大和颜色失真问题，提出了一种Dual-Path Error Compensation (DPEC)方法，以Retinex theory为基础，同时保留局部纹理细节并恢复全局亮度。DPEC通过精确的pixel-level error estimation和independent denoising mechanism来捕获细微差异并防止噪声放大，并引入HIS-Retinex loss指导训练，确保增强图像的亮度分布更接近真实世界条件。论文还整合了VMamba architecture到骨干网络中，以平衡计算速度和资源效率。实验结果显示，DPEC在定量和定性评估中显著优于现有最先进方法，代码已公开可用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.09553v5",
      "published_date": "2024-06-28 08:21:49 UTC",
      "updated_date": "2025-03-15 12:10:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:47:42.719606"
    },
    {
      "arxiv_id": "2406.19720v1",
      "title": "CUPID: Improving Battle Fairness and Position Satisfaction in Online MOBA Games with a Re-matchmaking System",
      "title_zh": "翻译失败",
      "authors": [
        "Ge Fan",
        "Chaoyun Zhang",
        "Kai Wang",
        "Yingjie Li",
        "Junyang Chen",
        "Zenglin Xu"
      ],
      "abstract": "The multiplayer online battle arena (MOBA) genre has gained significant\npopularity and economic success, attracting considerable research interest\nwithin the Human-Computer Interaction community. Enhancing the gaming\nexperience requires a deep understanding of player behavior, and a crucial\naspect of MOBA games is matchmaking, which aims to assemble teams of comparable\nskill levels. However, existing matchmaking systems often neglect important\nfactors such as players' position preferences and team assignment, resulting in\nimbalanced matches and reduced player satisfaction. To address these\nlimitations, this paper proposes a novel framework called CUPID, which\nintroduces a novel process called ``re-matchmaking'' to optimize team and\nposition assignments to improve both fairness and player satisfaction. CUPID\nincorporates a pre-filtering step to ensure a minimum level of matchmaking\nquality, followed by a pre-match win-rate prediction model that evaluates the\nfairness of potential assignments. By simultaneously considering players'\nposition satisfaction and game fairness, CUPID aims to provide an enhanced\nmatchmaking experience. Extensive experiments were conducted on two\nlarge-scale, real-world MOBA datasets to validate the effectiveness of CUPID.\nThe results surpass all existing state-of-the-art baselines, with an average\nrelative improvement of 7.18% in terms of win prediction accuracy. Furthermore,\nCUPID has been successfully deployed in a popular online mobile MOBA game. The\ndeployment resulted in significant improvements in match fairness and player\nsatisfaction, as evidenced by critical Human-Computer Interaction (HCI) metrics\ncovering usability, accessibility, and engagement, observed through A/B\ntesting. To the best of our knowledge, CUPID is the first re-matchmaking system\ndesigned specifically for large-scale MOBA games.",
      "tldr_zh": "本研究针对 MOBA 游戏中现有匹配系统忽略玩家位置偏好和团队分配导致的不公平问题，提出了一种名为 CUPID 的新框架，利用 re-matchmaking 过程优化团队和位置分配。CUPID 包括预过滤步骤和预匹配胜率预测模型，以同时提升游戏公平性和玩家满意度。在两个真实世界数据集上进行的实验显示，CUPID 比现有基准模型的胜率预测准确率平均提高了 7.18%。该系统已在热门移动 MOBA 游戏中成功部署，通过 A/B 测试证明了其在公平性、可用性和参与度等方面的显著改进，是首个针对大规模 MOBA 游戏的 re-matchmaking 系统。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "38 pages, accepted by CSCW 24",
      "pdf_url": "http://arxiv.org/pdf/2406.19720v1",
      "published_date": "2024-06-28 08:09:55 UTC",
      "updated_date": "2024-06-28 08:09:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:47:54.026356"
    },
    {
      "arxiv_id": "2406.19712v1",
      "title": "Uncertainty Quantification in Large Language Models Through Convex Hull Analysis",
      "title_zh": "通过凸包分析进行大语言模型的不确定性量化",
      "authors": [
        "Ferhat Ozgur Catak",
        "Murat Kuzlu"
      ],
      "abstract": "Uncertainty quantification approaches have been more critical in large\nlanguage models (LLMs), particularly high-risk applications requiring reliable\noutputs. However, traditional methods for uncertainty quantification, such as\nprobabilistic models and ensemble techniques, face challenges when applied to\nthe complex and high-dimensional nature of LLM-generated outputs. This study\nproposes a novel geometric approach to uncertainty quantification using convex\nhull analysis. The proposed method leverages the spatial properties of response\nembeddings to measure the dispersion and variability of model outputs. The\nprompts are categorized into three types, i.e., `easy', `moderate', and\n`confusing', to generate multiple responses using different LLMs at varying\ntemperature settings. The responses are transformed into high-dimensional\nembeddings via a BERT model and subsequently projected into a two-dimensional\nspace using Principal Component Analysis (PCA). The Density-Based Spatial\nClustering of Applications with Noise (DBSCAN) algorithm is utilized to cluster\nthe embeddings and compute the convex hull for each selected cluster. The\nexperimental results indicate that the uncertainty of the model for LLMs\ndepends on the prompt complexity, the model, and the temperature setting.",
      "tldr_zh": "本研究针对大型语言模型（LLMs）的不确定性量化问题，提出了一种基于凸包分析的几何方法，以应对传统方法（如概率模型和集成技术）在处理复杂高维输出时的挑战。该方法通过将提示分类为'easy'、'moderate' 和 'confusing' 类型，使用不同 LLMs 和温度设置生成响应，将这些响应转化为高维嵌入（via BERT 模型），并通过 Principal Component Analysis (PCA) 投影到二维空间，然后应用 Density-Based Spatial Clustering of Applications with Noise (DBSCAN) 算法聚类并计算凸包，以测量输出的分散性和变异性。实验结果显示，LLMs 的不确定性取决于提示复杂度、所用模型和温度设置，这为更可靠的 LLM 应用提供了新见解。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "17 pages",
      "pdf_url": "http://arxiv.org/pdf/2406.19712v1",
      "published_date": "2024-06-28 07:47:34 UTC",
      "updated_date": "2024-06-28 07:47:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:48:06.561231"
    },
    {
      "arxiv_id": "2406.19708v3",
      "title": "A Differentiable Approach to Multi-scale Brain Modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Chaoming Wang",
        "Muyang Lyu",
        "Tianqiu Zhang",
        "Sichao He",
        "Si Wu"
      ],
      "abstract": "We present a multi-scale differentiable brain modeling workflow utilizing\nBrainPy, a unique differentiable brain simulator that combines accurate brain\nsimulation with powerful gradient-based optimization. We leverage this\ncapability of BrainPy across different brain scales. At the single-neuron\nlevel, we implement differentiable neuron models and employ gradient methods to\noptimize their fit to electrophysiological data. On the network level, we\nincorporate connectomic data to construct biologically constrained network\nmodels. Finally, to replicate animal behavior, we train these models on\ncognitive tasks using gradient-based learning rules. Experiments demonstrate\nthat our approach achieves superior performance and speed in fitting\ngeneralized leaky integrate-and-fire and Hodgkin-Huxley single neuron models.\nAdditionally, training a biologically-informed network of excitatory and\ninhibitory spiking neurons on working memory tasks successfully replicates\nobserved neural activity and synaptic weight distributions. Overall, our\ndifferentiable multi-scale simulation approach offers a promising tool to\nbridge neuroscience data across electrophysiological, anatomical, and\nbehavioral scales.",
      "tldr_zh": "本研究提出了一种多尺度可微脑建模工作流，利用 BrainPy 工具结合准确脑模拟和梯度优化方法，应用于单神经元、网络和行为级别。具体而言，该方法通过可微神经元模型优化电生理数据拟合、整合连接组数据构建生物约束网络模型，并使用梯度学习规则训练模型以复制动物认知任务。实验结果显示，该方法在拟合广义泄漏积分放电和 Hodgkin-Huxley 单神经元模型时表现出优越性能和更快速度，并成功复制了工作记忆任务中的神经活动和突触权重分布。总体上，这种可微模拟方法为桥接电生理、解剖和行为尺度的神经科学数据提供了有前景的工具。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.CE",
        "q-bio.NC"
      ],
      "primary_category": "cs.NE",
      "comment": "2nd Differentiable Almost Everything Workshop at ICML 2024.\n  https://github.com/chaoming0625/differentiable-brain-modeling-workflow",
      "pdf_url": "http://arxiv.org/pdf/2406.19708v3",
      "published_date": "2024-06-28 07:41:31 UTC",
      "updated_date": "2024-09-25 11:56:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:48:20.253765"
    },
    {
      "arxiv_id": "2406.19705v5",
      "title": "DISCO: Efficient Diffusion Solver for Large-Scale Combinatorial Optimization Problems",
      "title_zh": "翻译失败",
      "authors": [
        "Kexiong Yu",
        "Hang Zhao",
        "Yuhang Huang",
        "Renjiao Yi",
        "Kai Xu",
        "Chenyang Zhu"
      ],
      "abstract": "Combinatorial Optimization (CO) problems are fundamentally important in\nnumerous real-world applications across diverse industries, characterized by\nentailing enormous solution space and demanding time-sensitive response.\nDespite recent advancements in neural solvers, their limited expressiveness\nstruggles to capture the multi-modal nature of CO landscapes. While some\nresearch has shifted towards diffusion models, these models still sample\nsolutions indiscriminately from the entire NP-complete solution space with\ntime-consuming denoising processes, which limit their practicality for large\nproblem scales. We propose DISCO, an efficient DIffusion Solver for large-scale\nCombinatorial Optimization problems that excels in both solution quality and\ninference speed. DISCO's efficacy is twofold: First, it enhances solution\nquality by constraining the sampling space to a more meaningful domain guided\nby solution residues, while preserving the multi-modal properties of the output\ndistributions. Second, it accelerates the denoising process through an\nanalytically solvable approach, enabling solution sampling with minimal\nreverse-time steps and significantly reducing inference time. DISCO delivers\nstrong performance on large-scale Traveling Salesman Problems and challenging\nMaximal Independent Set benchmarks, with inference time up to 5.28 times faster\nthan other diffusion alternatives. By incorporating a divide-and-conquer\nstrategy, DISCO can well generalize to solve unseen-scale problem instances,\neven surpassing models specifically trained for those scales.",
      "tldr_zh": "该论文提出 DISCO，一种高效的 Diffusion Solver，用于解决大规模 Combinatorial Optimization (CO) 问题，通过限制采样空间和加速去噪过程，同时保留输出分布的多模态特性，提升了解决方案质量和推理速度。DISCO 采用解决方案残差引导采样空间，并通过可分析求解的方法减少逆向步骤，使其在 Traveling Salesman Problems 和 Maximal Independent Set 基准上比其他扩散模型快 5.28 倍。实验结果显示，DISCO 不仅在已知规模问题上表现出色，还通过 divide-and-conquer 策略实现了对未见规模问题的良好泛化，甚至超越专门训练的模型。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.19705v5",
      "published_date": "2024-06-28 07:36:31 UTC",
      "updated_date": "2024-10-21 13:38:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:48:34.187938"
    },
    {
      "arxiv_id": "2407.12024v1",
      "title": "Leveraging Large Language Models for enhanced personalised user experience in Smart Homes",
      "title_zh": "利用大型语言模型增强智能家居中的个性化用户体验",
      "authors": [
        "Jordan Rey-Jouanchicot",
        "André Bottaro",
        "Eric Campo",
        "Jean-Léon Bouraoui",
        "Nadine Vigouroux",
        "Frédéric Vella"
      ],
      "abstract": "Smart home automation systems aim to improve the comfort and convenience of\nusers in their living environment. However, adapting automation to user needs\nremains a challenge. Indeed, many systems still rely on hand-crafted routines\nfor each smart object.This paper presents an original smart home architecture\nleveraging Large Language Models (LLMs) and user preferences to push the\nboundaries of personalisation and intuitiveness in the home environment.This\narticle explores a human-centred approach that uses the general knowledge\nprovided by LLMs to learn and facilitate interactions with the environment.The\nadvantages of the proposed model are demonstrated on a set of scenarios, as\nwell as a comparative analysis with various LLM implementations. Some metrics\nare assessed to determine the system's ability to maintain comfort, safety, and\nuser preferences. The paper details the approach to real-world implementation\nand evaluation.The proposed approach of using preferences shows up to 52.3%\nincrease in average grade, and with an average processing time reduced by 35.6%\non Starling 7B Alpha LLM. In addition, performance is 26.4% better than the\nresults of the larger models without preferences, with processing time almost\n20 times faster.",
      "tldr_zh": "这篇论文提出了一种创新的智能家居架构，利用 Large Language Models (LLMs) 和用户偏好来提升个性化体验，解决传统系统依赖手工例程的局限性。该方法采用人类中心的方法，借助 LLMs 的通用知识学习用户互动，从而实现更直观的家居环境控制和优化。在实验场景中，该架构使平均评分提高 52.3%，处理时间减少 35.6%（基于 Starling 7B Alpha LLM），并在性能上比更大模型提升 26.4%，处理速度快 20 倍，证明了其在舒适、安全和偏好维护方面的优势。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.12024v1",
      "published_date": "2024-06-28 07:08:20 UTC",
      "updated_date": "2024-06-28 07:08:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:48:43.495104"
    },
    {
      "arxiv_id": "2406.19690v1",
      "title": "Deep Fusion Model for Brain Tumor Classification Using Fine-Grained Gradient Preservation",
      "title_zh": "翻译失败",
      "authors": [
        "Niful Islam",
        "Mohaiminul Islam Bhuiyan",
        "Jarin Tasnim Raya",
        "Nur Shazwani Kamarudin",
        "Khan Md Hasib",
        "M. F. Mridha",
        "Dewan Md. Farid"
      ],
      "abstract": "Brain tumors are one of the most common diseases that lead to early death if\nnot diagnosed at an early stage. Traditional diagnostic approaches are\nextremely time-consuming and prone to errors. In this context, computer\nvision-based approaches have emerged as an effective tool for accurate brain\ntumor classification. While some of the existing solutions demonstrate\nnoteworthy accuracy, the models become infeasible to deploy in areas where\ncomputational resources are limited. This research addresses the need for\naccurate and fast classification of brain tumors with a priority of deploying\nthe model in technologically underdeveloped regions. The research presents a\nnovel architecture for precise brain tumor classification fusing pretrained\nResNet152V2 and modified VGG16 models. The proposed architecture undergoes a\ndiligent fine-tuning process that ensures fine gradients are preserved in deep\nneural networks, which are essential for effective brain tumor classification.\nThe proposed solution incorporates various image processing techniques to\nimprove image quality and achieves an astounding accuracy of 98.36% and 98.04%\nin Figshare and Kaggle datasets respectively. This architecture stands out for\nhaving a streamlined profile, with only 2.8 million trainable parameters. We\nhave leveraged 8-bit quantization to produce a model of size 73.881 MB,\nsignificantly reducing it from the previous size of 289.45 MB, ensuring smooth\ndeployment in edge devices even in resource-constrained areas. Additionally,\nthe use of Grad-CAM improves the interpretability of the model, offering\ninsightful information regarding its decision-making process. Owing to its high\ndiscriminative ability, this model can be a reliable option for accurate brain\ntumor classification.",
      "tldr_zh": "这篇论文针对脑肿瘤分类问题，提出了一种新型深度融合模型，结合预训练的 ResNet152V2 和修改后的 VGG16 架构，并通过 fine-grained gradient preservation 的细调过程确保模型在深度神经网络中保留关键梯度，从而实现高效分类。模型还整合了各种图像处理技术，分别在 Figshare 和 Kaggle 数据集上达到了 98.36% 和 98.04% 的高准确率，同时仅需 2.8 百万可训练参数，并通过 8-bit quantization 将模型大小减小至 73.881 MB，便于在计算资源有限的地区部署。使用 Grad-CAM 技术进一步提升了模型的可解释性，使其成为可靠的脑肿瘤诊断工具。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.19690v1",
      "published_date": "2024-06-28 07:06:02 UTC",
      "updated_date": "2024-06-28 07:06:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:48:56.603995"
    },
    {
      "arxiv_id": "2406.19686v1",
      "title": "Enhancing Radiological Diagnosis: A Collaborative Approach Integrating AI and Human Expertise for Visual Miss Correction",
      "title_zh": "增强放射学诊断：整合AI和人类专业知识的协作方法，用于视觉错误修正",
      "authors": [
        "Akash Awasthi",
        "Ngan Le",
        "Zhigang Deng",
        "Carol C. Wu",
        "Hien Van Nguyen"
      ],
      "abstract": "Human-AI collaboration to identify and correct perceptual errors in chest\nradiographs has not been previously explored. This study aimed to develop a\ncollaborative AI system, CoRaX, which integrates eye gaze data and radiology\nreports to enhance diagnostic accuracy in chest radiology by pinpointing\nperceptual errors and refining the decision-making process. Using public\ndatasets REFLACX and EGD-CXR, the study retrospectively developed CoRaX,\nemploying a large multimodal model to analyze image embeddings, eye gaze data,\nand radiology reports. The system's effectiveness was evaluated based on its\nreferral-making process, the quality of referrals, and performance in\ncollaborative diagnostic settings. CoRaX was tested on a simulated error\ndataset of 271 samples with 28% (93 of 332) missed abnormalities. The system\ncorrected 21% (71 of 332) of these errors, leaving 7% (22 of 312) unresolved.\nThe Referral-Usefulness score, indicating the accuracy of predicted regions for\nall true referrals, was 0.63 (95% CI 0.59, 0.68). The Total-Usefulness score,\nreflecting the diagnostic accuracy of CoRaX's interactions with radiologists,\nshowed that 84% (237 of 280) of these interactions had a score above 0.40. In\nconclusion, CoRaX efficiently collaborates with radiologists to address\nperceptual errors across various abnormalities, with potential applications in\nthe education and training of novice radiologists.",
      "tldr_zh": "这篇论文介绍了CoRaX系统，这是一个整合AI和人类专长的协作框架，旨在通过eye gaze data和放射学报告来识别并纠正胸部X光片中的感知错误，从而提升放射诊断准确性。系统采用大型多模态模型分析图像嵌入等数据，并基于REFLACX和EGD-CXR公共数据集进行开发和评估。在模拟错误数据集上，CoRaX纠正了21%（71/332）的异常错误，Referral-Usefulness得分达0.63（95% CI 0.59, 0.68），且84%（237/280）的交互Total-Usefulness得分高于0.40。该系统展示了在放射科医生教育和培训中的潜在应用潜力。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.HC"
      ],
      "primary_category": "eess.IV",
      "comment": "Under Review in Journal",
      "pdf_url": "http://arxiv.org/pdf/2406.19686v1",
      "published_date": "2024-06-28 06:51:38 UTC",
      "updated_date": "2024-06-28 06:51:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:49:18.435242"
    },
    {
      "arxiv_id": "2407.12814v1",
      "title": "Computational Politeness in Natural Language Processing: A Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Priyanshu Priya",
        "Mauajama Firdaus",
        "Asif Ekbal"
      ],
      "abstract": "Computational approach to politeness is the task of automatically predicting\nand generating politeness in text. This is a pivotal task for conversational\nanalysis, given the ubiquity and challenges of politeness in interactions. The\ncomputational approach to politeness has witnessed great interest from the\nconversational analysis community. This article is a compilation of past works\nin computational politeness in natural language processing. We view four\nmilestones in the research so far, viz. supervised and weakly-supervised\nfeature extraction to identify and induce politeness in a given text,\nincorporation of context beyond the target text, study of politeness across\ndifferent social factors, and study the relationship between politeness and\nvarious sociolinguistic cues. In this article, we describe the datasets,\napproaches, trends, and issues in computational politeness research. We also\ndiscuss representative performance values and provide pointers to future works,\nas given in the prior works. In terms of resources to understand the\nstate-of-the-art, this survey presents several valuable illustrations, most\nprominently, a table summarizing the past papers along different dimensions,\nsuch as the types of features, annotation techniques, and datasets used.",
      "tldr_zh": "这篇调查论文综述了自然语言处理(Natural Language Processing)中计算礼貌性的研究进展，焦点在于自动预测和生成文本中的礼貌性及其在对话分析中的挑战。论文概述了四个关键里程碑，包括监督和弱监督特征提取、整合文本外上下文、探讨礼貌在不同社会因素中的表现，以及分析礼貌与社会语言线索的关系。作者还总结了相关数据集、方法、趋势、问题和性能指标，并通过表格形式提供特征类型、注释技术和未来研究方向的指南。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Manuscript accepted at the ACM Computing Surveys (DOI:\n  https://doi.org/10.1145/3654660)",
      "pdf_url": "http://arxiv.org/pdf/2407.12814v1",
      "published_date": "2024-06-28 06:46:36 UTC",
      "updated_date": "2024-06-28 06:46:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:49:29.812759"
    },
    {
      "arxiv_id": "2406.19680v1",
      "title": "MimicMotion: High-Quality Human Motion Video Generation with Confidence-aware Pose Guidance",
      "title_zh": "MimicMotion：基于置信度感知姿态指导的高质量人体动作视频生成",
      "authors": [
        "Yuang Zhang",
        "Jiaxi Gu",
        "Li-Wen Wang",
        "Han Wang",
        "Junqi Cheng",
        "Yuefeng Zhu",
        "Fangyuan Zou"
      ],
      "abstract": "In recent years, generative artificial intelligence has achieved significant\nadvancements in the field of image generation, spawning a variety of\napplications. However, video generation still faces considerable challenges in\nvarious aspects, such as controllability, video length, and richness of\ndetails, which hinder the application and popularization of this technology. In\nthis work, we propose a controllable video generation framework, dubbed\nMimicMotion, which can generate high-quality videos of arbitrary length\nmimicking specific motion guidance. Compared with previous methods, our\napproach has several highlights. Firstly, we introduce confidence-aware pose\nguidance that ensures high frame quality and temporal smoothness. Secondly, we\nintroduce regional loss amplification based on pose confidence, which\nsignificantly reduces image distortion. Lastly, for generating long and smooth\nvideos, we propose a progressive latent fusion strategy. By this means, we can\nproduce videos of arbitrary length with acceptable resource consumption. With\nextensive experiments and user studies, MimicMotion demonstrates significant\nimprovements over previous approaches in various aspects. Detailed results and\ncomparisons are available on our project page:\nhttps://tencent.github.io/MimicMotion .",
      "tldr_zh": "这篇论文提出了 MimicMotion，一种可控的视频生成框架，能够生成任意长度的、高质量的人类动作视频，模仿特定动作指导。框架的关键创新包括引入 confidence-aware pose guidance 以确保帧质量和时间平滑性，以及基于 pose confidence 的 regional loss amplification 来减少图像失真。此外，他们提出了 progressive latent fusion strategy，以高效生成长视频，并通过广泛实验和用户研究证明了在视频可控性、长度和细节丰富性等方面比现有方法有显著改进。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.19680v1",
      "published_date": "2024-06-28 06:40:53 UTC",
      "updated_date": "2024-06-28 06:40:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:49:40.457919"
    },
    {
      "arxiv_id": "2407.00129v1",
      "title": "Multimodal Learning and Cognitive Processes in Radiology: MedGaze for Chest X-ray Scanpath Prediction",
      "title_zh": "放射学中的多模态学习和认知过程：MedGaze 用于胸部X光扫描路径",
      "authors": [
        "Akash Awasthi",
        "Ngan Le",
        "Zhigang Deng",
        "Rishi Agrawal",
        "Carol C. Wu",
        "Hien Van Nguyen"
      ],
      "abstract": "Predicting human gaze behavior within computer vision is integral for\ndeveloping interactive systems that can anticipate user attention, address\nfundamental questions in cognitive science, and hold implications for fields\nlike human-computer interaction (HCI) and augmented/virtual reality (AR/VR)\nsystems. Despite methodologies introduced for modeling human eye gaze behavior,\napplying these models to medical imaging for scanpath prediction remains\nunexplored. Our proposed system aims to predict eye gaze sequences from\nradiology reports and CXR images, potentially streamlining data collection and\nenhancing AI systems using larger datasets. However, predicting human scanpaths\non medical images presents unique challenges due to the diverse nature of\nabnormal regions. Our model predicts fixation coordinates and durations\ncritical for medical scanpath prediction, outperforming existing models in the\ncomputer vision community. Utilizing a two-stage training process and large\npublicly available datasets, our approach generates static heatmaps and eye\ngaze videos aligned with radiology reports, facilitating comprehensive\nanalysis. We validate our approach by comparing its performance with\nstate-of-the-art methods and assessing its generalizability among different\nradiologists, introducing novel strategies to model radiologists' search\npatterns during CXR image diagnosis. Based on the radiologist's evaluation,\nMedGaze can generate human-like gaze sequences with a high focus on relevant\nregions over the CXR images. It sometimes also outperforms humans in terms of\nredundancy and randomness in the scanpaths.",
      "tldr_zh": "这篇论文提出了 MedGaze 系统，通过 Multimodal Learning 和 Cognitive Processes 预测放射科医生在 Chest X-ray (CXR) 图像上的眼动路径 (scanpath)，旨在提升交互系统、认知科学及 HCI 和 AR/VR 领域的应用。系统利用两阶段训练过程和大型公开数据集，从放射报告和图像中预测注视坐标及持续时间，生成静态热图和眼动视频，以应对医疗图像中异常区域的多样性挑战。实验结果显示，MedGaze 优于现有计算机视觉模型，能模拟放射科医生的搜索模式，并在冗余和随机性方面有时超越人类表现，从而简化数据收集并增强 AI 在医疗成像中的泛化能力。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "eess.IV",
      "comment": "Submitted to the Journal",
      "pdf_url": "http://arxiv.org/pdf/2407.00129v1",
      "published_date": "2024-06-28 06:38:58 UTC",
      "updated_date": "2024-06-28 06:38:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:49:44.333903"
    },
    {
      "arxiv_id": "2406.19670v2",
      "title": "Function+Data Flow: A Framework to Specify Machine Learning Pipelines for Digital Twinning",
      "title_zh": "翻译失败",
      "authors": [
        "Eduardo de Conto",
        "Blaise Genest",
        "Arvind Easwaran"
      ],
      "abstract": "The development of digital twins (DTs) for physical systems increasingly\nleverages artificial intelligence (AI), particularly for combining data from\ndifferent sources or for creating computationally efficient, reduced-dimension\nmodels. Indeed, even in very different application domains, twinning employs\ncommon techniques such as model order reduction and modelization with hybrid\ndata (that is, data sourced from both physics-based models and sensors).\nDespite this apparent generality, current development practices are ad-hoc,\nmaking the design of AI pipelines for digital twinning complex and\ntime-consuming. Here we propose Function+Data Flow (FDF), a domain-specific\nlanguage (DSL) to describe AI pipelines within DTs. FDF aims to facilitate the\ndesign and validation of digital twins. Specifically, FDF treats functions as\nfirst-class citizens, enabling effective manipulation of models learned with\nAI. We illustrate the benefits of FDF on two concrete use cases from different\ndomains: predicting the plastic strain of a structure and modeling the\nelectromagnetic behavior of a bearing.",
      "tldr_zh": "这篇论文提出 Function+Data Flow (FDF) 框架，这是一个领域特定语言 (DSL)，用于指定机器学习管道在数字孪生 (digital twinning) 中的应用，以解决当前开发实践的临时性和复杂性。FDF 将函数视为第一类公民，便于有效操作 AI 模型，包括模型阶次约简和混合数据处理，从而简化数字孪生的设计和验证。通过两个实际案例——预测结构塑性应变和建模轴承电磁行为——展示了 FDF 在不同领域的益处，提高了效率和通用性。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "9 pages, 10 figures, to be published in AIware'24",
      "pdf_url": "http://arxiv.org/pdf/2406.19670v2",
      "published_date": "2024-06-28 05:44:47 UTC",
      "updated_date": "2024-07-08 08:28:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:49:57.776907"
    },
    {
      "arxiv_id": "2406.19653v3",
      "title": "ACES: Automatic Cohort Extraction System for Event-Stream Datasets",
      "title_zh": "ACES：针对事件流数据集的自动队列提取系统",
      "authors": [
        "Justin Xu",
        "Jack Gallifant",
        "Alistair E. W. Johnson",
        "Matthew B. A. McDermott"
      ],
      "abstract": "Reproducibility remains a significant challenge in machine learning (ML) for\nhealthcare. Datasets, model pipelines, and even task or cohort definitions are\noften private in this field, leading to a significant barrier in sharing,\niterating, and understanding ML results on electronic health record (EHR)\ndatasets. We address a significant part of this problem by introducing the\nAutomatic Cohort Extraction System (ACES) for event-stream data. This library\nis designed to simultaneously simplify the development of tasks and cohorts for\nML in healthcare and also enable their reproduction, both at an exact level for\nsingle datasets and at a conceptual level across datasets. To accomplish this,\nACES provides: (1) a highly intuitive and expressive domain-specific\nconfiguration language for defining both dataset-specific concepts and\ndataset-agnostic inclusion or exclusion criteria, and (2) a pipeline to\nautomatically extract patient records that meet these defined criteria from\nreal-world data. ACES can be automatically applied to any dataset in either the\nMedical Event Data Standard (MEDS) or Event Stream GPT (ESGPT) formats, or to\n*any* dataset in which the necessary task-specific predicates can be extracted\nin an event-stream form. ACES has the potential to significantly lower the\nbarrier to entry for defining ML tasks in representation learning, redefine the\nway researchers interact with EHR datasets, and significantly improve the state\nof reproducibility for ML studies using this modality. ACES is available at:\nhttps://github.com/justin13601/aces.",
      "tldr_zh": "这篇论文介绍了 ACES（Automatic Cohort Extraction System），一个针对事件流数据集的自动队列提取系统，旨在解决医疗领域机器学习（ML）的可重复性挑战，如数据集和任务定义的私有性问题。ACES 提供了一个直观的领域特定配置语言，用于定义数据集特定概念和数据集无关的包含/排除标准，以及一个管道来从电子健康记录（EHR）数据中自动提取符合标准的患者记录。该系统支持 MEDS 和 ESGPT 格式等多种数据集，并能提升任务开发效率和概念层面的可重复性。通过开源实现，ACES 有望降低 ML 任务定义的门槛，并改善研究者在 EHR 数据集上的互动和研究质量。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "[ICLR 2025] For the latest ACES online documentation, please see\n  https://eventstreamaces.readthedocs.io/en/latest/",
      "pdf_url": "http://arxiv.org/pdf/2406.19653v3",
      "published_date": "2024-06-28 04:48:05 UTC",
      "updated_date": "2025-03-02 01:47:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:50:10.957602"
    },
    {
      "arxiv_id": "2406.19651v1",
      "title": "CANDY: A Benchmark for Continuous Approximate Nearest Neighbor Search with Dynamic Data Ingestion",
      "title_zh": "翻译失败",
      "authors": [
        "Xianzhi Zeng",
        "Zhuoyan Wu",
        "Xinjing Hu",
        "Xuanhua Shi",
        "Shixuan Sun",
        "Shuhao Zhang"
      ],
      "abstract": "Approximate K Nearest Neighbor (AKNN) algorithms play a pivotal role in\nvarious AI applications, including information retrieval, computer vision, and\nnatural language processing. Although numerous AKNN algorithms and benchmarks\nhave been developed recently to evaluate their effectiveness, the dynamic\nnature of real-world data presents significant challenges that existing\nbenchmarks fail to address. Traditional benchmarks primarily assess retrieval\neffectiveness in static contexts and often overlook update efficiency, which is\ncrucial for handling continuous data ingestion. This limitation results in an\nincomplete assessment of an AKNN algorithms ability to adapt to changing data\npatterns, thereby restricting insights into their performance in dynamic\nenvironments. To address these gaps, we introduce CANDY, a benchmark tailored\nfor Continuous Approximate Nearest Neighbor Search with Dynamic Data Ingestion.\nCANDY comprehensively assesses a wide range of AKNN algorithms, integrating\nadvanced optimizations such as machine learning-driven inference to supplant\ntraditional heuristic scans, and improved distance computation methods to\nreduce computational overhead. Our extensive evaluations across diverse\ndatasets demonstrate that simpler AKNN baselines often surpass more complex\nalternatives in terms of recall and latency. These findings challenge\nestablished beliefs about the necessity of algorithmic complexity for high\nperformance. Furthermore, our results underscore existing challenges and\nilluminate future research opportunities. We have made the datasets and\nimplementation methods available at: https://github.com/intellistream/candy.",
      "tldr_zh": "该研究指出了现有 Approximate Nearest Neighbor (AKNN) 算法基准在处理动态数据摄取时的局限性，如忽略更新效率和数据变化适应。作者引入了 CANDY 基准，用于评估连续 AKNN 搜索，整合机器学习驱动的推理优化和改进的距离计算方法，以全面测试算法在动态环境中的性能。在跨多种数据集的广泛评估中，结果显示简单 AKNN 基线在 recall 和 latency 方面往往优于复杂算法，这挑战了算法复杂性的传统观点，并为未来研究提供了新见解；相关数据集和代码已在 GitHub 上公开。",
      "categories": [
        "cs.DB",
        "cs.AI"
      ],
      "primary_category": "cs.DB",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.19651v1",
      "published_date": "2024-06-28 04:46:11 UTC",
      "updated_date": "2024-06-28 04:46:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:50:21.932105"
    },
    {
      "arxiv_id": "2406.19648v1",
      "title": "Designing and Evaluating Multi-Chatbot Interface for Human-AI Communication: Preliminary Findings from a Persuasion Task",
      "title_zh": "翻译失败",
      "authors": [
        "Sion Yoon",
        "Tae Eun Kim",
        "Yoo Jung Oh"
      ],
      "abstract": "The dynamics of human-AI communication have been reshaped by language models\nsuch as ChatGPT. However, extant research has primarily focused on dyadic\ncommunication, leaving much to be explored regarding the dynamics of human-AI\ncommunication in group settings. The availability of multiple language model\nchatbots presents a unique opportunity for scholars to better understand the\ninteraction between humans and multiple chatbots. This study examines the\nimpact of multi-chatbot communication in a specific persuasion setting:\npromoting charitable donations. We developed an online environment that enables\nmulti-chatbot communication and conducted a pilot experiment utilizing two\nGPT-based chatbots, Save the Children and UNICEF chatbots, to promote\ncharitable donations. In this study, we present our development process of the\nmulti-chatbot interface and present preliminary findings from a pilot\nexperiment. Analysis of qualitative and quantitative feedback are presented,\nand limitations are addressed.",
      "tldr_zh": "这篇论文探讨了多聊天机器人(multi-chatbot)接口的设计和评估，旨在理解人类-AI 通信在群组设置中的动态，特别是应用于说服任务如促进慈善捐赠。研究团队开发了一个在线环境，使用两个 GPT-based chatbots（Save the Children 和 UNICEF 聊天机器人）进行试点实验，分析了用户互动的定性和定量反馈。初步发现表明，多-chatbot 通信可能增强说服效果，但也指出了实验的限制，为未来的人类-AI 群组互动研究提供了基础。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.19648v1",
      "published_date": "2024-06-28 04:33:41 UTC",
      "updated_date": "2024-06-28 04:33:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:50:35.457907"
    },
    {
      "arxiv_id": "2406.19644v2",
      "title": "Beyond Human Preferences: Exploring Reinforcement Learning Trajectory Evaluation and Improvement through LLMs",
      "title_zh": "超越人类偏好：通过 LLMs 探索强化学习轨迹评估和改进",
      "authors": [
        "Zichao Shen",
        "Tianchen Zhu",
        "Qingyun Sun",
        "Shiqi Gao",
        "Jianxin Li"
      ],
      "abstract": "Reinforcement learning (RL) faces challenges in evaluating policy\ntrajectories within intricate game tasks due to the difficulty in designing\ncomprehensive and precise reward functions. This inherent difficulty curtails\nthe broader application of RL within game environments characterized by diverse\nconstraints. Preference-based reinforcement learning (PbRL) presents a\npioneering framework that capitalizes on human preferences as pivotal reward\nsignals, thereby circumventing the need for meticulous reward engineering.\nHowever, obtaining preference data from human experts is costly and\ninefficient, especially under conditions marked by complex constraints. To\ntackle this challenge, we propose a LLM-enabled automatic preference generation\nframework named LLM4PG , which harnesses the capabilities of large language\nmodels (LLMs) to abstract trajectories, rank preferences, and reconstruct\nreward functions to optimize conditioned policies. Experiments on tasks with\ncomplex language constraints demonstrated the effectiveness of our LLM-enabled\nreward functions, accelerating RL convergence and overcoming stagnation caused\nby slow or absent progress under original reward structures. This approach\nmitigates the reliance on specialized human knowledge and demonstrates the\npotential of LLMs to enhance RL's effectiveness in complex environments in the\nwild.",
      "tldr_zh": "强化学习 (RL) 在复杂游戏任务中面临奖励函数设计困难的问题，而偏好-based RL (PbRL) 虽依赖人类偏好作为奖励信号，但获取此类数据成本高昂。论文提出 LLM4PG 框架，利用大型语言模型 (LLMs) 自动抽象轨迹、排名偏好并重构奖励函数，以优化受条件约束的政策。实验结果表明，该框架在具有复杂语言约束的任务上加速了 RL 的收敛速度，并克服了原奖励结构导致的停滞问题，最终减少了对专业人类知识的依赖，并展示了 LLMs 在复杂环境中的增强潜力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "accepted by IJCAI 2024 GAAMAL",
      "pdf_url": "http://arxiv.org/pdf/2406.19644v2",
      "published_date": "2024-06-28 04:21:24 UTC",
      "updated_date": "2024-07-01 03:32:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:50:48.693162"
    },
    {
      "arxiv_id": "2406.19643v3",
      "title": "Debate-to-Write: A Persona-Driven Multi-Agent Framework for Diverse Argument Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Zhe Hu",
        "Hou Pong Chan",
        "Jing Li",
        "Yu Yin"
      ],
      "abstract": "Writing persuasive arguments is a challenging task for both humans and\nmachines. It entails incorporating high-level beliefs from various perspectives\non the topic, along with deliberate reasoning and planning to construct a\ncoherent narrative. Current language models often generate surface tokens\nautoregressively, lacking explicit integration of these underlying controls,\nresulting in limited output diversity and coherence. In this work, we propose a\npersona-based multi-agent framework for argument writing. Inspired by the human\ndebate, we first assign each agent a persona representing its high-level\nbeliefs from a unique perspective, and then design an agent interaction process\nso that the agents can collaboratively debate and discuss the idea to form an\noverall plan for argument writing. Such debate process enables fluid and\nnonlinear development of ideas. We evaluate our framework on argumentative\nessay writing. The results show that our framework can generate more diverse\nand persuasive arguments through both automatic and human evaluations.",
      "tldr_zh": "该论文提出了一种名为Debate-to-Write的persona-based multi-agent framework，用于生成多样化的说服性论点，以解决当前语言模型在整合高水平信念、推理和规划方面的局限性，导致输出多样性和连贯性不足的问题。框架中，每个智能体被赋予一个persona，代表独特视角的高级信念，并通过协作辩论和讨论过程，形成非线性发展的整体写作计划。实验结果显示，该框架在论证性文章写作上通过自动和人类评估，生成更具多样性和说服力的论点。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at COLING 2025",
      "pdf_url": "http://arxiv.org/pdf/2406.19643v3",
      "published_date": "2024-06-28 04:21:20 UTC",
      "updated_date": "2025-01-03 10:23:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:50:58.903182"
    },
    {
      "arxiv_id": "2406.19638v1",
      "title": "Precision matters: Precision-aware ensemble for weakly supervised semantic segmentation",
      "title_zh": "精确性很重要：针对弱监督语义分割的精确度感知集成方法",
      "authors": [
        "Junsung Park",
        "Hyunjung Shim"
      ],
      "abstract": "Weakly Supervised Semantic Segmentation (WSSS) employs weak supervision, such\nas image-level labels, to train the segmentation model. Despite the impressive\nachievement in recent WSSS methods, we identify that introducing weak labels\nwith high mean Intersection of Union (mIoU) does not guarantee high\nsegmentation performance. Existing studies have emphasized the importance of\nprioritizing precision and reducing noise to improve overall performance. In\nthe same vein, we propose ORANDNet, an advanced ensemble approach tailored for\nWSSS. ORANDNet combines Class Activation Maps (CAMs) from two different\nclassifiers to increase the precision of pseudo-masks (PMs). To further\nmitigate small noise in the PMs, we incorporate curriculum learning. This\ninvolves training the segmentation model initially with pairs of smaller-sized\nimages and corresponding PMs, gradually transitioning to the original-sized\npairs. By combining the original CAMs of ResNet-50 and ViT, we significantly\nimprove the segmentation performance over the single-best model and the naive\nensemble model, respectively. We further extend our ensemble method to CAMs\nfrom AMN (ResNet-like) and MCTformer (ViT-like) models, achieving performance\nbenefits in advanced WSSS models. It highlights the potential of our ORANDNet\nas a final add-on module for WSSS models.",
      "tldr_zh": "本文研究发现，在弱监督语义分割 (WSSS) 中，使用高 mean Intersection of Union (mIoU) 的弱标签并不一定带来更好的性能，因此强调了优先提升精度和减少噪声的重要性。作者提出 ORANDNet，一种先进的集成方法，通过结合两个不同分类器的 Class Activation Maps (CAMs) 来提高伪掩码 (PMs) 的精度，并引入课程学习，从小尺寸图像逐渐过渡到原尺寸以进一步抑制噪声。实验结果显示，ORANDNet 结合 ResNet-50 和 ViT 的 CAMs，比单模型和简单集成方法提升了显著的分割性能，并在扩展到 AMN 和 MCTformer 等高级模型时继续获得收益。该方法可作为 WSSS 模型的最终附加模块，提供更可靠的性能提升。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "5 pages, 5 figures, accepted in AAAI 2024 Edge Intelligence Workshop",
      "pdf_url": "http://arxiv.org/pdf/2406.19638v1",
      "published_date": "2024-06-28 03:58:02 UTC",
      "updated_date": "2024-06-28 03:58:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:51:12.395022"
    },
    {
      "arxiv_id": "2407.00128v1",
      "title": "When Search Engine Services meet Large Language Models: Visions and Challenges",
      "title_zh": "翻译失败",
      "authors": [
        "Haoyi Xiong",
        "Jiang Bian",
        "Yuchen Li",
        "Xuhong Li",
        "Mengnan Du",
        "Shuaiqiang Wang",
        "Dawei Yin",
        "Sumi Helal"
      ],
      "abstract": "Combining Large Language Models (LLMs) with search engine services marks a\nsignificant shift in the field of services computing, opening up new\npossibilities to enhance how we search for and retrieve information, understand\ncontent, and interact with internet services. This paper conducts an in-depth\nexamination of how integrating LLMs with search engines can mutually benefit\nboth technologies. We focus on two main areas: using search engines to improve\nLLMs (Search4LLM) and enhancing search engine functions using LLMs\n(LLM4Search). For Search4LLM, we investigate how search engines can provide\ndiverse high-quality datasets for pre-training of LLMs, how they can use the\nmost relevant documents to help LLMs learn to answer queries more accurately,\nhow training LLMs with Learning-To-Rank (LTR) tasks can enhance their ability\nto respond with greater precision, and how incorporating recent search results\ncan make LLM-generated content more accurate and current. In terms of\nLLM4Search, we examine how LLMs can be used to summarize content for better\nindexing by search engines, improve query outcomes through optimization,\nenhance the ranking of search results by analyzing document relevance, and help\nin annotating data for learning-to-rank tasks in various learning contexts.\nHowever, this promising integration comes with its challenges, which include\naddressing potential biases and ethical issues in training models, managing the\ncomputational and other costs of incorporating LLMs into search services, and\ncontinuously updating LLM training with the ever-changing web content. We\ndiscuss these challenges and chart out required research directions to address\nthem. We also discuss broader implications for service computing, such as\nscalability, privacy concerns, and the need to adapt search engine\narchitectures for these advanced models.",
      "tldr_zh": "这篇论文探讨了将 Large Language Models (LLMs) 与搜索引擎服务整合的潜在益处和挑战，分为 Search4LLM 和 LLM4Search 两个主要方向。Search4LLM 强调利用搜索引擎提供高质量数据集、相关文档和 Learning-To-Rank (LTR) 任务来提升 LLMs 的查询响应精度和时效性；LLM4Search 则聚焦于使用 LLMs 优化搜索引擎的功能，如内容总结、查询优化、结果排名和数据标注。论文分析了整合带来的互惠效应，但也指出了关键挑战，包括模型偏见、伦理问题、计算成本以及内容更新的需求。最后，它为服务计算领域勾勒出未来研究方向，如提升可扩展性、解决隐私问题和调整架构，以实现更可靠的整合。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "Under Review",
      "pdf_url": "http://arxiv.org/pdf/2407.00128v1",
      "published_date": "2024-06-28 03:52:13 UTC",
      "updated_date": "2024-06-28 03:52:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:51:22.452963"
    },
    {
      "arxiv_id": "2406.19630v1",
      "title": "Optimal Video Compression using Pixel Shift Tracking",
      "title_zh": "翻译失败",
      "authors": [
        "Hitesh Saai Mananchery Panneerselvam",
        "Smit Anand"
      ],
      "abstract": "The Video comprises approximately ~85\\% of all internet traffic, but video\nencoding/compression is being historically done with hard coded rules, which\nhas worked well but only to a certain limit. We have seen a surge in video\ncompression algorithms using ML-based models in the last few years and many of\nthem have outperformed several legacy codecs. The models range from encoding\nvideo end to end using an ML approach or replacing some intermediate steps in\nlegacy codecs using ML models to increase the efficiency of those steps.\n  Optimizing video storage is an essential aspect of video processing, so we\nare proposing one of the possible approaches to achieve it is by avoiding\nredundant data at each frame. In this paper, we want to introduce the approach\nof redundancies removal in subsequent frames for a given video as a main\napproach for video compression. We call this method Redundancy Removal using\nShift (R\\textsuperscript2S). This method can be utilized across various Machine\nLearning model algorithms, and make the compression more accessible and\nadaptable. In this study, we have utilized a computer vision-based pixel point\ntracking method to identify redundant pixels to encode video for optimal\nstorage.",
      "tldr_zh": "这篇论文针对视频压缩问题，指出传统硬编码规则已达极限，而基于 ML 的算法正逐步超越传统编解码器。作者提出一种名为 Redundancy Removal using Shift (R²S) 的方法，通过计算机视觉的 Pixel Shift Tracking 技术识别并移除视频帧间的冗余像素，从而优化存储。实验结果显示，该方法可与其他 ML 模型结合，提升压缩效率和适应性，为视频处理提供更高效的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.19630v1",
      "published_date": "2024-06-28 03:36:38 UTC",
      "updated_date": "2024-06-28 03:36:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:51:33.963953"
    },
    {
      "arxiv_id": "2406.19626v3",
      "title": "Safety through feedback in Constrained RL",
      "title_zh": "通过反馈在约束强化学习中的安全",
      "authors": [
        "Shashank Reddy Chirra",
        "Pradeep Varakantham",
        "Praveen Paruchuri"
      ],
      "abstract": "In safety-critical RL settings, the inclusion of an additional cost function\nis often favoured over the arduous task of modifying the reward function to\nensure the agent's safe behaviour. However, designing or evaluating such a cost\nfunction can be prohibitively expensive. For instance, in the domain of\nself-driving, designing a cost function that encompasses all unsafe behaviours\n(e.g. aggressive lane changes) is inherently complex. In such scenarios, the\ncost function can be learned from feedback collected offline in between\ntraining rounds. This feedback can be system generated or elicited from a human\nobserving the training process. Previous approaches have not been able to scale\nto complex environments and are constrained to receiving feedback at the state\nlevel which can be expensive to collect. To this end, we introduce an approach\nthat scales to more complex domains and extends to beyond state-level feedback,\nthus, reducing the burden on the evaluator. Inferring the cost function in such\nsettings poses challenges, particularly in assigning credit to individual\nstates based on trajectory-level feedback. To address this, we propose a\nsurrogate objective that transforms the problem into a state-level supervised\nclassification task with noisy labels, which can be solved efficiently.\nAdditionally, it is often infeasible to collect feedback on every trajectory\ngenerated by the agent, hence, two fundamental questions arise: (1) Which\ntrajectories should be presented to the human? and (2) How many trajectories\nare necessary for effective learning? To address these questions, we introduce\n\\textit{novelty-based sampling} that selectively involves the evaluator only\nwhen the the agent encounters a \\textit{novel} trajectory. We showcase the\nefficiency of our method through experimentation on several benchmark Safety\nGymnasium environments and realistic self-driving scenarios.",
      "tldr_zh": "该论文针对安全关键的强化学习（Constrained RL）环境，提出了一种通过反馈学习成本函数的方法，以避免复杂且昂贵的奖励函数修改，例如在自动驾驶中处理不安全行为。该方法将轨迹级反馈转化为带噪声标签的状态级监督分类任务，使用代理目标来高效解决信用分配问题，并引入基于新颖性的采样策略，仅在代理遇到新轨迹时收集反馈，从而减少评估者负担。实验结果显示，该方法在 Safety Gymnasium 基准环境和实际自动驾驶场景中表现出色，提升了代理的安全性和学习效率。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at NeurIPS 2024 (Poster)",
      "pdf_url": "http://arxiv.org/pdf/2406.19626v3",
      "published_date": "2024-06-28 03:29:33 UTC",
      "updated_date": "2025-01-11 07:31:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:51:46.312109"
    },
    {
      "arxiv_id": "2407.01615v1",
      "title": "Edge-DIRECT: A Deep Reinforcement Learning-based Method for Solving Heterogeneous Electric Vehicle Routing Problem with Time Window Constraints",
      "title_zh": "Edge-DIRECT：一种基于深度强化学习的方法，用于解决带有时间窗约束的异构电动汽车路径规划问题",
      "authors": [
        "Arash Mozhdehi",
        "Mahdi Mohammadizadeh",
        "Xin Wang"
      ],
      "abstract": "In response to carbon-neutral policies in developed countries, electric\nvehicles route optimization has gained importance for logistics companies. With\nthe increasing focus on customer expectations and the shift towards more\ncustomer-oriented business models, the integration of delivery time-windows has\nbecome essential in logistics operations. Recognizing the critical nature of\nthese developments, this article studies the heterogeneous electric vehicle\nrouting problem with time-window constraints (HEVRPTW). To solve this variant\nof vehicle routing problem (VRP), we propose a DRL-based approach, named\nEdge-enhanced Dual attentIon encoderR and feature-EnhanCed dual aTtention\ndecoder (Edge-DIRECT). Edge-DIRECT features an extra graph representation, the\nnode connectivity of which is based on the overlap of customer time-windows.\nEdge-DIRECT's self-attention encoding mechanism is enhanced by exploiting the\nenergy consumption and travel time between the locations. To effectively\naccount for the heterogeneity of the EVs' fleet, a dual attention decoder has\nbeen introduced. Experimental results based on two real-world datasets reveal\nthat Edge-DIRECT outperforms a state-of-the-art DRL-based method and a\nwell-established heuristic approach in solution quality and execution time.\nFurthermore, it exhibits competitive performance when compared to another\nleading heuristic method.",
      "tldr_zh": "本文针对异构电动车路由问题（HEVRPTW），提出了一种基于深度强化学习（DRL）的Edge-DIRECT方法，以优化电动车路由并满足时间窗口约束。Edge-DIRECT通过额外基于客户时间窗口重叠的图表示、增强的自注意力编码机制（利用能源消耗和旅行时间）以及双注意力解码器来处理电动车异构性。实验在两个真实数据集上表明，该方法在解决方案质量和执行时间上优于现有DRL基准和启发式方法，并与领先的启发式方法表现出竞争性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.01615v1",
      "published_date": "2024-06-28 03:18:12 UTC",
      "updated_date": "2024-06-28 03:18:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:51:59.201807"
    },
    {
      "arxiv_id": "2406.19622v1",
      "title": "Data-Driven Lipschitz Continuity: A Cost-Effective Approach to Improve Adversarial Robustness",
      "title_zh": "数据驱动的李普希",
      "authors": [
        "Erh-Chung Chen",
        "Pin-Yu Chen",
        "I-Hsin Chung",
        "Che-Rung Lee"
      ],
      "abstract": "The security and robustness of deep neural networks (DNNs) have become\nincreasingly concerning. This paper aims to provide both a theoretical\nfoundation and a practical solution to ensure the reliability of DNNs. We\nexplore the concept of Lipschitz continuity to certify the robustness of DNNs\nagainst adversarial attacks, which aim to mislead the network with adding\nimperceptible perturbations into inputs. We propose a novel algorithm that\nremaps the input domain into a constrained range, reducing the Lipschitz\nconstant and potentially enhancing robustness. Unlike existing adversarially\ntrained models, where robustness is enhanced by introducing additional examples\nfrom other datasets or generative models, our method is almost cost-free as it\ncan be integrated with existing models without requiring re-training.\nExperimental results demonstrate the generalizability of our method, as it can\nbe combined with various models and achieve enhancements in robustness.\nFurthermore, our method achieves the best robust accuracy for CIFAR10,\nCIFAR100, and ImageNet datasets on the RobustBench leaderboard.",
      "tldr_zh": "本论文探讨了深度神经网络（DNNs）的安全性和鲁棒性问题，通过数据驱动的Lipschitz continuity方法来提升对抗攻击的鲁棒性。研究提出了一种新算法，将输入域重映射到受限范围，从而减少Lipschitz constant，并增强模型的可靠性，而无需重新训练，实现了几乎零成本的整合。与现有方法不同，该方法具有通用性，可与各种模型结合。实验结果显示，在CIFAR10、CIFAR100和ImageNet数据集上，该方法在RobustBench排行榜上取得了最佳鲁棒准确率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.19622v1",
      "published_date": "2024-06-28 03:10:36 UTC",
      "updated_date": "2024-06-28 03:10:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:52:12.161949"
    },
    {
      "arxiv_id": "2406.19614v1",
      "title": "A Survey on Data Quality Dimensions and Tools for Machine Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Yuhan Zhou",
        "Fengjiao Tu",
        "Kewei Sha",
        "Junhua Ding",
        "Haihua Chen"
      ],
      "abstract": "Machine learning (ML) technologies have become substantial in practically all\naspects of our society, and data quality (DQ) is critical for the performance,\nfairness, robustness, safety, and scalability of ML models. With the large and\ncomplex data in data-centric AI, traditional methods like exploratory data\nanalysis (EDA) and cross-validation (CV) face challenges, highlighting the\nimportance of mastering DQ tools. In this survey, we review 17 DQ evaluation\nand improvement tools in the last 5 years. By introducing the DQ dimensions,\nmetrics, and main functions embedded in these tools, we compare their strengths\nand limitations and propose a roadmap for developing open-source DQ tools for\nML. Based on the discussions on the challenges and emerging trends, we further\nhighlight the potential applications of large language models (LLMs) and\ngenerative AI in DQ evaluation and improvement for ML. We believe this\ncomprehensive survey can enhance understanding of DQ in ML and could drive\nprogress in data-centric AI. A complete list of the literature investigated in\nthis survey is available on GitHub at:\nhttps://github.com/haihua0913/awesome-dq4ml.",
      "tldr_zh": "这篇调查论文探讨了数据质量（DQ）在机器学习（ML）中的关键作用，包括对模型性能、公平性、鲁棒性和可扩展性的影响，尤其在数据中心 AI 时代，传统方法如探索性数据分析（EDA）和交叉验证（CV）面临挑战。作者审视了过去 5 年内的 17 个 DQ 评估和改进工具，介绍了这些工具的 DQ 维度、指标和主要功能，并比较了它们的优势、局限性，同时提出开发开源 DQ 工具的路线图。论文还讨论了大型语言模型（LLMs）和生成式 AI 在 DQ 评估和改进中的潜在应用，旨在提升对 ML 中 DQ 的理解并推动数据中心 AI 的进展。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "This paper has been accepted by The 6th IEEE International Conference\n  on Artificial Intelligence Testing (IEEE AITest 2024) as an invited paper",
      "pdf_url": "http://arxiv.org/pdf/2406.19614v1",
      "published_date": "2024-06-28 02:41:33 UTC",
      "updated_date": "2024-06-28 02:41:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:52:24.170756"
    },
    {
      "arxiv_id": "2407.12023v1",
      "title": "CMMaTH: A Chinese Multi-modal Math Skill Evaluation Benchmark for Foundation Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zhong-Zhi Li",
        "Ming-Liang Zhang",
        "Fei Yin",
        "Zhi-Long Ji",
        "Jin-Feng Bai",
        "Zhen-Ru Pan",
        "Fan-Hu Zeng",
        "Jian Xu",
        "Jia-Xin Zhang",
        "Cheng-Lin Liu"
      ],
      "abstract": "Due to the rapid advancements in multimodal large language models, evaluating\ntheir multimodal mathematical capabilities continues to receive wide attention.\nDespite the datasets like MathVista proposed benchmarks for assessing\nmathematical capabilities in multimodal scenarios, there is still a lack of\ncorresponding evaluation tools and datasets for fine-grained assessment in the\ncontext of K12 education in Chinese language. To systematically evaluate the\ncapability of multimodal large models in solving Chinese multimodal\nmathematical problems, we propose a Chinese Multi-modal Math Skill Evaluation\nBenchmark, named CMMaTH, contraining 23k multimodal K12 math related questions,\nforming the largest Chinese multimodal mathematical problem benchmark to date.\nCMMaTH questions from elementary to high school levels, provide increased\ndiversity in problem types, solution objectives, visual elements, detailed\nknowledge points, and standard solution annotations. We have constructed an\nopen-source tool GradeGPT integrated with the CMMaTH dataset, facilitating\nstable, rapid, and cost-free model evaluation. Our data and code are available.",
      "tldr_zh": "该论文提出 CMMaTH，这是一个针对多模态大型语言模型（multimodal large language models）的中文多模态数学技能评估基准，旨在填补现有工具在 K12 教育中文本和视觉数学问题评估的空白。CMMaTH 包含 23k 个多模态 K12 数学问题，从小学到高中水平，提供多样化的问题类型、视觉元素、详细知识点和标准解决方案，是目前最大的中文多模态数学问题数据集。研究团队还构建了开源工具 GradeGPT，便于稳定、快速且免费的模型评估，并公开了数据和代码，以促进进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.12023v1",
      "published_date": "2024-06-28 02:35:51 UTC",
      "updated_date": "2024-06-28 02:35:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:52:37.024610"
    },
    {
      "arxiv_id": "2406.19611v1",
      "title": "Multimodal Data Integration for Precision Oncology: Challenges and Future Directions",
      "title_zh": "多模态数据整合用于精准肿瘤学：挑战与未来方向",
      "authors": [
        "Huajun Zhou",
        "Fengtao Zhou",
        "Chenyu Zhao",
        "Yingxue Xu",
        "Luyang Luo",
        "Hao Chen"
      ],
      "abstract": "The essence of precision oncology lies in its commitment to tailor targeted\ntreatments and care measures to each patient based on the individual\ncharacteristics of the tumor. The inherent heterogeneity of tumors necessitates\ngathering information from diverse data sources to provide valuable insights\nfrom various perspectives, fostering a holistic comprehension of the tumor.\nOver the past decade, multimodal data integration technology for precision\noncology has made significant strides, showcasing remarkable progress in\nunderstanding the intricate details within heterogeneous data modalities. These\nstrides have exhibited tremendous potential for improving clinical\ndecision-making and model interpretation, contributing to the advancement of\ncancer care and treatment. Given the rapid progress that has been achieved, we\nprovide a comprehensive overview of about 300 papers detailing cutting-edge\nmultimodal data integration techniques in precision oncology. In addition, we\nconclude the primary clinical applications that have reaped significant\nbenefits, including early assessment, diagnosis, prognosis, and biomarker\ndiscovery. Finally, derived from the findings of this survey, we present an\nin-depth analysis that explores the pivotal challenges and reveals essential\npathways for future research in the field of multimodal data integration for\nprecision oncology.",
      "tldr_zh": "该论文综述了多模态数据集成在精准 oncology 中的进展与挑战，强调通过整合异质肿瘤数据来源（如多种模态信息）实现对肿瘤的整体理解，以支持个性化治疗。作者分析了约300篇文献，展示了这些技术在临床应用中的显著益处，包括早期 assessment、diagnosis、prognosis 和 biomarker discovery，从而提升了决策准确性和模型解释力。最后，论文深入探讨了当前面临的挑战，并提出了未来研究方向，如改进数据整合方法和增强跨模态协同。",
      "categories": [
        "q-bio.QM",
        "cs.AI"
      ],
      "primary_category": "q-bio.QM",
      "comment": "15 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.19611v1",
      "published_date": "2024-06-28 02:35:05 UTC",
      "updated_date": "2024-06-28 02:35:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:52:48.483736"
    },
    {
      "arxiv_id": "2407.01456v1",
      "title": "Information-Theoretic Foundations for Neural Scaling Laws",
      "title_zh": "翻译失败",
      "authors": [
        "Hong Jun Jeon",
        "Benjamin Van Roy"
      ],
      "abstract": "Neural scaling laws aim to characterize how out-of-sample error behaves as a\nfunction of model and training dataset size. Such scaling laws guide allocation\nof a computational resources between model and data processing to minimize\nerror. However, existing theoretical support for neural scaling laws lacks\nrigor and clarity, entangling the roles of information and optimization. In\nthis work, we develop rigorous information-theoretic foundations for neural\nscaling laws. This allows us to characterize scaling laws for data generated by\na two-layer neural network of infinite width. We observe that the optimal\nrelation between data and model size is linear, up to logarithmic factors,\ncorroborating large-scale empirical investigations. Concise yet general results\nof the kind we establish may bring clarity to this topic and inform future\ninvestigations.",
      "tldr_zh": "本研究建立了神经缩放定律（neural scaling laws）的信息理论基础（information-theoretic foundations），旨在清晰分析模型大小和训练数据集大小如何影响泛化误差（out-of-sample error），并指导计算资源分配。该框架针对由无限宽度两层神经网络生成的数据，证明了数据和模型大小之间最优关系为线性（up to logarithmic factors），这验证了大型实证研究的结果。通过这些严谨的理论分析，论文为未来神经网络优化和资源分配提供了清晰指导。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "arXiv admin note: text overlap with arXiv:2212.01365",
      "pdf_url": "http://arxiv.org/pdf/2407.01456v1",
      "published_date": "2024-06-28 02:20:54 UTC",
      "updated_date": "2024-06-28 02:20:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:52:59.516592"
    },
    {
      "arxiv_id": "2407.01614v3",
      "title": "Enhancing Stability for Large Language Models Training in Constrained Bandwidth Networks",
      "title_zh": "增强带宽",
      "authors": [
        "Yun Dai",
        "Tejas Dharamsi",
        "Byron Hsu",
        "Tao Song",
        "Hamed Firooz"
      ],
      "abstract": "Training extremely large language models (LLMs) with billions of parameters\nis a computationally intensive task that pushes the limits of current data\nparallel training systems. While techniques like ZeRO++ have enabled efficient\ndistributed training of such giant models on inexpensive low-bandwidth\nclusters, they can suffer from convergence issues due to potential race\nconditions in the hierarchical partitioning (hpZ) scheme employed to reduce\ncross-machine communication. In this work, we first show how these race\nconditions cause instability when training models with billions of parameters.\nWe then propose a modification to the partitioning algorithm that addresses\nthese convergence challenges while maintaining competitive training efficiency.\nEmpirical evaluation on training the multi-billion parameters Falcon Models and\nLlama-2 models demonstrates the updated algorithm's ability to achieve reliable\nconvergence on these massive models, where stock ZeRO++ hpZ fails to converge.\nThe updated algorithm enables robust training of larger models with 98\\%\nthroughput and model training speed improvement without sacrificing the quality\nof convergence.",
      "tldr_zh": "这篇论文针对在带宽受限网络中训练大型语言模型(LLMs)时，ZeRO++ 技术因 hierarchical partitioning (hpZ) 方案中的 race conditions 导致的训练不稳定性问题，进行了深入分析。作者提出了一种改进的 partitioning 算法，以消除这些收敛挑战，同时维持高效的训练性能。实验结果显示，该算法在训练 Falcon Models 和 Llama-2 等多亿参数模型时，实现了可靠收敛，并提供了98%的吞吐量和训练速度提升，而不影响模型质量。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.01614v3",
      "published_date": "2024-06-28 01:46:10 UTC",
      "updated_date": "2024-10-06 01:18:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:53:12.791164"
    },
    {
      "arxiv_id": "2407.12022v3",
      "title": "ITERTL: An Iterative Framework for Fine-tuning LLMs for RTL Code Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Peiyang Wu",
        "Nan Guo",
        "Xiao Xiao",
        "Wenming Li",
        "Xiaochun Ye",
        "Dongrui Fan"
      ],
      "abstract": "Recently, large language models (LLMs) have demonstrated excellent\nperformance, inspiring researchers to explore their use in automating register\ntransfer level (RTL) code generation and improving hardware design efficiency.\nHowever, the existing approaches to fine-tune LLMs for RTL generation typically\nare conducted on fixed datasets, which do not fully stimulate the capability of\nLLMs and require large amounts of reference data, which are costly to acquire.\nTo mitigate these issues, we innovatively introduce an iterative training\nparadigm named ITERTL. During each iteration, samples are drawn from the model\ntrained in the previous cycle. Then these new samples are employed for training\nin current loop. Furthermore, we introduce a plug-and-play data filtering\nstrategy, thereby encouraging the model to generate high-quality,\nself-contained code. Our model outperforms GPT4 and state-of-the-art (SOTA)\nopen-source models, achieving remarkable 53.8% pass@1 rate on VerilogEval-human\nbenchmark. Under similar conditions of data quantity and quality, our approach\nsignificantly outperforms the baseline. Extensive experiments validate the\neffectiveness of the proposed method.",
      "tldr_zh": "该研究提出 ITERTL，一种创新的迭代训练框架，用于微调 LLMs 以生成 RTL 代码，旨在解决现有方法依赖固定数据集的问题，从而减少对大量参考数据的需求。框架的核心在于每个迭代中使用前一轮模型生成的样本进行训练，并引入一个即插即用数据过滤策略，以鼓励模型产出高质量、自包含的代码。在 VerilogEval-human 基准上，ITERTL 实现了 53.8% 的 pass@1 率，优于 GPT-4 和 SOTA 开源模型，并在类似数据量和质量条件下显著超越基线。广泛实验验证了该方法的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.12022v3",
      "published_date": "2024-06-28 01:44:57 UTC",
      "updated_date": "2025-04-23 06:56:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:53:24.951978"
    },
    {
      "arxiv_id": "2406.19596v1",
      "title": "Optimizing Cyber Defense in Dynamic Active Directories through Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Diksha Goel",
        "Kristen Moore",
        "Mingyu Guo",
        "Derui Wang",
        "Minjune Kim",
        "Seyit Camtepe"
      ],
      "abstract": "This paper addresses a significant gap in Autonomous Cyber Operations (ACO)\nliterature: the absence of effective edge-blocking ACO strategies in dynamic,\nreal-world networks. It specifically targets the cybersecurity vulnerabilities\nof organizational Active Directory (AD) systems. Unlike the existing literature\non edge-blocking defenses which considers AD systems as static entities, our\nstudy counters this by recognizing their dynamic nature and developing advanced\nedge-blocking defenses through a Stackelberg game model between attacker and\ndefender. We devise a Reinforcement Learning (RL)-based attack strategy and an\nRL-assisted Evolutionary Diversity Optimization-based defense strategy, where\nthe attacker and defender improve each other strategy via parallel gameplay. To\naddress the computational challenges of training attacker-defender strategies\non numerous dynamic AD graphs, we propose an RL Training Facilitator that\nprunes environments and neural networks to eliminate irrelevant elements,\nenabling efficient and scalable training for large graphs. We extensively train\nthe attacker strategy, as a sophisticated attacker model is essential for a\nrobust defense. Our empirical results successfully demonstrate that our\nproposed approach enhances defender's proficiency in hardening dynamic AD\ngraphs while ensuring scalability for large-scale AD.",
      "tldr_zh": "本研究针对动态Active Directory (AD)系统中的网络安全漏洞，提出了一种基于Reinforcement Learning (RL)的边阻塞防御策略，以填补Autonomous Cyber Operations (ACO)文献的空白。不同于现有文献将AD视为静态实体，该方法采用Stackelberg游戏模型，让RL-based攻击策略和RL-assisted Evolutionary Diversity Optimization-based防御策略通过并行游戏相互优化，并引入RL Training Facilitator来修剪环境和神经网络，实现高效、可扩展的训练。实验结果显示，该方法显著提升了防御者在强化动态AD图方面的能力，并在大规模AD系统中确保了良好的可扩展性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "The manuscript has been accepted as full paper at European Symposium\n  on Research in Computer Security (ESORICS) 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.19596v1",
      "published_date": "2024-06-28 01:37:46 UTC",
      "updated_date": "2024-06-28 01:37:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:53:35.407831"
    },
    {
      "arxiv_id": "2407.01613v1",
      "title": "Self-adaptive weights based on balanced residual decay rate for physics-informed neural networks and deep operator networks",
      "title_zh": "翻译失败",
      "authors": [
        "Wenqian Chen",
        "Amanda A. Howard",
        "Panos Stinis"
      ],
      "abstract": "Physics-informed deep learning has emerged as a promising alternative for\nsolving partial differential equations. However, for complex problems, training\nthese networks can still be challenging, often resulting in unsatisfactory\naccuracy and efficiency. In this work, we demonstrate that the failure of plain\nphysics-informed neural networks arises from the significant discrepancy in the\nconvergence speed of residuals at different training points, where the slowest\nconvergence speed dominates the overall solution convergence. Based on these\nobservations, we propose a point-wise adaptive weighting method that balances\nthe residual decay rate across different training points. The performance of\nour proposed adaptive weighting method is compared with current\nstate-of-the-art adaptive weighting methods on benchmark problems for both\nphysics-informed neural networks and physics-informed deep operator networks.\nThrough extensive numerical results we demonstrate that our proposed approach\nof balanced residual decay rates offers several advantages, including bounded\nweights, high prediction accuracy, fast convergence speed, low training\nuncertainty, low computational cost and ease of hyperparameter tuning.",
      "tldr_zh": "本文研究了physics-informed neural networks和deep operator networks在解决偏微分方程时的训练挑战，指出残差在不同训练点收敛速度不均是导致准确性和效率低下的主要原因。作者提出了一种基于平衡残差衰减率的自适应加权方法，能够动态平衡各训练点的收敛速度。实验结果显示，该方法在基准问题上优于现有最先进方法，提供更高的预测准确性、快速收敛、低训练不确定性和低计算成本，并易于超参数调整。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "13 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2407.01613v1",
      "published_date": "2024-06-28 00:53:48 UTC",
      "updated_date": "2024-06-28 00:53:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:53:48.191928"
    },
    {
      "arxiv_id": "2407.00125v1",
      "title": "A Survey on Failure Analysis and Fault Injection in AI Systems",
      "title_zh": "人工智能系统中的故障分析和故障注入的综述",
      "authors": [
        "Guangba Yu",
        "Gou Tan",
        "Haojia Huang",
        "Zhenyu Zhang",
        "Pengfei Chen",
        "Roberto Natella",
        "Zibin Zheng"
      ],
      "abstract": "The rapid advancement of Artificial Intelligence (AI) has led to its\nintegration into various areas, especially with Large Language Models (LLMs)\nsignificantly enhancing capabilities in Artificial Intelligence Generated\nContent (AIGC). However, the complexity of AI systems has also exposed their\nvulnerabilities, necessitating robust methods for failure analysis (FA) and\nfault injection (FI) to ensure resilience and reliability. Despite the\nimportance of these techniques, there lacks a comprehensive review of FA and FI\nmethodologies in AI systems. This study fills this gap by presenting a detailed\nsurvey of existing FA and FI approaches across six layers of AI systems. We\nsystematically analyze 160 papers and repositories to answer three research\nquestions including (1) what are the prevalent failures in AI systems, (2) what\ntypes of faults can current FI tools simulate, (3) what gaps exist between the\nsimulated faults and real-world failures. Our findings reveal a taxonomy of AI\nsystem failures, assess the capabilities of existing FI tools, and highlight\ndiscrepancies between real-world and simulated failures. Moreover, this survey\ncontributes to the field by providing a framework for fault diagnosis,\nevaluating the state-of-the-art in FI, and identifying areas for improvement in\nFI techniques to enhance the resilience of AI systems.",
      "tldr_zh": "这篇调查论文探讨了AI系统中的故障分析(FA)和故障注入(FI)，旨在解决AI系统复杂性带来的漏洞问题，如Large Language Models (LLMs)在生成内容中的潜在风险。通过分析160篇论文和仓库，论文回答了AI系统常见故障类型、FI工具模拟故障的能力，以及模拟故障与真实故障之间的差距。研究构建了AI系统故障的分类框架，评估了现有FI工具的状态，并指出了改进方向，以提升AI系统的韧性和可靠性。总体上，该工作为FA和FI方法提供了全面综述，推动了AI系统可靠性研究的进展。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.00125v1",
      "published_date": "2024-06-28 00:32:03 UTC",
      "updated_date": "2024-06-28 00:32:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:53:59.457104"
    },
    {
      "arxiv_id": "2407.17475v1",
      "title": "An Approach to Detect Abnormal Submissions for CodeWorkout Dataset",
      "title_zh": "针对 CodeWorkout 数据集的异常提交检测方法",
      "authors": [
        "Alex Hicks",
        "Yang Shi",
        "Arun-Balajiee Lekshmi-Narayanan",
        "Wei Yan",
        "Samiha Marwan"
      ],
      "abstract": "Students interactions while solving problems in learning environments (i.e.\nlog data) are often used to support students learning. For example, researchers\nuse log data to develop systems that can provide students with personalized\nproblem recommendations based on their knowledge level. However, anomalies in\nthe students log data, such as cheating to solve programming problems, could\nintroduce a hidden bias in the log data. As a result, these systems may provide\ninaccurate problem recommendations, and therefore, defeat their purpose.\nClassical cheating detection methods, such as MOSS, can be used to detect code\nplagiarism. However, these methods cannot detect other abnormal events such as\na student gaming a system with multiple attempts of similar solutions to a\nparticular programming problem. This paper presents a preliminary study to\nanalyze log data with anomalies. The goal of our work is to overcome the\nabnormal instances when modeling personalizable recommendations in programming\nlearning environments.",
      "tldr_zh": "该研究探讨了学生在编程学习环境中的日志数据（log data）中存在的异常提交问题，这些异常（如作弊或多次尝试类似解决方案）可能导致个性化问题推荐系统出现偏差，从而影响推荐准确性。传统方法如 MOSS 可以检测代码抄袭，但无法识别其他异常行为。论文通过初步分析 CodeWorkout 数据集中的日志数据，提出一种检测异常提交的方法，旨在克服这些问题以改进编程学习环境的个性化推荐模型。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.17475v1",
      "published_date": "2024-06-28 00:26:15 UTC",
      "updated_date": "2024-06-28 00:26:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:54:15.175299"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 91,
  "processed_papers_count": 91,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-19T01:54:38.291416"
}