[
  {
    "arxiv_id": "2407.18428v1",
    "title": "Weighted Risk Invariance: Domain Generalization under Invariant Feature Shift",
    "authors": [
      "Gina Wong",
      "Joshua Gleason",
      "Rama Chellappa",
      "Yoav Wald",
      "Anqi Liu"
    ],
    "abstract": "Learning models whose predictions are invariant under multiple environments\nis a promising approach for out-of-distribution generalization. Such models are\ntrained to extract features $X_{\\text{inv}}$ where the conditional distribution\n$Y \\mid X_{\\text{inv}}$ of the label given the extracted features does not\nchange across environments. Invariant models are also supposed to generalize to\nshifts in the marginal distribution $p(X_{\\text{inv}})$ of the extracted\nfeatures $X_{\\text{inv}}$, a type of shift we call an $\\textit{invariant\ncovariate shift}$. However, we show that proposed methods for learning\ninvariant models underperform under invariant covariate shift, either failing\nto learn invariant models$\\unicode{x2014}$even for data generated from simple\nand well-studied linear-Gaussian models$\\unicode{x2014}$or having poor\nfinite-sample performance. To alleviate these problems, we propose\n$\\textit{weighted risk invariance}$ (WRI). Our framework is based on imposing\ninvariance of the loss across environments subject to appropriate reweightings\nof the training examples. We show that WRI provably learns invariant models,\ni.e. discards spurious correlations, in linear-Gaussian settings. We propose a\npractical algorithm to implement WRI by learning the density\n$p(X_{\\text{inv}})$ and the model parameters simultaneously, and we demonstrate\nempirically that WRI outperforms previous invariant learning methods under\ninvariant covariate shift.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.18428v1",
    "published_date": "2024-07-25 23:27:10 UTC",
    "updated_date": "2024-07-25 23:27:10 UTC"
  },
  {
    "arxiv_id": "2407.21058v1",
    "title": "Understanding the Interplay of Scale, Data, and Bias in Language Models: A Case Study with BERT",
    "authors": [
      "Muhammad Ali",
      "Swetasudha Panda",
      "Qinlan Shen",
      "Michael Wick",
      "Ari Kobren"
    ],
    "abstract": "In the current landscape of language model research, larger models, larger\ndatasets and more compute seems to be the only way to advance towards\nintelligence. While there have been extensive studies of scaling laws and\nmodels' scaling behaviors, the effect of scale on a model's social biases and\nstereotyping tendencies has received less attention. In this study, we explore\nthe influence of model scale and pre-training data on its learnt social biases.\nWe focus on BERT -- an extremely popular language model -- and investigate\nbiases as they show up during language modeling (upstream), as well as during\nclassification applications after fine-tuning (downstream). Our experiments on\nfour architecture sizes of BERT demonstrate that pre-training data\nsubstantially influences how upstream biases evolve with model scale. With\nincreasing scale, models pre-trained on large internet scrapes like Common\nCrawl exhibit higher toxicity, whereas models pre-trained on moderated data\nsources like Wikipedia show greater gender stereotypes. However, downstream\nbiases generally decrease with increasing model scale, irrespective of the\npre-training data. Our results highlight the qualitative role of pre-training\ndata in the biased behavior of language models, an often overlooked aspect in\nthe study of scale. Through a detailed case study of BERT, we shed light on the\ncomplex interplay of data and model scale, and investigate how it translates to\nconcrete biases.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.21058v1",
    "published_date": "2024-07-25 23:09:33 UTC",
    "updated_date": "2024-07-25 23:09:33 UTC"
  },
  {
    "arxiv_id": "2407.18423v1",
    "title": "HDL-GPT: High-Quality HDL is All You Need",
    "authors": [
      "Bhuvnesh Kumar",
      "Saurav Nanda",
      "Ganapathy Parthasarathy",
      "Pawan Patil",
      "Austin Tsai",
      "Parivesh Choudhary"
    ],
    "abstract": "This paper presents Hardware Description Language Generative Pre-trained\nTransformers (HDL-GPT), a novel approach that leverages the vast repository of\nopen-source High Definition Language (HDL) codes to train superior quality\nlarge code models. The core premise of this paper is the hypothesis that\nhigh-quality HDL is all you need to create models with exceptional performance\nand broad zero-shot generalization abilities. The paper elucidates the methods\nemployed for the curation and augmentation of large corpora from open-source\nHDL code, transforming highly variable quality data into high-quality data\nthrough careful prompting and context maintenance. We demonstrate that the\ncareful selection, filtering, and augmentation of data across HDLs can yield\npowerful models that surpass current state-of-the-art models. We also explore\nthe impact of different fine-tuning methods on the quality of results. We\ndescribe experimental results across a range of fine-tuned SOTA LLMs,\nsubstantiating our claims. We demonstrate improvements of 50% to 200% over SOTA\nHDL models on current benchmarks in tasks ranging from HDL circuit\nexplanations, code generation, formal and simulation testbench creation,\ntriaging bugs, and fixing them. HDL-GPT opens new avenues for the development\nof advanced model training techniques for circuit design tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "DAC 2024 Invited Paper",
    "pdf_url": "http://arxiv.org/pdf/2407.18423v1",
    "published_date": "2024-07-25 22:48:08 UTC",
    "updated_date": "2024-07-25 22:48:08 UTC"
  },
  {
    "arxiv_id": "2407.18422v3",
    "title": "A Black Swan Hypothesis: The Role of Human Irrationality in AI Safety",
    "authors": [
      "Hyunin Lee",
      "Chanwoo Park",
      "David Abel",
      "Ming Jin"
    ],
    "abstract": "Black swan events are statistically rare occurrences that carry extremely\nhigh risks. A typical view of defining black swan events is heavily assumed to\noriginate from an unpredictable time-varying environments; however, the\ncommunity lacks a comprehensive definition of black swan events. To this end,\nthis paper challenges that the standard view is incomplete and claims that\nhigh-risk, statistically rare events can also occur in unchanging environments\ndue to human misperception of their value and likelihood, which we call as\nspatial black swan event. We first carefully categorize black swan events,\nfocusing on spatial black swan events, and mathematically formalize the\ndefinition of black swan events. We hope these definitions can pave the way for\nthe development of algorithms to prevent such events by rationally correcting\nhuman perception.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "The title was changed and acknowledgment was included",
    "pdf_url": "http://arxiv.org/pdf/2407.18422v3",
    "published_date": "2024-07-25 22:44:39 UTC",
    "updated_date": "2025-03-20 19:18:24 UTC"
  },
  {
    "arxiv_id": "2407.18416v3",
    "title": "PersonaGym: Evaluating Persona Agents and LLMs",
    "authors": [
      "Vinay Samuel",
      "Henry Peng Zou",
      "Yue Zhou",
      "Shreyas Chaudhari",
      "Ashwin Kalyan",
      "Tanmay Rajpurohit",
      "Ameet Deshpande",
      "Karthik Narasimhan",
      "Vishvak Murahari"
    ],
    "abstract": "Persona agents, which are LLM agents that act according to an assigned\npersona, have demonstrated impressive contextual response capabilities across\nvarious applications. These persona agents offer significant enhancements\nacross diverse sectors, such as education, healthcare, and entertainment, where\nmodel developers can align agent responses to different user requirements\nthereby broadening the scope of agent applications. However, evaluating persona\nagent performance is incredibly challenging due to the complexity of assessing\npersona adherence in free-form interactions across various environments that\nare relevant to each persona agent. We introduce PersonaGym, the first dynamic\nevaluation framework for assessing persona agents, and PersonaScore, the first\nautomated human-aligned metric grounded in decision theory for comprehensive\nlarge-scale evaluation of persona agents. Our evaluation of 6 open and\nclosed-source LLMs, using a benchmark encompassing 200 personas and 10,000\nquestions, reveals significant opportunities for advancement in persona agent\ncapabilities across state-of-the-art models. For example, Claude 3.5 Sonnet\nonly has a 2.97% relative improvement in PersonaScore than GPT 3.5 despite\nbeing a much more advanced model. Importantly, we find that increased model\nsize and complexity do not necessarily imply enhanced persona agent\ncapabilities thereby highlighting the pressing need for algorithmic and\narchitectural invention towards faithful and performant persona agents.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "21 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2407.18416v3",
    "published_date": "2024-07-25 22:24:45 UTC",
    "updated_date": "2024-12-18 14:25:08 UTC"
  },
  {
    "arxiv_id": "2407.18414v2",
    "title": "Adversarially Robust Decision Transformer",
    "authors": [
      "Xiaohang Tang",
      "Afonso Marques",
      "Parameswaran Kamalaruban",
      "Ilija Bogunovic"
    ],
    "abstract": "Decision Transformer (DT), as one of the representative Reinforcement\nLearning via Supervised Learning (RvS) methods, has achieved strong performance\nin offline learning tasks by leveraging the powerful Transformer architecture\nfor sequential decision-making. However, in adversarial environments, these\nmethods can be non-robust, since the return is dependent on the strategies of\nboth the decision-maker and adversary. Training a probabilistic model\nconditioned on observed return to predict action can fail to generalize, as the\ntrajectories that achieve a return in the dataset might have done so due to a\nsuboptimal behavior adversary. To address this, we propose a worst-case-aware\nRvS algorithm, the Adversarially Robust Decision Transformer (ARDT), which\nlearns and conditions the policy on in-sample minimax returns-to-go. ARDT\naligns the target return with the worst-case return learned through minimax\nexpectile regression, thereby enhancing robustness against powerful test-time\nadversaries. In experiments conducted on sequential games with full data\ncoverage, ARDT can generate a maximin (Nash Equilibrium) strategy, the solution\nwith the largest adversarial robustness. In large-scale sequential games and\ncontinuous adversarial RL environments with partial data coverage, ARDT\ndemonstrates significantly superior robustness to powerful test-time\nadversaries and attains higher worst-case returns compared to contemporary DT\nmethods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.18414v2",
    "published_date": "2024-07-25 22:12:47 UTC",
    "updated_date": "2024-11-01 17:47:03 UTC"
  },
  {
    "arxiv_id": "2407.18413v1",
    "title": "Simulation of Neural Responses to Classical Music Using Organoid Intelligence Methods",
    "authors": [
      "Daniel Szelogowski"
    ],
    "abstract": "Music is a complex auditory stimulus capable of eliciting significant changes\nin brain activity, influencing cognitive processes such as memory, attention,\nand emotional regulation. However, the underlying mechanisms of music-induced\ncognitive processes remain largely unknown. Organoid intelligence and deep\nlearning models show promise for simulating and analyzing these neural\nresponses to classical music, an area significantly unexplored in computational\nneuroscience. Hence, we present the PyOrganoid library, an innovative tool that\nfacilitates the simulation of organoid learning models, integrating\nsophisticated machine learning techniques with biologically inspired organoid\nsimulations. Our study features the development of the Pianoid model, a \"deep\norganoid learning\" model that utilizes a Bidirectional LSTM network to predict\nEEG responses based on audio features from classical music recordings. This\nmodel demonstrates the feasibility of using computational methods to replicate\ncomplex neural processes, providing valuable insights into music perception and\ncognition. Likewise, our findings emphasize the utility of synthetic models in\nneuroscience research and highlight the PyOrganoid library's potential as a\nversatile tool for advancing studies in neuroscience and artificial\nintelligence.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG",
      "cs.SD",
      "eess.AS",
      "I.2; I.6; J.3; J.4; J.5"
    ],
    "primary_category": "cs.NE",
    "comment": "10 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2407.18413v1",
    "published_date": "2024-07-25 22:11:30 UTC",
    "updated_date": "2024-07-25 22:11:30 UTC"
  },
  {
    "arxiv_id": "2407.18387v1",
    "title": "SCALE: Self-regulated Clustered federAted LEarning in a Homogeneous Environment",
    "authors": [
      "Sai Puppala",
      "Ismail Hossain",
      "Md Jahangir Alam",
      "Sajedul Talukder",
      "Zahidur Talukder",
      "Syed Bahauddin"
    ],
    "abstract": "Federated Learning (FL) has emerged as a transformative approach for enabling\ndistributed machine learning while preserving user privacy, yet it faces\nchallenges like communication inefficiencies and reliance on centralized\ninfrastructures, leading to increased latency and costs. This paper presents a\nnovel FL methodology that overcomes these limitations by eliminating the\ndependency on edge servers, employing a server-assisted Proximity Evaluation\nfor dynamic cluster formation based on data similarity, performance indices,\nand geographical proximity. Our integrated approach enhances operational\nefficiency and scalability through a Hybrid Decentralized Aggregation Protocol,\nwhich merges local model training with peer-to-peer weight exchange and a\ncentralized final aggregation managed by a dynamically elected driver node,\nsignificantly curtailing global communication overhead. Additionally, the\nmethodology includes Decentralized Driver Selection, Check-pointing to reduce\nnetwork traffic, and a Health Status Verification Mechanism for system\nrobustness. Validated using the breast cancer dataset, our architecture not\nonly demonstrates a nearly tenfold reduction in communication overhead but also\nshows remarkable improvements in reducing training latency and energy\nconsumption while maintaining high learning performance, offering a scalable,\nefficient, and privacy-preserving solution for the future of federated learning\necosystems.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.ET",
      "cs.LG",
      "cs.PF"
    ],
    "primary_category": "cs.DC",
    "comment": "This research article got accepted in COMPSAC conference and going to\n  be published to IEEE",
    "pdf_url": "http://arxiv.org/pdf/2407.18387v1",
    "published_date": "2024-07-25 20:42:16 UTC",
    "updated_date": "2024-07-25 20:42:16 UTC"
  },
  {
    "arxiv_id": "2407.18367v1",
    "title": "Robust Claim Verification Through Fact Detection",
    "authors": [
      "Nazanin Jafari",
      "James Allan"
    ],
    "abstract": "Claim verification can be a challenging task. In this paper, we present a\nmethod to enhance the robustness and reasoning capabilities of automated claim\nverification through the extraction of short facts from evidence. Our novel\napproach, FactDetect, leverages Large Language Models (LLMs) to generate\nconcise factual statements from evidence and label these facts based on their\nsemantic relevance to the claim and evidence. The generated facts are then\ncombined with the claim and evidence. To train a lightweight supervised model,\nwe incorporate a fact-detection task into the claim verification process as a\nmultitasking approach to improve both performance and explainability. We also\nshow that augmenting FactDetect in the claim verification prompt enhances\nperformance in zero-shot claim verification using LLMs. Our method demonstrates\ncompetitive results in the supervised claim verification model by 15% on the F1\nscore when evaluated for challenging scientific claim verification datasets. We\nalso demonstrate that FactDetect can be augmented with claim and evidence for\nzero-shot prompting (AugFactDetect) in LLMs for verdict prediction. We show\nthat AugFactDetect outperforms the baseline with statistical significance on\nthree challenging scientific claim verification datasets with an average of\n17.3% performance gain compared to the best performing baselines.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.18367v1",
    "published_date": "2024-07-25 20:03:43 UTC",
    "updated_date": "2024-07-25 20:03:43 UTC"
  },
  {
    "arxiv_id": "2407.18365v1",
    "title": "FADAS: Towards Federated Adaptive Asynchronous Optimization",
    "authors": [
      "Yujia Wang",
      "Shiqiang Wang",
      "Songtao Lu",
      "Jinghui Chen"
    ],
    "abstract": "Federated learning (FL) has emerged as a widely adopted training paradigm for\nprivacy-preserving machine learning. While the SGD-based FL algorithms have\ndemonstrated considerable success in the past, there is a growing trend towards\nadopting adaptive federated optimization methods, particularly for training\nlarge-scale models. However, the conventional synchronous aggregation design\nposes a significant challenge to the practical deployment of those adaptive\nfederated optimization methods, particularly in the presence of straggler\nclients. To fill this research gap, this paper introduces federated adaptive\nasynchronous optimization, named FADAS, a novel method that incorporates\nasynchronous updates into adaptive federated optimization with provable\nguarantees. To further enhance the efficiency and resilience of our proposed\nmethod in scenarios with significant asynchronous delays, we also extend FADAS\nwith a delay-adaptive learning adjustment strategy. We rigorously establish the\nconvergence rate of the proposed algorithms and empirical results demonstrate\nthe superior performance of FADAS over other asynchronous FL baselines.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC",
      "math.OC"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.18365v1",
    "published_date": "2024-07-25 20:02:57 UTC",
    "updated_date": "2024-07-25 20:02:57 UTC"
  },
  {
    "arxiv_id": "2407.18358v1",
    "title": "Generative AI like ChatGPT in Blockchain Federated Learning: use cases, opportunities and future",
    "authors": [
      "Sai Puppala",
      "Ismail Hossain",
      "Md Jahangir Alam",
      "Sajedul Talukder",
      "Jannatul Ferdaus",
      "Mahedi Hasan",
      "Sameera Pisupati",
      "Shanmukh Mathukumilli"
    ],
    "abstract": "Federated learning has become a significant approach for training machine\nlearning models using decentralized data without necessitating the sharing of\nthis data. Recently, the incorporation of generative artificial intelligence\n(AI) methods has provided new possibilities for improving privacy, augmenting\ndata, and customizing models. This research explores potential integrations of\ngenerative AI in federated learning, revealing various opportunities to enhance\nprivacy, data efficiency, and model performance. It particularly emphasizes the\nimportance of generative models like generative adversarial networks (GANs) and\nvariational autoencoders (VAEs) in creating synthetic data that replicates the\ndistribution of real data. Generating synthetic data helps federated learning\naddress challenges related to limited data availability and supports robust\nmodel development. Additionally, we examine various applications of generative\nAI in federated learning that enable more personalized solutions.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "We are going to submit this research article into a conference which\n  is best fit for this topic",
    "pdf_url": "http://arxiv.org/pdf/2407.18358v1",
    "published_date": "2024-07-25 19:43:49 UTC",
    "updated_date": "2024-07-25 19:43:49 UTC"
  },
  {
    "arxiv_id": "2407.18343v2",
    "title": "Introducing δ-XAI: a novel sensitivity-based method for local AI explanations",
    "authors": [
      "Alessandro De Carlo",
      "Enea Parimbelli",
      "Nicola Melillo",
      "Giovanna Nicora"
    ],
    "abstract": "Explainable Artificial Intelligence (XAI) is central to the debate on\nintegrating Artificial Intelligence (AI) and Machine Learning (ML) algorithms\ninto clinical practice. High-performing AI/ML models, such as ensemble learners\nand deep neural networks, often lack interpretability, hampering clinicians'\ntrust in their predictions. To address this, XAI techniques are being developed\nto describe AI/ML predictions in human-understandable terms. One promising\ndirection is the adaptation of sensitivity analysis (SA) and global sensitivity\nanalysis (GSA), which inherently rank model inputs by their impact on\npredictions. Here, we introduce a novel delta-XAI method that provides local\nexplanations of ML model predictions by extending the delta index, a GSA\nmetric. The delta-XAI index assesses the impact of each feature's value on the\npredicted output for individual instances in both regression and classification\nproblems. We formalize the delta-XAI index and provide code for its\nimplementation. The delta-XAI method was evaluated on simulated scenarios using\nlinear regression models, with Shapley values serving as a benchmark. Results\nshowed that the delta-XAI index is generally consistent with Shapley values,\nwith notable discrepancies in models with highly impactful or extreme feature\nvalues. The delta-XAI index demonstrated higher sensitivity in detecting\ndominant features and handling extreme feature values. Qualitatively, the\ndelta-XAI provides intuitive explanations by leveraging probability density\nfunctions, making feature rankings clearer and more explainable for\npractitioners. Overall, the delta-XAI method appears promising for robustly\nobtaining local explanations of ML model predictions. Further investigations in\nreal-world clinical settings will be conducted to evaluate its impact on\nAI-assisted clinical workflows.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.18343v2",
    "published_date": "2024-07-25 19:07:49 UTC",
    "updated_date": "2024-07-29 13:25:41 UTC"
  },
  {
    "arxiv_id": "2408.05354v2",
    "title": "Trusting Your AI Agent Emotionally and Cognitively: Development and Validation of a Semantic Differential Scale for AI Trust",
    "authors": [
      "Ruoxi Shang",
      "Gary Hsieh",
      "Chirag Shah"
    ],
    "abstract": "Trust is not just a cognitive issue but also an emotional one, yet the\nresearch in human-AI interactions has primarily focused on the cognitive route\nof trust development. Recent work has highlighted the importance of studying\naffective trust towards AI, especially in the context of emerging human-like\nLLMs-powered conversational agents. However, there is a lack of validated and\ngeneralizable measures for the two-dimensional construct of trust in AI agents.\nTo address this gap, we developed and validated a set of 27-item semantic\ndifferential scales for affective and cognitive trust through a scenario-based\nsurvey study. We then further validated and applied the scale through an\nexperiment study. Our empirical findings showed how the emotional and cognitive\naspects of trust interact with each other and collectively shape a person's\noverall trust in AI agents. Our study methodology and findings also provide\ninsights into the capability of the state-of-art LLMs to foster trust through\ndifferent routes.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.05354v2",
    "published_date": "2024-07-25 18:55:33 UTC",
    "updated_date": "2024-11-07 20:34:20 UTC"
  },
  {
    "arxiv_id": "2407.18335v1",
    "title": "Combining Cognitive and Generative AI for Self-explanation in Interactive AI Agents",
    "authors": [
      "Shalini Sushri",
      "Rahul Dass",
      "Rhea Basappa",
      "Hong Lu",
      "Ashok Goel"
    ],
    "abstract": "The Virtual Experimental Research Assistant (VERA) is an inquiry-based\nlearning environment that empowers a learner to build conceptual models of\ncomplex ecological systems and experiment with agent-based simulations of the\nmodels. This study investigates the convergence of cognitive AI and generative\nAI for self-explanation in interactive AI agents such as VERA. From a cognitive\nAI viewpoint, we endow VERA with a functional model of its own design,\nknowledge, and reasoning represented in the Task--Method--Knowledge (TMK)\nlanguage. From the perspective of generative AI, we use ChatGPT, LangChain, and\nChain-of-Thought to answer user questions based on the VERA TMK model. Thus, we\ncombine cognitive and generative AI to generate explanations about how VERA\nworks and produces its answers. The preliminary evaluation of the generation of\nexplanations in VERA on a bank of 66 questions derived from earlier work\nappears promising.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "10 pages, 2 figures, 2 tables, 1 appendix, HEXED Workshop @EDM July\n  2024",
    "pdf_url": "http://arxiv.org/pdf/2407.18335v1",
    "published_date": "2024-07-25 18:46:11 UTC",
    "updated_date": "2024-07-25 18:46:11 UTC"
  },
  {
    "arxiv_id": "2408.05361v1",
    "title": "MindGPT: Advancing Human-AI Interaction with Non-Invasive fNIRS-Based Imagined Speech Decoding",
    "authors": [
      "Suyi Zhang",
      "Ekram Alam",
      "Jack Baber",
      "Francesca Bianco",
      "Edward Turner",
      "Maysam Chamanzar",
      "Hamid Dehghani"
    ],
    "abstract": "In the coming decade, artificial intelligence systems are set to\nrevolutionise every industry and facet of human life. Building communication\nsystems that enable seamless and symbiotic communication between humans and AI\nagents is increasingly important. This research advances the field of human-AI\ninteraction by developing an innovative approach to decode imagined speech\nusing non-invasive high-density functional near-infrared spectroscopy (fNIRS).\nNotably, this study introduces MindGPT, the first thought-to-LLM (large\nlanguage model) system in the world.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.05361v1",
    "published_date": "2024-07-25 18:18:52 UTC",
    "updated_date": "2024-07-25 18:18:52 UTC"
  },
  {
    "arxiv_id": "2407.18316v1",
    "title": "Affectively Framework: Towards Human-like Affect-Based Agents",
    "authors": [
      "Matthew Barthet",
      "Roberto Gallotta",
      "Ahmed Khalifa",
      "Antonios Liapis",
      "Georgios N. Yannakakis"
    ],
    "abstract": "Game environments offer a unique opportunity for training virtual agents due\nto their interactive nature, which provides diverse play traces and affect\nlabels. Despite their potential, no reinforcement learning framework\nincorporates human affect models as part of their observation space or reward\nmechanism. To address this, we present the \\emph{Affectively Framework}, a set\nof Open-AI Gym environments that integrate affect as part of the observation\nspace. This paper introduces the framework and its three game environments and\nprovides baseline experiments to validate its effectiveness and potential.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "5 pages, 2 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2407.18316v1",
    "published_date": "2024-07-25 18:18:10 UTC",
    "updated_date": "2024-07-25 18:18:10 UTC"
  },
  {
    "arxiv_id": "2407.18310v2",
    "title": "Revolutionizing Undergraduate Learning: CourseGPT and Its Generative AI Advancements",
    "authors": [
      "Ahmad M. Nazar",
      "Mohamed Y. Selim",
      "Ashraf Gaffar",
      "Shakil Ahmed"
    ],
    "abstract": "Integrating Generative AI (GenAI) into educational contexts presents a\ntransformative potential for enhancing learning experiences. This paper\nintroduces CourseGPT, a generative AI tool designed to support instructors and\nenhance the educational experiences of undergraduate students. Built on\nopen-source Large Language Models (LLMs) from Mistral AI, CourseGPT offers\ncontinuous instructor support and regular updates to course materials,\nenriching the learning environment. By utilizing course-specific content, such\nas slide decks and supplementary readings and references, CourseGPT provides\nprecise, dynamically generated responses to student inquiries. Unlike generic\nAI models, CourseGPT allows instructors to manage and control the responses,\nthus extending the course scope without overwhelming details. The paper\ndemonstrates the application of CourseGPT using the CPR E 431 - Basics of\nInformation System Security course as a pilot. This course, with its large\nenrollments and diverse curriculum, serves as an ideal testbed for CourseGPT.\nThe tool aims to enhance the learning experience, accelerate feedback\nprocesses, and streamline administrative tasks. The study evaluates CourseGPT's\nimpact on student outcomes, focusing on correctness scores, context recall, and\nfaithfulness of responses. Results indicate that the Mixtral-8x7b model, with a\nhigher parameter count, outperforms smaller models, achieving an 88.0%\ncorrectness score and a 66.6% faithfulness score. Additionally, feedback from\nformer students and teaching assistants on CourseGPT's accuracy, helpfulness,\nand overall performance was collected. The outcomes revealed that a significant\nmajority found CourseGPT to be highly accurate and beneficial in addressing\ntheir queries, with many praising its ability to provide timely and relevant\ninformation.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "8 pages",
    "pdf_url": "http://arxiv.org/pdf/2407.18310v2",
    "published_date": "2024-07-25 18:02:16 UTC",
    "updated_date": "2024-12-24 02:40:25 UTC"
  },
  {
    "arxiv_id": "2407.18242v3",
    "title": "LoRA-Pro: Are Low-Rank Adapters Properly Optimized?",
    "authors": [
      "Zhengbo Wang",
      "Jian Liang",
      "Ran He",
      "Zilei Wang",
      "Tieniu Tan"
    ],
    "abstract": "Low-rank adaptation, also known as LoRA, has emerged as a prominent method\nfor parameter-efficient fine-tuning of foundation models. Despite its\ncomputational efficiency, LoRA still yields inferior performance compared to\nfull fine-tuning. In this paper, we first uncover a fundamental connection\nbetween the optimization processes of LoRA and full fine-tuning: using LoRA for\noptimization is mathematically equivalent to full fine-tuning using a low-rank\ngradient for parameter updates. And this low-rank gradient can be expressed in\nterms of the gradients of the two low-rank matrices in LoRA. Leveraging this\ninsight, we introduce LoRA-Pro, a method that enhances LoRA's performance by\nstrategically adjusting the gradients of these low-rank matrices. This\nadjustment allows the low-rank gradient to more accurately approximate the full\nfine-tuning gradient, thereby narrowing the performance gap between LoRA and\nfull fine-tuning. Furthermore, we theoretically derive the optimal solutions\nfor adjusting the gradients of the low-rank matrices, applying them during\nfine-tuning in LoRA-Pro. We conduct extensive experiments across natural\nlanguage understanding, dialogue generation, mathematical reasoning, code\ngeneration, and image classification tasks, demonstrating that LoRA-Pro\nsubstantially improves LoRA's performance, effectively narrowing the gap with\nfull fine-tuning. Code is publicly available at\nhttps://github.com/mrflogs/LoRA-Pro.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Camera-Ready Version for ICLR 2025; technical corrections to previous\n  version",
    "pdf_url": "http://arxiv.org/pdf/2407.18242v3",
    "published_date": "2024-07-25 17:57:12 UTC",
    "updated_date": "2025-03-22 09:29:15 UTC"
  },
  {
    "arxiv_id": "2407.18219v2",
    "title": "Recursive Introspection: Teaching Language Model Agents How to Self-Improve",
    "authors": [
      "Yuxiao Qu",
      "Tianjun Zhang",
      "Naman Garg",
      "Aviral Kumar"
    ],
    "abstract": "A central piece in enabling intelligent agentic behavior in foundation models\nis to make them capable of introspecting upon their behavior, reasoning, and\ncorrecting their mistakes as more computation or interaction is available. Even\nthe strongest proprietary large language models (LLMs) do not quite exhibit the\nability of continually improving their responses sequentially, even in\nscenarios where they are explicitly told that they are making a mistake. In\nthis paper, we develop RISE: Recursive IntroSpEction, an approach for\nfine-tuning LLMs to introduce this capability, despite prior work hypothesizing\nthat this capability may not be possible to attain. Our approach prescribes an\niterative fine-tuning procedure, which attempts to teach the model how to alter\nits response after having executed previously unsuccessful attempts to solve a\nhard test-time problem, with optionally additional environment feedback. RISE\nposes fine-tuning for a single-turn prompt as solving a multi-turn Markov\ndecision process (MDP), where the initial state is the prompt. Inspired by\nprinciples in online imitation learning and reinforcement learning, we propose\nstrategies for multi-turn data collection and training so as to imbue an LLM\nwith the capability to recursively detect and correct its previous mistakes in\nsubsequent iterations. Our experiments show that RISE enables Llama2, Llama3,\nand Mistral models to improve themselves with more turns on math reasoning\ntasks, outperforming several single-turn strategies given an equal amount of\ninference-time computation. We also find that RISE scales well, often attaining\nlarger benefits with more capable models. Our analysis shows that RISE makes\nmeaningful improvements to responses to arrive at the correct solution for\nchallenging prompts, without disrupting one-turn abilities as a result of\nexpressing more complex distributions.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.18219v2",
    "published_date": "2024-07-25 17:35:59 UTC",
    "updated_date": "2024-07-26 17:50:27 UTC"
  },
  {
    "arxiv_id": "2407.18213v4",
    "title": "Scaling Trends in Language Model Robustness",
    "authors": [
      "Nikolaus Howe",
      "Ian McKenzie",
      "Oskar Hollinsworth",
      "Michał Zajac",
      "Tom Tseng",
      "Aaron Tucker",
      "Pierre-Luc Bacon",
      "Adam Gleave"
    ],
    "abstract": "Language models exhibit scaling laws, whereby increasing model and dataset\nsize predictably decrease negative log likelihood, unlocking a dazzling array\nof capabilities. At the same time, even the most capable systems are currently\nvulnerable to adversarial inputs such as jailbreaks and prompt injections,\ndespite concerted efforts to make them robust. As compute becomes more\naccessible to both attackers and defenders, which side will benefit more from\nscale? We attempt to answer this question with a detailed study of robustness\non language models spanning three orders of magnitude in parameter count. From\nthe defender's perspective, we find that in the absence of other interventions,\nincreasing model size alone does not consistently improve robustness. In\nadversarial training, we find that larger models are more sample-efficient and\nless compute-efficient than smaller models, and often better generalize their\ndefense to new threat models. From the attacker's perspective, we find that\nincreasing attack compute smoothly and reliably increases attack success rate\nagainst both finetuned and adversarially trained models. Finally, we show that\nacross model sizes studied, doubling compute on adversarial training only\nforces an attacker to less than double attack compute to maintain the same\nattack success rate. However, adversarial training becomes more and more\neffective on larger models, suggesting that defenders could eventually have the\nadvantage with increasing model size. These results underscore the value of\nadopting a scaling lens when discussing robustness of frontier models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CR",
      "I.2.7"
    ],
    "primary_category": "cs.LG",
    "comment": "58 pages; updated to include new results and analysis",
    "pdf_url": "http://arxiv.org/pdf/2407.18213v4",
    "published_date": "2024-07-25 17:26:41 UTC",
    "updated_date": "2025-02-19 22:32:47 UTC"
  },
  {
    "arxiv_id": "2407.18202v1",
    "title": "Differentiable Quantum Architecture Search in Asynchronous Quantum Reinforcement Learning",
    "authors": [
      "Samuel Yen-Chi Chen"
    ],
    "abstract": "The emergence of quantum reinforcement learning (QRL) is propelled by\nadvancements in quantum computing (QC) and machine learning (ML), particularly\nthrough quantum neural networks (QNN) built on variational quantum circuits\n(VQC). These advancements have proven successful in addressing sequential\ndecision-making tasks. However, constructing effective QRL models demands\nsignificant expertise due to challenges in designing quantum circuit\narchitectures, including data encoding and parameterized circuits, which\nprofoundly influence model performance. In this paper, we propose addressing\nthis challenge with differentiable quantum architecture search (DiffQAS),\nenabling trainable circuit parameters and structure weights using\ngradient-based optimization. Furthermore, we enhance training efficiency\nthrough asynchronous reinforcement learning (RL) methods facilitating parallel\ntraining. Through numerical simulations, we demonstrate that our proposed\nDiffQAS-QRL approach achieves performance comparable to manually-crafted\ncircuit architectures across considered environments, showcasing stability\nacross diverse scenarios. This methodology offers a pathway for designing QRL\nmodels without extensive quantum knowledge, ensuring robust performance and\nfostering broader application of QRL.",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.DC",
      "cs.LG",
      "cs.NE"
    ],
    "primary_category": "quant-ph",
    "comment": "Accepted by IEEE International Conference on Quantum Computing and\n  Engineering - QCE 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.18202v1",
    "published_date": "2024-07-25 17:11:00 UTC",
    "updated_date": "2024-07-25 17:11:00 UTC"
  },
  {
    "arxiv_id": "2407.18181v1",
    "title": "Gene Regulatory Network Inference from Pre-trained Single-Cell Transcriptomics Transformer with Joint Graph Learning",
    "authors": [
      "Sindhura Kommu",
      "Yizhi Wang",
      "Yue Wang",
      "Xuan Wang"
    ],
    "abstract": "Inferring gene regulatory networks (GRNs) from single-cell RNA sequencing\n(scRNA-seq) data is a complex challenge that requires capturing the intricate\nrelationships between genes and their regulatory interactions. In this study,\nwe tackle this challenge by leveraging the single-cell BERT-based pre-trained\ntransformer model (scBERT), trained on extensive unlabeled scRNA-seq data, to\naugment structured biological knowledge from existing GRNs. We introduce a\nnovel joint graph learning approach that combines the rich contextual\nrepresentations learned by pre-trained single-cell language models with the\nstructured knowledge encoded in GRNs using graph neural networks (GNNs). By\nintegrating these two modalities, our approach effectively reasons over boththe\ngene expression level constraints provided by the scRNA-seq data and the\nstructured biological knowledge inherent in GRNs. We evaluate our method on\nhuman cell benchmark datasets from the BEELINE study with cell type-specific\nground truth networks. The results demonstrate superior performance over\ncurrent state-of-the-art baselines, offering a deeper understanding of cellular\nregulatory mechanisms.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted into the ICML 2024 AI for Science workshop",
    "pdf_url": "http://arxiv.org/pdf/2407.18181v1",
    "published_date": "2024-07-25 16:42:08 UTC",
    "updated_date": "2024-07-25 16:42:08 UTC"
  },
  {
    "arxiv_id": "2408.05362v1",
    "title": "MindSpeech: Continuous Imagined Speech Decoding using High-Density fNIRS and Prompt Tuning for Advanced Human-AI Interaction",
    "authors": [
      "Suyi Zhang",
      "Ekram Alam",
      "Jack Baber",
      "Francesca Bianco",
      "Edward Turner",
      "Maysam Chamanzar",
      "Hamid Dehghani"
    ],
    "abstract": "In the coming decade, artificial intelligence systems will continue to\nimprove and revolutionise every industry and facet of human life. Designing\neffective, seamless and symbiotic communication paradigms between humans and AI\nagents is increasingly important. This paper reports a novel method for\nhuman-AI interaction by developing a direct brain-AI interface. We discuss a\nnovel AI model, called MindSpeech, which enables open-vocabulary, continuous\ndecoding for imagined speech. This study focuses on enhancing human-AI\ncommunication by utilising high-density functional near-infrared spectroscopy\n(fNIRS) data to develop an AI model capable of decoding imagined speech\nnon-invasively. We discuss a new word cloud paradigm for data collection,\nimproving the quality and variety of imagined sentences generated by\nparticipants and covering a broad semantic space. Utilising a prompt\ntuning-based approach, we employed the Llama2 large language model (LLM) for\ntext generation guided by brain signals. Our results show significant\nimprovements in key metrics, such as BLEU-1 and BERT P scores, for three out of\nfour participants, demonstrating the method's effectiveness. Additionally, we\ndemonstrate that combining data from multiple participants enhances the decoder\nperformance, with statistically significant improvements in BERT scores for two\nparticipants. Furthermore, we demonstrated significantly above-chance decoding\naccuracy for imagined speech versus resting conditions and the identified\nactivated brain regions during imagined speech tasks in our study are\nconsistent with the previous studies on brain regions involved in speech\nencoding. This study underscores the feasibility of continuous imagined speech\ndecoding. By integrating high-density fNIRS with advanced AI techniques, we\nhighlight the potential for non-invasive, accurate communication systems with\nAI in the near future.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.05362v1",
    "published_date": "2024-07-25 16:39:21 UTC",
    "updated_date": "2024-07-25 16:39:21 UTC"
  },
  {
    "arxiv_id": "2407.18178v1",
    "title": "PianoMime: Learning a Generalist, Dexterous Piano Player from Internet Demonstrations",
    "authors": [
      "Cheng Qian",
      "Julen Urain",
      "Kevin Zakka",
      "Jan Peters"
    ],
    "abstract": "In this work, we introduce PianoMime, a framework for training a\npiano-playing agent using internet demonstrations. The internet is a promising\nsource of large-scale demonstrations for training our robot agents. In\nparticular, for the case of piano-playing, Youtube is full of videos of\nprofessional pianists playing a wide myriad of songs. In our work, we leverage\nthese demonstrations to learn a generalist piano-playing agent capable of\nplaying any arbitrary song. Our framework is divided into three parts: a data\npreparation phase to extract the informative features from the Youtube videos,\na policy learning phase to train song-specific expert policies from the\ndemonstrations and a policy distillation phase to distil the policies into a\nsingle generalist agent. We explore different policy designs to represent the\nagent and evaluate the influence of the amount of training data on the\ngeneralization capability of the agent to novel songs not available in the\ndataset. We show that we are able to learn a policy with up to 56\\% F1 score on\nunseen songs.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.18178v1",
    "published_date": "2024-07-25 16:37:07 UTC",
    "updated_date": "2024-07-25 16:37:07 UTC"
  },
  {
    "arxiv_id": "2407.18175v1",
    "title": "Quasar-ViT: Hardware-Oriented Quantization-Aware Architecture Search for Vision Transformers",
    "authors": [
      "Zhengang Li",
      "Alec Lu",
      "Yanyue Xie",
      "Zhenglun Kong",
      "Mengshu Sun",
      "Hao Tang",
      "Zhong Jia Xue",
      "Peiyan Dong",
      "Caiwen Ding",
      "Yanzhi Wang",
      "Xue Lin",
      "Zhenman Fang"
    ],
    "abstract": "Vision transformers (ViTs) have demonstrated their superior accuracy for\ncomputer vision tasks compared to convolutional neural networks (CNNs).\nHowever, ViT models are often computation-intensive for efficient deployment on\nresource-limited edge devices. This work proposes Quasar-ViT, a\nhardware-oriented quantization-aware architecture search framework for ViTs, to\ndesign efficient ViT models for hardware implementation while preserving the\naccuracy. First, Quasar-ViT trains a supernet using our row-wise flexible\nmixed-precision quantization scheme, mixed-precision weight entanglement, and\nsupernet layer scaling techniques. Then, it applies an efficient\nhardware-oriented search algorithm, integrated with hardware latency and\nresource modeling, to determine a series of optimal subnets from supernet under\ndifferent inference latency targets. Finally, we propose a series of\nmodel-adaptive designs on the FPGA platform to support the architecture search\nand mitigate the gap between the theoretical computation reduction and the\npractical inference speedup. Our searched models achieve 101.5, 159.6, and\n251.6 frames-per-second (FPS) inference speed on the AMD/Xilinx ZCU102 FPGA\nwith 80.4%, 78.6%, and 74.9% top-1 accuracy, respectively, for the ImageNet\ndataset, consistently outperforming prior works.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by ICS 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.18175v1",
    "published_date": "2024-07-25 16:35:46 UTC",
    "updated_date": "2024-07-25 16:35:46 UTC"
  },
  {
    "arxiv_id": "2408.05369v1",
    "title": "A Cost-Effective Eye-Tracker for Early Detection of Mild Cognitive Impairment",
    "authors": [
      "Danilo Greco",
      "Francesco Masulli",
      "Stefano Rovetta",
      "Alberto Cabri",
      "Davide Daffonchio"
    ],
    "abstract": "This paper presents a low-cost eye-tracker aimed at carrying out tests based\non a Visual Paired Comparison protocol for the early detection of Mild\nCognitive Impairment. The proposed eye-tracking system is based on machine\nlearning algorithms, a standard webcam, and two personal computers that\nconstitute, respectively, the \"Measurement Sub-System\" performing the test on\nthe patients and the \"Test Management Sub-System\" used by medical staff for\nconfiguring the test protocol, recording the patient data, monitoring the test\nand storing the test results. The system also integrates an stress estimator\nbased on the measurement of heart rate variability obtained with\nphotoplethysmography.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "68T07, 68T10, 68T45",
      "I.2; I.4; I.5"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.05369v1",
    "published_date": "2024-07-25 16:00:02 UTC",
    "updated_date": "2024-07-25 16:00:02 UTC"
  },
  {
    "arxiv_id": "2407.18145v2",
    "title": "Taxonomy-Aware Continual Semantic Segmentation in Hyperbolic Spaces for Open-World Perception",
    "authors": [
      "Julia Hindel",
      "Daniele Cattaneo",
      "Abhinav Valada"
    ],
    "abstract": "Semantic segmentation models are typically trained on a fixed set of classes,\nlimiting their applicability in open-world scenarios. Class-incremental\nsemantic segmentation aims to update models with emerging new classes while\npreventing catastrophic forgetting of previously learned ones. However,\nexisting methods impose strict rigidity on old classes, reducing their\neffectiveness in learning new incremental classes. In this work, we propose\nTaxonomy-Oriented Poincar\\'e-regularized Incremental-Class Segmentation\n(TOPICS) that learns feature embeddings in hyperbolic space following explicit\ntaxonomy-tree structures. This supervision provides plasticity for old classes,\nupdating ancestors based on new classes while integrating new classes at\nfitting positions. Additionally, we maintain implicit class relational\nconstraints on the geometric basis of the Poincar\\'e ball. This ensures that\nthe latent space can continuously adapt to new constraints while maintaining a\nrobust structure to combat catastrophic forgetting. We also establish eight\nrealistic incremental learning protocols for autonomous driving scenarios,\nwhere novel classes can originate from known classes or the background.\nExtensive evaluations of TOPICS on the Cityscapes and Mapillary Vistas 2.0\nbenchmarks demonstrate that it achieves state-of-the-art performance. We make\nthe code and trained models publicly available at\nhttp://topics.cs.uni-freiburg.de.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.18145v2",
    "published_date": "2024-07-25 15:49:26 UTC",
    "updated_date": "2024-11-04 17:31:40 UTC"
  },
  {
    "arxiv_id": "2407.18143v1",
    "title": "Maximum Entropy On-Policy Actor-Critic via Entropy Advantage Estimation",
    "authors": [
      "Jean Seong Bjorn Choe",
      "Jong-Kook Kim"
    ],
    "abstract": "Entropy Regularisation is a widely adopted technique that enhances policy\noptimisation performance and stability. A notable form of entropy\nregularisation is augmenting the objective with an entropy term, thereby\nsimultaneously optimising the expected return and the entropy. This framework,\nknown as maximum entropy reinforcement learning (MaxEnt RL), has shown\ntheoretical and empirical successes. However, its practical application in\nstraightforward on-policy actor-critic settings remains surprisingly\nunderexplored. We hypothesise that this is due to the difficulty of managing\nthe entropy reward in practice. This paper proposes a simple method of\nseparating the entropy objective from the MaxEnt RL objective, which\nfacilitates the implementation of MaxEnt RL in on-policy settings. Our\nempirical evaluations demonstrate that extending Proximal Policy Optimisation\n(PPO) and Trust Region Policy Optimisation (TRPO) within the MaxEnt framework\nimproves policy optimisation performance in both MuJoCo and Procgen tasks.\nAdditionally, our results highlight MaxEnt RL's capacity to enhance\ngeneralisation.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.18143v1",
    "published_date": "2024-07-25 15:48:24 UTC",
    "updated_date": "2024-07-25 15:48:24 UTC"
  },
  {
    "arxiv_id": "2407.18129v2",
    "title": "Dallah: A Dialect-Aware Multimodal Large Language Model for Arabic",
    "authors": [
      "Fakhraddin Alwajih",
      "Gagan Bhatia",
      "Muhammad Abdul-Mageed"
    ],
    "abstract": "Recent advancements have significantly enhanced the capabilities of\nMultimodal Large Language Models (MLLMs) in generating and understanding\nimage-to-text content. Despite these successes, progress is predominantly\nlimited to English due to the scarcity of high quality multimodal resources in\nother languages. This limitation impedes the development of competitive models\nin languages such as Arabic. To alleviate this situation, we introduce an\nefficient Arabic multimodal assistant, dubbed Dallah, that utilizes an advanced\nlanguage model based on LLaMA-2 to facilitate multimodal interactions. Dallah\ndemonstrates state-of-the-art performance in Arabic MLLMs. Through fine-tuning\nsix Arabic dialects, Dallah showcases its capability to handle complex\ndialectal interactions incorporating both textual and visual elements. The\nmodel excels in two benchmark tests: one evaluating its performance on Modern\nStandard Arabic (MSA) and another specifically designed to assess dialectal\nresponses. Beyond its robust performance in multimodal interaction tasks,\nDallah has the potential to pave the way for further development of\ndialect-aware Arabic MLLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.18129v2",
    "published_date": "2024-07-25 15:36:48 UTC",
    "updated_date": "2024-07-26 15:34:12 UTC"
  },
  {
    "arxiv_id": "2407.18125v3",
    "title": "Self-supervised pre-training with diffusion model for few-shot landmark detection in x-ray images",
    "authors": [
      "Roberto Di Via",
      "Francesca Odone",
      "Vito Paolo Pastore"
    ],
    "abstract": "Deep neural networks have been extensively applied in the medical domain for\nvarious tasks, including image classification, segmentation, and landmark\ndetection. However, their application is often hindered by data scarcity, both\nin terms of available annotations and images. This study introduces a novel\napplication of denoising diffusion probabilistic models (DDPMs) to the landmark\ndetection task, specifically addressing the challenge of limited annotated data\nin x-ray imaging. Our key innovation lies in leveraging DDPMs for\nself-supervised pre-training in landmark detection, a previously unexplored\napproach in this domain. This method enables accurate landmark detection with\nminimal annotated training data (as few as 50 images), surpassing both ImageNet\nsupervised pre-training and traditional self-supervised techniques across three\npopular x-ray benchmark datasets. To our knowledge, this work represents the\nfirst application of diffusion models for self-supervised learning in landmark\ndetection, which may offer a valuable pre-training approach in few-shot\nregimes, for mitigating data scarcity.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at WACV 2025",
    "pdf_url": "http://arxiv.org/pdf/2407.18125v3",
    "published_date": "2024-07-25 15:32:59 UTC",
    "updated_date": "2025-03-06 17:03:35 UTC"
  },
  {
    "arxiv_id": "2407.18110v1",
    "title": "MapTune: Advancing ASIC Technology Mapping via Reinforcement Learning Guided Library Tuning",
    "authors": [
      "Mingju Liu",
      "Daniel Robinson",
      "Yingjie Li",
      "Cunxi Yu"
    ],
    "abstract": "Technology mapping involves mapping logical circuits to a library of cells.\nTraditionally, the full technology library is used, leading to a large search\nspace and potential overhead. Motivated by randomly sampled technology mapping\ncase studies, we propose MapTune framework that addresses this challenge by\nutilizing reinforcement learning to make design-specific choices during cell\nselection. By learning from the environment, MapTune refines the cell selection\nprocess, resulting in a reduced search space and potentially improved mapping\nquality.\n  The effectiveness of MapTune is evaluated on a wide range of benchmarks,\ndifferent technology libraries and technology mappers. The experimental results\ndemonstrate that MapTune achieves higher mapping accuracy and reducing\ndelay/area across diverse circuit designs, technology libraries and mappers.\nThe paper also discusses the Pareto-Optimal exploration and confirms the\nperpetual delay-area trade-off. Conducted on benchmark suites ISCAS 85/89,\nITC/ISCAS 99, VTR8.0 and EPFL benchmarks, the post-technology mapping and\npost-sizing quality-of-results (QoR) have been significantly improved, with\naverage Area-Delay Product (ADP) improvement of 22.54\\% among all different\nexploration settings in MapTune. The improvements are consistently remained for\nfour different technologies (7nm, 45nm, 130nm, and 180 nm) and two different\nmappers.",
    "categories": [
      "cs.AR",
      "cs.AI"
    ],
    "primary_category": "cs.AR",
    "comment": "IEEE/ACM International Conference on Computer-Aided Design (ICCAD\n  '24), October 27--31, 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.18110v1",
    "published_date": "2024-07-25 15:18:47 UTC",
    "updated_date": "2024-07-25 15:18:47 UTC"
  },
  {
    "arxiv_id": "2407.18105v1",
    "title": "Multi-Resolution Histopathology Patch Graphs for Ovarian Cancer Subtyping",
    "authors": [
      "Jack Breen",
      "Katie Allen",
      "Kieran Zucker",
      "Nicolas M. Orsi",
      "Nishant Ravikumar"
    ],
    "abstract": "Computer vision models are increasingly capable of classifying ovarian\nepithelial cancer subtypes, but they differ from pathologists by processing\nsmall tissue patches at a single resolution. Multi-resolution graph models\nleverage the spatial relationships of patches at multiple magnifications,\nlearning the context for each patch. In this study, we conduct the most\nthorough validation of a graph model for ovarian cancer subtyping to date.\nSeven models were tuned and trained using five-fold cross-validation on a set\nof 1864 whole slide images (WSIs) from 434 patients treated at Leeds Teaching\nHospitals NHS Trust. The cross-validation models were ensembled and evaluated\nusing a balanced hold-out test set of 100 WSIs from 30 patients, and an\nexternal validation set of 80 WSIs from 80 patients in the Transcanadian Study.\nThe best-performing model, a graph model using 10x+20x magnification data, gave\nbalanced accuracies of 73%, 88%, and 99% in cross-validation, hold-out testing,\nand external validation, respectively. However, this only exceeded the\nperformance of attention-based multiple instance learning in external\nvalidation, with a 93% balanced accuracy. Graph models benefitted greatly from\nusing the UNI foundation model rather than an ImageNet-pretrained ResNet50 for\nfeature extraction, with this having a much greater effect on performance than\nchanging the subsequent classification approach. The accuracy of the combined\nfoundation model and multi-resolution graph network offers a step towards the\nclinical applicability of these models, with a new highest-reported performance\nfor this task, though further validations are still required to ensure the\nrobustness and usability of the models.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "Initially submitted version of a paper which has been accepted in the\n  GRAIL workshop at MICCAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.18105v1",
    "published_date": "2024-07-25 15:08:54 UTC",
    "updated_date": "2024-07-25 15:08:54 UTC"
  },
  {
    "arxiv_id": "2407.18096v1",
    "title": "Privacy Threats and Countermeasures in Federated Learning for Internet of Things: A Systematic Review",
    "authors": [
      "Adel ElZemity",
      "Budi Arief"
    ],
    "abstract": "Federated Learning (FL) in the Internet of Things (IoT) environments can\nenhance machine learning by utilising decentralised data, but at the same time,\nit might introduce significant privacy and security concerns due to the\nconstrained nature of IoT devices. This represents a research challenge that we\naim to address in this paper. We systematically analysed recent literature to\nidentify privacy threats in FL within IoT environments, and evaluate the\ndefensive measures that can be employed to mitigate these threats. Using a\nSystematic Literature Review (SLR) approach, we searched five publication\ndatabases (Scopus, IEEE Xplore, Wiley, ACM, and Science Direct), collating\nrelevant papers published between 2017 and April 2024, a period which spans\nfrom the introduction of FL until now. Guided by the PRISMA protocol, we\nselected 49 papers to focus our systematic review on. We analysed these papers,\npaying special attention to the privacy threats and defensive measures --\nspecifically within the context of IoT -- using inclusion and exclusion\ncriteria tailored to highlight recent advances and critical insights. We\nidentified various privacy threats, including inference attacks, poisoning\nattacks, and eavesdropping, along with defensive measures such as Differential\nPrivacy and Secure Multi-Party Computation. These defences were evaluated for\ntheir effectiveness in protecting privacy without compromising the functional\nintegrity of FL in IoT settings. Our review underscores the necessity for\nrobust and efficient privacy-preserving strategies tailored for IoT\nenvironments. Notably, there is a need for strategies against replay, evasion,\nand model stealing attacks. Exploring lightweight defensive measures and\nemerging technologies such as blockchain may help improve the privacy of FL in\nIoT, leading to the creation of FL models that can operate under variable\nnetwork conditions.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.18096v1",
    "published_date": "2024-07-25 15:01:56 UTC",
    "updated_date": "2024-07-25 15:01:56 UTC"
  },
  {
    "arxiv_id": "2407.18078v1",
    "title": "PEFT-U: Parameter-Efficient Fine-Tuning for User Personalization",
    "authors": [
      "Christopher Clarke",
      "Yuzhao Heng",
      "Lingjia Tang",
      "Jason Mars"
    ],
    "abstract": "The recent emergence of Large Language Models (LLMs) has heralded a new era\nof human-AI interaction. These sophisticated models, exemplified by Chat-GPT\nand its successors, have exhibited remarkable capabilities in language\nunderstanding. However, as these LLMs have undergone exponential growth, a\ncrucial dimension that remains understudied is the personalization of these\nmodels. Large foundation models such as GPT-3 etc. focus on creating a\nuniversal model that serves a broad range of tasks and users. This approach\nemphasizes the model's generalization capabilities, treating users as a\ncollective rather than as distinct individuals. While practical for many common\napplications, this one-size-fits-all approach often fails to address the rich\ntapestry of human diversity and individual needs. To explore this issue we\nintroduce the PEFT-U Benchmark: a new dataset for building and evaluating NLP\nmodels for user personalization. \\datasetname{} consists of a series of\nuser-centered tasks containing diverse and individualized expressions where the\npreferences of users can potentially differ for the same input. Using PEFT-U,\nwe explore the challenge of efficiently personalizing LLMs to accommodate\nuser-specific preferences in the context of diverse user-centered tasks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.18078v1",
    "published_date": "2024-07-25 14:36:18 UTC",
    "updated_date": "2024-07-25 14:36:18 UTC"
  },
  {
    "arxiv_id": "2407.18061v1",
    "title": "Difficulty Estimation and Simplification of French Text Using LLMs",
    "authors": [
      "Henri Jamet",
      "Yash Raj Shrestha",
      "Michalis Vlachos"
    ],
    "abstract": "We leverage generative large language models for language learning\napplications, focusing on estimating the difficulty of foreign language texts\nand simplifying them to lower difficulty levels. We frame both tasks as\nprediction problems and develop a difficulty classification model using labeled\nexamples, transfer learning, and large language models, demonstrating superior\naccuracy compared to previous approaches. For simplification, we evaluate the\ntrade-off between simplification quality and meaning preservation, comparing\nzero-shot and fine-tuned performances of large language models. We show that\nmeaningful text simplifications can be obtained with limited fine-tuning. Our\nexperiments are conducted on French texts, but our methods are\nlanguage-agnostic and directly applicable to other foreign languages.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "10 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2407.18061v1",
    "published_date": "2024-07-25 14:16:08 UTC",
    "updated_date": "2024-07-25 14:16:08 UTC"
  },
  {
    "arxiv_id": "2407.18046v1",
    "title": "GaussianSR: High Fidelity 2D Gaussian Splatting for Arbitrary-Scale Image Super-Resolution",
    "authors": [
      "Jintong Hu",
      "Bin Xia",
      "Bin Chen",
      "Wenming Yang",
      "Lei Zhang"
    ],
    "abstract": "Implicit neural representations (INRs) have significantly advanced the field\nof arbitrary-scale super-resolution (ASSR) of images. Most existing INR-based\nASSR networks first extract features from the given low-resolution image using\nan encoder, and then render the super-resolved result via a multi-layer\nperceptron decoder. Although these approaches have shown promising results,\ntheir performance is constrained by the limited representation ability of\ndiscrete latent codes in the encoded features. In this paper, we propose a\nnovel ASSR method named GaussianSR that overcomes this limitation through 2D\nGaussian Splatting (2DGS). Unlike traditional methods that treat pixels as\ndiscrete points, GaussianSR represents each pixel as a continuous Gaussian\nfield. The encoded features are simultaneously refined and upsampled by\nrendering the mutually stacked Gaussian fields. As a result, long-range\ndependencies are established to enhance representation ability. In addition, a\nclassifier is developed to dynamically assign Gaussian kernels to all pixels to\nfurther improve flexibility. All components of GaussianSR (i.e., encoder,\nclassifier, Gaussian kernels, and decoder) are jointly learned end-to-end.\nExperiments demonstrate that GaussianSR achieves superior ASSR performance with\nfewer parameters than existing methods while enjoying interpretable and\ncontent-aware feature aggregations.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "13 pages, 12 figures",
    "pdf_url": "http://arxiv.org/pdf/2407.18046v1",
    "published_date": "2024-07-25 13:53:48 UTC",
    "updated_date": "2024-07-25 13:53:48 UTC"
  },
  {
    "arxiv_id": "2407.20276v2",
    "title": "Assessing AI Utility: The Random Guesser Test for Sequential Decision-Making Systems",
    "authors": [
      "Shun Ide",
      "Allison Blunt",
      "Djallel Bouneffouf"
    ],
    "abstract": "We propose a general approach to quantitatively assessing the risk and\nvulnerability of artificial intelligence (AI) systems to biased decisions. The\nguiding principle of the proposed approach is that any AI algorithm must\noutperform a random guesser. This may appear trivial, but empirical results\nfrom a simplistic sequential decision-making scenario involving roulette games\nshow that sophisticated AI-based approaches often underperform the random\nguesser by a significant margin. We highlight that modern recommender systems\nmay exhibit a similar tendency to favor overly low-risk options. We argue that\nthis \"random guesser test\" can serve as a useful tool for evaluating the\nutility of AI actions, and also points towards increasing exploration as a\npotential improvement to such systems.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "Accepted into AIBS 2024: The First Workshop on AI Behavioral Science,\n  5 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2407.20276v2",
    "published_date": "2024-07-25 13:44:22 UTC",
    "updated_date": "2024-08-11 13:56:58 UTC"
  },
  {
    "arxiv_id": "2407.18039v1",
    "title": "Peak-Controlled Logits Poisoning Attack in Federated Distillation",
    "authors": [
      "Yuhan Tang",
      "Aoxu Zhang",
      "Zhiyuan Wu",
      "Bo Gao",
      "Tian Wen",
      "Yuwei Wang",
      "Sheng Sun"
    ],
    "abstract": "Federated Distillation (FD) offers an innovative approach to distributed\nmachine learning, leveraging knowledge distillation for efficient and flexible\ncross-device knowledge transfer without necessitating the upload of extensive\nmodel parameters to a central server. While FD has gained popularity, its\nvulnerability to poisoning attacks remains underexplored. To address this gap,\nwe previously introduced FDLA (Federated Distillation Logits Attack), a method\nthat manipulates logits communication to mislead and degrade the performance of\nclient models. However, the impact of FDLA on participants with different\nidentities and the effects of malicious modifications at various stages of\nknowledge transfer remain unexplored. To this end, we present PCFDLA\n(Peak-Controlled Federated Distillation Logits Attack), an advanced and more\nstealthy logits poisoning attack method for FD. PCFDLA enhances the\neffectiveness of FDLA by carefully controlling the peak values of logits to\ncreate highly misleading yet inconspicuous modifications. Furthermore, we\nintroduce a novel metric for better evaluating attack efficacy, demonstrating\nthat PCFDLA maintains stealth while being significantly more disruptive to\nvictim models compared to its predecessors. Experimental results across various\ndatasets confirm the superior impact of PCFDLA on model accuracy, solidifying\nits potential threat in federated distillation systems.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "arXiv admin note: text overlap with arXiv:2401.03685",
    "pdf_url": "http://arxiv.org/pdf/2407.18039v1",
    "published_date": "2024-07-25 13:36:42 UTC",
    "updated_date": "2024-07-25 13:36:42 UTC"
  },
  {
    "arxiv_id": "2407.18035v1",
    "title": "RestoreAgent: Autonomous Image Restoration Agent via Multimodal Large Language Models",
    "authors": [
      "Haoyu Chen",
      "Wenbo Li",
      "Jinjin Gu",
      "Jingjing Ren",
      "Sixiang Chen",
      "Tian Ye",
      "Renjing Pei",
      "Kaiwen Zhou",
      "Fenglong Song",
      "Lei Zhu"
    ],
    "abstract": "Natural images captured by mobile devices often suffer from multiple types of\ndegradation, such as noise, blur, and low light. Traditional image restoration\nmethods require manual selection of specific tasks, algorithms, and execution\nsequences, which is time-consuming and may yield suboptimal results. All-in-one\nmodels, though capable of handling multiple tasks, typically support only a\nlimited range and often produce overly smooth, low-fidelity outcomes due to\ntheir broad data distribution fitting. To address these challenges, we first\ndefine a new pipeline for restoring images with multiple degradations, and then\nintroduce RestoreAgent, an intelligent image restoration system leveraging\nmultimodal large language models. RestoreAgent autonomously assesses the type\nand extent of degradation in input images and performs restoration through (1)\ndetermining the appropriate restoration tasks, (2) optimizing the task\nsequence, (3) selecting the most suitable models, and (4) executing the\nrestoration. Experimental results demonstrate the superior performance of\nRestoreAgent in handling complex degradation, surpassing human experts.\nFurthermore, the system modular design facilitates the fast integration of new\ntasks and models, enhancing its flexibility and scalability for various\napplications.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.18035v1",
    "published_date": "2024-07-25 13:29:37 UTC",
    "updated_date": "2024-07-25 13:29:37 UTC"
  },
  {
    "arxiv_id": "2407.18034v1",
    "title": "AttentionHand: Text-driven Controllable Hand Image Generation for 3D Hand Reconstruction in the Wild",
    "authors": [
      "Junho Park",
      "Kyeongbo Kong",
      "Suk-Ju Kang"
    ],
    "abstract": "Recently, there has been a significant amount of research conducted on 3D\nhand reconstruction to use various forms of human-computer interaction.\nHowever, 3D hand reconstruction in the wild is challenging due to extreme lack\nof in-the-wild 3D hand datasets. Especially, when hands are in complex pose\nsuch as interacting hands, the problems like appearance similarity, self-handed\noccclusion and depth ambiguity make it more difficult. To overcome these\nissues, we propose AttentionHand, a novel method for text-driven controllable\nhand image generation. Since AttentionHand can generate various and numerous\nin-the-wild hand images well-aligned with 3D hand label, we can acquire a new\n3D hand dataset, and can relieve the domain gap between indoor and outdoor\nscenes. Our method needs easy-to-use four modalities (i.e, an RGB image, a hand\nmesh image from 3D label, a bounding box, and a text prompt). These modalities\nare embedded into the latent space by the encoding phase. Then, through the\ntext attention stage, hand-related tokens from the given text prompt are\nattended to highlight hand-related regions of the latent embedding. After the\nhighlighted embedding is fed to the visual attention stage, hand-related\nregions in the embedding are attended by conditioning global and local hand\nmesh images with the diffusion-based pipeline. In the decoding phase, the final\nfeature is decoded to new hand images, which are well-aligned with the given\nhand mesh image and text prompt. As a result, AttentionHand achieved\nstate-of-the-art among text-to-hand image generation models, and the\nperformance of 3D hand mesh reconstruction was improved by additionally\ntraining with hand images generated by AttentionHand.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by ECCV 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.18034v1",
    "published_date": "2024-07-25 13:29:32 UTC",
    "updated_date": "2024-07-25 13:29:32 UTC"
  },
  {
    "arxiv_id": "2407.18022v1",
    "title": "Learning mental states estimation through self-observation: a developmental synergy between intentions and beliefs representations in a deep-learning model of Theory of Mind",
    "authors": [
      "Francesca Bianco",
      "Silvia Rigato",
      "Maria Laura Filippetti",
      "Dimitri Ognibene"
    ],
    "abstract": "Theory of Mind (ToM), the ability to attribute beliefs, intentions, or mental\nstates to others, is a crucial feature of human social interaction. In complex\nenvironments, where the human sensory system reaches its limits, behaviour is\nstrongly driven by our beliefs about the state of the world around us.\nAccessing others' mental states, e.g., beliefs and intentions, allows for more\neffective social interactions in natural contexts. Yet, these variables are not\ndirectly observable, making understanding ToM a challenging quest of interest\nfor different fields, including psychology, machine learning and robotics. In\nthis paper, we contribute to this topic by showing a developmental synergy\nbetween learning to predict low-level mental states (e.g., intentions, goals)\nand attributing high-level ones (i.e., beliefs). Specifically, we assume that\nlearning beliefs attribution can occur by observing one's own decision\nprocesses involving beliefs, e.g., in a partially observable environment. Using\na simple feed-forward deep learning model, we show that, when learning to\npredict others' intentions and actions, more accurate predictions can be\nacquired earlier if beliefs attribution is learnt simultaneously. Furthermore,\nwe show that the learning performance improves even when observed actors have a\ndifferent embodiment than the observer and the gain is higher when observing\nbeliefs-driven chunks of behaviour. We propose that our computational approach\ncan inform the understanding of human social cognitive development and be\nrelevant for the design of future adaptive social robots able to autonomously\nunderstand, assist, and learn from human interaction partners in novel natural\nenvironments and tasks.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.18022v1",
    "published_date": "2024-07-25 13:15:25 UTC",
    "updated_date": "2024-07-25 13:15:25 UTC"
  },
  {
    "arxiv_id": "2407.18021v1",
    "title": "Quadratic Advantage with Quantum Randomized Smoothing Applied to Time-Series Analysis",
    "authors": [
      "Nicola Franco",
      "Marie Kempkes",
      "Jakob Spiegelberg",
      "Jeanette Miriam Lorenz"
    ],
    "abstract": "As quantum machine learning continues to develop at a rapid pace, the\nimportance of ensuring the robustness and efficiency of quantum algorithms\ncannot be overstated. Our research presents an analysis of quantum randomized\nsmoothing, how data encoding and perturbation modeling approaches can be\nmatched to achieve meaningful robustness certificates. By utilizing an\ninnovative approach integrating Grover's algorithm, a quadratic sampling\nadvantage over classical randomized smoothing is achieved. This strategy\nnecessitates a basis state encoding, thus restricting the space of meaningful\nperturbations. We show how constrained $k$-distant Hamming weight perturbations\nare a suitable noise distribution here, and elucidate how they can be\nconstructed on a quantum computer. The efficacy of the proposed framework is\ndemonstrated on a time series classification task employing a Bag-of-Words\npre-processing solution. The advantage of quadratic sample reduction is\nrecovered especially in the regime with large number of samples. This may allow\nquantum computers to efficiently scale randomized smoothing to more complex\ntasks beyond the reach of classical methods.",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "quant-ph",
    "comment": "Accepted at the IEEE International Conference on Quantum Computing\n  and Engineering (QCE)",
    "pdf_url": "http://arxiv.org/pdf/2407.18021v1",
    "published_date": "2024-07-25 13:15:16 UTC",
    "updated_date": "2024-07-25 13:15:16 UTC"
  },
  {
    "arxiv_id": "2407.18017v1",
    "title": "A Sensitivity Analysis of Cellular Automata and Heterogeneous Topology Networks: Partially-Local Cellular Automata and Homogeneous Homogeneous Random Boolean Networks",
    "authors": [
      "Tom Eivind Glover",
      "Ruben Jahren",
      "Francesco Martinuzzi",
      "Pedro Gonçalves Lind",
      "Stefano Nichele"
    ],
    "abstract": "Elementary Cellular Automata (ECA) are a well-studied computational universe\nthat is, despite its simple configurations, capable of impressive computational\nvariety. Harvesting this computation in a useful way has historically shown\nitself to be difficult, but if combined with reservoir computing (RC), this\nbecomes much more feasible. Furthermore, RC and ECA enable energy-efficient AI,\nmaking the combination a promising concept for Edge AI. In this work, we\ncontrast ECA to substrates of Partially-Local CA (PLCA) and Homogeneous\nHomogeneous Random Boolean Networks (HHRBN). They are, in comparison, the\ntopological heterogeneous counterparts of ECA. This represents a step from ECA\ntowards more biological-plausible substrates. We analyse these substrates by\ntesting on an RC benchmark (5-bit memory), using Temporal Derrida plots to\nestimate the sensitivity and assess the defect collapse rate. We find that,\ncounterintuitively, disordered topology does not necessarily mean disordered\ncomputation. There are countering computational \"forces\" of topology\nimperfections leading to a higher collapse rate (order) and yet, if accounted\nfor, an increased sensitivity to the initial condition. These observations\ntogether suggest a shrinking critical range.",
    "categories": [
      "nlin.CG",
      "cs.AI",
      "cs.ET",
      "cs.NE"
    ],
    "primary_category": "nlin.CG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.18017v1",
    "published_date": "2024-07-25 13:08:24 UTC",
    "updated_date": "2024-07-25 13:08:24 UTC"
  },
  {
    "arxiv_id": "2407.17980v1",
    "title": "Personalized and Context-aware Route Planning for Edge-assisted Vehicles",
    "authors": [
      "Dinesh Cyril Selvaraj",
      "Falko Dressler",
      "Carla Fabiana Chiasserini"
    ],
    "abstract": "Conventional route planning services typically offer the same routes to all\ndrivers, focusing primarily on a few standardized factors such as travel\ndistance or time, overlooking individual driver preferences. With the inception\nof autonomous vehicles expected in the coming years, where vehicles will rely\non routes decided by such planners, there arises a need to incorporate the\nspecific preferences of each driver, ensuring personalized navigation\nexperiences. In this work, we propose a novel approach based on graph neural\nnetworks (GNNs) and deep reinforcement learning (DRL), aimed at customizing\nroutes to suit individual preferences. By analyzing the historical trajectories\nof individual drivers, we classify their driving behavior and associate it with\nrelevant road attributes as indicators of driver preferences. The GNN is\ncapable of representing the road network as graph-structured data effectively,\nwhile DRL is capable of making decisions utilizing reward mechanisms to\noptimize route selection with factors such as travel costs, congestion level,\nand driver satisfaction. We evaluate our proposed GNN-based DRL framework using\na real-world road network and demonstrate its ability to accommodate driver\npreferences, offering a range of route options tailored to individual drivers.\nThe results indicate that our framework can select routes that accommodate\ndriver's preferences with up to a 17% improvement compared to a generic route\nplanner, and reduce the travel time by 33% (afternoon) and 46% (evening)\nrelatively to the shortest distance-based approach.",
    "categories": [
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.17980v1",
    "published_date": "2024-07-25 12:14:12 UTC",
    "updated_date": "2024-07-25 12:14:12 UTC"
  },
  {
    "arxiv_id": "2407.18990v2",
    "title": "Stay Tuned: An Empirical Study of the Impact of Hyperparameters on LLM Tuning in Real-World Applications",
    "authors": [
      "Alon Halfon",
      "Shai Gretz",
      "Ofir Arviv",
      "Artem Spector",
      "Orith Toledo-Ronen",
      "Yoav Katz",
      "Liat Ein-Dor",
      "Michal Shmueli-Scheuer",
      "Noam Slonim"
    ],
    "abstract": "Fine-tuning Large Language Models (LLMs) is an effective method to enhance\ntheir performance on downstream tasks. However, choosing the appropriate\nsetting of tuning hyperparameters (HPs) is a labor-intensive and\ncomputationally expensive process. Here, we provide recommended HP\nconfigurations for practical use-cases that represent a better starting point\nfor practitioners, when considering two SOTA LLMs and two commonly used tuning\nmethods. We describe Coverage-based Search (CBS), a process for ranking HP\nconfigurations based on an offline extensive grid search, such that the top\nranked configurations collectively provide a practical robust recommendation\nfor a wide range of datasets and domains. We focus our experiments on\nLlama-3-8B and Mistral-7B, as well as full fine-tuning and LoRa, conducting a\ntotal of > 10,000 tuning experiments. Our results suggest that, in general,\nLlama-3-8B and LoRA should be preferred, when possible. Moreover, we show that\nfor both models and tuning methods, exploring only a few HP configurations, as\nrecommended by our analysis, can provide excellent results in practice, making\nthis work a valuable resource for practitioners.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.18990v2",
    "published_date": "2024-07-25 12:07:55 UTC",
    "updated_date": "2024-08-07 07:46:39 UTC"
  },
  {
    "arxiv_id": "2407.17963v1",
    "title": "Relating the Seemingly Unrelated: Principled Understanding of Generalization for Generative Models in Arithmetic Reasoning Tasks",
    "authors": [
      "Xingcheng Xu",
      "Zibo Zhao",
      "Haipeng Zhang",
      "Yanqing Yang"
    ],
    "abstract": "Large language models (LLMs) have demonstrated impressive versatility across\nnumerous tasks, yet their generalization capabilities remain poorly understood.\nTo investigate these behaviors, arithmetic tasks serve as important venues. In\nprevious studies, seemingly unrelated mysteries still exist -- (1) models with\nappropriate positional embeddings can correctly perform longer unseen\narithmetic operations such as addition, but their effectiveness varies in more\ncomplex tasks like multiplication; (2) models perform well for longer unseen\ncases in modular addition under specific moduli (e.g., modulo 100) but struggle\nunder very close moduli (e.g., modulo 101), regardless of the positional\nencoding used. We believe previous studies have been treating the symptoms\nrather than addressing the root cause -- they have paid excessive attention to\nimproving model components, while overlooking the differences in task\nproperties that may be the real drivers. This is confirmed by our unified\ntheoretical framework for different arithmetic scenarios. For example, unlike\nmultiplication, the digital addition task has the property of translation\ninvariance which naturally aligns with the relative positional encoding, and\nthis combination leads to successful generalization of addition to unseen\nlonger domains. The discrepancy in operations modulo 100 and 101 arises from\nthe base. Modulo 100, unlike 101, is compatible with the decimal system (base\n10), such that unseen information in digits beyond the units digit and the tens\ndigit is actually not needed for the task. Extensive experiments with GPT-like\nmodels validate our theoretical predictions. These findings deepen our\nunderstanding of the generalization mechanisms, and facilitate more\ndata-efficient model training and objective-oriented AI alignment.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.17963v1",
    "published_date": "2024-07-25 11:35:22 UTC",
    "updated_date": "2024-07-25 11:35:22 UTC"
  },
  {
    "arxiv_id": "2407.17951v1",
    "title": "Pruning Boolean d-DNNF Circuits Through Tseitin-Awareness",
    "authors": [
      "Vincent Derkinderen"
    ],
    "abstract": "Boolean circuits in d-DNNF form enable tractable probabilistic inference.\nHowever, as a key insight of this work, we show that commonly used d-DNNF\ncompilation approaches introduce irrelevant subcircuits. We call these\nsubcircuits Tseitin artifacts, as they are introduced due to the Tseitin\ntransformation step -- a well-established procedure to transform any circuit\ninto the CNF format required by several d-DNNF knowledge compilers. We discuss\nhow to detect and remove both Tseitin variables and Tseitin artifacts, leading\nto more succinct circuits. We empirically observe an average size reduction of\n77.5% when removing both Tseitin variables and artifacts. The additional\npruning of Tseitin artifacts reduces the size by 22.2% on average. This\nsignificantly improves downstream tasks that benefit from a more succinct\ncircuit, e.g., probabilistic inference tasks.",
    "categories": [
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "submitted to ICTAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.17951v1",
    "published_date": "2024-07-25 11:15:57 UTC",
    "updated_date": "2024-07-25 11:15:57 UTC"
  },
  {
    "arxiv_id": "2407.17950v1",
    "title": "Real Time American Sign Language Detection Using Yolo-v9",
    "authors": [
      "Amna Imran",
      "Meghana Shashishekhara Hulikal",
      "Hamza A. A. Gardi"
    ],
    "abstract": "This paper focuses on real-time American Sign Language Detection. YOLO is a\nconvolutional neural network (CNN) based model, which was first released in\n2015. In recent years, it gained popularity for its real-time detection\ncapabilities. Our study specifically targets YOLO-v9 model, released in 2024.\nAs the model is newly introduced, not much work has been done on it, especially\nnot in Sign Language Detection. Our paper provides deep insight on how YOLO- v9\nworks and better than previous model.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "11 pages, 13 figures, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2407.17950v1",
    "published_date": "2024-07-25 11:11:05 UTC",
    "updated_date": "2024-07-25 11:11:05 UTC"
  },
  {
    "arxiv_id": "2407.17940v3",
    "title": "Positive Text Reframing under Multi-strategy Optimization",
    "authors": [
      "Shutong Jia",
      "Biwei Cao",
      "Qingqing Gao",
      "Jiuxin Cao",
      "Bo Liu"
    ],
    "abstract": "Differing from sentiment transfer, positive reframing seeks to substitute\nnegative perspectives with positive expressions while preserving the original\nmeaning. With the emergence of pre-trained language models (PLMs), it is\npossible to achieve acceptable results by fine-tuning PLMs. Nevertheless,\ngenerating fluent, diverse and task-constrained reframing text remains a\nsignificant challenge. To tackle this issue, a \\textbf{m}ulti-\\textbf{s}trategy\n\\textbf{o}ptimization \\textbf{f}ramework (MSOF) is proposed in this paper.\nStarting from the objective of positive reframing, we first design positive\nsentiment reward and content preservation reward to encourage the model to\ntransform the negative expressions of the original text while ensuring the\nintegrity and consistency of the semantics. Then, different decoding\noptimization approaches are introduced to improve the quality of text\ngeneration. Finally, based on the modeling formula of positive reframing, we\npropose a multi-dimensional re-ranking method that further selects candidate\nsentences from three dimensions: strategy consistency, text similarity and\nfluency. Extensive experiments on two Seq2Seq PLMs, BART and T5, demonstrate\nour framework achieves significant improvements on unconstrained and controlled\npositive reframing tasks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "To appear at COLING 2025",
    "pdf_url": "http://arxiv.org/pdf/2407.17940v3",
    "published_date": "2024-07-25 10:58:42 UTC",
    "updated_date": "2024-12-16 12:57:12 UTC"
  },
  {
    "arxiv_id": "2407.17930v1",
    "title": "Comparison of different Artificial Neural Networks for Bitcoin price forecasting",
    "authors": [
      "Silas Baumann",
      "Karl A. Busch",
      "Hamza A. A. Gardi"
    ],
    "abstract": "This study investigates the impact of varying sequence lengths on the\naccuracy of predicting cryptocurrency returns using Artificial Neural Networks\n(ANNs). Utilizing the Mean Absolute Error (MAE) as a threshold criterion, we\naim to enhance prediction accuracy by excluding returns that are smaller than\nthis threshold, thus mitigating errors associated with minor returns. The\nsubsequent evaluation focuses on the accuracy of predicted returns that exceed\nthis threshold. We compare four sequence lengths 168 hours (7 days), 72 hours\n(3 days), 24 hours, and 12 hours each with a return prediction interval of 2\nhours. Our findings reveal the influence of sequence length on prediction\naccuracy and underscore the potential for optimized sequence configurations in\nfinancial forecasting models.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "9 pages, 8 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2407.17930v1",
    "published_date": "2024-07-25 10:39:50 UTC",
    "updated_date": "2024-07-25 10:39:50 UTC"
  },
  {
    "arxiv_id": "2407.17927v2",
    "title": "Invariance of deep image quality metrics to affine transformations",
    "authors": [
      "Nuria Alabau-Bosque",
      "Paula Daudén-Oliver",
      "Jorge Vila-Tomás",
      "Valero Laparra",
      "Jesús Malo"
    ],
    "abstract": "Deep architectures are the current state-of-the-art in predicting subjective\nimage quality. Usually, these models are evaluated according to their ability\nto correlate with human opinion in databases with a range of distortions that\nmay appear in digital media. However, these oversee affine transformations\nwhich may represent better the changes in the images actually happening in\nnatural conditions. Humans can be particularly invariant to these natural\ntransformations, as opposed to the digital ones. In this work, we evaluate\nstate-of-the-art deep image quality metrics by assessing their invariance to\naffine transformations, specifically: rotation, translation, scaling, and\nchanges in spectral illumination. Here invariance of a metric refers to the\nfact that certain distances should be neglected (considered to be zero) if\ntheir values are below a threshold. This is what we call invisibility threshold\nof a metric. We propose a methodology to assign such invisibility thresholds\nfor any perceptual metric. This methodology involves transformations to a\ndistance space common to any metric, and psychophysical measurements of\nthresholds in this common space. By doing so, we allow the analyzed metrics to\nbe directly comparable with actual human thresholds. We find that none of the\nstate-of-the-art metrics shows human-like results under this strong test based\non invisibility thresholds. This means that tuning the models exclusively to\npredict the visibility of generic distortions may disregard other properties of\nhuman vision as for instance invariances or invisibility thresholds.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "24 pages 40 figures",
    "pdf_url": "http://arxiv.org/pdf/2407.17927v2",
    "published_date": "2024-07-25 10:24:54 UTC",
    "updated_date": "2024-07-29 11:55:53 UTC"
  },
  {
    "arxiv_id": "2407.20274v1",
    "title": "Exploring the Plausibility of Hate and Counter Speech Detectors with Explainable AI",
    "authors": [
      "Adrian Jaques Böck",
      "Djordje Slijepčević",
      "Matthias Zeppelzauer"
    ],
    "abstract": "In this paper we investigate the explainability of transformer models and\ntheir plausibility for hate speech and counter speech detection. We compare\nrepresentatives of four different explainability approaches, i.e.,\ngradient-based, perturbation-based, attention-based, and prototype-based\napproaches, and analyze them quantitatively with an ablation study and\nqualitatively in a user study. Results show that perturbation-based\nexplainability performs best, followed by gradient-based and attention-based\nexplainability. Prototypebased experiments did not yield useful results.\nOverall, we observe that explainability strongly supports the users in better\nunderstanding the model predictions.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "conference, CBMI2024, 6 pages,",
    "pdf_url": "http://arxiv.org/pdf/2407.20274v1",
    "published_date": "2024-07-25 10:17:04 UTC",
    "updated_date": "2024-07-25 10:17:04 UTC"
  },
  {
    "arxiv_id": "2407.17915v4",
    "title": "The Dark Side of Function Calling: Pathways to Jailbreaking Large Language Models",
    "authors": [
      "Zihui Wu",
      "Haichang Gao",
      "Jianping He",
      "Ping Wang"
    ],
    "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities, but\ntheir power comes with significant security considerations. While extensive\nresearch has been conducted on the safety of LLMs in chat mode, the security\nimplications of their function calling feature have been largely overlooked.\nThis paper uncovers a critical vulnerability in the function calling process of\nLLMs, introducing a novel \"jailbreak function\" attack method that exploits\nalignment discrepancies, user coercion, and the absence of rigorous safety\nfilters. Our empirical study, conducted on six state-of-the-art LLMs including\nGPT-4o, Claude-3.5-Sonnet, and Gemini-1.5-pro, reveals an alarming average\nsuccess rate of over 90\\% for this attack. We provide a comprehensive analysis\nof why function calls are susceptible to such attacks and propose defensive\nstrategies, including the use of defensive prompts. Our findings highlight the\nurgent need for enhanced security measures in the function calling capabilities\nof LLMs, contributing to the field of AI safety by identifying a previously\nunexplored risk, designing an effective attack method, and suggesting practical\ndefensive measures. Our code is available at\nhttps://github.com/wooozihui/jailbreakfunction.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.17915v4",
    "published_date": "2024-07-25 10:09:21 UTC",
    "updated_date": "2024-12-24 09:35:05 UTC"
  },
  {
    "arxiv_id": "2407.17911v1",
    "title": "ReCorD: Reasoning and Correcting Diffusion for HOI Generation",
    "authors": [
      "Jian-Yu Jiang-Lin",
      "Kang-Yang Huang",
      "Ling Lo",
      "Yi-Ning Huang",
      "Terence Lin",
      "Jhih-Ciang Wu",
      "Hong-Han Shuai",
      "Wen-Huang Cheng"
    ],
    "abstract": "Diffusion models revolutionize image generation by leveraging natural\nlanguage to guide the creation of multimedia content. Despite significant\nadvancements in such generative models, challenges persist in depicting\ndetailed human-object interactions, especially regarding pose and object\nplacement accuracy. We introduce a training-free method named Reasoning and\nCorrecting Diffusion (ReCorD) to address these challenges. Our model couples\nLatent Diffusion Models with Visual Language Models to refine the generation\nprocess, ensuring precise depictions of HOIs. We propose an interaction-aware\nreasoning module to improve the interpretation of the interaction, along with\nan interaction correcting module to refine the output image for more precise\nHOI generation delicately. Through a meticulous process of pose selection and\nobject positioning, ReCorD achieves superior fidelity in generated images while\nefficiently reducing computational requirements. We conduct comprehensive\nexperiments on three benchmarks to demonstrate the significant progress in\nsolving text-to-image generation tasks, showcasing ReCorD's ability to render\ncomplex interactions accurately by outperforming existing methods in HOI\nclassification score, as well as FID and Verb CLIP-Score. Project website is\navailable at https://alberthkyhky.github.io/ReCorD/ .",
    "categories": [
      "cs.MM",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.MM",
    "comment": "Accepted by ACM MM 2024. Project website:\n  https://alberthkyhky.github.io/ReCorD/",
    "pdf_url": "http://arxiv.org/pdf/2407.17911v1",
    "published_date": "2024-07-25 10:06:26 UTC",
    "updated_date": "2024-07-25 10:06:26 UTC"
  },
  {
    "arxiv_id": "2407.17910v1",
    "title": "Causal Deepsets for Off-policy Evaluation under Spatial or Spatio-temporal Interferences",
    "authors": [
      "Runpeng Dai",
      "Jianing Wang",
      "Fan Zhou",
      "Shikai Luo",
      "Zhiwei Qin",
      "Chengchun Shi",
      "Hongtu Zhu"
    ],
    "abstract": "Off-policy evaluation (OPE) is widely applied in sectors such as\npharmaceuticals and e-commerce to evaluate the efficacy of novel products or\npolicies from offline datasets. This paper introduces a causal deepset\nframework that relaxes several key structural assumptions, primarily the\nmean-field assumption, prevalent in existing OPE methodologies that handle\nspatio-temporal interference. These traditional assumptions frequently prove\ninadequate in real-world settings, thereby restricting the capability of\ncurrent OPE methods to effectively address complex interference effects. In\nresponse, we advocate for the implementation of the permutation invariance (PI)\nassumption. This innovative approach enables the data-driven, adaptive learning\nof the mean-field function, offering a more flexible estimation method beyond\nconventional averaging. Furthermore, we present novel algorithms that\nincorporate the PI assumption into OPE and thoroughly examine their theoretical\nfoundations. Our numerical analyses demonstrate that this novel approach yields\nsignificantly more precise estimations than existing baseline algorithms,\nthereby substantially improving the practical applicability and effectiveness\nof OPE methodologies. A Python implementation of our proposed method is\navailable at https://github.com/BIG-S2/Causal-Deepsets.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "stat.ML",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.17910v1",
    "published_date": "2024-07-25 10:02:11 UTC",
    "updated_date": "2024-07-25 10:02:11 UTC"
  },
  {
    "arxiv_id": "2407.17896v2",
    "title": "SR-CurvANN: Advancing 3D Surface Reconstruction through Curvature-Aware Neural Networks",
    "authors": [
      "Marina Hernández-Bautista",
      "Francisco J. Melero"
    ],
    "abstract": "Incomplete or missing data in three-dimensional (3D) models can lead to\nerroneous or flawed renderings, limiting their usefulness in applications such\nas visualization, geometric computation, and 3D printing. Conventional\nsurface-repair techniques often fail to infer complex geometric details in\nmissing areas. Neural networks successfully address hole-filling tasks in 2D\nimages using inpainting techniques. The combination of surface reconstruction\nalgorithms, guided by the model's curvature properties and the creativity of\nneural networks in the inpainting processes should provide realistic results in\nthe hole completion task. In this paper, we propose a novel method entitled\nSR-CurvANN (Surface Reconstruction Based on Curvature-Aware Neural Networks)\nthat incorporates neural network-based 2D inpainting to effectively reconstruct\n3D surfaces. We train the neural networks with images that represent planar\nrepresentations of the curvature at vertices of hundreds of 3D models. Once the\nmissing areas have been inferred, a coarse-to-fine surface deformation process\nensures that the surface fits the reconstructed curvature image. Our proposal\nmakes it possible to learn and generalize patterns from a wide variety of\ntraining 3D models, generating comprehensive inpainted curvature images and\nsurfaces. Experiments conducted on 959 models with several holes have\ndemonstrated that SR-CurvANN excels in the shape completion process, filling\nholes with a remarkable level of realism and precision.",
    "categories": [
      "cs.GR",
      "cs.AI"
    ],
    "primary_category": "cs.GR",
    "comment": "Major changes in title, paper structure, text and figures. Improved\n  results. 23 pages, 14 figures. Decision about submission not taken yet",
    "pdf_url": "http://arxiv.org/pdf/2407.17896v2",
    "published_date": "2024-07-25 09:36:37 UTC",
    "updated_date": "2024-09-26 10:33:53 UTC"
  },
  {
    "arxiv_id": "2407.17892v1",
    "title": "An Iterative Approach to Topic Modelling",
    "authors": [
      "Albert Wong",
      "Florence Wing Yau Cheng",
      "Ashley Keung",
      "Yamileth Hercules",
      "Mary Alexandra Garcia",
      "Yew-Wei Lim",
      "Lien Pham"
    ],
    "abstract": "Topic modelling has become increasingly popular for summarizing text data,\nsuch as social media posts and articles. However, topic modelling is usually\ncompleted in one shot. Assessing the quality of resulting topics is\nchallenging. No effective methods or measures have been developed for assessing\nthe results or for making further enhancements to the topics. In this research,\nwe propose we propose to use an iterative process to perform topic modelling\nthat gives rise to a sense of completeness of the resulting topics when the\nprocess is complete. Using the BERTopic package, a popular method in topic\nmodelling, we demonstrate how the modelling process can be applied iteratively\nto arrive at a set of topics that could not be further improved upon using one\nof the three selected measures for clustering comparison as the decision\ncriteria. This demonstration is conducted using a subset of the COVIDSenti-A\ndataset. The early success leads us to believe that further research using in\nusing this approach in conjunction with other topic modelling algorithms could\nbe viable.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.17892v1",
    "published_date": "2024-07-25 09:26:07 UTC",
    "updated_date": "2024-07-25 09:26:07 UTC"
  },
  {
    "arxiv_id": "2408.01455v1",
    "title": "Ontology of Belief Diversity: A Community-Based Epistemological Approach",
    "authors": [
      "Tyler Fischella",
      "Erin van Liemt",
      "Qiuyi",
      "Zhang"
    ],
    "abstract": "AI applications across classification, fairness, and human interaction often\nimplicitly require ontologies of social concepts. Constructing these well,\nespecially when there are many relevant categories, is a controversial task but\nis crucial for achieving meaningful inclusivity. Here, we focus on developing a\npragmatic ontology of belief systems, which is a complex and often\ncontroversial space. By iterating on our community-based design until mutual\nagreement is reached, we found that epistemological methods were best for\ncategorizing the fundamental ways beliefs differ, maximally respecting our\nprinciples of inclusivity and brevity. We demonstrate our methodology's utility\nand interpretability via user studies in term annotation and sentiment analysis\nexperiments for belief fairness in language models.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "AIES 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.01455v1",
    "published_date": "2024-07-25 09:02:50 UTC",
    "updated_date": "2024-07-25 09:02:50 UTC"
  },
  {
    "arxiv_id": "2407.17881v1",
    "title": "Unraveling the Never-Ending Story of Lifecycles and Vitalizing Processes",
    "authors": [
      "Stephan A. Fahrenkrog-Petersen",
      "Saimir Bala",
      "Luise Pufahl",
      "Jan Mendling"
    ],
    "abstract": "Business process management (BPM) has been widely used to discover, model,\nanalyze, and optimize organizational processes. BPM looks at these processes\nwith analysis techniques that assume a clearly defined start and end. However,\nnot all processes adhere to this logic, with the consequence that their\nbehavior cannot be appropriately captured by BPM analysis techniques. This\npaper addresses this research problem at a conceptual level. More specifically,\nwe introduce the notion of vitalizing business processes that target the\nlifecycle process of one or more entities. We show the existence of lifecycle\nprocesses in many industries and that their appropriate conceptualizations pave\nthe way for the definition of suitable modeling and analysis techniques. This\npaper provides a set of requirements for their analysis, and a\nconceptualization of lifecycle and vitalizing processes.",
    "categories": [
      "cs.DB",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.DB",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.17881v1",
    "published_date": "2024-07-25 08:52:23 UTC",
    "updated_date": "2024-07-25 08:52:23 UTC"
  },
  {
    "arxiv_id": "2407.17879v2",
    "title": "HG-PIPE: Vision Transformer Acceleration with Hybrid-Grained Pipeline",
    "authors": [
      "Qingyu Guo",
      "Jiayong Wan",
      "Songqiang Xu",
      "Meng Li",
      "Yuan Wang"
    ],
    "abstract": "Vision Transformer (ViT) acceleration with field programmable gate array\n(FPGA) is promising but challenging. Existing FPGA-based ViT accelerators\nmainly rely on temporal architectures, which process different operators by\nreusing the same hardware blocks and suffer from extensive memory access\noverhead. Pipelined architectures, either coarse-grained or fine-grained,\nunroll the ViT computation spatially for memory access efficiency. However,\nthey usually suffer from significant hardware resource constraints and pipeline\nbubbles induced by the global computation dependency of ViT. In this paper, we\nintroduce HG-PIPE, a pipelined FPGA accelerator for high-throughput and\nlow-latency ViT processing. HG-PIPE features a hybrid-grained pipeline\narchitecture to reduce on-chip buffer cost and couples the computation dataflow\nand parallelism design to eliminate the pipeline bubbles. HG-PIPE further\nintroduces careful approximations to implement both linear and non-linear\noperators with abundant Lookup Tables (LUTs), thus alleviating resource\nconstraints. On a ZCU102 FPGA, HG-PIPE achieves 2.78 times better throughput\nand 2.52 times better resource efficiency than the prior-art accelerators,\ne.g., AutoViTAcc. With a VCK190 FPGA, HG-PIPE realizes end-to-end ViT\nacceleration on a single device and achieves 7118 images/s, which is 2.81 times\nfaster than a V100 GPU.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "68T07"
    ],
    "primary_category": "cs.AR",
    "comment": "Accepted by ICCAD 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.17879v2",
    "published_date": "2024-07-25 08:47:40 UTC",
    "updated_date": "2024-08-01 08:18:57 UTC"
  },
  {
    "arxiv_id": "2407.18989v4",
    "title": "Machine Learning for Fairness-Aware Load Shedding: A Real-Time Solution via Identifying Binding Constraints",
    "authors": [
      "Yuqi Zhou",
      "Joseph Severino",
      "Sanjana Vijayshankar",
      "Juliette Ugirumurera",
      "Jibo Sanyal"
    ],
    "abstract": "Timely and effective load shedding in power systems is critical for\nmaintaining supply-demand balance and preventing cascading blackouts. To\neliminate load shedding bias against specific regions in the system,\noptimization-based methods are uniquely positioned to help balance between\neconomic and fairness considerations. However, the resulting optimization\nproblem involves complex constraints, which can be time-consuming to solve and\nthus cannot meet the real-time requirements of load shedding. To tackle this\nchallenge, in this paper we present an efficient machine learning algorithm to\nenable millisecond-level computation for the optimization-based load shedding\nproblem. Numerical studies on both a 3-bus toy example and a realistic RTS-GMLC\nsystem have demonstrated the validity and efficiency of the proposed algorithm\nfor delivering fairness-aware and real-time load shedding decisions.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.SY"
    ],
    "primary_category": "eess.SY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.18989v4",
    "published_date": "2024-07-25 08:47:11 UTC",
    "updated_date": "2025-02-27 05:23:19 UTC"
  },
  {
    "arxiv_id": "2407.17874v1",
    "title": "Improving Domain-Specific ASR with LLM-Generated Contextual Descriptions",
    "authors": [
      "Jiwon Suh",
      "Injae Na",
      "Woohwan Jung"
    ],
    "abstract": "End-to-end automatic speech recognition (E2E ASR) systems have significantly\nimproved speech recognition through training on extensive datasets. Despite\nthese advancements, they still struggle to accurately recognize domain specific\nwords, such as proper nouns and technical terminologies. To address this\nproblem, we propose a method to utilize the state-of-the-art Whisper without\nmodifying its architecture, preserving its generalization performance while\nenabling it to leverage descriptions effectively. Moreover, we propose two\nadditional training techniques to improve the domain specific ASR: decoder\nfine-tuning, and context perturbation. We also propose a method to use a Large\nLanguage Model (LLM) to generate descriptions with simple metadata, when\ndescriptions are unavailable. Our experiments demonstrate that proposed methods\nnotably enhance domain-specific ASR accuracy on real-life datasets, with\nLLM-generated descriptions outperforming human-crafted ones in effectiveness.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to INTERSPEECH 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.17874v1",
    "published_date": "2024-07-25 08:44:04 UTC",
    "updated_date": "2024-07-25 08:44:04 UTC"
  },
  {
    "arxiv_id": "2407.17866v3",
    "title": "Financial Statement Analysis with Large Language Models",
    "authors": [
      "Alex Kim",
      "Maximilian Muhn",
      "Valeri Nikolaev"
    ],
    "abstract": "We investigate whether large language models (LLMs) can successfully perform\nfinancial statement analysis in a way similar to a professional human analyst.\nWe provide standardized and anonymous financial statements to GPT4 and instruct\nthe model to analyze them to determine the direction of firms' future earnings.\nEven without narrative or industry-specific information, the LLM outperforms\nfinancial analysts in its ability to predict earnings changes directionally.\nThe LLM exhibits a relative advantage over human analysts in situations when\nthe analysts tend to struggle. Furthermore, we find that the prediction\naccuracy of the LLM is on par with a narrowly trained state-of-the-art ML\nmodel. LLM prediction does not stem from its training memory. Instead, we find\nthat the LLM generates useful narrative insights about a company's future\nperformance. Lastly, our trading strategies based on GPT's predictions yield a\nhigher Sharpe ratio and alphas than strategies based on other models. Our\nresults suggest that LLMs may take a central role in analysis and\ndecision-making.",
    "categories": [
      "q-fin.ST",
      "cs.AI",
      "cs.CL",
      "q-fin.GN",
      "q-fin.PM"
    ],
    "primary_category": "q-fin.ST",
    "comment": "A co-author identified inconsistencies in the data and analyses while\n  attempting to replicate past analyses from the working paper. Accordingly, we\n  have temporarily withdrawn the working paper from circulation while we review\n  the research findings.",
    "pdf_url": "http://arxiv.org/pdf/2407.17866v3",
    "published_date": "2024-07-25 08:36:58 UTC",
    "updated_date": "2025-02-20 18:54:13 UTC"
  },
  {
    "arxiv_id": "2407.17857v1",
    "title": "Mew: Multiplexed Immunofluorescence Image Analysis through an Efficient Multiplex Network",
    "authors": [
      "Sukwon Yun",
      "Jie Peng",
      "Alexandro E. Trevino",
      "Chanyoung Park",
      "Tianlong Chen"
    ],
    "abstract": "Recent advancements in graph-based approaches for multiplexed\nimmunofluorescence (mIF) images have significantly propelled the field forward,\noffering deeper insights into patient-level phenotyping. However, current\ngraph-based methodologies encounter two primary challenges: (1) Cellular\nHeterogeneity, where existing approaches fail to adequately address the\ninductive biases inherent in graphs, particularly the homophily characteristic\nobserved in cellular connectivity and; (2) Scalability, where handling cellular\ngraphs from high-dimensional images faces difficulties in managing a high\nnumber of cells. To overcome these limitations, we introduce Mew, a novel\nframework designed to efficiently process mIF images through the lens of\nmultiplex network. Mew innovatively constructs a multiplex network comprising\ntwo distinct layers: a Voronoi network for geometric information and a\nCell-type network for capturing cell-wise homogeneity. This framework equips a\nscalable and efficient Graph Neural Network (GNN), capable of processing the\nentire graph during training. Furthermore, Mew integrates an interpretable\nattention module that autonomously identifies relevant layers for image\nclassification. Extensive experiments on a real-world patient dataset from\nvarious institutions highlight Mew's remarkable efficacy and efficiency,\nmarking a significant advancement in mIF image analysis. The source code of Mew\ncan be found here: \\url{https://github.com/UNITES-Lab/Mew}",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "ECCV 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.17857v1",
    "published_date": "2024-07-25 08:22:30 UTC",
    "updated_date": "2024-07-25 08:22:30 UTC"
  },
  {
    "arxiv_id": "2407.17854v1",
    "title": "Shapley Value-based Contrastive Alignment for Multimodal Information Extraction",
    "authors": [
      "Wen Luo",
      "Yu Xia",
      "Shen Tianshu",
      "Sujian Li"
    ],
    "abstract": "The rise of social media and the exponential growth of multimodal\ncommunication necessitates advanced techniques for Multimodal Information\nExtraction (MIE). However, existing methodologies primarily rely on direct\nImage-Text interactions, a paradigm that often faces significant challenges due\nto semantic and modality gaps between images and text. In this paper, we\nintroduce a new paradigm of Image-Context-Text interaction, where large\nmultimodal models (LMMs) are utilized to generate descriptive textual context\nto bridge these gaps. In line with this paradigm, we propose a novel Shapley\nValue-based Contrastive Alignment (Shap-CA) method, which aligns both\ncontext-text and context-image pairs. Shap-CA initially applies the Shapley\nvalue concept from cooperative game theory to assess the individual\ncontribution of each element in the set of contexts, texts and images towards\ntotal semantic and modality overlaps. Following this quantitative evaluation, a\ncontrastive learning strategy is employed to enhance the interactive\ncontribution within context-text/image pairs, while minimizing the influence\nacross these pairs. Furthermore, we design an adaptive fusion module for\nselective cross-modal fusion. Extensive experiments across four MIE datasets\ndemonstrate that our method significantly outperforms existing state-of-the-art\nmethods.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.MM"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted at ACM Multimedia 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.17854v1",
    "published_date": "2024-07-25 08:15:43 UTC",
    "updated_date": "2024-07-25 08:15:43 UTC"
  },
  {
    "arxiv_id": "2407.17844v4",
    "title": "Innovative Speech-Based Deep Learning Approaches for Parkinson's Disease Classification: A Systematic Review",
    "authors": [
      "Lisanne van Gelderen",
      "Cristian Tejedor-García"
    ],
    "abstract": "Parkinson's disease (PD), the second most prevalent neurodegenerative\ndisorder worldwide, frequently presents with early-stage speech impairments.\nRecent advancements in Artificial Intelligence (AI), particularly deep learning\n(DL), have significantly enhanced PD diagnosis through the analysis of speech\ndata. Nevertheless, the progress of research is restricted by the limited\navailability of publicly accessible speech-based PD datasets, primarily due to\nprivacy concerns. The goal of this systematic review is to explore the current\nlandscape of speech-based DL approaches for PD classification, based on 33\nscientific works published between January 2020 and March 2024. We discuss\ntheir available resources, capabilities, and potential limitations, and issues\nrelated to bias, explainability, and privacy. Furthermore, this review provides\nan overview of publicly accessible speech-based datasets and open-source\nmaterial for PD. The DL approaches identified are categorized into end-to-end\n(E2E) learning, transfer learning (TL), and deep acoustic feature extraction\n(DAFE). Among E2E approaches, Convolutional Neural Networks (CNNs) are\nprevalent, though Transformers are increasingly popular. E2E approaches face\nchallenges such as limited data and computational resources, especially with\nTransformers. TL addresses these issues by providing more robust PD diagnosis\nand better generalizability across languages. DAFE aims to improve the\nexplainability and interpretability of results by examining the specific\neffects of deep features on both other DL approaches and more traditional\nmachine learning (ML) methods. However, it often underperforms compared to E2E\nand TL approaches.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "van Gelderen, L., & Tejedor-Garc\\'ia, C. (2024). Innovative\n  Speech-Based Deep Learning Approaches for Parkinson's Disease Classification:\n  A Systematic Review. Applied Sciences, 14(17). doi:10.3390/app14177873 This\n  research was funded by the NWO research programme NGF AiNed Fellowship Grants\n  under the project Responsible AI for Voice Diagnostics (RAIVD) - grant number\n  NGF.1607.22.013",
    "pdf_url": "http://arxiv.org/pdf/2407.17844v4",
    "published_date": "2024-07-25 07:58:19 UTC",
    "updated_date": "2024-09-24 06:29:29 UTC"
  },
  {
    "arxiv_id": "2407.17843v2",
    "title": "DragText: Rethinking Text Embedding in Point-based Image Editing",
    "authors": [
      "Gayoon Choi",
      "Taejin Jeong",
      "Sujung Hong",
      "Seong Jae Hwang"
    ],
    "abstract": "Point-based image editing enables accurate and flexible control through\ncontent dragging. However, the role of text embedding during the editing\nprocess has not been thoroughly investigated. A significant aspect that remains\nunexplored is the interaction between text and image embeddings. During the\nprogressive editing in a diffusion model, the text embedding remains constant.\nAs the image embedding increasingly diverges from its initial state, the\ndiscrepancy between the image and text embeddings presents a significant\nchallenge. In this study, we found that the text prompt significantly\ninfluences the dragging process, particularly in maintaining content integrity\nand achieving the desired manipulation. Upon these insights, we propose\nDragText, which optimizes text embedding in conjunction with the dragging\nprocess to pair with the modified image embedding. Simultaneously, we\nregularize the text optimization process to preserve the integrity of the\noriginal text prompt. Our approach can be seamlessly integrated with existing\ndiffusion-based drag methods, enhancing performance with only a few lines of\ncode.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at WACV 2025; Code is released at\n  https://github.com/MICV-yonsei/DragText",
    "pdf_url": "http://arxiv.org/pdf/2407.17843v2",
    "published_date": "2024-07-25 07:57:55 UTC",
    "updated_date": "2024-12-04 07:50:27 UTC"
  },
  {
    "arxiv_id": "2407.17842v1",
    "title": "On the Opportunities of (Re)-Exploring Atmospheric Science by Foundation Models: A Case Study",
    "authors": [
      "Lujia Zhang",
      "Hanzhe Cui",
      "Yurong Song",
      "Chenyue Li",
      "Binhang Yuan",
      "Mengqian Lu"
    ],
    "abstract": "Most state-of-the-art AI applications in atmospheric science are based on\nclassic deep learning approaches. However, such approaches cannot automatically\nintegrate multiple complicated procedures to construct an intelligent agent,\nsince each functionality is enabled by a separate model learned from\nindependent climate datasets. The emergence of foundation models, especially\nmultimodal foundation models, with their ability to process heterogeneous input\ndata and execute complex tasks, offers a substantial opportunity to overcome\nthis challenge. In this report, we want to explore a central question - how the\nstate-of-the-art foundation model, i.e., GPT-4o, performs various atmospheric\nscientific tasks. Toward this end, we conduct a case study by categorizing the\ntasks into four main classes, including climate data processing, physical\ndiagnosis, forecast and prediction, and adaptation and mitigation. For each\ntask, we comprehensively evaluate the GPT-4o's performance along with a\nconcrete discussion. We hope that this report may shed new light on future AI\napplications and research in atmospheric science.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "28 pages, 12 figures",
    "pdf_url": "http://arxiv.org/pdf/2407.17842v1",
    "published_date": "2024-07-25 07:57:34 UTC",
    "updated_date": "2024-07-25 07:57:34 UTC"
  },
  {
    "arxiv_id": "2407.17839v1",
    "title": "Long-term Fairness in Ride-Hailing Platform",
    "authors": [
      "Yufan Kang",
      "Jeffrey Chan",
      "Wei Shao",
      "Flora D. Salim",
      "Christopher Leckie"
    ],
    "abstract": "Matching in two-sided markets such as ride-hailing has recently received\nsignificant attention. However, existing studies on ride-hailing mainly focus\non optimising efficiency, and fairness issues in ride-hailing have been\nneglected. Fairness issues in ride-hailing, including significant earning\ndifferences between drivers and variance of passenger waiting times among\ndifferent locations, have potential impacts on economic and ethical aspects.\nThe recent studies that focus on fairness in ride-hailing exploit traditional\noptimisation methods and the Markov Decision Process to balance efficiency and\nfairness. However, there are several issues in these existing studies, such as\nmyopic short-term decision-making from traditional optimisation and instability\nof fairness in a comparably longer horizon from both traditional optimisation\nand Markov Decision Process-based methods. To address these issues, we propose\na dynamic Markov Decision Process model to alleviate fairness issues currently\nfaced by ride-hailing, and seek a balance between efficiency and fairness, with\ntwo distinct characteristics: (i) a prediction module to predict the number of\nrequests that will be raised in the future from different locations to allow\nthe proposed method to consider long-term fairness based on the whole timeline\ninstead of consider fairness only based on historical and current data\npatterns; (ii) a customised scalarisation function for multi-objective\nmulti-agent Q Learning that aims to balance efficiency and fairness. Extensive\nexperiments on a publicly available real-world dataset demonstrate that our\nproposed method outperforms existing state-of-the-art methods.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted by ECML PKDD 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.17839v1",
    "published_date": "2024-07-25 07:54:07 UTC",
    "updated_date": "2024-07-25 07:54:07 UTC"
  },
  {
    "arxiv_id": "2407.17838v1",
    "title": "UMono: Physical Model Informed Hybrid CNN-Transformer Framework for Underwater Monocular Depth Estimation",
    "authors": [
      "Jian Wang",
      "Jing Wang",
      "Shenghui Rong",
      "Bo He"
    ],
    "abstract": "Underwater monocular depth estimation serves as the foundation for tasks such\nas 3D reconstruction of underwater scenes. However, due to the influence of\nlight and medium, the underwater environment undergoes a distinctive imaging\nprocess, which presents challenges in accurately estimating depth from a single\nimage. The existing methods fail to consider the unique characteristics of\nunderwater environments, leading to inadequate estimation results and limited\ngeneralization performance. Furthermore, underwater depth estimation requires\nextracting and fusing both local and global features, which is not fully\nexplored in existing methods. In this paper, an end-to-end learning framework\nfor underwater monocular depth estimation called UMono is presented, which\nincorporates underwater image formation model characteristics into network\narchitecture, and effectively utilize both local and global features of\nunderwater image. Experimental results demonstrate that the proposed method is\neffective for underwater monocular depth estimation and outperforms the\nexisting methods in both quantitative and qualitative analyses.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.17838v1",
    "published_date": "2024-07-25 07:52:11 UTC",
    "updated_date": "2024-07-25 07:52:11 UTC"
  },
  {
    "arxiv_id": "2407.20272v1",
    "title": "An Efficient Inference Framework for Early-exit Large Language Models",
    "authors": [
      "Ruijie Miao",
      "Yihan Yan",
      "Xinshuo Yao",
      "Tong Yang"
    ],
    "abstract": "Building efficient inference framework has gained increasing interests for\nresearch community. Early-exit models, a variant of LLMs, improves the\ninference efficiency of LLMs by skipping rest layers and directly generate\noutput tokens when they are confident enough. However, there is no work of LLM\ninference framework that takes early-exit models into consideration. This is\nnon-trivial as prior art on LLM inference cannot be directly applied to\nearly-exit models. In this work, we solves two key challenges in building\nefficient inference framework for early-exit models: (1) batch inference at\niteration-level granularity; and (2) KV cache management. For the former, we\npropose to process the batch until all sequences surpass the early-exit\nconfidence threshold. For the latter, we propose to fill the KV cache of rest\nlayers before the iteration terminates. Our evaluation shows that, compared\nwith the original vLLM operating at full layers, our solution achieves up to\n1.25x speed up.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.20272v1",
    "published_date": "2024-07-25 07:50:17 UTC",
    "updated_date": "2024-07-25 07:50:17 UTC"
  },
  {
    "arxiv_id": "2407.17827v2",
    "title": "Unified Lexical Representation for Interpretable Visual-Language Alignment",
    "authors": [
      "Yifan Li",
      "Yikai Wang",
      "Yanwei Fu",
      "Dongyu Ru",
      "Zheng Zhang",
      "Tong He"
    ],
    "abstract": "Visual-Language Alignment (VLA) has gained a lot of attention since CLIP's\ngroundbreaking work. Although CLIP performs well, the typical direct latent\nfeature alignment lacks clarity in its representation and similarity scores. On\nthe other hand, lexical representation, a vector whose element represents the\nsimilarity between the sample and a word from the vocabulary, is a natural\nsparse representation and interpretable, providing exact matches for individual\nwords. However, lexical representations are difficult to learn due to no\nground-truth supervision and false-discovery issues, and thus requires complex\ndesign to train effectively. In this paper, we introduce LexVLA, a more\ninterpretable VLA framework by learning a unified lexical representation for\nboth modalities without complex design. We use DINOv2 as our visual model for\nits local-inclined features and Llama 2, a generative language model, to\nleverage its in-context lexical prediction ability. To avoid the false\ndiscovery, we propose an overuse penalty to refrain the lexical representation\nfrom falsely frequently activating meaningless words. We demonstrate that these\ntwo pre-trained uni-modal models can be well-aligned by fine-tuning on the\nmodest multi-modal dataset and avoid intricate training configurations. On\ncross-modal retrieval benchmarks, LexVLA, trained on the CC-12M multi-modal\ndataset, outperforms baselines fine-tuned on larger datasets (e.g., YFCC15M)\nand those trained from scratch on even bigger datasets (e.g., 1.1B data,\nincluding CC-12M). We conduct extensive experiments to analyze LexVLA. Codes\nare available at https://github.com/Clementine24/LexVLA.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.17827v2",
    "published_date": "2024-07-25 07:35:27 UTC",
    "updated_date": "2024-11-11 13:46:50 UTC"
  },
  {
    "arxiv_id": "2407.17816v1",
    "title": "NC-NCD: Novel Class Discovery for Node Classification",
    "authors": [
      "Yue Hou",
      "Xueyuan Chen",
      "He Zhu",
      "Romei Liu",
      "Bowen Shi",
      "Jiaheng Liu",
      "Junran Wu",
      "Ke Xu"
    ],
    "abstract": "Novel Class Discovery (NCD) involves identifying new categories within\nunlabeled data by utilizing knowledge acquired from previously established\ncategories. However, existing NCD methods often struggle to maintain a balance\nbetween the performance of old and new categories. Discovering unlabeled new\ncategories in a class-incremental way is more practical but also more\nchallenging, as it is frequently hindered by either catastrophic forgetting of\nold categories or an inability to learn new ones. Furthermore, the\nimplementation of NCD on continuously scalable graph-structured data remains an\nunder-explored area. In response to these challenges, we introduce for the\nfirst time a more practical NCD scenario for node classification (i.e.,\nNC-NCD), and propose a novel self-training framework with prototype replay and\ndistillation called SWORD, adopted to our NC-NCD setting. Our approach enables\nthe model to cluster unlabeled new category nodes after learning labeled nodes\nwhile preserving performance on old categories without reliance on old category\nnodes. SWORD achieves this by employing a self-training strategy to learn new\ncategories and preventing the forgetting of old categories through the joint\nuse of feature prototypes and knowledge distillation. Extensive experiments on\nfour common benchmarks demonstrate the superiority of SWORD over other\nstate-of-the-art methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by CIKM'24",
    "pdf_url": "http://arxiv.org/pdf/2407.17816v1",
    "published_date": "2024-07-25 07:10:08 UTC",
    "updated_date": "2024-07-25 07:10:08 UTC"
  },
  {
    "arxiv_id": "2407.20271v3",
    "title": "Learn while Unlearn: An Iterative Unlearning Framework for Generative Language Models",
    "authors": [
      "Haoyu Tang",
      "Ye Liu",
      "Xi Zhao",
      "Xukai Liu",
      "Yanghai Zhang",
      "Kai Zhang",
      "Xiaofang Zhou",
      "Enhong Chen"
    ],
    "abstract": "Recent advances in machine learning, particularly in Natural Language\nProcessing (NLP), have produced powerful models trained on vast datasets.\nHowever, these models risk leaking sensitive information, raising privacy\nconcerns. In response, regulatory measures such as the European Union's General\nData Protection Regulation (GDPR) have driven increasing interest in Machine\nUnlearning techniques, which enable models to selectively forget specific data\nentries. Early unlearning approaches primarily relied on pre-processing\nmethods, while more recent research has shifted towards training-based\nsolutions. Despite their effectiveness, a key limitation persists: most methods\nrequire access to original training data, which is often unavailable.\nAdditionally, directly applying unlearning techniques bears the cost of\nundermining the model's expressive capabilities. To address these challenges,\nwe introduce the Iterative Contrastive Unlearning (ICU) framework, which\nconsists of three core components: A Knowledge Unlearning Induction module\ndesigned to target specific knowledge for removal using an unlearning loss; A\nContrastive Learning Enhancement module to preserve the model's expressive\ncapabilities against the pure unlearning goal; And an Iterative Unlearning\nRefinement module that dynamically adjusts the unlearning process through\nongoing evaluation and updates. Experimental results demonstrate the efficacy\nof our ICU method in unlearning sensitive information while maintaining the\nmodel's overall performance, offering a promising solution for\nprivacy-conscious machine learning applications.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.20271v3",
    "published_date": "2024-07-25 07:09:35 UTC",
    "updated_date": "2025-02-22 02:45:39 UTC"
  },
  {
    "arxiv_id": "2407.17813v1",
    "title": "Enhancing Model Performance: Another Approach to Vision-Language Instruction Tuning",
    "authors": [
      "Vedanshu",
      "MM Tripathi",
      "Bhavnesh Jaint"
    ],
    "abstract": "The integration of large language models (LLMs) with vision-language (VL)\ntasks has been a transformative development in the realm of artificial\nintelligence, highlighting the potential of LLMs as a versatile general-purpose\nchatbot. However, the current trend in this evolution focuses on the\nintegration of vision and language to create models that can operate in more\ndiverse and real-world contexts. We present a novel approach, termed Bottleneck\nAdapter, specifically crafted for enhancing the multimodal functionalities of\nthese complex models, enabling joint optimization of the entire multimodal LLM\nframework through a process known as Multimodal Model Tuning (MMT). Our\napproach utilizes lightweight adapters to connect the image encoder and LLM\nwithout the need for large, complex neural networks. Unlike the conventional\nmodular training schemes, our approach adopts an end-to-end optimization\nregime, which, when combined with the adapters, facilitates the joint\noptimization using a significantly smaller parameter set. Our method exhibits\nrobust performance with 90.12\\% accuracy, outperforming both human-level\nperformance (88.4\\%) and LaVIN-7B (89.41\\%).",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.17813v1",
    "published_date": "2024-07-25 06:59:15 UTC",
    "updated_date": "2024-07-25 06:59:15 UTC"
  },
  {
    "arxiv_id": "2407.17801v1",
    "title": "EEG-SSM: Leveraging State-Space Model for Dementia Detection",
    "authors": [
      "Xuan-The Tran",
      "Linh Le",
      "Quoc Toan Nguyen",
      "Thomas Do",
      "Chin-Teng Lin"
    ],
    "abstract": "State-space models (SSMs) have garnered attention for effectively processing\nlong data sequences, reducing the need to segment time series into shorter\nintervals for model training and inference. Traditionally, SSMs capture only\nthe temporal dynamics of time series data, omitting the equally critical\nspectral features. This study introduces EEG-SSM, a novel state-space\nmodel-based approach for dementia classification using EEG data. Our model\nfeatures two primary innovations: EEG-SSM temporal and EEG-SSM spectral\ncomponents. The temporal component is designed to efficiently process EEG\nsequences of varying lengths, while the spectral component enhances the model\nby integrating frequency-domain information from EEG signals. The synergy of\nthese components allows EEG-SSM to adeptly manage the complexities of\nmultivariate EEG data, significantly improving accuracy and stability across\ndifferent temporal resolutions. Demonstrating a remarkable 91.0 percent\naccuracy in classifying Healthy Control (HC), Frontotemporal Dementia (FTD),\nand Alzheimer's Disease (AD) groups, EEG-SSM outperforms existing models on the\nsame dataset. The development of EEG-SSM represents an improvement in the use\nof state-space models for screening dementia, offering more precise and\ncost-effective tools for clinical neuroscience.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.17801v1",
    "published_date": "2024-07-25 06:20:03 UTC",
    "updated_date": "2024-07-25 06:20:03 UTC"
  },
  {
    "arxiv_id": "2407.17797v1",
    "title": "A Unified Understanding of Adversarial Vulnerability Regarding Unimodal Models and Vision-Language Pre-training Models",
    "authors": [
      "Haonan Zheng",
      "Xinyang Deng",
      "Wen Jiang",
      "Wenrui Li"
    ],
    "abstract": "With Vision-Language Pre-training (VLP) models demonstrating powerful\nmultimodal interaction capabilities, the application scenarios of neural\nnetworks are no longer confined to unimodal domains but have expanded to more\ncomplex multimodal V+L downstream tasks. The security vulnerabilities of\nunimodal models have been extensively examined, whereas those of VLP models\nremain challenging. We note that in CV models, the understanding of images\ncomes from annotated information, while VLP models are designed to learn image\nrepresentations directly from raw text. Motivated by this discrepancy, we\ndeveloped the Feature Guidance Attack (FGA), a novel method that uses text\nrepresentations to direct the perturbation of clean images, resulting in the\ngeneration of adversarial images. FGA is orthogonal to many advanced attack\nstrategies in the unimodal domain, facilitating the direct application of rich\nresearch findings from the unimodal to the multimodal scenario. By\nappropriately introducing text attack into FGA, we construct Feature Guidance\nwith Text Attack (FGA-T). Through the interaction of attacking two modalities,\nFGA-T achieves superior attack effects against VLP models. Moreover,\nincorporating data augmentation and momentum mechanisms significantly improves\nthe black-box transferability of FGA-T. Our method demonstrates stable and\neffective attack capabilities across various datasets, downstream tasks, and\nboth black-box and white-box settings, offering a unified baseline for\nexploring the robustness of VLP models.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "14 pages, 9 figures, published in ACMMM2024(oral)",
    "pdf_url": "http://arxiv.org/pdf/2407.17797v1",
    "published_date": "2024-07-25 06:10:33 UTC",
    "updated_date": "2024-07-25 06:10:33 UTC"
  },
  {
    "arxiv_id": "2407.17791v2",
    "title": "Untrained neural networks can demonstrate memorization-independent abstract reasoning",
    "authors": [
      "Tomer Barak",
      "Yonatan Loewenstein"
    ],
    "abstract": "The nature of abstract reasoning is a matter of debate. Modern artificial\nneural network (ANN) models, like large language models, demonstrate impressive\nsuccess when tested on abstract reasoning problems. However, it has been argued\nthat their success reflects some form of memorization of similar problems (data\ncontamination) rather than a general-purpose abstract reasoning capability.\nThis concern is supported by evidence of brittleness, and the requirement of\nextensive training. In our study, we explored whether abstract reasoning can be\nachieved using the toolbox of ANNs, without prior training. Specifically, we\nstudied an ANN model in which the weights of a naive network are optimized\nduring the solution of the problem, using the problem data itself, rather than\nany prior knowledge. We tested this modeling approach on visual reasoning\nproblems and found that it performs relatively well. Crucially, this success\ndoes not rely on memorization of similar problems. We further suggest an\nexplanation of how it works. Finally, as problem solving is performed by\nchanging the ANN weights, we explored the connection between problem solving\nand the accumulation of knowledge in the ANNs.",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.17791v2",
    "published_date": "2024-07-25 05:58:58 UTC",
    "updated_date": "2024-11-08 13:45:38 UTC"
  },
  {
    "arxiv_id": "2407.17789v2",
    "title": "Very Large-Scale Multi-Agent Simulation in AgentScope",
    "authors": [
      "Xuchen Pan",
      "Dawei Gao",
      "Yuexiang Xie",
      "Yushuo Chen",
      "Zhewei Wei",
      "Yaliang Li",
      "Bolin Ding",
      "Ji-Rong Wen",
      "Jingren Zhou"
    ],
    "abstract": "Recent advances in large language models (LLMs) have opened new avenues for\napplying multi-agent systems in very large-scale simulations. However, there\nremain several challenges when conducting multi-agent simulations with existing\nplatforms, such as limited scalability and low efficiency, unsatisfied agent\ndiversity, and effort-intensive management processes. To address these\nchallenges, we develop several new features and components for AgentScope, a\nuser-friendly multi-agent platform, enhancing its convenience and flexibility\nfor supporting very large-scale multi-agent simulations. Specifically, we\npropose an actor-based distributed mechanism as the underlying technological\ninfrastructure towards great scalability and high efficiency, and provide\nflexible environment support for simulating various real-world scenarios, which\nenables parallel execution of multiple agents, automatic workflow conversion\nfor distributed deployment, and both inter-agent and agent-environment\ninteractions. Moreover, we integrate an easy-to-use configurable tool and an\nautomatic background generation pipeline in AgentScope, simplifying the process\nof creating agents with diverse yet detailed background settings. Last but not\nleast, we provide a web-based interface for conveniently monitoring and\nmanaging a large number of agents that might deploy across multiple devices. We\nconduct a comprehensive simulation to demonstrate the effectiveness of these\nproposed enhancements in AgentScope, and provide detailed observations and\ninsightful discussions to highlight the great potential of applying multi-agent\nsystems in large-scale simulations. The source code is released on GitHub at\nhttps://github.com/modelscope/agentscope/tree/main/examples/paper_large_scale_simulation\nto inspire further research and development in large-scale multi-agent\nsimulations.",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "primary_category": "cs.MA",
    "comment": "We have released code on\n  https://github.com/modelscope/agentscope/tree/main/examples/paper_large_scale_simulation",
    "pdf_url": "http://arxiv.org/pdf/2407.17789v2",
    "published_date": "2024-07-25 05:50:46 UTC",
    "updated_date": "2024-10-28 13:19:38 UTC"
  },
  {
    "arxiv_id": "2407.17787v1",
    "title": "HC-GST: Heterophily-aware Distribution Consistency based Graph Self-training",
    "authors": [
      "Fali Wang",
      "Tianxiang Zhao",
      "Junjie Xu",
      "Suhang Wang"
    ],
    "abstract": "Graph self-training (GST), which selects and assigns pseudo-labels to\nunlabeled nodes, is popular for tackling label sparsity in graphs. However,\nrecent study on homophily graphs show that GST methods could introduce and\namplify distribution shift between training and test nodes as they tend to\nassign pseudo-labels to nodes they are good at. As GNNs typically perform\nbetter on homophilic nodes, there could be potential shifts towards homophilic\npseudo-nodes, which is underexplored. Our preliminary experiments on\nheterophilic graphs verify that these methods can cause shifts in homophily\nratio distributions, leading to \\textit{training bias} that improves\nperformance on homophilic nodes while degrading it on heterophilic ones.\nTherefore, we study a novel problem of reducing homophily ratio distribution\nshifts during self-training on heterophilic graphs. A key challenge is the\naccurate calculation of homophily ratios and their distributions without\nextensive labeled data. To tackle them, we propose a novel Heterophily-aware\nDistribution Consistency-based Graph Self-Training (HC-GST) framework, which\nestimates homophily ratios using soft labels and optimizes a selection vector\nto align pseudo-nodes with the global homophily ratio distribution. Extensive\nexperiments on both homophilic and heterophilic graphs show that HC-GST\neffectively reduces training bias and enhances self-training performance.",
    "categories": [
      "cs.SI",
      "cs.AI"
    ],
    "primary_category": "cs.SI",
    "comment": "accepted by CIKM 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.17787v1",
    "published_date": "2024-07-25 05:38:06 UTC",
    "updated_date": "2024-07-25 05:38:06 UTC"
  },
  {
    "arxiv_id": "2407.17783v1",
    "title": "How Lightweight Can A Vision Transformer Be",
    "authors": [
      "Jen Hong Tan"
    ],
    "abstract": "In this paper, we explore a strategy that uses Mixture-of-Experts (MoE) to\nstreamline, rather than augment, vision transformers. Each expert in an MoE\nlayer is a SwiGLU feedforward network, where V and W2 are shared across the\nlayer. No complex attention or convolutional mechanisms are employed.\nDepth-wise scaling is applied to progressively reduce the size of the hidden\nlayer and the number of experts is increased in stages. Grouped query attention\nis used. We studied the proposed approach with and without pre-training on\nsmall datasets and investigated whether transfer learning works at this scale.\nWe found that the architecture is competitive even at a size of 0.67M\nparameters.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.17783v1",
    "published_date": "2024-07-25 05:23:20 UTC",
    "updated_date": "2024-07-25 05:23:20 UTC"
  },
  {
    "arxiv_id": "2407.17777v2",
    "title": "Babel: A Scalable Pre-trained Model for Multi-Modal Sensing via Expandable Modality Alignment",
    "authors": [
      "Shenghong Dai",
      "Shiqi Jiang",
      "Yifan Yang",
      "Ting Cao",
      "Mo Li",
      "Suman Banerjee",
      "Lili Qiu"
    ],
    "abstract": "This paper presents Babel, the expandable modality alignment model, specially\ndesigned for multi-modal sensing. While there has been considerable work on\nmulti-modality alignment, they all struggle to effectively incorporate multiple\nsensing modalities due to the data scarcity constraints. How to utilize\nmulti-modal data with partial pairings in sensing remains an unresolved\nchallenge. Babel tackles this challenge by introducing the concept of\nexpandable modality alignment. The key idea involves transforming the\nN-modality alignment into a series of binary-modality alignments. Novel\ntechniques are also proposed to further mitigate data scarcity issue and\nbalance the contribution of the newly incorporated modality with the previously\nestablished modality alignment during the expandable alignment process. We\nprovide the comprehensive implementation. In the pre-training phase, Babel\ncurrently aligns 6 sensing modalities, namely Wi-Fi, mmWave, IMU, LiDAR, video,\nand depth. For the deployment phase, as a foundation model, any single or\ncombination of aligned modalities could be selected from Babel and applied to\ndownstream tasks. Evaluation demonstrates Babel's outstanding performance on\neight human activity recognition datasets, compared to a broad range of\nbaselines e.g., the SOTA single-modal sensing networks, multi-modal sensing\nframework, and multi-modal large language models. Babel not only improves the\nperformance of individual modality sensing (12% averaged accuracy improvement),\nbut also effectively fuses multiple available modalities (up to 22% accuracy\nincrease). Case studies also highlight emerging application scenarios empowered\nby Babel, including cross-modality retrieval (i.e., sensing imaging), and\nbridging LLM for sensing comprehension.",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "eess.SP"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted by SenSys'25",
    "pdf_url": "http://arxiv.org/pdf/2407.17777v2",
    "published_date": "2024-07-25 05:10:48 UTC",
    "updated_date": "2025-03-21 10:51:22 UTC"
  },
  {
    "arxiv_id": "2408.00588v1",
    "title": "Closing the gap between open-source and commercial large language models for medical evidence summarization",
    "authors": [
      "Gongbo Zhang",
      "Qiao Jin",
      "Yiliang Zhou",
      "Song Wang",
      "Betina R. Idnay",
      "Yiming Luo",
      "Elizabeth Park",
      "Jordan G. Nestor",
      "Matthew E. Spotnitz",
      "Ali Soroush",
      "Thomas Campion",
      "Zhiyong Lu",
      "Chunhua Weng",
      "Yifan Peng"
    ],
    "abstract": "Large language models (LLMs) hold great promise in summarizing medical\nevidence. Most recent studies focus on the application of proprietary LLMs.\nUsing proprietary LLMs introduces multiple risk factors, including a lack of\ntransparency and vendor dependency. While open-source LLMs allow better\ntransparency and customization, their performance falls short compared to\nproprietary ones. In this study, we investigated to what extent fine-tuning\nopen-source LLMs can further improve their performance in summarizing medical\nevidence. Utilizing a benchmark dataset, MedReview, consisting of 8,161 pairs\nof systematic reviews and summaries, we fine-tuned three broadly-used,\nopen-sourced LLMs, namely PRIMERA, LongT5, and Llama-2. Overall, the fine-tuned\nLLMs obtained an increase of 9.89 in ROUGE-L (95% confidence interval:\n8.94-10.81), 13.21 in METEOR score (95% confidence interval: 12.05-14.37), and\n15.82 in CHRF score (95% confidence interval: 13.89-16.44). The performance of\nfine-tuned LongT5 is close to GPT-3.5 with zero-shot settings. Furthermore,\nsmaller fine-tuned models sometimes even demonstrated superior performance\ncompared to larger zero-shot models. The above trends of improvement were also\nmanifested in both human and GPT4-simulated evaluations. Our results can be\napplied to guide model selection for tasks demanding particular domain\nknowledge, such as medical evidence summarization.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.00588v1",
    "published_date": "2024-07-25 05:03:01 UTC",
    "updated_date": "2024-07-25 05:03:01 UTC"
  },
  {
    "arxiv_id": "2407.17773v3",
    "title": "KiVA: Kid-inspired Visual Analogies for Testing Large Multimodal Models",
    "authors": [
      "Eunice Yiu",
      "Maan Qraitem",
      "Anisa Noor Majhi",
      "Charlie Wong",
      "Yutong Bai",
      "Shiry Ginosar",
      "Alison Gopnik",
      "Kate Saenko"
    ],
    "abstract": "This paper investigates visual analogical reasoning in large multimodal\nmodels (LMMs) compared to human adults and children. A \"visual analogy\" is an\nabstract rule inferred from one image and applied to another. While benchmarks\nexist for testing visual reasoning in LMMs, they require advanced skills and\nomit basic visual analogies that even young children can make. Inspired by\ndevelopmental psychology, we propose a new benchmark of 4,300 visual\ntransformations of everyday objects to test LMMs on visual analogical reasoning\nand compare them to children (ages three to five) and to adults. We structure\nthe evaluation into three stages: identifying what changed (e.g., color,\nnumber, etc.), how it changed (e.g., added one object), and applying the rule\nto new scenarios. Our findings show that while GPT-o1, GPT-4V, LLaVA-1.5, and\nMANTIS identify the \"what\" effectively, they struggle with quantifying the\n\"how\" and extrapolating this rule to new objects. In contrast, children and\nadults exhibit much stronger analogical reasoning at all three stages.\nAdditionally, the strongest tested model, GPT-o1, performs better in tasks\ninvolving simple surface-level visual attributes like color and size,\ncorrelating with quicker human adult response times. Conversely, more complex\ntasks such as number, rotation, and reflection, which necessitate extensive\ncognitive processing and understanding of extrinsic spatial properties in the\nphysical world, present more significant challenges. Altogether, these findings\nhighlight the limitations of training models on data that primarily consists of\n2D images and text.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "10 pages. Project website: https://ey242.github.io/kiva.github.io/.\n  Benchmark and code: https://github.com/ey242/KiVA",
    "pdf_url": "http://arxiv.org/pdf/2407.17773v3",
    "published_date": "2024-07-25 05:02:39 UTC",
    "updated_date": "2025-03-05 03:07:12 UTC"
  },
  {
    "arxiv_id": "2407.17762v1",
    "title": "Mpox Detection Advanced: Rapid Epidemic Response Through Synthetic Data",
    "authors": [
      "Yudara Kularathne",
      "Prathapa Janitha",
      "Sithira Ambepitiya",
      "Prarththanan Sothyrajah",
      "Thanveer Ahamed",
      "Dinuka Wijesundara"
    ],
    "abstract": "Rapid development of disease detection models using computer vision is\ncrucial in responding to medical emergencies, such as epidemics or bioterrorism\nevents. Traditional data collection methods are often too slow in these\nscenarios, requiring innovative approaches for quick, reliable model generation\nfrom minimal data. Our study introduces a novel approach by constructing a\ncomprehensive computer vision model to detect Mpox lesions using only synthetic\ndata. Initially, these models generated a diverse set of synthetic images\nrepresenting Mpox lesions on various body parts (face, back, chest, leg, neck,\narm) across different skin tones as defined by the Fitzpatrick scale (fair,\nbrown, dark skin). Subsequently, we trained and tested a vision model with this\nsynthetic dataset to evaluate the diffusion models' efficacy in producing\nhigh-quality training data and its impact on the vision model's medical image\nrecognition performance. The results were promising; the vision model achieved\na 97% accuracy rate, with 96% precision and recall for Mpox cases, and\nsimilarly high metrics for normal and other skin disorder cases, demonstrating\nits ability to correctly identify true positives and minimize false positives.\nThe model achieved an F1-Score of 96% for Mpox cases and 98% for normal and\nother skin disorders, reflecting a balanced precision-recall relationship, thus\nensuring reliability and robustness in its predictions. Our proposed\nSynthVision methodology indicates the potential to develop accurate computer\nvision models with minimal data input for future medical emergencies.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "8 pages, 4 figures, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2407.17762v1",
    "published_date": "2024-07-25 04:33:19 UTC",
    "updated_date": "2024-07-25 04:33:19 UTC"
  },
  {
    "arxiv_id": "2407.17760v1",
    "title": "TwIPS: A Large Language Model Powered Texting Application to Simplify Conversational Nuances for Autistic Users",
    "authors": [
      "Rukhshan Haroon",
      "Fahad Dogar"
    ],
    "abstract": "Autistic individuals often experience difficulties in conveying and\ninterpreting emotional tone and non-literal nuances. Many also mask their\ncommunication style to avoid being misconstrued by others, spending\nconsiderable time and mental effort in the process. To address these challenges\nin text-based communication, we present TwIPS, a prototype texting application\npowered by a large language model (LLM), which can assist users with: a)\ndeciphering tone and meaning of incoming messages, b) ensuring the emotional\ntone of their message is in line with their intent, and c) coming up with\nalternate phrasing for messages that could be misconstrued and received\nnegatively by others. We leverage an AI-based simulation and a conversational\nscript to evaluate TwIPS with 8 autistic participants in an in-lab setting. Our\nfindings show TwIPS enables a convenient way for participants to seek\nclarifications, provides a better alternative to tone indicators, and\nfacilitates constructive reflection on writing technique and style. We also\nexamine how autistic users utilize language for self-expression and\ninterpretation in instant messaging, and gather feedback for enhancing our\nprototype. We conclude with a discussion around balancing user-autonomy with\nAI-mediation, establishing appropriate trust levels in AI systems, and\ncustomization needs if autistic users in the context of AI-assisted\ncommunication",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.17760v1",
    "published_date": "2024-07-25 04:15:54 UTC",
    "updated_date": "2024-07-25 04:15:54 UTC"
  },
  {
    "arxiv_id": "2407.17734v1",
    "title": "Cost-effective Instruction Learning for Pathology Vision and Language Analysis",
    "authors": [
      "Kaitao Chen",
      "Mianxin Liu",
      "Fang Yan",
      "Lei Ma",
      "Xiaoming Shi",
      "Lilong Wang",
      "Xiaosong Wang",
      "Lifeng Zhu",
      "Zhe Wang",
      "Mu Zhou",
      "Shaoting Zhang"
    ],
    "abstract": "The advent of vision-language models fosters the interactive conversations\nbetween AI-enabled models and humans. Yet applying these models into clinics\nmust deal with daunting challenges around large-scale training data, financial,\nand computational resources. Here we propose a cost-effective instruction\nlearning framework for conversational pathology named as CLOVER. CLOVER only\ntrains a lightweight module and uses instruction tuning while freezing the\nparameters of the large language model. Instead of using costly GPT-4, we\npropose well-designed prompts on GPT-3.5 for building generation-based\ninstructions, emphasizing the utility of pathological knowledge derived from\nthe Internet source. To augment the use of instructions, we construct a\nhigh-quality set of template-based instructions in the context of digital\npathology. From two benchmark datasets, our findings reveal the strength of\nhybrid-form instructions in the visual question-answer in pathology. Extensive\nresults show the cost-effectiveness of CLOVER in answering both open-ended and\nclosed-ended questions, where CLOVER outperforms strong baselines that possess\n37 times more training parameters and use instruction data generated from\nGPT-4. Through the instruction tuning, CLOVER exhibits robustness of few-shot\nlearning in the external clinical dataset. These findings demonstrate that\ncost-effective modeling of CLOVER could accelerate the adoption of rapid\nconversational applications in the landscape of digital pathology.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.17734v1",
    "published_date": "2024-07-25 03:12:57 UTC",
    "updated_date": "2024-07-25 03:12:57 UTC"
  },
  {
    "arxiv_id": "2407.21057v1",
    "title": "Multi-group Uncertainty Quantification for Long-form Text Generation",
    "authors": [
      "Terrance Liu",
      "Zhiwei Steven Wu"
    ],
    "abstract": "While large language models are rapidly moving towards consumer-facing\napplications, they are often still prone to factual errors and hallucinations.\nIn order to reduce the potential harms that may come from these errors, it is\nimportant for users to know to what extent they can trust an LLM when it makes\na factual claim. To this end, we study the problem of uncertainty\nquantification of factual correctness in long-form natural language generation.\nGiven some output from a large language model, we study both uncertainty at the\nlevel of individual claims contained within the output (via calibration) and\nuncertainty across the entire output itself (via conformal prediction).\nMoreover, we invoke multicalibration and multivalid conformal prediction to\nensure that such uncertainty guarantees are valid both marginally and across\ndistinct groups of prompts. Using the task of biography generation, we\ndemonstrate empirically that having access to and making use of additional\ngroup attributes for each prompt improves both overall and group-wise\nperformance. As the problems of calibration, conformal prediction, and their\nmulti-group counterparts have not been extensively explored previously in the\ncontext of long-form text generation, we consider these empirical results to\nform a benchmark for this setting.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.21057v1",
    "published_date": "2024-07-25 02:59:52 UTC",
    "updated_date": "2024-07-25 02:59:52 UTC"
  },
  {
    "arxiv_id": "2407.17695v2",
    "title": "Enhancing Agent Learning through World Dynamics Modeling",
    "authors": [
      "Zhiyuan Sun",
      "Haochen Shi",
      "Marc-Alexandre Côté",
      "Glen Berseth",
      "Xingdi Yuan",
      "Bang Liu"
    ],
    "abstract": "Large language models (LLMs) have been increasingly applied to tasks in\nlanguage understanding and interactive decision-making, with their impressive\nperformance largely attributed to the extensive domain knowledge embedded\nwithin them. However, the depth and breadth of this knowledge can vary across\ndomains. Many existing approaches assume that LLMs possess a comprehensive\nunderstanding of their environment, often overlooking potential gaps in their\ngrasp of actual world dynamics. To address this, we introduce Discover, Verify,\nand Evolve (DiVE), a framework that discovers world dynamics from a small\nnumber of demonstrations, verifies the accuracy of these dynamics, and evolves\nnew, advanced dynamics tailored to the current situation. Through extensive\nevaluations, we assess the impact of each component on performance and compare\nthe dynamics generated by DiVE to human-annotated dynamics. Our results show\nthat LLMs guided by DiVE make more informed decisions, achieving rewards\ncomparable to human players in the Crafter environment and surpassing methods\nthat require prior task-specific training in the MiniHack environment.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.17695v2",
    "published_date": "2024-07-25 01:32:41 UTC",
    "updated_date": "2024-10-15 15:48:04 UTC"
  },
  {
    "arxiv_id": "2407.17688v2",
    "title": "Examining the Influence of Political Bias on Large Language Model Performance in Stance Classification",
    "authors": [
      "Lynnette Hui Xian Ng",
      "Iain Cruickshank",
      "Roy Ka-Wei Lee"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities in\nexecuting tasks based on natural language queries. However, these models,\ntrained on curated datasets, inherently embody biases ranging from racial to\nnational and gender biases. It remains uncertain whether these biases impact\nthe performance of LLMs for certain tasks. In this study, we investigate the\npolitical biases of LLMs within the stance classification task, specifically\nexamining whether these models exhibit a tendency to more accurately classify\npolitically-charged stances. Utilizing three datasets, seven LLMs, and four\ndistinct prompting schemes, we analyze the performance of LLMs on politically\noriented statements and targets. Our findings reveal a statistically\nsignificant difference in the performance of LLMs across various politically\noriented stance classification tasks. Furthermore, we observe that this\ndifference primarily manifests at the dataset level, with models and prompting\nschemes showing statistically similar performances across different stance\nclassification datasets. Lastly, we observe that when there is greater\nambiguity in the target the statement is directed towards, LLMs have poorer\nstance classification accuracy.\n  Code & Dataset: http://doi.org/10.5281/zenodo.12938478",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at ICWSM 2025",
    "pdf_url": "http://arxiv.org/pdf/2407.17688v2",
    "published_date": "2024-07-25 01:11:38 UTC",
    "updated_date": "2024-07-26 12:47:13 UTC"
  },
  {
    "arxiv_id": "2407.17687v2",
    "title": "A Crowding Distance That Provably Solves the Difficulties of the NSGA-II in Many-Objective Optimization",
    "authors": [
      "Weijie Zheng",
      "Yao Gao",
      "Benjamin Doerr"
    ],
    "abstract": "Recent theoretical works have shown that the NSGA-II can have enormous\ndifficulties to solve problems with more than two objectives. In contrast,\nalgorithms like the NSGA-III or SMS-EMOA, differing from the NSGA-II only in\nthe secondary selection criterion, provably perform well in these situations.\n  To remedy this shortcoming of the NSGA-II, but at the same time keep the\nadvantages of the widely accepted crowding distance, we use the insights of\nthese previous work to define a variant of the crowding distance, called\ntruthful crowding distance. Different from the classic crowding distance, it\nhas for any number of objectives the desirable property that a small crowding\ndistance value indicates that some other solution has a similar objective\nvector.\n  Building on this property, we conduct mathematical runtime analyses for the\nNSGA-II with truthful crowding distance. We show that this algorithm can solve\nthe many-objective versions of the OneMinMax, COCZ, LOTZ, and OJZJ$_k$ problems\nin the same (polynomial) asymptotic runtimes as the NSGA-III and the SMS-EMOA.\nThis contrasts the exponential lower bounds previously shown for the classic\nNSGA-II. For the bi-objective versions of these problems, our NSGA-II has a\nsimilar performance as the classic NSGA-II, gaining however from smaller\nadmissible population sizes. For the bi-objective OneMinMax problem, we also\nobserve a (minimally) better performance in approximating the Pareto front.\n  These results suggest that our truthful version of the NSGA-II has the same\ngood performance as the classic NSGA-II in two objectives, but can resolve the\ndrastic problems in more than two objectives.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.17687v2",
    "published_date": "2024-07-25 01:09:58 UTC",
    "updated_date": "2024-08-18 09:35:27 UTC"
  }
]