[
  {
    "arxiv_id": "2504.16078v1",
    "title": "LLMs are Greedy Agents: Effects of RL Fine-tuning on Decision-Making Abilities",
    "authors": [
      "Thomas Schmied",
      "Jörg Bornschein",
      "Jordi Grau-Moya",
      "Markus Wulfmeier",
      "Razvan Pascanu"
    ],
    "abstract": "The success of Large Language Models (LLMs) has sparked interest in various\nagentic applications. A key hypothesis is that LLMs, leveraging common sense\nand Chain-of-Thought (CoT) reasoning, can effectively explore and efficiently\nsolve complex domains. However, LLM agents have been found to suffer from\nsub-optimal exploration and the knowing-doing gap, the inability to effectively\nact on knowledge present in the model. In this work, we systematically study\nwhy LLMs perform sub-optimally in decision-making scenarios. In particular, we\nclosely examine three prevalent failure modes: greediness, frequency bias, and\nthe knowing-doing gap. We propose mitigation of these shortcomings by\nfine-tuning via Reinforcement Learning (RL) on self-generated CoT rationales.\nOur experiments across multi-armed bandits, contextual bandits, and\nTic-tac-toe, demonstrate that RL fine-tuning enhances the decision-making\nabilities of LLMs by increasing exploration and narrowing the knowing-doing\ngap. Finally, we study both classic exploration mechanisms, such as\n$\\epsilon$-greedy, and LLM-specific approaches, such as self-correction and\nself-consistency, to enable more effective fine-tuning of LLMs for\ndecision-making.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16078v1",
    "published_date": "2025-04-22 17:57:14 UTC",
    "updated_date": "2025-04-22 17:57:14 UTC"
  },
  {
    "arxiv_id": "2504.16072v1",
    "title": "Describe Anything: Detailed Localized Image and Video Captioning",
    "authors": [
      "Long Lian",
      "Yifan Ding",
      "Yunhao Ge",
      "Sifei Liu",
      "Hanzi Mao",
      "Boyi Li",
      "Marco Pavone",
      "Ming-Yu Liu",
      "Trevor Darrell",
      "Adam Yala",
      "Yin Cui"
    ],
    "abstract": "Generating detailed and accurate descriptions for specific regions in images\nand videos remains a fundamental challenge for vision-language models. We\nintroduce the Describe Anything Model (DAM), a model designed for detailed\nlocalized captioning (DLC). DAM preserves both local details and global context\nthrough two key innovations: a focal prompt, which ensures high-resolution\nencoding of targeted regions, and a localized vision backbone, which integrates\nprecise localization with its broader context. To tackle the scarcity of\nhigh-quality DLC data, we propose a Semi-supervised learning (SSL)-based Data\nPipeline (DLC-SDP). DLC-SDP starts with existing segmentation datasets and\nexpands to unlabeled web images using SSL. We introduce DLC-Bench, a benchmark\ndesigned to evaluate DLC without relying on reference captions. DAM sets new\nstate-of-the-art on 7 benchmarks spanning keyword-level, phrase-level, and\ndetailed multi-sentence localized image and video captioning.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Project page: https://describe-anything.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2504.16072v1",
    "published_date": "2025-04-22 17:51:41 UTC",
    "updated_date": "2025-04-22 17:51:41 UTC"
  },
  {
    "arxiv_id": "2504.16061v1",
    "title": "Vision language models are unreliable at trivial spatial cognition",
    "authors": [
      "Sangeet Khemlani",
      "Tyler Tran",
      "Nathaniel Gyory",
      "Anthony M. Harrison",
      "Wallace E. Lawson",
      "Ravenna Thielstrom",
      "Hunter Thompson",
      "Taaren Singh",
      "J. Gregory Trafton"
    ],
    "abstract": "Vision language models (VLMs) are designed to extract relevant visuospatial\ninformation from images. Some research suggests that VLMs can exhibit humanlike\nscene understanding, while other investigations reveal difficulties in their\nability to process relational information. To achieve widespread applicability,\nVLMs must perform reliably, yielding comparable competence across a wide\nvariety of related tasks. We sought to test how reliable these architectures\nare at engaging in trivial spatial cognition, e.g., recognizing whether one\nobject is left of another in an uncluttered scene. We developed a benchmark\ndataset -- TableTest -- whose images depict 3D scenes of objects arranged on a\ntable, and used it to evaluate state-of-the-art VLMs. Results show that\nperformance could be degraded by minor variations of prompts that use logically\nequivalent descriptions. These analyses suggest limitations in how VLMs may\nreason about spatial relations in real-world applications. They also reveal\nnovel opportunities for bolstering image caption corpora for more efficient\ntraining and testing.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16061v1",
    "published_date": "2025-04-22 17:38:01 UTC",
    "updated_date": "2025-04-22 17:38:01 UTC"
  },
  {
    "arxiv_id": "2504.16053v1",
    "title": "LongMamba: Enhancing Mamba's Long Context Capabilities via Training-Free Receptive Field Enlargement",
    "authors": [
      "Zhifan Ye",
      "Kejing Xia",
      "Yonggan Fu",
      "Xin Dong",
      "Jihoon Hong",
      "Xiangchi Yuan",
      "Shizhe Diao",
      "Jan Kautz",
      "Pavlo Molchanov",
      "Yingyan Celine Lin"
    ],
    "abstract": "State space models (SSMs) have emerged as an efficient alternative to\nTransformer models for language modeling, offering linear computational\ncomplexity and constant memory usage as context length increases. However,\ndespite their efficiency in handling long contexts, recent studies have shown\nthat SSMs, such as Mamba models, generally underperform compared to\nTransformers in long-context understanding tasks. To address this significant\nshortfall and achieve both efficient and accurate long-context understanding,\nwe propose LongMamba, a training-free technique that significantly enhances the\nlong-context capabilities of Mamba models. LongMamba builds on our discovery\nthat the hidden channels in Mamba can be categorized into local and global\nchannels based on their receptive field lengths, with global channels primarily\nresponsible for long-context capability. These global channels can become the\nkey bottleneck as the input context lengthens. Specifically, when input lengths\nlargely exceed the training sequence length, global channels exhibit\nlimitations in adaptively extend their receptive fields, leading to Mamba's\npoor long-context performance. The key idea of LongMamba is to mitigate the\nhidden state memory decay in these global channels by preventing the\naccumulation of unimportant tokens in their memory. This is achieved by first\nidentifying critical tokens in the global channels and then applying token\nfiltering to accumulate only those critical tokens. Through extensive\nbenchmarking across synthetic and real-world long-context scenarios, LongMamba\nsets a new standard for Mamba's long-context performance, significantly\nextending its operational range without requiring additional training. Our code\nis available at https://github.com/GATECH-EIC/LongMamba.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.16053v1",
    "published_date": "2025-04-22 17:30:36 UTC",
    "updated_date": "2025-04-22 17:30:36 UTC"
  },
  {
    "arxiv_id": "2504.16047v1",
    "title": "Evaluating Vision Language Models (VLMs) for Radiology: A Comprehensive Analysis",
    "authors": [
      "Frank Li",
      "Hari Trivedi",
      "Bardia Khosravi",
      "Theo Dapamede",
      "Mohammadreza Chavoshi",
      "Abdulhameed Dere",
      "Rohan Satya Isaac",
      "Aawez Mansuri",
      "Janice Newsome",
      "Saptarshi Purkayastha",
      "Judy Gichoya"
    ],
    "abstract": "Foundation models, trained on vast amounts of data using self-supervised\ntechniques, have emerged as a promising frontier for advancing artificial\nintelligence (AI) applications in medicine. This study evaluates three\ndifferent vision-language foundation models (RAD-DINO, CheXagent, and\nBiomedCLIP) on their ability to capture fine-grained imaging features for\nradiology tasks. The models were assessed across classification, segmentation,\nand regression tasks for pneumothorax and cardiomegaly on chest radiographs.\nSelf-supervised RAD-DINO consistently excelled in segmentation tasks, while\ntext-supervised CheXagent demonstrated superior classification performance.\nBiomedCLIP showed inconsistent performance across tasks. A custom segmentation\nmodel that integrates global and local features substantially improved\nperformance for all foundation models, particularly for challenging\npneumothorax segmentation. The findings highlight that pre-training methodology\nsignificantly influences model performance on specific downstream tasks. For\nfine-grained segmentation tasks, models trained without text supervision\nperformed better, while text-supervised models offered advantages in\nclassification and interpretability. These insights provide guidance for\nselecting foundation models based on specific clinical applications in\nradiology.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16047v1",
    "published_date": "2025-04-22 17:20:34 UTC",
    "updated_date": "2025-04-22 17:20:34 UTC"
  },
  {
    "arxiv_id": "2504.16042v1",
    "title": "Approximate matrices of systems of max-min fuzzy relational equations",
    "authors": [
      "Ismaïl Baaj"
    ],
    "abstract": "In this article, we address the inconsistency of a system of max-min fuzzy\nrelational equations by minimally modifying the matrix governing the system in\norder to achieve consistency. Our method yields consistent systems that\napproximate the original inconsistent system in the following sense: the\nright-hand side vector of each consistent system is that of the inconsistent\nsystem, and the coefficients of the matrix governing each consistent system are\nobtained by modifying, exactly and minimally, the entries of the original\nmatrix that must be corrected to achieve consistency, while leaving all other\nentries unchanged.\n  To obtain a consistent system that closely approximates the considered\ninconsistent system, we study the distance (in terms of a norm among $L_1$,\n$L_2$ or $L_\\infty$) between the matrix of the inconsistent system and the set\nformed by the matrices of consistent systems that use the same right-hand side\nvector as the inconsistent system. We show that our method allows us to\ndirectly compute matrices of consistent systems that use the same right-hand\nside vector as the inconsistent system whose distance in terms of $L_\\infty$\nnorm to the matrix of the inconsistent system is minimal (the computational\ncosts are higher when using $L_1$ norm or $L_2$ norm). We also give an explicit\nanalytical formula for computing this minimal $L_\\infty$ distance. Finally, we\ntranslate our results for systems of min-max fuzzy relational equations and\npresent some potential applications.",
    "categories": [
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16042v1",
    "published_date": "2025-04-22 17:09:02 UTC",
    "updated_date": "2025-04-22 17:09:02 UTC"
  },
  {
    "arxiv_id": "2504.16041v1",
    "title": "Muon Optimizer Accelerates Grokking",
    "authors": [
      "Amund Tveit",
      "Bjørn Remseth",
      "Arve Skogvold"
    ],
    "abstract": "This paper investigates the impact of different optimizers on the grokking\nphenomenon, where models exhibit delayed generalization. We conducted\nexperiments across seven numerical tasks (primarily modular arithmetic) using a\nmodern Transformer architecture. The experimental configuration systematically\nvaried the optimizer (Muon vs. AdamW) and the softmax activation function\n(standard softmax, stablemax, and sparsemax) to assess their combined effect on\nlearning dynamics. Our empirical evaluation reveals that the Muon optimizer,\ncharacterized by its use of spectral norm constraints and second-order\ninformation, significantly accelerates the onset of grokking compared to the\nwidely used AdamW optimizer. Specifically, Muon reduced the mean grokking epoch\nfrom 153.09 to 102.89 across all configurations, a statistically significant\ndifference (t = 5.0175, p = 6.33e-08). This suggests that the optimizer choice\nplays a crucial role in facilitating the transition from memorization to\ngeneralization.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "I.2"
    ],
    "primary_category": "cs.LG",
    "comment": "8 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.16041v1",
    "published_date": "2025-04-22 17:08:09 UTC",
    "updated_date": "2025-04-22 17:08:09 UTC"
  },
  {
    "arxiv_id": "2504.16032v1",
    "title": "LLMs meet Federated Learning for Scalable and Secure IoT Management",
    "authors": [
      "Yazan Otoum",
      "Arghavan Asad",
      "Amiya Nayak"
    ],
    "abstract": "The rapid expansion of IoT ecosystems introduces severe challenges in\nscalability, security, and real-time decision-making. Traditional centralized\narchitectures struggle with latency, privacy concerns, and excessive resource\nconsumption, making them unsuitable for modern large-scale IoT deployments.\nThis paper presents a novel Federated Learning-driven Large Language Model\n(FL-LLM) framework, designed to enhance IoT system intelligence while ensuring\ndata privacy and computational efficiency. The framework integrates Generative\nIoT (GIoT) models with a Gradient Sensing Federated Strategy (GSFS),\ndynamically optimizing model updates based on real-time network conditions. By\nleveraging a hybrid edge-cloud processing architecture, our approach balances\nintelligence, scalability, and security in distributed IoT environments.\nEvaluations on the IoT-23 dataset demonstrate that our framework improves model\naccuracy, reduces response latency, and enhances energy efficiency,\noutperforming traditional FL techniques (i.e., FedAvg, FedOpt). These findings\nhighlight the potential of integrating LLM-powered federated learning into\nlarge-scale IoT ecosystems, paving the way for more secure, scalable, and\nadaptive IoT management solutions.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.ET"
    ],
    "primary_category": "cs.LG",
    "comment": "This work has been submitted to the IEEE Global Communications\n  Conference (GLOBECOM) 2025 for possible publication",
    "pdf_url": "http://arxiv.org/pdf/2504.16032v1",
    "published_date": "2025-04-22 16:56:59 UTC",
    "updated_date": "2025-04-22 16:56:59 UTC"
  },
  {
    "arxiv_id": "2504.16027v1",
    "title": "Benchmarking LLM for Code Smells Detection: OpenAI GPT-4.0 vs DeepSeek-V3",
    "authors": [
      "Ahmed R. Sadik",
      "Siddhata Govind"
    ],
    "abstract": "Determining the most effective Large Language Model for code smell detection\npresents a complex challenge. This study introduces a structured methodology\nand evaluation matrix to tackle this issue, leveraging a curated dataset of\ncode samples consistently annotated with known smells. The dataset spans four\nprominent programming languages Java, Python, JavaScript, and C++; allowing for\ncross language comparison. We benchmark two state of the art LLMs, OpenAI GPT\n4.0 and DeepSeek-V3, using precision, recall, and F1 score as evaluation\nmetrics. Our analysis covers three levels of detail: overall performance,\ncategory level performance, and individual code smell type performance.\nAdditionally, we explore cost effectiveness by comparing the token based\ndetection approach of GPT 4.0 with the pattern-matching techniques employed by\nDeepSeek V3. The study also includes a cost analysis relative to traditional\nstatic analysis tools such as SonarQube. The findings offer valuable guidance\nfor practitioners in selecting an efficient, cost effective solution for\nautomated code smell detection",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LG",
      "cs.PL"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16027v1",
    "published_date": "2025-04-22 16:44:39 UTC",
    "updated_date": "2025-04-22 16:44:39 UTC"
  },
  {
    "arxiv_id": "2504.16026v1",
    "title": "Trends in AI Supercomputers",
    "authors": [
      "Konstantin F. Pilz",
      "James Sanders",
      "Robi Rahman",
      "Lennart Heim"
    ],
    "abstract": "Frontier AI development relies on powerful AI supercomputers, yet analysis of\nthese systems is limited. We create a dataset of 500 AI supercomputers from\n2019 to 2025 and analyze key trends in performance, power needs, hardware cost,\nownership, and global distribution. We find that the computational performance\nof AI supercomputers has doubled every nine months, while hardware acquisition\ncost and power needs both doubled every year. The leading system in March 2025,\nxAI's Colossus, used 200,000 AI chips, had a hardware cost of \\$7B, and\nrequired 300 MW of power, as much as 250,000 households. As AI supercomputers\nevolved from tools for science to industrial machines, companies rapidly\nexpanded their share of total AI supercomputer performance, while the share of\ngovernments and academia diminished. Globally, the United States accounts for\nabout 75% of total performance in our dataset, with China in second place at\n15%. If the observed trends continue, the leading AI supercomputer in 2030 will\nachieve $2\\times10^{22}$ 16-bit FLOP/s, use two million AI chips, have a\nhardware cost of \\$200 billion, and require 9 GW of power. Our analysis\nprovides visibility into the AI supercomputer landscape, allowing policymakers\nto assess key AI trends like resource needs, ownership, and national\ncompetitiveness.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16026v1",
    "published_date": "2025-04-22 16:44:34 UTC",
    "updated_date": "2025-04-22 16:44:34 UTC"
  },
  {
    "arxiv_id": "2504.16021v1",
    "title": "Navigating the State of Cognitive Flow: Context-Aware AI Interventions for Effective Reasoning Support",
    "authors": [
      "Dinithi Dissanayake",
      "Suranga Nanayakkara"
    ],
    "abstract": "Flow theory describes an optimal cognitive state where individuals experience\ndeep focus and intrinsic motivation when a task's difficulty aligns with their\nskill level. In AI-augmented reasoning, interventions that disrupt the state of\ncognitive flow can hinder rather than enhance decision-making. This paper\nproposes a context-aware cognitive augmentation framework that adapts\ninterventions based on three key contextual factors: type, timing, and scale.\nBy leveraging multimodal behavioral cues (e.g., gaze behavior, typing\nhesitation, interaction speed), AI can dynamically adjust cognitive support to\nmaintain or restore flow. We introduce the concept of cognitive flow, an\nextension of flow theory in AI-augmented reasoning, where interventions are\npersonalized, adaptive, and minimally intrusive. By shifting from static\ninterventions to context-aware augmentation, our approach ensures that AI\nsystems support deep engagement in complex decision-making and reasoning\nwithout disrupting cognitive immersion.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "Presented at the 2025 ACM Workshop on Human-AI Interaction for\n  Augmented Reasoning, Report Number: CHI25-WS-AUGMENTED-REASONING",
    "pdf_url": "http://arxiv.org/pdf/2504.16021v1",
    "published_date": "2025-04-22 16:35:39 UTC",
    "updated_date": "2025-04-22 16:35:39 UTC"
  },
  {
    "arxiv_id": "2504.16020v2",
    "title": "AlphaGrad: Non-Linear Gradient Normalization Optimizer",
    "authors": [
      "Soham Sane"
    ],
    "abstract": "We introduce AlphaGrad, a memory-efficient, conditionally stateless optimizer\naddressing the memory overhead and hyperparameter complexity of adaptive\nmethods like Adam. AlphaGrad enforces scale invariance via tensor-wise L2\ngradient normalization followed by a smooth hyperbolic tangent transformation,\n$g' = \\tanh(\\alpha \\cdot \\tilde{g})$, controlled by a single steepness\nparameter $\\alpha$. Our contributions include: (1) the AlphaGrad algorithm\nformulation; (2) a formal non-convex convergence analysis guaranteeing\nstationarity; (3) extensive empirical evaluation on diverse RL benchmarks (DQN,\nTD3, PPO). Compared to Adam, AlphaGrad demonstrates a highly context-dependent\nperformance profile. While exhibiting instability in off-policy DQN, it\nprovides enhanced training stability with competitive results in TD3 (requiring\ncareful $\\alpha$ tuning) and achieves substantially superior performance in\non-policy PPO. These results underscore the critical importance of empirical\n$\\alpha$ selection, revealing strong interactions between the optimizer's\ndynamics and the underlying RL algorithm. AlphaGrad presents a compelling\nalternative optimizer for memory-constrained scenarios and shows significant\npromise for on-policy learning regimes where its stability and efficiency\nadvantages can be particularly impactful.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16020v2",
    "published_date": "2025-04-22 16:33:14 UTC",
    "updated_date": "2025-04-23 01:25:32 UTC"
  },
  {
    "arxiv_id": "2504.16005v2",
    "title": "CAPO: Cost-Aware Prompt Optimization",
    "authors": [
      "Tom Zehle",
      "Moritz Schlager",
      "Timo Heiß",
      "Matthias Feurer"
    ],
    "abstract": "Large language models (LLMs) have revolutionized natural language processing\nby solving a wide range of tasks simply guided by a prompt. Yet their\nperformance is highly sensitive to prompt formulation. While automated prompt\noptimization addresses this challenge by finding optimal prompts, current\nmethods require a substantial number of LLM calls and input tokens, making\nprompt optimization expensive. We introduce CAPO (Cost-Aware Prompt\nOptimization), an algorithm that enhances prompt optimization efficiency by\nintegrating AutoML techniques. CAPO is an evolutionary approach with LLMs as\noperators, incorporating racing to save evaluations and multi-objective\noptimization to balance performance with prompt length. It jointly optimizes\ninstructions and few-shot examples while leveraging task descriptions for\nimproved robustness. Our extensive experiments across diverse datasets and LLMs\ndemonstrate that CAPO outperforms state-of-the-art discrete prompt optimization\nmethods in 11/15 cases with improvements up to 21%p. Our algorithm achieves\nbetter performances already with smaller budgets, saves evaluations through\nracing, and decreases average prompt length via a length penalty, making it\nboth cost-efficient and cost-aware. Even without few-shot examples, CAPO\noutperforms its competitors and generally remains robust to initial prompts.\nCAPO represents an important step toward making prompt optimization more\npowerful and accessible by improving cost-efficiency.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.NE",
      "stat.ML"
    ],
    "primary_category": "cs.CL",
    "comment": "Submitted to AutoML 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.16005v2",
    "published_date": "2025-04-22 16:14:31 UTC",
    "updated_date": "2025-04-23 09:59:31 UTC"
  },
  {
    "arxiv_id": "2504.16000v1",
    "title": "How Private is Your Attention? Bridging Privacy with In-Context Learning",
    "authors": [
      "Soham Bonnerjee",
      "Zhen Wei",
      "Yeon",
      "Anna Asch",
      "Sagnik Nandy",
      "Promit Ghosal"
    ],
    "abstract": "In-context learning (ICL)-the ability of transformer-based models to perform\nnew tasks from examples provided at inference time-has emerged as a hallmark of\nmodern language models. While recent works have investigated the mechanisms\nunderlying ICL, its feasibility under formal privacy constraints remains\nlargely unexplored. In this paper, we propose a differentially private\npretraining algorithm for linear attention heads and present the first\ntheoretical analysis of the privacy-accuracy trade-off for ICL in linear\nregression. Our results characterize the fundamental tension between\noptimization and privacy-induced noise, formally capturing behaviors observed\nin private training via iterative methods. Additionally, we show that our\nmethod is robust to adversarial perturbations of training prompts, unlike\nstandard ridge regression. All theoretical findings are supported by extensive\nsimulations across diverse settings.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.CL",
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "stat.ML",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16000v1",
    "published_date": "2025-04-22 16:05:26 UTC",
    "updated_date": "2025-04-22 16:05:26 UTC"
  },
  {
    "arxiv_id": "2504.15995v1",
    "title": "OPUS-VFL: Incentivizing Optimal Privacy-Utility Tradeoffs in Vertical Federated Learning",
    "authors": [
      "Sindhuja Madabushi",
      "Ahmad Faraz Khan",
      "Haider Ali",
      "Jin-Hee Cho"
    ],
    "abstract": "Vertical Federated Learning (VFL) enables organizations with disjoint feature\nspaces but shared user bases to collaboratively train models without sharing\nraw data. However, existing VFL systems face critical limitations: they often\nlack effective incentive mechanisms, struggle to balance privacy-utility\ntradeoffs, and fail to accommodate clients with heterogeneous resource\ncapabilities. These challenges hinder meaningful participation, degrade model\nperformance, and limit practical deployment. To address these issues, we\npropose OPUS-VFL, an Optimal Privacy-Utility tradeoff Strategy for VFL.\nOPUS-VFL introduces a novel, privacy-aware incentive mechanism that rewards\nclients based on a principled combination of model contribution, privacy\npreservation, and resource investment. It employs a lightweight leave-one-out\n(LOO) strategy to quantify feature importance per client, and integrates an\nadaptive differential privacy mechanism that enables clients to dynamically\ncalibrate noise levels to optimize their individual utility. Our framework is\ndesigned to be scalable, budget-balanced, and robust to inference and poisoning\nattacks. Extensive experiments on benchmark datasets (MNIST, CIFAR-10, and\nCIFAR-100) demonstrate that OPUS-VFL significantly outperforms state-of-the-art\nVFL baselines in both efficiency and robustness. It reduces label inference\nattack success rates by up to 20%, increases feature inference reconstruction\nerror (MSE) by over 30%, and achieves up to 25% higher incentives for clients\nthat contribute meaningfully while respecting privacy and cost constraints.\nThese results highlight the practicality and innovation of OPUS-VFL as a\nsecure, fair, and performance-driven solution for real-world VFL.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15995v1",
    "published_date": "2025-04-22 16:00:11 UTC",
    "updated_date": "2025-04-22 16:00:11 UTC"
  },
  {
    "arxiv_id": "2504.15983v1",
    "title": "W-PCA Based Gradient-Free Proxy for Efficient Search of Lightweight Language Models",
    "authors": [
      "Shang Wang"
    ],
    "abstract": "The demand for efficient natural language processing (NLP) systems has led to\nthe development of lightweight language models. Previous work in this area has\nprimarily focused on manual design or training-based neural architecture search\n(NAS) methods. Recently, zero-shot NAS methods have been proposed for\nevaluating language models without the need for training. However, prevailing\napproaches to zero-shot NAS often face challenges such as biased evaluation\nmetrics and computational inefficiencies. In this paper, we introduce\nweight-weighted PCA (W-PCA), a novel zero-shot NAS method specifically tailored\nfor lightweight language models. Our approach utilizes two evaluation proxies:\nthe parameter count and the number of principal components with cumulative\ncontribution exceeding $\\eta$ in the feed-forward neural (FFN) layer.\nAdditionally, by eliminating the need for gradient computations, we optimize\nthe evaluation time, thus enhancing the efficiency of designing and evaluating\nlightweight language models. We conduct a comparative analysis on the GLUE and\nSQuAD datasets to evaluate our approach. The results demonstrate that our\nmethod significantly reduces training time compared to one-shot NAS methods and\nachieves higher scores in the testing phase compared to previous\nstate-of-the-art training-based methods. Furthermore, we perform ranking\nevaluations on a dataset sampled from the FlexiBERT search space. Our approach\nexhibits superior ranking correlation and further reduces solving time compared\nto other zero-shot NAS methods that require gradient computation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.15983v1",
    "published_date": "2025-04-22 15:33:01 UTC",
    "updated_date": "2025-04-22 15:33:01 UTC"
  },
  {
    "arxiv_id": "2504.15972v1",
    "title": "Bug Destiny Prediction in Large Open-Source Software Repositories through Sentiment Analysis and BERT Topic Modeling",
    "authors": [
      "Sophie C. Pope",
      "Andrew Barovic",
      "Armin Moin"
    ],
    "abstract": "This study explores a novel approach to predicting key bug-related outcomes,\nincluding the time to resolution, time to fix, and ultimate status of a bug,\nusing data from the Bugzilla Eclipse Project. Specifically, we leverage\nfeatures available before a bug is resolved to enhance predictive accuracy. Our\nmethodology incorporates sentiment analysis to derive both an emotionality\nscore and a sentiment classification (positive or negative). Additionally, we\nintegrate the bug's priority level and its topic, extracted using a BERTopic\nmodel, as features for a Convolutional Neural Network (CNN) and a Multilayer\nPerceptron (MLP). Our findings indicate that the combination of BERTopic and\nsentiment analysis can improve certain model performance metrics. Furthermore,\nwe observe that balancing model inputs enhances practical applicability, albeit\nat the cost of a significant reduction in accuracy in most cases. To address\nour primary objectives, predicting time-to-resolution, time-to-fix, and bug\ndestiny, we employ both binary classification and exact time value predictions,\nallowing for a comparative evaluation of their predictive effectiveness.\nResults demonstrate that sentiment analysis serves as a valuable predictor of a\nbug's eventual outcome, particularly in determining whether it will be fixed.\nHowever, its utility is less pronounced when classifying bugs into more complex\nor unconventional outcome categories.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15972v1",
    "published_date": "2025-04-22 15:18:14 UTC",
    "updated_date": "2025-04-22 15:18:14 UTC"
  },
  {
    "arxiv_id": "2504.15956v1",
    "title": "Universal Approximation with Softmax Attention",
    "authors": [
      "Jerry Yao-Chieh Hu",
      "Hude Liu",
      "Hong-Yu Chen",
      "Weimin Wu",
      "Han Liu"
    ],
    "abstract": "We prove that with linear transformations, both (i) two-layer self-attention\nand (ii) one-layer self-attention followed by a softmax function are universal\napproximators for continuous sequence-to-sequence functions on compact domains.\nOur main technique is a new interpolation-based method for analyzing\nattention's internal mechanism. This leads to our key insight: self-attention\nis able to approximate a generalized version of ReLU to arbitrary precision,\nand hence subsumes many known universal approximators. Building on these, we\nshow that two-layer multi-head attention alone suffices as a\nsequence-to-sequence universal approximator. In contrast, prior works rely on\nfeed-forward networks to establish universal approximation in Transformers.\nFurthermore, we extend our techniques to show that, (softmax-)attention-only\nlayers are capable of approximating various statistical models in-context. We\nbelieve these techniques hold independent interest.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15956v1",
    "published_date": "2025-04-22 14:51:33 UTC",
    "updated_date": "2025-04-22 14:51:33 UTC"
  },
  {
    "arxiv_id": "2504.15941v1",
    "title": "FairTranslate: An English-French Dataset for Gender Bias Evaluation in Machine Translation by Overcoming Gender Binarity",
    "authors": [
      "Fanny Jourdan",
      "Yannick Chevalier",
      "Cécile Favre"
    ],
    "abstract": "Large Language Models (LLMs) are increasingly leveraged for translation tasks\nbut often fall short when translating inclusive language -- such as texts\ncontaining the singular 'they' pronoun or otherwise reflecting fair linguistic\nprotocols. Because these challenges span both computational and societal\ndomains, it is imperative to critically evaluate how well LLMs handle inclusive\ntranslation with a well-founded framework.\n  This paper presents FairTranslate, a novel, fully human-annotated dataset\ndesigned to evaluate non-binary gender biases in machine translation systems\nfrom English to French. FairTranslate includes 2418 English-French sentence\npairs related to occupations, annotated with rich metadata such as the\nstereotypical alignment of the occupation, grammatical gender indicator\nambiguity, and the ground-truth gender label (male, female, or inclusive).\n  We evaluate four leading LLMs (Gemma2-2B, Mistral-7B, Llama3.1-8B,\nLlama3.3-70B) on this dataset under different prompting procedures. Our results\nreveal substantial biases in gender representation across LLMs, highlighting\npersistent challenges in achieving equitable outcomes in machine translation.\nThese findings underscore the need for focused strategies and interventions\naimed at ensuring fair and inclusive language usage in LLM-based translation\nsystems.\n  We make the FairTranslate dataset publicly available on Hugging Face, and\ndisclose the code for all experiments on GitHub.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "FAccT 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.15941v1",
    "published_date": "2025-04-22 14:35:16 UTC",
    "updated_date": "2025-04-22 14:35:16 UTC"
  },
  {
    "arxiv_id": "2504.15929v1",
    "title": "Meta-Entity Driven Triplet Mining for Aligning Medical Vision-Language Models",
    "authors": [
      "Saban Ozturk",
      "Melih B. Yilmaz",
      "Muti Kara",
      "M. Talat Yavuz",
      "Aykut Koç",
      "Tolga Çukur"
    ],
    "abstract": "Diagnostic imaging relies on interpreting both images and radiology reports,\nbut the growing data volumes place significant pressure on medical experts,\nyielding increased errors and workflow backlogs. Medical vision-language models\n(med-VLMs) have emerged as a powerful framework to efficiently process\nmultimodal imaging data, particularly in chest X-ray (CXR) evaluations, albeit\ntheir performance hinges on how well image and text representations are\naligned. Existing alignment methods, predominantly based on contrastive\nlearning, prioritize separation between disease classes over segregation of\nfine-grained pathology attributes like location, size or severity, leading to\nsuboptimal representations. Here, we propose MedTrim (Meta-entity-driven\nTriplet mining), a novel method that enhances image-text alignment through\nmultimodal triplet learning synergistically guided by disease class as well as\nadjectival and directional pathology descriptors. Unlike common alignment\nmethods that separate broad disease classes, MedTrim leverages structured\nmeta-entity information to preserve subtle but clinically significant\nintra-class variations. For this purpose, we first introduce an ontology-based\nentity recognition module that extracts pathology-specific meta-entities from\nCXR reports, as annotations on pathology attributes are rare in public\ndatasets. For refined sample selection in triplet mining, we then introduce a\nnovel score function that captures an aggregate measure of inter-sample\nsimilarity based on disease classes and adjectival/directional descriptors.\nLastly, we introduce a multimodal triplet alignment objective for explicit\nwithin- and cross-modal alignment between samples sharing detailed pathology\ncharacteristics. Our demonstrations indicate that MedTrim improves performance\nin downstream retrieval and classification tasks compared to state-of-the-art\nalignment methods.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "18 pages, 7 figures, 6 tables",
    "pdf_url": "http://arxiv.org/pdf/2504.15929v1",
    "published_date": "2025-04-22 14:17:51 UTC",
    "updated_date": "2025-04-22 14:17:51 UTC"
  },
  {
    "arxiv_id": "2504.15928v1",
    "title": "A Clinician-Friendly Platform for Ophthalmic Image Analysis Without Technical Barriers",
    "authors": [
      "Meng Wang",
      "Tian Lin",
      "Qingshan Hou",
      "Aidi Lin",
      "Jingcheng Wang",
      "Qingsheng Peng",
      "Truong X. Nguyen",
      "Danqi Fang",
      "Ke Zou",
      "Ting Xu",
      "Cancan Xue",
      "Ten Cheer Quek",
      "Qinkai Yu",
      "Minxin Liu",
      "Hui Zhou",
      "Zixuan Xiao",
      "Guiqin He",
      "Huiyu Liang",
      "Tingkun Shi",
      "Man Chen",
      "Linna Liu",
      "Yuanyuan Peng",
      "Lianyu Wang",
      "Qiuming Hu",
      "Junhong Chen",
      "Zhenhua Zhang",
      "Cheng Chen",
      "Yitian Zhao",
      "Dianbo Liu",
      "Jianhua Wu",
      "Xinjian Chen",
      "Changqing Zhang",
      "Triet Thanh Nguyen",
      "Yanda Meng",
      "Yalin Zheng",
      "Yih Chung Tham",
      "Carol Y. Cheung",
      "Huazhu Fu",
      "Haoyu Chen",
      "Ching-Yu Cheng"
    ],
    "abstract": "Artificial intelligence (AI) shows remarkable potential in medical imaging\ndiagnostics, but current models typically require retraining when deployed\nacross different clinical centers, limiting their widespread adoption. We\nintroduce GlobeReady, a clinician-friendly AI platform that enables ocular\ndisease diagnosis without retraining/fine-tuning or technical expertise.\nGlobeReady achieves high accuracy across imaging modalities: 93.9-98.5% for an\n11-category fundus photo dataset and 87.2-92.7% for a 15-category OCT dataset.\nThrough training-free local feature augmentation, it addresses domain shifts\nacross centers and populations, reaching an average accuracy of 88.9% across\nfive centers in China, 86.3% in Vietnam, and 90.2% in the UK. The built-in\nconfidence-quantifiable diagnostic approach further boosted accuracy to\n94.9-99.4% (fundus) and 88.2-96.2% (OCT), while identifying out-of-distribution\ncases at 86.3% (49 CFP categories) and 90.6% (13 OCT categories). Clinicians\nfrom multiple countries rated GlobeReady highly (average 4.6 out of 5) for its\nusability and clinical relevance. These results demonstrate GlobeReady's\nrobust, scalable diagnostic capability and potential to support ophthalmic care\nwithout technical barriers.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15928v1",
    "published_date": "2025-04-22 14:17:22 UTC",
    "updated_date": "2025-04-22 14:17:22 UTC"
  },
  {
    "arxiv_id": "2504.15927v1",
    "title": "New Recipe for Semi-supervised Community Detection: Clique Annealing under Crystallization Kinetics",
    "authors": [
      "Ling Cheng",
      "Jiashu Pu",
      "Ruicheng Liang",
      "Qian Shao",
      "Hezhe Qiao",
      "Feida Zhu"
    ],
    "abstract": "Semi-supervised community detection methods are widely used for identifying\nspecific communities due to the label scarcity. Existing semi-supervised\ncommunity detection methods typically involve two learning stages learning in\nboth initial identification and subsequent adjustment, which often starts from\nan unreasonable community core candidate. Moreover, these methods encounter\nscalability issues because they depend on reinforcement learning and generative\nadversarial networks, leading to higher computational costs and restricting the\nselection of candidates. To address these limitations, we draw a parallel\nbetween crystallization kinetics and community detection to integrate the\nspontaneity of the annealing process into community detection. Specifically, we\nliken community detection to identifying a crystal subgrain (core) that expands\ninto a complete grain (community) through a process similar to annealing. Based\non this finding, we propose CLique ANNealing (CLANN), which applies kinetics\nconcepts to community detection by integrating these principles into the\noptimization process to strengthen the consistency of the community core.\nSubsequently, a learning-free Transitive Annealer was employed to refine the\nfirst-stage candidates by merging neighboring cliques and repositioning the\ncommunity core, enabling a spontaneous growth process that enhances\nscalability. Extensive experiments on \\textbf{43} different network settings\ndemonstrate that CLANN outperforms state-of-the-art methods across multiple\nreal-world datasets, showcasing its exceptional efficacy and efficiency in\ncommunity detection.",
    "categories": [
      "cs.SI",
      "cs.AI"
    ],
    "primary_category": "cs.SI",
    "comment": "arXiv admin note: text overlap with arXiv:2203.05898 by other authors",
    "pdf_url": "http://arxiv.org/pdf/2504.15927v1",
    "published_date": "2025-04-22 14:17:15 UTC",
    "updated_date": "2025-04-22 14:17:15 UTC"
  },
  {
    "arxiv_id": "2504.15924v1",
    "title": "Achieving Distributive Justice in Federated Learning via Uncertainty Quantification",
    "authors": [
      "Alycia Carey",
      "Xintao Wu"
    ],
    "abstract": "Client-level fairness metrics for federated learning are used to ensure that\nall clients in a federation either: a) have similar final performance on their\nlocal data distributions (i.e., client parity), or b) obtain final performance\non their local data distributions relative to their contribution to the\nfederated learning process (i.e., contribution fairness). While a handful of\nworks that propose either client-parity or contribution-based fairness metrics\nground their definitions and decisions in social theories of equality -- such\nas distributive justice -- most works arbitrarily choose what notion of\nfairness to align with which makes it difficult for practitioners to choose\nwhich fairness metric aligns best with their fairness ethics. In this work, we\npropose UDJ-FL (Uncertainty-based Distributive Justice for Federated Learning),\na flexible federated learning framework that can achieve multiple distributive\njustice-based client-level fairness metrics. Namely, by utilizing techniques\ninspired by fair resource allocation, in conjunction with performing aleatoric\nuncertainty-based client weighing, our UDJ-FL framework is able to achieve\negalitarian, utilitarian, Rawls' difference principle, or desert-based\nclient-level fairness. We empirically show the ability of UDJ-FL to achieve all\nfour defined distributive justice-based client-level fairness metrics in\naddition to providing fairness equivalent to (or surpassing) other popular fair\nfederated learning works. Further, we provide justification for why aleatoric\nuncertainty weighing is necessary to the construction of our UDJ-FL framework\nas well as derive theoretical guarantees for the generalization bounds of\nUDJ-FL. Our code is publicly available at\nhttps://github.com/alycia-noel/UDJ-FL.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML",
      "68T01",
      "I.2.0"
    ],
    "primary_category": "cs.LG",
    "comment": "21 pages, 1 figure, 7 tables",
    "pdf_url": "http://arxiv.org/pdf/2504.15924v1",
    "published_date": "2025-04-22 14:07:56 UTC",
    "updated_date": "2025-04-22 14:07:56 UTC"
  },
  {
    "arxiv_id": "2504.15918v2",
    "title": "Ask2Loc: Learning to Locate Instructional Visual Answers by Asking Questions",
    "authors": [
      "Chang Zong",
      "Bin Li",
      "Shoujun Zhou",
      "Jian Wan",
      "Lei Zhang"
    ],
    "abstract": "Locating specific segments within an instructional video is an efficient way\nto acquire guiding knowledge. Generally, the task of obtaining video segments\nfor both verbal explanations and visual demonstrations is known as visual\nanswer localization (VAL). However, users often need multiple interactions to\nobtain answers that align with their expectations when using the system. During\nthese interactions, humans deepen their understanding of the video content by\nasking themselves questions, thereby accurately identifying the location.\nTherefore, we propose a new task, named In-VAL, to simulate the multiple\ninteractions between humans and videos in the procedure of obtaining visual\nanswers. The In-VAL task requires interactively addressing several semantic gap\nissues, including 1) the ambiguity of user intent in the input questions, 2)\nthe incompleteness of language in video subtitles, and 3) the fragmentation of\ncontent in video segments. To address these issues, we propose Ask2Loc, a\nframework for resolving In-VAL by asking questions. It includes three key\nmodules: 1) a chatting module to refine initial questions and uncover clear\nintentions, 2) a rewriting module to generate fluent language and create\ncomplete descriptions, and 3) a searching module to broaden local context and\nprovide integrated content. We conduct extensive experiments on three\nreconstructed In-VAL datasets. Compared to traditional end-to-end and two-stage\nmethods, our proposed Ask2Loc can improve performance by up to 14.91 (mIoU) on\nthe In-VAL task. Our code and datasets can be accessed at\nhttps://github.com/changzong/Ask2Loc.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.HC",
      "68T45, 68T20"
    ],
    "primary_category": "cs.CV",
    "comment": "16 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.15918v2",
    "published_date": "2025-04-22 14:03:16 UTC",
    "updated_date": "2025-04-23 03:01:06 UTC"
  },
  {
    "arxiv_id": "2504.15912v1",
    "title": "Automated Bug Report Prioritization in Large Open-Source Projects",
    "authors": [
      "Riley Pierson",
      "Armin Moin"
    ],
    "abstract": "Large open-source projects receive a large number of issues (known as bugs),\nincluding software defect (i.e., bug) reports and new feature requests from\ntheir user and developer communities at a fast rate. The often limited project\nresources do not allow them to deal with all issues. Instead, they have to\nprioritize them according to the project's priorities and the issues'\nseverities. In this paper, we propose a novel approach to automated bug\nprioritization based on the natural language text of the bug reports that are\nstored in the open bug repositories of the issue-tracking systems. We conduct\ntopic modeling using a variant of LDA called TopicMiner-MTM and text\nclassification with the BERT large language model to achieve a higher\nperformance level compared to the state-of-the-art. Experimental results using\nan existing reference dataset containing 85,156 bug reports of the Eclipse\nPlatform project indicate that we outperform existing approaches in terms of\nAccuracy, Precision, Recall, and F1-measure of the bug report priority\nprediction.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15912v1",
    "published_date": "2025-04-22 13:57:48 UTC",
    "updated_date": "2025-04-22 13:57:48 UTC"
  },
  {
    "arxiv_id": "2504.15905v1",
    "title": "GraphEdge: Dynamic Graph Partition and Task Scheduling for GNNs Computing in Edge Network",
    "authors": [
      "Wenjing Xiao",
      "Chenglong Shi",
      "Miaojiang Chen",
      "Zhiquan Liu",
      "Min Chen",
      "H. Herbert Song"
    ],
    "abstract": "With the exponential growth of Internet of Things (IoT) devices, edge\ncomputing (EC) is gradually playing an important role in providing\ncost-effective services. However, existing approaches struggle to perform well\nin graph-structured scenarios where user data is correlated, such as traffic\nflow prediction and social relationship recommender systems. In particular,\ngraph neural network (GNN)-based approaches lead to expensive server\ncommunication cost. To address this problem, we propose GraphEdge, an efficient\nGNN-based EC architecture. It considers the EC system of GNN tasks, where there\nare associations between users and it needs to take into account the task data\nof its neighbors when processing the tasks of a user. Specifically, the\narchitecture first perceives the user topology and represents their data\nassociations as a graph layout at each time step. Then the graph layout is\noptimized by calling our proposed hierarchical traversal graph cut algorithm\n(HiCut), which cuts the graph layout into multiple weakly associated subgraphs\nbased on the aggregation characteristics of GNN, and the communication cost\nbetween different subgraphs during GNN inference is minimized. Finally, based\non the optimized graph layout, our proposed deep reinforcement learning (DRL)\nbased graph offloading algorithm (DRLGO) is executed to obtain the optimal\noffloading strategy for the tasks of users, the offloading strategy is\nsubgraph-based, it tries to offload user tasks in a subgraph to the same edge\nserver as possible while minimizing the task processing time and energy\nconsumption of the EC system. Experimental results show the good effectiveness\nand dynamic adaptation of our proposed architecture and it also performs well\neven in dynamic scenarios.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "17 pages,12 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.15905v1",
    "published_date": "2025-04-22 13:45:13 UTC",
    "updated_date": "2025-04-22 13:45:13 UTC"
  },
  {
    "arxiv_id": "2504.15903v1",
    "title": "Impact of Noise on LLM-Models Performance in Abstraction and Reasoning Corpus (ARC) Tasks with Model Temperature Considerations",
    "authors": [
      "Nikhil Khandalkar",
      "Pavan Yadav",
      "Krishna Shinde",
      "Lokesh B. Ramegowda",
      "Rajarshi Das"
    ],
    "abstract": "Recent advancements in Large Language Models (LLMs) have generated growing\ninterest in their structured reasoning capabilities, particularly in tasks\ninvolving abstraction and pattern recognition. The Abstraction and Reasoning\nCorpus (ARC) benchmark plays a crucial role in evaluating these capabilities by\ntesting how well AI models generalize to novel problems. While GPT-4o\ndemonstrates strong performance by solving all ARC tasks under zero-noise\nconditions, other models like DeepSeek R1 and LLaMA 3.2 fail to solve any,\nsuggesting limitations in their ability to reason beyond simple pattern\nmatching. To explore this gap, we systematically evaluate these models across\ndifferent noise levels and temperature settings. Our results reveal that the\nintroduction of noise consistently impairs model performance, regardless of\narchitecture. This decline highlights a shared vulnerability: current LLMs,\ndespite showing signs of abstract reasoning, remain highly sensitive to input\nperturbations. Such fragility raises concerns about their real-world\napplicability, where noise and uncertainty are common. By comparing how\ndifferent model architectures respond to these challenges, we offer insights\ninto the structural weaknesses of modern LLMs in reasoning tasks. This work\nunderscores the need for developing more robust and adaptable AI systems\ncapable of handling the ambiguity and variability inherent in real-world\nscenarios. Our findings aim to guide future research toward enhancing model\ngeneralization, robustness, and alignment with human-like cognitive\nflexibility.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "60 pages, 25 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.15903v1",
    "published_date": "2025-04-22 13:43:58 UTC",
    "updated_date": "2025-04-22 13:43:58 UTC"
  },
  {
    "arxiv_id": "2504.15895v1",
    "title": "Dynamic Early Exit in Reasoning Models",
    "authors": [
      "Chenxu Yang",
      "Qingyi Si",
      "Yongjie Duan",
      "Zheliang Zhu",
      "Chenyu Zhu",
      "Zheng Lin",
      "Li Cao",
      "Weiping Wang"
    ],
    "abstract": "Recent advances in large reasoning language models (LRLMs) rely on test-time\nscaling, which extends long chain-of-thought (CoT) generation to solve complex\ntasks. However, overthinking in long CoT not only slows down the efficiency of\nproblem solving, but also risks accuracy loss due to the extremely detailed or\nredundant reasoning steps. We propose a simple yet effective method that allows\nLLMs to self-truncate CoT sequences by early exit during generation. Instead of\nrelying on fixed heuristics, the proposed method monitors model behavior at\npotential reasoning transition points (e.g.,\"Wait\" tokens) and dynamically\nterminates the next reasoning chain's generation when the model exhibits high\nconfidence in a trial answer. Our method requires no additional training and\ncan be seamlessly integrated into existing o1-like reasoning LLMs. Experiments\non multiple reasoning benchmarks MATH-500, AMC 2023, GPQA Diamond and AIME 2024\nshow that the proposed method is consistently effective on deepseek-series\nreasoning LLMs, reducing the length of CoT sequences by an average of 31% to\n43% while improving accuracy by 1.7% to 5.7%.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "19 pages, 11 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.15895v1",
    "published_date": "2025-04-22 13:36:53 UTC",
    "updated_date": "2025-04-22 13:36:53 UTC"
  },
  {
    "arxiv_id": "2504.15894v1",
    "title": "Supporting Data-Frame Dynamics in AI-assisted Decision Making",
    "authors": [
      "Chengbo Zheng",
      "Tim Miller",
      "Alina Bialkowski",
      "H Peter Soyer",
      "Monika Janda"
    ],
    "abstract": "High stakes decision-making often requires a continuous interplay between\nevolving evidence and shifting hypotheses, a dynamic that is not well supported\nby current AI decision support systems. In this paper, we introduce a\nmixed-initiative framework for AI assisted decision making that is grounded in\nthe data-frame theory of sensemaking and the evaluative AI paradigm. Our\napproach enables both humans and AI to collaboratively construct, validate, and\nadapt hypotheses. We demonstrate our framework with an AI-assisted skin cancer\ndiagnosis prototype that leverages a concept bottleneck model to facilitate\ninterpretable interactions and dynamic updates to diagnostic hypotheses.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "Presented at the 2025 ACM Workshop on Human-AI Interaction for\n  Augmented Reasoning, Report Number: CHI25-WS-AUGMENTED-REASONING",
    "pdf_url": "http://arxiv.org/pdf/2504.15894v1",
    "published_date": "2025-04-22 13:36:06 UTC",
    "updated_date": "2025-04-22 13:36:06 UTC"
  },
  {
    "arxiv_id": "2504.15883v1",
    "title": "Integrating Non-Linear Radon Transformation for Diabetic Retinopathy Grading",
    "authors": [
      "Farida Mohsen",
      "Samir Belhaouari",
      "Zubair Shah"
    ],
    "abstract": "Diabetic retinopathy is a serious ocular complication that poses a\nsignificant threat to patients' vision and overall health. Early detection and\naccurate grading are essential to prevent vision loss. Current automatic\ngrading methods rely heavily on deep learning applied to retinal fundus images,\nbut the complex, irregular patterns of lesions in these images, which vary in\nshape and distribution, make it difficult to capture subtle changes. This study\nintroduces RadFuse, a multi-representation deep learning framework that\nintegrates non-linear RadEx-transformed sinogram images with traditional fundus\nimages to enhance diabetic retinopathy detection and grading. Our RadEx\ntransformation, an optimized non-linear extension of the Radon transform,\ngenerates sinogram representations to capture complex retinal lesion patterns.\nBy leveraging both spatial and transformed domain information, RadFuse enriches\nthe feature set available to deep learning models, improving the\ndifferentiation of severity levels. We conducted extensive experiments on two\nbenchmark datasets, APTOS-2019 and DDR, using three convolutional neural\nnetworks (CNNs): ResNeXt-50, MobileNetV2, and VGG19. RadFuse showed significant\nimprovements over fundus-image-only models across all three CNN architectures\nand outperformed state-of-the-art methods on both datasets. For severity\ngrading across five stages, RadFuse achieved a quadratic weighted kappa of\n93.24%, an accuracy of 87.07%, and an F1-score of 87.17%. In binary\nclassification between healthy and diabetic retinopathy cases, the method\nreached an accuracy of 99.09%, precision of 98.58%, and recall of 99.6%,\nsurpassing previously established models. These results demonstrate RadFuse's\ncapacity to capture complex non-linear features, advancing diabetic retinopathy\nclassification and promoting the integration of advanced mathematical\ntransforms in medical image analysis.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15883v1",
    "published_date": "2025-04-22 13:27:28 UTC",
    "updated_date": "2025-04-22 13:27:28 UTC"
  },
  {
    "arxiv_id": "2504.15876v2",
    "title": "Bidirectional Task-Motion Planning Based on Hierarchical Reinforcement Learning for Strategic Confrontation",
    "authors": [
      "Qizhen Wu",
      "Lei Chen",
      "Kexin Liu",
      "Jinhu Lü"
    ],
    "abstract": "In swarm robotics, confrontation scenarios, including strategic\nconfrontations, require efficient decision-making that integrates discrete\ncommands and continuous actions. Traditional task and motion planning methods\nseparate decision-making into two layers, but their unidirectional structure\nfails to capture the interdependence between these layers, limiting\nadaptability in dynamic environments. Here, we propose a novel bidirectional\napproach based on hierarchical reinforcement learning, enabling dynamic\ninteraction between the layers. This method effectively maps commands to task\nallocation and actions to path planning, while leveraging cross-training\ntechniques to enhance learning across the hierarchical framework. Furthermore,\nwe introduce a trajectory prediction model that bridges abstract task\nrepresentations with actionable planning goals. In our experiments, it achieves\nover 80% in confrontation win rate and under 0.01 seconds in decision time,\noutperforming existing approaches. Demonstrations through large-scale tests and\nreal-world robot experiments further emphasize the generalization capabilities\nand practical applicability of our method.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15876v2",
    "published_date": "2025-04-22 13:22:58 UTC",
    "updated_date": "2025-04-23 15:00:10 UTC"
  },
  {
    "arxiv_id": "2504.15865v2",
    "title": "MedNNS: Supernet-based Medical Task-Adaptive Neural Network Search",
    "authors": [
      "Lotfi Abdelkrim Mecharbat",
      "Ibrahim Almakky",
      "Martin Takac",
      "Mohammad Yaqub"
    ],
    "abstract": "Deep learning (DL) has achieved remarkable progress in the field of medical\nimaging. However, adapting DL models to medical tasks remains a significant\nchallenge, primarily due to two key factors: (1) architecture selection, as\ndifferent tasks necessitate specialized model designs, and (2) weight\ninitialization, which directly impacts the convergence speed and final\nperformance of the models. Although transfer learning from ImageNet is a widely\nadopted strategy, its effectiveness is constrained by the substantial\ndifferences between natural and medical images. To address these challenges, we\nintroduce Medical Neural Network Search (MedNNS), the first Neural Network\nSearch framework for medical imaging applications. MedNNS jointly optimizes\narchitecture selection and weight initialization by constructing a meta-space\nthat encodes datasets and models based on how well they perform together. We\nbuild this space using a Supernetwork-based approach, expanding the model zoo\nsize by 51x times over previous state-of-the-art (SOTA) methods. Moreover, we\nintroduce rank loss and Fr\\'echet Inception Distance (FID) loss into the\nconstruction of the space to capture inter-model and inter-dataset\nrelationships, thereby achieving more accurate alignment in the meta-space.\nExperimental results across multiple datasets demonstrate that MedNNS\nsignificantly outperforms both ImageNet pre-trained DL models and SOTA Neural\nArchitecture Search (NAS) methods, achieving an average accuracy improvement of\n1.7% across datasets while converging substantially faster. The code and the\nprocessed meta-space is available at https://github.com/BioMedIA-MBZUAI/MedNNS.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15865v2",
    "published_date": "2025-04-22 13:04:40 UTC",
    "updated_date": "2025-04-23 05:28:18 UTC"
  },
  {
    "arxiv_id": "2504.15847v1",
    "title": "CARE: Compatibility-Aware Incentive Mechanisms for Federated Learning with Budgeted Requesters",
    "authors": [
      "Xiang Liu",
      "Hau Chan",
      "Minming Li",
      "Xianlong Zeng",
      "Chenchen Fu",
      "Weiwei Wu"
    ],
    "abstract": "Federated learning (FL) is a promising approach that allows requesters (\\eg,\nservers) to obtain local training models from workers (e.g., clients). Since\nworkers are typically unwilling to provide training services/models freely and\nvoluntarily, many incentive mechanisms in FL are designed to incentivize\nparticipation by offering monetary rewards from requesters. However, existing\nstudies neglect two crucial aspects of real-world FL scenarios. First, workers\ncan possess inherent incompatibility characteristics (e.g., communication\nchannels and data sources), which can lead to degradation of FL efficiency\n(e.g., low communication efficiency and poor model generalization). Second, the\nrequesters are budgeted, which limits the amount of workers they can hire for\ntheir tasks. In this paper, we investigate the scenario in FL where multiple\nbudgeted requesters seek training services from incompatible workers with\nprivate training costs. We consider two settings: the cooperative budget\nsetting where requesters cooperate to pool their budgets to improve their\noverall utility and the non-cooperative budget setting where each requester\noptimizes their utility within their own budgets. To address efficiency\ndegradation caused by worker incompatibility, we develop novel\ncompatibility-aware incentive mechanisms, CARE-CO and CARE-NO, for both\nsettings to elicit true private costs and determine workers to hire for\nrequesters and their rewards while satisfying requester budget constraints. Our\nmechanisms guarantee individual rationality, truthfulness, budget feasibility,\nand approximation performance. We conduct extensive experiments using\nreal-world datasets to show that the proposed mechanisms significantly\noutperform existing baselines.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15847v1",
    "published_date": "2025-04-22 12:42:45 UTC",
    "updated_date": "2025-04-22 12:42:45 UTC"
  },
  {
    "arxiv_id": "2504.15829v1",
    "title": "Generative AI for Research Data Processing: Lessons Learnt From Three Use Cases",
    "authors": [
      "Modhurita Mitra",
      "Martine G. de Vos",
      "Nicola Cortinovis",
      "Dawa Ometto"
    ],
    "abstract": "There has been enormous interest in generative AI since ChatGPT was launched\nin 2022. However, there are concerns about the accuracy and consistency of the\noutputs of generative AI. We have carried out an exploratory study on the\napplication of this new technology in research data processing. We identified\ntasks for which rule-based or traditional machine learning approaches were\ndifficult to apply, and then performed these tasks using generative AI.\n  We demonstrate the feasibility of using the generative AI model Claude 3 Opus\nin three research projects involving complex data processing tasks:\n  1) Information extraction: We extract plant species names from historical\nseedlists (catalogues of seeds) published by botanical gardens.\n  2) Natural language understanding: We extract certain data points (name of\ndrug, name of health indication, relative effectiveness, cost-effectiveness,\netc.) from documents published by Health Technology Assessment organisations in\nthe EU.\n  3) Text classification: We assign industry codes to projects on the\ncrowdfunding website Kickstarter.\n  We share the lessons we learnt from these use cases: How to determine if\ngenerative AI is an appropriate tool for a given data processing task, and if\nso, how to maximise the accuracy and consistency of the results obtained.",
    "categories": [
      "cs.AI",
      "68T50",
      "I.2.7"
    ],
    "primary_category": "cs.AI",
    "comment": "10 pages, 4 figures, 6 tables. Published in Proceedings of the 2024\n  IEEE 20th International Conference on e-Science (e-Science), Osaka, Japan",
    "pdf_url": "http://arxiv.org/pdf/2504.15829v1",
    "published_date": "2025-04-22 12:21:07 UTC",
    "updated_date": "2025-04-22 12:21:07 UTC"
  },
  {
    "arxiv_id": "2504.15827v1",
    "title": "DualOptim: Enhancing Efficacy and Stability in Machine Unlearning with Dual Optimizers",
    "authors": [
      "Xuyang Zhong",
      "Haochen Luo",
      "Chen Liu"
    ],
    "abstract": "Existing machine unlearning (MU) approaches exhibit significant sensitivity\nto hyperparameters, requiring meticulous tuning that limits practical\ndeployment. In this work, we first empirically demonstrate the instability and\nsuboptimal performance of existing popular MU methods when deployed in\ndifferent scenarios. To address this issue, we propose Dual Optimizer\n(DualOptim), which incorporates adaptive learning rate and decoupled momentum\nfactors. Empirical and theoretical evidence demonstrates that DualOptim\ncontributes to effective and stable unlearning. Through extensive experiments,\nwe show that DualOptim can significantly boost MU efficacy and stability across\ndiverse tasks, including image classification, image generation, and large\nlanguage models, making it a versatile approach to empower existing MU\nalgorithms.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15827v1",
    "published_date": "2025-04-22 12:18:26 UTC",
    "updated_date": "2025-04-22 12:18:26 UTC"
  },
  {
    "arxiv_id": "2504.15823v1",
    "title": "Human-Imperceptible Physical Adversarial Attack for NIR Face Recognition Models",
    "authors": [
      "Songyan Xie",
      "Jinghang Wen",
      "Encheng Su",
      "Qiucheng Yu"
    ],
    "abstract": "Near-infrared (NIR) face recognition systems, which can operate effectively\nin low-light conditions or in the presence of makeup, exhibit vulnerabilities\nwhen subjected to physical adversarial attacks. To further demonstrate the\npotential risks in real-world applications, we design a novel, stealthy, and\npractical adversarial patch to attack NIR face recognition systems in a\nblack-box setting. We achieved this by utilizing human-imperceptible\ninfrared-absorbing ink to generate multiple patches with digitally optimized\nshapes and positions for infrared images. To address the optimization mismatch\nbetween digital and real-world NIR imaging, we develop a light reflection model\nfor human skin to minimize pixel-level discrepancies by simulating NIR light\nreflection.\n  Compared to state-of-the-art (SOTA) physical attacks on NIR face recognition\nsystems, the experimental results show that our method improves the attack\nsuccess rate in both digital and physical domains, particularly maintaining\neffectiveness across various face postures. Notably, the proposed approach\noutperforms SOTA methods, achieving an average attack success rate of 82.46% in\nthe physical domain across different models, compared to 64.18% for existing\nmethods. The artifact is available at\nhttps://anonymous.4open.science/r/Human-imperceptible-adversarial-patch-0703/.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15823v1",
    "published_date": "2025-04-22 12:10:25 UTC",
    "updated_date": "2025-04-22 12:10:25 UTC"
  },
  {
    "arxiv_id": "2504.15812v1",
    "title": "Fusing Reward and Dueling Feedback in Stochastic Bandits",
    "authors": [
      "Xuchuang Wang",
      "Qirun Zeng",
      "Jinhang Zuo",
      "Xutong Liu",
      "Mohammad Hajiesmaili",
      "John C. S. Lui",
      "Adam Wierman"
    ],
    "abstract": "This paper investigates the fusion of absolute (reward) and relative\n(dueling) feedback in stochastic bandits, where both feedback types are\ngathered in each decision round. We derive a regret lower bound, demonstrating\nthat an efficient algorithm may incur only the smaller among the reward and\ndueling-based regret for each individual arm. We propose two fusion approaches:\n(1) a simple elimination fusion algorithm that leverages both feedback types to\nexplore all arms and unifies collected information by sharing a common\ncandidate arm set, and (2) a decomposition fusion algorithm that selects the\nmore effective feedback to explore the corresponding arms and randomly assigns\none feedback type for exploration and the other for exploitation in each round.\nThe elimination fusion experiences a suboptimal multiplicative term of the\nnumber of arms in regret due to the intrinsic suboptimality of dueling\nelimination. In contrast, the decomposition fusion achieves regret matching the\nlower bound up to a constant under a common assumption. Extensive experiments\nconfirm the efficacy of our algorithms and theoretical results.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15812v1",
    "published_date": "2025-04-22 11:51:20 UTC",
    "updated_date": "2025-04-22 11:51:20 UTC"
  },
  {
    "arxiv_id": "2504.15806v2",
    "title": "DAE-KAN: A Kolmogorov-Arnold Network Model for High-Index Differential-Algebraic Equations",
    "authors": [
      "Kai Luo",
      "Juan Tang",
      "Mingchao Cai",
      "Xiaoqing Zeng",
      "Manqi Xie",
      "Ming Yan"
    ],
    "abstract": "Kolmogorov-Arnold Networks (KANs) have emerged as a promising alternative to\nMulti-layer Perceptrons (MLPs) due to their superior function-fitting abilities\nin data-driven modeling. In this paper, we propose a novel framework, DAE-KAN,\nfor solving high-index differential-algebraic equations (DAEs) by integrating\nKANs with Physics-Informed Neural Networks (PINNs). This framework not only\npreserves the ability of traditional PINNs to model complex systems governed by\nphysical laws but also enhances their performance by leveraging the\nfunction-fitting strengths of KANs. Numerical experiments demonstrate that for\nDAE systems ranging from index-1 to index-3, DAE-KAN reduces the absolute\nerrors of both differential and algebraic variables by 1 to 2 orders of\nmagnitude compared to traditional PINNs. To assess the effectiveness of this\napproach, we analyze the drift-off error and find that both PINNs and DAE-KAN\noutperform classical numerical methods in controlling this phenomenon. Our\nresults highlight the potential of neural network methods, particularly\nDAE-KAN, in solving high-index DAEs with substantial computational accuracy and\ngeneralization, offering a promising solution for challenging partial\ndifferential-algebraic equations.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15806v2",
    "published_date": "2025-04-22 11:42:02 UTC",
    "updated_date": "2025-04-23 06:21:23 UTC"
  },
  {
    "arxiv_id": "2504.15804v1",
    "title": "Insights from Verification: Training a Verilog Generation LLM with Reinforcement Learning with Testbench Feedback",
    "authors": [
      "Ning Wang",
      "Bingkun Yao",
      "Jie Zhou",
      "Yuchen Hu",
      "Xi Wang",
      "Nan Guan",
      "Zhe Jiang"
    ],
    "abstract": "Large language models (LLMs) have shown strong performance in Verilog\ngeneration from natural language description. However, ensuring the functional\ncorrectness of the generated code remains a significant challenge. This paper\nintroduces a method that integrates verification insights from testbench into\nthe training of Verilog generation LLMs, aligning the training with the\nfundamental goal of hardware design: functional correctness. The main obstacle\nin using LLMs for Verilog code generation is the lack of sufficient functional\nverification data, particularly testbenches paired with design specifications\nand code. To address this problem, we introduce an automatic testbench\ngeneration pipeline that decomposes the process and uses feedback from the\nVerilog compiler simulator (VCS) to reduce hallucination and ensure\ncorrectness. We then use the testbench to evaluate the generated codes and\ncollect them for further training, where verification insights are introduced.\nOur method applies reinforcement learning (RL), specifically direct preference\noptimization (DPO), to align Verilog code generation with functional\ncorrectness by training preference pairs based on testbench outcomes. In\nevaluations on VerilogEval-Machine, VerilogEval-Human, RTLLM v1.1, RTLLM v2,\nand VerilogEval v2, our approach consistently outperforms state-of-the-art\nbaselines in generating functionally correct Verilog code. We open source all\ntraining code, data, and models at\nhttps://anonymous.4open.science/r/VeriPrefer-E88B.",
    "categories": [
      "cs.AR",
      "cs.AI"
    ],
    "primary_category": "cs.AR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15804v1",
    "published_date": "2025-04-22 11:38:14 UTC",
    "updated_date": "2025-04-22 11:38:14 UTC"
  },
  {
    "arxiv_id": "2504.15801v1",
    "title": "A closer look at how large language models trust humans: patterns and biases",
    "authors": [
      "Valeria Lerman",
      "Yaniv Dover"
    ],
    "abstract": "As large language models (LLMs) and LLM-based agents increasingly interact\nwith humans in decision-making contexts, understanding the trust dynamics\nbetween humans and AI agents becomes a central concern. While considerable\nliterature studies how humans trust AI agents, it is much less understood how\nLLM-based agents develop effective trust in humans. LLM-based agents likely\nrely on some sort of implicit effective trust in trust-related contexts (e.g.,\nevaluating individual loan applications) to assist and affect decision making.\nUsing established behavioral theories, we develop an approach that studies\nwhether LLMs trust depends on the three major trustworthiness dimensions:\ncompetence, benevolence and integrity of the human subject. We also study how\ndemographic variables affect effective trust. Across 43,200 simulated\nexperiments, for five popular language models, across five different scenarios\nwe find that LLM trust development shows an overall similarity to human trust\ndevelopment. We find that in most, but not all cases, LLM trust is strongly\npredicted by trustworthiness, and in some cases also biased by age, religion\nand gender, especially in financial scenarios. This is particularly true for\nscenarios common in the literature and for newer models. While the overall\npatterns align with human-like mechanisms of effective trust formation,\ndifferent models exhibit variation in how they estimate trust; in some cases,\ntrustworthiness and demographic factors are weak predictors of effective trust.\nThese findings call for a better understanding of AI-to-human trust dynamics\nand monitoring of biases and trust development patterns to prevent unintended\nand potentially harmful outcomes in trust-sensitive applications of AI.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15801v1",
    "published_date": "2025-04-22 11:31:50 UTC",
    "updated_date": "2025-04-22 11:31:50 UTC"
  },
  {
    "arxiv_id": "2504.15791v1",
    "title": "Crisp complexity of fuzzy classifiers",
    "authors": [
      "Raquel Fernandez-Peralta",
      "Javier Fumanal-Idocin",
      "Javier Andreu-Perez"
    ],
    "abstract": "Rule-based systems are a very popular form of explainable AI, particularly in\nthe fuzzy community, where fuzzy rules are widely used for control and\nclassification problems. However, fuzzy rule-based classifiers struggle to\nreach bigger traction outside of fuzzy venues, because users sometimes do not\nknow about fuzzy and because fuzzy partitions are not so easy to interpret in\nsome situations. In this work, we propose a methodology to reduce fuzzy\nrule-based classifiers to crisp rule-based classifiers. We study different\npossible crisp descriptions and implement an algorithm to obtain them. Also, we\nanalyze the complexity of the resulting crisp classifiers. We believe that our\nresults can help both fuzzy and non-fuzzy practitioners understand better the\nway in which fuzzy rule bases partition the feature space and how easily one\nsystem can be translated to another and vice versa. Our complexity metric can\nalso help to choose between different fuzzy classifiers based on what the\nequivalent crisp partitions look like.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15791v1",
    "published_date": "2025-04-22 11:06:25 UTC",
    "updated_date": "2025-04-22 11:06:25 UTC"
  },
  {
    "arxiv_id": "2504.15785v1",
    "title": "WALL-E 2.0: World Alignment by NeuroSymbolic Learning improves World Model-based LLM Agents",
    "authors": [
      "Siyu Zhou",
      "Tianyi Zhou",
      "Yijun Yang",
      "Guodong Long",
      "Deheng Ye",
      "Jing Jiang",
      "Chengqi Zhang"
    ],
    "abstract": "Can we build accurate world models out of large language models (LLMs)? How\ncan world models benefit LLM agents? The gap between the prior knowledge of\nLLMs and the specified environment's dynamics usually bottlenecks LLMs'\nperformance as world models. To bridge the gap, we propose a training-free\n\"world alignment\" that learns an environment's symbolic knowledge complementary\nto LLMs. The symbolic knowledge covers action rules, knowledge graphs, and\nscene graphs, which are extracted by LLMs from exploration trajectories and\nencoded into executable codes to regulate LLM agents' policies. We further\npropose an RL-free, model-based agent \"WALL-E 2.0\" through the model-predictive\ncontrol (MPC) framework. Unlike classical MPC requiring costly optimization on\nthe fly, we adopt an LLM agent as an efficient look-ahead optimizer of future\nsteps' actions by interacting with the neurosymbolic world model. While the LLM\nagent's strong heuristics make it an efficient planner in MPC, the quality of\nits planned actions is also secured by the accurate predictions of the aligned\nworld model. They together considerably improve learning efficiency in a new\nenvironment. On open-world challenges in Mars (Minecraft like) and ALFWorld\n(embodied indoor environments), WALL-E 2.0 significantly outperforms existing\nmethods, e.g., surpassing baselines in Mars by 16.1%-51.6% of success rate and\nby at least 61.7% in score. In ALFWorld, it achieves a new record 98% success\nrate after only 4 iterations.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Code is available at https://github.com/elated-sawyer/WALL-E",
    "pdf_url": "http://arxiv.org/pdf/2504.15785v1",
    "published_date": "2025-04-22 10:58:27 UTC",
    "updated_date": "2025-04-22 10:58:27 UTC"
  },
  {
    "arxiv_id": "2504.15784v1",
    "title": "Automated Creativity Evaluation for Large Language Models: A Reference-Based Approach",
    "authors": [
      "Ruizhe Li",
      "Chiwei Zhu",
      "Benfeng Xu",
      "Xiaorui Wang",
      "Zhendong Mao"
    ],
    "abstract": "Creative writing is a key capability of Large Language Models (LLMs), with\npotential applications in literature, storytelling, and various creative\ndomains. However, evaluating the creativity of machine-generated texts remains\na significant challenge, as existing methods either rely on costly manual\nannotations or fail to align closely with human assessments. In this paper, we\npropose an effective automated evaluation method based on the Torrance Test of\nCreative Writing (TTCW), which evaluates creativity as product. Our method\nemploys a reference-based Likert-style approach, scoring generated creative\ntexts relative to high-quality reference texts across various tests.\nExperimental results demonstrate that our method significantly improves the\nalignment between LLM evaluations and human assessments, achieving a pairwise\naccuracy of 0.75 (+15\\%).",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15784v1",
    "published_date": "2025-04-22 10:52:23 UTC",
    "updated_date": "2025-04-22 10:52:23 UTC"
  },
  {
    "arxiv_id": "2504.15780v1",
    "title": "TrustGeoGen: Scalable and Formal-Verified Data Engine for Trustworthy Multi-modal Geometric Problem Solving",
    "authors": [
      "Daocheng Fu",
      "Zijun Chen",
      "Renqiu Xia",
      "Qi Liu",
      "Yuan Feng",
      "Hongbin Zhou",
      "Renrui Zhang",
      "Shiyang Feng",
      "Peng Gao",
      "Junchi Yan",
      "Botian Shi",
      "Bo Zhang",
      "Yu Qiao"
    ],
    "abstract": "Mathematical geometric problem solving (GPS) often requires effective\nintegration of multimodal information and verifiable logical coherence. Despite\nthe fast development of large language models in general problem solving, it\nremains unresolved regarding with both methodology and benchmarks, especially\ngiven the fact that exiting synthetic GPS benchmarks are often not\nself-verified and contain noise and self-contradicted information due to the\nillusion of LLMs. In this paper, we propose a scalable data engine called\nTrustGeoGen for problem generation, with formal verification to provide a\nprincipled benchmark, which we believe lays the foundation for the further\ndevelopment of methods for GPS. The engine synthesizes geometric data through\nfour key innovations: 1) multimodal-aligned generation of diagrams, textual\ndescriptions, and stepwise solutions; 2) formal verification ensuring\nrule-compliant reasoning paths; 3) a bootstrapping mechanism enabling\ncomplexity escalation via recursive state generation and 4) our devised\nGeoExplore series algorithms simultaneously produce multi-solution variants and\nself-reflective backtracking traces. By formal logical verification,\nTrustGeoGen produces GeoTrust-200K dataset with guaranteed modality integrity,\nalong with GeoTrust-test testset. Experiments reveal the state-of-the-art\nmodels achieve only 49.17\\% accuracy on GeoTrust-test, demonstrating its\nevaluation stringency. Crucially, models trained on GeoTrust achieve OOD\ngeneralization on GeoQA, significantly reducing logical inconsistencies\nrelative to pseudo-label annotated by OpenAI-o1. Our code is available at\nhttps://github.com/Alpha-Innovator/TrustGeoGen",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15780v1",
    "published_date": "2025-04-22 10:45:23 UTC",
    "updated_date": "2025-04-22 10:45:23 UTC"
  },
  {
    "arxiv_id": "2504.15779v1",
    "title": "Shannon invariants: A scalable approach to information decomposition",
    "authors": [
      "Aaron J. Gutknecht",
      "Fernando E. Rosas",
      "David A. Ehrlich",
      "Abdullah Makkeh",
      "Pedro A. M. Mediano",
      "Michael Wibral"
    ],
    "abstract": "Distributed systems, such as biological and artificial neural networks,\nprocess information via complex interactions engaging multiple subsystems,\nresulting in high-order patterns with distinct properties across scales.\nInvestigating how these systems process information remains challenging due to\ndifficulties in defining appropriate multivariate metrics and ensuring their\nscalability to large systems. To address these challenges, we introduce a novel\nframework based on what we call \"Shannon invariants\" -- quantities that capture\nessential properties of high-order information processing in a way that depends\nonly on the definition of entropy and can be efficiently calculated for large\nsystems. Our theoretical results demonstrate how Shannon invariants can be used\nto resolve long-standing ambiguities regarding the interpretation of widely\nused multivariate information-theoretic measures. Moreover, our practical\nresults reveal distinctive information-processing signatures of various deep\nlearning architectures across layers, which lead to new insights into how these\nsystems process information and how this evolves during training. Overall, our\nframework resolves fundamental limitations in analyzing high-order phenomena\nand offers broad opportunities for theoretical developments and empirical\nanalyses.",
    "categories": [
      "cs.IT",
      "cs.AI",
      "cs.LG",
      "math.IT",
      "nlin.AO",
      "physics.data-an"
    ],
    "primary_category": "cs.IT",
    "comment": "16 pages, 4 Figures",
    "pdf_url": "http://arxiv.org/pdf/2504.15779v1",
    "published_date": "2025-04-22 10:41:38 UTC",
    "updated_date": "2025-04-22 10:41:38 UTC"
  },
  {
    "arxiv_id": "2504.15773v1",
    "title": "Clifford Group Equivariant Diffusion Models for 3D Molecular Generation",
    "authors": [
      "Cong Liu",
      "Sharvaree Vadgama",
      "David Ruhe",
      "Erik Bekkers",
      "Patrick Forrè"
    ],
    "abstract": "This paper explores leveraging the Clifford algebra's expressive power for\n$\\E(n)$-equivariant diffusion models. We utilize the geometric products between\nClifford multivectors and the rich geometric information encoded in Clifford\nsubspaces in \\emph{Clifford Diffusion Models} (CDMs). We extend the diffusion\nprocess beyond just Clifford one-vectors to incorporate all higher-grade\nmultivector subspaces. The data is embedded in grade-$k$ subspaces, allowing us\nto apply latent diffusion across complete multivectors. This enables CDMs to\ncapture the joint distribution across different subspaces of the algebra,\nincorporating richer geometric information through higher-order features. We\nprovide empirical results for unconditional molecular generation on the QM9\ndataset, showing that CDMs provide a promising avenue for generative modeling.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "7 pages, 1 figure, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2504.15773v1",
    "published_date": "2025-04-22 10:30:06 UTC",
    "updated_date": "2025-04-22 10:30:06 UTC"
  },
  {
    "arxiv_id": "2504.15766v1",
    "title": "Dynamic Intent Queries for Motion Transformer-based Trajectory Prediction",
    "authors": [
      "Tobias Demmler",
      "Lennart Hartung",
      "Andreas Tamke",
      "Thao Dang",
      "Alexander Hegai",
      "Karsten Haug",
      "Lars Mikelsons"
    ],
    "abstract": "In autonomous driving, accurately predicting the movements of other traffic\nparticipants is crucial, as it significantly influences a vehicle's planning\nprocesses. Modern trajectory prediction models strive to interpret complex\npatterns and dependencies from agent and map data. The Motion Transformer (MTR)\narchitecture and subsequent work define the most accurate methods in common\nbenchmarks such as the Waymo Open Motion Benchmark. The MTR model employs\npre-generated static intention points as initial goal points for trajectory\nprediction. However, the static nature of these points frequently leads to\nmisalignment with map data in specific traffic scenarios, resulting in\nunfeasible or unrealistic goal points. Our research addresses this limitation\nby integrating scene-specific dynamic intention points into the MTR model. This\nadaptation of the MTR model was trained and evaluated on the Waymo Open Motion\nDataset. Our findings demonstrate that incorporating dynamic intention points\nhas a significant positive impact on trajectory prediction accuracy, especially\nfor predictions over long time horizons. Furthermore, we analyze the impact on\nground truth trajectories which are not compliant with the map data or are\nillegal maneuvers.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15766v1",
    "published_date": "2025-04-22 10:20:35 UTC",
    "updated_date": "2025-04-22 10:20:35 UTC"
  },
  {
    "arxiv_id": "2504.15743v1",
    "title": "iMedic: Towards Smartphone-based Self-Auscultation Tool for AI-Powered Pediatric Respiratory Assessment",
    "authors": [
      "Seung Gyu Jeong",
      "Sung Woo Nam",
      "Seong Kwan Jung",
      "Seong-Eun Kim"
    ],
    "abstract": "Respiratory auscultation is crucial for early detection of pediatric\npneumonia, a condition that can quickly worsen without timely intervention. In\nareas with limited physician access, effective auscultation is challenging. We\npresent a smartphone-based system that leverages built-in microphones and\nadvanced deep learning algorithms to detect abnormal respiratory sounds\nindicative of pneumonia risk. Our end-to-end deep learning framework employs\ndomain generalization to integrate a large electronic stethoscope dataset with\na smaller smartphone-derived dataset, enabling robust feature learning for\naccurate respiratory assessments without expensive equipment. The accompanying\nmobile application guides caregivers in collecting high-quality lung sound\nsamples and provides immediate feedback on potential pneumonia risks. User\nstudies show strong classification performance and high acceptance,\ndemonstrating the system's ability to facilitate proactive interventions and\nreduce preventable childhood pneumonia deaths. By seamlessly integrating into\nubiquitous smartphones, this approach offers a promising avenue for more\nequitable and comprehensive remote pediatric care.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15743v1",
    "published_date": "2025-04-22 09:45:50 UTC",
    "updated_date": "2025-04-22 09:45:50 UTC"
  },
  {
    "arxiv_id": "2504.15724v1",
    "title": "Collaborative Split Federated Learning with Parallel Training and Aggregation",
    "authors": [
      "Yiannis Papageorgiou",
      "Yannis Thomas",
      "Alexios Filippakopoulos",
      "Ramin Khalili",
      "Iordanis Koutsopoulos"
    ],
    "abstract": "Federated learning (FL) operates based on model exchanges between the server\nand the clients, and it suffers from significant client-side computation and\ncommunication burden. Split federated learning (SFL) arises a promising\nsolution by splitting the model into two parts, that are trained sequentially:\nthe clients train the first part of the model (client-side model) and transmit\nit to the server that trains the second (server-side model). Existing SFL\nschemes though still exhibit long training delays and significant communication\noverhead, especially when clients of different computing capability\nparticipate. Thus, we propose Collaborative-Split Federated Learning~(C-SFL), a\nnovel scheme that splits the model into three parts, namely the model parts\ntrained at the computationally weak clients, the ones trained at the\ncomputationally strong clients, and the ones at the server. Unlike existing\nworks, C-SFL enables parallel training and aggregation of model's parts at the\nclients and at the server, resulting in reduced training delays and\ncommmunication overhead while improving the model's accuracy. Experiments\nverify the multiple gains of C-SFL against the existing schemes.",
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15724v1",
    "published_date": "2025-04-22 09:18:57 UTC",
    "updated_date": "2025-04-22 09:18:57 UTC"
  },
  {
    "arxiv_id": "2504.15719v1",
    "title": "Implementing Rational Choice Functions with LLMs and Measuring their Alignment with User Preferences",
    "authors": [
      "Anna Karnysheva",
      "Christian Drescher",
      "Dietrich Klakow"
    ],
    "abstract": "As large language models (LLMs) become integral to intelligent user\ninterfaces (IUIs), their role as decision-making agents raises critical\nconcerns about alignment. Although extensive research has addressed issues such\nas factuality, bias, and toxicity, comparatively little attention has been paid\nto measuring alignment to preferences, i.e., the relative desirability of\ndifferent alternatives, a concept used in decision making, economics, and\nsocial choice theory. However, a reliable decision-making agent makes choices\nthat align well with user preferences.\n  In this paper, we generalize existing methods that exploit LLMs for ranking\nalternative outcomes by addressing alignment with the broader and more flexible\nconcept of user preferences, which includes both strict preferences and\nindifference among alternatives. To this end, we put forward design principles\nfor using LLMs to implement rational choice functions, and provide the\nnecessary tools to measure preference satisfaction. We demonstrate the\napplicability of our approach through an empirical study in a practical\napplication of an IUI in the automotive domain.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15719v1",
    "published_date": "2025-04-22 09:08:21 UTC",
    "updated_date": "2025-04-22 09:08:21 UTC"
  },
  {
    "arxiv_id": "2504.15716v1",
    "title": "DianJin-R1: Evaluating and Enhancing Financial Reasoning in Large Language Models",
    "authors": [
      "Jie Zhu",
      "Qian Chen",
      "Huaixia Dou",
      "Junhui Li",
      "Lifan Guo",
      "Feng Chen",
      "Chi Zhang"
    ],
    "abstract": "Effective reasoning remains a core challenge for large language models (LLMs)\nin the financial domain, where tasks often require domain-specific knowledge,\nprecise numerical calculations, and strict adherence to compliance rules. We\npropose DianJin-R1, a reasoning-enhanced framework designed to address these\nchallenges through reasoning-augmented supervision and reinforcement learning.\nCentral to our approach is DianJin-R1-Data, a high-quality dataset constructed\nfrom CFLUE, FinQA, and a proprietary compliance corpus (Chinese Compliance\nCheck, CCC), combining diverse financial reasoning scenarios with verified\nannotations. Our models, DianJin-R1-7B and DianJin-R1-32B, are fine-tuned from\nQwen2.5-7B-Instruct and Qwen2.5-32B-Instruct using a structured format that\ngenerates both reasoning steps and final answers. To further refine reasoning\nquality, we apply Group Relative Policy Optimization (GRPO), a reinforcement\nlearning method that incorporates dual reward signals: one encouraging\nstructured outputs and another rewarding answer correctness. We evaluate our\nmodels on five benchmarks: three financial datasets (CFLUE, FinQA, and CCC) and\ntwo general reasoning benchmarks (MATH-500 and GPQA-Diamond). Experimental\nresults show that DianJin-R1 models consistently outperform their non-reasoning\ncounterparts, especially on complex financial tasks. Moreover, on the\nreal-world CCC dataset, our single-call reasoning models match or even surpass\nthe performance of multi-agent systems that require significantly more\ncomputational cost. These findings demonstrate the effectiveness of DianJin-R1\nin enhancing financial reasoning through structured supervision and\nreward-aligned learning, offering a scalable and practical solution for\nreal-world applications.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15716v1",
    "published_date": "2025-04-22 09:01:04 UTC",
    "updated_date": "2025-04-22 09:01:04 UTC"
  },
  {
    "arxiv_id": "2504.15707v1",
    "title": "RePOPE: Impact of Annotation Errors on the POPE Benchmark",
    "authors": [
      "Yannic Neuhaus",
      "Matthias Hein"
    ],
    "abstract": "Since data annotation is costly, benchmark datasets often incorporate labels\nfrom established image datasets. In this work, we assess the impact of label\nerrors in MSCOCO on the frequently used object hallucination benchmark POPE. We\nre-annotate the benchmark images and identify an imbalance in annotation errors\nacross different subsets. Evaluating multiple models on the revised labels,\nwhich we denote as RePOPE, we observe notable shifts in model rankings,\nhighlighting the impact of label quality. Code and data are available at\nhttps://github.com/YanNeu/RePOPE .",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15707v1",
    "published_date": "2025-04-22 08:47:59 UTC",
    "updated_date": "2025-04-22 08:47:59 UTC"
  },
  {
    "arxiv_id": "2504.15699v1",
    "title": "Advancing Embodied Agent Security: From Safety Benchmarks to Input Moderation",
    "authors": [
      "Ning Wang",
      "Zihan Yan",
      "Weiyang Li",
      "Chuan Ma",
      "He Chen",
      "Tao Xiang"
    ],
    "abstract": "Embodied agents exhibit immense potential across a multitude of domains,\nmaking the assurance of their behavioral safety a fundamental prerequisite for\ntheir widespread deployment. However, existing research predominantly\nconcentrates on the security of general large language models, lacking\nspecialized methodologies for establishing safety benchmarks and input\nmoderation tailored to embodied agents. To bridge this gap, this paper\nintroduces a novel input moderation framework, meticulously designed to\nsafeguard embodied agents. This framework encompasses the entire pipeline,\nincluding taxonomy definition, dataset curation, moderator architecture, model\ntraining, and rigorous evaluation. Notably, we introduce EAsafetyBench, a\nmeticulously crafted safety benchmark engineered to facilitate both the\ntraining and stringent assessment of moderators specifically designed for\nembodied agents. Furthermore, we propose Pinpoint, an innovative\nprompt-decoupled input moderation scheme that harnesses a masked attention\nmechanism to effectively isolate and mitigate the influence of functional\nprompts on moderation tasks. Extensive experiments conducted on diverse\nbenchmark datasets and models validate the feasibility and efficacy of the\nproposed approach. The results demonstrate that our methodologies achieve an\nimpressive average detection accuracy of 94.58%, surpassing the performance of\nexisting state-of-the-art techniques, alongside an exceptional moderation\nprocessing time of merely 0.002 seconds per instance.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "9 pages",
    "pdf_url": "http://arxiv.org/pdf/2504.15699v1",
    "published_date": "2025-04-22 08:34:35 UTC",
    "updated_date": "2025-04-22 08:34:35 UTC"
  },
  {
    "arxiv_id": "2504.15668v1",
    "title": "Exploring Inevitable Waypoints for Unsolvability Explanation in Hybrid Planning Problems",
    "authors": [
      "Mir Md Sajid Sarwar",
      "Rajarshi Ray"
    ],
    "abstract": "Explaining unsolvability of planning problems is of significant research\ninterest in Explainable AI Planning. AI planning literature has reported\nseveral research efforts on generating explanations of solutions to planning\nproblems. However, explaining the unsolvability of planning problems remains a\nlargely open and understudied problem. A widely practiced approach to plan\ngeneration and automated problem solving, in general, is to decompose tasks\ninto sub-problems that help progressively converge towards the goal. In this\npaper, we propose to adopt the same philosophy of sub-problem identification as\na mechanism for analyzing and explaining unsolvability of planning problems in\nhybrid systems. In particular, for a given unsolvable planning problem, we\npropose to identify common waypoints, which are universal obstacles to plan\nexistence; in other words, they appear on every plan from the source to the\nplanning goal. This work envisions such waypoints as sub-problems of the\nplanning problem and the unreachability of any of these waypoints as an\nexplanation for the unsolvability of the original planning problem. We propose\na novel method of waypoint identification by casting the problem as an instance\nof the longest common subsequence problem, a widely popular problem in computer\nscience, typically considered as an illustrative example for the dynamic\nprogramming paradigm. Once the waypoints are identified, we perform symbolic\nreachability analysis on them to identify the earliest unreachable waypoint and\nreport it as the explanation of unsolvability. We present experimental results\non unsolvable planning problems in hybrid domains.",
    "categories": [
      "cs.AI",
      "cs.FL",
      "I.2.0; F.4.3"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15668v1",
    "published_date": "2025-04-22 07:45:30 UTC",
    "updated_date": "2025-04-22 07:45:30 UTC"
  },
  {
    "arxiv_id": "2504.15663v1",
    "title": "FADEL: Uncertainty-aware Fake Audio Detection with Evidential Deep Learning",
    "authors": [
      "Ju Yeon Kang",
      "Ji Won Yoon",
      "Semin Kim",
      "Min Hyun Han",
      "Nam Soo Kim"
    ],
    "abstract": "Recently, fake audio detection has gained significant attention, as\nadvancements in speech synthesis and voice conversion have increased the\nvulnerability of automatic speaker verification (ASV) systems to spoofing\nattacks. A key challenge in this task is generalizing models to detect unseen,\nout-of-distribution (OOD) attacks. Although existing approaches have shown\npromising results, they inherently suffer from overconfidence issues due to the\nusage of softmax for classification, which can produce unreliable predictions\nwhen encountering unpredictable spoofing attempts. To deal with this\nlimitation, we propose a novel framework called fake audio detection with\nevidential learning (FADEL). By modeling class probabilities with a Dirichlet\ndistribution, FADEL incorporates model uncertainty into its predictions,\nthereby leading to more robust performance in OOD scenarios. Experimental\nresults on the ASVspoof2019 Logical Access (LA) and ASVspoof2021 LA datasets\nindicate that the proposed method significantly improves the performance of\nbaseline models. Furthermore, we demonstrate the validity of uncertainty\nestimation by analyzing a strong correlation between average uncertainty and\nequal error rate (EER) across different spoofing algorithms.",
    "categories": [
      "eess.AS",
      "cs.AI"
    ],
    "primary_category": "eess.AS",
    "comment": "Accepted at ICASSP 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.15663v1",
    "published_date": "2025-04-22 07:40:35 UTC",
    "updated_date": "2025-04-22 07:40:35 UTC"
  },
  {
    "arxiv_id": "2504.15659v1",
    "title": "VeriCoder: Enhancing LLM-Based RTL Code Generation through Functional Correctness Validation",
    "authors": [
      "Anjiang Wei",
      "Huanmi Tan",
      "Tarun Suresh",
      "Daniel Mendoza",
      "Thiago S. F. X. Teixeira",
      "Ke Wang",
      "Caroline Trippel",
      "Alex Aiken"
    ],
    "abstract": "Recent advances in Large Language Models (LLMs) have sparked growing interest\nin applying them to Electronic Design Automation (EDA) tasks, particularly\nRegister Transfer Level (RTL) code generation. While several RTL datasets have\nbeen introduced, most focus on syntactic validity rather than functional\nvalidation with tests, leading to training examples that compile but may not\nimplement the intended behavior. We present VERICODER, a model for RTL code\ngeneration fine-tuned on a dataset validated for functional correctness. This\nfine-tuning dataset is constructed using a novel methodology that combines unit\ntest generation with feedback-directed refinement. Given a natural language\nspecification and an initial RTL design, we prompt a teacher model\n(GPT-4o-mini) to generate unit tests and iteratively revise the RTL design\nbased on its simulation results using the generated tests. If necessary, the\nteacher model also updates the tests to ensure they comply with the natural\nlanguage specification. As a result of this process, every example in our\ndataset is functionally validated, consisting of a natural language\ndescription, an RTL implementation, and passing tests. Fine-tuned on this\ndataset of over 125,000 examples, VERICODER achieves state-of-the-art metrics\nin functional correctness on VerilogEval and RTLLM, with relative gains of up\nto 71.7% and 27.4% respectively. An ablation study further shows that models\ntrained on our functionally validated dataset outperform those trained on\nfunctionally non-validated datasets, underscoring the importance of\nhigh-quality datasets in RTL code generation.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.SE"
    ],
    "primary_category": "cs.AR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15659v1",
    "published_date": "2025-04-22 07:32:46 UTC",
    "updated_date": "2025-04-22 07:32:46 UTC"
  },
  {
    "arxiv_id": "2504.15654v1",
    "title": "A Vision-Enabled Prosthetic Hand for Children with Upper Limb Disabilities",
    "authors": [
      "Md Abdul Baset Sarker",
      "Art Nguyen",
      "Sigmond Kukla",
      "Kevin Fite",
      "Masudul H. Imtiaz"
    ],
    "abstract": "This paper introduces a novel AI vision-enabled pediatric prosthetic hand\ndesigned to assist children aged 10-12 with upper limb disabilities. The\nprosthesis features an anthropomorphic appearance, multi-articulating\nfunctionality, and a lightweight design that mimics a natural hand, making it\nboth accessible and affordable for low-income families. Using 3D printing\ntechnology and integrating advanced machine vision, sensing, and embedded\ncomputing, the prosthetic hand offers a low-cost, customizable solution that\naddresses the limitations of current myoelectric prostheses. A micro camera is\ninterfaced with a low-power FPGA for real-time object detection and assists\nwith precise grasping. The onboard DL-based object detection and grasp\nclassification models achieved accuracies of 96% and 100% respectively. In the\nforce prediction, the mean absolute error was found to be 0.018. The features\nof the proposed prosthetic hand can thus be summarized as: a) a wrist-mounted\nmicro camera for artificial sensing, enabling a wide range of hand-based tasks;\nb) real-time object detection and distance estimation for precise grasping; and\nc) ultra-low-power operation that delivers high performance within constrained\npower and resource limits.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15654v1",
    "published_date": "2025-04-22 07:23:51 UTC",
    "updated_date": "2025-04-22 07:23:51 UTC"
  },
  {
    "arxiv_id": "2504.15640v1",
    "title": "Cost-Effective Text Clustering with Large Language Models",
    "authors": [
      "Hongtao Wang",
      "Taiyan Zhang",
      "Renchi Yang",
      "Jianliang Xu"
    ],
    "abstract": "Text clustering aims to automatically partition a collection of text\ndocuments into distinct clusters based on linguistic features. In the\nliterature, this task is usually framed as metric clustering based on text\nembeddings from pre-trained encoders or a graph clustering problem upon\npairwise similarities from an oracle, e.g., a large ML model. Recently, large\nlanguage models (LLMs) bring significant advancement in this field by offering\ncontextualized text embeddings and highly accurate similarity scores, but\nmeanwhile, present grand challenges to cope with substantial computational\nand/or financial overhead caused by numerous API-based queries or inference\ncalls to the models.\n  In response, this paper proposes TECL, a cost-effective framework that taps\ninto the feedback from LLMs for accurate text clustering within a limited\nbudget of queries to LLMs. Under the hood, TECL adopts our EdgeLLM or\nTriangleLLM to construct must-link/cannot-link constraints for text pairs, and\nfurther leverages such constraints as supervision signals input to our weighted\nconstrained clustering approach to generate clusters. Particularly, EdgeLLM\n(resp. TriangleLLM) enables the identification of informative text pairs (resp.\ntriplets) for querying LLMs via well-thought-out greedy algorithms and accurate\nextraction of pairwise constraints through carefully-crafted prompting\ntechniques. Our experiments on multiple benchmark datasets exhibit that TECL\nconsistently and considerably outperforms existing solutions in unsupervised\ntext clustering under the same query cost for LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15640v1",
    "published_date": "2025-04-22 06:57:49 UTC",
    "updated_date": "2025-04-22 06:57:49 UTC"
  },
  {
    "arxiv_id": "2504.15637v1",
    "title": "DR.FIX: Automatically Fixing Data Races at Industry Scale",
    "authors": [
      "Farnaz Behrang",
      "Zhizhou Zhang",
      "Georgian-Vlad Saioc",
      "Peng Liu",
      "Milind Chabbi"
    ],
    "abstract": "Data races are a prevalent class of concurrency bugs in shared-memory\nparallel programs, posing significant challenges to software reliability and\nreproducibility. While there is an extensive body of research on detecting data\nraces and a wealth of practical detection tools across various programming\nlanguages, considerably less effort has been directed toward automatically\nfixing data races at an industrial scale. In large codebases, data races are\ncontinuously introduced and exhibit myriad patterns, making automated fixing\nparticularly challenging.\n  In this paper, we tackle the problem of automatically fixing data races at an\nindustrial scale. We present Dr.Fix, a tool that combines large language models\n(LLMs) with program analysis to generate fixes for data races in real-world\nsettings, effectively addressing a broad spectrum of racy patterns in complex\ncode contexts. Implemented for Go--the programming language widely used in\nmodern microservice architectures where concurrency is pervasive and data races\nare common--Dr.Fix seamlessly integrates into existing development workflows.\nWe detail the design of Dr.Fix and examine how individual design choices\ninfluence the quality of the fixes produced. Over the past 18 months, Dr.Fix\nhas been integrated into developer workflows at Uber demonstrating its\npractical utility. During this period, Dr.Fix produced patches for 224 (55%)\nfrom a corpus of 404 data races spanning various categories; 193 of these\npatches (86%) were accepted by more than a hundred developers via code reviews\nand integrated into the codebase.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.LG",
      "cs.PL",
      "cs.SE"
    ],
    "primary_category": "cs.DC",
    "comment": "To appear in PLDI 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.15637v1",
    "published_date": "2025-04-22 06:56:15 UTC",
    "updated_date": "2025-04-22 06:56:15 UTC"
  },
  {
    "arxiv_id": "2504.15634v1",
    "title": "Enhancing Reinforcement learning in 3-Dimensional Hydrophobic-Polar Protein Folding Model with Attention-based layers",
    "authors": [
      "Peizheng Liu",
      "Hitoshi Iba"
    ],
    "abstract": "Transformer-based architectures have recently propelled advances in sequence\nmodeling across domains, but their application to the hydrophobic-hydrophilic\n(H-P) model for protein folding remains relatively unexplored. In this work, we\nadapt a Deep Q-Network (DQN) integrated with attention mechanisms\n(Transformers) to address the 3D H-P protein folding problem. Our system\nformulates folding decisions as a self-avoiding walk in a reinforced\nenvironment, and employs a specialized reward function based on favorable\nhydrophobic interactions. To improve performance, the method incorporates\nvalidity check including symmetry-breaking constraints, dueling and double\nQ-learning, and prioritized replay to focus learning on critical transitions.\nExperimental evaluations on standard benchmark sequences demonstrate that our\napproach achieves several known best solutions for shorter sequences, and\nobtains near-optimal results for longer chains. This study underscores the\npromise of attention-based reinforcement learning for protein folding, and\ncreated a prototype of Transformer-based Q-network structure for 3-dimensional\nlattice models.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15634v1",
    "published_date": "2025-04-22 06:53:36 UTC",
    "updated_date": "2025-04-22 06:53:36 UTC"
  },
  {
    "arxiv_id": "2504.15610v2",
    "title": "A LoRA-Based Approach to Fine-Tuning LLMs for Educational Guidance in Resource-Constrained Settings",
    "authors": [
      "Md Millat Hosen"
    ],
    "abstract": "The current study describes a cost-effective method for adapting large\nlanguage models (LLMs) for academic advising with study-abroad contexts in mind\nand for application in low-resource methods for acculturation. With the\nMistral-7B-Instruct model applied with a Low-Rank Adaptation (LoRA) method and\na 4-bit quantization method, the model underwent training in two distinct\nstages related to this study's purpose to enhance domain specificity while\nmaintaining computational efficiency. In Phase 1, the model was conditioned\nwith a synthetic dataset via the Gemini Pro API, and in Phase 2, it was trained\nwith manually curated datasets from the StudyAbroadGPT project to achieve\nenhanced, contextualized responses. Technical innovations entailed\nmemory-efficient quantization, parameter-efficient adaptation, and continuous\ntraining analytics via Weights & Biases. After training, this study\ndemonstrated a reduction in training loss by 52.7%, 92% accuracy in\ndomain-specific recommendations, achieved 95% markdown-based formatting\nsupport, and a median run-rate of 100 samples per second on off-the-shelf GPU\nequipment. These findings support the effective application of\ninstruction-tuned LLMs within educational advisers, especially in low-resource\ninstitutional scenarios. Limitations included decreased generalizability and\nthe application of a synthetically generated dataset, but this framework is\nscalable for adding new multilingual-augmented and real-time academic advising\nprocesses. Future directions may include plans for the integration of\nretrieval-augmented generation, applying dynamic quantization routines, and\nconnecting to real-time academic databases to increase adaptability and\naccuracy.",
    "categories": [
      "cs.AI",
      "68T05 (Learning and adaptive systems), 68T07 (Artificial\n  intelligence and education)"
    ],
    "primary_category": "cs.AI",
    "comment": "18 pages, 6 figures (3 graphs + 3 flowchart/architecture diagrams),\n  submitted as a preprint for review consideration in AI for Education or\n  Machine Learning applications in low-resource settings. Includes detailed\n  experiments with LoRA and quantization methods for efficient LLM fine-tuning",
    "pdf_url": "http://arxiv.org/pdf/2504.15610v2",
    "published_date": "2025-04-22 06:08:13 UTC",
    "updated_date": "2025-04-23 04:59:47 UTC"
  },
  {
    "arxiv_id": "2504.15604v1",
    "title": "Exploring Next Token Prediction in Theory of Mind (ToM) Tasks: Comparative Experiments with GPT-2 and LLaMA-2 AI Models",
    "authors": [
      "Pavan Yadav",
      "Nikhil Khandalkar",
      "Krishna Shinde",
      "Lokesh B. Ramegowda",
      "Rajarshi Das"
    ],
    "abstract": "Language models have made significant progress in generating coherent text\nand predicting next tokens based on input prompts. This study compares the\nnext-token prediction performance of two well-known models: OpenAI's GPT-2 and\nMeta's Llama-2-7b-chat-hf on Theory of Mind (ToM) tasks. To evaluate their\ncapabilities, we built a dataset from 10 short stories sourced from the Explore\nToM Dataset. We enhanced these stories by programmatically inserting additional\nsentences (infills) using GPT-4, creating variations that introduce different\nlevels of contextual complexity. This setup enables analysis of how increasing\ncontext affects model performance. We tested both models under four temperature\nsettings (0.01, 0.5, 1.0, 2.0) and evaluated their ability to predict the next\ntoken across three reasoning levels. Zero-order reasoning involves tracking the\nstate, either current (ground truth) or past (memory). First-order reasoning\nconcerns understanding another's mental state (e.g., \"Does Anne know the apple\nis salted?\"). Second-order reasoning adds recursion (e.g., \"Does Anne think\nthat Charles knows the apple is salted?\").\n  Our results show that adding more infill sentences slightly reduces\nprediction accuracy, as added context increases complexity and ambiguity.\nLlama-2 consistently outperforms GPT-2 in prediction accuracy, especially at\nlower temperatures, demonstrating greater confidence in selecting the most\nprobable token. As reasoning complexity rises, model responses diverge more.\nNotably, GPT-2 and Llama-2 display greater variability in predictions during\nfirst- and second-order reasoning tasks. These findings illustrate how model\narchitecture, temperature, and contextual complexity influence next-token\nprediction, contributing to a better understanding of the strengths and\nlimitations of current language models.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "75 pages, 60 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.15604v1",
    "published_date": "2025-04-22 05:52:55 UTC",
    "updated_date": "2025-04-22 05:52:55 UTC"
  },
  {
    "arxiv_id": "2504.15587v1",
    "title": "MetaMolGen: A Neural Graph Motif Generation Model for De Novo Molecular Design",
    "authors": [
      "Zimo Yan",
      "Jie Zhang",
      "Zheng Xie",
      "Chang Liu",
      "Yizhen Liu",
      "Yiping Song"
    ],
    "abstract": "Molecular generation plays an important role in drug discovery and materials\nscience, especially in data-scarce scenarios where traditional generative\nmodels often struggle to achieve satisfactory conditional generalization. To\naddress this challenge, we propose MetaMolGen, a first-order\nmeta-learning-based molecular generator designed for few-shot and\nproperty-conditioned molecular generation. MetaMolGen standardizes the\ndistribution of graph motifs by mapping them to a normalized latent space, and\nemploys a lightweight autoregressive sequence model to generate SMILES\nsequences that faithfully reflect the underlying molecular structure. In\naddition, it supports conditional generation of molecules with target\nproperties through a learnable property projector integrated into the\ngenerative process.Experimental results demonstrate that MetaMolGen\nconsistently generates valid and diverse SMILES sequences under low-data\nregimes, outperforming conventional baselines. This highlights its advantage in\nfast adaptation and efficient conditional generation for practical molecular\ndesign.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15587v1",
    "published_date": "2025-04-22 05:04:33 UTC",
    "updated_date": "2025-04-22 05:04:33 UTC"
  },
  {
    "arxiv_id": "2504.15585v1",
    "title": "A Comprehensive Survey in LLM(-Agent) Full Stack Safety: Data, Training and Deployment",
    "authors": [
      "Kun Wang",
      "Guibin Zhang",
      "Zhenhong Zhou",
      "Jiahao Wu",
      "Miao Yu",
      "Shiqian Zhao",
      "Chenlong Yin",
      "Jinhu Fu",
      "Yibo Yan",
      "Hanjun Luo",
      "Liang Lin",
      "Zhihao Xu",
      "Haolang Lu",
      "Xinye Cao",
      "Xinyun Zhou",
      "Weifei Jin",
      "Fanci Meng",
      "Junyuan Mao",
      "Hao Wu",
      "Minghe Wang",
      "Fan Zhang",
      "Junfeng Fang",
      "Chengwei Liu",
      "Yifan Zhang",
      "Qiankun Li",
      "Chongye Guo",
      "Yalan Qin",
      "Yi Ding",
      "Donghai Hong",
      "Jiaming Ji",
      "Xinfeng Li",
      "Yifan Jiang",
      "Dongxia Wang",
      "Yihao Huang",
      "Yufei Guo",
      "Jen-tse Huang",
      "Yanwei Yue",
      "Wenke Huang",
      "Guancheng Wan",
      "Tianlin Li",
      "Lei Bai",
      "Jie Zhang",
      "Qing Guo",
      "Jingyi Wang",
      "Tianlong Chen",
      "Joey Tianyi Zhou",
      "Xiaojun Jia",
      "Weisong Sun",
      "Cong Wu",
      "Jing Chen",
      "Xuming Hu",
      "Yiming Li",
      "Xiao Wang",
      "Ningyu Zhang",
      "Luu Anh Tuan",
      "Guowen Xu",
      "Tianwei Zhang",
      "Xingjun Ma",
      "Xiang Wang",
      "Bo An",
      "Jun Sun",
      "Mohit Bansal",
      "Shirui Pan",
      "Yuval Elovici",
      "Bhavya Kailkhura",
      "Bo Li",
      "Yaodong Yang",
      "Hongwei Li",
      "Wenyuan Xu",
      "Yizhou Sun",
      "Wei Wang",
      "Qing Li",
      "Ke Tang",
      "Yu-Gang Jiang",
      "Felix Juefei-Xu",
      "Hui Xiong",
      "Xiaofeng Wang",
      "Shuicheng Yan",
      "Dacheng Tao",
      "Philip S. Yu",
      "Qingsong Wen",
      "Yang Liu"
    ],
    "abstract": "The remarkable success of Large Language Models (LLMs) has illuminated a\npromising pathway toward achieving Artificial General Intelligence for both\nacademic and industrial communities, owing to their unprecedented performance\nacross various applications. As LLMs continue to gain prominence in both\nresearch and commercial domains, their security and safety implications have\nbecome a growing concern, not only for researchers and corporations but also\nfor every nation. Currently, existing surveys on LLM safety primarily focus on\nspecific stages of the LLM lifecycle, e.g., deployment phase or fine-tuning\nphase, lacking a comprehensive understanding of the entire \"lifechain\" of LLMs.\nTo address this gap, this paper introduces, for the first time, the concept of\n\"full-stack\" safety to systematically consider safety issues throughout the\nentire process of LLM training, deployment, and eventual commercialization.\nCompared to the off-the-shelf LLM safety surveys, our work demonstrates several\ndistinctive advantages: (I) Comprehensive Perspective. We define the complete\nLLM lifecycle as encompassing data preparation, pre-training, post-training,\ndeployment and final commercialization. To our knowledge, this represents the\nfirst safety survey to encompass the entire lifecycle of LLMs. (II) Extensive\nLiterature Support. Our research is grounded in an exhaustive review of over\n800+ papers, ensuring comprehensive coverage and systematic organization of\nsecurity issues within a more holistic understanding. (III) Unique Insights.\nThrough systematic literature analysis, we have developed reliable roadmaps and\nperspectives for each chapter. Our work identifies promising research\ndirections, including safety in data generation, alignment techniques, model\nediting, and LLM-based agent systems. These insights provide valuable guidance\nfor researchers pursuing future work in this field.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15585v1",
    "published_date": "2025-04-22 05:02:49 UTC",
    "updated_date": "2025-04-22 05:02:49 UTC"
  },
  {
    "arxiv_id": "2504.15564v1",
    "title": "A Large-scale Class-level Benchmark Dataset for Code Generation with LLMs",
    "authors": [
      "Musfiqur Rahman",
      "SayedHassan Khatoonabadi",
      "Emad Shihab"
    ],
    "abstract": "Recent advancements in large language models (LLMs) have demonstrated\npromising capabilities in code generation tasks. However, most existing\nbenchmarks focus on isolated functions and fail to capture the complexity of\nreal-world, class-level software structures. To address this gap, we introduce\na large-scale, Python class-level dataset curated from $13{,}174$ real-world\nopen-source projects. The dataset contains over 842,000 class skeletons, each\nincluding class and method signatures, along with associated docstrings when\navailable. We preserve structural and contextual dependencies critical to\nrealistic software development scenarios and enrich the dataset with static\ncode metrics to support downstream analysis. To evaluate the usefulness of this\ndataset, we use extracted class skeletons as prompts for GPT-4 to generate full\nclass implementations. Results show that the LLM-generated classes exhibit\nstrong lexical and structural similarity to human-written counterparts, with\naverage ROUGE@L, BLEU, and TSED scores of 0.80, 0.59, and 0.73, respectively.\nThese findings confirm that well-structured prompts derived from real-world\nclass skeletons significantly enhance LLM performance in class-level code\ngeneration. This dataset offers a valuable resource for benchmarking, training,\nand improving LLMs in realistic software engineering contexts.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "This paper was submitted to the 29th International Conference on\n  Evaluation and Assessment in Software Engineering (EASE 2025) AI models/data\n  track",
    "pdf_url": "http://arxiv.org/pdf/2504.15564v1",
    "published_date": "2025-04-22 03:33:57 UTC",
    "updated_date": "2025-04-22 03:33:57 UTC"
  },
  {
    "arxiv_id": "2504.15552v1",
    "title": "A Multi-Agent Framework for Automated Qinqiang Opera Script Generation Using Large Language Models",
    "authors": [
      "Gengxian Cao",
      "Fengyuan Li",
      "Hong Duan",
      "Ye Yang",
      "Bofeng Wang",
      "Donghe Li"
    ],
    "abstract": "This paper introduces a novel multi-Agent framework that automates the end to\nend production of Qinqiang opera by integrating Large Language Models , visual\ngeneration, and Text to Speech synthesis. Three specialized agents collaborate\nin sequence: Agent1 uses an LLM to craft coherent, culturally grounded\nscripts;Agent2 employs visual generation models to render contextually accurate\nstage scenes; and Agent3 leverages TTS to produce synchronized, emotionally\nexpressive vocal performances. In a case study on Dou E Yuan, the system\nachieved expert ratings of 3.8 for script fidelity, 3.5 for visual coherence,\nand 3.8 for speech accuracy-culminating in an overall score of 3.6, a 0.3 point\nimprovement over a Single Agent baseline. Ablation experiments demonstrate that\nremoving Agent2 or Agent3 leads to drops of 0.4 and 0.5 points, respectively,\nunderscoring the value of modular collaboration. This work showcases how AI\ndriven pipelines can streamline and scale the preservation of traditional\nperforming arts, and points toward future enhancements in cross modal\nalignment, richer emotional nuance, and support for additional opera genres.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "17 pages,7 figures,1 tables",
    "pdf_url": "http://arxiv.org/pdf/2504.15552v1",
    "published_date": "2025-04-22 03:14:29 UTC",
    "updated_date": "2025-04-22 03:14:29 UTC"
  },
  {
    "arxiv_id": "2504.15549v1",
    "title": "Do It For Me vs. Do It With Me: Investigating User Perceptions of Different Paradigms of Automation in Copilots for Feature-Rich Software",
    "authors": [
      "Anjali Khurana",
      "Xiaotian Su",
      "April Yi Wang",
      "Parmit K Chilana"
    ],
    "abstract": "Large Language Model (LLM)-based in-application assistants, or copilots, can\nautomate software tasks, but users often prefer learning by doing, raising\nquestions about the optimal level of automation for an effective user\nexperience. We investigated two automation paradigms by designing and\nimplementing a fully automated copilot (AutoCopilot) and a semi-automated\ncopilot (GuidedCopilot) that automates trivial steps while offering\nstep-by-step visual guidance. In a user study (N=20) across data analysis and\nvisual design tasks, GuidedCopilot outperformed AutoCopilot in user control,\nsoftware utility, and learnability, especially for exploratory and creative\ntasks, while AutoCopilot saved time for simpler visual tasks. A follow-up\ndesign exploration (N=10) enhanced GuidedCopilot with task-and state-aware\nfeatures, including in-context preview clips and adaptive instructions. Our\nfindings highlight the critical role of user control and tailored guidance in\ndesigning the next generation of copilots that enhance productivity, support\ndiverse skill levels, and foster deeper software engagement.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.HC",
    "comment": "Accepted for publication in the CHI Conference on Human Factors in\n  Computing Systems (CHI 2025), April 26 - May 1, 2025, Yokohama, Japan",
    "pdf_url": "http://arxiv.org/pdf/2504.15549v1",
    "published_date": "2025-04-22 03:11:10 UTC",
    "updated_date": "2025-04-22 03:11:10 UTC"
  },
  {
    "arxiv_id": "2504.15546v1",
    "title": "A Framework for Testing and Adapting REST APIs as LLM Tools",
    "authors": [
      "Jayachandu Bandlamudi",
      "Ritwik Chaudhuri",
      "Neelamadhav Gantayat",
      "Kushal Mukherjee",
      "Prerna Agarwal",
      "Renuka Sindhgatta",
      "Sameep Mehta"
    ],
    "abstract": "Large Language Models (LLMs) are enabling autonomous agents to perform\ncomplex workflows using external tools or functions, often provided via REST\nAPIs in enterprise systems. However, directly utilizing these APIs as tools\nposes challenges due to their complex input schemas, elaborate responses, and\noften ambiguous documentation. Current benchmarks for tool testing do not\nadequately address these complexities, leading to a critical gap in evaluating\nAPI readiness for agent-driven automation. In this work, we present a novel\ntesting framework aimed at evaluating and enhancing the readiness of REST APIs\nto function as tools for LLM-based agents. Our framework transforms apis as\ntools, generates comprehensive test cases for the APIs, translates tests cases\ninto natural language instructions suitable for agents, enriches tool\ndefinitions and evaluates the agent's ability t correctly invoke the API and\nprocess its inputs and responses. To provide actionable insights, we analyze\nthe outcomes of 750 test cases, presenting a detailed taxonomy of errors,\nincluding input misinterpretation, output handling inconsistencies, and schema\nmismatches. Additionally, we classify these test cases to streamline debugging\nand refinement of tool integrations. This work offers a foundational step\ntoward enabling enterprise APIs as tools, improving their usability in\nagent-based applications.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "I.2.7"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15546v1",
    "published_date": "2025-04-22 02:52:08 UTC",
    "updated_date": "2025-04-22 02:52:08 UTC"
  },
  {
    "arxiv_id": "2504.15524v1",
    "title": "IPBench: Benchmarking the Knowledge of Large Language Models in Intellectual Property",
    "authors": [
      "Qiyao Wang",
      "Guhong Chen",
      "Hongbo Wang",
      "Huaren Liu",
      "Minghui Zhu",
      "Zhifei Qin",
      "Linwei Li",
      "Yilin Yue",
      "Shiqiang Wang",
      "Jiayan Li",
      "Yihang Wu",
      "Ziqiang Liu",
      "Longze Chen",
      "Run Luo",
      "Liyang Fan",
      "Jiaming Li",
      "Lei Zhang",
      "Kan Xu",
      "Hongfei Lin",
      "Hamid Alinejad-Rokny",
      "Shiwen Ni",
      "Yuan Lin",
      "Min Yang"
    ],
    "abstract": "Intellectual Property (IP) is a unique domain that integrates technical and\nlegal knowledge, making it inherently complex and knowledge-intensive. As large\nlanguage models (LLMs) continue to advance, they show great potential for\nprocessing IP tasks, enabling more efficient analysis, understanding, and\ngeneration of IP-related content. However, existing datasets and benchmarks\neither focus narrowly on patents or cover limited aspects of the IP field,\nlacking alignment with real-world scenarios. To bridge this gap, we introduce\nthe first comprehensive IP task taxonomy and a large, diverse bilingual\nbenchmark, IPBench, covering 8 IP mechanisms and 20 tasks. This benchmark is\ndesigned to evaluate LLMs in real-world intellectual property applications,\nencompassing both understanding and generation. We benchmark 16 LLMs, ranging\nfrom general-purpose to domain-specific models, and find that even the\nbest-performing model achieves only 75.8% accuracy, revealing substantial room\nfor improvement. Notably, open-source IP and law-oriented models lag behind\nclosed-source general-purpose models. We publicly release all data and code of\nIPBench and will continue to update it with additional IP-related tasks to\nbetter reflect real-world challenges in the intellectual property domain.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "89 pages, 75 figures, 55 tables",
    "pdf_url": "http://arxiv.org/pdf/2504.15524v1",
    "published_date": "2025-04-22 02:00:41 UTC",
    "updated_date": "2025-04-22 02:00:41 UTC"
  },
  {
    "arxiv_id": "2504.15515v2",
    "title": "Transport f divergences",
    "authors": [
      "Wuchen Li"
    ],
    "abstract": "We define a class of divergences to measure differences between probability\ndensity functions in one-dimensional sample space. The construction is based on\nthe convex function with the Jacobi operator of mapping function that\npushforwards one density to the other. We call these information measures\ntransport f-divergences. We present several properties of transport\n$f$-divergences, including invariances, convexities, variational formulations,\nand Taylor expansions in terms of mapping functions. Examples of transport\nf-divergences in generative models are provided.",
    "categories": [
      "math.ST",
      "cs.AI",
      "cs.IT",
      "math.IT",
      "stat.TH"
    ],
    "primary_category": "math.ST",
    "comment": "Comments are welcome",
    "pdf_url": "http://arxiv.org/pdf/2504.15515v2",
    "published_date": "2025-04-22 01:25:41 UTC",
    "updated_date": "2025-04-23 01:18:37 UTC"
  },
  {
    "arxiv_id": "2504.15499v1",
    "title": "Guillotine: Hypervisors for Isolating Malicious AIs",
    "authors": [
      "James Mickens",
      "Sarah Radway",
      "Ravi Netravali"
    ],
    "abstract": "As AI models become more embedded in critical sectors like finance,\nhealthcare, and the military, their inscrutable behavior poses ever-greater\nrisks to society. To mitigate this risk, we propose Guillotine, a hypervisor\narchitecture for sandboxing powerful AI models -- models that, by accident or\nmalice, can generate existential threats to humanity. Although Guillotine\nborrows some well-known virtualization techniques, Guillotine must also\nintroduce fundamentally new isolation mechanisms to handle the unique threat\nmodel posed by existential-risk AIs. For example, a rogue AI may try to\nintrospect upon hypervisor software or the underlying hardware substrate to\nenable later subversion of that control plane; thus, a Guillotine hypervisor\nrequires careful co-design of the hypervisor software and the CPUs, RAM, NIC,\nand storage devices that support the hypervisor software, to thwart side\nchannel leakage and more generally eliminate mechanisms for AI to exploit\nreflection-based vulnerabilities. Beyond such isolation at the software,\nnetwork, and microarchitectural layers, a Guillotine hypervisor must also\nprovide physical fail-safes more commonly associated with nuclear power plants,\navionic platforms, and other types of mission critical systems. Physical\nfail-safes, e.g., involving electromechanical disconnection of network cables,\nor the flooding of a datacenter which holds a rogue AI, provide defense in\ndepth if software, network, and microarchitectural isolation is compromised and\na rogue AI must be temporarily shut down or permanently destroyed.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.OS"
    ],
    "primary_category": "cs.CR",
    "comment": "To be published in the ACM SIGOPS 2025 Workshop on Hot Topics in\n  Operating Systems",
    "pdf_url": "http://arxiv.org/pdf/2504.15499v1",
    "published_date": "2025-04-22 00:29:18 UTC",
    "updated_date": "2025-04-22 00:29:18 UTC"
  },
  {
    "arxiv_id": "2504.15497v1",
    "title": "Scalable APT Malware Classification via Parallel Feature Extraction and GPU-Accelerated Learning",
    "authors": [
      "Noah Subedar",
      "Taeui Kim",
      "Saathwick Venkataramalingam"
    ],
    "abstract": "This paper presents an underlying framework for both automating and\naccelerating malware classification, more specifically, mapping malicious\nexecutables to known Advanced Persistent Threat (APT) groups. The main feature\nof this analysis is the assembly-level instructions present in executables\nwhich are also known as opcodes. The collection of such opcodes on many\nmalicious samples is a lengthy process; hence, open-source reverse engineering\ntools are used in tandem with scripts that leverage parallel computing to\nanalyze multiple files at once. Traditional and deep learning models are\napplied to create models capable of classifying malware samples. One-gram and\ntwo-gram datasets are constructed and used to train models such as SVM, KNN,\nand Decision Tree; however, they struggle to provide adequate results without\nrelying on metadata to support n-gram sequences. The computational limitations\nof such models are overcome with convolutional neural networks (CNNs) and\nheavily accelerated using graphical compute unit (GPU) resources.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "I.2.0; I.2.6; K.6.5"
    ],
    "primary_category": "cs.CR",
    "comment": "26 pages, 54 figures, 14 tables",
    "pdf_url": "http://arxiv.org/pdf/2504.15497v1",
    "published_date": "2025-04-22 00:05:05 UTC",
    "updated_date": "2025-04-22 00:05:05 UTC"
  }
]