[
  {
    "arxiv_id": "2504.16316v1",
    "title": "On the Consistency of GNN Explanations for Malware Detection",
    "authors": [
      "Hossein Shokouhinejad",
      "Griffin Higgins",
      "Roozbeh Razavi-Far",
      "Hesamodin Mohammadian",
      "Ali A. Ghorbani"
    ],
    "abstract": "Control Flow Graphs (CFGs) are critical for analyzing program execution and\ncharacterizing malware behavior. With the growing adoption of Graph Neural\nNetworks (GNNs), CFG-based representations have proven highly effective for\nmalware detection. This study proposes a novel framework that dynamically\nconstructs CFGs and embeds node features using a hybrid approach combining\nrule-based encoding and autoencoder-based embedding. A GNN-based classifier is\nthen constructed to detect malicious behavior from the resulting graph\nrepresentations. To improve model interpretability, we apply state-of-the-art\nexplainability techniques, including GNNExplainer, PGExplainer, and\nCaptumExplainer, the latter is utilized three attribution methods: Integrated\nGradients, Guided Backpropagation, and Saliency. In addition, we introduce a\nnovel aggregation method, called RankFusion, that integrates the outputs of the\ntop-performing explainers to enhance the explanation quality. We also evaluate\nexplanations using two subgraph extraction strategies, including the proposed\nGreedy Edge-wise Composition (GEC) method for improved structural coherence. A\ncomprehensive evaluation using accuracy, fidelity, and consistency metrics\ndemonstrates the effectiveness of the proposed framework in terms of accurate\nidentification of malware samples and generating reliable and interpretable\nexplanations.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16316v1",
    "published_date": "2025-04-22 23:25:12 UTC",
    "updated_date": "2025-04-22 23:25:12 UTC"
  },
  {
    "arxiv_id": "2504.16277v1",
    "title": "DataS^3: Dataset Subset Selection for Specialization",
    "authors": [
      "Neha Hulkund",
      "Alaa Maalouf",
      "Levi Cai",
      "Daniel Yang",
      "Tsun-Hsuan Wang",
      "Abigail O'Neil",
      "Timm Haucke",
      "Sandeep Mukherjee",
      "Vikram Ramaswamy",
      "Judy Hansen Shen",
      "Gabriel Tseng",
      "Mike Walmsley",
      "Daniela Rus",
      "Ken Goldberg",
      "Hannah Kerner",
      "Irene Chen",
      "Yogesh Girdhar",
      "Sara Beery"
    ],
    "abstract": "In many real-world machine learning (ML) applications (e.g. detecting broken\nbones in x-ray images, detecting species in camera traps), in practice models\nneed to perform well on specific deployments (e.g. a specific hospital, a\nspecific national park) rather than the domain broadly. However, deployments\noften have imbalanced, unique data distributions. Discrepancy between the\ntraining distribution and the deployment distribution can lead to suboptimal\nperformance, highlighting the need to select deployment-specialized subsets\nfrom the available training data. We formalize dataset subset selection for\nspecialization (DS3): given a training set drawn from a general distribution\nand a (potentially unlabeled) query set drawn from the desired\ndeployment-specific distribution, the goal is to select a subset of the\ntraining data that optimizes deployment performance.\n  We introduce DataS^3; the first dataset and benchmark designed specifically\nfor the DS3 problem. DataS^3 encompasses diverse real-world application\ndomains, each with a set of distinct deployments to specialize in. We conduct a\ncomprehensive study evaluating algorithms from various families--including\ncoresets, data filtering, and data curation--on DataS^3, and find that\ngeneral-distribution methods consistently fail on deployment-specific tasks.\nAdditionally, we demonstrate the existence of manually curated\n(deployment-specific) expert subsets that outperform training on all available\ndata with accuracy gains up to 51.3 percent. Our benchmark highlights the\ncritical role of tailored dataset curation in enhancing performance and\ntraining efficiency on deployment-specific distributions, which we posit will\nonly become more important as global, public datasets become available across\ndomains and ML models are deployed in the real world.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16277v1",
    "published_date": "2025-04-22 21:25:14 UTC",
    "updated_date": "2025-04-22 21:25:14 UTC"
  },
  {
    "arxiv_id": "2504.16276v2",
    "title": "An Automated Pipeline for Few-Shot Bird Call Classification: A Case Study with the Tooth-Billed Pigeon",
    "authors": [
      "Abhishek Jana",
      "Moeumu Uili",
      "James Atherton",
      "Mark O'Brien",
      "Joe Wood",
      "Leandra Brickson"
    ],
    "abstract": "This paper presents an automated one-shot bird call classification pipeline\ndesigned for rare species absent from large publicly available classifiers like\nBirdNET and Perch. While these models excel at detecting common birds with\nabundant training data, they lack options for species with only 1-3 known\nrecordings-a critical limitation for conservationists monitoring the last\nremaining individuals of endangered birds. To address this, we leverage the\nembedding space of large bird classification networks and develop a classifier\nusing cosine similarity, combined with filtering and denoising preprocessing\ntechniques, to optimize detection with minimal training data. We evaluate\nvarious embedding spaces using clustering metrics and validate our approach in\nboth a simulated scenario with Xeno-Canto recordings and a real-world test on\nthe critically endangered tooth-billed pigeon (Didunculus strigirostris), which\nhas no existing classifiers and only three confirmed recordings. The final\nmodel achieved 1.0 recall and 0.95 accuracy in detecting tooth-billed pigeon\ncalls, making it practical for use in the field. This open-source system\nprovides a practical tool for conservationists seeking to detect and monitor\nrare species on the brink of extinction.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.SD"
    ],
    "primary_category": "cs.LG",
    "comment": "16 pages, 5 figures, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2504.16276v2",
    "published_date": "2025-04-22 21:21:41 UTC",
    "updated_date": "2025-05-02 17:04:43 UTC"
  },
  {
    "arxiv_id": "2504.16275v1",
    "title": "Quantum Doubly Stochastic Transformers",
    "authors": [
      "Jannis Born",
      "Filip Skogh",
      "Kahn Rhrissorrakrai",
      "Filippo Utro",
      "Nico Wagner",
      "Aleksandros Sobczyk"
    ],
    "abstract": "At the core of the Transformer, the Softmax normalizes the attention matrix\nto be right stochastic. Previous research has shown that this often\ndestabilizes training and that enforcing the attention matrix to be doubly\nstochastic (through Sinkhorn's algorithm) consistently improves performance\nacross different tasks, domains and Transformer flavors. However, Sinkhorn's\nalgorithm is iterative, approximative, non-parametric and thus inflexible\nw.r.t. the obtained doubly stochastic matrix (DSM). Recently, it has been\nproven that DSMs can be obtained with a parametric quantum circuit, yielding a\nnovel quantum inductive bias for DSMs with no known classical analogue.\nMotivated by this, we demonstrate the feasibility of a hybrid classical-quantum\ndoubly stochastic Transformer (QDSFormer) that replaces the Softmax in the\nself-attention layer with a variational quantum circuit. We study the\nexpressive power of the circuit and find that it yields more diverse DSMs that\nbetter preserve information than classical operators. Across multiple\nsmall-scale object recognition tasks, we find that our QDSFormer consistently\nsurpasses both a standard Vision Transformer and other doubly stochastic\nTransformers. Beyond the established Sinkformer, this comparison includes a\nnovel quantum-inspired doubly stochastic Transformer (based on QR\ndecomposition) that can be of independent interest. The QDSFormer also shows\nimproved training stability and lower performance variation suggesting that it\nmay mitigate the notoriously unstable training of ViTs on small-scale data.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CE",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "Under Review",
    "pdf_url": "http://arxiv.org/pdf/2504.16275v1",
    "published_date": "2025-04-22 21:15:45 UTC",
    "updated_date": "2025-04-22 21:15:45 UTC"
  },
  {
    "arxiv_id": "2504.16273v1",
    "title": "Investigating LLMs in Clinical Triage: Promising Capabilities, Persistent Intersectional Biases",
    "authors": [
      "Joseph Lee",
      "Tianqi Shang",
      "Jae Young Baik",
      "Duy Duong-Tran",
      "Shu Yang",
      "Lingyao Li",
      "Li Shen"
    ],
    "abstract": "Large Language Models (LLMs) have shown promise in clinical decision support,\nyet their application to triage remains underexplored. We systematically\ninvestigate the capabilities of LLMs in emergency department triage through two\nkey dimensions: (1) robustness to distribution shifts and missing data, and (2)\ncounterfactual analysis of intersectional biases across sex and race. We assess\nmultiple LLM-based approaches, ranging from continued pre-training to\nin-context learning, as well as machine learning approaches. Our results\nindicate that LLMs exhibit superior robustness, and we investigate the key\nfactors contributing to the promising LLM-based approaches. Furthermore, in\nthis setting, we identify gaps in LLM preferences that emerge in particular\nintersections of sex and race. LLMs generally exhibit sex-based differences,\nbut they are most pronounced in certain racial groups. These findings suggest\nthat LLMs encode demographic preferences that may emerge in specific clinical\ncontexts or particular combinations of characteristics.",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted to GenAI4Health Workshop @ AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.16273v1",
    "published_date": "2025-04-22 21:11:47 UTC",
    "updated_date": "2025-04-22 21:11:47 UTC"
  },
  {
    "arxiv_id": "2504.16268v2",
    "title": "Boosting KNNClassifier Performance with Opposition-Based Data Transformation",
    "authors": [
      "Abdesslem Layeb"
    ],
    "abstract": "In this paper, we introduce a novel data transformation framework based on\nOpposition-Based Learning (OBL) to boost the performance of traditional\nclassification algorithms. Originally developed to accelerate convergence in\noptimization tasks, OBL is leveraged here to generate synthetic opposite\nsamples that enrich the training data and improve decision boundary formation.\nWe explore three OBL variants Global OBL, Class-Wise OBL, and Localized\nClass-Wise OBL and integrate them with K-Nearest Neighbors (KNN). Extensive\nexperiments conducted on 26 heterogeneous and high-dimensional datasets\ndemonstrate that OBL-enhanced classifiers consistently outperform the basic\nKNN. These findings underscore the potential of OBL as a lightweight yet\npowerful data transformation strategy for enhancing classification performance,\nespecially in complex or sparse learning environments.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16268v2",
    "published_date": "2025-04-22 21:03:31 UTC",
    "updated_date": "2025-04-25 08:27:58 UTC"
  },
  {
    "arxiv_id": "2504.16263v1",
    "title": "Gradient-Optimized Fuzzy Classifier: A Benchmark Study Against State-of-the-Art Models",
    "authors": [
      "Magnus Sieverding",
      "Nathan Steffen",
      "Kelly Cohen"
    ],
    "abstract": "This paper presents a performance benchmarking study of a Gradient-Optimized\nFuzzy Inference System (GF) classifier against several state-of-the-art machine\nlearning models, including Random Forest, XGBoost, Logistic Regression, Support\nVector Machines, and Neural Networks. The evaluation was conducted across five\ndatasets from the UCI Machine Learning Repository, each chosen for their\ndiversity in input types, class distributions, and classification complexity.\nUnlike traditional Fuzzy Inference Systems that rely on derivative-free\noptimization methods, the GF leverages gradient descent to significantly\nimproving training efficiency and predictive performance. Results demonstrate\nthat the GF model achieved competitive, and in several cases superior,\nclassification accuracy while maintaining high precision and exceptionally low\ntraining times. In particular, the GF exhibited strong consistency across folds\nand datasets, underscoring its robustness in handling noisy data and variable\nfeature sets. These findings support the potential of gradient optimized fuzzy\nsystems as interpretable, efficient, and adaptable alternatives to more complex\ndeep learning models in supervised learning tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16263v1",
    "published_date": "2025-04-22 20:47:06 UTC",
    "updated_date": "2025-04-22 20:47:06 UTC"
  },
  {
    "arxiv_id": "2504.21022v1",
    "title": "ConformalNL2LTL: Translating Natural Language Instructions into Temporal Logic Formulas with Conformal Correctness Guarantees",
    "authors": [
      "Jun Wang",
      "David Smith Sundarsingh",
      "Jyotirmoy V. Deshmukh",
      "Yiannis Kantaros"
    ],
    "abstract": "Linear Temporal Logic (LTL) has become a prevalent specification language for\nrobotic tasks. To mitigate the significant manual effort and expertise required\nto define LTL-encoded tasks, several methods have been proposed for translating\nNatural Language (NL) instructions into LTL formulas, which, however, lack\ncorrectness guarantees. To address this, we introduce a new NL-to-LTL\ntranslation method, called ConformalNL2LTL, that can achieve user-defined\ntranslation success rates over unseen NL commands. Our method constructs LTL\nformulas iteratively by addressing a sequence of open-vocabulary\nQuestion-Answering (QA) problems with LLMs. To enable uncertainty-aware\ntranslation, we leverage conformal prediction (CP), a distribution-free\nuncertainty quantification tool for black-box models. CP enables our method to\nassess the uncertainty in LLM-generated answers, allowing it to proceed with\ntranslation when sufficiently confident and request help otherwise. We provide\nboth theoretical and empirical results demonstrating that ConformalNL2LTL\nachieves user-specified translation accuracy while minimizing help rates.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.21022v1",
    "published_date": "2025-04-22 20:32:34 UTC",
    "updated_date": "2025-04-22 20:32:34 UTC"
  },
  {
    "arxiv_id": "2504.16226v1",
    "title": "Blockchain Meets Adaptive Honeypots: A Trust-Aware Approach to Next-Gen IoT Security",
    "authors": [
      "Yazan Otoum",
      "Arghavan Asad",
      "Amiya Nayak"
    ],
    "abstract": "Edge computing-based Next-Generation Wireless Networks (NGWN)-IoT offer\nenhanced bandwidth capacity for large-scale service provisioning but remain\nvulnerable to evolving cyber threats. Existing intrusion detection and\nprevention methods provide limited security as adversaries continually adapt\ntheir attack strategies. We propose a dynamic attack detection and prevention\napproach to address this challenge. First, blockchain-based authentication uses\nthe Deoxys Authentication Algorithm (DAA) to verify IoT device legitimacy\nbefore data transmission. Next, a bi-stage intrusion detection system is\nintroduced: the first stage uses signature-based detection via an Improved\nRandom Forest (IRF) algorithm. In contrast, the second stage applies\nfeature-based anomaly detection using a Diffusion Convolution Recurrent Neural\nNetwork (DCRNN). To ensure Quality of Service (QoS) and maintain Service Level\nAgreements (SLA), trust-aware service migration is performed using Heap-Based\nOptimization (HBO). Additionally, on-demand virtual High-Interaction honeypots\ndeceive attackers and extract attack patterns, which are securely stored using\nthe Bimodal Lattice Signature Scheme (BLISS) to enhance signature-based\nIntrusion Detection Systems (IDS). The proposed framework is implemented in the\nNS3 simulation environment and evaluated against existing methods across\nmultiple performance metrics, including accuracy, attack detection rate, false\nnegative rate, precision, recall, ROC curve, memory usage, CPU usage, and\nexecution time. Experimental results demonstrate that the framework\nsignificantly outperforms existing approaches, reinforcing the security of\nNGWN-enabled IoT ecosystems",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.ET",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "This paper has been submitted to the IEEE Transactions on Network\n  Science and Engineering (TNSE) for possible publication",
    "pdf_url": "http://arxiv.org/pdf/2504.16226v1",
    "published_date": "2025-04-22 19:36:19 UTC",
    "updated_date": "2025-04-22 19:36:19 UTC"
  },
  {
    "arxiv_id": "2504.16214v2",
    "title": "Hexcute: A Tile-based Programming Language with Automatic Layout and Task-Mapping Synthesis",
    "authors": [
      "Xiao Zhang",
      "Yaoyao Ding",
      "Yang Hu",
      "Gennady Pekhimenko"
    ],
    "abstract": "Deep learning (DL) workloads mainly run on accelerators like GPUs. Recent DL\nquantization techniques demand a new matrix multiplication operator with mixed\ninput data types, further complicating GPU optimization. Prior high-level\ncompilers like Triton lack the expressiveness to implement key optimizations\nlike fine-grained data pipelines and hardware-friendly memory layouts for these\noperators, while low-level programming models, such as Hidet, Graphene, and\nCUTLASS, require significant programming efforts. To balance expressiveness\nwith engineering effort, we propose Hexcute, a tile-based programming language\nthat exposes shared memory and register abstractions to enable fine-grained\noptimization for these operators. Additionally, Hexcute leverages task mapping\nto schedule the GPU program, and to reduce programming efforts, it automates\nlayout and task mapping synthesis with a novel type-inference-based algorithm.\nOur evaluation shows that Hexcute generalizes to a wide range of DL operators,\nachieves 1.7-11.28$\\times$ speedup over existing DL compilers for mixed-type\noperators, and brings up to 2.91$\\times$ speedup in the end-to-end evaluation.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.PL"
    ],
    "primary_category": "cs.LG",
    "comment": "17 pages, 24 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.16214v2",
    "published_date": "2025-04-22 19:01:28 UTC",
    "updated_date": "2025-04-30 17:29:28 UTC"
  },
  {
    "arxiv_id": "2504.16213v1",
    "title": "TinyML for Speech Recognition",
    "authors": [
      "Andrew Barovic",
      "Armin Moin"
    ],
    "abstract": "We train and deploy a quantized 1D convolutional neural network model to\nconduct speech recognition on a highly resource-constrained IoT edge device.\nThis can be useful in various Internet of Things (IoT) applications, such as\nsmart homes and ambient assisted living for the elderly and people with\ndisabilities, just to name a few examples. In this paper, we first create a new\ndataset with over one hour of audio data that enables our research and will be\nuseful to future studies in this field. Second, we utilize the technologies\nprovided by Edge Impulse to enhance our model's performance and achieve a high\nAccuracy of up to 97% on our dataset. For the validation, we implement our\nprototype using the Arduino Nano 33 BLE Sense microcontroller board. This\nmicrocontroller board is specifically designed for IoT and AI applications,\nmaking it an ideal choice for our target use case scenarios. While most\nexisting research focuses on a limited set of keywords, our model can process\n23 different keywords, enabling complex commands.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16213v1",
    "published_date": "2025-04-22 19:00:40 UTC",
    "updated_date": "2025-04-22 19:00:40 UTC"
  },
  {
    "arxiv_id": "2504.16209v1",
    "title": "HTN Plan Repair Algorithms Compared: Strengths and Weaknesses of Different Methods",
    "authors": [
      "Paul Zaidins",
      "Robert P. Goldman",
      "Ugur Kuter",
      "Dana Nau",
      "Mark Roberts"
    ],
    "abstract": "This paper provides theoretical and empirical comparisons of three recent\nhierarchical plan repair algorithms: SHOPFixer, IPyHOPPER, and Rewrite. Our\ntheoretical results show that the three algorithms correspond to three\ndifferent definitions of the plan repair problem, leading to differences in the\nalgorithms' search spaces, the repair problems they can solve, and the kinds of\nrepairs they can make. Understanding these distinctions is important when\nchoosing a repair method for any given application.\n  Building on the theoretical results, we evaluate the algorithms empirically\nin a series of benchmark planning problems. Our empirical results provide more\ndetailed insight into the runtime repair performance of these systems and the\ncoverage of the repair problems solved, based on algorithmic properties such as\nreplanning, chronological backtracking, and backjumping over plan trees.",
    "categories": [
      "cs.AI",
      "I.2.8"
    ],
    "primary_category": "cs.AI",
    "comment": "20 pages; 19 figures; To appear in the Proceedings for ICAPS 2025,\n  the 35th International Conference on Automated Planning and Schedulings",
    "pdf_url": "http://arxiv.org/pdf/2504.16209v1",
    "published_date": "2025-04-22 18:55:26 UTC",
    "updated_date": "2025-04-22 18:55:26 UTC"
  },
  {
    "arxiv_id": "2504.16204v1",
    "title": "Reflexive Prompt Engineering: A Framework for Responsible Prompt Engineering and Interaction Design",
    "authors": [
      "Christian Djeffal"
    ],
    "abstract": "Responsible prompt engineering has emerged as a critical framework for\nensuring that generative artificial intelligence (AI) systems serve society's\nneeds while minimizing potential harms. As generative AI applications become\nincreasingly powerful and ubiquitous, the way we instruct and interact with\nthem through prompts has profound implications for fairness, accountability,\nand transparency. This article examines how strategic prompt engineering can\nembed ethical and legal considerations and societal values directly into AI\ninteractions, moving beyond mere technical optimization for functionality. This\narticle proposes a comprehensive framework for responsible prompt engineering\nthat encompasses five interconnected components: prompt design, system\nselection, system configuration, performance evaluation, and prompt management.\nDrawing from empirical evidence, the paper demonstrates how each component can\nbe leveraged to promote improved societal outcomes while mitigating potential\nrisks. The analysis reveals that effective prompt engineering requires a\ndelicate balance between technical precision and ethical consciousness,\ncombining the systematic rigor and focus on functionality with the nuanced\nunderstanding of social impact. Through examination of real-world and emerging\npractices, the article illustrates how responsible prompt engineering serves as\na crucial bridge between AI development and deployment, enabling organizations\nto fine-tune AI outputs without modifying underlying model architectures. This\napproach aligns with broader \"Responsibility by Design\" principles, embedding\nethical considerations directly into the implementation process rather than\ntreating them as post-hoc additions. The article concludes by identifying key\nresearch directions and practical guidelines for advancing the field of\nresponsible prompt engineering.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL",
      "cs.ET"
    ],
    "primary_category": "cs.CY",
    "comment": "20 pages one figure",
    "pdf_url": "http://arxiv.org/pdf/2504.16204v1",
    "published_date": "2025-04-22 18:51:32 UTC",
    "updated_date": "2025-04-22 18:51:32 UTC"
  },
  {
    "arxiv_id": "2504.16193v1",
    "title": "Quality of explanation of xAI from the prespective of Italian end-users: Italian version of System Causability Scale (SCS)",
    "authors": [
      "Carmine Attanasio",
      "Alireza Mortezapour"
    ],
    "abstract": "Background and aim: Considering the scope of the application of artificial\nintelligence beyond the field of computer science, one of the concerns of\nresearchers is to provide quality explanations about the functioning of\nalgorithms based on artificial intelligence and the data extracted from it. The\npurpose of the present study is to validate the Italian version of system\ncausability scale (I-SCS) to measure the quality of explanations provided in a\nxAI.\n  Method: For this purpose, the English version, initially provided in 2020 in\ncoordination with the main developer, was utilized. The forward-backward\ntranslation method was applied to ensure accuracy. Finally, these nine steps\nwere completed by calculating the content validity index/ratio and conducting\ncognitive interviews with representative end users.\n  Results: The original version of the questionnaire consisted of 10 questions.\nHowever, based on the obtained indexes (CVR below 0.49), one question (Question\n8) was entirely removed. After completing the aforementioned steps, the Italian\nversion contained 9 questions. The representative sample of Italian end users\nfully comprehended the meaning and content of the questions in the Italian\nversion.\n  Conclusion: The Italian version obtained in this study can be used in future\nresearch studies as well as in the field by xAI developers. This tool can be\nused to measure the quality of explanations provided for an xAI system in\nItalian culture.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "This work will be presented in Coperman 2025 Conference",
    "pdf_url": "http://arxiv.org/pdf/2504.16193v1",
    "published_date": "2025-04-22 18:32:40 UTC",
    "updated_date": "2025-04-22 18:32:40 UTC"
  },
  {
    "arxiv_id": "2504.16188v1",
    "title": "FinNLI: Novel Dataset for Multi-Genre Financial Natural Language Inference Benchmarking",
    "authors": [
      "Jabez Magomere",
      "Elena Kochkina",
      "Samuel Mensah",
      "Simerjot Kaur",
      "Charese H. Smiley"
    ],
    "abstract": "We introduce FinNLI, a benchmark dataset for Financial Natural Language\nInference (FinNLI) across diverse financial texts like SEC Filings, Annual\nReports, and Earnings Call transcripts. Our dataset framework ensures diverse\npremise-hypothesis pairs while minimizing spurious correlations. FinNLI\ncomprises 21,304 pairs, including a high-quality test set of 3,304 instances\nannotated by finance experts. Evaluations show that domain shift significantly\ndegrades general-domain NLI performance. The highest Macro F1 scores for\npre-trained (PLMs) and large language models (LLMs) baselines are 74.57% and\n78.62%, respectively, highlighting the dataset's difficulty. Surprisingly,\ninstruction-tuned financial LLMs perform poorly, suggesting limited\ngeneralizability. FinNLI exposes weaknesses in current LLMs for financial\nreasoning, indicating room for improvement.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16188v1",
    "published_date": "2025-04-22 18:25:17 UTC",
    "updated_date": "2025-04-22 18:25:17 UTC"
  },
  {
    "arxiv_id": "2504.16173v2",
    "title": "FPGA-Based Neural Network Accelerators for Space Applications: A Survey",
    "authors": [
      "Pedro Antunes",
      "Artur Podobas"
    ],
    "abstract": "Space missions are becoming increasingly ambitious, necessitating\nhigh-performance onboard spacecraft computing systems. In response,\nfield-programmable gate arrays (FPGAs) have garnered significant interest due\nto their flexibility, cost-effectiveness, and radiation tolerance potential.\nConcurrently, neural networks (NNs) are being recognized for their capability\nto execute space mission tasks such as autonomous operations, sensor data\nanalysis, and data compression. This survey serves as a valuable resource for\nresearchers aiming to implement FPGA-based NN accelerators in space\napplications. By analyzing existing literature, identifying trends and gaps,\nand proposing future research directions, this work highlights the potential of\nthese accelerators to enhance onboard computing systems.",
    "categories": [
      "cs.AR",
      "cs.AI"
    ],
    "primary_category": "cs.AR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16173v2",
    "published_date": "2025-04-22 18:02:35 UTC",
    "updated_date": "2025-04-24 12:04:11 UTC"
  },
  {
    "arxiv_id": "2504.16172v2",
    "title": "Physics-Informed Inference Time Scaling via Simulation-Calibrated Scientific Machine Learning",
    "authors": [
      "Zexi Fan",
      "Yan Sun",
      "Shihao Yang",
      "Yiping Lu"
    ],
    "abstract": "High-dimensional partial differential equations (PDEs) pose significant\ncomputational challenges across fields ranging from quantum chemistry to\neconomics and finance. Although scientific machine learning (SciML) techniques\noffer approximate solutions, they often suffer from bias and neglect crucial\nphysical insights. Inspired by inference-time scaling strategies in language\nmodels, we propose Simulation-Calibrated Scientific Machine Learning (SCaSML),\na physics-informed framework that dynamically refines and debiases the SCiML\npredictions during inference by enforcing the physical laws. SCaSML leverages\nderived new physical laws that quantifies systematic errors and employs Monte\nCarlo solvers based on the Feynman-Kac and Elworthy-Bismut-Li formulas to\ndynamically correct the prediction. Both numerical and theoretical analysis\nconfirms enhanced convergence rates via compute-optimal inference methods. Our\nnumerical experiments demonstrate that SCaSML reduces errors by 20-50% compared\nto the base surrogate model, establishing it as the first algorithm to refine\napproximated solutions to high-dimensional PDE during inference. Code of SCaSML\nis available at https://github.com/Francis-Fan-create/SCaSML.",
    "categories": [
      "math.NA",
      "cs.AI",
      "cs.LG",
      "cs.NA",
      "math.PR",
      "stat.ML"
    ],
    "primary_category": "math.NA",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16172v2",
    "published_date": "2025-04-22 18:01:45 UTC",
    "updated_date": "2025-04-25 15:12:10 UTC"
  },
  {
    "arxiv_id": "2504.16171v1",
    "title": "A detection-task-specific deep-learning method to improve the quality of sparse-view myocardial perfusion SPECT images",
    "authors": [
      "Zezhang Yang",
      "Zitong Yu",
      "Nuri Choi",
      "Abhinav K. Jha"
    ],
    "abstract": "Myocardial perfusion imaging (MPI) with single-photon emission computed\ntomography (SPECT) is a widely used and cost-effective diagnostic tool for\ncoronary artery disease. However, the lengthy scanning time in this imaging\nprocedure can cause patient discomfort, motion artifacts, and potentially\ninaccurate diagnoses due to misalignment between the SPECT scans and the\nCT-scans which are acquired for attenuation compensation. Reducing projection\nangles is a potential way to shorten scanning time, but this can adversely\nimpact the quality of the reconstructed images. To address this issue, we\npropose a detection-task-specific deep-learning method for sparse-view MPI\nSPECT images. This method integrates an observer loss term that penalizes the\nloss of anthropomorphic channel features with the goal of improving performance\nin perfusion defect-detection task. We observed that, on the task of detecting\nmyocardial perfusion defects, the proposed method yielded an area under the\nreceiver operating characteristic (ROC) curve (AUC) significantly larger than\nthe sparse-view protocol. Further, the proposed method was observed to be able\nto restore the structure of the left ventricle wall, demonstrating ability to\novercome sparse-sampling artifacts. Our preliminary results motivate further\nevaluations of the method.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16171v1",
    "published_date": "2025-04-22 18:01:03 UTC",
    "updated_date": "2025-04-22 18:01:03 UTC"
  },
  {
    "arxiv_id": "2504.16078v1",
    "title": "LLMs are Greedy Agents: Effects of RL Fine-tuning on Decision-Making Abilities",
    "authors": [
      "Thomas Schmied",
      "Jörg Bornschein",
      "Jordi Grau-Moya",
      "Markus Wulfmeier",
      "Razvan Pascanu"
    ],
    "abstract": "The success of Large Language Models (LLMs) has sparked interest in various\nagentic applications. A key hypothesis is that LLMs, leveraging common sense\nand Chain-of-Thought (CoT) reasoning, can effectively explore and efficiently\nsolve complex domains. However, LLM agents have been found to suffer from\nsub-optimal exploration and the knowing-doing gap, the inability to effectively\nact on knowledge present in the model. In this work, we systematically study\nwhy LLMs perform sub-optimally in decision-making scenarios. In particular, we\nclosely examine three prevalent failure modes: greediness, frequency bias, and\nthe knowing-doing gap. We propose mitigation of these shortcomings by\nfine-tuning via Reinforcement Learning (RL) on self-generated CoT rationales.\nOur experiments across multi-armed bandits, contextual bandits, and\nTic-tac-toe, demonstrate that RL fine-tuning enhances the decision-making\nabilities of LLMs by increasing exploration and narrowing the knowing-doing\ngap. Finally, we study both classic exploration mechanisms, such as\n$\\epsilon$-greedy, and LLM-specific approaches, such as self-correction and\nself-consistency, to enable more effective fine-tuning of LLMs for\ndecision-making.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16078v1",
    "published_date": "2025-04-22 17:57:14 UTC",
    "updated_date": "2025-04-22 17:57:14 UTC"
  },
  {
    "arxiv_id": "2504.16072v1",
    "title": "Describe Anything: Detailed Localized Image and Video Captioning",
    "authors": [
      "Long Lian",
      "Yifan Ding",
      "Yunhao Ge",
      "Sifei Liu",
      "Hanzi Mao",
      "Boyi Li",
      "Marco Pavone",
      "Ming-Yu Liu",
      "Trevor Darrell",
      "Adam Yala",
      "Yin Cui"
    ],
    "abstract": "Generating detailed and accurate descriptions for specific regions in images\nand videos remains a fundamental challenge for vision-language models. We\nintroduce the Describe Anything Model (DAM), a model designed for detailed\nlocalized captioning (DLC). DAM preserves both local details and global context\nthrough two key innovations: a focal prompt, which ensures high-resolution\nencoding of targeted regions, and a localized vision backbone, which integrates\nprecise localization with its broader context. To tackle the scarcity of\nhigh-quality DLC data, we propose a Semi-supervised learning (SSL)-based Data\nPipeline (DLC-SDP). DLC-SDP starts with existing segmentation datasets and\nexpands to unlabeled web images using SSL. We introduce DLC-Bench, a benchmark\ndesigned to evaluate DLC without relying on reference captions. DAM sets new\nstate-of-the-art on 7 benchmarks spanning keyword-level, phrase-level, and\ndetailed multi-sentence localized image and video captioning.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Project page: https://describe-anything.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2504.16072v1",
    "published_date": "2025-04-22 17:51:41 UTC",
    "updated_date": "2025-04-22 17:51:41 UTC"
  },
  {
    "arxiv_id": "2504.18575v3",
    "title": "WASP: Benchmarking Web Agent Security Against Prompt Injection Attacks",
    "authors": [
      "Ivan Evtimov",
      "Arman Zharmagambetov",
      "Aaron Grattafiori",
      "Chuan Guo",
      "Kamalika Chaudhuri"
    ],
    "abstract": "Autonomous UI agents powered by AI have tremendous potential to boost human\nproductivity by automating routine tasks such as filing taxes and paying bills.\nHowever, a major challenge in unlocking their full potential is security, which\nis exacerbated by the agent's ability to take action on their user's behalf.\nExisting tests for prompt injections in web agents either over-simplify the\nthreat by testing unrealistic scenarios or giving the attacker too much power,\nor look at single-step isolated tasks. To more accurately measure progress for\nsecure web agents, we introduce WASP -- a new publicly available benchmark for\nend-to-end evaluation of Web Agent Security against Prompt injection attacks.\nEvaluating with WASP shows that even top-tier AI models, including those with\nadvanced reasoning capabilities, can be deceived by simple, low-effort\nhuman-written injections in very realistic scenarios. Our end-to-end evaluation\nreveals a previously unobserved insight: while attacks partially succeed in up\nto 86% of the case, even state-of-the-art agents often struggle to fully\ncomplete the attacker goals -- highlighting the current state of security by\nincompetence.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "Code and data: https://github.com/facebookresearch/wasp",
    "pdf_url": "http://arxiv.org/pdf/2504.18575v3",
    "published_date": "2025-04-22 17:51:03 UTC",
    "updated_date": "2025-05-16 22:42:29 UTC"
  },
  {
    "arxiv_id": "2504.16061v1",
    "title": "Vision language models are unreliable at trivial spatial cognition",
    "authors": [
      "Sangeet Khemlani",
      "Tyler Tran",
      "Nathaniel Gyory",
      "Anthony M. Harrison",
      "Wallace E. Lawson",
      "Ravenna Thielstrom",
      "Hunter Thompson",
      "Taaren Singh",
      "J. Gregory Trafton"
    ],
    "abstract": "Vision language models (VLMs) are designed to extract relevant visuospatial\ninformation from images. Some research suggests that VLMs can exhibit humanlike\nscene understanding, while other investigations reveal difficulties in their\nability to process relational information. To achieve widespread applicability,\nVLMs must perform reliably, yielding comparable competence across a wide\nvariety of related tasks. We sought to test how reliable these architectures\nare at engaging in trivial spatial cognition, e.g., recognizing whether one\nobject is left of another in an uncluttered scene. We developed a benchmark\ndataset -- TableTest -- whose images depict 3D scenes of objects arranged on a\ntable, and used it to evaluate state-of-the-art VLMs. Results show that\nperformance could be degraded by minor variations of prompts that use logically\nequivalent descriptions. These analyses suggest limitations in how VLMs may\nreason about spatial relations in real-world applications. They also reveal\nnovel opportunities for bolstering image caption corpora for more efficient\ntraining and testing.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16061v1",
    "published_date": "2025-04-22 17:38:01 UTC",
    "updated_date": "2025-04-22 17:38:01 UTC"
  },
  {
    "arxiv_id": "2504.16053v1",
    "title": "LongMamba: Enhancing Mamba's Long Context Capabilities via Training-Free Receptive Field Enlargement",
    "authors": [
      "Zhifan Ye",
      "Kejing Xia",
      "Yonggan Fu",
      "Xin Dong",
      "Jihoon Hong",
      "Xiangchi Yuan",
      "Shizhe Diao",
      "Jan Kautz",
      "Pavlo Molchanov",
      "Yingyan Celine Lin"
    ],
    "abstract": "State space models (SSMs) have emerged as an efficient alternative to\nTransformer models for language modeling, offering linear computational\ncomplexity and constant memory usage as context length increases. However,\ndespite their efficiency in handling long contexts, recent studies have shown\nthat SSMs, such as Mamba models, generally underperform compared to\nTransformers in long-context understanding tasks. To address this significant\nshortfall and achieve both efficient and accurate long-context understanding,\nwe propose LongMamba, a training-free technique that significantly enhances the\nlong-context capabilities of Mamba models. LongMamba builds on our discovery\nthat the hidden channels in Mamba can be categorized into local and global\nchannels based on their receptive field lengths, with global channels primarily\nresponsible for long-context capability. These global channels can become the\nkey bottleneck as the input context lengthens. Specifically, when input lengths\nlargely exceed the training sequence length, global channels exhibit\nlimitations in adaptively extend their receptive fields, leading to Mamba's\npoor long-context performance. The key idea of LongMamba is to mitigate the\nhidden state memory decay in these global channels by preventing the\naccumulation of unimportant tokens in their memory. This is achieved by first\nidentifying critical tokens in the global channels and then applying token\nfiltering to accumulate only those critical tokens. Through extensive\nbenchmarking across synthetic and real-world long-context scenarios, LongMamba\nsets a new standard for Mamba's long-context performance, significantly\nextending its operational range without requiring additional training. Our code\nis available at https://github.com/GATECH-EIC/LongMamba.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.16053v1",
    "published_date": "2025-04-22 17:30:36 UTC",
    "updated_date": "2025-04-22 17:30:36 UTC"
  },
  {
    "arxiv_id": "2504.16047v1",
    "title": "Evaluating Vision Language Models (VLMs) for Radiology: A Comprehensive Analysis",
    "authors": [
      "Frank Li",
      "Hari Trivedi",
      "Bardia Khosravi",
      "Theo Dapamede",
      "Mohammadreza Chavoshi",
      "Abdulhameed Dere",
      "Rohan Satya Isaac",
      "Aawez Mansuri",
      "Janice Newsome",
      "Saptarshi Purkayastha",
      "Judy Gichoya"
    ],
    "abstract": "Foundation models, trained on vast amounts of data using self-supervised\ntechniques, have emerged as a promising frontier for advancing artificial\nintelligence (AI) applications in medicine. This study evaluates three\ndifferent vision-language foundation models (RAD-DINO, CheXagent, and\nBiomedCLIP) on their ability to capture fine-grained imaging features for\nradiology tasks. The models were assessed across classification, segmentation,\nand regression tasks for pneumothorax and cardiomegaly on chest radiographs.\nSelf-supervised RAD-DINO consistently excelled in segmentation tasks, while\ntext-supervised CheXagent demonstrated superior classification performance.\nBiomedCLIP showed inconsistent performance across tasks. A custom segmentation\nmodel that integrates global and local features substantially improved\nperformance for all foundation models, particularly for challenging\npneumothorax segmentation. The findings highlight that pre-training methodology\nsignificantly influences model performance on specific downstream tasks. For\nfine-grained segmentation tasks, models trained without text supervision\nperformed better, while text-supervised models offered advantages in\nclassification and interpretability. These insights provide guidance for\nselecting foundation models based on specific clinical applications in\nradiology.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16047v1",
    "published_date": "2025-04-22 17:20:34 UTC",
    "updated_date": "2025-04-22 17:20:34 UTC"
  },
  {
    "arxiv_id": "2504.16042v1",
    "title": "Approximate matrices of systems of max-min fuzzy relational equations",
    "authors": [
      "Ismaïl Baaj"
    ],
    "abstract": "In this article, we address the inconsistency of a system of max-min fuzzy\nrelational equations by minimally modifying the matrix governing the system in\norder to achieve consistency. Our method yields consistent systems that\napproximate the original inconsistent system in the following sense: the\nright-hand side vector of each consistent system is that of the inconsistent\nsystem, and the coefficients of the matrix governing each consistent system are\nobtained by modifying, exactly and minimally, the entries of the original\nmatrix that must be corrected to achieve consistency, while leaving all other\nentries unchanged.\n  To obtain a consistent system that closely approximates the considered\ninconsistent system, we study the distance (in terms of a norm among $L_1$,\n$L_2$ or $L_\\infty$) between the matrix of the inconsistent system and the set\nformed by the matrices of consistent systems that use the same right-hand side\nvector as the inconsistent system. We show that our method allows us to\ndirectly compute matrices of consistent systems that use the same right-hand\nside vector as the inconsistent system whose distance in terms of $L_\\infty$\nnorm to the matrix of the inconsistent system is minimal (the computational\ncosts are higher when using $L_1$ norm or $L_2$ norm). We also give an explicit\nanalytical formula for computing this minimal $L_\\infty$ distance. Finally, we\ntranslate our results for systems of min-max fuzzy relational equations and\npresent some potential applications.",
    "categories": [
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16042v1",
    "published_date": "2025-04-22 17:09:02 UTC",
    "updated_date": "2025-04-22 17:09:02 UTC"
  },
  {
    "arxiv_id": "2504.16041v1",
    "title": "Muon Optimizer Accelerates Grokking",
    "authors": [
      "Amund Tveit",
      "Bjørn Remseth",
      "Arve Skogvold"
    ],
    "abstract": "This paper investigates the impact of different optimizers on the grokking\nphenomenon, where models exhibit delayed generalization. We conducted\nexperiments across seven numerical tasks (primarily modular arithmetic) using a\nmodern Transformer architecture. The experimental configuration systematically\nvaried the optimizer (Muon vs. AdamW) and the softmax activation function\n(standard softmax, stablemax, and sparsemax) to assess their combined effect on\nlearning dynamics. Our empirical evaluation reveals that the Muon optimizer,\ncharacterized by its use of spectral norm constraints and second-order\ninformation, significantly accelerates the onset of grokking compared to the\nwidely used AdamW optimizer. Specifically, Muon reduced the mean grokking epoch\nfrom 153.09 to 102.89 across all configurations, a statistically significant\ndifference (t = 5.0175, p = 6.33e-08). This suggests that the optimizer choice\nplays a crucial role in facilitating the transition from memorization to\ngeneralization.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "I.2"
    ],
    "primary_category": "cs.LG",
    "comment": "8 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.16041v1",
    "published_date": "2025-04-22 17:08:09 UTC",
    "updated_date": "2025-04-22 17:08:09 UTC"
  },
  {
    "arxiv_id": "2504.16032v2",
    "title": "LLMs meet Federated Learning for Scalable and Secure IoT Management",
    "authors": [
      "Yazan Otoum",
      "Arghavan Asad",
      "Amiya Nayak"
    ],
    "abstract": "The rapid expansion of IoT ecosystems introduces severe challenges in\nscalability, security, and real-time decision-making. Traditional centralized\narchitectures struggle with latency, privacy concerns, and excessive resource\nconsumption, making them unsuitable for modern large-scale IoT deployments.\nThis paper presents a novel Federated Learning-driven Large Language Model\n(FL-LLM) framework, designed to enhance IoT system intelligence while ensuring\ndata privacy and computational efficiency. The framework integrates Generative\nIoT (GIoT) models with a Gradient Sensing Federated Strategy (GSFS),\ndynamically optimizing model updates based on real-time network conditions. By\nleveraging a hybrid edge-cloud processing architecture, our approach balances\nintelligence, scalability, and security in distributed IoT environments.\nEvaluations on the IoT-23 dataset demonstrate that our framework improves model\naccuracy, reduces response latency, and enhances energy efficiency,\noutperforming traditional FL techniques (i.e., FedAvg, FedOpt). These findings\nhighlight the potential of integrating LLM-powered federated learning into\nlarge-scale IoT ecosystems, paving the way for more secure, scalable, and\nadaptive IoT management solutions.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.ET"
    ],
    "primary_category": "cs.LG",
    "comment": "This work has been submitted to the IEEE Global Communications\n  Conference (GLOBECOM) 2025 for possible publication",
    "pdf_url": "http://arxiv.org/pdf/2504.16032v2",
    "published_date": "2025-04-22 16:56:59 UTC",
    "updated_date": "2025-05-13 02:49:49 UTC"
  },
  {
    "arxiv_id": "2504.16027v1",
    "title": "Benchmarking LLM for Code Smells Detection: OpenAI GPT-4.0 vs DeepSeek-V3",
    "authors": [
      "Ahmed R. Sadik",
      "Siddhata Govind"
    ],
    "abstract": "Determining the most effective Large Language Model for code smell detection\npresents a complex challenge. This study introduces a structured methodology\nand evaluation matrix to tackle this issue, leveraging a curated dataset of\ncode samples consistently annotated with known smells. The dataset spans four\nprominent programming languages Java, Python, JavaScript, and C++; allowing for\ncross language comparison. We benchmark two state of the art LLMs, OpenAI GPT\n4.0 and DeepSeek-V3, using precision, recall, and F1 score as evaluation\nmetrics. Our analysis covers three levels of detail: overall performance,\ncategory level performance, and individual code smell type performance.\nAdditionally, we explore cost effectiveness by comparing the token based\ndetection approach of GPT 4.0 with the pattern-matching techniques employed by\nDeepSeek V3. The study also includes a cost analysis relative to traditional\nstatic analysis tools such as SonarQube. The findings offer valuable guidance\nfor practitioners in selecting an efficient, cost effective solution for\nautomated code smell detection",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LG",
      "cs.PL"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16027v1",
    "published_date": "2025-04-22 16:44:39 UTC",
    "updated_date": "2025-04-22 16:44:39 UTC"
  },
  {
    "arxiv_id": "2504.16026v2",
    "title": "Trends in AI Supercomputers",
    "authors": [
      "Konstantin F. Pilz",
      "James Sanders",
      "Robi Rahman",
      "Lennart Heim"
    ],
    "abstract": "Frontier AI development relies on powerful AI supercomputers, yet analysis of\nthese systems is limited. We create a dataset of 500 AI supercomputers from\n2019 to 2025 and analyze key trends in performance, power needs, hardware cost,\nownership, and global distribution. We find that the computational performance\nof AI supercomputers has doubled every nine months, while hardware acquisition\ncost and power needs both doubled every year. The leading system in March 2025,\nxAI's Colossus, used 200,000 AI chips, had a hardware cost of \\$7B, and\nrequired 300 MW of power, as much as 250,000 households. As AI supercomputers\nevolved from tools for science to industrial machines, companies rapidly\nexpanded their share of total AI supercomputer performance, while the share of\ngovernments and academia diminished. Globally, the United States accounts for\nabout 75% of total performance in our dataset, with China in second place at\n15%. If the observed trends continue, the leading AI supercomputer in 2030 will\nachieve $2\\times10^{22}$ 16-bit FLOP/s, use two million AI chips, have a\nhardware cost of \\$200 billion, and require 9 GW of power. Our analysis\nprovides visibility into the AI supercomputer landscape, allowing policymakers\nto assess key AI trends like resource needs, ownership, and national\ncompetitiveness.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16026v2",
    "published_date": "2025-04-22 16:44:34 UTC",
    "updated_date": "2025-04-23 20:08:26 UTC"
  },
  {
    "arxiv_id": "2504.16021v1",
    "title": "Navigating the State of Cognitive Flow: Context-Aware AI Interventions for Effective Reasoning Support",
    "authors": [
      "Dinithi Dissanayake",
      "Suranga Nanayakkara"
    ],
    "abstract": "Flow theory describes an optimal cognitive state where individuals experience\ndeep focus and intrinsic motivation when a task's difficulty aligns with their\nskill level. In AI-augmented reasoning, interventions that disrupt the state of\ncognitive flow can hinder rather than enhance decision-making. This paper\nproposes a context-aware cognitive augmentation framework that adapts\ninterventions based on three key contextual factors: type, timing, and scale.\nBy leveraging multimodal behavioral cues (e.g., gaze behavior, typing\nhesitation, interaction speed), AI can dynamically adjust cognitive support to\nmaintain or restore flow. We introduce the concept of cognitive flow, an\nextension of flow theory in AI-augmented reasoning, where interventions are\npersonalized, adaptive, and minimally intrusive. By shifting from static\ninterventions to context-aware augmentation, our approach ensures that AI\nsystems support deep engagement in complex decision-making and reasoning\nwithout disrupting cognitive immersion.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "Presented at the 2025 ACM Workshop on Human-AI Interaction for\n  Augmented Reasoning, Report Number: CHI25-WS-AUGMENTED-REASONING",
    "pdf_url": "http://arxiv.org/pdf/2504.16021v1",
    "published_date": "2025-04-22 16:35:39 UTC",
    "updated_date": "2025-04-22 16:35:39 UTC"
  },
  {
    "arxiv_id": "2504.16153v1",
    "title": "Leveraging Social Media Analytics for Sustainability Trend Detection in Saudi Arabias Evolving Market",
    "authors": [
      "Kanwal Aalijah"
    ],
    "abstract": "Saudi Arabias rapid economic growth and social evolution under Vision 2030\npresent a unique opportunity to track emerging trends in real time. Uncovering\ntrends in real time can open up new avenues for business and investment\nopportunities. This paper explores how AI and social media analytics can\nuncover and monitor these trends across sectors like sustainability,\nconstruction, food beverages industry, tourism, technology, and entertainment.\nThis paper focus on use of AI-driven methodology to identify sustainability\ntrends across Saudi Arabia. We processed millions of social media posts, news,\nblogs in order to understand sustainability trends in the region. The paper\npresents an AI approach that can help economists, businesses, government to\nunderstand sustainability trends and make better decisions around them. This\napproach offers both sector-specific and cross-sector insights, giving\ndecision-makers a reliable, up to date snapshot of Saudi Arabias market shifts.\nBeyond Saudi Arabia, this framework also shows potential for adapting to other\nregions. Overall, our findings highlight how by using AI-methodologies, give\ndecision makers a reliable method to understand how initiatives are perceived\nand adopted by the public and understand growth of trends.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "9",
    "pdf_url": "http://arxiv.org/pdf/2504.16153v1",
    "published_date": "2025-04-22 16:33:15 UTC",
    "updated_date": "2025-04-22 16:33:15 UTC"
  },
  {
    "arxiv_id": "2504.16020v2",
    "title": "AlphaGrad: Non-Linear Gradient Normalization Optimizer",
    "authors": [
      "Soham Sane"
    ],
    "abstract": "We introduce AlphaGrad, a memory-efficient, conditionally stateless optimizer\naddressing the memory overhead and hyperparameter complexity of adaptive\nmethods like Adam. AlphaGrad enforces scale invariance via tensor-wise L2\ngradient normalization followed by a smooth hyperbolic tangent transformation,\n$g' = \\tanh(\\alpha \\cdot \\tilde{g})$, controlled by a single steepness\nparameter $\\alpha$. Our contributions include: (1) the AlphaGrad algorithm\nformulation; (2) a formal non-convex convergence analysis guaranteeing\nstationarity; (3) extensive empirical evaluation on diverse RL benchmarks (DQN,\nTD3, PPO). Compared to Adam, AlphaGrad demonstrates a highly context-dependent\nperformance profile. While exhibiting instability in off-policy DQN, it\nprovides enhanced training stability with competitive results in TD3 (requiring\ncareful $\\alpha$ tuning) and achieves substantially superior performance in\non-policy PPO. These results underscore the critical importance of empirical\n$\\alpha$ selection, revealing strong interactions between the optimizer's\ndynamics and the underlying RL algorithm. AlphaGrad presents a compelling\nalternative optimizer for memory-constrained scenarios and shows significant\npromise for on-policy learning regimes where its stability and efficiency\nadvantages can be particularly impactful.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16020v2",
    "published_date": "2025-04-22 16:33:14 UTC",
    "updated_date": "2025-04-23 01:25:32 UTC"
  },
  {
    "arxiv_id": "2504.18574v1",
    "title": "Understanding the Skill Gap in Recurrent Language Models: The Role of the Gather-and-Aggregate Mechanism",
    "authors": [
      "Aviv Bick",
      "Eric Xing",
      "Albert Gu"
    ],
    "abstract": "SSMs offer efficient processing of long sequences with fixed state sizes, but\nstruggle with algorithmic tasks like retrieving past context. In this work, we\nexamine how such in-context retrieval operates within Transformer- and\nSSM-based language models. We find that both architectures develop the same\nfundamental Gather-and-Aggregate (G&A) mechanism. A Gather Head first\nidentifies and extracts relevant information from the context, which an\nAggregate Head then integrates into a final representation. Across both model\ntypes, G&A concentrates in just a few heads, making them critical bottlenecks\neven for benchmarks that require a basic form of retrieval. For example,\ndisabling a single Gather or Aggregate Head of a pruned Llama-3.1-8B degrades\nits ability to retrieve the correct answer letter in MMLU, reducing accuracy\nfrom 66% to 25%. This finding suggests that in-context retrieval can obscure\nthe limited knowledge demands of certain tasks. Despite strong MMLU performance\nwith retrieval intact, the pruned model fails on other knowledge tests. Similar\nG&A dependencies exist in GSM8K, BBH, and dialogue tasks. Given the\nsignificance of G&A in performance, we show that retrieval challenges in SSMs\nmanifest in how they implement G&A, leading to smoother attention patterns\nrather than the sharp token transitions that effective G&A relies on. Thus,\nwhile a gap exists between Transformers and SSMs in implementing in-context\nretrieval, it is confined to a few heads, not the entire model. This insight\nsuggests a unified explanation for performance differences between Transformers\nand SSMs while also highlighting ways to combine their strengths. For example,\nin pretrained hybrid models, attention components naturally take on the role of\nAggregate Heads. Similarly, in a pretrained pure SSM, replacing a single G&A\nhead with an attention-based variant significantly improves retrieval.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.18574v1",
    "published_date": "2025-04-22 16:15:19 UTC",
    "updated_date": "2025-04-22 16:15:19 UTC"
  },
  {
    "arxiv_id": "2504.16005v3",
    "title": "CAPO: Cost-Aware Prompt Optimization",
    "authors": [
      "Tom Zehle",
      "Moritz Schlager",
      "Timo Heiß",
      "Matthias Feurer"
    ],
    "abstract": "Large language models (LLMs) have revolutionized natural language processing\nby solving a wide range of tasks simply guided by a prompt. Yet their\nperformance is highly sensitive to prompt formulation. While automated prompt\noptimization addresses this challenge by finding optimal prompts, current\nmethods require a substantial number of LLM calls and input tokens, making\nprompt optimization expensive. We introduce CAPO (Cost-Aware Prompt\nOptimization), an algorithm that enhances prompt optimization efficiency by\nintegrating AutoML techniques. CAPO is an evolutionary approach with LLMs as\noperators, incorporating racing to save evaluations and multi-objective\noptimization to balance performance with prompt length. It jointly optimizes\ninstructions and few-shot examples while leveraging task descriptions for\nimproved robustness. Our extensive experiments across diverse datasets and LLMs\ndemonstrate that CAPO outperforms state-of-the-art discrete prompt optimization\nmethods in 11/15 cases with improvements up to 21%p. Our algorithm achieves\nbetter performances already with smaller budgets, saves evaluations through\nracing, and decreases average prompt length via a length penalty, making it\nboth cost-efficient and cost-aware. Even without few-shot examples, CAPO\noutperforms its competitors and generally remains robust to initial prompts.\nCAPO represents an important step toward making prompt optimization more\npowerful and accessible by improving cost-efficiency.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.NE",
      "stat.ML"
    ],
    "primary_category": "cs.CL",
    "comment": "Submitted to AutoML 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.16005v3",
    "published_date": "2025-04-22 16:14:31 UTC",
    "updated_date": "2025-04-25 15:27:15 UTC"
  },
  {
    "arxiv_id": "2504.16152v1",
    "title": "Heterogeneous networks in drug-target interaction prediction",
    "authors": [
      "Mohammad Molaee",
      "Nasrollah Moghadam Charkari"
    ],
    "abstract": "Drug discovery requires a tremendous amount of time and cost. Computational\ndrug-target interaction prediction, a significant part of this process, can\nreduce these requirements by narrowing the search space for wet lab\nexperiments. In this survey, we provide comprehensive details of graph machine\nlearning-based methods in predicting drug-target interaction, as they have\nshown promising results in this field. These details include the overall\nframework, main contribution, datasets, and their source codes. The selected\npapers were mainly published from 2020 to 2024. Prior to discussing papers, we\nbriefly introduce the datasets commonly used with these methods and\nmeasurements to assess their performance. Finally, future challenges and some\ncrucial areas that need to be explored are discussed.",
    "categories": [
      "q-bio.BM",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.BM",
    "comment": "18 pages, 5 figures, 10 tables",
    "pdf_url": "http://arxiv.org/pdf/2504.16152v1",
    "published_date": "2025-04-22 16:09:22 UTC",
    "updated_date": "2025-04-22 16:09:22 UTC"
  },
  {
    "arxiv_id": "2504.16000v1",
    "title": "How Private is Your Attention? Bridging Privacy with In-Context Learning",
    "authors": [
      "Soham Bonnerjee",
      "Zhen Wei",
      "Yeon",
      "Anna Asch",
      "Sagnik Nandy",
      "Promit Ghosal"
    ],
    "abstract": "In-context learning (ICL)-the ability of transformer-based models to perform\nnew tasks from examples provided at inference time-has emerged as a hallmark of\nmodern language models. While recent works have investigated the mechanisms\nunderlying ICL, its feasibility under formal privacy constraints remains\nlargely unexplored. In this paper, we propose a differentially private\npretraining algorithm for linear attention heads and present the first\ntheoretical analysis of the privacy-accuracy trade-off for ICL in linear\nregression. Our results characterize the fundamental tension between\noptimization and privacy-induced noise, formally capturing behaviors observed\nin private training via iterative methods. Additionally, we show that our\nmethod is robust to adversarial perturbations of training prompts, unlike\nstandard ridge regression. All theoretical findings are supported by extensive\nsimulations across diverse settings.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.CL",
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "stat.ML",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16000v1",
    "published_date": "2025-04-22 16:05:26 UTC",
    "updated_date": "2025-04-22 16:05:26 UTC"
  },
  {
    "arxiv_id": "2504.15995v1",
    "title": "OPUS-VFL: Incentivizing Optimal Privacy-Utility Tradeoffs in Vertical Federated Learning",
    "authors": [
      "Sindhuja Madabushi",
      "Ahmad Faraz Khan",
      "Haider Ali",
      "Jin-Hee Cho"
    ],
    "abstract": "Vertical Federated Learning (VFL) enables organizations with disjoint feature\nspaces but shared user bases to collaboratively train models without sharing\nraw data. However, existing VFL systems face critical limitations: they often\nlack effective incentive mechanisms, struggle to balance privacy-utility\ntradeoffs, and fail to accommodate clients with heterogeneous resource\ncapabilities. These challenges hinder meaningful participation, degrade model\nperformance, and limit practical deployment. To address these issues, we\npropose OPUS-VFL, an Optimal Privacy-Utility tradeoff Strategy for VFL.\nOPUS-VFL introduces a novel, privacy-aware incentive mechanism that rewards\nclients based on a principled combination of model contribution, privacy\npreservation, and resource investment. It employs a lightweight leave-one-out\n(LOO) strategy to quantify feature importance per client, and integrates an\nadaptive differential privacy mechanism that enables clients to dynamically\ncalibrate noise levels to optimize their individual utility. Our framework is\ndesigned to be scalable, budget-balanced, and robust to inference and poisoning\nattacks. Extensive experiments on benchmark datasets (MNIST, CIFAR-10, and\nCIFAR-100) demonstrate that OPUS-VFL significantly outperforms state-of-the-art\nVFL baselines in both efficiency and robustness. It reduces label inference\nattack success rates by up to 20%, increases feature inference reconstruction\nerror (MSE) by over 30%, and achieves up to 25% higher incentives for clients\nthat contribute meaningfully while respecting privacy and cost constraints.\nThese results highlight the practicality and innovation of OPUS-VFL as a\nsecure, fair, and performance-driven solution for real-world VFL.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15995v1",
    "published_date": "2025-04-22 16:00:11 UTC",
    "updated_date": "2025-04-22 16:00:11 UTC"
  },
  {
    "arxiv_id": "2504.15983v1",
    "title": "W-PCA Based Gradient-Free Proxy for Efficient Search of Lightweight Language Models",
    "authors": [
      "Shang Wang"
    ],
    "abstract": "The demand for efficient natural language processing (NLP) systems has led to\nthe development of lightweight language models. Previous work in this area has\nprimarily focused on manual design or training-based neural architecture search\n(NAS) methods. Recently, zero-shot NAS methods have been proposed for\nevaluating language models without the need for training. However, prevailing\napproaches to zero-shot NAS often face challenges such as biased evaluation\nmetrics and computational inefficiencies. In this paper, we introduce\nweight-weighted PCA (W-PCA), a novel zero-shot NAS method specifically tailored\nfor lightweight language models. Our approach utilizes two evaluation proxies:\nthe parameter count and the number of principal components with cumulative\ncontribution exceeding $\\eta$ in the feed-forward neural (FFN) layer.\nAdditionally, by eliminating the need for gradient computations, we optimize\nthe evaluation time, thus enhancing the efficiency of designing and evaluating\nlightweight language models. We conduct a comparative analysis on the GLUE and\nSQuAD datasets to evaluate our approach. The results demonstrate that our\nmethod significantly reduces training time compared to one-shot NAS methods and\nachieves higher scores in the testing phase compared to previous\nstate-of-the-art training-based methods. Furthermore, we perform ranking\nevaluations on a dataset sampled from the FlexiBERT search space. Our approach\nexhibits superior ranking correlation and further reduces solving time compared\nto other zero-shot NAS methods that require gradient computation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.15983v1",
    "published_date": "2025-04-22 15:33:01 UTC",
    "updated_date": "2025-04-22 15:33:01 UTC"
  },
  {
    "arxiv_id": "2504.15972v1",
    "title": "Bug Destiny Prediction in Large Open-Source Software Repositories through Sentiment Analysis and BERT Topic Modeling",
    "authors": [
      "Sophie C. Pope",
      "Andrew Barovic",
      "Armin Moin"
    ],
    "abstract": "This study explores a novel approach to predicting key bug-related outcomes,\nincluding the time to resolution, time to fix, and ultimate status of a bug,\nusing data from the Bugzilla Eclipse Project. Specifically, we leverage\nfeatures available before a bug is resolved to enhance predictive accuracy. Our\nmethodology incorporates sentiment analysis to derive both an emotionality\nscore and a sentiment classification (positive or negative). Additionally, we\nintegrate the bug's priority level and its topic, extracted using a BERTopic\nmodel, as features for a Convolutional Neural Network (CNN) and a Multilayer\nPerceptron (MLP). Our findings indicate that the combination of BERTopic and\nsentiment analysis can improve certain model performance metrics. Furthermore,\nwe observe that balancing model inputs enhances practical applicability, albeit\nat the cost of a significant reduction in accuracy in most cases. To address\nour primary objectives, predicting time-to-resolution, time-to-fix, and bug\ndestiny, we employ both binary classification and exact time value predictions,\nallowing for a comparative evaluation of their predictive effectiveness.\nResults demonstrate that sentiment analysis serves as a valuable predictor of a\nbug's eventual outcome, particularly in determining whether it will be fixed.\nHowever, its utility is less pronounced when classifying bugs into more complex\nor unconventional outcome categories.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15972v1",
    "published_date": "2025-04-22 15:18:14 UTC",
    "updated_date": "2025-04-22 15:18:14 UTC"
  },
  {
    "arxiv_id": "2504.15956v1",
    "title": "Universal Approximation with Softmax Attention",
    "authors": [
      "Jerry Yao-Chieh Hu",
      "Hude Liu",
      "Hong-Yu Chen",
      "Weimin Wu",
      "Han Liu"
    ],
    "abstract": "We prove that with linear transformations, both (i) two-layer self-attention\nand (ii) one-layer self-attention followed by a softmax function are universal\napproximators for continuous sequence-to-sequence functions on compact domains.\nOur main technique is a new interpolation-based method for analyzing\nattention's internal mechanism. This leads to our key insight: self-attention\nis able to approximate a generalized version of ReLU to arbitrary precision,\nand hence subsumes many known universal approximators. Building on these, we\nshow that two-layer multi-head attention alone suffices as a\nsequence-to-sequence universal approximator. In contrast, prior works rely on\nfeed-forward networks to establish universal approximation in Transformers.\nFurthermore, we extend our techniques to show that, (softmax-)attention-only\nlayers are capable of approximating various statistical models in-context. We\nbelieve these techniques hold independent interest.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15956v1",
    "published_date": "2025-04-22 14:51:33 UTC",
    "updated_date": "2025-04-22 14:51:33 UTC"
  },
  {
    "arxiv_id": "2504.15941v2",
    "title": "FairTranslate: An English-French Dataset for Gender Bias Evaluation in Machine Translation by Overcoming Gender Binarity",
    "authors": [
      "Fanny Jourdan",
      "Yannick Chevalier",
      "Cécile Favre"
    ],
    "abstract": "Large Language Models (LLMs) are increasingly leveraged for translation tasks\nbut often fall short when translating inclusive language -- such as texts\ncontaining the singular 'they' pronoun or otherwise reflecting fair linguistic\nprotocols. Because these challenges span both computational and societal\ndomains, it is imperative to critically evaluate how well LLMs handle inclusive\ntranslation with a well-founded framework.\n  This paper presents FairTranslate, a novel, fully human-annotated dataset\ndesigned to evaluate non-binary gender biases in machine translation systems\nfrom English to French. FairTranslate includes 2418 English-French sentence\npairs related to occupations, annotated with rich metadata such as the\nstereotypical alignment of the occupation, grammatical gender indicator\nambiguity, and the ground-truth gender label (male, female, or inclusive).\n  We evaluate four leading LLMs (Gemma2-2B, Mistral-7B, Llama3.1-8B,\nLlama3.3-70B) on this dataset under different prompting procedures. Our results\nreveal substantial biases in gender representation across LLMs, highlighting\npersistent challenges in achieving equitable outcomes in machine translation.\nThese findings underscore the need for focused strategies and interventions\naimed at ensuring fair and inclusive language usage in LLM-based translation\nsystems.\n  We make the FairTranslate dataset publicly available on Hugging Face, and\ndisclose the code for all experiments on GitHub.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "FAccT 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.15941v2",
    "published_date": "2025-04-22 14:35:16 UTC",
    "updated_date": "2025-05-05 12:19:32 UTC"
  },
  {
    "arxiv_id": "2504.15929v2",
    "title": "Meta-Entity Driven Triplet Mining for Aligning Medical Vision-Language Models",
    "authors": [
      "Saban Ozturk",
      "Melih B. Yilmaz",
      "Muti Kara",
      "M. Talat Yavuz",
      "Aykut Koç",
      "Tolga Çukur"
    ],
    "abstract": "Diagnostic imaging relies on interpreting both images and radiology reports,\nbut the growing data volumes place significant pressure on medical experts,\nyielding increased errors and workflow backlogs. Medical vision-language models\n(med-VLMs) have emerged as a powerful framework to efficiently process\nmultimodal imaging data, particularly in chest X-ray (CXR) evaluations, albeit\ntheir performance hinges on how well image and text representations are\naligned. Existing alignment methods, predominantly based on contrastive\nlearning, prioritize separation between disease classes over segregation of\nfine-grained pathology attributes like location, size or severity, leading to\nsuboptimal representations. Here, we propose MedTrim (Meta-entity-driven\nTriplet mining), a novel method that enhances image-text alignment through\nmultimodal triplet learning synergistically guided by disease class as well as\nadjectival and directional pathology descriptors. Unlike common alignment\nmethods that separate broad disease classes, MedTrim leverages structured\nmeta-entity information to preserve subtle but clinically significant\nintra-class variations. For this purpose, we first introduce an ontology-based\nentity recognition module that extracts pathology-specific meta-entities from\nCXR reports, as annotations on pathology attributes are rare in public\ndatasets. For refined sample selection in triplet mining, we then introduce a\nnovel score function that captures an aggregate measure of inter-sample\nsimilarity based on disease classes and adjectival/directional descriptors.\nLastly, we introduce a multimodal triplet alignment objective for explicit\nwithin- and cross-modal alignment between samples sharing detailed pathology\ncharacteristics. Our demonstrations indicate that MedTrim improves performance\nin downstream retrieval and classification tasks compared to state-of-the-art\nalignment methods.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "18 pages, 7 figures, 6 tables",
    "pdf_url": "http://arxiv.org/pdf/2504.15929v2",
    "published_date": "2025-04-22 14:17:51 UTC",
    "updated_date": "2025-04-24 01:26:34 UTC"
  },
  {
    "arxiv_id": "2504.15928v1",
    "title": "A Clinician-Friendly Platform for Ophthalmic Image Analysis Without Technical Barriers",
    "authors": [
      "Meng Wang",
      "Tian Lin",
      "Qingshan Hou",
      "Aidi Lin",
      "Jingcheng Wang",
      "Qingsheng Peng",
      "Truong X. Nguyen",
      "Danqi Fang",
      "Ke Zou",
      "Ting Xu",
      "Cancan Xue",
      "Ten Cheer Quek",
      "Qinkai Yu",
      "Minxin Liu",
      "Hui Zhou",
      "Zixuan Xiao",
      "Guiqin He",
      "Huiyu Liang",
      "Tingkun Shi",
      "Man Chen",
      "Linna Liu",
      "Yuanyuan Peng",
      "Lianyu Wang",
      "Qiuming Hu",
      "Junhong Chen",
      "Zhenhua Zhang",
      "Cheng Chen",
      "Yitian Zhao",
      "Dianbo Liu",
      "Jianhua Wu",
      "Xinjian Chen",
      "Changqing Zhang",
      "Triet Thanh Nguyen",
      "Yanda Meng",
      "Yalin Zheng",
      "Yih Chung Tham",
      "Carol Y. Cheung",
      "Huazhu Fu",
      "Haoyu Chen",
      "Ching-Yu Cheng"
    ],
    "abstract": "Artificial intelligence (AI) shows remarkable potential in medical imaging\ndiagnostics, but current models typically require retraining when deployed\nacross different clinical centers, limiting their widespread adoption. We\nintroduce GlobeReady, a clinician-friendly AI platform that enables ocular\ndisease diagnosis without retraining/fine-tuning or technical expertise.\nGlobeReady achieves high accuracy across imaging modalities: 93.9-98.5% for an\n11-category fundus photo dataset and 87.2-92.7% for a 15-category OCT dataset.\nThrough training-free local feature augmentation, it addresses domain shifts\nacross centers and populations, reaching an average accuracy of 88.9% across\nfive centers in China, 86.3% in Vietnam, and 90.2% in the UK. The built-in\nconfidence-quantifiable diagnostic approach further boosted accuracy to\n94.9-99.4% (fundus) and 88.2-96.2% (OCT), while identifying out-of-distribution\ncases at 86.3% (49 CFP categories) and 90.6% (13 OCT categories). Clinicians\nfrom multiple countries rated GlobeReady highly (average 4.6 out of 5) for its\nusability and clinical relevance. These results demonstrate GlobeReady's\nrobust, scalable diagnostic capability and potential to support ophthalmic care\nwithout technical barriers.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15928v1",
    "published_date": "2025-04-22 14:17:22 UTC",
    "updated_date": "2025-04-22 14:17:22 UTC"
  },
  {
    "arxiv_id": "2504.15927v1",
    "title": "New Recipe for Semi-supervised Community Detection: Clique Annealing under Crystallization Kinetics",
    "authors": [
      "Ling Cheng",
      "Jiashu Pu",
      "Ruicheng Liang",
      "Qian Shao",
      "Hezhe Qiao",
      "Feida Zhu"
    ],
    "abstract": "Semi-supervised community detection methods are widely used for identifying\nspecific communities due to the label scarcity. Existing semi-supervised\ncommunity detection methods typically involve two learning stages learning in\nboth initial identification and subsequent adjustment, which often starts from\nan unreasonable community core candidate. Moreover, these methods encounter\nscalability issues because they depend on reinforcement learning and generative\nadversarial networks, leading to higher computational costs and restricting the\nselection of candidates. To address these limitations, we draw a parallel\nbetween crystallization kinetics and community detection to integrate the\nspontaneity of the annealing process into community detection. Specifically, we\nliken community detection to identifying a crystal subgrain (core) that expands\ninto a complete grain (community) through a process similar to annealing. Based\non this finding, we propose CLique ANNealing (CLANN), which applies kinetics\nconcepts to community detection by integrating these principles into the\noptimization process to strengthen the consistency of the community core.\nSubsequently, a learning-free Transitive Annealer was employed to refine the\nfirst-stage candidates by merging neighboring cliques and repositioning the\ncommunity core, enabling a spontaneous growth process that enhances\nscalability. Extensive experiments on \\textbf{43} different network settings\ndemonstrate that CLANN outperforms state-of-the-art methods across multiple\nreal-world datasets, showcasing its exceptional efficacy and efficiency in\ncommunity detection.",
    "categories": [
      "cs.SI",
      "cs.AI"
    ],
    "primary_category": "cs.SI",
    "comment": "arXiv admin note: text overlap with arXiv:2203.05898 by other authors",
    "pdf_url": "http://arxiv.org/pdf/2504.15927v1",
    "published_date": "2025-04-22 14:17:15 UTC",
    "updated_date": "2025-04-22 14:17:15 UTC"
  },
  {
    "arxiv_id": "2504.15924v1",
    "title": "Achieving Distributive Justice in Federated Learning via Uncertainty Quantification",
    "authors": [
      "Alycia Carey",
      "Xintao Wu"
    ],
    "abstract": "Client-level fairness metrics for federated learning are used to ensure that\nall clients in a federation either: a) have similar final performance on their\nlocal data distributions (i.e., client parity), or b) obtain final performance\non their local data distributions relative to their contribution to the\nfederated learning process (i.e., contribution fairness). While a handful of\nworks that propose either client-parity or contribution-based fairness metrics\nground their definitions and decisions in social theories of equality -- such\nas distributive justice -- most works arbitrarily choose what notion of\nfairness to align with which makes it difficult for practitioners to choose\nwhich fairness metric aligns best with their fairness ethics. In this work, we\npropose UDJ-FL (Uncertainty-based Distributive Justice for Federated Learning),\na flexible federated learning framework that can achieve multiple distributive\njustice-based client-level fairness metrics. Namely, by utilizing techniques\ninspired by fair resource allocation, in conjunction with performing aleatoric\nuncertainty-based client weighing, our UDJ-FL framework is able to achieve\negalitarian, utilitarian, Rawls' difference principle, or desert-based\nclient-level fairness. We empirically show the ability of UDJ-FL to achieve all\nfour defined distributive justice-based client-level fairness metrics in\naddition to providing fairness equivalent to (or surpassing) other popular fair\nfederated learning works. Further, we provide justification for why aleatoric\nuncertainty weighing is necessary to the construction of our UDJ-FL framework\nas well as derive theoretical guarantees for the generalization bounds of\nUDJ-FL. Our code is publicly available at\nhttps://github.com/alycia-noel/UDJ-FL.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML",
      "68T01",
      "I.2.0"
    ],
    "primary_category": "cs.LG",
    "comment": "21 pages, 1 figure, 7 tables",
    "pdf_url": "http://arxiv.org/pdf/2504.15924v1",
    "published_date": "2025-04-22 14:07:56 UTC",
    "updated_date": "2025-04-22 14:07:56 UTC"
  },
  {
    "arxiv_id": "2504.15918v2",
    "title": "Ask2Loc: Learning to Locate Instructional Visual Answers by Asking Questions",
    "authors": [
      "Chang Zong",
      "Bin Li",
      "Shoujun Zhou",
      "Jian Wan",
      "Lei Zhang"
    ],
    "abstract": "Locating specific segments within an instructional video is an efficient way\nto acquire guiding knowledge. Generally, the task of obtaining video segments\nfor both verbal explanations and visual demonstrations is known as visual\nanswer localization (VAL). However, users often need multiple interactions to\nobtain answers that align with their expectations when using the system. During\nthese interactions, humans deepen their understanding of the video content by\nasking themselves questions, thereby accurately identifying the location.\nTherefore, we propose a new task, named In-VAL, to simulate the multiple\ninteractions between humans and videos in the procedure of obtaining visual\nanswers. The In-VAL task requires interactively addressing several semantic gap\nissues, including 1) the ambiguity of user intent in the input questions, 2)\nthe incompleteness of language in video subtitles, and 3) the fragmentation of\ncontent in video segments. To address these issues, we propose Ask2Loc, a\nframework for resolving In-VAL by asking questions. It includes three key\nmodules: 1) a chatting module to refine initial questions and uncover clear\nintentions, 2) a rewriting module to generate fluent language and create\ncomplete descriptions, and 3) a searching module to broaden local context and\nprovide integrated content. We conduct extensive experiments on three\nreconstructed In-VAL datasets. Compared to traditional end-to-end and two-stage\nmethods, our proposed Ask2Loc can improve performance by up to 14.91 (mIoU) on\nthe In-VAL task. Our code and datasets can be accessed at\nhttps://github.com/changzong/Ask2Loc.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.HC",
      "68T45, 68T20"
    ],
    "primary_category": "cs.CV",
    "comment": "16 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.15918v2",
    "published_date": "2025-04-22 14:03:16 UTC",
    "updated_date": "2025-04-23 03:01:06 UTC"
  },
  {
    "arxiv_id": "2504.15912v1",
    "title": "Automated Bug Report Prioritization in Large Open-Source Projects",
    "authors": [
      "Riley Pierson",
      "Armin Moin"
    ],
    "abstract": "Large open-source projects receive a large number of issues (known as bugs),\nincluding software defect (i.e., bug) reports and new feature requests from\ntheir user and developer communities at a fast rate. The often limited project\nresources do not allow them to deal with all issues. Instead, they have to\nprioritize them according to the project's priorities and the issues'\nseverities. In this paper, we propose a novel approach to automated bug\nprioritization based on the natural language text of the bug reports that are\nstored in the open bug repositories of the issue-tracking systems. We conduct\ntopic modeling using a variant of LDA called TopicMiner-MTM and text\nclassification with the BERT large language model to achieve a higher\nperformance level compared to the state-of-the-art. Experimental results using\nan existing reference dataset containing 85,156 bug reports of the Eclipse\nPlatform project indicate that we outperform existing approaches in terms of\nAccuracy, Precision, Recall, and F1-measure of the bug report priority\nprediction.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15912v1",
    "published_date": "2025-04-22 13:57:48 UTC",
    "updated_date": "2025-04-22 13:57:48 UTC"
  },
  {
    "arxiv_id": "2504.15905v1",
    "title": "GraphEdge: Dynamic Graph Partition and Task Scheduling for GNNs Computing in Edge Network",
    "authors": [
      "Wenjing Xiao",
      "Chenglong Shi",
      "Miaojiang Chen",
      "Zhiquan Liu",
      "Min Chen",
      "H. Herbert Song"
    ],
    "abstract": "With the exponential growth of Internet of Things (IoT) devices, edge\ncomputing (EC) is gradually playing an important role in providing\ncost-effective services. However, existing approaches struggle to perform well\nin graph-structured scenarios where user data is correlated, such as traffic\nflow prediction and social relationship recommender systems. In particular,\ngraph neural network (GNN)-based approaches lead to expensive server\ncommunication cost. To address this problem, we propose GraphEdge, an efficient\nGNN-based EC architecture. It considers the EC system of GNN tasks, where there\nare associations between users and it needs to take into account the task data\nof its neighbors when processing the tasks of a user. Specifically, the\narchitecture first perceives the user topology and represents their data\nassociations as a graph layout at each time step. Then the graph layout is\noptimized by calling our proposed hierarchical traversal graph cut algorithm\n(HiCut), which cuts the graph layout into multiple weakly associated subgraphs\nbased on the aggregation characteristics of GNN, and the communication cost\nbetween different subgraphs during GNN inference is minimized. Finally, based\non the optimized graph layout, our proposed deep reinforcement learning (DRL)\nbased graph offloading algorithm (DRLGO) is executed to obtain the optimal\noffloading strategy for the tasks of users, the offloading strategy is\nsubgraph-based, it tries to offload user tasks in a subgraph to the same edge\nserver as possible while minimizing the task processing time and energy\nconsumption of the EC system. Experimental results show the good effectiveness\nand dynamic adaptation of our proposed architecture and it also performs well\neven in dynamic scenarios.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "17 pages,12 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.15905v1",
    "published_date": "2025-04-22 13:45:13 UTC",
    "updated_date": "2025-04-22 13:45:13 UTC"
  },
  {
    "arxiv_id": "2504.15903v2",
    "title": "Impact of Noise on LLM-Models Performance in Abstraction and Reasoning Corpus (ARC) Tasks with Model Temperature Considerations",
    "authors": [
      "Nikhil Khandalkar",
      "Pavan Yadav",
      "Krishna Shinde",
      "Lokesh B. Ramegowda",
      "Rajarshi Das"
    ],
    "abstract": "Recent advancements in Large Language Models (LLMs) have generated growing\ninterest in their structured reasoning capabilities, particularly in tasks\ninvolving abstraction and pattern recognition. The Abstraction and Reasoning\nCorpus (ARC) benchmark plays a crucial role in evaluating these capabilities by\ntesting how well AI models generalize to novel problems. While GPT-4o\ndemonstrates strong performance by solving all ARC tasks under zero-noise\nconditions, other models like DeepSeek R1 and LLaMA 3.2 fail to solve any,\nsuggesting limitations in their ability to reason beyond simple pattern\nmatching. To explore this gap, we systematically evaluate these models across\ndifferent noise levels and temperature settings. Our results reveal that the\nintroduction of noise consistently impairs model performance, regardless of\narchitecture. This decline highlights a shared vulnerability: current LLMs,\ndespite showing signs of abstract reasoning, remain highly sensitive to input\nperturbations. Such fragility raises concerns about their real-world\napplicability, where noise and uncertainty are common. By comparing how\ndifferent model architectures respond to these challenges, we offer insights\ninto the structural weaknesses of modern LLMs in reasoning tasks. This work\nunderscores the need for developing more robust and adaptable AI systems\ncapable of handling the ambiguity and variability inherent in real-world\nscenarios. Our findings aim to guide future research toward enhancing model\ngeneralization, robustness, and alignment with human-like cognitive\nflexibility.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "60 pages, 25 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.15903v2",
    "published_date": "2025-04-22 13:43:58 UTC",
    "updated_date": "2025-04-23 13:23:40 UTC"
  },
  {
    "arxiv_id": "2504.15895v2",
    "title": "Dynamic Early Exit in Reasoning Models",
    "authors": [
      "Chenxu Yang",
      "Qingyi Si",
      "Yongjie Duan",
      "Zheliang Zhu",
      "Chenyu Zhu",
      "Qiaowei Li",
      "Zheng Lin",
      "Li Cao",
      "Weiping Wang"
    ],
    "abstract": "Recent advances in large reasoning language models (LRLMs) rely on test-time\nscaling, which extends long chain-of-thought (CoT) generation to solve complex\ntasks. However, overthinking in long CoT not only slows down the efficiency of\nproblem solving, but also risks accuracy loss due to the extremely detailed or\nredundant reasoning steps. We propose a simple yet effective method that allows\nLLMs to self-truncate CoT sequences by early exit during generation. Instead of\nrelying on fixed heuristics, the proposed method monitors model behavior at\npotential reasoning transition points (e.g.,\"Wait\" tokens) and dynamically\nterminates the next reasoning chain's generation when the model exhibits high\nconfidence in a trial answer. Our method requires no additional training and\ncan be seamlessly integrated into existing o1-like reasoning LLMs. Experiments\non 10 reasoning benchmarks (e.g., GSM8K, MATH-500, AMC, GPQA, AIME and\nLiveCodeBench) show that the proposed method is consistently effective on 11\ncutting-edge reasoning LLMs of varying series and sizes, reducing the length of\nCoT sequences by an average of 19.1% to 80.1% while improving accuracy by 0.3%\nto 5.0%.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "23 pages, 15 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.15895v2",
    "published_date": "2025-04-22 13:36:53 UTC",
    "updated_date": "2025-05-17 04:09:13 UTC"
  },
  {
    "arxiv_id": "2504.15894v1",
    "title": "Supporting Data-Frame Dynamics in AI-assisted Decision Making",
    "authors": [
      "Chengbo Zheng",
      "Tim Miller",
      "Alina Bialkowski",
      "H Peter Soyer",
      "Monika Janda"
    ],
    "abstract": "High stakes decision-making often requires a continuous interplay between\nevolving evidence and shifting hypotheses, a dynamic that is not well supported\nby current AI decision support systems. In this paper, we introduce a\nmixed-initiative framework for AI assisted decision making that is grounded in\nthe data-frame theory of sensemaking and the evaluative AI paradigm. Our\napproach enables both humans and AI to collaboratively construct, validate, and\nadapt hypotheses. We demonstrate our framework with an AI-assisted skin cancer\ndiagnosis prototype that leverages a concept bottleneck model to facilitate\ninterpretable interactions and dynamic updates to diagnostic hypotheses.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "Presented at the 2025 ACM Workshop on Human-AI Interaction for\n  Augmented Reasoning, Report Number: CHI25-WS-AUGMENTED-REASONING",
    "pdf_url": "http://arxiv.org/pdf/2504.15894v1",
    "published_date": "2025-04-22 13:36:06 UTC",
    "updated_date": "2025-04-22 13:36:06 UTC"
  },
  {
    "arxiv_id": "2504.15883v1",
    "title": "Integrating Non-Linear Radon Transformation for Diabetic Retinopathy Grading",
    "authors": [
      "Farida Mohsen",
      "Samir Belhaouari",
      "Zubair Shah"
    ],
    "abstract": "Diabetic retinopathy is a serious ocular complication that poses a\nsignificant threat to patients' vision and overall health. Early detection and\naccurate grading are essential to prevent vision loss. Current automatic\ngrading methods rely heavily on deep learning applied to retinal fundus images,\nbut the complex, irregular patterns of lesions in these images, which vary in\nshape and distribution, make it difficult to capture subtle changes. This study\nintroduces RadFuse, a multi-representation deep learning framework that\nintegrates non-linear RadEx-transformed sinogram images with traditional fundus\nimages to enhance diabetic retinopathy detection and grading. Our RadEx\ntransformation, an optimized non-linear extension of the Radon transform,\ngenerates sinogram representations to capture complex retinal lesion patterns.\nBy leveraging both spatial and transformed domain information, RadFuse enriches\nthe feature set available to deep learning models, improving the\ndifferentiation of severity levels. We conducted extensive experiments on two\nbenchmark datasets, APTOS-2019 and DDR, using three convolutional neural\nnetworks (CNNs): ResNeXt-50, MobileNetV2, and VGG19. RadFuse showed significant\nimprovements over fundus-image-only models across all three CNN architectures\nand outperformed state-of-the-art methods on both datasets. For severity\ngrading across five stages, RadFuse achieved a quadratic weighted kappa of\n93.24%, an accuracy of 87.07%, and an F1-score of 87.17%. In binary\nclassification between healthy and diabetic retinopathy cases, the method\nreached an accuracy of 99.09%, precision of 98.58%, and recall of 99.6%,\nsurpassing previously established models. These results demonstrate RadFuse's\ncapacity to capture complex non-linear features, advancing diabetic retinopathy\nclassification and promoting the integration of advanced mathematical\ntransforms in medical image analysis.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15883v1",
    "published_date": "2025-04-22 13:27:28 UTC",
    "updated_date": "2025-04-22 13:27:28 UTC"
  },
  {
    "arxiv_id": "2504.15876v2",
    "title": "Bidirectional Task-Motion Planning Based on Hierarchical Reinforcement Learning for Strategic Confrontation",
    "authors": [
      "Qizhen Wu",
      "Lei Chen",
      "Kexin Liu",
      "Jinhu Lü"
    ],
    "abstract": "In swarm robotics, confrontation scenarios, including strategic\nconfrontations, require efficient decision-making that integrates discrete\ncommands and continuous actions. Traditional task and motion planning methods\nseparate decision-making into two layers, but their unidirectional structure\nfails to capture the interdependence between these layers, limiting\nadaptability in dynamic environments. Here, we propose a novel bidirectional\napproach based on hierarchical reinforcement learning, enabling dynamic\ninteraction between the layers. This method effectively maps commands to task\nallocation and actions to path planning, while leveraging cross-training\ntechniques to enhance learning across the hierarchical framework. Furthermore,\nwe introduce a trajectory prediction model that bridges abstract task\nrepresentations with actionable planning goals. In our experiments, it achieves\nover 80% in confrontation win rate and under 0.01 seconds in decision time,\noutperforming existing approaches. Demonstrations through large-scale tests and\nreal-world robot experiments further emphasize the generalization capabilities\nand practical applicability of our method.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15876v2",
    "published_date": "2025-04-22 13:22:58 UTC",
    "updated_date": "2025-04-23 15:00:10 UTC"
  },
  {
    "arxiv_id": "2504.16148v1",
    "title": "Towards responsible AI for education: Hybrid human-AI to confront the Elephant in the room",
    "authors": [
      "Danial Hooshyar",
      "Gustav Šír",
      "Yeongwook Yang",
      "Eve Kikas",
      "Raija Hämäläinen",
      "Tommi Kärkkäinen",
      "Dragan Gašević",
      "Roger Azevedo"
    ],
    "abstract": "Despite significant advancements in AI-driven educational systems and ongoing\ncalls for responsible AI for education, several critical issues remain\nunresolved -- acting as the elephant in the room within AI in education,\nlearning analytics, educational data mining, learning sciences, and educational\npsychology communities. This critical analysis identifies and examines nine\npersistent challenges that continue to undermine the fairness, transparency,\nand effectiveness of current AI methods and applications in education. These\ninclude: (1) the lack of clarity around what AI for education truly means --\noften ignoring the distinct purposes, strengths, and limitations of different\nAI families -- and the trend of equating it with domain-agnostic,\ncompany-driven large language models; (2) the widespread neglect of essential\nlearning processes such as motivation, emotion, and (meta)cognition in\nAI-driven learner modelling and their contextual nature; (3) limited\nintegration of domain knowledge and lack of stakeholder involvement in AI\ndesign and development; (4) continued use of non-sequential machine learning\nmodels on temporal educational data; (5) misuse of non-sequential metrics to\nevaluate sequential models; (6) use of unreliable explainable AI methods to\nprovide explanations for black-box models; (7) ignoring ethical guidelines in\naddressing data inconsistencies during model training; (8) use of mainstream AI\nmethods for pattern discovery and learning analytics without systematic\nbenchmarking; and (9) overemphasis on global prescriptions while overlooking\nlocalised, student-specific recommendations. Supported by theoretical and\nempirical research, we demonstrate how hybrid AI methods -- specifically\nneural-symbolic AI -- can address the elephant in the room and serve as the\nfoundation for responsible, trustworthy AI systems in education.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16148v1",
    "published_date": "2025-04-22 13:20:43 UTC",
    "updated_date": "2025-04-22 13:20:43 UTC"
  },
  {
    "arxiv_id": "2504.15865v2",
    "title": "MedNNS: Supernet-based Medical Task-Adaptive Neural Network Search",
    "authors": [
      "Lotfi Abdelkrim Mecharbat",
      "Ibrahim Almakky",
      "Martin Takac",
      "Mohammad Yaqub"
    ],
    "abstract": "Deep learning (DL) has achieved remarkable progress in the field of medical\nimaging. However, adapting DL models to medical tasks remains a significant\nchallenge, primarily due to two key factors: (1) architecture selection, as\ndifferent tasks necessitate specialized model designs, and (2) weight\ninitialization, which directly impacts the convergence speed and final\nperformance of the models. Although transfer learning from ImageNet is a widely\nadopted strategy, its effectiveness is constrained by the substantial\ndifferences between natural and medical images. To address these challenges, we\nintroduce Medical Neural Network Search (MedNNS), the first Neural Network\nSearch framework for medical imaging applications. MedNNS jointly optimizes\narchitecture selection and weight initialization by constructing a meta-space\nthat encodes datasets and models based on how well they perform together. We\nbuild this space using a Supernetwork-based approach, expanding the model zoo\nsize by 51x times over previous state-of-the-art (SOTA) methods. Moreover, we\nintroduce rank loss and Fr\\'echet Inception Distance (FID) loss into the\nconstruction of the space to capture inter-model and inter-dataset\nrelationships, thereby achieving more accurate alignment in the meta-space.\nExperimental results across multiple datasets demonstrate that MedNNS\nsignificantly outperforms both ImageNet pre-trained DL models and SOTA Neural\nArchitecture Search (NAS) methods, achieving an average accuracy improvement of\n1.7% across datasets while converging substantially faster. The code and the\nprocessed meta-space is available at https://github.com/BioMedIA-MBZUAI/MedNNS.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15865v2",
    "published_date": "2025-04-22 13:04:40 UTC",
    "updated_date": "2025-04-23 05:28:18 UTC"
  },
  {
    "arxiv_id": "2504.21020v1",
    "title": "Context-Enhanced Contrastive Search for Improved LLM Text Generation",
    "authors": [
      "Jaydip Sen",
      "Rohit Pandey",
      "Hetvi Waghela"
    ],
    "abstract": "Recently, Large Language Models (LLMs) have demonstrated remarkable\nadvancements in Natural Language Processing (NLP). However, generating\nhigh-quality text that balances coherence, diversity, and relevance remains\nchallenging. Traditional decoding methods, such as bean search and top-k\nsampling, often struggle with either repetitive or incoherent outputs,\nparticularly in tasks that require long-form text generation. To address these\nlimitations, the paper proposes a novel enhancement of the well-known\nContrastive Search algorithm, Context-Enhanced Contrastive Search (CECS) with\ncontextual calibration. The proposed scheme introduces several novelties\nincluding dynamic contextual importance weighting, multi-level Contrastive\nSearch, and adaptive temperature control, to optimize the balance between\nfluency, creativity, and precision. The performance of CECS is evaluated using\nseveral standard metrics such as BLEU, ROUGE, and semantic similarity.\nExperimental results demonstrate significant improvements in both coherence and\nrelevance of the generated texts by CECS outperforming the existing Contrastive\nSearch techniques. The proposed algorithm has several potential applications in\nthe real world including legal document drafting, customer service chatbots,\nand content marketing.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "This is the pre-review version of our paper, which has been accepted\n  for publication in the IEEE 6th International Conference on Emerging\n  Technologies (INCET). The conference will be organized at Belgaum, India,\n  from May 24 to 26, 2025. This is not the final camera-ready paper, which will\n  be available on IEEE Xplore. The paper is 9 pages long, and it contains 2\n  Figures and 4 Tables",
    "pdf_url": "http://arxiv.org/pdf/2504.21020v1",
    "published_date": "2025-04-22 13:00:14 UTC",
    "updated_date": "2025-04-22 13:00:14 UTC"
  },
  {
    "arxiv_id": "2504.16145v1",
    "title": "Progressive Language-guided Visual Learning for Multi-Task Visual Grounding",
    "authors": [
      "Jingchao Wang",
      "Hong Wang",
      "Wenlong Zhang",
      "Kunhua Ji",
      "Dingjiang Huang",
      "Yefeng Zheng"
    ],
    "abstract": "Multi-task visual grounding (MTVG) includes two sub-tasks, i.e., Referring\nExpression Comprehension (REC) and Referring Expression Segmentation (RES). The\nexisting representative approaches generally follow the research pipeline which\nmainly consists of three core procedures, including independent feature\nextraction for visual and linguistic modalities, respectively, cross-modal\ninteraction module, and independent prediction heads for different sub-tasks.\nAlbeit achieving remarkable performance, this research line has two\nlimitations: 1) The linguistic content has not been fully injected into the\nentire visual backbone for boosting more effective visual feature extraction\nand it needs an extra cross-modal interaction module; 2) The relationship\nbetween REC and RES tasks is not effectively exploited to help the\ncollaborative prediction for more accurate output. To deal with these problems,\nin this paper, we propose a Progressive Language-guided Visual Learning\nframework for multi-task visual grounding, called PLVL, which not only finely\nmine the inherent feature expression of the visual modality itself but also\nprogressively inject the language information to help learn linguistic-related\nvisual features. In this manner, our PLVL does not need additional cross-modal\nfusion module while fully introducing the language guidance. Furthermore, we\nanalyze that the localization center for REC would help identify the\nto-be-segmented object region for RES to some extent. Inspired by this\ninvestigation, we design a multi-task head to accomplish collaborative\npredictions for these two sub-tasks. Extensive experiments conducted on several\nbenchmark datasets comprehensively substantiate that our PLVL obviously\noutperforms the representative methods in both REC and RES tasks.\nhttps://github.com/jcwang0602/PLVL",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16145v1",
    "published_date": "2025-04-22 12:48:12 UTC",
    "updated_date": "2025-04-22 12:48:12 UTC"
  },
  {
    "arxiv_id": "2504.15847v1",
    "title": "CARE: Compatibility-Aware Incentive Mechanisms for Federated Learning with Budgeted Requesters",
    "authors": [
      "Xiang Liu",
      "Hau Chan",
      "Minming Li",
      "Xianlong Zeng",
      "Chenchen Fu",
      "Weiwei Wu"
    ],
    "abstract": "Federated learning (FL) is a promising approach that allows requesters (\\eg,\nservers) to obtain local training models from workers (e.g., clients). Since\nworkers are typically unwilling to provide training services/models freely and\nvoluntarily, many incentive mechanisms in FL are designed to incentivize\nparticipation by offering monetary rewards from requesters. However, existing\nstudies neglect two crucial aspects of real-world FL scenarios. First, workers\ncan possess inherent incompatibility characteristics (e.g., communication\nchannels and data sources), which can lead to degradation of FL efficiency\n(e.g., low communication efficiency and poor model generalization). Second, the\nrequesters are budgeted, which limits the amount of workers they can hire for\ntheir tasks. In this paper, we investigate the scenario in FL where multiple\nbudgeted requesters seek training services from incompatible workers with\nprivate training costs. We consider two settings: the cooperative budget\nsetting where requesters cooperate to pool their budgets to improve their\noverall utility and the non-cooperative budget setting where each requester\noptimizes their utility within their own budgets. To address efficiency\ndegradation caused by worker incompatibility, we develop novel\ncompatibility-aware incentive mechanisms, CARE-CO and CARE-NO, for both\nsettings to elicit true private costs and determine workers to hire for\nrequesters and their rewards while satisfying requester budget constraints. Our\nmechanisms guarantee individual rationality, truthfulness, budget feasibility,\nand approximation performance. We conduct extensive experiments using\nreal-world datasets to show that the proposed mechanisms significantly\noutperform existing baselines.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15847v1",
    "published_date": "2025-04-22 12:42:45 UTC",
    "updated_date": "2025-04-22 12:42:45 UTC"
  },
  {
    "arxiv_id": "2504.15829v1",
    "title": "Generative AI for Research Data Processing: Lessons Learnt From Three Use Cases",
    "authors": [
      "Modhurita Mitra",
      "Martine G. de Vos",
      "Nicola Cortinovis",
      "Dawa Ometto"
    ],
    "abstract": "There has been enormous interest in generative AI since ChatGPT was launched\nin 2022. However, there are concerns about the accuracy and consistency of the\noutputs of generative AI. We have carried out an exploratory study on the\napplication of this new technology in research data processing. We identified\ntasks for which rule-based or traditional machine learning approaches were\ndifficult to apply, and then performed these tasks using generative AI.\n  We demonstrate the feasibility of using the generative AI model Claude 3 Opus\nin three research projects involving complex data processing tasks:\n  1) Information extraction: We extract plant species names from historical\nseedlists (catalogues of seeds) published by botanical gardens.\n  2) Natural language understanding: We extract certain data points (name of\ndrug, name of health indication, relative effectiveness, cost-effectiveness,\netc.) from documents published by Health Technology Assessment organisations in\nthe EU.\n  3) Text classification: We assign industry codes to projects on the\ncrowdfunding website Kickstarter.\n  We share the lessons we learnt from these use cases: How to determine if\ngenerative AI is an appropriate tool for a given data processing task, and if\nso, how to maximise the accuracy and consistency of the results obtained.",
    "categories": [
      "cs.AI",
      "68T50",
      "I.2.7"
    ],
    "primary_category": "cs.AI",
    "comment": "10 pages, 4 figures, 6 tables. Published in Proceedings of the 2024\n  IEEE 20th International Conference on e-Science (e-Science), Osaka, Japan",
    "pdf_url": "http://arxiv.org/pdf/2504.15829v1",
    "published_date": "2025-04-22 12:21:07 UTC",
    "updated_date": "2025-04-22 12:21:07 UTC"
  },
  {
    "arxiv_id": "2504.15827v1",
    "title": "DualOptim: Enhancing Efficacy and Stability in Machine Unlearning with Dual Optimizers",
    "authors": [
      "Xuyang Zhong",
      "Haochen Luo",
      "Chen Liu"
    ],
    "abstract": "Existing machine unlearning (MU) approaches exhibit significant sensitivity\nto hyperparameters, requiring meticulous tuning that limits practical\ndeployment. In this work, we first empirically demonstrate the instability and\nsuboptimal performance of existing popular MU methods when deployed in\ndifferent scenarios. To address this issue, we propose Dual Optimizer\n(DualOptim), which incorporates adaptive learning rate and decoupled momentum\nfactors. Empirical and theoretical evidence demonstrates that DualOptim\ncontributes to effective and stable unlearning. Through extensive experiments,\nwe show that DualOptim can significantly boost MU efficacy and stability across\ndiverse tasks, including image classification, image generation, and large\nlanguage models, making it a versatile approach to empower existing MU\nalgorithms.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15827v1",
    "published_date": "2025-04-22 12:18:26 UTC",
    "updated_date": "2025-04-22 12:18:26 UTC"
  },
  {
    "arxiv_id": "2504.15823v1",
    "title": "Human-Imperceptible Physical Adversarial Attack for NIR Face Recognition Models",
    "authors": [
      "Songyan Xie",
      "Jinghang Wen",
      "Encheng Su",
      "Qiucheng Yu"
    ],
    "abstract": "Near-infrared (NIR) face recognition systems, which can operate effectively\nin low-light conditions or in the presence of makeup, exhibit vulnerabilities\nwhen subjected to physical adversarial attacks. To further demonstrate the\npotential risks in real-world applications, we design a novel, stealthy, and\npractical adversarial patch to attack NIR face recognition systems in a\nblack-box setting. We achieved this by utilizing human-imperceptible\ninfrared-absorbing ink to generate multiple patches with digitally optimized\nshapes and positions for infrared images. To address the optimization mismatch\nbetween digital and real-world NIR imaging, we develop a light reflection model\nfor human skin to minimize pixel-level discrepancies by simulating NIR light\nreflection.\n  Compared to state-of-the-art (SOTA) physical attacks on NIR face recognition\nsystems, the experimental results show that our method improves the attack\nsuccess rate in both digital and physical domains, particularly maintaining\neffectiveness across various face postures. Notably, the proposed approach\noutperforms SOTA methods, achieving an average attack success rate of 82.46% in\nthe physical domain across different models, compared to 64.18% for existing\nmethods. The artifact is available at\nhttps://anonymous.4open.science/r/Human-imperceptible-adversarial-patch-0703/.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15823v1",
    "published_date": "2025-04-22 12:10:25 UTC",
    "updated_date": "2025-04-22 12:10:25 UTC"
  },
  {
    "arxiv_id": "2504.15812v1",
    "title": "Fusing Reward and Dueling Feedback in Stochastic Bandits",
    "authors": [
      "Xuchuang Wang",
      "Qirun Zeng",
      "Jinhang Zuo",
      "Xutong Liu",
      "Mohammad Hajiesmaili",
      "John C. S. Lui",
      "Adam Wierman"
    ],
    "abstract": "This paper investigates the fusion of absolute (reward) and relative\n(dueling) feedback in stochastic bandits, where both feedback types are\ngathered in each decision round. We derive a regret lower bound, demonstrating\nthat an efficient algorithm may incur only the smaller among the reward and\ndueling-based regret for each individual arm. We propose two fusion approaches:\n(1) a simple elimination fusion algorithm that leverages both feedback types to\nexplore all arms and unifies collected information by sharing a common\ncandidate arm set, and (2) a decomposition fusion algorithm that selects the\nmore effective feedback to explore the corresponding arms and randomly assigns\none feedback type for exploration and the other for exploitation in each round.\nThe elimination fusion experiences a suboptimal multiplicative term of the\nnumber of arms in regret due to the intrinsic suboptimality of dueling\nelimination. In contrast, the decomposition fusion achieves regret matching the\nlower bound up to a constant under a common assumption. Extensive experiments\nconfirm the efficacy of our algorithms and theoretical results.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15812v1",
    "published_date": "2025-04-22 11:51:20 UTC",
    "updated_date": "2025-04-22 11:51:20 UTC"
  },
  {
    "arxiv_id": "2504.15806v2",
    "title": "DAE-KAN: A Kolmogorov-Arnold Network Model for High-Index Differential-Algebraic Equations",
    "authors": [
      "Kai Luo",
      "Juan Tang",
      "Mingchao Cai",
      "Xiaoqing Zeng",
      "Manqi Xie",
      "Ming Yan"
    ],
    "abstract": "Kolmogorov-Arnold Networks (KANs) have emerged as a promising alternative to\nMulti-layer Perceptrons (MLPs) due to their superior function-fitting abilities\nin data-driven modeling. In this paper, we propose a novel framework, DAE-KAN,\nfor solving high-index differential-algebraic equations (DAEs) by integrating\nKANs with Physics-Informed Neural Networks (PINNs). This framework not only\npreserves the ability of traditional PINNs to model complex systems governed by\nphysical laws but also enhances their performance by leveraging the\nfunction-fitting strengths of KANs. Numerical experiments demonstrate that for\nDAE systems ranging from index-1 to index-3, DAE-KAN reduces the absolute\nerrors of both differential and algebraic variables by 1 to 2 orders of\nmagnitude compared to traditional PINNs. To assess the effectiveness of this\napproach, we analyze the drift-off error and find that both PINNs and DAE-KAN\noutperform classical numerical methods in controlling this phenomenon. Our\nresults highlight the potential of neural network methods, particularly\nDAE-KAN, in solving high-index DAEs with substantial computational accuracy and\ngeneralization, offering a promising solution for challenging partial\ndifferential-algebraic equations.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15806v2",
    "published_date": "2025-04-22 11:42:02 UTC",
    "updated_date": "2025-04-23 06:21:23 UTC"
  },
  {
    "arxiv_id": "2504.15804v1",
    "title": "Insights from Verification: Training a Verilog Generation LLM with Reinforcement Learning with Testbench Feedback",
    "authors": [
      "Ning Wang",
      "Bingkun Yao",
      "Jie Zhou",
      "Yuchen Hu",
      "Xi Wang",
      "Nan Guan",
      "Zhe Jiang"
    ],
    "abstract": "Large language models (LLMs) have shown strong performance in Verilog\ngeneration from natural language description. However, ensuring the functional\ncorrectness of the generated code remains a significant challenge. This paper\nintroduces a method that integrates verification insights from testbench into\nthe training of Verilog generation LLMs, aligning the training with the\nfundamental goal of hardware design: functional correctness. The main obstacle\nin using LLMs for Verilog code generation is the lack of sufficient functional\nverification data, particularly testbenches paired with design specifications\nand code. To address this problem, we introduce an automatic testbench\ngeneration pipeline that decomposes the process and uses feedback from the\nVerilog compiler simulator (VCS) to reduce hallucination and ensure\ncorrectness. We then use the testbench to evaluate the generated codes and\ncollect them for further training, where verification insights are introduced.\nOur method applies reinforcement learning (RL), specifically direct preference\noptimization (DPO), to align Verilog code generation with functional\ncorrectness by training preference pairs based on testbench outcomes. In\nevaluations on VerilogEval-Machine, VerilogEval-Human, RTLLM v1.1, RTLLM v2,\nand VerilogEval v2, our approach consistently outperforms state-of-the-art\nbaselines in generating functionally correct Verilog code. We open source all\ntraining code, data, and models at\nhttps://anonymous.4open.science/r/VeriPrefer-E88B.",
    "categories": [
      "cs.AR",
      "cs.AI"
    ],
    "primary_category": "cs.AR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15804v1",
    "published_date": "2025-04-22 11:38:14 UTC",
    "updated_date": "2025-04-22 11:38:14 UTC"
  },
  {
    "arxiv_id": "2504.15801v1",
    "title": "A closer look at how large language models trust humans: patterns and biases",
    "authors": [
      "Valeria Lerman",
      "Yaniv Dover"
    ],
    "abstract": "As large language models (LLMs) and LLM-based agents increasingly interact\nwith humans in decision-making contexts, understanding the trust dynamics\nbetween humans and AI agents becomes a central concern. While considerable\nliterature studies how humans trust AI agents, it is much less understood how\nLLM-based agents develop effective trust in humans. LLM-based agents likely\nrely on some sort of implicit effective trust in trust-related contexts (e.g.,\nevaluating individual loan applications) to assist and affect decision making.\nUsing established behavioral theories, we develop an approach that studies\nwhether LLMs trust depends on the three major trustworthiness dimensions:\ncompetence, benevolence and integrity of the human subject. We also study how\ndemographic variables affect effective trust. Across 43,200 simulated\nexperiments, for five popular language models, across five different scenarios\nwe find that LLM trust development shows an overall similarity to human trust\ndevelopment. We find that in most, but not all cases, LLM trust is strongly\npredicted by trustworthiness, and in some cases also biased by age, religion\nand gender, especially in financial scenarios. This is particularly true for\nscenarios common in the literature and for newer models. While the overall\npatterns align with human-like mechanisms of effective trust formation,\ndifferent models exhibit variation in how they estimate trust; in some cases,\ntrustworthiness and demographic factors are weak predictors of effective trust.\nThese findings call for a better understanding of AI-to-human trust dynamics\nand monitoring of biases and trust development patterns to prevent unintended\nand potentially harmful outcomes in trust-sensitive applications of AI.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15801v1",
    "published_date": "2025-04-22 11:31:50 UTC",
    "updated_date": "2025-04-22 11:31:50 UTC"
  },
  {
    "arxiv_id": "2504.18572v1",
    "title": "BELL: Benchmarking the Explainability of Large Language Models",
    "authors": [
      "Syed Quiser Ahmed",
      "Bharathi Vokkaliga Ganesh",
      "Jagadish Babu P",
      "Karthick Selvaraj",
      "ReddySiva Naga Parvathi Devi",
      "Sravya Kappala"
    ],
    "abstract": "Large Language Models have demonstrated remarkable capabilities in natural\nlanguage processing, yet their decision-making processes often lack\ntransparency. This opaqueness raises significant concerns regarding trust,\nbias, and model performance. To address these issues, understanding and\nevaluating the interpretability of LLMs is crucial. This paper introduces a\nstandardised benchmarking technique, Benchmarking the Explainability of Large\nLanguage Models, designed to evaluate the explainability of large language\nmodels.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.18572v1",
    "published_date": "2025-04-22 11:15:23 UTC",
    "updated_date": "2025-04-22 11:15:23 UTC"
  },
  {
    "arxiv_id": "2504.15791v1",
    "title": "Crisp complexity of fuzzy classifiers",
    "authors": [
      "Raquel Fernandez-Peralta",
      "Javier Fumanal-Idocin",
      "Javier Andreu-Perez"
    ],
    "abstract": "Rule-based systems are a very popular form of explainable AI, particularly in\nthe fuzzy community, where fuzzy rules are widely used for control and\nclassification problems. However, fuzzy rule-based classifiers struggle to\nreach bigger traction outside of fuzzy venues, because users sometimes do not\nknow about fuzzy and because fuzzy partitions are not so easy to interpret in\nsome situations. In this work, we propose a methodology to reduce fuzzy\nrule-based classifiers to crisp rule-based classifiers. We study different\npossible crisp descriptions and implement an algorithm to obtain them. Also, we\nanalyze the complexity of the resulting crisp classifiers. We believe that our\nresults can help both fuzzy and non-fuzzy practitioners understand better the\nway in which fuzzy rule bases partition the feature space and how easily one\nsystem can be translated to another and vice versa. Our complexity metric can\nalso help to choose between different fuzzy classifiers based on what the\nequivalent crisp partitions look like.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15791v1",
    "published_date": "2025-04-22 11:06:25 UTC",
    "updated_date": "2025-04-22 11:06:25 UTC"
  },
  {
    "arxiv_id": "2504.15785v1",
    "title": "WALL-E 2.0: World Alignment by NeuroSymbolic Learning improves World Model-based LLM Agents",
    "authors": [
      "Siyu Zhou",
      "Tianyi Zhou",
      "Yijun Yang",
      "Guodong Long",
      "Deheng Ye",
      "Jing Jiang",
      "Chengqi Zhang"
    ],
    "abstract": "Can we build accurate world models out of large language models (LLMs)? How\ncan world models benefit LLM agents? The gap between the prior knowledge of\nLLMs and the specified environment's dynamics usually bottlenecks LLMs'\nperformance as world models. To bridge the gap, we propose a training-free\n\"world alignment\" that learns an environment's symbolic knowledge complementary\nto LLMs. The symbolic knowledge covers action rules, knowledge graphs, and\nscene graphs, which are extracted by LLMs from exploration trajectories and\nencoded into executable codes to regulate LLM agents' policies. We further\npropose an RL-free, model-based agent \"WALL-E 2.0\" through the model-predictive\ncontrol (MPC) framework. Unlike classical MPC requiring costly optimization on\nthe fly, we adopt an LLM agent as an efficient look-ahead optimizer of future\nsteps' actions by interacting with the neurosymbolic world model. While the LLM\nagent's strong heuristics make it an efficient planner in MPC, the quality of\nits planned actions is also secured by the accurate predictions of the aligned\nworld model. They together considerably improve learning efficiency in a new\nenvironment. On open-world challenges in Mars (Minecraft like) and ALFWorld\n(embodied indoor environments), WALL-E 2.0 significantly outperforms existing\nmethods, e.g., surpassing baselines in Mars by 16.1%-51.6% of success rate and\nby at least 61.7% in score. In ALFWorld, it achieves a new record 98% success\nrate after only 4 iterations.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Code is available at https://github.com/elated-sawyer/WALL-E",
    "pdf_url": "http://arxiv.org/pdf/2504.15785v1",
    "published_date": "2025-04-22 10:58:27 UTC",
    "updated_date": "2025-04-22 10:58:27 UTC"
  },
  {
    "arxiv_id": "2504.15784v1",
    "title": "Automated Creativity Evaluation for Large Language Models: A Reference-Based Approach",
    "authors": [
      "Ruizhe Li",
      "Chiwei Zhu",
      "Benfeng Xu",
      "Xiaorui Wang",
      "Zhendong Mao"
    ],
    "abstract": "Creative writing is a key capability of Large Language Models (LLMs), with\npotential applications in literature, storytelling, and various creative\ndomains. However, evaluating the creativity of machine-generated texts remains\na significant challenge, as existing methods either rely on costly manual\nannotations or fail to align closely with human assessments. In this paper, we\npropose an effective automated evaluation method based on the Torrance Test of\nCreative Writing (TTCW), which evaluates creativity as product. Our method\nemploys a reference-based Likert-style approach, scoring generated creative\ntexts relative to high-quality reference texts across various tests.\nExperimental results demonstrate that our method significantly improves the\nalignment between LLM evaluations and human assessments, achieving a pairwise\naccuracy of 0.75 (+15\\%).",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15784v1",
    "published_date": "2025-04-22 10:52:23 UTC",
    "updated_date": "2025-04-22 10:52:23 UTC"
  },
  {
    "arxiv_id": "2504.15780v1",
    "title": "TrustGeoGen: Scalable and Formal-Verified Data Engine for Trustworthy Multi-modal Geometric Problem Solving",
    "authors": [
      "Daocheng Fu",
      "Zijun Chen",
      "Renqiu Xia",
      "Qi Liu",
      "Yuan Feng",
      "Hongbin Zhou",
      "Renrui Zhang",
      "Shiyang Feng",
      "Peng Gao",
      "Junchi Yan",
      "Botian Shi",
      "Bo Zhang",
      "Yu Qiao"
    ],
    "abstract": "Mathematical geometric problem solving (GPS) often requires effective\nintegration of multimodal information and verifiable logical coherence. Despite\nthe fast development of large language models in general problem solving, it\nremains unresolved regarding with both methodology and benchmarks, especially\ngiven the fact that exiting synthetic GPS benchmarks are often not\nself-verified and contain noise and self-contradicted information due to the\nillusion of LLMs. In this paper, we propose a scalable data engine called\nTrustGeoGen for problem generation, with formal verification to provide a\nprincipled benchmark, which we believe lays the foundation for the further\ndevelopment of methods for GPS. The engine synthesizes geometric data through\nfour key innovations: 1) multimodal-aligned generation of diagrams, textual\ndescriptions, and stepwise solutions; 2) formal verification ensuring\nrule-compliant reasoning paths; 3) a bootstrapping mechanism enabling\ncomplexity escalation via recursive state generation and 4) our devised\nGeoExplore series algorithms simultaneously produce multi-solution variants and\nself-reflective backtracking traces. By formal logical verification,\nTrustGeoGen produces GeoTrust-200K dataset with guaranteed modality integrity,\nalong with GeoTrust-test testset. Experiments reveal the state-of-the-art\nmodels achieve only 49.17\\% accuracy on GeoTrust-test, demonstrating its\nevaluation stringency. Crucially, models trained on GeoTrust achieve OOD\ngeneralization on GeoQA, significantly reducing logical inconsistencies\nrelative to pseudo-label annotated by OpenAI-o1. Our code is available at\nhttps://github.com/Alpha-Innovator/TrustGeoGen",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15780v1",
    "published_date": "2025-04-22 10:45:23 UTC",
    "updated_date": "2025-04-22 10:45:23 UTC"
  },
  {
    "arxiv_id": "2504.15779v1",
    "title": "Shannon invariants: A scalable approach to information decomposition",
    "authors": [
      "Aaron J. Gutknecht",
      "Fernando E. Rosas",
      "David A. Ehrlich",
      "Abdullah Makkeh",
      "Pedro A. M. Mediano",
      "Michael Wibral"
    ],
    "abstract": "Distributed systems, such as biological and artificial neural networks,\nprocess information via complex interactions engaging multiple subsystems,\nresulting in high-order patterns with distinct properties across scales.\nInvestigating how these systems process information remains challenging due to\ndifficulties in defining appropriate multivariate metrics and ensuring their\nscalability to large systems. To address these challenges, we introduce a novel\nframework based on what we call \"Shannon invariants\" -- quantities that capture\nessential properties of high-order information processing in a way that depends\nonly on the definition of entropy and can be efficiently calculated for large\nsystems. Our theoretical results demonstrate how Shannon invariants can be used\nto resolve long-standing ambiguities regarding the interpretation of widely\nused multivariate information-theoretic measures. Moreover, our practical\nresults reveal distinctive information-processing signatures of various deep\nlearning architectures across layers, which lead to new insights into how these\nsystems process information and how this evolves during training. Overall, our\nframework resolves fundamental limitations in analyzing high-order phenomena\nand offers broad opportunities for theoretical developments and empirical\nanalyses.",
    "categories": [
      "cs.IT",
      "cs.AI",
      "cs.LG",
      "math.IT",
      "nlin.AO",
      "physics.data-an"
    ],
    "primary_category": "cs.IT",
    "comment": "16 pages, 4 Figures",
    "pdf_url": "http://arxiv.org/pdf/2504.15779v1",
    "published_date": "2025-04-22 10:41:38 UTC",
    "updated_date": "2025-04-22 10:41:38 UTC"
  },
  {
    "arxiv_id": "2504.15773v2",
    "title": "Clifford Group Equivariant Diffusion Models for 3D Molecular Generation",
    "authors": [
      "Cong Liu",
      "Sharvaree Vadgama",
      "David Ruhe",
      "Erik Bekkers",
      "Patrick Forré"
    ],
    "abstract": "This paper explores leveraging the Clifford algebra's expressive power for\n$\\E(n)$-equivariant diffusion models. We utilize the geometric products between\nClifford multivectors and the rich geometric information encoded in Clifford\nsubspaces in \\emph{Clifford Diffusion Models} (CDMs). We extend the diffusion\nprocess beyond just Clifford one-vectors to incorporate all higher-grade\nmultivector subspaces. The data is embedded in grade-$k$ subspaces, allowing us\nto apply latent diffusion across complete multivectors. This enables CDMs to\ncapture the joint distribution across different subspaces of the algebra,\nincorporating richer geometric information through higher-order features. We\nprovide empirical results for unconditional molecular generation on the QM9\ndataset, showing that CDMs provide a promising avenue for generative modeling.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "7 pages, 1 figure, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2504.15773v2",
    "published_date": "2025-04-22 10:30:06 UTC",
    "updated_date": "2025-04-24 04:27:13 UTC"
  },
  {
    "arxiv_id": "2504.15766v1",
    "title": "Dynamic Intent Queries for Motion Transformer-based Trajectory Prediction",
    "authors": [
      "Tobias Demmler",
      "Lennart Hartung",
      "Andreas Tamke",
      "Thao Dang",
      "Alexander Hegai",
      "Karsten Haug",
      "Lars Mikelsons"
    ],
    "abstract": "In autonomous driving, accurately predicting the movements of other traffic\nparticipants is crucial, as it significantly influences a vehicle's planning\nprocesses. Modern trajectory prediction models strive to interpret complex\npatterns and dependencies from agent and map data. The Motion Transformer (MTR)\narchitecture and subsequent work define the most accurate methods in common\nbenchmarks such as the Waymo Open Motion Benchmark. The MTR model employs\npre-generated static intention points as initial goal points for trajectory\nprediction. However, the static nature of these points frequently leads to\nmisalignment with map data in specific traffic scenarios, resulting in\nunfeasible or unrealistic goal points. Our research addresses this limitation\nby integrating scene-specific dynamic intention points into the MTR model. This\nadaptation of the MTR model was trained and evaluated on the Waymo Open Motion\nDataset. Our findings demonstrate that incorporating dynamic intention points\nhas a significant positive impact on trajectory prediction accuracy, especially\nfor predictions over long time horizons. Furthermore, we analyze the impact on\nground truth trajectories which are not compliant with the map data or are\nillegal maneuvers.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15766v1",
    "published_date": "2025-04-22 10:20:35 UTC",
    "updated_date": "2025-04-22 10:20:35 UTC"
  },
  {
    "arxiv_id": "2504.15743v1",
    "title": "iMedic: Towards Smartphone-based Self-Auscultation Tool for AI-Powered Pediatric Respiratory Assessment",
    "authors": [
      "Seung Gyu Jeong",
      "Sung Woo Nam",
      "Seong Kwan Jung",
      "Seong-Eun Kim"
    ],
    "abstract": "Respiratory auscultation is crucial for early detection of pediatric\npneumonia, a condition that can quickly worsen without timely intervention. In\nareas with limited physician access, effective auscultation is challenging. We\npresent a smartphone-based system that leverages built-in microphones and\nadvanced deep learning algorithms to detect abnormal respiratory sounds\nindicative of pneumonia risk. Our end-to-end deep learning framework employs\ndomain generalization to integrate a large electronic stethoscope dataset with\na smaller smartphone-derived dataset, enabling robust feature learning for\naccurate respiratory assessments without expensive equipment. The accompanying\nmobile application guides caregivers in collecting high-quality lung sound\nsamples and provides immediate feedback on potential pneumonia risks. User\nstudies show strong classification performance and high acceptance,\ndemonstrating the system's ability to facilitate proactive interventions and\nreduce preventable childhood pneumonia deaths. By seamlessly integrating into\nubiquitous smartphones, this approach offers a promising avenue for more\nequitable and comprehensive remote pediatric care.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15743v1",
    "published_date": "2025-04-22 09:45:50 UTC",
    "updated_date": "2025-04-22 09:45:50 UTC"
  },
  {
    "arxiv_id": "2504.15724v1",
    "title": "Collaborative Split Federated Learning with Parallel Training and Aggregation",
    "authors": [
      "Yiannis Papageorgiou",
      "Yannis Thomas",
      "Alexios Filippakopoulos",
      "Ramin Khalili",
      "Iordanis Koutsopoulos"
    ],
    "abstract": "Federated learning (FL) operates based on model exchanges between the server\nand the clients, and it suffers from significant client-side computation and\ncommunication burden. Split federated learning (SFL) arises a promising\nsolution by splitting the model into two parts, that are trained sequentially:\nthe clients train the first part of the model (client-side model) and transmit\nit to the server that trains the second (server-side model). Existing SFL\nschemes though still exhibit long training delays and significant communication\noverhead, especially when clients of different computing capability\nparticipate. Thus, we propose Collaborative-Split Federated Learning~(C-SFL), a\nnovel scheme that splits the model into three parts, namely the model parts\ntrained at the computationally weak clients, the ones trained at the\ncomputationally strong clients, and the ones at the server. Unlike existing\nworks, C-SFL enables parallel training and aggregation of model's parts at the\nclients and at the server, resulting in reduced training delays and\ncommmunication overhead while improving the model's accuracy. Experiments\nverify the multiple gains of C-SFL against the existing schemes.",
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15724v1",
    "published_date": "2025-04-22 09:18:57 UTC",
    "updated_date": "2025-04-22 09:18:57 UTC"
  },
  {
    "arxiv_id": "2504.15719v1",
    "title": "Implementing Rational Choice Functions with LLMs and Measuring their Alignment with User Preferences",
    "authors": [
      "Anna Karnysheva",
      "Christian Drescher",
      "Dietrich Klakow"
    ],
    "abstract": "As large language models (LLMs) become integral to intelligent user\ninterfaces (IUIs), their role as decision-making agents raises critical\nconcerns about alignment. Although extensive research has addressed issues such\nas factuality, bias, and toxicity, comparatively little attention has been paid\nto measuring alignment to preferences, i.e., the relative desirability of\ndifferent alternatives, a concept used in decision making, economics, and\nsocial choice theory. However, a reliable decision-making agent makes choices\nthat align well with user preferences.\n  In this paper, we generalize existing methods that exploit LLMs for ranking\nalternative outcomes by addressing alignment with the broader and more flexible\nconcept of user preferences, which includes both strict preferences and\nindifference among alternatives. To this end, we put forward design principles\nfor using LLMs to implement rational choice functions, and provide the\nnecessary tools to measure preference satisfaction. We demonstrate the\napplicability of our approach through an empirical study in a practical\napplication of an IUI in the automotive domain.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15719v1",
    "published_date": "2025-04-22 09:08:21 UTC",
    "updated_date": "2025-04-22 09:08:21 UTC"
  },
  {
    "arxiv_id": "2504.15716v1",
    "title": "DianJin-R1: Evaluating and Enhancing Financial Reasoning in Large Language Models",
    "authors": [
      "Jie Zhu",
      "Qian Chen",
      "Huaixia Dou",
      "Junhui Li",
      "Lifan Guo",
      "Feng Chen",
      "Chi Zhang"
    ],
    "abstract": "Effective reasoning remains a core challenge for large language models (LLMs)\nin the financial domain, where tasks often require domain-specific knowledge,\nprecise numerical calculations, and strict adherence to compliance rules. We\npropose DianJin-R1, a reasoning-enhanced framework designed to address these\nchallenges through reasoning-augmented supervision and reinforcement learning.\nCentral to our approach is DianJin-R1-Data, a high-quality dataset constructed\nfrom CFLUE, FinQA, and a proprietary compliance corpus (Chinese Compliance\nCheck, CCC), combining diverse financial reasoning scenarios with verified\nannotations. Our models, DianJin-R1-7B and DianJin-R1-32B, are fine-tuned from\nQwen2.5-7B-Instruct and Qwen2.5-32B-Instruct using a structured format that\ngenerates both reasoning steps and final answers. To further refine reasoning\nquality, we apply Group Relative Policy Optimization (GRPO), a reinforcement\nlearning method that incorporates dual reward signals: one encouraging\nstructured outputs and another rewarding answer correctness. We evaluate our\nmodels on five benchmarks: three financial datasets (CFLUE, FinQA, and CCC) and\ntwo general reasoning benchmarks (MATH-500 and GPQA-Diamond). Experimental\nresults show that DianJin-R1 models consistently outperform their non-reasoning\ncounterparts, especially on complex financial tasks. Moreover, on the\nreal-world CCC dataset, our single-call reasoning models match or even surpass\nthe performance of multi-agent systems that require significantly more\ncomputational cost. These findings demonstrate the effectiveness of DianJin-R1\nin enhancing financial reasoning through structured supervision and\nreward-aligned learning, offering a scalable and practical solution for\nreal-world applications.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15716v1",
    "published_date": "2025-04-22 09:01:04 UTC",
    "updated_date": "2025-04-22 09:01:04 UTC"
  },
  {
    "arxiv_id": "2504.15707v1",
    "title": "RePOPE: Impact of Annotation Errors on the POPE Benchmark",
    "authors": [
      "Yannic Neuhaus",
      "Matthias Hein"
    ],
    "abstract": "Since data annotation is costly, benchmark datasets often incorporate labels\nfrom established image datasets. In this work, we assess the impact of label\nerrors in MSCOCO on the frequently used object hallucination benchmark POPE. We\nre-annotate the benchmark images and identify an imbalance in annotation errors\nacross different subsets. Evaluating multiple models on the revised labels,\nwhich we denote as RePOPE, we observe notable shifts in model rankings,\nhighlighting the impact of label quality. Code and data are available at\nhttps://github.com/YanNeu/RePOPE .",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15707v1",
    "published_date": "2025-04-22 08:47:59 UTC",
    "updated_date": "2025-04-22 08:47:59 UTC"
  },
  {
    "arxiv_id": "2504.16144v1",
    "title": "Detecting Actionable Requests and Offers on Social Media During Crises Using LLMs",
    "authors": [
      "Ahmed El Fekih Zguir",
      "Ferda Ofli",
      "Muhammad Imran"
    ],
    "abstract": "Natural disasters often result in a surge of social media activity, including\nrequests for assistance, offers of help, sentiments, and general updates. To\nenable humanitarian organizations to respond more efficiently, we propose a\nfine-grained hierarchical taxonomy to systematically organize crisis-related\ninformation about requests and offers into three critical dimensions: supplies,\nemergency personnel, and actions. Leveraging the capabilities of Large Language\nModels (LLMs), we introduce Query-Specific Few-shot Learning (QSF Learning)\nthat retrieves class-specific labeled examples from an embedding database to\nenhance the model's performance in detecting and classifying posts. Beyond\nclassification, we assess the actionability of messages to prioritize posts\nrequiring immediate attention. Extensive experiments demonstrate that our\napproach outperforms baseline prompting strategies, effectively identifying and\nprioritizing actionable requests and offers.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16144v1",
    "published_date": "2025-04-22 08:34:58 UTC",
    "updated_date": "2025-04-22 08:34:58 UTC"
  },
  {
    "arxiv_id": "2504.15699v2",
    "title": "Advancing Embodied Agent Security: From Safety Benchmarks to Input Moderation",
    "authors": [
      "Ning Wang",
      "Zihan Yan",
      "Weiyang Li",
      "Chuan Ma",
      "He Chen",
      "Tao Xiang"
    ],
    "abstract": "Embodied agents exhibit immense potential across a multitude of domains,\nmaking the assurance of their behavioral safety a fundamental prerequisite for\ntheir widespread deployment. However, existing research predominantly\nconcentrates on the security of general large language models, lacking\nspecialized methodologies for establishing safety benchmarks and input\nmoderation tailored to embodied agents. To bridge this gap, this paper\nintroduces a novel input moderation framework, meticulously designed to\nsafeguard embodied agents. This framework encompasses the entire pipeline,\nincluding taxonomy definition, dataset curation, moderator architecture, model\ntraining, and rigorous evaluation. Notably, we introduce EAsafetyBench, a\nmeticulously crafted safety benchmark engineered to facilitate both the\ntraining and stringent assessment of moderators specifically designed for\nembodied agents. Furthermore, we propose Pinpoint, an innovative\nprompt-decoupled input moderation scheme that harnesses a masked attention\nmechanism to effectively isolate and mitigate the influence of functional\nprompts on moderation tasks. Extensive experiments conducted on diverse\nbenchmark datasets and models validate the feasibility and efficacy of the\nproposed approach. The results demonstrate that our methodologies achieve an\nimpressive average detection accuracy of 94.58%, surpassing the performance of\nexisting state-of-the-art techniques, alongside an exceptional moderation\nprocessing time of merely 0.002 seconds per instance.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "9 pages",
    "pdf_url": "http://arxiv.org/pdf/2504.15699v2",
    "published_date": "2025-04-22 08:34:35 UTC",
    "updated_date": "2025-05-08 09:12:22 UTC"
  },
  {
    "arxiv_id": "2505.00013v1",
    "title": "Performance Evaluation of Emotion Classification in Japanese Using RoBERTa and DeBERTa",
    "authors": [
      "Yoichi Takenaka"
    ],
    "abstract": "Background Practical applications such as social media monitoring and\ncustomer-feedback analysis require accurate emotion detection for Japanese\ntext, yet resource scarcity and class imbalance hinder model performance.\n  Objective This study aims to build a high-accuracy model for predicting the\npresence or absence of eight Plutchik emotions in Japanese sentences.\n  Methods Using the WRIME corpus, we transform reader-averaged intensity scores\ninto binary labels and fine-tune four pre-trained language models (BERT,\nRoBERTa, DeBERTa-v3-base, DeBERTa-v3-large). For context, we also assess two\nlarge language models (TinySwallow-1.5B-Instruct and ChatGPT-4o). Accuracy and\nF1-score serve as evaluation metrics.\n  Results DeBERTa-v3-large attains the best mean accuracy (0.860) and F1-score\n(0.662), outperforming all other models. It maintains robust F1 across both\nhigh-frequency emotions (e.g., Joy, Anticipation) and low-frequency emotions\n(e.g., Anger, Trust). The LLMs lag, with ChatGPT-4o and\nTinySwallow-1.5B-Instruct scoring 0.527 and 0.292 in mean F1, respectively.\n  Conclusion The fine-tuned DeBERTa-v3-large model currently offers the most\nreliable solution for binary emotion classification in Japanese. We release\nthis model as a pip-installable package (pip install\ndeberta-emotion-predictor). Future work should augment data for rare emotions,\nreduce model size, and explore prompt engineering to improve LLM performance.\n  This manuscript is under review for possible publication in New Generation\nComputing.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "14 pages, 3 tables, 3 appendices. Submitted to New Generation\n  Computing. Includes comparisons between fine-tuned PLMs and LLMs on Japanese\n  emotion classification. Code available at\n  https://pypi.org/project/deberta-emotion-predictor/",
    "pdf_url": "http://arxiv.org/pdf/2505.00013v1",
    "published_date": "2025-04-22 07:51:37 UTC",
    "updated_date": "2025-04-22 07:51:37 UTC"
  },
  {
    "arxiv_id": "2504.15668v1",
    "title": "Exploring Inevitable Waypoints for Unsolvability Explanation in Hybrid Planning Problems",
    "authors": [
      "Mir Md Sajid Sarwar",
      "Rajarshi Ray"
    ],
    "abstract": "Explaining unsolvability of planning problems is of significant research\ninterest in Explainable AI Planning. AI planning literature has reported\nseveral research efforts on generating explanations of solutions to planning\nproblems. However, explaining the unsolvability of planning problems remains a\nlargely open and understudied problem. A widely practiced approach to plan\ngeneration and automated problem solving, in general, is to decompose tasks\ninto sub-problems that help progressively converge towards the goal. In this\npaper, we propose to adopt the same philosophy of sub-problem identification as\na mechanism for analyzing and explaining unsolvability of planning problems in\nhybrid systems. In particular, for a given unsolvable planning problem, we\npropose to identify common waypoints, which are universal obstacles to plan\nexistence; in other words, they appear on every plan from the source to the\nplanning goal. This work envisions such waypoints as sub-problems of the\nplanning problem and the unreachability of any of these waypoints as an\nexplanation for the unsolvability of the original planning problem. We propose\na novel method of waypoint identification by casting the problem as an instance\nof the longest common subsequence problem, a widely popular problem in computer\nscience, typically considered as an illustrative example for the dynamic\nprogramming paradigm. Once the waypoints are identified, we perform symbolic\nreachability analysis on them to identify the earliest unreachable waypoint and\nreport it as the explanation of unsolvability. We present experimental results\non unsolvable planning problems in hybrid domains.",
    "categories": [
      "cs.AI",
      "cs.FL",
      "I.2.0; F.4.3"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15668v1",
    "published_date": "2025-04-22 07:45:30 UTC",
    "updated_date": "2025-04-22 07:45:30 UTC"
  },
  {
    "arxiv_id": "2504.17807v1",
    "title": "Research on Cloud Platform Network Traffic Monitoring and Anomaly Detection System based on Large Language Models",
    "authors": [
      "Ze Yang",
      "Yihong Jin",
      "Juntian Liu",
      "Xinhe Xu",
      "Yihan Zhang",
      "Shuyang Ji"
    ],
    "abstract": "The rapidly evolving cloud platforms and the escalating complexity of network\ntraffic demand proper network traffic monitoring and anomaly detection to\nensure network security and performance. This paper introduces a large language\nmodel (LLM)-based network traffic monitoring and anomaly detection system. In\naddition to existing models such as autoencoders and decision trees, we harness\nthe power of large language models for processing sequence data from network\ntraffic, which allows us a better capture of underlying complex patterns, as\nwell as slight fluctuations in the dataset. We show for a given detection task,\nthe need for a hybrid model that incorporates the attention mechanism of the\ntransformer architecture into a supervised learning framework in order to\nachieve better accuracy. A pre-trained large language model analyzes and\npredicts the probable network traffic, and an anomaly detection layer that\nconsiders temporality and context is added. Moreover, we present a novel\ntransfer learning-based methodology to enhance the model's effectiveness to\nquickly adapt to unknown network structures and adversarial conditions without\nrequiring extensive labeled datasets. Actual results show that the designed\nmodel outperforms traditional methods in detection accuracy and computational\nefficiency, effectively identify various network anomalies such as zero-day\nattacks and traffic congestion pattern, and significantly reduce the false\npositive rate.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NI",
    "comment": "Proceedings of 2025 IEEE 7th International Conference on\n  Communications, Information System and Computer Engineering (CISCE 2025)",
    "pdf_url": "http://arxiv.org/pdf/2504.17807v1",
    "published_date": "2025-04-22 07:42:07 UTC",
    "updated_date": "2025-04-22 07:42:07 UTC"
  },
  {
    "arxiv_id": "2504.15663v1",
    "title": "FADEL: Uncertainty-aware Fake Audio Detection with Evidential Deep Learning",
    "authors": [
      "Ju Yeon Kang",
      "Ji Won Yoon",
      "Semin Kim",
      "Min Hyun Han",
      "Nam Soo Kim"
    ],
    "abstract": "Recently, fake audio detection has gained significant attention, as\nadvancements in speech synthesis and voice conversion have increased the\nvulnerability of automatic speaker verification (ASV) systems to spoofing\nattacks. A key challenge in this task is generalizing models to detect unseen,\nout-of-distribution (OOD) attacks. Although existing approaches have shown\npromising results, they inherently suffer from overconfidence issues due to the\nusage of softmax for classification, which can produce unreliable predictions\nwhen encountering unpredictable spoofing attempts. To deal with this\nlimitation, we propose a novel framework called fake audio detection with\nevidential learning (FADEL). By modeling class probabilities with a Dirichlet\ndistribution, FADEL incorporates model uncertainty into its predictions,\nthereby leading to more robust performance in OOD scenarios. Experimental\nresults on the ASVspoof2019 Logical Access (LA) and ASVspoof2021 LA datasets\nindicate that the proposed method significantly improves the performance of\nbaseline models. Furthermore, we demonstrate the validity of uncertainty\nestimation by analyzing a strong correlation between average uncertainty and\nequal error rate (EER) across different spoofing algorithms.",
    "categories": [
      "eess.AS",
      "cs.AI"
    ],
    "primary_category": "eess.AS",
    "comment": "Accepted at ICASSP 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.15663v1",
    "published_date": "2025-04-22 07:40:35 UTC",
    "updated_date": "2025-04-22 07:40:35 UTC"
  },
  {
    "arxiv_id": "2504.15659v1",
    "title": "VeriCoder: Enhancing LLM-Based RTL Code Generation through Functional Correctness Validation",
    "authors": [
      "Anjiang Wei",
      "Huanmi Tan",
      "Tarun Suresh",
      "Daniel Mendoza",
      "Thiago S. F. X. Teixeira",
      "Ke Wang",
      "Caroline Trippel",
      "Alex Aiken"
    ],
    "abstract": "Recent advances in Large Language Models (LLMs) have sparked growing interest\nin applying them to Electronic Design Automation (EDA) tasks, particularly\nRegister Transfer Level (RTL) code generation. While several RTL datasets have\nbeen introduced, most focus on syntactic validity rather than functional\nvalidation with tests, leading to training examples that compile but may not\nimplement the intended behavior. We present VERICODER, a model for RTL code\ngeneration fine-tuned on a dataset validated for functional correctness. This\nfine-tuning dataset is constructed using a novel methodology that combines unit\ntest generation with feedback-directed refinement. Given a natural language\nspecification and an initial RTL design, we prompt a teacher model\n(GPT-4o-mini) to generate unit tests and iteratively revise the RTL design\nbased on its simulation results using the generated tests. If necessary, the\nteacher model also updates the tests to ensure they comply with the natural\nlanguage specification. As a result of this process, every example in our\ndataset is functionally validated, consisting of a natural language\ndescription, an RTL implementation, and passing tests. Fine-tuned on this\ndataset of over 125,000 examples, VERICODER achieves state-of-the-art metrics\nin functional correctness on VerilogEval and RTLLM, with relative gains of up\nto 71.7% and 27.4% respectively. An ablation study further shows that models\ntrained on our functionally validated dataset outperform those trained on\nfunctionally non-validated datasets, underscoring the importance of\nhigh-quality datasets in RTL code generation.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.SE"
    ],
    "primary_category": "cs.AR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15659v1",
    "published_date": "2025-04-22 07:32:46 UTC",
    "updated_date": "2025-04-22 07:32:46 UTC"
  },
  {
    "arxiv_id": "2504.15654v2",
    "title": "A Vision-Enabled Prosthetic Hand for Children with Upper Limb Disabilities",
    "authors": [
      "Md Abdul Baset Sarker",
      "Art Nguyen",
      "Sigmond Kukla",
      "Kevin Fite",
      "Masudul H. Imtiaz"
    ],
    "abstract": "This paper introduces a novel AI vision-enabled pediatric prosthetic hand\ndesigned to assist children aged 10-12 with upper limb disabilities. The\nprosthesis features an anthropomorphic appearance, multi-articulating\nfunctionality, and a lightweight design that mimics a natural hand, making it\nboth accessible and affordable for low-income families. Using 3D printing\ntechnology and integrating advanced machine vision, sensing, and embedded\ncomputing, the prosthetic hand offers a low-cost, customizable solution that\naddresses the limitations of current myoelectric prostheses. A micro camera is\ninterfaced with a low-power FPGA for real-time object detection and assists\nwith precise grasping. The onboard DL-based object detection and grasp\nclassification models achieved accuracies of 96% and 100% respectively. In the\nforce prediction, the mean absolute error was found to be 0.018. The features\nof the proposed prosthetic hand can thus be summarized as: a) a wrist-mounted\nmicro camera for artificial sensing, enabling a wide range of hand-based tasks;\nb) real-time object detection and distance estimation for precise grasping; and\nc) ultra-low-power operation that delivers high performance within constrained\npower and resource limits.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15654v2",
    "published_date": "2025-04-22 07:23:51 UTC",
    "updated_date": "2025-04-27 15:39:59 UTC"
  },
  {
    "arxiv_id": "2504.15640v1",
    "title": "Cost-Effective Text Clustering with Large Language Models",
    "authors": [
      "Hongtao Wang",
      "Taiyan Zhang",
      "Renchi Yang",
      "Jianliang Xu"
    ],
    "abstract": "Text clustering aims to automatically partition a collection of text\ndocuments into distinct clusters based on linguistic features. In the\nliterature, this task is usually framed as metric clustering based on text\nembeddings from pre-trained encoders or a graph clustering problem upon\npairwise similarities from an oracle, e.g., a large ML model. Recently, large\nlanguage models (LLMs) bring significant advancement in this field by offering\ncontextualized text embeddings and highly accurate similarity scores, but\nmeanwhile, present grand challenges to cope with substantial computational\nand/or financial overhead caused by numerous API-based queries or inference\ncalls to the models.\n  In response, this paper proposes TECL, a cost-effective framework that taps\ninto the feedback from LLMs for accurate text clustering within a limited\nbudget of queries to LLMs. Under the hood, TECL adopts our EdgeLLM or\nTriangleLLM to construct must-link/cannot-link constraints for text pairs, and\nfurther leverages such constraints as supervision signals input to our weighted\nconstrained clustering approach to generate clusters. Particularly, EdgeLLM\n(resp. TriangleLLM) enables the identification of informative text pairs (resp.\ntriplets) for querying LLMs via well-thought-out greedy algorithms and accurate\nextraction of pairwise constraints through carefully-crafted prompting\ntechniques. Our experiments on multiple benchmark datasets exhibit that TECL\nconsistently and considerably outperforms existing solutions in unsupervised\ntext clustering under the same query cost for LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15640v1",
    "published_date": "2025-04-22 06:57:49 UTC",
    "updated_date": "2025-04-22 06:57:49 UTC"
  },
  {
    "arxiv_id": "2504.15637v1",
    "title": "DR.FIX: Automatically Fixing Data Races at Industry Scale",
    "authors": [
      "Farnaz Behrang",
      "Zhizhou Zhang",
      "Georgian-Vlad Saioc",
      "Peng Liu",
      "Milind Chabbi"
    ],
    "abstract": "Data races are a prevalent class of concurrency bugs in shared-memory\nparallel programs, posing significant challenges to software reliability and\nreproducibility. While there is an extensive body of research on detecting data\nraces and a wealth of practical detection tools across various programming\nlanguages, considerably less effort has been directed toward automatically\nfixing data races at an industrial scale. In large codebases, data races are\ncontinuously introduced and exhibit myriad patterns, making automated fixing\nparticularly challenging.\n  In this paper, we tackle the problem of automatically fixing data races at an\nindustrial scale. We present Dr.Fix, a tool that combines large language models\n(LLMs) with program analysis to generate fixes for data races in real-world\nsettings, effectively addressing a broad spectrum of racy patterns in complex\ncode contexts. Implemented for Go--the programming language widely used in\nmodern microservice architectures where concurrency is pervasive and data races\nare common--Dr.Fix seamlessly integrates into existing development workflows.\nWe detail the design of Dr.Fix and examine how individual design choices\ninfluence the quality of the fixes produced. Over the past 18 months, Dr.Fix\nhas been integrated into developer workflows at Uber demonstrating its\npractical utility. During this period, Dr.Fix produced patches for 224 (55%)\nfrom a corpus of 404 data races spanning various categories; 193 of these\npatches (86%) were accepted by more than a hundred developers via code reviews\nand integrated into the codebase.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.LG",
      "cs.PL",
      "cs.SE"
    ],
    "primary_category": "cs.DC",
    "comment": "To appear in PLDI 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.15637v1",
    "published_date": "2025-04-22 06:56:15 UTC",
    "updated_date": "2025-04-22 06:56:15 UTC"
  },
  {
    "arxiv_id": "2504.15634v1",
    "title": "Enhancing Reinforcement learning in 3-Dimensional Hydrophobic-Polar Protein Folding Model with Attention-based layers",
    "authors": [
      "Peizheng Liu",
      "Hitoshi Iba"
    ],
    "abstract": "Transformer-based architectures have recently propelled advances in sequence\nmodeling across domains, but their application to the hydrophobic-hydrophilic\n(H-P) model for protein folding remains relatively unexplored. In this work, we\nadapt a Deep Q-Network (DQN) integrated with attention mechanisms\n(Transformers) to address the 3D H-P protein folding problem. Our system\nformulates folding decisions as a self-avoiding walk in a reinforced\nenvironment, and employs a specialized reward function based on favorable\nhydrophobic interactions. To improve performance, the method incorporates\nvalidity check including symmetry-breaking constraints, dueling and double\nQ-learning, and prioritized replay to focus learning on critical transitions.\nExperimental evaluations on standard benchmark sequences demonstrate that our\napproach achieves several known best solutions for shorter sequences, and\nobtains near-optimal results for longer chains. This study underscores the\npromise of attention-based reinforcement learning for protein folding, and\ncreated a prototype of Transformer-based Q-network structure for 3-dimensional\nlattice models.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15634v1",
    "published_date": "2025-04-22 06:53:36 UTC",
    "updated_date": "2025-04-22 06:53:36 UTC"
  },
  {
    "arxiv_id": "2504.16142v1",
    "title": "A Non-Invasive Load Monitoring Method for Edge Computing Based on MobileNetV3 and Dynamic Time Regulation",
    "authors": [
      "Hangxu Liu",
      "Yaojie Sun",
      "Yu Wang"
    ],
    "abstract": "In recent years, non-intrusive load monitoring (NILM) technology has\nattracted much attention in the related research field by virtue of its unique\nadvantage of utilizing single meter data to achieve accurate decomposition of\ndevice-level energy consumption. Cutting-edge methods based on machine learning\nand deep learning have achieved remarkable results in load decomposition\naccuracy by fusing time-frequency domain features. However, these methods\ngenerally suffer from high computational costs and huge memory requirements,\nwhich become the main obstacles for their deployment on resource-constrained\nmicrocontroller units (MCUs). To address these challenges, this study proposes\nan innovative Dynamic Time Warping (DTW) algorithm in the time-frequency domain\nand systematically compares and analyzes the performance of six machine\nlearning techniques in home electricity scenarios. Through complete\nexperimental validation on edge MCUs, this scheme successfully achieves a\nrecognition accuracy of 95%. Meanwhile, this study deeply optimizes the\nfrequency domain feature extraction process, which effectively reduces the\nrunning time by 55.55% and the storage overhead by about 34.6%. The algorithm\nperformance will be further optimized in future research work. Considering that\nthe elimination of voltage transformer design can significantly reduce the\ncost, the subsequent research will focus on this direction, and is committed to\nproviding more cost-effective solutions for the practical application of NILM,\nand providing a solid theoretical foundation and feasible technical paths for\nthe design of efficient NILM systems in edge computing environments.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16142v1",
    "published_date": "2025-04-22 06:43:33 UTC",
    "updated_date": "2025-04-22 06:43:33 UTC"
  },
  {
    "arxiv_id": "2504.15610v2",
    "title": "A LoRA-Based Approach to Fine-Tuning LLMs for Educational Guidance in Resource-Constrained Settings",
    "authors": [
      "Md Millat Hosen"
    ],
    "abstract": "The current study describes a cost-effective method for adapting large\nlanguage models (LLMs) for academic advising with study-abroad contexts in mind\nand for application in low-resource methods for acculturation. With the\nMistral-7B-Instruct model applied with a Low-Rank Adaptation (LoRA) method and\na 4-bit quantization method, the model underwent training in two distinct\nstages related to this study's purpose to enhance domain specificity while\nmaintaining computational efficiency. In Phase 1, the model was conditioned\nwith a synthetic dataset via the Gemini Pro API, and in Phase 2, it was trained\nwith manually curated datasets from the StudyAbroadGPT project to achieve\nenhanced, contextualized responses. Technical innovations entailed\nmemory-efficient quantization, parameter-efficient adaptation, and continuous\ntraining analytics via Weights & Biases. After training, this study\ndemonstrated a reduction in training loss by 52.7%, 92% accuracy in\ndomain-specific recommendations, achieved 95% markdown-based formatting\nsupport, and a median run-rate of 100 samples per second on off-the-shelf GPU\nequipment. These findings support the effective application of\ninstruction-tuned LLMs within educational advisers, especially in low-resource\ninstitutional scenarios. Limitations included decreased generalizability and\nthe application of a synthetically generated dataset, but this framework is\nscalable for adding new multilingual-augmented and real-time academic advising\nprocesses. Future directions may include plans for the integration of\nretrieval-augmented generation, applying dynamic quantization routines, and\nconnecting to real-time academic databases to increase adaptability and\naccuracy.",
    "categories": [
      "cs.AI",
      "68T05 (Learning and adaptive systems), 68T07 (Artificial\n  intelligence and education)"
    ],
    "primary_category": "cs.AI",
    "comment": "18 pages, 6 figures (3 graphs + 3 flowchart/architecture diagrams),\n  submitted as a preprint for review consideration in AI for Education or\n  Machine Learning applications in low-resource settings. Includes detailed\n  experiments with LoRA and quantization methods for efficient LLM fine-tuning",
    "pdf_url": "http://arxiv.org/pdf/2504.15610v2",
    "published_date": "2025-04-22 06:08:13 UTC",
    "updated_date": "2025-04-23 04:59:47 UTC"
  },
  {
    "arxiv_id": "2504.15604v1",
    "title": "Exploring Next Token Prediction in Theory of Mind (ToM) Tasks: Comparative Experiments with GPT-2 and LLaMA-2 AI Models",
    "authors": [
      "Pavan Yadav",
      "Nikhil Khandalkar",
      "Krishna Shinde",
      "Lokesh B. Ramegowda",
      "Rajarshi Das"
    ],
    "abstract": "Language models have made significant progress in generating coherent text\nand predicting next tokens based on input prompts. This study compares the\nnext-token prediction performance of two well-known models: OpenAI's GPT-2 and\nMeta's Llama-2-7b-chat-hf on Theory of Mind (ToM) tasks. To evaluate their\ncapabilities, we built a dataset from 10 short stories sourced from the Explore\nToM Dataset. We enhanced these stories by programmatically inserting additional\nsentences (infills) using GPT-4, creating variations that introduce different\nlevels of contextual complexity. This setup enables analysis of how increasing\ncontext affects model performance. We tested both models under four temperature\nsettings (0.01, 0.5, 1.0, 2.0) and evaluated their ability to predict the next\ntoken across three reasoning levels. Zero-order reasoning involves tracking the\nstate, either current (ground truth) or past (memory). First-order reasoning\nconcerns understanding another's mental state (e.g., \"Does Anne know the apple\nis salted?\"). Second-order reasoning adds recursion (e.g., \"Does Anne think\nthat Charles knows the apple is salted?\").\n  Our results show that adding more infill sentences slightly reduces\nprediction accuracy, as added context increases complexity and ambiguity.\nLlama-2 consistently outperforms GPT-2 in prediction accuracy, especially at\nlower temperatures, demonstrating greater confidence in selecting the most\nprobable token. As reasoning complexity rises, model responses diverge more.\nNotably, GPT-2 and Llama-2 display greater variability in predictions during\nfirst- and second-order reasoning tasks. These findings illustrate how model\narchitecture, temperature, and contextual complexity influence next-token\nprediction, contributing to a better understanding of the strengths and\nlimitations of current language models.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "75 pages, 60 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.15604v1",
    "published_date": "2025-04-22 05:52:55 UTC",
    "updated_date": "2025-04-22 05:52:55 UTC"
  },
  {
    "arxiv_id": "2504.15587v2",
    "title": "MetaMolGen: A Neural Graph Motif Generation Model for De Novo Molecular Design",
    "authors": [
      "Zimo Yan",
      "Jie Zhang",
      "Zheng Xie",
      "Chang Liu",
      "Yizhen Liu",
      "Yiping Song"
    ],
    "abstract": "Molecular generation plays an important role in drug discovery and materials\nscience, especially in data-scarce scenarios where traditional generative\nmodels often struggle to achieve satisfactory conditional generalization. To\naddress this challenge, we propose MetaMolGen, a first-order\nmeta-learning-based molecular generator designed for few-shot and\nproperty-conditioned molecular generation. MetaMolGen standardizes the\ndistribution of graph motifs by mapping them to a normalized latent space, and\nemploys a lightweight autoregressive sequence model to generate SMILES\nsequences that faithfully reflect the underlying molecular structure. In\naddition, it supports conditional generation of molecules with target\nproperties through a learnable property projector integrated into the\ngenerative process.Experimental results demonstrate that MetaMolGen\nconsistently generates valid and diverse SMILES sequences under low-data\nregimes, outperforming conventional baselines. This highlights its advantage in\nfast adaptation and efficient conditional generation for practical molecular\ndesign.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15587v2",
    "published_date": "2025-04-22 05:04:33 UTC",
    "updated_date": "2025-05-12 13:18:44 UTC"
  },
  {
    "arxiv_id": "2504.15585v2",
    "title": "A Comprehensive Survey in LLM(-Agent) Full Stack Safety: Data, Training and Deployment",
    "authors": [
      "Kun Wang",
      "Guibin Zhang",
      "Zhenhong Zhou",
      "Jiahao Wu",
      "Miao Yu",
      "Shiqian Zhao",
      "Chenlong Yin",
      "Jinhu Fu",
      "Yibo Yan",
      "Hanjun Luo",
      "Liang Lin",
      "Zhihao Xu",
      "Haolang Lu",
      "Xinye Cao",
      "Xinyun Zhou",
      "Weifei Jin",
      "Fanci Meng",
      "Junyuan Mao",
      "Yu Wang",
      "Hao Wu",
      "Minghe Wang",
      "Fan Zhang",
      "Junfeng Fang",
      "Wenjie Qu",
      "Yue Liu",
      "Chengwei Liu",
      "Yifan Zhang",
      "Qiankun Li",
      "Chongye Guo",
      "Yalan Qin",
      "Zhaoxin Fan",
      "Yi Ding",
      "Donghai Hong",
      "Jiaming Ji",
      "Yingxin Lai",
      "Zitong Yu",
      "Xinfeng Li",
      "Yifan Jiang",
      "Yanhui Li",
      "Xinyu Deng",
      "Junlin Wu",
      "Dongxia Wang",
      "Yihao Huang",
      "Yufei Guo",
      "Jen-tse Huang",
      "Qiufeng Wang",
      "Wenxuan Wang",
      "Dongrui Liu",
      "Yanwei Yue",
      "Wenke Huang",
      "Guancheng Wan",
      "Heng Chang",
      "Tianlin Li",
      "Yi Yu",
      "Chenghao Li",
      "Jiawei Li",
      "Lei Bai",
      "Jie Zhang",
      "Qing Guo",
      "Jingyi Wang",
      "Tianlong Chen",
      "Joey Tianyi Zhou",
      "Xiaojun Jia",
      "Weisong Sun",
      "Cong Wu",
      "Jing Chen",
      "Xuming Hu",
      "Yiming Li",
      "Xiao Wang",
      "Ningyu Zhang",
      "Luu Anh Tuan",
      "Guowen Xu",
      "Jiaheng Zhang",
      "Tianwei Zhang",
      "Xingjun Ma",
      "Jindong Gu",
      "Xiang Wang",
      "Bo An",
      "Jun Sun",
      "Mohit Bansal",
      "Shirui Pan",
      "Lingjuan Lyu",
      "Yuval Elovici",
      "Bhavya Kailkhura",
      "Yaodong Yang",
      "Hongwei Li",
      "Wenyuan Xu",
      "Yizhou Sun",
      "Wei Wang",
      "Qing Li",
      "Ke Tang",
      "Yu-Gang Jiang",
      "Felix Juefei-Xu",
      "Hui Xiong",
      "Xiaofeng Wang",
      "Dacheng Tao",
      "Philip S. Yu",
      "Qingsong Wen",
      "Yang Liu"
    ],
    "abstract": "The remarkable success of Large Language Models (LLMs) has illuminated a\npromising pathway toward achieving Artificial General Intelligence for both\nacademic and industrial communities, owing to their unprecedented performance\nacross various applications. As LLMs continue to gain prominence in both\nresearch and commercial domains, their security and safety implications have\nbecome a growing concern, not only for researchers and corporations but also\nfor every nation. Currently, existing surveys on LLM safety primarily focus on\nspecific stages of the LLM lifecycle, e.g., deployment phase or fine-tuning\nphase, lacking a comprehensive understanding of the entire \"lifechain\" of LLMs.\nTo address this gap, this paper introduces, for the first time, the concept of\n\"full-stack\" safety to systematically consider safety issues throughout the\nentire process of LLM training, deployment, and eventual commercialization.\nCompared to the off-the-shelf LLM safety surveys, our work demonstrates several\ndistinctive advantages: (I) Comprehensive Perspective. We define the complete\nLLM lifecycle as encompassing data preparation, pre-training, post-training,\ndeployment and final commercialization. To our knowledge, this represents the\nfirst safety survey to encompass the entire lifecycle of LLMs. (II) Extensive\nLiterature Support. Our research is grounded in an exhaustive review of over\n800+ papers, ensuring comprehensive coverage and systematic organization of\nsecurity issues within a more holistic understanding. (III) Unique Insights.\nThrough systematic literature analysis, we have developed reliable roadmaps and\nperspectives for each chapter. Our work identifies promising research\ndirections, including safety in data generation, alignment techniques, model\nediting, and LLM-based agent systems. These insights provide valuable guidance\nfor researchers pursuing future work in this field.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15585v2",
    "published_date": "2025-04-22 05:02:49 UTC",
    "updated_date": "2025-05-19 09:31:40 UTC"
  },
  {
    "arxiv_id": "2504.15564v1",
    "title": "A Large-scale Class-level Benchmark Dataset for Code Generation with LLMs",
    "authors": [
      "Musfiqur Rahman",
      "SayedHassan Khatoonabadi",
      "Emad Shihab"
    ],
    "abstract": "Recent advancements in large language models (LLMs) have demonstrated\npromising capabilities in code generation tasks. However, most existing\nbenchmarks focus on isolated functions and fail to capture the complexity of\nreal-world, class-level software structures. To address this gap, we introduce\na large-scale, Python class-level dataset curated from $13{,}174$ real-world\nopen-source projects. The dataset contains over 842,000 class skeletons, each\nincluding class and method signatures, along with associated docstrings when\navailable. We preserve structural and contextual dependencies critical to\nrealistic software development scenarios and enrich the dataset with static\ncode metrics to support downstream analysis. To evaluate the usefulness of this\ndataset, we use extracted class skeletons as prompts for GPT-4 to generate full\nclass implementations. Results show that the LLM-generated classes exhibit\nstrong lexical and structural similarity to human-written counterparts, with\naverage ROUGE@L, BLEU, and TSED scores of 0.80, 0.59, and 0.73, respectively.\nThese findings confirm that well-structured prompts derived from real-world\nclass skeletons significantly enhance LLM performance in class-level code\ngeneration. This dataset offers a valuable resource for benchmarking, training,\nand improving LLMs in realistic software engineering contexts.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "This paper was submitted to the 29th International Conference on\n  Evaluation and Assessment in Software Engineering (EASE 2025) AI models/data\n  track",
    "pdf_url": "http://arxiv.org/pdf/2504.15564v1",
    "published_date": "2025-04-22 03:33:57 UTC",
    "updated_date": "2025-04-22 03:33:57 UTC"
  },
  {
    "arxiv_id": "2504.18569v1",
    "title": "Large Language Model Empowered Privacy-Protected Framework for PHI Annotation in Clinical Notes",
    "authors": [
      "Guanchen Wu",
      "Linzhi Zheng",
      "Han Xie",
      "Zhen Xiang",
      "Jiaying Lu",
      "Darren Liu",
      "Delgersuren Bold",
      "Bo Li",
      "Xiao Hu",
      "Carl Yang"
    ],
    "abstract": "The de-identification of private information in medical data is a crucial\nprocess to mitigate the risk of confidentiality breaches, particularly when\npatient personal details are not adequately removed before the release of\nmedical records. Although rule-based and learning-based methods have been\nproposed, they often struggle with limited generalizability and require\nsubstantial amounts of annotated data for effective performance. Recent\nadvancements in large language models (LLMs) have shown significant promise in\naddressing these issues due to their superior language comprehension\ncapabilities. However, LLMs present challenges, including potential privacy\nrisks when using commercial LLM APIs and high computational costs for deploying\nopen-source LLMs locally. In this work, we introduce LPPA, an LLM-empowered\nPrivacy-Protected PHI Annotation framework for clinical notes, targeting the\nEnglish language. By fine-tuning LLMs locally with synthetic notes, LPPA\nensures strong privacy protection and high PHI annotation accuracy. Extensive\nexperiments demonstrate LPPA's effectiveness in accurately de-identifying\nprivate information, offering a scalable and efficient solution for enhancing\npatient privacy protection.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "Shorter version published in MedInfo 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.18569v1",
    "published_date": "2025-04-22 03:18:36 UTC",
    "updated_date": "2025-04-22 03:18:36 UTC"
  },
  {
    "arxiv_id": "2504.15552v1",
    "title": "A Multi-Agent Framework for Automated Qinqiang Opera Script Generation Using Large Language Models",
    "authors": [
      "Gengxian Cao",
      "Fengyuan Li",
      "Hong Duan",
      "Ye Yang",
      "Bofeng Wang",
      "Donghe Li"
    ],
    "abstract": "This paper introduces a novel multi-Agent framework that automates the end to\nend production of Qinqiang opera by integrating Large Language Models , visual\ngeneration, and Text to Speech synthesis. Three specialized agents collaborate\nin sequence: Agent1 uses an LLM to craft coherent, culturally grounded\nscripts;Agent2 employs visual generation models to render contextually accurate\nstage scenes; and Agent3 leverages TTS to produce synchronized, emotionally\nexpressive vocal performances. In a case study on Dou E Yuan, the system\nachieved expert ratings of 3.8 for script fidelity, 3.5 for visual coherence,\nand 3.8 for speech accuracy-culminating in an overall score of 3.6, a 0.3 point\nimprovement over a Single Agent baseline. Ablation experiments demonstrate that\nremoving Agent2 or Agent3 leads to drops of 0.4 and 0.5 points, respectively,\nunderscoring the value of modular collaboration. This work showcases how AI\ndriven pipelines can streamline and scale the preservation of traditional\nperforming arts, and points toward future enhancements in cross modal\nalignment, richer emotional nuance, and support for additional opera genres.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "17 pages,7 figures,1 tables",
    "pdf_url": "http://arxiv.org/pdf/2504.15552v1",
    "published_date": "2025-04-22 03:14:29 UTC",
    "updated_date": "2025-04-22 03:14:29 UTC"
  },
  {
    "arxiv_id": "2504.15549v1",
    "title": "Do It For Me vs. Do It With Me: Investigating User Perceptions of Different Paradigms of Automation in Copilots for Feature-Rich Software",
    "authors": [
      "Anjali Khurana",
      "Xiaotian Su",
      "April Yi Wang",
      "Parmit K Chilana"
    ],
    "abstract": "Large Language Model (LLM)-based in-application assistants, or copilots, can\nautomate software tasks, but users often prefer learning by doing, raising\nquestions about the optimal level of automation for an effective user\nexperience. We investigated two automation paradigms by designing and\nimplementing a fully automated copilot (AutoCopilot) and a semi-automated\ncopilot (GuidedCopilot) that automates trivial steps while offering\nstep-by-step visual guidance. In a user study (N=20) across data analysis and\nvisual design tasks, GuidedCopilot outperformed AutoCopilot in user control,\nsoftware utility, and learnability, especially for exploratory and creative\ntasks, while AutoCopilot saved time for simpler visual tasks. A follow-up\ndesign exploration (N=10) enhanced GuidedCopilot with task-and state-aware\nfeatures, including in-context preview clips and adaptive instructions. Our\nfindings highlight the critical role of user control and tailored guidance in\ndesigning the next generation of copilots that enhance productivity, support\ndiverse skill levels, and foster deeper software engagement.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.HC",
    "comment": "Accepted for publication in the CHI Conference on Human Factors in\n  Computing Systems (CHI 2025), April 26 - May 1, 2025, Yokohama, Japan",
    "pdf_url": "http://arxiv.org/pdf/2504.15549v1",
    "published_date": "2025-04-22 03:11:10 UTC",
    "updated_date": "2025-04-22 03:11:10 UTC"
  },
  {
    "arxiv_id": "2504.15546v2",
    "title": "A Framework for Testing and Adapting REST APIs as LLM Tools",
    "authors": [
      "Jayachandu Bandlamudi",
      "Ritwik Chaudhuri",
      "Neelamadhav Gantayat",
      "Kushal Mukherjee",
      "Prerna Agarwal",
      "Renuka Sindhgatta",
      "Sameep Mehta"
    ],
    "abstract": "Large Language Models (LLMs) are enabling autonomous agents to perform\ncomplex workflows using external tools or functions, often provided via REST\nAPIs in enterprise systems. However, directly utilizing these APIs as tools\nposes challenges due to their complex input schemas, elaborate responses, and\noften ambiguous documentation. Current benchmarks for tool testing do not\nadequately address these complexities, leading to a critical gap in evaluating\nAPI readiness for agent-driven automation. In this work, we present a novel\ntesting framework aimed at evaluating and enhancing the readiness of REST APIs\nto function as tools for LLM-based agents. Our framework transforms apis as\ntools, generates comprehensive test cases for the APIs, translates tests cases\ninto natural language instructions suitable for agents, enriches tool\ndefinitions and evaluates the agent's ability t correctly invoke the API and\nprocess its inputs and responses. To provide actionable insights, we analyze\nthe outcomes of 750 test cases, presenting a detailed taxonomy of errors,\nincluding input misinterpretation, output handling inconsistencies, and schema\nmismatches. Additionally, we classify these test cases to streamline debugging\nand refinement of tool integrations. This work offers a foundational step\ntoward enabling enterprise APIs as tools, improving their usability in\nagent-based applications.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "I.2.7"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15546v2",
    "published_date": "2025-04-22 02:52:08 UTC",
    "updated_date": "2025-05-01 05:50:45 UTC"
  },
  {
    "arxiv_id": "2504.16140v1",
    "title": "SparseJEPA: Sparse Representation Learning of Joint Embedding Predictive Architectures",
    "authors": [
      "Max Hartman",
      "Lav Varshney"
    ],
    "abstract": "Joint Embedding Predictive Architectures (JEPA) have emerged as a powerful\nframework for learning general-purpose representations. However, these models\noften lack interpretability and suffer from inefficiencies due to dense\nembedding representations. We propose SparseJEPA, an extension that integrates\nsparse representation learning into the JEPA framework to enhance the quality\nof learned representations. SparseJEPA employs a penalty method that encourages\nlatent space variables to be shared among data features with strong semantic\nrelationships, while maintaining predictive performance. We demonstrate the\neffectiveness of SparseJEPA by training on the CIFAR-100 dataset and\npre-training a lightweight Vision Transformer. The improved embeddings are\nutilized in linear-probe transfer learning for both image classification and\nlow-level tasks, showcasing the architecture's versatility across different\ntransfer tasks. Furthermore, we provide a theoretical proof that demonstrates\nthat the grouping mechanism enhances representation quality. This was done by\ndisplaying that grouping reduces Multiinformation among latent-variables,\nincluding proofing the Data Processing Inequality for Multiinformation. Our\nresults indicate that incorporating sparsity not only refines the latent space\nbut also facilitates the learning of more meaningful and interpretable\nrepresentations. In further work, hope to further extend this method by finding\nnew ways to leverage the grouping mechanism through object-centric\nrepresentation learning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16140v1",
    "published_date": "2025-04-22 02:43:00 UTC",
    "updated_date": "2025-04-22 02:43:00 UTC"
  },
  {
    "arxiv_id": "2504.21019v1",
    "title": "Kill two birds with one stone: generalized and robust AI-generated text detection via dynamic perturbations",
    "authors": [
      "Yinghan Zhou",
      "Juan Wen",
      "Wanli Peng",
      "Yiming Xue",
      "Ziwei Zhang",
      "Zhengxian Wu"
    ],
    "abstract": "The growing popularity of large language models has raised concerns regarding\nthe potential to misuse AI-generated text (AIGT). It becomes increasingly\ncritical to establish an excellent AIGT detection method with high\ngeneralization and robustness. However, existing methods either focus on model\ngeneralization or concentrate on robustness. The unified mechanism, to\nsimultaneously address the challenges of generalization and robustness, is less\nexplored. In this paper, we argue that robustness can be view as a specific\nform of domain shift, and empirically reveal an intrinsic mechanism for model\ngeneralization of AIGT detection task. Then, we proposed a novel AIGT detection\nmethod (DP-Net) via dynamic perturbations introduced by a reinforcement\nlearning with elaborated reward and action. Experimentally, extensive results\nshow that the proposed DP-Net significantly outperforms some state-of-the-art\nAIGT detection methods for generalization capacity in three cross-domain\nscenarios. Meanwhile, the DP-Net achieves best robustness under two text\nadversarial attacks. The code is publicly available at\nhttps://github.com/CAU-ISS-Lab/AIGT-Detection-Evade-Detection/tree/main/DP-Net.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by NAACL 2025 main conference",
    "pdf_url": "http://arxiv.org/pdf/2504.21019v1",
    "published_date": "2025-04-22 02:21:19 UTC",
    "updated_date": "2025-04-22 02:21:19 UTC"
  },
  {
    "arxiv_id": "2504.15524v1",
    "title": "IPBench: Benchmarking the Knowledge of Large Language Models in Intellectual Property",
    "authors": [
      "Qiyao Wang",
      "Guhong Chen",
      "Hongbo Wang",
      "Huaren Liu",
      "Minghui Zhu",
      "Zhifei Qin",
      "Linwei Li",
      "Yilin Yue",
      "Shiqiang Wang",
      "Jiayan Li",
      "Yihang Wu",
      "Ziqiang Liu",
      "Longze Chen",
      "Run Luo",
      "Liyang Fan",
      "Jiaming Li",
      "Lei Zhang",
      "Kan Xu",
      "Hongfei Lin",
      "Hamid Alinejad-Rokny",
      "Shiwen Ni",
      "Yuan Lin",
      "Min Yang"
    ],
    "abstract": "Intellectual Property (IP) is a unique domain that integrates technical and\nlegal knowledge, making it inherently complex and knowledge-intensive. As large\nlanguage models (LLMs) continue to advance, they show great potential for\nprocessing IP tasks, enabling more efficient analysis, understanding, and\ngeneration of IP-related content. However, existing datasets and benchmarks\neither focus narrowly on patents or cover limited aspects of the IP field,\nlacking alignment with real-world scenarios. To bridge this gap, we introduce\nthe first comprehensive IP task taxonomy and a large, diverse bilingual\nbenchmark, IPBench, covering 8 IP mechanisms and 20 tasks. This benchmark is\ndesigned to evaluate LLMs in real-world intellectual property applications,\nencompassing both understanding and generation. We benchmark 16 LLMs, ranging\nfrom general-purpose to domain-specific models, and find that even the\nbest-performing model achieves only 75.8% accuracy, revealing substantial room\nfor improvement. Notably, open-source IP and law-oriented models lag behind\nclosed-source general-purpose models. We publicly release all data and code of\nIPBench and will continue to update it with additional IP-related tasks to\nbetter reflect real-world challenges in the intellectual property domain.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "89 pages, 75 figures, 55 tables",
    "pdf_url": "http://arxiv.org/pdf/2504.15524v1",
    "published_date": "2025-04-22 02:00:41 UTC",
    "updated_date": "2025-04-22 02:00:41 UTC"
  },
  {
    "arxiv_id": "2504.15515v2",
    "title": "Transport f divergences",
    "authors": [
      "Wuchen Li"
    ],
    "abstract": "We define a class of divergences to measure differences between probability\ndensity functions in one-dimensional sample space. The construction is based on\nthe convex function with the Jacobi operator of mapping function that\npushforwards one density to the other. We call these information measures\ntransport f-divergences. We present several properties of transport\n$f$-divergences, including invariances, convexities, variational formulations,\nand Taylor expansions in terms of mapping functions. Examples of transport\nf-divergences in generative models are provided.",
    "categories": [
      "math.ST",
      "cs.AI",
      "cs.IT",
      "math.IT",
      "stat.TH"
    ],
    "primary_category": "math.ST",
    "comment": "Comments are welcome",
    "pdf_url": "http://arxiv.org/pdf/2504.15515v2",
    "published_date": "2025-04-22 01:25:41 UTC",
    "updated_date": "2025-04-23 01:18:37 UTC"
  },
  {
    "arxiv_id": "2504.16139v1",
    "title": "Enhancing Trust Through Standards: A Comparative Risk-Impact Framework for Aligning ISO AI Standards with Global Ethical and Regulatory Contexts",
    "authors": [
      "Sridharan Sankaran"
    ],
    "abstract": "As artificial intelligence (AI) reshapes industries and societies, ensuring\nits trustworthiness-through mitigating ethical risks like bias, opacity, and\naccountability deficits-remains a global challenge. International Organization\nfor Standardization (ISO) AI standards, such as ISO/IEC 24027 and 24368, aim to\nfoster responsible development by embedding fairness, transparency, and risk\nmanagement into AI systems. However, their effectiveness varies across diverse\nregulatory landscapes, from the EU's risk-based AI Act to China's\nstability-focused measures and the U.S.'s fragmented state-led initiatives.\nThis paper introduces a novel Comparative Risk-Impact Assessment Framework to\nevaluate how well ISO standards address ethical risks within these contexts,\nproposing enhancements to strengthen their global applicability. By mapping ISO\nstandards to the EU AI Act and surveying regulatory frameworks in ten\nregions-including the UK, Canada, India, Japan, Singapore, South Korea, and\nBrazil-we establish a baseline for ethical alignment. The framework, applied to\ncase studies in the EU, US-Colorado, and China, reveals gaps: voluntary ISO\nstandards falter in enforcement (e.g., Colorado) and undervalue region-specific\nrisks like privacy (China). We recommend mandatory risk audits, region-specific\nannexes, and a privacy-focused module to enhance ISO's adaptability. This\napproach not only synthesizes global trends but also offers a replicable tool\nfor aligning standardization with ethical imperatives, fostering\ninteroperability and trust in AI worldwide. Policymakers and standards bodies\ncan leverage these insights to evolve AI governance, ensuring it meets diverse\nsocietal needs as the technology advances.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16139v1",
    "published_date": "2025-04-22 00:44:20 UTC",
    "updated_date": "2025-04-22 00:44:20 UTC"
  },
  {
    "arxiv_id": "2504.15499v1",
    "title": "Guillotine: Hypervisors for Isolating Malicious AIs",
    "authors": [
      "James Mickens",
      "Sarah Radway",
      "Ravi Netravali"
    ],
    "abstract": "As AI models become more embedded in critical sectors like finance,\nhealthcare, and the military, their inscrutable behavior poses ever-greater\nrisks to society. To mitigate this risk, we propose Guillotine, a hypervisor\narchitecture for sandboxing powerful AI models -- models that, by accident or\nmalice, can generate existential threats to humanity. Although Guillotine\nborrows some well-known virtualization techniques, Guillotine must also\nintroduce fundamentally new isolation mechanisms to handle the unique threat\nmodel posed by existential-risk AIs. For example, a rogue AI may try to\nintrospect upon hypervisor software or the underlying hardware substrate to\nenable later subversion of that control plane; thus, a Guillotine hypervisor\nrequires careful co-design of the hypervisor software and the CPUs, RAM, NIC,\nand storage devices that support the hypervisor software, to thwart side\nchannel leakage and more generally eliminate mechanisms for AI to exploit\nreflection-based vulnerabilities. Beyond such isolation at the software,\nnetwork, and microarchitectural layers, a Guillotine hypervisor must also\nprovide physical fail-safes more commonly associated with nuclear power plants,\navionic platforms, and other types of mission critical systems. Physical\nfail-safes, e.g., involving electromechanical disconnection of network cables,\nor the flooding of a datacenter which holds a rogue AI, provide defense in\ndepth if software, network, and microarchitectural isolation is compromised and\na rogue AI must be temporarily shut down or permanently destroyed.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.OS"
    ],
    "primary_category": "cs.CR",
    "comment": "To be published in the ACM SIGOPS 2025 Workshop on Hot Topics in\n  Operating Systems",
    "pdf_url": "http://arxiv.org/pdf/2504.15499v1",
    "published_date": "2025-04-22 00:29:18 UTC",
    "updated_date": "2025-04-22 00:29:18 UTC"
  },
  {
    "arxiv_id": "2504.15497v1",
    "title": "Scalable APT Malware Classification via Parallel Feature Extraction and GPU-Accelerated Learning",
    "authors": [
      "Noah Subedar",
      "Taeui Kim",
      "Saathwick Venkataramalingam"
    ],
    "abstract": "This paper presents an underlying framework for both automating and\naccelerating malware classification, more specifically, mapping malicious\nexecutables to known Advanced Persistent Threat (APT) groups. The main feature\nof this analysis is the assembly-level instructions present in executables\nwhich are also known as opcodes. The collection of such opcodes on many\nmalicious samples is a lengthy process; hence, open-source reverse engineering\ntools are used in tandem with scripts that leverage parallel computing to\nanalyze multiple files at once. Traditional and deep learning models are\napplied to create models capable of classifying malware samples. One-gram and\ntwo-gram datasets are constructed and used to train models such as SVM, KNN,\nand Decision Tree; however, they struggle to provide adequate results without\nrelying on metadata to support n-gram sequences. The computational limitations\nof such models are overcome with convolutional neural networks (CNNs) and\nheavily accelerated using graphical compute unit (GPU) resources.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "I.2.0; I.2.6; K.6.5"
    ],
    "primary_category": "cs.CR",
    "comment": "26 pages, 54 figures, 14 tables",
    "pdf_url": "http://arxiv.org/pdf/2504.15497v1",
    "published_date": "2025-04-22 00:05:05 UTC",
    "updated_date": "2025-04-22 00:05:05 UTC"
  }
]