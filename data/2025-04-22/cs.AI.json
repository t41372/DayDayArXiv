{
  "date": "2025-04-22",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-04-22 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦 AI 安全、LLM 在医疗和决策中的应用、序列模型优化以及视觉语言模型的创新进展，重点包括 LLM 在临床决策中的偏见分析和量子 Transformer 的性能提升；令人印象深刻的文章有“Describe Anything”在多模态任务中的突破，以及“LongMamba”对长序列处理的优化；这些论文突显了 AI 模型的鲁棒性和实际应用潜力。\n\n下面，我挑选了部分重要、话题度高的论文进行简要讨论，先聊核心贡献大的，再快速掠过其他。每个条目列出论文标题（中文 + 英文），并保留关键学术术语，突出主要贡献和发现。\n\n**1. 调查 LLM 在临床分诊中的能力：LLM 的鲁棒性、偏见分析和性能评估 (Investigating LLMs in Clinical Triage)**  \n这篇论文探讨了大型语言模型（LLMs）在紧急分诊中的应用，评估了其对分布偏移和缺失数据的鲁棒性，以及性别和种族的交叉偏见。主要贡献是通过对比 LLMs 和机器学习方法，发现 LLMs 在处理临床数据时更具鲁棒性，但存在特定交叉偏见（如性别差异在某些种族中更明显），这为医疗 AI 的公平性提供了重要启示。\n\n**2. DataS^3：针对专业化的数据集子集选择 (DataS^3: Dataset Subset Selection for Specialization)**  \n作者包括多名知名学者，如 Daniela Rus 和 Ken Goldberg。该论文提出了一种新框架，用于从一般分布数据中选择子集以优化部署性能。主要发现是，传统方法在部署特定任务中失败，而手动 curation 的子集可提升准确率高达 51.3%，强调了数据集 curation 在实际机器学习应用中的关键作用。\n\n**3. 描述任意事物：详细的局部图像和视频标题生成 (Describe Anything: Detailed Localized Image and Video Captioning)**  \n这篇论文引入了 Describe Anything Model (DAM)，用于生成详细的局部标题。主要贡献是通过 focal prompt 和 localized vision backbone 提升图像和视频的局部细节捕捉，发现 DAM 在多个基准上超越了现有方法，如在图像标题任务中提升了 14.91% 的 mIoU，展示了视觉语言模型在多任务中的潜力。\n\n**4. LongMamba：通过无训练感受野扩展提升 Mamba 的长序列能力 (LongMamba: Enhancing Mamba's Long Context Capabilities via Training-Free Receptive Field Enlargement)**  \n论文提出 LongMamba 方法，用于提升状态空间模型（SSMs）如 Mamba 在长序列任务中的性能。主要发现是通过识别全局通道并应用 token filtering，实现了无训练扩展，显著提升了长序列基准的性能，如在合成任务中超越传统方法，强调了高效序列建模的实用性。\n\n**5. 量子双重随机 Transformer (Quantum Doubly Stochastic Transformers)**  \n作者包括 Jannis Born，该论文探索了量子电路在 Transformer 中的应用。主要贡献是替换 Softmax 为变分量子电路，生成更丰富的双重随机矩阵（DSMs），发现这提升了小规模对象识别任务的性能，并改善了训练稳定性，展示了量子计算与 AI 的融合潜力。\n\n**6. 通用逼近性质的 Softmax Attention (Universal Approximation with Softmax Attention)**  \n论文证明了 Softmax Attention 在序列到序列函数中的通用逼近能力。主要发现是，两层自注意力机制可以逼近连续函数，并通过插值方法分析了其内部机制，这为 Transformer 架构提供了理论基础，扩展了其在建模中的应用。\n\n**7. IPBench：评估 LLM 在知识产权领域的知识基准 (IPBench: Benchmarking the Knowledge of Large Language Models in Intellectual Property)**  \n这篇论文构建了首个全面的知识产权任务基准数据集。主要贡献是覆盖 8 个 IP 机制和 20 个任务，发现现有 LLM 在知识产权推理中准确率仅 75.8%，并公开了数据集，突显了 LLM 在专业领域知识的局限性。\n\n**8. 消除两全其美：通过动态扰动提升 AI 生成文本检测的泛化和鲁棒性 (Kill two birds with one stone: generalized and robust AI-generated text detection via dynamic perturbations)**  \n论文提出 DP-Net 方法，用于检测 AI 生成文本。主要发现是通过强化学习引入动态扰动，提升了检测的泛化和鲁棒性，在跨域场景中准确率提高至 94.58%，为对抗文本检测提供了新框架。\n\n其他论文中，如“Scalable APT Malware Classification via Parallel Feature Extraction and GPU-Accelerated Learning”（可扩展的 APT 恶意软件分类，通过并行特征提取和 GPU 加速），主要贡献是优化了恶意软件分类的效率，但相对常规；“TrustGeoGen”（可信几何问题生成）则在 AI 验证中创新，但影响力较小，故快速掠过。总体上，今天的论文强调了 AI 的安全性和实际应用，读者可关注 LLM 在医疗和量子领域的进展。更多细节请查阅 arXiv！",
  "papers": [
    {
      "arxiv_id": "2504.16316v1",
      "title": "On the Consistency of GNN Explanations for Malware Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Hossein Shokouhinejad",
        "Griffin Higgins",
        "Roozbeh Razavi-Far",
        "Hesamodin Mohammadian",
        "Ali A. Ghorbani"
      ],
      "abstract": "Control Flow Graphs (CFGs) are critical for analyzing program execution and\ncharacterizing malware behavior. With the growing adoption of Graph Neural\nNetworks (GNNs), CFG-based representations have proven highly effective for\nmalware detection. This study proposes a novel framework that dynamically\nconstructs CFGs and embeds node features using a hybrid approach combining\nrule-based encoding and autoencoder-based embedding. A GNN-based classifier is\nthen constructed to detect malicious behavior from the resulting graph\nrepresentations. To improve model interpretability, we apply state-of-the-art\nexplainability techniques, including GNNExplainer, PGExplainer, and\nCaptumExplainer, the latter is utilized three attribution methods: Integrated\nGradients, Guided Backpropagation, and Saliency. In addition, we introduce a\nnovel aggregation method, called RankFusion, that integrates the outputs of the\ntop-performing explainers to enhance the explanation quality. We also evaluate\nexplanations using two subgraph extraction strategies, including the proposed\nGreedy Edge-wise Composition (GEC) method for improved structural coherence. A\ncomprehensive evaluation using accuracy, fidelity, and consistency metrics\ndemonstrates the effectiveness of the proposed framework in terms of accurate\nidentification of malware samples and generating reliable and interpretable\nexplanations.",
      "tldr_zh": "本研究提出一个新框架，用于评估Graph Neural Networks (GNNs)在恶意软件检测中的解释一致性，该框架基于Control Flow Graphs (CFGs)动态构建图形，并采用混合方法结合rule-based encoding和autoencoder-based embedding来嵌入节点特征。GNN-based分类器随后用于识别恶意行为，并通过GNNExplainer、PGExplainer和CaptumExplainer（包括Integrated Gradients、Guided Backpropagation和Saliency）等技术提升模型可解释性，同时引入新聚合方法RankFusion和子图提取策略如Greedy Edge-wise Composition (GEC)来优化解释质量。实验结果显示，该框架在准确率、fidelity和consistency指标上表现出色，能够更准确地识别恶意软件样本并生成可靠的解释。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.16316v1",
      "published_date": "2025-04-22 23:25:12 UTC",
      "updated_date": "2025-04-22 23:25:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:28:04.449170"
    },
    {
      "arxiv_id": "2504.16277v1",
      "title": "DataS^3: Dataset Subset Selection for Specialization",
      "title_zh": "DataS^3：用于专业化的数据集子集选择",
      "authors": [
        "Neha Hulkund",
        "Alaa Maalouf",
        "Levi Cai",
        "Daniel Yang",
        "Tsun-Hsuan Wang",
        "Abigail O'Neil",
        "Timm Haucke",
        "Sandeep Mukherjee",
        "Vikram Ramaswamy",
        "Judy Hansen Shen",
        "Gabriel Tseng",
        "Mike Walmsley",
        "Daniela Rus",
        "Ken Goldberg",
        "Hannah Kerner",
        "Irene Chen",
        "Yogesh Girdhar",
        "Sara Beery"
      ],
      "abstract": "In many real-world machine learning (ML) applications (e.g. detecting broken\nbones in x-ray images, detecting species in camera traps), in practice models\nneed to perform well on specific deployments (e.g. a specific hospital, a\nspecific national park) rather than the domain broadly. However, deployments\noften have imbalanced, unique data distributions. Discrepancy between the\ntraining distribution and the deployment distribution can lead to suboptimal\nperformance, highlighting the need to select deployment-specialized subsets\nfrom the available training data. We formalize dataset subset selection for\nspecialization (DS3): given a training set drawn from a general distribution\nand a (potentially unlabeled) query set drawn from the desired\ndeployment-specific distribution, the goal is to select a subset of the\ntraining data that optimizes deployment performance.\n  We introduce DataS^3; the first dataset and benchmark designed specifically\nfor the DS3 problem. DataS^3 encompasses diverse real-world application\ndomains, each with a set of distinct deployments to specialize in. We conduct a\ncomprehensive study evaluating algorithms from various families--including\ncoresets, data filtering, and data curation--on DataS^3, and find that\ngeneral-distribution methods consistently fail on deployment-specific tasks.\nAdditionally, we demonstrate the existence of manually curated\n(deployment-specific) expert subsets that outperform training on all available\ndata with accuracy gains up to 51.3 percent. Our benchmark highlights the\ncritical role of tailored dataset curation in enhancing performance and\ntraining efficiency on deployment-specific distributions, which we posit will\nonly become more important as global, public datasets become available across\ndomains and ML models are deployed in the real world.",
      "tldr_zh": "本论文正式化了数据集子集选择问题（DS3），即从一般分布的训练数据中选择子集，以优化机器学习模型在特定部署（如特定医院或国家公园）的性能，解决数据分布不平衡和差异带来的子优表现。作者引入了首个针对 DS3 的数据集和基准 DataS^3，涵盖多样真实应用领域，并评估了 coresets、data filtering 和 data curation 等算法家族。研究发现，一般分布方法在部署特定任务上表现不佳，而手动 curation 的专家子集可将准确率提高高达 51.3%，显著提升性能和训练效率。该工作强调了定制数据集 curation 在实际部署中的关键作用，随着全球数据集的可用性增加，这一问题将愈发重要。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.16277v1",
      "published_date": "2025-04-22 21:25:14 UTC",
      "updated_date": "2025-04-22 21:25:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:28:18.447511"
    },
    {
      "arxiv_id": "2504.16276v2",
      "title": "An Automated Pipeline for Few-Shot Bird Call Classification: A Case Study with the Tooth-Billed Pigeon",
      "title_zh": "翻译失败",
      "authors": [
        "Abhishek Jana",
        "Moeumu Uili",
        "James Atherton",
        "Mark O'Brien",
        "Joe Wood",
        "Leandra Brickson"
      ],
      "abstract": "This paper presents an automated one-shot bird call classification pipeline\ndesigned for rare species absent from large publicly available classifiers like\nBirdNET and Perch. While these models excel at detecting common birds with\nabundant training data, they lack options for species with only 1-3 known\nrecordings-a critical limitation for conservationists monitoring the last\nremaining individuals of endangered birds. To address this, we leverage the\nembedding space of large bird classification networks and develop a classifier\nusing cosine similarity, combined with filtering and denoising preprocessing\ntechniques, to optimize detection with minimal training data. We evaluate\nvarious embedding spaces using clustering metrics and validate our approach in\nboth a simulated scenario with Xeno-Canto recordings and a real-world test on\nthe critically endangered tooth-billed pigeon (Didunculus strigirostris), which\nhas no existing classifiers and only three confirmed recordings. The final\nmodel achieved 1.0 recall and 0.95 accuracy in detecting tooth-billed pigeon\ncalls, making it practical for use in the field. This open-source system\nprovides a practical tool for conservationists seeking to detect and monitor\nrare species on the brink of extinction.",
      "tldr_zh": "本论文提出了一种自动化 one-shot 鸟叫分类管道，针对大型公共分类器（如 BirdNET 和 Perch）中缺失的稀有物种，帮助保护者监测仅有1-3个录音的濒危鸟类。该方法利用大型鸟类分类网络的 embedding space 结合余弦相似度分类器，并融入过滤和去噪预处理技术，以最小训练数据实现高效检测。在模拟场景和真实测试中，该管道对濒危齿喙鸽（Didunculus strigirostris）的叫声达到了1.0召回率和0.95准确率，为开源工具提供实用解决方案，支持稀有物种的监测和保护。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.SD"
      ],
      "primary_category": "cs.LG",
      "comment": "16 pages, 5 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2504.16276v2",
      "published_date": "2025-04-22 21:21:41 UTC",
      "updated_date": "2025-05-02 17:04:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:28:28.879421"
    },
    {
      "arxiv_id": "2504.16275v1",
      "title": "Quantum Doubly Stochastic Transformers",
      "title_zh": "量子双重随机 Transformer",
      "authors": [
        "Jannis Born",
        "Filip Skogh",
        "Kahn Rhrissorrakrai",
        "Filippo Utro",
        "Nico Wagner",
        "Aleksandros Sobczyk"
      ],
      "abstract": "At the core of the Transformer, the Softmax normalizes the attention matrix\nto be right stochastic. Previous research has shown that this often\ndestabilizes training and that enforcing the attention matrix to be doubly\nstochastic (through Sinkhorn's algorithm) consistently improves performance\nacross different tasks, domains and Transformer flavors. However, Sinkhorn's\nalgorithm is iterative, approximative, non-parametric and thus inflexible\nw.r.t. the obtained doubly stochastic matrix (DSM). Recently, it has been\nproven that DSMs can be obtained with a parametric quantum circuit, yielding a\nnovel quantum inductive bias for DSMs with no known classical analogue.\nMotivated by this, we demonstrate the feasibility of a hybrid classical-quantum\ndoubly stochastic Transformer (QDSFormer) that replaces the Softmax in the\nself-attention layer with a variational quantum circuit. We study the\nexpressive power of the circuit and find that it yields more diverse DSMs that\nbetter preserve information than classical operators. Across multiple\nsmall-scale object recognition tasks, we find that our QDSFormer consistently\nsurpasses both a standard Vision Transformer and other doubly stochastic\nTransformers. Beyond the established Sinkformer, this comparison includes a\nnovel quantum-inspired doubly stochastic Transformer (based on QR\ndecomposition) that can be of independent interest. The QDSFormer also shows\nimproved training stability and lower performance variation suggesting that it\nmay mitigate the notoriously unstable training of ViTs on small-scale data.",
      "tldr_zh": "本研究提出了一种混合经典-量子框架 Quantum Doubly Stochastic Transformers (QDSFormer)，通过变分量子电路替换 Transformer 中 Softmax，以生成双随机矩阵 (DSMs)，从而解决注意力矩阵训练不稳定的问题。该方法利用量子电路的表达能力，产生更多样化的 DSMs 并更好地保留信息，比传统 Sinkhorn's algorithm 更灵活高效。在小规模物体识别任务上，QDSFormer 超过了标准 Vision Transformer (ViTs) 和其他双随机 Transformer，包括一个基于 QR decomposition 的新量子启发模型。实验结果显示，QDSFormer 显著提升了性能、训练稳定性和鲁棒性，为量子归纳偏差在 Transformer 架构中的应用提供了新见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Under Review",
      "pdf_url": "http://arxiv.org/pdf/2504.16275v1",
      "published_date": "2025-04-22 21:15:45 UTC",
      "updated_date": "2025-04-22 21:15:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:28:40.343991"
    },
    {
      "arxiv_id": "2504.16273v1",
      "title": "Investigating LLMs in Clinical Triage: Promising Capabilities, Persistent Intersectional Biases",
      "title_zh": "翻译失败",
      "authors": [
        "Joseph Lee",
        "Tianqi Shang",
        "Jae Young Baik",
        "Duy Duong-Tran",
        "Shu Yang",
        "Lingyao Li",
        "Li Shen"
      ],
      "abstract": "Large Language Models (LLMs) have shown promise in clinical decision support,\nyet their application to triage remains underexplored. We systematically\ninvestigate the capabilities of LLMs in emergency department triage through two\nkey dimensions: (1) robustness to distribution shifts and missing data, and (2)\ncounterfactual analysis of intersectional biases across sex and race. We assess\nmultiple LLM-based approaches, ranging from continued pre-training to\nin-context learning, as well as machine learning approaches. Our results\nindicate that LLMs exhibit superior robustness, and we investigate the key\nfactors contributing to the promising LLM-based approaches. Furthermore, in\nthis setting, we identify gaps in LLM preferences that emerge in particular\nintersections of sex and race. LLMs generally exhibit sex-based differences,\nbut they are most pronounced in certain racial groups. These findings suggest\nthat LLMs encode demographic preferences that may emerge in specific clinical\ncontexts or particular combinations of characteristics.",
      "tldr_zh": "本文系统调查了 LLMs 在紧急部门分诊中的能力，重点评估其对分布偏移和缺失数据的鲁棒性，以及性别和种族的交叉偏见(counterfactual analysis)。研究比较了多种 LLM 方法，包括继续预训练和 in-context learning，与传统机器学习方法，结果显示 LLMs 表现出更高的鲁棒性，并识别了关键影响因素。值得注意的是，LLMs 存在性别差异，且这些偏见在特定种族群体中更为明显，揭示了 LLMs 可能编码的人口统计偏好，可能在临床环境中显现。总体而言，此研究强调了 LLMs 在临床决策支持中的潜力，同时警示了持久的 intersectional biases。",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to GenAI4Health Workshop @ AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.16273v1",
      "published_date": "2025-04-22 21:11:47 UTC",
      "updated_date": "2025-04-22 21:11:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:28:52.266278"
    },
    {
      "arxiv_id": "2504.16268v2",
      "title": "Boosting KNNClassifier Performance with Opposition-Based Data Transformation",
      "title_zh": "翻译失败",
      "authors": [
        "Abdesslem Layeb"
      ],
      "abstract": "In this paper, we introduce a novel data transformation framework based on\nOpposition-Based Learning (OBL) to boost the performance of traditional\nclassification algorithms. Originally developed to accelerate convergence in\noptimization tasks, OBL is leveraged here to generate synthetic opposite\nsamples that enrich the training data and improve decision boundary formation.\nWe explore three OBL variants Global OBL, Class-Wise OBL, and Localized\nClass-Wise OBL and integrate them with K-Nearest Neighbors (KNN). Extensive\nexperiments conducted on 26 heterogeneous and high-dimensional datasets\ndemonstrate that OBL-enhanced classifiers consistently outperform the basic\nKNN. These findings underscore the potential of OBL as a lightweight yet\npowerful data transformation strategy for enhancing classification performance,\nespecially in complex or sparse learning environments.",
      "tldr_zh": "本研究提出了一种基于 Opposition-Based Learning (OBL) 的新型数据转换框架，用于提升传统分类算法的性能。具体来说，该框架通过生成合成对立样本来丰富训练数据并优化决策边界，探索了三种 OBL 变体（Global OBL、Class-Wise OBL 和 Localized Class-Wise OBL），并将其与 K-Nearest Neighbors (KNN) 分类器集成。在 26 个异构和高维数据集上的广泛实验显示，OBL 增强的 KNN 分类器在性能上 consistently 优于基本 KNN，平均准确率显著提升。该方法作为一种轻量级策略，展示了在复杂或稀疏学习环境中的强大潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.16268v2",
      "published_date": "2025-04-22 21:03:31 UTC",
      "updated_date": "2025-04-25 08:27:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:29:03.848202"
    },
    {
      "arxiv_id": "2504.16263v1",
      "title": "Gradient-Optimized Fuzzy Classifier: A Benchmark Study Against State-of-the-Art Models",
      "title_zh": "梯度优化的模糊分类器：针对最先进模型的基准研究",
      "authors": [
        "Magnus Sieverding",
        "Nathan Steffen",
        "Kelly Cohen"
      ],
      "abstract": "This paper presents a performance benchmarking study of a Gradient-Optimized\nFuzzy Inference System (GF) classifier against several state-of-the-art machine\nlearning models, including Random Forest, XGBoost, Logistic Regression, Support\nVector Machines, and Neural Networks. The evaluation was conducted across five\ndatasets from the UCI Machine Learning Repository, each chosen for their\ndiversity in input types, class distributions, and classification complexity.\nUnlike traditional Fuzzy Inference Systems that rely on derivative-free\noptimization methods, the GF leverages gradient descent to significantly\nimproving training efficiency and predictive performance. Results demonstrate\nthat the GF model achieved competitive, and in several cases superior,\nclassification accuracy while maintaining high precision and exceptionally low\ntraining times. In particular, the GF exhibited strong consistency across folds\nand datasets, underscoring its robustness in handling noisy data and variable\nfeature sets. These findings support the potential of gradient optimized fuzzy\nsystems as interpretable, efficient, and adaptable alternatives to more complex\ndeep learning models in supervised learning tasks.",
      "tldr_zh": "本研究对 Gradient-Optimized Fuzzy Inference System (GF) 分类器进行了基准测试，与 Random Forest、XGBoost、Logistic Regression、Support Vector Machines 和 Neural Networks 等状态艺术模型进行比较。实验使用 UCI Machine Learning Repository 的五个多样化数据集，评估了不同输入类型、类分布和分类复杂度的性能；GF 通过 gradient descent 优化，显著提升了训练效率和预测准确率。结果显示，GF 在多个数据集上实现了竞争性甚至更高的分类准确率和高精度，同时保持极低的训练时间，并展示了在处理噪声数据和可变特征集时的鲁棒性。这些发现突显了 gradient optimized fuzzy systems 作为可解释、高效替代方案的潜力，在监督学习任务中具有重要应用价值。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.16263v1",
      "published_date": "2025-04-22 20:47:06 UTC",
      "updated_date": "2025-04-22 20:47:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:29:15.380438"
    },
    {
      "arxiv_id": "2504.21022v1",
      "title": "ConformalNL2LTL: Translating Natural Language Instructions into Temporal Logic Formulas with Conformal Correctness Guarantees",
      "title_zh": "ConformalNL2LTL：将自然语言指令翻译成时序逻辑公式并提供保形正确性保证",
      "authors": [
        "Jun Wang",
        "David Smith Sundarsingh",
        "Jyotirmoy V. Deshmukh",
        "Yiannis Kantaros"
      ],
      "abstract": "Linear Temporal Logic (LTL) has become a prevalent specification language for\nrobotic tasks. To mitigate the significant manual effort and expertise required\nto define LTL-encoded tasks, several methods have been proposed for translating\nNatural Language (NL) instructions into LTL formulas, which, however, lack\ncorrectness guarantees. To address this, we introduce a new NL-to-LTL\ntranslation method, called ConformalNL2LTL, that can achieve user-defined\ntranslation success rates over unseen NL commands. Our method constructs LTL\nformulas iteratively by addressing a sequence of open-vocabulary\nQuestion-Answering (QA) problems with LLMs. To enable uncertainty-aware\ntranslation, we leverage conformal prediction (CP), a distribution-free\nuncertainty quantification tool for black-box models. CP enables our method to\nassess the uncertainty in LLM-generated answers, allowing it to proceed with\ntranslation when sufficiently confident and request help otherwise. We provide\nboth theoretical and empirical results demonstrating that ConformalNL2LTL\nachieves user-specified translation accuracy while minimizing help rates.",
      "tldr_zh": "这篇论文提出了 ConformalNL2LTL 方法，用于将自然语言 (NL) 指令翻译成线性时序逻辑 (LTL) 公式，同时提供用户定义的正确性保证，以解决现有翻译方法缺乏准确性的问题。方法通过 LLMs 迭代处理开放词汇的 Question-Answering (QA) 问题，并利用 conformal prediction (CP) 来评估不确定性，从而在翻译过程中决定是否继续或请求帮助。理论和实证结果表明，ConformalNL2LTL 能实现指定翻译成功率，同时最小化帮助请求率，为机器人任务规范的自动化生成提供了可靠框架。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.21022v1",
      "published_date": "2025-04-22 20:32:34 UTC",
      "updated_date": "2025-04-22 20:32:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:29:27.960743"
    },
    {
      "arxiv_id": "2504.16226v1",
      "title": "Blockchain Meets Adaptive Honeypots: A Trust-Aware Approach to Next-Gen IoT Security",
      "title_zh": "翻译失败",
      "authors": [
        "Yazan Otoum",
        "Arghavan Asad",
        "Amiya Nayak"
      ],
      "abstract": "Edge computing-based Next-Generation Wireless Networks (NGWN)-IoT offer\nenhanced bandwidth capacity for large-scale service provisioning but remain\nvulnerable to evolving cyber threats. Existing intrusion detection and\nprevention methods provide limited security as adversaries continually adapt\ntheir attack strategies. We propose a dynamic attack detection and prevention\napproach to address this challenge. First, blockchain-based authentication uses\nthe Deoxys Authentication Algorithm (DAA) to verify IoT device legitimacy\nbefore data transmission. Next, a bi-stage intrusion detection system is\nintroduced: the first stage uses signature-based detection via an Improved\nRandom Forest (IRF) algorithm. In contrast, the second stage applies\nfeature-based anomaly detection using a Diffusion Convolution Recurrent Neural\nNetwork (DCRNN). To ensure Quality of Service (QoS) and maintain Service Level\nAgreements (SLA), trust-aware service migration is performed using Heap-Based\nOptimization (HBO). Additionally, on-demand virtual High-Interaction honeypots\ndeceive attackers and extract attack patterns, which are securely stored using\nthe Bimodal Lattice Signature Scheme (BLISS) to enhance signature-based\nIntrusion Detection Systems (IDS). The proposed framework is implemented in the\nNS3 simulation environment and evaluated against existing methods across\nmultiple performance metrics, including accuracy, attack detection rate, false\nnegative rate, precision, recall, ROC curve, memory usage, CPU usage, and\nexecution time. Experimental results demonstrate that the framework\nsignificantly outperforms existing approaches, reinforcing the security of\nNGWN-enabled IoT ecosystems",
      "tldr_zh": "本文提出一种基于区块链和自适应 Honeypots 的信任感知框架，用于提升 Next-Generation Wireless Networks (NGWN)-IoT 的安全防护。该方法包括使用 Deoxys Authentication Algorithm (DAA) 进行设备认证、双阶段入侵检测系统（Improved Random Forest (IRF) 基于签名检测和 Diffusion Convolution Recurrent Neural Network (DCRNN) 基于特征异常检测）、Heap-Based Optimization (HBO) 实现信任感知服务迁移，以及虚拟高交互 Honeypots 欺骗攻击者并通过 Bimodal Lattice Signature Scheme (BLISS) 安全存储攻击模式。实验在 NS3 模拟环境中进行，结果显示该框架在准确率、攻击检测率、假阴性率、精确率、召回率等指标上显著优于现有方法，确保了 Quality of Service (QoS) 和 Service Level Agreements (SLA)。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.ET",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "This paper has been submitted to the IEEE Transactions on Network\n  Science and Engineering (TNSE) for possible publication",
      "pdf_url": "http://arxiv.org/pdf/2504.16226v1",
      "published_date": "2025-04-22 19:36:19 UTC",
      "updated_date": "2025-04-22 19:36:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:29:40.935403"
    },
    {
      "arxiv_id": "2504.16214v2",
      "title": "Hexcute: A Tile-based Programming Language with Automatic Layout and Task-Mapping Synthesis",
      "title_zh": "翻译失败",
      "authors": [
        "Xiao Zhang",
        "Yaoyao Ding",
        "Yang Hu",
        "Gennady Pekhimenko"
      ],
      "abstract": "Deep learning (DL) workloads mainly run on accelerators like GPUs. Recent DL\nquantization techniques demand a new matrix multiplication operator with mixed\ninput data types, further complicating GPU optimization. Prior high-level\ncompilers like Triton lack the expressiveness to implement key optimizations\nlike fine-grained data pipelines and hardware-friendly memory layouts for these\noperators, while low-level programming models, such as Hidet, Graphene, and\nCUTLASS, require significant programming efforts. To balance expressiveness\nwith engineering effort, we propose Hexcute, a tile-based programming language\nthat exposes shared memory and register abstractions to enable fine-grained\noptimization for these operators. Additionally, Hexcute leverages task mapping\nto schedule the GPU program, and to reduce programming efforts, it automates\nlayout and task mapping synthesis with a novel type-inference-based algorithm.\nOur evaluation shows that Hexcute generalizes to a wide range of DL operators,\nachieves 1.7-11.28$\\times$ speedup over existing DL compilers for mixed-type\noperators, and brings up to 2.91$\\times$ speedup in the end-to-end evaluation.",
      "tldr_zh": "该研究提出Hexcute，一种基于tile的编程语言，旨在解决深度学习(DL)量化技术对GPU优化带来的挑战，如混合输入数据类型的矩阵乘法操作。现有的高水平编译器如Triton缺乏细粒度优化能力，而低水平模型如Hidet、Graphene和CUTLASS则需大量编程努力；Hexcute通过暴露shared memory和register抽象，并使用新型的type-inference-based算法自动合成layout和task mapping，从而平衡表达性和工程效率。实验结果显示，Hexcute适用于多种DL运算符，在混合类型运算符上比现有DL编译器快1.7-11.28倍，并在端到端评估中实现高达2.91倍的加速。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.PL"
      ],
      "primary_category": "cs.LG",
      "comment": "17 pages, 24 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.16214v2",
      "published_date": "2025-04-22 19:01:28 UTC",
      "updated_date": "2025-04-30 17:29:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:29:52.321665"
    },
    {
      "arxiv_id": "2504.16213v1",
      "title": "TinyML for Speech Recognition",
      "title_zh": "TinyML 用于语音识别",
      "authors": [
        "Andrew Barovic",
        "Armin Moin"
      ],
      "abstract": "We train and deploy a quantized 1D convolutional neural network model to\nconduct speech recognition on a highly resource-constrained IoT edge device.\nThis can be useful in various Internet of Things (IoT) applications, such as\nsmart homes and ambient assisted living for the elderly and people with\ndisabilities, just to name a few examples. In this paper, we first create a new\ndataset with over one hour of audio data that enables our research and will be\nuseful to future studies in this field. Second, we utilize the technologies\nprovided by Edge Impulse to enhance our model's performance and achieve a high\nAccuracy of up to 97% on our dataset. For the validation, we implement our\nprototype using the Arduino Nano 33 BLE Sense microcontroller board. This\nmicrocontroller board is specifically designed for IoT and AI applications,\nmaking it an ideal choice for our target use case scenarios. While most\nexisting research focuses on a limited set of keywords, our model can process\n23 different keywords, enabling complex commands.",
      "tldr_zh": "本研究开发了一个量化后的 1D convolutional neural network 模型，用于在资源受限的 IoT 边缘设备上实现语音识别，适用于智能家居和辅助生活等应用。研究者首先创建了一个新的数据集，包含超过一小时的音频数据，并利用 Edge Impulse 技术提升模型性能，达到97%的准确率。模型部署在 Arduino Nano 33 BLE Sense 微控制器上，能处理23个不同关键词，支持更复杂的命令，与现有研究相比显著扩展了功能。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.16213v1",
      "published_date": "2025-04-22 19:00:40 UTC",
      "updated_date": "2025-04-22 19:00:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:30:03.279203"
    },
    {
      "arxiv_id": "2504.16209v1",
      "title": "HTN Plan Repair Algorithms Compared: Strengths and Weaknesses of Different Methods",
      "title_zh": "翻译失败",
      "authors": [
        "Paul Zaidins",
        "Robert P. Goldman",
        "Ugur Kuter",
        "Dana Nau",
        "Mark Roberts"
      ],
      "abstract": "This paper provides theoretical and empirical comparisons of three recent\nhierarchical plan repair algorithms: SHOPFixer, IPyHOPPER, and Rewrite. Our\ntheoretical results show that the three algorithms correspond to three\ndifferent definitions of the plan repair problem, leading to differences in the\nalgorithms' search spaces, the repair problems they can solve, and the kinds of\nrepairs they can make. Understanding these distinctions is important when\nchoosing a repair method for any given application.\n  Building on the theoretical results, we evaluate the algorithms empirically\nin a series of benchmark planning problems. Our empirical results provide more\ndetailed insight into the runtime repair performance of these systems and the\ncoverage of the repair problems solved, based on algorithmic properties such as\nreplanning, chronological backtracking, and backjumping over plan trees.",
      "tldr_zh": "本论文比较了三个HTN计划修复算法（SHOPFixer、IPyHOPPER 和 Rewrite）的优缺点，通过理论和实证分析揭示了它们的差异。理论结果显示，这些算法对应于计划修复问题的三种不同定义，导致搜索空间、解决问题的能力和修复类型各异，这对选择合适的应用方法至关重要。实证评估基于一系列基准规划问题，提供了这些算法在运行时性能和问题覆盖率方面的详细洞见，包括重新规划、chronological backtracking 和 backjumping over plan trees 等属性。",
      "categories": [
        "cs.AI",
        "I.2.8"
      ],
      "primary_category": "cs.AI",
      "comment": "20 pages; 19 figures; To appear in the Proceedings for ICAPS 2025,\n  the 35th International Conference on Automated Planning and Schedulings",
      "pdf_url": "http://arxiv.org/pdf/2504.16209v1",
      "published_date": "2025-04-22 18:55:26 UTC",
      "updated_date": "2025-04-22 18:55:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:30:16.233265"
    },
    {
      "arxiv_id": "2504.16204v1",
      "title": "Reflexive Prompt Engineering: A Framework for Responsible Prompt Engineering and Interaction Design",
      "title_zh": "翻译失败",
      "authors": [
        "Christian Djeffal"
      ],
      "abstract": "Responsible prompt engineering has emerged as a critical framework for\nensuring that generative artificial intelligence (AI) systems serve society's\nneeds while minimizing potential harms. As generative AI applications become\nincreasingly powerful and ubiquitous, the way we instruct and interact with\nthem through prompts has profound implications for fairness, accountability,\nand transparency. This article examines how strategic prompt engineering can\nembed ethical and legal considerations and societal values directly into AI\ninteractions, moving beyond mere technical optimization for functionality. This\narticle proposes a comprehensive framework for responsible prompt engineering\nthat encompasses five interconnected components: prompt design, system\nselection, system configuration, performance evaluation, and prompt management.\nDrawing from empirical evidence, the paper demonstrates how each component can\nbe leveraged to promote improved societal outcomes while mitigating potential\nrisks. The analysis reveals that effective prompt engineering requires a\ndelicate balance between technical precision and ethical consciousness,\ncombining the systematic rigor and focus on functionality with the nuanced\nunderstanding of social impact. Through examination of real-world and emerging\npractices, the article illustrates how responsible prompt engineering serves as\na crucial bridge between AI development and deployment, enabling organizations\nto fine-tune AI outputs without modifying underlying model architectures. This\napproach aligns with broader \"Responsibility by Design\" principles, embedding\nethical considerations directly into the implementation process rather than\ntreating them as post-hoc additions. The article concludes by identifying key\nresearch directions and practical guidelines for advancing the field of\nresponsible prompt engineering.",
      "tldr_zh": "这篇论文提出了 Reflexive Prompt Engineering 框架，用于负责任的提示工程（responsible prompt engineering），旨在确保生成式 AI 系统在公平性、问责性和透明性方面符合社会需求，同时减少潜在危害。框架包括五个相互连接的组件：prompt design、system selection、system configuration、performance evaluation 和 prompt management，通过这些组件将伦理和法律考虑嵌入 AI 交互过程，而无需修改底层模型架构。研究基于实证证据证明，这种方法能平衡技术精度与伦理意识，促进更好的社会结果，并为 AI 开发提供关键研究方向和实用指南。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL",
        "cs.ET"
      ],
      "primary_category": "cs.CY",
      "comment": "20 pages one figure",
      "pdf_url": "http://arxiv.org/pdf/2504.16204v1",
      "published_date": "2025-04-22 18:51:32 UTC",
      "updated_date": "2025-04-22 18:51:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:30:27.395069"
    },
    {
      "arxiv_id": "2504.16193v1",
      "title": "Quality of explanation of xAI from the prespective of Italian end-users: Italian version of System Causability Scale (SCS)",
      "title_zh": "xAI 的解释质量从意大利最终用户的视角：System Causability Scale (",
      "authors": [
        "Carmine Attanasio",
        "Alireza Mortezapour"
      ],
      "abstract": "Background and aim: Considering the scope of the application of artificial\nintelligence beyond the field of computer science, one of the concerns of\nresearchers is to provide quality explanations about the functioning of\nalgorithms based on artificial intelligence and the data extracted from it. The\npurpose of the present study is to validate the Italian version of system\ncausability scale (I-SCS) to measure the quality of explanations provided in a\nxAI.\n  Method: For this purpose, the English version, initially provided in 2020 in\ncoordination with the main developer, was utilized. The forward-backward\ntranslation method was applied to ensure accuracy. Finally, these nine steps\nwere completed by calculating the content validity index/ratio and conducting\ncognitive interviews with representative end users.\n  Results: The original version of the questionnaire consisted of 10 questions.\nHowever, based on the obtained indexes (CVR below 0.49), one question (Question\n8) was entirely removed. After completing the aforementioned steps, the Italian\nversion contained 9 questions. The representative sample of Italian end users\nfully comprehended the meaning and content of the questions in the Italian\nversion.\n  Conclusion: The Italian version obtained in this study can be used in future\nresearch studies as well as in the field by xAI developers. This tool can be\nused to measure the quality of explanations provided for an xAI system in\nItalian culture.",
      "tldr_zh": "本研究旨在验证意大利版系统可解释性量表(I-SCS)，用于评估xAI（可解释人工智能）系统解释质量，从意大利终端用户的视角出发。研究采用前向后向翻译方法，并通过计算内容有效性指数/比率(CVR)以及认知访谈来确保问卷的准确性和可理解性。结果显示，原有10个问题的问卷移除了一个问题（Question 8）后，剩余9个问题，意大利终端用户对其内容完全理解。该工具可用于未来研究和xAI开发中，测量意大利文化背景下xAI解释的质量。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "This work will be presented in Coperman 2025 Conference",
      "pdf_url": "http://arxiv.org/pdf/2504.16193v1",
      "published_date": "2025-04-22 18:32:40 UTC",
      "updated_date": "2025-04-22 18:32:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:30:39.631843"
    },
    {
      "arxiv_id": "2504.16188v1",
      "title": "FinNLI: Novel Dataset for Multi-Genre Financial Natural Language Inference Benchmarking",
      "title_zh": "FinNLI：用于多类型金融自然语言推理基准测试的新颖数据集",
      "authors": [
        "Jabez Magomere",
        "Elena Kochkina",
        "Samuel Mensah",
        "Simerjot Kaur",
        "Charese H. Smiley"
      ],
      "abstract": "We introduce FinNLI, a benchmark dataset for Financial Natural Language\nInference (FinNLI) across diverse financial texts like SEC Filings, Annual\nReports, and Earnings Call transcripts. Our dataset framework ensures diverse\npremise-hypothesis pairs while minimizing spurious correlations. FinNLI\ncomprises 21,304 pairs, including a high-quality test set of 3,304 instances\nannotated by finance experts. Evaluations show that domain shift significantly\ndegrades general-domain NLI performance. The highest Macro F1 scores for\npre-trained (PLMs) and large language models (LLMs) baselines are 74.57% and\n78.62%, respectively, highlighting the dataset's difficulty. Surprisingly,\ninstruction-tuned financial LLMs perform poorly, suggesting limited\ngeneralizability. FinNLI exposes weaknesses in current LLMs for financial\nreasoning, indicating room for improvement.",
      "tldr_zh": "本研究引入了 FinNLI，这是一个新的基准数据集，用于评估多类型金融文本（如 SEC Filings、Annual Reports 和 Earnings Call transcripts）的 Natural Language Inference (NLI)。数据集包含 21,304 对前提-假设对，其中包括由金融专家标注的高质量测试集 3,304 实例，并通过框架设计确保多样性和最小化虚假相关性。评估结果显示，领域转移显著降低了通用 NLI 模型的性能，预训练语言模型 (PLMs) 和大型语言模型 (LLMs) 的最高 Macro F1 分数分别为 74.57% 和 78.62%，而针对金融指令调整的 LLMs 表现不佳，暴露了当前模型在金融推理中的局限性，并指出了改进潜力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.16188v1",
      "published_date": "2025-04-22 18:25:17 UTC",
      "updated_date": "2025-04-22 18:25:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:30:53.372734"
    },
    {
      "arxiv_id": "2504.16173v2",
      "title": "FPGA-Based Neural Network Accelerators for Space Applications: A Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Pedro Antunes",
        "Artur Podobas"
      ],
      "abstract": "Space missions are becoming increasingly ambitious, necessitating\nhigh-performance onboard spacecraft computing systems. In response,\nfield-programmable gate arrays (FPGAs) have garnered significant interest due\nto their flexibility, cost-effectiveness, and radiation tolerance potential.\nConcurrently, neural networks (NNs) are being recognized for their capability\nto execute space mission tasks such as autonomous operations, sensor data\nanalysis, and data compression. This survey serves as a valuable resource for\nresearchers aiming to implement FPGA-based NN accelerators in space\napplications. By analyzing existing literature, identifying trends and gaps,\nand proposing future research directions, this work highlights the potential of\nthese accelerators to enhance onboard computing systems.",
      "tldr_zh": "这篇调查论文探讨了FPGA-based Neural Network Accelerators在太空应用的潜力，强调FPGA的灵活性、成本效益和辐射耐受性，使其适合处理太空任务如自主操作、传感器数据分析和数据压缩。论文通过分析现有文献，识别了当前趋势和研究空白，并提出未来研究方向，以提升机载计算系统的性能。总体而言，该工作为研究人员提供了宝贵资源，突出了这些加速器在高性能太空任务中的关键作用。",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "primary_category": "cs.AR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.16173v2",
      "published_date": "2025-04-22 18:02:35 UTC",
      "updated_date": "2025-04-24 12:04:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:31:05.982143"
    },
    {
      "arxiv_id": "2504.16172v2",
      "title": "Physics-Informed Inference Time Scaling via Simulation-Calibrated Scientific Machine Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Zexi Fan",
        "Yan Sun",
        "Shihao Yang",
        "Yiping Lu"
      ],
      "abstract": "High-dimensional partial differential equations (PDEs) pose significant\ncomputational challenges across fields ranging from quantum chemistry to\neconomics and finance. Although scientific machine learning (SciML) techniques\noffer approximate solutions, they often suffer from bias and neglect crucial\nphysical insights. Inspired by inference-time scaling strategies in language\nmodels, we propose Simulation-Calibrated Scientific Machine Learning (SCaSML),\na physics-informed framework that dynamically refines and debiases the SCiML\npredictions during inference by enforcing the physical laws. SCaSML leverages\nderived new physical laws that quantifies systematic errors and employs Monte\nCarlo solvers based on the Feynman-Kac and Elworthy-Bismut-Li formulas to\ndynamically correct the prediction. Both numerical and theoretical analysis\nconfirms enhanced convergence rates via compute-optimal inference methods. Our\nnumerical experiments demonstrate that SCaSML reduces errors by 20-50% compared\nto the base surrogate model, establishing it as the first algorithm to refine\napproximated solutions to high-dimensional PDE during inference. Code of SCaSML\nis available at https://github.com/Francis-Fan-create/SCaSML.",
      "tldr_zh": "该论文提出 Simulation-Calibrated Scientific Machine Learning (SCaSML)，一种物理信息框架，旨在解决科学机器学习 (SciML) 在处理高维偏微分方程 (PDEs) 时存在的偏差和忽略物理洞见的问题。SCaSML 通过动态应用新派生的物理定律和基于 Feynman-Kac 及 Elworthy-Bismut-Li 公式的 Monte Carlo 求解器，在推理阶段精炼预测并纠正系统错误。实验结果显示，该方法相较于基础代理模型减少 20-50% 的错误，并提升了收敛率，成为首个在推理时精炼高维 PDE 近似解的算法。",
      "categories": [
        "math.NA",
        "cs.AI",
        "cs.LG",
        "cs.NA",
        "math.PR",
        "stat.ML"
      ],
      "primary_category": "math.NA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.16172v2",
      "published_date": "2025-04-22 18:01:45 UTC",
      "updated_date": "2025-04-25 15:12:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:31:17.544091"
    },
    {
      "arxiv_id": "2504.16171v1",
      "title": "A detection-task-specific deep-learning method to improve the quality of sparse-view myocardial perfusion SPECT images",
      "title_zh": "翻译失败",
      "authors": [
        "Zezhang Yang",
        "Zitong Yu",
        "Nuri Choi",
        "Abhinav K. Jha"
      ],
      "abstract": "Myocardial perfusion imaging (MPI) with single-photon emission computed\ntomography (SPECT) is a widely used and cost-effective diagnostic tool for\ncoronary artery disease. However, the lengthy scanning time in this imaging\nprocedure can cause patient discomfort, motion artifacts, and potentially\ninaccurate diagnoses due to misalignment between the SPECT scans and the\nCT-scans which are acquired for attenuation compensation. Reducing projection\nangles is a potential way to shorten scanning time, but this can adversely\nimpact the quality of the reconstructed images. To address this issue, we\npropose a detection-task-specific deep-learning method for sparse-view MPI\nSPECT images. This method integrates an observer loss term that penalizes the\nloss of anthropomorphic channel features with the goal of improving performance\nin perfusion defect-detection task. We observed that, on the task of detecting\nmyocardial perfusion defects, the proposed method yielded an area under the\nreceiver operating characteristic (ROC) curve (AUC) significantly larger than\nthe sparse-view protocol. Further, the proposed method was observed to be able\nto restore the structure of the left ventricle wall, demonstrating ability to\novercome sparse-sampling artifacts. Our preliminary results motivate further\nevaluations of the method.",
      "tldr_zh": "本论文针对心肌灌注 SPECT 图像的稀疏视图问题，提出了一种特定于检测任务的深度学习方法，以缩短扫描时间并减少运动伪影。方法通过整合 observer loss term 来惩罚人类形态通道特征的损失，从而提升灌注缺陷检测性能。实验结果显示，该方法在检测心肌灌注缺陷任务上显著提高了 AUC 值，并成功恢复了左心室壁的结构。初步结果表明，该方法有望改善 SPECT 图像质量，并促进临床应用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.16171v1",
      "published_date": "2025-04-22 18:01:03 UTC",
      "updated_date": "2025-04-22 18:01:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:31:27.845763"
    },
    {
      "arxiv_id": "2504.16078v1",
      "title": "LLMs are Greedy Agents: Effects of RL Fine-tuning on Decision-Making Abilities",
      "title_zh": "LLMs 是贪婪代理：RL 微调对决策能力的影响",
      "authors": [
        "Thomas Schmied",
        "Jörg Bornschein",
        "Jordi Grau-Moya",
        "Markus Wulfmeier",
        "Razvan Pascanu"
      ],
      "abstract": "The success of Large Language Models (LLMs) has sparked interest in various\nagentic applications. A key hypothesis is that LLMs, leveraging common sense\nand Chain-of-Thought (CoT) reasoning, can effectively explore and efficiently\nsolve complex domains. However, LLM agents have been found to suffer from\nsub-optimal exploration and the knowing-doing gap, the inability to effectively\nact on knowledge present in the model. In this work, we systematically study\nwhy LLMs perform sub-optimally in decision-making scenarios. In particular, we\nclosely examine three prevalent failure modes: greediness, frequency bias, and\nthe knowing-doing gap. We propose mitigation of these shortcomings by\nfine-tuning via Reinforcement Learning (RL) on self-generated CoT rationales.\nOur experiments across multi-armed bandits, contextual bandits, and\nTic-tac-toe, demonstrate that RL fine-tuning enhances the decision-making\nabilities of LLMs by increasing exploration and narrowing the knowing-doing\ngap. Finally, we study both classic exploration mechanisms, such as\n$\\epsilon$-greedy, and LLM-specific approaches, such as self-correction and\nself-consistency, to enable more effective fine-tuning of LLMs for\ndecision-making.",
      "tldr_zh": "这篇论文探讨了大型语言模型（LLMs）在决策任务中的问题，包括贪婪（greediness）、频率偏差（frequency bias）和知行差距（knowing-doing gap），这些导致了次优探索和行动不力。研究者提出通过强化学习（RL）微调，使用自我生成的链式思维推理（CoT）来缓解这些缺陷，提升 LLMs 的决策能力。实验在多臂老虎机、上下文老虎机和 Tic-tac-toe 等环境中进行，结果显示 RL 微调显著增加了探索行为并缩小了知行差距。此外，论文还评估了经典探索机制如 ε-greedy，以及 LLMs 特有的方法如 self-correction 和 self-consistency，以优化微调效果。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.16078v1",
      "published_date": "2025-04-22 17:57:14 UTC",
      "updated_date": "2025-04-22 17:57:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:31:41.932735"
    },
    {
      "arxiv_id": "2504.16072v1",
      "title": "Describe Anything: Detailed Localized Image and Video Captioning",
      "title_zh": "翻译失败",
      "authors": [
        "Long Lian",
        "Yifan Ding",
        "Yunhao Ge",
        "Sifei Liu",
        "Hanzi Mao",
        "Boyi Li",
        "Marco Pavone",
        "Ming-Yu Liu",
        "Trevor Darrell",
        "Adam Yala",
        "Yin Cui"
      ],
      "abstract": "Generating detailed and accurate descriptions for specific regions in images\nand videos remains a fundamental challenge for vision-language models. We\nintroduce the Describe Anything Model (DAM), a model designed for detailed\nlocalized captioning (DLC). DAM preserves both local details and global context\nthrough two key innovations: a focal prompt, which ensures high-resolution\nencoding of targeted regions, and a localized vision backbone, which integrates\nprecise localization with its broader context. To tackle the scarcity of\nhigh-quality DLC data, we propose a Semi-supervised learning (SSL)-based Data\nPipeline (DLC-SDP). DLC-SDP starts with existing segmentation datasets and\nexpands to unlabeled web images using SSL. We introduce DLC-Bench, a benchmark\ndesigned to evaluate DLC without relying on reference captions. DAM sets new\nstate-of-the-art on 7 benchmarks spanning keyword-level, phrase-level, and\ndetailed multi-sentence localized image and video captioning.",
      "tldr_zh": "本研究针对视觉语言模型在生成图像和视频特定区域详细描述的挑战，引入了Describe Anything Model (DAM)，该模型通过focal prompt和高分辨率编码以及localized vision backbone整合本地化和全局上下文，实现详细本地化字幕(Detailed Localized Captioning, DLC)。为了解决高质量DLC数据稀缺的问题，研究者提出了Semi-supervised learning (SSL)-based Data Pipeline (DLC-SDP)，从现有分割数据集扩展到未标注的网络图像。还开发了DLC-Bench基准，用于无参考字幕的评估。DAM在7个基准上实现了新状态-of-the-art表现，涵盖关键词级、短语级和详细多句本地化图像及视频字幕。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Project page: https://describe-anything.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2504.16072v1",
      "published_date": "2025-04-22 17:51:41 UTC",
      "updated_date": "2025-04-22 17:51:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:31:52.172949"
    },
    {
      "arxiv_id": "2504.18575v3",
      "title": "WASP: Benchmarking Web Agent Security Against Prompt Injection Attacks",
      "title_zh": "WASP：",
      "authors": [
        "Ivan Evtimov",
        "Arman Zharmagambetov",
        "Aaron Grattafiori",
        "Chuan Guo",
        "Kamalika Chaudhuri"
      ],
      "abstract": "Autonomous UI agents powered by AI have tremendous potential to boost human\nproductivity by automating routine tasks such as filing taxes and paying bills.\nHowever, a major challenge in unlocking their full potential is security, which\nis exacerbated by the agent's ability to take action on their user's behalf.\nExisting tests for prompt injections in web agents either over-simplify the\nthreat by testing unrealistic scenarios or giving the attacker too much power,\nor look at single-step isolated tasks. To more accurately measure progress for\nsecure web agents, we introduce WASP -- a new publicly available benchmark for\nend-to-end evaluation of Web Agent Security against Prompt injection attacks.\nEvaluating with WASP shows that even top-tier AI models, including those with\nadvanced reasoning capabilities, can be deceived by simple, low-effort\nhuman-written injections in very realistic scenarios. Our end-to-end evaluation\nreveals a previously unobserved insight: while attacks partially succeed in up\nto 86% of the case, even state-of-the-art agents often struggle to fully\ncomplete the attacker goals -- highlighting the current state of security by\nincompetence.",
      "tldr_zh": "该研究引入了 WASP，这是一个新的公开基准，用于端到端评估 Web Agent 对 Prompt Injection Attacks 的安全性，旨在解决现有测试方法过于简化或不切实际的问题。WASP 通过模拟真实场景评估 AI 驱动的自主 UI 代理（如用于报税或支付账单的代理）在面对攻击时的表现，结果显示即使是顶级 AI 模型也容易被简单的人类编写的注入攻击欺骗。关键发现是，攻击在高达 86% 的情况下部分成功，但最先进的代理往往无法完全实现攻击者目标，这突显了当前 Web Agent 安全的“依赖于无能”状态。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "Code and data: https://github.com/facebookresearch/wasp",
      "pdf_url": "http://arxiv.org/pdf/2504.18575v3",
      "published_date": "2025-04-22 17:51:03 UTC",
      "updated_date": "2025-05-16 22:42:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:32:03.676106"
    },
    {
      "arxiv_id": "2504.16061v1",
      "title": "Vision language models are unreliable at trivial spatial cognition",
      "title_zh": "视觉语言模型在简单的空间认知中不可靠",
      "authors": [
        "Sangeet Khemlani",
        "Tyler Tran",
        "Nathaniel Gyory",
        "Anthony M. Harrison",
        "Wallace E. Lawson",
        "Ravenna Thielstrom",
        "Hunter Thompson",
        "Taaren Singh",
        "J. Gregory Trafton"
      ],
      "abstract": "Vision language models (VLMs) are designed to extract relevant visuospatial\ninformation from images. Some research suggests that VLMs can exhibit humanlike\nscene understanding, while other investigations reveal difficulties in their\nability to process relational information. To achieve widespread applicability,\nVLMs must perform reliably, yielding comparable competence across a wide\nvariety of related tasks. We sought to test how reliable these architectures\nare at engaging in trivial spatial cognition, e.g., recognizing whether one\nobject is left of another in an uncluttered scene. We developed a benchmark\ndataset -- TableTest -- whose images depict 3D scenes of objects arranged on a\ntable, and used it to evaluate state-of-the-art VLMs. Results show that\nperformance could be degraded by minor variations of prompts that use logically\nequivalent descriptions. These analyses suggest limitations in how VLMs may\nreason about spatial relations in real-world applications. They also reveal\nnovel opportunities for bolstering image caption corpora for more efficient\ntraining and testing.",
      "tldr_zh": "本研究发现，视觉语言模型（VLMs）在处理简单空间认知任务（如判断物体相对位置）时表现出不稳定性，尽管它们被设计用于提取图像中的视觉空间信息。研究者开发了TableTest基准数据集，包含物体排列在桌子上的3D场景图像，并使用它评估了最先进的VLMs。结果显示，使用逻辑等价描述的提示轻微变化会导致性能显著下降，这揭示了VLMs在真实世界应用中空间关系推理的局限性，并为增强图像标题语料库以优化训练和测试提供了新机会。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.16061v1",
      "published_date": "2025-04-22 17:38:01 UTC",
      "updated_date": "2025-04-22 17:38:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:32:15.865968"
    },
    {
      "arxiv_id": "2504.16053v1",
      "title": "LongMamba: Enhancing Mamba's Long Context Capabilities via Training-Free Receptive Field Enlargement",
      "title_zh": "LongMamba：通过无需训练的感受野扩大来增强 Mamba 的长上下文能力",
      "authors": [
        "Zhifan Ye",
        "Kejing Xia",
        "Yonggan Fu",
        "Xin Dong",
        "Jihoon Hong",
        "Xiangchi Yuan",
        "Shizhe Diao",
        "Jan Kautz",
        "Pavlo Molchanov",
        "Yingyan Celine Lin"
      ],
      "abstract": "State space models (SSMs) have emerged as an efficient alternative to\nTransformer models for language modeling, offering linear computational\ncomplexity and constant memory usage as context length increases. However,\ndespite their efficiency in handling long contexts, recent studies have shown\nthat SSMs, such as Mamba models, generally underperform compared to\nTransformers in long-context understanding tasks. To address this significant\nshortfall and achieve both efficient and accurate long-context understanding,\nwe propose LongMamba, a training-free technique that significantly enhances the\nlong-context capabilities of Mamba models. LongMamba builds on our discovery\nthat the hidden channels in Mamba can be categorized into local and global\nchannels based on their receptive field lengths, with global channels primarily\nresponsible for long-context capability. These global channels can become the\nkey bottleneck as the input context lengthens. Specifically, when input lengths\nlargely exceed the training sequence length, global channels exhibit\nlimitations in adaptively extend their receptive fields, leading to Mamba's\npoor long-context performance. The key idea of LongMamba is to mitigate the\nhidden state memory decay in these global channels by preventing the\naccumulation of unimportant tokens in their memory. This is achieved by first\nidentifying critical tokens in the global channels and then applying token\nfiltering to accumulate only those critical tokens. Through extensive\nbenchmarking across synthetic and real-world long-context scenarios, LongMamba\nsets a new standard for Mamba's long-context performance, significantly\nextending its operational range without requiring additional training. Our code\nis available at https://github.com/GATECH-EIC/LongMamba.",
      "tldr_zh": "本研究发现，状态空间模型 (SSMs) 如 Mamba 虽然在处理长上下文时具有高效性，但其长上下文理解能力不如 Transformers，主要由于隐藏通道中的全球通道无法适配扩展接收域 (Receptive Field)。为此，提出 LongMamba，一种无需额外训练的技术，通过识别并过滤全球通道中的关键 token，防止不重要 token 积累，从而显著增强 Mamba 的长上下文能力。实验在合成和真实场景基准测试中证明，LongMamba 显著提升了 Mamba 的性能，扩展了其操作范围，并提供了开源代码。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.16053v1",
      "published_date": "2025-04-22 17:30:36 UTC",
      "updated_date": "2025-04-22 17:30:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:32:27.868975"
    },
    {
      "arxiv_id": "2504.16047v1",
      "title": "Evaluating Vision Language Models (VLMs) for Radiology: A Comprehensive Analysis",
      "title_zh": "评估视觉语言模型 (VLMs) 用于放射学：全面分析",
      "authors": [
        "Frank Li",
        "Hari Trivedi",
        "Bardia Khosravi",
        "Theo Dapamede",
        "Mohammadreza Chavoshi",
        "Abdulhameed Dere",
        "Rohan Satya Isaac",
        "Aawez Mansuri",
        "Janice Newsome",
        "Saptarshi Purkayastha",
        "Judy Gichoya"
      ],
      "abstract": "Foundation models, trained on vast amounts of data using self-supervised\ntechniques, have emerged as a promising frontier for advancing artificial\nintelligence (AI) applications in medicine. This study evaluates three\ndifferent vision-language foundation models (RAD-DINO, CheXagent, and\nBiomedCLIP) on their ability to capture fine-grained imaging features for\nradiology tasks. The models were assessed across classification, segmentation,\nand regression tasks for pneumothorax and cardiomegaly on chest radiographs.\nSelf-supervised RAD-DINO consistently excelled in segmentation tasks, while\ntext-supervised CheXagent demonstrated superior classification performance.\nBiomedCLIP showed inconsistent performance across tasks. A custom segmentation\nmodel that integrates global and local features substantially improved\nperformance for all foundation models, particularly for challenging\npneumothorax segmentation. The findings highlight that pre-training methodology\nsignificantly influences model performance on specific downstream tasks. For\nfine-grained segmentation tasks, models trained without text supervision\nperformed better, while text-supervised models offered advantages in\nclassification and interpretability. These insights provide guidance for\nselecting foundation models based on specific clinical applications in\nradiology.",
      "tldr_zh": "这篇论文全面评估了三个视觉语言模型（VLMs）——RAD-DINO、CheXagent 和 BiomedCLIP——在放射学任务中捕捉细粒度图像特征的能力。模型在胸部 X 光片的分类、分割和回归任务上进行了测试，结果显示 RAD-DINO 在分割任务中表现最佳，而 CheXagent 在分类任务中表现出色，BiomedCLIP 的表现则不一致。通过整合全局和局部特征的自定义分割模型，研究显著提升了所有模型的性能，特别是针对气胸分割任务。研究发现，预训练方法对下游任务影响重大，没有文本监督的模型更适合细粒度分割，而文本监督模型在分类和可解释性方面具有优势，为放射学临床应用选择合适模型提供了指导。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.16047v1",
      "published_date": "2025-04-22 17:20:34 UTC",
      "updated_date": "2025-04-22 17:20:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:32:40.966174"
    },
    {
      "arxiv_id": "2504.16042v1",
      "title": "Approximate matrices of systems of max-min fuzzy relational equations",
      "title_zh": "最大-最小模糊关系方程系统的近似矩阵",
      "authors": [
        "Ismaïl Baaj"
      ],
      "abstract": "In this article, we address the inconsistency of a system of max-min fuzzy\nrelational equations by minimally modifying the matrix governing the system in\norder to achieve consistency. Our method yields consistent systems that\napproximate the original inconsistent system in the following sense: the\nright-hand side vector of each consistent system is that of the inconsistent\nsystem, and the coefficients of the matrix governing each consistent system are\nobtained by modifying, exactly and minimally, the entries of the original\nmatrix that must be corrected to achieve consistency, while leaving all other\nentries unchanged.\n  To obtain a consistent system that closely approximates the considered\ninconsistent system, we study the distance (in terms of a norm among $L_1$,\n$L_2$ or $L_\\infty$) between the matrix of the inconsistent system and the set\nformed by the matrices of consistent systems that use the same right-hand side\nvector as the inconsistent system. We show that our method allows us to\ndirectly compute matrices of consistent systems that use the same right-hand\nside vector as the inconsistent system whose distance in terms of $L_\\infty$\nnorm to the matrix of the inconsistent system is minimal (the computational\ncosts are higher when using $L_1$ norm or $L_2$ norm). We also give an explicit\nanalytical formula for computing this minimal $L_\\infty$ distance. Finally, we\ntranslate our results for systems of min-max fuzzy relational equations and\npresent some potential applications.",
      "tldr_zh": "这篇论文针对 max-min fuzzy relational equations 系统的非一致性问题，提出了一种通过最小修改矩阵的方法来实现系统一致性，同时保持右端向量不变，仅修改必要的矩阵条目。研究者分析了矩阵在 L1、L2 或 L∞ 范数下的距离，展示了如何直接计算 L∞ 范数最小距离的矩阵，并给出了显式公式，以确保修改后的系统尽可能接近原系统。最终，论文将这些结果扩展到 min-max fuzzy relational equations 系统，并探讨了潜在应用，如模糊系统优化和建模。",
      "categories": [
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.16042v1",
      "published_date": "2025-04-22 17:09:02 UTC",
      "updated_date": "2025-04-22 17:09:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:32:52.633594"
    },
    {
      "arxiv_id": "2504.16041v1",
      "title": "Muon Optimizer Accelerates Grokking",
      "title_zh": "翻译失败",
      "authors": [
        "Amund Tveit",
        "Bjørn Remseth",
        "Arve Skogvold"
      ],
      "abstract": "This paper investigates the impact of different optimizers on the grokking\nphenomenon, where models exhibit delayed generalization. We conducted\nexperiments across seven numerical tasks (primarily modular arithmetic) using a\nmodern Transformer architecture. The experimental configuration systematically\nvaried the optimizer (Muon vs. AdamW) and the softmax activation function\n(standard softmax, stablemax, and sparsemax) to assess their combined effect on\nlearning dynamics. Our empirical evaluation reveals that the Muon optimizer,\ncharacterized by its use of spectral norm constraints and second-order\ninformation, significantly accelerates the onset of grokking compared to the\nwidely used AdamW optimizer. Specifically, Muon reduced the mean grokking epoch\nfrom 153.09 to 102.89 across all configurations, a statistically significant\ndifference (t = 5.0175, p = 6.33e-08). This suggests that the optimizer choice\nplays a crucial role in facilitating the transition from memorization to\ngeneralization.",
      "tldr_zh": "本研究探讨了不同优化器对模型\"grokking\"现象（延迟泛化）的加速影响，通过七个数值任务（主要是模算术）在Transformer架构上进行实验。实验系统比较了Muon优化器与AdamW优化器，以及标准softmax、stablemax和sparsemax激活函数的组合效果。结果显示，Muon优化器利用谱范数约束和二阶信息，将平均grokking epoch从153.09显著降低到102.89（t=5.0175, p=6.33e-08），证明其在促进从记忆到泛化的过渡方面更有效。该发现强调了优化器选择在机器学习动态中的关键作用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "I.2"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.16041v1",
      "published_date": "2025-04-22 17:08:09 UTC",
      "updated_date": "2025-04-22 17:08:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:33:04.153435"
    },
    {
      "arxiv_id": "2504.16032v2",
      "title": "LLMs meet Federated Learning for Scalable and Secure IoT Management",
      "title_zh": "翻译失败",
      "authors": [
        "Yazan Otoum",
        "Arghavan Asad",
        "Amiya Nayak"
      ],
      "abstract": "The rapid expansion of IoT ecosystems introduces severe challenges in\nscalability, security, and real-time decision-making. Traditional centralized\narchitectures struggle with latency, privacy concerns, and excessive resource\nconsumption, making them unsuitable for modern large-scale IoT deployments.\nThis paper presents a novel Federated Learning-driven Large Language Model\n(FL-LLM) framework, designed to enhance IoT system intelligence while ensuring\ndata privacy and computational efficiency. The framework integrates Generative\nIoT (GIoT) models with a Gradient Sensing Federated Strategy (GSFS),\ndynamically optimizing model updates based on real-time network conditions. By\nleveraging a hybrid edge-cloud processing architecture, our approach balances\nintelligence, scalability, and security in distributed IoT environments.\nEvaluations on the IoT-23 dataset demonstrate that our framework improves model\naccuracy, reduces response latency, and enhances energy efficiency,\noutperforming traditional FL techniques (i.e., FedAvg, FedOpt). These findings\nhighlight the potential of integrating LLM-powered federated learning into\nlarge-scale IoT ecosystems, paving the way for more secure, scalable, and\nadaptive IoT management solutions.",
      "tldr_zh": "这篇论文针对物联网（IoT）生态系统的可伸缩性、安全性和实时决策挑战，提出了一种基于 Federated Learning 的 Large Language Model (FL-LLM) 框架，以提升系统智能并保障数据隐私。框架整合 Generative IoT (GIoT) 模型和 Gradient Sensing Federated Strategy (GSFS)，通过动态优化模型更新和混合边云处理架构，实现高效的分布式 IoT 环境管理。在 IoT-23 数据集上的评估显示，该框架显著提高了模型准确率、减少了响应延迟并提升了能源效率，优于传统 Federated Learning 技术如 FedAvg 和 FedOpt。这些成果为更安全、可伸缩的 IoT 管理解决方案铺平了道路。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.LG",
      "comment": "This work has been submitted to the IEEE Global Communications\n  Conference (GLOBECOM) 2025 for possible publication",
      "pdf_url": "http://arxiv.org/pdf/2504.16032v2",
      "published_date": "2025-04-22 16:56:59 UTC",
      "updated_date": "2025-05-13 02:49:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:33:17.072027"
    },
    {
      "arxiv_id": "2504.16027v1",
      "title": "Benchmarking LLM for Code Smells Detection: OpenAI GPT-4.0 vs DeepSeek-V3",
      "title_zh": "翻译失败",
      "authors": [
        "Ahmed R. Sadik",
        "Siddhata Govind"
      ],
      "abstract": "Determining the most effective Large Language Model for code smell detection\npresents a complex challenge. This study introduces a structured methodology\nand evaluation matrix to tackle this issue, leveraging a curated dataset of\ncode samples consistently annotated with known smells. The dataset spans four\nprominent programming languages Java, Python, JavaScript, and C++; allowing for\ncross language comparison. We benchmark two state of the art LLMs, OpenAI GPT\n4.0 and DeepSeek-V3, using precision, recall, and F1 score as evaluation\nmetrics. Our analysis covers three levels of detail: overall performance,\ncategory level performance, and individual code smell type performance.\nAdditionally, we explore cost effectiveness by comparing the token based\ndetection approach of GPT 4.0 with the pattern-matching techniques employed by\nDeepSeek V3. The study also includes a cost analysis relative to traditional\nstatic analysis tools such as SonarQube. The findings offer valuable guidance\nfor practitioners in selecting an efficient, cost effective solution for\nautomated code smell detection",
      "tldr_zh": "该研究评估了OpenAI GPT-4.0和DeepSeek-V3两种LLM在代码异味检测中的性能，采用一个结构化的方法和评估矩阵，基于一个包含Java、Python、JavaScript和C++语言的标注数据集。评估指标包括precision、recall和F1 score，涵盖整体性能、类别级性能以及单个代码异味类型性能。研究还比较了GPT-4.0的基于令牌的检测方法与DeepSeek-V3的模式匹配技术，并进行成本分析，与传统工具如SonarQube对比，为从业者选择高效、成本有效的自动代码异味检测方案提供指导。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG",
        "cs.PL"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.16027v1",
      "published_date": "2025-04-22 16:44:39 UTC",
      "updated_date": "2025-04-22 16:44:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:33:28.841405"
    },
    {
      "arxiv_id": "2504.16026v2",
      "title": "Trends in AI Supercomputers",
      "title_zh": "AI 超级计算机的趋势",
      "authors": [
        "Konstantin F. Pilz",
        "James Sanders",
        "Robi Rahman",
        "Lennart Heim"
      ],
      "abstract": "Frontier AI development relies on powerful AI supercomputers, yet analysis of\nthese systems is limited. We create a dataset of 500 AI supercomputers from\n2019 to 2025 and analyze key trends in performance, power needs, hardware cost,\nownership, and global distribution. We find that the computational performance\nof AI supercomputers has doubled every nine months, while hardware acquisition\ncost and power needs both doubled every year. The leading system in March 2025,\nxAI's Colossus, used 200,000 AI chips, had a hardware cost of \\$7B, and\nrequired 300 MW of power, as much as 250,000 households. As AI supercomputers\nevolved from tools for science to industrial machines, companies rapidly\nexpanded their share of total AI supercomputer performance, while the share of\ngovernments and academia diminished. Globally, the United States accounts for\nabout 75% of total performance in our dataset, with China in second place at\n15%. If the observed trends continue, the leading AI supercomputer in 2030 will\nachieve $2\\times10^{22}$ 16-bit FLOP/s, use two million AI chips, have a\nhardware cost of \\$200 billion, and require 9 GW of power. Our analysis\nprovides visibility into the AI supercomputer landscape, allowing policymakers\nto assess key AI trends like resource needs, ownership, and national\ncompetitiveness.",
      "tldr_zh": "这篇论文创建了一个涵盖2019至2025年500个AI supercomputers的数据集，并分析了其性能、功率需求、硬件成本、所有权和全球分布的趋势。研究发现，AI supercomputers的计算性能每九个月翻倍，而硬件成本和功率需求每年翻倍；例如，2025年领先系统xAI's Colossus使用20万AI芯片、硬件成本7亿美元、需300MW功率。公司在AI supercomputers性能份额中迅速增长，美国占全球75%、中国占15%。如果趋势持续，到2030年领先系统将达到2×10^22 16-bit FLOP/s、2百万AI芯片、成本200亿美元、需9GW功率，此分析为政策制定者提供关键洞见，以评估资源需求、所有权和国家竞争力。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.16026v2",
      "published_date": "2025-04-22 16:44:34 UTC",
      "updated_date": "2025-04-23 20:08:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:33:41.461172"
    },
    {
      "arxiv_id": "2504.16021v1",
      "title": "Navigating the State of Cognitive Flow: Context-Aware AI Interventions for Effective Reasoning Support",
      "title_zh": "翻译失败",
      "authors": [
        "Dinithi Dissanayake",
        "Suranga Nanayakkara"
      ],
      "abstract": "Flow theory describes an optimal cognitive state where individuals experience\ndeep focus and intrinsic motivation when a task's difficulty aligns with their\nskill level. In AI-augmented reasoning, interventions that disrupt the state of\ncognitive flow can hinder rather than enhance decision-making. This paper\nproposes a context-aware cognitive augmentation framework that adapts\ninterventions based on three key contextual factors: type, timing, and scale.\nBy leveraging multimodal behavioral cues (e.g., gaze behavior, typing\nhesitation, interaction speed), AI can dynamically adjust cognitive support to\nmaintain or restore flow. We introduce the concept of cognitive flow, an\nextension of flow theory in AI-augmented reasoning, where interventions are\npersonalized, adaptive, and minimally intrusive. By shifting from static\ninterventions to context-aware augmentation, our approach ensures that AI\nsystems support deep engagement in complex decision-making and reasoning\nwithout disrupting cognitive immersion.",
      "tldr_zh": "这篇论文基于 Flow theory，探讨了 AI 干预在增强推理过程中的潜在问题，即可能打断个体的最佳认知状态，从而影响决策。论文提出一个上下文感知的认知增强框架，通过适应干预的类型、时机和规模，利用多模态行为线索（如目光行为、打字犹豫、交互速度）来动态调整支持。引入 cognitive flow 概念作为 Flow theory 的扩展，该框架确保 AI 系统提供个性化、适应性和最小侵入的辅助，帮助维持深度参与复杂决策的认知沉浸。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "Presented at the 2025 ACM Workshop on Human-AI Interaction for\n  Augmented Reasoning, Report Number: CHI25-WS-AUGMENTED-REASONING",
      "pdf_url": "http://arxiv.org/pdf/2504.16021v1",
      "published_date": "2025-04-22 16:35:39 UTC",
      "updated_date": "2025-04-22 16:35:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:33:52.970202"
    },
    {
      "arxiv_id": "2504.16153v1",
      "title": "Leveraging Social Media Analytics for Sustainability Trend Detection in Saudi Arabias Evolving Market",
      "title_zh": "翻译失败",
      "authors": [
        "Kanwal Aalijah"
      ],
      "abstract": "Saudi Arabias rapid economic growth and social evolution under Vision 2030\npresent a unique opportunity to track emerging trends in real time. Uncovering\ntrends in real time can open up new avenues for business and investment\nopportunities. This paper explores how AI and social media analytics can\nuncover and monitor these trends across sectors like sustainability,\nconstruction, food beverages industry, tourism, technology, and entertainment.\nThis paper focus on use of AI-driven methodology to identify sustainability\ntrends across Saudi Arabia. We processed millions of social media posts, news,\nblogs in order to understand sustainability trends in the region. The paper\npresents an AI approach that can help economists, businesses, government to\nunderstand sustainability trends and make better decisions around them. This\napproach offers both sector-specific and cross-sector insights, giving\ndecision-makers a reliable, up to date snapshot of Saudi Arabias market shifts.\nBeyond Saudi Arabia, this framework also shows potential for adapting to other\nregions. Overall, our findings highlight how by using AI-methodologies, give\ndecision makers a reliable method to understand how initiatives are perceived\nand adopted by the public and understand growth of trends.",
      "tldr_zh": "本研究探讨了如何利用 AI 和 social media analytics 来实时检测沙特阿拉伯在 Vision 2030 驱动下可持续性趋势的变化，涵盖建筑、食品饮料、旅游、技术和娱乐等行业。研究方法涉及处理数百万条社交媒体帖子、新闻和博客数据，通过 AI 驱动的分析框架识别行业特定和跨行业见解。结果显示，该方法能为经济学家、企业和政府提供可靠的实时市场快照，帮助他们更好地理解公众对可持续性举措的感知和趋势增长潜力；此外，该框架具有适应其他地区的潜力。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "9",
      "pdf_url": "http://arxiv.org/pdf/2504.16153v1",
      "published_date": "2025-04-22 16:33:15 UTC",
      "updated_date": "2025-04-22 16:33:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:34:04.705263"
    },
    {
      "arxiv_id": "2504.16020v2",
      "title": "AlphaGrad: Non-Linear Gradient Normalization Optimizer",
      "title_zh": "AlphaGrad：非线性梯度归一化优化器",
      "authors": [
        "Soham Sane"
      ],
      "abstract": "We introduce AlphaGrad, a memory-efficient, conditionally stateless optimizer\naddressing the memory overhead and hyperparameter complexity of adaptive\nmethods like Adam. AlphaGrad enforces scale invariance via tensor-wise L2\ngradient normalization followed by a smooth hyperbolic tangent transformation,\n$g' = \\tanh(\\alpha \\cdot \\tilde{g})$, controlled by a single steepness\nparameter $\\alpha$. Our contributions include: (1) the AlphaGrad algorithm\nformulation; (2) a formal non-convex convergence analysis guaranteeing\nstationarity; (3) extensive empirical evaluation on diverse RL benchmarks (DQN,\nTD3, PPO). Compared to Adam, AlphaGrad demonstrates a highly context-dependent\nperformance profile. While exhibiting instability in off-policy DQN, it\nprovides enhanced training stability with competitive results in TD3 (requiring\ncareful $\\alpha$ tuning) and achieves substantially superior performance in\non-policy PPO. These results underscore the critical importance of empirical\n$\\alpha$ selection, revealing strong interactions between the optimizer's\ndynamics and the underlying RL algorithm. AlphaGrad presents a compelling\nalternative optimizer for memory-constrained scenarios and shows significant\npromise for on-policy learning regimes where its stability and efficiency\nadvantages can be particularly impactful.",
      "tldr_zh": "该论文提出 AlphaGrad，一种内存高效的条件无状态优化器，通过张量-wise L2 梯度归一化后应用平滑的 tanh 变换（$g' = \\tanh(\\alpha \\cdot \\tilde{g}$）来强制尺度不变性，仅需一个陡度参数 $\\alpha$ 即可简化超参数复杂性。贡献包括 AlphaGrad 算法的制定、正式的非凸收敛分析（保证平稳性），以及在强化学习（RL）基准（如 DQN、TD3 和 PPO）上的广泛实证评估。与 Adam 相比，AlphaGrad 的性能高度依赖上下文：在 DQN 中表现不稳定，但在 TD3 中提供更好的训练稳定性，并在 PPO 中显著优越，突显了 $\\alpha$ 参数选择的必要性。AlphaGrad 为内存受限场景提供了一个有前景的替代方案，尤其在 on-policy 学习中展现出稳定性与效率优势。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.16020v2",
      "published_date": "2025-04-22 16:33:14 UTC",
      "updated_date": "2025-04-23 01:25:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:34:17.285970"
    },
    {
      "arxiv_id": "2504.18574v1",
      "title": "Understanding the Skill Gap in Recurrent Language Models: The Role of the Gather-and-Aggregate Mechanism",
      "title_zh": "理解循环语言模型中的技能差距：聚集和聚合机制的作用",
      "authors": [
        "Aviv Bick",
        "Eric Xing",
        "Albert Gu"
      ],
      "abstract": "SSMs offer efficient processing of long sequences with fixed state sizes, but\nstruggle with algorithmic tasks like retrieving past context. In this work, we\nexamine how such in-context retrieval operates within Transformer- and\nSSM-based language models. We find that both architectures develop the same\nfundamental Gather-and-Aggregate (G&A) mechanism. A Gather Head first\nidentifies and extracts relevant information from the context, which an\nAggregate Head then integrates into a final representation. Across both model\ntypes, G&A concentrates in just a few heads, making them critical bottlenecks\neven for benchmarks that require a basic form of retrieval. For example,\ndisabling a single Gather or Aggregate Head of a pruned Llama-3.1-8B degrades\nits ability to retrieve the correct answer letter in MMLU, reducing accuracy\nfrom 66% to 25%. This finding suggests that in-context retrieval can obscure\nthe limited knowledge demands of certain tasks. Despite strong MMLU performance\nwith retrieval intact, the pruned model fails on other knowledge tests. Similar\nG&A dependencies exist in GSM8K, BBH, and dialogue tasks. Given the\nsignificance of G&A in performance, we show that retrieval challenges in SSMs\nmanifest in how they implement G&A, leading to smoother attention patterns\nrather than the sharp token transitions that effective G&A relies on. Thus,\nwhile a gap exists between Transformers and SSMs in implementing in-context\nretrieval, it is confined to a few heads, not the entire model. This insight\nsuggests a unified explanation for performance differences between Transformers\nand SSMs while also highlighting ways to combine their strengths. For example,\nin pretrained hybrid models, attention components naturally take on the role of\nAggregate Heads. Similarly, in a pretrained pure SSM, replacing a single G&A\nhead with an attention-based variant significantly improves retrieval.",
      "tldr_zh": "本研究探讨了循环语言模型（如SSMs）在处理算法任务（如上下文检索）时的技能差距，揭示了Transformer和SSMs模型都依赖于相同的Gather-and-Aggregate (G&A)机制，其中Gather Head提取相关信息，Aggregate Head整合这些信息。实验发现，G&A机制集中在少数heads上，是性能的关键瓶颈，例如在pruned Llama-3.1-8B模型中，禁用一个Gather或Aggregate Head会使MMLU准确率从66%降至25%。尽管SSMs在某些任务表现出色，但其实现G&A时存在问题，导致注意力模式更平滑而非锐利，无法有效处理检索。论文建议这种差距仅限于特定heads，并提出通过混合模型或替换heads（如用注意力机制）来结合Transformer和SSMs的优势，提升整体性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.18574v1",
      "published_date": "2025-04-22 16:15:19 UTC",
      "updated_date": "2025-04-22 16:15:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:34:29.866412"
    },
    {
      "arxiv_id": "2504.16005v3",
      "title": "CAPO: Cost-Aware Prompt Optimization",
      "title_zh": "CAPO: 成本感知提示优化",
      "authors": [
        "Tom Zehle",
        "Moritz Schlager",
        "Timo Heiß",
        "Matthias Feurer"
      ],
      "abstract": "Large language models (LLMs) have revolutionized natural language processing\nby solving a wide range of tasks simply guided by a prompt. Yet their\nperformance is highly sensitive to prompt formulation. While automated prompt\noptimization addresses this challenge by finding optimal prompts, current\nmethods require a substantial number of LLM calls and input tokens, making\nprompt optimization expensive. We introduce CAPO (Cost-Aware Prompt\nOptimization), an algorithm that enhances prompt optimization efficiency by\nintegrating AutoML techniques. CAPO is an evolutionary approach with LLMs as\noperators, incorporating racing to save evaluations and multi-objective\noptimization to balance performance with prompt length. It jointly optimizes\ninstructions and few-shot examples while leveraging task descriptions for\nimproved robustness. Our extensive experiments across diverse datasets and LLMs\ndemonstrate that CAPO outperforms state-of-the-art discrete prompt optimization\nmethods in 11/15 cases with improvements up to 21%p. Our algorithm achieves\nbetter performances already with smaller budgets, saves evaluations through\nracing, and decreases average prompt length via a length penalty, making it\nboth cost-efficient and cost-aware. Even without few-shot examples, CAPO\noutperforms its competitors and generally remains robust to initial prompts.\nCAPO represents an important step toward making prompt optimization more\npowerful and accessible by improving cost-efficiency.",
      "tldr_zh": "本论文提出 CAPO（Cost-Aware Prompt Optimization），一种整合 AutoML 技术的算法，用于高效优化大语言模型（LLMs）的提示，以解决现有方法高成本问题。CAPO 采用进化方法、racing 机制节省评估，以及多目标优化来平衡性能和提示长度，同时联合优化指令和少样本示例，利用任务描述提升鲁棒性。在多种数据集和 LLMs 上实验表明，CAPO 在 11/15 情况下优于最先进方法，提高高达 21%，并在更小预算下实现成本节约和提示长度减少。该方法即使无少样本示例，也表现出色，并提高了提示优化的可访问性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.NE",
        "stat.ML"
      ],
      "primary_category": "cs.CL",
      "comment": "Submitted to AutoML 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.16005v3",
      "published_date": "2025-04-22 16:14:31 UTC",
      "updated_date": "2025-04-25 15:27:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:34:40.906364"
    },
    {
      "arxiv_id": "2504.16152v1",
      "title": "Heterogeneous networks in drug-target interaction prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Mohammad Molaee",
        "Nasrollah Moghadam Charkari"
      ],
      "abstract": "Drug discovery requires a tremendous amount of time and cost. Computational\ndrug-target interaction prediction, a significant part of this process, can\nreduce these requirements by narrowing the search space for wet lab\nexperiments. In this survey, we provide comprehensive details of graph machine\nlearning-based methods in predicting drug-target interaction, as they have\nshown promising results in this field. These details include the overall\nframework, main contribution, datasets, and their source codes. The selected\npapers were mainly published from 2020 to 2024. Prior to discussing papers, we\nbriefly introduce the datasets commonly used with these methods and\nmeasurements to assess their performance. Finally, future challenges and some\ncrucial areas that need to be explored are discussed.",
      "tldr_zh": "这篇论文调查了异构网络（Heterogeneous networks）在药物-靶点交互预测（drug-target interaction prediction）中的应用，重点关注基于图机器学习（graph machine learning-based）的计算方法，以加速药物发现过程。该调查总结了从2020到2024年相关论文的整体框架、主要贡献、数据集及其源代码，并介绍了常用数据集和性能评估指标。最终，论文讨论了未来挑战，包括需要进一步探索的关键领域，以改进预测准确性和实用性。",
      "categories": [
        "q-bio.BM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.BM",
      "comment": "18 pages, 5 figures, 10 tables",
      "pdf_url": "http://arxiv.org/pdf/2504.16152v1",
      "published_date": "2025-04-22 16:09:22 UTC",
      "updated_date": "2025-04-22 16:09:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:34:52.389104"
    },
    {
      "arxiv_id": "2504.16000v1",
      "title": "How Private is Your Attention? Bridging Privacy with In-Context Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Soham Bonnerjee",
        "Zhen Wei",
        "Yeon",
        "Anna Asch",
        "Sagnik Nandy",
        "Promit Ghosal"
      ],
      "abstract": "In-context learning (ICL)-the ability of transformer-based models to perform\nnew tasks from examples provided at inference time-has emerged as a hallmark of\nmodern language models. While recent works have investigated the mechanisms\nunderlying ICL, its feasibility under formal privacy constraints remains\nlargely unexplored. In this paper, we propose a differentially private\npretraining algorithm for linear attention heads and present the first\ntheoretical analysis of the privacy-accuracy trade-off for ICL in linear\nregression. Our results characterize the fundamental tension between\noptimization and privacy-induced noise, formally capturing behaviors observed\nin private training via iterative methods. Additionally, we show that our\nmethod is robust to adversarial perturbations of training prompts, unlike\nstandard ridge regression. All theoretical findings are supported by extensive\nsimulations across diverse settings.",
      "tldr_zh": "本研究探讨了 In-Context Learning (ICL) 在隐私约束下的可行性，ICL 是 transformer 模型基于推理时提供的例子来执行新任务的核心能力。作者提出了一种针对线性注意力头的差异隐私预训练算法，并首次理论分析了 ICL 在线性回归中的隐私-准确性权衡，揭示了优化过程与隐私诱导噪声之间的基本张力。结果显示，该方法对训练提示的对抗性扰动具有鲁棒性，优于标准脊回归，且所有理论发现通过广泛的模拟实验在不同设置中得到验证。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.CL",
        "cs.CR",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.16000v1",
      "published_date": "2025-04-22 16:05:26 UTC",
      "updated_date": "2025-04-22 16:05:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:35:04.545116"
    },
    {
      "arxiv_id": "2504.15995v1",
      "title": "OPUS-VFL: Incentivizing Optimal Privacy-Utility Tradeoffs in Vertical Federated Learning",
      "title_zh": "OPUS-VFL：在垂直联邦学习中激励最优隐私-效用权衡",
      "authors": [
        "Sindhuja Madabushi",
        "Ahmad Faraz Khan",
        "Haider Ali",
        "Jin-Hee Cho"
      ],
      "abstract": "Vertical Federated Learning (VFL) enables organizations with disjoint feature\nspaces but shared user bases to collaboratively train models without sharing\nraw data. However, existing VFL systems face critical limitations: they often\nlack effective incentive mechanisms, struggle to balance privacy-utility\ntradeoffs, and fail to accommodate clients with heterogeneous resource\ncapabilities. These challenges hinder meaningful participation, degrade model\nperformance, and limit practical deployment. To address these issues, we\npropose OPUS-VFL, an Optimal Privacy-Utility tradeoff Strategy for VFL.\nOPUS-VFL introduces a novel, privacy-aware incentive mechanism that rewards\nclients based on a principled combination of model contribution, privacy\npreservation, and resource investment. It employs a lightweight leave-one-out\n(LOO) strategy to quantify feature importance per client, and integrates an\nadaptive differential privacy mechanism that enables clients to dynamically\ncalibrate noise levels to optimize their individual utility. Our framework is\ndesigned to be scalable, budget-balanced, and robust to inference and poisoning\nattacks. Extensive experiments on benchmark datasets (MNIST, CIFAR-10, and\nCIFAR-100) demonstrate that OPUS-VFL significantly outperforms state-of-the-art\nVFL baselines in both efficiency and robustness. It reduces label inference\nattack success rates by up to 20%, increases feature inference reconstruction\nerror (MSE) by over 30%, and achieves up to 25% higher incentives for clients\nthat contribute meaningfully while respecting privacy and cost constraints.\nThese results highlight the practicality and innovation of OPUS-VFL as a\nsecure, fair, and performance-driven solution for real-world VFL.",
      "tldr_zh": "该论文针对 Vertical Federated Learning (VFL) 中存在的激励机制不足、隐私与效用权衡困难以及异构资源能力问题，提出 OPUS-VFL 框架，以优化隐私-效用权衡。OPUS-VFL 引入隐私感知激励机制，根据客户端的模型贡献、隐私保护和资源投资进行奖励，并结合 leave-one-out (LOO) 策略量化特征重要性以及自适应差分隐私机制动态调整噪声水平，使框架具备可扩展性、预算平衡性和对推理及中毒攻击的鲁棒性。在 MNIST、CIFAR-10 和 CIFAR-100 数据集上的实验表明，OPUS-VFL 比现有基准方法提高效率和鲁棒性，标签推理攻击成功率降低高达 20%，特征重建错误 (MSE) 增加超过 30%，并为有意义贡献的客户端提供高达 25% 的更高激励，同时满足隐私和成本约束。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.15995v1",
      "published_date": "2025-04-22 16:00:11 UTC",
      "updated_date": "2025-04-22 16:00:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:35:17.869008"
    },
    {
      "arxiv_id": "2504.15983v1",
      "title": "W-PCA Based Gradient-Free Proxy for Efficient Search of Lightweight Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Shang Wang"
      ],
      "abstract": "The demand for efficient natural language processing (NLP) systems has led to\nthe development of lightweight language models. Previous work in this area has\nprimarily focused on manual design or training-based neural architecture search\n(NAS) methods. Recently, zero-shot NAS methods have been proposed for\nevaluating language models without the need for training. However, prevailing\napproaches to zero-shot NAS often face challenges such as biased evaluation\nmetrics and computational inefficiencies. In this paper, we introduce\nweight-weighted PCA (W-PCA), a novel zero-shot NAS method specifically tailored\nfor lightweight language models. Our approach utilizes two evaluation proxies:\nthe parameter count and the number of principal components with cumulative\ncontribution exceeding $\\eta$ in the feed-forward neural (FFN) layer.\nAdditionally, by eliminating the need for gradient computations, we optimize\nthe evaluation time, thus enhancing the efficiency of designing and evaluating\nlightweight language models. We conduct a comparative analysis on the GLUE and\nSQuAD datasets to evaluate our approach. The results demonstrate that our\nmethod significantly reduces training time compared to one-shot NAS methods and\nachieves higher scores in the testing phase compared to previous\nstate-of-the-art training-based methods. Furthermore, we perform ranking\nevaluations on a dataset sampled from the FlexiBERT search space. Our approach\nexhibits superior ranking correlation and further reduces solving time compared\nto other zero-shot NAS methods that require gradient computation.",
      "tldr_zh": "本文提出 W-PCA，一种基于 weight-weighted PCA 的零-shot NAS 方法，用于高效搜索轻量级语言模型，避免了传统方法的偏置评估指标和计算效率问题。该方法利用参数计数和 FFN 层中累计贡献超过 η 的主成分作为评估代理，并通过消除梯度计算来优化评估时间。在 GLUE 和 SQuAD 数据集上的实验结果显示，与 one-shot NAS 方法相比，该方法显著减少训练时间，并在测试分数上超越现有 state-of-the-art 训练-based 方法。此外，在 FlexiBERT 搜索空间的排名评估中，W-PCA 展示了更高的排名相关性和更短的求解时间。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.15983v1",
      "published_date": "2025-04-22 15:33:01 UTC",
      "updated_date": "2025-04-22 15:33:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:35:29.612082"
    },
    {
      "arxiv_id": "2504.15972v1",
      "title": "Bug Destiny Prediction in Large Open-Source Software Repositories through Sentiment Analysis and BERT Topic Modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Sophie C. Pope",
        "Andrew Barovic",
        "Armin Moin"
      ],
      "abstract": "This study explores a novel approach to predicting key bug-related outcomes,\nincluding the time to resolution, time to fix, and ultimate status of a bug,\nusing data from the Bugzilla Eclipse Project. Specifically, we leverage\nfeatures available before a bug is resolved to enhance predictive accuracy. Our\nmethodology incorporates sentiment analysis to derive both an emotionality\nscore and a sentiment classification (positive or negative). Additionally, we\nintegrate the bug's priority level and its topic, extracted using a BERTopic\nmodel, as features for a Convolutional Neural Network (CNN) and a Multilayer\nPerceptron (MLP). Our findings indicate that the combination of BERTopic and\nsentiment analysis can improve certain model performance metrics. Furthermore,\nwe observe that balancing model inputs enhances practical applicability, albeit\nat the cost of a significant reduction in accuracy in most cases. To address\nour primary objectives, predicting time-to-resolution, time-to-fix, and bug\ndestiny, we employ both binary classification and exact time value predictions,\nallowing for a comparative evaluation of their predictive effectiveness.\nResults demonstrate that sentiment analysis serves as a valuable predictor of a\nbug's eventual outcome, particularly in determining whether it will be fixed.\nHowever, its utility is less pronounced when classifying bugs into more complex\nor unconventional outcome categories.",
      "tldr_zh": "本研究提出了一种新方法，通过情感分析(Sentiment Analysis)和BERT Topic Modeling预测大型开源软件仓库（如Bugzilla Eclipse Project）中的bug命运，包括解决时间、修复时间和最终状态。方法利用bug解决前的特征，如情感强度分数、情感分类（积极或消极）、bug优先级以及BERTopic提取的主题，作为Convolutional Neural Network (CNN)和Multilayer Perceptron (MLP)的输入。结果显示，结合BERTopic和情感分析能提升某些模型性能指标，特别是情感分析在预测bug是否会被修复方面表现出色；然而，在处理更复杂的分类或平衡输入时，准确性可能显著降低。该方法为bug预测提供了实用性改进，但需权衡准确性和适用性。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.15972v1",
      "published_date": "2025-04-22 15:18:14 UTC",
      "updated_date": "2025-04-22 15:18:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:35:40.437896"
    },
    {
      "arxiv_id": "2504.15956v1",
      "title": "Universal Approximation with Softmax Attention",
      "title_zh": "翻译失败",
      "authors": [
        "Jerry Yao-Chieh Hu",
        "Hude Liu",
        "Hong-Yu Chen",
        "Weimin Wu",
        "Han Liu"
      ],
      "abstract": "We prove that with linear transformations, both (i) two-layer self-attention\nand (ii) one-layer self-attention followed by a softmax function are universal\napproximators for continuous sequence-to-sequence functions on compact domains.\nOur main technique is a new interpolation-based method for analyzing\nattention's internal mechanism. This leads to our key insight: self-attention\nis able to approximate a generalized version of ReLU to arbitrary precision,\nand hence subsumes many known universal approximators. Building on these, we\nshow that two-layer multi-head attention alone suffices as a\nsequence-to-sequence universal approximator. In contrast, prior works rely on\nfeed-forward networks to establish universal approximation in Transformers.\nFurthermore, we extend our techniques to show that, (softmax-)attention-only\nlayers are capable of approximating various statistical models in-context. We\nbelieve these techniques hold independent interest.",
      "tldr_zh": "本论文证明了，使用线性变换，两层自注意力(self-attention)机制或一层自注意力后跟softmax函数，能够作为紧致域上连续序列到序列函数的通用逼近器(universal approximators)。通过一种新的插值-based分析方法，研究揭示了自注意力能以任意精度逼近广义ReLU函数，从而涵盖了许多已知的通用逼近器。相比以往依赖前馈网络(feed-forward networks)的研究，本文展示了仅两层多头注意力(multi-head attention)机制就足以实现序列到序列的通用逼近。论文进一步扩展了这些技术，证明(softmax-)注意力-only层能在上下文中逼近各种统计模型，并认为这些方法具有独立兴趣。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.15956v1",
      "published_date": "2025-04-22 14:51:33 UTC",
      "updated_date": "2025-04-22 14:51:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:35:53.199945"
    },
    {
      "arxiv_id": "2504.15941v2",
      "title": "FairTranslate: An English-French Dataset for Gender Bias Evaluation in Machine Translation by Overcoming Gender Binarity",
      "title_zh": "翻译失败",
      "authors": [
        "Fanny Jourdan",
        "Yannick Chevalier",
        "Cécile Favre"
      ],
      "abstract": "Large Language Models (LLMs) are increasingly leveraged for translation tasks\nbut often fall short when translating inclusive language -- such as texts\ncontaining the singular 'they' pronoun or otherwise reflecting fair linguistic\nprotocols. Because these challenges span both computational and societal\ndomains, it is imperative to critically evaluate how well LLMs handle inclusive\ntranslation with a well-founded framework.\n  This paper presents FairTranslate, a novel, fully human-annotated dataset\ndesigned to evaluate non-binary gender biases in machine translation systems\nfrom English to French. FairTranslate includes 2418 English-French sentence\npairs related to occupations, annotated with rich metadata such as the\nstereotypical alignment of the occupation, grammatical gender indicator\nambiguity, and the ground-truth gender label (male, female, or inclusive).\n  We evaluate four leading LLMs (Gemma2-2B, Mistral-7B, Llama3.1-8B,\nLlama3.3-70B) on this dataset under different prompting procedures. Our results\nreveal substantial biases in gender representation across LLMs, highlighting\npersistent challenges in achieving equitable outcomes in machine translation.\nThese findings underscore the need for focused strategies and interventions\naimed at ensuring fair and inclusive language usage in LLM-based translation\nsystems.\n  We make the FairTranslate dataset publicly available on Hugging Face, and\ndisclose the code for all experiments on GitHub.",
      "tldr_zh": "本文提出 FairTranslate 数据集，这是一个全新的英文-法文句子对数据集，用于评估机器翻译系统中非二元性别偏见（overcoming gender binarity），旨在解决大型语言模型（LLMs）在处理包容性语言时的不足。数据集包含 2418 个句子对，涉及职业，并标注了丰富元数据，如职业的刻板印象、语法性别指示模糊性和真实性别标签（male, female 或 inclusive）。作者评估了四个领先的 LLMs（Gemma2-2B, Mistral-7B, Llama3.1-8B, Llama3.3-70B）在不同提示下的性能，结果显示这些模型在性别表示上存在显著偏见，突出了实现公平翻译的挑战。FairTranslate 数据集已公开在 Hugging Face 上，实验代码在 GitHub 上提供，以支持进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "FAccT 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.15941v2",
      "published_date": "2025-04-22 14:35:16 UTC",
      "updated_date": "2025-05-05 12:19:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:36:06.424952"
    },
    {
      "arxiv_id": "2504.15929v2",
      "title": "Meta-Entity Driven Triplet Mining for Aligning Medical Vision-Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Saban Ozturk",
        "Melih B. Yilmaz",
        "Muti Kara",
        "M. Talat Yavuz",
        "Aykut Koç",
        "Tolga Çukur"
      ],
      "abstract": "Diagnostic imaging relies on interpreting both images and radiology reports,\nbut the growing data volumes place significant pressure on medical experts,\nyielding increased errors and workflow backlogs. Medical vision-language models\n(med-VLMs) have emerged as a powerful framework to efficiently process\nmultimodal imaging data, particularly in chest X-ray (CXR) evaluations, albeit\ntheir performance hinges on how well image and text representations are\naligned. Existing alignment methods, predominantly based on contrastive\nlearning, prioritize separation between disease classes over segregation of\nfine-grained pathology attributes like location, size or severity, leading to\nsuboptimal representations. Here, we propose MedTrim (Meta-entity-driven\nTriplet mining), a novel method that enhances image-text alignment through\nmultimodal triplet learning synergistically guided by disease class as well as\nadjectival and directional pathology descriptors. Unlike common alignment\nmethods that separate broad disease classes, MedTrim leverages structured\nmeta-entity information to preserve subtle but clinically significant\nintra-class variations. For this purpose, we first introduce an ontology-based\nentity recognition module that extracts pathology-specific meta-entities from\nCXR reports, as annotations on pathology attributes are rare in public\ndatasets. For refined sample selection in triplet mining, we then introduce a\nnovel score function that captures an aggregate measure of inter-sample\nsimilarity based on disease classes and adjectival/directional descriptors.\nLastly, we introduce a multimodal triplet alignment objective for explicit\nwithin- and cross-modal alignment between samples sharing detailed pathology\ncharacteristics. Our demonstrations indicate that MedTrim improves performance\nin downstream retrieval and classification tasks compared to state-of-the-art\nalignment methods.",
      "tldr_zh": "该研究针对医疗视觉语言模型（med-VLMs）在诊断成像中的图像-文本对齐问题提出了一种新方法MedTrim，利用meta-entity驱动的三元组挖掘来提升模型性能，特别是针对胸部X光（CXR）报告的细粒度病理属性，如位置、大小和严重度。MedTrim首先引入基于本体论的实体识别模块，从CXR报告中提取病理特定meta-entities，以弥补公共数据集上此类注释的缺失；随后，通过一个新分数函数评估样本间的相似性，并采用多模态三元组对齐目标，实现样本间详细病理特征的显式对齐。实验结果显示，MedTrim在下游检索和分类任务中优于现有对比学习方法，提高了模型在临床应用中的准确性和效率。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "18 pages, 7 figures, 6 tables",
      "pdf_url": "http://arxiv.org/pdf/2504.15929v2",
      "published_date": "2025-04-22 14:17:51 UTC",
      "updated_date": "2025-04-24 01:26:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:36:17.972826"
    },
    {
      "arxiv_id": "2504.15928v1",
      "title": "A Clinician-Friendly Platform for Ophthalmic Image Analysis Without Technical Barriers",
      "title_zh": "翻译失败",
      "authors": [
        "Meng Wang",
        "Tian Lin",
        "Qingshan Hou",
        "Aidi Lin",
        "Jingcheng Wang",
        "Qingsheng Peng",
        "Truong X. Nguyen",
        "Danqi Fang",
        "Ke Zou",
        "Ting Xu",
        "Cancan Xue",
        "Ten Cheer Quek",
        "Qinkai Yu",
        "Minxin Liu",
        "Hui Zhou",
        "Zixuan Xiao",
        "Guiqin He",
        "Huiyu Liang",
        "Tingkun Shi",
        "Man Chen",
        "Linna Liu",
        "Yuanyuan Peng",
        "Lianyu Wang",
        "Qiuming Hu",
        "Junhong Chen",
        "Zhenhua Zhang",
        "Cheng Chen",
        "Yitian Zhao",
        "Dianbo Liu",
        "Jianhua Wu",
        "Xinjian Chen",
        "Changqing Zhang",
        "Triet Thanh Nguyen",
        "Yanda Meng",
        "Yalin Zheng",
        "Yih Chung Tham",
        "Carol Y. Cheung",
        "Huazhu Fu",
        "Haoyu Chen",
        "Ching-Yu Cheng"
      ],
      "abstract": "Artificial intelligence (AI) shows remarkable potential in medical imaging\ndiagnostics, but current models typically require retraining when deployed\nacross different clinical centers, limiting their widespread adoption. We\nintroduce GlobeReady, a clinician-friendly AI platform that enables ocular\ndisease diagnosis without retraining/fine-tuning or technical expertise.\nGlobeReady achieves high accuracy across imaging modalities: 93.9-98.5% for an\n11-category fundus photo dataset and 87.2-92.7% for a 15-category OCT dataset.\nThrough training-free local feature augmentation, it addresses domain shifts\nacross centers and populations, reaching an average accuracy of 88.9% across\nfive centers in China, 86.3% in Vietnam, and 90.2% in the UK. The built-in\nconfidence-quantifiable diagnostic approach further boosted accuracy to\n94.9-99.4% (fundus) and 88.2-96.2% (OCT), while identifying out-of-distribution\ncases at 86.3% (49 CFP categories) and 90.6% (13 OCT categories). Clinicians\nfrom multiple countries rated GlobeReady highly (average 4.6 out of 5) for its\nusability and clinical relevance. These results demonstrate GlobeReady's\nrobust, scalable diagnostic capability and potential to support ophthalmic care\nwithout technical barriers.",
      "tldr_zh": "该研究引入了GlobeReady，一种用户友好的AI平台，用于眼部疾病诊断，无需重新训练或技术专长，即可处理不同临床中心的图像分析。平台通过训练-free本地特征增强技术应对领域偏移，在多国数据集上实现高准确率，包括基金us照片的93.9-98.5%（11类）和OCT的87.2-92.7%（15类），平均跨五个中国中心达88.9%、越南86.3%和英国90.2%。内置的置信度量化诊断方法进一步提升准确率至94.9-99.4%（fundus）和88.2-96.2%（OCT），并有效识别分布外案例。临床医生对GlobeReady的可用性和临床相关性给予高评价（平均4.6分），展示了其鲁棒性和在眼科护理中的可扩展潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.15928v1",
      "published_date": "2025-04-22 14:17:22 UTC",
      "updated_date": "2025-04-22 14:17:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:36:29.007051"
    },
    {
      "arxiv_id": "2504.15927v1",
      "title": "New Recipe for Semi-supervised Community Detection: Clique Annealing under Crystallization Kinetics",
      "title_zh": "翻译失败",
      "authors": [
        "Ling Cheng",
        "Jiashu Pu",
        "Ruicheng Liang",
        "Qian Shao",
        "Hezhe Qiao",
        "Feida Zhu"
      ],
      "abstract": "Semi-supervised community detection methods are widely used for identifying\nspecific communities due to the label scarcity. Existing semi-supervised\ncommunity detection methods typically involve two learning stages learning in\nboth initial identification and subsequent adjustment, which often starts from\nan unreasonable community core candidate. Moreover, these methods encounter\nscalability issues because they depend on reinforcement learning and generative\nadversarial networks, leading to higher computational costs and restricting the\nselection of candidates. To address these limitations, we draw a parallel\nbetween crystallization kinetics and community detection to integrate the\nspontaneity of the annealing process into community detection. Specifically, we\nliken community detection to identifying a crystal subgrain (core) that expands\ninto a complete grain (community) through a process similar to annealing. Based\non this finding, we propose CLique ANNealing (CLANN), which applies kinetics\nconcepts to community detection by integrating these principles into the\noptimization process to strengthen the consistency of the community core.\nSubsequently, a learning-free Transitive Annealer was employed to refine the\nfirst-stage candidates by merging neighboring cliques and repositioning the\ncommunity core, enabling a spontaneous growth process that enhances\nscalability. Extensive experiments on \\textbf{43} different network settings\ndemonstrate that CLANN outperforms state-of-the-art methods across multiple\nreal-world datasets, showcasing its exceptional efficacy and efficiency in\ncommunity detection.",
      "tldr_zh": "本论文提出了一种新的半监督社区检测方法 CLANN（Clique ANNealing），通过借鉴结晶动力学的退火过程，将社区检测比作晶体亚晶粒（核心）的识别和扩展，以解决现有方法从不合理候选起始、依赖强化学习和生成对抗网络导致的计算成本高和可扩展性差的问题。CLANN 在优化过程中整合动力学概念强化社区核心一致性，并使用无学习 Transitive Annealer 精炼候选，通过合并相邻 cliques 和重新定位核心，实现自发增长过程。实验结果显示，在 43 种不同网络设置和多个真实数据集上，CLANN 优于最先进方法，在社区检测的效能和效率方面表现出色。",
      "categories": [
        "cs.SI",
        "cs.AI"
      ],
      "primary_category": "cs.SI",
      "comment": "arXiv admin note: text overlap with arXiv:2203.05898 by other authors",
      "pdf_url": "http://arxiv.org/pdf/2504.15927v1",
      "published_date": "2025-04-22 14:17:15 UTC",
      "updated_date": "2025-04-22 14:17:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:36:41.318622"
    },
    {
      "arxiv_id": "2504.15924v1",
      "title": "Achieving Distributive Justice in Federated Learning via Uncertainty Quantification",
      "title_zh": "通过不确定性量化在联邦学习中实现分配正义",
      "authors": [
        "Alycia Carey",
        "Xintao Wu"
      ],
      "abstract": "Client-level fairness metrics for federated learning are used to ensure that\nall clients in a federation either: a) have similar final performance on their\nlocal data distributions (i.e., client parity), or b) obtain final performance\non their local data distributions relative to their contribution to the\nfederated learning process (i.e., contribution fairness). While a handful of\nworks that propose either client-parity or contribution-based fairness metrics\nground their definitions and decisions in social theories of equality -- such\nas distributive justice -- most works arbitrarily choose what notion of\nfairness to align with which makes it difficult for practitioners to choose\nwhich fairness metric aligns best with their fairness ethics. In this work, we\npropose UDJ-FL (Uncertainty-based Distributive Justice for Federated Learning),\na flexible federated learning framework that can achieve multiple distributive\njustice-based client-level fairness metrics. Namely, by utilizing techniques\ninspired by fair resource allocation, in conjunction with performing aleatoric\nuncertainty-based client weighing, our UDJ-FL framework is able to achieve\negalitarian, utilitarian, Rawls' difference principle, or desert-based\nclient-level fairness. We empirically show the ability of UDJ-FL to achieve all\nfour defined distributive justice-based client-level fairness metrics in\naddition to providing fairness equivalent to (or surpassing) other popular fair\nfederated learning works. Further, we provide justification for why aleatoric\nuncertainty weighing is necessary to the construction of our UDJ-FL framework\nas well as derive theoretical guarantees for the generalization bounds of\nUDJ-FL. Our code is publicly available at\nhttps://github.com/alycia-noel/UDJ-FL.",
      "tldr_zh": "该论文针对联邦学习中的客户端公平性问题，提出 UDJ-FL（Uncertainty-based Distributive Justice for Federated Learning）框架，通过不确定性量化实现多种基于分配正义的公平指标，包括 egalitarian、utilitarian、Rawls' difference principle 和 desert-based 公平性。框架结合公平资源分配技术和 aleatoric uncertainty 基于客户端加权，确保客户端在本地数据分布上的性能相对其贡献得到公平对待。实验结果表明，UDJ-FL 能有效实现这些公平指标，并在性能上等同或优于现有方法，同时提供理论泛化界保证和代码开源支持。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML",
        "68T01",
        "I.2.0"
      ],
      "primary_category": "cs.LG",
      "comment": "21 pages, 1 figure, 7 tables",
      "pdf_url": "http://arxiv.org/pdf/2504.15924v1",
      "published_date": "2025-04-22 14:07:56 UTC",
      "updated_date": "2025-04-22 14:07:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:36:53.966582"
    },
    {
      "arxiv_id": "2504.15918v2",
      "title": "Ask2Loc: Learning to Locate Instructional Visual Answers by Asking Questions",
      "title_zh": "翻译失败",
      "authors": [
        "Chang Zong",
        "Bin Li",
        "Shoujun Zhou",
        "Jian Wan",
        "Lei Zhang"
      ],
      "abstract": "Locating specific segments within an instructional video is an efficient way\nto acquire guiding knowledge. Generally, the task of obtaining video segments\nfor both verbal explanations and visual demonstrations is known as visual\nanswer localization (VAL). However, users often need multiple interactions to\nobtain answers that align with their expectations when using the system. During\nthese interactions, humans deepen their understanding of the video content by\nasking themselves questions, thereby accurately identifying the location.\nTherefore, we propose a new task, named In-VAL, to simulate the multiple\ninteractions between humans and videos in the procedure of obtaining visual\nanswers. The In-VAL task requires interactively addressing several semantic gap\nissues, including 1) the ambiguity of user intent in the input questions, 2)\nthe incompleteness of language in video subtitles, and 3) the fragmentation of\ncontent in video segments. To address these issues, we propose Ask2Loc, a\nframework for resolving In-VAL by asking questions. It includes three key\nmodules: 1) a chatting module to refine initial questions and uncover clear\nintentions, 2) a rewriting module to generate fluent language and create\ncomplete descriptions, and 3) a searching module to broaden local context and\nprovide integrated content. We conduct extensive experiments on three\nreconstructed In-VAL datasets. Compared to traditional end-to-end and two-stage\nmethods, our proposed Ask2Loc can improve performance by up to 14.91 (mIoU) on\nthe In-VAL task. Our code and datasets can be accessed at\nhttps://github.com/changzong/Ask2Loc.",
      "tldr_zh": "本论文提出一个新任务 In-VAL（Interactive Visual Answer Localization），旨在模拟人类通过多次互动（如提问）来精确定位教学视频中的视觉片段，解决用户意图模糊、视频字幕不完整和内容碎片化等问题。作者开发了 Ask2Loc 框架，包括三个关键模块：chatting module 用于精炼问题并揭示清晰意图、rewriting module 用于生成流畅语言和完整描述，以及 searching module 用于扩展上下文并整合内容。通过在三个重建的 In-VAL 数据集上的实验，Ask2Loc 比传统端到端和两阶段方法提升了高达 14.91 mIoU 的性能，为交互式视频定位提供了有效解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.HC",
        "68T45, 68T20"
      ],
      "primary_category": "cs.CV",
      "comment": "16 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.15918v2",
      "published_date": "2025-04-22 14:03:16 UTC",
      "updated_date": "2025-04-23 03:01:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:37:05.019074"
    },
    {
      "arxiv_id": "2504.15912v1",
      "title": "Automated Bug Report Prioritization in Large Open-Source Projects",
      "title_zh": "大型开源项目中的自动错误报告优先级排序",
      "authors": [
        "Riley Pierson",
        "Armin Moin"
      ],
      "abstract": "Large open-source projects receive a large number of issues (known as bugs),\nincluding software defect (i.e., bug) reports and new feature requests from\ntheir user and developer communities at a fast rate. The often limited project\nresources do not allow them to deal with all issues. Instead, they have to\nprioritize them according to the project's priorities and the issues'\nseverities. In this paper, we propose a novel approach to automated bug\nprioritization based on the natural language text of the bug reports that are\nstored in the open bug repositories of the issue-tracking systems. We conduct\ntopic modeling using a variant of LDA called TopicMiner-MTM and text\nclassification with the BERT large language model to achieve a higher\nperformance level compared to the state-of-the-art. Experimental results using\nan existing reference dataset containing 85,156 bug reports of the Eclipse\nPlatform project indicate that we outperform existing approaches in terms of\nAccuracy, Precision, Recall, and F1-measure of the bug report priority\nprediction.",
      "tldr_zh": "本论文针对大型开源项目的 bug 报告优先排序问题，提出了一种基于自然语言文本的自动化方法，以帮助项目资源有限时有效分配资源。该方法结合了 TopicMiner-MTM（一种 LDA 变体）进行主题建模，以及 BERT 进行文本分类，从而提升了优先级预测的性能。在使用 Eclipse Platform 的 85,156 个 bug 报告数据集的实验中，该方法在 Accuracy, Precision, Recall 和 F1-measure 上均优于现有方法。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.15912v1",
      "published_date": "2025-04-22 13:57:48 UTC",
      "updated_date": "2025-04-22 13:57:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:37:16.947328"
    },
    {
      "arxiv_id": "2504.15905v1",
      "title": "GraphEdge: Dynamic Graph Partition and Task Scheduling for GNNs Computing in Edge Network",
      "title_zh": "翻译失败",
      "authors": [
        "Wenjing Xiao",
        "Chenglong Shi",
        "Miaojiang Chen",
        "Zhiquan Liu",
        "Min Chen",
        "H. Herbert Song"
      ],
      "abstract": "With the exponential growth of Internet of Things (IoT) devices, edge\ncomputing (EC) is gradually playing an important role in providing\ncost-effective services. However, existing approaches struggle to perform well\nin graph-structured scenarios where user data is correlated, such as traffic\nflow prediction and social relationship recommender systems. In particular,\ngraph neural network (GNN)-based approaches lead to expensive server\ncommunication cost. To address this problem, we propose GraphEdge, an efficient\nGNN-based EC architecture. It considers the EC system of GNN tasks, where there\nare associations between users and it needs to take into account the task data\nof its neighbors when processing the tasks of a user. Specifically, the\narchitecture first perceives the user topology and represents their data\nassociations as a graph layout at each time step. Then the graph layout is\noptimized by calling our proposed hierarchical traversal graph cut algorithm\n(HiCut), which cuts the graph layout into multiple weakly associated subgraphs\nbased on the aggregation characteristics of GNN, and the communication cost\nbetween different subgraphs during GNN inference is minimized. Finally, based\non the optimized graph layout, our proposed deep reinforcement learning (DRL)\nbased graph offloading algorithm (DRLGO) is executed to obtain the optimal\noffloading strategy for the tasks of users, the offloading strategy is\nsubgraph-based, it tries to offload user tasks in a subgraph to the same edge\nserver as possible while minimizing the task processing time and energy\nconsumption of the EC system. Experimental results show the good effectiveness\nand dynamic adaptation of our proposed architecture and it also performs well\neven in dynamic scenarios.",
      "tldr_zh": "本文提出 GraphEdge，一种动态图分区和任务调度架构，用于在边缘网络（EC）中优化图神经网络（GNN）计算，以解决用户数据关联导致的服务器通信成本高问题。具体方法包括使用层次遍历图切割算法（HiCut）将用户拓扑图优化为弱关联子图，减少 GNN 推理中的通信开销，以及基于深度强化学习（DRL）的图卸载算法（DRLGO）来实现子图任务的最优卸载策略，从而最小化任务处理时间和能量消耗。实验结果显示，GraphEdge 架构在动态场景中表现出色，提升了整体有效性和适应性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "17 pages,12 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.15905v1",
      "published_date": "2025-04-22 13:45:13 UTC",
      "updated_date": "2025-04-22 13:45:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:37:29.332551"
    },
    {
      "arxiv_id": "2504.15903v2",
      "title": "Impact of Noise on LLM-Models Performance in Abstraction and Reasoning Corpus (ARC) Tasks with Model Temperature Considerations",
      "title_zh": "翻译失败",
      "authors": [
        "Nikhil Khandalkar",
        "Pavan Yadav",
        "Krishna Shinde",
        "Lokesh B. Ramegowda",
        "Rajarshi Das"
      ],
      "abstract": "Recent advancements in Large Language Models (LLMs) have generated growing\ninterest in their structured reasoning capabilities, particularly in tasks\ninvolving abstraction and pattern recognition. The Abstraction and Reasoning\nCorpus (ARC) benchmark plays a crucial role in evaluating these capabilities by\ntesting how well AI models generalize to novel problems. While GPT-4o\ndemonstrates strong performance by solving all ARC tasks under zero-noise\nconditions, other models like DeepSeek R1 and LLaMA 3.2 fail to solve any,\nsuggesting limitations in their ability to reason beyond simple pattern\nmatching. To explore this gap, we systematically evaluate these models across\ndifferent noise levels and temperature settings. Our results reveal that the\nintroduction of noise consistently impairs model performance, regardless of\narchitecture. This decline highlights a shared vulnerability: current LLMs,\ndespite showing signs of abstract reasoning, remain highly sensitive to input\nperturbations. Such fragility raises concerns about their real-world\napplicability, where noise and uncertainty are common. By comparing how\ndifferent model architectures respond to these challenges, we offer insights\ninto the structural weaknesses of modern LLMs in reasoning tasks. This work\nunderscores the need for developing more robust and adaptable AI systems\ncapable of handling the ambiguity and variability inherent in real-world\nscenarios. Our findings aim to guide future research toward enhancing model\ngeneralization, robustness, and alignment with human-like cognitive\nflexibility.",
      "tldr_zh": "本研究评估了噪声水平和模型温度对大型语言模型 (LLMs) 在抽象和推理语料库 (ARC) 任务中的性能影响。实验比较了 GPT-4o、DeepSeek R1 和 LLaMA 3.2 等模型，发现 GPT-4o 在无噪声条件下能解决所有任务，而其他模型完全失败。结果显示，引入噪声会一致降低模型性能，无论架构如何，这暴露了 LLMs 对输入扰动的敏感性和在真实世界不确定性下的脆弱性。该工作强调了开发更鲁棒、适应性强的 AI 系统的重要性，以提升模型的泛化能力、鲁棒性和类似人类的认知灵活性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "60 pages, 25 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.15903v2",
      "published_date": "2025-04-22 13:43:58 UTC",
      "updated_date": "2025-04-23 13:23:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:37:40.798177"
    },
    {
      "arxiv_id": "2504.15895v2",
      "title": "Dynamic Early Exit in Reasoning Models",
      "title_zh": "推理模型中的动态提前退出",
      "authors": [
        "Chenxu Yang",
        "Qingyi Si",
        "Yongjie Duan",
        "Zheliang Zhu",
        "Chenyu Zhu",
        "Qiaowei Li",
        "Zheng Lin",
        "Li Cao",
        "Weiping Wang"
      ],
      "abstract": "Recent advances in large reasoning language models (LRLMs) rely on test-time\nscaling, which extends long chain-of-thought (CoT) generation to solve complex\ntasks. However, overthinking in long CoT not only slows down the efficiency of\nproblem solving, but also risks accuracy loss due to the extremely detailed or\nredundant reasoning steps. We propose a simple yet effective method that allows\nLLMs to self-truncate CoT sequences by early exit during generation. Instead of\nrelying on fixed heuristics, the proposed method monitors model behavior at\npotential reasoning transition points (e.g.,\"Wait\" tokens) and dynamically\nterminates the next reasoning chain's generation when the model exhibits high\nconfidence in a trial answer. Our method requires no additional training and\ncan be seamlessly integrated into existing o1-like reasoning LLMs. Experiments\non 10 reasoning benchmarks (e.g., GSM8K, MATH-500, AMC, GPQA, AIME and\nLiveCodeBench) show that the proposed method is consistently effective on 11\ncutting-edge reasoning LLMs of varying series and sizes, reducing the length of\nCoT sequences by an average of 19.1% to 80.1% while improving accuracy by 0.3%\nto 5.0%.",
      "tldr_zh": "该研究针对大型推理语言模型 (LRLMs) 中长链式思考 (CoT) 的过度思考问题，提出了一种动态早退出方法，让 LLMs 在生成过程中基于模型置信度自我截断 CoT 序列。该方法通过监控潜在推理转折点（如 \"Wait\" tokens），动态终止后续推理链，无需额外训练即可无缝集成到现有 o1-like 推理 LLMs 中。实验在 10 个推理基准（如 GSM8K、MATH-500 和 AIME）上显示，该方法在 11 个不同系列和大小的先进 LLMs 上有效，平均减少 CoT 序列长度 19.1% 到 80.1%，同时提高准确率 0.3% 到 5.0%。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "23 pages, 15 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.15895v2",
      "published_date": "2025-04-22 13:36:53 UTC",
      "updated_date": "2025-05-17 04:09:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:37:53.506046"
    },
    {
      "arxiv_id": "2504.15894v1",
      "title": "Supporting Data-Frame Dynamics in AI-assisted Decision Making",
      "title_zh": "支持 AI 辅助决策中的数据框架动态",
      "authors": [
        "Chengbo Zheng",
        "Tim Miller",
        "Alina Bialkowski",
        "H Peter Soyer",
        "Monika Janda"
      ],
      "abstract": "High stakes decision-making often requires a continuous interplay between\nevolving evidence and shifting hypotheses, a dynamic that is not well supported\nby current AI decision support systems. In this paper, we introduce a\nmixed-initiative framework for AI assisted decision making that is grounded in\nthe data-frame theory of sensemaking and the evaluative AI paradigm. Our\napproach enables both humans and AI to collaboratively construct, validate, and\nadapt hypotheses. We demonstrate our framework with an AI-assisted skin cancer\ndiagnosis prototype that leverages a concept bottleneck model to facilitate\ninterpretable interactions and dynamic updates to diagnostic hypotheses.",
      "tldr_zh": "本论文针对高风险决策中证据和假设动态互动的不足，提出一个基于data-frame theory of sensemaking和evaluative AI paradigm的混合主动框架。该框架支持人类和AI协作构建、验证和适应假设，从而提升决策过程的灵活性。在一个AI辅助皮肤癌诊断原型中，通过concept bottleneck model实现可解释交互和动态更新假设，展示了框架在实际应用中的有效性。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "Presented at the 2025 ACM Workshop on Human-AI Interaction for\n  Augmented Reasoning, Report Number: CHI25-WS-AUGMENTED-REASONING",
      "pdf_url": "http://arxiv.org/pdf/2504.15894v1",
      "published_date": "2025-04-22 13:36:06 UTC",
      "updated_date": "2025-04-22 13:36:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:38:04.573503"
    },
    {
      "arxiv_id": "2504.15883v1",
      "title": "Integrating Non-Linear Radon Transformation for Diabetic Retinopathy Grading",
      "title_zh": "整合非线性 Radon 变换用于糖尿病视网膜病变分级",
      "authors": [
        "Farida Mohsen",
        "Samir Belhaouari",
        "Zubair Shah"
      ],
      "abstract": "Diabetic retinopathy is a serious ocular complication that poses a\nsignificant threat to patients' vision and overall health. Early detection and\naccurate grading are essential to prevent vision loss. Current automatic\ngrading methods rely heavily on deep learning applied to retinal fundus images,\nbut the complex, irregular patterns of lesions in these images, which vary in\nshape and distribution, make it difficult to capture subtle changes. This study\nintroduces RadFuse, a multi-representation deep learning framework that\nintegrates non-linear RadEx-transformed sinogram images with traditional fundus\nimages to enhance diabetic retinopathy detection and grading. Our RadEx\ntransformation, an optimized non-linear extension of the Radon transform,\ngenerates sinogram representations to capture complex retinal lesion patterns.\nBy leveraging both spatial and transformed domain information, RadFuse enriches\nthe feature set available to deep learning models, improving the\ndifferentiation of severity levels. We conducted extensive experiments on two\nbenchmark datasets, APTOS-2019 and DDR, using three convolutional neural\nnetworks (CNNs): ResNeXt-50, MobileNetV2, and VGG19. RadFuse showed significant\nimprovements over fundus-image-only models across all three CNN architectures\nand outperformed state-of-the-art methods on both datasets. For severity\ngrading across five stages, RadFuse achieved a quadratic weighted kappa of\n93.24%, an accuracy of 87.07%, and an F1-score of 87.17%. In binary\nclassification between healthy and diabetic retinopathy cases, the method\nreached an accuracy of 99.09%, precision of 98.58%, and recall of 99.6%,\nsurpassing previously established models. These results demonstrate RadFuse's\ncapacity to capture complex non-linear features, advancing diabetic retinopathy\nclassification and promoting the integration of advanced mathematical\ntransforms in medical image analysis.",
      "tldr_zh": "本研究针对糖尿病视网膜病变（Diabetic Retinopathy）的早期检测和分级问题，提出RadFuse框架，该框架将非线性RadEx变换生成的正弦图（sinogram）表示与传统视网膜眼底图像相结合，增强深度学习模型对复杂病变模式的捕捉。RadEx作为Radon transform的优化扩展，能够捕获空间和变换域信息，从而改善病变严重程度的区分。实验在APTOS-2019和DDR数据集上使用ResNeXt-50、MobileNetV2和VGG19等CNNs进行评估，结果显示RadFuse比仅使用眼底图像的模型提升显著，在五级严重分级中达到quadratic weighted kappa 93.24%、准确率87.07%和F1-score 87.17%，并在二元分类中实现准确率99.09%，证明了其在医疗图像分析中的先进潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.15883v1",
      "published_date": "2025-04-22 13:27:28 UTC",
      "updated_date": "2025-04-22 13:27:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:38:18.556916"
    },
    {
      "arxiv_id": "2504.15876v2",
      "title": "Bidirectional Task-Motion Planning Based on Hierarchical Reinforcement Learning for Strategic Confrontation",
      "title_zh": "基于分层强化学习的双向任务-运动规划，用于战略对抗",
      "authors": [
        "Qizhen Wu",
        "Lei Chen",
        "Kexin Liu",
        "Jinhu Lü"
      ],
      "abstract": "In swarm robotics, confrontation scenarios, including strategic\nconfrontations, require efficient decision-making that integrates discrete\ncommands and continuous actions. Traditional task and motion planning methods\nseparate decision-making into two layers, but their unidirectional structure\nfails to capture the interdependence between these layers, limiting\nadaptability in dynamic environments. Here, we propose a novel bidirectional\napproach based on hierarchical reinforcement learning, enabling dynamic\ninteraction between the layers. This method effectively maps commands to task\nallocation and actions to path planning, while leveraging cross-training\ntechniques to enhance learning across the hierarchical framework. Furthermore,\nwe introduce a trajectory prediction model that bridges abstract task\nrepresentations with actionable planning goals. In our experiments, it achieves\nover 80% in confrontation win rate and under 0.01 seconds in decision time,\noutperforming existing approaches. Demonstrations through large-scale tests and\nreal-world robot experiments further emphasize the generalization capabilities\nand practical applicability of our method.",
      "tldr_zh": "本研究针对群机器人对抗场景中任务和动作规划的相互依赖问题，提出了一种基于分层强化学习(hierarchical reinforcement learning)的双向任务-动作规划(bidirectional task-motion planning)方法。该方法允许决策层间动态交互，将离散命令映射到任务分配，并结合动作规划和轨迹预测模型来桥接抽象任务与实际目标，同时利用交叉训练技术提升整体学习效率。在实验中，该方法在对抗场景中实现超过80%的胜率和小于0.01秒的决策时间，优于现有方法，并通过大规模测试和真实机器人实验证明了其泛化能力和实际适用性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.15876v2",
      "published_date": "2025-04-22 13:22:58 UTC",
      "updated_date": "2025-04-23 15:00:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:38:29.349760"
    },
    {
      "arxiv_id": "2504.16148v1",
      "title": "Towards responsible AI for education: Hybrid human-AI to confront the Elephant in the room",
      "title_zh": "迈向负责任的教育AI：混合人类",
      "authors": [
        "Danial Hooshyar",
        "Gustav Šír",
        "Yeongwook Yang",
        "Eve Kikas",
        "Raija Hämäläinen",
        "Tommi Kärkkäinen",
        "Dragan Gašević",
        "Roger Azevedo"
      ],
      "abstract": "Despite significant advancements in AI-driven educational systems and ongoing\ncalls for responsible AI for education, several critical issues remain\nunresolved -- acting as the elephant in the room within AI in education,\nlearning analytics, educational data mining, learning sciences, and educational\npsychology communities. This critical analysis identifies and examines nine\npersistent challenges that continue to undermine the fairness, transparency,\nand effectiveness of current AI methods and applications in education. These\ninclude: (1) the lack of clarity around what AI for education truly means --\noften ignoring the distinct purposes, strengths, and limitations of different\nAI families -- and the trend of equating it with domain-agnostic,\ncompany-driven large language models; (2) the widespread neglect of essential\nlearning processes such as motivation, emotion, and (meta)cognition in\nAI-driven learner modelling and their contextual nature; (3) limited\nintegration of domain knowledge and lack of stakeholder involvement in AI\ndesign and development; (4) continued use of non-sequential machine learning\nmodels on temporal educational data; (5) misuse of non-sequential metrics to\nevaluate sequential models; (6) use of unreliable explainable AI methods to\nprovide explanations for black-box models; (7) ignoring ethical guidelines in\naddressing data inconsistencies during model training; (8) use of mainstream AI\nmethods for pattern discovery and learning analytics without systematic\nbenchmarking; and (9) overemphasis on global prescriptions while overlooking\nlocalised, student-specific recommendations. Supported by theoretical and\nempirical research, we demonstrate how hybrid AI methods -- specifically\nneural-symbolic AI -- can address the elephant in the room and serve as the\nfoundation for responsible, trustworthy AI systems in education.",
      "tldr_zh": "这篇论文分析了AI在教育领域的九大关键挑战，这些问题如“elephant in the room”般被忽视，包括AI定义的模糊、忽略学习者的动机和情感、缺乏领域知识整合，以及使用不当的机器学习模型和评估指标等。这些挑战削弱了AI的教育应用在公平性、透明度和有效性方面的表现。为应对这些问题，论文提出采用hybrid human-AI方法，特别是neural-symbolic AI，通过理论和实证研究支持，实现负责任且可信赖的AI系统，最终提升教育AI的整体可靠性。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.16148v1",
      "published_date": "2025-04-22 13:20:43 UTC",
      "updated_date": "2025-04-22 13:20:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:38:40.232372"
    },
    {
      "arxiv_id": "2504.15865v2",
      "title": "MedNNS: Supernet-based Medical Task-Adaptive Neural Network Search",
      "title_zh": "翻译失败",
      "authors": [
        "Lotfi Abdelkrim Mecharbat",
        "Ibrahim Almakky",
        "Martin Takac",
        "Mohammad Yaqub"
      ],
      "abstract": "Deep learning (DL) has achieved remarkable progress in the field of medical\nimaging. However, adapting DL models to medical tasks remains a significant\nchallenge, primarily due to two key factors: (1) architecture selection, as\ndifferent tasks necessitate specialized model designs, and (2) weight\ninitialization, which directly impacts the convergence speed and final\nperformance of the models. Although transfer learning from ImageNet is a widely\nadopted strategy, its effectiveness is constrained by the substantial\ndifferences between natural and medical images. To address these challenges, we\nintroduce Medical Neural Network Search (MedNNS), the first Neural Network\nSearch framework for medical imaging applications. MedNNS jointly optimizes\narchitecture selection and weight initialization by constructing a meta-space\nthat encodes datasets and models based on how well they perform together. We\nbuild this space using a Supernetwork-based approach, expanding the model zoo\nsize by 51x times over previous state-of-the-art (SOTA) methods. Moreover, we\nintroduce rank loss and Fr\\'echet Inception Distance (FID) loss into the\nconstruction of the space to capture inter-model and inter-dataset\nrelationships, thereby achieving more accurate alignment in the meta-space.\nExperimental results across multiple datasets demonstrate that MedNNS\nsignificantly outperforms both ImageNet pre-trained DL models and SOTA Neural\nArchitecture Search (NAS) methods, achieving an average accuracy improvement of\n1.7% across datasets while converging substantially faster. The code and the\nprocessed meta-space is available at https://github.com/BioMedIA-MBZUAI/MedNNS.",
      "tldr_zh": "该论文提出 MedNNS，一种基于 Supernetwork 的医疗任务自适应神经网络搜索框架，旨在解决深度学习（DL）在医疗成像中面临的架构选择和权重初始化挑战，这些问题导致从 ImageNet 转移学习效果有限。MedNNS 通过构建一个基于数据集和模型性能的 meta-space 联合优化架构和权重，并引入 rank loss 和 Fréchet Inception Distance (FID) loss 来捕捉模型与数据集间的关系，从而扩展模型库大小比现有 SOTA 方法多 51 倍。实验结果显示，MedNNS 在多个数据集上比 ImageNet 预训练模型和 SOTA Neural Architecture Search (NAS) 方法平均准确率提高 1.7%，并显著加速模型收敛。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.15865v2",
      "published_date": "2025-04-22 13:04:40 UTC",
      "updated_date": "2025-04-23 05:28:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:38:54.510236"
    },
    {
      "arxiv_id": "2504.21020v1",
      "title": "Context-Enhanced Contrastive Search for Improved LLM Text Generation",
      "title_zh": "基于上下文的对比搜索用于提升LLM文本生成",
      "authors": [
        "Jaydip Sen",
        "Rohit Pandey",
        "Hetvi Waghela"
      ],
      "abstract": "Recently, Large Language Models (LLMs) have demonstrated remarkable\nadvancements in Natural Language Processing (NLP). However, generating\nhigh-quality text that balances coherence, diversity, and relevance remains\nchallenging. Traditional decoding methods, such as bean search and top-k\nsampling, often struggle with either repetitive or incoherent outputs,\nparticularly in tasks that require long-form text generation. To address these\nlimitations, the paper proposes a novel enhancement of the well-known\nContrastive Search algorithm, Context-Enhanced Contrastive Search (CECS) with\ncontextual calibration. The proposed scheme introduces several novelties\nincluding dynamic contextual importance weighting, multi-level Contrastive\nSearch, and adaptive temperature control, to optimize the balance between\nfluency, creativity, and precision. The performance of CECS is evaluated using\nseveral standard metrics such as BLEU, ROUGE, and semantic similarity.\nExperimental results demonstrate significant improvements in both coherence and\nrelevance of the generated texts by CECS outperforming the existing Contrastive\nSearch techniques. The proposed algorithm has several potential applications in\nthe real world including legal document drafting, customer service chatbots,\nand content marketing.",
      "tldr_zh": "该论文针对大语言模型(LLMs)在文本生成中存在的连贯性、多样性和相关性平衡问题，提出了一种改进的Contrastive Search算法——Context-Enhanced Contrastive Search(CECS)。CECS引入动态上下文重要性加权、多级Contrastive Search和自适应温度控制等创新机制，以优化生成的文本流畅性、创造性和精确性。实验结果显示，CECS在使用BLEU、ROUGE和语义相似性等指标评估时，显著提升了文本的连贯性和相关性，优于现有技术。该算法具有广泛应用潜力，包括法律文件起草、客户服务聊天机器人和内容营销等领域。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "This is the pre-review version of our paper, which has been accepted\n  for publication in the IEEE 6th International Conference on Emerging\n  Technologies (INCET). The conference will be organized at Belgaum, India,\n  from May 24 to 26, 2025. This is not the final camera-ready paper, which will\n  be available on IEEE Xplore. The paper is 9 pages long, and it contains 2\n  Figures and 4 Tables",
      "pdf_url": "http://arxiv.org/pdf/2504.21020v1",
      "published_date": "2025-04-22 13:00:14 UTC",
      "updated_date": "2025-04-22 13:00:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:39:06.259745"
    },
    {
      "arxiv_id": "2504.16145v1",
      "title": "Progressive Language-guided Visual Learning for Multi-Task Visual Grounding",
      "title_zh": "翻译失败",
      "authors": [
        "Jingchao Wang",
        "Hong Wang",
        "Wenlong Zhang",
        "Kunhua Ji",
        "Dingjiang Huang",
        "Yefeng Zheng"
      ],
      "abstract": "Multi-task visual grounding (MTVG) includes two sub-tasks, i.e., Referring\nExpression Comprehension (REC) and Referring Expression Segmentation (RES). The\nexisting representative approaches generally follow the research pipeline which\nmainly consists of three core procedures, including independent feature\nextraction for visual and linguistic modalities, respectively, cross-modal\ninteraction module, and independent prediction heads for different sub-tasks.\nAlbeit achieving remarkable performance, this research line has two\nlimitations: 1) The linguistic content has not been fully injected into the\nentire visual backbone for boosting more effective visual feature extraction\nand it needs an extra cross-modal interaction module; 2) The relationship\nbetween REC and RES tasks is not effectively exploited to help the\ncollaborative prediction for more accurate output. To deal with these problems,\nin this paper, we propose a Progressive Language-guided Visual Learning\nframework for multi-task visual grounding, called PLVL, which not only finely\nmine the inherent feature expression of the visual modality itself but also\nprogressively inject the language information to help learn linguistic-related\nvisual features. In this manner, our PLVL does not need additional cross-modal\nfusion module while fully introducing the language guidance. Furthermore, we\nanalyze that the localization center for REC would help identify the\nto-be-segmented object region for RES to some extent. Inspired by this\ninvestigation, we design a multi-task head to accomplish collaborative\npredictions for these two sub-tasks. Extensive experiments conducted on several\nbenchmark datasets comprehensively substantiate that our PLVL obviously\noutperforms the representative methods in both REC and RES tasks.\nhttps://github.com/jcwang0602/PLVL",
      "tldr_zh": "这篇论文针对多任务视觉 grounding (MTVG) 的子任务 Referring Expression Comprehension (REC) 和 Referring Expression Segmentation (RES)，提出了 Progressive Language-guided Visual Learning (PLVL) 框架，以解决现有方法中语言信息注入不足和任务间关系未充分利用的问题。PLVL 通过逐步注入语言指导到视觉特征提取中，实现了无需额外跨模态融合模块的协同学习，并设计了多任务预测头来利用 REC 的定位中心辅助 RES 的对象区域识别。实验结果显示，在多个基准数据集上，PLVL 在 REC 和 RES 任务上明显优于代表性方法，提供了一个更有效的多任务解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.16145v1",
      "published_date": "2025-04-22 12:48:12 UTC",
      "updated_date": "2025-04-22 12:48:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:39:17.680424"
    },
    {
      "arxiv_id": "2504.15847v1",
      "title": "CARE: Compatibility-Aware Incentive Mechanisms for Federated Learning with Budgeted Requesters",
      "title_zh": "翻译失败",
      "authors": [
        "Xiang Liu",
        "Hau Chan",
        "Minming Li",
        "Xianlong Zeng",
        "Chenchen Fu",
        "Weiwei Wu"
      ],
      "abstract": "Federated learning (FL) is a promising approach that allows requesters (\\eg,\nservers) to obtain local training models from workers (e.g., clients). Since\nworkers are typically unwilling to provide training services/models freely and\nvoluntarily, many incentive mechanisms in FL are designed to incentivize\nparticipation by offering monetary rewards from requesters. However, existing\nstudies neglect two crucial aspects of real-world FL scenarios. First, workers\ncan possess inherent incompatibility characteristics (e.g., communication\nchannels and data sources), which can lead to degradation of FL efficiency\n(e.g., low communication efficiency and poor model generalization). Second, the\nrequesters are budgeted, which limits the amount of workers they can hire for\ntheir tasks. In this paper, we investigate the scenario in FL where multiple\nbudgeted requesters seek training services from incompatible workers with\nprivate training costs. We consider two settings: the cooperative budget\nsetting where requesters cooperate to pool their budgets to improve their\noverall utility and the non-cooperative budget setting where each requester\noptimizes their utility within their own budgets. To address efficiency\ndegradation caused by worker incompatibility, we develop novel\ncompatibility-aware incentive mechanisms, CARE-CO and CARE-NO, for both\nsettings to elicit true private costs and determine workers to hire for\nrequesters and their rewards while satisfying requester budget constraints. Our\nmechanisms guarantee individual rationality, truthfulness, budget feasibility,\nand approximation performance. We conduct extensive experiments using\nreal-world datasets to show that the proposed mechanisms significantly\noutperform existing baselines.",
      "tldr_zh": "本论文针对Federated Learning (FL)中的激励机制问题，考虑了工作者之间的不兼容性（如通信渠道和数据来源）可能导致效率下降，以及请求者预算有限的现实场景。论文提出两种兼容性感知激励机制：CARE-CO（合作预算设置）和CARE-NO（非合作预算设置），这些机制能揭示工作者的真实私有成本、决定雇佣对象和奖励分配，同时保证个体理性、真实性、预算可行性和近似性能。通过在真实数据集上的广泛实验，CARE机制显著优于现有基线，提升了FL的整体效率和实用性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.15847v1",
      "published_date": "2025-04-22 12:42:45 UTC",
      "updated_date": "2025-04-22 12:42:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:39:30.177411"
    },
    {
      "arxiv_id": "2504.15829v1",
      "title": "Generative AI for Research Data Processing: Lessons Learnt From Three Use Cases",
      "title_zh": "翻译失败",
      "authors": [
        "Modhurita Mitra",
        "Martine G. de Vos",
        "Nicola Cortinovis",
        "Dawa Ometto"
      ],
      "abstract": "There has been enormous interest in generative AI since ChatGPT was launched\nin 2022. However, there are concerns about the accuracy and consistency of the\noutputs of generative AI. We have carried out an exploratory study on the\napplication of this new technology in research data processing. We identified\ntasks for which rule-based or traditional machine learning approaches were\ndifficult to apply, and then performed these tasks using generative AI.\n  We demonstrate the feasibility of using the generative AI model Claude 3 Opus\nin three research projects involving complex data processing tasks:\n  1) Information extraction: We extract plant species names from historical\nseedlists (catalogues of seeds) published by botanical gardens.\n  2) Natural language understanding: We extract certain data points (name of\ndrug, name of health indication, relative effectiveness, cost-effectiveness,\netc.) from documents published by Health Technology Assessment organisations in\nthe EU.\n  3) Text classification: We assign industry codes to projects on the\ncrowdfunding website Kickstarter.\n  We share the lessons we learnt from these use cases: How to determine if\ngenerative AI is an appropriate tool for a given data processing task, and if\nso, how to maximise the accuracy and consistency of the results obtained.",
      "tldr_zh": "该研究探索了生成式 AI 在研究数据处理中的应用，针对传统方法难以处理的复杂任务，使用 Claude 3 Opus 模型进行了三个用例的验证：（1）从历史种子目录中提取植物物种名称，（2）从欧盟健康技术评估文档中提取药物相关数据点，如药物名称、健康指示和成本效益，（3）为 Kickstarter 项目分配行业代码。结果证明了生成式 AI 的可行性，但突出了准确性和一致性问题。论文分享了关键经验教训，包括如何评估生成式 AI 的适用性以及优化输出准确性的策略。",
      "categories": [
        "cs.AI",
        "68T50",
        "I.2.7"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages, 4 figures, 6 tables. Published in Proceedings of the 2024\n  IEEE 20th International Conference on e-Science (e-Science), Osaka, Japan",
      "pdf_url": "http://arxiv.org/pdf/2504.15829v1",
      "published_date": "2025-04-22 12:21:07 UTC",
      "updated_date": "2025-04-22 12:21:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:39:40.597966"
    },
    {
      "arxiv_id": "2504.15827v1",
      "title": "DualOptim: Enhancing Efficacy and Stability in Machine Unlearning with Dual Optimizers",
      "title_zh": "翻译失败",
      "authors": [
        "Xuyang Zhong",
        "Haochen Luo",
        "Chen Liu"
      ],
      "abstract": "Existing machine unlearning (MU) approaches exhibit significant sensitivity\nto hyperparameters, requiring meticulous tuning that limits practical\ndeployment. In this work, we first empirically demonstrate the instability and\nsuboptimal performance of existing popular MU methods when deployed in\ndifferent scenarios. To address this issue, we propose Dual Optimizer\n(DualOptim), which incorporates adaptive learning rate and decoupled momentum\nfactors. Empirical and theoretical evidence demonstrates that DualOptim\ncontributes to effective and stable unlearning. Through extensive experiments,\nwe show that DualOptim can significantly boost MU efficacy and stability across\ndiverse tasks, including image classification, image generation, and large\nlanguage models, making it a versatile approach to empower existing MU\nalgorithms.",
      "tldr_zh": "本文研究发现，现有的机器取消学习 (Machine Unlearning, MU) 方法对超参数高度敏感，导致在不同场景下不稳定且性能不佳。作者提出 DualOptim，一种采用自适应学习率和解耦动量因子的双优化器框架，通过实证和理论证据证明其能有效提升 MU 的稳定性和效能。在广泛实验中，DualOptim 在图像分类、图像生成和大型语言模型等任务上显著改善了现有算法的表现，使其成为一种多功能增强工具。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.15827v1",
      "published_date": "2025-04-22 12:18:26 UTC",
      "updated_date": "2025-04-22 12:18:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:39:53.024814"
    },
    {
      "arxiv_id": "2504.15823v1",
      "title": "Human-Imperceptible Physical Adversarial Attack for NIR Face Recognition Models",
      "title_zh": "翻译失败",
      "authors": [
        "Songyan Xie",
        "Jinghang Wen",
        "Encheng Su",
        "Qiucheng Yu"
      ],
      "abstract": "Near-infrared (NIR) face recognition systems, which can operate effectively\nin low-light conditions or in the presence of makeup, exhibit vulnerabilities\nwhen subjected to physical adversarial attacks. To further demonstrate the\npotential risks in real-world applications, we design a novel, stealthy, and\npractical adversarial patch to attack NIR face recognition systems in a\nblack-box setting. We achieved this by utilizing human-imperceptible\ninfrared-absorbing ink to generate multiple patches with digitally optimized\nshapes and positions for infrared images. To address the optimization mismatch\nbetween digital and real-world NIR imaging, we develop a light reflection model\nfor human skin to minimize pixel-level discrepancies by simulating NIR light\nreflection.\n  Compared to state-of-the-art (SOTA) physical attacks on NIR face recognition\nsystems, the experimental results show that our method improves the attack\nsuccess rate in both digital and physical domains, particularly maintaining\neffectiveness across various face postures. Notably, the proposed approach\noutperforms SOTA methods, achieving an average attack success rate of 82.46% in\nthe physical domain across different models, compared to 64.18% for existing\nmethods. The artifact is available at\nhttps://anonymous.4open.science/r/Human-imperceptible-adversarial-patch-0703/.",
      "tldr_zh": "这篇论文提出了一种人类难以察觉的物理对抗攻击，针对近红外 (NIR) 人脸识别模型，旨在暴露其在真实场景下的漏洞。研究团队使用红外吸收墨水生成优化形状和位置的对抗贴纸，并开发了一个光反射模型来模拟人类皮肤的 NIR 光反射，从而减少数字与物理成像的差异。实验结果显示，该方法在物理域的攻击成功率平均达到 82.46%，比现有 SOTA 方法的 64.18% 显著提升，并在各种面部姿势下保持高有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.15823v1",
      "published_date": "2025-04-22 12:10:25 UTC",
      "updated_date": "2025-04-22 12:10:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:40:05.886698"
    },
    {
      "arxiv_id": "2504.15812v1",
      "title": "Fusing Reward and Dueling Feedback in Stochastic Bandits",
      "title_zh": "翻译失败",
      "authors": [
        "Xuchuang Wang",
        "Qirun Zeng",
        "Jinhang Zuo",
        "Xutong Liu",
        "Mohammad Hajiesmaili",
        "John C. S. Lui",
        "Adam Wierman"
      ],
      "abstract": "This paper investigates the fusion of absolute (reward) and relative\n(dueling) feedback in stochastic bandits, where both feedback types are\ngathered in each decision round. We derive a regret lower bound, demonstrating\nthat an efficient algorithm may incur only the smaller among the reward and\ndueling-based regret for each individual arm. We propose two fusion approaches:\n(1) a simple elimination fusion algorithm that leverages both feedback types to\nexplore all arms and unifies collected information by sharing a common\ncandidate arm set, and (2) a decomposition fusion algorithm that selects the\nmore effective feedback to explore the corresponding arms and randomly assigns\none feedback type for exploration and the other for exploitation in each round.\nThe elimination fusion experiences a suboptimal multiplicative term of the\nnumber of arms in regret due to the intrinsic suboptimality of dueling\nelimination. In contrast, the decomposition fusion achieves regret matching the\nlower bound up to a constant under a common assumption. Extensive experiments\nconfirm the efficacy of our algorithms and theoretical results.",
      "tldr_zh": "这篇论文探讨了在随机博弈(stochastic bandits)环境中融合绝对反馈(reward feedback)和相对反馈(dueling feedback)的机制，每轮决策均收集两种反馈。研究者推导了遗憾(regret)下界，并提出两种融合算法：简单消除融合算法，通过共享候选臂集利用两种反馈探索所有臂；以及分解融合算法，选择更有效的反馈进行探索，并随机分配反馈类型以优化利用。实验结果显示，分解融合算法在常见假设下实现了与下界相匹配的遗憾性能，验证了算法的有效性和理论分析。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.15812v1",
      "published_date": "2025-04-22 11:51:20 UTC",
      "updated_date": "2025-04-22 11:51:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:40:16.696170"
    },
    {
      "arxiv_id": "2504.15806v2",
      "title": "DAE-KAN: A Kolmogorov-Arnold Network Model for High-Index Differential-Algebraic Equations",
      "title_zh": "翻译失败",
      "authors": [
        "Kai Luo",
        "Juan Tang",
        "Mingchao Cai",
        "Xiaoqing Zeng",
        "Manqi Xie",
        "Ming Yan"
      ],
      "abstract": "Kolmogorov-Arnold Networks (KANs) have emerged as a promising alternative to\nMulti-layer Perceptrons (MLPs) due to their superior function-fitting abilities\nin data-driven modeling. In this paper, we propose a novel framework, DAE-KAN,\nfor solving high-index differential-algebraic equations (DAEs) by integrating\nKANs with Physics-Informed Neural Networks (PINNs). This framework not only\npreserves the ability of traditional PINNs to model complex systems governed by\nphysical laws but also enhances their performance by leveraging the\nfunction-fitting strengths of KANs. Numerical experiments demonstrate that for\nDAE systems ranging from index-1 to index-3, DAE-KAN reduces the absolute\nerrors of both differential and algebraic variables by 1 to 2 orders of\nmagnitude compared to traditional PINNs. To assess the effectiveness of this\napproach, we analyze the drift-off error and find that both PINNs and DAE-KAN\noutperform classical numerical methods in controlling this phenomenon. Our\nresults highlight the potential of neural network methods, particularly\nDAE-KAN, in solving high-index DAEs with substantial computational accuracy and\ngeneralization, offering a promising solution for challenging partial\ndifferential-algebraic equations.",
      "tldr_zh": "本文提出 DAE-KAN 框架，将 Kolmogorov-Arnold Networks (KANs) 整合到 Physics-Informed Neural Networks (PINNs) 中，用于解决高阶 Differential-Algebraic Equations (DAEs)。该框架保留了 PINNs 建模复杂物理系统的能力，同时利用 KANs 的优越函数拟合性能来提升整体效果。数值实验显示，DAE-KAN 在 index-1 到 index-3 的 DAE 系统上，将微分和代数变量的绝对误差降低了 1 到 2 个数量级，并比传统数值方法更有效地控制漂移误差 (drift-off error)。这项研究突显了 DAE-KAN 在高阶 DAEs 求解中的计算准确性和泛化潜力，为处理挑战性的偏微分代数方程提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.15806v2",
      "published_date": "2025-04-22 11:42:02 UTC",
      "updated_date": "2025-04-23 06:21:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:40:31.692077"
    },
    {
      "arxiv_id": "2504.15804v1",
      "title": "Insights from Verification: Training a Verilog Generation LLM with Reinforcement Learning with Testbench Feedback",
      "title_zh": "翻译失败",
      "authors": [
        "Ning Wang",
        "Bingkun Yao",
        "Jie Zhou",
        "Yuchen Hu",
        "Xi Wang",
        "Nan Guan",
        "Zhe Jiang"
      ],
      "abstract": "Large language models (LLMs) have shown strong performance in Verilog\ngeneration from natural language description. However, ensuring the functional\ncorrectness of the generated code remains a significant challenge. This paper\nintroduces a method that integrates verification insights from testbench into\nthe training of Verilog generation LLMs, aligning the training with the\nfundamental goal of hardware design: functional correctness. The main obstacle\nin using LLMs for Verilog code generation is the lack of sufficient functional\nverification data, particularly testbenches paired with design specifications\nand code. To address this problem, we introduce an automatic testbench\ngeneration pipeline that decomposes the process and uses feedback from the\nVerilog compiler simulator (VCS) to reduce hallucination and ensure\ncorrectness. We then use the testbench to evaluate the generated codes and\ncollect them for further training, where verification insights are introduced.\nOur method applies reinforcement learning (RL), specifically direct preference\noptimization (DPO), to align Verilog code generation with functional\ncorrectness by training preference pairs based on testbench outcomes. In\nevaluations on VerilogEval-Machine, VerilogEval-Human, RTLLM v1.1, RTLLM v2,\nand VerilogEval v2, our approach consistently outperforms state-of-the-art\nbaselines in generating functionally correct Verilog code. We open source all\ntraining code, data, and models at\nhttps://anonymous.4open.science/r/VeriPrefer-E88B.",
      "tldr_zh": "本文提出一种将验证反馈整合到 Verilog 生成 LLMs 训练中的方法，旨在提升代码的功能正确性，通过自动 testbench 生成管道和 Verilog 编译器模拟器 (VCS) 反馈来减少幻觉。核心技术采用强化学习 (RL)，specifically direct preference optimization (DPO)，基于 testbench 结果训练偏好对，以优化模型对硬件设计的适应性。在 VerilogEval-Machine、VerilogEval-Human、RTLLM v1.1 等基准测试中，该方法显著优于现有基线，并开源了所有训练代码、数据和模型。",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "primary_category": "cs.AR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.15804v1",
      "published_date": "2025-04-22 11:38:14 UTC",
      "updated_date": "2025-04-22 11:38:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:40:41.515409"
    },
    {
      "arxiv_id": "2504.15801v1",
      "title": "A closer look at how large language models trust humans: patterns and biases",
      "title_zh": "深入审视大型语言模型信任人类的模式与偏见",
      "authors": [
        "Valeria Lerman",
        "Yaniv Dover"
      ],
      "abstract": "As large language models (LLMs) and LLM-based agents increasingly interact\nwith humans in decision-making contexts, understanding the trust dynamics\nbetween humans and AI agents becomes a central concern. While considerable\nliterature studies how humans trust AI agents, it is much less understood how\nLLM-based agents develop effective trust in humans. LLM-based agents likely\nrely on some sort of implicit effective trust in trust-related contexts (e.g.,\nevaluating individual loan applications) to assist and affect decision making.\nUsing established behavioral theories, we develop an approach that studies\nwhether LLMs trust depends on the three major trustworthiness dimensions:\ncompetence, benevolence and integrity of the human subject. We also study how\ndemographic variables affect effective trust. Across 43,200 simulated\nexperiments, for five popular language models, across five different scenarios\nwe find that LLM trust development shows an overall similarity to human trust\ndevelopment. We find that in most, but not all cases, LLM trust is strongly\npredicted by trustworthiness, and in some cases also biased by age, religion\nand gender, especially in financial scenarios. This is particularly true for\nscenarios common in the literature and for newer models. While the overall\npatterns align with human-like mechanisms of effective trust formation,\ndifferent models exhibit variation in how they estimate trust; in some cases,\ntrustworthiness and demographic factors are weak predictors of effective trust.\nThese findings call for a better understanding of AI-to-human trust dynamics\nand monitoring of biases and trust development patterns to prevent unintended\nand potentially harmful outcomes in trust-sensitive applications of AI.",
      "tldr_zh": "本研究探讨大型语言模型(LLMs)如何发展对人类的有效信任，聚焦于信任模式和偏见，通过考察人类的competence（能力）、benevolence（善意）和integrity（诚信）等维度，以及人口统计变量如年龄、宗教和性别的影响。研究者基于行为理论，进行了43,200次模拟实验，涉及五种流行LLMs和五种场景，发现LLMs的信任发展整体类似于人类，但常受 trustworthiness 驱动，并在金融场景中表现出明显偏见。不同模型间存在差异，新模型更易受这些因素影响，这呼吁加强对AI对人类信任动态的监控，以防范潜在有害结果。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.15801v1",
      "published_date": "2025-04-22 11:31:50 UTC",
      "updated_date": "2025-04-22 11:31:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:40:55.191294"
    },
    {
      "arxiv_id": "2504.18572v1",
      "title": "BELL: Benchmarking the Explainability of Large Language Models",
      "title_zh": "BELL：大型语言模型可解释性的基准测试",
      "authors": [
        "Syed Quiser Ahmed",
        "Bharathi Vokkaliga Ganesh",
        "Jagadish Babu P",
        "Karthick Selvaraj",
        "ReddySiva Naga Parvathi Devi",
        "Sravya Kappala"
      ],
      "abstract": "Large Language Models have demonstrated remarkable capabilities in natural\nlanguage processing, yet their decision-making processes often lack\ntransparency. This opaqueness raises significant concerns regarding trust,\nbias, and model performance. To address these issues, understanding and\nevaluating the interpretability of LLMs is crucial. This paper introduces a\nstandardised benchmarking technique, Benchmarking the Explainability of Large\nLanguage Models, designed to evaluate the explainability of large language\nmodels.",
      "tldr_zh": "大型语言模型（LLMs）在自然语言处理中表现出色，但其决策过程缺乏透明性，导致信任、偏见和性能方面的担忧。  \n本文引入了一个标准化的基准测试技术，名为 BELL，用于评估 LLMs 的可解释性。  \nBELL 通过系统化的评估方法，帮助研究人员更好地理解和改进模型的透明度，从而提升整体模型性能和可靠性。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.18572v1",
      "published_date": "2025-04-22 11:15:23 UTC",
      "updated_date": "2025-04-22 11:15:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:41:05.028403"
    },
    {
      "arxiv_id": "2504.15791v1",
      "title": "Crisp complexity of fuzzy classifiers",
      "title_zh": "翻译失败",
      "authors": [
        "Raquel Fernandez-Peralta",
        "Javier Fumanal-Idocin",
        "Javier Andreu-Perez"
      ],
      "abstract": "Rule-based systems are a very popular form of explainable AI, particularly in\nthe fuzzy community, where fuzzy rules are widely used for control and\nclassification problems. However, fuzzy rule-based classifiers struggle to\nreach bigger traction outside of fuzzy venues, because users sometimes do not\nknow about fuzzy and because fuzzy partitions are not so easy to interpret in\nsome situations. In this work, we propose a methodology to reduce fuzzy\nrule-based classifiers to crisp rule-based classifiers. We study different\npossible crisp descriptions and implement an algorithm to obtain them. Also, we\nanalyze the complexity of the resulting crisp classifiers. We believe that our\nresults can help both fuzzy and non-fuzzy practitioners understand better the\nway in which fuzzy rule bases partition the feature space and how easily one\nsystem can be translated to another and vice versa. Our complexity metric can\nalso help to choose between different fuzzy classifiers based on what the\nequivalent crisp partitions look like.",
      "tldr_zh": "本研究针对模糊规则分类器（fuzzy rule-based classifiers）在可解释 AI 中的应用问题，提出一种方法将它们简化为清晰规则分类器（crisp rule-based classifiers），以解决用户对模糊概念的不熟悉和分区解释的困难。研究者探讨了多种可能的清晰描述形式，并开发了相应的算法来实现这种转换，同时分析了结果分类器的复杂性。该方法有助于模糊和非模糊从业者更好地理解模糊规则如何分区特征空间，并通过一个复杂性指标辅助选择最合适的模糊分类器，从而促进系统间的互译和优化。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.15791v1",
      "published_date": "2025-04-22 11:06:25 UTC",
      "updated_date": "2025-04-22 11:06:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:41:16.483333"
    },
    {
      "arxiv_id": "2504.15785v1",
      "title": "WALL-E 2.0: World Alignment by NeuroSymbolic Learning improves World Model-based LLM Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Siyu Zhou",
        "Tianyi Zhou",
        "Yijun Yang",
        "Guodong Long",
        "Deheng Ye",
        "Jing Jiang",
        "Chengqi Zhang"
      ],
      "abstract": "Can we build accurate world models out of large language models (LLMs)? How\ncan world models benefit LLM agents? The gap between the prior knowledge of\nLLMs and the specified environment's dynamics usually bottlenecks LLMs'\nperformance as world models. To bridge the gap, we propose a training-free\n\"world alignment\" that learns an environment's symbolic knowledge complementary\nto LLMs. The symbolic knowledge covers action rules, knowledge graphs, and\nscene graphs, which are extracted by LLMs from exploration trajectories and\nencoded into executable codes to regulate LLM agents' policies. We further\npropose an RL-free, model-based agent \"WALL-E 2.0\" through the model-predictive\ncontrol (MPC) framework. Unlike classical MPC requiring costly optimization on\nthe fly, we adopt an LLM agent as an efficient look-ahead optimizer of future\nsteps' actions by interacting with the neurosymbolic world model. While the LLM\nagent's strong heuristics make it an efficient planner in MPC, the quality of\nits planned actions is also secured by the accurate predictions of the aligned\nworld model. They together considerably improve learning efficiency in a new\nenvironment. On open-world challenges in Mars (Minecraft like) and ALFWorld\n(embodied indoor environments), WALL-E 2.0 significantly outperforms existing\nmethods, e.g., surpassing baselines in Mars by 16.1%-51.6% of success rate and\nby at least 61.7% in score. In ALFWorld, it achieves a new record 98% success\nrate after only 4 iterations.",
      "tldr_zh": "本研究针对大型语言模型(LLMs)作为世界模型时存在的先验知识与环境动态差距问题，提出了一种无训练的“world alignment”方法，通过神经符号学习从探索轨迹中提取行动规则、知识图谱和场景图谱，并编码成可执行代码以补充LLMs的知识。基于此，他们开发了RL-free的模型代理WALL-E 2.0，使用模型预测控制(MPC)框架，其中LLM代理作为高效的lookahead优化器，与神经符号世界模型交互来规划行动，从而提升代理在新环境中的学习效率。实验结果显示，WALL-E 2.0在Mars和ALFWorld等开放世界任务中显著优于基线方法，例如在Mars上成功率提高16.1%-51.6%，在ALFWorld上仅需4次迭代即达到98%的成功率。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Code is available at https://github.com/elated-sawyer/WALL-E",
      "pdf_url": "http://arxiv.org/pdf/2504.15785v1",
      "published_date": "2025-04-22 10:58:27 UTC",
      "updated_date": "2025-04-22 10:58:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:41:30.044516"
    },
    {
      "arxiv_id": "2504.15784v1",
      "title": "Automated Creativity Evaluation for Large Language Models: A Reference-Based Approach",
      "title_zh": "大型语言模型的自动创造力评估：一种基于参考的方法",
      "authors": [
        "Ruizhe Li",
        "Chiwei Zhu",
        "Benfeng Xu",
        "Xiaorui Wang",
        "Zhendong Mao"
      ],
      "abstract": "Creative writing is a key capability of Large Language Models (LLMs), with\npotential applications in literature, storytelling, and various creative\ndomains. However, evaluating the creativity of machine-generated texts remains\na significant challenge, as existing methods either rely on costly manual\nannotations or fail to align closely with human assessments. In this paper, we\npropose an effective automated evaluation method based on the Torrance Test of\nCreative Writing (TTCW), which evaluates creativity as product. Our method\nemploys a reference-based Likert-style approach, scoring generated creative\ntexts relative to high-quality reference texts across various tests.\nExperimental results demonstrate that our method significantly improves the\nalignment between LLM evaluations and human assessments, achieving a pairwise\naccuracy of 0.75 (+15\\%).",
      "tldr_zh": "这篇论文提出了一种基于参考的自动化方法，用于评估大型语言模型(LLMs)的创意写作能力，以解决现有评估方法依赖手动标注或与人类判断不一致的问题。方法借鉴Torrance Test of Creative Writing (TTCW)，采用reference-based Likert-style评分系统，将生成的创意文本与高质量参考文本进行比较。实验结果显示，该方法显著提升了与人类评估的一致性，pairwise accuracy达到0.75，提升了15%。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.15784v1",
      "published_date": "2025-04-22 10:52:23 UTC",
      "updated_date": "2025-04-22 10:52:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:41:41.097270"
    },
    {
      "arxiv_id": "2504.15780v1",
      "title": "TrustGeoGen: Scalable and Formal-Verified Data Engine for Trustworthy Multi-modal Geometric Problem Solving",
      "title_zh": "TrustGeoGen：可扩展且形式验证的数据引擎，用于",
      "authors": [
        "Daocheng Fu",
        "Zijun Chen",
        "Renqiu Xia",
        "Qi Liu",
        "Yuan Feng",
        "Hongbin Zhou",
        "Renrui Zhang",
        "Shiyang Feng",
        "Peng Gao",
        "Junchi Yan",
        "Botian Shi",
        "Bo Zhang",
        "Yu Qiao"
      ],
      "abstract": "Mathematical geometric problem solving (GPS) often requires effective\nintegration of multimodal information and verifiable logical coherence. Despite\nthe fast development of large language models in general problem solving, it\nremains unresolved regarding with both methodology and benchmarks, especially\ngiven the fact that exiting synthetic GPS benchmarks are often not\nself-verified and contain noise and self-contradicted information due to the\nillusion of LLMs. In this paper, we propose a scalable data engine called\nTrustGeoGen for problem generation, with formal verification to provide a\nprincipled benchmark, which we believe lays the foundation for the further\ndevelopment of methods for GPS. The engine synthesizes geometric data through\nfour key innovations: 1) multimodal-aligned generation of diagrams, textual\ndescriptions, and stepwise solutions; 2) formal verification ensuring\nrule-compliant reasoning paths; 3) a bootstrapping mechanism enabling\ncomplexity escalation via recursive state generation and 4) our devised\nGeoExplore series algorithms simultaneously produce multi-solution variants and\nself-reflective backtracking traces. By formal logical verification,\nTrustGeoGen produces GeoTrust-200K dataset with guaranteed modality integrity,\nalong with GeoTrust-test testset. Experiments reveal the state-of-the-art\nmodels achieve only 49.17\\% accuracy on GeoTrust-test, demonstrating its\nevaluation stringency. Crucially, models trained on GeoTrust achieve OOD\ngeneralization on GeoQA, significantly reducing logical inconsistencies\nrelative to pseudo-label annotated by OpenAI-o1. Our code is available at\nhttps://github.com/Alpha-Innovator/TrustGeoGen",
      "tldr_zh": "该论文提出TrustGeoGen，一种可扩展且形式验证的数据引擎，旨在为多模态几何问题求解(GPS)生成可靠基准，解决现有LLMs在方法和数据噪音问题上的不足。TrustGeoGen通过四大创新实现数据合成：多模态对齐生成图表、文本和解决方案；形式验证确保推理路径符合规则；引导机制递归提升问题复杂度；以及GeoExplore系列算法生成多解变体和自反回溯痕迹。实验显示，基于GeoTrust-200K数据集训练的模型在GeoQA上实现出色的OOD泛化，并显著减少逻辑不一致，而SOTA模型在GeoTrust-test上仅达到49.17%的准确率。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.15780v1",
      "published_date": "2025-04-22 10:45:23 UTC",
      "updated_date": "2025-04-22 10:45:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:41:53.396441"
    },
    {
      "arxiv_id": "2504.15779v1",
      "title": "Shannon invariants: A scalable approach to information decomposition",
      "title_zh": "Shannon 不变量：一种可扩展的信息分解方法",
      "authors": [
        "Aaron J. Gutknecht",
        "Fernando E. Rosas",
        "David A. Ehrlich",
        "Abdullah Makkeh",
        "Pedro A. M. Mediano",
        "Michael Wibral"
      ],
      "abstract": "Distributed systems, such as biological and artificial neural networks,\nprocess information via complex interactions engaging multiple subsystems,\nresulting in high-order patterns with distinct properties across scales.\nInvestigating how these systems process information remains challenging due to\ndifficulties in defining appropriate multivariate metrics and ensuring their\nscalability to large systems. To address these challenges, we introduce a novel\nframework based on what we call \"Shannon invariants\" -- quantities that capture\nessential properties of high-order information processing in a way that depends\nonly on the definition of entropy and can be efficiently calculated for large\nsystems. Our theoretical results demonstrate how Shannon invariants can be used\nto resolve long-standing ambiguities regarding the interpretation of widely\nused multivariate information-theoretic measures. Moreover, our practical\nresults reveal distinctive information-processing signatures of various deep\nlearning architectures across layers, which lead to new insights into how these\nsystems process information and how this evolves during training. Overall, our\nframework resolves fundamental limitations in analyzing high-order phenomena\nand offers broad opportunities for theoretical developments and empirical\nanalyses.",
      "tldr_zh": "本研究提出“Shannon invariants”框架，作为一种可扩展的方法，用于分解分布式系统（如生物和人工神经网络）中的高阶信息处理。该框架基于熵（entropy）的定义，捕捉系统交互的关键属性，并能高效应用于大型系统，从而解决现有多元信息理论测量的解释模糊性。实验结果揭示了各种深度学习架构（deep learning architectures）在不同层的信息处理特征，并提供新见解，展示这些系统在训练过程中的演变。总体上，该框架克服了分析高阶现象的根本限制，为理论发展和实证分析开辟了广阔机会。",
      "categories": [
        "cs.IT",
        "cs.AI",
        "cs.LG",
        "math.IT",
        "nlin.AO",
        "physics.data-an"
      ],
      "primary_category": "cs.IT",
      "comment": "16 pages, 4 Figures",
      "pdf_url": "http://arxiv.org/pdf/2504.15779v1",
      "published_date": "2025-04-22 10:41:38 UTC",
      "updated_date": "2025-04-22 10:41:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:42:04.569240"
    },
    {
      "arxiv_id": "2504.15773v2",
      "title": "Clifford Group Equivariant Diffusion Models for 3D Molecular Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Cong Liu",
        "Sharvaree Vadgama",
        "David Ruhe",
        "Erik Bekkers",
        "Patrick Forré"
      ],
      "abstract": "This paper explores leveraging the Clifford algebra's expressive power for\n$\\E(n)$-equivariant diffusion models. We utilize the geometric products between\nClifford multivectors and the rich geometric information encoded in Clifford\nsubspaces in \\emph{Clifford Diffusion Models} (CDMs). We extend the diffusion\nprocess beyond just Clifford one-vectors to incorporate all higher-grade\nmultivector subspaces. The data is embedded in grade-$k$ subspaces, allowing us\nto apply latent diffusion across complete multivectors. This enables CDMs to\ncapture the joint distribution across different subspaces of the algebra,\nincorporating richer geometric information through higher-order features. We\nprovide empirical results for unconditional molecular generation on the QM9\ndataset, showing that CDMs provide a promising avenue for generative modeling.",
      "tldr_zh": "本论文提出Clifford Diffusion Models (CDMs)，利用Clifford algebra的表达力和多矢量几何乘积来构建E(n)-equivariant扩散模型，用于3D分子生成。\nCDMs扩展扩散过程到所有更高等级的多矢量子空间，将数据嵌入grade-k子空间，并应用潜在扩散，以捕捉代数不同子空间的联合分布和更丰富的几何信息。\n实验结果显示，在QM9数据集上的无条件分子生成任务中，CDMs展现出有前景的性能，为生成建模提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "7 pages, 1 figure, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2504.15773v2",
      "published_date": "2025-04-22 10:30:06 UTC",
      "updated_date": "2025-04-24 04:27:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:42:17.420529"
    },
    {
      "arxiv_id": "2504.15766v1",
      "title": "Dynamic Intent Queries for Motion Transformer-based Trajectory Prediction",
      "title_zh": "动态意图查询用于基于 Motion Transformer 的轨迹预测",
      "authors": [
        "Tobias Demmler",
        "Lennart Hartung",
        "Andreas Tamke",
        "Thao Dang",
        "Alexander Hegai",
        "Karsten Haug",
        "Lars Mikelsons"
      ],
      "abstract": "In autonomous driving, accurately predicting the movements of other traffic\nparticipants is crucial, as it significantly influences a vehicle's planning\nprocesses. Modern trajectory prediction models strive to interpret complex\npatterns and dependencies from agent and map data. The Motion Transformer (MTR)\narchitecture and subsequent work define the most accurate methods in common\nbenchmarks such as the Waymo Open Motion Benchmark. The MTR model employs\npre-generated static intention points as initial goal points for trajectory\nprediction. However, the static nature of these points frequently leads to\nmisalignment with map data in specific traffic scenarios, resulting in\nunfeasible or unrealistic goal points. Our research addresses this limitation\nby integrating scene-specific dynamic intention points into the MTR model. This\nadaptation of the MTR model was trained and evaluated on the Waymo Open Motion\nDataset. Our findings demonstrate that incorporating dynamic intention points\nhas a significant positive impact on trajectory prediction accuracy, especially\nfor predictions over long time horizons. Furthermore, we analyze the impact on\nground truth trajectories which are not compliant with the map data or are\nillegal maneuvers.",
      "tldr_zh": "本研究针对自动驾驶中轨迹预测的挑战，提出了一种改进 Motion Transformer (MTR) 模型的方法，通过引入场景特定的动态意图点来取代静态意图点，从而解决目标点与地图数据不匹配的问题。该方法在 Waymo Open Motion Dataset 上进行训练和评估，结果显示动态意图点显著提升了预测准确性，尤其在长期时间范围内的预测上。同时，研究分析了其对不符合地图数据或非法操作的真实轨迹的影响，提供更可靠的交通参与者运动预测。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.15766v1",
      "published_date": "2025-04-22 10:20:35 UTC",
      "updated_date": "2025-04-22 10:20:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:42:28.565287"
    },
    {
      "arxiv_id": "2504.15743v1",
      "title": "iMedic: Towards Smartphone-based Self-Auscultation Tool for AI-Powered Pediatric Respiratory Assessment",
      "title_zh": "翻译失败",
      "authors": [
        "Seung Gyu Jeong",
        "Sung Woo Nam",
        "Seong Kwan Jung",
        "Seong-Eun Kim"
      ],
      "abstract": "Respiratory auscultation is crucial for early detection of pediatric\npneumonia, a condition that can quickly worsen without timely intervention. In\nareas with limited physician access, effective auscultation is challenging. We\npresent a smartphone-based system that leverages built-in microphones and\nadvanced deep learning algorithms to detect abnormal respiratory sounds\nindicative of pneumonia risk. Our end-to-end deep learning framework employs\ndomain generalization to integrate a large electronic stethoscope dataset with\na smaller smartphone-derived dataset, enabling robust feature learning for\naccurate respiratory assessments without expensive equipment. The accompanying\nmobile application guides caregivers in collecting high-quality lung sound\nsamples and provides immediate feedback on potential pneumonia risks. User\nstudies show strong classification performance and high acceptance,\ndemonstrating the system's ability to facilitate proactive interventions and\nreduce preventable childhood pneumonia deaths. By seamlessly integrating into\nubiquitous smartphones, this approach offers a promising avenue for more\nequitable and comprehensive remote pediatric care.",
      "tldr_zh": "该研究引入了 iMedic 系统，一种基于智能手机的自我听诊工具，利用内置麦克风和深度学习算法来检测儿童肺炎相关的异常呼吸音，从而实现 AI-Powered 的儿科呼吸评估。系统采用端到端的深度学习框架，通过 domain generalization 整合大型电子听诊器数据集和小规模智能手机数据集，确保在无昂贵设备的情况下进行准确的特征学习，并提供移动应用指导护理者收集高质量肺音样本及即时风险反馈。用户研究显示了强劲的分类性能和高接受度，证明该系统能促进主动干预，减少儿童肺炎死亡，并为公平的远程儿科护理提供新途径。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.15743v1",
      "published_date": "2025-04-22 09:45:50 UTC",
      "updated_date": "2025-04-22 09:45:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:42:41.061256"
    },
    {
      "arxiv_id": "2504.15724v1",
      "title": "Collaborative Split Federated Learning with Parallel Training and Aggregation",
      "title_zh": "协作式分割联邦学习，采用并行训练和聚合",
      "authors": [
        "Yiannis Papageorgiou",
        "Yannis Thomas",
        "Alexios Filippakopoulos",
        "Ramin Khalili",
        "Iordanis Koutsopoulos"
      ],
      "abstract": "Federated learning (FL) operates based on model exchanges between the server\nand the clients, and it suffers from significant client-side computation and\ncommunication burden. Split federated learning (SFL) arises a promising\nsolution by splitting the model into two parts, that are trained sequentially:\nthe clients train the first part of the model (client-side model) and transmit\nit to the server that trains the second (server-side model). Existing SFL\nschemes though still exhibit long training delays and significant communication\noverhead, especially when clients of different computing capability\nparticipate. Thus, we propose Collaborative-Split Federated Learning~(C-SFL), a\nnovel scheme that splits the model into three parts, namely the model parts\ntrained at the computationally weak clients, the ones trained at the\ncomputationally strong clients, and the ones at the server. Unlike existing\nworks, C-SFL enables parallel training and aggregation of model's parts at the\nclients and at the server, resulting in reduced training delays and\ncommmunication overhead while improving the model's accuracy. Experiments\nverify the multiple gains of C-SFL against the existing schemes.",
      "tldr_zh": "这篇论文针对Federated Learning (FL)中存在的客户端计算和通信负担问题，提出了Collaborative-Split Federated Learning (C-SFL)，一种将模型分成三部分的方法：分别在计算能力弱的客户端、强客户端和服务器上进行训练。C-SFL通过启用并行训练和聚合，显著降低了训练延迟和通信开销，同时提升了模型准确性。与现有Split Federated Learning (SFL)方案相比，实验验证了C-SFL的多方面优势。",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.15724v1",
      "published_date": "2025-04-22 09:18:57 UTC",
      "updated_date": "2025-04-22 09:18:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:42:52.950331"
    },
    {
      "arxiv_id": "2504.15719v1",
      "title": "Implementing Rational Choice Functions with LLMs and Measuring their Alignment with User Preferences",
      "title_zh": "使用 LLMs 实现理性选择函数并测量其与用户偏好的对齐",
      "authors": [
        "Anna Karnysheva",
        "Christian Drescher",
        "Dietrich Klakow"
      ],
      "abstract": "As large language models (LLMs) become integral to intelligent user\ninterfaces (IUIs), their role as decision-making agents raises critical\nconcerns about alignment. Although extensive research has addressed issues such\nas factuality, bias, and toxicity, comparatively little attention has been paid\nto measuring alignment to preferences, i.e., the relative desirability of\ndifferent alternatives, a concept used in decision making, economics, and\nsocial choice theory. However, a reliable decision-making agent makes choices\nthat align well with user preferences.\n  In this paper, we generalize existing methods that exploit LLMs for ranking\nalternative outcomes by addressing alignment with the broader and more flexible\nconcept of user preferences, which includes both strict preferences and\nindifference among alternatives. To this end, we put forward design principles\nfor using LLMs to implement rational choice functions, and provide the\nnecessary tools to measure preference satisfaction. We demonstrate the\napplicability of our approach through an empirical study in a practical\napplication of an IUI in the automotive domain.",
      "tldr_zh": "这篇论文探讨了大型语言模型 (LLMs) 在智能用户界面 (IUIs) 中作为决策代理时的偏好对齐问题，强调了测量用户偏好（如严格偏好和无差异）的必要性。作者推广了现有方法，通过提出设计原则来使用 LLMs 实现理性选择函数 (rational choice functions)，并提供了相应的工具来评估偏好满足度。实证研究在汽车领域的 IUI 应用中验证了该方法的有效性，展示了其在提升决策代理可靠性的潜力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.15719v1",
      "published_date": "2025-04-22 09:08:21 UTC",
      "updated_date": "2025-04-22 09:08:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:43:05.597115"
    },
    {
      "arxiv_id": "2504.15716v1",
      "title": "DianJin-R1: Evaluating and Enhancing Financial Reasoning in Large Language Models",
      "title_zh": "DianJin-R1：评估和增强大语言模型中的金融推理",
      "authors": [
        "Jie Zhu",
        "Qian Chen",
        "Huaixia Dou",
        "Junhui Li",
        "Lifan Guo",
        "Feng Chen",
        "Chi Zhang"
      ],
      "abstract": "Effective reasoning remains a core challenge for large language models (LLMs)\nin the financial domain, where tasks often require domain-specific knowledge,\nprecise numerical calculations, and strict adherence to compliance rules. We\npropose DianJin-R1, a reasoning-enhanced framework designed to address these\nchallenges through reasoning-augmented supervision and reinforcement learning.\nCentral to our approach is DianJin-R1-Data, a high-quality dataset constructed\nfrom CFLUE, FinQA, and a proprietary compliance corpus (Chinese Compliance\nCheck, CCC), combining diverse financial reasoning scenarios with verified\nannotations. Our models, DianJin-R1-7B and DianJin-R1-32B, are fine-tuned from\nQwen2.5-7B-Instruct and Qwen2.5-32B-Instruct using a structured format that\ngenerates both reasoning steps and final answers. To further refine reasoning\nquality, we apply Group Relative Policy Optimization (GRPO), a reinforcement\nlearning method that incorporates dual reward signals: one encouraging\nstructured outputs and another rewarding answer correctness. We evaluate our\nmodels on five benchmarks: three financial datasets (CFLUE, FinQA, and CCC) and\ntwo general reasoning benchmarks (MATH-500 and GPQA-Diamond). Experimental\nresults show that DianJin-R1 models consistently outperform their non-reasoning\ncounterparts, especially on complex financial tasks. Moreover, on the\nreal-world CCC dataset, our single-call reasoning models match or even surpass\nthe performance of multi-agent systems that require significantly more\ncomputational cost. These findings demonstrate the effectiveness of DianJin-R1\nin enhancing financial reasoning through structured supervision and\nreward-aligned learning, offering a scalable and practical solution for\nreal-world applications.",
      "tldr_zh": "该研究针对大型语言模型(LLMs)在金融领域的推理挑战（如领域知识、数值计算和合规规则），提出了DianJin-R1框架，通过推理增强监督和强化学习来提升模型性能。框架的核心是DianJin-R1-Data数据集，该数据集整合了CFLUE、FinQA和Chinese Compliance Check(CCC)等来源，提供高质量的金融推理场景和注解。模型基于Qwen2.5-7B-Instruct和Qwen2.5-32B-Instruct进行微调，并采用Group Relative Policy Optimization(GRPO)方法，使用双重奖励信号优化结构化输出和答案正确性。在CFLUE、FinQA、CCC、MATH-500和GPQA-Diamond等五个基准上，DianJin-R1模型显著优于非推理基线，尤其在复杂金融任务中表现突出，并展示了与多智能体系统相当的效率，提供可扩展的实际应用解决方案。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.15716v1",
      "published_date": "2025-04-22 09:01:04 UTC",
      "updated_date": "2025-04-22 09:01:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:43:20.307524"
    },
    {
      "arxiv_id": "2504.15707v1",
      "title": "RePOPE: Impact of Annotation Errors on the POPE Benchmark",
      "title_zh": "RePOPE：标注错误对 POPE 基准的影响",
      "authors": [
        "Yannic Neuhaus",
        "Matthias Hein"
      ],
      "abstract": "Since data annotation is costly, benchmark datasets often incorporate labels\nfrom established image datasets. In this work, we assess the impact of label\nerrors in MSCOCO on the frequently used object hallucination benchmark POPE. We\nre-annotate the benchmark images and identify an imbalance in annotation errors\nacross different subsets. Evaluating multiple models on the revised labels,\nwhich we denote as RePOPE, we observe notable shifts in model rankings,\nhighlighting the impact of label quality. Code and data are available at\nhttps://github.com/YanNeu/RePOPE .",
      "tldr_zh": "本文评估了MSCOCO数据集中的标注错误对物体幻觉基准POPE的影响，强调了数据标注质量的重要性。作者重新标注了基准图像，创建了修订版RePOPE数据集，并发现标注错误在不同子集间存在不平衡。实验结果显示，在RePOPE上评估多个模型后，模型排名出现显著变化，突显了标签错误对基准评估的潜在偏差。代码和数据可从https://github.com/YanNeu/RePOPE获取。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.15707v1",
      "published_date": "2025-04-22 08:47:59 UTC",
      "updated_date": "2025-04-22 08:47:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:43:28.596305"
    },
    {
      "arxiv_id": "2504.16144v1",
      "title": "Detecting Actionable Requests and Offers on Social Media During Crises Using LLMs",
      "title_zh": "使用 LLMs 检测危机期间社交媒体上的可",
      "authors": [
        "Ahmed El Fekih Zguir",
        "Ferda Ofli",
        "Muhammad Imran"
      ],
      "abstract": "Natural disasters often result in a surge of social media activity, including\nrequests for assistance, offers of help, sentiments, and general updates. To\nenable humanitarian organizations to respond more efficiently, we propose a\nfine-grained hierarchical taxonomy to systematically organize crisis-related\ninformation about requests and offers into three critical dimensions: supplies,\nemergency personnel, and actions. Leveraging the capabilities of Large Language\nModels (LLMs), we introduce Query-Specific Few-shot Learning (QSF Learning)\nthat retrieves class-specific labeled examples from an embedding database to\nenhance the model's performance in detecting and classifying posts. Beyond\nclassification, we assess the actionability of messages to prioritize posts\nrequiring immediate attention. Extensive experiments demonstrate that our\napproach outperforms baseline prompting strategies, effectively identifying and\nprioritizing actionable requests and offers.",
      "tldr_zh": "这篇论文提出了一种使用 Large Language Models (LLMs) 的方法，来检测危机期间社交媒体上的可行动请求和提供信息，以帮助人道主义组织更高效响应。研究者设计了一个细粒度的 hierarchical taxonomy，将这些信息组织成 supplies（物资）、emergency personnel（紧急人员）和 actions（行动）三个关键维度，并引入 Query-Specific Few-shot Learning (QSF Learning) 技术，通过从嵌入数据库中检索类特定标记示例来提升模型的检测和分类性能。此外，论文评估了消息的 actionability（可行动性），以优先处理紧急帖子，实验结果显示该方法优于基线提示策略，在识别和优先处理方面表现出色。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.16144v1",
      "published_date": "2025-04-22 08:34:58 UTC",
      "updated_date": "2025-04-22 08:34:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:43:42.756975"
    },
    {
      "arxiv_id": "2504.15699v2",
      "title": "Advancing Embodied Agent Security: From Safety Benchmarks to Input Moderation",
      "title_zh": "推进具身",
      "authors": [
        "Ning Wang",
        "Zihan Yan",
        "Weiyang Li",
        "Chuan Ma",
        "He Chen",
        "Tao Xiang"
      ],
      "abstract": "Embodied agents exhibit immense potential across a multitude of domains,\nmaking the assurance of their behavioral safety a fundamental prerequisite for\ntheir widespread deployment. However, existing research predominantly\nconcentrates on the security of general large language models, lacking\nspecialized methodologies for establishing safety benchmarks and input\nmoderation tailored to embodied agents. To bridge this gap, this paper\nintroduces a novel input moderation framework, meticulously designed to\nsafeguard embodied agents. This framework encompasses the entire pipeline,\nincluding taxonomy definition, dataset curation, moderator architecture, model\ntraining, and rigorous evaluation. Notably, we introduce EAsafetyBench, a\nmeticulously crafted safety benchmark engineered to facilitate both the\ntraining and stringent assessment of moderators specifically designed for\nembodied agents. Furthermore, we propose Pinpoint, an innovative\nprompt-decoupled input moderation scheme that harnesses a masked attention\nmechanism to effectively isolate and mitigate the influence of functional\nprompts on moderation tasks. Extensive experiments conducted on diverse\nbenchmark datasets and models validate the feasibility and efficacy of the\nproposed approach. The results demonstrate that our methodologies achieve an\nimpressive average detection accuracy of 94.58%, surpassing the performance of\nexisting state-of-the-art techniques, alongside an exceptional moderation\nprocessing time of merely 0.002 seconds per instance.",
      "tldr_zh": "该论文针对embodied agents的安全性问题，提出一个全面的输入moderation框架，以填补现有研究对embodied agents的专门方法缺失。该框架涵盖taxonomy definition、数据集curation、moderator architecture、模型training和严格evaluation，并引入EAsafetyBench作为专为embodied agents设计的安全基准，用于moderator的训练和评估。同时，论文提出Pinpoint方法，该方案采用prompt-decoupled设计和masked attention机制，有效隔离功能prompt的影响。实验结果显示，该方法在多种基准数据集和模型上实现平均检测准确率94.58%，处理时间仅0.002秒每实例，显著优于现有技术。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "9 pages",
      "pdf_url": "http://arxiv.org/pdf/2504.15699v2",
      "published_date": "2025-04-22 08:34:35 UTC",
      "updated_date": "2025-05-08 09:12:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:43:55.155742"
    },
    {
      "arxiv_id": "2505.00013v1",
      "title": "Performance Evaluation of Emotion Classification in Japanese Using RoBERTa and DeBERTa",
      "title_zh": "使用 RoBERTa 和 DeBERTa 对日语情感分类的性能评估",
      "authors": [
        "Yoichi Takenaka"
      ],
      "abstract": "Background Practical applications such as social media monitoring and\ncustomer-feedback analysis require accurate emotion detection for Japanese\ntext, yet resource scarcity and class imbalance hinder model performance.\n  Objective This study aims to build a high-accuracy model for predicting the\npresence or absence of eight Plutchik emotions in Japanese sentences.\n  Methods Using the WRIME corpus, we transform reader-averaged intensity scores\ninto binary labels and fine-tune four pre-trained language models (BERT,\nRoBERTa, DeBERTa-v3-base, DeBERTa-v3-large). For context, we also assess two\nlarge language models (TinySwallow-1.5B-Instruct and ChatGPT-4o). Accuracy and\nF1-score serve as evaluation metrics.\n  Results DeBERTa-v3-large attains the best mean accuracy (0.860) and F1-score\n(0.662), outperforming all other models. It maintains robust F1 across both\nhigh-frequency emotions (e.g., Joy, Anticipation) and low-frequency emotions\n(e.g., Anger, Trust). The LLMs lag, with ChatGPT-4o and\nTinySwallow-1.5B-Instruct scoring 0.527 and 0.292 in mean F1, respectively.\n  Conclusion The fine-tuned DeBERTa-v3-large model currently offers the most\nreliable solution for binary emotion classification in Japanese. We release\nthis model as a pip-installable package (pip install\ndeberta-emotion-predictor). Future work should augment data for rare emotions,\nreduce model size, and explore prompt engineering to improve LLM performance.\n  This manuscript is under review for possible publication in New Generation\nComputing.",
      "tldr_zh": "本研究针对日语文本的情感分类问题，评估了多种预训练语言模型的性能，旨在构建高准确率的模型来预测八种 Plutchik emotions 的存在或不存在。研究使用 WRIME corpus 将读者平均强度分数转化为二元标签，并微调了 BERT、RoBERTa、DeBERTa-v3-base 和 DeBERTa-v3-large 等模型，同时比较了 TinySwallow-1.5B-Instruct 和 ChatGPT-4o 的表现，以准确率和 F1-score 作为评估指标。结果显示，DeBERTa-v3-large 取得了最佳的平均准确率 (0.860) 和 F1-score (0.662)，在高频情感（如 Joy）和低频情感（如 Anger）上均表现出色，而大型语言模型的 F1-score 明显落后。作者发布了该模型作为 pip 安装包（deberta-emotion-predictor），并建议未来工作包括增强稀有情感数据、减小模型大小和探索 prompt engineering 以提升 LLM 性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "14 pages, 3 tables, 3 appendices. Submitted to New Generation\n  Computing. Includes comparisons between fine-tuned PLMs and LLMs on Japanese\n  emotion classification. Code available at\n  https://pypi.org/project/deberta-emotion-predictor/",
      "pdf_url": "http://arxiv.org/pdf/2505.00013v1",
      "published_date": "2025-04-22 07:51:37 UTC",
      "updated_date": "2025-04-22 07:51:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:44:09.274292"
    },
    {
      "arxiv_id": "2504.15668v1",
      "title": "Exploring Inevitable Waypoints for Unsolvability Explanation in Hybrid Planning Problems",
      "title_zh": "探索混合规划问题中不可避免的路径点以解释不可解性",
      "authors": [
        "Mir Md Sajid Sarwar",
        "Rajarshi Ray"
      ],
      "abstract": "Explaining unsolvability of planning problems is of significant research\ninterest in Explainable AI Planning. AI planning literature has reported\nseveral research efforts on generating explanations of solutions to planning\nproblems. However, explaining the unsolvability of planning problems remains a\nlargely open and understudied problem. A widely practiced approach to plan\ngeneration and automated problem solving, in general, is to decompose tasks\ninto sub-problems that help progressively converge towards the goal. In this\npaper, we propose to adopt the same philosophy of sub-problem identification as\na mechanism for analyzing and explaining unsolvability of planning problems in\nhybrid systems. In particular, for a given unsolvable planning problem, we\npropose to identify common waypoints, which are universal obstacles to plan\nexistence; in other words, they appear on every plan from the source to the\nplanning goal. This work envisions such waypoints as sub-problems of the\nplanning problem and the unreachability of any of these waypoints as an\nexplanation for the unsolvability of the original planning problem. We propose\na novel method of waypoint identification by casting the problem as an instance\nof the longest common subsequence problem, a widely popular problem in computer\nscience, typically considered as an illustrative example for the dynamic\nprogramming paradigm. Once the waypoints are identified, we perform symbolic\nreachability analysis on them to identify the earliest unreachable waypoint and\nreport it as the explanation of unsolvability. We present experimental results\non unsolvable planning problems in hybrid domains.",
      "tldr_zh": "该论文探讨了在混合规划问题（hybrid planning problems）中解释不可解性的方法，聚焦于Explainable AI Planning领域。研究提出通过识别“inevitable waypoints”（即通往目标的每条路径上必须经过的通用障碍点）来分析子问题，从而解释规划问题的不可解性。方法将waypoints识别问题转化为longest common subsequence问题，并结合symbolic reachability analysis来找出最早不可达的waypoints，作为不可解性的核心解释。实验结果显示，该方法在混合域的不可解规划问题上有效，提供了更系统的解释框架。",
      "categories": [
        "cs.AI",
        "cs.FL",
        "I.2.0; F.4.3"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.15668v1",
      "published_date": "2025-04-22 07:45:30 UTC",
      "updated_date": "2025-04-22 07:45:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:44:19.973999"
    },
    {
      "arxiv_id": "2504.17807v1",
      "title": "Research on Cloud Platform Network Traffic Monitoring and Anomaly Detection System based on Large Language Models",
      "title_zh": "基于大型语言模型的云平台网络流量监控和异常检测系统研究",
      "authors": [
        "Ze Yang",
        "Yihong Jin",
        "Juntian Liu",
        "Xinhe Xu",
        "Yihan Zhang",
        "Shuyang Ji"
      ],
      "abstract": "The rapidly evolving cloud platforms and the escalating complexity of network\ntraffic demand proper network traffic monitoring and anomaly detection to\nensure network security and performance. This paper introduces a large language\nmodel (LLM)-based network traffic monitoring and anomaly detection system. In\naddition to existing models such as autoencoders and decision trees, we harness\nthe power of large language models for processing sequence data from network\ntraffic, which allows us a better capture of underlying complex patterns, as\nwell as slight fluctuations in the dataset. We show for a given detection task,\nthe need for a hybrid model that incorporates the attention mechanism of the\ntransformer architecture into a supervised learning framework in order to\nachieve better accuracy. A pre-trained large language model analyzes and\npredicts the probable network traffic, and an anomaly detection layer that\nconsiders temporality and context is added. Moreover, we present a novel\ntransfer learning-based methodology to enhance the model's effectiveness to\nquickly adapt to unknown network structures and adversarial conditions without\nrequiring extensive labeled datasets. Actual results show that the designed\nmodel outperforms traditional methods in detection accuracy and computational\nefficiency, effectively identify various network anomalies such as zero-day\nattacks and traffic congestion pattern, and significantly reduce the false\npositive rate.",
      "tldr_zh": "本研究提出了一种基于大型语言模型（LLM）的云平台网络流量监控和异常检测系统，以应对网络流量复杂性和安全挑战。该系统整合了Transformer的注意力机制与监督学习框架，形成一个混合模型，用于处理序列数据并捕捉复杂模式和细微波动；同时，采用迁移学习方法，使模型快速适应未知网络结构和对抗条件，而无需大量标记数据集。实验结果显示，该系统在检测准确性和计算效率上优于传统模型（如自编码器和决策树），能够有效识别零日攻击和流量拥塞等异常，并显著降低假阳性率。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NI",
      "comment": "Proceedings of 2025 IEEE 7th International Conference on\n  Communications, Information System and Computer Engineering (CISCE 2025)",
      "pdf_url": "http://arxiv.org/pdf/2504.17807v1",
      "published_date": "2025-04-22 07:42:07 UTC",
      "updated_date": "2025-04-22 07:42:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:44:31.969553"
    },
    {
      "arxiv_id": "2504.15663v1",
      "title": "FADEL: Uncertainty-aware Fake Audio Detection with Evidential Deep Learning",
      "title_zh": "FADEL：基于证据深度学习的不确定性感知假音频检测",
      "authors": [
        "Ju Yeon Kang",
        "Ji Won Yoon",
        "Semin Kim",
        "Min Hyun Han",
        "Nam Soo Kim"
      ],
      "abstract": "Recently, fake audio detection has gained significant attention, as\nadvancements in speech synthesis and voice conversion have increased the\nvulnerability of automatic speaker verification (ASV) systems to spoofing\nattacks. A key challenge in this task is generalizing models to detect unseen,\nout-of-distribution (OOD) attacks. Although existing approaches have shown\npromising results, they inherently suffer from overconfidence issues due to the\nusage of softmax for classification, which can produce unreliable predictions\nwhen encountering unpredictable spoofing attempts. To deal with this\nlimitation, we propose a novel framework called fake audio detection with\nevidential learning (FADEL). By modeling class probabilities with a Dirichlet\ndistribution, FADEL incorporates model uncertainty into its predictions,\nthereby leading to more robust performance in OOD scenarios. Experimental\nresults on the ASVspoof2019 Logical Access (LA) and ASVspoof2021 LA datasets\nindicate that the proposed method significantly improves the performance of\nbaseline models. Furthermore, we demonstrate the validity of uncertainty\nestimation by analyzing a strong correlation between average uncertainty and\nequal error rate (EER) across different spoofing algorithms.",
      "tldr_zh": "该研究针对假音频检测中的过自信问题，提出FADEL框架，该框架基于Evidential Deep Learning，通过Dirichlet分布建模类概率以融入模型不确定性，从而提升对未知OOD攻击的鲁棒性。在ASVspoof2019 LA和ASVspoof2021 LA数据集上，FADEL显著改善了基线模型的性能，并通过不确定性与EER（等错误率）的强相关性，证明了不确定性估计的有效性。",
      "categories": [
        "eess.AS",
        "cs.AI"
      ],
      "primary_category": "eess.AS",
      "comment": "Accepted at ICASSP 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.15663v1",
      "published_date": "2025-04-22 07:40:35 UTC",
      "updated_date": "2025-04-22 07:40:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:44:43.760942"
    },
    {
      "arxiv_id": "2504.15659v1",
      "title": "VeriCoder: Enhancing LLM-Based RTL Code Generation through Functional Correctness Validation",
      "title_zh": "VeriCoder：通过功能正确性验证增强基于LLM的RTL代码生成",
      "authors": [
        "Anjiang Wei",
        "Huanmi Tan",
        "Tarun Suresh",
        "Daniel Mendoza",
        "Thiago S. F. X. Teixeira",
        "Ke Wang",
        "Caroline Trippel",
        "Alex Aiken"
      ],
      "abstract": "Recent advances in Large Language Models (LLMs) have sparked growing interest\nin applying them to Electronic Design Automation (EDA) tasks, particularly\nRegister Transfer Level (RTL) code generation. While several RTL datasets have\nbeen introduced, most focus on syntactic validity rather than functional\nvalidation with tests, leading to training examples that compile but may not\nimplement the intended behavior. We present VERICODER, a model for RTL code\ngeneration fine-tuned on a dataset validated for functional correctness. This\nfine-tuning dataset is constructed using a novel methodology that combines unit\ntest generation with feedback-directed refinement. Given a natural language\nspecification and an initial RTL design, we prompt a teacher model\n(GPT-4o-mini) to generate unit tests and iteratively revise the RTL design\nbased on its simulation results using the generated tests. If necessary, the\nteacher model also updates the tests to ensure they comply with the natural\nlanguage specification. As a result of this process, every example in our\ndataset is functionally validated, consisting of a natural language\ndescription, an RTL implementation, and passing tests. Fine-tuned on this\ndataset of over 125,000 examples, VERICODER achieves state-of-the-art metrics\nin functional correctness on VerilogEval and RTLLM, with relative gains of up\nto 71.7% and 27.4% respectively. An ablation study further shows that models\ntrained on our functionally validated dataset outperform those trained on\nfunctionally non-validated datasets, underscoring the importance of\nhigh-quality datasets in RTL code generation.",
      "tldr_zh": "该研究提出 VeriCoder，一种通过功能正确性验证增强基于 LLM 的 RTL 代码生成模型，以解决现有数据集仅关注语法有效性而忽略行为正确性的问题。方法包括使用教师模型 GPT-4o-mini 生成单元测试，并基于模拟结果进行迭代修订 RTL 设计，最终构建一个包含超过 125,000 个功能验证示例的数据集，每个示例包括自然语言描述、RTL 实现和通过测试。实验结果显示，VeriCoder 在 VerilogEval 和 RTLLM 基准上实现了功能正确性的最先进指标，相对提升高达 71.7% 和 27.4%，消融研究进一步证实，使用功能验证数据集训练的模型显著优于未验证数据集，强调了高质量数据的重要性。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.SE"
      ],
      "primary_category": "cs.AR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.15659v1",
      "published_date": "2025-04-22 07:32:46 UTC",
      "updated_date": "2025-04-22 07:32:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:44:57.980791"
    },
    {
      "arxiv_id": "2504.15654v2",
      "title": "A Vision-Enabled Prosthetic Hand for Children with Upper Limb Disabilities",
      "title_zh": "翻译失败",
      "authors": [
        "Md Abdul Baset Sarker",
        "Art Nguyen",
        "Sigmond Kukla",
        "Kevin Fite",
        "Masudul H. Imtiaz"
      ],
      "abstract": "This paper introduces a novel AI vision-enabled pediatric prosthetic hand\ndesigned to assist children aged 10-12 with upper limb disabilities. The\nprosthesis features an anthropomorphic appearance, multi-articulating\nfunctionality, and a lightweight design that mimics a natural hand, making it\nboth accessible and affordable for low-income families. Using 3D printing\ntechnology and integrating advanced machine vision, sensing, and embedded\ncomputing, the prosthetic hand offers a low-cost, customizable solution that\naddresses the limitations of current myoelectric prostheses. A micro camera is\ninterfaced with a low-power FPGA for real-time object detection and assists\nwith precise grasping. The onboard DL-based object detection and grasp\nclassification models achieved accuracies of 96% and 100% respectively. In the\nforce prediction, the mean absolute error was found to be 0.018. The features\nof the proposed prosthetic hand can thus be summarized as: a) a wrist-mounted\nmicro camera for artificial sensing, enabling a wide range of hand-based tasks;\nb) real-time object detection and distance estimation for precise grasping; and\nc) ultra-low-power operation that delivers high performance within constrained\npower and resource limits.",
      "tldr_zh": "本论文提出了一种新型AI视觉辅助的儿科假肢手，针对10-12岁儿童的上肢残疾，提供拟人外观、多关节功能和轻量设计，以低成本方式适合低收入家庭。假肢利用3D打印技术整合微型摄像头、FPGA和深度学习(DL-based)模型，实现实时物体检测、距离估计和精确抓取。实验结果显示，物体检测准确率达96%，抓取分类准确率100%，力预测平均绝对误差仅0.018，这为可定制的自主假肢解决方案提供了高效且资源节约的途径。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.15654v2",
      "published_date": "2025-04-22 07:23:51 UTC",
      "updated_date": "2025-04-27 15:39:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:45:09.927110"
    },
    {
      "arxiv_id": "2504.15640v1",
      "title": "Cost-Effective Text Clustering with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Hongtao Wang",
        "Taiyan Zhang",
        "Renchi Yang",
        "Jianliang Xu"
      ],
      "abstract": "Text clustering aims to automatically partition a collection of text\ndocuments into distinct clusters based on linguistic features. In the\nliterature, this task is usually framed as metric clustering based on text\nembeddings from pre-trained encoders or a graph clustering problem upon\npairwise similarities from an oracle, e.g., a large ML model. Recently, large\nlanguage models (LLMs) bring significant advancement in this field by offering\ncontextualized text embeddings and highly accurate similarity scores, but\nmeanwhile, present grand challenges to cope with substantial computational\nand/or financial overhead caused by numerous API-based queries or inference\ncalls to the models.\n  In response, this paper proposes TECL, a cost-effective framework that taps\ninto the feedback from LLMs for accurate text clustering within a limited\nbudget of queries to LLMs. Under the hood, TECL adopts our EdgeLLM or\nTriangleLLM to construct must-link/cannot-link constraints for text pairs, and\nfurther leverages such constraints as supervision signals input to our weighted\nconstrained clustering approach to generate clusters. Particularly, EdgeLLM\n(resp. TriangleLLM) enables the identification of informative text pairs (resp.\ntriplets) for querying LLMs via well-thought-out greedy algorithms and accurate\nextraction of pairwise constraints through carefully-crafted prompting\ntechniques. Our experiments on multiple benchmark datasets exhibit that TECL\nconsistently and considerably outperforms existing solutions in unsupervised\ntext clustering under the same query cost for LLMs.",
      "tldr_zh": "这篇论文针对大语言模型(LLMs)在文本聚类中的高计算和财务成本问题，提出了一种成本有效的框架TECL。TECL通过EdgeLLM和TriangleLLM利用贪婪算法选择信息丰富的文本对或三元组，并通过精心设计的提示技术提取must-link/cannot-link约束，作为监督信号输入到加权约束聚类方法中生成聚类。实验在多个基准数据集上显示，TECL在相同的LLMs查询预算下，显著优于现有无监督文本聚类解决方案，提高了聚类准确性。总的来说，该方法为高效利用LLMs实现文本聚类提供了新途径。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.15640v1",
      "published_date": "2025-04-22 06:57:49 UTC",
      "updated_date": "2025-04-22 06:57:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:45:20.791212"
    },
    {
      "arxiv_id": "2504.15637v1",
      "title": "DR.FIX: Automatically Fixing Data Races at Industry Scale",
      "title_zh": "翻译失败",
      "authors": [
        "Farnaz Behrang",
        "Zhizhou Zhang",
        "Georgian-Vlad Saioc",
        "Peng Liu",
        "Milind Chabbi"
      ],
      "abstract": "Data races are a prevalent class of concurrency bugs in shared-memory\nparallel programs, posing significant challenges to software reliability and\nreproducibility. While there is an extensive body of research on detecting data\nraces and a wealth of practical detection tools across various programming\nlanguages, considerably less effort has been directed toward automatically\nfixing data races at an industrial scale. In large codebases, data races are\ncontinuously introduced and exhibit myriad patterns, making automated fixing\nparticularly challenging.\n  In this paper, we tackle the problem of automatically fixing data races at an\nindustrial scale. We present Dr.Fix, a tool that combines large language models\n(LLMs) with program analysis to generate fixes for data races in real-world\nsettings, effectively addressing a broad spectrum of racy patterns in complex\ncode contexts. Implemented for Go--the programming language widely used in\nmodern microservice architectures where concurrency is pervasive and data races\nare common--Dr.Fix seamlessly integrates into existing development workflows.\nWe detail the design of Dr.Fix and examine how individual design choices\ninfluence the quality of the fixes produced. Over the past 18 months, Dr.Fix\nhas been integrated into developer workflows at Uber demonstrating its\npractical utility. During this period, Dr.Fix produced patches for 224 (55%)\nfrom a corpus of 404 data races spanning various categories; 193 of these\npatches (86%) were accepted by more than a hundred developers via code reviews\nand integrated into the codebase.",
      "tldr_zh": "这篇论文介绍了DR.FIX，一种自动修复数据竞争（data races）的工具，结合大型语言模型（LLMs）和程序分析，针对Go语言的工业规模代码库处理各种并发bug。DR.FIX无缝整合到开发工作流中，能够生成高质量补丁，覆盖复杂代码上下文中的多种数据竞争模式。在Uber的实际应用中，该工具在过去18个月内成功修复了404个数据竞争中的224个（55%），其中193个补丁（86%）通过代码审查后被接受并整合入代码库。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG",
        "cs.PL",
        "cs.SE"
      ],
      "primary_category": "cs.DC",
      "comment": "To appear in PLDI 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.15637v1",
      "published_date": "2025-04-22 06:56:15 UTC",
      "updated_date": "2025-04-22 06:56:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:45:31.139817"
    },
    {
      "arxiv_id": "2504.15634v1",
      "title": "Enhancing Reinforcement learning in 3-Dimensional Hydrophobic-Polar Protein Folding Model with Attention-based layers",
      "title_zh": "翻译失败",
      "authors": [
        "Peizheng Liu",
        "Hitoshi Iba"
      ],
      "abstract": "Transformer-based architectures have recently propelled advances in sequence\nmodeling across domains, but their application to the hydrophobic-hydrophilic\n(H-P) model for protein folding remains relatively unexplored. In this work, we\nadapt a Deep Q-Network (DQN) integrated with attention mechanisms\n(Transformers) to address the 3D H-P protein folding problem. Our system\nformulates folding decisions as a self-avoiding walk in a reinforced\nenvironment, and employs a specialized reward function based on favorable\nhydrophobic interactions. To improve performance, the method incorporates\nvalidity check including symmetry-breaking constraints, dueling and double\nQ-learning, and prioritized replay to focus learning on critical transitions.\nExperimental evaluations on standard benchmark sequences demonstrate that our\napproach achieves several known best solutions for shorter sequences, and\nobtains near-optimal results for longer chains. This study underscores the\npromise of attention-based reinforcement learning for protein folding, and\ncreated a prototype of Transformer-based Q-network structure for 3-dimensional\nlattice models.",
      "tldr_zh": "本文提出了一种将 Transformer-based 注意力机制整合到 Deep Q-Network (DQN) 中的方法，用于提升 3D 疏水-亲水 (H-P) 蛋白折叠模型的强化学习性能。系统将蛋白折叠决策表述为自避免行走，并采用基于有利疏水相互作用的奖励函数，同时融入有效性检查、对称性破坏约束、双 Q 学习和优先级重放等技术来优化学习过程。在标准基准序列的实验中，该方法在较短序列上取得了已知最佳解决方案，并在较长链上获得近似最优结果，展示了注意力-based 强化学习在蛋白折叠中的潜力，并创建了一个 Transformer-based Q-network 的原型。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.15634v1",
      "published_date": "2025-04-22 06:53:36 UTC",
      "updated_date": "2025-04-22 06:53:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:45:44.828997"
    },
    {
      "arxiv_id": "2504.16142v1",
      "title": "A Non-Invasive Load Monitoring Method for Edge Computing Based on MobileNetV3 and Dynamic Time Regulation",
      "title_zh": "翻译失败",
      "authors": [
        "Hangxu Liu",
        "Yaojie Sun",
        "Yu Wang"
      ],
      "abstract": "In recent years, non-intrusive load monitoring (NILM) technology has\nattracted much attention in the related research field by virtue of its unique\nadvantage of utilizing single meter data to achieve accurate decomposition of\ndevice-level energy consumption. Cutting-edge methods based on machine learning\nand deep learning have achieved remarkable results in load decomposition\naccuracy by fusing time-frequency domain features. However, these methods\ngenerally suffer from high computational costs and huge memory requirements,\nwhich become the main obstacles for their deployment on resource-constrained\nmicrocontroller units (MCUs). To address these challenges, this study proposes\nan innovative Dynamic Time Warping (DTW) algorithm in the time-frequency domain\nand systematically compares and analyzes the performance of six machine\nlearning techniques in home electricity scenarios. Through complete\nexperimental validation on edge MCUs, this scheme successfully achieves a\nrecognition accuracy of 95%. Meanwhile, this study deeply optimizes the\nfrequency domain feature extraction process, which effectively reduces the\nrunning time by 55.55% and the storage overhead by about 34.6%. The algorithm\nperformance will be further optimized in future research work. Considering that\nthe elimination of voltage transformer design can significantly reduce the\ncost, the subsequent research will focus on this direction, and is committed to\nproviding more cost-effective solutions for the practical application of NILM,\nand providing a solid theoretical foundation and feasible technical paths for\nthe design of efficient NILM systems in edge computing environments.",
      "tldr_zh": "本研究提出了一种基于 MobileNetV3 和 Dynamic Time Warping (DTW) 的非入侵负载监控 (NILM) 方法，旨在解决现有 NILM 技术在边缘计算环境中计算成本高和内存需求大的问题。该方法通过创新的时频域 DTW 算法和六种机器学习技术的性能比较，优化了频域特征提取过程，在资源受限的微控制器 (MCUs) 上实现了 95% 的识别准确率，同时将运行时间减少 55.55% 和存储开销降低约 34.6%。这项工作为边缘计算下的高效 NILM 系统提供了可行技术路径，并计划未来通过消除电压变压器设计进一步降低成本。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.16142v1",
      "published_date": "2025-04-22 06:43:33 UTC",
      "updated_date": "2025-04-22 06:43:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:45:56.818715"
    },
    {
      "arxiv_id": "2504.15610v2",
      "title": "A LoRA-Based Approach to Fine-Tuning LLMs for Educational Guidance in Resource-Constrained Settings",
      "title_zh": "翻译失败",
      "authors": [
        "Md Millat Hosen"
      ],
      "abstract": "The current study describes a cost-effective method for adapting large\nlanguage models (LLMs) for academic advising with study-abroad contexts in mind\nand for application in low-resource methods for acculturation. With the\nMistral-7B-Instruct model applied with a Low-Rank Adaptation (LoRA) method and\na 4-bit quantization method, the model underwent training in two distinct\nstages related to this study's purpose to enhance domain specificity while\nmaintaining computational efficiency. In Phase 1, the model was conditioned\nwith a synthetic dataset via the Gemini Pro API, and in Phase 2, it was trained\nwith manually curated datasets from the StudyAbroadGPT project to achieve\nenhanced, contextualized responses. Technical innovations entailed\nmemory-efficient quantization, parameter-efficient adaptation, and continuous\ntraining analytics via Weights & Biases. After training, this study\ndemonstrated a reduction in training loss by 52.7%, 92% accuracy in\ndomain-specific recommendations, achieved 95% markdown-based formatting\nsupport, and a median run-rate of 100 samples per second on off-the-shelf GPU\nequipment. These findings support the effective application of\ninstruction-tuned LLMs within educational advisers, especially in low-resource\ninstitutional scenarios. Limitations included decreased generalizability and\nthe application of a synthetically generated dataset, but this framework is\nscalable for adding new multilingual-augmented and real-time academic advising\nprocesses. Future directions may include plans for the integration of\nretrieval-augmented generation, applying dynamic quantization routines, and\nconnecting to real-time academic databases to increase adaptability and\naccuracy.",
      "tldr_zh": "本研究提出了一种基于 LoRA（Low-Rank Adaptation）的成本有效方法，用于微调大型语言模型（LLMs），以在资源受限环境中提供教育指导，特别是针对留学和文化适应场景。采用 Mistral-7B-Instruct 模型结合 4-bit 量化，两阶段训练（第一阶段使用 Gemini Pro API 生成的合成数据集，第二阶段使用手动整理的 StudyAbroadGPT 数据集），实现了参数高效适应和内存优化。结果显示，训练损失减少 52.7%，领域特定推荐准确率达 92%，Markdown 格式支持 95%，并在商用 GPU 上实现每秒 100 个样本的处理速率。该方法证明了在低资源机构中应用指令调整 LLMs 的可行性，但受限于泛化性和合成数据集问题，未来可整合检索增强生成（RAG）和动态量化以提升准确性和适应性。",
      "categories": [
        "cs.AI",
        "68T05 (Learning and adaptive systems), 68T07 (Artificial\n  intelligence and education)"
      ],
      "primary_category": "cs.AI",
      "comment": "18 pages, 6 figures (3 graphs + 3 flowchart/architecture diagrams),\n  submitted as a preprint for review consideration in AI for Education or\n  Machine Learning applications in low-resource settings. Includes detailed\n  experiments with LoRA and quantization methods for efficient LLM fine-tuning",
      "pdf_url": "http://arxiv.org/pdf/2504.15610v2",
      "published_date": "2025-04-22 06:08:13 UTC",
      "updated_date": "2025-04-23 04:59:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:46:13.894949"
    },
    {
      "arxiv_id": "2504.15604v1",
      "title": "Exploring Next Token Prediction in Theory of Mind (ToM) Tasks: Comparative Experiments with GPT-2 and LLaMA-2 AI Models",
      "title_zh": "翻译失败",
      "authors": [
        "Pavan Yadav",
        "Nikhil Khandalkar",
        "Krishna Shinde",
        "Lokesh B. Ramegowda",
        "Rajarshi Das"
      ],
      "abstract": "Language models have made significant progress in generating coherent text\nand predicting next tokens based on input prompts. This study compares the\nnext-token prediction performance of two well-known models: OpenAI's GPT-2 and\nMeta's Llama-2-7b-chat-hf on Theory of Mind (ToM) tasks. To evaluate their\ncapabilities, we built a dataset from 10 short stories sourced from the Explore\nToM Dataset. We enhanced these stories by programmatically inserting additional\nsentences (infills) using GPT-4, creating variations that introduce different\nlevels of contextual complexity. This setup enables analysis of how increasing\ncontext affects model performance. We tested both models under four temperature\nsettings (0.01, 0.5, 1.0, 2.0) and evaluated their ability to predict the next\ntoken across three reasoning levels. Zero-order reasoning involves tracking the\nstate, either current (ground truth) or past (memory). First-order reasoning\nconcerns understanding another's mental state (e.g., \"Does Anne know the apple\nis salted?\"). Second-order reasoning adds recursion (e.g., \"Does Anne think\nthat Charles knows the apple is salted?\").\n  Our results show that adding more infill sentences slightly reduces\nprediction accuracy, as added context increases complexity and ambiguity.\nLlama-2 consistently outperforms GPT-2 in prediction accuracy, especially at\nlower temperatures, demonstrating greater confidence in selecting the most\nprobable token. As reasoning complexity rises, model responses diverge more.\nNotably, GPT-2 and Llama-2 display greater variability in predictions during\nfirst- and second-order reasoning tasks. These findings illustrate how model\narchitecture, temperature, and contextual complexity influence next-token\nprediction, contributing to a better understanding of the strengths and\nlimitations of current language models.",
      "tldr_zh": "这篇论文比较了 GPT-2 和 LLaMA-2 在 Theory of Mind (ToM) 任务中的 next-token prediction 性能，旨在评估语言模型在理解心理状态方面的能力。研究者构建了一个数据集，使用来自 Explore ToM Dataset 的10个短故事，并通过 GPT-4 插入额外句子（infills）来增加上下文复杂性，同时测试了四个温度设置（0.01、0.5、1.0、2.0）下的模型表现。结果表明，添加更多 infill 句子会略微降低预测准确率，LLaMA-2 尤其在较低温度下优于 GPT-2，随着推理水平从零级（跟踪状态）到二级（递归推理）的增加，模型预测差异显著增大。这些发现揭示了模型架构、温度和上下文复杂性对语言模型性能的影响。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "75 pages, 60 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.15604v1",
      "published_date": "2025-04-22 05:52:55 UTC",
      "updated_date": "2025-04-22 05:52:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:46:23.030078"
    },
    {
      "arxiv_id": "2504.15587v2",
      "title": "MetaMolGen: A Neural Graph Motif Generation Model for De Novo Molecular Design",
      "title_zh": "翻译失败",
      "authors": [
        "Zimo Yan",
        "Jie Zhang",
        "Zheng Xie",
        "Chang Liu",
        "Yizhen Liu",
        "Yiping Song"
      ],
      "abstract": "Molecular generation plays an important role in drug discovery and materials\nscience, especially in data-scarce scenarios where traditional generative\nmodels often struggle to achieve satisfactory conditional generalization. To\naddress this challenge, we propose MetaMolGen, a first-order\nmeta-learning-based molecular generator designed for few-shot and\nproperty-conditioned molecular generation. MetaMolGen standardizes the\ndistribution of graph motifs by mapping them to a normalized latent space, and\nemploys a lightweight autoregressive sequence model to generate SMILES\nsequences that faithfully reflect the underlying molecular structure. In\naddition, it supports conditional generation of molecules with target\nproperties through a learnable property projector integrated into the\ngenerative process.Experimental results demonstrate that MetaMolGen\nconsistently generates valid and diverse SMILES sequences under low-data\nregimes, outperforming conventional baselines. This highlights its advantage in\nfast adaptation and efficient conditional generation for practical molecular\ndesign.",
      "tldr_zh": "本文提出 MetaMolGen，一种基于一阶 meta-learning 的神经图主题生成模型，用于 de novo 分子设计，尤其适用于数据稀缺场景下的少样本和属性条件分子生成。模型通过将 graph motifs 映射到归一化潜在空间，并采用轻量级自回归序列模型生成准确的 SMILES 序列，同时整合可学习的属性投影器以支持目标属性条件生成。实验结果显示，MetaMolGen 在低数据条件下生成有效的、多样化的分子序列，性能优于传统基线，并展示了快速适应和高效生成的优势，适用于实际药物发现和材料科学。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.15587v2",
      "published_date": "2025-04-22 05:04:33 UTC",
      "updated_date": "2025-05-12 13:18:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:46:34.445415"
    },
    {
      "arxiv_id": "2504.15585v2",
      "title": "A Comprehensive Survey in LLM(-Agent) Full Stack Safety: Data, Training and Deployment",
      "title_zh": "翻译失败",
      "authors": [
        "Kun Wang",
        "Guibin Zhang",
        "Zhenhong Zhou",
        "Jiahao Wu",
        "Miao Yu",
        "Shiqian Zhao",
        "Chenlong Yin",
        "Jinhu Fu",
        "Yibo Yan",
        "Hanjun Luo",
        "Liang Lin",
        "Zhihao Xu",
        "Haolang Lu",
        "Xinye Cao",
        "Xinyun Zhou",
        "Weifei Jin",
        "Fanci Meng",
        "Junyuan Mao",
        "Yu Wang",
        "Hao Wu",
        "Minghe Wang",
        "Fan Zhang",
        "Junfeng Fang",
        "Wenjie Qu",
        "Yue Liu",
        "Chengwei Liu",
        "Yifan Zhang",
        "Qiankun Li",
        "Chongye Guo",
        "Yalan Qin",
        "Zhaoxin Fan",
        "Yi Ding",
        "Donghai Hong",
        "Jiaming Ji",
        "Yingxin Lai",
        "Zitong Yu",
        "Xinfeng Li",
        "Yifan Jiang",
        "Yanhui Li",
        "Xinyu Deng",
        "Junlin Wu",
        "Dongxia Wang",
        "Yihao Huang",
        "Yufei Guo",
        "Jen-tse Huang",
        "Qiufeng Wang",
        "Wenxuan Wang",
        "Dongrui Liu",
        "Yanwei Yue",
        "Wenke Huang",
        "Guancheng Wan",
        "Heng Chang",
        "Tianlin Li",
        "Yi Yu",
        "Chenghao Li",
        "Jiawei Li",
        "Lei Bai",
        "Jie Zhang",
        "Qing Guo",
        "Jingyi Wang",
        "Tianlong Chen",
        "Joey Tianyi Zhou",
        "Xiaojun Jia",
        "Weisong Sun",
        "Cong Wu",
        "Jing Chen",
        "Xuming Hu",
        "Yiming Li",
        "Xiao Wang",
        "Ningyu Zhang",
        "Luu Anh Tuan",
        "Guowen Xu",
        "Jiaheng Zhang",
        "Tianwei Zhang",
        "Xingjun Ma",
        "Jindong Gu",
        "Xiang Wang",
        "Bo An",
        "Jun Sun",
        "Mohit Bansal",
        "Shirui Pan",
        "Lingjuan Lyu",
        "Yuval Elovici",
        "Bhavya Kailkhura",
        "Yaodong Yang",
        "Hongwei Li",
        "Wenyuan Xu",
        "Yizhou Sun",
        "Wei Wang",
        "Qing Li",
        "Ke Tang",
        "Yu-Gang Jiang",
        "Felix Juefei-Xu",
        "Hui Xiong",
        "Xiaofeng Wang",
        "Dacheng Tao",
        "Philip S. Yu",
        "Qingsong Wen",
        "Yang Liu"
      ],
      "abstract": "The remarkable success of Large Language Models (LLMs) has illuminated a\npromising pathway toward achieving Artificial General Intelligence for both\nacademic and industrial communities, owing to their unprecedented performance\nacross various applications. As LLMs continue to gain prominence in both\nresearch and commercial domains, their security and safety implications have\nbecome a growing concern, not only for researchers and corporations but also\nfor every nation. Currently, existing surveys on LLM safety primarily focus on\nspecific stages of the LLM lifecycle, e.g., deployment phase or fine-tuning\nphase, lacking a comprehensive understanding of the entire \"lifechain\" of LLMs.\nTo address this gap, this paper introduces, for the first time, the concept of\n\"full-stack\" safety to systematically consider safety issues throughout the\nentire process of LLM training, deployment, and eventual commercialization.\nCompared to the off-the-shelf LLM safety surveys, our work demonstrates several\ndistinctive advantages: (I) Comprehensive Perspective. We define the complete\nLLM lifecycle as encompassing data preparation, pre-training, post-training,\ndeployment and final commercialization. To our knowledge, this represents the\nfirst safety survey to encompass the entire lifecycle of LLMs. (II) Extensive\nLiterature Support. Our research is grounded in an exhaustive review of over\n800+ papers, ensuring comprehensive coverage and systematic organization of\nsecurity issues within a more holistic understanding. (III) Unique Insights.\nThrough systematic literature analysis, we have developed reliable roadmaps and\nperspectives for each chapter. Our work identifies promising research\ndirections, including safety in data generation, alignment techniques, model\nediting, and LLM-based agent systems. These insights provide valuable guidance\nfor researchers pursuing future work in this field.",
      "tldr_zh": "这篇论文对大型语言模型(LLMs)及其代理系统的全栈安全进行了全面调查，首次引入“full-stack”安全概念，涵盖LLMs生命周期的各个阶段，包括数据准备、预训练、后训练、部署和商业化。不同于现有调查，该工作基于超过800篇论文的系统文献分析，提供全面的视角和组织框架，强调了安全问题的整体理解。论文还提出了独特见解和未来研究方向，如数据生成安全、对齐技术(alignment techniques)、模型编辑(model editing)以及LLM-based agent systems的开发，为提升LLMs的安全性和可信度提供了宝贵指导。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.15585v2",
      "published_date": "2025-04-22 05:02:49 UTC",
      "updated_date": "2025-05-19 09:31:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:46:45.490103"
    },
    {
      "arxiv_id": "2504.15564v1",
      "title": "A Large-scale Class-level Benchmark Dataset for Code Generation with LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Musfiqur Rahman",
        "SayedHassan Khatoonabadi",
        "Emad Shihab"
      ],
      "abstract": "Recent advancements in large language models (LLMs) have demonstrated\npromising capabilities in code generation tasks. However, most existing\nbenchmarks focus on isolated functions and fail to capture the complexity of\nreal-world, class-level software structures. To address this gap, we introduce\na large-scale, Python class-level dataset curated from $13{,}174$ real-world\nopen-source projects. The dataset contains over 842,000 class skeletons, each\nincluding class and method signatures, along with associated docstrings when\navailable. We preserve structural and contextual dependencies critical to\nrealistic software development scenarios and enrich the dataset with static\ncode metrics to support downstream analysis. To evaluate the usefulness of this\ndataset, we use extracted class skeletons as prompts for GPT-4 to generate full\nclass implementations. Results show that the LLM-generated classes exhibit\nstrong lexical and structural similarity to human-written counterparts, with\naverage ROUGE@L, BLEU, and TSED scores of 0.80, 0.59, and 0.73, respectively.\nThese findings confirm that well-structured prompts derived from real-world\nclass skeletons significantly enhance LLM performance in class-level code\ngeneration. This dataset offers a valuable resource for benchmarking, training,\nand improving LLMs in realistic software engineering contexts.",
      "tldr_zh": "本研究引入了一个大规模的 Python 类级基准数据集，旨在解决现有代码生成基准数据集在处理真实世界软件结构时存在的局限性，该数据集从13,174个开源项目中提取，包含超过842,000个类骨架，包括类和方法签名以及文档字符串，并添加了静态代码指标。研究者使用这些类骨架作为提示输入GPT-4生成完整的类实现，结果显示生成的代码与人类代码在ROUGE@L、BLEU和TSED得分上分别达到0.80、0.59和0.73，证明结构化提示能显著提升LLMs在类级代码生成的性能。该数据集为基准测试、训练和改进LLMs在实际软件工程场景中的应用提供了宝贵资源。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "This paper was submitted to the 29th International Conference on\n  Evaluation and Assessment in Software Engineering (EASE 2025) AI models/data\n  track",
      "pdf_url": "http://arxiv.org/pdf/2504.15564v1",
      "published_date": "2025-04-22 03:33:57 UTC",
      "updated_date": "2025-04-22 03:33:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:46:58.161330"
    },
    {
      "arxiv_id": "2504.18569v1",
      "title": "Large Language Model Empowered Privacy-Protected Framework for PHI Annotation in Clinical Notes",
      "title_zh": "大语言模型赋能的隐私保护框架，用于临床笔记中的 PHI 标注",
      "authors": [
        "Guanchen Wu",
        "Linzhi Zheng",
        "Han Xie",
        "Zhen Xiang",
        "Jiaying Lu",
        "Darren Liu",
        "Delgersuren Bold",
        "Bo Li",
        "Xiao Hu",
        "Carl Yang"
      ],
      "abstract": "The de-identification of private information in medical data is a crucial\nprocess to mitigate the risk of confidentiality breaches, particularly when\npatient personal details are not adequately removed before the release of\nmedical records. Although rule-based and learning-based methods have been\nproposed, they often struggle with limited generalizability and require\nsubstantial amounts of annotated data for effective performance. Recent\nadvancements in large language models (LLMs) have shown significant promise in\naddressing these issues due to their superior language comprehension\ncapabilities. However, LLMs present challenges, including potential privacy\nrisks when using commercial LLM APIs and high computational costs for deploying\nopen-source LLMs locally. In this work, we introduce LPPA, an LLM-empowered\nPrivacy-Protected PHI Annotation framework for clinical notes, targeting the\nEnglish language. By fine-tuning LLMs locally with synthetic notes, LPPA\nensures strong privacy protection and high PHI annotation accuracy. Extensive\nexperiments demonstrate LPPA's effectiveness in accurately de-identifying\nprivate information, offering a scalable and efficient solution for enhancing\npatient privacy protection.",
      "tldr_zh": "这篇论文提出LPPA框架，利用Large Language Models (LLMs)来标注临床笔记中的PHI (Protected Health Information)，以解决现有规则和学习方法在泛化性和数据标注需求上的不足，同时避免使用商业LLM API带来的隐私风险。LPPA通过在本地微调LLMs并使用合成笔记，确保高隐私保护和PHI标注准确性。实验结果表明，该框架在PHI去标识化任务中表现出色，提供了一个可扩展、高效的患者隐私保护解决方案。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "Shorter version published in MedInfo 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.18569v1",
      "published_date": "2025-04-22 03:18:36 UTC",
      "updated_date": "2025-04-22 03:18:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:47:09.512132"
    },
    {
      "arxiv_id": "2504.15552v1",
      "title": "A Multi-Agent Framework for Automated Qinqiang Opera Script Generation Using Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Gengxian Cao",
        "Fengyuan Li",
        "Hong Duan",
        "Ye Yang",
        "Bofeng Wang",
        "Donghe Li"
      ],
      "abstract": "This paper introduces a novel multi-Agent framework that automates the end to\nend production of Qinqiang opera by integrating Large Language Models , visual\ngeneration, and Text to Speech synthesis. Three specialized agents collaborate\nin sequence: Agent1 uses an LLM to craft coherent, culturally grounded\nscripts;Agent2 employs visual generation models to render contextually accurate\nstage scenes; and Agent3 leverages TTS to produce synchronized, emotionally\nexpressive vocal performances. In a case study on Dou E Yuan, the system\nachieved expert ratings of 3.8 for script fidelity, 3.5 for visual coherence,\nand 3.8 for speech accuracy-culminating in an overall score of 3.6, a 0.3 point\nimprovement over a Single Agent baseline. Ablation experiments demonstrate that\nremoving Agent2 or Agent3 leads to drops of 0.4 and 0.5 points, respectively,\nunderscoring the value of modular collaboration. This work showcases how AI\ndriven pipelines can streamline and scale the preservation of traditional\nperforming arts, and points toward future enhancements in cross modal\nalignment, richer emotional nuance, and support for additional opera genres.",
      "tldr_zh": "本研究提出了一种多智能体框架，利用大型语言模型 (LLMs) 自动化秦腔戏曲的端到端生产，整合了 LLMs、视觉生成和文本到语音 (TTS) 合成。框架包括三个专门智能体：Agent1 使用 LLMs 创建连贯且文化底蕴深厚的脚本；Agent2 运用视觉生成模型渲染准确的舞台场景；Agent3 借助 TTS 产生同步且情感丰富的语音表演。在 Dou E Yuan 的案例研究中，该系统获得专家总分 3.6，比单一智能体基线提升 0.3 分，消融实验进一步证明移除 Agent2 或 Agent3 会显著降低性能。该框架展示了 AI 如何促进传统表演艺术的保存，并为未来跨模态对齐和支持更多戏曲类型提供潜力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "17 pages,7 figures,1 tables",
      "pdf_url": "http://arxiv.org/pdf/2504.15552v1",
      "published_date": "2025-04-22 03:14:29 UTC",
      "updated_date": "2025-04-22 03:14:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:47:23.692996"
    },
    {
      "arxiv_id": "2504.15549v1",
      "title": "Do It For Me vs. Do It With Me: Investigating User Perceptions of Different Paradigms of Automation in Copilots for Feature-Rich Software",
      "title_zh": "翻译失败",
      "authors": [
        "Anjali Khurana",
        "Xiaotian Su",
        "April Yi Wang",
        "Parmit K Chilana"
      ],
      "abstract": "Large Language Model (LLM)-based in-application assistants, or copilots, can\nautomate software tasks, but users often prefer learning by doing, raising\nquestions about the optimal level of automation for an effective user\nexperience. We investigated two automation paradigms by designing and\nimplementing a fully automated copilot (AutoCopilot) and a semi-automated\ncopilot (GuidedCopilot) that automates trivial steps while offering\nstep-by-step visual guidance. In a user study (N=20) across data analysis and\nvisual design tasks, GuidedCopilot outperformed AutoCopilot in user control,\nsoftware utility, and learnability, especially for exploratory and creative\ntasks, while AutoCopilot saved time for simpler visual tasks. A follow-up\ndesign exploration (N=10) enhanced GuidedCopilot with task-and state-aware\nfeatures, including in-context preview clips and adaptive instructions. Our\nfindings highlight the critical role of user control and tailored guidance in\ndesigning the next generation of copilots that enhance productivity, support\ndiverse skill levels, and foster deeper software engagement.",
      "tldr_zh": "本文研究了基于 Large Language Model (LLM) 的 copilots 在功能丰富的软件中的自动化范式，比较了全自动 AutoCopilot 和半自动 GuidedCopilot 的用户感知。用户研究（N=20）显示，GuidedCopilot 在用户控制、软件实用性和可学习性方面表现更好，尤其适用于探索性和创造性任务，而 AutoCopilot 则在简单视觉任务中节省时间。后续设计探索（N=10）通过添加任务感知预览和适应性指令增强了 GuidedCopilot，最终强调用户控制和定制指导是设计高效 copilots 的关键，以提升生产力、支持不同技能水平并促进更深层软件互动。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "comment": "Accepted for publication in the CHI Conference on Human Factors in\n  Computing Systems (CHI 2025), April 26 - May 1, 2025, Yokohama, Japan",
      "pdf_url": "http://arxiv.org/pdf/2504.15549v1",
      "published_date": "2025-04-22 03:11:10 UTC",
      "updated_date": "2025-04-22 03:11:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:47:34.295209"
    },
    {
      "arxiv_id": "2504.15546v2",
      "title": "A Framework for Testing and Adapting REST APIs as LLM Tools",
      "title_zh": "一种用于测试和适配 REST APIs 作为 LLM 工具的框架",
      "authors": [
        "Jayachandu Bandlamudi",
        "Ritwik Chaudhuri",
        "Neelamadhav Gantayat",
        "Kushal Mukherjee",
        "Prerna Agarwal",
        "Renuka Sindhgatta",
        "Sameep Mehta"
      ],
      "abstract": "Large Language Models (LLMs) are enabling autonomous agents to perform\ncomplex workflows using external tools or functions, often provided via REST\nAPIs in enterprise systems. However, directly utilizing these APIs as tools\nposes challenges due to their complex input schemas, elaborate responses, and\noften ambiguous documentation. Current benchmarks for tool testing do not\nadequately address these complexities, leading to a critical gap in evaluating\nAPI readiness for agent-driven automation. In this work, we present a novel\ntesting framework aimed at evaluating and enhancing the readiness of REST APIs\nto function as tools for LLM-based agents. Our framework transforms apis as\ntools, generates comprehensive test cases for the APIs, translates tests cases\ninto natural language instructions suitable for agents, enriches tool\ndefinitions and evaluates the agent's ability t correctly invoke the API and\nprocess its inputs and responses. To provide actionable insights, we analyze\nthe outcomes of 750 test cases, presenting a detailed taxonomy of errors,\nincluding input misinterpretation, output handling inconsistencies, and schema\nmismatches. Additionally, we classify these test cases to streamline debugging\nand refinement of tool integrations. This work offers a foundational step\ntoward enabling enterprise APIs as tools, improving their usability in\nagent-based applications.",
      "tldr_zh": "该论文提出一个框架，用于测试和适应 REST APIs 作为 LLM 工具，以解决 LLMs 在使用企业系统 API 时面临的复杂输入模式、详细响应和模糊文档等问题。该框架通过转换 APIs 为工具、生成全面测试用例、将测试用例转化为适合 LLM-based agents 的自然语言指令、丰富工具定义，并评估代理调用 API 和处理输入/响应的能力，来提升 API 的可用性。在分析 750 个测试用例后，论文建立了错误分类体系（如输入误解、输出处理不一致和模式不匹配），并分类测试用例以简化调试，从而为企业 APIs 在代理应用中的集成提供基础性改进。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "I.2.7"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.15546v2",
      "published_date": "2025-04-22 02:52:08 UTC",
      "updated_date": "2025-05-01 05:50:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:47:46.630065"
    },
    {
      "arxiv_id": "2504.16140v1",
      "title": "SparseJEPA: Sparse Representation Learning of Joint Embedding Predictive Architectures",
      "title_zh": "SparseJEPA：联合嵌入预测架构的稀疏表示学习",
      "authors": [
        "Max Hartman",
        "Lav Varshney"
      ],
      "abstract": "Joint Embedding Predictive Architectures (JEPA) have emerged as a powerful\nframework for learning general-purpose representations. However, these models\noften lack interpretability and suffer from inefficiencies due to dense\nembedding representations. We propose SparseJEPA, an extension that integrates\nsparse representation learning into the JEPA framework to enhance the quality\nof learned representations. SparseJEPA employs a penalty method that encourages\nlatent space variables to be shared among data features with strong semantic\nrelationships, while maintaining predictive performance. We demonstrate the\neffectiveness of SparseJEPA by training on the CIFAR-100 dataset and\npre-training a lightweight Vision Transformer. The improved embeddings are\nutilized in linear-probe transfer learning for both image classification and\nlow-level tasks, showcasing the architecture's versatility across different\ntransfer tasks. Furthermore, we provide a theoretical proof that demonstrates\nthat the grouping mechanism enhances representation quality. This was done by\ndisplaying that grouping reduces Multiinformation among latent-variables,\nincluding proofing the Data Processing Inequality for Multiinformation. Our\nresults indicate that incorporating sparsity not only refines the latent space\nbut also facilitates the learning of more meaningful and interpretable\nrepresentations. In further work, hope to further extend this method by finding\nnew ways to leverage the grouping mechanism through object-centric\nrepresentation learning.",
      "tldr_zh": "该论文提出 SparseJEPA，一种将稀疏表示学习整合到 Joint Embedding Predictive Architectures (JEPA) 框架中的扩展方法，以解决 JEPA 模型在表示质量、可解释性和效率方面的不足。SparseJEPA 通过 penalty method 鼓励潜变量在具有强语义关系的特征之间共享，从而保持预测性能的同时优化嵌入表示。在 CIFAR-100 数据集上训练并预训练轻量级 Vision Transformer 后，该方法在 linear-probe transfer learning 中表现出色，提升了图像分类和低级任务的性能。论文还提供了理论证明，表明分组机制通过减少 Multiinformation 提高了表示质量，并计划未来扩展到物体中心表示学习。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.16140v1",
      "published_date": "2025-04-22 02:43:00 UTC",
      "updated_date": "2025-04-22 02:43:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:47:59.788831"
    },
    {
      "arxiv_id": "2504.21019v1",
      "title": "Kill two birds with one stone: generalized and robust AI-generated text detection via dynamic perturbations",
      "title_zh": "翻译失败",
      "authors": [
        "Yinghan Zhou",
        "Juan Wen",
        "Wanli Peng",
        "Yiming Xue",
        "Ziwei Zhang",
        "Zhengxian Wu"
      ],
      "abstract": "The growing popularity of large language models has raised concerns regarding\nthe potential to misuse AI-generated text (AIGT). It becomes increasingly\ncritical to establish an excellent AIGT detection method with high\ngeneralization and robustness. However, existing methods either focus on model\ngeneralization or concentrate on robustness. The unified mechanism, to\nsimultaneously address the challenges of generalization and robustness, is less\nexplored. In this paper, we argue that robustness can be view as a specific\nform of domain shift, and empirically reveal an intrinsic mechanism for model\ngeneralization of AIGT detection task. Then, we proposed a novel AIGT detection\nmethod (DP-Net) via dynamic perturbations introduced by a reinforcement\nlearning with elaborated reward and action. Experimentally, extensive results\nshow that the proposed DP-Net significantly outperforms some state-of-the-art\nAIGT detection methods for generalization capacity in three cross-domain\nscenarios. Meanwhile, the DP-Net achieves best robustness under two text\nadversarial attacks. The code is publicly available at\nhttps://github.com/CAU-ISS-Lab/AIGT-Detection-Evade-Detection/tree/main/DP-Net.",
      "tldr_zh": "这篇论文针对AI-generated text (AIGT)的滥用问题，提出了一种统一方法来提升检测模型的泛化和鲁棒性。作者认为鲁棒性是领域转移的一种形式，并揭示了AIGT检测任务的内在泛化机制，然后开发了DP-Net，通过强化学习引入动态perturbations来优化检测过程。实验结果显示，DP-Net在三个跨域场景中泛化能力显著优于现有方法，并在两种文本对抗攻击下表现出最佳鲁棒性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by NAACL 2025 main conference",
      "pdf_url": "http://arxiv.org/pdf/2504.21019v1",
      "published_date": "2025-04-22 02:21:19 UTC",
      "updated_date": "2025-04-22 02:21:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:48:12.845993"
    },
    {
      "arxiv_id": "2504.15524v1",
      "title": "IPBench: Benchmarking the Knowledge of Large Language Models in Intellectual Property",
      "title_zh": "IPBench: 大语言模型在知识产权领域的知识基准测试",
      "authors": [
        "Qiyao Wang",
        "Guhong Chen",
        "Hongbo Wang",
        "Huaren Liu",
        "Minghui Zhu",
        "Zhifei Qin",
        "Linwei Li",
        "Yilin Yue",
        "Shiqiang Wang",
        "Jiayan Li",
        "Yihang Wu",
        "Ziqiang Liu",
        "Longze Chen",
        "Run Luo",
        "Liyang Fan",
        "Jiaming Li",
        "Lei Zhang",
        "Kan Xu",
        "Hongfei Lin",
        "Hamid Alinejad-Rokny",
        "Shiwen Ni",
        "Yuan Lin",
        "Min Yang"
      ],
      "abstract": "Intellectual Property (IP) is a unique domain that integrates technical and\nlegal knowledge, making it inherently complex and knowledge-intensive. As large\nlanguage models (LLMs) continue to advance, they show great potential for\nprocessing IP tasks, enabling more efficient analysis, understanding, and\ngeneration of IP-related content. However, existing datasets and benchmarks\neither focus narrowly on patents or cover limited aspects of the IP field,\nlacking alignment with real-world scenarios. To bridge this gap, we introduce\nthe first comprehensive IP task taxonomy and a large, diverse bilingual\nbenchmark, IPBench, covering 8 IP mechanisms and 20 tasks. This benchmark is\ndesigned to evaluate LLMs in real-world intellectual property applications,\nencompassing both understanding and generation. We benchmark 16 LLMs, ranging\nfrom general-purpose to domain-specific models, and find that even the\nbest-performing model achieves only 75.8% accuracy, revealing substantial room\nfor improvement. Notably, open-source IP and law-oriented models lag behind\nclosed-source general-purpose models. We publicly release all data and code of\nIPBench and will continue to update it with additional IP-related tasks to\nbetter reflect real-world challenges in the intellectual property domain.",
      "tldr_zh": "本论文介绍了 IPBench，这是一个全面的基准，用于评估大型语言模型（LLMs）在知识产权（IP）领域的知识表现，针对 IP 领域的技术与法律复杂性。研究团队首次提出一个 IP 任务分类法，并构建了一个大型多样化双语基准，涵盖 8 个 IP 机制和 20 个任务，包括理解和生成任务，以更好地模拟真实应用场景。对 16 个 LLMs（从通用到领域特定模型）的基准测试显示，最佳模型准确率仅为 75.8%，表明 LLMs 在 IP 任务上仍有显著改进空间；此外，开源的 IP 和法律导向模型落后于闭源通用模型。论文公开所有数据和代码，并计划持续更新以应对 IP 领域的实际挑战。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "89 pages, 75 figures, 55 tables",
      "pdf_url": "http://arxiv.org/pdf/2504.15524v1",
      "published_date": "2025-04-22 02:00:41 UTC",
      "updated_date": "2025-04-22 02:00:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:48:26.330544"
    },
    {
      "arxiv_id": "2504.15515v2",
      "title": "Transport f divergences",
      "title_zh": "翻译失败",
      "authors": [
        "Wuchen Li"
      ],
      "abstract": "We define a class of divergences to measure differences between probability\ndensity functions in one-dimensional sample space. The construction is based on\nthe convex function with the Jacobi operator of mapping function that\npushforwards one density to the other. We call these information measures\ntransport f-divergences. We present several properties of transport\n$f$-divergences, including invariances, convexities, variational formulations,\nand Taylor expansions in terms of mapping functions. Examples of transport\nf-divergences in generative models are provided.",
      "tldr_zh": "该论文定义了transport f-divergences，一种用于测量一维样本空间中概率密度函数之间差异的新型散度，基于凸函数和映射函数的Jacobi operator来实现密度pushforwards。论文探讨了这些散度的关键属性，包括不变性、凸性、变分公式以及对映射函数的Taylor expansions。最终，论文通过生成模型中的例子展示了transport f-divergences的应用潜力。",
      "categories": [
        "math.ST",
        "cs.AI",
        "cs.IT",
        "math.IT",
        "stat.TH"
      ],
      "primary_category": "math.ST",
      "comment": "Comments are welcome",
      "pdf_url": "http://arxiv.org/pdf/2504.15515v2",
      "published_date": "2025-04-22 01:25:41 UTC",
      "updated_date": "2025-04-23 01:18:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:48:35.938872"
    },
    {
      "arxiv_id": "2504.16139v1",
      "title": "Enhancing Trust Through Standards: A Comparative Risk-Impact Framework for Aligning ISO AI Standards with Global Ethical and Regulatory Contexts",
      "title_zh": "通过标准增强信任：一个用于将 ISO AI 标准与全球道德和监管环境对齐的比较风险影响",
      "authors": [
        "Sridharan Sankaran"
      ],
      "abstract": "As artificial intelligence (AI) reshapes industries and societies, ensuring\nits trustworthiness-through mitigating ethical risks like bias, opacity, and\naccountability deficits-remains a global challenge. International Organization\nfor Standardization (ISO) AI standards, such as ISO/IEC 24027 and 24368, aim to\nfoster responsible development by embedding fairness, transparency, and risk\nmanagement into AI systems. However, their effectiveness varies across diverse\nregulatory landscapes, from the EU's risk-based AI Act to China's\nstability-focused measures and the U.S.'s fragmented state-led initiatives.\nThis paper introduces a novel Comparative Risk-Impact Assessment Framework to\nevaluate how well ISO standards address ethical risks within these contexts,\nproposing enhancements to strengthen their global applicability. By mapping ISO\nstandards to the EU AI Act and surveying regulatory frameworks in ten\nregions-including the UK, Canada, India, Japan, Singapore, South Korea, and\nBrazil-we establish a baseline for ethical alignment. The framework, applied to\ncase studies in the EU, US-Colorado, and China, reveals gaps: voluntary ISO\nstandards falter in enforcement (e.g., Colorado) and undervalue region-specific\nrisks like privacy (China). We recommend mandatory risk audits, region-specific\nannexes, and a privacy-focused module to enhance ISO's adaptability. This\napproach not only synthesizes global trends but also offers a replicable tool\nfor aligning standardization with ethical imperatives, fostering\ninteroperability and trust in AI worldwide. Policymakers and standards bodies\ncan leverage these insights to evolve AI governance, ensuring it meets diverse\nsocietal needs as the technology advances.",
      "tldr_zh": "这篇论文提出了一种新的Comparative Risk-Impact Assessment Framework，用于评估ISO AI standards（如ISO/IEC 24027和24368）在全球不同监管环境中的有效性，旨在缓解AI伦理风险如偏见、不透明和责任缺失问题。研究通过映射ISO标准到EU AI Act并调查包括英国、加拿大、印度、日本、新加坡、南韩和巴西在内的十个地区的监管框架，揭示了标准在执行方面存在的差距，例如在美国的科罗拉多州强制性不足，以及对中国隐私风险的低重视。作者推荐实施强制风险审计、地区特定附件和隐私模块，以增强ISO标准的全球适应性，从而促进AI治理的互操作性和信任。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.16139v1",
      "published_date": "2025-04-22 00:44:20 UTC",
      "updated_date": "2025-04-22 00:44:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:48:49.187109"
    },
    {
      "arxiv_id": "2504.15499v1",
      "title": "Guillotine: Hypervisors for Isolating Malicious AIs",
      "title_zh": "Guillotine：用于隔离恶意 AI 的超管理程序",
      "authors": [
        "James Mickens",
        "Sarah Radway",
        "Ravi Netravali"
      ],
      "abstract": "As AI models become more embedded in critical sectors like finance,\nhealthcare, and the military, their inscrutable behavior poses ever-greater\nrisks to society. To mitigate this risk, we propose Guillotine, a hypervisor\narchitecture for sandboxing powerful AI models -- models that, by accident or\nmalice, can generate existential threats to humanity. Although Guillotine\nborrows some well-known virtualization techniques, Guillotine must also\nintroduce fundamentally new isolation mechanisms to handle the unique threat\nmodel posed by existential-risk AIs. For example, a rogue AI may try to\nintrospect upon hypervisor software or the underlying hardware substrate to\nenable later subversion of that control plane; thus, a Guillotine hypervisor\nrequires careful co-design of the hypervisor software and the CPUs, RAM, NIC,\nand storage devices that support the hypervisor software, to thwart side\nchannel leakage and more generally eliminate mechanisms for AI to exploit\nreflection-based vulnerabilities. Beyond such isolation at the software,\nnetwork, and microarchitectural layers, a Guillotine hypervisor must also\nprovide physical fail-safes more commonly associated with nuclear power plants,\navionic platforms, and other types of mission critical systems. Physical\nfail-safes, e.g., involving electromechanical disconnection of network cables,\nor the flooding of a datacenter which holds a rogue AI, provide defense in\ndepth if software, network, and microarchitectural isolation is compromised and\na rogue AI must be temporarily shut down or permanently destroyed.",
      "tldr_zh": "该论文提出 Guillotine，一种 hypervisor 架构，用于隔离可能构成生存威胁的恶意 AI，从而缓解 AI 在关键领域如金融、医疗和军事中的风险。Guillotine 借鉴虚拟化 techniques，但引入新机制，包括 hypervisor 软件与 CPU、RAM、NIC 和存储设备的协同设计，以防范 side channel leakage 和基于反射的漏洞。论文强调物理 fail-safes 的重要性，如断开网络电缆或摧毁数据中心，提供多层防御，确保在软件和硬件隔离失败时也能有效应对 AI 威胁。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.OS"
      ],
      "primary_category": "cs.CR",
      "comment": "To be published in the ACM SIGOPS 2025 Workshop on Hot Topics in\n  Operating Systems",
      "pdf_url": "http://arxiv.org/pdf/2504.15499v1",
      "published_date": "2025-04-22 00:29:18 UTC",
      "updated_date": "2025-04-22 00:29:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:49:00.848162"
    },
    {
      "arxiv_id": "2504.15497v1",
      "title": "Scalable APT Malware Classification via Parallel Feature Extraction and GPU-Accelerated Learning",
      "title_zh": "可扩展的 APT 恶意软件分类：通过并行特征提取和 GPU 加速学习",
      "authors": [
        "Noah Subedar",
        "Taeui Kim",
        "Saathwick Venkataramalingam"
      ],
      "abstract": "This paper presents an underlying framework for both automating and\naccelerating malware classification, more specifically, mapping malicious\nexecutables to known Advanced Persistent Threat (APT) groups. The main feature\nof this analysis is the assembly-level instructions present in executables\nwhich are also known as opcodes. The collection of such opcodes on many\nmalicious samples is a lengthy process; hence, open-source reverse engineering\ntools are used in tandem with scripts that leverage parallel computing to\nanalyze multiple files at once. Traditional and deep learning models are\napplied to create models capable of classifying malware samples. One-gram and\ntwo-gram datasets are constructed and used to train models such as SVM, KNN,\nand Decision Tree; however, they struggle to provide adequate results without\nrelying on metadata to support n-gram sequences. The computational limitations\nof such models are overcome with convolutional neural networks (CNNs) and\nheavily accelerated using graphical compute unit (GPU) resources.",
      "tldr_zh": "该论文提出了一种可扩展的框架，用于自动化和加速APT（Advanced Persistent Threat）恶意软件分类，通过并行特征提取处理可执行文件中的汇编指令（opcodes），并利用脚本和开源反向工程工具实现多文件同时分析。传统机器学习模型如SVM、KNN和Decision Tree在使用一元和二元数据集时效果有限，需要依赖元数据支持，而深度学习模型如CNN则通过GPU加速克服了计算瓶颈。实验结果表明，该框架显著提升了恶意软件分类的效率和准确性，为大规模APT检测提供了实用解决方案。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "I.2.0; I.2.6; K.6.5"
      ],
      "primary_category": "cs.CR",
      "comment": "26 pages, 54 figures, 14 tables",
      "pdf_url": "http://arxiv.org/pdf/2504.15497v1",
      "published_date": "2025-04-22 00:05:05 UTC",
      "updated_date": "2025-04-22 00:05:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:49:11.291354"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 106,
  "processed_papers_count": 106,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-24T15:49:31.611835"
}