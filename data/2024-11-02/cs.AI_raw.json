[
  {
    "arxiv_id": "2411.01375v3",
    "title": "Learning with Hidden Factorial Structure",
    "authors": [
      "Charles Arnal",
      "Clement Berenfeld",
      "Simon Rosenberg",
      "Vivien Cabannes"
    ],
    "abstract": "Statistical learning in high-dimensional spaces is challenging without a\nstrong underlying data structure. Recent advances with foundational models\nsuggest that text and image data contain such hidden structures, which help\nmitigate the curse of dimensionality. Inspired by results from nonparametric\nstatistics, we hypothesize that this phenomenon can be partially explained in\nterms of decomposition of complex tasks into simpler subtasks. In this paper,\nwe present a controlled experimental framework to test whether neural networks\ncan indeed exploit such \"hidden factorial structures\". We find that they do\nleverage these latent patterns to learn discrete distributions more\nefficiently. We also study the interplay between our structural assumptions and\nthe models' capacity for generalization.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "stat.ML",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.01375v3",
    "published_date": "2024-11-02 22:32:53 UTC",
    "updated_date": "2025-02-02 22:25:57 UTC"
  },
  {
    "arxiv_id": "2411.01373v1",
    "title": "Medical X-Ray Image Enhancement Using Global Contrast-Limited Adaptive Histogram Equalization",
    "authors": [
      "Sohrab Namazi Nia",
      "Frank Y. Shih"
    ],
    "abstract": "In medical imaging, accurate diagnosis heavily relies on effective image\nenhancement techniques, particularly for X-ray images. Existing methods often\nsuffer from various challenges such as sacrificing global image characteristics\nover local image characteristics or vice versa. In this paper, we present a\nnovel approach, called G-CLAHE (Global-Contrast Limited Adaptive Histogram\nEqualization), which perfectly suits medical imaging with a focus on X-rays.\nThis method adapts from Global Histogram Equalization (GHE) and Contrast\nLimited Adaptive Histogram Equalization (CLAHE) to take both advantages and\navoid weakness to preserve local and global characteristics. Experimental\nresults show that it can significantly improve current state-of-the-art\nalgorithms to effectively address their limitations and enhance the contrast\nand quality of X-ray images for diagnostic accuracy.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.01373v1",
    "published_date": "2024-11-02 22:20:56 UTC",
    "updated_date": "2024-11-02 22:20:56 UTC"
  },
  {
    "arxiv_id": "2411.01354v1",
    "title": "Online and Offline Evaluations of Collaborative Filtering and Content Based Recommender Systems",
    "authors": [
      "Ali Elahi",
      "Armin Zirak"
    ],
    "abstract": "Recommender systems are widely used AI applications designed to help users\nefficiently discover relevant items. The effectiveness of such systems is tied\nto the satisfaction of both users and providers. However, user satisfaction is\ncomplex and cannot be easily framed mathematically using information retrieval\nand accuracy metrics. While many studies evaluate accuracy through offline\ntests, a growing number of researchers argue that online evaluation methods\nsuch as A/B testing are better suited for this purpose. We have employed a\nvariety of algorithms on different types of datasets divergent in size and\nsubject, producing recommendations in various platforms, including media\nstreaming services, digital publishing websites, e-commerce systems, and news\nbroadcasting networks. Notably, our target websites and datasets are in Persian\n(Farsi) language.\n  This study provides a comparative analysis of a large-scale recommender\nsystem that has been operating for the past year across about 70 websites in\nIran, processing roughly 300 requests per second collectively. The system\nemploys user-based and item-based recommendations using content-based,\ncollaborative filtering, trend-based methods, and hybrid approaches. Through\nboth offline and online evaluations, we aim to identify where these algorithms\nperform most efficiently and determine the best method for our specific needs,\nconsidering the dataset and system scale. Our methods of evaluation include\nmanual evaluation, offline tests including accuracy and ranking metrics like\nhit-rate@k and nDCG, and online tests consisting of click-through rate (CTR).\nAdditionally we analyzed and proposed methods to address cold-start and\npopularity bias.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "9 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.01354v1",
    "published_date": "2024-11-02 20:05:31 UTC",
    "updated_date": "2024-11-02 20:05:31 UTC"
  },
  {
    "arxiv_id": "2411.01351v1",
    "title": "Guided Synthesis of Labeled Brain MRI Data Using Latent Diffusion Models for Segmentation of Enlarged Ventricles",
    "authors": [
      "Tim Ruschke",
      "Jonathan Frederik Carlsen",
      "Adam Espe Hansen",
      "Ulrich Lindberg",
      "Amalie Monberg Hindsholm",
      "Martin Norgaard",
      "Claes Nøhr Ladefoged"
    ],
    "abstract": "Deep learning models in medical contexts face challenges like data scarcity,\ninhomogeneity, and privacy concerns. This study focuses on improving\nventricular segmentation in brain MRI images using synthetic data. We employed\ntwo latent diffusion models (LDMs): a mask generator trained using 10,000\nmasks, and a corresponding SPADE image generator optimized using 6,881 scans to\ncreate an MRI conditioned on a 3D brain mask. Conditioning the mask generator\non ventricular volume in combination with classifier-free guidance enabled the\ncontrol of the ventricular volume distribution of the generated synthetic\nimages. Next, the performance of the synthetic data was tested using three\nnnU-Net segmentation models trained on a real, augmented and entirely synthetic\ndata, respectively. The resulting models were tested on a completely\nindependent hold-out dataset of patients with enlarged ventricles, with manual\ndelineation of the ventricles used as ground truth. The model trained on real\ndata showed a mean absolute error (MAE) of 9.09 \\pm 12.18 mL in predicted\nventricular volume, while the models trained on synthetic and augmented data\nshowed MAEs of 7.52 \\pm 4.81 mL and 6.23 \\pm 4.33 mL, respectively. Both the\nsynthetic and augmented model also outperformed the state-of-the-art model\nSynthSeg, which due to limited performance in cases of large ventricular\nvolumes, showed an MAE of 7.73 \\pm 12.12 mL with a factor of 3 higher standard\ndeviation. The model trained on augmented data showed the highest Dice score of\n0.892 \\pm 0.05, slightly outperforming SynthSeg and on par with the model\ntrained on real data. The synthetic model performed similar to SynthSeg. In\nsummary, we provide evidence that guided synthesis of labeled brain MRI data\nusing LDMs improves the segmentation of enlarged ventricles and outperforms\nexisting state-of-the-art segmentation models.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.01351v1",
    "published_date": "2024-11-02 19:44:10 UTC",
    "updated_date": "2024-11-02 19:44:10 UTC"
  },
  {
    "arxiv_id": "2411.01344v2",
    "title": "Privacy Leakage Overshadowed by Views of AI: A Study on Human Oversight of Privacy in Language Model Agent",
    "authors": [
      "Zhiping Zhang",
      "Bingcan Guo",
      "Tianshi Li"
    ],
    "abstract": "Language model (LM) agents that act on users' behalf for personal tasks\n(e.g., replying emails) can boost productivity, but are also susceptible to\nunintended privacy leakage risks. We present the first study on people's\ncapacity to oversee the privacy implications of the LM agents. By conducting a\ntask-based survey (N=300), we investigate how people react to and assess the\nresponse generated by LM agents for asynchronous interpersonal communication\ntasks, compared with a response they wrote. We found that people may favor the\nagent response with more privacy leakage over the response they drafted or\nconsider both good, leading to an increased harmful disclosure from 15.7% to\n55.0%. We further identified six privacy profiles to characterize distinct\npatterns of concerns, trust, and privacy preferences in LM agents. Our findings\nshed light on designing agentic systems that enable privacy-preserving\ninteractions and achieve bidirectional alignment on privacy preferences to help\nusers calibrate trust.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.01344v2",
    "published_date": "2024-11-02 19:15:42 UTC",
    "updated_date": "2025-01-30 20:31:49 UTC"
  },
  {
    "arxiv_id": "2411.01342v1",
    "title": "Adaptive World Models: Learning Behaviors by Latent Imagination Under Non-Stationarity",
    "authors": [
      "Emiliyan Gospodinov",
      "Vaisakh Shaj",
      "Philipp Becker",
      "Stefan Geyer",
      "Gerhard Neumann"
    ],
    "abstract": "Developing foundational world models is a key research direction for embodied\nintelligence, with the ability to adapt to non-stationary environments being a\ncrucial criterion. In this work, we introduce a new formalism, Hidden\nParameter-POMDP, designed for control with adaptive world models. We\ndemonstrate that this approach enables learning robust behaviors across a\nvariety of non-stationary RL benchmarks. Additionally, this formalism\neffectively learns task abstractions in an unsupervised manner, resulting in\nstructured, task-aware latent spaces.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at NeurIPS 2024 Workshop Adaptive Foundation Models",
    "pdf_url": "http://arxiv.org/pdf/2411.01342v1",
    "published_date": "2024-11-02 19:09:56 UTC",
    "updated_date": "2024-11-02 19:09:56 UTC"
  },
  {
    "arxiv_id": "2411.11862v1",
    "title": "Machine Learning Assisted Postural Movement Recognition using Photoplethysmography(PPG)",
    "authors": [
      "Robbie Maccay",
      "Roshan Weerasekera"
    ],
    "abstract": "With the growing percentage of elderly people and care home admissions, there\nis an urgent need for the development of fall detection and fall prevention\ntechnologies. This work presents, for the first time, the use of machine\nlearning techniques to recognize postural movements exclusively from\nPhotoplethysmography (PPG) data. To achieve this goal, a device was developed\nfor reading the PPG signal, segmenting the PPG signals into individual pulses,\nextracting pulse morphology and homeostatic characteristic features, and\nevaluating different ML algorithms. Investigations into different postural\nmovements (stationary, sitting to standing, and lying to standing) were\nperformed by 11 participants. The results of these investigations provided\ninsight into the differences in homeostasis after the movements in the PPG\nsignal. Various machine learning approaches were used for classification, and\nthe Artificial Neural Network (ANN) was found to be the best classifier, with a\ntesting accuracy of 85.2\\% and an F1 score of 78\\% from experimental results.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.11862v1",
    "published_date": "2024-11-02 18:56:41 UTC",
    "updated_date": "2024-11-02 18:56:41 UTC"
  },
  {
    "arxiv_id": "2411.10461v1",
    "title": "Utilizing Human Behavior Modeling to Manipulate Explanations in AI-Assisted Decision Making: The Good, the Bad, and the Scary",
    "authors": [
      "Zhuoyan Li",
      "Ming Yin"
    ],
    "abstract": "Recent advances in AI models have increased the integration of AI-based\ndecision aids into the human decision making process. To fully unlock the\npotential of AI-assisted decision making, researchers have computationally\nmodeled how humans incorporate AI recommendations into their final decisions,\nand utilized these models to improve human-AI team performance. Meanwhile, due\nto the ``black-box'' nature of AI models, providing AI explanations to human\ndecision makers to help them rely on AI recommendations more appropriately has\nbecome a common practice. In this paper, we explore whether we can\nquantitatively model how humans integrate both AI recommendations and\nexplanations into their decision process, and whether this quantitative\nunderstanding of human behavior from the learned model can be utilized to\nmanipulate AI explanations, thereby nudging individuals towards making targeted\ndecisions. Our extensive human experiments across various tasks demonstrate\nthat human behavior can be easily influenced by these manipulated explanations\ntowards targeted outcomes, regardless of the intent being adversarial or\nbenign. Furthermore, individuals often fail to detect any anomalies in these\nexplanations, despite their decisions being affected by them.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.10461v1",
    "published_date": "2024-11-02 18:33:28 UTC",
    "updated_date": "2024-11-02 18:33:28 UTC"
  },
  {
    "arxiv_id": "2411.01332v4",
    "title": "A Mechanistic Explanatory Strategy for XAI",
    "authors": [
      "Marcin Rabiza"
    ],
    "abstract": "Despite significant advancements in XAI, scholars continue to note a\npersistent lack of robust conceptual foundations and integration with broader\ndiscourse on scientific explanation. In response, emerging XAI research\nincreasingly draws on explanatory strategies from various scientific\ndisciplines and the philosophy of science to address these gaps. This paper\noutlines a mechanistic strategy for explaining the functional organization of\ndeep learning systems, situating recent developments in AI explainability\nwithin a broader philosophical context. According to the mechanistic approach,\nexplaining opaque AI systems involves identifying the mechanisms underlying\ndecision-making processes. For deep neural networks, this means discerning\nfunctionally relevant components - such as neurons, layers, circuits, or\nactivation patterns - and understanding their roles through decomposition,\nlocalization, and recomposition. Proof-of-principle case studies from image\nrecognition and language modeling align this theoretical framework with recent\nresearch from OpenAI and Anthropic. The findings suggest that pursuing\nmechanistic explanations can uncover elements that traditional explainability\ntechniques may overlook, ultimately contributing to more thoroughly explainable\nAI.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Forthcoming in M\\\"uller, V. C., Dung, L., L\\\"ohr, G., & Rumana, A.\n  (Eds.). Philosophy of Artificial Intelligence: The State of the Art, Synthese\n  Library, Springer Nature. Please cite the published version",
    "pdf_url": "http://arxiv.org/pdf/2411.01332v4",
    "published_date": "2024-11-02 18:30:32 UTC",
    "updated_date": "2025-03-25 01:41:47 UTC"
  },
  {
    "arxiv_id": "2411.01327v2",
    "title": "Visual Fourier Prompt Tuning",
    "authors": [
      "Runjia Zeng",
      "Cheng Han",
      "Qifan Wang",
      "Chunshu Wu",
      "Tong Geng",
      "Lifu Huang",
      "Ying Nian Wu",
      "Dongfang Liu"
    ],
    "abstract": "With the scale of vision Transformer-based models continuing to grow,\nfinetuning these large-scale pretrained models for new tasks has become\nincreasingly parameter-intensive. Visual prompt tuning is introduced as a\nparameter-efficient finetuning (PEFT) method to this trend. Despite its\nsuccesses, a notable research challenge persists within almost all PEFT\napproaches: significant performance degradation is observed when there is a\nsubstantial disparity between the datasets applied in pretraining and\nfinetuning phases. To address this challenge, we draw inspiration from human\nvisual cognition, and propose the Visual Fourier Prompt Tuning (VFPT) method as\na general and effective solution for adapting large-scale transformer-based\nmodels. Our approach innovatively incorporates the Fast Fourier Transform into\nprompt embeddings and harmoniously considers both spatial and frequency domain\ninformation. Apart from its inherent simplicity and intuitiveness, VFPT\nexhibits superior performance across all datasets, offering a general solution\nto dataset challenges, irrespective of data disparities. Empirical results\ndemonstrate that our approach outperforms current state-of-the-art baselines on\ntwo benchmarks, with low parameter usage (e.g., 0.57% of model parameters on\nVTAB-1k) and notable performance enhancements (e.g., 73.20% of mean accuracy on\nVTAB-1k). Our code is avaliable at https://github.com/runtsang/VFPT.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "[NeurIPS 2024] Homepage: https://runjia.tech/vfpt_page/",
    "pdf_url": "http://arxiv.org/pdf/2411.01327v2",
    "published_date": "2024-11-02 18:18:35 UTC",
    "updated_date": "2024-11-15 22:18:42 UTC"
  },
  {
    "arxiv_id": "2411.01316v1",
    "title": "FEED: Fairness-Enhanced Meta-Learning for Domain Generalization",
    "authors": [
      "Kai Jiang",
      "Chen Zhao",
      "Haoliang Wang",
      "Feng Chen"
    ],
    "abstract": "Generalizing to out-of-distribution data while being aware of model fairness\nis a significant and challenging problem in meta-learning. The goal of this\nproblem is to find a set of fairness-aware invariant parameters of classifier\nthat is trained using data drawn from a family of related training domains with\ndistribution shift on non-sensitive features as well as different levels of\ndependence between model predictions and sensitive features so that the\nclassifier can achieve good generalization performance on unknown but distinct\ntest domains. To tackle this challenge, existing state-of-the-art methods\neither address the domain generalization problem but completely ignore learning\nwith fairness or solely specify shifted domains with various fairness levels.\nThis paper introduces an approach to fairness-aware meta-learning that\nsignificantly enhances domain generalization capabilities. Our framework,\nFairness-Enhanced Meta-Learning for Domain Generalization (FEED), disentangles\nlatent data representations into content, style, and sensitive vectors. This\ndisentanglement facilitates the robust generalization of machine learning\nmodels across diverse domains while adhering to fairness constraints. Unlike\ntraditional methods that focus primarily on domain invariance or sensitivity to\nshifts, our model integrates a fairness-aware invariance criterion directly\ninto the meta-learning process. This integration ensures that the learned\nparameters uphold fairness consistently, even when domain characteristics vary\nwidely. We validate our approach through extensive experiments across multiple\nbenchmarks, demonstrating not only superior performance in maintaining high\naccuracy and fairness but also significant improvements over existing\nstate-of-the-art methods in domain generalization tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "IEEE International Conference on Big Data 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.01316v1",
    "published_date": "2024-11-02 17:34:33 UTC",
    "updated_date": "2024-11-02 17:34:33 UTC"
  },
  {
    "arxiv_id": "2411.03343v2",
    "title": "What Features in Prompts Jailbreak LLMs? Investigating the Mechanisms Behind Attacks",
    "authors": [
      "Nathalie Kirch",
      "Constantin Weisser",
      "Severin Field",
      "Helen Yannakoudakis",
      "Stephen Casper"
    ],
    "abstract": "Jailbreaks have been a central focus of research regarding the safety and\nreliability of large language models (LLMs), yet the mechanisms underlying\nthese attacks remain poorly understood. While previous studies have\npredominantly relied on linear methods to detect jailbreak attempts and model\nrefusals, we take a different approach by examining both linear and non-linear\nfeatures in prompts that lead to successful jailbreaks. First, we introduce a\nnovel dataset comprising 10,800 jailbreak attempts spanning 35 diverse attack\nmethods. Leveraging this dataset, we train probes to classify successful from\nunsuccessful jailbreaks using the latent representations corresponding to\nprompt tokens. Notably, we find that even when probes achieve high accuracy in\npredicting the success of jailbreaks, their performance often fails to\ngeneralize to unseen attack methods. This reveals that different jailbreaking\nstrategies exploit different non-linear, non-universal features. Next, we\ndemonstrate that non-linear probes provide a powerful tool for steering model\nbehavior. Specifically, we use these probes to guide targeted latent space\nperturbations, enabling us to effectively modulate the model's robustness\nagainst jailbreaks. Overall, our findings challenge the assumption that\njailbreaks can be fully understood through linear or simple universal prompt\nfeatures alone, highlighting the importance of a nuanced understanding of the\nmechanisms behind LLM vulnerabilities.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.03343v2",
    "published_date": "2024-11-02 17:29:47 UTC",
    "updated_date": "2025-05-14 12:32:17 UTC"
  },
  {
    "arxiv_id": "2411.01313v2",
    "title": "False Data Injection Attack Detection in Edge-based Smart Metering Networks with Federated Learning",
    "authors": [
      "Md Raihan Uddin",
      "Ratun Rahman",
      "Dinh C. Nguyen"
    ],
    "abstract": "Smart metering networks are increasingly susceptible to cyber threats, where\nfalse data injection (FDI) appears as a critical attack. Data-driven-based\nmachine learning (ML) methods have shown immense benefits in detecting FDI\nattacks via data learning and prediction abilities. Literature works have\nmostly focused on centralized learning and deploying FDI attack detection\nmodels at the control center, which requires data collection from local\nutilities like meters and transformers. However, this data sharing may raise\nprivacy concerns due to the potential disclosure of household information like\nenergy usage patterns. This paper proposes a new privacy-preserved FDI attack\ndetection by developing an efficient federated learning (FL) framework in the\nsmart meter network with edge computing. Distributed edge servers located at\nthe network edge run an ML-based FDI attack detection model and share the\ntrained model with the grid operator, aiming to build a strong FDI attack\ndetection model without data sharing. Simulation results demonstrate the\nefficiency of our proposed FL method over the conventional method without\ncollaboration.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "This work has been accepted by IEEE Consumer Communications &\n  Networking Conference (CCNC)",
    "pdf_url": "http://arxiv.org/pdf/2411.01313v2",
    "published_date": "2024-11-02 17:23:08 UTC",
    "updated_date": "2024-11-06 18:30:25 UTC"
  },
  {
    "arxiv_id": "2411.01312v2",
    "title": "From Federated Learning to Quantum Federated Learning for Space-Air-Ground Integrated Networks",
    "authors": [
      "Vu Khanh Quy",
      "Nguyen Minh Quy",
      "Tran Thi Hoai",
      "Shaba Shaon",
      "Md Raihan Uddin",
      "Tien Nguyen",
      "Dinh C. Nguyen",
      "Aryan Kaushik",
      "Periklis Chatzimisios"
    ],
    "abstract": "6G wireless networks are expected to provide seamless and data-based\nconnections that cover space-air-ground and underwater networks. As a core\npartition of future 6G networks, Space-Air-Ground Integrated Networks (SAGIN)\nhave been envisioned to provide countless real-time intelligent applications.\nTo realize this, promoting AI techniques into SAGIN is an inevitable trend. Due\nto the distributed and heterogeneous architecture of SAGIN, federated learning\n(FL) and then quantum FL are emerging AI model training techniques for enabling\nfuture privacy-enhanced and computation-efficient SAGINs. In this work, we\nexplore the vision of using FL/QFL in SAGINs. We present a few representative\napplications enabled by the integration of FL and QFL in SAGINs. A case study\nof QFL over UAV networks is also given, showing the merit of quantum-enabled\ntraining approach over the conventional FL benchmark. Research challenges along\nwith standardization for QFL adoption in future SAGINs are also highlighted.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "This work has been accepted by IEEE Conference on Standards for\n  Communications and Networking",
    "pdf_url": "http://arxiv.org/pdf/2411.01312v2",
    "published_date": "2024-11-02 17:13:00 UTC",
    "updated_date": "2024-11-06 18:35:53 UTC"
  },
  {
    "arxiv_id": "2411.01297v2",
    "title": "Receding Hamiltonian-Informed Optimal Neural Control and State Estimation for Closed-Loop Dynamical Systems",
    "authors": [
      "Josue N. Rivera",
      "Dengfeng Sun"
    ],
    "abstract": "This paper formalizes Hamiltonian-Informed Optimal Neural (Hion) controllers,\na novel class of neural network-based controllers for dynamical systems and\nexplicit non-linear model predictive control. Hion controllers estimate future\nstates and compute optimal control inputs using Pontryagin's Maximum Principle.\nThe proposed framework allows for customization of transient behavior,\naddressing limitations of existing methods. The Taylored Multi-Faceted Approach\nfor Neural ODE and Optimal Control (T-mano) architecture facilitates training\nand ensures accurate state estimation. Optimal control strategies are\ndemonstrated for both linear and non-linear dynamical systems.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.ET",
      "cs.LG",
      "cs.RO",
      "cs.SY"
    ],
    "primary_category": "eess.SY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.01297v2",
    "published_date": "2024-11-02 16:06:29 UTC",
    "updated_date": "2024-11-09 18:19:03 UTC"
  },
  {
    "arxiv_id": "2411.01295v2",
    "title": "Marginal Causal Flows for Validation and Inference",
    "authors": [
      "Daniel de Vassimon Manela",
      "Laura Battaglia",
      "Robin J. Evans"
    ],
    "abstract": "Investigating the marginal causal effect of an intervention on an outcome\nfrom complex data remains challenging due to the inflexibility of employed\nmodels and the lack of complexity in causal benchmark datasets, which often\nfail to reproduce intricate real-world data patterns. In this paper we\nintroduce Frugal Flows, a novel likelihood-based machine learning model that\nuses normalising flows to flexibly learn the data-generating process, while\nalso directly inferring the marginal causal quantities from observational data.\nWe propose that these models are exceptionally well suited for generating\nsynthetic data to validate causal methods. They can create synthetic datasets\nthat closely resemble the empirical dataset, while automatically and exactly\nsatisfying a user-defined average treatment effect. To our knowledge, Frugal\nFlows are the first generative model to both learn flexible data\nrepresentations and also exactly parameterise quantities such as the average\ntreatment effect and the degree of unobserved confounding. We demonstrate the\nabove with experiments on both simulated and real-world datasets.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ME",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "23 pages, 10 figures, Accepted as a Poster at NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.01295v2",
    "published_date": "2024-11-02 16:04:57 UTC",
    "updated_date": "2024-12-05 02:49:36 UTC"
  },
  {
    "arxiv_id": "2411.01292v2",
    "title": "Causal reasoning in difference graphs",
    "authors": [
      "Charles K. Assaad"
    ],
    "abstract": "Understanding causal mechanisms across different populations is essential for\ndesigning effective public health interventions. Recently, difference graphs\nhave been introduced as a tool to visually represent causal variations between\ntwo distinct populations. While there has been progress in inferring these\ngraphs from data through causal discovery methods, there remains a gap in\nsystematically leveraging their potential to enhance causal reasoning. This\npaper addresses that gap by establishing conditions for identifying causal\nchanges and effects using difference graphs. It specifically focuses on\nidentifying total causal changes and total effects in a nonparametric setting,\nas well as direct causal changes and direct effects in a linear setting. In\ndoing so, it provides a novel approach to causal reasoning that holds potential\nfor various public health applications.",
    "categories": [
      "cs.AI",
      "stat.ME"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted at CLeaR2025",
    "pdf_url": "http://arxiv.org/pdf/2411.01292v2",
    "published_date": "2024-11-02 16:01:42 UTC",
    "updated_date": "2025-02-16 12:17:39 UTC"
  },
  {
    "arxiv_id": "2411.01281v3",
    "title": "Varco Arena: A Tournament Approach to Reference-Free Benchmarking Large Language Models",
    "authors": [
      "Seonil Son",
      "Ju-Min Oh",
      "Heegon Jin",
      "Cheolhun Jang",
      "Jeongbeom Jeong",
      "Kuntae Kim"
    ],
    "abstract": "Most existing benchmarking approaches for evaluating the output quality of\nlarge language models (LLMs) rely on comparing LLM responses to predefined\nreferences. Such methods, based on static datasets, quickly become outdated as\nLLM capabilities and use cases evolve. In this work, we introduce VARCO\nArena--a novel, cost-effective, and robust benchmarking approach that leverages\na single-elimination tournament structure to minimize the number of required\ncomparisons while eliminating the need for static references or costly human\nannotations. We validate our approach through two experiments: (i) a simulation\nstudy that examines its robustness under various conditions, and (ii) an\nempirical evaluation using publicly available benchmark prompts. In both\nexperiments, VARCO Arena consistently outperforms current LLM benchmarking\npractices, achieving stronger correlations with human-established Elo ratings.\nOur results demonstrate that VARCO Arena not only produces reliable LLM\nrankings but also provides a scalable, adaptable solution for qualitative\nevaluation across diverse, customized use cases.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "8 pages for main body, 17 pages in total",
    "pdf_url": "http://arxiv.org/pdf/2411.01281v3",
    "published_date": "2024-11-02 15:23:28 UTC",
    "updated_date": "2025-02-19 01:34:31 UTC"
  },
  {
    "arxiv_id": "2411.01272v1",
    "title": "Improving Energy Efficiency in Manufacturing: A Novel Expert System Shell",
    "authors": [
      "Borys Ioshchikhes",
      "Michael Frank",
      "Tresa Maria Joseph",
      "Matthias Weigold"
    ],
    "abstract": "Expert systems are effective tools for automatically identifying energy\nefficiency potentials in manufacturing, thereby contributing significantly to\nglobal climate targets. These systems analyze energy data, pinpoint\ninefficiencies, and recommend optimizations to reduce energy consumption.\nBeyond systematic approaches for developing expert systems, there is a pressing\nneed for simple and rapid software implementation solutions. Expert system\nshells, which facilitate the swift development and deployment of expert\nsystems, are crucial tools in this process. They provide a template that\nsimplifies the creation and integration of expert systems into existing\nmanufacturing processes. This paper provides a comprehensive comparison of\nexisting expert system shells regarding their suitability for improving energy\nefficiency, highlighting significant gaps and limitations. To address these\ndeficiencies, we introduce a novel expert system shell, implemented in Jupyter\nNotebook, that provides a flexible and easily integrable solution for expert\nsystem development.",
    "categories": [
      "cs.AI",
      "cs.HC",
      "cs.SE"
    ],
    "primary_category": "cs.AI",
    "comment": "6 pages, 3 figures, preprint for conference contribution",
    "pdf_url": "http://arxiv.org/pdf/2411.01272v1",
    "published_date": "2024-11-02 14:50:37 UTC",
    "updated_date": "2024-11-02 14:50:37 UTC"
  },
  {
    "arxiv_id": "2411.01271v1",
    "title": "Interacting Large Language Model Agents. Interpretable Models and Social Learning",
    "authors": [
      "Adit Jain",
      "Vikram Krishnamurthy"
    ],
    "abstract": "This paper develops theory and algorithms for interacting large language\nmodel agents (LLMAs) using methods from statistical signal processing and\nmicroeconomics. While both fields are mature, their application to\ndecision-making by interacting LLMAs remains unexplored. Motivated by Bayesian\nsentiment analysis on online platforms, we construct interpretable models and\nstochastic control algorithms that enable LLMAs to interact and perform\nBayesian inference. Because interacting LLMAs learn from prior decisions and\nexternal inputs, they exhibit bias and herding behavior. Thus, developing\ninterpretable models and stochastic control algorithms is essential to\nunderstand and mitigate these behaviors. This paper has three main results.\nFirst, we show using Bayesian revealed preferences from microeconomics that an\nindividual LLMA satisfies the sufficient conditions for rationally inattentive\n(bounded rationality) utility maximization and, given an observation, the LLMA\nchooses an action that maximizes a regularized utility. Second, we utilize\nBayesian social learning to construct interpretable models for LLMAs that\ninteract sequentially with each other and the environment while performing\nBayesian inference. Our models capture the herding behavior exhibited by\ninteracting LLMAs. Third, we propose a stochastic control framework to delay\nherding and improve state estimation accuracy under two settings: (a) centrally\ncontrolled LLMAs and (b) autonomous LLMAs with incentives. Throughout the\npaper, we demonstrate the efficacy of our methods on real datasets for hate\nspeech classification and product quality assessment, using open-source models\nlike Mistral and closed-source models like ChatGPT. The main takeaway of this\npaper, based on substantial empirical analysis and mathematical formalism, is\nthat LLMAs act as rationally bounded Bayesian agents that exhibit social\nlearning when interacting.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.ET",
      "cs.MA",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.01271v1",
    "published_date": "2024-11-02 14:49:34 UTC",
    "updated_date": "2024-11-02 14:49:34 UTC"
  },
  {
    "arxiv_id": "2411.02442v2",
    "title": "TODO: Enhancing LLM Alignment with Ternary Preferences",
    "authors": [
      "Yuxiang Guo",
      "Lu Yin",
      "Bo Jiang",
      "Jiaqi Zhang"
    ],
    "abstract": "Aligning large language models (LLMs) with human intent is critical for\nenhancing their performance across a variety of tasks. Standard alignment\ntechniques, such as Direct Preference Optimization (DPO), often rely on the\nbinary Bradley-Terry (BT) model, which can struggle to capture the complexities\nof human preferences -- particularly in the presence of noisy or inconsistent\nlabels and frequent ties. To address these limitations, we introduce the\nTie-rank Oriented Bradley-Terry model (TOBT), an extension of the BT model that\nexplicitly incorporates ties, enabling more nuanced preference representation.\nBuilding on this, we propose Tie-rank Oriented Direct Preference Optimization\n(TODO), a novel alignment algorithm that leverages TOBT's ternary ranking\nsystem to improve preference alignment. In evaluations on Mistral-7B and Llama\n3-8B models, TODO consistently outperforms DPO in modeling preferences across\nboth in-distribution and out-of-distribution datasets. Additional assessments\nusing MT Bench and benchmarks such as Piqa, ARC-c, and MMLU further demonstrate\nTODO's superior alignment performance. Notably, TODO also shows strong results\nin binary preference alignment, highlighting its versatility and potential for\nbroader integration into LLM alignment. The implementation details can be found\nin https://github.com/XXares/TODO.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2411.02442v2",
    "published_date": "2024-11-02 14:36:03 UTC",
    "updated_date": "2025-03-29 02:56:45 UTC"
  },
  {
    "arxiv_id": "2411.01240v2",
    "title": "Boosting Federated Learning with FedEntOpt: Mitigating Label Skew by Entropy-Based Client Selection",
    "authors": [
      "Andreas Lutz",
      "Gabriele Steidl",
      "Karsten Müller",
      "Wojciech Samek"
    ],
    "abstract": "Deep learning is an emerging field revolutionizing various industries,\nincluding natural language processing, computer vision, and many more. These\ndomains typically require an extensive amount of data for optimal performance,\npotentially utilizing huge centralized data repositories. However, such\ncentralization could raise privacy issues concerning the storage of sensitive\ndata. To address this issue, federated learning was developed. It is a newly\ndistributed learning technique that enables to collaboratively train a deep\nlearning model on decentralized devices, referred to as clients, without\ncompromising their data privacy. Traditional federated learning methods often\nsuffer from severe performance degradation when the data distribution among\nclients differs significantly. This becomes especially problematic in the case\nof label distribution skew, where the distribution of labels varies across\nclients. To address this, a novel method called FedEntOpt is proposed.\nFedEntOpt is designed to mitigate performance issues caused by label\ndistribution skew by maximizing the entropy of the global label distribution of\nthe selected client subset in each federated learning round. This ensures that\nthe aggregated model parameters from the clients were exhibited to data from\nall available labels, which improves the accuracy of the global model.\nExtensive experiments on multiple benchmark datasets show that the proposed\nmethod outperforms several state-of-the-art algorithms by up to 6\\% in\nclassification accuracy under standard settings regardless of the model size.\nMoreover, it exhibits robust and superior performance in scenarios with low\nparticipation rates and client dropout, achieving increases in classification\naccuracy of over 30\\%. In addition, FedEntOpt offers the flexibility to be\ncombined with existing algorithms, enhancing their performance by over 40\\%.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.01240v2",
    "published_date": "2024-11-02 13:31:36 UTC",
    "updated_date": "2025-01-29 14:17:58 UTC"
  },
  {
    "arxiv_id": "2411.01236v1",
    "title": "AutoPT: How Far Are We from the End2End Automated Web Penetration Testing?",
    "authors": [
      "Benlong Wu",
      "Guoqiang Chen",
      "Kejiang Chen",
      "Xiuwei Shang",
      "Jiapeng Han",
      "Yanru He",
      "Weiming Zhang",
      "Nenghai Yu"
    ],
    "abstract": "Penetration testing is essential to ensure Web security, which can detect and\nfix vulnerabilities in advance, and prevent data leakage and serious\nconsequences. The powerful inference capabilities of large language models\n(LLMs) have made significant progress in various fields, and the development\npotential of LLM-based agents can revolutionize the cybersecurity penetration\ntesting industry. In this work, we establish a comprehensive end-to-end\npenetration testing benchmark using a real-world penetration testing\nenvironment to explore the capabilities of LLM-based agents in this domain. Our\nresults reveal that the agents are familiar with the framework of penetration\ntesting tasks, but they still face limitations in generating accurate commands\nand executing complete processes. Accordingly, we summarize the current\nchallenges, including the difficulty of maintaining the entire message history\nand the tendency for the agent to become stuck.\n  Based on the above insights, we propose a Penetration testing State Machine\n(PSM) that utilizes the Finite State Machine (FSM) methodology to address these\nlimitations. Then, we introduce AutoPT, an automated penetration testing agent\nbased on the principle of PSM driven by LLMs, which utilizes the inherent\ninference ability of LLM and the constraint framework of state machines. Our\nevaluation results show that AutoPT outperforms the baseline framework ReAct on\nthe GPT-4o mini model and improves the task completion rate from 22% to 41% on\nthe benchmark target. Compared with the baseline framework and manual work,\nAutoPT also reduces time and economic costs further. Hence, our AutoPT has\nfacilitated the development of automated penetration testing and significantly\nimpacted both academia and industry.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "22 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.01236v1",
    "published_date": "2024-11-02 13:24:30 UTC",
    "updated_date": "2024-11-02 13:24:30 UTC"
  },
  {
    "arxiv_id": "2411.01228v2",
    "title": "The Interaction Layer: An Exploration for Co-Designing User-LLM Interactions in Parental Wellbeing Support Systems",
    "authors": [
      "Sruthi Viswanathan",
      "Seray Ibrahim",
      "Ravi Shankar",
      "Reuben Binns",
      "Max Van Kleek",
      "Petr Slovak"
    ],
    "abstract": "Parenting brings emotional and physical challenges, from balancing work,\nchildcare, and finances to coping with exhaustion and limited personal time.\nYet, one in three parents never seek support. AI systems potentially offer\nstigma-free, accessible, and affordable solutions. Yet, user adoption often\nfails due to issues with explainability and reliability. To see if these issues\ncould be solved using a co-design approach, we developed and tested NurtureBot,\na wellbeing support assistant for new parents. 32 parents co-designed the\nsystem through Asynchronous Remote Communities method, identifying the key\nchallenge as achieving a \"successful chat.\" As part of co-design, parents\nrole-played as NurtureBot, rewriting its dialogues to improve user\nunderstanding, control, and outcomes. The refined prototype, featuring an\nInteraction Layer, was evaluated by 32 initial and 46 new parents, showing\nimproved user experience and usability, with final CUQ score of 91.3/100,\ndemonstrating successful interaction patterns. Our process revealed useful\ninteraction design lessons for effective AI parenting support.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.01228v2",
    "published_date": "2024-11-02 12:32:36 UTC",
    "updated_date": "2025-03-12 16:29:28 UTC"
  },
  {
    "arxiv_id": "2411.01212v1",
    "title": "Infinite-Resolution Integral Noise Warping for Diffusion Models",
    "authors": [
      "Yitong Deng",
      "Winnie Lin",
      "Lingxiao Li",
      "Dmitriy Smirnov",
      "Ryan Burgert",
      "Ning Yu",
      "Vincent Dedun",
      "Mohammad H. Taghavi"
    ],
    "abstract": "Adapting pretrained image-based diffusion models to generate temporally\nconsistent videos has become an impactful generative modeling research\ndirection. Training-free noise-space manipulation has proven to be an effective\ntechnique, where the challenge is to preserve the Gaussian white noise\ndistribution while adding in temporal consistency. Recently, Chang et al.\n(2024) formulated this problem using an integral noise representation with\ndistribution-preserving guarantees, and proposed an upsampling-based algorithm\nto compute it. However, while their mathematical formulation is advantageous,\nthe algorithm incurs a high computational cost. Through analyzing the\nlimiting-case behavior of their algorithm as the upsampling resolution goes to\ninfinity, we develop an alternative algorithm that, by gathering increments of\nmultiple Brownian bridges, achieves their infinite-resolution accuracy while\nsimultaneously reducing the computational cost by orders of magnitude. We prove\nand experimentally validate our theoretical claims, and demonstrate our\nmethod's effectiveness in real-world applications. We further show that our\nmethod readily extends to the 3-dimensional space.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.01212v1",
    "published_date": "2024-11-02 11:05:00 UTC",
    "updated_date": "2024-11-02 11:05:00 UTC"
  },
  {
    "arxiv_id": "2411.01211v2",
    "title": "Spatial Transformers for Radio Map Estimation",
    "authors": [
      "Pham Q. Viet",
      "Daniel Romero"
    ],
    "abstract": "Radio map estimation (RME) involves spatial interpolation of radio\nmeasurements to predict metrics such as the received signal strength at\nlocations where no measurements were collected. The most popular estimators\nnowadays project the measurement locations to a regular grid and complete the\nresulting measurement tensor with a convolutional deep neural network.\nUnfortunately, these approaches suffer from poor spatial resolution and require\na great number of parameters. The first contribution of this paper addresses\nthese limitations by means of an attention-based estimator named Spatial\nTransfOrmer for Radio Map estimation (STORM). This scheme not only outperforms\nthe existing estimators, but also exhibits lower computational complexity,\ntranslation equivariance, rotation equivariance, and full spatial resolution.\nThe second contribution is an extended transformer architecture that allows\nSTORM to perform active sensing, by which the next measurement location is\nselected based on the previous measurements. This is particularly useful for\nminimization of drive tests (MDT) in cellular networks, where operators request\nuser equipment to collect measurements. Finally, STORM is extensively validated\nby experiments with one ray-tracing and two real-measurement datasets.",
    "categories": [
      "math.OC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "math.OC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.01211v2",
    "published_date": "2024-11-02 11:04:45 UTC",
    "updated_date": "2024-11-07 14:51:44 UTC"
  },
  {
    "arxiv_id": "2411.01205v1",
    "title": "PRIMO: Progressive Induction for Multi-hop Open Rule Generation",
    "authors": [
      "Jianyu Liu",
      "Sheng Bi",
      "Guilin Qi"
    ],
    "abstract": "Open rule refer to the implication from premise atoms to hypothesis atoms,\nwhich captures various relations between instances in the real world. Injecting\nopen rule knowledge into the machine helps to improve the performance of\ndownstream tasks such as dialogue and relation extraction. Existing approaches\nfocus on single-hop open rule generation, ignoring multi-hop scenarios, leading\nto logical inconsistencies between premise and hypothesis atoms, as well as\nsemantic duplication of generated rule atoms. To address these issues, we\npropose a progressive multi-stage open rule generation method called PRIMO. We\nintroduce ontology information during the rule generation stage to reduce\nambiguity and improve rule accuracy. PRIMO constructs a multi-stage structure\nconsisting of generation, extraction, and ranking modules to fully leverage the\nlatent knowledge within the language model across multiple dimensions.\nFurthermore, we employ reinforcement learning from human feedback to further\noptimize model, enhancing the model's understanding of commonsense knowledge.\nExperiments show that compared to baseline models, PRIMO significantly improves\nrule quality and diversity while reducing the repetition rate of rule atoms.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "COLING 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.01205v1",
    "published_date": "2024-11-02 10:33:50 UTC",
    "updated_date": "2024-11-02 10:33:50 UTC"
  },
  {
    "arxiv_id": "2411.01204v1",
    "title": "Class-specific feature selection for classification explainability",
    "authors": [
      "Jesus S. Aguilar-Ruiz"
    ],
    "abstract": "Feature Selection techniques aim at finding a relevant subset of features\nthat perform equally or better than the original set of features at explaining\nthe behavior of data. Typically, features are extracted from feature ranking or\nsubset selection techniques, and the performance is measured by classification\nor regression tasks. However, while selected features may not have equal\nimportance for the task, they do have equal importance for each class. This\nwork first introduces a comprehensive review of the concept of class-specific,\nwith a focus on feature selection and classification. The fundamental idea of\nthe class-specific concept resides in the understanding that the significance\nof each feature can vary from one class to another. This contrasts with the\ntraditional class-independent approach, which evaluates the importance of\nattributes collectively for all classes. For example, in tumor prediction\nscenarios, each type of tumor may be associated with a distinct subset of\nrelevant features. These features possess significant discriminatory power,\nenabling the differentiation of one tumor type from others. This class-specific\nperspective offers a more effective approach to classification tasks by\nrecognizing and leveraging the unique characteristics of each class. Secondly,\nclassification schemes from one-versus-all and one-versus-each strategies are\ndescribed, and a novel deep one-versus-each strategy is introduced, which\noffers advantages from the point of view of explainability (feature selection)\nand decomposability (classification). Thirdly, a novel class-specific relevance\nmatrix is presented, from which some more sophisticated classification schemes\ncan be derived, such as the three-layer class-specific scheme. The potential\nfor further advancements is wide and will open new horizons for exploring novel\nresearch directions in multiclass hyperdimensional contexts.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.01204v1",
    "published_date": "2024-11-02 10:31:55 UTC",
    "updated_date": "2024-11-02 10:31:55 UTC"
  },
  {
    "arxiv_id": "2411.01203v1",
    "title": "XNB: Explainable Class-Specific NaIve-Bayes Classifier",
    "authors": [
      "Jesus S. Aguilar-Ruiz",
      "Cayetano Romero",
      "Andrea Cicconardi"
    ],
    "abstract": "In today's data-intensive landscape, where high-dimensional datasets are\nincreasingly common, reducing the number of input features is essential to\nprevent overfitting and improve model accuracy. Despite numerous efforts to\ntackle dimensionality reduction, most approaches apply a universal set of\nfeatures across all classes, potentially missing the unique characteristics of\nindividual classes. This paper presents the Explainable Class-Specific Naive\nBayes (XNB) classifier, which introduces two critical innovations: 1) the use\nof Kernel Density Estimation to calculate posterior probabilities, allowing for\na more accurate and flexible estimation process, and 2) the selection of\nclass-specific feature subsets, ensuring that only the most relevant variables\nfor each class are utilized. Extensive empirical analysis on high-dimensional\ngenomic datasets shows that XNB matches the classification performance of\ntraditional Naive Bayes while drastically improving model interpretability. By\nisolating the most relevant features for each class, XNB not only reduces the\nfeature set to a minimal, distinct subset for each class but also provides\ndeeper insights into how the model makes predictions. This approach offers\nsignificant advantages in fields where both precision and explainability are\ncritical.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.01203v1",
    "published_date": "2024-11-02 10:28:22 UTC",
    "updated_date": "2024-11-02 10:28:22 UTC"
  },
  {
    "arxiv_id": "2411.01200v3",
    "title": "GarmentLab: A Unified Simulation and Benchmark for Garment Manipulation",
    "authors": [
      "Haoran Lu",
      "Ruihai Wu",
      "Yitong Li",
      "Sijie Li",
      "Ziyu Zhu",
      "Chuanruo Ning",
      "Yan Shen",
      "Longzan Luo",
      "Yuanpei Chen",
      "Hao Dong"
    ],
    "abstract": "Manipulating garments and fabrics has long been a critical endeavor in the\ndevelopment of home-assistant robots. However, due to complex dynamics and\ntopological structures, garment manipulations pose significant challenges.\nRecent successes in reinforcement learning and vision-based methods offer\npromising avenues for learning garment manipulation. Nevertheless, these\napproaches are severely constrained by current benchmarks, which offer limited\ndiversity of tasks and unrealistic simulation behavior. Therefore, we present\nGarmentLab, a content-rich benchmark and realistic simulation designed for\ndeformable object and garment manipulation. Our benchmark encompasses a diverse\nrange of garment types, robotic systems and manipulators. The abundant tasks in\nthe benchmark further explores of the interactions between garments, deformable\nobjects, rigid bodies, fluids, and human body. Moreover, by incorporating\nmultiple simulation methods such as FEM and PBD, along with our proposed\nsim-to-real algorithms and real-world benchmark, we aim to significantly narrow\nthe sim-to-real gap. We evaluate state-of-the-art vision methods, reinforcement\nlearning, and imitation learning approaches on these tasks, highlighting the\nchallenges faced by current algorithms, notably their limited generalization\ncapabilities. Our proposed open-source environments and comprehensive analysis\nshow promising boost to future research in garment manipulation by unlocking\nthe full potential of these methods. We guarantee that we will open-source our\ncode as soon as possible. You can watch the videos in supplementary files to\nlearn more about the details of our work. Our project page is available at:\nhttps://garmentlab.github.io/",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.HC"
    ],
    "primary_category": "cs.RO",
    "comment": "NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.01200v3",
    "published_date": "2024-11-02 10:09:08 UTC",
    "updated_date": "2024-12-23 14:33:11 UTC"
  },
  {
    "arxiv_id": "2411.01188v1",
    "title": "Learning Rules Explaining Interactive Theorem Proving Tactic Prediction",
    "authors": [
      "Liao Zhang",
      "David M. Cerna",
      "Cezary Kaliszyk"
    ],
    "abstract": "Formally verifying the correctness of mathematical proofs is more accessible\nthan ever, however, the learning curve remains steep for many of the\nstate-of-the-art interactive theorem provers (ITP). Deriving the most\nappropriate subsequent proof step, and reasoning about it, given the multitude\nof possibilities, remains a daunting task for novice users. To improve the\nsituation, several investigations have developed machine learning based\nguidance for tactic selection. Such approaches struggle to learn non-trivial\nrelationships between the chosen tactic and the structure of the proof state\nand represent them as symbolic expressions. To address these issues we (i) We\nrepresent the problem as an Inductive Logic Programming (ILP) task, (ii) Using\nthe ILP representation we enriched the feature space by encoding additional,\ncomputationally expensive properties as background knowledge predicates, (iii)\nWe use this enriched feature space to learn rules explaining when a tactic is\napplicable to a given proof state, (iv) we use the learned rules to filter the\noutput of an existing tactic selection approach and empirically show\nimprovement over the non-filtering approaches.",
    "categories": [
      "cs.LO",
      "cs.AI",
      "cs.LG",
      "F.4.1, I.2.4"
    ],
    "primary_category": "cs.LO",
    "comment": "15 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.01188v1",
    "published_date": "2024-11-02 09:18:33 UTC",
    "updated_date": "2024-11-02 09:18:33 UTC"
  },
  {
    "arxiv_id": "2411.01184v1",
    "title": "Guiding Multi-agent Multi-task Reinforcement Learning by a Hierarchical Framework with Logical Reward Shaping",
    "authors": [
      "Chanjuan Liu",
      "Jinmiao Cong",
      "Bingcai Chen",
      "Yaochu Jin",
      "Enqiang Zhu"
    ],
    "abstract": "Multi-agent hierarchical reinforcement learning (MAHRL) has been studied as\nan effective means to solve intelligent decision problems in complex and\nlarge-scale environments. However, most current MAHRL algorithms follow the\ntraditional way of using reward functions in reinforcement learning, which\nlimits their use to a single task. This study aims to design a multi-agent\ncooperative algorithm with logic reward shaping (LRS), which uses a more\nflexible way of setting the rewards, allowing for the effective completion of\nmulti-tasks. LRS uses Linear Temporal Logic (LTL) to express the internal logic\nrelation of subtasks within a complex task. Then, it evaluates whether the\nsubformulae of the LTL expressions are satisfied based on a designed reward\nstructure. This helps agents to learn to effectively complete tasks by adhering\nto the LTL expressions, thus enhancing the interpretability and credibility of\ntheir decisions. To enhance coordination and cooperation among multiple agents,\na value iteration technique is designed to evaluate the actions taken by each\nagent. Based on this evaluation, a reward function is shaped for coordination,\nwhich enables each agent to evaluate its status and complete the remaining\nsubtasks through experiential learning. Experiments have been conducted on\nvarious types of tasks in the Minecraft-like environment. The results\ndemonstrate that the proposed algorithm can improve the performance of\nmulti-agents when learning to complete multi-tasks.",
    "categories": [
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.01184v1",
    "published_date": "2024-11-02 09:03:23 UTC",
    "updated_date": "2024-11-02 09:03:23 UTC"
  },
  {
    "arxiv_id": "2411.01179v1",
    "title": "Hollowed Net for On-Device Personalization of Text-to-Image Diffusion Models",
    "authors": [
      "Wonguk Cho",
      "Seokeon Choi",
      "Debasmit Das",
      "Matthias Reisser",
      "Taesup Kim",
      "Sungrack Yun",
      "Fatih Porikli"
    ],
    "abstract": "Recent advancements in text-to-image diffusion models have enabled the\npersonalization of these models to generate custom images from textual prompts.\nThis paper presents an efficient LoRA-based personalization approach for\non-device subject-driven generation, where pre-trained diffusion models are\nfine-tuned with user-specific data on resource-constrained devices. Our method,\ntermed Hollowed Net, enhances memory efficiency during fine-tuning by modifying\nthe architecture of a diffusion U-Net to temporarily remove a fraction of its\ndeep layers, creating a hollowed structure. This approach directly addresses\non-device memory constraints and substantially reduces GPU memory requirements\nfor training, in contrast to previous methods that primarily focus on\nminimizing training steps and reducing the number of parameters to update.\nAdditionally, the personalized Hollowed Net can be transferred back into the\noriginal U-Net, enabling inference without additional memory overhead.\nQuantitative and qualitative analyses demonstrate that our approach not only\nreduces training memory to levels as low as those required for inference but\nalso maintains or improves personalization performance compared to existing\nmethods.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.01179v1",
    "published_date": "2024-11-02 08:42:48 UTC",
    "updated_date": "2024-11-02 08:42:48 UTC"
  },
  {
    "arxiv_id": "2411.02438v1",
    "title": "Entropic Hetero-Associative Memory",
    "authors": [
      "Rafael Morales",
      "Luis A. Pineda"
    ],
    "abstract": "The Entropic Associative Memory holds objects in a 2D relation or ``memory\nplane'' using a finite table as the medium. Memory objects are stored by\nreinforcing simultaneously the cells used by the cue, implementing a form of\nHebb's learning rule. Stored objects are ``overlapped'' on the medium, hence\nthe memory is indeterminate and has an entropy value at each state. The\nretrieval operation constructs an object from the cue and such indeterminate\ncontent. In this paper we present the extension to the hetero-associative case\nin which these properties are preserved. Pairs of hetero-associated objects,\npossibly of different domain and/or modalities, are held in a 4D relation. The\nmemory retrieval operation selects a largely indeterminate 2D memory plane that\nis specific to the input cue; however, there is no cue left to retrieve an\nobject from such latter plane. We propose three incremental methods to address\nsuch missing cue problem, which we call random, sample and test, and search and\ntest. The model is assessed with composite recollections consisting of\nmanuscripts digits and letters selected from the MNIST and the EMNIST corpora,\nrespectively, such that cue digits retrieve their associated letters and vice\nversa. We show the memory performance and illustrate the memory retrieval\noperation using all three methods. The system shows promise for storing,\nrecognizing and retrieving very large sets of object with very limited\ncomputing resources.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "17 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.02438v1",
    "published_date": "2024-11-02 08:30:57 UTC",
    "updated_date": "2024-11-02 08:30:57 UTC"
  },
  {
    "arxiv_id": "2411.01173v1",
    "title": "Reasoning Limitations of Multimodal Large Language Models. A case study of Bongard Problems",
    "authors": [
      "Mikołaj Małkiński",
      "Szymon Pawlonka",
      "Jacek Mańdziuk"
    ],
    "abstract": "Abstract visual reasoning (AVR) encompasses a suite of tasks whose solving\nrequires the ability to discover common concepts underlying the set of pictures\nthrough an analogy-making process, similarly to human IQ tests. Bongard\nProblems (BPs), proposed in 1968, constitute a fundamental challenge in this\ndomain mainly due to their requirement to combine visual reasoning and verbal\ndescription. This work poses a question whether multimodal large language\nmodels (MLLMs) inherently designed to combine vision and language are capable\nof tackling BPs. To this end, we propose a set of diverse MLLM-suited\nstrategies to tackle BPs and examine four popular proprietary MLLMs: GPT-4o,\nGPT-4 Turbo, Gemini 1.5 Pro, and Claude 3.5 Sonnet, and four open models:\nInternVL2-8B, LLaVa-1.6 Mistral-7B, Phi-3.5-Vision, and Pixtral 12B. The above\nMLLMs are compared on three BP datasets: a set of original BP instances relying\non synthetic, geometry-based images and two recent datasets based on real-world\nimages, i.e., Bongard-HOI and Bongard-OpenWorld. The experiments reveal\nsignificant limitations of MLLMs in solving BPs. In particular, the models\nstruggle to solve the classical set of synthetic BPs, despite their visual\nsimplicity. Though their performance ameliorates on real-world concepts\nexpressed in Bongard-HOI and Bongard-OpenWorld, the models still have\ndifficulty in utilizing new information to improve their predictions, as well\nas utilizing a dialog context window effectively. To capture the reasons of\nperformance discrepancy between synthetic and real-world AVR domains, we\npropose Bongard-RWR, a new BP dataset consisting of real-world images that\ntranslates concepts from hand-crafted synthetic BPs to real-world concepts. The\nMLLMs' results on Bongard-RWR suggest that their poor performance on classical\nBPs is not due to domain specificity but rather reflects their general AVR\nlimitations.",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.01173v1",
    "published_date": "2024-11-02 08:06:30 UTC",
    "updated_date": "2024-11-02 08:06:30 UTC"
  },
  {
    "arxiv_id": "2411.01172v1",
    "title": "Covariance-based Space Regularization for Few-shot Class Incremental Learning",
    "authors": [
      "Yijie Hu",
      "Guanyu Yang",
      "Zhaorui Tan",
      "Xiaowei Huang",
      "Kaizhu Huang",
      "Qiu-Feng Wang"
    ],
    "abstract": "Few-shot Class Incremental Learning (FSCIL) presents a challenging yet\nrealistic scenario, which requires the model to continually learn new classes\nwith limited labeled data (i.e., incremental sessions) while retaining\nknowledge of previously learned base classes (i.e., base sessions). Due to the\nlimited data in incremental sessions, models are prone to overfitting new\nclasses and suffering catastrophic forgetting of base classes. To tackle these\nissues, recent advancements resort to prototype-based approaches to constrain\nthe base class distribution and learn discriminative representations of new\nclasses. Despite the progress, the limited data issue still induces ill-divided\nfeature space, leading the model to confuse the new class with old classes or\nfail to facilitate good separation among new classes. In this paper, we aim to\nmitigate these issues by directly constraining the span of each class\ndistribution from a covariance perspective. In detail, we propose a simple yet\neffective covariance constraint loss to force the model to learn each class\ndistribution with the same covariance matrix. In addition, we propose a\nperturbation approach to perturb the few-shot training samples in the feature\nspace, which encourages the samples to be away from the weighted distribution\nof other classes. Regarding perturbed samples as new class data, the classifier\nis forced to establish explicit boundaries between each new class and the\nexisting ones. Our approach is easy to integrate into existing FSCIL approaches\nto boost performance. Experiments on three benchmarks validate the\neffectiveness of our approach, achieving a new state-of-the-art performance of\nFSCIL.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "WACV2025,10 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.01172v1",
    "published_date": "2024-11-02 08:03:04 UTC",
    "updated_date": "2024-11-02 08:03:04 UTC"
  },
  {
    "arxiv_id": "2411.02437v1",
    "title": "TypeScore: A Text Fidelity Metric for Text-to-Image Generative Models",
    "authors": [
      "Georgia Gabriela Sampaio",
      "Ruixiang Zhang",
      "Shuangfei Zhai",
      "Jiatao Gu",
      "Josh Susskind",
      "Navdeep Jaitly",
      "Yizhe Zhang"
    ],
    "abstract": "Evaluating text-to-image generative models remains a challenge, despite the\nremarkable progress being made in their overall performances. While existing\nmetrics like CLIPScore work for coarse evaluations, they lack the sensitivity\nto distinguish finer differences as model performance rapidly improves. In this\nwork, we focus on the text rendering aspect of these models, which provides a\nlens for evaluating a generative model's fine-grained instruction-following\ncapabilities. To this end, we introduce a new evaluation framework called\nTypeScore to sensitively assess a model's ability to generate images with\nhigh-fidelity embedded text by following precise instructions. We argue that\nthis text generation capability serves as a proxy for general\ninstruction-following ability in image synthesis. TypeScore uses an additional\nimage description model and leverages an ensemble dissimilarity measure between\nthe original and extracted text to evaluate the fidelity of the rendered text.\nOur proposed metric demonstrates greater resolution than CLIPScore to\ndifferentiate popular image generation models across a range of instructions\nwith diverse text styles. Our study also evaluates how well these\nvision-language models (VLMs) adhere to stylistic instructions, disentangling\nstyle evaluation from embedded-text fidelity. Through human evaluation studies,\nwe quantitatively meta-evaluate the effectiveness of the metric. Comprehensive\nanalysis is conducted to explore factors such as text length, captioning\nmodels, and current progress towards human parity on this task. The framework\nprovides insights into remaining gaps in instruction-following for image\ngeneration with embedded text.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.02437v1",
    "published_date": "2024-11-02 07:56:54 UTC",
    "updated_date": "2024-11-02 07:56:54 UTC"
  },
  {
    "arxiv_id": "2411.01171v1",
    "title": "Fast and Memory-Efficient Video Diffusion Using Streamlined Inference",
    "authors": [
      "Zheng Zhan",
      "Yushu Wu",
      "Yifan Gong",
      "Zichong Meng",
      "Zhenglun Kong",
      "Changdi Yang",
      "Geng Yuan",
      "Pu Zhao",
      "Wei Niu",
      "Yanzhi Wang"
    ],
    "abstract": "The rapid progress in artificial intelligence-generated content (AIGC),\nespecially with diffusion models, has significantly advanced development of\nhigh-quality video generation. However, current video diffusion models exhibit\ndemanding computational requirements and high peak memory usage, especially for\ngenerating longer and higher-resolution videos. These limitations greatly\nhinder the practical application of video diffusion models on standard hardware\nplatforms. To tackle this issue, we present a novel, training-free framework\nnamed Streamlined Inference, which leverages the temporal and spatial\nproperties of video diffusion models. Our approach integrates three core\ncomponents: Feature Slicer, Operator Grouping, and Step Rehash. Specifically,\nFeature Slicer effectively partitions input features into sub-features and\nOperator Grouping processes each sub-feature with a group of consecutive\noperators, resulting in significant memory reduction without sacrificing the\nquality or speed. Step Rehash further exploits the similarity between adjacent\nsteps in diffusion, and accelerates inference through skipping unnecessary\nsteps. Extensive experiments demonstrate that our approach significantly\nreduces peak memory and computational overhead, making it feasible to generate\nhigh-quality videos on a single consumer GPU (e.g., reducing peak memory of\nAnimateDiff from 42GB to 11GB, featuring faster inference on 2080Ti).",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.01171v1",
    "published_date": "2024-11-02 07:52:18 UTC",
    "updated_date": "2024-11-02 07:52:18 UTC"
  },
  {
    "arxiv_id": "2411.01169v1",
    "title": "Bi-Level Graph Structure Learning for Next POI Recommendation",
    "authors": [
      "Liang Wang",
      "Shu Wu",
      "Qiang Liu",
      "Yanqiao Zhu",
      "Xiang Tao",
      "Mengdi Zhang",
      "Liang Wang"
    ],
    "abstract": "Next point-of-interest (POI) recommendation aims to predict a user's next\ndestination based on sequential check-in history and a set of POI candidates.\nGraph neural networks (GNNs) have demonstrated a remarkable capability in this\nendeavor by exploiting the extensive global collaborative signals present among\nPOIs. However, most of the existing graph-based approaches construct graph\nstructures based on pre-defined heuristics, failing to consider inherent\nhierarchical structures of POI features such as geographical locations and\nvisiting peaks, or suffering from noisy and incomplete structures in graphs. To\naddress the aforementioned issues, this paper presents a novel Bi-level Graph\nStructure Learning (BiGSL) for next POI recommendation. BiGSL first learns a\nhierarchical graph structure to capture the fine-to-coarse connectivity between\nPOIs and prototypes, and then uses a pairwise learning module to dynamically\ninfer relationships between POI pairs and prototype pairs. Based on the learned\nbi-level graphs, our model then employs a multi-relational graph network that\nconsiders both POI- and prototype-level neighbors, resulting in improved POI\nrepresentations. Our bi-level structure learning scheme is more robust to data\nnoise and incompleteness, and improves the exploration ability for\nrecommendation by alleviating sparsity issues. Experimental results on three\nreal-world datasets demonstrate the superiority of our model over existing\nstate-of-the-art methods, with a significant improvement in recommendation\naccuracy and exploration performance.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by IEEE Transactions on Knowledge and Data Engineering",
    "pdf_url": "http://arxiv.org/pdf/2411.01169v1",
    "published_date": "2024-11-02 07:40:16 UTC",
    "updated_date": "2024-11-02 07:40:16 UTC"
  },
  {
    "arxiv_id": "2411.01168v1",
    "title": "Prompt Tuning with Diffusion for Few-Shot Pre-trained Policy Generalization",
    "authors": [
      "Shengchao Hu",
      "Wanru Zhao",
      "Weixiong Lin",
      "Li Shen",
      "Ya Zhang",
      "Dacheng Tao"
    ],
    "abstract": "Offline reinforcement learning (RL) methods harness previous experiences to\nderive an optimal policy, forming the foundation for pre-trained large-scale\nmodels (PLMs). When encountering tasks not seen before, PLMs often utilize\nseveral expert trajectories as prompts to expedite their adaptation to new\nrequirements. Though a range of prompt-tuning methods have been proposed to\nenhance the quality of prompts, these methods often face optimization\nrestrictions due to prompt initialization, which can significantly constrain\nthe exploration domain and potentially lead to suboptimal solutions. To\neliminate the reliance on the initial prompt, we shift our perspective towards\nthe generative model, framing the prompt-tuning process as a form of\nconditional generative modeling, where prompts are generated from random noise.\nOur innovation, the Prompt Diffuser, leverages a conditional diffusion model to\nproduce prompts of exceptional quality. Central to our framework is the\napproach to trajectory reconstruction and the meticulous integration of\ndownstream task guidance during the training phase. Further experimental\nresults underscore the potency of the Prompt Diffuser as a robust and effective\ntool for the prompt-tuning process, demonstrating strong performance in the\nmeta-RL tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "19 pages",
    "pdf_url": "http://arxiv.org/pdf/2411.01168v1",
    "published_date": "2024-11-02 07:38:02 UTC",
    "updated_date": "2024-11-02 07:38:02 UTC"
  },
  {
    "arxiv_id": "2411.01166v1",
    "title": "Role Play: Learning Adaptive Role-Specific Strategies in Multi-Agent Interactions",
    "authors": [
      "Weifan Long",
      "Wen Wen",
      "Peng Zhai",
      "Lihua Zhang"
    ],
    "abstract": "Zero-shot coordination problem in multi-agent reinforcement learning (MARL),\nwhich requires agents to adapt to unseen agents, has attracted increasing\nattention. Traditional approaches often rely on the Self-Play (SP) framework to\ngenerate a diverse set of policies in a policy pool, which serves to improve\nthe generalization capability of the final agent. However, these frameworks may\nstruggle to capture the full spectrum of potential strategies, especially in\nreal-world scenarios that demand agents balance cooperation with competition.\nIn such settings, agents need strategies that can adapt to varying and often\nconflicting goals. Drawing inspiration from Social Value Orientation\n(SVO)-where individuals maintain stable value orientations during interactions\nwith others-we propose a novel framework called \\emph{Role Play} (RP). RP\nemploys role embeddings to transform the challenge of policy diversity into a\nmore manageable diversity of roles. It trains a common policy with role\nembedding observations and employs a role predictor to estimate the joint role\nembeddings of other agents, helping the learning agent adapt to its assigned\nrole. We theoretically prove that an approximate optimal policy can be achieved\nby optimizing the expected cumulative reward relative to an approximate\nrole-based policy. Experimental results in both cooperative (Overcooked) and\nmixed-motive games (Harvest, CleanUp) reveal that RP consistently outperforms\nstrong baselines when interacting with unseen agents, highlighting its\nrobustness and adaptability in complex environments.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.MA",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.01166v1",
    "published_date": "2024-11-02 07:25:48 UTC",
    "updated_date": "2024-11-02 07:25:48 UTC"
  },
  {
    "arxiv_id": "2411.14433v1",
    "title": "Transforming Engineering Education Using Generative AI and Digital Twin Technologies",
    "authors": [
      "Yu-Zheng Lin",
      "Ahmed Hussain J Alhamadah",
      "Matthew William Redondo",
      "Karan Himanshu Patel",
      "Sujan Ghimire",
      "Banafsheh Saber Latibari",
      "Soheil Salehi",
      "Pratik Satam"
    ],
    "abstract": "Digital twin technology, traditionally used in industry, is increasingly\nrecognized for its potential to enhance educational experiences. This study\ninvestigates the application of industrial digital twins (DTs) in education,\nfocusing on how DT models of varying fidelity can support different stages of\nBloom's taxonomy in the cognitive domain. We align Bloom's six cognitive stages\nwith educational levels: undergraduate studies for \"Remember\" and \"Understand,\"\nmaster's level for \"Apply\" and \"Analyze,\" and doctoral level for \"Evaluate\" and\n\"Create.\" Low-fidelity DTs aid essential knowledge acquisition and skill\ntraining, providing a low-risk environment for grasping fundamental concepts.\nMedium-fidelity DTs offer more detailed and dynamic simulations, enhancing\napplication skills and problem-solving. High-fidelity DTs support advanced\nlearners by replicating physical phenomena, allowing for innovative design and\ncomplex experiments. Within this framework, large language models (LLMs) serve\nas mentors, assessing progress, filling knowledge gaps, and assisting with DT\ninteractions, parameter setting, and debugging. We evaluate the educational\nimpact using the Kirkpatrick Model, examining how each DT model's fidelity\ninfluences learning outcomes. This framework helps educators make informed\ndecisions on integrating DTs and LLMs to meet specific learning objectives.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CR",
      "cs.HC"
    ],
    "primary_category": "cs.CY",
    "comment": "8 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.14433v1",
    "published_date": "2024-11-02 07:16:47 UTC",
    "updated_date": "2024-11-02 07:16:47 UTC"
  },
  {
    "arxiv_id": "2411.01159v2",
    "title": "Supervised Score-Based Modeling by Gradient Boosting",
    "authors": [
      "Changyuan Zhao",
      "Hongyang Du",
      "Guangyuan Liu",
      "Dusit Niyato"
    ],
    "abstract": "Score-based generative models can effectively learn the distribution of data\nby estimating the gradient of the distribution. Due to the multi-step denoising\ncharacteristic, researchers have recently considered combining score-based\ngenerative models with the gradient boosting algorithm, a multi-step supervised\nlearning algorithm, to solve supervised learning tasks. However, existing\ngenerative model algorithms are often limited by the stochastic nature of the\nmodels and the long inference time, impacting prediction performances.\nTherefore, we propose a Supervised Score-based Model (SSM), which can be viewed\nas a gradient boosting algorithm combining score matching. We provide a\ntheoretical analysis of learning and sampling for SSM to balance inference time\nand prediction accuracy. Via the ablation experiment in selected examples, we\ndemonstrate the outstanding performances of the proposed techniques.\nAdditionally, we compare our model with other probabilistic models, including\nNatural Gradient Boosting (NGboost), Classification and Regression Diffusion\nModels (CARD), Diffusion Boosted Trees (DBT), and non-probabilistic GBM models.\nThe experimental results show that our model outperforms existing models in\nboth accuracy and inference time.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.01159v2",
    "published_date": "2024-11-02 07:06:53 UTC",
    "updated_date": "2024-12-15 12:02:51 UTC"
  },
  {
    "arxiv_id": "2411.01158v1",
    "title": "Pin-Tuning: Parameter-Efficient In-Context Tuning for Few-Shot Molecular Property Prediction",
    "authors": [
      "Liang Wang",
      "Qiang Liu",
      "Shaozhen Liu",
      "Xin Sun",
      "Shu Wu",
      "Liang Wang"
    ],
    "abstract": "Molecular property prediction (MPP) is integral to drug discovery and\nmaterial science, but often faces the challenge of data scarcity in real-world\nscenarios. Addressing this, few-shot molecular property prediction (FSMPP) has\nbeen developed. Unlike other few-shot tasks, FSMPP typically employs a\npre-trained molecular encoder and a context-aware classifier, benefiting from\nmolecular pre-training and molecular context information. Despite these\nadvancements, existing methods struggle with the ineffective fine-tuning of\npre-trained encoders. We attribute this issue to the imbalance between the\nabundance of tunable parameters and the scarcity of labeled molecules, and the\nlack of contextual perceptiveness in the encoders. To overcome this hurdle, we\npropose a parameter-efficient in-context tuning method, named Pin-Tuning.\nSpecifically, we propose a lightweight adapter for pre-trained message passing\nlayers (MP-Adapter) and Bayesian weight consolidation for pre-trained atom/bond\nembedding layers (Emb-BWC), to achieve parameter-efficient tuning while\npreventing over-fitting and catastrophic forgetting. Additionally, we enhance\nthe MP-Adapters with contextual perceptiveness. This innovation allows for\nin-context tuning of the pre-trained encoder, thereby improving its\nadaptability for specific FSMPP tasks. When evaluated on public datasets, our\nmethod demonstrates superior tuning with fewer trainable parameters, improving\nfew-shot predictive performance.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.MN"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.01158v1",
    "published_date": "2024-11-02 07:06:30 UTC",
    "updated_date": "2024-11-02 07:06:30 UTC"
  },
  {
    "arxiv_id": "2411.01153v1",
    "title": "Designing a Robust Radiology Report Generation System",
    "authors": [
      "Sonit Singh"
    ],
    "abstract": "Recent advances in deep learning have enabled researchers to explore tasks at\nthe intersection of computer vision and natural language processing, such as\nimage captioning, visual question answering, visual dialogue, and visual\nlanguage navigation. Taking inspiration from image captioning, the task of\nradiology report generation aims at automatically generating radiology reports\nby having a comprehensive understanding of medical images. However,\nautomatically generating radiology reports from medical images is a challenging\ntask due to the complexity, diversity, and nature of medical images. In this\npaper, we outline the design of a robust radiology report generation system by\nintegrating different modules and highlighting best practices drawing upon\nlessons from our past work and also from relevant studies in the literature. We\nalso discuss the impact of integrating different components to form a single\nintegrated system. We believe that these best practices, when implemented,\ncould improve automatic radiology report generation, augment radiologists in\ndecision making, and expedite diagnostic workflow, in turn improve healthcare\nand save human lives.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "21 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.01153v1",
    "published_date": "2024-11-02 06:38:04 UTC",
    "updated_date": "2024-11-02 06:38:04 UTC"
  },
  {
    "arxiv_id": "2411.01146v1",
    "title": "Task-Aware Harmony Multi-Task Decision Transformer for Offline Reinforcement Learning",
    "authors": [
      "Ziqing Fan",
      "Shengchao Hu",
      "Yuhang Zhou",
      "Li Shen",
      "Ya Zhang",
      "Yanfeng Wang",
      "Dacheng Tao"
    ],
    "abstract": "The purpose of offline multi-task reinforcement learning (MTRL) is to develop\na unified policy applicable to diverse tasks without the need for online\nenvironmental interaction. Recent advancements approach this through sequence\nmodeling, leveraging the Transformer architecture's scalability and the\nbenefits of parameter sharing to exploit task similarities. However, variations\nin task content and complexity pose significant challenges in policy\nformulation, necessitating judicious parameter sharing and management of\nconflicting gradients for optimal policy performance. Furthermore, identifying\nthe optimal parameter subspace for each task often necessitates prior knowledge\nof the task identifier during inference, limiting applicability in real-world\nscenarios with variable task content and unknown current tasks. In this work,\nwe introduce the Harmony Multi-Task Decision Transformer (HarmoDT), a novel\nsolution designed to identify an optimal harmony subspace of parameters for\neach task. We formulate this as a bi-level optimization problem within a\nmeta-learning framework, where the upper level learns masks to define the\nharmony subspace, while the inner level focuses on updating parameters to\nimprove the overall performance of the unified policy. To eliminate the need\nfor task identifiers, we further design a group-wise variant (G-HarmoDT) that\nclusters tasks into coherent groups based on gradient information, and utilizes\na gating network to determine task identifiers during inference. Empirical\nevaluations across various benchmarks highlight the superiority of our\napproach, demonstrating its effectiveness in the multi-task context with\nspecific improvements of 8% gain in task-provided settings, 5% in task-agnostic\nsettings, and 10% in unseen settings.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Extension of corresponding ICML edition arXiv:2405.18080. arXiv admin\n  note: substantial text overlap with arXiv:2405.18080",
    "pdf_url": "http://arxiv.org/pdf/2411.01146v1",
    "published_date": "2024-11-02 05:49:14 UTC",
    "updated_date": "2024-11-02 05:49:14 UTC"
  },
  {
    "arxiv_id": "2411.01144v1",
    "title": "LEARNER: Learning Granular Labels from Coarse Labels using Contrastive Learning",
    "authors": [
      "Gautam Gare",
      "Jana Armouti",
      "Nikhil Madaan",
      "Rohan Panda",
      "Tom Fox",
      "Laura Hutchins",
      "Amita Krishnan",
      "Ricardo Rodriguez",
      "Bennett DeBoisblanc",
      "Deva Ramanan",
      "John Galeotti"
    ],
    "abstract": "A crucial question in active patient care is determining if a treatment is\nhaving the desired effect, especially when changes are subtle over short\nperiods. We propose using inter-patient data to train models that can learn to\ndetect these fine-grained changes within a single patient. Specifically, can a\nmodel trained on multi-patient scans predict subtle changes in an individual\npatient's scans? Recent years have seen increasing use of deep learning (DL) in\npredicting diseases using biomedical imaging, such as predicting COVID-19\nseverity using lung ultrasound (LUS) data. While extensive literature exists on\nsuccessful applications of DL systems when well-annotated large-scale datasets\nare available, it is quite difficult to collect a large corpus of personalized\ndatasets for an individual. In this work, we investigate the ability of recent\ncomputer vision models to learn fine-grained differences while being trained on\ndata showing larger differences. We evaluate on an in-house LUS dataset and a\npublic ADNI brain MRI dataset. We find that models pre-trained on clips from\nmultiple patients can better predict fine-grained differences in scans from a\nsingle patient by employing contrastive learning.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "eess.IV",
    "comment": "Under review at ISBI 2025 conference",
    "pdf_url": "http://arxiv.org/pdf/2411.01144v1",
    "published_date": "2024-11-02 05:27:52 UTC",
    "updated_date": "2024-11-02 05:27:52 UTC"
  },
  {
    "arxiv_id": "2411.01142v1",
    "title": "NEO: Saving GPU Memory Crisis with CPU Offloading for Online LLM Inference",
    "authors": [
      "Xuanlin Jiang",
      "Yang Zhou",
      "Shiyi Cao",
      "Ion Stoica",
      "Minlan Yu"
    ],
    "abstract": "Online LLM inference powers many exciting applications such as intelligent\nchatbots and autonomous agents. Modern LLM inference engines widely rely on\nrequest batching to improve inference throughput, aiming to make it\ncost-efficient when running on expensive GPU accelerators. However, the limited\nGPU memory has largely limited the batch size achieved in practice, leaving\nsignificant GPU compute resources wasted.\n  We present NEO, an online LLM inference system that offloads part of\nattention compute and KV cache states from the GPU to the local host CPU,\neffectively increasing the GPU batch size and thus inference throughput. To\nthis end, NEO proposes asymmetric GPU-CPU pipelining and load-aware scheduling\nto balance GPU and CPU loads and fully utilize their compute and memory\nresources. We evaluate NEO on a wide range of workloads (i.e., code generation,\ntext summarization), GPUs (i.e., T4, A10G, H100), and LLM models (i.e., 7B, 8B,\n70B). NEO achieves up to 7.5$\\times$, 26%, and 14% higher throughput compared\nto GPU-only approach on T4, A10G, and H100 GPUs, respectively, while\nmaintaining the same latency; with more powerful CPUs, NEO achieves up to 79.3%\nthroughput gain on A10G GPU.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.01142v1",
    "published_date": "2024-11-02 05:15:44 UTC",
    "updated_date": "2024-11-02 05:15:44 UTC"
  },
  {
    "arxiv_id": "2411.01140v3",
    "title": "Privacy-Preserving Federated Learning with Differentially Private Hyperdimensional Computing",
    "authors": [
      "Fardin Jalil Piran",
      "Zhiling Chen",
      "Mohsen Imani",
      "Farhad Imani"
    ],
    "abstract": "Federated Learning (FL) has become a key method for preserving data privacy\nin Internet of Things (IoT) environments, as it trains Machine Learning (ML)\nmodels locally while transmitting only model updates. Despite this design, FL\nremains susceptible to threats such as model inversion and membership inference\nattacks, which can reveal private training data. Differential Privacy (DP)\ntechniques are often introduced to mitigate these risks, but simply injecting\nDP noise into black-box ML models can compromise accuracy, particularly in\ndynamic IoT contexts, where continuous, lifelong learning leads to excessive\nnoise accumulation. To address this challenge, we propose Federated\nHyperDimensional computing with Privacy-preserving (FedHDPrivacy), an\neXplainable Artificial Intelligence (XAI) framework that integrates\nneuro-symbolic computing and DP. Unlike conventional approaches, FedHDPrivacy\nactively monitors the cumulative noise across learning rounds and adds only the\nadditional noise required to satisfy privacy constraints. In a real-world\napplication for monitoring manufacturing machining processes, FedHDPrivacy\nmaintains high performance while surpassing standard FL frameworks - Federated\nAveraging (FedAvg), Federated Proximal (FedProx), Federated Normalized\nAveraging (FedNova), and Federated Optimization (FedOpt) - by up to 37%.\nLooking ahead, FedHDPrivacy offers a promising avenue for further enhancements,\nsuch as incorporating multimodal data fusion.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "31 Pages, 14 Figures",
    "pdf_url": "http://arxiv.org/pdf/2411.01140v3",
    "published_date": "2024-11-02 05:00:44 UTC",
    "updated_date": "2025-03-22 04:10:19 UTC"
  },
  {
    "arxiv_id": "2411.01137v2",
    "title": "Data movement limits to frontier model training",
    "authors": [
      "Ege Erdil",
      "David Schneider-Joseph"
    ],
    "abstract": "We present a theoretical model of distributed training, and use it to analyze\nhow far dense and sparse training runs can be scaled. Under our baseline\nassumptions, given a three month training duration, data movement bottlenecks\nbegin to significantly lower hardware utilization for training runs exceeding\nabout $10^{28}$ FLOP, two orders of magnitude above the largest training run to\ndate, suggesting the arrival of fundamental barriers to scaling in three years\ngiven recent rates of growth. A training run exceeding about $10^{31}$ FLOP is\ninfeasible even at low utilization. However, more aggressive batch size scaling\nand/or shorter and fatter model shapes, if achievable, have the potential to\npermit much larger training runs.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.01137v2",
    "published_date": "2024-11-02 04:48:41 UTC",
    "updated_date": "2024-11-13 08:24:09 UTC"
  },
  {
    "arxiv_id": "2411.01114v1",
    "title": "Infant Agent: A Tool-Integrated, Logic-Driven Agent with Cost-Effective API Usage",
    "authors": [
      "Bin Lei",
      "Yuchen Li",
      "Yiming Zeng",
      "Tao Ren",
      "Yi Luo",
      "Tianyu Shi",
      "Zitian Gao",
      "Zeyu Hu",
      "Weitai Kang",
      "Qiuwu Chen"
    ],
    "abstract": "Despite the impressive capabilities of large language models (LLMs), they\ncurrently exhibit two primary limitations,\n\\textbf{\\uppercase\\expandafter{\\romannumeral 1}}: They struggle to\n\\textbf{autonomously solve the real world engineering problem}.\n\\textbf{\\uppercase\\expandafter{\\romannumeral 2}}: They remain\n\\textbf{challenged in reasoning through complex logic problems}. To address\nthese challenges, we developed the \\textsc{Infant Agent}, integrating\ntask-aware functions, operators, a hierarchical management system, and a memory\nretrieval mechanism. Together, these components enable large language models to\nsustain extended reasoning processes and handle complex, multi-step tasks\nefficiently, all while significantly reducing API costs. Using the\n\\textsc{Infant Agent}, GPT-4o's accuracy on the SWE-bench-lite dataset rises\nfrom $\\mathbf{0.33\\%}$ to $\\mathbf{30\\%}$, and in the AIME-2024 mathematics\ncompetition, it increases GPT-4o's accuracy from $\\mathbf{13.3\\%}$ to\n$\\mathbf{37\\%}$.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.01114v1",
    "published_date": "2024-11-02 02:48:37 UTC",
    "updated_date": "2024-11-02 02:48:37 UTC"
  },
  {
    "arxiv_id": "2411.01111v1",
    "title": "Rule Based Rewards for Language Model Safety",
    "authors": [
      "Tong Mu",
      "Alec Helyar",
      "Johannes Heidecke",
      "Joshua Achiam",
      "Andrea Vallone",
      "Ian Kivlichan",
      "Molly Lin",
      "Alex Beutel",
      "John Schulman",
      "Lilian Weng"
    ],
    "abstract": "Reinforcement learning based fine-tuning of large language models (LLMs) on\nhuman preferences has been shown to enhance both their capabilities and safety\nbehavior. However, in cases related to safety, without precise instructions to\nhuman annotators, the data collected may cause the model to become overly\ncautious, or to respond in an undesirable style, such as being judgmental.\nAdditionally, as model capabilities and usage patterns evolve, there may be a\ncostly need to add or relabel data to modify safety behavior. We propose a\nnovel preference modeling approach that utilizes AI feedback and only requires\na small amount of human data. Our method, Rule Based Rewards (RBR), uses a\ncollection of rules for desired or undesired behaviors (e.g. refusals should\nnot be judgmental) along with a LLM grader. In contrast to prior methods using\nAI feedback, our method uses fine-grained, composable, LLM-graded few-shot\nprompts as reward directly in RL training, resulting in greater control,\naccuracy and ease of updating. We show that RBRs are an effective training\nmethod, achieving an F1 score of 97.1, compared to a human-feedback baseline of\n91.7, resulting in much higher safety-behavior accuracy through better\nbalancing usefulness and safety.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted at Neurips 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.01111v1",
    "published_date": "2024-11-02 02:22:21 UTC",
    "updated_date": "2024-11-02 02:22:21 UTC"
  },
  {
    "arxiv_id": "2411.01098v1",
    "title": "Artificial Intelligence for Microbiology and Microbiome Research",
    "authors": [
      "Xu-Wen Wang",
      "Tong Wang",
      "Yang-Yu Liu"
    ],
    "abstract": "Advancements in artificial intelligence (AI) have transformed many scientific\nfields, with microbiology and microbiome research now experiencing significant\nbreakthroughs through machine learning and deep learning applications. This\nreview provides a comprehensive overview of AI-driven approaches tailored for\nmicrobiology and microbiome studies, emphasizing both technical advancements\nand biological insights. We begin with an introduction to foundational AI\ntechniques, including primary machine learning paradigms and various deep\nlearning architectures, and offer guidance on choosing between machine learning\nand deep learning methods based on specific research goals. The primary section\non application scenarios spans diverse research areas, from taxonomic\nprofiling, functional annotation & prediction, microbe-X interactions,\nmicrobial ecology, metabolic modeling, precision nutrition, clinical\nmicrobiology, to prevention & therapeutics. Finally, we discuss challenges\nunique to this field, including the balance between interpretability and\ncomplexity, the \"small n, large p\" problem, and the critical need for\nstandardized benchmarking datasets to validate and compare models. Together,\nthis review underscores AI's transformative role in microbiology and microbiome\nresearch, paving the way for innovative methodologies and applications that\nenhance our understanding of microbial life and its impact on our planet and\nour health.",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "q-bio.QM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.01098v1",
    "published_date": "2024-11-02 01:03:43 UTC",
    "updated_date": "2024-11-02 01:03:43 UTC"
  },
  {
    "arxiv_id": "2411.01086v3",
    "title": "Practical hybrid PQC-QKD protocols with enhanced security and performance",
    "authors": [
      "Pei Zeng",
      "Debayan Bandyopadhyay",
      "José A. Méndez Méndez",
      "Nolan Bitner",
      "Alexander Kolar",
      "Michael T. Solomon",
      "Ziyu Ye",
      "Filip Rozpędek",
      "Tian Zhong",
      "F. Joseph Heremans",
      "David D. Awschalom",
      "Liang Jiang",
      "Junyu Liu"
    ],
    "abstract": "Quantum resistance is vital for emerging cryptographic systems as quantum\ntechnologies continue to advance towards large-scale, fault-tolerant quantum\ncomputers. Resistance may be offered by quantum key distribution (QKD), which\nprovides information-theoretic security using quantum states of photons, but\nmay be limited by transmission loss at long distances. An alternative approach\nuses classical means and is conjectured to be resistant to quantum attacks,\nso-called post-quantum cryptography (PQC), but it is yet to be rigorously\nproven, and its current implementations are computationally expensive. To\novercome the security and performance challenges present in each, here we\ndevelop hybrid protocols by which QKD and PQC inter-operate within a joint\nquantum-classical network. In particular, we consider different hybrid designs\nthat may offer enhanced speed and/or security over the individual performance\nof either approach. Furthermore, we present a method for analyzing the security\nof hybrid protocols in key distribution networks. Our hybrid approach paves the\nway for joint quantum-classical communication networks, which leverage the\nadvantages of both QKD and PQC and can be tailored to the requirements of\nvarious practical networks.",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "quant-ph",
    "comment": "6 pages, 3 figures, including extra supplementary materials",
    "pdf_url": "http://arxiv.org/pdf/2411.01086v3",
    "published_date": "2024-11-02 00:02:01 UTC",
    "updated_date": "2024-11-07 22:01:15 UTC"
  }
]