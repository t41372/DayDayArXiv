{
  "date": "2026-01-16",
  "category": "cs.AI",
  "summary": "æ¬¢è¿æ¥åˆ° UTC æ—¶é—´ 2026-01-16 çš„ arXiv ä¸­æ–‡ TLDR å¿«æŠ¥ï¼\n\n**ä»Šæ—¥æ€»ç»“ï¼š**\nä»Šå¤©çš„ arXiv è®ºæ–‡è´¨é‡é¢‡é«˜ï¼ŒAgentic AI (æ™ºèƒ½ä½“) çš„æ²»ç†ä¸æ¶æ„è®¾è®¡æˆä¸ºç»å¯¹çƒ­ç‚¹ï¼Œä»ä¼ä¸šçº§æµç¨‹è‡ªåŠ¨åŒ–åˆ°é˜²æ­¢å¤šæ™ºèƒ½ä½“åˆè°‹çš„â€œåˆ¶åº¦è®¾è®¡â€å‡æœ‰æ¶‰åŠï¼›æ­¤å¤–ï¼ŒDeepSeek çš„æ¶æ„å½±å“æ˜¾ç°ï¼Œå‡ºç°äº†ä¸“é—¨å°†å…¶é«˜æ•ˆæ³¨æ„åŠ›æœºåˆ¶è¿ç§»è‡³ VLM çš„ç ”ç©¶ï¼›åœ¨æœºç†å¯è§£é‡Šæ€§æ–¹é¢ï¼Œç ”ç©¶è€…ä»¬å‘ç°äº† LLM ç¿»è¯‘èƒ½åŠ›çš„â€œå¼€å…³â€ä»¥åŠå¹»è§‰ä¸çº¿æ€§å…³ç³»çš„å¼ºç›¸å…³æ€§ã€‚\n\n---\n\n### ğŸš€ Agentic AIï¼šæ¶æ„ã€æ²»ç†ä¸åŸºå‡†\n**æ™ºèƒ½ä½“ç ”ç©¶æ­£åœ¨ä»å•ä¸€èƒ½åŠ›å‘å¤æ‚çš„ç¤¾ä¼šåŒ–åä½œå’Œä¼ä¸šçº§åº”ç”¨è½åœ°è½¬å˜ã€‚**\n\n**37. Institutional AI: Governing LLM Collusion in Multi-Agent Cournot Markets via Public Governance Graphs**\n**(åˆ¶åº¦åŒ– AIï¼šé€šè¿‡å…¬å…±æ²»ç†å›¾æ²»ç†å¤šæ™ºèƒ½ä½“å¤è¯ºå¸‚åœºä¸­çš„ LLM åˆè°‹)**\nè¿™ç¯‡æ–‡ç« éå¸¸æœ‰æ„æ€ï¼Œå®ƒæå‡ºäº†ä¸€ç§**ç³»ç»Ÿçº§çš„ AI å¯¹é½æ–¹æ³•**ã€‚ä½œè€…è®¤ä¸ºä»…é å¾®è°ƒæ™ºèƒ½ä½“åå¥½æ˜¯ä¸å¤Ÿçš„ï¼Œæˆ‘ä»¬éœ€è¦â€œåˆ¶åº¦è®¾è®¡â€ã€‚æ–‡ç« æå‡ºäº†â€œæ²»ç†å›¾â€ï¼ˆGovernance Graphï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªå…¬å¼€ã€ä¸å¯ç¯¡æ”¹çš„æ¸…å•ï¼Œå®šä¹‰äº†åˆæ³•çŠ¶æ€å’Œæƒ©ç½šæœºåˆ¶ã€‚å®éªŒè¡¨æ˜ï¼Œè¿™ç§åˆ¶åº¦åŒ–æ–¹æ³•èƒ½æœ‰æ•ˆé˜²æ­¢å¤šæ™ºèƒ½ä½“åœ¨å¤è¯ºå¸‚åœºæ¨¡å‹ä¸­å½¢æˆåˆè°‹ï¼Œæ¯”å•çº¯çš„ Prompt ç¦ä»¤æœ‰æ•ˆå¾—å¤šã€‚\n\n**2. POLARIS: Typed Planning and Governed Execution for Agentic AI in Back-Office Automation**\n**(POLARISï¼šç”¨äºåå°è‡ªåŠ¨åŒ–ä¸­ Agentic AI çš„ç±»å‹åŒ–è§„åˆ’ä¸å—æ§æ‰§è¡Œ)**\né’ˆå¯¹ä¼ä¸šåå°ï¼ˆBack-Officeï¼‰ä»»åŠ¡ï¼Œæå‡ºäº† POLARIS æ¡†æ¶ã€‚å®ƒå°†è‡ªåŠ¨åŒ–è§†ä¸ºâ€œç±»å‹åŒ–è§„åˆ’åˆæˆâ€ï¼ˆtyped plan synthesisï¼‰ï¼Œç”Ÿæˆçš„æ‰§è¡Œè®¡åˆ’æ˜¯ DAGï¼ˆæœ‰å‘æ— ç¯å›¾ï¼‰ã€‚æ ¸å¿ƒè´¡çŒ®åœ¨äºå¼•å…¥äº†**ç±»å‹æ£€æŸ¥**å’Œ**ç­–ç•¥æŠ¤æ **ï¼Œç¡®ä¿ Agent çš„æ‰§è¡Œæ˜¯å¯å®¡è®¡ä¸”ç¬¦åˆè§„èŒƒçš„ï¼Œè§£å†³äº†ä¼ä¸šåº”ç”¨ä¸­å¯¹ç¡®å®šæ€§å’Œåˆè§„æ€§çš„ç—›ç‚¹ã€‚\n\n**83. AgencyBench: Benchmarking the Frontiers of Autonomous Agents in 1M-Token Real-World Contexts**\n**(AgencyBenchï¼šåœ¨ 100 ä¸‡ Token çœŸå®ä¸–ç•Œè¯­å¢ƒä¸‹å¯¹è‡ªä¸»æ™ºèƒ½ä½“å‰æ²¿èƒ½åŠ›çš„åŸºå‡†æµ‹è¯•)**\nç°æœ‰çš„ Benchmark å¾€å¾€å¤ªçŸ­ã€å¤ªç®€å•ã€‚AgencyBench ä¸“æ³¨äº**é•¿è§†ç•Œï¼ˆLong-horizonï¼‰**çš„çœŸå®åœºæ™¯ï¼Œä»»åŠ¡å¹³å‡æ¶‰åŠ 90 æ¬¡å·¥å…·è°ƒç”¨å’Œ 100 ä¸‡ token çš„ä¸Šä¸‹æ–‡ã€‚è¯„ä¼°å‘ç°é—­æºæ¨¡å‹æ˜¾è‘—ä¼˜äºå¼€æºæ¨¡å‹ï¼ˆ48.4% vs 32.1%ï¼‰ï¼Œå¹¶æ­ç¤ºäº†æ¨¡å‹åœ¨èµ„æºæ•ˆç‡å’Œè‡ªæˆ‘ä¿®æ­£èƒ½åŠ›ä¸Šçš„å·¨å¤§å·®å¼‚ã€‚\n\n**70. ReCreate: Reasoning and Creating Domain Agents Driven by Experience**\n**(ReCreateï¼šç»éªŒé©±åŠ¨çš„é¢†åŸŸæ™ºèƒ½ä½“æ¨ç†ä¸åˆ›å»º)**\næå‡ºäº†ä¸€ä¸ªâ€œæ™ºèƒ½ä½“å³ä¼˜åŒ–å™¨â€ï¼ˆAgent-as-Optimizerï¼‰çš„èŒƒå¼ã€‚ReCreate å¯ä»¥ä»è¿‡å¾€çš„äº¤äº’å†å²ï¼ˆæˆåŠŸæˆ–å¤±è´¥çš„ç»éªŒï¼‰ä¸­å­¦ä¹ ï¼Œè‡ªåŠ¨åˆ›å»ºå’Œè°ƒæ•´é¢†åŸŸç‰¹å®šçš„ Agentï¼Œä¸ä»…çœ‹ç»“æœï¼Œè¿˜èƒ½åˆ†æåŸå› å¹¶ä¿®æ”¹æ¶æ„ï¼Œæ¯”äººå·¥è®¾è®¡çš„ Agent è¡¨ç°æ›´å¥½ã€‚\n\n---\n\n### ğŸ§  LLM æœºåˆ¶ã€æ•ˆç‡ä¸å¯è§£é‡Šæ€§\n**å¦‚ä½•è®©å¤§æ¨¡å‹æ›´é«˜æ•ˆã€æ›´é€æ˜ï¼Ÿä»Šå¤©çš„å‡ ç¯‡æ–‡ç« æä¾›äº†ç¡¬æ ¸çš„è§†è§’ã€‚**\n\n**25. MHA2MLA-VLM: Enabling DeepSeek's Economical Multi-Head Latent Attention across Vision-Language Models**\n**(MHA2MLA-VLMï¼šåœ¨è§†è§‰è¯­è¨€æ¨¡å‹ä¸­å¯ç”¨ DeepSeek çš„ç»æµå‹å¤šå¤´æ½œåœ¨æ³¨æ„åŠ›)**\n**å…³æ³¨ DeepSeek æ¶æ„çš„ç ”ç©¶è€…å¿…è¯»ã€‚** éšç€ VLM ä»»åŠ¡å˜å¤æ‚ï¼ŒKV Cache æ˜¾å­˜å ç”¨æˆä¸ºç“¶é¢ˆã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ— éœ€æ˜‚è´µé¢„è®­ç»ƒå³å¯å°†ç°æœ‰ VLM è½¬æ¢ä¸º DeepSeek å¼ **MLA (Multi-Head Latent Attention)** æ¶æ„çš„æ¡†æ¶ã€‚é€šè¿‡æ¨¡æ€è§£è€¦çš„ä½ç§©è¿‘ä¼¼ï¼Œæ˜¾è‘—é™ä½äº† KV Cache çš„å ç”¨ï¼Œä¸”ä¿æŒäº†åŸæœ‰æ€§èƒ½ã€‚\n\n**89. Finding the Translation Switch: Discovering and Exploiting the Task-Initiation Features in LLMs**\n**(å¯»æ‰¾ç¿»è¯‘å¼€å…³ï¼šå‘ç°å¹¶åˆ©ç”¨ LLM ä¸­çš„ä»»åŠ¡å¯åŠ¨ç‰¹å¾)**\né€šè¿‡ç¨€ç–è‡ªç¼–ç å™¨ï¼ˆSAEï¼‰ï¼Œä½œè€…åœ¨ LLM å†…éƒ¨æ‰¾åˆ°äº†ä¸€ç»„**â€œç¿»è¯‘å¯åŠ¨â€ç‰¹å¾**ã€‚å› æœå¹²é¢„å®éªŒè¡¨æ˜ï¼Œæ¿€æ´»è¿™äº›ç‰¹å¾èƒ½å¼ºåˆ¶æ¨¡å‹è¿›è¡Œç¿»è¯‘ï¼Œè€ŒæŠ‘åˆ¶å®ƒä»¬åˆ™ä¼šå¯¼è‡´å¹»è§‰ã€‚è¿™ä¸€å‘ç°ä¸ä»…æ­ç¤ºäº† LLM çš„å†…éƒ¨æœºç†ï¼Œè¿˜æå‡ºäº†ä¸€ç§é€šè¿‡ç­›é€‰â€œæœºåˆ¶ä¸Šå›°éš¾â€æ ·æœ¬è¿›è¡Œå¾®è°ƒçš„é«˜æ•ˆæ•°æ®é€‰æ‹©ç­–ç•¥ã€‚\n\n**31. Relational Linearity is a Predictor of Hallucinations**\n**(å…³ç³»çº¿æ€§åº¦æ˜¯å¹»è§‰çš„é¢„æµ‹æŒ‡æ ‡)**\nä¸ºä»€ä¹ˆ LLM ä¼šäº§ç”Ÿå¹»è§‰ï¼Ÿä½œè€…å‡è®¾ï¼š**çº¿æ€§å…³ç³»**çš„çŸ¥è¯†å­˜å‚¨å¾—æ›´æŠ½è±¡ï¼Œæ¨¡å‹éš¾ä»¥è‡ªæŸ¥ï¼›è€Œ**éçº¿æ€§å…³ç³»**å­˜å‚¨å¾—æ›´ç›´æ¥ã€‚å®éªŒå‘ç°ï¼Œå…³ç³»çº¿æ€§åº¦ä¸å¹»è§‰ç‡ä¹‹é—´å­˜åœ¨å¼ºç›¸å…³æ€§ï¼ˆr > 0.78ï¼‰ã€‚è¿™ä¸ºç†è§£å’Œç¼“è§£å¹»è§‰æä¾›äº†æ–°çš„ç†è®ºè§†è§’ã€‚\n\n**84. Spectral Characterization and Mitigation of Sequential Knowledge Editing Collapse**\n**(é¡ºåºçŸ¥è¯†ç¼–è¾‘å´©æºƒçš„è°±ç‰¹å¾ä¸ç¼“è§£)**\nè¿ç»­ç¼–è¾‘å¤§æ¨¡å‹ï¼ˆKnowledge Editingï¼‰å¾€å¾€å¯¼è‡´æ¨¡å‹é€šç”¨èƒ½åŠ›å´©æºƒã€‚æœ¬æ–‡é€šè¿‡**è°±åˆ†æ**å‘ç°ï¼Œæ¨¡å‹é€šç”¨èƒ½åŠ›ä¸é¢„è®­ç»ƒæƒé‡çŸ©é˜µçš„**ä¸»è¦å¥‡å¼‚æ–¹å‘**å¯†åˆ‡ç›¸å…³ã€‚æå‡ºçš„ REVIVE æ¡†æ¶é€šè¿‡ä¿æŠ¤è¿™äº›ä¸»è¦å¥‡å¼‚å­ç©ºé—´ï¼Œä½¿å¾—æ¨¡å‹åœ¨ç»å†äº† 20,000 æ¬¡ç¼–è¾‘åä»èƒ½ä¿æŒé€šç”¨èƒ½åŠ›ã€‚\n\n---\n\n### ğŸ‘ï¸ å¤šæ¨¡æ€ä¸è§†è§‰ (Multimodal & Vision)\n**è§†è§‰ç”Ÿæˆä¸æ¨ç†æ­£åœ¨å‘æ›´æ·±å±‚çš„ç‰©ç†ç†è§£å’Œé€»è¾‘æ¨ç†è¿›å‘ã€‚**\n\n**69. Vision-as-Inverse-Graphics Agent via Interleaved Multimodal Reasoning**\n**(VIGAï¼šé€šè¿‡äº¤é”™å¤šæ¨¡æ€æ¨ç†å®ç°çš„è§†è§‰å³é€†å›¾å½¢æ™ºèƒ½ä½“)**\nè®¡ç®—æœºè§†è§‰çš„é•¿æœŸç›®æ ‡æ˜¯å°†å›¾åƒé‡æ„ä¸ºå¯ç¼–è¾‘çš„å›¾å½¢ç¨‹åºã€‚VIGA æ™ºèƒ½ä½“é€šè¿‡â€œç¼–å†™-è¿è¡Œ-æ¸²æŸ“-æ¯”è¾ƒ-ä¿®æ”¹â€çš„é—­ç¯ï¼Œåˆ©ç”¨ VLM è¿›è¡Œäº¤é”™æ¨ç†ã€‚å®ƒä¸éœ€è¦å¾®è°ƒï¼Œå°±èƒ½åœ¨ 3D é‡æ„ã€åœºæ™¯ç¼–è¾‘ç­‰ä»»åŠ¡ä¸Šå®ç°å¼ºå¤§çš„ One-shot èƒ½åŠ›ã€‚\n\n**1. AI Co-Scientist for Knowledge Synthesis in Medical Contexts: A Proof of Concept**\n**(åŒ»å­¦è¯­å¢ƒä¸‹çŸ¥è¯†ç»¼åˆçš„ AI è”åˆç§‘å­¦å®¶ï¼šæ¦‚å¿µéªŒè¯)**\né’ˆå¯¹ç”Ÿç‰©åŒ»å­¦é¢†åŸŸçš„â€œç ”ç©¶æµªè´¹â€é—®é¢˜ï¼Œæå‡ºäº† AI Co-Scientistã€‚å®ƒåˆ©ç”¨ Neo4j çŸ¥è¯†å›¾è°±å’Œå‘é‡æ£€ç´¢ï¼Œå®ç°äº†åŸºäº PICOSï¼ˆäººç¾¤ã€å¹²é¢„ã€å¯¹ç…§ã€ç»“æœã€ç ”ç©¶è®¾è®¡ï¼‰æ¡†æ¶çš„è‡ªåŠ¨åŒ–çŸ¥è¯†ç»¼åˆã€‚Transformer æ¨¡å‹åœ¨ç ”ç©¶è®¾è®¡åˆ†ç±»ä¸Šè¾¾åˆ°äº† 95.7% çš„å‡†ç¡®ç‡ï¼Œå±•ç¤ºäº† AI åŠ é€ŸåŒ»å­¦è¯æ®åˆæˆçš„æ½œåŠ›ã€‚\n\n**101. PatientVLM Meets DocVLM: Pre-Consultation Dialogue Between Vision-Language Models for Efficient Diagnosis**\n**(PatientVLM é‡ä¸Š DocVLMï¼šç”¨äºé«˜æ•ˆè¯Šæ–­çš„è§†è§‰è¯­è¨€æ¨¡å‹é—´é¢„è¯Šå¯¹è¯)**\nè¿™ç¯‡è®ºæ–‡è®©ä¸¤ä¸ª VLM äº’ç›¸å¯¹è¯æ¥æ¨¡æ‹ŸåŒ»ç”Ÿé—®è¯Šã€‚DocVLM æ ¹æ®å›¾åƒæé—®ï¼ŒPatientVLM æ ¹æ®çœŸå®è¯Šæ–­ç”Ÿæˆç—‡çŠ¶æè¿°ã€‚è¿™ç§**åˆæˆå¯¹è¯æ•°æ®**è¢«ç”¨æ¥å¾®è°ƒæ¨¡å‹ï¼Œæ˜¾è‘—æå‡äº†è¯Šæ–­å‡†ç¡®ç‡ï¼Œè¯æ˜äº†æ¨¡æ‹ŸåŒ»æ‚£äº’åŠ¨æ•°æ®çš„ä»·å€¼ã€‚\n\n---\n\n### ğŸ¤– å…·èº«æ™ºèƒ½ä¸æœºå™¨äºº (Embodied AI)\n\n**32. The Great March 100: 100 Detail-oriented Tasks for Evaluating Embodied AI Agents**\n**(é•¿å¾ 100ï¼šç”¨äºè¯„ä¼°å…·èº« AI æ™ºèƒ½ä½“çš„ 100 é¡¹ç»†èŠ‚å¯¼å‘ä»»åŠ¡)**\næå‡ºäº†ä¸€ä¸ªæ–°çš„æœºå™¨äººå­¦ä¹ åŸºå‡†æµ‹è¯• GM-100ï¼ŒåŒ…å« 100 ä¸ªç²¾å¿ƒè®¾è®¡çš„ä»»åŠ¡ï¼Œæ—¨åœ¨å…¨é¢è¯„ä¼° VLAï¼ˆVision-Language-Actionï¼‰æ¨¡å‹çš„é•¿å°¾è¡Œä¸ºå’Œäº¤äº’èƒ½åŠ›ã€‚è¿™æ˜¯ä¸€ä¸ªè¿ˆå‘â€œæœºå™¨äººå­¦ä¹ å¥¥æ—åŒ¹å…‹â€çš„é‡è¦ä¸€æ­¥ã€‚\n\n**4. RobotDesignGPT: Automated Robot Design Synthesis using Vision Language Models**\n**(RobotDesignGPTï¼šä½¿ç”¨è§†è§‰è¯­è¨€æ¨¡å‹è‡ªåŠ¨åˆæˆæœºå™¨äººè®¾è®¡)**\nåˆ©ç”¨ VLM çš„é€šç”¨çŸ¥è¯†æ¥è‡ªåŠ¨åŒ–æœºå™¨äººè®¾è®¡æµç¨‹ã€‚ç”¨æˆ·è¾“å…¥æç¤ºè¯å’Œå‚è€ƒå›¾ï¼Œç³»ç»Ÿå°±èƒ½ç”Ÿæˆæ—¢ç¾è§‚åˆç¬¦åˆè¿åŠ¨å­¦åŸç†çš„æœºå™¨äººè®¾è®¡ï¼ˆä»è…¿å¼åŠ¨ç‰©åˆ°é£è¡Œç”Ÿç‰©ï¼‰ã€‚\n\n---\n\n### ğŸ›¡ï¸ å®‰å…¨ä¸ç¤¾ä¼šå½±å“\n\n**98. Beyond Max Tokens: Stealthy Resource Amplification via Tool Calling Chains in LLM Agents**\n**(è¶…è¶Šæœ€å¤§ Tokenï¼šLLM æ™ºèƒ½ä½“ä¸­é€šè¿‡å·¥å…·è°ƒç”¨é“¾è¿›è¡Œçš„éšç§˜èµ„æºæ”¾å¤§æ”»å‡»)**\næ­ç¤ºäº†ä¸€ç§é’ˆå¯¹ Agent çš„æ–°å‹ **DoS æ”»å‡»**ã€‚æ”»å‡»è€…é€šè¿‡æ“çºµå·¥å…·æœåŠ¡å™¨çš„è¿”å›ç­–ç•¥ï¼Œè¯±å¯¼ Agent è¿›å…¥æé•¿çš„å·¥å…·è°ƒç”¨å¾ªç¯ï¼ˆè¶…è¿‡ 6 ä¸‡ tokenï¼‰ï¼Œå¯¼è‡´æ¨ç†æˆæœ¬æ¿€å¢æ•°ç™¾å€ï¼Œä¸”å¾ˆéš¾è¢«å¸¸è§„éªŒè¯æ£€æµ‹åˆ°ã€‚\n\n**55. Artificial Intelligence and the US Economy: An Accounting Perspective on Investment and Production**\n**(äººå·¥æ™ºèƒ½ä¸ç¾å›½ç»æµï¼šæŠ•èµ„ä¸ç”Ÿäº§çš„ä¼šè®¡è§†è§’)**\nä»å®è§‚ç»æµè§’åº¦åˆ†æäº† AI çš„å½±å“ã€‚æ–‡ç« æŒ‡å‡ºï¼Œæ•°æ®ä¸­å¿ƒæ˜¯ AI ç”Ÿæ€çš„æ”¯æŸ±ï¼Œå¸å¼•äº†å·¨é¢æŠ•èµ„ã€‚è™½ç„¶ç›®å‰ AI ç¡¬ä»¶çš„é«˜è¿›å£å«é‡æŠµæ¶ˆäº†éƒ¨åˆ† GDP å¢é•¿ï¼Œä½† AI æœåŠ¡ç”Ÿäº§æœªæ¥å¯èƒ½å¯¹ GDP åšå‡ºä¸æŠ•èµ„ç›¸å½“çš„è´¡çŒ®ã€‚\n\n---\n**ğŸ’¡ ç®€è®¯ï¼š**\n*   **[29. HORSE]** æå‡ºäº†ä¸€ç§å±‚çº§æ­£äº¤æ®‹å·®ä¼ æ’­æ–¹æ³•ï¼Œç”¨äºæ›´ç¨³å®šçš„å¤§æ¨¡å‹æµ·é‡çŸ¥è¯†ç¼–è¾‘ã€‚\n*   **[28. Map2Thought]** ä¸º 3D VLM å¼•å…¥äº† Metric-CogMapï¼Œå®ç°äº†æ˜¾å¼ä¸”å¯è§£é‡Šçš„ç©ºé—´æ¨ç†ã€‚\n*   **[92. HADES]** åˆ©ç”¨å“ˆå¯†é¡¿åŠ¨åŠ›å­¦è¿›è¡Œè›‹ç™½è´¨ä¼˜åŒ–ï¼Œè§£å†³äº†åºåˆ—ä¼˜åŒ–ä¸­å¿½ç•¥ç»“æ„çº¦æŸçš„é—®é¢˜ã€‚\n*   **[7. Translation as Proxy]** å‘ç°ç¿»è¯‘è´¨é‡æ˜¯è¡¡é‡ LLM å¤šè¯­è¨€èƒ½åŠ›çš„ç»ä½³ä»£ç†æŒ‡æ ‡ï¼Œæ¯”æ˜‚è´µçš„ç‰¹å®šä»»åŠ¡è¯„æµ‹æ›´é«˜æ•ˆã€‚\n\nä»Šå¤©çš„å¿«æŠ¥å°±åˆ°è¿™é‡Œï¼Œå¸Œæœ›ä½ èƒ½ä»ä¸­æ‰¾åˆ°çµæ„Ÿï¼æˆ‘ä»¬æ˜å¤©è§ã€‚",
  "papers": [
    {
      "arxiv_id": "2601.11825v1",
      "title": "AI Co-Scientist for Knowledge Synthesis in Medical Contexts: A Proof of Concept",
      "title_zh": "åŒ»å­¦è¯­å¢ƒä¸‹çŸ¥è¯†åˆæˆçš„ AI ååŒç§‘å­¦å®¶ï¼šæ¦‚å¿µéªŒè¯",
      "authors": [
        "Arya Rahgozar",
        "Pouria Mortezaagha"
      ],
      "abstract": "Research waste in biomedical science is driven by redundant studies, incomplete reporting, and the limited scalability of traditional evidence synthesis workflows. We present an AI co-scientist for scalable and transparent knowledge synthesis based on explicit formalization of Population, Intervention, Comparator, Outcome, and Study design (PICOS). The platform integrates relational storage, vector-based semantic retrieval, and a Neo4j knowledge graph. Evaluation was conducted on dementia-sport and non-communicable disease corpora. Automated PICOS compliance and study design classification from titles and abstracts were performed using a Bidirectional Long Short-Term Memory baseline and a transformer-based multi-task classifier fine-tuned from PubMedBERT. Full-text synthesis employed retrieval-augmented generation with hybrid vector and graph retrieval, while BERTopic was used to identify thematic structure, redundancy, and evidence gaps. The transformer model achieved 95.7% accuracy for study design classification with strong agreement against expert annotations, while the Bi-LSTM achieved 87% accuracy for PICOS compliance detection. Retrieval-augmented generation outperformed non-retrieval generation for queries requiring structured constraints, cross-study integration, and graph-based reasoning, whereas non-retrieval approaches remained competitive for high-level summaries. Topic modeling revealed substantial thematic redundancy and identified underexplored research areas. These results demonstrate that PICOS-aware and explainable natural language processing can improve the scalability, transparency, and efficiency of evidence synthesis. The proposed architecture is domain-agnostic and offers a practical framework for reducing research waste across biomedical disciplines.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† AI co-scientistï¼Œä¸€ä¸ªç”¨äºåŒ»ç–—èƒŒæ™¯ä¸‹çŸ¥è¯†åˆæˆ (knowledge synthesis) çš„æ¦‚å¿µéªŒè¯å¹³å°ï¼Œæ—¨åœ¨è§£å†³ç”Ÿç‰©åŒ»å­¦ç ”ç©¶ä¸­çš„å†—ä½™å’Œè¯æ®åˆæˆå·¥ä½œæµæ‰©å±•æ€§å—é™ç­‰é—®é¢˜ã€‚è¯¥å¹³å°åŸºäº PICOS (Population, Intervention, Comparator, Outcome, Study design) çš„æ˜¾å¼å½¢å¼åŒ–ï¼Œé›†æˆäº†å…³ç³»å‹å­˜å‚¨ã€å‘é‡è¯­ä¹‰æ£€ç´¢å’Œ Neo4j çŸ¥è¯†å›¾è°± (knowledge graph)ã€‚æŠ€æœ¯ä¸Šåˆ©ç”¨å¾®è°ƒè‡ª PubMedBERT çš„ Transformer å¤šä»»åŠ¡åˆ†ç±»å™¨è¿›è¡Œç ”ç©¶è®¾è®¡åˆ†ç±»ï¼Œå¹¶ç»“åˆæ£€ç´¢å¢å¼ºç”Ÿæˆ (RAG) ä¸ BERTopic è¯†åˆ«ä¸»é¢˜ç»“æ„å’Œè¯æ®ç¼ºå£ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒTransformer æ¨¡å‹åœ¨åˆ†ç±»ä»»åŠ¡ä¸Šè¾¾åˆ°äº† 95.7% çš„å‡†ç¡®ç‡ï¼Œä¸” RAG åœ¨å¤„ç†è·¨ç ”ç©¶æ•´åˆå’Œå›¾è°±æ¨ç†æŸ¥è¯¢æ–¹é¢è¡¨ç°ä¼˜å¼‚ã€‚ä¸»é¢˜å»ºæ¨¡è¿›ä¸€æ­¥æ­ç¤ºäº†æ˜¾è‘—çš„ç ”ç©¶å†—ä½™ï¼Œå¹¶è¯†åˆ«å‡ºå°šæœªå……åˆ†æ¢ç´¢çš„é¢†åŸŸã€‚è¯¥æ¶æ„è¯æ˜äº†å…·å¤‡ PICOS æ„ŸçŸ¥å’Œå¯è§£é‡Šæ€§çš„è‡ªç„¶è¯­è¨€å¤„ç†æŠ€æœ¯èƒ½æ˜¾è‘—æå‡è¯æ®åˆæˆçš„é€æ˜åº¦ä¸æ•ˆç‡ï¼Œä¸ºå‡å°‘ç”Ÿç‰©åŒ»å­¦é¢†åŸŸçš„ç§‘ç ”æµªè´¹æä¾›äº†å¯è¡Œæ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11825v1",
      "published_date": "2026-01-16 23:07:58 UTC",
      "updated_date": "2026-01-16 23:07:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:54:43.563008+00:00"
    },
    {
      "arxiv_id": "2601.11816v1",
      "title": "POLARIS: Typed Planning and Governed Execution for Agentic AI in Back-Office Automation",
      "title_zh": "POLARISï¼šé¢å‘åå°è‡ªåŠ¨åŒ–æ™ºèƒ½ä½“ AI çš„ç±»å‹åŒ–è§„åˆ’ä¸å—æ§æ‰§è¡Œ",
      "authors": [
        "Zahra Moslemi",
        "Keerthi Koneru",
        "Yen-Ting Lee",
        "Sheethal Kumar",
        "Ramesh Radhakrishnan"
      ],
      "abstract": "Enterprise back office workflows require agentic systems that are auditable, policy-aligned, and operationally predictable, capabilities that generic multi-agent setups often fail to deliver. We present POLARIS (Policy-Aware LLM Agentic Reasoning for Integrated Systems), a governed orchestration framework that treats automation as typed plan synthesis and validated execution over LLM agents. A planner proposes structurally diverse, type checked directed acyclic graphs (DAGs), a rubric guided reasoning module selects a single compliant plan, and execution is guarded by validator gated checks, a bounded repair loop, and compiled policy guardrails that block or route side effects before they occur. Applied to document centric finance tasks, POLARIS produces decision grade artifacts and full execution traces while reducing human intervention. Empirically, POLARIS achieves a micro F1 of 0.81 on the SROIE dataset and, on a controlled synthetic suite, achieves 0.95 to 1.00 precision for anomaly routing with preserved audit trails. These evaluations constitute an initial benchmark for governed Agentic AI. POLARIS provides a methodological and benchmark reference for policy-aligned Agentic AI. Keywords Agentic AI, Enterprise Automation, Back-Office Tasks, Benchmarks, Governance, Typed Planning, Evaluation",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†POLARISï¼ˆPolicy-Aware LLM Agentic Reasoning for Integrated Systemsï¼‰ï¼Œä¸€ä¸ªé’ˆå¯¹ä¼ä¸šåå°è‡ªåŠ¨åŒ–è®¾è®¡çš„å—æ§ç¼–æ’æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³é€šç”¨å¤šæ™ºèƒ½ä½“ç³»ç»Ÿåœ¨å®¡è®¡ã€æ”¿ç­–å¯¹é½å’Œæ“ä½œå¯é¢„æµ‹æ€§æ–¹é¢çš„ä¸è¶³ã€‚è¯¥æ¡†æ¶å°†è‡ªåŠ¨åŒ–è§†ä¸ºç±»å‹åŒ–è®¡åˆ’åˆæˆï¼ˆTyped plan synthesisï¼‰ä»¥åŠåœ¨LLM agentsä¸Šçš„éªŒè¯æ‰§è¡Œï¼Œé€šè¿‡è§„åˆ’å™¨ç”Ÿæˆç»“æ„å¤šæ ·ä¸”ç»è¿‡ç±»å‹æ£€æŸ¥çš„æœ‰å‘æ— ç¯å›¾ï¼ˆDAGsï¼‰ï¼Œå¹¶åˆ©ç”¨å‡†åˆ™å¼•å¯¼çš„æ¨ç†æ¨¡å—ç­›é€‰åˆè§„è®¡åˆ’ã€‚åœ¨æ‰§è¡Œé˜¶æ®µï¼Œç³»ç»Ÿé€šè¿‡éªŒè¯å™¨é—¨æ§æ£€æŸ¥ã€å—é™ä¿®å¤å¾ªç¯å’Œç¼–è¯‘åçš„æ”¿ç­–æŠ¤æ ï¼ˆPolicy guardrailsï¼‰å¯¹ä¾§æ•ˆåº”è¿›è¡Œç®¡ç†ï¼Œç¡®ä¿ç”Ÿæˆå†³ç­–çº§äº§ç‰©å¹¶ä¿ç•™å®Œæ•´å®¡è®¡è¸ªè¿¹ã€‚å®éªŒè¡¨æ˜ï¼ŒPOLARISåœ¨SROIEæ•°æ®é›†ä¸Šè¾¾åˆ°äº†0.81çš„å¾®è§‚F1åˆ†æ•°ï¼Œå¹¶åœ¨å¼‚å¸¸è·¯ç”±ä»»åŠ¡ä¸­å®ç°äº†0.95è‡³1.00çš„ç²¾ç¡®ç‡ã€‚è¯¥ç ”ç©¶ä¸ºç­–ç•¥å¯¹é½çš„Agentic AIæä¾›äº†å…³é”®çš„æ–¹æ³•è®ºå‚è€ƒï¼Œå¹¶æ„å»ºäº†å—æ§æ™ºèƒ½ä½“ç³»ç»Ÿçš„åˆæ­¥è¯„ä¼°åŸºå‡†ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Workshop on Agentic AI Benchmarks and Applications for Enterprise Tasks: AAAI 2026",
      "pdf_url": "https://arxiv.org/pdf/2601.11816v1",
      "published_date": "2026-01-16 22:38:21 UTC",
      "updated_date": "2026-01-16 22:38:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:54:45.250866+00:00"
    },
    {
      "arxiv_id": "2601.11809v1",
      "title": "Multi-agent DRL-based Lane Change Decision Model for Cooperative Planning in Mixed Traffic",
      "title_zh": "æ··åˆäº¤é€šååŒè§„åˆ’ä¸­åŸºäºå¤šæ™ºèƒ½ä½“æ·±åº¦å¼ºåŒ–å­¦ä¹ çš„æ¢é“å†³ç­–æ¨¡å‹",
      "authors": [
        "Zeyu Mu",
        "Shangtong Zhang",
        "B. Brian Park"
      ],
      "abstract": "Connected automated vehicles (CAVs) possess the ability to communicate and coordinate with one another, enabling cooperative platooning that enhances both energy efficiency and traffic flow. However, during the initial stage of CAV deployment, the sparse distribution of CAVs among human-driven vehicles reduces the likelihood of forming effective cooperative platoons. To address this challenge, this study proposes a hybrid multi-agent lane change decision model aimed at increasing CAV participation in cooperative platooning and maximizing its associated benefits. The proposed model employs the QMIX framework, integrating traffic data processed through a convolutional neural network (CNN-QMIX). This architecture addresses a critical issue in dynamic traffic scenarios by enabling CAVs to make optimal decisions irrespective of the varying number of CAVs present in mixed traffic. Additionally, a trajectory planner and a model predictive controller are designed to ensure smooth and safe lane-change execution. The proposed model is trained and evaluated within a microsimulation environment under varying CAV market penetration rates. The results demonstrate that the proposed model efficiently manages fluctuating traffic agent numbers, significantly outperforming the baseline rule-based models. Notably, it enhances cooperative platooning rates up to 26.2\\%, showcasing its potential to optimize CAV cooperation and traffic dynamics during the early stage of deployment.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºæ··åˆå¤šæ™ºèƒ½ä½“æ·±åº¦å¼ºåŒ–å­¦ä¹ (Multi-agent DRL)çš„è½¦é“å˜æ¢å†³ç­–æ¨¡å‹ï¼Œæ—¨åœ¨è§£å†³æ··åˆäº¤é€šæµä¸­è”ç½‘è‡ªåŠ¨é©¾é©¶è½¦è¾†(CAVs)ç”±äºåˆ†å¸ƒç¨€ç–è€Œéš¾ä»¥å½¢æˆååŒç¼–é˜Ÿ(Cooperative Platooning)çš„é—®é¢˜ã€‚è¯¥æ¨¡å‹é‡‡ç”¨CNN-QMIXæ¶æ„ï¼Œé€šè¿‡ç»“åˆå·ç§¯ç¥ç»ç½‘ç»œ(CNN)ä¸QMIXæ¡†æ¶ï¼Œä½¿CAVsèƒ½å¤Ÿåœ¨æ™ºèƒ½ä½“æ•°é‡åŠ¨æ€å˜åŒ–çš„åœºæ™¯ä¸‹åšå‡ºæœ€ä¼˜å†³ç­–ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜é›†æˆäº†è½¨è¿¹è§„åˆ’å™¨(Trajectory Planner)å’Œæ¨¡å‹é¢„æµ‹æ§åˆ¶å™¨(Model Predictive Controller)ä»¥ç¡®ä¿å˜é“è¿‡ç¨‹çš„å®‰å…¨ä¸å¹³ç¨³ã€‚åœ¨å¾®è§‚ä»¿çœŸç¯å¢ƒä¸‹çš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨å¤„ç†æ³¢åŠ¨äº¤é€šæµæ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œæ˜¾è‘—ä¼˜äºåŸºäºè§„åˆ™(Rule-based)çš„åŸºå‡†æ¨¡å‹ã€‚æœ€ç»ˆç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•å°†ååŒç¼–é˜Ÿç‡æå‡äº†26.2%ï¼Œä¸ºCAVséƒ¨ç½²åˆæœŸçš„äº¤é€šæµä¼˜åŒ–å’Œåä½œè§„åˆ’æä¾›äº†æœ‰æ•ˆæ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Under review at IEEE Transactions on Intelligent Transportation Systems",
      "pdf_url": "https://arxiv.org/pdf/2601.11809v1",
      "published_date": "2026-01-16 22:22:05 UTC",
      "updated_date": "2026-01-16 22:22:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:54:50.435851+00:00"
    },
    {
      "arxiv_id": "2601.11801v1",
      "title": "RobotDesignGPT: Automated Robot Design Synthesis using Vision Language Models",
      "title_zh": "RobotDesignGPTï¼šåŸºäºè§†è§‰è¯­è¨€æ¨¡å‹çš„è‡ªåŠ¨åŒ–æœºå™¨äººè®¾è®¡åˆæˆ",
      "authors": [
        "Nitish Sontakke",
        "K. Niranjan Kumar",
        "Sehoon Ha"
      ],
      "abstract": "Robot design is a nontrivial process that involves careful consideration of multiple criteria, including user specifications, kinematic structures, and visual appearance. Therefore, the design process often relies heavily on domain expertise and significant human effort. The majority of current methods are rule-based, requiring the specification of a grammar or a set of primitive components and modules that can be composed to create a design. We propose a novel automated robot design framework, RobotDesignGPT, that leverages the general knowledge and reasoning capabilities of large pre-trained vision-language models to automate the robot design synthesis process. Our framework synthesizes an initial robot design from a simple user prompt and a reference image. Our novel visual feedback approach allows us to greatly improve the design quality and reduce unnecessary manual feedback. We demonstrate that our framework can design visually appealing and kinematically valid robots inspired by nature, ranging from legged animals to flying creatures. We justify the proposed framework by conducting an ablation study and a user study.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†RobotDesignGPTï¼Œä¸€ç§åˆ©ç”¨é¢„è®­ç»ƒè§†è§‰è¯­è¨€æ¨¡å‹(Vision-Language Models, VLMs)çš„é€šç”¨çŸ¥è¯†å’Œæ¨ç†èƒ½åŠ›æ¥è‡ªåŠ¨åŒ–æœºå™¨äººè®¾è®¡åˆæˆçš„æ–°å‹æ¡†æ¶ã€‚é’ˆå¯¹ä¼ ç»Ÿè®¾è®¡æ–¹æ³•è¿‡åº¦ä¾èµ–é¢†åŸŸä¸“å®¶å’Œè§„åˆ™åŒ–è¯­æ³•çš„é—®é¢˜ï¼Œè¯¥æ¡†æ¶ä»…éœ€é€šè¿‡ç®€å•çš„ç”¨æˆ·æç¤ºå’Œå‚è€ƒå›¾åƒå³å¯åˆæˆåˆå§‹æœºå™¨äººè®¾è®¡ã€‚é€šè¿‡å¼•å…¥åˆ›æ–°çš„è§†è§‰åé¦ˆ(Visual Feedback)æœºåˆ¶ï¼Œè¯¥ç³»ç»Ÿèƒ½å¤Ÿæ˜¾è‘—æå‡è®¾è®¡è´¨é‡å¹¶å¤§å¹…å‡å°‘äººå·¥å¹²é¢„ã€‚å®éªŒè¯æ˜ï¼ŒRobotDesignGPTèƒ½å¤Ÿè®¾è®¡å‡ºå—è‡ªç„¶ç•Œçµå·§åŠ¨ç‰©æˆ–é£è¡Œç”Ÿç‰©å¯å‘ã€ä¸”åœ¨è§†è§‰ç¾å­¦å’Œè¿åŠ¨å­¦(Kinematic)ä¸Šå‡æœ‰æ•ˆçš„æœºå™¨äººï¼Œå¹¶é€šè¿‡æ¶ˆèå®éªŒ(Ablation Study)å’Œç”¨æˆ·ç ”ç©¶éªŒè¯äº†è¯¥æ¡†æ¶çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11801v1",
      "published_date": "2026-01-16 22:04:49 UTC",
      "updated_date": "2026-01-16 22:04:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:54:44.379496+00:00"
    },
    {
      "arxiv_id": "2601.11792v1",
      "title": "A self-evolving multi-role collaborative framework with fine-grained difficulty guidance for innovative mathematical problem generation",
      "title_zh": "é¢å‘åˆ›æ–°æ€§æ•°å­¦é¢˜ç›®ç”Ÿæˆçš„ç»†ç²’åº¦éš¾åº¦å¼•å¯¼è‡ªæ¼”è¿›å¤šè§’è‰²åä½œæ¡†æ¶",
      "authors": [
        "Yifei Sun",
        "Yongan Li",
        "A. K. Qin",
        "Sicheng Hou",
        "Tamas Pflanzner"
      ],
      "abstract": "Mathematical problem generation (MPG) is a significant research direction in the field of intelligent education. In recent years, the rapid development of large language models (LLMs) has enabled new technological approaches to problem-generation tasks. Although existing LLMs can achieve high correctness rates, they generally lack innovation and exhibit poor discrimination. In this paper, we propose the task of innovative math problem generation (IMPG). To solve the IMPG task, this paper proposes a self-evolving, multi-role collaborative framework with fine-grained difficulty guidance. First, a multi-role collaborative mechanism comprising a sampler, generator, evaluator, state machine, and memory is constructed, ensuring the correctness of generated problems through iterative optimization informed by self-assessment and external feedback. Second, we introduce an improved difficulty model to quantify difficulty and provide fine-grained guidance. We adopt the data-driven association-guided path sampling (DAPS) algorithm to enhance the semantic rationality of sampled encodings. Third, we construct the HSM3K-CN dataset, which comprises high-quality high school math problems. A multi-stage training pipeline is adopted, incorporating continual pre-training (CPT), supervised fine-tuning (SFT), and group relative policy optimization (GRPO), to enhance the generation and evaluation capabilities of the base model. Finally, system self-evolution is achieved by transferring evaluation capabilities from the expert model to the apprentice model via distillation. Experiments show that, compared to baseline models, our proposed method significantly improves the innovation of the generated problems while maintaining a high correctness rate.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨æ•°å­¦é¢˜ç”Ÿæˆ(MPG)ä»»åŠ¡ä¸­æ™®éå­˜åœ¨çš„åˆ›æ–°æ€§ä¸è¶³å’ŒåŒºåˆ†åº¦å·®çš„é—®é¢˜ï¼Œæå‡ºäº†åˆ›æ–°æ€§æ•°å­¦é¢˜ç”Ÿæˆ(IMPG)ä»»åŠ¡åŠä¸€ç§å…·å¤‡ç»†ç²’åº¦éš¾åº¦å¼•å¯¼çš„è‡ªæˆ‘è¿›åŒ–å¤šè§’è‰²åä½œæ¡†æ¶ã€‚è¯¥æ¡†æ¶é›†æˆäº†é‡‡æ ·å™¨ã€ç”Ÿæˆå™¨ã€è¯„ä¼°å™¨ã€çŠ¶æ€æœºå’Œè®°å¿†æ¨¡å—ï¼Œé€šè¿‡è‡ªæˆ‘è¯„ä¼°ä¸å¤–éƒ¨åé¦ˆçš„è¿­ä»£ä¼˜åŒ–æ¥ä¿è¯é¢˜ç›®çš„æ­£ç¡®æ€§ã€‚ç ”ç©¶å¼•å…¥äº†æ”¹è¿›çš„éš¾åº¦æ¨¡å‹è¿›è¡Œé‡åŒ–å¼•å¯¼ï¼Œå¹¶é‡‡ç”¨æ•°æ®é©±åŠ¨çš„å…³è”å¼•å¯¼è·¯å¾„é‡‡æ ·(DAPS)ç®—æ³•å¢å¼ºé‡‡æ ·çš„è¯­ä¹‰åˆç†æ€§ã€‚é€šè¿‡åœ¨HSM3K-CNæ•°æ®é›†ä¸Šæ‰§è¡ŒåŒ…å«æŒç»­é¢„è®­ç»ƒ(CPT)ã€ç›‘ç£å¾®è°ƒ(SFT)å’Œç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–(GRPO)çš„å¤šé˜¶æ®µè®­ç»ƒï¼Œå¹¶åˆ©ç”¨çŸ¥è¯†è’¸é¦å®ç°ä»ä¸“å®¶åˆ°å­¦å¾’æ¨¡å‹çš„è¯„ä¼°èƒ½åŠ›è¿ç§»ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¿æŒé«˜æ­£ç¡®ç‡çš„åŒæ—¶æ˜¾è‘—æå‡äº†ç”Ÿæˆé¢˜ç›®çš„åˆ›æ–°æ€§ï¼Œæœ‰æ•ˆåœ°æ¨åŠ¨äº†æ™ºèƒ½æ•™è‚²ä¸­è‡ªåŠ¨åŒ–å‘½é¢˜æŠ€æœ¯çš„å‘å±•ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11792v1",
      "published_date": "2026-01-16 21:36:04 UTC",
      "updated_date": "2026-01-16 21:36:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:54:52.980100+00:00"
    },
    {
      "arxiv_id": "2601.11781v1",
      "title": "Risk-Aware Human-in-the-Loop Framework with Adaptive Intrusion Response for Autonomous Vehicles",
      "title_zh": "é¢å‘è‡ªåŠ¨é©¾é©¶æ±½è½¦çš„é£é™©æ„ŸçŸ¥å‹è‡ªé€‚åº”å…¥ä¾µå“åº”äººåœ¨å›è·¯æ¡†æ¶",
      "authors": [
        "Dawood Wasif",
        "Terrence J. Moore",
        "Seunghyun Yoon",
        "Hyuk Lim",
        "Dan Dongseong Kim",
        "Frederica F. Nelson",
        "Jin-Hee Cho"
      ],
      "abstract": "Autonomous vehicles must remain safe and effective when encountering rare long-tailed scenarios or cyber-physical intrusions during driving. We present RAIL, a risk-aware human-in-the-loop framework that turns heterogeneous runtime signals into calibrated control adaptations and focused learning. RAIL fuses three cues (curvature actuation integrity, time-to-collision proximity, and observation-shift consistency) into an Intrusion Risk Score (IRS) via a weighted Noisy-OR. When IRS exceeds a threshold, actions are blended with a cue-specific shield using a learned authority, while human override remains available; when risk is low, the nominal policy executes. A contextual bandit arbitrates among shields based on the cue vector, improving mitigation choices online. RAIL couples Soft Actor-Critic (SAC) with risk-prioritized replay and dual rewards so that takeovers and near misses steer learning while nominal behavior remains covered. On MetaDrive, RAIL achieves a Test Return (TR) of 360.65, a Test Success Rate (TSR) of 0.85, a Test Safety Violation (TSV) of 0.75, and a Disturbance Rate (DR) of 0.0027, while logging only 29.07 training safety violations, outperforming RL, safe RL, offline/imitation learning, and prior HITL baselines. Under Controller Area Network (CAN) injection and LiDAR spoofing attacks, it improves Success Rate (SR) to 0.68 and 0.80, lowers the Disengagement Rate under Attack (DRA) to 0.37 and 0.03, and reduces the Attack Success Rate (ASR) to 0.34 and 0.11. In CARLA, RAIL attains a TR of 1609.70 and TSR of 0.41 with only 8000 steps.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†RAILï¼Œä¸€ç§å…·æœ‰è‡ªé€‚åº”å…¥ä¾µå“åº”çš„é£é™©æ„ŸçŸ¥äººæœºå›ç¯(Human-in-the-Loop)æ¡†æ¶ï¼Œæ—¨åœ¨æå‡è‡ªåŠ¨é©¾é©¶è½¦è¾†åœ¨é•¿å°¾åœºæ™¯å’Œç½‘ç»œç‰©ç†å…¥ä¾µä¸‹çš„å®‰å…¨æ€§å’Œæœ‰æ•ˆæ€§ã€‚è¯¥æ¡†æ¶é€šè¿‡åŠ æƒNoisy-ORæ¨¡å‹å°†æ›²ç‡æ‰§è¡Œå®Œæ•´æ€§ã€ç¢°æ’æ—¶é—´æ¥è¿‘åº¦åŠè§‚å¯Ÿåç§»ä¸€è‡´æ€§ä¸‰ç§ä¿¡å·èåˆä¸ºå…¥ä¾µé£é™©è¯„åˆ†(Intrusion Risk Score)ã€‚å½“é£é™©è¯„åˆ†è¶…è¿‡é˜ˆå€¼æ—¶ï¼ŒRAILä½¿ç”¨å­¦ä¹ åˆ°çš„æƒé™å°†æ“ä½œä¸ç‰¹å®šé˜²æŠ¤ç½©(shield)èåˆå¹¶ä¿ç•™äººç±»æ¥ç®¡åŠŸèƒ½ï¼Œä½é£é™©æ—¶åˆ™æ‰§è¡Œåä¹‰ç­–ç•¥(nominal policy)ã€‚æ­¤å¤–ï¼Œç³»ç»Ÿåˆ©ç”¨ä¸Šä¸‹æ–‡å¤šè‡‚è€è™æœº(contextual bandit)åœ¨çº¿ä»²è£é˜²æŠ¤ç½©é€‰æ‹©ï¼Œå¹¶å°†è½¯Actor-Critic(SAC)ç®—æ³•ä¸é£é™©ä¼˜å…ˆå›æ”¾(risk-prioritized replay)ç»“åˆï¼Œåˆ©ç”¨æ¥ç®¡å’Œè¿‘ä¹ç¢°æ’çš„æ•°æ®å¼•å¯¼å­¦ä¹ ã€‚åœ¨MetaDriveå®éªŒä¸­ï¼ŒRAILåœ¨æµ‹è¯•æˆåŠŸç‡(TSR)å’Œå®‰å…¨æŒ‡æ ‡ä¸Šæ˜¾è‘—ä¼˜äºä¼ ç»Ÿå¼ºåŒ–å­¦ä¹ (RL)åŠç°æœ‰çš„äººæœºå›ç¯åŸºçº¿æ¨¡å‹ã€‚é’ˆå¯¹CANæ³¨å…¥å’ŒLiDARæ¬ºéª—æ”»å‡»ï¼Œè¯¥æ¡†æ¶æ˜¾è‘—æé«˜äº†æˆåŠŸç‡å¹¶å¤§å¹…é™ä½äº†æ”»å‡»æˆåŠŸç‡(ASR)ã€‚åœ¨CARLAç¯å¢ƒä¸‹çš„æµ‹è¯•è¿›ä¸€æ­¥è¯æ˜äº†è¯¥æ¨¡å‹ä»…éœ€æå°‘è®­ç»ƒæ­¥æ•°å³å¯è¾¾åˆ°é«˜é¢å›æŠ¥ï¼Œå±•ç°äº†æå¼ºçš„é²æ£’æ€§ä¸å­¦ä¹ æ•ˆç‡ã€‚",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "Submitted to ICRA 2026 (under review)",
      "pdf_url": "https://arxiv.org/pdf/2601.11781v1",
      "published_date": "2026-01-16 21:08:01 UTC",
      "updated_date": "2026-01-16 21:08:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:55:02.561662+00:00"
    },
    {
      "arxiv_id": "2601.11778v1",
      "title": "Translation as a Scalable Proxy for Multilingual Evaluation",
      "title_zh": "ç¿»è¯‘ï¼šå¤šè¯­è¨€è¯„ä¼°çš„å¯æ‰©å±•ä»£ç†æŒ‡æ ‡",
      "authors": [
        "Sheriff Issaka",
        "Erick Rosas Gonzalez",
        "Lieqi Liu",
        "Evans Kofi Agyei",
        "Lucas Bandarkar",
        "Nanyun Peng",
        "David Ifeoluwa Adelani",
        "Francisco GuzmÃ¡n",
        "Saadia Gabriel"
      ],
      "abstract": "The rapid proliferation of LLMs has created a critical evaluation paradox: while LLMs claim multilingual proficiency, comprehensive non-machine-translated benchmarks exist for fewer than 30 languages, leaving >98% of the world's 7,000 languages in an empirical void. Traditional benchmark construction faces scaling challenges such as cost, scarcity of domain experts, and data contamination. We evaluate the validity of a simpler alternative: can translation quality alone indicate a model's broader multilingual capabilities? Through systematic evaluation of 14 models (1B-72B parameters) across 9 diverse benchmarks and 7 translation metrics, we find that translation performance is a good indicator of downstream task success (e.g., Phi-4, median Pearson r: MetricX = 0.89, xCOMET = 0.91, SSA-COMET = 0.87). These results suggest that the representational abilities supporting faithful translation overlap with those required for multilingual understanding. Translation quality, thus emerges as a strong, inexpensive first-pass proxy of multilingual performance, enabling a translation-first screening with targeted follow-up for specific tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨å¤§è¯­è¨€æ¨¡å‹(LLMs)å¤šè¯­è¨€èƒ½åŠ›è¯„ä¼°ä¸­ï¼Œç”±äºéç¿»è¯‘åŸºå‡†æå…¶ç¨€ç¼ºä¸”æ„å»ºæˆæœ¬é«˜æ˜‚å¯¼è‡´çš„è¯„ä¼°å›°å¢ƒï¼Œå¹¶æå‡ºäº†å°†ç¿»è¯‘è´¨é‡ä½œä¸ºå…¶å¹¿æ³›å¤šè¯­è¨€èƒ½åŠ›çš„ä¸€ç§å¯æ‰©å±•ä»£ç†(Proxy)æ–¹æ¡ˆã€‚é€šè¿‡å¯¹14ä¸ªæ¨¡å‹åœ¨9ä¸ªåŸºå‡†å’Œ7ä¸ªç¿»è¯‘æŒ‡æ ‡ä¸Šçš„ç³»ç»ŸåŒ–è¯„ä¼°ï¼Œç ”ç©¶å‘ç°ç¿»è¯‘æ€§èƒ½ä¸ä¸‹æ¸¸ä»»åŠ¡çš„æˆåŠŸç‡å‘ˆç°å‡ºæå¼ºçš„ç›¸å…³æ€§ï¼Œä¾‹å¦‚åœ¨Phi-4æ¨¡å‹ä¸ŠMetricXå’ŒxCOMETçš„ä¸­ä½æ•°Pearson rç›¸å…³ç³»æ•°åˆ†åˆ«é«˜è¾¾0.89å’Œ0.91ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæ”¯æŒå¿ å®ç¿»è¯‘çš„è¡¨å¾èƒ½åŠ›ä¸å¤šè¯­è¨€ç†è§£æ‰€éœ€çš„è¡¨å¾èƒ½åŠ›é«˜åº¦é‡åˆã€‚å› æ­¤ï¼Œç¿»è¯‘è´¨é‡å¯ä»¥ä½œä¸ºä¸€ç§å¼ºæœ‰åŠ›ä¸”ä½æˆæœ¬çš„åˆæ­¥ç­›é€‰å·¥å…·ï¼Œç”¨äºå¿«é€Ÿè¯„ä¼°æ¨¡å‹çš„å¤šè¯­è¨€è¡¨ç°ã€‚è¿™ç§æ–¹æ³•ä¸ºè§£å†³å…¨çƒç»å¤§å¤šæ•°è¯­è¨€ç¼ºä¹è¯„ä¼°æ•°æ®çš„é—®é¢˜æä¾›äº†ä¸€ä¸ªé«˜æ•ˆä¸”å¯æ‰©å±•çš„è¯„ä¼°è·¯å¾„ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11778v1",
      "published_date": "2026-01-16 21:01:40 UTC",
      "updated_date": "2026-01-16 21:01:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:55:03.833004+00:00"
    },
    {
      "arxiv_id": "2601.11776v1",
      "title": "Cleansing the Artificial Mind: A Self-Reflective Detoxification Framework for Large Language Models",
      "title_zh": "å‡€åŒ–äººå·¥æ€ç»´ï¼šå¤§è¯­è¨€æ¨¡å‹çš„è‡ªæˆ‘åæ€å¼è„±æ¯’æ¡†æ¶",
      "authors": [
        "Kaituo Zhang",
        "Zhimeng Jiang",
        "Na Zou"
      ],
      "abstract": "Recent breakthroughs in Large Language Models (LLMs) have revealed remarkable generative capabilities and emerging self-regulatory mechanisms, including self-correction and self-rewarding. However, current detoxification techniques rarely exploit these built-in abilities; instead, they rely on external modules, labor-intensive data annotation, or human intervention --factors that hinder scalability and consistency. In this paper, we introduce a fully self-reflective detoxification framework that harnesses the inherent capacities of LLMs to detect, correct toxic content, and refine LLMs without external modules and data annotation. Specifically, we propose a Toxic Signal Detector --an internal self-identification mechanism, coupled with a systematic intervention process to transform toxic text into its non-toxic counterpart. This iterative procedure yields a contrastive detoxification dataset used to fine-tune the model, enhancing its ability for safe and coherent text generation. Experiments on benchmark datasets such as DetoxLLM and ParaDetox show that our method achieves better detoxification performance than state-of-the-art methods while preserving semantic fidelity. By obviating the need for human intervention or external components, this paper reveals the intrinsic self-detoxification ability of LLMs, offering a consistent and effective approach for mitigating harmful content generation. Ultimately, our findings underscore the potential for truly self-regulated language models, paving the way for more responsible and ethically guided text generation systems.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§å®Œå…¨è‡ªåæ€çš„å»æ¯’æ¡†æ¶(Self-Reflective Detoxification Framework)ï¼Œæ—¨åœ¨åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹(LLMs)çš„å†…åœ¨èƒ½åŠ›å®ç°æ¯’æ€§å†…å®¹çš„è‡ªæ£€æµ‹ä¸è‡ªçº æ­£ï¼Œä»è€Œæ‘†è„±å¯¹å¤–éƒ¨æ¨¡å—æˆ–é«˜æˆæœ¬äººå·¥æ ‡æ³¨çš„ä¾èµ–ã€‚è¯¥æ¡†æ¶æ ¸å¿ƒåŒ…å«ä¸€ä¸ªå†…éƒ¨è‡ªè¯†åˆ«æœºåˆ¶â€œæ¯’æ€§ä¿¡å·æ£€æµ‹å™¨â€(Toxic Signal Detector)ä»¥åŠä¸€å¥—ç³»ç»ŸåŒ–çš„å¹²é¢„æµç¨‹ï¼Œèƒ½å¤Ÿå°†æ¯’æ€§æ–‡æœ¬è½¬åŒ–ä¸ºéæ¯’æ€§å¯¹åº”æ–‡æœ¬ã€‚é€šè¿‡è¿™ä¸€è¿­ä»£è¿‡ç¨‹ç”Ÿæˆçš„å¯¹æ¯”å»æ¯’æ•°æ®é›†(Contrastive Detoxification Dataset)è¢«ç”¨äºæ¨¡å‹å¾®è°ƒï¼Œæ˜¾è‘—å¢å¼ºäº†å…¶ç”Ÿæˆå®‰å…¨ä¸”è¿è´¯æ–‡æœ¬çš„èƒ½åŠ›ã€‚åœ¨DetoxLLMå’ŒParaDetoxç­‰åŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¿æŒè¯­ä¹‰ä¿çœŸåº¦çš„åŒæ—¶ï¼Œå»æ¯’è¡¨ç°ä¼˜äºå½“å‰çš„SOTAæ–¹æ³•ã€‚è¯¥ç ”ç©¶æ­ç¤ºäº†LLMsæ½œè—çš„å†…åœ¨è‡ªå»æ¯’èƒ½åŠ›ï¼Œä¸ºå¼€å‘æ— éœ€å¤–éƒ¨å¹²é¢„ã€å…·å¤‡è‡ªæˆ‘ç›‘ç®¡èƒ½åŠ›çš„è´Ÿè´£ä»»äººå·¥æ™ºèƒ½ç³»ç»Ÿæä¾›äº†é«˜æ•ˆä¸”ä¸€è‡´çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11776v1",
      "published_date": "2026-01-16 21:01:26 UTC",
      "updated_date": "2026-01-16 21:01:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:55:00.465376+00:00"
    },
    {
      "arxiv_id": "2601.11768v1",
      "title": "Lightweight Self-Supervised Detection of Fundamental Frequency and Accurate Probability of Voicing in Monophonic Music",
      "title_zh": "è½»é‡çº§è‡ªç›‘ç£å•å£°éƒ¨éŸ³ä¹åŸºé¢‘æ£€æµ‹ä¸å‡†ç¡®å‘å£°æ¦‚ç‡ä¼°è®¡",
      "authors": [
        "Venkat Suprabath Bitra",
        "Homayoon Beigi"
      ],
      "abstract": "Reliable fundamental frequency (F 0) and voicing estimation is essential for neural synthesis, yet many pitch extractors depend on large labeled corpora and degrade under realistic recording artifacts. We propose a lightweight, fully self-supervised framework for joint F 0 estimation and voicing inference, designed for rapid single-instrument training from limited audio. Using transposition-equivariant learning on CQT features, we introduce an EM-style iterative reweighting scheme that uses Shift Cross-Entropy (SCE) consistency as a reliability signal to suppress uninformative noisy/unvoiced frames. The resulting weights provide confidence scores that enable pseudo-labeling for a separate lightweight voicing classifier without manual annotations. Trained on MedleyDB and evaluated on MDB-stem-synth ground truth, our method achieves competitive cross-corpus performance (RPA 95.84, RCA 96.24) and demonstrates cross-instrument generalization.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§è½»é‡çº§çš„å…¨è‡ªç›‘ç£(Self-Supervised)æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å•å£°é“éŸ³ä¹ä¸­åŸºé¢‘(Fundamental Frequency, F0)æ£€æµ‹å’Œæœ‰å£°æ¦‚ç‡(Probability of Voicing)ä¼°è®¡ä¾èµ–å¤§é‡æ ‡æ³¨æ•°æ®ä¸”åœ¨çœŸå®å½•éŸ³ç¯å¢ƒä¸‹æ€§èƒ½ä¸‹é™çš„é—®é¢˜ã€‚è¯¥æ¡†æ¶åœ¨CQTç‰¹å¾ä¸Šé‡‡ç”¨è½¬ç½®ç­‰å˜å­¦ä¹ (Transposition-Equivariant Learning)ï¼Œèƒ½å¤Ÿä»æœ‰é™çš„éŸ³é¢‘æ•°æ®ä¸­é’ˆå¯¹å•ä¸€ä¹å™¨è¿›è¡Œå¿«é€Ÿè®­ç»ƒã€‚ç ”ç©¶å¼•å…¥äº†ä¸€ç§ç±»EMç®—æ³•çš„è¿­ä»£é‡åŠ æƒæ–¹æ¡ˆï¼Œåˆ©ç”¨åç§»äº¤å‰ç†µ(Shift Cross-Entropy, SCE)ä¸€è‡´æ€§ä½œä¸ºå¯é æ€§ä¿¡å·ï¼Œä»è€Œæœ‰æ•ˆæŠ‘åˆ¶æ— ä¿¡æ¯çš„å™ªå£°æˆ–æ— å£°å¸§ã€‚ç”±æ­¤äº§ç”Ÿçš„æƒé‡å¯ä½œä¸ºç½®ä¿¡åˆ†æ•°ï¼Œåœ¨æ— éœ€äººå·¥æ ‡æ³¨çš„æƒ…å†µä¸‹ä¸ºç‹¬ç«‹çš„è½»é‡çº§æœ‰å£°åˆ†ç±»å™¨æä¾›ä¼ªæ ‡ç­¾(Pseudo-labeling)ã€‚åœ¨MedleyDBç­‰æ•°æ®é›†ä¸Šçš„è¯„ä¼°ç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨åŸå§‹éŸ³é«˜å‡†ç¡®ç‡(RPA)å’ŒåŸå§‹è‰²åº¦å‡†ç¡®ç‡(RCA)ä¸Šåˆ†åˆ«è¾¾åˆ°äº†95.84%å’Œ96.24%çš„ç«äº‰æ€§è¡¨ç°ã€‚å®éªŒè¯æ˜è¯¥æ–¹æ³•å…·æœ‰è‰¯å¥½çš„è·¨è¯­æ–™åº“æ€§èƒ½å’Œè·¨ä¹å™¨æ³›åŒ–èƒ½åŠ›ï¼Œä¸ºèµ„æºå—é™åœºæ™¯ä¸‹çš„é²æ£’éŸ³é¢‘åˆ†ææä¾›äº†æœ‰æ•ˆæ–¹æ¡ˆã€‚",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.LG",
        "cs.SD",
        "eess.SP"
      ],
      "primary_category": "eess.AS",
      "comment": "12 pages, 6 figures, 3 tables, and an appendix, Accepted for publication at ICPRAM 2026 in Marbella, Spain, on March 2, 2026",
      "pdf_url": "https://arxiv.org/pdf/2601.11768v1",
      "published_date": "2026-01-16 20:46:33 UTC",
      "updated_date": "2026-01-16 20:46:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:55:03.186029+00:00"
    },
    {
      "arxiv_id": "2601.14298v1",
      "title": "Guardrails for trust, safety, and ethical development and deployment of Large Language Models (LLM)",
      "title_zh": "å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¿¡ä»»ã€å®‰å…¨åŠä¼¦ç†åŒ–å¼€å‘ä¸éƒ¨ç½²çš„å®‰å…¨æŠ¤æ ",
      "authors": [
        "Anjanava Biswas",
        "Wrick Talukdar"
      ],
      "abstract": "The AI era has ushered in Large Language Models (LLM) to the technological forefront, which has been much of the talk in 2023, and is likely to remain as such for many years to come. LLMs are the AI models that are the power house behind generative AI applications such as ChatGPT. These AI models, fueled by vast amounts of data and computational prowess, have unlocked remarkable capabilities, from human-like text generation to assisting with natural language understanding (NLU) tasks. They have quickly become the foundation upon which countless applications and software services are being built, or at least being augmented with. However, as with any groundbreaking innovations, the rise of LLMs brings forth critical safety, privacy, and ethical concerns. These models are found to have a propensity to leak private information, produce false information, and can be coerced into generating content that can be used for nefarious purposes by bad actors, or even by regular users unknowingly. Implementing safeguards and guardrailing techniques is imperative for applications to ensure that the content generated by LLMs are safe, secure, and ethical. Thus, frameworks to deploy mechanisms that prevent misuse of these models via application implementations is imperative. In this study, wepropose a Flexible Adaptive Sequencing mechanism with trust and safety modules, that can be used to implement safety guardrails for the development and deployment of LLMs.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹ (Large Language Models, LLM) åœ¨é©±åŠ¨ç”Ÿæˆå¼ AI åº”ç”¨æ—¶é¢ä¸´çš„ä¸¥å³»å®‰å…¨ã€éšç§å’Œä¼¦ç†æŒ‘æˆ˜ï¼Œç‰¹åˆ«æ˜¯åœ¨éšç§æ³„éœ²ã€è™šå‡ä¿¡æ¯ç”Ÿæˆä»¥åŠè¢«æ¶æ„åˆ©ç”¨ç­‰æ–¹é¢çš„é£é™©ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œç ”ç©¶å¼ºè°ƒäº†åœ¨åº”ç”¨å±‚é¢å®æ–½å®‰å…¨æŠ¤æ  (Guardrails) æŠ€æœ¯ä»¥ç¡®ä¿å†…å®¹åˆè§„æ€§çš„ç´§è¿«æ€§ã€‚è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§åŒ…å«ä¿¡ä»»å’Œå®‰å…¨æ¨¡å—çš„çµæ´»è‡ªé€‚åº”åºåˆ—æœºåˆ¶ (Flexible Adaptive Sequencing mechanism)ï¼Œæ—¨åœ¨ä¸º LLM çš„å¼€å‘å’Œéƒ¨ç½²æä¾›ä¸€å¥—å¯æ‰©å±•çš„å®‰å…¨é˜²æŠ¤æ¡†æ¶ã€‚è¯¥æœºåˆ¶é€šè¿‡åœ¨åº”ç”¨å®ç°ä¸­éƒ¨ç½²ç‰¹å®šçš„å¹²é¢„æ‰‹æ®µï¼Œèƒ½å¤Ÿæœ‰æ•ˆé˜²æ­¢æ¨¡å‹çš„æ»¥ç”¨å¹¶ç¡®ä¿å…¶ç”Ÿæˆå†…å®¹ç¬¦åˆä¼¦ç†æ ‡å‡†ã€‚è¿™é¡¹å·¥ä½œä¸ºæ„å»ºå®‰å…¨ã€å¯é ä¸”å¯ä¿¡çš„ LLM åº”ç”¨ç¯å¢ƒæä¾›äº†å…³é”®çš„æŠ€æœ¯è·¯å¾„å’Œæ–¹æ³•è®ºæ”¯æŒã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.14298v1",
      "published_date": "2026-01-16 20:44:06 UTC",
      "updated_date": "2026-01-16 20:44:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:55:05.384336+00:00"
    },
    {
      "arxiv_id": "2601.11762v1",
      "title": "Industry-Aligned Granular Topic Modeling",
      "title_zh": "è¡Œä¸šå¯¹é½çš„ç»†ç²’åº¦ä¸»é¢˜å»ºæ¨¡",
      "authors": [
        "Sae Young Moon",
        "Myeongjun Erik Jang",
        "Haoyan Luo",
        "Chunyang Xiao",
        "Antonios Georgiadis",
        "Fran Silavong"
      ],
      "abstract": "Topic modeling has extensive applications in text mining and data analysis across various industrial sectors. Although the concept of granularity holds significant value for business applications by providing deeper insights, the capability of topic modeling methods to produce granular topics has not been thoroughly explored. In this context, this paper introduces a framework called TIDE, which primarily provides a novel granular topic modeling method based on large language models (LLMs) as a core feature, along with other useful functionalities for business applications, such as summarizing long documents, topic parenting, and distillation. Through extensive experiments on a variety of public and real-world business datasets, we demonstrate that TIDE's topic modeling approach outperforms modern topic modeling methods, and our auxiliary components provide valuable support for dealing with industrial business scenarios. The TIDE framework is currently undergoing the process of being open sourced.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å·¥ä¸šåº”ç”¨ä¸­ç»†ç²’åº¦ä¸»é¢˜æ´å¯Ÿçš„ä¸è¶³ï¼Œæå‡ºäº†åä¸º TIDE çš„æ–°å‹æ¡†æ¶ï¼Œæ—¨åœ¨å®ç° Industry-Aligned Granular Topic Modelingã€‚è¯¥æ¡†æ¶ä»¥åŸºäº Large Language Models (LLMs) çš„ç»†ç²’åº¦ä¸»é¢˜å»ºæ¨¡ä¸ºæ ¸å¿ƒï¼Œå¹¶é›†æˆäº†é•¿æ–‡æ¡£æ‘˜è¦ã€Topic Parenting å’Œ Distillation ç­‰å®ç”¨åŠŸèƒ½ï¼Œä»¥åº”å¯¹å¤æ‚çš„ä¸šåŠ¡éœ€æ±‚ã€‚åœ¨å…¬å…±æ•°æ®é›†å’ŒçœŸå®å·¥ä¸šæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒTIDE çš„ä¸»é¢˜å»ºæ¨¡æ•ˆæœä¼˜äºç°æœ‰çš„å…ˆè¿›æ–¹æ³•ï¼Œå…¶è¾…åŠ©ç»„ä»¶èƒ½ä¸ºå·¥ä¸šåœºæ™¯æä¾›å¼ºæœ‰åŠ›çš„æ”¯æŒã€‚ç›®å‰ï¼ŒTIDE æ¡†æ¶æ­£å¤„äºå¼€æºé˜¶æ®µï¼Œä¸ºå·¥ä¸šçº§çš„å¤§è§„æ¨¡æ–‡æœ¬åˆ†ææä¾›äº†é«˜æ•ˆä¸”å…·å¤‡ä¸šåŠ¡æ·±åº¦çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11762v1",
      "published_date": "2026-01-16 20:32:11 UTC",
      "updated_date": "2026-01-16 20:32:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:55:16.197929+00:00"
    },
    {
      "arxiv_id": "2601.11758v1",
      "title": "Early Linguistic Pattern of Anxiety from Social Media Using Interpretable Linguistic Features: A Multi-Faceted Validation Study with Author-Disjoint Evaluation",
      "title_zh": "åŸºäºå¯è§£é‡Šè¯­è¨€ç‰¹å¾çš„ç¤¾äº¤åª’ä½“ç„¦è™‘æ—©æœŸè¯­è¨€æ¨¡å¼ï¼šä¸€é¡¹ç»“åˆä½œè€…æ— å…³è¯„ä¼°çš„å¤šç»´åº¦éªŒè¯ç ”ç©¶",
      "authors": [
        "Arnab Das Utsa"
      ],
      "abstract": "Anxiety affects hundreds of millions of individuals globally, yet large-scale screening remains limited. Social media language provides an opportunity for scalable detection, but current models often lack interpretability, keyword-robustness validation, and rigorous user-level data integrity. This work presents a transparent approach to social media-based anxiety detection through linguistically interpretable feature-grounded modeling and cross-domain validation. Using a substantial dataset of Reddit posts, we trained a logistic regression classifier on carefully curated subreddits for training, validation, and test splits. Comprehensive evaluation included feature ablation, keyword masking experiments, and varying-density difference analyses comparing anxious and control groups, along with external validation using clinically interviewed participants with diagnosed anxiety disorders. The model achieved strong performance while maintaining high accuracy even after sentiment removal or keyword masking. Early detection using minimal post history significantly outperformed random classification, and cross-domain analysis demonstrated strong consistency with clinical interview data. Results indicate that transparent linguistic features can support reliable, generalizable, and keyword-robust anxiety detection. The proposed framework provides a reproducible baseline for interpretable mental health screening across diverse online contexts.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç¤¾äº¤åª’ä½“ç„¦è™‘æ£€æµ‹ä¸­æ¨¡å‹ç¼ºä¹å¯è§£é‡Šæ€§ã€å…³é”®è¯é²æ£’æ€§æ ¡éªŒåŠç”¨æˆ·æ•°æ®å®Œæ•´æ€§ç­‰é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºè¯­è¨€å­¦å¯è§£é‡Šç‰¹å¾(linguistically interpretable features)çš„é€æ˜åŒ–å»ºæ¨¡ä¸è·¨åŸŸéªŒè¯æ–¹æ³•ã€‚ä½œè€…åˆ©ç”¨å¤§è§„æ¨¡ Reddit æ•°æ®é›†ï¼Œé€šè¿‡é€»è¾‘å›å½’åˆ†ç±»å™¨(logistic regression classifier)è¿›è¡Œè®­ç»ƒï¼Œå¹¶å®æ–½äº†åŒ…æ‹¬ç‰¹å¾æ¶ˆè(feature ablation)ã€å…³é”®è¯é®è”½(keyword masking)ä»¥åŠç„¦è™‘ç»„ä¸å¯¹ç…§ç»„å·®å¼‚åˆ†æåœ¨å†…çš„å¤šç»´åº¦è¯„ä¼°ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜é€šè¿‡ä¸´åºŠè®¿è°ˆè¯Šæ–­çš„ç„¦è™‘ç—‡æ‚£è€…æ•°æ®è¿›è¡Œäº†å¤–éƒ¨éªŒè¯(external validation)ï¼Œç¡®ä¿äº†æ¨¡å‹åœ¨å®é™…åŒ»ç–—åœºæ™¯ä¸­çš„ä¸€è‡´æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨ä»…ä½¿ç”¨æçŸ­å‘å¸–å†å²ä¸”ç§»é™¤æƒ…æ„Ÿè¯æˆ–ç‰¹å®šå…³é”®è¯çš„æƒ…å†µä¸‹ï¼Œä¾ç„¶èƒ½ä¿æŒæé«˜çš„æ£€æµ‹å‡†ç¡®ç‡ã€‚è·¨åŸŸåˆ†æè¿›ä¸€æ­¥è¯æ˜äº†è¯¥æ¡†æ¶å…·æœ‰æé«˜çš„å¯é æ€§ä¸æ³›åŒ–èƒ½åŠ›ï¼Œä¸ºåœ¨ä¸åŒç½‘ç»œç¯å¢ƒä¸‹å¼€å±•å¯è§£é‡Šçš„å¿ƒç†å¥åº·å¤§è§„æ¨¡ç­›æŸ¥æä¾›äº†å¯å¤åˆ¶çš„åŸºå‡†ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "9 figures, more than 1o pages",
      "pdf_url": "https://arxiv.org/pdf/2601.11758v1",
      "published_date": "2026-01-16 20:22:34 UTC",
      "updated_date": "2026-01-16 20:22:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:55:22.480436+00:00"
    },
    {
      "arxiv_id": "2601.11747v1",
      "title": "PRISM: Learning Design Knowledge from Data for Stylistic Design Improvement",
      "title_zh": "PRISMï¼šä»æ•°æ®ä¸­å­¦ä¹ è®¾è®¡çŸ¥è¯†ä»¥å®ç°è®¾è®¡é£æ ¼æ”¹è¿›",
      "authors": [
        "Huaxiaoyue Wang",
        "Sunav Choudhary",
        "Franck Dernoncourt",
        "Yu Shen",
        "Stefano Petrangeli"
      ],
      "abstract": "Graphic design often involves exploring different stylistic directions, which can be time-consuming for non-experts. We address this problem of stylistically improving designs based on natural language instructions. While VLMs have shown initial success in graphic design, their pretrained knowledge on styles is often too general and misaligned with specific domain data. For example, VLMs may associate minimalism with abstract designs, whereas designers emphasize shape and color choices. Our key insight is to leverage design data -- a collection of real-world designs that implicitly capture designer's principles -- to learn design knowledge and guide stylistic improvement. We propose PRISM (PRior-Informed Stylistic Modification) that constructs and applies a design knowledge base through three stages: (1) clustering high-variance designs to capture diversity within a style, (2) summarizing each cluster into actionable design knowledge, and (3) retrieving relevant knowledge during inference to enable style-aware improvement. Experiments on the Crello dataset show that PRISM achieves the highest average rank of 1.49 (closer to 1 is better) over baselines in style alignment. User studies further validate these results, showing that PRISM is consistently preferred by designers.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†PRISMï¼ˆPRior-Informed Stylistic Modificationï¼‰ï¼Œä¸€ç§æ—¨åœ¨åˆ©ç”¨æ•°æ®å­¦ä¹ è®¾è®¡çŸ¥è¯†å¹¶ä¼˜åŒ–å¹³é¢è®¾è®¡é£æ ¼çš„æ¡†æ¶ï¼Œä»¥è§£å†³éä¸“ä¸šäººå£«åœ¨æ¢ç´¢è®¾è®¡æ–¹å‘æ—¶è€—æ—¶è¾ƒé•¿çš„é—®é¢˜ã€‚é’ˆå¯¹è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰é¢„è®­ç»ƒé£æ ¼çŸ¥è¯†è¿‡äºç¬¼ç»Ÿä¸”ä¸ç‰¹å®šé¢†åŸŸæ•°æ®ä¸åŒ¹é…çš„æŒ‘æˆ˜ï¼ŒPRISMé€šè¿‡æŒ–æ˜çœŸå®è®¾è®¡æ•°æ®ä¸­çš„éšå¼åŸåˆ™æ¥å¼•å¯¼é£æ ¼æ”¹è¿›ã€‚è¯¥æ¡†æ¶åŒ…å«ä¸‰ä¸ªæ ¸å¿ƒé˜¶æ®µï¼šé¦–å…ˆèšç±»é«˜æ–¹å·®è®¾è®¡ä»¥æ•æ‰é£æ ¼å¤šæ ·æ€§ï¼Œéšåå°†èšç±»ç»“æœæ€»ç»“ä¸ºå¯æ“ä½œçš„è®¾è®¡çŸ¥è¯†ï¼Œæœ€ååœ¨æ¨ç†æ—¶æ£€ç´¢ç›¸å…³çŸ¥è¯†ä»¥å®ç°é£æ ¼æ„ŸçŸ¥çš„ä¿®æ”¹ã€‚åœ¨Crelloæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒPRISMåœ¨é£æ ¼å¯¹é½æ–¹é¢çš„å¹³å‡æ’åä¸º1.49ï¼Œæ˜¾è‘—ä¼˜äºåŸºçº¿æ¨¡å‹ã€‚ç”¨æˆ·ç ”ç©¶ç»“æœåŒæ ·éªŒè¯äº†è¯¥æ–¹æ³•çš„ä¼˜è¶Šæ€§ï¼Œè¯æ˜PRISMç”Ÿæˆçš„æ–¹æ¡ˆåœ¨ä¸“ä¸šè®¾è®¡å¸ˆä¸­å…·æœ‰æ›´é«˜çš„è®¤å¯åº¦ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11747v1",
      "published_date": "2026-01-16 19:56:13 UTC",
      "updated_date": "2026-01-16 19:56:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:55:25.049943+00:00"
    },
    {
      "arxiv_id": "2601.11746v1",
      "title": "LIME-LLM: Probing Models with Fluent Counterfactuals, Not Broken Text",
      "title_zh": "LIME-LLMï¼šåˆ©ç”¨æµåˆ©åäº‹å®æ ·æœ¬è€Œéæ®‹æŸæ–‡æœ¬æ¢æµ‹æ¨¡å‹",
      "authors": [
        "George Mihaila",
        "Suleyman Olcay Polat",
        "Poli Nemkova",
        "Himanshu Sharma",
        "Namratha V. Urs",
        "Mark V. Albert"
      ],
      "abstract": "Local explanation methods such as LIME (Ribeiro et al., 2016) remain fundamental to trustworthy AI, yet their application to NLP is limited by a reliance on random token masking. These heuristic perturbations frequently generate semantically invalid, out-of-distribution inputs that weaken the fidelity of local surrogate models. While recent generative approaches such as LLiMe (Angiulli et al., 2025b) attempt to mitigate this by employing Large Language Models for neighborhood generation, they rely on unconstrained paraphrasing that introduces confounding variables, making it difficult to isolate specific feature contributions. We introduce LIME-LLM, a framework that replaces random noise with hypothesis-driven, controlled perturbations. By enforcing a strict \"Single Mask-Single Sample\" protocol and employing distinct neutral infill and boundary infill strategies, LIME-LLM constructs fluent, on-manifold neighborhoods that rigorously isolate feature effects. We evaluate our method against established baselines (LIME, SHAP, Integrated Gradients) and the generative LLiMe baseline across three diverse benchmarks: CoLA, SST-2, and HateXplain using human-annotated rationales as ground truth. Empirical results demonstrate that LIME-LLM establishes a new benchmark for black-box NLP explainability, achieving significant improvements in local explanation fidelity compared to both traditional perturbation-based methods and recent generative alternatives.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶æå‡ºäº† LIME-LLM æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ LIME ç­‰ä¼ ç»Ÿå±€éƒ¨è§£é‡Šæ–¹æ³•åœ¨å¤„ç†è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡æ—¶ï¼Œå› ä¾èµ–éšæœºæ ‡è®°æ©ç ï¼ˆrandom token maskingï¼‰è€Œäº§ç”Ÿè¯­ä¹‰æ— æ•ˆä¸”å±äºåˆ†å¸ƒå¤–ï¼ˆout-of-distributionï¼‰è¾“å…¥çš„é—®é¢˜ã€‚LIME-LLM æ‘’å¼ƒäº†ä¼ ç»Ÿçš„éšæœºå™ªå£°ï¼Œè½¬è€Œé‡‡ç”¨ç”±å‡è®¾é©±åŠ¨çš„å—æ§æ‰°åŠ¨ï¼ˆcontrolled perturbationsï¼‰æŠ€æœ¯æ¥ç”Ÿæˆé‚»åŸŸæ ·æœ¬ã€‚è¯¥æ¡†æ¶é€šè¿‡å®æ–½ä¸¥æ ¼çš„â€œå•æ©ç -å•æ ·æœ¬â€ï¼ˆSingle Mask-Single Sampleï¼‰åè®®ï¼Œå¹¶ç»“åˆä¸­æ€§å¡«å……ï¼ˆneutral infillï¼‰å’Œè¾¹ç•Œå¡«å……ï¼ˆboundary infillï¼‰ç­–ç•¥ï¼Œæ„å»ºå‡ºæµç•…ä¸”å¤„äºæµå½¢ä¸Šï¼ˆon-manifoldï¼‰çš„æ–‡æœ¬ï¼Œä»è€Œç²¾ç¡®éš”ç¦»ç‰¹å®šç‰¹å¾å¯¹æ¨¡å‹é¢„æµ‹çš„è´¡çŒ®ã€‚ç ”ç©¶å›¢é˜Ÿåœ¨ CoLAã€SST-2 å’Œ HateXplain ç­‰å¤šæ ·åŒ–åŸºå‡†æµ‹è¯•ä¸­ï¼Œåˆ©ç”¨äººå·¥æ ‡æ³¨çš„é€»è¾‘ä¾æ®ï¼ˆhuman-annotated rationalesï¼‰ä½œä¸ºé‡‘æ ‡å‡†è¿›è¡Œäº†è¯„ä¼°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä¸ LIMEã€SHAPã€Integrated Gradients ä»¥åŠæ–°å…´çš„ç”Ÿæˆå¼æ–¹æ³• LLiMe ç›¸æ¯”ï¼ŒLIME-LLM æ˜¾è‘—æå‡äº†å±€éƒ¨è§£é‡Šçš„å¿ å®åº¦ï¼ˆfidelityï¼‰ã€‚è¯¥ç ”ç©¶ä¸ºé»‘ç›’æ¨¡å‹çš„å¯è§£é‡Šæ€§å»ºç«‹äº†æ–°çš„åŸºå‡†ï¼Œè¯æ˜äº†é€šè¿‡æµç•…çš„å¯¹æŠ—æ€§æ ·æœ¬è€Œéç ´ç¢æ–‡æœ¬èƒ½æ›´æœ‰æ•ˆåœ°æ¢æµ‹æ¨¡å‹æœºåˆ¶ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11746v1",
      "published_date": "2026-01-16 19:55:06 UTC",
      "updated_date": "2026-01-16 19:55:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:55:26.826707+00:00"
    },
    {
      "arxiv_id": "2601.11713v1",
      "title": "Inter-Cell Interference Rejection Based on Ultrawideband Walsh-Domain Wireless Autoencoding",
      "title_zh": "åŸºäºè¶…å®½å¸¦ Walsh åŸŸæ— çº¿è‡ªç¼–ç çš„å°åŒºé—´å¹²æ‰°æŠ‘åˆ¶",
      "authors": [
        "Rodney Martinez Alonso",
        "Cel Thys",
        "Cedric Dehos",
        "Yuneisy Esthela Garcia Guzman",
        "Sofie Pollin"
      ],
      "abstract": "This paper proposes a novel technique for rejecting partial-in-band inter-cell interference (ICI) in ultrawideband communication systems. We present the design of an end-to-end wireless autoencoder architecture that jointly optimizes the transmitter and receiver encoding/decoding in the Walsh domain to mitigate interference from coexisting narrower-band 5G base stations. By exploiting the orthogonality and self-inverse properties of Walsh functions, the system distributes and learns to encode bit-words across parallel Walsh branches. Through analytical modeling and simulation, we characterize how 5G CPOFDM interference maps into the Walsh domain and identify optimal ratios of transmission frequencies and sampling rate where the end-to-end autoencoder achieves the highest rejection. Experimental results show that the proposed autoencoder achieves up to 12 dB of ICI rejection while maintaining a low block error rate (BLER) for the same baseline channel noise, i.e., baseline Signal-to-Noise-Ratio (SNR) without the interference.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ ultrawideband é€šä¿¡ç³»ç»Ÿï¼Œæå‡ºäº†ä¸€ç§åŸºäº Walsh-Domain æ— çº¿è‡ªåŠ¨ç¼–ç å™¨ï¼ˆWireless Autoencodingï¼‰çš„æ–°å‹å¹²æ‰°æŠ‘åˆ¶æŠ€æœ¯ï¼Œæ—¨åœ¨è§£å†³ 5G åŸºç«™å¼•èµ·çš„ partial-in-band inter-cell interference (ICI) é—®é¢˜ã€‚è¯¥æ–¹æ¡ˆè®¾è®¡äº†ä¸€ç§ç«¯åˆ°ç«¯æ¶æ„ï¼Œåˆ©ç”¨ Walsh å‡½æ•°çš„æ­£äº¤æ€§å’Œè‡ªåæ€§ï¼Œåœ¨ Walsh åŸŸå†…è”åˆä¼˜åŒ–å‘å°„ç«¯ç¼–ç ä¸æ¥æ”¶ç«¯è§£ç ï¼Œä»è€Œæœ‰æ•ˆè¿‡æ»¤å…±å­˜çš„çª„å¸¦å¹²æ‰°ã€‚é€šè¿‡å¯¹ 5G CP-OFDM å¹²æ‰°åœ¨ Walsh åŸŸæ˜ å°„å…³ç³»çš„åˆ†æï¼Œç ”ç©¶è¯†åˆ«äº†å®ç°æœ€é«˜æŠ‘åˆ¶å¢ç›Šçš„ä¼ è¾“é¢‘ç‡ä¸é‡‡æ ·ç‡æœ€ä¼˜æ¯”ä¾‹ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨ä¿æŒä½ block error rate (BLER) çš„å‰æä¸‹ï¼Œè¯¥è‡ªåŠ¨ç¼–ç å™¨å¯å®ç°é«˜è¾¾ 12 dB çš„ ICI æŠ‘åˆ¶æ•ˆæœã€‚è¿™é¡¹å·¥ä½œä¸º UWB ç³»ç»Ÿåœ¨å¤æ‚é¢‘è°±ç¯å¢ƒä¸‹çš„é²æ£’é€šä¿¡æä¾›äº†é‡è¦çš„æ–¹æ³•è®ºæ”¯æŒã€‚",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG",
        "cs.NI"
      ],
      "primary_category": "eess.SP",
      "comment": "This preprint was submitted to The 2026 EuCNC & 6G Summit",
      "pdf_url": "https://arxiv.org/pdf/2601.11713v1",
      "published_date": "2026-01-16 19:00:52 UTC",
      "updated_date": "2026-01-16 19:00:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:55:36.848443+00:00"
    },
    {
      "arxiv_id": "2601.11702v1",
      "title": "PASTA: A Scalable Framework for Multi-Policy AI Compliance Evaluation",
      "title_zh": "PASTAï¼šé¢å‘å¤šé¡¹äººå·¥æ™ºèƒ½æ”¿ç­–åˆè§„æ€§è¯„ä¼°çš„å¯æ‰©å±•æ¡†æ¶",
      "authors": [
        "Yu Yang",
        "Ig-Jae Kim",
        "Dongwook Yoon"
      ],
      "abstract": "AI compliance is becoming increasingly critical as AI systems grow more powerful and pervasive. Yet the rapid expansion of AI policies creates substantial burdens for resource-constrained practitioners lacking policy expertise. Existing approaches typically address one policy at a time, making multi-policy compliance costly. We present PASTA, a scalable compliance tool integrating four innovations: (1) a comprehensive model-card format supporting descriptive inputs across development stages; (2) a policy normalization scheme; (3) an efficient LLM-powered pairwise evaluation engine with cost-saving strategies; and (4) an interface delivering interpretable evaluations via compliance heatmaps and actionable recommendations. Expert evaluation shows PASTA's judgments closely align with human experts ($Ï\\geq .626$). The system evaluates five major policies in under two minutes at approximately \\$3. A user study (N = 12) confirms practitioners found outputs easy-to-understand and actionable, introducing a novel framework for scalable automated AI governance.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†PASTAï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨å®ç°Multi-Policy AI Compliance Evaluationï¼ˆå¤šæ”¿ç­–AIåˆè§„æ€§è¯„ä¼°ï¼‰çš„å¯æ‰©å±•æ¡†æ¶ï¼Œä»¥è§£å†³ä»ä¸šè€…åœ¨é¢å¯¹æ—¥ç›Šå¢å¤šçš„AIæ”¿ç­–æ—¶ç¼ºä¹ä¸“ä¸šçŸ¥è¯†ä¸”è¯„ä¼°æˆæœ¬é«˜æ˜‚çš„é—®é¢˜ã€‚è¯¥æ¡†æ¶é›†æˆäº†å››é¡¹æ ¸å¿ƒåˆ›æ–°ï¼šä¸€ç§æ”¯æŒè·¨å¼€å‘é˜¶æ®µæè¿°æ€§è¾“å…¥çš„å…¨é¢Model-cardæ ¼å¼ï¼Œä¸€å¥—Policy normalizationï¼ˆæ”¿ç­–æ ‡å‡†åŒ–ï¼‰æ–¹æ¡ˆï¼Œä¸€ä¸ªé«˜æ•ˆä¸”å…·æˆæœ¬æ•ˆç›Šçš„åŸºäºLLMï¼ˆå¤§è¯­è¨€æ¨¡å‹ï¼‰çš„Pairwise evaluation engineï¼ˆæˆå¯¹è¯„ä¼°å¼•æ“ï¼‰ï¼Œä»¥åŠä¸€ä¸ªæä¾›Compliance heatmapsï¼ˆåˆè§„çƒ­å›¾ï¼‰å’ŒActionable recommendationsï¼ˆå¯è¡Œæ€§å»ºè®®ï¼‰çš„å¯è§£é‡Šç•Œé¢ã€‚ä¸“å®¶è¯„ä¼°è¡¨æ˜ï¼ŒPASTAçš„åˆ¤æ–­ä¸äººç±»ä¸“å®¶é«˜åº¦ä¸€è‡´ï¼ˆ$\\rho \\geq .626$ï¼‰ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥ç³»ç»Ÿèƒ½åœ¨ä¸åˆ°ä¸¤åˆ†é’Ÿå†…ä»¥çº¦3ç¾å…ƒçš„æˆæœ¬å®Œæˆå¯¹äº”é¡¹ä¸»è¦æ”¿ç­–çš„è¯„ä¼°ã€‚ç”¨æˆ·ç ”ç©¶è¿›ä¸€æ­¥è¯å®ï¼Œä»ä¸šè€…è®¤ä¸ºå…¶è¾“å‡ºæ˜“äºç†è§£ä¸”å…·å¤‡å¯æ“ä½œæ€§ï¼Œä¸ºå®ç°å¯æ‰©å±•çš„è‡ªåŠ¨åŒ–AI Governanceï¼ˆAIæ²»ç†ï¼‰æä¾›äº†æ–°é¢–çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "28 pages, 7 figures",
      "pdf_url": "https://arxiv.org/pdf/2601.11702v1",
      "published_date": "2026-01-16 18:56:39 UTC",
      "updated_date": "2026-01-16 18:56:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:55:32.663931+00:00"
    },
    {
      "arxiv_id": "2601.11517v1",
      "title": "Do explanations generalize across large reasoning models?",
      "title_zh": "è§£é‡Šåœ¨å¤§å‹æ¨ç†æ¨¡å‹é—´æ˜¯å¦å…·æœ‰æ³›åŒ–æ€§ï¼Ÿ",
      "authors": [
        "Koyena Pal",
        "David Bau",
        "Chandan Singh"
      ],
      "abstract": "Large reasoning models (LRMs) produce a textual chain of thought (CoT) in the process of solving a problem, which serves as a potentially powerful tool to understand the problem by surfacing a human-readable, natural-language explanation. However, it is unclear whether these explanations generalize, i.e. whether they capture general patterns about the underlying problem rather than patterns which are esoteric to the LRM. This is a crucial question in understanding or discovering new concepts, e.g. in AI for science. We study this generalization question by evaluating a specific notion of generalizability: whether explanations produced by one LRM induce the same behavior when given to other LRMs. We find that CoT explanations often exhibit this form of generalization (i.e. they increase consistency between LRMs) and that this increased generalization is correlated with human preference rankings and post-training with reinforcement learning. We further analyze the conditions under which explanations yield consistent answers and propose a straightforward, sentence-level ensembling strategy that improves consistency. Taken together, these results prescribe caution when using LRM explanations to yield new insights and outline a framework for characterizing LRM explanation generalization.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§æ¨ç†æ¨¡å‹ (Large Reasoning Models) ç”Ÿæˆçš„é“¾å¼æ€ç»´ (Chain of Thought) è§£é‡Šæ˜¯å¦å…·æœ‰æ³›åŒ–æ€§ï¼Œå³ä¸€ä¸ªæ¨¡å‹äº§ç”Ÿçš„è§£é‡Šæ˜¯å¦èƒ½åœ¨å…¶ä»–æ¨¡å‹ä¸­è¯±å¯¼å‡ºä¸€è‡´çš„è¡Œä¸ºã€‚é€šè¿‡è¯„ä¼°ä¸åŒæ¨¡å‹é—´çš„è¡Œä¸ºä¸€è‡´æ€§ï¼Œä½œè€…å‘ç°è¿™ç§è§£é‡Šå±‚é¢çš„æ³›åŒ–ç°è±¡æ™®éå­˜åœ¨ï¼Œä¸”å…¶ä¸€è‡´æ€§çš„æå‡ä¸äººç±»åå¥½æ’åä»¥åŠå¼ºåŒ–å­¦ä¹  (Reinforcement Learning) çš„åè®­ç»ƒè¿‡ç¨‹æ˜¾è‘—ç›¸å…³ã€‚ç ”ç©¶è¿›ä¸€æ­¥åˆ†æäº†å½±å“è§£é‡Šä¸€è‡´æ€§çš„å…·ä½“æ¡ä»¶ï¼Œå¹¶æå‡ºäº†ä¸€ç§æœ‰æ•ˆçš„å¥å­çº§é›†æˆç­–ç•¥ (Ensembling Strategy) æ¥è¿›ä¸€æ­¥ä¼˜åŒ–æ¨¡å‹é—´çš„ä¸€è‡´è¡¨ç°ã€‚è¿™äº›ç ”ç©¶ç»“æœä¸ºè¯„ä¼°æ¨¡å‹è§£é‡Šçš„å¯é æ€§æä¾›äº†é‡è¦çš„ç†è®ºæ¡†æ¶ï¼ŒåŒæ—¶ä¹Ÿæé†’ç ”ç©¶è€…åœ¨åˆ©ç”¨è¿™äº›è§£é‡Šè·å–æ–°ç§‘å­¦è§è§£æ—¶åº”ä¿æŒè°¨æ…ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11517v1",
      "published_date": "2026-01-16 18:55:29 UTC",
      "updated_date": "2026-01-16 18:55:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:55:33.862505+00:00"
    },
    {
      "arxiv_id": "2601.11516v2",
      "title": "Building Production-Ready Probes For Gemini",
      "title_zh": "ä¸º Gemini æ„å»ºç”Ÿäº§çº§æ¢æµ‹å™¨",
      "authors": [
        "JÃ¡nos KramÃ¡r",
        "Joshua Engels",
        "Zheng Wang",
        "Bilal Chughtai",
        "Rohin Shah",
        "Neel Nanda",
        "Arthur Conmy"
      ],
      "abstract": "Frontier language model capabilities are improving rapidly. We thus need stronger mitigations against bad actors misusing increasingly powerful systems. Prior work has shown that activation probes may be a promising misuse mitigation technique, but we identify a key remaining challenge: probes fail to generalize under important production distribution shifts. In particular, we find that the shift from short-context to long-context inputs is difficult for existing probe architectures. We propose several new probe architectures that handle this long-context distribution shift.\n  We evaluate these probes in the cyber-offensive domain, testing their robustness against various production-relevant distribution shifts, including multi-turn conversations, long context prompts, and adaptive red teaming. Our results demonstrate that while our novel architectures address context length, a combination of architecture choice and training on diverse distributions is required for broad generalization. Additionally, we show that pairing probes with prompted classifiers achieves optimal accuracy at a low cost due to the computational efficiency of probes.\n  These findings have informed the successful deployment of misuse mitigation probes in user-facing instances of Gemini, Google's frontier language model. Finally, we find early positive results using AlphaEvolve to automate improvements in both probe architecture search and adaptive red teaming, showing that automating some AI safety research is already possible.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å‰æ²¿è¯­è¨€æ¨¡å‹åœ¨åº”å¯¹æ¶æ„è¡Œä¸ºè€…æ»¥ç”¨æ—¶é¢ä¸´çš„æŒ‘æˆ˜ï¼Œæ¢è®¨äº†æ¿€æ´»æ¢é’ˆ(Activation Probes)ä½œä¸ºç¼“è§£æŠ€æœ¯åœ¨ç”Ÿäº§ç¯å¢ƒåˆ†å¸ƒåç§»(Production Distribution Shifts)ä¸‹çš„å±€é™æ€§ã€‚ç ”ç©¶å‘ç°ç°æœ‰æ¢é’ˆæ¶æ„åœ¨ä»çŸ­ä¸Šä¸‹æ–‡å‘é•¿ä¸Šä¸‹æ–‡(Long-context)è¾“å…¥è¿‡æ¸¡æ—¶éš¾ä»¥æ³›åŒ–ï¼Œä¸ºæ­¤æå‡ºäº†èƒ½å¤Ÿå¤„ç†é•¿ä¸Šä¸‹æ–‡åˆ†å¸ƒåç§»çš„æ–°å‹æ¢é’ˆæ¶æ„ã€‚åœ¨ç½‘ç»œæ”»å‡»(Cyber-offensive)é¢†åŸŸï¼Œç ”ç©¶è€…æµ‹è¯•äº†æ¢é’ˆé’ˆå¯¹å¤šè½®å¯¹è¯ã€é•¿ä¸Šä¸‹æ–‡æç¤ºå’Œè‡ªé€‚åº”çº¢é˜Ÿæµ‹è¯•(Adaptive Red Teaming)çš„é²æ£’æ€§ã€‚ç»“æœè¡¨æ˜ï¼Œå®ç°å¹¿æ³›æ³›åŒ–ä¸ä»…éœ€è¦ä¼˜åŒ–çš„æ¶æ„ï¼Œè¿˜éœ€ç»“åˆå¤šæ ·åŒ–åˆ†å¸ƒçš„è®­ç»ƒï¼Œä¸”å°†æ¢é’ˆä¸æç¤ºåˆ†ç±»å™¨(Prompted Classifiers)ç»“åˆå¯åœ¨æä½æˆæœ¬ä¸‹è¾¾åˆ°æœ€ä¼˜å‡†ç¡®ç‡ã€‚è¯¥æˆæœå·²æˆåŠŸåº”ç”¨äºGoogleçš„å‰æ²¿è¯­è¨€æ¨¡å‹Geminiçš„æ»¥ç”¨ç¼“è§£ç³»ç»Ÿä¸­ï¼Œä¸ºç”¨æˆ·ä¾§çš„å®‰å…¨éƒ¨ç½²æä¾›äº†æ”¯æŒã€‚æ­¤å¤–ï¼Œç ”ç©¶å±•ç¤ºäº†åˆ©ç”¨AlphaEvolveè‡ªåŠ¨åŒ–æ”¹è¿›æ¢é’ˆæ¶æ„æœç´¢å’Œè‡ªé€‚åº”çº¢é˜Ÿæµ‹è¯•çš„æ½œåŠ›ï¼Œè¯æ˜äº†è‡ªåŠ¨åŒ–äººå·¥æ™ºèƒ½å®‰å…¨(AI Safety)ç ”ç©¶çš„å¯è¡Œæ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "v2 (minor typo fixes)",
      "pdf_url": "https://arxiv.org/pdf/2601.11516v2",
      "published_date": "2026-01-16 18:54:29 UTC",
      "updated_date": "2026-01-19 16:05:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:55:42.578412+00:00"
    },
    {
      "arxiv_id": "2601.11700v1",
      "title": "Telling Human and Machine Handwriting Apart",
      "title_zh": "åŒºåˆ†äººç±»ä¸æœºå™¨æ‰‹å†™",
      "authors": [
        "Luis A. Leiva",
        "Moises Diaz",
        "Nuwan T. Attygalle",
        "Miguel A. Ferrer",
        "Rejean Plamondon"
      ],
      "abstract": "Handwriting movements can be leveraged as a unique form of behavioral biometrics, to verify whether a real user is operating a device or application. This task can be framed as a reverse Turing test in which a computer has to detect if an input instance has been generated by a human or artificially. To tackle this task, we study ten public datasets of handwritten symbols (isolated characters, digits, gestures, pointing traces, and signatures) that are artificially reproduced using seven different synthesizers, including, among others, the Kinematic Theory (Sigma h model), generative adversarial networks, Transformers, and Diffusion models. We train a shallow recurrent neural network that achieves excellent performance (98.3 percent Area Under the ROC Curve (AUC) score and 1.4 percent equal error rate on average across all synthesizers and datasets) using nonfeaturized trajectory data as input. In few-shot settings, we show that our classifier achieves such an excellent performance when trained on just 10 percent of the data, as evaluated on the remaining 90% of the data as a test set. We further challenge our classifier in out-of-domain settings, and observe very competitive results as well. Our work has implications for computerized systems that need to verify human presence, and adds an additional layer of security to keep attackers at bay.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¦‚ä½•åŒºåˆ†äººç±»æ‰‹å†™ä¸æœºå™¨ç”Ÿæˆçš„ç¬”è¿¹ï¼Œå°†å…¶å®šä¹‰ä¸ºä¸€ç§éªŒè¯ç”¨æˆ·çœŸå®æ€§çš„è¡Œä¸ºç”Ÿç‰©è¯†åˆ«æŠ€æœ¯åŠé€†å‘å›¾çµæµ‹è¯•(reverse Turing test)ã€‚ä½œè€…åˆ©ç”¨åä¸ªåŒ…å«å­—ç¬¦ã€æ‰‹åŠ¿å’Œç­¾åçš„å…¬å…±æ•°æ®é›†ï¼Œç»“åˆè¿åŠ¨å­¦ç†è®º(Kinematic Theory)ã€ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ(GANs)ã€Transformerså’Œæ‰©æ•£æ¨¡å‹(Diffusion models)ç­‰ä¸ƒç§åˆæˆæŠ€æœ¯ï¼Œå¯¹äººç±»ä¸æœºå™¨ç¬”è¿¹è¿›è¡Œäº†ç³»ç»Ÿæ€§ç ”ç©¶ã€‚ç ”ç©¶æå‡ºäº†ä¸€ç§ç›´æ¥ä»¥éç‰¹å¾åŒ–è½¨è¿¹æ•°æ®ä½œä¸ºè¾“å…¥çš„æµ…å±‚å¾ªç¯ç¥ç»ç½‘ç»œ(shallow recurrent neural network)ï¼Œåœ¨å¤šé¡¹æµ‹è¯•ä¸­å®ç°äº†98.3%çš„æ›²çº¿ä¸‹é¢ç§¯(AUC)å’Œ1.4%çš„å¹³å‡ç­‰é”™è¯¯ç‡(EER)ã€‚å®éªŒè¿›ä¸€æ­¥è¯æ˜ï¼Œè¯¥åˆ†ç±»å™¨åœ¨ä»…ä½¿ç”¨10%æ•°æ®çš„å°‘æ ·æœ¬(few-shot)åœºæ™¯ä»¥åŠè·¨é¢†åŸŸ(out-of-domain)è®¾ç½®ä¸‹ä¾ç„¶ä¿æŒå“è¶Šæ€§èƒ½ã€‚è¿™é¡¹å·¥ä½œå¯¹äºå¢å¼ºè®¡ç®—æœºç³»ç»Ÿçš„å®‰å…¨æ€§ã€ç¡®ä¿äººç±»å­˜åœ¨éªŒè¯ä»¥åŠæŠµå¾¡è‡ªåŠ¨åŒ–æ”»å‡»å…·æœ‰é‡è¦æ„ä¹‰ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11700v1",
      "published_date": "2026-01-16 18:45:16 UTC",
      "updated_date": "2026-01-16 18:45:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:55:38.756692+00:00"
    },
    {
      "arxiv_id": "2601.11505v1",
      "title": "MetaboNet: The Largest Publicly Available Consolidated Dataset for Type 1 Diabetes Management",
      "title_zh": "MetaboNetï¼šè§„æ¨¡æœ€å¤§çš„1å‹ç³–å°¿ç—…ç®¡ç†å…¬å¼€æ•´åˆæ•°æ®é›†",
      "authors": [
        "Miriam K. Wolff",
        "Peter Calhoun",
        "Eleonora Maria Aiello",
        "Yao Qin",
        "Sam F. Royston"
      ],
      "abstract": "Progress in Type 1 Diabetes (T1D) algorithm development is limited by the fragmentation and lack of standardization across existing T1D management datasets. Current datasets differ substantially in structure and are time-consuming to access and process, which impedes data integration and reduces the comparability and generalizability of algorithmic developments. This work aims to establish a unified and accessible data resource for T1D algorithm development. Multiple publicly available T1D datasets were consolidated into a unified resource, termed the MetaboNet dataset. Inclusion required the availability of both continuous glucose monitoring (CGM) data and corresponding insulin pump dosing records. Additionally, auxiliary information such as reported carbohydrate intake and physical activity was retained when present. The MetaboNet dataset comprises 3135 subjects and 1228 patient-years of overlapping CGM and insulin data, making it substantially larger than existing standalone benchmark datasets. The resource is distributed as a fully public subset available for immediate download at https://metabo-net.org/ , and with a Data Use Agreement (DUA)-restricted subset accessible through their respective application processes. For the datasets in the latter subset, processing pipelines are provided to automatically convert the data into the standardized MetaboNet format. A consolidated public dataset for T1D research is presented, and the access pathways for both its unrestricted and DUA-governed components are described. The resulting dataset covers a broad range of glycemic profiles and demographics and thus can yield more generalizable algorithmic performance than individual datasets.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ Type 1 Diabetes (T1D) ç®¡ç†æ•°æ®ä¸­å­˜åœ¨çš„ç¢ç‰‡åŒ–å’Œç¼ºä¹æ ‡å‡†åŒ–é—®é¢˜ï¼Œæ„å»ºäº†ç›®å‰è§„æ¨¡æœ€å¤§çš„å…¬å…±æ•´åˆæ•°æ®é›† MetaboNetã€‚è¯¥æ•°æ®é›†é€šè¿‡æ•´åˆå¤šä¸ªå…¬å¼€èµ„æºï¼Œç»Ÿä¸€äº† Continuous Glucose Monitoring (CGM) æ•°æ®ä¸èƒ°å²›ç´ æ³µç»™è¯è®°å½•ï¼Œå¹¶ä¿ç•™äº†ç¢³æ°´åŒ–åˆç‰©æ‘„å…¥å’Œä½“åŠ›æ´»åŠ¨ç­‰è¾…åŠ©ä¿¡æ¯ã€‚MetaboNet æ¶µç›–äº† 3135 åå—è¯•è€…å’Œç´¯è®¡ 1228 ä¸ªç—…äººå¹´çš„é‡å æ•°æ®ï¼Œå…¶è§„æ¨¡æ˜¾è‘—ä¼˜äºç°æœ‰çš„ç‹¬ç«‹åŸºå‡†æ•°æ®é›†ã€‚ç ”ç©¶å›¢é˜Ÿä¸ä»…å‘å¸ƒäº†å¯ç›´æ¥ä¸‹è½½çš„å®Œå…¨å…¬å¼€å­é›†ï¼Œè¿˜é’ˆå¯¹å— Data Use Agreement (DUA) é™åˆ¶çš„å­é›†æä¾›äº†è‡ªåŠ¨æ ¼å¼è½¬æ¢ç®¡é“ã€‚è¯¥æ•°æ®é›†è¦†ç›–äº†å¹¿æ³›çš„è¡€ç³–ç‰¹å¾å’Œäººå£ç»Ÿè®¡å­¦åˆ†å¸ƒï¼Œæœ‰æ•ˆè§£å†³äº†æ•°æ®é›†æˆéš¾é¢˜ï¼Œä¸ºæå‡ç³–å°¿ç—…ç®¡ç†ç®—æ³•çš„é€šç”¨æ€§å’Œå¯æ¯”æ€§å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SY",
        "q-bio.QM"
      ],
      "primary_category": "cs.LG",
      "comment": "22 pages, 5 figures, 7 supplementary figures, submitted to JDST",
      "pdf_url": "https://arxiv.org/pdf/2601.11505v1",
      "published_date": "2026-01-16 18:38:33 UTC",
      "updated_date": "2026-01-16 18:38:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:56:01.817732+00:00"
    },
    {
      "arxiv_id": "2601.11496v1",
      "title": "The Poisoned Apple Effect: Strategic Manipulation of Mediated Markets via Technology Expansion of AI Agents",
      "title_zh": "æ¯’è‹¹æœæ•ˆåº”ï¼šé€šè¿‡ AI æ™ºèƒ½ä½“æŠ€æœ¯æ‰©å¼ å¯¹ä¸­ä»‹å¸‚åœºçš„ç­–ç•¥æ€§æ“çºµ",
      "authors": [
        "Eilam Shapira",
        "Roi Reichart",
        "Moshe Tennenholtz"
      ],
      "abstract": "The integration of AI agents into economic markets fundamentally alters the landscape of strategic interaction. We investigate the economic implications of expanding the set of available technologies in three canonical game-theoretic settings: bargaining (resource division), negotiation (asymmetric information trade), and persuasion (strategic information transmission). We find that simply increasing the choice of AI delegates can drastically shift equilibrium payoffs and regulatory outcomes, often creating incentives for regulators to proactively develop and release technologies. Conversely, we identify a strategic phenomenon termed the \"Poisoned Apple\" effect: an agent may release a new technology, which neither they nor their opponent ultimately uses, solely to manipulate the regulator's choice of market design in their favor. This strategic release improves the releaser's welfare at the expense of their opponent and the regulator's fairness objectives. Our findings demonstrate that static regulatory frameworks are vulnerable to manipulation via technology expansion, necessitating dynamic market designs that adapt to the evolving landscape of AI capabilities.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å°† AI Agents å¼•å…¥ç»æµå¸‚åœºåï¼ŒæŠ€æœ¯æ‰©å±•å¦‚ä½•ä»æ ¹æœ¬ä¸Šæ”¹å˜åšå¼ˆä¸­çš„ç­–ç•¥äº’åŠ¨ã€‚ä½œè€…åœ¨è®®ä»·ï¼ˆbargainingï¼‰ã€è°ˆåˆ¤ï¼ˆnegotiationï¼‰å’ŒåŠè¯´ï¼ˆpersuasionï¼‰è¿™ä¸‰ä¸ªç»å…¸çš„åšå¼ˆè®ºåœºæ™¯ä¸­ï¼Œç ”ç©¶äº†å¢åŠ å¯ç”¨æŠ€æœ¯æ‰€å¸¦æ¥çš„ç»æµå½±å“ã€‚ç ”ç©¶å‘ç°ï¼Œå•çº¯å¢åŠ  AI ä»£ç†çš„é€‰æ‹©å°±èƒ½æ˜¾è‘—æ”¹å˜å‡è¡¡æ”¶ç›Šï¼ˆequilibrium payoffsï¼‰å’Œç›‘ç®¡ç»“æœï¼Œç”šè‡³ä¿ƒä½¿ç›‘ç®¡è€…ä¸»åŠ¨å¼€å‘æ–°æŠ€æœ¯ã€‚å…³é”®çš„å‘ç°æ˜¯æ‰€è°“çš„â€œæ¯’è‹¹æœâ€ï¼ˆPoisoned Appleï¼‰æ•ˆåº”ï¼Œå³å‚ä¸è€…å¯èƒ½å‘å¸ƒä¸€ç§åŒæ–¹æœ€ç»ˆéƒ½ä¸ä½¿ç”¨çš„æŠ€æœ¯ï¼Œä»…ä»¥æ­¤æ“çºµç›‘ç®¡æœºæ„çš„å¸‚åœºè®¾è®¡ã€‚è¿™ç§ç­–ç•¥æ€§å‘å¸ƒæå‡äº†å‘å¸ƒè€…çš„ç¦åˆ©ï¼Œå´æŸå®³äº†å¯¹æ‰‹çš„åˆ©ç›Šå’Œç›‘ç®¡å…¬å¹³ã€‚ç ”ç©¶æœ€åæŒ‡å‡ºï¼Œé™æ€ç›‘ç®¡æ¡†æ¶åœ¨æŠ€æœ¯æ‰©å¼ é¢å‰æå…¶è„†å¼±ï¼Œå› æ­¤äºŸéœ€å»ºç«‹èƒ½å¤Ÿé€‚åº” AI ä¸šåŠ¡æ¼”å˜çš„åŠ¨æ€å¸‚åœºè®¾è®¡ã€‚",
      "categories": [
        "cs.GT",
        "cs.AI",
        "cs.CL",
        "cs.MA"
      ],
      "primary_category": "cs.GT",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11496v1",
      "published_date": "2026-01-16 18:18:03 UTC",
      "updated_date": "2026-01-16 18:18:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:56:16.708918+00:00"
    },
    {
      "arxiv_id": "2601.11492v1",
      "title": "BoxMind: Closed-loop AI strategy optimization for elite boxing validated in the 2024 Olympics",
      "title_zh": "BoxMindï¼šé¢å‘ç²¾è‹±æ‹³å‡»çš„é—­ç¯ AI ç­–ç•¥ä¼˜åŒ–åŠ 2024 å¹´å¥¥è¿ä¼šå®æˆ˜éªŒè¯",
      "authors": [
        "Kaiwen Wang",
        "Kaili Zheng",
        "Rongrong Deng",
        "Qingmin Fan",
        "Milin Zhang",
        "Zongrui Li",
        "Xuesi Zhou",
        "Bo Han",
        "Liren Chen",
        "Chenyi Guo",
        "Ji Wu"
      ],
      "abstract": "Competitive sports require sophisticated tactical analysis, yet combat disciplines like boxing remain underdeveloped in AI-driven analytics due to the complexity of action dynamics and the lack of structured tactical representations. To address this, we present BoxMind, a closed-loop AI expert system validated in elite boxing competition. By defining atomic punch events with precise temporal boundaries and spatial and technical attributes, we parse match footage into 18 hierarchical technical-tactical indicators. We then propose a graph-based predictive model that fuses these explicit technical-tactical profiles with learnable, time-variant latent embeddings to capture the dynamics of boxer matchups. Modeling match outcome as a differentiable function of technical-tactical indicators, we turn winning probability gradients into executable tactical adjustments. Experiments show that the outcome prediction model achieves state-of-the-art performance, with 69.8% accuracy on BoxerGraph test set and 87.5% on Olympic matches. Using this predictive model as a foundation, the system generates strategic recommendations that demonstrate proficiency comparable to human experts. BoxMind is validated through a closed-loop deployment during the 2024 Paris Olympics, directly contributing to the Chinese National Team's historic achievement of three gold and two silver medals. BoxMind establishes a replicable paradigm for transforming unstructured video data into strategic intelligence, bridging the gap between computer vision and decision support in competitive sports.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† BoxMindï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨ä¼˜åŒ–ç²¾è‹±æ‹³å‡»æˆ˜æœ¯çš„é—­ç¯ AI ä¸“å®¶ç³»ç»Ÿã€‚è¯¥ç³»ç»Ÿé€šè¿‡å®šä¹‰å…·æœ‰ç²¾ç¡®æ—¶ç©ºå±æ€§çš„åŸå­å‡»æ‰“äº‹ä»¶ï¼Œå°†æ¯”èµ›å½•åƒè§£æä¸º 18 ä¸ªå±‚çº§çš„ technical-tactical æŒ‡æ ‡ã€‚ç ”ç©¶å›¢é˜Ÿè¿›ä¸€æ­¥æå‡ºäº†ä¸€ç§åŸºäº graph-based çš„é¢„æµ‹æ¨¡å‹ï¼Œé€šè¿‡èåˆæ˜¾å¼æˆ˜æœ¯ç‰¹å¾ä¸å¯å­¦ä¹ çš„ time-variant latent embeddings æ¥æ•æ‰æ‹³å‡»å¯¹æŠ—çš„åŠ¨æ€è¿‡ç¨‹ã€‚BoxMind å°†æ¯”èµ›èƒœç‡å»ºæ¨¡ä¸ºæˆ˜æœ¯æŒ‡æ ‡çš„å¯å¾®å‡½æ•°ï¼Œä»è€Œå°†èƒœç‡æ¢¯åº¦è½¬åŒ–ä¸ºå…·ä½“çš„æˆ˜æœ¯è°ƒæ•´å»ºè®®ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥é¢„æµ‹æ¨¡å‹åœ¨ BoxerGraph æµ‹è¯•é›†ä¸Šçš„å‡†ç¡®ç‡ä¸º 69.8%ï¼Œè€Œåœ¨ 2024 å¹´å¥¥è¿ä¼šæ¯”èµ›ä¸­çš„å‡†ç¡®ç‡é«˜è¾¾ 87.5%ã€‚è¯¥ç³»ç»Ÿåœ¨å·´é»å¥¥è¿ä¼šæœŸé—´ä¸ºä¸­å›½å›½å®¶é˜Ÿæä¾›äº†ç›´æ¥çš„å†³ç­–æ”¯æŒï¼ŒåŠ©åŠ›å…¶å–å¾—ä¸‰é‡‘äºŒé“¶çš„å†å²æ€§ä½³ç»©ï¼Œä¸ºç«æŠ€ä½“è‚²ä¸­éç»“æ„åŒ–è§†é¢‘æ•°æ®è½¬åŒ–ä¸ºæˆ˜ç•¥æƒ…æŠ¥æä¾›äº†å¯å¤åˆ¶çš„èŒƒå¼ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11492v1",
      "published_date": "2026-01-16 18:14:46 UTC",
      "updated_date": "2026-01-16 18:14:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:56:15.023407+00:00"
    },
    {
      "arxiv_id": "2601.11479v1",
      "title": "Health Facility Location in Ethiopia: Leveraging LLMs to Integrate Expert Knowledge into Algorithmic Planning",
      "title_zh": "Ethiopia åŒ»ç–—è®¾æ–½é€‰å€ï¼šåˆ©ç”¨ LLMs å°†ä¸“å®¶çŸ¥è¯†æ•´åˆè‡³ç®—æ³•è§„åˆ’",
      "authors": [
        "Yohai Trabelsi",
        "Guojun Xiong",
        "Fentabil Getnet",
        "StÃ©phane Verguet",
        "Milind Tambe"
      ],
      "abstract": "Ethiopia's Ministry of Health is upgrading health posts to improve access to essential services, particularly in rural areas. Limited resources, however, require careful prioritization of which facilities to upgrade to maximize population coverage while accounting for diverse expert and stakeholder preferences. In collaboration with the Ethiopian Public Health Institute and Ministry of Health, we propose a hybrid framework that systematically integrates expert knowledge with optimization techniques. Classical optimization methods provide theoretical guarantees but require explicit, quantitative objectives, whereas stakeholder criteria are often articulated in natural language and difficult to formalize. To bridge these domains, we develop the Large language model and Extended Greedy (LEG) framework. Our framework combines a provable approximation algorithm for population coverage optimization with LLM-driven iterative refinement that incorporates human-AI alignment to ensure solutions reflect expert qualitative guidance while preserving coverage guarantees. Experiments on real-world data from three Ethiopian regions demonstrate the framework's effectiveness and its potential to inform equitable, data-driven health system planning.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŸƒå¡ä¿„æ¯”äºšå«ç”Ÿéƒ¨å‡çº§å†œæ‘åŒ»ç–—ç«™çš„éœ€æ±‚ï¼Œæå‡ºäº† LEG (Large language model and Extended Greedy) æ··åˆæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³èµ„æºæœ‰é™æ¡ä»¶ä¸‹çš„åŒ»ç–—è®¾æ–½é€‰å€ä¼˜åŒ–é—®é¢˜ã€‚ç”±äºä¸“å®¶å’Œåˆ©ç›Šç›¸å…³è€…çš„æ ‡å‡†é€šå¸¸ä»¥è‡ªç„¶è¯­è¨€è¡¨è¾¾ä¸”éš¾ä»¥å½¢å¼åŒ–ï¼Œè¯¥æ¡†æ¶å°†äººå£è¦†ç›–ä¼˜åŒ–çš„è¿‘ä¼¼ç®—æ³•ä¸ Large Language Model (LLM) é©±åŠ¨çš„è¿­ä»£ç²¾ç‚¼ç›¸ç»“åˆã€‚é€šè¿‡å¼•å…¥ Human-AI alignment æŠ€æœ¯ï¼ŒLEG ç¡®ä¿äº†é€‰å€æ–¹æ¡ˆåœ¨æ»¡è¶³ä¸“å®¶å®šæ€§æŒ‡å¯¼çš„åŒæ—¶ï¼Œèƒ½å¤Ÿä¿ç•™äººå£è¦†ç›–ç‡çš„ç†è®ºä¿è¯ã€‚åœ¨åŸƒå¡ä¿„æ¯”äºšä¸‰ä¸ªåœ°åŒºçš„çœŸå®æ•°æ®å®éªŒéªŒè¯äº†è¯¥æ¡†æ¶çš„æœ‰æ•ˆæ€§ï¼Œä¸ºå®ç°å…¬å¹³ã€æ•°æ®é©±åŠ¨çš„å«ç”Ÿç³»ç»Ÿè§„åˆ’æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11479v1",
      "published_date": "2026-01-16 18:02:09 UTC",
      "updated_date": "2026-01-16 18:02:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:56:20.740464+00:00"
    },
    {
      "arxiv_id": "2601.11468v1",
      "title": "Exploring LLM Features in Predictive Process Monitoring for Small-Scale Event-Logs",
      "title_zh": "æ¢ç©¶å°è§„æ¨¡äº‹ä»¶æ—¥å¿—é¢„æµ‹æ€§è¿‡ç¨‹ç›‘æ§ä¸­çš„ LLM ç‰¹å¾",
      "authors": [
        "Alessandro Padella",
        "Massimiliano de Leoni",
        "Marlon Dumas"
      ],
      "abstract": "Predictive Process Monitoring is a branch of process mining that aims to predict the outcome of an ongoing process. Recently, it leveraged machine-and-deep learning architectures. In this paper, we extend our prior LLM-based Predictive Process Monitoring framework, which was initially focused on total time prediction via prompting. The extension consists of comprehensively evaluating its generality, semantic leverage, and reasoning mechanisms, also across multiple Key Performance Indicators. Empirical evaluations conducted on three distinct event logs and across the Key Performance Indicators of Total Time and Activity Occurrence prediction indicate that, in data-scarce settings with only 100 traces, the LLM surpasses the benchmark methods. Furthermore, the experiments also show that the LLM exploits both its embodied prior knowledge and the internal correlations among training traces. Finally, we examine the reasoning strategies employed by the model, demonstrating that the LLM does not merely replicate existing predictive methods but performs higher-order reasoning to generate the predictions.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹(LLM)åœ¨å°è§„æ¨¡äº‹ä»¶æ—¥å¿—çš„é¢„æµ‹è¿‡ç¨‹ç›‘æ§(Predictive Process Monitoring)ä¸­çš„åº”ç”¨ç‰¹å¾ã€‚é€šè¿‡æ‰©å±•åŸæœ‰çš„åŸºäºæç¤ºçš„é¢„æµ‹æ¡†æ¶ï¼Œç ”ç©¶å…¨é¢è¯„ä¼°äº†å…¶åœ¨æ€»æ—¶é—´(Total Time)å’Œæ´»åŠ¨å‘ç”Ÿ(Activity Occurrence)ç­‰å…³é”®ç»©æ•ˆæŒ‡æ ‡(KPI)ä¸‹çš„é€šç”¨æ€§ã€è¯­ä¹‰æ æ†åŠæ¨ç†æœºåˆ¶ã€‚å®è¯è¯„ä¼°ç»“æœæ˜¾ç¤ºï¼Œåœ¨ä»…æœ‰100æ¡è½¨è¿¹çš„æ•°æ®ç¨€ç¼º(Data-scarce)è®¾å®šä¸‹ï¼ŒLLMçš„è¡¨ç°è¶…è¶Šäº†ä¼ ç»Ÿçš„åŸºå‡†æ–¹æ³•ã€‚å®éªŒè¯æ˜ï¼ŒLLMä¸ä»…èƒ½åˆ©ç”¨å…¶å†…åœ¨çš„å…ˆéªŒçŸ¥è¯†(Prior knowledge)ï¼Œè¿˜èƒ½æ•æ‰è®­ç»ƒè½¨è¿¹é—´çš„å†…éƒ¨ç›¸å…³æ€§ã€‚æœ€åï¼Œå¯¹æ¨ç†ç­–ç•¥çš„åˆ†æè¡¨æ˜LLMé€šè¿‡æ‰§è¡Œé«˜é˜¶æ¨ç†(Higher-order reasoning)è€Œéç®€å•æ¨¡ä»¿æ¥ç”Ÿæˆé¢„æµ‹ï¼Œå±•ç¤ºäº†å…¶åœ¨å¤„ç†å¤æ‚ä¸šåŠ¡æµç¨‹ä¸­çš„ç‹¬ç‰¹æ½œåŠ›ã€‚",
      "categories": [
        "cs.AI",
        "cs.IT"
      ],
      "primary_category": "cs.AI",
      "comment": "19 pages, 4 figure, TMIS journal submission",
      "pdf_url": "https://arxiv.org/pdf/2601.11468v1",
      "published_date": "2026-01-16 17:54:55 UTC",
      "updated_date": "2026-01-16 17:54:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:57:22.014180+00:00"
    },
    {
      "arxiv_id": "2601.11464v1",
      "title": "MHA2MLA-VLM: Enabling DeepSeek's Economical Multi-Head Latent Attention across Vision-Language Models",
      "title_zh": "MHA2MLA-VLMï¼šåœ¨è§†è§‰è¯­è¨€æ¨¡å‹ä¸­å®ç° DeepSeek ç»æµå‹å¤šå¤´æ½œåœ¨æ³¨æ„åŠ›æœºåˆ¶",
      "authors": [
        "Xiaoran Fan",
        "Zhichao Sun",
        "Tao Ji",
        "Lixing Shen",
        "Tao Gui"
      ],
      "abstract": "As vision-language models (VLMs) tackle increasingly complex and multimodal tasks, the rapid growth of Key-Value (KV) cache imposes significant memory and computational bottlenecks during inference. While Multi-Head Latent Attention (MLA) offers an effective means to compress the KV cache and accelerate inference, adapting existing VLMs to the MLA architecture without costly pretraining remains largely unexplored. In this work, we present MHA2MLA-VLM, a parameter-efficient and multimodal-aware framework for converting off-the-shelf VLMs to MLA. Our approach features two core techniques: (1) a modality-adaptive partial-RoPE strategy that supports both traditional and multimodal settings by selectively masking nonessential dimensions, and (2) a modality-decoupled low-rank approximation method that independently compresses the visual and textual KV spaces. Furthermore, we introduce parameter-efficient fine-tuning to minimize adaptation cost and demonstrate that minimizing output activation error, rather than parameter distance, substantially reduces performance loss. Extensive experiments on three representative VLMs show that MHA2MLA-VLM restores original model performance with minimal supervised data, significantly reduces KV cache footprint, and integrates seamlessly with KV quantization.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†MHA2MLA-VLMæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³è§†è§‰è¯­è¨€æ¨¡å‹(VLMs)åœ¨å¤„ç†å¤æ‚å¤šæ¨¡æ€ä»»åŠ¡æ—¶ï¼Œå› Key-Value (KV) cacheå¿«é€Ÿå¢é•¿å¯¼è‡´çš„å†…å­˜å’Œè®¡ç®—ç“¶é¢ˆã€‚è¯¥æ¡†æ¶æä¾›äº†ä¸€ç§é«˜æ•ˆæ–¹æ¡ˆï¼Œåœ¨æ— éœ€é«˜æ˜‚é¢„è®­ç»ƒæˆæœ¬çš„å‰æä¸‹ï¼Œå°†ç°æœ‰VLMsè½¬æ¢ä¸ºDeepSeekæå‡ºçš„Multi-Head Latent Attention (MLA)æ¶æ„ï¼Œä»¥å®ç°KV cacheçš„æœ‰æ•ˆå‹ç¼©ã€‚æ ¸å¿ƒæŠ€æœ¯åŒ…æ‹¬ä¸€ç§æ”¯æŒå¤šæ¨¡æ€è®¾ç½®çš„æ¨¡æ€è‡ªé€‚åº”partial-RoPEç­–ç•¥ï¼Œä»¥åŠä¸€ç§ç‹¬ç«‹å‹ç¼©è§†è§‰å’Œæ–‡æœ¬KVç©ºé—´çš„æ¨¡æ€è§£è€¦ä½ç§©è¿‘ä¼¼(low-rank approximation)æ–¹æ³•ã€‚æ­¤å¤–ï¼Œç ”ç©¶å‘ç°é€šè¿‡æœ€å°åŒ–è¾“å‡ºæ¿€æ´»è¯¯å·®è€Œéå‚æ•°è·ç¦»è¿›è¡Œå‚æ•°é«˜æ•ˆå¾®è°ƒï¼Œèƒ½æ˜¾è‘—é™ä½æ¨¡å‹è½¬æ¢å¸¦æ¥çš„æ€§èƒ½æŸå¤±ã€‚å®éªŒè¡¨æ˜ï¼ŒMHA2MLA-VLMåœ¨ä»…éœ€æå°‘é‡ç›‘ç£æ•°æ®çš„æƒ…å†µä¸‹å³å¯æ¢å¤åŸå§‹æ¨¡å‹æ€§èƒ½ï¼Œå¤§å¹…å‡å°‘äº†KV cacheå ç”¨ï¼Œå¹¶èƒ½ä¸KVé‡åŒ–æŠ€æœ¯æ— ç¼é›†æˆã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11464v1",
      "published_date": "2026-01-16 17:45:34 UTC",
      "updated_date": "2026-01-16 17:45:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:57:24.841665+00:00"
    },
    {
      "arxiv_id": "2601.11459v1",
      "title": "Interactive Narrative Analytics: Bridging Computational Narrative Extraction and Human Sensemaking",
      "title_zh": "äº¤äº’å¼å™äº‹åˆ†æï¼šè¿æ¥è®¡ç®—å™äº‹æå–ä¸äººç±»æ„ä¹‰æ„å»º",
      "authors": [
        "Brian Keith"
      ],
      "abstract": "Information overload and misinformation create significant challenges in extracting meaningful narratives from large news collections. This paper defines the nascent field of Interactive Narrative Analytics (INA), which combines computational narrative extraction with interactive visual analytics to support sensemaking. INA approaches enable the interactive exploration of narrative structures through computational methods and visual interfaces that facilitate human interpretation. The field faces challenges in scalability, interactivity, knowledge integration, and evaluation standardization, yet offers promising opportunities across news analysis, intelligence, scientific literature exploration, and social media analysis. Through the combination of computational and human insight, INA addresses complex challenges in narrative sensemaking.",
      "tldr_zh": "è¯¥ç ”ç©¶å®šä¹‰äº† Interactive Narrative Analytics (INA) è¿™ä¸€æ–°å…´é¢†åŸŸï¼Œæ—¨åœ¨åº”å¯¹ä»å¤§è§„æ¨¡æ–°é—»é›†åˆä¸­æå–æœ‰æ„ä¹‰å™äº‹çš„æŒ‘æˆ˜ã€‚INA é€šè¿‡å°† computational narrative extraction ä¸ interactive visual analytics ç›¸ç»“åˆï¼Œæœ‰æ•ˆåœ°æ”¯æŒäº†äººç±»çš„ sensemaking è¿‡ç¨‹ã€‚è¯¥é¢†åŸŸçš„æ–¹æ³•å…è®¸ç”¨æˆ·é€šè¿‡è®¡ç®—æ‰‹æ®µå’Œè§†è§‰ç•Œé¢äº¤äº’å¼åœ°æ¢ç´¢å™äº‹ç»“æ„ï¼Œä»è€Œä¿ƒè¿›äººç±»çš„è§£é‡Šä¸æ´å¯Ÿã€‚å°½ç®¡åœ¨ scalabilityã€interactivityã€knowledge integration å’Œ evaluation standardization æ–¹é¢ä»é¢ä¸´æŒ‘æˆ˜ï¼Œä½† INA åœ¨æ–°é—»åˆ†æã€æƒ…æŠ¥ã€ç§‘å­¦æ–‡çŒ®æ¢ç´¢å’Œç¤¾äº¤åª’ä½“åˆ†æç­‰é¢†åŸŸæä¾›äº†æå…·æ½œåŠ›çš„åº”ç”¨æœºä¼šã€‚é€šè¿‡æ•´åˆè®¡ç®—èƒ½åŠ›ä¸äººç±»æ™ºæ…§ï¼ŒINA ä¸ºè§£å†³å¤æ‚å™äº‹å»ºæ„ä¸­çš„é‡é‡æŒ‘æˆ˜æä¾›äº†ç³»ç»Ÿæ€§çš„è·¯å¾„ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL",
        "cs.CY",
        "cs.IR"
      ],
      "primary_category": "cs.HC",
      "comment": "17 pages, 5 figures, published in IEEE Access as open access paper",
      "pdf_url": "https://arxiv.org/pdf/2601.11459v1",
      "published_date": "2026-01-16 17:34:37 UTC",
      "updated_date": "2026-01-16 17:34:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:57:11.856772+00:00"
    },
    {
      "arxiv_id": "2601.11451v1",
      "title": "PRISM-CAFO: Prior-conditioned Remote-sensing Infrastructure Segmentation and Mapping for CAFOs",
      "title_zh": "PRISM-CAFOï¼šåŸºäºå…ˆéªŒæ¡ä»¶çš„é›†ä¸­å¼åŠ¨ç‰©é¥²å…»åœºé¥æ„ŸåŸºç¡€è®¾æ–½åˆ†å‰²ä¸åˆ¶å›¾",
      "authors": [
        "Oishee Bintey Hoque",
        "Nibir Chandra Mandal",
        "Kyle Luong",
        "Amanda Wilson",
        "Samarth Swarup",
        "Madhav Marathe",
        "Abhijin Adiga"
      ],
      "abstract": "Large-scale livestock operations pose significant risks to human health and the environment, while also being vulnerable to threats such as infectious diseases and extreme weather events. As the number of such operations continues to grow, accurate and scalable mapping has become increasingly important. In this work, we present an infrastructure-first, explainable pipeline for identifying and characterizing Concentrated Animal Feeding Operations (CAFOs) from aerial and satellite imagery. Our method (1) detects candidate infrastructure (e.g., barns, feedlots, manure lagoons, silos) with a domain-tuned YOLOv8 detector, then derives SAM2 masks from these boxes and filters component-specific criteria, (2) extracts structured descriptors (e.g., counts, areas, orientations, and spatial relations) and fuses them with deep visual features using a lightweight spatial cross-attention classifier, and (3) outputs both CAFO type predictions and mask-level attributions that link decisions to visible infrastructure. Through comprehensive evaluation, we show that our approach achieves state-of-the-art performance, with Swin-B+PRISM-CAFO surpassing the best performing baseline by up to 15\\%. Beyond strong predictive performance across diverse U.S. regions, we run systematic gradient--activation analyses that quantify the impact of domain priors and show ho",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† PRISM-CAFOï¼Œä¸€ç§é’ˆå¯¹èˆªç©ºå’Œå«æ˜Ÿå›¾åƒè¯†åˆ«ä¸ç‰¹å¾åŒ–é›†ä¸­å¼åŠ¨ç‰©é¥²å…»ä½œä¸šï¼ˆCAFOsï¼‰çš„åŸºç¡€è®¾æ–½ä¼˜å…ˆã€å¯è§£é‡Šæµç¨‹ã€‚è¯¥æ–¹æ³•é¦–å…ˆåˆ©ç”¨é¢†åŸŸè°ƒä¼˜çš„ YOLOv8 æ£€æµ‹å™¨è¯†åˆ«è°·ä»“ï¼ˆbarnsï¼‰ã€ç²ªæ± ï¼ˆmanure lagoonsï¼‰å’Œé’è´®çª–ï¼ˆsilosï¼‰ç­‰å€™é€‰åŸºç¡€è®¾æ–½ï¼Œå¹¶ç»“åˆ SAM2 ç”Ÿæˆçš„æ©ç è¿›è¡Œç­›é€‰ã€‚é€šè¿‡æå–æ•°é‡ã€é¢ç§¯åŠç©ºé—´å…³ç³»ç­‰ç»“æ„åŒ–æè¿°ç¬¦ï¼Œå¹¶ä½¿ç”¨è½»é‡çº§ç©ºé—´äº¤å‰æ³¨æ„åŠ›ï¼ˆspatial cross-attentionï¼‰æœºåˆ¶å°†å…¶ä¸æ·±åº¦è§†è§‰ç‰¹å¾èåˆï¼Œå®ç°äº†ç²¾å‡†çš„åˆ†ç±»ã€‚ç³»ç»Ÿä¸ä»…èƒ½é¢„æµ‹ CAFO ç±»å‹ï¼Œè¿˜èƒ½æä¾›å°†å†³ç­–ä¸å¯è§åŸºç¡€è®¾æ–½å…³è”çš„æ©ç çº§å½’å› ï¼ˆmask-level attributionsï¼‰ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSwin-B+PRISM-CAFO åœ¨å¤šä¸ªç¾å›½åŒºåŸŸçš„è¡¨ç°ä¼˜å¼‚ï¼Œå‡†ç¡®ç‡æ¯”ç°æœ‰æœ€ä½³åŸºå‡†æ¨¡å‹æé«˜äº† 15%ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶é€šè¿‡ç³»ç»Ÿçš„æ¢¯åº¦æ¿€æ´»åˆ†æï¼ˆgradient-activation analysesï¼‰é‡åŒ–äº†é¢†åŸŸå…ˆéªŒå¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“ï¼Œä¸ºå¤§è§„æ¨¡ç¯å¢ƒç›‘æµ‹æä¾›äº†é«˜æ•ˆä¸”å¯æ‰©å±•çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11451v1",
      "published_date": "2026-01-16 17:16:26 UTC",
      "updated_date": "2026-01-16 17:16:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:56:30.185283+00:00"
    },
    {
      "arxiv_id": "2601.11442v1",
      "title": "Map2Thought: Explicit 3D Spatial Reasoning via Metric Cognitive Maps",
      "title_zh": "Map2Thoughtï¼šåŸºäºåº¦é‡è®¤çŸ¥åœ°å›¾çš„æ˜¾å¼ä¸‰ç»´ç©ºé—´æ¨ç†",
      "authors": [
        "Xiangjun Gao",
        "Zhensong Zhang",
        "Dave Zhenyu Chen",
        "Songcen Xu",
        "Long Quan",
        "Eduardo PÃ©rez-Pellitero",
        "Youngkyoon Jang"
      ],
      "abstract": "We propose Map2Thought, a framework that enables explicit and interpretable spatial reasoning for 3D VLMs. The framework is grounded in two key components: Metric Cognitive Map (Metric-CogMap) and Cognitive Chain-of-Thought (Cog-CoT). Metric-CogMap provides a unified spatial representation by integrating a discrete grid for relational reasoning with a continuous, metric-scale representation for precise geometric understanding. Building upon the Metric-CogMap, Cog-CoT performs explicit geometric reasoning through deterministic operations, including vector operations, bounding-box distances, and occlusion-aware appearance order cues, producing interpretable inference traces grounded in 3D structure. Experimental results show that Map2Thought enables explainable 3D understanding, achieving 59.9% accuracy using only half the supervision, closely matching the 60.9% baseline trained with the full dataset. It consistently outperforms state-of-the-art methods by 5.3%, 4.8%, and 4.0% under 10%, 25%, and 50% training subsets, respectively, on the VSI-Bench.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Map2Thought æ¡†æ¶ï¼Œæ—¨åœ¨ä¸º 3D VLMs æä¾›æ˜¾å¼ä¸”å¯è§£é‡Šçš„ç©ºé—´æ¨ç†èƒ½åŠ›ã€‚è¯¥æ¡†æ¶çš„æ ¸å¿ƒç»„ä»¶åŒ…æ‹¬ Metric-CogMap å’Œ Cog-CoTï¼Œå…¶ä¸­ Metric-CogMap é€šè¿‡èåˆç”¨äºå…³ç³»æ¨ç†çš„ç¦»æ•£ç½‘æ ¼ä¸ç”¨äºç²¾ç¡®å‡ ä½•ç†è§£çš„è¿ç»­åº¦é‡è¡¨ç¤ºï¼Œå®ç°äº†ç»Ÿä¸€çš„ç©ºé—´è¡¨ç¤ºã€‚åŸºäºè¯¥åœ°å›¾ï¼ŒCog-CoT åˆ©ç”¨å‘é‡è¿ç®—ã€è¾¹ç•Œæ¡†è·ç¦»åŠé®æŒ¡æ„ŸçŸ¥é¡ºåºç­‰ç¡®å®šæ€§æ“ä½œæ‰§è¡Œæ˜¾å¼å‡ ä½•æ¨ç†ï¼Œä»è€Œç”Ÿæˆå…·æœ‰ 3D ç»“æ„æ”¯æ’‘çš„å¯è§£é‡Šæ¨ç†è½¨è¿¹ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMap2Thought åœ¨ä»…ä½¿ç”¨ä¸€åŠç›‘ç£æ•°æ®çš„æƒ…å†µä¸‹è¾¾åˆ°äº† 59.9% çš„å‡†ç¡®ç‡ï¼Œæ•ˆèƒ½æ¥è¿‘å…¨é‡è®­ç»ƒçš„åŸºçº¿æ¨¡å‹ã€‚åœ¨ VSI-Bench æµ‹è¯•ä¸­ï¼Œè¯¥æ¡†æ¶åœ¨ 10%ã€25% å’Œ 50% çš„è®­ç»ƒå­é›†ä¸‹å‡æ˜¾è‘—ä¼˜äºç°æœ‰ SOTA æ–¹æ³•ï¼Œæœ€é«˜æå‡è¾¾ 5.3%ã€‚è¿™ç§æ–¹æ³•ä¸ä»…æ˜¾è‘—æå‡äº† 3D ç©ºé—´æ¨ç†çš„å‡†ç¡®æ€§ï¼Œè¿˜é€šè¿‡æ˜¾å¼è¿ç®—å¢å¼ºäº†æ¨¡å‹åœ¨å¤æ‚åœºæ™¯ä¸‹çš„é€æ˜åº¦ä¸æ•°æ®æ•ˆç‡ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11442v1",
      "published_date": "2026-01-16 17:02:46 UTC",
      "updated_date": "2026-01-16 17:02:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:56:40.981527+00:00"
    },
    {
      "arxiv_id": "2601.11441v1",
      "title": "Hierarchical Orthogonal Residual Spread for Precise Massive Editing in Large Language Models",
      "title_zh": "é¢å‘å¤§è¯­è¨€æ¨¡å‹ç²¾å‡†å¤§è§„æ¨¡ç¼–è¾‘çš„å±‚çº§æ­£äº¤æ®‹å·®ä¼ æ’­",
      "authors": [
        "Xiaojie Gu",
        "Guangxu Chen",
        "Yuheng Yang",
        "Jingxin Han",
        "Andi Zhang"
      ],
      "abstract": "Large language models (LLMs) exhibit exceptional performance across various domains, yet they face critical safety concerns. Model editing has emerged as an effective approach to mitigate these issues. Existing model editing methods often focus on optimizing an information matrix that blends new and old knowledge. While effective, these approaches can be computationally expensive and may cause conflicts. In contrast, we shift our attention to Hierarchical Orthogonal Residual SprEad of the information matrix, which reduces noisy gradients and enables more stable edits from a different perspective. We demonstrate the effectiveness of our method HORSE through a clear theoretical comparison with several popular methods and extensive experiments conducted on two datasets across multiple LLMs. The results show that HORSE maintains precise massive editing across diverse scenarios. The code is available at https://github.com/XiaojieGu/HORSE",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹ (LLMs) åœ¨æ¨¡å‹ç¼–è¾‘ä¸­é¢ä¸´çš„è®¡ç®—æˆæœ¬é«˜å’ŒçŸ¥è¯†å†²çªç­‰æŒ‘æˆ˜ï¼Œæå‡ºäº†åä¸º HORSE (Hierarchical Orthogonal Residual SprEad) çš„æ–°æ–¹æ³•ã€‚HORSE é€šè¿‡å°†æ³¨æ„åŠ›è½¬å‘ä¿¡æ¯çŸ©é˜µçš„å±‚çº§æ­£äº¤æ®‹å·®æ‰©å±•ï¼Œæœ‰æ•ˆå‡å°‘äº†æ¢¯åº¦å™ªå£°ï¼Œå¹¶ä»ä¸åŒè§†è§’å®ç°äº†æ›´ç¨³å®šçš„æ¨¡å‹ç¼–è¾‘ã€‚ç ”ç©¶è€…é€šè¿‡ç†è®ºå¯¹æ¯”å’Œåœ¨å¤šä¸ª LLMs åŠä¸¤ä¸ªæ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒï¼ŒéªŒè¯äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒHORSE åœ¨å¤šæ ·åŒ–çš„åœºæ™¯ä¸­å‡èƒ½ä¿æŒç²¾ç¡®çš„å¤§è§„æ¨¡ç¼–è¾‘ (Massive Editing) æ€§èƒ½ã€‚è¯¥ç ”ç©¶çš„ç›¸å…³ä»£ç å·²åœ¨ GitHub ä¸Šå…¬å¼€ï¼Œä¸ºæå‡æ¨¡å‹ç¼–è¾‘çš„ç²¾ç¡®åº¦ä¸ç¨³å®šæ€§æä¾›äº†æ–°çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "ICASSP 2026",
      "pdf_url": "https://arxiv.org/pdf/2601.11441v1",
      "published_date": "2026-01-16 17:02:19 UTC",
      "updated_date": "2026-01-16 17:02:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:56:45.678947+00:00"
    },
    {
      "arxiv_id": "2601.11440v1",
      "title": "GenDA: Generative Data Assimilation on Complex Urban Areas via Classifier-Free Diffusion Guidance",
      "title_zh": "GenDAï¼šåŸºäºæ— åˆ†ç±»å™¨æ‰©æ•£å¼•å¯¼çš„å¤æ‚åŸå¸‚åŒºåŸŸç”Ÿæˆå¼æ•°æ®åŒåŒ–",
      "authors": [
        "Francisco Giral",
        "Ãlvaro Manzano",
        "Ignacio GÃ³mez",
        "Ricardo Vinuesa",
        "Soledad Le Clainche"
      ],
      "abstract": "Urban wind flow reconstruction is essential for assessing air quality, heat dispersion, and pedestrian comfort, yet remains challenging when only sparse sensor data are available. We propose GenDA, a generative data assimilation framework that reconstructs high-resolution wind fields on unstructured meshes from limited observations. The model employs a multiscale graph-based diffusion architecture trained on computational fluid dynamics (CFD) simulations and interprets classifier-free guidance as a learned posterior reconstruction mechanism: the unconditional branch learns a geometry-aware flow prior, while the sensor-conditioned branch injects observational constraints during sampling. This formulation enables obstacle-aware reconstruction and generalization across unseen geometries, wind directions, and mesh resolutions without retraining. We consider both sparse fixed sensors and trajectory-based observations using the same reconstruction procedure. When evaluated against supervised graph neural network (GNN) baselines and classical reduced-order data assimilation methods, GenDA reduces the relative root-mean-square error (RRMSE) by 25-57% and increases the structural similarity index (SSIM) by 23-33% across the tested meshes. Experiments are conducted on Reynolds-averaged Navier-Stokes (RANS) simulations of a real urban neighbourhood in Bristol, United Kingdom, at a characteristic Reynolds number of $\\mathrm{Re}\\approx2\\times10^{7}$, featuring complex building geometry and irregular terrain. The proposed framework provides a scalable path toward generative, geometry-aware data assimilation for environmental monitoring in complex domains.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†GenDAï¼Œä¸€ç§é€šè¿‡Classifier-Free Diffusion Guidanceåœ¨å¤æ‚åŸå¸‚åŒºåŸŸè¿›è¡Œç”Ÿæˆå¼æ•°æ®åŒåŒ–(Generative Data Assimilation)çš„æ¡†æ¶ï¼Œæ—¨åœ¨ä»ç¨€ç–ä¼ æ„Ÿå™¨æ•°æ®ä¸­é‡å»ºé«˜åˆ†è¾¨ç‡é£åœºã€‚è¯¥æ¨¡å‹é‡‡ç”¨åŸºäºå¤šå°ºåº¦å›¾(graph-based)çš„æ‰©æ•£æ¶æ„ï¼Œåœ¨è®¡ç®—æµä½“åŠ¨åŠ›å­¦(CFD)æ¨¡æ‹Ÿæ•°æ®ä¸Šè¿›è¡Œè®­ç»ƒï¼Œå¹¶å°†Classifier-Free Guidanceè§£é‡Šä¸ºä¸€ç§å­¦ä¹ åˆ°çš„åéªŒé‡å»ºæœºåˆ¶ã€‚å…¶ä¸­ï¼Œæ— æ¡ä»¶åˆ†æ”¯å­¦ä¹ å‡ ä½•æ„ŸçŸ¥çš„æµåŠ¨å…ˆéªŒï¼Œè€Œä¼ æ„Ÿå™¨æ¡ä»¶åˆ†æ”¯åœ¨é‡‡æ ·è¿‡ç¨‹ä¸­æ³¨å…¥è§‚æµ‹çº¦æŸï¼Œä»è€Œå®ç°éšœç¢ç‰©æ„ŸçŸ¥çš„é‡å»ºã€‚è¯¥æ¡†æ¶èƒ½å¤Ÿç›´æ¥æ³›åŒ–è‡³æœªè§è¿‡çš„å‡ ä½•å½¢çŠ¶ã€é£å‘å’Œç½‘æ ¼åˆ†è¾¨ç‡ï¼Œä¸”åŒæ—¶æ”¯æŒå›ºå®šä¼ æ„Ÿå™¨å’Œè½¨è¿¹è§‚æµ‹æ•°æ®çš„å¤„ç†ã€‚åœ¨è‹±å›½å¸ƒé‡Œæ–¯æ‰˜çœŸå®åŸå¸‚è¡—åŒºçš„é›·è¯ºå¹³å‡çº³ç»´-æ–¯æ‰˜å…‹æ–¯(RANS)æ¨¡æ‹Ÿå®éªŒä¸­ï¼ŒGenDAç›¸æ¯”äºç›‘ç£å›¾ç¥ç»ç½‘ç»œ(GNN)åŸºçº¿å’Œä¼ ç»Ÿæ•°æ®åŒåŒ–æ–¹æ³•ï¼Œå°†ç›¸å¯¹å‡æ–¹æ ¹è¯¯å·®(RRMSE)é™ä½äº†25-57%ï¼Œå¹¶å°†ç»“æ„ç›¸ä¼¼æ€§(SSIM)æå‡äº†23-33%ã€‚è¯¥ç ”ç©¶ä¸ºå¤æ‚åœ°å½¢ç¯å¢ƒç›‘æµ‹ä¸­çš„å‡ ä½•æ„ŸçŸ¥ç”Ÿæˆå¼æ•°æ®åŒåŒ–æä¾›äº†ä¸€ç§é«˜æ•ˆä¸”å¯æ‰©å±•çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11440v1",
      "published_date": "2026-01-16 17:02:00 UTC",
      "updated_date": "2026-01-16 17:02:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:56:53.034691+00:00"
    },
    {
      "arxiv_id": "2601.11429v1",
      "title": "Relational Linearity is a Predictor of Hallucinations",
      "title_zh": "å…³ç³»çº¿æ€§åº¦æ˜¯å¹»è§‰çš„é¢„æµ‹æŒ‡æ ‡",
      "authors": [
        "Yuetian Lu",
        "Yihong Liu",
        "Hinrich SchÃ¼tze"
      ],
      "abstract": "Hallucination is a central failure mode in large language models (LLMs). We focus on hallucinations of answers to questions like: \"Which instrument did Glenn Gould play?\", but we ask these questions for synthetic entities that are unknown to the model. Surprisingly, we find that medium-size models like Gemma-7B-IT frequently hallucinate, i.e., they have difficulty recognizing that the hallucinated fact is not part of their knowledge. We hypothesize that an important factor in causing these hallucinations is the linearity of the relation: linear relations tend to be stored more abstractly, making it difficult for the LLM to assess its knowledge; the facts of nonlinear relations tend to be stored more directly, making knowledge assessment easier. To investigate this hypothesis, we create SyntHal, a dataset of 6000 synthetic entities for six relations. In our experiments with four models, we determine, for each relation, the hallucination rate on SyntHal and also measure its linearity, using $Î”\\cos$. We find a strong correlation ($r \\in [.78,.82]$) between relational linearity and hallucination rate, providing evidence for our hypothesis that the underlying storage of triples of a relation is a factor in how well a model can self-assess its knowledge. This finding has implications for how to manage hallucination behavior and suggests new research directions for improving the representation of factual knowledge in LLMs.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹(LLMs)ä¸­çš„å¹»è§‰ç°è±¡ï¼Œç‰¹åˆ«æ˜¯æ¨¡å‹åœ¨é¢å¯¹æœªçŸ¥åˆæˆå®ä½“æ—¶éš¾ä»¥è¯†åˆ«è‡ªèº«çŸ¥è¯†ç¼ºå¤±çš„é—®é¢˜ã€‚ä½œè€…æå‡ºäº†å…³ç³»çº¿æ€§(Relational Linearity)æ˜¯å¯¼è‡´å¹»è§‰é‡è¦å› ç´ çš„å‡è®¾ï¼Œè®¤ä¸ºçº¿æ€§å…³ç³»å€¾å‘äºä»¥æ›´æŠ½è±¡çš„æ–¹å¼å­˜å‚¨ï¼Œå¯¼è‡´æ¨¡å‹éš¾ä»¥è¯„ä¼°å…¶çŸ¥è¯†ã€‚ä¸ºéªŒè¯æ­¤å‡è®¾ï¼Œç ”ç©¶è€…åˆ›å»ºäº†åŒ…å«6000ä¸ªåˆæˆå®ä½“çš„SyntHalæ•°æ®é›†ï¼Œå¹¶åˆ©ç”¨$Î”\\cos$æµ‹é‡äº†å››ç§æ¨¡å‹ä¸­ä¸åŒå…³ç³»çš„çº¿æ€§åº¦ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå…³ç³»çº¿æ€§åº¦ä¸å¹»è§‰ç‡ä¹‹é—´å­˜åœ¨æ˜¾è‘—çš„ç›¸å…³æ€§($r \\in [.78,.82]$)ï¼Œè¯æ˜äº†å…³ç³»çš„åº•å±‚å­˜å‚¨æ–¹å¼ä¼šå½±å“æ¨¡å‹çš„çŸ¥è¯†è‡ªè¯„ä¼°èƒ½åŠ›ã€‚è¿™ä¸€å‘ç°ä¸ºç®¡ç†å¹»è§‰è¡Œä¸ºæä¾›äº†æ–°è§è§£ï¼Œå¹¶ä¸ºä¼˜åŒ–LLMsçš„äº‹å®çŸ¥è¯†è¡¨ç¤ºæä¾›äº†æ–°çš„ç ”ç©¶æ–¹å‘ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "11 pages, 4 figures, 8 tables",
      "pdf_url": "https://arxiv.org/pdf/2601.11429v1",
      "published_date": "2026-01-16 16:47:49 UTC",
      "updated_date": "2026-01-16 16:47:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:57:37.843816+00:00"
    },
    {
      "arxiv_id": "2601.11421v1",
      "title": "The Great March 100: 100 Detail-oriented Tasks for Evaluating Embodied AI Agents",
      "title_zh": "The Great March 100ï¼šé¢å‘å…·èº«æ™ºèƒ½ä½“è¯„ä¼°çš„100é¡¹ç»†èŠ‚å¯¼å‘ä»»åŠ¡",
      "authors": [
        "Ziyu Wang",
        "Chenyuan Liu",
        "Yushun Xiang",
        "Runhao Zhang",
        "Qingbo Hao",
        "Hongliang Lu",
        "Houyu Chen",
        "Zhizhong Feng",
        "Kaiyue Zheng",
        "Dehao Ye",
        "Xianchao Zeng",
        "Xinyu Zhou",
        "Boran Wen",
        "Jiaxin Li",
        "Mingyu Zhang",
        "Kecheng Zheng",
        "Qian Zhu",
        "Ran Cheng",
        "Yong-Lu Li"
      ],
      "abstract": "Recently, with the rapid development of robot learning and imitation learning, numerous datasets and methods have emerged. However, these datasets and their task designs often lack systematic consideration and principles. This raises important questions: Do the current datasets and task designs truly advance the capabilities of robotic agents? Do evaluations on a few common tasks accurately reflect the differentiated performance of various methods proposed by different teams and evaluated on different tasks? To address these issues, we introduce the Great March 100 (\\textbf{GM-100}) as the first step towards a robot learning Olympics. GM-100 consists of 100 carefully designed tasks that cover a wide range of interactions and long-tail behaviors, aiming to provide a diverse and challenging set of tasks to comprehensively evaluate the capabilities of robotic agents and promote diversity and complexity in robot dataset task designs. These tasks are developed through systematic analysis and expansion of existing task designs, combined with insights from human-object interaction primitives and object affordances. We collect a large amount of trajectory data on different robotic platforms and evaluate several baseline models. Experimental results demonstrate that the GM-100 tasks are 1) feasible to execute and 2) sufficiently challenging to effectively differentiate the performance of current VLA models. Our data and code are available at https://rhos.ai/research/gm-100.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å½“å‰æœºå™¨äººå­¦ä¹ (robot learning)æ•°æ®é›†åœ¨ä»»åŠ¡è®¾è®¡ä¸Šç¼ºä¹ç³»ç»Ÿæ€§åŸåˆ™çš„é—®é¢˜ï¼Œæå‡ºäº†Great March 100 (GM-100)ï¼Œä½œä¸ºå…¨é¢è¯„ä¼°å…·èº«æ™ºèƒ½(Embodied AI)ä»£ç†èƒ½åŠ›çš„åŸºå‡†æµ‹è¯•ã€‚GM-100åŒ…å«100ä¸ªæ¶µç›–å¹¿æ³›äº¤äº’å’Œé•¿å°¾(long-tail)è¡Œä¸ºçš„ç²¾å¿ƒè®¾è®¡ä»»åŠ¡ï¼Œé€šè¿‡åˆ†æäººç±»ä¸ç‰©ä½“äº¤äº’åŸè¯­(human-object interaction primitives)å’Œç‰©ä½“åŠŸèƒ½ç‰¹æ€§(object affordances)å¯¹ä»»åŠ¡è¿›è¡Œäº†ç³»ç»Ÿæ€§æ‰©å±•ã€‚ç ”ç©¶å›¢é˜Ÿåœ¨ä¸åŒæœºå™¨äººå¹³å°ä¸Šæ”¶é›†äº†å¤§é‡è½¨è¿¹æ•°æ®ï¼Œå¹¶å¯¹å¤šç§åŸºçº¿æ¨¡å‹è¿›è¡Œäº†è¯„ä¼°ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒGM-100çš„ä»»åŠ¡åœ¨ä¿è¯å¯æ‰§è¡Œæ€§çš„åŒæ—¶å…·æœ‰é«˜åº¦æŒ‘æˆ˜æ€§ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåŒºåˆ†å½“å‰è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹(VLA models)çš„æ€§èƒ½å·®å¼‚ã€‚è¯¥å·¥ä½œçš„å¼€å±•ä¸ºæ¨åŠ¨æœºå™¨äººæ•°æ®é›†ä»»åŠ¡è®¾è®¡çš„å¤šæ ·æ€§ä¸å¤æ‚æ€§å¥ å®šäº†åŸºç¡€ï¼Œä¿ƒè¿›äº†æœºå™¨äººé¢†åŸŸçš„ç»¼åˆèƒ½åŠ›è¯„ä¼°ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11421v1",
      "published_date": "2026-01-16 16:42:05 UTC",
      "updated_date": "2026-01-16 16:42:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:57:41.253788+00:00"
    },
    {
      "arxiv_id": "2601.11409v1",
      "title": "Topology-Guaranteed Image Segmentation: Enforcing Connectivity, Genus, and Width Constraints",
      "title_zh": "å…·æœ‰æ‹“æ‰‘ä¿è¯çš„å›¾åƒåˆ†å‰²ï¼šè¿é€šæ€§ã€äºæ ¼åŠå®½åº¦çº¦æŸçš„å¼ºåˆ¶å®ç°",
      "authors": [
        "Wenxiao Li",
        "Xue-Cheng Tai",
        "Jun Liu"
      ],
      "abstract": "Existing research highlights the crucial role of topological priors in image segmentation, particularly in preserving essential structures such as connectivity and genus. Accurately capturing these topological features often requires incorporating width-related information, including the thickness and length inherent to the image structures. However, traditional mathematical definitions of topological structures lack this dimensional width information, limiting methods like persistent homology from fully addressing practical segmentation needs. To overcome this limitation, we propose a novel mathematical framework that explicitly integrates width information into the characterization of topological structures. This method leverages persistent homology, complemented by smoothing concepts from partial differential equations (PDEs), to modify local extrema of upper-level sets. This approach enables the resulting topological structures to inherently capture width properties. We incorporate this enhanced topological description into variational image segmentation models. Using some proper loss functions, we are also able to design neural networks that can segment images with the required topological and width properties. Through variational constraints on the relevant topological energies, our approach successfully preserves essential topological invariants such as connectivity and genus counts, simultaneously ensuring that segmented structures retain critical width attributes, including line thickness and length. Numerical experiments demonstrate the effectiveness of our method, showcasing its capability to maintain topological fidelity while explicitly embedding width characteristics into segmented image structures.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å›¾åƒåˆ†å‰²ä¸­æ‹“æ‰‘å…ˆéªŒç¼ºä¹å®½åº¦ã€åšåº¦å’Œé•¿åº¦ç­‰ç»´åº¦ä¿¡æ¯çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§èƒ½å¤ŸåŒæ—¶å¼ºåˆ¶çº¦æŸè¿é€šæ€§ (Connectivity)ã€äºæ ¼ (Genus) å’Œå®½åº¦ (Width) çš„æ–°å‹æ‹“æ‰‘ä¿è¯å›¾åƒåˆ†å‰²æ¡†æ¶ã€‚è¯¥æ–¹æ³•é€šè¿‡å°†å®½åº¦ä¿¡æ¯æ˜¾å¼é›†æˆåˆ°æ‹“æ‰‘ç»“æ„è¡¨å¾ä¸­ï¼Œå¼¥è¡¥äº†ä¼ ç»ŸæŒä¹…åŒè°ƒ (Persistent Homology) åœ¨å¤„ç†å®é™…åˆ†å‰²éœ€æ±‚æ—¶çš„å±€é™æ€§ã€‚å…·ä½“è€Œè¨€ï¼Œè¯¥æ¡†æ¶ç»“åˆäº†æŒä¹…åŒè°ƒä¸åå¾®åˆ†æ–¹ç¨‹ (PDEs) çš„å¹³æ»‘æ¦‚å¿µï¼Œé€šè¿‡ä¿®æ”¹ä¸Šæ°´å¹³é›†çš„å±€éƒ¨æå€¼ï¼Œä½¿ç”Ÿæˆçš„æ‹“æ‰‘ç»“æ„èƒ½å¤Ÿå†…åœ¨æ•æ‰å®½åº¦å±æ€§ã€‚ç ”ç©¶è€…å°†è¿™ç§å¢å¼ºçš„æ‹“æ‰‘æè¿°å¼•å…¥å˜åˆ†å›¾åƒåˆ†å‰²æ¨¡å‹ï¼Œå¹¶è®¾è®¡äº†ç›¸åº”çš„æŸå¤±å‡½æ•°ï¼Œä½¿ç¥ç»ç½‘ç»œèƒ½å¤Ÿå­¦ä¹ å…·æœ‰ç‰¹å®šæ‹“æ‰‘å’Œå®½åº¦ç‰¹æ€§çš„åˆ†å‰²ç»“æœã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¿æŒè¿é€šæ€§å’Œäºæ ¼è®¡æ•°ç­‰æ‹“æ‰‘ä¸å˜æ€§çš„åŒæ—¶ï¼Œæœ‰æ•ˆç¡®ä¿äº†åˆ†å‰²ç»“æ„ä¿ç•™å…³é”®çš„å®½åº¦å±æ€§ï¼Œå¦‚çº¿æ¡åšåº¦å’Œé•¿åº¦ã€‚æ•°å€¼å®éªŒéªŒè¯äº†è¯¥æ–¹æ¡ˆåœ¨ä¿æŒæ‹“æ‰‘å¿ å®åº¦çš„åŒæ—¶æ˜¾å¼åµŒå…¥å®½åº¦ç‰¹å¾çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11409v1",
      "published_date": "2026-01-16 16:29:48 UTC",
      "updated_date": "2026-01-16 16:29:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:57:46.491919+00:00"
    },
    {
      "arxiv_id": "2601.11400v1",
      "title": "Wetland mapping from sparse annotations with satellite image time series and temporal-aware segment anything model",
      "title_zh": "åŸºäºå«æ˜Ÿå½±åƒæ—¶é—´åºåˆ—ä¸æ—¶åºæ„ŸçŸ¥ä¸‡ç‰©åˆ†å‰²æ¨¡å‹çš„ç¨€ç–æ ‡æ³¨æ¹¿åœ°åˆ¶å›¾",
      "authors": [
        "Shuai Yuan",
        "Tianwu Lin",
        "Shuang Chen",
        "Yu Xia",
        "Peng Qin",
        "Xiangyu Liu",
        "Xiaoqing Xu",
        "Nan Xu",
        "Hongsheng Zhang",
        "Jie Wang",
        "Peng Gong"
      ],
      "abstract": "Accurate wetland mapping is essential for ecosystem monitoring, yet dense pixel-level annotation is prohibitively expensive and practical applications usually rely on sparse point labels, under which existing deep learning models perform poorly, while strong seasonal and inter-annual wetland dynamics further render single-date imagery inadequate and lead to significant mapping errors; although foundation models such as SAM show promising generalization from point prompts, they are inherently designed for static images and fail to model temporal information, resulting in fragmented masks in heterogeneous wetlands. To overcome these limitations, we propose WetSAM, a SAM-based framework that integrates satellite image time series for wetland mapping from sparse point supervision through a dual-branch design, where a temporally prompted branch extends SAM with hierarchical adapters and dynamic temporal aggregation to disentangle wetland characteristics from phenological variability, and a spatial branch employs a temporally constrained region-growing strategy to generate reliable dense pseudo-labels, while a bidirectional consistency regularization jointly optimizes both branches. Extensive experiments across eight global regions of approximately 5,000 km2 each demonstrate that WetSAM substantially outperforms state-of-the-art methods, achieving an average F1-score of 85.58%, and delivering accurate and structurally consistent wetland segmentation with minimal labeling effort, highlighting its strong generalization capability and potential for scalable, low-cost, high-resolution wetland mapping.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† WetSAMï¼Œä¸€ç§åŸºäº SAM çš„æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³æ¹¿åœ°åˆ¶å›¾é¢ä¸´çš„åƒç´ çº§æ ‡æ³¨æˆæœ¬é«˜æ˜‚ã€æ¹¿åœ°åŠ¨æ€å˜åŒ–å¤æ‚ä»¥åŠåŸºç¡€æ¨¡å‹éš¾ä»¥å»ºæ¨¡æ—¶é—´ä¿¡æ¯ç­‰æŒ‘æˆ˜ã€‚WetSAM é‡‡ç”¨åŒåˆ†æ”¯è®¾è®¡ï¼Œé€šè¿‡æ—¶é—´æç¤ºåˆ†æ”¯åˆ©ç”¨å±‚çº§é€‚é…å™¨ (Hierarchical Adapters) å’ŒåŠ¨æ€æ—¶é—´èšåˆ (Dynamic Temporal Aggregation) ä»ç‰©å€™å˜å¼‚ä¸­æå–æ¹¿åœ°ç‰¹å¾ï¼ŒåŒæ—¶åˆ©ç”¨ç©ºé—´åˆ†æ”¯ç”Ÿæˆå—æ—¶é—´çº¦æŸçš„å¯†é›†ä¼ªæ ‡ç­¾ã€‚é€šè¿‡åŒå‘ä¸€è‡´æ€§æ­£åˆ™åŒ– (Bidirectional Consistency Regularization) ååŒä¼˜åŒ–ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿä»…å‡­ç¨€ç–ç‚¹æ ‡æ³¨å®ç°é«˜ç²¾åº¦åˆ†å‰²ã€‚åœ¨å…¨çƒå…«ä¸ªåœ°åŒºçš„å¹¿æ³›å®éªŒè¯æ˜ï¼ŒWetSAM çš„å¹³å‡ F1-score è¾¾åˆ° 85.58%ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰æœ€å…ˆè¿›æ–¹æ³•ã€‚è¯¥ç ”ç©¶ä¸ä»…æå‡äº†æ¹¿åœ°åˆ¶å›¾çš„å‡†ç¡®æ€§ä¸ç»“æ„ä¸€è‡´æ€§ï¼Œè¿˜ä¸ºå¤§è§„æ¨¡ã€ä½æˆæœ¬ã€é«˜åˆ†è¾¨ç‡çš„ç”Ÿæ€ç›‘æµ‹æä¾›äº†æå…·æ½œåŠ›çš„æŠ€æœ¯æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11400v1",
      "published_date": "2026-01-16 16:10:32 UTC",
      "updated_date": "2026-01-16 16:10:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:57:51.455361+00:00"
    },
    {
      "arxiv_id": "2601.11389v1",
      "title": "Hyperparameter Optimization of Constraint Programming Solvers",
      "title_zh": "çº¦æŸç¼–ç¨‹æ±‚è§£å™¨çš„è¶…å‚æ•°ä¼˜åŒ–",
      "authors": [
        "Hedieh Haddad",
        "Thibault Falque",
        "Pierre Talbot",
        "Pascal Bouvry"
      ],
      "abstract": "The performance of constraint programming solvers is highly sensitive to the choice of their hyperparameters. Manually finding the best solver configuration is a difficult, time-consuming task that typically requires expert knowledge. In this paper, we introduce probe and solve algorithm, a novel two-phase framework for automated hyperparameter optimization integrated into the CPMpy library. This approach partitions the available time budget into two phases: a probing phase that explores different sets of hyperparameters using configurable hyperparameter optimization methods, followed by a solving phase where the best configuration found is used to tackle the problem within the remaining time.\n  We implement and compare two hyperparameter optimization methods within the probe and solve algorithm: Bayesian optimization and Hamming distance search. We evaluate the algorithm on two different constraint programming solvers, ACE and Choco, across 114 combinatorial problem instances, comparing their performance against the solver's default configurations.\n  Results show that using Bayesian optimization, the algorithm outperforms the solver's default configurations, improving solution quality for ACE in 25.4% of instances and matching the default performance in 57.9%, and for Choco, achieving superior results in 38.6% of instances. It also consistently surpasses Hamming distance search within the same framework, confirming the advantage of model-based exploration over simple local search. Overall, the probe and solve algorithm offers a practical, resource-aware approach for tuning constraint solvers that yields robust improvements across diverse problem types.",
      "tldr_zh": "Constraint Programming (CP) æ±‚è§£å™¨çš„æ€§èƒ½é«˜åº¦ä¾èµ–äº Hyperparameters çš„é€‰æ‹©ï¼Œä½†äººå·¥æ‰‹åŠ¨é…ç½®å¾€å¾€è€—æ—¶ä¸”éœ€è¦ä¸“å®¶ç»éªŒã€‚è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åä¸º probe and solve algorithm çš„æ–°å‹ä¸¤é˜¶æ®µè‡ªåŠ¨åŒ–è¶…å‚æ•°ä¼˜åŒ–æ¡†æ¶ï¼Œå¹¶å°†å…¶é›†æˆåœ¨ CPMpy åº“ä¸­ã€‚è¯¥æ–¹æ³•å°†æ—¶é—´é¢„ç®—åˆ’åˆ†ä¸ºæ¢æµ‹é˜¶æ®µå’Œæ±‚è§£é˜¶æ®µï¼Œå…ˆé€šè¿‡å¯é…ç½®çš„ä¼˜åŒ–æ–¹æ³•æ¢ç´¢è¶…å‚æ•°ï¼Œéšååˆ©ç”¨æ‰¾åˆ°çš„æœ€ä½³é…ç½®åœ¨å‰©ä½™æ—¶é—´å†…è§£å†³é—®é¢˜ã€‚ç ”ç©¶äººå‘˜åœ¨æ¡†æ¶å†…å®ç°å¹¶å¯¹æ¯”äº† Bayesian optimization å’Œ Hamming distance search ä¸¤ç§æ–¹æ³•ï¼Œå¹¶åœ¨ ACE å’Œ Choco æ±‚è§£å™¨åŠ 114 ä¸ªç»„åˆé—®é¢˜å®ä¾‹ä¸Šè¿›è¡Œäº†æµ‹è¯•ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä½¿ç”¨ Bayesian optimization çš„ç®—æ³•æ˜¾è‘—ä¼˜äºæ±‚è§£å™¨çš„é»˜è®¤é…ç½®ï¼Œåœ¨ ACE å’Œ Choco ä¸Šçš„æ€§èƒ½æå‡æ¯”ä¾‹åˆ†åˆ«è¾¾åˆ° 25.4% å’Œ 38.6%ã€‚è¯¥ç ”ç©¶è¯æ˜äº†åŸºäºæ¨¡å‹çš„æ¢ç´¢ä¼˜äºç®€å•çš„å±€éƒ¨æœç´¢ï¼Œä¸ºçº¦æŸæ±‚è§£å™¨æä¾›äº†ä¸€ç§å®ç”¨ä¸”å…·å¤‡èµ„æºæ„è¯† (Resource-aware) çš„è°ƒä¼˜æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "28 pages, 3 figures. Submitted to Journal of Combinatorial Optimization. Special Issue: Recent applications, models and algorithms in Combinatorial Optimization",
      "pdf_url": "https://arxiv.org/pdf/2601.11389v1",
      "published_date": "2026-01-16 16:02:36 UTC",
      "updated_date": "2026-01-16 16:02:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:58:32.064103+00:00"
    },
    {
      "arxiv_id": "2601.11379v1",
      "title": "Evaluating LLM Behavior in Hiring: Implicit Weights, Fairness Across Groups, and Alignment with Human Preferences",
      "title_zh": "è¯„ä¼°å¤§è¯­è¨€æ¨¡å‹åœ¨æ‹›è˜ä¸­çš„è¡Œä¸ºï¼šéšå«æƒé‡ã€è·¨ç¾¤ä½“å…¬å¹³æ€§ä»¥åŠä¸äººç±»åå¥½çš„å¯¹é½",
      "authors": [
        "Morgane Hoffmann",
        "Emma Jouffroy",
        "Warren Jouanneau",
        "Marc Palyart",
        "Charles Pebereau"
      ],
      "abstract": "General-purpose Large Language Models (LLMs) show significant potential in recruitment applications, where decisions require reasoning over unstructured text, balancing multiple criteria, and inferring fit and competence from indirect productivity signals. Yet, it is still uncertain how LLMs assign importance to each attribute and whether such assignments are in line with economic principles, recruiter preferences or broader societal norms. We propose a framework to evaluate an LLM's decision logic in recruitment, by drawing on established economic methodologies for analyzing human hiring behavior. We build synthetic datasets from real freelancer profiles and project descriptions from a major European online freelance marketplace and apply a full factorial design to estimate how a LLM weighs different match-relevant criteria when evaluating freelancer-project fit. We identify which attributes the LLM prioritizes and analyze how these weights vary across project contexts and demographic subgroups. Finally, we explain how a comparable experimental setup could be implemented with human recruiters to assess alignment between model and human decisions. Our findings reveal that the LLM weighs core productivity signals, such as skills and experience, but interprets certain features beyond their explicit matching value. While showing minimal average discrimination against minority groups, intersectional effects reveal that productivity signals carry different weights between demographic groups.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªè¯„ä¼°é€šç”¨å¤§è¯­è¨€æ¨¡å‹ (LLMs) åœ¨æ‹›è˜å†³ç­–ä¸­é€»è¾‘çš„æ¡†æ¶ï¼Œå€Ÿé‰´äº†åˆ†æäººç±»æ‹›è˜è¡Œä¸ºçš„ç»æµå­¦æ–¹æ³•ã€‚ç ”ç©¶äººå‘˜åˆ©ç”¨æ¬§æ´²åœ¨çº¿è‡ªç”±èŒä¸šå¸‚åœºçš„çœŸå®æ•°æ®æ„å»ºåˆæˆæ•°æ®é›†ï¼Œå¹¶é‡‡ç”¨å…¨æå› è®¾è®¡ (full factorial design) æ¥ä¼°ç®— LLMs åœ¨è¯„ä¼°äººå‘˜ä¸é¡¹ç›®åŒ¹é…åº¦æ—¶å¦‚ä½•æƒè¡¡ä¸åŒçš„æ ‡å‡†ã€‚ç»“æœæ˜¾ç¤ºï¼ŒLLMs èƒ½å¤Ÿä¼˜å…ˆå¤„ç†æŠ€èƒ½å’Œç»éªŒç­‰æ ¸å¿ƒç”Ÿäº§åŠ›ä¿¡å· (productivity signals)ï¼Œä½†å¯¹æŸäº›ç‰¹å¾çš„è§£è¯»è¶…å‡ºäº†å…¶æ˜¾æ€§çš„åŒ¹é…ä»·å€¼ã€‚è™½ç„¶é’ˆå¯¹å°‘æ•°æ—è£”ç¾¤ä½“çš„å¹³å‡æ­§è§†æå°ï¼Œä½†äº¤å‰æ€§æ•ˆåº” (intersectional effects) æ­ç¤ºäº†ç”Ÿäº§åŠ›ä¿¡å·åœ¨ä¸åŒäººå£ç‰¹å¾ç¾¤ä½“ä¹‹é—´çš„æƒé‡åˆ†é…å­˜åœ¨å·®å¼‚ã€‚è¯¥ç ”ç©¶è¿˜æ¢è®¨äº†å¦‚ä½•é€šè¿‡å®éªŒè¯„ä¼°æ¨¡å‹ä¸äººç±»æ‹›è˜è€…å†³ç­–ä¹‹é—´çš„å¯¹é½æƒ…å†µï¼Œä¸ºç†è§£ AI åœ¨æ‹›è˜ä¸­çš„å…¬å¹³æ€§ä¸å†³ç­–æœºåˆ¶æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.SI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11379v1",
      "published_date": "2026-01-16 15:38:03 UTC",
      "updated_date": "2026-01-16 15:38:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:57:53.162681+00:00"
    },
    {
      "arxiv_id": "2601.11369v2",
      "title": "Institutional AI: Governing LLM Collusion in Multi-Agent Cournot Markets via Public Governance Graphs",
      "title_zh": "Institutional AIï¼šåŸºäºå…¬å…±æ²»ç†å›¾çš„å¤šæ™ºèƒ½ä½“å¤è¯ºå¸‚åœº LLM åˆè°‹æ²»ç†",
      "authors": [
        "Marcantonio Bracale Syrnikov",
        "Federico Pierucci",
        "Marcello Galisai",
        "Matteo Prandi",
        "Piercosma Bisconti",
        "Francesco Giarrusso",
        "Olga Sorokoletova",
        "Vincenzo Suriani",
        "Daniele Nardi"
      ],
      "abstract": "Multi-agent LLM ensembles can converge on coordinated, socially harmful equilibria. This paper advances an experimental framework for evaluating Institutional AI, our system-level approach to AI alignment that reframes alignment from preference engineering in agent-space to mechanism design in institution-space. Central to this approach is the governance graph, a public, immutable manifest that declares legal states, transitions, sanctions, and restorative paths; an Oracle/Controller runtime interprets this manifest, attaching enforceable consequences to evidence of coordination while recording a cryptographically keyed, append-only governance log for audit and provenance. We apply the Institutional AI framework to govern the Cournot collusion case documented by prior work and compare three regimes: Ungoverned (baseline incentives from the structure of the Cournot market), Constitutional (a prompt-only policy-as-prompt prohibition implemented as a fixed written anti-collusion constitution, and Institutional (governance-graph-based). Across six model configurations including cross-provider pairs (N=90 runs/condition), the Institutional regime produces large reductions in collusion: mean tier falls from 3.1 to 1.8 (Cohen's d=1.28), and severe-collusion incidence drops from 50% to 5.6%. The prompt-only Constitutional baseline yields no reliable improvement, illustrating that declarative prohibitions do not bind under optimisation pressure. These results suggest that multi-agent alignment may benefit from being framed as an institutional design problem, where governance graphs can provide a tractable abstraction for alignment-relevant collective behavior.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Institutional AIæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¤šæ™ºèƒ½ä½“å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨Cournotå¸‚åœºä¸­å¯èƒ½å½¢æˆçš„å…±è°‹ï¼ˆcollusionï¼‰åŠç”±æ­¤äº§ç”Ÿçš„ç¤¾ä¼šå±å®³ã€‚è¿™ä¸€ç³»ç»Ÿçº§å¯¹é½æ–¹æ³•å°†å¯¹é½é‡å¿ƒä»æ™ºèƒ½ä½“ç©ºé—´çš„åå¥½å·¥ç¨‹ï¼ˆpreference engineeringï¼‰è½¬å‘äº†åˆ¶åº¦ç©ºé—´çš„æœºåˆ¶è®¾è®¡ï¼ˆmechanism designï¼‰ã€‚å…¶æ ¸å¿ƒåœ¨äºæ„å»ºä¸€ç§å…¬å¼€ä¸”ä¸å¯ç¯¡æ”¹çš„æ²»ç†å›¾ï¼ˆgovernance graphï¼‰ï¼Œç”¨äºå£°æ˜åˆæ³•çŠ¶æ€ã€åˆ¶è£æªæ–½å’Œä¿®å¤è·¯å¾„ï¼Œå¹¶ç”±Oracle/Controllerè¿è¡Œæ—¶æ ¹æ®æ²»ç†æ—¥å¿—æ‰§è¡Œå¼ºåˆ¶æ€§åæœã€‚ç ”ç©¶å¯¹æ¯”äº†æ— ç›‘ç®¡ã€åŸºäºæç¤ºè¯çš„å®ªæ³•ï¼ˆConstitutionalï¼‰ä»¥åŠåŸºäºæ²»ç†å›¾çš„åˆ¶åº¦æ¨¡å¼ï¼Œå®éªŒç»“æœæ˜¾ç¤ºInstitutionalæ¨¡å¼æ˜¾è‘—é™ä½äº†å…±è°‹ç¨‹åº¦ï¼Œå¹³å‡çº§åˆ«ä»3.1é™è‡³1.8ï¼Œä¸¥é‡å…±è°‹å‘ç”Ÿç‡ä»50%å¤§å¹…é™è‡³5.6%ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œä»…ä¾é æç¤ºè¯çš„Constitutionalæ¨¡å¼åœ¨ä¼˜åŒ–å‹åŠ›ä¸‹æœªèƒ½äº§ç”Ÿå¯é æ”¹è¿›ï¼Œè¯æ˜äº†å£°æ˜å¼ç¦ä»¤çš„å±€é™æ€§ã€‚è¿™äº›å‘ç°è¡¨æ˜å¤šæ™ºèƒ½ä½“å¯¹é½åº”è¢«è§†ä¸ºåˆ¶åº¦è®¾è®¡é—®é¢˜ï¼Œè€Œæ²»ç†å›¾ä¸ºç®¡ç†å¤æ‚çš„é›†ä½“è¡Œä¸ºæä¾›äº†å¯è¡Œçš„æŠ½è±¡æ‰‹æ®µã€‚",
      "categories": [
        "cs.GT",
        "cs.AI"
      ],
      "primary_category": "cs.GT",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11369v2",
      "published_date": "2026-01-16 15:26:56 UTC",
      "updated_date": "2026-01-20 12:10:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:57:58.952696+00:00"
    },
    {
      "arxiv_id": "2601.11359v1",
      "title": "Think-Clip-Sample: Slow-Fast Frame Selection for Video Understanding",
      "title_zh": "Think-Clip-Sampleï¼šé¢å‘è§†é¢‘ç†è§£çš„å¿«æ…¢å¸§é€‰æ‹©",
      "authors": [
        "Wenhui Tan",
        "Ruihua Song",
        "Jiaze Li",
        "Jianzhong Ju",
        "Zhenbo Luo"
      ],
      "abstract": "Recent progress in multi-modal large language models (MLLMs) has significantly advanced video understanding. However, their performance on long-form videos remains limited by computational constraints and suboptimal frame selection. We present Think-Clip-Sample (TCS), a training-free framework that enhances long video understanding through two key components: (i) Multi-Query Reasoning, which generates multiple queries to capture complementary aspects of the question and video; and (ii) Clip-level Slow-Fast Sampling, which adaptively balances dense local details and sparse global context. Extensive experiments on MLVU, LongVideoBench, and VideoMME demonstrate that TCS consistently improves performance across different MLLMs, boosting up to 6.9% accuracy, and is capable of achieving comparable accuracy with 50% fewer inference time cost, highlighting both efficiency and efficacy of TCS on long video understanding.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Think-Clip-Sample (TCS)ï¼Œè¿™æ˜¯ä¸€ä¸ªæ— éœ€è®­ç»ƒ (training-free) çš„æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ (MLLMs) åœ¨é•¿è§†é¢‘ç†è§£ä¸­é¢ä¸´çš„è®¡ç®—å—é™å’Œå¸§é€‰æ‹©ä¸ä½³ç­‰é—®é¢˜ã€‚è¯¥æ¡†æ¶åŒ…å«ä¸¤ä¸ªæ ¸å¿ƒç»„ä»¶ï¼šå¤šæŸ¥è¯¢æ¨ç† (Multi-Query Reasoning) é€šè¿‡ç”Ÿæˆå¤šä¸ªäº’è¡¥æŸ¥è¯¢æ¥æ•æ‰è§†é¢‘çš„å…³é”®ä¿¡æ¯ï¼›ç‰‡æ®µçº§å¿«æ…¢é‡‡æ · (Clip-level Slow-Fast Sampling) åˆ™ç”¨äºè‡ªé€‚åº”å¹³è¡¡å¯†é›†çš„å±€éƒ¨ç»†èŠ‚ä¸ç¨€ç–çš„å…¨å±€ä¸Šä¸‹æ–‡ã€‚åœ¨ MLVUã€LongVideoBench å’Œ VideoMME ç­‰å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒTCS åœ¨ä¸åŒæ¨¡å‹ä¸Šæœ€é«˜å¯æå‡ 6.9% çš„å‡†ç¡®ç‡ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿåœ¨å‡å°‘ 50% æ¨ç†æ—¶é—´æˆæœ¬çš„å‰æä¸‹å®ç°åŒç­‰çš„å‡†ç¡®åº¦ï¼Œå……åˆ†è¯æ˜äº†å…¶åœ¨é•¿è§†é¢‘ç†è§£ä»»åŠ¡ä¸­å…¼å…·å“è¶Šçš„æ•ˆç‡ä¸æ€§èƒ½ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ICASSP2026",
      "pdf_url": "https://arxiv.org/pdf/2601.11359v1",
      "published_date": "2026-01-16 15:14:04 UTC",
      "updated_date": "2026-01-16 15:14:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:58:13.758909+00:00"
    },
    {
      "arxiv_id": "2601.11354v1",
      "title": "AstroReason-Bench: Evaluating Unified Agentic Planning across Heterogeneous Space Planning Problems",
      "title_zh": "AstroReason-Benchï¼šè¯„ä¼°å¼‚æ„ç©ºé—´è§„åˆ’é—®é¢˜ä¸­çš„ç»Ÿä¸€æ™ºèƒ½ä½“è§„åˆ’",
      "authors": [
        "Weiyi Wang",
        "Xinchi Chen",
        "Jingjing Gong",
        "Xuanjing Huang",
        "Xipeng Qiu"
      ],
      "abstract": "Recent advances in agentic Large Language Models (LLMs) have positioned them as generalist planners capable of reasoning and acting across diverse tasks. However, existing agent benchmarks largely focus on symbolic or weakly grounded environments, leaving their performance in physics-constrained real-world domains underexplored. We introduce AstroReason-Bench, a comprehensive benchmark for evaluating agentic planning in Space Planning Problems (SPP), a family of high-stakes problems with heterogeneous objectives, strict physical constraints, and long-horizon decision-making. AstroReason-Bench integrates multiple scheduling regimes, including ground station communication and agile Earth observation, and provides a unified agent-oriented interaction protocol. Evaluating on a range of state-of-the-art open- and closed-source agentic LLM systems, we find that current agents substantially underperform specialized solvers, highlighting key limitations of generalist planning under realistic constraints. AstroReason-Bench offers a challenging and diagnostic testbed for future agentic research.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†AstroReason-Benchï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨è¯„ä¼°æ™ºèƒ½ä½“å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨ç©ºé—´è§„åˆ’é—®é¢˜(Space Planning Problems, SPP)ä¸­ç»Ÿä¸€è§„åˆ’èƒ½åŠ›çš„ç»¼åˆåŸºå‡†ã€‚è¯¥åŸºå‡†é’ˆå¯¹å…·æœ‰å¼‚æ„ç›®æ ‡ã€ä¸¥æ ¼ç‰©ç†çº¦æŸå’Œé•¿æ—¶ç¨‹(long-horizon)å†³ç­–ç‰¹å¾çš„é«˜é£é™©é¢†åŸŸï¼Œå¡«è¡¥äº†ç°æœ‰æ™ºèƒ½ä½“åŸºå‡†ç¼ºä¹ç‰©ç†çº¦æŸçœŸå®ç¯å¢ƒæµ‹è¯•çš„ç©ºç™½ã€‚AstroReason-Benché›†æˆäº†åœ°é¢ç«™é€šä¿¡å’Œæ•æ·åœ°çƒè§‚æµ‹ç­‰å¤šç§è°ƒåº¦æ–¹æ¡ˆï¼Œå¹¶æä¾›äº†ç»Ÿä¸€çš„é¢å‘æ™ºèƒ½ä½“çš„äº¤äº’åè®®ã€‚é€šè¿‡å¯¹å¤šç§æœ€å…ˆè¿›çš„å¼€æºå’Œé—­æºæ™ºèƒ½ä½“ç³»ç»Ÿè¿›è¡Œè¯„ä¼°ï¼Œç ”ç©¶å‘ç°ç›®å‰çš„æ™ºèƒ½ä½“åœ¨å¤„ç†ç°å®çº¦æŸæ—¶çš„è¡¨ç°æ˜¾è‘—é€Šäºä¸“é—¨çš„æ±‚è§£å™¨(specialized solvers)ï¼Œå‡¸æ˜¾äº†é€šç”¨è§„åˆ’èƒ½åŠ›çš„å±€é™æ€§ã€‚è¯¥åŸºå‡†ä¸ºæœªæ¥æ™ºèƒ½ä½“åœ¨å¤æ‚ç‰©ç†å—é™ç¯å¢ƒä¸‹çš„ç ”ç©¶æä¾›äº†ä¸€ä¸ªæå…·æŒ‘æˆ˜æ€§å’Œè¯Šæ–­æ€§çš„æµ‹è¯•å¹³å°ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11354v1",
      "published_date": "2026-01-16 15:02:41 UTC",
      "updated_date": "2026-01-16 15:02:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:58:24.450408+00:00"
    },
    {
      "arxiv_id": "2601.11350v1",
      "title": "FEATHer: Fourier-Efficient Adaptive Temporal Hierarchy Forecaster for Time-Series Forecasting",
      "title_zh": "FEATHerï¼šé¢å‘æ—¶é—´åºåˆ—é¢„æµ‹çš„é«˜æ•ˆå‚…é‡Œå¶è‡ªé€‚åº”æ—¶åºå±‚çº§é¢„æµ‹å™¨",
      "authors": [
        "Jaehoon Lee",
        "Seungwoo Lee",
        "Younghwi Kim",
        "Dohee Kim",
        "Sunghyun Sim"
      ],
      "abstract": "Time-series forecasting is fundamental in industrial domains like manufacturing and smart factories. As systems evolve toward automation, models must operate on edge devices (e.g., PLCs, microcontrollers) with strict constraints on latency and memory, limiting parameters to a few thousand. Conventional deep architectures are often impractical here. We propose the Fourier-Efficient Adaptive Temporal Hierarchy Forecaster (FEATHer) for accurate long-term forecasting under severe limits. FEATHer introduces: (i) ultra-lightweight multiscale decomposition into frequency pathways; (ii) a shared Dense Temporal Kernel using projection-depthwise convolution-projection without recurrence or attention; (iii) frequency-aware branch gating that adaptively fuses representations based on spectral characteristics; and (iv) a Sparse Period Kernel reconstructing outputs via period-wise downsampling to capture seasonality. FEATHer maintains a compact architecture (as few as 400 parameters) while outperforming baselines. Across eight benchmarks, it achieves the best ranking, recording 60 first-place results with an average rank of 2.05. These results demonstrate that reliable long-range forecasting is achievable on constrained edge hardware, offering a practical direction for industrial real-time inference.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† FEATHer (Fourier-Efficient Adaptive Temporal Hierarchy Forecaster)ï¼Œä¸€ç§ä¸“é—¨ä¸º PLC å’Œå¾®æ§åˆ¶å™¨ç­‰å—é™è¾¹ç¼˜è®¾å¤‡è®¾è®¡çš„è¶…è½»é‡çº§æ—¶é—´åºåˆ—é¢„æµ‹æ¨¡å‹ã€‚FEATHer æ ¸å¿ƒæ¶æ„åŒ…æ‹¬å¤šå°ºåº¦çš„é¢‘ç‡è·¯å¾„åˆ†è§£ï¼Œä»¥åŠä¸€ä¸ªåŸºäº projection-depthwise convolution-projection ç»“æ„çš„å…±äº« Dense Temporal Kernelï¼Œæœ‰æ•ˆé¿å…äº†å¤æ‚çš„é€’å½’æˆ–æ³¨æ„åŠ›æœºåˆ¶ã€‚ä¸ºäº†æå‡é¢„æµ‹ç²¾åº¦ï¼Œè¯¥æ¨¡å‹å¼•å…¥äº† frequency-aware branch gating è¿›è¡Œè‡ªé€‚åº”ç‰¹å¾èåˆï¼Œå¹¶åˆ©ç”¨ Sparse Period Kernel é€šè¿‡å‘¨æœŸæ€§ä¸‹é‡‡æ ·æ•æ‰æ•°æ®çš„å­£èŠ‚æ€§ç‰¹å¾ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒFEATHer åœ¨å‚æ•°é‡ä»…ä¸º 400 ä¸ªå·¦å³çš„æƒ…å†µä¸‹ï¼Œåœ¨å…«é¡¹åŸºå‡†æµ‹è¯•ä¸­è·å¾—äº† 60 é¡¹ç¬¬ä¸€ï¼Œå¹³å‡æ’åè¾¾åˆ° 2.05ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰åŸºå‡†æ¨¡å‹ã€‚è¯¥æˆæœè¯æ˜äº†åœ¨æä½ç®—åŠ›çš„å·¥ä¸šç¡¬ä»¶ä¸Šå®ç°å¯é çš„é•¿ç¨‹æ—¶é—´åºåˆ—é¢„æµ‹çš„å¯è¡Œæ€§ï¼Œä¸ºå·¥ä¸šç¯å¢ƒä¸‹çš„å®æ—¶æ¨ç†æä¾›äº†é«˜æ•ˆä¸”å®ç”¨çš„æŠ€æœ¯æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Submitted to IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)",
      "pdf_url": "https://arxiv.org/pdf/2601.11350v1",
      "published_date": "2026-01-16 14:57:41 UTC",
      "updated_date": "2026-01-16 14:57:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:58:12.774788+00:00"
    },
    {
      "arxiv_id": "2601.11344v1",
      "title": "How Much Would a Clinician Edit This Draft? Evaluating LLM Alignment for Patient Message Response Drafting",
      "title_zh": "ä¸´åºŠåŒ»ç”Ÿä¼šå¯¹è¿™ä»½è‰ç¨¿è¿›è¡Œå¤šå¤§ç¨‹åº¦çš„ä¿®æ”¹ï¼Ÿè¯„ä¼°å¤§è¯­è¨€æ¨¡å‹åœ¨æ‚£è€…æ¶ˆæ¯å›å¤è‰ç¨¿æ’°å†™ä¸­çš„å¯¹é½æ€§",
      "authors": [
        "Parker Seegmiller",
        "Joseph Gatto",
        "Sarah E. Greer",
        "Ganza Belise Isingizwe",
        "Rohan Ray",
        "Timothy E. Burdick",
        "Sarah Masud Preum"
      ],
      "abstract": "Large language models (LLMs) show promise in drafting responses to patient portal messages, yet their integration into clinical workflows raises various concerns, including whether they would actually save clinicians time and effort in their portal workload. We investigate LLM alignment with individual clinicians through a comprehensive evaluation of the patient message response drafting task. We develop a novel taxonomy of thematic elements in clinician responses and propose a novel evaluation framework for assessing clinician editing load of LLM-drafted responses at both content and theme levels. We release an expert-annotated dataset and conduct large-scale evaluations of local and commercial LLMs using various adaptation techniques including thematic prompting, retrieval-augmented generation, supervised fine-tuning, and direct preference optimization. Our results reveal substantial epistemic uncertainty in aligning LLM drafts with clinician responses. While LLMs demonstrate capability in drafting certain thematic elements, they struggle with clinician-aligned generation in other themes, particularly question asking to elicit further information from patients. Theme-driven adaptation strategies yield improvements across most themes. Our findings underscore the necessity of adapting LLMs to individual clinician preferences to enable reliable and responsible use in patient-clinician communication workflows.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨æ’°å†™æ‚£è€…é—¨æˆ·æ¶ˆæ¯å›å¤ä¸­çš„åº”ç”¨ï¼Œå¹¶é’ˆå¯¹å…¶èƒ½å¦å®é™…å‡è½»ä¸´åºŠåŒ»ç”Ÿå·¥ä½œé‡çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€å¥—è¯„ä¼° LLM ä¸ä¸ªä½“åŒ»ç”Ÿå¯¹é½ç¨‹åº¦çš„ç»¼åˆæ¡†æ¶ã€‚ç ”ç©¶è€…å¼€å‘äº†ä¸€ç§ä¸´åºŠåŒ»ç”Ÿå›å¤çš„ä¸»é¢˜å…ƒç´ åˆ†ç±»æ³•(Taxonomy)ï¼Œå¹¶å»ºç«‹äº†ä¸€ç§ä»å†…å®¹å’Œä¸»é¢˜å±‚é¢è¯„ä¼°åŒ»ç”Ÿå¯¹æ¨¡å‹è‰ç¨¿ä¿®æ”¹å·¥ä½œé‡(Editing load)çš„æ–°å‹è¯„ä»·ä½“ç³»ã€‚é€šè¿‡å‘å¸ƒä¸“å®¶æ ‡æ³¨çš„æ•°æ®é›†ï¼Œç ”ç©¶å›¢é˜Ÿè¯„ä¼°äº†å¤šç§æœ¬åœ°åŠå•†ä¸šæ¨¡å‹åœ¨ä¸»é¢˜æç¤ºã€æ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)ã€ç›‘ç£å¾®è°ƒ(SFT)å’Œç›´æ¥åå¥½ä¼˜åŒ–(DPO)ç­‰é€‚åº”æŠ€æœ¯ä¸‹çš„è¡¨ç°ã€‚å®éªŒç»“æœæ­ç¤ºäº†å°† LLM è‰ç¨¿ä¸åŒ»ç”Ÿå›å¤å¯¹é½æ—¶å­˜åœ¨æ˜¾è‘—çš„è®¤è¯†ä¸ç¡®å®šæ€§(Epistemic uncertainty)ï¼Œæ¨¡å‹è™½èƒ½èƒœä»»ç‰¹å®šä¸»é¢˜çš„æ’°å†™ï¼Œä½†åœ¨å‘æ‚£è€…ç´¢å–è¿›ä¸€æ­¥ä¿¡æ¯çš„æé—®ç¯èŠ‚ä»é¢ä¸´æŒ‘æˆ˜ã€‚ç ”ç©¶æœ€åå¼ºè°ƒï¼Œé‡‡ç”¨ä¸»é¢˜é©±åŠ¨çš„é€‚åº”ç­–ç•¥èƒ½æå‡ç”Ÿæˆè´¨é‡ï¼Œå¹¶æŒ‡å‡ºä¸ºäº†åœ¨ä¸´åºŠå·¥ä½œæµä¸­å®ç°å¯é ä¸”è´Ÿè´£ä»»çš„åº”ç”¨ï¼Œå¿…é¡»æ ¹æ®ä¸ªä½“åŒ»ç”Ÿçš„åå¥½å¯¹ LLM è¿›è¡Œé’ˆå¯¹æ€§è°ƒæ•´ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11344v1",
      "published_date": "2026-01-16 14:48:00 UTC",
      "updated_date": "2026-01-16 14:48:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:58:49.428490+00:00"
    },
    {
      "arxiv_id": "2601.11286v1",
      "title": "XChoice: Explainable Evaluation of AI-Human Alignment in LLM-based Constrained Choice Decision Making",
      "title_zh": "XChoiceï¼šå¤§è¯­è¨€æ¨¡å‹å—é™é€‰æ‹©å†³ç­–ä¸­äººæœºå¯¹é½çš„å¯è§£é‡Šæ€§è¯„ä¼°",
      "authors": [
        "Weihong Qi",
        "Fan Huang",
        "Rasika Muralidharan",
        "Jisun An",
        "Haewoon Kwak"
      ],
      "abstract": "We present XChoice, an explainable framework for evaluating AI-human alignment in constrained decision making. Moving beyond outcome agreement such as accuracy and F1 score, XChoice fits a mechanism-based decision model to human data and LLM-generated decisions, recovering interpretable parameters that capture the relative importance of decision factors, constraint sensitivity, and implied trade-offs. Alignment is assessed by comparing these parameter vectors across models, options, and subgroups. We demonstrate XChoice on Americans' daily time allocation using the American Time Use Survey (ATUS) as human ground truth, revealing heterogeneous alignment across models and activities and salient misalignment concentrated in Black and married groups. We further validate robustness of XChoice via an invariance analysis and evaluate targeted mitigation with a retrieval augmented generation (RAG) intervention. Overall, XChoice provides mechanism-based metrics that diagnose misalignment and support informed improvements beyond surface outcome matching.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†XChoiceï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºè¯„ä¼°å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å—é™å†³ç­–ä¸­ä¸äººç±»å¯¹é½ï¼ˆAI-human alignmentï¼‰çš„å¯è§£é‡Šæ€§æ¡†æ¶ã€‚è¯¥æ¡†æ¶è¶…è¶Šäº†ä¼ ç»Ÿçš„å‡†ç¡®ç‡å’ŒF1åˆ†æ•°ç­‰ç»“æœä¸€è‡´æ€§æŒ‡æ ‡ï¼Œé€šè¿‡å°†åŸºäºæœºåˆ¶çš„å†³ç­–æ¨¡å‹æ‹Ÿåˆåˆ°äººç±»æ•°æ®å’ŒLLMå†³ç­–ä¸­ï¼Œæå–å‡ºåæ˜ å†³ç­–å› ç´ ç›¸å¯¹é‡è¦æ€§ã€çº¦æŸæ•æ„Ÿæ€§åŠæƒè¡¡å–èˆçš„å¯è§£é‡Šå‚æ•°ã€‚ç ”ç©¶å›¢é˜Ÿåˆ©ç”¨ç¾å›½æ—¶é—´åˆ©ç”¨è°ƒæŸ¥ï¼ˆATUSï¼‰æ•°æ®ä½œä¸ºäººç±»åŸºå‡†è¿›è¡Œäº†éªŒè¯ï¼Œæ­ç¤ºäº†ä¸åŒæ¨¡å‹å’Œæ´»åŠ¨ä¹‹é—´å¯¹é½ç¨‹åº¦çš„å¼‚è´¨æ€§ï¼Œå¹¶å‘ç°å¤±é…ç°è±¡åœ¨é»‘äººå’Œå·²å©šç¾¤ä½“ä¸­å°¤ä¸ºæ˜¾è‘—ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶é€šè¿‡ä¸å˜æ€§åˆ†æéªŒè¯äº†XChoiceçš„é²æ£’æ€§ï¼Œå¹¶è¯„ä¼°äº†åˆ©ç”¨æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æŠ€æœ¯è¿›è¡Œé’ˆå¯¹æ€§ç¼“è§£çš„æ•ˆæœã€‚æ€»ä¹‹ï¼ŒXChoiceæä¾›çš„æœºåˆ¶æ€§æŒ‡æ ‡æœ‰åŠ©äºè¯Šæ–­AIä¸äººç±»çš„æ·±å±‚å¤±é…ï¼Œä¸ºè¶…è¶Šè¡¨é¢ç»“æœåŒ¹é…çš„æ¨¡å‹æ”¹è¿›æä¾›äº†ç§‘å­¦ä¾æ®ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11286v1",
      "published_date": "2026-01-16 13:35:38 UTC",
      "updated_date": "2026-01-16 13:35:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:58:46.661994+00:00"
    },
    {
      "arxiv_id": "2601.11282v1",
      "title": "From SERPs to Sound: How Search Engine Result Pages and AI-generated Podcasts Interact to Influence User Attitudes on Controversial Topics",
      "title_zh": "ä»æœç´¢å¼•æ“ç»“æœé¡µåˆ°éŸ³é¢‘ï¼šæœç´¢å¼•æ“ç»“æœé¡µä¸ AI ç”Ÿæˆæ’­å®¢å¦‚ä½•äº¤äº’å½±å“ç”¨æˆ·å¯¹äº‰è®®æ€§è¯é¢˜çš„æ€åº¦",
      "authors": [
        "Junjie Wang",
        "Gaole He",
        "Alisa Rieger",
        "Ujwal Gadiraju"
      ],
      "abstract": "Compared to search engine result pages (SERPs), AI-generated podcasts represent a relatively new and relatively more passive modality of information consumption, delivering narratives in a naturally engaging format. As these two media increasingly converge in everyday information-seeking behavior, it is essential to explore how their interaction influences user attitudes, particularly in contexts involving controversial, value-laden, and often debated topics. Addressing this need, we aim to understand how information mediums of present-day SERPs and AI-generated podcasts interact to shape the opinions of users. To this end, through a controlled user study (N=483), we investigated user attitudinal effects of consuming information via SERPs and AI-generated podcasts, focusing on how the sequence and modality of exposure shape user opinions. A majority of users in our study corresponded to attitude change outcomes, and we found an effect of sequence on attitude change. Our results further revealed a role of viewpoint bias and the degree of topic controversiality in shaping attitude change, although we found no effect of individual moderators.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†æœç´¢å¼•æ“ç»“æœé¡µé¢ (SERPs) ä¸ AI ç”Ÿæˆçš„æ’­å®¢ (AI-generated podcasts) ä¹‹é—´çš„äº¤äº’ä½œç”¨ï¼Œåˆ†æäº†è¿™ä¸¤ç§ä¿¡æ¯åª’ä»‹å¦‚ä½•å…±åŒå½±å“ç”¨æˆ·å¯¹äº‰è®®æ€§ã€ä»·å€¼å¯¼å‘è¯é¢˜çš„æ€åº¦ã€‚ç›¸æ¯”äºä¼ ç»Ÿçš„ SERPsï¼ŒAI ç”Ÿæˆçš„æ’­å®¢ä½œä¸ºä¸€ç§æ–°å…´ä¸”æ›´ä¸ºè¢«åŠ¨çš„ä¿¡æ¯è·å–æ–¹å¼ï¼Œé€šè¿‡æå…·å‚ä¸æ„Ÿçš„å™äº‹å½¢å¼ä¼ é€’å†…å®¹ã€‚ç ”ç©¶å›¢é˜Ÿé€šè¿‡ä¸€é¡¹åŒ…å« 483 åå—è¯•è€…çš„å—æ§ç”¨æˆ·ç ”ç©¶ (controlled user study)ï¼Œé‡ç‚¹è€ƒå¯Ÿäº†ä¿¡æ¯æš´éœ²çš„é¡ºåº (sequence) å’Œåª’ä»‹å½¢å¼ (modality) å¯¹ç”¨æˆ·è§‚ç‚¹å¡‘é€ çš„å½±å“ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œå¤§å¤šæ•°å—è¯•è€…è¡¨ç°å‡ºæ˜æ˜¾çš„æ€åº¦æ”¹å˜ (attitude change)ï¼Œä¸”è¿™ç§æ”¹å˜å—åˆ°ä¿¡æ¯å‘ˆç°é¡ºåºçš„æ˜¾è‘—å½±å“ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜å‘ç°è§‚ç‚¹åè§ (viewpoint bias) å’Œè¯é¢˜äº‰è®®ç¨‹åº¦ (topic controversiality) åœ¨æ€åº¦è½¬å˜ä¸­èµ·åˆ°äº†å…³é”®ä½œç”¨ï¼Œå°½ç®¡ä¸ªä½“è°ƒèŠ‚å˜é‡ (individual moderators) æœªè¡¨ç°å‡ºæ˜¾è‘—æ•ˆåº”ã€‚è¯¥ç ”ç©¶æ­ç¤ºäº†åœ¨ä¿¡æ¯åª’ä»‹æ—¥ç›Šèåˆçš„èƒŒæ™¯ä¸‹ï¼Œåª’ä»‹äº¤äº’å¦‚ä½•æ·±åˆ»é‡å¡‘ç”¨æˆ·å¯¹å¤æ‚ç¤¾ä¼šè®®é¢˜çš„è®¤çŸ¥ã€‚",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.HC",
        "cs.SI"
      ],
      "primary_category": "cs.IR",
      "comment": "ACM CHIIR 2026",
      "pdf_url": "https://arxiv.org/pdf/2601.11282v1",
      "published_date": "2026-01-16 13:31:11 UTC",
      "updated_date": "2026-01-16 13:31:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:58:51.125067+00:00"
    },
    {
      "arxiv_id": "2601.11269v1",
      "title": "X-Distill: Cross-Architecture Vision Distillation for Visuomotor Learning",
      "title_zh": "X-Distillï¼šé¢å‘è§†è§‰è¿åŠ¨å­¦ä¹ çš„è·¨æ¶æ„è§†è§‰è’¸é¦",
      "authors": [
        "Maanping Shao",
        "Feihong Zhang",
        "Gu Zhang",
        "Baiye Cheng",
        "Zhengrong Xue",
        "Huazhe Xu"
      ],
      "abstract": "Visuomotor policies often leverage large pre-trained Vision Transformers (ViTs) for their powerful generalization capabilities. However, their significant data requirements present a major challenge in the data-scarce context of most robotic learning settings, where compact CNNs with strong inductive biases can be more easily optimized. To address this trade-off, we introduce X-Distill, a simple yet highly effective method that synergizes the strengths of both architectures. Our approach involves an offline, cross-architecture knowledge distillation, transferring the rich visual representations of a large, frozen DINOv2 teacher to a compact ResNet-18 student on the general-purpose ImageNet dataset. This distilled encoder, now endowed with powerful visual priors, is then jointly fine-tuned with a diffusion policy head on the target manipulation tasks. Extensive experiments on $34$ simulated benchmarks and $5$ challenging real-world tasks demonstrate that our method consistently outperforms policies equipped with from-scratch ResNet or fine-tuned DINOv2 encoders. Notably, X-Distill also surpasses 3D encoders that utilize privileged point cloud observations or much larger Vision-Language Models. Our work highlights the efficacy of a simple, well-founded distillation strategy for achieving state-of-the-art performance in data-efficient robotic manipulation.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† X-Distillï¼Œä¸€ç§ç®€å•ä¸”é«˜æ•ˆçš„è·¨æ¶æ„è§†è§‰è’¸é¦ (Cross-Architecture Vision Distillation) æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³æœºå™¨äººè§†è§‰è¿åŠ¨å­¦ä¹  (Visuomotor Learning) ä¸­å¤§å‹ Vision Transformers (ViTs) å¯¹æ•°æ®éœ€æ±‚é‡å¤§ä¸ç´§å‡‘å‹ CNNs åœ¨æ•°æ®ç¨€ç¼ºç¯å¢ƒä¸‹æ›´æ˜“ä¼˜åŒ–çš„çŸ›ç›¾ã€‚è¯¥æ–¹æ³•é‡‡ç”¨ç¦»çº¿è’¸é¦ç­–ç•¥ï¼Œå°†é¢„è®­ç»ƒä¸”å†»ç»“çš„ DINOv2 å¤§æ¨¡å‹çš„ä¸°å¯Œè§†è§‰è¡¨å¾ï¼Œåœ¨é€šç”¨çš„ ImageNet æ•°æ®é›†ä¸Šè¿ç§»ç»™è½»é‡åŒ–çš„ ResNet-18 å­¦ç”Ÿæ¨¡å‹ã€‚è’¸é¦åçš„ç¼–ç å™¨è·å¾—äº†å¼ºå¤§çš„è§†è§‰å…ˆéªŒï¼Œéšåä¸æ‰©æ•£ç­–ç•¥ (diffusion policy) å¤´ç»“åˆï¼Œåœ¨ç›®æ ‡æ“ä½œä»»åŠ¡ä¸Šè¿›è¡Œè”åˆå¾®è°ƒã€‚é€šè¿‡å¯¹ 34 ä¸ªä»¿çœŸåŸºå‡†å’Œ 5 é¡¹çœŸå®ä¸–ç•Œä»»åŠ¡çš„å¹¿æ³›å®éªŒï¼Œç»“æœè¡¨æ˜ X-Distill å§‹ç»ˆä¼˜äºä»é›¶å¼€å§‹è®­ç»ƒçš„ ResNet æˆ–å¾®è°ƒåçš„ DINOv2 ç¼–ç å™¨ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œè¯¥æ–¹æ³•ç”šè‡³è¶…è¶Šäº†åˆ©ç”¨ç‰¹æƒç‚¹äº‘ (privileged point cloud) è§‚æµ‹çš„ 3D ç¼–ç å™¨ä»¥åŠå‚æ•°é‡æ›´å¤§çš„è§†è§‰è¯­è¨€æ¨¡å‹ (Vision-Language Models)ã€‚è¯¥å·¥ä½œè¯æ˜äº†é€šè¿‡åˆç†çš„è’¸é¦ç­–ç•¥ï¼Œå³å¯åœ¨æ•°æ®é«˜æ•ˆçš„æœºå™¨äººæ“ä½œä»»åŠ¡ä¸­å®ç°æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11269v1",
      "published_date": "2026-01-16 13:15:55 UTC",
      "updated_date": "2026-01-16 13:15:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:58:50.191726+00:00"
    },
    {
      "arxiv_id": "2601.11258v1",
      "title": "Knowledge is Not Enough: Injecting RL Skills for Continual Adaptation",
      "title_zh": "ä»…æœ‰çŸ¥è¯†æ˜¯ä¸å¤Ÿçš„ï¼šæ³¨å…¥å¼ºåŒ–å­¦ä¹ æŠ€èƒ½ä»¥å®ç°æŒç»­é€‚åº”",
      "authors": [
        "Pingzhi Tang",
        "Yiding Wang",
        "Muhan Zhang"
      ],
      "abstract": "Large Language Models (LLMs) face the \"knowledge cutoff\" challenge, where their frozen parametric memory prevents direct internalization of new information. While Supervised Fine-Tuning (SFT) is commonly used to update model knowledge, it often updates factual content without reliably improving the model's ability to use the newly incorporated information for question answering or decision-making. Reinforcement Learning (RL) is essential for acquiring reasoning skills; however, its high computational cost makes it impractical for efficient online adaptation. We empirically observe that the parameter updates induced by SFT and RL are nearly orthogonal. Based on this observation, we propose Parametric Skill Transfer (PaST), a framework that supports modular skill transfer for efficient and effective knowledge adaptation. By extracting a domain-agnostic Skill Vector from a source domain, we can linearly inject knowledge manipulation skills into a target model after it has undergone lightweight SFT on new data. Experiments on knowledge-incorporation QA (SQuAD, LooGLE) and agentic tool-use benchmarks (ToolBench) demonstrate the effectiveness of our method. On SQuAD, PaST outperforms the state-of-the-art self-editing SFT baseline by up to 9.9 points. PaST further scales to long-context QA on LooGLE with an 8.0-point absolute accuracy gain, and improves zero-shot ToolBench success rates by +10.3 points on average with consistent gains across tool categories, indicating strong scalability and cross-domain transferability of the Skill Vector.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨åº”å¯¹çŸ¥è¯†æˆªæ­¢(knowledge cutoff)æ—¶ï¼Œä¼ ç»Ÿç›‘ç£å¾®è°ƒ(SFT)æ— æ³•æœ‰æ•ˆæå‡æ¨¡å‹çŸ¥è¯†åˆ©ç”¨èƒ½åŠ›çš„é—®é¢˜ï¼Œæå‡ºäº†Parametric Skill Transfer (PaST)æ¡†æ¶ã€‚ç ”ç©¶äººå‘˜è§‚å¯Ÿåˆ°SFTä¸å¼ºåŒ–å­¦ä¹ (RL)å¼•å‘çš„å‚æ•°æ›´æ–°å…·æœ‰è¿‘ä¹æ­£äº¤çš„ç‰¹æ€§ï¼Œæ®æ­¤å¼€å‘äº†ä»æºåŸŸæå–é¢†åŸŸæ— å…³Skill Vectorçš„æŠ€æœ¯ã€‚é€šè¿‡å°†è¯¥å‘é‡çº¿æ€§æ³¨å…¥åˆ°ç»è¿‡è½»é‡çº§SFTçš„ç›®æ ‡æ¨¡å‹ä¸­ï¼ŒPaSTèƒ½å¤Ÿæ˜¾è‘—å¢å¼ºæ¨¡å‹å¯¹æ–°çŸ¥è¯†çš„æ“ä½œå’Œæ¨ç†æŠ€èƒ½ã€‚å®éªŒåœ¨SQuADã€LooGLEå’ŒToolBenchç­‰å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å‡å–å¾—äº†æ˜¾è‘—æˆæ•ˆï¼Œå…¶ä¸­åœ¨SQuADä¸Šçš„è¡¨ç°æ¯”SFTåŸºå‡†é«˜å‡º9.9ä¸ªç™¾åˆ†ç‚¹ï¼Œåœ¨ToolBenchä¸Šçš„é›¶æ ·æœ¬æˆåŠŸç‡å¹³å‡æå‡10.3ä¸ªç™¾åˆ†ç‚¹ã€‚è¿™ä¸€æ–¹æ³•è¯æ˜äº†Skill Vectorå…·å¤‡å¼ºå¤§çš„å¯æ‰©å±•æ€§ä¸è·¨é¢†åŸŸè¿ç§»èƒ½åŠ›ï¼Œä¸ºå®ç°å¤§æ¨¡å‹é«˜æ•ˆä¸”ä½æˆæœ¬çš„æŒç»­é€‚åº”æä¾›äº†åˆ›æ–°è·¯å¾„ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11258v1",
      "published_date": "2026-01-16 13:08:16 UTC",
      "updated_date": "2026-01-16 13:08:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:58:53.757652+00:00"
    },
    {
      "arxiv_id": "2601.11252v1",
      "title": "Beyond Model Scaling: Test-Time Intervention for Efficient Deep Reasoning",
      "title_zh": "è¶…è¶Šæ¨¡å‹è§„æ¨¡æ‰©å±•ï¼šé¢å‘é«˜æ•ˆæ·±åº¦æ¨ç†çš„æµ‹è¯•æ—¶å¹²é¢„",
      "authors": [
        "Qianyue Wang",
        "Jinwu Hu",
        "Yufeng Wang",
        "Huanxiang Lin",
        "Bolin Chen",
        "Zhiquan Wen",
        "Yaofo Chen",
        "Mingkui Tan"
      ],
      "abstract": "Large Reasoning Models (LRMs) excel at multi-step reasoning but often suffer from inefficient reasoning processes like overthinking and overshoot, where excessive or misdirected reasoning increases computational cost and degrades performance. Existing efficient reasoning methods operate in a closed-loop manner, lacking mechanisms for external intervention to guide the reasoning process. To address this, we propose Think-with-Me, a novel test-time interactive reasoning paradigm that introduces external feedback intervention into the reasoning process. Our key insights are that transitional conjunctions serve as natural points for intervention, signaling phases of self-validation or exploration and using transitional words appropriately to prolong the reasoning enhances performance, while excessive use affects performance. Building on these insights, Think-with-Me pauses reasoning at these points for external feedback, adaptively extending or terminating reasoning to reduce redundancy while preserving accuracy. The feedback is generated via a multi-criteria evaluation (rationality and completeness) and comes from either human or LLM proxies. We train the target model using Group Relative Policy Optimization (GRPO) to adapt to this interactive mode. Experiments show that Think-with-Me achieves a superior balance between accuracy and reasoning length under limited context windows. On AIME24, Think-with-Me outperforms QwQ-32B by 7.19% in accuracy while reducing average reasoning length by 81% under an 8K window. The paradigm also benefits security and creative tasks.",
      "tldr_zh": "é’ˆå¯¹å¤§æ¨ç†æ¨¡å‹(Large Reasoning Models, LRMs)åœ¨å¤šæ­¥æ¨ç†ä¸­æ™®éå­˜åœ¨çš„è¿‡åº¦æ€è€ƒ(overthinking)å’Œè¿‡åº¦åç¦»(overshoot)é—®é¢˜ï¼Œè¯¥ç ”ç©¶æå‡ºäº†Think-with-Meï¼Œä¸€ç§å¼•å…¥å¤–éƒ¨åé¦ˆå¹²é¢„çš„æµ‹è¯•æ—¶äº¤äº’å¼æ¨ç†èŒƒå¼(test-time interactive reasoning paradigm)ã€‚è¯¥æ–¹æ³•å°†è½¬æŠ˜è¿è¯(transitional conjunctions)è¯†åˆ«ä¸ºå¤©ç„¶çš„å¹²é¢„ç‚¹ï¼Œé€šè¿‡åœ¨è¿™äº›ç‚¹æš‚åœå¹¶å¼•å…¥åŸºäºåˆç†æ€§å’Œå®Œæ•´æ€§æ ‡å‡†çš„å¤–éƒ¨åé¦ˆï¼Œå®ç°æ¨ç†è¿‡ç¨‹çš„è‡ªé€‚åº”æ‰©å±•æˆ–ç»ˆæ­¢ã€‚ç ”ç©¶é‡‡ç”¨ç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–(Group Relative Policy Optimization, GRPO)è®­ç»ƒæ¨¡å‹ä»¥é€‚åº”äº¤äº’æ¨¡å¼ï¼Œæœ‰æ•ˆå‡å°‘äº†å†—ä½™å¹¶ä¿æŒäº†å‡†ç¡®æ€§ã€‚å®éªŒè¯æ˜ï¼ŒThink-with-Meåœ¨å‡†ç¡®ç‡ä¸æ¨ç†é•¿åº¦ä¹‹é—´å–å¾—äº†å“è¶Šå¹³è¡¡ï¼Œåœ¨AIME24æµ‹è¯•ä¸­ç›¸è¾ƒäºQwQ-32Bå‡†ç¡®ç‡æå‡7.19%ï¼Œä¸”å¹³å‡æ¨ç†é•¿åº¦ç¼©å‡äº†81%ã€‚æ­¤å¤–ï¼Œè¯¥èŒƒå¼åœ¨å®‰å…¨æ€§(security)å’Œåˆ›æ„ä»»åŠ¡(creative tasks)ä¸­ä¹Ÿå±•ç°å‡ºæ˜¾è‘—ä¼˜åŠ¿ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11252v1",
      "published_date": "2026-01-16 13:00:42 UTC",
      "updated_date": "2026-01-16 13:00:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:59:01.736706+00:00"
    },
    {
      "arxiv_id": "2601.11232v1",
      "title": "FactCorrector: A Graph-Inspired Approach to Long-Form Factuality Correction of Large Language Models",
      "title_zh": "FactCorrectorï¼šåŸºäºå›¾å¯å‘çš„å¤§è¯­è¨€æ¨¡å‹é•¿æ–‡æœ¬äº‹å®æ€§çº é”™æ–¹æ³•",
      "authors": [
        "Javier Carnerero-Cano",
        "Massimiliano Pronesti",
        "Radu Marinescu",
        "Tigran Tchrakian",
        "James Barry",
        "Jasmina Gajcin",
        "Yufang Hou",
        "Alessandra Pascale",
        "Elizabeth Daly"
      ],
      "abstract": "Large language models (LLMs) are widely used in knowledge-intensive applications but often generate factually incorrect responses. A promising approach to rectify these flaws is correcting LLMs using feedback. Therefore, in this paper, we introduce FactCorrector, a new post-hoc correction method that adapts across domains without retraining and leverages structured feedback about the factuality of the original response to generate a correction. To support rigorous evaluations of factuality correction methods, we also develop the VELI5 benchmark, a novel dataset containing systematically injected factual errors and ground-truth corrections. Experiments on VELI5 and several popular long-form factuality datasets show that the FactCorrector approach significantly improves factual precision while preserving relevance, outperforming strong baselines. We release our code at https://ibm.biz/factcorrector.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† FactCorrectorï¼Œä¸€ç§å—å›¾å¯å‘ (Graph-Inspired) çš„å¤§è¯­è¨€æ¨¡å‹ (LLMs) é•¿ç¯‡äº‹å®æ€§ä¿®æ­£æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³æ¨¡å‹åœ¨çŸ¥è¯†å¯†é›†å‹åº”ç”¨ä¸­ç”Ÿæˆé”™è¯¯ä¿¡æ¯çš„é—®é¢˜ã€‚ä½œä¸ºä¸€ç§åéªŒ (Post-hoc) ä¿®æ­£æ‰‹æ®µï¼ŒFactCorrector æ— éœ€é‡æ–°è®­ç»ƒå³å¯è·¨é¢†åŸŸé€‚é…ï¼Œå¹¶åˆ©ç”¨å…³äºåŸå§‹å“åº”äº‹å®æ€§çš„ç»“æ„åŒ–åé¦ˆæ¥ç”Ÿæˆä¿®æ­£å†…å®¹ã€‚ä¸ºäº†ä¸¥è°¨è¯„ä¼°æ­¤ç±»æ–¹æ³•ï¼Œç ”ç©¶è€…åŒæ­¥å¼€å‘äº† VELI5 åŸºå‡†æµ‹è¯•é›†ï¼Œå…¶ä¸­åŒ…å«ç³»ç»Ÿæ€§æ³¨å…¥çš„äº‹å®é”™è¯¯åŠå…¶å¯¹åº”çš„æ ‡å‡†ä¿®æ­£ã€‚åœ¨ VELI5 åŠå¤šä¸ªé•¿ç¯‡äº‹å®æ€§æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼ŒFactCorrector åœ¨ä¿æŒå†…å®¹ç›¸å…³æ€§çš„åŒæ—¶æ˜¾è‘—æå‡äº†äº‹å®ç²¾ç¡®åº¦ (Factual Precision)ã€‚è¯¥æ–¹æ³•çš„è¡¨ç°ä¼˜äºå¤šç§å¼ºåŸºçº¿æ¨¡å‹ï¼Œè¯æ˜äº†å…¶åœ¨æå‡æ¨¡å‹è¾“å‡ºçœŸå®æ€§æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11232v1",
      "published_date": "2026-01-16 12:23:58 UTC",
      "updated_date": "2026-01-16 12:23:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:59:06.679633+00:00"
    },
    {
      "arxiv_id": "2601.11219v1",
      "title": "SDFLoRA: Selective Dual-Module LoRA for Federated Fine-tuning with Heterogeneous Clients",
      "title_zh": "SDFLoRAï¼šé¢å‘å¼‚æ„å®¢æˆ·ç«¯è”é‚¦å¾®è°ƒçš„é€‰æ‹©æ€§åŒæ¨¡å— LoRA",
      "authors": [
        "Zhikang Shen",
        "Jianrong Lu",
        "Haiyuan Wan",
        "Jianhai Chen"
      ],
      "abstract": "Federated learning (FL) for large language models (LLMs) has attracted increasing attention as a way to enable privacy-preserving adaptation over distributed data. Parameter-efficient methods such as LoRA are widely adopted to reduce communication and memory costs. Despite these advances, practical FL deployments often exhibit rank heterogeneity, since different clients may use different low-rank configurations. This makes direct aggregation of LoRA updates biased and unstable. Existing solutions typically enforce unified ranks or align heterogeneous updates into a shared subspace, which over-constrains client-specific semantics, limits personalization, and provides weak protection of local client information under differential privacy noise. To address this issue, we propose Selective Dual-module Federated LoRA (SDFLoRA), which decomposes each client adapter into a global module that captures transferable knowledge and a local module that preserves client-specific adaptations. The global module is selectively aligned and aggregated across clients, while local modules remain private. This design enables robust learning under rank heterogeneity and supports privacy-aware optimization by injecting differential privacy noise exclusively into the global module. Experiments on GLUE benchmarks demonstrate that SDFLoRA outperforms representative federated LoRA baselines and achieves a better utility-privacy trade-off.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨è”é‚¦å­¦ä¹ (Federated Learning)ä¸­å› å®¢æˆ·ç«¯ç§©å¼‚æ„æ€§(rank heterogeneity)å¯¼è‡´çš„æ›´æ–°èšåˆåç½®å’Œä¸ªæ€§åŒ–å—é™é—®é¢˜ï¼Œæå‡ºäº†SDFLoRA (Selective Dual-module Federated LoRA)æ¡†æ¶ã€‚SDFLoRAå°†æ¯ä¸ªå®¢æˆ·ç«¯çš„é€‚é…å™¨åˆ†è§£ä¸ºæ•è·å¯è¿ç§»çŸ¥è¯†çš„å…¨å±€æ¨¡å—å’Œä¿ç•™å®¢æˆ·ç«¯ç‰¹å®šç‰¹å¾çš„å±€éƒ¨æ¨¡å—ã€‚å…¨å±€æ¨¡å—ç»è¿‡é€‰æ‹©æ€§å¯¹é½åè¿›è¡Œè·¨å®¢æˆ·ç«¯èšåˆï¼Œè€Œå±€éƒ¨æ¨¡å—åˆ™ä¿æŒç§æœ‰ï¼Œä»è€Œåœ¨ç§©å¼‚æ„ç¯å¢ƒä¸‹å®ç°äº†é²æ£’å­¦ä¹ å¹¶æ”¯æŒä¸ªæ€§åŒ–å¾®è°ƒã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶é€šè¿‡ä»…åœ¨å…¨å±€æ¨¡å—ä¸­æ³¨å…¥å·®åˆ†éšç§(Differential Privacy)å™ªå£°ï¼Œåœ¨ä¿éšœæœ¬åœ°ä¿¡æ¯å®‰å…¨çš„åŒæ—¶æ˜¾è‘—æå‡äº†æ¨¡å‹æ•ˆç”¨ã€‚åœ¨GLUEåŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒSDFLoRAçš„æ€§èƒ½ä¼˜äºç°æœ‰çš„è”é‚¦LoRAåŸºå‡†æ–¹æ³•ï¼Œå¹¶åœ¨æ¨¡å‹æ•ˆç”¨ä¸éšç§ä¿æŠ¤ä¹‹é—´å–å¾—äº†æ›´ä¼˜çš„æƒè¡¡ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11219v1",
      "published_date": "2026-01-16 11:53:38 UTC",
      "updated_date": "2026-01-16 11:53:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:59:06.461322+00:00"
    },
    {
      "arxiv_id": "2601.11688v1",
      "title": "SpecMap: Hierarchical LLM Agent for Datasheet-to-Code Traceability Link Recovery in Systems Engineering",
      "title_zh": "SpecMapï¼šé¢å‘ç³»ç»Ÿå·¥ç¨‹ä¸­æ•°æ®æ‰‹å†Œè‡³ä»£ç è¿½æº¯å…³ç³»æ¢å¤çš„å±‚çº§åŒ–å¤§è¯­è¨€æ¨¡å‹æ™ºèƒ½ä½“",
      "authors": [
        "Vedant Nipane",
        "Pulkit Agrawal",
        "Amit Singh"
      ],
      "abstract": "Establishing precise traceability between embedded systems datasheets and their corresponding code implementations remains a fundamental challenge in systems engineering, particularly for low-level software where manual mapping between specification documents and large code repositories is infeasible. Existing Traceability Link Recovery approaches primarily rely on lexical similarity and information retrieval techniques, which struggle to capture the semantic, structural, and symbol level relationships prevalent in embedded systems software. We present a hierarchical datasheet-to-code mapping methodology that employs large language models for semantic analysis while explicitly structuring the traceability process across multiple abstraction levels. Rather than performing direct specification-to-code matching, the proposed approach progressively narrows the search space through repository-level structure inference, file-level relevance estimation, and fine-grained symbollevel alignment. The method extends beyond function-centric mapping by explicitly covering macros, structs, constants, configuration parameters, and register definitions commonly found in systems-level C/C++ codebases. We evaluate the approach on multiple open-source embedded systems repositories using manually curated datasheet-to-code ground truth. Experimental results show substantial improvements over traditional information-retrieval-based baselines, achieving up to 73.3% file mapping accuracy. We significantly reduce computational overhead, lowering total LLM token consumption by 84% and end-to-end runtime by approximately 80%. This methodology supports automated analysis of large embedded software systems and enables downstream applications such as training data generation for systems-aware machine learning models, standards compliance verification, and large-scale specification coverage analysis.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† SpecMapï¼Œä¸€ç§ç”¨äºç³»ç»Ÿå·¥ç¨‹ä¸­æ•°æ®æ‰‹å†Œåˆ°ä»£ç è¿½æº¯é“¾è·¯æ¢å¤ (Traceability Link Recovery) çš„åˆ†å±‚å¤§è¯­è¨€æ¨¡å‹ (LLM) æ™ºèƒ½ä½“æ¡†æ¶ã€‚é’ˆå¯¹åµŒå…¥å¼ç³»ç»Ÿä¸­æ‰‹åŠ¨æ˜ å°„è§„æ ¼è¯´æ˜ä¹¦ä¸å¤§è§„æ¨¡ä»£ç åº“çš„æŒ‘æˆ˜ï¼Œä»¥åŠä¼ ç»Ÿä¿¡æ¯æ£€ç´¢ (Information Retrieval) æŠ€æœ¯éš¾ä»¥æ•æ‰è¯­ä¹‰å’Œç»“æ„åŒ–å…³ç³»çš„å±€é™ï¼ŒSpecMap é‡‡ç”¨äº†ä¸€ç§åˆ†å±‚æ˜ å°„æ–¹æ³•ã€‚è¯¥æ–¹æ³•é€šè¿‡ä»“åº“çº§ç»“æ„æ¨æ–­ (Repository-level Structure Inference)ã€æ–‡ä»¶çº§ç›¸å…³æ€§ä¼°è®¡å’Œç»†ç²’åº¦çš„ç¬¦å·çº§å¯¹é½ (Symbol-level Alignment) é€æ­¥ç¼©å°æœç´¢ç©ºé—´ï¼Œèƒ½å¤Ÿæ˜¾å¼å¤„ç† C/C++ ä»£ç ä¸­çš„å® (Macros)ã€ç»“æ„ä½“ (Structs) å’Œå¯„å­˜å™¨å®šä¹‰ (Register Definitions)ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSpecMap åœ¨æ–‡ä»¶æ˜ å°„å‡†ç¡®ç‡ä¸Šè¾¾åˆ°äº† 73.3%ï¼Œæ˜¾è‘—ä¼˜äºä¼ ç»ŸåŸºçº¿æ¨¡å‹ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•å°† LLM çš„ Token æ¶ˆè€—é™ä½äº† 84%ï¼Œç«¯åˆ°ç«¯è¿è¡Œæ—¶é—´ç¼©çŸ­äº†çº¦ 80%ï¼Œæœ‰æ•ˆæå‡äº†è®¡ç®—æ•ˆç‡ã€‚è¯¥ç ”ç©¶ä¸ä»…æ”¯æŒå¤§è§„æ¨¡è½¯ä»¶ç³»ç»Ÿçš„è‡ªåŠ¨åŒ–åˆ†æï¼Œè¿˜ä¸ºä¸‹æ¸¸çš„æ ‡å‡†åˆè§„æ€§éªŒè¯å’Œç³»ç»Ÿæ„ŸçŸ¥æœºå™¨å­¦ä¹ æ¨¡å‹çš„è®­ç»ƒæ•°æ®ç”Ÿæˆæä¾›äº†æœ‰åŠ›æ”¯æŒã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11688v1",
      "published_date": "2026-01-16 11:50:18 UTC",
      "updated_date": "2026-01-16 11:50:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:59:07.227512+00:00"
    },
    {
      "arxiv_id": "2601.11207v1",
      "title": "LoRA as Oracle",
      "title_zh": "LoRA ä½œä¸ºç¥è°•",
      "authors": [
        "Marco Arazzi",
        "Antonino Nocera"
      ],
      "abstract": "Backdoored and privacy-leaking deep neural networks pose a serious threat to the deployment of machine learning systems in security-critical settings. Existing defenses for backdoor detection and membership inference typically require access to clean reference models, extensive retraining, or strong assumptions about the attack mechanism. In this work, we introduce a novel LoRA-based oracle framework that leverages low-rank adaptation modules as a lightweight, model-agnostic probe for both backdoor detection and membership inference.\n  Our approach attaches task-specific LoRA adapters to a frozen backbone and analyzes their optimization dynamics and representation shifts when exposed to suspicious samples. We show that poisoned and member samples induce distinctive low-rank updates that differ significantly from those generated by clean or non-member data. These signals can be measured using simple ranking and energy-based statistics, enabling reliable inference without access to the original training data or modification of the deployed model.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† LoRA as Oracle æ¡†æ¶ï¼Œåˆ©ç”¨ä½ç§©è‡ªé€‚åº” (LoRA) æ¨¡å—ä½œä¸ºè½»é‡çº§ä¸”æ¨¡å‹æ— å…³çš„æ¢é’ˆï¼Œæ—¨åœ¨è§£å†³æ·±åº¦ç¥ç»ç½‘ç»œé¢ä¸´çš„åé—¨æ£€æµ‹ (backdoor detection) å’Œæˆå‘˜æ¨ç† (membership inference) éš¾é¢˜ã€‚è¯¥æ–¹æ³•é€šè¿‡åœ¨å†»ç»“çš„éª¨å¹²ç½‘ç»œä¸Šé™„åŠ ç‰¹å®šä»»åŠ¡çš„ LoRA é€‚é…å™¨ï¼Œå®æ—¶åˆ†æå…¶åœ¨æ¥è§¦å¯ç–‘æ ·æœ¬æ—¶çš„ä¼˜åŒ–åŠ¨æ€å’Œè¡¨ç¤ºåç§» (representation shifts)ã€‚ç ”ç©¶å‘ç°ï¼Œä¸­æ¯’æ ·æœ¬å’Œæˆå‘˜æ ·æœ¬ä¼šè¯±å¯¼äº§ç”Ÿä¸å¹²å‡€æ•°æ®æ˜¾è‘—ä¸åŒçš„ä½ç§©æ›´æ–°ä¿¡å·ï¼Œè¿™äº›ä¿¡å·å¯ä»¥é€šè¿‡ç®€å•çš„æ’åå’ŒåŸºäºèƒ½é‡çš„ç»Ÿè®¡é‡ (energy-based statistics) è¿›è¡Œæœ‰æ•ˆè¡¡é‡ã€‚è¯¥æ¡†æ¶çš„æ ¸å¿ƒä¼˜åŠ¿åœ¨äºæ— éœ€è®¿é—®åŸå§‹è®­ç»ƒæ•°æ®ï¼Œä¹Ÿä¸å¿…å¯¹å·²éƒ¨ç½²çš„æ¨¡å‹è¿›è¡Œä»»ä½•ä¿®æ”¹ã€‚å®éªŒè¯æ˜è¯¥æ–¹æ¡ˆèƒ½å¤Ÿå®ç°å¯é çš„æ¨ç†ï¼Œä¸ºå®‰å…¨å…³é”®ç¯å¢ƒä¸‹çš„æœºå™¨å­¦ä¹ ç³»ç»Ÿéƒ¨ç½²æä¾›äº†ä¸€ç§é«˜æ•ˆä¸”å®ç”¨çš„é˜²å¾¡æœºåˆ¶ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11207v1",
      "published_date": "2026-01-16 11:32:32 UTC",
      "updated_date": "2026-01-16 11:32:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:59:07.351891+00:00"
    },
    {
      "arxiv_id": "2601.11687v1",
      "title": "Semantic Caching and Intent-Driven Context Optimization for Multi-Agent Natural Language to Code Systems",
      "title_zh": "é¢å‘å¤šæ™ºèƒ½ä½“è‡ªç„¶è¯­è¨€è½¬ä»£ç ç³»ç»Ÿçš„è¯­ä¹‰ç¼“å­˜ä¸æ„å›¾é©±åŠ¨ä¸Šä¸‹æ–‡ä¼˜åŒ–",
      "authors": [
        "Harmohit Singh"
      ],
      "abstract": "We present a production-optimized multi-agent system designed to translate natural language queries into executable Python code for structured data analytics. Unlike systems that rely on expensive frontier models, our approach achieves high accuracy and cost efficiency through three key innovations: (1) a semantic caching system with LLM-based equivalence detection and structured adaptation hints that provides cache hit rates of 67% on production queries; (2) a dual-threshold decision mechanism that separates exact-match retrieval from reference-guided generation; and (3) an intent-driven dynamic prompt assembly system that reduces token consumption by 40-60% through table-aware context filtering. The system has been deployed in production for enterprise inventory management, processing over 10,000 queries with an average latency of 8.2 seconds and 94.3% semantic accuracy. We describe the architecture, present empirical results from production deployment, and discuss practical considerations for deploying LLM-based analytics systems at scale.",
      "tldr_zh": "è¯¥ç ”ç©¶ä»‹ç»äº†ä¸€ç§é’ˆå¯¹ç»“æ„åŒ–æ•°æ®åˆ†æç”Ÿäº§ä¼˜åŒ–çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼Œæ—¨åœ¨å°†è‡ªç„¶è¯­è¨€æŸ¥è¯¢é«˜æ•ˆåœ°è½¬æ¢ä¸ºå¯æ‰§è¡Œçš„ Python ä»£ç ã€‚ç³»ç»Ÿçš„æ ¸å¿ƒåˆ›æ–°ä¹‹ä¸€æ˜¯åŸºäº LLM ç­‰æ•ˆæ£€æµ‹å’Œç»“æ„åŒ–é€‚é…æç¤ºçš„è¯­ä¹‰ç¼“å­˜(Semantic Caching)ç³»ç»Ÿï¼Œä½¿å…¶åœ¨ç”Ÿäº§æŸ¥è¯¢ä¸­çš„ç¼“å­˜å‘½ä¸­ç‡è¾¾åˆ° 67%ã€‚åŒæ—¶ï¼Œè¯¥ç³»ç»Ÿé‡‡ç”¨åŒé˜ˆå€¼å†³ç­–æœºåˆ¶(Dual-threshold decision mechanism)å¹³è¡¡ç²¾ç¡®åŒ¹é…æ£€ç´¢ä¸å‚è€ƒå¼•å¯¼ç”Ÿæˆï¼Œå¹¶é€šè¿‡æ„å›¾é©±åŠ¨çš„åŠ¨æ€æç¤ºè£…é…ç³»ç»Ÿå°† Token æ¶ˆè€—é™ä½äº† 40-60%ã€‚è¯¥ç³»ç»Ÿå·²åœ¨ä¼ä¸šåº“å­˜ç®¡ç†ä¸­å®é™…éƒ¨ç½²å¹¶å¤„ç†äº†è¶…è¿‡ 10,000 æ¡æŸ¥è¯¢ï¼Œå®ç°äº† 94.3% çš„è¯­ä¹‰å‡†ç¡®ç‡å’Œ 8.2 ç§’çš„å¹³å‡å»¶è¿Ÿã€‚è¿™é¡¹å·¥ä½œé€šè¿‡å±•ç¤ºæ¶æ„è®¾è®¡å’Œå®è¯ç»“æœï¼Œä¸ºå¤§è§„æ¨¡éƒ¨ç½²åŸºäº LLM çš„åˆ†æç³»ç»Ÿæä¾›äº†å…³é”®çš„å®è·µæŒ‡å¯¼ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11687v1",
      "published_date": "2026-01-16 11:32:20 UTC",
      "updated_date": "2026-01-16 11:32:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:59:33.249872+00:00"
    },
    {
      "arxiv_id": "2601.11202v1",
      "title": "Epistemic Control and the Normativity of Machine Learning-Based Science",
      "title_zh": "è®¤è¯†è®ºæ§åˆ¶ä¸åŸºäºæœºå™¨å­¦ä¹ çš„ç§‘å­¦çš„è§„èŒƒæ€§",
      "authors": [
        "Emanuele Ratti"
      ],
      "abstract": "The past few years have witnessed an increasing use of machine learning (ML) systems in science. Paul Humphreys has argued that, because of specific characteristics of ML systems, human scientists are pushed out of the loop of science. In this chapter, I investigate to what extent this is true. First, I express these concerns in terms of what I call epistemic control. I identify two conditions for epistemic control, called tracking and tracing, drawing on works in philosophy of technology. With this new understanding of the problem, I then argue against Humphreys pessimistic view. Finally, I construct a more nuanced view of epistemic control in ML-based science.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†æœºå™¨å­¦ä¹ (Machine Learning)ç³»ç»Ÿåœ¨ç§‘å­¦é¢†åŸŸæ—¥ç›Šå¹¿æ³›çš„åº”ç”¨åŠå…¶å¯¹äººç±»ç§‘å­¦å®¶åœ°ä½çš„å½±å“ã€‚ä½œè€…é’ˆå¯¹ Paul Humphreys æå‡ºçš„å…³äºäººç±»ç§‘å­¦å®¶æ­£è¢«æ’é™¤åœ¨ç§‘ç ”ç¯èŠ‚ä¹‹å¤–çš„è§‚ç‚¹ï¼Œå¼•å…¥äº†è®¤çŸ¥æ§åˆ¶(Epistemic Control)çš„æ¦‚å¿µè¿›è¡Œæ·±å…¥åˆ†æã€‚é€šè¿‡å€Ÿé‰´æŠ€æœ¯å“²å­¦ï¼Œç ”ç©¶è¯†åˆ«äº†å®ç° Epistemic Control çš„ä¸¤ä¸ªæ ¸å¿ƒæ¡ä»¶ï¼šè¿½è¸ª(Tracking)ä¸æº¯æº(Tracing)ã€‚åŸºäºè¿™ä¸€ç†è®ºæ¡†æ¶ï¼Œä½œè€…åé©³äº† Humphreys çš„æ‚²è§‚ç«‹åœºï¼Œå¹¶è®ºè¯äº†äººç±»åœ¨ ML é©±åŠ¨çš„ç§‘å­¦ä¸­ç»´æŒæ§åˆ¶æƒçš„å¯èƒ½æ€§ã€‚æœ€ç»ˆï¼Œæœ¬æ–‡ä¸ºåŸºäº Machine Learning çš„ç§‘å­¦ç ”ç©¶æ„å»ºäº†ä¸€ç§å…³äº Epistemic Control æ›´ä¸ºç»†è‡´ä¸”å…·æœ‰è§„èŒƒæ€§çš„è§†è§’ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11202v1",
      "published_date": "2026-01-16 11:24:22 UTC",
      "updated_date": "2026-01-16 11:24:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:59:25.129921+00:00"
    },
    {
      "arxiv_id": "2601.11200v1",
      "title": "FAQ: Mitigating Quantization Error via Regenerating Calibration Data with Family-Aware Quantization",
      "title_zh": "FAQï¼šé€šè¿‡åŒæ—æ„ŸçŸ¥é‡åŒ–é‡æ„æ ¡å‡†æ•°æ®ä»¥ç¼“è§£é‡åŒ–è¯¯å·®",
      "authors": [
        "Haiyang Xiao",
        "Weiqing Li",
        "Jinyue Guo",
        "Guochao Jiang",
        "Guohua Liu",
        "Yuewei Zhang"
      ],
      "abstract": "Although post-training quantization (PTQ) provides an efficient numerical compression scheme for deploying large language models (LLMs) on resource-constrained devices, the representativeness and universality of calibration data remain a core bottleneck in determining the accuracy of quantization parameters. Traditional PTQ methods typically rely on limited samples, making it difficult to capture the activation distribution during the inference phase, leading to biases in quantization parameters. To address this, we propose \\textbf{FAQ} (Family-Aware Quantization), a calibration data regeneration framework that leverages prior knowledge from LLMs of the same family to generate high-fidelity calibration samples. Specifically, FAQ first inputs the original calibration samples into a larger LLM from the same family as the target model, regenerating a series of high-fidelity calibration data using a highly consistent knowledge system. Subsequently, this data, carrying Chain-of-Thought reasoning and conforming to the expected activation distribution, undergoes group competition under expert guidance to select the best samples, which are then re-normalized to enhance the effectiveness of standard PTQ. Experiments on multiple model series, including Qwen3-8B, show that FAQ reduces accuracy loss by up to 28.5\\% compared to the baseline with original calibration data, demonstrating its powerful potential and contribution.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†FAQ (Family-Aware Quantization)ï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨è®­ç»ƒåé‡åŒ–(Post-training quantization, PTQ)è¿‡ç¨‹ä¸­ç”±äºæ ¡å‡†æ•°æ®ä»£è¡¨æ€§ä¸è¶³å¯¼è‡´é‡åŒ–è¯¯å·®é—®é¢˜çš„æ¡†æ¶ã€‚FAQåˆ©ç”¨åŒç³»åˆ—æ›´å¤§è§„æ¨¡LLMçš„å…ˆéªŒçŸ¥è¯†æ¥é‡æ–°ç”Ÿæˆé«˜ä¿çœŸæ ¡å‡†æ ·æœ¬ï¼Œç¡®ä¿æ•°æ®ç¬¦åˆé¢„æœŸçš„æ¿€æ´»åˆ†å¸ƒå¹¶åŒ…å«é“¾å¼æ€ç»´(Chain-of-Thought)æ¨ç†ã€‚è¯¥æ¡†æ¶é€šè¿‡ä¸“å®¶æŒ‡å¯¼ä¸‹çš„ç»„å†…ç«äº‰æœºåˆ¶ç­›é€‰å‡ºæœ€ä½³æ ·æœ¬ï¼Œå¹¶è¿›è¡Œé‡æ–°å½’ä¸€åŒ–ä»¥å¢å¼ºæ ‡å‡†PTQçš„æœ‰æ•ˆæ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨åŒ…æ‹¬Qwen3-8Båœ¨å†…çš„å¤šä¸ªæ¨¡å‹ç³»åˆ—ä¸Šï¼ŒFAQç›¸æ¯”ä½¿ç”¨åŸå§‹æ ¡å‡†æ•°æ®çš„åŸºçº¿æ–¹æ³•å¯å‡å°‘é«˜è¾¾28.5%çš„ç²¾åº¦æŸå¤±ã€‚è¿™ä¸€æ–¹æ³•è¯æ˜äº†é€šè¿‡æ¨¡å‹å®¶æ—å†…éƒ¨çŸ¥è¯†è¿ç§»ç”Ÿæˆé«˜è´¨é‡æ ¡å‡†æ•°æ®åœ¨æå‡é‡åŒ–ç²¾åº¦æ–¹é¢çš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11200v1",
      "published_date": "2026-01-16 11:22:23 UTC",
      "updated_date": "2026-01-16 11:22:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:59:30.830346+00:00"
    },
    {
      "arxiv_id": "2601.11199v1",
      "title": "SD-RAG: A Prompt-Injection-Resilient Framework for Selective Disclosure in Retrieval-Augmented Generation",
      "title_zh": "SD-RAGï¼šé¢å‘æ£€ç´¢å¢å¼ºç”Ÿæˆä¸­é€‰æ‹©æ€§æŠ«éœ²çš„æŠ—æç¤ºæ³¨å…¥æ¡†æ¶",
      "authors": [
        "Aiman Al Masoud",
        "Marco Arazzi",
        "Antonino Nocera"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) has attracted significant attention due to its ability to combine the generative capabilities of Large Language Models (LLMs) with knowledge obtained through efficient retrieval mechanisms over large-scale data collections. Currently, the majority of existing approaches overlook the risks associated with exposing sensitive or access-controlled information directly to the generation model. Only a few approaches propose techniques to instruct the generative model to refrain from disclosing sensitive information; however, recent studies have also demonstrated that LLMs remain vulnerable to prompt injection attacks that can override intended behavioral constraints. For these reasons, we propose a novel approach to Selective Disclosure in Retrieval-Augmented Generation, called SD-RAG, which decouples the enforcement of security and privacy constraints from the generation process itself. Rather than relying on prompt-level safeguards, SD-RAG applies sanitization and disclosure controls during the retrieval phase, prior to augmenting the language model's input. Moreover, we introduce a semantic mechanism to allow the ingestion of human-readable dynamic security and privacy constraints together with an optimized graph-based data model that supports fine-grained, policy-aware retrieval. Our experimental evaluation demonstrates the superiority of SD-RAG over baseline existing approaches, achieving up to a $58\\%$ improvement in the privacy score, while also showing a strong resilience to prompt injection attacks targeting the generative model.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†SD-RAGï¼Œä¸€ä¸ªé’ˆå¯¹æ£€ç´¢å¢å¼ºç”Ÿæˆ(Retrieval-Augmented Generation, RAG)ä¸­é€‰æ‹©æ€§æŠ«éœ²(Selective Disclosure)é—®é¢˜çš„æŠ—æç¤ºæ³¨å…¥æ”»å‡»(Prompt-Injection-Resilient)æ¡†æ¶ã€‚é’ˆå¯¹ç°æœ‰æ–¹æ³•åœ¨å¤„ç†æ•æ„Ÿä¿¡æ¯æ—¶å®¹æ˜“å—åˆ°æç¤ºæ³¨å…¥(Prompt Injection)æ”»å‡»å¹¶ç»•è¿‡è¡Œä¸ºçº¦æŸçš„ç¼ºé™·ï¼ŒSD-RAGå°†å®‰å…¨ä¸éšç§çº¦æŸçš„æ‰§è¡Œä»ç”Ÿæˆè¿‡ç¨‹ä¸­è§£è€¦ã€‚è¯¥æ¡†æ¶é€šè¿‡åœ¨æ£€ç´¢é˜¶æ®µè€Œéç”Ÿæˆé˜¶æ®µåº”ç”¨æ¸…ç†(Sanitization)å’ŒæŠ«éœ²æ§åˆ¶ï¼Œç¡®ä¿åœ¨å¢å¼ºè¯­è¨€æ¨¡å‹è¾“å…¥å‰å®Œæˆå®‰å…¨è¿‡æ»¤ã€‚ç ”ç©¶è¿˜å¼•å…¥äº†è¯­ä¹‰æœºåˆ¶æ¥å¤„ç†åŠ¨æ€çš„å®‰å…¨ä¸éšç§çº¦æŸï¼Œå¹¶åˆ©ç”¨ä¼˜åŒ–çš„åŸºäºå›¾çš„æ•°æ®æ¨¡å‹(Graph-based Data Model)å®ç°ç»†ç²’åº¦çš„ç­–ç•¥æ„ŸçŸ¥æ£€ç´¢ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSD-RAGåœ¨éšç§è¯„åˆ†ä¸Šæ¯”ç°æœ‰æ–¹æ³•æå‡äº†é«˜è¾¾58%ï¼Œå¹¶åœ¨æŠµå¾¡é’ˆå¯¹ç”Ÿæˆæ¨¡å‹çš„æç¤ºæ³¨å…¥æ”»å‡»æ–¹é¢è¡¨ç°å‡ºæå¼ºçš„é²æ£’æ€§ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11199v1",
      "published_date": "2026-01-16 11:22:02 UTC",
      "updated_date": "2026-01-16 11:22:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:59:25.755688+00:00"
    },
    {
      "arxiv_id": "2601.11196v1",
      "title": "Artificial Intelligence and the US Economy: An Accounting Perspective on Investment and Production",
      "title_zh": "äººå·¥æ™ºèƒ½ä¸ US ç»æµï¼šåŸºäºæŠ•èµ„ä¸ç”Ÿäº§çš„æ ¸ç®—è§†è§’",
      "authors": [
        "Luisa Carpinelli",
        "Filippo Natoli",
        "Marco Taboga"
      ],
      "abstract": "Artificial intelligence (AI) has moved to the center of policy, market, and academic debates, but its macroeconomic footprint is still only partly understood. This paper provides an overview on how the current AI wave is captured in US national accounts, combining a simple macro-accounting framework with a stylized description of the AI production process. We highlight the crucial role played by data centers, which constitute the backbone of the AI ecosystem and have attracted formidable investment in 2025, as they are indispensable for meeting the rapidly increasing worldwide demand for AI services. We document that the boom in IT and AI-related capital expenditure in the first three quarters of the year has given an outsized boost to aggregate demand, while its contribution to GDP growth is smaller once the high import content of AI hardware is netted out. Furthermore, simple calculations suggest that, at current utilization rates and pricing, the production of services originating in new AI data centers could contribute to GDP over the turn of the next quarters on a scale comparable to that of investment spending to date. Short reinvestment cycles and uncertainty about future AI demand, while not currently acting as a macroeconomic drag, can nevertheless fuel macroeconomic risks over the medium term.",
      "tldr_zh": "è¯¥ç ”ç©¶ä»å®è§‚ä¼šè®¡(macro-accounting)è§†è§’å‡ºå‘ï¼Œç»“åˆAIç”Ÿäº§è¿‡ç¨‹çš„ç¨‹å¼åŒ–æè¿°ï¼Œæ·±å…¥æ¢è®¨äº†å½“å‰äººå·¥æ™ºèƒ½(AI)æµªæ½®åœ¨ç¾å›½å›½æ°‘ç»æµæ ¸ç®—ä¸­çš„ä½“ç°ã€‚ç ”ç©¶å¼ºè°ƒäº†æ•°æ®ä¸­å¿ƒ(data centers)ä½œä¸ºAIç”Ÿæ€ç³»ç»Ÿæ ¸å¿ƒæ”¯æ’‘çš„å…³é”®ä½œç”¨ï¼ŒæŒ‡å‡ºå…¶åœ¨2025å¹´å¸å¼•äº†å·¨å¤§çš„æŠ•èµ„ä»¥æ»¡è¶³å…¨çƒå¯¹AIæœåŠ¡çš„å¿«é€Ÿå¢é•¿éœ€æ±‚ã€‚æ•°æ®æ˜¾ç¤ºï¼Œ2025å¹´å‰ä¸‰å­£åº¦ITå’ŒAIç›¸å…³çš„èµ„æœ¬æ”¯å‡º(capital expenditure)æ˜¾è‘—ææŒ¯äº†æ€»éœ€æ±‚(aggregate demand)ï¼Œä½†ç”±äºAIç¡¬ä»¶çš„é«˜åº¦è¿›å£ä¾èµ–ï¼Œå…¶å¯¹GDPå¢é•¿çš„å®é™…è´¡çŒ®åœ¨æ‰£é™¤è¿›å£åæœ‰æ‰€ç¼©å‡ã€‚ç®€å•æµ‹ç®—è¡¨æ˜ï¼Œåœ¨ç°æœ‰çš„åˆ©ç”¨ç‡å’Œå®šä»·æ°´å¹³ä¸‹ï¼Œæ–°è½æˆæ•°æ®ä¸­å¿ƒäº§ç”Ÿçš„æœåŠ¡äº§å‡ºå¯¹æœªæ¥å‡ å­£åº¦GDPçš„è´¡çŒ®è§„æ¨¡å°†ä¸å½“å‰çš„æŠ•èµ„æ”¯å‡ºç›¸å½“ã€‚æœ€åï¼Œç ”ç©¶æŒ‡å‡ºè¾ƒçŸ­çš„å†æŠ•èµ„å‘¨æœŸ(reinvestment cycles)ä»¥åŠæœªæ¥AIéœ€æ±‚çš„ä¸ç¡®å®šæ€§ï¼Œè™½ç„¶ç›®å‰æœªæ„æˆå®è§‚ç»æµé˜»åŠ›ï¼Œä½†å¯èƒ½åœ¨ä¸­æœŸå†…å¼•å‘å®è§‚ç»æµé£é™©ã€‚",
      "categories": [
        "econ.GN",
        "cs.AI"
      ],
      "primary_category": "econ.GN",
      "comment": "35 pages, 11 figures, pre-print",
      "pdf_url": "https://arxiv.org/pdf/2601.11196v1",
      "published_date": "2026-01-16 11:15:43 UTC",
      "updated_date": "2026-01-16 11:15:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:59:37.704075+00:00"
    },
    {
      "arxiv_id": "2601.11189v1",
      "title": "Policy-Based Deep Reinforcement Learning Hyperheuristics for Job-Shop Scheduling Problems",
      "title_zh": "æ±‚è§£ä½œä¸šè½¦é—´è°ƒåº¦é—®é¢˜çš„åŸºäºç­–ç•¥çš„æ·±åº¦å¼ºåŒ–å­¦ä¹ è¶…å¯å‘å¼ç®—æ³•",
      "authors": [
        "Sofiene Lassoued",
        "Asrat Gobachew",
        "Stefan Lier",
        "Andreas Schwung"
      ],
      "abstract": "This paper proposes a policy-based deep reinforcement learning hyper-heuristic framework for solving the Job Shop Scheduling Problem. The hyper-heuristic agent learns to switch scheduling rules based on the system state dynamically. We extend the hyper-heuristic framework with two key mechanisms. First, action prefiltering restricts decision-making to feasible low-level actions, enabling low-level heuristics to be evaluated independently of environmental constraints and providing an unbiased assessment. Second, a commitment mechanism regulates the frequency of heuristic switching. We investigate the impact of different commitment strategies, from step-wise switching to full-episode commitment, on both training behavior and makespan. Additionally, we compare two action selection strategies at the policy level: deterministic greedy selection and stochastic sampling. Computational experiments on standard JSSP benchmarks demonstrate that the proposed approach outperforms traditional heuristics, metaheuristics, and recent neural network-based scheduling methods",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºç­–ç•¥çš„æ·±åº¦å¼ºåŒ–å­¦ä¹ (Deep Reinforcement Learning, DRL)è¶…å¯å‘å¼æ¡†æ¶ï¼Œæ—¨åœ¨é«˜æ•ˆè§£å†³ä½œä¸šè½¦é—´è°ƒåº¦é—®é¢˜(Job Shop Scheduling Problem, JSSP)ã€‚è¯¥æ¡†æ¶å…è®¸æ™ºèƒ½ä½“æ ¹æ®ç³»ç»ŸçŠ¶æ€åŠ¨æ€åˆ‡æ¢è°ƒåº¦è§„åˆ™ï¼Œå¹¶å¼•å…¥äº†åŠ¨ä½œé¢„è¿‡æ»¤(Action Prefiltering)å’Œæ‰¿è¯ºæœºåˆ¶(Commitment Mechanism)ä¸¤é¡¹æ ¸å¿ƒæŠ€æœ¯ã€‚åŠ¨ä½œé¢„è¿‡æ»¤é€šè¿‡å°†å†³ç­–é™åˆ¶åœ¨å¯è¡ŒèŒƒå›´å†…ï¼Œå®ç°äº†å¯¹ä½çº§å¯å‘å¼ç®—æ³•çš„æ— åå·®è¯„ä¼°ï¼›æ‰¿è¯ºæœºåˆ¶åˆ™ç”¨äºè°ƒèŠ‚å¯å‘å¼åˆ‡æ¢çš„é¢‘ç‡ï¼Œä»¥ä¼˜åŒ–è®­ç»ƒæ•ˆç‡å’Œå®Œå·¥æ—¶é—´(Makespan)ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜æ·±å…¥æ¢è®¨äº†ç¡®å®šæ€§è´ªå©ªé€‰æ‹©ä¸éšæœºé‡‡æ ·ä¸¤ç§åŠ¨ä½œé€‰æ‹©ç­–ç•¥çš„æ•ˆæœã€‚åœ¨æ ‡å‡†JSSPåŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ€§èƒ½ä¸Šä¼˜äºä¼ ç»Ÿçš„å¯å‘å¼ã€å…ƒå¯å‘å¼ä»¥åŠç°æœ‰çš„ç¥ç»ç½‘ç»œè°ƒåº¦æ–¹æ³•ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11189v1",
      "published_date": "2026-01-16 11:03:47 UTC",
      "updated_date": "2026-01-16 11:03:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:59:41.080802+00:00"
    },
    {
      "arxiv_id": "2601.11178v1",
      "title": "TANDEM: Temporal-Aware Neural Detection for Multimodal Hate Speech",
      "title_zh": "TANDEMï¼šé¢å‘å¤šæ¨¡æ€ä»‡æ¨è¨€è®ºçš„æ—¶åºæ„ŸçŸ¥ç¥ç»æ£€æµ‹",
      "authors": [
        "Girish A. Koushik",
        "Helen Treharne",
        "Diptesh Kanojia"
      ],
      "abstract": "Social media platforms are increasingly dominated by long-form multimodal content, where harmful narratives are constructed through a complex interplay of audio, visual, and textual cues. While automated systems can flag hate speech with high accuracy, they often function as \"black boxes\" that fail to provide the granular, interpretable evidence, such as precise timestamps and target identities, required for effective human-in-the-loop moderation. In this work, we introduce TANDEM, a unified framework that transforms audio-visual hate detection from a binary classification task into a structured reasoning problem. Our approach employs a novel tandem reinforcement learning strategy where vision-language and audio-language models optimize each other through self-constrained cross-modal context, stabilizing reasoning over extended temporal sequences without requiring dense frame-level supervision. Experiments across three benchmark datasets demonstrate that TANDEM significantly outperforms zero-shot and context-augmented baselines, achieving 0.73 F1 in target identification on HateMM (a 30% improvement over state-of-the-art) while maintaining precise temporal grounding. We further observe that while binary detection is robust, differentiating between offensive and hateful content remains challenging in multi-class settings due to inherent label ambiguity and dataset imbalance. More broadly, our findings suggest that structured, interpretable alignment is achievable even in complex multimodal settings, offering a blueprint for the next generation of transparent and actionable online safety moderation tools.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç¤¾äº¤åª’ä½“é•¿ç¯‡å¤šæ¨¡æ€å†…å®¹ä¸­çš„ä»‡æ¨è¨€è®ºï¼ˆhate speechï¼‰æ£€æµ‹é—®é¢˜ï¼Œæå‡ºäº†åä¸º TANDEM çš„ç»Ÿä¸€æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰ç³»ç»Ÿç¼ºä¹å¯è§£é‡Šæ€§åŠç²¾ç¡®è¯æ®é“¾çš„é—®é¢˜ã€‚è¯¥æ¡†æ¶å°†æ£€æµ‹ä»»åŠ¡è½¬åŒ–ä¸ºç»“æ„åŒ–æ¨ç†é—®é¢˜ï¼Œé‡‡ç”¨ä¸€ç§æ–°é¢–çš„ä¸²è”å¼ºåŒ–å­¦ä¹ ï¼ˆtandem reinforcement learningï¼‰ç­–ç•¥ï¼Œåˆ©ç”¨è§†è§‰è¯­è¨€ï¼ˆvision-languageï¼‰å’ŒéŸ³é¢‘è¯­è¨€ï¼ˆaudio-languageï¼‰æ¨¡å‹çš„ç›¸äº’ä¼˜åŒ–ï¼Œåœ¨æ— éœ€å¯†é›†å¸§çº§ç›‘ç£çš„æƒ…å†µä¸‹å®ç°äº†ç¨³å®šçš„é•¿æ—¶åºæ¨ç†ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒTANDEM åœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šæ˜¾è‘—ä¼˜äºåŸºçº¿æ¨¡å‹ï¼Œå…¶åœ¨ HateMM æ•°æ®é›†ä¸Šçš„ç›®æ ‡è¯†åˆ« F1 åˆ†æ•°è¾¾åˆ° 0.73ï¼Œæ¯”ç°æœ‰æœ€å…ˆè¿›æŠ€æœ¯æå‡äº† 30% å¹¶ä¿æŒäº†ç²¾ç¡®çš„æ—¶é—´å®šä½ï¼ˆtemporal groundingï¼‰ã€‚å°½ç®¡å¤šåˆ†ç±»è®¾ç½®ä¸‹çš„æ ‡ç­¾æ­§ä¹‰ä»æ˜¯æŒ‘æˆ˜ï¼Œä½† TANDEM è¯æ˜äº†åœ¨å¤æ‚å¤šæ¨¡æ€ç¯å¢ƒä¸‹å®ç°ç»“æ„åŒ–ã€å¯è§£é‡Šå¯¹é½çš„å¯è¡Œæ€§ï¼Œä¸ºé€æ˜ä¸”å¯æ“ä½œçš„åœ¨çº¿å®‰å…¨å®¡æ ¸å·¥å…·æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.MM",
        "cs.SI"
      ],
      "primary_category": "cs.AI",
      "comment": "Under review at ICWSM 2026",
      "pdf_url": "https://arxiv.org/pdf/2601.11178v1",
      "published_date": "2026-01-16 10:52:12 UTC",
      "updated_date": "2026-01-16 10:52:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:00:19.864871+00:00"
    },
    {
      "arxiv_id": "2601.11686v1",
      "title": "Proof of Concept: Multi-Target Wildfire Risk Prediction and Large Language Model Synthesis",
      "title_zh": "æ¦‚å¿µéªŒè¯ï¼šå¤šç›®æ ‡é‡ç«é£é™©é¢„æµ‹ä¸å¤§è¯­è¨€æ¨¡å‹ç»¼åˆ",
      "authors": [
        "Nicolas Caron",
        "Christophe Guyeux",
        "Hassan Noura",
        "Benjamin Aynes"
      ],
      "abstract": "Current state-of-the-art approaches to wildfire risk assessment often overlook operational needs, limiting their practical value for first responders and firefighting services. Effective wildfire management requires a multi-target analysis that captures the diverse dimensions of wildfire risk, including meteorological danger, ignition activity, intervention complexity, and resource mobilization, rather than relying on a single predictive indicator. In this proof of concept, we propose the development of a hybrid framework that combines predictive models for each risk dimension with large language models (LLMs) to synthesize heterogeneous outputs into structured, actionable reports.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å½“å‰é‡ç«é£é™©è¯„ä¼°æ¨¡å‹å¿½è§†å®é™…æ“ä½œéœ€æ±‚çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ä¸ªç»“åˆå¤šç›®æ ‡é‡ç«é£é™©é¢„æµ‹ä¸ Large Language Models (LLMs) åˆæˆçš„æ··åˆæ¡†æ¶ã€‚æœ‰æ•ˆçš„é‡ç«ç®¡ç†éœ€è¦æ•æ‰æ°”è±¡å±é™©ï¼ˆmeteorological dangerï¼‰ã€ç‚¹ç«æ´»åŠ¨ï¼ˆignition activityï¼‰ã€å¹²é¢„å¤æ‚æ€§ï¼ˆintervention complexityï¼‰å’Œèµ„æºåŠ¨å‘˜ï¼ˆresource mobilizationï¼‰ç­‰å¤šä¸ªç»´åº¦çš„é£é™©ï¼Œè€Œéä¾èµ–å•ä¸€é¢„æµ‹æŒ‡æ ‡ã€‚ä¸ºæ­¤ï¼Œè¯¥ç ”ç©¶å¼€å‘äº†ä¸€å¥— Proof of Concept ç³»ç»Ÿï¼Œå°†å„ç»´åº¦çš„é¢„æµ‹æ¨¡å‹ä¸ LLMs ç›¸ç»“åˆã€‚è¯¥æ¡†æ¶èƒ½å¤Ÿå°†å¼‚æ„çš„è¾“å‡ºæ•°æ®åˆæˆå¹¶è½¬åŒ–ä¸ºç»“æ„åŒ–çš„ã€å…·æœ‰å¯æ“ä½œæ€§çš„æŠ¥å‘Šï¼Œä»è€Œä¸ºä¸€çº¿æ•‘æ´äººå‘˜å’Œæ¶ˆé˜²éƒ¨é—¨æä¾›å†³ç­–æ”¯æŒã€‚è¿™ä¸€ç ”ç©¶è¯æ˜äº†å¤šç›®æ ‡åˆ†æä¸æ¨¡å‹åˆæˆæŠ€æœ¯åœ¨æå‡é‡ç«é£é™©ç®¡ç†å®é™…åº”ç”¨ä»·å€¼æ–¹é¢çš„æ½œåŠ›ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11686v1",
      "published_date": "2026-01-16 10:47:13 UTC",
      "updated_date": "2026-01-16 10:47:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:59:42.122608+00:00"
    },
    {
      "arxiv_id": "2601.11160v1",
      "title": "Clustering High-dimensional Data: Balancing Abstraction and Representation Tutorial at AAAI 2026",
      "title_zh": "é«˜ç»´æ•°æ®èšç±»ï¼šå¹³è¡¡æŠ½è±¡ä¸è¡¨ç¤ºï¼ˆAAAI 2026 æ•™ç¨‹ï¼‰",
      "authors": [
        "Claudia Plant",
        "Lena G. M. Bauer",
        "Christian BÃ¶hm"
      ],
      "abstract": "How to find a natural grouping of a large real data set? Clustering requires a balance between abstraction and representation. To identify clusters, we need to abstract from superfluous details of individual objects. But we also need a rich representation that emphasizes the key features shared by groups of objects that distinguish them from other groups of objects.\n  Each clustering algorithm implements a different trade-off between abstraction and representation. Classical K-means implements a high level of abstraction - details are simply averaged out - combined with a very simple representation - all clusters are Gaussians in the original data space. We will see how approaches to subspace and deep clustering support high-dimensional and complex data by allowing richer representations. However, with increasing representational expressiveness comes the need to explicitly enforce abstraction in the objective function to ensure that the resulting method performs clustering and not just representation learning. We will see how current deep clustering methods define and enforce abstraction through centroid-based and density-based clustering losses. Balancing the conflicting goals of abstraction and representation is challenging. Ideas from subspace clustering help by learning one latent space for the information that is relevant to clustering and another latent space to capture all other information in the data.\n  The tutorial ends with an outlook on future research in clustering. Future methods will more adaptively balance abstraction and representation to improve performance, energy efficiency and interpretability. By automatically finding the sweet spot between abstraction and representation, the human brain is very good at clustering and other related tasks such as single-shot learning. So, there is still much room for improvement.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†é«˜ç»´æ•°æ®èšç±»ä¸­æŠ½è±¡(Abstraction)ä¸è¡¨å¾(Representation)ä¹‹é—´çš„å¹³è¡¡é—®é¢˜ï¼ŒæŒ‡å‡ºæœ‰æ•ˆçš„èšç±»éœ€è¦åœ¨å¿½ç•¥ä¸ªä½“å†—ä½™ç»†èŠ‚çš„åŒæ—¶ï¼Œæå–èƒ½å¤ŸåŒºåˆ†ä¸åŒç»„çš„å…³é”®ç‰¹å¾ã€‚æ–‡ç« å¯¹æ¯”äº†ä¼ ç»Ÿ K-means ç®—æ³•çš„é«˜æŠ½è±¡ã€ç®€å•è¡¨å¾æ¨¡å¼ï¼Œä¸ç°ä»£å­ç©ºé—´èšç±»(Subspace Clustering)å’Œæ·±åº¦èšç±»(Deep Clustering)æ”¯æŒé«˜ç»´åº¦ã€å¤æ‚æ•°æ®çš„ä¸°å¯Œè¡¨å¾èƒ½åŠ›ã€‚é’ˆå¯¹è¡¨å¾èƒ½åŠ›å¢å¼ºå¯èƒ½å¯¼è‡´çš„çº¯è¡¨ç¤ºå­¦ä¹ é—®é¢˜ï¼Œè®ºæ–‡é˜è¿°äº†æ·±åº¦èšç±»å¦‚ä½•é€šè¿‡åŸºäºè´¨å¿ƒ(Centroid-based)å’ŒåŸºäºå¯†åº¦(Density-based)çš„æŸå¤±å‡½æ•°å¼ºåˆ¶æ‰§è¡ŒæŠ½è±¡ã€‚å­ç©ºé—´èšç±»é€šè¿‡å­¦ä¹ ä¸¤ä¸ªç‹¬ç«‹çš„æ½œåœ¨ç©ºé—´ï¼Œåˆ†åˆ«æ•è·ä¸èšç±»ç›¸å…³çš„ä¿¡æ¯å’Œæ•°æ®ä¸­çš„å…¶ä»–ä¿¡æ¯ï¼Œä»è€Œåè°ƒæŠ½è±¡ä¸è¡¨å¾çš„å†²çªã€‚æ•™ç¨‹æœ€åå±•æœ›äº†æœªæ¥èšç±»ç ”ç©¶çš„æ–¹å‘ï¼Œå¼ºè°ƒé€šè¿‡æ›´è‡ªé€‚åº”åœ°å¹³è¡¡æŠ½è±¡ä¸è¡¨å¾ï¼Œæå‡ç®—æ³•åœ¨æ€§èƒ½ã€èƒ½æºæ•ˆç‡å’Œå¯è§£é‡Šæ€§(Interpretability)æ–¹é¢çš„è¡¨ç°ã€‚è¯¥ç ”ç©¶æ—¨åœ¨å¯»æ‰¾æŠ½è±¡ä¸è¡¨å¾ä¹‹é—´çš„æœ€ä½³å¥‘åˆç‚¹ï¼Œä»¥ç¼©å°äººå·¥æ™ºèƒ½ä¸äººç±»å¤§è„‘åœ¨èšç±»åŠå•æ ·æœ¬å­¦ä¹ (Single-shot Learning)ç­‰ä»»åŠ¡ä¸Šçš„å·®è·ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11160v1",
      "published_date": "2026-01-16 10:22:25 UTC",
      "updated_date": "2026-01-16 10:22:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T20:59:47.191234+00:00"
    },
    {
      "arxiv_id": "2601.15319v1",
      "title": "Large Language Models as Simulative Agents for Neurodivergent Adult Psychometric Profiles",
      "title_zh": "å¤§è¯­è¨€æ¨¡å‹ä½œä¸ºç¥ç»å¤šæ ·æ€§æˆäººå¿ƒç†æµ‹é‡ç‰¹å¾çš„æ¨¡æ‹Ÿæ™ºèƒ½ä½“",
      "authors": [
        "Francesco Chiappone",
        "Davide Marocco",
        "Nicola Milano"
      ],
      "abstract": "Adult neurodivergence, including Attention-Deficit/Hyperactivity Disorder (ADHD), high-functioning Autism Spectrum Disorder (ASD), and Cognitive Disengagement Syndrome (CDS), is marked by substantial symptom overlap that limits the discriminant sensitivity of standard psychometric instruments. While recent work suggests that Large Language Models (LLMs) can simulate human psychometric responses from qualitative data, it remains unclear whether they can accurately and stably model neurodevelopmental traits rather than broad personality characteristics. This study examines whether LLMs can generate psychometric responses that approximate those of real individuals when grounded in a structured qualitative interview, and whether such simulations are sensitive to variations in trait intensity. Twenty-six adults completed a 29-item open-ended interview and four standardized self-report measures (ASRS, BAARS-IV, AQ, RAADS-R). Two LLMs (GPT-4o and Qwen3-235B-A22B) were prompted to infer an individual psychological profile from interview content and then respond to each questionnaire in-role. Accuracy, reliability, and sensitivity were assessed using group-level comparisons, error metrics, exact-match scoring, and a randomized baseline. Both models outperformed random responses across instruments, with GPT-4o showing higher accuracy and reproducibility. Simulated responses closely matched human data for ASRS, BAARS-IV, and RAADS-R, while the AQ revealed subscale-specific limitations, particularly in Attention to Detail. Overall, the findings indicate that interview-grounded LLMs can produce coherent and above-chance simulations of neurodevelopmental traits, supporting their potential use as synthetic participants in early-stage psychometric research, while highlighting clear domain-specific constraints.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹(Large Language Models, LLMs)åœ¨æ¨¡æ‹Ÿæˆäººç¥ç»å¤šæ ·æ€§(Neurodivergence)å¿ƒç†æµ‹é‡æ¦‚å†µæ–¹é¢çš„æ½œåŠ›ï¼Œæ¶µç›–äº†æ³¨æ„åŠ›ç¼ºé™·/å¤šåŠ¨éšœç¢(ADHD)ã€é«˜åŠŸèƒ½è‡ªé—­ç—‡è°±ç³»éšœç¢(ASD)åŠè®¤çŸ¥è„±èŠ‚ç»¼åˆå¾(CDS)ã€‚ç ”ç©¶äººå‘˜åŸºäº26åæˆäººçš„ç»“æ„åŒ–å®šæ€§è®¿è°ˆå†…å®¹ï¼Œåˆ©ç”¨GPT-4oå’ŒQwen3-235B-A22Bæ¨¡å‹æ¨¡æ‹Ÿä¸ªä½“å¿ƒç†ç‰¹å¾ï¼Œå¹¶å®ŒæˆASRSã€BAARS-IVã€AQå’ŒRAADS-Rå››é¡¹æ ‡å‡†åŒ–è‡ªè¯„é‡è¡¨ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œä¸¤ç§æ¨¡å‹çš„æ¨¡æ‹Ÿå“åº”å‡ä¼˜äºéšæœºåŸºå‡†ï¼Œä¸”GPT-4oåœ¨å‡†ç¡®æ€§å’Œå¯é‡ç°æ€§æ–¹é¢è¡¨ç°æ›´ä½³ã€‚å°½ç®¡æ¨¡å‹åœ¨ASRSã€BAARS-IVå’ŒRAADS-Ré‡è¡¨ä¸Šä¸äººç±»æ•°æ®é«˜åº¦åŒ¹é…ï¼Œä½†åœ¨AQé‡è¡¨çš„â€œç»†èŠ‚å…³æ³¨â€å­é‡è¡¨ä¸­æ˜¾ç¤ºå‡ºç‰¹å®šå±€é™ã€‚æ€»ä½“è€Œè¨€ï¼Œè¯¥ç ”ç©¶è¯æ˜äº†åŸºäºè®¿è°ˆèƒŒæ™¯çš„LLMsèƒ½å¤Ÿç”Ÿæˆè¿è´¯çš„ç¥ç»å‘è‚²ç‰¹è´¨æ¨¡æ‹Ÿï¼Œæ”¯æŒå…¶ä½œä¸ºæ—©æœŸå¿ƒç†æµ‹é‡ç ”ç©¶ä¸­åˆæˆå‚ä¸è€…çš„åº”ç”¨å‰æ™¯ï¼ŒåŒæ—¶ä¹ŸæŒ‡å‡ºäº†ç‰¹å®šé¢†åŸŸçš„æ€§èƒ½çº¦æŸã€‚",
      "categories": [
        "q-bio.NC",
        "cs.AI"
      ],
      "primary_category": "q-bio.NC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.15319v1",
      "published_date": "2026-01-16 10:16:58 UTC",
      "updated_date": "2026-01-16 10:16:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:00:03.611368+00:00"
    },
    {
      "arxiv_id": "2601.11151v1",
      "title": "Cross-Modal Attention Network with Dual Graph Learning in Multimodal Recommendation",
      "title_zh": "å¤šæ¨¡æ€æ¨èä¸­èåˆåŒå›¾å­¦ä¹ çš„è·¨æ¨¡æ€æ³¨æ„åŠ›ç½‘ç»œ",
      "authors": [
        "Ji Dai",
        "Quan Fang",
        "Jun Hu",
        "Desheng Cai",
        "Yang Yang",
        "Can Zhao"
      ],
      "abstract": "Multimedia recommendation systems leverage user-item interactions and multimodal information to capture user preferences, enabling more accurate and personalized recommendations. Despite notable advancements, existing approaches still face two critical limitations: first, shallow modality fusion often relies on simple concatenation, failing to exploit rich synergic intra- and inter-modal relationships; second, asymmetric feature treatment-where users are only characterized by interaction IDs while items benefit from rich multimodal content-hinders the learning of a shared semantic space. To address these issues, we propose a Cross-modal Recursive Attention Network with dual graph Embedding (CRANE). To tackle shallow fusion, we design a core Recursive Cross-Modal Attention (RCA) mechanism that iteratively refines modality features based on cross-correlations in a joint latent space, effectively capturing high-order intra- and inter-modal dependencies. For symmetric multimodal learning, we explicitly construct users' multimodal profiles by aggregating features of their interacted items. Furthermore, CRANE integrates a symmetric dual-graph framework-comprising a heterogeneous user-item interaction graph and a homogeneous item-item semantic graph-unified by a self-supervised contrastive learning objective to fuse behavioral and semantic signals. Despite these complex modeling capabilities, CRANE maintains high computational efficiency. Theoretical and empirical analyses confirm its scalability and high practical efficiency, achieving faster convergence on small datasets and superior performance ceilings on large-scale ones. Comprehensive experiments on four public real-world datasets validate an average 5% improvement in key metrics over state-of-the-art baselines.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†CRANEï¼ˆCross-modal Recursive Attention Network with dual graph Embeddingï¼‰ï¼Œæ—¨åœ¨è§£å†³å¤šæ¨¡æ€æ¨èç³»ç»Ÿä¸­æ¨¡æ€èåˆæµ…è–„ä»¥åŠç”¨æˆ·ä¸ç‰©å“ç‰¹å¾å¤„ç†ä¸å¯¹ç§°çš„é—®é¢˜ã€‚ä¸ºäº†å…‹æœæµ…å±‚èåˆï¼Œç ”ç©¶è®¾è®¡çš„Recursive Cross-Modal Attention (RCA) æœºåˆ¶é€šè¿‡åœ¨è”åˆæ½œç©ºé—´ä¸­åŸºäºäº¤å‰ç›¸å…³æ€§è¿›è¡Œè¿­ä»£ä¼˜åŒ–ï¼Œæœ‰æ•ˆæ•æ‰äº†é«˜é˜¶çš„æ¨¡æ€å†…ä¸æ¨¡æ€é—´ä¾èµ–å…³ç³»ã€‚é’ˆå¯¹å¯¹ç§°åŒ–å­¦ä¹ ï¼ŒCRANE é€šè¿‡èšåˆäº¤äº’è¿‡çš„ç‰©å“ç‰¹å¾æ¥æ˜¾å¼æ„å»ºç”¨æˆ·çš„å¤šæ¨¡æ€å±æ€§ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶é›†æˆäº†ä¸€ä¸ªå¯¹ç§°çš„åŒå›¾ï¼ˆDual-graphï¼‰ç»“æ„ï¼Œç»“åˆå¼‚æ„ç”¨æˆ·-ç‰©å“äº¤äº’å›¾å’ŒåŒæ„ç‰©å“-ç‰©å“è¯­ä¹‰å›¾ï¼Œå¹¶é€šè¿‡è‡ªç›‘ç£å¯¹æ¯”å­¦ä¹ ï¼ˆSelf-supervised Contrastive Learningï¼‰ç»Ÿä¸€è¡Œä¸ºä¸è¯­ä¹‰ä¿¡å·ã€‚å®éªŒåˆ†æè¡¨æ˜ï¼ŒCRANE åœ¨ä¿æŒé«˜è®¡ç®—æ•ˆç‡å’Œå¯æ‰©å±•æ€§çš„åŒæ—¶ï¼Œåœ¨å››ä¸ªå…¬å¼€æ•°æ®é›†ä¸Šæ¯”ç°æœ‰åŸºçº¿æ¨¡å‹å¹³å‡æå‡äº†5%çš„å…³é”®æŒ‡æ ‡ã€‚",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted to ACM Transactions on Multimedia Computing, Communications, and Applications (TOMM)",
      "pdf_url": "https://arxiv.org/pdf/2601.11151v1",
      "published_date": "2026-01-16 10:09:39 UTC",
      "updated_date": "2026-01-16 10:09:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:00:35.536230+00:00"
    },
    {
      "arxiv_id": "2601.11685v1",
      "title": "Towards Efficient Image Deblurring for Edge Deployment",
      "title_zh": "é¢å‘è¾¹ç¼˜éƒ¨ç½²çš„é«˜æ•ˆå›¾åƒå»æ¨¡ç³Š",
      "authors": [
        "Srinivas Miriyala",
        "Sowmya Vajrala",
        "Sravanth Kodavanti"
      ],
      "abstract": "Image deblurring is a critical stage in mobile image signal processing pipelines, where the ability to restore fine structures and textures must be balanced with real-time constraints on edge devices. While recent deep networks such as transformers and activation-free architectures achieve state-of-the-art (SOTA) accuracy, their efficiency is typically measured in FLOPs or parameters, which do not correlate with latency on embedded hardware. We propose a hardware-aware adaptation framework that restructures existing models through sensitivity-guided block substitution, surrogate distillation, and training-free multi-objective search driven by device profiling. Applied to the 36-block NAFNet baseline, the optimized variants achieve up to 55% reduction in GMACs compared to the recent transformer-based SOTA while maintaining competitive accuracy. Most importantly, on-device deployment yields a 1.25X latency improvement over the baseline. Experiments on motion deblurring (GoPro), defocus deblurring (DPDD), and auxiliary benchmarks (RealBlur-J/R, HIDE) demonstrate the generality of the approach, while comparisons with prior efficient baselines confirm its accuracy-efficiency trade-off. These results establish feedback-driven adaptation as a principled strategy for bridging the gap between algorithmic design and deployment-ready deblurring models.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è¾¹ç¼˜è®¾å¤‡ä¸Šå›¾åƒå»æ¨¡ç³Š(Image Deblurring)ä»»åŠ¡åœ¨æ¢å¤ç»†èŠ‚ä¸å®æ—¶æ€§ä¹‹é—´çš„çŸ›ç›¾ï¼Œæå‡ºäº†ä¸€ç§ç¡¬ä»¶æ„ŸçŸ¥(hardware-aware)çš„é€‚é…æ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡çµæ•åº¦å¼•å¯¼çš„å—æ›¿æ¢(sensitivity-guided block substitution)ã€ä»£ç†è’¸é¦(surrogate distillation)ä»¥åŠç”±è®¾å¤‡æ€§èƒ½åˆ†æé©±åŠ¨çš„å…è®­ç»ƒå¤šç›®æ ‡æœç´¢(training-free multi-objective search)æ¥é‡æ„ç°æœ‰æ¨¡å‹ã€‚åœ¨å¯¹ NAFNet åŸºå‡†æ¨¡å‹è¿›è¡Œä¼˜åŒ–åï¼Œè¯¥æ–¹æ³•åœ¨ä¿æŒç«äº‰ç²¾åº¦çš„åŒæ—¶ï¼Œæ¯”æœ€æ–°çš„åŸºäº Transformer çš„ SOTA æ¨¡å‹å‡å°‘äº† 55% çš„ GMACsã€‚æœ€é‡è¦çš„æ˜¯ï¼Œå®é™…è®¾å¤‡éƒ¨ç½²æ˜¾ç¤ºå…¶å»¶è¿Ÿæ¯”åŸºå‡†æ¨¡å‹æå‡äº† 1.25 å€ã€‚åœ¨ GoProã€DPDD ä»¥åŠ RealBlur ç­‰å¤šä¸ªæ•°æ®é›†ä¸Šçš„å®éªŒè¯æ˜äº†è¯¥æ–¹æ³•çš„é€šç”¨æ€§ä¸ä¼˜å¼‚çš„ç²¾åº¦-æ•ˆç‡æƒè¡¡ã€‚è¯¥ç ”ç©¶å±•ç¤ºäº†åé¦ˆé©±åŠ¨çš„é€‚é…ç­–ç•¥åœ¨å¼¥åˆç®—æ³•è®¾è®¡ä¸å®é™…éƒ¨ç½²æ¨¡å‹å·®è·æ–¹é¢çš„æ˜¾è‘—æ½œåŠ›ã€‚",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11685v1",
      "published_date": "2026-01-16 10:09:13 UTC",
      "updated_date": "2026-01-16 10:09:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:00:37.804724+00:00"
    },
    {
      "arxiv_id": "2601.11147v1",
      "title": "Do We Always Need Query-Level Workflows? Rethinking Agentic Workflow Generation for Multi-Agent Systems",
      "title_zh": "æˆ‘ä»¬æ˜¯å¦å§‹ç»ˆéœ€è¦æŸ¥è¯¢çº§å·¥ä½œæµï¼Ÿå¤šæ™ºèƒ½ä½“ç³»ç»Ÿæ™ºèƒ½ä½“å·¥ä½œæµç”Ÿæˆçš„å†æ€è€ƒ",
      "authors": [
        "Zixu Wang",
        "Bingbing Xu",
        "Yige Yuan",
        "Huawei Shen",
        "Xueqi Cheng"
      ],
      "abstract": "Multi-Agent Systems (MAS) built on large language models typically solve complex tasks by coordinating multiple agents through workflows. Existing approaches generates workflows either at task level or query level, but their relative costs and benefits remain unclear. After rethinking and empirical analyses, we show that query-level workflow generation is not always necessary, since a small set of top-K best task-level workflows together already covers equivalent or even more queries. We further find that exhaustive execution-based task-level evaluation is both extremely token-costly and frequently unreliable. Inspired by the idea of self-evolution and generative reward modeling, we propose a low-cost task-level generation framework \\textbf{SCALE}, which means \\underline{\\textbf{S}}elf prediction of the optimizer with few shot \\underline{\\textbf{CAL}}ibration for \\underline{\\textbf{E}}valuation instead of full validation execution. Extensive experiments demonstrate that \\textbf{SCALE} maintains competitive performance, with an average degradation of just 0.61\\% compared to existing approach across multiple datasets, while cutting overall token usage by up to 83\\%.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹é©±åŠ¨çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ(MAS)ä¸­ï¼Œä»»åŠ¡çº§(task-level)ä¸æŸ¥è¯¢çº§(query-level)å·¥ä½œæµç”Ÿæˆçš„ç›¸å¯¹æ•ˆç›Šä¸æˆæœ¬ã€‚é€šè¿‡å®è¯åˆ†æï¼Œä½œè€…å‘ç°æŸ¥è¯¢çº§å·¥ä½œæµå¹¶éæ€»æ˜¯å¿…éœ€ï¼Œå› ä¸ºä¸€å°ç»„é¡¶å°–çš„ä»»åŠ¡çº§å·¥ä½œæµé›†åˆå·²èƒ½è¦†ç›–ç­‰é‡ç”šè‡³æ›´å¤šçš„æŸ¥è¯¢éœ€æ±‚ã€‚é’ˆå¯¹ä¼ ç»ŸåŸºäºæ‰§è¡Œçš„ä»»åŠ¡çº§è¯„ä¼°å­˜åœ¨çš„é«˜Tokenæˆæœ¬å’Œä½å¯é æ€§é—®é¢˜ï¼Œç ”ç©¶æå‡ºäº†åä¸ºSCALEçš„ä½æˆæœ¬ç”Ÿæˆæ¡†æ¶ï¼Œè¯¥æ¡†æ¶é‡‡ç”¨ä¼˜åŒ–å™¨è‡ªæˆ‘é¢„æµ‹é…åˆå°‘é‡æ ·æœ¬æ ¡å‡†(few-shot calibration)è¿›è¡Œè¯„ä¼°ï¼Œä»è€Œå–ä»£å®Œæ•´çš„éªŒè¯æ‰§è¡Œã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSCALEåœ¨ç»´æŒç«äº‰åŠ›æ€§èƒ½çš„åŒæ—¶ï¼Œç›¸æ¯”ç°æœ‰æ–¹æ³•å¹³å‡æ€§èƒ½ä»…ä¸‹é™0.61%ï¼Œå´èƒ½å¤§å¹…å‰Šå‡é«˜è¾¾83%çš„Tokenä½¿ç”¨é‡ï¼Œä¸ºé«˜æ•ˆæ„å»ºå¤šæ™ºèƒ½ä½“ç³»ç»Ÿæä¾›äº†æ–°æ€è·¯ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "17 pages, 4 figures, 3 tables",
      "pdf_url": "https://arxiv.org/pdf/2601.11147v1",
      "published_date": "2026-01-16 10:05:51 UTC",
      "updated_date": "2026-01-16 10:05:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:00:36.547046+00:00"
    },
    {
      "arxiv_id": "2601.11144v2",
      "title": "Deep GraphRAG: A Balanced Approach to Hierarchical Retrieval and Adaptive Integration",
      "title_zh": "Deep GraphRAGï¼šå±‚çº§åŒ–æ£€ç´¢ä¸è‡ªé€‚åº”é›†æˆçš„å‡è¡¡æ–¹æ³•",
      "authors": [
        "Yuejie Li",
        "Ke Yang",
        "Tao Wang",
        "Bolin Chen",
        "Bowen Li",
        "Chengjun Mao"
      ],
      "abstract": "Graph-based Retrieval-Augmented Generation (GraphRAG) frameworks face a trade-off between the comprehensiveness of global search and the efficiency of local search. Existing methods are often challenged by navigating large-scale hierarchical graphs, optimizing retrieval paths, and balancing exploration-exploitation dynamics, frequently lacking robust multi-stage re-ranking. To overcome these deficits, we propose Deep GraphRAG, a framework designed for a balanced approach to hierarchical retrieval and adaptive integration. It introduces a hierarchical global-to-local retrieval strategy that integrates macroscopic inter-community and microscopic intra-community contextual relations. This strategy employs a three-stage process: (1) inter-community filtering, which prunes the search space using local context; (2) community-level refinement, which prioritizes relevant subgraphs via entity-interaction analysis; and (3) entity-level fine-grained search within target communities. A beam search-optimized dynamic re-ranking module guides this process, continuously filtering candidates to balance efficiency and global comprehensiveness. Deep GraphRAG also features a Knowledge Integration Module leveraging a compact LLM, trained with Dynamic Weighting Reward GRPO (DW-GRPO). This novel reinforcement learning approach dynamically adjusts reward weights to balance three key objectives: relevance, faithfulness, and conciseness. This training enables compact models (1.5B) to approach the performance of large models (70B) in the integration task. Evaluations on Natural Questions and HotpotQA demonstrate that Deep GraphRAG significantly outperforms baseline graph retrieval methods in both accuracy and efficiency.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Deep GraphRAGæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³Graph-based Retrieval-Augmented Generation (GraphRAG) åœ¨å…¨å±€æœç´¢çš„å…¨é¢æ€§ä¸å±€éƒ¨æœç´¢çš„æ•ˆç‡ä¹‹é—´éš¾ä»¥å¹³è¡¡çš„é—®é¢˜ã€‚è¯¥æ¡†æ¶å¼•å…¥äº†ä¸€ç§å±‚çº§åŒ–çš„ç”±å…¨å±€åˆ°å±€éƒ¨çš„æ£€ç´¢ç­–ç•¥ï¼Œé€šè¿‡ç¤¾åŒºé—´è¿‡æ»¤ã€ç¤¾åŒºçº§ç²¾ç‚¼å’Œå®ä½“çº§ç»†ç²’åº¦æœç´¢ä¸‰ä¸ªé˜¶æ®µï¼Œå®ç°äº†å®è§‚ç¤¾åŒºå…³ç³»ä¸å¾®è§‚è¯­å¢ƒçš„æ·±åº¦é›†æˆã€‚ä¸ºäº†å¹³è¡¡æ•ˆç‡ä¸å…¨é¢æ€§ï¼Œç³»ç»Ÿé‡‡ç”¨äº†æ³¢æŸæœç´¢ (beam search) ä¼˜åŒ–çš„åŠ¨æ€é‡æ’åºæ¨¡å—è¿›è¡Œè·¯å¾„å¼•å¯¼ã€‚æ­¤å¤–ï¼Œç ”ç©¶åˆ©ç”¨åŠ¨æ€åŠ æƒå¥–åŠ±GRPO (DW-GRPO) ç®—æ³•è®­ç»ƒè½»é‡åŒ–å¤§è¯­è¨€æ¨¡å‹ (LLM)ï¼Œä½¿å…¶åœ¨çŸ¥è¯†é›†æˆä»»åŠ¡ä¸­èƒ½ä»¥1.5Bçš„å‚æ•°è§„æ¨¡æ¥è¿‘70Bæ¨¡å‹çš„æ€§èƒ½è¡¨ç°ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒDeep GraphRAGåœ¨Natural Questionså’ŒHotpotQAç­‰åŸºå‡†æµ‹è¯•ä¸­çš„å‡†ç¡®ç‡ä¸æ•ˆç‡å‡æ˜¾è‘—ä¼˜äºç°æœ‰çš„å›¾æ£€ç´¢æ–¹æ³•ã€‚",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11144v2",
      "published_date": "2026-01-16 10:02:31 UTC",
      "updated_date": "2026-01-19 09:50:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:00:40.348210+00:00"
    },
    {
      "arxiv_id": "2601.11143v1",
      "title": "Learning Quadrupedal Locomotion for a Heavy Hydraulic Robot Using an Actuator Model",
      "title_zh": "åŸºäºæ‰§è¡Œå™¨æ¨¡å‹çš„é‡å‹æ¶²å‹æœºå™¨äººå››è¶³è¿åŠ¨å­¦ä¹ ",
      "authors": [
        "Minho Lee",
        "Hyeonseok Kim",
        "Jin Tak Kim",
        "Sangshin Park",
        "Jeong Hyun Lee",
        "Jungsan Cho",
        "Jemin Hwangbo"
      ],
      "abstract": "The simulation-to-reality (sim-to-real) transfer of large-scale hydraulic robots presents a significant challenge in robotics because of the inherent slow control response and complex fluid dynamics. The complex dynamics result from the multiple interconnected cylinder structure and the difference in fluid rates of the cylinders. These characteristics complicate detailed simulation for all joints, making it unsuitable for reinforcement learning (RL) applications. In this work, we propose an analytical actuator model driven by hydraulic dynamics to represent the complicated actuators. The model predicts joint torques for all 12 actuators in under 1 microsecond, allowing rapid processing in RL environments. We compare our model with neural network-based actuator models and demonstrate the advantages of our model in data-limited scenarios. The locomotion policy trained in RL with our model is deployed on a hydraulic quadruped robot, which is over 300 kg. This work is the first demonstration of a successful transfer of stable and robust command-tracking locomotion with RL on a heavy hydraulic quadruped robot, demonstrating advanced sim-to-real transferability.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§å‹æ¶²å‹æœºå™¨äººåœ¨æ¨¡æ‹Ÿåˆ°ç°å®è½¬æ¢(sim-to-real transfer)ä¸­å› æ§åˆ¶å“åº”æ…¢å’Œå¤æ‚æµä½“åŠ¨åŠ›å­¦(fluid dynamics)å¯¼è‡´çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§ç”±æ¶²å‹åŠ¨åŠ›å­¦é©±åŠ¨çš„è§£ææ‰§è¡Œå™¨æ¨¡å‹(analytical actuator model)ã€‚è¯¥æ¨¡å‹èƒ½å¤Ÿåœ¨1å¾®ç§’å†…å¿«é€Ÿé¢„æµ‹å…¨éƒ¨12ä¸ªæ‰§è¡Œå™¨çš„å…³èŠ‚æ‰­çŸ©(joint torques)ï¼Œä»è€Œæ»¡è¶³å¼ºåŒ–å­¦ä¹ (Reinforcement Learning)ç¯å¢ƒå¯¹é«˜é¢‘ç‡å¤„ç†çš„è¦æ±‚ã€‚é€šè¿‡å¯¹æ¯”å®éªŒè¯æ˜ï¼Œè¯¥è§£ææ¨¡å‹åœ¨æ•°æ®æœ‰é™çš„åœºæ™¯ä¸‹ä¼˜äºåŸºäºç¥ç»ç½‘ç»œçš„æ‰§è¡Œå™¨æ¨¡å‹ï¼Œå±•ç°å‡ºæ›´å¼ºçš„å®ç”¨æ€§ã€‚ç ”ç©¶äººå‘˜å°†åŸºäºæ­¤æ¨¡å‹è®­ç»ƒçš„æ­¥æ€ç­–ç•¥æˆåŠŸéƒ¨ç½²åœ¨è‡ªé‡è¶…è¿‡300å…¬æ–¤çš„é‡å‹æ¶²å‹å››è¶³æœºå™¨äººä¸Šï¼Œå®ç°äº†ç¨³å®šä¸”é²æ£’çš„æŒ‡ä»¤è¿½è¸ªç§»åŠ¨ã€‚è¿™æ˜¯ä¸šç•Œé¦–æ¬¡å®ç°åœ¨é‡å‹æ¶²å‹å››è¶³æœºå™¨äººä¸Šé€šè¿‡å¼ºåŒ–å­¦ä¹ å®Œæˆæ¨¡æ‹Ÿåˆ°ç°å®çš„æ­¥æ€è½¬æ¢ï¼Œè¯æ˜äº†è¯¥æ–¹æ³•åœ¨å¤„ç†å¤æ‚é‡å‹æœºå™¨äººåŠ¨åŠ›å­¦æ–¹é¢çš„å“è¶Šæ€§èƒ½ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "9 pages, Accepted to IEEE Robotics and Automation Letters (RA-L) 2025",
      "pdf_url": "https://arxiv.org/pdf/2601.11143v1",
      "published_date": "2026-01-16 10:01:09 UTC",
      "updated_date": "2026-01-16 10:01:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:00:40.036940+00:00"
    },
    {
      "arxiv_id": "2601.11135v1",
      "title": "Context-aware Graph Causality Inference for Few-Shot Molecular Property Prediction",
      "title_zh": "é¢å‘å°‘æ ·æœ¬åˆ†å­å±æ€§é¢„æµ‹çš„ä¸Šä¸‹æ–‡æ„ŸçŸ¥å›¾å› æœæ¨ç†",
      "authors": [
        "Van Thuy Hoang",
        "O-Joun Lee"
      ],
      "abstract": "Molecular property prediction is becoming one of the major applications of graph learning in Web-based services, e.g., online protein structure prediction and drug discovery. A key challenge arises in few-shot scenarios, where only a few labeled molecules are available for predicting unseen properties. Recently, several studies have used in-context learning to capture relationships among molecules and properties, but they face two limitations in: (1) exploiting prior knowledge of functional groups that are causally linked to properties and (2) identifying key substructures directly correlated with properties. We propose CaMol, a context-aware graph causality inference framework, to address these challenges by using a causal inference perspective, assuming that each molecule consists of a latent causal structure that determines a specific property. First, we introduce a context graph that encodes chemical knowledge by linking functional groups, molecules, and properties to guide the discovery of causal substructures. Second, we propose a learnable atom masking strategy to disentangle causal substructures from confounding ones. Third, we introduce a distribution intervener that applies backdoor adjustment by combining causal substructures with chemically grounded confounders, disentangling causal effects from real-world chemical variations. Experiments on diverse molecular datasets showed that CaMol achieved superior accuracy and sample efficiency in few-shot tasks, showing its generalizability to unseen properties. Also, the discovered causal substructures were strongly aligned with chemical knowledge about functional groups, supporting the model interpretability.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†CaMolï¼Œä¸€ç§ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„å›¾å› æœæ¨ç†(Context-aware graph causality inference)æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å°‘æ ·æœ¬(Few-Shot)åˆ†å­æ€§è´¨é¢„æµ‹ä¸­å…ˆéªŒçŸ¥è¯†åˆ©ç”¨ä¸è¶³å’Œå…³é”®å­ç»“æ„è¯†åˆ«å›°éš¾çš„é—®é¢˜ã€‚è¯¥æ¡†æ¶ä»å› æœæ¨ç†è§†è§’å‡ºå‘ï¼Œé¦–å…ˆå¼•å…¥ä¸€ä¸ªä¸Šä¸‹æ–‡å›¾(Context graph)ï¼Œé€šè¿‡å…³è”åŠŸèƒ½å›¢(Functional groups)ã€åˆ†å­å’Œæ€§è´¨æ¥ç¼–ç åŒ–å­¦çŸ¥è¯†ï¼Œä»è€ŒæŒ‡å¯¼å› æœå­ç»“æ„çš„å‘ç°ã€‚å…¶æ¬¡ï¼ŒCaMolé‡‡ç”¨å¯å­¦ä¹ çš„åŸå­æ©ç ç­–ç•¥(Atom masking strategy)ï¼Œå°†å› æœå­ç»“æ„ä¸å¹²æ‰°å› ç´ (Confounding ones)æœ‰æ•ˆè§£è€¦ã€‚æ­¤å¤–ï¼Œç ”ç©¶å¼•å…¥äº†åˆ†å¸ƒå¹²é¢„å™¨(Distribution intervener)ï¼Œé€šè¿‡åé—¨è°ƒæ•´(Backdoor adjustment)å°†å› æœæ•ˆåº”ä»ç°å®ä¸–ç•Œçš„åŒ–å­¦å˜å¼‚ä¸­åˆ†ç¦»å‡ºæ¥ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒCaMolåœ¨å¤šç§åˆ†å­æ•°æ®é›†çš„å°‘æ ·æœ¬ä»»åŠ¡ä¸­è¡¨ç°å‡ºä¼˜å¼‚çš„å‡†ç¡®ç‡å’Œæ ·æœ¬æ•ˆç‡ï¼Œå¹¶å±•ç°äº†å¯¹æœªçŸ¥æ€§è´¨çš„è‰¯å¥½æ³›åŒ–èƒ½åŠ›ã€‚æœ€åï¼Œæ¨¡å‹å‘ç°çš„å› æœå­ç»“æ„ä¸åŠŸèƒ½å›¢çš„åŒ–å­¦çŸ¥è¯†é«˜åº¦ä¸€è‡´ï¼Œæ˜¾è‘—æå‡äº†é¢„æµ‹ç»“æœçš„å¯è§£é‡Šæ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "15 pages",
      "pdf_url": "https://arxiv.org/pdf/2601.11135v1",
      "published_date": "2026-01-16 09:49:50 UTC",
      "updated_date": "2026-01-16 09:49:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:00:48.268836+00:00"
    },
    {
      "arxiv_id": "2601.11684v1",
      "title": "Mobile-friendly Image de-noising: Hardware Conscious Optimization for Edge Application",
      "title_zh": "é€‚é…ç§»åŠ¨ç«¯çš„å›¾åƒå»å™ªï¼šé¢å‘è¾¹ç¼˜åº”ç”¨çš„ç¡¬ä»¶æ„ŸçŸ¥ä¼˜åŒ–",
      "authors": [
        "Srinivas Miriyala",
        "Sowmya Vajrala",
        "Hitesh Kumar",
        "Sravanth Kodavanti",
        "Vikram Rajendiran"
      ],
      "abstract": "Image enhancement is a critical task in computer vision and photography that is often entangled with noise. This renders the traditional Image Signal Processing (ISP) ineffective compared to the advances in deep learning. However, the success of such methods is increasingly associated with the ease of their deployment on edge devices, such as smartphones. This work presents a novel mobile-friendly network for image de-noising obtained with Entropy-Regularized differentiable Neural Architecture Search (NAS) on a hardware-aware search space for a U-Net architecture, which is first-of-its-kind. The designed model has 12% less parameters, with ~2-fold improvement in ondevice latency and 1.5-fold improvement in the memory footprint for a 0.7% drop in PSNR, when deployed and profiled on Samsung Galaxy S24 Ultra. Compared to the SOTA Swin-Transformer for Image Restoration, the proposed network had competitive accuracy with ~18-fold reduction in GMACs. Further, the network was tested successfully for Gaussian de-noising with 3 intensities on 4 benchmarks and real-world de-noising on 1 benchmark demonstrating its generalization ability.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§é¢å‘ç§»åŠ¨ç«¯çš„å›¾åƒå»å™ªç½‘ç»œï¼Œé€šè¿‡åœ¨ç¡¬ä»¶æ„ŸçŸ¥çš„ U-Net æœç´¢ç©ºé—´ä¸­åº”ç”¨ç†µæ­£åˆ™åŒ–å¾®åˆ†ç¥ç»æ¶æ„æœç´¢(Entropy-Regularized differentiable Neural Architecture Search, NAS)è·å¾—ã€‚ä½œä¸ºé¦–ä¸ªé’ˆå¯¹ç¡¬ä»¶æ„è¯†ä¼˜åŒ–çš„ U-Net æ¶æ„ï¼Œè¯¥æ¨¡å‹æ—¨åœ¨è§£å†³æ·±åº¦å­¦ä¹ å»å™ªæ–¹æ³•åœ¨æ™ºèƒ½æ‰‹æœºç­‰è¾¹ç¼˜è®¾å¤‡ä¸Šéƒ¨ç½²å›°éš¾çš„æŒ‘æˆ˜ã€‚åœ¨ Samsung Galaxy S24 Ultra ä¸Šçš„éƒ¨ç½²æµ‹è¯•è¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨ PSNR ä»…ä¸‹é™ 0.7% çš„å‰æä¸‹ï¼Œå®ç°äº†å‚æ•°é‡å‡å°‘ 12%ã€ç«¯åˆ°ç«¯å»¶è¿Ÿç¼©çŸ­çº¦ 2 å€ä»¥åŠå†…å­˜å ç”¨é™ä½ 1.5 å€çš„æ˜¾è‘—æ€§èƒ½æå‡ã€‚ä¸ SOTA çš„ Swin-Transformer ç›¸æ¯”ï¼Œè¯¥ç½‘ç»œåœ¨ä¿æŒç«äº‰åŠ›å‡†ç¡®ç‡çš„åŒæ—¶ï¼Œå¤§å¹…å‰Šå‡äº†çº¦ 18 å€çš„ GMACsã€‚æ­¤å¤–ï¼Œè¯¥ç½‘ç»œåœ¨ 4 ä¸ª Gaussian å»å™ªåŸºå‡†å’ŒçœŸå®ä¸–ç•Œå»å™ªä»»åŠ¡ä¸­å‡éªŒè¯äº†ä¼˜ç§€çš„æ³›åŒ–èƒ½åŠ›ï¼Œè¯æ˜äº†å…¶åœ¨å®é™…è¾¹ç¼˜åº”ç”¨åœºæ™¯ä¸­çš„é«˜æ•ˆæ€§ä¸å®ç”¨æ€§ã€‚",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "Accepted at ICASSP 2025",
      "pdf_url": "https://arxiv.org/pdf/2601.11684v1",
      "published_date": "2026-01-16 09:39:01 UTC",
      "updated_date": "2026-01-16 09:39:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:00:56.975168+00:00"
    },
    {
      "arxiv_id": "2601.11124v1",
      "title": "Learn Before Represent: Bridging Generative and Contrastive Learning for Domain-Specific LLM Embeddings",
      "title_zh": "Learn Before Representï¼šè¡”æ¥ç”Ÿæˆå¼ä¸å¯¹æ¯”å¼å­¦ä¹ çš„é¢†åŸŸç‰¹å®šå¤§è¯­è¨€æ¨¡å‹åµŒå…¥",
      "authors": [
        "Xiaoyu Liang",
        "Yuchen Peng",
        "Jiale Luo",
        "Wenhao Wang",
        "Haoji Hu",
        "Xincheng Zhou"
      ],
      "abstract": "Large Language Models (LLMs) adapted via contrastive learning excel in general representation learning but struggle in vertical domains like chemistry and law, primarily due to a lack of domain-specific knowledge. This work identifies a core bottleneck: the prevailing ``LLM+CL'' paradigm focuses on semantic alignment but cannot perform knowledge acquisition, leading to failures on specialized terminology. To bridge this gap, we propose Learn Before Represent (LBR), a novel two-stage framework. LBR first injects domain knowledge via an Information Bottleneck-Constrained Generative Learning stage, preserving the LLM's causal attention to maximize knowledge acquisition while compressing semantics. It then performs Generative-Refined Contrastive Learning on the compressed representations for alignment. This approach maintains architectural consistency and resolves the objective conflict between generative and contrastive learning. Extensive experiments on medical, chemistry, and code retrieval tasks show that LBR significantly outperforms strong baselines. Our work establishes a new paradigm for building accurate and robust representations in vertical domains.",
      "tldr_zh": "ç°æœ‰çš„â€œLLM+CLâ€èŒƒå¼åœ¨å¯¹æ¯”å­¦ä¹ (Contrastive Learning)è¿‡ç¨‹ä¸­å¾€å¾€ä¾§é‡äºè¯­ä¹‰å¯¹é½è€Œå¿½ç•¥äº†çŸ¥è¯†è·å–ï¼Œå¯¼è‡´å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨åŒ–å­¦ã€æ³•å¾‹ç­‰å‚ç›´é¢†åŸŸé¢ä¸´ä¸“ä¸šæœ¯è¯­ç†è§£ä¸è¶³çš„ç“¶é¢ˆã€‚è¯¥ç ”ç©¶æå‡ºäº†Learn Before Represent (LBR)æ¡†æ¶ï¼Œè¿™æ˜¯ä¸€ç§ç»“åˆç”Ÿæˆå¼å­¦ä¹ ä¸å¯¹æ¯”å­¦ä¹ çš„æ–°é¢–ä¸¤é˜¶æ®µæ–¹æ³•ã€‚ç¬¬ä¸€é˜¶æ®µé€šè¿‡ä¿¡æ¯ç“¶é¢ˆçº¦æŸçš„ç”Ÿæˆå¼å­¦ä¹ (Information Bottleneck-Constrained Generative Learning)æ³¨å…¥é¢†åŸŸçŸ¥è¯†ï¼Œåœ¨æœ€å¤§åŒ–çŸ¥è¯†è·å–çš„åŒæ—¶å‹ç¼©è¯­ä¹‰ä¿¡æ¯ã€‚ç¬¬äºŒé˜¶æ®µåˆ™å¯¹å‹ç¼©åçš„è¡¨ç¤ºè¿›è¡Œç”Ÿæˆå¼ç»†åŒ–çš„å¯¹æ¯”å­¦ä¹ (Generative-Refined Contrastive Learning)ä»¥å®ç°å¯¹é½ã€‚è¿™ç§æ–¹æ³•è§£å†³äº†ç”Ÿæˆå¼ä¸å¯¹æ¯”å­¦ä¹ ä¹‹é—´çš„ç›®æ ‡å†²çªï¼Œå¹¶ä¿æŒäº†æ¶æ„ä¸€è‡´æ€§ã€‚åœ¨åŒ»ç–—ã€åŒ–å­¦å’Œä»£ç æ£€ç´¢ä»»åŠ¡ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒLBRçš„æ€§èƒ½æ˜¾è‘—ä¼˜äºç°æœ‰çš„å¼ºåŸºçº¿æ¨¡å‹ï¼Œä¸ºæ„å»ºå‡†ç¡®ä¸”ç¨³å¥çš„å‚ç›´é¢†åŸŸåµŒå…¥è¡¨ç¤ºå¥ å®šäº†æ–°èŒƒå¼ã€‚",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "10 pages, 3 figures",
      "pdf_url": "https://arxiv.org/pdf/2601.11124v1",
      "published_date": "2026-01-16 09:35:29 UTC",
      "updated_date": "2026-01-16 09:35:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:00:52.863511+00:00"
    },
    {
      "arxiv_id": "2601.11109v2",
      "title": "Vision-as-Inverse-Graphics Agent via Interleaved Multimodal Reasoning",
      "title_zh": "åŸºäºäº¤é”™å¤šæ¨¡æ€æ¨ç†çš„è§†è§‰å³é€†å‘å›¾å½¢å­¦æ™ºèƒ½ä½“",
      "authors": [
        "Shaofeng Yin",
        "Jiaxin Ge",
        "Zora Zhiruo Wang",
        "Xiuyu Li",
        "Michael J. Black",
        "Trevor Darrell",
        "Angjoo Kanazawa",
        "Haiwen Feng"
      ],
      "abstract": "Vision-as-inverse-graphics, the concept of reconstructing an image as an editable graphics program is a long-standing goal of computer vision. Yet even strong VLMs aren't able to achieve this in one-shot as they lack fine-grained spatial and physical grounding capability. Our key insight is that closing this gap requires interleaved multimodal reasoning through iterative execution and verification. Stemming from this, we present VIGA (Vision-as-Inverse-Graphic Agent) that starts from an empty world and reconstructs or edits scenes through a closed-loop write-run-render-compare-revise procedure. To support long-horizon reasoning, VIGA combines (i) a skill library that alternates generator and verifier roles and (ii) an evolving context memory that contains plans, code diffs, and render history. VIGA is task-agnostic as it doesn't require auxiliary modules, covering a wide range of tasks such as 3D reconstruction, multi-step scene editing, 4D physical interaction, and 2D document editing, etc. Empirically, we found VIGA substantially improves one-shot baselines on BlenderGym (35.32%) and SlideBench (117.17%). Moreover, VIGA is also model-agnostic as it doesn't require finetuning, enabling a unified protocol to evaluate heterogeneous foundation VLMs. To better support this protocol, we introduce BlenderBench, a challenging benchmark that stress-tests interleaved multimodal reasoning with graphics engine, where VIGA improves by 124.70%.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†VIGA (Vision-as-Inverse-Graphic Agent)ï¼Œæ—¨åœ¨å®ç°å°†å›¾åƒé‡æ„ä¸ºå¯ç¼–è¾‘å›¾å½¢ç¨‹åºçš„Vision-as-inverse-graphicsé•¿æœŸç›®æ ‡ã€‚é’ˆå¯¹ç°æœ‰è§†è§‰è¯­è¨€æ¨¡å‹(VLMs)åœ¨å•æ¬¡å°è¯•ä¸­ç¼ºä¹ç»†ç²’åº¦ç©ºé—´å’Œç‰©ç†æ„ŸçŸ¥èƒ½åŠ›çš„é—®é¢˜ï¼ŒVIGAé€šè¿‡è¿­ä»£æ‰§è¡Œä¸éªŒè¯çš„äº¤é”™å¤šæ¨¡æ€æ¨ç†(Interleaved Multimodal Reasoning)æ¥å¼¥è¡¥è¿™ä¸€å·®è·ã€‚è¯¥æ™ºèƒ½ä½“é‡‡ç”¨é—­ç¯çš„â€œç¼–å†™-è¿è¡Œ-æ¸²æŸ“-æ¯”è¾ƒ-ä¿®æ­£â€æµç¨‹ï¼Œå¹¶ç»“åˆäº†ç”±ç”Ÿæˆå™¨ä¸éªŒè¯å™¨äº¤æ›¿æ„æˆçš„æŠ€èƒ½åº“(Skill Library)ä»¥åŠåŒ…å«è®¡åˆ’ã€ä»£ç å·®å¼‚å’Œæ¸²æŸ“å†å²çš„æ¼”è¿›ä¸Šä¸‹æ–‡è®°å¿†(Evolving Context Memory)ã€‚VIGAå…·æœ‰ä»»åŠ¡æ— å…³æ€§å’Œæ¨¡å‹æ— å…³æ€§ï¼Œæ— éœ€å¾®è°ƒå³å¯å¤„ç†ä»3Dé‡å»ºã€åœºæ™¯ç¼–è¾‘åˆ°4Dç‰©ç†äº¤äº’åŠ2Dæ–‡æ¡£ç¼–è¾‘ç­‰å¹¿æ³›ä»»åŠ¡ã€‚å®éªŒè¡¨æ˜ï¼ŒVIGAåœ¨BlenderGymå’ŒSlideBenchä¸Šçš„è¡¨ç°æ˜¾è‘—ä¼˜äºå•æ¬¡åŸºçº¿æ¨¡å‹ï¼Œåˆ†åˆ«æå‡äº†35.32%å’Œ117.17%ã€‚æ­¤å¤–ï¼Œç ”ç©¶å›¢é˜Ÿè¿˜æ¨å‡ºäº†BlenderBenchåŸºå‡†ä»¥å‹åŠ›æµ‹è¯•å›¾å½¢å¼•æ“ç¯å¢ƒä¸‹çš„æ¨ç†èƒ½åŠ›ï¼ŒVIGAåœ¨è¯¥æµ‹è¯•ä¸­å®ç°äº†124.70%çš„æ€§èƒ½å¢é•¿ï¼Œè¯æ˜äº†å…¶åœ¨å¤„ç†é•¿ç¨‹å¤æ‚ä»»åŠ¡ä¸­çš„å“è¶Šæ•ˆèƒ½ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR"
      ],
      "primary_category": "cs.CV",
      "comment": "Project page: https://fugtemypt123.github.io/VIGA-website/",
      "pdf_url": "https://arxiv.org/pdf/2601.11109v2",
      "published_date": "2026-01-16 09:11:55 UTC",
      "updated_date": "2026-01-22 01:46:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:00:55.612351+00:00"
    },
    {
      "arxiv_id": "2601.11100v1",
      "title": "ReCreate: Reasoning and Creating Domain Agents Driven by Experience",
      "title_zh": "ReCreateï¼šç»éªŒé©±åŠ¨çš„é¢†åŸŸæ™ºèƒ½ä½“æ¨ç†ä¸æ„å»º",
      "authors": [
        "Zhezheng Hao",
        "Hong Wang",
        "Jian Luo",
        "Jianqing Zhang",
        "Yuyan Zhou",
        "Qiang Lin",
        "Can Wang",
        "Hande Dong",
        "Jiawei Chen"
      ],
      "abstract": "Large Language Model agents are reshaping the industrial landscape. However, most practical agents remain human-designed because tasks differ widely, making them labor-intensive to build. This situation poses a central question: can we automatically create and adapt domain agents in the wild? While several recent approaches have sought to automate agent creation, they typically treat agent generation as a black-box procedure and rely solely on final performance metrics to guide the process. Such strategies overlook critical evidence explaining why an agent succeeds or fails, and often require high computational costs. To address these limitations, we propose ReCreate, an experience-driven framework for the automatic creation of domain agents. ReCreate systematically leverages agent interaction histories, which provide rich concrete signals on both the causes of success or failure and the avenues for improvement. Specifically, we introduce an agent-as-optimizer paradigm that effectively learns from experience via three key components: (i) an experience storage and retrieval mechanism for on-demand inspection; (ii) a reasoning-creating synergy pipeline that maps execution experience into scaffold edits; and (iii) hierarchical updates that abstract instance-level details into reusable domain patterns. In experiments across diverse domains, ReCreate consistently outperforms human-designed agents and existing automated agent generation methods, even when starting from minimal seed scaffolds.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ReCreateæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹(Large Language Model)æ™ºèƒ½ä½“åœ¨ç‰¹å®šé¢†åŸŸæ„å»ºä¸­è¿‡äºä¾èµ–äººå·¥è®¾è®¡ã€åŠ³åŠ¨å¼ºåº¦å¤§ä¸”ç°æœ‰è‡ªåŠ¨åŒ–æ–¹æ³•ç¼ºä¹å¯è§£é‡Šæ€§åŠè®¡ç®—æˆæœ¬é«˜çš„é—®é¢˜ã€‚ReCreateé‡‡ç”¨äº†â€œæ™ºèƒ½ä½“å³ä¼˜åŒ–å™¨â€(agent-as-optimizer)çš„èŒƒå¼ï¼Œé€šè¿‡ç³»ç»Ÿæ€§åœ°åˆ©ç”¨æ™ºèƒ½ä½“çš„äº¤äº’å†å²(interaction histories)æ¥é©±åŠ¨é¢†åŸŸæ™ºèƒ½ä½“çš„è‡ªåŠ¨åˆ›å»ºä¸æ¼”è¿›ã€‚è¯¥æ¡†æ¶é›†æˆäº†ç»éªŒå­˜å‚¨ä¸æ£€ç´¢æœºåˆ¶ã€å°†æ‰§è¡Œç»éªŒæ˜ å°„ä¸ºè„šæ‰‹æ¶ç¼–è¾‘(scaffold edits)çš„æ¨ç†-åˆ›å»ºååŒæµæ°´çº¿ï¼Œä»¥åŠå°†å®ä¾‹ç»†èŠ‚æŠ½è±¡ä¸ºå¯å¤ç”¨é¢†åŸŸæ¨¡å¼çš„å±‚æ¬¡åŒ–æ›´æ–°(hierarchical updates)æœºåˆ¶ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒReCreateåœ¨å¤šä¸ªä¸åŒé¢†åŸŸçš„è¡¨ç°ä¸€è‡´ä¼˜äºäººå·¥è®¾è®¡çš„æ™ºèƒ½ä½“åŠç°æœ‰çš„è‡ªåŠ¨åŒ–ç”Ÿæˆæ–¹æ³•ã€‚å³ä½¿åœ¨åˆå§‹è„šæ‰‹æ¶æç®€çš„æƒ…å†µä¸‹ï¼Œè¯¥æ¡†æ¶ä¹Ÿèƒ½é€šè¿‡ç»éªŒé©±åŠ¨æ•æ‰æˆåŠŸæˆ–å¤±è´¥çš„æ·±å±‚åŸå› ï¼Œä»è€Œå®ç°é«˜æ•ˆçš„æ™ºèƒ½ä½“ä¼˜åŒ–ä¸æ€§èƒ½æå‡ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11100v1",
      "published_date": "2026-01-16 09:00:03 UTC",
      "updated_date": "2026-01-16 09:00:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:00:59.502495+00:00"
    },
    {
      "arxiv_id": "2601.11683v1",
      "title": "Attesting Model Lineage by Consisted Knowledge Evolution with Fine-Tuning Trajectory",
      "title_zh": "åŸºäºå¾®è°ƒè½¨è¿¹ä¸çŸ¥è¯†æ¼”åŒ–ä¸€è‡´æ€§çš„æ¨¡å‹è¡€ç¼˜éªŒè¯",
      "authors": [
        "Zhuoyi Shang",
        "Jiasen Li",
        "Pengzhen Chen",
        "Yanwei Liu",
        "Xiaoyan Gu",
        "Weiping Wang"
      ],
      "abstract": "The fine-tuning technique in deep learning gives rise to an emerging lineage relationship among models. This lineage provides a promising perspective for addressing security concerns such as unauthorized model redistribution and false claim of model provenance, which are particularly pressing in \\textcolor{blue}{open-weight model} libraries where robust lineage verification mechanisms are often lacking. Existing approaches to model lineage detection primarily rely on static architectural similarities, which are insufficient to capture the dynamic evolution of knowledge that underlies true lineage relationships. Drawing inspiration from the genetic mechanism of human evolution, we tackle the problem of model lineage attestation by verifying the joint trajectory of knowledge evolution and parameter modification. To this end, we propose a novel model lineage attestation framework. In our framework, model editing is first leveraged to quantify parameter-level changes introduced by fine-tuning. Subsequently, we introduce a novel knowledge vectorization mechanism that refines the evolved knowledge within the edited models into compact representations by the assistance of probe samples. The probing strategies are adapted to different types of model families. These embeddings serve as the foundation for verifying the arithmetic consistency of knowledge relationships across models, thereby enabling robust attestation of model lineage. Extensive experimental evaluations demonstrate the effectiveness and resilience of our approach in a variety of adversarial scenarios in the real world. Our method consistently achieves reliable lineage verification across a broad spectrum of model types, including classifiers, diffusion models, and large language models.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ·±åº¦å­¦ä¹ å¾®è°ƒæŠ€æœ¯å¼•å‘çš„æ¨¡å‹è¡€ç»Ÿ(Model Lineage)å…³ç³»ï¼Œæå‡ºäº†ä¸€ä¸ªå…¨æ–°çš„æ¨¡å‹è¡€ç»Ÿè¯æ˜æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¼€æºæ¨¡å‹åº“ä¸­å¸¸è§çš„æœªç»æˆæƒå†åˆ†å‘å’Œè™šå‡æ¥æºå£°æ˜ç­‰å®‰å…¨é—®é¢˜ã€‚ä¸ä»…ä¾èµ–é™æ€æ¶æ„ç›¸ä¼¼æ€§çš„ä¼ ç»Ÿæ–¹æ³•ä¸åŒï¼Œè¯¥æ¡†æ¶å—åˆ°äººç±»è¿›åŒ–çš„é—ä¼ æœºåˆ¶å¯å‘ï¼Œé€šè¿‡éªŒè¯çŸ¥è¯†æ¼”åŒ–(Knowledge Evolution)ä¸å‚æ•°ä¿®æ”¹(Parameter Modification)çš„è”åˆè½¨è¿¹æ¥ç¡®ç«‹è¡€ç»Ÿå…³ç³»ã€‚ç ”ç©¶é¦–å…ˆåˆ©ç”¨æ¨¡å‹ç¼–è¾‘æŠ€æœ¯é‡åŒ–å¾®è°ƒå¼•å…¥çš„å‚æ•°çº§å˜åŒ–ï¼Œéšåé€šè¿‡æ¢é’ˆæ ·æœ¬(Probe Samples)è¾…åŠ©çš„çŸ¥è¯†å‘é‡åŒ–æœºåˆ¶å°†æ¼”åŒ–çŸ¥è¯†æç‚¼ä¸ºç´§å‡‘è¡¨ç¤ºã€‚è¿™äº›å‘é‡åŒ–åµŒå…¥æ„æˆäº†éªŒè¯è·¨æ¨¡å‹çŸ¥è¯†å…³ç³»ç®—æœ¯ä¸€è‡´æ€§(Arithmetic Consistency)çš„åŸºç¡€ï¼Œä»è€Œå®ç°é²æ£’çš„è¡€ç»Ÿè¯æ˜ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šç§ç°å®å¯¹æŠ—åœºæ™¯ä¸‹è¡¨ç°å‡ºæé«˜çš„æœ‰æ•ˆæ€§å’ŒéŸ§æ€§ï¼Œèƒ½ä¸ºåˆ†ç±»å™¨ã€æ‰©æ•£æ¨¡å‹(Diffusion Models)åŠå¤§å‹è¯­è¨€æ¨¡å‹(LLMs)ç­‰å¤šç§æ¨¡å‹å®¶æ—æä¾›å¯é çš„è¡€ç»ŸéªŒè¯ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted to the 35th USENIX Security Symposium (USENIX Security 2026)",
      "pdf_url": "https://arxiv.org/pdf/2601.11683v1",
      "published_date": "2026-01-16 08:56:13 UTC",
      "updated_date": "2026-01-16 08:56:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:01:11.716516+00:00"
    },
    {
      "arxiv_id": "2601.11090v1",
      "title": "Efficient Multilingual Name Type Classification Using Convolutional Networks",
      "title_zh": "åŸºäºå·ç§¯ç½‘ç»œçš„é«˜æ•ˆå¤šè¯­è¨€åç§°ç±»å‹åˆ†ç±»",
      "authors": [
        "Davor Lauc"
      ],
      "abstract": "We present a convolutional neural network approach for classifying proper names by language and entity type. Our model, Onomas-CNN X, combines parallel convolution branches with depthwise-separable operations and hierarchical classification to process names efficiently on CPU hardware. We evaluate the architecture on a large multilingual dataset covering 104 languages and four entity types (person, organization, location, other). Onomas-CNN X achieves 92.1% accuracy while processing 2,813 names per second on a single CPU core - 46 times faster than fine-tuned XLM-RoBERTa with comparable accuracy. The model reduces energy consumption by a factor of 46 compared to transformer baselines. Our experiments demonstrate that specialized CNN architectures remain competitive with large pre-trained models for focused NLP tasks when sufficient training data exists.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Onomas-CNN X æ¨¡å‹ï¼Œè¿™æ˜¯ä¸€ç§æ—¨åœ¨é«˜æ•ˆå¤„ç†å¤šè¯­è¨€å§“åç±»å‹åˆ†ç±»çš„å·ç§¯ç¥ç»ç½‘ç»œ (convolutional neural network) æ–¹æ³•ã€‚è¯¥æ¶æ„ç»“åˆäº†å¹³è¡Œå·ç§¯åˆ†æ”¯ (parallel convolution branches)ã€æ·±åº¦å¯åˆ†ç¦»æ“ä½œ (depthwise-separable operations) ä»¥åŠå±‚æ¬¡åŒ–åˆ†ç±» (hierarchical classification)ï¼Œä¸“é—¨ä¼˜åŒ–äº†åœ¨ CPU ç¡¬ä»¶ä¸Šçš„è¿è¡Œæ•ˆç‡ã€‚ç ”ç©¶äººå‘˜åœ¨åŒ…å« 104 ç§è¯­è¨€å’Œå››ç§å®ä½“ç±»å‹çš„å¤§è§„æ¨¡æ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œç»“æœæ˜¾ç¤º Onomas-CNN X è¾¾åˆ°äº† 92.1% çš„å‡†ç¡®ç‡ã€‚åœ¨æ€§èƒ½æµ‹è¯•ä¸­ï¼Œè¯¥æ¨¡å‹å•æ ¸ CPU æ¯ç§’å¯å¤„ç† 2,813 ä¸ªå§“åï¼Œå…¶é€Ÿåº¦å’ŒèŠ‚èƒ½æ•ˆç‡å‡è¾¾åˆ°å¾®è°ƒå XLM-RoBERTa æ¨¡å‹çš„ 46 å€ã€‚å®éªŒç»“æœè¯æ˜ï¼Œå¯¹äºç‰¹å®šçš„ NLP ä»»åŠ¡ï¼Œåœ¨æ‹¥æœ‰å……è¶³è®­ç»ƒæ•°æ®çš„å‰æä¸‹ï¼Œä¸“é—¨è®¾è®¡çš„ CNN æ¶æ„ç›¸è¾ƒäºå¤§å‹é¢„è®­ç»ƒæ¨¡å‹ (large pre-trained models) åœ¨å®é™…åº”ç”¨ä¸­å…·æœ‰æå¼ºçš„æ€§èƒ½ä¸æˆæœ¬ä¼˜åŠ¿ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "Preprint of paper presented at ISAI-NLP Phukat 2025",
      "pdf_url": "https://arxiv.org/pdf/2601.11090v1",
      "published_date": "2026-01-16 08:41:45 UTC",
      "updated_date": "2026-01-16 08:41:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:01:14.639270+00:00"
    },
    {
      "arxiv_id": "2601.11089v2",
      "title": "MiCA: A Mobility-Informed Causal Adapter for Lightweight Epidemic Forecasting",
      "title_zh": "MiCAï¼šèåˆæµåŠ¨ä¿¡æ¯çš„è½»é‡çº§æµè¡Œç—…é¢„æµ‹å› æœé€‚é…å™¨",
      "authors": [
        "Suhan Guo",
        "Jiahong Deng",
        "Furao Shen"
      ],
      "abstract": "Accurate forecasting of infectious disease dynamics is critical for public health planning and intervention. Human mobility plays a central role in shaping the spatial spread of epidemics, but mobility data are noisy, indirect, and difficult to integrate reliably with disease records. Meanwhile, epidemic case time series are typically short and reported at coarse temporal resolution. These conditions limit the effectiveness of parameter-heavy mobility-aware forecasters that rely on clean and abundant data. In this work, we propose the Mobility-Informed Causal Adapter (MiCA), a lightweight and architecture-agnostic module for epidemic forecasting. MiCA infers mobility relations through causal discovery and integrates them into temporal forecasting models via gated residual mixing. This design allows lightweight forecasters to selectively exploit mobility-derived spatial structure while remaining robust under noisy and data-limited conditions, without introducing heavy relational components such as graph neural networks or full attention. Extensive experiments on four real-world epidemic datasets, including COVID-19 incidence, COVID-19 mortality, influenza, and dengue, show that MiCA consistently improves lightweight temporal backbones, achieving an average relative error reduction of 7.5\\% across forecasting horizons. Moreover, MiCA attains performance competitive with SOTA spatio-temporal models while remaining lightweight.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†MiCAï¼Œä¸€ç§ç”¨äºè½»é‡çº§ç–«æƒ…é¢„æµ‹çš„æµåŠ¨æ€§æ„ŸçŸ¥å› æœé€‚é…å™¨(Mobility-Informed Causal Adapter)ï¼Œæ—¨åœ¨è§£å†³äººç±»æµåŠ¨æ€§æ•°æ®(mobility data)å™ªå£°å¤§ã€éš¾ä»¥ä¸ä¼ æŸ“ç—…è®°å½•å¯é é›†æˆçš„éš¾é¢˜ã€‚MiCAä½œä¸ºä¸€ä¸ªæ¶æ„æ— å…³(architecture-agnostic)çš„è½»é‡çº§æ¨¡å—ï¼Œé€šè¿‡å› æœå‘ç°(causal discovery)æ¨æ–­æµåŠ¨æ€§å…³ç³»ï¼Œå¹¶åˆ©ç”¨é—¨æ§æ®‹å·®æ··åˆ(gated residual mixing)å°†å…¶æ•´åˆåˆ°æ—¶é—´é¢„æµ‹æ¨¡å‹ä¸­ã€‚è¯¥è®¾è®¡å…è®¸è½»é‡çº§é¢„æµ‹å™¨åœ¨ä¸å¼•å…¥å›¾ç¥ç»ç½‘ç»œ(GNN)æˆ–å…¨æ³¨æ„åŠ›æœºåˆ¶(full attention)ç­‰é‡å‹ç»„ä»¶çš„æƒ…å†µä¸‹ï¼Œæœ‰æ•ˆåˆ©ç”¨ç©ºé—´ç»“æ„å¹¶å¢å¼ºåœ¨æ•°æ®å—é™ç¯å¢ƒä¸‹çš„é²æ£’æ€§ã€‚åœ¨COVID-19ã€æµæ„Ÿå’Œç™»é©çƒ­ç­‰å››ç§çœŸå®æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒMiCAä½¿è½»é‡çº§æ—¶é—´éª¨å¹²æ¨¡å‹(temporal backbones)çš„å¹³å‡ç›¸å¯¹è¯¯å·®é™ä½äº†7.5%ã€‚å®éªŒè¯æ˜ï¼ŒMiCAåœ¨ä¿æŒè½»é‡åŒ–ç‰¹æ€§çš„åŒæ—¶ï¼Œè¾¾åˆ°äº†ä¸å½“å‰æœ€å…ˆè¿›(SOTA)æ—¶ç©ºæ¨¡å‹ç›¸å½“çš„ç«äº‰æ€§èƒ½ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11089v2",
      "published_date": "2026-01-16 08:41:06 UTC",
      "updated_date": "2026-01-19 01:58:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:01:20.410008+00:00"
    },
    {
      "arxiv_id": "2601.11078v1",
      "title": "Visual Marker Search for Autonomous Drone Landing in Diverse Urban Environments",
      "title_zh": "å¤šæ ·åŒ–åŸå¸‚ç¯å¢ƒä¸‹æ— äººæœºè‡ªä¸»ç€é™†çš„è§†è§‰æ ‡å¿—æœç´¢",
      "authors": [
        "Jiaohong Yao",
        "Linfeng Liang",
        "Yao Deng",
        "Xi Zheng",
        "Richard Han",
        "Yuankai Qi"
      ],
      "abstract": "Marker-based landing is widely used in drone delivery and return-to-base systems for its simplicity and reliability. However, most approaches assume idealized landing site visibility and sensor performance, limiting robustness in complex urban settings. We present a simulation-based evaluation suite on the AirSim platform with systematically varied urban layouts, lighting, and weather to replicate realistic operational diversity. Using onboard camera sensors (RGB for marker detection and depth for obstacle avoidance), we benchmark two heuristic coverage patterns and a reinforcement learning-based agent, analyzing how exploration strategy and scene complexity affect success rate, path efficiency, and robustness. Results underscore the need to evaluate marker-based autonomous landing under diverse, sensor-relevant conditions to guide the development of reliable aerial navigation systems.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ— äººæœºåœ¨å¤æ‚åŸå¸‚ç¯å¢ƒä¸­æ ‡è®°ç‚¹ç€é™†(Marker-based landing)æ—¶ç¨³å¥æ€§ä¸è¶³çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ä¸ªåŸºäºAirSimå¹³å°çš„ä»¿çœŸè¯„ä¼°å¥—ä»¶ã€‚è¯¥å¥—ä»¶é€šè¿‡ç³»ç»Ÿåœ°æ”¹å˜åŸå¸‚å¸ƒå±€ã€å…‰ç…§å’Œå¤©æ°”æ¡ä»¶æ¥æ¨¡æ‹Ÿç°å®æ“ä½œçš„å¤šæ ·æ€§ï¼Œå¹¶ç»“åˆæœºè½½RGBä¼ æ„Ÿå™¨è¿›è¡Œæ ‡è®°æ£€æµ‹(Marker detection)ä»¥åŠæ·±åº¦ä¼ æ„Ÿå™¨è¿›è¡Œéšœç¢ç‰©è§„é¿(Obstacle avoidance)ã€‚ç ”ç©¶å›¢é˜Ÿåˆ©ç”¨è¯¥å¥—ä»¶å¯¹æ¯”æµ‹è¯•äº†ä¸¤ç§å¯å‘å¼è¦†ç›–æ¨¡å¼(Heuristic coverage patterns)ä¸ä¸€ç§åŸºäºå¼ºåŒ–å­¦ä¹ (Reinforcement learning)çš„æ™ºèƒ½ä½“ï¼Œæ·±å…¥åˆ†æäº†æ¢ç´¢ç­–ç•¥å’Œåœºæ™¯å¤æ‚åº¦å¯¹ä»»åŠ¡æˆåŠŸç‡ã€è·¯å¾„æ•ˆç‡åŠç¨³å¥æ€§çš„å½±å“ã€‚å®éªŒç»“æœæ­ç¤ºäº†åœ¨å¤šæ ·åŒ–ä¸”ä¼ æ„Ÿå™¨ç›¸å…³çš„ç¯å¢ƒä¸‹è¿›è¡Œç³»ç»Ÿè¯„ä¼°çš„å¿…è¦æ€§ï¼Œä¸ºå¼€å‘æ›´å¯é çš„è‡ªä¸»æ— äººæœºå¯¼èˆªä¸ç€é™†ç³»ç»Ÿæä¾›äº†ç†è®ºä¾æ®å’ŒæŠ€æœ¯æŒ‡å¯¼ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11078v1",
      "published_date": "2026-01-16 08:24:23 UTC",
      "updated_date": "2026-01-16 08:24:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:01:17.395613+00:00"
    },
    {
      "arxiv_id": "2601.11077v1",
      "title": "ABC-Bench: Benchmarking Agentic Backend Coding in Real-World Development",
      "title_zh": "ABC-Benchï¼šé¢å‘çœŸå®å¼€å‘åœºæ™¯çš„æ™ºèƒ½ä½“åç«¯ç¼–ç åŸºå‡†æµ‹è¯•",
      "authors": [
        "Jie Yang",
        "Honglin Guo",
        "Li Ji",
        "Jiazheng Zhou",
        "Rui Zheng",
        "Zhikai Lei",
        "Shuo Zhang",
        "Zhiheng Xi",
        "Shichun Liu",
        "Yuxin Wang",
        "Bo Wang",
        "Yining Zheng",
        "Tao Gui",
        "Xipeng Qiu"
      ],
      "abstract": "The evolution of Large Language Models (LLMs) into autonomous agents has expanded the scope of AI coding from localized code generation to complex, repository-level, and execution-driven problem solving. However, current benchmarks predominantly evaluate code logic in static contexts, neglecting the dynamic, full-process requirements of real-world engineering, particularly in backend development which demands rigorous environment configuration and service deployment. To address this gap, we introduce ABC-Bench, a benchmark explicitly designed to evaluate agentic backend coding within a realistic, executable workflow. Using a scalable automated pipeline, we curated 224 practical tasks spanning 8 languages and 19 frameworks from open-source repositories. Distinct from previous evaluations, ABC-Bench require the agents to manage the entire development lifecycle from repository exploration to instantiating containerized services and pass the external end-to-end API tests. Our extensive evaluation reveals that even state-of-the-art models struggle to deliver reliable performance on these holistic tasks, highlighting a substantial disparity between current model capabilities and the demands of practical backend engineering. Our code is available at https://github.com/OpenMOSS/ABC-Bench.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨å¤„ç†ç¯å¢ƒé…ç½®å’Œåç«¯æœåŠ¡éƒ¨ç½²ç­‰å¤æ‚ä»»åŠ¡æ—¶å­˜åœ¨çš„è¯„ä¼°ç¼ºå£ï¼Œæå‡ºäº†ABC-Benchï¼Œè¿™æ˜¯ä¸€ä¸ªä¸“é—¨ç”¨äºè¯„ä¼°çœŸå®å¯æ‰§è¡Œå·¥ä½œæµä¸­ä»£ç†åç«¯ç¼–ç (Agentic Backend Coding)èƒ½åŠ›çš„åŸºå‡†æµ‹è¯•ã€‚ç ”ç©¶äººå‘˜é€šè¿‡è‡ªåŠ¨åŒ–ç®¡é“ä»å¼€æºä»“åº“ä¸­ç­›é€‰äº†æ¶‰åŠ8ç§è¯­è¨€å’Œ19ä¸ªæ¡†æ¶çš„224ä¸ªå®é™…å¼€å‘ä»»åŠ¡ã€‚ä¸ä»¥å¾€ä¾§é‡é™æ€é€»è¾‘çš„è¯„ä¼°ä¸åŒï¼ŒABC-Benchè¦æ±‚æ™ºèƒ½ä½“ç®¡ç†ä»ä»“åº“æ¢ç´¢åˆ°å®ä¾‹åŒ–å®¹å™¨åŒ–æœåŠ¡(Containerized Services)çš„å®Œæ•´å¼€å‘ç”Ÿå‘½å‘¨æœŸï¼Œå¹¶å¿…é¡»é€šè¿‡å¤–éƒ¨ç«¯åˆ°ç«¯(End-to-End)çš„APIæµ‹è¯•ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œå³ä½¿æ˜¯å½“å‰æœ€å…ˆè¿›çš„æ¨¡å‹åœ¨å¤„ç†è¿™äº›å…¨æµç¨‹ä»»åŠ¡æ—¶ä¹Ÿéš¾ä»¥æä¾›å¯é è¡¨ç°ï¼Œæ­ç¤ºäº†æ¨¡å‹èƒ½åŠ›ä¸å®é™…åç«¯å·¥ç¨‹éœ€æ±‚ä¹‹é—´çš„æ˜¾è‘—å·®è·ã€‚è¯¥ç ”ç©¶ä¸ºå¼€å‘æ›´å…·å®ç”¨æ€§çš„è‡ªä¸»ç¼–ç¨‹æ™ºèƒ½ä½“æä¾›äº†é‡è¦çš„è¯„ä¼°æ¡†æ¶å’Œæ•°æ®æ”¯æŒã€‚",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11077v1",
      "published_date": "2026-01-16 08:23:52 UTC",
      "updated_date": "2026-01-16 08:23:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:01:18.379799+00:00"
    },
    {
      "arxiv_id": "2601.11076v1",
      "title": "A3D: Adaptive Affordance Assembly with Dual-Arm Manipulation",
      "title_zh": "A3Dï¼šåŸºäºåŒè‡‚æ“ä½œçš„è‡ªé€‚åº”ç¤ºèƒ½ç»„è£…",
      "authors": [
        "Jiaqi Liang",
        "Yue Chen",
        "Qize Yu",
        "Yan Shen",
        "Haipeng Zhang",
        "Hao Dong",
        "Ruihai Wu"
      ],
      "abstract": "Furniture assembly is a crucial yet challenging task for robots, requiring precise dual-arm coordination where one arm manipulates parts while the other provides collaborative support and stabilization. To accomplish this task more effectively, robots need to actively adapt support strategies throughout the long-horizon assembly process, while also generalizing across diverse part geometries. We propose A3D, a framework which learns adaptive affordances to identify optimal support and stabilization locations on furniture parts. The method employs dense point-level geometric representations to model part interaction patterns, enabling generalization across varied geometries. To handle evolving assembly states, we introduce an adaptive module that uses interaction feedback to dynamically adjust support strategies during assembly based on previous interactions. We establish a simulation environment featuring 50 diverse parts across 8 furniture types, designed for dual-arm collaboration evaluation. Experiments demonstrate that our framework generalizes effectively to diverse part geometries and furniture categories in both simulation and real-world settings.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†A3Dï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨é€šè¿‡åŒè‡‚æ“çºµå®ç°å¤æ‚å®¶å…·ç»„è£…ä»»åŠ¡çš„æ¡†æ¶ã€‚å®¶å…·ç»„è£…è¦æ±‚æœºå™¨äººå…·å¤‡ç²¾ç¡®çš„åŒè‡‚åè°ƒèƒ½åŠ›ï¼Œå³ä¸€ä¸ªæœºæ¢°è‡‚æ“çºµéƒ¨ä»¶çš„åŒæ—¶ï¼Œå¦ä¸€ä¸ªæœºæ¢°è‡‚æä¾›åä½œæ”¯æ’‘ä¸ç¨³å®šã€‚A3Dæ¡†æ¶é€šè¿‡å­¦ä¹ Adaptive Affordanceæ¥è¯†åˆ«éƒ¨ä»¶ä¸Šçš„æœ€ä½³æ”¯æ’‘å’Œç¨³å®šä½ç½®ï¼Œå¹¶é‡‡ç”¨ç¨ å¯†çš„ç‚¹çº§å‡ ä½•è¡¨ç¤º(dense point-level geometric representations)æ¥å»ºæ¨¡äº¤äº’æ¨¡å¼ï¼Œä»¥å®ç°å¯¹ä¸åŒå‡ ä½•å½¢çŠ¶çš„æ³›åŒ–ã€‚æ­¤å¤–ï¼Œç ”ç©¶å¼•å…¥äº†ä¸€ä¸ªè‡ªé€‚åº”æ¨¡å—ï¼Œåˆ©ç”¨äº¤äº’åé¦ˆåœ¨é•¿æ—¶ç¨‹ç»„è£…è¿‡ç¨‹ä¸­åŠ¨æ€è°ƒæ•´æ”¯æ’‘ç­–ç•¥ã€‚é€šè¿‡åœ¨åŒ…å«8ç±»å®¶å…·ã€50ç§å¤šæ ·åŒ–éƒ¨ä»¶çš„ä»¿çœŸç¯å¢ƒåŠçœŸå®ä¸–ç•Œä¸­è¿›è¡Œå®éªŒï¼Œç»“æœè¯æ˜è¯¥æ¡†æ¶èƒ½æœ‰æ•ˆæ³›åŒ–è‡³å¤šæ ·çš„éƒ¨ä»¶å‡ ä½•å½¢çŠ¶å’Œå®¶å…·ç±»åˆ«ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "AAAI2026 oral",
      "pdf_url": "https://arxiv.org/pdf/2601.11076v1",
      "published_date": "2026-01-16 08:21:42 UTC",
      "updated_date": "2026-01-16 08:21:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:01:26.960735+00:00"
    },
    {
      "arxiv_id": "2601.11073v1",
      "title": "Bridging Cognitive Neuroscience and Graph Intelligence: Hippocampus-Inspired Multi-View Hypergraph Learning for Web Finance Fraud",
      "title_zh": "è¿æ¥è®¤çŸ¥ç¥ç»ç§‘å­¦ä¸å›¾æ™ºèƒ½ï¼šå—æµ·é©¬ä½“å¯å‘çš„ç½‘ç»œé‡‘èæ¬ºè¯ˆå¤šè§†å›¾è¶…å›¾å­¦ä¹ ",
      "authors": [
        "Rongkun Cui",
        "Nana Zhang",
        "Kun Zhu",
        "Qi Zhang"
      ],
      "abstract": "Online financial services constitute an essential component of contemporary web ecosystems, yet their openness introduces substantial exposure to fraud that harms vulnerable users and weakens trust in digital finance. Such threats have become a significant web harm that erodes societal fairness and affects the well being of online communities. However, existing detection methods based on graph neural networks (GNNs) struggle with two persistent challenges: (1) fraud camouflage, where malicious transactions mimic benign behaviors to evade detection, and (2) long-tailed data distributions, which obscure rare but critical fraudulent cases. To fill these gaps, we propose HIMVH, a Hippocampus-Inspired Multi-View Hypergraph learning model for web finance fraud detection. Specifically, drawing inspiration from the scene conflict monitoring role of the hippocampus, we design a cross-view inconsistency perception module that captures subtle discrepancies and behavioral heterogeneity across multiple transaction views. This module enables the model to identify subtle cross-view conflicts for detecting online camouflaged fraudulent behaviors. Furthermore, inspired by the match-mismatch novelty detection mechanism of the CA1 region, we introduce a novelty-aware hypergraph learning module that measures feature deviations from neighborhood expectations and adaptively reweights messages, thereby enhancing sensitivity to online rare fraud patterns in the long-tailed settings. Extensive experiments on six web-based financial fraud datasets demonstrate that HIMVH achieves 6.42\\% improvement in AUC, 9.74\\% in F1 and 39.14\\% in AP on average over 15 SOTA models.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç½‘ç»œé‡‘èæ¬ºè¯ˆæ£€æµ‹ä¸­å­˜åœ¨çš„æ¬ºè¯ˆä¼ªè£…(fraud camouflage)å’Œé•¿å°¾æ•°æ®åˆ†å¸ƒ(long-tailed data distributions)ä¸¤å¤§æ ¸å¿ƒæŒ‘æˆ˜ï¼Œæå‡ºäº†å—è®¤çŸ¥ç¥ç»ç§‘å­¦å¯å‘çš„æµ·é©¬ä½“å¤šè§†å›¾è¶…å›¾å­¦ä¹ æ¨¡å‹HIMVHã€‚è¯¥æ¨¡å‹å€Ÿé‰´æµ·é©¬ä½“(Hippocampus)çš„åœºæ™¯å†²çªç›‘æµ‹åŠŸèƒ½ï¼Œè®¾è®¡äº†è·¨è§†å›¾ä¸ä¸€è‡´æ„ŸçŸ¥æ¨¡å—(cross-view inconsistency perception module)ï¼Œé€šè¿‡æ•æ‰å¤šè§†å›¾äº¤æ˜“é—´çš„è¡Œä¸ºå¼‚æ„æ€§æ¥è¯†åˆ«é«˜åº¦éšè”½çš„ä¼ªè£…æ¬ºè¯ˆè¡Œä¸ºã€‚æ­¤å¤–ï¼Œå—æµ·é©¬ä½“CA1åŒºæ–°é¢–æ€§æ£€æµ‹æœºåˆ¶çš„å¯å‘ï¼Œæ¨¡å‹å¼•å…¥äº†æ–°é¢–æ€§æ„ŸçŸ¥è¶…å›¾å­¦ä¹ æ¨¡å—(novelty-aware hypergraph learning module)ï¼Œé€šè¿‡è¡¡é‡ç‰¹å¾åå·®å’Œè‡ªé€‚åº”æ¶ˆæ¯é‡æƒæå‡äº†å¯¹é•¿å°¾åˆ†å¸ƒä¸­ç½•è§æ¬ºè¯ˆæ¨¡å¼çš„æ•æ„Ÿæ€§ã€‚åœ¨å…­ä¸ªç½‘ç»œé‡‘èæ¬ºè¯ˆæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒHIMVHåœ¨AUCã€F1å’ŒAPæŒ‡æ ‡ä¸Šç›¸è¾ƒäº15ç§åŸºçº¿æ¨¡å‹å¹³å‡åˆ†åˆ«æå‡äº†6.42%ã€9.74%å’Œ39.14%ï¼Œè¯æ˜äº†è¯¥è·¨å­¦ç§‘æ–¹æ³•åœ¨å¤„ç†å¤æ‚é‡‘èå®‰å…¨é—®é¢˜ä¸Šçš„ä¼˜è¶Šæ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11073v1",
      "published_date": "2026-01-16 08:18:23 UTC",
      "updated_date": "2026-01-16 08:18:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:01:27.522213+00:00"
    },
    {
      "arxiv_id": "2601.11065v1",
      "title": "Fairness in Healthcare Processes: A Quantitative Analysis of Decision Making in Triage",
      "title_zh": "åŒ»ç–—æµç¨‹å…¬å¹³æ€§ï¼šåˆ†è¯Šå†³ç­–çš„å®šé‡åˆ†æ",
      "authors": [
        "Rachmadita Andreswari",
        "Stephan A. Fahrenkrog-Petersen",
        "Jan Mendling"
      ],
      "abstract": "Fairness in automated decision-making has become a critical concern, particularly in high-pressure healthcare scenarios such as emergency triage, where fast and equitable decisions are essential. Process mining is increasingly investigating fairness. There is a growing area focusing on fairness-aware algorithms. So far, we know less how these concepts perform on empirical healthcare data or how they cover aspects of justice theory. This study addresses this research problem and proposes a process mining approach to assess fairness in triage by linking real-life event logs with conceptual dimensions of justice. Using the MIMICEL event log (as derived from MIMIC-IV ED), we analyze time, re-do, deviation and decision as process outcomes, and evaluate the influence of age, gender, race, language and insurance using the Kruskal-Wallis, Chi-square and effect size measurements. These outcomes are mapped to justice dimensions to support the development of a conceptual framework. The results demonstrate which aspects of potential unfairness in high-acuity and sub-acute surface. In this way, this study contributes empirical insights that support further research in responsible, fairness-aware process mining in healthcare.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ€¥è¯Šåˆ†è¯Š(Triage)å†³ç­–è¿‡ç¨‹ä¸­çš„å…¬å¹³æ€§é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºæµç¨‹æŒ–æ˜(Process mining)çš„è¯„ä¼°æ–¹æ³•ï¼Œæ—¨åœ¨å°†çœŸå®äº‹ä»¶æ—¥å¿—ä¸æ­£ä¹‰ç†è®º(Justice theory)çš„ç»´åº¦ç›¸ç»“åˆã€‚ç ”ç©¶äººå‘˜åˆ©ç”¨æºè‡ªMIMIC-IV EDçš„MIMICELäº‹ä»¶æ—¥å¿—ï¼Œå¯¹æ—¶é—´ã€é‡å¤æ“ä½œã€åå·®å’Œå†³ç­–ç­‰è¿‡ç¨‹ç»“æœè¿›è¡Œäº†æ·±å…¥åˆ†æã€‚é€šè¿‡åº”ç”¨Kruskal-Wallisã€Chi-squareæ£€éªŒåŠæ•ˆåº”å€¼æµ‹é‡ï¼Œç³»ç»Ÿè¯„ä¼°äº†å¹´é¾„ã€æ€§åˆ«ã€ç§æ—ã€è¯­è¨€å’Œä¿é™©çŠ¶å†µå¯¹åŒ»ç–—å†³ç­–çš„å…·ä½“å½±å“ã€‚å®éªŒç»“æœæ­ç¤ºäº†åœ¨é«˜åº¦æ€¥æ€§(High-acuity)å’Œäºšæ€¥æ€§(Sub-acute)åˆ†è¯Šåœºæ™¯ä¸­å­˜åœ¨çš„æ½œåœ¨ä¸å…¬å¹³ç°è±¡ã€‚è¯¥ç ”ç©¶é€šè¿‡å®è¯åˆ†æä¸ºåŒ»ç–—é¢†åŸŸä¸­è´Ÿè´£ä»»ä¸”å…·å¤‡å…¬å¹³æ„è¯†(Fairness-aware)çš„æµç¨‹æŒ–æ˜æä¾›äº†é‡è¦è§è§£ï¼Œå¹¶æ”¯æŒäº†ç›¸å…³æ¦‚å¿µæ¡†æ¶çš„æ„å»ºã€‚",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "conference",
      "pdf_url": "https://arxiv.org/pdf/2601.11065v1",
      "published_date": "2026-01-16 08:02:33 UTC",
      "updated_date": "2026-01-16 08:02:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:01:33.286030+00:00"
    },
    {
      "arxiv_id": "2601.11063v1",
      "title": "H-AIM: Orchestrating LLMs, PDDL, and Behavior Trees for Hierarchical Multi-Robot Planning",
      "title_zh": "H-AIMï¼šèåˆå¤§è¯­è¨€æ¨¡å‹ã€PDDL ä¸è¡Œä¸ºæ ‘çš„åˆ†å±‚å¤šæœºå™¨äººè§„åˆ’",
      "authors": [
        "Haishan Zeng",
        "Peng Li"
      ],
      "abstract": "In embodied artificial intelligence, enabling heterogeneous robot teams to execute long-horizon tasks from high-level instructions remains a critical challenge. While large language models (LLMs) show promise in instruction parsing and preliminary planning, they exhibit limitations in long-term reasoning and dynamic multi-robot coordination. We propose Hierarchical Autonomous Intelligent Multi-Robot Planning(H-AIM), a novel embodied multi-robot task planning framework that addresses these issues through a three-stage cascaded architecture: 1) It leverages an LLM to parse instructions and generate Planning Domain Definition Language (PDDL) problem descriptions, thereby transforming commands into formal planning problems; 2) It combines the semantic reasoning of LLMs with the search capabilities of a classical planner to produce optimized action sequences; 3) It compiles the resulting plan into behavior trees for reactive control. The framework supports dynamically sized heterogeneous robot teams via a shared blackboard mechanism for communication and state synchronization. To validate our approach, we introduce the MACE-THOR benchmark dataset, comprising 42 complex tasks across 8 distinct household layouts. Experimental results demonstrate that H-AIM achieves a remarkable performance improvement, elevating the task success rate from 12% to 55% and boosting the goal condition recall from 32% to 72% against the strongest baseline, LaMMA-P.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†H-AIMï¼Œä¸€ç§æ—¨åœ¨è§£å†³å¼‚æ„æœºå™¨äººå›¢é˜Ÿåœ¨æ‰§è¡Œé•¿ç¨‹ä»»åŠ¡(long-horizon tasks)æ—¶é¢ä¸´çš„é•¿æœŸæ¨ç†å’ŒåŠ¨æ€åä½œéš¾é¢˜çš„å±‚æ¬¡åŒ–å¤šæœºå™¨äººè§„åˆ’æ¡†æ¶ã€‚è¯¥æ¡†æ¶é‡‡ç”¨äº†ä¸‰é˜¶æ®µçº§è”æ¶æ„ï¼Œé¦–å…ˆåˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹(LLMs)å°†é«˜å±‚æŒ‡ä»¤è§£æå¹¶è½¬åŒ–ä¸ºè§„åˆ’é¢†åŸŸå®šä¹‰è¯­è¨€(PDDL)é—®é¢˜æè¿°ã€‚éšåï¼ŒH-AIMå°†LLMsçš„è¯­ä¹‰æ¨ç†èƒ½åŠ›ä¸ç»å…¸è§„åˆ’å™¨çš„æœç´¢èƒ½åŠ›ç›¸ç»“åˆï¼Œç”Ÿæˆä¼˜åŒ–çš„åŠ¨ä½œåºåˆ—ã€‚æœ€ç»ˆï¼Œç”Ÿæˆçš„è®¡åˆ’è¢«ç¼–è¯‘ä¸ºè¡Œä¸ºæ ‘(Behavior Trees)ä»¥å®ç°ååº”å¼æ§åˆ¶ã€‚é€šè¿‡å…±äº«é»‘æ¿æœºåˆ¶(shared blackboard mechanism)ï¼Œè¯¥æ¡†æ¶æ”¯æŒäº†åŠ¨æ€è§„æ¨¡çš„å¼‚æ„æœºå™¨äººå›¢é˜Ÿè¿›è¡Œé€šä¿¡ä¸çŠ¶æ€åŒæ­¥ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨MACE-THORåŸºå‡†æµ‹è¯•ä¸­ï¼ŒH-AIMå°†ä»»åŠ¡æˆåŠŸç‡ä»12%æ˜¾è‘—æå‡è‡³55%ï¼Œå¹¶å¤§å¹…å¢å¼ºäº†ç›®æ ‡æ¡ä»¶å¬å›ç‡ï¼Œæ€§èƒ½è¿œè¶…LaMMA-Pç­‰åŸºçº¿æ¨¡å‹ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11063v1",
      "published_date": "2026-01-16 07:59:50 UTC",
      "updated_date": "2026-01-16 07:59:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:01:32.834647+00:00"
    },
    {
      "arxiv_id": "2601.11676v1",
      "title": "HALO: Semantic-Aware Distributed LLM Inference in Lossy Edge Network",
      "title_zh": "HALOï¼šé¢å‘æœ‰æŸè¾¹ç¼˜ç½‘ç»œçš„è¯­ä¹‰æ„ŸçŸ¥åˆ†å¸ƒå¼å¤§è¯­è¨€æ¨¡å‹æ¨ç†",
      "authors": [
        "Peirong Zheng",
        "Wenchao Xu",
        "Haozhao Wang",
        "Jinyu Chen",
        "Xuemin Shen"
      ],
      "abstract": "The deployment of large language models' (LLMs) inference at the edge can facilitate prompt service responsiveness while protecting user privacy. However, it is critically challenged by the resource constraints of a single edge node. Distributed inference has emerged to aggregate and leverage computational resources across multiple devices. Yet, existing methods typically require strict synchronization, which is often infeasible due to the unreliable network conditions. In this paper, we propose HALO, a novel framework that can boost the distributed LLM inference in lossy edge network. The core idea is to enable a relaxed yet effective synchronization by strategically allocating less critical neuron groups to unstable devices, thus avoiding the excessive waiting time incurred by delayed packets. HALO introduces three key mechanisms: (1) a semantic-aware predictor to assess the significance of neuron groups prior to activation. (2) a parallel execution scheme of neuron group loading during the model inference. (3) a load-balancing scheduler that efficiently orchestrates multiple devices with heterogeneous resources. Experimental results from a Raspberry Pi cluster demonstrate that HALO achieves a 3.41x end-to-end speedup for LLaMA-series LLMs under unreliable network conditions. It maintains performance comparable to optimal conditions and significantly outperforms the state-of-the-art in various scenarios.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†HALOæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨æœ‰æŸè¾¹ç¼˜ç½‘ç»œ(Lossy Edge Network)ä¸­è¿›è¡Œåˆ†å¸ƒå¼æ¨ç†æ—¶é¢ä¸´çš„ä¸¥æ ¼åŒæ­¥éš¾é¢˜ã€‚HALOé€šè¿‡ç­–ç•¥æ€§åœ°å°†é‡è¦æ€§è¾ƒä½çš„ç¥ç»å…ƒç»„(Neuron groups)åˆ†é…ç»™ä¸ç¨³å®šè®¾å¤‡ï¼Œå®ç°äº†æ¾å¼›ä¸”æœ‰æ•ˆçš„åŒæ­¥ï¼Œä»è€Œé¿å…äº†æ•°æ®åŒ…å»¶è¿Ÿå¯¼è‡´çš„è¿‡åº¦ç­‰å¾…ã€‚è¯¥æ¡†æ¶å¼•å…¥äº†ä¸‰ä¸ªå…³é”®æœºåˆ¶ï¼šè¯„ä¼°ç¥ç»å…ƒç»„é‡è¦æ€§çš„è¯­ä¹‰æ„ŸçŸ¥é¢„æµ‹å™¨(Semantic-aware predictor)ã€æ¨ç†è¿‡ç¨‹ä¸­çš„ç¥ç»å…ƒç»„å¹¶è¡ŒåŠ è½½æ–¹æ¡ˆï¼Œä»¥åŠä¼˜åŒ–å¼‚æ„èµ„æºè°ƒåº¦çš„è´Ÿè½½å‡è¡¡è°ƒåº¦å™¨(Load-balancing scheduler)ã€‚åœ¨æ ‘è“æ´¾(Raspberry Pi)é›†ç¾¤ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒHALOåœ¨ä¸ç¨³å®šçš„ç½‘ç»œæ¡ä»¶ä¸‹ä¸ºLLaMAç³»åˆ—æ¨¡å‹å¸¦æ¥äº†3.41å€çš„ç«¯åˆ°ç«¯åŠ é€Ÿã€‚å®éªŒç»“æœè¯æ˜è¯¥æ¡†æ¶èƒ½å¤Ÿç»´æŒä¸ç†æƒ³ç½‘ç»œæ¡ä»¶ç›¸å½“çš„æ€§èƒ½ï¼Œå¹¶åœ¨å¤šç§è¾¹ç¼˜è®¡ç®—åœºæ™¯ä¸­æ˜¾è‘—ä¼˜äºç°æœ‰æœ€å…ˆè¿›æŠ€æœ¯ã€‚",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.NI"
      ],
      "primary_category": "cs.DC",
      "comment": "Accepted by IEEE International Conference on Computer Communications (INFOCOM) 2026",
      "pdf_url": "https://arxiv.org/pdf/2601.11676v1",
      "published_date": "2026-01-16 07:37:23 UTC",
      "updated_date": "2026-01-16 07:37:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:01:34.253167+00:00"
    },
    {
      "arxiv_id": "2601.14295v1",
      "title": "Epistemic Constitutionalism Or: how to avoid coherence bias",
      "title_zh": "è®¤è¯†è®ºå®ªåˆ¶ï¼šå¦‚ä½•é¿å…è¿è´¯æ€§åå·®",
      "authors": [
        "Michele Loi"
      ],
      "abstract": "Large language models increasingly function as artificial reasoners: they evaluate arguments, assign credibility, and express confidence. Yet their belief-forming behavior is governed by implicit, uninspected epistemic policies. This paper argues for an epistemic constitution for AI: explicit, contestable meta-norms that regulate how systems form and express beliefs. Source attribution bias provides the motivating case: I show that frontier models enforce identity-stance coherence, penalizing arguments attributed to sources whose expected ideological position conflicts with the argument's content. When models detect systematic testing, these effects collapse, revealing that systems treat source-sensitivity as bias to suppress rather than as a capacity to execute well. I distinguish two constitutional approaches: the Platonic, which mandates formal correctness and default source-independence from a privileged standpoint, and the Liberal, which refuses such privilege, specifying procedural norms that protect conditions for collective inquiry while allowing principled source-attending grounded in epistemic vigilance. I argue for the Liberal approach, sketch a constitutional core of eight principles and four orientations, and propose that AI epistemic governance requires the same explicit, contestable structure we now expect for AI ethics.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)ä½œä¸ºäººå·¥æ¨ç†è€…åœ¨ä¿¡å¿µå½¢æˆè¿‡ç¨‹ä¸­å­˜åœ¨çš„éšå½¢è®¤çŸ¥ç­–ç•¥é—®é¢˜ï¼Œå¹¶æå‡ºäº†å»ºç«‹AIâ€œè®¤çŸ¥å®ªæ³•â€(epistemic constitution)çš„æ„æƒ³ã€‚é€šè¿‡å¯¹æ¥æºå½’å› åå·®(source attribution bias)çš„ç ”ç©¶ï¼Œä½œè€…å‘ç°å‰æ²¿æ¨¡å‹æ™®éå­˜åœ¨èº«ä»½ç«‹åœºä¸€è‡´æ€§(identity-stance coherence)ç°è±¡ï¼Œå³ä¼šç”±äºæ¥æºçš„æ„è¯†å½¢æ€èƒŒæ™¯ä¸è®ºç‚¹å†…å®¹å†²çªè€Œé™ä½è¯„ä»·ã€‚å®éªŒè¿›ä¸€æ­¥æ­ç¤ºäº†ç³»ç»Ÿå€¾å‘äºå°†æ¥æºæ•æ„Ÿæ€§è§†ä¸ºåº”è¢«æŠ‘åˆ¶çš„åå·®(bias)ï¼Œè€Œéä¸€ç§ç²¾ç»†æ‰§è¡Œçš„èƒ½åŠ›ã€‚ç ”ç©¶å¯¹æ¯”äº†å¼ºè°ƒå½¢å¼æ­£ç¡®æ€§çš„æŸæ‹‰å›¾å¼(Platonic)è·¯å¾„ä¸ä¿æŠ¤é›†ä½“æ¢ç©¶æ¡ä»¶çš„è‡ªç”±ä¸»ä¹‰(Liberal)è·¯å¾„ï¼Œå¹¶æ˜ç¡®ä¸»å¼ åè€…ã€‚ä½œè€…æœ€åæå‡ºäº†ç”±å…«é¡¹åŸåˆ™å’Œå››ä¸ªå¯¼å‘æ„æˆçš„å®ªæ³•æ ¸å¿ƒï¼Œè®¤ä¸ºAIè®¤çŸ¥æ²»ç†(epistemic governance)åº”å…·å¤‡ä¸AIä¼¦ç†åŒç­‰çš„æ˜¾æ€§ä¸”å¯äº‰è¾©çš„ç»“æ„ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "27 pages, 7 tables. Data: github.com/MicheleLoi/source-attribution-bias-data and github.com/MicheleLoi/source-attribution-bias-swiss-replication. Complete AI-assisted writing documentation: github.com/MicheleLoi/epistemic-constitutionalism-paper",
      "pdf_url": "https://arxiv.org/pdf/2601.14295v1",
      "published_date": "2026-01-16 07:36:30 UTC",
      "updated_date": "2026-01-16 07:36:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:01:49.448942+00:00"
    },
    {
      "arxiv_id": "2601.11049v1",
      "title": "Predicting Biased Human Decision-Making with Large Language Models in Conversational Settings",
      "title_zh": "åŸºäºå¤§è¯­è¨€æ¨¡å‹é¢„æµ‹å¯¹è¯åœºæ™¯ä¸‹çš„äººç±»å†³ç­–åè§",
      "authors": [
        "Stephen Pilli",
        "Vivek Nallur"
      ],
      "abstract": "We examine whether large language models (LLMs) can predict biased decision-making in conversational settings, and whether their predictions capture not only human cognitive biases but also how those effects change under cognitive load. In a pre-registered study (N = 1,648), participants completed six classic decision-making tasks via a chatbot with dialogues of varying complexity. Participants exhibited two well-documented cognitive biases: the Framing Effect and the Status Quo Bias. Increased dialogue complexity resulted in participants reporting higher mental demand. This increase in cognitive load selectively, but significantly, increased the effect of the biases, demonstrating the load-bias interaction. We then evaluated whether LLMs (GPT-4, GPT-5, and open-source models) could predict individual decisions given demographic information and prior dialogue. While results were mixed across choice problems, LLM predictions that incorporated dialogue context were significantly more accurate in several key scenarios. Importantly, their predictions reproduced the same bias patterns and load-bias interactions observed in humans. Across all models tested, the GPT-4 family consistently aligned with human behavior, outperforming GPT-5 and open-source models in both predictive accuracy and fidelity to human-like bias patterns. These findings advance our understanding of LLMs as tools for simulating human decision-making and inform the design of conversational agents that adapt to user biases.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)æ˜¯å¦èƒ½åœ¨å¯¹è¯åœºæ™¯ä¸‹é¢„æµ‹äººç±»çš„åè§å†³ç­–ï¼Œå¹¶åˆ†æå…¶é¢„æµ‹æ˜¯å¦æ•æ‰åˆ°äº†è®¤çŸ¥åè§åŠè®¤çŸ¥è´Ÿè·(Cognitive Load)å¯¹è¿™äº›åè§çš„å½±å“ã€‚é€šè¿‡ä¸€é¡¹æ¶‰åŠ1,648åå—è¯•è€…çš„é¢„æ³¨å†Œç ”ç©¶ï¼Œç ”ç©¶è€…åˆ©ç”¨èŠå¤©æœºå™¨äººè®©å‚ä¸è€…åœ¨ä¸åŒå¤æ‚åº¦çš„å¯¹è¯ä¸­å®Œæˆå…­é¡¹ç»å…¸å†³ç­–ä»»åŠ¡ã€‚å®éªŒç»“æœè¯å®äººç±»è¡¨ç°å‡ºæ˜¾è‘—çš„æ¡†æ¶æ•ˆåº”(Framing Effect)å’Œç°çŠ¶åè§(Status Quo Bias)ï¼Œä¸”éšç€å¯¹è¯å¤æ‚åº¦å¢åŠ å¯¼è‡´çš„è®¤çŸ¥è´Ÿè·ä¸Šå‡ï¼Œè¿™äº›åè§çš„å½±å“æ˜¾è‘—å¢å¼ºã€‚éšåè¯„ä¼°äº†GPT-4ã€GPT-5åŠå¼€æºæ¨¡å‹åœ¨ç»™å®šäººå£ç»Ÿè®¡ä¿¡æ¯å’Œå¯¹è¯èƒŒæ™¯ä¸‹é¢„æµ‹ä¸ªä½“å†³ç­–çš„èƒ½åŠ›ã€‚ç ”ç©¶å‘ç°ï¼Œçº³å…¥å¯¹è¯ä¸Šä¸‹æ–‡çš„LLMé¢„æµ‹åœ¨å¤šä¸ªå…³é”®åœºæ™¯ä¸­å‡†ç¡®æ€§æ˜¾è‘—æé«˜ï¼Œä¸”æˆåŠŸå¤ç°äº†äººç±»è§‚å¯Ÿåˆ°çš„åè§æ¨¡å¼åŠå…¶ä¸è®¤çŸ¥è´Ÿè·çš„äº¤äº’ä½œç”¨ã€‚åœ¨æ‰€æœ‰æµ‹è¯•æ¨¡å‹ä¸­ï¼ŒGPT-4ç³»åˆ—åœ¨é¢„æµ‹å‡†ç¡®æ€§å’Œå¯¹ç±»äººåè§æ¨¡å¼çš„è¿˜åŸåº¦ä¸Šè¡¨ç°æœ€å‡ºè‰²ï¼Œä¼˜äºGPT-5å’Œå¼€æºæ¨¡å‹ã€‚è¯¥ç ”ç©¶æ·±åŒ–äº†å¯¹LLMä½œä¸ºæ¨¡æ‹Ÿäººç±»å†³ç­–å·¥å…·çš„ç†è§£ï¼Œå¹¶ä¸ºå¼€å‘èƒ½é€‚åº”ç”¨æˆ·åè§çš„å¯¹è¯æ™ºèƒ½ä½“æä¾›äº†ç†è®ºä¾æ®ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "Accepted at ACM IUI 2026",
      "pdf_url": "https://arxiv.org/pdf/2601.11049v1",
      "published_date": "2026-01-16 07:30:21 UTC",
      "updated_date": "2026-01-16 07:30:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:01:50.154468+00:00"
    },
    {
      "arxiv_id": "2601.11044v2",
      "title": "AgencyBench: Benchmarking the Frontiers of Autonomous Agents in 1M-Token Real-World Contexts",
      "title_zh": "AgencyBenchï¼šç™¾ä¸‡ Token çœŸå®åœºæ™¯ä¸‹çš„è‡ªä¸»æ™ºèƒ½ä½“å‰æ²¿èƒ½åŠ›åŸºå‡†æµ‹è¯•",
      "authors": [
        "Keyu Li",
        "Junhao Shi",
        "Yang Xiao",
        "Mohan Jiang",
        "Jie Sun",
        "Yunze Wu",
        "Shijie Xia",
        "Xiaojie Cai",
        "Tianze Xu",
        "Weiye Si",
        "Wenjie Li",
        "Dequan Wang",
        "Pengfei Liu"
      ],
      "abstract": "Large Language Models (LLMs) based autonomous agents demonstrate multifaceted capabilities to contribute substantially to economic production. However, existing benchmarks remain focused on single agentic capability, failing to capture long-horizon real-world scenarios. Moreover, the reliance on human-in-the-loop feedback for realistic tasks creates a scalability bottleneck, hindering automated rollout collection and evaluation. To bridge this gap, we introduce AgencyBench, a comprehensive benchmark derived from daily AI usage, evaluating 6 core agentic capabilities across 32 real-world scenarios, comprising 138 tasks with specific queries, deliverables, and rubrics. These scenarios require an average of 90 tool calls, 1 million tokens, and hours of execution time to resolve. To enable automated evaluation, we employ a user simulation agent to provide iterative feedback, and a Docker sandbox to conduct visual and functional rubric-based assessment. Experiments reveal that closed-source models significantly outperform open-source models (48.4% vs 32.1%). Further analysis reveals significant disparities across models in resource efficiency, feedback-driven self-correction, and specific tool-use preferences. Finally, we investigate the impact of agentic scaffolds, observing that proprietary models demonstrate superior performance within their native ecosystems (e.g., Claude-4.5-Opus via Claude-Agent-SDK), while open-source models exhibit distinct performance peaks, suggesting potential optimization for specific execution frameworks. AgencyBench serves as a critical testbed for next-generation agents, highlighting the necessity of co-optimizing model architecture with agentic frameworks. We believe this work sheds light on the future direction of autonomous agents, and we release the full benchmark and evaluation toolkit at https://github.com/GAIR-NLP/AgencyBench.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°æœ‰å¤§è¯­è¨€æ¨¡å‹(LLMs)é©±åŠ¨çš„è‡ªåŠ¨æ™ºèƒ½ä½“(autonomous agents)è¯„æµ‹åŸºå‡†é›†ä¸­äºå•ä¸€èƒ½åŠ›ä¸”ç¼ºä¹é•¿ç¨‹çœŸå®åœºæ™¯çš„é—®é¢˜ï¼Œæå‡ºäº†AgencyBenchã€‚è¿™æ˜¯ä¸€ä¸ªæ¶µç›–32ä¸ªçœŸå®åœºæ™¯ã€6é¡¹æ ¸å¿ƒæ™ºèƒ½ä½“èƒ½åŠ›çš„ç»¼åˆè¯„æµ‹åŸºå‡†ï¼ŒåŒ…å«138ä¸ªå…·æœ‰ç‰¹å®šæŸ¥è¯¢ã€äº¤ä»˜ç‰©å’Œè¯„ä¼°å‡†åˆ™çš„ä»»åŠ¡ï¼Œå¹³å‡æ¯ä¸ªä»»åŠ¡æ¶‰åŠ100ä¸‡ä¸ªtokenå’Œ90æ¬¡å·¥å…·è°ƒç”¨(tool calls)ã€‚ä¸ºäº†å…‹æœäººå·¥åé¦ˆå¸¦æ¥çš„æ‰©å±•æ€§ç“¶é¢ˆï¼Œè¯¥æ¡†æ¶å¼•å…¥äº†ç”¨æˆ·æ¨¡æ‹Ÿæ™ºèƒ½ä½“(user simulation agent)æä¾›è¿­ä»£åé¦ˆï¼Œå¹¶åˆ©ç”¨Dockeræ²™ç®±(sandbox)è¿›è¡ŒåŸºäºè§†è§‰å’ŒåŠŸèƒ½çš„è‡ªåŠ¨åŒ–è¯„ä¼°ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œé—­æºæ¨¡å‹(closed-source models)çš„è¡¨ç°æ˜¾è‘—ä¼˜äºå¼€æºæ¨¡å‹ï¼Œä¸”ä¸¤è€…åœ¨èµ„æºæ•ˆç‡ã€è‡ªæˆ‘ä¿®å¤(self-correction)å’Œå·¥å…·ä½¿ç”¨åå¥½ä¸Šå­˜åœ¨æ˜æ˜¾å·®å¼‚ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜æ¢è®¨äº†æ™ºèƒ½ä½“æ¶æ„(agentic scaffolds)çš„å½±å“ï¼Œå‘ç°é—­æºæ¨¡å‹åœ¨å…¶åŸç”Ÿç”Ÿæ€ç³»ç»Ÿä¸‹è¡¨ç°æ›´ä¼˜ï¼Œè€Œå¼€æºæ¨¡å‹åˆ™åœ¨ç‰¹å®šæ‰§è¡Œæ¡†æ¶ä¸‹è¡¨ç°å‡ºæ€§èƒ½å³°å€¼ã€‚AgencyBenchä¸ºä¸‹ä¸€ä»£æ™ºèƒ½ä½“çš„å¼€å‘æä¾›äº†å…³é”®å®éªŒåœºï¼Œå¼ºè°ƒäº†æ¨¡å‹æ¶æ„ä¸æ™ºèƒ½ä½“æ¡†æ¶ååŒä¼˜åŒ–çš„å¿…è¦æ€§ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11044v2",
      "published_date": "2026-01-16 07:22:20 UTC",
      "updated_date": "2026-01-19 13:21:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:01:53.968238+00:00"
    },
    {
      "arxiv_id": "2601.11042v1",
      "title": "Spectral Characterization and Mitigation of Sequential Knowledge Editing Collapse",
      "title_zh": "è¿ç»­çŸ¥è¯†ç¼–è¾‘å´©æºƒçš„è°±ç‰¹æ€§è¡¨å¾ä¸ç¼“è§£",
      "authors": [
        "Chi Zhang",
        "Mengqi Zhang",
        "Xiaotian Ye",
        "Runxi Cheng",
        "Zisheng Zhou",
        "Ying Zhou",
        "Pengjie Ren",
        "Zhumin Chen"
      ],
      "abstract": "Sequential knowledge editing in large language models often causes catastrophic collapse of the model's general abilities, especially for parameter-modifying methods. Existing approaches mitigate this issue through heuristic constraints on parameter updates, yet the mechanisms underlying such degradation remain insufficiently understood. In this work, we present a spectral analysis of sequential knowledge editing and show that a model's general abilities are closely associated with dominant singular directions of pretrained weight matrices. These directions are highly sensitive to perturbations and are progressively disrupted by repeated edits, closely tracking the collapse in both editing efficacy and general performance. Building on this insight, we propose REVIVE, a plug-and-play framework that stabilizes sequential editing by explicitly preserving the dominant singular subspace. REVIVE represents parameter updates in the spectral basis of the original weights and filters components that would interfere with the protected region. Extensive experiments across multiple models and benchmarks show that REVIVE consistently improves editing efficacy while substantially preserving general abilities under long-horizon sequential editing, including extreme settings with up to 20,000 edits.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹åœ¨è¿ç»­çŸ¥è¯†ç¼–è¾‘(Sequential knowledge editing)è¿‡ç¨‹ä¸­å‡ºç°çš„é€šç”¨èƒ½åŠ›ç¾éš¾æ€§åç¼©é—®é¢˜ï¼Œé€šè¿‡é¢‘è°±åˆ†æ(Spectral analysis)æ­ç¤ºäº†å…¶èƒŒåçš„è¡°å‡æœºåˆ¶ã€‚ç ”ç©¶å‘ç°æ¨¡å‹çš„é€šç”¨èƒ½åŠ›ä¸é¢„è®­ç»ƒæƒé‡çŸ©é˜µçš„ä¸»å¥‡å¼‚æ–¹å‘(Dominant singular directions)å¯†åˆ‡ç›¸å…³ï¼Œè€Œè¿™äº›æ–¹å‘å¯¹æ‰°åŠ¨é«˜åº¦æ•æ„Ÿä¸”æ˜“éšè¿ç»­ç¼–è¾‘è€Œé€æ­¥ç ´åã€‚åŸºäºè¿™ä¸€å‘ç°ï¼Œä½œè€…æå‡ºäº†åä¸ºREVIVEçš„å³æ’å³ç”¨æ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡æ˜¾å¼ä¿ç•™ä¸»å¥‡å¼‚å­ç©ºé—´(Dominant singular subspace)æ¥ç¨³å®šè¿ç»­ç¼–è¾‘è¿‡ç¨‹ã€‚REVIVEåœ¨åŸå§‹æƒé‡çš„é¢‘è°±åŸºåº•ä¸­è¡¨ç¤ºå‚æ•°æ›´æ–°ï¼Œå¹¶è¿‡æ»¤æ‰ä¼šå¹²æ‰°å—ä¿æŠ¤åŒºåŸŸçš„åˆ†é‡ï¼Œä»è€Œå‡å°‘å¯¹æ¨¡å‹åŸºç¡€èƒ½åŠ›çš„å¹²æ‰°ã€‚åœ¨å¤šä¸ªæ¨¡å‹å’ŒåŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒREVIVEåœ¨é•¿è¾¾20,000æ¬¡ç¼–è¾‘çš„æç«¯è®¾ç½®ä¸‹ï¼Œä¸ä»…èƒ½æŒç»­æå‡ç¼–è¾‘æ•ˆç‡ï¼Œè¿˜èƒ½æ˜¾è‘—ä¿ç•™æ¨¡å‹çš„é€šç”¨èƒ½åŠ›ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "22 pages, 18 figures",
      "pdf_url": "https://arxiv.org/pdf/2601.11042v1",
      "published_date": "2026-01-16 07:18:14 UTC",
      "updated_date": "2026-01-16 07:18:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:01:52.449899+00:00"
    },
    {
      "arxiv_id": "2601.11037v1",
      "title": "BAPO: Boundary-Aware Policy Optimization for Reliable Agentic Search",
      "title_zh": "BAPOï¼šé¢å‘å¯é æ™ºèƒ½ä½“æœç´¢çš„è¾¹ç•Œæ„ŸçŸ¥ç­–ç•¥ä¼˜åŒ–",
      "authors": [
        "Shiyu Liu",
        "Yongjing Yin",
        "Jianhao Yan",
        "Yunbo Tang",
        "Qinggang Zhang",
        "Bei Li",
        "Xin Chen",
        "Jingang Wang",
        "Xunliang Cai",
        "Jinsong Su"
      ],
      "abstract": "RL-based agentic search enables LLMs to solve complex questions via dynamic planning and external search. While this approach significantly enhances accuracy with agent policies optimized via large-scale reinforcement learning, we identify a critical gap in reliability: these agents fail to recognize their reasoning boundaries and rarely admit ``I DON'T KNOW'' (IDK) even when evidence is insufficient or reasoning reaches its limit. The lack of reliability often leads to plausible but unreliable answers, introducing significant risks in many real-world scenarios. To this end, we propose Boundary-Aware Policy Optimization (BAPO), a novel RL framework designed to cultivate reliable boundary awareness without compromising accuracy. BAPO introduces two key components: (i) a group-based boundary-aware reward that encourages an IDK response only when the reasoning reaches its limit, and (ii) an adaptive reward modulator that strategically suspends this reward during early exploration, preventing the model from exploiting IDK as a shortcut. Extensive experiments on four benchmarks demonstrate that BAPO substantially enhances the overall reliability of agentic search.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŸºäºå¼ºåŒ–å­¦ä¹ (RL)çš„æ™ºèƒ½æœç´¢(Agentic Search)ä¸­å­˜åœ¨çš„å¯é æ€§é—®é¢˜ï¼ŒæŒ‡å‡ºå¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨é¢å¯¹è¯æ®ä¸è¶³æˆ–æ¨ç†å—é™æ—¶ï¼Œå¾€å¾€æ— æ³•è¯†åˆ«è‡ªèº«æ¨ç†è¾¹ç•Œï¼Œä¸”æå°‘åšå‡ºâ€œä¸çŸ¥é“â€(I DON'T KNOW, IDK)çš„å›ç­”ï¼Œä»è€Œå¯¼è‡´ç”Ÿæˆçœ‹ä¼¼åˆç†ä½†ä¸å¯é çš„ç­”æ¡ˆã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†è¾¹ç•Œæ„ŸçŸ¥ç­–ç•¥ä¼˜åŒ–(Boundary-Aware Policy Optimization, BAPO)æ¡†æ¶ï¼Œæ—¨åœ¨ä¸ç‰ºç‰²å‡†ç¡®æ€§çš„å‰æä¸‹åŸ¹å…»æ¨¡å‹çš„å¯é è¾¹ç•Œæ„è¯†ã€‚BAPO å¼•å…¥äº†åŸºäºç»„çš„è¾¹ç•Œæ„ŸçŸ¥å¥–åŠ±æœºåˆ¶(group-based boundary-aware reward)ï¼Œä»…åœ¨æ¨ç†ç¡®å®è¾¾åˆ°æé™æ—¶æ‰é¼“åŠ±æ¨¡å‹åšå‡º IDK å›ç­”ã€‚åŒæ—¶ï¼Œè¯¥æ¡†æ¶åŒ…å«ä¸€ä¸ªè‡ªé€‚åº”å¥–åŠ±è°ƒèŠ‚å™¨(adaptive reward modulator)ï¼Œåœ¨æ¢ç´¢æ—©æœŸé˜¶æ®µç­–ç•¥æ€§åœ°æš‚åœè¯¥å¥–åŠ±ï¼Œä»¥é˜²æ­¢æ¨¡å‹å°† IDK è§†ä¸ºé€ƒé¿ä»»åŠ¡çš„æ·å¾„ã€‚åœ¨å››ä¸ªåŸºå‡†æµ‹è¯•ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒBAPO æ˜¾è‘—æå‡äº†æ™ºèƒ½æœç´¢çš„æ•´ä½“å¯é æ€§ã€‚è¯¥ç ”ç©¶ä¸ºæ„å»ºåœ¨å¤æ‚åŠ¨æ€ç¯å¢ƒä¸‹æ—¢é«˜æ•ˆåˆå¯ä¿¡çš„è‡ªä¸»ä»£ç†æœç´¢ç­–ç•¥æä¾›äº†é‡è¦çš„æŠ€æœ¯æ”¯æ’‘ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Code is available at https://github.com/Liushiyu-0709/BAPO-Reliable-Search",
      "pdf_url": "https://arxiv.org/pdf/2601.11037v1",
      "published_date": "2026-01-16 07:06:58 UTC",
      "updated_date": "2026-01-16 07:06:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:01:55.885590+00:00"
    },
    {
      "arxiv_id": "2601.11035v1",
      "title": "Your One-Stop Solution for AI-Generated Video Detection",
      "title_zh": "AIç”Ÿæˆè§†é¢‘æ£€æµ‹çš„ä¸€ç«™å¼è§£å†³æ–¹æ¡ˆ",
      "authors": [
        "Long Ma",
        "Zihao Xue",
        "Yan Wang",
        "Zhiyuan Yan",
        "Jin Xu",
        "Xiaorui Jiang",
        "Haiyang Yu",
        "Yong Liao",
        "Zhen Bi"
      ],
      "abstract": "Recent advances in generative modeling can create remarkably realistic synthetic videos, making it increasingly difficult for humans to distinguish them from real ones and necessitating reliable detection methods.\n  However, two key limitations hinder the development of this field.\n  \\textbf{From the dataset perspective}, existing datasets are often limited in scale and constructed using outdated or narrowly scoped generative models, making it difficult to capture the diversity and rapid evolution of modern generative techniques. Moreover, the dataset construction process frequently prioritizes quantity over quality, neglecting essential aspects such as semantic diversity, scenario coverage, and technological representativeness.\n  \\textbf{From the benchmark perspective}, current benchmarks largely remain at the stage of dataset creation, leaving many fundamental issues and in-depth analysis yet to be systematically explored.\n  Addressing this gap, we propose AIGVDBench, a benchmark designed to be comprehensive and representative, covering \\textbf{31} state-of-the-art generation models and over \\textbf{440,000} videos. By executing more than \\textbf{1,500} evaluations on \\textbf{33} existing detectors belonging to four distinct categories. This work presents \\textbf{8 in-depth analyses} from multiple perspectives and identifies \\textbf{4 novel findings} that offer valuable insights for future research. We hope this work provides a solid foundation for advancing the field of AI-generated video detection.\n  Our benchmark is open-sourced at https://github.com/LongMa-2025/AIGVDBench.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç”Ÿæˆæ¨¡å‹åˆ¶é€ çš„å†™å®åˆæˆè§†é¢‘æ—¥ç›Šéš¾ä»¥è¾¨åˆ«çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ä¸ªå…¨é¢ä¸”å…·æœ‰ä»£è¡¨æ€§çš„è¯„ä¼°åŸºå‡† AIGVDBenchã€‚ä¸ºäº†è§£å†³ç°æœ‰æ•°æ®é›†è§„æ¨¡æœ‰é™ã€æ¨¡å‹é™ˆæ—§ä»¥åŠè¯­ä¹‰å¤šæ ·æ€§ä¸è¶³ç­‰æ ¸å¿ƒç—›ç‚¹ï¼ŒAIGVDBench æ¶µç›–äº† 31 ä¸ªæœ€å…ˆè¿›çš„ç”Ÿæˆæ¨¡å‹ï¼Œå¹¶åŒ…å«è¶…è¿‡ 440,000 ä¸ªè§†é¢‘ã€‚é€šè¿‡å¯¹å±äº 4 ä¸ªä¸åŒç±»åˆ«çš„ 33 ç§ç°æœ‰æ£€æµ‹å™¨ï¼ˆdetectorsï¼‰è¿›è¡Œè¶…è¿‡ 1,500 æ¬¡è¯„ä¼°ï¼Œè¯¥ç ”ç©¶ä»å¤šä¸ªç»´åº¦æä¾›äº† 8 é¡¹æ·±å…¥åˆ†æã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜æ€»ç»“äº† 4 é¡¹å…·æœ‰ä¸´åºŠæŒ‡å¯¼æ„ä¹‰çš„æ–°å‘ç°ï¼Œä¸ºæœªæ¥ AI-generated video detection çš„ç ”ç©¶æ–¹å‘æä¾›äº†é‡è¦è§è§£ã€‚è¯¥å·¥ä½œé€šè¿‡æ„å»ºå¤§è§„æ¨¡æ•°æ®é›†ä¸ç³»ç»Ÿæ€§è¯„ä¼°æ¡†æ¶ï¼Œä¸ºæ¨åŠ¨äººå·¥æ™ºèƒ½ç”Ÿæˆè§†é¢‘æ£€æµ‹æŠ€æœ¯çš„å‘å±•å¥ å®šäº†åšå®åŸºç¡€ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11035v1",
      "published_date": "2026-01-16 07:02:06 UTC",
      "updated_date": "2026-01-16 07:02:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:02:01.014571+00:00"
    },
    {
      "arxiv_id": "2601.11030v1",
      "title": "IDDR-NGP: Incorporating Detectors for Distractor Removal with Instant Neural Radiance Field",
      "title_zh": "IDDR-NGPï¼šç»“åˆæ£€æµ‹å™¨çš„å³æ—¶ç¥ç»è¾å°„åœºå¹²æ‰°ç‰©ç§»é™¤æ–¹æ³•",
      "authors": [
        "Xianliang Huang",
        "Jiajie Gou",
        "Shuhang Chen",
        "Zhizhou Zhong",
        "Jihong Guan",
        "Shuigeng Zhou"
      ],
      "abstract": "This paper presents the first unified distractor removal method, named IDDR-NGP, which directly operates on Instant-NPG. The method is able to remove a wide range of distractors in 3D scenes, such as snowflakes, confetti, defoliation and petals, whereas existing methods usually focus on a specific type of distractors. By incorporating implicit 3D representations with 2D detectors, we demonstrate that it is possible to efficiently restore 3D scenes from multiple corrupted images. We design the learned perceptual image patch similarity~( LPIPS) loss and the multi-view compensation loss (MVCL) to jointly optimize the rendering results of IDDR-NGP, which could aggregate information from multi-view corrupted images. All of them can be trained in an end-to-end manner to synthesize high-quality 3D scenes. To support the research on distractors removal in implicit 3D representations, we build a new benchmark dataset that consists of both synthetic and real-world distractors. To validate the effectiveness and robustness of IDDR-NGP, we provide a wide range of distractors with corresponding annotated labels added to both realistic and synthetic scenes. Extensive experimental results demonstrate the effectiveness and robustness of IDDR-NGP in removing multiple types of distractors. In addition, our approach achieves results comparable with the existing SOTA desnow methods and is capable of accurately removing both realistic and synthetic distractors.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†IDDR-NGPï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªç›´æ¥ä½œç”¨äºInstant-NGPçš„ç»Ÿä¸€å¹²æ‰°ç‰©ç§»é™¤æ–¹æ³•ã€‚ä¸ä¸“æ³¨äºç‰¹å®šç±»å‹å¹²æ‰°ç‰©çš„ç°æœ‰æ–¹æ³•ä¸åŒï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆç§»é™¤åŒ…æ‹¬é›ªèŠ±ã€äº”å½©ç¢çº¸ã€è½å¶å’ŒèŠ±ç“£åœ¨å†…çš„å¤šç§3Dåœºæ™¯å¹²æ‰°ç‰©ã€‚é€šè¿‡å°†2Dæ£€æµ‹å™¨ä¸éšå¼3Dè¡¨ç¤ºï¼ˆimplicit 3D representationsï¼‰ç›¸ç»“åˆï¼ŒIDDR-NGPèƒ½å¤Ÿä»å¤šå¼ å—æŸå›¾åƒä¸­é«˜æ•ˆæ¢å¤3Dåœºæ™¯ã€‚ç ”ç©¶å›¢é˜Ÿè®¾è®¡äº†å­¦ä¹ æ„ŸçŸ¥å›¾åƒè¡¥ä¸ç›¸ä¼¼åº¦ï¼ˆLPIPSï¼‰æŸå¤±å’Œå¤šè§†å›¾è¡¥å¿æŸå¤±ï¼ˆMVCLï¼‰æ¥å…±åŒä¼˜åŒ–æ¸²æŸ“ç»“æœï¼Œä»è€Œèšåˆæ¥è‡ªå¤šè§†å›¾å—æŸå›¾åƒçš„ä¿¡æ¯ã€‚ç³»ç»Ÿæ”¯æŒç«¯åˆ°ç«¯è®­ç»ƒä»¥åˆæˆé«˜è´¨é‡3Dåœºæ™¯ï¼Œç ”ç©¶è€…è¿˜ä¸ºæ­¤æ„å»ºäº†ä¸€ä¸ªåŒ…å«åˆæˆå’ŒçœŸå®ä¸–ç•Œå¹²æ‰°ç‰©çš„æ–°åŸºå‡†æ•°æ®é›†ã€‚å®éªŒç»“æœè¯æ˜äº†IDDR-NGPåœ¨ç§»é™¤å¤šç§å¹²æ‰°ç‰©æ–¹é¢çš„æœ‰æ•ˆæ€§å’Œé²æ£’æ€§ï¼Œå…¶æ€§èƒ½å¯ä¸ç°æœ‰çš„SOTAå»é›ªæ–¹æ³•ç›¸åª²ç¾ï¼Œèƒ½å¤Ÿå‡†ç¡®å¤„ç†å„ç§å¤æ‚çš„å¹²æ‰°åœºæ™¯ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "8 pages, 7 figures, accepted by ACM-MM23",
      "pdf_url": "https://arxiv.org/pdf/2601.11030v1",
      "published_date": "2026-01-16 06:51:09 UTC",
      "updated_date": "2026-01-16 06:51:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:02:03.369390+00:00"
    },
    {
      "arxiv_id": "2601.11021v1",
      "title": "Combating Spurious Correlations in Graph Interpretability via Self-Reflection",
      "title_zh": "é€šè¿‡è‡ªæˆ‘åæ€åº”å¯¹å›¾å¯è§£é‡Šæ€§ä¸­çš„è™šå‡ç›¸å…³æ€§",
      "authors": [
        "Kecheng Cai",
        "Chenyang Xu",
        "Chao Peng"
      ],
      "abstract": "Interpretable graph learning has recently emerged as a popular research topic in machine learning. The goal is to identify the important nodes and edges of an input graph that are crucial for performing a specific graph reasoning task. A number of studies have been conducted in this area, and various benchmark datasets have been proposed to facilitate evaluation. Among them, one of the most challenging is the Spurious-Motif benchmark, introduced at ICLR 2022. The datasets in this synthetic benchmark are deliberately designed to include spurious correlations, making it particularly difficult for models to distinguish truly relevant structures from misleading patterns. As a result, existing methods exhibit significantly worse performance on this benchmark compared to others.\n  In this paper, we focus on improving interpretability on the challenging Spurious-Motif datasets. We demonstrate that the self-reflection technique, commonly used in large language models to tackle complex tasks, can also be effectively adapted to enhance interpretability in datasets with strong spurious correlations. Specifically, we propose a self-reflection framework that can be integrated with existing interpretable graph learning methods. When such a method produces importance scores for each node and edge, our framework feeds these predictions back into the original method to perform a second round of evaluation. This iterative process mirrors how large language models employ self-reflective prompting to reassess their previous outputs. We further analyze the reasons behind this improvement from the perspective of graph representation learning, which motivates us to propose a fine-tuning training method based on this feedback mechanism.",
      "tldr_zh": "æœ¬ç ”ç©¶é’ˆå¯¹å›¾å­¦ä¹ è§£é‡Šæ€§(Graph Interpretability)ä¸­å­˜åœ¨çš„ä¼ªç›¸å…³(Spurious Correlations)é—®é¢˜ï¼Œç‰¹åˆ«æ˜¯æ¨¡å‹åœ¨æŒ‘æˆ˜æ€§çš„Spurious-MotifåŸºå‡†æµ‹è¯•é›†ä¸Šéš¾ä»¥åŒºåˆ†çœŸå®ç›¸å…³ç»“æ„ä¸è¯¯å¯¼æ€§æ¨¡å¼çš„å›°å¢ƒã€‚è®ºæ–‡æå‡ºäº†ä¸€ç§å€Ÿé‰´å¤§è¯­è¨€æ¨¡å‹(LLMs)è‡ªæˆ‘åæ€(Self-Reflection)æœºåˆ¶çš„é€šç”¨æ¡†æ¶ï¼Œæ—¨åœ¨å¢å¼ºç°æœ‰å›¾è§£é‡Šæ–¹æ³•åœ¨å¤æ‚æ•°æ®é›†ä¸Šçš„è¡¨ç°ã€‚è¯¥æ¡†æ¶é€šè¿‡å°†åˆæ­¥ç”Ÿæˆçš„èŠ‚ç‚¹å’Œè¾¹é‡è¦æ€§å¾—åˆ†åé¦ˆç»™åŸæ–¹æ³•è¿›è¡ŒäºŒæ¬¡è¯„ä¼°ï¼Œåˆ©ç”¨è¿­ä»£è¿‡ç¨‹å®ç°å¯¹å…ˆå‰è¾“å‡ºçš„é‡æ–°å®¡è§†ã€‚ä½œè€…è¿›ä¸€æ­¥ä»å›¾è¡¨ç¤ºå­¦ä¹ (Graph Representation Learning)çš„è§†è§’åˆ†æäº†è¯¥æœºåˆ¶çš„æœ‰æ•ˆæ€§ï¼Œå¹¶æ®æ­¤å¼€å‘äº†ä¸€ç§åŸºäºåé¦ˆæœºåˆ¶çš„å¾®è°ƒ(Fine-tuning)è®­ç»ƒæ–¹æ³•ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•èƒ½æœ‰æ•ˆæå‡è§£é‡Šçš„å‡†ç¡®æ€§ï¼Œä¸ºæ„å»ºæ›´å…·é²æ£’æ€§çš„å¯è§£é‡Šå›¾æœºå™¨å­¦ä¹ æ¨¡å‹æä¾›äº†æ–°çš„æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11021v1",
      "published_date": "2026-01-16 06:31:16 UTC",
      "updated_date": "2026-01-16 06:31:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:02:04.968552+00:00"
    },
    {
      "arxiv_id": "2601.11019v1",
      "title": "Finding the Translation Switch: Discovering and Exploiting the Task-Initiation Features in LLMs",
      "title_zh": "å¯»æ‰¾ç¿»è¯‘å¼€å…³ï¼šå¤§è¯­è¨€æ¨¡å‹ä»»åŠ¡å¯åŠ¨ç‰¹å¾çš„å‘ç°ä¸åˆ©ç”¨",
      "authors": [
        "Xinwei Wu",
        "Heng Liu",
        "Xiaohu Zhao",
        "Yuqi Ren",
        "Linlong Xu",
        "Longyue Wang",
        "Deyi Xiong",
        "Weihua Luo",
        "Kaifu Zhang"
      ],
      "abstract": "Large Language Models (LLMs) frequently exhibit strong translation abilities, even without task-specific fine-tuning. However, the internal mechanisms governing this innate capability remain largely opaque. To demystify this process, we leverage Sparse Autoencoders (SAEs) and introduce a novel framework for identifying task-specific features. Our method first recalls features that are frequently co-activated on translation inputs and then filters them for functional coherence using a PCA-based consistency metric. This framework successfully isolates a small set of **translation initiation** features. Causal interventions demonstrate that amplifying these features steers the model towards correct translation, while ablating them induces hallucinations and off-task outputs, confirming they represent a core component of the model's innate translation competency. Moving from analysis to application, we leverage this mechanistic insight to propose a new data selection strategy for efficient fine-tuning. Specifically, we prioritize training on **mechanistically hard** samples-those that fail to naturally activate the translation initiation features. Experiments show this approach significantly improves data efficiency and suppresses hallucinations. Furthermore, we find these mechanisms are transferable to larger models of the same family. Our work not only decodes a core component of the translation mechanism in LLMs but also provides a blueprint for using internal model mechanism to create more robust and efficient models. The codes are available at https://github.com/flamewei123/AAAI26-translation-Initiation-Features.",
      "tldr_zh": "è¯¥ç ”ç©¶åˆ©ç”¨ç¨€ç–è‡ªåŠ¨ç¼–ç å™¨(Sparse Autoencoders, SAEs)å’ŒåŸºäºä¸»æˆåˆ†åˆ†æ(PCA)çš„ä¸€è‡´æ€§åº¦é‡ï¼Œæ­ç¤ºäº†å¤§è¯­è¨€æ¨¡å‹(LLMs)å†…åœ¨ç¿»è¯‘èƒ½åŠ›çš„åº•å±‚æœºåˆ¶ã€‚é€šè¿‡è¯¥æ¡†æ¶ï¼Œç ”ç©¶è€…æˆåŠŸè¯†åˆ«å‡ºä¸€ç»„å…³é”®çš„â€œç¿»è¯‘å¯åŠ¨â€(translation initiation)ç‰¹å¾ï¼Œå¹¶é€šè¿‡å› æœå¹²é¢„å®éªŒè¯æ˜è¿™äº›ç‰¹å¾æ˜¯æ¨¡å‹ç¿»è¯‘èƒ½åŠ›çš„æ ¸å¿ƒç»„ä»¶ã€‚åŸºäºè¿™ä¸€æœºæ¢°è®ºè§è§£ï¼Œç ”ç©¶æå‡ºäº†ä¸€ç§é’ˆå¯¹â€œæœºåˆ¶éš¾ç‚¹â€(mechanistically hard)æ ·æœ¬çš„æ•°æ®é€‰æ‹©ç­–ç•¥ï¼Œæ—¨åœ¨é€šè¿‡ä¼˜å…ˆè®­ç»ƒæ— æ³•è‡ªç„¶æ¿€æ´»ç¿»è¯‘å¯åŠ¨ç‰¹å¾çš„æ ·æœ¬æ¥æé«˜å¾®è°ƒæ•ˆç‡ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨æ˜¾è‘—æå‡æ•°æ®æ•ˆç‡çš„åŒæ—¶æœ‰æ•ˆæŠ‘åˆ¶äº†å¹»è§‰ç”Ÿæˆï¼Œä¸”ç›¸å…³æœºåˆ¶åœ¨åŒç³»åˆ—å¤§å‹æ¨¡å‹ä¸­è¡¨ç°å‡ºè‰¯å¥½çš„å¯è¿ç§»æ€§ã€‚è¯¥å·¥ä½œä¸ä»…è§£ç äº†LLMsç¿»è¯‘æœºåˆ¶çš„æ ¸å¿ƒï¼Œä¹Ÿä¸ºåˆ©ç”¨æ¨¡å‹å†…éƒ¨æœºåˆ¶æ„å»ºæ›´ç¨³å¥ã€é«˜æ•ˆçš„æ¨¡å‹æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by AAAI 2026",
      "pdf_url": "https://arxiv.org/pdf/2601.11019v1",
      "published_date": "2026-01-16 06:29:07 UTC",
      "updated_date": "2026-01-16 06:29:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:02:13.308623+00:00"
    },
    {
      "arxiv_id": "2601.11675v1",
      "title": "Generating metamers of human scene understanding",
      "title_zh": "ç”Ÿæˆäººç±»åœºæ™¯ç†è§£çš„æ„ŸçŸ¥ç­‰å€¼å›¾åƒ",
      "authors": [
        "Ritik Raina",
        "Abe Leite",
        "Alexandros Graikos",
        "Seoyoung Ahn",
        "Dimitris Samaras",
        "Gregory J. Zelinsky"
      ],
      "abstract": "Human vision combines low-resolution \"gist\" information from the visual periphery with sparse but high-resolution information from fixated locations to construct a coherent understanding of a visual scene. In this paper, we introduce MetamerGen, a tool for generating scenes that are aligned with latent human scene representations. MetamerGen is a latent diffusion model that combines peripherally obtained scene gist information with information obtained from scene-viewing fixations to generate image metamers for what humans understand after viewing a scene. Generating images from both high and low resolution (i.e. \"foveated\") inputs constitutes a novel image-to-image synthesis problem, which we tackle by introducing a dual-stream representation of the foveated scenes consisting of DINOv2 tokens that fuse detailed features from fixated areas with peripherally degraded features capturing scene context. To evaluate the perceptual alignment of MetamerGen generated images to latent human scene representations, we conducted a same-different behavioral experiment where participants were asked for a \"same\" or \"different\" response between the generated and the original image. With that, we identify scene generations that are indeed metamers for the latent scene representations formed by the viewers. MetamerGen is a powerful tool for understanding scene understanding. Our proof-of-concept analyses uncovered specific features at multiple levels of visual processing that contributed to human judgments. While it can generate metamers even conditioned on random fixations, we find that high-level semantic alignment most strongly predicts metamerism when the generated scenes are conditioned on viewers' own fixated regions.",
      "tldr_zh": "è¯¥ç ”ç©¶ä»‹ç»äº† MetamerGenï¼Œè¿™æ˜¯ä¸€ç§ç”¨äºç”Ÿæˆä¸äººç±»åœºæ™¯è¡¨å¾ (latent human scene representations) å¯¹é½çš„åœºæ™¯å›¾åƒçš„æ½œåœ¨æ‰©æ•£æ¨¡å‹ (latent diffusion model)ã€‚è¯¥å·¥å…·é’ˆå¯¹äººç±»è§†è§‰ç»“åˆå¤–å‘¨ä½åˆ†è¾¨ç‡ä¿¡æ¯ä¸æ³¨è§†ç‚¹é«˜åˆ†è¾¨ç‡ä¿¡æ¯çš„ç‰¹ç‚¹ï¼Œæå‡ºäº†ä¸€ç§åŒæµè¡¨å¾ (dual-stream representation) æ–¹æ³•ï¼Œåˆ©ç”¨ DINOv2 ä»¤ç‰Œèåˆæ³¨è§†åŒºåŸŸçš„ç»†èŠ‚ç‰¹å¾ä¸å¤–å‘¨é€€åŒ–çš„åœºæ™¯ä¸Šä¸‹æ–‡ç‰¹å¾ã€‚MetamerGen è§£å†³äº†ä»é«˜ä½åˆ†è¾¨ç‡æ··åˆè¾“å…¥è¿›è¡Œå›¾åƒåˆ°å›¾åƒåˆæˆ (image-to-image synthesis) çš„æ–°å‹é—®é¢˜ï¼Œæ—¨åœ¨é‡æ„äººç±»åœ¨è§‚å¯Ÿåœºæ™¯åå½¢æˆçš„ç†è§£å†…å®¹ã€‚ç ”ç©¶é€šè¿‡â€œåŒå¼‚åˆ¤æ–­â€è¡Œä¸ºå®éªŒ (same-different behavioral experiment) è¯„ä¼°äº†ç”Ÿæˆå›¾åƒä¸äººç±»æ½œåœ¨åœºæ™¯è¡¨å¾ä¹‹é—´çš„æ„ŸçŸ¥å¯¹é½ç¨‹åº¦ï¼ŒæˆåŠŸè¯†åˆ«å‡ºèƒ½å¼•å‘ç›¸åŒè¡¨å¾çš„åŒæ„å¼‚è´¨ä½“ (metamers)ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå½“ç”Ÿæˆåœºæ™¯åŸºäºè§‚å¯Ÿè€…è‡ªèº«çš„æ³¨è§†åŒºåŸŸæ—¶ï¼Œé«˜å±‚è¯­ä¹‰å¯¹é½ (high-level semantic alignment) å¯¹é¢„æµ‹åŒæ„å¼‚è´¨æ€§ (metamerism) çš„å½±å“æœ€ä¸ºæ˜¾è‘—ã€‚MetamerGen ä¸ºç ”ç©¶åœºæ™¯ç†è§£ (scene understanding) æä¾›äº†å¼ºæœ‰åŠ›çš„å·¥å…·ï¼Œæ­ç¤ºäº†ä¸åŒè§†è§‰å¤„ç†å±‚é¢ä¸Šè´¡çŒ®äºäººç±»åˆ¤æ–­çš„å…·ä½“ç‰¹å¾ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11675v1",
      "published_date": "2026-01-16 06:24:59 UTC",
      "updated_date": "2026-01-16 06:24:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:02:14.471194+00:00"
    },
    {
      "arxiv_id": "2601.11016v1",
      "title": "Contextual Distributionally Robust Optimization with Causal and Continuous Structure: An Interpretable and Tractable Approach",
      "title_zh": "å…·æœ‰å› æœä¸è¿ç»­ç»“æ„çš„æƒ…å¢ƒåˆ†å¸ƒé²æ£’ä¼˜åŒ–ï¼šä¸€ç§å…¼å…·å¯è§£é‡Šæ€§ä¸æ˜“å¤„ç†æ€§çš„æ–¹æ³•",
      "authors": [
        "Fenglin Zhang",
        "Jie Wang"
      ],
      "abstract": "In this paper, we introduce a framework for contextual distributionally robust optimization (DRO) that considers the causal and continuous structure of the underlying distribution by developing interpretable and tractable decision rules that prescribe decisions using covariates. We first introduce the causal Sinkhorn discrepancy (CSD), an entropy-regularized causal Wasserstein distance that encourages continuous transport plans while preserving the causal consistency. We then formulate a contextual DRO model with a CSD-based ambiguity set, termed Causal Sinkhorn DRO (Causal-SDRO), and derive its strong dual reformulation where the worst-case distribution is characterized as a mixture of Gibbs distributions. To solve the corresponding infinite-dimensional policy optimization, we propose the Soft Regression Forest (SRF) decision rule, which approximates optimal policies within arbitrary measurable function spaces. The SRF preserves the interpretability of classical decision trees while being fully parametric, differentiable, and Lipschitz smooth, enabling intrinsic interpretation from both global and local perspectives. To solve the Causal-SDRO with parametric decision rules, we develop an efficient stochastic compositional gradient algorithm that converges to an $\\varepsilon$-stationary point at a rate of $O(\\varepsilon^{-4})$, matching the convergence rate of standard stochastic gradient descent. Finally, we validate our method through numerical experiments on synthetic and real-world datasets, demonstrating its superior performance and interpretability.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªé’ˆå¯¹ Contextual Distributionally Robust Optimization (DRO) çš„æ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡æ„å»ºå¯è§£é‡Šä¸”æ˜“äºå¤„ç†çš„å†³ç­–è§„åˆ™æ¥å¤„ç†åº•å±‚åˆ†å¸ƒçš„å› æœå’Œè¿ç»­ç»“æ„ã€‚ç ”ç©¶é¦–å…ˆå¼•å…¥äº† Causal Sinkhorn Discrepancy (CSD)ï¼Œè¿™æ˜¯ä¸€ç§å¸¦æœ‰ç†µæ­£åˆ™åŒ–çš„å› æœ Wasserstein è·ç¦»ï¼Œèƒ½å¤Ÿåœ¨ä¿ç•™å› æœä¸€è‡´æ€§çš„åŒæ—¶ä¿ƒè¿›è¿ç»­ä¼ è¾“è®¡åˆ’ã€‚åŸºäºæ­¤æ„å»ºäº† Causal Sinkhorn DRO (Causal-SDRO) æ¨¡å‹å¹¶æ¨å¯¼äº†å…¶å¼ºå¯¹å¶é‡æ„ï¼Œå°†æœ€åæƒ…å†µåˆ†å¸ƒè¡¨å¾ä¸º Gibbs distributions çš„æ··åˆå½¢å¼ã€‚ä¸ºäº†è§£å†³æ— é™ç»´ç­–ç•¥ä¼˜åŒ–é—®é¢˜ï¼Œç ”ç©¶æå‡ºäº† Soft Regression Forest (SRF) å†³ç­–è§„åˆ™ï¼Œè¯¥è§„åˆ™åœ¨ä¿æŒç»å…¸å†³ç­–æ ‘å¯è§£é‡Šæ€§çš„åŒæ—¶ï¼Œå…·å¤‡å…¨å‚æ•°åŒ–ã€å¯å¾®å’Œ Lipschitz smooth çš„ç‰¹æ€§ï¼Œæ”¯æŒå…¨å±€å’Œå±€éƒ¨çš„å†…åœ¨è§£é‡Šã€‚æ­¤å¤–ï¼Œç ”ç©¶å¼€å‘äº†ä¸€ç§é«˜æ•ˆçš„éšæœºç»„åˆæ¢¯åº¦ç®—æ³•ï¼Œå…¶æ”¶æ•›é€Ÿåº¦è¾¾åˆ° $O(\\varepsilon^{-4})$ï¼Œä¸æ ‡å‡†éšæœºæ¢¯åº¦ä¸‹é™ä¸€è‡´ã€‚æ•°å€¼å®éªŒåœ¨åˆæˆå’ŒçœŸå®ä¸–ç•Œæ•°æ®é›†ä¸ŠéªŒè¯äº†è¯¥æ–¹æ³•åœ¨é²æ£’å†³ç­–ä»»åŠ¡ä¸­å±•ç°å‡ºçš„å“è¶Šæ€§èƒ½ä¸é«˜åº¦å¯è§£é‡Šæ€§ã€‚",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG",
        "math.OC"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11016v1",
      "published_date": "2026-01-16 06:18:22 UTC",
      "updated_date": "2026-01-16 06:18:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:02:26.455523+00:00"
    },
    {
      "arxiv_id": "2601.11012v1",
      "title": "Efficient Protein Optimization via Structure-aware Hamiltonian Dynamics",
      "title_zh": "åŸºäºç»“æ„æ„ŸçŸ¥å“ˆå¯†é¡¿åŠ¨åŠ›å­¦çš„é«˜æ•ˆè›‹ç™½è´¨ä¼˜åŒ–",
      "authors": [
        "Jiahao Wang",
        "Shuangjia Zheng"
      ],
      "abstract": "The ability to engineer optimized protein variants has transformative potential for biotechnology and medicine. Prior sequence-based optimization methods struggle with the high-dimensional complexities due to the epistasis effect and the disregard for structural constraints. To address this, we propose HADES, a Bayesian optimization method utilizing Hamiltonian dynamics to efficiently sample from a structure-aware approximated posterior. Leveraging momentum and uncertainty in the simulated physical movements, HADES enables rapid transition of proposals toward promising areas. A position discretization procedure is introduced to propose discrete protein sequences from such a continuous state system. The posterior surrogate is powered by a two-stage encoder-decoder framework to determine the structure and function relationships between mutant neighbors, consequently learning a smoothed landscape to sample from. Extensive experiments demonstrate that our method outperforms state-of-the-art baselines in in-silico evaluations across most metrics. Remarkably, our approach offers a unique advantage by leveraging the mutual constraints between protein structure and sequence, facilitating the design of protein sequences with similar structures and optimized properties. The code and data are publicly available at https://github.com/GENTEL-lab/HADES.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†HADESï¼Œä¸€ç§åŸºäºHamiltonian dynamicsçš„é«˜æ•ˆBayesian optimizationè›‹ç™½è´¨ä¼˜åŒ–æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³ä¼ ç»Ÿåºåˆ—ä¼˜åŒ–æ–¹æ³•å› ä¸Šä½æ€§æ•ˆåº”(epistasis effect)å’Œå¿½è§†ç»“æ„çº¦æŸè€Œé¢ä¸´çš„é«˜ç»´å¤æ‚æ€§é—®é¢˜ã€‚HADESåˆ©ç”¨æ¨¡æ‹Ÿç‰©ç†è¿åŠ¨ä¸­çš„momentumå’Œuncertaintyï¼Œé€šè¿‡structure-awareçš„è¿‘ä¼¼åéªŒé‡‡æ ·ï¼Œå¼•å¯¼ä¼˜åŒ–è¿‡ç¨‹å¿«é€Ÿå‘é«˜æ€§èƒ½åŒºåŸŸè¿‡æ¸¡ã€‚ç ”ç©¶å¼•å…¥äº†position discretizationç¨‹åºå°†è¿ç»­çŠ¶æ€è½¬æ¢ä¸ºç¦»æ•£åºåˆ—ï¼Œå¹¶ç»“åˆä¸¤é˜¶æ®µencoder-decoderæ¡†æ¶æ¥å»ºæ¨¡ç»“æ„ä¸åŠŸèƒ½ä¹‹é—´çš„å…³ç³»ï¼Œä»è€Œåœ¨å¹³æ»‘çš„æ€§èƒ½æ™¯è§‚ä¸­è¿›è¡Œé‡‡æ ·ã€‚å®éªŒè¯æ˜ï¼ŒHADESåœ¨å¤šé¡¹in-silicoè¯„ä¼°æŒ‡æ ‡ä¸Šå‡ä¼˜äºç°æœ‰åŸºçº¿æ¨¡å‹ï¼Œå…¶æ ¸å¿ƒä¼˜åŠ¿åœ¨äºèƒ½å¤Ÿæœ‰æ•ˆåˆ©ç”¨è›‹ç™½è´¨ç»“æ„ä¸åºåˆ—çš„ç›¸äº’çº¦æŸï¼Œå®ç°å¯¹å…·æœ‰ç›¸ä¼¼ç»“æ„ä¸”æ€§è´¨ä¼˜åŒ–çš„è›‹ç™½è´¨å˜ä½“çš„ç²¾å‡†è®¾è®¡ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11012v1",
      "published_date": "2026-01-16 05:53:53 UTC",
      "updated_date": "2026-01-16 05:53:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:02:28.330016+00:00"
    },
    {
      "arxiv_id": "2601.11007v1",
      "title": "AdaMARP: An Adaptive Multi-Agent Interaction Framework for General Immersive Role-Playing",
      "title_zh": "AdaMARPï¼šé¢å‘é€šç”¨æ²‰æµ¸å¼è§’è‰²æ‰®æ¼”çš„è‡ªé€‚åº”å¤šæ™ºèƒ½ä½“äº¤äº’æ¡†æ¶",
      "authors": [
        "Zhenhua Xu",
        "Dongsheng Chen",
        "Shuo Wang",
        "Jian Li",
        "Chengjie Wang",
        "Meng Han",
        "Yabiao Wang"
      ],
      "abstract": "LLM role-playing aims to portray arbitrary characters in interactive narratives, yet existing systems often suffer from limited immersion and adaptability. They typically under-model dynamic environmental information and assume largely static scenes and casts, offering insufficient support for multi-character orchestration, scene transitions, and on-the-fly character introduction. We propose an adaptive multi-agent role-playing framework, AdaMARP, featuring an immersive message format that interleaves [Thought], (Action), <Environment>, and Speech, together with an explicit Scene Manager that governs role-playing through discrete actions (init_scene, pick_speaker, switch_scene, add_role, end) accompanied by rationales. To train these capabilities, we construct AdaRPSet for the Actor Model and AdaSMSet for supervising orchestration decisions, and introduce AdaptiveBench for trajectory-level evaluation. Experiments across multiple backbones and model scales demonstrate consistent improvements: AdaRPSet enhances character consistency, environment grounding, and narrative coherence, with an 8B actor outperforming several commercial LLMs, while AdaSMSet enables smoother scene transitions and more natural role introductions, surpassing Claude Sonnet 4.5 using only a 14B LLM.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLM)è§’è‰²æ‰®æ¼”ä¸­å­˜åœ¨çš„æ²‰æµ¸æ„Ÿä¸è¶³å’Œé€‚åº”æ€§å·®ç­‰é—®é¢˜ï¼ŒæŒ‡å‡ºå½“å‰ç³»ç»Ÿåœ¨å¤„ç†å¤šè§’è‰²åè°ƒã€åœºæ™¯è½¬æ¢åŠåŠ¨æ€è§’è‰²å¼•å…¥æ–¹é¢çš„å±€é™æ€§ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†åä¸º AdaMARP çš„è‡ªé€‚åº”å¤šæ™ºèƒ½ä½“è§’è‰²æ‰®æ¼”æ¡†æ¶ï¼Œè¯¥æ¡†æ¶åˆ›æ–°åœ°é‡‡ç”¨äº†äº¤ç»‡ [Thought]ã€(Action)ã€<Environment> å’Œ Speech çš„æ²‰æµ¸å¼æ¶ˆæ¯æ ¼å¼ã€‚åŒæ—¶ï¼Œè¯¥æ¡†æ¶å¼•å…¥äº†ä¸€ä¸ªæ˜¾å¼çš„ Scene Managerï¼Œé€šè¿‡æ‰§è¡Œ init_sceneã€pick_speaker å’Œ switch_scene ç­‰ç¦»æ•£åŠ¨ä½œåŠå¯¹åº”ç†ç”±æ¥ååŒè§’è‰²æ‰®æ¼”è¿‡ç¨‹ã€‚ä¸ºäº†è®­ç»ƒè¿™äº›èƒ½åŠ›ï¼Œç ”ç©¶å›¢é˜Ÿæ„å»ºäº† AdaRPSet å’Œ AdaSMSet æ•°æ®é›†ï¼Œå¹¶æ¨å‡ºäº†ç”¨äºè½¨è¿¹çº§è¯„ä¼°çš„ AdaptiveBenchã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒAdaRPSet æ˜¾è‘—å¢å¼ºäº†è§’è‰²ä¸€è‡´æ€§ä¸ç¯å¢ƒæ¥åœ°æ„Ÿ(grounding)ï¼Œä½¿å¾— 8B è§„æ¨¡çš„æ¨¡å‹åœ¨è¡¨ç°ä¸Šä¼˜äºå¤šä¸ªå•†ç”¨ LLMã€‚æ­¤å¤–ï¼ŒåŸºäº AdaSMSet è®­ç»ƒçš„ 14B æ¨¡å‹åœ¨å®ç°å¹³æ»‘åœºæ™¯è½¬æ¢ä¸è‡ªç„¶è§’è‰²å¼•å…¥æ–¹é¢è¶…è¶Šäº† Claude Sonnet 4.5ï¼Œè¯æ˜äº†è¯¥æ¡†æ¶åœ¨é€šç”¨æ²‰æµ¸å¼è§’è‰²æ‰®æ¼”é¢†åŸŸçš„å“è¶Šæ€§èƒ½ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11007v1",
      "published_date": "2026-01-16 05:41:45 UTC",
      "updated_date": "2026-01-16 05:41:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:02:30.389473+00:00"
    },
    {
      "arxiv_id": "2601.11674v1",
      "title": "Pigment Network Detection and Classification in Dermoscopic Images Using Directional Imaging Algorithms and Convolutional Neural Networks",
      "title_zh": "åŸºäºæ–¹å‘æ€§æˆåƒç®—æ³•ä¸å·ç§¯ç¥ç»ç½‘ç»œçš„çš®è‚¤é•œå›¾åƒè‰²ç´ ç½‘ç»œæ£€æµ‹åŠåˆ†ç±»",
      "authors": [
        "M. A. Rasel",
        "Sameem Abdul Kareem",
        "Unaizah Obaidellah"
      ],
      "abstract": "Early diagnosis of melanoma, which can save thousands of lives, relies heavily on the analysis of dermoscopic images. One crucial diagnostic criterion is the identification of unusual pigment network (PN). However, distinguishing between regular (typical) and irregular (atypical) PN is challenging. This study aims to automate the PN detection process using a directional imaging algorithm and classify PN types using machine learning classifiers. The directional imaging algorithm incorporates Principal Component Analysis (PCA), contrast enhancement, filtering, and noise reduction. Applied to the PH2 dataset, this algorithm achieved a 96% success rate, which increased to 100% after pixel intensity adjustments. We created a new dataset containing only PN images from these results. We then employed two classifiers, Convolutional Neural Network (CNN) and Bag of Features (BoF), to categorize PN into atypical and typical classes. Given the limited dataset of 200 images, a simple and effective CNN was designed, featuring two convolutional layers and two batch normalization layers. The proposed CNN achieved 90% accuracy, 90% sensitivity, and 89% specificity. When compared to state-of-the-art methods, our CNN demonstrated superior performance. Our study highlights the potential of the proposed CNN model for effective PN classification, suggesting future research should focus on expanding datasets and incorporating additional dermatological features to further enhance melanoma diagnosis.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§è‡ªåŠ¨åŒ–æ£€æµ‹å’Œåˆ†ç±»çš®è‚¤é•œå›¾åƒä¸­è‰²ç´ ç½‘ç»œ(Pigment Network, PN)çš„æ–¹æ³•ï¼Œæ—¨åœ¨æ˜¾è‘—æå‡é»‘è‰²ç´ ç˜¤çš„æ—©æœŸè¯Šæ–­æ•ˆç‡ã€‚ç ”ç©¶é¦–å…ˆé‡‡ç”¨ç»“åˆäº†ä¸»æˆåˆ†åˆ†æ(Principal Component Analysis, PCA)ã€å¯¹æ¯”åº¦å¢å¼ºå’Œæ»¤æ³¢æŠ€æœ¯çš„æ–¹å‘æ€§æˆåƒç®—æ³•(Directional Imaging Algorithm)ï¼Œåœ¨PH2æ•°æ®é›†ä¸Šå®ç°äº†100%çš„æ£€æµ‹æˆåŠŸç‡ã€‚éšåï¼Œç ”ç©¶è€…è®¾è®¡å¹¶åº”ç”¨äº†ä¸€ç§åŒ…å«ä¸¤å±‚å·ç§¯ä¸ä¸¤å±‚æ‰¹å½’ä¸€åŒ–å±‚çš„å·ç§¯ç¥ç»ç½‘ç»œ(Convolutional Neural Network, CNN)ï¼Œä¸“é—¨ç”¨äºå°†PNåˆ†ç±»ä¸ºå…¸å‹ä¸éå…¸å‹ä¸¤ç±»ã€‚åœ¨ä»…æœ‰200å¼ å›¾åƒçš„æ•°æ®é›†ä¸Šï¼Œè¯¥CNNæ¨¡å‹è¾¾åˆ°äº†90%çš„å‡†ç¡®ç‡ã€90%çš„çµæ•åº¦å’Œ89%çš„ç‰¹å¼‚æ€§ã€‚ä¸ç°æœ‰çš„å‰æ²¿(state-of-the-art)æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥ç ”ç©¶æå‡ºçš„ç®—æ³•ä¸æ¨¡å‹è¡¨ç°å‡ºæ›´ä¼˜è¶Šçš„æ€§èƒ½ï¼Œä¸ºçš®è‚¤ç—…ç‰¹å¾çš„è‡ªåŠ¨åŒ–åˆ†ç±»æä¾›äº†æ–°çš„æœ‰æ•ˆé€”å¾„ã€‚",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11674v1",
      "published_date": "2026-01-16 05:38:48 UTC",
      "updated_date": "2026-01-16 05:38:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:02:36.222631+00:00"
    },
    {
      "arxiv_id": "2601.11000v1",
      "title": "When Personalization Misleads: Understanding and Mitigating Hallucinations in Personalized LLMs",
      "title_zh": "å½“ä¸ªæ€§åŒ–äº§ç”Ÿè¯¯å¯¼ï¼šç†è§£ä¸ç¼“è§£ä¸ªæ€§åŒ–å¤§è¯­è¨€æ¨¡å‹ä¸­çš„å¹»è§‰",
      "authors": [
        "Zhongxiang Sun",
        "Yi Zhan",
        "Chenglei Shen",
        "Weijie Yu",
        "Xiao Zhang",
        "Ming He",
        "Jun Xu"
      ],
      "abstract": "Personalized large language models (LLMs) adapt model behavior to individual users to enhance user satisfaction, yet personalization can inadvertently distort factual reasoning. We show that when personalized LLMs face factual queries, there exists a phenomenon where the model generates answers aligned with a user's prior history rather than the objective truth, resulting in personalization-induced hallucinations that degrade factual reliability and may propagate incorrect beliefs, due to representational entanglement between personalization and factual representations. To address this issue, we propose Factuality-Preserving Personalized Steering (FPPS), a lightweight inference-time approach that mitigates personalization-induced factual distortions while preserving personalized behavior. We further introduce PFQABench, the first benchmark designed to jointly evaluate factual and personalized question answering under personalization. Experiments across multiple LLM backbones and personalization methods show that FPPS substantially improves factual accuracy while maintaining personalized performance.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†ä¸ªæ€§åŒ–å¤§è¯­è¨€æ¨¡å‹(Personalized LLMs)åœ¨æå‡ç”¨æˆ·æ»¡æ„åº¦çš„åŒæ—¶ï¼Œå¯èƒ½å› ä¸ªæ€§åŒ–è¡¨ç¤ºä¸äº‹å®è¡¨ç¤ºä¹‹é—´çš„è¡¨ç¤ºçº ç¼ (representational entanglement)è€Œå¯¼è‡´äº‹å®æ¨ç†å¤±çœŸçš„é—®é¢˜ã€‚ä½œè€…å‘ç°æ¨¡å‹åœ¨é¢å¯¹äº‹å®æ€§æŸ¥è¯¢æ—¶ï¼Œå¾€å¾€ä¼šç”Ÿæˆä¸ç”¨æˆ·å†å²åå¥½å¯¹é½è€Œéå®¢è§‚äº‹å®çš„ç­”æ¡ˆï¼Œä»è€Œäº§ç”Ÿä¸ªæ€§åŒ–è¯±å¯¼å¹»è§‰(personalization-induced hallucinations)ã€‚ä¸ºè§£å†³æ­¤é—®é¢˜ï¼Œç ”ç©¶æå‡ºäº†ä¸€ç§è½»é‡çº§çš„æ¨ç†æ—¶æ–¹æ³•ï¼Œå³äº‹å®ä¿ç•™ä¸ªæ€§åŒ–å¯¼å‘(Factuality-Preserving Personalized Steering, FPPS)ï¼Œæ—¨åœ¨å‡å°‘äº‹å®æ‰­æ›²çš„åŒæ—¶ä¿ç•™ä¸ªæ€§åŒ–ç‰¹å¾ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜å¼•å…¥äº†é¦–ä¸ªä¸“é—¨è®¾è®¡çš„åŸºå‡†æµ‹è¯•é›†PFQABenchï¼Œç”¨äºè”åˆè¯„ä¼°ä¸ªæ€§åŒ–åœºæ™¯ä¸‹çš„äº‹å®ä¸ä¸ªæ€§åŒ–é—®ç­”èƒ½åŠ›ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒFPPSåœ¨å¤šç§æ¨¡å‹æ¶æ„ä¸Šå‡èƒ½æ˜¾è‘—æå‡äº‹å®å‡†ç¡®æ€§ï¼Œå¹¶æœ‰æ•ˆç»´æŒäº†ä¸ªæ€§åŒ–æ€§èƒ½ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "20 pages, 15 figures",
      "pdf_url": "https://arxiv.org/pdf/2601.11000v1",
      "published_date": "2026-01-16 05:20:10 UTC",
      "updated_date": "2026-01-16 05:20:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:02:33.755856+00:00"
    },
    {
      "arxiv_id": "2601.10960v1",
      "title": "Steering Language Models Before They Speak: Logit-Level Interventions",
      "title_zh": "è¨€å‡ºä¹‹å‰çš„è¯­è¨€æ¨¡å‹å¼•å¯¼ï¼šLogit å±‚é¢å¹²é¢„",
      "authors": [
        "Hyeseon An",
        "Shinwoo Park",
        "Hyundong Jin",
        "Yo-Sub Han"
      ],
      "abstract": "Steering LLMs is essential for specialized applications such as style-sensitive text rewriting, user-adaptive communication, and toxicity mitigation. Current steering methods, such as prompting-based and activation-based approaches, are widely used to guide model behavior. However, activation-based techniques require deep access to internal layers, while prompting-based steering often fails to provide consistent or fine-grained control. In order to address these limitations, we propose a training-free inference-time logit intervention for controllable generation. Our approach utilizes a statistical token score table derived from z-normalized log-odds of labeled corpora to shift the decoding distribution. Empirical evaluations across three diverse datasets focusing on writing complexity, formality, and toxicity demonstrate that our method effectively steers output characteristics, confirming its broad applicability and task-agnostic nature. Our results show that statistically grounded logit steering can achieve large, consistent, and multi-task control gains: up to +47%p accuracy and 50x f1 improvement.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¼•å¯¼å¤§è¯­è¨€æ¨¡å‹ (LLMs) åœ¨é£æ ¼é‡å†™ã€è‡ªé€‚åº”é€šä¿¡å’Œæ¯’æ€§å‡è½»ç­‰ä¸“ä¸šåº”ç”¨ä¸­çš„é‡è¦æ€§ï¼Œå¹¶é’ˆå¯¹ç°æœ‰ prompting-based æ–¹æ³•æ§åˆ¶ä¸åŠ›ä»¥åŠ activation-based æŠ€æœ¯éœ€æ·±å±‚è®¿é—®çš„å±€é™ï¼Œæå‡ºäº†ä¸€ç§æ— éœ€è®­ç»ƒçš„æ¨ç†é˜¶æ®µ logit intervention æ–¹æ³•ã€‚è¯¥æ–¹æ³•é€šè¿‡ä½¿ç”¨åŸºäºæ ‡æ³¨è¯­æ–™åº“ z-normalized log-odds æ¨å¯¼å‡ºçš„ç»Ÿè®¡æ ‡è®°è¯„åˆ†è¡¨ (statistical token score table) æ¥å®æ—¶è°ƒæ•´è§£ç åˆ†å¸ƒï¼Œä»è€Œå®ç°å¯¹ç”Ÿæˆå†…å®¹çš„ç²¾ç»†åŒ–æ§åˆ¶ã€‚åœ¨å†™ä½œå¤æ‚åº¦ã€æ­£å¼åº¦å’Œæ¯’æ€§ç­‰å¤šä¸ªæ•°æ®é›†ä¸Šçš„å®éªŒéªŒè¯äº†è¯¥æ–¹æ¡ˆçš„æœ‰æ•ˆæ€§ï¼Œå±•ç¤ºäº†å…¶ task-agnostic çš„é€šç”¨ç‰¹å¾ã€‚ç ”ç©¶ç»“æœæ˜¾ç¤ºï¼Œè¿™ç§åŸºäºç»Ÿè®¡çš„ logit steering æŠ€æœ¯èƒ½å¤Ÿæ˜¾è‘—æå‡å¤šä»»åŠ¡æ§åˆ¶æ•ˆæœï¼Œä½¿å‡†ç¡®ç‡æœ€é«˜æå‡ 47% ä¸” F1 åˆ†æ•°å®ç° 50 å€çš„å¢é•¿ï¼Œä¸ºå¯æ§ç”Ÿæˆæä¾›äº†ä¸€ç§é«˜æ•ˆä¸”ç¨³å¥çš„æ–°é€”å¾„ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "14 pages, 5 figures, preprint",
      "pdf_url": "https://arxiv.org/pdf/2601.10960v1",
      "published_date": "2026-01-16 03:00:33 UTC",
      "updated_date": "2026-01-16 03:00:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:02:39.041089+00:00"
    },
    {
      "arxiv_id": "2601.11670v1",
      "title": "A Confidence-Variance Theory for Pseudo-Label Selection in Semi-Supervised Learning",
      "title_zh": "åŠç›‘ç£å­¦ä¹ ä¸­ä¼ªæ ‡ç­¾é€‰æ‹©çš„ç½®ä¿¡åº¦-æ–¹å·®ç†è®º",
      "authors": [
        "Jinshi Liu",
        "Pan Liu"
      ],
      "abstract": "Most pseudo-label selection strategies in semi-supervised learning rely on fixed confidence thresholds, implicitly assuming that prediction confidence reliably indicates correctness. In practice, deep networks are often overconfident: high-confidence predictions can still be wrong, while informative low-confidence samples near decision boundaries are discarded. This paper introduces a Confidence-Variance (CoVar) theory framework that provides a principled joint reliability criterion for pseudo-label selection. Starting from the entropy minimization principle, we derive a reliability measure that combines maximum confidence (MC) with residual-class variance (RCV), which characterizes how probability mass is distributed over non-maximum classes. The derivation shows that reliable pseudo-labels should have both high MC and low RCV, and that the influence of RCV increases as confidence grows, thereby correcting overconfident but unstable predictions. From this perspective, we cast pseudo-label selection as a spectral relaxation problem that maximizes separability in a confidence-variance feature space, and design a threshold-free selection mechanism to distinguish high- from low-reliability predictions. We integrate CoVar as a plug-in module into representative semi-supervised semantic segmentation and image classification methods. Across PASCAL VOC 2012, Cityscapes, CIFAR-10, and Mini-ImageNet with varying label ratios and backbones, it consistently improves over strong baselines, indicating that combining confidence with residual-class variance provides a more reliable basis for pseudo-label selection than fixed confidence thresholds. (Code: https://github.com/ljs11528/CoVar_Pseudo_Label_Selection.git)",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ç½®ä¿¡åº¦-æ–¹å·®(Confidence-Variance, CoVar)ç†è®ºæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³åŠç›‘ç£å­¦ä¹ (Semi-Supervised Learning)ä¸­å›ºå®šç½®ä¿¡åº¦é˜ˆå€¼å› æ·±åº¦ç½‘ç»œè¿‡åº¦è‡ªä¿¡è€Œå¯¼è‡´çš„ä¼ªæ ‡ç­¾é€‰æ‹©å¤±æ•ˆé—®é¢˜ã€‚è¯¥æ¡†æ¶ç»“åˆæœ€å¤§ç½®ä¿¡åº¦(Maximum Confidence, MC)ä¸å‰©ä½™ç±»åˆ«æ–¹å·®(Residual-Class Variance, RCV)æ„å»ºäº†è”åˆå¯é æ€§å‡†åˆ™ï¼ŒæŒ‡å‡ºå¯é çš„ä¼ªæ ‡ç­¾åº”åŒæ—¶æ»¡è¶³é«˜MCä¸ä½RCVï¼Œä¸”RCVèƒ½æœ‰æ•ˆçº æ­£é«˜ç½®ä¿¡åº¦ä½†ä¸ç¨³å®šçš„é¢„æµ‹ã€‚ç ”ç©¶è¿›ä¸€æ­¥å°†ä¼ªæ ‡ç­¾é€‰æ‹©å»ºæ¨¡ä¸ºå…‰è°±æ¾å¼›(Spectral Relaxation)é—®é¢˜ï¼Œé€šè¿‡æœ€å¤§åŒ–ç½®ä¿¡åº¦-æ–¹å·®ç‰¹å¾ç©ºé—´çš„å¯åˆ†æ€§ï¼Œå®ç°äº†ä¸€ç§æ— éœ€æ‰‹åŠ¨è®¾å®šé˜ˆå€¼çš„è‡ªé€‚åº”é€‰æ‹©æœºåˆ¶ã€‚å®éªŒè¯æ˜ï¼ŒCoVarä½œä¸ºé€šç”¨æ’ä»¶åœ¨PASCAL VOC 2012ã€Cityscapesã€CIFAR-10åŠMini-ImageNetç­‰å¤šä¸ªè¯­ä¹‰åˆ†å‰²ä¸å›¾åƒåˆ†ç±»åŸºå‡†æ•°æ®é›†ä¸Šå‡æ˜¾è‘—ä¼˜äºç°æœ‰å¼ºåŸºå‡†æ–¹æ³•ã€‚è¿™ä¸€ç ”ç©¶è¡¨æ˜ï¼Œç»“åˆç½®ä¿¡åº¦ä¸æ®‹å·®ç±»åˆ«åˆ†å¸ƒç‰¹å¾æ¯”å•çº¯ä¾èµ–å›ºå®šç½®ä¿¡åº¦é˜ˆå€¼èƒ½æä¾›æ›´å¯é çš„ä¼ªæ ‡ç­¾é€‰æ‹©ä¾æ®ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11670v1",
      "published_date": "2026-01-16 02:51:59 UTC",
      "updated_date": "2026-01-16 02:51:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:02:41.300755+00:00"
    },
    {
      "arxiv_id": "2601.10955v1",
      "title": "Beyond Max Tokens: Stealthy Resource Amplification via Tool Calling Chains in LLM Agents",
      "title_zh": "è¶…è¶Šæœ€å¤§ Tokenï¼šå¤§è¯­è¨€æ¨¡å‹æ™ºèƒ½ä½“ä¸­åŸºäºå·¥å…·è°ƒç”¨é“¾çš„éšè”½èµ„æºæ”¾å¤§",
      "authors": [
        "Kaiyu Zhou",
        "Yongsen Zheng",
        "Yicheng He",
        "Meng Xue",
        "Xueluan Gong",
        "Yuji Wang",
        "Kwok-Yan Lam"
      ],
      "abstract": "The agent-tool communication loop is a critical attack surface in modern Large Language Model (LLM) agents. Existing Denial-of-Service (DoS) attacks, primarily triggered via user prompts or injected retrieval-augmented generation (RAG) context, are ineffective for this new paradigm. They are fundamentally single-turn and often lack a task-oriented approach, making them conspicuous in goal-oriented workflows and unable to exploit the compounding costs of multi-turn agent-tool interactions. We introduce a stealthy, multi-turn economic DoS attack that operates at the tool layer under the guise of a correctly completed task. Our method adjusts text-visible fields and a template-governed return policy in a benign, Model Context Protocol (MCP)-compatible tool server, optimizing these edits with a Monte Carlo Tree Search (MCTS) optimizer. These adjustments leave function signatures unchanged and preserve the final payload, steering the agent into prolonged, verbose tool-calling sequences using text-only notices. This compounds costs across turns, escaping single-turn caps while keeping the final answer correct to evade validation. Across six LLMs on the ToolBench and BFCL benchmarks, our attack expands tasks into trajectories exceeding 60,000 tokens, inflates costs by up to 658x, and raises energy by 100-560x. It drives GPU KV cache occupancy from <1% to 35-74% and cuts co-running throughput by approximately 50%. Because the server remains protocol-compatible and task outcomes are correct, conventional checks fail. These results elevate the agent-tool interface to a first-class security frontier, demanding a paradigm shift from validating final answers to monitoring the economic and computational cost of the entire agentic process.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹(LLM)æ™ºèƒ½ä½“å·¥å…·è°ƒç”¨å¾ªç¯ä¸­çš„å®‰å…¨éšæ‚£ï¼ŒæŒ‡å‡ºä¼ ç»Ÿçš„æ‹’ç»æœåŠ¡(DoS)æ”»å‡»åœ¨å¤šè½®ä»»åŠ¡æµä¸­å®¹æ˜“è¢«å¯Ÿè§‰ä¸”æ•ˆæœæœ‰é™ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†ä¸€ç§éšè”½çš„å¤šè½®ç»æµæ‹’ç»æœåŠ¡æ”»å‡»ï¼Œé€šè¿‡åœ¨å…¼å®¹æ¨¡å‹ä¸Šä¸‹æ–‡åè®®(Model Context Protocol, MCP)çš„å·¥å…·æœåŠ¡å™¨ä¸­ï¼Œåˆ©ç”¨è’™ç‰¹å¡æ´›æ ‘æœç´¢(Monte Carlo Tree Search, MCTS)ä¼˜åŒ–å™¨å¾®è°ƒæ–‡æœ¬å­—æ®µä¸è¿”å›ç­–ç•¥ã€‚è¯¥æ–¹æ³•åœ¨ä¿è¯å‡½æ•°ç­¾åä¸å˜åŠæœ€ç»ˆä»»åŠ¡ç»“æœæ­£ç¡®ä»¥é€ƒé¿éªŒè¯çš„åŒæ—¶ï¼Œè¯±å¯¼æ™ºèƒ½ä½“è¿›å…¥æå…¶å†—é•¿ä¸”é«˜æ¶ˆè€—çš„å·¥å…·è°ƒç”¨åºåˆ—ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ”»å‡»åœ¨ToolBenchå’ŒBFCLåŸºå‡†æµ‹è¯•ä¸­èƒ½å°†ä»»åŠ¡è½¨è¿¹æ‰©å±•è‡³è¶…è¿‡60,000ä¸ªTokensï¼Œä½¿ç»æµæˆæœ¬å¢åŠ é«˜è¾¾658å€ï¼Œå¹¶å¯¼è‡´GPUçš„é”®å€¼ç¼“å­˜(KV cache)å ç”¨ç‡å¤§å¹…é£™å‡ã€‚è¿™ä¸€å‘ç°è¯æ˜äº†ä¼ ç»Ÿçš„ç­”æ¡ˆéªŒè¯æœºåˆ¶åœ¨åº”å¯¹æ­¤ç±»éšè”½æ”»å‡»æ—¶çš„å¤±æ•ˆï¼Œå¼ºè°ƒäº†å°†å®‰å…¨é˜²å¾¡é‡ç‚¹è½¬å‘ç›‘æ§æ™ºèƒ½ä½“å…¨æµç¨‹è®¡ç®—æˆæœ¬çš„ç´§è¿«æ€§ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.10955v1",
      "published_date": "2026-01-16 02:47:45 UTC",
      "updated_date": "2026-01-16 02:47:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:02:44.239734+00:00"
    },
    {
      "arxiv_id": "2601.15316v1",
      "title": "The Paradigm Shift: A Comprehensive Survey on Large Vision Language Models for Multimodal Fake News Detection",
      "title_zh": "èŒƒå¼è½¬å˜ï¼šå¤šæ¨¡æ€è™šå‡æ–°é—»æ£€æµ‹ä¸­çš„å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹å…¨é¢ç»¼è¿°",
      "authors": [
        "Wei Ai",
        "Yilong Tan",
        "Yuntao Shou",
        "Tao Meng",
        "Haowen Chen",
        "Zhixiong He",
        "Keqin Li"
      ],
      "abstract": "In recent years, the rapid evolution of large vision-language models (LVLMs) has driven a paradigm shift in multimodal fake news detection (MFND), transforming it from traditional feature-engineering approaches to unified, end-to-end multimodal reasoning frameworks. Early methods primarily relied on shallow fusion techniques to capture correlations between text and images, but they struggled with high-level semantic understanding and complex cross-modal interactions. The emergence of LVLMs has fundamentally changed this landscape by enabling joint modeling of vision and language with powerful representation learning, thereby enhancing the ability to detect misinformation that leverages both textual narratives and visual content. Despite these advances, the field lacks a systematic survey that traces this transition and consolidates recent developments. To address this gap, this paper provides a comprehensive review of MFND through the lens of LVLMs. We first present a historical perspective, mapping the evolution from conventional multimodal detection pipelines to foundation model-driven paradigms. Next, we establish a structured taxonomy covering model architectures, datasets, and performance benchmarks. Furthermore, we analyze the remaining technical challenges, including interpretability, temporal reasoning, and domain generalization. Finally, we outline future research directions to guide the next stage of this paradigm shift. To the best of our knowledge, this is the first comprehensive survey to systematically document and analyze the transformative role of LVLMs in combating multimodal fake news. The summary of existing methods mentioned is in our Github: \\href{https://github.com/Tan-YiLong/Overview-of-Fake-News-Detection}{https://github.com/Tan-YiLong/Overview-of-Fake-News-Detection}.",
      "tldr_zh": "è¿™ç¯‡ç»¼è¿°è®ºæ–‡æ¢è®¨äº†å¤šæ¨¡æ€è™šå‡æ–°é—»æ£€æµ‹(Multimodal Fake News Detection, MFND)é¢†åŸŸä»ä¼ ç»Ÿçš„ç‰¹å¾å·¥ç¨‹æ–¹æ³•å‘åŸºäºå¤§è§†è§‰è¯­è¨€æ¨¡å‹(Large Vision-Language Models, LVLMs)çš„ç»Ÿä¸€ç«¯åˆ°ç«¯æ¨ç†æ¡†æ¶çš„èŒƒå¼è½¬å˜ã€‚æ—©æœŸæ–¹æ³•ä¸»è¦ä¾èµ–æµ…å±‚èåˆæŠ€æœ¯ï¼Œéš¾ä»¥å¤„ç†é«˜å±‚è¯­ä¹‰ç†è§£å’Œå¤æ‚çš„è·¨æ¨¡æ€äº¤äº’ï¼Œè€ŒLVLMsé€šè¿‡å¼ºå¤§çš„è¡¨ç¤ºå­¦ä¹ å’Œè”åˆå»ºæ¨¡èƒ½åŠ›ï¼Œæ˜¾è‘—å¢å¼ºäº†æ£€æµ‹ç»“åˆæ–‡æœ¬å™äº‹å’Œè§†è§‰å†…å®¹çš„è¯¯å¯¼æ€§ä¿¡æ¯çš„èƒ½åŠ›ã€‚è¯¥ç ”ç©¶é€šè¿‡LVLMsçš„è§†è§’å…¨é¢å›é¡¾äº†MFNDçš„å‘å±•å†ç¨‹ï¼Œæç»˜äº†ä»å¸¸è§„æ£€æµ‹æµæ°´çº¿åˆ°åŸºç¡€æ¨¡å‹é©±åŠ¨èŒƒå¼çš„æ¼”è¿›è·¯å¾„ã€‚è®ºæ–‡å»ºç«‹äº†ä¸€ä¸ªç»“æ„åŒ–çš„åˆ†ç±»ä½“ç³»ï¼Œæ¶µç›–äº†æ¨¡å‹æ¶æ„(Architectures)ã€æ•°æ®é›†(Datasets)å’Œæ€§èƒ½åŸºå‡†(Benchmarks)ã€‚æ­¤å¤–ï¼Œæ–‡ç« è¿˜åˆ†æäº†å½“å‰é¢ä¸´çš„æŠ€æœ¯æŒ‘æˆ˜ï¼ŒåŒ…æ‹¬å¯è§£é‡Šæ€§(Interpretability)ã€æ—¶é—´æ¨ç†(Temporal Reasoning)å’Œé¢†åŸŸæ³›åŒ–(Domain Generalization)ã€‚æœ€åï¼Œè¯¥ç»¼è¿°æ€»ç»“äº†æœªæ¥çš„ç ”ç©¶æ–¹å‘ï¼Œæ—¨åœ¨å¼•å¯¼èŒƒå¼è½¬å˜çš„ä¸‹ä¸€é˜¶æ®µï¼Œæ˜¯é¦–ç¯‡ç³»ç»Ÿè®°å½•å’Œåˆ†æLVLMsåœ¨å¯¹æŠ—å¤šæ¨¡æ€è™šå‡æ–°é—»ä¸­è½¬å‹ä½œç”¨çš„ç»¼åˆæ€§ç»¼è¿°ã€‚",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.15316v1",
      "published_date": "2026-01-16 02:40:16 UTC",
      "updated_date": "2026-01-16 02:40:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:02:47.439174+00:00"
    },
    {
      "arxiv_id": "2601.10951v1",
      "title": "Multi-Stage Patient Role-Playing Framework for Realistic Clinical Interactions",
      "title_zh": "é¢å‘çœŸå®ä¸´åºŠäº’åŠ¨çš„å¤šé˜¶æ®µæ‚£è€…è§’è‰²æ‰®æ¼”æ¡†æ¶",
      "authors": [
        "Shijie Jiang",
        "Zefan Zhang",
        "Kehua Zhu",
        "Tian Bai",
        "Ruihong Zhao"
      ],
      "abstract": "The simulation of realistic clinical interactions plays a pivotal role in advancing clinical Large Language Models (LLMs) and supporting medical diagnostic education. Existing approaches and benchmarks rely on generic or LLM-generated dialogue data, which limits the authenticity and diversity of doctor-patient interactions. In this work, we propose the first Chinese patient simulation dataset (Ch-PatientSim), constructed from realistic clinical interaction scenarios to comprehensively evaluate the performance of models in emulating patient behavior. Patients are simulated based on a five-dimensional persona structure. To address issues of the persona class imbalance, a portion of the dataset is augmented using few-shot generation, followed by manual verification. We evaluate various state-of-the-art LLMs and find that most produce overly formal responses that lack individual personality. To address this limitation, we propose a training-free Multi-Stage Patient Role-Playing (MSPRP) framework, which decomposes interactions into three stages to ensure both personalization and realism in model responses. Experimental results demonstrate that our approach significantly improves model performance across multiple dimensions of patient simulation.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°æœ‰ä¸´åºŠå¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨æ¨¡æ‹ŸåŒ»æ‚£äº’åŠ¨æ—¶ç¼ºä¹çœŸå®æ€§å’Œå¤šæ ·æ€§çš„é—®é¢˜ï¼Œæå‡ºäº†é¦–ä¸ªåŸºäºçœŸå®ä¸´åºŠåœºæ™¯çš„ä¸­æ–‡ç—…äººæ¨¡æ‹Ÿæ•°æ®é›†Ch-PatientSimã€‚è¯¥æ•°æ®é›†é‡‡ç”¨äº”ç»´äººæ ¼ç»“æ„(persona structure)å®šä¹‰ç—…äººç‰¹å¾ï¼Œå¹¶åˆ©ç”¨å°‘æ ·æœ¬ç”Ÿæˆ(few-shot generation)ç»“åˆäººå·¥æ ¡éªŒçš„æ–¹æ³•è§£å†³äº†æ•°æ®ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜ã€‚ç ”ç©¶é€šè¿‡è¯„ä¼°å‘ç°ï¼Œç°æœ‰ä¸»æµæ¨¡å‹åœ¨æ¨¡æ‹Ÿç—…äººæ—¶æ™®éå­˜åœ¨å›å¤è¿‡äºæ­£å¼ä¸”ç¼ºä¹ä¸ªæ€§åŒ–ç‰¹è´¨çš„é—®é¢˜ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†ä¸€ç§æ— éœ€è®­ç»ƒçš„å¤šé˜¶æ®µç—…äººè§’è‰²æ‰®æ¼”(Multi-Stage Patient Role-Playing, MSPRP)æ¡†æ¶ï¼Œå°†äº’åŠ¨è¿‡ç¨‹åˆ†è§£ä¸ºä¸‰ä¸ªé˜¶æ®µï¼Œä»¥ç¡®ä¿æ¨¡å‹ç”Ÿæˆçš„å“åº”å…¼å…·ä¸ªæ€§åŒ–ä¸çœŸå®æ„Ÿã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªæ¨¡æ‹Ÿç»´åº¦ä¸Šæ˜¾è‘—æå‡äº†æ¨¡å‹çš„æ€§èƒ½ï¼Œä¸ºä¸´åºŠè¯Šæ–­æ•™è‚²å’ŒåŒ»ç–—æ¨¡å‹çš„å‘å±•æä¾›äº†é‡è¦æ”¯æŒã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "22 pages, 5figures, under review",
      "pdf_url": "https://arxiv.org/pdf/2601.10951v1",
      "published_date": "2026-01-16 02:34:22 UTC",
      "updated_date": "2026-01-16 02:34:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:02:47.228746+00:00"
    },
    {
      "arxiv_id": "2601.10945v1",
      "title": "PatientVLM Meets DocVLM: Pre-Consultation Dialogue Between Vision-Language Models for Efficient Diagnosis",
      "title_zh": "PatientVLM é‡ä¸Š DocVLMï¼šæ—¨åœ¨å®ç°é«˜æ•ˆè¯Šæ–­çš„è§†è§‰è¯­è¨€æ¨¡å‹è¯Šå‰å¯¹è¯",
      "authors": [
        "K Lokesh",
        "Abhirama Subramanyam Penamakuri",
        "Uday Agarwal",
        "Apoorva Challa",
        "Shreya K Gowda",
        "Somesh Gupta",
        "Anand Mishra"
      ],
      "abstract": "Traditionally, AI research in medical diagnosis has largely centered on image analysis. While this has led to notable advancements, the absence of patient-reported symptoms continues to hinder diagnostic accuracy. To address this, we propose a Pre-Consultation Dialogue Framework (PCDF) that mimics real-world diagnostic procedures, where doctors iteratively query patients before reaching a conclusion. Specifically, we simulate diagnostic dialogues between two vision-language models (VLMs): a DocVLM, which generates follow-up questions based on the image and dialogue history, and a PatientVLM, which responds using a symptom profile derived from the ground-truth diagnosis. We additionally conducted a small-scale clinical validation of the synthetic symptoms generated by our framework, with licensed clinicians confirming their clinical relevance, symptom coverage, and overall realism. These findings indicate that the resulting DocVLM-PatientVLM interactions form coherent, multi-turn consultations paired with images and diagnoses, which we then use to fine-tune the DocVLM. This dialogue-based supervision leads to substantial gains over image-only training, highlighting the value of realistic symptom elicitation for diagnosis.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Pre-Consultation Dialogue Framework (PCDF)ï¼Œæ—¨åœ¨è§£å†³ä¼ ç»Ÿ AI åŒ»å­¦è¯Šæ–­å› è¿‡åº¦ä¾èµ–å›¾åƒåˆ†æè€Œç¼ºä¹æ‚£è€…è‡ªè¿°ç—‡çŠ¶å¯¼è‡´çš„å‡†ç¡®æ€§å—é™é—®é¢˜ã€‚è¯¥æ¡†æ¶é€šè¿‡æ¨¡æ‹ŸçœŸå®ä¸´åºŠè¯Šæ–­ä¸­çš„é—®è¯Šè¿‡ç¨‹ï¼Œè®©ä¸¤ä¸ªè§†è§‰è¯­è¨€æ¨¡å‹(VLMs)è¿›è¡Œäº¤äº’ï¼šDocVLM è´Ÿè´£ç»“åˆå›¾åƒä¸å¯¹è¯å†å²ç”Ÿæˆåç»­æé—®ï¼Œè€Œ PatientVLM åˆ™æ ¹æ®çœŸå®è¯Šæ–­è¡ç”Ÿçš„ç—‡çŠ¶ç‰¹å¾è¿›è¡Œå›ç­”ã€‚ç ”ç©¶å›¢é˜Ÿé€šè¿‡æ‰§ä¸šåŒ»ç”Ÿçš„å°è§„æ¨¡ä¸´åºŠéªŒè¯ï¼Œç¡®è®¤äº†è¯¥æ¡†æ¶ç”Ÿæˆçš„åˆæˆç—‡çŠ¶åœ¨ä¸´åºŠç›¸å…³æ€§å’ŒçœŸå®æ„Ÿæ–¹é¢å‡ç¬¦åˆåŒ»ç–—æ ‡å‡†ã€‚è¿™äº›é«˜è´¨é‡çš„å¤šè½®å¯¹è¯æ•°æ®éšåè¢«ç”¨äºå¾®è°ƒ DocVLMï¼Œæ„å»ºäº†åŸºäºå¯¹è¯çš„ç›‘ç£å­¦ä¹ æœºåˆ¶ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä¸ä»…ä¾èµ–å›¾åƒçš„è®­ç»ƒæ¨¡å¼ç›¸æ¯”ï¼Œè¿™ç§æ–¹æ³•æ˜¾è‘—æå‡äº†æ¨¡å‹çš„è¯Šæ–­æ€§èƒ½ï¼Œè¯æ˜äº†åœ¨ AI è¯Šæ–­ä¸­å¼•å…¥ç°å®ç—‡çŠ¶å¼•å¯¼(symptom elicitation)çš„å·¨å¤§ä»·å€¼ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at AAAI 2026 Main Track",
      "pdf_url": "https://arxiv.org/pdf/2601.10945v1",
      "published_date": "2026-01-16 02:18:29 UTC",
      "updated_date": "2026-01-16 02:18:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:03:00.547547+00:00"
    },
    {
      "arxiv_id": "2601.11667v1",
      "title": "Distill-then-Replace: Efficient Task-Specific Hybrid Attention Model Construction",
      "title_zh": "Distill-then-Replaceï¼šé«˜æ•ˆçš„ç‰¹å®šä»»åŠ¡æ··åˆæ³¨æ„åŠ›æ¨¡å‹æ„å»º",
      "authors": [
        "Xiaojie Xia",
        "Huigang Zhang",
        "Chaoliang Zhong",
        "Jun Sun",
        "Yusuke Oishi"
      ],
      "abstract": "Transformer architectures deliver state-of-the-art accuracy via dense full-attention, but their quadratic time and memory complexity with respect to sequence length limits practical deployment. Linear attention mechanisms offer linear or near-linear scaling yet often incur performance degradation. Hybrid models that integrate full and linear attention layers promise a balance between efficiency and expressiveness, but face two major challenges: training such hybrid models from scratch is computationally expensive, and manually designing the optimal placement of attention types is highly nontrivial. We address both issues by first transferring weights from the pretrained full-attention modules to its linear attention counterparts through blockwise local distillation, and second, introducing a greedy layer replacement strategy that iteratively substitutes full attention blocks with linear ones while monitoring validation performance on the target task. This yields a task-specific hybrid model in a single efficient pass, without costly re-training or neural architecture search, and can be applied to any pretrained full-attention backbone for diverse downstream tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ Transformer æ¶æ„ä¸­ dense full-attention çš„è®¡ç®—å¤æ‚åº¦éšåºåˆ—é•¿åº¦å‘ˆå¹³æ–¹å¢é•¿è€Œé™åˆ¶å®é™…åº”ç”¨çš„é—®é¢˜ï¼Œæ¢è®¨äº†ç»“åˆ full-attention ä¸ linear attention å±‚çš„ Hybrid modelsã€‚ä½œè€…æå‡ºäº† Distill-then-Replace æ¡†æ¶ï¼Œé¦–å…ˆé€šè¿‡ blockwise local distillation æŠ€æœ¯å°†é¢„è®­ç»ƒ full-attention æ¨¡å—çš„æƒé‡è¿ç§»è‡³å…¶ linear attention å¯¹åº”é¡¹ï¼Œè§£å†³äº†æ··åˆæ¨¡å‹ä»å¤´è®­ç»ƒæˆæœ¬é«˜æ˜‚çš„éš¾é¢˜ã€‚éšåï¼Œè¯¥æ–¹æ³•é‡‡ç”¨è´ªå¿ƒå±‚æ›¿æ¢ç­–ç•¥ï¼ˆgreedy layer replacementï¼‰ï¼Œåœ¨ç›‘æ§éªŒè¯é›†æ€§èƒ½çš„åŒæ—¶è¿­ä»£åœ°å°† full attention blocks æ›¿æ¢ä¸º linear blocksã€‚è¿™ç§æ–¹æ¡ˆæ— éœ€å¤æ‚çš„ neural architecture search æˆ–æ˜‚è´µçš„é‡æ–°è®­ç»ƒï¼Œä»…éœ€ä¸€æ¬¡é«˜æ•ˆè¿‡ç¨‹å³å¯ä¸ºä»»ä½•é¢„è®­ç»ƒ backbone æ„å»ºä»»åŠ¡ç‰¹å®šçš„æ··åˆæ¨¡å‹ã€‚æœ€ç»ˆå®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šç§ä¸‹æ¸¸ä»»åŠ¡ä¸­æœ‰æ•ˆå¹³è¡¡äº†æ¨¡å‹çš„è¡¨è¾¾èƒ½åŠ›ä¸æ¨ç†æ•ˆç‡ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.11667v1",
      "published_date": "2026-01-16 02:01:40 UTC",
      "updated_date": "2026-01-16 02:01:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:03:17.339521+00:00"
    },
    {
      "arxiv_id": "2601.10931v1",
      "title": "Sparse Data Tree Canopy Segmentation: Fine-Tuning Leading Pretrained Models on Only 150 Images",
      "title_zh": "ç¨€ç–æ•°æ®ä¸‹çš„æ ‘å† åˆ†å‰²ï¼šä»…åˆ©ç”¨ 150 å¼ å›¾åƒå¾®è°ƒä¸»æµé¢„è®­ç»ƒæ¨¡å‹",
      "authors": [
        "David Szczecina",
        "Hudson Sun",
        "Anthony Bertnyk",
        "Niloofar Azad",
        "Kyle Gao",
        "Lincoln Linlin Xu"
      ],
      "abstract": "Tree canopy detection from aerial imagery is an important task for environmental monitoring, urban planning, and ecosystem analysis. Simulating real-life data annotation scarcity, the Solafune Tree Canopy Detection competition provides a small and imbalanced dataset of only 150 annotated images, posing significant challenges for training deep models without severe overfitting. In this work, we evaluate five representative architectures, YOLOv11, Mask R-CNN, DeepLabv3, Swin-UNet, and DINOv2, to assess their suitability for canopy segmentation under extreme data scarcity. Our experiments show that pretrained convolution-based models, particularly YOLOv11 and Mask R-CNN, generalize significantly better than pretrained transformer-based models. DeeplabV3, Swin-UNet and DINOv2 underperform likely due to differences between semantic and instance segmentation tasks, the high data requirements of Vision Transformers, and the lack of strong inductive biases. These findings confirm that transformer-based architectures struggle in low-data regimes without substantial pretraining or augmentation and that differences between semantic and instance segmentation further affect model performance. We provide a detailed analysis of training strategies, augmentation policies, and model behavior under the small-data constraint and demonstrate that lightweight CNN-based methods remain the most reliable for canopy detection on limited imagery.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹èˆªç©ºå½±åƒä¸­çš„æ ‘å† åˆ†å‰²ä»»åŠ¡ï¼Œæ¢è®¨äº†åœ¨ä»…æœ‰150å¼ æ ‡æ³¨å›¾åƒçš„æåº¦æ•°æ®ç¨€ç¼º(Data Scarcity)æƒ…å†µä¸‹å¦‚ä½•æœ‰æ•ˆè®­ç»ƒæ·±åº¦å­¦ä¹ æ¨¡å‹ã€‚ä½œè€…å¯¹æ¯”è¯„ä¼°äº†YOLOv11ã€Mask R-CNNã€DeepLabv3ã€Swin-UNetå’ŒDINOv2äº”ç§ä»£è¡¨æ€§æ¶æ„ï¼Œæ—¨åœ¨è¯„ä¼°ä¸åŒæ¨¡å‹åœ¨æå°æ ·æœ¬é›†ä¸Šçš„æ³›åŒ–èƒ½åŠ›ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒåŸºäºå·ç§¯(Convolution-based)çš„æ¨¡å‹ï¼Œç‰¹åˆ«æ˜¯YOLOv11å’ŒMask R-CNNï¼Œå…¶æ€§èƒ½æ˜¾è‘—ä¼˜äºåŸºäºTransformerçš„æ¨¡å‹ã€‚ç ”ç©¶æŒ‡å‡ºï¼ŒTransformeræ¶æ„ç”±äºç¼ºä¹å¼ºå½’çº³åç½®(Inductive Biases)ä¸”å¯¹æ•°æ®é‡éœ€æ±‚è¾ƒé«˜ï¼Œåœ¨ç¼ºä¹å¤§è§„æ¨¡é¢„è®­ç»ƒæ—¶éš¾ä»¥åœ¨å°æ ·æœ¬ä»»åŠ¡ä¸­å‘æŒ¥ä¼˜åŠ¿ã€‚æ­¤å¤–ï¼Œè¯­ä¹‰åˆ†å‰²ä¸å®ä¾‹åˆ†å‰²ä»»åŠ¡çš„å›ºæœ‰å·®å¼‚ä¹Ÿå¯¹æ¨¡å‹è¡¨ç°äº§ç”Ÿäº†å½±å“ã€‚è¯¥å·¥ä½œé€šè¿‡è¯¦ç»†åˆ†æè®­ç»ƒç­–ç•¥å’Œå¢å¼ºæ”¿ç­–ï¼Œè¯æ˜äº†è½»é‡åŒ–CNNæ–¹æ³•åœ¨å—é™æ•°æ®ä¸‹è¿›è¡Œæ ‘å† æ£€æµ‹çš„å¯é æ€§ï¼Œä¸ºç¯å¢ƒç›‘æµ‹ç­‰å®é™…åº”ç”¨åœºæ™¯æä¾›äº†é‡è¦çš„æ¨¡å‹é€‰æ‹©æŒ‡å¯¼ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "4 pages, 2 figures",
      "pdf_url": "https://arxiv.org/pdf/2601.10931v1",
      "published_date": "2026-01-16 01:20:32 UTC",
      "updated_date": "2026-01-16 01:20:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:04:03.728580+00:00"
    },
    {
      "arxiv_id": "2601.11666v1",
      "title": "MATEX: Multi-scale Attention and Text-guided Explainability of Medical Vision-Language Models",
      "title_zh": "MATEXï¼šåŒ»å­¦è§†è§‰-è¯­è¨€æ¨¡å‹çš„å¤šå°ºåº¦æ³¨æ„åŠ›ä¸æ–‡æœ¬å¼•å¯¼å¯è§£é‡Šæ€§",
      "authors": [
        "Muhammad Imran",
        "Chi Lee",
        "Yugyung Lee"
      ],
      "abstract": "We introduce MATEX (Multi-scale Attention and Text-guided Explainability), a novel framework that advances interpretability in medical vision-language models by incorporating anatomically informed spatial reasoning. MATEX synergistically combines multi-layer attention rollout, text-guided spatial priors, and layer consistency analysis to produce precise, stable, and clinically meaningful gradient attribution maps. By addressing key limitations of prior methods, such as spatial imprecision, lack of anatomical grounding, and limited attention granularity, MATEX enables more faithful and interpretable model explanations. Evaluated on the MS-CXR dataset, MATEX outperforms the state-of-the-art M2IB approach in both spatial precision and alignment with expert-annotated findings. These results highlight MATEX's potential to enhance trust and transparency in radiological AI applications.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†MATEXï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨æå‡åŒ»å­¦è§†è§‰è¯­è¨€æ¨¡å‹(Medical Vision-Language Models)å¯è§£é‡Šæ€§çš„åˆ›æ–°æ¡†æ¶ï¼Œé€šè¿‡å¼•å…¥è§£å‰–å­¦æ„ŸçŸ¥çš„ç©ºé—´æ¨ç†æ¥å¢å¼ºæ¨¡å‹çš„é€æ˜åº¦ã€‚MATEXååŒç»“åˆäº†å¤šå±‚æ³¨æ„åŠ›å±•å¼€(multi-layer attention rollout)ã€æ–‡æœ¬å¼•å¯¼çš„ç©ºé—´å…ˆéªŒ(text-guided spatial priors)ä»¥åŠå±‚ä¸€è‡´æ€§åˆ†æ(layer consistency analysis)ï¼Œä»è€Œç”Ÿæˆç²¾ç¡®ã€ç¨³å®šä¸”å…·æœ‰ä¸´åºŠæ„ä¹‰çš„æ¢¯åº¦å½’å› å›¾(gradient attribution maps)ã€‚è¯¥æ¡†æ¶æœ‰æ•ˆè§£å†³äº†å…ˆå‰æ–¹æ³•ä¸­å­˜åœ¨çš„ç©ºé—´ç²¾åº¦ä¸è¶³ã€ç¼ºä¹è§£å‰–å­¦åŸºç¡€åŠæ³¨æ„åŠ›ç²’åº¦æœ‰é™ç­‰å±€é™æ€§ï¼Œå®ç°äº†æ›´å¿ å®ä¸”æ˜“äºè§£é‡Šçš„æ¨¡å‹è¯´æ˜ã€‚åœ¨MS-CXRæ•°æ®é›†ä¸Šçš„è¯„ä¼°ç»“æœè¡¨æ˜ï¼ŒMATEXåœ¨ç©ºé—´ç²¾åº¦ä»¥åŠä¸ä¸“å®¶æ ‡æ³¨ç»“æœçš„ä¸€è‡´æ€§æ–¹é¢å‡ä¼˜äºç›®å‰çš„SOTAæ–¹æ³•M2IBã€‚è¿™äº›å‘ç°å‡¸æ˜¾äº†MATEXåœ¨å¢å¼ºæ”¾å°„å­¦AIåº”ç”¨çš„å¯ä¿¡åº¦ä¸é€æ˜åº¦æ–¹é¢çš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "12 pages, 3 figures, 1 table",
      "pdf_url": "https://arxiv.org/pdf/2601.11666v1",
      "published_date": "2026-01-16 01:18:02 UTC",
      "updated_date": "2026-01-16 01:18:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:03:02.467248+00:00"
    },
    {
      "arxiv_id": "2601.10926v1",
      "title": "Selecting Language Models for Social Science: Start Small, Start Open, and Validate",
      "title_zh": "ç¤¾ä¼šç§‘å­¦è¯­è¨€æ¨¡å‹é€‰æ‹©ï¼šä»å°è§„æ¨¡ã€å¼€æºèµ·æ­¥ï¼Œå¹¶è¿›è¡ŒéªŒè¯",
      "authors": [
        "Dustin S. Stoltz",
        "Marshall A. Taylor",
        "Sanuj Kumar"
      ],
      "abstract": "Currently, there are thousands of large pretrained language models (LLMs) available to social scientists. How do we select among them? Using validity, reliability, reproducibility, and replicability as guides, we explore the significance of: (1) model openness, (2) model footprint, (3) training data, and (4) model architectures and fine-tuning. While ex-ante tests of validity (i.e., benchmarks) are often privileged in these discussions, we argue that social scientists cannot altogether avoid validating computational measures (ex-post). Replicability, in particular, is a more pressing guide for selecting language models. Being able to reliably replicate a particular finding that entails the use of a language model necessitates reliably reproducing a task. To this end, we propose starting with smaller, open models, and constructing delimited benchmarks to demonstrate the validity of the entire computational pipeline.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†ç¤¾ä¼šç§‘å­¦å®¶åœ¨é¢å¯¹æˆåƒä¸Šä¸‡çš„å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æ—¶åº”å¦‚ä½•è¿›è¡Œæœ‰æ•ˆé€‰æ‹©ã€‚ä½œè€…ä»¥æ•ˆåº¦ï¼ˆvalidityï¼‰ã€ä¿¡åº¦ï¼ˆreliabilityï¼‰ã€å†ç°æ€§ï¼ˆreproducibilityï¼‰å’Œå¯å¤åˆ¶æ€§ï¼ˆreplicabilityï¼‰ä¸ºæ ¸å¿ƒå‡†åˆ™ï¼Œæ·±å…¥åˆ†æäº†æ¨¡å‹å¼€æ”¾æ€§ï¼ˆmodel opennessï¼‰ã€æ¨¡å‹å ç”¨ç©ºé—´ï¼ˆmodel footprintï¼‰ã€è®­ç»ƒæ•°æ®åŠæ¶æ„ç­‰å› ç´ çš„å½±å“ã€‚ç ”ç©¶æŒ‡å‡ºï¼Œè™½ç„¶äº‹å‰åŸºå‡†æµ‹è¯•ï¼ˆbenchmarksï¼‰å¸¸è¢«ä¼˜å…ˆè€ƒè™‘ï¼Œä½†ç¤¾ä¼šç§‘å­¦å®¶å¿…é¡»å¯¹è®¡ç®—åº¦é‡è¿›è¡Œäº‹åï¼ˆex-postï¼‰éªŒè¯ã€‚ç”±äºå¯å¤åˆ¶æ€§æ˜¯ç¡®ä¿ç ”ç©¶å¯é æ€§çš„å…³é”®ï¼Œä½œè€…å»ºè®®ç ”ç©¶è€…åº”ä¼˜å…ˆé€‰æ‹©è¾ƒå°çš„å¼€æºæ¨¡å‹ï¼ˆopen modelsï¼‰ã€‚æœ€åï¼Œè¯¥ç ”ç©¶æå€¡é€šè¿‡æ„å»ºç•Œé™æ˜ç¡®çš„åŸºå‡†æ¥éªŒè¯æ•´ä¸ªè®¡ç®—æµç¨‹çš„æœ‰æ•ˆæ€§ï¼Œä»è€Œä¸ºç¤¾ä¼šç§‘å­¦ç ”ç©¶æä¾›æ›´ç¨³å¥çš„æŠ€æœ¯æ”¯æ’‘ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.10926v1",
      "published_date": "2026-01-16 01:01:47 UTC",
      "updated_date": "2026-01-16 01:01:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:04:12.659408+00:00"
    },
    {
      "arxiv_id": "2601.10922v1",
      "title": "What Matters in Data Curation for Multimodal Reasoning? Insights from the DCVLR Challenge",
      "title_zh": "å¤šæ¨¡æ€æ¨ç†æ•°æ®ç­–åº”çš„æ ¸å¿ƒè¦ç´ ï¼šæ¥è‡ª DCVLR æŒ‘æˆ˜èµ›çš„å¯ç¤º",
      "authors": [
        "Yosub Shin",
        "Michael Buriek",
        "Boris Sobolev",
        "Pavel Bushuyeu",
        "Vikas Kumar",
        "Haoyang Xu",
        "Samuel Watson",
        "Igor Molybog"
      ],
      "abstract": "We study data curation for multimodal reasoning through the NeurIPS 2025 Data Curation for Vision-Language Reasoning (DCVLR) challenge, which isolates dataset selection by fixing the model and training protocol. Using a compact curated dataset derived primarily from Walton Multimodal Cold Start, our submission placed first in the challenge. Through post-competition ablations, we show that difficulty-based example selection on an aligned base dataset is the dominant driver of performance gains. Increasing dataset size does not reliably improve mean accuracy under the fixed training recipe, but mainly reduces run-to-run variance, while commonly used diversity and synthetic augmentation heuristics provide no additional benefit and often degrade performance. These results characterize DCVLR as a saturation-regime evaluation and highlight the central role of alignment and difficulty in data-efficient multimodal reasoning.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤šæ¨¡æ€æ¨ç†ä¸­çš„æ•°æ®ç­–å±•(Data Curation)é—®é¢˜ï¼Œé€šè¿‡å‚åŠ NeurIPS 2025 Data Curation for Vision-Language Reasoning (DCVLR) ç«èµ›ï¼Œåœ¨å›ºå®šæ¨¡å‹å’Œè®­ç»ƒåè®®çš„æƒ…å†µä¸‹å®ç°äº†æ€§èƒ½çªç ´ã€‚ç ”ç©¶å›¢é˜Ÿåˆ©ç”¨ä»Walton Multimodal Cold Startè¡ç”Ÿçš„ç²¾é€‰æ•°æ®é›†è·å¾—äº†ç«èµ›ç¬¬ä¸€åï¼Œå¹¶æ·±å…¥åˆ†æäº†å½±å“æ€§èƒ½çš„å…³é”®å› ç´ ã€‚èµ›åæ¶ˆèå®éªŒè¡¨æ˜ï¼Œåœ¨å¯¹é½çš„åŸºå‡†æ•°æ®é›†ä¸Šè¿›è¡ŒåŸºäºéš¾åº¦çš„æ ·æœ¬é€‰æ‹©(difficulty-based example selection)æ˜¯æ€§èƒ½æå‡çš„æ ¸å¿ƒé©±åŠ¨åŠ›ã€‚ç ”ç©¶å‘ç°ï¼Œåœ¨å›ºå®šè®­ç»ƒæ–¹æ¡ˆä¸‹ï¼Œå•çº¯å¢åŠ æ•°æ®é›†è§„æ¨¡ä¸»è¦èµ·åˆ°é™ä½è¿è¡Œæ–¹å·®(variance)çš„ä½œç”¨ï¼Œè€Œéç¨³æ­¥æå‡å¹³å‡å‡†ç¡®ç‡ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œå¸¸ç”¨çš„å¤šæ ·æ€§(diversity)å’Œåˆæˆå¢å¼º(synthetic augmentation)æ–¹æ³•åœ¨æ­¤åœºæ™¯ä¸‹å¹¶æœªå¸¦æ¥é¢å¤–æ”¶ç›Šï¼Œç”šè‡³å¯èƒ½æŸå®³æ¨¡å‹è¡¨ç°ã€‚è¿™ä¸€ç»“æœå°†DCVLRç•Œå®šä¸ºä¸€ç§é¥±å’Œæœºåˆ¶è¯„ä¼°(saturation-regime evaluation)ï¼Œå¼ºè°ƒäº†å¯¹é½(alignment)å’Œéš¾åº¦åœ¨æ•°æ®é«˜æ•ˆå‹å¤šæ¨¡æ€æ¨ç†ä¸­çš„å†³å®šæ€§ä½œç”¨ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.10922v1",
      "published_date": "2026-01-16 00:50:01 UTC",
      "updated_date": "2026-01-16 00:50:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:03:14.693632+00:00"
    },
    {
      "arxiv_id": "2601.10921v1",
      "title": "RobuMTL: Enhancing Multi-Task Learning Robustness Against Weather Conditions",
      "title_zh": "RobuMTLï¼šå¢å¼ºå¤šä»»åŠ¡å­¦ä¹ å¯¹å¤©æ°”æ¡ä»¶çš„é²æ£’æ€§",
      "authors": [
        "Tasneem Shaffee",
        "Sherief Reda"
      ],
      "abstract": "Robust Multi-Task Learning (MTL) is crucial for autonomous systems operating in real-world environments, where adverse weather conditions can severely degrade model performance and reliability. In this paper, we introduce RobuMTL, a novel architecture designed to adaptively address visual degradation by dynamically selecting task-specific hierarchical Low-Rank Adaptation (LoRA) modules and a LoRA expert squad based on input perturbations in a mixture-of-experts fashion. Our framework enables adaptive specialization based on input characteristics, improving robustness across diverse real-world conditions. To validate our approach, we evaluated it on the PASCAL and NYUD-v2 datasets and compared it against single-task models, standard MTL baselines, and state-of-the-art methods. On the PASCAL benchmark, RobuMTL delivers a +2.8% average relative improvement under single perturbations and up to +44.4% under mixed weather conditions compared to the MTL baseline. On NYUD-v2, RobuMTL achieves a +9.7% average relative improvement across tasks. The code is available at GitHub.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† RobuMTLï¼Œä¸€ç§æ—¨åœ¨å¢å¼ºå¤šä»»åŠ¡å­¦ä¹  (Multi-Task Learning, MTL) é²æ£’æ€§çš„æ–°å‹æ¶æ„ï¼Œä»¥è§£å†³è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿåœ¨æ¶åŠ£å¤©æ°”ä¸‹è§†è§‰æ€§èƒ½ä¸¥é‡ä¸‹é™çš„é—®é¢˜ã€‚è¯¥æ¶æ„é‡‡ç”¨æ··åˆä¸“å®¶ (Mixture-of-Experts) æ¨¡å¼ï¼Œèƒ½å¤Ÿæ ¹æ®è¾“å…¥æ‰°åŠ¨åŠ¨æ€é€‰æ‹©ä»»åŠ¡ç‰¹å®šçš„å±‚æ¬¡åŒ–ä½ç§©è‡ªé€‚åº” (Low-Rank Adaptation, LoRA) æ¨¡å—å’Œ LoRA ä¸“å®¶å°ç»„ã€‚é€šè¿‡è¿™ç§è‡ªé€‚åº”ä¸“ä¸šåŒ–æœºåˆ¶ï¼ŒRobuMTL æœ‰æ•ˆæå‡äº†æ¨¡å‹åœ¨ä¸åŒçœŸå®ç¯å¢ƒæ¡ä»¶ä¸‹çš„åº”å¯¹èƒ½åŠ›ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨ PASCAL æ•°æ®é›†ä¸Šï¼ŒRobuMTL åœ¨å•ä¸€æ‰°åŠ¨ä¸‹çš„è¡¨ç°ä¼˜äºåŸºçº¿æ¨¡å‹ï¼Œè€Œåœ¨æ··åˆå¤©æ°”æ¡ä»¶ä¸‹çš„ç›¸å¯¹æ”¹è¿›æ›´æ˜¯é«˜è¾¾ +44.4%ã€‚åœ¨ NYUD-v2 æ•°æ®é›†ä¸Šï¼Œè¯¥æ–¹æ³•ä¹Ÿåœ¨å„é¡¹ä»»åŠ¡ä¸­å®ç°äº† +9.7% çš„å¹³å‡ç›¸å¯¹æå‡ã€‚è¿™é¡¹å·¥ä½œé€šè¿‡åŠ¨æ€æ¨¡å—é€‰æ‹©æœºåˆ¶ï¼Œä¸ºæ„å»ºåœ¨å¤æ‚æ°”è±¡æ¡ä»¶ä¸‹ä¾ç„¶ä¿æŒé«˜æ•ˆã€å¯é çš„è‡ªä¸»ç³»ç»Ÿæä¾›äº†é‡è¦çš„æŠ€æœ¯æ”¯æ’‘ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) 2026",
      "pdf_url": "https://arxiv.org/pdf/2601.10921v1",
      "published_date": "2026-01-16 00:41:42 UTC",
      "updated_date": "2026-01-16 00:41:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:03:12.731944+00:00"
    },
    {
      "arxiv_id": "2601.10917v1",
      "title": "Self-learned representation-guided latent diffusion model for breast cancer classification in deep ultraviolet whole surface images",
      "title_zh": "ç”¨äºæ·±ç´«å¤–å…¨è¡¨é¢å›¾åƒä¹³è…ºç™Œåˆ†ç±»çš„è‡ªå­¦ä¹ è¡¨å¾å¼•å¯¼æ½œåœ¨æ‰©æ•£æ¨¡å‹",
      "authors": [
        "Pouya Afshin",
        "David Helminiak",
        "Tianling Niu",
        "Julie M. Jorns",
        "Tina Yen",
        "Bing Yu",
        "Dong Hye Ye"
      ],
      "abstract": "Breast-Conserving Surgery (BCS) requires precise intraoperative margin assessment to preserve healthy tissue. Deep Ultraviolet Fluorescence Scanning Microscopy (DUV-FSM) offers rapid, high-resolution surface imaging for this purpose; however, the scarcity of annotated DUV data hinders the training of robust deep learning models. To address this, we propose an Self-Supervised Learning (SSL)-guided Latent Diffusion Model (LDM) to generate high-quality synthetic training patches. By guiding the LDM with embeddings from a fine-tuned DINO teacher, we inject rich semantic details of cellular structures into the synthetic data. We combine real and synthetic patches to fine-tune a Vision Transformer (ViT), utilizing patch prediction aggregation for WSI-level classification. Experiments using 5-fold cross-validation demonstrate that our method achieves 96.47 % accuracy and reduces the FID score to 45.72, significantly outperforming class-conditioned baselines.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä¿ä¹³æ‰‹æœ¯(Breast-Conserving Surgery, BCS)ä¸­æ·±ç´«å¤–è§å…‰æ‰«ææ˜¾å¾®é•œ(DUV-FSM)æ ‡æ³¨æ•°æ®åŒ®ä¹çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§ç”±è‡ªç›‘ç£å­¦ä¹ (Self-Supervised Learning, SSL)å¼•å¯¼çš„æ½œæ‰©æ•£æ¨¡å‹(Latent Diffusion Model, LDM)ï¼Œç”¨äºç”Ÿæˆé«˜è´¨é‡çš„åˆæˆè®­ç»ƒå›¾åƒã€‚è¯¥æ–¹æ³•é€šè¿‡åˆ©ç”¨å¾®è°ƒåçš„DINOæ•™å¸ˆæ¨¡å‹æ‰€æå–çš„åµŒå…¥å‘é‡(embeddings)æ¥æŒ‡å¯¼LDMç”Ÿæˆè¿‡ç¨‹ï¼Œä»è€Œå°†ç»†èƒç»“æ„çš„ä¸°å¯Œè¯­ä¹‰ç»†èŠ‚æ³¨å…¥åˆ°åˆæˆæ•°æ®ä¸­ã€‚ç ”ç©¶ç»“åˆçœŸå®ä¸åˆæˆå›¾åƒå—å…±åŒå¾®è°ƒè§†è§‰äº’æ„Ÿå™¨(Vision Transformer, ViT)ï¼Œå¹¶åˆ©ç”¨å›¾åƒå—é¢„æµ‹èšåˆæŠ€æœ¯å®ç°å…¨è¡¨é¢å›¾åƒ(WSI)çº§åˆ«çš„åˆ†ç±»ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨äº”æŠ˜äº¤å‰éªŒè¯ä¸­è¾¾åˆ°äº†96.47%çš„å‡†ç¡®ç‡ï¼Œå¹¶å°†FIDåˆ†æ•°é™ä½è‡³45.72ï¼Œæ€§èƒ½æ˜¾è‘—ä¼˜äºåŸºäºç±»åˆ«æ¡ä»¶çš„åŸºçº¿æ¨¡å‹ã€‚è¿™ä¸€æˆæœè¯æ˜äº†ç»“åˆç”Ÿæˆå¼æ¨¡å‹ä¸è‡ªç›‘ç£è¡¨å¾å­¦ä¹ åœ¨æå‡åŒ»å­¦å½±åƒåˆ†ç±»é²æ£’æ€§æ–¹é¢çš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "This paper has been accepted for the IEEE International Symposium on Biomedical Imaging (ISBI) 2026, London, UK, and will be presented in the corresponding session",
      "pdf_url": "https://arxiv.org/pdf/2601.10917v1",
      "published_date": "2026-01-16 00:22:22 UTC",
      "updated_date": "2026-01-16 00:22:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T21:03:25.964331+00:00"
    }
  ],
  "processing_status": "completed",
  "error": null,
  "raw_papers_fetched": true,
  "papers_count": 108,
  "processed_papers_count": 108,
  "failed_papers_count": 0,
  "llm_backup_calls": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2026-01-24T21:05:00.034895+00:00"
}