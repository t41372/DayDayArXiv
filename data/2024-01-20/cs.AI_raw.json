[
  {
    "arxiv_id": "2401.11337v1",
    "title": "Prompting Large Vision-Language Models for Compositional Reasoning",
    "authors": [
      "Timothy Ossowski",
      "Ming Jiang",
      "Junjie Hu"
    ],
    "abstract": "Vision-language models such as CLIP have shown impressive capabilities in\nencoding texts and images into aligned embeddings, enabling the retrieval of\nmultimodal data in a shared embedding space. However, these embedding-based\nmodels still face challenges in effectively matching images and texts with\nsimilar visio-linguistic compositionality, as evidenced by their performance on\nthe recent Winoground dataset. In this paper, we argue that this limitation\nstems from two factors: the use of single vector representations for complex\nmultimodal data, and the absence of step-by-step reasoning in these\nembedding-based methods. To address this issue, we make an exploratory step\nusing a novel generative method that prompts large vision-language models\n(e.g., GPT-4) to depict images and perform compositional reasoning. Our method\noutperforms other embedding-based methods on the Winoground dataset, and\nobtains further improvement of up to 10% accuracy when enhanced with the\noptimal description.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.11337v1",
    "published_date": "2024-01-20 22:04:28 UTC",
    "updated_date": "2024-01-20 22:04:28 UTC"
  },
  {
    "arxiv_id": "2402.00043v1",
    "title": "Interactive and Intelligent Root Cause Analysis in Manufacturing with Causal Bayesian Networks and Knowledge Graphs",
    "authors": [
      "Christoph Wehner",
      "Maximilian Kertel",
      "Judith Wewerka"
    ],
    "abstract": "Root Cause Analysis (RCA) in the manufacturing of electric vehicles is the\nprocess of identifying fault causes. Traditionally, the RCA is conducted\nmanually, relying on process expert knowledge. Meanwhile, sensor networks\ncollect significant amounts of data in the manufacturing process. Using this\ndata for RCA makes it more efficient. However, purely data-driven methods like\nCausal Bayesian Networks have problems scaling to large-scale, real-world\nmanufacturing processes due to the vast amount of potential cause-effect\nrelationships (CERs). Furthermore, purely data-driven methods have the\npotential to leave out already known CERs or to learn spurious CERs. The paper\ncontributes by proposing an interactive and intelligent RCA tool that combines\nexpert knowledge of an electric vehicle manufacturing process and a data-driven\nmachine learning method. It uses reasoning over a large-scale Knowledge Graph\nof the manufacturing process while learning a Causal Bayesian Network. In\naddition, an Interactive User Interface enables a process expert to give\nfeedback to the root cause graph by adding and removing information to the\nKnowledge Graph. The interactive and intelligent RCA tool reduces the learning\ntime of the Causal Bayesian Network while decreasing the number of spurious\nCERs. Thus, the interactive and intelligent RCA tool closes the feedback loop\nbetween expert and machine learning method.",
    "categories": [
      "cs.AI",
      "cs.CE",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.00043v1",
    "published_date": "2024-01-20 21:25:57 UTC",
    "updated_date": "2024-01-20 21:25:57 UTC"
  },
  {
    "arxiv_id": "2401.11325v3",
    "title": "Detecting Hidden Triggers: Mapping Non-Markov Reward Functions to Markov",
    "authors": [
      "Gregory Hyde",
      "Eugene Santos Jr"
    ],
    "abstract": "Many Reinforcement Learning algorithms assume a Markov reward function to\nguarantee optimality. However, not all reward functions are Markov. This paper\nproposes a framework for mapping non-Markov reward functions into equivalent\nMarkov ones by learning specialized reward automata, Reward Machines. Unlike\nthe general practice of learning Reward Machines, we do not require a set of\nhigh-level propositional symbols from which to learn. Rather, we learn hidden\ntriggers, directly from data, that construct them. We demonstrate the\nimportance of learning Reward Machines over their Deterministic Finite-State\nAutomata counterparts given their ability to model reward dependencies. We\nformalize this distinction in our learning objective. Our mapping process is\nconstructed as an Integer Linear Programming problem. We prove that our\nmappings form a suitable proxy for maximizing reward expectations. We\nempirically validate our approach by learning black-box, non-Markov reward\nfunctions in the Officeworld domain. Additionally, we demonstrate the\neffectiveness of learning reward dependencies in a new domain, Breakfastworld.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.11325v3",
    "published_date": "2024-01-20 21:09:27 UTC",
    "updated_date": "2024-08-16 16:18:28 UTC"
  },
  {
    "arxiv_id": "2401.11316v1",
    "title": "PRILoRA: Pruned and Rank-Increasing Low-Rank Adaptation",
    "authors": [
      "Nadav Benedek",
      "Lior Wolf"
    ],
    "abstract": "With the proliferation of large pre-trained language models (PLMs),\nfine-tuning all model parameters becomes increasingly inefficient, particularly\nwhen dealing with numerous downstream tasks that entail substantial training\nand storage costs. Several approaches aimed at achieving parameter-efficient\nfine-tuning (PEFT) have been proposed. Among them, Low-Rank Adaptation (LoRA)\nstands out as an archetypal method, incorporating trainable rank decomposition\nmatrices into each target module. Nevertheless, LoRA does not consider the\nvarying importance of each layer. To address these challenges, we introduce\nPRILoRA, which linearly allocates a different rank for each layer, in an\nincreasing manner, and performs pruning throughout the training process,\nconsidering both the temporary magnitude of weights and the accumulated\nstatistics of the input to any given layer. We validate the effectiveness of\nPRILoRA through extensive experiments on eight GLUE benchmarks, setting a new\nstate of the art.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "EACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2401.11316v1",
    "published_date": "2024-01-20 20:25:17 UTC",
    "updated_date": "2024-01-20 20:25:17 UTC"
  },
  {
    "arxiv_id": "2401.11314v2",
    "title": "CodeAid: Evaluating a Classroom Deployment of an LLM-based Programming Assistant that Balances Student and Educator Needs",
    "authors": [
      "Majeed Kazemitabaar",
      "Runlong Ye",
      "Xiaoning Wang",
      "Austin Z. Henley",
      "Paul Denny",
      "Michelle Craig",
      "Tovi Grossman"
    ],
    "abstract": "Timely, personalized feedback is essential for students learning programming.\nLLM-powered tools like ChatGPT offer instant support, but reveal direct answers\nwith code, which may hinder deep conceptual engagement. We developed CodeAid,\nan LLM-powered programming assistant delivering helpful, technically correct\nresponses, without revealing code solutions. CodeAid answers conceptual\nquestions, generates pseudo-code with line-by-line explanations, and annotates\nstudent's incorrect code with fix suggestions. We deployed CodeAid in a\nprogramming class of 700 students for a 12-week semester. A thematic analysis\nof 8,000 usages of CodeAid was performed, further enriched by weekly surveys,\nand 22 student interviews. We then interviewed eight programming educators to\ngain further insights. Our findings reveal four design considerations for\nfuture educational AI assistants: D1) exploiting AI's unique benefits; D2)\nsimplifying query formulation while promoting cognitive engagement; D3)\navoiding direct responses while encouraging motivated learning; and D4)\nmaintaining transparency and control for students to asses and steer AI\nresponses.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "CHI 2024 Paper - The paper includes 17 pages, 8 figures, 2 tables,\n  along with a 2-page appendix",
    "pdf_url": "http://arxiv.org/pdf/2401.11314v2",
    "published_date": "2024-01-20 20:14:42 UTC",
    "updated_date": "2024-02-25 22:47:24 UTC"
  },
  {
    "arxiv_id": "2401.11284v1",
    "title": "Evaluating Driver Readiness in Conditionally Automated Vehicles from Eye-Tracking Data and Head Pose",
    "authors": [
      "Mostafa Kazemi",
      "Mahdi Rezaei",
      "Mohsen Azarmi"
    ],
    "abstract": "As automated driving technology advances, the role of the driver to resume\ncontrol of the vehicle in conditionally automated vehicles becomes increasingly\ncritical. In the SAE Level 3 or partly automated vehicles, the driver needs to\nbe available and ready to intervene when necessary. This makes it essential to\nevaluate their readiness accurately. This article presents a comprehensive\nanalysis of driver readiness assessment by combining head pose features and\neye-tracking data. The study explores the effectiveness of predictive models in\nevaluating driver readiness, addressing the challenges of dataset limitations\nand limited ground truth labels. Machine learning techniques, including LSTM\narchitectures, are utilised to model driver readiness based on the\nSpatio-temporal status of the driver's head pose and eye gaze. The experiments\nin this article revealed that a Bidirectional LSTM architecture, combining both\nfeature sets, achieves a mean absolute error of 0.363 on the DMD dataset,\ndemonstrating superior performance in assessing driver readiness. The modular\narchitecture of the proposed model also allows the integration of additional\ndriver-specific features, such as steering wheel activity, enhancing its\nadaptability and real-world applicability.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.11284v1",
    "published_date": "2024-01-20 17:32:52 UTC",
    "updated_date": "2024-01-20 17:32:52 UTC"
  },
  {
    "arxiv_id": "2401.14413v1",
    "title": "Aprendizado de máquina aplicado na eletroquímica",
    "authors": [
      "Carlos Eduardo do Egito Araújo",
      "Lívia F. Sgobbi",
      "Iwens Gervasio Sene Jr",
      "Sergio Teixeira de Carvalho"
    ],
    "abstract": "This systematic review focuses on analyzing the use of machine learning\ntechniques for identifying and quantifying analytes in various electrochemical\napplications, presenting the available applications in the literature. Machine\nlearning is a tool that can facilitate the analysis and enhance the\nunderstanding of processes involving various analytes. In electrochemical\nbiosensors, it increases the precision of medical diagnostics, improving the\nidentification of biomarkers and pathogens with high reliability. It can be\neffectively used for the classification of complex chemical products; in\nenvironmental monitoring, using low-cost sensors; in portable devices and\nwearable systems; among others. Currently, the analysis of some analytes is\nstill performed manually, requiring the expertise of a specialist in the field\nand thus hindering the generalization of results. In light of the advancements\nin artificial intelligence today, this work proposes to carry out a systematic\nreview of the literature on the applications of artificial intelligence\ntechniques. A set of articles has been identified that address electrochemical\nproblems using machine learning techniques, more specifically, supervised\nlearning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "in Portuguese language",
    "pdf_url": "http://arxiv.org/pdf/2401.14413v1",
    "published_date": "2024-01-20 16:41:25 UTC",
    "updated_date": "2024-01-20 16:41:25 UTC"
  },
  {
    "arxiv_id": "2402.00881v1",
    "title": "On the Interplay of Artificial Intelligence and Space-Air-Ground Integrated Networks: A Survey",
    "authors": [
      "Adilya Bakambekova",
      "Nour Kouzayha",
      "Tareq Al-Naffouri"
    ],
    "abstract": "Space-Air-Ground Integrated Networks (SAGINs), which incorporate space and\naerial networks with terrestrial wireless systems, are vital enablers of the\nemerging sixth-generation (6G) wireless networks. Besides bringing significant\nbenefits to various applications and services, SAGINs are envisioned to extend\nhigh-speed broadband coverage to remote areas, such as small towns or mining\nsites, or areas where terrestrial infrastructure cannot reach, such as\nairplanes or maritime use cases. However, due to the limited power and storage\nresources, as well as other constraints introduced by the design of terrestrial\nnetworks, SAGINs must be intelligently configured and controlled to satisfy the\nenvisioned requirements. Meanwhile, Artificial Intelligence (AI) is another\ncritical enabler of 6G. Due to massive amounts of available data, AI has been\nleveraged to address pressing challenges of current and future wireless\nnetworks. By adding AI and facilitating the decision-making and prediction\nprocedures, SAGINs can effectively adapt to their surrounding environment, thus\nenhancing the performance of various metrics. In this work, we aim to\ninvestigate the interplay of AI and SAGINs by providing a holistic overview of\nstate-of-the-art research in AI-enabled SAGINs. Specifically, we present a\ncomprehensive overview of some potential applications of AI in SAGINs. We also\ncover open issues in employing AI and detail the contributions of SAGINs in the\ndevelopment of AI. Finally, we highlight some limitations of the existing\nresearch works and outline potential future research directions.",
    "categories": [
      "cs.NI",
      "cs.AI"
    ],
    "primary_category": "cs.NI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.00881v1",
    "published_date": "2024-01-20 16:10:31 UTC",
    "updated_date": "2024-01-20 16:10:31 UTC"
  },
  {
    "arxiv_id": "2401.11257v2",
    "title": "Measuring Policy Distance for Multi-Agent Reinforcement Learning",
    "authors": [
      "Tianyi Hu",
      "Zhiqiang Pu",
      "Xiaolin Ai",
      "Tenghai Qiu",
      "Jianqiang Yi"
    ],
    "abstract": "Diversity plays a crucial role in improving the performance of multi-agent\nreinforcement learning (MARL). Currently, many diversity-based methods have\nbeen developed to overcome the drawbacks of excessive parameter sharing in\ntraditional MARL. However, there remains a lack of a general metric to quantify\npolicy differences among agents. Such a metric would not only facilitate the\nevaluation of the diversity evolution in multi-agent systems, but also provide\nguidance for the design of diversity-based MARL algorithms. In this paper, we\npropose the multi-agent policy distance (MAPD), a general tool for measuring\npolicy differences in MARL. By learning the conditional representations of\nagents' decisions, MAPD can computes the policy distance between any pair of\nagents. Furthermore, we extend MAPD to a customizable version, which can\nquantify differences among agent policies on specified aspects. Based on the\nonline deployment of MAPD, we design a multi-agent dynamic parameter sharing\n(MADPS) algorithm as an example of the MAPD's applications. Extensive\nexperiments demonstrate that our method is effective in measuring differences\nin agent policies and specific behavioral tendencies. Moreover, in comparison\nto other methods of parameter sharing, MADPS exhibits superior performance.",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "primary_category": "cs.MA",
    "comment": "9 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2401.11257v2",
    "published_date": "2024-01-20 15:34:51 UTC",
    "updated_date": "2024-01-28 15:37:54 UTC"
  },
  {
    "arxiv_id": "2401.12247v1",
    "title": "Exploring consumers response to text-based chatbots in e-commerce: The moderating role of task complexity and chatbot disclosure",
    "authors": [
      "Xusen Cheng",
      "Ying Bao",
      "Alex Zarifis",
      "Wankun Gong",
      "Jian Mou"
    ],
    "abstract": "Artificial intelligence based chatbots have brought unprecedented business\npotential. This study aims to explore consumers trust and response to a\ntext-based chatbot in ecommerce, involving the moderating effects of task\ncomplexity and chatbot identity disclosure. A survey method with 299 useable\nresponses was conducted in this research. This study adopted the ordinary least\nsquares regression to test the hypotheses. First, the consumers perception of\nboth the empathy and friendliness of the chatbot positively impacts their trust\nin it. Second, task complexity negatively moderates the relationship between\nfriendliness and consumers trust. Third, disclosure of the text based chatbot\nnegatively moderates the relationship between empathy and consumers trust,\nwhile it positively moderates the relationship between friendliness and\nconsumers trust. Fourth, consumers trust in the chatbot increases their\nreliance on the chatbot and decreases their resistance to the chatbot in future\ninteractions. Adopting the stimulus organism response framework, this study\nprovides important insights on consumers perception and response to the\ntext-based chatbot. The findings of this research also make suggestions that\ncan increase consumers positive responses to text based chatbots. Extant\nstudies have investigated the effects of automated bots attributes on consumers\nperceptions. However, the boundary conditions of these effects are largely\nignored. This research is one of the first attempts to provide a deep\nunderstanding of consumers responses to a chatbot.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Internet Research (2021)",
    "pdf_url": "http://arxiv.org/pdf/2401.12247v1",
    "published_date": "2024-01-20 15:17:50 UTC",
    "updated_date": "2024-01-20 15:17:50 UTC"
  },
  {
    "arxiv_id": "2401.11252v1",
    "title": "Automated Fusion of Multimodal Electronic Health Records for Better Medical Predictions",
    "authors": [
      "Suhan Cui",
      "Jiaqi Wang",
      "Yuan Zhong",
      "Han Liu",
      "Ting Wang",
      "Fenglong Ma"
    ],
    "abstract": "The widespread adoption of Electronic Health Record (EHR) systems in\nhealthcare institutes has generated vast amounts of medical data, offering\nsignificant opportunities for improving healthcare services through deep\nlearning techniques. However, the complex and diverse modalities and feature\nstructures in real-world EHR data pose great challenges for deep learning model\ndesign. To address the multi-modality challenge in EHR data, current approaches\nprimarily rely on hand-crafted model architectures based on intuition and\nempirical experiences, leading to sub-optimal model architectures and limited\nperformance. Therefore, to automate the process of model design for mining EHR\ndata, we propose a novel neural architecture search (NAS) framework named\nAutoFM, which can automatically search for the optimal model architectures for\nencoding diverse input modalities and fusion strategies. We conduct thorough\nexperiments on real-world multi-modal EHR data and prediction tasks, and the\nresults demonstrate that our framework not only achieves significant\nperformance improvement over existing state-of-the-art methods but also\ndiscovers meaningful network architectures effectively.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by SDM 2024",
    "pdf_url": "http://arxiv.org/pdf/2401.11252v1",
    "published_date": "2024-01-20 15:14:14 UTC",
    "updated_date": "2024-01-20 15:14:14 UTC"
  },
  {
    "arxiv_id": "2401.11249v1",
    "title": "Evaluating if trust and personal information privacy concerns are barriers to using health insurance that explicitly utilizes AI",
    "authors": [
      "Alex Zarifis",
      "Peter Kawalek",
      "Aida Azadegan"
    ],
    "abstract": "Trust and privacy have emerged as significant concerns in online\ntransactions. Sharing information on health is especially sensitive but it is\nnecessary for purchasing and utilizing health insurance. Evidence shows that\nconsumers are increasingly comfortable with technology in place of humans, but\nthe expanding use of AI potentially changes this. This research explores\nwhether trust and privacy concern are barriers to the adoption of AI in health\ninsurance. Two scenarios are compared: The first scenario has limited AI that\nis not in the interface and its presence is not explicitly revealed to the\nconsumer. In the second scenario there is an AI interface and AI evaluation,\nand this is explicitly revealed to the consumer. The two scenarios were modeled\nand compared using SEM PLS-MGA. The findings show that trust is significantly\nlower in the second scenario where AI is visible. Privacy concerns are higher\nwith AI but the difference is not statistically significant within the model.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "H.0; A.0; K.4; K.6"
    ],
    "primary_category": "cs.CY",
    "comment": "Journal of Internet Commerce (2021)",
    "pdf_url": "http://arxiv.org/pdf/2401.11249v1",
    "published_date": "2024-01-20 15:02:56 UTC",
    "updated_date": "2024-01-20 15:02:56 UTC"
  },
  {
    "arxiv_id": "2401.11235v1",
    "title": "TreeMIL: A Multi-instance Learning Framework for Time Series Anomaly Detection with Inexact Supervision",
    "authors": [
      "Chen Liu",
      "Shibo He",
      "Haoyu Liu",
      "Shizhong Li"
    ],
    "abstract": "Time series anomaly detection (TSAD) plays a vital role in various domains\nsuch as healthcare, networks, and industry. Considering labels are crucial for\ndetection but difficult to obtain, we turn to TSAD with inexact supervision:\nonly series-level labels are provided during the training phase, while\npoint-level anomalies are predicted during the testing phase. Previous works\nfollow a traditional multi-instance learning (MIL) approach, which focuses on\nencouraging high anomaly scores at individual time steps. However, time series\nanomalies are not only limited to individual point anomalies, they can also be\ncollective anomalies, typically exhibiting abnormal patterns over subsequences.\nTo address the challenge of collective anomalies, in this paper, we propose a\ntree-based MIL framework (TreeMIL). We first adopt an N-ary tree structure to\ndivide the entire series into multiple nodes, where nodes at different levels\nrepresent subsequences with different lengths. Then, the subsequence features\nare extracted to determine the presence of collective anomalies. Finally, we\ncalculate point-level anomaly scores by aggregating features from nodes at\ndifferent levels. Experiments conducted on seven public datasets and eight\nbaselines demonstrate that TreeMIL achieves an average 32.3% improvement in F1-\nscore compared to previous state-of-the-art methods. The code is available at\nhttps://github.com/fly-orange/TreeMIL.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "This paper has been accepted by IEEE ICASSP 2024",
    "pdf_url": "http://arxiv.org/pdf/2401.11235v1",
    "published_date": "2024-01-20 14:15:04 UTC",
    "updated_date": "2024-01-20 14:15:04 UTC"
  },
  {
    "arxiv_id": "2402.01679v2",
    "title": "STICKERCONV: Generating Multimodal Empathetic Responses from Scratch",
    "authors": [
      "Yiqun Zhang",
      "Fanheng Kong",
      "Peidong Wang",
      "Shuang Sun",
      "Lingshuai Wang",
      "Shi Feng",
      "Daling Wang",
      "Yifei Zhang",
      "Kaisong Song"
    ],
    "abstract": "Stickers, while widely recognized for enhancing empathetic communication in\nonline interactions, remain underexplored in current empathetic dialogue\nresearch, notably due to the challenge of a lack of comprehensive datasets. In\nthis paper, we introduce the Agent for STICKERCONV (Agent4SC), which uses\ncollaborative agent interactions to realistically simulate human behavior with\nsticker usage, thereby enhancing multimodal empathetic communication. Building\non this foundation, we develop a multimodal empathetic dialogue dataset,\nSTICKERCONV, comprising 12.9K dialogue sessions, 5.8K unique stickers, and 2K\ndiverse conversational scenarios. This dataset serves as a benchmark for\nmultimodal empathetic generation. To advance further, we propose PErceive and\nGenerate Stickers (PEGS), a multimodal empathetic response generation\nframework, complemented by a comprehensive set of empathy evaluation metrics\nbased on LLM. Our experiments demonstrate PEGS's effectiveness in generating\ncontextually relevant and emotionally resonant multimodal empathetic responses,\ncontributing to the advancement of more nuanced and engaging empathetic\ndialogue systems.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.01679v2",
    "published_date": "2024-01-20 13:44:21 UTC",
    "updated_date": "2024-02-16 11:27:14 UTC"
  },
  {
    "arxiv_id": "2402.00042v2",
    "title": "Optimized Task Assignment and Predictive Maintenance for Industrial Machines using Markov Decision Process",
    "authors": [
      "Ali Nasir",
      "Samir Mekid",
      "Zaid Sawlan",
      "Omar Alsawafy"
    ],
    "abstract": "This paper considers a distributed decision-making approach for manufacturing\ntask assignment and condition-based machine health maintenance. Our approach\nconsiders information sharing between the task assignment and health management\ndecision-making agents. We propose the design of the decision-making agents\nbased on Markov decision processes. The key advantage of using a Markov\ndecision process-based approach is the incorporation of uncertainty involved in\nthe decision-making process. The paper provides detailed mathematical models\nalong with the associated practical execution strategy. In order to demonstrate\nthe effectiveness and practical applicability of our proposed approach, we have\nincluded a detailed numerical case study that is based on open source milling\nmachine tool degradation data. Our case study indicates that the proposed\napproach offers flexibility in terms of the selection of cost parameters and it\nallows for offline computation and analysis of the decision-making policy.\nThese features create and opportunity for the future work on learning of the\ncost parameters associated with our proposed model using artificial\nintelligence.",
    "categories": [
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.AI",
    "comment": "19 pages, 11 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2402.00042v2",
    "published_date": "2024-01-20 12:12:14 UTC",
    "updated_date": "2024-02-03 14:17:07 UTC"
  },
  {
    "arxiv_id": "2401.11217v1",
    "title": "A Hybrid Approach of Transfer Learning and Physics-Informed Modeling: Improving Dissolved Oxygen Concentration Prediction in an Industrial Wastewater Treatment Plant",
    "authors": [
      "Ece S. Koksal",
      "Erdal Aydin"
    ],
    "abstract": "Constructing first principles models is a challenging task for nonlinear and\ncomplex systems such as a wastewater treatment unit. In recent years,\ndata-driven models are widely used to overcome the complexity. However, they\noften suffer from issues such as missing, low quality or noisy data. Transfer\nlearning is a solution for this issue where knowledge from another task is\ntransferred to target one to increase the prediction performance. In this work,\nthe objective is increasing the prediction performance of an industrial\nwastewater treatment plant by transferring the knowledge of (i) an open-source\nsimulation model that captures the underlying physics of the process, albeit\nwith dissimilarities to the target plant, (ii) another industrial plant\ncharacterized by noisy and limited data but located in the same refinery, and\n(iii) the model in (ii) and making the objective function of the training\nproblem physics informed where the physics information derived from the\nopen-source model in (ii). The results have shown that test and validation\nperformance are improved up to 27% and 59%, respectively.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.DS"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.11217v1",
    "published_date": "2024-01-20 11:53:08 UTC",
    "updated_date": "2024-01-20 11:53:08 UTC"
  },
  {
    "arxiv_id": "2401.11212v3",
    "title": "Programming Distributed Collective Processes in the eXchange Calculus",
    "authors": [
      "Giorgio Audrito",
      "Roberto Casadei",
      "Ferruccio Damiani",
      "Gianluca Torta",
      "Mirko Viroli"
    ],
    "abstract": "Recent trends like the Internet of Things (IoT) suggest a vision of dense and\nmulti-scale deployments of computing devices in nearly all kinds of\nenvironments. A prominent engineering challenge revolves around programming the\ncollective adaptive behaviour of such computational ecosystems. This requires\nabstractions able to capture concepts like ensembles (dynamic groups of\ncooperating devices) and collective tasks (joint activities carried out by\nensembles). In this work, we consider collections of devices interacting with\nneighbours and that execute in nearly-synchronised sense-compute-interact\nrounds, where the computation is given by a single program mapping sensing\nvalues and incoming messages to output and outcoming messages. To support\nprogramming whole computational collectives, we propose the abstraction of a\ndistributed collective process, which can be used to define at once the\nensemble formation logic and its collective task. We formalise the abstraction\nin the eXchange Calculus (XC), a core functional language based on neighbouring\nvalues (maps from neighbours to values) where state and interaction is handled\nthrough a single primitive, exchange, and provide a corresponding\nimplementation in the FCPP language. Then, we exercise distributed collective\nprocesses using two case studies: multi-hop message propagation and distributed\nmonitoring of spatial properties. Finally, we discuss the features of the\nabstraction and its suitability for different kinds of distributed computing\napplications.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.MA",
      "cs.PL",
      "D.1.3; F.1.1; F.4.3; I.2.11; J.7"
    ],
    "primary_category": "cs.DC",
    "comment": "41 pages, 17 figures",
    "pdf_url": "http://arxiv.org/pdf/2401.11212v3",
    "published_date": "2024-01-20 11:37:44 UTC",
    "updated_date": "2025-04-04 15:23:08 UTC"
  },
  {
    "arxiv_id": "2401.11201v1",
    "title": "Navigating the Thin Line: Examining User Behavior in Search to Detect Engagement and Backfire Effects",
    "authors": [
      "F. M. Cau",
      "N. Tintarev"
    ],
    "abstract": "Opinionated users often seek information that aligns with their preexisting\nbeliefs while dismissing contradictory evidence due to confirmation bias. This\nconduct hinders their ability to consider alternative stances when searching\nthe web. Despite this, few studies have analyzed how the diversification of\nsearch results on disputed topics influences the search behavior of highly\nopinionated users. To this end, we present a preregistered user study (n = 257)\ninvestigating whether different levels (low and high) of bias metrics and\nsearch results presentation (with or without AI-predicted stances labels) can\naffect the stance diversity consumption and search behavior of opinionated\nusers on three debated topics (i.e., atheism, intellectual property rights, and\nschool uniforms). Our results show that exposing participants to\n(counter-attitudinally) biased search results increases their consumption of\nattitude-opposing content, but we also found that bias was associated with a\ntrend toward overall fewer interactions within the search page. We also found\nthat 19% of users interacted with queries and search pages but did not select\nany search results. When we removed these participants in a post-hoc analysis,\nwe found that stance labels increased the diversity of stances consumed by\nusers, particularly when the search results were biased. Our findings highlight\nthe need for future research to explore distinct search scenario settings to\ngain insight into opinionated users' behavior.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "17 pages, 3 figures, ECIR2024 (46th European Conference on\n  Information Retrieval - IR4Good track)",
    "pdf_url": "http://arxiv.org/pdf/2401.11201v1",
    "published_date": "2024-01-20 10:28:25 UTC",
    "updated_date": "2024-01-20 10:28:25 UTC"
  },
  {
    "arxiv_id": "2401.11188v1",
    "title": "Fast and Exact Enumeration of Deep Networks Partitions Regions",
    "authors": [
      "Randall Balestriero",
      "Yann LeCun"
    ],
    "abstract": "One fruitful formulation of Deep Networks (DNs) enabling their theoretical\nstudy and providing practical guidelines to practitioners relies on Piecewise\nAffine Splines. In that realm, a DN's input-mapping is expressed as per-region\naffine mapping where those regions are implicitly determined by the model's\narchitecture and form a partition of their input space. That partition -- which\nis involved in all the results spanned from this line of research -- has so far\nonly been computed on $2/3$-dimensional slices of the DN's input space or\nestimated by random sampling. In this paper, we provide the first parallel\nalgorithm that does exact enumeration of the DN's partition regions. The\nproposed algorithm enables one to finally assess the closeness of the commonly\nemployed approximations methods, e.g. based on random sampling of the DN input\nspace. One of our key finding is that if one is only interested in regions with\n``large'' volume, then uniform sampling of the space is highly efficient, but\nthat if one is also interested in discovering the ``small'' regions of the\npartition, then uniform sampling is exponentially costly with the DN's input\nspace dimension. On the other hand, our proposed method has complexity scaling\nlinearly with input dimension and the number of regions.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.11188v1",
    "published_date": "2024-01-20 09:51:52 UTC",
    "updated_date": "2024-01-20 09:51:52 UTC"
  },
  {
    "arxiv_id": "2401.11174v3",
    "title": "Pixel-Wise Recognition for Holistic Surgical Scene Understanding",
    "authors": [
      "Nicolás Ayobi",
      "Santiago Rodríguez",
      "Alejandra Pérez",
      "Isabela Hernández",
      "Nicolás Aparicio",
      "Eugénie Dessevres",
      "Sebastián Peña",
      "Jessica Santander",
      "Juan Ignacio Caicedo",
      "Nicolás Fernández",
      "Pablo Arbeláez"
    ],
    "abstract": "This paper presents the Holistic and Multi-Granular Surgical Scene\nUnderstanding of Prostatectomies (GraSP) dataset, a curated benchmark that\nmodels surgical scene understanding as a hierarchy of complementary tasks with\nvarying levels of granularity. Our approach encompasses long-term tasks, such\nas surgical phase and step recognition, and short-term tasks, including\nsurgical instrument segmentation and atomic visual actions detection. To\nexploit our proposed benchmark, we introduce the Transformers for Actions,\nPhases, Steps, and Instrument Segmentation (TAPIS) model, a general\narchitecture that combines a global video feature extractor with localized\nregion proposals from an instrument segmentation model to tackle the\nmulti-granularity of our benchmark. Through extensive experimentation in ours\nand alternative benchmarks, we demonstrate TAPIS's versatility and\nstate-of-the-art performance across different tasks. This work represents a\nfoundational step forward in Endoscopic Vision, offering a novel framework for\nfuture research towards holistic surgical scene understanding.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Preprint submitted to Medical Image Analysis. Official extension of\n  previous MICCAI 2022\n  (https://link.springer.com/chapter/10.1007/978-3-031-16449-1_42) and ISBI\n  2023 (https://ieeexplore.ieee.org/document/10230819) orals. Data and codes\n  are available at https://github.com/BCV-Uniandes/GraSP",
    "pdf_url": "http://arxiv.org/pdf/2401.11174v3",
    "published_date": "2024-01-20 09:09:52 UTC",
    "updated_date": "2024-12-27 01:39:43 UTC"
  },
  {
    "arxiv_id": "2402.01677v5",
    "title": "Embedding Ontologies via Incorporating Extensional and Intensional Knowledge",
    "authors": [
      "Keyu Wang",
      "Guilin Qi",
      "Jiaoyan Chen",
      "Yi Huang",
      "Tianxing Wu"
    ],
    "abstract": "Ontologies contain rich knowledge within domain, which can be divided into\ntwo categories, namely extensional knowledge and intensional knowledge.\nExtensional knowledge provides information about the concrete instances that\nbelong to specific concepts in the ontology, while intensional knowledge\ndetails inherent properties, characteristics, and semantic associations among\nconcepts. However, existing ontology embedding approaches fail to take both\nextensional knowledge and intensional knowledge into fine consideration\nsimultaneously. In this paper, we propose a novel ontology embedding approach\nnamed EIKE (Extensional and Intensional Knowledge Embedding) by representing\nontologies in two spaces, called extensional space and intensional space. EIKE\npresents a unified framework for embedding instances, concepts and their\nrelations in an ontology, applying a geometry-based method to model extensional\nknowledge and a pretrained language model to model intensional knowledge, which\ncan capture both structure information and textual information. Experimental\nresults show that EIKE significantly outperforms state-of-the-art methods in\nthree datasets for both triple classification and link prediction, indicating\nthat EIKE provides a more comprehensive and representative perspective of the\ndomain.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.01677v5",
    "published_date": "2024-01-20 08:44:34 UTC",
    "updated_date": "2025-04-21 15:58:38 UTC"
  },
  {
    "arxiv_id": "2401.12244v1",
    "title": "Large-scale Reinforcement Learning for Diffusion Models",
    "authors": [
      "Yinan Zhang",
      "Eric Tzeng",
      "Yilun Du",
      "Dmitry Kislyuk"
    ],
    "abstract": "Text-to-image diffusion models are a class of deep generative models that\nhave demonstrated an impressive capacity for high-quality image generation.\nHowever, these models are susceptible to implicit biases that arise from\nweb-scale text-image training pairs and may inaccurately model aspects of\nimages we care about. This can result in suboptimal samples, model bias, and\nimages that do not align with human ethics and preferences. In this paper, we\npresent an effective scalable algorithm to improve diffusion models using\nReinforcement Learning (RL) across a diverse set of reward functions, such as\nhuman preference, compositionality, and fairness over millions of images. We\nillustrate how our approach substantially outperforms existing methods for\naligning diffusion models with human preferences. We further illustrate how\nthis substantially improves pretrained Stable Diffusion (SD) models, generating\nsamples that are preferred by humans 80.3% of the time over those from the base\nSD model while simultaneously improving both the composition and diversity of\ngenerated samples.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.12244v1",
    "published_date": "2024-01-20 08:10:43 UTC",
    "updated_date": "2024-01-20 08:10:43 UTC"
  },
  {
    "arxiv_id": "2401.11156v2",
    "title": "Generalizing Speaker Verification for Spoof Awareness in the Embedding Space",
    "authors": [
      "Xuechen Liu",
      "Md Sahidullah",
      "Kong Aik Lee",
      "Tomi Kinnunen"
    ],
    "abstract": "It is now well-known that automatic speaker verification (ASV) systems can be\nspoofed using various types of adversaries. The usual approach to counteract\nASV systems against such attacks is to develop a separate spoofing\ncountermeasure (CM) module to classify speech input either as a bonafide, or a\nspoofed utterance. Nevertheless, such a design requires additional computation\nand utilization efforts at the authentication stage. An alternative strategy\ninvolves a single monolithic ASV system designed to handle both zero-effort\nimposter (non-targets) and spoofing attacks. Such spoof-aware ASV systems have\nthe potential to provide stronger protections and more economic computations.\nTo this end, we propose to generalize the standalone ASV (G-SASV) against\nspoofing attacks, where we leverage limited training data from CM to enhance a\nsimple backend in the embedding space, without the involvement of a separate CM\nmodule during the test (authentication) phase. We propose a novel yet simple\nbackend classifier based on deep neural networks and conduct the study via\ndomain adaptation and multi-task integration of spoof embeddings at the\ntraining stage. Experiments are conducted on the ASVspoof 2019 logical access\ndataset, where we improve the performance of statistical ASV backends on the\njoint (bonafide and spoofed) and spoofed conditions by a maximum of 36.2% and\n49.8% in terms of equal error rates, respectively.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CR",
    "comment": "Published in IEEE/ACM Transactions on Audio, Speech, and Language\n  Processing (doi updated)",
    "pdf_url": "http://arxiv.org/pdf/2401.11156v2",
    "published_date": "2024-01-20 07:30:22 UTC",
    "updated_date": "2024-01-28 02:53:19 UTC"
  },
  {
    "arxiv_id": "2401.11143v4",
    "title": "Density Adaptive Attention is All You Need: Robust Parameter-Efficient Fine-Tuning Across Multiple Modalities",
    "authors": [
      "Georgios Ioannides",
      "Aman Chadha",
      "Aaron Elkins"
    ],
    "abstract": "We propose the Multi-Head Density Adaptive Attention Mechanism (DAAM), a\nnovel probabilistic attention framework that can be used for\nParameter-Efficient Fine-tuning (PEFT), and the Density Adaptive Transformer\n(DAT), designed to enhance information aggregation across multiple modalities,\nincluding Speech, Text, and Vision. DAAM integrates learnable mean and variance\ninto its attention mechanism, implemented in a multi-head framework, enabling\nit to collectively model any probability distribution for dynamic recalibration\nof feature significance. This method demonstrates significant improvements,\nespecially with highly non-stationary data, surpassing the state-of-the-art\nattention techniques in model performance, up to approximately +20% (abs.) in\naccuracy. Empirically, DAAM exhibits superior adaptability and efficacy across\na diverse range of tasks, including emotion recognition in speech, image\nclassification, and text classification, thereby establishing its robustness\nand versatility in handling data across multiple modalities. Furthermore, we\nintroduce the Importance Factor, a new learning-based metric that enhances the\nexplainability of models trained with DAAM-based methods.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.SD",
      "eess.AS",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.11143v4",
    "published_date": "2024-01-20 06:42:32 UTC",
    "updated_date": "2024-09-29 00:45:46 UTC"
  },
  {
    "arxiv_id": "2401.11140v1",
    "title": "Stability Plasticity Decoupled Fine-tuning For Few-shot end-to-end Object Detection",
    "authors": [
      "Yuantao Yin",
      "Ping Yin"
    ],
    "abstract": "Few-shot object detection(FSOD) aims to design methods to adapt object\ndetectors efficiently with only few annotated samples. Fine-tuning has been\nshown to be an effective and practical approach. However, previous works often\ntake the classical base-novel two stage fine-tuning procedure but ignore the\nimplicit stability-plasticity contradiction among different modules.\nSpecifically, the random re-initialized classifiers need more plasticity to\nadapt to novel samples. The other modules inheriting pre-trained weights demand\nmore stability to reserve their class-agnostic knowledge. Regular fine-tuning\nwhich couples the optimization of these two parts hurts the model\ngeneralization in FSOD scenarios. In this paper, we find that this problem is\nprominent in the end-to-end object detector Sparse R-CNN for its\nmulti-classifier cascaded architecture. We propose to mitigate this\ncontradiction by a new three-stage fine-tuning procedure by introducing an\naddtional plasticity classifier fine-tuning(PCF) stage. We further design the\nmulti-source ensemble(ME) technique to enhance the generalization of the model\nin the final fine-tuning stage. Extensive experiments verify that our method is\neffective in regularizing Sparse R-CNN, outperforming previous methods in the\nFSOD benchmark.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.11140v1",
    "published_date": "2024-01-20 06:31:30 UTC",
    "updated_date": "2024-01-20 06:31:30 UTC"
  },
  {
    "arxiv_id": "2402.04880v2",
    "title": "Combining Cloud and Mobile Computing for Machine Learning",
    "authors": [
      "Ruiqi Xu",
      "Tianchi Zhang"
    ],
    "abstract": "Although the computing power of mobile devices is increasing, machine\nlearning models are also growing in size. This trend creates problems for\nmobile devices due to limitations like their memory capacity and battery life.\nWhile many services, like ChatGPT and Midjourney, run all the inferences in the\ncloud, we believe a flexible and fine-grained task distribution is more\ndesirable. In this work, we consider model segmentation as a solution to\nimproving the user experience, dividing the computation between mobile devices\nand the cloud in a way that offloads the compute-heavy portion of the model\nwhile minimizing the data transfer required. We show that the division not only\nreduces the wait time for users but can also be fine-tuned to optimize the\nworkloads of the cloud. To achieve that, we design a scheduler that collects\ninformation about network quality, client device capability, and job\nrequirements, making decisions to achieve consistent performance across a range\nof devices while reducing the work the cloud needs to perform.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.DC",
    "comment": "Ruiqi Xu and Tianchi Zhang contributed equally to this work",
    "pdf_url": "http://arxiv.org/pdf/2402.04880v2",
    "published_date": "2024-01-20 06:14:22 UTC",
    "updated_date": "2024-02-23 22:17:22 UTC"
  },
  {
    "arxiv_id": "2402.00041v1",
    "title": "Spatial-temporal-demand clustering for solving large-scale vehicle routing problems with time windows",
    "authors": [
      "Christoph Kerscher",
      "Stefan Minner"
    ],
    "abstract": "Several metaheuristics use decomposition and pruning strategies to solve\nlarge-scale instances of the vehicle routing problem (VRP). Those complexity\nreduction techniques often rely on simple, problem-specific rules. However, the\ngrowth in available data and advances in computer hardware enable data-based\napproaches that use machine learning (ML) to improve scalability of solution\nalgorithms. We propose a decompose-route-improve (DRI) framework that groups\ncustomers using clustering. Its similarity metric incorporates customers'\nspatial, temporal, and demand data and is formulated to reflect the problem's\nobjective function and constraints. The resulting sub-routing problems can\nindependently be solved using any suitable algorithm. We apply pruned local\nsearch (LS) between solved subproblems to improve the overall solution. Pruning\nis based on customers' similarity information obtained in the decomposition\nphase. In a computational study, we parameterize and compare existing\nclustering algorithms and benchmark the DRI against the Hybrid Genetic Search\n(HGS) of Vidal et al. (2013). Results show that our data-based approach\noutperforms classic cluster-first, route-second approaches solely based on\ncustomers' spatial information. The newly introduced similarity metric forms\nseparate sub-VRPs and improves the selection of LS moves in the improvement\nphase. Thus, the DRI scales existing metaheuristics to achieve high-quality\nsolutions faster for large-scale VRPs by efficiently reducing complexity.\nFurther, the DRI can be easily adapted to various solution methods and VRP\ncharacteristics, such as distribution of customer locations and demands, depot\nlocation, and different time window scenarios, making it a generalizable\napproach to solving routing problems.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.NE",
      "math.OC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.00041v1",
    "published_date": "2024-01-20 06:06:01 UTC",
    "updated_date": "2024-01-20 06:06:01 UTC"
  },
  {
    "arxiv_id": "2401.11120v2",
    "title": "Enhancing Large Language Models for Clinical Decision Support by Incorporating Clinical Practice Guidelines",
    "authors": [
      "David Oniani",
      "Xizhi Wu",
      "Shyam Visweswaran",
      "Sumit Kapoor",
      "Shravan Kooragayalu",
      "Katelyn Polanska",
      "Yanshan Wang"
    ],
    "abstract": "Background Large Language Models (LLMs), enhanced with Clinical Practice\nGuidelines (CPGs), can significantly improve Clinical Decision Support (CDS).\nHowever, methods for incorporating CPGs into LLMs are not well studied. Methods\nWe develop three distinct methods for incorporating CPGs into LLMs: Binary\nDecision Tree (BDT), Program-Aided Graph Construction (PAGC), and\nChain-of-Thought-Few-Shot Prompting (CoT-FSP). To evaluate the effectiveness of\nthe proposed methods, we create a set of synthetic patient descriptions and\nconduct both automatic and human evaluation of the responses generated by four\nLLMs: GPT-4, GPT-3.5 Turbo, LLaMA, and PaLM 2. Zero-Shot Prompting (ZSP) was\nused as the baseline method. We focus on CDS for COVID-19 outpatient treatment\nas the case study. Results All four LLMs exhibit improved performance when\nenhanced with CPGs compared to the baseline ZSP. BDT outperformed both CoT-FSP\nand PAGC in automatic evaluation. All of the proposed methods demonstrated high\nperformance in human evaluation. Conclusion LLMs enhanced with CPGs demonstrate\nsuperior performance, as compared to plain LLMs with ZSP, in providing accurate\nrecommendations for COVID-19 outpatient treatment, which also highlights the\npotential for broader applications beyond the case study.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.11120v2",
    "published_date": "2024-01-20 05:10:46 UTC",
    "updated_date": "2024-01-23 19:43:06 UTC"
  },
  {
    "arxiv_id": "2401.13697v1",
    "title": "Toward Robust Multimodal Learning using Multimodal Foundational Models",
    "authors": [
      "Xianbing Zhao",
      "Soujanya Poria",
      "Xuejiao Li",
      "Yixin Chen",
      "Buzhou Tang"
    ],
    "abstract": "Existing multimodal sentiment analysis tasks are highly rely on the\nassumption that the training and test sets are complete multimodal data, while\nthis assumption can be difficult to hold: the multimodal data are often\nincomplete in real-world scenarios. Therefore, a robust multimodal model in\nscenarios with randomly missing modalities is highly preferred. Recently,\nCLIP-based multimodal foundational models have demonstrated impressive\nperformance on numerous multimodal tasks by learning the aligned cross-modal\nsemantics of image and text pairs, but the multimodal foundational models are\nalso unable to directly address scenarios involving modality absence. To\nalleviate this issue, we propose a simple and effective framework, namely TRML,\nToward Robust Multimodal Learning using Multimodal Foundational Models. TRML\nemploys generated virtual modalities to replace missing modalities, and aligns\nthe semantic spaces between the generated and missing modalities. Concretely,\nwe design a missing modality inference module to generate virtual modaliites\nand replace missing modalities. We also design a semantic matching learning\nmodule to align semantic spaces generated and missing modalities. Under the\nprompt of complete modality, our model captures the semantics of missing\nmodalities by leveraging the aligned cross-modal semantic space. Experiments\ndemonstrate the superiority of our approach on three multimodal sentiment\nanalysis benchmark datasets, CMU-MOSI, CMU-MOSEI, and MELD.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "Under Review",
    "pdf_url": "http://arxiv.org/pdf/2401.13697v1",
    "published_date": "2024-01-20 04:46:43 UTC",
    "updated_date": "2024-01-20 04:46:43 UTC"
  },
  {
    "arxiv_id": "2401.11113v2",
    "title": "SleepNet: Attention-Enhanced Robust Sleep Prediction using Dynamic Social Networks",
    "authors": [
      "Maryam Khalid",
      "Elizabeth B. Klerman",
      "Andrew W. Mchill",
      "Andrew J. K. Phillips",
      "Akane Sano"
    ],
    "abstract": "Sleep behavior significantly impacts health and acts as an indicator of\nphysical and mental well-being. Monitoring and predicting sleep behavior with\nubiquitous sensors may therefore assist in both sleep management and tracking\nof related health conditions. While sleep behavior depends on, and is reflected\nin the physiology of a person, it is also impacted by external factors such as\ndigital media usage, social network contagion, and the surrounding weather. In\nthis work, we propose SleepNet, a system that exploits social contagion in\nsleep behavior through graph networks and integrates it with physiological and\nphone data extracted from ubiquitous mobile and wearable devices for predicting\nnext-day sleep labels about sleep duration. Our architecture overcomes the\nlimitations of large-scale graphs containing connections irrelevant to sleep\nbehavior by devising an attention mechanism. The extensive experimental\nevaluation highlights the improvement provided by incorporating social networks\nin the model. Additionally, we conduct robustness analysis to demonstrate the\nsystem's performance in real-life conditions. The outcomes affirm the stability\nof SleepNet against perturbations in input data. Further analyses emphasize the\nsignificance of network topology in prediction performance revealing that users\nwith higher eigenvalue centrality are more vulnerable to data perturbations.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SI",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted for publication in Proceedings of the ACM on Interactive,\n  Mobile, Wearable and Ubiquitous Technologies (IMWUT), 8 (March 2024)",
    "pdf_url": "http://arxiv.org/pdf/2401.11113v2",
    "published_date": "2024-01-20 04:38:34 UTC",
    "updated_date": "2024-01-27 02:05:41 UTC"
  },
  {
    "arxiv_id": "2401.12998v1",
    "title": "Evaluating and Enhancing Large Language Models Performance in Domain-specific Medicine: Osteoarthritis Management with DocOA",
    "authors": [
      "Xi Chen",
      "MingKe You",
      "Li Wang",
      "WeiZhi Liu",
      "Yu Fu",
      "Jie Xu",
      "Shaoting Zhang",
      "Gang Chen",
      "Kang Li",
      "Jian Li"
    ],
    "abstract": "The efficacy of large language models (LLMs) in domain-specific medicine,\nparticularly for managing complex diseases such as osteoarthritis (OA), remains\nlargely unexplored. This study focused on evaluating and enhancing the clinical\ncapabilities of LLMs in specific domains, using osteoarthritis (OA) management\nas a case study. A domain specific benchmark framework was developed, which\nevaluate LLMs across a spectrum from domain-specific knowledge to clinical\napplications in real-world clinical scenarios. DocOA, a specialized LLM\ntailored for OA management that integrates retrieval-augmented generation (RAG)\nand instruction prompts, was developed. The study compared the performance of\nGPT-3.5, GPT-4, and a specialized assistant, DocOA, using objective and human\nevaluations. Results showed that general LLMs like GPT-3.5 and GPT-4 were less\neffective in the specialized domain of OA management, particularly in providing\npersonalized treatment recommendations. However, DocOA showed significant\nimprovements. This study introduces a novel benchmark framework which assesses\nthe domain-specific abilities of LLMs in multiple aspects, highlights the\nlimitations of generalized LLMs in clinical contexts, and demonstrates the\npotential of tailored approaches for developing domain-specific medical LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "16 Pages, 7 Figures",
    "pdf_url": "http://arxiv.org/pdf/2401.12998v1",
    "published_date": "2024-01-20 03:41:23 UTC",
    "updated_date": "2024-01-20 03:41:23 UTC"
  },
  {
    "arxiv_id": "2401.11094v1",
    "title": "TypeDance: Creating Semantic Typographic Logos from Image through Personalized Generation",
    "authors": [
      "Shishi Xiao",
      "Liangwei Wang",
      "Xiaojuan Ma",
      "Wei Zeng"
    ],
    "abstract": "Semantic typographic logos harmoniously blend typeface and imagery to\nrepresent semantic concepts while maintaining legibility. Conventional methods\nusing spatial composition and shape substitution are hindered by the\nconflicting requirement for achieving seamless spatial fusion between\ngeometrically dissimilar typefaces and semantics. While recent advances made AI\ngeneration of semantic typography possible, the end-to-end approaches exclude\ndesigner involvement and disregard personalized design. This paper presents\nTypeDance, an AI-assisted tool incorporating design rationales with the\ngenerative model for personalized semantic typographic logo design. It\nleverages combinable design priors extracted from uploaded image exemplars and\nsupports type-imagery mapping at various structural granularity, achieving\ndiverse aesthetic designs with flexible control. Additionally, we instantiate a\ncomprehensive design workflow in TypeDance, including ideation, selection,\ngeneration, evaluation, and iteration. A two-task user evaluation, including\nimitation and creation, confirmed the usability of TypeDance in design across\ndifferent usage scenarios",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "24 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2401.11094v1",
    "published_date": "2024-01-20 02:55:11 UTC",
    "updated_date": "2024-01-20 02:55:11 UTC"
  },
  {
    "arxiv_id": "2401.11089v1",
    "title": "FedRKG: A Privacy-preserving Federated Recommendation Framework via Knowledge Graph Enhancement",
    "authors": [
      "Dezhong Yao",
      "Tongtong Liu",
      "Qi Cao",
      "Hai Jin"
    ],
    "abstract": "Federated Learning (FL) has emerged as a promising approach for preserving\ndata privacy in recommendation systems by training models locally. Recently,\nGraph Neural Networks (GNN) have gained popularity in recommendation tasks due\nto their ability to capture high-order interactions between users and items.\nHowever, privacy concerns prevent the global sharing of the entire user-item\ngraph. To address this limitation, some methods create pseudo-interacted items\nor users in the graph to compensate for missing information for each client.\nUnfortunately, these methods introduce random noise and raise privacy concerns.\nIn this paper, we propose FedRKG, a novel federated recommendation system,\nwhere a global knowledge graph (KG) is constructed and maintained on the server\nusing publicly available item information, enabling higher-order user-item\ninteractions. On the client side, a relation-aware GNN model leverages diverse\nKG relationships. To protect local interaction items and obscure gradients, we\nemploy pseudo-labeling and Local Differential Privacy (LDP). Extensive\nexperiments conducted on three real-world datasets demonstrate the competitive\nperformance of our approach compared to centralized algorithms while ensuring\nprivacy preservation. Moreover, FedRKG achieves an average accuracy improvement\nof 4% compared to existing federated learning baselines.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.DC",
      "cs.IR"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.11089v1",
    "published_date": "2024-01-20 02:38:21 UTC",
    "updated_date": "2024-01-20 02:38:21 UTC"
  },
  {
    "arxiv_id": "2401.11085v1",
    "title": "Adaptive Global-Local Representation Learning and Selection for Cross-Domain Facial Expression Recognition",
    "authors": [
      "Yuefang Gao",
      "Yuhao Xie",
      "Zeke Zexi Hu",
      "Tianshui Chen",
      "Liang Lin"
    ],
    "abstract": "Domain shift poses a significant challenge in Cross-Domain Facial Expression\nRecognition (CD-FER) due to the distribution variation across different\ndomains. Current works mainly focus on learning domain-invariant features\nthrough global feature adaptation, while neglecting the transferability of\nlocal features. Additionally, these methods lack discriminative supervision\nduring training on target datasets, resulting in deteriorated feature\nrepresentation in target domain. To address these limitations, we propose an\nAdaptive Global-Local Representation Learning and Selection (AGLRLS) framework.\nThe framework incorporates global-local adversarial adaptation and\nsemantic-aware pseudo label generation to enhance the learning of\ndomain-invariant and discriminative feature during training. Meanwhile, a\nglobal-local prediction consistency learning is introduced to improve\nclassification results during inference. Specifically, the framework consists\nof separate global-local adversarial learning modules that learn\ndomain-invariant global and local features independently. We also design a\nsemantic-aware pseudo label generation module, which computes semantic labels\nbased on global and local features. Moreover, a novel dynamic threshold\nstrategy is employed to learn the optimal thresholds by leveraging independent\nprediction of global and local features, ensuring filtering out the unreliable\npseudo labels while retaining reliable ones. These labels are utilized for\nmodel optimization through the adversarial learning process in an end-to-end\nmanner. During inference, a global-local prediction consistency module is\ndeveloped to automatically learn an optimal result from multiple predictions.\nWe conduct comprehensive experiments and analysis based on a fair evaluation\nbenchmark. The results demonstrate that the proposed framework outperforms the\ncurrent competing methods by a substantial margin.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.11085v1",
    "published_date": "2024-01-20 02:21:41 UTC",
    "updated_date": "2024-01-20 02:21:41 UTC"
  },
  {
    "arxiv_id": "2401.11081v1",
    "title": "Learning from Aggregate responses: Instance Level versus Bag Level Loss Functions",
    "authors": [
      "Adel Javanmard",
      "Lin Chen",
      "Vahab Mirrokni",
      "Ashwinkumar Badanidiyuru",
      "Gang Fu"
    ],
    "abstract": "Due to the rise of privacy concerns, in many practical applications the\ntraining data is aggregated before being shared with the learner, in order to\nprotect privacy of users' sensitive responses. In an aggregate learning\nframework, the dataset is grouped into bags of samples, where each bag is\navailable only with an aggregate response, providing a summary of individuals'\nresponses in that bag. In this paper, we study two natural loss functions for\nlearning from aggregate responses: bag-level loss and the instance-level loss.\nIn the former, the model is learnt by minimizing a loss between aggregate\nresponses and aggregate model predictions, while in the latter the model aims\nto fit individual predictions to the aggregate responses. In this work, we show\nthat the instance-level loss can be perceived as a regularized form of the\nbag-level loss. This observation lets us compare the two approaches with\nrespect to bias and variance of the resulting estimators, and introduce a novel\ninterpolating estimator which combines the two approaches. For linear\nregression tasks, we provide a precise characterization of the risk of the\ninterpolating estimator in an asymptotic regime where the size of the training\nset grows in proportion to the features dimension. Our analysis allows us to\ntheoretically understand the effect of different factors, such as bag size on\nthe model prediction risk. In addition, we propose a mechanism for\ndifferentially private learning from aggregate responses and derive the optimal\nbag size in terms of prediction risk-privacy trade-off. We also carry out\nthorough experiments to corroborate our theory and show the efficacy of the\ninterpolating estimator.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.ST",
      "stat.ML",
      "stat.TH"
    ],
    "primary_category": "cs.LG",
    "comment": "To appear in the Twelfth International Conference on Learning\n  Representations (ICLR 2024)",
    "pdf_url": "http://arxiv.org/pdf/2401.11081v1",
    "published_date": "2024-01-20 02:14:11 UTC",
    "updated_date": "2024-01-20 02:14:11 UTC"
  },
  {
    "arxiv_id": "2402.04882v1",
    "title": "LMUFormer: Low Complexity Yet Powerful Spiking Model With Legendre Memory Units",
    "authors": [
      "Zeyu Liu",
      "Gourav Datta",
      "Anni Li",
      "Peter Anthony Beerel"
    ],
    "abstract": "Transformer models have demonstrated high accuracy in numerous applications\nbut have high complexity and lack sequential processing capability making them\nill-suited for many streaming applications at the edge where devices are\nheavily resource-constrained. Thus motivated, many researchers have proposed\nreformulating the transformer models as RNN modules which modify the\nself-attention computation with explicit states. However, these approaches\noften incur significant performance degradation. The ultimate goal is to\ndevelop a model that has the following properties: parallel training, streaming\nand low-cost inference, and SOTA performance. In this paper, we propose a new\ndirection to achieve this goal. We show how architectural modifications to a\nrecurrent model can help push its performance toward Transformer models while\nretaining its sequential processing capability. Specifically, inspired by the\nrecent success of Legendre Memory Units (LMU) in sequence learning tasks, we\npropose LMUFormer, which augments the LMU with convolutional patch embedding\nand convolutional channel mixer. Moreover, we present a spiking version of this\narchitecture, which introduces the benefit of states within the patch embedding\nand channel mixer modules while simultaneously reducing the computing\ncomplexity. We evaluated our architectures on multiple sequence datasets. In\ncomparison to SOTA transformer-based models within the ANN domain on the SCv2\ndataset, our LMUFormer demonstrates comparable performance while necessitating\na remarkable 53 times reduction in parameters and a substantial 65 times\ndecrement in FLOPs. Additionally, owing to our model's proficiency in real-time\ndata processing, we can achieve a 32.03% reduction in sequence length, all\nwhile incurring an inconsequential decline in performance. Our code is publicly\navailable at https://github.com/zeyuliu1037/LMUFormer.git.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.NE",
    "comment": "The 12th International Conference on Learning Representations (ICLR\n  2024)",
    "pdf_url": "http://arxiv.org/pdf/2402.04882v1",
    "published_date": "2024-01-20 01:10:18 UTC",
    "updated_date": "2024-01-20 01:10:18 UTC"
  }
]