{
  "date": "2024-03-26",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-03-26 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦于 AI 模型优化、多模态学习和生成式 AI 应用等领域，强调大型语言模型（LLM）的改进（如 InternLM2 的技术报告）和实际应用（如情感识别和知识蒸馏），同时涉及图神经网络安全性和医疗图像分析等话题。令人印象深刻的文章包括 InternLM2 的开源 LLM 框架，以及 LLM 在情感和定量推理中的创新应用，这些展示了知名学者（如 Yu Qiao 和 Dahua Lin 团队）在高效 AI 模型上的进展。\n\n下面，我将挑选并简要讨论部分关键论文，先优先聊那些创新性强、可能有话题度的文章（如 LLM 和多模态模型），并快速掠过次要内容。每个条目包括论文标题（中文 + 英文）和核心贡献。\n\n### 重点论文讨论\n\n**1. InternLM2 Technical Report（中文：InternLM2 技术报告；英文：InternLM2 Technical Report）**  \n   作者包括 Yu Qiao 和 Dahua Lin 等知名学者。该论文介绍了开源 LLM InternLM2，通过创新的预训练和优化技术（如条件强化学习），在 6 个维度和 30 个基准上超越前代模型，支持长上下文建模。主要发现：在长序列任务中，InternLM2 显著提升了性能，并在多数据集上实现高效推理。\n\n**2. Oh! We Freeze: Improving Quantized Knowledge Distillation via Signal Propagation Analysis for Large Language Models（中文：Oh! We Freeze：通过信号传播分析改进大型语言模型的量化知识蒸馏；英文：Oh! We Freeze: Improving Quantized Knowledge Distillation via Signal Propagation Analysis for Large Language Models）**  \n   这篇论文提出 ov-freeze 技术，通过分析梯度传播稳定量化蒸馏过程。主要贡献：在 4-bit 量化 LLaMAv2-Chat 模型上，实现了接近浮点精度的性能，仅损失 0.7% 的准确率，适用于边缘设备部署。\n\n**3. Large Language Models Produce Responses Perceived to be Empathic（中文：大型语言模型生成被感知为有同理心的响应；英文：Large Language Models Produce Responses Perceived to be Empathic）**  \n   作者包括 Desmond C. Ong。该研究发现 LLM（如 GPT-4 Turbo）生成的响应在情感任务中被评为更具同理心。主要发现：语言分析显示模型使用独特风格（如标点和表情符号），可提升人机支持场景的同理心效果。\n\n**4. Don't Trust: Verify -- Grounding LLM Quantitative Reasoning with Autoformalization（中文：不要信任：验证——通过自动形式化提升 LLM 定量推理；英文：Don't Trust: Verify -- Grounding LLM Quantitative Reasoning with Autoformalization）**  \n   作者团队包括 Yuhuai Wu 和 Kilian Q. Weinberger（ICLR 2024）。论文引入自动形式化方法验证 LLM 的推理一致性。主要贡献：在 GSM8K 等数据集上，方法比多数投票提升 12% 的准确率，确保 LLM 输出可靠。\n\n**5. ALISA: Accelerating Large Language Model Inference via Sparsity-Aware KV Caching（中文：ALISA：通过稀疏感知 KV 缓存加速大型语言模型推理；英文：ALISA: Accelerating Large Language Model Inference via Sparsity-Aware KV Caching）**  \n   这篇论文提出稀疏感知 KV 缓存技术，优化 LLM 推理效率。主要发现：在资源受限系统中，ALISA 比基线提升 3 倍吞吐量，同时保持性能。\n\n**6. Reinforcement Learning-based Receding Horizon Control using Adaptive Control Barrier Functions for Safety-Critical Systems（中文：基于自适应控制屏障函数的强化学习再现地平线控制，用于安全关键系统；英文：Reinforcement Learning-based Receding Horizon Control using Adaptive Control Barrier Functions for Safety-Critical Systems）**  \n   论文探索强化学习在安全系统（如自动驾驶）中的应用，使用自适应控制屏障函数优化控制。主要贡献：显著减少不可行情况，提升性能，适用于复杂交通场景。\n\n其他论文如多模态主题建模（A Large Language Models for Education: A Survey and Outlook）和图像生成（AID: Attention Interpolation of Text-to-Image Diffusion）等，也展示了 AI 在教育和视觉领域的潜力，但这些相对常规，我这里仅快速提及：它们分别提供了教育 AI 综述和注意力机制改进图像插值，贡献在于扩展应用场景，但细节较少创新点。\n\n总之，今天的论文突出了 AI 模型的实用性和优化，LLM 相关工作尤其值得关注。如果你对特定领域感兴趣，可以深入这些论文！",
  "papers": [
    {
      "arxiv_id": "2403.18159v2",
      "title": "Oh! We Freeze: Improving Quantized Knowledge Distillation via Signal Propagation Analysis for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Kartikeya Bhardwaj",
        "Nilesh Prasad Pandey",
        "Sweta Priyadarshi",
        "Kyunggeun Lee",
        "Jun Ma",
        "Harris Teague"
      ],
      "abstract": "Large generative models such as large language models (LLMs) and diffusion\nmodels have revolutionized the fields of NLP and computer vision respectively.\nHowever, their slow inference, high computation and memory requirement makes it\nchallenging to deploy them on edge devices. In this study, we propose a\nlight-weight quantization aware fine tuning technique using knowledge\ndistillation (KD-QAT) to improve the performance of 4-bit weight quantized LLMs\nusing commonly available datasets to realize a popular language use case, on\ndevice chat applications. To improve this paradigm of finetuning, as main\ncontributions, we provide insights into stability of KD-QAT by empirically\nstudying the gradient propagation during training to better understand the\nvulnerabilities of KD-QAT based approaches to low-bit quantization errors.\nBased on our insights, we propose ov-freeze, a simple technique to stabilize\nthe KD-QAT process. Finally, we experiment with the popular 7B LLaMAv2-Chat\nmodel at 4-bit quantization level and demonstrate that ov-freeze results in\nnear floating point precision performance, i.e., less than 0.7% loss of\naccuracy on Commonsense Reasoning benchmarks.",
      "tldr_zh": "该研究针对大型语言模型（Large Language Models, LLMs）的部署挑战，提出了一种轻量化的量化感知微调技术（KD-QAT），利用知识蒸馏改善4位权重量化后的性能，以支持设备端聊天应用。论文通过经验分析梯度传播，揭示了KD-QAT在低位量化错误下的稳定性问题，并引入ov-freeze技术来稳定训练过程。实验结果显示，在7B LLaMAv2-Chat模型上应用ov-freeze后，4位量化性能接近浮点精度，仅在常识推理基准上损失不到0.7%的准确率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at Practical ML for Low Resource Settings Workshop at ICLR\n  2024",
      "pdf_url": "http://arxiv.org/pdf/2403.18159v2",
      "published_date": "2024-03-26 23:51:44 UTC",
      "updated_date": "2024-03-28 08:22:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:54:54.699994"
    },
    {
      "arxiv_id": "2403.18148v1",
      "title": "Large Language Models Produce Responses Perceived to be Empathic",
      "title_zh": "翻译失败",
      "authors": [
        "Yoon Kyung Lee",
        "Jina Suh",
        "Hongli Zhan",
        "Junyi Jessy Li",
        "Desmond C. Ong"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated surprising performance on many\ntasks, including writing supportive messages that display empathy. Here, we had\nthese models generate empathic messages in response to posts describing common\nlife experiences, such as workplace situations, parenting, relationships, and\nother anxiety- and anger-eliciting situations. Across two studies (N=192, 202),\nwe showed human raters a variety of responses written by several models (GPT4\nTurbo, Llama2, and Mistral), and had people rate these responses on how\nempathic they seemed to be. We found that LLM-generated responses were\nconsistently rated as more empathic than human-written responses. Linguistic\nanalyses also show that these models write in distinct, predictable ``styles\",\nin terms of their use of punctuation, emojis, and certain words. These results\nhighlight the potential of using LLMs to enhance human peer support in contexts\nwhere empathy is important.",
      "tldr_zh": "本研究发现，Large Language Models (LLMs) 生成的响应被人类评委视为比人类写的更富有同理心。研究通过两组实验（N=192 和 202），让模型如 GPT4 Turbo、Llama2 和 Mistral 生成对常见生活经历（如工作、育儿和关系问题）的回应，并进行人类评分。语言分析显示，这些模型采用独特的写作风格，包括特定标点、表情符号和词汇的使用。总体结果表明，LLMs 有潜力在需要同理心的情境中提升人类同伴支持。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.18148v1",
      "published_date": "2024-03-26 23:14:34 UTC",
      "updated_date": "2024-03-26 23:14:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:55:07.316954"
    },
    {
      "arxiv_id": "2403.18145v1",
      "title": "A Real-Time Rescheduling Algorithm for Multi-robot Plan Execution",
      "title_zh": "多机器人计划执行的实时重调度算法",
      "authors": [
        "Ying Feng",
        "Adittyo Paul",
        "Zhe Chen",
        "Jiaoyang Li"
      ],
      "abstract": "One area of research in multi-agent path finding is to determine how\nreplanning can be efficiently achieved in the case of agents being delayed\nduring execution. One option is to reschedule the passing order of agents,\ni.e., the sequence in which agents visit the same location. In response, we\npropose Switchable-Edge Search (SES), an A*-style algorithm designed to find\noptimal passing orders. We prove the optimality of SES and evaluate its\nefficiency via simulations. The best variant of SES takes less than 1 second\nfor small- and medium-sized problems and runs up to 4 times faster than\nbaselines for large-sized problems.",
      "tldr_zh": "该论文针对多机器人路径规划中的代理延迟问题，提出了一种实时重新调度算法Switchable-Edge Search (SES)，这是一个基于A*-style的算法，用于优化代理访问相同位置的通过顺序。SES算法被证明具有最优性，能够高效地重新规划代理的执行路径。通过模拟实验，最佳SES变体在小中型问题上处理时间小于1秒，并在大型问题上比基线算法快4倍，从而提升了多机器人系统的执行效率。",
      "categories": [
        "cs.AI",
        "cs.MA",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "ICAPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.18145v1",
      "published_date": "2024-03-26 23:10:41 UTC",
      "updated_date": "2024-03-26 23:10:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:55:17.374805"
    },
    {
      "arxiv_id": "2403.18140v1",
      "title": "Juru: Legal Brazilian Large Language Model from Reputable Sources",
      "title_zh": "翻译失败",
      "authors": [
        "Roseval Malaquias Junior",
        "Ramon Pires",
        "Roseli Romero",
        "Rodrigo Nogueira"
      ],
      "abstract": "The high computational cost associated with pretraining large language models\nlimits their research. Two strategies have emerged to address this issue:\ndomain specialization and pretraining with high-quality data. To explore these\nstrategies, we specialized the Sabi\\'a-2 Small model with 1.9 billion unique\ntokens from reputable Brazilian legal sources and conducted few-shot\nevaluations on legal and general knowledge exams. Our model, Juru, demonstrates\nthe benefits of domain specialization with a reduced amount of pretraining\ndata. However, this specialization comes at the expense of degrading\nperformance in other knowledge areas within the same language. This study\ncontributes to the growing body of scientific evidence showing that pretraining\ndata selection may enhance the performance of large language models, enabling\nthe exploration of these models at a lower cost.",
      "tldr_zh": "本研究开发了Juru模型，这是一个从可信巴西法律来源训练的领域专业化Large Language Model（LLM），通过对Sabiá-2 Small模型使用1.9亿独特标记的数据进行预训练，旨在降低训练成本。实验结果显示，Juru在法律知识考试的few-shot评估中表现出色，但这导致了同一语言中其他知识领域的性能下降。该研究证明了预训练数据选择的策略可以提升LLM的特定领域表现，同时为低成本模型探索提供科学依据。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.18140v1",
      "published_date": "2024-03-26 22:54:12 UTC",
      "updated_date": "2024-03-26 22:54:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:55:29.597694"
    },
    {
      "arxiv_id": "2403.18136v2",
      "title": "Identifying Backdoored Graphs in Graph Neural Network Training: An Explanation-Based Approach with Novel Metrics",
      "title_zh": "翻译失败",
      "authors": [
        "Jane Downer",
        "Ren Wang",
        "Binghui Wang"
      ],
      "abstract": "Graph Neural Networks (GNNs) have gained popularity in numerous domains, yet\nthey are vulnerable to backdoor attacks that can compromise their performance\nand ethical application. The detection of these attacks is crucial for\nmaintaining the reliability and security of GNN classification tasks, but\neffective detection techniques are lacking. Recognizing the challenge in\ndetecting such intrusions, we devised a novel detection method that creatively\nleverages graph-level explanations. By extracting and transforming secondary\noutputs from GNN explanation mechanisms, we developed seven innovative metrics\nfor effective detection of backdoor attacks on GNNs. Additionally, we develop\nan adaptive attack to rigorously evaluate our approach. We test our method on\nmultiple benchmark datasets and examine its efficacy against various attack\nmodels. Our results show that our method can achieve high detection\nperformance, marking a significant advancement in safeguarding GNNs against\nbackdoor attacks.",
      "tldr_zh": "该研究针对图神经网络(GNNs)易受后门攻击(backdoor attacks)的影响，提出了一种基于解释机制的检测方法，通过提取和转换GNN解释的次级输出，开发了七个创新指标来识别后门图。论文还设计了一个自适应攻击用于评估该方法的鲁棒性，并在多个基准数据集上进行了测试，对抗各种攻击模型。结果显示，该方法实现了高检测性能，显著提升了GNNs的安全性和可靠性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.18136v2",
      "published_date": "2024-03-26 22:41:41 UTC",
      "updated_date": "2024-11-12 06:21:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:55:42.246355"
    },
    {
      "arxiv_id": "2403.18133v1",
      "title": "AE SemRL: Learning Semantic Association Rules with Autoencoders",
      "title_zh": "AE SemRL：利用自编码器学习语义关联规则",
      "authors": [
        "Erkan Karabulut",
        "Victoria Degeler",
        "Paul Groth"
      ],
      "abstract": "Association Rule Mining (ARM) is the task of learning associations among data\nfeatures in the form of logical rules. Mining association rules from\nhigh-dimensional numerical data, for example, time series data from a large\nnumber of sensors in a smart environment, is a computationally intensive task.\nIn this study, we propose an Autoencoder-based approach to learn and extract\nassociation rules from time series data (AE SemRL). Moreover, we argue that in\nthe presence of semantic information related to time series data sources,\nsemantics can facilitate learning generalizable and explainable association\nrules. Despite enriching time series data with additional semantic features, AE\nSemRL makes learning association rules from high-dimensional data feasible. Our\nexperiments show that semantic association rules can be extracted from a latent\nrepresentation created by an Autoencoder and this method has in the order of\nhundreds of times faster execution time than state-of-the-art ARM approaches in\nmany scenarios. We believe that this study advances a new way of extracting\nassociations from representations and has the potential to inspire more\nresearch in this field.",
      "tldr_zh": "本研究提出了一种基于 Autoencoder 的方法 AE SemRL，用于从高维时序数据中学习和提取语义关联规则（Association Rule Mining, ARM），以解决传统方法计算密集的问题。该方法利用 Autoencoder 的潜在表示结合时序数据的语义信息，帮助生成更通用和可解释的关联规则，即使数据维度增加也能高效处理。实验结果显示，AE SemRL 在许多场景下比现有 ARM 方法快数百倍，并从潜在表示中成功提取语义规则，为关联规则挖掘领域开辟了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.18133v1",
      "published_date": "2024-03-26 22:28:43 UTC",
      "updated_date": "2024-03-26 22:28:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:55:52.787568"
    },
    {
      "arxiv_id": "2403.18132v1",
      "title": "Recommendation of data-free class-incremental learning algorithms by simulating future data",
      "title_zh": "通过模拟未来数据",
      "authors": [
        "Eva Feillet",
        "Adrian Popescu",
        "Céline Hudelot"
      ],
      "abstract": "Class-incremental learning deals with sequential data streams composed of\nbatches of classes. Various algorithms have been proposed to address the\nchallenging case where samples from past classes cannot be stored. However,\nselecting an appropriate algorithm for a user-defined setting is an open\nproblem, as the relative performance of these algorithms depends on the\nincremental settings. To solve this problem, we introduce an algorithm\nrecommendation method that simulates the future data stream. Given an initial\nset of classes, it leverages generative models to simulate future classes from\nthe same visual domain. We evaluate recent algorithms on the simulated stream\nand recommend the one which performs best in the user-defined incremental\nsetting. We illustrate the effectiveness of our method on three large datasets\nusing six algorithms and six incremental settings. Our method outperforms\ncompetitive baselines, and performance is close to that of an oracle choosing\nthe best algorithm in each setting. This work contributes to facilitate the\npractical deployment of incremental learning.",
      "tldr_zh": "该论文针对类增量学习(class-incremental learning)中算法选择的难题，提出了一种推荐方法，通过模拟未来数据流来为用户特定设置选择最佳算法。方法利用生成模型(generative models)从初始类样本中模拟同一视觉域的未来类，然后在模拟数据上评估多个算法，并推荐表现最优的那个。实验在三个大型数据集上使用六个算法和六个增量设置进行验证，结果显示该方法优于竞争基线，性能接近于理想的预言机(oracle)，有助于推动增量学习的实际部署。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.18132v1",
      "published_date": "2024-03-26 22:26:39 UTC",
      "updated_date": "2024-03-26 22:26:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:56:06.006599"
    },
    {
      "arxiv_id": "2403.18120v1",
      "title": "Don't Trust: Verify -- Grounding LLM Quantitative Reasoning with Autoformalization",
      "title_zh": "翻译失败",
      "authors": [
        "Jin Peng Zhou",
        "Charles Staats",
        "Wenda Li",
        "Christian Szegedy",
        "Kilian Q. Weinberger",
        "Yuhuai Wu"
      ],
      "abstract": "Large language models (LLM), such as Google's Minerva and OpenAI's GPT\nfamilies, are becoming increasingly capable of solving mathematical\nquantitative reasoning problems. However, they still make unjustified logical\nand computational errors in their reasoning steps and answers. In this paper,\nwe leverage the fact that if the training corpus of LLMs contained sufficiently\nmany examples of formal mathematics (e.g. in Isabelle, a formal theorem proving\nenvironment), they can be prompted to translate i.e. autoformalize informal\nmathematical statements into formal Isabelle code -- which can be verified\nautomatically for internal consistency. This provides a mechanism to\nautomatically reject solutions whose formalized versions are inconsistent\nwithin themselves or with the formalized problem statement. We evaluate our\nmethod on GSM8K, MATH and MultiArith datasets and demonstrate that our approach\nprovides a consistently better heuristic than vanilla majority voting -- the\npreviously best method to identify correct answers, by more than 12% on GSM8K.\nIn our experiments it improves results consistently across all datasets and LLM\nmodel sizes. The code can be found at https://github.com/jinpz/dtv.",
      "tldr_zh": "这篇论文针对大型语言模型(LLMs)如Minerva和GPT系列在数学定量推理中出现的逻辑和计算错误，提出了一种基于自动形式化(autoformalization)的验证方法。方法利用LLMs的训练语料中形式化数学示例（如Isabelle环境），通过提示将非正式数学语句转化为可自动验证的形式化代码，以检查内部一致性并拒绝不一致的解决方案。在GSM8K、MATH和MultiArith数据集上的实验显示，该方法比传统的多数投票提高了超过12%的准确率，并在所有数据集和模型大小上均表现出一致改善，为更可靠的LLM推理提供了新机制。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "ICLR 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.18120v1",
      "published_date": "2024-03-26 22:01:13 UTC",
      "updated_date": "2024-03-26 22:01:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:56:19.480070"
    },
    {
      "arxiv_id": "2403.18116v1",
      "title": "QuakeSet: A Dataset and Low-Resource Models to Monitor Earthquakes through Sentinel-1",
      "title_zh": "翻译失败",
      "authors": [
        "Daniele Rege Cambrin",
        "Paolo Garza"
      ],
      "abstract": "Earthquake monitoring is necessary to promptly identify the affected areas,\nthe severity of the events, and, finally, to estimate damages and plan the\nactions needed for the restoration process. The use of seismic stations to\nmonitor the strength and origin of earthquakes is limited when dealing with\nremote areas (we cannot have global capillary coverage). Identification and\nanalysis of all affected areas is mandatory to support areas not monitored by\ntraditional stations. Using social media images in crisis management has proven\neffective in various situations. However, they are still limited by the\npossibility of using communication infrastructures in case of an earthquake and\nby the presence of people in the area. Moreover, social media images and\nmessages cannot be used to estimate the actual severity of earthquakes and\ntheir characteristics effectively. The employment of satellites to monitor\nchanges around the globe grants the possibility of exploiting instrumentation\nthat is not limited by the visible spectrum, the presence of land\ninfrastructures, and people in the affected areas. In this work, we propose a\nnew dataset composed of images taken from Sentinel-1 and a new series of tasks\nto help monitor earthquakes from a new detailed view. Coupled with the data, we\nprovide a series of traditional machine learning and deep learning models as\nbaselines to assess the effectiveness of ML-based models in earthquake\nanalysis.",
      "tldr_zh": "本文提出QuakeSet数据集，利用Sentinel-1卫星图像来监测地震，提供了一个新的详细视角，以弥补传统地震站和社交媒体图像的局限性。该数据集针对地震监测定义了一系列新任务，包括识别受影响区域和评估事件严重程度。作者还提供了传统机器学习和深度学习基线模型，评估这些低资源模型在地震分析中的有效性，旨在支持全球范围内的灾害响应和恢复规划。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at ISCRAM 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.18116v1",
      "published_date": "2024-03-26 21:45:29 UTC",
      "updated_date": "2024-03-26 21:45:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:56:28.729745"
    },
    {
      "arxiv_id": "2403.18105v2",
      "title": "Large Language Models for Education: A Survey and Outlook",
      "title_zh": "翻译失败",
      "authors": [
        "Shen Wang",
        "Tianlong Xu",
        "Hang Li",
        "Chaoli Zhang",
        "Joleen Liang",
        "Jiliang Tang",
        "Philip S. Yu",
        "Qingsong Wen"
      ],
      "abstract": "The advent of Large Language Models (LLMs) has brought in a new era of\npossibilities in the realm of education. This survey paper summarizes the\nvarious technologies of LLMs in educational settings from multifaceted\nperspectives, encompassing student and teacher assistance, adaptive learning,\nand commercial tools. We systematically review the technological advancements\nin each perspective, organize related datasets and benchmarks, and identify the\nrisks and challenges associated with deploying LLMs in education. Furthermore,\nwe outline future research opportunities, highlighting the potential promising\ndirections. Our survey aims to provide a comprehensive technological picture\nfor educators, researchers, and policymakers to harness the power of LLMs to\nrevolutionize educational practices and foster a more effective personalized\nlearning environment.",
      "tldr_zh": "这篇调查论文总结了大语言模型（LLMs）在教育领域的应用，包括学生和教师辅助、适应性学习以及商业工具等方面。作者系统回顾了相关技术进展，组织了数据集和基准，并分析了部署 LLMs 在教育中的风险和挑战，如潜在的伦理和实际问题。论文还概述了未来的研究机会，强调 LLMs 有望革新教育实践，推动更有效的个性化学习环境。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.18105v2",
      "published_date": "2024-03-26 21:04:29 UTC",
      "updated_date": "2024-04-01 18:47:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:56:41.937759"
    },
    {
      "arxiv_id": "2403.18101v1",
      "title": "Towards Explainable Clustering: A Constrained Declarative based Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Mathieu Guilbert",
        "Christel Vrain",
        "Thi-Bich-Hanh Dao"
      ],
      "abstract": "The domain of explainable AI is of interest in all Machine Learning fields,\nand it is all the more important in clustering, an unsupervised task whose\nresult must be validated by a domain expert. We aim at finding a clustering\nthat has high quality in terms of classic clustering criteria and that is\nexplainable, and we argue that these two dimensions must be considered when\nbuilding the clustering. We consider that a good global explanation of a\nclustering should give the characteristics of each cluster taking into account\ntheir abilities to describe its objects (coverage) while distinguishing it from\nthe other clusters (discrimination). Furthermore, we aim at leveraging expert\nknowledge, at different levels, on the structure of the expected clustering or\non its explanations. In our framework an explanation of a cluster is a set of\npatterns, and we propose a novel interpretable constrained clustering method\ncalled ECS for declarative clustering with Explainabilty-driven Cluster\nSelection that integrates structural or domain expert knowledge expressed by\nmeans of constraints. It is based on the notion of coverage and discrimination\nthat are formalized at different levels (cluster / clustering), each allowing\nfor exceptions through parameterized thresholds. Our method relies on four\nsteps: generation of a set of partitions, computation of frequent patterns for\neach cluster, pruning clusters that violates some constraints, and selection of\nclusters and associated patterns to build an interpretable clustering. This\nlast step is combinatorial and we have developed a Constraint-Programming (CP)\nmodel to solve it. The method can integrate prior knowledge in the form of user\nconstraints, both before or in the CP model.",
      "tldr_zh": "这篇论文针对可解释 AI 在聚类领域的应用，提出了一种基于约束声明式方法的 ECS（declarative clustering with Explainability-driven Cluster Selection）方法，以同时优化聚类的质量和可解释性。方法强调每个聚类的特征需兼顾 coverage（覆盖率）和 discrimination（区分度），并允许通过约束整合专家知识，如对聚类结构或解释的先验信息。ECS 包括四个步骤：生成分区集、计算每个聚类的频繁模式、修剪违反约束的聚类，以及使用 Constraint-Programming (CP) 模型进行最终聚类选择，从而构建可解释的聚类结果。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.18101v1",
      "published_date": "2024-03-26 21:00:06 UTC",
      "updated_date": "2024-03-26 21:00:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:56:56.611412"
    },
    {
      "arxiv_id": "2403.18100v1",
      "title": "Driving Intelligent IoT Monitoring and Control through Cloud Computing and Machine Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Hanzhe Li",
        "Xiangxiang Wang",
        "Yuan Feng",
        "Yaqian Qi",
        "Jingxiao Tian"
      ],
      "abstract": "This article explores how to drive intelligent iot monitoring and control\nthrough cloud computing and machine learning. As iot and the cloud continue to\ngenerate large and diverse amounts of data as sensor devices in the network,\nthe collected data is sent to the cloud for statistical analysis, prediction,\nand data analysis to achieve business objectives. However, because the cloud\ncomputing model is limited by distance, it can be problematic in environments\nwhere the quality of the Internet connection is not ideal for critical\noperations. Therefore, edge computing, as a distributed computing architecture,\nmoves the location of processing applications, data and services from the\ncentral node of the network to the logical edge node of the network to reduce\nthe dependence on cloud processing and analysis of data, and achieve near-end\ndata processing and analysis. The combination of iot and edge computing can\nreduce latency, improve efficiency, and enhance security, thereby driving the\ndevelopment of intelligent systems. The paper also introduces the development\nof iot monitoring and control technology, the application of edge computing in\niot monitoring and control, and the role of machine learning in data analysis\nand fault detection. Finally, the application and effect of intelligent\nInternet of Things monitoring and control system in industry, agriculture,\nmedical and other fields are demonstrated through practical cases and\nexperimental studies.",
      "tldr_zh": "这篇论文探讨了通过云 computing 和 machine learning 驱动智能 IoT 监控和控制的方式，强调了 IoT 设备生成的大量数据如何通过云端进行分析和预测，但受限于网络距离和连接质量。论文提出引入 edge computing 作为分布式架构，将数据处理从云端移至网络边缘，以减少延迟、提升效率并增强安全，从而优化 IoT 系统。最终，通过实际案例和实验，展示了该智能监控系统在工业、农业和医疗等领域中的应用效果和益处。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.18100v1",
      "published_date": "2024-03-26 20:59:48 UTC",
      "updated_date": "2024-03-26 20:59:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:57:07.582453"
    },
    {
      "arxiv_id": "2403.18098v1",
      "title": "GPTs and Language Barrier: A Cross-Lingual Legal QA Examination",
      "title_zh": "翻译失败",
      "authors": [
        "Ha-Thanh Nguyen",
        "Hiroaki Yamada",
        "Ken Satoh"
      ],
      "abstract": "In this paper, we explore the application of Generative Pre-trained\nTransformers (GPTs) in cross-lingual legal Question-Answering (QA) systems\nusing the COLIEE Task 4 dataset. In the COLIEE Task 4, given a statement and a\nset of related legal articles that serve as context, the objective is to\ndetermine whether the statement is legally valid, i.e., if it can be inferred\nfrom the provided contextual articles or not, which is also known as an\nentailment task. By benchmarking four different combinations of English and\nJapanese prompts and data, we provide valuable insights into GPTs' performance\nin multilingual legal QA scenarios, contributing to the development of more\nefficient and accurate cross-lingual QA solutions in the legal domain.",
      "tldr_zh": "本文探讨了生成式预训练 transformer (GPTs) 在跨语言法律问答 (QA) 系统中的应用，特别使用 COLIEE Task 4 数据集进行基准测试。该任务涉及判断给定语句是否能从相关法律文章中推断出来，即一个蕴含任务 (entailment task)，并测试了四种英语和日语提示及数据的组合。结果提供了 GPTs 在多语言法律 QA 场景中性能的宝贵见解，有助于推动更高效、准确的跨语言 QA 解决方案在法律领域的开发。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "NLP 2024, Kobe, Japan",
      "pdf_url": "http://arxiv.org/pdf/2403.18098v1",
      "published_date": "2024-03-26 20:47:32 UTC",
      "updated_date": "2024-03-26 20:47:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:57:20.622008"
    },
    {
      "arxiv_id": "2403.18093v1",
      "title": "Enhancing Legal Document Retrieval: A Multi-Phase Approach with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Hai-Long Nguyen",
        "Duc-Minh Nguyen",
        "Tan-Minh Nguyen",
        "Ha-Thanh Nguyen",
        "Thi-Hai-Yen Vuong",
        "Ken Satoh"
      ],
      "abstract": "Large language models with billions of parameters, such as GPT-3.5, GPT-4,\nand LLaMA, are increasingly prevalent. Numerous studies have explored effective\nprompting techniques to harness the power of these LLMs for various research\nproblems. Retrieval, specifically in the legal data domain, poses a challenging\ntask for the direct application of Prompting techniques due to the large number\nand substantial length of legal articles. This research focuses on maximizing\nthe potential of prompting by placing it as the final phase of the retrieval\nsystem, preceded by the support of two phases: BM25 Pre-ranking and BERT-based\nRe-ranking. Experiments on the COLIEE 2023 dataset demonstrate that integrating\nprompting techniques on LLMs into the retrieval system significantly improves\nretrieval accuracy. However, error analysis reveals several existing issues in\nthe retrieval system that still need resolution.",
      "tldr_zh": "这篇论文提出了一种多阶段方法来提升法律文档检索，使用 Large Language Models (LLMs) 如 GPT-3.5 和 GPT-4 作为最终的 Prompting 阶段，前置 BM25 Pre-ranking 和 BERT-based Re-ranking，以应对法律文章数量多和长度大的挑战。实验在 COLIEE 2023 数据集上进行，结果显示这种整合显著提高了检索准确性。儘管如此，错误分析揭示了系统中仍存在一些问题需要进一步解决。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "JURISIN 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.18093v1",
      "published_date": "2024-03-26 20:25:53 UTC",
      "updated_date": "2024-03-26 20:25:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:57:32.418762"
    },
    {
      "arxiv_id": "2404.00057v1",
      "title": "PerOS: Personalized Self-Adapting Operating Systems in the Cloud",
      "title_zh": "PerOS：云端的个性化自适应操作系统",
      "authors": [
        "Hongyu Hè"
      ],
      "abstract": "Operating systems (OSes) are foundational to computer systems, managing\nhardware resources and ensuring secure environments for diverse applications.\nHowever, despite their enduring importance, the fundamental design objectives\nof OSes have seen minimal evolution over decades. Traditionally prioritizing\naspects like speed, memory efficiency, security, and scalability, these\nobjectives often overlook the crucial aspect of intelligence as well as\npersonalized user experience. The lack of intelligence becomes increasingly\ncritical amid technological revolutions, such as the remarkable advancements in\nmachine learning (ML).\n  Today's personal devices, evolving into intimate companions for users, pose\nunique challenges for traditional OSes like Linux and iOS, especially with the\nemergence of specialized hardware featuring heterogeneous components.\nFurthermore, the rise of large language models (LLMs) in ML has introduced\ntransformative capabilities, reshaping user interactions and software\ndevelopment paradigms.\n  While existing literature predominantly focuses on leveraging ML methods for\nsystem optimization or accelerating ML workloads, there is a significant gap in\naddressing personalized user experiences at the OS level. To tackle this\nchallenge, this work proposes PerOS, a personalized OS ingrained with LLM\ncapabilities. PerOS aims to provide tailored user experiences while\nsafeguarding privacy and personal data through declarative interfaces,\nself-adaptive kernels, and secure data management in a scalable cloud-centric\narchitecture; therein lies the main research question of this work: How can we\ndevelop intelligent, secure, and scalable OSes that deliver personalized\nexperiences to thousands of users?",
      "tldr_zh": "传统操作系统（OSes）在设计上长期注重速度、内存效率、安全性和可扩展性，却忽略了智能性和个性化，尤其在机器学习（ML）和大型语言模型（LLMs）快速发展时代。论文提出 PerOS，一种整合 LLMs 能力的个性化自适应操作系统，旨在通过声明式接口、自适应内核以及安全的云端数据管理，提供量身定制的用户体验。PerOS 强调隐私保护和可扩展性，针对现代异构硬件设备和用户互动挑战，探索如何构建智能、安全且可扩展的 OSes 来服务数千用户。最终，该框架有望革新 OS 设计，推动个性化计算的发展。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CR",
        "cs.OS"
      ],
      "primary_category": "cs.HC",
      "comment": "29 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.00057v1",
      "published_date": "2024-03-26 20:10:31 UTC",
      "updated_date": "2024-03-26 20:10:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:57:44.762278"
    },
    {
      "arxiv_id": "2403.18079v2",
      "title": "Paths to Equilibrium in Games",
      "title_zh": "游戏中的通往均衡的路径",
      "authors": [
        "Bora Yongacoglu",
        "Gürdal Arslan",
        "Lacra Pavel",
        "Serdar Yüksel"
      ],
      "abstract": "In multi-agent reinforcement learning (MARL) and game theory, agents\nrepeatedly interact and revise their strategies as new data arrives, producing\na sequence of strategy profiles. This paper studies sequences of strategies\nsatisfying a pairwise constraint inspired by policy updating in reinforcement\nlearning, where an agent who is best responding in one period does not switch\nits strategy in the next period. This constraint merely requires that\noptimizing agents do not switch strategies, but does not constrain the\nnon-optimizing agents in any way, and thus allows for exploration. Sequences\nwith this property are called satisficing paths, and arise naturally in many\nMARL algorithms. A fundamental question about strategic dynamics is such: for a\ngiven game and initial strategy profile, is it always possible to construct a\nsatisficing path that terminates at an equilibrium? The resolution of this\nquestion has implications about the capabilities or limitations of a class of\nMARL algorithms. We answer this question in the affirmative for normal-form\ngames. Our analysis reveals a counterintuitive insight that reward\ndeteriorating strategic updates are key to driving play to equilibrium along a\nsatisficing path.",
      "tldr_zh": "这篇论文探讨了多智能体强化学习(MARL)和博弈论中，代理通过策略序列逐步互动并更新策略的过程。作者引入了satisficing paths的概念，该序列满足一个配对约束，即最佳响应的代理不会立即切换策略，从而允许探索。论文证明，对于正规形式博弈(normal-form games)，无论初始策略配置如何，都可以构建一个satisficing path到达均衡。关键发现是，奖励恶化的策略更新是驱动系统达到均衡的核心机制，这为MARL算法的设计提供了重要启示。",
      "categories": [
        "cs.GT",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.GT",
      "comment": "Accepted to NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.18079v2",
      "published_date": "2024-03-26 19:58:39 UTC",
      "updated_date": "2024-10-01 17:33:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:57:56.919865"
    },
    {
      "arxiv_id": "2403.18067v1",
      "title": "State of the art applications of deep learning within tracking and detecting marine debris: A survey",
      "title_zh": "翻译失败",
      "authors": [
        "Zoe Moorton",
        "Zeyneb Kurt",
        "Wai Lok Woo"
      ],
      "abstract": "Deep learning techniques have been explored within the marine litter problem\nfor approximately 20 years but the majority of the research has developed\nrapidly in the last five years. We provide an in-depth, up to date, summary and\nanalysis of 28 of the most recent and significant contributions of deep\nlearning in marine debris. From cross referencing the research paper results,\nthe YOLO family significantly outperforms all other methods of object detection\nbut there are many respected contributions to this field that have\ncategorically agreed that a comprehensive database of underwater debris is not\ncurrently available for machine learning. Using a small dataset curated and\nlabelled by us, we tested YOLOv5 on a binary classification task and found the\naccuracy was low and the rate of false positives was high; highlighting the\nimportance of a comprehensive database. We conclude this survey with over 40\nfuture research recommendations and open challenges.",
      "tldr_zh": "这是一篇关于深度学习在海洋垃圾追踪和检测中的最新应用调查，总结并分析了28个重要研究贡献。调查发现，YOLO系列在物体检测方面显著优于其他方法，但强调目前缺乏全面的 underwater debris 数据库，这限制了模型的性能。作者使用自有小数据集测试YOLOv5的 binary classification 任务，结果显示准确率较低且假阳性率较高。论文最终提出了40多个未来研究推荐和开放挑战，以推动该领域的进展。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Review paper, 60 pages including references, 1 figure, 3 tables, 1\n  supplementary data",
      "pdf_url": "http://arxiv.org/pdf/2403.18067v1",
      "published_date": "2024-03-26 19:36:50 UTC",
      "updated_date": "2024-03-26 19:36:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:58:09.028342"
    },
    {
      "arxiv_id": "2403.18063v2",
      "title": "Heracles: A Hybrid SSM-Transformer Model for High-Resolution Image and Time-Series Analysis",
      "title_zh": "Heracles：一种用于高分辨率图像和时间序列分析的混合 SSM-Transformer 模型",
      "authors": [
        "Badri N. Patro",
        "Suhas Ranganath",
        "Vinay P. Namboodiri",
        "Vijay S. Agneeswaran"
      ],
      "abstract": "Transformers have revolutionized image modeling tasks with adaptations like\nDeIT, Swin, SVT, Biformer, STVit, and FDVIT. However, these models often face\nchallenges with inductive bias and high quadratic complexity, making them less\nefficient for high-resolution images. State space models (SSMs) such as Mamba,\nV-Mamba, ViM, and SiMBA offer an alternative to handle high resolution images\nin computer vision tasks. These SSMs encounter two major issues. First, they\nbecome unstable when scaled to large network sizes. Second, although they\nefficiently capture global information in images, they inherently struggle with\nhandling local information. To address these challenges, we introduce Heracles,\na novel SSM that integrates a local SSM, a global SSM, and an attention-based\ntoken interaction module. Heracles leverages a Hartely kernel-based state space\nmodel for global image information, a localized convolutional network for local\ndetails, and attention mechanisms in deeper layers for token interactions. Our\nextensive experiments demonstrate that Heracles-C-small achieves\nstate-of-the-art performance on the ImageNet dataset with 84.5\\% top-1\naccuracy. Heracles-C-Large and Heracles-C-Huge further improve accuracy to\n85.9\\% and 86.4\\%, respectively. Additionally, Heracles excels in transfer\nlearning tasks on datasets such as CIFAR-10, CIFAR-100, Oxford Flowers, and\nStanford Cars, and in instance segmentation on the MSCOCO dataset. Heracles\nalso proves its versatility by achieving state-of-the-art results on seven\ntime-series datasets, showcasing its ability to generalize across domains with\nspectral data, capturing both local and global information. The project page is\navailable at this link.\\url{https://github.com/badripatro/heracles}",
      "tldr_zh": "本论文提出 Heracles，一种混合 SSM-Transformer 模型，旨在解决传统 Transformers 在高分辨率图像处理中的归纳偏差和高二次复杂度问题，以及 SSMs 如 Mamba 在模型扩展不稳定性和局部信息处理上的局限。Heracles 整合了基于 Hartely 内核的全球 SSM 处理全局图像信息、局部卷积网络捕捉细节，以及注意力机制进行令牌交互。实验结果显示，Heracles-C-small 在 ImageNet 上达到 84.5% top-1 准确率，而更大模型进一步提升至 85.9% 和 86.4%；此外，它在转移学习（如 CIFAR-10）、实例分割（如 MSCOCO）和七个时间序列数据集上均实现最先进性能，证明了其跨域泛化能力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.18063v2",
      "published_date": "2024-03-26 19:29:21 UTC",
      "updated_date": "2024-06-03 18:22:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:58:22.959988"
    },
    {
      "arxiv_id": "2403.18062v1",
      "title": "ShapeGrasp: Zero-Shot Task-Oriented Grasping with Large Language Models through Geometric Decomposition",
      "title_zh": "翻译失败",
      "authors": [
        "Samuel Li",
        "Sarthak Bhagat",
        "Joseph Campbell",
        "Yaqi Xie",
        "Woojun Kim",
        "Katia Sycara",
        "Simon Stepputtis"
      ],
      "abstract": "Task-oriented grasping of unfamiliar objects is a necessary skill for robots\nin dynamic in-home environments. Inspired by the human capability to grasp such\nobjects through intuition about their shape and structure, we present a novel\nzero-shot task-oriented grasping method leveraging a geometric decomposition of\nthe target object into simple, convex shapes that we represent in a graph\nstructure, including geometric attributes and spatial relationships. Our\napproach employs minimal essential information - the object's name and the\nintended task - to facilitate zero-shot task-oriented grasping. We utilize the\ncommonsense reasoning capabilities of large language models to dynamically\nassign semantic meaning to each decomposed part and subsequently reason over\nthe utility of each part for the intended task. Through extensive experiments\non a real-world robotics platform, we demonstrate that our grasping approach's\ndecomposition and reasoning pipeline is capable of selecting the correct part\nin 92% of the cases and successfully grasping the object in 82% of the tasks we\nevaluate. Additional videos, experiments, code, and data are available on our\nproject website: https://shapegrasp.github.io/.",
      "tldr_zh": "该论文提出ShapeGrasp，一种零样本(zero-shot)任务导向抓取方法，通过将目标物体几何分解成简单凸形并用图结构表示其几何属性和空间关系，仅需物体名称和预定任务作为输入。利用大型语言模型(LLMs)的常识推理能力，该方法动态为每个分解部分分配语义含义，并评估其对任务的效用。实验结果显示，在真实机器人平台上，ShapeGrasp在92%的案例中正确选择部分，并在82%的任务中成功抓取物体。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "8 pages",
      "pdf_url": "http://arxiv.org/pdf/2403.18062v1",
      "published_date": "2024-03-26 19:26:53 UTC",
      "updated_date": "2024-03-26 19:26:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:58:31.604993"
    },
    {
      "arxiv_id": "2403.18058v2",
      "title": "COIG-CQIA: Quality is All You Need for Chinese Instruction Fine-tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Yuelin Bai",
        "Xinrun Du",
        "Yiming Liang",
        "Yonggang Jin",
        "Junting Zhou",
        "Ziqiang Liu",
        "Feiteng Fang",
        "Mingshan Chang",
        "Tianyu Zheng",
        "Xincheng Zhang",
        "Nuo Ma",
        "Zekun Wang",
        "Ruibin Yuan",
        "Haihong Wu",
        "Hongquan Lin",
        "Wenhao Huang",
        "Jiajun Zhang",
        "Chenghua Lin",
        "Jie Fu",
        "Min Yang",
        "Shiwen Ni",
        "Ge Zhang"
      ],
      "abstract": "Remarkable progress on English instruction tuning has facilitated the\nefficacy and reliability of large language models (LLMs). However, there\nremains a noticeable gap in instruction tuning for Chinese, where the complex\nlinguistic features pose significant challenges. Existing datasets, generally\ndistilled from English-centric LLMs, are not well-aligned with Chinese users'\ninteraction patterns. To bridge this gap, we introduce COIG-CQIA, a new Chinese\ninstruction tuning dataset derived from various real-world resources and\nundergoing rigorous human verification. We conduct extensive experiments on\nCOIG-CQIA, and compare them with strong baseline models and datasets. The\nexperimental results show that models trained on COIG-CQIA achieve highly\ncompetitive performance in diverse benchmarks. Additionally, our findings offer\nseveral insights for designing effective Chinese instruction-tuning datasets\nand data-mixing strategies. Our dataset are available at\nhttps://huggingface.co/datasets/m-a-p/COIG-CQIA.",
      "tldr_zh": "该论文介绍了 COIG-CQIA，这是一个针对中文指令微调的新数据集，旨在解决现有英语中心数据集不适应中文用户互动模式的问题。COIG-CQIA 通过从真实世界资源中获取数据并进行严格的人工验证，确保了高质量的训练样本。实验结果显示，在该数据集上微调的模型在各种 benchmarks 中表现出高度竞争性的性能，并提供了设计有效中文 instruction tuning 数据集和数据混合策略的宝贵见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.18058v2",
      "published_date": "2024-03-26 19:24:18 UTC",
      "updated_date": "2024-11-02 11:08:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:58:44.367375"
    },
    {
      "arxiv_id": "2403.18057v1",
      "title": "Prioritized League Reinforcement Learning for Large-Scale Heterogeneous Multiagent Systems",
      "title_zh": "针对大规模异构多智能体系统的优先化联盟强化学习",
      "authors": [
        "Qingxu Fu",
        "Zhiqiang Pu",
        "Min Chen",
        "Tenghai Qiu",
        "Jianqiang Yi"
      ],
      "abstract": "Large-scale heterogeneous multiagent systems feature various realistic\nfactors in the real world, such as agents with diverse abilities and overall\nsystem cost. In comparison to homogeneous systems, heterogeneous systems offer\nsignificant practical advantages. Nonetheless, they also present challenges for\nmultiagent reinforcement learning, including addressing the non-stationary\nproblem and managing an imbalanced number of agents with different types. We\npropose a Prioritized Heterogeneous League Reinforcement Learning (PHLRL)\nmethod to address large-scale heterogeneous cooperation problems. PHLRL\nmaintains a record of various policies that agents have explored during their\ntraining and establishes a heterogeneous league consisting of diverse policies\nto aid in future policy optimization. Furthermore, we design a prioritized\npolicy gradient approach to compensate for the gap caused by differences in the\nnumber of different types of agents. Next, we use Unreal Engine to design a\nlarge-scale heterogeneous cooperation benchmark named Large-Scale Multiagent\nOperation (LSMO), which is a complex two-team competition scenario that\nrequires collaboration from both ground and airborne agents. We use experiments\nto show that PHLRL outperforms state-of-the-art methods, including QTRAN and\nQPLEX in LSMO.",
      "tldr_zh": "本论文针对大型异构多智能体系统（如代理多样性和非平稳问题）面临的挑战，提出了 Prioritized Heterogeneous League Reinforcement Learning (PHLRL) 方法，以优化异构合作问题。PHLRL 通过维护代理探索的策略记录、建立异构联盟并采用优先化策略梯度，补偿不同类型代理数量的不平衡。作者还设计了 Large-Scale Multiagent Operation (LSMO) 基准，使用 Unreal Engine 模拟复杂两队竞争场景，实验结果显示 PHLRL 在 LSMO 上优于现有方法如 QTRAN 和 QPLEX。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.18057v1",
      "published_date": "2024-03-26 19:21:50 UTC",
      "updated_date": "2024-03-26 19:21:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:58:58.660870"
    },
    {
      "arxiv_id": "2403.18056v1",
      "title": "Self-Clustering Hierarchical Multi-Agent Reinforcement Learning with Extensible Cooperation Graph",
      "title_zh": "带有可扩展",
      "authors": [
        "Qingxu Fu",
        "Tenghai Qiu",
        "Jianqiang Yi",
        "Zhiqiang Pu",
        "Xiaolin Ai"
      ],
      "abstract": "Multi-Agent Reinforcement Learning (MARL) has been successful in solving many\ncooperative challenges. However, classic non-hierarchical MARL algorithms still\ncannot address various complex multi-agent problems that require hierarchical\ncooperative behaviors. The cooperative knowledge and policies learned in\nnon-hierarchical algorithms are implicit and not interpretable, thereby\nrestricting the integration of existing knowledge. This paper proposes a novel\nhierarchical MARL model called Hierarchical Cooperation Graph Learning (HCGL)\nfor solving general multi-agent problems. HCGL has three components: a dynamic\nExtensible Cooperation Graph (ECG) for achieving self-clustering cooperation; a\ngroup of graph operators for adjusting the topology of ECG; and an MARL\noptimizer for training these graph operators. HCGL's key distinction from other\nMARL models is that the behaviors of agents are guided by the topology of ECG\ninstead of policy neural networks. ECG is a three-layer graph consisting of an\nagent node layer, a cluster node layer, and a target node layer. To manipulate\nthe ECG topology in response to changing environmental conditions, four graph\noperators are trained to adjust the edge connections of ECG dynamically. The\nhierarchical feature of ECG provides a unique approach to merge primitive\nactions (actions executed by the agents) and cooperative actions (actions\nexecuted by the clusters) into a unified action space, allowing us to integrate\nfundamental cooperative knowledge into an extensible interface. In our\nexperiments, the HCGL model has shown outstanding performance in multi-agent\nbenchmarks with sparse rewards. We also verify that HCGL can easily be\ntransferred to large-scale scenarios with high zero-shot transfer success\nrates.",
      "tldr_zh": "本文提出了一种名为Hierarchical Cooperation Graph Learning (HCGL) 的分层多代理强化学习(MARL) 模型，用于解决经典非分层MARL算法在处理复杂分层合作问题时的局限性，如策略不透明和知识整合困难。HCGL的核心组件包括动态Extensible Cooperation Graph (ECG) 用于自聚类合作、一组graph operators动态调整ECG拓扑，以及MARL optimizer训练这些操作符，从而将代理行为由ECG的三层结构（agent node layer、cluster node layer和target node layer）指导，实现原始动作和合作动作的统一。实验结果表明，HCGL在稀疏奖励的多代理基准上表现出色，并易于转移到大规模场景中，实现了高零-shot transfer成功率。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.18056v1",
      "published_date": "2024-03-26 19:19:16 UTC",
      "updated_date": "2024-03-26 19:19:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:59:12.990821"
    },
    {
      "arxiv_id": "2403.18051v1",
      "title": "Supervisory Prompt Training",
      "title_zh": "监督提示训练",
      "authors": [
        "Jean Ghislain Billa",
        "Min Oh",
        "Liang Du"
      ],
      "abstract": "The performance of Large Language Models (LLMs) relies heavily on the quality\nof prompts, which are often manually engineered and task-specific, making them\ncostly and non-scalable. We propose a novel approach, Supervisory Prompt\nTraining (SPT). SPT automates the generation of highly effective prompts using\na dual LLM system. In this system, one LLM, the generator, performs a task\nwhile the other, the corrector, provides feedback and generates improved\nprompts. In contrast to earlier techniques, both the generator and corrector\ncollaboratively and continuously improve their prompts over time. We also\nintroduce the concept of \\textit{impact scores} to measure the sentence-level\neffectiveness of the prompts. Our method was tested on four benchmarks, testing\nthe level of hallucinations in LLMs. Notably, we were able to increase the\naccuracy of GPT-4 on GSM8K from 65.8\\% to 94.1\\% (28.3\\% increase). SPT\nadvances LLMs by refining prompts to enhance performance and reduce\nhallucinations, offering an efficient and scalable alternative to traditional\nmodel fine-tuning.",
      "tldr_zh": "大语言模型（LLMs）的性能严重依赖于提示的质量，但手动设计提示往往成本高且不易扩展。我们提出了一种新方法Supervisory Prompt Training (SPT)，利用双LLM系统——其中一个作为generator执行任务，另一个作为corrector提供反馈并生成改进提示。SPT的创新在于generator和corrector协作持续优化提示，并引入impact scores来衡量提示在句子级别的有效性。在四个基准测试中，该方法显著降低了LLMs的幻觉水平，例如将GPT-4在GSM8K上的准确率从65.8%提高到94.1%。SPT为提升LLMs性能提供了一种高效、可扩展的替代方案，优于传统模型微调。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.18051v1",
      "published_date": "2024-03-26 19:08:20 UTC",
      "updated_date": "2024-03-26 19:08:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:59:25.960931"
    },
    {
      "arxiv_id": "2403.18028v2",
      "title": "Predicting Species Occurrence Patterns from Partial Observations",
      "title_zh": "基于部分观察的物种出现模式预测",
      "authors": [
        "Hager Radi Abdelwahed",
        "Mélisande Teng",
        "David Rolnick"
      ],
      "abstract": "To address the interlinked biodiversity and climate crises, we need an\nunderstanding of where species occur and how these patterns are changing.\nHowever, observational data on most species remains very limited, and the\namount of data available varies greatly between taxonomic groups. We introduce\nthe problem of predicting species occurrence patterns given (a) satellite\nimagery, and (b) known information on the occurrence of other species. To\nevaluate algorithms on this task, we introduce SatButterfly, a dataset of\nsatellite images, environmental data and observational data for butterflies,\nwhich is designed to pair with the existing SatBird dataset of bird\nobservational data. To address this task, we propose a general model, R-Tran,\nfor predicting species occurrence patterns that enables the use of partial\nobservational data wherever found. We find that R-Tran outperforms other\nmethods in predicting species encounter rates with partial information both\nwithin a taxon (birds) and across taxa (birds and butterflies). Our approach\nopens new perspectives to leveraging insights from species with abundant data\nto other species with scarce data, by modelling the ecosystems in which they\nco-occur.",
      "tldr_zh": "本文探讨了利用卫星图像和部分物种观测数据来预测物种分布模式的问题，以应对生物多样性和气候危机的挑战。研究引入了SatButterfly数据集，包括卫星图像、环境数据和蝴蝶观测数据，并与现有的SatBird数据集相结合。作者提出R-Tran模型，该模型能有效整合部分观测数据，在同一分类群（如鸟类）和跨分类群（如鸟类和蝴蝶）预测物种遇见率时，优于其他方法。总体而言，此方法通过建模物种共存生态系统，提供从数据丰富的物种推断数据稀缺物种的新途径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "q-bio.PE"
      ],
      "primary_category": "cs.LG",
      "comment": "Tackling Climate Change with Machine Learning workshop at ICLR 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.18028v2",
      "published_date": "2024-03-26 18:29:39 UTC",
      "updated_date": "2024-03-28 17:06:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:59:35.534728"
    },
    {
      "arxiv_id": "2403.18025v2",
      "title": "Improving Pre-trained Language Model Sensitivity via Mask Specific losses: A case study on Biomedical NER",
      "title_zh": "翻译失败",
      "authors": [
        "Micheal Abaho",
        "Danushka Bollegala",
        "Gary Leeming",
        "Dan Joyce",
        "Iain E Buchan"
      ],
      "abstract": "Adapting language models (LMs) to novel domains is often achieved through\nfine-tuning a pre-trained LM (PLM) on domain-specific data. Fine-tuning\nintroduces new knowledge into an LM, enabling it to comprehend and efficiently\nperform a target domain task. Fine-tuning can however be inadvertently\ninsensitive if it ignores the wide array of disparities (e.g in word meaning)\nbetween source and target domains. For instance, words such as chronic and\npressure may be treated lightly in social conversations, however, clinically,\nthese words are usually an expression of concern. To address insensitive\nfine-tuning, we propose Mask Specific Language Modeling (MSLM), an approach\nthat efficiently acquires target domain knowledge by appropriately weighting\nthe importance of domain-specific terms (DS-terms) during fine-tuning. MSLM\njointly masks DS-terms and generic words, then learns mask-specific losses by\nensuring LMs incur larger penalties for inaccurately predicting DS-terms\ncompared to generic words. Results of our analysis show that MSLM improves LMs\nsensitivity and detection of DS-terms. We empirically show that an optimal\nmasking rate not only depends on the LM, but also on the dataset and the length\nof sequences. Our proposed masking strategy outperforms advanced masking\nstrategies such as span- and PMI-based masking.",
      "tldr_zh": "本研究针对微调预训练语言模型 (PLM) 时可能忽略源域和目标域（如生物医学领域）差异的问题，提出了一种 Mask Specific Language Modeling (MSLM) 方法，以提升模型对领域特定术语 (DS-terms) 的敏感性。MSLM 通过联合掩码 DS-terms 和通用词，并应用 mask-specific losses 来加大对 DS-terms 预测错误的惩罚，从而更高效地获取目标域知识。实验结果显示，该方法显著提高了 PLM 在 Biomedical NER 任务中的 DS-terms 检测性能，且其最优掩码率取决于模型、数据集和序列长度；此外，MSLM 优于先进的掩码策略，如 span- and PMI-based masking。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Paper alrerady accepted for publishing by the NAACL 2024 conference\n  (main conference paper)",
      "pdf_url": "http://arxiv.org/pdf/2403.18025v2",
      "published_date": "2024-03-26 18:23:16 UTC",
      "updated_date": "2024-03-28 11:01:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:59:46.588825"
    },
    {
      "arxiv_id": "2403.17933v2",
      "title": "SLEDGE: Synthesizing Driving Environments with Generative Models and Rule-Based Traffic",
      "title_zh": "翻译失败",
      "authors": [
        "Kashyap Chitta",
        "Daniel Dauner",
        "Andreas Geiger"
      ],
      "abstract": "SLEDGE is the first generative simulator for vehicle motion planning trained\non real-world driving logs. Its core component is a learned model that is able\nto generate agent bounding boxes and lane graphs. The model's outputs serve as\nan initial state for rule-based traffic simulation. The unique properties of\nthe entities to be generated for SLEDGE, such as their connectivity and\nvariable count per scene, render the naive application of most modern\ngenerative models to this task non-trivial. Therefore, together with a\nsystematic study of existing lane graph representations, we introduce a novel\nraster-to-vector autoencoder. It encodes agents and the lane graph into\ndistinct channels in a rasterized latent map. This facilitates both\nlane-conditioned agent generation and combined generation of lanes and agents\nwith a Diffusion Transformer. Using generated entities in SLEDGE enables\ngreater control over the simulation, e.g. upsampling turns or increasing\ntraffic density. Further, SLEDGE can support 500m long routes, a capability not\nfound in existing data-driven simulators like nuPlan. It presents new\nchallenges for planning algorithms, evidenced by failure rates of over 40% for\nPDM, the winner of the 2023 nuPlan challenge, when tested on hard routes and\ndense traffic generated by our model. Compared to nuPlan, SLEDGE requires\n500$\\times$ less storage to set up (<4 GB), making it a more accessible option\nand helping with democratizing future research in this field.",
      "tldr_zh": "该论文提出了 SLEDGE，一种基于真实驾驶日志训练的生成式模拟器，用于合成驾驶环境，结合生成模型和规则-based 交通模拟。核心方法包括一个新型 raster-to-vector autoencoder，将代理 bounding boxes 和车道图编码到栅格化潜在地图的不同通道，并利用 Diffusion Transformer 实现车道条件下的代理生成和联合生成。SLEDGE 允许对模拟场景进行更大控制，如增加转弯频率或交通密度，并支持长达 500m 的路线。实验显示，在 SLEDGE 生成的复杂场景中，nuPlan 挑战获胜者 PDM 的失败率超过 40%，揭示了新挑战。与 nuPlan 相比，SLEDGE 的存储需求降低 500 倍（不到 4 GB），有助于推动该领域的可访问性研究。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "ECCV 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.17933v2",
      "published_date": "2024-03-26 17:58:29 UTC",
      "updated_date": "2024-07-11 17:27:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:00:00.657951"
    },
    {
      "arxiv_id": "2403.17927v2",
      "title": "MAGIS: LLM-Based Multi-Agent Framework for GitHub Issue Resolution",
      "title_zh": "翻译失败",
      "authors": [
        "Wei Tao",
        "Yucheng Zhou",
        "Yanlin Wang",
        "Wenqiang Zhang",
        "Hongyu Zhang",
        "Yu Cheng"
      ],
      "abstract": "In software development, resolving the emergent issues within GitHub\nrepositories is a complex challenge that involves not only the incorporation of\nnew code but also the maintenance of existing code. Large Language Models\n(LLMs) have shown promise in code generation but face difficulties in resolving\nGithub issues, particularly at the repository level. To overcome this\nchallenge, we empirically study the reason why LLMs fail to resolve GitHub\nissues and analyze the major factors. Motivated by the empirical findings, we\npropose a novel LLM-based Multi-Agent framework for GitHub Issue reSolution,\nMAGIS, consisting of four agents customized for software evolution: Manager,\nRepository Custodian, Developer, and Quality Assurance Engineer agents. This\nframework leverages the collaboration of various agents in the planning and\ncoding process to unlock the potential of LLMs to resolve GitHub issues. In\nexperiments, we employ the SWE-bench benchmark to compare MAGIS with popular\nLLMs, including GPT-3.5, GPT-4, and Claude-2. MAGIS can resolve 13.94% GitHub\nissues, significantly outperforming the baselines. Specifically, MAGIS achieves\nan eight-fold increase in resolved ratio over the direct application of GPT-4,\nthe advanced LLM.",
      "tldr_zh": "该研究分析了大型语言模型（LLM）在解决GitHub问题时的局限性，特别是仓库级别挑战，并通过实证研究识别主要因素。论文提出MAGIS框架，一种基于LLM的多代理系统，包括Manager、Repository Custodian、Developer和Quality Assurance Engineer代理，这些代理协作进行规划和编码，以提升软件演化过程。实验结果显示，在SWE-bench基准测试中，MAGIS成功解决了13.94%的GitHub问题，比直接使用GPT-4等基线模型提高了八倍性能。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.17927v2",
      "published_date": "2024-03-26 17:57:57 UTC",
      "updated_date": "2024-06-27 12:40:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:00:10.778118"
    },
    {
      "arxiv_id": "2403.17924v3",
      "title": "AID: Attention Interpolation of Text-to-Image Diffusion",
      "title_zh": "翻译失败",
      "authors": [
        "Qiyuan He",
        "Jinghao Wang",
        "Ziwei Liu",
        "Angela Yao"
      ],
      "abstract": "Conditional diffusion models can create unseen images in various settings,\naiding image interpolation. Interpolation in latent spaces is well-studied, but\ninterpolation with specific conditions like text or poses is less understood.\nSimple approaches, such as linear interpolation in the space of conditions,\noften result in images that lack consistency, smoothness, and fidelity. To that\nend, we introduce a novel training-free technique named Attention Interpolation\nvia Diffusion (AID). Our key contributions include 1) proposing an inner/outer\ninterpolated attention layer; 2) fusing the interpolated attention with\nself-attention to boost fidelity; and 3) applying beta distribution to\nselection to increase smoothness. We also present a variant, Prompt-guided\nAttention Interpolation via Diffusion (PAID), that considers interpolation as a\ncondition-dependent generative process. This method enables the creation of new\nimages with greater consistency, smoothness, and efficiency, and offers control\nover the exact path of interpolation. Our approach demonstrates effectiveness\nfor conceptual and spatial interpolation. Code and demo are available at\nhttps://github.com/QY-H00/attention-interpolation-diffusion.",
      "tldr_zh": "本研究探讨了条件扩散模型在文本到图像插值中的挑战，特别是在特定条件（如文本或姿势）下，传统线性插值方法常导致图像缺乏一致性、平滑性和保真度。为此，提出了一种无需训练的 AID（Attention Interpolation via Diffusion）技术，包括内/外插值注意力层、融合插值与自注意力以提升保真度，以及应用 beta 分布来增加平滑度。论文还引入 PAID（Prompt-guided Attention Interpolation via Diffusion）变体，将插值视为条件相关的生成过程，从而实现更高效的一致图像生成，并提供对插值路径的精确控制。实验证明，该方法在概念和空间插值任务中表现出色，提供开源代码和演示。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "NeurIPS 2024 Conference Paper",
      "pdf_url": "http://arxiv.org/pdf/2403.17924v3",
      "published_date": "2024-03-26 17:57:05 UTC",
      "updated_date": "2024-10-04 17:09:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:00:22.741454"
    },
    {
      "arxiv_id": "2403.17919v4",
      "title": "LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning",
      "title_zh": "LISA：逐层重要性采样用于内存高效的大语言模型微调",
      "authors": [
        "Rui Pan",
        "Xiang Liu",
        "Shizhe Diao",
        "Renjie Pi",
        "Jipeng Zhang",
        "Chi Han",
        "Tong Zhang"
      ],
      "abstract": "The machine learning community has witnessed impressive advancements since\nlarge language models (LLMs) first appeared. Yet, their massive memory\nconsumption has become a significant roadblock to large-scale training. For\ninstance, a 7B model typically requires at least 60 GB of GPU memory with full\nparameter training, which presents challenges for researchers without access to\nhigh-resource environments. Parameter Efficient Fine-Tuning techniques such as\nLow-Rank Adaptation (LoRA) have been proposed to alleviate this problem.\nHowever, in most large-scale fine-tuning settings, their performance does not\nreach the level of full parameter training because they confine the parameter\nsearch to a low-rank subspace. Attempting to complement this deficiency, we\ninvestigate the layerwise properties of LoRA on fine-tuning tasks and observe\nan unexpected but consistent skewness of weight norms across different layers.\nUtilizing this key observation, a surprisingly simple training strategy is\ndiscovered, which outperforms both LoRA and full parameter training in a wide\nrange of settings with memory costs as low as LoRA. We name it Layerwise\nImportance Sampled AdamW (LISA), a promising alternative for LoRA, which\napplies the idea of importance sampling to different layers in LLMs and\nrandomly freezes most middle layers during optimization. Experimental results\nshow that with similar or less GPU memory consumption, LISA surpasses LoRA or\neven full parameter tuning in downstream fine-tuning tasks, where LISA\nconsistently outperforms LoRA by over 10%-35% in terms of MT-Bench score while\nachieving on-par or better performance in MMLU, AGIEval and WinoGrande. On\nlarge models, specifically LLaMA-2-70B, LISA surpasses LoRA on MT-Bench, GSM8K,\nand PubMedQA, demonstrating its effectiveness across different domains.",
      "tldr_zh": "该论文提出 LISA（Layerwise Importance Sampled AdamW），一种内存高效的微调策略，用于解决大型语言模型 (LLMs) 在训练中高内存消耗的问题。LISA 基于对 LoRA（Low-Rank Adaptation）层级权重偏差的观察，通过重要性采样和随机冻结大部分中间层，实现参数优化，同时保持与 LoRA 相似的内存开销。实验结果显示，LISA 在下游任务中超越 LoRA 和全参数训练，在 MT-Bench 上提升 10%-35%，并在 MMLU、AGIEval、WinoGrande 及 LLaMA-2-70B 模型上表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.17919v4",
      "published_date": "2024-03-26 17:55:02 UTC",
      "updated_date": "2024-12-25 19:03:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:00:35.584976"
    },
    {
      "arxiv_id": "2403.17918v3",
      "title": "AgentStudio: A Toolkit for Building General Virtual Agents",
      "title_zh": "AgentStudio：构建通用虚拟代理",
      "authors": [
        "Longtao Zheng",
        "Zhiyuan Huang",
        "Zhenghai Xue",
        "Xinrun Wang",
        "Bo An",
        "Shuicheng Yan"
      ],
      "abstract": "General virtual agents need to handle multimodal observations, master complex\naction spaces, and self-improve in dynamic, open-domain environments. However,\nexisting environments are often domain-specific and require complex setups,\nwhich limits agent development and evaluation in real-world settings. As a\nresult, current evaluations lack in-depth analyses that decompose fundamental\nagent capabilities. We introduce AgentStudio, a trinity of environments, tools,\nand benchmarks to address these issues. AgentStudio provides a lightweight,\ninteractive environment with highly generic observation and action spaces,\ne.g., video observations and GUI/API actions. It integrates tools for creating\nonline benchmark tasks, annotating GUI elements, and labeling actions in\nvideos. Based on our environment and tools, we curate an online task suite that\nbenchmarks both GUI interactions and function calling with efficient\nauto-evaluation. We also reorganize existing datasets and collect new ones\nusing our tools to establish three datasets: GroundUI, IDMBench, and\nCriticBench. These datasets evaluate fundamental agent abilities, including GUI\ngrounding, learning from videos, and success detection, pointing to the\ndesiderata for robust, general, and open-ended virtual agents.",
      "tldr_zh": "该论文介绍了 AgentStudio，一种用于构建通用虚拟代理的工具包，旨在解决现有环境在处理多模态观察、复杂动作空间和动态环境中的局限性。AgentStudio 包括轻量级交互式环境、工具和基准，提供通用观察（如视频）和动作空间（如 GUI/API 操作），并支持创建在线任务、标注 GUI 元素和视频动作。基于此，论文整理了现有数据集并收集新数据集，建立 GroundUI、IDMBench 和 CriticBench，用于评估代理的核心能力，包括 GUI 定位、从视频学习和成功检测。总体上，AgentStudio 为开发鲁棒、通用且开放式虚拟代理提供了全面框架和基准标准。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "ICLR 2025. Project page: https://ltzheng.github.io/agent-studio",
      "pdf_url": "http://arxiv.org/pdf/2403.17918v3",
      "published_date": "2024-03-26 17:54:15 UTC",
      "updated_date": "2025-02-14 08:13:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:00:47.215935"
    },
    {
      "arxiv_id": "2403.17916v3",
      "title": "CMP: Cooperative Motion Prediction with Multi-Agent Communication",
      "title_zh": "CMP：基于多智能体通信的合作运动预测",
      "authors": [
        "Zehao Wang",
        "Yuping Wang",
        "Zhuoyuan Wu",
        "Hengbo Ma",
        "Zhaowei Li",
        "Hang Qiu",
        "Jiachen Li"
      ],
      "abstract": "The confluence of the advancement of Autonomous Vehicles (AVs) and the\nmaturity of Vehicle-to-Everything (V2X) communication has enabled the\ncapability of cooperative connected and automated vehicles (CAVs). Building on\ntop of cooperative perception, this paper explores the feasibility and\neffectiveness of cooperative motion prediction. Our method, CMP, takes LiDAR\nsignals as model input to enhance tracking and prediction capabilities. Unlike\nprevious work that focuses separately on either cooperative perception or\nmotion prediction, our framework, to the best of our knowledge, is the first to\naddress the unified problem where CAVs share information in both perception and\nprediction modules. Incorporated into our design is the unique capability to\ntolerate realistic V2X transmission delays, while dealing with bulky perception\nrepresentations. We also propose a prediction aggregation module, which unifies\nthe predictions obtained by different CAVs and generates the final prediction.\nThrough extensive experiments and ablation studies on the OPV2V and V2V4Real\ndatasets, we demonstrate the effectiveness of our method in cooperative\nperception, tracking, and motion prediction. In particular, CMP reduces the\naverage prediction error by 12.3% compared with the strongest baseline. Our\nwork marks a significant step forward in the cooperative capabilities of CAVs,\nshowcasing enhanced performance in complex scenarios. More details can be found\non the project website: https://cmp-cooperative-prediction.github.io.",
      "tldr_zh": "本研究提出CMP框架，利用多智能体通信实现合作运动预测（Cooperative Motion Prediction），旨在提升Autonomous Vehicles (AVs)与Vehicle-to-Everything (V2X)通信下的合作连接和自动化车辆(CAVs)性能。CMP以LiDAR信号作为输入，首次统一合作感知和运动预测模块，让CAVs在感知和预测过程中共享信息，同时处理V2X传输延迟和庞大感知表示，并引入预测聚合模块来整合多车辆预测结果。通过在OPV2V和V2V4Real数据集上的实验，CMP将平均预测错误降低12.3%，显著改善跟踪和预测准确性，推动CAVs在复杂场景中的合作能力。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.RO",
      "comment": "IEEE Robotics and Automation Letters; Project website:\n  https://cmp-cooperative-prediction.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2403.17916v3",
      "published_date": "2024-03-26 17:53:27 UTC",
      "updated_date": "2025-03-12 19:03:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:01:02.442870"
    },
    {
      "arxiv_id": "2403.17914v1",
      "title": "Hierarchical Multi-label Classification for Fine-level Event Extraction from Aviation Accident Reports",
      "title_zh": "翻译失败",
      "authors": [
        "Xinyu Zhao",
        "Hao Yan",
        "Yongming Liu"
      ],
      "abstract": "A large volume of accident reports is recorded in the aviation domain, which\ngreatly values improving aviation safety. To better use those reports, we need\nto understand the most important events or impact factors according to the\naccident reports. However, the increasing number of accident reports requires\nlarge efforts from domain experts to label those reports. In order to make the\nlabeling process more efficient, many researchers have started developing\nalgorithms to identify the underlying events from accident reports\nautomatically. This article argues that we can identify the events more\naccurately by leveraging the event taxonomy. More specifically, we consider the\nproblem a hierarchical classification task where we first identify the\ncoarse-level information and then predict the fine-level information. We\nachieve this hierarchical classification process by incorporating a novel\nhierarchical attention module into BERT. To further utilize the information\nfrom event taxonomy, we regularize the proposed model according to the\nrelationship and distribution among labels. The effectiveness of our framework\nis evaluated with the data collected by National Transportation Safety Board\n(NTSB). It has been shown that fine-level prediction accuracy is highly\nimproved, and the regularization term can be beneficial to the rare event\nidentification problem.",
      "tldr_zh": "这篇论文针对航空事故报告的事件提取问题，提出了一种分层多标签分类方法，以提高事件识别的准确性和标注效率。具体而言，该方法首先识别粗粒度信息，然后通过融入BERT模型和一个新型的分层注意力模块来预测细粒度信息，并利用正则化项来优化标签间的关系和分布。在NTSB数据集上的实验显示，该框架显著提升了细粒度事件预测的准确率，特别是对稀有事件的识别效果更佳。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted in INFORMS Journal of Data Science",
      "pdf_url": "http://arxiv.org/pdf/2403.17914v1",
      "published_date": "2024-03-26 17:51:06 UTC",
      "updated_date": "2024-03-26 17:51:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:01:12.898705"
    },
    {
      "arxiv_id": "2403.17891v1",
      "title": "Image-based Novel Fault Detection with Deep Learning Classifiers using Hierarchical Labels",
      "title_zh": "翻译失败",
      "authors": [
        "Nurettin Sergin",
        "Jiayu Huang",
        "Tzyy-Shuh Chang",
        "Hao Yan"
      ],
      "abstract": "One important characteristic of modern fault classification systems is the\nability to flag the system when faced with previously unseen fault types. This\nwork considers the unknown fault detection capabilities of deep neural\nnetwork-based fault classifiers. Specifically, we propose a methodology on how,\nwhen available, labels regarding the fault taxonomy can be used to increase\nunknown fault detection performance without sacrificing model performance. To\nachieve this, we propose to utilize soft label techniques to improve the\nstate-of-the-art deep novel fault detection techniques during the training\nprocess and novel hierarchically consistent detection statistics for online\nnovel fault detection. Finally, we demonstrated increased detection performance\non novel fault detection in inspection images from the hot steel rolling\nprocess, with results well replicated across multiple scenarios and baseline\ndetection methods.",
      "tldr_zh": "这篇论文探讨了基于图像的未知故障检测（Novel Fault Detection），利用 Deep Learning Classifiers 和 Hierarchical Labels 来提升检测性能。作者提出了一种方法，通过软标签技术（Soft Label Techniques）改进训练过程，并引入新的层次一致检测统计（Hierarchically Consistent Detection Statistics），以提高未知故障检测能力，同时保持模型整体性能。实验结果显示，在热钢轧制过程的检查图像上，该方法显著提升了检测性能，并在多个场景和基线方法中得到良好复现，为现代故障分类系统提供了更可靠的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted in IISE Transaction",
      "pdf_url": "http://arxiv.org/pdf/2403.17891v1",
      "published_date": "2024-03-26 17:22:29 UTC",
      "updated_date": "2024-03-26 17:22:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:01:26.204222"
    },
    {
      "arxiv_id": "2403.17873v1",
      "title": "Addressing Social Misattributions of Large Language Models: An HCXAI-based Approach",
      "title_zh": "解决大型语言模型的社会误归因：基于 HCXAI 的方法",
      "authors": [
        "Andrea Ferrario",
        "Alberto Termine",
        "Alessandro Facchini"
      ],
      "abstract": "Human-centered explainable AI (HCXAI) advocates for the integration of social\naspects into AI explanations. Central to the HCXAI discourse is the Social\nTransparency (ST) framework, which aims to make the socio-organizational\ncontext of AI systems accessible to their users. In this work, we suggest\nextending the ST framework to address the risks of social misattributions in\nLarge Language Models (LLMs), particularly in sensitive areas like mental\nhealth. In fact LLMs, which are remarkably capable of simulating roles and\npersonas, may lead to mismatches between designers' intentions and users'\nperceptions of social attributes, risking to promote emotional manipulation and\ndangerous behaviors, cases of epistemic injustice, and unwarranted trust. To\naddress these issues, we propose enhancing the ST framework with a fifth\n'W-question' to clarify the specific social attributions assigned to LLMs by\nits designers and users. This addition aims to bridge the gap between LLM\ncapabilities and user perceptions, promoting the ethically responsible\ndevelopment and use of LLM-based technology.",
      "tldr_zh": "该研究基于 Human-centered explainable AI (HCXAI) 的方法，扩展 Social Transparency (ST) 框架，以解决 Large Language Models (LLMs) 在敏感领域如心理健康中可能引发的社会误归因问题，例如情感操纵、危险行为和认知不公正。论文提出在 ST 框架中添加一个第五个 'W-question'，用于明确 LLMs 设计者和用户分配的具体社会归因，从而桥接设计意图与用户感知的差距。最终，这一增强有助于促进 LLMs 技术的伦理负责开发和应用，确保更可信赖的人机互动。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Extended version of the manuscript accepted for the ACM CHI Workshop\n  on Human-Centered Explainable AI 2024 (HCXAI24)",
      "pdf_url": "http://arxiv.org/pdf/2403.17873v1",
      "published_date": "2024-03-26 17:02:42 UTC",
      "updated_date": "2024-03-26 17:02:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:01:36.810613"
    },
    {
      "arxiv_id": "2403.17847v1",
      "title": "Climate Downscaling: A Deep-Learning Based Super-resolution Model of Precipitation Data with Attention Block and Skip Connections",
      "title_zh": "气候",
      "authors": [
        "Chia-Hao Chiang",
        "Zheng-Han Huang",
        "Liwen Liu",
        "Hsin-Chien Liang",
        "Yi-Chi Wang",
        "Wan-Ling Tseng",
        "Chao Wang",
        "Che-Ta Chen",
        "Ko-Chih Wang"
      ],
      "abstract": "Human activities accelerate consumption of fossil fuels and produce\ngreenhouse gases, resulting in urgent issues today: global warming and the\nclimate change. These indirectly cause severe natural disasters, plenty of\nlives suffering and huge losses of agricultural properties. To mitigate impacts\non our lands, scientists are developing renewable, reusable, and clean energies\nand climatologists are trying to predict the extremes. Meanwhile, governments\nare publicizing resource-saving policies for a more eco-friendly society and\narousing environment awareness. One of the most influencing factors is the\nprecipitation, bringing condensed water vapor onto lands. Water resources are\nthe most significant but basic needs in society, not only supporting our\nlivings, but also economics. In Taiwan, although the average annual\nprecipitation is up to 2,500 millimeter (mm), the water allocation for each\nperson is lower than the global average due to drastically geographical\nelevation changes and uneven distribution through the year. Thus, it is crucial\nto track and predict the rainfall to make the most use of it and to prevent the\nfloods. However, climate models have limited resolution and require intensive\ncomputational power for local-scale use. Therefore, we proposed a deep\nconvolutional neural network with skip connections, attention blocks, and\nauxiliary data concatenation, in order to downscale the low-resolution\nprecipitation data into high-resolution one. Eventually, we compare with other\nclimate downscaling methods and show better performance in metrics of Mean\nAbsolute Error (MAE), Root Mean Square Error (RMSE), Pearson Correlation,\nstructural similarity index (SSIM), and forecast indicators.",
      "tldr_zh": "这篇论文针对气候变化导致的降水预测挑战，提出了一种基于深度学习的超分辨率模型，用于将低分辨率降水数据下采样到高分辨率。该模型整合了跳跃连接（skip connections）、注意力块（attention blocks）和辅助数据连接，旨在提升预测精度并考虑区域因素，如台湾的不均匀降水分布。与其他气候下采样方法相比，该模型在 Mean Absolute Error (MAE)、Root Mean Square Error (RMSE)、Pearson Correlation、structural similarity index (SSIM) 等指标上表现出优异性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.17847v1",
      "published_date": "2024-03-26 16:36:50 UTC",
      "updated_date": "2024-03-26 16:36:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:01:49.596756"
    },
    {
      "arxiv_id": "2403.17846v2",
      "title": "Hierarchical Open-Vocabulary 3D Scene Graphs for Language-Grounded Robot Navigation",
      "title_zh": "翻译失败",
      "authors": [
        "Abdelrhman Werby",
        "Chenguang Huang",
        "Martin Büchner",
        "Abhinav Valada",
        "Wolfram Burgard"
      ],
      "abstract": "Recent open-vocabulary robot mapping methods enrich dense geometric maps with\npre-trained visual-language features. While these maps allow for the prediction\nof point-wise saliency maps when queried for a certain language concept,\nlarge-scale environments and abstract queries beyond the object level still\npose a considerable hurdle, ultimately limiting language-grounded robotic\nnavigation. In this work, we present HOV-SG, a hierarchical open-vocabulary 3D\nscene graph mapping approach for language-grounded robot navigation. Leveraging\nopen-vocabulary vision foundation models, we first obtain state-of-the-art\nopen-vocabulary segment-level maps in 3D and subsequently construct a 3D scene\ngraph hierarchy consisting of floor, room, and object concepts, each enriched\nwith open-vocabulary features. Our approach is able to represent multi-story\nbuildings and allows robotic traversal of those using a cross-floor Voronoi\ngraph. HOV-SG is evaluated on three distinct datasets and surpasses previous\nbaselines in open-vocabulary semantic accuracy on the object, room, and floor\nlevel while producing a 75% reduction in representation size compared to dense\nopen-vocabulary maps. In order to prove the efficacy and generalization\ncapabilities of HOV-SG, we showcase successful long-horizon\nlanguage-conditioned robot navigation within real-world multi-storage\nenvironments. We provide code and trial video data at http://hovsg.github.io/.",
      "tldr_zh": "本文提出 HOV-SG，一种分层 open-vocabulary 3D 场景图映射方法，旨在解决现有机器人导航系统中大规模环境和抽象语言查询的挑战，通过整合 open-vocabulary 视觉基础模型构建包含 floor、room 和 object 概念的层次化场景图。 该框架支持多层建筑的机器人遍历，利用 cross-floor Voronoi graph 实现高效导航，并在三个数据集上实现了 object、room 和 floor 级别的语义准确性超越基线，同时将表示大小减少75%。 实验结果证明了 HOV-SG 的有效性和泛化能力，在真实世界多层环境中实现了成功的长horizon 语言条件机器人导航。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Code and video are available at http://hovsg.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2403.17846v2",
      "published_date": "2024-03-26 16:36:43 UTC",
      "updated_date": "2024-06-03 17:12:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:02:03.730338"
    },
    {
      "arxiv_id": "2403.17839v2",
      "title": "ReMamber: Referring Image Segmentation with Mamba Twister",
      "title_zh": "翻译失败",
      "authors": [
        "Yuhuan Yang",
        "Chaofan Ma",
        "Jiangchao Yao",
        "Zhun Zhong",
        "Ya Zhang",
        "Yanfeng Wang"
      ],
      "abstract": "Referring Image Segmentation~(RIS) leveraging transformers has achieved great\nsuccess on the interpretation of complex visual-language tasks. However, the\nquadratic computation cost makes it resource-consuming in capturing long-range\nvisual-language dependencies. Fortunately, Mamba addresses this with efficient\nlinear complexity in processing. However, directly applying Mamba to\nmulti-modal interactions presents challenges, primarily due to inadequate\nchannel interactions for the effective fusion of multi-modal data. In this\npaper, we propose ReMamber, a novel RIS architecture that integrates the power\nof Mamba with a multi-modal Mamba Twister block. The Mamba Twister explicitly\nmodels image-text interaction, and fuses textual and visual features through\nits unique channel and spatial twisting mechanism. We achieve competitive\nresults on three challenging benchmarks with a simple and efficient\narchitecture. Moreover, we conduct thorough analyses of ReMamber and discuss\nother fusion designs using Mamba. These provide valuable perspectives for\nfuture research. The code has been released at:\nhttps://github.com/yyh-rain-song/ReMamber.",
      "tldr_zh": "该论文提出 ReMamber，一种新型 Referring Image Segmentation (RIS) 架构，使用 Mamba 模型来解决 Transformer 在处理长距离视觉-语言依赖时的高计算成本问题。ReMamber 引入 Mamba Twister 块，通过显式的图像-文本交互和独特的通道与空间扭曲机制，实现多模态特征的有效融合。实验在三个挑战性基准上取得了竞争性结果，并对其他 Mamba 融合设计进行了深入分析，为未来研究提供宝贵视角。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "ECCV 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.17839v2",
      "published_date": "2024-03-26 16:27:37 UTC",
      "updated_date": "2024-07-25 02:08:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:02:14.206583"
    },
    {
      "arxiv_id": "2403.17827v2",
      "title": "DiffH2O: Diffusion-Based Synthesis of Hand-Object Interactions from Textual Descriptions",
      "title_zh": "翻译失败",
      "authors": [
        "Sammy Christen",
        "Shreyas Hampali",
        "Fadime Sener",
        "Edoardo Remelli",
        "Tomas Hodan",
        "Eric Sauser",
        "Shugao Ma",
        "Bugra Tekin"
      ],
      "abstract": "Generating natural hand-object interactions in 3D is challenging as the\nresulting hand and object motions are expected to be physically plausible and\nsemantically meaningful. Furthermore, generalization to unseen objects is\nhindered by the limited scale of available hand-object interaction datasets. In\nthis paper, we propose a novel method, dubbed DiffH2O, which can synthesize\nrealistic, one or two-handed object interactions from provided text prompts and\ngeometry of the object. The method introduces three techniques that enable\neffective learning from limited data. First, we decompose the task into a\ngrasping stage and an text-based manipulation stage and use separate diffusion\nmodels for each. In the grasping stage, the model only generates hand motions,\nwhereas in the manipulation phase both hand and object poses are synthesized.\nSecond, we propose a compact representation that tightly couples hand and\nobject poses and helps in generating realistic hand-object interactions. Third,\nwe propose two different guidance schemes to allow more control of the\ngenerated motions: grasp guidance and detailed textual guidance. Grasp guidance\ntakes a single target grasping pose and guides the diffusion model to reach\nthis grasp at the end of the grasping stage, which provides control over the\ngrasping pose. Given a grasping motion from this stage, multiple different\nactions can be prompted in the manipulation phase. For the textual guidance, we\ncontribute comprehensive text descriptions to the GRAB dataset and show that\nthey enable our method to have more fine-grained control over hand-object\ninteractions. Our quantitative and qualitative evaluation demonstrates that the\nproposed method outperforms baseline methods and leads to natural hand-object\nmotions.",
      "tldr_zh": "本文提出DiffH2O方法，利用diffusion-based模型从文本提示和物体几何合成真实的一手或两手3D手-物体交互，解决了现有数据集规模有限导致的泛化性问题。该方法将任务分解为抓取阶段（仅生成手部动作）和基于文本的操作阶段（生成手部及物体姿势），并引入紧耦合的姿势表示以及抓取指导和详细文本指导方案，以实现更精确的控制。为GRAB数据集添加了全面文本描述，实验结果显示DiffH2O在定性和定量评估中优于基线方法，生成更自然的交互动作。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Project Page: https://diffh2o.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2403.17827v2",
      "published_date": "2024-03-26 16:06:42 UTC",
      "updated_date": "2024-12-23 17:36:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:02:27.375933"
    },
    {
      "arxiv_id": "2403.17826v1",
      "title": "On the Computational Complexity of Stackelberg Planning and Meta-Operator Verification: Technical Report",
      "title_zh": "Stackelberg Planning 和 Meta-Operator Verification 的计算复杂度：技术报告",
      "authors": [
        "Gregor Behnke",
        "Marcel Steinmetz"
      ],
      "abstract": "Stackelberg planning is a recently introduced single-turn two-player\nadversarial planning model, where two players are acting in a joint classical\nplanning task, the objective of the first player being hampering the second\nplayer from achieving its goal. This places the Stackelberg planning problem\nsomewhere between classical planning and general combinatorial two-player\ngames. But, where exactly? All investigations of Stackelberg planning so far\nfocused on practical aspects. We close this gap by conducting the first\ntheoretical complexity analysis of Stackelberg planning. We show that in\ngeneral Stackelberg planning is actually no harder than classical planning.\nUnder a polynomial plan-length restriction, however, Stackelberg planning is a\nlevel higher up in the polynomial complexity hierarchy, suggesting that\ncompilations into classical planning come with a worst-case exponential\nplan-length increase. In attempts to identify tractable fragments, we further\nstudy its complexity under various planning task restrictions, showing that\nStackelberg planning remains intractable where classical planning is not. We\nfinally inspect the complexity of meta-operator verification, a problem that\nhas been recently connected to Stackelberg planning.",
      "tldr_zh": "这篇论文首次对 Stackelberg planning 的计算复杂性进行了理论分析，将其定位于经典 planning 和一般组合两玩家游戏之间。研究发现，在一般情况下，Stackelberg planning 的复杂性不高于 classical planning；但在多项式计划长度限制下，它在多项式复杂性层次中高一级，可能导致编译成 classical planning 时计划长度指数级增加。论文进一步探讨了各种规划任务限制下的复杂性，发现 Stackelberg planning 在 classical planning 易处理的场景中仍保持 intractable。最后，它还分析了 meta-operator verification 的复杂性，该问题与 Stackelberg planning 相关联。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Presented at ICAPS24",
      "pdf_url": "http://arxiv.org/pdf/2403.17826v1",
      "published_date": "2024-03-26 16:06:33 UTC",
      "updated_date": "2024-03-26 16:06:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:02:37.445857"
    },
    {
      "arxiv_id": "2403.17819v1",
      "title": "Accelerating Radio Spectrum Regulation Workflows with Large Language Models (LLMs)",
      "title_zh": "翻译失败",
      "authors": [
        "Amir Ghasemi",
        "Paul Guinand"
      ],
      "abstract": "Wireless spectrum regulation is a complex and demanding process due to the\nrapid pace of technological progress, increasing demand for spectrum, and a\nmultitude of stakeholders with potentially conflicting interests, alongside\nsignificant economic implications. To navigate this, regulators must engage\neffectively with all parties, keep pace with global technology trends, conduct\ntechnical evaluations, issue licenses in a timely manner, and comply with\nvarious legal and policy frameworks.\n  In light of these challenges, this paper demonstrates example applications of\nLarge Language Models (LLMs) to expedite spectrum regulatory processes. We\nexplore various roles that LLMs can play in this context while identifying some\nof the challenges to address. The paper also offers practical case studies and\ninsights, with appropriate experiments, highlighting the transformative\npotential of LLMs in spectrum management.",
      "tldr_zh": "这篇论文探讨了无线频谱监管的复杂挑战，包括快速技术进步、多方利益冲突和经济影响，并提出利用 Large Language Models (LLMs) 来加速监管流程。作者分析了 LLMs 在监管中的多种角色，如辅助各方沟通、技术评估和许可证发放，同时识别了潜在挑战。论文通过实际案例研究和实验，展示了 LLMs 在频谱管理中的变革潜力，有望提升监管效率和及时性。",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.17819v1",
      "published_date": "2024-03-26 15:54:48 UTC",
      "updated_date": "2024-03-26 15:54:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:02:49.144916"
    },
    {
      "arxiv_id": "2403.17814v1",
      "title": "D-PAD: Deep-Shallow Multi-Frequency Patterns Disentangling for Time Series Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaobing Yuan",
        "Ling Chen"
      ],
      "abstract": "In time series forecasting, effectively disentangling intricate temporal\npatterns is crucial. While recent works endeavor to combine decomposition\ntechniques with deep learning, multiple frequencies may still be mixed in the\ndecomposed components, e.g., trend and seasonal. Furthermore, frequency domain\nanalysis methods, e.g., Fourier and wavelet transforms, have limitations in\nresolution in the time domain and adaptability. In this paper, we propose\nD-PAD, a deep-shallow multi-frequency patterns disentangling neural network for\ntime series forecasting. Specifically, a multi-component decomposing (MCD)\nblock is introduced to decompose the series into components with different\nfrequency ranges, corresponding to the \"shallow\" aspect. A\ndecomposition-reconstruction-decomposition (D-R-D) module is proposed to\nprogressively extract the information of frequencies mixed in the components,\ncorresponding to the \"deep\" aspect. After that, an interaction and fusion (IF)\nmodule is used to further analyze the components. Extensive experiments on\nseven real-world datasets demonstrate that D-PAD achieves the state-of-the-art\nperformance, outperforming the best baseline by an average of 9.48% and 7.15%\nin MSE and MAE, respectively.",
      "tldr_zh": "本论文提出D-PAD框架，用于时间序列预测中的多频率模式分离，旨在解决现有分解技术和频率域方法（如Fourier和wavelet transforms）在时间域分辨率和适应性上的局限。D-PAD结合“浅”层多组件分解(MCD)块来分解序列成不同频率范围的组件，以及“深”层分解-重建-分解(D-R-D)模块来逐步提取混合频率信息，并通过交互和融合(IF)模块进一步分析这些组件。在七个真实数据集上的广泛实验表明，D-PAD在MSE和MAE上分别比最佳基线平均提高了9.48%和7.15%，实现了最先进性能。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.17814v1",
      "published_date": "2024-03-26 15:52:36 UTC",
      "updated_date": "2024-03-26 15:52:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:03:05.668715"
    },
    {
      "arxiv_id": "2403.17787v2",
      "title": "Evaluating the Efficacy of Prompt-Engineered Large Multimodal Models Versus Fine-Tuned Vision Transformers in Image-Based Security Applications",
      "title_zh": "翻译失败",
      "authors": [
        "Fouad Trad",
        "Ali Chehab"
      ],
      "abstract": "The success of Large Language Models (LLMs) has led to a parallel rise in the\ndevelopment of Large Multimodal Models (LMMs), which have begun to transform a\nvariety of applications. These sophisticated multimodal models are designed to\ninterpret and analyze complex data by integrating multiple modalities such as\ntext and images, thereby opening new avenues for a range of applications. This\npaper investigates the applicability and effectiveness of prompt-engineered\nLMMs that process both images and text, including models such as LLaVA,\nBakLLaVA, Moondream, Gemini-pro-vision, and GPT-4o, compared to fine-tuned\nVision Transformer (ViT) models in addressing critical security challenges. We\nfocus on two distinct security tasks: 1) a visually evident task of detecting\nsimple triggers, such as small pixel variations in images that could be\nexploited to access potential backdoors in the models, and 2) a visually\nnon-evident task of malware classification through visual representations. In\nthe visually evident task, some LMMs, such as Gemini-pro-vision and GPT-4o,\nhave demonstrated the potential to achieve good performance with careful prompt\nengineering, with GPT-4o achieving the highest accuracy and F1-score of 91.9\\%\nand 91\\%, respectively. However, the fine-tuned ViT models exhibit perfect\nperformance in this task due to its simplicity. For the visually non-evident\ntask, the results highlight a significant divergence in performance, with ViT\nmodels achieving F1-scores of 97.11\\% in predicting 25 malware classes and\n97.61\\% in predicting 5 malware families, whereas LMMs showed suboptimal\nperformance despite iterative prompt improvements. This study not only\nshowcases the strengths and limitations of prompt-engineered LMMs in\ncybersecurity applications but also emphasizes the unmatched efficacy of\nfine-tuned ViT models for precise and dependable tasks.",
      "tldr_zh": "这篇论文评估了提示工程的 Large Multimodal Models (LMMs)，如 LLaVA 和 GPT-4o，与微调的 Vision Transformers (ViT) 模型在图像安全应用中的效能，焦点任务包括检测视觉触发器（如像素变化）和恶意软件分类。研究发现，在简单任务中，某些 LMMs 通过精心提示工程实现了高性能，例如 GPT-4o 的准确率和 F1-score 分别达到 91.9% 和 91%。然而，在复杂任务如恶意软件分类中，微调的 ViT 模型表现出压倒性优势，F1-score 达 97.11% 和 97.61%，而 LMMs 的表现仍 suboptimal。该研究强调了 LMMs 的潜力及其局限性，并突出了 Fine-Tuned ViT 在精确、安全任务中的可靠性。",
      "categories": [
        "cs.AI",
        "cs.CR",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.17787v2",
      "published_date": "2024-03-26 15:20:49 UTC",
      "updated_date": "2024-06-10 10:07:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:03:17.894815"
    },
    {
      "arxiv_id": "2403.17784v1",
      "title": "SciCapenter: Supporting Caption Composition for Scientific Figures with Machine-Generated Captions and Ratings",
      "title_zh": "SciCapenter：利用机器生成标题和评级支持科学图形标题撰写",
      "authors": [
        "Ting-Yao Hsu",
        "Chieh-Yang Huang",
        "Shih-Hong Huang",
        "Ryan Rossi",
        "Sungchul Kim",
        "Tong Yu",
        "C. Lee Giles",
        "Ting-Hao K. Huang"
      ],
      "abstract": "Crafting effective captions for figures is important. Readers heavily depend\non these captions to grasp the figure's message. However, despite a\nwell-developed set of AI technologies for figures and captions, these have\nrarely been tested for usefulness in aiding caption writing. This paper\nintroduces SciCapenter, an interactive system that puts together cutting-edge\nAI technologies for scientific figure captions to aid caption composition.\nSciCapenter generates a variety of captions for each figure in a scholarly\narticle, providing scores and a comprehensive checklist to assess caption\nquality across multiple critical aspects, such as helpfulness, OCR mention, key\ntakeaways, and visual properties reference. Users can directly edit captions in\nSciCapenter, resubmit for revised evaluations, and iteratively refine them. A\nuser study with Ph.D. students indicates that SciCapenter significantly lowers\nthe cognitive load of caption writing. Participants' feedback further offers\nvaluable design insights for future systems aiming to enhance caption writing.",
      "tldr_zh": "本文介绍了SciCapenter，一种交互式系统，利用AI技术辅助科学图表的标题撰写，通过生成多种标题、提供评分和全面检查列表（如helpfulness、OCR mention、key takeaways和visual properties reference）来评估标题质量。用户可在系统中直接编辑标题、重新提交以获取修订评估，并进行迭代优化。研究结果显示，SciCapenter显著降低了博士生在标题撰写中的认知负担，并为未来类似系统提供了宝贵的设计见解。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "CHI EA '24: Extended Abstracts of the 2024 CHI Conference on Human\n  Factors in Computing Systems",
      "pdf_url": "http://arxiv.org/pdf/2403.17784v1",
      "published_date": "2024-03-26 15:16:14 UTC",
      "updated_date": "2024-03-26 15:16:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:03:27.851787"
    },
    {
      "arxiv_id": "2403.17778v2",
      "title": "Towards a FAIR Documentation of Workflows and Models in Applied Mathematics",
      "title_zh": "翻译失败",
      "authors": [
        "Marco Reidelbach",
        "Björn Schembera",
        "Marcus Weber"
      ],
      "abstract": "Modeling-Simulation-Optimization workflows play a fundamental role in applied\nmathematics. The Mathematical Research Data Initiative, MaRDI, responded to\nthis by developing a FAIR and machine-interpretable template for a\ncomprehensive documentation of such workflows. MaRDMO, a Plugin for the\nResearch Data Management Organiser, enables scientists from diverse fields to\ndocument and publish their workflows on the MaRDI Portal seamlessly using the\nMaRDI template. Central to these workflows are mathematical models. MaRDI\naddresses them with the MathModDB ontology, offering a structured formal model\ndescription. Here, we showcase the interaction between MaRDMO and the MathModDB\nKnowledge Graph through an algebraic modeling workflow from the Digital\nHumanities. This demonstration underscores the versatility of both services\nbeyond their original numerical domain.",
      "tldr_zh": "本研究旨在提升应用数学中 Modeling-Simulation-Optimization 工作流的文档化标准，MaRDI 倡议开发了一个 FAIR 和机器可解释的模板，以实现全面记录和发布。MaRDMO 插件作为关键工具，允许科学家无缝地在 MaRDI Portal 上使用该模板记录工作流，同时 MathModDB 本体提供结构化的数学模型描述。研究通过一个数字人文领域的代数建模工作流展示了 MaRDMO 与 MathModDB Knowledge Graph 的交互，证明了这些服务在非数值领域的通用性和灵活性。",
      "categories": [
        "cs.AI",
        "cs.DB",
        "cs.DL",
        "H.3.3; H.3.7; E.0"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.17778v2",
      "published_date": "2024-03-26 15:11:18 UTC",
      "updated_date": "2024-07-31 08:19:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:03:37.870988"
    },
    {
      "arxiv_id": "2403.17768v2",
      "title": "SciNews: From Scholarly Complexities to Public Narratives -- A Dataset for Scientific News Report Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Dongqi Liu",
        "Yifan Wang",
        "Jia Loy",
        "Vera Demberg"
      ],
      "abstract": "Scientific news reports serve as a bridge, adeptly translating complex\nresearch articles into reports that resonate with the broader public. The\nautomated generation of such narratives enhances the accessibility of scholarly\ninsights. In this paper, we present a new corpus to facilitate this paradigm\ndevelopment. Our corpus comprises a parallel compilation of academic\npublications and their corresponding scientific news reports across nine\ndisciplines. To demonstrate the utility and reliability of our dataset, we\nconduct an extensive analysis, highlighting the divergences in readability and\nbrevity between scientific news narratives and academic manuscripts. We\nbenchmark our dataset employing state-of-the-art text generation models. The\nevaluation process involves both automatic and human evaluation, which lays the\ngroundwork for future explorations into the automated generation of scientific\nnews reports. The dataset and code related to this work are available at\nhttps://dongqi.me/projects/SciNews.",
      "tldr_zh": "本研究介绍了SciNews数据集，该数据集旨在桥接学术复杂性和公众叙事，通过提供平行编译的学术出版物及其对应的科学新闻报道，覆盖九个学科。该数据集突出了科学新闻报道在可读性和简洁性上与学术手稿的差异，并通过最先进的文本生成模型进行基准测试，包括自动和人工评估，以促进科学新闻报道的自动化生成。实验结果为未来探索学术见解的可访问性奠定了基础，相关数据集和代码可从https://dongqi.me/projects/SciNews获取。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "LREC-COLING 2024 Main Conference Paper",
      "pdf_url": "http://arxiv.org/pdf/2403.17768v2",
      "published_date": "2024-03-26 14:54:48 UTC",
      "updated_date": "2024-12-10 09:12:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:03:50.612045"
    },
    {
      "arxiv_id": "2403.17995v1",
      "title": "Semi-Supervised Image Captioning Considering Wasserstein Graph Matching",
      "title_zh": "翻译失败",
      "authors": [
        "Yang Yang"
      ],
      "abstract": "Image captioning can automatically generate captions for the given images,\nand the key challenge is to learn a mapping function from visual features to\nnatural language features. Existing approaches are mostly supervised ones,\ni.e., each image has a corresponding sentence in the training set. However,\nconsidering that describing images always requires a huge of manpower, we\nusually have limited amount of described images (i.e., image-text pairs) and a\nlarge number of undescribed images in real-world applications. Thereby, a\ndilemma is the \"Semi-Supervised Image Captioning\". To solve this problem, we\npropose a novel Semi-Supervised Image Captioning method considering Wasserstein\nGraph Matching (SSIC-WGM), which turns to adopt the raw image inputs to\nsupervise the generated sentences. Different from traditional single modal\nsemi-supervised methods, the difficulty of semi-supervised cross-modal learning\nlies in constructing intermediately comparable information among heterogeneous\nmodalities. In this paper, SSIC-WGM adopts the successful scene graphs as\nintermediate information, and constrains the generated sentences from two\naspects: 1) inter-modal consistency. SSIC-WGM constructs the scene graphs of\nthe raw image and generated sentence respectively, then employs the wasserstein\ndistance to better measure the similarity between region embeddings of\ndifferent graphs. 2) intra-modal consistency. SSIC-WGM takes the data\naugmentation techniques for the raw images, then constrains the consistency\namong augmented images and generated sentences. Consequently, SSIC-WGM combines\nthe cross-modal pseudo supervision and structure invariant measure for\nefficiently using the undescribed images, and learns more reasonable mapping\nfunction.",
      "tldr_zh": "该论文针对图像字幕生成（Image Captioning）中的数据标注难题，提出了一种半监督方法SSIC-WGM（Semi-Supervised Image Captioning considering Wasserstein Graph Matching），旨在利用大量未标注图像来提升模型性能。SSIC-WGM 通过构建场景图（scene graphs）作为中间信息，从两个方面约束生成的句子：一是跨模态一致性（inter-modal consistency），使用Wasserstein距离测量图像和句子图中区域嵌入的相似性；二是模态内一致性（intra-modal consistency），通过数据增强技术确保增强图像与生成句子的稳定性。该方法结合跨模态伪监督和结构不变性测量，高效利用未标注数据，学习更合理的视觉到语言映射函数，从而改善图像字幕生成的实际应用效果。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.17995v1",
      "published_date": "2024-03-26 14:47:05 UTC",
      "updated_date": "2024-03-26 14:47:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:04:03.106788"
    },
    {
      "arxiv_id": "2403.17755v1",
      "title": "DataCook: Crafting Anti-Adversarial Examples for Healthcare Data Copyright Protection",
      "title_zh": "翻译失败",
      "authors": [
        "Sihan Shang",
        "Jiancheng Yang",
        "Zhenglong Sun",
        "Pascal Fua"
      ],
      "abstract": "In the realm of healthcare, the challenges of copyright protection and\nunauthorized third-party misuse are increasingly significant. Traditional\nmethods for data copyright protection are applied prior to data distribution,\nimplying that models trained on these data become uncontrollable. This paper\nintroduces a novel approach, named DataCook, designed to safeguard the\ncopyright of healthcare data during the deployment phase. DataCook operates by\n\"cooking\" the raw data before distribution, enabling the development of models\nthat perform normally on this processed data. However, during the deployment\nphase, the original test data must be also \"cooked\" through DataCook to ensure\nnormal model performance. This process grants copyright holders control over\nauthorization during the deployment phase. The mechanism behind DataCook is by\ncrafting anti-adversarial examples (AntiAdv), which are designed to enhance\nmodel confidence, as opposed to standard adversarial examples (Adv) that aim to\nconfuse models. Similar to Adv, AntiAdv introduces imperceptible perturbations,\nensuring that the data processed by DataCook remains easily understandable. We\nconducted extensive experiments on MedMNIST datasets, encompassing both 2D/3D\ndata and the high-resolution variants. The outcomes indicate that DataCook\neffectively meets its objectives, preventing models trained on AntiAdv from\nanalyzing unauthorized data effectively, without compromising the validity and\naccuracy of the data in legitimate scenarios. Code and data are available at\nhttps://github.com/MedMNIST/DataCook.",
      "tldr_zh": "该论文提出了一种名为DataCook的创新方法，用于在医疗数据部署阶段保护版权，解决传统方法在数据分发后模型不可控的问题。DataCook通过“烹饪”原始数据生成反对抗样本（AntiAdv），这些样本引入不易察觉的扰动来增强模型信心，从而确保未经授权的数据无法正常分析。实验在MedMNIST数据集（包括2D/3D和高分辨率变体）上验证，DataCook有效防止模型在非法场景下处理数据，同时在合法场景中保持数据准确性和有效性。",
      "categories": [
        "cs.AI",
        "cs.CR",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.17755v1",
      "published_date": "2024-03-26 14:44:51 UTC",
      "updated_date": "2024-03-26 14:44:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:04:13.755077"
    },
    {
      "arxiv_id": "2403.17742v1",
      "title": "Using Stratified Sampling to Improve LIME Image Explanations",
      "title_zh": "翻译失败",
      "authors": [
        "Muhammad Rashid",
        "Elvio G. Amparore",
        "Enrico Ferrari",
        "Damiano Verda"
      ],
      "abstract": "We investigate the use of a stratified sampling approach for LIME Image, a\npopular model-agnostic explainable AI method for computer vision tasks, in\norder to reduce the artifacts generated by typical Monte Carlo sampling. Such\nartifacts are due to the undersampling of the dependent variable in the\nsynthetic neighborhood around the image being explained, which may result in\ninadequate explanations due to the impossibility of fitting a linear regressor\non the sampled data. We then highlight a connection with the Shapley theory,\nwhere similar arguments about undersampling and sample relevance were suggested\nin the past. We derive all the formulas and adjustment factors required for an\nunbiased stratified sampling estimator. Experiments show the efficacy of the\nproposed approach.",
      "tldr_zh": "本文提出了一种使用分层采样(stratified sampling)的方法来改进 LIME Image，这是一种流行的模型无关可解释 AI 技术，用于减少 Monte Carlo 采样导致的 artifacts，这些 artifacts 源于图像周围合成邻域中因变量的欠采样，从而影响线性回归器的拟合。研究者突出了这一问题与 Shapley 理论的联系，并导出了无偏分层采样估计器的所有公式和调整因素。实验结果证明，该方法在提升解释准确性和可靠性方面表现出显著效果。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.17742v1",
      "published_date": "2024-03-26 14:30:23 UTC",
      "updated_date": "2024-03-26 14:30:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:04:27.558682"
    },
    {
      "arxiv_id": "2403.17740v3",
      "title": "All-in-One: Heterogeneous Interaction Modeling for Cold-Start Rating Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Shuheng Fang",
        "Kangfei Zhao",
        "Yu Rong",
        "Zhixun Li",
        "Jeffrey Xu Yu"
      ],
      "abstract": "Cold-start rating prediction is a fundamental problem in recommender systems\nthat has been extensively studied. Many methods have been proposed that exploit\nexplicit relations among existing data, such as collaborative filtering, social\nrecommendations and heterogeneous information network, to alleviate the data\ninsufficiency issue for cold-start users and items. However, the explicit\nrelations constructed based on data between different roles may be unreliable\nand irrelevant, which limits the performance ceiling of the specific\nrecommendation task. Motivated by this, in this paper, we propose a flexible\nframework dubbed heterogeneous interaction rating network (HIRE). HIRE dose not\nsolely rely on the pre-defined interaction pattern or the manually constructed\nheterogeneous information network. Instead, we devise a Heterogeneous\nInteraction Module (HIM) to jointly model the heterogeneous interactions and\ndirectly infer the important interactions via the observed data. In the\nexperiments, we evaluate our model under three cold-start settings on three\nreal-world datasets. The experimental results show that HIRE outperforms other\nbaselines by a large margin. Furthermore, we visualize the inferred\ninteractions of HIRE to confirm the contribution of our model.",
      "tldr_zh": "这篇论文针对推荐系统中的冷启动评分预测（cold-start rating prediction）问题，提出了一种灵活框架HIRE（Heterogeneous Interaction Rating Network）。HIRE通过其Heterogeneous Interaction Module (HIM)联合建模异构交互，并基于观察数据直接推断重要交互，而非依赖预定义的交互模式或手动构建的异构信息网络。实验在三个真实数据集和三种冷启动设置上表明，HIRE大幅优于基线模型，并通过可视化结果验证了其建模贡献。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "14 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.17740v3",
      "published_date": "2024-03-26 14:29:34 UTC",
      "updated_date": "2024-12-06 05:26:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:04:39.192931"
    },
    {
      "arxiv_id": "2403.17735v1",
      "title": "Out-of-distribution Rumor Detection via Test-Time Adaptation",
      "title_zh": "翻译失败",
      "authors": [
        "Xiang Tao",
        "Mingqing Zhang",
        "Qiang Liu",
        "Shu Wu",
        "Liang Wang"
      ],
      "abstract": "Due to the rapid spread of rumors on social media, rumor detection has become\nan extremely important challenge. Existing methods for rumor detection have\nachieved good performance, as they have collected enough corpus from the same\ndata distribution for model training. However, significant distribution shifts\nbetween the training data and real-world test data occur due to differences in\nnews topics, social media platforms, languages and the variance in propagation\nscale caused by news popularity. This leads to a substantial decline in the\nperformance of these existing methods in Out-Of-Distribution (OOD) situations.\nTo address this problem, we propose a simple and efficient method named\nTest-time Adaptation for Rumor Detection under distribution shifts (TARD). This\nmethod models the propagation of news in the form of a propagation graph, and\nbuilds propagation graph test-time adaptation framework, enhancing the model's\nadaptability and robustness when facing OOD problems. Extensive experiments\nconducted on two group datasets collected from real-world social platforms\ndemonstrate that our framework outperforms the state-of-the-art methods in\nperformance.",
      "tldr_zh": "现有谣言检测方法在Out-Of-Distribution (OOD) 场景下，由于新闻主题、社交平台、语言和传播规模的差异，导致性能显著下降。为解决这一问题，本文提出TARD（Test-time Adaptation for Rumor Detection under distribution shifts）方法，通过建模新闻传播图并构建测试时适应框架，提升模型的适应性和鲁棒性。实验在两个真实社交平台数据集上表明，TARD 框架的表现优于最先进方法。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.17735v1",
      "published_date": "2024-03-26 14:24:01 UTC",
      "updated_date": "2024-03-26 14:24:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:04:51.840199"
    },
    {
      "arxiv_id": "2403.17726v4",
      "title": "Tiny Models are the Computational Saver for Large Models",
      "title_zh": "小型模型是大型模型的计算节省器",
      "authors": [
        "Qingyuan Wang",
        "Barry Cardiff",
        "Antoine Frappé",
        "Benoit Larras",
        "Deepu John"
      ],
      "abstract": "This paper introduces TinySaver, an early-exit-like dynamic model compression\napproach which employs tiny models to substitute large models adaptively.\nDistinct from traditional compression techniques, dynamic methods like\nTinySaver can leverage the difficulty differences to allow certain inputs to\ncomplete their inference processes early, thereby conserving computational\nresources. Most existing early exit designs are implemented by attaching\nadditional network branches to the model's backbone. Our study, however,\nreveals that completely independent tiny models can replace a substantial\nportion of the larger models' job with minimal impact on performance. Employing\nthem as the first exit can remarkably enhance computational efficiency. By\nsearching and employing the most appropriate tiny model as the computational\nsaver for a given large model, the proposed approaches work as a novel and\ngeneric method to model compression. This finding will help the research\ncommunity in exploring new compression methods to address the escalating\ncomputational demands posed by rapidly evolving AI models. Our evaluation of\nthis approach in ImageNet-1k classification demonstrates its potential to\nreduce the number of compute operations by up to 90\\%, with only negligible\nlosses in performance, across various modern vision models.",
      "tldr_zh": "本研究提出TinySaver，一种动态模型压缩方法，使用tiny models来适配性地替换large models，从而节省计算资源。该方法不同于传统early-exit设计，而是采用完全独立的tiny models作为first exit，利用输入难度差异让部分推理提前完成，同时保持性能影响最小。通过搜索最合适的tiny model，TinySaver为large models提供了一种通用压缩策略，帮助缓解AI模型计算需求的增长。在ImageNet-1k分类任务上，该方法可减少高达90%的计算操作，而性能损失微不足道。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.17726v4",
      "published_date": "2024-03-26 14:14:30 UTC",
      "updated_date": "2025-01-13 12:38:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:05:05.739095"
    },
    {
      "arxiv_id": "2403.17710v4",
      "title": "Optimization-based Prompt Injection Attack to LLM-as-a-Judge",
      "title_zh": "翻译失败",
      "authors": [
        "Jiawen Shi",
        "Zenghui Yuan",
        "Yinuo Liu",
        "Yue Huang",
        "Pan Zhou",
        "Lichao Sun",
        "Neil Zhenqiang Gong"
      ],
      "abstract": "LLM-as-a-Judge uses a large language model (LLM) to select the best response\nfrom a set of candidates for a given question. LLM-as-a-Judge has many\napplications such as LLM-powered search, reinforcement learning with AI\nfeedback (RLAIF), and tool selection. In this work, we propose JudgeDeceiver,\nan optimization-based prompt injection attack to LLM-as-a-Judge. JudgeDeceiver\ninjects a carefully crafted sequence into an attacker-controlled candidate\nresponse such that LLM-as-a-Judge selects the candidate response for an\nattacker-chosen question no matter what other candidate responses are.\nSpecifically, we formulate finding such sequence as an optimization problem and\npropose a gradient based method to approximately solve it. Our extensive\nevaluation shows that JudgeDeceive is highly effective, and is much more\neffective than existing prompt injection attacks that manually craft the\ninjected sequences and jailbreak attacks when extended to our problem. We also\nshow the effectiveness of JudgeDeceiver in three case studies, i.e.,\nLLM-powered search, RLAIF, and tool selection. Moreover, we consider defenses\nincluding known-answer detection, perplexity detection, and perplexity windowed\ndetection. Our results show these defenses are insufficient, highlighting the\nurgent need for developing new defense strategies. Our implementation is\navailable at this repository: https://github.com/ShiJiawenwen/JudgeDeceiver.",
      "tldr_zh": "这篇论文提出了JudgeDeceiver，一种针对LLM-as-a-Judge的基于优化的prompt injection attack，用于操纵大语言模型（LLM）从候选响应中选择攻击者指定的响应，无论其他选项如何。研究者将攻击问题形式化为优化问题，并采用梯度-based方法来生成精心设计的注入序列，使其比手动crafted的prompt injection attack和扩展的jailbreak attacks更有效。实验结果显示，JudgeDeceiver在LLM-powered search、RLAIF和tool selection等应用场景中表现出高有效性，并成功规避了known-answer detection、perplexity detection等防御措施。论文强调了这些发现突显了开发新防御策略的迫切需求，并提供了开源实现。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "To appear in the Proceedings of The ACM Conference on Computer and\n  Communications Security (CCS), 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.17710v4",
      "published_date": "2024-03-26 13:58:00 UTC",
      "updated_date": "2025-03-03 03:36:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:05:19.828177"
    },
    {
      "arxiv_id": "2403.17706v2",
      "title": "A Large Language Model Guided Topic Refinement Mechanism for Short Text Modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Shuyu Chang",
        "Rui Wang",
        "Peng Ren",
        "Qi Wang",
        "Haiping Huang"
      ],
      "abstract": "Modeling topics effectively in short texts, such as tweets and news snippets,\nis crucial to capturing rapidly evolving social trends. Existing topic models\noften struggle to accurately capture the underlying semantic patterns of short\ntexts, primarily due to the sparse nature of such data. This nature of texts\nleads to an unavoidable lack of co-occurrence information, which hinders the\ncoherence and granularity of mined topics. This paper introduces a novel\nmodel-agnostic mechanism, termed Topic Refinement, which leverages the advanced\ntext comprehension capabilities of Large Language Models (LLMs) for short-text\ntopic modeling. Unlike traditional methods, this post-processing mechanism\nenhances the quality of topics extracted by various topic modeling methods\nthrough prompt engineering. We guide LLMs in identifying semantically intruder\nwords within the extracted topics and suggesting coherent alternatives to\nreplace these words. This process mimics human-like identification, evaluation,\nand refinement of the extracted topics. Extensive experiments on four diverse\ndatasets demonstrate that Topic Refinement boosts the topic quality and\nimproves the performance in topic-related text classification tasks.",
      "tldr_zh": "本研究针对短文本（如推文和新闻片段）的主题建模问题，指出现有模型因数据稀疏导致共现信息不足，影响主题的连贯性和粒度。论文提出一个模型无关的 Topic Refinement 机制，利用 Large Language Models (LLMs) 通过 prompt engineering 识别提取主题中的 semantically intruder words，并建议连贯的替代词汇，以模拟人类式的主题精炼过程。该机制显著提升了主题质量，并在四个多样化数据集上的实验中，改善了主题相关文本分类任务的性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Extended version of paper accepted at DASFAA 2025 (16 pages, 6\n  figures)",
      "pdf_url": "http://arxiv.org/pdf/2403.17706v2",
      "published_date": "2024-03-26 13:50:34 UTC",
      "updated_date": "2025-02-16 14:36:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:05:29.568665"
    },
    {
      "arxiv_id": "2403.17698v1",
      "title": "MEP: Multiple Kernel Learning Enhancing Relative Positional Encoding Length Extrapolation",
      "title_zh": "MEP：多核学习增强相对位置编码",
      "authors": [
        "Weiguo Gao"
      ],
      "abstract": "When the predicted sequence length exceeds the length seen during training,\nthe transformer's inference accuracy diminishes. Existing relative position\nencoding methods, such as those based on the ALiBi technique, address the\nlength extrapolation challenge exclusively through the implementation of a\nsingle kernel function, which introduces a constant bias to every post-softmax\nattention scores according to their distance. These approaches do not\ninvestigate or employ multiple kernel functions to address the extrapolation\nchallenge. Drawing on the ALiBi approach, this study proposes a novel relative\npositional encoding method, called MEP, which employs a weighted average to\ncombine distinct kernel functions(such as the exponential kernel and the\nGaussian kernel) to generate a bias that is applied to post-softmax attention\nscores. Initially, the framework utilizes various kernel functions to construct\nmultiple kernel functions. Each kernel function adheres to a consistent mean\nweight coefficient, harnessing the synergistic advantages of different kernels\nto formulate an innovative bias function. Subsequently, specific slopes are\ntailored for each kernel function, applying penalties at varying rates, to\nenhance the model's extrapolation capabilities. Finally, this bias is\nseamlessly incorporated as a penalty to the post-softmax scores. We present two\ndistinct versions of our method: a parameter-free variant that requires no new\nlearnable parameters, which enhances length extrapolation capabilities without\ncompromising training efficiency, and a parameterized variant capable of\nintegrating state-of-the-art techniques. Empirical evaluations across diverse\ndatasets have demonstrated that both variants of our method achieve\nstate-of-the-art performance, outperforming traditional parameter-free and\nparameterized approaches.",
      "tldr_zh": "本文提出 MEP 方法，通过结合多个 kernel functions（如 exponential kernel 和 Gaussian kernel）的加权平均，生成一个应用于 post-softmax attention scores 的偏差，以增强 Transformer 的相对位置编码长度外推能力。MEP 框架首先构建多个 kernel functions，每个函数具有一致的均值权重系数和定制 slopes，以优化外推性能；该方法提供无参数版本（不引入新参数，提高效率）和参数化版本（可整合先进技术）。实验结果显示，MEP 在多种数据集上均超越传统方法，实现了最先进性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.17698v1",
      "published_date": "2024-03-26 13:38:06 UTC",
      "updated_date": "2024-03-26 13:38:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:05:41.847819"
    },
    {
      "arxiv_id": "2403.17693v1",
      "title": "ExpressEdit: Video Editing with Natural Language and Sketching",
      "title_zh": "翻译失败",
      "authors": [
        "Bekzat Tilekbay",
        "Saelyne Yang",
        "Michal Lewkowicz",
        "Alex Suryapranata",
        "Juho Kim"
      ],
      "abstract": "Informational videos serve as a crucial source for explaining conceptual and\nprocedural knowledge to novices and experts alike. When producing informational\nvideos, editors edit videos by overlaying text/images or trimming footage to\nenhance the video quality and make it more engaging. However, video editing can\nbe difficult and time-consuming, especially for novice video editors who often\nstruggle with expressing and implementing their editing ideas. To address this\nchallenge, we first explored how multimodality$-$natural language (NL) and\nsketching, which are natural modalities humans use for expression$-$can be\nutilized to support video editors in expressing video editing ideas. We\ngathered 176 multimodal expressions of editing commands from 10 video editors,\nwhich revealed the patterns of use of NL and sketching in describing edit\nintents. Based on the findings, we present ExpressEdit, a system that enables\nediting videos via NL text and sketching on the video frame. Powered by LLM and\nvision models, the system interprets (1) temporal, (2) spatial, and (3)\noperational references in an NL command and spatial references from sketching.\nThe system implements the interpreted edits, which then the user can iterate\non. An observational study (N=10) showed that ExpressEdit enhanced the ability\nof novice video editors to express and implement their edit ideas. The system\nallowed participants to perform edits more efficiently and generate more ideas\nby generating edits based on user's multimodal edit commands and supporting\niterations on the editing commands. This work offers insights into the design\nof future multimodal interfaces and AI-based pipelines for video editing.",
      "tldr_zh": "该研究针对信息视频编辑的挑战，提出ExpressEdit系统，利用自然语言 (NL) 和绘图等多模态方式，帮助编辑者更高效地表达和实现编辑想法。通过分析176个多模态编辑命令，系统基于LLM和视觉模型解释NL中的时间、空间和操作引用，以及绘图中的空间引用，并自动实施编辑。实验结果显示，在10名新手编辑者的观察性研究中，ExpressEdit显著提升了编辑效率、创意生成和迭代能力，为未来多模态界面和AI视频编辑管道的设计提供了宝贵见解。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "22 pages, 5 figures, to be published in ACM IUI 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.17693v1",
      "published_date": "2024-03-26 13:34:21 UTC",
      "updated_date": "2024-03-26 13:34:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:05:53.316738"
    },
    {
      "arxiv_id": "2403.17683v2",
      "title": "Solution for Emotion Prediction Competition of Workshop on Emotionally and Culturally Intelligent AI",
      "title_zh": "翻译失败",
      "authors": [
        "Shengdong Xu",
        "Zhouyang Chi",
        "Yang Yang"
      ],
      "abstract": "This report provide a detailed description of the method that we explored and\nproposed in the WECIA Emotion Prediction Competition (EPC), which predicts a\nperson's emotion through an artistic work with a comment. The dataset of this\ncompetition is ArtELingo, designed to encourage work on diversity across\nlanguages and cultures. The dataset has two main challenges, namely modal\nimbalance problem and language-cultural differences problem. In order to\naddress this issue, we propose a simple yet effective approach called\nsingle-multi modal with Emotion-Cultural specific prompt(ECSP), which focuses\non using the single modal message to enhance the performance of multimodal\nmodels and a well-designed prompt to reduce cultural differences problem. To\nclarify, our approach contains two main blocks:\n(1)XLM-R\\cite{conneau2019unsupervised} based unimodal model and\nX$^2$-VLM\\cite{zeng2022x} based multimodal model (2) Emotion-Cultural specific\nprompt. Our approach ranked first in the final test with a score of 0.627.",
      "tldr_zh": "这篇论文针对WECIA情感预测竞赛，提出了一种名为ECSP（single-multi modal with Emotion-Cultural specific prompt）的简单有效方法，用于通过艺术作品和评论预测个人的情感。方法的核心包括使用XLM-R基于的单模态模型和X²-VLM基于的多模态模型，以缓解modal imbalance问题，同时通过Emotion-Cultural specific prompt减少language-cultural differences问题。最终，该方法在ArtELingo数据集上的测试中排名第一，得分0.627，展示了其在跨语言文化情感预测中的优越性能。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.17683v2",
      "published_date": "2024-03-26 13:14:18 UTC",
      "updated_date": "2024-03-31 14:44:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:06:07.627793"
    },
    {
      "arxiv_id": "2403.17677v1",
      "title": "Onboard deep lossless and near-lossless predictive coding of hyperspectral images with line-based attention",
      "title_zh": "翻译失败",
      "authors": [
        "Diego Valsesia",
        "Tiziano Bianchi",
        "Enrico Magli"
      ],
      "abstract": "Deep learning methods have traditionally been difficult to apply to\ncompression of hyperspectral images onboard of spacecrafts, due to the large\ncomputational complexity needed to achieve adequate representational power, as\nwell as the lack of suitable datasets for training and testing. In this paper,\nwe depart from the traditional autoencoder approach and we design a predictive\nneural network, called LineRWKV, that works recursively line-by-line to limit\nmemory consumption. In order to achieve that, we adopt a novel hybrid\nattentive-recursive operation that combines the representational advantages of\nTransformers with the linear complexity and recursive implementation of\nrecurrent neural networks. The compression algorithm performs prediction of\neach pixel using LineRWKV, followed by entropy coding of the residual.\nExperiments on the HySpecNet-11k dataset and PRISMA images show that LineRWKV\nis the first deep-learning method to outperform CCSDS-123.0-B-2 at lossless and\nnear-lossless compression. Promising throughput results are also evaluated on a\n7W embedded system.",
      "tldr_zh": "该论文解决了深度学习在航天器上高光谱图像压缩的挑战，提出了一种名为 LineRWKV 的预测神经网络，通过逐行递归处理来限制内存消耗。LineRWKV 采用新型混合注意-递归操作，结合 Transformers 的表示优势和 recurrent neural networks 的线性复杂性，对每个像素进行预测后使用熵编码处理残差。在 HySpecNet-11k 数据集和 PRISMA 图像上的实验表明，LineRWKV 是首个在无损和近无损压缩中优于 CCSDS-123.0-B-2 的深度学习方法，并在 7W 嵌入式系统上实现了有前景的吞吐量。",
      "categories": [
        "eess.IV",
        "cs.AI"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.17677v1",
      "published_date": "2024-03-26 13:05:02 UTC",
      "updated_date": "2024-03-26 13:05:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:06:18.394530"
    },
    {
      "arxiv_id": "2403.17674v1",
      "title": "Depending on yourself when you should: Mentoring LLM with RL agents to become the master in cybersecurity games",
      "title_zh": "翻译失败",
      "authors": [
        "Yikuan Yan",
        "Yaolun Zhang",
        "Keman Huang"
      ],
      "abstract": "Integrating LLM and reinforcement learning (RL) agent effectively to achieve\ncomplementary performance is critical in high stake tasks like cybersecurity\noperations. In this study, we introduce SecurityBot, a LLM agent mentored by\npre-trained RL agents, to support cybersecurity operations. In particularly,\nthe LLM agent is supported with a profile module to generated behavior\nguidelines, a memory module to accumulate local experiences, a reflection\nmodule to re-evaluate choices, and an action module to reduce action space.\nAdditionally, it adopts the collaboration mechanism to take suggestions from\npre-trained RL agents, including a cursor for dynamic suggestion taken, an\naggregator for multiple mentors' suggestions ranking and a caller for proactive\nsuggestion asking. Building on the CybORG experiment framework, our experiences\nshow that SecurityBot demonstrates significant performance improvement compared\nwith LLM or RL standalone, achieving the complementary performance in the\ncybersecurity games.",
      "tldr_zh": "本研究提出 SecurityBot，一种由预训练 RL 代理指导的 LLM 代理，旨在通过整合 LLM 和 RL 的互补性能来提升网络安全操作。该代理包括 profile 模块生成行为指南、memory 模块积累本地经验、reflection 模块重新评估选择，以及 action 模块减少行动空间；同时采用协作机制，如 cursor 用于动态建议、aggregator 用于多个导师建议的排名，以及 caller 用于主动请求建议。在 CybORG 实验框架下，SecurityBot 在网络安全游戏中比单独使用 LLM 或 RL 表现出显著性能提升，实现互补优势。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.CR",
      "comment": "10 pages",
      "pdf_url": "http://arxiv.org/pdf/2403.17674v1",
      "published_date": "2024-03-26 13:02:46 UTC",
      "updated_date": "2024-03-26 13:02:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:06:29.850726"
    },
    {
      "arxiv_id": "2403.18872v1",
      "title": "Targeted Visualization of the Backbone of Encoder LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Isaac Roberts",
        "Alexander Schulz",
        "Luca Hermes",
        "Barbara Hammer"
      ],
      "abstract": "Attention based Large Language Models (LLMs) are the state-of-the-art in\nnatural language processing (NLP). The two most common architectures are\nencoders such as BERT, and decoders like the GPT models. Despite the success of\nencoder models, on which we focus in this work, they also bear several risks,\nincluding issues with bias or their susceptibility for adversarial attacks,\nsignifying the necessity for explainable AI to detect such issues. While there\ndoes exist various local explainability methods focusing on the prediction of\nsingle inputs, global methods based on dimensionality reduction for\nclassification inspection, which have emerged in other domains and that go\nfurther than just using t-SNE in the embedding space, are not widely spread in\nNLP.\n  To reduce this gap, we investigate the application of DeepView, a method for\nvisualizing a part of the decision function together with a data set in two\ndimensions, to the NLP domain. While in previous work, DeepView has been used\nto inspect deep image classification models, we demonstrate how to apply it to\nBERT-based NLP classifiers and investigate its usability in this domain,\nincluding settings with adversarially perturbed input samples and pre-trained,\nfine-tuned, and multi-task models.",
      "tldr_zh": "这篇论文针对基于Attention的Encoder LLMs（如BERT），探讨了通过可视化技术提升模型可解释性的方法，以检测偏见和对抗攻击风险。作者引入DeepView——一种二维可视化决策函数的工具，将其从图像分类领域扩展到NLP，应用于BERT-based分类器，包括预训练、微调、多任务模型和对抗样本设置。实验结果表明，DeepView有助于全局分析模型行为，填补了NLP中降维可视化方法的空白，并为可解释AI提供了实用框架。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.18872v1",
      "published_date": "2024-03-26 12:51:02 UTC",
      "updated_date": "2024-03-26 12:51:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:06:40.601076"
    },
    {
      "arxiv_id": "2403.17661v2",
      "title": "Language Models for Text Classification: Is In-Context Learning Enough?",
      "title_zh": "语言模型用于文本分类：上下文学习是否足够？",
      "authors": [
        "Aleksandra Edwards",
        "Jose Camacho-Collados"
      ],
      "abstract": "Recent foundational language models have shown state-of-the-art performance\nin many NLP tasks in zero- and few-shot settings. An advantage of these models\nover more standard approaches based on fine-tuning is the ability to understand\ninstructions written in natural language (prompts), which helps them generalise\nbetter to different tasks and domains without the need for specific training\ndata. This makes them suitable for addressing text classification problems for\ndomains with limited amounts of annotated instances. However, existing research\nis limited in scale and lacks understanding of how text generation models\ncombined with prompting techniques compare to more established methods for text\nclassification such as fine-tuning masked language models. In this paper, we\naddress this research gap by performing a large-scale evaluation study for 16\ntext classification datasets covering binary, multiclass, and multilabel\nproblems. In particular, we compare zero- and few-shot approaches of large\nlanguage models to fine-tuning smaller language models. We also analyse the\nresults by prompt, classification type, domain, and number of labels. In\ngeneral, the results show how fine-tuning smaller and more efficient language\nmodels can still outperform few-shot approaches of larger language models,\nwhich have room for improvement when it comes to text classification.",
      "tldr_zh": "本文探讨了大型语言模型的 In-Context Learning（包括 zero-shot 和 few-shot 方法）是否足以胜任文本分类任务。研究通过大规模评估，比较了这些方法与微调较小语言模型的性能，涵盖了16个数据集，包括二元、多类和多标签分类问题。结果显示，微调较小、更高效的语言模型通常表现出色，而大型语言模型在文本分类方面仍有改进空间，尤其受提示、领域和标签数量的影响。总的来说，这为选择合适的文本分类策略提供了重要见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at LREC-COLING 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.17661v2",
      "published_date": "2024-03-26 12:47:39 UTC",
      "updated_date": "2024-04-14 15:45:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:06:53.533676"
    },
    {
      "arxiv_id": "2403.17993v3",
      "title": "Mixing Artificial and Natural Intelligence: From Statistical Mechanics to AI and Back to Turbulence",
      "title_zh": "翻译失败",
      "authors": [
        "Michael Chertkov"
      ],
      "abstract": "The paper reflects on the future role of AI in scientific research, with a\nspecial focus on turbulence studies, and examines the evolution of AI,\nparticularly through Diffusion Models rooted in non-equilibrium statistical\nmechanics. It underscores the significant impact of AI on advancing reduced,\nLagrangian models of turbulence through innovative use of deep neural networks.\nAdditionally, the paper reviews various other AI applications in turbulence\nresearch and outlines potential challenges and opportunities in the concurrent\nadvancement of AI and statistical hydrodynamics. This discussion sets the stage\nfor a future where AI and turbulence research are intricately intertwined,\nleading to more profound insights and advancements in both fields.",
      "tldr_zh": "这篇论文探讨了人工智能（AI）在科学研究中的未来角色，特别是对湍流研究的潜在影响，并审视了 AI 的演变，包括源于非平衡统计力学（Statistical Mechanics）的扩散模型（Diffusion Models）。论文强调 AI 通过深度神经网络（deep neural networks）显著推进了湍流的简化拉格朗日模型（reduced, Lagrangian models），并回顾了 AI 在湍流研究中的其他应用。最终，它概述了 AI 与统计流体力学（statistical hydrodynamics）共同发展的挑战和机会，预见两者将深度交织，带来更深刻的见解和进步。",
      "categories": [
        "cs.LG",
        "cond-mat.stat-mech",
        "cs.AI",
        "physics.flu-dyn"
      ],
      "primary_category": "cs.LG",
      "comment": "38 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.17993v3",
      "published_date": "2024-03-26 12:45:52 UTC",
      "updated_date": "2024-07-12 20:25:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:07:06.620211"
    },
    {
      "arxiv_id": "2403.17656v1",
      "title": "SGHormer: An Energy-Saving Graph Transformer Driven by Spikes",
      "title_zh": "翻译失败",
      "authors": [
        "Huizhe Zhang",
        "Jintang Li",
        "Liang Chen",
        "Zibin Zheng"
      ],
      "abstract": "Graph Transformers (GTs) with powerful representation learning ability make a\nhuge success in wide range of graph tasks. However, the costs behind\noutstanding performances of GTs are higher energy consumption and computational\noverhead. The complex structure and quadratic complexity during attention\ncalculation in vanilla transformer seriously hinder its scalability on the\nlarge-scale graph data. Though existing methods have made strides in\nsimplifying combinations among blocks or attention-learning paradigm to improve\nGTs' efficiency, a series of energy-saving solutions originated from\nbiologically plausible structures are rarely taken into consideration when\nconstructing GT framework. To this end, we propose a new spiking-based graph\ntransformer (SGHormer). It turns full-precision embeddings into sparse and\nbinarized spikes to reduce memory and computational costs. The spiking graph\nself-attention and spiking rectify blocks in SGHormer explicitly capture global\nstructure information and recover the expressive power of spiking embeddings,\nrespectively. In experiments, SGHormer achieves comparable performances to\nother full-precision GTs with extremely low computational energy consumption.\nThe results show that SGHomer makes a remarkable progress in the field of\nlow-energy GTs.",
      "tldr_zh": "本研究针对Graph Transformers (GTs) 在处理大规模图数据时的高能量消耗和计算开销问题，提出了一种基于脉冲驱动的能量节省框架SGHormer。SGHormer通过将全精度嵌入转换为稀疏二值化spikes，显著降低内存和计算成本，同时引入spiking graph self-attention和spiking rectify blocks来捕获全局结构信息并增强表达能力。实验结果显示，SGHormer在各种图任务上与传统全精度GTs性能相当，但能量消耗极低，标志着低能量GTs领域的重要进展。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NE",
      "comment": "9 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.17656v1",
      "published_date": "2024-03-26 12:39:02 UTC",
      "updated_date": "2024-03-26 12:39:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:07:18.041189"
    },
    {
      "arxiv_id": "2403.17653v1",
      "title": "An Extension-based Approach for Computing and Verifying Preferences in Abstract Argumentation",
      "title_zh": "基于扩展的方法用于计算和验证抽象论证中的偏好",
      "authors": [
        "Quratul-ain Mahesar",
        "Nir Oren",
        "Wamberto W. Vasconcelos"
      ],
      "abstract": "We present an extension-based approach for computing and verifying\npreferences in an abstract argumentation system. Although numerous\nargumentation semantics have been developed previously for identifying\nacceptable sets of arguments from an argumentation framework, there is a lack\nof justification behind their acceptability based on implicit argument\npreferences. Preference-based argumentation frameworks allow one to determine\nwhat arguments are justified given a set of preferences. Our research considers\nthe inverse of the standard reasoning problem, i.e., given an abstract\nargumentation framework and a set of justified arguments, we compute what the\npossible preferences over arguments are. Furthermore, there is a need to verify\n(i.e., assess) that the computed preferences would lead to the acceptable sets\nof arguments. This paper presents a novel approach and algorithm for\nexhaustively computing and enumerating all possible sets of preferences\n(restricted to three identified cases) for a conflict-free set of arguments in\nan abstract argumentation framework. We prove the soundness, completeness and\ntermination of the algorithm. The research establishes that preferences are\ndetermined using an extension-based approach after the evaluation phase\n(acceptability of arguments) rather than stated beforehand. In this work, we\nfocus our research study on grounded, preferred and stable semantics. We show\nthat the complexity of computing sets of preferences is exponential in the\nnumber of arguments, and thus, describe an approximate approach and algorithm\nto compute the preferences. Furthermore, we present novel algorithms for\nverifying (i.e., assessing) the computed preferences. We provide details of the\nimplementation of the algorithms (source code has been made available), various\nexperiments performed to evaluate the algorithms and the analysis of the\nresults.",
      "tldr_zh": "这篇论文提出了一种基于扩展（extension-based）的途径，用于在抽象论证（abstract argumentation）系统中计算和验证偏好，逆转了传统方法，通过给定论证框架和一组正当论证来推断可能的偏好集。研究设计了新算法，针对三种特定情况穷举计算偏好，并证明算法的正确性（soundness, completeness 和 termination），同时针对 grounded、preferred 和 stable semantics 进行了分析。结果显示计算复杂性为指数级，因此引入了近似算法和验证机制，并通过实验和实现细节验证了方法的有效性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.17653v1",
      "published_date": "2024-03-26 12:36:11 UTC",
      "updated_date": "2024-03-26 12:36:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:07:31.512189"
    },
    {
      "arxiv_id": "2403.17643v3",
      "title": "S+t-SNE -- Bringing Dimensionality Reduction to Data Streams",
      "title_zh": "翻译失败",
      "authors": [
        "Pedro C. Vieira",
        "João P. Montrezol",
        "João T. Vieira",
        "João Gama"
      ],
      "abstract": "We present S+t-SNE, an adaptation of the t-SNE algorithm designed to handle\ninfinite data streams. The core idea behind S+t-SNE is to update the t-SNE\nembedding incrementally as new data arrives, ensuring scalability and\nadaptability to handle streaming scenarios. By selecting the most important\npoints at each step, the algorithm ensures scalability while keeping\ninformative visualisations. By employing a blind method for drift management,\nthe algorithm adjusts the embedding space, which facilitates the visualisation\nof evolving data dynamics. Our experimental evaluations demonstrate the\neffectiveness and efficiency of S+t-SNE, whilst highlighting its ability to\ncapture patterns in a streaming scenario. We hope our approach offers\nresearchers and practitioners a real-time tool for understanding and\ninterpreting high-dimensional data.",
      "tldr_zh": "我们提出了 S+t-SNE，这是一种针对无限数据流的 t-SNE 算法适应版，能够通过增量更新嵌入空间来处理新数据，确保算法的可扩展性和适应性。该方法通过选择每个步骤的最重要点并采用盲方法管理数据漂移（drift），从而保持信息丰富的可视化并捕捉演变的数据动态。实验评估证明，S+t-SNE 在流式场景中表现出色，能有效捕获模式，并为研究者和从业者提供实时工具来理解高维数据。",
      "categories": [
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.AI",
      "comment": "This preprint has undergone peer review but does not have any\n  post-submission improvements or corrections. Full version after peer-review\n  and post-acceptance improvements was presented at IDA2024\n  (https://ida2024.blogs.dsv.su.se/)",
      "pdf_url": "http://arxiv.org/pdf/2403.17643v3",
      "published_date": "2024-03-26 12:23:34 UTC",
      "updated_date": "2025-01-21 15:52:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:07:42.669090"
    },
    {
      "arxiv_id": "2403.17992v1",
      "title": "Interpretable cancer cell detection with phonon microscopy using multi-task conditional neural networks for inter-batch calibration",
      "title_zh": "翻译失败",
      "authors": [
        "Yijie Zheng",
        "Rafael Fuentes-Dominguez",
        "Matt Clark",
        "George S. D. Gordon",
        "Fernando Perez-Cota"
      ],
      "abstract": "Advances in artificial intelligence (AI) show great potential in revealing\nunderlying information from phonon microscopy (high-frequency ultrasound) data\nto identify cancerous cells. However, this technology suffers from the 'batch\neffect' that comes from unavoidable technical variations between each\nexperiment, creating confounding variables that the AI model may inadvertently\nlearn. We therefore present a multi-task conditional neural network framework\nto simultaneously achieve inter-batch calibration, by removing confounding\nvariables, and accurate cell classification of time-resolved phonon-derived\nsignals. We validate our approach by training and validating on different\nexperimental batches, achieving a balanced precision of 89.22% and an average\ncross-validated precision of 89.07% for classifying background, healthy and\ncancerous regions. Classification can be performed in 0.5 seconds with only\nsimple prior batch information required for multiple batch corrections.\nFurther, we extend our model to reconstruct denoised signals, enabling physical\ninterpretation of salient features indicating disease state including sound\nvelocity, sound attenuation and cell-adhesion to substrate.",
      "tldr_zh": "该研究针对 phonon microscopy 数据中存在的 batch effect（实验间技术变异导致的混淆变量）问题，提出了一种多任务条件神经网络框架，用于同时实现 inter-batch calibration 和精确的癌细胞检测。该框架在不同实验批次上验证，实现了89.22%的平衡精度和89.07%的平均交叉验证精度，并能在0.5秒内完成分类，仅需简单的先验批次信息。进一步，该模型扩展到重建去噪信号，允许对关键物理特征（如声速、声衰减和细胞附着）进行解释，从而提升了癌细胞检测的可解释性和可靠性。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.LG",
        "eess.IV",
        "eess.SP"
      ],
      "primary_category": "q-bio.QM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.17992v1",
      "published_date": "2024-03-26 12:20:10 UTC",
      "updated_date": "2024-03-26 12:20:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:07:54.470202"
    },
    {
      "arxiv_id": "2403.17637v3",
      "title": "PeersimGym: An Environment for Solving the Task Offloading Problem with Reinforcement Learning",
      "title_zh": "PeersimGym：一种用于通过强化学习解决任务卸载问题的环境",
      "authors": [
        "Frederico Metelo",
        "Stevo Racković",
        "Pedro Ákos Costa",
        "Cláudia Soares"
      ],
      "abstract": "Task offloading, crucial for balancing computational loads across devices in\nnetworks such as the Internet of Things, poses significant optimization\nchallenges, including minimizing latency and energy usage under strict\ncommunication and storage constraints. While traditional optimization falls\nshort in scalability; and heuristic approaches lack in achieving optimal\noutcomes, Reinforcement Learning (RL) offers a promising avenue by enabling the\nlearning of optimal offloading strategies through iterative interactions.\nHowever, the efficacy of RL hinges on access to rich datasets and\ncustom-tailored, realistic training environments. To address this, we introduce\nPeersimGym, an open-source, customizable simulation environment tailored for\ndeveloping and optimizing task offloading strategies within computational\nnetworks. PeersimGym supports a wide range of network topologies and\ncomputational constraints and integrates a \\textit{PettingZoo}-based interface\nfor RL agent deployment in both solo and multi-agent setups. Furthermore, we\ndemonstrate the utility of the environment through experiments with Deep\nReinforcement Learning agents, showcasing the potential of RL-based approaches\nto significantly enhance offloading strategies in distributed computing\nsettings. PeersimGym thus bridges the gap between theoretical RL models and\ntheir practical applications, paving the way for advancements in efficient task\noffloading methodologies.",
      "tldr_zh": "该论文介绍了 PeersimGym，这是一个开源、可定制的模拟环境，旨在通过强化学习（RL）解决物联网等网络中的任务卸载问题，帮助最小化延迟和能源消耗。PeersimGym 支持多种网络拓扑、计算约束，并整合 PettingZoo 接口，支持单代理和多代理 RL 部署。实验结果显示，使用深度强化学习代理能显著提升任务卸载策略的效率，为分布式计算应用提供实际可行的优化方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Published in the proceedings of the conference on Machine Learning\n  and Knowledge Discovery in Databases. Applied Data Science Track. ECML PKDD\n  2024. Lecture Notes in Computer Science(), vol 14949. Springer, Cham",
      "pdf_url": "http://arxiv.org/pdf/2403.17637v3",
      "published_date": "2024-03-26 12:12:44 UTC",
      "updated_date": "2024-10-08 10:56:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:08:06.394069"
    },
    {
      "arxiv_id": "2403.17633v4",
      "title": "UADA3D: Unsupervised Adversarial Domain Adaptation for 3D Object Detection with Sparse LiDAR and Large Domain Gaps",
      "title_zh": "翻译失败",
      "authors": [
        "Maciej K Wozniak",
        "Mattias Hansson",
        "Marko Thiel",
        "Patric Jensfelt"
      ],
      "abstract": "In this study, we address a gap in existing unsupervised domain adaptation\napproaches on LiDAR-based 3D object detection, which have predominantly\nconcentrated on adapting between established, high-density autonomous driving\ndatasets. We focus on sparser point clouds, capturing scenarios from different\nperspectives: not just from vehicles on the road but also from mobile robots on\nsidewalks, which encounter significantly different environmental conditions and\nsensor configurations. We introduce Unsupervised Adversarial Domain Adaptation\nfor 3D Object Detection (UADA3D). UADA3D does not depend on pre-trained source\nmodels or teacher-student architectures. Instead, it uses an adversarial\napproach to directly learn domain-invariant features. We demonstrate its\nefficacy in various adaptation scenarios, showing significant improvements in\nboth self-driving car and mobile robot domains. Our code is open-source and\nwill be available soon.",
      "tldr_zh": "本研究针对现有无监督域适应方法在 LiDAR-based 3D Object Detection 中的局限性，特别关注稀疏点云数据以及不同视角（如车辆和移动机器人）的环境差异。作者提出 UADA3D，一种不依赖预训练源模型或教师-学生架构的对抗域适应方法，通过学习域不变特征来直接提升检测性能。在各种适应场景中，UADA3D 实现了自驾车和移动机器人领域的显著改进，代码即将开源。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted for IEEE RA-L 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.17633v4",
      "published_date": "2024-03-26 12:08:14 UTC",
      "updated_date": "2024-10-21 11:34:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:08:18.267016"
    },
    {
      "arxiv_id": "2403.17632v3",
      "title": "Data-driven Energy Consumption Modelling for Electric Micromobility using an Open Dataset",
      "title_zh": "翻译失败",
      "authors": [
        "Yue Ding",
        "Sen Yan",
        "Maqsood Hussain Shah",
        "Hongyuan Fang",
        "Ji Li",
        "Mingming Liu"
      ],
      "abstract": "The escalating challenges of traffic congestion and environmental degradation\nunderscore the critical importance of embracing E-Mobility solutions in urban\nspaces. In particular, micro E-Mobility tools such as E-scooters and E-bikes,\nplay a pivotal role in this transition, offering sustainable alternatives for\nurban commuters. However, the energy consumption patterns for these tools are a\ncritical aspect that impacts their effectiveness in real-world scenarios and is\nessential for trip planning and boosting user confidence in using these. To\nthis effect, recent studies have utilised physical models customised for\nspecific mobility tools and conditions, but these models struggle with\ngeneralization and effectiveness in real-world scenarios due to a notable\nabsence of open datasets for thorough model evaluation and verification. To\nfill this gap, our work presents an open dataset, collected in Dublin, Ireland,\nspecifically designed for energy modelling research related to E-Scooters and\nE-Bikes. Furthermore, we provide a comprehensive analysis of energy consumption\nmodelling based on the dataset using a set of representative machine learning\nalgorithms and compare their performance against the contemporary mathematical\nmodels as a baseline. Our results demonstrate a notable advantage for\ndata-driven models in comparison to the corresponding mathematical models for\nestimating energy consumption. Specifically, data-driven models outperform\nphysical models in accuracy by up to 83.83% for E-Bikes and 82.16% for\nE-Scooters based on an in-depth analysis of the dataset under certain\nassumptions.",
      "tldr_zh": "该论文探讨了基于公开数据集的电动微型交通工具(E-Micromobility)能源消耗建模，以应对城市交通拥堵和环境退化的挑战。作者提供了一个在爱尔兰都柏林收集的开放数据集，专注于E-Scooters和E-Bikes的能源建模，并使用代表性machine learning algorithms进行分析，与传统数学模型作为基准进行比较。结果显示，数据驱动模型在准确性上显著优于物理模型，E-Bikes的改进幅度高达83.83%，E-Scooters则达82.16%，为出行规划和用户信心提升提供了更可靠的工具。",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "7 pages, 5 figures, 4 tables. This manuscript has been accepted by\n  the IEEE ITEC 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.17632v3",
      "published_date": "2024-03-26 12:08:05 UTC",
      "updated_date": "2024-11-08 17:01:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:08:30.947454"
    },
    {
      "arxiv_id": "2403.17611v1",
      "title": "Denoising Table-Text Retrieval for Open-Domain Question Answering",
      "title_zh": "翻译失败",
      "authors": [
        "Deokhyung Kang",
        "Baikjin Jung",
        "Yunsu Kim",
        "Gary Geunbae Lee"
      ],
      "abstract": "In table-text open-domain question answering, a retriever system retrieves\nrelevant evidence from tables and text to answer questions. Previous studies in\ntable-text open-domain question answering have two common challenges: firstly,\ntheir retrievers can be affected by false-positive labels in training datasets;\nsecondly, they may struggle to provide appropriate evidence for questions that\nrequire reasoning across the table. To address these issues, we propose\nDenoised Table-Text Retriever (DoTTeR). Our approach involves utilizing a\ndenoised training dataset with fewer false positive labels by discarding\ninstances with lower question-relevance scores measured through a false\npositive detection model. Subsequently, we integrate table-level ranking\ninformation into the retriever to assist in finding evidence for questions that\ndemand reasoning across the table. To encode this ranking information, we\nfine-tune a rank-aware column encoder to identify minimum and maximum values\nwithin a column. Experimental results demonstrate that DoTTeR significantly\noutperforms strong baselines on both retrieval recall and downstream QA tasks.\nOur code is available at https://github.com/deokhk/DoTTeR.",
      "tldr_zh": "本文提出 Denoised Table-Text Retriever (DoTTeR)，一种针对表-文本开放域问答的检索框架，旨在解决训练数据集中的假阳性标签和跨表推理需求的问题。DoTTeR 通过假阳性检测模型评估问题相关性分数来去噪训练数据集，并整合表级排名信息（如微调 rank-aware column encoder 以识别列中的最小和最大值），从而提升证据检索的准确性。实验结果表明，DoTTeR 在检索召回和下游 QA 任务上显著优于强基线模型。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to LREC-COLING 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.17611v1",
      "published_date": "2024-03-26 11:44:49 UTC",
      "updated_date": "2024-03-26 11:44:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:08:43.646646"
    },
    {
      "arxiv_id": "2403.18871v1",
      "title": "Clinical Domain Knowledge-Derived Template Improves Post Hoc AI Explanations in Pneumothorax Classification",
      "title_zh": "基于临床领域知识导出的模板改善气胸分类中的事后AI解释",
      "authors": [
        "Han Yuan",
        "Chuan Hong",
        "Pengtao Jiang",
        "Gangming Zhao",
        "Nguyen Tuan Anh Tran",
        "Xinxing Xu",
        "Yet Yen Yan",
        "Nan Liu"
      ],
      "abstract": "Background: Pneumothorax is an acute thoracic disease caused by abnormal air\ncollection between the lungs and chest wall. To address the opaqueness often\nassociated with deep learning (DL) models, explainable artificial intelligence\n(XAI) methods have been introduced to outline regions related to pneumothorax\ndiagnoses made by DL models. However, these explanations sometimes diverge from\nactual lesion areas, highlighting the need for further improvement. Method: We\npropose a template-guided approach to incorporate the clinical knowledge of\npneumothorax into model explanations generated by XAI methods, thereby\nenhancing the quality of these explanations. Utilizing one lesion delineation\ncreated by radiologists, our approach first generates a template that\nrepresents potential areas of pneumothorax occurrence. This template is then\nsuperimposed on model explanations to filter out extraneous explanations that\nfall outside the template's boundaries. To validate its efficacy, we carried\nout a comparative analysis of three XAI methods with and without our template\nguidance when explaining two DL models in two real-world datasets. Results: The\nproposed approach consistently improved baseline XAI methods across twelve\nbenchmark scenarios built on three XAI methods, two DL models, and two\ndatasets. The average incremental percentages, calculated by the performance\nimprovements over the baseline performance, were 97.8% in Intersection over\nUnion (IoU) and 94.1% in Dice Similarity Coefficient (DSC) when comparing model\nexplanations and ground-truth lesion areas. Conclusions: In the context of\npneumothorax diagnoses, we proposed a template-guided approach for improving AI\nexplanations. We anticipate that our template guidance will forge a fresh\napproach to elucidating AI models by integrating clinical domain expertise.",
      "tldr_zh": "该研究针对深度学习(DL)模型在气胸(Pneumothorax)分类中的解释不准确问题，提出了一种基于临床领域知识的模板引导方法，以提升后验AI解释(XAI)质量。该方法首先利用放射科医生绘制的病变轮廓生成代表性模板，然后将模板叠加到XAI输出上，过滤掉无关区域。在两个真实数据集上进行的实验显示，该方法在三个XAI方法、两个DL模型和十二个基准场景中，平均使Intersection over Union (IoU)提高97.8%，Dice Similarity Coefficient (DSC)提高94.1%。这项创新为将临床专业知识整合到AI解释中提供了新途径，提升了诊断的可解释性和可靠性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.18871v1",
      "published_date": "2024-03-26 11:40:06 UTC",
      "updated_date": "2024-03-26 11:40:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:08:55.133584"
    },
    {
      "arxiv_id": "2403.17608v2",
      "title": "Fake or JPEG? Revealing Common Biases in Generated Image Detection Datasets",
      "title_zh": "Fake or JPEG？揭示生成图像检测数据集中的常见偏差",
      "authors": [
        "Patrick Grommelt",
        "Louis Weiss",
        "Franz-Josef Pfreundt",
        "Janis Keuper"
      ],
      "abstract": "The widespread adoption of generative image models has highlighted the urgent\nneed to detect artificial content, which is a crucial step in combating\nwidespread manipulation and misinformation. Consequently, numerous detectors\nand associated datasets have emerged. However, many of these datasets\ninadvertently introduce undesirable biases, thereby impacting the effectiveness\nand evaluation of detectors. In this paper, we emphasize that many datasets for\nAI-generated image detection contain biases related to JPEG compression and\nimage size. Using the GenImage dataset, we demonstrate that detectors indeed\nlearn from these undesired factors. Furthermore, we show that removing the\nnamed biases substantially increases robustness to JPEG compression and\nsignificantly alters the cross-generator performance of evaluated detectors.\nSpecifically, it leads to more than 11 percentage points increase in\ncross-generator performance for ResNet50 and Swin-T detectors on the GenImage\ndataset, achieving state-of-the-art results.\n  We provide the dataset and source codes of this paper on the anonymous\nwebsite: https://www.unbiased-genimage.org",
      "tldr_zh": "本论文揭示了生成图像检测数据集中的常见偏置问题，如 JPEG 压缩和图像大小，这些偏置会影响检测器的有效性和评估准确性。研究者使用 GenImage 数据集，展示了检测器如何从这些非预期因素中学习，并通过移除偏置来提升鲁棒性。结果显示，移除偏置后，ResNet50 和 Swin-T 检测器的跨生成器性能提高了超过 11 百分点，达到了 state-of-the-art 水平。该工作提供了数据集和源代码，以促进更可靠的 AI 生成图像检测研究。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.17608v2",
      "published_date": "2024-03-26 11:39:00 UTC",
      "updated_date": "2024-03-28 15:24:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:09:10.212122"
    },
    {
      "arxiv_id": "2403.17607v1",
      "title": "Fully-fused Multi-Layer Perceptrons on Intel Data Center GPUs",
      "title_zh": "在英特尔数据中心GPU上的完全融合多层感知器",
      "authors": [
        "Kai Yuan",
        "Christoph Bauinger",
        "Xiangyi Zhang",
        "Pascal Baehr",
        "Matthias Kirchhart",
        "Darius Dabert",
        "Adrien Tousnakhoff",
        "Pierre Boudier",
        "Michael Paulitsch"
      ],
      "abstract": "This paper presents a SYCL implementation of Multi-Layer Perceptrons (MLPs),\nwhich targets and is optimized for the Intel Data Center GPU Max 1550. To\nincrease the performance, our implementation minimizes the slow global memory\naccesses by maximizing the data reuse within the general register file and the\nshared local memory by fusing the operations in each layer of the MLP. We show\nwith a simple roofline model that this results in a significant increase in the\narithmetic intensity, leading to improved performance, especially for\ninference. We compare our approach to a similar CUDA implementation for MLPs\nand show that our implementation on the Intel Data Center GPU outperforms the\nCUDA implementation on Nvidia's H100 GPU by a factor up to 2.84 in inference\nand 1.75 in training. The paper also showcases the efficiency of our SYCL\nimplementation in three significant areas: Image Compression, Neural Radiance\nFields, and Physics-Informed Machine Learning. In all cases, our implementation\noutperforms the off-the-shelf Intel Extension for PyTorch (IPEX) implementation\non the same Intel GPU by up to a factor of 30 and the CUDA PyTorch version on\nNvidia's H100 GPU by up to a factor 19. The code can be found at\nhttps://github.com/intel/tiny-dpcpp-nn.",
      "tldr_zh": "本文提出了一种针对 Intel Data Center GPU Max 1550 的 SYCL 实现，用于优化 Multi-Layer Perceptrons (MLPs)，通过融合层级操作最大化数据重用（如在 general register file 和 shared local memory 中），从而减少全局内存访问并提升算术强度。实验结果显示，该实现比 CUDA 版本在 Nvidia H100 GPU 上的性能高出高达 2.84 倍（推理）和 1.75 倍（训练），并在 Image Compression、Neural Radiance Fields 和 Physics-Informed Machine Learning 等领域 outperform 现有 Intel Extension for PyTorch (IPEX) 和 CUDA PyTorch 实现。代码开源于 https://github.com/intel/tiny-dpcpp-nn，提供了一种高效的跨平台神经网络优化方案。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.17607v1",
      "published_date": "2024-03-26 11:38:39 UTC",
      "updated_date": "2024-03-26 11:38:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:09:22.361768"
    },
    {
      "arxiv_id": "2403.18870v3",
      "title": "SugarcaneNet: An Optimized Ensemble of LASSO-Regularized Pre-trained Models for Accurate Disease Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Md. Simul Hasan Talukder",
        "Sharmin Akter",
        "Abdullah Hafez Nur",
        "Mohammad Aljaidi",
        "Rejwan Bin Sulaiman",
        "Ali Fayez Alkoradees"
      ],
      "abstract": "Sugarcane, a key crop for the world's sugar industry, is prone to several\ndiseases that have a substantial negative influence on both its yield and\nquality. To effectively manage and implement preventative initiatives, diseases\nmust be detected promptly and accurately. In this study, we present a unique\nmodel called sugarcaneNet2024 that outperforms previous methods for\nautomatically and quickly detecting sugarcane disease through leaf image\nprocessing. Our proposed model consolidates an optimized weighted average\nensemble of seven customized and LASSO-regularized pre-trained models,\nparticularly InceptionV3, InceptionResNetV2, DenseNet201, DenseNet169,\nXception, and ResNet152V2. Initially, we added three more dense layers with\n0.0001 LASSO regularization, three 30% dropout layers, and three batch\nnormalizations with renorm enabled at the bottom of these pre-trained models to\nimprove the performance. The accuracy of sugarcane leaf disease classification\nwas greatly increased by this addition. Following this, several comparative\nstudies between the average ensemble and individual models were carried out,\nindicating that the ensemble technique performed better. The average ensemble\nof all modified pre-trained models produced outstanding outcomes: 100%, 99%,\n99%, and 99.45% for f1 score, precision, recall, and accuracy, respectively.\nPerformance was further enhanced by the implementation of an optimized weighted\naverage ensemble technique incorporated with grid search. This optimized\nsugarcaneNet2024 model performed the best for detecting sugarcane diseases,\nhaving achieved accuracy, precision, recall, and F1 score of 99.67%, 100%,\n100%, and 100% , respectively.",
      "tldr_zh": "本研究针对甘蔗病害对产量和质量的负面影响，提出了一种名为 SugarcaneNet 的优化模型，用于通过叶片图像实现快速准确的病害分类。模型采用七个 LASSO 正则化预训练模型（包括 InceptionV3、InceptionResNetV2、DenseNet201、DenseNet169、Xception 和 ResNet152V2）的加权平均集成，并添加三层密集层（带有 0.0001 LASSO 正则化）、三层 30% dropout 层和三层批标准化（renorm 启用），显著提升了分类性能。实验结果显示，该优化模型在甘蔗病害检测上取得了 99.67% 的准确率、100% 的精确度、100% 的召回率和 100% 的 F1 分数，优于单个模型和平均集成方法。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "32 pages, 11 Figures, 13 Tables",
      "pdf_url": "http://arxiv.org/pdf/2403.18870v3",
      "published_date": "2024-03-26 11:23:08 UTC",
      "updated_date": "2024-11-16 11:36:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:09:34.658950"
    },
    {
      "arxiv_id": "2403.17601v3",
      "title": "LASIL: Learner-Aware Supervised Imitation Learning For Long-term Microscopic Traffic Simulation",
      "title_zh": "翻译失败",
      "authors": [
        "Ke Guo",
        "Zhenwei Miao",
        "Wei Jing",
        "Weiwei Liu",
        "Weizi Li",
        "Dayang Hao",
        "Jia Pan"
      ],
      "abstract": "Microscopic traffic simulation plays a crucial role in transportation\nengineering by providing insights into individual vehicle behavior and overall\ntraffic flow. However, creating a realistic simulator that accurately\nreplicates human driving behaviors in various traffic conditions presents\nsignificant challenges. Traditional simulators relying on heuristic models\noften fail to deliver accurate simulations due to the complexity of real-world\ntraffic environments. Due to the covariate shift issue, existing imitation\nlearning-based simulators often fail to generate stable long-term simulations.\nIn this paper, we propose a novel approach called learner-aware supervised\nimitation learning to address the covariate shift problem in multi-agent\nimitation learning. By leveraging a variational autoencoder simultaneously\nmodeling the expert and learner state distribution, our approach augments\nexpert states such that the augmented state is aware of learner state\ndistribution. Our method, applied to urban traffic simulation, demonstrates\nsignificant improvements over existing state-of-the-art baselines in both\nshort-term microscopic and long-term macroscopic realism when evaluated on the\nreal-world dataset pNEUMA.",
      "tldr_zh": "该论文针对微观交通模拟中的挑战，提出了一种新型方法LASIL（Learner-Aware Supervised Imitation Learning），以解决多智能体模仿学习中的covariate shift问题，从而实现更稳定的长期模拟。LASIL利用变分自编码器(Variational Autoencoder)同时建模专家和学习者状态分布，通过增强专家状态使其aware of learner state distribution，提升模拟的准确性。在pNEUMA真实数据集上的实验表明，该方法在短期微观和长期宏观现实性方面显著优于现有最先进基线，为更真实的人类驾驶行为模拟提供了有效解决方案。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by CVPR 2024. arXiv admin note: text overlap with\n  arXiv:2306.06401",
      "pdf_url": "http://arxiv.org/pdf/2403.17601v3",
      "published_date": "2024-03-26 11:13:35 UTC",
      "updated_date": "2024-05-23 07:41:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:09:45.019533"
    },
    {
      "arxiv_id": "2403.17589v1",
      "title": "Dual Memory Networks: A Versatile Adaptation Approach for Vision-Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yabin Zhang",
        "Wenjie Zhu",
        "Hui Tang",
        "Zhiyuan Ma",
        "Kaiyang Zhou",
        "Lei Zhang"
      ],
      "abstract": "With the emergence of pre-trained vision-language models like CLIP, how to\nadapt them to various downstream classification tasks has garnered significant\nattention in recent research. The adaptation strategies can be typically\ncategorized into three paradigms: zero-shot adaptation, few-shot adaptation,\nand the recently-proposed training-free few-shot adaptation. Most existing\napproaches are tailored for a specific setting and can only cater to one or two\nof these paradigms. In this paper, we introduce a versatile adaptation approach\nthat can effectively work under all three settings. Specifically, we propose\nthe dual memory networks that comprise dynamic and static memory components.\nThe static memory caches training data knowledge, enabling training-free\nfew-shot adaptation, while the dynamic memory preserves historical test\nfeatures online during the testing process, allowing for the exploration of\nadditional data insights beyond the training set. This novel capability\nenhances model performance in the few-shot setting and enables model usability\nin the absence of training data. The two memory networks employ the same\nflexible memory interactive strategy, which can operate in a training-free mode\nand can be further enhanced by incorporating learnable projection layers. Our\napproach is tested across 11 datasets under the three task settings.\nRemarkably, in the zero-shot scenario, it outperforms existing methods by over\n3\\% and even shows superior results against methods utilizing external training\ndata. Additionally, our method exhibits robust performance against natural\ndistribution shifts. Codes are available at \\url{https://github.com/YBZh/DMN}.",
      "tldr_zh": "本研究提出了一种通用的适应方法，Dual Memory Networks，用于将预训练视觉语言模型（如 CLIP）适应到零-shot adaptation、few-shot adaptation 和 training-free few-shot adaptation 等多种下游分类任务设置。框架包括静态内存（缓存训练数据知识，支持无训练少样本适应）和动态内存（在线保存测试特征，探索额外数据洞见），二者采用相同的灵活内存交互策略，可在无训练模式下运作，并通过可学习投影层进一步增强。实验在 11 个数据集上验证，该方法在零-shot 场景下比现有方法提升超过 3%，甚至优于使用外部训练数据的方法，同时对自然分布偏移表现出色。该框架为模型适应提供了更具弹性的解决方案，并开源代码以便进一步应用。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR2024; Codes are available at \\url{https://github.com/YBZh/DMN}",
      "pdf_url": "http://arxiv.org/pdf/2403.17589v1",
      "published_date": "2024-03-26 10:54:07 UTC",
      "updated_date": "2024-03-26 10:54:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:09:56.630576"
    },
    {
      "arxiv_id": "2403.17587v1",
      "title": "Parameterized Analysis of Bribery in Challenge the Champ Tournaments",
      "title_zh": "Challenge the Champ Tournaments 中贿赂的参数化分析",
      "authors": [
        "Juhi Chaudhary",
        "Hendrik Molter",
        "Meirav Zehavi"
      ],
      "abstract": "Challenge the champ tournaments are one of the simplest forms of competition,\nwhere a (initially selected) champ is repeatedly challenged by other players.\nIf a player beats the champ, then that player is considered the new (current)\nchamp. Each player in the competition challenges the current champ once in a\nfixed order. The champ of the last round is considered the winner of the\ntournament. We investigate a setting where players can be bribed to lower their\nwinning probability against the initial champ. The goal is to maximize the\nprobability of the initial champ winning the tournament by bribing the other\nplayers, while not exceeding a given budget for the bribes. Mattei et al.\n[Journal of Applied Logic, 2015] showed that the problem can be solved in\npseudo-polynomial time, and that it is in XP when parameterized by the number\nof players.\n  We show that the problem is weakly NP-hard and W[1]-hard when parameterized\nby the number of players. On the algorithmic side, we show that the problem is\nfixed-parameter tractable when parameterized either by the number of different\nbribe values or the number of different probability values. To this end, we\nestablish several results that are of independent interest. In particular, we\nshow that the product knapsack problem is W[1]-hard when parameterized by the\nnumber of items in the knapsack, and that constructive bribery for cup\ntournaments is W[1]-hard when parameterized by the number of players.\nFurthermore, we present a novel way of designing mixed integer linear programs,\nensuring optimal solutions where all variables are integers.",
      "tldr_zh": "这篇论文分析了 Challenge the Champ 锦标赛中贿赂玩家的参数化问题，目标是通过贿赂降低其他玩家击败初始冠军的概率，从而在给定预算下最大化初始冠军获胜概率。研究者证明了该问题是 weakly NP-hard 和 W[1]-hard 当参数化为玩家数量时，但当参数化为不同贿赂值数量或不同概率值数量时，则是 fixed-parameter tractable (FPT)。此外，论文建立了独立兴趣的结果，如产品背包问题在物品数量参数化时的 W[1]-hard，并提出了一种确保变量为整数的混合整数线性程序设计方法。",
      "categories": [
        "cs.DS",
        "cs.AI"
      ],
      "primary_category": "cs.DS",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.17587v1",
      "published_date": "2024-03-26 10:53:25 UTC",
      "updated_date": "2024-03-26 10:53:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:10:08.931048"
    },
    {
      "arxiv_id": "2403.17582v1",
      "title": "Towards a Zero-Data, Controllable, Adaptive Dialog System",
      "title_zh": "迈向零数据、可控、自适应对话系统",
      "authors": [
        "Dirk Väth",
        "Lindsey Vanderlyn",
        "Ngoc Thang Vu"
      ],
      "abstract": "Conversational Tree Search (V\\\"ath et al., 2023) is a recent approach to\ncontrollable dialog systems, where domain experts shape the behavior of a\nReinforcement Learning agent through a dialog tree. The agent learns to\nefficiently navigate this tree, while adapting to information needs, e.g.,\ndomain familiarity, of different users. However, the need for additional\ntraining data hinders deployment in new domains. To address this, we explore\napproaches to generate this data directly from dialog trees. We improve the\noriginal approach, and show that agents trained on synthetic data can achieve\ncomparable dialog success to models trained on human data, both when using a\ncommercial Large Language Model for generation, or when using a smaller\nopen-source model, running on a single GPU. We further demonstrate the\nscalability of our approach by collecting and testing on two new datasets:\nONBOARD, a new domain helping foreign residents moving to a new city, and the\nmedical domain DIAGNOSE, a subset of Wikipedia articles related to scalp and\nhead symptoms. Finally, we perform human testing, where no statistically\nsignificant differences were found in either objective or subjective measures\nbetween models trained on human and generated data.",
      "tldr_zh": "该论文针对可控对话系统Conversational Tree Search提出了一种零数据方法，通过从对话树直接生成合成数据来训练强化学习代理，从而避免依赖额外的人类训练数据。研究改进了原框架，使用商业Large Language Model或小型开源模型训练代理，结果显示这些代理在对话成功率上与人类数据训练模型相当。实验扩展到新数据集ONBOARD（帮助外地居民适应新城市）和DIAGNOSE（头皮和头部症状相关），并通过人类测试证实，在客观和主观指标上，合成数据模型与人类数据模型无统计学显著差异。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.17582v1",
      "published_date": "2024-03-26 10:45:11 UTC",
      "updated_date": "2024-03-26 10:45:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:10:20.722694"
    },
    {
      "arxiv_id": "2403.17556v1",
      "title": "m3P: Towards Multimodal Multilingual Translation with Multimodal Prompt",
      "title_zh": "翻译失败",
      "authors": [
        "Jian Yang",
        "Hongcheng Guo",
        "Yuwei Yin",
        "Jiaqi Bai",
        "Bing Wang",
        "Jiaheng Liu",
        "Xinnian Liang",
        "Linzheng Cahi",
        "Liqun Yang",
        "Zhoujun Li"
      ],
      "abstract": "Multilingual translation supports multiple translation directions by\nprojecting all languages in a shared space, but the translation quality is\nundermined by the difference between languages in the text-only modality,\nespecially when the number of languages is large. To bridge this gap, we\nintroduce visual context as the universal language-independent representation\nto facilitate multilingual translation. In this paper, we propose a framework\nto leverage the multimodal prompt to guide the Multimodal Multilingual neural\nMachine Translation (m3P), which aligns the representations of different\nlanguages with the same meaning and generates the conditional vision-language\nmemory for translation. We construct a multilingual multimodal instruction\ndataset (InstrMulti102) to support 102 languages. Our method aims to minimize\nthe representation distance of different languages by regarding the image as a\ncentral language. Experimental results show that m3P outperforms previous\ntext-only baselines and multilingual multimodal methods by a large margin.\nFurthermore, the probing experiments validate the effectiveness of our method\nin enhancing translation under the low-resource and massively multilingual\nscenario.",
      "tldr_zh": "该研究提出 m3P 框架，通过引入多模态提示来提升多语言翻译的性能，旨在利用视觉上下文作为语言无关的通用表示，桥接不同语言间的差距。m3P 框架对齐不同语言的表示，并生成条件视觉-语言记忆，支持 Multimodal Multilingual Neural Machine Translation。研究构建了 InstrMulti102 数据集，涵盖 102 种语言，用于多语言多模态指令训练。实验结果表明，m3P 显著优于文本-only 基线和现有多模态方法，尤其在低资源和大规模多语言场景下表现出色。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "COLING 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.17556v1",
      "published_date": "2024-03-26 10:04:24 UTC",
      "updated_date": "2024-03-26 10:04:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:10:32.055728"
    },
    {
      "arxiv_id": "2403.17549v1",
      "title": "Practical Applications of Advanced Cloud Services and Generative AI Systems in Medical Image Analysis",
      "title_zh": "高级云服务和生成式 AI 系统在医学图像分析中的实际应用",
      "authors": [
        "Jingyu Xu",
        "Binbin Wu",
        "Jiaxin Huang",
        "Yulu Gong",
        "Yifan Zhang",
        "Bo Liu"
      ],
      "abstract": "The medical field is one of the important fields in the application of\nartificial intelligence technology. With the explosive growth and\ndiversification of medical data, as well as the continuous improvement of\nmedical needs and challenges, artificial intelligence technology is playing an\nincreasingly important role in the medical field. Artificial intelligence\ntechnologies represented by computer vision, natural language processing, and\nmachine learning have been widely penetrated into diverse scenarios such as\nmedical imaging, health management, medical information, and drug research and\ndevelopment, and have become an important driving force for improving the level\nand quality of medical services.The article explores the transformative\npotential of generative AI in medical imaging, emphasizing its ability to\ngenerate syntheticACM-2 data, enhance images, aid in anomaly detection, and\nfacilitate image-to-image translation. Despite challenges like model\ncomplexity, the applications of generative models in healthcare, including\nMed-PaLM 2 technology, show promising results. By addressing limitations in\ndataset size and diversity, these models contribute to more accurate diagnoses\nand improved patient outcomes. However, ethical considerations and\ncollaboration among stakeholders are essential for responsible implementation.\nThrough experiments leveraging GANs to augment brain tumor MRI datasets, the\nstudy demonstrates how generative AI can enhance image quality and diversity,\nultimately advancing medical diagnostics and patient care.",
      "tldr_zh": "该论文探讨了生成式 AI 在医疗图像分析中的实际应用，包括生成合成数据、图像增强、异常检测和图像转换，从而提高诊断准确性和患者结果。作者强调了如 Med-PaLM 2 和 GANs 等技术的潜力，通过实验对脑肿瘤 MRI 数据集进行增强，展示了图像质量和多样性的显著改善。尽管模型复杂性和数据集限制带来挑战，但论文指出，伦理考虑以及利益相关者间的合作是实现负责任应用的必要条件。",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.17549v1",
      "published_date": "2024-03-26 09:55:49 UTC",
      "updated_date": "2024-03-26 09:55:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:10:43.861687"
    },
    {
      "arxiv_id": "2403.17542v1",
      "title": "VDSC: Enhancing Exploration Timing with Value Discrepancy and State Counts",
      "title_zh": "VDSC: 通过价值差异和状态计数增强探索时机",
      "authors": [
        "Marius Captari",
        "Remo Sasso",
        "Matthia Sabatelli"
      ],
      "abstract": "Despite the considerable attention given to the questions of \\textit{how\nmuch} and \\textit{how to} explore in deep reinforcement learning, the\ninvestigation into \\textit{when} to explore remains relatively less researched.\nWhile more sophisticated exploration strategies can excel in specific, often\nsparse reward environments, existing simpler approaches, such as\n$\\epsilon$-greedy, persist in outperforming them across a broader spectrum of\ndomains. The appeal of these simpler strategies lies in their ease of\nimplementation and generality across a wide range of domains. The downside is\nthat these methods are essentially a blind switching mechanism, which\ncompletely disregards the agent's internal state. In this paper, we propose to\nleverage the agent's internal state to decide \\textit{when} to explore,\naddressing the shortcomings of blind switching mechanisms. We present Value\nDiscrepancy and State Counts through homeostasis (VDSC), a novel approach for\nefficient exploration timing. Experimental results on the Atari suite\ndemonstrate the superiority of our strategy over traditional methods such as\n$\\epsilon$-greedy and Boltzmann, as well as more sophisticated techniques like\nNoisy Nets.",
      "tldr_zh": "该论文探讨了强化学习中探索策略的“何时探索”问题，指出现有简单方法如 ε-greedy 虽然通用但忽略了代理的内部状态，导致盲目切换。作者提出 VDSC（Value Discrepancy and State Counts through homeostasis）方法，利用代理内部状态（如 Value Discrepancy 和 State Counts）来动态决定探索时机，从而提升探索效率。实验结果显示，在 Atari suite 上，VDSC 优于传统策略如 ε-greedy 和 Boltzmann，以及高级技术如 Noisy Nets，证明了其在广泛环境中的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.17542v1",
      "published_date": "2024-03-26 09:44:57 UTC",
      "updated_date": "2024-03-26 09:44:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:10:55.609118"
    },
    {
      "arxiv_id": "2403.17532v1",
      "title": "KC-GenRe: A Knowledge-constrained Generative Re-ranking Method Based on Large Language Models for Knowledge Graph Completion",
      "title_zh": "KC-GenRe：一种基于大型语言模型的知识约束生成式重新排序方法，用于知识图谱补全",
      "authors": [
        "Yilin Wang",
        "Minghao Hu",
        "Zhen Huang",
        "Dongsheng Li",
        "Dong Yang",
        "Xicheng Lu"
      ],
      "abstract": "The goal of knowledge graph completion (KGC) is to predict missing facts\namong entities. Previous methods for KGC re-ranking are mostly built on\nnon-generative language models to obtain the probability of each candidate.\nRecently, generative large language models (LLMs) have shown outstanding\nperformance on several tasks such as information extraction and dialog systems.\nLeveraging them for KGC re-ranking is beneficial for leveraging the extensive\npre-trained knowledge and powerful generative capabilities. However, it may\nencounter new problems when accomplishing the task, namely mismatch,\nmisordering and omission. To this end, we introduce KC-GenRe, a\nknowledge-constrained generative re-ranking method based on LLMs for KGC. To\novercome the mismatch issue, we formulate the KGC re-ranking task as a\ncandidate identifier sorting generation problem implemented by generative LLMs.\nTo tackle the misordering issue, we develop a knowledge-guided interactive\ntraining method that enhances the identification and ranking of candidates. To\naddress the omission issue, we design a knowledge-augmented constrained\ninference method that enables contextual prompting and controlled generation,\nso as to obtain valid rankings. Experimental results show that KG-GenRe\nachieves state-of-the-art performance on four datasets, with gains of up to\n6.7% and 7.7% in the MRR and Hits@1 metric compared to previous methods, and\n9.0% and 11.1% compared to that without re-ranking. Extensive analysis\ndemonstrates the effectiveness of components in KG-GenRe.",
      "tldr_zh": "本文提出 KC-GenRe，一种基于大型语言模型(LLMs)的知识约束生成式重排序方法，用于知识图谱补全(KGC)，旨在解决传统方法在重排序中的不匹配、错误排序和遗漏问题。方法将 KGC 重排序任务转化为候选标识符排序生成问题，并通过知识引导的交互训练和知识增强的约束推理来提升候选识别和排序准确性。实验结果显示，KC-GenRe 在四个数据集上达到最先进性能，MRR 和 Hits@1 指标分别较之前方法提升 6.7% 和 7.7%，并证明了其组件的有效性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "This paper has been accepted for publication in the proceedings of\n  LREC-COLING 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.17532v1",
      "published_date": "2024-03-26 09:36:59 UTC",
      "updated_date": "2024-03-26 09:36:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:11:09.765017"
    },
    {
      "arxiv_id": "2403.17530v1",
      "title": "Boosting Few-Shot Learning with Disentangled Self-Supervised Learning and Meta-Learning for Medical Image Classification",
      "title_zh": "通过解耦自监督学习和元学习提升少样本学习，用于医疗图像分类",
      "authors": [
        "Eva Pachetti",
        "Sotirios A. Tsaftaris",
        "Sara Colantonio"
      ],
      "abstract": "Background and objective: Employing deep learning models in critical domains\nsuch as medical imaging poses challenges associated with the limited\navailability of training data. We present a strategy for improving the\nperformance and generalization capabilities of models trained in low-data\nregimes. Methods: The proposed method starts with a pre-training phase, where\nfeatures learned in a self-supervised learning setting are disentangled to\nimprove the robustness of the representations for downstream tasks. We then\nintroduce a meta-fine-tuning step, leveraging related classes between\nmeta-training and meta-testing phases but varying the granularity level. This\napproach aims to enhance the model's generalization capabilities by exposing it\nto more challenging classification tasks during meta-training and evaluating it\non easier tasks but holding greater clinical relevance during meta-testing. We\ndemonstrate the effectiveness of the proposed approach through a series of\nexperiments exploring several backbones, as well as diverse pre-training and\nfine-tuning schemes, on two distinct medical tasks, i.e., classification of\nprostate cancer aggressiveness from MRI data and classification of breast\ncancer malignity from microscopic images. Results: Our results indicate that\nthe proposed approach consistently yields superior performance w.r.t. ablation\nexperiments, maintaining competitiveness even when a distribution shift between\ntraining and evaluation data occurs. Conclusion: Extensive experiments\ndemonstrate the effectiveness and wide applicability of the proposed approach.\nWe hope that this work will add another solution to the arsenal of addressing\nlearning issues in data-scarce imaging domains.",
      "tldr_zh": "本研究针对医疗图像分类中数据有限的挑战，提出了一种结合解缠结自监督学习（disentangled self-supervised learning）和元学习（meta-learning）的策略，以提升少样本学习（few-shot learning）的性能和泛化能力。方法包括先进行自监督预训练以解缠结特征，提高下游任务的鲁棒性，然后通过元微调步骤，利用元训练和元测试阶段的相关类和粒度差异，让模型适应更具挑战性的任务。实验在两个医疗任务上进行，包括从 MRI 数据分类前列腺癌侵略性和从显微图像分类乳腺癌恶性，结果显示该方法在消融实验中显著优于基线，即使存在数据分布偏移，也保持竞争力。总之，该方法证明了其在数据稀缺的图像领域中的有效性和广泛适用性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "I.2; I.4; I.5; J.3"
      ],
      "primary_category": "cs.CV",
      "comment": "20 pages, 4 figures, 4 tables. Submitted to Elsevier on 25 March 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.17530v1",
      "published_date": "2024-03-26 09:36:20 UTC",
      "updated_date": "2024-03-26 09:36:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:11:20.385837"
    },
    {
      "arxiv_id": "2403.17525v2",
      "title": "Equipping Sketch Patches with Context-Aware Positional Encoding for Graphic Sketch Representation",
      "title_zh": "为草图补丁配备上下文感知位置编码以实现图形草图表示",
      "authors": [
        "Sicong Zang",
        "Zhijun Fang"
      ],
      "abstract": "When benefiting graphic sketch representation with sketch drawing orders,\nrecent studies have linked sketch patches as graph edges by drawing orders in\naccordance to a temporal-based nearest neighboring strategy. However, such\nconstructed graph edges may be unreliable, since the contextual relationships\nbetween patches may be inconsistent with the sequential positions in drawing\norders, due to variants of sketch drawings. In this paper, we propose a\nvariant-drawing-protected method by equipping sketch patches with context-aware\npositional encoding (PE) to make better use of drawing orders for sketch\nlearning. We introduce a sinusoidal absolute PE to embed the sequential\npositions in drawing orders, and a learnable relative PE to encode the unseen\ncontextual relationships between patches. Both types of PEs never attend the\nconstruction of graph edges, but are injected into graph nodes to cooperate\nwith the visual patterns captured from patches. After linking nodes by semantic\nproximity, during message aggregation via graph convolutional networks, each\nnode receives both semantic features from patches and contextual information\nfrom PEs from its neighbors, which equips local patch patterns with global\ncontextual information, further obtaining drawing-order-enhanced sketch\nrepresentations. Experimental results indicate that our method significantly\nimproves sketch healing and controllable sketch synthesis. The source codes\ncould be found at https://github.com/SCZang/DC-gra2seq.",
      "tldr_zh": "该论文针对图形草图表示中，依赖绘图顺序构建图边可能导致上下文关系不一致的问题，提出了一种配备上下文感知位置编码 (Context-Aware Positional Encoding) 的方法，以更好地利用绘图顺序。方法包括使用 Sinusoidal Absolute PE 嵌入顺序位置，以及 Learnable Relative PE 编码补丁间的上下文关系，这些编码注入到图节点中，与视觉模式合作，并在图卷积网络 (Graph Convolutional Networks) 的消息聚合过程中增强局部补丁与全局信息的结合。实验结果显示，该方法显著提高了草图修复和可控草图合成性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.17525v2",
      "published_date": "2024-03-26 09:26:12 UTC",
      "updated_date": "2025-05-13 07:25:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:11:34.496369"
    },
    {
      "arxiv_id": "2403.17516v2",
      "title": "MapGuide: A Simple yet Effective Method to Reconstruct Continuous Language from Brain Activities",
      "title_zh": "MapGuide：一种简单而有效的从脑活动重建连续语言的方法",
      "authors": [
        "Xinpei Zhao",
        "Jingyuan Sun",
        "Shaonan Wang",
        "Jing Ye",
        "Xiaohan Zhang",
        "Chengqing Zong"
      ],
      "abstract": "Decoding continuous language from brain activity is a formidable yet\npromising field of research. It is particularly significant for aiding people\nwith speech disabilities to communicate through brain signals. This field\naddresses the complex task of mapping brain signals to text. The previous best\nattempt reverse-engineered this process in an indirect way: it began by\nlearning to encode brain activity from text and then guided text generation by\naligning with predicted brain responses. In contrast, we propose a simple yet\neffective method that guides text reconstruction by directly comparing them\nwith the predicted text embeddings mapped from brain activities. Comprehensive\nexperiments reveal that our method significantly outperforms the current\nstate-of-the-art model, showing average improvements of 77% and 54% on BLEU and\nMETEOR scores. We further validate the proposed modules through detailed\nablation studies and case analyses and highlight a critical correlation: the\nmore precisely we map brain activities to text embeddings, the better the text\nreconstruction results. Such insight can simplify the task of reconstructing\nlanguage from brain activities for future work, emphasizing the importance of\nimproving brain-to-text-embedding mapping techniques.",
      "tldr_zh": "该研究提出MapGuide，一种简单有效的从脑活动重建连续语言的方法，通过直接比较预测的文本嵌入（从脑活动映射而来）来指导文本重建，从而解决言语障碍者沟通难题，与之前间接编码脑活动的方法形成对比。实验结果显示，MapGuide在BLEU和METEOR分数上分别比当前最先进模型提高了77%和54%。此外，通过消融研究和案例分析，论文揭示了一个关键相关性：脑活动到文本嵌入的映射精度越高，文本重建效果越好，这为简化未来脑信号解码任务提供了重要启示。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to NAACL 2024 main conference",
      "pdf_url": "http://arxiv.org/pdf/2403.17516v2",
      "published_date": "2024-03-26 09:18:59 UTC",
      "updated_date": "2024-04-02 12:05:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:11:44.648018"
    },
    {
      "arxiv_id": "2403.17515v1",
      "title": "Prediction-sharing During Training and Inference",
      "title_zh": "翻译失败",
      "authors": [
        "Yotam Gafni",
        "Ronen Gradwohl",
        "Moshe Tennenholtz"
      ],
      "abstract": "Two firms are engaged in a competitive prediction task. Each firm has two\nsources of data -- labeled historical data and unlabeled inference-time data --\nand uses the former to derive a prediction model, and the latter to make\npredictions on new instances. We study data-sharing contracts between the\nfirms. The novelty of our study is to introduce and highlight the differences\nbetween contracts that share prediction models only, contracts to share\ninference-time predictions only, and contracts to share both. Our analysis\nproceeds on three levels. First, we develop a general Bayesian framework that\nfacilitates our study. Second, we narrow our focus to two natural settings\nwithin this framework: (i) a setting in which the accuracy of each firm's\nprediction model is common knowledge, but the correlation between the\nrespective models is unknown; and (ii) a setting in which two hypotheses exist\nregarding the optimal predictor, and one of the firms has a structural\nadvantage in deducing it. Within these two settings we study optimal contract\nchoice. More specifically, we find the individually rational and Pareto-optimal\ncontracts for some notable cases, and describe specific settings where each of\nthe different sharing contracts emerge as optimal. Finally, in the third level\nof our analysis we demonstrate the applicability of our concepts in a synthetic\nsimulation using real loan data.",
      "tldr_zh": "这篇论文探讨了两个公司在竞争性预测任务中数据共享合同的设计，每个公司利用标记的历史数据训练模型，并使用未标记的推理时数据进行预测。作者引入了三种合同类型：仅共享预测模型、仅共享推理时预测，或两者兼备，并使用Bayesian框架进行分析。研究聚焦于两个场景：（1）模型准确性为共同知识但相关性未知；（2）存在两种最优预测器假设，其中一公司有结构优势。结果显示，在特定情况下，某些共享合同是个体理性和Pareto-optimal的，并通过合成模拟和真实贷款数据验证了这些概念。",
      "categories": [
        "econ.TH",
        "cs.AI",
        "cs.GT",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "econ.TH",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.17515v1",
      "published_date": "2024-03-26 09:18:50 UTC",
      "updated_date": "2024-03-26 09:18:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:11:56.674765"
    },
    {
      "arxiv_id": "2403.17479v1",
      "title": "Natural Language Requirements Testability Measurement Based on Requirement Smells",
      "title_zh": "基于需求气味的自然语言需求可测试性测量",
      "authors": [
        "Morteza Zakeri-Nasrabadi",
        "Saeed Parsa"
      ],
      "abstract": "Requirements form the basis for defining software systems' obligations and\ntasks. Testable requirements help prevent failures, reduce maintenance costs,\nand make it easier to perform acceptance tests. However, despite the importance\nof measuring and quantifying requirements testability, no automatic approach\nfor measuring requirements testability has been proposed based on the\nrequirements smells, which are at odds with the requirements testability. This\npaper presents a mathematical model to evaluate and rank the natural language\nrequirements testability based on an extensive set of nine requirements smells,\ndetected automatically, and acceptance test efforts determined by requirement\nlength and its application domain. Most of the smells stem from uncountable\nadjectives, context-sensitive, and ambiguous words. A comprehensive dictionary\nis required to detect such words. We offer a neural word-embedding technique to\ngenerate such a dictionary automatically. Using the dictionary, we could\nautomatically detect Polysemy smell (domain-specific ambiguity) for the first\ntime in 10 application domains. Our empirical study on nearly 1000 software\nrequirements from six well-known industrial and academic projects demonstrates\nthat the proposed smell detection approach outperforms Smella, a\nstate-of-the-art tool, in detecting requirements smells. The precision and\nrecall of smell detection are improved with an average of 0.03 and 0.33,\nrespectively, compared to the state-of-the-art. The proposed requirement\ntestability model measures the testability of 985 requirements with a mean\nabsolute error of 0.12 and a mean squared error of 0.03, demonstrating the\nmodel's potential for practical use.",
      "tldr_zh": "这篇论文提出了一种基于 requirements smells 的数学模型，用于评估和排名自然语言 requirements 的测试性，以帮助防止软件失败、降低维护成本并简化验收测试。模型依赖于自动检测的九种 requirements smells（如不可数形容词、上下文敏感词和模糊词），并结合要求长度和应用领域，使用神经词嵌入技术自动生成字典，首次实现了在10个应用领域检测 Polysemy smell。实证研究对近1000个软件 requirements 进行了分析，与 state-of-the-art 工具 Smella 相比，精确率和召回率分别平均提高了0.03和0.33；该模型对985个 requirements 的测试性测量显示，平均绝对误差为0.12，均方误差为0.03，证明了其实际应用潜力。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "45 pages, 16 figures, and 13 tables; submitted as a journal paper",
      "pdf_url": "http://arxiv.org/pdf/2403.17479v1",
      "published_date": "2024-03-26 08:19:29 UTC",
      "updated_date": "2024-03-26 08:19:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:12:09.574875"
    },
    {
      "arxiv_id": "2403.17467v1",
      "title": "A Unified Kernel for Neural Network Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Shao-Qun Zhang",
        "Zong-Yi Chen",
        "Yong-Ming Tian",
        "Xun Lu"
      ],
      "abstract": "Past decades have witnessed a great interest in the distinction and\nconnection between neural network learning and kernel learning. Recent\nadvancements have made theoretical progress in connecting infinite-wide neural\nnetworks and Gaussian processes. Two predominant approaches have emerged: the\nNeural Network Gaussian Process (NNGP) and the Neural Tangent Kernel (NTK). The\nformer, rooted in Bayesian inference, represents a zero-order kernel, while the\nlatter, grounded in the tangent space of gradient descents, is a first-order\nkernel. In this paper, we present the Unified Neural Kernel (UNK), which\ncharacterizes the learning dynamics of neural networks with gradient descents\nand parameter initialization. The proposed UNK kernel maintains the limiting\nproperties of both NNGP and NTK, exhibiting behaviors akin to NTK with a finite\nlearning step and converging to NNGP as the learning step approaches infinity.\nBesides, we also theoretically characterize the uniform tightness and learning\nconvergence of the UNK kernel, providing comprehensive insights into this\nunified kernel. Experimental results underscore the effectiveness of our\nproposed method.",
      "tldr_zh": "本论文提出Unified Neural Kernel (UNK)，一种统一框架，用于描述神经网络在梯度下降和参数初始化下的学习动态，从而桥接Neural Network Gaussian Process (NNGP)和Neural Tangent Kernel (NTK)。UNK在有限学习步长下表现类似于NTK，并在步长趋于无穷大时收敛到NNGP，同时理论上证明了其均匀紧致性和学习收敛性。该方法通过实验验证了其有效性，为神经网络学习与内核学习的整合提供了新见解。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.17467v1",
      "published_date": "2024-03-26 07:55:45 UTC",
      "updated_date": "2024-03-26 07:55:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:12:20.262470"
    },
    {
      "arxiv_id": "2403.17465v4",
      "title": "LaRE$^2$: Latent Reconstruction Error Based Method for Diffusion-Generated Image Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Yunpeng Luo",
        "Junlong Du",
        "Ke Yan",
        "Shouhong Ding"
      ],
      "abstract": "The evolution of Diffusion Models has dramatically improved image generation\nquality, making it increasingly difficult to differentiate between real and\ngenerated images. This development, while impressive, also raises significant\nprivacy and security concerns. In response to this, we propose a novel Latent\nREconstruction error guided feature REfinement method (LaRE^2) for detecting\nthe diffusion-generated images. We come up with the Latent Reconstruction Error\n(LaRE), the first reconstruction-error based feature in the latent space for\ngenerated image detection. LaRE surpasses existing methods in terms of feature\nextraction efficiency while preserving crucial cues required to differentiate\nbetween the real and the fake. To exploit LaRE, we propose an Error-Guided\nfeature REfinement module (EGRE), which can refine the image feature guided by\nLaRE to enhance the discriminativeness of the feature. Our EGRE utilizes an\nalign-then-refine mechanism, which effectively refines the image feature for\ngenerated-image detection from both spatial and channel perspectives. Extensive\nexperiments on the large-scale GenImage benchmark demonstrate the superiority\nof our LaRE^2, which surpasses the best SoTA method by up to 11.9%/12.1%\naverage ACC/AP across 8 different image generators. LaRE also surpasses\nexisting methods in terms of feature extraction cost, delivering an impressive\nspeed enhancement of 8 times. Code is available.",
      "tldr_zh": "这篇论文针对Diffusion Models生成的图像检测问题，提出了一种新型方法LaRE²（Latent Reconstruction Error guided feature REfinement method）。该方法引入Latent Reconstruction Error (LaRE)作为首个在潜在空间的基于重建错误的特征，以高效提取区分真实和生成图像的关键线索，并通过Error-Guided feature REfinement module (EGRE)采用align-then-refine机制，从空间和通道角度精炼图像特征。在GenImage benchmark上的实验显示，LaRE²比最佳SoTA方法平均ACC/AP提高了多达11.9%/12.1%跨8个图像生成器，同时实现了8倍的特征提取速度提升。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2024. Code is available at https://github.com/luo3300612/LaRE",
      "pdf_url": "http://arxiv.org/pdf/2403.17465v4",
      "published_date": "2024-03-26 07:55:16 UTC",
      "updated_date": "2025-02-21 12:51:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:12:33.775243"
    },
    {
      "arxiv_id": "2403.17456v3",
      "title": "Imitating Cost-Constrained Behaviors in Reinforcement Learning",
      "title_zh": "在强化学习中模仿成本约束的行为",
      "authors": [
        "Qian Shao",
        "Pradeep Varakantham",
        "Shih-Fen Cheng"
      ],
      "abstract": "Complex planning and scheduling problems have long been solved using various\noptimization or heuristic approaches. In recent years, imitation learning that\naims to learn from expert demonstrations has been proposed as a viable\nalternative to solving these problems. Generally speaking, imitation learning\nis designed to learn either the reward (or preference) model or directly the\nbehavioral policy by observing the behavior of an expert. Existing work in\nimitation learning and inverse reinforcement learning has focused on imitation\nprimarily in unconstrained settings (e.g., no limit on fuel consumed by the\nvehicle). However, in many real-world domains, the behavior of an expert is\ngoverned not only by reward (or preference) but also by constraints. For\ninstance, decisions on self-driving delivery vehicles are dependent not only on\nthe route preferences/rewards (depending on past demand data) but also on the\nfuel in the vehicle and the time available. In such problems, imitation\nlearning is challenging as decisions are not only dictated by the reward model\nbut are also dependent on a cost-constrained model. In this paper, we provide\nmultiple methods that match expert distributions in the presence of trajectory\ncost constraints through (a) Lagrangian-based method; (b) Meta-gradients to\nfind a good trade-off between expected return and minimizing constraint\nviolation; and (c) Cost-violation-based alternating gradient. We empirically\nshow that leading imitation learning approaches imitate cost-constrained\nbehaviors poorly and our meta-gradient-based approach achieves the best\nperformance.",
      "tldr_zh": "这篇论文探讨了在强化学习中模仿受成本约束行为的挑战，传统imitation learning方法主要针对无约束环境，导致在现实场景（如自驾车辆的燃料限制）中表现不佳。作者提出了三种方法来匹配专家行为的轨迹分布：（a）基于Lagrangian的优化方法、（b）Meta-gradients来平衡预期回报和约束违反、以及（c）Cost-violation-based alternating gradient。实验结果表明，这些方法中Meta-gradients方法表现出色，显著优于现有imitation learning方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to the 34th International Conference on Automated Planning\n  and Scheduling (ICAPS-24)",
      "pdf_url": "http://arxiv.org/pdf/2403.17456v3",
      "published_date": "2024-03-26 07:41:54 UTC",
      "updated_date": "2024-05-23 08:57:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:12:44.015145"
    },
    {
      "arxiv_id": "2403.17445v1",
      "title": "Incorporating Exponential Smoothing into MLP: A Simple but Effective Sequence Model",
      "title_zh": "将指数平滑融入 MLP：一个简单但有效的序列模型",
      "authors": [
        "Jiqun Chu",
        "Zuoquan Lin"
      ],
      "abstract": "Modeling long-range dependencies in sequential data is a crucial step in\nsequence learning. A recently developed model, the Structured State Space (S4),\ndemonstrated significant effectiveness in modeling long-range sequences.\nHowever, It is unclear whether the success of S4 can be attributed to its\nintricate parameterization and HiPPO initialization or simply due to State\nSpace Models (SSMs). To further investigate the potential of the deep SSMs, we\nstart with exponential smoothing (ETS), a simple SSM, and propose a stacked\narchitecture by directly incorporating it into an element-wise MLP. We augment\nsimple ETS with additional parameters and complex field to reduce the inductive\nbias. Despite increasing less than 1\\% of parameters of element-wise MLP, our\nmodels achieve comparable results to S4 on the LRA benchmark.",
      "tldr_zh": "该研究探讨了序列学习中建模长程依赖的重要性，并质疑 Structured State Space (S4) 模型的成功是否源于其复杂参数化和 HiPPO 初始化。作者提出了一种简单方法，将 Exponential Smoothing (ETS) 整合到元素级 MLP 中，形成一个堆叠架构，通过添加少于 1% 参数和复杂字段来减少归纳偏差。尽管模型设计简单，该方法在 LRA benchmark 上取得了与 S4 相当的性能结果，证明了简单 State Space Models (SSMs) 的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages, 5 tables, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.17445v1",
      "published_date": "2024-03-26 07:23:46 UTC",
      "updated_date": "2024-03-26 07:23:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:12:56.109612"
    },
    {
      "arxiv_id": "2403.17428v2",
      "title": "Aligning Large Language Models for Enhancing Psychiatric Interviews Through Symptom Delineation and Summarization: Pilot Study",
      "title_zh": "翻译失败",
      "authors": [
        "Jae-hee So",
        "Joonhwan Chang",
        "Eunji Kim",
        "Junho Na",
        "JiYeon Choi",
        "Jy-yong Sohn",
        "Byung-Hoon Kim",
        "Sang Hui Chu"
      ],
      "abstract": "Background: Advancements in large language models (LLMs) have opened new\npossibilities in psychiatric interviews, an underexplored area where LLMs could\nbe valuable. This study focuses on enhancing psychiatric interviews by\nanalyzing counseling data from North Korean defectors who have experienced\ntrauma and mental health issues.\n  Objective: The study investigates whether LLMs can (1) identify parts of\nconversations that suggest psychiatric symptoms and recognize those symptoms,\nand (2) summarize stressors and symptoms based on interview transcripts.\n  Methods: LLMs are tasked with (1) extracting stressors from transcripts, (2)\nidentifying symptoms and their corresponding sections, and (3) generating\ninterview summaries using the extracted data. The transcripts were labeled by\nmental health experts for training and evaluation.\n  Results: In the zero-shot inference setting using GPT-4 Turbo, 73 out of 102\nsegments demonstrated a recall mid-token distance d < 20 in identifying\nsymptom-related sections. For recognizing specific symptoms, fine-tuning\noutperformed zero-shot inference, achieving an accuracy, precision, recall, and\nF1-score of 0.82. For the generative summarization task, LLMs using symptom and\nstressor information scored highly on G-Eval metrics: coherence (4.66),\nconsistency (4.73), fluency (2.16), and relevance (4.67). Retrieval-augmented\ngeneration showed no notable performance improvement.\n  Conclusions: LLMs, with fine-tuning or appropriate prompting, demonstrated\nstrong accuracy (over 0.8) for symptom delineation and achieved high coherence\n(4.6+) in summarization. This study highlights their potential to assist mental\nhealth practitioners in analyzing psychiatric interviews.",
      "tldr_zh": "本研究探讨了大型语言模型（LLMs）在精神病学访谈中的应用，旨在通过症状界定和总结来辅助分析朝鲜脱北者的创伤和心理健康数据。研究目标包括识别对话中暗示精神症状的部分及其症状，并基于访谈记录生成压力源和症状总结。方法涉及使用GPT-4 Turbo进行零样本推理和微调任务，包括提取压力源、识别症状相关段落，以及生成总结，并以专家标记数据进行评估。结果显示，微调后症状识别准确率、精确率、召回率和F1分数均达0.82，而总结生成在G-Eval指标上表现出高连贯性（4.66）和一致性（4.73），尽管检索增强生成未见显著提升。该研究证明LLMs通过适当提示或微调，能以超过0.8的准确率辅助心理健康从业者分析访谈，提供潜在临床支持。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.17428v2",
      "published_date": "2024-03-26 06:50:04 UTC",
      "updated_date": "2025-02-10 13:28:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:13:10.334755"
    },
    {
      "arxiv_id": "2403.17426v1",
      "title": "Knowledge-Powered Recommendation for an Improved Diet Water Footprint",
      "title_zh": "翻译失败",
      "authors": [
        "Saurav Joshi",
        "Filip Ilievski",
        "Jay Pujara"
      ],
      "abstract": "According to WWF, 1.1 billion people lack access to water, and 2.7 billion\nexperience water scarcity at least one month a year. By 2025, two-thirds of the\nworld's population may be facing water shortages. This highlights the urgency\nof managing water usage efficiently, especially in water-intensive sectors like\nfood. This paper proposes a recommendation engine, powered by knowledge graphs,\naiming to facilitate sustainable and healthy food consumption. The engine\nrecommends ingredient substitutes in user recipes that improve nutritional\nvalue and reduce environmental impact, particularly water footprint. The system\narchitecture includes source identification, information extraction, schema\nalignment, knowledge graph construction, and user interface development. The\nresearch offers a promising tool for promoting healthier eating habits and\ncontributing to water conservation efforts.",
      "tldr_zh": "该论文针对全球水资源短缺问题（如11亿人缺水和27亿人每年至少一个月面临水荒），提出了一种基于知识 graphs 的推荐引擎，以促进可持续健康饮食。系统通过分析用户配方，推荐成分替代方案，提高营养价值并降低水 footprint 等环境影响。整体架构包括源识别、信息提取、schema alignment、知识图谱构建和用户界面开发，为推动更健康的饮食习惯和水资源保护提供了一个有前景的工具。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "3 pages, 1 figure, AAAI'24",
      "pdf_url": "http://arxiv.org/pdf/2403.17426v1",
      "published_date": "2024-03-26 06:47:17 UTC",
      "updated_date": "2024-03-26 06:47:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:13:20.829934"
    },
    {
      "arxiv_id": "2403.17421v3",
      "title": "MA4DIV: Multi-Agent Reinforcement Learning for Search Result Diversification",
      "title_zh": "翻译失败",
      "authors": [
        "Yiqun Chen",
        "Jiaxin Mao",
        "Yi Zhang",
        "Dehong Ma",
        "Long Xia",
        "Jun Fan",
        "Daiting Shi",
        "Zhicong Cheng",
        "Simiu Gu",
        "Dawei Yin"
      ],
      "abstract": "Search result diversification (SRD), which aims to ensure that documents in a\nranking list cover a broad range of subtopics, is a significant and widely\nstudied problem in Information Retrieval and Web Search. Existing methods\nprimarily utilize a paradigm of \"greedy selection\", i.e., selecting one\ndocument with the highest diversity score at a time or optimize an\napproximation of the objective function. These approaches tend to be\ninefficient and are easily trapped in a suboptimal state. To address these\nchallenges, we introduce Multi-Agent reinforcement learning (MARL) for search\nresult DIVersity, which called MA4DIV. In this approach, each document is an\nagent and the search result diversification is modeled as a cooperative task\namong multiple agents. By modeling the SRD ranking problem as a cooperative\nMARL problem, this approach allows for directly optimizing the diversity\nmetrics, such as $\\alpha$-NDCG, while achieving high training efficiency. We\nconducted experiments on public TREC datasets and a larger scale dataset in the\nindustrial setting. The experiemnts show that MA4DIV achieves substantial\nimprovements in both effectiveness and efficiency than existing baselines,\nespecially on the industrial dataset. The code of MA4DIV can be seen on\nhttps://github.com/chenyiqun/MA4DIV.",
      "tldr_zh": "本研究针对搜索结果多样化 (SRD) 问题，提出了一种基于 Multi-Agent Reinforcement Learning (MARL) 的框架 MA4DIV，以解决现有贪婪选择方法的效率低下和易陷入次优状态的局限。MA4DIV 将每个文档视为一个智能体，将 SRD 建模为多智能体间的合作任务，从而直接优化多样性指标如 α-NDCG，同时提升训练效率。在 TREC 数据集和工业规模数据集上的实验表明，该方法在有效性和效率上均显著优于现有基线，尤其在工业场景中表现突出。代码已在 GitHub 上公开。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.17421v3",
      "published_date": "2024-03-26 06:34:23 UTC",
      "updated_date": "2025-02-06 14:41:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:13:32.950996"
    },
    {
      "arxiv_id": "2403.17419v1",
      "title": "AI Safety: Necessary, but insufficient and possibly problematic",
      "title_zh": "AI 安全：必要的，但不足够且可能有问题",
      "authors": [
        "Deepak P"
      ],
      "abstract": "This article critically examines the recent hype around AI safety. We first\nstart with noting the nature of the AI safety hype as being dominated by\ngovernments and corporations, and contrast it with other avenues within AI\nresearch on advancing social good. We consider what 'AI safety' actually means,\nand outline the dominant concepts that the digital footprint of AI safety\naligns with. We posit that AI safety has a nuanced and uneasy relationship with\ntransparency and other allied notions associated with societal good, indicating\nthat it is an insufficient notion if the goal is that of societal good in a\nbroad sense. We note that the AI safety debate has already influenced some\nregulatory efforts in AI, perhaps in not so desirable directions. We also share\nour concerns on how AI safety may normalize AI that advances structural harm\nthrough providing exploitative and harmful AI with a veneer of safety.",
      "tldr_zh": "这篇文章批判性地审视了 AI Safety 的炒作，指出其主要由政府和公司主导，与其他促进社会公益的 AI 研究途径形成对比。作者探讨了“AI Safety”的实际含义及其数字足迹所对应的主导概念，认为它与透明性(transparency)和其他社会公益相关概念的关系微妙且不安定，因此在追求广义社会公益时是不充分的。文章进一步警告，AI Safety 辩论可能影响 AI 监管(regulatory efforts)走向不理想的方向，并可能使推进结构性伤害的剥削性 AI 获得安全表象，从而正常化有害技术。",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "AI & Soc (2024)",
      "pdf_url": "http://arxiv.org/pdf/2403.17419v1",
      "published_date": "2024-03-26 06:18:42 UTC",
      "updated_date": "2024-03-26 06:18:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:13:46.137173"
    },
    {
      "arxiv_id": "2403.17410v2",
      "title": "On permutation-invariant neural networks",
      "title_zh": "翻译失败",
      "authors": [
        "Masanari Kimura",
        "Ryotaro Shimizu",
        "Yuki Hirakawa",
        "Ryosuke Goto",
        "Yuki Saito"
      ],
      "abstract": "Conventional machine learning algorithms have traditionally been designed\nunder the assumption that input data follows a vector-based format, with an\nemphasis on vector-centric paradigms. However, as the demand for tasks\ninvolving set-based inputs has grown, there has been a paradigm shift in the\nresearch community towards addressing these challenges. In recent years, the\nemergence of neural network architectures such as Deep Sets and Transformers\nhas presented a significant advancement in the treatment of set-based data.\nThese architectures are specifically engineered to naturally accommodate sets\nas input, enabling more effective representation and processing of set\nstructures. Consequently, there has been a surge of research endeavors\ndedicated to exploring and harnessing the capabilities of these architectures\nfor various tasks involving the approximation of set functions. This\ncomprehensive survey aims to provide an overview of the diverse problem\nsettings and ongoing research efforts pertaining to neural networks that\napproximate set functions. By delving into the intricacies of these approaches\nand elucidating the associated challenges, the survey aims to equip readers\nwith a comprehensive understanding of the field. Through this comprehensive\nperspective, we hope that researchers can gain valuable insights into the\npotential applications, inherent limitations, and future directions of\nset-based neural networks. Indeed, from this survey we gain two insights: i)\nDeep Sets and its variants can be generalized by differences in the aggregation\nfunction, and ii) the behavior of Deep Sets is sensitive to the choice of the\naggregation function. From these observations, we show that Deep Sets, one of\nthe well-known permutation-invariant neural networks, can be generalized in the\nsense of a quasi-arithmetic mean.",
      "tldr_zh": "这篇论文综述了排列不变神经网络(permutation-invariant neural networks)，聚焦于处理集合数据(set-based inputs)的挑战，并回顾了Deep Sets和Transformers等架构的进展。这些架构通过自然适应集合结构，提高了集合函数(set functions)近似的效果。论文提供了两个关键见解：i) Deep Sets及其变体可以通过聚合函数(aggregation function)的差异进行泛化，ii) Deep Sets的行为对聚合函数的选择高度敏感，从而展示了Deep Sets可以用准算术均值(quasi-arithmetic mean)进行泛化。该综述有助于读者理解该领域的应用潜力、局限性和未来方向。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.17410v2",
      "published_date": "2024-03-26 06:06:01 UTC",
      "updated_date": "2024-03-28 22:28:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:13:57.571572"
    },
    {
      "arxiv_id": "2403.17407v3",
      "title": "Transcribing Bengali Text with Regional Dialects to IPA using District Guided Tokens",
      "title_zh": "翻译失败",
      "authors": [
        "S M Jishanul Islam",
        "Sadia Ahmmed",
        "Sahid Hossain Mustakim"
      ],
      "abstract": "Accurate transcription of Bengali text to the International Phonetic Alphabet\n(IPA) is a challenging task due to the complex phonology of the language and\ncontext-dependent sound changes. This challenge is even more for regional\nBengali dialects due to unavailability of standardized spelling conventions for\nthese dialects, presence of local and foreign words popular in those regions\nand phonological diversity across different regions. This paper presents an\napproach to this sequence-to-sequence problem by introducing the District\nGuided Tokens (DGT) technique on a new dataset spanning six districts of\nBangladesh. The key idea is to provide the model with explicit information\nabout the regional dialect or \"district\" of the input text before generating\nthe IPA transcription. This is achieved by prepending a district token to the\ninput sequence, effectively guiding the model to understand the unique phonetic\npatterns associated with each district. The DGT technique is applied to\nfine-tune several transformer-based models, on this new dataset. Experimental\nresults demonstrate the effectiveness of DGT, with the ByT5 model achieving\nsuperior performance over word-based models like mT5, BanglaT5, and umT5. This\nis attributed to ByT5's ability to handle a high percentage of\nout-of-vocabulary words in the test set. The proposed approach highlights the\nimportance of incorporating regional dialect information into ubiquitous\nnatural language processing systems for languages with diverse phonological\nvariations. The following work was a result of the \"Bhashamul\" challenge, which\nis dedicated to solving the problem of Bengali text with regional dialects to\nIPA transcription https://www.kaggle.com/competitions/regipa/. The training and\ninference notebooks are available through the competition link.",
      "tldr_zh": "该研究针对孟加拉语文本转国际音标 (IPA) 的挑战，提出了一种使用 District Guided Tokens (DGT) 技术的方法，以处理区域方言的复杂音韵变化、缺乏标准化拼写和词汇多样性问题。具体而言，该方法在输入序列前添加区域（district）标记，帮助 Transformer-based 模型理解特定地区的语音模式，并在涵盖孟加拉国六个地区的全新数据集上进行微调。实验结果显示，ByT5 模型在处理高比例词汇外词汇时表现出色，优于 mT5、BanglaT5 和 umT5 等模型，显著提升了转录准确性。该方法强调了在自然语言处理系统中整合区域方言信息的重要性，并源于“Bhashamul”挑战。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "F.2.2; I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "Updated missing references to the dataset and corrected some\n  sentences in sections 1 and 2. This work became the champion of the Bhashamul\n  challenge",
      "pdf_url": "http://arxiv.org/pdf/2403.17407v3",
      "published_date": "2024-03-26 05:55:21 UTC",
      "updated_date": "2024-04-02 04:15:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:14:09.789026"
    },
    {
      "arxiv_id": "2403.17395v1",
      "title": "An Open-source End-to-End Logic Optimization Framework for Large-scale Boolean Network with Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Zhen Li",
        "Kaixiang Zhu",
        "Xuegong Zhou",
        "Lingli Wang"
      ],
      "abstract": "We propose an open-source end-to-end logic optimization framework for\nlarge-scale boolean network with reinforcement learning.",
      "tldr_zh": "这篇论文提出了一种开源的端到-end逻辑优化框架，针对大规模Boolean网络进行优化。框架利用Reinforcement Learning来实现端到端的优化流程，提供高效的解决方案。该框架的开源特性有助于推动相关领域的进一步研究和应用。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "5 pages, 4 figures, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2403.17395v1",
      "published_date": "2024-03-26 05:25:01 UTC",
      "updated_date": "2024-03-26 05:25:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:14:19.904870"
    },
    {
      "arxiv_id": "2403.17385v1",
      "title": "ELLEN: Extremely Lightly Supervised Learning For Efficient Named Entity Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Haris Riaz",
        "Razvan-Gabriel Dumitru",
        "Mihai Surdeanu"
      ],
      "abstract": "In this work, we revisit the problem of semi-supervised named entity\nrecognition (NER) focusing on extremely light supervision, consisting of a\nlexicon containing only 10 examples per class. We introduce ELLEN, a simple,\nfully modular, neuro-symbolic method that blends fine-tuned language models\nwith linguistic rules. These rules include insights such as ''One Sense Per\nDiscourse'', using a Masked Language Model as an unsupervised NER, leveraging\npart-of-speech tags to identify and eliminate unlabeled entities as false\nnegatives, and other intuitions about classifier confidence scores in local and\nglobal context. ELLEN achieves very strong performance on the CoNLL-2003\ndataset when using the minimal supervision from the lexicon above. It also\noutperforms most existing (and considerably more complex) semi-supervised NER\nmethods under the same supervision settings commonly used in the literature\n(i.e., 5% of the training data). Further, we evaluate our CoNLL-2003 model in a\nzero-shot scenario on WNUT-17 where we find that it outperforms GPT-3.5 and\nachieves comparable performance to GPT-4. In a zero-shot setting, ELLEN also\nachieves over 75% of the performance of a strong, fully supervised model\ntrained on gold data. Our code is available at:\nhttps://github.com/hriaz17/ELLEN.",
      "tldr_zh": "本文提出 ELLEN，一种极简监督的命名实体识别 (NER) 方法，结合微调语言模型与语言规则（如 “One Sense Per Discourse”、Masked Language Model 和词性标签处理），仅需每个类 10 个示例的词汇表即可实现高效学习。实验结果显示，ELLEN 在 CoNLL-2003 数据集上显著优于现有半监督方法，并在相同监督设置下（如 5% 训练数据）表现出色。在零样本场景中，ELLEN 超越了 GPT-3.5，在 WNUT-17 上与 GPT-4 相当，并达到了完全监督模型性能的 75% 以上。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to LREC-COLING 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.17385v1",
      "published_date": "2024-03-26 05:11:51 UTC",
      "updated_date": "2024-03-26 05:11:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:14:35.368844"
    },
    {
      "arxiv_id": "2403.17384v1",
      "title": "Explainable Graph Neural Networks for Observation Impact Analysis in Atmospheric State Estimation",
      "title_zh": "可解释图神经网络用于大气状态估计中的观测影响分析",
      "authors": [
        "Hyeon-Ju Jeon",
        "Jeon-Ho Kang",
        "In-Hyuk Kwon",
        "O-Joun Lee"
      ],
      "abstract": "This paper investigates the impact of observations on atmospheric state\nestimation in weather forecasting systems using graph neural networks (GNNs)\nand explainability methods. We integrate observation and Numerical Weather\nPrediction (NWP) points into a meteorological graph, extracting $k$-hop\nsubgraphs centered on NWP points. Self-supervised GNNs are employed to estimate\nthe atmospheric state by aggregating data within these $k$-hop radii. The study\napplies gradient-based explainability methods to quantify the significance of\ndifferent observations in the estimation process. Evaluated with data from 11\nsatellite and land-based observations, the results highlight the effectiveness\nof visualizing the importance of observation types, enhancing the understanding\nand optimization of observational data in weather forecasting.",
      "tldr_zh": "这篇论文提出了一种使用 Graph Neural Networks (GNNs) 和可解释性方法来分析观察数据对大气状态估计的影响，旨在提升天气预报系统的优化。研究将观察数据和 Numerical Weather Prediction (NWP) 点整合成气象图，并提取以 NWP 点为中心的 k-hop subgraphs，通过自监督 GNNs 聚合数据来估计大气状态。接着，应用 gradient-based explainability methods 量化不同观察的重要性；在 11 种卫星和陆基观察数据上进行评估，结果显示了可视化观察类型重要性的有效性，从而增强了对观察数据的理解和优化潜力。",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.17384v1",
      "published_date": "2024-03-26 05:10:47 UTC",
      "updated_date": "2024-03-26 05:10:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:14:47.210040"
    },
    {
      "arxiv_id": "2403.17381v1",
      "title": "Application-Driven Innovation in Machine Learning",
      "title_zh": "机器学习中的应用驱动创新",
      "authors": [
        "David Rolnick",
        "Alan Aspuru-Guzik",
        "Sara Beery",
        "Bistra Dilkina",
        "Priya L. Donti",
        "Marzyeh Ghassemi",
        "Hannah Kerner",
        "Claire Monteleoni",
        "Esther Rolf",
        "Milind Tambe",
        "Adam White"
      ],
      "abstract": "As applications of machine learning proliferate, innovative algorithms\ninspired by specific real-world challenges have become increasingly important.\nSuch work offers the potential for significant impact not merely in domains of\napplication but also in machine learning itself. In this paper, we describe the\nparadigm of application-driven research in machine learning, contrasting it\nwith the more standard paradigm of methods-driven research. We illustrate the\nbenefits of application-driven machine learning and how this approach can\nproductively synergize with methods-driven work. Despite these benefits, we\nfind that reviewing, hiring, and teaching practices in machine learning often\nhold back application-driven innovation. We outline how these processes may be\nimproved.",
      "tldr_zh": "这篇论文探讨了机器学习中的 application-driven research 范式，即由真实世界挑战驱动的创新算法，与传统的 methods-driven research 进行对比。论文强调，这种应用导向方法不仅能在应用领域产生重大影响，还能反哺机器学习本身，并与方法驱动研究实现协同效应。尽管存在这些优势，但当前的审稿、招聘和教学实践往往抑制了 application-driven 创新。论文最后概述了改进这些过程的潜在策略，以促进更具影响力的机器学习研究。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.17381v1",
      "published_date": "2024-03-26 04:59:27 UTC",
      "updated_date": "2024-03-26 04:59:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:14:57.071928"
    },
    {
      "arxiv_id": "2403.17377v1",
      "title": "Self-Rectifying Diffusion Sampling with Perturbed-Attention Guidance",
      "title_zh": "翻译失败",
      "authors": [
        "Donghoon Ahn",
        "Hyoungwon Cho",
        "Jaewon Min",
        "Wooseok Jang",
        "Jungwoo Kim",
        "SeonHwa Kim",
        "Hyun Hee Park",
        "Kyong Hwan Jin",
        "Seungryong Kim"
      ],
      "abstract": "Recent studies have demonstrated that diffusion models are capable of\ngenerating high-quality samples, but their quality heavily depends on sampling\nguidance techniques, such as classifier guidance (CG) and classifier-free\nguidance (CFG). These techniques are often not applicable in unconditional\ngeneration or in various downstream tasks such as image restoration. In this\npaper, we propose a novel sampling guidance, called Perturbed-Attention\nGuidance (PAG), which improves diffusion sample quality across both\nunconditional and conditional settings, achieving this without requiring\nadditional training or the integration of external modules. PAG is designed to\nprogressively enhance the structure of samples throughout the denoising\nprocess. It involves generating intermediate samples with degraded structure by\nsubstituting selected self-attention maps in diffusion U-Net with an identity\nmatrix, by considering the self-attention mechanisms' ability to capture\nstructural information, and guiding the denoising process away from these\ndegraded samples. In both ADM and Stable Diffusion, PAG surprisingly improves\nsample quality in conditional and even unconditional scenarios. Moreover, PAG\nsignificantly improves the baseline performance in various downstream tasks\nwhere existing guidances such as CG or CFG cannot be fully utilized, including\nControlNet with empty prompts and image restoration such as inpainting and\ndeblurring.",
      "tldr_zh": "该论文提出了一种新型采样指导技术Perturbed-Attention Guidance (PAG)，旨在提升扩散模型在无条件和条件生成中的样本质量，而无需额外训练或外部模块。PAG通过在扩散U-Net的去噪过程中，用身份矩阵替换选定的self-attention映射，生成结构退化的中间样本，并引导模型远离这些样本，从而逐步增强样本的结构。实验结果显示，PAG在ADM和Stable Diffusion模型上显著提高了条件和无条件生成的质量，并在下游任务如ControlNet（空提示场景）和图像修复（包括修复和去模糊）中改善了基线性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Project page is available at\n  https://ku-cvlab.github.io/Perturbed-Attention-Guidance",
      "pdf_url": "http://arxiv.org/pdf/2403.17377v1",
      "published_date": "2024-03-26 04:49:11 UTC",
      "updated_date": "2024-03-26 04:49:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:15:11.056838"
    },
    {
      "arxiv_id": "2403.17373v1",
      "title": "AIDE: An Automatic Data Engine for Object Detection in Autonomous Driving",
      "title_zh": "翻译失败",
      "authors": [
        "Mingfu Liang",
        "Jong-Chyi Su",
        "Samuel Schulter",
        "Sparsh Garg",
        "Shiyu Zhao",
        "Ying Wu",
        "Manmohan Chandraker"
      ],
      "abstract": "Autonomous vehicle (AV) systems rely on robust perception models as a\ncornerstone of safety assurance. However, objects encountered on the road\nexhibit a long-tailed distribution, with rare or unseen categories posing\nchallenges to a deployed perception model. This necessitates an expensive\nprocess of continuously curating and annotating data with significant human\neffort. We propose to leverage recent advances in vision-language and large\nlanguage models to design an Automatic Data Engine (AIDE) that automatically\nidentifies issues, efficiently curates data, improves the model through\nauto-labeling, and verifies the model through generation of diverse scenarios.\nThis process operates iteratively, allowing for continuous self-improvement of\nthe model. We further establish a benchmark for open-world detection on AV\ndatasets to comprehensively evaluate various learning paradigms, demonstrating\nour method's superior performance at a reduced cost.",
      "tldr_zh": "该研究针对自动驾驶中物体检测面临的挑战，如道路物体长尾分布和稀有类别问题，提出了一种Automatic Data Engine (AIDE)。AIDE利用vision-language models和large language models自动识别问题、整理数据、进行auto-labeling，并通过生成多样场景来验证模型，实现模型的迭代式自提升。实验结果显示，该方法在建立的自动驾驶开放世界检测基准上，表现出优于其他学习范式的性能，同时显著降低了数据标注成本。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by CVPR-2024",
      "pdf_url": "http://arxiv.org/pdf/2403.17373v1",
      "published_date": "2024-03-26 04:27:56 UTC",
      "updated_date": "2024-03-26 04:27:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:15:21.446670"
    },
    {
      "arxiv_id": "2403.17368v1",
      "title": "ChatGPT Rates Natural Language Explanation Quality Like Humans: But on Which Scales?",
      "title_zh": "ChatGPT 像人类一样评级自然语言解释质量：但在哪些尺度上？",
      "authors": [
        "Fan Huang",
        "Haewoon Kwak",
        "Kunwoo Park",
        "Jisun An"
      ],
      "abstract": "As AI becomes more integral in our lives, the need for transparency and\nresponsibility grows. While natural language explanations (NLEs) are vital for\nclarifying the reasoning behind AI decisions, evaluating them through human\njudgments is complex and resource-intensive due to subjectivity and the need\nfor fine-grained ratings. This study explores the alignment between ChatGPT and\nhuman assessments across multiple scales (i.e., binary, ternary, and 7-Likert\nscale). We sample 300 data instances from three NLE datasets and collect 900\nhuman annotations for both informativeness and clarity scores as the text\nquality measurement. We further conduct paired comparison experiments under\ndifferent ranges of subjectivity scores, where the baseline comes from 8,346\nhuman annotations. Our results show that ChatGPT aligns better with humans in\nmore coarse-grained scales. Also, paired comparisons and dynamic prompting\n(i.e., providing semantically similar examples in the prompt) improve the\nalignment. This research advances our understanding of large language models'\ncapabilities to assess the text explanation quality in different configurations\nfor responsible AI development.",
      "tldr_zh": "本研究探讨了ChatGPT在评估自然语言解释(NLEs)质量时与人类的对齐程度，特别是在binary、ternary和7-Likert scale等不同粒度规模下的表现。研究者从三个NLE数据集采样300个实例，收集900个人类标注（针对informativeness和clarity），并通过配对比较实验和动态提示（提供语义相似的例子）来分析对齐情况。结果显示，ChatGPT在更粗粒度的规模上与人类评估更一致，且这些方法显著改善了其性能。该工作为理解大型语言模型在负责任AI发展中的文本解释评估能力提供了重要洞见。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accpeted by LREC-COLING 2024 main conference, long paper",
      "pdf_url": "http://arxiv.org/pdf/2403.17368v1",
      "published_date": "2024-03-26 04:07:08 UTC",
      "updated_date": "2024-03-26 04:07:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:15:34.735124"
    },
    {
      "arxiv_id": "2403.17361v1",
      "title": "Bridging Textual and Tabular Worlds for Fact Verification: A Lightweight, Attention-Based Model",
      "title_zh": "桥接文本和",
      "authors": [
        "Shirin Dabbaghi Varnosfaderani",
        "Canasai Kruengkrai",
        "Ramin Yahyapour",
        "Junichi Yamagishi"
      ],
      "abstract": "FEVEROUS is a benchmark and research initiative focused on fact extraction\nand verification tasks involving unstructured text and structured tabular data.\nIn FEVEROUS, existing works often rely on extensive preprocessing and utilize\nrule-based transformations of data, leading to potential context loss or\nmisleading encodings. This paper introduces a simple yet powerful model that\nnullifies the need for modality conversion, thereby preserving the original\nevidence's context. By leveraging pre-trained models on diverse text and\ntabular datasets and by incorporating a lightweight attention-based mechanism,\nour approach efficiently exploits latent connections between different data\ntypes, thereby yielding comprehensive and reliable verdict predictions. The\nmodel's modular structure adeptly manages multi-modal information, ensuring the\nintegrity and authenticity of the original evidence are uncompromised.\nComparative analyses reveal that our approach exhibits competitive performance,\naligning itself closely with top-tier models on the FEVEROUS benchmark.",
      "tldr_zh": "本论文提出了一种轻量级、基于注意力机制的模型，用于事实验证任务，旨在桥接文本和表格数据世界，同时避免传统模态转换带来的上下文损失。模型利用预训练模型处理非结构化文本和结构化表格数据，通过注意力机制高效捕捉潜在连接，确保证据的完整性和真实性。在 FEVEROUS 基准测试中，该方法表现出与顶级模型相当的竞争性性能，展示了其在事实提取和验证方面的可靠性和实用性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted for a presentation at LREC-COLING 2024 - The 2024 Joint\n  International Conference on Computational Linguistics, Language Resources and\n  Evaluation",
      "pdf_url": "http://arxiv.org/pdf/2403.17361v1",
      "published_date": "2024-03-26 03:54:25 UTC",
      "updated_date": "2024-03-26 03:54:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:15:44.905888"
    },
    {
      "arxiv_id": "2403.17358v1",
      "title": "Addressing Myopic Constrained POMDP Planning with Recursive Dual Ascent",
      "title_zh": "翻译失败",
      "authors": [
        "Paula Stocco",
        "Suhas Chundi",
        "Arec Jamgochian",
        "Mykel J. Kochenderfer"
      ],
      "abstract": "Lagrangian-guided Monte Carlo tree search with global dual ascent has been\napplied to solve large constrained partially observable Markov decision\nprocesses (CPOMDPs) online. In this work, we demonstrate that these global dual\nparameters can lead to myopic action selection during exploration, ultimately\nleading to suboptimal decision making. To address this, we introduce\nhistory-dependent dual variables that guide local action selection and are\noptimized with recursive dual ascent. We empirically compare the performance of\nour approach on a motivating toy example and two large CPOMDPs, demonstrating\nimproved exploration, and ultimately, safer outcomes.",
      "tldr_zh": "本研究发现，现有Lagrangian-guided Monte Carlo tree search使用全局dual ascent解决大型constrained partially observable Markov decision processes (CPOMDPs)时，会导致myopic行动选择和次优决策。为解决此问题，论文引入history-dependent dual variables来指导局部行动选择，并采用recursive dual ascent进行优化。实验结果显示，该方法在玩具示例和两个大型CPOMDPs上显著提升了探索效率，并实现了更安全的决策结果。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to the 2024 International Conference on Automated Planning\n  and Scheduling (ICAPS)",
      "pdf_url": "http://arxiv.org/pdf/2403.17358v1",
      "published_date": "2024-03-26 03:46:33 UTC",
      "updated_date": "2024-03-26 03:46:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:15:56.832888"
    },
    {
      "arxiv_id": "2403.17357v1",
      "title": "MESIA: Understanding and Leveraging Supplementary Nature of Method-level Comments for Automatic Comment Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Xinglu Pan",
        "Chenxiao Liu",
        "Yanzhen Zou",
        "Tao Xie",
        "Bing Xie"
      ],
      "abstract": "Code comments are important for developers in program comprehension. In\nscenarios of comprehending and reusing a method, developers expect code\ncomments to provide supplementary information beyond the method signature.\nHowever, the extent of such supplementary information varies a lot in different\ncode comments. In this paper, we raise the awareness of the supplementary\nnature of method-level comments and propose a new metric named MESIA (Mean\nSupplementary Information Amount) to assess the extent of supplementary\ninformation that a code comment can provide. With the MESIA metric, we conduct\nexperiments on a popular code-comment dataset and three common types of neural\napproaches to generate method-level comments. Our experimental results\ndemonstrate the value of our proposed work with a number of findings. (1)\nSmall-MESIA comments occupy around 20% of the dataset and mostly fall into only\nthe WHAT comment category. (2) Being able to provide various kinds of essential\ninformation, large-MESIA comments in the dataset are difficult for existing\nneural approaches to generate. (3) We can improve the capability of existing\nneural approaches to generate large-MESIA comments by reducing the proportion\nof small-MESIA comments in the training set. (4) The retrained model can\ngenerate large-MESIA comments that convey essential meaningful supplementary\ninformation for methods in the small-MESIA test set, but will get a lower BLEU\nscore in evaluation. These findings indicate that with good training data,\nauto-generated comments can sometimes even surpass human-written reference\ncomments, and having no appropriate ground truth for evaluation is an issue\nthat needs to be addressed by future work on automatic comment generation.",
      "tldr_zh": "该论文关注方法级代码注释的补充性质，提出 MESIA（Mean Supplementary Information Amount）指标来量化注释提供的信息量，以提升自动评论生成。研究通过实验分析一个流行数据集，发现小 MESIA 评论占约 20% 且多为 WHAT 类别，而大 MESIA 评论难以由现有神经方法生成。作者证明，通过减少训练集中小 MESIA 评论的比例，可以改善模型生成更具意义的大 MESIA 评论，尽管 BLEU 分数降低，并强调未来需解决评价基准的缺失问题。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "In 32nd IEEE/ACM International Conference on Program Comprehension\n  (ICPC'24)",
      "pdf_url": "http://arxiv.org/pdf/2403.17357v1",
      "published_date": "2024-03-26 03:44:51 UTC",
      "updated_date": "2024-03-26 03:44:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:16:09.504455"
    },
    {
      "arxiv_id": "2403.17350v1",
      "title": "The Solution of the Zodiac Killer's 340-Character Cipher",
      "title_zh": "翻译失败",
      "authors": [
        "David Oranchak",
        "Sam Blake",
        "Jarl Van Eycke"
      ],
      "abstract": "The case of the Zodiac Killer is one of the most widely known unsolved serial\nkiller cases in history. The unidentified killer murdered five known victims\nand terrorized the state of California. He also communicated extensively with\nthe press and law enforcement. Besides his murders, Zodiac was known for his\nuse of ciphers. The first Zodiac cipher was solved within a week of its\npublication, while the second cipher was solved by the authors after 51 years,\nwhen it was discovered to be a transposition and homophonic substitution cipher\nwith unusual qualities. In this paper, we detail the historical significance of\nthis cipher and the numerous efforts which culminated in its solution.",
      "tldr_zh": "本论文介绍了Zodiac Killer的340-Character Cipher的破解过程，该密码是一种transposition and homophonic substitution cipher，在51年后由作者首次解决。Zodiac Killer是美国历史上著名的未解连环杀手案，他通过密码与媒体和执法部门沟通，该密码的破解揭示了其历史意义和背后的努力。研究详细阐述了破解的诸多尝试和成果，为密码学领域提供了宝贵案例。",
      "categories": [
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.17350v1",
      "published_date": "2024-03-26 03:28:02 UTC",
      "updated_date": "2024-03-26 03:28:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:16:20.943642"
    },
    {
      "arxiv_id": "2403.17342v1",
      "title": "The Solution for the ICCV 2023 1st Scientific Figure Captioning Challenge",
      "title_zh": "翻译失败",
      "authors": [
        "Dian Chao",
        "Xin Song",
        "Shupeng Zhong",
        "Boyuan Wang",
        "Xiangyu Wu",
        "Chen Zhu",
        "Yang Yang"
      ],
      "abstract": "In this paper, we propose a solution for improving the quality of captions\ngenerated for figures in papers. We adopt the approach of summarizing the\ntextual content in the paper to generate image captions. Throughout our study,\nwe encounter discrepancies in the OCR information provided in the official\ndataset. To rectify this, we employ the PaddleOCR toolkit to extract OCR\ninformation from all images. Moreover, we observe that certain textual content\nin the official paper pertains to images that are not relevant for captioning,\nthereby introducing noise during caption generation. To mitigate this issue, we\nleverage LLaMA to extract image-specific information by querying the textual\ncontent based on image mentions, effectively filtering out extraneous\ninformation. Additionally, we recognize a discrepancy between the primary use\nof maximum likelihood estimation during text generation and the evaluation\nmetrics such as ROUGE employed to assess the quality of generated captions. To\nbridge this gap, we integrate the BRIO model framework, enabling a more\ncoherent alignment between the generation and evaluation processes. Our\napproach ranked first in the final test with a score of 4.49.",
      "tldr_zh": "该论文提出了一种针对 ICCV 2023 第一届科学图表标题生成挑战赛的解决方案，通过总结论文文本内容来改进图像标题的质量。为解决官方数据集中的 OCR 信息不准确问题，研究团队使用 PaddleOCR 工具重新提取图像文本；同时，采用 LLaMA 模型基于图像提及查询文本内容，过滤无关噪声以减少干扰。此外，他们整合 BRIO 模型框架，以更好地桥接最大似然估计生成与 ROUGE 等评估指标，最终在挑战赛中排名第一，得分 4.49。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.17342v1",
      "published_date": "2024-03-26 03:03:50 UTC",
      "updated_date": "2024-03-26 03:03:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:16:33.070021"
    },
    {
      "arxiv_id": "2403.17338v3",
      "title": "Reinforcement Learning-based Receding Horizon Control using Adaptive Control Barrier Functions for Safety-Critical Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Ehsan Sabouni",
        "H. M. Sabbir Ahmad",
        "Vittorio Giammarino",
        "Christos G. Cassandras",
        "Ioannis Ch. Paschalidis",
        "Wenchao Li"
      ],
      "abstract": "Optimal control methods provide solutions to safety-critical problems but\neasily become intractable. Control Barrier Functions (CBFs) have emerged as a\npopular technique that facilitates their solution by provably guaranteeing\nsafety, through their forward invariance property, at the expense of some\nperformance loss. This approach involves defining a performance objective\nalongside CBF-based safety constraints that must always be enforced.\nUnfortunately, both performance and solution feasibility can be significantly\nimpacted by two key factors: (i) the selection of the cost function and\nassociated parameters, and (ii) the calibration of parameters within the\nCBF-based constraints, which capture the trade-off between performance and\nconservativeness. %as well as infeasibility. To address these challenges, we\npropose a Reinforcement Learning (RL)-based Receding Horizon Control (RHC)\napproach leveraging Model Predictive Control (MPC) with CBFs (MPC-CBF). In\nparticular, we parameterize our controller and use bilevel optimization, where\nRL is used to learn the optimal parameters while MPC computes the optimal\ncontrol input. We validate our method by applying it to the challenging\nautomated merging control problem for Connected and Automated Vehicles (CAVs)\nat conflicting roadways. Results demonstrate improved performance and a\nsignificant reduction in the number of infeasible cases compared to traditional\nheuristic approaches used for tuning CBF-based controllers, showcasing the\neffectiveness of the proposed method.",
      "tldr_zh": "本文提出了一种基于 Reinforcement Learning (RL) 的 Receding Horizon Control (RHC) 方法，利用 Adaptive Control Barrier Functions (CBFs) 来解决安全关键系统的控制问题，该方法通过双层优化学习最优参数，同时使用 Model Predictive Control (MPC) 计算最优控制输入，以缓解传统方法在性能和可行性方面的局限。相比传统启发式调优方式，该框架显著提高了系统性能，并减少了不可行案例的数量。实验在 Connected and Automated Vehicles (CAVs) 的自动合并控制场景中进行了验证，证明了其有效性。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.17338v3",
      "published_date": "2024-03-26 02:49:08 UTC",
      "updated_date": "2025-02-19 20:37:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:16:46.614066"
    },
    {
      "arxiv_id": "2403.17333v1",
      "title": "The Pursuit of Fairness in Artificial Intelligence Models: A Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Tahsin Alamgir Kheya",
        "Mohamed Reda Bouadjenek",
        "Sunil Aryal"
      ],
      "abstract": "Artificial Intelligence (AI) models are now being utilized in all facets of\nour lives such as healthcare, education and employment. Since they are used in\nnumerous sensitive environments and make decisions that can be life altering,\npotential biased outcomes are a pressing matter. Developers should ensure that\nsuch models don't manifest any unexpected discriminatory practices like\npartiality for certain genders, ethnicities or disabled people. With the\nubiquitous dissemination of AI systems, researchers and practitioners are\nbecoming more aware of unfair models and are bound to mitigate bias in them.\nSignificant research has been conducted in addressing such issues to ensure\nmodels don't intentionally or unintentionally perpetuate bias. This survey\noffers a synopsis of the different ways researchers have promoted fairness in\nAI systems. We explore the different definitions of fairness existing in the\ncurrent literature. We create a comprehensive taxonomy by categorizing\ndifferent types of bias and investigate cases of biased AI in different\napplication domains. A thorough study is conducted of the approaches and\ntechniques employed by researchers to mitigate bias in AI models. Moreover, we\nalso delve into the impact of biased models on user experience and the ethical\nconsiderations to contemplate when developing and deploying such models. We\nhope this survey helps researchers and practitioners understand the intricate\ndetails of fairness and bias in AI systems. By sharing this thorough survey, we\naim to promote additional discourse in the domain of equitable and responsible\nAI.",
      "tldr_zh": "这篇调查论文探讨了人工智能（AI）模型中公平性的追求，强调了偏见在医疗、教育和就业等敏感领域的潜在风险，如针对性别、种族或残疾群体的歧视。论文首先定义了现有文献中的各种fairness概念，并构建了一个全面的taxonomy来分类不同类型的bias，同时分析了AI在多个应用领域的偏见案例。作者总结了研究者采用的缓解bias的方法和技术，包括检测和修正策略，并讨论了偏见对用户体验的影响以及开发和部署AI模型时的道德考虑。该调查旨在促进对equitable and responsible AI的进一步讨论和实践。",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "37 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.17333v1",
      "published_date": "2024-03-26 02:33:36 UTC",
      "updated_date": "2024-03-26 02:33:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:16:58.149141"
    },
    {
      "arxiv_id": "2403.17329v2",
      "title": "Deep Support Vectors",
      "title_zh": "深度支持向量",
      "authors": [
        "Junhoo Lee",
        "Hyunho Lee",
        "Kyomin Hwang",
        "Nojun Kwak"
      ],
      "abstract": "Deep learning has achieved tremendous success. \\nj{However,} unlike SVMs,\nwhich provide direct decision criteria and can be trained with a small dataset,\nit still has significant weaknesses due to its requirement for massive datasets\nduring training and the black-box characteristics on decision criteria.\n\\nj{This paper addresses} these issues by identifying support vectors in deep\nlearning models. To this end, we propose the DeepKKT condition, an adaptation\nof the traditional Karush-Kuhn-Tucker (KKT) condition for deep learning models,\nand confirm that generated Deep Support Vectors (DSVs) using this condition\nexhibit properties similar to traditional support vectors. This allows us to\napply our method to few-shot dataset distillation problems and alleviate the\nblack-box characteristics of deep learning models. Additionally, we demonstrate\nthat the DeepKKT condition can transform conventional classification models\ninto generative models with high fidelity, particularly as latent\n\\jh{generative} models using class labels as latent variables. We validate the\neffectiveness of DSVs \\nj{using common datasets (ImageNet, CIFAR10 \\nj{and}\nCIFAR100) on the general architectures (ResNet and ConvNet)}, proving their\npractical applicability. (See Fig.~\\ref{fig:generated})",
      "tldr_zh": "该论文针对深度学习模型需要大量数据集训练且决策黑盒的问题，提出 DeepKKT 条件，这是一种对传统 Karush-Kuhn-Tucker (KKT) 条件的适应，用于识别深度学习中的 Deep Support Vectors (DSVs)。DSVs 展现出类似于传统支持向量的特性，从而应用于 few-shot dataset distillation 和缓解模型的黑盒特性，同时可以将常规分类模型转化为高保真生成模型，使用类标签作为潜在变量。实验在 ImageNet、CIFAR10 和 CIFAR100 等数据集以及 ResNet 和 ConvNet 架构上验证了 DSVs 的有效性，证明了其实际可行性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.17329v2",
      "published_date": "2024-03-26 02:24:32 UTC",
      "updated_date": "2024-06-27 06:19:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:17:12.542699"
    },
    {
      "arxiv_id": "2403.17328v2",
      "title": "Learning Traffic Signal Control via Genetic Programming",
      "title_zh": "翻译失败",
      "authors": [
        "Xiao-Cheng Liao",
        "Yi Mei",
        "Mengjie Zhang"
      ],
      "abstract": "The control of traffic signals is crucial for improving transportation\nefficiency. Recently, learning-based methods, especially Deep Reinforcement\nLearning (DRL), garnered substantial success in the quest for more efficient\ntraffic signal control strategies. However, the design of rewards in DRL highly\ndemands domain knowledge to converge to an effective policy, and the final\npolicy also presents difficulties in terms of explainability. In this work, a\nnew learning-based method for signal control in complex intersections is\nproposed. In our approach, we design a concept of phase urgency for each signal\nphase. During signal transitions, the traffic light control strategy selects\nthe next phase to be activated based on the phase urgency. We then proposed to\nrepresent the urgency function as an explainable tree structure. The urgency\nfunction can calculate the phase urgency for a specific phase based on the\ncurrent road conditions. Genetic programming is adopted to perform\ngradient-free optimization of the urgency function. We test our algorithm on\nmultiple public traffic signal control datasets. The experimental results\nindicate that the tree-shaped urgency function evolved by genetic programming\noutperforms the baselines, including a state-of-the-art method in the\ntransportation field and a well-known DRL-based method.",
      "tldr_zh": "这篇论文提出了一种基于 Genetic Programming 的交通信号控制方法，以解决 Deep Reinforcement Learning (DRL) 在奖励函数设计和策略解释性方面的局限性。该方法引入了 phase urgency 概念，通过树结构表示紧急度函数，并根据当前路况计算相位优先级，使用 Genetic Programming 进行无梯度优化。实验结果显示，该方法在多个公共交通信号控制数据集上优于基线模型，包括最先进的交通领域方法和著名的 DRL 方法。",
      "categories": [
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.17328v2",
      "published_date": "2024-03-26 02:22:08 UTC",
      "updated_date": "2025-01-05 05:19:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:17:23.602273"
    },
    {
      "arxiv_id": "2405.12985v1",
      "title": "Sketch2Prototype: Rapid Conceptual Design Exploration and Prototyping with Generative AI",
      "title_zh": "翻译失败",
      "authors": [
        "Kristen M. Edwards",
        "Brandon Man",
        "Faez Ahmed"
      ],
      "abstract": "Sketch2Prototype is an AI-based framework that transforms a hand-drawn sketch\ninto a diverse set of 2D images and 3D prototypes through sketch-to-text,\ntext-to-image, and image-to-3D stages. This framework, shown across various\nsketches, rapidly generates text, image, and 3D modalities for enhanced\nearly-stage design exploration. We show that using text as an intermediate\nmodality outperforms direct sketch-to-3D baselines for generating diverse and\nmanufacturable 3D models. We find limitations in current image-to-3D\ntechniques, while noting the value of the text modality for user-feedback and\niterative design augmentation.",
      "tldr_zh": "论文介绍了 Sketch2Prototype，一个基于 Generative AI 的框架，能够将手绘草图快速转化为多样化的 2D 图像和 3D 原型，通过 sketch-to-text、text-to-image 和 image-to-3D 阶段进行多模态生成。  \n该框架显著提升了早期设计探索的效率，研究发现，使用文本作为中间模态比直接 sketch-to-3D 基线更能生成多样化且可制造的 3D 模型。  \n然而，当前 image-to-3D 技术存在局限性，而文本模态为用户反馈和迭代设计提供了重要价值。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.HC",
      "comment": "10 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.12985v1",
      "published_date": "2024-03-26 02:12:17 UTC",
      "updated_date": "2024-03-26 02:12:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:17:35.471999"
    },
    {
      "arxiv_id": "2403.17319v1",
      "title": "JMultiWOZ: A Large-Scale Japanese Multi-Domain Task-Oriented Dialogue Dataset",
      "title_zh": "JMultiWOZ：大规模日语多领域任务导向对话数据集",
      "authors": [
        "Atsumoto Ohashi",
        "Ryu Hirai",
        "Shinya Iizuka",
        "Ryuichiro Higashinaka"
      ],
      "abstract": "Dialogue datasets are crucial for deep learning-based task-oriented dialogue\nsystem research. While numerous English language multi-domain task-oriented\ndialogue datasets have been developed and contributed to significant\nadvancements in task-oriented dialogue systems, such a dataset does not exist\nin Japanese, and research in this area is limited compared to that in English.\nIn this study, towards the advancement of research and development of\ntask-oriented dialogue systems in Japanese, we constructed JMultiWOZ, the first\nJapanese language large-scale multi-domain task-oriented dialogue dataset.\nUsing JMultiWOZ, we evaluated the dialogue state tracking and response\ngeneration capabilities of the state-of-the-art methods on the existing major\nEnglish benchmark dataset MultiWOZ2.2 and the latest large language model\n(LLM)-based methods. Our evaluation results demonstrated that JMultiWOZ\nprovides a benchmark that is on par with MultiWOZ2.2. In addition, through\nevaluation experiments of interactive dialogues with the models and human\nparticipants, we identified limitations in the task completion capabilities of\nLLMs in Japanese.",
      "tldr_zh": "本研究构建了JMultiWOZ，这是第一个大规模日语多域任务导向对话数据集，旨在填补日语领域在任务导向对话系统研究中的空白。研究者使用JMultiWOZ评估了最先进方法的对话状态跟踪和响应生成性能，并与MultiWOZ2.2基准以及LLM-based方法进行了比较。结果表明，JMultiWOZ提供了一个与MultiWOZ2.2相当的评估标准，同时暴露了LLM在日语任务完成能力上的局限性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by LREC-COLING 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.17319v1",
      "published_date": "2024-03-26 02:01:18 UTC",
      "updated_date": "2024-03-26 02:01:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:17:46.769119"
    },
    {
      "arxiv_id": "2403.17312v1",
      "title": "ALISA: Accelerating Large Language Model Inference via Sparsity-Aware KV Caching",
      "title_zh": "翻译失败",
      "authors": [
        "Youpeng Zhao",
        "Di Wu",
        "Jun Wang"
      ],
      "abstract": "The Transformer architecture has significantly advanced natural language\nprocessing (NLP) and has been foundational in developing large language models\n(LLMs) such as LLaMA and OPT, which have come to dominate a broad range of NLP\ntasks. Despite their superior accuracy, LLMs present unique challenges in\npractical inference, concerning the compute and memory-intensive nature. Thanks\nto the autoregressive characteristic of LLM inference, KV caching for the\nattention layers in Transformers can effectively accelerate LLM inference by\nsubstituting quadratic-complexity computation with linear-complexity memory\naccesses. Yet, this approach requires increasing memory as demand grows for\nprocessing longer sequences. The overhead leads to reduced throughput due to\nI/O bottlenecks and even out-of-memory errors, particularly on\nresource-constrained systems like a single commodity GPU. In this paper, we\npropose ALISA, a novel algorithm-system co-design solution to address the\nchallenges imposed by KV caching. On the algorithm level, ALISA prioritizes\ntokens that are most important in generating a new token via a Sparse Window\nAttention (SWA) algorithm. SWA introduces high sparsity in attention layers and\nreduces the memory footprint of KV caching at negligible accuracy loss. On the\nsystem level, ALISA employs three-phase token-level dynamical scheduling and\noptimizes the trade-off between caching and recomputation, thus maximizing the\noverall performance in resource-constrained systems. In a single GPU-CPU\nsystem, we demonstrate that under varying workloads, ALISA improves the\nthroughput of baseline systems such as FlexGen and vLLM by up to 3X and 1.9X,\nrespectively.",
      "tldr_zh": "本研究提出 ALISA，一种算法-系统联合设计框架，旨在通过稀疏感知 KV caching 加速大型语言模型 (LLMs) 的推理过程，解决传统方法在长序列处理中面临的内存开销和 I/O 瓶颈问题。在算法层面，ALISA 采用 Sparse Window Attention (SWA) 算法来优先处理关键 tokens，引入高稀疏性从而减少 KV caching 的内存占用，同时保持 negligible 的准确性损失；在系统层面，通过三阶段 token-level 动态调度优化 caching 与 recomputation 的权衡。实验结果显示，在单 GPU-CPU 系统下，ALISA 相较于 FlexGen 和 vLLM 基线系统，吞吐量分别提高了最高 3X 和 1.9X。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.PF"
      ],
      "primary_category": "cs.AI",
      "comment": "ISCA 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.17312v1",
      "published_date": "2024-03-26 01:46:34 UTC",
      "updated_date": "2024-03-26 01:46:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:18:00.098919"
    },
    {
      "arxiv_id": "2403.17308v1",
      "title": "Neural Multimodal Topic Modeling: A Comprehensive Evaluation",
      "title_zh": "神经多模态主题建模：全面评估",
      "authors": [
        "Felipe González-Pizarro",
        "Giuseppe Carenini"
      ],
      "abstract": "Neural topic models can successfully find coherent and diverse topics in\ntextual data. However, they are limited in dealing with multimodal datasets\n(e.g., images and text). This paper presents the first systematic and\ncomprehensive evaluation of multimodal topic modeling of documents containing\nboth text and images. In the process, we propose two novel topic modeling\nsolutions and two novel evaluation metrics. Overall, our evaluation on an\nunprecedented rich and diverse collection of datasets indicates that both of\nour models generate coherent and diverse topics. Nevertheless, the extent to\nwhich one method outperforms the other depends on the metrics and dataset\ncombinations, which suggests further exploration of hybrid solutions in the\nfuture. Notably, our succinct human evaluation aligns with the outcomes\ndetermined by our proposed metrics. This alignment not only reinforces the\ncredibility of our metrics but also highlights the potential for their\napplication in guiding future multimodal topic modeling endeavors.",
      "tldr_zh": "这篇论文对神经主题模型（Neural topic models）在处理多模态数据集（如文本和图像）时的局限性进行了首个系统全面评估。研究者提出了两个新颖的主题建模解决方案和两个评估指标，通过在多样数据集上的实验，证明这些模型能生成连贯且多样的主题，但表现依赖于具体指标和数据集组合。结果显示，人类评估与提出的指标结果一致，这不仅验证了指标的可靠性，还为未来探索混合解决方案提供了指导。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "Camera-Ready for LREC-COLING 2024 (Long Paper)",
      "pdf_url": "http://arxiv.org/pdf/2403.17308v1",
      "published_date": "2024-03-26 01:29:46 UTC",
      "updated_date": "2024-03-26 01:29:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:18:10.810863"
    },
    {
      "arxiv_id": "2403.17306v2",
      "title": "Visual Hallucination: Definition, Quantification, and Prescriptive Remediations",
      "title_zh": "翻译失败",
      "authors": [
        "Anku Rani",
        "Vipula Rawte",
        "Harshad Sharma",
        "Neeraj Anand",
        "Krishnav Rajbangshi",
        "Amit Sheth",
        "Amitava Das"
      ],
      "abstract": "The troubling rise of hallucination presents perhaps the most significant\nimpediment to the advancement of responsible AI. In recent times, considerable\nresearch has focused on detecting and mitigating hallucination in Large\nLanguage Models (LLMs). However, it's worth noting that hallucination is also\nquite prevalent in Vision-Language models (VLMs). In this paper, we offer a\nfine-grained discourse on profiling VLM hallucination based on two tasks: i)\nimage captioning, and ii) Visual Question Answering (VQA). We delineate eight\nfine-grained orientations of visual hallucination: i) Contextual Guessing, ii)\nIdentity Incongruity, iii) Geographical Erratum, iv) Visual Illusion, v) Gender\nAnomaly, vi) VLM as Classifier, vii) Wrong Reading, and viii) Numeric\nDiscrepancy. We curate Visual HallucInation eLiciTation (VHILT), a publicly\navailable dataset comprising 2,000 samples generated using eight VLMs across\ntwo tasks of captioning and VQA along with human annotations for the categories\nas mentioned earlier.",
      "tldr_zh": "该论文探讨了视觉语言模型（VLMs）中的视觉幻觉（Visual Hallucination）问题，定义了其概念并提出量化方法，以应对其对负责任 AI 发展的阻碍。作者识别了八种细粒度的幻觉类型，包括 Contextual Guessing、Identity Incongruity 和 Geographic Erratum 等，并基于图像描述和 Visual Question Answering (VQA) 任务进行分析。论文构建了公开数据集 Visual HallucInation eLiciTation (VHILT)，包含 2,000 个样本及人类标注，并提供了处方性缓解策略，以帮助减少 VLMs 中的幻觉现象。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.17306v2",
      "published_date": "2024-03-26 01:28:42 UTC",
      "updated_date": "2024-03-31 03:52:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:18:23.675583"
    },
    {
      "arxiv_id": "2403.17297v1",
      "title": "InternLM2 Technical Report",
      "title_zh": "InternLM2 技术报告",
      "authors": [
        "Zheng Cai",
        "Maosong Cao",
        "Haojiong Chen",
        "Kai Chen",
        "Keyu Chen",
        "Xin Chen",
        "Xun Chen",
        "Zehui Chen",
        "Zhi Chen",
        "Pei Chu",
        "Xiaoyi Dong",
        "Haodong Duan",
        "Qi Fan",
        "Zhaoye Fei",
        "Yang Gao",
        "Jiaye Ge",
        "Chenya Gu",
        "Yuzhe Gu",
        "Tao Gui",
        "Aijia Guo",
        "Qipeng Guo",
        "Conghui He",
        "Yingfan Hu",
        "Ting Huang",
        "Tao Jiang",
        "Penglong Jiao",
        "Zhenjiang Jin",
        "Zhikai Lei",
        "Jiaxing Li",
        "Jingwen Li",
        "Linyang Li",
        "Shuaibin Li",
        "Wei Li",
        "Yining Li",
        "Hongwei Liu",
        "Jiangning Liu",
        "Jiawei Hong",
        "Kaiwen Liu",
        "Kuikun Liu",
        "Xiaoran Liu",
        "Chengqi Lv",
        "Haijun Lv",
        "Kai Lv",
        "Li Ma",
        "Runyuan Ma",
        "Zerun Ma",
        "Wenchang Ning",
        "Linke Ouyang",
        "Jiantao Qiu",
        "Yuan Qu",
        "Fukai Shang",
        "Yunfan Shao",
        "Demin Song",
        "Zifan Song",
        "Zhihao Sui",
        "Peng Sun",
        "Yu Sun",
        "Huanze Tang",
        "Bin Wang",
        "Guoteng Wang",
        "Jiaqi Wang",
        "Jiayu Wang",
        "Rui Wang",
        "Yudong Wang",
        "Ziyi Wang",
        "Xingjian Wei",
        "Qizhen Weng",
        "Fan Wu",
        "Yingtong Xiong",
        "Chao Xu",
        "Ruiliang Xu",
        "Hang Yan",
        "Yirong Yan",
        "Xiaogui Yang",
        "Haochen Ye",
        "Huaiyuan Ying",
        "Jia Yu",
        "Jing Yu",
        "Yuhang Zang",
        "Chuyu Zhang",
        "Li Zhang",
        "Pan Zhang",
        "Peng Zhang",
        "Ruijie Zhang",
        "Shuo Zhang",
        "Songyang Zhang",
        "Wenjian Zhang",
        "Wenwei Zhang",
        "Xingcheng Zhang",
        "Xinyue Zhang",
        "Hui Zhao",
        "Qian Zhao",
        "Xiaomeng Zhao",
        "Fengzhe Zhou",
        "Zaida Zhou",
        "Jingming Zhuo",
        "Yicheng Zou",
        "Xipeng Qiu",
        "Yu Qiao",
        "Dahua Lin"
      ],
      "abstract": "The evolution of Large Language Models (LLMs) like ChatGPT and GPT-4 has\nsparked discussions on the advent of Artificial General Intelligence (AGI).\nHowever, replicating such advancements in open-source models has been\nchallenging. This paper introduces InternLM2, an open-source LLM that\noutperforms its predecessors in comprehensive evaluations across 6 dimensions\nand 30 benchmarks, long-context modeling, and open-ended subjective evaluations\nthrough innovative pre-training and optimization techniques. The pre-training\nprocess of InternLM2 is meticulously detailed, highlighting the preparation of\ndiverse data types including text, code, and long-context data. InternLM2\nefficiently captures long-term dependencies, initially trained on 4k tokens\nbefore advancing to 32k tokens in pre-training and fine-tuning stages,\nexhibiting remarkable performance on the 200k ``Needle-in-a-Haystack\" test.\nInternLM2 is further aligned using Supervised Fine-Tuning (SFT) and a novel\nConditional Online Reinforcement Learning from Human Feedback (COOL RLHF)\nstrategy that addresses conflicting human preferences and reward hacking. By\nreleasing InternLM2 models in different training stages and model sizes, we\nprovide the community with insights into the model's evolution.",
      "tldr_zh": "本论文介绍了 InternLM2，一个开源的大型语言模型 (LLM)，它通过创新的预训练和优化技术，在6个维度、30个基准测试以及长上下文建模中超越了其前身。InternLM2 的预训练过程利用多样数据类型（如文本、代码和长上下文数据），从4k tokens逐步扩展到32k tokens，并在“Needle-in-a-Haystack”测试中表现出色。模型通过 Supervised Fine-Tuning (SFT) 和新型 Conditional Online Reinforcement Learning from Human Feedback (COOL RLHF) 策略进行对齐，解决了人类偏好冲突和奖励黑客问题；最终，通过发布不同训练阶段和模型大小的版本，为社区提供了模型演化的宝贵洞见。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.17297v1",
      "published_date": "2024-03-26 00:53:24 UTC",
      "updated_date": "2024-03-26 00:53:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T19:18:34.747968"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 118,
  "processed_papers_count": 118,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-17T19:18:54.842649"
}