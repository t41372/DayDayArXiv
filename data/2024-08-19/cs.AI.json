{
  "date": "2024-08-19",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-08-19 的 arXiv 中文 TLDR 快报！今天 arXiv 的论文主要聚焦于 AI 模型的优化与应用，尤其是大语言模型 (LLM) 在规则学习、推荐系统和医学诊断中的创新，同时涉及强化学习、图像生成和高效计算方法；重点包括 LLM 的自提升和高效框架设计，令人印象深刻的文章有 KAN 2.0（作者包括 Max Tegmark）和多模态 LLM 在复杂任务中的应用，而知名学者的参与（如 Tegmark）进一步提升了这些研究的学术影响力。\n\n下面，我将挑选并讨论今天更重要的论文，先从高影响力或创新性强的入手，并将相关主题归类讨论。其他较常规或应用性不强的论文（如某些小规模数据集构建或特定领域优化），将快速掠过，只简要提及其核心点，以控制篇幅。\n\n### LLM 与规则学习\n- **IDEA: Enhancing the Rule Learning Ability of Large Language Model Agent through Induction, Deduction, and Abduction（中文：通过归纳、演绎和溯因增强大语言模型代理的规则学习能力）**  \n  这篇论文提出 IDEA 框架，用于提升 LLM 在交互环境中学习规则的能力。主要贡献是通过整合归纳、演绎和溯因，LLM 代理能从有限观察中生成假设、验证计划并优化规则，实验显示显著改善规则学习性能，并与人类行为比较。该研究对 LLM 在真实场景中的应用（如机器人决策）有重要启示。\n\n- **Boolean Matrix Logic Programming（中文：布尔矩阵逻辑编程）**  \n  作者探索了布尔矩阵在数据逻辑程序评估中的应用，贡献包括高效模块设计，能加速线性递归数据逻辑程序的推理。相比基线，性能提升 30 倍以上，对逻辑编程和 AI 优化有实际价值。\n\n相关论文如第 14 篇（Boolean Matrix Logic Programming）和第 19 篇（Active learning of digenic functions with boolean matrix logic programming）则快速掠过：它们扩展了布尔矩阵在逻辑学习中的应用，但细节较技术化，贡献主要在效率提升。\n\n### AI 在推荐系统和预测中的创新\n- **TeamLoRA: Boosting Low-Rank Adaptation with Expert Collaboration and Competition（中文：通过专家协作与竞争提升低秩适配）**  \n  这篇论文提出 TeamLoRA 方法，创新地将专家协作（知识共享）和竞争（游戏理论机制）融入低秩适配 (LoRA)，显著提升多任务学习的准确性和效率。实验显示，在多任务基准上比传统 LoRA 提升 11.4%，并保持参数高效，对 LLM 微调有实际指导意义。\n\n- **Joint Modeling of Search and Recommendations Via an Unified Contextual Recommender (UniCoRn)（中文：通过统一上下文推荐器联合建模搜索和推荐）**  \n  作者设计 UniCoRn 框架，统一搜索和推荐任务，减少维护复杂性。主要发现是通过深度学习整合上下文，提升推荐准确性。该方法对实际推荐系统（如电商）有直接应用价值。\n\n其他推荐相关论文（如第 33 篇 Efficient Reinforcement Learning in Probabilistic Reward Machines）快速提及：它优化了强化学习在马尔可夫决策中的遗憾边界，但核心在于理论提升，不如上述两篇实用。\n\n### 图像生成和高效模型设计\n- **KAN 2.0: Kolmogorov-Arnold Networks Meet Science（中文：Kolmogorov-Arnold 网络与科学的结合）**  \n  作者（包括知名学者 Max Tegmark）扩展 KAN 框架，创新地将它应用于科学发现，如识别特征、模块结构和符号公式。主要贡献是新工具如 MultKAN 和 kanpiler，能高效发现物理定律。该论文在 AI + 科学交叉领域有突破性影响，值得关注。\n\n- **BrewCLIP: A Bifurcated Representation Learning Framework for Audio-Visual Retrieval（中文：双分支表示学习框架用于音视频检索）**  \n  这篇提出双分支模型，结合文本和非文本信息提升音视频匹配。主要发现是通过预训练模型和提示机制，显著提高检索性能。该研究对多模态 AI 应用（如媒体检索）有启发。\n\n图像处理论文如第 26 篇（Are LLMs Any Good for High-Level Synthesis?）快速掠过：它评估 LLM 在硬件设计中的潜力，但实验局限于特定领域，影响力有限。\n\n### 强化学习和医学应用\n- **Efficient Reinforcement Learning in Probabilistic Reward Machines（中文：在概率奖励机中高效强化学习）**  \n  作者设计算法，优化马尔可夫决策过程的遗憾边界，达到 O(√HOAT)。主要贡献是首次高效处理非马尔可夫奖励，提供理论下界匹配。该方法对机器人和决策系统有实际价值。\n\n- **Towards Automation of Human Stage of Decay Identification: An Artificial Intelligence Approach（中文：通过人工智能自动化人类腐烂阶段识别）**  \n  这篇使用深度学习模型（如 Xception）自动化腐烂阶段分类，准确率达 87.8%，并与人类专家比较。主要发现是 AI 可媲美专家水平，对法医学有应用潜力。\n\n医学相关论文如第 4 篇（Feasibility of assessing cognitive impairment via distributed camera network）快速提及：它使用隐私保护相机网络检测认知障碍，准确率 71%，但更侧重初步探索。\n\n### 其他亮点和快速掠过\n今天还有一些跨领域论文，如第 101 篇（BatGPT-Chem: A Foundation Large Model For Retrosynthesis Prediction），它构建 150 亿参数 LLM 用于化学合成预测，零-shot 能力强，对药物发现有启发；以及第 78 篇（Demystifying Reinforcement Learning in Production Scheduling），它用可解释 AI 分析强化学习在生产调度中的决策，提升了实际应用透明度。\n\n剩余论文（如数据集构建或小规模优化，如第 17、35、49 篇）则因主题较常规或影响力有限而快速掠过：它们主要贡献在于新数据集或细微改进，对特定领域有参考价值，但整体不如上述论文突出。\n\n总之，今天的 arXiv 强调 AI 效率和实际应用，LLM 和强化学习领域尤为活跃。如果你对 LLM 自提升或科学模型设计感兴趣，建议优先查看 KAN 2.0 和 TeamLoRA。明天的快报见！",
  "papers": [
    {
      "arxiv_id": "2408.10455v5",
      "title": "IDEA: Enhancing the Rule Learning Ability of Large Language Model Agent through Induction, Deduction, and Abduction",
      "title_zh": "翻译失败",
      "authors": [
        "Kaiyu He",
        "Mian Zhang",
        "Shuo Yan",
        "Peilin Wu",
        "Zhiyu Zoey Chen"
      ],
      "abstract": "While large language models (LLMs) have been thoroughly evaluated for\ndeductive and inductive reasoning, their proficiency in holistic rule learning\nin interactive environments remains less explored. We introduce RULEARN, a\nnovel benchmark to assess the rule-learning abilities of LLM agents in\ninteractive settings. In RULEARN, agents strategically interact with simulated\nenvironments to gather observations, discern patterns, and solve complex\nproblems. To enhance the rule-learning capabilities for LLM agents, we propose\nIDEA, a novel reasoning framework that integrates the process of Induction,\nDeduction, and Abduction. The IDEA agent generates initial hypotheses from\nlimited observations through abduction, devises plans to validate these\nhypotheses or leverages them to solve problems via deduction, and refines\nprevious hypotheses through induction, dynamically establishing and applying\nrules that mimic human rule-learning behaviors. Our evaluation of the IDEA\nframework, which involves five representative LLMs, demonstrates significant\nimprovements over the baseline. Furthermore, our study with human participants\nreveals notable discrepancies in rule-learning behaviors between humans and\nLLMs. We believe our benchmark will serve as a valuable and challenging\nresource, and IDEA will provide crucial insights for the development of LLM\nagents capable of human-like rule learning in real-world scenarios. Our code\nand data is publicly available.",
      "tldr_zh": "本研究引入了RULEARN基准，用于评估大型语言模型(LLMs)代理在交互环境中学习规则的能力，填补了LLMs在演绎和归纳推理之外的整体规则学习空白。作者提出IDEA框架，该框架整合了Induction（归纳）、Deduction（演绎）和Abduction（溯因）推理过程：代理通过Abduction从有限观察生成初始假设，利用Deduction制定计划验证或解决问题，并通过Induction完善假设，从而模仿人类动态建立和应用规则。在评估中，IDEA框架在使用五种代表性LLMs时，比基线方法显著提升了性能；此外，与人类参与者的比较揭示了LLMs在规则学习行为上的差异，为开发更具人类-like规则学习能力的LLMs代理提供了关键见解。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.10455v5",
      "published_date": "2024-08-19 23:37:07 UTC",
      "updated_date": "2024-12-19 05:45:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:26:47.072508"
    },
    {
      "arxiv_id": "2408.10450v1",
      "title": "RUMI: Rummaging Using Mutual Information",
      "title_zh": "翻译失败",
      "authors": [
        "Sheng Zhong",
        "Nima Fazeli",
        "Dmitry Berenson"
      ],
      "abstract": "This paper presents Rummaging Using Mutual Information (RUMI), a method for\nonline generation of robot action sequences to gather information about the\npose of a known movable object in visually-occluded environments. Focusing on\ncontact-rich rummaging, our approach leverages mutual information between the\nobject pose distribution and robot trajectory for action planning. From an\nobserved partial point cloud, RUMI deduces the compatible object pose\ndistribution and approximates the mutual information of it with workspace\noccupancy in real time. Based on this, we develop an information gain cost\nfunction and a reachability cost function to keep the object within the robot's\nreach. These are integrated into a model predictive control (MPC) framework\nwith a stochastic dynamics model, updating the pose distribution in a closed\nloop. Key contributions include a new belief framework for object pose\nestimation, an efficient information gain computation strategy, and a robust\nMPC-based control scheme. RUMI demonstrates superior performance in both\nsimulated and real tasks compared to baseline methods.",
      "tldr_zh": "本文提出 RUMI 方法，利用 Mutual Information 来在线生成机器人动作序列，从而在视觉遮挡环境中收集已知可移动物体的姿势信息，焦点在于接触丰富的 rummaging 任务。RUMI 从 observed partial point cloud 推断物体姿势分布，并通过 Information Gain Cost Function 和 Reachability Cost Function 集成到 Model Predictive Control (MPC) 框架中，实现实时互信息近似和闭环更新。关键贡献包括一个新的 belief framework for object pose estimation、一个高效的 information gain computation strategy 和一个 robust MPC-based control scheme；实验结果显示 RUMI 在模拟和真实任务中比基线方法表现出色。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "I.2.9"
      ],
      "primary_category": "cs.RO",
      "comment": "19 pages, 17 figures, submitted to IEEE Transactions on Robotics\n  (T-RO)",
      "pdf_url": "http://arxiv.org/pdf/2408.10450v1",
      "published_date": "2024-08-19 23:16:18 UTC",
      "updated_date": "2024-08-19 23:16:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:26:50.463390"
    },
    {
      "arxiv_id": "2408.10446v1",
      "title": "The Brittleness of AI-Generated Image Watermarking Techniques: Examining Their Robustness Against Visual Paraphrasing Attacks",
      "title_zh": "AI 生成图像水印技术的脆弱性：检验其对抗视觉改述攻击的鲁棒性",
      "authors": [
        "Niyar R Barman",
        "Krish Sharma",
        "Ashhar Aziz",
        "Shashwat Bajpai",
        "Shwetangshu Biswas",
        "Vasu Sharma",
        "Vinija Jain",
        "Aman Chadha",
        "Amit Sheth",
        "Amitava Das"
      ],
      "abstract": "The rapid advancement of text-to-image generation systems, exemplified by\nmodels like Stable Diffusion, Midjourney, Imagen, and DALL-E, has heightened\nconcerns about their potential misuse. In response, companies like Meta and\nGoogle have intensified their efforts to implement watermarking techniques on\nAI-generated images to curb the circulation of potentially misleading visuals.\nHowever, in this paper, we argue that current image watermarking methods are\nfragile and susceptible to being circumvented through visual paraphrase\nattacks. The proposed visual paraphraser operates in two steps. First, it\ngenerates a caption for the given image using KOSMOS-2, one of the latest\nstate-of-the-art image captioning systems. Second, it passes both the original\nimage and the generated caption to an image-to-image diffusion system. During\nthe denoising step of the diffusion pipeline, the system generates a visually\nsimilar image that is guided by the text caption. The resulting image is a\nvisual paraphrase and is free of any watermarks. Our empirical findings\ndemonstrate that visual paraphrase attacks can effectively remove watermarks\nfrom images. This paper provides a critical assessment, empirically revealing\nthe vulnerability of existing watermarking techniques to visual paraphrase\nattacks. While we do not propose solutions to this issue, this paper serves as\na call to action for the scientific community to prioritize the development of\nmore robust watermarking techniques. Our first-of-its-kind visual paraphrase\ndataset and accompanying code are publicly available.",
      "tldr_zh": "本研究探讨了AI生成图像水印技术的脆弱性，特别是对visual paraphrasing attacks的抵抗力，揭示了现有方法（如Meta和Google采用的）容易被绕过的问题。作者提出了一种两步攻击框架：首先使用KOSMOS-2生成图像标题，其次将原图像和标题输入图像到图像扩散系统，生成视觉相似的无水印图像。实验结果显示，这种攻击能有效移除水印，强调了watermarking techniques的潜在缺陷，并呼吁科学界开发更robust的解决方案；同时，论文公开了首个visual paraphrase数据集和代码以促进进一步研究。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "23 pages and 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.10446v1",
      "published_date": "2024-08-19 22:58:30 UTC",
      "updated_date": "2024-08-19 22:58:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:27:01.012315"
    },
    {
      "arxiv_id": "2408.10442v1",
      "title": "Feasibility of assessing cognitive impairment via distributed camera network and privacy-preserving edge computing",
      "title_zh": "通过分布式相机网络和保护隐私的边缘计算评估认知障碍的可行性",
      "authors": [
        "Chaitra Hegde",
        "Yashar Kiarashi",
        "Allan I Levey",
        "Amy D Rodriguez",
        "Hyeokhyen Kwon",
        "Gari D Clifford"
      ],
      "abstract": "INTRODUCTION: Mild cognitive impairment (MCI) is characterized by a decline\nin cognitive functions beyond typical age and education-related expectations.\nSince, MCI has been linked to reduced social interactions and increased aimless\nmovements, we aimed to automate the capture of these behaviors to enhance\nlongitudinal monitoring.\n  METHODS: Using a privacy-preserving distributed camera network, we collected\nmovement and social interaction data from groups of individuals with MCI\nundergoing therapy within a 1700$m^2$ space. We developed movement and social\ninteraction features, which were then used to train a series of machine\nlearning algorithms to distinguish between higher and lower cognitive\nfunctioning MCI groups.\n  RESULTS: A Wilcoxon rank-sum test revealed statistically significant\ndifferences between high and low-functioning cohorts in features such as linear\npath length, walking speed, change in direction while walking, entropy of\nvelocity and direction change, and number of group formations in the indoor\nspace. Despite lacking individual identifiers to associate with specific levels\nof MCI, a machine learning approach using the most significant features\nprovided a 71% accuracy.\n  DISCUSSION: We provide evidence to show that a privacy-preserving low-cost\ncamera network using edge computing framework has the potential to distinguish\nbetween different levels of cognitive impairment from the movements and social\ninteractions captured during group activities.",
      "tldr_zh": "本研究探讨了通过分布式摄像头网络和隐私保护边缘计算评估轻度认知障碍(MCI)的可行性，旨在自动化捕获患者减少的社会互动和增加的无目的运动，以增强纵向监测。方法涉及在1700平方米空间中收集MCI患者运动和社会互动数据，开发相关特征，并使用机器学习算法训练区分高功能和低功能群体。结果显示，Wilcoxon rank-sum test检测到显著差异，包括线性路径长度、步行速度、方向变化的熵以及群组形成数量，机器学习模型基于这些特征实现了71%的准确率。该框架证明了隐私保护、低成本的边缘计算系统在区分不同认知障碍水平方面的潜力，为自主监测提供新途径。",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.10442v1",
      "published_date": "2024-08-19 22:34:43 UTC",
      "updated_date": "2024-08-19 22:34:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:27:14.023417"
    },
    {
      "arxiv_id": "2408.10437v3",
      "title": "Understanding Generative AI Content with Embedding Models",
      "title_zh": "翻译失败",
      "authors": [
        "Max Vargas",
        "Reilly Cannon",
        "Andrew Engel",
        "Anand D. Sarwate",
        "Tony Chiang"
      ],
      "abstract": "Constructing high-quality features is critical to any quantitative data\nanalysis. While feature engineering was historically addressed by carefully\nhand-crafting data representations based on domain expertise, deep neural\nnetworks (DNNs) now offer a radically different approach. DNNs implicitly\nengineer features by transforming their input data into hidden feature vectors\ncalled embeddings. For embedding vectors produced by foundation models -- which\nare trained to be useful across many contexts -- we demonstrate that simple and\nwell-studied dimensionality-reduction techniques such as Principal Component\nAnalysis uncover inherent heterogeneity in input data concordant with\nhuman-understandable explanations. Of the many applications for this framework,\nwe find empirical evidence that there is intrinsic separability between real\nsamples and those generated by artificial intelligence (AI).",
      "tldr_zh": "该论文探讨了使用嵌入模型（embedding models）来理解生成式AI内容的重要性，强调深度神经网络（DNNs）通过隐式生成嵌入向量（embeddings）来实现特征工程，而非依赖手工设计。\n研究发现，对于基础模型（foundation models）产生的嵌入向量，应用主成分分析（Principal Component Analysis, PCA）等降维技术，能揭示输入数据的内在异质性，并与人类可理解的解释相符。\n关键发现是，实验证据显示真实样本和AI生成样本在嵌入空间中具有内在可分离性，这为定量分析AI内容提供了新框架。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.10437v3",
      "published_date": "2024-08-19 22:07:05 UTC",
      "updated_date": "2025-02-22 18:56:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:27:24.400645"
    },
    {
      "arxiv_id": "2408.10428v1",
      "title": "Are LLMs Any Good for High-Level Synthesis?",
      "title_zh": "翻译失败",
      "authors": [
        "Yuchao Liao",
        "Tosiron Adegbija",
        "Roman Lysecky"
      ],
      "abstract": "The increasing complexity and demand for faster, energy-efficient hardware\ndesigns necessitate innovative High-Level Synthesis (HLS) methodologies. This\npaper explores the potential of Large Language Models (LLMs) to streamline or\nreplace the HLS process, leveraging their ability to understand natural\nlanguage specifications and refactor code. We survey the current research and\nconduct experiments comparing Verilog designs generated by a standard HLS tool\n(Vitis HLS) with those produced by LLMs translating C code or natural language\nspecifications. Our evaluation focuses on quantifying the impact on\nperformance, power, and resource utilization, providing an assessment of the\nefficiency of LLM-based approaches. This study aims to illuminate the role of\nLLMs in HLS, identifying promising directions for optimized hardware design in\napplications such as AI acceleration, embedded systems, and high-performance\ncomputing.",
      "tldr_zh": "这篇论文探讨了大型语言模型 (LLMs) 在高层次综合 (HLS) 中的潜力，旨在通过理解自然语言规范和代码重构来简化或取代传统 HLS 流程，以应对硬件设计的复杂性和效率需求。研究者调查了现有文献，并通过实验比较 LLMs 从 C 代码或自然语言规范生成的 Verilog 设计与标准工具（如 Vitis HLS）的输出。评估重点量化了 LLMs 方法在性能、功耗和资源利用率方面的影响，结果显示了其在优化硬件设计方面的可行性。该研究为 LLMs 在 AI 加速、嵌入式系统和高性能计算等应用中的角色提供了宝贵见解。",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "primary_category": "cs.AR",
      "comment": "ICCAD '24 Special Session on AI4HLS: New Frontiers in High-Level\n  Synthesis Augmented with Artificial Intelligence",
      "pdf_url": "http://arxiv.org/pdf/2408.10428v1",
      "published_date": "2024-08-19 21:40:28 UTC",
      "updated_date": "2024-08-19 21:40:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:27:37.407347"
    },
    {
      "arxiv_id": "2408.10417v1",
      "title": "Development of an AI Anti-Bullying System Using Large Language Model Key Topic Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Matthew Tassava",
        "Cameron Kolodjski",
        "Jordan Milbrath",
        "Adorah Bishop",
        "Nathan Flanders",
        "Robbie Fetsch",
        "Danielle Hanson",
        "Jeremy Straub"
      ],
      "abstract": "This paper presents and evaluates work on the development of an artificial\nintelligence (AI) anti-bullying system. The system is designed to identify\ncoordinated bullying attacks via social media and other mechanisms,\ncharacterize them and propose remediation and response activities to them. In\nparticular, a large language model (LLM) is used to populate an enhanced expert\nsystem-based network model of a bullying attack. This facilitates analysis and\nremediation activity - such as generating report messages to social media\ncompanies - determination. The system is described and the efficacy of the LLM\nfor populating the model is analyzed herein.",
      "tldr_zh": "本论文介绍了使用 Large Language Model (LLM) 开发一个 AI 反欺凌系统的过程，该系统旨在识别和特征化通过社交媒体等渠道的协调欺凌攻击，并提出相应的补救和响应措施。核心方法涉及 LLM 填充一个增强的专家系统网络模型，以分析攻击并生成报告消息，如向社交媒体公司报告。研究评估了 LLM 在模型填充方面的效能，展示了该系统在应对欺凌问题上的潜在实用价值。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.10417v1",
      "published_date": "2024-08-19 21:09:31 UTC",
      "updated_date": "2024-08-19 21:09:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:27:47.603365"
    },
    {
      "arxiv_id": "2408.10414v1",
      "title": "Towards Automation of Human Stage of Decay Identification: An Artificial Intelligence Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Anna-Maria Nau",
        "Phillip Ditto",
        "Dawnie Wolfe Steadman",
        "Audris Mockus"
      ],
      "abstract": "Determining the stage of decomposition (SOD) is crucial for estimating the\npostmortem interval and identifying human remains. Currently, labor-intensive\nmanual scoring methods are used for this purpose, but they are subjective and\ndo not scale for the emerging large-scale archival collections of human\ndecomposition photos. This study explores the feasibility of automating two\ncommon human decomposition scoring methods proposed by Megyesi and Gelderman\nusing artificial intelligence (AI). We evaluated two popular deep learning\nmodels, Inception V3 and Xception, by training them on a large dataset of human\ndecomposition images to classify the SOD for different anatomical regions,\nincluding the head, torso, and limbs. Additionally, an interrater study was\nconducted to assess the reliability of the AI models compared to human forensic\nexaminers for SOD identification. The Xception model achieved the best\nclassification performance, with macro-averaged F1 scores of .878, .881, and\n.702 for the head, torso, and limbs when predicting Megyesi's SODs, and .872,\n.875, and .76 for the head, torso, and limbs when predicting Gelderman's SODs.\nThe interrater study results supported AI's ability to determine the SOD at a\nreliability level comparable to a human expert. This work demonstrates the\npotential of AI models trained on a large dataset of human decomposition images\nto automate SOD identification.",
      "tldr_zh": "该研究旨在自动化人类分解阶段（Stage of Decay, SOD）的识别，以解决传统手动方法的主观性和扩展性问题。研究者使用深度学习模型 Inception V3 和 Xception 在大型人类分解图像数据集上训练，针对头、躯干和四肢区域分类 Megyesi 和 Gelderman 的 SOD 方法。Xception 模型表现出色，其宏平均 F1 分数在 Megyesi 方法上分别为 0.878（头）、0.881（躯干）和 0.702（四肢），而在 Gelderman 方法上分别为 0.872、0.875 和 0.76。通过 interrater 研究，AI 的可靠性与人类法医专家相当，为大规模档案图像的 SOD 识别提供自动化解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "13 pages",
      "pdf_url": "http://arxiv.org/pdf/2408.10414v1",
      "published_date": "2024-08-19 21:00:40 UTC",
      "updated_date": "2024-08-19 21:00:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:28:00.310266"
    },
    {
      "arxiv_id": "2408.10397v2",
      "title": "Webcam-based Pupil Diameter Prediction Benefits from Upscaling",
      "title_zh": "翻译失败",
      "authors": [
        "Vijul Shah",
        "Brian B. Moser",
        "Ko Watanabe",
        "Andreas Dengel"
      ],
      "abstract": "Capturing pupil diameter is essential for assessing psychological and\nphysiological states such as stress levels and cognitive load. However, the low\nresolution of images in eye datasets often hampers precise measurement. This\nstudy evaluates the impact of various upscaling methods, ranging from bicubic\ninterpolation to advanced super-resolution, on pupil diameter predictions. We\ncompare several pre-trained methods, including CodeFormer, GFPGAN, Real-ESRGAN,\nHAT, and SRResNet. Our findings suggest that pupil diameter prediction models\ntrained on upscaled datasets are highly sensitive to the selected upscaling\nmethod and scale. Our results demonstrate that upscaling methods consistently\nenhance the accuracy of pupil diameter prediction models, highlighting the\nimportance of upscaling in pupilometry. Overall, our work provides valuable\ninsights for selecting upscaling techniques, paving the way for more accurate\nassessments in psychological and physiological research.",
      "tldr_zh": "本文研究了通过图像放大方法提升基于网络摄像头的瞳孔直径预测准确性，以应对眼部数据集分辨率低导致的测量问题。研究比较了多种预训练放大技术，包括CodeFormer、GFPGAN、Real-ESRGAN、HAT和SRResNet，并评估了这些方法对预测模型的影响。结果表明，瞳孔直径预测模型对所选放大方法和缩放比例高度敏感，但整体上，这些方法能显著提高预测精度。总体而言，该工作为心理和生理研究中的瞳孔测量提供了重要指导，帮助实现更精确的评估。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.10397v2",
      "published_date": "2024-08-19 20:28:39 UTC",
      "updated_date": "2024-12-22 19:35:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:28:11.905690"
    },
    {
      "arxiv_id": "2408.10395v1",
      "title": "Evaluating Image-Based Face and Eye Tracking with Event Cameras",
      "title_zh": "使用事件相机评估基于图像的面部和眼睛跟踪",
      "authors": [
        "Khadija Iddrisu",
        "Waseem Shariff",
        "Noel E. OConnor",
        "Joseph Lemley",
        "Suzanne Little"
      ],
      "abstract": "Event Cameras, also known as Neuromorphic sensors, capture changes in local\nlight intensity at the pixel level, producing asynchronously generated data\ntermed ``events''. This distinct data format mitigates common issues observed\nin conventional cameras, like under-sampling when capturing fast-moving\nobjects, thereby preserving critical information that might otherwise be lost.\nHowever, leveraging this data often necessitates the development of\nspecialized, handcrafted event representations that can integrate seamlessly\nwith conventional Convolutional Neural Networks (CNNs), considering the unique\nattributes of event data. In this study, We evaluate event-based Face and Eye\ntracking. The core objective of our study is to showcase the viability of\nintegrating conventional algorithms with event-based data, transformed into a\nframe format while preserving the unique benefits of event cameras. To validate\nour approach, we constructed a frame-based event dataset by simulating events\nbetween RGB frames derived from the publicly accessible Helen Dataset. We\nassess its utility for face and eye detection tasks through the application of\nGR-YOLO -- a pioneering technique derived from YOLOv3. This evaluation includes\na comparative analysis with results derived from training the dataset with\nYOLOv8. Subsequently, the trained models were tested on real event streams from\nvarious iterations of Prophesee's event cameras and further evaluated on the\nFaces in Event Stream (FES) benchmark dataset. The models trained on our\ndataset shows a good prediction performance across all the datasets obtained\nfor validation with the best results of a mean Average precision score of 0.91.\nAdditionally, The models trained demonstrated robust performance on real event\ncamera data under varying light conditions.",
      "tldr_zh": "本研究评估了使用 Event Cameras 进行基于图像的面部和眼睛跟踪，Event Cameras 通过捕捉像素级光强度变化生成异步事件数据，避免了传统相机在快速移动物体捕捉时的欠采样问题。研究团队构建了一个基于 Helen Dataset 的帧式事件数据集，并使用 GR-YOLO（基于 YOLOv3）和 YOLOv8 算法进行面部和眼睛检测训练与比较。结果显示，训练模型在 Prophesee 的 event cameras 和 Faces in Event Stream (FES) benchmark 数据集上表现出色，最好 mean Average precision (mAP) 达 0.91，并在不同光照条件下保持鲁棒性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "This paper has been accepted at The Workshop On Neuromorphic Vision:\n  Advantages and Applications of Event Cameras at the European Conference on\n  Computer Vision (ECCV), 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.10395v1",
      "published_date": "2024-08-19 20:27:08 UTC",
      "updated_date": "2024-08-19 20:27:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:28:24.146220"
    },
    {
      "arxiv_id": "2408.10394v1",
      "title": "Joint Modeling of Search and Recommendations Via an Unified Contextual Recommender (UniCoRn)",
      "title_zh": "翻译失败",
      "authors": [
        "Moumita Bhattacharya",
        "Vito Ostuni",
        "Sudarshan Lamkhede"
      ],
      "abstract": "Search and recommendation systems are essential in many services, and they\nare often developed separately, leading to complex maintenance and technical\ndebt. In this paper, we present a unified deep learning model that efficiently\nhandles key aspects of both tasks.",
      "tldr_zh": "该研究指出，搜索和推荐系统在许多服务中至关重要，但通常被分开开发，导致维护复杂和技术债务问题。为解决此问题，论文提出了一种统一的深度学习模型UniCoRn（Unified Contextual Recommender），它通过整合上下文信息高效处理搜索和推荐任务的关键方面。该模型有助于简化系统开发并减少技术债务，为构建更集成化的服务提供新途径。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "3 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2408.10394v1",
      "published_date": "2024-08-19 20:26:45 UTC",
      "updated_date": "2024-08-19 20:26:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:28:35.696800"
    },
    {
      "arxiv_id": "2408.10383v1",
      "title": "BrewCLIP: A Bifurcated Representation Learning Framework for Audio-Visual Retrieval",
      "title_zh": "翻译失败",
      "authors": [
        "Zhenyu Lu",
        "Lakshay Sethi"
      ],
      "abstract": "Previous methods for audio-image matching generally fall into one of two\ncategories: pipeline models or End-to-End models. Pipeline models first\ntranscribe speech and then encode the resulting text; End-to-End models encode\nspeech directly. Generally, pipeline models outperform end-to-end models, but\nthe intermediate transcription necessarily discards some potentially useful\nnon-textual information. In addition to textual information, speech can convey\ndetails such as accent, mood, and and emphasis, which should be effectively\ncaptured in the encoded representation. In this paper, we investigate whether\nnon-textual information, which is overlooked by pipeline-based models, can be\nleveraged to improve speech-image matching performance. We thoroughly analyze\nand compare End-to-End models, pipeline models, and our proposed dual-channel\nmodel for robust audio-image retrieval on a variety of datasets. Our approach\nachieves a substantial performance gain over the previous state-of-the-art by\nleveraging strong pretrained models, a prompting mechanism and a bifurcated\ndesign.",
      "tldr_zh": "本研究探讨了音频-图像匹配任务中的现有方法，包括 Pipeline models（先转录语音再编码文本）和 End-to-End models（直接编码语音），指出 Pipeline models 虽性能更强，但会丢弃非文本信息如口音、情绪和强调。论文提出 BrewCLIP，一种双通道（Bifurcated）表示学习框架，通过整合预训练模型、prompting mechanism 和 bifurcated design，利用这些非文本信息来提升音频-视觉检索性能。在多种数据集上的实验中，该框架显著超过了现有 state-of-the-art 方法，实现了实质性性能提升。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.10383v1",
      "published_date": "2024-08-19 19:56:10 UTC",
      "updated_date": "2024-08-19 19:56:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:28:49.957224"
    },
    {
      "arxiv_id": "2408.10381v1",
      "title": "Efficient Reinforcement Learning in Probabilistic Reward Machines",
      "title_zh": "在概率奖励机中的高效强化学习",
      "authors": [
        "Xiaofeng Lin",
        "Xuezhou Zhang"
      ],
      "abstract": "In this paper, we study reinforcement learning in Markov Decision Processes\nwith Probabilistic Reward Machines (PRMs), a form of non-Markovian reward\ncommonly found in robotics tasks. We design an algorithm for PRMs that achieves\na regret bound of $\\widetilde{O}(\\sqrt{HOAT} + H^2O^2A^{3/2} + H\\sqrt{T})$,\nwhere $H$ is the time horizon, $O$ is the number of observations, $A$ is the\nnumber of actions, and $T$ is the number of time-steps. This result improves\nover the best-known bound, $\\widetilde{O}(H\\sqrt{OAT})$ of\n\\citet{pmlr-v206-bourel23a} for MDPs with Deterministic Reward Machines (DRMs),\na special case of PRMs. When $T \\geq H^3O^3A^2$ and $OA \\geq H$, our regret\nbound leads to a regret of $\\widetilde{O}(\\sqrt{HOAT})$, which matches the\nestablished lower bound of $\\Omega(\\sqrt{HOAT})$ for MDPs with DRMs up to a\nlogarithmic factor. To the best of our knowledge, this is the first efficient\nalgorithm for PRMs. Additionally, we present a new simulation lemma for\nnon-Markovian rewards, which enables reward-free exploration for any\nnon-Markovian reward given access to an approximate planner. Complementing our\ntheoretical findings, we show through extensive experiment evaluations that our\nalgorithm indeed outperforms prior methods in various PRM environments.",
      "tldr_zh": "本论文研究了在 Probabilistic Reward Machines (PRMs) 中的高效强化学习，针对非马尔可夫奖励问题（如机器人任务）提出了一种新算法。该算法实现了遗憾界 $\\widetilde{O}(\\sqrt{HOAT} + H^2O^2A^{3/2} + H\\sqrt{T})$，在特定条件下（如 $T \\geq H^3O^3A^2$）达到 $\\widetilde{O}(\\sqrt{HOAT})$，这比先前 Deterministic Reward Machines (DRMs) 的 $\\widetilde{O}(H\\sqrt{OAT})$ 界限有了显著改善。论文还引入了一个新的 simulation lemma，支持非马尔可夫奖励的奖励自由探索，并通过广泛实验验证，证明该算法在各种 PRM 环境中优于现有方法。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "33 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.10381v1",
      "published_date": "2024-08-19 19:51:53 UTC",
      "updated_date": "2024-08-19 19:51:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:29:02.084084"
    },
    {
      "arxiv_id": "2408.10369v2",
      "title": "Boolean Matrix Logic Programming",
      "title_zh": "布尔矩阵逻辑编程",
      "authors": [
        "Lun Ai",
        "Stephen H. Muggleton"
      ],
      "abstract": "We describe a datalog query evaluation approach based on efficient and\ncomposable boolean matrix manipulation modules. We first define an overarching\nproblem, Boolean Matrix Logic Programming (BMLP), which uses boolean matrices\nas an alternative computation to evaluate datalog programs. We develop two\nnovel BMLP modules for bottom-up inferences on linear dyadic recursive datalog\nprograms, and show how additional modules can extend this capability to compute\nboth linear and non-linear recursive datalog programs of arity two. Our\nempirical results demonstrate that these modules outperform general-purpose and\nspecialised systems by factors of 30x and 9x, respectively, when evaluating\nlarge programs with millions of facts. This boolean matrix approach\nsignificantly enhances the efficiency of datalog querying to support logic\nprogramming techniques.",
      "tldr_zh": "论文提出了 Boolean Matrix Logic Programming (BMLP)，一种基于高效可组合布尔矩阵操作的 Datalog 查询评估方法，作为传统计算的替代方案。研究开发了两个新模块，用于处理线性二元递归 Datalog 程序的底部向上推理，并展示了如何扩展这些模块以支持线性及非线性递归程序的计算。实验结果显示，在评估包含数百万事实的大型程序时，BMLP 模块分别比通用系统和专业系统快 30 倍和 9 倍，从而显著提升了 Datalog 查询的效率，并强化了逻辑编程技术。",
      "categories": [
        "cs.SC",
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.SC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.10369v2",
      "published_date": "2024-08-19 19:26:49 UTC",
      "updated_date": "2024-08-25 20:06:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:29:13.772867"
    },
    {
      "arxiv_id": "2408.10365v1",
      "title": "AI-Driven Review Systems: Evaluating LLMs in Scalable and Bias-Aware Academic Reviews",
      "title_zh": "翻译失败",
      "authors": [
        "Keith Tyser",
        "Ben Segev",
        "Gaston Longhitano",
        "Xin-Yu Zhang",
        "Zachary Meeks",
        "Jason Lee",
        "Uday Garg",
        "Nicholas Belsten",
        "Avi Shporer",
        "Madeleine Udell",
        "Dov Te'eni",
        "Iddo Drori"
      ],
      "abstract": "Automatic reviewing helps handle a large volume of papers, provides early\nfeedback and quality control, reduces bias, and allows the analysis of trends.\nWe evaluate the alignment of automatic paper reviews with human reviews using\nan arena of human preferences by pairwise comparisons. Gathering human\npreference may be time-consuming; therefore, we also use an LLM to\nautomatically evaluate reviews to increase sample efficiency while reducing\nbias. In addition to evaluating human and LLM preferences among LLM reviews, we\nfine-tune an LLM to predict human preferences, predicting which reviews humans\nwill prefer in a head-to-head battle between LLMs. We artificially introduce\nerrors into papers and analyze the LLM's responses to identify limitations, use\nadaptive review questions, meta prompting, role-playing, integrate visual and\ntextual analysis, use venue-specific reviewing materials, and predict human\npreferences, improving upon the limitations of the traditional review\nprocesses. We make the reviews of publicly available arXiv and open-access\nNature journal papers available online, along with a free service which helps\nauthors review and revise their research papers and improve their quality. This\nwork develops proof-of-concept LLM reviewing systems that quickly deliver\nconsistent, high-quality reviews and evaluate their quality. We mitigate the\nrisks of misuse, inflated review scores, overconfident ratings, and skewed\nscore distributions by augmenting the LLM with multiple documents, including\nthe review form, reviewer guide, code of ethics and conduct, area chair\nguidelines, and previous year statistics, by finding which errors and\nshortcomings of the paper may be detected by automated reviews, and evaluating\npairwise reviewer preferences. This work identifies and addresses the\nlimitations of using LLMs as reviewers and evaluators and enhances the quality\nof the reviewing process.",
      "tldr_zh": "该论文提出了一种AI驱动的审阅系统，使用LLMs（Large Language Models）来评估学术论文审阅的准确性、可扩展性和偏见控制，通过pairwise comparisons与人类偏好比较来衡量自动审阅与人工审阅的alignment。研究方法包括fine-tune LLM预测人类偏好、引入人为错误测试LLM局限性、采用adaptive review questions、meta prompting和role-playing等技术，以改进传统审阅过程并减少风险。实验结果表明，该系统能快速提供一致的高质量审阅，并通过整合多文档（如审阅指南和道德准则）来缓解误用和偏见问题，同时公开了arXiv和Nature论文的审阅服务以提升学术质量。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "42 pages",
      "pdf_url": "http://arxiv.org/pdf/2408.10365v1",
      "published_date": "2024-08-19 19:10:38 UTC",
      "updated_date": "2024-08-19 19:10:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:29:24.961835"
    },
    {
      "arxiv_id": "2408.10362v2",
      "title": "Query languages for neural networks",
      "title_zh": "神经网络的查询语言",
      "authors": [
        "Martin Grohe",
        "Christoph Standke",
        "Juno Steegmans",
        "Jan Van den Bussche"
      ],
      "abstract": "We lay the foundations for a database-inspired approach to interpreting and\nunderstanding neural network models by querying them using declarative\nlanguages. Towards this end we study different query languages, based on\nfirst-order logic, that mainly differ in their access to the neural network\nmodel. First-order logic over the reals naturally yields a language which views\nthe network as a black box; only the input--output function defined by the\nnetwork can be queried. This is essentially the approach of constraint query\nlanguages. On the other hand, a white-box language can be obtained by viewing\nthe network as a weighted graph, and extending first-order logic with summation\nover weight terms. The latter approach is essentially an abstraction of SQL. In\ngeneral, the two approaches are incomparable in expressive power, as we will\nshow. Under natural circumstances, however, the white-box approach can subsume\nthe black-box approach; this is our main result. We prove the result concretely\nfor linear constraint queries over real functions definable by feedforward\nneural networks with a fixed number of hidden layers and piecewise linear\nactivation functions.",
      "tldr_zh": "该论文探讨了使用声明式查询语言来解释和理解神经网络模型的数据库启发式方法，基于一阶逻辑（first-order logic）设计不同查询语言。黑盒（black box）方法仅允许查询神经网络的输入-输出函数，而白盒（white box）方法则将网络视为加权图，并扩展一阶逻辑以包括权重求和，从而提升表达能力。研究发现，这两种方法在一般情况下表达能力不可比，但在针对固定隐藏层和分段线性激活函数（piecewise linear activation functions）的feedforward神经网络时，白盒方法可以包含黑盒方法，为神经网络查询提供更坚实的基础。",
      "categories": [
        "cs.AI",
        "cs.DB",
        "cs.LO",
        "H.2.3; I.2.6"
      ],
      "primary_category": "cs.AI",
      "comment": "To appear at ICDT 2025",
      "pdf_url": "http://arxiv.org/pdf/2408.10362v2",
      "published_date": "2024-08-19 18:59:52 UTC",
      "updated_date": "2024-08-21 12:50:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:29:36.958711"
    },
    {
      "arxiv_id": "2408.10360v6",
      "title": "HaSPeR: An Image Repository for Hand Shadow Puppet Recognition",
      "title_zh": "HaSPeR：手影戏识别图像仓库",
      "authors": [
        "Syed Rifat Raiyan",
        "Zibran Zarif Amio",
        "Sabbir Ahmed"
      ],
      "abstract": "Hand shadow puppetry, also known as shadowgraphy or ombromanie, is a form of\ntheatrical art and storytelling where hand shadows are projected onto flat\nsurfaces to create illusions of living creatures. The skilled performers create\nthese silhouettes by hand positioning, finger movements, and dexterous gestures\nto resemble shadows of animals and objects. Due to the lack of practitioners\nand a seismic shift in people's entertainment standards, this art form is on\nthe verge of extinction. To facilitate its preservation and proliferate it to a\nwider audience, we introduce ${\\rm H{\\small A}SP{\\small E}R}$, a novel dataset\nconsisting of 15,000 images of hand shadow puppets across 15 classes extracted\nfrom both professional and amateur hand shadow puppeteer clips. We provide a\ndetailed statistical analysis of the dataset and employ a range of pretrained\nimage classification models to establish baselines. Our findings show a\nsubstantial performance superiority of skip-connected convolutional models over\nattention-based transformer architectures. We also find that lightweight\nmodels, such as MobileNetV2, suited for mobile applications and embedded\ndevices, perform comparatively well. We surmise that such low-latency\narchitectures can be useful in developing ombromanie teaching tools, and we\ncreate a prototype application to explore this surmission. Keeping the\nbest-performing model ResNet34 under the limelight, we conduct comprehensive\nfeature-spatial, explainability, and error analyses to gain insights into its\ndecision-making process. To the best of our knowledge, this is the first\ndocumented dataset and research endeavor to preserve this dying art for future\ngenerations, with computer vision approaches. Our code and data will be\npublicly available.",
      "tldr_zh": "本研究引入了 HaSPeR 数据集，这是一个包含 15,000 张手影戏图像的仓库，涵盖 15 个类别，旨在保存这一濒临灭绝的艺术形式。研究者对数据集进行了详细统计分析，并使用预训练图像分类模型（如 ResNet34 和 MobileNetV2）建立了基准，结果显示跳跃连接卷积模型在性能上优于注意力-based transformer 架构。轻量级模型如 MobileNetV2 表现出色，适合开发低延迟教学工具，因此团队创建了一个原型应用，并通过特征空间、解释性和错误分析深入探讨了 ResNet34 的决策过程；代码和数据将公开可用，以支持未来研究。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Submitted to Image and Vision Computing, 15 pages, 110 figures, 2\n  tables",
      "pdf_url": "http://arxiv.org/pdf/2408.10360v6",
      "published_date": "2024-08-19 18:56:24 UTC",
      "updated_date": "2025-03-31 19:29:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:29:50.458690"
    },
    {
      "arxiv_id": "2408.10351v1",
      "title": "The Psychological Impacts of Algorithmic and AI-Driven Social Media on Teenagers: A Call to Action",
      "title_zh": "翻译失败",
      "authors": [
        "Sunil Arora",
        "Sahil Arora",
        "John D. Hastings"
      ],
      "abstract": "This study investigates the meta-issues surrounding social media, which,\nwhile theoretically designed to enhance social interactions and improve our\nsocial lives by facilitating the sharing of personal experiences and life\nevents, often results in adverse psychological impacts. Our investigation\nreveals a paradoxical outcome: rather than fostering closer relationships and\nimproving social lives, the algorithms and structures that underlie social\nmedia platforms inadvertently contribute to a profound psychological impact on\nindividuals, influencing them in unforeseen ways. This phenomenon is\nparticularly pronounced among teenagers, who are disproportionately affected by\ncurated online personas, peer pressure to present a perfect digital image, and\nthe constant bombardment of notifications and updates that characterize their\nsocial media experience. As such, we issue a call to action for policymakers,\nplatform developers, and educators to prioritize the well-being of teenagers in\nthe digital age and work towards creating secure and safe social media\nplatforms that protect the young from harm, online harassment, and\nexploitation.",
      "tldr_zh": "这篇论文研究了算法驱动的社交媒体（algorithmic and AI-driven social media）对青少年的心理影响，发现这些平台虽旨在提升社交互动，却反而导致负面后果，如强化假想完美形象、同伴压力和通知轰炸，进而加剧心理问题。调查结果显示，青少年群体尤为易受影响，面临孤立、在线骚扰和剥削的风险。作者发出行动号召，敦促政策制定者、平台开发者和教育者优先考虑青少年福祉，构建安全可靠的数字环境以防范潜在危害。",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.CY",
        "cs.HC",
        "H.5.2; I.2.6; J.4; H.3.5"
      ],
      "primary_category": "cs.SI",
      "comment": "7 pages, 0 figures, 2 tables, 2024 IEEE Conference on Digital\n  Platforms and Societal Harms",
      "pdf_url": "http://arxiv.org/pdf/2408.10351v1",
      "published_date": "2024-08-19 18:49:12 UTC",
      "updated_date": "2024-08-19 18:49:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:30:01.625280"
    },
    {
      "arxiv_id": "2408.14487v3",
      "title": "Active learning of digenic functions with boolean matrix logic programming",
      "title_zh": "翻译失败",
      "authors": [
        "Lun Ai",
        "Stephen H. Muggleton",
        "Shi-shun Liang",
        "Geoff S. Baldwin"
      ],
      "abstract": "We apply logic-based machine learning techniques to facilitate cellular\nengineering and drive biological discovery, based on comprehensive databases of\nmetabolic processes called genome-scale metabolic network models (GEMs).\nPredicted host behaviours are not always correctly described by GEMs. Learning\nthe intricate genetic interactions within GEMs presents computational and\nempirical challenges. To address these, we describe a novel approach called\nBoolean Matrix Logic Programming (BMLP) by leveraging boolean matrices to\nevaluate large logic programs. We introduce a new system, $BMLP_{active}$,\nwhich efficiently explores the genomic hypothesis space by guiding informative\nexperimentation through active learning. In contrast to sub-symbolic methods,\n$BMLP_{active}$ encodes a state-of-the-art GEM of a widely accepted bacterial\nhost in an interpretable and logical representation using datalog logic\nprograms. Notably, $BMLP_{active}$ can successfully learn the interaction\nbetween a gene pair with fewer training examples than random experimentation,\novercoming the increase in experimental design space. $BMLP_{active}$ enables\nrapid optimisation of metabolic models and offers a realistic approach to a\nself-driving lab for microbial engineering.",
      "tldr_zh": "该研究提出 Boolean Matrix Logic Programming (BMLP) 方法，利用布尔矩阵评估大型逻辑程序，以解决 genome-scale metabolic network models (GEMs) 中遗传互动的计算和经验挑战。研究引入 $BMLP_{active}$ 系统，通过 active learning 技术高效探索基因组假设空间，并使用 datalog 逻辑程序对细菌宿主 GEM 进行可解释表示，从而指导信息实验。相比随机实验，$BMLP_{active}$ 能用更少的训练示例成功学习基因对互动，促进代谢模型的快速优化，并为微生物工程的自驱动实验室提供现实解决方案。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.SC",
        "q-bio.MN"
      ],
      "primary_category": "cs.AI",
      "comment": "arXiv admin note: substantial text overlap with arXiv:2405.06724",
      "pdf_url": "http://arxiv.org/pdf/2408.14487v3",
      "published_date": "2024-08-19 18:47:07 UTC",
      "updated_date": "2024-11-13 10:09:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:30:14.289030"
    },
    {
      "arxiv_id": "2408.10343v1",
      "title": "LegalBench-RAG: A Benchmark for Retrieval-Augmented Generation in the Legal Domain",
      "title_zh": "LegalBench-RAG：法律领域检索增强生成的基准测试",
      "authors": [
        "Nicholas Pipitone",
        "Ghita Houir Alami"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) systems are showing promising potential,\nand are becoming increasingly relevant in AI-powered legal applications.\nExisting benchmarks, such as LegalBench, assess the generative capabilities of\nLarge Language Models (LLMs) in the legal domain, but there is a critical gap\nin evaluating the retrieval component of RAG systems. To address this, we\nintroduce LegalBench-RAG, the first benchmark specifically designed to evaluate\nthe retrieval step of RAG pipelines within the legal space. LegalBench-RAG\nemphasizes precise retrieval by focusing on extracting minimal, highly relevant\ntext segments from legal documents. These highly relevant snippets are\npreferred over retrieving document IDs, or large sequences of imprecise chunks,\nboth of which can exceed context window limitations. Long context windows cost\nmore to process, induce higher latency, and lead LLMs to forget or hallucinate\ninformation. Additionally, precise results allow LLMs to generate citations for\nthe end user. The LegalBench-RAG benchmark is constructed by retracing the\ncontext used in LegalBench queries back to their original locations within the\nlegal corpus, resulting in a dataset of 6,858 query-answer pairs over a corpus\nof over 79M characters, entirely human-annotated by legal experts. We also\nintroduce LegalBench-RAG-mini, a lightweight version for rapid iteration and\nexperimentation. By providing a dedicated benchmark for legal retrieval,\nLegalBench-RAG serves as a critical tool for companies and researchers focused\non enhancing the accuracy and performance of RAG systems in the legal domain.\nThe LegalBench-RAG dataset is publicly available at\nhttps://github.com/zeroentropy-cc/legalbenchrag.",
      "tldr_zh": "这篇论文引入了 LegalBench-RAG，这是一个专门针对法律领域的 Retrieval-Augmented Generation (RAG) 系统检索步骤的基准测试，旨在填补现有基准如 LegalBench 只评估 Large Language Models (LLMs) 生成能力而忽略检索组件的空白。LegalBench-RAG 强调从法律文件中提取最小且高度相关的文本段，以减少处理成本、延迟和信息遗忘或幻觉问题，同时支持 LLMs 生成准确引文。数据集由 6,858 个查询-答案对组成，总计超过 79M 字符，并由法律专家人工标注；此外，还提供了轻量版 LegalBench-RAG-mini 用于快速实验。该基准为研究者和公司提升 RAG 系统在法律领域的准确性和性能提供了关键工具，并公开了数据集。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.10343v1",
      "published_date": "2024-08-19 18:30:18 UTC",
      "updated_date": "2024-08-19 18:30:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:30:27.461499"
    },
    {
      "arxiv_id": "2408.10334v1",
      "title": "A Disguised Wolf Is More Harmful Than a Toothless Tiger: Adaptive Malicious Code Injection Backdoor Attack Leveraging User Behavior as Triggers",
      "title_zh": "翻译失败",
      "authors": [
        "Shangxi Wu",
        "Jitao Sang"
      ],
      "abstract": "In recent years, large language models (LLMs) have made significant progress\nin the field of code generation. However, as more and more users rely on these\nmodels for software development, the security risks associated with code\ngeneration models have become increasingly significant. Studies have shown that\ntraditional deep learning robustness issues also negatively impact the field of\ncode generation. In this paper, we first present the game-theoretic model that\nfocuses on security issues in code generation scenarios. This framework\noutlines possible scenarios and patterns where attackers could spread malicious\ncode models to create security threats. We also pointed out for the first time\nthat the attackers can use backdoor attacks to dynamically adjust the timing of\nmalicious code injection, which will release varying degrees of malicious code\ndepending on the skill level of the user. Through extensive experiments on\nleading code generation models, we validate our proposed game-theoretic model\nand highlight the significant threats that these new attack scenarios pose to\nthe safe use of code models.",
      "tldr_zh": "本研究探讨了大型语言模型（LLMs）在代码生成中的安全风险，首次提出一种基于游戏理论模型的框架，用于分析攻击者在代码生成场景中传播恶意代码的可能模式。攻击者通过后门攻击（backdoor attacks）动态调整恶意代码注入时机，根据用户技能水平释放不同程度的恶意代码，从而实现更隐蔽和针对性的威胁。在领先代码生成模型上的广泛实验验证了该模型的有效性，并强调了这些新攻击场景对代码模型安全使用的重大潜在危害。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.10334v1",
      "published_date": "2024-08-19 18:18:04 UTC",
      "updated_date": "2024-08-19 18:18:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:30:38.973209"
    },
    {
      "arxiv_id": "2408.10328v1",
      "title": "Decoding Human Emotions: Analyzing Multi-Channel EEG Data using LSTM Networks",
      "title_zh": "解码人类情绪：使用 LSTM 网络分析多通道 EEG 数据",
      "authors": [
        "Shyam K Sateesh",
        "Sparsh BK",
        "Uma D"
      ],
      "abstract": "Emotion recognition from electroencephalogram (EEG) signals is a thriving\nfield, particularly in neuroscience and Human-Computer Interaction (HCI). This\nstudy aims to understand and improve the predictive accuracy of emotional state\nclassification through metrics such as valence, arousal, dominance, and\nlikeness by applying a Long Short-Term Memory (LSTM) network to analyze EEG\nsignals. Using a popular dataset of multi-channel EEG recordings known as DEAP,\nwe look towards leveraging LSTM networks' properties to handle temporal\ndependencies within EEG signal data. This allows for a more comprehensive\nunderstanding and classification of emotional parameter states. We obtain\naccuracies of 89.89%, 90.33%, 90.70%, and 90.54% for arousal, valence,\ndominance, and likeness, respectively, demonstrating significant improvements\nin emotion recognition model capabilities. This paper elucidates the\nmethodology and architectural specifics of our LSTM model and provides a\nbenchmark analysis with existing papers.",
      "tldr_zh": "这篇论文使用 Long Short-Term Memory (LSTM) 网络分析多通道 EEG 数据，旨在提升情绪状态分类的准确性，包括 valence、arousal、dominance 和 likeness 等指标。研究者基于 DEAP 数据集，利用 LSTM 处理 EEG 信号中的时间依赖性，实现了对情绪参数的全面理解和分类。结果显示，准确率分别为 arousal 89.89%、valence 90.33%、dominance 90.70% 和 likeness 90.54%，并通过方法论细节和基准分析证明了该模型在情绪识别领域的显著改进。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.LG",
      "comment": "13 pages, 3 figures; accepted at ICDSA '24 Conference, Jaipur, India",
      "pdf_url": "http://arxiv.org/pdf/2408.10328v1",
      "published_date": "2024-08-19 18:10:47 UTC",
      "updated_date": "2024-08-19 18:10:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:30:53.259850"
    },
    {
      "arxiv_id": "2408.10205v1",
      "title": "KAN 2.0: Kolmogorov-Arnold Networks Meet Science",
      "title_zh": "翻译失败",
      "authors": [
        "Ziming Liu",
        "Pingchuan Ma",
        "Yixuan Wang",
        "Wojciech Matusik",
        "Max Tegmark"
      ],
      "abstract": "A major challenge of AI + Science lies in their inherent incompatibility:\ntoday's AI is primarily based on connectionism, while science depends on\nsymbolism. To bridge the two worlds, we propose a framework to seamlessly\nsynergize Kolmogorov-Arnold Networks (KANs) and science. The framework\nhighlights KANs' usage for three aspects of scientific discovery: identifying\nrelevant features, revealing modular structures, and discovering symbolic\nformulas. The synergy is bidirectional: science to KAN (incorporating\nscientific knowledge into KANs), and KAN to science (extracting scientific\ninsights from KANs). We highlight major new functionalities in the pykan\npackage: (1) MultKAN: KANs with multiplication nodes. (2) kanpiler: a KAN\ncompiler that compiles symbolic formulas into KANs. (3) tree converter: convert\nKANs (or any neural networks) to tree graphs. Based on these tools, we\ndemonstrate KANs' capability to discover various types of physical laws,\nincluding conserved quantities, Lagrangians, symmetries, and constitutive laws.",
      "tldr_zh": "该论文提出 KAN 2.0 框架，以桥接 AI 的连接主义和科学的符号主义，强调 Kolmogorov-Arnold Networks (KANs) 在科学发现中的作用，包括识别相关特征、揭示模块结构和发现符号公式。\n框架实现双向协同：将科学知识融入 KANs（如通过新工具 MultKAN 和 kanpiler），以及从 KANs 中提取科学洞见（如使用 tree converter 转换网络为树图）。\n实验演示了 KANs 在发现各种物理定律的能力，包括守恒量、Lagrangians、对称性和本构定律，从而推动 AI 与科学的融合。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.comp-ph",
        "physics.data-an"
      ],
      "primary_category": "cs.LG",
      "comment": "27 pages, 14 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.10205v1",
      "published_date": "2024-08-19 17:59:04 UTC",
      "updated_date": "2024-08-19 17:59:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:31:05.691809"
    },
    {
      "arxiv_id": "2408.10841v1",
      "title": "DELIA: Diversity-Enhanced Learning for Instruction Adaptation in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yuanhao Zeng",
        "Fei Ren",
        "Xinpeng Zhou",
        "Yihang Wang",
        "Yingxia Shao"
      ],
      "abstract": "Although instruction tuning is widely used to adjust behavior in Large\nLanguage Models (LLMs), extensive empirical evidence and research indicates\nthat it is primarily a process where the model fits to specific task formats,\nrather than acquiring new knowledge or capabilities. We propose that this\nlimitation stems from biased features learned during instruction tuning, which\ndiffer from ideal task-specfic features, leading to learn less underlying\nsemantics in downstream tasks. However, ideal features are unknown and\nincalculable, constraining past work to rely on prior knowledge to assist\nreasoning or training, which limits LLMs' capabilities to the developers'\nabilities, rather than data-driven scalable learning. In our paper, through our\nnovel data synthesis method, DELIA (Diversity-Enhanced Learning for Instruction\nAdaptation), we leverage the buffering effect of extensive diverse data in LLMs\ntraining to transform biased features in instruction tuning into approximations\nof ideal features, without explicit prior ideal features. Experiments show\nDELIA's better performance compared to common instruction tuning and other\nbaselines. It outperforms common instruction tuning by 17.07%-33.41% on\nIcelandic-English translation bleurt score (WMT-21 dataset, gemma-7b-it) and\nimproves accuracy by 36.1% on formatted text generation (Llama2-7b-chat).\nNotably, among knowledge injection methods we've known, DELIA uniquely align\nthe internal representations of new special tokens with their prior semantics.",
      "tldr_zh": "这篇论文指出，Large Language Models (LLMs) 的 instruction tuning 主要使模型适应特定任务格式而非获得新知识，导致偏置特征限制了底层语义学习。作者提出 DELIA (Diversity-Enhanced Learning for Instruction Adaptation)，一种新型数据合成方法，通过利用大量多样数据的缓冲效应，将偏置特征转化为理想特征的近似，而无需显式先验知识。实验结果显示，DELIA 比传统 instruction tuning 在 Icelandic-English 翻译上提升 17.07%-33.41% (bleurt score，WMT-21 数据集，gemma-7b-it)，并在格式化文本生成上提高 36.1% (Llama2-7b-chat)，且独特地对齐新特殊标记的内部表示与原有语义。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.10841v1",
      "published_date": "2024-08-19 17:56:06 UTC",
      "updated_date": "2024-08-19 17:56:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:31:18.211723"
    },
    {
      "arxiv_id": "2408.10197v1",
      "title": "Demystifying the Communication Characteristics for Distributed Transformer Models",
      "title_zh": "翻译失败",
      "authors": [
        "Quentin Anthony",
        "Benjamin Michalowicz",
        "Jacob Hatef",
        "Lang Xu",
        "Mustafa Abduljabbar",
        "Aamir Shafi",
        "Hari Subramoni",
        "Dhabaleswar Panda"
      ],
      "abstract": "Deep learning (DL) models based on the transformer architecture have\nrevolutionized many DL applications such as large language models (LLMs),\nvision transformers, audio generation, and time series prediction. Much of this\nprogress has been fueled by distributed training, yet distributed communication\nremains a substantial bottleneck to training progress. This paper examines the\ncommunication behavior of transformer models - that is, how different\nparallelism schemes used in multi-node/multi-GPU DL Training communicate data\nin the context of transformers. We use GPT-based language models as a case\nstudy of the transformer architecture due to their ubiquity. We validate the\nempirical results obtained from our communication logs using analytical models.\nAt a high level, our analysis reveals a need to optimize small message\npoint-to-point communication further, correlations between sequence length,\nper-GPU throughput, model size, and optimizations used, and where to\npotentially guide further optimizations in framework and HPC middleware design\nand optimization.",
      "tldr_zh": "本研究探讨了Transformer模型在分布式训练中的通信特性，旨在解决通信瓶颈对训练效率的影响。论文以GPT为基础的语言模型作为案例研究，通过分析不同并行方案（如multi-node/multi-GPU DL Training）的通信日志，并结合分析模型，验证了经验结果。研究发现，序列长度、per-GPU throughput、模型大小及优化策略之间存在显著相关性，并强调需要进一步优化小消息point-to-point communication。最终，该分析为分布式训练框架和HPC中间件的设计提供优化指导。",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.10197v1",
      "published_date": "2024-08-19 17:54:29 UTC",
      "updated_date": "2024-08-19 17:54:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:31:28.092752"
    },
    {
      "arxiv_id": "2408.10195v1",
      "title": "SpaRP: Fast 3D Object Reconstruction and Pose Estimation from Sparse Views",
      "title_zh": "翻译失败",
      "authors": [
        "Chao Xu",
        "Ang Li",
        "Linghao Chen",
        "Yulin Liu",
        "Ruoxi Shi",
        "Hao Su",
        "Minghua Liu"
      ],
      "abstract": "Open-world 3D generation has recently attracted considerable attention. While\nmany single-image-to-3D methods have yielded visually appealing outcomes, they\noften lack sufficient controllability and tend to produce hallucinated regions\nthat may not align with users' expectations. In this paper, we explore an\nimportant scenario in which the input consists of one or a few unposed 2D\nimages of a single object, with little or no overlap. We propose a novel\nmethod, SpaRP, to reconstruct a 3D textured mesh and estimate the relative\ncamera poses for these sparse-view images. SpaRP distills knowledge from 2D\ndiffusion models and finetunes them to implicitly deduce the 3D spatial\nrelationships between the sparse views. The diffusion model is trained to\njointly predict surrogate representations for camera poses and multi-view\nimages of the object under known poses, integrating all information from the\ninput sparse views. These predictions are then leveraged to accomplish 3D\nreconstruction and pose estimation, and the reconstructed 3D model can be used\nto further refine the camera poses of input views. Through extensive\nexperiments on three datasets, we demonstrate that our method not only\nsignificantly outperforms baseline methods in terms of 3D reconstruction\nquality and pose prediction accuracy but also exhibits strong efficiency. It\nrequires only about 20 seconds to produce a textured mesh and camera poses for\nthe input views. Project page: https://chaoxu.xyz/sparp.",
      "tldr_zh": "该论文提出了一种名为SpaRP的新方法，用于从稀疏视图（sparse views）快速重建3D对象并估计相机位姿。SpaRP通过从2D扩散模型（diffusion models）中提炼知识并进行微调，隐式推断输入图像间的3D空间关系，同时预测相机位姿的代理表示和多视图图像，以实现联合3D重建和位姿估计。实验结果显示，该方法在三个数据集上显著优于基线方法，在3D重建质量和位姿预测准确性方面表现出色，且仅需约20秒即可生成纹理网格和相机位姿。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR"
      ],
      "primary_category": "cs.CV",
      "comment": "ECCV 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.10195v1",
      "published_date": "2024-08-19 17:53:10 UTC",
      "updated_date": "2024-08-19 17:53:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:31:40.235862"
    },
    {
      "arxiv_id": "2408.10189v2",
      "title": "Transformers to SSMs: Distilling Quadratic Knowledge to Subquadratic Models",
      "title_zh": "翻译失败",
      "authors": [
        "Aviv Bick",
        "Kevin Y. Li",
        "Eric P. Xing",
        "J. Zico Kolter",
        "Albert Gu"
      ],
      "abstract": "Transformer architectures have become a dominant paradigm for domains like\nlanguage modeling but suffer in many inference settings due to their\nquadratic-time self-attention. Recently proposed subquadratic architectures,\nsuch as Mamba, have shown promise, but have been pretrained with substantially\nless computational resources than the strongest Transformer models. In this\nwork, we present a method that is able to distill a pretrained Transformer\narchitecture into alternative architectures such as state space models (SSMs).\nThe key idea to our approach is that we can view both Transformers and SSMs as\napplying different forms of mixing matrices over the token sequences. We can\nthus progressively distill the Transformer architecture by matching different\ndegrees of granularity in the SSM: first matching the mixing matrices\nthemselves, then the hidden units at each block, and finally the end-to-end\npredictions. Our method, called MOHAWK, is able to distill a Mamba-2 variant\nbased on the Phi-1.5 architecture (Phi-Mamba) using only 3B tokens and a hybrid\nversion (Hybrid Phi-Mamba) using 5B tokens. Despite using less than 1% of the\ntraining data typically used to train models from scratch, Phi-Mamba boasts\nsubstantially stronger performance compared to all past open-source\nnon-Transformer models. MOHAWK allows models like SSMs to leverage\ncomputational resources invested in training Transformer-based architectures,\nhighlighting a new avenue for building such models.",
      "tldr_zh": "本文提出 MOHAWK 方法，用于将预训练的 Transformers 架构蒸馏到亚二次方模型如 SSMs 中，解决 Transformers 的二次方时间复杂度问题。关键思路是将两者视为在 token 序列上应用不同混合矩阵，并通过匹配混合矩阵、隐藏单元和端到端预测逐步实现知识转移。实验显示，基于 Phi-1.5 的 Phi-Mamba 变体仅用 3B tokens 训练，便在性能上超越了过去的开源非-Transformer 模型，而混合版本 Hybrid Phi-Mamba 则用 5B tokens 进一步提升效果。该方法为 SSMs 等模型利用 Transformers 的训练资源开辟了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.10189v2",
      "published_date": "2024-08-19 17:48:11 UTC",
      "updated_date": "2025-02-08 20:53:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:31:54.111835"
    },
    {
      "arxiv_id": "2408.10181v1",
      "title": "Imbalance-Aware Culvert-Sewer Defect Segmentation Using an Enhanced Feature Pyramid Network",
      "title_zh": "翻译失败",
      "authors": [
        "Rasha Alshawi",
        "Md Meftahul Ferdaus",
        "Mahdi Abdelguerfi",
        "Kendall Niles",
        "Ken Pathak",
        "Steve Sloan"
      ],
      "abstract": "Imbalanced datasets are a significant challenge in real-world scenarios. They\nlead to models that underperform on underrepresented classes, which is a\ncritical issue in infrastructure inspection. This paper introduces the Enhanced\nFeature Pyramid Network (E-FPN), a deep learning model for the semantic\nsegmentation of culverts and sewer pipes within imbalanced datasets. The E-FPN\nincorporates architectural innovations like sparsely connected blocks and\ndepth-wise separable convolutions to improve feature extraction and handle\nobject variations. To address dataset imbalance, the model employs strategies\nlike class decomposition and data augmentation. Experimental results on the\nculvert-sewer defects dataset and a benchmark aerial semantic segmentation\ndrone dataset show that the E-FPN outperforms state-of-the-art methods,\nachieving an average Intersection over Union (IoU) improvement of 13.8% and\n27.2%, respectively. Additionally, class decomposition and data augmentation\ntogether boost the model's performance by approximately 6.9% IoU. The proposed\nE-FPN presents a promising solution for enhancing object segmentation in\nchallenging, multi-class real-world datasets, with potential applications\nextending beyond culvert-sewer defect detection.",
      "tldr_zh": "本文提出Enhanced Feature Pyramid Network (E-FPN)，一种针对不平衡数据集的语义分割模型，用于culvert和sewer管道缺陷检测。E-FPN 通过引入sparsely connected blocks和depth-wise separable convolutions来优化特征提取，并采用class decomposition和data augmentation策略来缓解数据不平衡问题。实验结果显示，在culvert-sewer defects dataset上，E-FPN 比现有方法平均Intersection over Union (IoU)提高了13.8%，而在benchmark aerial semantic segmentation drone dataset上提升了27.2%。这些创新为处理多类真实世界数据集的物体分割提供了有效解决方案，具有广泛应用潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.10181v1",
      "published_date": "2024-08-19 17:40:18 UTC",
      "updated_date": "2024-08-19 17:40:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:32:05.992773"
    },
    {
      "arxiv_id": "2408.10178v2",
      "title": "NeuRodin: A Two-stage Framework for High-Fidelity Neural Surface Reconstruction",
      "title_zh": "Neu",
      "authors": [
        "Yifan Wang",
        "Di Huang",
        "Weicai Ye",
        "Guofeng Zhang",
        "Wanli Ouyang",
        "Tong He"
      ],
      "abstract": "Signed Distance Function (SDF)-based volume rendering has demonstrated\nsignificant capabilities in surface reconstruction. Although promising,\nSDF-based methods often fail to capture detailed geometric structures,\nresulting in visible defects. By comparing SDF-based volume rendering to\ndensity-based volume rendering, we identify two main factors within the\nSDF-based approach that degrade surface quality: SDF-to-density representation\nand geometric regularization. These factors introduce challenges that hinder\nthe optimization of the SDF field. To address these issues, we introduce\nNeuRodin, a novel two-stage neural surface reconstruction framework that not\nonly achieves high-fidelity surface reconstruction but also retains the\nflexible optimization characteristics of density-based methods. NeuRodin\nincorporates innovative strategies that facilitate transformation of arbitrary\ntopologies and reduce artifacts associated with density bias. Extensive\nevaluations on the Tanks and Temples and ScanNet++ datasets demonstrate the\nsuperiority of NeuRodin, showing strong reconstruction capabilities for both\nindoor and outdoor environments using solely posed RGB captures. Project\nwebsite: https://open3dvlab.github.io/NeuRodin/",
      "tldr_zh": "该研究发现，基于 Signed Distance Function (SDF) 的体渲染方法在表面重建中虽有效，但因 SDF-to-density 表示和几何正则化问题，常导致几何细节缺失和优化困难。NeuRodin 提出一个创新的两阶段神经表面重建框架，通过结合 density-based 方法的灵活优化特性，实现高保真重建，并引入策略处理任意拓扑变换和减少密度偏差相关的伪像。在 Tanks and Temples 和 ScanNet++ 数据集上的评估显示，NeuRodin 使用仅定位 RGB 捕获即可在室内和室外环境中显著提升重建质量。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.10178v2",
      "published_date": "2024-08-19 17:36:35 UTC",
      "updated_date": "2024-12-22 07:24:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:32:16.137713"
    },
    {
      "arxiv_id": "2408.10175v1",
      "title": "Fairness Under Cover: Evaluating the Impact of Occlusions on Demographic Bias in Facial Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Rafael M. Mamede",
        "Pedro C. Neto",
        "Ana F. Sequeira"
      ],
      "abstract": "This study investigates the effects of occlusions on the fairness of face\nrecognition systems, particularly focusing on demographic biases. Using the\nRacial Faces in the Wild (RFW) dataset and synthetically added realistic\nocclusions, we evaluate their effect on the performance of face recognition\nmodels trained on the BUPT-Balanced and BUPT-GlobalFace datasets. We note\nincreases in the dispersion of FMR, FNMR, and accuracy alongside decreases in\nfairness according to Equilized Odds, Demographic Parity, STD of Accuracy, and\nFairness Discrepancy Rate. Additionally, we utilize a pixel attribution method\nto understand the importance of occlusions in model predictions, proposing a\nnew metric, Face Occlusion Impact Ratio (FOIR), that quantifies the extent to\nwhich occlusions affect model performance across different demographic groups.\nOur results indicate that occlusions exacerbate existing demographic biases,\nwith models placing higher importance on occlusions in an unequal fashion,\nparticularly affecting African individuals more severely.",
      "tldr_zh": "本研究评估了遮挡（occlusions）对人脸识别系统公平性的影响，特别是对人口统计学偏见（demographic biases）的加剧作用。研究者使用 Racial Faces in the Wild (RFW) 数据集添加合成遮挡，并测试基于 BUPT-Balanced 和 BUPT-GlobalFace 数据集训练的模型，结果显示 FMR、FNMR 和准确率（accuracy）的离散度增加，同时公平性指标如 Equilized Odds、Demographic Parity、STD of Accuracy 和 Fairness Discrepancy Rate 均下降。论文引入了新指标 Face Occlusion Impact Ratio (FOIR) 通过像素归因方法（pixel attribution method）量化遮挡对不同群体的影响，并发现遮挡不平等地加剧了偏见，尤其是对非洲裔个体的负面影响更大。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at ECCV Workshop FAILED",
      "pdf_url": "http://arxiv.org/pdf/2408.10175v1",
      "published_date": "2024-08-19 17:34:19 UTC",
      "updated_date": "2024-08-19 17:34:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:32:30.119927"
    },
    {
      "arxiv_id": "2408.10174v2",
      "title": "SMILE: Zero-Shot Sparse Mixture of Low-Rank Experts Construction From Pre-Trained Foundation Models",
      "title_zh": "翻译失败",
      "authors": [
        "Anke Tang",
        "Li Shen",
        "Yong Luo",
        "Shuai Xie",
        "Han Hu",
        "Lefei Zhang",
        "Bo Du",
        "Dacheng Tao"
      ],
      "abstract": "Deep model training on extensive datasets is increasingly becoming\ncost-prohibitive, prompting the widespread adoption of deep model fusion\ntechniques to leverage knowledge from pre-existing models. From simple weight\naveraging to more sophisticated methods like AdaMerging, model fusion\neffectively improves model performance and accelerates the development of new\nmodels. However, potential interference between parameters of individual models\nand the lack of interpretability in the fusion progress remain significant\nchallenges. Existing methods often try to resolve the parameter interference\nissue by evaluating attributes of parameters, such as their magnitude or sign,\nor by parameter pruning. In this study, we begin by examining the fine-tuning\nof linear layers through the lens of subspace analysis and explicitly define\nparameter interference as an optimization problem to shed light on this\nsubject. Subsequently, we introduce an innovative approach to model fusion\ncalled zero-shot Sparse MIxture of Low-rank Experts (SMILE) construction, which\nallows for the upscaling of source models into an MoE model without extra data\nor further training. Our approach relies on the observation that fine-tuning\nmostly keeps the important parts from the pre-training, but it uses less\nsignificant or unused areas to adapt to new tasks. Also, the issue of parameter\ninterference, which is intrinsically intractable in the original parameter\nspace, can be managed by expanding the dimensions. We conduct extensive\nexperiments across diverse scenarios, such as image classification and text\ngeneration tasks, using full fine-tuning and LoRA fine-tuning, and we apply our\nmethod to large language models (CLIP models, Flan-T5 models, and Mistral-7B\nmodels), highlighting the adaptability and scalability of SMILE. Code is\navailable at https://github.com/tanganke/fusion_bench",
      "tldr_zh": "该论文提出了 SMILE 方法，这是一种零样本（Zero-Shot）构建稀疏混合低秩专家（Sparse Mixture of Low-Rank Experts）的技术，用于从预训练基础模型中融合知识，从而避免传统模型融合中的参数干扰问题。SMILE 通过子空间分析将预训练模型的重要部分保留，并利用未使用区域适应新任务，实现模型扩展而无需额外数据或训练。实验结果显示，该方法在图像分类和文本生成任务上表现出色，并成功应用于 CLIP、Flan-T5 和 Mistral-7B 等大型语言模型，证明了其适应性和可扩展性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Code is available at https://github.com/tanganke/fusion_bench",
      "pdf_url": "http://arxiv.org/pdf/2408.10174v2",
      "published_date": "2024-08-19 17:32:15 UTC",
      "updated_date": "2024-08-26 07:34:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:32:44.156834"
    },
    {
      "arxiv_id": "2408.10161v2",
      "title": "NeuFlow v2: High-Efficiency Optical Flow Estimation on Edge Devices",
      "title_zh": "翻译失败",
      "authors": [
        "Zhiyong Zhang",
        "Aniket Gupta",
        "Huaizu Jiang",
        "Hanumant Singh"
      ],
      "abstract": "Real-time high-accuracy optical flow estimation is crucial for various\nreal-world applications. While recent learning-based optical flow methods have\nachieved high accuracy, they often come with significant computational costs.\nIn this paper, we propose a highly efficient optical flow method that balances\nhigh accuracy with reduced computational demands. Building upon NeuFlow v1, we\nintroduce new components including a much more light-weight backbone and a fast\nrefinement module. Both these modules help in keeping the computational demands\nlight while providing close to state of the art accuracy. Compares to other\nstate of the art methods, our model achieves a 10x-70x speedup while\nmaintaining comparable performance on both synthetic and real-world data. It is\ncapable of running at over 20 FPS on 512x384 resolution images on a Jetson Orin\nNano. The full training and evaluation code is available at\nhttps://github.com/neufieldrobotics/NeuFlow_v2.",
      "tldr_zh": "本文提出 NeuFlow v2，一种高效的光流估计方法，旨在平衡高准确性和低计算需求，以适应边缘设备应用。基于 NeuFlow v1，该方法引入更轻量级的主干网络和快速精炼模块，显著减少计算开销的同时保持接近最先进水平。实验结果显示，NeuFlow v2 比其他最先进方法实现 10x-70x 的加速，并在 Jetson Orin Nano 上处理 512x384 分辨率图像时超过 20 FPS，同时在合成和真实数据上保持可比性能。开源代码可从 GitHub 获取。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.10161v2",
      "published_date": "2024-08-19 17:13:34 UTC",
      "updated_date": "2024-08-21 23:23:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:32:56.324088"
    },
    {
      "arxiv_id": "2408.10159v4",
      "title": "Customizing Language Models with Instance-wise LoRA for Sequential Recommendation",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaoyu Kong",
        "Jiancan Wu",
        "An Zhang",
        "Leheng Sheng",
        "Hui Lin",
        "Xiang Wang",
        "Xiangnan He"
      ],
      "abstract": "Sequential recommendation systems predict the next interaction item based on\nusers' past interactions, aligning recommendations with individual preferences.\nLeveraging the strengths of Large Language Models (LLMs) in knowledge\ncomprehension and reasoning, recent approaches are eager to apply LLMs to\nsequential recommendation. A common paradigm is converting user behavior\nsequences into instruction data, and fine-tuning the LLM with\nparameter-efficient fine-tuning (PEFT) methods like Low-Rank Adaption (LoRA).\nHowever, the uniform application of LoRA across diverse user behaviors is\ninsufficient to capture individual variability, resulting in negative transfer\nbetween disparate sequences. To address these challenges, we propose\nInstance-wise LoRA (iLoRA). We innovatively treat the sequential recommendation\ntask as a form of multi-task learning, integrating LoRA with the Mixture of\nExperts (MoE) framework. This approach encourages different experts to capture\nvarious aspects of user behavior. Additionally, we introduce a sequence\nrepresentation guided gate function that generates customized expert\nparticipation weights for each user sequence, which allows dynamic parameter\nadjustment for instance-wise recommendations. In sequential recommendation,\niLoRA achieves an average relative improvement of 11.4\\% over basic LoRA in the\nhit ratio metric, with less than a 1\\% relative increase in trainable\nparameters. Extensive experiments on three benchmark datasets demonstrate the\neffectiveness of iLoRA, highlighting its superior performance compared to\nexisting methods in mitigating negative transfer and improving recommendation\naccuracy. Our data and code are available at\nhttps://github.com/AkaliKong/iLoRA.",
      "tldr_zh": "该研究针对顺序推荐（Sequential Recommendation）系统，提出了一种名为 Instance-wise LoRA (iLoRA) 的方法，以解决统一应用 Low-Rank Adaption (LoRA) 在处理用户行为多样性时导致的负面转移问题。iLoRA 将推荐任务视为多任务学习，结合 Mixture of Experts (MoE) 框架，让不同专家捕捉用户行为的各种方面，并引入序列表示引导的门控函数，为每个用户序列动态调整专家参与权重，实现个性化参数微调。实验结果显示，iLoRA 在三个基准数据集上比基本 LoRA 的命中率 (hit ratio) 平均提升 11.4%，同时训练参数仅增加不到 1%，有效提高了推荐准确性和缓解了负面转移。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "NeurIPS 2024 poster",
      "pdf_url": "http://arxiv.org/pdf/2408.10159v4",
      "published_date": "2024-08-19 17:09:32 UTC",
      "updated_date": "2025-01-21 03:40:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:33:08.392883"
    },
    {
      "arxiv_id": "2408.10292v1",
      "title": "Leveraging Superfluous Information in Contrastive Representation Learning",
      "title_zh": "在对比表示学习中利用多余信息",
      "authors": [
        "Xuechu Yu"
      ],
      "abstract": "Contrastive representation learning, which aims to learnthe shared\ninformation between different views of unlabeled data by maximizing the mutual\ninformation between them, has shown its powerful competence in self-supervised\nlearning for downstream tasks. However, recent works have demonstrated that\nmore estimated mutual information does not guarantee better performance in\ndifferent downstream tasks. Such works inspire us to conjecture that the\nlearned representations not only maintain task-relevant information from\nunlabeled data but also carry task-irrelevant information which is superfluous\nfor downstream tasks, thus leading to performance degeneration. In this paper\nwe show that superfluous information does exist during the conventional\ncontrastive learning framework, and further design a new objective, namely\nSuperInfo, to learn robust representations by a linear combination of both\npredictive and superfluous information. Besides, we notice that it is feasible\nto tune the coefficients of introduced losses to discard task-irrelevant\ninformation, while keeping partial non-shared task-relevant information\naccording to our SuperInfo loss.We demonstrate that learning with our loss can\noften outperform the traditional contrastive learning approaches on image\nclassification, object detection and instance segmentation tasks with\nsignificant improvements.",
      "tldr_zh": "这篇论文探讨了对比学习（Contrastive representation learning）中存在的冗余信息问题，即学习到的表示不仅包含任务相关信息，还包括任务无关的冗余信息，导致下游任务性能下降。作者提出了一种新目标函数SuperInfo，通过线性组合预测信息和冗余信息来学习更鲁棒的表示，并通过调整损失函数系数来过滤掉任务无关信息，同时保留部分非共享的任务相关信息。实验结果显示，该方法在图像分类、目标检测和实例分割任务上显著优于传统对比学习方法，取得了显著的性能提升。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.10292v1",
      "published_date": "2024-08-19 16:21:08 UTC",
      "updated_date": "2024-08-19 16:21:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:33:18.656256"
    },
    {
      "arxiv_id": "2408.10130v1",
      "title": "Rhyme-aware Chinese lyric generator based on GPT",
      "title_zh": "翻译失败",
      "authors": [
        "Yixiao Yuan",
        "Yangchen Huang",
        "Yu Ma",
        "Xinjin Li",
        "Zhenglin Li",
        "Yiming Shi",
        "Huapeng Zhou"
      ],
      "abstract": "Neural language representation models such as GPT, pre-trained on large-scale\ncorpora, can effectively capture rich semantic patterns from plain text and be\nfine-tuned to consistently improve natural language generation performance.\nHowever, existing pre-trained language models used to generate lyrics rarely\nconsider rhyme information, which is crucial in lyrics. Using a pre-trained\nmodel directly results in poor performance. To enhance the rhyming quality of\ngenerated lyrics, we incorporate integrated rhyme information into our model,\nthereby improving lyric generation performance.",
      "tldr_zh": "本研究针对现有基于 GPT 等神经语言表示模型的歌词生成问题，指出这些模型在处理中文歌词时忽略了押韵信息，导致生成性能较差。研究提出了一种 Rhyme-aware 生成器，通过将押韵信息整合到预训练模型中，提升了歌词的韵律和整体质量。该方法为中文歌词生成提供了更有效的解决方案，显著改善了生成结果的自然性和艺术性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.10130v1",
      "published_date": "2024-08-19 16:17:20 UTC",
      "updated_date": "2024-08-19 16:17:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:33:31.385076"
    },
    {
      "arxiv_id": "2408.10128v2",
      "title": "Advancing Voice Cloning for Nepali: Leveraging Transfer Learning in a Low-Resource Language",
      "title_zh": "翻译失败",
      "authors": [
        "Manjil Karki",
        "Pratik Shakya",
        "Sandesh Acharya",
        "Ravi Pandit",
        "Dinesh Gothe"
      ],
      "abstract": "Voice cloning is a prominent feature in personalized speech interfaces. A\nneural vocal cloning system can mimic someone's voice using just a few audio\nsamples. Both speaker encoding and speaker adaptation are topics of research in\nthe field of voice cloning. Speaker adaptation relies on fine-tuning a\nmulti-speaker generative model, which involves training a separate model to\ninfer a new speaker embedding used for speaker encoding. Both methods can\nachieve excellent performance, even with a small number of cloning audios, in\nterms of the speech's naturalness and similarity to the original speaker.\nSpeaker encoding approaches are more appropriate for low-resource deployment\nsince they require significantly less memory and have a faster cloning time\nthan speaker adaption, which can offer slightly greater naturalness and\nsimilarity. The main goal is to create a vocal cloning system that produces\naudio output with a Nepali accent or that sounds like Nepali. For the further\nadvancement of TTS, the idea of transfer learning was effectively used to\naddress several issues that were encountered in the development of this system,\nincluding the poor audio quality and the lack of available data.",
      "tldr_zh": "本文提出了一种针对低资源语言尼泊尔语的语音克隆（voice cloning）系统，旨在生成带有尼泊尔口音的音频输出，以提升个性化语音接口的性能。研究比较了说话者编码（speaker encoding）和说话者适配（speaker adaptation）方法，发现说话者编码更适合低资源部署，因为它内存占用少且克隆时间更快，同时保持较高的语音自然度和相似度。为了解决数据不足和音频质量差的问题，作者成功应用了迁移学习（transfer learning），从而推进了TTS（Text-to-Speech）技术的进步。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "eess.AS",
        "91F20",
        "I.2.7"
      ],
      "primary_category": "cs.SD",
      "comment": "6 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.10128v2",
      "published_date": "2024-08-19 16:15:09 UTC",
      "updated_date": "2024-08-23 16:15:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:33:43.663060"
    },
    {
      "arxiv_id": "2408.10126v2",
      "title": "Learning Brave Assumption-Based Argumentation Frameworks via ASP",
      "title_zh": "翻译失败",
      "authors": [
        "Emanuele De Angelis",
        "Maurizio Proietti",
        "Francesca Toni"
      ],
      "abstract": "Assumption-based Argumentation (ABA) is advocated as a unifying formalism for\nvarious forms of non-monotonic reasoning, including logic programming. It\nallows capturing defeasible knowledge, subject to argumentative debate. While,\nin much existing work, ABA frameworks are given up-front, in this paper we\nfocus on the problem of automating their learning from background knowledge and\npositive/negative examples. Unlike prior work, we newly frame the problem in\nterms of brave reasoning under stable extensions for ABA. We present a novel\nalgorithm based on transformation rules (such as Rote Learning, Folding,\nAssumption Introduction and Fact Subsumption) and an implementation thereof\nthat makes use of Answer Set Programming. Finally, we compare our technique to\nstate-of-the-art ILP systems that learn defeasible knowledge.",
      "tldr_zh": "该论文探讨了通过Answer Set Programming (ASP)学习Assumption-Based Argumentation (ABA)框架的方法，旨在从背景知识和正/负例子中自动推断ABA框架，以处理非单调推理中的可辩驳知识。作者首次将学习问题框架化为ABA的稳定扩展下的brave reasoning，并提出了一种基于转换规则（如Rote Learning、Folding、Assumption Introduction和Fact Subsumption）的算法。实验实现利用ASP进行计算，并与最先进的Inductive Logic Programming (ILP)系统进行比较，展示了该方法的有效性。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "Extended version of the paper published in: Proceedings 27th European\n  Conference on Artificial Intelligence, Frontiers in Artificial Intelligence\n  and Applications, Volume 392: ECAI 2024, pp. 3445 - 3452. DOI:\n  10.3233/FAIA240896",
      "pdf_url": "http://arxiv.org/pdf/2408.10126v2",
      "published_date": "2024-08-19 16:13:35 UTC",
      "updated_date": "2024-11-08 11:30:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:33:54.454285"
    },
    {
      "arxiv_id": "2408.10124v1",
      "title": "Molecular Graph Representation Learning Integrating Large Language Models with Domain-specific Small Models",
      "title_zh": "分子图表示学习：整合大语言模型与领域特定小模型",
      "authors": [
        "Tianyu Zhang",
        "Yuxiang Ren",
        "Chengbin Hou",
        "Hairong Lv",
        "Xuegong Zhang"
      ],
      "abstract": "Molecular property prediction is a crucial foundation for drug discovery. In\nrecent years, pre-trained deep learning models have been widely applied to this\ntask. Some approaches that incorporate prior biological domain knowledge into\nthe pre-training framework have achieved impressive results. However, these\nmethods heavily rely on biochemical experts, and retrieving and summarizing\nvast amounts of domain knowledge literature is both time-consuming and\nexpensive. Large Language Models (LLMs) have demonstrated remarkable\nperformance in understanding and efficiently providing general knowledge.\nNevertheless, they occasionally exhibit hallucinations and lack precision in\ngenerating domain-specific knowledge. Conversely, Domain-specific Small Models\n(DSMs) possess rich domain knowledge and can accurately calculate molecular\ndomain-related metrics. However, due to their limited model size and singular\nfunctionality, they lack the breadth of knowledge necessary for comprehensive\nrepresentation learning. To leverage the advantages of both approaches in\nmolecular property prediction, we propose a novel Molecular Graph\nrepresentation learning framework that integrates Large language models and\nDomain-specific small models (MolGraph-LarDo). Technically, we design a\ntwo-stage prompt strategy where DSMs are introduced to calibrate the knowledge\nprovided by LLMs, enhancing the accuracy of domain-specific information and\nthus enabling LLMs to generate more precise textual descriptions for molecular\nsamples. Subsequently, we employ a multi-modal alignment method to coordinate\nvarious modalities, including molecular graphs and their corresponding\ndescriptive texts, to guide the pre-training of molecular representations.\nExtensive experiments demonstrate the effectiveness of the proposed method.",
      "tldr_zh": "该论文提出MolGraph-LarDo框架，旨在通过整合Large Language Models (LLMs)和Domain-specific Small Models (DSMs)来提升分子属性预测的准确性，以加速药物发现过程。框架采用二阶段提示策略，让DSMs校准LLMs提供的知识，从而生成更精确的分子文本描述，并通过多模态对齐方法协调分子图和描述文本以指导分子表示的预训练。实验结果显示，该方法在分子属性预测任务中表现出色，证明了其有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IR",
        "physics.chem-ph",
        "q-bio.BM"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.10124v1",
      "published_date": "2024-08-19 16:11:59 UTC",
      "updated_date": "2024-08-19 16:11:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:34:08.570748"
    },
    {
      "arxiv_id": "2408.10120v1",
      "title": "Geometry Informed Tokenization of Molecules for Language Model Generation",
      "title_zh": "基于几何信息的分子标记化，用于语言模型生成",
      "authors": [
        "Xiner Li",
        "Limei Wang",
        "Youzhi Luo",
        "Carl Edwards",
        "Shurui Gui",
        "Yuchao Lin",
        "Heng Ji",
        "Shuiwang Ji"
      ],
      "abstract": "We consider molecule generation in 3D space using language models (LMs),\nwhich requires discrete tokenization of 3D molecular geometries. Although\ntokenization of molecular graphs exists, that for 3D geometries is largely\nunexplored. Here, we attempt to bridge this gap by proposing the Geo2Seq, which\nconverts molecular geometries into $SE(3)$-invariant 1D discrete sequences.\nGeo2Seq consists of canonical labeling and invariant spherical representation\nsteps, which together maintain geometric and atomic fidelity in a format\nconducive to LMs. Our experiments show that, when coupled with Geo2Seq, various\nLMs excel in molecular geometry generation, especially in controlled generation\ntasks.",
      "tldr_zh": "该论文探讨了使用语言模型（LMs）在3D空间生成分子的过程，强调了将3D分子几何结构离散化成标记的重要性。作者提出Geo2Seq方法，将分子几何转换为SE(3)-invariant的1D离散序列，通过canonical labeling和invariant spherical representation步骤，确保几何和原子保真度，并使其适合LMs处理。实验结果显示，结合Geo2Seq的各种LMs在分子几何生成任务中表现出色，尤其在控制生成任务上。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.10120v1",
      "published_date": "2024-08-19 16:09:59 UTC",
      "updated_date": "2024-08-19 16:09:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:34:18.451609"
    },
    {
      "arxiv_id": "2408.10119v1",
      "title": "Factorized-Dreamer: Training A High-Quality Video Generator with Limited and Low-Quality Data",
      "title_zh": "Factorized-Dreamer：使用有限且低质量数据训练高质量视频生成器",
      "authors": [
        "Tao Yang",
        "Yangming Shi",
        "Yunwen Huang",
        "Feng Chen",
        "Yin Zheng",
        "Lei Zhang"
      ],
      "abstract": "Text-to-video (T2V) generation has gained significant attention due to its\nwide applications to video generation, editing, enhancement and translation,\n\\etc. However, high-quality (HQ) video synthesis is extremely challenging\nbecause of the diverse and complex motions existed in real world. Most existing\nworks struggle to address this problem by collecting large-scale HQ videos,\nwhich are inaccessible to the community. In this work, we show that publicly\navailable limited and low-quality (LQ) data are sufficient to train a HQ video\ngenerator without recaptioning or finetuning. We factorize the whole T2V\ngeneration process into two steps: generating an image conditioned on a highly\ndescriptive caption, and synthesizing the video conditioned on the generated\nimage and a concise caption of motion details. Specifically, we present\n\\emph{Factorized-Dreamer}, a factorized spatiotemporal framework with several\ncritical designs for T2V generation, including an adapter to combine text and\nimage embeddings, a pixel-aware cross attention module to capture pixel-level\nimage information, a T5 text encoder to better understand motion description,\nand a PredictNet to supervise optical flows. We further present a noise\nschedule, which plays a key role in ensuring the quality and stability of video\ngeneration. Our model lowers the requirements in detailed captions and HQ\nvideos, and can be directly trained on limited LQ datasets with noisy and brief\ncaptions such as WebVid-10M, largely alleviating the cost to collect\nlarge-scale HQ video-text pairs. Extensive experiments in a variety of T2V and\nimage-to-video generation tasks demonstrate the effectiveness of our proposed\nFactorized-Dreamer. Our source codes are available at\n\\url{https://github.com/yangxy/Factorized-Dreamer/}.",
      "tldr_zh": "本研究提出了一种名为 Factorized-Dreamer 的框架，用于在有限和低质量 (LQ) 数据上训练高质量视频生成器，解决了文本到视频 (T2V) 生成中数据依赖性的问题，而无需重新标注或微调。框架将 T2V 过程分解为两个步骤：首先基于详细描述生成图像，然后结合图像和简要动作描述合成视频，关键设计包括 adapter 结合文本和图像嵌入、pixel-aware cross attention 模块捕捉像素级信息、T5 text encoder 理解动作描述，以及 PredictNet 监督光流。作者还引入噪声调度以提升生成质量和稳定性，并在 WebVid-10M 等数据集上进行训练，显著降低了收集大规模高质量视频的成本；实验结果显示，该模型在各种 T2V 和图像到视频任务中表现出色，证明了其有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.10119v1",
      "published_date": "2024-08-19 16:08:00 UTC",
      "updated_date": "2024-08-19 16:08:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:34:33.229747"
    },
    {
      "arxiv_id": "2408.10113v1",
      "title": "Enhancing Reinforcement Learning Through Guided Search",
      "title_zh": "通过引导搜索增强强化学习",
      "authors": [
        "Jérôme Arjonilla",
        "Abdallah Saffidine",
        "Tristan Cazenave"
      ],
      "abstract": "With the aim of improving performance in Markov Decision Problem in an\nOff-Policy setting, we suggest taking inspiration from what is done in Offline\nReinforcement Learning (RL). In Offline RL, it is a common practice during\npolicy learning to maintain proximity to a reference policy to mitigate\nuncertainty, reduce potential policy errors, and help improve performance. We\nfind ourselves in a different setting, yet it raises questions about whether a\nsimilar concept can be applied to enhance performance ie, whether it is\npossible to find a guiding policy capable of contributing to performance\nimprovement, and how to incorporate it into our RL agent. Our attention is\nparticularly focused on algorithms based on Monte Carlo Tree Search (MCTS) as a\nguide.MCTS renowned for its state-of-the-art capabilities across various\ndomains, catches our interest due to its ability to converge to equilibrium in\nsingle-player and two-player contexts. By harnessing the power of MCTS as a\nguide for our RL agent, we observed a significant performance improvement,\nsurpassing the outcomes achieved by utilizing each method in isolation. Our\nexperiments were carried out on the Atari 100k benchmark.",
      "tldr_zh": "该论文提出了一种通过引导搜索增强强化学习（Reinforcement Learning）的方法，借鉴离线强化学习（Offline RL）的理念，使用参考策略来减少不确定性和错误，从而提升Off-Policy设置下的性能。具体而言，作者将Monte Carlo Tree Search (MCTS)作为指导策略整合到RL代理中，利用MCTS的收敛能力来优化决策过程。在Atari 100k基准上的实验结果显示，这种结合方法显著提高了性能，超过了单独使用每种方法的表现。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted Paper at ECAI 2024; Extended Version",
      "pdf_url": "http://arxiv.org/pdf/2408.10113v1",
      "published_date": "2024-08-19 16:00:02 UTC",
      "updated_date": "2024-08-19 16:00:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:34:46.557849"
    },
    {
      "arxiv_id": "2408.10111v2",
      "title": "PLUTUS: A Well Pre-trained Large Unified Transformer can Unveil Financial Time Series Regularities",
      "title_zh": "翻译失败",
      "authors": [
        "Yuanjian Xu",
        "Anxian Liu",
        "Jianing Hao",
        "Zhenzhuo Li",
        "Shichang Meng",
        "Guang Zhang"
      ],
      "abstract": "Financial time series modeling is crucial for understanding and predicting\nmarket behaviors but faces challenges such as non-linearity, non-stationarity,\nand high noise levels. Traditional models struggle to capture complex patterns\ndue to these issues, compounded by limitations in computational resources and\nmodel capacity. Inspired by the success of large language models in NLP, we\nintroduce $\\textbf{PLUTUS}$, a $\\textbf{P}$re-trained $\\textbf{L}$arge\n$\\textbf{U}$nified $\\textbf{T}$ransformer-based model that $\\textbf{U}$nveils\nregularities in financial time $\\textbf{S}$eries. PLUTUS uses an invertible\nembedding module with contrastive learning and autoencoder techniques to create\nan approximate one-to-one mapping between raw data and patch embeddings.\nTimeFormer, an attention based architecture, forms the core of PLUTUS,\neffectively modeling high-noise time series. We incorporate a novel attention\nmechanisms to capture features across both variable and temporal dimensions.\nPLUTUS is pre-trained on an unprecedented dataset of 100 billion observations,\ndesigned to thrive in noisy financial environments. To our knowledge, PLUTUS is\nthe first open-source, large-scale, pre-trained financial time series model\nwith over one billion parameters. It achieves state-of-the-art performance in\nvarious tasks, demonstrating strong transferability and establishing a robust\nfoundational model for finance. Our research provides technical guidance for\npre-training financial time series data, setting a new standard in the field.",
      "tldr_zh": "该研究针对金融时间序列的非线性、非平稳和高噪声挑战，提出 PLUTUS，一种预训练的大型统一 Transformer 模型，用于揭示隐藏的序列规律。PLUTUS 采用可逆嵌入模块（invertible embedding module）结合对比学习（contrastive learning）和自编码器（autoencoder）技术，实现原始数据与 patch embeddings 的近似一对一映射，并以 TimeFormer 架构为核心，引入新型注意力机制捕捉变量和时间维度的特征。该模型在 100 亿观察值的数据集上预训练，是首个开源的、参数超过 10 亿的金融时间序列预训练模型，在各种任务中实现最先进性能，并展示出强大的转移能力。作为金融领域的全新基础模型，PLUTUS 为预训练技术提供了重要指导，树立了行业新标准。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.10111v2",
      "published_date": "2024-08-19 15:59:46 UTC",
      "updated_date": "2024-08-20 02:59:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:34:59.072683"
    },
    {
      "arxiv_id": "2408.10108v1",
      "title": "Envisioning Possibilities and Challenges of AI for Personalized Cancer Care",
      "title_zh": "展望 AI 在个性化癌症护理中的可能性与挑战",
      "authors": [
        "Elaine Kong",
        "Kuo-Ting",
        "Huang",
        "Aakash Gautam"
      ],
      "abstract": "The use of Artificial Intelligence (AI) in healthcare, including in caring\nfor cancer survivors, has gained significant interest. However, gaps remain in\nour understanding of how such AI systems can provide care, especially for\nethnic and racial minority groups who continue to face care disparities.\nThrough interviews with six cancer survivors, we identify critical gaps in\ncurrent healthcare systems such as a lack of personalized care and insufficient\ncultural and linguistic accommodation. AI, when applied to care, was seen as a\nway to address these issues by enabling real-time, culturally aligned, and\nlinguistically appropriate interactions. We also uncovered concerns about the\nimplications of AI-driven personalization, such as data privacy, loss of human\ntouch in caregiving, and the risk of echo chambers that limit exposure to\ndiverse information. We conclude by discussing the trade-offs between\nAI-enhanced personalization and the need for structural changes in healthcare\nthat go beyond technological solutions, leading us to argue that we should\nbegin by asking, ``Why personalization?''",
      "tldr_zh": "这篇论文通过采访六名癌症幸存者，探讨了AI在个性化癌症护理中的潜在益处和挑战，特别是针对种族和民族少数群体的护理差距。研究发现，AI可以提供实时、文化和语言适配的互动，从而缓解现有医疗系统的个性化不足和文化适应问题。然而，作者也强调了潜在风险，包括数据隐私问题、失去人情关怀以及回音室效应导致的信息多样性缺失。最终，论文呼吁在推进AI应用前，权衡技术解决方案与结构性变革，并从“为什么需要个性化？”这一根本问题入手。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "7 pages, 1 table, short paper at CSCW 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.10108v1",
      "published_date": "2024-08-19 15:55:46 UTC",
      "updated_date": "2024-08-19 15:55:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:35:10.595698"
    },
    {
      "arxiv_id": "2408.10107v1",
      "title": "Perturb-and-Compare Approach for Detecting Out-of-Distribution Samples in Constrained Access Environments",
      "title_zh": "基于扰动并比较的方法，用于在受限访问环境中检测分布外样本",
      "authors": [
        "Heeyoung Lee",
        "Hoyoon Byun",
        "Changdae Oh",
        "JinYeong Bak",
        "Kyungwoo Song"
      ],
      "abstract": "Accessing machine learning models through remote APIs has been gaining\nprevalence following the recent trend of scaling up model parameters for\nincreased performance. Even though these models exhibit remarkable ability,\ndetecting out-of-distribution (OOD) samples remains a crucial safety concern\nfor end users as these samples may induce unreliable outputs from the model. In\nthis work, we propose an OOD detection framework, MixDiff, that is applicable\neven when the model's parameters or its activations are not accessible to the\nend user. To bypass the access restriction, MixDiff applies an identical\ninput-level perturbation to a given target sample and a similar in-distribution\n(ID) sample, then compares the relative difference in the model outputs of\nthese two samples. MixDiff is model-agnostic and compatible with existing\noutput-based OOD detection methods. We provide theoretical analysis to\nillustrate MixDiff's effectiveness in discerning OOD samples that induce\noverconfident outputs from the model and empirically demonstrate that MixDiff\nconsistently enhances the OOD detection performance on various datasets in\nvision and text domains.",
      "tldr_zh": "这篇论文提出了一种名为MixDiff的框架，用于在模型参数不可访问的环境中检测Out-of-Distribution (OOD)样本，以解决远程API访问模型可能导致不可靠输出的安全问题。MixDiff方法通过对目标样本和一个相似的In-Distribution (ID)样本施加相同的输入级扰动，然后比较模型输出的相对差异，来实现模型无关的OOD检测，并兼容现有基于输出的检测技术。理论分析和实验验证显示，MixDiff能有效识别引起模型过度自信的OOD样本，并在视觉和文本领域的多种数据集上显著提升检测性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to European Conference on Artificial Intelligence (ECAI)\n  2024",
      "pdf_url": "http://arxiv.org/pdf/2408.10107v1",
      "published_date": "2024-08-19 15:51:31 UTC",
      "updated_date": "2024-08-19 15:51:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:35:22.682919"
    },
    {
      "arxiv_id": "2408.10096v2",
      "title": "Convert and Speak: Zero-shot Accent Conversion with Minimum Supervision",
      "title_zh": "转换并说话：零样本口音转换的最小监督",
      "authors": [
        "Zhijun Jia",
        "Huaying Xue",
        "Xiulian Peng",
        "Yan Lu"
      ],
      "abstract": "Low resource of parallel data is the key challenge of accent conversion(AC)\nproblem in which both the pronunciation units and prosody pattern need to be\nconverted. We propose a two-stage generative framework \"convert-and-speak\" in\nwhich the conversion is only operated on the semantic token level and the\nspeech is synthesized conditioned on the converted semantic token with a speech\ngenerative model in target accent domain. The decoupling design enables the\n\"speaking\" module to use massive amount of target accent speech and relieves\nthe parallel data required for the \"conversion\" module. Conversion with the\nbridge of semantic token also relieves the requirement for the data with text\ntranscriptions and unlocks the usage of language pre-training technology to\nfurther efficiently reduce the need of parallel accent speech data. To reduce\nthe complexity and latency of \"speaking\", a single-stage AR generative model is\ndesigned to achieve good quality as well as lower computation cost. Experiments\non Indian-English to general American-English conversion show that the proposed\nframework achieves state-of-the-art performance in accent similarity, speech\nquality, and speaker maintenance with only 15 minutes of weakly parallel data\nwhich is not constrained to the same speaker. Extensive experimentation with\ndiverse accent types suggests that this framework possesses a high degree of\nadaptability, making it readily scalable to accommodate other accents with\nlow-resource data. Audio samples are available at\nhttps://www.microsoft.com/en-us/research/project/convert-and-speak-zero-shot-accent-conversion-with-minimumsupervision/.",
      "tldr_zh": "本研究提出“Convert and Speak”框架，实现zero-shot口音转换（accent conversion），仅需最小监督，通过两阶段设计先在语义 token 级别转换发音和韵律模式，然后基于转换后的语义 token 使用目标口音语音合成模型生成语音。该框架的解耦设计减少了对平行数据的依赖，并利用语言预训练技术进一步降低资源需求，同时采用单阶段AR生成模型来优化复杂性和延迟。实验结果显示，在印度英语到美国英语的转换中，仅用15分钟弱平行数据，该框架就达到了最先进的口音相似度、语音质量和说话者保持性能，并展示出高适应性，可扩展到其他低资源口音。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "9 pages, ACM MM2024(accepted)",
      "pdf_url": "http://arxiv.org/pdf/2408.10096v2",
      "published_date": "2024-08-19 15:33:59 UTC",
      "updated_date": "2024-08-22 09:56:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:35:36.203922"
    },
    {
      "arxiv_id": "2408.10086v1",
      "title": "ARMADA: Attribute-Based Multimodal Data Augmentation",
      "title_zh": "ARMADA：基于属性的多模态数据增强",
      "authors": [
        "Xiaomeng Jin",
        "Jeonghwan Kim",
        "Yu Zhou",
        "Kuan-Hao Huang",
        "Te-Lin Wu",
        "Nanyun Peng",
        "Heng Ji"
      ],
      "abstract": "In Multimodal Language Models (MLMs), the cost of manually annotating\nhigh-quality image-text pair data for fine-tuning and alignment is extremely\nhigh. While existing multimodal data augmentation frameworks propose ways to\naugment image-text pairs, they either suffer from semantic inconsistency\nbetween texts and images, or generate unrealistic images, causing knowledge gap\nwith real world examples. To address these issues, we propose Attribute-based\nMultimodal Data Augmentation (ARMADA), a novel multimodal data augmentation\nmethod via knowledge-guided manipulation of visual attributes of the mentioned\nentities. Specifically, we extract entities and their visual attributes from\nthe original text data, then search for alternative values for the visual\nattributes under the guidance of knowledge bases (KBs) and large language\nmodels (LLMs). We then utilize an image-editing model to edit the images with\nthe extracted attributes. ARMADA is a novel multimodal data generation\nframework that: (i) extracts knowledge-grounded attributes from symbolic KBs\nfor semantically consistent yet distinctive image-text pair generation, (ii)\ngenerates visually similar images of disparate categories using neighboring\nentities in the KB hierarchy, and (iii) uses the commonsense knowledge of LLMs\nto modulate auxiliary visual attributes such as backgrounds for more robust\nrepresentation of original entities. Our empirical results over four downstream\ntasks demonstrate the efficacy of our framework to produce high-quality data\nand enhance the model performance. This also highlights the need to leverage\nexternal knowledge proxies for enhanced interpretability and real-world\ngrounding.",
      "tldr_zh": "该研究针对多模态语言模型（MLMs）中图像-文本对数据标注的高成本问题，提出了一种基于属性的多模态数据增强框架ARMADA。ARMADA通过从原始文本提取实体及其视觉属性，并利用知识库（KBs）和大型语言模型（LLMs）指导下搜索备选属性值，然后使用图像编辑模型对图像进行修改，以生成语义一致且真实的增强数据。该框架的关键创新包括：(i) 从KBs提取知识引导属性，确保图像-文本对的语义一致性和独特性，(ii) 通过KB层次中的相邻实体生成视觉相似的不同类别图像，以及(iii) 利用LLMs的常识知识调整辅助属性如背景，提高数据的鲁棒性。实验结果显示，ARMADA在四个下游任务上显著提升了模型性能，并强调了利用外部知识代理来增强可解释性和真实世界关联的必要性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.10086v1",
      "published_date": "2024-08-19 15:27:25 UTC",
      "updated_date": "2024-08-19 15:27:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:35:47.409089"
    },
    {
      "arxiv_id": "2408.10077v1",
      "title": "No Screening is More Efficient with Multiple Objects",
      "title_zh": "翻译失败",
      "authors": [
        "Shunya Noda",
        "Genta Okada"
      ],
      "abstract": "We study efficient mechanism design for allocating multiple heterogeneous\nobjects. We aim to maximize the residual surplus, the total value generated\nfrom an allocation minus the costs for screening agents' values. We discover a\nrobust trend indicating that no-screening mechanisms such as serial\ndictatorship with exogenous priority order tend to perform better as the\nvariety of goods increases. We analyze the underlying reasons by characterizing\nefficient mechanisms in a stylized environment. We also apply an automated\nmechanism design approach to numerically derive efficient mechanisms and\nvalidate the trend in general environments. Building on this implication, we\npropose the register-invite-book system (RIB) as an efficient system for\nscheduling vaccination against pandemic diseases.",
      "tldr_zh": "这篇论文研究了分配多个异质对象的机制设计，目标是最大化剩余盈余（总价值减去筛查代理值成本）。作者发现，随着商品多样性的增加，不筛查机制如序列独裁（serial dictatorship）带有外生优先顺序的表现更优，因为它能更高效地处理复杂分配。论文通过分析简化环境表征高效机制，并采用自动化机制设计方法在一般环境中进行数值验证。最终，基于这一趋势，提出 register-invite-book system (RIB) 作为疫情疫苗接种调度的实用系统。",
      "categories": [
        "econ.TH",
        "cs.AI",
        "cs.GT",
        "cs.LG"
      ],
      "primary_category": "econ.TH",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.10077v1",
      "published_date": "2024-08-19 15:20:42 UTC",
      "updated_date": "2024-08-19 15:20:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:35:58.762128"
    },
    {
      "arxiv_id": "2408.10075v1",
      "title": "Personalizing Reinforcement Learning from Human Feedback with Variational Preference Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Sriyash Poddar",
        "Yanming Wan",
        "Hamish Ivison",
        "Abhishek Gupta",
        "Natasha Jaques"
      ],
      "abstract": "Reinforcement Learning from Human Feedback (RLHF) is a powerful paradigm for\naligning foundation models to human values and preferences. However, current\nRLHF techniques cannot account for the naturally occurring differences in\nindividual human preferences across a diverse population. When these\ndifferences arise, traditional RLHF frameworks simply average over them,\nleading to inaccurate rewards and poor performance for individual subgroups. To\naddress the need for pluralistic alignment, we develop a class of multimodal\nRLHF methods. Our proposed techniques are based on a latent variable\nformulation - inferring a novel user-specific latent and learning reward models\nand policies conditioned on this latent without additional user-specific data.\nWhile conceptually simple, we show that in practice, this reward modeling\nrequires careful algorithmic considerations around model architecture and\nreward scaling. To empirically validate our proposed technique, we first show\nthat it can provide a way to combat underspecification in simulated control\nproblems, inferring and optimizing user-specific reward functions. Next, we\nconduct experiments on pluralistic language datasets representing diverse user\npreferences and demonstrate improved reward function accuracy. We additionally\nshow the benefits of this probabilistic framework in terms of measuring\nuncertainty, and actively learning user preferences. This work enables learning\nfrom diverse populations of users with divergent preferences, an important\nchallenge that naturally occurs in problems from robot learning to foundation\nmodel alignment.",
      "tldr_zh": "本论文针对Reinforcement Learning from Human Feedback (RLHF)中个体偏好差异的问题，提出了一种基于latent variable formulation的变分偏好学习方法，能够推断用户特定潜在变量，并在不需额外数据的情况下学习个性化奖励模型和策略，从而实现多元化的模型对齐。实验结果显示，该方法在模拟控制问题中有效处理underspecification，并在线语数据集上提升了奖励函数准确性，同时提供不确定性测量和主动学习用户偏好的能力。该框架为机器人学习和基础模型对齐等领域的多样用户偏好学习提供了重要解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "weirdlabuw.github.io/vpl",
      "pdf_url": "http://arxiv.org/pdf/2408.10075v1",
      "published_date": "2024-08-19 15:18:30 UTC",
      "updated_date": "2024-08-19 15:18:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:36:11.781837"
    },
    {
      "arxiv_id": "2408.10074v1",
      "title": "Synthesis of Reward Machines for Multi-Agent Equilibrium Design (Full Version)",
      "title_zh": "用于多智能体均衡设计的奖励机器合成（完整版本）",
      "authors": [
        "Muhammad Najib",
        "Giuseppe Perelli"
      ],
      "abstract": "Mechanism design is a well-established game-theoretic paradigm for designing\ngames to achieve desired outcomes. This paper addresses a closely related but\ndistinct concept, equilibrium design. Unlike mechanism design, the designer's\nauthority in equilibrium design is more constrained; she can only modify the\nincentive structures in a given game to achieve certain outcomes without the\nability to create the game from scratch. We study the problem of equilibrium\ndesign using dynamic incentive structures, known as reward machines. We use\nweighted concurrent game structures for the game model, with goals (for the\nplayers and the designer) defined as mean-payoff objectives. We show how reward\nmachines can be used to represent dynamic incentives that allocate rewards in a\nmanner that optimises the designer's goal. We also introduce the main decision\nproblem within our framework, the payoff improvement problem. This problem\nessentially asks whether there exists a dynamic incentive (represented by some\nreward machine) that can improve the designer's payoff by more than a given\nthreshold value. We present two variants of the problem: strong and weak. We\ndemonstrate that both can be solved in polynomial time using a Turing machine\nequipped with an NP oracle. Furthermore, we also establish that these variants\nare either NP-hard or coNP-hard. Finally, we show how to synthesise the\ncorresponding reward machine if it exists.",
      "tldr_zh": "本论文探讨了多智能体平衡设计（equilibrium design），区别于机制设计（mechanism design），设计师仅能修改现有游戏的激励结构，而非从零创建游戏。论文提出使用回报机器（reward machines）和加权并发游戏结构（weighted concurrent game structures）来表示动态激励，并以均值收益目标（mean-payoff objectives）作为玩家的目标。作者引入回报改进问题（payoff improvement problem）的强变体和弱变体，证明这些问题可在多项式时间内解决（使用 NP oracle），尽管可能 NP-hard 或 coNP-hard，并展示了如何合成相应的回报机器以优化设计师的收益。",
      "categories": [
        "cs.GT",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.GT",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.10074v1",
      "published_date": "2024-08-19 15:17:58 UTC",
      "updated_date": "2024-08-19 15:17:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:36:24.032798"
    },
    {
      "arxiv_id": "2408.10072v2",
      "title": "FFAA: Multimodal Large Language Model based Explainable Open-World Face Forgery Analysis Assistant",
      "title_zh": "FFAA：基于多模态大型语言模型的可解释开放世界",
      "authors": [
        "Zhengchao Huang",
        "Bin Xia",
        "Zicheng Lin",
        "Zhun Mou",
        "Wenming Yang",
        "Jiaya Jia"
      ],
      "abstract": "The rapid advancement of deepfake technologies has sparked widespread public\nconcern, particularly as face forgery poses a serious threat to public\ninformation security. However, the unknown and diverse forgery techniques,\nvaried facial features and complex environmental factors pose significant\nchallenges for face forgery analysis. Existing datasets lack descriptive\nannotations of these aspects, making it difficult for models to distinguish\nbetween real and forged faces using only visual information amid various\nconfounding factors. In addition, existing methods fail to yield user-friendly\nand explainable results, hindering the understanding of the model's\ndecision-making process. To address these challenges, we introduce a novel\nOpen-World Face Forgery Analysis VQA (OW-FFA-VQA) task and its corresponding\nbenchmark. To tackle this task, we first establish a dataset featuring a\ndiverse collection of real and forged face images with essential descriptions\nand reliable forgery reasoning. Based on this dataset, we introduce FFAA: Face\nForgery Analysis Assistant, consisting of a fine-tuned Multimodal Large\nLanguage Model (MLLM) and Multi-answer Intelligent Decision System (MIDS). By\nintegrating hypothetical prompts with MIDS, the impact of fuzzy classification\nboundaries is effectively mitigated, enhancing model robustness. Extensive\nexperiments demonstrate that our method not only provides user-friendly and\nexplainable results but also significantly boosts accuracy and robustness\ncompared to previous methods.",
      "tldr_zh": "该研究针对面部伪造技术的快速发展及其对公共信息安全的威胁，引入了新的Open-World Face Forgery Analysis VQA (OW-FFA-VQA) 任务，并建立了一个包含真实和伪造面部图像的描述性数据集，以解决现有模型在区分真假时的局限性。论文提出FFAA系统，该系统基于微调的Multimodal Large Language Model (MLLM) 和Multi-answer Intelligent Decision System (MIDS)，通过整合假设性提示来缓解模糊分类边界，提升模型的鲁棒性和可解释性。实验结果显示，FFAA不仅提供用户友好的解释性输出，还显著提高了准确性和鲁棒性，超越了现有方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "23 pages, 21 figures; project page: https://ffaa-vl.github.io",
      "pdf_url": "http://arxiv.org/pdf/2408.10072v2",
      "published_date": "2024-08-19 15:15:20 UTC",
      "updated_date": "2024-11-21 14:37:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:36:34.590714"
    },
    {
      "arxiv_id": "2408.10060v4",
      "title": "Facial Wrinkle Segmentation for Cosmetic Dermatology: Pretraining with Texture Map-Based Weak Supervision",
      "title_zh": "美容皮肤科的面部皱纹分割：基于纹理图的弱监督预训练",
      "authors": [
        "Junho Moon",
        "Haejun Chung",
        "Ikbeom Jang"
      ],
      "abstract": "Facial wrinkle detection plays a crucial role in cosmetic dermatology.\nPrecise manual segmentation of facial wrinkles is challenging and\ntime-consuming, with inherent subjectivity leading to inconsistent results\namong graders. To address this issue, we propose two solutions. First, we build\nand release the first public facial wrinkle dataset, 'FFHQ-Wrinkle', an\nextension of the NVIDIA FFHQ dataset. It includes 1,000 images with human\nlabels and 50,000 images with automatically generated weak labels. This dataset\ncould serve as a foundation for the research community to develop advanced\nwrinkle detection algorithms. Second, we introduce a simple training strategy\nutilizing texture maps, applicable to various segmentation models, to detect\nwrinkles across the face. Our two-stage training strategy first pretrain models\non a large dataset with weak labels (N=50k), or masked texture maps generated\nthrough computer vision techniques, without human intervention. We then\nfinetune the models using human-labeled data (N=1k), which consists of manually\nlabeled wrinkle masks. The network takes as input a combination of RGB and\nmasked texture map of the image, comprising four channels, in finetuning. We\neffectively combine labels from multiple annotators to minimize subjectivity in\nmanual labeling. Our strategies demonstrate improved segmentation performance\nin facial wrinkle segmentation both quantitatively and visually compared to\nexisting pretraining methods. The dataset is available at\nhttps://github.com/labhai/ffhq-wrinkle-dataset.",
      "tldr_zh": "本研究针对面部皱纹分割（Facial Wrinkle Segmentation）在美容皮肤科中的应用，提出了一种基于纹理图（Texture Map-Based）的弱监督预训练策略，以解决手动标注的挑战性、主观性和不一致性问题。主要贡献包括构建并发布首个公开数据集'FFHQ-Wrinkle'，它基于NVIDIA FFHQ扩展，包含1000张手动标签图像和50000张自动生成弱标签图像，为研究社区提供基础。该策略采用两阶段训练：首先在大型弱标签数据集（N=50k）上预训练模型，使用masked texture maps；然后结合RGB图像和纹理图（四通道输入）在手动标签数据（N=1k）上微调，并融合多标注者标签以减少主观性。实验结果显示，该方法在面部皱纹分割的定量和视觉性能上均优于现有预训练方法。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at International Conference on Pattern Recognition (ICPR),\n  2024",
      "pdf_url": "http://arxiv.org/pdf/2408.10060v4",
      "published_date": "2024-08-19 14:54:12 UTC",
      "updated_date": "2024-11-19 03:58:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:36:49.018567"
    },
    {
      "arxiv_id": "2408.10040v1",
      "title": "The Practimum-Optimum Algorithm for Manufacturing Scheduling: A Paradigm Shift Leading to Breakthroughs in Scale and Performance",
      "title_zh": "Practimum-Optimum 算法用于制造调度：一种范式转变，导致规模和性能方面的突破",
      "authors": [
        "Moshe BenBassat"
      ],
      "abstract": "The Practimum-Optimum (P-O) algorithm represents a paradigm shift in\ndeveloping automatic optimization products for complex real-life business\nproblems such as large-scale manufacturing scheduling. It leverages deep\nbusiness domain expertise to create a group of virtual human expert (VHE)\nagents with different \"schools of thought\" on how to create high-quality\nschedules. By computerizing them into algorithms, P-O generates many valid\nschedules at far higher speeds than human schedulers are capable of. Initially,\nthese schedules can also be local optimum peaks far away from high-quality\nschedules. By submitting these schedules to a reinforced machine learning\nalgorithm (RL), P-O learns the weaknesses and strengths of each VHE schedule,\nand accordingly derives reward and punishment changes in the Demand Set that\nwill modify the relative priorities for time and resource allocation that jobs\nreceived in the prior iteration that led to the current state of the schedule.\nThese cause the core logic of the VHE algorithms to explore, in the subsequent\niteration, substantially different parts of the schedules universe and\npotentially find higher-quality schedules. Using the hill climbing analogy,\nthis may be viewed as a big jump, shifting from a given local peak to a faraway\npromising start point equipped with knowledge embedded in the demand set for\nfuture iterations. This is a fundamental difference from most contemporary\nalgorithms, which spend considerable time on local micro-steps restricted to\nthe neighbourhoods of local peaks they visit. This difference enables a\nbreakthrough in scale and performance for fully automatic manufacturing\nscheduling in complex organizations. The P-O algorithm is at the heart of\nPlataine Scheduler that, in one click, routinely schedules 30,000-50,000 tasks\nfor real-life complex manufacturing operations.",
      "tldr_zh": "该研究提出Practimum-Optimum (P-O)算法，这是一种革命性的优化方法，用于解决复杂制造调度的实际问题，通过创建虚拟人类专家 (VHE) 代理模拟不同“思想流派”来快速生成多种有效调度。算法利用强化机器学习 (RL) 来分析这些调度的优缺点，并通过修改Demand Set的优先级引导代理探索更广阔的调度空间，实现从局部最优向高质解决方案的大幅跳跃。与传统算法不同，P-O显著提升了规模和性能，能够一键自动处理30,000-50,000个任务的真实制造操作。总的来说，这标志着制造调度领域的范式转变，提供更高效的自动优化工具。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.10040v1",
      "published_date": "2024-08-19 14:32:21 UTC",
      "updated_date": "2024-08-19 14:32:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:37:00.106992"
    },
    {
      "arxiv_id": "2408.10039v3",
      "title": "MSDiagnosis: A Benchmark for Evaluating Large Language Models in Multi-Step Clinical Diagnosis",
      "title_zh": "MSDiagnosis：用于评估大语言模型在多步临床诊断中的基准",
      "authors": [
        "Ruihui Hou",
        "Shencheng Chen",
        "Yongqi Fan",
        "Guangya Yu",
        "Lifeng Zhu",
        "Jing Sun",
        "Jingping Liu",
        "Tong Ruan"
      ],
      "abstract": "Clinical diagnosis is critical in medical practice, typically requiring a\ncontinuous and evolving process that includes primary diagnosis, differential\ndiagnosis, and final diagnosis. However, most existing clinical diagnostic\ntasks are single-step processes, which does not align with the complex\nmulti-step diagnostic procedures found in real-world clinical settings. In this\npaper, we propose a Chinese clinical diagnostic benchmark, called MSDiagnosis.\nThis benchmark consists of 2,225 cases from 12 departments, covering tasks such\nas primary diagnosis, differential diagnosis, and final diagnosis.\nAdditionally, we propose a novel and effective framework. This framework\ncombines forward inference, backward inference, reflection, and refinement,\nenabling the large language model to self-evaluate and adjust its diagnostic\nresults. To this end, we test open-source models, closed-source models, and our\nproposed framework.The experimental results demonstrate the effectiveness of\nthe proposed method. We also provide a comprehensive experimental analysis and\nsuggest future research directions for this task.",
      "tldr_zh": "本研究针对临床诊断的多步骤过程（如初步诊断、鉴别诊断和最终诊断），提出一个中文基准MSDiagnosis，包含2,225个病例，覆盖12个临床部门，以评估Large Language Models在真实多步诊断任务中的性能。研究引入了一个新框架，结合forward inference、backward inference、reflection和refinement机制，让模型能够自我评估和调整诊断结果。实验结果显示，该框架在开源和闭源模型上表现出色，提升了诊断准确性，并为未来Large Language Models在临床应用的研究提供了全面分析和方向。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.10039v3",
      "published_date": "2024-08-19 14:31:57 UTC",
      "updated_date": "2024-12-16 09:33:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:37:10.088861"
    },
    {
      "arxiv_id": "2408.10015v2",
      "title": "Deterministic Policy Gradient Primal-Dual Methods for Continuous-Space Constrained MDPs",
      "title_zh": "翻译失败",
      "authors": [
        "Sergio Rozada",
        "Dongsheng Ding",
        "Antonio G. Marques",
        "Alejandro Ribeiro"
      ],
      "abstract": "We study the problem of computing deterministic optimal policies for\nconstrained Markov decision processes (MDPs) with continuous state and action\nspaces, which are widely encountered in constrained dynamical systems.\nDesigning deterministic policy gradient methods in continuous state and action\nspaces is particularly challenging due to the lack of enumerable state-action\npairs and the adoption of deterministic policies, hindering the application of\nexisting policy gradient methods. To this end, we develop a deterministic\npolicy gradient primal-dual method to find an optimal deterministic policy with\nnon-asymptotic convergence. Specifically, we leverage regularization of the\nLagrangian of the constrained MDP to propose a deterministic policy gradient\nprimal-dual (D-PGPD) algorithm that updates the deterministic policy via a\nquadratic-regularized gradient ascent step and the dual variable via a\nquadratic-regularized gradient descent step. We prove that the primal-dual\niterates of D-PGPD converge at a sub-linear rate to an optimal regularized\nprimal-dual pair. We instantiate D-PGPD with function approximation and prove\nthat the primal-dual iterates of D-PGPD converge at a sub-linear rate to an\noptimal regularized primal-dual pair, up to a function approximation error.\nFurthermore, we demonstrate the effectiveness of our method in two continuous\ncontrol problems: robot navigation and fluid control. This appears to be the\nfirst work that proposes a deterministic policy search method for\ncontinuous-space constrained MDPs.",
      "tldr_zh": "本文研究了连续状态和动作空间的约束马尔可夫决策过程（Constrained MDPs），提出了一种确定性策略梯度主双重方法（Deterministic Policy Gradient Primal-Dual Methods），即 D-PGPD 算法，以解决现有方法的局限性。D-PGPD 通过二次正则化梯度上升更新确定性策略，并使用梯度下降更新双重变量，证明了其子线性收敛率，即使结合函数逼近，也能收敛到最优正则化主双重对（up to function approximation error）。实验在机器人导航和流体控制问题中验证了该方法的有效性，这是首个针对连续空间 Constrained MDPs 的确定性策略搜索方法。",
      "categories": [
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.10015v2",
      "published_date": "2024-08-19 14:11:04 UTC",
      "updated_date": "2025-04-04 11:14:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:37:24.433972"
    },
    {
      "arxiv_id": "2408.10003v2",
      "title": "Towards a Knowledge Graph for Models and Algorithms in Applied Mathematics",
      "title_zh": "翻译失败",
      "authors": [
        "Björn Schembera",
        "Frank Wübbeling",
        "Hendrik Kleikamp",
        "Burkhard Schmidt",
        "Aurela Shehu",
        "Marco Reidelbach",
        "Christine Biedinger",
        "Jochen Fiedler",
        "Thomas Koprucki",
        "Dorothea Iglezakis",
        "Dominik Göddeke"
      ],
      "abstract": "Mathematical models and algorithms are an essential part of mathematical\nresearch data, as they are epistemically grounding numerical data. In order to\nrepresent models and algorithms as well as their relationship semantically to\nmake this research data FAIR, two previously distinct ontologies were merged\nand extended, becoming a living knowledge graph. The link between the two\nontologies is established by introducing computational tasks, as they occur in\nmodeling, corresponding to algorithmic tasks. Moreover, controlled vocabularies\nare incorporated and a new class, distinguishing base quantities from specific\nuse case quantities, was introduced. Also, both models and algorithms can now\nbe enriched with metadata. Subject-specific metadata is particularly relevant\nhere, such as the symmetry of a matrix or the linearity of a mathematical\nmodel. This is the only way to express specific workflows with concrete models\nand algorithms, as the feasible solution algorithm can only be determined if\nthe mathematical properties of a model are known. We demonstrate this using two\nexamples from different application areas of applied mathematics. In addition,\nwe have already integrated over 250 research assets from applied mathematics\ninto our knowledge graph.",
      "tldr_zh": "本文提出构建一个知识 graph，用于语义表示应用数学中的模型和算法及其关系，以使研究数据符合 FAIR 原则。作者通过合并并扩展两个原本独立的本体（ontologies），引入计算任务（computational tasks）作为连接桥梁，并添加受控词汇表（controlled vocabularies）和一个新类来区分基本量与特定用例量。模型和算法现在可添加元数据（metadata），如矩阵的对称性或模型的线性性，从而支持表达具体的 workflows，并根据数学属性选择可行算法。最终，通过两个应用数学领域的例子进行演示，并已集成超过 250 个研究资产。",
      "categories": [
        "cs.AI",
        "cs.DL"
      ],
      "primary_category": "cs.AI",
      "comment": "Preprint submitted to the 18th International Conference on Metadata\n  and Semantics Research 2024 and published as a full, revised article",
      "pdf_url": "http://arxiv.org/pdf/2408.10003v2",
      "published_date": "2024-08-19 13:57:49 UTC",
      "updated_date": "2025-02-26 14:03:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:37:36.280048"
    },
    {
      "arxiv_id": "2408.11871v2",
      "title": "MegaFake: A Theory-Driven Dataset of Fake News Generated by Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Lionel Z. Wang",
        "Yiming Ma",
        "Renfei Gao",
        "Beichen Guo",
        "Han Zhu",
        "Wenqi Fan",
        "Zexin Lu",
        "Ka Chung Ng"
      ],
      "abstract": "The advent of large language models (LLMs) has revolutionized online content\ncreation, making it much easier to generate high-quality fake news. This misuse\nthreatens the integrity of our digital environment and ethical standards.\nTherefore, understanding the motivations and mechanisms behind LLM-generated\nfake news is crucial. In this study, we analyze the creation of fake news from\na social psychology perspective and develop a comprehensive LLM-based\ntheoretical framework, LLM-Fake Theory. We introduce a novel pipeline that\nautomates the generation of fake news using LLMs, thereby eliminating the need\nfor manual annotation. Utilizing this pipeline, we create a theoretically\ninformed Machine-generated Fake news dataset, MegaFake, derived from the\nGossipCop dataset. We conduct comprehensive analyses to evaluate our MegaFake\ndataset. We believe that our dataset and insights will provide valuable\ncontributions to future research focused on the detection and governance of\nfake news in the era of LLMs.",
      "tldr_zh": "这篇论文从社会心理学视角分析大型语言模型(LLMs)生成假新闻的动机和机制，并提出一个全面的理论框架LLM-Fake Theory。研究团队开发了一个自动化管道，使用LLMs生成假新闻数据集MegaFake，该数据集基于GossipCop数据集，并消除了手动标注的需求。通过全面分析，MegaFake数据集及其见解将为未来LLMs时代假新闻的检测和治理提供宝贵贡献。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.11871v2",
      "published_date": "2024-08-19 13:27:07 UTC",
      "updated_date": "2024-09-25 06:21:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:37:47.014076"
    },
    {
      "arxiv_id": "2408.09972v1",
      "title": "Edge-Cloud Collaborative Motion Planning for Autonomous Driving with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jiao Chen",
        "Suyan Dai",
        "Fangfang Chen",
        "Zuohong Lv",
        "Jianhua Tang"
      ],
      "abstract": "Integrating large language models (LLMs) into autonomous driving enhances\npersonalization and adaptability in open-world scenarios. However, traditional\nedge computing models still face significant challenges in processing complex\ndriving data, particularly regarding real-time performance and system\nefficiency. To address these challenges, this study introduces EC-Drive, a\nnovel edge-cloud collaborative autonomous driving system with data drift\ndetection capabilities. EC-Drive utilizes drift detection algorithms to\nselectively upload critical data, including new obstacles and traffic pattern\nchanges, to the cloud for processing by GPT-4, while routine data is\nefficiently managed by smaller LLMs on edge devices. This approach not only\nreduces inference latency but also improves system efficiency by optimizing\ncommunication resource use. Experimental validation confirms the system's\nrobust processing capabilities and practical applicability in real-world\ndriving conditions, demonstrating the effectiveness of this edge-cloud\ncollaboration framework. Our data and system demonstration will be released at\nhttps://sites.google.com/view/ec-drive.",
      "tldr_zh": "该研究提出EC-Drive，一种边缘-云协作自动驾驶系统，利用大型语言模型(LLMs)解决传统边缘计算在处理复杂驾驶数据时的实时性能和系统效率挑战。系统通过数据漂移检测算法选择性地将关键数据（如新障碍物和交通模式变化）上传到云端，由GPT-4处理，而常规数据则由边缘设备的较小LLMs管理，从而减少推理延迟并优化通信资源。实验验证显示，EC-Drive在真实驾驶条件下表现出色，提高了系统的鲁棒性和实用性，为LLMs在自动驾驶中的应用提供了有效框架。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.09972v1",
      "published_date": "2024-08-19 13:19:15 UTC",
      "updated_date": "2024-08-19 13:19:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:37:59.645217"
    },
    {
      "arxiv_id": "2408.09967v2",
      "title": "Unsupervised Machine Learning Hybrid Approach Integrating Linear Programming in Loss Function: A Robust Optimization Technique",
      "title_zh": "翻译失败",
      "authors": [
        "Andrew Kiruluta",
        "Andreas Lemos"
      ],
      "abstract": "This paper presents a novel hybrid approach that integrates linear\nprogramming (LP) within the loss function of an unsupervised machine learning\nmodel. By leveraging the strengths of both optimization techniques and machine\nlearning, this method introduces a robust framework for solving complex\noptimization problems where traditional methods may fall short. The proposed\napproach encapsulates the constraints and objectives of a linear programming\nproblem directly into the loss function, guiding the learning process to adhere\nto these constraints while optimizing the desired outcomes. This technique not\nonly preserves the interpretability of linear programming but also benefits\nfrom the flexibility and adaptability of machine learning, making it\nparticularly well-suited for unsupervised or semi-supervised learning\nscenarios.",
      "tldr_zh": "本论文提出了一种新颖的混合方法，将线性规划 (Linear Programming, LP) 整合到无监督机器学习模型的损失函数中，以构建一个稳健的优化框架。方法通过直接将 LP 的约束和目标嵌入损失函数，引导学习过程同时遵守这些约束并优化结果，从而解决了传统优化技术在复杂问题中的局限性。这种方法保留了 LP 的可解释性，同时利用机器学习的灵活性和适应性，特别适用于无监督或半监督学习场景。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.09967v2",
      "published_date": "2024-08-19 13:14:26 UTC",
      "updated_date": "2025-04-18 14:16:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:38:12.093886"
    },
    {
      "arxiv_id": "2408.09958v1",
      "title": "AdaResNet: Enhancing Residual Networks with Dynamic Weight Adjustment for Improved Feature Integration",
      "title_zh": "AdaResNet：通过动态权重调整增强残差网络以改进特征整合",
      "authors": [
        "Hong Su"
      ],
      "abstract": "In very deep neural networks, gradients can become extremely small during\nbackpropagation, making it challenging to train the early layers. ResNet\n(Residual Network) addresses this issue by enabling gradients to flow directly\nthrough the network via skip connections, facilitating the training of much\ndeeper networks. However, in these skip connections, the input ipd is directly\nadded to the transformed data tfd, treating ipd and tfd equally, without\nadapting to different scenarios. In this paper, we propose AdaResNet\n(Auto-Adapting Residual Network), which automatically adjusts the ratio between\nipd and tfd based on the training data. We introduce a variable,\nweight}_{tfd}^{ipd, to represent this ratio. This variable is dynamically\nadjusted during backpropagation, allowing it to adapt to the training data\nrather than remaining fixed. Experimental results demonstrate that AdaResNet\nachieves a maximum accuracy improvement of over 50\\% compared to traditional\nResNet.",
      "tldr_zh": "本论文针对深度神经网络中梯度消失问题，指出传统 ResNet 通过 skip connections 实现梯度直接流动，但未动态调整输入数据 (ipd) 和变换数据 (tfd) 的比例，导致适应性不足。AdaResNet 提出一种动态权重调整机制，引入变量 weight}_{tfd}^{ipd} 在 backpropagation 过程中自动优化 ipd 和 tfd 的权重比例，以提升特征整合效果。实验结果显示，AdaResNet 相较于传统 ResNet 实现了超过 50% 的准确率提升，为训练更深层网络提供了新方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.09958v1",
      "published_date": "2024-08-19 12:58:51 UTC",
      "updated_date": "2024-08-19 12:58:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:38:24.402898"
    },
    {
      "arxiv_id": "2408.09957v1",
      "title": "Contextual Importance and Utility in Python: New Functionality and Insights with the py-ciu Package",
      "title_zh": "翻译失败",
      "authors": [
        "Kary Främling"
      ],
      "abstract": "The availability of easy-to-use and reliable software implementations is\nimportant for allowing researchers in academia and industry to test, assess and\ntake into use eXplainable AI (XAI) methods. This paper describes the\n\\texttt{py-ciu} Python implementation of the Contextual Importance and Utility\n(CIU) model-agnostic, post-hoc explanation method and illustrates capabilities\nof CIU that go beyond the current state-of-the-art that could be useful for XAI\npractitioners in general.",
      "tldr_zh": "这篇论文介绍了 py-ciu 包，这是 Contextual Importance and Utility (CIU) 方法的 Python 实现，旨在为研究人员提供易用且可靠的工具来测试、评估和应用 eXplainable AI (XAI) 方法。CIU 作为一种 model-agnostic, post-hoc explanation 技术，能够超越当前最先进水平，提供额外的功能和见解，帮助用户更好地理解模型决策。总体而言，该包增强了 XAI 领域的实用性，为学术和工业从业者带来了新的机会。",
      "categories": [
        "cs.AI",
        "I.2.4"
      ],
      "primary_category": "cs.AI",
      "comment": "In Proceedings of XAI 2024 Workshop of 33rd International Joint\n  Conference on Artificial Intelligence (IJCAI 2024), Jeju, South Corea",
      "pdf_url": "http://arxiv.org/pdf/2408.09957v1",
      "published_date": "2024-08-19 12:57:50 UTC",
      "updated_date": "2024-08-19 12:57:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:38:35.788714"
    },
    {
      "arxiv_id": "2408.09952v1",
      "title": "Weakly Supervised Pretraining and Multi-Annotator Supervised Finetuning for Facial Wrinkle Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Ik Jun Moon",
        "Junho Moon",
        "Ikbeom Jang"
      ],
      "abstract": "1. Research question: With the growing interest in skin diseases and skin\naesthetics, the ability to predict facial wrinkles is becoming increasingly\nimportant. This study aims to evaluate whether a computational model,\nconvolutional neural networks (CNN), can be trained for automated facial\nwrinkle segmentation. 2. Findings: Our study presents an effective technique\nfor integrating data from multiple annotators and illustrates that transfer\nlearning can enhance performance, resulting in dependable segmentation of\nfacial wrinkles. 3. Meaning: This approach automates intricate and\ntime-consuming tasks of wrinkle analysis with a deep learning framework. It\ncould be used to facilitate skin treatments and diagnostics.",
      "tldr_zh": "本研究针对面部皱纹检测，探讨了使用卷积神经网络 (CNN) 进行自动化分割的可行性，旨在解决皮肤疾病和美学领域的需求。研究提出了一种结合弱监督预训练 (Weakly Supervised Pretraining) 和多标注者监督微调 (Multi-Annotator Supervised Finetuning) 的方法，通过整合多位标注者数据和转移学习 (transfer learning) 提升模型性能。实验结果显示，该技术实现了可靠的皱纹分割，显著提高了准确性。最后，这种框架可自动化繁琐的皱纹分析任务，有助于皮肤治疗和诊断的应用。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.09952v1",
      "published_date": "2024-08-19 12:47:47 UTC",
      "updated_date": "2024-08-19 12:47:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:38:48.357205"
    },
    {
      "arxiv_id": "2408.09951v1",
      "title": "Principle Driven Parameterized Fiber Model based on GPT-PINN Neural Network",
      "title_zh": "翻译失败",
      "authors": [
        "Yubin Zang",
        "Boyu Hua",
        "Zhenzhou Tang",
        "Zhipeng Lin",
        "Fangzheng Zhang",
        "Simin Li",
        "Zuxing Zhang",
        "Hongwei Chen"
      ],
      "abstract": "In cater the need of Beyond 5G communications, large numbers of data driven\nartificial intelligence based fiber models has been put forward as to utilize\nartificial intelligence's regression ability to predict pulse evolution in\nfiber transmission at a much faster speed compared with the traditional split\nstep Fourier method. In order to increase the physical interpretabiliy,\nprinciple driven fiber models have been proposed which inserts the Nonlinear\nSchodinger Equation into their loss functions. However, regardless of either\nprinciple driven or data driven models, they need to be re-trained the whole\nmodel under different transmission conditions. Unfortunately, this situation\ncan be unavoidable when conducting the fiber communication optimization work.\nIf the scale of different transmission conditions is large, then the whole\nmodel needs to be retrained large numbers of time with relatively large scale\nof parameters which may consume higher time costs. Computing efficiency will be\ndragged down as well. In order to address this problem, we propose the\nprinciple driven parameterized fiber model in this manuscript. This model\nbreaks down the predicted NLSE solution with respect to one set of transmission\ncondition into the linear combination of several eigen solutions which were\noutputted by each pre-trained principle driven fiber model via the reduced\nbasis method. Therefore, the model can greatly alleviate the heavy burden of\nre-training since only the linear combination coefficients need to be found\nwhen changing the transmission condition. Not only strong physical\ninterpretability can the model posses, but also higher computing efficiency can\nbe obtained. Under the demonstration, the model's computational complexity is\n0.0113% of split step Fourier method and 1% of the previously proposed\nprinciple driven fiber model.",
      "tldr_zh": "该论文针对 Beyond 5G 通信中光纤传输预测的需求，提出了一种基于 GPT-PINN 神经网络的原理驱动参数化光纤模型，以解决现有数据驱动或原理驱动模型在不同传输条件下需重新训练的效率问题。该模型利用 reduced basis method 将 Nonlinear Schrödinger Equation (NLSE) 解决方案分解为多个预训练模型的线性组合，仅需调整组合系数即可适应新条件，从而显著减少训练负担并保持强物理可解释性。实验结果显示，该模型的计算复杂度仅为传统 Split Step Fourier 方法的 0.0113% 和先前原理驱动模型的 1%，大大提升了计算效率。",
      "categories": [
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.09951v1",
      "published_date": "2024-08-19 12:44:00 UTC",
      "updated_date": "2024-08-19 12:44:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:39:00.910176"
    },
    {
      "arxiv_id": "2408.09948v1",
      "title": "Caption-Driven Explorations: Aligning Image and Text Embeddings through Human-Inspired Foveated Vision",
      "title_zh": "翻译失败",
      "authors": [
        "Dario Zanca",
        "Andrea Zugarini",
        "Simon Dietz",
        "Thomas R. Altstidl",
        "Mark A. Turban Ndjeuha",
        "Leo Schwinn",
        "Bjoern Eskofier"
      ],
      "abstract": "Understanding human attention is crucial for vision science and AI. While\nmany models exist for free-viewing, less is known about task-driven image\nexploration. To address this, we introduce CapMIT1003, a dataset with captions\nand click-contingent image explorations, to study human attention during the\ncaptioning task. We also present NevaClip, a zero-shot method for predicting\nvisual scanpaths by combining CLIP models with NeVA algorithms. NevaClip\ngenerates fixations to align the representations of foveated visual stimuli and\ncaptions. The simulated scanpaths outperform existing human attention models in\nplausibility for captioning and free-viewing tasks. This research enhances the\nunderstanding of human attention and advances scanpath prediction models.",
      "tldr_zh": "该研究介绍了CapMIT1003数据集，该数据集包含标题和点击相关的图像探索，用于分析人类在标题任务中的注意力模式。研究提出NevaClip，一种零样本方法，通过结合CLIP模型和NeVA算法，生成注视点以对齐foveated vision视觉刺激和文本标题的表示。实验结果显示，NevaClip模拟的扫描路径在标题和自由观看任务中比现有模型更可靠，从而提升了对人类注意力的理解并推进扫描路径预测模型的发展。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "arXiv admin note: substantial text overlap with arXiv:2305.12380",
      "pdf_url": "http://arxiv.org/pdf/2408.09948v1",
      "published_date": "2024-08-19 12:41:46 UTC",
      "updated_date": "2024-08-19 12:41:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:39:11.652150"
    },
    {
      "arxiv_id": "2408.09947v1",
      "title": "Fiber Transmission Model with Parameterized Inputs based on GPT-PINN Neural Network",
      "title_zh": "翻译失败",
      "authors": [
        "Yubin Zang",
        "Boyu Hua",
        "Zhipeng Lin",
        "Fangzheng Zhang",
        "Simin Li",
        "Zuxing Zhang",
        "Hongwei Chen"
      ],
      "abstract": "In this manuscript, a novelty principle driven fiber transmission model for\nshort-distance transmission with parameterized inputs is put forward. By taking\ninto the account of the previously proposed principle driven fiber model, the\nreduced basis expansion method and transforming the parameterized inputs into\nparameterized coefficients of the Nonlinear Schrodinger Equations, universal\nsolutions with respect to inputs corresponding to different bit rates can all\nbe obtained without the need of re-training the whole model. This model, once\nadopted, can have prominent advantages in both computation efficiency and\nphysical background. Besides, this model can still be effectively trained\nwithout the needs of transmitted signals collected in advance. Tasks of on-off\nkeying signals with bit rates ranging from 2Gbps to 50Gbps are adopted to\ndemonstrate the fidelity of the model.",
      "tldr_zh": "本论文提出了一种基于 GPT-PINN Neural Network 的新型光纤传输模型，支持参数化输入，适用于短距离传输。该模型通过 reduced basis expansion method 将参数化输入转化为 Nonlinear Schrödinger Equations 的参数化系数，从而实现通用解决方案，无需重新训练即可处理不同比特率，提高了计算效率并保留物理背景。该模型无需预先收集传输信号即可有效训练，并在 2Gbps 到 50Gbps 的 on-off keying 信号任务中验证了其高保真度。",
      "categories": [
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.09947v1",
      "published_date": "2024-08-19 12:37:15 UTC",
      "updated_date": "2024-08-19 12:37:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:39:24.754722"
    },
    {
      "arxiv_id": "2408.09946v1",
      "title": "Microscopic Analysis on LLM players via Social Deduction Game",
      "title_zh": "通过社会推演游戏对LLM玩家的微观分析",
      "authors": [
        "Byungjun Kim",
        "Dayeon Seo",
        "Bugeun Kim"
      ],
      "abstract": "Recent studies have begun developing autonomous game players for social\ndeduction games using large language models (LLMs). When building LLM players,\nfine-grained evaluations are crucial for addressing weaknesses in game-playing\nabilities. However, existing studies have often overlooked such assessments.\nSpecifically, we point out two issues with the evaluation methods employed.\nFirst, game-playing abilities have typically been assessed through game-level\noutcomes rather than specific event-level skills; Second, error analyses have\nlacked structured methodologies. To address these issues, we propose an\napproach utilizing a variant of the SpyFall game, named SpyGame. We conducted\nan experiment with four LLMs, analyzing their gameplay behavior in SpyGame both\nquantitatively and qualitatively. For the quantitative analysis, we introduced\neight metrics to resolve the first issue, revealing that these metrics are more\neffective than existing ones for evaluating the two critical skills: intent\nidentification and camouflage. In the qualitative analysis, we performed\nthematic analysis to resolve the second issue. This analysis identifies four\nmajor categories that affect gameplay of LLMs. Additionally, we demonstrate how\nthese categories complement and support the findings from the quantitative\nanalysis.",
      "tldr_zh": "本研究指出了现有评估大型语言模型（LLMs）在社交推理游戏中玩家能力的不足，包括依赖游戏级别结果和缺乏结构化错误分析。为解决这些问题，研究者提出使用SpyFall游戏的变体SpyGame，对四个LLMs进行定量和定性分析。定量分析引入八个新指标，更有效地评估关键技能如意图识别和伪装；定性分析通过主题分析识别了四个主要类别影响LLMs的游戏表现。这些发现证明了新方法的可行性，并为提升LLMs的游戏能力提供了互补性见解。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Under review, 10 pages",
      "pdf_url": "http://arxiv.org/pdf/2408.09946v1",
      "published_date": "2024-08-19 12:35:23 UTC",
      "updated_date": "2024-08-19 12:35:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:39:39.162205"
    },
    {
      "arxiv_id": "2408.09945v4",
      "title": "Large Language Models for Classical Chinese Poetry Translation: Benchmarking, Evaluating, and Improving",
      "title_zh": "大型语言模型在古典中文诗歌翻译中的应用：基准测试、评估和改进",
      "authors": [
        "Andong Chen",
        "Lianzhang Lou",
        "Kehai Chen",
        "Xuefeng Bai",
        "Yang Xiang",
        "Muyun Yang",
        "Tiejun Zhao",
        "Min Zhang"
      ],
      "abstract": "Different from the traditional translation tasks, classical Chinese poetry\ntranslation requires both adequacy and fluency in translating culturally and\nhistorically significant content and linguistic poetic elegance. Large language\nmodels (LLMs) with impressive multilingual capabilities may bring a ray of hope\nto achieve this extreme translation demand. This paper first introduces a\nsuitable benchmark (PoetMT) where each Chinese poetry has a recognized elegant\ntranslation. Meanwhile, we propose a new metric based on GPT-4 to evaluate the\nextent to which current LLMs can meet these demands. Our empirical evaluation\nreveals that the existing LLMs fall short in the challenging task. Hence, we\npropose a Retrieval-Augmented Machine Translation (RAT) method which\nincorporates knowledge related to classical poetry for advancing the\ntranslation of Chinese Poetry in LLMs. Experimental results show that RAT\nconsistently outperforms all comparison methods regarding wildly used BLEU,\nCOMET, BLEURT, our proposed metric, and human evaluation.",
      "tldr_zh": "本研究探讨了大型语言模型（LLMs）在古典中文诗歌翻译中的应用，强调了翻译的准确性（adequacy）和流畅性（fluency）以及文化诗意的要求。首先，引入了PoetMT基准数据集和基于GPT-4的新评估指标，以评估LLMs在这一任务上的表现。结果显示，现有的LLMs难以满足这些严格需求，因此提出Retrieval-Augmented Machine Translation (RAT)方法，通过整合相关古典诗歌知识来提升翻译质量。实验证明，RAT在BLEU、COMET、BLEURT指标以及新评估指标和人工评估中均优于其他方法。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Work in progress",
      "pdf_url": "http://arxiv.org/pdf/2408.09945v4",
      "published_date": "2024-08-19 12:34:31 UTC",
      "updated_date": "2024-12-30 07:26:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:39:48.735885"
    },
    {
      "arxiv_id": "2408.09933v1",
      "title": "SZU-AFS Antispoofing System for the ASVspoof 5 Challenge",
      "title_zh": "翻译失败",
      "authors": [
        "Yuxiong Xu",
        "Jiafeng Zhong",
        "Sengui Zheng",
        "Zefeng Liu",
        "Bin Li"
      ],
      "abstract": "This paper presents the SZU-AFS anti-spoofing system, designed for Track 1 of\nthe ASVspoof 5 Challenge under open conditions. The system is built with four\nstages: selecting a baseline model, exploring effective data augmentation (DA)\nmethods for fine-tuning, applying a co-enhancement strategy based on gradient\nnorm aware minimization (GAM) for secondary fine-tuning, and fusing logits\nscores from the two best-performing fine-tuned models. The system utilizes the\nWav2Vec2 front-end feature extractor and the AASIST back-end classifier as the\nbaseline model. During model fine-tuning, three distinct DA policies have been\ninvestigated: single-DA, random-DA, and cascade-DA. Moreover, the employed\nGAM-based co-enhancement strategy, designed to fine-tune the augmented model at\nboth data and optimizer levels, helps the Adam optimizer find flatter minima,\nthereby boosting model generalization. Overall, the final fusion system\nachieves a minDCF of 0.115 and an EER of 4.04% on the evaluation set.",
      "tldr_zh": "本论文提出 SZU-AFS 反欺骗系统，针对 ASVspoof 5 挑战赛 Track 1 的开放条件，通过四个阶段构建：选择 Wav2Vec2 前端特征提取器和 AASIST 后端分类器的基线模型、探索 single-DA、random-DA 和 cascade-DA 等数据增强方法进行微调。系统还采用基于梯度范数感知最小化 (GAM) 的联合增强策略，在数据和优化器层面二次微调模型，以提升 Adam 优化器的泛化能力。最终，融合两个最佳微调模型的 logits 得分，在评估集上实现 minDCF 0.115 和 EER 4.04%，显著提高了语音反欺骗性能。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "8 pages, 2 figures, ASVspoof 5 Workshop (Interspeech2024 Satellite)",
      "pdf_url": "http://arxiv.org/pdf/2408.09933v1",
      "published_date": "2024-08-19 12:12:29 UTC",
      "updated_date": "2024-08-19 12:12:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:40:01.614699"
    },
    {
      "arxiv_id": "2408.10846v2",
      "title": "Harmonizing Attention: Training-free Texture-aware Geometry Transfer",
      "title_zh": "和谐注意力：免训练的纹理感知几何转移",
      "authors": [
        "Eito Ikuta",
        "Yohan Lee",
        "Akihiro Iohara",
        "Yu Saito",
        "Toshiyuki Tanaka"
      ],
      "abstract": "Extracting geometry features from photographic images independently of\nsurface texture and transferring them onto different materials remains a\ncomplex challenge. In this study, we introduce Harmonizing Attention, a novel\ntraining-free approach that leverages diffusion models for texture-aware\ngeometry transfer. Our method employs a simple yet effective modification of\nself-attention layers, allowing the model to query information from multiple\nreference images within these layers. This mechanism is seamlessly integrated\ninto the inversion process as Texture-aligning Attention and into the\ngeneration process as Geometry-aligning Attention. This dual-attention approach\nensures the effective capture and transfer of material-independent geometry\nfeatures while maintaining material-specific textural continuity, all without\nthe need for model fine-tuning.",
      "tldr_zh": "这篇论文提出了 Harmonizing Attention，一种无需训练的纹理感知几何转移方法，利用 diffusion models 从照片中提取独立于表面纹理的几何特征，并将其转移到不同材料上。方法通过修改 self-attention layers，引入 Texture-aligning Attention（用于反演过程）和 Geometry-aligning Attention（用于生成过程），允许模型从多个参考图像中查询信息，从而有效捕获几何特征。Harmonizing Attention 确保了材料无关几何特征的精确转移，同时保持材料特定纹理的连续性，而无需进行模型微调。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at WACV2025",
      "pdf_url": "http://arxiv.org/pdf/2408.10846v2",
      "published_date": "2024-08-19 12:06:25 UTC",
      "updated_date": "2024-09-01 14:57:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:40:13.242877"
    },
    {
      "arxiv_id": "2408.10843v3",
      "title": "Detecting Wildfires on UAVs with Real-time Segmentation Trained by Larger Teacher Models",
      "title_zh": "翻译失败",
      "authors": [
        "Julius Pesonen",
        "Teemu Hakala",
        "Väinö Karjalainen",
        "Niko Koivumäki",
        "Lauri Markelin",
        "Anna-Maria Raita-Hakola",
        "Juha Suomalainen",
        "Ilkka Pölönen",
        "Eija Honkavaara"
      ],
      "abstract": "Early detection of wildfires is essential to prevent large-scale fires\nresulting in extensive environmental, structural, and societal damage. Uncrewed\naerial vehicles (UAVs) can cover large remote areas effectively with quick\ndeployment requiring minimal infrastructure and equipping them with small\ncameras and computers enables autonomous real-time detection. In remote areas,\nhowever, detection methods are limited to onboard computation due to the lack\nof high-bandwidth mobile networks. For accurate camera-based localisation,\nsegmentation of the detected smoke is essential but training data for deep\nlearning-based wildfire smoke segmentation is limited. This study shows how\nsmall specialised segmentation models can be trained using only bounding box\nlabels, leveraging zero-shot foundation model supervision. The method offers\nthe advantages of needing only fairly easily obtainable bounding box labels and\nrequiring training solely for the smaller student network. The proposed method\nachieved 63.3% mIoU on a manually annotated and diverse wildfire dataset. The\nused model can perform in real-time at ~25 fps with a UAV-carried NVIDIA Jetson\nOrin NX computer while reliably recognising smoke, as demonstrated at\nreal-world forest burning events. Code is available at:\nhttps://gitlab.com/fgi_nls/public/wildfire-real-time-segmentation",
      "tldr_zh": "本文提出了一种利用较大教师模型训练小型分割模型的方法，用于UAVs上的野火实时检测，仅需边界框标签和零样本基础模型监督，以克服训练数据有限的挑战。该方法专注于烟雾分割，确保在偏远地区依赖机载计算的自主操作。实验结果显示，模型在多样野火数据集上达到63.3% mIoU，并在NVIDIA Jetson Orin NX上以约25 fps实时运行，并在真实森林燃烧事件中可靠识别烟雾。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "I.4.6"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.10843v3",
      "published_date": "2024-08-19 11:42:54 UTC",
      "updated_date": "2024-12-18 08:54:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:40:27.181144"
    },
    {
      "arxiv_id": "2408.09899v1",
      "title": "LCE: A Framework for Explainability of DNNs for Ultrasound Image Based on Concept Discovery",
      "title_zh": "翻译失败",
      "authors": [
        "Weiji Kong",
        "Xun Gong",
        "Juan Wang"
      ],
      "abstract": "Explaining the decisions of Deep Neural Networks (DNNs) for medical images\nhas become increasingly important. Existing attribution methods have difficulty\nexplaining the meaning of pixels while existing concept-based methods are\nlimited by additional annotations or specific model structures that are\ndifficult to apply to ultrasound images. In this paper, we propose the Lesion\nConcept Explainer (LCE) framework, which combines attribution methods with\nconcept-based methods. We introduce the Segment Anything Model (SAM),\nfine-tuned on a large number of medical images, for concept discovery to enable\na meaningful explanation of ultrasound image DNNs. The proposed framework is\nevaluated in terms of both faithfulness and understandability. We point out\ndeficiencies in the popular faithfulness evaluation metrics and propose a new\nevaluation metric. Our evaluation of public and private breast ultrasound\ndatasets (BUSI and FG-US-B) shows that LCE performs well compared to\ncommonly-used explainability methods. Finally, we also validate that LCE can\nconsistently provide reliable explanations for more meaningful fine-grained\ndiagnostic tasks in breast ultrasound.",
      "tldr_zh": "该论文提出LCE框架，用于解释基于超声图像的深度神经网络(DNNs)决策，通过结合归因方法和概念发现方法来解决现有解释技术的局限性。LCE利用在大量医疗图像上微调的Segment Anything Model (SAM)进行概念发现，从而为超声图像提供更有意义的解释。研究评估了LCE在faithful和understandability方面的性能，引入了新的faithful评估指标，并在乳腺超声数据集(BUSI和FG-US-B)上证明其比传统方法表现更优，并适用于细粒度的诊断任务。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.09899v1",
      "published_date": "2024-08-19 11:13:49 UTC",
      "updated_date": "2024-08-19 11:13:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:40:36.965683"
    },
    {
      "arxiv_id": "2408.09894v1",
      "title": "Preoperative Rotator Cuff Tear Prediction from Shoulder Radiographs using a Convolutional Block Attention Module-Integrated Neural Network",
      "title_zh": "翻译失败",
      "authors": [
        "Chris Hyunchul Jo",
        "Jiwoong Yang",
        "Byunghwan Jeon",
        "Hackjoon Shim",
        "Ikbeom Jang"
      ],
      "abstract": "Research question: We test whether a plane shoulder radiograph can be used\ntogether with deep learning methods to identify patients with rotator cuff\ntears as opposed to using an MRI in standard of care. Findings: By integrating\nconvolutional block attention modules into a deep neural network, our model\ndemonstrates high accuracy in detecting patients with rotator cuff tears,\nachieving an average AUC of 0.889 and an accuracy of 0.831. Meaning: This study\nvalidates the efficacy of our deep learning model to accurately detect rotation\ncuff tears from radiographs, offering a viable pre-assessment or alternative to\nmore expensive imaging techniques such as MRI.",
      "tldr_zh": "本研究旨在通过深度学习方法，利用肩部X光片预测术前肩袖撕裂患者，以替代标准的MRI检查。研究团队开发了一种集成Convolutional Block Attention Module的神经网络模型，该模型在检测肩袖撕裂时表现出色，平均AUC达到0.889，准确率达0.831。结果验证了该方法的有效性，为提供一种经济高效的预评估工具提供了可行方案，潜在地减少对昂贵成像技术的依赖。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.09894v1",
      "published_date": "2024-08-19 11:08:49 UTC",
      "updated_date": "2024-08-19 11:08:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:40:49.220472"
    },
    {
      "arxiv_id": "2408.09881v2",
      "title": "Uncertainty Quantification of Surrogate Models using Conformal Prediction",
      "title_zh": "利用保形预测对代理模型进行不确定性量化",
      "authors": [
        "Vignesh Gopakumar",
        "Ander Gray",
        "Joel Oskarsson",
        "Lorenzo Zanisi",
        "Stanislas Pamela",
        "Daniel Giles",
        "Matt Kusner",
        "Marc Peter Deisenroth"
      ],
      "abstract": "Data-driven surrogate models have shown immense potential as quick,\ninexpensive approximations to complex numerical and experimental modelling\ntasks. However, most surrogate models of physical systems do not quantify their\nuncertainty, rendering their predictions unreliable, requiring further\nvalidation. Though Bayesian approximations offer some solace in estimating the\nerror associated with these models, they cannot provide guarantees, and the\nquality of their inferences depends on the availability of prior information\nand good approximations to posteriors for complex problems. This is\nparticularly pertinent to multi-variable or spatio-temporal problems. Our work\nconstructs and formalises a conformal prediction framework that satisfies\nmarginal coverage for spatio-temporal predictions in a model-agnostic manner,\nrequiring near-zero computational costs. We provide an extensive empirical\nstudy of the application of the framework to ascertain valid error bars that\nprovide guaranteed coverage across the surrogate model's domain of operation.\nThe application scope of our work extends across a large range of\nspatio-temporal models, from solving partial differential equations to weather\nforecasting. Through the applications, the paper looks at providing\nstatistically valid error bars for deterministic models, as well as crafting\nguarantees to the error bars of probabilistic models. Our conformal prediction\nformalisation provides guaranteed coverage of the surrogate model, regardless\nof model architecture, and its training regime and is unbothered by the curse\nof dimensionality.",
      "tldr_zh": "本研究针对数据驱动的代理模型（surrogate models）在预测不确定性量化方面的不足，提出了一种基于 Conformal Prediction 的框架，以模型无关的方式为时空预测（spatio-temporal predictions）提供 marginal coverage，并显著降低计算成本。该框架通过形式化方法，确保预测结果的统计有效性，并在多变量问题中不受维度诅咒影响。实验结果显示，该方法在求解偏微分方程和天气预报等应用中，为确定性模型生成可靠的误差条带，并增强概率模型的误差保证，提供普遍适用的覆盖率保障。",
      "categories": [
        "cs.AI",
        "physics.ao-ph",
        "physics.plasm-ph"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.09881v2",
      "published_date": "2024-08-19 10:46:19 UTC",
      "updated_date": "2024-10-31 11:14:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:41:03.003243"
    },
    {
      "arxiv_id": "2408.09873v1",
      "title": "New spectral imaging biomarkers for sepsis and mortality in intensive care",
      "title_zh": "重症监护中败血症和死亡率的新的光谱成像生物标志物",
      "authors": [
        "Silvia Seidlitz",
        "Katharina Hölzl",
        "Ayca von Garrel",
        "Jan Sellner",
        "Stephan Katzenschlager",
        "Tobias Hölle",
        "Dania Fischer",
        "Maik von der Forst",
        "Felix C. F. Schmitt",
        "Markus A. Weigand",
        "Lena Maier-Hein",
        "Maximilian Dietrich"
      ],
      "abstract": "With sepsis remaining a leading cause of mortality, early identification of\nseptic patients and those at high risk of death is a challenge of high\nsocioeconomic importance. The driving hypothesis of this study was that\nhyperspectral imaging (HSI) could provide novel biomarkers for sepsis diagnosis\nand treatment management due to its potential to monitor microcirculatory\nalterations. We conducted a comprehensive study involving HSI data of the palm\nand fingers from more than 480 patients on the day of their intensive care unit\n(ICU) admission. The findings demonstrate that HSI measurements can predict\nsepsis with an area under the receiver operating characteristic curve (AUROC)\nof 0.80 (95 % confidence interval (CI) [0.76; 0.84]) and mortality with an\nAUROC of 0.72 (95 % CI [0.65; 0.79]). The predictive performance improves\nsubstantially when additional clinical data is incorporated, leading to an\nAUROC of up to 0.94 (95 % CI [0.92; 0.96]) for sepsis and 0.84 (95 % CI [0.78;\n0.89]) for mortality. We conclude that HSI presents novel imaging biomarkers\nfor the rapid, non-invasive prediction of sepsis and mortality, suggesting its\npotential as an important modality for guiding diagnosis and treatment.",
      "tldr_zh": "这篇论文探讨了使用高光谱成像(HSI)作为新生物标志物，来预测ICU中败血症(sepsis)和死亡风险，基于对超过480名患者掌部和手指的HSI数据采集。研究发现，HSI单独预测败血症的AUROC为0.80（95% CI [0.76; 0.84]），预测死亡的AUROC为0.72（95% CI [0.65; 0.79]）。当结合额外临床数据时，预测性能显著提升，败血症AUROC达0.94（95% CI [0.92; 0.96]），死亡AUROC达0.84（95% CI [0.78; 0.89]）。总体结论是，HSI提供了一种快速、非侵入性的成像工具，有潜力指导败血症的诊断和治疗管理。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "eess.IV"
      ],
      "primary_category": "cs.LG",
      "comment": "Markus A. Weigand, Lena Maier-Hein and Maximilian Dietrich\n  contributed equally",
      "pdf_url": "http://arxiv.org/pdf/2408.09873v1",
      "published_date": "2024-08-19 10:24:57 UTC",
      "updated_date": "2024-08-19 10:24:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:41:15.793293"
    },
    {
      "arxiv_id": "2408.09860v2",
      "title": "3D-Aware Instance Segmentation and Tracking in Egocentric Videos",
      "title_zh": "翻译失败",
      "authors": [
        "Yash Bhalgat",
        "Vadim Tschernezki",
        "Iro Laina",
        "João F. Henriques",
        "Andrea Vedaldi",
        "Andrew Zisserman"
      ],
      "abstract": "Egocentric videos present unique challenges for 3D scene understanding due to\nrapid camera motion, frequent object occlusions, and limited object visibility.\nThis paper introduces a novel approach to instance segmentation and tracking in\nfirst-person video that leverages 3D awareness to overcome these obstacles. Our\nmethod integrates scene geometry, 3D object centroid tracking, and instance\nsegmentation to create a robust framework for analyzing dynamic egocentric\nscenes. By incorporating spatial and temporal cues, we achieve superior\nperformance compared to state-of-the-art 2D approaches. Extensive evaluations\non the challenging EPIC Fields dataset demonstrate significant improvements\nacross a range of tracking and segmentation consistency metrics. Specifically,\nour method outperforms the next best performing approach by $7$ points in\nAssociation Accuracy (AssA) and $4.5$ points in IDF1 score, while reducing the\nnumber of ID switches by $73\\%$ to $80\\%$ across various object categories.\nLeveraging our tracked instance segmentations, we showcase downstream\napplications in 3D object reconstruction and amodal video object segmentation\nin these egocentric settings.",
      "tldr_zh": "这篇论文提出了一种 3D-Aware 的方法，用于 egocentric videos 中的实例分割和跟踪，以应对快速相机运动、物体遮挡和有限可见性的挑战。该方法整合场景几何、3D 物体中心跟踪和实例分割，充分利用空间和时间线索，实现比最先进 2D 方法更优的性能。在 EPIC Fields 数据集上的评估显示，该方法在 Association Accuracy (AssA) 上提升 7 点、IDF1 得分提升 4.5 点，并将 ID 切换减少 73% 到 80%。此外，该框架支持下游应用，如 3D 物体重建和 amodal video object segmentation。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Camera-ready for ACCV 2024. More experiments added",
      "pdf_url": "http://arxiv.org/pdf/2408.09860v2",
      "published_date": "2024-08-19 10:08:25 UTC",
      "updated_date": "2024-11-20 12:51:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:41:26.762111"
    },
    {
      "arxiv_id": "2408.09856v1",
      "title": "TeamLoRA: Boosting Low-Rank Adaptation with Expert Collaboration and Competition",
      "title_zh": "TeamLoRA：通过专家协作和竞争提升低秩适应",
      "authors": [
        "Tianwei Lin",
        "Jiang Liu",
        "Wenqiao Zhang",
        "Zhaocheng Li",
        "Yang Dai",
        "Haoyuan Li",
        "Zhelun Yu",
        "Wanggui He",
        "Juncheng Li",
        "Hao Jiang",
        "Siliang Tang",
        "Yueting Zhuang"
      ],
      "abstract": "While Parameter-Efficient Fine-Tuning (PEFT) methods like LoRA have\neffectively addressed GPU memory constraints during fine-tuning, their\nperformance often falls short, especially in multidimensional task scenarios.\nTo address this issue, one straightforward solution is to introduce\ntask-specific LoRA modules as domain experts, leveraging the modeling of\nmultiple experts' capabilities and thus enhancing the general capability of\nmulti-task learning. Despite promising, these additional components often add\ncomplexity to the training and inference process, contravening the efficient\ncharacterization of PEFT designed for. Considering this, we introduce an\ninnovative PEFT method, TeamLoRA, consisting of a collaboration and competition\nmodule for experts, and thus achieving the right balance of effectiveness and\nefficiency: (i) For collaboration, a novel knowledge-sharing and -organizing\nmechanism is devised to appropriately reduce the scale of matrix operations,\nthereby boosting the training and inference speed. (ii) For competition, we\npropose leveraging a game-theoretic interaction mechanism for experts,\nencouraging experts to transfer their domain-specific knowledge while facing\ndiverse downstream tasks, and thus enhancing the performance. By doing so,\nTeamLoRA elegantly connects the experts as a \"Team\" with internal collaboration\nand competition, enabling a faster and more accurate PEFT paradigm for\nmulti-task learning. To validate the superiority of TeamLoRA, we curate a\ncomprehensive multi-task evaluation(CME) benchmark to thoroughly assess the\ncapability of multi-task learning. Experiments conducted on our CME and other\nbenchmarks indicate the effectiveness and efficiency of TeamLoRA. Our project\nis available at https://github.com/Lin-Tianwei/TeamLoRA.",
      "tldr_zh": "该论文针对 Parameter-Efficient Fine-Tuning (PEFT) 方法如 LoRA 在多任务场景下性能不足的问题，提出了一种创新方法 TeamLoRA，通过专家协作和竞争机制提升多任务学习能力。具体而言，TeamLoRA 引入知识共享与组织模块来减少矩阵操作规模，提高训练和推理速度，以及博弈论交互机制鼓励专家间知识转移，从而平衡有效性和效率。在自定义的综合多任务评估 (CME) 基准和其他基准上的实验表明，TeamLoRA 显著提高了性能和速度。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.09856v1",
      "published_date": "2024-08-19 09:58:53 UTC",
      "updated_date": "2024-08-19 09:58:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:41:38.333693"
    },
    {
      "arxiv_id": "2408.09853v1",
      "title": "Self-Directed Turing Test for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Weiqi Wu",
        "Hongqiu Wu",
        "Hai Zhao"
      ],
      "abstract": "The Turing test examines whether AIs can exhibit human-like behaviour in\nnatural language conversations. Traditional Turing tests adopt a rigid dialogue\nformat where each participant sends only one message each time and require\ncontinuous human involvement to direct the entire interaction with the test\nsubject. This fails to reflect a natural conversational style and hinders the\nevaluation of Large Language Models (LLMs) in complex and prolonged dialogues.\nThis paper proposes the Self-Directed Turing Test, which extends the original\ntest with a burst dialogue format, allowing more dynamic exchanges by multiple\nconsecutive messages. It further efficiently reduces human workload by having\nthe LLM self-direct the majority of the test process, iteratively generating\ndialogues that simulate its interaction with humans. With the pseudo-dialogue\nhistory, the model then engages in a shorter dialogue with a human, which is\npaired with a human-human conversation on the same topic to be judged using\nquestionnaires. We introduce the X-Turn Pass-Rate metric to assess the human\nlikeness of LLMs across varying durations. While LLMs like GPT-4 initially\nperform well, achieving pass rates of 51.9% and 38.9% during 3 turns and 10\nturns of dialogues respectively, their performance drops as the dialogue\nprogresses, which underscores the difficulty in maintaining consistency in the\nlong term.",
      "tldr_zh": "这篇论文针对传统 Turing 测试的僵化格式和对人类参与的依赖，提出了 Self-Directed Turing Test，用于评估 Large Language Models (LLMs) 在复杂长对话中的表现。该方法采用 burst dialogue format 允许多条连续消息交换，并让 LLMs 自行生成模拟人类互动的伪对话历史，从而减少人类工作量，并通过问卷与人类-人类对话进行比较。论文引入 X-Turn Pass-Rate 指标评估不同对话长度的表现，结果显示 GPT-4 在 3 回合对话中通过率达 51.9%，但在 10 回合时降至 38.9%，突显了 LLMs 在长期对话中维持一致性的困难。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.09853v1",
      "published_date": "2024-08-19 09:57:28 UTC",
      "updated_date": "2024-08-19 09:57:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:41:51.189139"
    },
    {
      "arxiv_id": "2408.09849v2",
      "title": "Importance Weighting Can Help Large Language Models Self-Improve",
      "title_zh": "重要性加权可以帮助大型语言模型自我改进",
      "authors": [
        "Chunyang Jiang",
        "Chi-min Chan",
        "Wei Xue",
        "Qifeng Liu",
        "Yike Guo"
      ],
      "abstract": "Large language models (LLMs) have shown remarkable capability in numerous\ntasks and applications. However, fine-tuning LLMs using high-quality datasets\nunder external supervision remains prohibitively expensive. In response, LLM\nself-improvement approaches have been vibrantly developed recently. The typical\nparadigm of LLM self-improvement involves training LLM on self-generated data,\npart of which may be detrimental and should be filtered out due to the unstable\ndata quality. While current works primarily employs filtering strategies based\non answer correctness, in this paper, we demonstrate that filtering out correct\nbut with high distribution shift extent (DSE) samples could also benefit the\nresults of self-improvement. Given that the actual sample distribution is\nusually inaccessible, we propose a new metric called DS weight to approximate\nDSE, inspired by the Importance Weighting methods. Consequently, we integrate\nDS weight with self-consistency to comprehensively filter the self-generated\nsamples and fine-tune the language model. Experiments show that with only a\ntiny valid set (up to 5\\% size of the training set) to compute DS weight, our\napproach can notably promote the reasoning ability of current LLM\nself-improvement methods. The resulting performance is on par with methods that\nrely on external supervision from pre-trained reward models.",
      "tldr_zh": "本研究探讨了如何通过重要性加权（Importance Weighting）提升大型语言模型（LLMs）的自提升能力，解决自生成数据中不稳定质量问题。论文提出DS weight指标来近似分布偏移程度（DSE），并结合自一致性（self-consistency）过滤出正确但偏移严重的样本，从而优化训练过程。实验结果显示，仅使用少量有效集（训练集的5%）计算DS weight，即可显著提高LLMs的推理能力，其性能可与依赖外部监督的预训练奖励模型方法相当。总的来说，这一方法为更高效的LLMs自提升提供了新途径。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.09849v2",
      "published_date": "2024-08-19 09:51:02 UTC",
      "updated_date": "2024-12-12 14:56:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:42:00.872579"
    },
    {
      "arxiv_id": "2408.09841v2",
      "title": "Demystifying Reinforcement Learning in Production Scheduling via Explainable AI",
      "title_zh": "翻译失败",
      "authors": [
        "Daniel Fischer",
        "Hannah M. Hüsener",
        "Felix Grumbach",
        "Lukas Vollenkemper",
        "Arthur Müller",
        "Pascal Reusch"
      ],
      "abstract": "Deep Reinforcement Learning (DRL) is a frequently employed technique to solve\nscheduling problems. Although DRL agents ace at delivering viable results in\nshort computing times, their reasoning remains opaque. We conduct a case study\nwhere we systematically apply two explainable AI (xAI) frameworks, namely SHAP\n(DeepSHAP) and Captum (Input x Gradient), to describe the reasoning behind\nscheduling decisions of a specialized DRL agent in a flow production. We find\nthat methods in the xAI literature lack falsifiability and consistent\nterminology, do not adequately consider domain-knowledge, the target audience\nor real-world scenarios, and typically provide simple input-output explanations\nrather than causal interpretations. To resolve this issue, we introduce a\nhypotheses-based workflow. This approach enables us to inspect whether\nexplanations align with domain knowledge and match the reward hypotheses of the\nagent. We furthermore tackle the challenge of communicating these insights to\nthird parties by tailoring hypotheses to the target audience, which can serve\nas interpretations of the agent's behavior after verification. Our proposed\nworkflow emphasizes the repeated verification of explanations and may be\napplicable to various DRL-based scheduling use cases.",
      "tldr_zh": "这篇论文探讨了Deep Reinforcement Learning (DRL) 在生产调度中的不透明问题，通过Explainable AI (xAI) 框架如SHAP (DeepSHAP) 和Captum (Input x Gradient) 来分析DRL代理的决策过程。研究发现，现有的xAI方法缺乏可证伪性、一致术语，且未充分考虑领域知识、目标受众或真实场景，通常仅提供简单输入-输出解释而非因果解释。为解决这些问题，作者引入了一个基于假设的(hypotheses-based)工作流程，用于验证解释是否与领域知识和代理的奖励假设一致，并通过针对受众定制假设来有效沟通代理行为。该工作流程强调解释的反复验证，并可扩展应用于各种DRL-based的调度用例。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.09841v2",
      "published_date": "2024-08-19 09:39:01 UTC",
      "updated_date": "2024-08-30 10:28:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:42:15.627052"
    },
    {
      "arxiv_id": "2408.09839v2",
      "title": "Segment-Anything Models Achieve Zero-shot Robustness in Autonomous Driving",
      "title_zh": "翻译失败",
      "authors": [
        "Jun Yan",
        "Pengyu Wang",
        "Danni Wang",
        "Weiquan Huang",
        "Daniel Watzenig",
        "Huilin Yin"
      ],
      "abstract": "Semantic segmentation is a significant perception task in autonomous driving.\nIt suffers from the risks of adversarial examples. In the past few years, deep\nlearning has gradually transitioned from convolutional neural network (CNN)\nmodels with a relatively small number of parameters to foundation models with a\nhuge number of parameters. The segment-anything model (SAM) is a generalized\nimage segmentation framework that is capable of handling various types of\nimages and is able to recognize and segment arbitrary objects in an image\nwithout the need to train on a specific object. It is a unified model that can\nhandle diverse downstream tasks, including semantic segmentation, object\ndetection, and tracking. In the task of semantic segmentation for autonomous\ndriving, it is significant to study the zero-shot adversarial robustness of\nSAM. Therefore, we deliver a systematic empirical study on the robustness of\nSAM without additional training. Based on the experimental results, the\nzero-shot adversarial robustness of the SAM under the black-box corruptions and\nwhite-box adversarial attacks is acceptable, even without the need for\nadditional training. The finding of this study is insightful in that the\ngigantic model parameters and huge amounts of training data lead to the\nphenomenon of emergence, which builds a guarantee of adversarial robustness.\nSAM is a vision foundation model that can be regarded as an early prototype of\nan artificial general intelligence (AGI) pipeline. In such a pipeline, a\nunified model can handle diverse tasks. Therefore, this research not only\ninspects the impact of vision foundation models on safe autonomous driving but\nalso provides a perspective on developing trustworthy AGI. The code is\navailable at: https://github.com/momo1986/robust_sam_iv.",
      "tldr_zh": "该论文探讨了Segment-Anything Model (SAM) 在自动驾驶语义分割任务中的零样本对抗鲁棒性，强调了SAM 作为通用图像分割框架的优势，能处理各种图像和任务而无需特定训练。研究通过系统实证实验发现，SAM 在黑盒 corruptions 和白盒 adversarial attacks 下表现出可接受的鲁棒性，这归因于其巨大参数量和海量训练数据引发的emergence 现象。最终，该工作不仅为安全自动驾驶提供洞见，还为开发可信赖的artificial general intelligence (AGI) 管道提供了新视角。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to IAVVC 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.09839v2",
      "published_date": "2024-08-19 09:35:51 UTC",
      "updated_date": "2024-10-01 07:50:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:42:26.971717"
    },
    {
      "arxiv_id": "2408.09834v3",
      "title": "Minor DPO reject penalty to increase training robustness",
      "title_zh": "翻译失败",
      "authors": [
        "Shiming Xie",
        "Hong Chen",
        "Fred Yu",
        "Zeye Sun",
        "Xiuyu Wu",
        "Yingfan Hu"
      ],
      "abstract": "Learning from human preference is a paradigm used in large-scale language\nmodel (LLM) fine-tuning step to better align pretrained LLM to human preference\nfor downstream task. In the past it uses reinforcement learning from human\nfeedback (RLHF) algorithm to optimize the LLM policy to align with these\npreferences and not to draft too far from the original model. Recently, Direct\nPreference Optimization (DPO) has been proposed to solve the alignment problem\nwith a simplified RL-free method. Using preference pairs of chosen and reject\ndata, DPO models the relative log probability as implicit reward function and\noptimize LLM policy using a simple binary cross entropy objective directly. DPO\nis quite straight forward and easy to be understood. It perform efficiently and\nwell in most cases. In this article, we analyze the working mechanism of\n$\\beta$ in DPO, disclose its syntax difference between RL algorithm and DPO,\nand understand the potential shortage brought by the DPO simplification. With\nthese insights, we propose MinorDPO, which is better aligned to the original RL\nalgorithm, and increase the stability of preference optimization process.",
      "tldr_zh": "本研究分析了Direct Preference Optimization (DPO)中β参数的机制及其与Reinforcement Learning from Human Feedback (RLHF)算法的语法差异，揭示了DPO简化过程可能带来的稳定性不足。作者提出MinorDPO方法，通过调整拒绝惩罚机制，使其更紧密地对齐原始RL算法，提升了LLM偏好优化的训练稳健性。实验结果表明，MinorDPO能有效解决DPO的潜在短板，为大型语言模型(LLM)微调提供更可靠的优化策略。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages, 19 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.09834v3",
      "published_date": "2024-08-19 09:29:31 UTC",
      "updated_date": "2024-08-30 13:54:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:42:37.402253"
    },
    {
      "arxiv_id": "2408.09825v1",
      "title": "TDNetGen: Empowering Complex Network Resilience Prediction with Generative Augmentation of Topology and Dynamics",
      "title_zh": "翻译失败",
      "authors": [
        "Chang Liu",
        "Jingtao Ding",
        "Yiwen Song",
        "Yong Li"
      ],
      "abstract": "Predicting the resilience of complex networks, which represents the ability\nto retain fundamental functionality amidst external perturbations or internal\nfailures, plays a critical role in understanding and improving real-world\ncomplex systems. Traditional theoretical approaches grounded in nonlinear\ndynamical systems rely on prior knowledge of network dynamics. On the other\nhand, data-driven approaches frequently encounter the challenge of insufficient\nlabeled data, a predicament commonly observed in real-world scenarios. In this\npaper, we introduce a novel resilience prediction framework for complex\nnetworks, designed to tackle this issue through generative data augmentation of\nnetwork topology and dynamics. The core idea is the strategic utilization of\nthe inherent joint distribution present in unlabeled network data, facilitating\nthe learning process of the resilience predictor by illuminating the\nrelationship between network topology and dynamics. Experiment results on three\nnetwork datasets demonstrate that our proposed framework TDNetGen can achieve\nhigh prediction accuracy up to 85%-95%. Furthermore, the framework still\ndemonstrates a pronounced augmentation capability in extreme low-data regimes,\nthereby underscoring its utility and robustness in enhancing the prediction of\nnetwork resilience. We have open-sourced our code in the following link,\nhttps://github.com/tsinghua-fib-lab/TDNetGen.",
      "tldr_zh": "这篇论文提出了TDNetGen框架，用于通过生成式数据增强网络拓扑和动态来提升复杂网络弹性预测的准确性。框架利用无标签网络数据的内在联合分布，揭示拓扑与动态之间的关系，从而帮助弹性预测器在数据不足的真实场景中进行有效学习。实验在三个网络数据集上实现了高达85%-95%的预测准确率，并在极端低数据环境下展示了显著的增强能力，为复杂系统韧性分析提供了鲁棒解决方案。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.09825v1",
      "published_date": "2024-08-19 09:20:31 UTC",
      "updated_date": "2024-08-19 09:20:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:42:49.809762"
    },
    {
      "arxiv_id": "2408.09819v1",
      "title": "CMoralEval: A Moral Evaluation Benchmark for Chinese Large Language Models",
      "title_zh": "CMoralEval：针对中文大语言模型的道德评估基准",
      "authors": [
        "Linhao Yu",
        "Yongqi Leng",
        "Yufei Huang",
        "Shang Wu",
        "Haixin Liu",
        "Xinmeng Ji",
        "Jiahui Zhao",
        "Jinwang Song",
        "Tingting Cui",
        "Xiaoqing Cheng",
        "Tao Liu",
        "Deyi Xiong"
      ],
      "abstract": "What a large language model (LLM) would respond in ethically relevant\ncontext? In this paper, we curate a large benchmark CMoralEval for morality\nevaluation of Chinese LLMs. The data sources of CMoralEval are two-fold: 1) a\nChinese TV program discussing Chinese moral norms with stories from the society\nand 2) a collection of Chinese moral anomies from various newspapers and\nacademic papers on morality. With these sources, we aim to create a moral\nevaluation dataset characterized by diversity and authenticity. We develop a\nmorality taxonomy and a set of fundamental moral principles that are not only\nrooted in traditional Chinese culture but also consistent with contemporary\nsocietal norms. To facilitate efficient construction and annotation of\ninstances in CMoralEval, we establish a platform with AI-assisted instance\ngeneration to streamline the annotation process. These help us curate\nCMoralEval that encompasses both explicit moral scenarios (14,964 instances)\nand moral dilemma scenarios (15,424 instances), each with instances from\ndifferent data sources. We conduct extensive experiments with CMoralEval to\nexamine a variety of Chinese LLMs. Experiment results demonstrate that\nCMoralEval is a challenging benchmark for Chinese LLMs. The dataset is publicly\navailable at \\url{https://github.com/tjunlp-lab/CMoralEval}.",
      "tldr_zh": "这篇论文提出了 CMoralEval，一个用于评估中文大语言模型(LLMs)的道德表现基准数据集，旨在通过多样化和真实的社会故事考察模型在道德情境中的响应。数据集基于中国电视节目和社会道德异常案例构建，涵盖显性道德场景(14,964 实例)和道德困境场景(15,424 实例)，并采用道德分类法、基本道德原则以及 AI 辅助平台来简化实例生成和标注。实验结果显示，CMoralEval 对各种中文 LLMs 构成挑战，突显了模型在道德评估上的不足，该数据集已公开在 GitHub 上可用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by ACL 2024 (Findings)",
      "pdf_url": "http://arxiv.org/pdf/2408.09819v1",
      "published_date": "2024-08-19 09:15:35 UTC",
      "updated_date": "2024-08-19 09:15:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:43:04.569660"
    },
    {
      "arxiv_id": "2408.09817v1",
      "title": "Contextual Dual Learning Algorithm with Listwise Distillation for Unbiased Learning to Rank",
      "title_zh": "翻译失败",
      "authors": [
        "Lulu Yu",
        "Keping Bi",
        "Shiyu Ni",
        "Jiafeng Guo"
      ],
      "abstract": "Unbiased Learning to Rank (ULTR) aims to leverage biased implicit user\nfeedback (e.g., click) to optimize an unbiased ranking model. The effectiveness\nof the existing ULTR methods has primarily been validated on synthetic\ndatasets. However, their performance on real-world click data remains unclear.\nRecently, Baidu released a large publicly available dataset of their web search\nlogs. Subsequently, the NTCIR-17 ULTRE-2 task released a subset dataset\nextracted from it. We conduct experiments on commonly used or effective ULTR\nmethods on this subset to determine whether they maintain their effectiveness.\nIn this paper, we propose a Contextual Dual Learning Algorithm with Listwise\nDistillation (CDLA-LD) to simultaneously address both position bias and\ncontextual bias. We utilize a listwise-input ranking model to obtain\nreconstructed feature vectors incorporating local contextual information and\nemploy the Dual Learning Algorithm (DLA) method to jointly train this ranking\nmodel and a propensity model to address position bias. As this ranking model\nlearns the interaction information within the documents list of the training\nset, to enhance the ranking model's generalization ability, we additionally\ntrain a pointwise-input ranking model to learn the listwise-input ranking\nmodel's capability for relevance judgment in a listwise manner. Extensive\nexperiments and analysis confirm the effectiveness of our approach.",
      "tldr_zh": "该论文针对 Unbiased Learning to Rank (ULTR) 问题，提出了一种 Contextual Dual Learning Algorithm with Listwise Distillation (CDLA-LD) 方法，以利用偏置的隐式用户反馈（如点击）优化无偏排序模型，同时处理位置偏置和上下文偏置。方法通过 listwise-input 排名模型获取包含本地上下文信息的重构特征向量，并采用 Dual Learning Algorithm (DLA) 联合训练排名模型和倾向性模型，以提升模型的准确性。为增强泛化能力，作者进一步训练了一个 pointwise-input 排名模型，通过 listwise distillation 学习 listwise-input 模型的相关性判断。实验在 Baidu 搜索日志和 NTCIR-17 ULTRE-2 数据集上证实，CDLA-LD 显著提高了 ULTR 方法的有效性。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "12 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.09817v1",
      "published_date": "2024-08-19 09:13:52 UTC",
      "updated_date": "2024-08-19 09:13:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:43:15.691893"
    },
    {
      "arxiv_id": "2408.09807v3",
      "title": "Reset-free Reinforcement Learning with World Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zhao Yang",
        "Thomas M. Moerland",
        "Mike Preuss",
        "Aske Plaat",
        "Edward S. Hu"
      ],
      "abstract": "Reinforcement learning (RL) is an appealing paradigm for training intelligent\nagents, enabling policy acquisition from the agent's own autonomously acquired\nexperience. However, the training process of RL is far from automatic,\nrequiring extensive human effort to reset the agent and environments. To tackle\nthe challenging reset-free setting, we first demonstrate the superiority of\nmodel-based (MB) RL methods in such setting, showing that a straightforward\nadaptation of MBRL can outperform all the prior state-of-the-art methods while\nrequiring less supervision. We then identify limitations inherent to this\ndirect extension and propose a solution called model-based reset-free\n(MoReFree) agent, which further enhances the performance. MoReFree adapts two\nkey mechanisms, exploration and policy learning, to handle reset-free tasks by\nprioritizing task-relevant states. It exhibits superior data-efficiency across\nvarious reset-free tasks without access to environmental reward or\ndemonstrations while significantly outperforming privileged baselines that\nrequire supervision. Our findings suggest model-based methods hold significant\npromise for reducing human effort in RL. Website:\nhttps://yangzhao-666.github.io/morefree",
      "tldr_zh": "该论文探讨了无重置强化学习（Reinforcement Learning），旨在减少人为干预，通过基于模型（MBRL）的世界模型（World Models）方法实现代理从自主经验中学习。作者提出MoReFree代理，改进了探索和策略学习机制，优先处理任务相关状态，从而提升数据效率。实验结果显示，MoReFree在各种无重置任务中无需环境奖励或演示即可显著优于基线方法，证明基于模型的方法能大幅降低RL的人工监督需求。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.09807v3",
      "published_date": "2024-08-19 08:56:00 UTC",
      "updated_date": "2025-02-22 22:27:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:43:26.419137"
    },
    {
      "arxiv_id": "2408.09794v2",
      "title": "AutoML-guided Fusion of Entity and LLM-based Representations for Document Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Boshko Koloski",
        "Senja Pollak",
        "Roberto Navigli",
        "Blaž Škrlj"
      ],
      "abstract": "Large semantic knowledge bases are grounded in factual knowledge. However,\nrecent approaches to dense text representations (i.e. embeddings) do not\nefficiently exploit these resources. Dense and robust representations of\ndocuments are essential for effectively solving downstream classification and\nretrieval tasks. This work demonstrates that injecting embedded information\nfrom knowledge bases can augment the performance of contemporary Large Language\nModel (LLM)-based representations for the task of text classification. Further,\nby considering automated machine learning (AutoML) with the fused\nrepresentation space, we demonstrate it is possible to improve classification\naccuracy even if we use low-dimensional projections of the original\nrepresentation space obtained via efficient matrix factorization. This result\nshows that significantly faster classifiers can be achieved with minimal or no\nloss in predictive performance, as demonstrated using five strong LLM baselines\non six diverse real-life datasets. The code is freely available at\n\\url{https://github.com/bkolosk1/bablfusion.git}.",
      "tldr_zh": "这篇论文提出了一种AutoML-guided方法，通过融合实体表示和LLM-based表示来增强文档分类性能。具体而言，研究注入知识库的嵌入信息（embeddings）来补充LLM表示的不足，并利用AutoML优化融合空间，同时通过矩阵分解（matrix factorization）实现低维投影以加速分类器。实验在五个LLM基线和六个真实数据集上表明，这种方法显著提高了分类准确率，同时保持了最小性能损失。代码已在GitHub上开源，方便进一步应用。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at the 2024 Discovery Science Conference, oral presentation\n  track",
      "pdf_url": "http://arxiv.org/pdf/2408.09794v2",
      "published_date": "2024-08-19 08:41:40 UTC",
      "updated_date": "2024-09-30 14:02:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:43:38.385687"
    },
    {
      "arxiv_id": "2408.10287v3",
      "title": "Recognizing Beam Profiles from Silicon Photonics Gratings using Transformer Model",
      "title_zh": "使用 Transformer 模型识别硅光子学",
      "authors": [
        "Yu Dian Lim",
        "Hong Yu Li",
        "Simon Chun Kiat Goh",
        "Xiangyu Wang",
        "Peng Zhao",
        "Chuan Seng Tan"
      ],
      "abstract": "Over the past decade, there has been extensive work in developing integrated\nsilicon photonics (SiPh) gratings for the optical addressing of trapped ion\nqubits in the ion trap quantum computing community. However, when viewing beam\nprofiles from infrared (IR) cameras, it is often difficult to determine the\ncorresponding heights where the beam profiles are located. In this work, we\ndeveloped transformer models to recognize the corresponding height categories\nof beam profiles of light from SiPh gratings. The model is trained using two\ntechniques: (1) input patches, and (2) input sequence. For model trained with\ninput patches, the model achieved recognition accuracy of 0.938. Meanwhile,\nmodel trained with input sequence shows lower accuracy of 0.895. However, when\nrepeating the model-training 150 cycles, model trained with input patches shows\ninconsistent accuracy ranges between 0.445 to 0.959, while model trained with\ninput sequence exhibit higher accuracy values between 0.789 to 0.936. The\nobtained outcomes can be expanded to various applications, including\nauto-focusing of light beam and auto-adjustment of z-axis stage to acquire\ndesired beam profiles.",
      "tldr_zh": "本文提出了一种使用Transformer Model来识别硅光子学(SiPh)光栅光束轮廓对应高度类别的方法，以解决从红外相机观察时难以确定光束高度的问题。模型通过两种训练技术进行训练：输入补丁和输入序列，其中输入补丁技术实现了0.938的准确率，而输入序列技术达到0.895的准确率。重复训练150次后，输入补丁方法的准确率不稳定（范围0.445-0.959），而输入序列方法表现出更高的稳定性（范围0.789-0.936）。该研究的结果可扩展到光束自动聚焦和z轴舞台自动调整等应用中。",
      "categories": [
        "physics.optics",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "physics.optics",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.10287v3",
      "published_date": "2024-08-19 08:33:16 UTC",
      "updated_date": "2024-08-22 05:24:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:43:51.557547"
    },
    {
      "arxiv_id": "2408.10286v3",
      "title": "GARLIC: GPT-Augmented Reinforcement Learning with Intelligent Control for Vehicle Dispatching",
      "title_zh": "GARLIC：GPT增强的强化学习，带有智能控制，用于车辆调度",
      "authors": [
        "Xiao Han",
        "Zijian Zhang",
        "Xiangyu Zhao",
        "Yuanshao Zhu",
        "Guojiang Shen",
        "Xiangjie Kong",
        "Xuetao Wei",
        "Liqiang Nie",
        "Jieping Ye"
      ],
      "abstract": "As urban residents demand higher travel quality, vehicle dispatch has become\na critical component of online ride-hailing services. However, current vehicle\ndispatch systems struggle to navigate the complexities of urban traffic\ndynamics, including unpredictable traffic conditions, diverse driver behaviors,\nand fluctuating supply and demand patterns. These challenges have resulted in\ntravel difficulties for passengers in certain areas, while many drivers in\nother areas are unable to secure orders, leading to a decline in the overall\nquality of urban transportation services. To address these issues, this paper\nintroduces GARLIC: a framework of GPT-Augmented Reinforcement Learning with\nIntelligent Control for vehicle dispatching. GARLIC utilizes multiview graphs\nto capture hierarchical traffic states, and learns a dynamic reward function\nthat accounts for individual driving behaviors. The framework further\nintegrates a GPT model trained with a custom loss function to enable\nhigh-precision predictions and optimize dispatching policies in real-world\nscenarios. Experiments conducted on two real-world datasets demonstrate that\nGARLIC effectively aligns with driver behaviors while reducing the empty load\nrate of vehicles.",
      "tldr_zh": "该研究针对城市交通的复杂性（如不可预测的交通条件、多样化的驾驶行为和波动性的供需模式）提出GARLIC框架，即GPT-Augmented Reinforcement Learning with Intelligent Control，用于优化车辆调度。GARLIC利用multiview graphs捕捉分层的交通状态，并学习一个动态奖励函数来考虑个体驾驶行为，同时整合GPT模型通过自定义损失函数实现高精度预测和调度策略优化。实验在两个真实数据集上表明，该框架能有效与驾驶行为对齐，并显著降低车辆的空载率，从而提升整体城市交通服务质量。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2408.10286v3",
      "published_date": "2024-08-19 08:23:38 UTC",
      "updated_date": "2024-12-16 00:11:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:44:02.048873"
    },
    {
      "arxiv_id": "2408.09785v2",
      "title": "GoNoGo: An Efficient LLM-based Multi-Agent System for Streamlining Automotive Software Release Decision-Making",
      "title_zh": "翻译失败",
      "authors": [
        "Arsham Gholamzadeh Khoee",
        "Yinan Yu",
        "Robert Feldt",
        "Andris Freimanis",
        "Patrick Andersson Rhodin",
        "Dhasarathy Parthasarathy"
      ],
      "abstract": "Traditional methods for making software deployment decisions in the\nautomotive industry typically rely on manual analysis of tabular software test\ndata. These methods often lead to higher costs and delays in the software\nrelease cycle due to their labor-intensive nature. Large Language Models (LLMs)\npresent a promising solution to these challenges. However, their application\ngenerally demands multiple rounds of human-driven prompt engineering, which\nlimits their practical deployment, particularly for industrial end-users who\nneed reliable and efficient results. In this paper, we propose GoNoGo, an LLM\nagent system designed to streamline automotive software deployment while\nmeeting both functional requirements and practical industrial constraints.\nUnlike previous systems, GoNoGo is specifically tailored to address\ndomain-specific and risk-sensitive systems. We evaluate GoNoGo's performance\nacross different task difficulties using zero-shot and few-shot examples taken\nfrom industrial practice. Our results show that GoNoGo achieves a 100% success\nrate for tasks up to Level 2 difficulty with 3-shot examples, and maintains\nhigh performance even for more complex tasks. We find that GoNoGo effectively\nautomates decision-making for simpler tasks, significantly reducing the need\nfor manual intervention. In summary, GoNoGo represents an efficient and\nuser-friendly LLM-based solution currently employed in our industrial partner's\ncompany to assist with software release decision-making, supporting more\ninformed and timely decisions in the release process for risk-sensitive vehicle\nsystems.",
      "tldr_zh": "本文提出 GoNoGo，一种基于 LLM（Large Language Models）的多代理系统，旨在简化汽车软件部署决策过程，解决传统手动分析方法的成本高和延误问题。该系统针对领域特定和风险敏感系统设计，通过零-shot 和 few-shot 示例进行评估，在难度级别 2 的任务中实现 100% 成功率，并显著减少手动干预。实验结果显示，GoNoGo 适用于更复杂任务，并已在工业伙伴公司实际应用，支持更高效和明智的软件发布决策。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.09785v2",
      "published_date": "2024-08-19 08:22:20 UTC",
      "updated_date": "2024-09-29 09:46:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:44:14.364837"
    },
    {
      "arxiv_id": "2408.09781v1",
      "title": "Neural Horizon Model Predictive Control -- Increasing Computational Efficiency with Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Hendrik Alsmeier",
        "Anton Savchenko",
        "Rolf Findeisen"
      ],
      "abstract": "The expansion in automation of increasingly fast applications and low-power\nedge devices poses a particular challenge for optimization based control\nalgorithms, like model predictive control. Our proposed machine-learning\nsupported approach addresses this by utilizing a feed-forward neural network to\nreduce the computation load of the online-optimization. We propose\napproximating part of the problem horizon, while maintaining safety guarantees\n-- constraint satisfaction -- via the remaining optimization part of the\ncontroller. The approach is validated in simulation, demonstrating an\nimprovement in computational efficiency, while maintaining guarantees and\nnear-optimal performance. The proposed MPC scheme can be applied to a wide\nrange of applications, including those requiring a rapid control response, such\nas robotics and embedded applications with limited computational resources.",
      "tldr_zh": "该论文提出了Neural Horizon Model Predictive Control方法，使用前馈神经网络(feed-forward neural network)来减少模型预测控制(MPC)的在线优化计算负载。方法通过神经网络近似部分问题地平线，同时保留剩余优化部分以确保约束满足和安全保证。在模拟实验中，该方案显著提高了计算效率，同时保持了近似最优性能，并适用于需要快速响应应用的领域，如机器人和嵌入式系统。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.LG",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "6 pages, 4 figures, 4 tables, American Control Conference (ACC) 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.09781v1",
      "published_date": "2024-08-19 08:13:37 UTC",
      "updated_date": "2024-08-19 08:13:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:44:26.380673"
    },
    {
      "arxiv_id": "2408.09768v3",
      "title": "MalLight: Influence-Aware Coordinated Traffic Signal Control for Traffic Signal Malfunctions",
      "title_zh": "翻译失败",
      "authors": [
        "Qinchen Yang",
        "Zejun Xie",
        "Hua Wei",
        "Desheng Zhang",
        "Yu Yang"
      ],
      "abstract": "Urban traffic is subject to disruptions that cause extended waiting time and\nsafety issues at signalized intersections. While numerous studies have\naddressed the issue of intelligent traffic systems in the context of various\ndisturbances, traffic signal malfunction, a common real-world occurrence with\nsignificant repercussions, has received comparatively limited attention. The\nprimary objective of this research is to mitigate the adverse effects of\ntraffic signal malfunction, such as traffic congestion and collision, by\noptimizing the control of neighboring functioning signals. To achieve this\ngoal, this paper presents a novel traffic signal control framework (MalLight),\nwhich leverages an Influence-aware State Aggregation Module (ISAM) and an\nInfluence-aware Reward Aggregation Module (IRAM) to achieve coordinated control\nof surrounding traffic signals. To the best of our knowledge, this study\npioneers the application of a Reinforcement Learning(RL)-based approach to\naddress the challenges posed by traffic signal malfunction. Empirical\ninvestigations conducted on real-world datasets substantiate the superior\nperformance of our proposed methodology over conventional and deep\nlearning-based alternatives in the presence of signal malfunction, with\nreduction of throughput alleviated by as much as 48.6$\\%$.",
      "tldr_zh": "该研究针对交通信号故障导致的拥堵和安全问题，提出了一种新型框架MalLight，用于优化附近正常信号灯的协调控制。MalLight整合了Influence-aware State Aggregation Module (ISAM)和Influence-aware Reward Aggregation Module (IRAM)，通过强化学习 (RL) 基于方法来评估和聚合信号影响，实现高效响应。实验结果显示，该框架在真实数据集上优于传统和深度学习基准，成功减轻了高达48.6%的交通量损失，为处理信号故障提供了创新解决方案。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Paper accepted to CIKM24 Full Research track",
      "pdf_url": "http://arxiv.org/pdf/2408.09768v3",
      "published_date": "2024-08-19 07:57:13 UTC",
      "updated_date": "2024-09-13 03:10:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:44:37.671852"
    },
    {
      "arxiv_id": "2408.09767v1",
      "title": "Propagating the prior from shallow to deep with a pre-trained velocity-model Generative Transformer network",
      "title_zh": "翻译失败",
      "authors": [
        "Randy Harsuko",
        "Shijun Cheng",
        "Tariq Alkhalifah"
      ],
      "abstract": "Building subsurface velocity models is essential to our goals in utilizing\nseismic data for Earth discovery and exploration, as well as monitoring. With\nthe dawn of machine learning, these velocity models (or, more precisely, their\ndistribution) can be stored accurately and efficiently in a generative model.\nThese stored velocity model distributions can be utilized to regularize or\nquantify uncertainties in inverse problems, like full waveform inversion.\nHowever, most generators, like normalizing flows or diffusion models, treat the\nimage (velocity model) uniformly, disregarding spatial dependencies and\nresolution changes with respect to the observation locations. To address this\nweakness, we introduce VelocityGPT, a novel implementation that utilizes\nTransformer decoders trained autoregressively to generate a velocity model from\nshallow subsurface to deep. Owing to the fact that seismic data are often\nrecorded on the Earth's surface, a top-down generator can utilize the inverted\ninformation in the shallow as guidance (prior) to generating the deep. To\nfacilitate the implementation, we use an additional network to compress the\nvelocity model. We also inject prior information, like well or structure\n(represented by a migration image) to generate the velocity model. Using\nsynthetic data, we demonstrate the effectiveness of VelocityGPT as a promising\napproach in generative model applications for seismic velocity model building.",
      "tldr_zh": "该论文提出 VelocityGPT，一种基于预训练的 Transformer 网络，用于从浅层到深层生成地下速度模型，从而解决传统生成模型忽略空间依赖性和分辨率变化的问题。该模型采用自回归训练，利用浅层信息作为深层生成的先验，并通过额外网络压缩模型和注入先验信息（如井数据或迁移图像）来提升生成精度。实验在合成数据上证明了 VelocityGPT 的有效性，为地震数据逆问题中的正则化和不确定性量化提供了有前景的方法。",
      "categories": [
        "physics.geo-ph",
        "cs.AI",
        "physics.comp-ph"
      ],
      "primary_category": "physics.geo-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.09767v1",
      "published_date": "2024-08-19 07:56:43 UTC",
      "updated_date": "2024-08-19 07:56:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:44:52.094198"
    },
    {
      "arxiv_id": "2408.09764v1",
      "title": "Event Stream based Human Action Recognition: A High-Definition Benchmark Dataset and Algorithms",
      "title_zh": "基于事件流的人类动作识别：一个高清基准数据集和算法",
      "authors": [
        "Xiao Wang",
        "Shiao Wang",
        "Pengpeng Shao",
        "Bo Jiang",
        "Lin Zhu",
        "Yonghong Tian"
      ],
      "abstract": "Human Action Recognition (HAR) stands as a pivotal research domain in both\ncomputer vision and artificial intelligence, with RGB cameras dominating as the\npreferred tool for investigation and innovation in this field. However, in\nreal-world applications, RGB cameras encounter numerous challenges, including\nlight conditions, fast motion, and privacy concerns. Consequently, bio-inspired\nevent cameras have garnered increasing attention due to their advantages of low\nenergy consumption, high dynamic range, etc. Nevertheless, most existing\nevent-based HAR datasets are low resolution ($346 \\times 260$). In this paper,\nwe propose a large-scale, high-definition ($1280 \\times 800$) human action\nrecognition dataset based on the CeleX-V event camera, termed CeleX-HAR. It\nencompasses 150 commonly occurring action categories, comprising a total of\n124,625 video sequences. Various factors such as multi-view, illumination,\naction speed, and occlusion are considered when recording these data. To build\na more comprehensive benchmark dataset, we report over 20 mainstream HAR models\nfor future works to compare. In addition, we also propose a novel Mamba vision\nbackbone network for event stream based HAR, termed EVMamba, which equips the\nspatial plane multi-directional scanning and novel voxel temporal scanning\nmechanism. By encoding and mining the spatio-temporal information of event\nstreams, our EVMamba has achieved favorable results across multiple datasets.\nBoth the dataset and source code will be released on\n\\url{https://github.com/Event-AHU/CeleX-HAR}",
      "tldr_zh": "本论文提出一个大规模、高分辨率（1280 × 800）的CeleX-HAR数据集，用于基于事件流的Human Action Recognition (HAR)，以解决RGB相机在光线、快速运动和隐私等方面的挑战。该数据集涵盖150个常见动作类别、124,625个视频序列，并考虑了多视图、光照、动作速度和遮挡等因素，同时提供超过20个主流HAR模型的基准评估。作者还开发了新型骨干网络EVMamba，结合空间平面多向扫描和体素时间扫描机制来编码事件流的时空信息，在多个数据集上取得了优异性能。数据集和源代码已计划在GitHub上发布，为事件流HAR研究提供重要资源。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.CV",
      "comment": "In Peer Review",
      "pdf_url": "http://arxiv.org/pdf/2408.09764v1",
      "published_date": "2024-08-19 07:52:20 UTC",
      "updated_date": "2024-08-19 07:52:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:45:04.704163"
    },
    {
      "arxiv_id": "2408.09748v1",
      "title": "Revisiting Reciprocal Recommender Systems: Metrics, Formulation, and Method",
      "title_zh": "翻译失败",
      "authors": [
        "Chen Yang",
        "Sunhao Dai",
        "Yupeng Hou",
        "Wayne Xin Zhao",
        "Jun Xu",
        "Yang Song",
        "Hengshu Zhu"
      ],
      "abstract": "Reciprocal recommender systems~(RRS), conducting bilateral recommendations\nbetween two involved parties, have gained increasing attention for enhancing\nmatching efficiency. However, the majority of existing methods in the\nliterature still reuse conventional ranking metrics to separately assess the\nperformance on each side of the recommendation process. These methods overlook\nthe fact that the ranking outcomes of both sides collectively influence the\neffectiveness of the RRS, neglecting the necessity of a more holistic\nevaluation and a capable systemic solution.\n  In this paper, we systemically revisit the task of reciprocal recommendation,\nby introducing the new metrics, formulation, and method. Firstly, we propose\nfive new evaluation metrics that comprehensively and accurately assess the\nperformance of RRS from three distinct perspectives: overall coverage,\nbilateral stability, and balanced ranking. These metrics provide a more\nholistic understanding of the system's effectiveness and enable a comprehensive\nevaluation. Furthermore, we formulate the RRS from a causal perspective,\nformulating recommendations as bilateral interventions, which can better model\nthe decoupled effects of potential influencing factors. By utilizing the\npotential outcome framework, we further develop a model-agnostic causal\nreciprocal recommendation method that considers the causal effects of\nrecommendations. Additionally, we introduce a reranking strategy to maximize\nmatching outcomes, as measured by the proposed metrics. Extensive experiments\non two real-world datasets from recruitment and dating scenarios demonstrate\nthe effectiveness of our proposed metrics and approach. The code and dataset\nare available at: https://github.com/RUCAIBox/CRRS.",
      "tldr_zh": "这篇论文重新审视了互惠推荐系统 (RRS)，强调现有方法使用传统 ranking metrics 单独评估双侧推荐的不足，忽略了整体匹配效率。论文提出五个新的评估指标，从整体覆盖、双侧稳定性和平衡排名三个角度全面评估 RRS 性能。作者从因果视角重新制定 RRS，将推荐视为双侧干预，并开发了一个模型无关的因果推荐方法，结合重新排名策略来最大化匹配结果。在两个真实数据集（招聘和约会场景）上的实验验证了这些新指标和方法的有效性。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "KDD 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.09748v1",
      "published_date": "2024-08-19 07:21:02 UTC",
      "updated_date": "2024-08-19 07:21:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:45:15.515807"
    },
    {
      "arxiv_id": "2408.09746v1",
      "title": "Enhanced Cascade Prostate Cancer Classifier in mp-MRI Utilizing Recall Feedback Adaptive Loss and Prior Knowledge-Based Feature Extraction",
      "title_zh": "翻译失败",
      "authors": [
        "Kun Luo",
        "Bowen Zheng",
        "Shidong Lv",
        "Jie Tao",
        "Qiang Wei"
      ],
      "abstract": "Prostate cancer is the second most common cancer in males worldwide, and\nmpMRI is commonly used for diagnosis. However, interpreting mpMRI is\nchallenging and requires expertise from radiologists. This highlights the\nurgent need for automated grading in mpMRI. Existing studies lack integration\nof clinical prior information and suffer from uneven training sample\ndistribution due to prevalence. Therefore, we propose a solution that\nincorporates prior knowledge, addresses the issue of uneven medical sample\ndistribution, and maintains high interpretability in mpMRI. Firstly, we\nintroduce Prior Knowledge-Based Feature Extraction, which mathematically models\nthe PI-RADS criteria for prostate cancer as diagnostic information into model\ntraining. Secondly, we propose Adaptive Recall Feedback Loss to address the\nextremely imbalanced data problem. This method adjusts the training dynamically\nbased on accuracy and recall in the validation set, resulting in high accuracy\nand recall simultaneously in the testing set.Thirdly, we design an Enhanced\nCascade Prostate Cancer Classifier that classifies prostate cancer into\ndifferent levels in an interpretable way, which refines the classification\nresults and helps with clinical intervention. Our method is validated through\nexperiments on the PI-CAI dataset and outperforms other methods with a more\nbalanced result in both accuracy and recall rate.",
      "tldr_zh": "这篇论文针对 mp-MRI 中前列腺癌诊断的挑战，提出了一种 Enhanced Cascade Prostate Cancer Classifier，以解决临床先验信息缺失和样本分布不均的问题。论文引入 Prior Knowledge-Based Feature Extraction 方法，将 PI-RADS 标准数学建模并融入模型训练，提高了诊断的准确性和可解释性。同时，提出 Adaptive Recall Feedback Loss 动态调整训练过程，基于验证集的准确率和召回率平衡数据不平衡问题。实验在 PI-CAI 数据集上验证，该方法在准确率和召回率上均优于现有方法，为临床干预提供了更可靠的工具。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.09746v1",
      "published_date": "2024-08-19 07:18:06 UTC",
      "updated_date": "2024-08-19 07:18:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:45:30.240594"
    },
    {
      "arxiv_id": "2408.09743v1",
      "title": "R2GenCSR: Retrieving Context Samples for Large Language Model based X-ray Medical Report Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Xiao Wang",
        "Yuehang Li",
        "Fuling Wang",
        "Shiao Wang",
        "Chuanfu Li",
        "Bo Jiang"
      ],
      "abstract": "Inspired by the tremendous success of Large Language Models (LLMs), existing\nX-ray medical report generation methods attempt to leverage large models to\nachieve better performance. They usually adopt a Transformer to extract the\nvisual features of a given X-ray image, and then, feed them into the LLM for\ntext generation. How to extract more effective information for the LLMs to help\nthem improve final results is an urgent problem that needs to be solved.\nAdditionally, the use of visual Transformer models also brings high\ncomputational complexity. To address these issues, this paper proposes a novel\ncontext-guided efficient X-ray medical report generation framework.\nSpecifically, we introduce the Mamba as the vision backbone with linear\ncomplexity, and the performance obtained is comparable to that of the strong\nTransformer model. More importantly, we perform context retrieval from the\ntraining set for samples within each mini-batch during the training phase,\nutilizing both positively and negatively related samples to enhance feature\nrepresentation and discriminative learning. Subsequently, we feed the vision\ntokens, context information, and prompt statements to invoke the LLM for\ngenerating high-quality medical reports. Extensive experiments on three X-ray\nreport generation datasets (i.e., IU-Xray, MIMIC-CXR, CheXpert Plus) fully\nvalidated the effectiveness of our proposed model. The source code of this work\nwill be released on \\url{https://github.com/Event-AHU/Medical_Image_Analysis}.",
      "tldr_zh": "这篇论文提出 R2GenCSR 框架，用于基于 Large Language Models (LLMs) 的 X-ray 医学报告生成，旨在解决传统方法中视觉特征提取效率低下和高计算复杂度问题。具体地，该框架采用 Mamba 作为视觉骨干网络，实现线性复杂度，同时性能与 Transformer 相当；并在训练阶段从训练集检索正负相关上下文样本，以增强特征表示和判别学习。最终，将视觉标记、上下文信息和提示语句输入 LLMs 生成高质量报告。实验在 IU-Xray、MIMIC-CXR 和 CheXpert Plus 数据集上验证了该方法的有效性，并计划开源代码。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "In Peer Review",
      "pdf_url": "http://arxiv.org/pdf/2408.09743v1",
      "published_date": "2024-08-19 07:15:11 UTC",
      "updated_date": "2024-08-19 07:15:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:45:42.270687"
    },
    {
      "arxiv_id": "2408.09742v1",
      "title": "Paired Completion: Flexible Quantification of Issue-framing at Scale with LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Simon D Angus",
        "Lachlan O'Neill"
      ],
      "abstract": "Detecting and quantifying issue framing in textual discourse - the\nperspective one takes to a given topic (e.g. climate science vs. denialism,\nmisogyny vs. gender equality) - is highly valuable to a range of end-users from\nsocial and political scientists to program evaluators and policy analysts.\nHowever, conceptual framing is notoriously challenging for automated natural\nlanguage processing (NLP) methods since the words and phrases used by either\n`side' of an issue are often held in common, with only subtle stylistic\nflourishes separating their use. Here we develop and rigorously evaluate new\ndetection methods for issue framing and narrative analysis within large text\ndatasets. By introducing a novel application of next-token log probabilities\nderived from generative large language models (LLMs) we show that issue framing\ncan be reliably and efficiently detected in large corpora with only a few\nexamples of either perspective on a given issue, a method we call `paired\ncompletion'. Through 192 independent experiments over three novel, synthetic\ndatasets, we evaluate paired completion against prompt-based LLM methods and\nlabelled methods using traditional NLP and recent LLM contextual embeddings. We\nadditionally conduct a cost-based analysis to mark out the feasible set of\nperformant methods at production-level scales, and a model bias analysis.\nTogether, our work demonstrates a feasible path to scalable, accurate and\nlow-bias issue-framing in large corpora.",
      "tldr_zh": "该论文提出了一种名为Paired Completion的新方法，利用大型语言模型(LLMs)的next-token log probabilities来灵活量化大规模文本中的issue-framing，例如气候科学与否认主义等视角差异。该方法仅需少量示例即可高效检测框架，仅凭微妙风格差异进行区分，并在三个合成数据集上通过192个独立实验验证，与基于提示的LLM方法、传统NLP和LLM嵌入方法相比表现出色。论文还进行了成本分析和模型偏差分析，证明Paired Completion在可扩展性、准确性和低偏差方面提供了可行的路径。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "econ.GN",
        "q-fin.EC",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.09742v1",
      "published_date": "2024-08-19 07:14:15 UTC",
      "updated_date": "2024-08-19 07:14:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:45:52.039674"
    },
    {
      "arxiv_id": "2408.09734v1",
      "title": "Mutually-Aware Feature Learning for Few-Shot Object Counting",
      "title_zh": "翻译失败",
      "authors": [
        "Yerim Jeon",
        "Subeen Lee",
        "Jihwan Kim",
        "Jae-Pil Heo"
      ],
      "abstract": "Few-shot object counting has garnered significant attention for its\npracticality as it aims to count target objects in a query image based on given\nexemplars without the need for additional training. However, there is a\nshortcoming in the prevailing extract-and-match approach: query and exemplar\nfeatures lack interaction during feature extraction since they are extracted\nunaware of each other and later correlated based on similarity. This can lead\nto insufficient target awareness of the extracted features, resulting in target\nconfusion in precisely identifying the actual target when multiple class\nobjects coexist. To address this limitation, we propose a novel framework,\nMutually-Aware FEAture learning(MAFEA), which encodes query and exemplar\nfeatures mutually aware of each other from the outset. By encouraging\ninteraction between query and exemplar features throughout the entire pipeline,\nwe can obtain target-aware features that are robust to a multi-category\nscenario. Furthermore, we introduce a background token to effectively associate\nthe target region of query with exemplars and decouple its background region\nfrom them. Our extensive experiments demonstrate that our model reaches a new\nstate-of-the-art performance on the two challenging benchmarks, FSCD-LVIS and\nFSC-147, with a remarkably reduced degree of the target confusion problem.",
      "tldr_zh": "该论文针对 Few-Shot Object Counting 的问题，提出了一种新框架 Mutually-Aware FEAture learning (MAFEA)，以解决现有提取和匹配方法中查询图像与样本特征缺乏交互，导致多类对象时目标混淆的局限性。MAFEA 通过让查询和样本特征从一开始就相互感知，并在整个流程中进行互动，生成更 robust 的目标感知特征。框架还引入背景 token 来精确关联查询图像的目标区域并分离背景，从而提升在多类别场景下的性能。实验结果显示，该方法在 FSCD-LVIS 和 FSC-147 基准上达到了新的 state-of-the-art 表现，并显著减少了目标混淆问题。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Submitted to Pattern Recognition",
      "pdf_url": "http://arxiv.org/pdf/2408.09734v1",
      "published_date": "2024-08-19 06:46:24 UTC",
      "updated_date": "2024-08-19 06:46:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:46:03.656569"
    },
    {
      "arxiv_id": "2408.09720v1",
      "title": "Pedestrian Attribute Recognition: A New Benchmark Dataset and A Large Language Model Augmented Framework",
      "title_zh": "行人属性识别：一个新的基准数据集和一个大型语言模型增强框架",
      "authors": [
        "Jiandong Jin",
        "Xiao Wang",
        "Qian Zhu",
        "Haiyang Wang",
        "Chenglong Li"
      ],
      "abstract": "Pedestrian Attribute Recognition (PAR) is one of the indispensable tasks in\nhuman-centered research. However, existing datasets neglect different domains\n(e.g., environments, times, populations, and data sources), only conducting\nsimple random splits, and the performance of these datasets has already\napproached saturation. In the past five years, no large-scale dataset has been\nopened to the public. To address this issue, this paper proposes a new\nlarge-scale, cross-domain pedestrian attribute recognition dataset to fill the\ndata gap, termed MSP60K. It consists of 60,122 images and 57 attribute\nannotations across eight scenarios. Synthetic degradation is also conducted to\nfurther narrow the gap between the dataset and real-world challenging\nscenarios. To establish a more rigorous benchmark, we evaluate 17\nrepresentative PAR models under both random and cross-domain split protocols on\nour dataset. Additionally, we propose an innovative Large Language Model (LLM)\naugmented PAR framework, named LLM-PAR. This framework processes pedestrian\nimages through a Vision Transformer (ViT) backbone to extract features and\nintroduces a multi-embedding query Transformer to learn partial-aware features\nfor attribute classification. Significantly, we enhance this framework with LLM\nfor ensemble learning and visual feature augmentation. Comprehensive\nexperiments across multiple PAR benchmark datasets have thoroughly validated\nthe efficacy of our proposed framework. The dataset and source code\naccompanying this paper will be made publicly available at\n\\url{https://github.com/Event-AHU/OpenPAR}.",
      "tldr_zh": "本文提出一个新的大规模跨域数据集 MSP60K，用于 Pedestrian Attribute Recognition (PAR)，它包含 60,122 张图像、57 个属性标注和八个场景，还通过合成退化处理模拟真实世界挑战，以填补现有数据集的不足。作者评估了 17 个代表性 PAR 模型在随机和跨域分割协议下的性能，并引入了创新框架 LLM-PAR，该框架基于 Vision Transformer (ViT) 提取特征、多嵌入查询 Transformer 学习部分感知特征，并利用 Large Language Model (LLM) 进行集成学习和视觉特征增强。实验结果在多个 PAR 基准数据集上证明了 LLM-PAR 框架的有效性，数据集和源代码将公开以推动相关研究。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "MSP60K PAR Benchmark Dataset, LLM based PAR model, In Peer Review",
      "pdf_url": "http://arxiv.org/pdf/2408.09720v1",
      "published_date": "2024-08-19 06:19:31 UTC",
      "updated_date": "2024-08-19 06:19:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:46:15.700663"
    },
    {
      "arxiv_id": "2408.09715v2",
      "title": "HYDEN: Hyperbolic Density Representations for Medical Images and Reports",
      "title_zh": "翻译失败",
      "authors": [
        "Zhi Qiao",
        "Linbin Han",
        "Xiantong Zhen",
        "Jia-Hong Gao",
        "Zhen Qian"
      ],
      "abstract": "In light of the inherent entailment relations between images and text,\nhyperbolic point vector embeddings, leveraging the hierarchical modeling\nadvantages of hyperbolic space, have been utilized for visual semantic\nrepresentation learning. However, point vector embedding approaches fail to\naddress the issue of semantic uncertainty, where an image may have multiple\ninterpretations, and text may refer to different images, a phenomenon\nparticularly prevalent in the medical domain. Therefor, we propose\n\\textbf{HYDEN}, a novel hyperbolic density embedding based image-text\nrepresentation learning approach tailored for specific medical domain data.\nThis method integrates text-aware local features alongside global features from\nimages, mapping image-text features to density features in hyperbolic space via\nusing hyperbolic pseudo-Gaussian distributions. An encapsulation loss function\nis employed to model the partial order relations between image-text density\ndistributions. Experimental results demonstrate the interpretability of our\napproach and its superior performance compared to the baseline methods across\nvarious zero-shot tasks and different datasets.",
      "tldr_zh": "该研究提出HYDEN，一种基于超曲空间的密度嵌入方法，用于医学图像和报告的表示学习，以解决传统点向量嵌入无法处理语义不确定性的问题，例如图像的多重解释或文本的模糊对应。HYDEN通过整合图像的文本感知局部特征和全局特征，将这些特征映射到超曲空间中的密度特征，并使用超曲伪高斯分布及封装损失函数来建模图像-文本密度分布之间的部分顺序关系。实验结果表明，该方法在各种零样本任务和不同数据集上表现出色，优于基线方法，并提升了模型的可解释性。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "eess.IV"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.09715v2",
      "published_date": "2024-08-19 06:06:30 UTC",
      "updated_date": "2024-08-20 03:13:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:46:25.594767"
    },
    {
      "arxiv_id": "2408.09703v1",
      "title": "Partial-Multivariate Model for Forecasting",
      "title_zh": "部分多变量模型用于预测",
      "authors": [
        "Jaehoon Lee",
        "Hankook Lee",
        "Sungik Choi",
        "Sungjun Cho",
        "Moontae Lee"
      ],
      "abstract": "When solving forecasting problems including multiple time-series features,\nexisting approaches often fall into two extreme categories, depending on\nwhether to utilize inter-feature information: univariate and\ncomplete-multivariate models. Unlike univariate cases which ignore the\ninformation, complete-multivariate models compute relationships among a\ncomplete set of features. However, despite the potential advantage of\nleveraging the additional information, complete-multivariate models sometimes\nunderperform univariate ones. Therefore, our research aims to explore a middle\nground between these two by introducing what we term Partial-Multivariate\nmodels where a neural network captures only partial relationships, that is,\ndependencies within subsets of all features. To this end, we propose PMformer,\na Transformer-based partial-multivariate model, with its training algorithm. We\ndemonstrate that PMformer outperforms various univariate and\ncomplete-multivariate models, providing a theoretical rationale and empirical\nanalysis for its superiority. Additionally, by proposing an inference technique\nfor PMformer, the forecasting accuracy is further enhanced. Finally, we\nhighlight other advantages of PMformer: efficiency and robustness under missing\nfeatures.",
      "tldr_zh": "本研究针对多时间序列预测问题，指出现有方法的两极化——univariate模型忽略特征间关系，而complete-multivariate模型计算所有特征间关系，但后者有时表现不如前者。论文提出Partial-Multivariate模型，通过捕捉部分特征间的依赖关系（dependencies within subsets of all features）作为中间方案，并开发了基于Transformer的PMformer模型及其训练算法。实验结果显示，PMformer在预测准确性上优于各种univariate和complete-multivariate模型，并通过理论分析和实证验证其优势；此外，该模型还提升了效率和在缺失特征下的鲁棒性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "25 pages",
      "pdf_url": "http://arxiv.org/pdf/2408.09703v1",
      "published_date": "2024-08-19 05:18:50 UTC",
      "updated_date": "2024-08-19 05:18:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:46:39.320809"
    },
    {
      "arxiv_id": "2408.10285v1",
      "title": "BatGPT-Chem: A Foundation Large Model For Retrosynthesis Prediction",
      "title_zh": "BatGPT-Chem：用于逆合成预测的基础大模型",
      "authors": [
        "Yifei Yang",
        "Runhan Shi",
        "Zuchao Li",
        "Shu Jiang",
        "Bao-Liang Lu",
        "Yang Yang",
        "Hai Zhao"
      ],
      "abstract": "Retrosynthesis analysis is pivotal yet challenging in drug discovery and\norganic chemistry. Despite the proliferation of computational tools over the\npast decade, AI-based systems often fall short in generalizing across diverse\nreaction types and exploring alternative synthetic pathways. This paper\npresents BatGPT-Chem, a large language model with 15 billion parameters,\ntailored for enhanced retrosynthesis prediction. Integrating chemical tasks via\na unified framework of natural language and SMILES notation, this approach\nsynthesizes extensive instructional data from an expansive chemical database.\nEmploying both autoregressive and bidirectional training techniques across over\none hundred million instances, BatGPT-Chem captures a broad spectrum of\nchemical knowledge, enabling precise prediction of reaction conditions and\nexhibiting strong zero-shot capabilities. Superior to existing AI methods, our\nmodel demonstrates significant advancements in generating effective strategies\nfor complex molecules, as validated by stringent benchmark tests. BatGPT-Chem\nnot only boosts the efficiency and creativity of retrosynthetic analysis but\nalso establishes a new standard for computational tools in synthetic design.\nThis development empowers chemists to adeptly address the synthesis of novel\ncompounds, potentially expediting the innovation cycle in drug manufacturing\nand materials science. We release our trial platform at\n\\url{https://www.batgpt.net/dapp/chem}.",
      "tldr_zh": "该研究引入了BatGPT-Chem，一种150亿参数的大型语言模型，旨在提升回顾合成预测（retrosynthesis prediction）的准确性和泛化能力，以解决现有AI工具在处理多样反应类型和替代路径时的不足。模型通过整合自然语言和SMILES表示的统一框架，从大型化学数据库合成指令数据，并采用自回归和双向训练技术在超过一亿实例上训练，捕捉广泛的化学知识。实验结果显示，BatGPT-Chem在预测反应条件和生成复杂分子合成策略方面显著优于现有方法，具有强大的zero-shot capabilities，并通过基准测试验证。该模型不仅提高了回顾合成分析的效率和创造力，还为药物制造和材料科学创新提供了新标准，并提供了试用平台。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.10285v1",
      "published_date": "2024-08-19 05:17:40 UTC",
      "updated_date": "2024-08-19 05:17:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:46:55.263381"
    },
    {
      "arxiv_id": "2408.09702v1",
      "title": "Photorealistic Object Insertion with Diffusion-Guided Inverse Rendering",
      "title_zh": "翻译失败",
      "authors": [
        "Ruofan Liang",
        "Zan Gojcic",
        "Merlin Nimier-David",
        "David Acuna",
        "Nandita Vijaykumar",
        "Sanja Fidler",
        "Zian Wang"
      ],
      "abstract": "The correct insertion of virtual objects in images of real-world scenes\nrequires a deep understanding of the scene's lighting, geometry and materials,\nas well as the image formation process. While recent large-scale diffusion\nmodels have shown strong generative and inpainting capabilities, we find that\ncurrent models do not sufficiently \"understand\" the scene shown in a single\npicture to generate consistent lighting effects (shadows, bright reflections,\netc.) while preserving the identity and details of the composited object. We\npropose using a personalized large diffusion model as guidance to a physically\nbased inverse rendering process. Our method recovers scene lighting and\ntone-mapping parameters, allowing the photorealistic composition of arbitrary\nvirtual objects in single frames or videos of indoor or outdoor scenes. Our\nphysically based pipeline further enables automatic materials and tone-mapping\nrefinement.",
      "tldr_zh": "这篇论文提出了一种基于Diffusion-Guided Inverse Rendering的方法，用于在真实场景图像中实现逼真的虚拟对象插入，以解决现有扩散模型在理解场景照明、几何和材质方面的不足。方法利用个性化的大型扩散模型作为指导，结合物理基于的逆渲染过程来恢复场景的照明和色调映射参数，从而生成一致的灯光效果（如阴影和反射）并保留对象的身份细节。该方法适用于室内或室外场景的单帧或视频，并支持自动材质和色调映射的精炼，提高了合成效果的真实性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR"
      ],
      "primary_category": "cs.CV",
      "comment": "ECCV 2024, Project page:\n  https://research.nvidia.com/labs/toronto-ai/DiPIR/",
      "pdf_url": "http://arxiv.org/pdf/2408.09702v1",
      "published_date": "2024-08-19 05:15:45 UTC",
      "updated_date": "2024-08-19 05:15:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:47:07.701874"
    },
    {
      "arxiv_id": "2408.09698v5",
      "title": "Harnessing Multimodal Large Language Models for Multimodal Sequential Recommendation",
      "title_zh": "利用多模态大语言模型进行多模态序列推荐",
      "authors": [
        "Yuyang Ye",
        "Zhi Zheng",
        "Yishan Shen",
        "Tianshu Wang",
        "Hengruo Zhang",
        "Peijun Zhu",
        "Runlong Yu",
        "Kai Zhang",
        "Hui Xiong"
      ],
      "abstract": "Recent advances in Large Language Models (LLMs) have demonstrated significant\npotential in the field of Recommendation Systems (RSs). Most existing studies\nhave focused on converting user behavior logs into textual prompts and\nleveraging techniques such as prompt tuning to enable LLMs for recommendation\ntasks. Meanwhile, research interest has recently grown in multimodal\nrecommendation systems that integrate data from images, text, and other sources\nusing modality fusion techniques. This introduces new challenges to the\nexisting LLM-based recommendation paradigm which relies solely on text modality\ninformation. Moreover, although Multimodal Large Language Models (MLLMs)\ncapable of processing multi-modal inputs have emerged, how to equip MLLMs with\nmulti-modal recommendation capabilities remains largely unexplored. To this\nend, in this paper, we propose the Multimodal Large Language Model-enhanced\nMultimodaln Sequential Recommendation (MLLM-MSR) model. To capture the dynamic\nuser preference, we design a two-stage user preference summarization method.\nSpecifically, we first utilize an MLLM-based item-summarizer to extract image\nfeature given an item and convert the image into text. Then, we employ a\nrecurrent user preference summarization generation paradigm to capture the\ndynamic changes in user preferences based on an LLM-based user-summarizer.\nFinally, to enable the MLLM for multi-modal recommendation task, we propose to\nfine-tune a MLLM-based recommender using Supervised Fine-Tuning (SFT)\ntechniques. Extensive evaluations across various datasets validate the\neffectiveness of MLLM-MSR, showcasing its superior ability to capture and adapt\nto the evolving dynamics of user preferences.",
      "tldr_zh": "本文提出MLLM-MSR模型，利用Multimodal Large Language Models (MLLMs)来增强多模态顺序推荐系统，解决传统LLM-based推荐依赖单一文本模态的局限性。模型采用两阶段用户偏好总结方法：首先通过MLLM-based item-summarizer提取图像特征并转换为文本，然后使用LLM-based user-summarizer捕获动态用户偏好变化，并通过Supervised Fine-Tuning (SFT)技术微调推荐器。实验在多个数据集上验证了MLLM-MSR的有效性，展示了其在捕捉和适应用户偏好动态方面的显著优势。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.09698v5",
      "published_date": "2024-08-19 04:44:32 UTC",
      "updated_date": "2025-01-13 17:48:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:47:17.618807"
    },
    {
      "arxiv_id": "2408.09695v1",
      "title": "LightWeather: Harnessing Absolute Positional Encoding to Efficient and Scalable Global Weather Forecasting",
      "title_zh": "LightWeather：利用绝对位置编码实现高效且可扩展的全球天气预报",
      "authors": [
        "Yisong Fu",
        "Fei Wang",
        "Zezhi Shao",
        "Chengqing Yu",
        "Yujie Li",
        "Zhao Chen",
        "Zhulin An",
        "Yongjun Xu"
      ],
      "abstract": "Recently, Transformers have gained traction in weather forecasting for their\ncapability to capture long-term spatial-temporal correlations. However, their\ncomplex architectures result in large parameter counts and extended training\ntimes, limiting their practical application and scalability to global-scale\nforecasting. This paper aims to explore the key factor for accurate weather\nforecasting and design more efficient solutions. Interestingly, our empirical\nfindings reveal that absolute positional encoding is what really works in\nTransformer-based weather forecasting models, which can explicitly model the\nspatial-temporal correlations even without attention mechanisms. We\ntheoretically prove that its effectiveness stems from the integration of\ngeographical coordinates and real-world time features, which are intrinsically\nrelated to the dynamics of weather. Based on this, we propose LightWeather, a\nlightweight and effective model for station-based global weather forecasting.\nWe employ absolute positional encoding and a simple MLP in place of other\ncomponents of Transformer. With under 30k parameters and less than one hour of\ntraining time, LightWeather achieves state-of-the-art performance on global\nweather datasets compared to other advanced DL methods. The results underscore\nthe superiority of integrating spatial-temporal knowledge over complex\narchitectures, providing novel insights for DL in weather forecasting.",
      "tldr_zh": "该研究发现，在Transformer-based天气预报模型中，Absolute Positional Encoding是关键因素，能有效捕捉空间-时间相关性，即使无需注意力机制。该方法通过整合地理坐标和真实时间特征来建模天气动态，并提出LightWeather模型，该模型使用Absolute Positional Encoding和简单的MLP，仅有不到30k参数，训练时间不到一小时。实验结果显示，LightWeather在全球天气数据集上实现SOTA性能，比其他高级DL方法更高效和可扩展，为深度学习在天气预报中的应用提供新见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.ao-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.09695v1",
      "published_date": "2024-08-19 04:23:40 UTC",
      "updated_date": "2024-08-19 04:23:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:47:28.642755"
    },
    {
      "arxiv_id": "2408.09682v1",
      "title": "Simulating Field Experiments with Large Language Models",
      "title_zh": "使用大型语言模型模拟实地实验",
      "authors": [
        "Yaoyu Chen",
        "Yuheng Hu",
        "Yingda Lu"
      ],
      "abstract": "Prevailing large language models (LLMs) are capable of human responses\nsimulation through its unprecedented content generation and reasoning\nabilities. However, it is not clear whether and how to leverage LLMs to\nsimulate field experiments. In this paper, we propose and evaluate two\nprompting strategies: the observer mode that allows a direct prediction on main\nconclusions and the participant mode that simulates distributions of responses\nfrom participants. Using this approach, we examine fifteen well cited field\nexperimental papers published in INFORMS and MISQ, finding encouraging\nalignments between simulated experimental results and the actual results in\ncertain scenarios. We further identify topics of which LLMs underperform,\nincluding gender difference and social norms related research. Additionally,\nthe automatic and standardized workflow proposed in this paper enables the\npossibility of a large-scale screening of more papers with field experiments.\nThis paper pioneers the utilization of large language models (LLMs) for\nsimulating field experiments, presenting a significant extension to previous\nwork which focused solely on lab environments. By introducing two novel\nprompting strategies, observer and participant modes, we demonstrate the\nability of LLMs to both predict outcomes and replicate participant responses\nwithin complex field settings. Our findings indicate a promising alignment with\nactual experimental results in certain scenarios, achieving a stimulation\naccuracy of 66% in observer mode. This study expands the scope of potential\napplications for LLMs and illustrates their utility in assisting researchers\nprior to engaging in expensive field experiments. Moreover, it sheds light on\nthe boundaries of LLMs when used in simulating field experiments, serving as a\ncautionary note for researchers considering the integration of LLMs into their\nexperimental toolkit.",
      "tldr_zh": "这篇论文探讨了使用大型语言模型 (LLMs) 模拟现场实验的可行性，提出了两种提示策略：观察者模式（直接预测主要结论）和参与者模式（模拟参与者响应分布）。通过评估15篇发表在INFORMS和MISQ的知名现场实验论文，研究发现LLMs在某些场景下与实际结果高度一致，实现了66%的模拟准确率。论文还识别出LLMs在性别差异和社会规范相关主题上的表现不足，并引入了一个自动化的标准化工作流程，支持大规模论文筛选，从而扩展了LLMs在实验模拟中的应用潜力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "17 pages, 5 figures, 6 tables",
      "pdf_url": "http://arxiv.org/pdf/2408.09682v1",
      "published_date": "2024-08-19 03:41:43 UTC",
      "updated_date": "2024-08-19 03:41:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:47:40.755880"
    },
    {
      "arxiv_id": "2408.09680v2",
      "title": "MambaLoc: Efficient Camera Localisation via State Space Model",
      "title_zh": "翻译失败",
      "authors": [
        "Jialu Wang",
        "Kaichen Zhou",
        "Andrew Markham",
        "Niki Trigoni"
      ],
      "abstract": "Location information is pivotal for the automation and intelligence of\nterminal devices and edge-cloud IoT systems, such as autonomous vehicles and\naugmented reality. However, achieving reliable positioning across diverse IoT\napplications remains challenging due to significant training costs and the\nnecessity of densely collected data. To tackle these issues, we have\ninnovatively applied the selective state space (SSM) model to visual\nlocalization, introducing a new model named MambaLoc. The proposed model\ndemonstrates exceptional training efficiency by capitalizing on the SSM model's\nstrengths in efficient feature extraction, rapid computation, and memory\noptimization, and it further ensures robustness in sparse data environments due\nto its parameter sparsity. Additionally, we propose the Global Information\nSelector (GIS), which leverages selective SSM to implicitly achieve the\nefficient global feature extraction capabilities of Non-local Neural Networks.\nThis design leverages the computational efficiency of the SSM model alongside\nthe Non-local Neural Networks' capacity to capture long-range dependencies with\nminimal layers. Consequently, the GIS enables effective global information\ncapture while significantly accelerating convergence. Our extensive\nexperimental validation using public indoor and outdoor datasets first\ndemonstrates our model's effectiveness, followed by evidence of its versatility\nwith various existing localization models. Our code and models are publicly\navailable to support further research and development in this area.",
      "tldr_zh": "本研究针对视觉定位的训练成本高和数据密集问题，创新地将 Selective State Space Model (SSM) 应用于摄像头定位，提出新模型 MambaLoc，以实现高效特征提取、快速计算和内存优化，同时在稀疏数据环境中保持鲁棒性。论文引入 Global Information Selector (GIS)，利用 selective SSM 隐式实现 Non-local Neural Networks 的全局特征提取能力，从而高效捕获长距离依赖关系并加速模型收敛。实验在公共室内外数据集上验证了 MambaLoc 的有效性和通用性，与现有定位模型兼容；代码和模型已公开，以支持进一步研究。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.09680v2",
      "published_date": "2024-08-19 03:38:29 UTC",
      "updated_date": "2024-08-20 08:44:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:47:55.423219"
    },
    {
      "arxiv_id": "2408.09675v1",
      "title": "Multi-Agent Reinforcement Learning for Autonomous Driving: A Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Ruiqi Zhang",
        "Jing Hou",
        "Florian Walter",
        "Shangding Gu",
        "Jiayi Guan",
        "Florian Röhrbein",
        "Yali Du",
        "Panpan Cai",
        "Guang Chen",
        "Alois Knoll"
      ],
      "abstract": "Reinforcement Learning (RL) is a potent tool for sequential decision-making\nand has achieved performance surpassing human capabilities across many\nchallenging real-world tasks. As the extension of RL in the multi-agent system\ndomain, multi-agent RL (MARL) not only need to learn the control policy but\nalso requires consideration regarding interactions with all other agents in the\nenvironment, mutual influences among different system components, and the\ndistribution of computational resources. This augments the complexity of\nalgorithmic design and poses higher requirements on computational resources.\nSimultaneously, simulators are crucial to obtain realistic data, which is the\nfundamentals of RL. In this paper, we first propose a series of metrics of\nsimulators and summarize the features of existing benchmarks. Second, to ease\ncomprehension, we recall the foundational knowledge and then synthesize the\nrecently advanced studies of MARL-related autonomous driving and intelligent\ntransportation systems. Specifically, we examine their environmental modeling,\nstate representation, perception units, and algorithm design. Conclusively, we\ndiscuss open challenges as well as prospects and opportunities. We hope this\npaper can help the researchers integrate MARL technologies and trigger more\ninsightful ideas toward the intelligent and autonomous driving.",
      "tldr_zh": "这篇论文对 Multi-Agent Reinforcement Learning (MARL) 在自动驾驶领域的应用进行了全面调查，强调了 MARL 需要处理代理间互动、系统组件影响以及资源分配的复杂性。论文首先提出了模拟器的评估指标，并总结了现有基准的特征，以支持现实数据获取。接着，它回顾了 MARL 的基础知识，并分析了最近的研究，包括环境建模、状态表示、感知单元和算法设计。最后，论文讨论了开放挑战、未来机遇，并旨在帮助研究者整合 MARL 技术，促进智能自动驾驶的发展。",
      "categories": [
        "cs.AI",
        "cs.MA",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "23 pages, 6 figures and 2 tables. Submitted to IEEE Journal",
      "pdf_url": "http://arxiv.org/pdf/2408.09675v1",
      "published_date": "2024-08-19 03:31:20 UTC",
      "updated_date": "2024-08-19 03:31:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:48:08.013876"
    },
    {
      "arxiv_id": "2408.09656v2",
      "title": "A Comparison of Large Language Model and Human Performance on Random Number Generation Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Rachel M. Harrison"
      ],
      "abstract": "Random Number Generation Tasks (RNGTs) are used in psychology for examining\nhow humans generate sequences devoid of predictable patterns. By adapting an\nexisting human RNGT for an LLM-compatible environment, this preliminary study\ntests whether ChatGPT-3.5, a large language model (LLM) trained on\nhuman-generated text, exhibits human-like cognitive biases when generating\nrandom number sequences. Initial findings indicate that ChatGPT-3.5 more\neffectively avoids repetitive and sequential patterns compared to humans, with\nnotably lower repeat frequencies and adjacent number frequencies. Continued\nresearch into different models, parameters, and prompting methodologies will\ndeepen our understanding of how LLMs can more closely mimic human random\ngeneration behaviors, while also broadening their applications in cognitive and\nbehavioral science research.",
      "tldr_zh": "本研究比较了大型语言模型（LLM）和人类在随机数生成任务（RNGTs）上的表现，通过将现有人类任务适应为LLM兼容环境，测试ChatGPT-3.5是否会表现出类似人类的认知偏差。结果表明，ChatGPT-3.5比人类更有效地避免重复和相邻数字模式，具有更低的重复频率。未来研究将深入探讨不同模型、参数和提示方法，以提升LLMs模拟人类随机生成行为的能力，并扩展其在认知和行为科学领域的应用。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "q-bio.NC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.09656v2",
      "published_date": "2024-08-19 02:34:15 UTC",
      "updated_date": "2024-08-20 02:05:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:48:16.984838"
    },
    {
      "arxiv_id": "2408.11869v3",
      "title": "ELDER: Enhancing Lifelong Model Editing with Mixture-of-LoRA",
      "title_zh": "翻译失败",
      "authors": [
        "Jiaang Li",
        "Quan Wang",
        "Zhongnan Wang",
        "Yongdong Zhang",
        "Zhendong Mao"
      ],
      "abstract": "Large language models (LLMs) require model editing to efficiently update\nspecific knowledge within them and avoid factual errors. Most model editing\nmethods are solely designed for single-time use and result in a significant\nforgetting effect in lifelong editing scenarios, where sequential edits are\nconducted over time. Previous approaches manage sequential edits by freezing\noriginal parameters and discretely allocating new parameters for each knowledge\nupdate. However, these methods lack robustness to minor input variations due to\nthe discrete mapping between data and parameters. To overcome this challenge,\nwe propose ELDER, a novel approach to create a continuous association between\ndata and adapters. ELDER integrates multiple LoRAs through a router network and\nis trained to establish a smooth data-adapter association, thereby enhancing\nthe edit robustness and generalization of semantically equivalent inputs. To\nensure inputs containing the same knowledge will be processed by the same\nLoRAs, we design a novel loss to guide the model link LoRA allocations with\nedit knowledge. Furthermore, we propose a deferral mechanism to retain the\noriginal LLM capabilities post-edit. Extensive experiments on GPT-2 XL and\nLLaMA2-7B demonstrate that ELDER effectively edits models in the lifelong\nsetting, outperforming eight baselines while exhibiting strong scalability and\npreserving LLMs' general abilities on downstream tasks. Our code is available\nat https://github.com/JiaangL/ELDER.",
      "tldr_zh": "本研究针对大型语言模型 (LLMs) 在终身编辑场景中的遗忘效应和对输入变异的不鲁棒性问题，提出了一种新型方法 ELDER，该方法利用 Mixture-of-LoRA 通过路由网络整合多个 LoRA 适配器，建立连续的数据-适配器关联，并设计了一个新损失函数确保相同知识的输入使用相同的 LoRA，同时引入延期机制保留模型的原始能力。ELDER 通过这种方式提升了编辑的鲁棒性和泛化性能。实验在 GPT-2 XL 和 LLaMA2-7B 上表明，该方法在终身编辑任务中优于八个基线，展示了强大的可扩展性和在下游任务上的通用能力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by AAAI-25",
      "pdf_url": "http://arxiv.org/pdf/2408.11869v3",
      "published_date": "2024-08-19 02:27:00 UTC",
      "updated_date": "2025-01-14 04:25:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:48:28.961818"
    },
    {
      "arxiv_id": "2408.09651v1",
      "title": "Data-driven Conditional Instrumental Variables for Debiasing Recommender Systems",
      "title_zh": "数据驱动的条件工具变量用于推荐系统的去偏置",
      "authors": [
        "Zhirong Huang",
        "Shichao Zhang",
        "Debo Cheng",
        "Jiuyong Li",
        "Lin Liu",
        "Guangquan Lu"
      ],
      "abstract": "In recommender systems, latent variables can cause user-item interaction data\nto deviate from true user preferences. This biased data is then used to train\nrecommendation models, further amplifying the bias and ultimately compromising\nboth recommendation accuracy and user satisfaction. Instrumental Variable (IV)\nmethods are effective tools for addressing the confounding bias introduced by\nlatent variables; however, identifying a valid IV is often challenging. To\novercome this issue, we propose a novel data-driven conditional IV (CIV)\ndebiasing method for recommender systems, called CIV4Rec. CIV4Rec automatically\ngenerates valid CIVs and their corresponding conditioning sets directly from\ninteraction data, significantly reducing the complexity of IV selection while\neffectively mitigating the confounding bias caused by latent variables in\nrecommender systems. Specifically, CIV4Rec leverages a variational autoencoder\n(VAE) to generate the representations of the CIV and its conditional set from\ninteraction data, followed by the application of least squares to derive causal\nrepresentations for click prediction. Extensive experiments on two real-world\ndatasets, Movielens-10M and Douban-Movie, demonstrate that our CIV4Rec\nsuccessfully identifies valid CIVs, effectively reduces bias, and consequently\nimproves recommendation accuracy.",
      "tldr_zh": "该研究针对推荐系统中潜在变量导致的用户-物品交互数据偏见问题，提出了一种数据驱动的条件工具变量（Conditional Instrumental Variables, CIV）去偏方法，名为 CIV4Rec，以提升推荐准确性和用户满意度。CIV4Rec 通过变分自编码器（Variational Autoencoder, VAE）从交互数据中自动生成有效的 CIV 及其条件集，随后运用最小二乘法获取因果表示，用于点击预测，从而简化了工具变量的选择过程。实验在真实数据集 Movielens-10M 和 Douban-Movie 上验证了该方法的有效性，能够成功识别 CIV、减少混杂偏见，并显著提高推荐性能。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.09651v1",
      "published_date": "2024-08-19 02:17:22 UTC",
      "updated_date": "2024-08-19 02:17:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:48:40.686476"
    },
    {
      "arxiv_id": "2408.09650v1",
      "title": "ExpoMamba: Exploiting Frequency SSM Blocks for Efficient and Effective Image Enhancement",
      "title_zh": "翻译失败",
      "authors": [
        "Eashan Adhikarla",
        "Kai Zhang",
        "John Nicholson",
        "Brian D. Davison"
      ],
      "abstract": "Low-light image enhancement remains a challenging task in computer vision,\nwith existing state-of-the-art models often limited by hardware constraints and\ncomputational inefficiencies, particularly in handling high-resolution images.\nRecent foundation models, such as transformers and diffusion models, despite\ntheir efficacy in various domains, are limited in use on edge devices due to\ntheir computational complexity and slow inference times. We introduce\nExpoMamba, a novel architecture that integrates components of the frequency\nstate space within a modified U-Net, offering a blend of efficiency and\neffectiveness. This model is specifically optimized to address mixed exposure\nchallenges, a common issue in low-light image enhancement, while ensuring\ncomputational efficiency. Our experiments demonstrate that ExpoMamba enhances\nlow-light images up to 2-3x faster than traditional models with an inference\ntime of 36.6 ms and achieves a PSNR improvement of approximately 15-20% over\ncompeting models, making it highly suitable for real-time image processing\napplications.",
      "tldr_zh": "该研究提出ExpoMamba，一种创新架构，将Frequency SSM Blocks整合到修改后的U-Net中，用于高效处理低光图像增强问题。该模型针对混合曝光挑战进行优化，确保计算效率，同时克服现有模型在硬件限制和推理速度上的不足。实验结果显示，ExpoMamba的推理时间仅为36.6 ms，比传统模型快2-3倍，并实现PSNR改善约15-20%，使其特别适合实时图像处理应用。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.09650v1",
      "published_date": "2024-08-19 02:16:47 UTC",
      "updated_date": "2024-08-19 02:16:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:48:53.011724"
    },
    {
      "arxiv_id": "2408.09649v2",
      "title": "Deep Learning-based Machine Condition Diagnosis using Short-time Fourier Transformation Variants",
      "title_zh": "翻译失败",
      "authors": [
        "Eduardo Jr Piedad",
        "Zherish Galvin Mayordo",
        "Eduardo Prieto-Araujo",
        "Oriol Gomis-Bellmunt"
      ],
      "abstract": "In motor condition diagnosis, electrical current signature serves as an\nalternative feature to vibration-based sensor data, which is a more expensive\nand invasive method. Machine learning (ML) techniques have been emerging in\ndiagnosing motor conditions using only motor phase current signals. This study\nconverts time-series motor current signals to time-frequency 2D plots using\nShort-time Fourier Transform (STFT) methods. The motor current signal dataset\nconsists of 3,750 sample points with five classes - one healthy and four\nsynthetically-applied motor fault conditions, and with five loading conditions:\n0, 25, 50, 75, and 100%. Five transformation methods are used on the dataset:\nnon-overlap and overlap STFTs, non-overlap and overlap realigned STFTs, and\nsynchrosqueezed STFT. Then, deep learning (DL) models based on the previous\nConvolutional Neural Network (CNN) architecture are trained and validated from\ngenerated plots of each method. The DL models of overlap-STFT, overlap R-STFT,\nnon-overlap STFT, non-overlap R-STFT, and synchrosqueezed-STFT performed\nexceptionally with an average accuracy of 97.65, 96.03, 96.08, 96.32, and\n88.27%, respectively. Four methods outperformed the previous best ML method\nwith 93.20% accuracy, while all five outperformed previous 2D-plot-based\nmethods with accuracy of 80.25, 74.80, and 82.80%, respectively, using the same\ndataset, same DL architecture, and validation steps.",
      "tldr_zh": "本研究针对电机故障诊断，使用电机电流信号作为特征替代昂贵的振动传感器数据，并采用 Short-time Fourier Transform (STFT) 的变体将时间序列信号转换为时间-频率 2D 图。研究数据集包含 3,750 个样本点，涵盖一个健康状态和四种合成故障，以及五种负载条件（0%、25%、50%、75%、100%），并训练基于 Convolutional Neural Network (CNN) 的深度学习模型。结果显示，五种方法（overlap-STFT、overlap R-STFT、non-overlap STFT、non-overlap R-STFT 和 synchrosqueezed-STFT）的平均准确率分别为 97.65%、96.03%、96.08%、96.32% 和 88.27%，均超过了先前最佳 ML 方法（93.20%）和 2D-plot-based 方法（最高 82.80%）。这项工作证明了 STFT 变体在机器状态诊断中的有效性，为高效故障检测提供了新途径。",
      "categories": [
        "eess.SP",
        "cs.AI"
      ],
      "primary_category": "eess.SP",
      "comment": "4 pages, 6 images, presented at 2024 International Conference on\n  Diagnostics in Electrical Engineering (Diagnostika)",
      "pdf_url": "http://arxiv.org/pdf/2408.09649v2",
      "published_date": "2024-08-19 02:16:17 UTC",
      "updated_date": "2024-10-14 10:05:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:49:08.837017"
    },
    {
      "arxiv_id": "2408.09646v1",
      "title": "Debiased Contrastive Representation Learning for Mitigating Dual Biases in Recommender Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Zhirong Huang",
        "Shichao Zhang",
        "Debo Cheng",
        "Jiuyong Li",
        "Lin Liu",
        "Guixian Zhang"
      ],
      "abstract": "In recommender systems, popularity and conformity biases undermine\nrecommender effectiveness by disproportionately favouring popular items,\nleading to their over-representation in recommendation lists and causing an\nunbalanced distribution of user-item historical data. We construct a causal\ngraph to address both biases and describe the abstract data generation\nmechanism. Then, we use it as a guide to develop a novel Debiased Contrastive\nLearning framework for Mitigating Dual Biases, called DCLMDB. In DCLMDB, both\npopularity bias and conformity bias are handled in the model training process\nby contrastive learning to ensure that user choices and recommended items are\nnot unduly influenced by conformity and popularity. Extensive experiments on\ntwo real-world datasets, Movielens-10M and Netflix, show that DCLMDB can\neffectively reduce the dual biases, as well as significantly enhance the\naccuracy and diversity of recommendations.",
      "tldr_zh": "本研究针对推荐系统中存在的流行度(popularity bias)和从众偏差(conformity bias)问题，提出了一种新型Debiased Contrastive Learning框架，名为DCLMDB，通过构建因果图来指导模型训练，确保用户选择和推荐结果不受这些偏差影响。DCLMDB在训练过程中利用对比学习(Contrastive Learning)技术来处理双重偏差，从而实现更平衡的用户-物品数据分布。实验在Movielens-10M和Netflix真实数据集上验证了该框架的有效性，不仅显著降低了偏差，还提升了推荐的准确性和多样性。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.09646v1",
      "published_date": "2024-08-19 02:12:40 UTC",
      "updated_date": "2024-08-19 02:12:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:49:16.689945"
    },
    {
      "arxiv_id": "2408.09644v2",
      "title": "Exploring Wavelet Transformations for Deep Learning-based Machine Condition Diagnosis",
      "title_zh": "探索小波变换用于基于深度学习的机器状态诊断",
      "authors": [
        "Eduardo Jr Piedad",
        "Christian Ainsley Del Rosario",
        "Eduardo Prieto-Araujo",
        "Oriol Gomis-Bellmunt"
      ],
      "abstract": "Deep learning (DL) strategies have recently been utilized to diagnose motor\nfaults by simply analyzing motor phase current signals, offering a less costly\nand non-intrusive alternative to vibration sensors. This research transforms\nthese time-series current signals into time-frequency 2D representations via\nWavelet Transform (WT). The dataset for motor current signals includes 3,750\ndata points across five categories: one representing normal conditions and four\nrepresenting artificially induced faults, each under five different load\nconditions: 0, 25, 50, 75, and 100%. The study employs five WT-based\ntechniques: WT-Amor, WT-Bump, WT-Morse, WSST-Amor, and WSST-Bump. Subsequently,\nfive DL models adopting prior Convolutional Neural Network (CNN) architecture\nwere developed and tested using the transformed 2D plots from each method. The\nDL models for WT-Amor, WT-Bump, and WT-Morse showed remarkable effectiveness\nwith peak model accuracy of 90.93, 89.20, and 93.73%, respectively, surpassing\nprevious 2D-image-based methods that recorded accuracy of 80.25, 74.80, and\n82.80% respectively using the identical dataset and validation protocol.\nNotably, the WT-Morse approach slightly exceeded the formerly highest ML\ntechnique, achieving a 93.20% accuracy. However, the two WSST methods that\nutilized synchrosqueezing techniques faced difficulty accurately classifying\nmotor faults. The performance of Wavelet-based deep learning methods offers a\ncompelling alternative for machine condition monitoring.",
      "tldr_zh": "这篇论文探讨了使用Wavelet Transform (WT)将电机电流信号转换为时间-频率2D表示，以提升基于深度学习的电机故障诊断方法。研究利用一个包含3750个数据点的数据集，涵盖正常和四种故障条件下的五种负载水平，并测试了五种WT技术（包括WT-Amor、WT-Bump、WT-Morse、WSST-Amor和WSST-Bump）。通过Convolutional Neural Network (CNN)模型的训练，WT-Morse等方法实现了最高93.73%的准确率，显著超过了先前2D图像方法的80.25-82.80%。总体而言，该方法为更高效的机器状况监测提供了可行的替代方案。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "eess.SP",
      "comment": "4 pages, 6 figures, presented at the 2024 International Conference on\n  Diagnostics in Electrical Engineering (Diagnostika)",
      "pdf_url": "http://arxiv.org/pdf/2408.09644v2",
      "published_date": "2024-08-19 02:06:33 UTC",
      "updated_date": "2024-10-14 10:08:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:49:32.122764"
    },
    {
      "arxiv_id": "2408.11868v1",
      "title": "Improving embedding with contrastive fine-tuning on small datasets with expert-augmented scores",
      "title_zh": "翻译失败",
      "authors": [
        "Jun Lu",
        "David Li",
        "Bill Ding",
        "Yu Kang"
      ],
      "abstract": "This paper presents an approach to improve text embedding models through\ncontrastive fine-tuning on small datasets augmented with expert scores. It\nfocuses on enhancing semantic textual similarity tasks and addressing text\nretrieval problems. The proposed method uses soft labels derived from\nexpert-augmented scores to fine-tune embedding models, preserving their\nversatility and ensuring retrieval capability is improved. The paper evaluates\nthe method using a Q\\&A dataset from an online shopping website and eight\nexpert models. Results show improved performance over a benchmark model across\nmultiple metrics on various retrieval tasks from the massive text embedding\nbenchmark (MTEB). The method is cost-effective and practical for real-world\napplications, especially when labeled data is scarce.",
      "tldr_zh": "这篇论文提出了一种通过 contrastive fine-tuning 在小型数据集上改进文本嵌入模型的方法，利用专家增强的评分（expert-augmented scores）生成软标签，以提升语义文本相似性（semantic textual similarity）任务和文本检索性能。方法保留了模型的通用性，同时优化了检索能力，并在在线购物网站的 Q&A 数据集以及八个专家模型上进行评估。结果显示，该方法在 massive text embedding benchmark (MTEB) 的多种检索任务中，超过了基准模型的多项指标。该方法成本低效且实用，尤其适用于数据标注稀缺的真实场景。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.11868v1",
      "published_date": "2024-08-19 01:59:25 UTC",
      "updated_date": "2024-08-19 01:59:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:49:42.385895"
    },
    {
      "arxiv_id": "2408.09639v2",
      "title": "How to Make the Most of LLMs' Grammatical Knowledge for Acceptability Judgments",
      "title_zh": "如何充分利用 LLMs 的语法知识进行可接受性判断",
      "authors": [
        "Yusuke Ide",
        "Yuto Nishida",
        "Justin Vasselli",
        "Miyu Oba",
        "Yusuke Sakai",
        "Hidetaka Kamigaito",
        "Taro Watanabe"
      ],
      "abstract": "The grammatical knowledge of language models (LMs) is often measured using a\nbenchmark of linguistic minimal pairs, where the LMs are presented with a pair\nof acceptable and unacceptable sentences and required to judge which is more\nacceptable. Conventional approaches directly compare sentence probabilities\nassigned by LMs, but recent large language models (LLMs) are trained to perform\ntasks via prompting, and thus, the raw probabilities they assign may not fully\nreflect their grammatical knowledge. In this study, we attempt to derive more\naccurate acceptability judgments from LLMs using prompts and templates. Through\nextensive experiments in English and Chinese, we compare nine judgment methods\nand find two of them, a probability readout method -- in-template LP and a\nprompt-based method -- Yes/No probability computing, achieve higher accuracy\nthan the conventional ones. Our analysis reveals that these methods excel in\ndifferent linguistic phenomena, suggesting they access different aspects of\nLLMs' knowledge. We also find that ensembling the two methods outperforms\nsingle methods. Consequently, we recommend these techniques, either\nindividually or ensembled, as more effective alternatives to conventional\napproaches for assessing grammatical knowledge in LLMs.",
      "tldr_zh": "本文研究如何更有效地利用大型语言模型（LLMs）的语法知识来评估句子可接受性，指出传统基于句子概率的方法可能无法完全捕捉LLMs的知识。研究者通过实验比较了九种判断方法，包括in-template LP（概率读取方法）和Yes/No probability computing（基于提示的方法），并发现这些方法在英语和中文数据集上实现了更高的准确率。分析显示，不同方法擅长处理各种语言现象，且将两种方法结合使用能进一步提升性能。作为主要贡献，论文推荐这些技术作为评估LLMs语法知识的更优替代方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "NAACL 2025 main",
      "pdf_url": "http://arxiv.org/pdf/2408.09639v2",
      "published_date": "2024-08-19 01:53:47 UTC",
      "updated_date": "2025-02-07 07:02:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:49:55.516071"
    },
    {
      "arxiv_id": "2408.09635v1",
      "title": "Meta-Learning on Augmented Gene Expression Profiles for Enhanced Lung Cancer Detection",
      "title_zh": "基于增强基因表达谱的元学习以提升肺癌检测",
      "authors": [
        "Arya Hadizadeh Moghaddam",
        "Mohsen Nayebi Kerdabadi",
        "Cuncong Zhong",
        "Zijun Yao"
      ],
      "abstract": "Gene expression profiles obtained through DNA microarray have proven\nsuccessful in providing critical information for cancer detection classifiers.\nHowever, the limited number of samples in these datasets poses a challenge to\nemploy complex methodologies such as deep neural networks for sophisticated\nanalysis. To address this \"small data\" dilemma, Meta-Learning has been\nintroduced as a solution to enhance the optimization of machine learning models\nby utilizing similar datasets, thereby facilitating a quicker adaptation to\ntarget datasets without the requirement of sufficient samples. In this study,\nwe present a meta-learning-based approach for predicting lung cancer from gene\nexpression profiles. We apply this framework to well-established deep learning\nmethodologies and employ four distinct datasets for the meta-learning tasks,\nwhere one as the target dataset and the rest as source datasets. Our approach\nis evaluated against both traditional and deep learning methodologies, and the\nresults show the superior performance of meta-learning on augmented source data\ncompared to the baselines trained on single datasets. Moreover, we conduct the\ncomparative analysis between meta-learning and transfer learning methodologies\nto highlight the efficiency of the proposed approach in addressing the\nchallenges associated with limited sample sizes. Finally, we incorporate the\nexplainability study to illustrate the distinctiveness of decisions made by\nmeta-learning.",
      "tldr_zh": "该研究针对基因表达谱数据样本量有限的问题，提出了一种基于 Meta-Learning 的方法，用于增强肺癌检测的准确性。该方法利用四个数据集（一个作为目标数据集，其余作为源数据集）来优化深度学习模型，使其在小样本场景下更快适应并学习。实验结果显示，与传统和深度学习基线相比，Meta-Learning 在增强源数据上的表现更优越，并在与 Transfer Learning 的比较中突出了其处理样本不足的效率。最后，通过 explainability study，研究展示了 Meta-Learning 决策的独特性，为基因表达分析提供了新insights。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.GN"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to AMIA 2024 Annual Symposium",
      "pdf_url": "http://arxiv.org/pdf/2408.09635v1",
      "published_date": "2024-08-19 01:39:12 UTC",
      "updated_date": "2024-08-19 01:39:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:50:07.126127"
    },
    {
      "arxiv_id": "2408.09626v1",
      "title": "On the Foundations of Conflict-Driven Solving for Hybrid MKNF Knowledge Bases",
      "title_zh": "翻译失败",
      "authors": [
        "Riley Kinahan",
        "Spencer Killen",
        "Kevin Wan",
        "Jia-Huai You"
      ],
      "abstract": "Hybrid MKNF Knowledge Bases (HMKNF-KBs) constitute a formalism for tightly\nintegrated reasoning over closed-world rules and open-world ontologies. This\napproach allows for accurate modeling of real-world systems, which often rely\non both categorical and normative reasoning. Conflict-driven solving is the\nleading approach for computationally hard problems, such as satisfiability\n(SAT) and answer set programming (ASP), in which MKNF is rooted. This paper\ninvestigates the theoretical underpinnings required for a conflict-driven\nsolver of HMKNF-KBs. The approach defines a set of completion and loop\nformulas, whose satisfaction characterizes MKNF models. This forms the basis\nfor a set of nogoods, which in turn can be used as the backbone for a\nconflict-driven solver.",
      "tldr_zh": "这篇论文探讨了 Hybrid MKNF Knowledge Bases (HMKNF-KBs) 的理论基础，HMKNF-KBs 是一种形式主义，用于紧密整合闭世界规则和开世界本体（closed-world rules and open-world ontologies）的推理，以精确建模依赖分类和规范性推理的真实系统。作者定义了 completion 和 loop formulas，这些 formulas 的满足性用于表征 MKNF models，并从中派生 nogoods 作为冲突驱动求解（conflict-driven solving）的核心机制。总体上，这为基于 conflict-driven solving 的 HMKNF-KBs 求解器提供了坚实支撑，提升了处理 SAT 和 ASP 等计算困难问题的能力。",
      "categories": [
        "cs.AI",
        "I.2.4"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.09626v1",
      "published_date": "2024-08-19 01:13:02 UTC",
      "updated_date": "2024-08-19 01:13:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:50:18.502303"
    },
    {
      "arxiv_id": "2408.09624v1",
      "title": "Attention is a smoothed cubic spline",
      "title_zh": "注意力是一种平滑的三次样条",
      "authors": [
        "Zehua Lai",
        "Lek-Heng Lim",
        "Yucong Liu"
      ],
      "abstract": "We highlight a perhaps important but hitherto unobserved insight: The\nattention module in a transformer is a smoothed cubic spline. Viewed in this\nmanner, this mysterious but critical component of a transformer becomes a\nnatural development of an old notion deeply entrenched in classical\napproximation theory. More precisely, we show that with ReLU-activation,\nattention, masked attention, encoder-decoder attention are all cubic splines.\nAs every component in a transformer is constructed out of compositions of\nvarious attention modules (= cubic splines) and feed forward neural networks (=\nlinear splines), all its components -- encoder, decoder, and encoder-decoder\nblocks; multilayered encoders and decoders; the transformer itself -- are cubic\nor higher-order splines. If we assume the Pierce-Birkhoff conjecture, then the\nconverse also holds, i.e., every spline is a ReLU-activated encoder. Since a\nspline is generally just $C^2$, one way to obtain a smoothed $C^\\infty$-version\nis by replacing ReLU with a smooth activation; and if this activation is chosen\nto be SoftMax, we recover the original transformer as proposed by Vaswani et\nal. This insight sheds light on the nature of the transformer by casting it\nentirely in terms of splines, one of the best known and thoroughly understood\nobjects in applied mathematics.",
      "tldr_zh": "论文发现，Transformer中的attention模块本质上是一个平滑的cubic spline，将这一关键组件与经典逼近理论中的样条概念联系起来。研究通过分析证明，使用ReLU激活的attention、masked attention和encoder-decoder attention等均为cubic splines，从而Transformer的所有组件，包括编码器、解码器和整体结构，都是cubic或更高阶样条。假设Pierce-Birkhoff猜想成立，则反之亦然，即每条样条可视为ReLU-activated encoder；通过替换为SoftMax激活，可获得平滑的C∞版本，恢复原始Transformer。这一洞见为理解Transformer提供了新视角，将其置于应用数学的框架中。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.NA",
        "math.NA",
        "26B40, 41A15, 65D07, 68T01, 14P10, 13J30"
      ],
      "primary_category": "cs.AI",
      "comment": "20 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.09624v1",
      "published_date": "2024-08-19 00:56:44 UTC",
      "updated_date": "2024-08-19 00:56:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:50:41.652010"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 119,
  "processed_papers_count": 119,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-19T16:51:05.349935"
}