[
  {
    "arxiv_id": "2505.13778v1",
    "title": "CoIn: Counting the Invisible Reasoning Tokens in Commercial Opaque LLM APIs",
    "authors": [
      "Guoheng Sun",
      "Ziyao Wang",
      "Bowei Tian",
      "Meng Liu",
      "Zheyu Shen",
      "Shwai He",
      "Yexiao He",
      "Wanghao Ye",
      "Yiting Wang",
      "Ang Li"
    ],
    "abstract": "As post-training techniques evolve, large language models (LLMs) are increasingly augmented with structured multi-step reasoning abilities, often optimized through reinforcement learning. These reasoning-enhanced models outperform standard LLMs on complex tasks and now underpin many commercial LLM APIs. However, to protect proprietary behavior and reduce verbosity, providers typically conceal the reasoning traces while returning only the final answer. This opacity introduces a critical transparency gap: users are billed for invisible reasoning tokens, which often account for the majority of the cost, yet have no means to verify their authenticity. This opens the door to token count inflation, where providers may overreport token usage or inject synthetic, low-effort tokens to inflate charges. To address this issue, we propose CoIn, a verification framework that audits both the quantity and semantic validity of hidden tokens. CoIn constructs a verifiable hash tree from token embedding fingerprints to check token counts, and uses embedding-based relevance matching to detect fabricated reasoning content. Experiments demonstrate that CoIn, when deployed as a trusted third-party auditor, can effectively detect token count inflation with a success rate reaching up to 94.7%, showing the strong ability to restore billing transparency in opaque LLM services. The dataset and code are available at https://github.com/CASE-Lab-UMD/LLM-Auditing-CoIn.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.13778v1",
    "published_date": "2025-05-19 23:39:23 UTC",
    "updated_date": "2025-05-19 23:39:23 UTC"
  },
  {
    "arxiv_id": "2505.13777v1",
    "title": "Sat2Sound: A Unified Framework for Zero-Shot Soundscape Mapping",
    "authors": [
      "Subash Khanal",
      "Srikumar Sastry",
      "Aayush Dhakal",
      "Adeel Ahmad",
      "Nathan Jacobs"
    ],
    "abstract": "We present Sat2Sound, a multimodal representation learning framework for soundscape mapping, designed to predict the distribution of sounds at any location on Earth. Existing methods for this task rely on satellite image and paired geotagged audio samples, which often fail to capture the diversity of sound sources at a given location. To address this limitation, we enhance existing datasets by leveraging a Vision-Language Model (VLM) to generate semantically rich soundscape descriptions for locations depicted in satellite images. Our approach incorporates contrastive learning across audio, audio captions, satellite images, and satellite image captions. We hypothesize that there is a fixed set of soundscape concepts shared across modalities. To this end, we learn a shared codebook of soundscape concepts and represent each sample as a weighted average of these concepts. Sat2Sound achieves state-of-the-art performance in cross-modal retrieval between satellite image and audio on two datasets: GeoSound and SoundingEarth. Additionally, building on Sat2Sound's ability to retrieve detailed soundscape captions, we introduce a novel application: location-based soundscape synthesis, which enables immersive acoustic experiences. Our code and models will be publicly available.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.SD"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.13777v1",
    "published_date": "2025-05-19 23:36:04 UTC",
    "updated_date": "2025-05-19 23:36:04 UTC"
  },
  {
    "arxiv_id": "2505.13775v3",
    "title": "Beyond Semantics: The Unreasonable Effectiveness of Reasonless Intermediate Tokens",
    "authors": [
      "Karthik Valmeekam",
      "Kaya Stechly",
      "Vardhan Palod",
      "Atharva Gundawar",
      "Subbarao Kambhampati"
    ],
    "abstract": "Recent impressive results from large reasoning models have been interpreted as a triumph of Chain of Thought (CoT), especially of training on CoTs sampled from base LLMs to help find new reasoning patterns. While these traces certainly seem to help model performance, it is not clear how they actually influence it, with some works ascribing semantics to the traces and others cautioning against relying on them as transparent and faithful proxies of the model's internal computational process. To systematically investigate the role of end-user semantics of derivational traces, we set up a controlled study where we train transformer models from scratch on formally verifiable reasoning traces and the solutions they lead to. We notice that, despite significant gains over the solution-only baseline, models trained on entirely correct traces can still produce invalid reasoning traces even when arriving at correct solutions. More interestingly, our experiments also show that models trained on corrupted traces, whose intermediate reasoning steps bear no relation to the problem they accompany, perform similarly to those trained on correct ones, and even generalize better on out-of-distribution tasks. We also study the effect of GRPO-based RL post-training on trace validity, noting that while solution accuracy increase, this is not accompanied by any improvements in trace validity. Finally, we examine whether reasoning-trace length reflects inference-time scaling and find that trace length is largely agnostic to the underlying computational complexity of the problem being solved. These results challenge the assumption that intermediate tokens or ``Chains of Thought'' reflect or induce predictable reasoning behaviors and caution against anthropomorphizing such outputs or over-interpreting them (despite their mostly seemingly forms) as evidence of human-like or algorithmic behaviors in language models.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.13775v3",
    "published_date": "2025-05-19 23:29:23 UTC",
    "updated_date": "2025-11-22 07:49:57 UTC"
  },
  {
    "arxiv_id": "2505.13774v2",
    "title": "Measuring the Faithfulness of Thinking Drafts in Large Reasoning Models",
    "authors": [
      "Zidi Xiong",
      "Shan Chen",
      "Zhenting Qi",
      "Himabindu Lakkaraju"
    ],
    "abstract": "Large Reasoning Models (LRMs) have significantly enhanced their capabilities in complex problem-solving by introducing a thinking draft that enables multi-path Chain-of-Thought explorations before producing final answers. Ensuring the faithfulness of these intermediate reasoning processes is crucial for reliable monitoring, interpretation, and effective control. In this paper, we propose a systematic counterfactual intervention framework to rigorously evaluate thinking draft faithfulness. Our approach focuses on two complementary dimensions: (1) Intra-Draft Faithfulness, which assesses whether individual reasoning steps causally influence subsequent steps and the final draft conclusion through counterfactual step insertions; and (2) Draft-to-Answer Faithfulness, which evaluates whether final answers are logically consistent with and dependent on the thinking draft, by perturbing the draft's concluding logic. We conduct extensive experiments across six state-of-the-art LRMs. Our findings show that current LRMs demonstrate selective faithfulness to intermediate reasoning steps and frequently fail to faithfully align with the draft conclusions. These results underscore the need for more faithful and interpretable reasoning in advanced LRMs.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.13774v2",
    "published_date": "2025-05-19 23:20:24 UTC",
    "updated_date": "2025-05-28 19:41:14 UTC"
  },
  {
    "arxiv_id": "2505.13773v1",
    "title": "Model Cards for AI Teammates: Comparing Human-AI Team Familiarization Methods for High-Stakes Environments",
    "authors": [
      "Ryan Bowers",
      "Richard Agbeyibor",
      "Jack Kolb",
      "Karen Feigh"
    ],
    "abstract": "We compare three methods of familiarizing a human with an artificial intelligence (AI) teammate (\"agent\") prior to operation in a collaborative, fast-paced intelligence, surveillance, and reconnaissance (ISR) environment. In a between-subjects user study (n=60), participants either read documentation about the agent, trained alongside the agent prior to the mission, or were given no familiarization. Results showed that the most valuable information about the agent included details of its decision-making algorithms and its relative strengths and weaknesses compared to the human. This information allowed the familiarization groups to form sophisticated team strategies more quickly than the control group. Documentation-based familiarization led to the fastest adoption of these strategies, but also biased participants towards risk-averse behavior that prevented high scores. Participants familiarized through direct interaction were able to infer much of the same information through observation, and were more willing to take risks and experiment with different control modes, but reported weaker understanding of the agent's internal processes. Significant differences were seen between individual participants' risk tolerance and methods of AI interaction, which should be considered when designing human-AI control interfaces. Based on our findings, we recommend a human-AI team familiarization method that combines AI documentation, structured in-situ training, and exploratory interaction.",
    "categories": [
      "cs.AI",
      "cs.HC",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "Submitted to IEEE RO-MAN 2025 (under review). 8 pages, 7 figures",
    "pdf_url": "https://arxiv.org/pdf/2505.13773v1",
    "published_date": "2025-05-19 23:19:16 UTC",
    "updated_date": "2025-05-19 23:19:16 UTC"
  },
  {
    "arxiv_id": "2505.13770v1",
    "title": "Ice Cream Doesn't Cause Drowning: Benchmarking LLMs Against Statistical Pitfalls in Causal Inference",
    "authors": [
      "Jin Du",
      "Li Chen",
      "Xun Xian",
      "An Luo",
      "Fangqiao Tian",
      "Ganghua Wang",
      "Charles Doss",
      "Xiaotong Shen",
      "Jie Ding"
    ],
    "abstract": "Reliable causal inference is essential for making decisions in high-stakes areas like medicine, economics, and public policy. However, it remains unclear whether large language models (LLMs) can handle rigorous and trustworthy statistical causal inference. Current benchmarks usually involve simplified tasks. For example, these tasks might only ask LLMs to identify semantic causal relationships or draw conclusions directly from raw data. As a result, models may overlook important statistical pitfalls, such as Simpson's paradox or selection bias. This oversight limits the applicability of LLMs in the real world. To address these limitations, we propose CausalPitfalls, a comprehensive benchmark designed to rigorously evaluate the capability of LLMs in overcoming common causal inference pitfalls. Our benchmark features structured challenges across multiple difficulty levels, each paired with grading rubrics. This approach allows us to quantitatively measure both causal reasoning capabilities and the reliability of LLMs' responses. We evaluate models using two protocols: (1) direct prompting, which assesses intrinsic causal reasoning, and (2) code-assisted prompting, where models generate executable code for explicit statistical analysis. Additionally, we validate the effectiveness of this judge by comparing its scoring with assessments from human experts. Our results reveal significant limitations in current LLMs when performing statistical causal inference. The CausalPitfalls benchmark provides essential guidance and quantitative metrics to advance the development of trustworthy causal reasoning systems.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "stat.ME",
      "stat.ML"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.13770v1",
    "published_date": "2025-05-19 23:06:00 UTC",
    "updated_date": "2025-05-19 23:06:00 UTC"
  },
  {
    "arxiv_id": "2506.11022v2",
    "title": "Security Degradation in Iterative AI Code Generation -- A Systematic Analysis of the Paradox",
    "authors": [
      "Shivani Shukla",
      "Himanshu Joshi",
      "Romilla Syed"
    ],
    "abstract": "The rapid adoption of Large Language Models(LLMs) for code generation has transformed software development, yet little attention has been given to how security vulnerabilities evolve through iterative LLM feedback. This paper analyzes security degradation in AI-generated code through a controlled experiment with 400 code samples across 40 rounds of \"improvements\" using four distinct prompting strategies. Our findings show a 37.6% increase in critical vulnerabilities after just five iterations, with distinct vulnerability patterns emerging across different prompting approaches. This evidence challenges the assumption that iterative LLM refinement improves code security and highlights the essential role of human expertise in the loop. We propose practical guidelines for developers to mitigate these risks, emphasizing the need for robust human validation between LLM iterations to prevent the paradoxical introduction of new security issues during supposedly beneficial code \"improvements\".",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL",
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "Keywords - Large Language Models, Security Vulnerabilities, AI-Generated Code, Iterative Feedback, Software Security, Secure Coding Practices, Feedback Loops, LLM Prompting Strategies",
    "pdf_url": "https://arxiv.org/pdf/2506.11022v2",
    "published_date": "2025-05-19 22:55:51 UTC",
    "updated_date": "2025-09-26 02:44:27 UTC"
  },
  {
    "arxiv_id": "2505.13766v2",
    "title": "Advancing Software Quality: A Standards-Focused Review of LLM-Based Assurance Techniques",
    "authors": [
      "Avinash Patil"
    ],
    "abstract": "Software Quality Assurance (SQA) is critical for delivering reliable, secure, and efficient software products. The Software Quality Assurance Process aims to provide assurance that work products and processes comply with predefined provisions and plans. Recent advancements in Large Language Models (LLMs) present new opportunities to enhance existing SQA processes by automating tasks like requirement analysis, code review, test generation, and compliance checks. Simultaneously, established standards such as ISO/IEC 12207, ISO/IEC 25010, ISO/IEC 5055, ISO 9001/ISO/IEC 90003, CMMI, and TMM provide structured frameworks for ensuring robust quality practices. This paper surveys the intersection of LLM-based SQA methods and these recognized standards, highlighting how AI-driven solutions can augment traditional approaches while maintaining compliance and process maturity. We first review the foundational software quality standards and the technical fundamentals of LLMs in software engineering. Next, we explore various LLM-based SQA applications, including requirement validation, defect detection, test generation, and documentation maintenance. We then map these applications to key software quality frameworks, illustrating how LLMs can address specific requirements and metrics within each standard. Empirical case studies and open-source initiatives demonstrate the practical viability of these methods. At the same time, discussions on challenges (e.g., data privacy, model bias, explainability) underscore the need for deliberate governance and auditing. Finally, we propose future directions encompassing adaptive learning, privacy-focused deployments, multimodal analysis, and evolving standards for AI-driven software quality.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.SE",
    "comment": "16 pages, 1 Table, 6 Figures",
    "pdf_url": "https://arxiv.org/pdf/2505.13766v2",
    "published_date": "2025-05-19 22:49:30 UTC",
    "updated_date": "2026-01-07 19:48:54 UTC"
  },
  {
    "arxiv_id": "2505.13763v2",
    "title": "Language Models Are Capable of Metacognitive Monitoring and Control of Their Internal Activations",
    "authors": [
      "Li Ji-An",
      "Hua-Dong Xiong",
      "Robert C. Wilson",
      "Marcelo G. Mattar",
      "Marcus K. Benna"
    ],
    "abstract": "Large language models (LLMs) can sometimes report the strategies they actually use to solve tasks, yet at other times seem unable to recognize those strategies that govern their behavior. This suggests a limited degree of metacognition - the capacity to monitor one's own cognitive processes for subsequent reporting and self-control. Metacognition enhances LLMs' capabilities in solving complex tasks but also raises safety concerns, as models may obfuscate their internal processes to evade neural-activation-based oversight (e.g., safety detector). Given society's increased reliance on these models, it is critical that we understand their metacognitive abilities. To address this, we introduce a neuroscience-inspired neurofeedback paradigm that uses in-context learning to quantify metacognitive abilities of LLMs to report and control their activation patterns. We demonstrate that their abilities depend on several factors: the number of in-context examples provided, the semantic interpretability of the neural activation direction (to be reported/controlled), and the variance explained by that direction. These directions span a \"metacognitive space\" with dimensionality much lower than the model's neural space, suggesting LLMs can monitor only a small subset of their neural activations. Our paradigm provides empirical evidence to quantify metacognition in LLMs, with significant implications for AI safety (e.g., adversarial attack and defense).",
    "categories": [
      "cs.AI",
      "cs.CL",
      "q-bio.NC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.13763v2",
    "published_date": "2025-05-19 22:32:25 UTC",
    "updated_date": "2025-10-24 02:36:51 UTC"
  },
  {
    "arxiv_id": "2506.06301v1",
    "title": "Large Language Models and Their Applications in Roadway Safety and Mobility Enhancement: A Comprehensive Review",
    "authors": [
      "Muhammad Monjurul Karim",
      "Yan Shi",
      "Shucheng Zhang",
      "Bingzhang Wang",
      "Mehrdad Nasri",
      "Yinhai Wang"
    ],
    "abstract": "Roadway safety and mobility remain critical challenges for modern transportation systems, demanding innovative analytical frameworks capable of addressing complex, dynamic, and heterogeneous environments. While traditional engineering methods have made progress, the complexity and dynamism of real-world traffic necessitate more advanced analytical frameworks. Large Language Models (LLMs), with their unprecedented capabilities in natural language understanding, knowledge integration, and reasoning, represent a promising paradigm shift. This paper comprehensively reviews the application and customization of LLMs for enhancing roadway safety and mobility. A key focus is how LLMs are adapted -- via architectural, training, prompting, and multimodal strategies -- to bridge the \"modality gap\" with transportation's unique spatio-temporal and physical data. The review systematically analyzes diverse LLM applications in mobility (e.g., traffic flow prediction, signal control) and safety (e.g., crash analysis, driver behavior assessment,). Enabling technologies such as V2X integration, domain-specific foundation models, explainability frameworks, and edge computing are also examined. Despite significant potential, challenges persist regarding inherent LLM limitations (hallucinations, reasoning deficits), data governance (privacy, bias), deployment complexities (sim-to-real, latency), and rigorous safety assurance. Promising future research directions are highlighted, including advanced multimodal fusion, enhanced spatio-temporal reasoning, human-AI collaboration, continuous learning, and the development of efficient, verifiable systems. This review provides a structured roadmap of current capabilities, limitations, and opportunities, underscoring LLMs' transformative potential while emphasizing the need for responsible innovation to realize safer, more intelligent transportation systems.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.06301v1",
    "published_date": "2025-05-19 21:51:18 UTC",
    "updated_date": "2025-05-19 21:51:18 UTC"
  },
  {
    "arxiv_id": "2505.13742v1",
    "title": "Understanding Task Representations in Neural Networks via Bayesian Ablation",
    "authors": [
      "Andrew Nam",
      "Declan Campbell",
      "Thomas Griffiths",
      "Jonathan Cohen",
      "Sarah-Jane Leslie"
    ],
    "abstract": "Neural networks are powerful tools for cognitive modeling due to their flexibility and emergent properties. However, interpreting their learned representations remains challenging due to their sub-symbolic semantics. In this work, we introduce a novel probabilistic framework for interpreting latent task representations in neural networks. Inspired by Bayesian inference, our approach defines a distribution over representational units to infer their causal contributions to task performance. Using ideas from information theory, we propose a suite of tools and metrics to illuminate key model properties, including representational distributedness, manifold complexity, and polysemanticity.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.13742v1",
    "published_date": "2025-05-19 21:36:09 UTC",
    "updated_date": "2025-05-19 21:36:09 UTC"
  },
  {
    "arxiv_id": "2505.13740v2",
    "title": "Improving Compositional Generation with Diffusion Models Using Lift Scores",
    "authors": [
      "Chenning Yu",
      "Sicun Gao"
    ],
    "abstract": "We introduce a novel resampling criterion using lift scores, for improving compositional generation in diffusion models. By leveraging the lift scores, we evaluate whether generated samples align with each single condition and then compose the results to determine whether the composed prompt is satisfied. Our key insight is that lift scores can be efficiently approximated using only the original diffusion model, requiring no additional training or external modules. We develop an optimized variant that achieves relatively lower computational overhead during inference while maintaining effectiveness. Through extensive experiments, we demonstrate that lift scores significantly improved the condition alignment for compositional generation across 2D synthetic data, CLEVR position tasks, and text-to-image synthesis. Our code is available at http://rainorangelemon.github.io/complift.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.13740v2",
    "published_date": "2025-05-19 21:34:42 UTC",
    "updated_date": "2025-05-25 22:15:10 UTC"
  },
  {
    "arxiv_id": "2505.13738v2",
    "title": "Power Lines: Scaling Laws for Weight Decay and Batch Size in LLM Pre-training",
    "authors": [
      "Shane Bergsma",
      "Nolan Dey",
      "Gurpreet Gosal",
      "Gavia Gray",
      "Daria Soboleva",
      "Joel Hestness"
    ],
    "abstract": "Efficient LLM pre-training requires well-tuned hyperparameters (HPs), including learning rate $η$ and weight decay $λ$. We study scaling laws for HPs: formulas for how to scale HPs as we scale model size N, dataset size D, and batch size B. Recent work suggests the AdamW timescale, $τ= B/(ηλD)$, should remain constant across training settings, and we verify the implication that optimal $λ$ scales linearly with B, for a fixed N and D. However, as N and D scale, we show optimal $τ$ obeys a precise power law in the tokens-per-parameter ratio, D/N. This law thus provides a method to accurately predict $λ$opt in advance of large-scale training. We also study scaling laws for optimal batch size Bopt (the B enabling lowest loss at a given N,D) and critical batch size Bcrit (the B beyond which further data parallelism becomes ineffective). In contrast to prior work, we find both Bopt and Bcrit scale as power laws in D, independent of model size, N. Finally, we analyze how these findings inform the real-world selection of Pareto-optimal N and D under dual training time and compute objectives. All experiments were run on Cerebras CS-3 systems.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "NeurIPS 2025",
    "pdf_url": "https://arxiv.org/pdf/2505.13738v2",
    "published_date": "2025-05-19 21:27:33 UTC",
    "updated_date": "2025-11-23 19:09:41 UTC"
  },
  {
    "arxiv_id": "2505.13737v2",
    "title": "Causal Head Gating: A Framework for Interpreting Roles of Attention Heads in Transformers",
    "authors": [
      "Andrew Nam",
      "Henry Conklin",
      "Yukang Yang",
      "Thomas Griffiths",
      "Jonathan Cohen",
      "Sarah-Jane Leslie"
    ],
    "abstract": "We present causal head gating (CHG), a scalable method for interpreting the functional roles of attention heads in transformer models. CHG learns soft gates over heads and assigns them a causal taxonomy - facilitating, interfering, or irrelevant - based on their impact on task performance. Unlike prior approaches in mechanistic interpretability, which are hypothesis-driven and require prompt templates or target labels, CHG applies directly to any dataset using standard next-token prediction. We evaluate CHG across multiple large language models (LLMs) in the Llama 3 model family and diverse tasks, including syntax, commonsense, and mathematical reasoning, and show that CHG scores yield causal, not merely correlational, insight validated via ablation and causal mediation analyses. We also introduce contrastive CHG, a variant that isolates sub-circuits for specific task components. Our findings reveal that LLMs contain multiple sparse task-sufficient sub-circuits, that individual head roles depend on interactions with others (low modularity), and that instruction following and in-context learning rely on separable mechanisms.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "10 pages, 5 figures, 2 tables. The Thirty-Ninth Annual Conference on Neural Information Processing Systems (NeurIPS 2025)",
    "pdf_url": "https://arxiv.org/pdf/2505.13737v2",
    "published_date": "2025-05-19 21:24:13 UTC",
    "updated_date": "2025-10-23 23:48:30 UTC"
  },
  {
    "arxiv_id": "2505.13729v1",
    "title": "SayCoNav: Utilizing Large Language Models for Adaptive Collaboration in Decentralized Multi-Robot Navigation",
    "authors": [
      "Abhinav Rajvanshi",
      "Pritish Sahu",
      "Tixiao Shan",
      "Karan Sikka",
      "Han-Pang Chiu"
    ],
    "abstract": "Adaptive collaboration is critical to a team of autonomous robots to perform complicated navigation tasks in large-scale unknown environments. An effective collaboration strategy should be determined and adapted according to each robot's skills and current status to successfully achieve the shared goal. We present SayCoNav, a new approach that leverages large language models (LLMs) for automatically generating this collaboration strategy among a team of robots. Building on the collaboration strategy, each robot uses the LLM to generate its plans and actions in a decentralized way. By sharing information to each other during navigation, each robot also continuously updates its step-by-step plans accordingly. We evaluate SayCoNav on Multi-Object Navigation (MultiON) tasks, that require the team of the robots to utilize their complementary strengths to efficiently search multiple different objects in unknown environments. By validating SayCoNav with varied team compositions and conditions against baseline methods, our experimental results show that SayCoNav can improve search efficiency by at most 44.28% through effective collaboration among heterogeneous robots. It can also dynamically adapt to the changing conditions during task execution.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.13729v1",
    "published_date": "2025-05-19 20:58:06 UTC",
    "updated_date": "2025-05-19 20:58:06 UTC"
  },
  {
    "arxiv_id": "2505.17072v2",
    "title": "Safety Alignment Can Be Not Superficial With Explicit Safety Signals",
    "authors": [
      "Jianwei Li",
      "Jung-Eun Kim"
    ],
    "abstract": "Recent studies on the safety alignment of large language models (LLMs) have revealed that existing approaches often operate superficially, leaving models vulnerable to various adversarial attacks. Despite their significance, these studies generally fail to offer actionable solutions beyond data augmentation for achieving more robust safety mechanisms. This paper identifies a fundamental cause of this superficiality: existing alignment approaches often presume that models can implicitly learn a safety-related reasoning task during the alignment process, enabling them to refuse harmful requests. However, the learned safety signals are often diluted by other competing objectives, leading models to struggle with drawing a firm safety-conscious decision boundary when confronted with adversarial attacks. Based on this observation, by explicitly introducing a safety-related binary classification task and integrating its signals with our attention and decoding strategies, we eliminate this ambiguity and allow models to respond more responsibly to malicious queries. We emphasize that, with less than 0.2x overhead cost, our approach enables LLMs to assess the safety of both the query and the previously generated tokens at each necessary generating step. Extensive experiments demonstrate that our method significantly improves the resilience of LLMs against various adversarial attacks, offering a promising pathway toward more robust generative AI systems.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "ICML 2025",
    "pdf_url": "https://arxiv.org/pdf/2505.17072v2",
    "published_date": "2025-05-19 20:40:46 UTC",
    "updated_date": "2025-05-30 05:54:56 UTC"
  },
  {
    "arxiv_id": "2505.13718v2",
    "title": "Warm Up Before You Train: Unlocking General Reasoning in Resource-Constrained Settings",
    "authors": [
      "Safal Shrestha",
      "Minwu Kim",
      "Aadim Nepal",
      "Anubhav Shrestha",
      "Keith Ross"
    ],
    "abstract": "Designing effective reasoning-capable LLMs typically requires training using Reinforcement Learning with Verifiable Rewards (RLVR) or distillation with carefully curated Long Chain of Thoughts (CoT), both of which depend heavily on extensive training data. This creates a major challenge when the amount of quality training data is scarce. We propose a sample-efficient, two-stage training strategy to develop reasoning LLMs under limited supervision. In the first stage, we \"warm up\" the model by distilling Long CoTs from a toy domain, namely, Knights \\& Knaves (K\\&K) logic puzzles to acquire general reasoning skills. In the second stage, we apply RLVR to the warmed-up model using a limited set of target-domain examples. Our experiments demonstrate that this two-phase approach offers several benefits: $(i)$ the warmup phase alone facilitates generalized reasoning, leading to performance improvements across a range of tasks, including MATH, HumanEval$^{+}$, and MMLU-Pro; $(ii)$ When both the base model and the warmed-up model are RLVR trained on the same small dataset ($\\leq100$ examples), the warmed-up model consistently outperforms the base model; $(iii)$ Warming up before RLVR training allows a model to maintain cross-domain generalizability even after training on a specific domain; $(iv)$ Introducing warmup in the pipeline improves not only accuracy but also overall sample efficiency during RLVR training. The results in this paper highlight the promise of warmup for building robust reasoning LLMs in data-scarce environments.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.13718v2",
    "published_date": "2025-05-19 20:29:15 UTC",
    "updated_date": "2025-05-26 08:43:26 UTC"
  },
  {
    "arxiv_id": "2505.15849v2",
    "title": "What Lives? A meta-analysis of diverse opinions on the definition of life",
    "authors": [
      "Reed Bender",
      "Karina Kofman",
      "Blaise Agüera y Arcas",
      "Michael Levin"
    ],
    "abstract": "The question of \"what is life?\" has challenged scientists and philosophers for centuries, producing an array of definitions that reflect both the mystery of its emergence and the diversity of disciplinary perspectives brought to bear on the question. Despite significant progress in our understanding of biological systems, psychology, computation, and information theory, no single definition for life has yet achieved universal acceptance. This challenge becomes increasingly urgent as advances in synthetic biology, artificial intelligence, and astrobiology challenge our traditional conceptions of what it means to be alive. We undertook a methodological approach that leverages large language models (LLMs) to analyze a set of definitions of life provided by a curated set of cross-disciplinary experts. We used a novel pairwise correlation analysis to map the definitions into distinct feature vectors, followed by agglomerative clustering, intra-cluster semantic analysis, and t-SNE projection to reveal underlying conceptual archetypes. This methodology revealed a continuous landscape of the themes relating to the definition of life, suggesting that what has historically been approached as a binary taxonomic problem should be instead conceived as differentiated perspectives within a unified conceptual latent space. We offer a new methodological bridge between reductionist and holistic approaches to fundamental questions in science and philosophy, demonstrating how computational semantic analysis can reveal conceptual patterns across disciplinary boundaries, and opening similar pathways for addressing other contested definitional territories across the sciences.",
    "categories": [
      "q-bio.OT",
      "cs.AI",
      "cs.CY",
      "q-bio.BM",
      "q-bio.CB",
      "q-bio.SC",
      "stat.AP"
    ],
    "primary_category": "q-bio.OT",
    "comment": "54 pages, 4 figures, 2 tables, 11 supplemental figures, 3 supplemental tables",
    "pdf_url": "https://arxiv.org/pdf/2505.15849v2",
    "published_date": "2025-05-19 20:17:37 UTC",
    "updated_date": "2025-08-06 12:47:41 UTC"
  },
  {
    "arxiv_id": "2505.13709v2",
    "title": "Policy-Driven World Model Adaptation for Robust Offline Model-based Reinforcement Learning",
    "authors": [
      "Jiayu Chen",
      "Le Xu",
      "Aravind Venugopal",
      "Jeff Schneider"
    ],
    "abstract": "Offline reinforcement learning (RL) offers a powerful paradigm for data-driven control. Compared to model-free approaches, offline model-based RL (MBRL) explicitly learns a world model from a static dataset and uses it as a surrogate simulator, improving data efficiency and enabling potential generalization beyond the dataset support. However, most existing offline MBRL methods follow a two-stage training procedure: first learning a world model by maximizing the likelihood of the observed transitions, then optimizing a policy to maximize its expected return under the learned model. This objective mismatch results in a world model that is not necessarily optimized for effective policy learning. Moreover, we observe that policies learned via offline MBRL often lack robustness during deployment, and small adversarial noise in the environment can lead to significant performance degradation. To address these, we propose a framework that dynamically adapts the world model alongside the policy under a unified learning objective aimed at improving robustness. At the core of our method is a maximin optimization problem, which we solve by innovatively utilizing Stackelberg learning dynamics. We provide theoretical analysis to support our design and introduce computationally efficient implementations. We benchmark our algorithm on twelve noisy D4RL MuJoCo tasks and three stochastic Tokamak Control tasks, demonstrating its state-of-the-art performance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.13709v2",
    "published_date": "2025-05-19 20:14:33 UTC",
    "updated_date": "2025-11-11 07:00:57 UTC"
  },
  {
    "arxiv_id": "2505.13706v1",
    "title": "Are Large Language Models Good at Detecting Propaganda?",
    "authors": [
      "Julia Jose",
      "Rachel Greenstadt"
    ],
    "abstract": "Propagandists use rhetorical devices that rely on logical fallacies and emotional appeals to advance their agendas. Recognizing these techniques is key to making informed decisions. Recent advances in Natural Language Processing (NLP) have enabled the development of systems capable of detecting manipulative content. In this study, we look at several Large Language Models and their performance in detecting propaganda techniques in news articles. We compare the performance of these LLMs with transformer-based models. We find that, while GPT-4 demonstrates superior F1 scores (F1=0.16) compared to GPT-3.5 and Claude 3 Opus, it does not outperform a RoBERTa-CRF baseline (F1=0.67). Additionally, we find that all three LLMs outperform a MultiGranularity Network (MGN) baseline in detecting instances of one out of six propaganda techniques (name-calling), with GPT-3.5 and GPT-4 also outperforming the MGN baseline in detecting instances of appeal to fear and flag-waving.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.13706v1",
    "published_date": "2025-05-19 20:11:13 UTC",
    "updated_date": "2025-05-19 20:11:13 UTC"
  },
  {
    "arxiv_id": "2505.13697v3",
    "title": "RL in Name Only? Analyzing the Structural Assumptions in RL post-training for LLMs",
    "authors": [
      "Soumya Rani Samineni",
      "Durgesh Kalwar",
      "Karthik Valmeekam",
      "Kaya Stechly",
      "Subbarao Kambhampati"
    ],
    "abstract": "Reinforcement learning-based post-training of large language models (LLMs) has recently gained attention, particularly following the release of DeepSeek R1, which applied GRPO for fine-tuning. Amid the growing hype around improved reasoning abilities attributed to RL post-training, we critically examine the formulation and assumptions underlying these methods. We start by highlighting the popular structural assumptions made in modeling LLM training as a Markov Decision Process (MDP), and show how they lead to a degenerate MDP that doesn't quite need the RL/GRPO apparatus. The two critical structural assumptions include (1) making the MDP states be just a concatenation of the actions-with states becoming the context window and the actions becoming the tokens in LLMs and (2) splitting the reward of a state-action trajectory uniformly across the trajectory. Through a comprehensive analysis, we demonstrate that these simplifying assumptions make the approach effectively equivalent to an outcome-driven supervised learning. Our experiments on benchmarks including GSM8K and Countdown using Qwen-2.5 base models show that iterative supervised fine-tuning, incorporating both positive and negative samples, achieves performance comparable to GRPO-based training. We will also argue that the structural assumptions indirectly incentivize the RL to generate longer sequences of intermediate tokens-which in turn feeds into the narrative of \"RL generating longer thinking traces.\" While RL may well be a very useful technique for improving the reasoning abilities of LLMs, our analysis shows that the simplistic structural assumptions made in modeling the underlying MDP render the popular LLM RL frameworks and their interpretations questionable.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.13697v3",
    "published_date": "2025-05-19 19:57:15 UTC",
    "updated_date": "2025-11-10 23:14:22 UTC"
  },
  {
    "arxiv_id": "2505.13696v1",
    "title": "Building spatial world models from sparse transitional episodic memories",
    "authors": [
      "Zizhan He",
      "Maxime Daigle",
      "Pouya Bashivan"
    ],
    "abstract": "Many animals possess a remarkable capacity to rapidly construct flexible mental models of their environments. These world models are crucial for ethologically relevant behaviors such as navigation, exploration, and planning. The ability to form episodic memories and make inferences based on these sparse experiences is believed to underpin the efficiency and adaptability of these models in the brain. Here, we ask: Can a neural network learn to construct a spatial model of its surroundings from sparse and disjoint episodic memories? We formulate the problem in a simulated world and propose a novel framework, the Episodic Spatial World Model (ESWM), as a potential answer. We show that ESWM is highly sample-efficient, requiring minimal observations to construct a robust representation of the environment. It is also inherently adaptive, allowing for rapid updates when the environment changes. In addition, we demonstrate that ESWM readily enables near-optimal strategies for exploring novel environments and navigating between arbitrary points, all without the need for additional training.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.13696v1",
    "published_date": "2025-05-19 19:56:24 UTC",
    "updated_date": "2025-05-19 19:56:24 UTC"
  },
  {
    "arxiv_id": "2505.13672v1",
    "title": "A*-Decoding: Token-Efficient Inference Scaling",
    "authors": [
      "Giannis Chatziveroglou"
    ],
    "abstract": "Inference-time scaling has emerged as a powerful alternative to parameter scaling for improving language model performance on complex reasoning tasks. While existing methods have shown strong performance gains under fixed compute budgets, there has been little focus on optimally utilizing that budget during inference. In this work, we introduce A*-decoding, a search-based inference-time strategy that builds on the A* search algorithm to optimally utilize a fixed compute budget by prioritizing high-quality reasoning paths during generation. We frame language model decoding as a structured search in a state space of partial solutions, applying the A* transition model to identify promising continuations guided by an external process supervision signal. In our experiments, A*-decoding reaches the performance levels of strong inference scaling baselines like best-of-N and particle filtering while using up to 3x fewer tokens and 30% fewer PRM passes under equivalent compute budgets. On the MATH500 and AIME 2024 benchmarks, A*-decoding enables Llama-3.2-1B-Instruct to match the performance of the 70x larger Llama-3.1-70B-Instruct, and allows Qwen3-1.7B to reach o1-like reasoning accuracy. These results highlight the power of structured search in decoding, offering an alternative to brute-force sampling or scale-driven gains. Our work demonstrates how thoughtful inference-time strategies can enhance reasoning in SLMs, pointing toward future advances in more efficient and scalable language model deployment.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.13672v1",
    "published_date": "2025-05-19 19:19:48 UTC",
    "updated_date": "2025-05-19 19:19:48 UTC"
  },
  {
    "arxiv_id": "2505.13668v3",
    "title": "MAFA: A multi-agent framework for annotation",
    "authors": [
      "Mahmood Hegazy",
      "Aaron Rodrigues",
      "Azzam Naeem"
    ],
    "abstract": "Modern consumer banking applications require accurate and efficient retrieval of information in response to user queries. Mapping user utterances to the most relevant Frequently Asked Questions (FAQs) is a crucial component of these systems. Traditional approaches often rely on a single model or technique, which may not capture the nuances of diverse user inquiries. In this paper, we introduce a multi-agent framework for FAQ annotation that combines multiple specialized agents with different approaches and a judge agent that reranks candidates to produce optimal results. Our agents utilize a structured reasoning approach inspired by Attentive Reasoning Queries (ARQs), which guides them through systematic reasoning steps using targeted, task-specific JSON queries. Our framework features a few-shot example strategy, where each agent receives different few-shots, enhancing ensemble diversity and coverage of the query space. We evaluate our framework on a real-world major bank dataset as well as public benchmark datasets (LCQMC and FiQA), demonstrating significant improvements over single-agent approaches across multiple metrics, including a 14% increase in Top-1 accuracy, an 18% increase in Top-5 accuracy, and a 12% improvement in Mean Reciprocal Rank on our dataset, and similar gains on public benchmarks when compared with traditional and single-agent annotation techniques. Our framework is particularly effective at handling ambiguous queries, making it well-suited for deployment in production banking applications while showing strong generalization capabilities across different domains and languages.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.13668v3",
    "published_date": "2025-05-19 19:16:37 UTC",
    "updated_date": "2025-10-15 21:26:33 UTC"
  },
  {
    "arxiv_id": "2505.13650v1",
    "title": "Self-Reinforced Graph Contrastive Learning",
    "authors": [
      "Chou-Ying Hsieh",
      "Chun-Fu Jang",
      "Cheng-En Hsieh",
      "Qian-Hui Chen",
      "Sy-Yen Kuo"
    ],
    "abstract": "Graphs serve as versatile data structures in numerous real-world domains-including social networks, molecular biology, and knowledge graphs-by capturing intricate relational information among entities. Among graph-based learning techniques, Graph Contrastive Learning (GCL) has gained significant attention for its ability to derive robust, self-supervised graph representations through the contrasting of positive and negative sample pairs. However, a critical challenge lies in ensuring high-quality positive pairs so that the intrinsic semantic and structural properties of the original graph are preserved rather than distorted. To address this issue, we propose SRGCL (Self-Reinforced Graph Contrastive Learning), a novel framework that leverages the model's own encoder to dynamically evaluate and select high-quality positive pairs. We designed a unified positive pair generator employing multiple augmentation strategies, and a selector guided by the manifold hypothesis to maintain the underlying geometry of the latent space. By adopting a probabilistic mechanism for selecting positive pairs, SRGCL iteratively refines its assessment of pair quality as the encoder's representational power improves. Extensive experiments on diverse graph-level classification tasks demonstrate that SRGCL, as a plug-in module, consistently outperforms state-of-the-art GCL methods, underscoring its adaptability and efficacy across various domains.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.13650v1",
    "published_date": "2025-05-19 18:45:54 UTC",
    "updated_date": "2025-05-19 18:45:54 UTC"
  },
  {
    "arxiv_id": "2505.13636v2",
    "title": "Incentivizing Truthful Language Models via Peer Elicitation Games",
    "authors": [
      "Baiting Chen",
      "Tong Zhu",
      "Jiale Han",
      "Lexin Li",
      "Gang Li",
      "Xiaowu Dai"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated strong generative capabilities but remain prone to inconsistencies and hallucinations. We introduce Peer Elicitation Games (PEG), a training-free, game-theoretic framework for aligning LLMs through a peer elicitation mechanism involving a generator and multiple discriminators instantiated from distinct base models. Discriminators interact in a peer evaluation setting, where utilities are computed using a determinant-based mutual information score that provably incentivizes truthful reporting without requiring ground-truth labels. We establish theoretical guarantees showing that each agent, via online learning, achieves sublinear regret in the sense their cumulative performance approaches that of the best fixed truthful strategy in hindsight. Moreover, we prove last-iterate convergence to a truthful Nash equilibrium, ensuring that the actual policies used by agents converge to stable and truthful behavior over time. Empirical evaluations across multiple benchmarks demonstrate significant improvements in factual accuracy. These results position PEG as a practical approach for eliciting truthful behavior from LLMs without supervision or fine-tuning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.GT"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.13636v2",
    "published_date": "2025-05-19 18:16:58 UTC",
    "updated_date": "2025-10-19 21:36:32 UTC"
  },
  {
    "arxiv_id": "2505.13631v2",
    "title": "Learning (Approximately) Equivariant Networks via Constrained Optimization",
    "authors": [
      "Andrei Manolache",
      "Luiz F. O. Chamon",
      "Mathias Niepert"
    ],
    "abstract": "Equivariant neural networks are designed to respect symmetries through their architecture, boosting generalization and sample efficiency when those symmetries are present in the data distribution. Real-world data, however, often departs from perfect symmetry because of noise, structural variation, measurement bias, or other symmetry-breaking effects. Strictly equivariant models may struggle to fit the data, while unconstrained models lack a principled way to leverage partial symmetries. Even when the data is fully symmetric, enforcing equivariance can hurt training by limiting the model to a restricted region of the parameter space. Guided by homotopy principles, where an optimization problem is solved by gradually transforming a simpler problem into a complex one, we introduce Adaptive Constrained Equivariance (ACE), a constrained optimization approach that starts with a flexible, non-equivariant model and gradually reduces its deviation from equivariance. This gradual tightening smooths training early on and settles the model at a data-driven equilibrium, balancing between equivariance and non-equivariance. Across multiple architectures and tasks, our method consistently improves performance metrics, sample efficiency, and robustness to input perturbations compared with strictly equivariant models and heuristic equivariance relaxations.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "NeurIPS 2025 Oral Camera-Ready",
    "pdf_url": "https://arxiv.org/pdf/2505.13631v2",
    "published_date": "2025-05-19 18:08:09 UTC",
    "updated_date": "2025-12-11 07:51:20 UTC"
  },
  {
    "arxiv_id": "2505.13617v1",
    "title": "Direction-Aware Neural Acoustic Fields for Few-Shot Interpolation of Ambisonic Impulse Responses",
    "authors": [
      "Christopher Ick",
      "Gordon Wichern",
      "Yoshiki Masuyama",
      "François Germain",
      "Jonathan Le Roux"
    ],
    "abstract": "The characteristics of a sound field are intrinsically linked to the geometric and spatial properties of the environment surrounding a sound source and a listener. The physics of sound propagation is captured in a time-domain signal known as a room impulse response (RIR). Prior work using neural fields (NFs) has allowed learning spatially-continuous representations of RIRs from finite RIR measurements. However, previous NF-based methods have focused on monaural omnidirectional or at most binaural listeners, which does not precisely capture the directional characteristics of a real sound field at a single point. We propose a direction-aware neural field (DANF) that more explicitly incorporates the directional information by Ambisonic-format RIRs. While DANF inherently captures spatial relations between sources and listeners, we further propose a direction-aware loss. In addition, we investigate the ability of DANF to adapt to new rooms in various ways including low-rank adaptation.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "cs.SD"
    ],
    "primary_category": "eess.AS",
    "comment": "Accepted at Interspeech 2025",
    "pdf_url": "https://arxiv.org/pdf/2505.13617v1",
    "published_date": "2025-05-19 18:01:53 UTC",
    "updated_date": "2025-05-19 18:01:53 UTC"
  },
  {
    "arxiv_id": "2505.13448v2",
    "title": "CIE: Controlling Language Model Text Generations Using Continuous Signals",
    "authors": [
      "Vinay Samuel",
      "Harshita Diddee",
      "Yiming Zhang",
      "Daphne Ippolito"
    ],
    "abstract": "Aligning language models (LMs) with user intent is becoming increasingly relevant to enhance user experience. This calls for designing methods that can allow users to control the properties of the language that LMs generate, for example, controlling the length of the generation or the complexity of the language that gets chosen. Most existing work attempts to integrate users' control by conditioning LM generations on natural language prompts or discrete control signals, which are often brittle and hard to scale. In this work, we are interested in continuous control signals, ones that exist along a spectrum that can't easily be captured in a natural language prompt or via existing techniques in conditional generation. Through a case study in controlling the precise response-length of generations, we demonstrate how an LM can be finetuned to expect a control vector that is interpolated between a \"low\" and a \"high\" token embedding. Our method more reliably exerts response-length control than in-context learning methods or fine-tuning methods that represent the control signal as a discrete signal.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "EMNLP Main 2025",
    "pdf_url": "https://arxiv.org/pdf/2505.13448v2",
    "published_date": "2025-05-19 17:59:58 UTC",
    "updated_date": "2025-09-19 19:06:03 UTC"
  },
  {
    "arxiv_id": "2505.13445v1",
    "title": "Trust, But Verify: A Self-Verification Approach to Reinforcement Learning with Verifiable Rewards",
    "authors": [
      "Xiaoyuan Liu",
      "Tian Liang",
      "Zhiwei He",
      "Jiahao Xu",
      "Wenxuan Wang",
      "Pinjia He",
      "Zhaopeng Tu",
      "Haitao Mi",
      "Dong Yu"
    ],
    "abstract": "Large Language Models (LLMs) show great promise in complex reasoning, with Reinforcement Learning with Verifiable Rewards (RLVR) being a key enhancement strategy. However, a prevalent issue is ``superficial self-reflection'', where models fail to robustly verify their own outputs. We introduce RISE (Reinforcing Reasoning with Self-Verification), a novel online RL framework designed to tackle this. RISE explicitly and simultaneously trains an LLM to improve both its problem-solving and self-verification abilities within a single, integrated RL process. The core mechanism involves leveraging verifiable rewards from an outcome verifier to provide on-the-fly feedback for both solution generation and self-verification tasks. In each iteration, the model generates solutions, then critiques its own on-policy generated solutions, with both trajectories contributing to the policy update. Extensive experiments on diverse mathematical reasoning benchmarks show that RISE consistently improves model's problem-solving accuracy while concurrently fostering strong self-verification skills. Our analyses highlight the advantages of online verification and the benefits of increased verification compute. Additionally, RISE models exhibit more frequent and accurate self-verification behaviors during reasoning. These advantages reinforce RISE as a flexible and effective path towards developing more robust and self-aware reasoners.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "code available at https://github.com/xyliu-cs/RISE",
    "pdf_url": "https://arxiv.org/pdf/2505.13445v1",
    "published_date": "2025-05-19 17:59:31 UTC",
    "updated_date": "2025-05-19 17:59:31 UTC"
  },
  {
    "arxiv_id": "2505.13439v1",
    "title": "VTBench: Evaluating Visual Tokenizers for Autoregressive Image Generation",
    "authors": [
      "Huawei Lin",
      "Tong Geng",
      "Zhaozhuo Xu",
      "Weijie Zhao"
    ],
    "abstract": "Autoregressive (AR) models have recently shown strong performance in image generation, where a critical component is the visual tokenizer (VT) that maps continuous pixel inputs to discrete token sequences. The quality of the VT largely defines the upper bound of AR model performance. However, current discrete VTs fall significantly behind continuous variational autoencoders (VAEs), leading to degraded image reconstructions and poor preservation of details and text. Existing benchmarks focus on end-to-end generation quality, without isolating VT performance. To address this gap, we introduce VTBench, a comprehensive benchmark that systematically evaluates VTs across three core tasks: Image Reconstruction, Detail Preservation, and Text Preservation, and covers a diverse range of evaluation scenarios. We systematically assess state-of-the-art VTs using a set of metrics to evaluate the quality of reconstructed images. Our findings reveal that continuous VAEs produce superior visual representations compared to discrete VTs, particularly in retaining spatial structure and semantic detail. In contrast, the degraded representations produced by discrete VTs often lead to distorted reconstructions, loss of fine-grained textures, and failures in preserving text and object integrity. Furthermore, we conduct experiments on GPT-4o image generation and discuss its potential AR nature, offering new insights into the role of visual tokenization. We release our benchmark and codebase publicly to support further research and call on the community to develop strong, general-purpose open-source VTs.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "24 pages, 13 figures, 3 tables",
    "pdf_url": "https://arxiv.org/pdf/2505.13439v1",
    "published_date": "2025-05-19 17:59:01 UTC",
    "updated_date": "2025-05-19 17:59:01 UTC"
  },
  {
    "arxiv_id": "2505.13438v3",
    "title": "Optimizing Anytime Reasoning via Budget Relative Policy Optimization",
    "authors": [
      "Penghui Qi",
      "Zichen Liu",
      "Tianyu Pang",
      "Chao Du",
      "Wee Sun Lee",
      "Min Lin"
    ],
    "abstract": "Scaling test-time compute is crucial for enhancing the reasoning capabilities of large language models (LLMs). Existing approaches typically employ reinforcement learning (RL) to maximize a verifiable reward obtained at the end of reasoning traces. However, such methods optimize only the final performance under a large and fixed token budget, which hinders efficiency in both training and deployment. In this work, we present a novel framework, AnytimeReasoner, to optimize anytime reasoning performance, which aims to improve token efficiency and the flexibility of reasoning under varying token budget constraints. To achieve this, we truncate the complete thinking process to fit within sampled token budgets from a prior distribution, compelling the model to summarize the optimal answer for each truncated thinking for verification. This introduces verifiable dense rewards into the reasoning process, facilitating more effective credit assignment in RL optimization. We then optimize the thinking and summary policies in a decoupled manner to maximize the cumulative reward. Additionally, we introduce a novel variance reduction technique, Budget Relative Policy Optimization (BRPO), to enhance the robustness and efficiency of the learning process when reinforcing the thinking policy. Empirical results in mathematical reasoning tasks demonstrate that our method consistently outperforms GRPO across all thinking budgets under various prior distributions, enhancing both training and token efficiency.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.13438v3",
    "published_date": "2025-05-19 17:58:44 UTC",
    "updated_date": "2025-11-07 07:01:30 UTC"
  },
  {
    "arxiv_id": "2505.13437v1",
    "title": "FinePhys: Fine-grained Human Action Generation by Explicitly Incorporating Physical Laws for Effective Skeletal Guidance",
    "authors": [
      "Dian Shao",
      "Mingfei Shi",
      "Shengda Xu",
      "Haodong Chen",
      "Yongle Huang",
      "Binglu Wang"
    ],
    "abstract": "Despite significant advances in video generation, synthesizing physically plausible human actions remains a persistent challenge, particularly in modeling fine-grained semantics and complex temporal dynamics. For instance, generating gymnastics routines such as \"switch leap with 0.5 turn\" poses substantial difficulties for current methods, often yielding unsatisfactory results. To bridge this gap, we propose FinePhys, a Fine-grained human action generation framework that incorporates Physics to obtain effective skeletal guidance. Specifically, FinePhys first estimates 2D poses in an online manner and then performs 2D-to-3D dimension lifting via in-context learning. To mitigate the instability and limited interpretability of purely data-driven 3D poses, we further introduce a physics-based motion re-estimation module governed by Euler-Lagrange equations, calculating joint accelerations via bidirectional temporal updating. The physically predicted 3D poses are then fused with data-driven ones, offering multi-scale 2D heatmap guidance for the diffusion process. Evaluated on three fine-grained action subsets from FineGym (FX-JUMP, FX-TURN, and FX-SALTO), FinePhys significantly outperforms competitive baselines. Comprehensive qualitative results further demonstrate FinePhys's ability to generate more natural and plausible fine-grained human actions.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "CVPR 2025",
    "pdf_url": "https://arxiv.org/pdf/2505.13437v1",
    "published_date": "2025-05-19 17:58:11 UTC",
    "updated_date": "2025-05-19 17:58:11 UTC"
  },
  {
    "arxiv_id": "2505.13427v2",
    "title": "MM-PRM: Enhancing Multimodal Mathematical Reasoning with Scalable Step-Level Supervision",
    "authors": [
      "Lingxiao Du",
      "Fanqing Meng",
      "Zongkai Liu",
      "Zhixiang Zhou",
      "Ping Luo",
      "Qiaosheng Zhang",
      "Wenqi Shao"
    ],
    "abstract": "While Multimodal Large Language Models (MLLMs) have achieved impressive progress in vision-language understanding, they still struggle with complex multi-step reasoning, often producing logically inconsistent or partially correct solutions. A key limitation lies in the lack of fine-grained supervision over intermediate reasoning steps. To address this, we propose MM-PRM, a process reward model trained within a fully automated, scalable framework. We first build MM-Policy, a strong multimodal model trained on diverse mathematical reasoning data. Then, we construct MM-K12, a curated dataset of 10,000 multimodal math problems with verifiable answers, which serves as seed data. Leveraging a Monte Carlo Tree Search (MCTS)-based pipeline, we generate over 700k step-level annotations without human labeling. The resulting PRM is used to score candidate reasoning paths in the Best-of-N inference setup and achieves significant improvements across both in-domain (MM-K12 test set) and out-of-domain (OlympiadBench, MathVista, etc.) benchmarks. Further analysis confirms the effectiveness of soft labels, smaller learning rates, and path diversity in optimizing PRM performance. MM-PRM demonstrates that process supervision is a powerful tool for enhancing the logical robustness of multimodal reasoning systems. We release all our codes and data at https://github.com/ModalMinds/MM-PRM.",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.13427v2",
    "published_date": "2025-05-19 17:55:08 UTC",
    "updated_date": "2025-06-05 05:29:41 UTC"
  },
  {
    "arxiv_id": "2505.13425v1",
    "title": "Learnware of Language Models: Specialized Small Language Models Can Do Big",
    "authors": [
      "Zhi-Hao Tan",
      "Zi-Chen Zhao",
      "Hao-Yu Shi",
      "Xin-Yu Zhang",
      "Peng Tan",
      "Yang Yu",
      "Zhi-Hua Zhou"
    ],
    "abstract": "The learnware paradigm offers a novel approach to machine learning by enabling users to reuse a set of well-trained models for tasks beyond the models' original purposes. It eliminates the need to build models from scratch, instead relying on specifications (representations of a model's capabilities) to identify and leverage the most suitable models for new tasks. While learnware has proven effective in many scenarios, its application to language models has remained largely unexplored. At the same time, large language models (LLMs) have demonstrated remarkable universal question-answering abilities, yet they face challenges in specialized scenarios due to data scarcity, privacy concerns, and high computational costs, thus more and more specialized small language models (SLMs) are being trained for specific domains. To address these limitations systematically, the learnware paradigm provides a promising solution by enabling maximum utilization of specialized SLMs, and allowing users to identify and reuse them in a collaborative and privacy-preserving manner.\n  This paper presents a preliminary attempt to apply the learnware paradigm to language models. We simulated a learnware system comprising approximately 100 learnwares of specialized SLMs with 8B parameters, fine-tuned across finance, healthcare, and mathematics domains. Each learnware contains an SLM and a specification, which enables users to identify the most relevant models without exposing their own data. Experimental results demonstrate promising performance: by selecting one suitable learnware for each task-specific inference, the system outperforms the base SLMs on all benchmarks. Compared to LLMs, the system outperforms Qwen1.5-110B, Qwen2.5-72B, and Llama3.1-70B-Instruct by at least 14% in finance domain tasks, and surpasses Flan-PaLM-540B (ranked 7th on the Open Medical LLM Leaderboard) in medical domain tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.13425v1",
    "published_date": "2025-05-19 17:54:35 UTC",
    "updated_date": "2025-05-19 17:54:35 UTC"
  },
  {
    "arxiv_id": "2505.13417v1",
    "title": "AdaptThink: Reasoning Models Can Learn When to Think",
    "authors": [
      "Jiajie Zhang",
      "Nianyi Lin",
      "Lei Hou",
      "Ling Feng",
      "Juanzi Li"
    ],
    "abstract": "Recently, large reasoning models have achieved impressive performance on various tasks by employing human-like deep thinking. However, the lengthy thinking process substantially increases inference overhead, making efficiency a critical bottleneck. In this work, we first demonstrate that NoThinking, which prompts the reasoning model to skip thinking and directly generate the final solution, is a better choice for relatively simple tasks in terms of both performance and efficiency. Motivated by this, we propose AdaptThink, a novel RL algorithm to teach reasoning models to choose the optimal thinking mode adaptively based on problem difficulty. Specifically, AdaptThink features two core components: (1) a constrained optimization objective that encourages the model to choose NoThinking while maintaining the overall performance; (2) an importance sampling strategy that balances Thinking and NoThinking samples during on-policy training, thereby enabling cold start and allowing the model to explore and exploit both thinking modes throughout the training process. Our experiments indicate that AdaptThink significantly reduces the inference costs while further enhancing performance. Notably, on three math datasets, AdaptThink reduces the average response length of DeepSeek-R1-Distill-Qwen-1.5B by 53% and improves its accuracy by 2.4%, highlighting the promise of adaptive thinking-mode selection for optimizing the balance between reasoning quality and efficiency. Our codes and models are available at https://github.com/THU-KEG/AdaptThink.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.13417v1",
    "published_date": "2025-05-19 17:50:52 UTC",
    "updated_date": "2025-05-19 17:50:52 UTC"
  },
  {
    "arxiv_id": "2505.13408v1",
    "title": "CoT-Kinetics: A Theoretical Modeling Assessing LRM Reasoning Process",
    "authors": [
      "Jinhe Bi",
      "Danqi Yan",
      "Yifan Wang",
      "Wenke Huang",
      "Haokun Chen",
      "Guancheng Wan",
      "Mang Ye",
      "Xun Xiao",
      "Hinrich Schuetze",
      "Volker Tresp",
      "Yunpu Ma"
    ],
    "abstract": "Recent Large Reasoning Models significantly improve the reasoning ability of Large Language Models by learning to reason, exhibiting the promising performance in solving complex tasks. LRMs solve tasks that require complex reasoning by explicitly generating reasoning trajectories together with answers. Nevertheless, judging the quality of such an output answer is not easy because only considering the correctness of the answer is not enough and the soundness of the reasoning trajectory part matters as well. Logically, if the soundness of the reasoning part is poor, even if the answer is correct, the confidence of the derived answer should be low. Existing methods did consider jointly assessing the overall output answer by taking into account the reasoning part, however, their capability is still not satisfactory as the causal relationship of the reasoning to the concluded answer cannot properly reflected. In this paper, inspired by classical mechanics, we present a novel approach towards establishing a CoT-Kinetics energy equation. Specifically, our CoT-Kinetics energy equation formulates the token state transformation process, which is regulated by LRM internal transformer layers, as like a particle kinetics dynamics governed in a mechanical field. Our CoT-Kinetics energy assigns a scalar score to evaluate specifically the soundness of the reasoning phase, telling how confident the derived answer could be given the evaluated reasoning. As such, the LRM's overall output quality can be accurately measured, rather than a coarse judgment (e.g., correct or incorrect) anymore.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.13408v1",
    "published_date": "2025-05-19 17:44:26 UTC",
    "updated_date": "2025-05-19 17:44:26 UTC"
  },
  {
    "arxiv_id": "2505.13406v1",
    "title": "AutoMathKG: The automated mathematical knowledge graph based on LLM and vector database",
    "authors": [
      "Rong Bian",
      "Yu Geng",
      "Zijian Yang",
      "Bing Cheng"
    ],
    "abstract": "A mathematical knowledge graph (KG) presents knowledge within the field of mathematics in a structured manner. Constructing a math KG using natural language is an essential but challenging task. There are two major limitations of existing works: first, they are constrained by corpus completeness, often discarding or manually supplementing incomplete knowledge; second, they typically fail to fully automate the integration of diverse knowledge sources. This paper proposes AutoMathKG, a high-quality, wide-coverage, and multi-dimensional math KG capable of automatic updates. AutoMathKG regards mathematics as a vast directed graph composed of Definition, Theorem, and Problem entities, with their reference relationships as edges. It integrates knowledge from ProofWiki, textbooks, arXiv papers, and TheoremQA, enhancing entities and relationships with large language models (LLMs) via in-context learning for data augmentation. To search for similar entities, MathVD, a vector database, is built through two designed embedding strategies using SBERT. To automatically update, two mechanisms are proposed. For knowledge completion mechanism, Math LLM is developed to interact with AutoMathKG, providing missing proofs or solutions. For knowledge fusion mechanism, MathVD is used to retrieve similar entities, and LLM is used to determine whether to merge with a candidate or add as a new entity. A wide range of experiments demonstrate the advanced performance and broad applicability of the AutoMathKG system, including superior reachability query results in MathVD compared to five baselines and robust mathematical reasoning capability in Math LLM.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.13406v1",
    "published_date": "2025-05-19 17:41:29 UTC",
    "updated_date": "2025-05-19 17:41:29 UTC"
  },
  {
    "arxiv_id": "2505.18191v1",
    "title": "SzCORE as a benchmark: report from the seizure detection challenge at the 2025 AI in Epilepsy and Neurological Disorders Conference",
    "authors": [
      "Jonathan Dan",
      "Amirhossein Shahbazinia",
      "Christodoulos Kechris",
      "David Atienza"
    ],
    "abstract": "Reliable automatic seizure detection from long-term EEG remains a challenge, as current machine learning models often fail to generalize across patients or clinical settings. Manual EEG review remains the clinical standard, underscoring the need for robust models and standardized evaluation. To rigorously assess algorithm performance, we organized a challenge using a private dataset of continuous EEG recordings from 65 subjects (4,360 hours). Expert neurophysiologists annotated the data, providing ground truth for seizure events. Participants were required to detect seizure onset and duration, with evaluation based on event-based metrics, including sensitivity, precision, F1-score, and false positives per day. The SzCORE framework ensured standardized evaluation. The primary ranking criterion was the event-based F1-score, reflecting clinical relevance by balancing sensitivity and false positives. The challenge received 30 submissions from 19 teams, with 28 algorithms evaluated. Results revealed wide variability in performance, with a top F1-score of 43% (sensitivity 37%, precision 45%), highlighting the ongoing difficulty of seizure detection. The challenge also revealed a gap between reported performance and real-world evaluation, emphasizing the importance of rigorous benchmarking. Compared to previous challenges and commercial systems, the best-performing algorithm in this contest showed improved performance. Importantly, the challenge platform now supports continuous benchmarking, enabling reproducible research, integration of new datasets, and clinical evaluation of seizure detection algorithms using a standardized framework.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG",
      "cs.PF"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.18191v1",
    "published_date": "2025-05-19 17:36:20 UTC",
    "updated_date": "2025-05-19 17:36:20 UTC"
  },
  {
    "arxiv_id": "2505.13400v1",
    "title": "Robin: A multi-agent system for automating scientific discovery",
    "authors": [
      "Ali Essam Ghareeb",
      "Benjamin Chang",
      "Ludovico Mitchener",
      "Angela Yiu",
      "Caralyn J. Szostkiewicz",
      "Jon M. Laurent",
      "Muhammed T. Razzak",
      "Andrew D. White",
      "Michaela M. Hinks",
      "Samuel G. Rodriques"
    ],
    "abstract": "Scientific discovery is driven by the iterative process of background research, hypothesis generation, experimentation, and data analysis. Despite recent advancements in applying artificial intelligence to scientific discovery, no system has yet automated all of these stages in a single workflow. Here, we introduce Robin, the first multi-agent system capable of fully automating the key intellectual steps of the scientific process. By integrating literature search agents with data analysis agents, Robin can generate hypotheses, propose experiments, interpret experimental results, and generate updated hypotheses, achieving a semi-autonomous approach to scientific discovery. By applying this system, we were able to identify a novel treatment for dry age-related macular degeneration (dAMD), the major cause of blindness in the developed world. Robin proposed enhancing retinal pigment epithelium phagocytosis as a therapeutic strategy, and identified and validated a promising therapeutic candidate, ripasudil. Ripasudil is a clinically-used rho kinase (ROCK) inhibitor that has never previously been proposed for treating dAMD. To elucidate the mechanism of ripasudil-induced upregulation of phagocytosis, Robin then proposed and analyzed a follow-up RNA-seq experiment, which revealed upregulation of ABCA1, a critical lipid efflux pump and possible novel target. All hypotheses, experimental plans, data analyses, and data figures in the main text of this report were produced by Robin. As the first AI system to autonomously discover and validate a novel therapeutic candidate within an iterative lab-in-the-loop framework, Robin establishes a new paradigm for AI-driven scientific discovery.",
    "categories": [
      "cs.AI",
      "cs.MA",
      "q-bio.QM"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.13400v1",
    "published_date": "2025-05-19 17:36:17 UTC",
    "updated_date": "2025-05-19 17:36:17 UTC"
  },
  {
    "arxiv_id": "2505.13393v2",
    "title": "IG Parser: A Software Package for the Encoding of Institutional Statements using the Institutional Grammar",
    "authors": [
      "Christopher K. Frantz"
    ],
    "abstract": "This article provides an overview of IG Parser, a software that facilitates qualitative content analysis of formal (e.g., legal) rules or informal (e.g., social) norms, and strategies (such as conventions) -- referred to as institutions -- that govern social systems and operate configurally to describe institutional systems. To this end, the IG Parser employs a distinctive syntax that ensures rigorous encoding of natural language, while automating the transformation into various formats that support the downstream analysis using diverse analytical techniques. The conceptual core of the IG Parser is an associated syntax, IG Script, that operationalizes the conceptual foundations of the Institutional Grammar, and more specifically the Institutional Grammar 2.0, an analytical paradigm for institutional analysis. This article presents the IG Parser, including its conceptual foundations, the syntax specification of IG Script, and its architectural principles. This overview is augmented with selective illustrative examples that highlight its use and the associated benefits.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.MA",
    "comment": "24 pages",
    "pdf_url": "https://arxiv.org/pdf/2505.13393v2",
    "published_date": "2025-05-19 17:33:15 UTC",
    "updated_date": "2025-05-20 09:52:05 UTC"
  },
  {
    "arxiv_id": "2505.13391v1",
    "title": "Advancing Generalization Across a Variety of Abstract Visual Reasoning Tasks",
    "authors": [
      "Mikołaj Małkiński",
      "Jacek Mańdziuk"
    ],
    "abstract": "The abstract visual reasoning (AVR) domain presents a diverse suite of analogy-based tasks devoted to studying model generalization. Recent years have brought dynamic progress in the field, particularly in i.i.d. scenarios, in which models are trained and evaluated on the same data distributions. Nevertheless, o.o.d. setups that assess model generalization to new test distributions remain challenging even for the most recent models. To advance generalization in AVR tasks, we present the Pathways of Normalized Group Convolution model (PoNG), a novel neural architecture that features group convolution, normalization, and a parallel design. We consider a wide set of AVR benchmarks, including Raven's Progressive Matrices and visual analogy problems with both synthetic and real-world images. The experiments demonstrate strong generalization capabilities of the proposed model, which in several settings outperforms the existing literature methods.",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted to the 34th International Joint Conference on Artificial Intelligence (IJCAI 2025)",
    "pdf_url": "https://arxiv.org/pdf/2505.13391v1",
    "published_date": "2025-05-19 17:32:07 UTC",
    "updated_date": "2025-05-19 17:32:07 UTC"
  },
  {
    "arxiv_id": "2505.13388v3",
    "title": "R3: Robust Rubric-Agnostic Reward Models",
    "authors": [
      "David Anugraha",
      "Zilu Tang",
      "Lester James V. Miranda",
      "Hanyang Zhao",
      "Mohammad Rifqi Farhansyah",
      "Garry Kuwanto",
      "Derry Wijaya",
      "Genta Indra Winata"
    ],
    "abstract": "Reward models are essential for aligning language model outputs with human preferences, yet existing approaches often lack both controllability and interpretability. These models are typically optimized for narrow objectives, limiting their generalizability to broader downstream tasks. Moreover, their scalar outputs are difficult to interpret without contextual reasoning. To address these limitations, we introduce $\\shortmethodname$, a novel reward modeling framework that is rubric-agnostic, generalizable across evaluation dimensions, and provides interpretable, reasoned score assignments. $\\shortmethodname$ enables more transparent and flexible evaluation of language models, supporting robust alignment with diverse human values and use cases. Our models, data, and code are available as open source at https://github.com/rubricreward/r3.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Preprint",
    "pdf_url": "https://arxiv.org/pdf/2505.13388v3",
    "published_date": "2025-05-19 17:29:03 UTC",
    "updated_date": "2025-09-19 22:07:47 UTC"
  },
  {
    "arxiv_id": "2505.13381v1",
    "title": "How Adding Metacognitive Requirements in Support of AI Feedback in Practice Exams Transforms Student Learning Behaviors",
    "authors": [
      "Mak Ahmad",
      "Prerna Ravi",
      "David Karger",
      "Marc Facciotti"
    ],
    "abstract": "Providing personalized, detailed feedback at scale in large undergraduate STEM courses remains a persistent challenge. We present an empirically evaluated practice exam system that integrates AI generated feedback with targeted textbook references, deployed in a large introductory biology course. Our system encourages metacognitive behavior by asking students to explain their answers and declare their confidence. It uses OpenAI's GPT-4o to generate personalized feedback based on this information, while directing them to relevant textbook sections. Through interaction logs from consenting participants across three midterms (541, 342, and 413 students respectively), totaling 28,313 question-student interactions across 146 learning objectives, along with 279 surveys and 23 interviews, we examined the system's impact on learning outcomes and engagement. Across all midterms, feedback types showed no statistically significant performance differences, though some trends suggested potential benefits. The most substantial impact came from the required confidence ratings and explanations, which students reported transferring to their actual exam strategies. About 40 percent of students engaged with textbook references when prompted by feedback -- far higher than traditional reading rates. Survey data revealed high satisfaction (mean rating 4.1 of 5), with 82.1 percent reporting increased confidence on practiced midterm topics, and 73.4 percent indicating they could recall and apply specific concepts. Our findings suggest that embedding structured reflection requirements may be more impactful than sophisticated feedback mechanisms.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "10 pages, 3 figures, to appear in Proceedings of the Twelfth ACM Conference on Learning @ Scale (L@S 2025), July 2025, Palermo, Italy",
    "pdf_url": "https://arxiv.org/pdf/2505.13381v1",
    "published_date": "2025-05-19 17:25:07 UTC",
    "updated_date": "2025-05-19 17:25:07 UTC"
  },
  {
    "arxiv_id": "2505.13380v1",
    "title": "CompeteSMoE -- Statistically Guaranteed Mixture of Experts Training via Competition",
    "authors": [
      "Nam V. Nguyen",
      "Huy Nguyen",
      "Quang Pham",
      "Van Nguyen",
      "Savitha Ramasamy",
      "Nhat Ho"
    ],
    "abstract": "Sparse mixture of experts (SMoE) offers an appealing solution to scale up the model complexity beyond the mean of increasing the network's depth or width. However, we argue that effective SMoE training remains challenging because of the suboptimal routing process where experts that perform computation do not directly contribute to the routing process. In this work, we propose competition, a novel mechanism to route tokens to experts with the highest neural response. Theoretically, we show that the competition mechanism enjoys a better sample efficiency than the traditional softmax routing. Furthermore, we develop CompeteSMoE, a simple yet effective algorithm to train large language models by deploying a router to learn the competition policy, thus enjoying strong performances at a low training overhead. Our extensive empirical evaluations on both the visual instruction tuning and language pre-training tasks demonstrate the efficacy, robustness, and scalability of CompeteSMoE compared to state-of-the-art SMoE strategies. We have made the implementation available at: https://github.com/Fsoft-AIC/CompeteSMoE. This work is an improved version of the previous study at arXiv:2402.02526",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "52 pages. This work is an improved version of the previous study at arXiv:2402.02526",
    "pdf_url": "https://arxiv.org/pdf/2505.13380v1",
    "published_date": "2025-05-19 17:24:26 UTC",
    "updated_date": "2025-05-19 17:24:26 UTC"
  },
  {
    "arxiv_id": "2505.13379v2",
    "title": "Thinkless: LLM Learns When to Think",
    "authors": [
      "Gongfan Fang",
      "Xinyin Ma",
      "Xinchao Wang"
    ],
    "abstract": "Reasoning Language Models, capable of extended chain-of-thought reasoning, have demonstrated remarkable performance on tasks requiring complex logical inference. However, applying elaborate reasoning for all queries often results in substantial computational inefficiencies, particularly when many problems admit straightforward solutions. This motivates an open question: Can LLMs learn when to think? To answer this, we propose Thinkless, a learnable framework that empowers an LLM to adaptively select between short-form and long-form reasoning, based on both task complexity and the model's ability. Thinkless is trained under a reinforcement learning paradigm and employs two control tokens, <short> for concise responses and <think> for detailed reasoning. At the core of our method is a Decoupled Group Relative Policy Optimization (DeGRPO) algorithm, which decomposes the learning objective of hybrid reasoning into two components: (1) a control token loss that governs the selection of the reasoning mode, and (2) a response loss that improves the accuracy of the generated answers. This decoupled formulation enables fine-grained control over the contributions of each objective, stabilizing training and effectively preventing collapse observed in vanilla GRPO. Empirically, on several benchmarks such as Minerva Algebra, MATH-500, and GSM8K, Thinkless is able to reduce the usage of long-chain thinking by 50% - 90%, significantly improving the efficiency of Reasoning Language Models. The code is available at https://github.com/VainF/Thinkless",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.13379v2",
    "published_date": "2025-05-19 17:24:16 UTC",
    "updated_date": "2025-06-26 14:06:49 UTC"
  },
  {
    "arxiv_id": "2505.13372v1",
    "title": "Exploiting Symbolic Heuristics for the Synthesis of Domain-Specific Temporal Planning Guidance using Reinforcement Learning",
    "authors": [
      "Irene Brugnara",
      "Alessandro Valentini",
      "Andrea Micheli"
    ],
    "abstract": "Recent work investigated the use of Reinforcement Learning (RL) for the synthesis of heuristic guidance to improve the performance of temporal planners when a domain is fixed and a set of training problems (not plans) is given. The idea is to extract a heuristic from the value function of a particular (possibly infinite-state) MDP constructed over the training problems.\n  In this paper, we propose an evolution of this learning and planning framework that focuses on exploiting the information provided by symbolic heuristics during both the RL and planning phases. First, we formalize different reward schemata for the synthesis and use symbolic heuristics to mitigate the problems caused by the truncation of episodes needed to deal with the potentially infinite MDP. Second, we propose learning a residual of an existing symbolic heuristic, which is a \"correction\" of the heuristic value, instead of eagerly learning the whole heuristic from scratch. Finally, we use the learned heuristic in combination with a symbolic heuristic using a multiple-queue planning approach to balance systematic search with imperfect learned information. We experimentally compare all the approaches, highlighting their strengths and weaknesses and significantly advancing the state of the art for this planning and learning schema.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.13372v1",
    "published_date": "2025-05-19 17:19:13 UTC",
    "updated_date": "2025-05-19 17:19:13 UTC"
  },
  {
    "arxiv_id": "2505.13358v3",
    "title": "One-Step Offline Distillation of Diffusion-based Models via Koopman Modeling",
    "authors": [
      "Nimrod Berman",
      "Ilan Naiman",
      "Moshe Eliasof",
      "Hedi Zisling",
      "Omri Azencot"
    ],
    "abstract": "Diffusion-based generative models have demonstrated exceptional performance, yet their iterative sampling procedures remain computationally expensive. A prominent strategy to mitigate this cost is distillation, with offline distillation offering particular advantages in terms of efficiency, modularity, and flexibility. In this work, we identify two key observations that motivate a principled distillation framework: (1) while diffusion models have been viewed through the lens of dynamical systems theory, powerful and underexplored tools can be further leveraged; and (2) diffusion models inherently impose structured, semantically coherent trajectories in latent space. Building on these observations, we introduce the Koopman Distillation Model (KDM), a novel offline distillation approach grounded in Koopman theory - a classical framework for representing nonlinear dynamics linearly in a transformed space. KDM encodes noisy inputs into an embedded space where a learned linear operator propagates them forward, followed by a decoder that reconstructs clean samples. This enables single-step generation while preserving semantic fidelity. We provide theoretical justification for our approach: (1) under mild assumptions, the learned diffusion dynamics admit a finite-dimensional Koopman representation; and (2) proximity in the Koopman latent space correlates with semantic similarity in the generated outputs, allowing for effective trajectory alignment. KDM achieves highly competitive performance across standard offline distillation benchmarks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.13358v3",
    "published_date": "2025-05-19 16:59:47 UTC",
    "updated_date": "2025-10-23 17:59:57 UTC"
  },
  {
    "arxiv_id": "2505.13355v2",
    "title": "Survey: Multi-Armed Bandits Meet Large Language Models",
    "authors": [
      "Djallel Bouneffouf",
      "Raphael Feraud"
    ],
    "abstract": "Bandit algorithms and Large Language Models (LLMs) have emerged as powerful tools in artificial intelligence, each addressing distinct yet complementary challenges in decision-making and natural language processing. This survey explores the synergistic potential between these two fields, highlighting how bandit algorithms can enhance the performance of LLMs and how LLMs, in turn, can provide novel insights for improving bandit-based decision-making. We first examine the role of bandit algorithms in optimizing LLM fine-tuning, prompt engineering, and adaptive response generation, focusing on their ability to balance exploration and exploitation in large-scale learning tasks. Subsequently, we explore how LLMs can augment bandit algorithms through advanced contextual understanding, dynamic adaptation, and improved policy selection using natural language reasoning. By providing a comprehensive review of existing research and identifying key challenges and opportunities, this survey aims to bridge the gap between bandit algorithms and LLMs, paving the way for innovative applications and interdisciplinary research in AI.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.13355v2",
    "published_date": "2025-05-19 16:57:57 UTC",
    "updated_date": "2025-09-30 03:33:36 UTC"
  },
  {
    "arxiv_id": "2505.13346v3",
    "title": "J4R: Learning to Judge with Equivalent Initial State Group Relative Policy Optimization",
    "authors": [
      "Austin Xu",
      "Yilun Zhou",
      "Xuan-Phi Nguyen",
      "Caiming Xiong",
      "Shafiq Joty"
    ],
    "abstract": "To keep pace with the increasing pace of large language models (LLM) development, model output evaluation has transitioned away from time-consuming human evaluation to automatic evaluation, where LLMs themselves are tasked with assessing and critiquing other model outputs. LLM-as-judge models are a class of generative evaluators that excel in evaluating relatively simple domains, like chat quality, but struggle in reasoning intensive domains where model responses contain more substantive and challenging content. To remedy existing judge shortcomings, we explore training judges with reinforcement learning (RL). We make three key contributions: (1) We propose the Equivalent Initial State Group Relative Policy Optimization (EIS-GRPO) algorithm, which allows us to train our judge to be robust to positional biases that arise in more complex evaluation settings. (2) We introduce ReasoningJudgeBench, a benchmark that evaluates judges in diverse reasoning settings not covered by prior work. (3) We train Judge for Reasoning (J4R), a 7B judge trained with EIS-GRPO that outperforms GPT-4o and the next best small judge by 6.7% and 9%, matching or exceeding the performance of larger GRPO-trained judges on both JudgeBench and ReasoningJudgeBench.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "25 pages, 4 figures, 6 tables. Updated with code and benchmark",
    "pdf_url": "https://arxiv.org/pdf/2505.13346v3",
    "published_date": "2025-05-19 16:50:35 UTC",
    "updated_date": "2025-06-18 16:58:25 UTC"
  },
  {
    "arxiv_id": "2505.13344v2",
    "title": "RoPECraft: Training-Free Motion Transfer with Trajectory-Guided RoPE Optimization on Diffusion Transformers",
    "authors": [
      "Ahmet Berke Gokmen",
      "Yigit Ekin",
      "Bahri Batuhan Bilecen",
      "Aysegul Dundar"
    ],
    "abstract": "We propose RoPECraft, a training-free video motion transfer method for diffusion transformers that operates solely by modifying their rotary positional embeddings (RoPE). We first extract dense optical flow from a reference video, and utilize the resulting motion offsets to warp the complex-exponential tensors of RoPE, effectively encoding motion into the generation process. These embeddings are then further optimized during denoising time steps via trajectory alignment between the predicted and target velocities using a flow-matching objective. To keep the output faithful to the text prompt and prevent duplicate generations, we incorporate a regularization term based on the phase components of the reference video's Fourier transform, projecting the phase angles onto a smooth manifold to suppress high-frequency artifacts. Experiments on benchmarks reveal that RoPECraft outperforms all recently published methods, both qualitatively and quantitatively.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "https://berkegokmen1.github.io/RoPECraft/",
    "pdf_url": "https://arxiv.org/pdf/2505.13344v2",
    "published_date": "2025-05-19 16:50:26 UTC",
    "updated_date": "2025-11-24 21:39:54 UTC"
  },
  {
    "arxiv_id": "2505.13339v1",
    "title": "OPA-Pack: Object-Property-Aware Robotic Bin Packing",
    "authors": [
      "Jia-Hui Pan",
      "Yeok Tatt Cheah",
      "Zhengzhe Liu",
      "Ka-Hei Hui",
      "Xiaojie Gao",
      "Pheng-Ann Heng",
      "Yun-Hui Liu",
      "Chi-Wing Fu"
    ],
    "abstract": "Robotic bin packing aids in a wide range of real-world scenarios such as e-commerce and warehouses. Yet, existing works focus mainly on considering the shape of objects to optimize packing compactness and neglect object properties such as fragility, edibility, and chemistry that humans typically consider when packing objects. This paper presents OPA-Pack (Object-Property-Aware Packing framework), the first framework that equips the robot with object property considerations in planning the object packing. Technical-wise, we develop a novel object property recognition scheme with retrieval-augmented generation and chain-of-thought reasoning, and build a dataset with object property annotations for 1,032 everyday objects. Also, we formulate OPA-Net, aiming to jointly separate incompatible object pairs and reduce pressure on fragile objects, while compacting the packing. Further, OPA-Net consists of a property embedding layer to encode the property of candidate objects to be packed, together with a fragility heightmap and an avoidance heightmap to keep track of the packed objects. Then, we design a reward function and adopt a deep Q-learning scheme to train OPA-Net. Experimental results manifest that OPA-Pack greatly improves the accuracy of separating incompatible object pairs (from 52% to 95%) and largely reduces pressure on fragile objects (by 29.4%), while maintaining good packing compactness. Besides, we demonstrate the effectiveness of OPA-Pack on a real packing platform, showcasing its practicality in real-world scenarios.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Submitted to IEEE Transactions on Robotics (TRO) on Feb. 10, 2025",
    "pdf_url": "https://arxiv.org/pdf/2505.13339v1",
    "published_date": "2025-05-19 16:48:14 UTC",
    "updated_date": "2025-05-19 16:48:14 UTC"
  },
  {
    "arxiv_id": "2505.13338v2",
    "title": "Contextual Paralinguistic Data Creation for Multi-Modal Speech-LLM: Data Condensation and Spoken QA Generation",
    "authors": [
      "Qiongqiong Wang",
      "Hardik B. Sailor",
      "Tianchi Liu",
      "Ai Ti Aw"
    ],
    "abstract": "Current speech-LLMs exhibit limited capability in contextual reasoning alongside paralinguistic understanding, primarily due to the lack of Question-Answer (QA) datasets that cover both aspects. We propose a novel framework for dataset generation from in-the-wild speech data, that integrates contextual reasoning with paralinguistic information. It consists of a pseudo paralinguistic label-based data condensation of in-the-wild speech and LLM-based Contextual Paralinguistic QA (CPQA) generation. The effectiveness is validated by a strong correlation in evaluations of the Qwen2-Audio-7B-Instruct model on a dataset created by our framework and human-generated CPQA dataset. The results also reveal the speech-LLM's limitations in handling empathetic reasoning tasks, highlighting the need for such datasets and more robust models. The proposed framework is first of its kind and has potential in training more robust speech-LLMs with paralinguistic reasoning capabilities.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at Interspeech 2025. [v2]: The dataset has been released, and the link is now updated",
    "pdf_url": "https://arxiv.org/pdf/2505.13338v2",
    "published_date": "2025-05-19 16:47:46 UTC",
    "updated_date": "2025-06-03 04:11:48 UTC"
  },
  {
    "arxiv_id": "2505.13329v1",
    "title": "Recommender Systems for Democracy: Toward Adversarial Robustness in Voting Advice Applications",
    "authors": [
      "Frédéric Berdoz",
      "Dustin Brunner",
      "Yann Vonlanthen",
      "Roger Wattenhofer"
    ],
    "abstract": "Voting advice applications (VAAs) help millions of voters understand which political parties or candidates best align with their views. This paper explores the potential risks these applications pose to the democratic process when targeted by adversarial entities. In particular, we expose 11 manipulation strategies and measure their impact using data from Switzerland's primary VAA, Smartvote, collected during the last two national elections. We find that altering application parameters, such as the matching method, can shift a party's recommendation frequency by up to 105%. Cherry-picking questionnaire items can increase party recommendation frequency by over 261%, while subtle changes to parties' or candidates' responses can lead to a 248% increase. To address these vulnerabilities, we propose adversarial robustness properties VAAs should satisfy, introduce empirical metrics for assessing the resilience of various matching methods, and suggest possible avenues for research toward mitigating the effect of manipulation. Our framework is key to ensuring secure and reliable AI-based VAAs poised to emerge in the near future.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.CY",
    "comment": "This is the extended version of the paper, accepted at IJCAI 2025",
    "pdf_url": "https://arxiv.org/pdf/2505.13329v1",
    "published_date": "2025-05-19 16:38:06 UTC",
    "updated_date": "2025-05-19 16:38:06 UTC"
  },
  {
    "arxiv_id": "2505.13324v1",
    "title": "From What Ifs to Insights: Counterfactuals in Causal Inference vs. Explainable AI",
    "authors": [
      "Galit Shmueli",
      "David Martens",
      "Jaewon Yoo",
      "Travis Greene"
    ],
    "abstract": "Counterfactuals play a pivotal role in the two distinct data science fields of causal inference (CI) and explainable artificial intelligence (XAI). While the core idea behind counterfactuals remains the same in both fields--the examination of what would have happened under different circumstances--there are key differences in how they are used and interpreted. We introduce a formal definition that encompasses the multi-faceted concept of the counterfactual in CI and XAI. We then discuss how counterfactuals are used, evaluated, generated, and operationalized in CI vs. XAI, highlighting conceptual and practical differences. By comparing and contrasting the two, we hope to identify opportunities for cross-fertilization across CI and XAI.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG",
      "econ.EM",
      "stat.ME"
    ],
    "primary_category": "stat.ML",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.13324v1",
    "published_date": "2025-05-19 16:34:36 UTC",
    "updated_date": "2025-05-19 16:34:36 UTC"
  },
  {
    "arxiv_id": "2505.13316v1",
    "title": "Denoising Diffusion Probabilistic Model for Point Cloud Compression at Low Bit-Rates",
    "authors": [
      "Gabriele Spadaro",
      "Alberto Presta",
      "Jhony H. Giraldo",
      "Marco Grangetto",
      "Wei Hu",
      "Giuseppe Valenzise",
      "Attilio Fiandrotti",
      "Enzo Tartaglione"
    ],
    "abstract": "Efficient compression of low-bit-rate point clouds is critical for bandwidth-constrained applications. However, existing techniques mainly focus on high-fidelity reconstruction, requiring many bits for compression. This paper proposes a \"Denoising Diffusion Probabilistic Model\" (DDPM) architecture for point cloud compression (DDPM-PCC) at low bit-rates. A PointNet encoder produces the condition vector for the generation, which is then quantized via a learnable vector quantizer. This configuration allows to achieve a low bitrates while preserving quality. Experiments on ShapeNet and ModelNet40 show improved rate-distortion at low rates compared to standardized and state-of-the-art approaches. We publicly released the code at https://github.com/EIDOSLAB/DDPM-PCC.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "6 pages, 5 figures, accepted at ICME 2025",
    "pdf_url": "https://arxiv.org/pdf/2505.13316v1",
    "published_date": "2025-05-19 16:29:12 UTC",
    "updated_date": "2025-05-19 16:29:12 UTC"
  },
  {
    "arxiv_id": "2505.13315v2",
    "title": "KHRONOS: a Kernel-Based Neural Architecture for Rapid, Resource-Efficient Scientific Computation",
    "authors": [
      "Reza T. Batley",
      "Sourav Saha"
    ],
    "abstract": "Contemporary models of high dimensional physical systems are constrained by the curse of dimensionality and a reliance on dense data. We introduce KHRONOS (Kernel Expansion Hierarchy for Reduced Order, Neural Optimized Surrogates), an AI framework for model based, model free and model inversion tasks. KHRONOS constructs continuously differentiable target fields with a hierarchical composition of per-dimension kernel expansions, which are tensorized into modes and then superposed. We evaluate KHRONOS on a canonical 2D, Poisson equation benchmark: across 16 to 512 degrees of freedom (DoFs), it obtained L_2-square errors of 5e-4 down to 6e-11. This represents a greater than 100-fold gain over Kolmogorov Arnold Networks (which itself reports a 100 times improvement on MLPs/PINNs with 100 times fewer parameters) when controlling for the number of parameters. This also represents a 1e6-fold improvement in L_2-square error compared to standard linear FEM at comparable DoFs. Inference complexity is dominated by inner products, yielding sub-millisecond full-field predictions that scale to an arbitrary resolution. For inverse problems, KHRONOS facilitates rapid, iterative level set recovery in only a few forward evaluations, with sub-microsecond per sample latency. KHRONOS's scalability, expressivity, and interpretability open new avenues in constrained edge computing, online control, computer vision, and beyond.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MS"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.13315v2",
    "published_date": "2025-05-19 16:29:07 UTC",
    "updated_date": "2025-05-26 01:40:00 UTC"
  },
  {
    "arxiv_id": "2505.13308v3",
    "title": "Seek in the Dark: Reasoning via Test-Time Instance-Level Policy Gradient in Latent Space",
    "authors": [
      "Hengli Li",
      "Chenxi Li",
      "Tong Wu",
      "Xuekai Zhu",
      "Yuxuan Wang",
      "Zhaoxin Yu",
      "Eric Hanchen Jiang",
      "Song-Chun Zhu",
      "Zixia Jia",
      "Ying Nian Wu",
      "Zilong Zheng"
    ],
    "abstract": "Reasoning ability, a core component of human intelligence, continues to pose a significant challenge for Large Language Models (LLMs) in the pursuit of AGI. Although model performance has improved under the training scaling law, significant challenges remain, particularly with respect to training algorithms, such as catastrophic forgetting, and the limited availability of novel training data. As an alternative, test-time scaling enhances reasoning performance by increasing test-time computation without parameter updating. Unlike prior methods in this paradigm focused on token space, we propose leveraging latent space for more effective reasoning and better adherence to the test-time scaling law. We introduce LatentSeek, a novel framework that enhances LLM reasoning through Test-Time Instance-level Adaptation (TTIA) within the model's latent space. Specifically, LatentSeek leverages policy gradient to iteratively update latent representations, guided by self-generated reward signals. LatentSeek is evaluated on a range of reasoning benchmarks, including GSM8K, MATH-500, and AIME2024, across multiple LLM architectures. Results show that LatentSeek consistently outperforms strong baselines, such as Chain-of-Thought prompting and fine-tuning-based methods. Furthermore, our analysis demonstrates that LatentSeek is highly efficient, typically converging within a few iterations for problems of average complexity, while also benefiting from additional iterations, thereby highlighting the potential of test-time scaling in the latent space. These findings position LatentSeek as a lightweight, scalable, and effective solution for enhancing the reasoning capabilities of LLMs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.13308v3",
    "published_date": "2025-05-19 16:26:02 UTC",
    "updated_date": "2026-01-19 14:21:52 UTC"
  },
  {
    "arxiv_id": "2505.13307v1",
    "title": "RBF++: Quantifying and Optimizing Reasoning Boundaries across Measurable and Unmeasurable Capabilities for Chain-of-Thought Reasoning",
    "authors": [
      "Qiguang Chen",
      "Libo Qin",
      "Jinhao Liu",
      "Yue Liao",
      "Jiaqi Wang",
      "Jingxuan Zhou",
      "Wanxiang Che"
    ],
    "abstract": "Chain-of-Thought (CoT) reasoning has proven effective in enhancing large language models (LLMs) on complex tasks, spurring research into its underlying mechanisms. However, two primary challenges remain for real-world applications: (1) the lack of quantitative metrics and actionable guidelines for evaluating and optimizing measurable boundaries of CoT capability, and (2) the absence of methods to assess boundaries of unmeasurable CoT capability, such as multimodal perception. To address these gaps, we introduce the Reasoning Boundary Framework++ (RBF++). To tackle the first challenge, we define the reasoning boundary (RB) as the maximum limit of CoT performance. We also propose a combination law for RBs, enabling quantitative analysis and offering actionable guidance across various CoT tasks. For the second challenge, particularly in multimodal scenarios, we introduce a constant assumption, which replaces unmeasurable RBs with scenario-specific constants. Additionally, we propose the reasoning boundary division mechanism, which divides unmeasurable RBs into two sub-boundaries, facilitating the quantification and optimization of both unmeasurable domain knowledge and multimodal perception capabilities. Extensive experiments involving 38 models across 13 tasks validate the feasibility of our framework in cross-modal settings. Additionally, we evaluate 10 CoT strategies, offer insights into optimization and decay from two complementary perspectives, and expand evaluation benchmarks for measuring RBs in LLM reasoning. We hope this work advances the understanding of RBs and optimization strategies in LLMs. Code and data are available at https://github.com/LightChen233/reasoning-boundary.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CL",
    "comment": "Manuscript",
    "pdf_url": "https://arxiv.org/pdf/2505.13307v1",
    "published_date": "2025-05-19 16:25:55 UTC",
    "updated_date": "2025-05-19 16:25:55 UTC"
  },
  {
    "arxiv_id": "2505.13292v1",
    "title": "Cross-Cloud Data Privacy Protection: Optimizing Collaborative Mechanisms of AI Systems by Integrating Federated Learning and LLMs",
    "authors": [
      "Huaiying Luo",
      "Cheng Ji"
    ],
    "abstract": "In the age of cloud computing, data privacy protection has become a major challenge, especially when sharing sensitive data across cloud environments. However, how to optimize collaboration across cloud environments remains an unresolved problem. In this paper, we combine federated learning with large-scale language models to optimize the collaborative mechanism of AI systems. Based on the existing federated learning framework, we introduce a cross-cloud architecture in which federated learning works by aggregating model updates from decentralized nodes without exposing the original data. At the same time, combined with large-scale language models, its powerful context and semantic understanding capabilities are used to improve model training efficiency and decision-making ability. We've further innovated by introducing a secure communication layer to ensure the privacy and integrity of model updates and training data. The model enables continuous model adaptation and fine-tuning across different cloud environments while protecting sensitive data. Experimental results show that the proposed method is significantly better than the traditional federated learning model in terms of accuracy, convergence speed and data privacy protection.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "Accepted by 2025 IEEE 7th International Conference on Communications, Information System and Computer Engineering",
    "pdf_url": "https://arxiv.org/pdf/2505.13292v1",
    "published_date": "2025-05-19 16:14:27 UTC",
    "updated_date": "2025-05-19 16:14:27 UTC"
  },
  {
    "arxiv_id": "2505.13291v1",
    "title": "TimeSeriesGym: A Scalable Benchmark for (Time Series) Machine Learning Engineering Agents",
    "authors": [
      "Yifu Cai",
      "Xinyu Li",
      "Mononito Goswami",
      "Michał Wiliński",
      "Gus Welter",
      "Artur Dubrawski"
    ],
    "abstract": "We introduce TimeSeriesGym, a scalable benchmarking framework for evaluating Artificial Intelligence (AI) agents on time series machine learning engineering challenges. Existing benchmarks lack scalability, focus narrowly on model building in well-defined settings, and evaluate only a limited set of research artifacts (e.g., CSV submission files). To make AI agent benchmarking more relevant to the practice of machine learning engineering, our framework scales along two critical dimensions. First, recognizing that effective ML engineering requires a range of diverse skills, TimeSeriesGym incorporates challenges from diverse sources spanning multiple domains and tasks. We design challenges to evaluate both isolated capabilities (including data handling, understanding research repositories, and code translation) and their combinations, and rather than addressing each challenge independently, we develop tools that support designing multiple challenges at scale. Second, we implement evaluation mechanisms for multiple research artifacts, including submission files, code, and models, using both precise numeric measures and more flexible LLM-based evaluation approaches. This dual strategy balances objective assessment with contextual judgment. Although our initial focus is on time series applications, our framework can be readily extended to other data modalities, broadly enhancing the comprehensiveness and practical utility of agentic AI evaluation. We open-source our benchmarking framework to facilitate future research on the ML engineering capabilities of AI agents.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Open source code available at https://github.com/moment-timeseries-foundation-model/TimeSeriesGym. YC, XL, MG and MW contributed equally, and should be considered joint first authors",
    "pdf_url": "https://arxiv.org/pdf/2505.13291v1",
    "published_date": "2025-05-19 16:11:23 UTC",
    "updated_date": "2025-05-19 16:11:23 UTC"
  },
  {
    "arxiv_id": "2505.14723v1",
    "title": "QUADS: QUAntized Distillation Framework for Efficient Speech Language Understanding",
    "authors": [
      "Subrata Biswas",
      "Mohammad Nur Hossain Khan",
      "Bashima Islam"
    ],
    "abstract": "Spoken Language Understanding (SLU) systems must balance performance and efficiency, particularly in resource-constrained environments. Existing methods apply distillation and quantization separately, leading to suboptimal compression as distillation ignores quantization constraints. We propose QUADS, a unified framework that optimizes both through multi-stage training with a pre-tuned model, enhancing adaptability to low-bit regimes while maintaining accuracy. QUADS achieves 71.13\\% accuracy on SLURP and 99.20\\% on FSC, with only minor degradations of up to 5.56\\% compared to state-of-the-art models. Additionally, it reduces computational complexity by 60--73$\\times$ (GMACs) and model size by 83--700$\\times$, demonstrating strong robustness under extreme quantization. These results establish QUADS as a highly efficient solution for real-world, resource-constrained SLU applications.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.SD"
    ],
    "primary_category": "eess.AS",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.14723v1",
    "published_date": "2025-05-19 16:09:51 UTC",
    "updated_date": "2025-05-19 16:09:51 UTC"
  },
  {
    "arxiv_id": "2505.13287v1",
    "title": "Level Generation with Quantum Reservoir Computing",
    "authors": [
      "João S. Ferreira",
      "Pierre Fromholz",
      "Hari Shaji",
      "James R. Wootton"
    ],
    "abstract": "Reservoir computing is a form of machine learning particularly suited for time series analysis, including forecasting predictions. We take an implementation of \\emph{quantum} reservoir computing that was initially designed to generate variants of musical scores and adapt it to create levels of Super Mario Bros. Motivated by our analysis of these levels, we develop a new Roblox \\textit{obby} where the courses can be generated in real time on superconducting qubit hardware, and investigate some of the constraints placed by such real-time generation.",
    "categories": [
      "cs.AI",
      "quant-ph"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.13287v1",
    "published_date": "2025-05-19 16:09:30 UTC",
    "updated_date": "2025-05-19 16:09:30 UTC"
  },
  {
    "arxiv_id": "2505.13280v1",
    "title": "FlowPure: Continuous Normalizing Flows for Adversarial Purification",
    "authors": [
      "Elias Collaert",
      "Abel Rodríguez",
      "Sander Joos",
      "Lieven Desmet",
      "Vera Rimmer"
    ],
    "abstract": "Despite significant advancements in the area, adversarial robustness remains a critical challenge in systems employing machine learning models. The removal of adversarial perturbations at inference time, known as adversarial purification, has emerged as a promising defense strategy. To achieve this, state-of-the-art methods leverage diffusion models that inject Gaussian noise during a forward process to dilute adversarial perturbations, followed by a denoising step to restore clean samples before classification. In this work, we propose FlowPure, a novel purification method based on Continuous Normalizing Flows (CNFs) trained with Conditional Flow Matching (CFM) to learn mappings from adversarial examples to their clean counterparts. Unlike prior diffusion-based approaches that rely on fixed noise processes, FlowPure can leverage specific attack knowledge to improve robustness under known threats, while also supporting a more general stochastic variant trained on Gaussian perturbations for settings where such knowledge is unavailable. Experiments on CIFAR-10 and CIFAR-100 demonstrate that our method outperforms state-of-the-art purification-based defenses in preprocessor-blind and white-box scenarios, and can do so while fully preserving benign accuracy in the former. Moreover, our results show that not only is FlowPure a highly effective purifier but it also holds a strong potential for adversarial detection, identifying preprocessor-blind PGD samples with near-perfect accuracy.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.13280v1",
    "published_date": "2025-05-19 16:04:43 UTC",
    "updated_date": "2025-05-19 16:04:43 UTC"
  },
  {
    "arxiv_id": "2505.13273v1",
    "title": "Seeing the Unseen: How EMoE Unveils Bias in Text-to-Image Diffusion Models",
    "authors": [
      "Lucas Berry",
      "Axel Brando",
      "Wei-Di Chang",
      "Juan Camilo Gamboa Higuera",
      "David Meger"
    ],
    "abstract": "Estimating uncertainty in text-to-image diffusion models is challenging because of their large parameter counts (often exceeding 100 million) and operation in complex, high-dimensional spaces with virtually infinite input possibilities. In this paper, we propose Epistemic Mixture of Experts (EMoE), a novel framework for efficiently estimating epistemic uncertainty in diffusion models. EMoE leverages pre-trained networks without requiring additional training, enabling direct uncertainty estimation from a prompt. We leverage a latent space within the diffusion process that captures epistemic uncertainty better than existing methods. Experimental results on the COCO dataset demonstrate EMoE's effectiveness, showing a strong correlation between uncertainty and image quality. Additionally, EMoE identifies under-sampled languages and regions with higher uncertainty, revealing hidden biases in the training set. This capability demonstrates the relevance of EMoE as a tool for addressing fairness and accountability in AI-generated content.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.13273v1",
    "published_date": "2025-05-19 15:53:32 UTC",
    "updated_date": "2025-05-19 15:53:32 UTC"
  },
  {
    "arxiv_id": "2505.13268v1",
    "title": "Representation of perceived prosodic similarity of conversational feedback",
    "authors": [
      "Livia Qian",
      "Carol Figueroa",
      "Gabriel Skantze"
    ],
    "abstract": "Vocal feedback (e.g., `mhm', `yeah', `okay') is an important component of spoken dialogue and is crucial to ensuring common ground in conversational systems. The exact meaning of such feedback is conveyed through both lexical and prosodic form. In this work, we investigate the perceived prosodic similarity of vocal feedback with the same lexical form, and to what extent existing speech representations reflect such similarities. A triadic comparison task with recruited participants is used to measure perceived similarity of feedback responses taken from two different datasets. We find that spectral and self-supervised speech representations encode prosody better than extracted pitch features, especially in the case of feedback from the same speaker. We also find that it is possible to further condense and align the representations to human perception through contrastive learning.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Interspeech 2025",
    "pdf_url": "https://arxiv.org/pdf/2505.13268v1",
    "published_date": "2025-05-19 15:47:51 UTC",
    "updated_date": "2025-05-19 15:47:51 UTC"
  },
  {
    "arxiv_id": "2505.13264v1",
    "title": "Net-Zero: A Comparative Study on Neural Network Design for Climate-Economic PDEs Under Uncertainty",
    "authors": [
      "Carlos Rodriguez-Pardo",
      "Louis Daumas",
      "Leonardo Chiani",
      "Massimo Tavoni"
    ],
    "abstract": "Climate-economic modeling under uncertainty presents significant computational challenges that may limit policymakers' ability to address climate change effectively. This paper explores neural network-based approaches for solving high-dimensional optimal control problems arising from models that incorporate ambiguity aversion in climate mitigation decisions. We develop a continuous-time endogenous-growth economic model that accounts for multiple mitigation pathways, including emission-free capital and carbon intensity reductions. Given the inherent complexity and high dimensionality of these models, traditional numerical methods become computationally intractable. We benchmark several neural network architectures against finite-difference generated solutions, evaluating their ability to capture the dynamic interactions between uncertainty, technology transitions, and optimal climate policy. Our findings demonstrate that appropriate neural architecture selection significantly impacts both solution accuracy and computational efficiency when modeling climate-economic systems under uncertainty. These methodological advances enable more sophisticated modeling of climate policy decisions, allowing for better representation of technology transitions and uncertainty-critical elements for developing effective mitigation strategies in the face of climate change.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE",
      "cs.PF",
      "math.AP"
    ],
    "primary_category": "cs.LG",
    "comment": "Under review",
    "pdf_url": "https://arxiv.org/pdf/2505.13264v1",
    "published_date": "2025-05-19 15:46:12 UTC",
    "updated_date": "2025-05-19 15:46:12 UTC"
  },
  {
    "arxiv_id": "2505.13257v2",
    "title": "Is Active Persona Inference Necessary for Aligning Small Models to Personal Preferences?",
    "authors": [
      "Zilu Tang",
      "Afra Feyza Akyürek",
      "Ekin Akyürek",
      "Derry Wijaya"
    ],
    "abstract": "A prominent issue in aligning language models (LMs) to personalized preferences is underspecification -- the lack of information from users about their preferences. A popular trend of injecting such specification is adding a prefix (e.g. prior relevant conversations) to the current user's conversation to steer preference distribution. Most methods passively model personal preferences with prior example preferences pairs. We ask whether models benefit from actively inferring preference descriptions, and address this question by creating a synthetic personalized alignment dataset based on famous people with known public preferences. We then test how effective finetuned 1-8B size models are at inferring and aligning to personal preferences. Results show that higher-quality active prefixes lead to better generalization, more contextually faithful models, and less systematic biases across different protected attributes. All our results suggest active alignment can lead to a more controllable and efficient path for personalized alignment.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "9 pages, EMNLP PALS workshop 2025",
    "pdf_url": "https://arxiv.org/pdf/2505.13257v2",
    "published_date": "2025-05-19 15:39:48 UTC",
    "updated_date": "2025-09-29 16:23:06 UTC"
  },
  {
    "arxiv_id": "2505.13253v1",
    "title": "Composing Dextrous Grasping and In-hand Manipulation via Scoring with a Reinforcement Learning Critic",
    "authors": [
      "Lennart Röstel",
      "Dominik Winkelbauer",
      "Johannes Pitz",
      "Leon Sievers",
      "Berthold Bäuml"
    ],
    "abstract": "In-hand manipulation and grasping are fundamental yet often separately addressed tasks in robotics. For deriving in-hand manipulation policies, reinforcement learning has recently shown great success. However, the derived controllers are not yet useful in real-world scenarios because they often require a human operator to place the objects in suitable initial (grasping) states. Finding stable grasps that also promote the desired in-hand manipulation goal is an open problem. In this work, we propose a method for bridging this gap by leveraging the critic network of a reinforcement learning agent trained for in-hand manipulation to score and select initial grasps. Our experiments show that this method significantly increases the success rate of in-hand manipulation without requiring additional training. We also present an implementation of a full grasp manipulation pipeline on a real-world system, enabling autonomous grasping and reorientation even of unwieldy objects.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.13253v1",
    "published_date": "2025-05-19 15:36:34 UTC",
    "updated_date": "2025-05-19 15:36:34 UTC"
  },
  {
    "arxiv_id": "2505.13580v1",
    "title": "OMGPT: A Sequence Modeling Framework for Data-driven Operational Decision Making",
    "authors": [
      "Hanzhao Wang",
      "Guanting Chen",
      "Kalyan Talluri",
      "Xiaocheng Li"
    ],
    "abstract": "We build a Generative Pre-trained Transformer (GPT) model from scratch to solve sequential decision making tasks arising in contexts of operations research and management science which we call OMGPT. We first propose a general sequence modeling framework to cover several operational decision making tasks as special cases, such as dynamic pricing, inventory management, resource allocation, and queueing control. Under the framework, all these tasks can be viewed as a sequential prediction problem where the goal is to predict the optimal future action given all the historical information. Then we train a transformer-based neural network model (OMGPT) as a natural and powerful architecture for sequential modeling. This marks a paradigm shift compared to the existing methods for these OR/OM tasks in that (i) the OMGPT model can take advantage of the huge amount of pre-trained data; (ii) when tackling these problems, OMGPT does not assume any analytical model structure and enables a direct and rich mapping from the history to the future actions. Either of these two aspects, to the best of our knowledge, is not achieved by any existing method. We establish a Bayesian perspective to theoretically understand the working mechanism of the OMGPT on these tasks, which relates its performance with the pre-training task diversity and the divergence between the testing task and pre-training tasks. Numerically, we observe a surprising performance of the proposed model across all the above tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "arXiv admin note: text overlap with arXiv:2405.14219",
    "pdf_url": "https://arxiv.org/pdf/2505.13580v1",
    "published_date": "2025-05-19 15:33:03 UTC",
    "updated_date": "2025-05-19 15:33:03 UTC"
  },
  {
    "arxiv_id": "2505.13579v1",
    "title": "Learning Wavelet-Sparse FDK for 3D Cone-Beam CT Reconstruction",
    "authors": [
      "Yipeng Sun",
      "Linda-Sophie Schneider",
      "Chengze Ye",
      "Mingxuan Gu",
      "Siyuan Mei",
      "Siming Bayer",
      "Andreas Maier"
    ],
    "abstract": "Cone-Beam Computed Tomography (CBCT) is essential in medical imaging, and the Feldkamp-Davis-Kress (FDK) algorithm is a popular choice for reconstruction due to its efficiency. However, FDK is susceptible to noise and artifacts. While recent deep learning methods offer improved image quality, they often increase computational complexity and lack the interpretability of traditional methods. In this paper, we introduce an enhanced FDK-based neural network that maintains the classical algorithm's interpretability by selectively integrating trainable elements into the cosine weighting and filtering stages. Recognizing the challenge of a large parameter space inherent in 3D CBCT data, we leverage wavelet transformations to create sparse representations of the cosine weights and filters. This strategic sparsification reduces the parameter count by $93.75\\%$ without compromising performance, accelerates convergence, and importantly, maintains the inference computational cost equivalent to the classical FDK algorithm. Our method not only ensures volumetric consistency and boosts robustness to noise, but is also designed for straightforward integration into existing CT reconstruction pipelines. This presents a pragmatic enhancement that can benefit clinical applications, particularly in environments with computational limitations.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "eess.IV",
    "comment": "Accepted by Fully3D 2025",
    "pdf_url": "https://arxiv.org/pdf/2505.13579v1",
    "published_date": "2025-05-19 15:31:40 UTC",
    "updated_date": "2025-05-19 15:31:40 UTC"
  },
  {
    "arxiv_id": "2505.13246v1",
    "title": "Agentic Publications: An LLM-Driven Framework for Interactive Scientific Publishing, Supplementing Traditional Papers with AI-Powered Knowledge Systems",
    "authors": [
      "Roberto Pugliese",
      "George Kourousias",
      "Francesco Venier",
      "Grazia Garlatti Costa"
    ],
    "abstract": "The exponential growth of scientific literature presents significant challenges for researchers navigating the complex knowledge landscape. We propose \"Agentic Publications\", a novel LLM-driven framework complementing traditional publishing by transforming papers into interactive knowledge systems. Our architecture integrates structured data with unstructured content through retrieval-augmented generation and multi-agent verification. The framework offers interfaces for both humans and machines, combining narrative explanations with machine-readable outputs while addressing ethical considerations through automated validation and transparent governance. Key features include continuous knowledge updates, automatic integration of new findings, and customizable detail levels. Our proof-of-concept demonstrates multilingual interaction, API accessibility, and structured knowledge representation through vector databases, knowledge graphs, and verification agents. This approach enhances scientific communication across disciplines, improving efficiency and collaboration while preserving traditional publishing pathways, particularly valuable for interdisciplinary fields where knowledge integration remains challenging.",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.13246v1",
    "published_date": "2025-05-19 15:28:10 UTC",
    "updated_date": "2025-05-19 15:28:10 UTC"
  },
  {
    "arxiv_id": "2505.17070v1",
    "title": "Improving endpoint detection in end-to-end streaming ASR for conversational speech",
    "authors": [
      "Anandh C",
      "Karthik Pandia Durai",
      "Jeena Prakash",
      "Manickavela Arumugam",
      "Kadri Hacioglu",
      "S. Pavankumar Dubagunta",
      "Andreas Stolcke",
      "Shankar Venkatesan",
      "Aravind Ganapathiraju"
    ],
    "abstract": "ASR endpointing (EP) plays a major role in delivering a good user experience in products supporting human or artificial agents in human-human/machine conversations. Transducer-based ASR (T-ASR) is an end-to-end (E2E) ASR modelling technique preferred for streaming. A major limitation of T-ASR is delayed emission of ASR outputs, which could lead to errors or delays in EP. Inaccurate EP will cut the user off while speaking, returning incomplete transcript while delays in EP will increase the perceived latency, degrading the user experience. We propose methods to improve EP by addressing delayed emission along with EP mistakes. To address the delayed emission problem, we introduce an end-of-word token at the end of each word, along with a delay penalty. The EP delay is addressed by obtaining a reliable frame-level speech activity detection using an auxiliary network. We apply the proposed methods on Switchboard conversational speech corpus and evaluate it against a delay penalty method.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL",
    "comment": "Submitted to Interspeech 2024",
    "pdf_url": "https://arxiv.org/pdf/2505.17070v1",
    "published_date": "2025-05-19 15:19:59 UTC",
    "updated_date": "2025-05-19 15:19:59 UTC"
  },
  {
    "arxiv_id": "2505.13232v3",
    "title": "StarFT: Robust Fine-tuning of Zero-shot Models via Spuriosity Alignment",
    "authors": [
      "Younghyun Kim",
      "Jongheon Jeong",
      "Sangkyung Kwak",
      "Kyungmin Lee",
      "Juho Lee",
      "Jinwoo Shin"
    ],
    "abstract": "Learning robust representations from data often requires scale, which has led to the success of recent zero-shot models such as CLIP. However, the obtained robustness can easily be deteriorated when these models are fine-tuned on other downstream tasks (e.g., of smaller scales). Previous works often interpret this phenomenon in the context of domain shift, developing fine-tuning methods that aim to preserve the original domain as much as possible. However, in a different context, fine-tuned models with limited data are also prone to learning features that are spurious to humans, such as background or texture. In this paper, we propose StarFT (Spurious Textual Alignment Regularization), a novel framework for fine-tuning zero-shot models to enhance robustness by preventing them from learning spuriosity. We introduce a regularization that aligns the output distribution for spuriosity-injected labels with the original zero-shot model, ensuring that the model is not induced to extract irrelevant features further from these descriptions. We leverage recent language models to get such spuriosity-injected labels by generating alternative textual descriptions that highlight potentially confounding features. Extensive experiments validate the robust generalization of StarFT and its emerging properties: zero-shot group robustness and improved zero-shot classification. Notably, StarFT boosts both worst-group and average accuracy by 14.30% and 3.02%, respectively, in the Waterbirds group shift scenario, where other robust fine-tuning baselines show even degraded performance.",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "IJCAI 2025; Code is available at https://github.com/alinlab/StarFT",
    "pdf_url": "https://arxiv.org/pdf/2505.13232v3",
    "published_date": "2025-05-19 15:15:35 UTC",
    "updated_date": "2025-06-27 13:19:58 UTC"
  },
  {
    "arxiv_id": "2505.13227v3",
    "title": "Scaling Computer-Use Grounding via User Interface Decomposition and Synthesis",
    "authors": [
      "Tianbao Xie",
      "Jiaqi Deng",
      "Xiaochuan Li",
      "Junlin Yang",
      "Haoyuan Wu",
      "Jixuan Chen",
      "Wenjing Hu",
      "Xinyuan Wang",
      "Yuhui Xu",
      "Zekun Wang",
      "Yiheng Xu",
      "Junli Wang",
      "Doyen Sahoo",
      "Tao Yu",
      "Caiming Xiong"
    ],
    "abstract": "Graphical user interface (GUI) grounding, the ability to map natural language instructions to specific actions on graphical user interfaces, remains a critical bottleneck in computer use agent development. Current benchmarks oversimplify grounding tasks as short referring expressions, failing to capture the complexity of real-world interactions that require software commonsense, layout understanding, and fine-grained manipulation capabilities. To address these limitations, we introduce OSWorld-G, a comprehensive benchmark comprising 564 finely annotated samples across diverse task types including text matching, element recognition, layout understanding, and precise manipulation. Additionally, we synthesize and release the largest computer use grounding dataset Jedi, which contains 4 million examples through multi-perspective decoupling of tasks. Our multi-scale models trained on Jedi demonstrate its effectiveness by outperforming existing approaches on ScreenSpot-v2, ScreenSpot-Pro, and our OSWorld-G. Furthermore, we demonstrate that improved grounding with Jedi directly enhances agentic capabilities of general foundation models on complex computer tasks, improving from 5% to 27% on OSWorld. Through detailed ablation studies, we identify key factors contributing to grounding performance and verify that combining specialized data for different interface elements enables compositional generalization to novel interfaces. All benchmark, data, checkpoints, and code are open-sourced and available at https://osworld-grounding.github.io.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "49 pages, 13 figures",
    "pdf_url": "https://arxiv.org/pdf/2505.13227v3",
    "published_date": "2025-05-19 15:09:23 UTC",
    "updated_date": "2025-10-24 19:08:03 UTC"
  },
  {
    "arxiv_id": "2505.18190v4",
    "title": "PhySense: Sensor Placement Optimization for Accurate Physics Sensing",
    "authors": [
      "Yuezhou Ma",
      "Haixu Wu",
      "Hang Zhou",
      "Huikun Weng",
      "Jianmin Wang",
      "Mingsheng Long"
    ],
    "abstract": "Physics sensing plays a central role in many scientific and engineering domains, which inherently involves two coupled tasks: reconstructing dense physical fields from sparse observations and optimizing scattered sensor placements to observe maximum information. While deep learning has made rapid advances in sparse-data reconstruction, existing methods generally omit optimization of sensor placements, leaving the mutual enhancement between reconstruction and placement on the shelf. To change this suboptimal practice, we propose PhySense, a synergistic two-stage framework that learns to jointly reconstruct physical fields and to optimize sensor placements, both aiming for accurate physics sensing. The first stage involves a flow-based generative model enhanced by cross-attention to adaptively fuse sparse observations. Leveraging the reconstruction feedback, the second stage performs sensor placement via projected gradient descent to satisfy spatial constraints. We further prove that the learning objectives of the two stages are consistent with classical variance-minimization principles, providing theoretical guarantees. Extensive experiments across three challenging benchmarks, especially a 3D geometry dataset, indicate PhySense achieves state-of-the-art physics sensing accuracy and discovers informative sensor placements previously unconsidered. Code is available at this repository: https://github.com/thuml/PhySense.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.18190v4",
    "published_date": "2025-05-19 14:59:11 UTC",
    "updated_date": "2025-12-01 04:14:30 UTC"
  },
  {
    "arxiv_id": "2505.13211v1",
    "title": "MAGI-1: Autoregressive Video Generation at Scale",
    "authors": [
      "Sand. ai",
      "Hansi Teng",
      "Hongyu Jia",
      "Lei Sun",
      "Lingzhi Li",
      "Maolin Li",
      "Mingqiu Tang",
      "Shuai Han",
      "Tianning Zhang",
      "W. Q. Zhang",
      "Weifeng Luo",
      "Xiaoyang Kang",
      "Yuchen Sun",
      "Yue Cao",
      "Yunpeng Huang",
      "Yutong Lin",
      "Yuxin Fang",
      "Zewei Tao",
      "Zheng Zhang",
      "Zhongshu Wang",
      "Zixun Liu",
      "Dai Shi",
      "Guoli Su",
      "Hanwen Sun",
      "Hong Pan",
      "Jie Wang",
      "Jiexin Sheng",
      "Min Cui",
      "Min Hu",
      "Ming Yan",
      "Shucheng Yin",
      "Siran Zhang",
      "Tingting Liu",
      "Xianping Yin",
      "Xiaoyu Yang",
      "Xin Song",
      "Xuan Hu",
      "Yankai Zhang",
      "Yuqiao Li"
    ],
    "abstract": "We present MAGI-1, a world model that generates videos by autoregressively predicting a sequence of video chunks, defined as fixed-length segments of consecutive frames. Trained to denoise per-chunk noise that increases monotonically over time, MAGI-1 enables causal temporal modeling and naturally supports streaming generation. It achieves strong performance on image-to-video (I2V) tasks conditioned on text instructions, providing high temporal consistency and scalability, which are made possible by several algorithmic innovations and a dedicated infrastructure stack. MAGI-1 facilitates controllable generation via chunk-wise prompting and supports real-time, memory-efficient deployment by maintaining constant peak inference cost, regardless of video length. The largest variant of MAGI-1 comprises 24 billion parameters and supports context lengths of up to 4 million tokens, demonstrating the scalability and robustness of our approach. The code and models are available at https://github.com/SandAI-org/MAGI-1 and https://github.com/SandAI-org/MagiAttention. The product can be accessed at https://sand.ai.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.13211v1",
    "published_date": "2025-05-19 14:58:50 UTC",
    "updated_date": "2025-05-19 14:58:50 UTC"
  },
  {
    "arxiv_id": "2505.13210v1",
    "title": "Picturized and Recited with Dialects: A Multimodal Chinese Representation Framework for Sentiment Analysis of Classical Chinese Poetry",
    "authors": [
      "Xiaocong Du",
      "Haoyu Pei",
      "Haipeng Zhang"
    ],
    "abstract": "Classical Chinese poetry is a vital and enduring part of Chinese literature, conveying profound emotional resonance. Existing studies analyze sentiment based on textual meanings, overlooking the unique rhythmic and visual features inherent in poetry,especially since it is often recited and accompanied by Chinese paintings. In this work, we propose a dialect-enhanced multimodal framework for classical Chinese poetry sentiment analysis. We extract sentence-level audio features from the poetry and incorporate audio from multiple dialects,which may retain regional ancient Chinese phonetic features, enriching the phonetic representation. Additionally, we generate sentence-level visual features, and the multimodal features are fused with textual features enhanced by LLM translation through multimodal contrastive representation learning. Our framework outperforms state-of-the-art methods on two public datasets, achieving at least 2.51% improvement in accuracy and 1.63% in macro F1. We open-source the code to facilitate research in this area and provide insights for general multimodal Chinese representation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.13210v1",
    "published_date": "2025-05-19 14:58:44 UTC",
    "updated_date": "2025-05-19 14:58:44 UTC"
  },
  {
    "arxiv_id": "2505.13577v3",
    "title": "VocalAgent: Large Language Models for Vocal Health Diagnostics with Safety-Aware Evaluation",
    "authors": [
      "Yubin Kim",
      "Taehan Kim",
      "Wonjune Kang",
      "Eugene Park",
      "Joonsik Yoon",
      "Dongjae Lee",
      "Xin Liu",
      "Daniel McDuff",
      "Hyeonhoon Lee",
      "Cynthia Breazeal",
      "Hae Won Park"
    ],
    "abstract": "Vocal health plays a crucial role in peoples' lives, significantly impacting their communicative abilities and interactions. However, despite the global prevalence of voice disorders, many lack access to convenient diagnosis and treatment. This paper introduces VocalAgent, an audio large language model (LLM) to address these challenges through vocal health diagnosis. We leverage Qwen-Audio-Chat fine-tuned on three datasets collected in-situ from hospital patients, and present a multifaceted evaluation framework encompassing a safety assessment to mitigate diagnostic biases, cross-lingual performance analysis, and modality ablation studies. VocalAgent demonstrates superior accuracy on voice disorder classification compared to state-of-the-art baselines. Its LLM-based method offers a scalable solution for broader adoption of health diagnostics, while underscoring the importance of ethical and technical validation.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Accepted by Proceedings of Interspeech 2025; Website: https://han811.github.io/VocalAgent2025/",
    "pdf_url": "https://arxiv.org/pdf/2505.13577v3",
    "published_date": "2025-05-19 14:58:42 UTC",
    "updated_date": "2025-09-25 23:01:20 UTC"
  },
  {
    "arxiv_id": "2505.13208v1",
    "title": "Efficient Generation of Parameterised Quantum Circuits from Large Texts",
    "authors": [
      "Colin Krawchuk",
      "Nikhil Khatri",
      "Neil John Ortega",
      "Dimitri Kartsaklis"
    ],
    "abstract": "Quantum approaches to natural language processing (NLP) are redefining how linguistic information is represented and processed. While traditional hybrid quantum-classical models rely heavily on classical neural networks, recent advancements propose a novel framework, DisCoCirc, capable of directly encoding entire documents as parameterised quantum circuits (PQCs), besides enjoying some additional interpretability and compositionality benefits. Following these ideas, this paper introduces an efficient methodology for converting large-scale texts into quantum circuits using tree-like representations of pregroup diagrams. Exploiting the compositional parallels between language and quantum mechanics, grounded in symmetric monoidal categories, our approach enables faithful and efficient encoding of syntactic and discourse relationships in long and complex texts (up to 6410 words in our experiments) to quantum circuits. The developed system is provided to the community as part of the augmented open-source quantum NLP package lambeq Gen II.",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "quant-ph",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.13208v1",
    "published_date": "2025-05-19 14:57:53 UTC",
    "updated_date": "2025-05-19 14:57:53 UTC"
  },
  {
    "arxiv_id": "2505.13201v1",
    "title": "MatPredict: a dataset and benchmark for learning material properties of diverse indoor objects",
    "authors": [
      "Yuzhen Chen",
      "Hojun Son",
      "Arpan Kusari"
    ],
    "abstract": "Determining material properties from camera images can expand the ability to identify complex objects in indoor environments, which is valuable for consumer robotics applications. To support this, we introduce MatPredict, a dataset that combines the high-quality synthetic objects from Replica dataset with MatSynth dataset's material properties classes - to create objects with diverse material properties. We select 3D meshes of specific foreground objects and render them with different material properties. In total, we generate \\textbf{18} commonly occurring objects with \\textbf{14} different materials. We showcase how we provide variability in terms of lighting and camera placement for these objects. Next, we provide a benchmark for inferring material properties from visual images using these perturbed models in the scene, discussing the specific neural network models involved and their performance based on different image comparison metrics. By accurately simulating light interactions with different materials, we can enhance realism, which is crucial for training models effectively through large-scale simulations. This research aims to revolutionize perception in consumer robotics. The dataset is provided \\href{https://huggingface.co/datasets/UMTRI/MatPredict}{here} and the code is provided \\href{https://github.com/arpan-kusari/MatPredict}{here}.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.13201v1",
    "published_date": "2025-05-19 14:54:04 UTC",
    "updated_date": "2025-05-19 14:54:04 UTC"
  },
  {
    "arxiv_id": "2505.13196v2",
    "title": "A Physics-Inspired Optimizer: Velocity Regularized Adam",
    "authors": [
      "Pranav Vaidhyanathan",
      "Lucas Schorling",
      "Natalia Ares",
      "Michael A. Osborne"
    ],
    "abstract": "We introduce Velocity-Regularized Adam (VRAdam), a physics-inspired optimizer for training deep neural networks that draws on ideas from quartic terms for kinetic energy with its stabilizing effects on various system dynamics. Previous algorithms, including the ubiquitous Adam, operate at the so-called adaptive edge of stability regime during training, leading to rapid oscillations and slowed convergence of loss. However, VRAdam adds a higher order penalty on the learning rate based on the velocity such that the algorithm automatically slows down whenever weight updates become large. In practice, we observe that the effective dynamic learning rate shrinks in high-velocity regimes, and damping oscillations. By combining this velocity-based regularizer for global damping with per-parameter scaling of Adam, we create a powerful hybrid optimizer. For this optimizer, we provide rigorous theoretical analysis of operation at the edge of stability from a physical and control perspective for the momentum. Furthermore, we derive convergence bounds with the rate $\\mathcal{O}(\\ln(N)/\\sqrt{N})$ for a stochastic non convex objective under mild assumptions. We demonstrate that VRAdam exceeds the performance against standard optimizers including AdamW. We benchmark various tasks such as image classification, language modeling, and generative modeling using diverse architectures and training methodologies including Convolutional Neural Networks (CNNs), Transformers, and GFlowNets.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "quant-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "L. Schorling and P. Vaidhyanathan contributed equally to this work. 20 pages, 10 figures",
    "pdf_url": "https://arxiv.org/pdf/2505.13196v2",
    "published_date": "2025-05-19 14:51:40 UTC",
    "updated_date": "2025-10-01 00:53:20 UTC"
  },
  {
    "arxiv_id": "2505.13195v1",
    "title": "Adversarial Testing in LLMs: Insights into Decision-Making Vulnerabilities",
    "authors": [
      "Lili Zhang",
      "Haomiaomiao Wang",
      "Long Cheng",
      "Libao Deng",
      "Tomas Ward"
    ],
    "abstract": "As Large Language Models (LLMs) become increasingly integrated into real-world decision-making systems, understanding their behavioural vulnerabilities remains a critical challenge for AI safety and alignment. While existing evaluation metrics focus primarily on reasoning accuracy or factual correctness, they often overlook whether LLMs are robust to adversarial manipulation or capable of using adaptive strategy in dynamic environments. This paper introduces an adversarial evaluation framework designed to systematically stress-test the decision-making processes of LLMs under interactive and adversarial conditions. Drawing on methodologies from cognitive psychology and game theory, our framework probes how models respond in two canonical tasks: the two-armed bandit task and the Multi-Round Trust Task. These tasks capture key aspects of exploration-exploitation trade-offs, social cooperation, and strategic flexibility. We apply this framework to several state-of-the-art LLMs, including GPT-3.5, GPT-4, Gemini-1.5, and DeepSeek-V3, revealing model-specific susceptibilities to manipulation and rigidity in strategy adaptation. Our findings highlight distinct behavioral patterns across models and emphasize the importance of adaptability and fairness recognition for trustworthy AI deployment. Rather than offering a performance benchmark, this work proposes a methodology for diagnosing decision-making weaknesses in LLM-based agents, providing actionable insights for alignment and safety research.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.13195v1",
    "published_date": "2025-05-19 14:50:44 UTC",
    "updated_date": "2025-05-19 14:50:44 UTC"
  },
  {
    "arxiv_id": "2505.13192v2",
    "title": "True Zero-Shot Inference of Dynamical Systems Preserving Long-Term Statistics",
    "authors": [
      "Christoph Jürgen Hemmer",
      "Daniel Durstewitz"
    ],
    "abstract": "Complex, temporally evolving phenomena, from climate to brain activity, are governed by dynamical systems (DS). DS reconstruction (DSR) seeks to infer generative surrogate models of these from observed data, reproducing their long-term behavior. Existing DSR approaches require purpose-training for any new system observed, lacking the zero-shot and in-context inference capabilities known from LLMs. Here we introduce DynaMix, a novel multivariate ALRNN-based mixture-of-experts architecture pre-trained for DSR, the first DSR model able to generalize zero-shot to out-of-domain DS. Just from a provided context signal, without any re-training, DynaMix faithfully forecasts the long-term evolution of novel DS where existing time series (TS) foundation models, like Chronos, fail -- at a fraction of the number of parameters (0.1%) and orders of magnitude faster inference times. DynaMix outperforms TS foundation models in terms of long-term statistics, and often also short-term forecasts, even on real-world time series, like traffic or weather data, typically used for training and evaluating TS models, but not at all part of DynaMix' training corpus. We illustrate some of the failure modes of TS models for DSR problems, and conclude that models built on DS principles may bear a huge potential also for advancing the TS prediction field.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.DS",
      "nlin.CD"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.13192v2",
    "published_date": "2025-05-19 14:49:10 UTC",
    "updated_date": "2025-10-24 15:51:36 UTC"
  },
  {
    "arxiv_id": "2505.13191v2",
    "title": "Emergence of Fixational and Saccadic Movements in a Multi-Level Recurrent Attention Model for Vision",
    "authors": [
      "Pengcheng Pan",
      "Yonekura Shogo",
      "Yasuo Kuniyoshi"
    ],
    "abstract": "Inspired by foveal vision, hard attention models promise interpretability and parameter economy. However, existing models like the Recurrent Model of Visual Attention (RAM) and Deep Recurrent Attention Model (DRAM) failed to model the hierarchy of human vision system, that compromise on the visual exploration dynamics. As a result, they tend to produce attention that are either overly fixational or excessively saccadic, diverging from human eye movement behavior. In this paper, we propose a Multi-Level Recurrent Attention Model (MRAM), a novel hard attention framework that explicitly models the neural hierarchy of human visual processing. By decoupling the function of glimpse location generation and task execution in two recurrent layers, MRAM emergent a balanced behavior between fixation and saccadic movement. Our results show that MRAM not only achieves more human-like attention dynamics, but also consistently outperforms CNN, RAM and DRAM baselines on standard image classification benchmarks.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.13191v2",
    "published_date": "2025-05-19 14:48:36 UTC",
    "updated_date": "2025-11-17 13:11:41 UTC"
  },
  {
    "arxiv_id": "2505.13188v2",
    "title": "When a Reinforcement Learning Agent Encounters Unknown Unknowns",
    "authors": [
      "Juntian Zhu",
      "Miguel de Carvalho",
      "Zhouwang Yang",
      "Fengxiang He"
    ],
    "abstract": "An AI agent might surprisingly find she has reached an unknown state which she has never been aware of -- an unknown unknown. We mathematically ground this scenario in reinforcement learning: an agent, after taking an action calculated from value functions $Q$ and $V$ defined on the {\\it {aware domain}}, reaches a state out of the domain. To enable the agent to handle this scenario, we propose an {\\it episodic Markov decision {process} with growing awareness} (EMDP-GA) model, taking a new {\\it noninformative value expansion} (NIVE) approach to expand value functions to newly aware areas: when an agent arrives at an unknown unknown, value functions $Q$ and $V$ whereon are initialised by noninformative beliefs -- the averaged values on the aware domain. This design is out of respect for the complete absence of knowledge in the newly discovered state. The upper confidence bound momentum Q-learning is then adapted to the growing awareness for training the EMDP-GA model. We prove that (1) the regret of our approach is asymptotically consistent with the state of the art (SOTA) without exposure to unknown unknowns in an extremely uncertain environment, and (2) our computational complexity and space complexity are comparable with the SOTA -- these collectively suggest that though an unknown unknown is surprising, it will be asymptotically properly discovered with decent speed and an affordable cost.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.13188v2",
    "published_date": "2025-05-19 14:45:58 UTC",
    "updated_date": "2025-09-03 11:20:30 UTC"
  },
  {
    "arxiv_id": "2505.13182v13",
    "title": "Information Science Principles of Machine Learning: A Causal Chain Meta-Framework Based on Formalized Information Mapping",
    "authors": [
      "Jianfeng Xu"
    ],
    "abstract": "This paper addresses the current lack of a unified formal framework in machine learning theory, as well as the absence of robust theoretical foundations for interpretability and ethical safety assurance. We first construct a formal information model, employing sets of well-formed formulas (WFFs) to explicitly define the ontological states and carrier mappings for the core components of machine learning. By introducing learnable and processable predicates, as well as learning and processing functions, we analyze the logical inference and constraint rules underlying causal chains in models, thereby establishing the Machine Learning Theory Meta-Framework (MLT-MF). Building upon this framework, we propose universal definitions for model interpretability and ethical safety, and rigorously prove and validate four key theorems: the equivalence between model interpretability and information existence, the constructive formulation of ethical safety assurance and two types of total variation distance (TVD) upper bounds. This work overcomes the limitations of previous fragmented approaches, providing a unified theoretical foundation from an information science perspective to systematically address the critical challenges currently facing machine learning.",
    "categories": [
      "cs.LO",
      "cs.AI"
    ],
    "primary_category": "cs.LO",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.13182v13",
    "published_date": "2025-05-19 14:39:41 UTC",
    "updated_date": "2025-11-08 04:33:37 UTC"
  },
  {
    "arxiv_id": "2505.13180v1",
    "title": "ViPlan: A Benchmark for Visual Planning with Symbolic Predicates and Vision-Language Models",
    "authors": [
      "Matteo Merler",
      "Nicola Dainese",
      "Minttu Alakuijala",
      "Giovanni Bonetta",
      "Pietro Ferrazzi",
      "Yu Tian",
      "Bernardo Magnini",
      "Pekka Marttinen"
    ],
    "abstract": "Integrating Large Language Models with symbolic planners is a promising direction for obtaining verifiable and grounded plans compared to planning in natural language, with recent works extending this idea to visual domains using Vision-Language Models (VLMs). However, rigorous comparison between VLM-grounded symbolic approaches and methods that plan directly with a VLM has been hindered by a lack of common environments, evaluation protocols and model coverage. We introduce ViPlan, the first open-source benchmark for Visual Planning with symbolic predicates and VLMs. ViPlan features a series of increasingly challenging tasks in two domains: a visual variant of the classic Blocksworld planning problem and a simulated household robotics environment. We benchmark nine open-source VLM families across multiple sizes, along with selected closed models, evaluating both VLM-grounded symbolic planning and using the models directly to propose actions. We find symbolic planning to outperform direct VLM planning in Blocksworld, where accurate image grounding is crucial, whereas the opposite is true in the household robotics tasks, where commonsense knowledge and the ability to recover from errors are beneficial. Finally, we show that across most models and methods, there is no significant benefit to using Chain-of-Thought prompting, suggesting that current VLMs still struggle with visual reasoning.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "9 pages, 5 figures and 1 table in the main text; 43 pages, 9 figures and 16 tables including supplementary material",
    "pdf_url": "https://arxiv.org/pdf/2505.13180v1",
    "published_date": "2025-05-19 14:38:15 UTC",
    "updated_date": "2025-05-19 14:38:15 UTC"
  },
  {
    "arxiv_id": "2505.13176v2",
    "title": "ToolSpectrum : Towards Personalized Tool Utilization for Large Language Models",
    "authors": [
      "Zihao Cheng",
      "Hongru Wang",
      "Zeming Liu",
      "Yuhang Guo",
      "Yuanfang Guo",
      "Yunhong Wang",
      "Haifeng Wang"
    ],
    "abstract": "While integrating external tools into large language models (LLMs) enhances their ability to access real-time information and domain-specific services, existing approaches focus narrowly on functional tool selection following user instructions, overlooking the context-aware personalization in tool selection. This oversight leads to suboptimal user satisfaction and inefficient tool utilization, particularly when overlapping toolsets require nuanced selection based on contextual factors. To bridge this gap, we introduce ToolSpectrum, a benchmark designed to evaluate LLMs' capabilities in personalized tool utilization. Specifically, we formalize two key dimensions of personalization, user profile and environmental factors, and analyze their individual and synergistic impacts on tool utilization. Through extensive experiments on ToolSpectrum, we demonstrate that personalized tool utilization significantly improves user experience across diverse scenarios. However, even state-of-the-art LLMs exhibit the limited ability to reason jointly about user profiles and environmental factors, often prioritizing one dimension at the expense of the other. Our findings underscore the necessity of context-aware personalization in tool-augmented LLMs and reveal critical limitations for current models. Our data and code are available at https://github.com/Chengziha0/ToolSpectrum.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by ACL 2025 Findings",
    "pdf_url": "https://arxiv.org/pdf/2505.13176v2",
    "published_date": "2025-05-19 14:30:46 UTC",
    "updated_date": "2025-05-22 14:08:07 UTC"
  },
  {
    "arxiv_id": "2505.13175v1",
    "title": "Enhancing LLMs for Time Series Forecasting via Structure-Guided Cross-Modal Alignment",
    "authors": [
      "Siming Sun",
      "Kai Zhang",
      "Xuejun Jiang",
      "Wenchao Meng",
      "Qinmin Yang"
    ],
    "abstract": "The emerging paradigm of leveraging pretrained large language models (LLMs) for time series forecasting has predominantly employed linguistic-temporal modality alignment strategies through token-level or layer-wise feature mapping. However, these approaches fundamentally neglect a critical insight: the core competency of LLMs resides not merely in processing localized token features but in their inherent capacity to model holistic sequence structures. This paper posits that effective cross-modal alignment necessitates structural consistency at the sequence level. We propose the Structure-Guided Cross-Modal Alignment (SGCMA), a framework that fully exploits and aligns the state-transition graph structures shared by time-series and linguistic data as sequential modalities, thereby endowing time series with language-like properties and delivering stronger generalization after modality alignment. SGCMA consists of two key components, namely Structure Alignment and Semantic Alignment. In Structure Alignment, a state transition matrix is learned from text data through Hidden Markov Models (HMMs), and a shallow transformer-based Maximum Entropy Markov Model (MEMM) receives the hot-start transition matrix and annotates each temporal patch into state probability, ensuring that the temporal representation sequence inherits language-like sequential dynamics. In Semantic Alignment, cross-attention is applied between temporal patches and the top-k tokens within each state, and the ultimate temporal embeddings are derived by the expected value of these embeddings using a weighted average based on state probabilities. Experiments on multiple benchmarks demonstrate that SGCMA achieves state-of-the-art performance, offering a novel approach to cross-modal alignment in time series forecasting.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.13175v1",
    "published_date": "2025-05-19 14:30:41 UTC",
    "updated_date": "2025-05-19 14:30:41 UTC"
  },
  {
    "arxiv_id": "2505.13157v1",
    "title": "Role-Playing Evaluation for Large Language Models",
    "authors": [
      "Yassine El Boudouri",
      "Walter Nuninger",
      "Julian Alvarez",
      "Yvan Peter"
    ],
    "abstract": "Large Language Models (LLMs) demonstrate a notable capacity for adopting personas and engaging in role-playing. However, evaluating this ability presents significant challenges, as human assessments are resource-intensive and automated evaluations can be biased. To address this, we introduce Role-Playing Eval (RPEval), a novel benchmark designed to assess LLM role-playing capabilities across four key dimensions: emotional understanding, decision-making, moral alignment, and in-character consistency. This article details the construction of RPEval and presents baseline evaluations. Our code and dataset are available at https://github.com/yelboudouri/RPEval",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.13157v1",
    "published_date": "2025-05-19 14:18:16 UTC",
    "updated_date": "2025-05-19 14:18:16 UTC"
  },
  {
    "arxiv_id": "2505.13156v1",
    "title": "Tianyi: A Traditional Chinese Medicine all-rounder language model and its Real-World Clinical Practice",
    "authors": [
      "Zhi Liu",
      "Tao Yang",
      "Jing Wang",
      "Yexin Chen",
      "Zhan Gao",
      "Jiaxi Yang",
      "Kui Chen",
      "Bingji Lu",
      "Xiaochen Li",
      "Changyong Luo",
      "Yan Li",
      "Xiaohong Gu",
      "Peng Cao"
    ],
    "abstract": "Natural medicines, particularly Traditional Chinese Medicine (TCM), are gaining global recognition for their therapeutic potential in addressing human symptoms and diseases. TCM, with its systematic theories and extensive practical experience, provides abundant resources for healthcare. However, the effective application of TCM requires precise syndrome diagnosis, determination of treatment principles, and prescription formulation, which demand decades of clinical expertise. Despite advancements in TCM-based decision systems, machine learning, and deep learning research, limitations in data and single-objective constraints hinder their practical application. In recent years, large language models (LLMs) have demonstrated potential in complex tasks, but lack specialization in TCM and face significant challenges, such as too big model scale to deploy and issues with hallucination. To address these challenges, we introduce Tianyi with 7.6-billion-parameter LLM, a model scale proper and specifically designed for TCM, pre-trained and fine-tuned on diverse TCM corpora, including classical texts, expert treatises, clinical records, and knowledge graphs. Tianyi is designed to assimilate interconnected and systematic TCM knowledge through a progressive learning manner. Additionally, we establish TCMEval, a comprehensive evaluation benchmark, to assess LLMs in TCM examinations, clinical tasks, domain-specific question-answering, and real-world trials. The extensive evaluations demonstrate the significant potential of Tianyi as an AI assistant in TCM clinical practice and research, bridging the gap between TCM knowledge and practical application.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "23 pages, 4 figures, and 1 tables",
    "pdf_url": "https://arxiv.org/pdf/2505.13156v1",
    "published_date": "2025-05-19 14:17:37 UTC",
    "updated_date": "2025-05-19 14:17:37 UTC"
  },
  {
    "arxiv_id": "2505.13144v1",
    "title": "Temporal Distance-aware Transition Augmentation for Offline Model-based Reinforcement Learning",
    "authors": [
      "Dongsu Lee",
      "Minhae Kwon"
    ],
    "abstract": "The goal of offline reinforcement learning (RL) is to extract a high-performance policy from the fixed datasets, minimizing performance degradation due to out-of-distribution (OOD) samples. Offline model-based RL (MBRL) is a promising approach that ameliorates OOD issues by enriching state-action transitions with augmentations synthesized via a learned dynamics model. Unfortunately, seminal offline MBRL methods often struggle in sparse-reward, long-horizon tasks. In this work, we introduce a novel MBRL framework, dubbed Temporal Distance-Aware Transition Augmentation (TempDATA), that generates augmented transitions in a temporally structured latent space rather than in raw state space. To model long-horizon behavior, TempDATA learns a latent abstraction that captures a temporal distance from both trajectory and transition levels of state space. Our experiments confirm that TempDATA outperforms previous offline MBRL methods and achieves matching or surpassing the performance of diffusion-based trajectory augmentation and goal-conditioned RL on the D4RL AntMaze, FrankaKitchen, CALVIN, and pixel-based FrankaKitchen.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "2025 ICML",
    "pdf_url": "https://arxiv.org/pdf/2505.13144v1",
    "published_date": "2025-05-19 14:11:14 UTC",
    "updated_date": "2025-05-19 14:11:14 UTC"
  },
  {
    "arxiv_id": "2505.13136v2",
    "title": "New Encoders for German Trained from Scratch: Comparing ModernGBERT with Converted LLM2Vec Models",
    "authors": [
      "Julia Wunderle",
      "Anton Ehrmanntraut",
      "Jan Pfister",
      "Fotis Jannidis",
      "Andreas Hotho"
    ],
    "abstract": "Encoders remain essential for efficient German NLP and NLU scenarios despite the rise of decoder-only LLMs. This work studies two routes to high-quality German encoders under identical data and training constraints: 1) training from scratch and 2) converting decoders via LLM2Vec. We introduce two resources: ModernGBERT (134M, 1B), fully transparent German encoders in the ModernBERT style, and LLäMmleinVec (120M, 1B, 7B), decoder-to-encoder conversions trained with masked next-token prediction, both undergoing a context extension to 8.192 tokens.\n  Across SuperGLEBer, ModernGBERT 1B sets a new state of the art (avg 0.808), surpassing GBERT Large (+4%) and the seven-times larger converted 7B model (0.787). On German MTEB after supervised fine-tuning, ModernGBERT 1B (0.551) approaches the converted 7B model (0.557).\n  We release all models, checkpoints, datasets, and full training records, and introduce an encoder-adapted QA-NIAH evaluation. All in all, our results provide actionable guidance: when parameter efficiency and latency matter, from-scratch encoders dominate. When a pre-trained decoder exists and compute is a limited, conversion offers an effective alternative. ModernGBERT and LLäMmleinVec, including all code, data and intermediary checkpoints are published under a research-only RAIL license.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "under review @LREC",
    "pdf_url": "https://arxiv.org/pdf/2505.13136v2",
    "published_date": "2025-05-19 14:07:20 UTC",
    "updated_date": "2025-11-03 12:45:10 UTC"
  },
  {
    "arxiv_id": "2505.14719v3",
    "title": "MSVIT: Improving Spiking Vision Transformer Using Multi-scale Attention Fusion",
    "authors": [
      "Wei Hua",
      "Chenlin Zhou",
      "Jibin Wu",
      "Yansong Chua",
      "Yangyang Shu"
    ],
    "abstract": "The combination of Spiking Neural Networks (SNNs) with Vision Transformer architectures has garnered significant attention due to their potential for energy-efficient and high-performance computing paradigms. However, a substantial performance gap still exists between SNN-based and ANN-based transformer architectures. While existing methods propose spiking self-attention mechanisms that are successfully combined with SNNs, the overall architectures proposed by these methods suffer from a bottleneck in effectively extracting features from different image scales. In this paper, we address this issue and propose MSVIT. This novel spike-driven Transformer architecture firstly uses multi-scale spiking attention (MSSA) to enhance the capabilities of spiking attention blocks. We validate our approach across various main datasets. The experimental results show that MSVIT outperforms existing SNN-based models, positioning itself as a state-of-the-art solution among SNN-transformer architectures. The codes are available at https://github.com/Nanhu-AI-Lab/MSViT.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "11pages, 2figures, accepted by IJCAI'25 (34th International Joint Conference on Artificial Intelligence)",
    "pdf_url": "https://arxiv.org/pdf/2505.14719v3",
    "published_date": "2025-05-19 14:01:03 UTC",
    "updated_date": "2025-06-18 03:58:23 UTC"
  },
  {
    "arxiv_id": "2505.13130v1",
    "title": "Adaptive Image Restoration for Video Surveillance: A Real-Time Approach",
    "authors": [
      "Muhammad Awais Amin",
      "Adama Ilboudo",
      "Abdul Samad bin Shahid",
      "Amjad Ali",
      "Waqas Haider Khan Bangyal"
    ],
    "abstract": "One of the major challenges in the field of computer vision especially for detection, segmentation, recognition, monitoring, and automated solutions, is the quality of images. Image degradation, often caused by factors such as rain, fog, lighting, etc., has a negative impact on automated decision-making.Furthermore, several image restoration solutions exist, including restoration models for single degradation and restoration models for multiple degradations. However, these solutions are not suitable for real-time processing. In this study, the aim was to develop a real-time image restoration solution for video surveillance. To achieve this, using transfer learning with ResNet_50, we developed a model for automatically identifying the types of degradation present in an image to reference the necessary treatment(s) for image restoration. Our solution has the advantage of being flexible and scalable.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.13130v1",
    "published_date": "2025-05-19 14:00:10 UTC",
    "updated_date": "2025-05-19 14:00:10 UTC"
  },
  {
    "arxiv_id": "2505.13126v2",
    "title": "Zero-Shot Iterative Formalization and Planning in Partially Observable Environments",
    "authors": [
      "Liancheng Gong",
      "Wang Zhu",
      "Jesse Thomason",
      "Li Zhang"
    ],
    "abstract": "Using LLMs not to predict plans but to formalize an environment into the Planning Domain Definition Language (PDDL) has been shown to improve performance and control. Existing work focuses on fully observable environments; we tackle the more realistic and challenging partially observable environments that lack of complete, reliable information. We propose PDDLego+, a framework to iteratively formalize, plan, grow, and refine PDDL representations in a zero-shot manner, without needing access to any existing trajectories. On two textual simulated environments, we show that PDDLego+ improves goal reaching success and exhibits robustness against problem complexity. We also show that the domain knowledge captured after a successful trial can benefit future tasks.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.13126v2",
    "published_date": "2025-05-19 13:58:15 UTC",
    "updated_date": "2025-05-20 13:53:50 UTC"
  },
  {
    "arxiv_id": "2505.13124v2",
    "title": "$μ$PC: Scaling Predictive Coding to 100+ Layer Networks",
    "authors": [
      "Francesco Innocenti",
      "El Mehdi Achour",
      "Christopher L. Buckley"
    ],
    "abstract": "The biological implausibility of backpropagation (BP) has motivated many alternative, brain-inspired algorithms that attempt to rely only on local information, such as predictive coding (PC) and equilibrium propagation. However, these algorithms have notoriously struggled to train very deep networks, preventing them from competing with BP in large-scale settings. Indeed, scaling PC networks (PCNs) has recently been posed as a challenge for the community (Pinchetti et al., 2024). Here, we show that 100+ layer PCNs can be trained reliably using a Depth-$μ$P parameterisation (Yang et al., 2023; Bordelon et al., 2023) which we call \"$μ$PC\". By analysing the scaling behaviour of PCNs, we reveal several pathologies that make standard PCNs difficult to train at large depths. We then show that, despite addressing only some of these instabilities, $μ$PC allows stable training of very deep (up to 128-layer) residual networks on simple classification tasks with competitive performance and little tuning compared to current benchmarks. Moreover, $μ$PC enables zero-shot transfer of both weight and activity learning rates across widths and depths. Our results serve as a first step towards scaling PC to more complex architectures and have implications for other local algorithms. Code for $μ$PC is made available as part of a JAX library for PCNs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "35 pages, 42 figures",
    "pdf_url": "https://arxiv.org/pdf/2505.13124v2",
    "published_date": "2025-05-19 13:54:29 UTC",
    "updated_date": "2025-11-28 10:13:02 UTC"
  },
  {
    "arxiv_id": "2505.13573v1",
    "title": "FreeMesh: Boosting Mesh Generation with Coordinates Merging",
    "authors": [
      "Jian Liu",
      "Haohan Weng",
      "Biwen Lei",
      "Xianghui Yang",
      "Zibo Zhao",
      "Zhuo Chen",
      "Song Guo",
      "Tao Han",
      "Chunchao Guo"
    ],
    "abstract": "The next-coordinate prediction paradigm has emerged as the de facto standard in current auto-regressive mesh generation methods. Despite their effectiveness, there is no efficient measurement for the various tokenizers that serialize meshes into sequences. In this paper, we introduce a new metric Per-Token-Mesh-Entropy (PTME) to evaluate the existing mesh tokenizers theoretically without any training. Building upon PTME, we propose a plug-and-play tokenization technique called coordinate merging. It further improves the compression ratios of existing tokenizers by rearranging and merging the most frequent patterns of coordinates. Through experiments on various tokenization methods like MeshXL, MeshAnything V2, and Edgerunner, we further validate the performance of our method. We hope that the proposed PTME and coordinate merging can enhance the existing mesh tokenizers and guide the further development of native mesh generation.",
    "categories": [
      "cs.GR",
      "cs.AI"
    ],
    "primary_category": "cs.GR",
    "comment": "Accepted by ICML 2025, camera-ready version",
    "pdf_url": "https://arxiv.org/pdf/2505.13573v1",
    "published_date": "2025-05-19 13:52:57 UTC",
    "updated_date": "2025-05-19 13:52:57 UTC"
  },
  {
    "arxiv_id": "2505.13123v1",
    "title": "Just Dance with $π$! A Poly-modal Inductor for Weakly-supervised Video Anomaly Detection",
    "authors": [
      "Snehashis Majhi",
      "Giacomo D'Amicantonio",
      "Antitza Dantcheva",
      "Quan Kong",
      "Lorenzo Garattoni",
      "Gianpiero Francesca",
      "Egor Bondarev",
      "Francois Bremond"
    ],
    "abstract": "Weakly-supervised methods for video anomaly detection (VAD) are conventionally based merely on RGB spatio-temporal features, which continues to limit their reliability in real-world scenarios. This is due to the fact that RGB-features are not sufficiently distinctive in setting apart categories such as shoplifting from visually similar events. Therefore, towards robust complex real-world VAD, it is essential to augment RGB spatio-temporal features by additional modalities. Motivated by this, we introduce the Poly-modal Induced framework for VAD: \"PI-VAD\", a novel approach that augments RGB representations by five additional modalities. Specifically, the modalities include sensitivity to fine-grained motion (Pose), three dimensional scene and entity representation (Depth), surrounding objects (Panoptic masks), global motion (optical flow), as well as language cues (VLM). Each modality represents an axis of a polygon, streamlined to add salient cues to RGB. PI-VAD includes two plug-in modules, namely Pseudo-modality Generation module and Cross Modal Induction module, which generate modality-specific prototypical representation and, thereby, induce multi-modal information into RGB cues. These modules operate by performing anomaly-aware auxiliary tasks and necessitate five modality backbones -- only during training. Notably, PI-VAD achieves state-of-the-art accuracy on three prominent VAD datasets encompassing real-world scenarios, without requiring the computational overhead of five modality backbones at inference.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.13123v1",
    "published_date": "2025-05-19 13:51:57 UTC",
    "updated_date": "2025-05-19 13:51:57 UTC"
  },
  {
    "arxiv_id": "2505.13122v2",
    "title": "When majority rules, minority loses: bias amplification of gradient descent",
    "authors": [
      "François Bachoc",
      "Jérôme Bolte",
      "Ryan Boustany",
      "Jean-Michel Loubes"
    ],
    "abstract": "Despite growing empirical evidence of bias amplification in machine learning, its theoretical foundations remain poorly understood. We develop a formal framework for majority-minority learning tasks, showing how standard training can favor majority groups and produce stereotypical predictors that neglect minority-specific features. Assuming population and variance imbalance, our analysis reveals three key findings: (i) the close proximity between ``full-data'' and stereotypical predictors, (ii) the dominance of a region where training the entire model tends to merely learn the majority traits, and (iii) a lower bound on the additional training required. Our results are illustrated through experiments in deep learning for tabular and image classification tasks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.13122v2",
    "published_date": "2025-05-19 13:51:49 UTC",
    "updated_date": "2025-10-20 07:35:36 UTC"
  },
  {
    "arxiv_id": "2505.13118v1",
    "title": "Unveil Sources of Uncertainty: Feature Contribution to Conformal Prediction Intervals",
    "authors": [
      "Marouane Il Idrissi",
      "Agathe Fernandes Machado",
      "Ewen Gallic",
      "Arthur Charpentier"
    ],
    "abstract": "Cooperative game theory methods, notably Shapley values, have significantly enhanced machine learning (ML) interpretability. However, existing explainable AI (XAI) frameworks mainly attribute average model predictions, overlooking predictive uncertainty. This work addresses that gap by proposing a novel, model-agnostic uncertainty attribution (UA) method grounded in conformal prediction (CP). By defining cooperative games where CP interval properties-such as width and bounds-serve as value functions, we systematically attribute predictive uncertainty to input features. Extending beyond the traditional Shapley values, we use the richer class of Harsanyi allocations, and in particular the proportional Shapley values, which distribute attribution proportionally to feature importance. We propose a Monte Carlo approximation method with robust statistical guarantees to address computational feasibility, significantly improving runtime efficiency. Our comprehensive experiments on synthetic benchmarks and real-world datasets demonstrate the practical utility and interpretative depth of our approach. By combining cooperative game theory and conformal prediction, we offer a rigorous, flexible toolkit for understanding and communicating predictive uncertainty in high-stakes ML applications.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.13118v1",
    "published_date": "2025-05-19 13:49:05 UTC",
    "updated_date": "2025-05-19 13:49:05 UTC"
  },
  {
    "arxiv_id": "2505.13116v1",
    "title": "Continuous Fair SMOTE -- Fairness-Aware Stream Learning from Imbalanced Data",
    "authors": [
      "Kathrin Lammers",
      "Valerie Vaquet",
      "Barbara Hammer"
    ],
    "abstract": "As machine learning is increasingly applied in an online fashion to deal with evolving data streams, the fairness of these algorithms is a matter of growing ethical and legal concern. In many use cases, class imbalance in the data also needs to be dealt with to ensure predictive performance. Current fairness-aware stream learners typically attempt to solve these issues through in- or post-processing by focusing on optimizing one specific discrimination metric, addressing class imbalance in a separate processing step. While C-SMOTE is a highly effective model-agnostic pre-processing approach to mitigate class imbalance, as a side effect of this method, algorithmic bias is often introduced.\n  Therefore, we propose CFSMOTE - a fairness-aware, continuous SMOTE variant - as a pre-processing approach to simultaneously address the class imbalance and fairness concerns by employing situation testing and balancing fairness-relevant groups during oversampling. Unlike other fairness-aware stream learners, CFSMOTE is not optimizing for only one specific fairness metric, therefore avoiding potentially problematic trade-offs. Our experiments show significant improvement on several common group fairness metrics in comparison to vanilla C-SMOTE while maintaining competitive performance, also in comparison to other fairness-aware algorithms.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.13116v1",
    "published_date": "2025-05-19 13:46:47 UTC",
    "updated_date": "2025-05-19 13:46:47 UTC"
  },
  {
    "arxiv_id": "2505.13115v1",
    "title": "Benchmarking and Confidence Evaluation of LALMs For Temporal Reasoning",
    "authors": [
      "Debarpan Bhattacharya",
      "Apoorva Kulkarni",
      "Sriram Ganapathy"
    ],
    "abstract": "The popular success of text-based large language models (LLM) has streamlined the attention of the multimodal community to combine other modalities like vision and audio along with text to achieve similar multimodal capabilities. In this quest, large audio language models (LALMs) have to be evaluated on reasoning related tasks which are different from traditional classification or generation tasks. Towards this goal, we propose a novel dataset called temporal reasoning evaluation of audio (TREA).\n  We benchmark open-source LALMs and observe that they are consistently behind human capabilities on the tasks in the TREA dataset. While evaluating LALMs, we also propose an uncertainty metric, which computes the invariance of the model to semantically identical perturbations of the input. Our analysis shows that the accuracy and uncertainty metrics are not necessarily correlated and thus, points to a need for wholesome evaluation of LALMs for high-stakes applications.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted in INTERSPEECH, 2025, Rotterdam, The Netherlands",
    "pdf_url": "https://arxiv.org/pdf/2505.13115v1",
    "published_date": "2025-05-19 13:46:35 UTC",
    "updated_date": "2025-05-19 13:46:35 UTC"
  },
  {
    "arxiv_id": "2506.08020v1",
    "title": "Bi-level Unbalanced Optimal Transport for Partial Domain Adaptation",
    "authors": [
      "Zi-Ying Chen",
      "Chuan-Xian Ren",
      "Hong Yan"
    ],
    "abstract": "Partial domain adaptation (PDA) problem requires aligning cross-domain samples while distinguishing the outlier classes for accurate knowledge transfer. The widely used weighting framework tries to address the outlier classes by introducing the reweighed source domain with a similar label distribution to the target domain. However, the empirical modeling of weights can only characterize the sample-wise relations, which leads to insufficient exploration of cluster structures, and the weights could be sensitive to the inaccurate prediction and cause confusion on the outlier classes. To tackle these issues, we propose a Bi-level Unbalanced Optimal Transport (BUOT) model to simultaneously characterize the sample-wise and class-wise relations in a unified transport framework. Specifically, a cooperation mechanism between sample-level and class-level transport is introduced, where the sample-level transport provides essential structure information for the class-level knowledge transfer, while the class-level transport supplies discriminative information for the outlier identification. The bi-level transport plan provides guidance for the alignment process. By incorporating the label-aware transport cost, the local transport structure is ensured and a fast computation formulation is derived to improve the efficiency. Extensive experiments on benchmark datasets validate the competitiveness of BUOT.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.08020v1",
    "published_date": "2025-05-19 13:40:40 UTC",
    "updated_date": "2025-05-19 13:40:40 UTC"
  },
  {
    "arxiv_id": "2505.13109v3",
    "title": "FreeKV: Boosting KV Cache Retrieval for Efficient LLM Inference",
    "authors": [
      "Guangda Liu",
      "Chengwei Li",
      "Zhenyu Ning",
      "Jing Lin",
      "Yiwu Yao",
      "Danning Ke",
      "Minyi Guo",
      "Jieru Zhao"
    ],
    "abstract": "Large language models (LLMs) have been widely deployed with rapidly expanding context windows to support increasingly demanding applications. However, long contexts pose significant deployment challenges, primarily due to the KV cache whose size grows proportionally with context length. While KV cache compression methods are proposed to address this issue, KV dropping methods incur considerable accuracy loss, and KV retrieval methods suffer from significant efficiency bottlenecks. We propose FreeKV, an algorithm-system co-optimization framework to enhance KV retrieval efficiency while preserving accuracy. On the algorithm side, FreeKV introduces speculative retrieval to shift the KV selection and recall processes out of the critical path, combined with fine-grained correction to ensure accuracy. On the system side, FreeKV employs hybrid KV layouts across CPU and GPU memory to eliminate fragmented data transfers, and leverages double-buffered streamed recall to further improve efficiency. Experiments demonstrate that FreeKV achieves near-lossless accuracy across various scenarios and models, delivering up to 13$\\times$ speedup compared to SOTA KV retrieval methods.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.13109v3",
    "published_date": "2025-05-19 13:36:45 UTC",
    "updated_date": "2025-12-16 04:58:49 UTC"
  },
  {
    "arxiv_id": "2505.13102v2",
    "title": "Lightweight and Interpretable Transformer via Mixed Graph Algorithm Unrolling for Traffic Forecast",
    "authors": [
      "Ji Qi",
      "Tam Thuc Do",
      "Mingxiao Liu",
      "Zhuoshi Pan",
      "Yuzhe Li",
      "Gene Cheung",
      "H. Vicky Zhao"
    ],
    "abstract": "Unlike conventional \"black-box\" transformers with classical self-attention mechanism, we build a lightweight and interpretable transformer-like neural net by unrolling a mixed-graph-based optimization algorithm to forecast traffic with spatial and temporal dimensions. We construct two graphs: an undirected graph $\\mathcal{G}^u$ capturing spatial correlations across geography, and a directed graph $\\mathcal{G}^d$ capturing sequential relationships over time. We predict future samples of signal $\\mathbf{x}$, assuming it is \"smooth\" with respect to both $\\mathcal{G}^u$ and $\\mathcal{G}^d$, where we design new $\\ell_2$ and $\\ell_1$-norm variational terms to quantify and promote signal smoothness (low-frequency reconstruction) on a directed graph. We design an iterative algorithm based on alternating direction method of multipliers (ADMM), and unroll it into a feed-forward network for data-driven parameter learning. We insert graph learning modules for $\\mathcal{G}^u$ and $\\mathcal{G}^d$ that play the role of self-attention. Experiments show that our unrolled networks achieve competitive traffic forecast performance as state-of-the-art prediction schemes, while reducing parameter counts drastically. Our code is available in https://github.com/SingularityUndefined/Unrolling-GSP-STForecast .",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "comment": "23 pages, 4 figures, 8 tables",
    "pdf_url": "https://arxiv.org/pdf/2505.13102v2",
    "published_date": "2025-05-19 13:32:34 UTC",
    "updated_date": "2025-10-12 04:45:53 UTC"
  },
  {
    "arxiv_id": "2505.13101v1",
    "title": "ARIW-Framework: Adaptive Robust Iterative Watermarking Framework",
    "authors": [
      "Shaowu Wu",
      "Liting Zeng",
      "Wei Lu",
      "Xiangyang Luo"
    ],
    "abstract": "With the rapid rise of large models, copyright protection for generated image content has become a critical security challenge. Although deep learning watermarking techniques offer an effective solution for digital image copyright protection, they still face limitations in terms of visual quality, robustness and generalization. To address these issues, this paper proposes an adaptive robust iterative watermarking framework (ARIW-Framework) that achieves high-quality watermarked images while maintaining exceptional robustness and generalization performance. Specifically, we introduce an iterative approach to optimize the encoder for generating robust residuals. The encoder incorporates noise layers and a decoder to compute robustness weights for residuals under various noise attacks. By employing a parallel optimization strategy, the framework enhances robustness against multiple types of noise attacks. Furthermore, we leverage image gradients to determine the embedding strength at each pixel location, significantly improving the visual quality of the watermarked images. Extensive experiments demonstrate that the proposed method achieves superior visual quality while exhibiting remarkable robustness and generalization against noise attacks.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "10 pages, 4 figures",
    "pdf_url": "https://arxiv.org/pdf/2505.13101v1",
    "published_date": "2025-05-19 13:31:48 UTC",
    "updated_date": "2025-05-19 13:31:48 UTC"
  },
  {
    "arxiv_id": "2505.13098v1",
    "title": "LLM-KG-Bench 3.0: A Compass for SemanticTechnology Capabilities in the Ocean of LLMs",
    "authors": [
      "Lars-Peter Meyer",
      "Johannes Frey",
      "Desiree Heim",
      "Felix Brei",
      "Claus Stadler",
      "Kurt Junghanns",
      "Michael Martin"
    ],
    "abstract": "Current Large Language Models (LLMs) can assist developing program code beside many other things, but can they support working with Knowledge Graphs (KGs) as well? Which LLM is offering the best capabilities in the field of Semantic Web and Knowledge Graph Engineering (KGE)? Is this possible to determine without checking many answers manually? The LLM-KG-Bench framework in Version 3.0 is designed to answer these questions. It consists of an extensible set of tasks for automated evaluation of LLM answers and covers different aspects of working with semantic technologies. In this paper the LLM-KG-Bench framework is presented in Version 3 along with a dataset of prompts, answers and evaluations generated with it and several state-of-the-art LLMs. Significant enhancements have been made to the framework since its initial release, including an updated task API that offers greater flexibility in handling evaluation tasks, revised tasks, and extended support for various open models through the vllm library, among other improvements. A comprehensive dataset has been generated using more than 30 contemporary open and proprietary LLMs, enabling the creation of exemplary model cards that demonstrate the models' capabilities in working with RDF and SPARQL, as well as comparing their performance on Turtle and JSON-LD RDF serialization tasks.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.DB"
    ],
    "primary_category": "cs.AI",
    "comment": "Peer reviewed publication at ESWC 2025 Resources Track",
    "pdf_url": "https://arxiv.org/pdf/2505.13098v1",
    "published_date": "2025-05-19 13:29:27 UTC",
    "updated_date": "2025-05-19 13:29:27 UTC"
  },
  {
    "arxiv_id": "2505.13572v3",
    "title": "Q${}^2$Forge: Minting Competency Questions and SPARQL Queries for Question-Answering Over Knowledge Graphs",
    "authors": [
      "Yousouf Taghzouti",
      "Franck Michel",
      "Tao Jiang",
      "Louis-Félix Nothias",
      "Fabien Gandon"
    ],
    "abstract": "The SPARQL query language is the standard method to access knowledge graphs (KGs). However, formulating SPARQL queries is a significant challenge for non-expert users, and remains time-consuming for the experienced ones. Best practices recommend to document KGs with competency questions and example queries to contextualise the knowledge they contain and illustrate their potential applications. In practice, however, this is either not the case or the examples are provided in limited numbers. Large Language Models (LLMs) are being used in conversational agents and are proving to be an attractive solution with a wide range of applications, from simple question-answering about common knowledge to generating code in a targeted programming language. However, training and testing these models to produce high quality SPARQL queries from natural language questions requires substantial datasets of question-query pairs. In this paper, we present Q${}^2$Forge that addresses the challenge of generating new competency questions for a KG and corresponding SPARQL queries. It iteratively validates those queries with human feedback and LLM as a judge. Q${}^2$Forge is open source, generic, extensible and modular, meaning that the different modules of the application (CQ generation, query generation and query refinement) can be used separately, as an integrated pipeline, or replaced by alternative services. The result is a complete pipeline from competency question formulation to query evaluation, supporting the creation of reference query sets for any target KG.",
    "categories": [
      "cs.DB",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.DB",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.13572v3",
    "published_date": "2025-05-19 13:26:51 UTC",
    "updated_date": "2025-12-12 09:31:39 UTC"
  },
  {
    "arxiv_id": "2505.13094v1",
    "title": "Time-Frequency-Based Attention Cache Memory Model for Real-Time Speech Separation",
    "authors": [
      "Guo Chen",
      "Kai Li",
      "Runxuan Yang",
      "Xiaolin Hu"
    ],
    "abstract": "Existing causal speech separation models often underperform compared to non-causal models due to difficulties in retaining historical information. To address this, we propose the Time-Frequency Attention Cache Memory (TFACM) model, which effectively captures spatio-temporal relationships through an attention mechanism and cache memory (CM) for historical information storage. In TFACM, an LSTM layer captures frequency-relative positions, while causal modeling is applied to the time dimension using local and global representations. The CM module stores past information, and the causal attention refinement (CAR) module further enhances time-based feature representations for finer granularity. Experimental results showed that TFACM achieveed comparable performance to the SOTA TF-GridNet-Causal model, with significantly lower complexity and fewer trainable parameters. For more details, visit the project page: https://cslikai.cn/TFACM/.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.13094v1",
    "published_date": "2025-05-19 13:25:51 UTC",
    "updated_date": "2025-05-19 13:25:51 UTC"
  },
  {
    "arxiv_id": "2505.13087v1",
    "title": "Graph Alignment for Benchmarking Graph Neural Networks and Learning Positional Encodings",
    "authors": [
      "Adrien Lagesse",
      "Marc Lelarge"
    ],
    "abstract": "We propose a novel benchmarking methodology for graph neural networks (GNNs) based on the graph alignment problem, a combinatorial optimization task that generalizes graph isomorphism by aligning two unlabeled graphs to maximize overlapping edges. We frame this problem as a self-supervised learning task and present several methods to generate graph alignment datasets using synthetic random graphs and real-world graph datasets from multiple domains. For a given graph dataset, we generate a family of graph alignment datasets with increasing difficulty, allowing us to rank the performance of various architectures. Our experiments indicate that anisotropic graph neural networks outperform standard convolutional architectures. To further demonstrate the utility of the graph alignment task, we show its effectiveness for unsupervised GNN pre-training, where the learned node embeddings outperform other positional encodings on three molecular regression tasks and achieve state-of-the-art results on the PCQM4Mv2 dataset with significantly fewer parameters. To support reproducibility and further research, we provide an open-source Python package to generate graph alignment datasets and benchmark new GNN architectures.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.13087v1",
    "published_date": "2025-05-19 13:22:17 UTC",
    "updated_date": "2025-05-19 13:22:17 UTC"
  },
  {
    "arxiv_id": "2505.13082v1",
    "title": "MultiActor-Audiobook: Zero-Shot Audiobook Generation with Faces and Voices of Multiple Speakers",
    "authors": [
      "Kyeongman Park",
      "Seongho Joo",
      "Kyomin Jung"
    ],
    "abstract": "We introduce MultiActor-Audiobook, a zero-shot approach for generating audiobooks that automatically produces consistent, expressive, and speaker-appropriate prosody, including intonation and emotion. Previous audiobook systems have several limitations: they require users to manually configure the speaker's prosody, read each sentence with a monotonic tone compared to voice actors, or rely on costly training. However, our MultiActor-Audiobook addresses these issues by introducing two novel processes: (1) MSP (**Multimodal Speaker Persona Generation**) and (2) LSI (**LLM-based Script Instruction Generation**). With these two processes, MultiActor-Audiobook can generate more emotionally expressive audiobooks with a consistent speaker prosody without additional training. We compare our system with commercial products, through human and MLLM evaluations, achieving competitive results. Furthermore, we demonstrate the effectiveness of MSP and LSI through ablation studies.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.13082v1",
    "published_date": "2025-05-19 13:13:46 UTC",
    "updated_date": "2025-05-19 13:13:46 UTC"
  },
  {
    "arxiv_id": "2505.13079v1",
    "title": "Cross-modal Knowledge Transfer Learning as Graph Matching Based on Optimal Transport for ASR",
    "authors": [
      "Xugang Lu",
      "Peng Shen",
      "Yu Tsao",
      "Hisashi Kawai"
    ],
    "abstract": "Transferring linguistic knowledge from a pretrained language model (PLM) to acoustic feature learning has proven effective in enhancing end-to-end automatic speech recognition (E2E-ASR). However, aligning representations between linguistic and acoustic modalities remains a challenge due to inherent modality gaps. Optimal transport (OT) has shown promise in mitigating these gaps by minimizing the Wasserstein distance (WD) between linguistic and acoustic feature distributions. However, previous OT-based methods overlook structural relationships, treating feature vectors as unordered sets. To address this, we propose Graph Matching Optimal Transport (GM-OT), which models linguistic and acoustic sequences as structured graphs. Nodes represent feature embeddings, while edges capture temporal and sequential relationships. GM-OT minimizes both WD (between nodes) and Gromov-Wasserstein distance (GWD) (between edges), leading to a fused Gromov-Wasserstein distance (FGWD) formulation. This enables structured alignment and more efficient knowledge transfer compared to existing OT-based approaches. Theoretical analysis further shows that prior OT-based methods in linguistic knowledge transfer can be viewed as a special case within our GM-OT framework. We evaluate GM-OT on Mandarin ASR using a CTC-based E2E-ASR system with a PLM for knowledge transfer. Experimental results demonstrate significant performance gains over state-of-the-art models, validating the effectiveness of our approach.",
    "categories": [
      "eess.AS",
      "cs.AI"
    ],
    "primary_category": "eess.AS",
    "comment": "To appear in Interspeech 2025",
    "pdf_url": "https://arxiv.org/pdf/2505.13079v1",
    "published_date": "2025-05-19 13:13:18 UTC",
    "updated_date": "2025-05-19 13:13:18 UTC"
  },
  {
    "arxiv_id": "2505.13077v2",
    "title": "Advancing Sequential Numerical Prediction in Autoregressive Models",
    "authors": [
      "Xiang Fei",
      "Jinghui Lu",
      "Qi Sun",
      "Hao Feng",
      "Yanjie Wang",
      "Wei Shi",
      "An-Lan Wang",
      "Jingqun Tang",
      "Can Huang"
    ],
    "abstract": "Autoregressive models have become the de facto choice for sequence generation tasks, but standard approaches treat digits as independent tokens and apply cross-entropy loss, overlooking the coherent structure of numerical sequences. This paper introduces Numerical Token Integrity Loss (NTIL) to address this gap. NTIL operates at two levels: (1) token-level, where it extends the Earth Mover's Distance (EMD) to preserve ordinal relationships between numerical values, and (2) sequence-level, where it penalizes the overall discrepancy between the predicted and actual sequences. This dual approach improves numerical prediction and integrates effectively with LLMs/MLLMs. Extensive experiments show significant performance improvements with NTIL.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to ACL 2025 Main Conference",
    "pdf_url": "https://arxiv.org/pdf/2505.13077v2",
    "published_date": "2025-05-19 13:11:28 UTC",
    "updated_date": "2025-05-28 10:48:01 UTC"
  },
  {
    "arxiv_id": "2505.13076v1",
    "title": "The Hidden Dangers of Browsing AI Agents",
    "authors": [
      "Mykyta Mudryi",
      "Markiyan Chaklosh",
      "Grzegorz Wójcik"
    ],
    "abstract": "Autonomous browsing agents powered by large language models (LLMs) are increasingly used to automate web-based tasks. However, their reliance on dynamic content, tool execution, and user-provided data exposes them to a broad attack surface. This paper presents a comprehensive security evaluation of such agents, focusing on systemic vulnerabilities across multiple architectural layers. Our work outlines the first end-to-end threat model for browsing agents and provides actionable guidance for securing their deployment in real-world environments. To address discovered threats, we propose a defense in depth strategy incorporating input sanitization, planner executor isolation, formal analyzers, and session safeguards. These measures protect against both initial access and post exploitation attack vectors. Through a white box analysis of a popular open source project, Browser Use, we demonstrate how untrusted web content can hijack agent behavior and lead to critical security breaches. Our findings include prompt injection, domain validation bypass, and credential exfiltration, evidenced by a disclosed CVE and a working proof of concept exploit.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.13076v1",
    "published_date": "2025-05-19 13:10:29 UTC",
    "updated_date": "2025-05-19 13:10:29 UTC"
  },
  {
    "arxiv_id": "2505.13073v1",
    "title": "Structure-Aware Corpus Construction and User-Perception-Aligned Metrics for Large-Language-Model Code Completion",
    "authors": [
      "Dengfeng Liu",
      "Jucai Zhai",
      "Xiaoguang Jiang",
      "Ziqun Li",
      "Qianjin Yu",
      "Feng Liu",
      "Rui Ye",
      "Huang Liu",
      "Zhiguo Yang",
      "Yongsheng Du",
      "Fang Tan"
    ],
    "abstract": "Code completion technology based on large language model has significantly improved the development efficiency of programmers. However, in practical applications, there remains a gap between current commonly used code completion evaluation metrics and users' actual perception. To address this issue, we propose two evaluation metrics for code completion tasks--LCP and ROUGE-LCP, from the perspective of probabilistic modeling. Furthermore, to tackle the lack of effective structural semantic modeling and cross-module dependency information in LLMs for repository-level code completion scenarios, we propose a data processing method based on a Structure-Preserving and Semantically-Reordered Code Graph (SPSR-Graph). Through theoretical analysis and experimental validation, we demonstrate the superiority of the proposed evaluation metrics in terms of user perception consistency, as well as the effectiveness of the data processing method in enhancing model performance.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "14 pages,8 figures",
    "pdf_url": "https://arxiv.org/pdf/2505.13073v1",
    "published_date": "2025-05-19 13:09:32 UTC",
    "updated_date": "2025-05-19 13:09:32 UTC"
  },
  {
    "arxiv_id": "2505.13053v1",
    "title": "SNAPE-PM: Building and Utilizing Dynamic Partner Models for Adaptive Explanation Generation",
    "authors": [
      "Amelie S. Robrecht",
      "Christoph R. Kowalski",
      "Stefan Kopp"
    ],
    "abstract": "Adapting to the addressee is crucial for successful explanations, yet poses significant challenges for dialogsystems. We adopt the approach of treating explanation generation as a non-stationary decision process, where the optimal strategy varies according to changing beliefs about the explainee and the interaction context. In this paper we address the questions of (1) how to track the interaction context and the relevant listener features in a formally defined computational partner model, and (2) how to utilize this model in the dynamically adjusted, rational decision process that determines the currently best explanation strategy. We propose a Bayesian inference-based approach to continuously update the partner model based on user feedback, and a non-stationary Markov Decision Process to adjust decision-making based on the partner model values. We evaluate an implementation of this framework with five simulated interlocutors, demonstrating its effectiveness in adapting to different partners with constant and even changing feedback behavior. The results show high adaptivity with distinct explanation strategies emerging for different partners, highlighting the potential of our approach to improve explainable AI systems and dialogsystems in general.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "currently under review at Frontiers in Communication",
    "pdf_url": "https://arxiv.org/pdf/2505.13053v1",
    "published_date": "2025-05-19 12:42:23 UTC",
    "updated_date": "2025-05-19 12:42:23 UTC"
  },
  {
    "arxiv_id": "2505.13044v1",
    "title": "CAIM: Development and Evaluation of a Cognitive AI Memory Framework for Long-Term Interaction with Intelligent Agents",
    "authors": [
      "Rebecca Westhäußer",
      "Frederik Berenz",
      "Wolfgang Minker",
      "Sebastian Zepf"
    ],
    "abstract": "Large language models (LLMs) have advanced the field of artificial intelligence (AI) and are a powerful enabler for interactive systems. However, they still face challenges in long-term interactions that require adaptation towards the user as well as contextual knowledge and understanding of the ever-changing environment. To overcome these challenges, holistic memory modeling is required to efficiently retrieve and store relevant information across interaction sessions for suitable responses. Cognitive AI, which aims to simulate the human thought process in a computerized model, highlights interesting aspects, such as thoughts, memory mechanisms, and decision-making, that can contribute towards improved memory modeling for LLMs. Inspired by these cognitive AI principles, we propose our memory framework CAIM. CAIM consists of three modules: 1.) The Memory Controller as the central decision unit; 2.) the Memory Retrieval, which filters relevant data for interaction upon request; and 3.) the Post-Thinking, which maintains the memory storage. We compare CAIM against existing approaches, focusing on metrics such as retrieval accuracy, response correctness, contextual coherence, and memory storage. The results demonstrate that CAIM outperforms baseline frameworks across different metrics, highlighting its context-awareness and potential to improve long-term human-AI interactions.",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.13044v1",
    "published_date": "2025-05-19 12:33:52 UTC",
    "updated_date": "2025-05-19 12:33:52 UTC"
  },
  {
    "arxiv_id": "2505.13043v2",
    "title": "A Generalized Label Shift Perspective for Cross-Domain Gaze Estimation",
    "authors": [
      "Hao-Ran Yang",
      "Xiaohui Chen",
      "Chuan-Xian Ren"
    ],
    "abstract": "Aiming to generalize the well-trained gaze estimation model to new target domains, Cross-domain Gaze Estimation (CDGE) is developed for real-world application scenarios. Existing CDGE methods typically extract the domain-invariant features to mitigate domain shift in feature space, which is proved insufficient by Generalized Label Shift (GLS) theory. In this paper, we introduce a novel GLS perspective to CDGE and modelize the cross-domain problem by label and conditional shift problem. A GLS correction framework is presented and a feasible realization is proposed, in which a importance reweighting strategy based on truncated Gaussian distribution is introduced to overcome the continuity challenges in label shift correction. To embed the reweighted source distribution to conditional invariant learning, we further derive a probability-aware estimation of conditional operator discrepancy. Extensive experiments on standard CDGE tasks with different backbone models validate the superior generalization capability across domain and applicability on various models of proposed method.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "NeurIPS 2025",
    "pdf_url": "https://arxiv.org/pdf/2505.13043v2",
    "published_date": "2025-05-19 12:33:52 UTC",
    "updated_date": "2025-10-28 08:36:12 UTC"
  },
  {
    "arxiv_id": "2505.13036v1",
    "title": "KIT's Offline Speech Translation and Instruction Following Submission for IWSLT 2025",
    "authors": [
      "Sai Koneru",
      "Maike Züfle",
      "Thai-Binh Nguyen",
      "Seymanur Akti",
      "Jan Niehues",
      "Alexander Waibel"
    ],
    "abstract": "The scope of the International Workshop on Spoken Language Translation (IWSLT) has recently broadened beyond traditional Speech Translation (ST) to encompass a wider array of tasks, including Speech Question Answering and Summarization. This shift is partly driven by the growing capabilities of modern systems, particularly with the success of Large Language Models (LLMs). In this paper, we present the Karlsruhe Institute of Technology's submissions for the Offline ST and Instruction Following (IF) tracks, where we leverage LLMs to enhance performance across all tasks. For the Offline ST track, we propose a pipeline that employs multiple automatic speech recognition systems, whose outputs are fused using an LLM with document-level context. This is followed by a two-step translation process, incorporating additional refinement step to improve translation quality. For the IF track, we develop an end-to-end model that integrates a speech encoder with an LLM to perform a wide range of instruction-following tasks. We complement it with a final document-level refinement stage to further enhance output quality by using contextual information.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.13036v1",
    "published_date": "2025-05-19 12:21:29 UTC",
    "updated_date": "2025-05-19 12:21:29 UTC"
  },
  {
    "arxiv_id": "2505.13033v2",
    "title": "TSPulse: Dual Space Tiny Pre-Trained Models for Rapid Time-Series Analysis",
    "authors": [
      "Vijay Ekambaram",
      "Subodh Kumar",
      "Arindam Jati",
      "Sumanta Mukherjee",
      "Tomoya Sakai",
      "Pankaj Dayama",
      "Wesley M. Gifford",
      "Jayant Kalagnanam"
    ],
    "abstract": "The rise of time-series pre-trained models has advanced temporal representation learning, but current state-of-the-art models are often large-scale, requiring substantial compute. We introduce TSPulse, ultra-compact time-series pre-trained models with only 1M parameters, specialized to perform strongly across classification, anomaly detection, imputation, and retrieval tasks. TSPulse introduces innovations at both the architecture and task levels. At the architecture level, it employs a dual-space masked reconstruction, learning from both time and frequency domains to capture complementary signals. This is further enhanced by a dual-embedding disentanglement, generating both detailed embeddings for fine-grained analysis and high-level semantic embeddings for broader task understanding. Notably, TSPulse's semantic embeddings are robust to shifts in time, magnitude, and noise, which is important for robust retrieval. At the task level, TSPulse incorporates TSLens, a fine-tuning component enabling task-specific feature attention. It also introduces a multi-head triangulation technique that correlates deviations from multiple prediction heads, enhancing anomaly detection by fusing complementary model outputs. Additionally, a hybrid mask pretraining is proposed to improves zero-shot imputation by reducing pre-training bias. These architecture and task innovations collectively contribute to TSPulse's significant performance gains: 5-16% on the UEA classification benchmarks, +20% on the TSB-AD anomaly detection leaderboard, +50% in zero-shot imputation, and +25% in time-series retrieval. Remarkably, these results are achieved with just 1M parameters (10-100X smaller than existing SOTA models) and allow GPU-free inference, setting a new standard for efficient time-series pre-trained models. The models can be accessed from https://huggingface.co/ibm-granite/granite-timeseries-tspulse-r1",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.13033v2",
    "published_date": "2025-05-19 12:18:53 UTC",
    "updated_date": "2025-06-25 04:59:41 UTC"
  },
  {
    "arxiv_id": "2505.13031v2",
    "title": "MindOmni: Unleashing Reasoning Generation in Vision Language Models with RGPO",
    "authors": [
      "Yicheng Xiao",
      "Lin Song",
      "Yukang Chen",
      "Yingmin Luo",
      "Yuxin Chen",
      "Yukang Gan",
      "Wei Huang",
      "Xiu Li",
      "Xiaojuan Qi",
      "Ying Shan"
    ],
    "abstract": "Recent text-to-image systems face limitations in handling multimodal inputs and complex reasoning tasks. We introduce MindOmni, a unified multimodal large language model that addresses these challenges by incorporating reasoning generation through reinforcement learning. MindOmni leverages a three-phase training strategy: i) design of a unified vision language model with a decoder-only diffusion module, ii) supervised fine-tuning with Chain-of-Thought (CoT) instruction data, and iii) our proposed Reasoning Generation Policy Optimization (RGPO) algorithm, utilizing multimodal feedback to effectively guide policy updates. Experimental results demonstrate that MindOmni outperforms existing models, achieving impressive performance on both understanding and generation benchmarks, meanwhile showcasing advanced fine-grained reasoning generation capabilities, especially with mathematical reasoning instruction. All codes will be made public at https://github.com/TencentARC/MindOmni",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Code: https://github.com/TencentARC/MindOmni",
    "pdf_url": "https://arxiv.org/pdf/2505.13031v2",
    "published_date": "2025-05-19 12:17:04 UTC",
    "updated_date": "2025-06-11 15:44:25 UTC"
  },
  {
    "arxiv_id": "2505.13028v2",
    "title": "Evaluating the efficacy of LLM Safety Solutions : The Palit Benchmark Dataset",
    "authors": [
      "Sayon Palit",
      "Daniel Woods"
    ],
    "abstract": "Large Language Models (LLMs) are increasingly integrated into critical systems in industries like healthcare and finance. Users can often submit queries to LLM-enabled chatbots, some of which can enrich responses with information retrieved from internal databases storing sensitive data. This gives rise to a range of attacks in which a user submits a malicious query and the LLM-system outputs a response that creates harm to the owner, such as leaking internal data or creating legal liability by harming a third-party. While security tools are being developed to counter these threats, there is little formal evaluation of their effectiveness and usability. This study addresses this gap by conducting a thorough comparative analysis of LLM security tools. We identified 13 solutions (9 closed-source, 4 open-source), but only 7 were evaluated due to a lack of participation by proprietary model owners.To evaluate, we built a benchmark dataset of malicious prompts, and evaluate these tools performance against a baseline LLM model (ChatGPT-3.5-Turbo). Our results show that the baseline model has too many false positives to be used for this task. Lakera Guard and ProtectAI LLM Guard emerged as the best overall tools showcasing the tradeoff between usability and performance. The study concluded with recommendations for greater transparency among closed source providers, improved context-aware detections, enhanced open-source engagement, increased user awareness, and the adoption of more representative performance metrics.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.13028v2",
    "published_date": "2025-05-19 12:12:00 UTC",
    "updated_date": "2025-05-20 07:34:53 UTC"
  },
  {
    "arxiv_id": "2505.13026v3",
    "title": "Step-wise Adaptive Integration of Supervised Fine-tuning and Reinforcement Learning for Task-Specific LLMs",
    "authors": [
      "Jack Chen",
      "Fazhong Liu",
      "Naruto Liu",
      "Yuhan Luo",
      "Erqu Qin",
      "Harry Zheng",
      "Tian Dong",
      "Haojin Zhu",
      "Yan Meng",
      "Xiao Wang"
    ],
    "abstract": "Large language models (LLMs) excel at mathematical reasoning and logical problem-solving. The current popular training paradigms primarily use supervised fine-tuning (SFT) and reinforcement learning (RL) to enhance the models' reasoning abilities. However, when using SFT or RL alone, there are respective challenges: SFT may suffer from overfitting, while RL is prone to mode collapse. The state-of-the-art methods have proposed hybrid training schemes. However, static switching faces challenges such as poor generalization across different tasks and high dependence on data quality. In response to these challenges, inspired by the curriculum learning-quiz mechanism in human reasoning cultivation, We propose SASR, a step-wise adaptive hybrid training framework that theoretically unifies SFT and RL and dynamically balances the two throughout optimization. SASR uses SFT for initial warm-up to establish basic reasoning skills, and then uses an adaptive dynamic adjustment algorithm based on gradient norm and divergence relative to the original distribution to seamlessly integrate SFT with the online RL method GRPO. By monitoring the training status of LLMs and adjusting the training process in sequence, SASR ensures a smooth transition between training schemes, maintaining core reasoning abilities while exploring different paths. Experimental results demonstrate that SASR outperforms SFT, RL, and static hybrid training methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.13026v3",
    "published_date": "2025-05-19 12:10:17 UTC",
    "updated_date": "2025-08-04 07:29:42 UTC"
  },
  {
    "arxiv_id": "2505.13025v1",
    "title": "LiBOG: Lifelong Learning for Black-Box Optimizer Generation",
    "authors": [
      "Jiyuan Pei",
      "Yi Mei",
      "Jialin Liu",
      "Mengjie Zhang"
    ],
    "abstract": "Meta-Black-Box Optimization (MetaBBO) garners attention due to its success in automating the configuration and generation of black-box optimizers, significantly reducing the human effort required for optimizer design and discovering optimizers with higher performance than classic human-designed optimizers. However, existing MetaBBO methods conduct one-off training under the assumption that a stationary problem distribution with extensive and representative training problem samples is pre-available. This assumption is often impractical in real-world scenarios, where diverse problems following shifting distribution continually arise. Consequently, there is a pressing need for methods that can continuously learn from new problems encountered on-the-fly and progressively enhance their capabilities. In this work, we explore a novel paradigm of lifelong learning in MetaBBO and introduce LiBOG, a novel approach designed to learn from sequentially encountered problems and generate high-performance optimizers for Black-Box Optimization (BBO). LiBOG consolidates knowledge both across tasks and within tasks to mitigate catastrophic forgetting. Extensive experiments demonstrate LiBOG's effectiveness in learning to generate high-performance optimizers in a lifelong learning manner, addressing catastrophic forgetting while maintaining plasticity to learn new tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at IJCAI 2025. To appear",
    "pdf_url": "https://arxiv.org/pdf/2505.13025v1",
    "published_date": "2025-05-19 12:09:25 UTC",
    "updated_date": "2025-05-19 12:09:25 UTC"
  },
  {
    "arxiv_id": "2505.13023v3",
    "title": "Anti-Inpainting: A Proactive Defense Approach against Malicious Diffusion-based Inpainters under Unknown Conditions",
    "authors": [
      "Yimao Guo",
      "Zuomin Qu",
      "Wei Lu",
      "Xiangyang Luo"
    ],
    "abstract": "With the increasing prevalence of diffusion-based malicious image manipulation, existing proactive defense methods struggle to safeguard images against tampering under unknown conditions. To address this, we propose Anti-Inpainting, a proactive defense approach that achieves protection comprising three novel modules. First, we introduce a multi-level deep feature extractor to obtain intricate features from the diffusion denoising process, enhancing protective effectiveness. Second, we design a multi-scale, semantic-preserving data augmentation technique to enhance the transferability of adversarial perturbations across unknown conditions. Finally, we propose a selection-based distribution deviation optimization strategy to bolster protection against manipulations guided by diverse random seeds. Extensive experiments on InpaintGuardBench and CelebA-HQ demonstrate that Anti-Inpainting effectively defends against diffusion-based inpainters under unknown conditions. Additionally, our approach demonstrates robustness against various image purification methods and transferability across different diffusion model versions.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.13023v3",
    "published_date": "2025-05-19 12:07:29 UTC",
    "updated_date": "2025-08-02 11:16:27 UTC"
  },
  {
    "arxiv_id": "2505.13011v2",
    "title": "Unveiling and Steering Connectome Organization with Interpretable Latent Variables",
    "authors": [
      "Yubin Li",
      "Xingyu Liu",
      "Guozhang Chen"
    ],
    "abstract": "The brain's intricate connectome, a blueprint for its function, presents immense complexity, yet it arises from a compact genetic code, hinting at underlying low-dimensional organizational principles. This work bridges connectomics and representation learning to uncover these principles. We propose a framework that combines subgraph extraction from the Drosophila connectome, FlyWire, with a generative model to derive interpretable low-dimensional representations of neural circuitry. Crucially, an explainability module links these latent dimensions to specific structural features, offering insights into their functional relevance. We validate our approach by demonstrating effective graph reconstruction and, significantly, the ability to manipulate these latent codes to controllably generate connectome subgraphs with predefined properties. This research offers a novel tool for understanding brain architecture and a potential avenue for designing bio-inspired artificial neural networks.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.13011v2",
    "published_date": "2025-05-19 11:54:40 UTC",
    "updated_date": "2025-05-27 04:10:37 UTC"
  },
  {
    "arxiv_id": "2505.13010v2",
    "title": "To Bias or Not to Bias: Detecting bias in News with bias-detector",
    "authors": [
      "Himel Ghosh",
      "Ahmed Mosharafa",
      "Georg Groh"
    ],
    "abstract": "Media bias detection is a critical task in ensuring fair and balanced information dissemination, yet it remains challenging due to the subjectivity of bias and the scarcity of high-quality annotated data. In this work, we perform sentence-level bias classification by fine-tuning a RoBERTa-based model on the expert-annotated BABE dataset. Using McNemar's test and the 5x2 cross-validation paired t-test, we show statistically significant improvements in performance when comparing our model to a domain-adaptively pre-trained DA-RoBERTa baseline. Furthermore, attention-based analysis shows that our model avoids common pitfalls like oversensitivity to politically charged terms and instead attends more meaningfully to contextually relevant tokens. For a comprehensive examination of media bias, we present a pipeline that combines our model with an already-existing bias-type classifier. Our method exhibits good generalization and interpretability, despite being constrained by sentence-level analysis and dataset size because of a lack of larger and more advanced bias corpora. We talk about context-aware modeling, bias neutralization, and advanced bias type classification as potential future directions. Our findings contribute to building more robust, explainable, and socially responsible NLP systems for media bias detection.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "7 pages, 5 figures, 2 tables",
    "pdf_url": "https://arxiv.org/pdf/2505.13010v2",
    "published_date": "2025-05-19 11:54:39 UTC",
    "updated_date": "2025-12-26 23:06:48 UTC"
  },
  {
    "arxiv_id": "2505.12996v1",
    "title": "ExTrans: Multilingual Deep Reasoning Translation via Exemplar-Enhanced Reinforcement Learning",
    "authors": [
      "Jiaan Wang",
      "Fandong Meng",
      "Jie Zhou"
    ],
    "abstract": "In recent years, the emergence of large reasoning models (LRMs), such as OpenAI-o1 and DeepSeek-R1, has shown impressive capabilities in complex problems, e.g., mathematics and coding. Some pioneering studies attempt to bring the success of LRMs in neural machine translation (MT). They try to build LRMs with deep reasoning MT ability via reinforcement learning (RL). Despite some progress that has been made, these attempts generally focus on several high-resource languages, e.g., English and Chinese, leaving the performance on other languages unclear. Besides, the reward modeling methods in previous work do not fully unleash the potential of reinforcement learning in MT. In this work, we first design a new reward modeling method that compares the translation results of the policy MT model with a strong LRM (i.e., DeepSeek-R1-671B), and quantifies the comparisons to provide rewards. Experimental results demonstrate the superiority of the reward modeling method. Using Qwen2.5-7B-Instruct as the backbone, the trained model achieves the new state-of-the-art performance in literary translation, and outperforms strong LRMs including OpenAI-o1 and DeepSeeK-R1. Furthermore, we extend our method to the multilingual settings with 11 languages. With a carefully designed lightweight reward modeling in RL, we can simply transfer the strong MT ability from a single direction into multiple (i.e., 90) translation directions and achieve impressive multilingual MT performance.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "12 pages, 2 figures",
    "pdf_url": "https://arxiv.org/pdf/2505.12996v1",
    "published_date": "2025-05-19 11:34:47 UTC",
    "updated_date": "2025-05-19 11:34:47 UTC"
  },
  {
    "arxiv_id": "2505.12992v3",
    "title": "Fractured Chain-of-Thought Reasoning",
    "authors": [
      "Baohao Liao",
      "Hanze Dong",
      "Yuhui Xu",
      "Doyen Sahoo",
      "Christof Monz",
      "Junnan Li",
      "Caiming Xiong"
    ],
    "abstract": "Inference-time scaling techniques have significantly bolstered the reasoning capabilities of large language models (LLMs) by harnessing additional computational effort at inference without retraining. Similarly, Chain-of-Thought (CoT) prompting and its extension, Long CoT, improve accuracy by generating rich intermediate reasoning trajectories, but these approaches incur substantial token costs that impede their deployment in latency-sensitive settings. In this work, we first show that truncated CoT, which stops reasoning before completion and directly generates the final answer, often matches full CoT sampling while using dramatically fewer tokens. Building on this insight, we introduce Fractured Sampling, a unified inference-time strategy that interpolates between full CoT and solution-only sampling along three orthogonal axes: (1) the number of reasoning trajectories, (2) the number of final solutions per trajectory, and (3) the depth at which reasoning traces are truncated. Through extensive experiments on five diverse reasoning benchmarks and several model scales, we demonstrate that Fractured Sampling consistently achieves superior accuracy-cost trade-offs, yielding steep log-linear scaling gains in Pass@k versus token budget. Our analysis reveals how to allocate computation across these dimensions to maximize performance, paving the way for more efficient and scalable LLM reasoning. Code is available at https://github.com/BaohaoLiao/frac-cot.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.12992v3",
    "published_date": "2025-05-19 11:30:41 UTC",
    "updated_date": "2025-06-18 15:41:14 UTC"
  },
  {
    "arxiv_id": "2505.12983v1",
    "title": "An Empirical Study of Many-to-Many Summarization with Large Language Models",
    "authors": [
      "Jiaan Wang",
      "Fandong Meng",
      "Zengkui Sun",
      "Yunlong Liang",
      "Yuxuan Cao",
      "Jiarong Xu",
      "Haoxiang Shi",
      "Jie Zhou"
    ],
    "abstract": "Many-to-many summarization (M2MS) aims to process documents in any language and generate the corresponding summaries also in any language. Recently, large language models (LLMs) have shown strong multi-lingual abilities, giving them the potential to perform M2MS in real applications. This work presents a systematic empirical study on LLMs' M2MS ability. Specifically, we first reorganize M2MS data based on eight previous domain-specific datasets. The reorganized data contains 47.8K samples spanning five domains and six languages, which could be used to train and evaluate LLMs. Then, we benchmark 18 LLMs in a zero-shot manner and an instruction-tuning manner. Fine-tuned traditional models (e.g., mBART) are also conducted for comparisons. Our experiments reveal that, zero-shot LLMs achieve competitive results with fine-tuned traditional models. After instruct-tuning, open-source LLMs can significantly improve their M2MS ability, and outperform zero-shot LLMs (including GPT-4) in terms of automatic evaluations. In addition, we demonstrate that this task-specific improvement does not sacrifice the LLMs' general task-solving abilities. However, as revealed by our human evaluation, LLMs still face the factuality issue, and the instruction tuning might intensify the issue. Thus, how to control factual errors becomes the key when building LLM summarizers in real applications, and is worth noting in future research.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to ACL 2025 main conference",
    "pdf_url": "https://arxiv.org/pdf/2505.12983v1",
    "published_date": "2025-05-19 11:18:54 UTC",
    "updated_date": "2025-05-19 11:18:54 UTC"
  },
  {
    "arxiv_id": "2505.12981v2",
    "title": "From Assistants to Adversaries: Exploring the Security Risks of Mobile LLM Agents",
    "authors": [
      "Liangxuan Wu",
      "Chao Wang",
      "Tianming Liu",
      "Yanjie Zhao",
      "Haoyu Wang"
    ],
    "abstract": "The growing adoption of large language models (LLMs) has led to a new paradigm in mobile computing--LLM-powered mobile AI agents--capable of decomposing and automating complex tasks directly on smartphones. However, the security implications of these agents remain largely unexplored. In this paper, we present the first comprehensive security analysis of mobile LLM agents, encompassing three representative categories: System-level AI Agents developed by original equipment manufacturers (e.g., YOYO Assistant), Third-party Universal Agents (e.g., Zhipu AI AutoGLM), and Emerging Agent Frameworks (e.g., Alibaba Mobile Agent). We begin by analyzing the general workflow of mobile agents and identifying security threats across three core capability dimensions: language-based reasoning, GUI-based interaction, and system-level execution. Our analysis reveals 11 distinct attack surfaces, all rooted in the unique capabilities and interaction patterns of mobile LLM agents, and spanning their entire operational lifecycle. To investigate these threats in practice, we introduce AgentScan, a semi-automated security analysis framework that systematically evaluates mobile LLM agents across all 11 attack scenarios. Applying AgentScan to nine widely deployed agents, we uncover a concerning trend: every agent is vulnerable to targeted attacks. In the most severe cases, agents exhibit vulnerabilities across eight distinct attack vectors. These attacks can cause behavioral deviations, privacy leakage, or even full execution hijacking. Based on these findings, we propose a set of defensive design principles and practical recommendations for building secure mobile LLM agents. Our disclosures have received positive feedback from two major device vendors. Overall, this work highlights the urgent need for standardized security practices in the fast-evolving landscape of LLM-driven mobile automation.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.12981v2",
    "published_date": "2025-05-19 11:17:46 UTC",
    "updated_date": "2025-05-20 07:02:05 UTC"
  },
  {
    "arxiv_id": "2505.12966v1",
    "title": "Multiscale Adaptive Conflict-Balancing Model For Multimedia Deepfake Detection",
    "authors": [
      "Zihan Xiong",
      "Xiaohua Wu",
      "Lei Chen",
      "Fangqi Lou"
    ],
    "abstract": "Advances in computer vision and deep learning have blurred the line between deepfakes and authentic media, undermining multimedia credibility through audio-visual forgery. Current multimodal detection methods remain limited by unbalanced learning between modalities. To tackle this issue, we propose an Audio-Visual Joint Learning Method (MACB-DF) to better mitigate modality conflicts and neglect by leveraging contrastive learning to assist in multi-level and cross-modal fusion, thereby fully balancing and exploiting information from each modality. Additionally, we designed an orthogonalization-multimodal pareto module that preserves unimodal information while addressing gradient conflicts in audio-video encoders caused by differing optimization targets of the loss functions. Extensive experiments and ablation studies conducted on mainstream deepfake datasets demonstrate consistent performance gains of our model across key evaluation metrics, achieving an average accuracy of 95.5% across multiple datasets. Notably, our method exhibits superior cross-dataset generalization capabilities, with absolute improvements of 8.0% and 7.7% in ACC scores over the previous best-performing approach when trained on DFDC and tested on DefakeAVMiT and FakeAVCeleb datasets.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "9 pages,ICMR accepted",
    "pdf_url": "https://arxiv.org/pdf/2505.12966v1",
    "published_date": "2025-05-19 11:01:49 UTC",
    "updated_date": "2025-05-19 11:01:49 UTC"
  },
  {
    "arxiv_id": "2505.13567v2",
    "title": "Learning Dynamics of RNNs in Closed-Loop Environments",
    "authors": [
      "Yoav Ger",
      "Omri Barak"
    ],
    "abstract": "Recurrent neural networks (RNNs) trained on neuroscience-inspired tasks offer powerful models of brain computation. However, typical training paradigms rely on open-loop, supervised settings, whereas real-world learning unfolds in closed-loop environments. Here, we develop a mathematical theory describing the learning dynamics of linear RNNs trained in closed-loop contexts. We first demonstrate that two otherwise identical RNNs, trained in either closed- or open-loop modes, follow markedly different learning trajectories. To probe this divergence, we analytically characterize the closed-loop case, revealing distinct stages aligned with the evolution of the training loss. Specifically, we show that the learning dynamics of closed-loop RNNs, in contrast to open-loop ones, are governed by an interplay between two competing objectives: short-term policy improvement and long-term stability of the agent-environment interaction. Finally, we apply our framework to a realistic motor control task, highlighting its broader applicability. Taken together, our results underscore the importance of modeling closed-loop dynamics in a biologically plausible setting.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.NC"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at NeurIPS 2025",
    "pdf_url": "https://arxiv.org/pdf/2505.13567v2",
    "published_date": "2025-05-19 11:00:23 UTC",
    "updated_date": "2025-11-06 07:45:12 UTC"
  },
  {
    "arxiv_id": "2505.12963v1",
    "title": "Segmentation of temporomandibular joint structures on mri images using neural networks for diagnosis of pathologies",
    "authors": [
      "Maksim I. Ivanov",
      "Olga E. Mendybaeva",
      "Yuri E. Karyakin",
      "Igor N. Glukhikh",
      "Aleksey V. Lebedev"
    ],
    "abstract": "This article explores the use of artificial intelligence for the diagnosis of pathologies of the temporomandibular joint (TMJ), in particular, for the segmentation of the articular disc on MRI images. The relevance of the work is due to the high prevalence of TMJ pathologies, as well as the need to improve the accuracy and speed of diagnosis in medical institutions. During the study, the existing solutions (Diagnocat, MandSeg) were analyzed, which, as a result, are not suitable for studying the articular disc due to the orientation towards bone structures. To solve the problem, an original dataset was collected from 94 images with the classes \"temporomandibular joint\" and \"jaw\". To increase the amount of data, augmentation methods were used. After that, the models of U-Net, YOLOv8n, YOLOv11n and Roboflow neural networks were trained and compared. The evaluation was carried out according to the Dice Score, Precision, Sensitivity, Specificity, and Mean Average Precision metrics. The results confirm the potential of using the Roboflow model for segmentation of the temporomandibular joint. In the future, it is planned to develop an algorithm for measuring the distance between the jaws and determining the position of the articular disc, which will improve the diagnosis of TMJ pathologies.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "10 pages, 10 figures",
    "pdf_url": "https://arxiv.org/pdf/2505.12963v1",
    "published_date": "2025-05-19 10:58:02 UTC",
    "updated_date": "2025-05-19 10:58:02 UTC"
  },
  {
    "arxiv_id": "2505.12960v1",
    "title": "Hardware-Adaptive and Superlinear-Capacity Memristor-based Associative Memory",
    "authors": [
      "Chengping He",
      "Mingrui Jiang",
      "Keyi Shan",
      "Szu-Hao Yang",
      "Zefan Li",
      "Shengbo Wang",
      "Giacomo Pedretti",
      "Jim Ignowski",
      "Can Li"
    ],
    "abstract": "Brain-inspired computing aims to mimic cognitive functions like associative memory, the ability to recall complete patterns from partial cues. Memristor technology offers promising hardware for such neuromorphic systems due to its potential for efficient in-memory analog computing. Hopfield Neural Networks (HNNs) are a classic model for associative memory, but implementations on conventional hardware suffer from efficiency bottlenecks, while prior memristor-based HNNs faced challenges with vulnerability to hardware defects due to offline training, limited storage capacity, and difficulty processing analog patterns. Here we introduce and experimentally demonstrate on integrated memristor hardware a new hardware-adaptive learning algorithm for associative memories that significantly improves defect tolerance and capacity, and naturally extends to scalable multilayer architectures capable of handling both binary and continuous patterns. Our approach achieves 3x effective capacity under 50% device faults compared to state-of-the-art methods. Furthermore, its extension to multilayer architectures enables superlinear capacity scaling (\\(\\propto N^{1.49}\\ for binary patterns) and effective recalling of continuous patterns (\\propto N^{1.74}\\ scaling), as compared to linear capacity scaling for previous HNNs. It also provides flexibility to adjust capacity by tuning hidden neurons for the same-sized patterns. By leveraging the massive parallelism of the hardware enabled by synchronous updates, it reduces energy by 8.8x and latency by 99.7% for 64-dimensional patterns over asynchronous schemes, with greater improvements at scale. This promises the development of more reliable memristor-based associative memory systems and enables new applications research due to the significantly improved capacity, efficiency, and flexibility.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.ET"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.12960v1",
    "published_date": "2025-05-19 10:55:09 UTC",
    "updated_date": "2025-05-19 10:55:09 UTC"
  },
  {
    "arxiv_id": "2505.13565v2",
    "title": "Aligning Trustworthy AI with Democracy: A Dual Taxonomy of Opportunities and Risks",
    "authors": [
      "Oier Mentxaka",
      "Natalia Díaz-Rodríguez",
      "Mark Coeckelbergh",
      "Marcos López de Prado",
      "Emilia Gómez",
      "David Fernández Llorca",
      "Enrique Herrera-Viedma",
      "Francisco Herrera"
    ],
    "abstract": "Artificial Intelligence (AI) poses both significant risks and valuable opportunities for democratic governance. This paper introduces a dual taxonomy to evaluate AI's complex relationship with democracy: the AI Risks to Democracy (AIRD) taxonomy, which identifies how AI can undermine core democratic principles such as autonomy, fairness, and trust; and the AI's Positive Contributions to Democracy (AIPD) taxonomy, which highlights AI's potential to enhance transparency, participation, efficiency, and evidence-based policymaking.\n  Grounded in the European Union's approach to ethical AI governance, and particularly the seven Trustworthy AI requirements proposed by the European Commission's High-Level Expert Group on AI, each identified risk is aligned with mitigation strategies based on EU regulatory and normative frameworks. Our analysis underscores the transversal importance of transparency and societal well-being across all risk categories and offers a structured lens for aligning AI systems with democratic values.\n  By integrating democratic theory with practical governance tools, this paper offers a normative and actionable framework to guide research, regulation, and institutional design to support trustworthy, democratic AI. It provides scholars with a conceptual foundation to evaluate the democratic implications of AI, equips policymakers with structured criteria for ethical oversight, and helps technologists align system design with democratic principles. In doing so, it bridges the gap between ethical aspirations and operational realities, laying the groundwork for more inclusive, accountable, and resilient democratic systems in the algorithmic age.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CY",
    "comment": "26 pages, 5 figures",
    "pdf_url": "https://arxiv.org/pdf/2505.13565v2",
    "published_date": "2025-05-19 10:51:08 UTC",
    "updated_date": "2026-01-13 11:40:27 UTC"
  },
  {
    "arxiv_id": "2505.12951v1",
    "title": "DGRO: Enhancing LLM Reasoning via Exploration-Exploitation Control and Reward Variance Management",
    "authors": [
      "Xuerui Su",
      "Liya Guo",
      "Yue Wang",
      "Yi Zhu",
      "Zhiming Ma",
      "Zun Wang",
      "Yuting Liu"
    ],
    "abstract": "Inference scaling further accelerates Large Language Models (LLMs) toward Artificial General Intelligence (AGI), with large-scale Reinforcement Learning (RL) to unleash long Chain-of-Thought reasoning. Most contemporary reasoning approaches usually rely on handcrafted rule-based reward functions. However, the tarde-offs of exploration and exploitation in RL algorithms involves multiple complex considerations, and the theoretical and empirical impacts of manually designed reward functions remain insufficiently explored. In this paper, we propose Decoupled Group Reward Optimization (DGRO), a general RL algorithm for LLM reasoning. On the one hand, DGRO decouples the traditional regularization coefficient into two independent hyperparameters: one scales the policy gradient term, and the other regulates the distance from the sampling policy. This decoupling not only enables precise control over balancing exploration and exploitation, but also can be seamlessly extended to Online Policy Mirror Descent (OPMD) algorithms in Kimi k1.5 and Direct Reward Optimization. On the other hand, we observe that reward variance significantly affects both convergence speed and final model performance. We conduct both theoretical analysis and extensive empirical validation to assess DGRO, including a detailed ablation study that investigates its performance and optimization dynamics. Experimental results show that DGRO achieves state-of-the-art performance on the Logic dataset with an average accuracy of 96.9\\%, and demonstrates strong generalization across mathematical benchmarks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.12951v1",
    "published_date": "2025-05-19 10:44:49 UTC",
    "updated_date": "2025-05-19 10:44:49 UTC"
  },
  {
    "arxiv_id": "2505.13563v3",
    "title": "Breaking the Compression Ceiling: Data-Free Pipeline for Ultra-Efficient Delta Compression",
    "authors": [
      "Xiaohui Wang",
      "Peng Ye",
      "Chenyu Huang",
      "Shenghe Zheng",
      "Bo Zhang",
      "Lei Bai",
      "Wanli Ouyang",
      "Tao Chen"
    ],
    "abstract": "With the rise of the fine-tuned-pretrained paradigm, storing numerous fine-tuned models for multi-tasking creates significant storage overhead. Delta compression alleviates this by storing only the pretrained model and the highly compressed delta weights (the differences between fine-tuned and pretrained model weights). However, existing methods fail to maintain both high compression and performance, and often rely on data. To address these challenges, we propose UltraDelta, the first data-free delta compression pipeline that achieves both ultra-high compression and strong performance. UltraDelta is designed to minimize redundancy, maximize information, and stabilize performance across inter-layer, intra-layer, and global dimensions, using three key components: (1) Variance-Based Mixed Sparsity Allocation assigns sparsity based on variance, giving lower sparsity to high-variance layers to preserve inter-layer information. (2) Distribution-Aware Compression applies uniform quantization and then groups parameters by value, followed by group-wise pruning, to better preserve intra-layer distribution. (3) Trace-Norm-Guided Rescaling uses the trace norm of delta weights to estimate a global rescaling factor, improving model stability under higher compression. Extensive experiments across (a) large language models (fine-tuned on LLaMA-2 7B and 13B) with up to 50x compression, (b) general NLP models (RoBERTa-base, T5-base) with up to 224x compression, (c) vision models (ViT-B/32, ViT-L/14) with up to 132x compression, and (d) multi-modal models (BEiT-3) with 18x compression, demonstrate that UltraDelta consistently outperforms existing methods, especially under ultra-high compression. Code is available at https://github.com/xiaohuiwang000/UltraDelta.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at NeurIPS 2025",
    "pdf_url": "https://arxiv.org/pdf/2505.13563v3",
    "published_date": "2025-05-19 10:37:22 UTC",
    "updated_date": "2025-10-13 17:33:00 UTC"
  },
  {
    "arxiv_id": "2505.12944v2",
    "title": "CALM-PDE: Continuous and Adaptive Convolutions for Latent Space Modeling of Time-dependent PDEs",
    "authors": [
      "Jan Hagnberger",
      "Daniel Musekamp",
      "Mathias Niepert"
    ],
    "abstract": "Solving time-dependent Partial Differential Equations (PDEs) using a densely discretized spatial domain is a fundamental problem in various scientific and engineering disciplines, including modeling climate phenomena and fluid dynamics. However, performing these computations directly in the physical space often incurs significant computational costs. To address this issue, several neural surrogate models have been developed that operate in a compressed latent space to solve the PDE. While these approaches reduce computational complexity, they often use Transformer-based attention mechanisms to handle irregularly sampled domains, resulting in increased memory consumption. In contrast, convolutional neural networks allow memory-efficient encoding and decoding but are limited to regular discretizations. Motivated by these considerations, we propose CALM-PDE, a model class that efficiently solves arbitrarily discretized PDEs in a compressed latent space. We introduce a novel continuous convolution-based encoder-decoder architecture that uses an epsilon-neighborhood-constrained kernel and learns to apply the convolution operator to adaptive and optimized query points. We demonstrate the effectiveness of CALM-PDE on a diverse set of PDEs with both regularly and irregularly sampled spatial domains. CALM-PDE is competitive with or outperforms existing baseline methods while offering significant improvements in memory and inference time efficiency compared to Transformer-based methods.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.NE",
      "physics.comp-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted for publication at the 39th Conference on Neural Information Processing Systems (NeurIPS) 2025, San Diego, California, USA",
    "pdf_url": "https://arxiv.org/pdf/2505.12944v2",
    "published_date": "2025-05-19 10:31:30 UTC",
    "updated_date": "2025-10-23 15:43:38 UTC"
  },
  {
    "arxiv_id": "2505.12942v3",
    "title": "A3 : an Analytical Low-Rank Approximation Framework for Attention",
    "authors": [
      "Jeffrey T. H. Wong",
      "Cheng Zhang",
      "Xinye Cao",
      "Pedro Gimenes",
      "George A. Constantinides",
      "Wayne Luk",
      "Yiren Zhao"
    ],
    "abstract": "Large language models have demonstrated remarkable performance; however, their massive parameter counts make deployment highly expensive. Low-rank approximation offers a promising compression solution, yet existing approaches have two main limitations: (1) They focus on minimizing the output error of individual linear layers, without considering the architectural characteristics of Transformers, and (2) they decompose a large weight matrix into two small low-rank matrices. Consequently, these methods often fall short compared to other compression techniques like pruning and quantization, and introduce runtime overhead such as the extra GEMM kernel launches for decomposed small matrices. To address these limitations, we propose $\\tt A^\\tt 3$, a post-training low-rank approximation framework. $\\tt A^\\tt 3$ splits a Transformer layer into three functional components, namely $\\tt QK$, $\\tt OV$, and $\\tt MLP$. For each component, $\\tt A^\\tt 3$ provides an analytical solution that reduces the hidden dimension size inside each component while minimizing the component's functional loss ($\\it i.e.$, error in attention scores, attention outputs, and MLP outputs). This approach directly reduces model sizes, KV cache sizes, and FLOPs without introducing any runtime overheads. In addition, it provides a new narrative in advancing the optimization problem from singular linear layer loss optimization toward improved end-to-end performance. Through extensive experiments, we show that $\\tt A^\\tt 3$ maintains superior performance compared to SoTAs. For example, under the same reduction budget in computation and memory, our low-rank approximated LLaMA 3.1-70B achieves a perplexity of 4.69 on WikiText-2, outperforming the previous SoTA's 7.87 by 3.18. We also demonstrate the versatility of $\\tt A^\\tt 3$, including KV cache compression, quantization, and mixed-rank assignments for enhanced performance.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.12942v3",
    "published_date": "2025-05-19 10:29:32 UTC",
    "updated_date": "2025-06-25 23:03:54 UTC"
  },
  {
    "arxiv_id": "2505.12938v2",
    "title": "Leveraging LLM Inconsistency to Boost Pass@k Performance",
    "authors": [
      "Uri Dalal",
      "Meirav Segal",
      "Zvika Ben-Haim",
      "Dan Lahav",
      "Omer Nevo"
    ],
    "abstract": "Large language models (LLMs) achieve impressive abilities in numerous domains, but exhibit inconsistent performance in response to minor input changes. Rather than view this as a drawback, in this paper we introduce a novel method for leveraging models' inconsistency to boost Pass@k performance. Specifically, we present a \"Variator\" agent that generates k variants of a given task and submits one candidate solution for each one. Our variant generation approach is applicable to a wide range of domains as it is task agnostic and compatible with free-form inputs. We demonstrate the efficacy of our agent theoretically using a probabilistic model of the inconsistency effect, and show empirically that it outperforms the baseline on the APPS dataset. Furthermore, we establish that inconsistency persists even in frontier reasoning models across coding and cybersecurity domains, suggesting our method is likely to remain relevant for future model generations.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.12938v2",
    "published_date": "2025-05-19 10:22:04 UTC",
    "updated_date": "2025-05-20 14:22:15 UTC"
  },
  {
    "arxiv_id": "2505.12929v1",
    "title": "Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs",
    "authors": [
      "Zhihe Yang",
      "Xufang Luo",
      "Zilong Wang",
      "Dongqi Han",
      "Zhiyuan He",
      "Dongsheng Li",
      "Yunjian Xu"
    ],
    "abstract": "Reinforcement learning (RL) has become a cornerstone for enhancing the reasoning capabilities of large language models (LLMs), with recent innovations such as Group Relative Policy Optimization (GRPO) demonstrating exceptional effectiveness. In this study, we identify a critical yet underexplored issue in RL training: low-probability tokens disproportionately influence model updates due to their large gradient magnitudes. This dominance hinders the effective learning of high-probability tokens, whose gradients are essential for LLMs' performance but are substantially suppressed. To mitigate this interference, we propose two novel methods: Advantage Reweighting and Low-Probability Token Isolation (Lopti), both of which effectively attenuate gradients from low-probability tokens while emphasizing parameter updates driven by high-probability tokens. Our approaches promote balanced updates across tokens with varying probabilities, thereby enhancing the efficiency of RL training. Experimental results demonstrate that they substantially improve the performance of GRPO-trained LLMs, achieving up to a 46.2% improvement in K&K Logic Puzzle reasoning tasks. Our implementation is available at https://github.com/zhyang2226/AR-Lopti.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "24 pages, 12 figures",
    "pdf_url": "https://arxiv.org/pdf/2505.12929v1",
    "published_date": "2025-05-19 10:14:08 UTC",
    "updated_date": "2025-05-19 10:14:08 UTC"
  },
  {
    "arxiv_id": "2505.12925v2",
    "title": "CPRet: A Dataset, Benchmark, and Model for Retrieval in Competitive Programming",
    "authors": [
      "Han Deng",
      "Yuan Meng",
      "Shixiang Tang",
      "Wanli Ouyang",
      "Xinzhu Ma"
    ],
    "abstract": "Competitive programming benchmarks are widely used in scenarios such as programming contests and large language model assessments. However, the growing presence of duplicate or highly similar problems raises concerns not only about competition fairness, but also about the validity of competitive programming as a benchmark for model evaluation. In this paper, we propose a new problem, similar question retrieval, to tackle this issue. Due to the lack of both data and models, solving this problem is challenging. To this end, we introduce CPRet, a retrieval-oriented benchmark suite for competitive programming, covering four retrieval tasks: two code-centric (i.e., Text-to-Code, Code-to-Code) and two newly proposed problem-centric tasks (i.e., Problem-to-Duplicate, Simplified-to-Full) built from a combination of automatically crawled problem-solution data and manually curated annotations. Our contribution includes both high-quality training data and temporally separated test sets for reliable evaluation. Besides, we further develop two task-specialized retrievers based on this dataset: CPRetriever-Code, trained with a novel Group-InfoNCE loss for problem-code alignment, and CPRetriever-Prob, fine-tuned for identifying problem-level similarity. Both models achieve strong results and are open-sourced for local use. Finally, we analyze LiveCodeBench and find that high-similarity problems inflate model pass rates and reduce differentiation, underscoring the need for similarity-aware evaluation in future benchmarks.\n  Github: https://github.com/coldchair/CPRet\n  Online Demo: https://www.cpret.online/",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.SE",
    "comment": "Accepted by NeurIPS 2025 Dataset and Benchmark Track",
    "pdf_url": "https://arxiv.org/pdf/2505.12925v2",
    "published_date": "2025-05-19 10:07:51 UTC",
    "updated_date": "2025-10-26 03:34:29 UTC"
  },
  {
    "arxiv_id": "2505.13562v1",
    "title": "Randomised Optimism via Competitive Co-Evolution for Matrix Games with Bandit Feedback",
    "authors": [
      "Shishen Lin"
    ],
    "abstract": "Learning in games is a fundamental problem in machine learning and artificial intelligence, with numerous applications~\\citep{silver2016mastering,schrittwieser2020mastering}. This work investigates two-player zero-sum matrix games with an unknown payoff matrix and bandit feedback, where each player observes their actions and the corresponding noisy payoff. Prior studies have proposed algorithms for this setting~\\citep{o2021matrix,maiti2023query,cai2024uncoupled}, with \\citet{o2021matrix} demonstrating the effectiveness of deterministic optimism (e.g., \\ucb) in achieving sublinear regret. However, the potential of randomised optimism in matrix games remains theoretically unexplored.\n  We propose Competitive Co-evolutionary Bandit Learning (\\coebl), a novel algorithm that integrates evolutionary algorithms (EAs) into the bandit framework to implement randomised optimism through EA variation operators. We prove that \\coebl achieves sublinear regret, matching the performance of deterministic optimism-based methods. To the best of our knowledge, this is the first theoretical regret analysis of an evolutionary bandit learning algorithm in matrix games.\n  Empirical evaluations on diverse matrix game benchmarks demonstrate that \\coebl not only achieves sublinear regret but also consistently outperforms classical bandit algorithms, including \\exptr~\\citep{auer2002nonstochastic}, the variant \\exptrni~\\citep{cai2024uncoupled}, and \\ucb~\\citep{o2021matrix}. These results highlight the potential of evolutionary bandit learning, particularly the efficacy of randomised optimism via evolutionary algorithms in game-theoretic settings.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.GT",
      "cs.LG",
      "cs.NE"
    ],
    "primary_category": "stat.ML",
    "comment": "21 pages, 10 figures, accepted at IJCAI 2025",
    "pdf_url": "https://arxiv.org/pdf/2505.13562v1",
    "published_date": "2025-05-19 10:05:55 UTC",
    "updated_date": "2025-05-19 10:05:55 UTC"
  },
  {
    "arxiv_id": "2505.12923v2",
    "title": "The Traitors: Deception and Trust in Multi-Agent Language Model Simulations",
    "authors": [
      "Pedro M. P. Curvo"
    ],
    "abstract": "As AI systems increasingly assume roles where trust and alignment with human values are essential, understanding when and why they engage in deception has become a critical research priority. We introduce The Traitors, a multi-agent simulation framework inspired by social deduction games, designed to probe deception, trust formation, and strategic communication among large language model (LLM) agents under asymmetric information. A minority of agents the traitors seek to mislead the majority, while the faithful must infer hidden identities through dialogue and reasoning. Our contributions are: (1) we ground the environment in formal frameworks from game theory, behavioral economics, and social cognition; (2) we develop a suite of evaluation metrics capturing deception success, trust dynamics, and collective inference quality; (3) we implement a fully autonomous simulation platform where LLMs reason over persistent memory and evolving social dynamics, with support for heterogeneous agent populations, specialized traits, and adaptive behaviors. Our initial experiments across DeepSeek-V3, GPT-4o-mini, and GPT-4o (10 runs per model) reveal a notable asymmetry: advanced models like GPT-4o demonstrate superior deceptive capabilities yet exhibit disproportionate vulnerability to others' falsehoods. This suggests deception skills may scale faster than detection abilities. Overall, The Traitors provides a focused, configurable testbed for investigating LLM behavior in socially nuanced interactions. We position this work as a contribution toward more rigorous research on deception mechanisms, alignment challenges, and the broader social reliability of AI systems.",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "9 main pages, 31 pages",
    "pdf_url": "https://arxiv.org/pdf/2505.12923v2",
    "published_date": "2025-05-19 10:01:35 UTC",
    "updated_date": "2025-12-14 19:24:05 UTC"
  },
  {
    "arxiv_id": "2505.12920v1",
    "title": "PyFCG: Fluid Construction Grammar in Python",
    "authors": [
      "Paul Van Eecke",
      "Katrien Beuls"
    ],
    "abstract": "We present PyFCG, an open source software library that ports Fluid Construction Grammar (FCG) to the Python programming language. PyFCG enables its users to seamlessly integrate FCG functionality into Python programs, and to use FCG in combination with other libraries within Python's rich ecosystem. Apart from a general description of the library, this paper provides three walkthrough tutorials that demonstrate example usage of PyFCG in typical use cases of FCG: (i) formalising and testing construction grammar analyses, (ii) learning usage-based construction grammars from corpora, and (iii) implementing agent-based experiments on emergent communication.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.12920v1",
    "published_date": "2025-05-19 10:00:01 UTC",
    "updated_date": "2025-05-19 10:00:01 UTC"
  },
  {
    "arxiv_id": "2505.14718v1",
    "title": "Enhancing Shape Perception and Segmentation Consistency for Industrial Image Inspection",
    "authors": [
      "Guoxuan Mao",
      "Ting Cao",
      "Ziyang Li",
      "Yuan Dong"
    ],
    "abstract": "Semantic segmentation stands as a pivotal research focus in computer vision. In the context of industrial image inspection, conventional semantic segmentation models fail to maintain the segmentation consistency of fixed components across varying contextual environments due to a lack of perception of object contours. Given the real-time constraints and limited computing capability of industrial image detection machines, it is also necessary to create efficient models to reduce computational complexity. In this work, a Shape-Aware Efficient Network (SPENet) is proposed, which focuses on the shapes of objects to achieve excellent segmentation consistency by separately supervising the extraction of boundary and body information from images. In SPENet, a novel method is introduced for describing fuzzy boundaries to better adapt to real-world scenarios named Variable Boundary Domain (VBD). Additionally, a new metric, Consistency Mean Square Error(CMSE), is proposed to measure segmentation consistency for fixed components. Our approach attains the best segmentation accuracy and competitive speed on our dataset, showcasing significant advantages in CMSE among numerous state-of-the-art real-time segmentation networks, achieving a reduction of over 50% compared to the previously top-performing models.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.14718v1",
    "published_date": "2025-05-19 09:57:00 UTC",
    "updated_date": "2025-05-19 09:57:00 UTC"
  },
  {
    "arxiv_id": "2505.12910v2",
    "title": "SourceDetMamba: A Graph-aware State Space Model for Source Detection in Sequential Hypergraphs",
    "authors": [
      "Le Cheng",
      "Peican Zhu",
      "Yangming Guo",
      "Chao Gao",
      "Zhen Wang",
      "Keke Tang"
    ],
    "abstract": "Source detection on graphs has demonstrated high efficacy in identifying rumor origins. Despite advances in machine learning-based methods, many fail to capture intrinsic dynamics of rumor propagation. In this work, we present SourceDetMamba: A Graph-aware State Space Model for Source Detection in Sequential Hypergraphs, which harnesses the recent success of the state space model Mamba, known for its superior global modeling capabilities and computational efficiency, to address this challenge. Specifically, we first employ hypergraphs to model high-order interactions within social networks. Subsequently, temporal network snapshots generated during the propagation process are sequentially fed in reverse order into Mamba to infer underlying propagation dynamics. Finally, to empower the sequential model to effectively capture propagation patterns while integrating structural information, we propose a novel graph-aware state update mechanism, wherein the state of each node is propagated and refined by both temporal dependencies and topological context. Extensive evaluations on eight datasets demonstrate that SourceDetMamba consistently outperforms state-of-the-art approaches.",
    "categories": [
      "cs.SI",
      "cs.AI"
    ],
    "primary_category": "cs.SI",
    "comment": "Accepted by IJCAI25",
    "pdf_url": "https://arxiv.org/pdf/2505.12910v2",
    "published_date": "2025-05-19 09:45:27 UTC",
    "updated_date": "2025-06-04 12:57:51 UTC"
  },
  {
    "arxiv_id": "2505.12909v3",
    "title": "Sinusoidal Initialization, Time for a New Start",
    "authors": [
      "Alberto Fernández-Hernández",
      "Jose I. Mestre",
      "Manuel F. Dolz",
      "Jose Duato",
      "Enrique S. Quintana-Ortí"
    ],
    "abstract": "Initialization plays a critical role in Deep Neural Network training, directly influencing convergence, stability, and generalization. Common approaches such as Glorot and He initializations rely on randomness, which can produce uneven weight distributions across layer connections. In this paper, we introduce the Sinusoidal initialization, a novel deterministic method that employs sinusoidal functions to construct structured weight matrices expressly to improve the spread and balance of weights throughout the network while simultaneously fostering a more uniform, well-conditioned distribution of neuron activation states from the very first forward pass. Because Sinusoidal initialization begins with weights and activations that are already evenly and efficiently utilized, it delivers consistently faster convergence, greater training stability, and higher final accuracy across a wide range of models, including convolutional neural networks, vision transformers, and large language models. On average, our experiments show an increase of 4.9% in final validation accuracy and 20.9% in convergence speed. By replacing randomness with structure, this initialization provides a stronger and more reliable foundation for Deep Learning systems.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.12909v3",
    "published_date": "2025-05-19 09:45:18 UTC",
    "updated_date": "2025-12-10 02:40:59 UTC"
  },
  {
    "arxiv_id": "2505.12908v1",
    "title": "Dynamic Graph Induced Contour-aware Heat Conduction Network for Event-based Object Detection",
    "authors": [
      "Xiao Wang",
      "Yu Jin",
      "Lan Chen",
      "Bo Jiang",
      "Lin Zhu",
      "Yonghong Tian",
      "Jin Tang",
      "Bin Luo"
    ],
    "abstract": "Event-based Vision Sensors (EVS) have demonstrated significant advantages over traditional RGB frame-based cameras in low-light conditions, high-speed motion capture, and low latency. Consequently, object detection based on EVS has attracted increasing attention from researchers. Current event stream object detection algorithms are typically built upon Convolutional Neural Networks (CNNs) or Transformers, which either capture limited local features using convolutional filters or incur high computational costs due to the utilization of self-attention. Recently proposed vision heat conduction backbone networks have shown a good balance between efficiency and accuracy; however, these models are not specifically designed for event stream data. They exhibit weak capability in modeling object contour information and fail to exploit the benefits of multi-scale features. To address these issues, this paper proposes a novel dynamic graph induced contour-aware heat conduction network for event stream based object detection, termed CvHeat-DET. The proposed model effectively leverages the clear contour information inherent in event streams to predict the thermal diffusivity coefficients within the heat conduction model, and integrates hierarchical structural graph features to enhance feature learning across multiple scales. Extensive experiments on three benchmark datasets for event stream-based object detection fully validated the effectiveness of the proposed model. The source code of this paper will be released on https://github.com/Event-AHU/OpenEvDET.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.12908v1",
    "published_date": "2025-05-19 09:44:01 UTC",
    "updated_date": "2025-05-19 09:44:01 UTC"
  },
  {
    "arxiv_id": "2505.12904v1",
    "title": "The Computation of Generalized Embeddings for Underwater Acoustic Target Recognition using Contrastive Learning",
    "authors": [
      "Hilde I. Hummel",
      "Arwin Gansekoele",
      "Sandjai Bhulai",
      "Rob van der Mei"
    ],
    "abstract": "The increasing level of sound pollution in marine environments poses an increased threat to ocean health, making it crucial to monitor underwater noise. By monitoring this noise, the sources responsible for this pollution can be mapped. Monitoring is performed by passively listening to these sounds. This generates a large amount of data records, capturing a mix of sound sources such as ship activities and marine mammal vocalizations. Although machine learning offers a promising solution for automatic sound classification, current state-of-the-art methods implement supervised learning. This requires a large amount of high-quality labeled data that is not publicly available. In contrast, a massive amount of lower-quality unlabeled data is publicly available, offering the opportunity to explore unsupervised learning techniques. This research explores this possibility by implementing an unsupervised Contrastive Learning approach. Here, a Conformer-based encoder is optimized by the so-called Variance-Invariance-Covariance Regularization loss function on these lower-quality unlabeled data and the translation to the labeled data is made. Through classification tasks involving recognizing ship types and marine mammal vocalizations, our method demonstrates to produce robust and generalized embeddings. This shows to potential of unsupervised methods for various automatic underwater acoustic analysis tasks.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.12904v1",
    "published_date": "2025-05-19 09:37:46 UTC",
    "updated_date": "2025-05-19 09:37:46 UTC"
  },
  {
    "arxiv_id": "2505.12903v1",
    "title": "Towards Low-Latency Event Stream-based Visual Object Tracking: A Slow-Fast Approach",
    "authors": [
      "Shiao Wang",
      "Xiao Wang",
      "Liye Jin",
      "Bo Jiang",
      "Lin Zhu",
      "Lan Chen",
      "Yonghong Tian",
      "Bin Luo"
    ],
    "abstract": "Existing tracking algorithms typically rely on low-frame-rate RGB cameras coupled with computationally intensive deep neural network architectures to achieve effective tracking. However, such frame-based methods inherently face challenges in achieving low-latency performance and often fail in resource-constrained environments. Visual object tracking using bio-inspired event cameras has emerged as a promising research direction in recent years, offering distinct advantages for low-latency applications. In this paper, we propose a novel Slow-Fast Tracking paradigm that flexibly adapts to different operational requirements, termed SFTrack. The proposed framework supports two complementary modes, i.e., a high-precision slow tracker for scenarios with sufficient computational resources, and an efficient fast tracker tailored for latency-aware, resource-constrained environments. Specifically, our framework first performs graph-based representation learning from high-temporal-resolution event streams, and then integrates the learned graph-structured information into two FlashAttention-based vision backbones, yielding the slow and fast trackers, respectively. The fast tracker achieves low latency through a lightweight network design and by producing multiple bounding box outputs in a single forward pass. Finally, we seamlessly combine both trackers via supervised fine-tuning and further enhance the fast tracker's performance through a knowledge distillation strategy. Extensive experiments on public benchmarks, including FE240, COESOT, and EventVOT, demonstrate the effectiveness and efficiency of our proposed method across different real-world scenarios. The source code has been released on https://github.com/Event-AHU/SlowFast_Event_Track.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.12903v1",
    "published_date": "2025-05-19 09:37:23 UTC",
    "updated_date": "2025-05-19 09:37:23 UTC"
  },
  {
    "arxiv_id": "2505.12900v1",
    "title": "AutoGEEval: A Multimodal and Automated Framework for Geospatial Code Generation on GEE with Large Language Models",
    "authors": [
      "Shuyang Hou",
      "Zhangxiao Shen",
      "Huayi Wu",
      "Jianyuan Liang",
      "Haoyue Jiao",
      "Yaxian Qing",
      "Xiaopu Zhang",
      "Xu Li",
      "Zhipeng Gui",
      "Xuefeng Guan",
      "Longgang Xiang"
    ],
    "abstract": "Geospatial code generation is emerging as a key direction in the integration of artificial intelligence and geoscientific analysis. However, there remains a lack of standardized tools for automatic evaluation in this domain. To address this gap, we propose AutoGEEval, the first multimodal, unit-level automated evaluation framework for geospatial code generation tasks on the Google Earth Engine (GEE) platform powered by large language models (LLMs). Built upon the GEE Python API, AutoGEEval establishes a benchmark suite (AutoGEEval-Bench) comprising 1325 test cases that span 26 GEE data types. The framework integrates both question generation and answer verification components to enable an end-to-end automated evaluation pipeline-from function invocation to execution validation. AutoGEEval supports multidimensional quantitative analysis of model outputs in terms of accuracy, resource consumption, execution efficiency, and error types. We evaluate 18 state-of-the-art LLMs-including general-purpose, reasoning-augmented, code-centric, and geoscience-specialized models-revealing their performance characteristics and potential optimization pathways in GEE code generation. This work provides a unified protocol and foundational resource for the development and assessment of geospatial code generation models, advancing the frontier of automated natural language to domain-specific code translation.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CG",
      "cs.CL",
      "cs.DB"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.12900v1",
    "published_date": "2025-05-19 09:35:58 UTC",
    "updated_date": "2025-05-19 09:35:58 UTC"
  },
  {
    "arxiv_id": "2505.14717v1",
    "title": "Aneumo: A Large-Scale Multimodal Aneurysm Dataset with Computational Fluid Dynamics Simulations and Deep Learning Benchmarks",
    "authors": [
      "Xigui Li",
      "Yuanye Zhou",
      "Feiyang Xiao",
      "Xin Guo",
      "Chen Jiang",
      "Tan Pan",
      "Xingmeng Zhang",
      "Cenyu Liu",
      "Zeyun Miao",
      "Jianchao Ge",
      "Xiansheng Wang",
      "Qimeng Wang",
      "Yichi Zhang",
      "Wenbo Zhang",
      "Fengping Zhu",
      "Limei Han",
      "Yuan Qi",
      "Chensen Lin",
      "Yuan Cheng"
    ],
    "abstract": "Intracranial aneurysms (IAs) are serious cerebrovascular lesions found in approximately 5\\% of the general population. Their rupture may lead to high mortality. Current methods for assessing IA risk focus on morphological and patient-specific factors, but the hemodynamic influences on IA development and rupture remain unclear. While accurate for hemodynamic studies, conventional computational fluid dynamics (CFD) methods are computationally intensive, hindering their deployment in large-scale or real-time clinical applications. To address this challenge, we curated a large-scale, high-fidelity aneurysm CFD dataset to facilitate the development of efficient machine learning algorithms for such applications. Based on 427 real aneurysm geometries, we synthesized 10,660 3D shapes via controlled deformation to simulate aneurysm evolution. The authenticity of these synthetic shapes was confirmed by neurosurgeons. CFD computations were performed on each shape under eight steady-state mass flow conditions, generating a total of 85,280 blood flow dynamics data covering key parameters. Furthermore, the dataset includes segmentation masks, which can support tasks that use images, point clouds or other multimodal data as input. Additionally, we introduced a benchmark for estimating flow parameters to assess current modeling methods. This dataset aims to advance aneurysm research and promote data-driven approaches in biofluids, biomedical engineering, and clinical risk assessment. The code and dataset are available at: https://github.com/Xigui-Li/Aneumo.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.14717v1",
    "published_date": "2025-05-19 09:32:09 UTC",
    "updated_date": "2025-05-19 09:32:09 UTC"
  },
  {
    "arxiv_id": "2505.13561v1",
    "title": "Language and Thought: The View from LLMs",
    "authors": [
      "Daniel Rothschild"
    ],
    "abstract": "Daniel Dennett speculated in *Kinds of Minds* 1996: \"Perhaps the kind of mind you get when you add language to it is so different from the kind of mind you can have without language that calling them both minds is a mistake.\" Recent work in AI can be seen as testing Dennett's thesis by exploring the performance of AI systems with and without linguistic training. I argue that the success of Large Language Models at inferential reasoning, limited though it may be, supports Dennett's radical view about the effect of language on thought. I suggest it is the abstractness and efficiency of linguistic encoding that lies behind the capacity of LLMs to perform inferences across a wide range of domains. In a slogan, language makes inference computationally tractable. I assess what these results in AI indicate about the role of language in the workings of our own biological minds.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "37 Pages",
    "pdf_url": "https://arxiv.org/pdf/2505.13561v1",
    "published_date": "2025-05-19 09:29:32 UTC",
    "updated_date": "2025-05-19 09:29:32 UTC"
  },
  {
    "arxiv_id": "2505.12894v2",
    "title": "HyperDet: Source Detection in Hypergraphs via Interactive Relationship Construction and Feature-rich Attention Fusion",
    "authors": [
      "Le Cheng",
      "Peican Zhu",
      "Yangming Guo",
      "Keke Tang",
      "Chao Gao",
      "Zhen Wang"
    ],
    "abstract": "Hypergraphs offer superior modeling capabilities for social networks, particularly in capturing group phenomena that extend beyond pairwise interactions in rumor propagation. Existing approaches in rumor source detection predominantly focus on dyadic interactions, which inadequately address the complexity of more intricate relational structures. In this study, we present a novel approach for Source Detection in Hypergraphs (HyperDet) via Interactive Relationship Construction and Feature-rich Attention Fusion. Specifically, our methodology employs an Interactive Relationship Construction module to accurately model both the static topology and dynamic interactions among users, followed by the Feature-rich Attention Fusion module, which autonomously learns node features and discriminates between nodes using a self-attention mechanism, thereby effectively learning node representations under the framework of accurately modeled higher-order relationships. Extensive experimental validation confirms the efficacy of our HyperDet approach, showcasing its superiority relative to current state-of-the-art methods.",
    "categories": [
      "cs.SI",
      "cs.AI"
    ],
    "primary_category": "cs.SI",
    "comment": "Accepted by IJCAI25",
    "pdf_url": "https://arxiv.org/pdf/2505.12894v2",
    "published_date": "2025-05-19 09:27:46 UTC",
    "updated_date": "2025-06-04 12:44:45 UTC"
  },
  {
    "arxiv_id": "2505.12891v4",
    "title": "TIME: A Multi-level Benchmark for Temporal Reasoning of LLMs in Real-World Scenarios",
    "authors": [
      "Shaohang Wei",
      "Wei Li",
      "Feifan Song",
      "Wen Luo",
      "Tianyi Zhuang",
      "Haochen Tan",
      "Zhijiang Guo",
      "Houfeng Wang"
    ],
    "abstract": "Temporal reasoning is pivotal for Large Language Models (LLMs) to comprehend the real world. However, existing works neglect the real-world challenges for temporal reasoning: (1) intensive temporal information, (2) fast-changing event dynamics, and (3) complex temporal dependencies in social interactions. To bridge this gap, we propose a multi-level benchmark TIME, designed for temporal reasoning in real-world scenarios. TIME consists of 38,522 QA pairs, covering 3 levels with 11 fine-grained sub-tasks. This benchmark encompasses 3 sub-datasets reflecting different real-world challenges: TIME-Wiki, TIME-News, and TIME-Dial. We conduct extensive experiments on reasoning models and non-reasoning models. And we conducted an in-depth analysis of temporal reasoning performance across diverse real-world scenarios and tasks, and summarized the impact of test-time scaling on temporal reasoning capabilities. Additionally, we release TIME-Lite, a human-annotated subset to foster future research and standardized evaluation in temporal reasoning. The code is available at https://github.com/sylvain-wei/TIME , the dataset is available at https://huggingface.co/datasets/SylvainWei/TIME , and the project page link is https://sylvain-wei.github.io/TIME/ .",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted by NeurIPS 2025 (Spotlight)",
    "pdf_url": "https://arxiv.org/pdf/2505.12891v4",
    "published_date": "2025-05-19 09:22:02 UTC",
    "updated_date": "2025-10-08 03:45:45 UTC"
  },
  {
    "arxiv_id": "2505.12886v1",
    "title": "Detection and Mitigation of Hallucination in Large Reasoning Models: A Mechanistic Perspective",
    "authors": [
      "Zhongxiang Sun",
      "Qipeng Wang",
      "Haoyu Wang",
      "Xiao Zhang",
      "Jun Xu"
    ],
    "abstract": "Large Reasoning Models (LRMs) have shown impressive capabilities in multi-step reasoning tasks. However, alongside these successes, a more deceptive form of model error has emerged--Reasoning Hallucination--where logically coherent but factually incorrect reasoning traces lead to persuasive yet faulty conclusions. Unlike traditional hallucinations, these errors are embedded within structured reasoning, making them more difficult to detect and potentially more harmful. In this work, we investigate reasoning hallucinations from a mechanistic perspective. We propose the Reasoning Score, which quantifies the depth of reasoning by measuring the divergence between logits obtained from projecting late layers of LRMs to the vocabulary space, effectively distinguishing shallow pattern-matching from genuine deep reasoning. Using this score, we conduct an in-depth analysis on the ReTruthQA dataset and identify two key reasoning hallucination patterns: early-stage fluctuation in reasoning depth and incorrect backtracking to flawed prior steps. These insights motivate our Reasoning Hallucination Detection (RHD) framework, which achieves state-of-the-art performance across multiple domains. To mitigate reasoning hallucinations, we further introduce GRPO-R, an enhanced reinforcement learning algorithm that incorporates step-level deep reasoning rewards via potential-based shaping. Our theoretical analysis establishes stronger generalization guarantees, and experiments demonstrate improved reasoning quality and reduced hallucination rates.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "25 pages",
    "pdf_url": "https://arxiv.org/pdf/2505.12886v1",
    "published_date": "2025-05-19 09:16:40 UTC",
    "updated_date": "2025-05-19 09:16:40 UTC"
  },
  {
    "arxiv_id": "2505.12884v2",
    "title": "TinyAlign: Boosting Lightweight Vision-Language Models by Mitigating Modal Alignment Bottlenecks",
    "authors": [
      "Yuanze Hu",
      "Zhaoxin Fan",
      "Xinyu Wang",
      "Gen Li",
      "Ye Qiu",
      "Zhichao Yang",
      "Wenjun Wu",
      "Kejian Wu",
      "Yifan Sun",
      "Xiaotie Deng",
      "Jin Dong"
    ],
    "abstract": "Lightweight Vision-Language Models (VLMs) are indispensable for resource-constrained applications. The prevailing approach to aligning vision and language models involves freezing both the vision encoder and the language model while training small connector modules. However, this strategy heavily depends on the intrinsic capabilities of the language model, which can be suboptimal for lightweight models with limited representational capacity. In this work, we investigate this alignment bottleneck through the lens of mutual information, demonstrating that the constrained capacity of the language model inherently limits the Effective Mutual Information (EMI) between multimodal inputs and outputs, thereby compromising alignment quality. To address this challenge, we propose TinyAlign, a novel framework inspired by Retrieval-Augmented Generation, which strategically retrieves relevant context from a memory bank to enrich multimodal inputs and enhance their alignment. Extensive empirical evaluations reveal that TinyAlign significantly reduces training loss, accelerates convergence, and enhances task performance. Remarkably, it allows models to achieve baseline-level performance with only 40\\% of the fine-tuning data, highlighting exceptional data efficiency. Our work thus offers a practical pathway for developing more capable lightweight VLMs while introducing a fresh theoretical lens to better understand and address alignment bottlenecks in constrained multimodal systems.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.12884v2",
    "published_date": "2025-05-19 09:11:54 UTC",
    "updated_date": "2025-06-30 08:29:25 UTC"
  },
  {
    "arxiv_id": "2505.12882v1",
    "title": "PhyDA: Physics-Guided Diffusion Models for Data Assimilation in Atmospheric Systems",
    "authors": [
      "Hao Wang",
      "Jindong Han",
      "Wei Fan",
      "Weijia Zhang",
      "Hao Liu"
    ],
    "abstract": "Data Assimilation (DA) plays a critical role in atmospheric science by reconstructing spatially continous estimates of the system state, which serves as initial conditions for scientific analysis. While recent advances in diffusion models have shown great potential for DA tasks, most existing approaches remain purely data-driven and often overlook the physical laws that govern complex atmospheric dynamics. As a result, they may yield physically inconsistent reconstructions that impair downstream applications. To overcome this limitation, we propose PhyDA, a physics-guided diffusion framework designed to ensure physical coherence in atmospheric data assimilation. PhyDA introduces two key components: (1) a Physically Regularized Diffusion Objective that integrates physical constraints into the training process by penalizing deviations from known physical laws expressed as partial differential equations, and (2) a Virtual Reconstruction Encoder that bridges observational sparsity for structured latent representations, further enhancing the model's ability to infer complete and physically coherent states. Experiments on the ERA5 reanalysis dataset demonstrate that PhyDA achieves superior accuracy and better physical plausibility compared to state-of-the-art baselines. Our results emphasize the importance of combining generative modeling with domain-specific physical knowledge and show that PhyDA offers a promising direction for improving real-world data assimilation systems.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.12882v1",
    "published_date": "2025-05-19 09:10:55 UTC",
    "updated_date": "2025-05-19 09:10:55 UTC"
  },
  {
    "arxiv_id": "2505.12880v1",
    "title": "AdS-GNN -- a Conformally Equivariant Graph Neural Network",
    "authors": [
      "Maksim Zhdanov",
      "Nabil Iqbal",
      "Erik Bekkers",
      "Patrick Forré"
    ],
    "abstract": "Conformal symmetries, i.e.\\ coordinate transformations that preserve angles, play a key role in many fields, including physics, mathematics, computer vision and (geometric) machine learning. Here we build a neural network that is equivariant under general conformal transformations. To achieve this, we lift data from flat Euclidean space to Anti de Sitter (AdS) space. This allows us to exploit a known correspondence between conformal transformations of flat space and isometric transformations on the AdS space. We then build upon the fact that such isometric transformations have been extensively studied on general geometries in the geometric deep learning literature. We employ message-passing layers conditioned on the proper distance, yielding a computationally efficient framework. We validate our model on tasks from computer vision and statistical physics, demonstrating strong performance, improved generalization capacities, and the ability to extract conformal data such as scaling dimensions from the trained network.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "hep-th"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.12880v1",
    "published_date": "2025-05-19 09:08:52 UTC",
    "updated_date": "2025-05-19 09:08:52 UTC"
  },
  {
    "arxiv_id": "2505.13557v1",
    "title": "AMAQA: A Metadata-based QA Dataset for RAG Systems",
    "authors": [
      "Davide Bruni",
      "Marco Avvenuti",
      "Nicola Tonellotto",
      "Maurizio Tesconi"
    ],
    "abstract": "Retrieval-augmented generation (RAG) systems are widely used in question-answering (QA) tasks, but current benchmarks lack metadata integration, hindering evaluation in scenarios requiring both textual data and external information. To address this, we present AMAQA, a new open-access QA dataset designed to evaluate tasks combining text and metadata. The integration of metadata is especially important in fields that require rapid analysis of large volumes of data, such as cybersecurity and intelligence, where timely access to relevant information is critical. AMAQA includes about 1.1 million English messages collected from 26 public Telegram groups, enriched with metadata such as timestamps, topics, emotional tones, and toxicity indicators, which enable precise and contextualized queries by filtering documents based on specific criteria. It also includes 450 high-quality QA pairs, making it a valuable resource for advancing research on metadata-driven QA and RAG systems. To the best of our knowledge, AMAQA is the first single-hop QA benchmark to incorporate metadata and labels such as topics covered in the messages. We conduct extensive tests on the benchmark, establishing a new standard for future research. We show that leveraging metadata boosts accuracy from 0.12 to 0.61, highlighting the value of structured context. Building on this, we explore several strategies to refine the LLM input by iterating over provided context and enriching it with noisy documents, achieving a further 3-point gain over the best baseline and a 14-point improvement over simple metadata filtering. The dataset is available at https://anonymous.4open.science/r/AMAQA-5D0D/",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.13557v1",
    "published_date": "2025-05-19 08:59:08 UTC",
    "updated_date": "2025-05-19 08:59:08 UTC"
  },
  {
    "arxiv_id": "2505.12872v2",
    "title": "From Grunts to Lexicons: Emergent Language from Cooperative Foraging",
    "authors": [
      "Maytus Piriyajitakonkij",
      "Rujikorn Charakorn",
      "Weicheng Tao",
      "Wei Pan",
      "Mingfei Sun",
      "Cheston Tan",
      "Mengmi Zhang"
    ],
    "abstract": "Language is a powerful communicative and cognitive tool. It enables humans to express thoughts, share intentions, and reason about complex phenomena. Despite our fluency in using and understanding language, the question of how it arises and evolves over time remains unsolved. A leading hypothesis in linguistics and anthropology posits that language evolved to meet the ecological and social demands of early human cooperation. Language did not arise in isolation, but through shared survival goals. Inspired by this view, we investigate the emergence of language in multi-agent Foraging Games. These environments are designed to reflect the cognitive and ecological constraints believed to have influenced the evolution of communication. Agents operate in a shared grid world with only partial knowledge about other agents and the environment, and must coordinate to complete games like picking up high-value targets or executing temporally ordered actions. Using end-to-end deep reinforcement learning, agents learn both actions and communication strategies from scratch. We find that agents develop communication protocols with hallmark features of natural language: arbitrariness, interchangeability, displacement, cultural transmission, and compositionality. We quantify each property and analyze how different factors, such as population size, social dynamics, and temporal dependencies, shape specific aspects of the emergent language. Our framework serves as a platform for studying how language can evolve from partial observability, temporal reasoning, and cooperative goals in embodied multi-agent settings. We will release all data, code, and models publicly.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.12872v2",
    "published_date": "2025-05-19 08:57:30 UTC",
    "updated_date": "2025-09-26 02:22:11 UTC"
  },
  {
    "arxiv_id": "2505.12871v1",
    "title": "Does Low Rank Adaptation Lead to Lower Robustness against Training-Time Attacks?",
    "authors": [
      "Zi Liang",
      "Haibo Hu",
      "Qingqing Ye",
      "Yaxin Xiao",
      "Ronghua Li"
    ],
    "abstract": "Low rank adaptation (LoRA) has emerged as a prominent technique for fine-tuning large language models (LLMs) thanks to its superb efficiency gains over previous methods. While extensive studies have examined the performance and structural properties of LoRA, its behavior upon training-time attacks remain underexplored, posing significant security risks. In this paper, we theoretically investigate the security implications of LoRA's low-rank structure during fine-tuning, in the context of its robustness against data poisoning and backdoor attacks. We propose an analytical framework that models LoRA's training dynamics, employs the neural tangent kernel to simplify the analysis of the training process, and applies information theory to establish connections between LoRA's low rank structure and its vulnerability against training-time attacks. Our analysis indicates that LoRA exhibits better robustness to backdoor attacks than full fine-tuning, while becomes more vulnerable to untargeted data poisoning due to its over-simplified information geometry. Extensive experimental evaluations have corroborated our theoretical findings.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "To appear at ICML 25",
    "pdf_url": "https://arxiv.org/pdf/2505.12871v1",
    "published_date": "2025-05-19 08:57:08 UTC",
    "updated_date": "2025-05-19 08:57:08 UTC"
  },
  {
    "arxiv_id": "2505.12869v1",
    "title": "Outsourced Privacy-Preserving Feature Selection Based on Fully Homomorphic Encryption",
    "authors": [
      "Koki Wakiyama",
      "Tomohiro I",
      "Hiroshi Sakamoto"
    ],
    "abstract": "Feature selection is a technique that extracts a meaningful subset from a set of features in training data. When the training data is large-scale, appropriate feature selection enables the removal of redundant features, which can improve generalization performance, accelerate the training process, and enhance the interpretability of the model. This study proposes a privacy-preserving computation model for feature selection. Generally, when the data owner and analyst are the same, there is no need to conceal the private information. However, when they are different parties or when multiple owners exist, an appropriate privacy-preserving framework is required. Although various private feature selection algorithms, they all require two or more computing parties and do not guarantee security in environments where no external party can be fully trusted. To address this issue, we propose the first outsourcing algorithm for feature selection using fully homomorphic encryption. Compared to a prior two-party algorithm, our result improves the time and space complexity O(kn^2) to O(kn log^3 n) and O(kn), where k and n denote the number of features and data samples, respectively. We also implemented the proposed algorithm and conducted comparative experiments with the naive one. The experimental result shows the efficiency of our method even with small datasets.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "14 pages",
    "pdf_url": "https://arxiv.org/pdf/2505.12869v1",
    "published_date": "2025-05-19 08:55:56 UTC",
    "updated_date": "2025-05-19 08:55:56 UTC"
  },
  {
    "arxiv_id": "2505.12864v6",
    "title": "LEXam: Benchmarking Legal Reasoning on 340 Law Exams",
    "authors": [
      "Yu Fan",
      "Jingwei Ni",
      "Jakob Merane",
      "Yang Tian",
      "Yoan Hermstrüwer",
      "Yinya Huang",
      "Mubashara Akhtar",
      "Etienne Salimbeni",
      "Florian Geering",
      "Oliver Dreyer",
      "Daniel Brunner",
      "Markus Leippold",
      "Mrinmaya Sachan",
      "Alexander Stremitzer",
      "Christoph Engel",
      "Elliott Ash",
      "Joel Niklaus"
    ],
    "abstract": "Long-form legal reasoning remains a key challenge for large language models (LLMs) in spite of recent advances in test-time scaling. To address this, we introduce \\textsc{LEXam}, a novel benchmark derived from 340 law exams spanning 116 law school courses across a range of subjects and degree levels. The dataset comprises 4,886 law exam questions in English and German, including 2,841 long-form, open-ended questions and 2,045 multiple-choice questions. Besides reference answers, the open questions are also accompanied by explicit guidance outlining the expected legal reasoning approach such as issue spotting, rule recall, or rule application. Our evaluation on both open-ended and multiple-choice questions present significant challenges for current LLMs; in particular, they notably struggle with open questions that require structured, multi-step legal reasoning. Moreover, our results underscore the effectiveness of the dataset in differentiating between models with varying capabilities. Deploying an ensemble LLM-as-a-Judge paradigm with rigorous human expert validation, we demonstrate how model-generated reasoning steps can be evaluated consistently and accurately, closely aligning with human expert assessments. Our evaluation setup provides a scalable method to assess legal reasoning quality beyond simple accuracy metrics. We have open-sourced our code on https://github.com/LEXam-Benchmark/LEXam and released our data on https://huggingface.co/datasets/LEXam-Benchmark/LEXam. Project page: https://lexam-benchmark.github.io.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.12864v6",
    "published_date": "2025-05-19 08:48:12 UTC",
    "updated_date": "2026-01-20 21:54:40 UTC"
  },
  {
    "arxiv_id": "2505.12863v1",
    "title": "Unified Cross-modal Translation of Score Images, Symbolic Music, and Performance Audio",
    "authors": [
      "Jongmin Jung",
      "Dongmin Kim",
      "Sihun Lee",
      "Seola Cho",
      "Hyungjoon Soh",
      "Irmak Bukey",
      "Chris Donahue",
      "Dasaem Jeong"
    ],
    "abstract": "Music exists in various modalities, such as score images, symbolic scores, MIDI, and audio. Translations between each modality are established as core tasks of music information retrieval, such as automatic music transcription (audio-to-MIDI) and optical music recognition (score image to symbolic score). However, most past work on multimodal translation trains specialized models on individual translation tasks. In this paper, we propose a unified approach, where we train a general-purpose model on many translation tasks simultaneously. Two key factors make this unified approach viable: a new large-scale dataset and the tokenization of each modality. Firstly, we propose a new dataset that consists of more than 1,300 hours of paired audio-score image data collected from YouTube videos, which is an order of magnitude larger than any existing music modal translation datasets. Secondly, our unified tokenization framework discretizes score images, audio, MIDI, and MusicXML into a sequence of tokens, enabling a single encoder-decoder Transformer to tackle multiple cross-modal translation as one coherent sequence-to-sequence task. Experimental results confirm that our unified multitask model improves upon single-task baselines in several key areas, notably reducing the symbol error rate for optical music recognition from 24.58% to a state-of-the-art 13.67%, while similarly substantial improvements are observed across the other translation tasks. Notably, our approach achieves the first successful score-image-conditioned audio generation, marking a significant breakthrough in cross-modal music generation.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CV",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Submitted to IEEE Transactions on Audio, Speech and Language Processing (TASLPRO)",
    "pdf_url": "https://arxiv.org/pdf/2505.12863v1",
    "published_date": "2025-05-19 08:46:45 UTC",
    "updated_date": "2025-05-19 08:46:45 UTC"
  },
  {
    "arxiv_id": "2505.12851v1",
    "title": "FLTG: Byzantine-Robust Federated Learning via Angle-Based Defense and Non-IID-Aware Weighting",
    "authors": [
      "Yanhua Wen",
      "Lu Ai",
      "Gang Liu",
      "Chuang Li",
      "Jianhao Wei"
    ],
    "abstract": "Byzantine attacks during model aggregation in Federated Learning (FL) threaten training integrity by manipulating malicious clients' updates. Existing methods struggle with limited robustness under high malicious client ratios and sensitivity to non-i.i.d. data, leading to degraded accuracy. To address this, we propose FLTG, a novel aggregation algorithm integrating angle-based defense and dynamic reference selection. FLTG first filters clients via ReLU-clipped cosine similarity, leveraging a server-side clean dataset to exclude misaligned updates. It then dynamically selects a reference client based on the prior global model to mitigate non-i.i.d. bias, assigns aggregation weights inversely proportional to angular deviations, and normalizes update magnitudes to suppress malicious scaling. Evaluations across datasets of varying complexity under five classic attacks demonstrate FLTG's superiority over state-of-the-art methods under extreme bias scenarios and sustains robustness with a higher proportion(over 50%) of malicious clients.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "14 pages, 5 figures, BlockSys2025",
    "pdf_url": "https://arxiv.org/pdf/2505.12851v1",
    "published_date": "2025-05-19 08:39:07 UTC",
    "updated_date": "2025-05-19 08:39:07 UTC"
  },
  {
    "arxiv_id": "2505.12845v1",
    "title": "Multi-Level Aware Preference Learning: Enhancing RLHF for Complex Multi-Instruction Tasks",
    "authors": [
      "Ruopei Sun",
      "Jianfeng Cai",
      "Jinhua Zhu",
      "Kangwen Zhao",
      "Dongyun Xue",
      "Wengang Zhou",
      "Li Li",
      "Houqiang Li"
    ],
    "abstract": "RLHF has emerged as a predominant approach for aligning artificial intelligence systems with human preferences, demonstrating exceptional and measurable efficacy in instruction following tasks; however, it exhibits insufficient compliance capabilities when confronted with complex multi-instruction tasks. Conventional approaches rely heavily on human annotation or more sophisticated large language models, thereby introducing substantial resource expenditure or potential bias concerns. Meanwhile, alternative synthetic methods that augment standard preference datasets often compromise the model's semantic quality. Our research identifies a critical oversight in existing techniques, which predominantly focus on comparing responses while neglecting valuable latent signals embedded within prompt inputs, and which only focus on preference disparities at the intra-sample level, while neglecting to account for the inter-sample level preference differentials that exist among preference data. To leverage these previously neglected indicators, we propose a novel Multi-level Aware Preference Learning (MAPL) framework, capable of enhancing multi-instruction capabilities. Specifically, for any given response in original preference data pairs, we construct varied prompts with a preference relation under different conditions, in order to learn intra-sample level preference disparities. Furthermore, for any given original preference pair, we synthesize multi-instruction preference pairs to capture preference discrepancies at the inter-sample level. Building on the two datasets constructed above, we consequently devise two sophisticated training objective functions. Subsequently, our framework integrates seamlessly into both Reward Modeling and Direct Preference Optimization paradigms. Through rigorous evaluation across multiple benchmarks, we empirically validate the efficacy of our framework.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.12845v1",
    "published_date": "2025-05-19 08:33:11 UTC",
    "updated_date": "2025-05-19 08:33:11 UTC"
  },
  {
    "arxiv_id": "2505.12844v2",
    "title": "AGI-Elo: How Far Are We From Mastering A Task?",
    "authors": [
      "Shuo Sun",
      "Yimin Zhao",
      "Christina Dao Wen Lee",
      "Jiawei Sun",
      "Chengran Yuan",
      "Zefan Huang",
      "Dongen Li",
      "Justin KW Yeoh",
      "Alok Prakash",
      "Thomas W. Malone",
      "Marcelo H. Ang"
    ],
    "abstract": "As the field progresses toward Artificial General Intelligence (AGI), there is a pressing need for more comprehensive and insightful evaluation frameworks that go beyond aggregate performance metrics. This paper introduces a unified rating system that jointly models the difficulty of individual test cases and the competency of AI models (or humans) across vision, language, and action domains. Unlike existing metrics that focus solely on models, our approach allows for fine-grained, difficulty-aware evaluations through competitive interactions between models and tasks, capturing both the long-tail distribution of real-world challenges and the competency gap between current models and full task mastery. We validate the generalizability and robustness of our system through extensive experiments on multiple established datasets and models across distinct AGI domains. The resulting rating distributions offer novel perspectives and interpretable insights into task difficulty, model progression, and the outstanding challenges that remain on the path to achieving full AGI task mastery.",
    "categories": [
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.12844v2",
    "published_date": "2025-05-19 08:30:13 UTC",
    "updated_date": "2025-05-24 05:25:10 UTC"
  },
  {
    "arxiv_id": "2505.12843v1",
    "title": "Bias Fitting to Mitigate Length Bias of Reward Model in RLHF",
    "authors": [
      "Kangwen Zhao",
      "Jianfeng Cai",
      "Jinhua Zhu",
      "Ruopei Sun",
      "Dongyun Xue",
      "Wengang Zhou",
      "Li Li",
      "Houqiang Li"
    ],
    "abstract": "Reinforcement Learning from Human Feedback relies on reward models to align large language models with human preferences. However, RLHF often suffers from reward hacking, wherein policy learning exploits flaws in the trained reward model to maximize reward scores without genuinely aligning with human preferences. A significant example of such reward hacking is length bias, where reward models usually favor longer responses irrespective of actual response quality. Previous works on length bias have notable limitations, these approaches either mitigate bias without characterizing the bias form, or simply assume a linear length-reward relation. To accurately model the intricate nature of length bias and facilitate more effective bias mitigation, we propose FiMi-RM (Bias Fitting to Mitigate Length Bias of Reward Model in RLHF), a framework that autonomously learns and corrects underlying bias patterns. Our approach consists of three stages: First, we train a standard reward model which inherently contains length bias. Next, we deploy a lightweight fitting model to explicitly capture the non-linear relation between length and reward. Finally, we incorporate this learned relation into the reward model to debias. Experimental results demonstrate that FiMi-RM achieves a more balanced length-reward distribution. Furthermore, when applied to alignment algorithms, our debiased reward model improves length-controlled win rate and reduces verbosity without compromising its performance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Due to the word limit for arXiv abstract, the abstract here has been abridged compared to the one in the PDF",
    "pdf_url": "https://arxiv.org/pdf/2505.12843v1",
    "published_date": "2025-05-19 08:29:28 UTC",
    "updated_date": "2025-05-19 08:29:28 UTC"
  },
  {
    "arxiv_id": "2505.12837v1",
    "title": "The Hidden Structure -- Improving Legal Document Understanding Through Explicit Text Formatting",
    "authors": [
      "Christian Braun",
      "Alexander Lilienbeck",
      "Daniel Mentjukov"
    ],
    "abstract": "Legal contracts possess an inherent, semantically vital structure (e.g., sections, clauses) that is crucial for human comprehension but whose impact on LLM processing remains under-explored. This paper investigates the effects of explicit input text structure and prompt engineering on the performance of GPT-4o and GPT-4.1 on a legal question-answering task using an excerpt of the CUAD. We compare model exact-match accuracy across various input formats: well-structured plain-text (human-generated from CUAD), plain-text cleaned of line breaks, extracted plain-text from Azure OCR, plain-text extracted by GPT-4o Vision, and extracted (and interpreted) Markdown (MD) from GPT-4o Vision. To give an indication of the impact of possible prompt engineering, we assess the impact of shifting task instructions to the system prompt and explicitly informing the model about the structured nature of the input. Our findings reveal that GPT-4o demonstrates considerable robustness to variations in input structure, but lacks in overall performance. Conversely, GPT-4.1's performance is markedly sensitive; poorly structured inputs yield suboptimal results (but identical with GPT-4o), while well-structured formats (original CUAD text, GPT-4o Vision text and GPT-4o MD) improve exact-match accuracy by ~20 percentage points. Optimizing the system prompt to include task details and an advisory about structured input further elevates GPT-4.1's accuracy by an additional ~10-13 percentage points, with Markdown ultimately achieving the highest performance under these conditions (79 percentage points overall exact-match accuracy). This research empirically demonstrates that while newer models exhibit greater resilience, careful input structuring and strategic prompt design remain critical for optimizing the performance of LLMs, and can significantly affect outcomes in high-stakes legal applications.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "20 pages, 3 figures",
    "pdf_url": "https://arxiv.org/pdf/2505.12837v1",
    "published_date": "2025-05-19 08:25:21 UTC",
    "updated_date": "2025-05-19 08:25:21 UTC"
  },
  {
    "arxiv_id": "2505.12833v2",
    "title": "Reasoning BO: Enhancing Bayesian Optimization with Long-Context Reasoning Power of LLMs",
    "authors": [
      "Zhuo Yang",
      "Daolang Wang",
      "Lingli Ge",
      "Beilun Wang",
      "Tianfan Fu",
      "Yuqiang Li"
    ],
    "abstract": "Many real-world scientific and industrial applications require the optimization of expensive black-box functions. Bayesian Optimization (BO) provides an effective framework for such problems. However, traditional BO methods are prone to get trapped in local optima and often lack interpretable insights. To address this issue, this paper designs Reasoning BO, a novel framework that leverages reasoning models to guide the sampling process in BO while incorporating multi-agent systems and knowledge graphs for online knowledge accumulation. By integrating the reasoning and contextual understanding capabilities of Large Language Models (LLMs), we can provide strong guidance to enhance the BO process. As the optimization progresses, Reasoning BO provides real-time sampling recommendations along with critical insights grounded in plausible scientific theories, aiding in the discovery of superior solutions within the search space. We systematically evaluate our approach across 10 diverse tasks encompassing synthetic mathematical functions and complex real-world applications. The framework demonstrates its capability to progressively refine sampling strategies through real-time insights and hypothesis evolution, effectively identifying higher-performing regions of the search space for focused exploration. This process highlights the powerful reasoning and context-learning abilities of LLMs in optimization scenarios. For example, in the Direct Arylation task, our method increased the yield to 60.7%, whereas traditional BO achieved only a 25.2% yield. Furthermore, our investigation reveals that smaller LLMs, when fine-tuned through reinforcement learning, can attain comparable performance to their larger counterparts.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.12833v2",
    "published_date": "2025-05-19 08:20:40 UTC",
    "updated_date": "2025-09-26 03:12:20 UTC"
  },
  {
    "arxiv_id": "2505.12822v2",
    "title": "Emergent Specialization: Rare Token Neurons in Language Models",
    "authors": [
      "Jing Liu",
      "Haozheng Wang",
      "Yueheng Li"
    ],
    "abstract": "Large language models struggle with representing and generating rare tokens despite their importance in specialized domains. In this study, we identify neuron structures with exceptionally strong influence on language model's prediction of rare tokens, termed as rare token neurons, and investigate the mechanism for their emergence and behavior. These neurons exhibit a characteristic three-phase organization (plateau, power-law, and rapid decay) that emerges dynamically during training, evolving from a homogeneous initial state to a functionally differentiated architecture. In the activation space, rare token neurons form a coordinated subnetwork that selectively co-activates while avoiding co-activation with other neurons. This functional specialization potentially correlates with the development of heavy-tailed weight distributions, suggesting a statistical mechanical basis for emergent specialization.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "9 pages, 6 figures",
    "pdf_url": "https://arxiv.org/pdf/2505.12822v2",
    "published_date": "2025-05-19 08:05:13 UTC",
    "updated_date": "2025-05-22 16:03:57 UTC"
  },
  {
    "arxiv_id": "2505.12821v1",
    "title": "SynDec: A Synthesize-then-Decode Approach for Arbitrary Textual Style Transfer via Large Language Models",
    "authors": [
      "Han Sun",
      "Zhen Sun",
      "Zongmin Zhang",
      "Linzhao Jia",
      "Wei Shao",
      "Min Zhang"
    ],
    "abstract": "Large Language Models (LLMs) are emerging as dominant forces for textual style transfer. However, for arbitrary style transfer, LLMs face two key challenges: (1) considerable reliance on manually-constructed prompts and (2) rigid stylistic biases inherent in LLMs. In this paper, we propose a novel Synthesize-then-Decode (SynDec) approach, which automatically synthesizes high-quality prompts and amplifies their roles during decoding process. Specifically, our approach synthesizes prompts by selecting representative few-shot samples, conducting a four-dimensional style analysis, and reranking the candidates. At LLM decoding stage, the TST effect is amplified by maximizing the contrast in output probabilities between scenarios with and without the synthesized prompt, as well as between prompts and negative samples. We conduct extensive experiments and the results show that SynDec outperforms existing state-of-the-art LLM-based methods on five out of six benchmarks (e.g., achieving up to a 9\\% increase in accuracy for modern-to-Elizabethan English transfer). Detailed ablation studies further validate the effectiveness of SynDec.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.12821v1",
    "published_date": "2025-05-19 08:03:38 UTC",
    "updated_date": "2025-05-19 08:03:38 UTC"
  },
  {
    "arxiv_id": "2505.12815v2",
    "title": "Learning In Chaos: Efficient Autoscaling and Self-Healing for Multi-Party Distributed Training",
    "authors": [
      "Wenjiao Feng",
      "Rongxing Xiao",
      "Zonghang Li",
      "Hongfang Yu",
      "Gang Sun",
      "Long Luo",
      "Mohsen Guizani",
      "Qirong Ho",
      "Steve Liu"
    ],
    "abstract": "Node and link churn in multi-party, cross-region clusters over wide-area networks (WANs) often disrupts distributed training. However, checkpoint-based recovery and cloud-centric autoscaling react slowly and assume centralized control, which is misaligned with the self-governed setup where institutions can freely join and leave. This paper proposes Chaos, a multi-party distributed training system with self-healing and autoscaling, enabling robust and elastic training under churn. It speeds up autoscaling via multi-neighbor state replication and model sharding. We formalize the sharding and assignment as a MINLP that captures WAN heterogeneity, and reduce it to a tractable MILP by analyzing its monotonicity on a divisibility chain. By establishing an equivalence, we derive a greedy algorithm that follows optimality rules and yields the optimal solution in polynomial time. Chaos uses a cluster monitor to track resource and topology changes, and handles scaling events through peer negotiation protocols, enabling fully self-governed autoscaling among institutions. Experiments show that Chaos has substantially lower scale-out delay than Pollux, Elan, and Autoscaling, and handles scale-in, connect-link, and disconnect-link events within 20ms. It also delivers the lowest idle time, showing superior resource use and scalability as the cluster grows.",
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "primary_category": "cs.DC",
    "comment": "14 pages, 16 figures",
    "pdf_url": "https://arxiv.org/pdf/2505.12815v2",
    "published_date": "2025-05-19 07:52:17 UTC",
    "updated_date": "2025-09-13 18:39:29 UTC"
  },
  {
    "arxiv_id": "2505.12814v2",
    "title": "PsyMem: Fine-grained psychological alignment and Explicit Memory Control for Advanced Role-Playing LLMs",
    "authors": [
      "Xilong Cheng",
      "Yunxiao Qin",
      "Yuting Tan",
      "Zhengnan Li",
      "Ye Wang",
      "Hongjiang Xiao",
      "Yuan Zhang"
    ],
    "abstract": "Existing LLM-based role-playing methods often rely on superficial textual descriptions or simplistic metrics, inadequately modeling both intrinsic and extrinsic character dimensions. Additionally, they typically simulate character memory with implicit model knowledge or basic retrieval augment generation without explicit memory alignment, compromising memory consistency. The two issues weaken reliability of role-playing LLMs in several applications, such as trustworthy social simulation. To address these limitations, we propose PsyMem, a novel framework integrating fine-grained psychological attributes and explicit memory control for role-playing. PsyMem supplements textual descriptions with 26 psychological indicators to detailed model character. Additionally, PsyMem implements memory alignment training, explicitly trains the model to align character's response with memory, thereby enabling dynamic memory-controlled responding during inference. By training Qwen2.5-7B-Instruct on our specially designed dataset (including 5,414 characters and 38,962 dialogues extracted from novels), the resulting model, termed as PsyMem-Qwen, outperforms baseline models in role-playing, achieving the best performance in human-likeness and character fidelity.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Pre-MIT Press publication version, has been accepted by TACL",
    "pdf_url": "https://arxiv.org/pdf/2505.12814v2",
    "published_date": "2025-05-19 07:45:09 UTC",
    "updated_date": "2025-10-20 14:52:07 UTC"
  },
  {
    "arxiv_id": "2505.12811v1",
    "title": "Dynamic Sight Range Selection in Multi-Agent Reinforcement Learning",
    "authors": [
      "Wei-Chen Liao",
      "Ti-Rong Wu",
      "I-Chen Wu"
    ],
    "abstract": "Multi-agent reinforcement Learning (MARL) is often challenged by the sight range dilemma, where agents either receive insufficient or excessive information from their environment. In this paper, we propose a novel method, called Dynamic Sight Range Selection (DSR), to address this issue. DSR utilizes an Upper Confidence Bound (UCB) algorithm and dynamically adjusts the sight range during training. Experiment results show several advantages of using DSR. First, we demonstrate using DSR achieves better performance in three common MARL environments, including Level-Based Foraging (LBF), Multi-Robot Warehouse (RWARE), and StarCraft Multi-Agent Challenge (SMAC). Second, our results show that DSR consistently improves performance across multiple MARL algorithms, including QMIX and MAPPO. Third, DSR offers suitable sight ranges for different training steps, thereby accelerating the training process. Finally, DSR provides additional interpretability by indicating the optimal sight range used during training. Unlike existing methods that rely on global information or communication mechanisms, our approach operates solely based on the individual sight ranges of agents. This approach offers a practical and efficient solution to the sight range dilemma, making it broadly applicable to real-world complex environments.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.MA",
    "comment": "Accepted at AAMAS 2025. The compiled PDF includes the appendix",
    "pdf_url": "https://arxiv.org/pdf/2505.12811v1",
    "published_date": "2025-05-19 07:40:42 UTC",
    "updated_date": "2025-05-19 07:40:42 UTC"
  },
  {
    "arxiv_id": "2505.12805v2",
    "title": "FedSVD: Adaptive Orthogonalization for Private Federated Learning with LoRA",
    "authors": [
      "Seanie Lee",
      "Sangwoo Park",
      "Dong Bok Lee",
      "Dominik Wagner",
      "Haebin Seong",
      "Tobias Bocklet",
      "Juho Lee",
      "Sung Ju Hwang"
    ],
    "abstract": "Low-Rank Adaptation (LoRA), which introduces a product of two trainable low-rank matrices into frozen pre-trained weights, is widely used for efficient fine-tuning of language models in federated learning (FL). However, when combined with differentially private stochastic gradient descent (DP-SGD), LoRA faces substantial noise amplification: DP-SGD perturbs per-sample gradients, and the matrix multiplication of the LoRA update ($BA$) intensifies this effect. Freezing one matrix (e.g., $A$) reduces the noise but restricts model expressiveness, often resulting in suboptimal adaptation. To address this, we propose $\\texttt{FedSVD}$, a simple yet effective method that introduces a global reparameterization based on singular value decomposition (SVD). In our approach, each client optimizes only the $B$ matrix and transmits it to the server. The server aggregates the $B$ matrices, computes the product $BA$ using the previous $A$, and refactorizes the result via SVD. This yields a new adaptive $A$ composed of the orthonormal right singular vectors of $BA$, and an updated $B$ containing the remaining SVD components. This reparameterization avoids quadratic noise amplification, while allowing $A$ to better capture the principal directions of the aggregate updates. Moreover, the orthonormal structure of $A$ bounds the gradient norms of $B$ and preserves more signal under DP-SGD, as confirmed by our theoretical analysis. As a result, $\\texttt{FedSVD}$ consistently improves stability and performance across a variety of privacy settings and benchmarks, outperforming relevant baselines under both private and non-private regimes.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "NeurIPS 2025",
    "pdf_url": "https://arxiv.org/pdf/2505.12805v2",
    "published_date": "2025-05-19 07:32:56 UTC",
    "updated_date": "2025-10-25 06:07:40 UTC"
  },
  {
    "arxiv_id": "2505.12800v1",
    "title": "OZSpeech: One-step Zero-shot Speech Synthesis with Learned-Prior-Conditioned Flow Matching",
    "authors": [
      "Hieu-Nghia Huynh-Nguyen",
      "Ngoc Son Nguyen",
      "Huynh Nguyen Dang",
      "Thieu Vo",
      "Truong-Son Hy",
      "Van Nguyen"
    ],
    "abstract": "Text-to-speech (TTS) systems have seen significant advancements in recent years, driven by improvements in deep learning and neural network architectures. Viewing the output speech as a data distribution, previous approaches often employ traditional speech representations, such as waveforms or spectrograms, within the Flow Matching framework. However, these methods have limitations, including overlooking various speech attributes and incurring high computational costs due to additional constraints introduced during training. To address these challenges, we introduce OZSpeech, the first TTS method to explore optimal transport conditional flow matching with one-step sampling and a learned prior as the condition, effectively disregarding preceding states and reducing the number of sampling steps. Our approach operates on disentangled, factorized components of speech in token format, enabling accurate modeling of each speech attribute, which enhances the TTS system's ability to precisely clone the prompt speech. Experimental results show that our method achieves promising performance over existing methods in content accuracy, naturalness, prosody generation, and speaker style preservation. Audio samples are available at our demo page https://ozspeech.github.io/OZSpeech_Web/.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.12800v1",
    "published_date": "2025-05-19 07:31:55 UTC",
    "updated_date": "2025-05-19 07:31:55 UTC"
  },
  {
    "arxiv_id": "2505.12795v4",
    "title": "FRABench and UFEval: Unified Fine-grained Evaluation with Task and Aspect Generalization",
    "authors": [
      "Shibo Hong",
      "Jiahao Ying",
      "Haiyuan Liang",
      "Mengdi Zhang",
      "Jun Kuang",
      "Jiazheng Zhang",
      "Yixin Cao"
    ],
    "abstract": "Evaluating open-ended outputs of Multimodal Large Language Models has become a bottleneck as model capabilities, task diversity, and modality rapidly expand. Existing ``MLLM-as-a-Judge'' evaluators, though promising, remain constrained to specific tasks and aspects. In this paper, we argue that, on one hand, based on the interconnected nature of aspects, learning specific aspects can generalize to unseen aspects; on the other hand, jointly learning to assess multiple visual aspects and tasks may foster a synergistic effect. To this end, we propose UFEval, the first unified fine-grained evaluator with task and aspect generalization for four evaluation tasks -- Natural Language Generation, Image Understanding, Image Generation, and Interleaved Text-and-Image Generation. However, training such a unified evaluator is hindered by the lack of a large-scale, multi-modal, and aspect-level resource. To address this gap, we introduce FRABench, a comprehensive fine-grained evaluation dataset. Specifically, (1) We first construct a hierarchical aspect taxonomy encompassing 112 distinct aspects across the aforementioned four tasks. (2) Based on this taxonomy, we create FRABench, comprising 60.4k pairwise samples with 325k evaluation labels obtained from a combination of human and GPT-4o annotations. (3) Finally, leveraging FRABench, we develop UFEval, a unified fine-grained evaluator. Experiments show that learning on specific aspects enables UFEval to generalize to unseen aspects, and joint learning to assess diverse visual tasks and aspects can lead to substantial mutual benefits.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.12795v4",
    "published_date": "2025-05-19 07:29:26 UTC",
    "updated_date": "2025-09-29 16:11:09 UTC"
  },
  {
    "arxiv_id": "2505.12788v1",
    "title": "Mixture Policy based Multi-Hop Reasoning over N-tuple Temporal Knowledge Graphs",
    "authors": [
      "Zhongni Hou",
      "Miao Su",
      "Xiaolong Jin",
      "Zixuan Li",
      "Long Bai",
      "Jiafeng Guo",
      "Xueqi Cheng"
    ],
    "abstract": "Temporal Knowledge Graphs (TKGs), which utilize quadruples in the form of (subject, predicate, object, timestamp) to describe temporal facts, have attracted extensive attention. N-tuple TKGs (N-TKGs) further extend traditional TKGs by utilizing n-tuples to incorporate auxiliary elements alongside core elements (i.e., subject, predicate, and object) of facts, so as to represent them in a more fine-grained manner. Reasoning over N-TKGs aims to predict potential future facts based on historical ones. However, existing N-TKG reasoning methods often lack explainability due to their black-box nature. Therefore, we introduce a new Reinforcement Learning-based method, named MT-Path, which leverages the temporal information to traverse historical n-tuples and construct a temporal reasoning path. Specifically, in order to integrate the information encapsulated within n-tuples, i.e., the entity-irrelevant information within the predicate, the information about core elements, and the complete information about the entire n-tuples, MT-Path utilizes a mixture policy-driven action selector, which bases on three low-level policies, namely, the predicate-focused policy, the core-element-focused policy and the whole-fact-focused policy. Further, MT-Path utilizes an auxiliary element-aware GCN to capture the rich semantic dependencies among facts, thereby enabling the agent to gain a deep understanding of each n-tuple. Experimental results demonstrate the effectiveness and the explainability of MT-Path.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.12788v1",
    "published_date": "2025-05-19 07:20:33 UTC",
    "updated_date": "2025-05-19 07:20:33 UTC"
  },
  {
    "arxiv_id": "2505.12781v4",
    "title": "A Token is Worth over 1,000 Tokens: Efficient Knowledge Distillation through Low-Rank Clone",
    "authors": [
      "Jitai Hao",
      "Qiang Huang",
      "Hao Liu",
      "Xinyan Xiao",
      "Zhaochun Ren",
      "Jun Yu"
    ],
    "abstract": "Training high-performing Small Language Models (SLMs) remains costly, even with knowledge distillation and pruning from larger teacher models. Existing work often faces three key challenges: (1) information loss from hard pruning, (2) inefficient alignment of representations, and (3) underutilization of informative activations, particularly from Feed-Forward Networks (FFNs). To address these challenges, we introduce Low-Rank Clone (LRC), an efficient pre-training method that constructs SLMs aspiring to behavioral equivalence with strong teacher models. LRC trains a set of low-rank projection matrices that jointly enable soft pruning by compressing teacher weights, and activation clone by aligning student activations, including FFN signals, with those of the teacher. This unified design maximizes knowledge transfer while removing the need for explicit alignment modules. Extensive experiments with open-source teachers (e.g., Llama-3.2-3B-Instruct, Qwen2.5-3B/7B-Instruct) show that LRC matches or surpasses state-of-the-art models trained on trillions of tokens--while using only 20B tokens, achieving over 1,000x training efficiency. Our codes and model checkpoints are available at https://github.com/CURRENTF/LowRankClone and https://huggingface.co/collections/JitaiHao/low-rank-clone-lrc-6828389e96a93f1d4219dfaf.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "NeurIPS 2025 Spotlight",
    "pdf_url": "https://arxiv.org/pdf/2505.12781v4",
    "published_date": "2025-05-19 07:10:42 UTC",
    "updated_date": "2025-12-18 12:54:34 UTC"
  },
  {
    "arxiv_id": "2505.20306v2",
    "title": "Multi-Modal Artificial Intelligence of Embryo Grading and Pregnancy Prediction in Assisted Reproductive Technology: A Review",
    "authors": [
      "Xueqiang Ouyang",
      "Jia Wei"
    ],
    "abstract": "Infertility, a pressing global health concern, affects a substantial proportion of individuals worldwide. While advancements in assisted reproductive technology (ART) have offered effective interventions, conventional in vitro fertilization-embryo transfer (IVF-ET) procedures still encounter significant hurdles in enhancing pregnancy success rates. Key challenges include the inherent subjectivity in embryo grading and the inefficiency of multi-modal data integration. Against this backdrop, the adoption of AI-driven technologies has emerged as a pivotal strategy to address these issues. This article presents a comprehensive review of the progress in AI applications for embryo grading and pregnancy prediction from a novel perspective, with a specific focus on the utilization of different modal data, such as static images, time-lapse videos, and structured tabular data. The reason for this perspective is that reorganizing tasks based on data sources can not only more accurately depict the essence of the problem but also help clarify the rationality and limitations of model design. Furthermore, this review critically examines the core challenges in contemporary research, encompassing the intricacies of multi-modal feature fusion, constraints imposed by data scarcity, limitations in model generalization capabilities, and the dynamically evolving legal and regulatory frameworks. On this basis, it explicitly identifies potential avenues for future research, aiming to provide actionable guidance for advancing the application of multi-modal AI in the field of ART.",
    "categories": [
      "cs.AI",
      "eess.IV",
      "q-bio.QM"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.20306v2",
    "published_date": "2025-05-19 07:07:13 UTC",
    "updated_date": "2025-09-24 11:44:12 UTC"
  },
  {
    "arxiv_id": "2505.12774v1",
    "title": "UniHM: Universal Human Motion Generation with Object Interactions in Indoor Scenes",
    "authors": [
      "Zichen Geng",
      "Zeeshan Hayder",
      "Wei Liu",
      "Ajmal Mian"
    ],
    "abstract": "Human motion synthesis in complex scenes presents a fundamental challenge, extending beyond conventional Text-to-Motion tasks by requiring the integration of diverse modalities such as static environments, movable objects, natural language prompts, and spatial waypoints. Existing language-conditioned motion models often struggle with scene-aware motion generation due to limitations in motion tokenization, which leads to information loss and fails to capture the continuous, context-dependent nature of 3D human movement. To address these issues, we propose UniHM, a unified motion language model that leverages diffusion-based generation for synthesizing scene-aware human motion. UniHM is the first framework to support both Text-to-Motion and Text-to-Human-Object Interaction (HOI) in complex 3D scenes. Our approach introduces three key contributions: (1) a mixed-motion representation that fuses continuous 6DoF motion with discrete local motion tokens to improve motion realism; (2) a novel Look-Up-Free Quantization VAE (LFQ-VAE) that surpasses traditional VQ-VAEs in both reconstruction accuracy and generative performance; and (3) an enriched version of the Lingo dataset augmented with HumanML3D annotations, providing stronger supervision for scene-specific motion learning. Experimental results demonstrate that UniHM achieves comparative performance on the OMOMO benchmark for text-to-HOI synthesis and yields competitive results on HumanML3D for general text-conditioned motion generation.",
    "categories": [
      "cs.GR",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.GR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.12774v1",
    "published_date": "2025-05-19 07:02:12 UTC",
    "updated_date": "2025-05-19 07:02:12 UTC"
  },
  {
    "arxiv_id": "2505.13554v1",
    "title": "Combining the Best of Both Worlds: A Method for Hybrid NMT and LLM Translation",
    "authors": [
      "Zhanglin Wu",
      "Daimeng Wei",
      "Xiaoyu Chen",
      "Hengchao Shang",
      "Jiaxin Guo",
      "Zongyao Li",
      "Yuanchang Luo",
      "Jinlong Yang",
      "Zhiqiang Rao",
      "Hao Yang"
    ],
    "abstract": "Large language model (LLM) shows promising performances in a variety of downstream tasks, such as machine translation (MT). However, using LLMs for translation suffers from high computational costs and significant latency. Based on our evaluation, in most cases, translations using LLMs are comparable to that generated by neural machine translation (NMT) systems. Only in particular scenarios, LLM and NMT models show respective advantages. As a result, integrating NMT and LLM for translation and using LLM only when necessary seems to be a sound solution. A scheduling policy that optimizes translation result while ensuring fast speed and as little LLM usage as possible is thereby required. We compare several scheduling policies and propose a novel and straightforward decider that leverages source sentence features. We conduct extensive experiments on multilingual test sets and the result shows that we can achieve optimal translation performance with minimal LLM usage, demonstrating effectiveness of our decider.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "9 pages, 2 figures, 9 tables, ACL 2025",
    "pdf_url": "https://arxiv.org/pdf/2505.13554v1",
    "published_date": "2025-05-19 06:50:52 UTC",
    "updated_date": "2025-05-19 06:50:52 UTC"
  },
  {
    "arxiv_id": "2505.12767v1",
    "title": "Language Models That Walk the Talk: A Framework for Formal Fairness Certificates",
    "authors": [
      "Danqing Chen",
      "Tobias Ladner",
      "Ahmed Rayen Mhadhbi",
      "Matthias Althoff"
    ],
    "abstract": "As large language models become integral to high-stakes applications, ensuring their robustness and fairness is critical. Despite their success, large language models remain vulnerable to adversarial attacks, where small perturbations, such as synonym substitutions, can alter model predictions, posing risks in fairness-critical areas, such as gender bias mitigation, and safety-critical areas, such as toxicity detection. While formal verification has been explored for neural networks, its application to large language models remains limited. This work presents a holistic verification framework to certify the robustness of transformer-based language models, with a focus on ensuring gender fairness and consistent outputs across different gender-related terms. Furthermore, we extend this methodology to toxicity detection, offering formal guarantees that adversarially manipulated toxic inputs are consistently detected and appropriately censored, thereby ensuring the reliability of moderation systems. By formalizing robustness within the embedding space, this work strengthens the reliability of language models in ethical AI deployment and content moderation.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.12767v1",
    "published_date": "2025-05-19 06:46:17 UTC",
    "updated_date": "2025-05-19 06:46:17 UTC"
  },
  {
    "arxiv_id": "2505.12763v1",
    "title": "Rethinking Reward Model Evaluation Through the Lens of Reward Overoptimization",
    "authors": [
      "Sunghwan Kim",
      "Dongjin Kang",
      "Taeyoon Kwon",
      "Hyungjoo Chae",
      "Dongha Lee",
      "Jinyoung Yeo"
    ],
    "abstract": "Reward models (RMs) play a crucial role in reinforcement learning from human feedback (RLHF), aligning model behavior with human preferences. However, existing benchmarks for reward models show a weak correlation with the performance of optimized policies, suggesting that they fail to accurately assess the true capabilities of RMs. To bridge this gap, we explore several evaluation designs through the lens of reward overoptimization\\textemdash a phenomenon that captures both how well the reward model aligns with human preferences and the dynamics of the learning signal it provides to the policy. The results highlight three key findings on how to construct a reliable benchmark: (i) it is important to minimize differences between chosen and rejected responses beyond correctness, (ii) evaluating reward models requires multiple comparisons across a wide range of chosen and rejected responses, and (iii) given that reward models encounter responses with diverse representations, responses should be sourced from a variety of models. However, we also observe that a extremely high correlation with degree of overoptimization leads to comparatively lower correlation with certain downstream performance. Thus, when designing a benchmark, it is desirable to use the degree of overoptimization as a useful tool, rather than the end goal.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to ACL 2025",
    "pdf_url": "https://arxiv.org/pdf/2505.12763v1",
    "published_date": "2025-05-19 06:43:08 UTC",
    "updated_date": "2025-05-19 06:43:08 UTC"
  },
  {
    "arxiv_id": "2505.12762v1",
    "title": "IDEAL: Data Equilibrium Adaptation for Multi-Capability Language Model Alignment",
    "authors": [
      "Chenlin Ming",
      "Chendi Qu",
      "Mengzhang Cai",
      "Qizhi Pei",
      "Zhuoshi Pan",
      "Yu Li",
      "Xiaoming Duan",
      "Lijun Wu",
      "Conghui He"
    ],
    "abstract": "Large Language Models (LLMs) have achieved impressive performance through Supervised Fine-tuning (SFT) on diverse instructional datasets. When training on multiple capabilities simultaneously, the mixture training dataset, governed by volumes of data from different domains, is a critical factor that directly impacts the final model's performance. Unlike many studies that focus on enhancing the quality of training datasets through data selection methods, few works explore the intricate relationship between the compositional quantity of mixture training datasets and the emergent capabilities of LLMs. Given the availability of a high-quality multi-domain training dataset, understanding the impact of data from each domain on the model's overall capabilities is crucial for preparing SFT data and training a well-balanced model that performs effectively across diverse domains. In this work, we introduce IDEAL, an innovative data equilibrium adaptation framework designed to effectively optimize volumes of data from different domains within mixture SFT datasets, thereby enhancing the model's alignment and performance across multiple capabilities. IDEAL employs a gradient-based approach to iteratively refine the training data distribution, dynamically adjusting the volumes of domain-specific data based on their impact on downstream task performance. By leveraging this adaptive mechanism, IDEAL ensures a balanced dataset composition, enabling the model to achieve robust generalization and consistent proficiency across diverse tasks. Experiments across different capabilities demonstrate that IDEAL outperforms conventional uniform data allocation strategies, achieving a comprehensive improvement of approximately 7% in multi-task evaluation scores.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.12762v1",
    "published_date": "2025-05-19 06:42:44 UTC",
    "updated_date": "2025-05-19 06:42:44 UTC"
  },
  {
    "arxiv_id": "2505.12761v3",
    "title": "Enhancing Channel-Independent Time Series Forecasting via Cross-Variate Patch Embedding",
    "authors": [
      "Donghwa Shin",
      "Edwin Zhang"
    ],
    "abstract": "Transformers have recently gained popularity in time series forecasting due to their ability to capture long-term dependencies. However, many existing models focus only on capturing temporal dependencies while omitting intricate relationships between variables. Recent models have tried tackling this by explicitly modeling both cross-time and cross-variate dependencies through a sequential or unified attention mechanism, but they are entirely channel dependent (CD) across all layers, making them potentially susceptible to overfitting. To address this, we propose Cross-Variate Patch Embeddings (CVPE), a lightweight CD module that injects cross-variate context into channel-independent (CI) models by simply modifying the patch embedding process. We achieve this by adding a learnable positional encoding and a lightweight router-attention block to the vanilla patch embedding layer. We then integrate CVPE into Time-LLM, a multimodal CI forecasting model, to demonstrate its effectiveness in capturing cross-variate dependencies and enhance the CI model's performance. Extensive experimental results on seven real-world datasets show that our enhanced Time-LLM outperforms the original baseline model simply by incorporating the CVPE module, with no other changes.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Added link to code implementation in PDF abstract",
    "pdf_url": "https://arxiv.org/pdf/2505.12761v3",
    "published_date": "2025-05-19 06:41:14 UTC",
    "updated_date": "2025-05-22 23:29:44 UTC"
  },
  {
    "arxiv_id": "2507.18454v1",
    "title": "Sandwich: Separating Prefill-Decode Compilation for Efficient CPU LLM Serving",
    "authors": [
      "Juntao Zhao",
      "Jiuru Li",
      "Chuan Wu"
    ],
    "abstract": "Utilizing CPUs to serve large language models (LLMs) is a resource-friendly alternative to GPU serving. Existing CPU-based solutions ignore workload differences between the prefill and the decode phases of LLM inference, applying a static per-NUMA (Non-Uniform Memory Access) node model partition and utilizing vendor libraries for operator-level execution, which is suboptimal. We propose Sandwich, a hardware-centric CPU-based LLM serving engine that uses different execution plans for the prefill and decode phases and optimizes them separately.\n  We evaluate Sandwich across diverse baselines and datasets on five CPU platforms, including x86 with AVX-2 and AVX-512, as well as ARM with NEON. Sandwich achieves an average 2.01x throughput improvement and 90% satisfactory time-to-first-token (TTFT) and time-per-output-token (TPOT) latencies with up to 3.40x lower requirements in single sequence serving, and significant improvement in Goodput in continuous-batching serving. The GEMM kernels generated by Sandwich outperform representative vendor kernels and other dynamic shape solutions, achieving performance comparable to static compilers with three orders of magnitude less kernel tuning costs.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.DC",
      "cs.PL"
    ],
    "primary_category": "cs.AR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.18454v1",
    "published_date": "2025-05-19 06:37:29 UTC",
    "updated_date": "2025-05-19 06:37:29 UTC"
  },
  {
    "arxiv_id": "2506.13769v1",
    "title": "Non-planar Object Detection and Identification by Features Matching and Triangulation Growth",
    "authors": [
      "Filippo Leveni"
    ],
    "abstract": "Object detection and identification is surely a fundamental topic in the computer vision field; it plays a crucial role in many applications such as object tracking, industrial robots control, image retrieval, etc. We propose a feature-based approach for detecting and identifying distorted occurrences of a given template in a scene image by incremental grouping of feature matches between the image and the template. For this purpose, we consider the Delaunay triangulation of template features as an useful tool through which to be guided in this iterative approach. The triangulation is treated as a graph and, starting from a single triangle, neighboring nodes are considered and the corresponding features are identified; then matches related to them are evaluated to determine if they are worthy to be grouped. This evaluation is based on local consistency criteria derived from geometric and photometric properties of local features. Our solution allows the identification of the object in situations where geometric models (e.g. homography) does not hold, thus enable the detection of objects such that the template is non planar or when it is planar but appears distorted in the image. We show that our approach performs just as well or better than application of homography-based RANSAC in scenarios in which distortion is nearly absent, while when the deformation becomes relevant our method shows better description performance.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Master's thesis at Politecnico di Milano",
    "pdf_url": "https://arxiv.org/pdf/2506.13769v1",
    "published_date": "2025-05-19 06:20:07 UTC",
    "updated_date": "2025-05-19 06:20:07 UTC"
  },
  {
    "arxiv_id": "2505.12751v1",
    "title": "Structure-based Anomaly Detection and Clustering",
    "authors": [
      "Filippo Leveni"
    ],
    "abstract": "Anomaly detection is a fundamental problem in domains such as healthcare, manufacturing, and cybersecurity. This thesis proposes new unsupervised methods for anomaly detection in both structured and streaming data settings. In the first part, we focus on structure-based anomaly detection, where normal data follows low-dimensional manifolds while anomalies deviate from them. We introduce Preference Isolation Forest (PIF), which embeds data into a high-dimensional preference space via manifold fitting, and isolates outliers using two variants: Voronoi-iForest, based on geometric distances, and RuzHash-iForest, leveraging Locality Sensitive Hashing for scalability. We also propose Sliding-PIF, which captures local manifold information for streaming scenarios. Our methods outperform existing techniques on synthetic and real datasets. We extend this to structure-based clustering with MultiLink, a novel method for recovering multiple geometric model families in noisy data. MultiLink merges clusters via a model-aware linkage strategy, enabling robust multi-class structure recovery. It offers key advantages over existing approaches, such as speed, reduced sensitivity to thresholds, and improved robustness to poor initial sampling. The second part of the thesis addresses online anomaly detection in evolving data streams. We propose Online Isolation Forest (Online-iForest), which uses adaptive, multi-resolution histograms and dynamically updates tree structures to track changes over time. It avoids retraining while achieving accuracy comparable to offline models, with superior efficiency for real-time applications. Finally, we tackle anomaly detection in cybersecurity via open-set recognition for malware classification. We enhance a Gradient Boosting classifier with MaxLogit to detect unseen malware families, a method now integrated into Cleafy's production system.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Doctoral dissertation at Politecnico di Milano",
    "pdf_url": "https://arxiv.org/pdf/2505.12751v1",
    "published_date": "2025-05-19 06:20:00 UTC",
    "updated_date": "2025-05-19 06:20:00 UTC"
  },
  {
    "arxiv_id": "2505.12750v1",
    "title": "Malware families discovery via Open-Set Recognition on Android manifest permissions",
    "authors": [
      "Filippo Leveni",
      "Matteo Mistura",
      "Francesco Iubatti",
      "Carmine Giangregorio",
      "Nicolò Pastore",
      "Cesare Alippi",
      "Giacomo Boracchi"
    ],
    "abstract": "Malware are malicious programs that are grouped into families based on their penetration technique, source code, and other characteristics. Classifying malware programs into their respective families is essential for building effective defenses against cyber threats. Machine learning models have a huge potential in malware detection on mobile devices, as malware families can be recognized by classifying permission data extracted from Android manifest files. Still, the malware classification task is challenging due to the high-dimensional nature of permission data and the limited availability of training samples. In particular, the steady emergence of new malware families makes it impossible to acquire a comprehensive training set covering all the malware classes. In this work, we present a malware classification system that, on top of classifying known malware, detects new ones. In particular, we combine an open-set recognition technique developed within the computer vision community, namely MaxLogit, with a tree-based Gradient Boosting classifier, which is particularly effective in classifying high-dimensional data. Our solution turns out to be very practical, as it can be seamlessly employed in a standard classification workflow, and efficient, as it adds minimal computational overhead. Experiments on public and proprietary datasets demonstrate the potential of our solution, which has been deployed in a business environment.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "Submitted to European Conference on Artificial Intelligence (ECAI 2025)",
    "pdf_url": "https://arxiv.org/pdf/2505.12750v1",
    "published_date": "2025-05-19 06:19:54 UTC",
    "updated_date": "2025-05-19 06:19:54 UTC"
  },
  {
    "arxiv_id": "2505.12748v2",
    "title": "TeleOpBench: A Simulator-Centric Benchmark for Dual-Arm Dexterous Teleoperation",
    "authors": [
      "Hangyu Li",
      "Qin Zhao",
      "Haoran Xu",
      "Xinyu Jiang",
      "Qingwei Ben",
      "Feiyu Jia",
      "Haoyu Zhao",
      "Liang Xu",
      "Jia Zeng",
      "Hanqing Wang",
      "Bo Dai",
      "Junting Dong",
      "Jiangmiao Pang"
    ],
    "abstract": "Teleoperation is a cornerstone of embodied-robot learning, and bimanual dexterous teleoperation in particular provides rich demonstrations that are difficult to obtain with fully autonomous systems. While recent studies have proposed diverse hardware pipelines-ranging from inertial motion-capture gloves to exoskeletons and vision-based interfaces-there is still no unified benchmark that enables fair, reproducible comparison of these systems. In this paper, we introduce TeleOpBench, a simulator-centric benchmark tailored to bimanual dexterous teleoperation. TeleOpBench contains 30 high-fidelity task environments that span pick-and-place, tool use, and collaborative manipulation, covering a broad spectrum of kinematic and force-interaction difficulty. Within this benchmark we implement four representative teleoperation modalities-(i) MoCap, (ii) VR device, (iii) arm-hand exoskeletons, and (iv) monocular vision tracking-and evaluate them with a common protocol and metric suite. To validate that performance in simulation is predictive of real-world behavior, we conduct mirrored experiments on a physical dual-arm platform equipped with two 6-DoF dexterous hands. Across 10 held-out tasks we observe a strong correlation between simulator and hardware performance, confirming the external validity of TeleOpBench. TeleOpBench establishes a common yardstick for teleoperation research and provides an extensible platform for future algorithmic and hardware innovation. Codes is now available at https://github.com/cyjdlhy/TeleOpBench .",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.RO",
    "comment": "Project page:https://gorgeous2002.github.io/TeleOpBench/, Codes:https://github.com/cyjdlhy/TeleOpBench",
    "pdf_url": "https://arxiv.org/pdf/2505.12748v2",
    "published_date": "2025-05-19 06:08:53 UTC",
    "updated_date": "2025-09-15 08:42:29 UTC"
  },
  {
    "arxiv_id": "2505.12746v2",
    "title": "Correspondence of high-dimensional emotion structures elicited by video clips between humans and Multimodal LLMs",
    "authors": [
      "Haruka Asanuma",
      "Naoko Koide-Majima",
      "Ken Nakamura",
      "Takato Horii",
      "Shinji Nishimoto",
      "Masafumi Oizumi"
    ],
    "abstract": "Recent studies have revealed that human emotions exhibit a high-dimensional, complex structure. A full capturing of this complexity requires new approaches, as conventional models that disregard high dimensionality risk overlooking key nuances of human emotions. Here, we examined the extent to which the latest generation of rapidly evolving Multimodal Large Language Models (MLLMs) capture these high-dimensional, intricate emotion structures, including capabilities and limitations. Specifically, we compared self-reported emotion ratings from participants watching videos with model-generated estimates (e.g., Gemini or GPT). We evaluated performance not only at the individual video level but also from emotion structures that account for inter-video relationships. At the level of simple correlation between emotion structures, our results demonstrated strong similarity between human and model-inferred emotion structures. To further explore whether the similarity between humans and models is at the signle item level or the coarse-categorical level, we applied Gromov Wasserstein Optimal Transport. We found that although performance was not necessarily high at the strict, single-item level, performance across video categories that elicit similar emotions was substantial, indicating that the model could infer human emotional experiences at the category level. Our results suggest that current state-of-the-art MLLMs broadly capture the complex high-dimensional emotion structures at the category level, as well as their apparent limitations in accurately capturing entire structures at the single-item level.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "25 pages, 7 figures",
    "pdf_url": "https://arxiv.org/pdf/2505.12746v2",
    "published_date": "2025-05-19 06:03:22 UTC",
    "updated_date": "2025-05-23 05:15:14 UTC"
  },
  {
    "arxiv_id": "2505.12745v1",
    "title": "PEER pressure: Model-to-Model Regularization for Single Source Domain Generalization",
    "authors": [
      "Dong Kyu Cho",
      "Inwoo Hwang",
      "Sanghack Lee"
    ],
    "abstract": "Data augmentation is a popular tool for single source domain generalization, which expands the source domain by generating simulated ones, improving generalization on unseen target domains. In this work, we show that the performance of such augmentation-based methods in the target domains universally fluctuates during training, posing challenges in model selection under realistic scenarios. We argue that the fluctuation stems from the inability of the model to accumulate the knowledge learned from diverse augmentations, exacerbating feature distortion during training. Based on this observation, we propose a novel generalization method, coined Parameter-Space Ensemble with Entropy Regularization (PEER), that uses a proxy model to learn the augmented data on behalf of the main model. The main model is updated by averaging its parameters with the proxy model, progressively accumulating knowledge over the training steps. Maximizing the mutual information between the output representations of the two models guides the learning process of the proxy model, mitigating feature distortion during training. Experimental results demonstrate the effectiveness of PEER in reducing the OOD performance fluctuation and enhancing generalization across various datasets, including PACS, Digits, Office-Home, and VLCS. Notably, our method with simple random augmentation achieves state-of-the-art performance, surpassing prior approaches on sDG that utilize complex data augmentation strategies.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "21 pages, 9 figures, Accepted at CVPR 2025",
    "pdf_url": "https://arxiv.org/pdf/2505.12745v1",
    "published_date": "2025-05-19 06:01:11 UTC",
    "updated_date": "2025-05-19 06:01:11 UTC"
  },
  {
    "arxiv_id": "2505.12744v1",
    "title": "Incentivizing Multimodal Reasoning in Large Models for Direct Robot Manipulation",
    "authors": [
      "Weiliang Tang",
      "Dong Jing",
      "Jia-Hui Pan",
      "Zhiwu Lu",
      "Yun-Hui Liu",
      "Li Erran Li",
      "Mingyu Ding",
      "Chi-Wing Fu"
    ],
    "abstract": "Recent Large Multimodal Models have demonstrated remarkable reasoning capabilities, especially in solving complex mathematical problems and realizing accurate spatial perception. Our key insight is that these emerging abilities can naturally extend to robotic manipulation by enabling LMMs to directly infer the next goal in language via reasoning, rather than relying on a separate action head. However, this paradigm meets two main challenges: i) How to make LMMs understand the spatial action space, and ii) How to fully exploit the reasoning capacity of LMMs in solving these tasks. To tackle the former challenge, we propose a novel task formulation, which inputs the current states of object parts and the gripper, and reformulates rotation by a new axis representation instead of traditional Euler angles. This representation is more compatible with spatial reasoning and easier to interpret within a unified language space. For the latter challenge, we design a pipeline to utilize cutting-edge LMMs to generate a small but high-quality reasoning dataset of multi-round dialogues that successfully solve manipulation tasks for supervised fine-tuning. Then, we perform reinforcement learning by trial-and-error interactions in simulation to further enhance the model's reasoning abilities for robotic manipulation. Our resulting reasoning model built upon a 7B backbone, named ReasonManip, demonstrates three notable advantages driven by its system-2 level reasoning capabilities: i) exceptional generalizability to out-of-distribution environments, objects, and tasks; ii) inherent sim-to-real transfer ability enabled by the unified language representation shared across domains; iii) transparent interpretability connecting high-level reasoning and low-level control. Extensive experiments demonstrate the effectiveness of the proposed paradigm and its potential to advance LMM-driven robotic manipulation.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "17 pages, 16 figures",
    "pdf_url": "https://arxiv.org/pdf/2505.12744v1",
    "published_date": "2025-05-19 06:00:14 UTC",
    "updated_date": "2025-05-19 06:00:14 UTC"
  },
  {
    "arxiv_id": "2505.12741v1",
    "title": "Dense Communication between Language Models",
    "authors": [
      "Shiguang Wu",
      "Yaqing Wang",
      "Quanming Yao"
    ],
    "abstract": "As higher-level intelligence emerges from the combination of modular components with lower-level intelligence, many works combines Large Language Models (LLMs) for collective intelligence. Such combination is achieved by building communications among LLMs. While current systems primarily facilitate such communication through natural language, this paper proposes a novel paradigm of direct dense vector communication between LLMs. Our approach eliminates the unnecessary embedding and de-embedding steps when LLM interact with another, enabling more efficient information transfer, fully differentiable optimization pathways, and exploration of capabilities beyond human heuristics. We use such stripped LLMs as vertexes and optimizable seq2seq modules as edges to construct LMNet, with similar structure as MLPs. By utilizing smaller pre-trained LLMs as vertexes, we train a LMNet that achieves comparable performance with LLMs in similar size with only less than 0.1% training cost. This offers a new perspective on scaling for general intelligence rather than training a monolithic LLM from scratch. Besides, the proposed method can be used for other applications, like customizing LLM with limited data, showing its versatility.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.12741v1",
    "published_date": "2025-05-19 05:56:06 UTC",
    "updated_date": "2025-05-19 05:56:06 UTC"
  },
  {
    "arxiv_id": "2505.12738v1",
    "title": "EpiLLM: Unlocking the Potential of Large Language Models in Epidemic Forecasting",
    "authors": [
      "Chenghua Gong",
      "Rui Sun",
      "Yuhao Zheng",
      "Juyuan Zhang",
      "Tianjun Gu",
      "Liming Pan",
      "Linyuan Lv"
    ],
    "abstract": "Advanced epidemic forecasting is critical for enabling precision containment strategies, highlighting its strategic importance for public health security. While recent advances in Large Language Models (LLMs) have demonstrated effectiveness as foundation models for domain-specific tasks, their potential for epidemic forecasting remains largely unexplored. In this paper, we introduce EpiLLM, a novel LLM-based framework tailored for spatio-temporal epidemic forecasting. Considering the key factors in real-world epidemic transmission: infection cases and human mobility, we introduce a dual-branch architecture to achieve fine-grained token-level alignment between such complex epidemic patterns and language tokens for LLM adaptation. To unleash the multi-step forecasting and generalization potential of LLM architectures, we propose an autoregressive modeling paradigm that reformulates the epidemic forecasting task into next-token prediction. To further enhance LLM perception of epidemics, we introduce spatio-temporal prompt learning techniques, which strengthen forecasting capabilities from a data-driven perspective. Extensive experiments show that EpiLLM significantly outperforms existing baselines on real-world COVID-19 datasets and exhibits scaling behavior characteristic of LLMs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "cs.LG",
    "comment": "18 pages",
    "pdf_url": "https://arxiv.org/pdf/2505.12738v1",
    "published_date": "2025-05-19 05:53:25 UTC",
    "updated_date": "2025-05-19 05:53:25 UTC"
  },
  {
    "arxiv_id": "2505.12737v2",
    "title": "Option-aware Temporally Abstracted Value for Offline Goal-Conditioned Reinforcement Learning",
    "authors": [
      "Hongjoon Ahn",
      "Heewoong Choi",
      "Jisu Han",
      "Taesup Moon"
    ],
    "abstract": "Offline goal-conditioned reinforcement learning (GCRL) offers a practical learning paradigm in which goal-reaching policies are trained from abundant state-action trajectory datasets without additional environment interaction. However, offline GCRL still struggles with long-horizon tasks, even with recent advances that employ hierarchical policy structures, such as HIQL. Identifying the root cause of this challenge, we observe the following insight. Firstly, performance bottlenecks mainly stem from the high-level policy's inability to generate appropriate subgoals. Secondly, when learning the high-level policy in the long-horizon regime, the sign of the advantage estimate frequently becomes incorrect. Thus, we argue that improving the value function to produce a clear advantage estimate for learning the high-level policy is essential. In this paper, we propose a simple yet effective solution: Option-aware Temporally Abstracted value learning, dubbed OTA, which incorporates temporal abstraction into the temporal-difference learning process. By modifying the value update to be option-aware, our approach contracts the effective horizon length, enabling better advantage estimates even in long-horizon regimes. We experimentally show that the high-level policy learned using the OTA value function achieves strong performance on complex tasks from OGBench, a recently proposed offline GCRL benchmark, including maze navigation and visual robotic manipulation environments.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.12737v2",
    "published_date": "2025-05-19 05:51:11 UTC",
    "updated_date": "2025-11-04 02:26:57 UTC"
  },
  {
    "arxiv_id": "2505.12734v1",
    "title": "SounDiT: Geo-Contextual Soundscape-to-Landscape Generation",
    "authors": [
      "Junbo Wang",
      "Haofeng Tan",
      "Bowen Liao",
      "Albert Jiang",
      "Teng Fei",
      "Qixing Huang",
      "Zhengzhong Tu",
      "Shan Ye",
      "Yuhao Kang"
    ],
    "abstract": "We present a novel and practically significant problem-Geo-Contextual Soundscape-to-Landscape (GeoS2L) generation-which aims to synthesize geographically realistic landscape images from environmental soundscapes. Prior audio-to-image generation methods typically rely on general-purpose datasets and overlook geographic and environmental contexts, resulting in unrealistic images that are misaligned with real-world environmental settings. To address this limitation, we introduce a novel geo-contextual computational framework that explicitly integrates geographic knowledge into multimodal generative modeling. We construct two large-scale geo-contextual multimodal datasets, SoundingSVI and SonicUrban, pairing diverse soundscapes with real-world landscape images. We propose SounDiT, a novel Diffusion Transformer (DiT)-based model that incorporates geo-contextual scene conditioning to synthesize geographically coherent landscape images. Furthermore, we propose a practically-informed geo-contextual evaluation framework, the Place Similarity Score (PSS), across element-, scene-, and human perception-levels to measure consistency between input soundscapes and generated landscape images. Extensive experiments demonstrate that SounDiT outperforms existing baselines in both visual fidelity and geographic settings. Our work not only establishes foundational benchmarks for GeoS2L generation but also highlights the importance of incorporating geographic domain knowledge in advancing multimodal generative models, opening new directions at the intersection of generative AI, geography, urban planning, and environmental sciences.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.GR",
      "cs.HC",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "14 pages, 5 figures",
    "pdf_url": "https://arxiv.org/pdf/2505.12734v1",
    "published_date": "2025-05-19 05:47:13 UTC",
    "updated_date": "2025-05-19 05:47:13 UTC"
  },
  {
    "arxiv_id": "2505.12731v2",
    "title": "Accelerating Adaptive Retrieval Augmented Generation via Instruction-Driven Representation Reduction of Retrieval Overlaps",
    "authors": [
      "Jie Ou",
      "Jinyu Guo",
      "Shuaihong Jiang",
      "Zhaokun Wang",
      "Libo Qin",
      "Shunyu Yao",
      "Wenhong Tian"
    ],
    "abstract": "Retrieval-augmented generation (RAG) has emerged as a pivotal method for expanding the knowledge of large language models. To handle complex queries more effectively, researchers developed Adaptive-RAG (A-RAG) to enhance the generated quality through multiple interactions with external knowledge bases. Despite its effectiveness, A-RAG exacerbates the pre-existing efficiency challenges inherent in RAG, which are attributable to its reliance on multiple iterations of generation. Existing A-RAG approaches process all retrieved contents from scratch. However, they ignore the situation where there is a significant overlap in the content of the retrieval results across rounds. The overlapping content is redundantly represented, which leads to a large proportion of repeated computations, thus affecting the overall efficiency. To address this issue, this paper introduces a model-agnostic approach that can be generally applied to A-RAG methods, which is dedicated to reducing the redundant representation process caused by the overlapping of retrieval results. Specifically, we use cache access and parallel generation to speed up the prefilling and decoding stages respectively. Additionally, we also propose an instruction-driven module to further guide the model to more effectively attend to each part of the content in a more suitable way for LLMs. Experiments show that our approach achieves 2.79 and 2.33 times significant acceleration on average for prefilling and decoding respectively while maintaining equal generation quality.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted at Findings of ACL 2025",
    "pdf_url": "https://arxiv.org/pdf/2505.12731v2",
    "published_date": "2025-05-19 05:39:38 UTC",
    "updated_date": "2025-05-25 13:03:54 UTC"
  },
  {
    "arxiv_id": "2505.12716v3",
    "title": "Shadow-FT: Tuning Instruct Model via Training on Paired Base Model",
    "authors": [
      "Taiqiang Wu",
      "Runming Yang",
      "Jiayi Li",
      "Pengfei Hu",
      "Yik-Chung Wu",
      "Ngai Wong",
      "Yujiu Yang"
    ],
    "abstract": "Large language models (LLMs) consistently benefit from further fine-tuning on various tasks. However, we observe that directly tuning the Instruct (i.e., instruction-tuned) models often leads to marginal improvements and even performance degeneration. Notably, paired Base models, the foundation for these Instruct variants, contain highly similar weight values (i.e., less than 2% on average for Llama 3.1 8B). The Base model tends to be a good learner yet a weak backbone without post-training. Therefore, we propose a novel Shadow-FT framework to tune the Instruct models by leveraging the corresponding Base models. The key insight is to fine-tune the Base model, and then \\textit{directly} graft the learned weight updates to the Instruct model. Our proposed Shadow-FT introduces no additional parameters, is easy to implement, and significantly improves performance. We conduct extensive experiments on tuning mainstream LLMs, such as Qwen 3 and Llama 3 series, and evaluate them across 19 benchmarks covering coding, reasoning, and mathematical tasks. Experimental results demonstrate that Shadow-FT consistently outperforms conventional full-parameter and parameter-efficient tuning approaches. Further analyses indicate that Shadow-FT can be applied to multimodal large language models (MLLMs) and combined with direct preference optimization~(DPO). Codes and weights are available at \\href{https://github.com/wutaiqiang/Shadow-FT}{Github}.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "24 pages, 12 tables, 8 figures. Previous name: Shadow-FT: Tuning Instruct via Base",
    "pdf_url": "https://arxiv.org/pdf/2505.12716v3",
    "published_date": "2025-05-19 05:16:21 UTC",
    "updated_date": "2025-09-26 03:43:47 UTC"
  },
  {
    "arxiv_id": "2505.12711v2",
    "title": "Any-to-Any Learning in Computational Pathology via Triplet Multimodal Pretraining",
    "authors": [
      "Qichen Sun",
      "Zhengrui Guo",
      "Rui Peng",
      "Hao Chen",
      "Jinzhuo Wang"
    ],
    "abstract": "Recent advances in computational pathology and artificial intelligence have significantly enhanced the utilization of gigapixel whole-slide images and and additional modalities (e.g., genomics) for pathological diagnosis. Although deep learning has demonstrated strong potential in pathology, several key challenges persist: (1) fusing heterogeneous data types requires sophisticated strategies beyond simple concatenation due to high computational costs; (2) common scenarios of missing modalities necessitate flexible strategies that allow the model to learn robustly in the absence of certain modalities; (3) the downstream tasks in CPath are diverse, ranging from unimodal to multimodal, cnecessitating a unified model capable of handling all modalities. To address these challenges, we propose ALTER, an any-to-any tri-modal pretraining framework that integrates WSIs, genomics, and pathology reports. The term \"any\" emphasizes ALTER's modality-adaptive design, enabling flexible pretraining with any subset of modalities, and its capacity to learn robust, cross-modal representations beyond WSI-centric approaches. We evaluate ALTER across extensive clinical tasks including survival prediction, cancer subtyping, gene mutation prediction, and report generation, achieving superior or comparable performance to state-of-the-art baselines.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.12711v2",
    "published_date": "2025-05-19 05:07:34 UTC",
    "updated_date": "2025-05-20 12:57:58 UTC"
  },
  {
    "arxiv_id": "2505.13551v2",
    "title": "Counter-Inferential Behavior in Natural and Artificial Cognitive Systems",
    "authors": [
      "Serge Dolgikh"
    ],
    "abstract": "This study explores the emergence of counter-inferential behavior in natural and artificial cognitive systems, that is, patterns in which agents misattribute empirical success or suppress adaptation, leading to epistemic rigidity or maladaptive stability. We analyze archetypal scenarios in which such behavior arises: reinforcement of stability through reward imbalance, meta-cognitive attribution of success to internal superiority, and protective reframing under perceived model fragility. Rather than arising from noise or flawed design, these behaviors emerge through structured interactions between internal information models, empirical feedback, and higher-order evaluation mechanisms. Drawing on evidence from artificial systems, biological cognition, human psychology, and social dynamics, we identify counter-inferential behavior as a general cognitive vulnerability that can manifest even in otherwise well-adapted systems. The findings highlight the importance of preserving minimal adaptive activation under stable conditions and suggest design principles for cognitive architectures that can resist rigidity under informational stress.",
    "categories": [
      "cs.AI",
      "cs.NE",
      "cs.SI"
    ],
    "primary_category": "cs.AI",
    "comment": "23 pages, 3 figures",
    "pdf_url": "https://arxiv.org/pdf/2505.13551v2",
    "published_date": "2025-05-19 05:04:07 UTC",
    "updated_date": "2025-06-09 04:19:52 UTC"
  },
  {
    "arxiv_id": "2505.12707v1",
    "title": "PLAICraft: Large-Scale Time-Aligned Vision-Speech-Action Dataset for Embodied AI",
    "authors": [
      "Yingchen He",
      "Christian D. Weilbach",
      "Martyna E. Wojciechowska",
      "Yuxuan Zhang",
      "Frank Wood"
    ],
    "abstract": "Advances in deep generative modelling have made it increasingly plausible to train human-level embodied agents. Yet progress has been limited by the absence of large-scale, real-time, multi-modal, and socially interactive datasets that reflect the sensory-motor complexity of natural environments. To address this, we present PLAICraft, a novel data collection platform and dataset capturing multiplayer Minecraft interactions across five time-aligned modalities: video, game output audio, microphone input audio, mouse, and keyboard actions. Each modality is logged with millisecond time precision, enabling the study of synchronous, embodied behaviour in a rich, open-ended world. The dataset comprises over 10,000 hours of gameplay from more than 10,000 global participants.\\footnote{We have done a privacy review for the public release of an initial 200-hour subset of the dataset, with plans to release most of the dataset over time.} Alongside the dataset, we provide an evaluation suite for benchmarking model capabilities in object recognition, spatial awareness, language grounding, and long-term memory. PLAICraft opens a path toward training and evaluating agents that act fluently and purposefully in real time, paving the way for truly embodied artificial intelligence.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.LG",
    "comment": "9 pages, 8 figures",
    "pdf_url": "https://arxiv.org/pdf/2505.12707v1",
    "published_date": "2025-05-19 05:00:47 UTC",
    "updated_date": "2025-05-19 05:00:47 UTC"
  },
  {
    "arxiv_id": "2505.12705v2",
    "title": "DreamGen: Unlocking Generalization in Robot Learning through Video World Models",
    "authors": [
      "Joel Jang",
      "Seonghyeon Ye",
      "Zongyu Lin",
      "Jiannan Xiang",
      "Johan Bjorck",
      "Yu Fang",
      "Fengyuan Hu",
      "Spencer Huang",
      "Kaushil Kundalia",
      "Yen-Chen Lin",
      "Loic Magne",
      "Ajay Mandlekar",
      "Avnish Narayan",
      "You Liang Tan",
      "Guanzhi Wang",
      "Jing Wang",
      "Qi Wang",
      "Yinzhen Xu",
      "Xiaohui Zeng",
      "Kaiyuan Zheng",
      "Ruijie Zheng",
      "Ming-Yu Liu",
      "Luke Zettlemoyer",
      "Dieter Fox",
      "Jan Kautz",
      "Scott Reed",
      "Yuke Zhu",
      "Linxi Fan"
    ],
    "abstract": "We introduce DreamGen, a simple yet highly effective 4-stage pipeline for training robot policies that generalize across behaviors and environments through neural trajectories - synthetic robot data generated from video world models. DreamGen leverages state-of-the-art image-to-video generative models, adapting them to the target robot embodiment to produce photorealistic synthetic videos of familiar or novel tasks in diverse environments. Since these models generate only videos, we recover pseudo-action sequences using either a latent action model or an inverse-dynamics model (IDM). Despite its simplicity, DreamGen unlocks strong behavior and environment generalization: a humanoid robot can perform 22 new behaviors in both seen and unseen environments, while requiring teleoperation data from only a single pick-and-place task in one environment. To evaluate the pipeline systematically, we introduce DreamGen Bench, a video generation benchmark that shows a strong correlation between benchmark performance and downstream policy success. Our work establishes a promising new axis for scaling robot learning well beyond manual data collection. Code available at https://github.com/NVIDIA/GR00T-Dreams.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "See website for videos: https://research.nvidia.com/labs/gear/dreamgen",
    "pdf_url": "https://arxiv.org/pdf/2505.12705v2",
    "published_date": "2025-05-19 04:55:39 UTC",
    "updated_date": "2025-06-17 22:33:35 UTC"
  },
  {
    "arxiv_id": "2505.12703v1",
    "title": "SpatialLLM: From Multi-modality Data to Urban Spatial Intelligence",
    "authors": [
      "Jiabin Chen",
      "Haiping Wang",
      "Jinpeng Li",
      "Yuan Liu",
      "Zhen Dong",
      "Bisheng Yang"
    ],
    "abstract": "We propose SpatialLLM, a novel approach advancing spatial intelligence tasks in complex urban scenes. Unlike previous methods requiring geographic analysis tools or domain expertise, SpatialLLM is a unified language model directly addressing various spatial intelligence tasks without any training, fine-tuning, or expert intervention. The core of SpatialLLM lies in constructing detailed and structured scene descriptions from raw spatial data to prompt pre-trained LLMs for scene-based analysis. Extensive experiments show that, with our designs, pretrained LLMs can accurately perceive spatial distribution information and enable zero-shot execution of advanced spatial intelligence tasks, including urban planning, ecological analysis, traffic management, etc. We argue that multi-field knowledge, context length, and reasoning ability are key factors influencing LLM performances in urban analysis. We hope that SpatialLLM will provide a novel viable perspective for urban intelligent analysis and management. The code and dataset are available at https://github.com/WHU-USI3DV/SpatialLLM.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.12703v1",
    "published_date": "2025-05-19 04:53:41 UTC",
    "updated_date": "2025-05-19 04:53:41 UTC"
  },
  {
    "arxiv_id": "2505.13550v1",
    "title": "JIR-Arena: The First Benchmark Dataset for Just-in-time Information Recommendation",
    "authors": [
      "Ke Yang",
      "Kevin Ros",
      "Shankar Kumar Senthil Kumar",
      "ChengXiang Zhai"
    ],
    "abstract": "Just-in-time Information Recommendation (JIR) is a service designed to deliver the most relevant information precisely when users need it, , addressing their knowledge gaps with minimal effort and boosting decision-making and efficiency in daily life. Advances in device-efficient deployment of foundation models and the growing use of intelligent wearable devices have made always-on JIR assistants feasible. However, there has been no systematic effort to formally define JIR tasks or establish evaluation frameworks. To bridge this gap, we present the first mathematical definition of JIR tasks and associated evaluation metrics. Additionally, we introduce JIR-Arena, a multimodal benchmark dataset featuring diverse, information-request-intensive scenarios to evaluate JIR systems across critical dimensions: i) accurately inferring user information needs, ii) delivering timely and relevant recommendations, and iii) avoiding irrelevant content that may distract users.\n  Developing a JIR benchmark dataset poses challenges due to subjectivity in estimating user information needs and uncontrollable system variables affecting reproducibility. To address these, JIR-Arena: i) combines input from multiple humans and large AI models to approximate information need distributions; ii) assesses JIR quality through information retrieval outcomes using static knowledge base snapshots; and iii) employs a multi-turn, multi-entity validation framework to improve objectivity and generality. Furthermore, we implement a baseline JIR system capable of processing real-time information streams aligned with user inputs. Our evaluation of this baseline system on JIR-Arena indicates that while foundation model-based JIR systems simulate user needs with reasonable precision, they face challenges in recall and effective content retrieval. To support future research in this new area, we fully release our code and data.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.13550v1",
    "published_date": "2025-05-19 04:49:47 UTC",
    "updated_date": "2025-05-19 04:49:47 UTC"
  },
  {
    "arxiv_id": "2506.01994v1",
    "title": "Re-experiment Smart: a Novel Method to Enhance Data-driven Prediction of Mechanical Properties of Epoxy Polymers",
    "authors": [
      "Wanshan Cui",
      "Yejin Jeong",
      "Inwook Song",
      "Gyuri Kim",
      "Minsang Kwon",
      "Donghun Lee"
    ],
    "abstract": "Accurate prediction of polymer material properties through data-driven approaches greatly accelerates novel material development by reducing redundant experiments and trial-and-error processes. However, inevitable outliers in empirical measurements can severely skew machine learning results, leading to erroneous prediction models and suboptimal material designs. To address this limitation, we propose a novel approach to enhance dataset quality efficiently by integrating multi-algorithm outlier detection with selective re-experimentation of unreliable outlier cases. To validate the empirical effectiveness of the approach, we systematically construct a new dataset containing 701 measurements of three key mechanical properties: glass transition temperature ($T_g$), tan $δ$ peak, and crosslinking density ($v_{c}$). To demonstrate its general applicability, we report the performance improvements across multiple machine learning models, including Elastic Net, SVR, Random Forest, and TPOT, to predict the three key properties. Our method reliably reduces prediction error (RMSE) and significantly improves accuracy with minimal additional experimental work, requiring only about 5% of the dataset to be re-measured. These findings highlight the importance of data quality enhancement in achieving reliable machine learning applications in polymer science and present a scalable strategy for improving predictive reliability in materials science.",
    "categories": [
      "cond-mat.soft",
      "cond-mat.mtrl-sci",
      "cs.AI"
    ],
    "primary_category": "cond-mat.soft",
    "comment": "27 pages, 8 figures",
    "pdf_url": "https://arxiv.org/pdf/2506.01994v1",
    "published_date": "2025-05-19 04:42:18 UTC",
    "updated_date": "2025-05-19 04:42:18 UTC"
  },
  {
    "arxiv_id": "2505.12701v1",
    "title": "Counterfactual Explanations for Continuous Action Reinforcement Learning",
    "authors": [
      "Shuyang Dong",
      "Shangtong Zhang",
      "Lu Feng"
    ],
    "abstract": "Reinforcement Learning (RL) has shown great promise in domains like healthcare and robotics but often struggles with adoption due to its lack of interpretability. Counterfactual explanations, which address \"what if\" scenarios, provide a promising avenue for understanding RL decisions but remain underexplored for continuous action spaces. We propose a novel approach for generating counterfactual explanations in continuous action RL by computing alternative action sequences that improve outcomes while minimizing deviations from the original sequence. Our approach leverages a distance metric for continuous actions and accounts for constraints such as adhering to predefined policies in specific states. Evaluations in two RL domains, Diabetes Control and Lunar Lander, demonstrate the effectiveness, efficiency, and generalization of our approach, enabling more interpretable and trustworthy RL applications.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by International Joint Conference on Artificial Intelligence (IJCAI) 2025",
    "pdf_url": "https://arxiv.org/pdf/2505.12701v1",
    "published_date": "2025-05-19 04:41:54 UTC",
    "updated_date": "2025-05-19 04:41:54 UTC"
  },
  {
    "arxiv_id": "2505.12692v1",
    "title": "Bullying the Machine: How Personas Increase LLM Vulnerability",
    "authors": [
      "Ziwei Xu",
      "Udit Sanghi",
      "Mohan Kankanhalli"
    ],
    "abstract": "Large Language Models (LLMs) are increasingly deployed in interactions where they are prompted to adopt personas. This paper investigates whether such persona conditioning affects model safety under bullying, an adversarial manipulation that applies psychological pressures in order to force the victim to comply to the attacker. We introduce a simulation framework in which an attacker LLM engages a victim LLM using psychologically grounded bullying tactics, while the victim adopts personas aligned with the Big Five personality traits. Experiments using multiple open-source LLMs and a wide range of adversarial goals reveal that certain persona configurations -- such as weakened agreeableness or conscientiousness -- significantly increase victim's susceptibility to unsafe outputs. Bullying tactics involving emotional or sarcastic manipulation, such as gaslighting and ridicule, are particularly effective. These findings suggest that persona-driven interaction introduces a novel vector for safety risks in LLMs and highlight the need for persona-aware safety evaluation and alignment strategies.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.12692v1",
    "published_date": "2025-05-19 04:32:02 UTC",
    "updated_date": "2025-05-19 04:32:02 UTC"
  },
  {
    "arxiv_id": "2505.12684v2",
    "title": "Towards Effective Federated Graph Foundation Model via Mitigating Knowledge Entanglement",
    "authors": [
      "Yinlin Zhu",
      "Xunkai Li",
      "Jishuo Jia",
      "Miao Hu",
      "Di Wu",
      "Meikang Qiu"
    ],
    "abstract": "Recent advances in graph machine learning have shifted to data-centric paradigms, driven by two emerging fields: (1) Federated graph learning (FGL) enables multi-client collaboration but faces challenges from data and task heterogeneity, limiting its practicality; (2) Graph foundation models (GFM) offer strong domain generalization but are usually trained on single machines, missing out on cross-silo data and resources.\n  These paradigms are complementary, and their integration brings notable benefits. Motivated by this, we propose FedGFM, a novel decentralized GFM training paradigm. However, a key challenge is knowledge entanglement, where multi-domain knowledge merges into indistinguishable representations, hindering downstream adaptation.\n  To address this, we present FedGFM+, an enhanced framework with two core modules to reduce knowledge entanglement: (1) AncDAI: A global anchor-based domain-aware initialization strategy. Before pre-training, each client encodes its local graph into domain-specific prototypes that serve as semantic anchors. Synthetic embeddings around these anchors initialize the global model. We theoretically prove these prototypes are distinguishable across domains, providing a strong inductive bias to disentangle domain-specific knowledge. (2) AdaDPP: A local adaptive domain-sensitive prompt pool. Each client learns a lightweight graph prompt capturing domain semantics during pre-training. During fine-tuning, prompts from all clients form a pool from which the GFM selects relevant prompts to augment target graph attributes, improving downstream adaptation.\n  FedGFM+ is evaluated on 8 diverse benchmarks across multiple domains and tasks, outperforming 20 baselines from supervised learning, FGL, and federated GFM variants.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DB",
      "cs.SI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by NeurIPS 2025",
    "pdf_url": "https://arxiv.org/pdf/2505.12684v2",
    "published_date": "2025-05-19 04:06:32 UTC",
    "updated_date": "2025-11-14 01:50:42 UTC"
  },
  {
    "arxiv_id": "2505.12680v2",
    "title": "Ineq-Comp: Benchmarking Human-Intuitive Compositional Reasoning in Automated Theorem Proving on Inequalities",
    "authors": [
      "Haoyu Zhao",
      "Yihan Geng",
      "Shange Tang",
      "Yong Lin",
      "Bohan Lyu",
      "Hongzhou Lin",
      "Chi Jin",
      "Sanjeev Arora"
    ],
    "abstract": "LLM-based formal proof assistants (e.g., in Lean) hold great promise for automating mathematical discovery. But beyond syntactic correctness, do these systems truly understand mathematical structure as humans do? We investigate this question in context of mathematical inequalities -- specifically the prover's ability to recognize that the given problem simplifies by applying a known inequality such as AM/GM. Specifically, we are interested in their ability to do this in a compositional setting where multiple inequalities must be applied as part of a solution. We introduce Ineq-Comp, a benchmark built from elementary inequalities through systematic transformations, including variable duplication, algebraic rewriting, and multi-step composition. Although these problems remain easy for humans, we find that most provers -- including Goedel, STP, and Kimina-7B -- struggle significantly. DeepSeek-Prover-V2-7B shows relative robustness, but still suffers a 20% performance drop (pass@32). Even for DeepSeek-Prover-V2-671B model, the gap between compositional variants and seed problems exists, implying that simply scaling up the model size alone does not fully solve the compositional weakness. Strikingly, performance remains poor for all models even when formal proofs of the constituent parts are provided in context, revealing that the source of weakness is indeed in compositional reasoning. Our results expose a persisting gap between the generalization behavior of current AI provers and human mathematical intuition. All data and evaluation code can be found at https://github.com/haoyuzhao123/LeanIneqComp.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "To appear in NeurIPS 2025 Track on Datasets and Benchmarks. 28 pages",
    "pdf_url": "https://arxiv.org/pdf/2505.12680v2",
    "published_date": "2025-05-19 03:56:05 UTC",
    "updated_date": "2025-10-20 04:36:02 UTC"
  },
  {
    "arxiv_id": "2505.13547v1",
    "title": "Exploring Federated Pruning for Large Language Models",
    "authors": [
      "Pengxin Guo",
      "Yinong Wang",
      "Wei Li",
      "Mengting Liu",
      "Ming Li",
      "Jinkai Zheng",
      "Liangqiong Qu"
    ],
    "abstract": "LLM pruning has emerged as a promising technology for compressing LLMs, enabling their deployment on resource-limited devices. However, current methodologies typically require access to public calibration samples, which can be challenging to obtain in privacy-sensitive domains. To address this issue, we introduce FedPrLLM, a comprehensive federated pruning framework designed for the privacy-preserving compression of LLMs. In FedPrLLM, each client only needs to calculate a pruning mask matrix based on its local calibration data and share it with the server to prune the global model. This approach allows for collaborative pruning of the global model with the knowledge of each client while maintaining local data privacy. Additionally, we conduct extensive experiments to explore various possibilities within the FedPrLLM framework, including different comparison groups, pruning strategies, and the decision to scale weights. Our extensive evaluation reveals that one-shot pruning with layer comparison and no weight scaling is the optimal choice within the FedPrLLM framework. We hope our work will help guide future efforts in pruning LLMs in privacy-sensitive fields. Our code is available at https://github.com/Pengxin-Guo/FedPrLLM.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.13547v1",
    "published_date": "2025-05-19 03:41:54 UTC",
    "updated_date": "2025-05-19 03:41:54 UTC"
  },
  {
    "arxiv_id": "2505.12669v1",
    "title": "Text2midi-InferAlign: Improving Symbolic Music Generation with Inference-Time Alignment",
    "authors": [
      "Abhinaba Roy",
      "Geeta Puri",
      "Dorien Herremans"
    ],
    "abstract": "We present Text2midi-InferAlign, a novel technique for improving symbolic music generation at inference time. Our method leverages text-to-audio alignment and music structural alignment rewards during inference to encourage the generated music to be consistent with the input caption. Specifically, we introduce two objectives scores: a text-audio consistency score that measures rhythmic alignment between the generated music and the original text caption, and a harmonic consistency score that penalizes generated music containing notes inconsistent with the key. By optimizing these alignment-based objectives during the generation process, our model produces symbolic music that is more closely tied to the input captions, thereby improving the overall quality and coherence of the generated compositions. Our approach can extend any existing autoregressive model without requiring further training or fine-tuning. We evaluate our work on top of Text2midi - an existing text-to-midi generation model, demonstrating significant improvements in both objective and subjective evaluation metrics.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.MM",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "7 pages, 1 figure, 5 tables",
    "pdf_url": "https://arxiv.org/pdf/2505.12669v1",
    "published_date": "2025-05-19 03:36:06 UTC",
    "updated_date": "2025-05-19 03:36:06 UTC"
  },
  {
    "arxiv_id": "2505.13546v1",
    "title": "Prompt Stability Matters: Evaluating and Optimizing Auto-Generated Prompt in General-Purpose Systems",
    "authors": [
      "Ke Chen",
      "Yufei Zhou",
      "Xitong Zhang",
      "Haohan Wang"
    ],
    "abstract": "Automatic prompt generation plays a crucial role in enabling general-purpose multi-agent systems to perform diverse tasks autonomously. Existing methods typically evaluate prompts based on their immediate task performance, overlooking the intrinsic qualities that determine their reliability. This outcome-centric view not only limits interpretability but also fails to account for the inherent stochasticity of large language models (LLMs). In this work, we bring attention to prompt stability-the consistency of model responses across repeated executions-as a key factor for building robust and effective prompt generation systems. To quantify this, we propose semantic stability as a criterion for assessing the response consistency of prompts, and fine-tune a LLaMA-based evaluator to measure it automatically across tasks. These components have enabled us to develop the first stability-aware general-purpose prompt generation system that leverages stability feedback to iteratively enhance both prompt quality and system-level performance. Furthermore, we establish a logical chain between prompt stability and task success by analyzing the structural dependencies within our system, proving stability as a necessary condition for effective system-level execution. Empirical results across general and domain-specific tasks demonstrate that our stability-aware framework improves both accuracy and output consistency. By shifting the focus from one-off results to persistent reliability, our work offers a new perspective on prompt design and contributes practical tools for building more trustworthy general-purpose systems.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.13546v1",
    "published_date": "2025-05-19 03:28:33 UTC",
    "updated_date": "2025-05-19 03:28:33 UTC"
  },
  {
    "arxiv_id": "2505.12664v1",
    "title": "Multi-View Wireless Sensing via Conditional Generative Learning: Framework and Model Design",
    "authors": [
      "Ziqing Xing",
      "Zhaoyang Zhang",
      "Zirui Chen",
      "Hongning Ruan",
      "Zhaohui Yang"
    ],
    "abstract": "In this paper, we incorporate physical knowledge into learning-based high-precision target sensing using the multi-view channel state information (CSI) between multiple base stations (BSs) and user equipment (UEs). Such kind of multi-view sensing problem can be naturally cast into a conditional generation framework. To this end, we design a bipartite neural network architecture, the first part of which uses an elaborately designed encoder to fuse the latent target features embedded in the multi-view CSI, and then the second uses them as conditioning inputs of a powerful generative model to guide the target's reconstruction. Specifically, the encoder is designed to capture the physical correlation between the CSI and the target, and also be adaptive to the numbers and positions of BS-UE pairs. Therein the view-specific nature of CSI is assimilated by introducing a spatial positional embedding scheme, which exploits the structure of electromagnetic(EM)-wave propagation channels. Finally, a conditional diffusion model with a weighted loss is employed to generate the target's point cloud from the fused features. Extensive numerical results demonstrate that the proposed generative multi-view (Gen-MV) sensing framework exhibits excellent flexibility and significant performance improvement on the reconstruction quality of target's shape and EM properties.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "submitted to IEEE Transactions on Wireless Communications",
    "pdf_url": "https://arxiv.org/pdf/2505.12664v1",
    "published_date": "2025-05-19 03:27:24 UTC",
    "updated_date": "2025-05-19 03:27:24 UTC"
  },
  {
    "arxiv_id": "2505.12662v1",
    "title": "Know3-RAG: A Knowledge-aware RAG Framework with Adaptive Retrieval, Generation, and Filtering",
    "authors": [
      "Xukai Liu",
      "Ye Liu",
      "Shiwen Wu",
      "Yanghai Zhang",
      "Yihao Yuan",
      "Kai Zhang",
      "Qi Liu"
    ],
    "abstract": "Recent advances in large language models (LLMs) have led to impressive progress in natural language generation, yet their tendency to produce hallucinated or unsubstantiated content remains a critical concern. To improve factual reliability, Retrieval-Augmented Generation (RAG) integrates external knowledge during inference. However, existing RAG systems face two major limitations: (1) unreliable adaptive control due to limited external knowledge supervision, and (2) hallucinations caused by inaccurate or irrelevant references. To address these issues, we propose Know3-RAG, a knowledge-aware RAG framework that leverages structured knowledge from knowledge graphs (KGs) to guide three core stages of the RAG process, including retrieval, generation, and filtering. Specifically, we introduce a knowledge-aware adaptive retrieval module that employs KG embedding to assess the confidence of the generated answer and determine retrieval necessity, a knowledge-enhanced reference generation strategy that enriches queries with KG-derived entities to improve generated reference relevance, and a knowledge-driven reference filtering mechanism that ensures semantic alignment and factual accuracy of references. Experiments on multiple open-domain QA benchmarks demonstrate that Know3-RAG consistently outperforms strong baselines, significantly reducing hallucinations and enhancing answer reliability.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.12662v1",
    "published_date": "2025-05-19 03:25:18 UTC",
    "updated_date": "2025-05-19 03:25:18 UTC"
  },
  {
    "arxiv_id": "2505.13545v2",
    "title": "Know Or Not: a library for evaluating out-of-knowledge base robustness",
    "authors": [
      "Jessica Foo",
      "Pradyumna Shyama Prasad",
      "Shaun Khoo"
    ],
    "abstract": "While the capabilities of large language models (LLMs) have progressed significantly, their use in high-stakes applications have been limited due to risks of hallucination. One key approach in reducing hallucination is retrieval-augmented generation (RAG), but even in such setups, LLMs may still hallucinate when presented with questions outside of the knowledge base. Such behavior is unacceptable in high-stake applications where LLMs are expected to abstain from answering queries it does not have sufficient context on. In this work, we present a novel methodology for systematically evaluating out-of-knowledge base (OOKB) robustness of LLMs (whether LLMs know or do not know) in the RAG setting, without the need for manual annotation of gold standard answers. We implement our methodology in knowornot, an open-source library that enables users to develop their own customized evaluation data and pipelines for OOKB robustness. knowornot comprises four main features. Firstly, it provides a unified, high-level API that streamlines the process of setting up and running robustness benchmarks. Secondly, its modular architecture emphasizes extensibility and flexibility, allowing users to easily integrate their own LLM clients and RAG settings. Thirdly, its rigorous data modeling design ensures experiment reproducibility, reliability and traceability. Lastly, it implements a comprehensive suite of tools for users to customize their pipelines. We demonstrate the utility of knowornot by developing a challenging benchmark, PolicyBench, which spans four Question-Answer (QA) chatbots on government policies, and analyze its OOKB robustness. The source code of knowornot is available https://github.com/govtech-responsibleai/KnowOrNot.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.13545v2",
    "published_date": "2025-05-19 03:17:41 UTC",
    "updated_date": "2025-07-21 14:09:54 UTC"
  },
  {
    "arxiv_id": "2505.12655v2",
    "title": "Web Intellectual Property at Risk: Preventing Unauthorized Real-Time Retrieval by Large Language Models",
    "authors": [
      "Yisheng Zhong",
      "Yizhu Wen",
      "Junfeng Guo",
      "Mehran Kafai",
      "Heng Huang",
      "Hanqing Guo",
      "Zhuangdi Zhu"
    ],
    "abstract": "The protection of cyber Intellectual Property (IP) such as web content is an increasingly critical concern. The rise of large language models (LLMs) with online retrieval capabilities enables convenient access to information but often undermines the rights of original content creators. As users increasingly rely on LLM-generated responses, they gradually diminish direct engagement with original information sources, which will significantly reduce the incentives for IP creators to contribute, and lead to a saturating cyberspace with more AI-generated content. In response, we propose a novel defense framework that empowers web content creators to safeguard their web-based IP from unauthorized LLM real-time extraction and redistribution by leveraging the semantic understanding capability of LLMs themselves. Our method follows principled motivations and effectively addresses an intractable black-box optimization problem. Real-world experiments demonstrated that our methods improve defense success rates from 2.5% to 88.6% on different LLMs, outperforming traditional defenses such as configuration-based restrictions.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "13 pages, 13 figures, 4 tables",
    "pdf_url": "https://arxiv.org/pdf/2505.12655v2",
    "published_date": "2025-05-19 03:14:08 UTC",
    "updated_date": "2025-06-06 04:55:29 UTC"
  },
  {
    "arxiv_id": "2505.12654v2",
    "title": "Predicting Turn-Taking and Backchannel in Human-Machine Conversations Using Linguistic, Acoustic, and Visual Signals",
    "authors": [
      "Yuxin Lin",
      "Yinglin Zheng",
      "Ming Zeng",
      "Wangzheng Shi"
    ],
    "abstract": "This paper addresses the gap in predicting turn-taking and backchannel actions in human-machine conversations using multi-modal signals (linguistic, acoustic, and visual). To overcome the limitation of existing datasets, we propose an automatic data collection pipeline that allows us to collect and annotate over 210 hours of human conversation videos. From this, we construct a Multi-Modal Face-to-Face (MM-F2F) human conversation dataset, including over 1.5M words and corresponding turn-taking and backchannel annotations from approximately 20M frames. Additionally, we present an end-to-end framework that predicts the probability of turn-taking and backchannel actions from multi-modal signals. The proposed model emphasizes the interrelation between modalities and supports any combination of text, audio, and video inputs, making it adaptable to a variety of realistic scenarios. Our experiments show that our approach achieves state-of-the-art performance on turn-taking and backchannel prediction tasks, achieving a 10% increase in F1-score on turn-taking and a 33% increase on backchannel prediction. Our dataset and code are publicly available online to ease of subsequent research.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepected by ACL 2025",
    "pdf_url": "https://arxiv.org/pdf/2505.12654v2",
    "published_date": "2025-05-19 03:08:30 UTC",
    "updated_date": "2025-05-20 06:59:31 UTC"
  },
  {
    "arxiv_id": "2505.12651v1",
    "title": "$\\texttt{DIAMONDs}$: A Dataset for $\\mathbb{D}$ynamic $\\mathbb{I}$nformation $\\mathbb{A}$nd $\\mathbb{M}$ental modeling $\\mathbb{O}$f $\\mathbb{N}$umeric $\\mathbb{D}$iscussions",
    "authors": [
      "Sayontan Ghosh",
      "Mahnaz Koupaee",
      "Yash Kumar Lal",
      "Pegah Alipoormolabashi",
      "Mohammad Saqib Hasan",
      "Jun Seok Kang",
      "Niranjan Balasubramanian"
    ],
    "abstract": "Understanding multiparty conversations demands robust Theory of Mind (ToM) capabilities, including the ability to track dynamic information, manage knowledge asymmetries, and distinguish relevant information across extended exchanges. To advance ToM evaluation in such settings, we present a carefully designed scalable methodology for generating high-quality benchmark conversation-question pairs with these characteristics. Using this methodology, we create $\\texttt{DIAMONDs}$, a new conversational QA dataset covering common business, financial or other group interactions. In these goal-oriented conversations, participants often have to track certain numerical quantities (say $\\textit{expected profit}$) of interest that can be derived from other variable quantities (like $\\textit{marketing expenses, expected sales, salary}$, etc.), whose values also change over the course of the conversation. $\\texttt{DIAMONDs}$ questions pose simple numerical reasoning problems over such quantities of interest (e.g., $\\textit{funds required for charity events, expected company profit next quarter}$, etc.) in the context of the information exchanged in conversations. This allows for precisely evaluating ToM capabilities for carefully tracking and reasoning over participants' knowledge states.\n  Our evaluation of state-of-the-art language models reveals significant challenges in handling participant-centric reasoning, specifically in situations where participants have false beliefs. Models also struggle with conversations containing distractors and show limited ability to identify scenarios with insufficient information. These findings highlight current models' ToM limitations in handling real-world multi-party conversations.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.12651v1",
    "published_date": "2025-05-19 03:05:13 UTC",
    "updated_date": "2025-05-19 03:05:13 UTC"
  },
  {
    "arxiv_id": "2505.12650v1",
    "title": "AutoMat: Enabling Automated Crystal Structure Reconstruction from Microscopy via Agentic Tool Use",
    "authors": [
      "Yaotian Yang",
      "Yiwen Tang",
      "Yizhe Chen",
      "Xiao Chen",
      "Jiangjie Qiu",
      "Hao Xiong",
      "Haoyu Yin",
      "Zhiyao Luo",
      "Yifei Zhang",
      "Sijia Tao",
      "Wentao Li",
      "Qinghua Zhang",
      "Yuqiang Li",
      "Wanli Ouyang",
      "Bin Zhao",
      "Xiaonan Wang",
      "Fei Wei"
    ],
    "abstract": "Machine learning-based interatomic potentials and force fields depend critically on accurate atomic structures, yet such data are scarce due to the limited availability of experimentally resolved crystals. Although atomic-resolution electron microscopy offers a potential source of structural data, converting these images into simulation-ready formats remains labor-intensive and error-prone, creating a bottleneck for model training and validation. We introduce AutoMat, an end-to-end, agent-assisted pipeline that automatically transforms scanning transmission electron microscopy (STEM) images into atomic crystal structures and predicts their physical properties. AutoMat combines pattern-adaptive denoising, physics-guided template retrieval, symmetry-aware atomic reconstruction, fast relaxation and property prediction via MatterSim, and coordinated orchestration across all stages. We propose the first dedicated STEM2Mat-Bench for this task and evaluate performance using lattice RMSD, formation energy MAE, and structure-matching success rate. By orchestrating external tool calls, AutoMat enables a text-only LLM to outperform vision-language models in this domain, achieving closed-loop reasoning throughout the pipeline. In large-scale experiments over 450 structure samples, AutoMat substantially outperforms existing multimodal large language models and tools. These results validate both AutoMat and STEM2Mat-Bench, marking a key step toward bridging microscopy and atomistic simulation in materials science.The code and dataset are publicly available at https://github.com/yyt-2378/AutoMat and https://huggingface.co/datasets/yaotianvector/STEM2Mat.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "The code and dataset are publicly available at https://github.com/yyt-2378/AutoMat and https://huggingface.co/datasets/yaotianvector/STEM2Mat",
    "pdf_url": "https://arxiv.org/pdf/2505.12650v1",
    "published_date": "2025-05-19 03:04:50 UTC",
    "updated_date": "2025-05-19 03:04:50 UTC"
  },
  {
    "arxiv_id": "2505.17067v5",
    "title": "Unveil Multi-Picture Descriptions for Multilingual Mild Cognitive Impairment Detection via Contrastive Learning",
    "authors": [
      "Kristin Qi",
      "Jiali Cheng",
      "Youxiang Zhu",
      "Hadi Amiri",
      "Xiaohui Liang"
    ],
    "abstract": "Detecting Mild Cognitive Impairment from picture descriptions is critical yet challenging, especially in multilingual and multiple picture settings. Prior work has primarily focused on English speakers describing a single picture (e.g., the 'Cookie Theft'). The TAUKDIAL-2024 challenge expands this scope by introducing multilingual speakers and multiple pictures, which presents new challenges in analyzing picture-dependent content. To address these challenges, we propose a framework with three components: (1) enhancing discriminative representation learning via supervised contrastive learning, (2) involving image modality rather than relying solely on speech and text modalities, and (3) applying a Product of Experts (PoE) strategy to mitigate spurious correlations and overfitting. Our framework improves MCI detection performance, achieving a +7.1% increase in Unweighted Average Recall (UAR) (from 68.1% to 75.2%) and a +2.9% increase in F1 score (from 80.6% to 83.5%) compared to the text unimodal baseline. Notably, the contrastive learning component yields greater gains for the text modality compared to speech. These results highlight our framework's effectiveness in multilingual and multi-picture MCI detection.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "IEEE Global Communications Conference (GlobeCom) 2025",
    "pdf_url": "https://arxiv.org/pdf/2505.17067v5",
    "published_date": "2025-05-19 03:03:08 UTC",
    "updated_date": "2025-09-03 03:38:04 UTC"
  },
  {
    "arxiv_id": "2505.12641v2",
    "title": "Single Image Reflection Separation via Dual Prior Interaction Transformer",
    "authors": [
      "Yue Huang",
      "Zi'ang Li",
      "Tianle Hu",
      "Jie Wen",
      "Guanbin Li",
      "Jinglin Zhang",
      "Guoxu Zhou",
      "Xiaozhao Fang"
    ],
    "abstract": "Single image reflection separation aims to separate the transmission and reflection layers from a mixed image. Existing methods typically combine general priors from pre-trained models with task-specific priors such as text prompts and reflection detection. However, the transmission prior, as the most direct task-specific prior for the target transmission layer, has not been effectively modeled or fully utilized, limiting performance in complex scenarios. To address this issue, we propose a dual-prior interaction framework based on lightweight transmission prior generation and effective prior fusion. First, we design a Local Linear Correction Network (LLCN) that finetunes pre-trained models based on the physical constraint T=SI+B, where S and B represent pixel-wise and channel-wise scaling and bias transformations. LLCN efficiently generates high-quality transmission priors with minimal parameters. Second, we construct a Dual-Prior Interaction Transformer (DPIT) that employs a dual-stream channel reorganization attention mechanism. By reorganizing features from general and transmission priors for attention computation, DPIT achieves deep fusion of both priors, fully exploiting their complementary information. Experimental results on multiple benchmark datasets demonstrate that the proposed method achieves state-of-the-art performance.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.12641v2",
    "published_date": "2025-05-19 02:50:15 UTC",
    "updated_date": "2026-01-08 11:53:15 UTC"
  },
  {
    "arxiv_id": "2505.12638v3",
    "title": "ChromFound: Towards A Universal Foundation Model for Single-Cell Chromatin Accessibility Data",
    "authors": [
      "Yifeng Jiao",
      "Yuchen Liu",
      "Yu Zhang",
      "Xin Guo",
      "Yushuai Wu",
      "Chen Jiang",
      "Jiyang Li",
      "Hongwei Zhang",
      "Limei Han",
      "Xin Gao",
      "Yuan Qi",
      "Yuan Cheng"
    ],
    "abstract": "The advent of single-cell Assay for Transposase-Accessible Chromatin using sequencing (scATAC-seq) offers an innovative perspective for deciphering regulatory mechanisms by assembling a vast repository of single-cell chromatin accessibility data. While foundation models have achieved significant success in single-cell transcriptomics, there is currently no foundation model for scATAC-seq that supports zero-shot high-quality cell identification and comprehensive multi-omics analysis simultaneously. Key challenges lie in the high dimensionality and sparsity of scATAC-seq data, as well as the lack of a standardized schema for representing open chromatin regions (OCRs). Here, we present ChromFound, a foundation model tailored for scATAC-seq. ChromFound utilizes a hybrid architecture and genome-aware tokenization to effectively capture genome-wide long contexts and regulatory signals from dynamic chromatin landscapes. Pretrained on 1.97 million cells from 30 tissues and 6 disease conditions, ChromFound demonstrates broad applicability across 6 diverse tasks. Notably, it achieves robust zero-shot performance in generating universal cell representations and exhibits excellent transferability in cell type annotation and cross-omics prediction. By uncovering enhancer-gene links undetected by existing computational methods, ChromFound offers a promising framework for understanding disease risk variants in the noncoding genome.",
    "categories": [
      "q-bio.GN",
      "cs.AI",
      "cs.CE",
      "cs.LG"
    ],
    "primary_category": "q-bio.GN",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.12638v3",
    "published_date": "2025-05-19 02:45:42 UTC",
    "updated_date": "2025-10-26 14:29:28 UTC"
  },
  {
    "arxiv_id": "2505.12632v1",
    "title": "Scalable Video-to-Dataset Generation for Cross-Platform Mobile Agents",
    "authors": [
      "Yunseok Jang",
      "Yeda Song",
      "Sungryull Sohn",
      "Lajanugen Logeswaran",
      "Tiange Luo",
      "Dong-Ki Kim",
      "Kyunghoon Bae",
      "Honglak Lee"
    ],
    "abstract": "Recent advancements in Large Language Models (LLMs) and Vision-Language Models (VLMs) have sparked significant interest in developing GUI visual agents. We introduce MONDAY (Mobile OS Navigation Task Dataset for Agents from YouTube), a large-scale dataset of 313K annotated frames from 20K instructional videos capturing diverse real-world mobile OS navigation across multiple platforms. Models that include MONDAY in their pre-training phases demonstrate robust cross-platform generalization capabilities, consistently outperforming models trained on existing single OS datasets while achieving an average performance gain of 18.11%p on an unseen mobile OS platform. To enable continuous dataset expansion as mobile platforms evolve, we present an automated framework that leverages publicly available video content to create comprehensive task datasets without manual annotation. Our framework comprises robust OCR-based scene detection (95.04% F1score), near-perfect UI element detection (99.87% hit ratio), and novel multi-step action identification to extract reliable action sequences across diverse interface configurations. We contribute both the MONDAY dataset and our automated collection framework to facilitate future research in mobile OS navigation.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "CVPR 2025",
    "pdf_url": "https://arxiv.org/pdf/2505.12632v1",
    "published_date": "2025-05-19 02:39:03 UTC",
    "updated_date": "2025-05-19 02:39:03 UTC"
  },
  {
    "arxiv_id": "2505.12630v1",
    "title": "Degradation-Aware Feature Perturbation for All-in-One Image Restoration",
    "authors": [
      "Xiangpeng Tian",
      "Xiangyu Liao",
      "Xiao Liu",
      "Meng Li",
      "Chao Ren"
    ],
    "abstract": "All-in-one image restoration aims to recover clear images from various degradation types and levels with a unified model. Nonetheless, the significant variations among degradation types present challenges for training a universal model, often resulting in task interference, where the gradient update directions of different tasks may diverge due to shared parameters. To address this issue, motivated by the routing strategy, we propose DFPIR, a novel all-in-one image restorer that introduces Degradation-aware Feature Perturbations(DFP) to adjust the feature space to align with the unified parameter space. In this paper, the feature perturbations primarily include channel-wise perturbations and attention-wise perturbations. Specifically, channel-wise perturbations are implemented by shuffling the channels in high-dimensional space guided by degradation types, while attention-wise perturbations are achieved through selective masking in the attention space. To achieve these goals, we propose a Degradation-Guided Perturbation Block (DGPB) to implement these two functions, positioned between the encoding and decoding stages of the encoder-decoder architecture. Extensive experimental results demonstrate that DFPIR achieves state-of-the-art performance on several all-in-one image restoration tasks including image denoising, image dehazing, image deraining, motion deblurring, and low-light image enhancement. Our codes are available at https://github.com/TxpHome/DFPIR.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to CVPR 2025. 8 pages, 7 figures",
    "pdf_url": "https://arxiv.org/pdf/2505.12630v1",
    "published_date": "2025-05-19 02:37:11 UTC",
    "updated_date": "2025-05-19 02:37:11 UTC"
  },
  {
    "arxiv_id": "2505.18188v2",
    "title": "Improving Generative Inverse Design of Rectangular Patch Antennas with Test Time Optimization",
    "authors": [
      "Beck LaBash",
      "Shahriar Khushrushahi",
      "Fabian Ruehle"
    ],
    "abstract": "We propose a two-stage deep learning framework for the inverse design of rectangular patch antennas. Our approach leverages generative modeling to learn a latent representation of antenna frequency response curves and conditions a subsequent generative model on these responses to produce feasible antenna geometries. We further demonstrate that leveraging search and optimization techniques at test-time improves the accuracy of the generated designs and enables consideration of auxiliary objectives such as manufacturability. Our approach generalizes naturally to different design criteria, and can be easily adapted to more complex geometric design spaces.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG",
      "eess.SY"
    ],
    "primary_category": "eess.SP",
    "comment": "Code and dataset available at https://github.com/becklabs/patch-antenna-tto",
    "pdf_url": "https://arxiv.org/pdf/2505.18188v2",
    "published_date": "2025-05-19 02:24:28 UTC",
    "updated_date": "2025-05-27 00:40:18 UTC"
  },
  {
    "arxiv_id": "2505.12626v3",
    "title": "scSiameseClu: A Siamese Clustering Framework for Interpreting single-cell RNA Sequencing Data",
    "authors": [
      "Ping Xu",
      "Zhiyuan Ning",
      "Pengjiang Li",
      "Wenhao Liu",
      "Pengyang Wang",
      "Jiaxu Cui",
      "Yuanchun Zhou",
      "Pengfei Wang"
    ],
    "abstract": "Single-cell RNA sequencing (scRNA-seq) reveals cell heterogeneity, with cell clustering playing a key role in identifying cell types and marker genes. Recent advances, especially graph neural networks (GNNs)-based methods, have significantly improved clustering performance. However, the analysis of scRNA-seq data remains challenging due to noise, sparsity, and high dimensionality. Compounding these challenges, GNNs often suffer from over-smoothing, limiting their ability to capture complex biological information. In response, we propose scSiameseClu, a novel Siamese Clustering framework for interpreting single-cell RNA-seq data, comprising of 3 key steps: (1) Dual Augmentation Module, which applies biologically informed perturbations to the gene expression matrix and cell graph relationships to enhance representation robustness; (2) Siamese Fusion Module, which combines cross-correlation refinement and adaptive information fusion to capture complex cellular relationships while mitigating over-smoothing; and (3) Optimal Transport Clustering, which utilizes Sinkhorn distance to efficiently align cluster assignments with predefined proportions while maintaining balance. Comprehensive evaluations on seven real-world datasets demonstrate that scSiameseClu outperforms state-of-the-art methods in single-cell clustering, cell type annotation, and cell type classification, providing a powerful tool for scRNA-seq data interpretation.",
    "categories": [
      "q-bio.GN",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.GN",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.12626v3",
    "published_date": "2025-05-19 02:17:09 UTC",
    "updated_date": "2025-10-02 02:55:07 UTC"
  },
  {
    "arxiv_id": "2505.12623v1",
    "title": "Lightweight and Effective Preference Construction in PIBT for Large-Scale Multi-Agent Pathfinding",
    "authors": [
      "Keisuke Okumura",
      "Hiroki Nagai"
    ],
    "abstract": "PIBT is a computationally lightweight algorithm that can be applied to a variety of multi-agent pathfinding (MAPF) problems, generating the next collision-free locations of agents given another. Because of its simplicity and scalability, it is becoming a popular underlying scheme for recent large-scale MAPF methods involving several hundreds or thousands of agents. Vanilla PIBT makes agents behave greedily towards their assigned goals, while agents typically have multiple best actions, since the graph shortest path is not always unique. Consequently, tiebreaking about how to choose between these actions significantly affects resulting solutions. This paper studies two simple yet effective techniques for tiebreaking in PIBT, without compromising its computational advantage. The first technique allows an agent to intelligently dodge another, taking into account whether each action will hinder the progress of the next timestep. The second technique is to learn, through multiple PIBT runs, how an action causes regret in others and to use this information to minimise regret collectively. Our empirical results demonstrate that these techniques can reduce the solution cost of one-shot MAPF and improve the throughput of lifelong MAPF. For instance, in densely populated one-shot cases, the combined use of these tiebreaks achieves improvements of around 10-20% in sum-of-costs, without significantly compromising the speed of a PIBT-based planner.",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "primary_category": "cs.MA",
    "comment": "To be presented at SoCS-25",
    "pdf_url": "https://arxiv.org/pdf/2505.12623v1",
    "published_date": "2025-05-19 02:12:29 UTC",
    "updated_date": "2025-05-19 02:12:29 UTC"
  },
  {
    "arxiv_id": "2505.13544v3",
    "title": "Multi-head Temporal Latent Attention",
    "authors": [
      "Keqi Deng",
      "Philip C. Woodland"
    ],
    "abstract": "While Transformer self-attention offers strong parallelism, the Key-Value (KV) cache grows linearly with sequence length and becomes a bottleneck for inference efficiency. Multi-head latent attention was recently developed to compress the KV cache into a low-rank latent space. This paper proposes Multi-head Temporal Latent Attention (MTLA), which further reduces the KV cache size along the temporal dimension, greatly lowering the memory footprint of self-attention inference. MTLA employs a hyper-network to dynamically merge temporally adjacent KV cache vectors. To address the mismatch between the compressed KV cache and processed sequence lengths, a stride-aware causal mask is proposed to ensure efficient parallel training and consistency with inference behaviour. Experiments across tasks, including speech translation, speech recognition, speech understanding and text summarisation, demonstrate that MTLA achieves competitive performance compared to standard Multi-Head Attention (MHA), while greatly improving inference speed and GPU memory usage. For example, on a English-German speech translation task, MTLA achieves a 5.3x speedup and a reduction in GPU memory usage by a factor of 8.3 compared to MHA, while maintaining translation quality.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by NeurIPS 2025",
    "pdf_url": "https://arxiv.org/pdf/2505.13544v3",
    "published_date": "2025-05-19 02:09:41 UTC",
    "updated_date": "2025-11-02 20:27:27 UTC"
  },
  {
    "arxiv_id": "2505.12594v1",
    "title": "AD-AGENT: A Multi-agent Framework for End-to-end Anomaly Detection",
    "authors": [
      "Tiankai Yang",
      "Junjun Liu",
      "Wingchun Siu",
      "Jiahang Wang",
      "Zhuangzhuang Qian",
      "Chanjuan Song",
      "Cheng Cheng",
      "Xiyang Hu",
      "Yue Zhao"
    ],
    "abstract": "Anomaly detection (AD) is essential in areas such as fraud detection, network monitoring, and scientific research. However, the diversity of data modalities and the increasing number of specialized AD libraries pose challenges for non-expert users who lack in-depth library-specific knowledge and advanced programming skills. To tackle this, we present AD-AGENT, an LLM-driven multi-agent framework that turns natural-language instructions into fully executable AD pipelines. AD-AGENT coordinates specialized agents for intent parsing, data preparation, library and model selection, documentation mining, and iterative code generation and debugging. Using a shared short-term workspace and a long-term cache, the agents integrate popular AD libraries like PyOD, PyGOD, and TSLib into a unified workflow. Experiments demonstrate that AD-AGENT produces reliable scripts and recommends competitive models across libraries. The system is open-sourced to support further research and practical applications in AD.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.12594v1",
    "published_date": "2025-05-19 01:14:57 UTC",
    "updated_date": "2025-05-19 01:14:57 UTC"
  },
  {
    "arxiv_id": "2505.12585v1",
    "title": "Learning Robust Spectral Dynamics for Temporal Domain Generalization",
    "authors": [
      "En Yu",
      "Jie Lu",
      "Xiaoyu Yang",
      "Guangquan Zhang",
      "Zhen Fang"
    ],
    "abstract": "Modern machine learning models struggle to maintain performance in dynamic environments where temporal distribution shifts, \\emph{i.e., concept drift}, are prevalent. Temporal Domain Generalization (TDG) seeks to enable model generalization across evolving domains, yet existing approaches typically assume smooth incremental changes, struggling with complex real-world drifts involving long-term structure (incremental evolution/periodicity) and local uncertainties. To overcome these limitations, we introduce FreKoo, which tackles these challenges via a novel frequency-domain analysis of parameter trajectories. It leverages the Fourier transform to disentangle parameter evolution into distinct spectral bands. Specifically, low-frequency component with dominant dynamics are learned and extrapolated using the Koopman operator, robustly capturing diverse drift patterns including both incremental and periodicity. Simultaneously, potentially disruptive high-frequency variations are smoothed via targeted temporal regularization, preventing overfitting to transient noise and domain uncertainties. In addition, this dual spectral strategy is rigorously grounded through theoretical analysis, providing stability guarantees for the Koopman prediction, a principled Bayesian justification for the high-frequency regularization, and culminating in a multiscale generalization bound connecting spectral dynamics to improved generalization. Extensive experiments demonstrate FreKoo's significant superiority over SOTA TDG approaches, particularly excelling in real-world streaming scenarios with complex drifts and uncertainties.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.12585v1",
    "published_date": "2025-05-19 00:38:18 UTC",
    "updated_date": "2025-05-19 00:38:18 UTC"
  },
  {
    "arxiv_id": "2505.12583v2",
    "title": "A Comprehensive Survey on Physical Risk Control in the Era of Foundation Model-enabled Robotics",
    "authors": [
      "Takeshi Kojima",
      "Yaonan Zhu",
      "Yusuke Iwasawa",
      "Toshinori Kitamura",
      "Gang Yan",
      "Shu Morikuni",
      "Ryosuke Takanami",
      "Alfredo Solano",
      "Tatsuya Matsushima",
      "Akiko Murakami",
      "Yutaka Matsuo"
    ],
    "abstract": "Recent Foundation Model-enabled robotics (FMRs) display greatly improved general-purpose skills, enabling more adaptable automation than conventional robotics. Their ability to handle diverse tasks thus creates new opportunities to replace human labor. However, unlike general foundation models, FMRs interact with the physical world, where their actions directly affect the safety of humans and surrounding objects, requiring careful deployment and control. Based on this proposition, our survey comprehensively summarizes robot control approaches to mitigate physical risks by covering all the lifespan of FMRs ranging from pre-deployment to post-accident stage. Specifically, we broadly divide the timeline into the following three phases: (1) pre-deployment phase, (2) pre-incident phase, and (3) post-incident phase. Throughout this survey, we find that there is much room to study (i) pre-incident risk mitigation strategies, (ii) research that assumes physical interaction with humans, and (iii) essential issues of foundation models themselves. We hope that this survey will be a milestone in providing a high-resolution analysis of the physical risks of FMRs and their control, contributing to the realization of a good human-robot relationship.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted to IJCAI 2025 Survey Track",
    "pdf_url": "https://arxiv.org/pdf/2505.12583v2",
    "published_date": "2025-05-19 00:11:42 UTC",
    "updated_date": "2025-05-30 07:28:49 UTC"
  },
  {
    "arxiv_id": "2505.12581v1",
    "title": "An approach based on class activation maps for investigating the effects of data augmentation on neural networks for image classification",
    "authors": [
      "Lucas M. Dorneles",
      "Luan Fonseca Garcia",
      "Joel Luís Carbonera"
    ],
    "abstract": "Neural networks have become increasingly popular in the last few years as an effective tool for the task of image classification due to the impressive performance they have achieved on this task. In image classification tasks, it is common to use data augmentation strategies to increase the robustness of trained networks to changes in the input images and to avoid overfitting. Although data augmentation is a widely adopted technique, the literature lacks a body of research analyzing the effects data augmentation methods have on the patterns learned by neural network models working on complex datasets. The primary objective of this work is to propose a methodology and set of metrics that may allow a quantitative approach to analyzing the effects of data augmentation in convolutional networks applied to image classification. An important tool used in the proposed approach lies in the concept of class activation maps for said models, which allow us to identify and measure the importance these models assign to each individual pixel in an image when executing the classification task. From these maps, we may then extract metrics over the similarities and differences between maps generated by these models trained on a given dataset with different data augmentation strategies. Experiments made using this methodology suggest that the effects of these data augmentation techniques not only can be analyzed in this way but also allow us to identify different impact profiles over the trained models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.12581v1",
    "published_date": "2025-05-19 00:03:57 UTC",
    "updated_date": "2025-05-19 00:03:57 UTC"
  }
]