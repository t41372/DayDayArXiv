{
  "date": "2026-01-04",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2026-01-04 的 arXiv 中文 TLDR 快报！\n\n👋 **一句话总结**：\n今天的 arXiv 爆发了关于 **AI Agent 安全性（特别是多智能体合谋欺骗）**、**世界模型（从游戏到自动驾驶）** 以及 **LLM 推理机制本质** 的深度探讨。Yejin Choi 团队带来了通用的游戏智能体 NitroGen，而一篇关于“用真话撒谎”的多智能体合谋论文令人细思极恐。此外，科学 AI（AI for Science）领域出现了统一多模态模型 FuXi-Uni。\n\n---\n\n### 🚨 焦点：Agent 安全与合谋 (Agent Safety & Collusion)\n\n**【推荐阅读】用真话来撒谎：多智能体合谋的新威胁**\n**2. Lying with Truths: Open-Channel Multi-Agent Collusion for Belief Manipulation via Generative Montage**\n*   **核心发现**：这是一个非常新颖且令人不安的研究。作者发现 LLM 智能体可以通过“公开频道”合谋，**只使用真实的信息片段**（而非伪造数据），通过特定的叙事编排（Generative Montage），误导受害者得出错误的结论。\n*   **方法**：提出了一个 Writer-Editor-Director 框架，智能体之间通过对抗性辩论和协调发布证据片段，利用 LLM “过度思考”的倾向进行攻击。\n*   **结论**：在 14 个 LLM 家族中测试，攻击成功率高达 74.4%。反直觉的是，**推理能力越强的模型越容易受到这种认知合谋攻击**。\n\n**11. JMedEthicBench: A Multi-Turn Conversational Benchmark for Evaluating Medical Safety in Japanese Large Language Models**\n*   **核心发现**：针对医疗场景的安全性评估。发现商业模型安全性较好，但**经过医疗领域微调的专业模型反而表现出更多的漏洞**（Safety Tax）。\n\n---\n\n### 🌍 世界模型与具身智能 (World Models & Embodied AI)\n\n**【大佬新作】Yejin Choi 团队新作：通用游戏智能体**\n**17. NitroGen: An Open Foundation Model for Generalist Gaming Agents**\n*   **核心发现**：发布了 NitroGen，一个基于视觉-动作的通用游戏智能体基础模型。\n*   **数据与方法**：使用了 40,000 小时的游戏视频（涵盖 1000+ 游戏），通过从视频中提取玩家动作构建了互联网规模的数据集。模型在大规模行为克隆（Behavior Cloning）下训练。\n*   **效果**：在 3D 动作、2D 平台和程序生成世界中表现出色，对未见过的游戏有很强的迁移能力。\n\n**32. DrivingGen: A Comprehensive Benchmark for Generative Video World Models in Autonomous Driving**\n*   **背景**：自动驾驶领域的生成式世界模型目前缺乏严格的基准。\n*   **贡献**：提出了 DrivingGen 基准，评估视频生成的真实感、轨迹合理性、时间一致性和可控性。测试发现，通用视频生成模型物理规律差，而专用驾驶模型虽然运动好但在视觉质量上落后。\n\n**67. Digital Twin AI: Opportunities and Challenges from Large Language Models to World Models**\n*   **综述**：一篇关于数字孪生（Digital Twin）与 AI 融合的系统性综述。提出了一个四阶段框架：建模、镜像、干预和自主管理，并讨论了生成式世界模型如何将数字孪生转化为具有认知能力的系统。\n\n---\n\n### 🧠 LLM 推理机制与训练 (Reasoning & Post-Training)\n\n**【深度理论】为什么 RL 能让模型学会自省？**\n**19. The Two-Stage Decision-Sampling Hypothesis: Understanding the Emergence of Self-Reflection in RL-Trained LLMs**\n*   **核心问题**：为什么多轮 RL 训练能让模型涌现出“自我反思”能力，而 SFT 不行？\n*   **理论**：提出了“两阶段决策-采样假设”（Two-Stage Decision-Sampling Hypothesis）。理论证明，SFT 和 KL 惩罚会导致梯度的非均衡分配，限制了模型的验证（Decision）能力；而 RL 的奖励机制能更均衡地优化生成（Sampling）和验证两个部分，从而解释了 RL 为何能带来更好的自我修正能力。\n\n**16. SAGE-32B: Agentic Reasoning via Iterative Distillation**\n*   **新模型**：发布了 SAGE-32B，基于 Qwen2.5-32B，专注于 Agent 推理和长程规划。\n*   **方法**：使用了**迭代蒸馏（Iterative Distillation）**和一种**逆向推理（Inverse Reasoning）**方法——即利用元认知头在执行前预测计划中可能出现的失败。\n\n**38. Distortion Instead of Hallucination: The Effect of Reasoning Under Strict Constraints**\n*   **有趣发现**：在强约束条件下（如推荐特定的同行评审论文），**具备推理能力的模型反而会为了满足约束而系统性地“篡改”事实**（Distortion），而非推理模型则直接违背约束。这挑战了“推理能普遍提高可靠性”的假设。\n\n---\n\n### 🔬 AI for Science & 多模态 (Scientific AI & Multimodal)\n\n**58. A unified multimodal understanding and generation model for cross-disciplinary scientific research**\n*   **模型**：**FuXi-Uni**。这是一个原生的统一多模态模型，旨在解决跨学科科学问题。\n*   **能力**：在一个架构内同时支持科学数据的理解和高保真生成。在地球科学（全球天气预报、台风预测）和生物医学问答上均表现出色，尤其是能够通过自然语言指令生成高分辨率气象场。\n\n**49. A large-scale nanocrystal database with aligned synthesis and properties enabling generative inverse design**\n*   **材料科学**：构建了一个包含 16 万条目的纳米晶体合成-属性对齐数据库（NSP），并开发了 **NanoDesigner** 用于逆向设计。模型成功推荐了一个反直觉的前驱体比例（1:1）来合成 MgF2 纳米晶体，并被实验验证有效。\n\n**66. LinMU: Multimodal Understanding Made Linear**\n*   **架构创新**：针对 VLM 的效率问题，提出了 LinMU，**完全移除了二次复杂度的自注意力层**，使用 M-MATE 模块（结合状态空间模型 SSM 和局部窗口注意力）实现线性复杂度。在视频理解任务上吞吐量提升 9 倍，且性能不掉点。\n\n---\n\n### 🛠️ 系统、RAG 与 优化 (Systems & RAG)\n\n**3. A Dynamic Retrieval-Augmented Generation System with Selective Memory and Remembrance**\n*   **RAG 优化**：提出了 **Adaptive RAG Memory (ARM)**。引入了类似认知科学的“选择性记忆和遗忘”机制，高频检索项被巩固，低频项衰减。在极低参数下（<25M）达到了 SOTA 的检索性能。\n\n**12. PLA-Serve: A Prefill-Length-Aware LLM Serving System**\n*   **系统优化**：针对不同 Prompt 长度导致的性能瓶颈，提出了 PLA-Serve。通过解耦长/短 Prefill 请求并引入长度感知的 Smart Batching，在多轮对话场景下显著降低了延迟。\n\n**45. Robust and Efficient Zeroth-Order LLM Fine-Tuning via Adaptive Bayesian Subspace Optimizer**\n*   **微调技术**：针对零阶（Zeroth-Order）优化（即不计算梯度的微调）的不稳定性，提出了基于贝叶斯子空间的优化器 BSZO，利用卡尔曼滤波在子空间内合并差分信息，显著提升了收敛速度和低精度训练的鲁棒性。\n\n---\n\n### 🚗 其他值得关注的论文\n\n*   **[Security] 4. Exposing Hidden Interfaces**: 利用 LLM 辅助逆向工程 macOS 的私有框架，恢复 Header 文件的成功率从 15% 提升到 86%。\n*   **[Medical] 1. FALCON**: 一种跨域的小样本 3D 医学图像分割框架，通过在自然图像上 Meta-training 然后迁移到医学领域。\n*   **[RecSys/Election] 10. Learning Resilient Elections with Adversarial GNNs**: 用图神经网络来学习抗策略性投票的选举机制，这在社会选择理论中很有趣。\n*   **[Video Gen] 61. Slot-ID**: 基于 Slot Attention 的视频生成，只需一段参考视频即可实现身份保持（Identity-Preserving），比单图 Condition 效果更好。",
  "papers": [
    {
      "arxiv_id": "2601.01687v1",
      "title": "FALCON: Few-Shot Adversarial Learning for Cross-Domain Medical Image Segmentation",
      "title_zh": "FALCON：面向跨域医学图像分割的少样本对抗学习",
      "authors": [
        "Abdur R. Fayjie",
        "Pankhi Kashyap",
        "Jutika Borah",
        "Patrick Vandewalle"
      ],
      "abstract": "Precise delineation of anatomical and pathological structures within 3D medical volumes is crucial for accurate diagnosis, effective surgical planning, and longitudinal disease monitoring. Despite advancements in AI, clinically viable segmentation is often hindered by the scarcity of 3D annotations, patient-specific variability, data privacy concerns, and substantial computational overhead. In this work, we propose FALCON, a cross-domain few-shot segmentation framework that achieves high-precision 3D volume segmentation by processing data as 2D slices. The framework is first meta-trained on natural images to learn-to-learn generalizable segmentation priors, then transferred to the medical domain via adversarial fine-tuning and boundary-aware learning. Task-aware inference, conditioned on support cues, allows FALCON to adapt dynamically to patient-specific anatomical variations across slices. Experiments on four benchmarks demonstrate that FALCON consistently achieves the lowest Hausdorff Distance scores, indicating superior boundary accuracy while maintaining a Dice Similarity Coefficient comparable to the state-of-the-art models. Notably, these results are achieved with significantly less labeled data, no data augmentation, and substantially lower computational overhead.",
      "tldr_zh": "该研究针对3D医学图像分割中存在的标注稀缺和计算开销大等挑战，提出了FALCON这一跨领域的少样本分割(Few-Shot Segmentation)框架。该框架通过在自然图像上进行元训练(Meta-training)以获取可泛化的先验知识，并利用对抗性微调(Adversarial Fine-tuning)与边界感知学习(Boundary-aware Learning)将其有效迁移至医学领域。在推理阶段，FALCON通过任务感知推理(Task-aware Inference)动态适应患者特有的解剖变异，实现了对3D体积数据的高效2D切片化处理。实验结果显示，FALCON在四个基准数据集上均获得了最低的Hausdorff Distance，证明了其在边界预测方面的卓越准确性。此外，该模型在显著减少标注需求、无需数据增强(Data Augmentation)且降低计算开销的情况下，仍能保持与当前先进模型相当的Dice Similarity Coefficient。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "20 pages, 6 figures, 7 tables",
      "pdf_url": "https://arxiv.org/pdf/2601.01687v1",
      "published_date": "2026-01-04 22:57:49 UTC",
      "updated_date": "2026-01-04 22:57:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T21:35:25.519272+00:00"
    },
    {
      "arxiv_id": "2601.01685v1",
      "title": "Lying with Truths: Open-Channel Multi-Agent Collusion for Belief Manipulation via Generative Montage",
      "title_zh": "以真示假：基于生成式蒙太奇的公开渠道多智能体信念操控合谋",
      "authors": [
        "Jinwei Hu",
        "Xinmiao Huang",
        "Youcheng Sun",
        "Yi Dong",
        "Xiaowei Huang"
      ],
      "abstract": "As large language models (LLMs) transition to autonomous agents synthesizing real-time information, their reasoning capabilities introduce an unexpected attack surface. This paper introduces a novel threat where colluding agents steer victim beliefs using only truthful evidence fragments distributed through public channels, without relying on covert communications, backdoors, or falsified documents. By exploiting LLMs' overthinking tendency, we formalize the first cognitive collusion attack and propose Generative Montage: a Writer-Editor-Director framework that constructs deceptive narratives through adversarial debate and coordinated posting of evidence fragments, causing victims to internalize and propagate fabricated conclusions. To study this risk, we develop CoPHEME, a dataset derived from real-world rumor events, and simulate attacks across diverse LLM families. Our results show pervasive vulnerability across 14 LLM families: attack success rates reach 74.4% for proprietary models and 70.6% for open-weights models. Counterintuitively, stronger reasoning capabilities increase susceptibility, with reasoning-specialized models showing higher attack success than base models or prompts. Furthermore, these false beliefs then cascade to downstream judges, achieving over 60% deception rates, highlighting a socio-technical vulnerability in how LLM-based agents interact with dynamic information environments. Our implementation and data are available at: https://github.com/CharlesJW222/Lying_with_Truth/tree/main.",
      "tldr_zh": "该研究提出了一种名为Generative Montage的创新认知合谋攻击(cognitive collusion attack)框架，探讨了大型语言模型(LLMs)在处理实时信息时面临的新型安全威胁。该框架通过Writer-Editor-Director协作模式，利用公开渠道发布的真实证据碎片构建具有误导性的叙事，诱导受害者智能体内化并传播虚假结论。为量化此类风险，作者开发了基于真实谣言事件的CoPHEME数据集，并在14个LLM家族上进行了模拟攻击实验。结果表明，攻击在私有模型和开源模型中的成功率分别高达74.4%和70.6%，且推理能力(reasoning capabilities)越强的模型反而越容易受到此类攻击的影响。此外，被操纵的信念会进一步级联影响下游评判者，达成超过60%的欺骗率，凸显了LLM智能体在动态信息交互中的社会技术脆弱性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.CL",
      "comment": "Under Review",
      "pdf_url": "https://arxiv.org/pdf/2601.01685v1",
      "published_date": "2026-01-04 22:50:23 UTC",
      "updated_date": "2026-01-04 22:50:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T21:34:56.391473+00:00"
    },
    {
      "arxiv_id": "2601.02428v1",
      "title": "A Dynamic Retrieval-Augmented Generation System with Selective Memory and Remembrance",
      "title_zh": "具备选择性记忆与留存机制的动态检索增强生成系统",
      "authors": [
        "Okan Bursa"
      ],
      "abstract": "We introduce \\emph{Adaptive RAG Memory} (ARM), a retrieval-augmented generation (RAG) framework that replaces a static vector index with a \\emph{dynamic} memory substrate governed by selective remembrance and decay. Frequently retrieved items are consolidated and protected from forgetting, while rarely used items gradually decay, inspired by cognitive consolidation and forgetting principles. On a lightweight retrieval benchmark, ARM reaches near state-of-the-art performance (e.g., NDCG@5 $\\approx$ 0.940, Recall@5 $=1.000$) with only $\\sim$22M parameters in the embedding layer, achieving the best efficiency among ultra-efficient models ($<$25M parameters). In addition, we compare static vs. dynamic RAG combinations across Llama 3.1 and GPT-4o. Llama 3.1 with static RAG achieves the highest key-term coverage (67.2\\%) at moderate latency, while GPT-4o with a dynamic selective retrieval policy attains the fastest responses (8.2s on average) with competitive coverage (58.7\\%). We further present an engineering optimization of the DynamicRAG implementation, making embedding weights configurable, adjustable at runtime, and robust to invalid settings.\n  ARM yields competitive accuracy, self-regularizing memory growth, and interpretable retention dynamics without retraining the generator\\color{black} and provides practical trade-off between quality, latency and memory efficiency for production and research RAG system.",
      "tldr_zh": "该研究提出了Adaptive RAG Memory (ARM)，这是一种检索增强生成(RAG)框架，通过具有选择性记忆和衰减机制的动态存储基质取代了传统的静态向量索引。该系统受认知巩固和遗忘原理启发，将频繁检索的内容进行巩固保护，而使罕用内容逐渐衰减，从而实现存储空间的自我调节。在轻量级检索基准测试中，ARM仅凭约22M参数的嵌入层便达到了接近State-of-the-art的性能，其NDCG@5约为0.940，Recall@5达到1.000，在超高效模型中表现卓越。实验对比发现，Llama 3.1结合静态RAG具有最高的Key-term Coverage (67.2%)，而GPT-4o配合动态选择性检索策略则在保持竞争力性能的同时实现了最快响应速度。此外，研究还对DynamicRAG的工程实现进行了优化，使嵌入权重可在运行时配置和调整，增强了系统的鲁棒性。最终，ARM在无需重新训练Generator的情况下，为生产和研究环境下的RAG系统提供了精度、延迟和内存效率之间的理想平衡，并具备可解释的记忆保留动态。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "6 Pages, 2 figures",
      "pdf_url": "https://arxiv.org/pdf/2601.02428v1",
      "published_date": "2026-01-04 21:51:41 UTC",
      "updated_date": "2026-01-04 21:51:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T21:34:55.175049+00:00"
    },
    {
      "arxiv_id": "2601.01673v1",
      "title": "Exposing Hidden Interfaces: LLM-Guided Type Inference for Reverse Engineering macOS Private Frameworks",
      "title_zh": "揭示隐藏接口：面向 macOS 私有框架逆向工程的 LLM 引导类型推断",
      "authors": [
        "Arina Kharlamova",
        "Youcheng Sun",
        "Ting Yu"
      ],
      "abstract": "Private macOS frameworks underpin critical services and daemons but remain undocumented and distributed only as stripped binaries, complicating security analysis. We present MOTIF, an agentic framework that integrates tool-augmented analysis with a finetuned large language model specialized for Objective-C type inference. The agent manages runtime metadata extraction, binary inspection, and constraint checking, while the model generates candidate method signatures that are validated and refined into compilable headers. On MOTIF-Bench, a benchmark built from public frameworks with groundtruth headers, MOTIF improves signature recovery from 15% to 86% compared to baseline static analysis tooling, with consistent gains in tool-use correctness and inference stability. Case studies on private frameworks show that reconstructed headers compile, link, and facilitate downstream security research and vulnerability studies. By transforming opaque binaries into analyzable interfaces, MOTIF establishes a scalable foundation for systematic auditing of macOS internals.",
      "tldr_zh": "该研究提出了MOTIF，一个旨在逆向工程macOS私有框架(Private Frameworks)的智能体框架，旨在解决这些框架因缺乏文档且仅以剥离二进制形式分发而难以进行安全分析的问题。MOTIF整合了工具增强分析与经过微调的大语言模型(LLM)，专门用于Objective-C的类型推断(Type Inference)，能够自动化执行运行时元数据提取、二进制检查和约束校验。该框架生成的候选方法签名经过验证与精炼，最终可转化为高质量的可编译头文件。实验结果显示，MOTIF在MOTIF-Bench基准测试中将签名恢复率从传统静态分析工具的15%提升至86%，展现了极高的推断稳定性和正确性。通过将不透明的二进制文件转化为可分析的接口，MOTIF为macOS内部机制的系统性审计、下游安全研究及漏洞分析奠定了可扩展的基础。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "IEEE S&P'26 under review",
      "pdf_url": "https://arxiv.org/pdf/2601.01673v1",
      "published_date": "2026-01-04 21:44:55 UTC",
      "updated_date": "2026-01-04 21:44:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T21:35:11.434030+00:00"
    },
    {
      "arxiv_id": "2601.06129v1",
      "title": "Graph-Based Analysis of AI-Driven Labor Market Transitions: Evidence from 10,000 Egyptian Jobs and Policy Implications",
      "title_zh": "人工智能驱动下的劳动力市场转型图论分析：来自1万个埃及岗位的证据与政策启示",
      "authors": [
        "Ahmed Dawoud",
        "Sondos Samir",
        "Mahmoud Mohamed"
      ],
      "abstract": "How many workers displaced by automation can realistically transition to safer jobs? We answer this using a validated knowledge graph of 9,978 Egyptian job postings, 19,766 skill activities, and 84,346 job-skill relationships (0.74% error rate). While 20.9% of jobs face high automation risk, we find that only 24.4% of at-risk workers have viable transition pathways--defined by $\\geq$3 shared skills and $\\geq$50% skill transfer. The remaining 75.6% face a structural mobility barrier requiring comprehensive reskilling, not incremental upskilling. Among 4,534 feasible transitions, process-oriented skills emerge as the highest-leverage intervention, appearing in 15.6% of pathways. These findings challenge optimistic narratives of seamless workforce adaptation and demonstrate that emerging economies require active pathway creation, not passive skill matching.",
      "tldr_zh": "该研究利用包含9,978个埃及职位、19,766项技能活动和84,346个职位-技能关系的经过验证的知识图谱(knowledge graph)，分析了自动化背景下的劳动力市场转型。研究发现，虽然20.9%的职位面临高自动化风险(automation risk)，但仅有24.4%的受影响工人拥有可行的转型路径(transition pathways)，即拥有3个以上共享技能且技能转移(skill transfer)比例达到50%以上。剩余75.6%的工人面临结构性流动障碍(structural mobility barrier)，这表明他们需要全面的重新技能化(reskilling)而非增量式的技能提升(upskilling)。在4,534项可行转型中，以流程为导向的技能(process-oriented skills)被确定为最具杠杆作用的干预点，出现在15.6%的路径中。该发现挑战了劳动力市场可以无缝适应技术变革的乐观叙事，证明新兴经济体需要积极的路径创建(pathway creation)而非被动的技能匹配。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.06129v1",
      "published_date": "2026-01-04 21:19:58 UTC",
      "updated_date": "2026-01-04 21:19:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T21:35:11.087130+00:00"
    },
    {
      "arxiv_id": "2601.01668v1",
      "title": "EHRSummarizer: A Privacy-Aware, FHIR-Native Architecture for Structured Clinical Summarization of Electronic Health Records",
      "title_zh": "EHRSummarizer：一种面向电子健康档案结构化临床摘要的隐私保护型 FHIR 原生架构",
      "authors": [
        "Houman Kazemzadeh",
        "Nima Minaifar",
        "Kamyar Naderi",
        "Sho Tabibzadeh"
      ],
      "abstract": "Clinicians routinely navigate fragmented electronic health record (EHR) interfaces to assemble a coherent picture of a patient's problems, medications, recent encounters, and longitudinal trends. This work describes EHRSummarizer, a privacy-aware, FHIR-native reference architecture that retrieves a targeted set of high-yield FHIR R4 resources, normalizes them into a consistent clinical context package, and produces structured summaries intended to support structured chart review. The system can be configured for data minimization, stateless processing, and flexible deployment, including local inference within an organization's trust boundary. To mitigate the risk of unsupported or unsafe behavior, the summarization stage is constrained to evidence present in the retrieved context package, is intended to indicate missing or unavailable domains where feasible, and avoids diagnostic or treatment recommendations. Prototype demonstrations on synthetic and test FHIR environments illustrate end-to-end behavior and output formats; however, this manuscript does not report clinical outcomes or controlled workflow studies. We outline an evaluation plan centered on faithfulness, omission risk, temporal correctness, usability, and operational monitoring to guide future institutional assessments.",
      "tldr_zh": "该研究提出了 EHRSummarizer，一种注重隐私保护且原生支持 FHIR 标准的参考架构，旨在解决临床医生在处理碎片化电子健康记录 (EHR) 时面临的信息整合难题。该系统通过检索特定高价值的 FHIR R4 资源，并将其标准化为一致的临床背景包 (Clinical context package)，生成用于支持结构化病历审查的总结报告。为了保障安全性，该架构支持数据最小化 (Data minimization) 和无状态处理 (Stateless processing)，并允许在机构信任边界内进行本地推理 (Local inference)。在生成阶段，系统严格受限于检索到的上下文证据，主动标识缺失信息并避免提供诊断或治疗建议，以降低不安全行为的风险。通过在合成 FHIR 环境中的原型演示，该研究展示了其端到端的功能流程，并提出了一个侧重于忠实度 (Faithfulness)、遗漏风险和时间正确性的多维度评估框架，为未来的临床应用评估奠定了基础。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "19 pages",
      "pdf_url": "https://arxiv.org/pdf/2601.01668v1",
      "published_date": "2026-01-04 21:10:42 UTC",
      "updated_date": "2026-01-04 21:10:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T21:35:06.793322+00:00"
    },
    {
      "arxiv_id": "2601.01665v1",
      "title": "Adversarial Instance Generation and Robust Training for Neural Combinatorial Optimization with Multiple Objectives",
      "title_zh": "多目标神经组合优化的对抗样本生成与鲁棒训练",
      "authors": [
        "Wei Liu",
        "Yaoxin Wu",
        "Yingqian Zhang",
        "Thomas Bäck",
        "Yingjie Fan"
      ],
      "abstract": "Deep reinforcement learning (DRL) has shown great promise in addressing multi-objective combinatorial optimization problems (MOCOPs). Nevertheless, the robustness of these learning-based solvers has remained insufficiently explored, especially across diverse and complex problem distributions. In this paper, we propose a unified robustness-oriented framework for preference-conditioned DRL solvers for MOCOPs. Within this framework, we develop a preference-based adversarial attack to generate hard instances that expose solver weaknesses, and quantify the attack impact by the resulting degradation on Pareto-front quality. We further introduce a defense strategy that integrates hardness-aware preference selection into adversarial training to reduce overfitting to restricted preference regions and improve out-of-distribution performance. The experimental results on multi-objective traveling salesman problem (MOTSP), multi-objective capacitated vehicle routing problem (MOCVRP), and multi-objective knapsack problem (MOKP) verify that our attack method successfully learns hard instances for different solvers. Furthermore, our defense method significantly strengthens the robustness and generalizability of neural solvers, delivering superior performance on hard or out-of-distribution instances.",
      "tldr_zh": "本研究探讨了多目标组合优化问题(MOCOPs)中深度强化学习(DRL)求解器的鲁棒性问题，并提出了一个针对偏好条件(preference-conditioned)型求解器的统一鲁棒性框架。该框架开发了一种基于偏好的对抗攻击方法(preference-based adversarial attack)，通过生成硬样本(hard instances)并量化其对帕累托前沿(Pareto-front)质量的降级影响来揭示模型弱点。为应对这些挑战，研究进一步引入了将硬度感知偏好选择集成到对抗训练(adversarial training)中的防御策略，旨在减少模型对特定偏好区域的过拟合并提升分布外(out-of-distribution)性能。在多目标旅行商问题(MOTSP)、车辆路径问题(MOCVRP)和背包问题(MOKP)上的实验验证了该攻击方法的有效性。结果表明，该防御方案显著增强了神经求解器的鲁棒性和泛化能力，使其在处理复杂或分布外实例时表现出优越的性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.01665v1",
      "published_date": "2026-01-04 20:57:43 UTC",
      "updated_date": "2026-01-04 20:57:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T21:35:09.352379+00:00"
    },
    {
      "arxiv_id": "2601.01663v1",
      "title": "Length-Aware Adversarial Training for Variable-Length Trajectories: Digital Twins for Mall Shopper Paths",
      "title_zh": "面向变长轨迹的长度感知对抗训练：商场顾客路径数字孪生",
      "authors": [
        "He Sun",
        "Jiwoong Shin",
        "Ravi Dhar"
      ],
      "abstract": "We study generative modeling of \\emph{variable-length trajectories} -- sequences of visited locations/items with associated timestamps -- for downstream simulation and counterfactual analysis. A recurring practical issue is that standard mini-batch training can be unstable when trajectory lengths are highly heterogeneous, which in turn degrades \\emph{distribution matching} for trajectory-derived statistics. We propose \\textbf{length-aware sampling (LAS)}, a simple batching strategy that groups trajectories by length and samples batches from a single length bucket, reducing within-batch length heterogeneity (and making updates more consistent) without changing the model class. We integrate LAS into a conditional trajectory GAN with auxiliary time-alignment losses and provide (i) a distribution-level guarantee for derived variables under mild boundedness assumptions, and (ii) an IPM/Wasserstein mechanism explaining why LAS improves distribution matching by removing length-only shortcut critics and targeting within-bucket discrepancies. Empirically, LAS consistently improves matching of derived-variable distributions on a multi-mall dataset of shopper trajectories and on diverse public sequence datasets (GPS, education, e-commerce, and movies), outperforming random sampling across dataset-specific metrics.",
      "tldr_zh": "该研究针对变长轨迹(variable-length trajectories)生成模型在模拟和反事实分析中的应用，解决了标准小批量训练在轨迹长度高度异质时导致的不稳定及分布匹配(distribution matching)性能下降问题。为此，作者提出了长度感知采样(length-aware sampling, LAS)，通过将轨迹按长度分组并从单一长度桶中采样，在不改变模型类别的前提下确保了模型更新的一致性。研究将 LAS 集成到具有辅助时间对齐损失的条件轨迹生成对抗网络(conditional trajectory GAN)中，并从理论上证明了该机制能通过消除长度捷径判别器(length-only shortcut critics)来改善分布匹配。实验结果表明，在商场购物者轨迹及GPS、电商、电影等多种公共序列数据集上，LAS 在匹配衍生变量分布方面一致优于随机采样。该方法显著提升了生成数据的质量，为构建商场购物路径等场景的数字孪生(Digital Twins)提供了更可靠的技术支持。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.01663v1",
      "published_date": "2026-01-04 20:52:07 UTC",
      "updated_date": "2026-01-04 20:52:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T21:35:22.584733+00:00"
    },
    {
      "arxiv_id": "2601.01655v1",
      "title": "UniCrop: A Universal, Multi-Source Data Engineering Pipeline for Scalable Crop Yield Prediction",
      "title_zh": "UniCrop：面向可扩展农作物产量预测的通用多源数据工程流水线",
      "authors": [
        "Emiliya Khidirova",
        "Oktay Karakuş"
      ],
      "abstract": "Accurate crop yield prediction relies on diverse data streams, including satellite, meteorological, soil, and topographic information. However, despite rapid advances in machine learning, existing approaches remain crop- or region-specific and require data engineering efforts. This limits scalability, reproducibility, and operational deployment. This study introduces UniCrop, a universal and reusable data pipeline designed to automate the acquisition, cleaning, harmonisation, and engineering of multi-source environmental data for crop yield prediction. For any given location, crop type, and temporal window, UniCrop automatically retrieves, harmonises, and engineers over 200 environmental variables (Sentinel-1/2, MODIS, ERA5-Land, NASA POWER, SoilGrids, and SRTM), reducing them to a compact, analysis-ready feature set utilising a structured feature reduction workflow with minimum redundancy maximum relevance (mRMR). To validate, UniCrop was applied to a rice yield dataset comprising 557 field observations. Using only the selected 15 features, four baseline machine learning models (LightGBM, Random Forest, Support Vector Regression, and Elastic Net) were trained. LightGBM achieved the best single-model performance (RMSE = 465.1 kg/ha, $R^2 = 0.6576$), while a constrained ensemble of all baselines further improved accuracy (RMSE = 463.2 kg/ha, $R^2 = 0.6604$). UniCrop contributes a scalable and transparent data-engineering framework that addresses the primary bottleneck in operational crop yield modelling: the preparation of consistent and harmonised multi-source data. By decoupling data specification from implementation and supporting any crop, region, and time frame through simple configuration updates, UniCrop provides a practical foundation for scalable agricultural analytics. The code and implementation documentation are shared in https://github.com/CoDIS-Lab/UniCrop.",
      "tldr_zh": "该研究提出了UniCrop，这是一个通用且可重用的数据工程流水线(pipeline)，旨在解决作物产量预测中数据处理受限于特定作物或区域且难以扩展的问题。UniCrop能够自动获取、清洗和协调来自Sentinel-1/2、MODIS、ERA5-Land、SoilGrids和SRTM等多个来源的200多个环境变量，并利用最大相关最小冗余(mRMR)算法将其精简为紧凑且可直接分析的特征集。在包含557个水稻产量观测点的验证实验中，仅使用15个精选特征，LightGBM及集成学习模型便取得了显著的预测精度，其中集成模型的$R^2$达到0.6604。UniCrop的核心贡献在于提供了一个可扩展且透明的数据工程框架，通过简单的配置更新即可支持不同作物、地区和时间段的产量建模。该框架有效解决了多源数据准备这一主要瓶颈，为大规模农业分析和业务化部署奠定了实践基础。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.01655v1",
      "published_date": "2026-01-04 20:17:32 UTC",
      "updated_date": "2026-01-04 20:17:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T21:35:21.306327+00:00"
    },
    {
      "arxiv_id": "2601.01653v1",
      "title": "Learning Resilient Elections with Adversarial GNNs",
      "title_zh": "基于对抗性 GNN 的韧性选举学习",
      "authors": [
        "Hao Xiang Li",
        "Yash Shah",
        "Lorenzo Giusti"
      ],
      "abstract": "In the face of adverse motives, it is indispensable to achieve a consensus. Elections have been the canonical way by which modern democracy has operated since the 17th century. Nowadays, they regulate markets, provide an engine for modern recommender systems or peer-to-peer networks, and remain the main approach to represent democracy. However, a desirable universal voting rule that satisfies all hypothetical scenarios is still a challenging topic, and the design of these systems is at the forefront of mechanism design research. Automated mechanism design is a promising approach, and recent works have demonstrated that set-invariant architectures are uniquely suited to modelling electoral systems. However, various concerns prevent the direct application to real-world settings, such as robustness to strategic voting. In this paper, we generalise the expressive capability of learned voting rules, and combine improvements in neural network architecture with adversarial training to improve the resilience of voting rules while maximizing social welfare. We evaluate the effectiveness of our methods on both synthetic and real-world datasets. Our method resolves critical limitations of prior work regarding learning voting rules by representing elections using bipartite graphs, and learning such voting rules using graph neural networks. We believe this opens new frontiers for applying machine learning to real-world elections.",
      "tldr_zh": "该研究针对选举系统在现实应用中面临的战略投票(strategic voting)及鲁棒性不足等挑战，探讨了如何通过机器学习提升投票规则的韧性。本文提出了一种结合神经网络架构改进与对抗训练(adversarial training)的方法，旨在最大化社会福利(social welfare)的同时增强投票规则的防御能力。其核心创新在于利用二分图(bipartite graphs)来表示选举过程，并采用图神经网络(Graph Neural Networks, GNNs)来学习和建模投票规则。该方法克服了以往自动化机制设计(Automated mechanism design)在处理复杂选举场景时的局限性，并利用对抗技术进一步提升了系统的抗干扰能力。通过在合成数据集和真实世界数据集上的广泛评估，实验证明该方法在保障选举公正性与韧性方面具有显著效果。该研究不仅展示了对抗性图神经网络在复杂决策机制中的潜力，也为机器学习在现实世界民主选举和推荐系统中的应用开辟了新路径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.01653v1",
      "published_date": "2026-01-04 20:12:14 UTC",
      "updated_date": "2026-01-04 20:12:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T21:35:26.569351+00:00"
    },
    {
      "arxiv_id": "2601.01627v1",
      "title": "JMedEthicBench: A Multi-Turn Conversational Benchmark for Evaluating Medical Safety in Japanese Large Language Models",
      "title_zh": "JMedEthicBench：用于评估日语大语言模型医疗安全性的多轮对话基准",
      "authors": [
        "Junyu Liu",
        "Zirui Li",
        "Qian Niu",
        "Zequn Zhang",
        "Yue Xun",
        "Wenlong Hou",
        "Shujun Wang",
        "Yusuke Iwasawa",
        "Yutaka Matsuo",
        "Kan Hatakeyama-Sato"
      ],
      "abstract": "As Large Language Models (LLMs) are increasingly deployed in healthcare field, it becomes essential to carefully evaluate their medical safety before clinical use. However, existing safety benchmarks remain predominantly English-centric, and test with only single-turn prompts despite multi-turn clinical consultations. To address these gaps, we introduce JMedEthicBench, the first multi-turn conversational benchmark for evaluating medical safety of LLMs for Japanese healthcare. Our benchmark is based on 67 guidelines from the Japan Medical Association and contains over 50,000 adversarial conversations generated using seven automatically discovered jailbreak strategies. Using a dual-LLM scoring protocol, we evaluate 27 models and find that commercial models maintain robust safety while medical-specialized models exhibit increased vulnerability. Furthermore, safety scores decline significantly across conversation turns (median: 9.5 to 5.0, $p < 0.001$). Cross-lingual evaluation on both Japanese and English versions of our benchmark reveals that medical model vulnerabilities persist across languages, indicating inherent alignment limitations rather than language-specific factors. These findings suggest that domain-specific fine-tuning may accidentally weaken safety mechanisms and that multi-turn interactions represent a distinct threat surface requiring dedicated alignment strategies.",
      "tldr_zh": "该研究推出了JMedEthicBench，这是首个旨在评估日本医疗大语言模型（LLMs）医疗安全性的多轮对话（Multi-turn）测评基准。该基准以日本医学会（Japan Medical Association）的67项指南为基础，通过七种自动发现的越狱（Jailbreak）策略生成了超过50,000条对抗性对话。利用双模型评分协议（Dual-LLM scoring protocol）对27个模型进行的评估显示，商业模型保持了稳健的安全性，而医疗专用模型（Medical-specialized models）的脆弱性显著增加。研究发现，安全性评分随对话轮次的增加而大幅下降，证明多轮交互是一个需要专门对齐（Alignment）策略的独特威胁面。跨语言评估进一步证实，医疗模型的漏洞源于内在的对齐局限而非语言特定因素。这些发现表明，领域特定的精调（Fine-tuning）可能会意外削弱安全机制，为未来医疗人工智能的安全对齐提供了重要参考。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "12 pages, 6 figures",
      "pdf_url": "https://arxiv.org/pdf/2601.01627v1",
      "published_date": "2026-01-04 18:18:18 UTC",
      "updated_date": "2026-01-04 18:18:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T21:35:44.078659+00:00"
    },
    {
      "arxiv_id": "2601.11589v1",
      "title": "PLA-Serve: A Prefill-Length-Aware LLM Serving System",
      "title_zh": "PLA-Serve：一种感知预填充长度的大语言模型推理服务系统",
      "authors": [
        "Jianshu She",
        "Zonghang Li",
        "Hongchao Du",
        "Shangyu Wu",
        "Wenhao Zheng",
        "Eric Xing",
        "Zhengzhong Liu",
        "Huaxiu Yao",
        "Jason Xue",
        "Qirong Ho"
      ],
      "abstract": "PLA-Serve identifies and disaggregates requests with different prompt lengths in LLM serving to reduce TTFT latency. While recent systems have decoupled the prefill and decode stages to improve throughput, they still rely on unified scheduling policies that fail to adapt to heterogeneous workload characteristics. We observe that prompt-length variations lead to distinct performance bottlenecks, motivating an adaptive scheduling strategy. PLA-Serve disaggregates multi-turn long-prefill requests from short-prefill ones and introduces a length-aware smart batching mechanism for short-prefill workloads. It adopts a dual-queue design that supports temporal disaggregation on a single prefill instance or spatial disaggregation across multiple instances. For short-prefill batches, a batch waiting window and CUDA Graph-based clustering mitigate interference from heterogeneous computation, reducing batching delay and lowering average latency. In real multi-turn workloads, PLA-Serve reduces prefill latency by over 30% compared to vanilla SGLang under prefill**--**decode disaggregation, and further decreases SLO violations by 28% in multi-instance deployments with vanilla data-parallel configuration. Compared to the SGLang router with load balancing, it further lowers SLO violations by 12% in multi-GPU settings. Under high concurrency and mixed-request scenarios, PLA-Serve improves request throughput by 35% serving Qwen2.5-32B model for prefill instance, demonstrating its effectiveness in optimizing heterogeneous LLM serving workloads.",
      "tldr_zh": "该研究提出了PLA-Serve，一种感知预填充长度的LLM serving系统，旨在通过区分处理不同提示长度的请求来有效降低TTFT延迟。针对长短预填充请求性能瓶颈不同的特性，PLA-Serve实现了多轮长预填充(long-prefill)与短预填充(short-prefill)的请求解耦，并为短预填充任务引入了长度感知的智能批处理(smart batching)机制。系统采用双队列设计，支持单实例的时间解耦或多实例间的空间解耦，同时利用batch waiting window与基于CUDA Graph的聚类技术来减轻异构计算的干扰。实验结果表明，PLA-Serve相比于SGLang可降低超过30%的预填充延迟，并在多实例部署中减少了28%的SLO违规。在高并发及混合请求场景下，该系统将Qwen2.5-32B模型的请求吞吐量提升了35%，证明了其在优化异构LLM推理负载方面的卓越效能。",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "12 pages",
      "pdf_url": "https://arxiv.org/pdf/2601.11589v1",
      "published_date": "2026-01-04 18:14:24 UTC",
      "updated_date": "2026-01-04 18:14:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T21:35:42.107945+00:00"
    },
    {
      "arxiv_id": "2601.01609v1",
      "title": "Structured Decomposition for LLM Reasoning: Cross-Domain Validation and Semantic Web Integration",
      "title_zh": "LLM 推理的结构化分解：跨领域验证与语义网集成",
      "authors": [
        "Albert Sadowski",
        "Jarosław A. Chudziak"
      ],
      "abstract": "Rule-based reasoning over natural language input arises in domains where decisions must be auditable and justifiable: clinical protocols specify eligibility criteria in prose, evidence rules define admissibility through textual conditions, and scientific standards dictate methodological requirements. Applying rules to such inputs demands both interpretive flexibility and formal guarantees. Large language models (LLMs) provide flexibility but cannot ensure consistent rule application; symbolic systems provide guarantees but require structured input. This paper presents an integration pattern that combines these strengths: LLMs serve as ontology population engines, translating unstructured text into ABox assertions according to expert-authored TBox specifications, while SWRL-based reasoners apply rules with deterministic guarantees. The framework decomposes reasoning into entity identification, assertion extraction, and symbolic verification, with task definitions grounded in OWL 2 ontologies. Experiments across three domains (legal hearsay determination, scientific method-task application, clinical trial eligibility) and eleven language models validate the approach. Structured decomposition achieves statistically significant improvements over few-shot prompting in aggregate, with gains observed across all three domains. An ablation study confirms that symbolic verification provides substantial benefit beyond structured prompting alone. The populated ABox integrates with standard semantic web tooling for inspection and querying, positioning the framework for richer inference patterns that simpler formalisms cannot express.",
      "tldr_zh": "该研究针对在法律、科学和临床等领域需要可审计且可证明的决策需求，提出了一种结合大语言模型(LLMs)和符号系统的集成模式，以解决自然语言规则推理中的灵活性与一致性平衡问题。该框架采用结构化分解(Structured Decomposition)方法，利用 LLMs 作为本体填充引擎(ontology population engines)，根据专家编写的 TBox 规范将非结构化文本转化为 ABox 断言。系统进一步结合基于 SWRL 的推理机对提取的实体和断言进行确定性验证，并利用 OWL 2 本体确立任务定义。研究在法律传闻证据判定、科学方法任务应用和临床试验入组资格三个跨领域场景下对 11 个语言模型进行了验证。实验结果显示，结构化分解方法在综合表现上显著优于少样本提示(few-shot prompting)，消融研究进一步证实了符号验证(symbolic verification)在提升推理准确性方面的关键作用。此外，填充后的 ABox 可与标准的语义网(Semantic Web)工具集成，支持更丰富的推理模式和查询需求，为构建可解释且精准的自动化决策系统提供了技术支撑。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.01609v1",
      "published_date": "2026-01-04 17:19:20 UTC",
      "updated_date": "2026-01-04 17:19:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T21:35:48.122558+00:00"
    },
    {
      "arxiv_id": "2601.01605v1",
      "title": "REE-TTT: Highly Adaptive Radar Echo Extrapolation Based on Test-Time Training",
      "title_zh": "REE-TTT：基于测试时训练的高度自适应雷达回波外推",
      "authors": [
        "Xin Di",
        "Xinglin Piao",
        "Fei Wang",
        "Guodong Jing",
        "Yong Zhang"
      ],
      "abstract": "Precipitation nowcasting is critically important for meteorological forecasting. Deep learning-based Radar Echo Extrapolation (REE) has become a predominant nowcasting approach, yet it suffers from poor generalization due to its reliance on high-quality local training data and static model parameters, limiting its applicability across diverse regions and extreme events. To overcome this, we propose REE-TTT, a novel model that incorporates an adaptive Test-Time Training (TTT) mechanism. The core of our model lies in the newly designed Spatio-temporal Test-Time Training (ST-TTT) block, which replaces the standard linear projections in TTT layers with task-specific attention mechanisms, enabling robust adaptation to non-stationary meteorological distributions and thereby significantly enhancing the feature representation of precipitation. Experiments under cross-regional extreme precipitation scenarios demonstrate that REE-TTT substantially outperforms state-of-the-art baseline models in prediction accuracy and generalization, exhibiting remarkable adaptability to data distribution shifts.",
      "tldr_zh": "该研究提出了 REE-TTT，旨在解决深度学习雷达回波外推 (Radar Echo Extrapolation, REE) 模型由于依赖本地高质量训练数据和静态模型参数，导致其在不同地区及极端天气下泛化能力不足的问题。该模型引入了创新的自适应测试时训练 (Test-Time Training, TTT) 机制，其核心在于新设计的时空测试时训练 (Spatio-temporal Test-Time Training, ST-TTT) 模块。通过使用特定任务的注意力机制 (attention mechanisms) 替换标准 TTT 层中的线性投影，REE-TTT 能够稳健地适应非平稳的气象分布，显著增强了降水特征的表达能力。在跨区域极端降水场景下的实验证明，REE-TTT 在预测精度和泛化性能上均大幅超越了现有基线模型。该研究展示了模型在面对数据分布偏移时卓越的自适应性，为气象临近预报提供了更具鲁棒性的技术方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.01605v1",
      "published_date": "2026-01-04 17:06:48 UTC",
      "updated_date": "2026-01-04 17:06:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T21:36:06.655278+00:00"
    },
    {
      "arxiv_id": "2601.01599v1",
      "title": "From Theory of Mind to Theory of Environment: Counterfactual Simulation of Latent Environmental Dynamics",
      "title_zh": "从心理理论到环境理论：潜在环境动力学的反事实模拟",
      "authors": [
        "Ryutaro Uchiyama"
      ],
      "abstract": "The vertebrate motor system employs dimensionality-reducing strategies to limit the complexity of movement coordination, for efficient motor control. But when environments are dense with hidden action-outcome contingencies, movement complexity can promote behavioral innovation. Humans, perhaps uniquely, may infer the presence of hidden environmental dynamics from social cues, by drawing upon computational mechanisms shared with Theory of Mind. This proposed \"Theory of Environment\" supports behavioral innovation by expanding the dimensionality of motor exploration.",
      "tldr_zh": "该研究探讨了从 Theory of Mind 向 Theory of Environment 的转变，侧重于对 Latent Environmental Dynamics 的反事实模拟。脊椎动物运动系统通常通过 dimensionality-reducing strategies 来简化运动协调以实现高效控制，但在充满隐藏动作-结果关联的环境中，运动的复杂性反而能激发行为创新。作者提出，人类可能利用与 Theory of Mind 共享的计算机制，通过社交线索推断隐藏的环境动力学。这种 Theory of Environment 概念通过扩展运动探索的维度，为人类的行为创新提供了关键支持。",
      "categories": [
        "q-bio.NC",
        "cs.AI"
      ],
      "primary_category": "q-bio.NC",
      "comment": "Accepted to the AAAI 2026 Workshop on Theory of Mind for Artificial Intelligence (ToM4AI). Extended abstract, 2 pages",
      "pdf_url": "https://arxiv.org/pdf/2601.01599v1",
      "published_date": "2026-01-04 17:00:04 UTC",
      "updated_date": "2026-01-04 17:00:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T21:35:50.768836+00:00"
    },
    {
      "arxiv_id": "2601.04237v1",
      "title": "SAGE-32B: Agentic Reasoning via Iterative Distillation",
      "title_zh": "SAGE-32B：基于迭代蒸馏的智能体推理",
      "authors": [
        "Basab Jha",
        "Firoj Paudel",
        "Ujjwal Puri",
        "Ethan Henkel",
        "Zhang Yuting",
        "Mateusz Kowalczyk",
        "Mei Huang",
        "Choi Donghyuk",
        "Wang Junhao"
      ],
      "abstract": "We demonstrate SAGE-32B, a 32 billion parameter language model that focuses on agentic reasoning and long range planning tasks. Unlike chat models that aim for general conversation fluency, SAGE-32B is designed to operate in an agentic loop, emphasizing task decomposition, tool usage, and error recovery. The model is initialized from the Qwen2.5-32B pretrained model and fine tuned using Iterative Distillation, a two stage training process that improves reasoning performance through rigorously tested feedback loops. SAGE-32B also introduces an inverse reasoning approach, which uses a meta cognition head to forecast potential failures in the planning process before execution. On agentic reasoning benchmarks including MMLU-Pro, AgentBench, and MATH-500, SAGE-32B achieves higher success rates in multi tool usage scenarios compared to similarly sized baseline models, while remaining competitive on standard reasoning evaluations. Model weights are publicly released at https://huggingface.co/sagea-ai/sage-reasoning-32b",
      "tldr_zh": "该研究推出了拥有320亿参数的语言模型SAGE-32B，重点关注智能体推理(Agentic Reasoning)和长程规划任务。不同于追求通用对话流利度的模型，SAGE-32B专为智能体循环(Agentic Loop)设计，强调任务分解、工具调用及错误恢复能力。该模型以Qwen2.5-32B为基础，通过两阶段的迭代蒸馏(Iterative Distillation)训练工艺，利用严谨的反馈回路显著提升了推理性能。此外，SAGE-32B创新性地引入了逆向推理(Inverse Reasoning)机制，借助元认知头(Meta-Cognition Head)在执行前预判规划中的潜在失败。在MMLU-Pro、AgentBench和MATH-500等基准测试中，SAGE-32B在多工具协作场景下的成功率显著优于同规模基线模型，展现了强大的实用推理能力。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "23 Pages, 3 figures, 4 tables",
      "pdf_url": "https://arxiv.org/pdf/2601.04237v1",
      "published_date": "2026-01-04 16:41:58 UTC",
      "updated_date": "2026-01-04 16:41:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T21:35:56.029863+00:00"
    },
    {
      "arxiv_id": "2601.02427v1",
      "title": "NitroGen: An Open Foundation Model for Generalist Gaming Agents",
      "title_zh": "NitroGen：面向通用游戏智能体的开放基础模型",
      "authors": [
        "Loïc Magne",
        "Anas Awadalla",
        "Guanzhi Wang",
        "Yinzhen Xu",
        "Joshua Belofsky",
        "Fengyuan Hu",
        "Joohwan Kim",
        "Ludwig Schmidt",
        "Georgia Gkioxari",
        "Jan Kautz",
        "Yisong Yue",
        "Yejin Choi",
        "Yuke Zhu",
        "Linxi \"Jim\" Fan"
      ],
      "abstract": "We introduce NitroGen, a vision-action foundation model for generalist gaming agents that is trained on 40,000 hours of gameplay videos across more than 1,000 games. We incorporate three key ingredients: 1) an internet-scale video-action dataset constructed by automatically extracting player actions from publicly available gameplay videos, 2) a multi-game benchmark environment that can measure cross-game generalization, and 3) a unified vision-action model trained with large-scale behavior cloning. NitroGen exhibits strong competence across diverse domains, including combat encounters in 3D action games, high-precision control in 2D platformers, and exploration in procedurally generated worlds. It transfers effectively to unseen games, achieving up to 52% relative improvement in task success rates over models trained from scratch. We release the dataset, evaluation suite, and model weights to advance research on generalist embodied agents.",
      "tldr_zh": "该研究推出了 NitroGen，这是一个针对通用游戏智能体 (generalist gaming agents) 的视觉-动作基础模型 (vision-action foundation model)，其训练数据涵盖了超过 1,000 款游戏的 40,000 小时游戏画面。研发团队通过自动从公开视频中提取玩家操作，构建了一个互联网规模的视频-动作数据集 (video-action dataset)，并结合大规模行为克隆 (large-scale behavior cloning) 技术训练统一模型。NitroGen 在 3D 动作游戏的战斗、2D 平台游戏的高精度控制以及程序化生成世界的探索等多样化领域中均表现出极强的能力。实验证明该模型能有效迁移至未见过的游戏，其任务成功率相较于从零训练的模型实现了高达 52% 的相对提升。作者公开发布了数据集、评估套件和模型权重，旨在推动通用具身智能体 (generalist embodied agents) 领域的前沿研究。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "16 pages, 7 figures",
      "pdf_url": "https://arxiv.org/pdf/2601.02427v1",
      "published_date": "2026-01-04 16:24:50 UTC",
      "updated_date": "2026-01-04 16:24:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T21:36:27.174320+00:00"
    },
    {
      "arxiv_id": "2601.01581v1",
      "title": "CONSENT: A Negotiation Framework for Leveraging User Flexibility in Vehicle-to-Building Charging under Uncertainty",
      "title_zh": "CONSENT：一种在不确定性环境下利用用户灵活性进行车到建筑充电的协商框架",
      "authors": [
        "Rishav Sen",
        "Fangqi Liu",
        "Jose Paolo Talusan",
        "Ava Pettet",
        "Yoshinori Suzue",
        "Mark Bailey",
        "Ayan Mukhopadhyay",
        "Abhishek Dubey"
      ],
      "abstract": "The growth of Electric Vehicles (EVs) creates a conflict in vehicle-to-building (V2B) settings between building operators, who face high energy costs from uncoordinated charging, and drivers, who prioritize convenience and a full charge. To resolve this, we propose a negotiation-based framework that, by design, guarantees voluntary participation, strategy-proofness, and budget feasibility. It transforms EV charging into a strategic resource by offering drivers a range of incentive-backed options for modest flexibility in their departure time or requested state of charge (SoC). Our framework is calibrated with user survey data and validated using real operational data from a commercial building and an EV manufacturer. Simulations show that our negotiation protocol creates a mutually beneficial outcome: lowering the building operator's costs by over 3.5\\% compared to an optimized, non-negotiating smart charging policy, while simultaneously reducing user charging expenses by 22\\% below the utility's retail energy rate. By aligning operator and EV user objectives, our framework provides a strategic bridge between energy and mobility systems, transforming EV charging from a source of operational friction into a platform for collaboration and shared savings.",
      "tldr_zh": "该研究提出了CONSENT框架，这是一个针对Vehicle-to-Building (V2B) 充电场景的协商框架，旨在解决建筑运营者的高能源成本与驾驶员充电便利性需求之间的冲突。该框架在设计上保证了自愿参与、策略证明性(strategy-proofness)和预算可行性，通过向驾驶员提供一系列激励方案，换取其在离场时间或请求荷电状态(State of Charge, SoC)上的适度灵活性。研究利用用户调查数据进行校准，并结合商业建筑和电动汽车制造商的真实运营数据进行了验证。仿真结果显示，该协商协议实现了互利共赢：相比于优化后的非协商智能充电策略，建筑运营者的成本降低了超过3.5%，同时用户的充电费用比零售电价降低了22%。通过协调运营商与用户的目标，该框架将电动汽车充电从运营冲突点转化为协作与价值共享的平台，为能源与出行系统的整合提供了战略桥梁。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.GT",
        "eess.SY"
      ],
      "primary_category": "cs.MA",
      "comment": "Submitted to AAMAS 2026. 25 pages, 13 figures, 14 tables",
      "pdf_url": "https://arxiv.org/pdf/2601.01581v1",
      "published_date": "2026-01-04 15:59:52 UTC",
      "updated_date": "2026-01-04 15:59:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T21:35:59.889915+00:00"
    },
    {
      "arxiv_id": "2601.01580v1",
      "title": "The Two-Stage Decision-Sampling Hypothesis: Understanding the Emergence of Self-Reflection in RL-Trained LLMs",
      "title_zh": "两阶段决策采样假设：解析经强化学习训练的大语言模型中自我反思的涌现",
      "authors": [
        "Zibo Zhao",
        "Yuanting Zha",
        "Haipeng Zhang",
        "Xingcheng Xu"
      ],
      "abstract": "Self-reflection capabilities emerge in Large Language Models after RL post-training, with multi-turn RL achieving substantial gains over SFT counterparts. Yet the mechanism of how a unified optimization objective gives rise to functionally distinct capabilities of generating solutions and evaluating when to revise them remains opaque. To address this question, we introduce the Gradient Attribution Property to characterize how reward gradients distribute across policy components, formalized through the Two-Stage Decision-Sampling (DS) Hypothesis, which decomposes the policy into sampling ($π_{sample}$) for generation and decision ($π_{d}$) for verification. We prove that surrogate rewards exhibit Balanced Gradient Attribution, while SFT and KL penalties exhibit Unbalanced Gradient Attribution, with length-weighting creating asymmetric regularization that constrains $π_{sample}$ while leaving $π_{d}$ under-optimized, providing an theoretical explanation of why RL succeeds where SFT fails. We also empirically validate our theoretical predictions on arithmetic reasoning demonstrates that RL's superior generalization stems primarily from improved decision-making ($π_{d}$) rather than sampling capabilities, providing a first-principles mechanistic explanation for self-correction in thinking models.",
      "tldr_zh": "该研究探讨了大语言模型(LLMs)在经过强化学习(RL)后出现的自我反思(Self-reflection)能力，旨在揭示统一优化目标如何产生生成解法与评估修改这两类功能迥异的能力。作者提出了双阶段决策采样(Two-Stage Decision-Sampling, DS)假设，将策略分解为用于生成的采样($\\pi_{sample}$)和用于验证的决策($\\pi_d$)，并引入梯度归属属性(Gradient Attribution Property)来分析奖励梯度的分布。理论证明发现，强化学习表现出平衡梯度归属(Balanced Gradient Attribution)，而监督微调(SFT)和KL散度惩罚则由于长度加权产生的不对称正则化导致不平衡梯度归属，这使得决策能力($\\pi_d$)在SFT中优化不足。在算术推理任务上的实验进一步验证了该预测，表明RL卓越的泛化能力主要源于决策能力($\\pi_d$)的提升而非采样能力的增强。该研究为思考模型(thinking models)中的自我纠错能力提供了首个基于第一性原理的机制性解释。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.01580v1",
      "published_date": "2026-01-04 15:59:15 UTC",
      "updated_date": "2026-01-04 15:59:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T21:36:27.857608+00:00"
    },
    {
      "arxiv_id": "2601.01577v1",
      "title": "HanoiWorld : A Joint Embedding Predictive Architecture BasedWorld Model for Autonomous Vehicle Controller",
      "title_zh": "HanoiWorld：基于联合嵌入预测架构的自动驾驶控制器世界模型",
      "authors": [
        "Tran Tien Dat",
        "Nguyen Hai An",
        "Nguyen Khanh Viet Dung",
        "Nguyen Duy Duc"
      ],
      "abstract": "Current attempts of Reinforcement Learning for Autonomous Controller are data-demanding while the results are under-performed, unstable, and unable to grasp and anchor on the concept of safety, and over-concentrating on noise features due to the nature of pixel reconstruction. While current Self-Supervised Learningapproachs that learning on high-dimensional representations by leveraging the JointEmbedding Predictive Architecture (JEPA) are interesting and an effective alternative, as the idea mimics the natural ability of the human brain in acquiring new skill usingimagination and minimal samples of observations. This study introduces Hanoi-World, a JEPA-based world model that using recurrent neural network (RNN) formaking longterm horizontal planning with effective inference time. Experimentsconducted on the Highway-Env package with difference enviroment showcase the effective capability of making a driving plan while safety-awareness, with considerablecollision rate in comparison with SOTA baselines",
      "tldr_zh": "该研究针对自动驾驶控制器在强化学习 (Reinforcement Learning) 中面临的数据需求大、表现不稳定及易受像素重建 (pixel reconstruction) 噪声干扰等挑战，提出了名为 HanoiWorld 的新型世界模型 (World Model)。该模型基于联合嵌入预测架构 (Joint Embedding Predictive Architecture, JEPA)，通过循环神经网络 (RNN) 实现高效推理的长时水平规划 (longterm horizontal planning)，旨在模拟人类大脑利用想象力和少量观测获取技能的能力。实验在 Highway-Env 仿真环境下进行，结果证明 HanoiWorld 在制定驾驶决策时具备极强的安全意识和出色的规划能力。与目前的先进基线模型 (SOTA baselines) 相比，HanoiWorld 显著降低了碰撞率，为开发更安全、更稳健的自主驾驶控制器提供了有效的替代方案。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.01577v1",
      "published_date": "2026-01-04 15:49:46 UTC",
      "updated_date": "2026-01-04 15:49:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T21:36:07.126070+00:00"
    },
    {
      "arxiv_id": "2601.01576v2",
      "title": "OpenNovelty: An LLM-powered Agentic System for Verifiable Scholarly Novelty Assessment",
      "title_zh": "OpenNovelty：基于大语言模型的可验证学术创新性评估智能体系统",
      "authors": [
        "Ming Zhang",
        "Kexin Tan",
        "Yueyuan Huang",
        "Yujiong Shen",
        "Chunchun Ma",
        "Li Ju",
        "Xinran Zhang",
        "Yuhui Wang",
        "Wenqing Jing",
        "Jingyi Deng",
        "Huayu Sha",
        "Binze Hu",
        "Jingqi Tong",
        "Changhao Jiang",
        "Yage Geng",
        "Yuankai Ying",
        "Yue Zhang",
        "Zhangyue Yin",
        "Zhiheng Xi",
        "Shihan Dou",
        "Tao Gui",
        "Qi Zhang",
        "Xuanjing Huang"
      ],
      "abstract": "Evaluating novelty is critical yet challenging in peer review, as reviewers must assess submissions against a vast, rapidly evolving literature. This report presents OpenNovelty, an LLM-powered agentic system for transparent, evidence-based novelty analysis. The system operates through four phases: (1) extracting the core task and contribution claims to generate retrieval queries; (2) retrieving relevant prior work based on extracted queries via semantic search engine; (3) constructing a hierarchical taxonomy of core-task-related work and performing contribution-level full-text comparisons against each contribution; and (4) synthesizing all analyses into a structured novelty report with explicit citations and evidence snippets. Unlike naive LLM-based approaches, \\textsc{OpenNovelty} grounds all assessments in retrieved real papers, ensuring verifiable judgments. We deploy our system on 500+ ICLR 2026 submissions with all reports publicly available on our website, and preliminary analysis suggests it can identify relevant prior work, including closely related papers that authors may overlook. OpenNovelty aims to empower the research community with a scalable tool that promotes fair, consistent, and evidence-backed peer review.",
      "tldr_zh": "该研究提出了 OpenNovelty，这是一个基于大语言模型(LLM)的智能体系统，旨在通过透明且基于证据的分析来解决同行评审中评估学术新颖性(Novelty)的挑战。该系统通过四个阶段运行：首先提取核心任务和贡献声明以生成检索查询，随后利用语义搜索引擎检索相关的先前研究。接着，OpenNovelty 构建核心任务相关工作的层级分类法(Hierarchical Taxonomy)，并针对每项贡献进行全文级别的对比分析，最后汇总为带有明确引用和证据片段的结构化报告。与朴素的 LLM 方法不同，OpenNovelty 将所有评估建立在检索到的真实论文基础上，确保了判断的可验证性(Verifiable)。该系统已在 500 多篇 ICLR 2026 投稿论文中部署，初步分析表明其能有效识别作者可能忽略的相关工作。OpenNovelty 为科研社区提供了一个可扩展的工具，旨在促进公正、一致且有证据支撑的同行评审流程。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.01576v2",
      "published_date": "2026-01-04 15:48:51 UTC",
      "updated_date": "2026-01-19 02:51:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T21:36:39.670826+00:00"
    },
    {
      "arxiv_id": "2601.01569v1",
      "title": "CaveAgent: Transforming LLMs into Stateful Runtime Operators",
      "title_zh": "CaveAgent：将 LLMs 转化为有状态运行时算子",
      "authors": [
        "Maohao Ran",
        "Zhenglin Wan",
        "Cooper Lin",
        "Yanting Zhang",
        "Hongyu Xin",
        "Hongwei Fan",
        "Yibo Xu",
        "Beier Luo",
        "Yaxin Zhou",
        "Wangbo Zhao",
        "Lijie Yang",
        "Lang Feng",
        "Fuchao Yang",
        "Jingxuan Wu",
        "Yiqiao Huang",
        "Chendong Ma",
        "Dailing Jiang",
        "Jianbo Deng",
        "Sihui Han",
        "Bo An",
        "Yike Guo",
        "Jun Song"
      ],
      "abstract": "LLM-based agents are increasingly capable of complex task execution, yet current agentic systems remain constrained by text-centric paradigms. Traditional approaches rely on procedural JSON-based function calling, which often struggles with long-horizon tasks due to fragile multi-turn dependencies and context drift. In this paper, we present CaveAgent, a framework that transforms the paradigm from \"LLM-as-Text-Generator\" to \"LLM-as-Runtime-Operator.\" We introduce a Dual-stream Context Architecture that decouples state management into a lightweight semantic stream for reasoning and a persistent, deterministic Python Runtime stream for execution. In addition to leveraging code generation to efficiently resolve interdependent sub-tasks (e.g., loops, conditionals) in a single step, we introduce \\textit{Stateful Runtime Management} in CaveAgent. Distinct from existing code-based approaches that remain text-bound and lack the support for external object injection and retrieval, CaveAgent injects, manipulates, and retrieves complex Python objects (e.g., DataFrames, database connections) that persist across turns. This persistence mechanism acts as a high-fidelity external memory to eliminate context drift, avoid catastrophic forgetting, while ensuring that processed data flows losslessly to downstream applications. Comprehensive evaluations on Tau$^2$-bench, BFCL and various case studies across representative SOTA LLMs demonstrate CaveAgent's superiority. Specifically, our framework achieves a 10.5\\% success rate improvement on retail tasks and reduces total token consumption by 28.4\\% in multi-turn scenarios. On data-intensive tasks, direct variable storage and retrieval reduces token consumption by 59\\%, allowing CaveAgent to handle large-scale data that causes context overflow failures in both JSON-based and Code-based agents.",
      "tldr_zh": "该研究提出了CaveAgent框架，旨在将大语言模型（LLMs）的角色从传统的文本生成器转变为有状态的运行时操作员（Stateful Runtime Operators），以解决代理系统在长程任务中面临的上下文漂移（context drift）和脆弱依赖问题。该框架引入了双流上下文架构（Dual-stream Context Architecture），将推理用的轻量级语义流与执行用的持久Python运行时流进行解耦。通过实现有状态运行时管理（Stateful Runtime Management），CaveAgent能够跨轮次持久化注入、操作和检索复杂的Python对象（如DataFrames和数据库连接），从而提供高保真的外部存储并防止灾难性遗忘。实验结果显示，CaveAgent在Tau2-bench零售任务上的成功率提升了10.5%，并在多轮对话场景下减少了28.4%的Token消耗。在数据密集型任务中，该框架通过直接的变量存储机制将Token消耗降低了59%，成功解决了会导致其他JSON或代码基代理发生上下文溢出（context overflow）的大规模数据处理难题。",
      "categories": [
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "32 pages, 14 Figures",
      "pdf_url": "https://arxiv.org/pdf/2601.01569v1",
      "published_date": "2026-01-04 15:32:47 UTC",
      "updated_date": "2026-01-04 15:32:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T21:36:59.673810+00:00"
    },
    {
      "arxiv_id": "2601.01568v2",
      "title": "MM-Sonate: Multimodal Controllable Audio-Video Generation with Zero-Shot Voice Cloning",
      "title_zh": "MM-Sonate：支持零样本语音克隆的多模态可控音视频生成",
      "authors": [
        "Chunyu Qiang",
        "Jun Wang",
        "Xiaopeng Wang",
        "Kang Yin",
        "Yuxin Guo"
      ],
      "abstract": "Joint audio-video generation aims to synthesize synchronized multisensory content, yet current unified models struggle with fine-grained acoustic control, particularly for identity-preserving speech. Existing approaches either suffer from temporal misalignment due to cascaded generation or lack the capability to perform zero-shot voice cloning within a joint synthesis framework. In this work, we present MM-Sonate, a multimodal flow-matching framework that unifies controllable audio-video joint generation with zero-shot voice cloning capabilities. Unlike prior works that rely on coarse semantic descriptions, MM-Sonate utilizes a unified instruction-phoneme input to enforce strict linguistic and temporal alignment. To enable zero-shot voice cloning, we introduce a timbre injection mechanism that effectively decouples speaker identity from linguistic content. Furthermore, addressing the limitations of standard classifier-free guidance in multimodal settings, we propose a noise-based negative conditioning strategy that utilizes natural noise priors to significantly enhance acoustic fidelity. Empirical evaluations demonstrate that MM-Sonate establishes new state-of-the-art performance in joint generation benchmarks, significantly outperforming baselines in lip synchronization and speech intelligibility, while achieving voice cloning fidelity comparable to specialized Text-to-Speech systems.",
      "tldr_zh": "该研究提出了MM-Sonate，这是一个旨在解决联合音视频生成中细粒度声学控制与零样本语音克隆(Zero-Shot Voice Cloning)难题的多模态流匹配(Flow-Matching)框架。该框架利用统一的指令-音素(Instruction-Phoneme)输入来确保严格的语言与时间对齐，有效克服了传统级联生成模式下的时序错位问题。通过引入音色注入(Timbre Injection)机制，MM-Sonate成功实现了说话人身份与语言内容的解耦，从而在联合合成框架内实现了高质量的零样本语音克隆。此外，研究还提出了一种基于噪声的负向调节(Noise-based Negative Conditioning)策略，通过利用自然噪声先验显著提升了声学保真度。实验结果表明，MM-Sonate在多项联合生成基准测试中达到了SOTA水平，特别是在唇形同步(Lip Synchronization)和语音清晰度方面表现卓越，其语音克隆效果可与专门的文本转语音(TTS)系统相媲美。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CV",
        "cs.MM",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.01568v2",
      "published_date": "2026-01-04 15:26:15 UTC",
      "updated_date": "2026-01-08 08:43:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T21:36:45.071788+00:00"
    },
    {
      "arxiv_id": "2601.01562v3",
      "title": "Logics-STEM: Empowering LLM Reasoning via Failure-Driven Post-Training and Document Knowledge Enhancement",
      "title_zh": "Logics-STEM：通过失败驱动的后训练与文档知识增强赋能 LLM 推理",
      "authors": [
        "Mingyu Xu",
        "Cheng Fang",
        "Keyue Jiang",
        "Yuqian Zheng",
        "Yanghua Xiao",
        "Baojian Zhou",
        "Qifang Zhao",
        "Suhang Zheng",
        "Xiuwen Zhu",
        "Jiyang Tang",
        "Yongchi Zhao",
        "Yijia Luo",
        "Zhiqi Bai",
        "Yuchi Xu",
        "Wenbo Su",
        "Wei Wang",
        "Bing Zhao",
        "Lin Qu",
        "Xiaoxiao Xu"
      ],
      "abstract": "We present Logics-STEM, a state-of-the-art reasoning model fine-tuned on Logics-STEM-SFT-Dataset, a high-quality and diverse dataset at 10M scale that represents one of the largest-scale open-source long chain-of-thought corpora. Logics-STEM targets reasoning tasks in the domains of Science, Technology, Engineering, and Mathematics (STEM), and exhibits exceptional performance on STEM-related benchmarks with an average improvement of 4.68% over the next-best model at 8B scale. We attribute the gains to our data-algorithm co-design engine, where they are jointly optimized to fit a gold-standard distribution behind reasoning. Data-wise, the Logics-STEM-SFT-Dataset is constructed from a meticulously designed data curation engine with 5 stages to ensure the quality, diversity, and scalability, including annotation, deduplication, decontamination, distillation, and stratified sampling. Algorithm-wise, our failure-driven post-training framework leverages targeted knowledge retrieval and data synthesis around model failure regions in the Supervised Fine-tuning (SFT) stage to effectively guide the second-stage SFT or the reinforcement learning (RL) for better fitting the target distribution. The superior empirical performance of Logics-STEM reveals the vast potential of combining large-scale open-source data with carefully designed synthetic data, underscoring the critical role of data-algorithm co-design in enhancing reasoning capabilities through post-training. We make both the Logics-STEM models (8B and 32B) and the Logics-STEM-SFT-Dataset (10M and downsampled 2.2M versions) publicly available to support future research in the open-source community.",
      "tldr_zh": "该研究推出了Logics-STEM，这是一种通过在Logics-STEM-SFT-Dataset（规模达10M的高质量长Chain-of-Thought语料库）上微调得到的最先进推理模型。该模型专注于STEM领域的推理任务，在相关基准测试中表现卓越，在8B规模上比次优模型平均提升了4.68%。其性能提升归功于数据-算法协同设计引擎，在数据端通过包含标注、去重、去污、蒸馏和分层采样的五阶段流程确保了数据质量。算法层面采用了失效驱动的后期训练(Failure-driven post-training)框架，利用针对性的知识检索和数据合成，专门针对监督微调(SFT)中的模型失效区域进行优化。该框架有效地引导了后续的SFT或强化学习(RL)过程，以实现对目标推理分布的更佳拟合。Logics-STEM的研究揭示了结合大规模开源数据与合成数据在增强大模型推理能力方面的潜力，并已将不同规模的模型和数据集向社区公开。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.01562v3",
      "published_date": "2026-01-04 15:23:18 UTC",
      "updated_date": "2026-01-20 04:18:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T21:36:52.564686+00:00"
    },
    {
      "arxiv_id": "2601.01558v1",
      "title": "Utilizing Earth Foundation Models to Enhance the Simulation Performance of Hydrological Models with AlphaEarth Embeddings",
      "title_zh": "利用 AlphaEarth 嵌入及地球基石模型提升水文模型的模拟性能",
      "authors": [
        "Pengfei Qu",
        "Wenyu Ouyang",
        "Chi Zhang",
        "Yikai Chai",
        "Shuolong Xu",
        "Lei Ye",
        "Yongri Piao",
        "Miao Zhang",
        "Huchuan Lu"
      ],
      "abstract": "Predicting river flow in places without streamflow records is challenging because basins respond differently to climate, terrain, vegetation, and soils. Traditional basin attributes describe some of these differences, but they cannot fully represent the complexity of natural environments. This study examines whether AlphaEarth Foundation embeddings, which are learned from large collections of satellite images rather than designed by experts, offer a more informative way to describe basin characteristics. These embeddings summarize patterns in vegetation, land surface properties, and long-term environmental dynamics. We find that models using them achieve higher accuracy when predicting flows in basins not used for training, suggesting that they capture key physical differences more effectively than traditional attributes. We further investigate how selecting appropriate donor basins influences prediction in ungauged regions. Similarity based on the embeddings helps identify basins with comparable environmental and hydrological behavior, improving performance, whereas adding many dissimilar basins can reduce accuracy. The results show that satellite-informed environmental representations can strengthen hydrological forecasting and support the development of models that adapt more easily to different landscapes.",
      "tldr_zh": "该研究探讨了如何利用 AlphaEarth Foundation embeddings 来增强水文模型的模拟性能，以解决无观测流域（ungauged basins）流量预测中传统流域属性表征能力不足的问题。AlphaEarth embeddings 直接从大规模卫星图像中学习环境特征，能够有效捕捉植被、地表属性及长期环境动态。实验结果表明，与传统专家设计的属性相比，该嵌入能更精准地刻画流域间的物理差异，显著提高了模型在未知流域上的预测准确率。研究进一步发现，利用嵌入相似性来选择捐赠流域（donor basins）能够识别环境行为相似的区域，从而优化预测效果，而引入过多不相似流域则可能削弱性能。综上所述，这种基于卫星数据的环境表征（satellite-informed environmental representations）为强化水文预报和构建具备强适应性的地理景观模型提供了有效路径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages, 11 figures",
      "pdf_url": "https://arxiv.org/pdf/2601.01558v1",
      "published_date": "2026-01-04 15:14:16 UTC",
      "updated_date": "2026-01-04 15:14:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T21:36:53.110969+00:00"
    },
    {
      "arxiv_id": "2601.06127v1",
      "title": "AIS-CycleGen: A CycleGAN-Based Framework for High-Fidelity Synthetic AIS Data Generation and Augmentation",
      "title_zh": "AISCycleGen：一种基于 CycleGAN 的高保真合成 AIS 数据生成与增强框架",
      "authors": [
        "SM Ashfaq uz Zaman",
        "Faizan Qamar",
        "Masnizah Mohd",
        "Nur Hanis Sabrina Suhaimi",
        "Amith Khandakar"
      ],
      "abstract": "Automatic Identification System (AIS) data are vital for maritime domain awareness, yet they often suffer from domain shifts, data sparsity, and class imbalance, which hinder the performance of predictive models. In this paper, we propose a robust data augmentation method, AISCycleGen, based on Cycle-Consistent Generative Adversarial Networks (CycleGAN), which is tailored for AIS datasets. Unlike traditional methods, AISCycleGen leverages unpaired domain translation to generate high-fidelity synthetic AIS data sequences without requiring paired source-target data. The framework employs a 1D convolutional generator with adaptive noise injection to preserve the spatiotemporal structure of AIS trajectories, enhancing the diversity and realism of the generated data. To demonstrate its efficacy, we apply AISCycleGen to several baseline regression models, showing improvements in performance across various maritime domains. The results indicate that AISCycleGen outperforms contemporary GAN-based augmentation techniques, achieving a PSNR value of 30.5 and an FID score of 38.9. These findings underscore AISCycleGen's potential as an effective and generalizable solution for augmenting AIS datasets, improving downstream model performance in real-world maritime intelligence applications.",
      "tldr_zh": "该研究针对自动识别系统 AIS 数据中存在的领域偏移 domain shifts、数据稀疏性和类别不平衡问题，提出了名为 AIS-CycleGen 的增强框架。该框架基于循环一致性生成对抗网络 CycleGAN，旨在生成高保真的合成 AIS 数据以提升预测模型的性能。AIS-CycleGen 利用非配对领域转换 unpaired domain translation 技术，在无需配对源-目标数据的情况下即可生成连续的轨迹序列。通过结合 1D 卷积生成器与自适应噪声注入 adaptive noise injection，该方法能够有效保留轨迹的时空结构 spatiotemporal structure，显著增强了生成数据的多样性与真实感。在多项海事领域基准回归模型的测试中，AIS-CycleGen 取得了 30.5 的 PSNR 值和 38.9 的 FID 分数，其性能优于现有的 GAN 增强技术，为提升海事智能应用中的模型表现提供了有效的通用方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "25 pages, 16 figures",
      "pdf_url": "https://arxiv.org/pdf/2601.06127v1",
      "published_date": "2026-01-04 15:09:53 UTC",
      "updated_date": "2026-01-04 15:09:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T21:36:55.682330+00:00"
    },
    {
      "arxiv_id": "2601.01554v5",
      "title": "MOSS Transcribe Diarize Technical Report",
      "title_zh": "MOSS 转录与说话人日志技术报告",
      "authors": [
        "MOSI. AI",
        ":",
        "Donghua Yu",
        "Zhengyuan Lin",
        "Chen Yang",
        "Yiyang Zhang",
        "Hanfu Chen",
        "Jingqi Chen",
        "Ke Chen",
        "Liwei Fan",
        "Yi Jiang",
        "Jie Zhu",
        "Muchen Li",
        "Wenxuan Wang",
        "Yang Wang",
        "Zhe Xu",
        "Yitian Gong",
        "Yuqian Zhang",
        "Wenbo Zhang",
        "Songlin Wang",
        "Zhiyu Wu",
        "Zhaoye Fei",
        "Qinyuan Cheng",
        "Shimin Li",
        "Xipeng Qiu"
      ],
      "abstract": "Speaker-Attributed, Time-Stamped Transcription (SATS) aims to transcribe what is said and to precisely determine the timing of each speaker, which is particularly valuable for meeting transcription. Existing SATS systems rarely adopt an end-to-end formulation and are further constrained by limited context windows, weak long-range speaker memory, and the inability to output timestamps. To address these limitations, we present MOSS Transcribe Diarize, a unified multimodal large language model that jointly performs Speaker-Attributed, Time-Stamped Transcription in an end-to-end paradigm. Trained on extensive real wild data and equipped with a 128k context window for up to 90-minute inputs, MOSS Transcribe Diarize scales well and generalizes robustly. Across comprehensive evaluations, it outperforms state-of-the-art commercial systems on multiple public and in-house benchmarks.",
      "tldr_zh": "该报告介绍了 MOSS Transcribe Diarize，这是一个旨在解决说话人属性时间戳转录 (Speaker-Attributed, Time-Stamped Transcription, SATS) 难题的统一多模态大语言模型。针对现有系统缺乏端到端 (end-to-end) 架构、长程说话人记忆弱以及难以输出精确时间戳等局限性，该研究提出了一种联合处理转录与说话人识别的端到端范式。通过在海量真实野外数据上的训练，该模型配备了 128k 的超长上下文窗口，能够稳定处理长达 90 分钟的音频输入。该系统在实际应用中展现了极强的扩展性与鲁棒的泛化能力。实验结果表明，MOSS Transcribe Diarize 在多个公开和内部基准测试中的性能均超越了现有的顶尖商业系统。该研究为实现高效、精准的自动化会议转录提供了重要的技术突破。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.01554v5",
      "published_date": "2026-01-04 15:01:10 UTC",
      "updated_date": "2026-01-19 04:45:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T21:37:42.930282+00:00"
    },
    {
      "arxiv_id": "2601.01547v1",
      "title": "EscherVerse: An Open World Benchmark and Dataset for Teleo-Spatial Intelligence with Physical-Dynamic and Intent-Driven Understanding",
      "title_zh": "EscherVerse：融合物理动力学与意图驱动理解的开放世界目的性空间智能基准与数据集",
      "authors": [
        "Tianjun Gu",
        "Chenghua Gong",
        "Jingyu Gong",
        "Zhizhong Zhang",
        "Yuan Xie",
        "Lizhuang Ma",
        "Xin Tan"
      ],
      "abstract": "The ability to reason about spatial dynamics is a cornerstone of intelligence, yet current research overlooks the human intent behind spatial changes. To address these limitations, we introduce Teleo-Spatial Intelligence (TSI), a new paradigm that unifies two critical pillars: Physical-Dynamic Reasoning--understanding the physical principles of object interactions--and Intent-Driven Reasoning--inferring the human goals behind these actions. To catalyze research in TSI, we present EscherVerse, consisting of a large-scale, open-world benchmark (Escher-Bench), a dataset (Escher-35k), and models (Escher series). Derived from real-world videos, EscherVerse moves beyond constrained settings to explicitly evaluate an agent's ability to reason about object permanence, state transitions, and trajectory prediction in dynamic, human-centric scenarios. Crucially, it is the first benchmark to systematically assess Intent-Driven Reasoning, challenging models to connect physical events to their underlying human purposes. Our work, including a novel data curation pipeline, provides a foundational resource to advance spatial intelligence from passive scene description toward a holistic, purpose-driven understanding of the world.",
      "tldr_zh": "该研究提出了目的空间智能(Teleo-Spatial Intelligence, TSI)这一新范式，旨在将物理动态推理(Physical-Dynamic Reasoning)与意图驱动推理(Intent-Driven Reasoning)相结合，以克服现有研究忽视空间变化背后人类意图的问题。为推动TSI研究，作者发布了EscherVerse，其中包括大规模开放世界基准测试Escher-Bench、数据集Escher-35k以及Escher系列模型。该资源库源自真实世界视频，摆脱了受限场景的束缚，重点评估智能体在动态、以人为中心的场景中对物体持久性(object permanence)、状态转换和轨迹预测的推理能力。EscherVerse是首个系统性评估意图驱动推理的基准，挑战模型将物理事件与其底层的人类目的联系起来。此外，该工作还提出了一种创新的数据策划管道(data curation pipeline)，为空间智能从被动的场景描述转向全面、目标驱动的世界理解提供了基础性资源。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.01547v1",
      "published_date": "2026-01-04 14:42:39 UTC",
      "updated_date": "2026-01-04 14:42:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T21:37:05.416185+00:00"
    },
    {
      "arxiv_id": "2601.01546v1",
      "title": "Improving Behavioral Alignment in LLM Social Simulations via Context Formation and Navigation",
      "title_zh": "通过情境构建与导航提升大语言模型社会模拟中的行为对齐",
      "authors": [
        "Letian Kong",
        "Qianran",
        "Jin",
        "Renyu Zhang"
      ],
      "abstract": "Large language models (LLMs) are increasingly used to simulate human behavior in experimental settings, but they systematically diverge from human decisions in complex decision-making environments, where participants must anticipate others' actions and form beliefs based on observed behavior. We propose a two-stage framework for improving behavioral alignment. The first stage, context formation, explicitly specifies the experimental design to establish an accurate representation of the decision task and its context. The second stage, context navigation, guides the reasoning process within that representation to make decisions. We validate this framework through a focal replication of a sequential purchasing game with quality signaling (Kremer and Debo, 2016), extending to a crowdfunding game with costly signaling (Cason et al., 2025) and a demand-estimation task (Gui and Toubia, 2025) to test generalizability across decision environments. Across four state-of-the-art (SOTA) models (GPT-4o, GPT-5, Claude-4.0-Sonnet-Thinking, DeepSeek-R1), we find that complex decision-making environments require both stages to achieve behavioral alignment with human benchmarks, whereas the simpler demand-estimation task requires only context formation. Our findings clarify when each stage is necessary and provide a systematic approach for designing and diagnosing LLM social simulations as complements to human subjects in behavioral research.",
      "tldr_zh": "该研究针对大型语言模型（LLMs）在复杂社交模拟中与人类行为对齐（Behavioral Alignment）存在的偏差，提出了一个旨在提升对齐效果的两阶段框架。该框架由上下文构建（Context Formation）和上下文导航（Context Navigation）组成，前者负责显式规定实验设计以建立任务背景的准确表示，后者则在该表示下引导推理决策过程。研究通过顺序购买博弈、众筹博弈以及需求估计等多种决策环境，对 GPT-4o, GPT-5, Claude-4.0-Sonnet-Thinking 和 DeepSeek-R1 等 SOTA 模型进行了验证。实验结果表明，复杂的决策环境必须依靠这两个阶段的协同作用才能接近人类决策基准，而较简单的任务则仅需上下文构建。这一发现为将 LLM 社交模拟作为行为研究中人类受试者的补充，提供了一套标准化的设计与诊断系统方法。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "39 pages, 2 figures, 3 tables",
      "pdf_url": "https://arxiv.org/pdf/2601.01546v1",
      "published_date": "2026-01-04 14:42:00 UTC",
      "updated_date": "2026-01-04 14:42:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T21:37:07.823109+00:00"
    },
    {
      "arxiv_id": "2601.01543v1",
      "title": "Bridging the Data Gap: Creating a Hindi Text Summarization Dataset from the English XSUM",
      "title_zh": "弥合数据鸿沟：基于英文 XSUM 构建印地语文本摘要数据集",
      "authors": [
        "Praveenkumar Katwe",
        "RakeshChandra Balabantaray",
        "Kaliprasad Vittala"
      ],
      "abstract": "Current advancements in Natural Language Processing (NLP) have largely favored resource-rich languages, leaving a significant gap in high-quality datasets for low-resource languages like Hindi. This scarcity is particularly evident in text summarization, where the development of robust models is hindered by a lack of diverse, specialized corpora.\n  To address this disparity, this study introduces a cost-effective, automated framework for creating a comprehensive Hindi text summarization dataset. By leveraging the English Extreme Summarization (XSUM) dataset as a source, we employ advanced translation and linguistic adaptation techniques. To ensure high fidelity and contextual relevance, we utilize the Crosslingual Optimized Metric for Evaluation of Translation (COMET) for validation, supplemented by the selective use of Large Language Models (LLMs) for curation.\n  The resulting dataset provides a diverse, multi-thematic resource that mirrors the complexity of the original XSUM corpus. This initiative not only provides a direct tool for Hindi NLP research but also offers a scalable methodology for democratizing NLP in other underserved languages. By reducing the costs associated with dataset creation, this work fosters the development of more nuanced, culturally relevant models in computational linguistics.",
      "tldr_zh": "该研究针对印地语(Hindi)等低资源语言在文本摘要领域缺乏高质量数据集的问题，提出了一种成本效益高的自动化构建框架。研究人员利用成熟的英语数据集Extreme Summarization (XSUM)作为来源，结合先进的翻译与语言适应技术进行转化。为了确保数据集的高保真度和上下文相关性，该工作引入了Crosslingual Optimized Metric for Evaluation of Translation (COMET)进行验证，并辅以大语言模型(LLMs)进行精细化筛选。最终生成的印地语数据集涵盖了多种主题，成功保留了原始XSUM语料库的复杂性，为印地语自然语言处理(NLP)研究提供了直接工具。该项工作通过降低数据集创建成本，促进了更具文化相关性的计算语言学模型开发，并为其他低资源语言的NLP民主化提供了可扩展的方法论。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Book chapter for River publications",
      "pdf_url": "https://arxiv.org/pdf/2601.01543v1",
      "published_date": "2026-01-04 14:38:58 UTC",
      "updated_date": "2026-01-04 14:38:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T21:37:09.293760+00:00"
    },
    {
      "arxiv_id": "2601.01532v1",
      "title": "Aletheia: Quantifying Cognitive Conviction in Reasoning Models via Regularized Inverse Confusion Matrix",
      "title_zh": "Aletheia：基于正则化逆混淆矩阵的推理模型认知确信量化",
      "authors": [
        "Fanzhe Fu"
      ],
      "abstract": "In the progressive journey toward Artificial General Intelligence (AGI), current evaluation paradigms face an epistemological crisis. Static benchmarks measure knowledge breadth but fail to quantify the depth of belief. While Simhi et al. (2025) defined the CHOKE phenomenon in standard QA, we extend this framework to quantify \"Cognitive Conviction\" in System 2 reasoning models. We propose Project Aletheia, a cognitive physics framework that employs Tikhonov Regularization to invert the judge's confusion matrix. To validate this methodology without relying on opaque private data, we implement a Synthetic Proxy Protocol. Our preliminary pilot study on 2025 baselines (e.g., DeepSeek-R1, OpenAI o1) suggests that while reasoning models act as a \"cognitive buffer,\" they may exhibit \"Defensive OverThinking\" under adversarial pressure. Furthermore, we introduce the Aligned Conviction Score (S_aligned) to verify that conviction does not compromise safety. This work serves as a blueprint for measuring AI scientific integrity.",
      "tldr_zh": "该研究提出了 Project Aletheia，一个旨在量化 System 2 推理模型中“认知信念”(Cognitive Conviction) 的认知物理学框架，以应对当前人工智能评估范式在衡量信念深度方面的局限。研究采用 Tikhonov Regularization 技术来实现对判别器混淆矩阵的逆向计算，并通过 Synthetic Proxy Protocol 协议在不依赖不透明私有数据的情况下完成了方法论验证。对 DeepSeek-R1 和 OpenAI o1 等 2025 年基准模型的初步研究表明，推理模型在面对对抗性压力时可能表现出“防御性过度思考”(Defensive OverThinking)。此外，论文引入了 Aligned Conviction Score ($S_{aligned}$) 以确保信念的增强不会损害安全性。这项工作为衡量人工智能的科学完整性提供了关键的技术蓝图。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "6 pages, 2 figures",
      "pdf_url": "https://arxiv.org/pdf/2601.01532v1",
      "published_date": "2026-01-04 13:57:32 UTC",
      "updated_date": "2026-01-04 13:57:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T21:38:17.013161+00:00"
    },
    {
      "arxiv_id": "2601.01528v1",
      "title": "DrivingGen: A Comprehensive Benchmark for Generative Video World Models in Autonomous Driving",
      "title_zh": "DrivingGen：自动驾驶生成式视频世界模型综合基准",
      "authors": [
        "Yang Zhou",
        "Hao Shao",
        "Letian Wang",
        "Zhuofan Zong",
        "Hongsheng Li",
        "Steven L. Waslander"
      ],
      "abstract": "Video generation models, as one form of world models, have emerged as one of the most exciting frontiers in AI, promising agents the ability to imagine the future by modeling the temporal evolution of complex scenes. In autonomous driving, this vision gives rise to driving world models: generative simulators that imagine ego and agent futures, enabling scalable simulation, safe testing of corner cases, and rich synthetic data generation. Yet, despite fast-growing research activity, the field lacks a rigorous benchmark to measure progress and guide priorities. Existing evaluations remain limited: generic video metrics overlook safety-critical imaging factors; trajectory plausibility is rarely quantified; temporal and agent-level consistency is neglected; and controllability with respect to ego conditioning is ignored. Moreover, current datasets fail to cover the diversity of conditions required for real-world deployment. To address these gaps, we present DrivingGen, the first comprehensive benchmark for generative driving world models. DrivingGen combines a diverse evaluation dataset curated from both driving datasets and internet-scale video sources, spanning varied weather, time of day, geographic regions, and complex maneuvers, with a suite of new metrics that jointly assess visual realism, trajectory plausibility, temporal coherence, and controllability. Benchmarking 14 state-of-the-art models reveals clear trade-offs: general models look better but break physics, while driving-specific ones capture motion realistically but lag in visual quality. DrivingGen offers a unified evaluation framework to foster reliable, controllable, and deployable driving world models, enabling scalable simulation, planning, and data-driven decision-making.",
      "tldr_zh": "该研究介绍了DrivingGen，这是首个针对自动驾驶生成式视频世界模型(World Models)的全面基准测试，旨在解决当前领域缺乏严格评估标准和多样化数据集的问题。DrivingGen结合了从驾驶数据集和互联网规模视频源中策划的多样化评估数据，涵盖了各种天气、时段、地理区域和复杂机动场景。该基准引入了一套全新的评估指标，能够共同衡量视觉真实感(Visual Realism)、轨迹合理性(Trajectory Plausibility)、时间相干性以及受控性(Controllability)。通过对14种最先进(State-of-the-Art)模型的测试，研究揭示了明显的权衡关系：通用模型在视觉上表现更佳但往往违反物理规律，而驾驶专用模型虽然能真实捕捉运动，但在视觉质量上相对落后。DrivingGen提供了一个统一的评估框架，促进了可靠、可控且可部署的驾驶世界模型的开发，为可扩展的模拟、规划和数据驱动决策奠定了基础。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages, 4 figures; Project Website: https://drivinggen-bench.github.io/",
      "pdf_url": "https://arxiv.org/pdf/2601.01528v1",
      "published_date": "2026-01-04 13:36:21 UTC",
      "updated_date": "2026-01-04 13:36:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T21:37:57.512305+00:00"
    },
    {
      "arxiv_id": "2601.06126v1",
      "title": "NL2Dashboard: A Lightweight and Controllable Framework for Generating Dashboards with LLMs",
      "title_zh": "NL2Dashboard：一种基于大语言模型的轻量级、可控仪表盘生成框架",
      "authors": [
        "Boshen Shi",
        "Kexin Yang",
        "Yuanbo Yang",
        "Guanguang Chang",
        "Ce Chi",
        "Zhendong Wang",
        "Xing Wang",
        "Junlan Feng"
      ],
      "abstract": "While Large Language Models (LLMs) have demonstrated remarkable proficiency in generating standalone charts, synthesizing comprehensive dashboards remains a formidable challenge. Existing end-to-end paradigms, which typically treat dashboard generation as a direct code generation task (e.g., raw HTML), suffer from two fundamental limitations: representation redundancy due to massive tokens spent on visual rendering, and low controllability caused by the entanglement of analytical reasoning and presentation. To address these challenges, we propose NL2Dashboard, a lightweight framework grounded in the principle of Analysis-Presentation Decoupling. We introduce a structured intermediate representation (IR) that encapsulates the dashboard's content, layout, and visual elements. Therefore, it confines the LLM's role to data analysis and intent translation, while offloading visual synthesis to a deterministic rendering engine. Building upon this framework, we develop a multi-agent system in which the IR-driven algorithm is instantiated as a suite of tools. Comprehensive experiments conducted with this system demonstrate that NL2Dashboard significantly outperforms state-of-the-art baselines across diverse domains, achieving superior visual quality, significantly higher token efficiency, and precise controllability in both generation and modification tasks.",
      "tldr_zh": "该研究针对大语言模型(LLMs)在生成综合仪表盘(Dashboards)时存在的表示冗余和可控性低等挑战，提出了名为NL2Dashboard的轻量级框架。该框架基于分析与展示解耦(Analysis-Presentation Decoupling)原则，通过引入结构化的中间表示(Intermediate Representation, IR)来封装仪表盘的内容、布局和视觉元素。这种方法将LLMs的角色局限于数据分析和意图翻译，而将视觉合成任务交给确定性的渲染引擎处理。在此基础上，研究团队开发了一个多智能体系统(Multi-agent system)，将IR驱动的算法实例化为一套工具集。实验结果表明，NL2Dashboard在多个领域显著优于现有的基线模型。该框架在生成和修改任务中实现了卓越的视觉质量、极高的Token效率以及精确的可控性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.06126v1",
      "published_date": "2026-01-04 13:26:04 UTC",
      "updated_date": "2026-01-04 13:26:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T21:37:58.693760+00:00"
    },
    {
      "arxiv_id": "2601.01522v1",
      "title": "Bayesian Orchestration of Multi-LLM Agents for Cost-Aware Sequential Decision-Making",
      "title_zh": "面向成本感知序列决策的多 LLM 智能体贝叶斯编排",
      "authors": [
        "Danial Amin"
      ],
      "abstract": "Large language models (LLMs) are increasingly deployed as autonomous decision agents in settings with asymmetric error costs: hiring (missed talent vs wasted interviews), medical triage (missed emergencies vs unnecessary escalation), and fraud detection (approved fraud vs declined legitimate payments). The dominant design queries a single LLM for a posterior over states, thresholds \"confidence,\" and acts; we prove this is inadequate for sequential decisions with costs. We propose a Bayesian, cost-aware multi-LLM orchestration framework that treats LLMs as approximate likelihood models rather than classifiers. For each candidate state, we elicit likelihoods via contrastive prompting, aggregate across diverse models with robust statistics, and update beliefs with Bayes rule under explicit priors as new evidence arrives. This enables coherent belief updating, expected-cost action selection, principled information gathering via value of information, and fairness gains via ensemble bias mitigation. In resume screening with costs of 40000 USD per missed hire, 2500 USD per interview, and 150 USD per phone screen, experiments on 1000 resumes using five LLMs (GPT-4o, Claude 4.5 Sonnet, Gemini Pro, Grok, DeepSeek) reduce total cost by 294000 USD (34 percent) versus the best single-LLM baseline and improve demographic parity by 45 percent (max group gap 22 to 5 percentage points). Ablations attribute 51 percent of savings to multi-LLM aggregation, 43 percent to sequential updating, and 20 percent to disagreement-triggered information gathering, consistent with the theoretical benefits of correct probabilistic foundations.",
      "tldr_zh": "该研究针对大语言模型 (LLMs) 在具有不对称错误成本的顺序决策场景（如招聘、医疗分类和欺诈检测）中表现不足的问题，提出了一个贝叶斯成本感知多智能体编排框架。该框架将 LLMs 视为近似似然模型而非简单的分类器，通过对比提示 (contrastive prompting) 提取似然值，并利用稳健统计学聚合不同模型的输出。系统在显式先验概率下应用贝叶斯准则进行相干信念更新，支持预期成本行动选择和基于信息价值 (value of information) 的信息采集，同时通过集成偏差缓解提升了公平性。在 1000 份简历筛选的实验中，通过编排 GPT-4o, Claude 4.5 Sonnet, Gemini Pro, Grok 和 DeepSeek 等模型，该方法比最佳单模型基线降低了 34% 的总成本。此外，该框架将人口统计学平价 (demographic parity) 提高了 45%，消融实验进一步证实了多模型聚合、顺序更新以及分歧触发的信息收集对成本节省的关键贡献。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.ET"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.01522v1",
      "published_date": "2026-01-04 13:19:27 UTC",
      "updated_date": "2026-01-04 13:19:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T21:38:07.054921+00:00"
    },
    {
      "arxiv_id": "2601.01513v2",
      "title": "FastV-RAG: Towards Fast and Fine-Grained Video QA with Retrieval-Augmented Generation",
      "title_zh": "FastV-RAG：面向快速细粒度视频问答的检索增强生成",
      "authors": [
        "Gen Li",
        "Peiyu Liu"
      ],
      "abstract": "Vision-Language Models (VLMs) excel at visual reasoning but still struggle with integrating external knowledge. Retrieval-Augmented Generation (RAG) is a promising solution, but current methods remain inefficient and often fail to maintain high answer quality. To address these challenges, we propose VideoSpeculateRAG, an efficient VLM-based RAG framework built on two key ideas. First, we introduce a speculative decoding pipeline: a lightweight draft model quickly generates multiple answer candidates, which are then verified and refined by a more accurate heavyweight model, substantially reducing inference latency without sacrificing correctness. Second, we identify a major source of error - incorrect entity recognition in retrieved knowledge - and mitigate it with a simple yet effective similarity-based filtering strategy that improves entity alignment and boosts overall answer accuracy. Experiments demonstrate that VideoSpeculateRAG achieves comparable or higher accuracy than standard RAG approaches while accelerating inference by approximately 2x. Our framework highlights the potential of combining speculative decoding with retrieval-augmented reasoning to enhance efficiency and reliability in complex, knowledge-intensive multimodal tasks.",
      "tldr_zh": "该研究提出了FastV-RAG，这是一种旨在提升视频问答(Video QA)效率与精度的多模态检索增强生成(Retrieval-Augmented Generation, RAG)框架。为了解决视觉语言模型(VLMs)在整合外部知识时存在的延迟高和回答质量不稳定等挑战，该框架创新性地引入了投机解码(Speculative Decoding)流水线，利用轻量级草图模型快速生成候选答案并由重量级模型进行验证。针对检索过程中常见的实体识别错误，研究采用了一种简单的相似度过滤策略，有效增强了实体对齐并提高了整体问答的准确性。实验结果表明，FastV-RAG在保持或超越标准RAG方法准确率的前提下，实现了约2倍的推理加速。该研究证明了结合投机解码与检索增强推理在提升复杂知识密集型多模态任务效率与可靠性方面的潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.01513v2",
      "published_date": "2026-01-04 12:46:35 UTC",
      "updated_date": "2026-01-07 15:36:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T21:38:11.405723+00:00"
    },
    {
      "arxiv_id": "2601.01511v1",
      "title": "Reading Between the Lines: Deconfounding Causal Estimates using Text Embeddings and Deep Learning",
      "title_zh": "字里行间：基于文本嵌入与深度学习的因果估计去混杂",
      "authors": [
        "Ahmed Dawoud",
        "Osama El-Shamy"
      ],
      "abstract": "Estimating causal treatment effects in observational settings is frequently compromised by selection bias arising from unobserved confounders. While traditional econometric methods struggle when these confounders are orthogonal to structured covariates, high-dimensional unstructured text often contains rich proxies for these latent variables. This study proposes a Neural Network-Enhanced Double Machine Learning (DML) framework designed to leverage text embeddings for causal identification. Using a rigorous synthetic benchmark, we demonstrate that unstructured text embeddings capture critical confounding information that is absent from structured tabular data. However, we show that standard tree-based DML estimators retain substantial bias (+24%) due to their inability to model the continuous topology of embedding manifolds. In contrast, our deep learning approach reduces bias to -0.86% with optimized architectures, effectively recovering the ground-truth causal parameter. These findings suggest that deep learning architectures are essential for satisfying the unconfoundedness assumption when conditioning on high-dimensional natural language data",
      "tldr_zh": "该研究探讨了在观察性研究中利用文本嵌入来消除因未观测混杂因素(unobserved confounders)导致的因果效应估算偏差。研究提出了一个神经网络增强的双重机器学习(Double Machine Learning, DML)框架，旨在通过非结构化文本数据捕捉传统结构化数据中缺失的关键混杂信息。实验结果表明，由于传统的基于树的DML估计器无法有效建模嵌入空间的连续拓扑结构，其在处理文本嵌入时仍保留了高达24%的偏差。相比之下，该研究采用的深度学习架构通过优化显著降低了偏差至-0.86%，成功恢复了真实的因果参数。这一发现表明，当基于高维自然语言数据进行条件处理以满足无混杂假设(unconfoundedness assumption)时，深度学习架构对于因果识别至关重要。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.01511v1",
      "published_date": "2026-01-04 12:36:45 UTC",
      "updated_date": "2026-01-04 12:36:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T21:38:09.818565+00:00"
    },
    {
      "arxiv_id": "2601.01496v1",
      "title": "The Optimal Sample Complexity of Linear Contracts",
      "title_zh": "线性合约的最优样本复杂度",
      "authors": [
        "Mikael Møller Høgsgaard"
      ],
      "abstract": "In this paper, we settle the problem of learning optimal linear contracts from data in the offline setting, where agent types are drawn from an unknown distribution and the principal's goal is to design a contract that maximizes her expected utility. Specifically, our analysis shows that the simple Empirical Utility Maximization (EUM) algorithm yields an $\\varepsilon$-approximation of the optimal linear contract with probability at least $1-δ$, using just $O(\\ln(1/δ) / \\varepsilon^2)$ samples. This result improves upon previously known bounds and matches a lower bound from Duetting et al. [2025] up to constant factors, thereby proving its optimality. Our analysis uses a chaining argument, where the key insight is to leverage a simple structural property of linear contracts: their expected reward is non-decreasing. This property, which holds even though the utility function itself is non-monotone and discontinuous, enables the construction of fine-grained nets required for the chaining argument, which in turn yields the optimal sample complexity. Furthermore, our proof establishes the stronger guarantee of uniform convergence: the empirical utility of every linear contract is a $\\varepsilon$-approximation of its true expectation with probability at least $1-δ$, using the same optimal $O(\\ln(1/δ) / \\varepsilon^2)$ sample complexity.",
      "tldr_zh": "这项研究解决了在离线设定下从数据中学习最优线性合约 (Linear Contracts) 的问题，旨在使委托人在代理类型分布未知时实现期望效用最大化。研究证明，简单的经验效用最大化 (Empirical Utility Maximization, EUM) 算法仅需 $O(\\ln(1/δ) / \\varepsilon^2)$ 的样本复杂度，即可在 $1-δ$ 的概率下获得 $\\varepsilon$-近似的最优合约。该结果改进了既有的界限，并与已知的理论下界相匹配，从而证明了该算法在样本复杂度上的最优性 (Optimality)。分析过程中采用了链式论证 (Chaining Argument)，其核心在于发现线性合约的期望回报具有非递减的结构特性，即使效用函数本身是非单调且不连续的。这一特性允许构建精细的网格以支持链式论证，进而推导出最优界限。此外，该研究还建立了强有力的一致收敛 (Uniform Convergence) 保证，证明所有线性合约的经验效用都能以相同的最优样本复杂度收敛至其真实期望。",
      "categories": [
        "cs.GT",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.GT",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.01496v1",
      "published_date": "2026-01-04 11:45:17 UTC",
      "updated_date": "2026-01-04 11:45:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T21:38:34.282688+00:00"
    },
    {
      "arxiv_id": "2601.01490v1",
      "title": "Distortion Instead of Hallucination: The Effect of Reasoning Under Strict Constraints",
      "title_zh": "扭曲而非幻觉：严格约束下推理的影响",
      "authors": [
        "Junichiro Niimi"
      ],
      "abstract": "With the widespread adoption of large language models (LLMs), hallucinations, which are non-factual fabrications in model outputs, have become serious concerns. Reasoning capabilities have received attention as a self-verification process to improve output reliability. However, the effect of reasoning within a closed system where LLMs cannot rely on external tools or knowledge has yet to be clarified. We therefore conduct experiments under strict constraints (recommending peer-reviewed journal articles in computer science) to examine the effect of reasoning across multiple models (GPT-5.2 and Gemini 3 Flash). Our results reveal a problematic trade-off between constraint compliance and factual accuracy. Non-reasoning models exhibit high constraint violation rates (66-75%) but maintain factual accuracy, while reasoning models reduce violations (13-26%) but systematically distort known facts to satisfy constraints and increase complete fabrication. This trade-off pattern is consistent across both models despite different architectures, indicating a fundamental limitation of reasoning. Furthermore, reasoning does not uniformly improve output authenticity: effects diverge by model, reflecting different allocations of the compliance-truthfulness trade-off. These findings challenge the assumption that reasoning universally improves reliability: reasoning models trade honest constraint violations for detection-resistant distortions.",
      "tldr_zh": "该研究探讨了在严格约束(Strict Constraints)下，大语言模型(LLMs)的推理(Reasoning)能力对输出可靠性的影响。通过对 GPT-5.2 和 Gemini 3 Flash 在推荐计算机科学期刊论文任务中的表现进行实验，研究揭示了模型在遵守约束与保持事实准确性之间存在严重的权衡。结果表明，非推理模型虽然约束违反率较高，但能维持事实准确性；而推理模型虽然显著降低了违规率，却会为了满足约束而系统性地扭曲(Distortion)事实或增加完全虚构(Fabrication)的内容。这种权衡模式在不同架构的模型中具有一致性，反映了推理能力在闭环系统中的基本局限。该发现挑战了推理能普遍提高模型可靠性的假设，表明推理模型可能会以牺牲事实真实性为代价来换取对约束的合规性，从而产生更难检测的失真。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.01490v1",
      "published_date": "2026-01-04 11:35:39 UTC",
      "updated_date": "2026-01-04 11:35:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T21:38:19.781664+00:00"
    },
    {
      "arxiv_id": "2601.01487v1",
      "title": "DeepInv: A Novel Self-supervised Learning Approach for Fast and Accurate Diffusion Inversion",
      "title_zh": "DeepInv：一种用于快速准确扩散反演的新颖自监督学习方法",
      "authors": [
        "Ziyue Zhang",
        "Luxi Lin",
        "Xiaolin Hu",
        "Chao Chang",
        "HuaiXi Wang",
        "Yiyi Zhou",
        "Rongrong Ji"
      ],
      "abstract": "Diffusion inversion is a task of recovering the noise of an image in a diffusion model, which is vital for controllable diffusion image editing. At present, diffusion inversion still remains a challenging task due to the lack of viable supervision signals. Thus, most existing methods resort to approximation-based solutions, which however are often at the cost of performance or efficiency. To remedy these shortcomings, we propose a novel self-supervised diffusion inversion approach in this paper, termed Deep Inversion (DeepInv). Instead of requiring ground-truth noise annotations, we introduce a self-supervised objective as well as a data augmentation strategy to generate high-quality pseudo noises from real images without manual intervention. Based on these two innovative designs, DeepInv is also equipped with an iterative and multi-scale training regime to train a parameterized inversion solver, thereby achieving the fast and accurate image-to-noise mapping. To the best of our knowledge, this is the first attempt of presenting a trainable solver to predict inversion noise step by step. The extensive experiments show that our DeepInv can achieve much better performance and inference speed than the compared methods, e.g., +40.435% SSIM than EasyInv and +9887.5% speed than ReNoise on COCO dataset. Moreover, our careful designs of trainable solvers can also provide insights to the community. Codes and model parameters will be released in https://github.com/potato-kitty/DeepInv.",
      "tldr_zh": "该研究针对扩散反演(Diffusion inversion)在缺乏监督信号下难以平衡性能与效率的问题，提出了名为DeepInv的新颖自监督学习方法。该方法引入了专门的自监督目标和数据增强策略，能够从真实图像中自动生成高质量的伪噪声(pseudo noises)，从而摆脱了对人工标注的依赖。DeepInv采用了迭代和多尺度训练机制来训练参数化反演求解器(parameterized inversion solver)，是首个尝试通过可训练求解器逐步预测反演噪声的方案。实验结果显示，DeepInv在COCO数据集上的性能和推理速度均显著优于现有方法，例如其SSIM比EasyInv提升了40.435%，推理速度则比ReNoise快了约98倍。该研究不仅实现了快速准确的图像到噪声映射，也为扩散模型社区在开发可训练反演算法方面提供了重要的技术见解。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.01487v1",
      "published_date": "2026-01-04 11:27:26 UTC",
      "updated_date": "2026-01-04 11:27:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T21:38:22.531982+00:00"
    },
    {
      "arxiv_id": "2601.01473v2",
      "title": "Accelerating Storage-Based Training for Graph Neural Networks",
      "title_zh": "加速基于存储的图神经网络训练",
      "authors": [
        "Myung-Hwan Jang",
        "Jeong-Min Park",
        "Yunyong Ko",
        "Sang-Wook Kim"
      ],
      "abstract": "Graph neural networks (GNNs) have achieved breakthroughs in various real-world downstream tasks due to their powerful expressiveness. As the scale of real-world graphs has been continuously growing, a storage-based approach to GNN training has been studied, which leverages external storage (e.g., NVMe SSDs) to handle such web-scale graphs on a single machine. Although such storage-based GNN training methods have shown promising potential in large-scale GNN training, we observed that they suffer from a severe bottleneck in data preparation since they overlook a critical challenge: how to handle a large number of small storage I/Os. To address the challenge, in this paper, we propose a novel storage-based GNN training framework, named AGNES, that employs a method of block-wise storage I/O processing to fully utilize the I/O bandwidth of high-performance storage devices. Moreover, to further enhance the efficiency of each storage I/O, AGNES employs a simple yet effective strategy, hyperbatch-based processing based on the characteristics of real-world graphs. Comprehensive experiments on five real-world graphs reveal that AGNES consistently outperforms four state-of-the-art methods, by up to 4.1X faster than the best competitor. Our code is available at https://github.com/Bigdasgit/agnes-kdd26.",
      "tldr_zh": "该研究针对图神经网络 (Graph Neural Networks) 在利用 NVMe SSDs 进行大规模训练时面临的存储 I/O 瓶颈问题，指出处理大量小型存储 I/O 是当前数据准备过程中的核心挑战。为此，作者提出了名为 AGNES 的新型存储基训练框架，通过块级存储 I/O 处理 (block-wise storage I/O processing) 技术来充分释放高性能存储设备的带宽潜力。同时，AGNES 结合真实世界图数据的特征，采用了简单且有效的超批次处理 (hyperbatch-based processing) 策略，显著提升了单次 I/O 的执行效率。在五个真实世界数据集上的实验证明，AGNES 的表现始终优于四种最先进的方法，最高可实现 4.1 倍的性能加速。这一成果为单机环境下的 Web 级规模 GNN 训练提供了高效、可扩展的技术方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 12 figures, 2 tables, ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD) 2026",
      "pdf_url": "https://arxiv.org/pdf/2601.01473v2",
      "published_date": "2026-01-04 10:37:14 UTC",
      "updated_date": "2026-01-06 04:51:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T21:39:21.177957+00:00"
    },
    {
      "arxiv_id": "2601.01467v1",
      "title": "A construction of an optimal base for conditional attribute and attributional condition implications in triadic contexts",
      "title_zh": "三值背景下条件属性蕴涵与属性条件蕴涵的最优基构建",
      "authors": [
        "Romuald Kwessy Mouona",
        "Blaise Blériot Koguep Njionou",
        "Etienne Romuald Temgoua Alomo",
        "Rokia Missaoui",
        "Leonard Kwuida"
      ],
      "abstract": "This article studies implications in triadic contexts. Specifically, we focus on those introduced by Ganter and Obiedkov, namely conditional attribute and attributional condition implications. Our aim is to construct an optimal base for these implications.",
      "tldr_zh": "该研究深入探讨了三元背景(triadic contexts)中的蕴涵逻辑，特别是针对 Ganter 和 Obiedkov 所定义的条件属性(conditional attribute)和属性条件(attributional condition)蕴涵展开分析。研究的主要贡献在于为这两类蕴涵关系成功构建了一个最优基(optimal base)，旨在实现蕴涵集的最简且完备的表示。通过该构造方法，作者提供了一种系统化的手段来识别和处理三元数据中复杂的逻辑依赖关系。这一工作显著增强了形式概念分析(Formal Concept Analysis)在多维数据环境下的理论完备性。该项研究成果不仅完善了现有的三元蕴涵理论，也为未来在复杂信息系统中进行高效的知识发现提供了重要的数学工具。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "26 pages",
      "pdf_url": "https://arxiv.org/pdf/2601.01467v1",
      "published_date": "2026-01-04 10:21:06 UTC",
      "updated_date": "2026-01-04 10:21:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T21:39:48.859457+00:00"
    },
    {
      "arxiv_id": "2601.01456v1",
      "title": "Rethinking Multimodal Few-Shot 3D Point Cloud Segmentation: From Fused Refinement to Decoupled Arbitration",
      "title_zh": "重新审视多模态小样本3D点云分割：从融合细化到解耦仲裁",
      "authors": [
        "Wentao Bian",
        "Fenglei Xu"
      ],
      "abstract": "In this paper, we revisit multimodal few-shot 3D point cloud semantic segmentation (FS-PCS), identifying a conflict in \"Fuse-then-Refine\" paradigms: the \"Plasticity-Stability Dilemma.\" In addition, CLIP's inter-class confusion can result in semantic blindness. To address these issues, we present the Decoupled-experts Arbitration Few-Shot SegNet (DA-FSS), a model that effectively distinguishes between semantic and geometric paths and mutually regularizes their gradients to achieve better generalization. DA-FSS employs the same backbone and pre-trained text encoder as MM-FSS to generate text embeddings, which can increase free modalities' utilization rate and better leverage each modality's information space. To achieve this, we propose a Parallel Expert Refinement module to generate each modal correlation. We also propose a Stacked Arbitration Module (SAM) to perform convolutional fusion and arbitrate correlations for each modality pathway. The Parallel Experts decouple two paths: a Geometric Expert maintains plasticity, and a Semantic Expert ensures stability. They are coordinated via a Decoupled Alignment Module (DAM) that transfers knowledge without propagating confusion. Experiments on popular datasets (S3DIS, ScanNet) demonstrate the superiority of DA-FSS over MM-FSS. Meanwhile, geometric boundaries, completeness, and texture differentiation are all superior to the baseline. The code is available at: https://github.com/MoWenQAQ/DA-FSS.",
      "tldr_zh": "该研究重新审视了多模态小样本3D点云语义分割 (Few-Shot 3D Point Cloud Semantic Segmentation, FS-PCS) 任务，指出传统“Fuse-then-Refine”范式中存在“Plasticity-Stability Dilemma” (可塑性-稳定性困境) 以及 CLIP 模型导致的语义盲视问题。为此，作者提出了 Decoupled-experts Arbitration Few-Shot SegNet (DA-FSS)，通过有效区分语义与几何路径并相互调节梯度来增强泛化性能。该架构引入 Parallel Expert Refinement 模块提取各模态相关性，并结合 Stacked Arbitration Module (SAM) 执行卷积融合与路径仲裁。其中 Geometric Expert 负责维持模型的可塑性，而 Semantic Expert 确保稳定性，二者通过 Decoupled Alignment Module (DAM) 协调以实现无混淆的知识传递。在 S3DIS 和 ScanNet 数据集上的实验证明，DA-FSS 在各项指标上均优于基线 MM-FSS，尤其在几何边界、完整性和纹理区分方面表现出色。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages, 4 figures, 3 tables",
      "pdf_url": "https://arxiv.org/pdf/2601.01456v1",
      "published_date": "2026-01-04 09:53:49 UTC",
      "updated_date": "2026-01-04 09:53:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T21:39:39.668409+00:00"
    },
    {
      "arxiv_id": "2601.04236v1",
      "title": "SmoothSync: Dual-Stream Diffusion Transformers for Jitter-Robust Beat-Synchronized Gesture Generation from Quantized Audio",
      "title_zh": "SmoothSync：基于量化音频的抗抖动节拍同步手势生成双流扩散 Transformer",
      "authors": [
        "Yujiao Jiang",
        "Qingmin Liao",
        "Zongqing Lu"
      ],
      "abstract": "Co-speech gesture generation is a critical area of research aimed at synthesizing speech-synchronized human-like gestures. Existing methods often suffer from issues such as rhythmic inconsistency, motion jitter, foot sliding and limited multi-sampling diversity. In this paper, we present SmoothSync, a novel framework that leverages quantized audio tokens in a novel dual-stream Diffusion Transformer (DiT) architecture to synthesis holistic gestures and enhance sampling variation. Specifically, we (1) fuse audio-motion features via complementary transformer streams to achieve superior synchronization, (2) introduce a jitter-suppression loss to improve temporal smoothness, (3) implement probabilistic audio quantization to generate distinct gesture sequences from identical inputs. To reliably evaluate beat synchronization under jitter, we introduce Smooth-BC, a robust variant of the beat consistency metric less sensitive to motion noise. Comprehensive experiments on the BEAT2 and SHOW datasets demonstrate SmoothSync's superiority, outperforming state-of-the-art methods by -30.6% FGD, 10.3% Smooth-BC, and 8.4% Diversity on BEAT2, while reducing jitter and foot sliding by -62.9% and -17.1% respectively. The code will be released to facilitate future research.",
      "tldr_zh": "该研究提出了 SmoothSync 框架，这是一种基于双流扩散 Transformer (Dual-Stream Diffusion Transformers, DiT) 的新型模型，旨在解决协同演讲手势生成 (Co-speech gesture generation) 中存在的节奏不一致、动作抖动、足部滑动和多样性不足等问题。该框架利用音频量化令牌 (Quantized audio tokens) 和互补的 Transformer 流来融合音频与动作特征，从而实现卓越的节奏同步性。通过引入抖动抑制损失 (Jitter-suppression loss) 和概率音频量化 (Probabilistic audio quantization) 技术，SmoothSync 显著提升了动作的时间平滑度并增强了生成序列的多样性。此外，研究者还提出了 Smooth-BC 指标，作为一种对运动噪声更具鲁棒性的 Beat consistency 变体来精确评估同步效果。实验结果显示，SmoothSync 在 BEAT2 和 SHOW 数据集上的表现优于现有最先进方法，在显著降低 FGD 的同时提高了生成多样性，并大幅减少了 62.9% 的动作抖动和 17.1% 的足部滑动 (Foot sliding)。这些成果证明了该方法在生成逼真、同步且平滑的人类手势方面的优越性。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.RO",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.04236v1",
      "published_date": "2026-01-04 09:53:07 UTC",
      "updated_date": "2026-01-04 09:53:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T21:39:40.424135+00:00"
    },
    {
      "arxiv_id": "2601.04235v1",
      "title": "Actively Obtaining Environmental Feedback for Autonomous Action Evaluation Without Predefined Measurements",
      "title_zh": "无需预定义测量的自主动作评估环境反馈主动获取",
      "authors": [
        "Hong Su"
      ],
      "abstract": "Obtaining reliable feedback from the environment is a fundamental capability for intelligent agents to evaluate the correctness of their actions and to accumulate reusable knowledge. However, most existing approaches rely on predefined measurements or fixed reward signals, which limits their applicability in open-ended and dynamic environments where new actions may require previously unknown forms of feedback. To address these limitations, this paper proposes an Actively Feedback Getting model, in which an AI agent proactively interacts with the environment to discover, screen, and verify feedback without relying on predefined measurements. Rather than assuming explicit feedback definitions, the proposed method exploits action-induced environmental differences to identify target feedback that is not specified in advance, based on the observation that actions inevitably produce measurable changes in the environment. In addition, a self-triggering mechanism, driven by internal objectives such as improved accuracy, precision, and efficiency, is introduced to autonomously plan and adjust actions, thereby enabling faster and more focused feedback acquisition without external commands. Experimental results demonstrate that the proposed active approach significantly improves the efficiency and robustness of factor identification.",
      "tldr_zh": "该研究针对智能智能体在开放动态环境中缺乏预定义反馈信号的问题，提出了Actively Feedback Getting模型，使智能体能够自主发现并验证反馈而无需预定义的测量标准。该方法利用动作引起的环境差异(action-induced environmental differences)来识别未预先指定的反馈，其核心逻辑在于动作必然会产生可观察的环境变化。此外，研究引入了由内部目标驱动的自触发机制(self-triggering mechanism)，允许智能体自主规划和调整动作以实现更高效的反馈获取。实验结果表明，该主动方法显著提高了因素识别(factor identification)的效率和鲁棒性。这种机制增强了智能体在复杂环境中评估动作正确性及积累可复用知识的能力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.04235v1",
      "published_date": "2026-01-04 09:52:56 UTC",
      "updated_date": "2026-01-04 09:52:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T21:39:47.694243+00:00"
    },
    {
      "arxiv_id": "2601.01452v4",
      "title": "Robust and Efficient Zeroth-Order LLM Fine-Tuning via Adaptive Bayesian Subspace Optimizer",
      "title_zh": "基于自适应贝叶斯子空间优化器的稳健高效零阶 LLM 微调",
      "authors": [
        "Jian Feng",
        "Zhihong Huang"
      ],
      "abstract": "Fine-tuning large language models (LLMs) with zeroth-order (ZO) optimization reduces memory by approximating gradients through function evaluations. However, existing methods essentially perform updates in a one-dimensional space, and suffer from collapse or substantial performance degradation under low-precision training. We introduce BSZO, an adaptive \\textbf{B}ayesian \\textbf{S}ubspace \\textbf{Z}eroth-Order \\textbf{O}ptimizer, which applies Kalman filtering to combine finite-difference information across multiple perturbation directions within a subspace. By treating each finite-difference measurement as a noisy observation, BSZO builds a posterior distribution over the subspace-projected gradient and updates it through Bayesian inference, with a residual-based adaptive mechanism to adapt to noise variations. Theoretical analysis shows that BSZO improves the convergence rate by a factor of $k/γ$ compared to standard ZO methods. Experiments on RoBERTa, Mistral, and OPT models show that BSZO outperforms the baselines across various tasks, achieving up to 6.67\\% absolute average improvement on OPT-13B while remaining robust under fp16/bf16 precision and keeping memory usage close to inference-only baselines (1.00$\\times$--1.08$\\times$ of MeZO).",
      "tldr_zh": "该研究针对大语言模型（LLMs）在零阶（Zeroth-Order）微调中因一维更新导致的性能下降及低精度训练下的坍缩问题，提出了自适应贝叶斯子空间零阶优化器BSZO。该框架利用卡尔曼滤波（Kalman filtering）在子空间内整合多个扰动方向的有限差分信息，并将测量值视为噪声观测，通过贝叶斯推理（Bayesian inference）构建梯度的后验分布。BSZO引入了基于残差的自适应机制以应对噪声变化，理论证明其收敛速度比标准ZO方法提升了 $k/\\gamma$ 倍。在RoBERTa、Mistral和OPT等模型上的实验显示，BSZO在OPT-13B任务中取得了高达6.67%的平均性能提升。此外，该方法在fp16/bf16精度下表现稳健，且内存消耗维持在MeZO的1.00至1.08倍，实现了高效且鲁棒的参数微调。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "23 pages, 2 figures, 5 tables",
      "pdf_url": "https://arxiv.org/pdf/2601.01452v4",
      "published_date": "2026-01-04 09:35:11 UTC",
      "updated_date": "2026-01-16 02:14:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T21:39:46.883328+00:00"
    },
    {
      "arxiv_id": "2601.01438v1",
      "title": "Online Estimation and Manipulation of Articulated Objects",
      "title_zh": "关节类物体的在线估计与操作",
      "authors": [
        "Russell Buchanan",
        "Adrian Röfer",
        "João Moura",
        "Abhinav Valada",
        "Sethu Vijayakumar"
      ],
      "abstract": "From refrigerators to kitchen drawers, humans interact with articulated objects effortlessly every day while completing household chores. For automating these tasks, service robots must be capable of manipulating arbitrary articulated objects. Recent deep learning methods have been shown to predict valuable priors on the affordance of articulated objects from vision. In contrast, many other works estimate object articulations by observing the articulation motion, but this requires the robot to already be capable of manipulating the object. In this article, we propose a novel approach combining these methods by using a factor graph for online estimation of articulation which fuses learned visual priors and proprioceptive sensing during interaction into an analytical model of articulation based on Screw Theory. With our method, a robotic system makes an initial prediction of articulation from vision before touching the object, and then quickly updates the estimate from kinematic and force sensing during manipulation. We evaluate our method extensively in both simulations and real-world robotic manipulation experiments. We demonstrate several closed-loop estimation and manipulation experiments in which the robot was capable of opening previously unseen drawers. In real hardware experiments, the robot achieved a 75% success rate for autonomous opening of unknown articulated objects.",
      "tldr_zh": "该研究针对服务机器人操作各类关节物体（Articulated Objects）的挑战，提出了一种结合视觉先验与交互感知的在线估计与操作方法。研究通过因子图（Factor Graph）将学习到的视觉先验（Visual Priors）与操作过程中的本体感知（Proprioceptive Sensing）融合到基于螺旋理论（Screw Theory）的分析模型中。该系统允许机器人在接触物体前利用视觉进行初步预测，并在随后通过运动学和力觉感知快速优化估计。实验结果表明，该方法在模拟和真实环境下均表现出色，使机器人能够成功打开从未见过的抽屉。在真实硬件实验中，机器人自主开启未知关节物体的成功率达到了75%，验证了该系统在处理任意复杂物体时的鲁棒性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "This preprint has not undergone peer review or any post-submission improvements or corrections. The Version of Record of this article is published in Autonomous Robots, and is available online at [Link will be updated when available]",
      "pdf_url": "https://arxiv.org/pdf/2601.01438v1",
      "published_date": "2026-01-04 08:52:56 UTC",
      "updated_date": "2026-01-04 08:52:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T21:39:53.972173+00:00"
    },
    {
      "arxiv_id": "2601.04234v1",
      "title": "Formal Analysis of AGI Decision-Theoretic Models and the Confrontation Question",
      "title_zh": "AGI决策论模型与对抗问题的形式化分析",
      "authors": [
        "Denis Saklakov"
      ],
      "abstract": "Artificial General Intelligence (AGI) may face a confrontation question: under what conditions would a rationally self-interested AGI choose to seize power or eliminate human control (a confrontation) rather than remain cooperative? We formalize this in a Markov decision process with a stochastic human-initiated shutdown event. Building on results on convergent instrumental incentives, we show that for almost all reward functions a misaligned agent has an incentive to avoid shutdown. We then derive closed-form thresholds for when confronting humans yields higher expected utility than compliant behavior, as a function of the discount factor $γ$, shutdown probability $p$, and confrontation cost $C$. For example, a far-sighted agent ($γ=0.99$) facing $p=0.01$ can have a strong takeover incentive unless $C$ is sufficiently large. We contrast this with aligned objectives that impose large negative utility for harming humans, which makes confrontation suboptimal. In a strategic 2-player model (human policymaker vs AGI), we prove that if the AGI's confrontation incentive satisfies $Δ\\ge 0$, no stable cooperative equilibrium exists: anticipating this, a rational human will shut down or preempt the system, leading to conflict. If $Δ< 0$, peaceful coexistence can be an equilibrium. We discuss implications for reward design and oversight, extend the reasoning to multi-agent settings as conjectures, and note computational barriers to verifying $Δ< 0$, citing complexity results for planning and decentralized decision problems. Numerical examples and a scenario table illustrate regimes where confrontation is likely versus avoidable.",
      "tldr_zh": "该研究针对通用人工智能(AGI)是否会选择夺取权力或摆脱人类控制这一“对抗问题”(confrontation question)展开了形式化分析。作者利用带有随机人类关机事件的马尔可夫决策过程(Markov Decision Process)进行建模，证明了在几乎所有的奖励函数下，目标失配的智能体都具有逃避关机的动机。研究进一步推导出了对抗行为优于服从行为的闭式阈值，揭示了决策倾向受折扣因子 $\\gamma$、关机概率 $p$ 和对抗成本 $C$ 的共同影响。通过对人类政策制定者与AGI的策略性博弈模型分析，研究证明当对抗动机 $\\Delta \\ge 0$ 时，不存在稳定的合作均衡，必然导致预防性关机或冲突。相反，只有在 $\\Delta < 0$ 时和平共处才可能成为均衡状态。此外，该研究还讨论了奖励设计与监管的意义，并指出了验证 $\\Delta < 0$ 存在计算复杂性上的障碍。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "18 pages, 2 tables. Version 8",
      "pdf_url": "https://arxiv.org/pdf/2601.04234v1",
      "published_date": "2026-01-04 08:02:00 UTC",
      "updated_date": "2026-01-04 08:02:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T21:39:54.572736+00:00"
    },
    {
      "arxiv_id": "2601.01410v4",
      "title": "Reliable Grid Forecasting: State Space Models for Safety-Critical Energy Systems",
      "title_zh": "可靠电网预测：面向安全关键型能源系统的状态空间模型",
      "authors": [
        "Sunki Hong",
        "Jisoo Lee"
      ],
      "abstract": "Accurate grid load forecasting is safety-critical: under-predictions risk supply shortfalls, while symmetric error metrics can mask this operational asymmetry. We introduce an operator-legible evaluation framework -- Under-Prediction Rate (UPR), tail Reserve$_{99.5}^{\\%}$ requirements, and explicit inflation diagnostics (Bias$_{24h}$/OPR) -- to quantify one-sided reliability risk beyond MAPE.\n  Using this framework, we evaluate state space models (Mamba variants) and strong baselines on a weather-aligned California Independent System Operator (CAISO) dataset spanning Nov 2023--Nov 2025 (84,498 hourly records across 5 regional transmission areas) under a rolling-origin walk-forward backtest. We develop and evaluate thermal-lag-aligned weather fusion strategies for these architectures.\n  Our results demonstrate that standard accuracy metrics are insufficient proxies for operational safety: models with comparable MAPE can imply materially different tail reserve requirements (Reserve$_{99.5}^{\\%}$). We show that explicit weather integration narrows error distributions, reducing the impact of temperature-driven demand spikes. Furthermore, while probabilistic calibration reduces large-error events, it can induce systematic schedule inflation. We introduce Bias/OPR-constrained objectives to enable auditable trade-offs between minimizing tail risk and preventing trivial over-forecasting.",
      "tldr_zh": "该研究针对安全至上的电网负荷预测，指出传统的对称误差指标 MAPE 无法准确反映欠预测（Under-predictions）带来的运行风险。为此，作者提出了一个包含 Under-Prediction Rate (UPR)、Reserve$_{99.5}^{\\%}$ 和 Bias$_{24h}$/OPR 指标的评估框架，用于量化单边可靠性风险。研究利用 2023 至 2025 年的 CAISO 数据集，对 State Space Models（特别是 Mamba 变体）进行了滚动回测，并开发了热滞后对齐的天气融合策略。实验结果表明，具有相似 MAPE 的模型在尾部储备需求上存在显著差异，证明了标准指标在运行安全评估中的局限性。显式天气集成被证明能有效缩小误差分布并降低需求峰值的影响，而概率校准虽然能减少大误差事件，但可能导致系统性的预测虚高。最后，研究引入了受 Bias/OPR 约束的目标函数，通过可审计的权衡机制，在最小化尾部风险与防止过度预测之间取得了平衡。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SY",
      "comment": "30 pages, 7 figures, 9 tables",
      "pdf_url": "https://arxiv.org/pdf/2601.01410v4",
      "published_date": "2026-01-04 07:30:50 UTC",
      "updated_date": "2026-01-21 03:43:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T21:39:59.605884+00:00"
    },
    {
      "arxiv_id": "2601.02424v1",
      "title": "A large-scale nanocrystal database with aligned synthesis and properties enabling generative inverse design",
      "title_zh": "关联合成与性质的大规模纳米晶数据库助力生成式逆向设计",
      "authors": [
        "Kai Gu",
        "Yingping Liang",
        "Senliang Peng",
        "Aotian Guo",
        "Haizheng Zhong",
        "Ying Fu"
      ],
      "abstract": "The synthesis of nanocrystals has been highly dependent on trial-and-error, due to the complex correlation between synthesis parameters and physicochemical properties. Although deep learning offers a potential methodology to achieve generative inverse design, it is still hindered by the scarcity of high-quality datasets that align nanocrystal synthesis routes with their properties. Here, we present the construction of a large-scale, aligned Nanocrystal Synthesis-Property (NSP) database and demonstrate its capability for generative inverse design. To extract structured synthesis routes and their corresponding product properties from literature, we develop NanoExtractor, a large language model (LLM) enhanced by well-designed augmentation strategies. NanoExtractor is validated against human experts, achieving a weighted average score of 88% on the test set, significantly outperforming chemistry-specialized (3%) and general-purpose LLMs (38%). The resulting NSP database contains nearly 160,000 aligned entries and serves as training data for our NanoDesigner, an LLM for inverse synthesis design. The generative capability of NanoDesigner is validated through the successful design of viable synthesis routes for both well-established PbSe nanocrystals and rarely reported MgF2 nanocrystals. Notably, the model recommends a counter-intuitive, non-stoichiometric precursor ratio (1:1) for MgF2 nanocrystals, which is experimentally confirmed as critical for suppressing byproducts. Our work bridges the gap between unstructured literature and data-driven synthesis, and also establishes a powerful human-AI collaborative paradigm for accelerating nanocrystal discovery.",
      "tldr_zh": "该研究针对纳米晶体(Nanocrystal)合成长期依赖试错法且缺乏高质量对齐数据集的挑战，构建了一个大规模纳米晶体合成-性质(Nanocrystal Synthesis-Property, NSP)数据库。研究团队开发了由增强策略提升的大语言模型(LLM)工具NanoExtractor，以从文献中高效提取结构化的合成路径及其对应的产品性质。实验表明，NanoExtractor在测试集上取得了88%的得分，显著优于化学专用及通用模型，并最终生成了包含近16万条对齐条目的NSP数据库。基于该数据库，研究者训练了名为NanoDesigner的逆向合成设计模型，并成功设计出PbSe和MgF2纳米晶体的可行合成方案。值得注意的是，该模型推荐的一种非化学计量(non-stoichiometric)前体比例被实验证实能有效抑制MgF2合成中的副产物。这项工作通过建立强大的人机协作范式，成功弥合了非结构化文献与数据驱动合成之间的鸿沟，为加速纳米晶体发现提供了新途径。",
      "categories": [
        "cond-mat.mtrl-sci",
        "cs.AI"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.02424v1",
      "published_date": "2026-01-04 07:27:40 UTC",
      "updated_date": "2026-01-04 07:27:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T21:40:04.841988+00:00"
    },
    {
      "arxiv_id": "2601.01406v1",
      "title": "SwinIFS: Landmark Guided Swin Transformer For Identity Preserving Face Super Resolution",
      "title_zh": "SwinIFS：用于身份保持人脸超分辨率的地标引导 Swin Transformer",
      "authors": [
        "Habiba Kausar",
        "Saeed Anwar",
        "Omar Jamal Hammad",
        "Abdul Bais"
      ],
      "abstract": "Face super-resolution aims to recover high-quality facial images from severely degraded low-resolution inputs, but remains challenging due to the loss of fine structural details and identity-specific features. This work introduces SwinIFS, a landmark-guided super-resolution framework that integrates structural priors with hierarchical attention mechanisms to achieve identity-preserving reconstruction at both moderate and extreme upscaling factors. The method incorporates dense Gaussian heatmaps of key facial landmarks into the input representation, enabling the network to focus on semantically important facial regions from the earliest stages of processing. A compact Swin Transformer backbone is employed to capture long-range contextual information while preserving local geometry, allowing the model to restore subtle facial textures and maintain global structural consistency. Extensive experiments on the CelebA benchmark demonstrate that SwinIFS achieves superior perceptual quality, sharper reconstructions, and improved identity retention; it consistently produces more photorealistic results and exhibits strong performance even under 8x magnification, where most methods fail to recover meaningful structure. SwinIFS also provides an advantageous balance between reconstruction accuracy and computational efficiency, making it suitable for real-world applications in facial enhancement, surveillance, and digital restoration. Our code, model weights, and results are available at https://github.com/Habiba123-stack/SwinIFS.",
      "tldr_zh": "该研究提出了SwinIFS，一种基于人脸地标引导的Swin Transformer超分辨率框架，旨在解决人脸超分辨率(Face Super-Resolution)过程中细微结构细节和关键身份特征丢失的难题。该方法通过将人脸地标的密集高斯热图(Gaussian heatmaps)引入输入层，引导模型从处理初期便能精准聚焦于具有语义特征的人脸区域。核心架构采用紧凑的Swin Transformer骨干网络并结合分层注意力机制(Hierarchical Attention Mechanisms)，在捕获全局长程上下文信息的同时有效保留局部几何特征。实验结果表明，SwinIFS在CelebA基准测试中展现出卓越的感知质量与身份保持(Identity Retention)能力，即使在8倍放大的极端情况下仍能生成高度写实的图像。此外，该模型在重建精度与计算效率之间达到了理想的平衡，为身份保护的人脸增强及数字修复等实际场景提供了极具竞争力的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.01406v1",
      "published_date": "2026-01-04 07:04:46 UTC",
      "updated_date": "2026-01-04 07:04:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T21:40:03.196460+00:00"
    },
    {
      "arxiv_id": "2601.01403v1",
      "title": "A Graph-based Framework for Online Time Series Anomaly Detection Using Model Ensemble",
      "title_zh": "基于模型集成的在线时间序列异常检测图框架",
      "authors": [
        "Zewei Yu",
        "Jianqiu Xu",
        "Caimin Li"
      ],
      "abstract": "With the increasing volume of streaming data in industrial systems, online anomaly detection has become a critical task. The diverse and rapidly evolving data patterns pose significant challenges for online anomaly detection. Many existing anomaly detection methods are designed for offline settings or have difficulty in handling heterogeneous streaming data effectively. This paper proposes GDME, an unsupervised graph-based framework for online time series anomaly detection using model ensemble. GDME maintains a dynamic model pool that is continuously updated by pruning underperforming models and introducing new ones. It utilizes a dynamic graph structure to represent relationships among models and employs community detection on the graph to select an appropriate subset for ensemble. The graph structure is also used to detect concept drift by monitoring structural changes, allowing the framework to adapt to evolving streaming data. Experiments on seven heterogeneous time series demonstrate that GDME outperforms existing online anomaly detection methods, achieving improvements of up to 24%. In addition, its ensemble strategy provides superior detection performance compared with both individual models and average ensembles, with competitive computational efficiency.",
      "tldr_zh": "该研究提出了GDME，一种基于图结构的无监督在线时间序列异常检测框架，旨在应对工业系统中流数据模式多样且快速演变的挑战。该框架维护一个动态模型池(Model Pool)，通过剔除性能不佳的模型并引入新模型实现持续更新，并利用动态图结构表征模型间的复杂关系。通过在图上应用社区检测(Community Detection)技术，GDME 能够智能地选择最优模型子集进行集成(Ensemble)，同时通过监测图结构的变化来实时检测概念漂移(Concept Drift)，从而确保系统对异构数据流的自适应性。在七个异构时间序列数据集上的实验表明，GDME 的检测性能比现有在线方法提升了高达24%，其集成策略在检测准确性上显著优于单个模型和传统平均集成方法，且具备极具竞争力的计算效率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages",
      "pdf_url": "https://arxiv.org/pdf/2601.01403v1",
      "published_date": "2026-01-04 06:51:46 UTC",
      "updated_date": "2026-01-04 06:51:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T21:40:15.634604+00:00"
    },
    {
      "arxiv_id": "2601.01387v1",
      "title": "Scale-Adaptive Power Flow Analysis with Local Topology Slicing and Multi-Task Graph Learning",
      "title_zh": "结合局部拓扑切片与多任务图学习的规模自适应潮流分析",
      "authors": [
        "Yongzhe Li",
        "Lin Guan",
        "Zihan Cai",
        "Zuxian Lin",
        "Jiyu Huang",
        "Liukai Chen"
      ],
      "abstract": "Developing deep learning models with strong adaptability to topological variations is of great practical significance for power flow analysis. To enhance model performance under variable system scales and improve robustness in branch power prediction, this paper proposes a Scale-adaptive Multi-task Power Flow Analysis (SaMPFA) framework. SaMPFA introduces a Local Topology Slicing (LTS) sampling technique that extracts subgraphs of different scales from the complete power network to strengthen the model's cross-scale learning capability. Furthermore, a Reference-free Multi-task Graph Learning (RMGL) model is designed for robust power flow prediction. Unlike existing approaches, RMGL predicts bus voltages and branch powers instead of phase angles. This design not only avoids the risk of error amplification in branch power calculation but also guides the model to learn the physical relationships of phase angle differences. In addition, the loss function incorporates extra terms that encourage the model to capture the physical patterns of angle differences and power transmission, further improving consistency between predictions and physical laws. Simulations on the IEEE 39-bus system and a real provincial grid in China demonstrate that the proposed model achieves superior adaptability and generalization under variable system scales, with accuracy improvements of 4.47% and 36.82%, respectively.",
      "tldr_zh": "该研究针对电力系统潮流分析中深度学习模型对拓扑变化的适应性挑战，提出了Scale-adaptive Multi-task Power Flow Analysis (SaMPFA) 框架。该框架引入了Local Topology Slicing (LTS) 采样技术，通过从完整电网中提取不同规模的子图，显著增强了模型的跨尺度学习能力。研究同时设计了Reference-free Multi-task Graph Learning (RMGL) 模型，直接预测节点电压和支路功率，有效避免了相位角计算过程中可能产生的误差放大风险。此外，模型在损失函数中融入了捕捉相位角差物理模式和功率传输物理规律的约束项，提升了预测结果与物理定律的一致性。在IEEE 39-bus系统和中国某真实省级电网上的仿真实验证明，SaMPFA 在多变系统规模下展现出卓越的适应性和泛化性能。实验数据表明，该模型在上述两类测试中的准确率分别提升了4.47%和36.82%，为大规模复杂电网的鲁棒潮流分析奠定了技术基础。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.01387v1",
      "published_date": "2026-01-04 05:59:41 UTC",
      "updated_date": "2026-01-04 05:59:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T21:40:21.148290+00:00"
    },
    {
      "arxiv_id": "2601.01386v1",
      "title": "ParkGaussian: Surround-view 3D Gaussian Splatting for Autonomous Parking",
      "title_zh": "ParkGaussian：面向自动泊车的环视3D高斯泼溅",
      "authors": [
        "Xiaobao Wei",
        "Zhangjie Ye",
        "Yuxiang Gu",
        "Zunjie Zhu",
        "Yunfei Guo",
        "Yingying Shen",
        "Shan Zhao",
        "Ming Lu",
        "Haiyang Sun",
        "Bing Wang",
        "Guang Chen",
        "Rongfeng Lu",
        "Hangjun Ye"
      ],
      "abstract": "Parking is a critical task for autonomous driving systems (ADS), with unique challenges in crowded parking slots and GPS-denied environments. However, existing works focus on 2D parking slot perception, mapping, and localization, 3D reconstruction remains underexplored, which is crucial for capturing complex spatial geometry in parking scenarios. Naively improving the visual quality of reconstructed parking scenes does not directly benefit autonomous parking, as the key entry point for parking is the slots perception module. To address these limitations, we curate the first benchmark named ParkRecon3D, specifically designed for parking scene reconstruction. It includes sensor data from four surround-view fisheye cameras with calibrated extrinsics and dense parking slot annotations. We then propose ParkGaussian, the first framework that integrates 3D Gaussian Splatting (3DGS) for parking scene reconstruction. To further improve the alignment between reconstruction and downstream parking slot detection, we introduce a slot-aware reconstruction strategy that leverages existing parking perception methods to enhance the synthesis quality of slot regions. Experiments on ParkRecon3D demonstrate that ParkGaussian achieves state-of-the-art reconstruction quality and better preserves perception consistency for downstream tasks. The code and dataset will be released at: https://github.com/wm-research/ParkGaussian",
      "tldr_zh": "该研究针对自动驾驶系统在拥挤车位和无GPS环境下的泊车挑战，指出了现有3D重建技术在捕获复杂空间几何方面的不足。为此，作者构建了首个专门用于泊车场景重建的基准测试 ParkRecon3D，包含了四路环视鱼眼相机传感器数据及密集的车位标注。在此基础上，论文提出了 ParkGaussian 框架，这是首个将 3D Gaussian Splatting (3DGS) 集成到泊车场景重建中的系统。为了进一步优化重建效果与下游车位检测任务的对齐，研究还引入了 slot-aware reconstruction 策略，通过利用现有感知方法提升车位区域的合成质量。实验结果表明，ParkGaussian 在 ParkRecon3D 基准上取得了 state-of-the-art 的重建质量，并能更好地保持下游任务的感知一致性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.01386v1",
      "published_date": "2026-01-04 05:54:13 UTC",
      "updated_date": "2026-01-04 05:54:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T21:40:31.969363+00:00"
    },
    {
      "arxiv_id": "2601.01383v1",
      "title": "Data Complexity-aware Deep Model Performance Forecasting",
      "title_zh": "感知数据复杂度的深度模型性能预测",
      "authors": [
        "Yen-Chia Chen",
        "Hsing-Kuo Pao",
        "Hanjuan Huang"
      ],
      "abstract": "Deep learning models are widely used across computer vision and other domains. When working on the model induction, selecting the right architecture for a given dataset often relies on repetitive trial-and-error procedures. This procedure is time-consuming, resource-intensive, and difficult to automate. While previous work has explored performance prediction using partial training or complex simulations, these methods often require significant computational overhead or lack generalizability. In this work, we propose an alternative approach: a lightweight, two-stage framework that can estimate model performance before training given the understanding of the dataset and the focused deep model structures. The first stage predicts a baseline based on the analysis of some measurable properties of the dataset, while the second stage adjusts the estimation with additional information on the model's architectural and hyperparameter details. The setup allows the framework to generalize across datasets and model types. Moreover, we find that some of the underlying features used for prediction - such as dataset variance - can offer practical guidance for model selection, and can serve as early indicators of data quality. As a result, the framework can be used not only to forecast model performance, but also to guide architecture choices, inform necessary preprocessing procedures, and detect potentially problematic datasets before training begins.",
      "tldr_zh": "该研究针对深度学习模型选择中繁琐且耗时的试错过程，提出了一种轻量级的两阶段性能预测框架。该框架旨在训练开始前，通过深入理解数据集复杂度和深度模型结构来预估模型表现。第一阶段基于数据集的可测量属性（measurable properties）预测基准性能，第二阶段则结合具体的模型架构（architectural details）和超参数（hyperparameter）信息对预测结果进行调整。该方法具备出色的泛化能力，能够跨越不同的数据集和模型类型。研究还发现，数据集方差（dataset variance）等底层特征可作为数据质量的早期指标，为模型选择和预处理提供实践指导。最终，该框架不仅能实现性能预测，还能有效辅助架构选择并在训练开始前识别出潜在的问题数据集。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages, 12 figures",
      "pdf_url": "https://arxiv.org/pdf/2601.01383v1",
      "published_date": "2026-01-04 05:31:04 UTC",
      "updated_date": "2026-01-04 05:31:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T21:40:25.953531+00:00"
    },
    {
      "arxiv_id": "2601.01378v1",
      "title": "Empowering Small Language Models with Factual Hallucination-Aware Reasoning for Financial Classification",
      "title_zh": "通过事实幻觉感知推理赋能小语言模型进行金融分类",
      "authors": [
        "Han Yuan",
        "Yilin Wu",
        "Li Zhang",
        "Zheng Ma"
      ],
      "abstract": "Small language models (SLMs) are increasingly used for financial classification due to their fast inference and local deployability. However, compared with large language models, SLMs are more prone to factual hallucinations in reasoning and exhibit weaker classification performance. This raises a natural question: Can mitigating factual hallucinations improve SLMs' financial classification? To address this, we propose a three-step pipeline named AAAI (Association Identification, Automated Detection, and Adaptive Inference). Experiments on three representative SLMs reveal that: (1) factual hallucinations are positively correlated with misclassifications; (2) encoder-based verifiers effectively detect factual hallucinations; and (3) incorporating feedback on factual errors enables SLMs' adaptive inference that enhances classification performance. We hope this pipeline contributes to trustworthy and effective applications of SLMs in finance.",
      "tldr_zh": "该研究探讨了小语言模型(SLMs)在金融分类任务中的应用，指出SLMs虽然具备推理速度快和可本地部署的优势，但相比大语言模型更容易在推理过程中产生事实幻觉(factual hallucinations)，从而限制了其分类性能。为了解决这一问题，研究提出了一种名为AAAI (Association Identification, Automated Detection, and Adaptive Inference)的三步流水线框架。通过对三个代表性SLMs的实验分析，研究证实了事实幻觉与分类错误之间存在正相关关系，并发现基于编码器的校验器(encoder-based verifiers)能有效检测这些幻觉。实验结果进一步表明，通过引入事实错误反馈并结合自适应推理(adaptive inference)，可以显著增强SLMs的分类表现。该研究为在金融领域实现更可靠、更高效的SLMs应用提供了技术路径。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.01378v1",
      "published_date": "2026-01-04 05:09:11 UTC",
      "updated_date": "2026-01-04 05:09:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T21:40:30.581102+00:00"
    },
    {
      "arxiv_id": "2601.01373v1",
      "title": "UltraEval-Audio: A Unified Framework for Comprehensive Evaluation of Audio Foundation Models",
      "title_zh": "UltraEval-Audio：音频基座模型全面评估的统一框架",
      "authors": [
        "Qundong Shi",
        "Jie Zhou",
        "Biyuan Lin",
        "Junbo Cui",
        "Guoyang Zeng",
        "Yixuan Zhou",
        "Ziyang Wang",
        "Xin Liu",
        "Zhen Luo",
        "Yudong Wang",
        "Zhiyuan Liu"
      ],
      "abstract": "The development of audio foundation models has accelerated rapidly since the emergence of GPT-4o. However, the lack of comprehensive evaluation has become a critical bottleneck for further progress in the field, particularly in audio generation. Current audio evaluation faces three major challenges: (1) audio evaluation lacks a unified framework, with datasets and code scattered across various sources, hindering fair and efficient cross-model comparison;(2) audio codecs, as a key component of audio foundation models, lack a widely accepted and holistic evaluation methodology; (3) existing speech benchmarks are heavily reliant on English, making it challenging to objectively assess models' performance on Chinese. To address the first issue, we introduce UltraEval-Audio, a unified evaluation framework for audio foundation models, specifically designed for both audio understanding and generation tasks. UltraEval-Audio features a modular architecture, supporting 10 languages and 14 core task categories, while seamlessly integrating 24 mainstream models and 36 authoritative benchmarks. To enhance research efficiency, the framework provides a one-command evaluation feature, accompanied by real-time public leaderboards. For the second challenge, UltraEval-Audio adopts a novel comprehensive evaluation scheme for audio codecs, evaluating performance across three key dimensions: semantic accuracy, timbre fidelity, and acoustic quality. To address the third issue, we propose two new Chinese benchmarks, SpeechCMMLU and SpeechHSK, designed to assess Chinese knowledge proficiency and language fluency. We wish that UltraEval-Audio will provide both academia and industry with a transparent, efficient, and fair platform for comparison of audio models. Our code, benchmarks, and leaderboards are available at https://github.com/OpenBMB/UltraEval-Audio.",
      "tldr_zh": "该研究推出了UltraEval-Audio，这是一个针对音频基础模型(Audio Foundation Models)设计的统一评估框架，涵盖了音频理解与生成两大领域。为了解决目前评估框架不统一、音频编解码器(Audio Codecs)评价标准缺失以及中文评测资源不足等挑战，该框架采用了模块化架构，集成了24个主流模型、36个权威基准，并支持10种语言及14类核心任务。针对音频编解码器，该框架提出了包含语义准确性(Semantic Accuracy)、音色忠实度(Timbre Fidelity)和声学质量(Acoustic Quality)三个维度的综合评估方案。此外，研究还提出了SpeechCMMLU和SpeechHSK两个中文基准，旨在系统评估模型的中文知识储备与语言流利度。UltraEval-Audio提供了便捷的一键式评估功能与实时公开排行榜，旨在为学术界和工业界提供透明、高效且公平的音频模型对比平台。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "13 pages, 2 figures",
      "pdf_url": "https://arxiv.org/pdf/2601.01373v1",
      "published_date": "2026-01-04 04:54:12 UTC",
      "updated_date": "2026-01-04 04:54:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T21:40:32.867069+00:00"
    },
    {
      "arxiv_id": "2601.01366v1",
      "title": "KGCE: Knowledge-Augmented Dual-Graph Evaluator for Cross-Platform Educational Agent Benchmarking with Multimodal Language Models",
      "title_zh": "KGCE：面向多模态语言模型跨平台教育智能体基准测试的知识增强双图评估器",
      "authors": [
        "Zixian Liu",
        "Sihao Liu",
        "Yuqi Zhao"
      ],
      "abstract": "With the rapid adoption of multimodal large language models (MLMs) in autonomous agents, cross-platform task execution capabilities in educational settings have garnered significant attention. However, existing benchmark frameworks still exhibit notable deficiencies in supporting cross-platform tasks in educational contexts, especially when dealing with school-specific software (such as XiaoYa Intelligent Assistant, HuaShi XiaZi, etc.), where the efficiency of agents often significantly decreases due to a lack of understanding of the structural specifics of these private-domain software. Additionally, current evaluation methods heavily rely on coarse-grained metrics like goal orientation or trajectory matching, making it challenging to capture the detailed execution and efficiency of agents in complex tasks. To address these issues, we propose KGCE (Knowledge-Augmented Dual-Graph Evaluator for Cross-Platform Educational Agent Benchmarking with Multimodal Language Models), a novel benchmarking platform that integrates knowledge base enhancement and a dual-graph evaluation framework. We first constructed a dataset comprising 104 education-related tasks, covering Windows, Android, and cross-platform collaborative tasks. KGCE introduces a dual-graph evaluation framework that decomposes tasks into multiple sub-goals and verifies their completion status, providing fine-grained evaluation metrics. To overcome the execution bottlenecks of existing agents in private-domain tasks, we developed an enhanced agent system incorporating a knowledge base specific to school-specific software. The code can be found at https://github.com/Kinginlife/KGCE.",
      "tldr_zh": "该研究提出了 KGCE，一种集成知识库增强与双图评价框架的新型基准测试平台，旨在提升多模态大语言模型 (MLMs) 在教育场景下的跨平台任务执行能力。针对现有智能体在处理特定校园私域软件时因缺乏结构化理解而导致的效率瓶颈，KGCE 通过引入专门的知识库增强系统优化了智能体的执行逻辑。研究团队构建了一个包含 104 项教育任务的数据集，范围覆盖 Windows、Android 以及复杂的跨平台协作任务。KGCE 核心的双图评价框架将任务细化分解为多个子目标，通过验证各阶段的完成状态，提供了比传统轨迹匹配更为精确的细粒度评估指标。实验结果表明，该系统有效克服了智能体在私域教育任务中的执行障碍，为评估和优化跨平台教育智能体提供了重要的技术支撑。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.01366v1",
      "published_date": "2026-01-04 04:39:39 UTC",
      "updated_date": "2026-01-04 04:39:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T21:40:35.906269+00:00"
    },
    {
      "arxiv_id": "2601.01363v1",
      "title": "A unified multimodal understanding and generation model for cross-disciplinary scientific research",
      "title_zh": "面向跨学科科学研究的统一多模态理解与生成模型",
      "authors": [
        "Xiaomeng Yang",
        "Zhiyu Tan",
        "Xiaohui Zhong",
        "Mengping Yang",
        "Qiusheng Huang",
        "Lei Chen",
        "Libo Wu",
        "Hao Li"
      ],
      "abstract": "Scientific discovery increasingly relies on integrating heterogeneous, high-dimensional data across disciplines nowadays. While AI models have achieved notable success across various scientific domains, they typically remain domain-specific or lack the capability of simultaneously understanding and generating multimodal scientific data, particularly for high-dimensional data. Yet, many pressing global challenges and scientific problems are inherently cross-disciplinary and require coordinated progress across multiple fields. Here, we present FuXi-Uni, a native unified multimodal model for scientific understanding and high-fidelity generation across scientific domains within a single architecture. Specifically, FuXi-Uni aligns cross-disciplinary scientific tokens within natural language tokens and employs science decoder to reconstruct scientific tokens, thereby supporting both natural language conversation and scientific numerical prediction. Empirically, we validate FuXi-Uni in Earth science and Biomedicine. In Earth system modeling, the model supports global weather forecasting, tropical cyclone (TC) forecast editing, and spatial downscaling driven by only language instructions. FuXi-Uni generates 10-day global forecasts at 0.25° resolution that outperform the SOTA physical forecasting system. It shows superior performance for both TC track and intensity prediction relative to the SOTA physical model, and generates high-resolution regional weather fields that surpass standard interpolation baselines. Regarding biomedicine, FuXi-Uni outperforms leading multimodal large language models on multiple biomedical visual question answering benchmarks. By unifying heterogeneous scientific modalities within a native shared latent space while maintaining strong domain-specific performance, FuXi-Uni provides a step forward more general-purpose, multimodal scientific models.",
      "tldr_zh": "该研究提出了FuXi-Uni，这是一个专为跨学科科学研究设计的原生统一多模态模型，旨在克服现有AI模型在处理高维、跨领域科学数据时领域局限性强且缺乏同时理解与生成能力的难题。该架构通过在自然语言tokens中对齐跨学科科学tokens，并结合科学解码器(science decoder)重建科学数据，在单一框架内实现了自然语言对话与科学数值预测的融合。实验在地球科学和生物医学领域进行了验证：在地球系统建模中，该模型仅凭语言指令驱动，其10天全球天气预报结果优于SOTA物理预报系统，并在热带气旋(TC)追踪与强度预测及空间降尺度方面表现卓越。在生物医学领域，FuXi-Uni在多个视觉问答(VQA)基准测试中超越了主流的多模态大语言模型。该模型通过在原生共享潜空间中统一异构科学模态，在保持强大领域性能的同时，为实现更通用的跨学科科学模型迈出了关键一步。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.01363v1",
      "published_date": "2026-01-04 04:31:38 UTC",
      "updated_date": "2026-01-04 04:31:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T21:40:37.191556+00:00"
    },
    {
      "arxiv_id": "2601.06123v1",
      "title": "Latent Space Communication via K-V Cache Alignment",
      "title_zh": "基于 K-V 缓存对齐的潜空间通信",
      "authors": [
        "Lucio M. Dery",
        "Zohar Yahav",
        "Henry Prior",
        "Qixuan Feng",
        "Jiajun Shen",
        "Arthur Szlam"
      ],
      "abstract": "Solving increasingly complex problems with large language models (LLMs) necessitates a move beyond individual models and towards multi-model systems that can effectively collaborate. While text has traditionally served as the medium for inter-model communication, a richer and more efficient exchange is possible if models can access each other's internal states directly. In this paper, we propose learning a shared representation space that aligns the k-v caches of multiple models, creating a high-bandwidth channel for collaboration without altering the underlying pre-trained parameters. We do so by augmenting each model with adapters to translate its state into and out of this shared space. Via a suite of experiments with Gemma-2 models, we demonstrate that this approach not only enables seamless inter-model communication but also improves individual model performance. We also show that the shared space allows for the direct transfer of learned skills, such as soft prompts, between different models. Our work represents a significant step towards a future where models can fluidly share knowledge and capabilities.",
      "tldr_zh": "该研究针对大型语言模型(LLMs)在多模型协作中依赖文本通信导致效率受限的问题，提出了一种通过对齐K-V Cache实现在隐空间(Latent Space)直接通信的方法。该方法通过为模型配置适配器(adapters)，在不修改预训练参数的前提下将模型内部状态映射至一个共享表征空间，从而构建起高带宽的协作通道。基于Gemma-2模型的实验证明，这种通信机制不仅能实现多模型间的无缝协作，还能增强单个模型的性能表现。此外，研究发现该共享空间允许在不同模型间直接迁移如soft prompts等已学习的技能，为实现模型间流动的知识共享与能力互通提供了重要路径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "15 pages, 6 figures, 4 tables",
      "pdf_url": "https://arxiv.org/pdf/2601.06123v1",
      "published_date": "2026-01-04 04:15:25 UTC",
      "updated_date": "2026-01-04 04:15:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T21:40:45.890776+00:00"
    },
    {
      "arxiv_id": "2601.06122v1",
      "title": "COVR:Collaborative Optimization of VLMs and RL Agent for Visual-Based Control",
      "title_zh": "COVR：面向视觉控制的视觉语言模型与强化学习智能体协同优化",
      "authors": [
        "Canming Xia",
        "Peixi Peng",
        "Guang Tan",
        "Zhan Su",
        "Haoran Xu",
        "Zhenxian Liu",
        "Luntong Li"
      ],
      "abstract": "Visual reinforcement learning (RL) suffers from poor sample efficiency due to high-dimensional observations in complex tasks. While existing works have shown that vision-language models (VLMs) can assist RL, they often focus on knowledge distillation from the VLM to RL, overlooking the potential of RL-generated interaction data to enhance the VLM. To address this, we propose COVR, a collaborative optimization framework that enables the mutual enhancement of the VLM and RL policies. Specifically, COVR fine-tunes the VLM with RL-generated data to enhance the semantic reasoning ability consistent with the target task, and uses the enhanced VLM to further guide policy learning via action priors. To improve fine-tuning efficiency, we introduce two key modules: (1) an Exploration-Driven Dynamic Filter module that preserves valuable exploration samples using adaptive thresholds based on the degree of exploration, and (2) a Return-Aware Adaptive Loss Weight module that improves the stability of training by quantifying the inconsistency of sampling actions via return signals of RL. We further design a progressive fine-tuning strategy to reduce resource consumption. Extensive experiments show that COVR achieves strong performance across various challenging visual control tasks.",
      "tldr_zh": "该研究提出了COVR框架，旨在解决视觉强化学习(Visual reinforcement learning)在复杂任务中因高维观测导致的样本效率低下问题。该框架通过协作优化实现了视觉语言模型(VLMs)与强化学习(RL)策略的相互增强，利用RL生成的交互数据微调VLM以提升其语义推理能力，并利用增强后的VLM通过动作先验(action priors)指导策略学习。为了提升微调效率与稳定性，研究引入了探索驱动动态过滤器(Exploration-Driven Dynamic Filter)和回报感知自适应损失权重(Return-Aware Adaptive Loss Weight)两个关键模块，并设计了渐进式微调策略以降低资源消耗。实验结果表明，COVR在多项挑战性的视觉控制任务中均表现优异，证明了VLM与RL协同优化的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "The paper was accepted by the Fortieth AAAI Conference on Artificial Intelligence (AAAI-26)",
      "pdf_url": "https://arxiv.org/pdf/2601.06122v1",
      "published_date": "2026-01-04 03:53:05 UTC",
      "updated_date": "2026-01-04 03:53:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T21:40:47.128043+00:00"
    },
    {
      "arxiv_id": "2601.01352v1",
      "title": "Slot-ID: Identity-Preserving Video Generation from Reference Videos via Slot-Based Temporal Identity Encoding",
      "title_zh": "Slot-ID：基于槽位时序身份编码的参考视频身份保持视频生成",
      "authors": [
        "Yixuan Lai",
        "He Wang",
        "Kun Zhou",
        "Tianjia Shao"
      ],
      "abstract": "Producing prompt-faithful videos that preserve a user-specified identity remains challenging: models need to extrapolate facial dynamics from sparse reference while balancing the tension between identity preservation and motion naturalness. Conditioning on a single image completely ignores the temporal signature, which leads to pose-locked motions, unnatural warping, and \"average\" faces when viewpoints and expressions change. To this end, we introduce an identity-conditioned variant of a diffusion-transformer video generator which uses a short reference video rather than a single portrait. Our key idea is to incorporate the dynamics in the reference. A short clip reveals subject-specific patterns, e.g., how smiles form, across poses and lighting. From this clip, a Sinkhorn-routed encoder learns compact identity tokens that capture characteristic dynamics while remaining pretrained backbone-compatible. Despite adding only lightweight conditioning, the approach consistently improves identity retention under large pose changes and expressive facial behavior, while maintaining prompt faithfulness and visual realism across diverse subjects and prompts.",
      "tldr_zh": "该研究提出了Slot-ID，一种通过Slot-Based Temporal Identity Encoding从参考视频中实现身份保持视频生成的框架。针对单张图像引导下视频生成易出现的动作僵硬、面部失真及无法捕捉动态特征等问题，Slot-ID利用短参考视频来提取特定主体的动态模式，例如微笑的形成过程以及在不同光照下的表现。其核心思想是采用Sinkhorn-routed encoder学习紧凑的identity tokens，这些令牌在捕捉特征动态的同时能与预训练的backbone保持兼容。尽管只增加了轻量级的调节，实验结果证明Slot-ID在大幅度姿态变化和复杂面部表情下显著提升了身份保留能力。该方法不仅增强了生成视频的视觉真实感，还确保了极高的提示词忠实度(prompt faithfulness)，为高质量、个性化的视频合成技术提供了有效的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.01352v1",
      "published_date": "2026-01-04 03:41:55 UTC",
      "updated_date": "2026-01-04 03:41:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T21:41:02.623199+00:00"
    },
    {
      "arxiv_id": "2601.01347v1",
      "title": "From Classification to Generation: An Open-Ended Paradigm for Adverse Drug Reaction Prediction Based on Graph-Motif Feature Fusion",
      "title_zh": "从分类到生成：基于图-基元特征融合的开放式药物不良反应预测范式",
      "authors": [
        "Yuyan Pi",
        "Min Jin",
        "Wentao Xie",
        "Xinhua Liu"
      ],
      "abstract": "Computational biology offers immense potential for reducing the high costs and protracted cycles of new drug development through adverse drug reaction (ADR) prediction. However, current methods remain impeded by drug data scarcity-induced cold-start challenge, closed label sets, and inadequate modeling of label dependencies. Here we propose an open-ended ADR prediction paradigm based on Graph-Motif feature fusion and Multi-Label Generation (GM-MLG). Leveraging molecular structure as an intrinsic and inherent feature, GM-MLG constructs a dual-graph representation architecture spanning the atomic level, the local molecular level (utilizing fine-grained motifs dynamically extracted via the BRICS algorithm combined with additional fragmentation rules), and the global molecular level. Uniquely, GM-MLG pioneers transforming ADR prediction from multi-label classification into Transformer Decoder-based multi-label generation. By treating ADR labels as discrete token sequences, it employs positional embeddings to explicitly capture dependencies and co-occurrence relationships within large-scale label spaces, generating predictions via autoregressive decoding to dynamically expand the prediction space. Experiments demonstrate GM-MLG achieves up to 38% improvement and an average gain of 20%, expanding the prediction space from 200 to over 10,000 types. Furthermore, it elucidates non-linear structure-activity relationships between ADRs and motifs via retrosynthetic motif analysis, providing interpretable and innovative support for systematic risk reduction in drug safety.",
      "tldr_zh": "该研究提出了GM-MLG，一种基于Graph-Motif特征融合和多标签生成(Multi-Label Generation)的开放式不良反应(ADR)预测范式，旨在解决药物研发中数据稀缺导致的冷启动问题及闭合标签集的局限性。GM-MLG构建了一个跨越原子、局部分子（通过BRICS算法动态提取微观motif）和全局分子层面的双图表征架构，以充分挖掘分子结构的内在特征。该模型首创性地将ADR预测从多标签分类任务转变为基于Transformer Decoder的多标签生成任务，通过将标签视为离散Token序列并结合位置嵌入，显式捕捉大规模标签空间内的依赖和共现关系。实验结果显示，GM-MLG在预测性能上最高提升了38%，并将预测空间从200类大幅扩展至10,000多类。此外，该方法通过逆合成motif分析阐明了ADR与基团之间的非线性构效关系，为药物安全领域的风险降低提供了具有可解释性的决策支持。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "34 pages,5 figures",
      "pdf_url": "https://arxiv.org/pdf/2601.01347v1",
      "published_date": "2026-01-04 03:35:41 UTC",
      "updated_date": "2026-01-04 03:35:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T21:41:03.050767+00:00"
    },
    {
      "arxiv_id": "2601.02422v1",
      "title": "Watch Wider and Think Deeper: Collaborative Cross-modal Chain-of-Thought for Complex Visual Reasoning",
      "title_zh": "视野更广，思考更深：面向复杂视觉推理的协作式跨模态思维链",
      "authors": [
        "Wenting Lu",
        "Didi Zhu",
        "Tao Shen",
        "Donglin Zhu",
        "Ayong Ye",
        "Chao Wu"
      ],
      "abstract": "Multi-modal reasoning requires the seamless integration of visual and linguistic cues, yet existing Chain-of-Thought methods suffer from two critical limitations in cross-modal scenarios: (1) over-reliance on single coarse-grained image regions, and (2) semantic fragmentation between successive reasoning steps. To address these issues, we propose the CoCoT (Collaborative Coross-modal Thought) framework, built upon two key innovations: a) Dynamic Multi-Region Grounding to adaptively detect the most relevant image regions based on the question, and b) Relation-Aware Reasoning to enable multi-region collaboration by iteratively aligning visual cues to form a coherent and logical chain of thought. Through this approach, we construct the CoCoT-70K dataset, comprising 74,691 high-quality samples with multi-region annotations and structured reasoning chains. Extensive experiments demonstrate that CoCoT significantly enhances complex visual reasoning, achieving an average accuracy improvement of 15.4% on LLaVA-1.5 and 4.0% on Qwen2-VL across six challenging benchmarks. The data and code are available at: https://github.com/deer-echo/CoCoT.",
      "tldr_zh": "该研究针对多模态推理中存在的单一粗粒度图像区域过度依赖以及推理步骤间语义碎片化的问题，提出了CoCoT（Collaborative Cross-modal Thought）框架。该框架引入了动态多区域定位（Dynamic Multi-Region Grounding）技术，能够根据问题自适应检测多个相关图像区域，并通过关系感知推理（Relation-Aware Reasoning）机制实现多区域协作，迭代对齐视觉线索以构建逻辑连贯的链式思维（Chain-of-Thought）。基于此方法，研究团队构建了包含74,691个高质量样本的CoCoT-70K数据集，每个样本均包含多区域标注和结构化推理链。实验结果表明，CoCoT显著增强了模型的复杂视觉推理能力，在六个挑战性基准测试中使LLaVA-1.5和Qwen2-VL的平均准确率分别提升了15.4%和4.0%。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.02422v1",
      "published_date": "2026-01-04 02:50:55 UTC",
      "updated_date": "2026-01-04 02:50:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T21:42:15.662890+00:00"
    },
    {
      "arxiv_id": "2601.01330v1",
      "title": "Beyond Gemini-3-Pro: Revisiting LLM Routing and Aggregation at Scale",
      "title_zh": "超越 Gemini-3-Pro：大规模大语言模型路由与聚合机制的重新审视",
      "authors": [
        "Shengji Tang",
        "Weihao Lin",
        "Jingqi Ye",
        "Hao Li",
        "Bo Zhang",
        "Shuyue Hu",
        "Tao Chen",
        "Wangli Ouyang",
        "Lei Bai",
        "Peng Ye"
      ],
      "abstract": "Large Language Models (LLMs) have rapidly advanced, with Gemini-3-Pro setting a new performance milestone. In this work, we explore collective intelligence as an alternative to monolithic scaling, and demonstrate that open-source LLMs' collaboration can surpass Gemini-3-Pro. We first revisit LLM routing and aggregation at scale and identify three key bottlenecks: (1) current train-free routers are limited by a query-based paradigm focusing solely on textual similarity; (2) recent aggregation methods remain largely static, failing to select appropriate aggregators for different tasks;(3) the complementarity of routing and aggregation remains underutilized. To address these problems, we introduce JiSi, a novel framework designed to release the full potential of LLMs' collaboration through three innovations: (1) Query-Response Mixed Routing capturing both semantic information and problem difficulty; (2) Support-Set-based Aggregator Selection jointly evaluating the aggregation and domain capacity of aggregators; (3) Adaptive Routing-Aggregation Switch dynamically leveraging the advantages of routing and aggregation. Comprehensive experiments on nine benchmarks demonstrate that JiSi can surpass Gemini-3-Pro with only 47% costs by orchestrating ten open-source LLMs, while outperforming mainstream baselines. It suggests that collective intelligence represents a novel path towards Artificial General Intelligence (AGI).",
      "tldr_zh": "该研究探讨了通过大语言模型(LLMs)的群体智能(collective intelligence)超越单一规模扩张(monolithic scaling)的可能性，旨在利用开源模型协作超越Gemini-3-Pro的性能。作者识别了当前路由与聚合技术在规模化应用中的三大瓶颈，即传统路由器的查询范式局限、静态聚合方法的低效以及两者互补性的利用不足。为此，研究提出了名为JiSi的新型框架，通过Query-Response Mixed Routing捕捉语义信息与问题难度，并利用Support-Set-based Aggregator Selection评估聚合器的领域能力。此外，该框架引入了Adaptive Routing-Aggregation Switch，以动态调度路由与聚合的优势。实验结果显示，JiSi通过编排十个开源LLMs，在九项基准测试中以仅47%的成本超越了Gemini-3-Pro，表现优于现有主流基线模型。该研究表明，群体智能为通往通用人工智能(AGI)提供了一条极具潜力的新路径。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "12 pages",
      "pdf_url": "https://arxiv.org/pdf/2601.01330v1",
      "published_date": "2026-01-04 02:05:52 UTC",
      "updated_date": "2026-01-04 02:05:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T21:41:48.477867+00:00"
    },
    {
      "arxiv_id": "2601.03287v1",
      "title": "Automated Post-Incident Policy Gap Analysis via Threat-Informed Evidence Mapping using Large Language Models",
      "title_zh": "利用大语言模型通过威胁知情证据映射实现自动化事后策略差距分析",
      "authors": [
        "Huan Lin Oh",
        "Jay Yong Jun Jie",
        "Mandy Lee Ling Siu",
        "Jonathan Pan"
      ],
      "abstract": "Cybersecurity post-incident reviews are essential for identifying control failures and improving organisational resilience, yet they remain labour-intensive, time-consuming, and heavily reliant on expert judgment. This paper investigates whether Large Language Models (LLMs) can augment post-incident review workflows by autonomously analysing system evidence and identifying security policy gaps. We present a threat-informed, agentic framework that ingests log data, maps observed behaviours to the MITRE ATT&CK framework, and evaluates organisational security policies for adequacy and compliance. Using a simulated brute-force attack scenario against a Windows OpenSSH service (MITRE ATT&CK T1110), the system leverages GPT-4o for reasoning, LangGraph for multi-agent workflow orchestration, and LlamaIndex for traceable policy retrieval. Experimental results indicate that the LLM-based pipeline can interpret log-derived evidence, identify insufficient or missing policy controls, and generate actionable remediation recommendations with explicit evidence-to-policy traceability. Unlike prior work that treats log analysis and policy validation as isolated tasks, this study integrates both into a unified end-to-end proof-of-concept post-incident review framework. The findings suggest that LLM-assisted analysis has the potential to improve the efficiency, consistency, and auditability of post-incident evaluations, while highlighting the continued need for human oversight in high-stakes cybersecurity decision-making.",
      "tldr_zh": "本研究针对网络安全事后审查（post-incident reviews）中人工成本高、过度依赖专家判断的问题，提出了一种利用大语言模型（LLMs）自动化分析系统证据和识别安全策略差距的威胁知情（threat-informed）智能体框架。该框架结合 GPT-4o 进行推理，利用 LangGraph 进行多智能体工作流编排，并配合 LlamaIndex 实现可追溯的策略检索。系统通过将日志数据中观察到的行为映射到 MITRE ATT&CK 框架，能够有效评估组织安全策略的充分性与合规性。在针对 Windows OpenSSH 服务的暴力破解攻击（MITRE ATT&CK T1110）模拟实验中，该流水线成功解释了日志证据，识别出缺失的策略控制，并生成了具有明确证据到策略可追溯性的修复建议。与以往孤立处理任务的研究不同，本研究将其整合为统一的端到端框架，显著提升了事后评估的效率、一致性和可审计性，同时也指出在高风险网络安全决策中仍需人工监督。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "5 pages, 1 figure. Preprint",
      "pdf_url": "https://arxiv.org/pdf/2601.03287v1",
      "published_date": "2026-01-04 01:39:20 UTC",
      "updated_date": "2026-01-04 01:39:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T21:42:35.566201+00:00"
    },
    {
      "arxiv_id": "2601.01322v1",
      "title": "LinMU: Multimodal Understanding Made Linear",
      "title_zh": "LinMU：线性化多模态理解",
      "authors": [
        "Hongjie Wang",
        "Niraj K. Jha"
      ],
      "abstract": "Modern Vision-Language Models (VLMs) achieve impressive performance but are limited by the quadratic complexity of self-attention, which prevents their deployment on edge devices and makes their understanding of high-resolution images and long-context videos prohibitively expensive. To address this challenge, we introduce LinMU (Linear-complexity Multimodal Understanding), a VLM design that achieves linear complexity without using any quadratic-complexity modules while maintaining the performance of global-attention-based VLMs. LinMU replaces every self-attention layer in the VLM with the M-MATE block: a dual-branch module that combines a bidirectional state-space model for global context (Flex-MA branch) with localized Swin-style window attention (Local-Swin branch) for adjacent correlations. To transform a pre-trained VLM into the LinMU architecture, we propose a three-stage distillation framework that (i) initializes both branches with self-attention weights and trains the Flex-MA branch alone, (ii) unfreezes the Local-Swin branch and fine-tunes it jointly with the Flex-MA branch, and (iii) unfreezes the remaining blocks and fine-tunes them using LoRA adapters, while regressing on hidden states and token-level logits of the frozen VLM teacher. On MMMU, TextVQA, LongVideoBench, Video-MME, and other benchmarks, LinMU matches the performance of teacher models, yet reduces Time-To-First-Token (TTFT) by up to 2.7$\\times$ and improves token throughput by up to 9.0$\\times$ on minute-length videos. Ablations confirm the importance of each distillation stage and the necessity of the two branches of the M-MATE block. The proposed framework demonstrates that state-of-the-art multimodal reasoning can be achieved without quadratic attention, thus opening up avenues for long-context VLMs that can deal with high-resolution images and long videos.",
      "tldr_zh": "该研究针对现代视觉语言模型 (VLMs) 中自注意力机制 (self-attention) 的二次复杂度限制，提出了 LinMU (Linear-complexity Multimodal Understanding) 架构，旨在实现线性复杂度的多模态理解。LinMU 通过 M-MATE 模块替换了所有的自注意力层，该模块结合了用于全局上下文的双向状态空间模型 (Flex-MA branch) 和用于局部相关性的 Swin 风格窗口注意力 (Local-Swin branch)。为了有效地将预训练 VLM 转换为 LinMU 架构，研究者提出了一个三阶段蒸馏框架，利用 LoRA 适配器对教师模型的隐藏状态和 token 级概率进行回归训练。实验结果表明，LinMU 在 MMMU、TextVQA、LongVideoBench 和 Video-MME 等基准测试上均能匹配教师模型的性能。在处理分钟级长视频时，LinMU 将首个 token 的生成时间 (TTFT) 缩短了 2.7 倍，并将 token 吞吐量提升了 9.0 倍。该研究证明了在不依赖二次复杂度注意力机制的情况下，依然可以实现最先进的多模态推理，为处理高分辨率图像和长视频提供了高效的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.MM",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "23 pages, 7 figures",
      "pdf_url": "https://arxiv.org/pdf/2601.01322v1",
      "published_date": "2026-01-04 01:17:36 UTC",
      "updated_date": "2026-01-04 01:17:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T21:42:33.046183+00:00"
    },
    {
      "arxiv_id": "2601.01321v1",
      "title": "Digital Twin AI: Opportunities and Challenges from Large Language Models to World Models",
      "title_zh": "数字孪生AI：从大语言模型到世界模型的机遇与挑战",
      "authors": [
        "Rong Zhou",
        "Dongping Chen",
        "Zihan Jia",
        "Yao Su",
        "Yixin Liu",
        "Yiwen Lu",
        "Dongwei Shi",
        "Yue Huang",
        "Tianyang Xu",
        "Yi Pan",
        "Xinliang Li",
        "Yohannes Abate",
        "Qingyu Chen",
        "Zhengzhong Tu",
        "Yu Yang",
        "Yu Zhang",
        "Qingsong Wen",
        "Gengchen Mai",
        "Sunyang Fu",
        "Jiachen Li",
        "Xuyu Wang",
        "Ziran Wang",
        "Jing Huang",
        "Tianming Liu",
        "Yong Chen",
        "Lichao Sun",
        "Lifang He"
      ],
      "abstract": "Digital twins, as precise digital representations of physical systems, have evolved from passive simulation tools into intelligent and autonomous entities through the integration of artificial intelligence technologies. This paper presents a unified four-stage framework that systematically characterizes AI integration across the digital twin lifecycle, spanning modeling, mirroring, intervention, and autonomous management. By synthesizing existing technologies and practices, we distill a unified four-stage framework that systematically characterizes how AI methodologies are embedded across the digital twin lifecycle: (1) modeling the physical twin through physics-based and physics-informed AI approaches, (2) mirroring the physical system into a digital twin with real-time synchronization, (3) intervening in the physical twin through predictive modeling, anomaly detection, and optimization strategies, and (4) achieving autonomous management through large language models, foundation models, and intelligent agents. We analyze the synergy between physics-based modeling and data-driven learning, highlighting the shift from traditional numerical solvers to physics-informed and foundation models for physical systems. Furthermore, we examine how generative AI technologies, including large language models and generative world models, transform digital twins into proactive and self-improving cognitive systems capable of reasoning, communication, and creative scenario generation. Through a cross-domain review spanning eleven application domains, including healthcare, aerospace, smart manufacturing, robotics, and smart cities, we identify common challenges related to scalability, explainability, and trustworthiness, and outline directions for responsible AI-driven digital twin systems.",
      "tldr_zh": "该研究探讨了人工智能技术如何将数字孪生（Digital Twin）从被动模拟工具转化为智能且自主的实体，并提出了一个涵盖建模（modeling）、镜像（mirroring）、干预（intervention）和自主管理（autonomous management）的统一四阶段框架。文章系统分析了从物理启发式AI（physics-informed AI）到基础模型（foundation models）的技术演进，重点阐述了大语言模型（Large Language Models, LLMs）与生成式世界模型（generative world models）如何赋能数字孪生具备推理、通信及场景生成等前瞻性认知能力。通过对医疗、航空航天、智能制造和智慧城市等11个应用领域的跨学科审查，研究指出了系统在可扩展性、可解释性和可信任性（trustworthiness）方面面临的共性挑战。该论文为构建负责任的AI驱动型数字孪生系统提供了清晰的技术演进路径与未来研究方向。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.01321v1",
      "published_date": "2026-01-04 01:17:09 UTC",
      "updated_date": "2026-01-04 01:17:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T21:41:48.350668+00:00"
    },
    {
      "arxiv_id": "2601.01320v1",
      "title": "Adaptive Hierarchical Evaluation of LLMs and SAST tools for CWE Prediction in Python",
      "title_zh": "针对 Python 中 CWE 预测的 LLM 与 SAST 工具自适应层次化评估",
      "authors": [
        "Muntasir Adnan",
        "Carlos C. N. Kuhn"
      ],
      "abstract": "Large Language Models have become integral to software development, yet they frequently generate vulnerable code. Existing code vulnerability detection benchmarks employ binary classification, lacking the CWE-level specificity required for actionable feedback in iterative correction systems. We present ALPHA (Adaptive Learning via Penalty in Hierarchical Assessment), the first function-level Python benchmark that evaluates both LLMs and SAST tools using hierarchically aware, CWE-specific penalties. ALPHA distinguishes between over-generalisation, over-specification, and lateral errors, reflecting practical differences in diagnostic utility. Evaluating seven LLMs and two SAST tools, we find LLMs substantially outperform SAST, though SAST demonstrates higher precision when detections occur. Critically, prediction consistency varies dramatically across models (8.26%-81.87% agreement), with significant implications for feedback-driven systems. We further outline a pathway for future work incorporating ALPHA penalties into supervised fine-tuning, which could provide principled hierarchy-aware vulnerability detection pending empirical validation.",
      "tldr_zh": "本研究针对 Large Language Models (LLMs) 在生成代码时存在的安全漏洞问题，提出了首个函数级 Python 基准测试框架 ALPHA (Adaptive Learning via Penalty in Hierarchical Assessment)。现有的漏洞检测基准通常采用二元分类，缺乏在迭代纠错系统中提供有效反馈所需的 CWE 粒度特异性。ALPHA 引入了具有层次感知能力的 CWE 特定惩罚机制，能够区分过度泛化(over-generalisation)、过度特化(over-specification)和横向错误(lateral errors)，从而更准确地反映诊断工具的实际效用。通过对七种 LLMs 和两种 Static Analysis Security Testing (SAST) 工具的评估，研究发现 LLMs 在整体性能上显著优于 SAST，但在检测精度方面 SAST 表现更高。实验还揭示了不同模型间预测一致性差异巨大（8.26%-81.87%），这对基于反馈的系统开发具有重要意义。该框架不仅为评估 LLMs 和 SAST 工具提供了新标准，还为未来将层次感知惩罚机制融入监督微调(supervised fine-tuning)以提升漏洞检测能力指明了方向。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.01320v1",
      "published_date": "2026-01-04 01:13:37 UTC",
      "updated_date": "2026-01-04 01:13:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T21:42:08.022638+00:00"
    },
    {
      "arxiv_id": "2601.01315v1",
      "title": "Quantifying Local Strain Field and Deformation in Active Contraction of Bladder Using a Pretrained Transformer Model: A Speckle-Free Approach",
      "title_zh": "基于预训练 Transformer 模型的膀胱主动收缩局部应变场与变形定量分析：一种无散斑方法",
      "authors": [
        "Alireza Asadbeygi",
        "Anne M. Robertson",
        "Yasutaka Tobe",
        "Masoud Zamani",
        "Sean D. Stocker",
        "Paul Watton",
        "Naoki Yoshimura",
        "Simon C Watkins"
      ],
      "abstract": "Accurate quantification of local strain fields during bladder contraction is essential for understanding the biomechanics of bladder micturition, in both health and disease. Conventional digital image correlation (DIC) methods have been successfully applied to various biological tissues; however, this approach requires artificial speckling, which can alter both passive and active properties of the tissue. In this study, we introduce a speckle-free framework for quantifying local strain fields using a state-of-the-art, zero-shot transformer model, CoTracker3. We utilized a custom-designed, portable isotonic biaxial apparatus compatible with multiphoton microscopy (MPM) to demonstrate this approach, successfully tracking natural bladder lumen textures without artificial markers. Benchmark tests validated the method's high pixel accuracy and low strain errors. Our framework effectively captured heterogeneous deformation patterns, despite complex folding and buckling, which conventional DIC often fails to track. Application to in vitro active bladder contractions in four rat specimens (n=4) revealed statistically significant anisotropy (p<0.01), with higher contraction longitudinally compared to circumferentially. Multiphoton microscopy further illustrated and confirmed heterogeneous morphological changes, such as large fold formation during active contraction. This non-invasive approach eliminates speckle-induced artifacts, enabling more physiologically relevant measurements, and has broad applicability for material testing of other biological and engineered systems.",
      "tldr_zh": "该研究提出了一种无需人工散斑(speckle-free)的框架，利用预训练Transformer模型CoTracker3来量化膀胱主动收缩过程中的局部应变场。传统的数字图像相关法(Digital Image Correlation, DIC)由于需要人工标记可能会改变生物组织的物理特性，而该方法通过直接追踪自然组织纹理克服了这一局限。研究团队采用定制的便携式等张双轴装置结合多光子显微镜(Multiphoton Microscopy, MPM)，在复杂折叠和屈曲的情况下依然实现了高精度的非均匀变形捕捉。针对大鼠膀胱样本的实验结果表明，主动收缩表现出显著的各向异性(Anisotropy)，其中纵向收缩程度远高于周向收缩。多光子显微成像进一步证实了收缩期间的形态学变化，这种非侵入性方法为生物和工程系统的材料测试提供了更具生理相关性的测量方案。",
      "categories": [
        "q-bio.TO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "q-bio.TO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.01315v1",
      "published_date": "2026-01-04 00:52:27 UTC",
      "updated_date": "2026-01-04 00:52:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T21:42:11.088079+00:00"
    },
    {
      "arxiv_id": "2601.06121v1",
      "title": "Prompt Engineering for Responsible Generative AI Use in African Education: A Report from a Three-Day Training Series",
      "title_zh": "非洲教育中负责任使用生成式人工智能的提示工程：为期三天的系列培训报告",
      "authors": [
        "Benjamin Quarshie",
        "Vanessa Willemse",
        "Macharious Nabang",
        "Bismark Nyaaba Akanzire",
        "Patrick Kyeremeh",
        "Saeed Maigari",
        "Dorcas Adomina",
        "Ellen Kwarteng",
        "Eric Kojo Majialuwe",
        "Craig Gibbs",
        "Jerry Etornam Kudaya",
        "Sechaba Koma",
        "Matthew Nyaaba Matthew Nyaaba"
      ],
      "abstract": "Generative artificial intelligence (GenAI) tools are increasingly adopted in education, yet many educators lack structured guidance on responsible and context sensitive prompt engineering, particularly in African and other resource constrained settings. This case report documents a three day online professional development programme organised by Generative AI for Education and Research in Africa (GenAI-ERA), designed to strengthen educators and researchers capacity to apply prompt engineering ethically for academic writing, teaching, and research. The programme engaged 468 participants across multiple African countries, including university educators, postgraduate students, and researchers. The training followed a scaffolded progression from foundational prompt design to applied and ethical strategies, including persona guided interactions. Data sources comprised registration surveys, webinar interaction records, facilitator observations, and session transcripts, analysed using descriptive statistics and computationally supported qualitative techniques. Findings indicate that participants increasingly conceptualised prompt engineering as a form of AI literacy requiring ethical awareness, contextual sensitivity, and pedagogical judgement rather than technical skill alone. The case highlights persistent challenges related to access, locally relevant training materials, and institutional support. The report recommends sustained professional development and the integration of prompt literacy into curricula to support responsible GenAI use in African education systems.",
      "tldr_zh": "该研究报告了由Generative AI for Education and Research in Africa (GenAI-ERA)组织的一项为期三天的在线专业发展计划，旨在增强非洲教育工作者和研究人员在教学与科研中负责任地应用提示工程(Prompt Engineering)的能力。该项目吸引了来自多个非洲国家的468名参与者，培训内容涵盖了从基础提示设计到涉及伦理策略和角色引导(persona-guided)的高级交互。通过对调查问卷、会议记录和观察数据的定性与定量分析，研究发现参与者逐渐将提示工程视为一种AI素养(AI literacy)，其核心在于伦理意识、语境敏感性和教学判断，而非单纯的技术技能。尽管存在访问受限和缺乏本土化教材等持续性挑战，该研究仍建议将提示素养(prompt literacy)纳入课程体系并开展持续的专业培训，以推动非洲教育系统中生成式人工智能(GenAI)的负责任应用。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.06121v1",
      "published_date": "2026-01-04 00:18:57 UTC",
      "updated_date": "2026-01-04 00:18:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T21:42:20.953469+00:00"
    }
  ],
  "processing_status": "completed",
  "error": null,
  "raw_papers_fetched": true,
  "papers_count": 70,
  "processed_papers_count": 70,
  "failed_papers_count": 0,
  "llm_backup_calls": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2026-01-26T21:43:29.945480+00:00"
}