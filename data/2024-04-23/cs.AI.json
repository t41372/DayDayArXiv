{
  "date": "2024-04-23",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-04-23 的 arXiv 中文 TLDR 快报！\n\n今天的 arXiv 论文主要聚焦于 AI 模型的创新应用，尤其是大型语言模型 (LLM) 在逻辑推理、医疗诊断、生成任务和图神经网络领域的进展，令人印象深刻的作品包括 PRISM 的临床试验匹配（使用 GPT-4）和 DreamCraft 的文本引导生成，展示了知名学者如 Chitta Baral 和 Julian Togelius 的贡献，这些论文突出了 LLM 的实际潜力，但也暴露了挑战如数据隐私和泛化能力。\n\n以下是今日论文的精选摘要，我优先选取了重要、话题度高或有影响力的文章（如涉及 LLM 推理、医疗 AI 和生成模型），并将相关主题归类讨论。对于其他次要论文，我会简要掠过，以控制篇幅。每个条目列出论文标题（中文 + 英文），并保留核心学术术语，清晰概述主要贡献和发现。\n\n### LLM 逻辑推理与医疗应用\n- **PRISM: Patient Records Interpretation for Semantic Clinical Trial Matching using Large Language Models**（PRISM: 利用大型语言模型的患者记录解释进行语义临床试验匹配）  \n  作者包括 Yanshan Wang 和 Hrituraj Singh。该论文提出使用 GPT-4 和自定义模型 OncoLLM 进行临床试验匹配，通过真实 EHR 数据实现端到端评估。贡献：OncoLLM 在真实数据上匹配医生表现，展示了 LLM 在医疗决策中的潜力，强调了隐私保护和准确性。\n\n- **LogicBench: Towards Systematic Evaluation of Logical Reasoning Ability of Large Language Models**（LogicBench: 面向大型语言模型逻辑推理能力的系统评估）  \n  作者包括 Chitta Baral。该研究构建了 LogicBench 数据集，评估 LLM（如 GPT-4、Llama-2）在 25 种逻辑模式下的推理能力。发现：LLM 在复杂推理和否定任务上表现不佳，但通过链式思考可提升，突显了 LLM 逻辑推理的局限性。\n\n- **Adapting an Artificial Intelligence Sexually Transmitted Diseases Symptom Checker Tool for Mpox Detection: The HeHealth Experience**（适配 AI 性传播疾病症状检查工具用于猴痘检测：HeHealth 的经验）  \n  该论文讨论了使用卷积神经网络改进的 AI 工具在猴痘检测中的应用。贡献：工具准确率达 87%，并提供了数据隐私和泛化建议，展示了 AI 在突发公共卫生事件中的实用价值。\n\n### 生成模型与多模态创新\n- **DreamCraft: Text-Guided Generation of Functional 3D Environments in Minecraft**（DreamCraft: 文本引导的 Minecraft 功能性 3D 环境生成）  \n  作者包括 Julian Togelius。该工作使用量化 Neural Radiance Fields 生成文本驱动的 Minecraft 环境。发现：模型能创建功能性结构（如遵守相邻规则），提升了文本到 3D 生成的灵活性。\n\n- **FlashSpeech: Efficient Zero-Shot Speech Synthesis**（FlashSpeech: 高效的零样本语音合成）  \n  论文提出基于潜在一致性模型的快速语音合成框架。贡献：生成速度比现有方法快 20 倍，同时保持高质量，适用于语音编辑和转换，突出了扩散模型在实时应用中的效率。\n\n- **Mamba3D: Enhancing Local Features for 3D Point Cloud Analysis via State Space Model**（Mamba3D: 通过状态空间模型增强 3D 点云分析的局部特征）  \n  该研究使用 Mamba 模型处理 3D 点云数据。发现：在分类任务上超越 Transformer 模型，证明了状态空间模型在点云分析中的线性复杂度优势。\n\n### 联邦学习与可持续 AI\n- **FedGreen: Carbon-aware Federated Learning with Model Size Adaptation**（FedGreen: 基于模型大小适应的碳感知联邦学习）  \n  作者包括 Jiayu Zhou。该论文优化联邦学习以减少碳排放，通过自适应模型大小和有序 Dropout。贡献：显著降低碳足迹，同时保持精度，强调了 AI 的环境可持续性。\n\n其他论文，如涉及语音识别的 Killkan（Kichwa 语言数据集构建）、图生成模型的 Mamba3D 变体，或强化学习的 PROBS（棋盘游戏算法），等虽有创新，但主题较 niche 或重复，我仅快速提及：这些工作扩展了 AI 在低资源语言、文化模拟和游戏领域的应用，但整体影响力不如上述重点论文。\n\n总之，今天的论文展示了 AI 在医疗、生成和可持续领域的潜力，但也提醒我们注意推理局限和环境影响。继续关注这些进展！",
  "papers": [
    {
      "arxiv_id": "2404.15564v1",
      "title": "Guided AbsoluteGrad: Magnitude of Gradients Matters to Explanation's Localization and Saliency",
      "title_zh": "Guided AbsoluteGrad：梯度的幅度对解释的定位和显著性至关",
      "authors": [
        "Jun Huang",
        "Yan Liu"
      ],
      "abstract": "This paper proposes a new gradient-based XAI method called Guided\nAbsoluteGrad for saliency map explanations. We utilize both positive and\nnegative gradient magnitudes and employ gradient variance to distinguish the\nimportant areas for noise deduction. We also introduce a novel evaluation\nmetric named ReCover And Predict (RCAP), which considers the Localization and\nVisual Noise Level objectives of the explanations. We propose two propositions\nfor these two objectives and prove the necessity of evaluating them. We\nevaluate Guided AbsoluteGrad with seven gradient-based XAI methods using the\nRCAP metric and other SOTA metrics in three case studies: (1) ImageNet dataset\nwith ResNet50 model; (2) International Skin Imaging Collaboration (ISIC)\ndataset with EfficientNet model; (3) the Places365 dataset with DenseNet161\nmodel. Our method surpasses other gradient-based approaches, showcasing the\nquality of enhanced saliency map explanations through gradient magnitude.",
      "tldr_zh": "本研究提出了一种新的梯度-based XAI 方法，名为 Guided AbsoluteGrad，用于生成 saliency map 解释，通过利用正负梯度幅度和梯度方差来识别重要区域并减少噪声，从而提升解释的定位准确性和显著性。论文引入了一个新评价指标 RCAP（ReCover And Predict），它同时考虑解释的定位和视觉噪声水平，并证明了评估这些目标的必要性。研究者通过三个案例研究（包括 ImageNet 与 ResNet50、ISIC 与 EfficientNet、Places365 与 DenseNet161）比较了七种梯度-based XAI 方法，结果显示 Guided AbsoluteGrad 在所有指标上超过了其他方法，突显了梯度幅度在解释质量中的关键作用。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "CAI2024 Camera-ready Submission",
      "pdf_url": "http://arxiv.org/pdf/2404.15564v1",
      "published_date": "2024-04-23 23:26:02 UTC",
      "updated_date": "2024-04-23 23:26:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:44:52.085036"
    },
    {
      "arxiv_id": "2404.16885v1",
      "title": "Adapting an Artificial Intelligence Sexually Transmitted Diseases Symptom Checker Tool for Mpox Detection: The HeHealth Experience",
      "title_zh": "翻译失败",
      "authors": [
        "Rayner Kay Jin Tan",
        "Dilruk Perera",
        "Salomi Arasaratnam",
        "Yudara Kularathne"
      ],
      "abstract": "Artificial Intelligence applications have shown promise in the management of\npandemics and have been widely used to assist the identification,\nclassification, and diagnosis of medical images. In response to the global\noutbreak of Monkeypox (Mpox), the HeHealth.ai team leveraged an existing tool\nto screen for sexually transmitted diseases to develop a digital screening test\nfor symptomatic Mpox through AI approaches. Prior to the global outbreak of\nMpox, the team developed a smartphone app, where app users can use their own\nsmartphone cameras to take pictures of their own penises to screen for\nsymptomatic STD. The AI model was initially developed using 5000 cases and use\na modified convolutional neural network to output prediction scores across\nvisually diagnosable penis pathologies including Syphilis, Herpes Simplex\nVirus, and Human Papilloma Virus. From June 2022 to October 2022, a total of\nabout 22,000 users downloaded the HeHealth app, and about 21,000 images have\nbeen analyzed using HeHealth AI technology. We then engaged in formative\nresearch, stakeholder engagement, rapid consolidation images, a validation\nstudy, and implementation of the tool from July 2022. From July 2022 to October\n2022, a total of 1000 Mpox related images had been used to train the Mpox\nsymptom checker tool. Our digital symptom checker tool showed accuracy of 87%\nto rule in Mpox and 90% to rule out symptomatic Mpox. Several hurdles\nidentified included issues of data privacy and security for app users, initial\nlack of data to train the AI tool, and the potential generalizability of input\ndata. We offer several suggestions to help others get started on similar\nprojects in emergency situations, including engaging a wide range of\nstakeholders, having a multidisciplinary team, prioritizing pragmatism, as well\nas the concept that big data in fact is made up of small data.",
      "tldr_zh": "HeHealth.ai 团队将现有的 Artificial Intelligence 性病症状检查工具适应用于 Mpox 检测，通过修改卷积神经网络(convolutional neural network)并利用智能手机图像进行训练，该工具最初基于 5000 个病例开发，后添加 1000 张 Mpox 相关图像以提升准确性。结果显示，该数字筛查工具在确认 Mpox 时准确率达 87%，排除时达 90%。论文还讨论了数据隐私和安全、数据不足以及输入数据泛化性的挑战，并建议在类似紧急项目中强调多利益相关者参与、多学科团队合作和注重实用性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "15 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.16885v1",
      "published_date": "2024-04-23 23:14:30 UTC",
      "updated_date": "2024-04-23 23:14:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:45:05.669719"
    },
    {
      "arxiv_id": "2404.15549v2",
      "title": "PRISM: Patient Records Interpretation for Semantic Clinical Trial Matching using Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Shashi Kant Gupta",
        "Aditya Basu",
        "Mauro Nievas",
        "Jerrin Thomas",
        "Nathan Wolfrath",
        "Adhitya Ramamurthi",
        "Bradley Taylor",
        "Anai N. Kothari",
        "Regina Schwind",
        "Therica M. Miller",
        "Sorena Nadaf-Rahrov",
        "Yanshan Wang",
        "Hrituraj Singh"
      ],
      "abstract": "Clinical trial matching is the task of identifying trials for which patients\nmay be potentially eligible. Typically, this task is labor-intensive and\nrequires detailed verification of patient electronic health records (EHRs)\nagainst the stringent inclusion and exclusion criteria of clinical trials. This\nprocess is manual, time-intensive, and challenging to scale up, resulting in\nmany patients missing out on potential therapeutic options. Recent advancements\nin Large Language Models (LLMs) have made automating patient-trial matching\npossible, as shown in multiple concurrent research studies. However, the\ncurrent approaches are confined to constrained, often synthetic datasets that\ndo not adequately mirror the complexities encountered in real-world medical\ndata. In this study, we present the first, end-to-end large-scale empirical\nevaluation of clinical trial matching using real-world EHRs. Our study\nshowcases the capability of LLMs to accurately match patients with appropriate\nclinical trials. We perform experiments with proprietary LLMs, including GPT-4\nand GPT-3.5, as well as our custom fine-tuned model called OncoLLM and show\nthat OncoLLM, despite its significantly smaller size, not only outperforms\nGPT-3.5 but also matches the performance of qualified medical doctors. All\nexperiments were carried out on real-world EHRs that include clinical notes and\navailable clinical trials from a single cancer center in the United States.",
      "tldr_zh": "本研究提出PRISM框架，利用Large Language Models (LLMs) 自动匹配患者电子健康记录 (EHRs) 与临床试验的语义标准，以解决传统手动匹配耗时且低效的问题。研究首次进行大规模实证评估，使用真实世界EHRs和美国一家癌症中心的临床试验数据，实验涉及GPT-4、GPT-3.5以及自定义微调模型OncoLLM。结果显示，OncoLLM尽管模型规模较小，却超过了GPT-3.5的表现，并达到了合格医生的水平，为临床试验匹配的自动化和可扩展性提供了重要进展。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "30 Pages, 8 Figures, Supplementary Work Attached",
      "pdf_url": "http://arxiv.org/pdf/2404.15549v2",
      "published_date": "2024-04-23 22:33:19 UTC",
      "updated_date": "2024-04-27 03:10:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:45:14.959989"
    },
    {
      "arxiv_id": "2404.16074v1",
      "title": "Explaining AI Decisions: Towards Achieving Human-Centered Explainability in Smart Home Environments",
      "title_zh": "解释 AI 决策：朝着在智能家居环境中实现以人为本的可解释性",
      "authors": [
        "Md Shajalal",
        "Alexander Boden",
        "Gunnar Stevens",
        "Delong Du",
        "Dean-Robin Kern"
      ],
      "abstract": "Smart home systems are gaining popularity as homeowners strive to enhance\ntheir living and working environments while minimizing energy consumption.\nHowever, the adoption of artificial intelligence (AI)-enabled decision-making\nmodels in smart home systems faces challenges due to the complexity and\nblack-box nature of these systems, leading to concerns about explainability,\ntrust, transparency, accountability, and fairness. The emerging field of\nexplainable artificial intelligence (XAI) addresses these issues by providing\nexplanations for the models' decisions and actions. While state-of-the-art XAI\nmethods are beneficial for AI developers and practitioners, they may not be\neasily understood by general users, particularly household members. This paper\nadvocates for human-centered XAI methods, emphasizing the importance of\ndelivering readily comprehensible explanations to enhance user satisfaction and\ndrive the adoption of smart home systems. We review state-of-the-art XAI\nmethods and prior studies focusing on human-centered explanations for general\nusers in the context of smart home applications. Through experiments on two\nsmart home application scenarios, we demonstrate that explanations generated by\nprominent XAI techniques might not be effective in helping users understand and\nmake decisions. We thus argue for the necessity of a human-centric approach in\nrepresenting explanations in smart home systems and highlight relevant\nhuman-computer interaction (HCI) methodologies, including user studies,\nprototyping, technology probes analysis, and heuristic evaluation, that can be\nemployed to generate and present human-centered explanations to users.",
      "tldr_zh": "这篇论文探讨了智能家居系统中AI决策的黑箱性质带来的可解释性、信任和公平性挑战，强调了以人为本的XAI（Explainable Artificial Intelligence）方法的重要性，以提供易懂的解释并提升用户满意度。作者审阅了现有XAI技术，并通过两个智能家居应用场景的实验，证明这些解释可能无法有效帮助普通用户理解和决策。论文主张采用HCI（Human-Computer Interaction）方法，如用户研究、原型设计和技术评估，来开发更人性化的解释，从而推动智能家居系统的广泛采用。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "This is the pre-print version of our accepted paper at the 2nd World\n  Conference on eXplainable Artificial Intelligence (xAI2024), which will be\n  held in Valletta, Malta in 17-19 July, 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.16074v1",
      "published_date": "2024-04-23 22:31:42 UTC",
      "updated_date": "2024-04-23 22:31:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:45:27.822961"
    },
    {
      "arxiv_id": "2404.15538v1",
      "title": "DreamCraft: Text-Guided Generation of Functional 3D Environments in Minecraft",
      "title_zh": "DreamCraft：文本引导的功能性 3D 环境生成于 Minecraft",
      "authors": [
        "Sam Earle",
        "Filippos Kokkinos",
        "Yuhe Nie",
        "Julian Togelius",
        "Roberta Raileanu"
      ],
      "abstract": "Procedural Content Generation (PCG) algorithms enable the automatic\ngeneration of complex and diverse artifacts. However, they don't provide\nhigh-level control over the generated content and typically require domain\nexpertise. In contrast, text-to-3D methods allow users to specify desired\ncharacteristics in natural language, offering a high amount of flexibility and\nexpressivity. But unlike PCG, such approaches cannot guarantee functionality,\nwhich is crucial for certain applications like game design. In this paper, we\npresent a method for generating functional 3D artifacts from free-form text\nprompts in the open-world game Minecraft. Our method, DreamCraft, trains\nquantized Neural Radiance Fields (NeRFs) to represent artifacts that, when\nviewed in-game, match given text descriptions. We find that DreamCraft produces\nmore aligned in-game artifacts than a baseline that post-processes the output\nof an unconstrained NeRF. Thanks to the quantized representation of the\nenvironment, functional constraints can be integrated using specialized loss\nterms. We show how this can be leveraged to generate 3D structures that match a\ntarget distribution or obey certain adjacency rules over the block types.\nDreamCraft inherits a high degree of expressivity and controllability from the\nNeRF, while still being able to incorporate functional constraints through\ndomain-specific objectives.",
      "tldr_zh": "本文提出DreamCraft方法，通过文本指导在Minecraft中生成功能性3D环境，解决了Procedural Content Generation (PCG)缺乏高层控制和text-to-3D方法无法保证功能性的问题。该方法训练quantized Neural Radiance Fields (NeRFs)来表示工件，使其在游戏中匹配自由文本描述，并通过专门的loss terms整合功能约束，如块类型目标分布和邻接规则。与基线模型相比，DreamCraft生成更精确的游戏内工件，实现了NeRF的高表达性与功能性约束的结合。",
      "categories": [
        "cs.GR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.GR",
      "comment": "16 pages, 9 figures, accepted to Foundation of Digital Games 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.15538v1",
      "published_date": "2024-04-23 21:57:14 UTC",
      "updated_date": "2024-04-23 21:57:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:45:40.242052"
    },
    {
      "arxiv_id": "2407.05205v1",
      "title": "The AI Companion in Education: Analyzing the Pedagogical Potential of ChatGPT in Computer Science and Engineering",
      "title_zh": "翻译失败",
      "authors": [
        "Zhangying He",
        "Thomas Nguyen",
        "Tahereh Miari",
        "Mehrdad Aliasgari",
        "Setareh Rafatirad",
        "Hossein Sayadi"
      ],
      "abstract": "Artificial Intelligence (AI), with ChatGPT as a prominent example, has\nrecently taken center stage in various domains including higher education,\nparticularly in Computer Science and Engineering (CSE). The AI revolution\nbrings both convenience and controversy, offering substantial benefits while\nlacking formal guidance on their application. The primary objective of this\nwork is to comprehensively analyze the pedagogical potential of ChatGPT in CSE\neducation, understanding its strengths and limitations from the perspectives of\neducators and learners. We employ a systematic approach, creating a diverse\nrange of educational practice problems within CSE field, focusing on various\nsubjects such as data science, programming, AI, machine learning, networks, and\nmore. According to our examinations, certain question types, like conceptual\nknowledge queries, typically do not pose significant challenges to ChatGPT, and\nthus, are excluded from our analysis. Alternatively, we focus our efforts on\ndeveloping more in-depth and personalized questions and project-based tasks.\nThese questions are presented to ChatGPT, followed by interactions to assess\nits effectiveness in delivering complete and meaningful responses. To this end,\nwe propose a comprehensive five-factor reliability analysis framework to\nevaluate the responses. This assessment aims to identify when ChatGPT excels\nand when it faces challenges. Our study concludes with a correlation analysis,\ndelving into the relationships among subjects, task types, and limiting\nfactors. This analysis offers valuable insights to enhance ChatGPT's utility in\nCSE education, providing guidance to educators and students regarding its\nreliability and efficacy.",
      "tldr_zh": "这篇论文分析了 ChatGPT 在计算机科学和工程 (CSE) 教育中的教育潜力，探讨其优势和局限性，从教育者和学习者的视角出发。研究采用系统方法，创建多样化的深入问题和项目任务（如数据科学、编程、AI 和机器学习等主题），并使用五因素可靠性分析框架评估 ChatGPT 的响应质量。最终，通过相关性分析，论文揭示了主题、任务类型与限制因素之间的关系，提供指导性见解，帮助教育者与学生更有效地利用 ChatGPT。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "conference, 13 pages",
      "pdf_url": "http://arxiv.org/pdf/2407.05205v1",
      "published_date": "2024-04-23 21:42:30 UTC",
      "updated_date": "2024-04-23 21:42:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:45:50.944877"
    },
    {
      "arxiv_id": "2404.15532v1",
      "title": "BattleAgent: Multi-modal Dynamic Emulation on Historical Battles to Complement Historical Analysis",
      "title_zh": "BattleAgent：多模态动态仿真历史战役以补充历史分析",
      "authors": [
        "Shuhang Lin",
        "Wenyue Hua",
        "Lingyao Li",
        "Che-Jui Chang",
        "Lizhou Fan",
        "Jianchao Ji",
        "Hang Hua",
        "Mingyu Jin",
        "Jiebo Luo",
        "Yongfeng Zhang"
      ],
      "abstract": "This paper presents BattleAgent, an emulation system that combines the Large\nVision-Language Model and Multi-agent System. This novel system aims to\nsimulate complex dynamic interactions among multiple agents, as well as between\nagents and their environments, over a period of time. It emulates both the\ndecision-making processes of leaders and the viewpoints of ordinary\nparticipants, such as soldiers. The emulation showcases the current\ncapabilities of agents, featuring fine-grained multi-modal interactions between\nagents and landscapes. It develops customizable agent structures to meet\nspecific situational requirements, for example, a variety of battle-related\nactivities like scouting and trench digging. These components collaborate to\nrecreate historical events in a lively and comprehensive manner while offering\ninsights into the thoughts and feelings of individuals from diverse viewpoints.\nThe technological foundations of BattleAgent establish detailed and immersive\nsettings for historical battles, enabling individual agents to partake in,\nobserve, and dynamically respond to evolving battle scenarios. This methodology\nholds the potential to substantially deepen our understanding of historical\nevents, particularly through individual accounts. Such initiatives can also aid\nhistorical research, as conventional historical narratives often lack\ndocumentation and prioritize the perspectives of decision-makers, thereby\noverlooking the experiences of ordinary individuals. BattelAgent illustrates\nAI's potential to revitalize the human aspect in crucial social events, thereby\nfostering a more nuanced collective understanding and driving the progressive\ndevelopment of human society.",
      "tldr_zh": "本文提出 BattleAgent 系统，该系统结合 Large Vision-Language Model 和 Multi-agent System，模拟历史战役中的多代理动态互动，包括领导者的决策过程和普通参与者（如士兵）的观点。BattleAgent 通过细粒度的 Multi-modal 互动和可定制代理结构（如侦察或挖战壕），重现生动全面的历史场景，并提供不同视角的见解。实验表明，该方法能加深对历史事件的理解，尤其是普通个体的经历，从而辅助历史研究并展示 AI 在提升社会认知方面的潜力。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.MA"
      ],
      "primary_category": "cs.HC",
      "comment": "26 pages, 14 figures The data and code for this project are\n  accessible at https://github.com/agiresearch/battleagent",
      "pdf_url": "http://arxiv.org/pdf/2404.15532v1",
      "published_date": "2024-04-23 21:37:22 UTC",
      "updated_date": "2024-04-23 21:37:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:46:03.555770"
    },
    {
      "arxiv_id": "2404.15522v2",
      "title": "LogicBench: Towards Systematic Evaluation of Logical Reasoning Ability of Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Mihir Parmar",
        "Nisarg Patel",
        "Neeraj Varshney",
        "Mutsumi Nakamura",
        "Man Luo",
        "Santosh Mashetty",
        "Arindam Mitra",
        "Chitta Baral"
      ],
      "abstract": "Recently developed large language models (LLMs) have been shown to perform\nremarkably well on a wide range of language understanding tasks. But, can they\nreally \"reason\" over the natural language? This question has been receiving\nsignificant research attention and many reasoning skills such as commonsense,\nnumerical, and qualitative have been studied. However, the crucial skill\npertaining to 'logical reasoning' has remained underexplored. Existing work\ninvestigating this reasoning ability of LLMs has focused only on a couple of\ninference rules (such as modus ponens and modus tollens) of propositional and\nfirst-order logic. Addressing the above limitation, we comprehensively evaluate\nthe logical reasoning ability of LLMs on 25 different reasoning patterns\nspanning over propositional, first-order, and non-monotonic logics. To enable\nsystematic evaluation, we introduce LogicBench, a natural language\nquestion-answering dataset focusing on the use of a single inference rule. We\nconduct detailed analysis with a range of LLMs such as GPT-4, ChatGPT, Gemini,\nLlama-2, and Mistral using chain-of-thought prompting. Experimental results\nshow that existing LLMs do not fare well on LogicBench; especially, they\nstruggle with instances involving complex reasoning and negations. Furthermore,\nthey sometimes overlook contextual information necessary for reasoning to\narrive at the correct conclusion. We believe that our work and findings\nfacilitate future research for evaluating and enhancing the logical reasoning\nability of LLMs. Data and code are available at\nhttps://github.com/Mihir3009/LogicBench.",
      "tldr_zh": "该论文引入了 LogicBench，这是一个专注于评估大型语言模型 (LLMs) 逻辑推理能力的自然语言问答数据集，涵盖了 25 种推理模式，包括命题逻辑、一阶逻辑和非单调逻辑。研究者使用 chain-of-thought prompting 方法，对 GPT-4、ChatGPT、Gemini、Llama-2 和 Mistral 等模型进行系统评估。实验结果显示，现有的 LLMs 在处理复杂推理和否定实例时表现较差，且经常忽略必要的上下文信息，导致准确性不足。该工作旨在促进未来对 LLMs 逻辑推理能力的评估和提升，并提供了数据集和代码以支持进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at ACL(Main) 2024 | First version available @\n  https://openreview.net/forum?id=7NR2ZVzZxx",
      "pdf_url": "http://arxiv.org/pdf/2404.15522v2",
      "published_date": "2024-04-23 21:08:49 UTC",
      "updated_date": "2024-06-06 08:15:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:46:16.217079"
    },
    {
      "arxiv_id": "2404.15518v3",
      "title": "An MRP Formulation for Supervised Learning: Generalized Temporal Difference Learning Models",
      "title_zh": "一种 MRP 公式化用于监督学习：广义的时间差分学习模型",
      "authors": [
        "Yangchen Pan",
        "Junfeng Wen",
        "Chenjun Xiao",
        "Philip Torr"
      ],
      "abstract": "In traditional statistical learning, data points are usually assumed to be\nindependently and identically distributed (i.i.d.) following an unknown\nprobability distribution. This paper presents a contrasting viewpoint,\nperceiving data points as interconnected and employing a Markov reward process\n(MRP) for data modeling. We reformulate the typical supervised learning as an\non-policy policy evaluation problem within reinforcement learning (RL),\nintroducing a generalized temporal difference (TD) learning algorithm as a\nresolution. Theoretically, our analysis draws connections between the solutions\nof linear TD learning and ordinary least squares (OLS). We also show that under\nspecific conditions, particularly when noises are correlated, the TD's solution\nproves to be a more effective estimator than OLS. Furthermore, we establish the\nconvergence of our generalized TD algorithms under linear function\napproximation. Empirical studies verify our theoretical results, examine the\nvital design of our TD algorithm and show practical utility across various\ndatasets, encompassing tasks such as regression and image classification with\ndeep learning.",
      "tldr_zh": "本论文提出了一种新视角，将传统监督学习中的数据点视为相互连接的马尔可夫奖励过程 (MRP)，并将其重新表述为强化学习 (RL) 中的 on-policy 策略评估问题，从而引入广义的时差学习 (TD) 算法作为解决方案。理论分析显示，TD 学习与普通最小二乘 (OLS) 存在联系，并在噪声相关条件下提供更有效的估计，同时证明了该算法在线性函数逼近下的收敛性。实验结果验证了这些理论发现，并在回归和图像分类等任务上展示了该方法的实际实用性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.15518v3",
      "published_date": "2024-04-23 21:02:58 UTC",
      "updated_date": "2024-07-16 18:53:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:46:26.491315"
    },
    {
      "arxiv_id": "2404.15516v1",
      "title": "Visual Delta Generator with Large Multi-modal Models for Semi-supervised Composed Image Retrieval",
      "title_zh": "基于",
      "authors": [
        "Young Kyun Jang",
        "Donghyun Kim",
        "Zihang Meng",
        "Dat Huynh",
        "Ser-Nam Lim"
      ],
      "abstract": "Composed Image Retrieval (CIR) is a task that retrieves images similar to a\nquery, based on a provided textual modification. Current techniques rely on\nsupervised learning for CIR models using labeled triplets of the reference\nimage, text, target image. These specific triplets are not as commonly\navailable as simple image-text pairs, limiting the widespread use of CIR and\nits scalability. On the other hand, zero-shot CIR can be relatively easily\ntrained with image-caption pairs without considering the image-to-image\nrelation, but this approach tends to yield lower accuracy. We propose a new\nsemi-supervised CIR approach where we search for a reference and its related\ntarget images in auxiliary data and learn our large language model-based Visual\nDelta Generator (VDG) to generate text describing the visual difference (i.e.,\nvisual delta) between the two. VDG, equipped with fluent language knowledge and\nbeing model agnostic, can generate pseudo triplets to boost the performance of\nCIR models. Our approach significantly improves the existing supervised\nlearning approaches and achieves state-of-the-art results on the CIR\nbenchmarks.",
      "tldr_zh": "该论文针对 Composed Image Retrieval (CIR) 任务提出了一种半监督方法，以解决传统监督学习依赖稀缺的三元组数据（参考图像、文本、目标图像）的问题。作者开发了基于大型多模态模型的 Visual Delta Generator (VDG)，该模型通过搜索辅助数据并生成描述图像间视觉差异（visual delta）的文本，从而创建伪三元组来提升 CIR 模型的性能。与现有方法相比，该方法显著提高了准确率，并在 CIR 基准测试中达到了最先进的结果。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "15 pages",
      "pdf_url": "http://arxiv.org/pdf/2404.15516v1",
      "published_date": "2024-04-23 21:00:22 UTC",
      "updated_date": "2024-04-23 21:00:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:46:38.948965"
    },
    {
      "arxiv_id": "2404.15515v3",
      "title": "ToM-LM: Delegating Theory of Mind Reasoning to External Symbolic Executors in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Weizhi Tang",
        "Vaishak Belle"
      ],
      "abstract": "Theory of Mind (ToM) refers to the ability of individuals to attribute mental\nstates to others. While Large Language Models (LLMs) have shown some promise\nwith ToM ability, they still struggle with complex ToM reasoning. Our approach\nleverages an external symbolic executor, specifically the SMCDEL model checker,\nand fine-tuning to improve the ToM reasoning ability of LLMs. In our approach,\nan LLM is first fine-tuned through pairs of natural language and symbolic\nformulation representation of ToM problems and is then instructed to generate\nthe symbolic formulation with a one-shot in-context example. The generated\nsymbolic formulation is then executed by the SMCDEL model checker to perform\ntransparent and verifiable ToM reasoning and give the final result. We\ndemonstrate that our approach, ToM-LM, shows a significant improvement over all\nthe constructed baselines. Our study proposes a novel view about externalizing\na particular component of ToM reasoning, mainly reasoning about beliefs, and\nsuggests generalizing it to other aspects of ToM reasoning.",
      "tldr_zh": "该研究提出 ToM-LM 方法，通过将 Theory of Mind (ToM) 推理委托给外部符号执行器（如 SMCDEL 模型检查器）来提升 Large Language Models (LLMs) 的 ToM 推理能力。方法包括先对 LLM 进行 fine-tuning，使其将自然语言的 ToM 问题转化为符号表述，然后使用 SMCDEL 执行透明、可验证的推理过程。实验结果显示，ToM-LM 显著优于基线模型，在处理复杂 ToM 任务时表现出色。该方法还建议将这种外部化策略推广到 ToM 推理的其他方面，如信念推理，提供了一种新型的模块化推理框架。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at NeSy 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.15515v3",
      "published_date": "2024-04-23 20:59:03 UTC",
      "updated_date": "2024-06-26 15:57:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:46:52.827247"
    },
    {
      "arxiv_id": "2405.02327v2",
      "title": "CausalLP: Learning causal relations with weighted knowledge graph link prediction",
      "title_zh": "CausalLP：通过加权知识图谱链接预测学习因果关系",
      "authors": [
        "Utkarshani Jaimini",
        "Cory Henson",
        "Amit P. Sheth"
      ],
      "abstract": "Causal networks are useful in a wide variety of applications, from medical\ndiagnosis to root-cause analysis in manufacturing. In practice, however, causal\nnetworks are often incomplete with missing causal relations. This paper\npresents a novel approach, called CausalLP, that formulates the issue of\nincomplete causal networks as a knowledge graph completion problem. More\nspecifically, the task of finding new causal relations in an incomplete causal\nnetwork is mapped to the task of knowledge graph link prediction. The use of\nknowledge graphs to represent causal relations enables the integration of\nexternal domain knowledge; and as an added complexity, the causal relations\nhave weights representing the strength of the causal association between\nentities in the knowledge graph. Two primary tasks are supported by CausalLP:\ncausal explanation and causal prediction. An evaluation of this approach uses a\nbenchmark dataset of simulated videos for causal reasoning, CLEVRER-Humans, and\ncompares the performance of multiple knowledge graph embedding algorithms. Two\ndistinct dataset splitting approaches are used for evaluation: (1) random-based\nsplit, which is the method typically employed to evaluate link prediction\nalgorithms, and (2) Markov-based split, a novel data split technique that\nutilizes the Markovian property of causal relations. Results show that using\nweighted causal relations improves causal link prediction over the baseline\nwithout weighted relations.",
      "tldr_zh": "本论文提出CausalLP方法，将不完整的因果网络问题转化为知识图谱（knowledge graph）完成任务，旨在通过知识图谱链接预测（link prediction）学习新的因果关系，并整合外部领域知识。CausalLP处理加权因果关系（weighted causal relations），其中权重表示实体间因果关联的强度，支持因果解释和因果预测两大任务。实验使用CLEVRER-Humans基准数据集，比较多种知识图谱嵌入算法，并采用随机-based split和Markov-based split评估，结果显示加权关系显著提升了因果链接预测性能，比基线模型表现更好。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "9 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.02327v2",
      "published_date": "2024-04-23 20:50:06 UTC",
      "updated_date": "2024-07-12 11:11:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:47:05.494145"
    },
    {
      "arxiv_id": "2404.15503v1",
      "title": "FedGreen: Carbon-aware Federated Learning with Model Size Adaptation",
      "title_zh": "FedGreen：",
      "authors": [
        "Ali Abbasi",
        "Fan Dong",
        "Xin Wang",
        "Henry Leung",
        "Jiayu Zhou",
        "Steve Drew"
      ],
      "abstract": "Federated learning (FL) provides a promising collaborative framework to build\na model from distributed clients, and this work investigates the carbon\nemission of the FL process. Cloud and edge servers hosting FL clients may\nexhibit diverse carbon footprints influenced by their geographical locations\nwith varying power sources, offering opportunities to reduce carbon emissions\nby training local models with adaptive computations and communications. In this\npaper, we propose FedGreen, a carbon-aware FL approach to efficiently train\nmodels by adopting adaptive model sizes shared with clients based on their\ncarbon profiles and locations using ordered dropout as a model compression\ntechnique. We theoretically analyze the trade-offs between the produced carbon\nemissions and the convergence accuracy, considering the carbon intensity\ndiscrepancy across countries to choose the parameters optimally. Empirical\nstudies show that FedGreen can substantially reduce the carbon footprints of FL\ncompared to the state-of-the-art while maintaining competitive model accuracy.",
      "tldr_zh": "这篇论文提出FedGreen，一种碳感知的Federated Learning (FL) 方法，通过根据客户端的碳配置文件和地理位置自适应调整模型大小，并采用ordered dropout作为模型压缩技术，来减少FL过程中的碳排放。研究理论分析了碳排放与模型收敛准确率之间的权衡，考虑不同国家碳强度差异来优化参数设置。实证实验显示，FedGreen相较于现有技术显著降低碳足迹，同时保持竞争性的模型准确率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.15503v1",
      "published_date": "2024-04-23 20:37:26 UTC",
      "updated_date": "2024-04-23 20:37:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:47:16.751074"
    },
    {
      "arxiv_id": "2405.00709v1",
      "title": "Evaluating Tool-Augmented Agents in Remote Sensing Platforms",
      "title_zh": "翻译失败",
      "authors": [
        "Simranjit Singh",
        "Michael Fore",
        "Dimitrios Stamoulis"
      ],
      "abstract": "Tool-augmented Large Language Models (LLMs) have shown impressive\ncapabilities in remote sensing (RS) applications. However, existing benchmarks\nassume question-answering input templates over predefined image-text data\npairs. These standalone instructions neglect the intricacies of realistic\nuser-grounded tasks. Consider a geospatial analyst: they zoom in a map area,\nthey draw a region over which to collect satellite imagery, and they succinctly\nask \"Detect all objects here\". Where is `here`, if it is not explicitly\nhardcoded in the image-text template, but instead is implied by the system\nstate, e.g., the live map positioning? To bridge this gap, we present\nGeoLLM-QA, a benchmark designed to capture long sequences of verbal, visual,\nand click-based actions on a real UI platform. Through in-depth evaluation of\nstate-of-the-art LLMs over a diverse set of 1,000 tasks, we offer insights\ntowards stronger agents for RS applications.",
      "tldr_zh": "这篇论文评估了Tool-augmented LLMs在遥感（RS）平台上的表现，指出现有基准测试过于简化，无法捕捉现实用户任务的复杂交互，如地图缩放、区域绘制和简要指令。论文引入了GeoLLM-QA基准，该基准设计捕捉长序列的verbal、visual和click-based动作，并基于真实UI平台进行测试。通过对最先进LLMs在1000个任务上的深入评估，论文提供了增强RS应用中代理能力的宝贵见解。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "ICLR 2024 Machine Learning for Remote Sensing (ML4RS) Workshop",
      "pdf_url": "http://arxiv.org/pdf/2405.00709v1",
      "published_date": "2024-04-23 20:37:24 UTC",
      "updated_date": "2024-04-23 20:37:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:47:29.567065"
    },
    {
      "arxiv_id": "2404.16884v1",
      "title": "Aligning Knowledge Graphs Provided by Humans and Generated from Neural Networks in Specific Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Tangrui Li",
        "Jun Zhou"
      ],
      "abstract": "This paper develops an innovative method that enables neural networks to\ngenerate and utilize knowledge graphs, which describe their concept-level\nknowledge and optimize network parameters through alignment with human-provided\nknowledge. This research addresses a gap where traditionally, network-generated\nknowledge has been limited to applications in downstream symbolic analysis or\nenhancing network transparency. By integrating a novel autoencoder design with\nthe Vector Symbolic Architecture (VSA), we have introduced auxiliary tasks that\nsupport end-to-end training. Our approach eschews traditional dependencies on\nontologies or word embedding models, mining concepts from neural networks and\ndirectly aligning them with human knowledge. Experiments show that our method\nconsistently captures network-generated concepts that align closely with human\nknowledge and can even uncover new, useful concepts not previously identified\nby humans. This plug-and-play strategy not only enhances the interpretability\nof neural networks but also facilitates the integration of symbolic logical\nreasoning within these systems.",
      "tldr_zh": "本研究提出了一种创新方法，让神经网络生成知识图谱并通过与人类提供的知识图谱对齐来优化网络参数，从而提升神经网络在特定任务中的性能。该方法整合了新型自编码器和 Vector Symbolic Architecture (VSA)，引入辅助任务支持端到端训练，并直接从神经网络中挖掘概念，而不依赖传统本体或词嵌入模型。实验结果显示，该方法能准确捕获与人类知识紧密对齐的概念，甚至发现新的有用概念，最终提高了神经网络的可解释性，并促进了符号逻辑推理的整合。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.16884v1",
      "published_date": "2024-04-23 20:33:17 UTC",
      "updated_date": "2024-04-23 20:33:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:47:40.873847"
    },
    {
      "arxiv_id": "2404.15501v1",
      "title": "Killkan: The Automatic Speech Recognition Dataset for Kichwa with Morphosyntactic Information",
      "title_zh": "翻译失败",
      "authors": [
        "Chihiro Taguchi",
        "Jefferson Saransig",
        "Dayana Velásquez",
        "David Chiang"
      ],
      "abstract": "This paper presents Killkan, the first dataset for automatic speech\nrecognition (ASR) in the Kichwa language, an indigenous language of Ecuador.\nKichwa is an extremely low-resource endangered language, and there have been no\nresources before Killkan for Kichwa to be incorporated in applications of\nnatural language processing. The dataset contains approximately 4 hours of\naudio with transcription, translation into Spanish, and morphosyntactic\nannotation in the format of Universal Dependencies. The audio data was\nretrieved from a publicly available radio program in Kichwa. This paper also\nprovides corpus-linguistic analyses of the dataset with a special focus on the\nagglutinative morphology of Kichwa and frequent code-switching with Spanish.\nThe experiments show that the dataset makes it possible to develop the first\nASR system for Kichwa with reliable quality despite its small dataset size.\nThis dataset, the ASR model, and the code used to develop them will be publicly\navailable. Thus, our study positively showcases resource building and its\napplications for low-resource languages and their community.",
      "tldr_zh": "本文介绍了Killkan数据集，这是首个针对Kichwa语言的Automatic Speech Recognition (ASR)数据集，旨在支持这一低资源濒危语言的自然语言处理应用。数据集包含约4小时音频、转录、西班牙语翻译以及Universal Dependencies格式的morphosyntactic annotation，数据来源于公开的Kichwa广播节目。论文对数据集进行了语料库分析，重点探讨了Kichwa的agglutinative morphology和与西班牙语的频繁code-switching现象。实验结果显示，尽管数据集规模较小，仍能开发出可靠的Kichwa ASR系统。该数据集、模型和相关代码将公开可用，推动低资源语言社区的研究和发展。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "11 pages, 9 tables, 3 figures, to be published in LREC-COLING 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.15501v1",
      "published_date": "2024-04-23 20:26:07 UTC",
      "updated_date": "2024-04-23 20:26:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:47:53.358566"
    },
    {
      "arxiv_id": "2404.15500v1",
      "title": "GeoLLM-Engine: A Realistic Environment for Building Geospatial Copilots",
      "title_zh": "翻译失败",
      "authors": [
        "Simranjit Singh",
        "Michael Fore",
        "Dimitrios Stamoulis"
      ],
      "abstract": "Geospatial Copilots unlock unprecedented potential for performing Earth\nObservation (EO) applications through natural language instructions. However,\nexisting agents rely on overly simplified single tasks and template-based\nprompts, creating a disconnect with real-world scenarios. In this work, we\npresent GeoLLM-Engine, an environment for tool-augmented agents with intricate\ntasks routinely executed by analysts on remote sensing platforms. We enrich our\nenvironment with geospatial API tools, dynamic maps/UIs, and external\nmultimodal knowledge bases to properly gauge an agent's proficiency in\ninterpreting realistic high-level natural language commands and its functional\ncorrectness in task completions. By alleviating overheads typically associated\nwith human-in-the-loop benchmark curation, we harness our massively parallel\nengine across 100 GPT-4-Turbo nodes, scaling to over half a million diverse\nmulti-tool tasks and across 1.1 million satellite images. By moving beyond\ntraditional single-task image-caption paradigms, we investigate\nstate-of-the-art agents and prompting techniques against long-horizon prompts.",
      "tldr_zh": "本研究引入 GeoLLM-Engine，这是一个用于构建 Geospatial Copilots 的真实环境，旨在通过工具增强代理处理复杂的 Earth Observation (EO) 应用，解决现有代理依赖单一任务和模板提示的局限性。该环境整合了地理空间 API 工具、动态地图/UI 和外部多模态知识库，以评估代理对高水平自然语言命令的解释能力及任务完成的正确性。通过大规模并行引擎，利用 100 个 GPT-4-Turbo 节点生成超过 50 万个多工具任务和 110 万张卫星图像，该研究超越了传统的单一任务图像-标题范式，并调查了最先进代理在长horizon提示下的性能。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Earthvision 2024, CVPR Workshop",
      "pdf_url": "http://arxiv.org/pdf/2404.15500v1",
      "published_date": "2024-04-23 20:23:37 UTC",
      "updated_date": "2024-04-23 20:23:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:48:05.469658"
    },
    {
      "arxiv_id": "2404.16072v1",
      "title": "Playing Board Games with the Predict Results of Beam Search Algorithm",
      "title_zh": "翻译失败",
      "authors": [
        "Sergey Pastukhov"
      ],
      "abstract": "This paper introduces a novel algorithm for two-player deterministic games\nwith perfect information, which we call PROBS (Predict Results of Beam Search).\nUnlike existing methods that predominantly rely on Monte Carlo Tree Search\n(MCTS) for decision processes, our approach leverages a simpler beam search\nalgorithm. We evaluate the performance of our algorithm across a selection of\nboard games, where it consistently demonstrates an increased winning ratio\nagainst baseline opponents. A key result of this study is that the PROBS\nalgorithm operates effectively, even when the beam search size is considerably\nsmaller than the average number of turns in the game.",
      "tldr_zh": "本论文提出了一种名为PROBS的新算法，用于两人玩的确定性完美信息游戏，通过beam search算法进行决策，与传统依赖Monte Carlo Tree Search (MCTS)的方法不同，PROBS采用更简单的搜索策略。在多种棋盘游戏的测试中，PROBS显示出更高的获胜率，对抗基线对手表现出色。关键发现是，即使beam search的大小远小于游戏的平均回合数，该算法仍能有效运行，为游戏AI决策提供了一个高效替代方案。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.16072v1",
      "published_date": "2024-04-23 20:10:27 UTC",
      "updated_date": "2024-04-23 20:10:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:48:14.596997"
    },
    {
      "arxiv_id": "2404.15492v1",
      "title": "Multi-scale Intervention Planning based on Generative Design",
      "title_zh": "翻译失败",
      "authors": [
        "Ioannis Kavouras",
        "Ioannis Rallis",
        "Emmanuel Sardis",
        "Eftychios Protopapadakis",
        "Anastasios Doulamis",
        "Nikolaos Doulamis"
      ],
      "abstract": "The scarcity of green spaces, in urban environments, consists a critical\nchallenge. There are multiple adverse effects, impacting the health and\nwell-being of the citizens. Small scale interventions, e.g. pocket parks, is a\nviable solution, but comes with multiple constraints, involving the design and\nimplementation over a specific area. In this study, we harness the capabilities\nof generative AI for multi-scale intervention planning, focusing on nature\nbased solutions. By leveraging image-to-image and image inpainting algorithms,\nwe propose a methodology to address the green space deficit in urban areas.\nFocusing on two alleys in Thessaloniki, where greenery is lacking, we\ndemonstrate the efficacy of our approach in visualizing NBS interventions. Our\nfindings underscore the transformative potential of emerging technologies in\nshaping the future of urban intervention planning processes.",
      "tldr_zh": "本研究针对城市环境中绿色空间稀缺及其对市民健康的影响，提出了一种基于生成式设计的多尺度干预规划方法。利用图像到图像转换（image-to-image）和图像修复（image inpainting）算法，该方法专注于基于自然的解决方案（NBS），旨在可视化并优化小型干预如袖珍公园。研究以塞萨洛尼基的两个缺乏绿化的小巷为例，证明了该方法的有效性，并突出了新兴技术在提升城市干预规划过程中的变革潜力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.15492v1",
      "published_date": "2024-04-23 20:06:56 UTC",
      "updated_date": "2024-04-23 20:06:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:48:28.188523"
    },
    {
      "arxiv_id": "2404.15488v1",
      "title": "IryoNLP at MEDIQA-CORR 2024: Tackling the Medical Error Detection & Correction Task On the Shoulders of Medical Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Jean-Philippe Corbeil"
      ],
      "abstract": "In natural language processing applied to the clinical domain, utilizing\nlarge language models has emerged as a promising avenue for error detection and\ncorrection on clinical notes, a knowledge-intensive task for which annotated\ndata is scarce. This paper presents MedReAct'N'MedReFlex, which leverages a\nsuite of four LLM-based medical agents. The MedReAct agent initiates the\nprocess by observing, analyzing, and taking action, generating trajectories to\nguide the search to target a potential error in the clinical notes.\nSubsequently, the MedEval agent employs five evaluators to assess the targeted\nerror and the proposed correction. In cases where MedReAct's actions prove\ninsufficient, the MedReFlex agent intervenes, engaging in reflective analysis\nand proposing alternative strategies. Finally, the MedFinalParser agent formats\nthe final output, preserving the original style while ensuring the integrity of\nthe error correction process. One core component of our method is our RAG\npipeline based on our ClinicalCorp corpora. Among other well-known sources\ncontaining clinical guidelines and information, we preprocess and release the\nopen-source MedWiki dataset for clinical RAG application. Our results\ndemonstrate the central role of our RAG approach with ClinicalCorp leveraged\nthrough the MedReAct'N'MedReFlex framework. It achieved the ninth rank on the\nMEDIQA-CORR 2024 final leaderboard.",
      "tldr_zh": "这篇论文介绍了IryoNLP团队在MEDIQA-CORR 2024竞赛中处理医疗错误检测与修正任务的方法，采用了一个基于LLM的四代理系统：MedReAct、MedEval、MedReFlex和MedFinalParser。MedReAct代理通过观察、分析和行动生成错误定位轨迹，MedEval代理使用五个评估器评估错误和修正方案，MedReFlex代理在必要时进行反思分析并提出替代策略，而MedFinalParser代理负责格式化最终输出以保持原风格。核心组件包括基于ClinicalCorp语料库的RAG管道，以及开源MedWiki数据集的发布。该框架在竞赛中排名第九，突显了RAG方法在知识密集型临床任务中的关键作用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.15488v1",
      "published_date": "2024-04-23 20:00:37 UTC",
      "updated_date": "2024-04-23 20:00:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:48:43.181866"
    },
    {
      "arxiv_id": "2405.00708v1",
      "title": "Interactive Analysis of LLMs using Meaningful Counterfactuals",
      "title_zh": "翻译失败",
      "authors": [
        "Furui Cheng",
        "Vilém Zouhar",
        "Robin Shing Moon Chan",
        "Daniel Fürst",
        "Hendrik Strobelt",
        "Mennatallah El-Assady"
      ],
      "abstract": "Counterfactual examples are useful for exploring the decision boundaries of\nmachine learning models and determining feature attributions. How can we apply\ncounterfactual-based methods to analyze and explain LLMs? We identify the\nfollowing key challenges. First, the generated textual counterfactuals should\nbe meaningful and readable to users and thus can be mentally compared to draw\nconclusions. Second, to make the solution scalable to long-form text, users\nshould be equipped with tools to create batches of counterfactuals from\nperturbations at various granularity levels and interactively analyze the\nresults. In this paper, we tackle the above challenges and contribute 1) a\nnovel algorithm for generating batches of complete and meaningful textual\ncounterfactuals by removing and replacing text segments in different\ngranularities, and 2) LLM Analyzer, an interactive visualization tool to help\nusers understand an LLM's behaviors by interactively inspecting and aggregating\nmeaningful counterfactuals. We evaluate the proposed algorithm by the\ngrammatical correctness of its generated counterfactuals using 1,000 samples\nfrom medical, legal, finance, education, and news datasets. In our experiments,\n97.2% of the counterfactuals are grammatically correct. Through a use case,\nuser studies, and feedback from experts, we demonstrate the usefulness and\nusability of the proposed interactive visualization tool.",
      "tldr_zh": "该论文探讨了使用有意义的反事实（counterfactual examples）来分析和解释大型语言模型（LLMs）的决策边界和特征归因。作者识别了关键挑战，包括生成可读且有意义的文本反事实，以及为长文本提供可扩展的批量生成和交互分析工具。为此，他们贡献了1) 一个新算法，通过移除和替换不同粒度的文本段落来生成批量完整且有意义的文本反事实，以及2) LLM Analyzer，一个交互式可视化工具，帮助用户通过检查和聚合这些反事实来理解LLMs的行为。在实验中，使用来自医疗、法律、金融、教育和新闻等数据集的1000个样本，该算法生成的反事实中有97.2%在语法上正确，并通过用例、用户研究和专家反馈证明了工具的实用性和可用性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC",
        "cs.LG",
        "I.2.7; H.5.2"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.00708v1",
      "published_date": "2024-04-23 19:57:03 UTC",
      "updated_date": "2024-04-23 19:57:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:48:57.594761"
    },
    {
      "arxiv_id": "2404.15485v3",
      "title": "Evaluating the Efficacy of Large Language Models in Identifying Phishing Attempts",
      "title_zh": "评估大型语言模型识别网络钓鱼尝试的效能",
      "authors": [
        "Het Patel",
        "Umair Rehman",
        "Farkhund Iqbal"
      ],
      "abstract": "Phishing, a prevalent cybercrime tactic for decades, remains a significant\nthreat in today's digital world. By leveraging clever social engineering\nelements and modern technology, cybercrime targets many individuals,\nbusinesses, and organizations to exploit trust and security. These\ncyber-attackers are often disguised in many trustworthy forms to appear as\nlegitimate sources. By cleverly using psychological elements like urgency,\nfear, social proof, and other manipulative strategies, phishers can lure\nindividuals into revealing sensitive and personalized information. Building on\nthis pervasive issue within modern technology, this paper aims to analyze the\neffectiveness of 15 Large Language Models (LLMs) in detecting phishing\nattempts, specifically focusing on a randomized set of \"419 Scam\" emails. The\nobjective is to determine which LLMs can accurately detect phishing emails by\nanalyzing a text file containing email metadata based on predefined criteria.\nThe experiment concluded that the following models, ChatGPT 3.5,\nGPT-3.5-Turbo-Instruct, and ChatGPT, were the most effective in detecting\nphishing emails.",
      "tldr_zh": "这篇论文评估了15个Large Language Models (LLMs)在识别Phishing (网络钓鱼)尝试的有效性，特别针对一组随机“419 Scam”电子邮件。研究方法涉及让LLMs分析包含电子邮件元数据的文本文件，并根据预定义标准进行检测。结果表明，ChatGPT 3.5、GPT-3.5-Turbo-Instruct和ChatGPT是最有效的模型，在检测Phishing邮件方面表现出色。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "7 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.15485v3",
      "published_date": "2024-04-23 19:55:18 UTC",
      "updated_date": "2024-06-06 21:03:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:49:08.241995"
    },
    {
      "arxiv_id": "2404.16071v1",
      "title": "Augmenting the Author: Exploring the Potential of AI Collaboration in Academic Writing",
      "title_zh": "增强作者：探索人工智能协作在学术写作中的潜力",
      "authors": [
        "Joseph Tu",
        "Hilda Hadan",
        "Derrick M. Wang",
        "Sabrina A Sgandurra",
        "Reza Hadi Mogavi",
        "Lennart E. Nacke"
      ],
      "abstract": "This workshop paper presents a critical examination of the integration of\nGenerative AI (Gen AI) into the academic writing process, focusing on the use\nof AI as a collaborative tool. It contrasts the performance and interaction of\ntwo AI models, Gemini and ChatGPT, through a collaborative inquiry approach\nwhere researchers engage in facilitated sessions to design prompts that elicit\nspecific AI responses for crafting research outlines. This case study\nhighlights the importance of prompt design, output analysis, and recognizing\nthe AI's limitations to ensure responsible and effective AI integration in\nscholarly work. Preliminary findings suggest that prompt variation\nsignificantly affects output quality and reveals distinct capabilities and\nconstraints of each model. The paper contributes to the field of Human-Computer\nInteraction by exploring effective prompt strategies and providing a\ncomparative analysis of Gen AI models, ultimately aiming to enhance AI-assisted\nacademic writing and prompt a deeper dialogue within the HCI community.",
      "tldr_zh": "这篇研讨会论文探讨了生成式AI（Gen AI）在学术写作中的协作潜力，将AI视为辅助工具，通过比较Gemini和ChatGPT模型进行分析。研究采用协作探究方法，让研究者设计提示以生成研究提纲，并强调提示设计、输出分析以及AI限制的重要性，以确保负责任的整合。初步发现显示，提示变化显著影响输出质量，并揭示了每个模型的独特能力和约束，最终为Human-Computer Interaction (HCI) 领域提供有效提示策略，促进AI辅助学术写作的提升和社区对话。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "5 pages, workshop paper, CHI 2024 conference GENAI",
      "pdf_url": "http://arxiv.org/pdf/2404.16071v1",
      "published_date": "2024-04-23 19:06:39 UTC",
      "updated_date": "2024-04-23 19:06:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:49:20.187573"
    },
    {
      "arxiv_id": "2405.02326v2",
      "title": "Evaluating LLMs for Hardware Design and Test",
      "title_zh": "翻译失败",
      "authors": [
        "Jason Blocklove",
        "Siddharth Garg",
        "Ramesh Karri",
        "Hammond Pearce"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated capabilities for producing\ncode in Hardware Description Languages (HDLs). However, most of the focus\nremains on their abilities to write functional code, not test code. The\nhardware design process consists of both design and test, and so eschewing\nvalidation and verification leaves considerable potential benefit unexplored,\ngiven that a design and test framework may allow for progress towards full\nautomation of the digital design pipeline. In this work, we perform one of the\nfirst studies exploring how a LLM can both design and test hardware modules\nfrom provided specifications. Using a suite of 8 representative benchmarks, we\nexamined the capabilities and limitations of the state-of-the-art\nconversational LLMs when producing Verilog for functional and verification\npurposes. We taped out the benchmarks on a Skywater 130nm shuttle and received\nthe functional chip.",
      "tldr_zh": "这篇论文评估了大型语言模型(LLMs)在硬件设计和测试中的能力，重点探讨其生成硬件描述语言(HDLs)功能代码和测试代码的潜力。研究使用8个代表性基准测试，考察了LLMs生成Verilog代码的性能，并分析了其优势和局限性。最终，他们将这些基准测试流片到Skywater 130nm芯片上，并成功获得功能芯片，这为实现全自动化数字设计管道提供了重要进展。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.PL"
      ],
      "primary_category": "cs.AR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.02326v2",
      "published_date": "2024-04-23 18:55:49 UTC",
      "updated_date": "2024-12-02 01:59:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:49:32.417626"
    },
    {
      "arxiv_id": "2404.15449v1",
      "title": "ID-Aligner: Enhancing Identity-Preserving Text-to-Image Generation with Reward Feedback Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Weifeng Chen",
        "Jiacheng Zhang",
        "Jie Wu",
        "Hefeng Wu",
        "Xuefeng Xiao",
        "Liang Lin"
      ],
      "abstract": "The rapid development of diffusion models has triggered diverse applications.\nIdentity-preserving text-to-image generation (ID-T2I) particularly has received\nsignificant attention due to its wide range of application scenarios like AI\nportrait and advertising. While existing ID-T2I methods have demonstrated\nimpressive results, several key challenges remain: (1) It is hard to maintain\nthe identity characteristics of reference portraits accurately, (2) The\ngenerated images lack aesthetic appeal especially while enforcing identity\nretention, and (3) There is a limitation that cannot be compatible with\nLoRA-based and Adapter-based methods simultaneously. To address these issues,\nwe present \\textbf{ID-Aligner}, a general feedback learning framework to\nenhance ID-T2I performance. To resolve identity features lost, we introduce\nidentity consistency reward fine-tuning to utilize the feedback from face\ndetection and recognition models to improve generated identity preservation.\nFurthermore, we propose identity aesthetic reward fine-tuning leveraging\nrewards from human-annotated preference data and automatically constructed\nfeedback on character structure generation to provide aesthetic tuning signals.\nThanks to its universal feedback fine-tuning framework, our method can be\nreadily applied to both LoRA and Adapter models, achieving consistent\nperformance gains. Extensive experiments on SD1.5 and SDXL diffusion models\nvalidate the effectiveness of our approach. \\textbf{Project Page:\n\\url{https://idaligner.github.io/}}",
      "tldr_zh": "这篇论文提出了 ID-Aligner，一种基于奖励反馈学习的框架，用于提升身份保留文本到图像生成 (ID-T2I)，以解决现有方法在保持参考肖像身份特征、美学吸引力和兼容性方面的挑战。框架通过引入身份一致性奖励微调（利用面部检测和识别模型的反馈）来改善身份保留，以及身份美学奖励微调（基于人类标注偏好数据和自动反馈）来增强图像美学，同时确保兼容 LoRA-based 和 Adapter-based 方法。实验在 SD1.5 和 SDXL 扩散模型上验证了该方法的有效性，实现了显著的性能提升。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.15449v1",
      "published_date": "2024-04-23 18:41:56 UTC",
      "updated_date": "2024-04-23 18:41:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:49:45.234884"
    },
    {
      "arxiv_id": "2404.15447v1",
      "title": "GLoD: Composing Global Contexts and Local Details in Image Generation",
      "title_zh": "GLoD：在图像生成中组合全局上下文与局部细节",
      "authors": [
        "Moyuru Yamada"
      ],
      "abstract": "Diffusion models have demonstrated their capability to synthesize\nhigh-quality and diverse images from textual prompts. However, simultaneous\ncontrol over both global contexts (e.g., object layouts and interactions) and\nlocal details (e.g., colors and emotions) still remains a significant\nchallenge. The models often fail to understand complex descriptions involving\nmultiple objects and reflect specified visual attributes to wrong targets or\nignore them. This paper presents Global-Local Diffusion (\\textit{GLoD}), a\nnovel framework which allows simultaneous control over the global contexts and\nthe local details in text-to-image generation without requiring training or\nfine-tuning. It assigns multiple global and local prompts to corresponding\nlayers and composes their noises to guide a denoising process using pre-trained\ndiffusion models. Our framework enables complex global-local compositions,\nconditioning objects in the global prompt with the local prompts while\npreserving other unspecified identities. Our quantitative and qualitative\nevaluations demonstrate that GLoD effectively generates complex images that\nadhere to both user-provided object interactions and object details.",
      "tldr_zh": "该论文探讨了扩散模型（Diffusion models）在文本到图像生成中难以同时控制全局上下文（如物体布局和互动）和局部细节（如颜色和情感）的挑战，常导致模型错误应用或忽略指定属性。论文提出了一种新框架Global-Local Diffusion (GLoD)，无需训练或微调，通过为对应层分配多个全局和局部提示，并组合它们的噪声来指导去噪过程，从而实现对复杂图像的精确控制。GLoD 能够对全局提示中的物体进行局部条件化，同时保留未指定元素，确保生成图像符合用户意图。实验结果显示，GLoD 在定量和定性评估中有效生成符合物体互动和细节的复杂图像。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.15447v1",
      "published_date": "2024-04-23 18:39:57 UTC",
      "updated_date": "2024-04-23 18:39:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:49:55.998906"
    },
    {
      "arxiv_id": "2404.15420v3",
      "title": "XC-Cache: Cross-Attending to Cached Context for Efficient LLM Inference",
      "title_zh": "翻译失败",
      "authors": [
        "João Monteiro",
        "Étienne Marcotte",
        "Pierre-André Noël",
        "Valentina Zantedeschi",
        "David Vázquez",
        "Nicolas Chapados",
        "Christopher Pal",
        "Perouz Taslakian"
      ],
      "abstract": "In-context learning (ICL) approaches typically leverage prompting to\ncondition decoder-only language model generation on reference information.\nJust-in-time processing of a context is inefficient due to the quadratic cost\nof self-attention operations, and caching is desirable. However, caching\ntransformer states can easily require almost as much space as the model\nparameters. When the right context isn't known in advance, caching ICL can be\nchallenging. This work addresses these limitations by introducing models that,\ninspired by the encoder-decoder architecture, use cross-attention to condition\ngeneration on reference text without the prompt. More precisely, we leverage\npre-trained decoder-only models and only train a small number of added layers.\nWe use Question-Answering (QA) as a testbed to evaluate the ability of our\nmodels to perform conditional generation and observe that they outperform ICL,\nare comparable to fine-tuned prompted LLMs, and drastically reduce the space\nfootprint relative to standard KV caching by two orders of magnitude.",
      "tldr_zh": "该论文提出 XC-Cache 方法，通过 cross-attention 机制处理缓存上下文，提高大型语言模型（LLM）的推理效率，解决 In-context learning (ICL) 中自注意力操作的二次方计算成本和缓存空间问题。该方法借鉴编码器-解码器架构，在预训练的解码器模型基础上，仅训练少量额外层，实现对参考文本的条件生成，而无需依赖提示。实验结果显示，在 Question-Answering (QA) 任务上，XC-Cache 优于 ICL，与 fine-tuned prompted LLMs 性能相当，并将空间占用相对于标准 KV caching 减少两个数量级。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.15420v3",
      "published_date": "2024-04-23 18:10:42 UTC",
      "updated_date": "2024-11-01 14:56:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:50:10.022124"
    },
    {
      "arxiv_id": "2404.15417v2",
      "title": "The Power of Resets in Online Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Zakaria Mhammedi",
        "Dylan J. Foster",
        "Alexander Rakhlin"
      ],
      "abstract": "Simulators are a pervasive tool in reinforcement learning, but most existing\nalgorithms cannot efficiently exploit simulator access -- particularly in\nhigh-dimensional domains that require general function approximation. We\nexplore the power of simulators through online reinforcement learning with\n{local simulator access} (or, local planning), an RL protocol where the agent\nis allowed to reset to previously observed states and follow their dynamics\nduring training. We use local simulator access to unlock new statistical\nguarantees that were previously out of reach:\n  - We show that MDPs with low coverability (Xie et al. 2023) -- a general\nstructural condition that subsumes Block MDPs and Low-Rank MDPs -- can be\nlearned in a sample-efficient fashion with only $Q^{\\star}$-realizability\n(realizability of the optimal state-value function); existing online RL\nalgorithms require significantly stronger representation conditions.\n  - As a consequence, we show that the notorious Exogenous Block MDP problem\n(Efroni et al. 2022) is tractable under local simulator access.\n  The results above are achieved through a computationally inefficient\nalgorithm. We complement them with a more computationally efficient algorithm,\nRVFS (Recursive Value Function Search), which achieves provable sample\ncomplexity guarantees under a strengthened statistical assumption known as\npushforward coverability. RVFS can be viewed as a principled, provable\ncounterpart to a successful empirical paradigm that combines recursive search\n(e.g., MCTS) with value function approximation.",
      "tldr_zh": "本研究探讨了在线强化学习（Reinforcement Learning）中通过本地模拟器访问（local simulator access）——即允许代理重置到之前状态并模拟动态——来提升学习效率。论文证明，在低覆盖性（low coverability）MDPs（Markov Decision Processes）条件下，仅需Q*-realizability（最优状态价值函数的实现性）即可实现样本高效学习，这比现有算法所需的更强表示条件更宽松。结果显示，外生块MDP（Exogenous Block MDP）问题在这种设置下变得可处理；此外，作者提出了一种高效算法RVFS（Recursive Value Function Search），在加强的统计假设pushforward coverability下，提供可证明的样本复杂度保证，并作为递归搜索（如MCTS）与价值函数近似的可靠对应。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Fixed a small typo",
      "pdf_url": "http://arxiv.org/pdf/2404.15417v2",
      "published_date": "2024-04-23 18:09:53 UTC",
      "updated_date": "2024-04-26 14:31:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:50:21.827031"
    },
    {
      "arxiv_id": "2404.15418v1",
      "title": "Machine Learning Techniques with Fairness for Prediction of Completion of Drug and Alcohol Rehabilitation",
      "title_zh": "结合公平性的机器学习技术用于药物和酒精康复完成预测",
      "authors": [
        "Karen Roberts-Licklider",
        "Theodore Trafalis"
      ],
      "abstract": "The aim of this study is to look at predicting whether a person will complete\na drug and alcohol rehabilitation program and the number of times a person\nattends. The study is based on demographic data obtained from Substance Abuse\nand Mental Health Services Administration (SAMHSA) from both admissions and\ndischarge data from drug and alcohol rehabilitation centers in Oklahoma.\nDemographic data is highly categorical which led to binary encoding being used\nand various fairness measures being utilized to mitigate bias of nine\ndemographic variables. Kernel methods such as linear, polynomial, sigmoid, and\nradial basis functions were compared using support vector machines at various\nparameter ranges to find the optimal values. These were then compared to\nmethods such as decision trees, random forests, and neural networks. Synthetic\nMinority Oversampling Technique Nominal (SMOTEN) for categorical data was used\nto balance the data with imputation for missing data. The nine bias variables\nwere then intersectionalized to mitigate bias and the dual and triple\ninteractions were integrated to use the probabilities to look at worst case\nratio fairness mitigation. Disparate Impact, Statistical Parity difference,\nConditional Statistical Parity Ratio, Demographic Parity, Demographic Parity\nRatio, Equalized Odds, Equalized Odds Ratio, Equal Opportunity, and Equalized\nOpportunity Ratio were all explored at both the binary and multiclass\nscenarios.",
      "tldr_zh": "本研究旨在使用机器学习技术预测个体是否完成药物和酒精康复程序以及出席次数，同时融入公平性措施以缓解偏见。基于 Substance Abuse and Mental Health Services Administration (SAMHSA) 的入院和出院数据，该团队采用二元编码处理分类数据，并使用 Synthetic Minority Oversampling Technique Nominal (SMOTEN) 进行数据平衡和缺失值插值。研究比较了各种核方法（如线性、多项式、Sigmoid 和 Radial Basis Functions）结合 Support Vector Machines (SVM)，以及决策树、随机森林和神经网络等模型，并通过 Disparate Impact、Statistical Parity difference 和 Equalized Odds 等公平度量评估并缓解九个人口统计变量的偏见。最终结果展示了这些方法在公平性优化下的预测性能，为减少机器学习模型偏见提供了实用见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.15418v1",
      "published_date": "2024-04-23 18:09:53 UTC",
      "updated_date": "2024-04-23 18:09:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:50:31.853688"
    },
    {
      "arxiv_id": "2404.15410v1",
      "title": "Planning the path with Reinforcement Learning: Optimal Robot Motion Planning in RoboCup Small Size League Environments",
      "title_zh": "翻译失败",
      "authors": [
        "Mateus G. Machado",
        "João G. Melo",
        "Cleber Zanchettin",
        "Pedro H. M. Braga",
        "Pedro V. Cunha",
        "Edna N. S. Barros",
        "Hansenclever F. Bassani"
      ],
      "abstract": "This work investigates the potential of Reinforcement Learning (RL) to tackle\nrobot motion planning challenges in the dynamic RoboCup Small Size League\n(SSL). Using a heuristic control approach, we evaluate RL's effectiveness in\nobstacle-free and single-obstacle path-planning environments. Ablation studies\nreveal significant performance improvements. Our method achieved a 60% time\ngain in obstacle-free environments compared to baseline algorithms.\nAdditionally, our findings demonstrated dynamic obstacle avoidance\ncapabilities, adeptly navigating around moving blocks. These findings highlight\nthe potential of RL to enhance robot motion planning in the challenging and\nunpredictable SSL environment.",
      "tldr_zh": "本研究探讨了 Reinforcement Learning (RL) 在 RoboCup Small Size League (SSL) 动态环境中进行机器人运动规划的潜力，通过启发式控制方法评估其在无障碍和单一障碍场景中的表现。研究进行了消融实验，证明 RL 显著提升了规划效率，在无障碍环境中比基线算法节省了 60% 的时间。结果还展示了 RL 的动态障碍物避让能力，能够有效绕过移动障碍。这些发现强调了 RL 在复杂 SSL 环境中优化机器人路径规划的应用价值。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "12 pages, 3 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2404.15410v1",
      "published_date": "2024-04-23 18:01:30 UTC",
      "updated_date": "2024-04-23 18:01:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:50:43.870192"
    },
    {
      "arxiv_id": "2404.15406v2",
      "title": "Wiki-LLaVA: Hierarchical Retrieval-Augmented Generation for Multimodal LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Davide Caffagni",
        "Federico Cocchi",
        "Nicholas Moratelli",
        "Sara Sarto",
        "Marcella Cornia",
        "Lorenzo Baraldi",
        "Rita Cucchiara"
      ],
      "abstract": "Multimodal LLMs are the natural evolution of LLMs, and enlarge their\ncapabilities so as to work beyond the pure textual modality. As research is\nbeing carried out to design novel architectures and vision-and-language\nadapters, in this paper we concentrate on endowing such models with the\ncapability of answering questions that require external knowledge. Our\napproach, termed Wiki-LLaVA, aims at integrating an external knowledge source\nof multimodal documents, which is accessed through a hierarchical retrieval\npipeline. Relevant passages, using this approach, are retrieved from the\nexternal knowledge source and employed as additional context for the LLM,\naugmenting the effectiveness and precision of generated dialogues. We conduct\nextensive experiments on datasets tailored for visual question answering with\nexternal data and demonstrate the appropriateness of our approach.",
      "tldr_zh": "这篇论文提出了 Wiki-LLaVA，一种针对 Multimodal LLMs 的层次化检索增强生成方法，旨在帮助这些模型处理需要外部知识的视觉问答任务。该方法通过一个分层检索管道从外部多模态文档中提取相关段落，作为 LLM 的额外上下文，从而提升生成对话的准确性和有效性。在针对视觉问答数据集的广泛实验中，Wiki-LLaVA 展示了显著的性能改进，证明了其在增强 Multimodal LLMs 能力的适用性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2024 Workshop on What is Next in Multimodal Foundation Models",
      "pdf_url": "http://arxiv.org/pdf/2404.15406v2",
      "published_date": "2024-04-23 18:00:09 UTC",
      "updated_date": "2024-05-22 07:15:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:50:56.371146"
    },
    {
      "arxiv_id": "2404.15276v1",
      "title": "SMPLer: Taming Transformers for Monocular 3D Human Shape and Pose Estimation",
      "title_zh": "翻译失败",
      "authors": [
        "Xiangyu Xu",
        "Lijuan Liu",
        "Shuicheng Yan"
      ],
      "abstract": "Existing Transformers for monocular 3D human shape and pose estimation\ntypically have a quadratic computation and memory complexity with respect to\nthe feature length, which hinders the exploitation of fine-grained information\nin high-resolution features that is beneficial for accurate reconstruction. In\nthis work, we propose an SMPL-based Transformer framework (SMPLer) to address\nthis issue. SMPLer incorporates two key ingredients: a decoupled attention\noperation and an SMPL-based target representation, which allow effective\nutilization of high-resolution features in the Transformer. In addition, based\non these two designs, we also introduce several novel modules including a\nmulti-scale attention and a joint-aware attention to further boost the\nreconstruction performance. Extensive experiments demonstrate the effectiveness\nof SMPLer against existing 3D human shape and pose estimation methods both\nquantitatively and qualitatively. Notably, the proposed algorithm achieves an\nMPJPE of 45.2 mm on the Human3.6M dataset, improving upon Mesh Graphormer by\nmore than 10% with fewer than one-third of the parameters. Code and pretrained\nmodels are available at https://github.com/xuxy09/SMPLer.",
      "tldr_zh": "本研究提出 SMPLer 框架，以解决现有 Transformer 在单目 3D 人体形状和姿势估计中的二次方计算复杂度问题，从而有效利用高分辨率特征。SMPLer 采用解耦注意力操作和基于 SMPL 的目标表示作为关键设计，并引入多尺度注意力和关节感知注意力等新模块，进一步提升重建准确性。实验结果显示，SMPLer 在 Human3.6M 数据集上实现 45.2 mm 的 MPJPE，比 Mesh Graphormer 提高了 10% 以上，同时参数量不到其三分之一。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "Published at TPAMI 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.15276v1",
      "published_date": "2024-04-23 17:59:59 UTC",
      "updated_date": "2024-04-23 17:59:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:51:11.807917"
    },
    {
      "arxiv_id": "2404.15272v3",
      "title": "CT-GLIP: 3D Grounded Language-Image Pretraining with CT Scans and Radiology Reports for Full-Body Scenarios",
      "title_zh": "翻译失败",
      "authors": [
        "Jingyang Lin",
        "Yingda Xia",
        "Jianpeng Zhang",
        "Ke Yan",
        "Le Lu",
        "Jiebo Luo",
        "Ling Zhang"
      ],
      "abstract": "Medical Vision-Language Pretraining (Med-VLP) establishes a connection\nbetween visual content from medical images and the relevant textual\ndescriptions. Existing Med-VLP methods primarily focus on 2D images depicting a\nsingle body part, notably chest X-rays. In this paper, we extend the scope of\nMed-VLP to encompass 3D images, specifically targeting full-body scenarios, by\nusing a multimodal dataset of CT images and reports. Compared with the 2D\ncounterpart, 3D VLP is required to effectively capture essential semantics from\nsignificantly sparser representation in 3D imaging. In this paper, we introduce\nCT-GLIP (Grounded Language-Image Pretraining with CT scans), a novel method\nthat constructs organ-level image-text pairs to enhance multimodal contrastive\nlearning, aligning grounded visual features with precise diagnostic text.\nAdditionally, we developed an abnormality dictionary to augment contrastive\nlearning with diverse contrastive pairs. Our method, trained on a multimodal CT\ndataset comprising 44,011 organ-level vision-text pairs from 17,702 patients\nacross 104 organs, demonstrates it can identify organs and abnormalities in a\nzero-shot manner using natural languages. The performance of CT-GLIP is\nvalidated on a separate test set of 1,130 patients, focusing on the 16 most\nfrequent abnormalities across 7 organs. The experimental results show our\nmodel's superior performance over the standard CLIP framework across zero-shot\nand fine-tuning scenarios, using both CNN and ViT architectures.",
      "tldr_zh": "本论文扩展了Medical Vision-Language Pretraining (Med-VLP) 到3D图像领域，专注于使用CT扫描和放射学报告处理全身场景，以克服现有2D方法（如胸部X光）的局限性。CT-GLIP方法通过构建器官级图像-文本对、增强多模态对比学习并引入异常字典，实现了对稀疏3D视觉特征与精确诊断文本的更好对齐。实验结果显示，该模型在包含44,011对数据的多模态CT数据集上训练后，能在零样本场景下识别器官和异常，并在测试集上超越标准CLIP框架的表现，尤其在使用CNN和ViT架构时。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "12 pages, 5 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2404.15272v3",
      "published_date": "2024-04-23 17:59:01 UTC",
      "updated_date": "2024-04-29 03:25:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:51:21.490870"
    },
    {
      "arxiv_id": "2404.15271v1",
      "title": "Automatic Layout Planning for Visually-Rich Documents with Instruction-Following Models",
      "title_zh": "翻译失败",
      "authors": [
        "Wanrong Zhu",
        "Jennifer Healey",
        "Ruiyi Zhang",
        "William Yang Wang",
        "Tong Sun"
      ],
      "abstract": "Recent advancements in instruction-following models have made user\ninteractions with models more user-friendly and efficient, broadening their\napplicability. In graphic design, non-professional users often struggle to\ncreate visually appealing layouts due to limited skills and resources. In this\nwork, we introduce a novel multimodal instruction-following framework for\nlayout planning, allowing users to easily arrange visual elements into tailored\nlayouts by specifying canvas size and design purpose, such as for book covers,\nposters, brochures, or menus. We developed three layout reasoning tasks to\ntrain the model in understanding and executing layout instructions. Experiments\non two benchmarks show that our method not only simplifies the design process\nfor non-professionals but also surpasses the performance of few-shot GPT-4V\nmodels, with mIoU higher by 12% on Crello. This progress highlights the\npotential of multimodal instruction-following models to automate and simplify\nthe design process, providing an approachable solution for a wide range of\ndesign tasks on visually-rich documents.",
      "tldr_zh": "本研究提出了一种新型多模态指令-following模型框架，用于自动规划视觉丰富文档的布局设计。该框架允许非专业用户通过指定画布大小和设计目的（如书籍封面、海报或菜单）来轻松安排视觉元素，并开发了三个布局推理任务来训练模型理解和执行指令。在两个基准测试中，该方法超过了 few-shot GPT-4V 模型的表现，在 Crello 数据集上 mIoU 提高了 12%，从而简化了设计过程并展示了多模态指令-following 模型在自动化视觉文档设计中的潜力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.15271v1",
      "published_date": "2024-04-23 17:58:33 UTC",
      "updated_date": "2024-04-23 17:58:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:51:34.297354"
    },
    {
      "arxiv_id": "2404.15269v3",
      "title": "Aligning LLM Agents by Learning Latent Preference from User Edits",
      "title_zh": "通过从用户编辑中学习潜在偏好对齐LLM智能体",
      "authors": [
        "Ge Gao",
        "Alexey Taymanov",
        "Eduardo Salinas",
        "Paul Mineiro",
        "Dipendra Misra"
      ],
      "abstract": "We study interactive learning of LLM-based language agents based on user\nedits made to the agent's output. In a typical setting such as writing\nassistants, the user interacts with a language agent to generate a response\ngiven a context, and may optionally edit the agent response to personalize it\nbased on their latent preference, in addition to improving the correctness. The\nedit feedback is naturally generated, making it a suitable candidate for\nimproving the agent's alignment with the user's preference, and for reducing\nthe cost of user edits over time. We propose a learning framework, PRELUDE that\ninfers a description of the user's latent preference based on historic edit\ndata. The inferred user preference descriptions are used to define prompts for\ngenerating responses in the future. This avoids fine-tuning the agent, which is\ncostly, challenging to scale with the number of users, and may even degrade its\nperformance on other tasks. Furthermore, learning descriptive preference\nimproves interpretability, allowing the user to view and modify the learned\npreference. However, user preference can be complex, subtle, and vary based on\ncontext, making it challenging to learn. To address this, we propose a simple\nyet effective algorithm named CIPHER that leverages the LLM to infer the user\npreference for a given context based on user edits. In the future, CIPHER\nretrieves inferred preferences from the k-closest contexts in the history, and\nforms an aggregate preference for response generation. We introduce two\ninteractive environments -- summarization and email writing, and use a GPT-4\nsimulated user for evaluation. On both tasks, CIPHER outperforms several\nbaselines by achieving the lowest edit distance cost while only having a small\noverhead in LLM query cost. Our analysis reports that user preferences learned\nby CIPHER show significant similarity to the ground truth latent preferences.",
      "tldr_zh": "该研究提出了一种交互式学习框架 PRELUDE，用于通过用户对 LLM 代理输出的编辑来对齐代理与用户潜在偏好的匹配。该框架利用算法 CIPHER 基于历史编辑数据推断用户的上下文相关偏好，并通过检索和聚合相似上下文的偏好来生成未来的响应提示，从而避免了昂贵的模型微调，同时提升了可解释性和可扩展性。在摘要和电子邮件写作等交互环境中，使用 GPT-4 模拟用户进行评估，结果显示 CIPHER 比基线方法实现了最低的编辑距离成本，且学习到的用户偏好与真实潜在偏好高度相似。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.15269v3",
      "published_date": "2024-04-23 17:57:47 UTC",
      "updated_date": "2024-11-23 16:19:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:51:45.533737"
    },
    {
      "arxiv_id": "2404.15256v4",
      "title": "TOP-Nav: Legged Navigation Integrating Terrain, Obstacle and Proprioception Estimation",
      "title_zh": "翻译失败",
      "authors": [
        "Junli Ren",
        "Yikai Liu",
        "Yingru Dai",
        "Junfeng Long",
        "Guijin Wang"
      ],
      "abstract": "Legged navigation is typically examined within open-world, off-road, and\nchallenging environments. In these scenarios, estimating external disturbances\nrequires a complex synthesis of multi-modal information. This underlines a\nmajor limitation in existing works that primarily focus on avoiding obstacles.\nIn this work, we propose TOP-Nav, a novel legged navigation framework that\nintegrates a comprehensive path planner with Terrain awareness, Obstacle\navoidance and close-loop Proprioception. TOP-Nav underscores the synergies\nbetween vision and proprioception in both path and motion planning. Within the\npath planner, we present and integrate a terrain estimator that enables the\nrobot to select waypoints on terrains with higher traversability while\neffectively avoiding obstacles. In the motion planning level, we not only\nimplement a locomotion controller to track the navigation commands, but also\nconstruct a proprioception advisor to provide motion evaluations for the path\nplanner. Based on the close-loop motion feedback, we make online corrections\nfor the vision-based terrain and obstacle estimations. Consequently, TOP-Nav\nachieves open-world navigation that the robot can handle terrains or\ndisturbances beyond the distribution of prior knowledge and overcomes\nconstraints imposed by visual conditions. Building upon extensive experiments\nconducted in both simulation and real-world environments, TOP-Nav demonstrates\nsuperior performance in open-world navigation compared to existing methods.",
      "tldr_zh": "该论文提出 TOP-Nav，一种新型腿式导航框架，整合了 Terrain awareness、地形意识、Obstacle avoidance、障碍物避免和Proprioception、本体感觉估计，以处理开放世界中的复杂导航挑战。框架在路径规划中引入地形估计器，帮助机器人选择高可穿越性的路径并避开障碍，同时在运动规划层使用运动控制器和本体感觉顾问，提供闭环反馈以在线修正视觉估计。实验结果显示，TOP-Nav 在模拟和真实环境中显著优于现有方法，能够应对超出先前知识分布的地形干扰和视觉限制。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "Published on CoRL 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.15256v4",
      "published_date": "2024-04-23 17:42:45 UTC",
      "updated_date": "2024-09-27 07:16:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:51:57.272664"
    },
    {
      "arxiv_id": "2404.15247v2",
      "title": "XFT: Unlocking the Power of Code Instruction Tuning by Simply Merging Upcycled Mixture-of-Experts",
      "title_zh": "翻译失败",
      "authors": [
        "Yifeng Ding",
        "Jiawei Liu",
        "Yuxiang Wei",
        "Terry Yue Zhuo",
        "Lingming Zhang"
      ],
      "abstract": "We introduce XFT, a simple yet powerful training scheme, by simply merging\nupcycled Mixture-of-Experts (MoE) to unleash the performance limit of\ninstruction-tuned code Large Language Models (LLMs). While vanilla sparse\nupcycling fails to improve instruction tuning, XFT introduces a shared expert\nmechanism with a novel routing weight normalization strategy into sparse\nupcycling, which significantly boosts instruction tuning. After fine-tuning the\nupcycled MoE model, XFT introduces a learnable model merging mechanism to\ncompile the upcycled MoE model back to a dense model, achieving upcycled\nMoE-level performance with only dense-model compute. By applying XFT to a 1.3B\nmodel, we create a new state-of-the-art tiny code LLM (<3B) with 67.1 and 64.6\npass@1 on HumanEval and HumanEval+ respectively. With the same data and model\narchitecture, XFT improves supervised fine-tuning (SFT) by 13% on HumanEval+,\nalong with consistent improvements from 2% to 13% on MBPP+, MultiPL-E, and\nDS-1000, demonstrating its generalizability. XFT is fully orthogonal to\nexisting techniques such as Evol-Instruct and OSS-Instruct, opening a new\ndimension for improving code instruction tuning. Codes are available at\nhttps://github.com/ise-uiuc/xft.",
      "tldr_zh": "本研究提出 XFT，一种简单有效的训练方案，通过合并 upcycled Mixture-of-Experts (MoE) 来提升代码 Large Language Models (LLMs) 的指令调整性能。XFT 引入共享专家机制和新型路由权重归一化策略来优化稀疏 upcycling，并使用可学习的模型合并机制将 upcycled MoE 模型编译回密集模型，从而在密集模型计算下实现 MoE 级性能。在 1.3B 模型上应用 XFT 后，该模型在 HumanEval 和 HumanEval+ 上分别达到 67.1 和 64.6 pass@1 的新基准，与相同数据和架构相比，在 HumanEval+ 等多个基准上提升 2% 到 13%。XFT 与现有技术如 Evol-Instruct 正交，提供了一个新的维度来改进代码指令调整。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.SE"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.15247v2",
      "published_date": "2024-04-23 17:32:24 UTC",
      "updated_date": "2024-06-06 18:18:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:52:10.680923"
    },
    {
      "arxiv_id": "2404.15238v1",
      "title": "CultureBank: An Online Community-Driven Knowledge Base Towards Culturally Aware Language Technologies",
      "title_zh": "CultureBank：一个由",
      "authors": [
        "Weiyan Shi",
        "Ryan Li",
        "Yutong Zhang",
        "Caleb Ziems",
        "Chunhua yu",
        "Raya Horesh",
        "Rogério Abreu de Paula",
        "Diyi Yang"
      ],
      "abstract": "To enhance language models' cultural awareness, we design a generalizable\npipeline to construct cultural knowledge bases from different online\ncommunities on a massive scale. With the pipeline, we construct CultureBank, a\nknowledge base built upon users' self-narratives with 12K cultural descriptors\nsourced from TikTok and 11K from Reddit. Unlike previous cultural knowledge\nresources, CultureBank contains diverse views on cultural descriptors to allow\nflexible interpretation of cultural knowledge, and contextualized cultural\nscenarios to help grounded evaluation. With CultureBank, we evaluate different\nLLMs' cultural awareness, and identify areas for improvement. We also fine-tune\na language model on CultureBank: experiments show that it achieves better\nperformances on two downstream cultural tasks in a zero-shot setting. Finally,\nwe offer recommendations based on our findings for future culturally aware\nlanguage technologies. The project page is https://culturebank.github.io . The\ncode and model is at https://github.com/SALT-NLP/CultureBank . The released\nCultureBank dataset is at https://huggingface.co/datasets/SALT-NLP/CultureBank .",
      "tldr_zh": "该论文提出了一种可泛化的管道，从 TikTok 和 Reddit 等在线社区收集用户自述数据，构建了 CultureBank 知识库，该库包含 12K 个 TikTok 文化描述符和 11K 个 Reddit 描述符，提供多样化文化观点和情境化场景，以提升语言模型的文化意识。研究者使用 CultureBank 评估不同 LLMs 的文化感知能力，识别出改进领域，并通过在 CultureBank 上微调语言模型，实现了在零样本（zero-shot）设置下下游文化任务的性能提升。最后，论文基于实验结果为未来 culturally aware 语言技术提供了推荐，并公开了相关资源。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "32 pages, 7 figures, preprint",
      "pdf_url": "http://arxiv.org/pdf/2404.15238v1",
      "published_date": "2024-04-23 17:16:08 UTC",
      "updated_date": "2024-04-23 17:16:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:52:22.857172"
    },
    {
      "arxiv_id": "2405.01575v1",
      "title": "Software Mention Recognition with a Three-Stage Framework Based on BERTology Models at SOMD 2024",
      "title_zh": "翻译失败",
      "authors": [
        "Thuy Nguyen Thi",
        "Anh Nguyen Viet",
        "Thin Dang Van",
        "Ngan Nguyen Luu Thuy"
      ],
      "abstract": "This paper describes our systems for the sub-task I in the Software Mention\nDetection in Scholarly Publications shared-task. We propose three approaches\nleveraging different pre-trained language models (BERT, SciBERT, and XLM-R) to\ntackle this challenge. Our bestperforming system addresses the named entity\nrecognition (NER) problem through a three-stage framework. (1) Entity Sentence\nClassification - classifies sentences containing potential software mentions;\n(2) Entity Extraction - detects mentions within classified sentences; (3)\nEntity Type Classification - categorizes detected mentions into specific\nsoftware types. Experiments on the official dataset demonstrate that our\nthree-stage framework achieves competitive performance, surpassing both other\nparticipating teams and our alternative approaches. As a result, our framework\nbased on the XLM-R-based model achieves a weighted F1-score of 67.80%,\ndelivering our team the 3rd rank in Sub-task I for the Software Mention\nRecognition task.",
      "tldr_zh": "这篇论文针对SOMD 2024共享任务的Sub-task I，提出了一种基于BERT、SciBERT和XLM-R等BERTology模型的三阶段框架，用于软件提及识别（Software Mention Recognition）。框架包括：(1) Entity Sentence Classification分类潜在软件提及的句子；(2) Entity Extraction检测这些句子中的提及；(3) Entity Type Classification将检测到的提及分类为特定软件类型。实验结果显示，该框架在官方数据集上基于XLM-R模型取得了67.80%的加权F1-score，在任务中排名第三，优于其他参赛团队和备选方法。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.SE",
      "comment": "Software mention recognition, Named entity recognition, Transformer,\n  Three-stage framework",
      "pdf_url": "http://arxiv.org/pdf/2405.01575v1",
      "published_date": "2024-04-23 17:06:24 UTC",
      "updated_date": "2024-04-23 17:06:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:52:33.521166"
    },
    {
      "arxiv_id": "2404.15231v2",
      "title": "Direct Zernike Coefficient Prediction from Point Spread Functions and Extended Images using Deep Learning",
      "title_zh": "使用深度学习从点扩散函数和扩展图像直接预测 Zernike 系数",
      "authors": [
        "Yong En Kok",
        "Alexander Bentley",
        "Andrew Parkes",
        "Amanda J. Wright",
        "Michael G. Somekh",
        "Michael Pound"
      ],
      "abstract": "Optical imaging quality can be severely degraded by system and sample induced\naberrations. Existing adaptive optics systems typically rely on iterative\nsearch algorithm to correct for aberrations and improve images. This study\ndemonstrates the application of convolutional neural networks to characterise\nthe optical aberration by directly predicting the Zernike coefficients from two\nto three phase-diverse optical images. We evaluated our network on 600,000\nsimulated Point Spread Function (PSF) datasets randomly generated within the\nrange of -1 to 1 radians using the first 25 Zernike coefficients. The results\nshow that using only three phase-diverse images captured above, below and at\nthe focal plane with an amplitude of 1 achieves a low RMSE of 0.10 radians on\nthe simulated PSF dataset. Furthermore, this approach directly predicts Zernike\nmodes simulated extended 2D samples, while maintaining a comparable RMSE of\n0.15 radians. We demonstrate that this approach is effective using only a\nsingle prediction step, or can be iterated a small number of times. This simple\nand straightforward technique provides rapid and accurate method for predicting\nthe aberration correction using three or less phase-diverse images, paving the\nway for evaluation on real-world dataset.",
      "tldr_zh": "本研究提出了一种使用深度学习的方法，直接从点扩散函数（Point Spread Functions, PSF）和扩展图像预测 Zernike 系数，以纠正光学成像中的系统和样本诱导像差。该方法采用卷积神经网络（convolutional neural networks）从 2 到 3 张相位多样光学图像中进行预测，避免了传统迭代搜索算法的复杂性。在模拟的 600,000 个 PSF 数据集上测试，使用前 25 个 Zernike 系数范围 -1 到 1 弧度时，该方法仅需三张图像（焦点以上、以下和焦点处）即可实现 RMSE 为 0.10 弧度的低误差；对于扩展的 2D 样本，RMSE 保持在 0.15 弧度。该技术通过单步或少量迭代预测，提供快速准确的像差校正方案，为真实数据集应用铺平了道路。",
      "categories": [
        "physics.optics",
        "cs.AI"
      ],
      "primary_category": "physics.optics",
      "comment": "12 pages, 6 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2404.15231v2",
      "published_date": "2024-04-23 17:03:53 UTC",
      "updated_date": "2024-04-24 15:23:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:52:45.349724"
    },
    {
      "arxiv_id": "2404.15392v1",
      "title": "Naïve Bayes and Random Forest for Crop Yield Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Abbas Maazallahi",
        "Sreehari Thota",
        "Naga Prasad Kondaboina",
        "Vineetha Muktineni",
        "Deepthi Annem",
        "Abhi Stephen Rokkam",
        "Mohammad Hossein Amini",
        "Mohammad Amir Salari",
        "Payam Norouzzadeh",
        "Eli Snir",
        "Bahareh Rahmani"
      ],
      "abstract": "This study analyzes crop yield prediction in India from 1997 to 2020,\nfocusing on various crops and key environmental factors. It aims to predict\nagricultural yields by utilizing advanced machine learning techniques like\nLinear Regression, Decision Tree, KNN, Na\\\"ive Bayes, K-Mean Clustering, and\nRandom Forest. The models, particularly Na\\\"ive Bayes and Random Forest,\ndemonstrate high effectiveness, as shown through data visualizations. The\nresearch concludes that integrating these analytical methods significantly\nenhances the accuracy and reliability of crop yield predictions, offering vital\ncontributions to agricultural data science.",
      "tldr_zh": "这篇论文分析了1997年至2020年印度的作物产量预测，聚焦于各种作物和关键环境因素。研究运用了多种机器学习技术，包括Linear Regression、Decision Tree、KNN、Naïve Bayes、K-Mean Clustering和Random Forest，其中Naïve Bayes和Random Forest模型显示出高有效性，并通过数据可视化进行验证。最终结论表明，整合这些方法显著提高了预测的准确性和可靠性，为农业数据科学提供了重要贡献。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.15392v1",
      "published_date": "2024-04-23 16:55:45 UTC",
      "updated_date": "2024-04-23 16:55:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:52:59.660983"
    },
    {
      "arxiv_id": "2404.15224v1",
      "title": "Deep Models for Multi-View 3D Object Recognition: A Review",
      "title_zh": "多视图 3D 对象识别的深度模型：综述",
      "authors": [
        "Mona Alzahrani",
        "Muhammad Usman",
        "Salma Kammoun",
        "Saeed Anwar",
        "Tarek Helmy"
      ],
      "abstract": "Human decision-making often relies on visual information from multiple\nperspectives or views. In contrast, machine learning-based object recognition\nutilizes information from a single image of the object. However, the\ninformation conveyed by a single image may not be sufficient for accurate\ndecision-making, particularly in complex recognition problems. The utilization\nof multi-view 3D representations for object recognition has thus far\ndemonstrated the most promising results for achieving state-of-the-art\nperformance. This review paper comprehensively covers recent progress in\nmulti-view 3D object recognition methods for 3D classification and retrieval\ntasks. Specifically, we focus on deep learning-based and transformer-based\ntechniques, as they are widely utilized and have achieved state-of-the-art\nperformance. We provide detailed information about existing deep learning-based\nand transformer-based multi-view 3D object recognition models, including the\nmost commonly used 3D datasets, camera configurations and number of views, view\nselection strategies, pre-trained CNN architectures, fusion strategies, and\nrecognition performance on 3D classification and 3D retrieval tasks.\nAdditionally, we examine various computer vision applications that use\nmulti-view classification. Finally, we highlight key findings and future\ndirections for developing multi-view 3D object recognition methods to provide\nreaders with a comprehensive understanding of the field.",
      "tldr_zh": "这篇综述论文回顾了多视角 3D 对象识别方法的发展，强调了深度学习和 Transformer 技术在 3D 分类和检索任务中的应用，因为这些方法已实现最先进性能。论文详细介绍了现有模型的关键组件，包括常用 3D 数据集、相机配置、视图选择策略、预训练 CNN 架构、融合策略，以及在相关任务上的识别性能。同时，它探讨了多视角分类在计算机视觉应用的潜力，并总结了关键发现和未来研究方向，如进一步提升模型鲁棒性和泛化能力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.15224v1",
      "published_date": "2024-04-23 16:54:31 UTC",
      "updated_date": "2024-04-23 16:54:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:53:11.017561"
    },
    {
      "arxiv_id": "2404.15390v2",
      "title": "Uncertainty in latent representations of variational autoencoders optimized for visual tasks",
      "title_zh": "针对视觉任务优化的变分自编码器的潜在表示中的不确定性",
      "authors": [
        "Josefina Catoni",
        "Domonkos Martos",
        "Ferenc Csikor",
        "Enzo Ferrante",
        "Diego H. Milone",
        "Balázs Meszéna",
        "Gergő Orbán",
        "Rodrigo Echeveste"
      ],
      "abstract": "Deep Generative Models (DGMs) can learn flexible latent variable\nrepresentations of images while avoiding intractable computations, common in\nBayesian inference. However, investigating the properties of inference in\nVariational Autoencoders (VAEs), a major class of DGMs, reveals severe problems\nin their uncertainty representations. Here we draw inspiration from classical\ncomputer vision to introduce an inductive bias into the VAE by incorporating a\nglobal explaining-away latent variable, which remedies defective inference in\nVAEs. Unlike standard VAEs, the Explaing-Away VAE (EA-VAE) provides uncertainty\nestimates that align with normative requirements across a wide spectrum of\nperceptual tasks, including image corruption, interpolation, and\nout-of-distribution detection. We find that restored inference capabilities are\ndelivered by developing a motif in the inference network (the encoder) which is\nwidespread in biological neural networks: divisive normalization. Our results\nestablish EA-VAEs as reliable tools to perform inference under deep generative\nmodels with appropriate estimates of uncertainty.",
      "tldr_zh": "本研究探讨了针对视觉任务优化的 Variational Autoencoders (VAEs) 在潜在表示中的不确定性问题，指出标准 VAEs 存在严重的推理缺陷。作者引入 inductive bias，通过添加全局 explaining-away 潜在变量并在推理网络（encoder）中实现 divisive normalization，开发了 Explaing-Away VAE (EA-VAE)，从而改善了不确定性估计。实验结果显示，EA-VAE 在图像损坏、插值和异常检测等感知任务中提供与规范要求一致的可靠不确定性，确立了其作为深度生成模型推理工具的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.15390v2",
      "published_date": "2024-04-23 16:26:29 UTC",
      "updated_date": "2025-01-23 19:13:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:53:23.459134"
    },
    {
      "arxiv_id": "2406.06538v1",
      "title": "Understanding attention-based encoder-decoder networks: a case study with chess scoresheet recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Sergio Y. Hayashi",
        "Nina S. T. Hirata"
      ],
      "abstract": "Deep neural networks are largely used for complex prediction tasks. There is\nplenty of empirical evidence of their successful end-to-end training for a\ndiversity of tasks. Success is often measured based solely on the final\nperformance of the trained network, and explanations on when, why and how they\nwork are less emphasized. In this paper we study encoder-decoder recurrent\nneural networks with attention mechanisms for the task of reading handwritten\nchess scoresheets. Rather than prediction performance, our concern is to better\nunderstand how learning occurs in these type of networks. We characterize the\ntask in terms of three subtasks, namely input-output alignment, sequential\npattern recognition, and handwriting recognition, and experimentally\ninvestigate which factors affect their learning. We identify competition,\ncollaboration and dependence relations between the subtasks, and argue that\nsuch knowledge might help one to better balance factors to properly train a\nnetwork.",
      "tldr_zh": "本论文研究了基于注意力机制的 encoder-decoder recurrent neural networks 在手写国际象棋记分卡识别任务中的学习过程，重点关注网络的内部机制而非仅凭最终性能。作者将任务分解为三个子任务：input-output alignment、sequential pattern recognition 和 handwriting recognition，并通过实验调查了影响这些子任务学习的因素。研究发现，子任务之间存在竞争、协作和依赖关系，这种理解有助于更好地平衡训练因素，提升网络的整体表现。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "This work was accepted and published in the 2022 26th International\n  Conference on Pattern Recognition (ICPR)",
      "pdf_url": "http://arxiv.org/pdf/2406.06538v1",
      "published_date": "2024-04-23 16:23:18 UTC",
      "updated_date": "2024-04-23 16:23:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:53:34.447839"
    },
    {
      "arxiv_id": "2404.15141v1",
      "title": "CutDiffusion: A Simple, Fast, Cheap, and Strong Diffusion Extrapolation Method",
      "title_zh": "翻译失败",
      "authors": [
        "Mingbao Lin",
        "Zhihang Lin",
        "Wengyi Zhan",
        "Liujuan Cao",
        "Rongrong Ji"
      ],
      "abstract": "Transforming large pre-trained low-resolution diffusion models to cater to\nhigher-resolution demands, i.e., diffusion extrapolation, significantly\nimproves diffusion adaptability. We propose tuning-free CutDiffusion, aimed at\nsimplifying and accelerating the diffusion extrapolation process, making it\nmore affordable and improving performance. CutDiffusion abides by the existing\npatch-wise extrapolation but cuts a standard patch diffusion process into an\ninitial phase focused on comprehensive structure denoising and a subsequent\nphase dedicated to specific detail refinement. Comprehensive experiments\nhighlight the numerous almighty advantages of CutDiffusion: (1) simple method\nconstruction that enables a concise higher-resolution diffusion process without\nthird-party engagement; (2) fast inference speed achieved through a single-step\nhigher-resolution diffusion process, and fewer inference patches required; (3)\ncheap GPU cost resulting from patch-wise inference and fewer patches during the\ncomprehensive structure denoising; (4) strong generation performance, stemming\nfrom the emphasis on specific detail refinement.",
      "tldr_zh": "本论文提出 CutDiffusion，一种无需调优的简单、快速、廉价且高效的扩散外推方法，用于将预训练的低分辨率扩散模型适应到高分辨率需求。CutDiffusion 基于现有的 patch-wise extrapolation，但将标准补丁扩散过程分为两个阶段：初始阶段专注于全面结构去噪，以及后续阶段致力于特定细节精炼。这种设计确保了简洁的更高分辨率扩散过程，同时减少第三方依赖。实验结果显示，CutDiffusion 在生成性能上表现出色，比传统方法更快、更省 GPU 资源，并显著提升整体适应性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.15141v1",
      "published_date": "2024-04-23 15:47:58 UTC",
      "updated_date": "2024-04-23 15:47:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:53:47.166147"
    },
    {
      "arxiv_id": "2404.15121v1",
      "title": "Taming Diffusion Probabilistic Models for Character Control",
      "title_zh": "翻译失败",
      "authors": [
        "Rui Chen",
        "Mingyi Shi",
        "Shaoli Huang",
        "Ping Tan",
        "Taku Komura",
        "Xuelin Chen"
      ],
      "abstract": "We present a novel character control framework that effectively utilizes\nmotion diffusion probabilistic models to generate high-quality and diverse\ncharacter animations, responding in real-time to a variety of dynamic\nuser-supplied control signals. At the heart of our method lies a\ntransformer-based Conditional Autoregressive Motion Diffusion Model (CAMDM),\nwhich takes as input the character's historical motion and can generate a range\nof diverse potential future motions conditioned on high-level, coarse user\ncontrol. To meet the demands for diversity, controllability, and computational\nefficiency required by a real-time controller, we incorporate several key\nalgorithmic designs. These include separate condition tokenization,\nclassifier-free guidance on past motion, and heuristic future trajectory\nextension, all designed to address the challenges associated with taming motion\ndiffusion probabilistic models for character control. As a result, our work\nrepresents the first model that enables real-time generation of high-quality,\ndiverse character animations based on user interactive control, supporting\nanimating the character in multiple styles with a single unified model. We\nevaluate our method on a diverse set of locomotion skills, demonstrating the\nmerits of our method over existing character controllers. Project page and\nsource codes: https://aiganimation.github.io/CAMDM/",
      "tldr_zh": "本文提出了一种新型角色控制框架，利用运动扩散概率模型（Diffusion Probabilistic Models）生成高质量、多样化的角色动画，并实时响应用户提供的动态控制信号。核心是基于Transformer's Conditional Autoregressive Motion Diffusion Model (CAMDM)，该模型以角色历史运动为输入，结合高水平用户控制生成多种潜在未来运动。为了实现多样性、可控性和计算效率，该框架引入了条件标记化、基于过去运动的分类器免费指导，以及启发式未来轨迹扩展等关键设计。实验结果表明，该方法在各种运动技能上优于现有控制器，并首次支持使用单一统一模型实现实时、多风格角色动画生成。",
      "categories": [
        "cs.GR",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.GR",
      "comment": "Accepted by SIGGRAPH 2024 (Conference Track). Project page and source\n  codes: https://aiganimation.github.io/CAMDM/",
      "pdf_url": "http://arxiv.org/pdf/2404.15121v1",
      "published_date": "2024-04-23 15:20:17 UTC",
      "updated_date": "2024-04-23 15:20:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:53:58.451989"
    },
    {
      "arxiv_id": "2405.00706v3",
      "title": "From Complexity to Clarity: How AI Enhances Perceptions of Scientists and the Public's Understanding of Science",
      "title_zh": "翻译失败",
      "authors": [
        "David M. Markowitz"
      ],
      "abstract": "This paper evaluated the effectiveness of using generative AI to simplify\nscience communication and enhance the public's understanding of science. By\ncomparing lay summaries of journal articles from PNAS, yoked to those generated\nby AI, this work first assessed linguistic simplicity differences across such\nsummaries and public perceptions in follow-up experiments. Specifically, Study\n1a analyzed simplicity features of PNAS abstracts (scientific summaries) and\nsignificance statements (lay summaries), observing that lay summaries were\nindeed linguistically simpler, but effect size differences were small. Study 1b\nused a large language model, GPT-4, to create significance statements based on\npaper abstracts and this more than doubled the average effect size without\nfine-tuning. Study 2 experimentally demonstrated that simply-written GPT\nsummaries facilitated more favorable perceptions of scientists (they were\nperceived as more credible and trustworthy, but less intelligent) than more\ncomplexly-written human PNAS summaries. Crucially, Study 3 experimentally\ndemonstrated that participants comprehended scientific writing better after\nreading simple GPT summaries compared to complex PNAS summaries. In their own\nwords, participants also summarized scientific papers in a more detailed and\nconcrete manner after reading GPT summaries compared to PNAS summaries of the\nsame article. AI has the potential to engage scientific communities and the\npublic via a simple language heuristic, advocating for its integration into\nscientific dissemination for a more informed society.",
      "tldr_zh": "这篇论文评估了 generative AI 在简化科学传播方面的有效性，特别通过比较 PNAS 期刊文章的 lay summaries 与 GPT-4 生成的摘要。研究 1a 和 1b 发现，AI 生成的摘要显著提高了语言简单性，平均效果大小翻倍，而无需微调。实验结果显示（研究 2 和 3），简单 GPT 摘要使科学家被视为更可信和可信赖（但较不智能），并提升了公众对科学内容的理解和详细总结能力。最终，论文主张将 AI 整合到科学传播中，以促进更广泛的公众参与和更知情的社会。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "17 pages",
      "pdf_url": "http://arxiv.org/pdf/2405.00706v3",
      "published_date": "2024-04-23 14:43:35 UTC",
      "updated_date": "2024-08-28 15:29:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:54:11.681615"
    },
    {
      "arxiv_id": "2404.15388v1",
      "title": "ML-based identification of the interface regions for coupling local and nonlocal models",
      "title_zh": "基于机器学习的局部与非局部模型耦合接口区域识别",
      "authors": [
        "Noujoud Nader",
        "Patrick Diehl",
        "Marta D'Elia",
        "Christian Glusa",
        "Serge Prudhomme"
      ],
      "abstract": "Local-nonlocal coupling approaches combine the computational efficiency of\nlocal models and the accuracy of nonlocal models. However, the coupling process\nis challenging, requiring expertise to identify the interface between local and\nnonlocal regions. This study introduces a machine learning-based approach to\nautomatically detect the regions in which the local and nonlocal models should\nbe used in a coupling approach. This identification process uses the loading\nfunctions and provides as output the selected model at the grid points.\nTraining is based on datasets of loading functions for which reference coupling\nconfigurations are computed using accurate coupled solutions, where accuracy is\nmeasured in terms of the relative error between the solution to the coupling\napproach and the solution to the nonlocal model. We study two approaches that\ndiffer from one another in terms of the data structure. The first approach,\nreferred to as the full-domain input data approach, inputs the full load vector\nand outputs a full label vector. In this case, the classification process is\ncarried out globally. The second approach consists of a window-based approach,\nwhere loads are preprocessed and partitioned into windows and the problem is\nformulated as a node-wise classification approach in which the central point of\neach window is treated individually. The classification problems are solved via\ndeep learning algorithms based on convolutional neural networks. The\nperformance of these approaches is studied on one-dimensional numerical\nexamples using F1-scores and accuracy metrics. In particular, it is shown that\nthe windowing approach provides promising results, achieving an accuracy of\n0.96 and an F1-score of 0.97. These results underscore the potential of the\napproach to automate coupling processes, leading to more accurate and\ncomputationally efficient solutions for material science applications.",
      "tldr_zh": "这篇论文提出了一种基于机器学习的 方法，用于自动识别本地模型（local models）和非本地模型（nonlocal models）耦合的界面区域，以简化耦合过程并减少手动干预。方法包括两种接近：全域输入数据方法（full-domain input data approach），对整个负载向量进行全局分类；以及窗口-based 方法（window-based approach），将负载预处理成窗口并进行节点-wise 分类，两者均使用卷积神经网络（convolutional neural networks）进行训练和预测。实验在二维数值例子上评估，使用 F1-scores 和 accuracy 指标，窗口方法表现出色，达到0.96的准确率和0.97的F1-score。这些结果突显了该方法的潜力，可自动化耦合过程，提高材料科学应用的计算效率和准确性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "23 pages, 14 figures, research paper",
      "pdf_url": "http://arxiv.org/pdf/2404.15388v1",
      "published_date": "2024-04-23 14:19:36 UTC",
      "updated_date": "2024-04-23 14:19:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:54:24.056809"
    },
    {
      "arxiv_id": "2404.15070v2",
      "title": "BotDGT: Dynamicity-aware Social Bot Detection with Dynamic Graph Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Buyun He",
        "Yingguang Yang",
        "Qi Wu",
        "Hao Liu",
        "Renyu Yang",
        "Hao Peng",
        "Xiang Wang",
        "Yong Liao",
        "Pengyuan Zhou"
      ],
      "abstract": "Detecting social bots has evolved into a pivotal yet intricate task, aimed at\ncombating the dissemination of misinformation and preserving the authenticity\nof online interactions. While earlier graph-based approaches, which leverage\ntopological structure of social networks, yielded notable outcomes, they\noverlooked the inherent dynamicity of social networks -- In reality, they\nlargely depicted the social network as a static graph and solely relied on its\nmost recent state. Due to the absence of dynamicity modeling, such approaches\nare vulnerable to evasion, particularly when advanced social bots interact with\nother users to camouflage identities and escape detection. To tackle these\nchallenges, we propose BotDGT, a novel framework that not only considers the\ntopological structure, but also effectively incorporates dynamic nature of\nsocial network. Specifically, we characterize a social network as a dynamic\ngraph. A structural module is employed to acquire topological information from\neach historical snapshot. Additionally, a temporal module is proposed to\nintegrate historical context and model the evolving behavior patterns exhibited\nby social bots and legitimate users. Experimental results demonstrate the\nsuperiority of BotDGT against the leading methods that neglected the dynamic\nnature of social networks in terms of accuracy, recall, and F1-score.",
      "tldr_zh": "该论文提出BotDGT框架，用于检测社交bots，旨在解决传统图-based方法忽略社交网络动态性的问题，从而提升检测准确性和鲁棒性。BotDGT将社交网络建模为动态图，结合结构模块提取拓扑信息和时间模块整合历史上下文，以捕捉bots和合法用户的演化行为模式。实验结果显示，BotDGT在准确率、召回率和F1-score上优于领先的静态方法，为有效对抗虚假信息传播提供了新途径。",
      "categories": [
        "cs.SI",
        "cs.AI"
      ],
      "primary_category": "cs.SI",
      "comment": "IJCAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.15070v2",
      "published_date": "2024-04-23 14:19:13 UTC",
      "updated_date": "2024-04-24 08:01:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:54:33.573311"
    },
    {
      "arxiv_id": "2404.15065v2",
      "title": "Formal Verification of Graph Convolutional Networks with Uncertain Node Features and Uncertain Graph Structure",
      "title_zh": "翻译失败",
      "authors": [
        "Tobias Ladner",
        "Michael Eichelbeck",
        "Matthias Althoff"
      ],
      "abstract": "Graph neural networks are becoming increasingly popular in the field of\nmachine learning due to their unique ability to process data structured in\ngraphs. They have also been applied in safety-critical environments where\nperturbations inherently occur. However, these perturbations require us to\nformally verify neural networks before their deployment in safety-critical\nenvironments as neural networks are prone to adversarial attacks. While there\nexists research on the formal verification of neural networks, there is no work\nverifying the robustness of generic graph convolutional network architectures\nwith uncertainty in the node features and in the graph structure over multiple\nmessage-passing steps. This work addresses this research gap by explicitly\npreserving the non-convex dependencies of all elements in the underlying\ncomputations through reachability analysis with (matrix) polynomial zonotopes.\nWe demonstrate our approach on three popular benchmark datasets.",
      "tldr_zh": "本研究针对图卷积网络(Graph Convolutional Networks)中节点特征和图结构的不确定性，提出了一种正式验证(Formal Verification)方法，以提升其在安全关键环境(safety-critical environments)中的鲁棒性。现有工作虽有神经网络验证研究，但未覆盖图神经网络(Graph Neural Networks)在多步消息传递(message-passing)下的不确定性问题。作者通过可达性分析(Reachability Analysis)使用矩阵多项式 zonotopes 保留底层计算的非凸依赖，从而实现对通用图卷积网络架构的鲁棒性验证。在三个流行基准数据集上演示了该方法的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "published at Transactions on Machine Learning Research (TMLR) 2025",
      "pdf_url": "http://arxiv.org/pdf/2404.15065v2",
      "published_date": "2024-04-23 14:12:48 UTC",
      "updated_date": "2025-04-16 13:23:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:54:45.721793"
    },
    {
      "arxiv_id": "2404.15059v1",
      "title": "Using deep reinforcement learning to promote sustainable human behaviour on a common pool resource problem",
      "title_zh": "翻译失败",
      "authors": [
        "Raphael Koster",
        "Miruna Pîslar",
        "Andrea Tacchetti",
        "Jan Balaguer",
        "Leqi Liu",
        "Romuald Elie",
        "Oliver P. Hauser",
        "Karl Tuyls",
        "Matt Botvinick",
        "Christopher Summerfield"
      ],
      "abstract": "A canonical social dilemma arises when finite resources are allocated to a\ngroup of people, who can choose to either reciprocate with interest, or keep\nthe proceeds for themselves. What resource allocation mechanisms will encourage\nlevels of reciprocation that sustain the commons? Here, in an iterated\nmultiplayer trust game, we use deep reinforcement learning (RL) to design an\nallocation mechanism that endogenously promotes sustainable contributions from\nhuman participants to a common pool resource. We first trained neural networks\nto behave like human players, creating a stimulated economy that allowed us to\nstudy how different mechanisms influenced the dynamics of receipt and\nreciprocation. We then used RL to train a social planner to maximise aggregate\nreturn to players. The social planner discovered a redistributive policy that\nled to a large surplus and an inclusive economy, in which players made roughly\nequal gains. The RL agent increased human surplus over baseline mechanisms\nbased on unrestricted welfare or conditional cooperation, by conditioning its\ngenerosity on available resources and temporarily sanctioning defectors by\nallocating fewer resources to them. Examining the AI policy allowed us to\ndevelop an explainable mechanism that performed similarly and was more popular\namong players. Deep reinforcement learning can be used to discover mechanisms\nthat promote sustainable human behaviour.",
      "tldr_zh": "这篇论文使用 deep reinforcement learning (RL) 来设计资源分配机制，旨在解决 common pool resource problem 中的社会困境，促进可持续的人类贡献行为。研究者先训练神经网络模拟人类玩家，创建模拟经济，然后用 RL 训练一个社会规划者，开发出一种再分配政策，通过根据可用资源调整慷慨度和暂时惩罚叛逃者，提高了玩家的总体剩余。实验结果显示，该机制比基线方法（如无限制福利或条件合作）提升了人类收益，并衍生出一个可解释的机制，获得玩家更广泛认可。",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.GT"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.15059v1",
      "published_date": "2024-04-23 14:07:39 UTC",
      "updated_date": "2024-04-23 14:07:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:54:59.588945"
    },
    {
      "arxiv_id": "2404.15058v1",
      "title": "A Mechanism-Based Approach to Mitigating Harms from Persuasive Generative AI",
      "title_zh": "翻译失败",
      "authors": [
        "Seliem El-Sayed",
        "Canfer Akbulut",
        "Amanda McCroskery",
        "Geoff Keeling",
        "Zachary Kenton",
        "Zaria Jalan",
        "Nahema Marchal",
        "Arianna Manzini",
        "Toby Shevlane",
        "Shannon Vallor",
        "Daniel Susser",
        "Matija Franklin",
        "Sophie Bridgers",
        "Harry Law",
        "Matthew Rahtz",
        "Murray Shanahan",
        "Michael Henry Tessler",
        "Arthur Douillard",
        "Tom Everitt",
        "Sasha Brown"
      ],
      "abstract": "Recent generative AI systems have demonstrated more advanced persuasive\ncapabilities and are increasingly permeating areas of life where they can\ninfluence decision-making. Generative AI presents a new risk profile of\npersuasion due the opportunity for reciprocal exchange and prolonged\ninteractions. This has led to growing concerns about harms from AI persuasion\nand how they can be mitigated, highlighting the need for a systematic study of\nAI persuasion. The current definitions of AI persuasion are unclear and related\nharms are insufficiently studied. Existing harm mitigation approaches\nprioritise harms from the outcome of persuasion over harms from the process of\npersuasion. In this paper, we lay the groundwork for the systematic study of AI\npersuasion. We first put forward definitions of persuasive generative AI. We\ndistinguish between rationally persuasive generative AI, which relies on\nproviding relevant facts, sound reasoning, or other forms of trustworthy\nevidence, and manipulative generative AI, which relies on taking advantage of\ncognitive biases and heuristics or misrepresenting information. We also put\nforward a map of harms from AI persuasion, including definitions and examples\nof economic, physical, environmental, psychological, sociocultural, political,\nprivacy, and autonomy harm. We then introduce a map of mechanisms that\ncontribute to harmful persuasion. Lastly, we provide an overview of approaches\nthat can be used to mitigate against process harms of persuasion, including\nprompt engineering for manipulation classification and red teaming. Future work\nwill operationalise these mitigations and study the interaction between\ndifferent types of mechanisms of persuasion.",
      "tldr_zh": "这篇论文提出了一种基于机制的方法来缓解说服性生成式 AI 的危害，强调生成式 AI 通过互惠交流和持久互动可能带来的新风险。论文首先定义了 rationally persuasive generative AI（依赖事实和推理的说服）和 manipulative generative AI（利用认知偏差或误导信息），并映射了包括经济、身体、心理、社会文化、政治、隐私和自治等领域的潜在危害。接着，论文介绍了导致有害说服的机制地图，并概述了缓解策略，如提示工程用于操纵分类和 red teaming 测试。未来工作将进一步操作化这些方法，并探索不同说服机制的交互效应。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.15058v1",
      "published_date": "2024-04-23 14:07:20 UTC",
      "updated_date": "2024-04-23 14:07:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:55:11.816491"
    },
    {
      "arxiv_id": "2404.15045v1",
      "title": "Multi-Head Mixture-of-Experts",
      "title_zh": "翻译失败",
      "authors": [
        "Xun Wu",
        "Shaohan Huang",
        "Wenhui Wang",
        "Furu Wei"
      ],
      "abstract": "Sparse Mixtures of Experts (SMoE) scales model capacity without significant\nincreases in training and inference costs, but exhibits the following two\nissues: (1) Low expert activation, where only a small subset of experts are\nactivated for optimization. (2) Lacking fine-grained analytical capabilities\nfor multiple semantic concepts within individual tokens. We propose Multi-Head\nMixture-of-Experts (MH-MoE), which employs a multi-head mechanism to split each\ntoken into multiple sub-tokens. These sub-tokens are then assigned to and\nprocessed by a diverse set of experts in parallel, and seamlessly reintegrated\ninto the original token form. The multi-head mechanism enables the model to\ncollectively attend to information from various representation spaces within\ndifferent experts, while significantly enhances expert activation, thus deepens\ncontext understanding and alleviate overfitting. Moreover, our MH-MoE is\nstraightforward to implement and decouples from other SMoE optimization\nmethods, making it easy to integrate with other SMoE models for enhanced\nperformance. Extensive experimental results across three tasks: English-focused\nlanguage modeling, Multi-lingual language modeling and Masked multi-modality\nmodeling tasks, demonstrate the effectiveness of MH-MoE.",
      "tldr_zh": "该研究针对 Sparse Mixtures of Experts (SMoE) 模型存在的两个问题——低专家激活率和对单个 token 内多个语义概念的细粒度分析能力不足——提出了一种新的 Multi-Head Mixture-of-Experts (MH-MoE) 框架。MH-MoE 通过 multi-head 机制将每个 token 分割成多个 sub-tokens，这些 sub-tokens 被并行分配到不同 experts 处理，然后重新整合，从而提升专家激活、深化上下文理解并缓解过拟合。该框架易于实现且可与其它 SMoE 优化方法解耦，实验在英语语言建模、多语言建模和掩码多模态建模任务上证明了其有效性，显著提升了模型性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.15045v1",
      "published_date": "2024-04-23 13:47:09 UTC",
      "updated_date": "2024-04-23 13:47:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:55:24.386157"
    },
    {
      "arxiv_id": "2404.15042v2",
      "title": "Leverage Variational Graph Representation For Model Poisoning on Federated Learning",
      "title_zh": "利用变分图表示进行联邦学习中的模型投毒",
      "authors": [
        "Kai Li",
        "Xin Yuan",
        "Jingjing Zheng",
        "Wei Ni",
        "Falko Dressler",
        "Abbas Jamalipour"
      ],
      "abstract": "This paper puts forth a new training data-untethered model poisoning (MP)\nattack on federated learning (FL). The new MP attack extends an adversarial\nvariational graph autoencoder (VGAE) to create malicious local models based\nsolely on the benign local models overheard without any access to the training\ndata of FL. Such an advancement leads to the VGAE-MP attack that is not only\nefficacious but also remains elusive to detection. VGAE-MP attack extracts\ngraph structural correlations among the benign local models and the training\ndata features, adversarially regenerates the graph structure, and generates\nmalicious local models using the adversarial graph structure and benign models'\nfeatures. Moreover, a new attacking algorithm is presented to train the\nmalicious local models using VGAE and sub-gradient descent, while enabling an\noptimal selection of the benign local models for training the VGAE. Experiments\ndemonstrate a gradual drop in FL accuracy under the proposed VGAE-MP attack and\nthe ineffectiveness of existing defense mechanisms in detecting the attack,\nposing a severe threat to FL.",
      "tldr_zh": "本文提出了一种新型模型毒化（model poisoning，MP）攻击，名为VGAE-MP，针对联邦学习（federated learning，FL），它无需访问训练数据，仅基于监听到的良性本地模型来生成恶意模型。该攻击利用对抗性变分图自编码器（adversarial variational graph autoencoder，VGAE）提取良性模型间的图结构相关性，进行逆向生成并结合特征创建恶意模型，同时引入一个基于VGAE和子梯度下降的攻击算法来优化模型选择。实验结果显示，该攻击会导致FL准确率逐步下降，且现有防御机制无法有效检测，凸显了对FL系统的严重安全威胁。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "12 pages, 8 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2404.15042v2",
      "published_date": "2024-04-23 13:43:56 UTC",
      "updated_date": "2024-04-24 16:08:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:55:37.295377"
    },
    {
      "arxiv_id": "2404.15034v1",
      "title": "Deep Multi-View Channel-Wise Spatio-Temporal Network for Traffic Flow Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Hao Miao",
        "Senzhang Wang",
        "Meiyue Zhang",
        "Diansheng Guo",
        "Funing Sun",
        "Fan Yang"
      ],
      "abstract": "Accurately forecasting traffic flows is critically important to many real\napplications including public safety and intelligent transportation systems.\nThe challenges of this problem include both the dynamic mobility patterns of\nthe people and the complex spatial-temporal correlations of the urban traffic\ndata. Meanwhile, most existing models ignore the diverse impacts of the various\ntraffic observations (e.g. vehicle speed and road occupancy) on the traffic\nflow prediction, and different traffic observations can be considered as\ndifferent channels of input features. We argue that the analysis in\nmultiple-channel traffic observations might help to better address this\nproblem. In this paper, we study the novel problem of multi-channel traffic\nflow prediction, and propose a deep \\underline{M}ulti-\\underline{V}iew\n\\underline{C}hannel-wise \\underline{S}patio-\\underline{T}emporal\n\\underline{Net}work (MVC-STNet) model to effectively address it. Specifically,\nwe first construct the localized and globalized spatial graph where the\nmulti-view fusion module is used to effectively extract the local and global\nspatial dependencies. Then LSTM is used to learn the temporal correlations. To\neffectively model the different impacts of various traffic observations on\ntraffic flow prediction, a channel-wise graph convolutional network is also\ndesigned. Extensive experiments are conducted over the PEMS04 and PEMS08\ndatasets. The results demonstrate that the proposed MVC-STNet outperforms\nstate-of-the-art methods by a large margin.",
      "tldr_zh": "这篇论文针对交通流量预测的挑战，提出了一种深度 Multi-View Channel-Wise Spatio-Temporal Network (MVC-STNet) 模型，以处理动态人群移动模式和复杂空间-时间相关性。模型通过多视图融合模块提取局部和全局空间依赖，使用 LSTM 学习时间相关性，并设计通道-wise 图卷积网络来分析不同交通观察（如车辆速度和道路占用率）对预测的影响。实验结果显示，在 PEMS04 和 PEMS08 数据集上，MVC-STNet 比现有方法大幅提升准确率，为智能交通系统提供了更有效的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by AAAI2020 workshop",
      "pdf_url": "http://arxiv.org/pdf/2404.15034v1",
      "published_date": "2024-04-23 13:39:04 UTC",
      "updated_date": "2024-04-23 13:39:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:55:47.187978"
    },
    {
      "arxiv_id": "2404.15022v1",
      "title": "A review of deep learning-based information fusion techniques for multimodal medical image classification",
      "title_zh": "翻译失败",
      "authors": [
        "Yihao Li",
        "Mostafa El Habib Daho",
        "Pierre-Henri Conze",
        "Rachid Zeghlache",
        "Hugo Le Boité",
        "Ramin Tadayoni",
        "Béatrice Cochener",
        "Mathieu Lamard",
        "Gwenolé Quellec"
      ],
      "abstract": "Multimodal medical imaging plays a pivotal role in clinical diagnosis and\nresearch, as it combines information from various imaging modalities to provide\na more comprehensive understanding of the underlying pathology. Recently, deep\nlearning-based multimodal fusion techniques have emerged as powerful tools for\nimproving medical image classification. This review offers a thorough analysis\nof the developments in deep learning-based multimodal fusion for medical\nclassification tasks. We explore the complementary relationships among\nprevalent clinical modalities and outline three main fusion schemes for\nmultimodal classification networks: input fusion, intermediate fusion\n(encompassing single-level fusion, hierarchical fusion, and attention-based\nfusion), and output fusion. By evaluating the performance of these fusion\ntechniques, we provide insight into the suitability of different network\narchitectures for various multimodal fusion scenarios and application domains.\nFurthermore, we delve into challenges related to network architecture\nselection, handling incomplete multimodal data management, and the potential\nlimitations of multimodal fusion. Finally, we spotlight the promising future of\nTransformer-based multimodal fusion techniques and give recommendations for\nfuture research in this rapidly evolving field.",
      "tldr_zh": "这篇综述论文审视了基于深度学习的 multimodal medical image classification 中的信息融合技术，强调了多模态成像在临床诊断中的重要性及其与深度学习相结合的潜力。论文概述了三种主要融合方案：input fusion、intermediate fusion（包括 single-level fusion、hierarchical fusion 和 attention-based fusion）以及 output fusion，并评估了这些方法在不同场景下的性能和适用性。作者讨论了面临的挑战，如网络架构选择、处理不完整 multimodal 数据以及潜在限制，同时展望了 Transformer-based multimodal fusion 的前景，并为未来研究提供推荐。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.15022v1",
      "published_date": "2024-04-23 13:31:18 UTC",
      "updated_date": "2024-04-23 13:31:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:55:59.015160"
    },
    {
      "arxiv_id": "2404.14994v3",
      "title": "Transformers Can Represent $n$-gram Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Anej Svete",
        "Ryan Cotterell"
      ],
      "abstract": "Existing work has analyzed the representational capacity of the transformer\narchitecture by means of formal models of computation. However, the focus so\nfar has been on analyzing the architecture in terms of language\n\\emph{acceptance}. We contend that this is an ill-suited problem in the study\nof \\emph{language models} (LMs), which are definitionally \\emph{probability\ndistributions} over strings. In this paper, we focus on the relationship\nbetween transformer LMs and $n$-gram LMs, a simple and historically relevant\nclass of language models. We show that transformer LMs using the hard or sparse\nattention mechanisms can exactly represent any $n$-gram LM, giving us a\nconcrete lower bound on their probabilistic representational capacity. This\nprovides a first step towards understanding the mechanisms that transformer LMs\ncan use to represent probability distributions over strings.",
      "tldr_zh": "该研究批评了现有工作仅从语言接受角度分析transformer架构的表示能力，认为这不适用于语言模型（LMs），后者本质上是字符串上的概率分布。论文探讨了transformer LMs与n-gram LMs的关系，证明使用hard attention或sparse attention机制的transformer LMs可以精确表示任何n-gram LM，从而为transformer LMs的概率表示能力提供了具体下界。这一发现有助于理解transformer LMs如何机制性地表示字符串概率分布。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CC",
        "cs.FL",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.14994v3",
      "published_date": "2024-04-23 12:51:37 UTC",
      "updated_date": "2024-06-20 15:21:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:56:10.389849"
    },
    {
      "arxiv_id": "2404.14986v1",
      "title": "$\\texttt{MiniMol}$: A Parameter-Efficient Foundation Model for Molecular Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Kerstin Kläser",
        "Błażej Banaszewski",
        "Samuel Maddrell-Mander",
        "Callum McLean",
        "Luis Müller",
        "Ali Parviz",
        "Shenyang Huang",
        "Andrew Fitzgibbon"
      ],
      "abstract": "In biological tasks, data is rarely plentiful as it is generated from\nhard-to-gather measurements. Therefore, pre-training foundation models on large\nquantities of available data and then transfer to low-data downstream tasks is\na promising direction. However, how to design effective foundation models for\nmolecular learning remains an open question, with existing approaches typically\nfocusing on models with large parameter capacities. In this work, we propose\n$\\texttt{MiniMol}$, a foundational model for molecular learning with 10 million\nparameters. $\\texttt{MiniMol}$ is pre-trained on a mix of roughly 3300 sparsely\ndefined graph- and node-level tasks of both quantum and biological nature. The\npre-training dataset includes approximately 6 million molecules and 500 million\nlabels. To demonstrate the generalizability of $\\texttt{MiniMol}$ across tasks,\nwe evaluate it on downstream tasks from the Therapeutic Data Commons (TDC)\nADMET group showing significant improvements over the prior state-of-the-art\nfoundation model across 17 tasks. $\\texttt{MiniMol}$ will be a public and\nopen-sourced model for future research.",
      "tldr_zh": "本研究提出$\\texttt{MiniMol}$，一个仅有1000万参数的分子学习基础模型，旨在解决生物任务中数据稀缺的挑战，通过高效预训练来提升下游任务性能。$\\texttt{MiniMol}$在约3300个稀疏定义的图级和节点级任务（包括量子和生物性质）上进行预训练，数据集涵盖600万分子和5亿标签。实验结果显示，该模型在Therapeutic Data Commons (TDC) ADMET组的17个下游任务上，比现有最先进的基础模型取得了显著改进。$\\texttt{MiniMol}$将作为公开开源模型，支持未来的分子学习研究。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.14986v1",
      "published_date": "2024-04-23 12:43:15 UTC",
      "updated_date": "2024-04-23 12:43:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:56:24.411285"
    },
    {
      "arxiv_id": "2404.14979v3",
      "title": "SGFormer: Spherical Geometry Transformer for 360 Depth Estimation",
      "title_zh": "翻译失败",
      "authors": [
        "Junsong Zhang",
        "Zisong Chen",
        "Chunyu Lin",
        "Lang Nie",
        "Zhijie Shen",
        "Kang Liao",
        "Junda Huang",
        "Yao Zhao"
      ],
      "abstract": "Panoramic distortion poses a significant challenge in 360 depth estimation,\nparticularly pronounced at the north and south poles. Existing methods either\nadopt a bi-projection fusion strategy to remove distortions or model long-range\ndependencies to capture global structures, which can result in either unclear\nstructure or insufficient local perception. In this paper, we propose a\nspherical geometry transformer, named SGFormer, to address the above issues,\nwith an innovative step to integrate spherical geometric priors into vision\ntransformers. To this end, we retarget the transformer decoder to a spherical\nprior decoder (termed SPDecoder), which endeavors to uphold the integrity of\nspherical structures during decoding. Concretely, we leverage bipolar\nre-projection, circular rotation, and curve local embedding to preserve the\nspherical characteristics of equidistortion, continuity, and surface distance,\nrespectively. Furthermore, we present a query-based global conditional position\nembedding to compensate for spatial structure at varying resolutions. It not\nonly boosts the global perception of spatial position but also sharpens the\ndepth structure across different patches. Finally, we conduct extensive\nexperiments on popular benchmarks, demonstrating our superiority over\nstate-of-the-art solutions.",
      "tldr_zh": "该论文提出SGFormer，一种球形几何Transformer，用于解决360度深度估计中的全景扭曲问题，尤其是南北极的挑战。SGFormer通过将球形几何先验集成到视觉Transformer中，设计了Spherical Prior Decoder (SPDecoder)，利用双极重新投影、圆形旋转和曲线局部嵌入来保留等扭曲、连续性和表面距离等球形特性。此外，该框架引入基于查询的全局条件位置嵌入，以提升不同分辨率的全局空间感知和深度结构。实验结果表明，SGFormer在流行基准上优于现有最先进方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.14979v3",
      "published_date": "2024-04-23 12:36:24 UTC",
      "updated_date": "2025-02-25 15:14:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:56:34.570494"
    },
    {
      "arxiv_id": "2406.06537v1",
      "title": "Interactive Generation of Laparoscopic Videos with Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Ivan Iliash",
        "Simeon Allmendinger",
        "Felix Meissen",
        "Niklas Kühl",
        "Daniel Rückert"
      ],
      "abstract": "Generative AI, in general, and synthetic visual data generation, in specific,\nhold much promise for benefiting surgical training by providing photorealism to\nsimulation environments. Current training methods primarily rely on reading\nmaterials and observing live surgeries, which can be time-consuming and\nimpractical. In this work, we take a significant step towards improving the\ntraining process. Specifically, we use diffusion models in combination with a\nzero-shot video diffusion method to interactively generate realistic\nlaparoscopic images and videos by specifying a surgical action through text and\nguiding the generation with tool positions through segmentation masks. We\ndemonstrate the performance of our approach using the publicly available Cholec\ndataset family and evaluate the fidelity and factual correctness of our\ngenerated images using a surgical action recognition model as well as the\npixel-wise F1-score for the spatial control of tool generation. We achieve an\nFID of 38.097 and an F1-score of 0.71.",
      "tldr_zh": "本文提出了一种交互式生成腹腔镜视频的方法，使用 diffusion models 和 zero-shot video diffusion method，通过文本指定手术动作并利用 segmentation masks 引导工具位置，从而为外科训练提供逼真的合成视觉数据。该方法解决了传统训练依赖阅读材料和观察活体手术的局限性，提高了训练效率。在公开的 Cholec 数据集上实验，生成的图像实现了 FID 38.097 和 F1-score 0.71，证明了其高保真度和事实正确性。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "7 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.06537v1",
      "published_date": "2024-04-23 12:36:07 UTC",
      "updated_date": "2024-04-23 12:36:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:56:48.203522"
    },
    {
      "arxiv_id": "2404.16880v3",
      "title": "Atomas: Hierarchical Alignment on Molecule-Text for Unified Molecule Understanding and Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Yikun Zhang",
        "Geyan Ye",
        "Chaohao Yuan",
        "Bo Han",
        "Long-Kai Huang",
        "Jianhua Yao",
        "Wei Liu",
        "Yu Rong"
      ],
      "abstract": "Molecule-and-text cross-modal representation learning has emerged as a\npromising direction for enhancing the quality of molecular representation,\nthereby improving performance in various scientific fields. However, most\napproaches employ a global alignment approach to learn the knowledge from\ndifferent modalities that may fail to capture fine-grained information, such as\nmolecule-and-text fragments and stereoisomeric nuances, which is crucial for\ndownstream tasks. Furthermore, it is incapable of modeling such information\nusing a similar global alignment strategy due to the lack of annotations about\nthe fine-grained fragments in the existing dataset. In this paper, we propose\nAtomas, a hierarchical molecular representation learning framework that jointly\nlearns representations from SMILES strings and text. We design a Hierarchical\nAdaptive Alignment model to automatically learn the fine-grained fragment\ncorrespondence between two modalities and align these representations at three\nsemantic levels. Atomas's end-to-end training framework supports understanding\nand generating molecules, enabling a wider range of downstream tasks. Atomas\nachieves superior performance across 12 tasks on 11 datasets, outperforming 11\nbaseline models thus highlighting the effectiveness and versatility of our\nmethod. Scaling experiments further demonstrate Atomas's robustness and\nscalability. Moreover, visualization and qualitative analysis, validated by\nhuman experts, confirm the chemical relevance of our approach. Codes are\nreleased on https://github.com/yikunpku/Atomas.",
      "tldr_zh": "该研究提出 Atomas 框架，通过分层分子表示学习联合处理 SMILES 字符串和文本，以解决现有全局对齐方法无法捕捉细粒度信息（如分子片段和立体异构体）的问题。Atomas 采用 Hierarchical Adaptive Alignment 模型，自动学习两个模态之间的细粒度片段对应，并在三个语义级别上进行对齐，支持分子理解和生成任务。实验结果显示，Atomas 在 11 个数据集的 12 个任务上优于 11 个基线模型，并通过扩展实验、可视化和人类专家验证证明了其鲁棒性、扩展性和化学相关性。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "q-bio.QM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.16880v3",
      "published_date": "2024-04-23 12:35:44 UTC",
      "updated_date": "2025-03-03 16:34:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:57:03.378810"
    },
    {
      "arxiv_id": "2404.14967v1",
      "title": "CoARF: Controllable 3D Artistic Style Transfer for Radiance Fields",
      "title_zh": "翻译失败",
      "authors": [
        "Deheng Zhang",
        "Clara Fernandez-Labrador",
        "Christopher Schroers"
      ],
      "abstract": "Creating artistic 3D scenes can be time-consuming and requires specialized\nknowledge. To address this, recent works such as ARF, use a radiance\nfield-based approach with style constraints to generate 3D scenes that resemble\na style image provided by the user. However, these methods lack fine-grained\ncontrol over the resulting scenes. In this paper, we introduce Controllable\nArtistic Radiance Fields (CoARF), a novel algorithm for controllable 3D scene\nstylization. CoARF enables style transfer for specified objects, compositional\n3D style transfer and semantic-aware style transfer. We achieve controllability\nusing segmentation masks with different label-dependent loss functions. We also\npropose a semantic-aware nearest neighbor matching algorithm to improve the\nstyle transfer quality. Our extensive experiments demonstrate that CoARF\nprovides user-specified controllability of style transfer and superior style\ntransfer quality with more precise feature matching.",
      "tldr_zh": "该论文提出 CoARF，一种可控的 3D 艺术风格转移算法，针对基于 Radiance Fields 的 3D 场景生成问题，解决了现有方法如 ARF 在细粒度控制方面的不足。CoARF 支持针对指定对象的风格转移、组合 3D 风格转移以及语义感知风格转移，通过使用 segmentation masks 和 label-dependent loss functions 来实现用户指定的控制。作者还引入了 semantic-aware nearest neighbor matching algorithm，以提升风格转移质量；实验结果显示，CoARF 提供了更精确的特征匹配和优越的风格转移性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR"
      ],
      "primary_category": "cs.CV",
      "comment": "International Conference on 3D Vision 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.14967v1",
      "published_date": "2024-04-23 12:22:32 UTC",
      "updated_date": "2024-04-23 12:22:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:57:13.921879"
    },
    {
      "arxiv_id": "2404.14966v2",
      "title": "Mamba3D: Enhancing Local Features for 3D Point Cloud Analysis via State Space Model",
      "title_zh": "翻译失败",
      "authors": [
        "Xu Han",
        "Yuan Tang",
        "Zhaoxuan Wang",
        "Xianzhi Li"
      ],
      "abstract": "Existing Transformer-based models for point cloud analysis suffer from\nquadratic complexity, leading to compromised point cloud resolution and\ninformation loss. In contrast, the newly proposed Mamba model, based on state\nspace models (SSM), outperforms Transformer in multiple areas with only linear\ncomplexity. However, the straightforward adoption of Mamba does not achieve\nsatisfactory performance on point cloud tasks. In this work, we present\nMamba3D, a state space model tailored for point cloud learning to enhance local\nfeature extraction, achieving superior performance, high efficiency, and\nscalability potential. Specifically, we propose a simple yet effective Local\nNorm Pooling (LNP) block to extract local geometric features. Additionally, to\nobtain better global features, we introduce a bidirectional SSM (bi-SSM) with\nboth a token forward SSM and a novel backward SSM that operates on the feature\nchannel. Extensive experimental results show that Mamba3D surpasses\nTransformer-based counterparts and concurrent works in multiple tasks, with or\nwithout pre-training. Notably, Mamba3D achieves multiple SoTA, including an\noverall accuracy of 92.6% (train from scratch) on the ScanObjectNN and 95.1%\n(with single-modal pre-training) on the ModelNet40 classification task, with\nonly linear complexity. Our code and weights are available at\nhttps://github.com/xhanxu/Mamba3D.",
      "tldr_zh": "本文提出 Mamba3D，一种基于 State Space Model (SSM) 的模型，用于提升 3D 点云分析的局部特征提取，解决现有 Transformer 模型的二次复杂度问题，从而减少信息丢失并提高效率。Mamba3D 引入 Local Norm Pooling (LNP) 块来提取局部几何特征，并采用 bidirectional SSM (bi-SSM) 结合 token 前向和后向操作，以优化全局特征。实验结果显示，Mamba3D 在多个任务中超越 Transformer 基线和同期工作，实现 SoTA 成绩，如 ScanObjectNN 上从零训练达到 92.6% 准确率，以及 ModelNet40 上单模态预训练达到 95.1% 准确率，仅需线性复杂度。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "ACM MM 2024. Code and weights are available at\n  https://github.com/xhanxu/Mamba3D",
      "pdf_url": "http://arxiv.org/pdf/2404.14966v2",
      "published_date": "2024-04-23 12:20:27 UTC",
      "updated_date": "2024-09-02 12:55:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:57:27.542300"
    },
    {
      "arxiv_id": "2404.14963v5",
      "title": "Achieving >97% on GSM8K: Deeply Understanding the Problems Makes LLMs Better Solvers for Math Word Problems",
      "title_zh": "在 GSM8K 上实现 >97%：深入理解问题使 LLMs ",
      "authors": [
        "Qihuang Zhong",
        "Kang Wang",
        "Ziyang Xu",
        "Juhua Liu",
        "Liang Ding",
        "Bo Du"
      ],
      "abstract": "Chain-of-Thought (CoT) prompting has enhanced the performance of Large\nLanguage Models (LLMs) across various reasoning tasks. However, CoT still falls\nshort in dealing with complex math word problems, as it usually suffers from\nthree pitfalls: semantic misunderstanding errors, calculation errors, and\nstep-missing errors. Prior studies involve addressing the calculation errors\nand step-missing errors, but neglect the semantic misunderstanding errors,\nwhich is the major factor limiting the reasoning performance of LLMs. To this\nend, we propose a simple-yet-effective method, namely Deeply Understanding the\nProblems (DUP), to improve the LLMs' math problem-solving ability by addressing\nsemantic misunderstanding errors. The core of our method is to encourage the\nLLMs to deeply understand the problems and extract the key problem-solving\ninformation used for better reasoning. Extensive experiments on 10 diverse\nreasoning benchmarks show that our DUP method consistently outperforms the\nother counterparts by a large margin. More encouragingly, DUP achieves a new\nSOTA result on the GSM8K benchmark, with an accuracy of 97.1% under the\nzero-shot setting.",
      "tldr_zh": "该研究指出，Chain-of-Thought (CoT) 提示虽然提升了 Large Language Models (LLMs) 的推理性能，但仍存在语义误解错误、计算错误和步骤缺失错误，其中语义误解是主要瓶颈。作者提出 Deeply Understanding the Problems (DUP) 方法，通过鼓励 LLMs 深入理解问题并提取关键信息来解决语义误解问题，从而改善数学文字问题的求解能力。在 10 个多样化推理基准上的广泛实验显示，DUP 显著优于其他方法，并在 GSM8K 基准上实现零样本设置下的 97.1% 准确率新纪录。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "The article has been accepted by Frontiers of Computer Science (FCS),\n  with the DOI: { 10.1007/s11704-025-41102-z }",
      "pdf_url": "http://arxiv.org/pdf/2404.14963v5",
      "published_date": "2024-04-23 12:16:05 UTC",
      "updated_date": "2025-03-27 07:08:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:57:37.481861"
    },
    {
      "arxiv_id": "2404.15386v1",
      "title": "Large-Scale Multipurpose Benchmark Datasets For Assessing Data-Driven Deep Learning Approaches For Water Distribution Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Andres Tello",
        "Huy Truong",
        "Alexander Lazovik",
        "Victoria Degeler"
      ],
      "abstract": "Currently, the number of common benchmark datasets that researchers can use\nstraight away for assessing data-driven deep learning approaches is very\nlimited. Most studies provide data as configuration files. It is still up to\neach practitioner to follow a particular data generation method and run\ncomputationally intensive simulations to obtain usable data for model training\nand evaluation. In this work, we provide a collection of datasets that includes\nseveral small and medium size publicly available Water Distribution Networks\n(WDNs), including Anytown, Modena, Balerma, C-Town, D-Town, L-Town, Ky1, Ky6,\nKy8, and Ky13. In total 1,394,400 hours of WDNs data operating under normal\nconditions is made available to the community.",
      "tldr_zh": "本研究指出，目前用于评估数据驱动深度学习方法的供水网络（Water Distribution Networks, WDNs）基准数据集非常有限，大多数研究仅提供配置文件，需要研究者自行运行模拟生成数据。论文提供了一个大规模多用途数据集集合，包括 AnyTown、Modena、Balerma、C-Town、D-Town、L-Town、Ky1、Ky6、Ky8 和 Ky13 等小型和中型 WDNs。总共提供 1,394,400 小时的正常运行数据，旨在方便社区直接用于模型训练和评估，从而推动相关领域的深度学习应用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Presented at WDSA CCWI, Ferrara, Italy, July 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.15386v1",
      "published_date": "2024-04-23 11:58:40 UTC",
      "updated_date": "2024-04-23 11:58:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:57:49.212899"
    },
    {
      "arxiv_id": "2404.14952v1",
      "title": "Leveraging Speech for Gesture Detection in Multimodal Communication",
      "title_zh": "翻译失败",
      "authors": [
        "Esam Ghaleb",
        "Ilya Burenko",
        "Marlou Rasenberg",
        "Wim Pouw",
        "Ivan Toni",
        "Peter Uhrig",
        "Anna Wilson",
        "Judith Holler",
        "Aslı Özyürek",
        "Raquel Fernández"
      ],
      "abstract": "Gestures are inherent to human interaction and often complement speech in\nface-to-face communication, forming a multimodal communication system. An\nimportant task in gesture analysis is detecting a gesture's beginning and end.\nResearch on automatic gesture detection has primarily focused on visual and\nkinematic information to detect a limited set of isolated or silent gestures\nwith low variability, neglecting the integration of speech and vision signals\nto detect gestures that co-occur with speech. This work addresses this gap by\nfocusing on co-speech gesture detection, emphasising the synchrony between\nspeech and co-speech hand gestures. We address three main challenges: the\nvariability of gesture forms, the temporal misalignment between gesture and\nspeech onsets, and differences in sampling rate between modalities. We\ninvestigate extended speech time windows and employ separate backbone models\nfor each modality to address the temporal misalignment and sampling rate\ndifferences. We utilize Transformer encoders in cross-modal and early fusion\ntechniques to effectively align and integrate speech and skeletal sequences.\nThe study results show that combining visual and speech information\nsignificantly enhances gesture detection performance. Our findings indicate\nthat expanding the speech buffer beyond visual time segments improves\nperformance and that multimodal integration using cross-modal and early fusion\ntechniques outperforms baseline methods using unimodal and late fusion methods.\nAdditionally, we find a correlation between the models' gesture prediction\nconfidence and low-level speech frequency features potentially associated with\ngestures. Overall, the study provides a better understanding and detection\nmethods for co-speech gestures, facilitating the analysis of multimodal\ncommunication.",
      "tldr_zh": "本文研究了在多模态通信中利用语音来检测语音伴随手势（co-speech gestures），以解决现有方法忽略语音和视觉信号整合的问题。作者通过扩展语音时间窗口、采用独立骨干模型处理每个模态，以及使用Transformer编码器进行跨模态和早期融合，来应对手势变异性、时序不对齐和采样率差异等挑战。实验结果表明，多模态整合显著提升手势检测性能，扩展语音缓冲区和融合技术优于单模态或晚融合基线方法，并发现模型预测置信度与语音频率特征相关，从而为多模态通信分析提供更有效的检测方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.14952v1",
      "published_date": "2024-04-23 11:54:05 UTC",
      "updated_date": "2024-04-23 11:54:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:58:02.797958"
    },
    {
      "arxiv_id": "2404.14941v1",
      "title": "Delayed Bottlenecking: Alleviating Forgetting in Pre-trained Graph Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Zhe Zhao",
        "Pengkun Wang",
        "Xu Wang",
        "Haibin Wen",
        "Xiaolong Xie",
        "Zhengyang Zhou",
        "Qingfu Zhang",
        "Yang Wang"
      ],
      "abstract": "Pre-training GNNs to extract transferable knowledge and apply it to\ndownstream tasks has become the de facto standard of graph representation\nlearning. Recent works focused on designing self-supervised pre-training tasks\nto extract useful and universal transferable knowledge from large-scale\nunlabeled data. However, they have to face an inevitable question: traditional\npre-training strategies that aim at extracting useful information about\npre-training tasks, may not extract all useful information about the downstream\ntask. In this paper, we reexamine the pre-training process within traditional\npre-training and fine-tuning frameworks from the perspective of Information\nBottleneck (IB) and confirm that the forgetting phenomenon in pre-training\nphase may cause detrimental effects on downstream tasks. Therefore, we propose\na novel \\underline{D}elayed \\underline{B}ottlenecking \\underline{P}re-training\n(DBP) framework which maintains as much as possible mutual information between\nlatent representations and training data during pre-training phase by\nsuppressing the compression operation and delays the compression operation to\nfine-tuning phase to make sure the compression can be guided with labeled\nfine-tuning data and downstream tasks. To achieve this, we design two\ninformation control objectives that can be directly optimized and further\nintegrate them into the actual model design. Extensive experiments on both\nchemistry and biology domains demonstrate the effectiveness of DBP.",
      "tldr_zh": "该论文从 Information Bottleneck (IB) 视角重新审视预训练 Graph Neural Networks (GNNs) 的过程，发现预训练阶段的遗忘现象可能损害下游任务性能。作者提出 Delayed Bottlenecking Pre-training (DBP) 框架，通过抑制预训练阶段的压缩操作来保持 latent representations 与训练数据的 mutual information，并将压缩延迟到 fine-tuning 阶段，以利用标签数据指导优化。实验在化学和生物领域显示，DBP 框架显著提升了模型的泛化能力和任务表现。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.14941v1",
      "published_date": "2024-04-23 11:35:35 UTC",
      "updated_date": "2024-04-23 11:35:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:58:13.344967"
    },
    {
      "arxiv_id": "2404.14933v1",
      "title": "Fin-Fed-OD: Federated Outlier Detection on Financial Tabular Data",
      "title_zh": "翻译失败",
      "authors": [
        "Dayananda Herurkar",
        "Sebastian Palacio",
        "Ahmed Anwar",
        "Joern Hees",
        "Andreas Dengel"
      ],
      "abstract": "Anomaly detection in real-world scenarios poses challenges due to dynamic and\noften unknown anomaly distributions, requiring robust methods that operate\nunder an open-world assumption. This challenge is exacerbated in practical\nsettings, where models are employed by private organizations, precluding data\nsharing due to privacy and competitive concerns. Despite potential benefits,\nthe sharing of anomaly information across organizations is restricted. This\npaper addresses the question of enhancing outlier detection within individual\norganizations without compromising data confidentiality. We propose a novel\nmethod leveraging representation learning and federated learning techniques to\nimprove the detection of unknown anomalies. Specifically, our approach utilizes\nlatent representations obtained from client-owned autoencoders to refine the\ndecision boundary of inliers. Notably, only model parameters are shared between\norganizations, preserving data privacy. The efficacy of our proposed method is\nevaluated on two standard financial tabular datasets and an image dataset for\nanomaly detection in a distributed setting. The results demonstrate a strong\nimprovement in the classification of unknown outliers during the inference\nphase for each organization's model.",
      "tldr_zh": "该论文提出Fin-Fed-OD，一种基于联邦学习(Federated Learning)的异常检测方法，旨在解决金融表格数据中未知异常分布的挑战，同时保护组织间数据隐私。方法利用客户端拥有的自编码器(Autoencoders)生成潜在表示，并通过共享模型参数来优化内点的决策边界，而非直接交换数据。实验在两个标准金融表格数据集和一个图像数据集上进行，结果显示，该方法显著提高了分布式设置下未知异常的分类准确率，为隐私敏感环境下的异常检测提供了有效解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.14933v1",
      "published_date": "2024-04-23 11:22:04 UTC",
      "updated_date": "2024-04-23 11:22:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:58:24.923732"
    },
    {
      "arxiv_id": "2404.14928v2",
      "title": "Graph Machine Learning in the Era of Large Language Models (LLMs)",
      "title_zh": "图机器学习在大语言模型（LLMs）时代",
      "authors": [
        "Wenqi Fan",
        "Shijie Wang",
        "Jiani Huang",
        "Zhikai Chen",
        "Yu Song",
        "Wenzhuo Tang",
        "Haitao Mao",
        "Hui Liu",
        "Xiaorui Liu",
        "Dawei Yin",
        "Qing Li"
      ],
      "abstract": "Graphs play an important role in representing complex relationships in\nvarious domains like social networks, knowledge graphs, and molecular\ndiscovery. With the advent of deep learning, Graph Neural Networks (GNNs) have\nemerged as a cornerstone in Graph Machine Learning (Graph ML), facilitating the\nrepresentation and processing of graph structures. Recently, LLMs have\ndemonstrated unprecedented capabilities in language tasks and are widely\nadopted in a variety of applications such as computer vision and recommender\nsystems. This remarkable success has also attracted interest in applying LLMs\nto the graph domain. Increasing efforts have been made to explore the potential\nof LLMs in advancing Graph ML's generalization, transferability, and few-shot\nlearning ability. Meanwhile, graphs, especially knowledge graphs, are rich in\nreliable factual knowledge, which can be utilized to enhance the reasoning\ncapabilities of LLMs and potentially alleviate their limitations such as\nhallucinations and the lack of explainability. Given the rapid progress of this\nresearch direction, a systematic review summarizing the latest advancements for\nGraph ML in the era of LLMs is necessary to provide an in-depth understanding\nto researchers and practitioners. Therefore, in this survey, we first review\nthe recent developments in Graph ML. We then explore how LLMs can be utilized\nto enhance the quality of graph features, alleviate the reliance on labeled\ndata, and address challenges such as graph heterogeneity and\nout-of-distribution (OOD) generalization. Afterward, we delve into how graphs\ncan enhance LLMs, highlighting their abilities to enhance LLM pre-training and\ninference. Furthermore, we investigate various applications and discuss the\npotential future directions in this promising field.",
      "tldr_zh": "这篇调查论文探讨了在大型语言模型(LLMs)时代下图机器学习(Graph Machine Learning)的最新进展，强调了LLMs如何提升Graph Neural Networks (GNNs)的泛化能力、转移性和少样本学习，同时利用知识图等图结构来缓解LLMs的幻觉问题和解释性不足。论文系统回顾了LLMs在改善图特征质量、减少标注数据依赖以及处理图异质性和OOD泛化方面的作用，并阐述了图数据如何增强LLMs的预训练和推理能力。最终，该研究总结了各种应用场景，并指出未来方向，如进一步整合LLMs与Graph ML以推动更可靠的AI系统。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.14928v2",
      "published_date": "2024-04-23 11:13:39 UTC",
      "updated_date": "2024-06-04 01:31:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:58:37.615152"
    },
    {
      "arxiv_id": "2404.15385v1",
      "title": "Sum of Group Error Differences: A Critical Examination of Bias Evaluation in Biometric Verification and a Dual-Metric Measure",
      "title_zh": "翻译失败",
      "authors": [
        "Alaa Elobaid",
        "Nathan Ramoly",
        "Lara Younes",
        "Symeon Papadopoulos",
        "Eirini Ntoutsi",
        "Ioannis Kompatsiaris"
      ],
      "abstract": "Biometric Verification (BV) systems often exhibit accuracy disparities across\ndifferent demographic groups, leading to biases in BV applications. Assessing\nand quantifying these biases is essential for ensuring the fairness of BV\nsystems. However, existing bias evaluation metrics in BV have limitations, such\nas focusing exclusively on match or non-match error rates, overlooking bias on\ndemographic groups with performance levels falling between the best and worst\nperformance levels, and neglecting the magnitude of the bias present.\n  This paper presents an in-depth analysis of the limitations of current bias\nevaluation metrics in BV and, through experimental analysis, demonstrates their\ncontextual suitability, merits, and limitations. Additionally, it introduces a\nnovel general-purpose bias evaluation measure for BV, the ``Sum of Group Error\nDifferences (SEDG)''. Our experimental results on controlled synthetic datasets\ndemonstrate the effectiveness of demographic bias quantification when using\nexisting metrics and our own proposed measure. We discuss the applicability of\nthe bias evaluation metrics in a set of simulated demographic bias scenarios\nand provide scenario-based metric recommendations. Our code is publicly\navailable under \\url{https://github.com/alaaobeid/SEDG}.",
      "tldr_zh": "本研究 critically examines 生物特征验证（Biometric Verification, BV）系统中的偏差问题，指出现有偏差评估指标的局限性，如仅关注匹配或非匹配错误率、忽略中间性能群体以及未考虑偏差幅度。作者通过实验分析评估了这些指标的优缺点，并引入了一个新指标Sum of Group Error Differences (SEDG)，用于更全面地量化BV系统的群体偏差。在合成数据集上的实验结果证明了SEDG的有效性，并为不同模拟偏差场景提供了基于情境的指标推荐，相关代码已在GitHub上公开。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.15385v1",
      "published_date": "2024-04-23 10:59:44 UTC",
      "updated_date": "2024-04-23 10:59:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:58:49.457879"
    },
    {
      "arxiv_id": "2404.15384v1",
      "title": "FL-TAC: Enhanced Fine-Tuning in Federated Learning via Low-Rank, Task-Specific Adapter Clustering",
      "title_zh": "翻译失败",
      "authors": [
        "Siqi Ping",
        "Yuzhu Mao",
        "Yang Liu",
        "Xiao-Ping Zhang",
        "Wenbo Ding"
      ],
      "abstract": "Although large-scale pre-trained models hold great potential for adapting to\ndownstream tasks through fine-tuning, the performance of such fine-tuned models\nis often limited by the difficulty of collecting sufficient high-quality,\ntask-specific data. Federated Learning (FL) offers a promising solution by\nenabling fine-tuning across large-scale clients with a variety of task data,\nbut it is bottlenecked by significant communication overhead due to the\npre-trained models' extensive size. This paper addresses the high communication\ncost for fine-tuning large pre-trained models within FL frameworks through\nlow-rank fine-tuning. Specifically, we train a low-rank adapter for each\nindividual task on the client side, followed by server-side clustering for\nsimilar group of adapters to achieve task-specific aggregation. Extensive\nexperiments on various language and vision tasks, such as GLUE and\nCIFAR-10/100, reveal the evolution of task-specific adapters throughout the FL\ntraining process and verify the effectiveness of the proposed low-rank\ntask-specific adapter clustering (TAC) method.",
      "tldr_zh": "该论文提出 FL-TAC 方法，通过低秩微调（low-rank fine-tuning）来提升 Federated Learning (FL) 中的微调效率，解决大型预训练模型在跨客户端训练时的高通信开销问题。具体而言，该方法在客户端为每个任务训练 low-rank adapter，然后在服务器端对类似适配器进行 clustering，实现任务特定聚合。实验在 GLUE 和 CIFAR-10/100 等语言和视觉任务上验证了 TAC 的有效性，展示了任务特定适配器的演化过程，并证明了其在减少开销和提高性能方面的优势。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.15384v1",
      "published_date": "2024-04-23 10:50:38 UTC",
      "updated_date": "2024-04-23 10:50:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:59:02.981014"
    },
    {
      "arxiv_id": "2404.14906v1",
      "title": "Driver Activity Classification Using Generalizable Representations from Vision-Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Ross Greer",
        "Mathias Viborg Andersen",
        "Andreas Møgelmose",
        "Mohan Trivedi"
      ],
      "abstract": "Driver activity classification is crucial for ensuring road safety, with\napplications ranging from driver assistance systems to autonomous vehicle\ncontrol transitions. In this paper, we present a novel approach leveraging\ngeneralizable representations from vision-language models for driver activity\nclassification. Our method employs a Semantic Representation Late Fusion Neural\nNetwork (SRLF-Net) to process synchronized video frames from multiple\nperspectives. Each frame is encoded using a pretrained vision-language encoder,\nand the resulting embeddings are fused to generate class probability\npredictions. By leveraging contrastively-learned vision-language\nrepresentations, our approach achieves robust performance across diverse driver\nactivities. We evaluate our method on the Naturalistic Driving Action\nRecognition Dataset, demonstrating strong accuracy across many classes. Our\nresults suggest that vision-language representations offer a promising avenue\nfor driver monitoring systems, providing both accuracy and interpretability\nthrough natural language descriptors.",
      "tldr_zh": "本研究针对驾驶员活动分类问题，提出了一种利用视觉语言模型(Vision-Language Models)通用表示的新方法，以提升道路安全和自动驾驶系统。该方法采用语义表示晚融合神经网络(SRLF-Net)，通过预训练的视觉语言编码器处理多视角同步视频帧，并融合嵌入生成类别概率预测，从而实现对多样驾驶活动的鲁棒识别。在Naturalistic Driving Action Recognition Dataset上的实验显示，该方法在多个类别中表现出高准确率，并通过自然语言描述提供可解释性，为驾驶员监控系统的发展提供了新途径。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.14906v1",
      "published_date": "2024-04-23 10:42:24 UTC",
      "updated_date": "2024-04-23 10:42:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:59:14.381574"
    },
    {
      "arxiv_id": "2404.14901v2",
      "title": "Beyond Code Generation: An Observational Study of ChatGPT Usage in Software Engineering Practice",
      "title_zh": "超越代码生成：ChatGPT 在软件工程实践中的使用观察性研究",
      "authors": [
        "Ranim Khojah",
        "Mazen Mohamad",
        "Philipp Leitner",
        "Francisco Gomes de Oliveira Neto"
      ],
      "abstract": "Large Language Models (LLMs) are frequently discussed in academia and the\ngeneral public as support tools for virtually any use case that relies on the\nproduction of text, including software engineering. Currently there is much\ndebate, but little empirical evidence, regarding the practical usefulness of\nLLM-based tools such as ChatGPT for engineers in industry. We conduct an\nobservational study of 24 professional software engineers who have been using\nChatGPT over a period of one week in their jobs, and qualitatively analyse\ntheir dialogues with the chatbot as well as their overall experience (as\ncaptured by an exit survey). We find that, rather than expecting ChatGPT to\ngenerate ready-to-use software artifacts (e.g., code), practitioners more often\nuse ChatGPT to receive guidance on how to solve their tasks or learn about a\ntopic in more abstract terms. We also propose a theoretical framework for how\n(i) purpose of the interaction, (ii) internal factors (e.g., the user's\npersonality), and (iii) external factors (e.g., company policy) together shape\nthe experience (in terms of perceived usefulness and trust). We envision that\nour framework can be used by future research to further the academic discussion\non LLM usage by software engineering practitioners, and to serve as a reference\npoint for the design of future empirical LLM research in this domain.",
      "tldr_zh": "这篇论文通过对24名专业软件工程师使用ChatGPT一周的观察性研究，探讨了Large Language Models (LLMs)在软件工程实践中的实际应用。研究发现，工程师们更倾向于将ChatGPT作为获取任务指导和抽象知识的工具，而不是直接生成代码。作者提出一个理论框架，结合互动目的、内部因素（如用户个性）和外部因素（如公司政策），来解释用户对ChatGPT的感知有用性和信任。该框架可为未来研究提供参考，推动LLMs在软件工程领域的学术讨论。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted at the ACM International Conference on the Foundations of\n  Software Engineering (FSE) 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.14901v2",
      "published_date": "2024-04-23 10:34:16 UTC",
      "updated_date": "2024-05-21 12:53:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:59:27.685106"
    },
    {
      "arxiv_id": "2404.14897v1",
      "title": "Beyond the Speculative Game: A Survey of Speculative Execution in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Chen Zhang",
        "Zhuorui Liu",
        "Dawei Song"
      ],
      "abstract": "With the increasingly giant scales of (causal) large language models (LLMs),\nthe inference efficiency comes as one of the core concerns along the improved\nperformance. In contrast to the memory footprint, the latency bottleneck seems\nto be of greater importance as there can be billions of requests to a LLM\n(e.g., GPT-4) per day. The bottleneck is mainly due to the autoregressive\ninnateness of LLMs, where tokens can only be generated sequentially during\ndecoding. To alleviate the bottleneck, the idea of speculative execution, which\noriginates from the field of computer architecture, is introduced to LLM\ndecoding in a \\textit{draft-then-verify} style. Under this regime, a sequence\nof tokens will be drafted in a fast pace by utilizing some heuristics, and then\nthe tokens shall be verified in parallel by the LLM. As the costly sequential\ninference is parallelized, LLM decoding speed can be significantly boosted.\nDriven by the success of LLMs in recent couple of years, a growing literature\nin this direction has emerged. Yet, there lacks a position survey to summarize\nthe current landscape and draw a roadmap for future development of this\npromising area. To meet this demand, we present the very first survey paper\nthat reviews and unifies literature of speculative execution in LLMs (e.g.,\nblockwise parallel decoding, speculative decoding, etc.) in a comprehensive\nframework and a systematic taxonomy. Based on the taxonomy, we present a\ncritical review and comparative analysis of the current arts. Finally we\nhighlight various key challenges and future directions to further develop the\narea.",
      "tldr_zh": "这篇调查论文探讨了投机执行(speculative execution)在大型语言模型(LLMs)中的应用，以解决LLMs的自回归(autoregressive)特性导致的推理延迟问题。论文引入了“draft-then-verify”风格，即先快速草拟 token 序列，然后并行验证，从而显著提升解码速度。作者通过一个全面框架和系统分类（如块式并行解码和投机解码等）回顾并比较了现有文献，并对关键技术进行批判性分析。最后，论文突出了面临的挑战和未来发展方向，为优化LLMs的推理效率提供路线图。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages, 4 figures, 1 table, rejected from IJCAI 2024, revision in\n  progress",
      "pdf_url": "http://arxiv.org/pdf/2404.14897v1",
      "published_date": "2024-04-23 10:25:45 UTC",
      "updated_date": "2024-04-23 10:25:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:59:39.595903"
    },
    {
      "arxiv_id": "2404.15383v1",
      "title": "WANDR: Intention-guided Human Motion Generation",
      "title_zh": "WANDR：意图引导的人类运动生成",
      "authors": [
        "Markos Diomataris",
        "Nikos Athanasiou",
        "Omid Taheri",
        "Xi Wang",
        "Otmar Hilliges",
        "Michael J. Black"
      ],
      "abstract": "Synthesizing natural human motions that enable a 3D human avatar to walk and\nreach for arbitrary goals in 3D space remains an unsolved problem with many\napplications. Existing methods (data-driven or using reinforcement learning)\nare limited in terms of generalization and motion naturalness. A primary\nobstacle is the scarcity of training data that combines locomotion with goal\nreaching. To address this, we introduce WANDR, a data-driven model that takes\nan avatar's initial pose and a goal's 3D position and generates natural human\nmotions that place the end effector (wrist) on the goal location. To solve\nthis, we introduce novel intention features that drive rich goal-oriented\nmovement. Intention guides the agent to the goal, and interactively adapts the\ngeneration to novel situations without needing to define sub-goals or the\nentire motion path. Crucially, intention allows training on datasets that have\ngoal-oriented motions as well as those that do not. WANDR is a conditional\nVariational Auto-Encoder (c-VAE), which we train using the AMASS and CIRCLE\ndatasets. We evaluate our method extensively and demonstrate its ability to\ngenerate natural and long-term motions that reach 3D goals and generalize to\nunseen goal locations. Our models and code are available for research purposes\nat wandr.is.tue.mpg.de.",
      "tldr_zh": "该研究提出WANDR，一种基于数据驱动的模型，用于生成引导人类动作，使3D人类头像在空间中自然行走并到达任意3D目标位置。WANDR引入了新型intention features，作为驱动因素，帮助代理适应动态情况并实现目标导向运动，而无需预定义子目标或路径。模型采用条件变分自编码器(c-VAE)架构，使用AMASS和CIRCLE数据集进行训练。实验结果显示，WANDR能产生自然的长期动作，准确到达未见目标位置，并超越现有方法在泛化和自然性上的表现。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.15383v1",
      "published_date": "2024-04-23 10:20:17 UTC",
      "updated_date": "2024-04-23 10:20:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:59:51.242241"
    },
    {
      "arxiv_id": "2404.15382v1",
      "title": "Feature Distribution Shift Mitigation with Contrastive Pretraining for Intrusion Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Weixing Wang",
        "Haojin Yang",
        "Christoph Meinel",
        "Hasan Yagiz Özkan",
        "Cristian Bermudez Serna",
        "Carmen Mas-Machuca"
      ],
      "abstract": "In recent years, there has been a growing interest in using Machine Learning\n(ML), especially Deep Learning (DL) to solve Network Intrusion Detection (NID)\nproblems. However, the feature distribution shift problem remains a difficulty,\nbecause the change in features' distributions over time negatively impacts the\nmodel's performance. As one promising solution, model pretraining has emerged\nas a novel training paradigm, which brings robustness against feature\ndistribution shift and has proven to be successful in Computer Vision (CV) and\nNatural Language Processing (NLP). To verify whether this paradigm is\nbeneficial for NID problem, we propose SwapCon, a ML model in the context of\nNID, which compresses shift-invariant feature information during the\npretraining stage and refines during the finetuning stage. We exemplify the\nevidence of feature distribution shift using the Kyoto2006+ dataset. We\ndemonstrate how pretraining a model with the proper size can increase\nrobustness against feature distribution shifts by over 8%. Moreover, we show\nhow an adequate numerical embedding strategy also enhances the performance of\npretrained models. Further experiments show that the proposed SwapCon model\nalso outperforms eXtreme Gradient Boosting (XGBoost) and K-Nearest Neighbor\n(KNN) based models by a large margin.",
      "tldr_zh": "本研究针对网络入侵检测（NID）中的特征分布偏移问题，提出了一种基于对比预训练（Contrastive Pretraining）的SwapCon模型，以提升模型的鲁棒性。SwapCon在预训练阶段压缩偏移不变的特征信息，并在微调阶段进一步精炼，从而缓解特征分布变化对性能的影响。实验使用Kyoto2006+数据集证明，该模型通过适当的模型大小和数值嵌入策略，提高了超过8%的鲁棒性，并大幅超越XGBoost和K-Nearest Neighbor (KNN)基线模型。总的来说，此方法为NID问题提供了更可靠的深度学习（Deep Learning, DL）解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NI"
      ],
      "primary_category": "cs.LG",
      "comment": "accepted by ICMLCN24",
      "pdf_url": "http://arxiv.org/pdf/2404.15382v1",
      "published_date": "2024-04-23 10:15:10 UTC",
      "updated_date": "2024-04-23 10:15:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:00:02.364750"
    },
    {
      "arxiv_id": "2404.14871v1",
      "title": "Exploring Human-AI Collaboration in Agile: Customised LLM Meeting Assistants",
      "title_zh": "翻译失败",
      "authors": [
        "Beatriz Cabrero-Daniel",
        "Tomas Herda",
        "Victoria Pichler",
        "Martin Eder"
      ],
      "abstract": "This action research study focuses on the integration of \"AI assistants\" in\ntwo Agile software development meetings: the Daily Scrum and a feature\nrefinement, a planning meeting that is part of an in-house Scaled Agile\nframework. We discuss the critical drivers of success, and establish a link\nbetween the use of AI and team collaboration dynamics. We conclude with a list\nof lessons learnt during the interventions in an industrial context, and\nprovide a assessment checklist for companies and teams to reflect on their\nreadiness level. This paper is thus a road-map to facilitate the integration of\nAI tools in Agile setups.",
      "tldr_zh": "这篇行动研究探讨了在敏捷(Agile)软件开发会议中整合自定义 LLM 会议助手的可能性，焦点放在 Daily Scrum 和特征细化会议（作为 Scaled Agile 框架的一部分）上。研究分析了成功的关键驱动因素，并建立了 AI assistants 使用与团队协作动态之间的联系。最终，论文总结了在工业环境中的教训列表和评估检查表，作为公司整合 AI 工具到 Agile 设置中的路线图。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.SE",
      "comment": "International Conference on Agile Software Development (XP 2024), 14\n  pages",
      "pdf_url": "http://arxiv.org/pdf/2404.14871v1",
      "published_date": "2024-04-23 09:55:25 UTC",
      "updated_date": "2024-04-23 09:55:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:00:15.765568"
    },
    {
      "arxiv_id": "2404.15381v4",
      "title": "Advances and Open Challenges in Federated Foundation Models",
      "title_zh": "联邦基础模型中的进展与开放挑战",
      "authors": [
        "Chao Ren",
        "Han Yu",
        "Hongyi Peng",
        "Xiaoli Tang",
        "Bo Zhao",
        "Liping Yi",
        "Alysa Ziying Tan",
        "Yulan Gao",
        "Anran Li",
        "Xiaoxiao Li",
        "Zengxiang Li",
        "Qiang Yang"
      ],
      "abstract": "The integration of Foundation Models (FMs) with Federated Learning (FL)\npresents a transformative paradigm in Artificial Intelligence (AI). This\nintegration offers enhanced capabilities, while addressing concerns of privacy,\ndata decentralization and computational efficiency. This paper provides a\ncomprehensive survey of the emerging field of Federated Foundation Models\n(FedFM), elucidating their synergistic relationship and exploring novel\nmethodologies, challenges, and future directions that the FL research field\nneeds to focus on in order to thrive in the age of FMs. A systematic\nmulti-tiered taxonomy is proposed, categorizing existing FedFM approaches for\nmodel training, aggregation, trustworthiness, and incentivization. Key\nchallenges, including how to enable FL to deal with high complexity of\ncomputational demands, privacy considerations, contribution evaluation, and\ncommunication efficiency, are thoroughly discussed. Moreover, this paper\nexplores the intricate challenges of communication, scalability and security\ninherent in training/fine-tuning FMs via FL. It highlights the potential of\nquantum computing to revolutionize the processes of training, inference,\noptimization and security. This survey also introduces the implementation\nrequirement of FedFM and some practical FedFM applications. It highlights\nlessons learned with a clear understanding of our findings for FedFM. Finally,\nthis survey not only provides insights into the current state and challenges of\nFedFM, but also offers a blueprint for future research directions, emphasizing\nthe need for developing trustworthy solutions. It serves as a foundational\nguide for researchers and practitioners interested in contributing to this\ninterdisciplinary and rapidly advancing field.",
      "tldr_zh": "这篇论文综述了Federated Foundation Models (FedFM)，探讨了Foundation Models (FMs)与Federated Learning (FL)的整合如何提升AI能力，同时解决隐私、数据分散化和计算效率问题。论文提出一个系统化的多层分类法，分类现有FedFM方法，包括模型训练、聚合、trustworthiness和incentivization，并深入讨论挑战如计算需求复杂度、隐私保护、贡献评估和通信效率。最终，它强调量子计算的潜力，提供FedFM的实施要求、实际应用及经验教训，并为未来研究绘制蓝图，呼吁开发可信赖的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Survey of Federated Foundation Models (FedFM)",
      "pdf_url": "http://arxiv.org/pdf/2404.15381v4",
      "published_date": "2024-04-23 09:44:58 UTC",
      "updated_date": "2024-09-08 09:38:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:00:28.989832"
    },
    {
      "arxiv_id": "2404.15380v1",
      "title": "ControlTraj: Controllable Trajectory Generation with Topology-Constrained Diffusion Model",
      "title_zh": "ControlTraj：基于拓扑约束扩散模型的可控轨迹生成",
      "authors": [
        "Yuanshao Zhu",
        "James Jianqiao Yu",
        "Xiangyu Zhao",
        "Qidong Liu",
        "Yongchao Ye",
        "Wei Chen",
        "Zijian Zhang",
        "Xuetao Wei",
        "Yuxuan Liang"
      ],
      "abstract": "Generating trajectory data is among promising solutions to addressing privacy\nconcerns, collection costs, and proprietary restrictions usually associated\nwith human mobility analyses. However, existing trajectory generation methods\nare still in their infancy due to the inherent diversity and unpredictability\nof human activities, grappling with issues such as fidelity, flexibility, and\ngeneralizability. To overcome these obstacles, we propose ControlTraj, a\nControllable Trajectory generation framework with the topology-constrained\ndiffusion model. Distinct from prior approaches, ControlTraj utilizes a\ndiffusion model to generate high-fidelity trajectories while integrating the\nstructural constraints of road network topology to guide the geographical\noutcomes. Specifically, we develop a novel road segment autoencoder to extract\nfine-grained road segment embedding. The encoded features, along with trip\nattributes, are subsequently merged into the proposed geographic denoising UNet\narchitecture, named GeoUNet, to synthesize geographic trajectories from white\nnoise. Through experimentation across three real-world data settings,\nControlTraj demonstrates its ability to produce human-directed, high-fidelity\ntrajectory generation with adaptability to unexplored geographical contexts.",
      "tldr_zh": "该研究提出ControlTraj框架，利用拓扑约束的diffusion model生成高保真轨迹数据，以解决人类移动分析中存在的隐私、成本和专有限制问题。框架通过开发道路段自编码器提取细粒度道路段嵌入，并将这些特征与行程属性整合到GeoUNet架构中，从白噪声合成受地理约束的轨迹。实验在三个真实世界数据设置中验证，ControlTraj能产生用户指导的高保真轨迹，并展示出对未探索地理环境的适应性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.15380v1",
      "published_date": "2024-04-23 09:42:45 UTC",
      "updated_date": "2024-04-23 09:42:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:00:38.060925"
    },
    {
      "arxiv_id": "2404.14851v4",
      "title": "From Matching to Generation: A Survey on Generative Information Retrieval",
      "title_zh": "从匹配到生成：生成式信息检索的调查",
      "authors": [
        "Xiaoxi Li",
        "Jiajie Jin",
        "Yujia Zhou",
        "Yuyao Zhang",
        "Peitian Zhang",
        "Yutao Zhu",
        "Zhicheng Dou"
      ],
      "abstract": "Information Retrieval (IR) systems are crucial tools for users to access\ninformation, which have long been dominated by traditional methods relying on\nsimilarity matching. With the advancement of pre-trained language models,\ngenerative information retrieval (GenIR) emerges as a novel paradigm,\nattracting increasing attention. Based on the form of information provided to\nusers, current research in GenIR can be categorized into two aspects:\n\\textbf{(1) Generative Document Retrieval} (GR) leverages the generative\nmodel's parameters for memorizing documents, enabling retrieval by directly\ngenerating relevant document identifiers without explicit indexing. \\textbf{(2)\nReliable Response Generation} employs language models to directly generate\ninformation users seek, breaking the limitations of traditional IR in terms of\ndocument granularity and relevance matching while offering flexibility,\nefficiency, and creativity to meet practical needs. This paper aims to\nsystematically review the latest research progress in GenIR. We will summarize\nthe advancements in GR regarding model training and structure, document\nidentifier, incremental learning, etc., as well as progress in reliable\nresponse generation in aspects of internal knowledge memorization, external\nknowledge augmentation, etc. We also review the evaluation, challenges and\nfuture developments in GenIR systems. This review aims to offer a comprehensive\nreference for researchers, encouraging further development in the GenIR field.\nGithub Repository: https://github.com/RUC-NLPIR/GenIR-Survey",
      "tldr_zh": "这篇论文对生成式信息检索（GenIR）进行了系统调查，探讨了从传统基于相似性匹配的信息检索（IR）向生成式范式的转变。论文将 GenIR 分为两大方面：Generative Document Retrieval (GR)，通过生成模型参数记忆文档并直接生成相关文档标识符，而无需显式索引；以及 Reliable Response Generation，利用语言模型直接生成用户所需信息，提升灵活性、效率和创造性。总体上，论文总结了 GR 在模型训练、结构和文档标识符等方面的进展，以及 Reliable Response Generation 在内部知识记忆和外部知识增强等领域的最新研究，并讨论了评估方法、面临的挑战和未来发展方向，为 GenIR 领域的研究提供全面参考。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.14851v4",
      "published_date": "2024-04-23 09:05:37 UTC",
      "updated_date": "2025-03-04 08:38:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:00:51.347966"
    },
    {
      "arxiv_id": "2404.14830v1",
      "title": "CoProNN: Concept-based Prototypical Nearest Neighbors for Explaining Vision Models",
      "title_zh": "翻译失败",
      "authors": [
        "Teodor Chiaburu",
        "Frank Haußer",
        "Felix Bießmann"
      ],
      "abstract": "Mounting evidence in explainability for artificial intelligence (XAI)\nresearch suggests that good explanations should be tailored to individual tasks\nand should relate to concepts relevant to the task. However, building task\nspecific explanations is time consuming and requires domain expertise which can\nbe difficult to integrate into generic XAI methods. A promising approach\ntowards designing useful task specific explanations with domain experts is\nbased on compositionality of semantic concepts. Here, we present a novel\napproach that enables domain experts to quickly create concept-based\nexplanations for computer vision tasks intuitively via natural language.\nLeveraging recent progress in deep generative methods we propose to generate\nvisual concept-based prototypes via text-to-image methods. These prototypes are\nthen used to explain predictions of computer vision models via a simple\nk-Nearest-Neighbors routine. The modular design of CoProNN is simple to\nimplement, it is straightforward to adapt to novel tasks and allows for\nreplacing the classification and text-to-image models as more powerful models\nare released. The approach can be evaluated offline against the ground-truth of\npredefined prototypes that can be easily communicated also to domain experts as\nthey are based on visual concepts. We show that our strategy competes very well\nwith other concept-based XAI approaches on coarse grained image classification\ntasks and may even outperform those methods on more demanding fine grained\ntasks. We demonstrate the effectiveness of our method for human-machine\ncollaboration settings in qualitative and quantitative user studies. All code\nand experimental data can be found in our GitHub\n$\\href{https://github.com/TeodorChiaburu/beexplainable}{repository}$.",
      "tldr_zh": "该研究提出CoProNN，一种基于概念的原型最近邻（Prototypical Nearest Neighbors）方法，用于解释视觉模型（Vision Models），旨在通过自然语言让领域专家快速创建任务特定的XAI（Explainable AI）解释。方法利用文本到图像生成技术创建视觉概念原型，然后通过k-Nearest-Neighbors（k-NN）例程来解释模型预测，实现模块化和易适应性。实验结果显示，CoProNN在粗粒度和细粒度图像分类任务上优于现有XAI方法，并在用户研究中证明了其在人机协作中的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "24 pages, 9 figures, 2 tables, accepted at WCXAI 2024 Valletta",
      "pdf_url": "http://arxiv.org/pdf/2404.14830v1",
      "published_date": "2024-04-23 08:32:38 UTC",
      "updated_date": "2024-04-23 08:32:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:01:04.564212"
    },
    {
      "arxiv_id": "2404.14822v1",
      "title": "CNN2GNN: How to Bridge CNN with GNN",
      "title_zh": "CNN2GNN：如何桥接 CNN 与 GNN",
      "authors": [
        "Ziheng Jiao",
        "Hongyuan Zhang",
        "Xuelong Li"
      ],
      "abstract": "Although the convolutional neural network (CNN) has achieved excellent\nperformance in vision tasks by extracting the intra-sample representation, it\nwill take a higher training expense because of stacking numerous convolutional\nlayers. Recently, as the bilinear models, graph neural networks (GNN) have\nsucceeded in exploring the underlying topological relationship among the graph\ndata with a few graph neural layers. Unfortunately, it cannot be directly\nutilized on non-graph data due to the lack of graph structure and has high\ninference latency on large-scale scenarios. Inspired by these complementary\nstrengths and weaknesses, \\textit{we discuss a natural question, how to bridge\nthese two heterogeneous networks?} In this paper, we propose a novel CNN2GNN\nframework to unify CNN and GNN together via distillation. Firstly, to break the\nlimitations of GNN, a differentiable sparse graph learning module is designed\nas the head of networks to dynamically learn the graph for inductive learning.\nThen, a response-based distillation is introduced to transfer the knowledge\nfrom CNN to GNN and bridge these two heterogeneous networks. Notably, due to\nextracting the intra-sample representation of a single instance and the\ntopological relationship among the datasets simultaneously, the performance of\ndistilled ``boosted'' two-layer GNN on Mini-ImageNet is much higher than CNN\ncontaining dozens of layers such as ResNet152.",
      "tldr_zh": "本研究探讨了如何桥接卷积神经网络(CNN)和图神经网络(GNN)，以结合二者的优势：CNN擅长提取样本内表示但训练成本高，而GNN能高效探索拓扑关系但限于图数据。论文提出CNN2GNN框架，通过一个可微分稀疏图学习模块动态生成图结构，并引入基于响应的知识蒸馏技术，将CNN的知识转移到GNN中，实现归纳学习。实验结果显示，在Mini-ImageNet数据集上，蒸馏后的两层GNN性能超过了如ResNet152等深层CNN，证明了该框架的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.14822v1",
      "published_date": "2024-04-23 08:19:08 UTC",
      "updated_date": "2024-04-23 08:19:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:01:16.202536"
    },
    {
      "arxiv_id": "2405.01574v1",
      "title": "On Using Agent-based Modeling and Simulation for Studying Blockchain Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Önder Gürcan"
      ],
      "abstract": "There is a need for a simulation framework, which is develop as a software\nusing modern engineering approaches (e.g., modularity --i.e., model reuse--,\ntesting, continuous development and continuous integration, automated\nmanagement of builds, dependencies and documentation) and agile principles, (1)\nto make rapid prototyping of industrial cases and (2) to carry out their\nfeasibility analysis in a realistic manner (i.e., to test hypothesis by\nsimulating complex experiments involving large numbers of participants of\ndifferent types acting in one or several blockchain systems).",
      "tldr_zh": "该论文探讨了使用 Agent-based Modeling and Simulation 来研究区块链系统的潜在价值，强调了开发一个先进的模拟框架的需求。框架采用现代工程方法，如 modularity、testing、continuous development and integration，以及 agile principles，以支持区块链工业案例的快速原型设计。该框架允许通过模拟涉及大量不同类型参与者的复杂实验，来以现实方式进行可行性分析和假设测试，从而提升区块链系统的研究效率。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "2 pages, \"JFMS 2020 -- Les Journees Francophones de la Modelisation\n  et de la Simulation -- Convergences entre la Theorie de la Modelisation et la\n  Simulation et les Systemes Multi-Agents\"",
      "pdf_url": "http://arxiv.org/pdf/2405.01574v1",
      "published_date": "2024-04-23 08:06:37 UTC",
      "updated_date": "2024-04-23 08:06:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:01:28.982927"
    },
    {
      "arxiv_id": "2404.14809v1",
      "title": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications",
      "title_zh": "翻译失败",
      "authors": [
        "Wenbo Shang",
        "Xin Huang"
      ],
      "abstract": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics.",
      "tldr_zh": "这篇调查论文探讨了大型语言模型(LLMs)在生成图分析(Generative Graph Analytics)中的应用，重点总结了LLMs如何处理图数据任务的优势，如无需训练图学习模型并减少手动标注成本。论文将LLM-based generative graph analytics(LLM-GGA)分为三类：LLM-based graph query processing(LLM-GQP)，包括图理解和知识图谱(KG)增强检索；LLM-based graph inference and learning(LLM-GIL)，涵盖图学习、推理和表示；以及基于图的LLM应用。最终，论文评估了LLM模型的优缺点、基准数据集，并指出了现有挑战和未来研究方向，如改进提示设计和跨领域整合。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.CL",
      "comment": "31 pages including references, 22 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.14809v1",
      "published_date": "2024-04-23 07:39:24 UTC",
      "updated_date": "2024-04-23 07:39:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:01:40.167828"
    },
    {
      "arxiv_id": "2404.15379v3",
      "title": "Clustering of timed sequences -- Application to the analysis of care pathways",
      "title_zh": "翻译失败",
      "authors": [
        "Thomas Guyet",
        "Pierre Pinson",
        "Enoal Gesny"
      ],
      "abstract": "Improving the future of healthcare starts by better understanding the current\nactual practices in hospital settings. This motivates the objective of\ndiscovering typical care pathways from patient data. Revealing typical care\npathways can be achieved through clustering. The difficulty in clustering care\npathways, represented by sequences of timestamped events, lies in defining a\nsemantically appropriate metric and clustering algorithms. In this article, we\nadapt two methods developed for time series to the clustering of timed\nsequences: the drop-DTW metric and the DBA approach for the construction of\naveraged time sequences. These methods are then applied in clustering\nalgorithms to propose original and sound clustering algorithms for timed\nsequences. This approach is experimented with and evaluated on synthetic and\nreal-world data.",
      "tldr_zh": "该论文探讨了通过聚类分析定时序列（timed sequences）来发现典型护理路径（care pathways），以更好地理解医院实际实践并改善医疗保健。作者改编了两种时间序列（time series）方法：drop-DTW 度量和 DBA 方法，用于构建平均时间序列，并将其整合到聚类算法中，以处理事件序列的语义挑战。在合成数据和真实世界数据上进行的实验验证了这一方法的有效性和适用性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.15379v3",
      "published_date": "2024-04-23 07:16:13 UTC",
      "updated_date": "2024-12-19 15:54:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:01:52.803517"
    },
    {
      "arxiv_id": "2404.14786v2",
      "title": "RealTCD: Temporal Causal Discovery from Interventional Data with Large Language Model",
      "title_zh": "RealTCD：利用大型语言模型从干预数据中进行时序因果发现",
      "authors": [
        "Peiwen Li",
        "Xin Wang",
        "Zeyang Zhang",
        "Yuan Meng",
        "Fang Shen",
        "Yue Li",
        "Jialong Wang",
        "Yang Li",
        "Wenweu Zhu"
      ],
      "abstract": "In the field of Artificial Intelligence for Information Technology\nOperations, causal discovery is pivotal for operation and maintenance of graph\nconstruction, facilitating downstream industrial tasks such as root cause\nanalysis. Temporal causal discovery, as an emerging method, aims to identify\ntemporal causal relationships between variables directly from observations by\nutilizing interventional data. However, existing methods mainly focus on\nsynthetic datasets with heavy reliance on intervention targets and ignore the\ntextual information hidden in real-world systems, failing to conduct causal\ndiscovery for real industrial scenarios. To tackle this problem, in this paper\nwe propose to investigate temporal causal discovery in industrial scenarios,\nwhich faces two critical challenges: 1) how to discover causal relationships\nwithout the interventional targets that are costly to obtain in practice, and\n2) how to discover causal relations via leveraging the textual information in\nsystems which can be complex yet abundant in industrial contexts. To address\nthese challenges, we propose the RealTCD framework, which is able to leverage\ndomain knowledge to discover temporal causal relationships without\ninterventional targets. Specifically, we first develop a score-based temporal\ncausal discovery method capable of discovering causal relations for root cause\nanalysis without relying on interventional targets through strategic masking\nand regularization. Furthermore, by employing Large Language Models (LLMs) to\nhandle texts and integrate domain knowledge, we introduce LLM-guided\nmeta-initialization to extract the meta-knowledge from textual information\nhidden in systems to boost the quality of discovery. We conduct extensive\nexperiments on simulation and real-world datasets to show the superiority of\nour proposed RealTCD framework over existing baselines in discovering temporal\ncausal structures.",
      "tldr_zh": "该论文提出RealTCD框架，旨在解决工业场景中时间因果发现的挑战，包括无需依赖昂贵的干预目标和利用系统中的文本信息。RealTCD采用基于分数的因果发现方法，通过战略性掩码和正则化来识别时间因果关系，并引入Large Language Models (LLMs)引导的元初始化，以从文本中提取领域知识提升发现质量。实验结果显示，该框架在模拟和真实数据集上优于现有基线，在根因分析等任务中表现出色。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "stat.ME"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.14786v2",
      "published_date": "2024-04-23 06:52:40 UTC",
      "updated_date": "2024-05-26 13:08:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:02:05.768040"
    },
    {
      "arxiv_id": "2404.17598v1",
      "title": "Revealing and Utilizing In-group Favoritism for Graph-based Collaborative Filtering",
      "title_zh": "翻译失败",
      "authors": [
        "Hoin Jung",
        "Hyunsoo Cho",
        "Myungje Choi",
        "Joowon Lee",
        "Jung Ho Park",
        "Myungjoo Kang"
      ],
      "abstract": "When it comes to a personalized item recommendation system, It is essential\nto extract users' preferences and purchasing patterns. Assuming that users in\nthe real world form a cluster and there is common favoritism in each cluster,\nin this work, we introduce Co-Clustering Wrapper (CCW). We compute co-clusters\nof users and items with co-clustering algorithms and add CF subnetworks for\neach cluster to extract the in-group favoritism. Combining the features from\nthe networks, we obtain rich and unified information about users. We\nexperimented real world datasets considering two aspects: Finding the number of\ngroups divided according to in-group preference, and measuring the quantity of\nimprovement of the performance.",
      "tldr_zh": "本研究探讨了基于图的协同过滤(Graph-based Collaborative Filtering)中，用户群体的内部偏好(in-group favoritism)，假设用户形成集群并共享共同偏好。论文引入了Co-Clustering Wrapper (CCW)方法，通过co-clustering算法计算用户和物品的co-clusters，并为每个集群添加CF subnetworks，以提取和利用这些内部偏好，从而获得关于用户的丰富统一信息。在真实数据集上的实验验证了该方法在确定基于in-group preference的分组数量和提升推荐性能方面的有效性。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG",
        "cs.SI"
      ],
      "primary_category": "cs.IR",
      "comment": "7 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.17598v1",
      "published_date": "2024-04-23 06:43:58 UTC",
      "updated_date": "2024-04-23 06:43:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:02:15.992844"
    },
    {
      "arxiv_id": "2404.14771v1",
      "title": "Music Style Transfer With Diffusion Model",
      "title_zh": "基于扩散模型的音乐风格转移",
      "authors": [
        "Hong Huang",
        "Yuyi Wang",
        "Luyao Li",
        "Jun Lin"
      ],
      "abstract": "Previous studies on music style transfer have mainly focused on one-to-one\nstyle conversion, which is relatively limited. When considering the conversion\nbetween multiple styles, previous methods required designing multiple modes to\ndisentangle the complex style of the music, resulting in large computational\ncosts and slow audio generation. The existing music style transfer methods\ngenerate spectrograms with artifacts, leading to significant noise in the\ngenerated audio. To address these issues, this study proposes a music style\ntransfer framework based on diffusion models (DM) and uses spectrogram-based\nmethods to achieve multi-to-multi music style transfer. The GuideDiff method is\nused to restore spectrograms to high-fidelity audio, accelerating audio\ngeneration speed and reducing noise in the generated audio. Experimental\nresults show that our model has good performance in multi-mode music style\ntransfer compared to the baseline and can generate high-quality audio in\nreal-time on consumer-grade GPUs.",
      "tldr_zh": "本文提出了一种基于Diffusion Model (DM)的音乐风格转移框架，使用谱图方法实现多对多风格转换，解决了传统方法在计算成本高、音频生成慢和噪声问题上的局限性。该框架结合GuideDiff方法，将谱图恢复为高保真音频，显著加速生成过程并减少伪像。实验结果显示，该模型在多模式音乐风格转移中比基线表现更优，并在消费级GPU上实现实时高质量音频生成。",
      "categories": [
        "cs.SD",
        "cs.AI"
      ],
      "primary_category": "cs.SD",
      "comment": "8 pages, 6 figures, ICMC 2023",
      "pdf_url": "http://arxiv.org/pdf/2404.14771v1",
      "published_date": "2024-04-23 06:22:19 UTC",
      "updated_date": "2024-04-23 06:22:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:02:28.243262"
    },
    {
      "arxiv_id": "2404.14763v3",
      "title": "Evolutionary Reinforcement Learning via Cooperative Coevolution",
      "title_zh": "通过合作协同进化的进化强化学习",
      "authors": [
        "Chengpeng Hu",
        "Jialin Liu",
        "Xin Yao"
      ],
      "abstract": "Recently, evolutionary reinforcement learning has obtained much attention in\nvarious domains. Maintaining a population of actors, evolutionary reinforcement\nlearning utilises the collected experiences to improve the behaviour policy\nthrough efficient exploration. However, the poor scalability of genetic\noperators limits the efficiency of optimising high-dimensional neural\nnetworks.To address this issue, this paper proposes a novel cooperative\ncoevolutionary reinforcement learning (CoERL) algorithm. Inspired by\ncooperative coevolution, CoERL periodically and adaptively decomposes the\npolicy optimisation problem into multiple subproblems and evolves a population\nof neural networks for each of the subproblems. Instead of using genetic\noperators, CoERL directly searches for partial gradients to update the policy.\nUpdating policy with partial gradients maintains consistency between the\nbehaviour spaces of parents and offspring across generations.The experiences\ncollected by the population are then used to improve the entire policy, which\nenhances the sampling efficiency.Experiments on six benchmark locomotion tasks\ndemonstrate that CoERL outperforms seven state-of-the-art algorithms and\nbaselines.Ablation study verifies the unique contribution of CoERL's core\ningredients.",
      "tldr_zh": "这篇论文提出了一种新型算法Cooperative Coevolutionary Reinforcement Learning (CoERL)，旨在解决传统进化强化学习在优化高维神经网络时因遗传操作符扩展性差而导致的效率问题。CoERL受合作协同进化启发，通过定期自适应地将策略优化问题分解成多个子问题，并为每个子问题演化神经网络群体，同时使用部分梯度直接更新策略，以保持行为空间的一致性和提升采样效率。在六个基准运动任务上的实验显示，CoERL优于七个最先进算法和基线，且消融研究证实了其核心组件的独特贡献。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "This paper is accepted by 27th European Conference on Artificial\n  Intelligence",
      "pdf_url": "http://arxiv.org/pdf/2404.14763v3",
      "published_date": "2024-04-23 05:56:35 UTC",
      "updated_date": "2024-08-01 13:35:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:02:40.675869"
    },
    {
      "arxiv_id": "2404.14760v2",
      "title": "Retrieval Augmented Generation for Domain-specific Question Answering",
      "title_zh": "针对特定领域的问答的检索增强生成",
      "authors": [
        "Sanat Sharma",
        "David Seunghyun Yoon",
        "Franck Dernoncourt",
        "Dewang Sultania",
        "Karishma Bagga",
        "Mengjiao Zhang",
        "Trung Bui",
        "Varun Kotte"
      ],
      "abstract": "Question answering (QA) has become an important application in the advanced\ndevelopment of large language models. General pre-trained large language models\nfor question-answering are not trained to properly understand the knowledge or\nterminology for a specific domain, such as finance, healthcare, education, and\ncustomer service for a product. To better cater to domain-specific\nunderstanding, we build an in-house question-answering system for Adobe\nproducts. We propose a novel framework to compile a large question-answer\ndatabase and develop the approach for retrieval-aware finetuning of a Large\nLanguage model. We showcase that fine-tuning the retriever leads to major\nimprovements in the final generation. Our overall approach reduces\nhallucinations during generation while keeping in context the latest retrieval\ninformation for contextual grounding.",
      "tldr_zh": "这篇论文针对领域特定问答（QA）的挑战，提出了一种基于Retrieval Augmented Generation的框架，以提升大型语言模型（LLMs）在特定领域（如金融、健康或Adobe产品客服）中的表现。作者构建了一个内部QA系统，通过编译大型问答数据库并采用retrieval-aware finetuning方法来优化检索器，从而显著改善最终生成结果。该方法有效减少了生成时的hallucinations，并确保了检索信息的上下文grounding，增强了模型的准确性和相关性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "AAAI 2024 (Association for the Advancement of Artificial\n  Intelligence) Scientific Document Understanding Workshop",
      "pdf_url": "http://arxiv.org/pdf/2404.14760v2",
      "published_date": "2024-04-23 05:51:45 UTC",
      "updated_date": "2024-05-29 16:18:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:02:53.165526"
    },
    {
      "arxiv_id": "2404.14757v2",
      "title": "SST: Multi-Scale Hybrid Mamba-Transformer Experts for Long-Short Range Time Series Forecasting",
      "title_zh": "SST：多尺度混合 Mamba-Transformer 专家用于",
      "authors": [
        "Xiongxiao Xu",
        "Canyu Chen",
        "Yueqing Liang",
        "Baixiang Huang",
        "Guangji Bai",
        "Liang Zhao",
        "Kai Shu"
      ],
      "abstract": "Despite significant progress in time series forecasting, existing forecasters\noften overlook the heterogeneity between long-range and short-range time\nseries, leading to performance degradation in practical applications. In this\nwork, we highlight the need of distinct objectives tailored to different\nranges. We point out that time series can be decomposed into global patterns\nand local variations, which should be addressed separately in long- and\nshort-range time series. To meet the objectives, we propose a multi-scale\nhybrid Mamba-Transformer experts model State Space Transformer (SST). SST\nleverages Mamba as an expert to extract global patterns in coarse-grained\nlong-range time series, and Local Window Transformer (LWT), the other expert to\nfocus on capturing local variations in fine-grained short-range time series.\nWith an input-dependent mechanism, State Space Model (SSM)-based Mamba is able\nto selectively retain long-term patterns and filter out fluctuations, while LWT\nemploys a local window to enhance locality-awareness capability, thus\neffectively capturing local variations. To adaptively integrate the global\npatterns and local variations, a long-short router dynamically adjusts\ncontributions of the two experts. SST achieves superior performance with\nscaling linearly $O(L)$ on time series length $L$. The comprehensive\nexperiments demonstrate the SST can achieve SOTA results in long-short range\ntime series forecasting while maintaining low memory footprint and\ncomputational cost. The code of SST is available at\nhttps://github.com/XiongxiaoXu/SST.",
      "tldr_zh": "这篇论文指出现有时间序列预测模型忽略了长短期序列的异质性，导致性能下降，并提出 SST（State Space Transformer）模型来针对性地处理长序列的全局模式和短序列的局部变化。SST 采用多尺度混合专家架构，使用 Mamba 专家提取粗粒度长序列中的全局模式，以及 Local Window Transformer (LWT) 专家捕获细粒度短序列中的局部变化，并通过长短期路由器动态整合两者。实验结果显示，SST 在长短期时间序列预测中达到 SOTA 性能，同时实现线性复杂度 O(L) 并保持低内存和计算成本。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.14757v2",
      "published_date": "2024-04-23 05:43:44 UTC",
      "updated_date": "2024-08-22 17:55:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:03:07.443712"
    },
    {
      "arxiv_id": "2404.14755v2",
      "title": "SkinGEN: an Explainable Dermatology Diagnosis-to-Generation Framework with Interactive Vision-Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Bo Lin",
        "Yingjing Xu",
        "Xuanwen Bao",
        "Zhou Zhao",
        "Zhouyang Wang",
        "Jianwei Yin"
      ],
      "abstract": "With the continuous advancement of vision language models (VLMs) technology,\nremarkable research achievements have emerged in the dermatology field, the\nfourth most prevalent human disease category. However, despite these\nadvancements, VLM still faces explainable problems to user in diagnosis due to\nthe inherent complexity of dermatological conditions, existing tools offer\nrelatively limited support for user comprehension. We propose SkinGEN, a\ndiagnosis-to-generation framework that leverages the stable diffusion(SD) model\nto generate reference demonstrations from diagnosis results provided by VLM,\nthereby enhancing the visual explainability for users. Through extensive\nexperiments with Low-Rank Adaptation (LoRA), we identify optimal strategies for\nskin condition image generation. We conduct a user study with 32 participants\nevaluating both the system performance and explainability. Results demonstrate\nthat SkinGEN significantly improves users' comprehension of VLM predictions and\nfosters increased trust in the diagnostic process. This work paves the way for\nmore transparent and user-centric VLM applications in dermatology and beyond.",
      "tldr_zh": "本研究提出SkinGEN框架，利用交互式视觉语言模型(VLMs)从诊断结果生成参考演示图像，以提升皮肤病诊断的可解释性。该框架结合Stable Diffusion(SD)模型和Low-Rank Adaptation(LoRA)技术，通过优化实验策略来生成高质量的皮肤病图像。用户研究涉及32名参与者，结果显示SkinGEN显著提高了用户对VLM预测的理解，并增强了对诊断过程的信任。该工作为更透明的用户中心VLM应用在皮肤病及其他领域铺平了道路。",
      "categories": [
        "cs.MM",
        "cs.AI",
        "cs.CV",
        "cs.HC"
      ],
      "primary_category": "cs.MM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.14755v2",
      "published_date": "2024-04-23 05:36:33 UTC",
      "updated_date": "2025-02-13 03:15:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:03:17.254281"
    },
    {
      "arxiv_id": "2404.14754v1",
      "title": "Skip the Benchmark: Generating System-Level High-Level Synthesis Data using Generative Machine Learning",
      "title_zh": "跳过基准测试：使用生成式机器学习生成系统级高层次综合数据",
      "authors": [
        "Yuchao Liao",
        "Tosiron Adegbija",
        "Roman Lysecky",
        "Ravi Tandon"
      ],
      "abstract": "High-Level Synthesis (HLS) Design Space Exploration (DSE) is a widely\naccepted approach for efficiently exploring Pareto-optimal and optimal hardware\nsolutions during the HLS process. Several HLS benchmarks and datasets are\navailable for the research community to evaluate their methodologies.\nUnfortunately, these resources are limited and may not be sufficient for\ncomplex, multi-component system-level explorations. Generating new data using\nexisting HLS benchmarks can be cumbersome, given the expertise and time\nrequired to effectively generate data for different HLS designs and directives.\nAs a result, synthetic data has been used in prior work to evaluate\nsystem-level HLS DSE. However, the fidelity of the synthetic data to real data\nis often unclear, leading to uncertainty about the quality of system-level HLS\nDSE. This paper proposes a novel approach, called Vaegan, that employs\ngenerative machine learning to generate synthetic data that is robust enough to\nsupport complex system-level HLS DSE experiments that would be unattainable\nwith only the currently available data. We explore and adapt a Variational\nAutoencoder (VAE) and Generative Adversarial Network (GAN) for this task and\nevaluate our approach using state-of-the-art datasets and metrics. We compare\nour approach to prior works and show that Vaegan effectively generates\nsynthetic HLS data that closely mirrors the ground truth's distribution.",
      "tldr_zh": "这篇论文针对 High-Level Synthesis (HLS) Design Space Exploration (DSE) 的数据集限制问题，提出了一种名为 Vaegan 的新方法，利用生成式机器学习生成合成数据，以支持复杂的系统级 HLS 实验。Vaegan 结合 Variational Autoencoder (VAE) 和 Generative Adversarial Network (GAN) 技术，生成的数据分布更接近真实数据，避免了依赖有限基准的难题。实验评估显示，Vaegan 与现有方法相比，能更有效地模拟真实分布，提升了系统级 HLS DSE 的可靠性和适用性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.AR"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at Great Lakes Symposium on VLSI 2024 (GLSVLSI 24)",
      "pdf_url": "http://arxiv.org/pdf/2404.14754v1",
      "published_date": "2024-04-23 05:32:22 UTC",
      "updated_date": "2024-04-23 05:32:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:03:30.809763"
    },
    {
      "arxiv_id": "2404.14750v2",
      "title": "Grounded Knowledge-Enhanced Medical Vision-Language Pre-training for Chest X-Ray",
      "title_zh": "翻译失败",
      "authors": [
        "Qiao Deng",
        "Zhongzhen Huang",
        "Yunqi Wang",
        "Zhichuan Wang",
        "Zhao Wang",
        "Xiaofan Zhang",
        "Qi Dou",
        "Yeung Yu Hui",
        "Edward S. Hui"
      ],
      "abstract": "Medical foundation models have the potential to revolutionize healthcare by\nproviding robust and generalized representations of medical data. Medical\nvision-language pre-training has emerged as a promising approach for learning\ndomain-general representations of medical image and text. Current algorithms\nthat exploit global and local alignment between medical image and text could\nhowever be marred by redundant information in medical data. To address this\nissue, we propose a grounded knowledge-enhanced medical vision-language\npre-training (GK-MVLP) framework for chest X-ray. In this framework, medical\nknowledge was grounded to the appropriate anatomical regions by using a\ntransformer-based grounded knowledge-enhanced module for fine-grained alignment\nbetween textural features of medical knowledge and the corresponding anatomical\nregion-level visual features. The performance of GK-MVLP was competitive with\nor exceeded the state of the art on downstream image understanding tasks (chest\nX-ray disease classification, disease localization), generative task (report\ngeneration), and vision-language understanding task (medical visual\nquestion-answering). Our results demonstrate the advantage of incorporating\ngrounding mechanism to remove biases and improve the alignment between chest\nX-ray image and radiology report.",
      "tldr_zh": "这篇论文提出了 Grounded Knowledge-Enhanced Medical Vision-Language Pre-training (GK-MVLP) 框架，用于胸部 X-ray 的医疗视觉语言预训练，以解决现有算法因冗余信息导致的对齐问题。该框架利用基于 Transformer 的模块，将医疗知识 grounding 到相应的解剖区域，实现文本特征与区域级视觉特征的细粒度对齐。实验结果显示，GK-MVLP 在下游任务中表现出色，包括胸部 X-ray 疾病分类、定位、报告生成和医疗视觉问答等，超过了现有方法，并证明了 grounding 机制在去除偏差和提升图像与报告对齐方面的优势。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.14750v2",
      "published_date": "2024-04-23 05:16:24 UTC",
      "updated_date": "2025-02-17 02:49:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:03:42.815517"
    },
    {
      "arxiv_id": "2404.14746v1",
      "title": "A Customer Level Fraudulent Activity Detection Benchmark for Enhancing Machine Learning Model Research and Evaluation",
      "title_zh": "翻译失败",
      "authors": [
        "Phoebe Jing",
        "Yijing Gao",
        "Xianlong Zeng"
      ],
      "abstract": "In the field of fraud detection, the availability of comprehensive and\nprivacy-compliant datasets is crucial for advancing machine learning research\nand developing effective anti-fraud systems. Traditional datasets often focus\non transaction-level information, which, while useful, overlooks the broader\ncontext of customer behavior patterns that are essential for detecting\nsophisticated fraud schemes. The scarcity of such data, primarily due to\nprivacy concerns, significantly hampers the development and testing of\npredictive models that can operate effectively at the customer level.\nAddressing this gap, our study introduces a benchmark that contains structured\ndatasets specifically designed for customer-level fraud detection. The\nbenchmark not only adheres to strict privacy guidelines to ensure user\nconfidentiality but also provides a rich source of information by encapsulating\ncustomer-centric features. We have developed the benchmark that allows for the\ncomprehensive evaluation of various machine learning models, facilitating a\ndeeper understanding of their strengths and weaknesses in predicting fraudulent\nactivities. Through this work, we seek to bridge the existing gap in data\navailability, offering researchers and practitioners a valuable resource that\nempowers the development of next-generation fraud detection techniques.",
      "tldr_zh": "本文针对欺诈检测领域的数据集不足问题，强调了客户级信息的缺失（如客户行为模式）对机器学习模型（machine learning models）开发的影响，并指出隐私担忧是主要障碍。研究贡献了一个新的欺诈检测 benchmark，该基准包含结构化的客户中心数据集，严格遵守隐私指南并提供丰富特征。借助这个 benchmark，研究者可以全面评估各种机器学习模型的优缺点，从而推动更有效的下一代欺诈检测技术的创新。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages, 3 figures, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2404.14746v1",
      "published_date": "2024-04-23 04:57:44 UTC",
      "updated_date": "2024-04-23 04:57:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:03:55.967908"
    },
    {
      "arxiv_id": "2404.14741v3",
      "title": "Generate-on-Graph: Treat LLM as both Agent and KG in Incomplete Knowledge Graph Question Answering",
      "title_zh": "翻译失败",
      "authors": [
        "Yao Xu",
        "Shizhu He",
        "Jiabei Chen",
        "Zihao Wang",
        "Yangqiu Song",
        "Hanghang Tong",
        "Guang Liu",
        "Kang Liu",
        "Jun Zhao"
      ],
      "abstract": "To address the issues of insufficient knowledge and hallucination in Large\nLanguage Models (LLMs), numerous studies have explored integrating LLMs with\nKnowledge Graphs (KGs). However, these methods are typically evaluated on\nconventional Knowledge Graph Question Answering (KGQA) with complete KGs, where\nall factual triples required for each question are entirely covered by the\ngiven KG. In such cases, LLMs primarily act as an agent to find answer entities\nwithin the KG, rather than effectively integrating the internal knowledge of\nLLMs and external knowledge sources such as KGs. In fact, KGs are often\nincomplete to cover all the knowledge required to answer questions. To simulate\nthese real-world scenarios and evaluate the ability of LLMs to integrate\ninternal and external knowledge, we propose leveraging LLMs for QA under\nIncomplete Knowledge Graph (IKGQA), where the provided KG lacks some of the\nfactual triples for each question, and construct corresponding datasets. To\nhandle IKGQA, we propose a training-free method called Generate-on-Graph (GoG),\nwhich can generate new factual triples while exploring KGs. Specifically, GoG\nperforms reasoning through a Thinking-Searching-Generating framework, which\ntreats LLM as both Agent and KG in IKGQA. Experimental results on two datasets\ndemonstrate that our GoG outperforms all previous methods.",
      "tldr_zh": "该研究针对大型语言模型(LLM)存在的知识不足和幻觉问题，提出在不完整知识图谱(Incomplete Knowledge Graph, IKGQA)场景下进行问答评估，构建了相应的数据集，以模拟真实世界情况。作者引入了无训练方法Generate-on-Graph (GoG)，通过Thinking-Searching-Generating框架，将LLM同时视为代理(Agent)和知识图谱(KG)，从而生成新的事实三元组(factual triples)并进行推理。实验结果显示，GoG在两个数据集上优于现有方法，证明了其在整合内部和外部知识方面的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by EMNLP 2024 Main",
      "pdf_url": "http://arxiv.org/pdf/2404.14741v3",
      "published_date": "2024-04-23 04:47:22 UTC",
      "updated_date": "2024-10-06 10:55:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:04:05.765728"
    },
    {
      "arxiv_id": "2404.14736v1",
      "title": "Qualitative Approaches to Voice UX",
      "title_zh": "翻译失败",
      "authors": [
        "Katie Seaborn",
        "Jacqueline Urakami",
        "Peter Pennefather",
        "Norihisa P. Miyake"
      ],
      "abstract": "Voice is a natural mode of expression offered by modern computer-based\nsystems. Qualitative perspectives on voice-based user experiences (voice UX)\noffer rich descriptions of complex interactions that numbers alone cannot fully\nrepresent. We conducted a systematic review of the literature on qualitative\napproaches to voice UX, capturing the nature of this body of work in a\nsystematic map and offering a qualitative synthesis of findings. We highlight\nthe benefits of qualitative methods for voice UX research, identify\nopportunities for increasing rigour in methods and outcomes, and distill\npatterns of experience across a diversity of devices and modes of qualitative\npraxis.",
      "tldr_zh": "这篇论文探讨了定性方法在语音用户体验（voice UX）中的应用，通过系统文献回顾和定性综合分析，提供了对复杂互动的丰富描述。研究强调了定性方法的好处，例如捕捉数字无法完全代表的互动细节，并识别了提升方法和结果严谨性的机会。最终，论文提炼了跨多种设备和定性实践模式的经验模式，为voice UX 研究提供了宝贵见解。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL",
        "cs.CY",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.14736v1",
      "published_date": "2024-04-23 04:33:49 UTC",
      "updated_date": "2024-04-23 04:33:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:04:17.456527"
    },
    {
      "arxiv_id": "2407.05181v1",
      "title": "Instructors as Innovators: A future-focused approach to new AI learning opportunities, with prompts",
      "title_zh": "翻译失败",
      "authors": [
        "Ethan Mollick",
        "Lilach Mollick"
      ],
      "abstract": "This paper explores how instructors can leverage generative AI to create\npersonalized learning experiences for students that transform teaching and\nlearning. We present a range of AI-based exercises that enable novel forms of\npractice and application including simulations, mentoring, coaching, and\nco-creation. For each type of exercise, we provide prompts that instructors can\ncustomize, along with guidance on classroom implementation, assessment, and\nrisks to consider. We also provide blueprints, prompts that help instructors\ncreate their own original prompts. Instructors can leverage their content and\npedagogical expertise to design these experiences, putting them in the role of\nbuilders and innovators. We argue that this instructor-driven approach has the\npotential to democratize the development of educational technology by enabling\nindividual instructors to create AI exercises and tools tailored to their\nstudents' needs. While the exercises in this paper are a starting point, not a\ndefinitive solutions, they demonstrate AI's potential to expand what is\npossible in teaching and learning.",
      "tldr_zh": "这篇论文探讨教师如何利用生成式 AI（Generative AI）创建个性化的学习体验，从而革新教学方式。论文介绍了多种 AI 基于的练习类型，包括 simulations、mentoring、coaching 和 co-creation，并为每种类型提供可定制的 prompts、课堂实施指导、评估方法以及风险考虑，还包括 blueprints 来帮助教师设计原创 prompts。作者强调，这种教师主导的方法能让个体教师成为教育技术的构建者和创新者，从而民主化教育工具的开发，尽管这些练习仅是起点，但展示了 AI 在扩展教学可能性的潜力。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "Includes prompts in Appendixes A and B",
      "pdf_url": "http://arxiv.org/pdf/2407.05181v1",
      "published_date": "2024-04-23 04:01:38 UTC",
      "updated_date": "2024-04-23 04:01:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:04:30.267891"
    },
    {
      "arxiv_id": "2404.14716v2",
      "title": "Bayesian Example Selection Improves In-Context Learning for Speech, Text, and Visual Modalities",
      "title_zh": "翻译失败",
      "authors": [
        "Siyin Wang",
        "Chao-Han Huck Yang",
        "Ji Wu",
        "Chao Zhang"
      ],
      "abstract": "Large language models (LLMs) can adapt to new tasks through in-context\nlearning (ICL) based on a few examples presented in dialogue history without\nany model parameter update. Despite such convenience, the performance of ICL\nheavily depends on the quality of the in-context examples presented, which\nmakes the in-context example selection approach a critical choice. This paper\nproposes a novel Bayesian in-Context example Selection method (ByCS) for ICL.\nExtending the inference probability conditioned on in-context examples based on\nBayes' theorem, ByCS focuses on the inverse inference conditioned on test\ninput. Following the assumption that accurate inverse inference probability\n(likelihood) will result in accurate inference probability (posterior),\nin-context examples are selected based on their inverse inference results.\nDiverse and extensive cross-tasking and cross-modality experiments are\nperformed with speech, text, and image examples. Experimental results show the\nefficacy and robustness of our ByCS method on various models, tasks and\nmodalities.",
      "tldr_zh": "这篇论文提出了一种Bayesian in-Context example Selection (ByCS)方法，以提升大型语言模型(LLMs)在语音、文本和视觉模态上的In-Context Learning (ICL)性能，因为ICL的效果高度依赖于in-context examples的质量。ByCS基于Bayes' theorem，通过关注测试输入的逆向推理概率来选择示例，假设准确的逆向推理将导致更可靠的整体推理结果。实验在多样化的跨任务和跨模态场景中进行，结果显示ByCS在各种模型、任务和模态上表现出色，具有显著的效能和鲁棒性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "17 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.14716v2",
      "published_date": "2024-04-23 03:42:48 UTC",
      "updated_date": "2024-06-16 08:49:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:04:42.247840"
    },
    {
      "arxiv_id": "2404.14712v5",
      "title": "ORBIT: Oak Ridge Base Foundation Model for Earth System Predictability",
      "title_zh": "翻译失败",
      "authors": [
        "Xiao Wang",
        "Siyan Liu",
        "Aristeidis Tsaris",
        "Jong-Youl Choi",
        "Ashwin Aji",
        "Ming Fan",
        "Wei Zhang",
        "Junqi Yin",
        "Moetasim Ashfaq",
        "Dan Lu",
        "Prasanna Balaprakash"
      ],
      "abstract": "Earth system predictability is challenged by the complexity of environmental\ndynamics and the multitude of variables involved. Current AI foundation models,\nalthough advanced by leveraging large and heterogeneous data, are often\nconstrained by their size and data integration, limiting their effectiveness in\naddressing the full range of Earth system prediction challenges. To overcome\nthese limitations, we introduce the Oak Ridge Base Foundation Model for Earth\nSystem Predictability (ORBIT), an advanced vision transformer model that scales\nup to 113 billion parameters using a novel hybrid tensor-data orthogonal\nparallelism technique. As the largest model of its kind, ORBIT surpasses the\ncurrent climate AI foundation model size by a thousandfold. Performance scaling\ntests conducted on the Frontier supercomputer have demonstrated that ORBIT\nachieves 684 petaFLOPS to 1.6 exaFLOPS sustained throughput, with scaling\nefficiency maintained at 41% to 85% across 49,152 AMD GPUs. These breakthroughs\nestablish new advances in AI-driven climate modeling and demonstrate promise to\nsignificantly improve the Earth system predictability.",
      "tldr_zh": "该研究针对地球系统预测的复杂性和变量多样性问题，引入了 ORBIT（Oak Ridge Base Foundation Model），这是一种规模达113亿参数的先进vision transformer模型，采用hybrid tensor-data orthogonal parallelism技术来提升数据整合和计算效率。相比现有气候AI基础模型，ORBIT的规模扩大一千倍，并在Frontier超级计算机上实现了684 petaFLOPS到1.6 exaFLOPS的持续吞吐量，扩展效率在49,152 AMD GPUs上维持41%至85%。这些进展为AI驱动的气候建模带来新突破，并显著提高了地球系统预测的可行性。",
      "categories": [
        "physics.ao-ph",
        "cs.AI",
        "cs.DC",
        "eess.IV",
        "physics.geo-ph"
      ],
      "primary_category": "physics.ao-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.14712v5",
      "published_date": "2024-04-23 03:39:57 UTC",
      "updated_date": "2024-08-19 15:20:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:04:55.376520"
    },
    {
      "arxiv_id": "2406.06535v3",
      "title": "Utilizing Graph Generation for Enhanced Domain Adaptive Object Detection",
      "title_zh": "利用图生成增强领域自适应目标检测",
      "authors": [
        "Mu Wang"
      ],
      "abstract": "The problem of Domain Adaptive in the field of Object Detection involves the\ntransfer of object detection models from labeled source domains to unannotated\ntarget domains. Recent advancements in this field aim to address domain\ndiscrepancies by aligning pixel-pairs across domains within a non-Euclidean\ngraphical space, thereby minimizing semantic distribution variance. Despite\ntheir remarkable achievements, these methods often use coarse semantic\nrepresentations to model graphs, mainly due to ignoring non-informative\nelements and failing to focus on precise semantic alignment. Additionally, the\ngeneration of coarse graphs inherently introduces abnormal nodes, posing\nchallenges and potentially biasing domain adaptation outcomes. Consequently, we\npropose a framework, which utilizes the Graph Generation to enhance the quality\nof DAOD (\\method{}). Specifically, we introduce a Node Refinement module that\nutilizes a memory bank to reconstruct noisy sampled nodes while applying\ncontrastive regularization to noisy features. To enhance semantic alignment, we\npropose separating domain-specific styles from category invariance encoded\nwithin graph covariances, which allows us to selectively remove domain-specific\nstyles while preserving category-invariant information, thus facilitating more\naccurate semantic alignment across different domains. Furthermore, we propose a\nGraph Optimization adaptor, leveraging variational inference to mitigate the\nimpact of abnormal nodes. Extensive experimentation across three adaptation\nbenchmarks validates that \\method{} achieves state-of-the-art performance in\nthe task of unsupervised domain adaptation.",
      "tldr_zh": "该研究针对 Domain Adaptive Object Detection (DAOD) 的挑战，提出了一种利用 Graph Generation 的框架，以解决现有方法在语义对齐中忽略非信息元素和引入异常节点的问题。具体而言，该框架包括 Node Refinement 模块，通过内存银行重建噪声节点并应用对比正则化，以及分离域特定风格和类别不变信息以实现更精确的语义对齐，同时引入 Graph Optimization adaptor 利用变分推理减少异常节点的影响。实验结果显示，该方法在三个无监督域适应基准上实现了最先进性能，显著提升了对象检测模型的跨域适应能力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.06535v3",
      "published_date": "2024-04-23 03:11:08 UTC",
      "updated_date": "2024-11-12 02:10:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:05:07.895088"
    },
    {
      "arxiv_id": "2404.15378v3",
      "title": "Hierarchical Hybrid Sliced Wasserstein: A Scalable Metric for Heterogeneous Joint Distributions",
      "title_zh": "翻译失败",
      "authors": [
        "Khai Nguyen",
        "Nhat Ho"
      ],
      "abstract": "Sliced Wasserstein (SW) and Generalized Sliced Wasserstein (GSW) have been\nwidely used in applications due to their computational and statistical\nscalability. However, the SW and the GSW are only defined between distributions\nsupported on a homogeneous domain. This limitation prevents their usage in\napplications with heterogeneous joint distributions with marginal distributions\nsupported on multiple different domains. Using SW and GSW directly on the joint\ndomains cannot make a meaningful comparison since their homogeneous slicing\noperator i.e., Radon Transform (RT) and Generalized Radon Transform (GRT) are\nnot expressive enough to capture the structure of the joint supports set. To\naddress the issue, we propose two new slicing operators i.e., Partial\nGeneralized Radon Transform (PGRT) and Hierarchical Hybrid Radon Transform\n(HHRT). In greater detail, PGRT is the generalization of Partial Radon\nTransform (PRT), which transforms a subset of function arguments non-linearly\nwhile HHRT is the composition of PRT and multiple domain-specific PGRT on\nmarginal domain arguments. By using HHRT, we extend the SW into Hierarchical\nHybrid Sliced Wasserstein (H2SW) distance which is designed specifically for\ncomparing heterogeneous joint distributions. We then discuss the topological,\nstatistical, and computational properties of H2SW. Finally, we demonstrate the\nfavorable performance of H2SW in 3D mesh deformation, deep 3D mesh\nautoencoders, and datasets comparison.",
      "tldr_zh": "该论文针对 Sliced Wasserstein (SW) 和 Generalized Sliced Wasserstein (GSW) 仅适用于同质域分布的局限性，提出两种新 slicing operators：Partial Generalized Radon Transform (PGRT) 和 Hierarchical Hybrid Radon Transform (HHRT)，以处理异质联合分布。HHRT 通过结合 PRT 和多个 domain-specific PGRT，实现对异质域的非线性变换，从而扩展 SW 为 Hierarchical Hybrid Sliced Wasserstein (H2SW) 距离，用于更精确地比较异质联合分布。论文分析了 H2SW 的拓扑、统计和计算属性，并在 3D 网格变形、深度 3D 网格自编码器以及数据集比较等应用中展示了其优越性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to NeurIPS 2024, 27 pages, 11 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2404.15378v3",
      "published_date": "2024-04-23 03:04:22 UTC",
      "updated_date": "2024-10-08 01:39:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:05:20.575017"
    },
    {
      "arxiv_id": "2404.14700v4",
      "title": "FlashSpeech: Efficient Zero-Shot Speech Synthesis",
      "title_zh": "FlashSpeech：高效零样本语音合成",
      "authors": [
        "Zhen Ye",
        "Zeqian Ju",
        "Haohe Liu",
        "Xu Tan",
        "Jianyi Chen",
        "Yiwen Lu",
        "Peiwen Sun",
        "Jiahao Pan",
        "Weizhen Bian",
        "Shulin He",
        "Wei Xue",
        "Qifeng Liu",
        "Yike Guo"
      ],
      "abstract": "Recent progress in large-scale zero-shot speech synthesis has been\nsignificantly advanced by language models and diffusion models. However, the\ngeneration process of both methods is slow and computationally intensive.\nEfficient speech synthesis using a lower computing budget to achieve quality on\npar with previous work remains a significant challenge. In this paper, we\npresent FlashSpeech, a large-scale zero-shot speech synthesis system with\napproximately 5\\% of the inference time compared with previous work.\nFlashSpeech is built on the latent consistency model and applies a novel\nadversarial consistency training approach that can train from scratch without\nthe need for a pre-trained diffusion model as the teacher. Furthermore, a new\nprosody generator module enhances the diversity of prosody, making the rhythm\nof the speech sound more natural. The generation processes of FlashSpeech can\nbe achieved efficiently with one or two sampling steps while maintaining high\naudio quality and high similarity to the audio prompt for zero-shot speech\ngeneration. Our experimental results demonstrate the superior performance of\nFlashSpeech. Notably, FlashSpeech can be about 20 times faster than other\nzero-shot speech synthesis systems while maintaining comparable performance in\nterms of voice quality and similarity. Furthermore, FlashSpeech demonstrates\nits versatility by efficiently performing tasks like voice conversion, speech\nediting, and diverse speech sampling. Audio samples can be found in\nhttps://flashspeech.github.io/.",
      "tldr_zh": "本文提出 FlashSpeech，一种高效的 zero-shot speech synthesis 系统，其推理时间仅为先前工作的 5%，生成速度可达 20 倍加速。FlashSpeech 基于 latent consistency model，并采用新型 adversarial consistency training 方法，从零开始训练，同时引入 prosody generator 模块来增强语音的多样性和自然节奏。实验结果显示，该系统在保持高音频质量和与音频提示的高相似度前提下，能高效处理语音转换、语音编辑和多样语音采样任务。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "Efficient zero-shot speech synthesis",
      "pdf_url": "http://arxiv.org/pdf/2404.14700v4",
      "published_date": "2024-04-23 02:57:46 UTC",
      "updated_date": "2024-10-24 08:19:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:05:32.887004"
    },
    {
      "arxiv_id": "2404.14688v3",
      "title": "FMint: Bridging Human Designed and Data Pretrained Models for Differential Equation Foundation Model",
      "title_zh": "翻译失败",
      "authors": [
        "Zezheng Song",
        "Jiaxin Yuan",
        "Haizhao Yang"
      ],
      "abstract": "The fast simulation of dynamical systems is a key challenge in many\nscientific and engineering applications, such as weather forecasting, disease\ncontrol, and drug discovery. With the recent success of deep learning, there is\nincreasing interest in using neural networks to solve differential equations in\na data-driven manner. However, existing methods are either limited to specific\ntypes of differential equations or require large amounts of data for training.\nThis restricts their practicality in many real-world applications, where data\nis often scarce or expensive to obtain. To address this, we propose a novel\nmulti-modal foundation model, named \\textbf{FMint} (\\textbf{F}oundation\n\\textbf{M}odel based on \\textbf{In}i\\textbf{t}ialization), to bridge the gap\nbetween human-designed and data-driven models for the fast simulation of\ndynamical systems. Built on a decoder-only transformer architecture with\nin-context learning, FMint utilizes both numerical and textual data to learn a\nuniversal error correction scheme for dynamical systems, using prompted\nsequences of coarse solutions from traditional solvers. The model is\npre-trained on a corpus of 40K ODEs, and we perform extensive experiments on\nchallenging ODEs that exhibit chaotic behavior and of high dimensionality. Our\nresults demonstrate the effectiveness of the proposed model in terms of both\naccuracy and efficiency compared to classical numerical solvers, highlighting\nFMint's potential as a general-purpose solver for dynamical systems. Our\napproach achieves an accuracy improvement of 1 to 2 orders of magnitude over\nstate-of-the-art dynamical system simulators, and delivers a 5X speedup\ncompared to traditional numerical algorithms. The code for FMint is available\nat \\url{https://github.com/margotyjx/FMint}.",
      "tldr_zh": "该论文提出FMint，一种多模态基础模型，用于桥接人类设计的模型和数据驱动模型，以实现动态系统的快速模拟。该模型基于解码器-only transformer架构，支持in-context learning，通过利用数值和文本数据学习通用的错误修正方案，并使用传统求解器的粗略解决方案进行提示序列训练。在40K ODEs的语料上预训练后，FMint在具有混沌行为和高维度挑战性ODEs上的实验中，相比经典数值求解器准确性提高了1到2个数量级，并实现了5倍的速度提升，展示了其作为通用动态系统求解器的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE",
        "cs.NA",
        "math.DS",
        "math.NA"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.14688v3",
      "published_date": "2024-04-23 02:36:47 UTC",
      "updated_date": "2024-09-30 19:50:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:05:45.315887"
    },
    {
      "arxiv_id": "2404.14687v1",
      "title": "Pegasus-v1 Technical Report",
      "title_zh": "Pegasus-v1 技术报告",
      "authors": [
        "Raehyuk Jung",
        "Hyojun Go",
        "Jaehyuk Yi",
        "Jiho Jang",
        "Daniel Kim",
        "Jay Suh",
        "Aiden Lee",
        "Cooper Han",
        "Jae Lee",
        "Jeff Kim",
        "Jin-Young Kim",
        "Junwan Kim",
        "Kyle Park",
        "Lucas Lee",
        "Mars Ha",
        "Minjoon Seo",
        "Abraham Jo",
        "Ed Park",
        "Hassan Kianinejad",
        "SJ Kim",
        "Tony Moon",
        "Wade Jeong",
        "Andrei Popescu",
        "Esther Kim",
        "EK Yoon",
        "Genie Heo",
        "Henry Choi",
        "Jenna Kang",
        "Kevin Han",
        "Noah Seo",
        "Sunny Nguyen",
        "Ryan Won",
        "Yeonhoo Park",
        "Anthony Giuliani",
        "Dave Chung",
        "Hans Yoon",
        "James Le",
        "Jenny Ahn",
        "June Lee",
        "Maninder Saini",
        "Meredith Sanders",
        "Soyoung Lee",
        "Sue Kim",
        "Travis Couture"
      ],
      "abstract": "This technical report introduces Pegasus-1, a multimodal language model\nspecialized in video content understanding and interaction through natural\nlanguage. Pegasus-1 is designed to address the unique challenges posed by video\ndata, such as interpreting spatiotemporal information, to offer nuanced video\ncontent comprehension across various lengths. This technical report overviews\nPegasus-1's architecture, training strategies, and its performance in\nbenchmarks on video conversation, zero-shot video question answering, and video\nsummarization. We also explore qualitative characteristics of Pegasus-1 ,\ndemonstrating its capabilities as well as its limitations, in order to provide\nreaders a balanced view of its current state and its future direction.",
      "tldr_zh": "这篇技术报告介绍了Pegasus-1，一种专注于视频内容理解和自然语言交互的多模态语言模型，旨在处理视频数据的时空信息挑战，实现对不同长度视频的细致解读。报告概述了Pegasus-1的架构设计和训练策略，包括如何优化模型在视频对话、zero-shot video question answering和video summarization等基准上的性能。实验结果显示，Pegasus-1在这些任务中表现出色，同时报告还分析了其定性特征，如优势和局限性，以提供平衡的评估和未来发展方向。",
      "categories": [
        "cs.MM",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.MM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.14687v1",
      "published_date": "2024-04-23 02:32:57 UTC",
      "updated_date": "2024-04-23 02:32:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:05:55.924022"
    },
    {
      "arxiv_id": "2404.14680v1",
      "title": "Automated Multi-Language to English Machine Translation Using Generative Pre-Trained Transformers",
      "title_zh": "基于生成式预训练变换器的自动多语言到英语机器翻译",
      "authors": [
        "Elijah Pelofske",
        "Vincent Urias",
        "Lorie M. Liebrock"
      ],
      "abstract": "The task of accurate and efficient language translation is an extremely\nimportant information processing task. Machine learning enabled and automated\ntranslation that is accurate and fast is often a large topic of interest in the\nmachine learning and data science communities. In this study, we examine using\nlocal Generative Pretrained Transformer (GPT) models to perform automated zero\nshot black-box, sentence wise, multi-natural-language translation into English\ntext. We benchmark 16 different open-source GPT models, with no custom\nfine-tuning, from the Huggingface LLM repository for translating 50 different\nnon-English languages into English using translated TED Talk transcripts as the\nreference dataset. These GPT model inference calls are performed strictly\nlocally, on single A100 Nvidia GPUs. Benchmark metrics that are reported are\nlanguage translation accuracy, using BLEU, GLEU, METEOR, and chrF text overlap\nmeasures, and wall-clock time for each sentence translation. The best overall\nperforming GPT model for translating into English text for the BLEU metric is\nReMM-v2-L2-13B with a mean score across all tested languages of $0.152$, for\nthe GLEU metric is ReMM-v2-L2-13B with a mean score across all tested languages\nof $0.256$, for the chrF metric is Llama2-chat-AYT-13B with a mean score across\nall tested languages of $0.448$, and for the METEOR metric is ReMM-v2-L2-13B\nwith a mean score across all tested languages of $0.438$.",
      "tldr_zh": "该研究探讨了使用开源 Generative Pre-Trained Transformers (GPT) 模型进行多语言到英语的自动零样本翻译，旨在评估其准确性和效率。研究者基准测试了 16 个无自定义微调的 GPT 模型，从 Huggingface LLM 仓库中选取，使用 TED 演讲转录作为数据集，对 50 种非英语语言进行句子级翻译，所有推理均在单块 A100 Nvidia GPU 上本地执行。评估指标包括 BLEU、GLEU、METEOR 和 chrF 等翻译准确性分数，以及翻译时间，其中 ReMM-v2-L2-13B 模型在 BLEU (0.152)、GLEU (0.256) 和 METEOR (0.438) 上表现最佳，而 Llama2-chat-AYT-13B 在 chrF (0.448) 上领先。整体结果为多语言翻译技术提供了宝贵的基准参考。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.14680v1",
      "published_date": "2024-04-23 02:19:35 UTC",
      "updated_date": "2024-04-23 02:19:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:06:09.762729"
    },
    {
      "arxiv_id": "2404.14674v1",
      "title": "HOIN: High-Order Implicit Neural Representations",
      "title_zh": "HOIN：高阶隐式神经表示",
      "authors": [
        "Yang Chen",
        "Ruituo Wu",
        "Yipeng Liu",
        "Ce Zhu"
      ],
      "abstract": "Implicit neural representations (INR) suffer from worsening spectral bias,\nwhich results in overly smooth solutions to the inverse problem. To deal with\nthis problem, we propose a universal framework for processing inverse problems\ncalled \\textbf{High-Order Implicit Neural Representations (HOIN)}. By refining\nthe traditional cascade structure to foster high-order interactions among\nfeatures, HOIN enhances the model's expressive power and mitigates spectral\nbias through its neural tangent kernel's (NTK) strong diagonal properties,\naccelerating and optimizing inverse problem resolution. By analyzing the\nmodel's expression space, high-order derivatives, and the NTK matrix, we\ntheoretically validate the feasibility of HOIN. HOIN realizes 1 to 3 dB\nimprovements in most inverse problems, establishing a new state-of-the-art\nrecovery quality and training efficiency, thus providing a new general paradigm\nfor INR and paving the way for it to solve the inverse problem.",
      "tldr_zh": "本研究针对Implicit neural representations (INR) 在逆问题中存在的谱偏置问题，提出了一种通用框架High-Order Implicit Neural Representations (HOIN)。HOIN 通过改进传统级联结构，促进特征间的高阶交互，提升模型的表达能力和neural tangent kernel (NTK) 的强对角属性，从而减轻谱偏置并加速逆问题解决。理论分析包括模型表达式空间、高阶导数和NTK 矩阵，验证了HOIN 的可行性；实验结果显示，HOIN 在大多数逆问题上实现了1 到3 dB 的性能提升，建立新的最先进恢复质量和训练效率，并为INR 提供了一个新的通用范式。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.MM"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.14674v1",
      "published_date": "2024-04-23 02:00:58 UTC",
      "updated_date": "2024-04-23 02:00:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:06:20.522914"
    },
    {
      "arxiv_id": "2404.14664v1",
      "title": "Employing Layerwised Unsupervised Learning to Lessen Data and Loss Requirements in Forward-Forward Algorithms",
      "title_zh": "翻译失败",
      "authors": [
        "Taewook Hwang",
        "Hyein Seo",
        "Sangkeun Jung"
      ],
      "abstract": "Recent deep learning models such as ChatGPT utilizing the back-propagation\nalgorithm have exhibited remarkable performance. However, the disparity between\nthe biological brain processes and the back-propagation algorithm has been\nnoted. The Forward-Forward algorithm, which trains deep learning models solely\nthrough the forward pass, has emerged to address this. Although the\nForward-Forward algorithm cannot replace back-propagation due to limitations\nsuch as having to use special input and loss functions, it has the potential to\nbe useful in special situations where back-propagation is difficult to use. To\nwork around this limitation and verify usability, we propose an Unsupervised\nForward-Forward algorithm. Using an unsupervised learning model enables\ntraining with usual loss functions and inputs without restriction. Through this\napproach, we lead to stable learning and enable versatile utilization across\nvarious datasets and tasks. From a usability perspective, given the\ncharacteristics of the Forward-Forward algorithm and the advantages of the\nproposed method, we anticipate its practical application even in scenarios such\nas federated learning, where deep learning layers need to be trained separately\nin physically distributed environments.",
      "tldr_zh": "这篇论文针对 Forward-Forward algorithm 的局限性（如需特殊输入和损失函数），提出了一种基于层级化无监督学习(Unsupervised Forward-Forward)的改进方法，以减少数据和损失函数的要求。\n该方法通过无监督学习模型实现稳定训练，支持常规损失函数和输入，从而增强算法在各种数据集和任务中的通用性。\n此外，该方法有望应用于联邦学习(federated learning)等分布式场景中，实现高效的深度学习训练。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.14664v1",
      "published_date": "2024-04-23 01:49:12 UTC",
      "updated_date": "2024-04-23 01:49:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:06:34.167658"
    },
    {
      "arxiv_id": "2404.14660v1",
      "title": "AI Procurement Checklists: Revisiting Implementation in the Age of AI Governance",
      "title_zh": "翻译失败",
      "authors": [
        "Tom Zick",
        "Mason Kortz",
        "David Eaves",
        "Finale Doshi-Velez"
      ],
      "abstract": "Public sector use of AI has been quietly on the rise for the past decade, but\nonly recently have efforts to regulate it entered the cultural zeitgeist. While\nsimple to articulate, promoting ethical and effective roll outs of AI systems\nin government is a notoriously elusive task. On the one hand there are\nhard-to-address pitfalls associated with AI-based tools, including concerns\nabout bias towards marginalized communities, safety, and gameability. On the\nother, there is pressure not to make it too difficult to adopt AI, especially\nin the public sector which typically has fewer resources than the private\nsector$\\unicode{x2014}$conserving scarce government resources is often the draw\nof using AI-based tools in the first place. These tensions create a real risk\nthat procedures built to ensure marginalized groups are not hurt by government\nuse of AI will, in practice, be performative and ineffective. To inform the\nlatest wave of regulatory efforts in the United States, we look to\njurisdictions with mature regulations around government AI use. We report on\nlessons learned by officials in Brazil, Singapore and Canada, who have\ncollectively implemented risk categories, disclosure requirements and\nassessments into the way they procure AI tools. In particular, we investigate\ntwo implemented checklists: the Canadian Directive on Automated Decision-Making\n(CDADM) and the World Economic Forum's AI Procurement in a Box (WEF). We detail\nthree key pitfalls around expertise, risk frameworks and transparency, that can\ndecrease the efficacy of regulations aimed at government AI use and suggest\navenues for improvement.",
      "tldr_zh": "该论文探讨了在AI治理时代，公共部门AI采购检查列表的实施挑战，强调了AI工具的偏见、安全和可操纵性问题与资源限制之间的张力，可能导致监管措施流于形式。作者通过分析巴西、新加坡和加拿大的成熟监管经验，包括风险类别、披露要求和评估，特别调查了Canadian Directive on Automated Decision-Making (CDADM)和World Economic Forum's AI Procurement in a Box (WEF)。研究识别了三个关键缺陷：专业知识不足、风险框架不完善以及透明度问题，并提出改进建议，以提升政府AI采购的有效性。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.14660v1",
      "published_date": "2024-04-23 01:45:38 UTC",
      "updated_date": "2024-04-23 01:45:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:06:44.839741"
    },
    {
      "arxiv_id": "2405.06660v1",
      "title": "AI and Machine Learning for Next Generation Science Assessments",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaoming Zhai"
      ],
      "abstract": "This chapter focuses on the transformative role of Artificial Intelligence\n(AI) and Machine Learning (ML) in science assessments. The paper begins with a\ndiscussion of the Framework for K-12 Science Education, which calls for a shift\nfrom conceptual learning to knowledge-in-use. This shift necessitates the\ndevelopment of new types of assessments that align with the Framework's three\ndimensions: science and engineering practices, disciplinary core ideas, and\ncrosscutting concepts. The paper further highlights the limitations of\ntraditional assessment methods like multiple-choice questions, which often fail\nto capture the complexities of scientific thinking and three-dimensional\nlearning in science. It emphasizes the need for performance-based assessments\nthat require students to engage in scientific practices like modeling,\nexplanation, and argumentation. The paper achieves three major goals: reviewing\nthe current state of ML-based assessments in science education, introducing a\nframework for scoring accuracy in ML-based automatic assessments, and\ndiscussing future directions and challenges. It delves into the evolution of\nML-based automatic scoring systems, discussing various types of ML, like\nsupervised, unsupervised, and semi-supervised learning. These systems can\nprovide timely and objective feedback, thus alleviating the burden on teachers.\nThe paper concludes by exploring pre-trained models like BERT and finetuned\nChatGPT, which have shown promise in assessing students' written responses\neffectively.",
      "tldr_zh": "这篇论文探讨了人工智能(AI)和机器学习(ML)在下一代科学评估中的变革作用，强调从概念学习转向知识-in-use的转变，以符合Framework for K-12 Science Education的三维框架：科学与工程实践、学科核心想法和交叉概念。传统评估方法如多项选择题因无法捕捉科学思维的复杂性而存在局限，因此论文主张采用基于表现的评估，让学生参与建模、解释和论证等实践。论文的主要贡献包括回顾ML-based assessments在科学教育中的现状、引入一个ML-based自动评估的评分准确性框架，以及讨论监督、非监督和半监督学习等技术的应用。最终，它探讨了预训练模型如BERT和finetuned ChatGPT的潜力，这些系统能提供及时、客观的反馈，减轻教师负担，并指出了未来方向和挑战。",
      "categories": [
        "physics.ed-ph",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "physics.ed-ph",
      "comment": "18 pages, book chapter, in the book: Jiao, H., & Lissitz, R. W.\n  (Eds.). Machine learning, natural language processing and psychometrics.\n  Charlotte, NC: Information Age Publisher",
      "pdf_url": "http://arxiv.org/pdf/2405.06660v1",
      "published_date": "2024-04-23 01:39:20 UTC",
      "updated_date": "2024-04-23 01:39:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:06:57.121758"
    },
    {
      "arxiv_id": "2404.14646v2",
      "title": "Exploring and Unleashing the Power of Large Language Models in Automated Code Translation",
      "title_zh": "探索和释放大型语言模型在自动代码翻译中的潜力",
      "authors": [
        "Zhen Yang",
        "Fang Liu",
        "Zhongxing Yu",
        "Jacky Wai Keung",
        "Jia Li",
        "Shuo Liu",
        "Yifan Hong",
        "Xiaoxue Ma",
        "Zhi Jin",
        "Ge Li"
      ],
      "abstract": "Code translation tools (transpilers) are developed for automatic\nsource-to-source translation. Although learning-based transpilers have shown\nimpressive enhancement against rule-based counterparts, owing to their\ntask-specific pre-training on extensive monolingual corpora. Their current\nperformance still remains unsatisfactory for practical deployment, and the\nassociated training resources are also prohibitively expensive. LLMs\npre-trained on huge amounts of human-written code/text have shown remarkable\nperformance in many code intelligence tasks due to their powerful generality,\neven without task-specific training. Thus, LLMs can potentially circumvent the\nabove limitations, but they have not been exhaustively explored yet. This paper\ninvestigates diverse LLMs and learning-based transpilers for automated code\ntranslation tasks, finding that: although certain LLMs have outperformed\ncurrent transpilers, they still have some accuracy issues, where most of the\nfailures are induced by a lack of comprehension of source programs, missing\nclear instructions on I/O types in translation, and ignoring discrepancies\nbetween source and target programs. Enlightened by the above findings, we\nfurther propose UniTrans, a Unified code Translation framework, applicable to\nvarious LLMs, for unleashing their power in this field. Specifically, UniTrans\nfirst crafts a series of test cases for target programs with the assistance of\nsource programs. Next, it harnesses the above auto-generated test cases to\naugment the code translation and then evaluate their correctness via execution.\nAfterward, UniTrans further (iteratively) repairs incorrectly translated\nprograms prompted by test case execution results. Extensive experiments are\nconducted on six settings of translation datasets between Python, Java, and\nC++. Three recent LLMs of diverse sizes are tested with UniTrans, and all\nachieve substantial improvements.",
      "tldr_zh": "本文探讨了大型语言模型(LLMs)在自动代码翻译中的潜力，通过比较 LLMs 与学习-based transpilers，发现 LLMs 虽然在某些方面表现优于现有工具，但仍面临准确性问题，如源程序理解不足、I/O 类型指令缺失及源目标程序差异。针对这些问题，研究提出 UniTrans 框架，该框架统一适用于各种 LLMs，包括生成测试用例增强翻译、通过执行评估正确性以及迭代修复错误翻译。实验在 Python、Java 和 C++ 间的六种翻译设置上进行，结果显示三个不同规模的 LLMs 在应用 UniTrans 后均实现了显著性能提升。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "23 pages, 7 figures, accepted by FSE'24 (2024 ACM International\n  Conference on the Foundations of Software Engineering)",
      "pdf_url": "http://arxiv.org/pdf/2404.14646v2",
      "published_date": "2024-04-23 00:49:46 UTC",
      "updated_date": "2024-05-11 13:20:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:07:11.806308"
    },
    {
      "arxiv_id": "2407.05176v1",
      "title": "Towards Socially and Environmentally Responsible AI",
      "title_zh": "翻译失败",
      "authors": [
        "Pengfei Li",
        "Yejia Liu",
        "Jianyi Yang",
        "Shaolei Ren"
      ],
      "abstract": "The sharply increasing sizes of artificial intelligence (AI) models come with\nsignificant energy consumption and environmental footprints, which can\ndisproportionately impact certain (often marginalized) regions and hence create\nenvironmental inequity concerns. Moreover, concerns with social inequity have\nalso emerged, as AI computing resources may not be equitably distributed across\nthe globe and users from certain disadvantaged regions with severe resource\nconstraints can consistently experience inferior model performance.\nImportantly, the inequity concerns that encompass both social and environmental\ndimensions still remain unexplored and have increasingly hindered responsible\nAI. In this paper, we leverage the spatial flexibility of AI inference\nworkloads and propose equitable geographical load balancing (GLB) to fairly\nbalance AI's regional social and environmental costs. Concretely, to penalize\nthe disproportionately high social and environmental costs for equity, we\nintroduce $L_q$ norms as novel regularization terms into the optimization\nobjective for GLB decisions. Our empirical results based on real-world AI\ninference traces demonstrate that while the existing GLB algorithms result in\ndisproportionately large social and environmental costs in certain regions, our\nproposed equitable GLB can fairly balance AI's negative social and\nenvironmental costs across all the regions.",
      "tldr_zh": "这篇论文探讨了人工智能（AI）模型规模增长带来的能源消耗和环境足迹问题，这些问题可能导致某些边缘化地区承受不公平负担，并引发社会不公，如AI计算资源分配不均，造成资源匮乏地区的用户体验劣势。为解决这些问题，论文提出equitable geographical load balancing (GLB)方法，利用AI推理工作负载的空间灵活性，并在优化目标中引入$L_q$ norms作为正则化项，以公平平衡AI的社会和环境成本。实验基于真实AI推理跟踪数据表明，与现有GLB算法相比，该方法显著减少了特定地区的过度负担，实现更公平的成本分配。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "Presented at HotEthics 2024 (co-located with ASPLOS' 24)",
      "pdf_url": "http://arxiv.org/pdf/2407.05176v1",
      "published_date": "2024-04-23 00:41:41 UTC",
      "updated_date": "2024-04-23 00:41:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:07:21.824959"
    },
    {
      "arxiv_id": "2404.14635v1",
      "title": "Digital Twins for forecasting and decision optimisation with machine learning: applications in wastewater treatment",
      "title_zh": "翻译失败",
      "authors": [
        "Matthew Colwell",
        "Mahdi Abolghasemi"
      ],
      "abstract": "Prediction and optimisation are two widely used techniques that have found\nmany applications in solving real-world problems. While prediction is concerned\nwith estimating the unknown future values of a variable, optimisation is\nconcerned with optimising the decision given all the available data. These\nmethods are used together to solve problems for sequential decision-making\nwhere often we need to predict the future values of variables and then use them\nfor determining the optimal decisions. This paradigm is known as forecast and\noptimise and has numerous applications, e.g., forecast demand for a product and\nthen optimise inventory, forecast energy demand and schedule generations,\nforecast demand for a service and schedule staff, to name a few. In this\nextended abstract, we review a digital twin that was developed and applied in\nwastewater treatment in Urban Utility to improve their operational efficiency.\nWhile the current study is tailored to the case study problem, the underlying\nprinciples can be used to solve similar problems in other domains.",
      "tldr_zh": "该论文探讨了数字孪生（Digital Twins）结合机器学习（machine learning）用于预测（forecasting）和决策优化（decision optimisation）的技术，并将其应用于废水处理（wastewater treatment）领域。通过预测未知变量值并优化决策，该方法解决了顺序决策问题，如预测需求后调整资源。研究回顾了在 Urban Utility 开发的数字孪生案例，提升了废水处理的运营效率；虽然针对特定场景，但其底层原理可推广到其他领域。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "A bit thin, but an interesting application of ML methods for decision\n  making",
      "pdf_url": "http://arxiv.org/pdf/2404.14635v1",
      "published_date": "2024-04-23 00:18:20 UTC",
      "updated_date": "2024-04-23 00:18:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:07:32.813409"
    },
    {
      "arxiv_id": "2405.02325v4",
      "title": "Are Biological Systems More Intelligent Than Artificial Intelligence?",
      "title_zh": "生物系统比人工智能更智能吗？",
      "authors": [
        "Michael Timothy Bennett"
      ],
      "abstract": "Are biological self-organising systems more `intelligent' than artificial\nintelligence? If so, why? We frame intelligence as adaptability, and explore\nthis question using a mathematical formalism of causal learning. We compare\nsystems by how they delegate control, illustrating how this applies with\nexamples of computational, biological, human organisational and economic\nsystems. We formally show the scale-free, dynamic, bottom-up architecture of\nbiological self-organisation allows for more efficient adaptation than the\nstatic top-down architecture typical of computers, because adaptation can take\nplace at lower levels of abstraction. Artificial intelligence rests on a\nstatic, human-engineered `stack'. It only adapts at high levels of abstraction.\nTo put it provocatively, a static computational stack is like an inflexible\nbureaucracy. Biology is more `intelligent' because it delegates adaptation down\nthe stack. We call this multilayer-causal-learning. It inherits a flaw of\nbiological systems. Cells become cancerous when isolated from the collective\ninformational structure, reverting to primitive transcriptional behaviour. We\nshow states analogous to cancer occur when collectives are too tightly\nconstrained. To adapt to adverse conditions control should be delegated to the\ngreatest extent, like the doctrine of mission-command. Our result shows how to\ndesign more robust systems and lays a mathematical foundation for future\nempirical research.",
      "tldr_zh": "本论文探讨了生物自组织系统是否比人工智能更“智能”，将智能定义为适应性，并使用mathematical formalism of causal learning进行比较。研究发现，生物系统的规模自由、动态、自下而上的架构允许更高效的适应，因为它能将控制委托到较低抽象级别，而人工智能依赖于静态、人类设计的“stack”，仅在高抽象级别适应。论文正式证明了这种multilayer-causal-learning机制使生物系统更灵活，但也继承了如癌症般的缺陷，当系统过于约束时可能导致类似问题。最终，作者建议通过最大程度委托控制（如doctrine of mission-command）来设计更健壮的系统，并为未来实证研究奠定数学基础。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Definitions shared with arXiv:2404.07227, arXiv:2302.00843",
      "pdf_url": "http://arxiv.org/pdf/2405.02325v4",
      "published_date": "2024-04-23 00:13:14 UTC",
      "updated_date": "2025-01-23 05:24:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T03:07:46.933623"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 114,
  "processed_papers_count": 114,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-18T03:08:08.750247"
}