[
  {
    "arxiv_id": "2401.07389v1",
    "title": "A Rapid Review of Clustering Algorithms",
    "authors": [
      "Hui Yin",
      "Amir Aryani",
      "Stephen Petrie",
      "Aishwarya Nambissan",
      "Aland Astudillo",
      "Shengyuan Cao"
    ],
    "abstract": "Clustering algorithms aim to organize data into groups or clusters based on\nthe inherent patterns and similarities within the data. They play an important\nrole in today's life, such as in marketing and e-commerce, healthcare, data\norganization and analysis, and social media. Numerous clustering algorithms\nexist, with ongoing developments introducing new ones. Each algorithm possesses\nits own set of strengths and weaknesses, and as of now, there is no universally\napplicable algorithm for all tasks. In this work, we analyzed existing\nclustering algorithms and classify mainstream algorithms across five different\ndimensions: underlying principles and characteristics, data point assignment to\nclusters, dataset capacity, predefined cluster numbers and application area.\nThis classification facilitates researchers in understanding clustering\nalgorithms from various perspectives and helps them identify algorithms\nsuitable for solving specific tasks. Finally, we discussed the current trends\nand potential future directions in clustering algorithms. We also identified\nand discussed open challenges and unresolved issues in the field.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "68-02",
      "I.2.0"
    ],
    "primary_category": "cs.LG",
    "comment": "25 pages, 7 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2401.07389v1",
    "published_date": "2024-01-14 23:19:53 UTC",
    "updated_date": "2024-01-14 23:19:53 UTC"
  },
  {
    "arxiv_id": "2401.07387v2",
    "title": "Noise-Aware Training of Neuromorphic Dynamic Device Networks",
    "authors": [
      "Luca Manneschi",
      "Ian T. Vidamour",
      "Kilian D. Stenning",
      "Charles Swindells",
      "Guru Venkat",
      "David Griffin",
      "Lai Gui",
      "Daanish Sonawala",
      "Denis Donskikh",
      "Dana Hariga",
      "Susan Stepney",
      "Will R. Branford",
      "Jack C. Gartside",
      "Thomas Hayward",
      "Matthew O. A. Ellis",
      "Eleni Vasilaki"
    ],
    "abstract": "Physical computing has the potential to enable widespread embodied\nintelligence by leveraging the intrinsic dynamics of complex systems for\nefficient sensing, processing, and interaction. While individual devices\nprovide basic data processing capabilities, networks of interconnected devices\ncan perform more complex and varied tasks. However, designing networks to\nperform dynamic tasks is challenging without physical models and accurate\nquantification of device noise. We propose a novel, noise-aware methodology for\ntraining device networks using Neural Stochastic Differential Equations\n(Neural-SDEs) as differentiable digital twins, accurately capturing the\ndynamics and associated stochasticity of devices with intrinsic memory. Our\napproach employs backpropagation through time and cascade learning, allowing\nnetworks to effectively exploit the temporal properties of physical devices. We\nvalidate our method on diverse networks of spintronic devices across temporal\nclassification and regression benchmarks. By decoupling the training of\nindividual device models from network training, our method reduces the required\ntraining data and provides a robust framework for programming dynamical devices\nwithout relying on analytical descriptions of their dynamics.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.ET",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.07387v2",
    "published_date": "2024-01-14 22:46:53 UTC",
    "updated_date": "2024-10-28 17:24:42 UTC"
  },
  {
    "arxiv_id": "2401.07382v2",
    "title": "Beyond Sparse Rewards: Enhancing Reinforcement Learning with Language Model Critique in Text Generation",
    "authors": [
      "Meng Cao",
      "Lei Shu",
      "Lei Yu",
      "Yun Zhu",
      "Nevan Wichers",
      "Yinxiao Liu",
      "Lei Meng"
    ],
    "abstract": "Reinforcement learning (RL) can align language models with non-differentiable\nreward signals, such as human preferences. However, a major challenge arises\nfrom the sparsity of these reward signals - typically, there is only a single\nreward for an entire output. This sparsity of rewards can lead to inefficient\nand unstable learning. To address this challenge, our paper introduces an novel\nframework that utilizes the critique capability of Large Language Models (LLMs)\nto produce intermediate-step rewards during RL training. Our method involves\ncoupling a policy model with a critic language model, which is responsible for\nproviding comprehensive feedback of each part of the output. This feedback is\nthen translated into token or span-level rewards that can be used to guide the\nRL training process. We investigate this approach under two different settings:\none where the policy model is smaller and is paired with a more powerful critic\nmodel, and another where a single language model fulfills both roles. We assess\nour approach on three text generation tasks: sentiment control, language model\ndetoxification, and summarization. Experimental results show that incorporating\nartificial intrinsic rewards significantly improve both sample efficiency and\nthe overall performance of the policy model, supported by both automatic and\nhuman evaluation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.07382v2",
    "published_date": "2024-01-14 22:05:11 UTC",
    "updated_date": "2024-02-19 18:19:20 UTC"
  },
  {
    "arxiv_id": "2401.07379v1",
    "title": "Inference of dynamical gene regulatory networks from single-cell data with physics informed neural networks",
    "authors": [
      "Maria Mircea",
      "Diego Garlaschelli",
      "Stefan Semrau"
    ],
    "abstract": "One of the main goals of developmental biology is to reveal the gene\nregulatory networks (GRNs) underlying the robust differentiation of multipotent\nprogenitors into precisely specified cell types. Most existing methods to infer\nGRNs from experimental data have limited predictive power as the inferred GRNs\nmerely reflect gene expression similarity or correlation. Here, we demonstrate,\nhow physics-informed neural networks (PINNs) can be used to infer the\nparameters of predictive, dynamical GRNs that provide mechanistic understanding\nof biological processes. Specifically we study GRNs that exhibit bifurcation\nbehavior and can therefore model cell differentiation. We show that PINNs\noutperform regular feed-forward neural networks on the parameter inference task\nand analyze two relevant experimental scenarios: 1. a system with cell\ncommunication for which gene expression trajectories are available and 2.\nsnapshot measurements of a cell population in which cell communication is\nabsent. Our analysis will inform the design of future experiments to be\nanalyzed with PINNs and provides a starting point to explore this powerful\nclass of neural network models further.",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "cs.LG",
      "physics.bio-ph",
      "q-bio.MN"
    ],
    "primary_category": "q-bio.QM",
    "comment": "25 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2401.07379v1",
    "published_date": "2024-01-14 21:43:10 UTC",
    "updated_date": "2024-01-14 21:43:10 UTC"
  },
  {
    "arxiv_id": "2401.07378v3",
    "title": "Efficient approximation of Earth Mover's Distance Based on Nearest Neighbor Search",
    "authors": [
      "Guangyu Meng",
      "Ruyu Zhou",
      "Liu Liu",
      "Peixian Liang",
      "Fang Liu",
      "Danny Chen",
      "Michael Niemier",
      "X. Sharon Hu"
    ],
    "abstract": "Earth Mover's Distance (EMD) is an important similarity measure between two\ndistributions, used in computer vision and many other application domains.\nHowever, its exact calculation is computationally and memory intensive, which\nhinders its scalability and applicability for large-scale problems. Various\napproximate EMD algorithms have been proposed to reduce computational costs,\nbut they suffer lower accuracy and may require additional memory usage or\nmanual parameter tuning. In this paper, we present a novel approach, NNS-EMD,\nto approximate EMD using Nearest Neighbor Search (NNS), in order to achieve\nhigh accuracy, low time complexity, and high memory efficiency. The NNS\noperation reduces the number of data points compared in each NNS iteration and\noffers opportunities for parallel processing. We further accelerate NNS-EMD via\nvectorization on GPU, which is especially beneficial for large datasets. We\ncompare NNS-EMD with both the exact EMD and state-of-the-art approximate EMD\nalgorithms on image classification and retrieval tasks. We also apply NNS-EMD\nto calculate transport mapping and realize color transfer between images.\nNNS-EMD can be 44x to 135x faster than the exact EMD implementation, and\nachieves superior accuracy, speedup, and memory efficiency over existing\napproximate EMD methods.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.07378v3",
    "published_date": "2024-01-14 21:42:18 UTC",
    "updated_date": "2025-05-14 13:38:53 UTC"
  },
  {
    "arxiv_id": "2401.07364v2",
    "title": "PDE Generalization of In-Context Operator Networks: A Study on 1D Scalar Nonlinear Conservation Laws",
    "authors": [
      "Liu Yang",
      "Stanley J. Osher"
    ],
    "abstract": "Can we build a single large model for a wide range of PDE-related scientific\nlearning tasks? Can this model generalize to new PDEs, even of new forms,\nwithout any fine-tuning? In-context operator learning and the corresponding\nmodel In-Context Operator Networks (ICON) represent an initial exploration of\nthese questions. The capability of ICON regarding the first question has been\ndemonstrated previously. In this paper, we present a detailed methodology for\nsolving PDE problems with ICON, and show how a single ICON model can make\nforward and reverse predictions for different equations with different strides,\nprovided with appropriately designed data prompts. We show the positive\nevidence to the second question, i.e., ICON can generalize well to some PDEs\nwith new forms without any fine-tuning. This is exemplified through a study on\n1D scalar nonlinear conservation laws, a family of PDEs with temporal\nevolution. We also show how to broaden the range of problems that an ICON model\ncan address, by transforming functions and equations to ICON's capability\nscope. We believe that the progress in this paper is a significant step towards\nthe goal of training a foundation model for PDE-related tasks under the\nin-context operator learning framework.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NA",
      "math.NA"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.07364v2",
    "published_date": "2024-01-14 20:41:36 UTC",
    "updated_date": "2024-01-21 22:08:20 UTC"
  },
  {
    "arxiv_id": "2401.07359v3",
    "title": "Reliability and Interpretability in Science and Deep Learning",
    "authors": [
      "Luigi Scorzato"
    ],
    "abstract": "In recent years, the question of the reliability of Machine Learning (ML)\nmethods has acquired significant importance, and the analysis of the associated\nuncertainties has motivated a growing amount of research. However, most of\nthese studies have applied standard error analysis to ML models, and in\nparticular Deep Neural Network (DNN) models, which represent a rather\nsignificant departure from standard scientific modelling. It is therefore\nnecessary to integrate the standard error analysis with a deeper\nepistemological analysis of the possible differences between DNN models and\nstandard scientific modelling and the possible implications of these\ndifferences in the assessment of reliability. This article offers several\ncontributions. First, it emphasises the ubiquitous role of model assumptions\n(both in ML and traditional Science) against the illusion of theory-free\nscience. Secondly, model assumptions are analysed from the point of view of\ntheir (epistemic) complexity, which is shown to be language-independent. It is\nargued that the high epistemic complexity of DNN models hinders the estimate of\ntheir reliability and also their prospect of long-term progress. Some potential\nways forward are suggested. Thirdly, this article identifies the close relation\nbetween a model's epistemic complexity and its interpretability, as introduced\nin the context of responsible AI. This clarifies in which sense, and to what\nextent, the lack of understanding of a model (black-box problem) impacts its\ninterpretability in a way that is independent of individual skills. It also\nclarifies how interpretability is a precondition for assessing the reliability\nof any model, which cannot be based on statistical analysis alone. This article\nfocuses on the comparison between traditional scientific models and DNN models.\nBut, Random Forest and Logistic Regression models are also briefly considered.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "physics.hist-ph"
    ],
    "primary_category": "cs.AI",
    "comment": "To appear in Minds and Machines",
    "pdf_url": "http://arxiv.org/pdf/2401.07359v3",
    "published_date": "2024-01-14 20:14:07 UTC",
    "updated_date": "2024-06-12 06:18:04 UTC"
  },
  {
    "arxiv_id": "2401.07353v2",
    "title": "Towards Engineering Fair and Equitable Software Systems for Managing Low-Altitude Airspace Authorizations",
    "authors": [
      "Usman Gohar",
      "Michael C. Hunter",
      "Agnieszka Marczak-Czajka",
      "Robyn R. Lutz",
      "Myra B. Cohen",
      "Jane Cleland-Huang"
    ],
    "abstract": "Small Unmanned Aircraft Systems (sUAS) have gained widespread adoption across\na diverse range of applications. This has introduced operational complexities\nwithin shared airspaces and an increase in reported incidents, raising safety\nconcerns. In response, the U.S. Federal Aviation Administration (FAA) is\ndeveloping a UAS Traffic Management (UTM) system to control access to airspace\nbased on an sUAS's predicted ability to safely complete its mission. However, a\nfully automated system capable of swiftly approving or denying flight requests\ncan be prone to bias and must consider safety, transparency, and fairness to\ndiverse stakeholders. In this paper, we present an initial study that explores\nstakeholders' perspectives on factors that should be considered in an automated\nsystem. Results indicate flight characteristics and environmental conditions\nwere perceived as most important but pilot and drone capabilities should also\nbe considered. Further, several respondents indicated an aversion to any\nAI-supported automation, highlighting the need for full transparency in\nautomated decision-making. Results provide a societal perspective on the\nchallenges of automating UTM flight authorization decisions and help frame the\nongoing design of a solution acceptable to the broader sUAS community.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.07353v2",
    "published_date": "2024-01-14 19:40:32 UTC",
    "updated_date": "2024-02-03 14:55:07 UTC"
  },
  {
    "arxiv_id": "2401.07348v4",
    "title": "Generative AI in EU Law: Liability, Privacy, Intellectual Property, and Cybersecurity",
    "authors": [
      "Claudio Novelli",
      "Federico Casolari",
      "Philipp Hacker",
      "Giorgio Spedicato",
      "Luciano Floridi"
    ],
    "abstract": "The advent of Generative AI, particularly through Large Language Models\n(LLMs) like ChatGPT and its successors, marks a paradigm shift in the AI\nlandscape. Advanced LLMs exhibit multimodality, handling diverse data formats,\nthereby broadening their application scope. However, the complexity and\nemergent autonomy of these models introduce challenges in predictability and\nlegal compliance. This paper delves into the legal and regulatory implications\nof Generative AI and LLMs in the European Union context, analyzing aspects of\nliability, privacy, intellectual property, and cybersecurity. It critically\nexamines the adequacy of the existing and proposed EU legislation, including\nthe Artificial Intelligence Act (AIA) draft, in addressing the unique\nchallenges posed by Generative AI in general and LLMs in particular. The paper\nidentifies potential gaps and shortcomings in the legislative framework and\nproposes recommendations to ensure the safe and compliant deployment of\ngenerative models, ensuring they align with the EU's evolving digital landscape\nand legal standards.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.07348v4",
    "published_date": "2024-01-14 19:16:29 UTC",
    "updated_date": "2024-03-15 17:10:29 UTC"
  },
  {
    "arxiv_id": "2401.07336v1",
    "title": "Construction and Evaluation of Mandarin Multimodal Emotional Speech Database",
    "authors": [
      "Zhu Ting",
      "Li Liangqi",
      "Duan Shufei",
      "Zhang Xueying",
      "Xiao Zhongzhe",
      "Jia Hairng",
      "Liang Huizhi"
    ],
    "abstract": "A multi-modal emotional speech Mandarin database including articulatory\nkinematics, acoustics, glottal and facial micro-expressions is designed and\nestablished, which is described in detail from the aspects of corpus design,\nsubject selection, recording details and data processing. Where signals are\nlabeled with discrete emotion labels (neutral, happy, pleasant, indifferent,\nangry, sad, grief) and dimensional emotion labels (pleasure, arousal,\ndominance). In this paper, the validity of dimension annotation is verified by\nstatistical analysis of dimension annotation data. The SCL-90 scale data of\nannotators are verified and combined with PAD annotation data for analysis, so\nas to explore the internal relationship between the outlier phenomenon in\nannotation and the psychological state of annotators. In order to verify the\nspeech quality and emotion discrimination of the database, this paper uses 3\nbasic models of SVM, CNN and DNN to calculate the recognition rate of these\nseven emotions. The results show that the average recognition rate of seven\nemotions is about 82% when using acoustic data alone. When using glottal data\nalone, the average recognition rate is about 72%. Using kinematics data alone,\nthe average recognition rate also reaches 55.7%. Therefore, the database is of\nhigh quality and can be used as an important source for speech analysis\nresearch, especially for the task of multimodal emotional speech analysis.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.SD",
      "eess.SP"
    ],
    "primary_category": "eess.AS",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.07336v1",
    "published_date": "2024-01-14 17:56:36 UTC",
    "updated_date": "2024-01-14 17:56:36 UTC"
  },
  {
    "arxiv_id": "2401.10284v1",
    "title": "MorpheusNet: Resource efficient sleep stage classifier for embedded on-line systems",
    "authors": [
      "Ali Kavoosi",
      "Morgan P. Mitchell",
      "Raveen Kariyawasam",
      "John E. Fleming",
      "Penny Lewis",
      "Heidi Johansen-Berg",
      "Hayriye Cagnan",
      "Timothy Denison"
    ],
    "abstract": "Sleep Stage Classification (SSC) is a labor-intensive task, requiring experts\nto examine hours of electrophysiological recordings for manual classification.\nThis is a limiting factor when it comes to leveraging sleep stages for\ntherapeutic purposes. With increasing affordability and expansion of wearable\ndevices, automating SSC may enable deployment of sleep-based therapies at\nscale. Deep Learning has gained increasing attention as a potential method to\nautomate this process. Previous research has shown accuracy comparable to\nmanual expert scores. However, previous approaches require sizable amount of\nmemory and computational resources. This constrains the ability to classify in\nreal time and deploy models on the edge. To address this gap, we aim to provide\na model capable of predicting sleep stages in real-time, without requiring\naccess to external computational sources (e.g., mobile phone, cloud). The\nalgorithm is power efficient to enable use on embedded battery powered systems.\nOur compact sleep stage classifier can be deployed on most off-the-shelf\nmicrocontrollers (MCU) with constrained hardware settings. This is due to the\nmemory footprint of our approach requiring significantly fewer operations. The\nmodel was tested on three publicly available data bases and achieved\nperformance comparable to the state of the art, whilst reducing model\ncomplexity by orders of magnitude (up to 280 times smaller compared to state of\nthe art). We further optimized the model with quantization of parameters to 8\nbits with only an average drop of 0.95% in accuracy. When implemented in\nfirmware, the quantized model achieves a latency of 1.6 seconds on an Arm\nCortexM4 processor, allowing its use for on-line SSC-based therapies.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "This paper was presented at the 2023 IEEE conference on Systems, Man,\n  and Cybernetics (SMC)",
    "pdf_url": "http://arxiv.org/pdf/2401.10284v1",
    "published_date": "2024-01-14 17:52:08 UTC",
    "updated_date": "2024-01-14 17:52:08 UTC"
  },
  {
    "arxiv_id": "2401.07333v1",
    "title": "ELLA-V: Stable Neural Codec Language Modeling with Alignment-guided Sequence Reordering",
    "authors": [
      "Yakun Song",
      "Zhuo Chen",
      "Xiaofei Wang",
      "Ziyang Ma",
      "Xie Chen"
    ],
    "abstract": "The language model (LM) approach based on acoustic and linguistic prompts,\nsuch as VALL-E, has achieved remarkable progress in the field of zero-shot\naudio generation. However, existing methods still have some limitations: 1)\nrepetitions, transpositions, and omissions in the output synthesized speech due\nto limited alignment constraints between audio and phoneme tokens; 2)\nchallenges of fine-grained control over the synthesized speech with\nautoregressive (AR) language model; 3) infinite silence generation due to the\nnature of AR-based decoding, especially under the greedy strategy. To alleviate\nthese issues, we propose ELLA-V, a simple but efficient LM-based zero-shot\ntext-to-speech (TTS) framework, which enables fine-grained control over\nsynthesized audio at the phoneme level. The key to ELLA-V is interleaving\nsequences of acoustic and phoneme tokens, where phoneme tokens appear ahead of\nthe corresponding acoustic tokens. The experimental findings reveal that our\nmodel outperforms VALL-E in terms of accuracy and delivers more stable results\nusing both greedy and sampling-based decoding strategies. The code of ELLA-V\nwill be open-sourced after cleanups. Audio samples are available at\nhttps://ereboas.github.io/ELLAV/.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL",
    "comment": "Working in progress",
    "pdf_url": "http://arxiv.org/pdf/2401.07333v1",
    "published_date": "2024-01-14 17:43:55 UTC",
    "updated_date": "2024-01-14 17:43:55 UTC"
  },
  {
    "arxiv_id": "2401.07324v3",
    "title": "Small LLMs Are Weak Tool Learners: A Multi-LLM Agent",
    "authors": [
      "Weizhou Shen",
      "Chenliang Li",
      "Hongzhan Chen",
      "Ming Yan",
      "Xiaojun Quan",
      "Hehong Chen",
      "Ji Zhang",
      "Fei Huang"
    ],
    "abstract": "Large Language Model (LLM) agents significantly extend the capabilities of\nstandalone LLMs, empowering them to interact with external tools (e.g., APIs,\nfunctions) and complete various tasks in a self-directed fashion. The challenge\nof tool use demands that LLMs not only understand user queries and generate\nanswers accurately but also excel in task planning, tool invocation, and result\nsummarization. While traditional works focus on training a single LLM with all\nthese capabilities, performance limitations become apparent, particularly with\nsmaller models. To overcome these challenges, we propose a novel approach that\ndecomposes the aforementioned capabilities into a planner, caller, and\nsummarizer. Each component is implemented by a single LLM that focuses on a\nspecific capability and collaborates with others to accomplish the task. This\nmodular framework facilitates individual updates and the potential use of\nsmaller LLMs for building each capability. To effectively train this framework,\nwe introduce a two-stage training paradigm. First, we fine-tune a backbone LLM\non the entire dataset without discriminating sub-tasks, providing the model\nwith a comprehensive understanding of the task. Second, the fine-tuned LLM is\nused to instantiate the planner, caller, and summarizer respectively, which are\ncontinually fine-tuned on respective sub-tasks. Evaluation across various\ntool-use benchmarks illustrates that our proposed multi-LLM framework surpasses\nthe traditional single-LLM approach, highlighting its efficacy and advantages\nin tool learning.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "On progress, github repo: https://github.com/X-PLUG/Multi-LLM-Agent",
    "pdf_url": "http://arxiv.org/pdf/2401.07324v3",
    "published_date": "2024-01-14 16:17:07 UTC",
    "updated_date": "2024-02-16 12:42:25 UTC"
  },
  {
    "arxiv_id": "2401.07314v3",
    "title": "MapGPT: Map-Guided Prompting with Adaptive Path Planning for Vision-and-Language Navigation",
    "authors": [
      "Jiaqi Chen",
      "Bingqian Lin",
      "Ran Xu",
      "Zhenhua Chai",
      "Xiaodan Liang",
      "Kwan-Yee K. Wong"
    ],
    "abstract": "Embodied agents equipped with GPT as their brains have exhibited\nextraordinary decision-making and generalization abilities across various\ntasks. However, existing zero-shot agents for vision-and-language navigation\n(VLN) only prompt GPT-4 to select potential locations within localized\nenvironments, without constructing an effective \"global-view\" for the agent to\nunderstand the overall environment. In this work, we present a novel map-guided\nGPT-based agent, dubbed MapGPT, which introduces an online linguistic-formed\nmap to encourage global exploration. Specifically, we build an online map and\nincorporate it into the prompts that include node information and topological\nrelationships, to help GPT understand the spatial environment. Benefiting from\nthis design, we further propose an adaptive planning mechanism to assist the\nagent in performing multi-step path planning based on a map, systematically\nexploring multiple candidate nodes or sub-goals step by step. Extensive\nexperiments demonstrate that our MapGPT is applicable to both GPT-4 and GPT-4V,\nachieving state-of-the-art zero-shot performance on R2R and REVERIE\nsimultaneously (~10% and ~12% improvements in SR), and showcasing the newly\nemergent global thinking and path planning abilities of the GPT.",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "LLM/VLM-based VLN Agents. Accepted to ACL 2024. Project:\n  https://chen-judge.github.io/MapGPT/",
    "pdf_url": "http://arxiv.org/pdf/2401.07314v3",
    "published_date": "2024-01-14 15:34:48 UTC",
    "updated_date": "2024-06-20 07:23:45 UTC"
  },
  {
    "arxiv_id": "2401.07301v2",
    "title": "Small Language Model Can Self-correct",
    "authors": [
      "Haixia Han",
      "Jiaqing Liang",
      "Jie Shi",
      "Qianyu He",
      "Yanghua Xiao"
    ],
    "abstract": "Generative Language Models (LMs) such as ChatGPT have exhibited remarkable\nperformance across various downstream tasks. Nevertheless, one of their most\nprominent drawbacks is generating inaccurate or false information with a\nconfident tone. Previous studies have devised sophisticated pipelines and\nprompts to induce large LMs to exhibit the capability for self-correction.\nHowever, large LMs are explicitly prompted to verify and modify its answers\nseparately rather than completing all steps spontaneously like humans.\nMoreover, these complex prompts are extremely challenging for small LMs to\nfollow. In this paper, we introduce the \\underline{I}ntrinsic\n\\underline{S}elf-\\underline{C}orrection (ISC) in generative language models,\naiming to correct the initial output of LMs in a self-triggered manner, even\nfor those small LMs with 6 billion parameters. Specifically, we devise a\npipeline for constructing self-correction data and propose Partial Answer\nMasking (PAM), aiming to endow the model with the capability for intrinsic\nself-correction through fine-tuning. We conduct experiments using LMs with\nparameters sizes ranging from 6 billion to 13 billion in two tasks, including\ncommonsense reasoning and factual knowledge reasoning. Our experiments\ndemonstrate that the outputs generated using ISC outperform those generated\nwithout self-correction. We believe that the output quality of even small LMs\ncan be further improved by empowering them with the ability to intrinsic\nself-correct.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.07301v2",
    "published_date": "2024-01-14 14:29:07 UTC",
    "updated_date": "2024-05-11 12:51:39 UTC"
  },
  {
    "arxiv_id": "2401.08699v3",
    "title": "On Image Search in Histopathology",
    "authors": [
      "H. R. Tizhoosh",
      "Liron Pantanowitz"
    ],
    "abstract": "Pathology images of histopathology can be acquired from camera-mounted\nmicroscopes or whole slide scanners. Utilizing similarity calculations to match\npatients based on these images holds significant potential in research and\nclinical contexts. Recent advancements in search technologies allow for\nimplicit quantification of tissue morphology across diverse primary sites,\nfacilitating comparisons and enabling inferences about diagnosis, and\npotentially prognosis, and predictions for new patients when compared against a\ncurated database of diagnosed and treated cases. In this paper, we\ncomprehensively review the latest developments in image search technologies for\nhistopathology, offering a concise overview tailored for computational\npathology researchers seeking effective, fast and efficient image search\nmethods in their work.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.IR",
      "q-bio.QM"
    ],
    "primary_category": "eess.IV",
    "comment": "A chapter in the Book \"Artificial INtelligence in Digital Pathology\"\n  by Cohen and Chauhan, 2024",
    "pdf_url": "http://arxiv.org/pdf/2401.08699v3",
    "published_date": "2024-01-14 12:38:49 UTC",
    "updated_date": "2024-03-22 03:31:22 UTC"
  },
  {
    "arxiv_id": "2401.07278v3",
    "title": "Semi-Supervised Semantic Segmentation using Redesigned Self-Training for White Blood Cells",
    "authors": [
      "Vinh Quoc Luu",
      "Duy Khanh Le",
      "Huy Thanh Nguyen",
      "Minh Thanh Nguyen",
      "Thinh Tien Nguyen",
      "Vinh Quang Dinh"
    ],
    "abstract": "Artificial Intelligence (AI) in healthcare, especially in white blood cell\ncancer diagnosis, is hindered by two primary challenges: the lack of\nlarge-scale labeled datasets for white blood cell (WBC) segmentation and\noutdated segmentation methods. These challenges inhibit the development of more\naccurate and modern techniques to diagnose cancer relating to white blood\ncells. To address the first challenge, a semi-supervised learning framework\nshould be devised to efficiently capitalize on the scarcity of the dataset\navailable. In this work, we address this issue by proposing a novel\nself-training pipeline with the incorporation of FixMatch. Self-training is a\ntechnique that utilizes the model trained on labeled data to generate\npseudo-labels for the unlabeled data and then re-train on both of them.\nFixMatch is a consistency-regularization algorithm to enforce the model's\nrobustness against variations in the input image. We discover that by\nincorporating FixMatch in the self-training pipeline, the performance improves\nin the majority of cases. Our performance achieved the best performance with\nthe self-training scheme with consistency on DeepLab-V3 architecture and\nResNet-50, reaching 90.69%, 87.37%, and 76.49% on Zheng 1, Zheng 2, and LISC\ndatasets, respectively.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.07278v3",
    "published_date": "2024-01-14 12:22:34 UTC",
    "updated_date": "2024-02-23 10:09:24 UTC"
  },
  {
    "arxiv_id": "2401.07271v1",
    "title": "SpineCLUE: Automatic Vertebrae Identification Using Contrastive Learning and Uncertainty Estimation",
    "authors": [
      "Sheng Zhang",
      "Minheng Chen",
      "Junxian Wu",
      "Ziyue Zhang",
      "Tonglong Li",
      "Cheng Xue",
      "Youyong Kong"
    ],
    "abstract": "Vertebrae identification in arbitrary fields-of-view plays a crucial role in\ndiagnosing spine disease. Most spine CT contain only local regions, such as the\nneck, chest, and abdomen. Therefore, identification should not depend on\nspecific vertebrae or a particular number of vertebrae being visible. Existing\nmethods at the spine-level are unable to meet this challenge. In this paper, we\npropose a three-stage method to address the challenges in 3D CT vertebrae\nidentification at vertebrae-level. By sequentially performing the tasks of\nvertebrae localization, segmentation, and identification, the anatomical prior\ninformation of the vertebrae is effectively utilized throughout the process.\nSpecifically, we introduce a dual-factor density clustering algorithm to\nacquire localization information for individual vertebra, thereby facilitating\nsubsequent segmentation and identification processes. In addition, to tackle\nthe issue of interclass similarity and intra-class variability, we pre-train\nour identification network by using a supervised contrastive learning method.\nTo further optimize the identification results, we estimated the uncertainty of\nthe classification network and utilized the message fusion module to combine\nthe uncertainty scores, while aggregating global information about the spine.\nOur method achieves state-of-the-art results on the VerSe19 and VerSe20\nchallenge benchmarks. Additionally, our approach demonstrates outstanding\ngeneralization performance on an collected dataset containing a wide range of\nabnormal cases.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.07271v1",
    "published_date": "2024-01-14 12:02:39 UTC",
    "updated_date": "2024-01-14 12:02:39 UTC"
  },
  {
    "arxiv_id": "2401.07263v1",
    "title": "BET: Explaining Deep Reinforcement Learning through The Error-Prone Decisions",
    "authors": [
      "Xiao Liu",
      "Jie Zhao",
      "Wubing Chen",
      "Mao Tan",
      "Yongxing Su"
    ],
    "abstract": "Despite the impressive capabilities of Deep Reinforcement Learning (DRL)\nagents in many challenging scenarios, their black-box decision-making process\nsignificantly limits their deployment in safety-sensitive domains. Several\nprevious self-interpretable works focus on revealing the critical states of the\nagent's decision. However, they cannot pinpoint the error-prone states. To\naddress this issue, we propose a novel self-interpretable structure, named\nBackbone Extract Tree (BET), to better explain the agent's behavior by identify\nthe error-prone states. At a high level, BET hypothesizes that states in which\nthe agent consistently executes uniform decisions exhibit a reduced propensity\nfor errors. To effectively model this phenomenon, BET expresses these states\nwithin neighborhoods, each defined by a curated set of representative states.\nTherefore, states positioned at a greater distance from these representative\nbenchmarks are more prone to error. We evaluate BET in various popular RL\nenvironments and show its superiority over existing self-interpretable models\nin terms of explanation fidelity. Furthermore, we demonstrate a use case for\nproviding explanations for the agents in StarCraft II, a sophisticated\nmulti-agent cooperative game. To the best of our knowledge, we are the first to\nexplain such a complex scenarios using a fully transparent structure.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "This is an early version of a paper that submitted to IJCAI 2024 8\n  pages, 4 figures and 1 table",
    "pdf_url": "http://arxiv.org/pdf/2401.07263v1",
    "published_date": "2024-01-14 11:45:05 UTC",
    "updated_date": "2024-01-14 11:45:05 UTC"
  },
  {
    "arxiv_id": "2402.18582v1",
    "title": "Streamlining the Selection Phase of Systematic Literature Reviews (SLRs) Using AI-Enabled GPT-4 Assistant API",
    "authors": [
      "Seyed Mohammad Ali Jafari"
    ],
    "abstract": "The escalating volume of academic literature presents a formidable challenge\nin staying updated with the newest research developments. Addressing this, this\nstudy introduces a pioneering AI-based tool, configured specifically to\nstreamline the efficiency of the article selection phase in Systematic\nLiterature Reviews (SLRs). Utilizing the robust capabilities of OpenAI's GPT-4\nAssistant API, the tool successfully homogenizes the article selection process\nacross a broad array of academic disciplines. Implemented through a tripartite\napproach consisting of data preparation, AI-mediated article assessment, and\nstructured result presentation, this tool significantly accelerates the\ntime-consuming task of literature reviews. Importantly, this tool could be\nhighly beneficial in fields such as management and economics, where the SLR\nprocess involves substantial human judgment. The adoption of a standard GPT\nmodel can substantially reduce potential biases and enhance the speed and\nprecision of the SLR selection phase. This not only amplifies researcher\nproductivity and accuracy but also denotes a considerable stride forward in the\nway academic research is conducted amidst the surging body of scholarly\npublications.",
    "categories": [
      "cs.DL",
      "cs.AI"
    ],
    "primary_category": "cs.DL",
    "comment": "11 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.18582v1",
    "published_date": "2024-01-14 11:16:16 UTC",
    "updated_date": "2024-01-14 11:16:16 UTC"
  },
  {
    "arxiv_id": "2401.07250v2",
    "title": "Stabilizing Sharpness-aware Minimization Through A Simple Renormalization Strategy",
    "authors": [
      "Chengli Tan",
      "Jiangshe Zhang",
      "Junmin Liu",
      "Yicheng Wang",
      "Yunda Hao"
    ],
    "abstract": "Recently, sharpness-aware minimization (SAM) has attracted much attention\nbecause of its surprising effectiveness in improving generalization\nperformance. However, compared to stochastic gradient descent (SGD), it is more\nprone to getting stuck at the saddle points, which as a result may lead to\nperformance degradation. To address this issue, we propose a simple\nrenormalization strategy, dubbed Stable SAM (SSAM), so that the gradient norm\nof the descent step maintains the same as that of the ascent step. Our strategy\nis easy to implement and flexible enough to integrate with SAM and its\nvariants, almost at no computational cost. With elementary tools from convex\noptimization and learning theory, we also conduct a theoretical analysis of\nsharpness-aware training, revealing that compared to SGD, the effectiveness of\nSAM is only assured in a limited regime of learning rate. In contrast, we show\nhow SSAM extends this regime of learning rate and then it can consistently\nperform better than SAM with the minor modification. Finally, we demonstrate\nthe improved performance of SSAM on several representative data sets and tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "33 pages",
    "pdf_url": "http://arxiv.org/pdf/2401.07250v2",
    "published_date": "2024-01-14 10:53:36 UTC",
    "updated_date": "2024-09-10 02:58:54 UTC"
  },
  {
    "arxiv_id": "2401.07237v3",
    "title": "Distilling Event Sequence Knowledge From Large Language Models",
    "authors": [
      "Somin Wadhwa",
      "Oktie Hassanzadeh",
      "Debarun Bhattacharjya",
      "Ken Barker",
      "Jian Ni"
    ],
    "abstract": "Event sequence models have been found to be highly effective in the analysis\nand prediction of events. Building such models requires availability of\nabundant high-quality event sequence data. In certain applications, however,\nclean structured event sequences are not available, and automated sequence\nextraction results in data that is too noisy and incomplete. In this work, we\nexplore the use of Large Language Models (LLMs) to generate event sequences\nthat can effectively be used for probabilistic event model construction. This\ncan be viewed as a mechanism of distilling event sequence knowledge from LLMs.\nOur approach relies on a Knowledge Graph (KG) of event concepts with partial\ncausal relations to guide the generative language model for causal event\nsequence generation. We show that our approach can generate high-quality event\nsequences, filling a knowledge gap in the input KG. Furthermore, we explore how\nthe generated sequences can be leveraged to discover useful and more complex\nstructured knowledge from pattern mining and probabilistic event models. We\nrelease our sequence generation code and evaluation framework, as well as\ncorpus of event sequence data.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "In Proceedings of 23rd International Semantic Web Conference (ISWC),\n  2024",
    "pdf_url": "http://arxiv.org/pdf/2401.07237v3",
    "published_date": "2024-01-14 09:34:42 UTC",
    "updated_date": "2024-07-01 21:43:56 UTC"
  },
  {
    "arxiv_id": "2401.07234v1",
    "title": "The Effects of Data Imbalance Under a Federated Learning Approach for Credit Risk Forecasting",
    "authors": [
      "Shuyao Zhang",
      "Jordan Tay",
      "Pedro Baiz"
    ],
    "abstract": "Credit risk forecasting plays a crucial role for commercial banks and other\nfinancial institutions in granting loans to customers and minimise the\npotential loss. However, traditional machine learning methods require the\nsharing of sensitive client information with an external server to build a\nglobal model, potentially posing a risk of security threats and privacy\nleakage. A newly developed privacy-preserving distributed machine learning\ntechnique known as Federated Learning (FL) allows the training of a global\nmodel without the necessity of accessing private local data directly. This\ninvestigation examined the feasibility of federated learning in credit risk\nassessment and showed the effects of data imbalance on model performance. Two\nneural network architectures, Multilayer Perceptron (MLP) and Long Short-Term\nMemory (LSTM), and one tree ensemble architecture, Extreme Gradient Boosting\n(XGBoost), were explored across three different datasets under various\nscenarios involving different numbers of clients and data distribution\nconfigurations. We demonstrate that federated models consistently outperform\nlocal models on non-dominant clients with smaller datasets. This trend is\nespecially pronounced in highly imbalanced data scenarios, yielding a\nremarkable average improvement of 17.92% in model performance. However, for\ndominant clients (clients with more data), federated models may not exhibit\nsuperior performance, suggesting the need for special incentives for this type\nof clients to encourage their participation.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.07234v1",
    "published_date": "2024-01-14 09:15:10 UTC",
    "updated_date": "2024-01-14 09:15:10 UTC"
  },
  {
    "arxiv_id": "2402.01662v4",
    "title": "Generative Ghosts: Anticipating Benefits and Risks of AI Afterlives",
    "authors": [
      "Meredith Ringel Morris",
      "Jed R. Brubaker"
    ],
    "abstract": "As AI systems quickly improve in both breadth and depth of performance, they\nlend themselves to creating increasingly powerful and realistic agents,\nincluding the possibility of agents modeled on specific people. We anticipate\nthat within our lifetimes it may become common practice for people to create\ncustom AI agents to interact with loved ones and/or the broader world after\ndeath; indeed, the past year has seen a boom in startups purporting to offer\nsuch services. We call these generative ghosts, since such agents will be\ncapable of generating novel content rather than merely parroting content\nproduced by their creator while living. In this paper, we reflect on the\nhistory of technologies for AI afterlives, including current early attempts by\nindividual enthusiasts and startup companies to create generative ghosts. We\nthen introduce a novel design space detailing potential implementations of\ngenerative ghosts, and use this analytic framework to ground discussion of the\npractical and ethical implications of various approaches to designing\ngenerative ghosts, including potential positive and negative impacts on\nindividuals and society. Based on these considerations, we lay out a research\nagenda for the AI and HCI research communities to better understand the\nrisk/benefit landscape of this novel technology so as to ultimately empower\npeople who wish to create and interact with AI afterlives to do so in a\nbeneficial manner.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "version 4, updated to include new references and examples",
    "pdf_url": "http://arxiv.org/pdf/2402.01662v4",
    "published_date": "2024-01-14 08:57:45 UTC",
    "updated_date": "2024-12-12 20:17:54 UTC"
  },
  {
    "arxiv_id": "2401.07220v1",
    "title": "Application of 2D Homography for High Resolution Traffic Data Collection using CCTV Cameras",
    "authors": [
      "Linlin Zhang",
      "Xiang Yu",
      "Abdulateef Daud",
      "Abdul Rashid Mussah",
      "Yaw Adu-Gyamfi"
    ],
    "abstract": "Traffic cameras remain the primary source data for surveillance activities\nsuch as congestion and incident monitoring. To date, State agencies continue to\nrely on manual effort to extract data from networked cameras due to limitations\nof the current automatic vision systems including requirements for complex\ncamera calibration and inability to generate high resolution data. This study\nimplements a three-stage video analytics framework for extracting\nhigh-resolution traffic data such vehicle counts, speed, and acceleration from\ninfrastructure-mounted CCTV cameras. The key components of the framework\ninclude object recognition, perspective transformation, and vehicle trajectory\nreconstruction for traffic data collection. First, a state-of-the-art vehicle\nrecognition model is implemented to detect and classify vehicles. Next, to\ncorrect for camera distortion and reduce partial occlusion, an algorithm\ninspired by two-point linear perspective is utilized to extracts the region of\ninterest (ROI) automatically, while a 2D homography technique transforms the\nCCTV view to bird's-eye view (BEV). Cameras are calibrated with a two-layer\nmatrix system to enable the extraction of speed and acceleration by converting\nimage coordinates to real-world measurements. Individual vehicle trajectories\nare constructed and compared in BEV using two time-space-feature-based object\ntrackers, namely Motpy and BYTETrack. The results of the current study showed\nabout +/- 4.5% error rate for directional traffic counts, less than 10% MSE for\nspeed bias between camera estimates in comparison to estimates from probe data\nsources. Extracting high-resolution data from traffic cameras has several\nimplications, ranging from improvements in traffic management and identify\ndangerous driving behavior, high-risk areas for accidents, and other safety\nconcerns, enabling proactive measures to reduce accidents and fatalities.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "25 pages, 9 figures, this paper was submitted for consideration for\n  presentation at the 102nd Annual Meeting of the Transportation Research\n  Board, January 2023",
    "pdf_url": "http://arxiv.org/pdf/2401.07220v1",
    "published_date": "2024-01-14 07:33:14 UTC",
    "updated_date": "2024-01-14 07:33:14 UTC"
  },
  {
    "arxiv_id": "2401.08696v1",
    "title": "Hierarchical Source-to-Post-Route QoR Prediction in High-Level Synthesis with GNNs",
    "authors": [
      "Mingzhe Gao",
      "Jieru Zhao",
      "Zhe Lin",
      "Minyi Guo"
    ],
    "abstract": "High-level synthesis (HLS) notably speeds up the hardware design process by\navoiding RTL programming. However, the turnaround time of HLS increases\nsignificantly when post-route quality of results (QoR) are considered during\noptimization. To tackle this issue, we propose a hierarchical post-route QoR\nprediction approach for FPGA HLS, which features: (1) a modeling flow that\ndirectly estimates latency and post-route resource usage from C/C++ programs;\n(2) a graph construction method that effectively represents the control and\ndata flow graph of source code and effects of HLS pragmas; and (3) a\nhierarchical GNN training and prediction method capable of capturing the impact\nof loop hierarchies. Experimental results show that our method presents a\nprediction error of less than 10% for different types of QoR metrics, which\ngains tremendous improvement compared with the state-of-the-art GNN methods. By\nadopting our proposed methodology, the runtime for design space exploration in\nHLS is shortened to tens of minutes and the achieved ADRS is reduced to 6.91%\non average.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AR",
    "comment": "Accepted for publication at DATE 2024",
    "pdf_url": "http://arxiv.org/pdf/2401.08696v1",
    "published_date": "2024-01-14 07:24:08 UTC",
    "updated_date": "2024-01-14 07:24:08 UTC"
  },
  {
    "arxiv_id": "2402.18581v1",
    "title": "Multi-objective Optimal Roadside Units Deployment in Urban Vehicular Networks",
    "authors": [
      "Weian Guo",
      "Zecheng Kang",
      "Dongyang Li",
      "Lun Zhang",
      "Li Li"
    ],
    "abstract": "The significance of transportation efficiency, safety, and related services\nis increasing in urban vehicular networks. Within such networks, roadside units\n(RSUs) serve as intermediates in facilitating communication. Therefore, the\ndeployment of RSUs is of utmost importance in ensuring the quality of\ncommunication services. However, the optimization objectives, such as time\ndelay and deployment cost, are commonly developed from diverse perspectives. As\na result, it is possible that conflicts may arise among the objectives.\nFurthermore, in urban environments, the presence of various obstacles, such as\nbuildings, gardens, lakes, and other infrastructure, poses challenges for the\ndeployment of RSUs. Hence, the deployment encounters significant difficulties\ndue to the existence of multiple objectives, constraints imposed by obstacles,\nand the necessity to explore a large-scale optimization space. To address this\nissue, two versions of multi-objective optimization algorithms are proposed in\nthis paper. By utilizing a multi-population strategy and an adaptive\nexploration technique, the methods efficiently explore a large-scale\ndecision-variable space. In order to mitigate the issue of an overcrowded\ndeployment of RSUs, a calibrating mechanism is adopted to adjust RSU density\nduring the optimization procedures. The proposed methods also take care of data\noffloading between vehicles and RSUs by setting up an iterative best response\nsequence game (IBRSG). By comparing the proposed algorithms with several\nstate-of-the-art algorithms, the results demonstrate that our strategies\nperform better in both high-density and low-density urban scenarios. The\nresults also indicate that the proposed solutions substantially improve the\nefficiency of vehicular networks.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "This manuscript has been submitted to the journal of IEEE\n  Transactions on Vehicular Technology",
    "pdf_url": "http://arxiv.org/pdf/2402.18581v1",
    "published_date": "2024-01-14 05:02:12 UTC",
    "updated_date": "2024-01-14 05:02:12 UTC"
  },
  {
    "arxiv_id": "2401.09476v1",
    "title": "A Framework for Agricultural Food Supply Chain using Blockchain",
    "authors": [
      "Sudarssan N"
    ],
    "abstract": "The main aim of the paper is to create a trust and transparency in the food\nsupply chain system, ensuring food safety for everyone with the help of\nBlockchain Technology. Food supply chain is the process of tracing a crop from\nthe farmer or producer to the buyer. With the advent of blockchain, providing a\nsafe and fraud-free environment for the provision of numerous agricultural\nnecessities has become much easier. Because of the globalization of trade, the\npresent supply chain market today includes various companies involving\nintegration of data, complex transactions and distribution. Information tamper\nresistance, supply-demand relationships, and traceable oversight are all\ndifficulties that arise as a result of this. Blockchain is a distributed ledger\ntechnology that can provide information that is resistant to tampering. This\nstrategy can eliminate the need for a centralized trusted authority,\nintermediaries, and business histories, allowing for increased production and\nsecurity while maintaining the highest levels of integrity, liability, and\nsafety. In order to have an integrity and transparency in food supply chain in\nthe agricultural sector, a framework is proposed here based on block chain and\nIoT.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "5 Pages, 5 figures, Under Review",
    "pdf_url": "http://arxiv.org/pdf/2401.09476v1",
    "published_date": "2024-01-14 04:16:01 UTC",
    "updated_date": "2024-01-14 04:16:01 UTC"
  },
  {
    "arxiv_id": "2401.08695v1",
    "title": "Enabling Collaborative Clinical Diagnosis of Infectious Keratitis by Integrating Expert Knowledge and Interpretable Data-driven Intelligence",
    "authors": [
      "Zhengqing Fang",
      "Shuowen Zhou",
      "Zhouhang Yuan",
      "Yuxuan Si",
      "Mengze Li",
      "Jinxu Li",
      "Yesheng Xu",
      "Wenjia Xie",
      "Kun Kuang",
      "Yingming Li",
      "Fei Wu",
      "Yu-Feng Yao"
    ],
    "abstract": "Although data-driven artificial intelligence (AI) in medical image diagnosis\nhas shown impressive performance in silico, the lack of interpretability makes\nit difficult to incorporate the \"black box\" into clinicians' workflows. To make\nthe diagnostic patterns learned from data understandable by clinicians, we\ndevelop an interpretable model, knowledge-guided diagnosis model (KGDM), that\nprovides a visualized reasoning process containing AI-based biomarkers and\nretrieved cases that with the same diagnostic patterns. It embraces clinicians'\nprompts into the interpreted reasoning through human-AI interaction, leading to\npotentially enhanced safety and more accurate predictions. This study\ninvestigates the performance, interpretability, and clinical utility of KGDM in\nthe diagnosis of infectious keratitis (IK), which is the leading cause of\ncorneal blindness. The classification performance of KGDM is evaluated on a\nprospective validation dataset, an external testing dataset, and an publicly\navailable testing dataset. The diagnostic odds ratios (DOR) of the interpreted\nAI-based biomarkers are effective, ranging from 3.011 to 35.233 and exhibit\nconsistent diagnostic patterns with clinic experience. Moreover, a human-AI\ncollaborative diagnosis test is conducted and the participants with\ncollaboration achieved a performance exceeding that of both humans and AI. By\nsynergistically integrating interpretability and interaction, this study\nfacilitates the convergence of clinicians' expertise and data-driven\nintelligence. The promotion of inexperienced ophthalmologists with the aid of\nAI-based biomarkers, as well as increased AI prediction by intervention from\nexperienced ones, demonstrate a promising diagnostic paradigm for infectious\nkeratitis using KGDM, which holds the potential for extension to other diseases\nwhere experienced medical practitioners are limited and the safety of AI is\nconcerned.",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "33 pages",
    "pdf_url": "http://arxiv.org/pdf/2401.08695v1",
    "published_date": "2024-01-14 02:10:54 UTC",
    "updated_date": "2024-01-14 02:10:54 UTC"
  },
  {
    "arxiv_id": "2401.07179v1",
    "title": "Forecasting GDP in Europe with Textual Data",
    "authors": [
      "Luca Barbaglia",
      "Sergio Consoli",
      "Sebastiano Manzan"
    ],
    "abstract": "We evaluate the informational content of news-based sentiment indicators for\nforecasting Gross Domestic Product (GDP) and other macroeconomic variables of\nthe five major European economies. Our data set includes over 27 million\narticles for 26 major newspapers in 5 different languages. The evidence\nindicates that these sentiment indicators are significant predictors to\nforecast macroeconomic variables and their predictive content is robust to\ncontrolling for other indicators available to forecasters in real-time.",
    "categories": [
      "cs.CE",
      "cs.AI",
      "cs.CL",
      "91B62, 91B84, 91B86"
    ],
    "primary_category": "cs.CE",
    "comment": "34 pages, 6 figures, published in Journal of Applied Econometrics\n  (Early view)",
    "pdf_url": "http://arxiv.org/pdf/2401.07179v1",
    "published_date": "2024-01-14 00:33:30 UTC",
    "updated_date": "2024-01-14 00:33:30 UTC"
  }
]