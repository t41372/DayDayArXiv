{
  "date": "2024-01-14",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-01-14 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 更新了 30 篇论文，主要聚焦 AI 算法优化、强化学习、生成式 AI 应用、生物医学诊断和法律影响等领域，其中 Stanley J. Osher 和 Luciano Floridi 等知名学者的作品尤为突出，强调了 AI 的可解释性、泛化能力和实际应用潜力，如 PDE 相关模型的创新和 AI 法律框架的分析。\n\n### 重点论文亮点\n以下挑选了最具影响力和话题度的论文，先从核心创新和实际应用入手，再简要提及其他。\n\n1. **快速综述聚类算法 (A Rapid Review of Clustering Algorithms)**  \n   这篇综述分析了现有聚类算法的优缺点，并从底层原理、数据分配、数据集容量、预定义簇数和应用领域五个维度进行分类，帮助研究者选择适合特定任务的算法。主要贡献是提供了一个全面框架，讨论了未来趋势和挑战，如算法的普适性问题。\n\n2. **噪声感知训练神经形态动态设备网络 (Noise-Aware Training of Neuromorphic Dynamic Device Networks)**  \n   作者团队包括多名专家，提出了一种使用 Neural-SDEs 作为数字孪生模型的噪声感知训练方法，适用于自带记忆的物理设备网络。该方法通过时间反向传播和级联学习，提升了设备网络在时序任务中的性能，并验证了其在自旋电子设备上的有效性，显著减少了训练数据需求。\n\n3. **超越稀疏奖励：使用语言模型批评增强文本生成的强化学习 (Beyond Sparse Rewards: Enhancing Reinforcement Learning with Language Model Critique in Text Generation)**  \n   这篇论文引入了一个框架，利用大语言模型 (LLMs) 提供中间步骤奖励，指导强化学习训练。贡献包括在情感控制、模型去毒化和摘要任务上的性能提升，实验显示该方法提高了样本效率，并通过分层模型设计（如策略模型和批评模型）增强了稳定性。\n\n4. **使用物理信息神经网络从单细胞数据推断动态基因调控网络 (Inference of dynamical gene regulatory networks from single-cell data with physics informed neural networks)**  \n   作者包括 Diego Garlaschelli 和 Stefan Semrau，展示了 PINNs 在推断基因调控网络中的优势。该方法超越了传统相关性分析，能预测细胞分化，支持双重场景（有/无细胞通信），为开发生物学实验提供指导。\n\n5. **PDE 泛化中的 In-Context 算子网络：针对 1D 标量非线性守恒定律的研究 (PDE Generalization of In-Context Operator Networks: A Study on 1D Scalar Nonlinear Conservation Laws)**  \n   知名学者 Stanley J. Osher 参与，提出 ICON 模型能零 fine-tuning 泛化到新 PDE 形式。通过数据提示和函数转换，实现前向和反向预测。该发现标志着 AI 在科学计算中的基础模型潜力。\n\n6. **生成式 AI 在欧盟法律中的应用：责任、隐私、知识产权和网络安全 (Generative AI in EU Law: Liability, Privacy, Intellectual Property, and Cybersecurity)**  \n   作者包括 Luciano Floridi，分析了生成式 AI（如 LLMs）的法律挑战，评估欧盟 AI 法案草案的不足，并提出改进建议。贡献在于桥接 AI 技术和法规，确保合规部署。\n\n其他论文如 **高效逼近 Earth Mover's Distance (Efficient approximation of Earth Mover's Distance)**，通过最近邻搜索优化了计算效率，提升了图像分类任务的性能；**小语言模型的自校正 (Small LLMs Are Weak Tool Learners)**，探索了多 LLM 代理框架，提高了工具学习效果。这些虽有创新，但相对基础或应用导向较弱，故从简。\n\n今天的更新显示 AI 向可解释性和实际应用倾斜，若您关注生物医学或法律领域，建议优先查看以上论文。更多细节可查阅 arXiv！",
  "papers": [
    {
      "arxiv_id": "2401.07389v1",
      "title": "A Rapid Review of Clustering Algorithms",
      "title_zh": "聚类算法的快速综述",
      "authors": [
        "Hui Yin",
        "Amir Aryani",
        "Stephen Petrie",
        "Aishwarya Nambissan",
        "Aland Astudillo",
        "Shengyuan Cao"
      ],
      "abstract": "Clustering algorithms aim to organize data into groups or clusters based on\nthe inherent patterns and similarities within the data. They play an important\nrole in today's life, such as in marketing and e-commerce, healthcare, data\norganization and analysis, and social media. Numerous clustering algorithms\nexist, with ongoing developments introducing new ones. Each algorithm possesses\nits own set of strengths and weaknesses, and as of now, there is no universally\napplicable algorithm for all tasks. In this work, we analyzed existing\nclustering algorithms and classify mainstream algorithms across five different\ndimensions: underlying principles and characteristics, data point assignment to\nclusters, dataset capacity, predefined cluster numbers and application area.\nThis classification facilitates researchers in understanding clustering\nalgorithms from various perspectives and helps them identify algorithms\nsuitable for solving specific tasks. Finally, we discussed the current trends\nand potential future directions in clustering algorithms. We also identified\nand discussed open challenges and unresolved issues in the field.",
      "tldr_zh": "这篇论文对Clustering Algorithms进行了快速综述，探讨了这些算法如何基于数据内在模式和相似性将数据组织成群，并强调了它们在营销、电子商务、医疗和社交媒体等领域的应用。作者分析并分类了主流算法，按五个维度进行划分，包括底层原则、数据点分配、数据集容量、预定义簇数和应用领域，以帮助研究者从不同角度理解和选择合适算法。最后，论文讨论了Clustering Algorithms的当前趋势、潜在未来方向，以及存在的开放挑战和未解决问题。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "68-02",
        "I.2.0"
      ],
      "primary_category": "cs.LG",
      "comment": "25 pages, 7 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2401.07389v1",
      "published_date": "2024-01-14 23:19:53 UTC",
      "updated_date": "2024-01-14 23:19:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T21:44:44.561904"
    },
    {
      "arxiv_id": "2401.07387v2",
      "title": "Noise-Aware Training of Neuromorphic Dynamic Device Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Luca Manneschi",
        "Ian T. Vidamour",
        "Kilian D. Stenning",
        "Charles Swindells",
        "Guru Venkat",
        "David Griffin",
        "Lai Gui",
        "Daanish Sonawala",
        "Denis Donskikh",
        "Dana Hariga",
        "Susan Stepney",
        "Will R. Branford",
        "Jack C. Gartside",
        "Thomas Hayward",
        "Matthew O. A. Ellis",
        "Eleni Vasilaki"
      ],
      "abstract": "Physical computing has the potential to enable widespread embodied\nintelligence by leveraging the intrinsic dynamics of complex systems for\nefficient sensing, processing, and interaction. While individual devices\nprovide basic data processing capabilities, networks of interconnected devices\ncan perform more complex and varied tasks. However, designing networks to\nperform dynamic tasks is challenging without physical models and accurate\nquantification of device noise. We propose a novel, noise-aware methodology for\ntraining device networks using Neural Stochastic Differential Equations\n(Neural-SDEs) as differentiable digital twins, accurately capturing the\ndynamics and associated stochasticity of devices with intrinsic memory. Our\napproach employs backpropagation through time and cascade learning, allowing\nnetworks to effectively exploit the temporal properties of physical devices. We\nvalidate our method on diverse networks of spintronic devices across temporal\nclassification and regression benchmarks. By decoupling the training of\nindividual device models from network training, our method reduces the required\ntraining data and provides a robust framework for programming dynamical devices\nwithout relying on analytical descriptions of their dynamics.",
      "tldr_zh": "本研究针对神经形态动态设备网络的设计挑战，提出了一种噪声感知训练方法，以应对缺乏物理模型和设备噪声量化的问题。该方法利用 Neural-SDEs 作为可微数字孪生体，精确捕捉设备的动态和随机性，并结合 backpropagation through time 和 cascade learning 技术，使网络有效利用物理设备的时序特性。在 spintronic 设备网络上进行验证，该方法在时序分类和回归基准中表现出色，减少了所需训练数据，并提供了一个无需依赖设备动态分析描述的鲁棒框架。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.ET",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.07387v2",
      "published_date": "2024-01-14 22:46:53 UTC",
      "updated_date": "2024-10-28 17:24:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T21:44:56.748094"
    },
    {
      "arxiv_id": "2401.07382v2",
      "title": "Beyond Sparse Rewards: Enhancing Reinforcement Learning with Language Model Critique in Text Generation",
      "title_zh": "超越稀疏奖励：在文本生成中使用语言模型评估增强强化学习",
      "authors": [
        "Meng Cao",
        "Lei Shu",
        "Lei Yu",
        "Yun Zhu",
        "Nevan Wichers",
        "Yinxiao Liu",
        "Lei Meng"
      ],
      "abstract": "Reinforcement learning (RL) can align language models with non-differentiable\nreward signals, such as human preferences. However, a major challenge arises\nfrom the sparsity of these reward signals - typically, there is only a single\nreward for an entire output. This sparsity of rewards can lead to inefficient\nand unstable learning. To address this challenge, our paper introduces an novel\nframework that utilizes the critique capability of Large Language Models (LLMs)\nto produce intermediate-step rewards during RL training. Our method involves\ncoupling a policy model with a critic language model, which is responsible for\nproviding comprehensive feedback of each part of the output. This feedback is\nthen translated into token or span-level rewards that can be used to guide the\nRL training process. We investigate this approach under two different settings:\none where the policy model is smaller and is paired with a more powerful critic\nmodel, and another where a single language model fulfills both roles. We assess\nour approach on three text generation tasks: sentiment control, language model\ndetoxification, and summarization. Experimental results show that incorporating\nartificial intrinsic rewards significantly improve both sample efficiency and\nthe overall performance of the policy model, supported by both automatic and\nhuman evaluation.",
      "tldr_zh": "本研究提出了一种新框架，用于解决强化学习（RL）在文本生成任务中因奖励信号稀疏性导致的学习效率低和不稳定问题。该框架利用大型语言模型（LLMs）的批评能力，提供输出每个部分的中间反馈，并将其转化为 token 或 span 级别的奖励，以指导 RL 训练。具体来说，方法将策略模型与批评者模型结合，并在情感控制、语言模型去毒化和摘要生成等任务上进行评估。实验结果显示，这种加入人工内在奖励的做法显著提升了样本效率和整体性能，并获得自动和人类评估的支持。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.07382v2",
      "published_date": "2024-01-14 22:05:11 UTC",
      "updated_date": "2024-02-19 18:19:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T21:45:09.185161"
    },
    {
      "arxiv_id": "2401.07379v1",
      "title": "Inference of dynamical gene regulatory networks from single-cell data with physics informed neural networks",
      "title_zh": "翻译失败",
      "authors": [
        "Maria Mircea",
        "Diego Garlaschelli",
        "Stefan Semrau"
      ],
      "abstract": "One of the main goals of developmental biology is to reveal the gene\nregulatory networks (GRNs) underlying the robust differentiation of multipotent\nprogenitors into precisely specified cell types. Most existing methods to infer\nGRNs from experimental data have limited predictive power as the inferred GRNs\nmerely reflect gene expression similarity or correlation. Here, we demonstrate,\nhow physics-informed neural networks (PINNs) can be used to infer the\nparameters of predictive, dynamical GRNs that provide mechanistic understanding\nof biological processes. Specifically we study GRNs that exhibit bifurcation\nbehavior and can therefore model cell differentiation. We show that PINNs\noutperform regular feed-forward neural networks on the parameter inference task\nand analyze two relevant experimental scenarios: 1. a system with cell\ncommunication for which gene expression trajectories are available and 2.\nsnapshot measurements of a cell population in which cell communication is\nabsent. Our analysis will inform the design of future experiments to be\nanalyzed with PINNs and provides a starting point to explore this powerful\nclass of neural network models further.",
      "tldr_zh": "本研究利用physics informed neural networks (PINNs)从单细胞数据中推断动态gene regulatory networks (GRNs)，以揭示多能前体细胞分化的机制过程，并解决现有方法仅依赖基因表达相似性导致预测力不足的问题。PINNs通过整合物理信息和神经网络，显著优于常规前馈神经网络，在参数推断任务中表现出色，特别是针对表现出分叉行为的GRNs模拟细胞分化。研究分析了两种实验场景——包括细胞通信的基因表达轨迹和无通信的细胞群快照测量——为未来实验设计提供指导，并扩展了PINNs在生物学中的应用潜力。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.LG",
        "physics.bio-ph",
        "q-bio.MN"
      ],
      "primary_category": "q-bio.QM",
      "comment": "25 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2401.07379v1",
      "published_date": "2024-01-14 21:43:10 UTC",
      "updated_date": "2024-01-14 21:43:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T21:45:22.141778"
    },
    {
      "arxiv_id": "2401.07378v3",
      "title": "Efficient approximation of Earth Mover's Distance Based on Nearest Neighbor Search",
      "title_zh": "基于最近邻搜索的 Earth Mover's Distance 高效近似方法",
      "authors": [
        "Guangyu Meng",
        "Ruyu Zhou",
        "Liu Liu",
        "Peixian Liang",
        "Fang Liu",
        "Danny Chen",
        "Michael Niemier",
        "X. Sharon Hu"
      ],
      "abstract": "Earth Mover's Distance (EMD) is an important similarity measure between two\ndistributions, used in computer vision and many other application domains.\nHowever, its exact calculation is computationally and memory intensive, which\nhinders its scalability and applicability for large-scale problems. Various\napproximate EMD algorithms have been proposed to reduce computational costs,\nbut they suffer lower accuracy and may require additional memory usage or\nmanual parameter tuning. In this paper, we present a novel approach, NNS-EMD,\nto approximate EMD using Nearest Neighbor Search (NNS), in order to achieve\nhigh accuracy, low time complexity, and high memory efficiency. The NNS\noperation reduces the number of data points compared in each NNS iteration and\noffers opportunities for parallel processing. We further accelerate NNS-EMD via\nvectorization on GPU, which is especially beneficial for large datasets. We\ncompare NNS-EMD with both the exact EMD and state-of-the-art approximate EMD\nalgorithms on image classification and retrieval tasks. We also apply NNS-EMD\nto calculate transport mapping and realize color transfer between images.\nNNS-EMD can be 44x to 135x faster than the exact EMD implementation, and\nachieves superior accuracy, speedup, and memory efficiency over existing\napproximate EMD methods.",
      "tldr_zh": "本文提出了一种基于 Nearest Neighbor Search (NNS) 的高效近似算法 NNS-EMD，用于计算 Earth Mover's Distance (EMD)，以解决其精确计算在计算量和内存密集方面的挑战。NNS-EMD 通过减少数据点比较、支持并行处理，并利用 GPU 向量化加速，实现了高准确性、低时间复杂度和高内存效率。在图像分类、检索以及颜色转移任务的实验中，该方法比精确 EMD 快 44 至 135 倍，并显著优于现有近似算法的表现。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.07378v3",
      "published_date": "2024-01-14 21:42:18 UTC",
      "updated_date": "2025-05-14 13:38:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T21:45:33.482274"
    },
    {
      "arxiv_id": "2401.07364v2",
      "title": "PDE Generalization of In-Context Operator Networks: A Study on 1D Scalar Nonlinear Conservation Laws",
      "title_zh": "翻译失败",
      "authors": [
        "Liu Yang",
        "Stanley J. Osher"
      ],
      "abstract": "Can we build a single large model for a wide range of PDE-related scientific\nlearning tasks? Can this model generalize to new PDEs, even of new forms,\nwithout any fine-tuning? In-context operator learning and the corresponding\nmodel In-Context Operator Networks (ICON) represent an initial exploration of\nthese questions. The capability of ICON regarding the first question has been\ndemonstrated previously. In this paper, we present a detailed methodology for\nsolving PDE problems with ICON, and show how a single ICON model can make\nforward and reverse predictions for different equations with different strides,\nprovided with appropriately designed data prompts. We show the positive\nevidence to the second question, i.e., ICON can generalize well to some PDEs\nwith new forms without any fine-tuning. This is exemplified through a study on\n1D scalar nonlinear conservation laws, a family of PDEs with temporal\nevolution. We also show how to broaden the range of problems that an ICON model\ncan address, by transforming functions and equations to ICON's capability\nscope. We believe that the progress in this paper is a significant step towards\nthe goal of training a foundation model for PDE-related tasks under the\nin-context operator learning framework.",
      "tldr_zh": "这篇论文探讨了是否能构建一个单一模型来处理广泛的PDE（偏微分方程）相关科学学习任务，并专注于In-Context Operator Networks (ICON)的泛化能力。作者详细介绍了使用ICON的方法，通过设计适当的数据提示，使单个模型能够在不进行微调的情况下，对不同方程进行正向和逆向预测。研究在1D scalar nonlinear conservation laws（一维标量非线性守恒定律）上展示了ICON对新形式PDE的良好泛化效果。最终，论文通过函数和方程转换扩展了ICON的适用范围，为训练PDE相关任务的基金会模型提供了重要进展。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NA",
        "math.NA"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.07364v2",
      "published_date": "2024-01-14 20:41:36 UTC",
      "updated_date": "2024-01-21 22:08:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T21:45:45.743779"
    },
    {
      "arxiv_id": "2401.07359v3",
      "title": "Reliability and Interpretability in Science and Deep Learning",
      "title_zh": "科学和深度学习中的可靠性和可解释性",
      "authors": [
        "Luigi Scorzato"
      ],
      "abstract": "In recent years, the question of the reliability of Machine Learning (ML)\nmethods has acquired significant importance, and the analysis of the associated\nuncertainties has motivated a growing amount of research. However, most of\nthese studies have applied standard error analysis to ML models, and in\nparticular Deep Neural Network (DNN) models, which represent a rather\nsignificant departure from standard scientific modelling. It is therefore\nnecessary to integrate the standard error analysis with a deeper\nepistemological analysis of the possible differences between DNN models and\nstandard scientific modelling and the possible implications of these\ndifferences in the assessment of reliability. This article offers several\ncontributions. First, it emphasises the ubiquitous role of model assumptions\n(both in ML and traditional Science) against the illusion of theory-free\nscience. Secondly, model assumptions are analysed from the point of view of\ntheir (epistemic) complexity, which is shown to be language-independent. It is\nargued that the high epistemic complexity of DNN models hinders the estimate of\ntheir reliability and also their prospect of long-term progress. Some potential\nways forward are suggested. Thirdly, this article identifies the close relation\nbetween a model's epistemic complexity and its interpretability, as introduced\nin the context of responsible AI. This clarifies in which sense, and to what\nextent, the lack of understanding of a model (black-box problem) impacts its\ninterpretability in a way that is independent of individual skills. It also\nclarifies how interpretability is a precondition for assessing the reliability\nof any model, which cannot be based on statistical analysis alone. This article\nfocuses on the comparison between traditional scientific models and DNN models.\nBut, Random Forest and Logistic Regression models are also briefly considered.",
      "tldr_zh": "这篇论文探讨了机器学习（ML）方法，特别是深度神经网络（DNN）模型的可靠性和可解释性（interpretability），并将其与传统科学建模进行比较。论文强调模型假设在ML和科学中的普遍作用，驳斥了无理论科学的幻觉，并分析了假设的认识论复杂性（epistemic complexity），指出DNN模型的高复杂性阻碍了可靠性的评估和长期进步。作者进一步阐明，可解释性与认识论复杂性密切相关，是评估任何模型可靠性的先决条件，而非仅依赖统计分析；论文还简要讨论了Random Forest和Logistic Regression模型，以提供更广泛的对比。总的来说，这为提升AI模型的可靠性提供了理论基础和潜在改进路径。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "physics.hist-ph"
      ],
      "primary_category": "cs.AI",
      "comment": "To appear in Minds and Machines",
      "pdf_url": "http://arxiv.org/pdf/2401.07359v3",
      "published_date": "2024-01-14 20:14:07 UTC",
      "updated_date": "2024-06-12 06:18:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T21:45:57.672041"
    },
    {
      "arxiv_id": "2401.07353v2",
      "title": "Towards Engineering Fair and Equitable Software Systems for Managing Low-Altitude Airspace Authorizations",
      "title_zh": "翻译失败",
      "authors": [
        "Usman Gohar",
        "Michael C. Hunter",
        "Agnieszka Marczak-Czajka",
        "Robyn R. Lutz",
        "Myra B. Cohen",
        "Jane Cleland-Huang"
      ],
      "abstract": "Small Unmanned Aircraft Systems (sUAS) have gained widespread adoption across\na diverse range of applications. This has introduced operational complexities\nwithin shared airspaces and an increase in reported incidents, raising safety\nconcerns. In response, the U.S. Federal Aviation Administration (FAA) is\ndeveloping a UAS Traffic Management (UTM) system to control access to airspace\nbased on an sUAS's predicted ability to safely complete its mission. However, a\nfully automated system capable of swiftly approving or denying flight requests\ncan be prone to bias and must consider safety, transparency, and fairness to\ndiverse stakeholders. In this paper, we present an initial study that explores\nstakeholders' perspectives on factors that should be considered in an automated\nsystem. Results indicate flight characteristics and environmental conditions\nwere perceived as most important but pilot and drone capabilities should also\nbe considered. Further, several respondents indicated an aversion to any\nAI-supported automation, highlighting the need for full transparency in\nautomated decision-making. Results provide a societal perspective on the\nchallenges of automating UTM flight authorization decisions and help frame the\nongoing design of a solution acceptable to the broader sUAS community.",
      "tldr_zh": "该论文探讨了小无人机系统(sUAS)在低空空域授权管理中面临的公平性和公平问题，背景是sUAS的广泛应用导致了共享空域的复杂性和安全风险，而美国联邦航空管理局(FAA)正在开发UAS Traffic Management (UTM)系统来自动化飞行请求审批。研究通过初步调查收集利益相关者的观点，发现飞行特征和环境条件被视为最重要因素，同时飞行员和无人机能力也应纳入考虑。许多受访者对AI支持的自动化持反对态度，强调决策过程的完全透明。这些发现为设计安全、透明且公平的UTM系统提供了社会视角，并指导了更广泛的sUAS社区接受的解决方案。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.07353v2",
      "published_date": "2024-01-14 19:40:32 UTC",
      "updated_date": "2024-02-03 14:55:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T21:46:08.659984"
    },
    {
      "arxiv_id": "2401.07348v4",
      "title": "Generative AI in EU Law: Liability, Privacy, Intellectual Property, and Cybersecurity",
      "title_zh": "翻译失败",
      "authors": [
        "Claudio Novelli",
        "Federico Casolari",
        "Philipp Hacker",
        "Giorgio Spedicato",
        "Luciano Floridi"
      ],
      "abstract": "The advent of Generative AI, particularly through Large Language Models\n(LLMs) like ChatGPT and its successors, marks a paradigm shift in the AI\nlandscape. Advanced LLMs exhibit multimodality, handling diverse data formats,\nthereby broadening their application scope. However, the complexity and\nemergent autonomy of these models introduce challenges in predictability and\nlegal compliance. This paper delves into the legal and regulatory implications\nof Generative AI and LLMs in the European Union context, analyzing aspects of\nliability, privacy, intellectual property, and cybersecurity. It critically\nexamines the adequacy of the existing and proposed EU legislation, including\nthe Artificial Intelligence Act (AIA) draft, in addressing the unique\nchallenges posed by Generative AI in general and LLMs in particular. The paper\nidentifies potential gaps and shortcomings in the legislative framework and\nproposes recommendations to ensure the safe and compliant deployment of\ngenerative models, ensuring they align with the EU's evolving digital landscape\nand legal standards.",
      "tldr_zh": "本文探讨了生成式 AI，特别是大型语言模型 (LLMs) 如 ChatGPT，在欧盟法律框架下的影响，焦点包括责任 (liability)、隐私 (privacy)、知识产权 (intellectual property) 和网络安全 (cybersecurity)。论文批判性地分析了现有和拟议的欧盟立法，如 Artificial Intelligence Act (AIA) 草案，评估其在应对这些模型的复杂性和自主性挑战方面的 adequacy。研究识别了立法框架中的潜在 gaps 和 shortcomings，例如在预测性和合规性方面的不足。最终，论文提出 recommendations，以确保生成式 AI 的安全部署，符合欧盟的数字景观和法律标准。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.07348v4",
      "published_date": "2024-01-14 19:16:29 UTC",
      "updated_date": "2024-03-15 17:10:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T21:46:22.051883"
    },
    {
      "arxiv_id": "2401.07336v1",
      "title": "Construction and Evaluation of Mandarin Multimodal Emotional Speech Database",
      "title_zh": "翻译失败",
      "authors": [
        "Zhu Ting",
        "Li Liangqi",
        "Duan Shufei",
        "Zhang Xueying",
        "Xiao Zhongzhe",
        "Jia Hairng",
        "Liang Huizhi"
      ],
      "abstract": "A multi-modal emotional speech Mandarin database including articulatory\nkinematics, acoustics, glottal and facial micro-expressions is designed and\nestablished, which is described in detail from the aspects of corpus design,\nsubject selection, recording details and data processing. Where signals are\nlabeled with discrete emotion labels (neutral, happy, pleasant, indifferent,\nangry, sad, grief) and dimensional emotion labels (pleasure, arousal,\ndominance). In this paper, the validity of dimension annotation is verified by\nstatistical analysis of dimension annotation data. The SCL-90 scale data of\nannotators are verified and combined with PAD annotation data for analysis, so\nas to explore the internal relationship between the outlier phenomenon in\nannotation and the psychological state of annotators. In order to verify the\nspeech quality and emotion discrimination of the database, this paper uses 3\nbasic models of SVM, CNN and DNN to calculate the recognition rate of these\nseven emotions. The results show that the average recognition rate of seven\nemotions is about 82% when using acoustic data alone. When using glottal data\nalone, the average recognition rate is about 72%. Using kinematics data alone,\nthe average recognition rate also reaches 55.7%. Therefore, the database is of\nhigh quality and can be used as an important source for speech analysis\nresearch, especially for the task of multimodal emotional speech analysis.",
      "tldr_zh": "本文构建并评估了一个多模态情感语音数据库，涵盖唇部运动、声学、声门和面部微表情数据，并从语料设计、受试者选择、录音细节和数据处理等方面进行详细描述。数据库使用离散情感标签（neutral, happy, pleasant, indifferent, angry, sad, grief）和维度情感标签（pleasure, arousal, dominance）进行标注，并通过统计分析验证了维度标注的有效性，同时结合 SCL-90 量表数据探索了标注者心理状态与标注异常的关系。研究采用 SVM, CNN 和 DNN 模型测试情感识别率，结果显示使用声学数据时平均识别率约82%，声门数据约72%，运动学数据约55.7%。该数据库质量高，可作为语音分析研究的重要资源，特别是多模态情感语音分析任务。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.SD",
        "eess.SP"
      ],
      "primary_category": "eess.AS",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.07336v1",
      "published_date": "2024-01-14 17:56:36 UTC",
      "updated_date": "2024-01-14 17:56:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T21:46:35.759875"
    },
    {
      "arxiv_id": "2401.10284v1",
      "title": "MorpheusNet: Resource efficient sleep stage classifier for embedded on-line systems",
      "title_zh": "翻译失败",
      "authors": [
        "Ali Kavoosi",
        "Morgan P. Mitchell",
        "Raveen Kariyawasam",
        "John E. Fleming",
        "Penny Lewis",
        "Heidi Johansen-Berg",
        "Hayriye Cagnan",
        "Timothy Denison"
      ],
      "abstract": "Sleep Stage Classification (SSC) is a labor-intensive task, requiring experts\nto examine hours of electrophysiological recordings for manual classification.\nThis is a limiting factor when it comes to leveraging sleep stages for\ntherapeutic purposes. With increasing affordability and expansion of wearable\ndevices, automating SSC may enable deployment of sleep-based therapies at\nscale. Deep Learning has gained increasing attention as a potential method to\nautomate this process. Previous research has shown accuracy comparable to\nmanual expert scores. However, previous approaches require sizable amount of\nmemory and computational resources. This constrains the ability to classify in\nreal time and deploy models on the edge. To address this gap, we aim to provide\na model capable of predicting sleep stages in real-time, without requiring\naccess to external computational sources (e.g., mobile phone, cloud). The\nalgorithm is power efficient to enable use on embedded battery powered systems.\nOur compact sleep stage classifier can be deployed on most off-the-shelf\nmicrocontrollers (MCU) with constrained hardware settings. This is due to the\nmemory footprint of our approach requiring significantly fewer operations. The\nmodel was tested on three publicly available data bases and achieved\nperformance comparable to the state of the art, whilst reducing model\ncomplexity by orders of magnitude (up to 280 times smaller compared to state of\nthe art). We further optimized the model with quantization of parameters to 8\nbits with only an average drop of 0.95% in accuracy. When implemented in\nfirmware, the quantized model achieves a latency of 1.6 seconds on an Arm\nCortexM4 processor, allowing its use for on-line SSC-based therapies.",
      "tldr_zh": "本论文针对睡眠阶段分类(SSC)的劳动密集型问题，提出了一种资源高效的模型MorpheusNet，旨在实现实时睡眠阶段预测并部署在嵌入式系统上，而无需外部计算资源如手机或云端。该模型采用紧凑的深度学习架构，显著降低了内存和计算需求，使其适合于廉价的微控制器(MCU)。在三个公开数据库上测试，MorpheusNet的性能与最先进方法相当，但模型复杂度减少了最多280倍；通过参数量化到8位，仅损失0.95%的准确率，并在Arm Cortex M4处理器上实现1.6秒的延迟，支持在线SSC-based疗法。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "This paper was presented at the 2023 IEEE conference on Systems, Man,\n  and Cybernetics (SMC)",
      "pdf_url": "http://arxiv.org/pdf/2401.10284v1",
      "published_date": "2024-01-14 17:52:08 UTC",
      "updated_date": "2024-01-14 17:52:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T21:46:49.524779"
    },
    {
      "arxiv_id": "2401.07333v1",
      "title": "ELLA-V: Stable Neural Codec Language Modeling with Alignment-guided Sequence Reordering",
      "title_zh": "翻译失败",
      "authors": [
        "Yakun Song",
        "Zhuo Chen",
        "Xiaofei Wang",
        "Ziyang Ma",
        "Xie Chen"
      ],
      "abstract": "The language model (LM) approach based on acoustic and linguistic prompts,\nsuch as VALL-E, has achieved remarkable progress in the field of zero-shot\naudio generation. However, existing methods still have some limitations: 1)\nrepetitions, transpositions, and omissions in the output synthesized speech due\nto limited alignment constraints between audio and phoneme tokens; 2)\nchallenges of fine-grained control over the synthesized speech with\nautoregressive (AR) language model; 3) infinite silence generation due to the\nnature of AR-based decoding, especially under the greedy strategy. To alleviate\nthese issues, we propose ELLA-V, a simple but efficient LM-based zero-shot\ntext-to-speech (TTS) framework, which enables fine-grained control over\nsynthesized audio at the phoneme level. The key to ELLA-V is interleaving\nsequences of acoustic and phoneme tokens, where phoneme tokens appear ahead of\nthe corresponding acoustic tokens. The experimental findings reveal that our\nmodel outperforms VALL-E in terms of accuracy and delivers more stable results\nusing both greedy and sampling-based decoding strategies. The code of ELLA-V\nwill be open-sourced after cleanups. Audio samples are available at\nhttps://ereboas.github.io/ELLAV/.",
      "tldr_zh": "本研究针对基于语言模型（LM）的零样本音频生成（如VALL-E）存在的问题，包括输出语音中的重复、转置、遗漏、细粒度控制挑战以及autoregressive (AR) 解码导致的无限沉默，提出了一种简单高效的框架ELLA-V。ELLA-V的关键创新是通过alignment-guided sequence reordering，将音素tokens置于对应的acoustic tokens之前，实现对合成音频在音素级别的细粒度控制。实验结果表明，ELLA-V在准确性上优于VALL-E，并在greedy和采样-based解码策略下提供更稳定的性能，为零样本text-to-speech (TTS) 系统提供了可靠改进。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "Working in progress",
      "pdf_url": "http://arxiv.org/pdf/2401.07333v1",
      "published_date": "2024-01-14 17:43:55 UTC",
      "updated_date": "2024-01-14 17:43:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T21:47:01.405852"
    },
    {
      "arxiv_id": "2401.07324v3",
      "title": "Small LLMs Are Weak Tool Learners: A Multi-LLM Agent",
      "title_zh": "翻译失败",
      "authors": [
        "Weizhou Shen",
        "Chenliang Li",
        "Hongzhan Chen",
        "Ming Yan",
        "Xiaojun Quan",
        "Hehong Chen",
        "Ji Zhang",
        "Fei Huang"
      ],
      "abstract": "Large Language Model (LLM) agents significantly extend the capabilities of\nstandalone LLMs, empowering them to interact with external tools (e.g., APIs,\nfunctions) and complete various tasks in a self-directed fashion. The challenge\nof tool use demands that LLMs not only understand user queries and generate\nanswers accurately but also excel in task planning, tool invocation, and result\nsummarization. While traditional works focus on training a single LLM with all\nthese capabilities, performance limitations become apparent, particularly with\nsmaller models. To overcome these challenges, we propose a novel approach that\ndecomposes the aforementioned capabilities into a planner, caller, and\nsummarizer. Each component is implemented by a single LLM that focuses on a\nspecific capability and collaborates with others to accomplish the task. This\nmodular framework facilitates individual updates and the potential use of\nsmaller LLMs for building each capability. To effectively train this framework,\nwe introduce a two-stage training paradigm. First, we fine-tune a backbone LLM\non the entire dataset without discriminating sub-tasks, providing the model\nwith a comprehensive understanding of the task. Second, the fine-tuned LLM is\nused to instantiate the planner, caller, and summarizer respectively, which are\ncontinually fine-tuned on respective sub-tasks. Evaluation across various\ntool-use benchmarks illustrates that our proposed multi-LLM framework surpasses\nthe traditional single-LLM approach, highlighting its efficacy and advantages\nin tool learning.",
      "tldr_zh": "该研究发现小型 Large Language Models (LLMs) 在工具学习方面表现较弱，难以有效处理任务规划、工具调用和结果总结等挑战。论文提出一种多-LLM 代理框架，将这些能力分解为 planner（规划者）、caller（调用者）和 summarizer（总结者）三个独立组件，每个由一个 LLM 实现，并通过协作完成任务。采用两阶段训练范式，首先在整个数据集上微调 LLM 以获得全面理解，然后分别微调各组件；实验结果显示，该框架在各种工具使用基准上超过了传统单一 LLM 方法，证明了其在提升工具学习效能方面的优势。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "On progress, github repo: https://github.com/X-PLUG/Multi-LLM-Agent",
      "pdf_url": "http://arxiv.org/pdf/2401.07324v3",
      "published_date": "2024-01-14 16:17:07 UTC",
      "updated_date": "2024-02-16 12:42:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T21:47:14.731792"
    },
    {
      "arxiv_id": "2401.07314v3",
      "title": "MapGPT: Map-Guided Prompting with Adaptive Path Planning for Vision-and-Language Navigation",
      "title_zh": "翻译失败",
      "authors": [
        "Jiaqi Chen",
        "Bingqian Lin",
        "Ran Xu",
        "Zhenhua Chai",
        "Xiaodan Liang",
        "Kwan-Yee K. Wong"
      ],
      "abstract": "Embodied agents equipped with GPT as their brains have exhibited\nextraordinary decision-making and generalization abilities across various\ntasks. However, existing zero-shot agents for vision-and-language navigation\n(VLN) only prompt GPT-4 to select potential locations within localized\nenvironments, without constructing an effective \"global-view\" for the agent to\nunderstand the overall environment. In this work, we present a novel map-guided\nGPT-based agent, dubbed MapGPT, which introduces an online linguistic-formed\nmap to encourage global exploration. Specifically, we build an online map and\nincorporate it into the prompts that include node information and topological\nrelationships, to help GPT understand the spatial environment. Benefiting from\nthis design, we further propose an adaptive planning mechanism to assist the\nagent in performing multi-step path planning based on a map, systematically\nexploring multiple candidate nodes or sub-goals step by step. Extensive\nexperiments demonstrate that our MapGPT is applicable to both GPT-4 and GPT-4V,\nachieving state-of-the-art zero-shot performance on R2R and REVERIE\nsimultaneously (~10% and ~12% improvements in SR), and showcasing the newly\nemergent global thinking and path planning abilities of the GPT.",
      "tldr_zh": "本文提出 MapGPT，一种基于地图引导的提示框架，用于视觉和语言导航 (VLN)，通过引入在线语言形式地图 (online linguistic-formed map) 来帮助 GPT-4 和 GPT-4V 理解全局空间环境，并支持系统化的探索。MapGPT 结合节点信息、拓扑关系和自适应规划机制 (adaptive planning mechanism)，实现多步路径规划和候选节点探索。实验结果显示，该方法在 R2R 和 REVERIE 数据集上实现了最先进的零样本性能，提高了约 10% 和 12% 的成功率 (SR)，突显了 GPT 的全局思考和路径规划能力。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "LLM/VLM-based VLN Agents. Accepted to ACL 2024. Project:\n  https://chen-judge.github.io/MapGPT/",
      "pdf_url": "http://arxiv.org/pdf/2401.07314v3",
      "published_date": "2024-01-14 15:34:48 UTC",
      "updated_date": "2024-06-20 07:23:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T21:47:25.802572"
    },
    {
      "arxiv_id": "2401.07301v2",
      "title": "Small Language Model Can Self-correct",
      "title_zh": "小型语言模型可以自我修正",
      "authors": [
        "Haixia Han",
        "Jiaqing Liang",
        "Jie Shi",
        "Qianyu He",
        "Yanghua Xiao"
      ],
      "abstract": "Generative Language Models (LMs) such as ChatGPT have exhibited remarkable\nperformance across various downstream tasks. Nevertheless, one of their most\nprominent drawbacks is generating inaccurate or false information with a\nconfident tone. Previous studies have devised sophisticated pipelines and\nprompts to induce large LMs to exhibit the capability for self-correction.\nHowever, large LMs are explicitly prompted to verify and modify its answers\nseparately rather than completing all steps spontaneously like humans.\nMoreover, these complex prompts are extremely challenging for small LMs to\nfollow. In this paper, we introduce the \\underline{I}ntrinsic\n\\underline{S}elf-\\underline{C}orrection (ISC) in generative language models,\naiming to correct the initial output of LMs in a self-triggered manner, even\nfor those small LMs with 6 billion parameters. Specifically, we devise a\npipeline for constructing self-correction data and propose Partial Answer\nMasking (PAM), aiming to endow the model with the capability for intrinsic\nself-correction through fine-tuning. We conduct experiments using LMs with\nparameters sizes ranging from 6 billion to 13 billion in two tasks, including\ncommonsense reasoning and factual knowledge reasoning. Our experiments\ndemonstrate that the outputs generated using ISC outperform those generated\nwithout self-correction. We believe that the output quality of even small LMs\ncan be further improved by empowering them with the ability to intrinsic\nself-correct.",
      "tldr_zh": "本研究针对生成式语言模型（Generative Language Models）易产生不准确信息的缺陷，提出Intrinsic Self-Correction (ISC) 方法，使小语言模型（6B 参数级别）能够自发触发输出自更正。ISC 通过构建自更正数据管道和Partial Answer Masking (PAM) 技术，对模型进行微调，提升其内在自更正能力。实验在6B至13B参数的模型上测试常识推理和事实知识推理任务，结果显示，使用ISC的输出质量显著优于无自更正基准，证明小模型也能通过这一机制改善性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.07301v2",
      "published_date": "2024-01-14 14:29:07 UTC",
      "updated_date": "2024-05-11 12:51:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T21:47:36.478889"
    },
    {
      "arxiv_id": "2401.08699v3",
      "title": "On Image Search in Histopathology",
      "title_zh": "翻译失败",
      "authors": [
        "H. R. Tizhoosh",
        "Liron Pantanowitz"
      ],
      "abstract": "Pathology images of histopathology can be acquired from camera-mounted\nmicroscopes or whole slide scanners. Utilizing similarity calculations to match\npatients based on these images holds significant potential in research and\nclinical contexts. Recent advancements in search technologies allow for\nimplicit quantification of tissue morphology across diverse primary sites,\nfacilitating comparisons and enabling inferences about diagnosis, and\npotentially prognosis, and predictions for new patients when compared against a\ncurated database of diagnosed and treated cases. In this paper, we\ncomprehensively review the latest developments in image search technologies for\nhistopathology, offering a concise overview tailored for computational\npathology researchers seeking effective, fast and efficient image search\nmethods in their work.",
      "tldr_zh": "该论文讨论了在组织病理学(histopathology)中利用图像搜索技术的应用，包括通过相机安装显微镜或全滑扫描仪获取病理图像，并基于相似性计算匹配患者图像。作者强调，这些技术可实现组织形态的隐式量化，跨不同原发部位进行比较，从而辅助诊断、预后预测，并为新患者提供基于已诊断病例数据库的推断。总体上，该文为计算病理学研究者提供了对图像搜索方法最新发展的全面回顾，旨在推广高效、快速且有效的搜索策略。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.IR",
        "q-bio.QM"
      ],
      "primary_category": "eess.IV",
      "comment": "A chapter in the Book \"Artificial INtelligence in Digital Pathology\"\n  by Cohen and Chauhan, 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.08699v3",
      "published_date": "2024-01-14 12:38:49 UTC",
      "updated_date": "2024-03-22 03:31:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T21:47:48.906231"
    },
    {
      "arxiv_id": "2401.07278v3",
      "title": "Semi-Supervised Semantic Segmentation using Redesigned Self-Training for White Blood Cells",
      "title_zh": "翻译失败",
      "authors": [
        "Vinh Quoc Luu",
        "Duy Khanh Le",
        "Huy Thanh Nguyen",
        "Minh Thanh Nguyen",
        "Thinh Tien Nguyen",
        "Vinh Quang Dinh"
      ],
      "abstract": "Artificial Intelligence (AI) in healthcare, especially in white blood cell\ncancer diagnosis, is hindered by two primary challenges: the lack of\nlarge-scale labeled datasets for white blood cell (WBC) segmentation and\noutdated segmentation methods. These challenges inhibit the development of more\naccurate and modern techniques to diagnose cancer relating to white blood\ncells. To address the first challenge, a semi-supervised learning framework\nshould be devised to efficiently capitalize on the scarcity of the dataset\navailable. In this work, we address this issue by proposing a novel\nself-training pipeline with the incorporation of FixMatch. Self-training is a\ntechnique that utilizes the model trained on labeled data to generate\npseudo-labels for the unlabeled data and then re-train on both of them.\nFixMatch is a consistency-regularization algorithm to enforce the model's\nrobustness against variations in the input image. We discover that by\nincorporating FixMatch in the self-training pipeline, the performance improves\nin the majority of cases. Our performance achieved the best performance with\nthe self-training scheme with consistency on DeepLab-V3 architecture and\nResNet-50, reaching 90.69%, 87.37%, and 76.49% on Zheng 1, Zheng 2, and LISC\ndatasets, respectively.",
      "tldr_zh": "该论文针对白血细胞癌症诊断中数据集稀缺和分割方法过时的问题，提出了一种基于Semi-Supervised Semantic Segmentation的改进自训练框架，以高效利用有限的标注数据。框架结合Self-Training技术生成未标注数据的伪标签，并融入FixMatch一致性正则化算法，以增强模型对输入图像变异的鲁棒性。实验结果显示，在DeepLab-V3和ResNet-50架构上，该方法在Zheng 1、Zheng 2和LISC数据集上分别达到了90.69%、87.37%和76.49%的性能，显著提升了白血细胞分割准确率。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.07278v3",
      "published_date": "2024-01-14 12:22:34 UTC",
      "updated_date": "2024-02-23 10:09:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T21:48:01.288268"
    },
    {
      "arxiv_id": "2401.07271v1",
      "title": "SpineCLUE: Automatic Vertebrae Identification Using Contrastive Learning and Uncertainty Estimation",
      "title_zh": "SpineCLUE：使用对比学习和不确定性估计的自动椎骨识别",
      "authors": [
        "Sheng Zhang",
        "Minheng Chen",
        "Junxian Wu",
        "Ziyue Zhang",
        "Tonglong Li",
        "Cheng Xue",
        "Youyong Kong"
      ],
      "abstract": "Vertebrae identification in arbitrary fields-of-view plays a crucial role in\ndiagnosing spine disease. Most spine CT contain only local regions, such as the\nneck, chest, and abdomen. Therefore, identification should not depend on\nspecific vertebrae or a particular number of vertebrae being visible. Existing\nmethods at the spine-level are unable to meet this challenge. In this paper, we\npropose a three-stage method to address the challenges in 3D CT vertebrae\nidentification at vertebrae-level. By sequentially performing the tasks of\nvertebrae localization, segmentation, and identification, the anatomical prior\ninformation of the vertebrae is effectively utilized throughout the process.\nSpecifically, we introduce a dual-factor density clustering algorithm to\nacquire localization information for individual vertebra, thereby facilitating\nsubsequent segmentation and identification processes. In addition, to tackle\nthe issue of interclass similarity and intra-class variability, we pre-train\nour identification network by using a supervised contrastive learning method.\nTo further optimize the identification results, we estimated the uncertainty of\nthe classification network and utilized the message fusion module to combine\nthe uncertainty scores, while aggregating global information about the spine.\nOur method achieves state-of-the-art results on the VerSe19 and VerSe20\nchallenge benchmarks. Additionally, our approach demonstrates outstanding\ngeneralization performance on an collected dataset containing a wide range of\nabnormal cases.",
      "tldr_zh": "本研究提出SpineCLUE，一种用于任意视野脊椎CT图像的自动椎体识别方法，旨在解决现有方法依赖特定椎体或数量的局限性。该方法采用三阶段流程，包括使用双因素密度聚类算法进行椎体定位、基于监督对比学习预训练的分割和识别网络，以及不确定性估计结合消息融合模块来优化结果和聚合脊柱全局信息。通过有效利用椎体解剖先验信息，该方法在VerSe19和VerSe20基准上实现了最先进性能，并在包含异常病例的自定义数据集上展示了优秀的泛化能力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.07271v1",
      "published_date": "2024-01-14 12:02:39 UTC",
      "updated_date": "2024-01-14 12:02:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T21:48:12.896881"
    },
    {
      "arxiv_id": "2401.07263v1",
      "title": "BET: Explaining Deep Reinforcement Learning through The Error-Prone Decisions",
      "title_zh": "翻译失败",
      "authors": [
        "Xiao Liu",
        "Jie Zhao",
        "Wubing Chen",
        "Mao Tan",
        "Yongxing Su"
      ],
      "abstract": "Despite the impressive capabilities of Deep Reinforcement Learning (DRL)\nagents in many challenging scenarios, their black-box decision-making process\nsignificantly limits their deployment in safety-sensitive domains. Several\nprevious self-interpretable works focus on revealing the critical states of the\nagent's decision. However, they cannot pinpoint the error-prone states. To\naddress this issue, we propose a novel self-interpretable structure, named\nBackbone Extract Tree (BET), to better explain the agent's behavior by identify\nthe error-prone states. At a high level, BET hypothesizes that states in which\nthe agent consistently executes uniform decisions exhibit a reduced propensity\nfor errors. To effectively model this phenomenon, BET expresses these states\nwithin neighborhoods, each defined by a curated set of representative states.\nTherefore, states positioned at a greater distance from these representative\nbenchmarks are more prone to error. We evaluate BET in various popular RL\nenvironments and show its superiority over existing self-interpretable models\nin terms of explanation fidelity. Furthermore, we demonstrate a use case for\nproviding explanations for the agents in StarCraft II, a sophisticated\nmulti-agent cooperative game. To the best of our knowledge, we are the first to\nexplain such a complex scenarios using a fully transparent structure.",
      "tldr_zh": "这篇论文针对 Deep Reinforcement Learning (DRL) 代理的黑箱决策问题，提出了一种新型自解释结构 Backbone Extract Tree (BET)，旨在通过识别错误易发状态来提升代理行为的解释性。BET 基于假设，即代理在执行一致决策的状态下错误较少，并利用代表性状态的邻域来量化状态的错误风险，从而精确定位高风险区域。在各种 RL 环境中，BET 展示了比现有模型更高的解释保真度，并首次在复杂的 StarCraft II 多代理合作游戏中提供了完全透明的解释结构。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "This is an early version of a paper that submitted to IJCAI 2024 8\n  pages, 4 figures and 1 table",
      "pdf_url": "http://arxiv.org/pdf/2401.07263v1",
      "published_date": "2024-01-14 11:45:05 UTC",
      "updated_date": "2024-01-14 11:45:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T21:48:25.729460"
    },
    {
      "arxiv_id": "2402.18582v1",
      "title": "Streamlining the Selection Phase of Systematic Literature Reviews (SLRs) Using AI-Enabled GPT-4 Assistant API",
      "title_zh": "翻译失败",
      "authors": [
        "Seyed Mohammad Ali Jafari"
      ],
      "abstract": "The escalating volume of academic literature presents a formidable challenge\nin staying updated with the newest research developments. Addressing this, this\nstudy introduces a pioneering AI-based tool, configured specifically to\nstreamline the efficiency of the article selection phase in Systematic\nLiterature Reviews (SLRs). Utilizing the robust capabilities of OpenAI's GPT-4\nAssistant API, the tool successfully homogenizes the article selection process\nacross a broad array of academic disciplines. Implemented through a tripartite\napproach consisting of data preparation, AI-mediated article assessment, and\nstructured result presentation, this tool significantly accelerates the\ntime-consuming task of literature reviews. Importantly, this tool could be\nhighly beneficial in fields such as management and economics, where the SLR\nprocess involves substantial human judgment. The adoption of a standard GPT\nmodel can substantially reduce potential biases and enhance the speed and\nprecision of the SLR selection phase. This not only amplifies researcher\nproductivity and accuracy but also denotes a considerable stride forward in the\nway academic research is conducted amidst the surging body of scholarly\npublications.",
      "tldr_zh": "这篇论文提出了一种基于 AI 的工具，利用 GPT-4 Assistant API 来简化 Systematic Literature Reviews (SLRs) 中的文章选择阶段，应对学术文献数量激增的挑战。该工具采用三部分方法，包括数据准备、AI 辅助文章评估和结构化结果呈现，从而显著加速审查过程、减少潜在偏见，并提升研究者的生产力和准确性。研究强调，该工具在管理学和经济学等依赖人类判断的领域特别有益，推动了学术研究效率的整体提升。",
      "categories": [
        "cs.DL",
        "cs.AI"
      ],
      "primary_category": "cs.DL",
      "comment": "11 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.18582v1",
      "published_date": "2024-01-14 11:16:16 UTC",
      "updated_date": "2024-01-14 11:16:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T21:48:36.292717"
    },
    {
      "arxiv_id": "2401.07250v2",
      "title": "Stabilizing Sharpness-aware Minimization Through A Simple Renormalization Strategy",
      "title_zh": "翻译失败",
      "authors": [
        "Chengli Tan",
        "Jiangshe Zhang",
        "Junmin Liu",
        "Yicheng Wang",
        "Yunda Hao"
      ],
      "abstract": "Recently, sharpness-aware minimization (SAM) has attracted much attention\nbecause of its surprising effectiveness in improving generalization\nperformance. However, compared to stochastic gradient descent (SGD), it is more\nprone to getting stuck at the saddle points, which as a result may lead to\nperformance degradation. To address this issue, we propose a simple\nrenormalization strategy, dubbed Stable SAM (SSAM), so that the gradient norm\nof the descent step maintains the same as that of the ascent step. Our strategy\nis easy to implement and flexible enough to integrate with SAM and its\nvariants, almost at no computational cost. With elementary tools from convex\noptimization and learning theory, we also conduct a theoretical analysis of\nsharpness-aware training, revealing that compared to SGD, the effectiveness of\nSAM is only assured in a limited regime of learning rate. In contrast, we show\nhow SSAM extends this regime of learning rate and then it can consistently\nperform better than SAM with the minor modification. Finally, we demonstrate\nthe improved performance of SSAM on several representative data sets and tasks.",
      "tldr_zh": "该研究针对 sharpness-aware minimization (SAM) 在优化过程中容易卡在 saddle points 的问题，提出了一种简单 renormalization 策略，名为 Stable SAM (SSAM)，以确保 descent step 和 ascent step 的 gradient norm 保持一致。SSAM 方法易于实现，几乎无额外计算开销，并可灵活整合到 SAM 及其变体中。通过 convex optimization 和 learning theory 的理论分析，研究揭示 SAM 的有效性仅限于有限的学习率范围，而 SSAM 扩展了这一范围，提升了优化稳定性。实验结果显示，SSAM 在多个代表性数据集和任务上比 SAM 表现出色，验证了其性能优势。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "33 pages",
      "pdf_url": "http://arxiv.org/pdf/2401.07250v2",
      "published_date": "2024-01-14 10:53:36 UTC",
      "updated_date": "2024-09-10 02:58:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T21:48:50.395291"
    },
    {
      "arxiv_id": "2401.07237v3",
      "title": "Distilling Event Sequence Knowledge From Large Language Models",
      "title_zh": "从大型语言模型中蒸馏事件序列知识",
      "authors": [
        "Somin Wadhwa",
        "Oktie Hassanzadeh",
        "Debarun Bhattacharjya",
        "Ken Barker",
        "Jian Ni"
      ],
      "abstract": "Event sequence models have been found to be highly effective in the analysis\nand prediction of events. Building such models requires availability of\nabundant high-quality event sequence data. In certain applications, however,\nclean structured event sequences are not available, and automated sequence\nextraction results in data that is too noisy and incomplete. In this work, we\nexplore the use of Large Language Models (LLMs) to generate event sequences\nthat can effectively be used for probabilistic event model construction. This\ncan be viewed as a mechanism of distilling event sequence knowledge from LLMs.\nOur approach relies on a Knowledge Graph (KG) of event concepts with partial\ncausal relations to guide the generative language model for causal event\nsequence generation. We show that our approach can generate high-quality event\nsequences, filling a knowledge gap in the input KG. Furthermore, we explore how\nthe generated sequences can be leveraged to discover useful and more complex\nstructured knowledge from pattern mining and probabilistic event models. We\nrelease our sequence generation code and evaluation framework, as well as\ncorpus of event sequence data.",
      "tldr_zh": "本文探讨了从 Large Language Models (LLMs) 中提炼事件序列知识，以解决事件序列模型在数据缺乏或噪声问题上的挑战。研究方法利用 Knowledge Graph (KG) 包含的部分因果关系来指导 LLMs 生成高质量的因果事件序列，从而填补 KG 中的知识空白。实验结果显示，这些生成的序列可用于模式挖掘和构建概率事件模型，发现更复杂的结构化知识；此外，作者发布了序列生成代码、评估框架和事件序列数据集，以促进进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "In Proceedings of 23rd International Semantic Web Conference (ISWC),\n  2024",
      "pdf_url": "http://arxiv.org/pdf/2401.07237v3",
      "published_date": "2024-01-14 09:34:42 UTC",
      "updated_date": "2024-07-01 21:43:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T21:49:01.448925"
    },
    {
      "arxiv_id": "2401.07234v1",
      "title": "The Effects of Data Imbalance Under a Federated Learning Approach for Credit Risk Forecasting",
      "title_zh": "联邦学习方法下数据不平衡对信贷风险预测的影响",
      "authors": [
        "Shuyao Zhang",
        "Jordan Tay",
        "Pedro Baiz"
      ],
      "abstract": "Credit risk forecasting plays a crucial role for commercial banks and other\nfinancial institutions in granting loans to customers and minimise the\npotential loss. However, traditional machine learning methods require the\nsharing of sensitive client information with an external server to build a\nglobal model, potentially posing a risk of security threats and privacy\nleakage. A newly developed privacy-preserving distributed machine learning\ntechnique known as Federated Learning (FL) allows the training of a global\nmodel without the necessity of accessing private local data directly. This\ninvestigation examined the feasibility of federated learning in credit risk\nassessment and showed the effects of data imbalance on model performance. Two\nneural network architectures, Multilayer Perceptron (MLP) and Long Short-Term\nMemory (LSTM), and one tree ensemble architecture, Extreme Gradient Boosting\n(XGBoost), were explored across three different datasets under various\nscenarios involving different numbers of clients and data distribution\nconfigurations. We demonstrate that federated models consistently outperform\nlocal models on non-dominant clients with smaller datasets. This trend is\nespecially pronounced in highly imbalanced data scenarios, yielding a\nremarkable average improvement of 17.92% in model performance. However, for\ndominant clients (clients with more data), federated models may not exhibit\nsuperior performance, suggesting the need for special incentives for this type\nof clients to encourage their participation.",
      "tldr_zh": "这篇论文探讨了在Federated Learning (FL)框架下，数据不平衡对信用风险预测的影响，旨在解决传统机器学习中隐私泄露的问题。研究使用Multilayer Perceptron (MLP)、Long Short-Term Memory (LSTM)和Extreme Gradient Boosting (XGBoost)三种模型，在三个数据集上测试了不同客户端数量和数据分布场景。结果表明，FL模型在数据较少的非主导客户端上显著优于本地模型，尤其在高度不平衡数据中，平均性能提升17.92%。然而，对于数据较多的主导客户端，FL模型可能不如本地模型，因此论文建议提供激励机制以鼓励这些客户端参与。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.07234v1",
      "published_date": "2024-01-14 09:15:10 UTC",
      "updated_date": "2024-01-14 09:15:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T21:49:15.010586"
    },
    {
      "arxiv_id": "2402.01662v4",
      "title": "Generative Ghosts: Anticipating Benefits and Risks of AI Afterlives",
      "title_zh": "生成式幽灵：预见 AI 死后世界的益处和风险",
      "authors": [
        "Meredith Ringel Morris",
        "Jed R. Brubaker"
      ],
      "abstract": "As AI systems quickly improve in both breadth and depth of performance, they\nlend themselves to creating increasingly powerful and realistic agents,\nincluding the possibility of agents modeled on specific people. We anticipate\nthat within our lifetimes it may become common practice for people to create\ncustom AI agents to interact with loved ones and/or the broader world after\ndeath; indeed, the past year has seen a boom in startups purporting to offer\nsuch services. We call these generative ghosts, since such agents will be\ncapable of generating novel content rather than merely parroting content\nproduced by their creator while living. In this paper, we reflect on the\nhistory of technologies for AI afterlives, including current early attempts by\nindividual enthusiasts and startup companies to create generative ghosts. We\nthen introduce a novel design space detailing potential implementations of\ngenerative ghosts, and use this analytic framework to ground discussion of the\npractical and ethical implications of various approaches to designing\ngenerative ghosts, including potential positive and negative impacts on\nindividuals and society. Based on these considerations, we lay out a research\nagenda for the AI and HCI research communities to better understand the\nrisk/benefit landscape of this novel technology so as to ultimately empower\npeople who wish to create and interact with AI afterlives to do so in a\nbeneficial manner.",
      "tldr_zh": "该论文探讨了“generative ghosts”——一种能生成新内容的AI代理，用于在个人死后与亲人或社会互动，并预测此技术将成为常见实践。作者回顾了AI后世技术的历史，并引入一个新设计空间框架来分析generative ghosts的潜在实现方式，包括实际和伦理影响，如对个人和社会的积极益处（例如情感支持）和风险（例如误导性内容）。最终，论文提出研究议程，呼吁AI和HCI社区深入评估风险/益处，以确保人们能安全有益地创建和互动AI后世技术。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "version 4, updated to include new references and examples",
      "pdf_url": "http://arxiv.org/pdf/2402.01662v4",
      "published_date": "2024-01-14 08:57:45 UTC",
      "updated_date": "2024-12-12 20:17:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T21:49:25.352766"
    },
    {
      "arxiv_id": "2401.07220v1",
      "title": "Application of 2D Homography for High Resolution Traffic Data Collection using CCTV Cameras",
      "title_zh": "翻译失败",
      "authors": [
        "Linlin Zhang",
        "Xiang Yu",
        "Abdulateef Daud",
        "Abdul Rashid Mussah",
        "Yaw Adu-Gyamfi"
      ],
      "abstract": "Traffic cameras remain the primary source data for surveillance activities\nsuch as congestion and incident monitoring. To date, State agencies continue to\nrely on manual effort to extract data from networked cameras due to limitations\nof the current automatic vision systems including requirements for complex\ncamera calibration and inability to generate high resolution data. This study\nimplements a three-stage video analytics framework for extracting\nhigh-resolution traffic data such vehicle counts, speed, and acceleration from\ninfrastructure-mounted CCTV cameras. The key components of the framework\ninclude object recognition, perspective transformation, and vehicle trajectory\nreconstruction for traffic data collection. First, a state-of-the-art vehicle\nrecognition model is implemented to detect and classify vehicles. Next, to\ncorrect for camera distortion and reduce partial occlusion, an algorithm\ninspired by two-point linear perspective is utilized to extracts the region of\ninterest (ROI) automatically, while a 2D homography technique transforms the\nCCTV view to bird's-eye view (BEV). Cameras are calibrated with a two-layer\nmatrix system to enable the extraction of speed and acceleration by converting\nimage coordinates to real-world measurements. Individual vehicle trajectories\nare constructed and compared in BEV using two time-space-feature-based object\ntrackers, namely Motpy and BYTETrack. The results of the current study showed\nabout +/- 4.5% error rate for directional traffic counts, less than 10% MSE for\nspeed bias between camera estimates in comparison to estimates from probe data\nsources. Extracting high-resolution data from traffic cameras has several\nimplications, ranging from improvements in traffic management and identify\ndangerous driving behavior, high-risk areas for accidents, and other safety\nconcerns, enabling proactive measures to reduce accidents and fatalities.",
      "tldr_zh": "本文提出一个三阶段视频分析框架，利用CCTV摄像头自动提取高分辨率交通数据，包括车辆计数、速度和加速度，以解决当前自动系统复杂校准和数据精度问题的限制。框架的关键组件包括物体识别模型用于检测和分类车辆、2D Homography技术将CCTV视图转换为鸟瞰视图(BEV)以校正畸变和提取ROI，以及使用Motpy和BYTETrack追踪器重建车辆轨迹。实验结果显示，方向交通计数误差约+/-4.5%，速度偏差MSE小于10%，与探针数据源比较准确。该方法可提升交通管理、识别危险驾驶行为和高风险事故区域，从而减少事故发生。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "25 pages, 9 figures, this paper was submitted for consideration for\n  presentation at the 102nd Annual Meeting of the Transportation Research\n  Board, January 2023",
      "pdf_url": "http://arxiv.org/pdf/2401.07220v1",
      "published_date": "2024-01-14 07:33:14 UTC",
      "updated_date": "2024-01-14 07:33:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T21:49:39.142774"
    },
    {
      "arxiv_id": "2401.08696v1",
      "title": "Hierarchical Source-to-Post-Route QoR Prediction in High-Level Synthesis with GNNs",
      "title_zh": "翻译失败",
      "authors": [
        "Mingzhe Gao",
        "Jieru Zhao",
        "Zhe Lin",
        "Minyi Guo"
      ],
      "abstract": "High-level synthesis (HLS) notably speeds up the hardware design process by\navoiding RTL programming. However, the turnaround time of HLS increases\nsignificantly when post-route quality of results (QoR) are considered during\noptimization. To tackle this issue, we propose a hierarchical post-route QoR\nprediction approach for FPGA HLS, which features: (1) a modeling flow that\ndirectly estimates latency and post-route resource usage from C/C++ programs;\n(2) a graph construction method that effectively represents the control and\ndata flow graph of source code and effects of HLS pragmas; and (3) a\nhierarchical GNN training and prediction method capable of capturing the impact\nof loop hierarchies. Experimental results show that our method presents a\nprediction error of less than 10% for different types of QoR metrics, which\ngains tremendous improvement compared with the state-of-the-art GNN methods. By\nadopting our proposed methodology, the runtime for design space exploration in\nHLS is shortened to tens of minutes and the achieved ADRS is reduced to 6.91%\non average.",
      "tldr_zh": "本文提出了一种分层后路由 QoR 预测方法，用于 FPGA HLS，以解决优化过程中转向时间过长的问题。该方法包括从 C/C++ 程序直接估计延迟和资源使用的建模流程、有效表示源代码控制数据流和 HLS 指令影响的图构建方法，以及捕捉循环层次的分层 GNN 训练和预测技术。实验结果显示，该方法在各种 QoR 指标上预测错误率低于 10%，显著优于现有 GNN 方法，并将 HLS 设计空间探索时间缩短到几十分钟，平均 ADRS 降低至 6.91%。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AR",
      "comment": "Accepted for publication at DATE 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.08696v1",
      "published_date": "2024-01-14 07:24:08 UTC",
      "updated_date": "2024-01-14 07:24:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T21:49:50.333870"
    },
    {
      "arxiv_id": "2402.18581v1",
      "title": "Multi-objective Optimal Roadside Units Deployment in Urban Vehicular Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Weian Guo",
        "Zecheng Kang",
        "Dongyang Li",
        "Lun Zhang",
        "Li Li"
      ],
      "abstract": "The significance of transportation efficiency, safety, and related services\nis increasing in urban vehicular networks. Within such networks, roadside units\n(RSUs) serve as intermediates in facilitating communication. Therefore, the\ndeployment of RSUs is of utmost importance in ensuring the quality of\ncommunication services. However, the optimization objectives, such as time\ndelay and deployment cost, are commonly developed from diverse perspectives. As\na result, it is possible that conflicts may arise among the objectives.\nFurthermore, in urban environments, the presence of various obstacles, such as\nbuildings, gardens, lakes, and other infrastructure, poses challenges for the\ndeployment of RSUs. Hence, the deployment encounters significant difficulties\ndue to the existence of multiple objectives, constraints imposed by obstacles,\nand the necessity to explore a large-scale optimization space. To address this\nissue, two versions of multi-objective optimization algorithms are proposed in\nthis paper. By utilizing a multi-population strategy and an adaptive\nexploration technique, the methods efficiently explore a large-scale\ndecision-variable space. In order to mitigate the issue of an overcrowded\ndeployment of RSUs, a calibrating mechanism is adopted to adjust RSU density\nduring the optimization procedures. The proposed methods also take care of data\noffloading between vehicles and RSUs by setting up an iterative best response\nsequence game (IBRSG). By comparing the proposed algorithms with several\nstate-of-the-art algorithms, the results demonstrate that our strategies\nperform better in both high-density and low-density urban scenarios. The\nresults also indicate that the proposed solutions substantially improve the\nefficiency of vehicular networks.",
      "tldr_zh": "本研究针对城市车辆网络中路边单位（RSUs）的部署问题，强调了多目标优化（如时延和部署成本）的冲突，以及城市障碍物（如建筑物）带来的挑战。论文提出两种多-objective optimization算法，采用多群策略、自适应探索技术及校准机制来优化大规模决策空间，并通过迭代最佳响应序列游戏（IBRSG）处理车辆与RSUs的数据卸载，以避免RSU过度部署。实验结果显示，该方法在高密度和低密度城市场景下比现有算法性能更优，提升了车辆网络的整体效率。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "This manuscript has been submitted to the journal of IEEE\n  Transactions on Vehicular Technology",
      "pdf_url": "http://arxiv.org/pdf/2402.18581v1",
      "published_date": "2024-01-14 05:02:12 UTC",
      "updated_date": "2024-01-14 05:02:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T21:50:01.516714"
    },
    {
      "arxiv_id": "2401.09476v1",
      "title": "A Framework for Agricultural Food Supply Chain using Blockchain",
      "title_zh": "基于区块链的农业食品供应链框架",
      "authors": [
        "Sudarssan N"
      ],
      "abstract": "The main aim of the paper is to create a trust and transparency in the food\nsupply chain system, ensuring food safety for everyone with the help of\nBlockchain Technology. Food supply chain is the process of tracing a crop from\nthe farmer or producer to the buyer. With the advent of blockchain, providing a\nsafe and fraud-free environment for the provision of numerous agricultural\nnecessities has become much easier. Because of the globalization of trade, the\npresent supply chain market today includes various companies involving\nintegration of data, complex transactions and distribution. Information tamper\nresistance, supply-demand relationships, and traceable oversight are all\ndifficulties that arise as a result of this. Blockchain is a distributed ledger\ntechnology that can provide information that is resistant to tampering. This\nstrategy can eliminate the need for a centralized trusted authority,\nintermediaries, and business histories, allowing for increased production and\nsecurity while maintaining the highest levels of integrity, liability, and\nsafety. In order to have an integrity and transparency in food supply chain in\nthe agricultural sector, a framework is proposed here based on block chain and\nIoT.",
      "tldr_zh": "本研究提出一个基于区块链（Blockchain）的框架，用于农业食品供应链，以提升信任、透明度和食品安全。该框架通过区块链技术实现信息防篡改（Information tamper resistance）和可追溯监督，结合物联网（IoT）来处理复杂的供应链交易和分布问题。相比传统系统，该方法消除了中心化权威和中间商的需求，提高了生产力、安全性和完整性，从而为全球化的农业供应链提供更可靠的解决方案。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "5 Pages, 5 figures, Under Review",
      "pdf_url": "http://arxiv.org/pdf/2401.09476v1",
      "published_date": "2024-01-14 04:16:01 UTC",
      "updated_date": "2024-01-14 04:16:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T21:50:12.129195"
    },
    {
      "arxiv_id": "2401.08695v1",
      "title": "Enabling Collaborative Clinical Diagnosis of Infectious Keratitis by Integrating Expert Knowledge and Interpretable Data-driven Intelligence",
      "title_zh": "翻译失败",
      "authors": [
        "Zhengqing Fang",
        "Shuowen Zhou",
        "Zhouhang Yuan",
        "Yuxuan Si",
        "Mengze Li",
        "Jinxu Li",
        "Yesheng Xu",
        "Wenjia Xie",
        "Kun Kuang",
        "Yingming Li",
        "Fei Wu",
        "Yu-Feng Yao"
      ],
      "abstract": "Although data-driven artificial intelligence (AI) in medical image diagnosis\nhas shown impressive performance in silico, the lack of interpretability makes\nit difficult to incorporate the \"black box\" into clinicians' workflows. To make\nthe diagnostic patterns learned from data understandable by clinicians, we\ndevelop an interpretable model, knowledge-guided diagnosis model (KGDM), that\nprovides a visualized reasoning process containing AI-based biomarkers and\nretrieved cases that with the same diagnostic patterns. It embraces clinicians'\nprompts into the interpreted reasoning through human-AI interaction, leading to\npotentially enhanced safety and more accurate predictions. This study\ninvestigates the performance, interpretability, and clinical utility of KGDM in\nthe diagnosis of infectious keratitis (IK), which is the leading cause of\ncorneal blindness. The classification performance of KGDM is evaluated on a\nprospective validation dataset, an external testing dataset, and an publicly\navailable testing dataset. The diagnostic odds ratios (DOR) of the interpreted\nAI-based biomarkers are effective, ranging from 3.011 to 35.233 and exhibit\nconsistent diagnostic patterns with clinic experience. Moreover, a human-AI\ncollaborative diagnosis test is conducted and the participants with\ncollaboration achieved a performance exceeding that of both humans and AI. By\nsynergistically integrating interpretability and interaction, this study\nfacilitates the convergence of clinicians' expertise and data-driven\nintelligence. The promotion of inexperienced ophthalmologists with the aid of\nAI-based biomarkers, as well as increased AI prediction by intervention from\nexperienced ones, demonstrate a promising diagnostic paradigm for infectious\nkeratitis using KGDM, which holds the potential for extension to other diseases\nwhere experienced medical practitioners are limited and the safety of AI is\nconcerned.",
      "tldr_zh": "本文提出了一种可解释模型Knowledge-Guided Diagnosis Model (KGDM)，通过整合AI-based biomarkers、检索类似病例和临床医生互动，提供可视化推理过程，以提升感染性角膜炎（infectious keratitis）的诊断准确性和安全性。KGDM在多个数据集上评估，诊断优势比（DOR）从3.011到35.233，展现出与临床经验一致的诊断模式。研究进行的人-AI协作测试显示，参与者通过协作实现的表现优于单独人类或AI。总体而言，此方法促进了临床专家知识与数据驱动智能的融合，具有扩展到其他疾病的潜力，以辅助经验不足的医生并提升AI的安全性。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "33 pages",
      "pdf_url": "http://arxiv.org/pdf/2401.08695v1",
      "published_date": "2024-01-14 02:10:54 UTC",
      "updated_date": "2024-01-14 02:10:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T21:50:27.082558"
    },
    {
      "arxiv_id": "2401.07179v1",
      "title": "Forecasting GDP in Europe with Textual Data",
      "title_zh": "基于文本数据的欧洲 GDP 预测",
      "authors": [
        "Luca Barbaglia",
        "Sergio Consoli",
        "Sebastiano Manzan"
      ],
      "abstract": "We evaluate the informational content of news-based sentiment indicators for\nforecasting Gross Domestic Product (GDP) and other macroeconomic variables of\nthe five major European economies. Our data set includes over 27 million\narticles for 26 major newspapers in 5 different languages. The evidence\nindicates that these sentiment indicators are significant predictors to\nforecast macroeconomic variables and their predictive content is robust to\ncontrolling for other indicators available to forecasters in real-time.",
      "tldr_zh": "本文评估了基于新闻的情绪指标（sentiment indicators）在预测欧洲五大经济体 GDP 和其他宏观经济变量方面的信息含量。研究利用了超过 2700 万篇文章的数据，涵盖 26 家主要报纸和 5 种语言。结果显示，这些情绪指标是显著的预测因子，且其预测价值在控制其他实时可用指标后保持稳健。",
      "categories": [
        "cs.CE",
        "cs.AI",
        "cs.CL",
        "91B62, 91B84, 91B86"
      ],
      "primary_category": "cs.CE",
      "comment": "34 pages, 6 figures, published in Journal of Applied Econometrics\n  (Early view)",
      "pdf_url": "http://arxiv.org/pdf/2401.07179v1",
      "published_date": "2024-01-14 00:33:30 UTC",
      "updated_date": "2024-01-14 00:33:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T21:50:37.064101"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 30,
  "processed_papers_count": 30,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-16T21:50:54.939093"
}